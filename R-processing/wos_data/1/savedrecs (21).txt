FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Das, R
   Debnath, D
   Pakray, P
   Kumar, NC
AF Das, Ranjita
   Debnath, Dipanwita
   Pakray, Partha
   Kumar, Naga Chaitanya
TI A binary grey wolf optimizer to solve the scientific document
   summarization problem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE ScisummNet; Grey wolf optimization; Extractive text summarization; News
   summarization; Scientific document summarization; Research article
   summarization
AB The extraction of information from the extensive volume of online textual data poses a significant challenge, and text summarization plays a pivotal role in overcoming this challenge. Conventionally, an extractive text summary, which consists of the most relevant sentences from the text itself, can effectively represent the given text. However, identifying such a subset of sentences is challenging. To overcome this problem, this paper introduces a Binary Gray Wolf Optimization (BGWO)-based text summarization approach that tackles the sentence selection problem. The proposed system performs pre-processing on the input texts, identifies noteworthy features, and generates a text segment that includes the most relevant sentences. Subsequently, the BGWO algorithm is employed to generate an optimal summary from the text segment. The BGWO-based text summarization approach begins by initializing the population as a set of feasible solution vectors represented by binary values, indicating the presence or absence of sentences in the summary. Thereafter, fitness functions incorporating textual features are constructed, and the population's fitness is evaluated. Through non-dominated sorting and crowding distance, individuals are categorized as alpha, beta, delta, or gamma wolves. In each iteration, their positions are updated using crossover and mutation operations, and individuals are ranked based on their fitness scores. Finally, the alpha wolf is selected as the optimal summary candidate. The proposed method is evaluated and compared to various existing methods on the DUC-2001, DUC-2002, and ScisummNet datasets using ROUGE measures. Statistics based on ROUGE scores are also computed, demonstrating that the proposed system is statistically significant. The experimental results demonstrate that BGWO outperforms ROUGE scores for single-document summarization, including low-resource documents.
C1 [Das, Ranjita] Natl Inst Technol Agartala, Dept Comp Sci & Engn, Agartala 799046, Tripura, India.
   [Das, Ranjita; Debnath, Dipanwita; Kumar, Naga Chaitanya] Natl Inst Technol Mizoram, Dept Comp Sci & Engn, Aizawl 796012, Mizoram, India.
   [Debnath, Dipanwita] Koneru Lakshmaiah Educ Fdn, Dept CSE, Vaddeswaram 522302, India.
   [Pakray, Partha] Natl Inst Technol Silchar, Dept Comp Sci & Engn, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Agartala; National Institute of Technology (NIT System);
   National Institute of Technology Mizoram; Koneru Lakshmaiah Education
   Foundation (K L Deemed to be University); National Institute of
   Technology (NIT System); National Institute of Technology Silchar
RP Das, R (corresponding author), Natl Inst Technol Agartala, Dept Comp Sci & Engn, Agartala 799046, Tripura, India.; Das, R (corresponding author), Natl Inst Technol Mizoram, Dept Comp Sci & Engn, Aizawl 796012, Mizoram, India.
EM ranjita.nitm@gmail.com; ddebnath.nita@gmail.com; partha@cse.nits.ac.in;
   cnck1999@gmail.com
RI Pakray, Partha/H-7805-2012
CR Alguliyev RM, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12340
   Aliguliyev RM, 2009, EXPERT SYST APPL, V36, P7764, DOI 10.1016/j.eswa.2008.11.022
   Assent I, 2008, PROC INT CONF DATA, P307, DOI 10.1109/ICDE.2008.4497439
   Beltagy I, 2020, Arxiv, DOI arXiv:2004.05150
   Cao Z, 2016, P JOINT WORKSH BIBL, P132
   Chakraborty T, 2016, Arxiv, DOI arXiv:1609.00081
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Debnath Dipanwita, 2022, Advanced Techniques for IoT Applications: Proceedings of EAIT 2020. Lecture Notes in Networks and Systems. (LNNS 292), P289, DOI 10.1007/978-981-16-4435-1_28
   Debnath D, 2018, BIRNDL SIGIR, P164
   Debnath D, 2021, NEURAL COMPUT APPL, DOI 10.1007/s00521-021-06337-4
   Debnath D, 2020, INT CONF SOFT COMP, P244, DOI [10.1109/ISCMI51676.2020.9311571, 10.1109/iscmi51676.2020.9311571]
   Deng Z., 2021, Automatic related work section generation by sentence extraction and reordering
   Emary E, 2016, NEUROCOMPUTING, V172, P371, DOI 10.1016/j.neucom.2015.06.083
   Garzone M, 2000, LECT NOTES ARTIF INT, V1822, P337
   Ghodratnama S, 2020, IEEE ACCESS, V8, P139084, DOI 10.1109/ACCESS.2020.3012539
   Hernández-Alvarez M, 2016, NAT LANG ENG, V22, P327, DOI 10.1017/S1351324915000388
   Hong M, 2021, MATH COMPUT SIMULAT, V185, P88, DOI 10.1016/j.matcom.2020.12.009
   Jaidka K., 2016, P JOINT WORKSH BIBLI, P93
   Jaidka K, 2019, Arxiv, DOI arXiv:1909.00764
   Jana E, 2020, TRENDS APPL TEXT SUM, P216
   Khan A, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/7526580
   Lewis M, 2019, Arxiv, DOI [arXiv:1910.13461, DOI 10.48550/ARXIV.1910.13461]
   Li L, 2016, P JOINT WORKSH BIBL, P156
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Liu Y., 2019, ARXIV
   Ma S, 2018, BIRNDL SIGIR
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Nomoto T., 2016, P JOINT WORKSH BIBL, P168
   Ramadhan MR, 2020, 2020 4 INT C INF COM, P1, DOI [10.1109/ICICoS51170.2020.9299005, DOI 10.1109/ICICOS51170.2020.9299005]
   Saini N, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0223477
   Saini N, 2019, KNOWL-BASED SYST, V164, P45, DOI 10.1016/j.knosys.2018.10.021
   Sanchez-Gomez JM, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106231
   Too J, 2018, COMPUTERS, V7, DOI 10.3390/computers7040058
   Vázquez E, 2018, J INTELL FUZZY SYST, V35, P353, DOI 10.3233/JIFS-169594
   Vladimir B, 2003, ARXIV
   Wan Xiaojun., 2005, CIKM '05: Proceedings of the 14th ACM international conference on Information and knowledge management, P301
   Wang, 2018, BIRNDL SIGIR
   Park JW, 2020, Arxiv, DOI arXiv:2007.03405
   Zerva C, 2020, SCIENTOMETRICS, V125, P3109, DOI 10.1007/s11192-020-03455-z
NR 40
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 17
PY 2023
DI 10.1007/s11042-023-16358-x
EA AUG 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P3YY0
UT WOS:001050048600014
DA 2024-07-18
ER

PT J
AU Guo, X
   Zhang, YD
   Lu, SY
   Lu, ZH
AF Guo, Xing
   Zhang, Yudong
   Lu, Siyuan
   Lu, Zhihai
TI Facial expression recognition: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Facial expression recognition; Machine learning; Deep learning;
   Expression dataset
ID FEATURE-EXTRACTION; RECOMMENDATION SYSTEM; EMOTION RECOGNITION; FACE
   RECOGNITION; NEURAL-NETWORK; FEATURES; DATABASE; PATTERN
AB Facial expression recognition has become a hot issue in the field of artificial intelligence. So, we collect literature on facial expression recognition. First, methods based on machine learning are introduced in detail, which include image preprocessing, feature extraction, and image classification. Then, we review deep learning methods in detail: convolutional neural networks, deep belief networks, generative adversarial networks, and recurrent neural networks. Moreover, the advantages and limitations of different facial expression recognition methods are compared. In addition, 20 commonly used facial expression datasets are collected in this paper, and the types of expressions and the number of images contained in each dataset are summarized. Finally, the current problems and future development of facial expression recognition are concluded.
C1 [Guo, Xing; Lu, Zhihai] Nanjing Normal Univ, Sch Educ Sci, Nanjing 210023, Jiangsu, Peoples R China.
   [Zhang, Yudong; Lu, Siyuan] Univ Leicester, Sch Comp & Math Sci, Leicester LE1 7RH, England.
C3 Nanjing Normal University; University of Leicester
RP Lu, ZH (corresponding author), Nanjing Normal Univ, Sch Educ Sci, Nanjing 210023, Jiangsu, Peoples R China.
EM guoxing@njnu.edu.cn; yudongzhang@ieee.org; sl672@le.ac.uk;
   luzhihai@njnu.edu.cn
RI Arjmandmanesh, Saba/AGA-7907-2022; lu, siyuan/HPC-7372-2023; Zhang,
   Yudong/I-7633-2013
OI guo, xing/0000-0001-9963-7025
CR Aamir M, 2020, ARAB J SCI ENG, V45, P10605, DOI 10.1007/s13369-020-04811-0
   Abdulrahman M, 2014, SIG PROCESS COMMUN, P2265, DOI 10.1109/SIU.2014.6830717
   Aifanti N., 2010, P 11 INT WORKSHOP IM
   Albahli S, 2021, CURR MED IMAGING, V17, P973, DOI 10.2174/1573405616666201123120417
   Alenazy WM, 2021, J AMB INTEL HUM COMP, V12, P1631, DOI 10.1007/s12652-020-02235-0
   Ali G, 2020, IEEE ACCESS, V8, P134950, DOI 10.1109/ACCESS.2020.3009908
   Ali K, 2019, INT J COMPUT SCI NET, P1738
   Ali K, 2021, INT C PATT RECOG, P9460, DOI 10.1109/ICPR48806.2021.9412172
   Andrew G, 2012, INT CONF ACOUST SPEE, P4265, DOI 10.1109/ICASSP.2012.6288861
   Aneja D, 2016, 13 AS C COMP VIS ACC
   [Anonymous], 2010, PROC 3 INT WORKSHOP
   [Anonymous], 2002, IEEE INT C AUT FAC G
   Barman A, 2019, IET IMAGE PROCESS, V13, P1349, DOI 10.1049/iet-ipr.2018.5481
   Bashyal S, 2008, ENG APPL ARTIF INTEL, V21, P1056, DOI 10.1016/j.engappai.2007.11.010
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2022, ENVIRON SCI POLLUT R, V29, P14780, DOI 10.1007/s11356-021-16627-y
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Cambridge AL, ORL DAT FAC
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen LI., 2019, COMPUT ENG DES, V40, P1430
   Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353
   Chengeta K, 2019, P 11 INT C COMP COLL, V11684, P85
   Choi S, 2012, AIK C, P242
   Chowdary MK, 2023, NEURAL COMPUT APPL, V35, P23311, DOI 10.1007/s00521-021-06012-8
   Christou N, 2019, ADV INTELL SYST COMP, V797, P539, DOI 10.1007/978-981-13-1165-9_49
   Cohn Jeffrey, 2007, The handbook of emotion elicitation and assessment, P203, DOI DOI 10.1093/OSO/9780195169157.003.0014
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Dhall A, 2011, ACTED FACIAL EXPT WI
   Dhall A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Dharanya V, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103110
   Dubey M., 2016, International Research Journal of Engineering and Technology (IRJET), V3, P488
   Ebner NC, 2010, BEHAV RES METHODS, V42, P351, DOI 10.3758/BRM.42.1.351
   Eddy SR, 1996, CURR OPIN STRUC BIOL, V6, P361, DOI 10.1016/S0959-440X(96)80056-X
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Fang YX, 2022, MULTIMED TOOLS APPL, V81, P16863, DOI 10.1007/s11042-022-12592-x
   [冯晓毅 Feng Xiaoyi], 2020, [西北大学学报. 自然科学版, Journal of Northwest University. Natural Science Edition], V50, P319
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gopalan NP., 2019, FACIAL EXPRESSION RE
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Guo X, 2022, CMES-COMP MODEL ENG, V130, P23, DOI 10.32604/cmes.2021.017679
   Hablani R, 2020, BIOSCI BIOTECH RES C, V13, P185, DOI 10.21786/bbrc/13.14/44
   Han ZY, 2021, NEURAL PROCESS LETT, V53, P4189, DOI 10.1007/s11063-021-10591-x
   Han ZY, 2019, NEUROCOMPUTING, V368, P188, DOI 10.1016/j.neucom.2019.08.049
   Hassan SM, 2021, ENG TECHNOL APPL SCI, V11, P7172, DOI 10.48084/etasr.4080
   He Y, 2020, IEEE ACCESS, V8, P190184, DOI 10.1109/ACCESS.2020.3032406
   Heng Wei, 2020, 2020 15th IEEE Conference on Industrial Electronics and Applications (ICIEA), P90, DOI 10.1109/ICIEA48937.2020.9248180
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hong J, 2020, LECT NOTES COMPUT SC, V11962, P100, DOI 10.1007/978-3-030-37734-2_9
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   [胡敏 Hu Min], 2020, [电子测量与仪器学报, Journal of Electronic Measurement and Instrument], V34, P103
   Hu YY, 2021, I C COMM SOFTW NET, P318, DOI 10.1109/ICCSN52437.2021.9463605
   Huang K, 2020, LECT NOTES COMPUT SC, V11962, P161, DOI 10.1007/978-3-030-37734-2_14
   Huang Y., 2019, Facial expression recognition: A survey, V11, page, P1189
   Ilyas BR, 2019, INT C CONTROL DECISI, P344, DOI [10.1109/CoDIT.2019.8820410, 10.1109/codit.2019.8820410]
   Jabid Taskeed, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P482, DOI 10.1109/AVSS.2010.17
   [蒋斌 Jiang Bin], 2019, [计算机科学, Computer Science], V46, P53
   Jin X, 2020, INT J MACH LEARN CYB, V11, P779, DOI 10.1007/s13042-019-01024-2
   Jung H, 2015, KOR-JPN JT WORKS FR
   Khan SA, 2018, INFORM-J COMPUT INFO, V42, P507, DOI 10.31449/inf.v42i4.2037
   Khanzada A, 2020, ARXIV
   Kim S, 2017, INT SOC DES C SEOUL
   Kolakowska A, 2014, ADV INTELL SYST, V300, P51, DOI 10.1007/978-3-319-08491-6_5
   Kuang L., 2016, Facial expression recognition method based on convolutional network integration
   Küntzler T, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.627561
   Kuo CM, 2018, IEEE COMPUT SOC CONF, P2202, DOI 10.1109/CVPRW.2018.00286
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Li C., 2009, 2008 2 INT S INT INF
   Li H, 2019, IEEE INT C INT ROBOT, P94, DOI 10.1109/ICRIS.2019.00032
   Li Q, 2019, CHIN AUTOM CONGR, P4526, DOI [10.1109/cac48633.2019.8996796, 10.1109/CAC48633.2019.8996796]
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Li SZ, 2011, HDB FACE RECOGNITION, P305
   Li TF, 2022, EURASIP J WIREL COMM, V2022, DOI 10.1186/s13638-022-02106-6
   Liang XC, 2019, J PHYS CONF SER, V1229, DOI 10.1088/1742-6596/1229/1/012002
   Lipton Z. C., 2015, ARXIV
   Liu Fangyuan, 2018, Computer Engineering and Applications, V54, P11, DOI 10.3778/j.issn.1002-8331.1711-0028
   Liu HY, 2020, IEEE INT CONF AUTOMA, P615, DOI 10.1109/FG47880.2020.00102
   Liu J, 2021, IEEE ACCESS, V9, P12158, DOI 10.1109/ACCESS.2021.3051403
   Liu ZT, 2015, CHIN CONTR CONF, P3852
   Lu LH, 2021, COMPUT INTELL-US, V1
   Lucey P, 2010, COMPUTER VISION PATT
   Lundqvist D., 1998, The Karolinska Directed Emotional Faces-KDEF
   Luo Y, 2013, OPTIK, V124, P2767, DOI 10.1016/j.ijleo.2012.08.040
   Lyons MJ., 1998, The Japanese female facial expression (JAFFE) database
   Ma H, 2021, SIGNAL IMAGE VIDEO P, V15, P1507, DOI 10.1007/s11760-021-01883-9
   Ma SH, 2019, CHIN CONT DECIS CONF, P640, DOI [10.1109/CCDC.2019.8833483, 10.1109/ccdc.2019.8833483]
   Mavadati M, 2016, IEEE COMPUT SOC CONF, P1452, DOI 10.1109/CVPRW.2016.182
   Mehrabian A., 1974, APPROACH ENV PSYCHOL, P222, DOI DOI 10.1016/J.ELERAP.2013.07.001
   Mishra N, 2021, 2021 5 INT C INT COM
   Mohan K, 2021, NEURAL COMPUT APPL, V33, P9125, DOI 10.1007/s00521-020-05676-y
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Mungra D, 2020, MULTIMED TOOLS APPL, V79, P2285, DOI 10.1007/s11042-019-08397-0
   Murugappan M, 2020, 2020 4 INT C COMP CO
   Nagar P., 2015, INT J ADV INF TECHNO, V5, P5
   Nawaz SA, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256971
   Ngo QT, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092639
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Patel K, 2020, IEEE ACCESS, V8, P90495, DOI 10.1109/ACCESS.2020.2993803
   Peng X, 2017, IEEE I CONF COMP VIS, P1632, DOI 10.1109/ICCV.2017.180
   Raghu V.N., 2020, ARXIV
   Rahimzadeh M, 2021, INTRO NEW DATASET ME
   Rajan S, 2020, IET IMAGE PROCESS, V14, P1373, DOI 10.1049/iet-ipr.2019.1188
   Rao K, 2005, P 2 IND INT C ART IN
   Rokkones AS, 2019, IEEE ICCE, P283, DOI [10.1109/icce-berlin47944.2019.8966234, 10.1109/ICCE-Berlin47944.2019.8966234]
   Saito JH, 2005, ESANN 2005 13 EUR S
   Sawyer R, 2017, PROCEEDINGS OF THE 25TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'17), P192, DOI 10.1145/3079628.3079686
   Sengupta S, 2016, IEEE WINT CONF APPL
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shan D., 2005, IEEE INT C IM PROC G
   Shan SG, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P157
   Sharma R., 2016, INT J COMPUT APPL, V153, P32
   Sharma S., 2016, INT J SCI RES DEV, V4, P1905
   Shehu HA, 2020, 4 INT C MATH SCI ICM
   Shiva Prakash B, 2019, INT C SOFT COMP PROB
   Singh S, 2020, 2020 10TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P324, DOI [10.1109/ccwc47524.2020.9031283, 10.1109/CCWC47524.2020.9031283]
   Song KS, 2019, IEEE ROMAN, DOI 10.1109/ro-man46459.2019.8956436
   Song L, 2019, 2019 IEEE ACIS 18 IN
   Sun JM, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3545, DOI 10.1109/ICMLC.2008.4621018
   [孙雪华 Sun Xuehua], 2020, [云南大学学报. 自然科学版, Journal of Yunnan University. Natural Science], V42, P877
   Supta SR, 2020, PROCEEDINGS OF 2020 6TH IEEE INTERNATIONAL WOMEN IN ENGINEERING (WIE) CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (WIECON-ECE 2020), P66, DOI 10.1109/WIECON-ECE52138.2020.9397965
   Uçar A, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA), P371, DOI 10.1109/INISTA.2017.8001188
   Uddin MZ, 2017, IEEE ACCESS, V5, P4525, DOI 10.1109/ACCESS.2017.2676238
   Ullah A, 2018, 2018 14 IEEE INT C S
   Vedantham R, 2020, MULTIMED TOOLS APPL, V79, P21487, DOI 10.1007/s11042-020-08901-x
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Viroonluecha P., 2020, 15 INT JOINT S ART I
   Wang F, 2019, CHIN INT AUT C JIANG, V586, P138
   Wang M., 2010, 2010 INT C COMP APPL
   Wang WX, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P211, DOI 10.1145/3343031.3351032
   Wang YB, 2004, INT C PATT RECOG, P926, DOI 10.1109/ICPR.2004.1334680
   Whitehill J, 2009, IEEE T PATTERN ANAL, V31, P2106, DOI 10.1109/TPAMI.2009.42
   Wingenbach TSH, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147112
   Xu QT, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P2304, DOI [10.1109/itnec48623.2020.9084763, 10.1109/ITNEC48623.2020.9084763]
   Xu Y, 2016, PATTERN RECOGN, V54, P68, DOI 10.1016/j.patcog.2015.12.017
   Yadav KS, 2020, MULTIMED TOOLS APPL, V79, P13089, DOI 10.1007/s11042-019-08443-x
   Yaermaimaiti Y, 2021, J DECIS SYST, DOI 10.1080/12460125.2021.1961378
   Yan Y, 2020, IEEE T MULTIMEDIA, V22, P2792, DOI 10.1109/TMM.2019.2962317
   Yang B, 2020, RADIOENGINEERING, V29, P259, DOI 10.13164/re.2020.0259
   Yang HY, 2018, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2018.00231
   Yang L, 2020, KNOWL-BASED SYST, V204, DOI 10.1016/j.knosys.2020.106217
   Yang Y., 2014, SOFTWARE, V35, P115
   Yao L, 2021, MULTIMED TOOLS APPL, V80, P24287, DOI 10.1007/s11042-021-10836-w
   Yin L., 2006, INT C AUT FAC GEST R
   Yue CT, 2019, PROC ADAPT LEARN OPT, V10, P12, DOI 10.1007/978-3-030-01520-6_2
   Zhalehpour S, 2017, IEEE T AFFECT COMPUT, V8, P300, DOI 10.1109/TAFFC.2016.2553038
   Zhang SQ, 2019, IEEE ACCESS, V7, P32297, DOI 10.1109/ACCESS.2019.2901521
   Zhang T., 2017, IEEE T AFFECT COMPUT, V13, P1195
   Zhang T, 2019, IEEE T CYBERNETICS, V49, P839, DOI 10.1109/TCYB.2017.2788081
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
   [张翼鹏 Zhang Yipeng], 2013, [电子与信息学报, Journal of Electronics & Information Technology], V35, P1630
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
   Zhao R, 2021, INT C PATT RECOG, P4412, DOI 10.1109/ICPR48806.2021.9413000
   Zhao XM, 2016, IETE TECH REV, V33, P505, DOI 10.1080/02564602.2015.1117403
   Zheng H, 2020, INFORM SCIENCES, V533, P60, DOI 10.1016/j.ins.2020.04.041
   Zhi RC, 2019, PROCEEDINGS OF 2019 IEEE 8TH JOINT INTERNATIONAL INFORMATION TECHNOLOGY AND ARTIFICIAL INTELLIGENCE CONFERENCE (ITAIC 2019), P1373, DOI [10.1109/ITAIC.2019.8785844, 10.1109/itaic.2019.8785844]
   Zhou J, 2020, MULTIMED TOOLS APPL, V79, P26305, DOI 10.1007/s11042-020-08919-1
   Zhou Tao, 2020, Computer Engineering and Applications, V56, P24, DOI 10.3778/j.issn.1002-8331.1911-0183
   Zhou X, 2021, J INF PROCESS SYST, V17, P337, DOI 10.3745/JIPS.01.0067
NR 160
TC 0
Z9 0
U1 82
U2 144
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 17
PY 2023
DI 10.1007/s11042-023-15982-x
EA AUG 2023
PG 47
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P3YY0
UT WOS:001050048600010
DA 2024-07-18
ER

PT J
AU Rustam, F
   Sharif, MZ
   Aljedaani, W
   Lee, E
   Ashraf, I
AF Rustam, Furqan
   Sharif, Muhammad Zahid
   Aljedaani, Wajdi
   Lee, Ernesto
   Ashraf, Imran
TI Bee detection in bee hives using selective features from acoustic data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Bee detection; Acoustic analysis; Feature engineering; Mel-frequency
   cepstral features
ID LANGUAGE; SOUND
AB Honeybees, a key pollinator of the world's most cultivated crops, are experiencing colony collapses due to a variety of factors. The existence of honeybees and queens is critical to the sociality of a colony, and the presence of bees in agricultural settings is vital to the ecological balance. Moreover, beehives without a queen may lead to the decline of an entire colony therefore finding them through effective and an accurate approach is a critical task. In this scenario, we analyzed acoustic/sound data of various classes (i.e. Bee, NoBee, and NoQueen) from beehive colonies. This study examines five distinct features including spectral centroid, zero-crossing rate, Mel-frequency cepstral coefficients (MFCC), chromagram, and constant Q-transform characteristics for their suitability in detecting bees using the acoustic data. In addition, selective features using principal component analysis (PCA), Chi-square analysis (Chi2), and singular value decomposition (SVD) are used. Moreover, the study proposes hybrid features where selective PCA, Chi2, and SVD characteristics are integrated to create a suitable feature set. Experimental results exhibit the suitability of the hybrid feature set which outperformed individual features for "Bee", "NoBee" and "NoQueen" classes prediction. Cross-validation and T-test results also confirm the superior performance of hybrid MFCC features. The results indicate that RF and KNN show better performance than other machine learning models with maximum accuracy scores of 0.82 and 0.83, respectively.
C1 [Rustam, Furqan] Univ Coll Dublin, Sch Comp Sci, Dublin D04 V1W8, Ireland.
   [Sharif, Muhammad Zahid] Chinese Acad Sci, Hefei Inst Phys Sci, Hefei 230031, Peoples R China.
   [Sharif, Muhammad Zahid] Univ Sci & Technol China, Hefei 230026, Peoples R China.
   [Aljedaani, Wajdi] Univ North Texas, 155 Union Cir, Denton, TX 76203 USA.
   [Lee, Ernesto] Miami Dade Coll, Coll Engn & Technol, Miami, FL USA.
   [Ashraf, Imran] Yeungnam Univ, Informat & Commun Engn, Gyongsan 38541, South Korea.
C3 University College Dublin; Chinese Academy of Sciences; Hefei Institutes
   of Physical Science, CAS; Chinese Academy of Sciences; University of
   Science & Technology of China, CAS; University of North Texas System;
   University of North Texas Denton; Yeungnam University
RP Ashraf, I (corresponding author), Yeungnam Univ, Informat & Commun Engn, Gyongsan 38541, South Korea.
EM furqan.rustam1@gmail.com; 2011ag4010@uaf.edu.pk; wajdi.j1@gmail.com;
   elee@mdc.edu; imranashraf@ynu.ac.kr
RI Rustam, Furqan/ABE-4772-2020
OI Rustam, Furqan/0000-0001-8403-1047; Ashraf, Imran/0000-0002-8271-6496
CR Abrol DP, 2012, POLLINATION BIOLOGY: BIODIVERSITY CONSERVATION AND AGRICULTURAL PRODUCTION, P1, DOI 10.1007/978-94-007-1942-2
   Andreev N., 2017, LACTIC ACID FERMENTA, DOI [10.1201/9781315116280, DOI 10.1201/9781315116280]
   Anwar O, 2022, COMPUT ELECTRON AGR, V201, DOI 10.1016/j.compag.2022.107281
   Mezquida DA, 2009, SPAN J AGRIC RES, V7, P824
   Bachu R., 2008, AM SOC ENG ED ASEE Z, P1
   Birajdar GK, 2020, J AMB INTEL HUM COMP, V11, P329, DOI 10.1007/s12652-019-01303-4
   Bortolotti L., 2014, Neurobiology of Chemical Communication, DOI DOI 10.1201/B16511-6
   Braga AR, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2019.105161
   Calderone NW, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0037235
   Cecchi S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092726
   Cejrowski T, 2018, LECT NOTES ARTIF INT, V10752, P297, DOI 10.1007/978-3-319-75420-8_28
   Chakroborty S, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY, VOLS 1-6, P2914
   Debauche O, 2018, PROCEDIA COMPUT SCI, V130, P991, DOI 10.1016/j.procs.2018.04.103
   Ellis DP., 2007, Classifying music audio with timbral and chroma features
   Epa, 2020, PEST ISS WORKS HON B
   Eskov E., 2011, ENTOMOL REV, V91, P347, DOI [10.1134/S0013873811030092, DOI 10.1134/S0013873811030092]
   Fallucchi F, 2009, P WORKSH GEOM MOD NA, P66
   Fatima E, 2021, IEEE ACCESS, V9, P28101, DOI 10.1109/ACCESS.2021.3056285
   Ferrari S, 2008, COMPUT ELECTRON AGR, V64, P72, DOI 10.1016/j.compag.2008.05.010
   Flores JM, 2019, SCI TOTAL ENVIRON, V653, P1111, DOI 10.1016/j.scitotenv.2018.11.004
   FRINGS H, 1957, SCIENCE, V125, P122, DOI 10.1126/science.125.3238.122
   Giannakopoulos T., 2014, Introduction to Audio Analysis, P59, DOI DOI 10.1016/B978-0-08-099388-1.00004-2
   Gouyon F., 2000, P COST G 6 C DIG AUD, V5, P16
   Hasan M. R., 2004, 3 INT C EL COMP ENG, P565
   Henry M, 2012, SCIENCE, V336, P348, DOI 10.1126/science.1215039
   Hossan M. A., 2010, 2010 4 INT C SIGN PR, P1, DOI DOI 10.1109/ICSPCS.2010.5709752
   Howard D., 2013, P I ACOUSTICS, V35, P290
   Hung KLJ, 2018, P ROY SOC B-BIOL SCI, V285, DOI 10.1098/rspb.2017.2140
   Jafor Sadeek Quaderi S, 2022, ARXIV
   kaggle, BEEHIVE BUZZ ANOMALI
   Liu H, 1995, PROC INT C TOOLS ART, P388, DOI 10.1109/TAI.1995.479783
   Malhi A, 2004, IEEE T INSTRUM MEAS, V53, P1517, DOI 10.1109/TIM.2004.834070
   MICHELSEN A, 1986, BEHAV ECOL SOCIOBIOL, V18, P207, DOI 10.1007/BF00290824
   Muda L, 2010, Arxiv, DOI arXiv:1003.4083
   Nolasco I, 2021, Arxiv, DOI arXiv:1811.06016
   Ntalampiras S, 2012, J AUDIO ENG SOC, V60, P686
   Qandour A., 2014, Remote beehive monitoring using acoustic signals
   Rigatti Steven J, 2017, J Insur Med, V47, P31, DOI 10.17849/insm-47-01-31-39.1
   Robles -Guerrero A., 2017, Res. Comput. Sci., V142, P89, DOI DOI 10.13053/RCS-142-1-9
   Rustam F, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12061474
   Rustam F, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21111078
   Ruvinga S, 2021, INT CONF INTEL ENVIR, DOI 10.1109/IE51775.2021.9486575
   Schörkhuber C, 2013, J AUDIO ENG SOC, V61, P562
   Shafique R, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21186221
   Sharif MZ, 2020, SOCIOBIOLOGY, V67, P566, DOI 10.13102/sociobiology.v67i4.5860
   Sharif MZ, 2022, APPL ENTOMOL ZOOL, V57, P289, DOI 10.1007/s13355-021-00765-3
   Sperandei S, 2014, BIOCHEM MEDICA, V24, P12, DOI 10.11613/BM.2014.003
   Srinivasu PN, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.654
   Suthaharan S, 2016, INTEGR SER INFORM SY, V36, P207
   towardsdatascience, 2022, CHI SQUARE TEST FEAT
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Voudiotis G, 2022, SIGNALS-BASEL, V3, P506, DOI 10.3390/signals3030030
   Vulli A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082988
   Wun S, 2014, J AUDIO ENG SOC, V62, P575, DOI 10.17743/jaes.2014.0035
   Yang JC, 2019, DIGIT SIGNAL PROCESS, V89, P30, DOI 10.1016/j.dsp.2019.02.018
   Yigit H, 2013, 2013 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMPUTER AND COMPUTATION (ICECCO), P228, DOI 10.1109/ICECCO.2013.6718270
   Zgank A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010021
NR 57
TC 2
Z9 2
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 14
PY 2023
DI 10.1007/s11042-023-15192-5
EA AUG 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P2HF6
UT WOS:001048894900007
DA 2024-07-18
ER

PT J
AU Yücel, ME
   Ünsalan, C
AF Yucel, M. Erkin
   Unsalan, Cem
TI Planogram compliance control via object detection, sequence alignment,
   and focused iterative search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Object detection; Planogram compliance control; Sequence alignment;
   Focused search
AB Smart retail stores are becoming the fact of our lives. Several computer vision and sensor based systems are working together to achieve such a complex and automated operation. Besides, the retail sector already has several open and challenging problems which can be solved with the help of pattern recognition and computer vision methods. One important problem to be tackled is the planogram compliance control. In this study, we propose a novel method to solve it. The proposed method is based on object detection, planogram compliance control, and focused and iterative search steps. The object detection step is formed by local feature extraction and implicit shape model formation. The planogram compliance control step is formed by sequence alignment via the modified Needleman-Wunsch algorithm. The focused and iterative search step aims to improve the performance of the object detection and planogram compliance control steps. We tested all these steps on two different datasets. The results show that our proposed method achieves a 0.992 F1 score in object detection and a 0.935 F1 score in planogram compliance control. We further analyzed the strengths and weaknesses of the proposed method from different perspectives. We finally summarized possible extensions to our work.
C1 [Yucel, M. Erkin; Unsalan, Cem] Marmara Univ, Fac Engn, Dept Elect & Elect Engn, Istanbul, Turkiye.
C3 Marmara University
RP Ünsalan, C (corresponding author), Marmara Univ, Fac Engn, Dept Elect & Elect Engn, Istanbul, Turkiye.
EM mehmety@migros.com.tr; cem.unsalan@marmara.edu.tr
FU TUBITAK [5190042]
FX This work is supported by TUBITAK under project no 5190042. We certify
   that there is no actualor potential conflict of interest in relation to
   this article.
CR Aastrup J, 2010, INT REV RETAIL DISTR, V20, P147, DOI 10.1080/09593960903498284
   Alcantarilla PF, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.13
   Badger technologies, 2021, RET AUT
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Fellowai, 2021, AUTONOMOUS NAVIGATIO
   Franco A, 2017, EXPERT SYST APPL, V81, P163, DOI 10.1016/j.eswa.2017.02.050
   George M, 2014, LECT NOTES COMPUT SC, V8690, P440, DOI 10.1007/978-3-319-10605-2_29
   Goldman E, 2019, PROC CVPR IEEE, P5222, DOI 10.1109/CVPR.2019.00537
   Han J, 2012, MOR KAUF D, P1
   Leibe Bastian, 2004, WORKSH STAT LEARN CO
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Liu S, 2016, IEEE MULTIMEDIA, V23, P54, DOI 10.1109/MMUL.2016.19
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marder M, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2015.2394513
   NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4
   Planorama, 2019, IM REC RET EX MERCH
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Santra B, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108257
   Santra B, 2019, IMAGE VISION COMPUT, V86, P45, DOI 10.1016/j.imavis.2019.03.005
   Saqlain M, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/4916818
   Shelfie, 2022, US
   Ton Z, 2010, PROD OPER MANAG, V19, P546, DOI 10.1111/j.1937-5956.2010.01120.x
   Ye C, 2021, OBJECT DETECTION DEN, P1245
NR 23
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 11
PY 2023
DI 10.1007/s11042-023-16427-1
EA AUG 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O9TM0
UT WOS:001047169200003
DA 2024-07-18
ER

PT J
AU Shen, XH
   An, JB
   Teng, ZS
AF Shen, Xiaohu
   An, Jubai
   Teng, Zhisong
TI Key frame extraction method with global information balance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Key frame extraction; Yield to pedestrians; Object trajectory;
   Surveillance video; Global information
AB Key frame extraction can provide evidence for traffic violation detection, which is essential to support administrative punishment. However, the existing key frame extraction methods failed to model context information in complex semantic cases, such as failing to yield to pedestrian. To address this problem, we have proposed a key frame extraction model with global information balance (GIB), an intelligent vehicle violation screenshot method based on balancing the global information of video frames. The proposed GIB extracts three screenshots from the videos of vehicles failing to yield to pedestrians at crosswalks without signals. First, the proposed GIB defines the extraction of global information based on trajectories, comprising spatial structure and motion attributes as feature factors. Then, based on semantic correlation analysis for global information, relational entity filtering is implemented to avoid the interference of non-key entities and improve the effectiveness of the features. Finally, a search and pruning policy prioritizing mutual information is designed to maximize the global information entropy among preserved nodes to ensure the optimal prediction solution in case of a large global search solution space. The policy is implemented in the key frame prediction task in the Seq2Seq model based on the attention mechanism. The results of several experiments confirm the superior performance of the proposed method compared to conventional methods in terms of the evaluation of frame-time differential, perceptual hashing, and subjective scoring. For example, the perceptual hashing values of the proposed method were 10.5% and 6.7% greater than semantic correlation extraction and image similarity extraction, respectively, which are baseline methods based on local information.
C1 [Shen, Xiaohu] Jiangsu Police Inst, Dept Forens Sci & Technol, Nanjing 210031, Peoples R China.
   [Shen, Xiaohu; An, Jubai] Dalian Maritime Univ, Coll Informat Sci & Technol, Dalian 116026, Liaoning, Peoples R China.
   [Teng, Zhisong] Nanjing Publ Secur Sub Bur Jiangning, Nanjing 211100, Peoples R China.
C3 Jiangsu Police Institute; Dalian Maritime University
RP Shen, XH (corresponding author), Jiangsu Police Inst, Dept Forens Sci & Technol, Nanjing 210031, Peoples R China.; Shen, XH (corresponding author), Dalian Maritime Univ, Coll Informat Sci & Technol, Dalian 116026, Liaoning, Peoples R China.
EM shenxiaohu@jspi.cn
FU National Natural Science Foundation of China [61976032]; Applicable
   Innovation Project of the Ministry of Public Security of China
   [2020YYCXHNST046]
FX AcknowledgmentsThe authors greatly appreciate the reviewers' suggestions
   and the editor's encouragement. The work is partially supported by the
   National Natural Science Foundation of China (Grant Number: 61976032)
   and the Applicable Innovation Project of the Ministry of Public Security
   of China (Grant Number: 2020YYCXHNST046).
CR Ahmad F, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2019), P405, DOI [10.1109/siprocess.2019.8868839, 10.1109/SIPROCESS.2019.8868839]
   Chamasemani FF, 2015, PROCEEDINGS 5TH IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2015), P470, DOI 10.1109/ICCSCE.2015.7482231
   Chao GC, 2010, IEEE T CIRC SYST VID, V20, P1395, DOI 10.1109/TCSVT.2010.2087491
   Damnjanovic Uros, 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P63, DOI 10.1109/WIAMIS.2008.53
   Sang DV, 2019, SOICT 2019: PROCEEDINGS OF THE TENTH INTERNATIONAL SYMPOSIUM ON INFORMATION AND COMMUNICATION TECHNOLOGY, P280, DOI 10.1145/3368926.3369691
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Dow CR, 2020, SOFTWARE PRACT EXPER, V50, P630, DOI 10.1002/spe.2742
   Ge Rui, 2017, Control Theory & Applications, V34, P790, DOI 10.7641/CTA.2017.60607
   Ji J, 2019, INT J REMOTE SENS, V40, P3672, DOI 10.1080/01431161.2018.1552812
   Jiaqi Zhang, 2021, 2021 IEEE International Conference on Power, Intelligent Computing and Systems (ICPICS), P180, DOI 10.1109/ICPICS52425.2021.9524267
   Kajabad E. N., 2020, 2020 INT C ELECT COM, P1, DOI DOI 10.1109/ICECCE49384.2020.9179224
   Kar A, 2017, PROC CVPR IEEE, P5699, DOI 10.1109/CVPR.2017.604
   Lan Z., 2016, J CHONGQING JIAOTONG, V35, P129
   Laroca R., 2018, P INT JOINT C NEUR N, P1
   Lee S, 2020, IEEE T IMAGE PROCESS, V29, P2395, DOI 10.1109/TIP.2019.2948286
   Li YH, 2016, LECT NOTES COMPUT SC, V9911, P203, DOI 10.1007/978-3-319-46478-7_13
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   [刘云鹏 Liu Yunpeng], 2013, [中国图象图形学报, Journal of Image and Graphics], V18, P933
   Ma X, 2010, STUD COMPUT INTELL, V287, P53
   Mahmoud KM, 2013, LECT NOTES COMPUT SC, V8156, P733
   Ministry of Housing and Urban-Rural Development of the People's Republic of China, 2011, GB506882011 MIN HOUS
   Nallapati R., 2016, P 20 SIGNLL C COMP N, P280, DOI DOI 10.18653/V1/K16-1028
   Raikwar Suresh C., 2014, 2014 5th International Conference on Computer and Communication Technology (ICCCT), P297, DOI 10.1109/ICCCT.2014.7001508
   Shen XH, 2021, INT J INTELL SYST, V36, P5241, DOI 10.1002/int.22511
   Simonyan K, 2014, ADV NEUR IN, V27
   Song XH, 2016, NEUROCOMPUTING, V187, P66, DOI 10.1016/j.neucom.2015.07.131
   Tuan Linh Dang, 2020, ICIC Express Letters, V14, P961, DOI 10.24507/icicel.14.10.961
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wong A, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P95, DOI 10.1109/CRV.2018.00023
   Xia J., 2010, J SUZHOU U, V30, p1
   Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685
   Yan X, 2018, Arxiv, DOI [arXiv:1804.10021, DOI 10.48550/ARXIV.1804.10021]
   Yin YH, 2020, DIGIT SIGNAL PROCESS, V102, DOI 10.1016/j.dsp.2020.102756
   Yuan Luo, 2018, Pattern Recognition and Image Analysis, V28, P225, DOI 10.1134/S1054661818020190
   Zhang Y., 2021, Journal of Beijing Institute of Technology (Social Sciences Edition), V30, P311
   Zheng R, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0135694
   Zhong Ji, 2010, Proceedings of the 2010 2nd International Conference on Signal Processing Systems (ICSPS 2010), P250, DOI 10.1109/ICSPS.2010.5555504
   Zhong MJ., 2019, COMPUT TECHNOL DEV, V29, P164
   Zhong Q, 2020, IEEE ACCESS, V8, P174424, DOI 10.1109/ACCESS.2020.3025774
NR 39
TC 1
Z9 1
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 8
PY 2023
DI 10.1007/s11042-023-16386-7
EA AUG 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O6EV9
UT WOS:001044727600001
DA 2024-07-18
ER

PT J
AU Aziz, RM
   Hussain, A
   Sharma, P
AF Aziz, Rabia Musheer
   Hussain, Aftab
   Sharma, Prajwal
TI Cognizable crime rate prediction and analysis under Indian penal code
   using deep learning with novel optimization approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Particle swarm-cuckoo search (PS-CS); Convolutional neural network
   (CNN); Visual geometry group (VGG); Residual neural network (ResNet)
ID SYSTEM
AB The exacerbation of high crime rate has become a critical impediment to the country's economy, therefore necessitating the involvement of data analysts and scientists in extracting invaluable insights from crime data to proffer solutions towards crime prevention and regulation. To this end, this study presents a novel Particle Swarm-Cuckoo Search (PS-CS) optimization algorithm which leverages the potency of both particle swarm optimization and cuckoo search algorithms to enhance the optimization of network parameters and enable the training of deep neural networks for crime prediction. The proposed PS-CS model supersedes the traditional backpropagation algorithm which is fraught with limitations such as slow convergence and a proclivity for local optima. The implementation of the proposed model has the potential to be an efficacious tool for predicting crime rates in India, thus facilitating the efforts of law enforcement agencies in controlling and curbing criminal activities. We conducted a comprehensive and intricate evaluation of the efficacy of our proposed methodologies vis-a-vis the most pervasive and prevalent classification models currently in use. These models encompassed not only conventional machine learning techniques, such as Multiple Linear Regression, Support Vector Regression (SVR), Random Forest Regression, and Decision Trees, but also advanced and state-of-the-art deep learning models such as Residual Neural Network-152 (ResNet), Visual Geometry Group (VGG), and EfficienteNet-B7. Our findings evince that the suggested approach, PS-CS, in conjunction with CNN model, outperformed all other models, yielding an unparalleled accuracy score of 99.87%. By comparison, other models, including Multiple Linear Regression, SVR, Random Forest Regression, and Decision Trees, exhibited markedly inferior accuracy scores ranging from 80% to 95%. It is therefore evident that our proposed methodology, when integrated with a deep learning model, proves to be an exceedingly efficacious and robust solution for classification tasks.
C1 [Aziz, Rabia Musheer] VIT Bhopal Univ, Sch Adv Sci & languages, Sehore 466114, Madhya Pradesh, India.
   [Hussain, Aftab; Sharma, Prajwal] VIT Bhopal Univ, Sch Comp Sci & Engn, Sehore 466114, India.
C3 VIT Bhopal University; VIT Bhopal University
RP Aziz, RM (corresponding author), VIT Bhopal Univ, Sch Adv Sci & languages, Sehore 466114, Madhya Pradesh, India.
EM rabia.aziz2010@gmail.com
CR Ab Hamid TMT, 2021, ENSEMBLE BASED FILTE, V5
   Acion L, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0175383
   [Anonymous], 2018, 2 INT C TRENDS EL IN
   Awal MA, 2016, 2016 5TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS AND VISION (ICIEV), P333
   Aziz R., 2022, Karbala Int. J. Mod. Sci., V8, P139, DOI [10.33640/2405-609X.3229, DOI 10.33640/2405-609X.3229]
   Aziz Rabia Musheer, 2022, International Journal of Information Technology, P3321, DOI 10.1007/s41870-022-00864-6
   Aziz R.M., 2023, Computational and Analytic Methods in Biological Sciences, P23, DOI DOI 10.1201/9781003393238
   Aziz R, 2017, COMPUT BIOL CHEM, V71, P161, DOI 10.1016/j.compbiolchem.2017.10.009
   Aziz RM, 2023, CHEM BIODIVERS, V20, DOI 10.1002/cbdv.202201123
   Aziz RM, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13020697
   Aziz RM, 2023, MULTIMED TOOLS APPL, V82, P3677, DOI 10.1007/s11042-022-13437-3
   Aziz RM, 2022, J COMPUT BIOL, V29, P565, DOI 10.1089/cmb.2021.0410
   Aziz RM., 2022, ANN DATA SCI, V6, P1, DOI DOI 10.1007/S40745-022-00424-6
   Aziz RM, 2022, KARBALA INT J MOD SC, V8, P1, DOI [DOI 10.33640/2405-609X.3197, 10.33640/2405-609X.3197]
   Buonanno P, 2008, INT REV LAW ECON, V28, P89, DOI 10.1016/j.irle.2008.02.005
   Das P, 2019, ADV INTELL SYST, V711, P191, DOI 10.1007/978-981-10-8055-5_18
   Desai NP., 2022, Turk J Comput Math Educ, V13, P85
   Dutt A., 2018, PEOPLE INT J SOCIAL, V4, P212
   Gacharich N, 2021, THESIS FLORIDA ATLAN
   Gupta M, 2014, J ENTERP INF MANAG
   Gupta M, 2014, J ENTERP INF MANAG, V27, P512, DOI 10.1108/JEIM-10-2012-0073
   Hann C, 2009, THEOR CULT SOC, V26, P126, DOI 10.1177/0263276409348084
   Harb A, 2020, COMPUTAT GEOSCI, V24, P1979, DOI 10.1007/s10596-019-09887-8
   Hassan MM, 2018, FUTURE GENER COMP SY, V81, P307, DOI 10.1016/j.future.2017.11.029
   Hassan SU, 2021, INT J INFORM MANAGE, V56, DOI 10.1016/j.ijinfomgt.2019.102045
   Hatcher WG, 2018, IEEE ACCESS, V6, P24411, DOI 10.1109/ACCESS.2018.2830661
   Heeramun R, 2017, J AM ACAD CHILD PSY, V56, P491, DOI 10.1016/j.jaac.2017.03.011
   HOSSAIN S., 2020, INT C COMP SCI COMM, P277
   Jawad K, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13095322
   Jenga K, 2023, J AMBIENT INTELL HUM, V14, P2887
   Keyvanpour M, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2010.12.143
   Khiralla F. A. M., 2020, International Journal of Computer Science Network, V9, P252
   Kulsudjarit K, 2004, ANN NY ACAD SCI, V1025, P446, DOI 10.1196/annals.1316.055
   Kumar Avanish, 2021, International Conference on Deep Learning, Artificial Intelligence and Robotics ICDLAIR 2019. Proceedings. Lecture Notes in Networks and Systems (LNNS 175), P153, DOI 10.1007/978-3-030-67187-7_17
   Kumar J, 2023, INT J DYNAM CONTROL, V11, P482, DOI 10.1007/s40435-022-01024-1
   Kumar K, 2017, 2017 9 INT C ADV PAT, P1
   Kumar S, 2018, 2018 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT'18)
   Kumari Shreya, 2021, International Conference on Deep Learning, Artificial Intelligence and Robotics ICDLAIR 2019. Proceedings. Lecture Notes in Networks and Systems (LNNS 175), P339, DOI 10.1007/978-3-030-67187-7_35
   McDermott RC, 2015, PSYCHOL MEN MASCULIN, V16, P355, DOI 10.1037/a0039544
   Misra S, 2021, GLOBAL PERSPECTIVES, V171
   Mittal M, 2019, COMPUT ECON, V53, P1467, DOI 10.1007/s10614-018-9821-x
   Morewitz S, 2019, KIDNAPPING AND VIOLENCE: NEW RESEARCH AND CLINICAL PERSPECTIVES, P1, DOI 10.1007/978-1-4939-2117-1
   Rodrigues A, 2023, STOCH ENV RES RISK A, V37, P2815, DOI 10.1007/s00477-023-02420-5
   Safat W, 2021, IEEE ACCESS, V9, P70080, DOI 10.1109/ACCESS.2021.3078117
   Saravanan P., 2021, Advances in Smart Grid Technology. Select Proceedings of PECCON 2019. Lecture Notes in Electrical Engineering (LNEE 688), P435, DOI 10.1007/978-981-15-7241-8_31
   Tayal DK, 2015, AI SOC, V30, P117, DOI 10.1007/s00146-014-0539-6
   ToppiReddy Hitesh Kumar Reddy, 2018, Procedia Computer Science, V132, P696, DOI 10.1016/j.procs.2018.05.075
   van Dijk A, 2017, CRIMINAL LIABILITY S
   Venter G, 2003, AIAA J, V41, P1583, DOI 10.2514/2.2111
   Vijayvergia A, 2021, MULTIMED TOOLS APPL, V80, P28349, DOI 10.1007/s11042-021-10997-8
   Vijayvergia A, 2018, 2018 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT'18)
   Wang DS, 2018, SOFT COMPUT, V22, P387, DOI 10.1007/s00500-016-2474-6
   Wang SZ, 2022, IEEE T KNOWL DATA EN, V34, P3681, DOI 10.1109/TKDE.2020.3025580
   Wheeler AP, 2021, J QUANT CRIMINOL, V37, P445, DOI 10.1007/s10940-020-09457-7
   Yadav S, 2017, 2017 INTERNATIONAL CONFERENCE OF ELECTRONICS, COMMUNICATION AND AEROSPACE TECHNOLOGY (ICECA), VOL 1, P225, DOI 10.1109/ICECA.2017.8203676
   Yaqoob A, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11051081
NR 56
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 7
PY 2023
DI 10.1007/s11042-023-16371-0
EA AUG 2023
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O4RY6
UT WOS:001043714700005
DA 2024-07-18
ER

PT J
AU Elsedimy, EI
   AboHashish, SMM
   Algarni, F
AF Elsedimy, E. I.
   AboHashish, Sara M. M.
   Algarni, Fahad
TI New cardiovascular disease prediction approach using support vector
   machine and quantum-behaved particle swarm optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cardiovascular disease; Quantum-behaved particle swarm optimization
   (QPSO); Support vector machine (SVM); Cleveland heart disease dataset
ID FEATURE-SELECTION; LEARNING ALGORITHMS; PSO
AB Cardiovascular disease (CVD) is one of the leading causes of death worldwide. Early detection of CVD reduces the risk of a heart attack and increases the chance of recovery. The use of angiography to detect CVD is expensive and has negative side effects. In addition, existing CVD diagnostic methods usually achieve low detection rates and reach the best decision after many iterations with low convergence speeds. Therefore, a novel heart disease detection model based on the quantum-behaved particle swarm optimization (QPSO) algorithm and support vector machine (SVM) classification model, namely, QPSO-SVM, was proposed to analyze and predict heart disease risk. First, the data preprocessing was performed by transforming nominal data into numerical data and applying effective scaling techniques. Next, the SVM fitness equation is expressed as an optimization problem and solved using the QPSO to determine the optimal features. Finally, a self-adaptive threshold method for tuning the QPSO-SVM parameters is proposed, which permits it to drop into local minima, and balances between exploration and exploitation in the solution search space. The proposed model is applied to the Cleveland heart disease dataset and compared with state-of-the-art models. The experimental results show that the proposed QPSO-SVM model achieved the best heart-disease-prediction accuracies of 96.31% on the Cleveland heart data set. Furthermore, QPSO-SVM outperforms other state-of-the-art prediction models considered in this research in terms of sensitivity (96.13%), specificity (93.56%), precision (94.23%), and F1 score (0.95%).
C1 [Elsedimy, E. I.; AboHashish, Sara M. M.] Port Said Univ, Fac Management Technol & Informat Syst, Dept Syst & Informat Technol, Port Said 42526, Egypt.
   [Algarni, Fahad] Univ Bisha, Fac Comp & Informat Technol, Bisha 61922, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Port Said University; University of Bisha
RP Elsedimy, EI (corresponding author), Port Said Univ, Fac Management Technol & Informat Syst, Dept Syst & Informat Technol, Port Said 42526, Egypt.
EM elsodamey_sayed@himc.psu.edu.eg; sara_mohamed@himc.psu.edu.eg;
   fahad.a.algarni@gmail.com
RI elsedimy, elsayed/AHE-2874-2022
OI elsedimy, elsayed/0000-0003-0781-2231; abohashish,
   sara/0000-0002-9426-7093
FU Science, Technology amp; Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & amp;
   Innovation Funding Authority (STDF) in cooperation with The Egyptian
   Knowledge Bank (EKB). Open access funding provided by The Science,
   Technology & amp; Innovation Funding Authority (STDF) in cooperation
   with The Egyptian Knowledge Bank (EKB)
CR Ahmed H, 2020, FUTURE GENER COMP SY, V111, P714, DOI 10.1016/j.future.2019.09.056
   Akella A, 2021, FUTUR SCI OA, V7, DOI 10.2144/fsoa-2020-0206
   Al-Tashi Q, 2019, ADV INTELL SYST, V843, P257, DOI 10.1007/978-3-319-99007-1_25
   Aljarah I, 2018, COGN COMPUT, V10, P478, DOI 10.1007/s12559-017-9542-9
   [Anonymous], 2014, 2014 International Conference on Electronics and Communication Systems (ICECS), DOI DOI 10.1109/ECS.2014.6892729
   Babaoglu I, 2010, EXPERT SYST APPL, V37, P2182, DOI 10.1016/j.eswa.2009.07.055
   Bashir ZA, 2009, IEEE T POWER SYST, V24, P20, DOI 10.1109/TPWRS.2008.2008606
   Benjamin, 2018, CIRCULATION, V137, pE493, DOI 10.1161/CIR.0000000000000573
   Chicco D, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-1023-5
   Dogan N, 2013, INFORM TECHNOL MANAG, V14, P105, DOI 10.1007/s10799-012-0135-8
   Dua M, 2019, SOFT COMPUT, V23, P11801, DOI 10.1007/s00500-018-03731-4
   Dwivedi AK, 2018, NEURAL COMPUT APPL, V29, P685, DOI 10.1007/s00521-016-2604-1
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Ghosh P, 2021, IEEE ACCESS, V9, P19304, DOI 10.1109/ACCESS.2021.3053759
   Gokulnath CB, 2019, CLUSTER COMPUT, V22, P14777, DOI 10.1007/s10586-018-2416-4
   Gupta R, 2020, INFORM SCIENCES, V530, P201, DOI 10.1016/j.ins.2020.01.031
   Joloudari JH, 2022, FRONT CARDIOVASC MED, V8, DOI 10.3389/fcvm.2021.760178
   Kishor Amit, 2021, Proceedings of Second International Conference on Computing, Communications, and Cyber-Security. IC4S 2020. Lecture Notes in Networks and Systems (LNNS 203), P691, DOI 10.1007/978-981-16-0733-2_49
   Kishor A, 2022, WIRELESS PERS COMMUN, V127, P1615, DOI 10.1007/s11277-021-08708-5
   Latha C. Beulah Christalin, 2019, Informatics in Medicine Unlocked, V16, DOI 10.1016/j.imu.2019.100203
   Lin SW, 2008, EXPERT SYST APPL, V35, P1817, DOI 10.1016/j.eswa.2007.08.088
   Liu X, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/8272091
   Liu Xiaoyong, 2014, ScientificWorldJournal, V2014, P548483, DOI 10.1155/2014/548483
   Lo CS, 2012, COMPUT MATH APPL, V64, P1153, DOI 10.1016/j.camwa.2012.03.033
   Nandy S, 2023, NEURAL COMPUT APPL, V35, P14723, DOI 10.1007/s00521-021-06124-1
   Obasi T, 2019, IEEE INT CONF BIG DA, P2393, DOI 10.1109/BigData47090.2019.9005488
   Perumal R., 2020, INT J ADV SCI TECHNO, V29, P4225
   Priya RL, 2021, HEALTH TECHNOL-GER, V11, P63, DOI 10.1007/s12553-020-00508-4
   Rajkumar A, 2018, INT J APPL ENG RES, V13, P1716
   Reddy KVV, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11188352
   Shanmuganathan V, 2020, NEURAL COMPUT APPL, V32, P16723, DOI 10.1007/s00521-020-05349-w
   Subramaniam O, 2019, INT J RECENT TECHNOL, VEng7, P2277
   Sun J, 2012, EVOL COMPUT, V20, P349, DOI 10.1162/EVCO_a_00049
   Swathy M, 2022, ICT EXPRESS, V8, P109, DOI 10.1016/j.icte.2021.08.021
   García-Ordás MT, 2023, MULTIMED TOOLS APPL, V82, P31759, DOI 10.1007/s11042-023-14817-z
   Tharwat A, 2019, J CLASSIF, V36, P576, DOI 10.1007/s00357-018-9299-1
   Tharwat A, 2018, APPL INTELL, V48, P670, DOI 10.1007/s10489-017-0994-0
   Ul Haq A, 2018, MOB INF SYST, V2018, DOI 10.1155/2018/3860146
   Vapnik V., 1995, NATURE STAT LEARNING
   Vieira SM, 2013, APPL SOFT COMPUT, V13, P3494, DOI 10.1016/j.asoc.2013.03.021
   Wang GG, 2013, J APPL MATH, DOI 10.1155/2013/696491
   Wang J, 2023, ARTIF INTELL REV, V56, P203, DOI 10.1007/s10462-022-10170-z
   Wei-jia L., 2016, J INTELL SYST, V26, P573
   Who.int [homepage on the internet], WHO CARDIOVASCULAR D
   Yin S, 2014, NEUROCOMPUTING, V145, P263, DOI 10.1016/j.neucom.2014.05.035
   Yoo H, 2021, MULTIMED TOOLS APPL, V80, P34713, DOI 10.1007/s11042-020-09052-9
   Yousef R, 2022, MULTIMEDIA SYST, V28, P881, DOI 10.1007/s00530-021-00884-5
   Yuvali M, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10030311
NR 48
TC 5
Z9 5
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 5
PY 2023
DI 10.1007/s11042-023-16194-z
EA AUG 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O4EJ2
UT WOS:001043360000005
OA hybrid
DA 2024-07-18
ER

PT J
AU Srivastava, V
   Singh, SS
AF Srivastava, Vishal
   Singh, Shashank Sheshar
TI A meta-heuristics based framework of cluster label optimization in MR
   images using stable random walk
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Evolutionary computations; BAT optimization; MRI; Clustering
ID AUTOMATED SEGMENTATION; SWARM INTELLIGENCE; ALGORITHM; ENTROPY
AB Cluster labeling is a problem of finding optimal clusters by maximizing the similarity within clusters. Generally, classical optimization methods are used for clustering, which depends upon initial estimates. Meta-heuristic optimization techniques came into existence to avoid this shortcoming as they are not problem-specific and do not dependent on the initial estimates. Optimal threshold selection is a widely known problem for image clustering that optimizes the entropy of image clusters. But for region-wise clustering, the sheer amount of literature is available that uses evolutionary techniques. Sub-optimal cluster selection and slow convergence are the problems that arise in meta-heuristics approaches. In this paper, we optimize the region-wise cluster labels for an efficient objective function. In particular, we consider the cluster label optimization problems in tumour-based magnetic resonance (MR) images. In order to solve the problem, a meta-heuristic approaches is used. The stable random walk is incorporated with the BAT algorithm to avoid the potential endangerment of local minima trapping. Further, the objective improvement is carried out by hybridizing the intra-cluster and inter-cluster-based objectives. To assess the efficiency of the proposed approach, we evaluated the proposed method against the recently proposed techniques. The evolutionary technique is well performed in various aspects of cluster label evaluation and paves new ideas for future research lines.
C1 [Srivastava, Vishal] Bennett Univ, Sch Comp Sci Engn & Technol, Greater Noida, India.
   [Singh, Shashank Sheshar] Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, India.
C3 Thapar Institute of Engineering & Technology
RP Srivastava, V (corresponding author), Bennett Univ, Sch Comp Sci Engn & Technol, Greater Noida, India.
EM vishalismdhanbad@gmail.com
OI srivastava, vishal/0000-0002-2064-5805
CR Ahmad A, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114149
   Alam S, 2015, SWARM EVOL COMPUT, V25, P36, DOI 10.1016/j.swevo.2015.10.003
   Alguliyev RM, 2020, EXPERT SYST APPL, V150, DOI 10.1016/j.eswa.2020.113294
   Ali S, 2021, MED IMAGE ANAL, V70, DOI 10.1016/j.media.2021.102002
   Anter AM, 2019, INFORM SCIENCES, V503, P670, DOI 10.1016/j.ins.2019.07.026
   Askari S, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113856
   Boudjemaa R, 2020, INT J BIO-INSPIR COM, V15, P100, DOI 10.1504/IJBIC.2020.106441
   Calinski T., 1974, Communications in Statistics-Simulation and Computation, V3, P1, DOI [10.1080/03610927408827101, DOI 10.1080/03610927408827101]
   CHAMBERS JM, 1976, J AM STAT ASSOC, V71, P340, DOI 10.2307/2285309
   Chauhan S, 2023, SOFT COMPUT, V27, P9565, DOI 10.1007/s00500-023-08090-3
   Chauhan S, 2023, ENG APPL ARTIF INTEL, V119, DOI 10.1016/j.engappai.2022.105803
   Chen J, 2018, SWARM EVOL COMPUT, V38, P287, DOI 10.1016/j.swevo.2017.09.002
   Chen X, 2020, KNOWL-BASED SYST, V188, DOI 10.1016/j.knosys.2019.105002
   Dadjoo M, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114224
   Das A, 2017, SWARM EVOL COMPUT, V35, P26, DOI 10.1016/j.swevo.2017.02.004
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   de Amorim RC, 2021, EXPERT SYST APPL, V177, DOI 10.1016/j.eswa.2021.114971
   de Gusmao RP, 2019, EXPERT SYST APPL, V123, P34, DOI 10.1016/j.eswa.2018.12.053
   Deng JZ, 2019, KNOWL-BASED SYST, V175, P96, DOI 10.1016/j.knosys.2019.03.009
   Dhal KG, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2021.106814
   Dou Q, 2017, MED IMAGE ANAL, V41, P40, DOI 10.1016/j.media.2017.05.001
   Ertenlice O, 2018, SWARM EVOL COMPUT, V39, P36, DOI 10.1016/j.swevo.2018.01.009
   Fang H, 2018, SWARM EVOL COMPUT, V42, P99, DOI 10.1016/j.swevo.2018.02.014
   Ferrante E, 2017, MED IMAGE ANAL, V39, P101, DOI 10.1016/j.media.2017.04.010
   Fornarelli G, 2013, SWARM EVOL COMPUT, V11, P31, DOI 10.1016/j.swevo.2013.02.002
   Ghanem WAHM, 2019, NEURAL COMPUT APPL, V31, P617, DOI 10.1007/s00521-017-3021-9
   Han YF, 2007, NEUROCOMPUTING, V70, P665, DOI 10.1016/j.neucom.2006.10.022
   Horng MH, 2010, EXPERT SYST APPL, V37, P4580, DOI 10.1016/j.eswa.2009.12.050
   Huang XH, 2014, KNOWL-BASED SYST, V70, P293, DOI 10.1016/j.knosys.2014.07.009
   Jiang YZ, 2017, APPL SOFT COMPUT, V52, P1181, DOI 10.1016/j.asoc.2016.09.008
   Juang LH, 2010, MEASUREMENT, V43, P941, DOI 10.1016/j.measurement.2010.03.013
   Karimzadeh S, 2019, EXPERT SYST APPL, V126, P265, DOI 10.1016/j.eswa.2019.02.022
   Khan I, 2021, EXPERT SYST APPL, V172, DOI 10.1016/j.eswa.2021.114622
   KRZANOWSKI WJ, 1988, BIOMETRICS, V44, P23, DOI 10.2307/2531893
   Kuwil FH, 2020, EXPERT SYST APPL, V156, DOI 10.1016/j.eswa.2020.113435
   Lavanya PG, 2021, EXPERT SYST APPL, V173, DOI 10.1016/j.eswa.2021.114658
   Li DY, 2021, SWARM EVOL COMPUT, V60, DOI 10.1016/j.swevo.2020.100789
   Li W, 2021, NEUROCOMPUTING, V458, P514, DOI 10.1016/j.neucom.2019.12.141
   Lu SY, 2021, NEURAL COMPUT APPL, V33, P10799, DOI 10.1007/s00521-020-05082-4
   Mahmood F, 2018, MED IMAGE ANAL, V48, P230, DOI 10.1016/j.media.2018.06.005
   Mookiah MRK, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101905
   Nock R, 2005, PATTERN RECOGN, V38, P835, DOI 10.1016/j.patcog.2004.11.009
   Öztürk S, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106799
   Perez-Cham OE, 2021, SWARM EVOL COMPUT, V61, DOI 10.1016/j.swevo.2020.100817
   Rajasekhar A, 2017, SWARM EVOL COMPUT, V32, P25, DOI 10.1016/j.swevo.2016.06.001
   Roshanzamir M, 2019, SWARM EVOL COMPUT, V51, DOI 10.1016/j.swevo.2019.100581
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Salavati C, 2019, SWARM EVOL COMPUT, V51, DOI 10.1016/j.swevo.2019.100614
   Sharma KK, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106567
   Sharma KK, 2019, EXPERT SYST APPL, V137, P100, DOI 10.1016/j.eswa.2019.06.050
   Singh P, 2021, SWARM EVOL COMPUT, V63, DOI 10.1016/j.swevo.2021.100863
   Srivastava V, 2023, NEUROCOMPUTING, V541, DOI 10.1016/j.neucom.2023.126286
   Srivastava V, 2023, BIOMED SIGNAL PROCES, V82, DOI 10.1016/j.bspc.2022.104513
   Srivastava V, 2022, SOFT COMPUT, V26, P6201, DOI 10.1007/s00500-022-07138-0
   Srivastava V, 2022, NEURAL PROCESS LETT, V54, P1753, DOI 10.1007/s11063-021-10704-6
   Srivastava V, 2021, NEURAL PROCESS LETT, V53, P607, DOI 10.1007/s11063-020-10415-4
   Srivastava V, 2020, MULTIMED TOOLS APPL, V79, P5897, DOI 10.1007/s11042-019-08477-1
   Stolte S, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101742
   Sundgaard JV, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102034
   Tabakhi S, 2015, PATTERN RECOGN, V48, P2798, DOI 10.1016/j.patcog.2015.03.020
   Tao Q, 2020, NEUROCOMPUTING, V393, P234, DOI 10.1016/j.neucom.2018.12.093
   Teraiya J, 2022, EVOL INTELL, V15, P1935, DOI 10.1007/s12065-021-00599-6
   Thakkar A, 2020, SWARM EVOL COMPUT, V53, DOI 10.1016/j.swevo.2019.100631
   Tharwat A, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114430
   Tsai C, 1995, PATTERN RECOGN, V28, P1825, DOI 10.1016/0031-3203(95)00047-X
   Wang PC, 2020, NEUROCOMPUTING, V407, P313, DOI 10.1016/j.neucom.2019.06.112
   Wang R, 2020, KNOWL-BASED SYST, V201, DOI 10.1016/j.knosys.2020.106047
   Wang X, 2021, NEUROCOMPUTING, V437, P131, DOI 10.1016/j.neucom.2021.01.056
   Wang XK, 2021, NEUROCOMPUTING, V425, P23, DOI 10.1016/j.neucom.2020.10.105
   Wang Y, 2020, SWARM EVOL COMPUT, V55, DOI 10.1016/j.swevo.2020.100675
   Wu B, 2020, INFORM SCIENCES, V533, P72, DOI 10.1016/j.ins.2020.05.033
   Wu GH, 2020, SWARM EVOL COMPUT, V55, DOI 10.1016/j.swevo.2020.100690
   Xing ZW, 2021, NEUROCOMPUTING, V440, P297, DOI 10.1016/j.neucom.2021.01.064
   Yin SB, 2014, PATTERN RECOGN, V47, P2894, DOI 10.1016/j.patcog.2014.03.009
   Zadegan SMR, 2013, KNOWL-BASED SYST, V39, P133, DOI 10.1016/j.knosys.2012.10.012
   Zamiri M, 2021, EXPERT SYST APPL, V173, DOI 10.1016/j.eswa.2021.114657
   Zhao D, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114122
NR 77
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21397
EP 21434
DI 10.1007/s11042-023-16392-9
EA AUG 2023
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001042601200005
DA 2024-07-18
ER

PT J
AU Unar, S
   Su, YN
   Zhao, X
   Liu, PB
   Wang, YF
   Fu, XP
AF Unar, Salahuddin
   Su, Yining
   Zhao, Xiu
   Liu, Pengbo
   Wang, Yafei
   Fu, Xianping
TI Towards applying image retrieval approach for finding semantic locations
   in autonomous vehicles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Autonomous vehicle; Advanced driver assistance system;
   Semantic locations
ID DRIVER BEHAVIOR; FUSION; FEATURES; SYSTEM
AB The current world today is indisputably digital and its advanced digital technologies have grown more rapidly than ever since. The recent scientific and engineering progress in autonomous vehicles (AVs) and advanced driver assistance systems (ADAS) make us believe that autonomous vehicles will be fully functional without human intervention in the near future. The current ADAS methods are best at realizing different modes of AV, however, it still lacks behind to handle uncertain situations such as deciding the specific location to stop. To overcome this, we propose a novel image retrieval approach for finding the semantic locations by using vigorous features and color information. Firstly, the proposed method offers different image categories and the driver selects a query image of the semantic location. Secondly, the method extracts its salient features and color information using the proposed technique. Thirdly, the method computes the similarity between the query image and the dataset images. Finally, if the threshold similarity is found, the method asks the driver for appropriate actions (e.g. slow down or stop). The experimental results on three benchmark datasets show the efficiency and accuracy of the proposed method for finding the semantic locations in autonomous vehicles.
C1 [Unar, Salahuddin; Su, Yining; Zhao, Xiu; Liu, Pengbo; Wang, Yafei; Fu, Xianping] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
C3 Dalian Maritime University
RP Unar, S; Fu, XP (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
EM imulticoder@gmail.com; fxp@dlmu.edu.cn
RI Unar, Salahuddin/K-3480-2019
OI Unar, Salahuddin/0000-0003-1174-8236
FU National Natural Science Foundation of China [62176037]; Research
   Project of China Disabled Persons' Federation on Assistive Technology
   [2021CDPFAT-09]; Liaoning Revitalization Talents Program Grant
   [XLYC1908007]; Dalian Science and Technology Innovation Fund
   [2019J11CY001, 2021JJ12GX028]
FX & nbsp;This research was funded by the National Natural Science
   Foundation of China Grant 62176037, by the Research Project of China
   Disabled Persons' Federation on Assistive Technology Grant
   2021CDPFAT-09, by the Liaoning Revitalization Talents Program Grant
   XLYC1908007, by the Dalian Science and Technology Innovation Fund Grant
   2019J11CY001, and Grant 2021JJ12GX028.
CR Arefnezhad S, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2020.113778
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bingyi Cao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P726, DOI 10.1007/978-3-030-58565-5_43
   Chen BH, 2022, MULTIMED TOOLS APPL, V81, P30785, DOI 10.1007/s11042-022-12706-5
   Chen KJ, 2021, IEEE T INTELL TRANSP, V22, P2751, DOI 10.1109/TITS.2020.2974495
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Dorigo M, 2006, IEEE COMPUT INTELL M, V1, P28, DOI 10.1109/MCI.2006.329691
   Gao J, 2023, MULTIMED TOOLS APPL, P1, DOI [10.1007/S11042-023-14499-7/TABLES/9, DOI 10.1007/S11042-023-14499-7/TABLES/9]
   Gao Y, 2018, IEEE T INTELL TRANSP, V19, P320, DOI 10.1109/TITS.2017.2750087
   Ghahremani M, 2021, MULTIMED TOOLS APPL, V80, P28245, DOI 10.1007/s11042-021-10895-z
   Gordo A, 2016, LECT NOTES COMPUTER
   Hechri A, 2020, IET IMAGE PROCESS, V14, P939, DOI 10.1049/iet-ipr.2019.0634
   Hsu CC, 2023, MULTIMED TOOLS APPL, V82, P10763, DOI 10.1007/s11042-022-13742-x
   Ibrahimi S, 2022, IEEE WINT CONF APPL, P468, DOI 10.1109/WACV51458.2022.00054
   Jiang F, 2016, NEUROCOMPUTING, V175, P146, DOI 10.1016/j.neucom.2015.10.044
   Jiang GQ, 2022, IEEE T CIRC SYST VID, V32, P5307, DOI 10.1109/TCSVT.2022.3143848
   Kukkala VK, 2018, IEEE CONSUM ELECTR M, V7, P18, DOI 10.1109/MCE.2018.2828440
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li GF, 2021, KNOWL-BASED SYST, V213, DOI 10.1016/j.knosys.2020.106617
   Liu PZ, 2017, INFORM SCIENCES, V390, P95, DOI 10.1016/j.ins.2017.01.025
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ng Tony, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P253, DOI 10.1007/978-3-030-58595-2_16
   Olaverri-Monreal C, 2019, FUTURE GENER COMP SY, V95, P880, DOI 10.1016/j.future.2018.01.050
   Ouyang J., 2021, Advances in Neural Information Processing Systems, V34, P3135
   Peng T, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112953
   Pérez-Gil O, 2022, MULTIMED TOOLS APPL, V81, P3553, DOI 10.1007/s11042-021-11437-3
   Perumal PS, 2022, EXPERT SYST APPL, V199, DOI 10.1016/j.eswa.2022.117178
   Qian WB, 2022, INFORM SCIENCES, V582, P38, DOI 10.1016/j.ins.2021.08.076
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Radenovic F, 2018, PROC CVPR IEEE, P5706, DOI 10.1109/CVPR.2018.00598
   Rahman MJ, 2020, IET INTELL TRANSP SY, V14, P2083, DOI 10.1049/iet-its.2020.0087
   Revaud J, 2019, IEEE I CONF COMP VIS, P5106, DOI 10.1109/ICCV.2019.00521
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sahoo GK, 2023, MULTIMED TOOLS APPL, V82, P11697, DOI 10.1007/s11042-022-13450-6
   Sarwar A, 2019, J INF SCI, V45, P117, DOI 10.1177/0165551518782825
   Sun QY, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115781
   Sun W, 2021, MULTIMED TOOLS APPL, V80, P30803, DOI 10.1007/s11042-020-09171-3
   Syu JL, 2017, MULTIMED TOOLS APPL, V76, P18387, DOI 10.1007/s11042-016-4123-6
   Teichmann M, 2019, PROC CVPR IEEE, P5104, DOI 10.1109/CVPR.2019.00525
   Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453
   Unar S, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23094537
   Unar S, 2019, KNOWL-BASED SYST, V179, P8, DOI 10.1016/j.knosys.2019.05.001
   Unar S, 2019, IET IMAGE PROCESS, V13, P1191, DOI 10.1049/iet-ipr.2019.0098
   Unar S, 2019, IET IMAGE PROCESS, V13, P515, DOI 10.1049/iet-ipr.2018.5277
   Unar S, 2018, INFORM FUSION, V44, P176, DOI 10.1016/j.inffus.2018.03.006
   Walia E, 2014, J VIS COMMUN IMAGE R, V25, P1335, DOI 10.1016/j.jvcir.2014.05.005
   Wang HB, 2023, IEEE T MULTIMEDIA, V25, P6629, DOI 10.1109/TMM.2022.3212270
   Wang HB, 2020, IEEE T VEH TECHNOL, V69, P10484, DOI 10.1109/TVT.2020.3009162
   Wang WC, 2022, MULTIMED TOOLS APPL, V81, P39873, DOI 10.1007/s11042-022-12300-9
   Xiao L, 2022, MULTIMED TOOLS APPL, V81, P3165, DOI 10.1007/s11042-020-09066-3
   Xiao WC, 2022, FUTURE GENER COMP SY, V132, P152, DOI 10.1016/j.future.2022.02.007
   Yuan YJ, 2020, MULTIMED TOOLS APPL, V79, P16573, DOI 10.1007/s11042-019-7729-7
   Zamir AR, 2014, IEEE T PATTERN ANAL, V36, P1546, DOI 10.1109/TPAMI.2014.2299799
   Zhang JD, 2021, MULTIMED TOOLS APPL, V80, P18181, DOI 10.1007/s11042-020-10370-1
NR 55
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20537
EP 20558
DI 10.1007/s11042-023-16387-6
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001041470300001
DA 2024-07-18
ER

PT J
AU Jerrish, DJ
   Nankar, O
   Gite, S
   Patil, S
   Kotecha, K
   Selvachandran, G
   Abraham, A
AF Jerrish, Daryl Jacob
   Nankar, Om
   Gite, Shilpa
   Patil, Shruti
   Kotecha, Ketan
   Selvachandran, Ganeshsree
   Abraham, Ajith
TI Deep learning approaches for lyme disease detection: leveraging
   progressive resizing and self-supervised learning models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lyme disease; Self-supervised learning; Contrast learning; Progressive
   resizing; Convolutional neural networks; Momentum contrast for
   unsupervised visual representation learning
ID ERYTHEMA MIGRANS; SKIN-LESIONS
AB Lyme disease diagnosis poses a significant challenge, with blood tests exhibiting an alarming inaccuracy rate of nearly 60% in detecting early-stage infections. As a result, there is an urgent need for improved diagnostic methods that can offer more accurate detection outcomes. To address this pressing issue, our study focuses on harnessing the potential of deep learning approaches, specifically by employing model pipelining through progressive resizing and multiple self-supervised learning models. In this paper, we present a comprehensive exploration of self-supervised learning models, including SimCLR, SwAV, MoCo, and BYOL, tailored to the context of Lyme disease detection using medical imaging. The effectiveness and performance of these models are evaluated using standard metrics such as F1 score, precision, recall, and accuracy. Furthermore, we emphasize the significance of progressive resizing and its implications when dealing with convolutional neural networks (CNNs) for medical image analysis. By leveraging deep learning approaches, progressive resizing, and self-supervised learning models, the challenges associated with Lyme disease detection are effectively addressed in this study. The application of our novel methodology and the execution of a comprehensive evaluation framework contribute invaluable insights, fostering the development of more efficient and accurate diagnostic methods for Lyme disease. It is firmly believed that our research will serve as a catalyst, inspiring interdisciplinary collaborations that accelerate progress at the convergence of medicine, computing, and technology, ultimately benefiting public health.
C1 [Jerrish, Daryl Jacob; Nankar, Om; Gite, Shilpa; Patil, Shruti; Kotecha, Ketan] Deemed Univ, Symbiosis Ctr Appl Artificial Intelligence, Symbiosis Int, Pune 412115, Maharashtra, India.
   [Jerrish, Daryl Jacob; Nankar, Om; Gite, Shilpa; Patil, Shruti] Symbiosis Int Univ, Symbiosis Inst Technol, Artificial Intelligence & Machine Learning Dept, Pune 412115, Maharashtra, India.
   [Selvachandran, Ganeshsree] UCSI Univ, Inst Actuarial Sci & Data Analyt, Jalan Menara Gading, Kuala Lumpur 56000, Malaysia.
   [Selvachandran, Ganeshsree] Symbiosis Inst Technol Symbiosis Int Univ, Pune 412115, India.
   [Abraham, Ajith] FLAME Univ, Fac Comp & Data Sci, Gat 1270, Pune 412115, Maharashtra, India.
C3 Symbiosis International University; Symbiosis International University;
   Symbiosis Institute of Technology (SIT); UCSI University
RP Gite, S (corresponding author), Deemed Univ, Symbiosis Ctr Appl Artificial Intelligence, Symbiosis Int, Pune 412115, Maharashtra, India.; Gite, S (corresponding author), Symbiosis Int Univ, Symbiosis Inst Technol, Artificial Intelligence & Machine Learning Dept, Pune 412115, Maharashtra, India.; Selvachandran, G (corresponding author), UCSI Univ, Inst Actuarial Sci & Data Analyt, Jalan Menara Gading, Kuala Lumpur 56000, Malaysia.; Selvachandran, G (corresponding author), Symbiosis Inst Technol Symbiosis Int Univ, Pune 412115, India.
EM daryl.j.jerrish@gmail.com; om.nankar.btech2019@sitpune.edu.in;
   shilpa.gite@sitpune.edu.in; shruti.patil@sitpune.edu.in;
   director@sitpune.edu.in; Ganeshsree@ucsiuniversity.edu.my;
   ajith.abraham@flame.edu.in
RI Kotecha, Ketan/U-3927-2017; Selvachandran, Ganeshsree/P-3000-2017;
   Abraham, Ajith/A-1416-2008
OI Selvachandran, Ganeshsree/0000-0001-7161-2109; Abraham,
   Ajith/0000-0002-0169-6738
CR Alam MN, 2016, IEEE ENG MED BIO, P1365, DOI 10.1109/EMBC.2016.7590961
   [Anonymous], LYM DIS RASH DAT
   Awad M, 2015, Efficient learning machines: theories, concepts, and applications for engineers and system designers, DOI DOI 10.1007/978-1-4302-5990-9
   Azizi S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3458, DOI 10.1109/ICCV48922.2021.00346
   Bhatt AR, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.348
   Burlina PM, 2020, COMPUT BIOL MED, V125, DOI 10.1016/j.compbiomed.2020.103977
   Burlina PM, 2019, COMPUT BIOL MED, V105, P151, DOI 10.1016/j.compbiomed.2018.12.007
   Caron M., 2020, Advances in neural information processing systems, V33, P9912
   Caron M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9630, DOI 10.1109/ICCV48922.2021.00951
   Chaves L, 2023, LECT NOTES COMPUTER, V13804, DOI [10.1007/978-3-031-25069-9_11, DOI 10.1007/978-3-031-25069-9_11]
   Chen T, 2020, PR MACH LEARN RES, V119
   Chung M, 2021, ARTIF INTELL MED, V113, DOI 10.1016/j.artmed.2021.102023
   Cuk E, 2014, STROJ VESTN-J MECH E, V60, P115, DOI 10.5545/sv-jme.2013.1046
   Dang YJ, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-2004-9
   Dosovitskiy A, 2016, IEEE T PATTERN ANAL, V38, P1734, DOI 10.1109/TPAMI.2015.2496141
   Grill Jean-Bastien, 2020, ADV NEURAL INFORM PR
   Hamad MA, 2018, P 2018 INT C INN INT, P1, DOI DOI 10.1109/INTLEC.2018.8612316
   Harangi B, 2018, J BIOMED INFORM, V86, P25, DOI 10.1016/j.jbi.2018.08.006
   Horn EJ, 2020, J CLIN MICROBIOL, V58, DOI 10.1128/JCM.00032-20
   Hossain SI, 2022, COMPUT METH PROG BIO, V215, DOI 10.1016/j.cmpb.2022.106624
   Immagulate I., 2015, INT J MED IMAGING, V3, P34, DOI [10.11648/j.ijmi.20150302.15, DOI 10.11648/J.IJMI.20150302.15]
   Jang SI, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49095-z
   Kwasigroch A, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9111930
   Kwon JH., 2019, MED PHYS, V46, P3111
   Li X., 2020, MED PHYS, V47, P2127
   Liu TY, 2022, ARTIF INTELL MED, V125, DOI 10.1016/j.artmed.2021.102235
   Livieris IE, 2021, EVOL SYST-GER, V12, P155, DOI 10.1007/s12530-019-09324-2
   Manjusha KK., 2014, INT J ADV RES COMPUT, V4, P864
   Masood A, 2015, I IEEE EMBS C NEUR E, P1012, DOI 10.1109/NER.2015.7146798
   Mehdy MM, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/2610628
   Oren O, 2020, LANCET DIGIT HEALTH, V2, pE486, DOI 10.1016/S2589-7500(20)30160-6
   Priya HAG, 2018, 2018 INTERNATIONAL CONFERENCE ON CONTROL, POWER, COMMUNICATION AND COMPUTING TECHNOLOGIES (ICCPCCT), P553, DOI 10.1109/ICCPCCT.2018.8574277
   Rathod Jainesh, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1048, DOI 10.1109/ICECA.2018.8474593
   ROY K, 2019, 2019 INT C OPT APPL, P1
   Sarkar V, 2019, 2019 IEEE 26TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING, DATA, AND ANALYTICS (HIPC), P1, DOI 10.1109/HiPC.2019.00012
   Seixas JL, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE & COMPUTATIONAL INTELLIGENCE (CSCI), P677, DOI [10.1109/CSCI.2016.132, 10.1109/CSCI.2016.0133]
   Shurrab S, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.1045
   Sowrirajan H, 2021, PR MACH LEARN RES, V143, P728
   Sumithra R, 2015, PROCEDIA COMPUT SCI, V45, P76, DOI 10.1016/j.procs.2015.03.090
   Tan MX, 2021, PR MACH LEARN RES, V139, P7102
   Verma Anurag Kumar, 2019, Asian Pac J Cancer Prev, V20, P1887, DOI 10.31557/APJCP.2019.20.6.1887
   Xu H, 2023, COMPUT ECON, V61, P1, DOI 10.1007/s10614-019-09909-8
   Zhang J., 2021, COMPUT METH PROG BIO, V210
   Zhang N, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101756
   Zhang XY, 2018, BMC MED INFORM DECIS, V18, DOI 10.1186/s12911-018-0631-9
NR 45
TC 0
Z9 0
U1 8
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21281
EP 21318
DI 10.1007/s11042-023-16306-9
EA AUG 2023
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040962400010
DA 2024-07-18
ER

PT J
AU Roumaissa, B
   Chaouki, BM
AF Roumaissa, Bekiri
   Chaouki, Babahenini Mohamed
TI Hand pose estimation based on regression method from monocular RGB
   cameras for handling occlusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand pose estimation; Occlusion; RGB image; Deep learning; Human
   Computer Interaction
ID 3D HAND
AB Hand pose estimation is a significant research topic for various computer vision applications. Nonetheless, reliable and robust pose estimation with existing methods remains challenging due to the complex anatomy of the hand and the varying shapes and sizes of hands. The traditional approach involved using depth sensors or multi-camera setups. However, with the advent of deep learning, there has been a shift towards using deep neural networks to learn, grasp, and manipulate objects accurately. In this paper, we propose an end-to-end framework called "ResUnet network" that can efficiently detect and estimate the position of a human hand from a monocular RGB image. Our proposal aims to handle occlusion issue during the hand-object interaction in real-time. The ResUnet architecture includes three modules, feature extraction, 2D pose regression, and 3D hand estimation. The first module extracts the feature maps of the cropped hand to generate 2D heatmaps. The second module uses the previous outputs to regress the 2D pose coordinates employing Latent Heatmaps Representation (LHR). The last module concatenates the intermediate features with the upsampling block to process 3D regression and predict the 3D bones using a tree structure of the hand. Quantitative and qualitative results on three datasets GANerated, SynthHands, and Stereo Hand Pose Tracking Benchmark (STB), consistently demonstrate that our regression approach outperforms the current state-of-the-art hand pose estimation methods.
C1 [Roumaissa, Bekiri; Chaouki, Babahenini Mohamed] Mohamed Khider Univ, Comp Sci Dept, LESIA Lab, Biskra 07000, Algeria.
C3 Universite Mohamed Khider Biskra
RP Roumaissa, B (corresponding author), Mohamed Khider Univ, Comp Sci Dept, LESIA Lab, Biskra 07000, Algeria.
EM roumaissa.bekiri@univ-biskra.dz; mc.babahenini@univ-biskra.dz
RI BABAHENINI, Mohamed Chaouki/F-1427-2017
OI BABAHENINI, Mohamed Chaouki/0000-0001-7972-8026
CR Athitsos V, 2003, PROC CVPR IEEE, P432
   Baek S, 2018, PROC CVPR IEEE, P8330, DOI 10.1109/CVPR.2018.00869
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Boukhayma A, 2019, PROC CVPR IEEE, P10835, DOI 10.1109/CVPR.2019.01110
   Cai YJ, 2018, LECT NOTES COMPUT SC, V11210, P678, DOI 10.1007/978-3-030-01231-1_41
   Chen LJ, 2018, ADV NEUR IN, V31
   Dibra E, 2018, IEEE COMPUT SOC CONF, P1188, DOI 10.1109/CVPRW.2018.00155
   Feng Q, 2020, COMPUT ANIMAT VIRT W, V31, DOI 10.1002/cav.1956
   Gao CY, 2022, NEUROCOMPUTING, V474, P25, DOI 10.1016/j.neucom.2021.12.013
   Ge LH, 2019, PROC CVPR IEEE, P10825, DOI 10.1109/CVPR.2019.01109
   Ge LH, 2017, PROC CVPR IEEE, P5679, DOI 10.1109/CVPR.2017.602
   Ge L, 2016, PROC CVPR IEEE, P3593, DOI 10.1109/CVPR.2016.391
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hasson Y, 2019, PROC CVPR IEEE, P11799, DOI 10.1109/CVPR.2019.01208
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He Yang, 2020, CVPR, P2009
   Iqbal U, 2018, LECT NOTES COMPUT SC, V11215, P125, DOI 10.1007/978-3-030-01252-6_8
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kourbane I, 2022, APPL INTELL, V52, P16667, DOI 10.1007/s10489-022-03390-x
   Kulon D., 2019, ARXIV
   Li MR, 2021, IEEE T CIRC SYST VID, V31, P4883, DOI 10.1109/TCSVT.2021.3055862
   Li SL, 2020, IEEE INT CONF ROBOT, P993, DOI [10.1109/ICRA40945.2020.9197299, 10.1109/icra40945.2020.9197299]
   Mofarreh-Bonab M, 2022, VISUAL COMPUT, V38, P2023, DOI 10.1007/s00371-021-02263-7
   Moon G, 2018, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2018.00533
   Mueller F, 2018, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2018.00013
   Mueller F, 2017, IEEE I CONF COMP VIS, P1163, DOI 10.1109/ICCV.2017.131
   Oberweger M, 2020, IEEE T PATTERN ANAL, V42, P1898, DOI 10.1109/TPAMI.2019.2907951
   Qian C, 2014, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.2014.145
   Romero J., 2022, ARXIV
   Romero J, 2010, IEEE INT CONF ROBOT, P458, DOI 10.1109/ROBOT.2010.5509753
   Spurr A, 2018, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2018.00017
   Sridhar S, 2013, IEEE I CONF COMP VIS, P2456, DOI 10.1109/ICCV.2013.305
   Su YZ, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P222, DOI 10.1109/ISMAR-Adjunct.2019.00-42
   Tekin B, 2019, PROC CVPR IEEE, P4506, DOI 10.1109/CVPR.2019.00464
   Le VH, 2019, ISCIT 2019: PROCEEDINGS OF 2019 19TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P76, DOI 10.1109/ISCIT.2019.8905243
   Wan CD, 2016, LECT NOTES COMPUT SC, V9907, P554, DOI 10.1007/978-3-319-46487-9_34
   Wu MY, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102802
   Xiang DL, 2019, PROC CVPR IEEE, P10957, DOI 10.1109/CVPR.2019.01122
   Ye Q, 2018, LECT NOTES COMPUT SC, V11214, P817, DOI 10.1007/978-3-030-01249-6_49
   Yeo HS, 2015, MULTIMED TOOLS APPL, V74, P2687, DOI 10.1007/s11042-013-1501-1
   Yuan S., 2018, ARXIV
   Zhang X, 2019, IEEE I CONF COMP VIS, P2354, DOI 10.1109/ICCV.2019.00244
   Zhang Y, 2016, ARXIV
   Zhou YD, 2018, LECT NOTES COMPUT SC, V11218, P521, DOI 10.1007/978-3-030-01264-9_31
   Zimmermann C, 2017, IEEE I CONF COMP VIS, P4913, DOI 10.1109/ICCV.2017.525
NR 45
TC 1
Z9 1
U1 5
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21497
EP 21523
DI 10.1007/s11042-023-16384-9
EA AUG 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040962400005
DA 2024-07-18
ER

PT J
AU Shen, X
   Wang, HB
   Li, YF
   Gao, TZ
   Fu, XP
AF Shen, Xin
   Wang, Huibing
   Li, Yafeng
   Gao, Tianzhu
   Fu, Xianping
TI Criss-cross global interaction-based selective attention in YOLO for
   underwater object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater object detection; Information interaction; Selective
   attention; YOLO detectors
AB With the development of computer vision, object detection has attracted wide attention and achieved exciting results in most situations. However, facing underwater environments, object detection's performance degrades severely due to multiple ineluctable factors, including poor underwater imaging quality, underwater objects with protective colors, etc. These lead to strong interference of underwater backgrounds and the weak discriminability of underwater object features, which make underwater object detection become an extremely challenging task and cry out for reliable solutions. In order to reduce the underwater background interference and improve underwater object perception, we first propose the criss-cross global interaction strategy (CGIS). CGIS consists of two criss-cross structures, where feature decomposition and feature extraction are performed sequentially according to different criss-cross shapes in each structure. For information interaction, our strategy simultaneously avoids the destruction of direct information correspondence and the lack of global information interaction. According to different parameter allocation strategies, CGIS is further divided into standard criss-cross global interaction strategy (SCGIS) and efficient criss-cross global interaction strategy (ECGIS). We then design the criss-cross global interaction-based selective attention in different target dimensions. Our selective attention efficiently perceives global underwater information and rationally allocates precious computing resources to important underwater regions. We finally combine the designed selective attention with YOLO detectors, where attention modules are added to both ends of the feature fusion. The experimental results show that our work makes important progress in achieving efficient underwater object detection. Our selective attention shows good robustness in various YOLO detectors and exhibits ideal generalization in different detection tasks.
C1 [Shen, Xin; Wang, Huibing; Li, Yafeng; Gao, Tianzhu; Fu, Xianping] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
   [Fu, Xianping] Peng Cheng Lab, Shenzhen 518000, Peoples R China.
C3 Dalian Maritime University; Peng Cheng Laboratory
RP Fu, XP (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.; Fu, XP (corresponding author), Peng Cheng Lab, Shenzhen 518000, Peoples R China.
EM shenxin@dlmu.edu.cn; huibing.wang@dlmu.edu.cn; yfl@dlmu.edu.cn;
   brain@dlmu.edu.cn; fxp@dlmu.edu.cn
RI Yafeng, Li/GWQ-5263-2022
FU National Natural Science Foundation of China [61370142, 61802043,
   61272368, 62176037, 62002041]; Fundamental Research Funds for the
   Central Universities [3132016352, 3132021238]; Dalian Science and
   Technology Innovation Fund [2018J12GX037, 2019J11CY001, 2021JJ12GX028];
   Liaoning Revitalization Talents Program [XLYC1908007]; Liaoning Doctoral
   Research Start-up Fund Project Grant [2021-BS-075]; China Postdoctoral
   Science Foundation [3620080307]
FX The authors gratefully acknowledge the financial supports from the
   National Natural Science Foundation of China under Grant 61370142, Grant
   61802043, Grant 61272368, Grant 62176037 and Grant 62002041, in part by
   the Fundamental Research Funds for the Central Universities under Grant
   3132016352 and Grant 3132021238, in part by the Dalian Science and
   Technology Innovation Fund under Grant 2018J12GX037, Grant 2019J11CY001
   and Grant 2021JJ12GX028, in part by Liaoning Revitalization Talents
   Program under Grant XLYC1908007, in part by the Liaoning Doctoral
   Research Start-up Fund Project Grant 2021-BS-075, and in part by the
   China Postdoctoral Science Foundation under Grant 3620080307.
CR [Anonymous], 2022, YOLOV6 SINGLE STAGE
   [Anonymous], 2023, YOLOV8
   [Anonymous], 2023, BRACKISH DATASET
   [Anonymous], 2023, UNDERWATER ROBOT PIC
   Bhaumik G, 2023, MULTIMED TOOLS APPL, DOI [10.1007/s11042-023-16988-1, 10.1007/s11042-021-11623-3]
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Cao P, 2022, MULTIMED TOOLS APPL, V81, P34325, DOI 10.1007/s11042-022-12792-5
   Chen L, 2022, PATTERN RECOGN, V132, DOI 10.1016/j.patcog.2022.108926
   Chen YM, 2023, MOL BIOTECHNOL, V65, P361, DOI 10.1007/s12033-022-00526-9
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Ge Z., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.08430
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Jocher G., 2021, YOLOV5
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Lee H, 2019, IEEE I CONF COMP VIS, P1854, DOI 10.1109/ICCV.2019.00194
   Li X., 2019, ARXIV
   Lin WH, 2020, INT CONF ACOUST SPEE, P2588, DOI [10.1109/icassp40776.2020.9053829, 10.1109/ICASSP40776.2020.9053829]
   Liu CW, 2022, IEEE T CIRC SYST VID, V32, P2831, DOI 10.1109/TCSVT.2021.3100059
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Mao YX, 2022, PATTERN RECOGN IMAGE, V32, P591, DOI 10.1134/S1054661822030245
   Park J.C., 2018, P BRIT MACHINE VISIO
   Qin ZQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P763, DOI 10.1109/ICCV48922.2021.00082
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Song PH, 2023, NEUROCOMPUTING, V530, P150, DOI 10.1016/j.neucom.2023.01.088
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wang C.-Y., 2022, arXiv
   Wang H., 2022, IEEE Transactions on Multimedia
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu FQ, 2021, NEURAL COMPUT APPL, V33, P3637, DOI 10.1007/s00521-020-05217-7
   Xu S., 2023, Neurocomputing
   Yang J., 2021, arXiv
   Yeh CH, 2022, IEEE T NEUR NET LEAR, V33, P6129, DOI 10.1109/TNNLS.2021.3072414
   Yu HF, 2023, APPL INTELL, V53, P2434, DOI 10.1007/s10489-022-03622-0
   Zhang QL, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2235, DOI 10.1109/ICASSP39728.2021.9414568
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhao H., 2020, P IEEE CVF C COMP VI, V2020, P10076, DOI 10.1109/CVPR42600.2020.01009
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
NR 51
TC 4
Z9 4
U1 12
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20003
EP 20032
DI 10.1007/s11042-023-16311-y
EA JUL 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040015500007
DA 2024-07-18
ER

PT J
AU Huang, SG
   Arpaci, I
   Al-Emran, M
   Kilicarslan, S
   Al-Sharafi, MA
AF Huang, Shigao
   Arpaci, Ibrahim
   Al-Emran, Mostafa
   Kilicarslan, Serhat
   Al-Sharafi, Mohammed A.
TI A comparative analysis of classical machine learning and deep learning
   techniques for predicting lung cancer survivability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Survival period prediction; Lung cancer; Demographic and clinical
   features; Classical machine learning; Deep learning
ID CLASSIFICATION
AB Lung cancer, one of the deadliest forms of cancer, can significantly improve patient survival rates by 60-70% if detected in its early stages. The prediction of lung cancer patient survival has grown to be a popular area of research among medical and computer science experts. This study aims to predict the survival period of lung cancer patients using 12 demographic and clinical features. This is achieved through a comparative analysis between traditional machine learning and deep learning techniques, deviating from previous studies that primarily used CT or X-ray images. The dataset included 10,001 lung cancer patients, and the data attributes involved gender, age, race, T (tumor size), M (tumor dissemination to other organs), N (lymph node involvement), Chemo, DX-Bone, DX-Brain, DX-Liver, DX-Lung, and survival months. Six supervised machine learning and deep learning techniques were applied, including logistic-regression (Logistic), Bayes classifier (BayesNet), lazy-classifier (LWL), meta-classifier (AttributeSelectedClassifier (ASC)), rule-learner (OneR), decision-tree (J48), and deep neural network (DNN). The findings suggest that DNN surpassed the performance of the six traditional machine learning models in accurately predicting the survival duration of lung cancer patients, achieving an accuracy rate of 88.58%. This evidence is thought to assist healthcare experts in cost management and timely treatment provision.
C1 [Huang, Shigao] Fourth Mil Med Univ, Xijing Hosp, Natl Translat Sci Ctr Mol Med, Dept Cell Biol, Xian, Peoples R China.
   [Arpaci, Ibrahim] Bandirma Onyedi Eylul Univ, Dept Software Engn, Balikesir, Turkiye.
   [Al-Emran, Mostafa] British Univ Dubai, Fac Engn & IT, Dubai, U Arab Emirates.
   [Al-Emran, Mostafa] Dijlah Univ Coll, Dept Comp Tech Engn, Baghdad, Iraq.
   [Kilicarslan, Serhat] Tokat Gaziosmanpasa Univ, Dept Informat, Tokat, Turkiye.
   [Al-Sharafi, Mohammed A.] Univ Tenaga Nas, Inst Informat & Comp Energy, Putrajaya Campus, Kajang 43000, Selangor, Malaysia.
C3 Air Force Military Medical University; Bandirma Onyedi Eylul University;
   Dijlah University College; Gaziosmanpasa University; Universiti Tenaga
   Nasional
RP Al-Emran, M (corresponding author), British Univ Dubai, Fac Engn & IT, Dubai, U Arab Emirates.; Al-Emran, M (corresponding author), Dijlah Univ Coll, Dept Comp Tech Engn, Baghdad, Iraq.
EM huangshigao2010@aliyun.com; iarpaci@bandirma.edu.tr;
   mustafa.n.alemran@gmail.com; serhat.kilicarslan@gop.edu.tr;
   mohamed.a.alsharafi@gmail.com
RI Al-Sharafi, Mohammed A./E-1530-2017; ARPACI, Ibrahim/AAC-2389-2019;
   Al-Emran, Mostafa/W-4466-2018; KILIÇARSLAN, Serhat/AHB-3775-2022
OI Al-Sharafi, Mohammed A./0000-0003-0726-6031; ARPACI,
   Ibrahim/0000-0001-6513-4569; Al-Emran, Mostafa/0000-0002-5269-5380;
   KILIÇARSLAN, Serhat/0000-0001-9483-4425
CR ACS A. C. S., 2022, KEY STAT LUNG CANC
   Adem K., 2021, Afyon Kocatepe Universitesi Fen Ve Muhendis. Bilim. Derg., V21, P300, DOI [10.35414/akufemubid.788898, DOI 10.35414/AKUFEMUBID.788898]
   Adem K, 2019, EXPERT SYST APPL, V115, P557, DOI 10.1016/j.eswa.2018.08.050
   Ajagbe SA, 2022, 2022 INT C ELECT COM, P1, DOI [10.1109/ICECET55527.2022.9872568, DOI 10.1109/ICECET55527.2022.9872568]
   Al-Emran M., 2021, Studies in Systems, Decision and Control, P1, DOI DOI 10.1007/978-3-030-67716-9_1
   Alshurideh M, 2023, INTERACT LEARN ENVIR, V31, P1214, DOI 10.1080/10494820.2020.1826982
   Arpaci I, 2021, MULTIMED TOOLS APPL, V80, P11943, DOI 10.1007/s11042-020-10340-7
   Arpaci I, 2019, COMPUT HUM BEHAV, V90, P181, DOI 10.1016/j.chb.2018.09.005
   Awotunde JB, 2021, COMM COM INF SC, V1455, P319, DOI 10.1007/978-3-030-89654-6_23
   Boddu RSK, 2022, MATER TODAY-PROC, V56, P2213, DOI 10.1016/j.matpr.2021.11.549
   Brinati D, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-01597-4
   Bülbül MA, 2022, ARAB J SCI ENG, V47, P2329, DOI 10.1007/s13369-021-06168-4
   Cai ZH, 2015, MOL BIOSYST, V11, P791, DOI 10.1039/c4mb00659c
   Celik A.E., 2022, 2022 12 INT C ADV CO, P540, DOI DOI 10.1109/ACIT54803.2022.9913114
   Chen YC, 2014, COMPUT BIOL MED, V48, P1, DOI 10.1016/j.compbiomed.2014.02.006
   Citak D, 2021, J FOOD MEAS CHARACT, V15, P1843, DOI 10.1007/s11694-020-00761-1
   Dass MV, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, ENERGY & COMMUNICATION (CIEC), P558, DOI 10.1109/CIEC.2014.6959151
   Doppalapudi S, 2021, INT J MED INFORM, V148, DOI 10.1016/j.ijmedinf.2020.104371
   Dutta AK, 2022, INTELL AUTOM SOFT CO, V31, P1007, DOI 10.32604/iasc.2022.019778
   Erkan U, 2021, NEURAL COMPUT APPL, V33, P5381, DOI 10.1007/s00521-020-05343-2
   Feng X, 2020, FRONT COMPUT NEUROSC, V14, DOI 10.3389/fncom.2020.00025
   Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199
   Hsu CH, 2018, 2018 IEEE 8TH INTERNATIONAL SYMPOSIUM ON CLOUD AND SERVICE COMPUTING (SC2), P111, DOI 10.1109/SC2.2018.00023
   Hussain L, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12136517
   Ibrahim DM, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104348
   Jiang Y, 2022, BRAIN SCI, V12, DOI 10.3390/brainsci12060797
   Kilicarslan S, 2020, MED HYPOTHESES, V137, DOI 10.1016/j.mehy.2020.109577
   Kumar R, 2011, INDIAN PEDIATR, V48, P277, DOI 10.1007/s13312-011-0055-4
   Kwong RY, 2003, CIRCULATION, V108, pE104, DOI 10.1161/01.CIR.0000086899.32832.EC
   Liu CL, 2019, C IND ELECT APPL, P1204, DOI 10.1109/iciea.2019.8833699
   McWilliams A, 2015, IEEE T BIO-MED ENG, V62, P2044, DOI 10.1109/TBME.2015.2409092
   Nadkarni Nidhi S., 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P863, DOI 10.1109/ICOEI.2019.8862577
   Ogunseye E.O., 2022, ParadigmPlus, V3, P11, DOI [10.55969/paradigmplus.v3n2a2, DOI 10.55969/PARADIGMPLUS.V3N2A2]
   Pacal I, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105031
   Peng Gang, 2011, Proceedings of the 2011 12th International Conference on Parallel and Distributed Computing Applications and Technologies (PDCAT 2011), P197, DOI 10.1109/PDCAT.2011.64
   Sahoo G., 2012, INT J INFORM TECHNOL, V4, P43, DOI [10.5815/ijitcs.2012.07.06, DOI 10.5815/IJITCS.2012.07.06]
   SEER, 2021, SEER INC DAT 1975 20
   She YL, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.5842
   Vas M, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, CONTROL AND AUTOMATION (ICCUBEA)
   Vegega C., 2020, PARADIGMPLUS, V1, P1, DOI [10.55969/paradigmplus.v1n1a1, DOI 10.55969/PARADIGMPLUS.V1N1A1]
   Wang HK, 2017, EJNMMI RES, V7, DOI 10.1186/s13550-017-0260-9
   Wu J, 2016, RADIOLOGY, V281, P270, DOI 10.1148/radiol.2016151829
   Wu Q, 2017, 2017 INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND INTELLIGENT CONTROLS (ISCSIC), P88, DOI 10.1109/ISCSIC.2017.22
   Xie Y, 2021, TRANSL ONCOL, V14, DOI 10.1016/j.tranon.2020.100907
   Ye N., 2003, HDB DATA MINING, DOI [10.1201/b12469, DOI 10.1201/B12469]
   Zaza S, 2015, PR INT CONF ELEARN, P275, DOI 10.1109/ECONF.2015.57
   Zhou, 2021, INT J GEN MED, V5911
NR 47
TC 4
Z9 4
U1 6
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34183
EP 34198
DI 10.1007/s11042-023-16349-y
EA JUL 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:001043237000003
DA 2024-07-18
ER

PT J
AU Choudhary, A
   Arora, A
AF Choudhary, Anshika
   Arora, Anuja
TI GIN-FND: Leveraging users' preferences for graph isomorphic network
   driven fake news detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Graph Neural Network; Graph Isomorphic Network; GIN; User preferences;
   Graph modelling; Fake news detection
AB Exponential growth of news content on social media makes it easy to know the recent updates but confidence to get genuine or fake news is uncertain. Often these uncertainties are so convincing and undetectable by cautious human inspection. In the present work, a peculiar feature of social media -the news propagation graph is considered an evident feature for news identification due to the exposure of varying content dissemination patterns of fake and real news through these propagation graphs. In the article, news content features and user profile features are embedded with nodes, and a tweet-retweet network is used to model the propagation graph of fake/real news in the social network. Further, a specialized variant of graph neural network- graph isomorphic network has been used to develop the Graph Isomorphic Network Fake News Detection (GIN-FND) model. The isomorphic network-based similarity in propagation graph for fake news detection of news is validated on word embedding features (SpaCy and LargeBERT) and user profile features. Results show the overall outstanding performance of the proposed GIN-FND model in comparison with the existing graph neural network model for fake news detection. GIN-FND achieved the best accuracy by making use of SpaCy features is 98.63% and 85.48% for the training dataset, 95.24% and 77.42% for validation, 95.61 and 79.64% for the test dataset of Gossip Cop and PolitiFact respectively.
C1 [Choudhary, Anshika; Arora, Anuja] Jaypee Inst Informat & Technol, Dept Comp Sci & Engn & Informat Technol, Noida, Uttar Pradesh, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Choudhary, A (corresponding author), Jaypee Inst Informat & Technol, Dept Comp Sci & Engn & Informat Technol, Noida, Uttar Pradesh, India.
EM 18403001@mail.jiit.ac.in; anuja.arora@jiit.ac.in
RI Arora, Anuja/T-7013-2019
OI Arora, Anuja/0000-0001-5215-1300; Choudhary, Anshika/0000-0003-3411-4287
CR Aggrawal Niyati, 2019, International Journal of Business Innovation and Research, V20, P106
   Aggrawal N, 2021, KYBERNETES, V50, P1811, DOI 10.1108/K-03-2020-0128
   Babai L., 1979, 20th Annual Symposium of Foundations of Computer Science, P39, DOI 10.1109/SFCS.1979.8
   Bauskar S., 2019, International Journal of Information Engineering and Electronic Business, V11, P1
   Cai HY, 2017, Arxiv, DOI arXiv:1705.05085
   Chandra S, 2020, Arxiv, DOI arXiv:2008.06274
   Chaudhary Anshika, 2019, 2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon), P346, DOI 10.1109/COMITCon.2019.8862186
   Choudhary Anshika, 2022, International Journal of Ambient Computing and Intelligence, DOI 10.4018/IJACI.309407
   Choudhary A, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114171
   Conroy N. J., 2015, P ASS INFORM SCI TEC, V52, P1, DOI 10.1002/pra2.2015.145052010082
   Dai HJ, 2018, Arxiv, DOI arXiv:1704.01665
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dou Y., 2021, User preference-aware fake news detection
   Dou YT, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2051, DOI 10.1145/3404835.3462990
   Fout A, 2017, ADV NEUR IN, V30
   Hamilton WL, 2017, ADV NEUR IN, V30
   Han Y, 2020, Arxiv, DOI arXiv:2007.03316
   Hassan N, 2017, PROC VLDB ENDOW, V10, P1945
   Honnibal M., 2017, IN PRESS, DOI DOI 10.3233/978-1-60750-588-4-1080
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Karnyoto AS, 2022, INT J MACH LEARN CYB, V13, P2033, DOI 10.1007/s13042-021-01503-5
   Hamilton WL, 2018, Arxiv, DOI [arXiv:1709.05584, 10.48550/arXiv.1709.05584]
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li QF, 2020, Arxiv, DOI arXiv:2010.05202
   Liao H, 2020, PREPRINT
   Ma J., 2018, Rumor Detection on Twitter with Tree-Structured Recursive Neural Networks
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Ma J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P708, DOI 10.18653/v1/P17-1066
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Monti F, 2019, Arxiv, DOI arXiv:1902.06673
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Nguyen VH, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1165, DOI 10.1145/3340531.3412046
   Oono Kenta, 2019, arXiv, DOI DOI 10.48550/ARXIV.1905.10947
   P‚rez-Rosas V, 2017, Arxiv, DOI [arXiv:1708.07104, DOI 10.48550/ARXIV.1708.07104]
   Sahoo SR, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106983
   Shervashidze N, 2011, J MACH LEARN RES, V12, P2539
   Shu K, 2020, BIG DATA, V8, P171, DOI 10.1089/big.2020.0062
   Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994
   Song CG, 2022, NEUROCOMPUTING, V505, P362, DOI 10.1016/j.neucom.2022.07.057
   Taneja A, 2018, SOCIAL NETWORK ANALY, P203
   Tschiatschek S, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P517, DOI 10.1145/3184558.3188722
   Turenne N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0189080
   Ullah I, 2022, APPL INTELL, V52, P9033, DOI 10.1007/s10489-021-02973-4
   van den Berg R, 2017, Arxiv, DOI arXiv:1706.02263
   Veličkovic P, 2018, Arxiv, DOI arXiv:1710.10903
   Wallace B., 2015, ARXIV
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wani A., 2021, CombatingOnline Hostile Posts in Regional Languages During Emergency Situation, P153
   Weisfeiler B., 1968, Nauchno-Technicheskaya Informatsiya, V2, P12
   Wieder O, 2020, DRUG DISCOV TODAY-TE
   Wu L, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P637, DOI 10.1145/3159652.3159677
   Wu YJ, 2020, AAAI CONF ARTIF INTE, V34, P1054
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xu K., 2018, arXiv, DOI DOI 10.48550/ARXIV.1810.00826
   Ying J., 2018, arXiv
   Zhang JW, 2020, PROC INT CONF DATA, P1826, DOI 10.1109/ICDE48307.2020.00180
   Zhou J, 2020, AI OPEN, V1, P57, DOI 10.1016/j.aiopen.2021.01.001
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
   Zhou XY, 2020, LECT NOTES ARTIF INT, V12085, P354, DOI 10.1007/978-3-030-47436-2_27
NR 60
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUL 24
PY 2023
DI 10.1007/s11042-023-16285-x
EA JUL 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA N2YI0
UT WOS:001035725700011
DA 2024-07-18
ER

PT J
AU Jain, S
   Doriya, R
AF Jain, Saurabh
   Doriya, Rajesh
TI Performance evaluation of hyper-ledger fabric-based consensus mechanism
   on multi-robot path planning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Path planning; Multi-robot; Blockchain; Hyperledger fabric; Ordering
   services; Consensus
AB Path planning is one of the key issues in Robotics. Finding the optimal path in a dense environment is a very critical task. Coordination and collision avoidance between diverse robots is necessary for creating a collision-free environment as well as efficient path planning. Therefore, with any collision avoidance, it is very important to form a consensus among the robots to reach an optimal solution. The consensus is a term that is used in various platforms (Bitcoin, Ethereum, and Hyperledger fabric) in the blockchain, which means that an agreement between entities is the only appropriate solution. There are different platforms in the blockchain (Some of which are public and some are private), where consensus can be formed between robots. Mobile robots are one of the resource-constraint devices, in terms of memory, battery, storage, and limited on-board processing. For this reason, various researches state that the public blockchain (like Proof of Work) is not appropriate for resource-constraints devices such as robotics. Private Blockchain network, such as Hyperledger Fabric may be a better choice for the resource constrained devices. In this paper, Kafka-based ordering service is being implemented in a multi-robot path planning environment. The simulation results say, despite being resource-intensive Kafka is better than Solo in many aspects. Kafka-based ordering service is efficient in terms of consensus time, ledger commit latency, and CPU utilization in a robotics environment.
C1 [Jain, Saurabh; Doriya, Rajesh] Natl Inst Technol, Dept Informat Technol, Raipur 492010, Chhattisgarh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Jain, S (corresponding author), Natl Inst Technol, Dept Informat Technol, Raipur 492010, Chhattisgarh, India.
EM sjain.phd2017.it@nitrr.ac.in; rajeshdoriya.it@nitrr.ac.in
RI Doriya, Rajesh/AAT-2477-2020
OI Doriya, Rajesh/0000-0001-6375-4940; Jain, Dr.
   Saurabh/0000-0002-0338-3356
CR Afanasyev I, SOLUTIONS MULTIAGENT, DOI [10.5555/3338290.3338366, DOI 10.5555/3338290.3338366]
   Alqassem I, 2014, 2014 IEEE INTERNATIONAL CONFERENCE (ITHINGS) - 2014 IEEE INTERNATIONAL CONFERENCE ON GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) - 2014 IEEE INTERNATIONAL CONFERENCE ON CYBER-PHYSICAL-SOCIAL COMPUTING (CPS), P436, DOI 10.1109/iThings.2014.78
   Androulaki E, 2018, EUROSYS '18: PROCEEDINGS OF THE THIRTEENTH EUROSYS CONFERENCE, DOI 10.1145/3190508.3190538
   [Anonymous], BRING KAFK BAS ORD S
   [Anonymous], ZOOKEEPER COORD DIST
   Basegio TL, 2018, LECT NOTES ARTIF INT, V10738, P75, DOI 10.1007/978-3-319-91899-0_5
   Bohlin R., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P521, DOI 10.1109/ROBOT.2000.844107
   Boyd C, 2016, LECT NOTES COMPUT SC, V9722, P161, DOI 10.1007/978-3-319-40253-6_10
   Camenisch J, 2010, LECT NOTES COMPUT SC, V6371, P198, DOI 10.1007/978-3-642-15898-8_13
   Dewangan RK, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES AND MANAGEMENT FOR COMPUTING, COMMUNICATION, CONTROLS, ENERGY AND MATERIALS (ICSTM), P423, DOI 10.1109/ICSTM.2017.8089197
   Erdmann Michael., 1986, on Multiple Moving Objects. pages, P1419, DOI DOI 10.1109/ROBOT.1986.1087401
   Fernando D, 2019, LECT NOTES BUS INF P, V361, P136, DOI 10.1007/978-3-030-30429-4_10
   Fuenfrocken M, 2016, 2016 WORKSHOP ON AUTOMOTIVE SYSTEMS/SOFTWARE ARCHITECTURES (WASA), P14, DOI 10.1109/WASA.2016.11
   Galtier M., 2019, ARXIV
   Gervais A., 2016, P 2016 ACMSIGSAC C C, P3
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Masehian E, 2010, ADV ELECTR COMPUT EN, V10, P69, DOI 10.4316/AECE.2010.04011
   Mokhtar A, 2019, 2019 IEEE 5TH WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P584, DOI [10.1109/wf-iot.2019.8767340, 10.1109/WF-IoT.2019.8767340]
   Nakamoto S., 2008, DECENTRAL BUS REV
   Nakamoto S., 2008, DECENT BUS REV, V21260, DOI https://bitcoin.org/bitcoin.pdf
   Peck ME, 2017, IEEE SPECTRUM, V54, P24, DOI 10.1109/MSPEC.2017.8048835
   Sharma K, 2020, INT J INTELL ROBOT, V4, P294, DOI 10.1007/s41315-020-00129-0
   Sousa J, 2018, I C DEPEND SYS NETWO, P51, DOI 10.1109/DSN.2018.00018
   Thakkar P, 2018, I S MOD ANAL SIM COM, P264, DOI 10.1109/MASCOTS.2018.00034
   Tosh DK, 2017, 2017 IEEE 8TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (UEMCON), P469, DOI 10.1109/UEMCON.2017.8249088
   Xu XW, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ARCHITECTURE (ICSA 2017), P243, DOI 10.1109/ICSA.2017.33
   Zheng ZB, 2017, IEEE INT CONGR BIG, P557, DOI 10.1109/BigDataCongress.2017.85
NR 27
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 15769
EP 15783
DI 10.1007/s11042-023-16341-6
EA JUL 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035725700001
DA 2024-07-18
ER

PT J
AU Nathiya, S
   Sujatha, R
AF Nathiya, S.
   Sujatha, R.
TI GAN with CCSO: generative adversarial network-driven CAViaR competitive
   swarm optimizer for medical video super resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical diagnosis; Competitive swarm optimizer; Generative adversarial
   network; Tversky index; Super resolution
AB In medical image analysis, there is a vast requirement of information in an image. The medical diagnosis is fine when the fine details in the image are preserved and the image is in high resolution. In medical imaging, getting high-resolution images is demanding and expensiveas it needscomplicated and luxurious instruments, skilled human resources, and also causes operation delays. The medical videos with the super resolution support the specialists in monitoring the tiny lesions, thereby enhancing the probability of analyzing and treating the disease. The super resolution methods based on deep learning assist to mine rich details from a low-resolution image. Hence, this research develops a Generative Adversarial Network with CAViaR Competitive Swarm Optimizer(GAN with CCSO) for medical super resolution. Initially, from the input medical video the frames are removed, and then the video super resolution phase is done. In this phase, every frame is subjected to Polynomial and Laplacian Weighted Regression model and GAN with CCSO, separately. Then, the Tversky index-based fusion mechanism is accomplished to fuse the outcome obtained from the Polynomial and Laplacian weighted Regression model and GAN with the CCSO approach to obtain efficient, super resolution frames. At last, the enhanced super resolution image is obtained. The proposed CCSO is formulatedwith the Conditional Autoregressive Value at Risk by Regression Quantiles (CAViaR) and Competitive Swarm Optimizer (CSO). Besides, the proposed GAN with the CCSO technique achieved effective performance in terms of a higher Structural Similarity Index Measure (SSIM) of 0.939 dB, higher Second Derivative Measure of Enhancement (SDME) of 76.03 dB, and maximal Peak Signal-to-noise ratio (PSNR) of 37.26 dB, for upscaling factor 2.
C1 [Nathiya, S.; Sujatha, R.] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore Campus,Tiruvalam Rd, Vellore 632014, Tamilnadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Sujatha, R (corresponding author), Vellore Inst Technol, Sch Informat Technol & Engn, Vellore Campus,Tiruvalam Rd, Vellore 632014, Tamilnadu, India.
EM nathiya.s2019@vitstudent.ac.in; r.sujatha@vit.ac.in
RI Radhakrishnan, Sujatha/C-5239-2019
OI Radhakrishnan, Sujatha/0000-0002-1993-7544
CR Amar BD, 2017, P INT C INF COMM TEC, P10
   [Anonymous], About Us
   Cheng Peng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7747, DOI 10.1109/CVPR42600.2020.00777
   Cheng R, 2015, IEEE T CYBERNETICS, V45, P191, DOI 10.1109/TCYB.2014.2322602
   Dian RW, 2017, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2017.411
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Engle RF, 2004, J BUS ECON STAT, V22, P367, DOI 10.1198/073500104000000370
   Han L, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9122085
   Jhih-Yuan Lin, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P66, DOI 10.1007/978-3-030-59719-1_7
   KOMPELLA VP, 1992, IEEE INFOCOM SER, P2078, DOI 10.1109/INFCOM.1992.263480
   Liu H, 2020, SINGLE FRAME MULTIFR
   Liu H, 2021, J OPER RES SOC, V72, P2460, DOI 10.1080/01605682.2020.1796535
   Ma C, 2020, PROC CVPR IEEE, P5568, DOI 10.1109/CVPR42600.2020.00561
   Nah S, 2019, PROC CVPR IEEE, P8094, DOI 10.1109/CVPR.2019.00829
   Okuhata Hiroyuki, 2014, 2014 IEEE International Conference on Consumer Electronics (ICCE), P181, DOI 10.1109/ICCE.2014.6775963
   Pascual S, 2017, INTERSPEECH, P3642, DOI 10.21437/Interspeech.2017-1428
   Reddy AP, 2020, EVOL INTELL, P1
   Ren S, 2021, IEEE ACCESS, V9, P17909, DOI 10.1109/ACCESS.2021.3054433
   Ren S, 2019, 2019 INTERNATIONAL CONFERENCE ON INTERNET OF THINGS (ITHINGS) AND IEEE GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE CYBER, PHYSICAL AND SOCIAL COMPUTING (CPSCOM) AND IEEE SMART DATA (SMARTDATA), P682, DOI [10.1109/iThings/GreenCom/CPSCom/SmartData.2019.00130, 10.1109/iThings/GreenGom/CPSGom/SmartData.2019.00130]
   Sudhakar R, 2019, IMAGING SCI J, V67, P305, DOI 10.1080/13682199.2019.1652445
   Sun W, 2020, NEUROCOMPUTING, V406, P24, DOI 10.1016/j.neucom.2020.03.068
   Taha M, 2021, MULTIMED TOOLS APPL, V80, P26833, DOI 10.1007/s11042-021-10934-9
   Taha M, 2021, TELECOMMUN SYST, V77, P63, DOI 10.1007/s11235-020-00741-2
   Thawakar O, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909900
   Usman M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-61705-9
   zenodo, About us
NR 26
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17373
EP 17394
DI 10.1007/s11042-023-16134-x
EA JUL 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035725700003
DA 2024-07-18
ER

PT J
AU Meena, G
   Mohbey, KK
   Indian, A
   Khan, MZ
   Kumar, S
AF Meena, Gaurav
   Mohbey, Krishna Kumar
   Indian, Ajay
   Khan, Mohammad Zubair
   Kumar, Sunil
TI Identifying emotions from facial expressions using a deep convolutional
   neural network-based approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Facial sentiment analysis; Convolutional neural networks
ID SENTIMENT ANALYSIS; STATE
AB Sentiment identification on facial expression is an interesting study domain with applications in various disciplines, including security, health, and human-machine interfaces. The main goal of sentiment analysis is to decide an individual's perspective on a topic or the document's overall contextual polarity. In nonverbal communication, sentiment analysis plays a vital role in an individual's feelings, reflecting on the faces. Researchers in this area are interested in improving models and methods and extracting various characteristics to provide a better computer prediction of sentiments. Sentiment polarities are mainly classified as positive, negative, and neutral. Many sentiment analysis approaches exist, but deep learning architectures can handle extensive data and provide better performances. We presented a solution based on the CNN (Convolutional Neural Network) model for handling this problem. This work uses the extended Cohn Kanade (CK+) and FER-2013 datasets for facial expression recognition study. Several existing architectures are used to evaluate the efficiency of the proposed model. Extensive experiments are carried out on both CK+ and FER-2013 data sets, and our framework outperforms state-of-the-art techniques. According to obtained results, the CNN3 model gives 79% and 95% accuracy for FER-2013 and CK+ datasets, respectively.
C1 [Meena, Gaurav; Mohbey, Krishna Kumar; Indian, Ajay] Cent Univ Rajasthan, Dept Comp Sci, Ajmer 305817, India.
   [Khan, Mohammad Zubair] Taibah Univ, Dept Comp Sci, Fac Engn, Yanbu, Saudi Arabia.
   [Kumar, Sunil] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, India.
C3 Central University of Rajasthan (CURAJ); Taibah University; Vellore
   Institute of Technology (VIT); VIT Vellore
RP Meena, G (corresponding author), Cent Univ Rajasthan, Dept Comp Sci, Ajmer 305817, India.
EM gaurav.meena@curaj.ac.in; kmohbey@curaj.ac.in; ajay.indian@curaj.ac.in;
   mkhanb@taibahu.edu.sa; 2sunil.cs@gmail.com
RI Kumar, Dr. Sunil/ABH-1802-2021; Indian, Ajay/AHI-5427-2022; KHAN,
   MOHAMMAD ZUBAIR/D-4478-2012
OI Kumar, Dr. Sunil/0000-0002-9778-6550; KHAN, MOHAMMAD
   ZUBAIR/0000-0002-2409-7172; meena, gaurav/0000-0001-5528-2437
CR Agrawal A, 2020, VISUAL COMPUT, V36, P405, DOI 10.1007/s00371-019-01630-9
   Ain QT, 2017, INT J ADV COMPUT SC, V8, P424
   Alsharekh MF, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22166105
   [Anonymous], 2017, INT J ENG SCI
   Appasaheb Borgalli Rohan, 2022, Journal of Physics: Conference Series, V2236, DOI 10.1088/1742-6596/2236/1/012004
   Babajee P, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P36, DOI [10.1109/ZINC50678.2020.9161445, 10.1109/zinc50678.2020.9161445]
   Benamara NK, 2021, INTEGR COMPUT-AID E, V28, P97, DOI 10.3233/ICA-200643
   Bengio Y., 2017, DEEP LEARNING
   Benmohamed A, 2015, MULTIMED TOOLS APPL, V74, P9297, DOI 10.1007/s11042-014-2082-3
   Cai GY, 2015, LECT NOTES ARTIF INT, V9362, P159, DOI 10.1007/978-3-319-25207-0_14
   Campos V, 2017, IMAGE VISION COMPUT, V65, P15, DOI 10.1016/j.imavis.2017.01.011
   Castellano G, 2023, MULTIMED TOOLS APPL, V82, P12751, DOI 10.1007/s11042-022-14050-0
   Chen T., 2014, arXiv
   Dalai R., 2017, INT RES J ENG TECHNO, V4
   Gajarla V., 2015, Georgia Institute of Technology, V2015, P1
   Gan YL, 2019, PATTERN RECOGN LETT, V125, P105, DOI 10.1016/j.patrec.2019.04.002
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Gudi A., 2015, 2015 11 IEEE INT C W, V6, P1
   Gupta S, 2022, MULTIMED TOOLS APPL, V81, P14475, DOI 10.1007/s11042-022-12103-y
   Haykin S., 2009, NEURAL NETWORKS LEAR
   Huang YJ, 2021, SIGNAL IMAGE VIDEO P, V15, P1031, DOI 10.1007/s11760-020-01828-8
   Islam J, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCES ON BIG DATA AND CLOUD COMPUTING (BDCLOUD 2016) SOCIAL COMPUTING AND NETWORKING (SOCIALCOM 2016) SUSTAINABLE COMPUTING AND COMMUNICATIONS (SUSTAINCOM 2016) (BDCLOUD-SOCIALCOM-SUSTAINCOM 2016), P124, DOI 10.1109/BDCloud-SocialCom-SustainCom.2016.29
   Jiang P, 2020, IEEE SIGNAL PROC LET, V27, P1954, DOI 10.1109/LSP.2020.3031504
   Jindal S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING (ICIP), P447, DOI 10.1109/INFOP.2015.7489424
   Jokhio F.A., 2019, J INFORM COMMUNICATI, P44
   Kim JH, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062026
   Kumar A, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108255
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Maynard D, 2012, LECT NOTES COMPUT SC, V7117, P88, DOI 10.1007/978-3-642-25953-1_8
   Meena G., 2022, SN COMPUT SCI, V3, P116, DOI [10.1007/s42979-021-00993-y, DOI 10.1007/S42979-021-00993-Y]
   Montoyo A, 2012, DECIS SUPPORT SYST, V53, P675, DOI 10.1016/j.dss.2012.05.022
   Moran J.L., 2019, UC MERCED UNDERGRADU, V11
   Ng A, 2017, DEEP LEARNING SPECIA
   Onita D, 2019, P RECENT ADV NATURAL, P862
   Pandey A., 2020, Recent Advances in Computer Science and Communications, V14, P2785, DOI [DOI 10.2174/2666255813999200721004720, 10.2174/2666255813999200721004720]
   Parimala M, 2021, SOFTWARE PRACT EXPER, V51, P550, DOI 10.1002/spe.2851
   Patel K, 2020, IEEE ACCESS, V8, P90495, DOI 10.1109/ACCESS.2020.2993803
   Qin Z., 2018, ARXIV
   Rashid TA, 2016, INT S INT SYST TECHN, P73, DOI [10.1007/978-3-319-47952-1_6, DOI 10.1007/978-3-319-47952-1]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Renda A, 2019, EXPERT SYST APPL, V136, P1, DOI 10.1016/j.eswa.2019.06.025
   Riaz MN, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041087
   Sadr H., 2021, J AI DATA MINING, V9, P141
   Said Y, 2021, MULTIMED TOOLS APPL, V80, P25241, DOI 10.1007/s11042-021-10918-9
   Salunke Vipul, 2021, Inventive Communication and Computational Technologies. Proceedings of ICICCT 2020. Lecture Notes in Networks and Systems (LNNS 145), P143, DOI 10.1007/978-981-15-7345-3_12
   Song KK, 2018, NEUROCOMPUTING, V312, P218, DOI 10.1016/j.neucom.2018.05.104
   Tai Y, 2021, ARXIV
   Torres A., 2018, In Intelligent Data-Centric Systems, Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications, P61
   Tsytsarau M, 2012, DATA MIN KNOWL DISC, V24, P478, DOI 10.1007/s10618-011-0238-6
   Ul Haq I, 2019, COMPLEXITY, DOI 10.1155/2019/3581419
   Wang Jingwen., 2016, IJCAI, P3484
   Yang JF, 2018, IEEE T MULTIMEDIA, V20, P2513, DOI 10.1109/TMM.2018.2803520
   You QZ, 2015, AAAI CONF ARTIF INTE, P381
   Yu J.X., 2021, IAENG INT J COMPUTER, V48
   Zang HY, 2021, IEEE ACCESS, V9, P64487, DOI 10.1109/ACCESS.2021.3075389
NR 56
TC 15
Z9 15
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 15711
EP 15732
DI 10.1007/s11042-023-16174-3
EA JUL 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001034665300006
DA 2024-07-18
ER

PT J
AU Liu, W
   Lu, XB
   Wei, Y
AF Liu, Wei
   Lu, Xiaobo
   Wei, Yun
TI AMFF-net: adaptive multi-modal feature fusion network for image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; AMFF network; CNN local-global features;
   Traditional global features
AB Convolutional neural networks(CNNs) have been applied to different computer vision tasks such as image classification and recognition, object detection, and segmentation due to the excellent capability of feature extraction and strong generalization ability in recent years. However, CNNs mainly represent the semantic information of images by aggregating local features. It is proved that some global features, such as histograms of oriented gradients, color information, and local binary pattern features, are useful for image recognition. Nonetheless, some researchers simply concatenate these features together, overlooking the differences between features, which leads to the inability to obtain desired performance or even worse results. To better integrate multi-modal features, in this paper a novel feature fusion module is proposed, named AMFF Network, which can adaptively fuse CNNs' local-global features and traditional global features. That's to say, the high-level semantic characteristic of objects and the low-level detailed information and appearance features can be combined dynamically by this network. It is convenient to embed the network in various architectures and can generalize effectively in various datasets. Furtherly, we show that the AMFF module brings obvious performance improvements for current state-of-the-art methods at some additional calculation cost. Experiments performed on multiple benchmark datasets, such as Fashion-MNIST, CIFAR10, CIFAR100, Tiny-Imagenet-200, and Market1501, demonstrate that the proposed AMFF-Net module can bring significant promotion in different datasets for image classification.
C1 [Liu, Wei; Lu, Xiaobo] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
   [Liu, Wei; Lu, Xiaobo] Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Peoples R China.
   [Wei, Yun] Beijing Mass Transit Railway Operat Corp Ltd, Beijing 100044, Peoples R China.
C3 Southeast University - China
RP Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.; Lu, XB (corresponding author), Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Peoples R China.
EM fighting_l_w@163.com; xblu2013@126.com; luckyboy0309@163.com
FU National Key R amp;D Program of China [2020YFB1600700]; Major scientific
   research projects of China Railway Group [K2019G046]
FX AcknowledgementsWe sincerely thank the support of the National Key R &D
   Program of China under Grant 2020YFB1600700 and the Major scientific
   research projects of China Railway Group under Grant K2019G046
CR [Anonymous], 2004, Brain and visual perception: the story of a 25-year collaboration
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding XH, 2021, PROC CVPR IEEE, P10881, DOI 10.1109/CVPR46437.2021.01074
   Ding XH, 2021, PROC CVPR IEEE, P13728, DOI 10.1109/CVPR46437.2021.01352
   Ding XH, 2019, IEEE I CONF COMP VIS, P1911, DOI 10.1109/ICCV.2019.00200
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gowda SN, 2019, LECT NOTES COMPUT SC, V11364, P581, DOI 10.1007/978-3-030-20870-7_36
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang J, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00474
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kwon J, 2021, ARXIV
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Li YH, 2023, IEEE T PATTERN ANAL, V45, P1489, DOI 10.1109/TPAMI.2022.3164083
   Lin Y, 2020, IEEE IND ELEC, P3847, DOI [10.1109/IECON43393.2020.9255104, 10.1109/iecon43393.2020.9255104]
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Margae AK., 2015, INT REV COMPUTERS SO, V10, P52, DOI [10.15866/irecos.v10i1.5051, DOI 10.15866/IRECOS.V10I1.5051]
   NAVON D, 1977, COGNITIVE PSYCHOL, V9, P353, DOI 10.1016/0010-0285(77)90012-3
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Rahman Mohammad Marufur, 2021, SN Comput Sci, V2, P371, DOI 10.1007/s42979-021-00762-x
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Kumar DS, 2020, INT J AMBIENT ENERGY, DOI 10.1080/01430750.2020.1730961
   Shi, 2019, INT C MACH LEARN, P7005
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Nguyen TK, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4, P280, DOI 10.5220/0007389302800291
   Tomasi C, 2022, COMPUTER VISION SAMP, P1
   Wei G, 2022, ARXIV
   Wu J., 2017, Tech. rep.
   Xiang XG, 2007, IEEE IMAGE PROC, P2353
   Xiao H., FASHION MNIST NOVEL
   Zhang T, 2021, IEEE T GEOSCI REMOTE
   Zhang TL, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416550041
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhichao Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12041, DOI 10.1109/CVPR42600.2020.01206
   Zhou T, 2020, IEEE T MED IMAGING, V39, P2772, DOI 10.1109/TMI.2020.2975344
NR 45
TC 0
Z9 0
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17069
EP 17091
DI 10.1007/s11042-023-16217-9
EA JUL 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035582300005
DA 2024-07-18
ER

PT J
AU Basu, S
   Singhal, S
   Singh, D
AF Basu, Shatabdi
   Singhal, Sunita
   Singh, Dilbag
TI A Systematic Literature Review on Multimodal Medical Image Fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Multimodal medical image fusion; Evaluation metrics; Image modality;
   Medical image fusion rules; Systematic literature review
ID CONVOLUTIONAL NEURAL-NETWORK; CENTRAL FORCE OPTIMIZATION; SPARSE
   REPRESENTATION; MAGNETIC-RESONANCE; SHEARLET TRANSFORM;
   SPATIAL-FREQUENCY; WAVELET TRANSFORM; EFFICIENT DWT; DOMAIN; MRI
AB Medical image fusion is a relevant area with widespread application in disease diagnosis and prediction with easily available image scans of Computed Tomography, Positron Emission Tomography, Magnetic Resonance Imaging, and Single Photon Emission Computed Tomography. Each diagnostic image modality has its advantages and limitations. Multimodal Medical Image Fusion aims to combine more than one image of the same or different modality to enhance the image content and provide more information about diseases. We performed a Systematic Literature Review according to the methodology outlined in Kitchenham Charter and based on our search string, we extracted 844 studies from four electronic databases published between 2017 and 2021. Around 175 studies were selected for further in-depth analysis using inclusion and exclusion criteria. We further divide this review article into five sections that (a) Identify the most frequently used input image decomposition methods (b) Describes the most common fusion rules applied on decomposed sub-bands (c) Discusses the optimization algorithms used to improve the efficiency of the fusion scheme (d) Examines the modalities which are subjected to image fusion techniques in the medical domain (e) Identifies the evaluation metrics used to judge the effectiveness of image fusion technique. The result of the comparative study of five sections highlights that the majority of studies use multiscale decomposition methods, and hybrid and neural network-based fusion rules while the CT-MRI combination was mostly used as an input dataset. The review also indicated the prevalent use of particle swarm optimization and non-reference metrics in the majority of studies. Our results suggest that medical image fusion can improve the quality and accuracy of medical images for diagnosis and treatment planning. Further research can be conducted to handle potential research gaps outlined in this review and optimize medical image fusion for clinical applications.
C1 [Basu, Shatabdi; Singhal, Sunita] Manipal Univ Jaipur, Comp Sci & Engn, Ajmer Express Highway, Jaipur 303007, Rajasthan, India.
   [Singh, Dilbag] NYU, Ctr Biomed Imaging, Dept Radiol, Grossman Sch Med, New York, NY USA.
C3 Manipal University Jaipur; New York University
RP Singhal, S (corresponding author), Manipal Univ Jaipur, Comp Sci & Engn, Ajmer Express Highway, Jaipur 303007, Rajasthan, India.
EM shatabdi.bs@gmail.com; sunita.singhal@jaipur.manipal.edu;
   singhd17@nyu.edu
RI Singhal, Sunita/AGJ-5989-2022; Singh, Dilbag/AAQ-6339-2020
OI Singhal, Sunita/0000-0003-2462-8102; Singh, Dilbag/0000-0001-6475-4491
CR Abas AI, 2021, TURK J ELECTR ENG CO, V29, P2780, DOI 10.3906/elk-2105-170
   Aishwarya N, 2018, INT J IMAG SYST TECH, V28, P175, DOI 10.1002/ima.22268
   Akbarpour T, 2019, INT J WAVELETS MULTI, V17, DOI 10.1142/S0219691319500231
   Arif M, 2020, SOFT COMPUT, V24, P1815, DOI 10.1007/s00500-019-04011-5
   Asha CS, 2019, IEEE ACCESS, V7, P40782, DOI 10.1109/ACCESS.2019.2908076
   Azam MA, 2021, CMC-COMPUT MATER CON, V68, P821, DOI 10.32604/cmc.2021.016131
   Bengueddoudj A, 2017, J INNOV OPT HEAL SCI, V10, DOI 10.1142/S1793545817500018
   Benjamin JR, 2018, INT J COMPUT ASS RAD, V13, P229, DOI 10.1007/s11548-017-1692-4
   Bhardwaj J, 2020, MED BIOL ENG COMPUT, V58, P2397, DOI 10.1007/s11517-020-02209-6
   Bhateja V, 2018, REV SCI INSTRUM, V89, DOI 10.1063/1.5016947
   Cai W, 2022, IEEE T GEOSCI REMOTE
   Ch MMI, 2019, SIGNAL IMAGE VIDEO P, V13, P1157, DOI 10.1007/s11760-019-01459-8
   Chai PF, 2017, IEEE ACCESS, V5, P6724, DOI 10.1109/ACCESS.2017.2685178
   Chang LH, 2019, IET IMAGE PROCESS, V13, P83, DOI 10.1049/iet-ipr.2018.5720
   Chao Z, 2018, PHYS MEDICA, V48, P11, DOI 10.1016/j.ejmp.2018.03.008
   Chavan SS, 2017, COMPUT BIOL MED, V81, P64, DOI 10.1016/j.compbiomed.2016.12.006
   Chen CI, 2017, IEEE SENS J, V17, P6995, DOI 10.1109/JSEN.2017.2747220
   Chen JY, 2021, INTERNET THINGS-NETH, V14, DOI 10.1016/j.iot.2020.100172
   Chinnadurai P, 2016, ANN VASC SURG, V30, P138, DOI 10.1016/j.avsg.2015.06.070
   Daniel E, 2018, IEEE SENS J, V18, P6804, DOI 10.1109/JSEN.2018.2822712
   Daniel E, 2017, BIOMED SIGNAL PROCES, V34, P36, DOI 10.1016/j.bspc.2017.01.003
   Das M, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102535
   Das M, 2021, INT J IMAG SYST TECH, V31, P2170, DOI 10.1002/ima.22575
   Das M, 2020, IET IMAGE PROCESS, V14, P4291, DOI 10.1049/iet-ipr.2020.0219
   Devanna H, 2019, CLUSTER COMPUT, V22, P11193, DOI 10.1007/s10586-017-1351-0
   Ding Z, 2020, BIOMED RES INT-UK, V2020
   Ding ZS, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102697
   Dinh PH, 2021, APPL INTELL, V51, P8416, DOI 10.1007/s10489-021-02282-w
   Dinh PH, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2021.114576
   Diwakar M, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102788
   Du J, 2020, INFORM SCIENCES, V525, P93, DOI 10.1016/j.ins.2020.03.051
   Du J, 2020, INT J IMAG SYST TECH, V30, P271, DOI 10.1002/ima.22367
   Du J, 2019, IEEE ACCESS, V7, P56443, DOI 10.1109/ACCESS.2019.2900483
   Du J, 2018, INFORM SCIENCES, V430, P567, DOI 10.1016/j.ins.2017.12.008
   Du J, 2016, NEUROCOMPUTING, V215, P3, DOI 10.1016/j.neucom.2015.07.160
   Duan C, 2019, J VIS COMMUN IMAGE R, V60, P319, DOI 10.1016/j.jvcir.2019.02.027
   Duan JW, 2021, IEEE ACCESS, V9, P96353, DOI 10.1109/ACCESS.2021.3094972
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   El-Hoseny HM, 2019, INFRARED PHYS TECHN, V102, DOI 10.1016/j.infrared.2019.102975
   El-Hoseny HM, 2019, MULTIMED TOOLS APPL, V78, P26373, DOI 10.1007/s11042-019-7552-1
   El-Hoseny HM, 2018, INFRARED PHYS TECHN, V94, P223, DOI 10.1016/j.infrared.2018.09.003
   Faragallah OS, 2021, IEEE ACCESS, V9, P11358, DOI 10.1109/ACCESS.2020.3048315
   Fu J, 2021, INFORM SCIENCES, V576, P484, DOI 10.1016/j.ins.2021.06.083
   Fu J, 2021, OPTIK, V237, DOI 10.1016/j.ijleo.2021.166726
   Fu J, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102488
   Fu J, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.104048
   Gai D, 2019, IEEE ACCESS, V7, P85413, DOI 10.1109/ACCESS.2019.2925424
   Gao Y, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102852
   Geng P, 2017, J MED BIOL ENG, V37, P230, DOI 10.1007/s40846-016-0200-6
   Ghassemian H, 2016, INFORM FUSION, V32, P75, DOI 10.1016/j.inffus.2016.03.003
   Goyal B, 2021, MEASUREMENT, V182, DOI 10.1016/j.measurement.2021.109663
   Goyal S, 2020, SIGNAL IMAGE VIDEO P, V14, P719, DOI 10.1007/s11760-019-01597-z
   Guo K, 2021, BMC MED IMAGING, V21, DOI 10.1186/s12880-021-00642-z
   Guo K, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22121423
   Gupta D, 2018, BIOCYBERN BIOMED ENG, V38, P262, DOI 10.1016/j.bbe.2017.12.005
   He KJ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3066467
   Hermessi H, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108036
   Hermessi H, 2018, NEURAL COMPUT APPL, V30, P2029, DOI 10.1007/s00521-018-3441-1
   Hou RC, 2019, MED BIOL ENG COMPUT, V57, P887, DOI 10.1007/s11517-018-1935-8
   Hu Q, 2021, SOFT COMPUT, V25, P4393, DOI 10.1007/s00500-020-05448-9
   Hu Q, 2020, SIGNAL PROCESS-IMAGE, V83, DOI 10.1016/j.image.2019.115758
   Huang B, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/8279342
   Huang CX, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00210
   Huang J, 2020, IEEE ACCESS, V8, P55145, DOI 10.1109/ACCESS.2020.2982016
   Huang XN, 2021, IEEE ACCESS, V9, P33756, DOI 10.1109/ACCESS.2021.3061078
   Huang YP, 2021, INT J IMAG SYST TECH, V31, P1246, DOI 10.1002/ima.22523
   Jabason E, 2019, IEEE ACCESS, V7, P97865, DOI 10.1109/ACCESS.2019.2930225
   Jiang JH, 2021, INT J IMAG SYST TECH, V31, P2003, DOI 10.1002/ima.22560
   Jiang W, 2018, COMPUT ELECTR ENG, V67, P252, DOI 10.1016/j.compeleceng.2018.03.037
   Jiang YP, 2020, ANN TRANSL MED, V8, DOI 10.21037/atm.2020.04.20
   Jin X, 2020, IEEE T INSTRUM MEAS, V69, P5900, DOI 10.1109/TIM.2019.2962849
   Jin X, 2018, SIGNAL PROCESS, V153, P379, DOI 10.1016/j.sigpro.2018.08.002
   Kang JY, 2020, IEEE ACCESS, V8, P6368, DOI 10.1109/ACCESS.2019.2963741
   Kar MK., 2019, ICIC EXPRESS LETT B, V10, P75
   Kaur M, 2021, J AMB INTEL HUM COMP, V12, P2483, DOI 10.1007/s12652-020-02386-0
   Kavitha S, 2017, SOFT COMPUT, V21, P3307, DOI 10.1007/s00500-015-2009-6
   Khare A, 2021, MULTIMED TOOLS APPL, V80, P11491, DOI 10.1007/s11042-020-10184-1
   Kitchenham B., 2007, GUIDELINES PERFORMIN
   Kong WW, 2021, SIGNAL PROCESS, V181, DOI 10.1016/j.sigpro.2020.107921
   Kong WW, 2019, IEEE T INSTRUM MEAS, V68, P938, DOI 10.1109/TIM.2018.2865046
   Kumar KB, 2021, 2021 INTERNATIONAL CONFERENCE ON SUSTAINABLE ENERGY AND FUTURE ELECTRIC TRANSPORTATION (SEFET), DOI 10.1109/SeFet48154.2021.9375714
   Kumar P, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3985
   Li B, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107793
   Li B, 2021, INT J NEURAL SYST, V31, DOI 10.1142/S0129065720500501
   Li LL, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23050591
   Li QQ, 2021, COMPUT BIOL MED, V131, DOI 10.1016/j.compbiomed.2021.104239
   Li Wei, 2023, Personal and Ubiquitous Computing, P2019, DOI 10.1007/s00779-019-01317-x
   Li W, 2021, INT J IMAG SYST TECH, V31, P204, DOI 10.1002/ima.22476
   Li WS, 2019, IEEE ACCESS, V7, P173019, DOI 10.1109/ACCESS.2019.2953786
   Li WS, 2018, SIGNAL IMAGE VIDEO P, V12, P437, DOI 10.1007/s11760-017-1176-6
   Li WS, 2018, INT J IMAG SYST TECH, V28, P3, DOI 10.1002/ima.22251
   Li XQ, 2019, MED BIOL ENG COMPUT, V57, P2265, DOI 10.1007/s11517-019-02023-9
   Li XS, 2021, INFORM SCIENCES, V569, P302, DOI 10.1016/j.ins.2021.04.052
   Li XH, 2021, J AMB INTEL HUM COMP, V12, P1995, DOI 10.1007/s12652-020-02293-4
   Li Y, 2019, MULTIMED TOOLS APPL, V78, P34459, DOI 10.1007/s11042-019-08027-9
   Liu XB, 2018, MED BIOL ENG COMPUT, V56, P1565, DOI 10.1007/s11517-018-1796-1
   Liu XB, 2018, BIOMED SIGNAL PROCES, V40, P343, DOI 10.1016/j.bspc.2017.10.001
   Liu XB, 2017, NEUROCOMPUTING, V235, P131, DOI 10.1016/j.neucom.2017.01.006
   Liu YY, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.101996
   Liu YY, 2021, INT J IMAG SYST TECH, V31, P391, DOI 10.1002/ima.22460
   Liu Y, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.104050
   Liu Y, 2020, INFORM FUSION, V64, P71, DOI 10.1016/j.inffus.2020.06.013
   Liu Y, 2019, IEEE SIGNAL PROC LET, V26, P485, DOI 10.1109/LSP.2019.2895749
   Liu Z, 2019, COMPUT METH PROG BIO, V175, P73, DOI 10.1016/j.cmpb.2019.04.010
   Lou XC, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/1544955
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Manchanda M, 2018, J VIS COMMUN IMAGE R, V51, P76, DOI 10.1016/j.jvcir.2017.12.011
   Maqsood S, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101810
   Meng LY, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.04.013
   Muzammil SR, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10110904
   Na Y, 2018, IET IMAGE PROCESS, V12, P138, DOI 10.1049/iet-ipr.2016.0920
   Nair RR, 2021, J INTELL FUZZY SYST, V41, P5375, DOI 10.3233/JIFS-189860
   Nair RR, 2021, MULTIMED TOOLS APPL, V80, P19079, DOI 10.1007/s11042-020-10439-x
   Nair RR, 2021, OPTIK, V225, DOI 10.1016/j.ijleo.2020.165742
   Nair RR, 2019, IET IMAGE PROCESS, V13, P1447, DOI 10.1049/iet-ipr.2018.6556
   Nath MK, 2013, INT J IMAG SYST TECH, V23, P327, DOI 10.1002/ima.22067
   Nath MK, 2012, INT J IMAG SYST TECH, V22, P161, DOI 10.1002/ima.22017
   Ouerghi H, 2018, IET IMAGE PROCESS, V12, P1873, DOI 10.1049/iet-ipr.2017.1298
   Padmavathi K, 2020, ENG SCI TECHNOL, V23, P225, DOI 10.1016/j.jestch.2019.03.008
   Palkar B, 2019, IET IMAGE PROCESS, V13, P2271, DOI 10.1049/iet-ipr.2018.5609
   Panigrahy C, 2020, IEEE SIGNAL PROC LET, V27, P690, DOI 10.1109/LSP.2020.2989054
   Paramanandham N, 2018, INFRARED PHYS TECHN, V88, P13, DOI 10.1016/j.infrared.2017.11.006
   Parvathy VS, 2020, HEALTH CARE MANAG SC, V23, P661, DOI 10.1007/s10729-019-09492-2
   Patil HV, 2018, SADHANA-ACAD P ENG S, V43, DOI 10.1007/s12046-018-0796-z
   Pei CY, 2020, IEEE ACCESS, V8, P140216, DOI 10.1109/ACCESS.2020.3013027
   Dinh PH, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102696
   Dinh PH, 2021, BIOMED SIGNAL PROCES, V67, DOI 10.1016/j.bspc.2021.102536
   Polinati S, 2020, MULTIMED TOOLS APPL, V79, P23645, DOI 10.1007/s11042-020-09017-y
   Polinati S, 2020, OPTIK, V205, DOI 10.1016/j.ijleo.2019.163947
   Prakash O, 2019, OPTIK, V182, P995, DOI 10.1016/j.ijleo.2018.12.028
   Qi SH, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102053
   Rajalingam B, 2022, MULTIMEDIA SYST, V28, P1449, DOI 10.1007/s00530-020-00706-0
   Rajalingam B., 2019, Procedia Computer Science, V152, P150, DOI 10.1016/j.procs.2019.05.037
   Ramlal SD, 2019, INT J IMAG SYST TECH, V29, P146, DOI 10.1002/ima.22310
   Ramlal SD, 2018, SIGNAL IMAGE VIDEO P, V12, P1479, DOI 10.1007/s11760-018-1303-z
   Sandhya S, 2019, L N COMPUT VIS BIOME, V31, P61, DOI 10.1007/978-3-030-04061-1_7
   Shahdoosti HR, 2018, MULTIMED TOOLS APPL, V77, P22649, DOI 10.1007/s11042-017-5067-1
   Shandoosti HR, 2018, DIGIT SIGNAL PROCESS, V79, P9, DOI 10.1016/j.dsp.2018.04.002
   Shehanaz S, 2021, OPTIK, V231, DOI 10.1016/j.ijleo.2021.166413
   Shibu DS, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102789
   Singh S., 2020, IEEE T INSTRUM MEAS, V70, P1
   Singh S, 2021, INT J IMAG SYST TECH, V31, P981, DOI 10.1002/ima.22507
   Singh S, 2020, IEEE T INSTRUM MEAS, V69, P3855, DOI 10.1109/TIM.2019.2933341
   Singh S, 2020, IEEE T INSTRUM MEAS, V69, P593, DOI 10.1109/TIM.2019.2902808
   Singh S, 2019, INT J IMAG SYST TECH, V29, P50, DOI 10.1002/ima.22294
   Singh S, 2018, BIOMED SIGNAL PROCES, V46, P281, DOI 10.1016/j.bspc.2018.05.042
   Soundrapandiyan R, 2017, INT J IMAG SYST TECH, V27, P118, DOI 10.1002/ima.22216
   Srivastava A, 2017, ADV INTELL SYST, V469, P577, DOI 10.1007/978-981-10-1678-3_55
   Parvathy VS, 2020, INT J IMAG SYST TECH, V30, P847, DOI 10.1002/ima.22436
   Sufyan A, 2022, INT J IMAG SYST TECH, V32, P324, DOI 10.1002/ima.22649
   Shibu DS, 2021, INT J IMAG SYST TECH, V31, P2249, DOI 10.1002/ima.22592
   Tan L, 2019, COMPUT MATH METHOD M, V2019, DOI 10.1155/2019/3503267
   Tan W, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102280
   Tan W, 2020, NEURAL COMPUT APPL, DOI 10.1007/s00521-020-05173-2
   Tang L, 2018, INT J IMAG SYST TECH, V28, P99, DOI 10.1002/ima.22261
   Tang L, 2017, INT J IMAG SYST TECH, V27, P57, DOI 10.1002/ima.22210
   Tannaz A, 2020, MULTIDIM SYST SIGN P, V31, P269, DOI 10.1007/s11045-019-00662-7
   Tawfik N, 2021, J AMB INTEL HUM COMP, V12, P6001, DOI 10.1007/s12652-020-02154-0
   Tawfik N, 2021, MULTIMED TOOLS APPL, V80, P6369, DOI 10.1007/s11042-020-08834-5
   Tirupal T, 2019, IRAN J FUZZY SYST, V16, P33
   Ullah H, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101724
   Vanitha K, 2021, CURR MED IMAGING, V17, P634, DOI 10.2174/1573405616666201118123220
   Venkatrao PH, 2018, IET IMAGE PROCESS, V12, P572, DOI 10.1049/iet-ipr.2017.0573
   Vishwakarma A, 2018, MULTIMED TOOLS APPL, V77, P32013, DOI 10.1007/s11042-018-6254-4
   Wang GF, 2021, COMPUT BIOL MED, V129, DOI 10.1016/j.compbiomed.2020.104179
   Wang KP, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082169
   Wang LF, 2021, IEEE ACCESS, V9, P67634, DOI 10.1109/ACCESS.2021.3075953
   Wang LF, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420570037
   Wang QX, 2020, J APPL CLIN MED PHYS, V21, P139, DOI 10.1002/acm2.12882
   Wang ZY, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2021.114574
   Wang ZB, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103823
   Xia JM, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/3290136
   Xia KJ, 2019, CLUSTER COMPUT, V22, P1515, DOI 10.1007/s10586-018-2026-1
   Xu H, 2021, INFORM FUSION, V76, P177, DOI 10.1016/j.inffus.2021.06.001
   Xu ZY, 2021, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.615435
   Yadav SP, 2020, MED BIOL ENG COMPUT, V58, P669, DOI 10.1007/s11517-020-02136-6
   Yang Y, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3046911
   Yang Y, 2019, IEEE J BIOMED HEALTH, V23, P1647, DOI 10.1109/JBHI.2018.2869096
   Yang ZG, 2019, IEEE ACCESS, V7, P175947, DOI 10.1109/ACCESS.2019.2955382
   Yin M, 2019, IEEE T INSTRUM MEAS, V68, P49, DOI 10.1109/TIM.2018.2838778
   Yu M, 2021, IET IMAGE PROCESS, V15, P1203, DOI 10.1049/ipr2.12092
   Zhang HN, 2021, MOBILE NETW APPL, V26, P1960, DOI 10.1007/s11036-020-01728-8
   Zhang L, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.103024
   Zhang SQ, 2021, MULTIMED TOOLS APPL, V80, P21135, DOI 10.1007/s11042-021-10596-7
   Zhang XF, 2021, IET IMAGE PROCESS, V15, P1688, DOI 10.1049/ipr2.12137
   Zhang ZC, 2021, MULTIMED TOOLS APPL, V80, P2847, DOI 10.1007/s11042-020-09647-2
   Zhang ZC, 2020, INT J IMAG SYST TECH, V30, P1066, DOI 10.1002/ima.22446
   Zhao F, 2019, IEEE ACCESS, V7, P44002, DOI 10.1109/ACCESS.2019.2908378
   Zhao MJ, 2021, SENS IMAGING, V22, DOI 10.1007/s11220-021-00330-w
   Zhou T, 2021, BIOMED RES INT, V2021, DOI 10.1155/2021/8824395
   Zhu R, 2020, IEEE ACCESS, V8, P91336, DOI 10.1109/ACCESS.2020.2993493
   Zhu ZQ, 2019, IEEE ACCESS, V7, P20811, DOI 10.1109/ACCESS.2019.2898111
   Zhu ZQ, 2018, INFORM SCIENCES, V432, P516, DOI 10.1016/j.ins.2017.09.010
   Zong JJ, 2017, BIOMED SIGNAL PROCES, V34, P195, DOI 10.1016/j.bspc.2017.02.005
NR 194
TC 1
Z9 1
U1 20
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 15845
EP 15913
DI 10.1007/s11042-023-15913-w
EA JUL 2023
PG 69
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001031517600002
DA 2024-07-18
ER

PT J
AU Danaci, KI
   Akagunduz, E
AF Danaci, Kevser Irem
   Akagunduz, Erdem
TI A survey on infrared image & video sets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Infrared image & video sets; Infrared imagery; Survey; Deep learning
   datasets
ID OBJECT DETECTION; TARGET DETECTION; FUSION; PERFORMANCE; SURVEILLANCE;
   DETECTORS; BENCHMARK; IR
AB In this survey, we compile a list of publicly available infrared image and video sets for artificial intelligence and computer vision researchers. We mainly focus on IR image and video sets, which are collected and labelled for computer vision applications such as object detection, object segmentation, classification, and motion detection. We categorise 109 publicly available or private sets according to their sensor types, image resolution, and scale. We describe each set in detail regarding their collection purpose, operation environment, optical system properties, and application area. We also cover a general overview of fundamental concepts related to IR imagery, such as IR radiation, IR detectors, IR optics and application fields. We analyse the statistical significance of the entire corpus from different perspectives. This survey will be a guideline for computer vision and artificial intelligence researchers who want to delve into working with the spectra beyond the visible domain.
C1 [Danaci, Kevser Irem] Sivas Univ Sci & Technol, Dept Elect & Elect Engn, Sivas, Turkiye.
   [Akagunduz, Erdem] Middle East Tech Univ, Grad Sch Informat, Ankara, Turkiye.
C3 Sivas University of Science & Technology; Middle East Technical
   University
RP Danaci, KI (corresponding author), Sivas Univ Sci & Technol, Dept Elect & Elect Engn, Sivas, Turkiye.
EM kiremdanaci@sivas.edu.tr; akaerdem@metu.edu.tr
RI Akagündüz, Erdem/W-1788-2018
OI Akagündüz, Erdem/0000-0002-0792-7306
CR Akula A, 2014, INFRARED PHYS TECHN, V63, P103, DOI 10.1016/j.infrared.2013.12.012
   Alaska Fisheries Science Center, DAT MACH LEARN ALG D
   Aniket A, 2022, BIRD DATASET
   [Anonymous], 2018, MULTIMODAL DATASET H
   [Anonymous], 2020, THERMAL IMAGES DISEA
   Ariffin SMZSZ, 2016, SIG P ALGO ARCH ARR, P191, DOI 10.1109/SPA.2016.7763611
   Asaari MSM, 2014, EXPERT SYST APPL, V41, P3367, DOI 10.1016/j.eswa.2013.11.033
   AV-Public, 2022, ALL THERM DAT
   Bagavathiappan S, 2013, INFRARED PHYS TECHN, V60, P35, DOI 10.1016/j.infrared.2013.03.006
   Bahnsen CH, 2019, IEEE T INTELL TRANSP, V20, P2802, DOI 10.1109/TITS.2018.2872502
   Benes R, 2013, PATTERN RECOGN LETT, V34, P536, DOI 10.1016/j.patrec.2012.11.011
   Berg A., 2015, 2015 12 IEEE INT C A
   Bernardet J., 2015, Bergey's Manual of Systematics of Archaea and Bacteria, DOI DOI 10.1002/9781118960608.OBM00033
   Bertozzi M, 2006, 2006 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P231, DOI 10.1109/IVS.2006.1689633
   Bilodeau GA, 2014, INFRARED PHYS TECHN, V64, P79, DOI 10.1016/j.infrared.2014.02.005
   Bondi E, 2020, IEEE WINT CONF APPL, P1736, DOI [10.1109/WACV45572.2020.9093284, 10.1109/wacv45572.2020.9093284]
   Boreman G D, 1998, BASIC ELECT OPTICS E, V31
   Brown M, 2011, PROC CVPR IEEE, P177, DOI 10.1109/CVPR.2011.5995637
   Chen X, 2005, COMPUT VIS IMAGE UND, V99, P332, DOI 10.1016/j.cviu.2005.03.001
   Chingovska I., 2016, Face Recognition Across the Imaging Spectrum, P165, DOI 10.1007/978-3-319-28501-68
   Clerke A M, 2003, POPULAR HIST ASTRONO
   Computer Vision and Biometrics Lab, 2022, MULT BIOM DAT THERM
   Cosar S, 2018, IEEE ENG MED BIO, P5010, DOI 10.1109/EMBC.2018.8513201
   Cosar S, 2020, J INTELL ROBOT SYST, V98, P85, DOI 10.1007/s10846-019-01026-w
   da Silva ACER, 2020, DATA BRIEF, V30, DOI 10.1016/j.dib.2020.105445
   DAngelo E, 2006, ROBIN CHALLENGE
   Daniels A., 2018, Field Guide to Infrared Systems, Detectors, Vthird
   Davis JW, 2007, COMPUT VIS IMAGE UND, V106, P162, DOI 10.1016/j.cviu.2006.06.010
   Davis JW, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P364
   Dodge S. F., 2017, ARXIV
   Erazo-Aux J, 2020, DATA BRIEF, V32, DOI 10.1016/j.dib.2020.106313
   Faundez-Zanuy M, 2014, COGN COMPUT, V6, P230, DOI 10.1007/s12559-013-9230-3
   Faundez-Zanuy M, 2011, PATTERN RECOGN LETT, V32, P1548, DOI 10.1016/j.patrec.2011.04.022
   FLIR, 2022, Free flir thermal dataset for algorithm training
   Gade Rikke, 2018, IPSJ Transactions on Computer Vision and Applications, V10, DOI 10.1186/s41074-017-0038-z
   Gao CQ, 2016, NEUROCOMPUTING, V212, P36, DOI 10.1016/j.neucom.2016.05.094
   Gebhardt E, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P37
   Ghayoumi zadeh H, 2016, SEGMENTING BREAST CA, DOI [10.17877/DE290R-17666, DOI 10.17877/DE290R-17666]
   Ghayoumi zadeh H., 2017, IRAN J MED PHYS, V14, P114
   Ghiass RS, 2018, QUANT INFRARED THERM, P512, DOI 10.21611/qirt.2018.051
   González A, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060820
   Ha Q, 2017, IEEE INT C INT ROBOT, P5108, DOI 10.1109/IROS.2017.8206396
   HACARUS Inc, 2020, NEAR INFR HYP IM DAT
   HAMAMATSU PHOTONICS K.K., 2011, CHAR US INFR DED
   Hammoud RI., 2021, SYNTHESIS LECT COMPU, V10, P1
   Haque MA, 2018, IEEE INT CONF AUTOMA, P250, DOI 10.1109/FG.2018.00044
   He YJ, 2021, INFRARED PHYS TECHN, V116, DOI 10.1016/j.infrared.2021.103813
   Hou FJ, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su141811161
   Hwang S, 2015, PROC CVPR IEEE, P1037, DOI 10.1109/CVPR.2015.7298706
   Iwashita Y, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P280, DOI 10.1109/MIPR.2019.00057
   Jia XY, 2021, IEEE INT CONF COMP V, P3489, DOI 10.1109/ICCVW54120.2021.00389
   Karasawa T, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P35, DOI 10.1145/3126686.3126727
   Karim A, 2013, IOP CONF SER-MAT SCI, V51, DOI 10.1088/1757-899X/51/1/012001
   Kong SG, 2007, INT J COMPUT VISION, V71, P215, DOI 10.1007/s11263-006-6655-0
   Korki14, 2022, KORKI14
   Kristan M, 2016, IEEE T PATTERN ANAL, V38, P2137, DOI 10.1109/TPAMI.2016.2516982
   Kristo M, 2020, IEEE ACCESS, V8, P125459, DOI 10.1109/ACCESS.2020.3007481
   KRUSE PW, 1995, INFRARED PHYS TECHN, V36, P869, DOI 10.1016/1350-4495(95)00014-P
   Kumar Ajay, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563110
   Lee A J, 2019, VIVID VISION VISIBIL
   Li SZ, 2007, IEEE T PATTERN ANAL, V29, P627, DOI 10.1109/TPAMI.2007.1014
   Liu H, 2019, INFRARED PHYS TECHN, V96, P390, DOI 10.1016/j.infrared.2018.08.028
   Liu Q, 2018, ADV NEUR IN, V31
   Liu Q, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3847, DOI 10.1145/3394171.3413922
   Lord S. D., 1992, NASA Technical Memorandum 103957
   Mantecón T, 2016, LECT NOTES COMPUT SC, V10016, P47, DOI 10.1007/978-3-319-48680-2_5
   Miezianko R, 2022, TERRAVIC RES INFRARE
   Miron A, 2014, MULTI MODAL MULTIDOM
   Morris N, 2007, STAT INFRARED IMAGES, P1, DOI [10.1109/CVPR.2007.383003, DOI 10.1109/CVPR.2007.383003]
   MOSS TS, 1976, INFRARED PHYS, V16, P29, DOI 10.1016/0020-0891(76)90006-3
   Nelson J, 2020, THERMAL DOGS PEOPLE
   Olmeda D, 2013, INTEGR COMPUT-AID E, V20, P347, DOI 10.3233/ICA-130441
   Palmero C, 2016, INT J COMPUT VISION, V118, P217, DOI 10.1007/s11263-016-0901-x
   Panetta K, 2020, IEEE T PATTERN ANAL, V42, P509, DOI 10.1109/TPAMI.2018.2884458
   Parr A C, 2005, OPTICAL RADIOMETRY, V41
   Patino L, 2016, IEEE COMPUT SOC CONF, P1240, DOI 10.1109/CVPRW.2016.157
   Perpetuini D, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18063286
   Piñeiro-Ave J, 2014, INFRARED PHYS TECHN, V63, P222, DOI 10.1016/j.infrared.2014.01.007
   PINI S, 2020, P INT JOINT C BIOM I
   Portmann J, 2014, IEEE INT CONF ROBOT, P1794, DOI 10.1109/ICRA.2014.6907094
   Pramerdorfer C, 2020, IEEE IMAGE PROC, P1611, DOI 10.1109/ICIP40778.2020.9191284
   Prasad DK, 2017, IEEE T INTELL TRANSP, V18, P1993, DOI 10.1109/TITS.2016.2634580
   Projects R U, 2022, PEOPL DET THERM DAT
   Rivadeneira RE, 2020, VISAPP: PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4: VISAPP, P111, DOI 10.5220/0009173601110119
   Rivadeneira RE, 2019, LECT NOTES COMPUT SC, V11663, P417, DOI 10.1007/978-3-030-27272-2_37
   Roboflow, 2020, THERM CHEET OBJ DET
   Rogalski A, 1997, P SOC PHOTO-OPT INS, V3182, P14, DOI 10.1117/12.280417
   Rogalski A, 2002, INFRARED PHYS TECHN, V43, P187, DOI 10.1016/S1350-4495(02)00140-8
   Schneider P, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22113992
   Sedik, 2020, MBD MULTIBIOMETRIC D, DOI [10.17632/94ksjgbwnz.1, DOI 10.17632/94KSJGBWNZ.1]
   SENSIAC, 2008, MIL SENS INF AN CTR
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shamsoshoara A, 2021, COMPUT NETW, V193, DOI 10.1016/j.comnet.2021.108001
   Socarras Y, 2013, ADAPTING PEDESTRIAN
   Soundrapandiyan R, 2022, MULTIMED TOOLS APPL, V81, P9045, DOI 10.1007/s11042-021-11250-y
   Sousa E, 2017, INFRARED PHYS TECHN, V85, P315, DOI 10.1016/j.infrared.2017.07.020
   Speth J, 2021, DECEPTION DETECTION
   Strat T, 2005, VIVID TRACKING EVALU
   Sun X., 2021, A Dataset for Small Infrared Moving Target Detection Under Clutter Background DB/OL
   Toet A, 1997, DISPLAYS, V18, P85, DOI 10.1016/S0141-9382(97)00014-0
   Toet A, 2002, PROC SPIE, V4718, P118, DOI 10.1117/12.478798
   Toet A, 2016, TRICLOBS DYNAMIC MUL
   Treible W, 2017, PROC CVPR IEEE, P134, DOI 10.1109/CVPR.2017.22
   Trist Eric., 1997, SOCIAL ENGAGEMENT SO, P1
   Tu Z., 2020, ARXIV
   Ul Huda N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071982
   UMDAMAV-Dataset, 2022, THERMAL OVERHEAD DAT
   Venkataraman B, 2003, INSIGHT, V45, P531, DOI 10.1784/insi.45.8.531.52914
   Visual Lab, 2022, THERM IM BREAST CANC
   Vollmer M., 2018, Infrared Thermal Imaging. Fundamentals, Research and Applications, VSecond
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Westlake ST, 2020, PROC SPIE, V11543, DOI 10.1117/12.2573774
   Wu Z, 2014, IEEE COMPUT SOC CONF, P201, DOI 10.1109/CVPRW.2014.39
   Xu ZW, 2019, INFRARED PHYS TECHN, V96, P199, DOI 10.1016/j.infrared.2018.11.007
   Yaman M, 2015, J VIS COMMUN IMAGE R, V26, P115, DOI 10.1016/j.jvcir.2014.11.010
   Yoon JS, 2016, IEEE INT VEH SYM, P978, DOI 10.1109/IVS.2016.7535507
   Zhang HZ, 2018, MULTIMED TOOLS APPL, V77, P26657, DOI 10.1007/s11042-018-5883-y
   Zhang L, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2490823
   Zhang Mabel M., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P10, DOI 10.1109/CVPRW.2015.7301291
   Zukal M, 2013, RADIOENGINEERING, V22, P68
NR 120
TC 3
Z9 3
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16485
EP 16523
DI 10.1007/s11042-023-15327-8
EA JUL 2023
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001029126000014
DA 2024-07-18
ER

PT J
AU Zhang, D
   Liu, N
   Wu, ZK
   Wang, XC
AF Zhang, Dan
   Liu, Na
   Wu, Zhongke
   Wang, Xingce
TI 3D craniofacial similarity calculation and craniofacial relationships
   analysis based on spectral analysis method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Two-view geometry; Correspondence matching; RANSAC; GPU calculation;
   Gradient difference
ID SOFT-TISSUE DEPTHS; SKULL; RECONSTRUCTION; SUPERIMPOSITION;
   IDENTIFICATION; SHAPE; MODEL
AB The field of 3D craniofacial similarity calculation and craniofacial relationships(the relationships between the human skull and face) analysis is a challenging and meaningful task in archaeology, forensic science, and anthropology. Although anthropologists have been involved in the application and illustration of craniofacial relationships in their research, due to the complexity of the 3D skull (with multiple holes), and the facial expression changes of 3D human faces, it is difficult to accurately perform 3D craniofacial similarity calculations and theoretical validation of craniofacial relationships are difficult. To address this challenge, we propose a data-driven framework that constructs a shape feature space based on spectral analysis to describe the intrinsic structure of 3D skulls and faces. Our framework includes a shape analysis method to measure 3D craniofacial similarity and a statistical method using canonical correlation analysis to comprehensively describe the craniofacial relationships from global statistical features and individual geometric features. Based on an Asian craniofacial database, we demonstrate the effectiveness of our framework through validation results and skull identification. Most importantly, we provide two craniofacial relationships rules through theoretical validation and numerical results: R1-the human skull has a strong correlation with the face; R2-the similarity change trend of the skull is generally consistent with the corresponding face similarity. These craniofacial relationships rules can be applied to general craniofacial analysis tasks and scenarios, providing a solid theoretical basis for relevant researchers. Our research represents a significant contribution to the field of 3D craniofacial similarity calculation and craniofacial relationships analysis.
C1 [Zhang, Dan; Liu, Na; Wu, Zhongke; Wang, Xingce] Beijing Normal Univ, Sch Artificial Intelligence, Beijing 100875, Peoples R China.
   [Zhang, Dan] Qinghai Normal Univ, Sch Comp Sci, Xining 81017, Peoples R China.
   [Zhang, Dan] State Key lab Tibetan Intelligent Informat Proc &, Xining 81017, Peoples R China.
C3 Beijing Normal University; Qinghai Normal University
RP Zhang, D; Wang, XC (corresponding author), Beijing Normal Univ, Sch Artificial Intelligence, Beijing 100875, Peoples R China.; Zhang, D (corresponding author), Qinghai Normal Univ, Sch Comp Sci, Xining 81017, Peoples R China.; Zhang, D (corresponding author), State Key lab Tibetan Intelligent Informat Proc &, Xining 81017, Peoples R China.
EM danz@mail.bnu.edu.cn; lna@mail.bnu.edu.cn; zwu@bnu.edu.cn;
   wangxingce@bnu.edu.cn
RI Han, Yang/JVN-5921-2024; JIANG, Peng/KGL-3427-2024; li,
   jixiang/JXN-7599-2024; yang, zhou/KBB-6972-2024; chen,
   bin/KBQ-8114-2024; Zhang, Dan/AFA-2608-2022
OI chen, bin/0000-0002-3398-1314; Zhang, Dan/0000-0002-7295-4837; Dan,
   Zhang/0000-0001-5676-0656
FU Natural Science Youth Foundation of Qinghai Province [kjqn 2021004];
   National Natural Science Foundation of China [62102213]; Independent
   project fund of the state key lab of the Tibetan Intelligent Information
   Processing and Application (Co-established by the province and the
   ministry); Young and middle-aged scientific research fund of Qinghai
   Normal University;  [2023-ZJ-947Q];  [2022-SKL-014]
FX & nbsp;The authors would like to thank the Natural Science Youth
   Foundation of Qinghai Province(No.2023-ZJ-947Q); National Natural
   Science Foundation of China (Grant Nos. 62102213); Independent project
   fund of the state key lab of the Tibetan Intelligent Information
   Processing and Application (Co-established by the province and the
   ministry)(Grant Nos.2022-SKL-014); Young and middle-aged scientific
   research fund of Qinghai Normal University (Grant Nos.kjqn 2021004). The
   authors would also like to thank the database provider the Institute of
   Virtual Reality and Visualization Technology, Beijing Normal University.
CR Ahlgren P, 2003, J AM SOC INF SCI TEC, V54, P550, DOI 10.1002/asi.10242
   Alomar A, 2022, COMPUT METH PROG BIO, V221, DOI 10.1016/j.cmpb.2022.106893
   Aronov B, 2006, LECT NOTES COMPUT SC, V4168, P52
   Berar M, 2005, ISPA 2005: PROCEEDINGS OF THE 4TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P365, DOI 10.1109/ISPA.2005.195439
   Berar M, 2011, FORENSIC SCI INT, V210, P228, DOI 10.1016/j.forsciint.2011.03.010
   Borrelli MR, 2020, J CRANIOFAC SURG, V31, P15, DOI 10.1097/SCS.0000000000005840
   Campomanes-Alvarez C, 2018, IEEE T INF FOREN SEC, V13, P1481, DOI 10.1109/TIFS.2018.2791434
   Claes P., 2006, Journal of Computing and Information Technology - CIT, V14, P21, DOI 10.2498/cit.2006.01.03
   Claes P, 2006, FORENSIC SCI INT, V159, pS147, DOI 10.1016/j.forsciint.2006.02.035
   Damas Sergio, 2020, HDB CRANIOFACIAL SUP, P11, DOI DOI 10.1007/978-3-319-11137-7_3
   Deng QQ, 2016, FORENSIC SCI INT, V259, P19, DOI 10.1016/j.forsciint.2015.10.033
   Duan FQ, 2014, IEEE T INF FOREN SEC, V9, P1322, DOI 10.1109/TIFS.2014.2332981
   Ernst F., 2014, British Journal of Medicine and Medical Research, V4, P937
   Farrera A, 2016, FORENSIC SCI INT, V262, DOI 10.1016/j.forsciint.2016.02.046
   Fenton TW, 2008, J FORENSIC SCI, V53, P34, DOI 10.1111/j.1556-4029.2007.00624.x
   Guyomarc'h P, 2013, FORENSIC SCI INT, V231, DOI 10.1016/j.forsciint.2013.04.007
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hierl T, 2021, J ORAL MAXIL SURG, V79, DOI 10.1016/j.joms.2020.08.034
   Hu YL, 2013, MULTIMED TOOLS APPL, V64, P345, DOI 10.1007/s11042-012-1005-4
   Huete MI, 2015, LEGAL MED-TOKYO, V17, P267, DOI 10.1016/j.legalmed.2015.02.001
   Jeelani W, 2015, J FORENSIC SCI, V60, P1420, DOI 10.1111/1556-4029.12851
   Ling H., 2006, CVPR, V1, P246, DOI DOI 10.1109/CVPR.2006.99
   Mal PavlaZednkov, 2018, FORENSIC SCI INT, V292
   Mansour RF, 2020, MULTIMED TOOLS APPL, V79, P22065, DOI 10.1007/s11042-017-5015-0
   Marecková K, 2013, NEUROIMAGE, V79, P234, DOI 10.1016/j.neuroimage.2013.04.110
   Meikle B, 2020, J FORENSIC SCI, V65, P939, DOI 10.1111/1556-4029.14230
   Memoli Facundo, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P256, DOI 10.1109/ICCVW.2009.5457690
   Munn L, 2018, FORENSIC SCI INT, V289, P40, DOI 10.1016/j.forsciint.2018.05.016
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Paysan P, 2009, LECT NOTES COMPUT SC, V5748, P232, DOI 10.1007/978-3-642-03798-6_24
   Pei Y, 2008, COMPUT GRAPH FORUM, V27, P1711, DOI 10.1111/j.1467-8659.2008.01315.x
   Reuter M, 2009, COMPUT AIDED DESIGN, V41, P739, DOI 10.1016/j.cad.2009.02.007
   Rustamov Raif M, 2007, P S GEOM PROC, V257, P225
   Rynn C., 2012, RELATIONSHIPS SKULL
   Saadeh M, 2020, FORENSIC SCI INT, V317, DOI 10.1016/j.forsciint.2020.110468
   Shui WY, 2020, MULTIMED TOOLS APPL, V79, P25589, DOI 10.1007/s11042-020-09189-7
   Shui WY, 2017, COMPUT BIOL MED, V90, P33, DOI 10.1016/j.compbiomed.2017.08.023
   Simmons-Ehrhardt T, 2021, ADV EXP MED BIOL, V1317, P53, DOI 10.1007/978-3-030-61125-5_4
   Steiert C, 2022, NEUROSURG REV, V45, P2745, DOI 10.1007/s10143-022-01784-6
   Stephan CN, 2019, FORENSIC SCI INT, V304, DOI 10.1016/j.forsciint.2019.109965
   Stephan CN, 2008, J FORENSIC SCI, V53, P1257, DOI 10.1111/j.1556-4029.2008.00852.x
   Stephan CN, 2014, J FORENSIC SCI, V59, P454, DOI 10.1111/1556-4029.12328
   Stephan CN, 2001, J FORENSIC SCI, V46, P432
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Tan JS, 2020, VISUAL COMPUT, V36, P1739, DOI 10.1007/s00371-019-01767-7
   Nguyen TN, 2020, MED BIOL ENG COMPUT, V58, P2355, DOI 10.1007/s11517-020-02219-4
   techniques of facial approximation and craniofacial superimposition, 2009, HDB FORENSIC ANTHR A, V25, P304
   Tilotta FM, 2010, FORENSIC SCI INT, V200, P50, DOI 10.1016/j.forsciint.2010.03.029
   Vuollo V, 2016, STAT MED, V35, P4891, DOI 10.1002/sim.7032
   Wang SF, 2015, COMPUT AIDED GEOM D, V35-36, P206, DOI 10.1016/j.cagd.2015.03.003
   Wilkinson CM, 2003, J FORENSIC SCI, V48, P728
   Zhang NAK, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, DOI 10.1145/3503161.3548254
NR 52
TC 0
Z9 0
U1 5
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14063
EP 14084
DI 10.1007/s11042-023-16048-8
EA JUL 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001028770200013
DA 2024-07-18
ER

PT J
AU Zhang, M
   Meng, D
   Pei, YT
   Wen, JH
AF Zhang, Mei
   Meng, Dan
   Pei, Yongtao
   Wen, Jinghua
TI Research on image segmentation method based on improved Snake model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Snake model; Smooth noise reduction; Gaussian filter; Bilateral filter;
   Edge profile extraction; Image segmentation
AB Image segmentation is one of the key research fields in computer vision, and the research of image segmentation methods based on active contour model has been continuously advanced in recent years. Aiming at the defect problem such as traditional Snake model algorithm is more sensitive to the noise of the original target image, it is proposed that an improved segmentation algorithm based on bilateral filter to replace the original Gaussian filter of the traditional Snake model, to reduce the noise of the original target image, by weighing the spatial domain weights and domain weights of the pixel points, so as to achieve the purpose of edge denising, so that the original target image edge contour can be further optimized and extracted; By using the snake model before and after improvement, we performed a qualitative and comparative analysis for the extraction effects on edge contour of the same original target image object, and it was verified that the improved snake model proposed here is more accurate and effective. The accuracy and effectiveness of the improved model here are objectively and quantitatively verified, according to the number of sampling points extracted, peak of noise-signal ratio(SNR) of the result map extracted and image quality of original target image object edge profile.
C1 [Zhang, Mei; Meng, Dan; Pei, Yongtao; Wen, Jinghua] Guizhou Univ Financial & Econ, Informat Inst, Guiyang 550025, Peoples R China.
   [Zhang, Mei] Guizhou Key Lab Big Data Stat Anal 2019 5103, Guiyang 550025, Peoples R China.
RP Zhang, M (corresponding author), Guizhou Univ Financial & Econ, Informat Inst, Guiyang 550025, Peoples R China.; Zhang, M (corresponding author), Guizhou Key Lab Big Data Stat Anal 2019 5103, Guiyang 550025, Peoples R China.
EM zm_gy@sina.com
FU department of science and technology of Guizhou province; Science and
   Technology Program of the Guizhou Provincial Science and Technology
   Agency; Guizhou Key Laboratory of Big Data Statistical Analysis
   [[2020]1Y156];  [[2019]5103];  [ZK [2023] general 031]
FX The authors would like to thank the basic research program (natural
   science) project supported by department of science and technology of
   Guizhou province (Contract no: QianKeHe foundation-ZK [2023] general
   031).The authors would like to thank the project supported by Science
   and Technology Program of the Guizhou Provincial Science and Technology
   Agency (Contract number:QianKeHeBasic[2020]1Y156). The authors would
   like to thank Guizhou Key Laboratory of Big Data Statistical Analysis(
   No.[2019]5103),.The funders had active role in study design, data
   collection and analysis, decision to publish, and preparation of the
   manuscript.
CR Chaddad A, 2015, HEALTH TECHNOL-GER, V5, P179, DOI 10.1007/s12553-015-0115-1
   Chang JX, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13122406
   Chao M, 2019, RES 3 DIMENSIONAL SE, DOI [10.27061/d.cnki.ghgdu.2019.000076, DOI 10.27061/D.CNKI.GHGDU.2019.000076]
   Cui Jinge, 2018, Computer Engineering and Applications, V54, P223, DOI 10.3778/j.issn.1002-8331.1706-0062
   [高乃珺 Gao Naijun], 2019, [光学技术, Optical Technology], V45, P336
   Ghaffarian S, 2019, INT J REMOTE SENS, V40, P1217, DOI 10.1080/01431161.2018.1524178
   Guo LH, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108013
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Khalifa AF, 2023, CMC-COMPUT MATER CON, V75, P1995, DOI 10.32604/cmc.2023.035888
   Lechuan H, 2020, RES BUILDING EXTRACT, DOI [10.27061/d.cnki.ghgdu.2020.001744, DOI 10.27061/D.CNKI.GHGDU.2020.001744]
   Leite M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122312140
   Mengjia X, 2021, OPTIMIZATION IMAGE R, DOI [10.27389/d.cnki.gxadu.2021.001708, DOI 10.27389/D.CNKI.GXADU.2021.001708]
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Qing C, 2019, RES IMAGE SEGMENTATI, DOI [10.27406/d.cnki.gxbgu.2019.000017, DOI 10.27406/D.CNKI.GXBGU.2019.000017]
   Rajendran A, 2011, DIGITAL IMAGE PROCES, V3, P1076
   Reynolds S, 2017, ENEURO, V4, DOI 10.1523/ENEURO.0012-17.2017
   Shanila N., 2022, International Journal of Biomedical Engineering and Technology, P283, DOI 10.1504/IJBET.2022.124188
   Nguyen TH, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12111702
   Tong Y., 2020, COMPUT APPL SOFTW, V37, P226, DOI [10.3969/j.issn.1000-386x.2020.05.039, DOI 10.3969/J.ISSN.1000-386X.2020.05.039]
   Wang X-Y., 2021, COMPUT SIMUL, V38, P132
   Wang YS, 2021, OPTIK, V241, DOI 10.1016/j.ijleo.2021.167175
   Xiaoqian Y., 2020, COMPUT APP RES, V37, P385
   Xing Wei., 2016, COMPUT ENG DES, V37, P3327, DOI [10.16208/j.issn1000-7024.2016.12.036, DOI 10.16208/J.ISSN1000-7024.2016.12.036]
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   [周航 Zhou Hang], 2017, [北京交通大学学报. 自然科学版, Journal of Beijing Jiaotong University], V41, P43
   Zia H, 2022, 2022 AS C ADV ROB AU, DOI [10.1109/ARACE56528.2022, DOI 10.1109/ARACE56528.2022]
NR 26
TC 0
Z9 0
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13977
EP 13994
DI 10.1007/s11042-023-15822-y
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001028770200015
DA 2024-07-18
ER

PT J
AU Nguyen, M
   Amirpour, H
   Tashtarian, F
   Timmerer, C
   Hellwagner, H
AF Nguyen, Minh
   Amirpour, Hadi
   Tashtarian, Farzad
   Timmerer, Christian
   Hellwagner, Hermann
TI Performance analysis of H2BR: HTTP/2-based segment upgrading to improve
   the QoE in HAS
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HTTP adaptive streaming; DASH; Retransmission; QoE; HTTP; 2; H2BR
ID RATE ADAPTATION; VIDEO; HEVC
AB HTTP Adaptive Streaming (HAS) plays a key role in over-the-top video streaming with the ability to reduce the video stall duration by adapting the quality of transmitted video segments to the network conditions. However, HAS still suffers from two problems. First, it incurs variations in video quality because of throughput fluctuation. Adaptive bitrate (ABR) algorithms at the HAS client usually select a low-quality segment when the throughput drops to avoid stall events, which impairs the Quality of Experience (QoE) of the end-users. Second, many ABR algorithms choose the lowest-quality segments at the beginning of a video streaming session to ramp up the playout buffer early on. Although this strategy decreases the startup time, clients can be annoyed as they have to watch a low-quality video initially. To address these issues, we introduced the H2BR technique (H TTP/2-B ased R etransmission) (Nguyen et al. 33) that utilizes certain features of HTTP/2 (including server push, multiplexing, stream priority, and stream termination) for late transmissions of higher-quality versions of video segments already in the client buffer, in order to improve video quality. Although H2BR was shown to enhance the QoE, limited streaming scenarios were considered resulting in a lack of general conclusions on H2BR's performance. Thus, this article provides a profound evaluation to answer three open questions: (i) how H2BR's performance is impacted by parameters at the server side (i.e., various encoding specifications), at the network side (i.e., packet loss rate), and at the client side (i.e., buffer size) on the performance of H2BR; (ii) how H2BR outperforms other state-of-the-art approaches in different configurations of the parameters above; (iii) how to effectively utilize H2BR on top of ABR algorithms in various streaming scenarios. The experimental results show that H2BR's performance increases with the buffer size and decreases with increasing packet loss rates and/or video segment duration. The number of quality levels can negatively or positively impact on H2BR's performance, depending on the ABR algorithm deployed. In general, H2BR is able to enhance the video quality by up to 17% and 14% in scalable video streaming and in non-scalable video streaming, respectively. Compared with an existing retransmission technique (i.e., SQUAD Wang et al., ACM Trans Multimed Comput Commun Applic (TOMM) 13(3s): 45, 49), H2BR shows better results with more than 10% in QoE and 9% in the average video quality.
C1 [Nguyen, Minh; Amirpour, Hadi; Tashtarian, Farzad; Timmerer, Christian; Hellwagner, Hermann] Alpen Adria Univ Klagenfurt, Christian Doppler Lab ATHENA, Univ Str 65-67, A-9020 Klagenfurt, Austria.
C3 University of Klagenfurt
RP Nguyen, M (corresponding author), Alpen Adria Univ Klagenfurt, Christian Doppler Lab ATHENA, Univ Str 65-67, A-9020 Klagenfurt, Austria.
EM minh.nguyen@aau.at
OI Amirpour, Hadi/0000-0001-9853-1720; Nguyen, Minh/0000-0002-9691-1719
FU Austrian Federal Ministry for Digital and Economic Affairs; National
   Foundation for Research, Technology, and Development; Christian Doppler
   Research Association
FX The financial support of the Austrian Federal Ministry for Digital and
   Economic Affairs, the National Foundation for Research, Technology, and
   Development, and the Christian Doppler Research Association is
   gratefully acknowledged. Christian Doppler Laboratory ATHENA:
   https://athena.itec.aau.at/.
CR [Anonymous], P1203 ITUT REC, DOI 11.1002/ps/P1203-01
   Apple, 2020, HLS AUTH SPEC APPL D
   Batalla JM, 2016, IEEE J SEL AREA COMM, V34, P2154, DOI 10.1109/JSAC.2016.2577360
   Belda R, 2020, MULTIMED TOOLS APPL, V79, P25143, DOI 10.1007/s11042-020-09214-9
   Belshe M., 2015, Tech. rep., DOI DOI 10.17487/RFC7540
   Ben Yahia M, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3280854
   Bentaleb A, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3387921
   Bentaleb A, 2019, IEEE COMMUN SURV TUT, V21, P562, DOI 10.1109/COMST.2018.2862938
   Bhat D, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1616, DOI 10.1145/3240508.3240664
   Bitmovin Inc, 2020, 2020 VID DEV REP
   Bouten N, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P1399
   Cranley N, 2006, INT J HUM-COMPUT ST, V64, P637, DOI 10.1016/j.ijhcs.2005.12.002
   Dai H., 2011, Acta Horticulturae, P169, DOI 10.1145/1943552.1943575
   developer, AT T DEV ADAPTIVE BI
   Dobrian F, 2011, ACM SIGCOMM COMP COM, V41, P362, DOI 10.1145/2043164.2018478
   Nguyen DN, 2019, INT SYMP WIREL, DOI [10.1109/CLEOE-EQEC.2019.8872848, 10.1109/wpmc48795.2019.9096169]
   Elgabli A, 2018, IEEE ACM T NETWORK, V26, P1633, DOI 10.1109/TNET.2018.2844123
   Grafl M., 2013, Proc. IEEE World of Wireless, P1
   Hossfeld Tobias, 2014, 2014 Sixth International Workshop on Quality of Multimedia Experience (QoMEX), P111, DOI 10.1109/QoMEX.2014.6982305
   Huang TY, 2014, SIGCOMM'14: PROCEEDINGS OF THE 2014 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P187, DOI 10.1145/2619239.2626296
   Juluri P, 2015, IEEE INT CONF COMM, P1765, DOI 10.1109/ICCW.2015.7247436
   Kalva H, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P158, DOI 10.1109/ICCE.2012.6161787
   Le HT, 2018, IEEE T CIRC SYST VID, V28, P2423, DOI 10.1109/TCSVT.2018.2850740
   Le HT, 2013, PROC INT CONF ADV, P33, DOI 10.1109/ATC.2013.6698072
   Li Z., Toward a practical perceptual video quality metric
   Li Z, 2014, IEEE J SEL AREA COMM, V32, P719, DOI 10.1109/JSAC.2014.140405
   Liu CH, 2012, SIGNAL PROCESS-IMAGE, V27, P288, DOI 10.1016/j.image.2011.10.001
   Miller K, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2990505
   Nguyen M, 2017, 2017 4TH NAFOSTED CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS), P302, DOI 10.1109/NAFOSTED.2017.8108082
   Nguyen MT, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534328
   Muller Cornelius, 2013, 2013 IEEE Symposium on Large-Scale Data Analysis and Visualization (LDAV), P1, DOI 10.1109/LDAV.2013.6675152
   Nguyen DH, 2018, 2018 IEEE SEVENTH INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND ELECTRONICS (IEEE ICCE 2018), P261, DOI 10.1109/CCE.2018.8465722
   Nguyen DV, 2016, IEICE COMMUN EXPRESS, V5, P69, DOI 10.1587/comex.2015XBL0177
   Nguyen M, 2020, P 25 PACKET VIDEO WO, P1, DOI [10.1145/3386292.3397117, DOI 10.1145/3386292.3397117]
   Nguyen M, 2020, P WORKSH EV PERF INT, P28, DOI [10.1145/3405796.3405829, DOI 10.1145/3405796.3405829]
   Oelbaum T, 2008, IEEE IMAGE PROC, P2772, DOI 10.1109/ICIP.2008.4712369
   Ogasawara T, 2019, CONSUM COMM NETWORK, DOI 10.1109/ccnc.2019.8651792
   Petrangeli S, 2015, IEEE INT CONF MULTI
   Raake A., 2017, 2017 9 INT C QUALITY, P1, DOI DOI 10.1109/QOMEX.2017.7965631
   Rainer B, 2012, EUR SIGNAL PR CONF, P1519
   Rizzo L., 1997, Computer Communication Review, V27, P31, DOI 10.1145/251007.251012
   Robitza W, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P466, DOI 10.1145/3204949.3208124
   Rusan A, 2015, INT C INTELL COMP CO, P529, DOI 10.1109/ICCP.2015.7312715
   Ryu ES, 2017, MULTIMED TOOLS APPL, V76, P25511, DOI 10.1007/s11042-017-4835-2
   Scharf M., 2006, IEEE GLOBECOM 2006, P1, DOI DOI 10.1109/GLOCOM.2006.333
   Sieber C, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P1318
   Spiteri K, 2016, IEEE INFOCOM SER, DOI 10.1109/infocom.2016.7524428
   Thang TC, 2014, IEEE J SEL AREA COMM, V32, P693, DOI 10.1109/JSAC.2014.140403
   van der Hooft J, 2016, IEEE COMMUN LETT, V20, P2177, DOI 10.1109/LCOMM.2016.2601087
   Wang C, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3092839
   Wei Sheng., 2014, NETWORK OPERATING SY, P37
   Wisniewski P, 2015, IEEE ICC, P6867, DOI 10.1109/ICC.2015.7249420
   Yadav PK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1130, DOI 10.1145/3123266.3123390
   Ye Y, 2014, IEEE MULTIMEDIA, V21, P58, DOI 10.1109/MMUL.2014.47
   Zabrovskiy A, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P438, DOI 10.1145/3204949.3208140
   Zhang T, 2015, MOBICOM '15: PROCEEDINGS OF THE 21ST ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P426, DOI 10.1145/2789168.2790123
   Zhou C, 2014, IEEE T CIRC SYST VID, V24, P681, DOI 10.1109/TCSVT.2013.2290580
NR 57
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12561
EP 12595
DI 10.1007/s11042-023-15516-5
EA JUL 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001027813700006
OA hybrid
DA 2024-07-18
ER

PT J
AU Karthikeyan, P
   Chang, CC
   Hsiung, PA
AF Karthikeyan, P.
   Chang, Chih Chun
   Hsiung, Pao-Ann
TI Labor exploitation investigation using statistical and multiple object
   tracking assessment methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple Object Tracking (MOT); Distant Water Fishing(DWF); YOLOv7;
   Object detection; Mobile Application
AB Labor exploitation in Taiwan's Distant Water Fishing (DWF) industry has been a significant issue for many years. Migrant fishermen from Southeast Asian countries, including Indonesia and the Philippines, have reported being subjected to poor working conditions, long work hours, and low pay. Our research aims to identify and address labor exploitation in Taiwan's DWF vessels through the development of a three-module system. The first module is a mobile application interface used to collect data from fishermen and captains. The second module is responsible for collecting data from an offline SQLite database and Closed-circuit television (CCTV) footage from DWF vessels. The third module employs fisherman detection and tracking models to analyze working hours. We have developed two models to analyze labor exploitation in DWF vessels: a statistical assessment method and a Multiple Object Tracking (MOT) assessment methods. The statistical assessment method provides a quick response, while the MOT assessment method tracks all fishermen in CCTV footage and computes their 24-h work time, which is then compared with the mobile application data to identify instances of labor exploitation. We applied statistical assessment methods to analyze CCTV footage from January 25th, 2022, to January 31st, 2022, and MOT assessment methods were applied to CCTV footage from February 7th, 2022, to February 13th, 2022. Our analysis indicates that there were no instances of labor exploitation during this time frame.
C1 [Karthikeyan, P.; Chang, Chih Chun; Hsiung, Pao-Ann] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Daxue Rd, Chiayi 62102, Taiwan.
C3 National Chung Cheng University
RP Karthikeyan, P (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Daxue Rd, Chiayi 62102, Taiwan.
EM nrmkarthi@gmail.com; cjj880506@gmail.com; pahsiung@ccu.edu.tw
RI P, Karthikeyan/Q-8849-2016
OI P, Karthikeyan/0000-0001-8977-5520
FU National Science and Technology Council (NSTC) of Taiwan [1102420-H-194]
FX This work is supported by the National Science and Technology
   Council(NSTC) of Taiwan through research project 110-2420-H-194.
CR Bae Kwang-Ho, 2019, [Journal of Sasang Constitutional Medicine, 사상체질의학회지], V31, P12, DOI 10.7730/JSCM.2019.31.2.12
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Cao J, 2022, ARXIV
   Ciaparrone G, 2020, NEUROCOMPUTING, V381, P61, DOI 10.1016/j.neucom.2019.11.023
   Dendorfer P, 2021, INT J COMPUT VISION, V129, P845, DOI 10.1007/s11263-020-01393-0
   Howard AG, 2023, ARXIV
   Jackson B., 2019, J MOD SLAVERY, V4, P61
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Leal-Taixe L, 2023, ARXIV
   Li W., 2021, ARXIV
   Luo WH, 2021, ARTIF INTELL-AMST, V293, DOI 10.1016/j.artint.2020.103448
   McDonald GG, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2016238117
   Mumic N, 2021, STAT METHOD APPL-GER, V30, P819, DOI 10.1007/s10260-021-00582-6
   Pang JM, 2021, PROC CVPR IEEE, P164, DOI 10.1109/CVPR46437.2021.00023
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren S, 2015, 20 9 C NEURAL INFORM
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Selig ER, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-28916-2
   Stadler D., 2021, 2021 17 IEEE INT C A, P1, DOI DOI 10.1109/AVSS52988.2021.9663836
   Swartz W, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2100341118
   Tai TH, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12156013
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang Z., 2019, arXiv
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wolek A, 2022, IEEE J OCEANIC ENG, V47, P32, DOI 10.1109/JOE.2020.3015415
   Xingyi Zhou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P474, DOI 10.1007/978-3-030-58548-8_28
   Yang F., 2022, ARXIV
   Yen KW, 2021, MAR POLICY, V134, DOI 10.1016/j.marpol.2021.104805
   Yu E, 2023, IEEE T MULTIMEDIA, V25, P2686, DOI 10.1109/TMM.2022.3150169
   Zhang Y.-F., 2021, arXiv
   Zhang YF, 2021, INT J COMPUT VISION, V129, P3069, DOI 10.1007/s11263-021-01513-4
   Zhou X., 2019, arXiv
NR 32
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 46085
EP 46108
DI 10.1007/s11042-023-16094-2
EA JUL 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:001026613700006
DA 2024-07-18
ER

PT J
AU Poo, LJ
   Lan, Y
AF Poo, Low Jin
   Lan, Yu
TI Optimized intellectual natural language processing using automated chord
   tag construction for auto accompaniment in music
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural Language Processing; Accompaniment; Independent component
   analysis; Dual fast transform; Cumulative wavelet transform; Fast
   Fourier transform
AB One of the most crucial components of music is accompaniment creation and chord arrangement is essential to accompanying development. A greater level of musical skill and a thorough knowledge of music theory are often required for competent accompaniment production. To organise and provide space for additional chords, a Bengio Nesterov Momentum optimizer to Bidirectional Encoder Representations from Transformers (BNM-BERT) intuitive computer approach is provided. To replace manual chord creation for accompaniment, the work has generated Optimised Intellectual Natural Language Processing Music Accompaniment. An Overlapping Segmentation based Independent Component Analysis (OS-ICA) technique, which ensuring the frame interval signals are continuous and smoothness is used to begin the procedure after segmentation. Then, theme signal feature extraction is performed using the Dual Fast Transform (DFT), which combines the Continues Wavelet Transform (CWT) and Fast Fourier Transform (FFT) for feature extraction from music audio signals. This results in coefficients for the timbral texture, tonal texture, Pitch class Profile (PCP), and rhythmic activity, among other features of musical information that are specific to the sound spectrum. Then, to enhance the musical accompaniment, very pertinent rhythmic signals are chosen employing HE instated Jellyfish inquiry advancement (HEinit-JSO). The unlabeled audio stream is labelled using average linkage based on hierarchical divisive clustering after the feature is chosen. Finally, automatic chord label creation is done using the BNM- BERT model. The examination reveals that the well-before algorithm outperforms the standards in terms of reconstructive probability and generating effectiveness. Additionally, it shows how cascading effects can be used for accompaniment improvement, texture generation from chord circumstances, and chord analysis.
C1 [Poo, Low Jin] Management & Sci Univ, Univ Dr,Sect 13, Shah Alam 40100, Selangor, Malaysia.
   [Lan, Yu] City Univ Malaysia, Fac Educ, 8, Jalan 51A-223, Selangor Darul Ehsan 46100, Petaling Jaya, Malaysia.
C3 Management Science University
RP Poo, LJ (corresponding author), Management & Sci Univ, Univ Dr,Sect 13, Shah Alam 40100, Selangor, Malaysia.
EM jasonlow22@gmail.com; 309433613@qq.com
CR Aljanaki A, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1806.04903
   Aljunid MF, 2020, CAAI T INTELL TECHNO, V5, P268, DOI 10.1049/trit.2020.0031
   Bayle Y, 2019, MULTIMED TOOLS APPL, V78, P2703, DOI 10.1007/s11042-018-5797-8
   Bisharad D, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12429
   Briot JP, 2020, NEURAL COMPUT APPL, V32, P981, DOI 10.1007/s00521-018-3813-6
   Cai L, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01614-6
   Chen CF, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/4606027
   Chen N., 2021, Aggress. Violent Behav, V1, DOI DOI 10.1016/J.AVB.2021.101632
   Chin H, 2018, INT CONF BIG DATA, P517, DOI 10.1109/BigComp.2018.00085
   Duggirala S, 2020, INT CONF UBIQUIT INF, DOI 10.1109/imcom48794.2020.9001675
   Dukic H, 2019, THESIS KARL FRANZENS
   Elbir A., 2018, 2018 INN INT SYST AP, P1, DOI DOI 10.1109/ASYU.2018.8554016
   Falola PB., 2022, RESEARCHJET J ANAL I, V3, P35, DOI [10.17605/OSF.IO/FZQXW, DOI 10.17605/OSF.IO/FZQXW]
   Gajecki T, 2018, J ACOUST SOC AM, V143, P3602, DOI 10.1121/1.5042056
   Ghildiyal Anirudh, 2020, 2020 4th International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1368, DOI 10.1109/ICECA49313.2020.9297444
   Ghosal D, 2018, INTERSPEECH, P2087
   Herremans D, 2020, NEURAL COMPUT APPL, V32, P913, DOI 10.1007/s00521-019-04166-0
   Hizlisoy S, 2021, ENG SCI TECHNOL, V24, P760, DOI 10.1016/j.jestch.2020.10.009
   Jia BJ, 2019, MULTIMEDIA SYST, V25, P617, DOI 10.1007/s00530-019-00607-x
   Jiang N, 2020, AAAI CONF ARTIF INTE, V34, P710
   Kamala A., 2022, ENG P, V31, P64, DOI [10.3390/ASEC2022-13803, DOI 10.3390/ASEC2022-13803]
   Liu T, 2018, AIP CONF PROC, V1967, DOI 10.1063/1.5039095
   Liu Y, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2003.08954
   Nasrullah Z, 2019, IEEE IJCNN
   Pons J, 2019, ARXIV, DOI DOI 10.48550/ARXIV.1909.06654
   Sarkar R, 2020, MULTIMED TOOLS APPL, V79, P765, DOI 10.1007/s11042-019-08192-x
   Schedl M, 2019, FRONT APPL MATH STAT, V5, DOI 10.3389/fams.2019.00044
   Sharma G, 2020, APPL ACOUST, V158, DOI 10.1016/j.apacoust.2019.107020
   Siphocly NNJ, 2021, IEICE P SERIES, V64
   Song GX, 2018, NEUROCOMPUTING, V292, P104, DOI 10.1016/j.neucom.2018.02.076
   Vishnupriya S, 2018, INT CONF COMP COMMUN
   Wen XL, 2021, SOFT COMPUT, V25, P3087, DOI 10.1007/s00500-020-05364-y
   Wu WL, 2018, CHIN AUTOM CONGR, P192, DOI 10.1109/CAC.2018.8623623
   Yu Y, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3281746
NR 34
TC 2
Z9 2
U1 4
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13753
EP 13773
DI 10.1007/s11042-023-16101-6
EA JUL 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023992100001
DA 2024-07-18
ER

PT J
AU Yang, HG
   Xia, Z
   Chen, YQ
   Zhu, LQ
   Dai, LH
   Xu, RT
   Sun, GY
   Yu, HY
   Xu, WT
AF Yang, Haigen
   Xia, Zhun
   Chen, Yanqing
   Zhu, Linqun
   Dai, Luohao
   Xu, Ruotian
   Sun, GuiYing
   Yu, Hongyang
   Xu, Wenting
TI Research on visual simulation for complex weapon equipment
   interoperability based on MBSE
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MBSE; Interoperability simulation; UE4; SysML; MagicDraw
AB As military reforms continue to develop, the battlefield environment is becoming increasingly complex, and traditional single-service combat methods have evolved into integrated joint and collaborative information operations that break down service boundaries on land, sea, and air. The level of weapon system confrontation has also evolved into a system-to-system confrontation. Traditional document-based system architecture design methods can no longer address the complexity and emergent challenges of weapon system construction. In this paper, based on model-driven system engineering, an open, integrated, model-driven weapon equipment interaction system that supports human interaction was constructed using the SysML modeling language and Magicdraw modeling tool. The Unreal Engine 4 landscape building function was used to construct a virtual battlefield environment, and a communication server was developed using C# language to perform visual simulation of interoperability between weapon systems. Based on model-driven weapon equipment interoperability, visual simulation is used to ensure that the function of the weapon equipment system meets the requirements of combat and the combat effectiveness of the system is maximized.
C1 [Yang, Haigen; Xia, Zhun; Chen, Yanqing; Zhu, Linqun; Dai, Luohao; Xu, Ruotian] Nanjing Univ Posts & Telecommun, Engn Res Ctr Wider & Wireless Commun Technol, Minist Educ, 21003, Nanjing, Peoples R China.
   [Sun, GuiYing] Chinese Peoples Liberat Army 61416, Beijing 100089, Peoples R China.
   [Yu, Hongyang; Xu, Wenting] Beijing Electromech Engn Inst, Beijing 100074, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Yang, HG (corresponding author), Nanjing Univ Posts & Telecommun, Engn Res Ctr Wider & Wireless Commun Technol, Minist Educ, 21003, Nanjing, Peoples R China.
EM yhg@njupt.edu.cn
OI Yang, Haigen/0000-0003-2617-5127
CR Aghamohammadpour A, 2023, J SUPERCOMPUT, V79, P4215, DOI 10.1007/s11227-022-04808-6
   Anyanhun Awele, 2022, INCOSE International Symposium, P665, DOI 10.1002/iis2.12956
   DeLaurentis DA, 2011, J AIRCRAFT, V48, P760, DOI 10.2514/1.C031008
   Good MR, 2020, TECHNOLOGY INSERTION, V132, P59
   Graves H, 2011, ANN MATH ARTIF INTEL, V63, P53, DOI 10.1007/s10472-011-9267-5
   Gregory J, 2020, J SYST SOFTWARE, V160, DOI 10.1016/j.jss.2019.110453
   Hongxing, 2021, AIRCR ENG AEROSP TEC, V93, P937, DOI [10.1108/AEAT-03-2020-0062, DOI 10.1108/AEAT-03-2020-0062]
   Huang YY, 2015, KNOWL-BASED SYST, V89, P527, DOI 10.1016/j.knosys.2015.08.020
   Jacobs J, 2017, SOFTW SYST MODEL, V16, P1145, DOI 10.1007/s10270-015-0511-z
   Leserf P, 2019, SOFTW SYST MODEL, V18, P3265, DOI 10.1007/s10270-019-00717-0
   Ling MF, 2005, MIL OPER RES, V10, P5, DOI 10.5711/morj.10.1.5
   Liu B, 2012, INFORMATION-TOKYO, V15, P5659
   Lu JZ, 2020, IEEE SYST J, V14, P1297, DOI 10.1109/JSYST.2019.2911418
   Mazeika D, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/5137625
   Pandey Mohinder, 2022, INCOSE International Symposium, P737, DOI 10.1002/iis2.12961
   Planas E, 2020, COMPUT STAND INTER, V67, DOI 10.1016/j.csi.2019.103363
   Rogers EB, 2021, SYSTEMS ENG, V24, P385, DOI 10.1002/sys.21592
   Silingas D, 2009, INF TECHNOL CONTROL, V38, P153
   Sprock T, 2020, J RES NATL INST STAN, V125, DOI 10.6028/jres.125.023
   Squires A, 2010, SYSTEMS ENG, V13, P381, DOI 10.1002/sys.20157
   Tao ZG, 2017, ENTERP INF SYST-UK, V11, P627, DOI 10.1080/17517575.2015.1068374
   Wan W, 2016, ADV ENG INFORM, V30, P585, DOI 10.1016/j.aei.2016.07.003
   Wolny S, 2020, SOFTW SYST MODEL, V19, P111, DOI 10.1007/s10270-019-00735-y
   Yang HG, 2021, AIP ADV, V11, DOI 10.1063/5.0043494
   Yang HG, 2019, ADV MECH ENG, V11, DOI 10.1177/1687814019827129
   Zhang L, 2019, J COASTAL RES, P652, DOI 10.2112/SI93-088.1
   Zhang TT, 2012, 2012 IEEE AIAA 31 DI
NR 27
TC 1
Z9 1
U1 12
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13463
EP 13482
DI 10.1007/s11042-023-15950-5
EA JUL 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001024891800006
OA hybrid
DA 2024-07-18
ER

PT J
AU Rashid, Y
   Bhat, JI
AF Rashid, Yasir
   Bhat, Javaid Iqbal
TI Topological to deep learning era for identifying influencers in online
   social networks :a systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Prominent user; Influential nodes; Online social networks; Deep
   learning; Graph convolution networks(GCNs); Communities
ID INFLUENTIAL NODES; COMPLEX NETWORKS; IDENTIFICATION; TWITTER; USERS;
   SPREADERS; DOMAIN
AB Influential user detection in social media networks involves identifying users who have a significant impact on the network's dynamics and can shape opinions and behaviours of other users. This paper reviews different topological and deep learning techniques for identifying influencers in online social networks. It examines various methods, such as degree centrality, closeness centrality, betweenness centrality, PageRank, and graph convolutional networks, and compares their strengths and limitations in terms of computational complexity, accuracy, and robustness. The paper aims to provide insights into the state-of-the-art techniques for identifying influencers in online social networks, and to highlight future research directions in this field. The findings of this review paper will be particularly valuable for researchers and practitioners interested in social network analysis.
C1 [Rashid, Yasir; Bhat, Javaid Iqbal] Islamic Univ Sci & Technol, Dept Comp Sci, Kashmir, India.
RP Bhat, JI (corresponding author), Islamic Univ Sci & Technol, Dept Comp Sci, Kashmir, India.
EM yasir.rashid@iust.ac.in; javaid.iqbal@iust.ac.in
CR Abbruzzese R, 2021, INFORM SCIENCES, V578, P364, DOI 10.1016/j.ins.2021.07.014
   Al-garadi MA, 2016, PHYS A
   Al-Garadi MA, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3155897
   Albert R, 2000, NATURE, V406, P378, DOI 10.1038/35019019
   Ali M, 2022, TECHNOL FORECAST SOC, V188
   Alshahrani M, 2020, INFORM SCIENCES, V527, P88, DOI 10.1016/j.ins.2020.03.060
   Amati G, 2019, MULTIMED TOOLS APPL, V78, P3395, DOI 10.1007/s11042-018-6728-4
   [Anonymous], 2023, COMMUNICATION PATTER, VC7, P725
   Arora A, 2019, J RETAIL CONSUM SERV, V49, P86, DOI 10.1016/j.jretconser.2019.03.012
   Arularasan AN, 2019, CLUSTER COMPUT, V22, pS4035, DOI 10.1007/s10586-018-2616-y
   Bahutair M, 2022, J SUPERCOMPUT, V78, P2098, DOI 10.1007/s11227-021-03947-6
   Balaji TK, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100395
   Bao ZK, 2017, PHYS LETT A, V381, P976, DOI 10.1016/j.physleta.2017.01.043
   Basaras P, 2017, IDENTIFYING INFLUENT, V4697, P1
   Batagelj V., 2002, Generalized cores. CoRR cs.DS/0202039, V5, P1
   Ben Jabeur L, 2012, LECT NOTES COMPUT SC, V7608, P111, DOI 10.1007/978-3-642-34109-0_12
   Bigonha C, 2012, SENTIMENT BASED INFL, P169
   Bonacich P, 2007, SOC NETWORKS, V29, P555, DOI 10.1016/j.socnet.2007.04.002
   Borgatti SP, 2006, SOC NETWORKS, V28, P466, DOI 10.1016/j.socnet.2005.11.005
   Boroujeni RJ, 2022, EXPERT SYST APPL, V202, DOI 10.1016/j.eswa.2022.117452
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Chai W., 2013, ACQR NOVEL FRAMEWORK
   Chen X, 2018, ACM INT C P SER MARC, P70
   Chiroque LF, 2021, DISSERTATION
   Corsi N, 2022, EUR UROL FOCUS
   Cossu JV, 2015, SECOND EUROPEAN NETWORK INTELLIGENCE CONFERENCE (ENIC 2015), P83, DOI 10.1109/ENIC.2015.20
   De La Garza H, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18095002
   De Salve A, 2021, ACM T KNOWL DISCOV D, V15, DOI 10.1145/3441447
   Dechun Liu, 2011, 2011 3rd International Conference on Multimedia Information Networking and Security, P278, DOI 10.1109/MINES.2011.109
   Ding ZY, 2013, J ZHEJIANG U-SCI C, V14, P701, DOI 10.1631/jzus.CIIP1302
   Elbaghazaoui BE, 2022, DATA PROFILING MACHI, V10, P201
   Gammoudi F, 2022, SOC NETW ANAL MIN, V12, DOI 10.1007/s13278-022-00972-y
   Ghosal D, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P154
   Gong X., 2023, SHS WEB C, V153, P01009, DOI [10.1051/shsconf/202315301009, DOI 10.1051/SHSCONF/202315301009]
   GROSS J, 2022, J INTERACT ADVERT, P1
   Gu J, 2022, INVESTIGATION INFLUE
   Guenon N, 2020, ARXIV
   Guruprasad S, 2021, 2021 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER TECHNOLOGIES AND OPTIMIZATION TECHNIQUES (ICEECCOT), P762, DOI 10.1109/ICEECCOT52851.2021.9707966
   Hafiene N, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113642
   Han M, 2018, MATH FDN COMPUT, V1, P201, DOI 10.3934/mfc.2018010
   Alwan WH, 2020, IEEE ACCESS, V8, P169594, DOI 10.1109/ACCESS.2020.3020560
   He X, 2023, LIGHTGCN SIMPLIFYING
   Hidri A, 2021, INFERRING INFLUENTIA
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang X, 2020, ENTROPY-SWITZ, V22
   Pham H, 2016, PROC INT CONF DATA, P529, DOI 10.1109/ICDE.2016.7498268
   Ibnoulouafi A, 2018, CHAOS SOLITON FRACT, V114, P69, DOI 10.1016/j.chaos.2018.06.022
   Ignat O, 2021, DETECTING INSPIRING
   Jain S, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110037
   Jeelani Z, 2023, SIGNAL IMAGE VIDEO P, V17, P2679, DOI 10.1007/s11760-023-02484-4
   Jiang J, 2013, ACM T WEB, V7, DOI 10.1145/2517040
   Kao L-j, 2015, MINING INFLUENTIAL U
   Karoui W, 2023, INFORM SYST, V112, DOI 10.1016/j.is.2022.102132
   Karoui W, 2022, SOC NETW ANAL MIN, V12, DOI 10.1007/s13278-022-00942-4
   Khan H, 2018, 2018 INTERNATIONAL CONFERENCE ON ENGINEERING & EMERGING TECHNOLOGIES (ICEET), P50
   Khanday Akib Mohi Ud Din, 2021, Int J Inf Technol, V13, P115, DOI 10.1007/s41870-020-00550-5
   Kim S, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING, P41, DOI 10.1109/ASONAM.2009.59
   Kumar S, 2021, EXP SYST APPL, V212
   Kumar S, 2021, APPL INTELL, V51, P7647, DOI 10.1007/s10489-021-02266-w
   Kumar S, 2020, PHYSICA A, V553, DOI 10.1016/j.physa.2020.124215
   Li HW, 2021, CHAOS SOLITON FRACT, V143, DOI 10.1016/j.chaos.2020.110456
   Li JX, 2020, INFORM SYST, V92, DOI 10.1016/j.is.2020.101522
   Li WM, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102818
   Liang JM, 2012, INT CONF CLOUD COMP
   Liao H, 2017, PHYS REP, V689, P1, DOI 10.1016/j.physrep.2017.05.001
   Liu N, 2007, IDENTIFYING DOMAIN D, P3122
   Liu Y, 2021, PATTERNS, V2, DOI 10.1016/j.patter.2021.100321
   Lü LY, 2016, PHYS REP, V650, P1, DOI 10.1016/j.physrep.2016.06.007
   Lü LY, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021202
   Mao G-j, 2016, PAGERANK BASED MININ
   Mei Y, 2006, FINDING ANAL PRINCIP, P478
   Mislove A, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P29
   Mithe S, 2019, DEEP LEARNING GRAPHS
   Mnasri W, 2021, APPL INTELL, V51, P7365, DOI 10.1007/s10489-021-02203-x
   Morone F, 2015, NATURE, V524, P65, DOI 10.1038/nature14604
   Nafees L., 2021, Digital Business, V1
   Newman MEJ., 2007, HOUCHES SUMMER SCH P, V85, P309, DOI [10.1016/S0924-8099(07)80015-1, DOI 10.1016/S0924-8099(07)80015-1]
   Ngo D-t, 2020, IDENTIFYING MICROINF
   Nouh M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P969, DOI 10.1109/ICDMW.2015.88
   Open Access, 2012, K SHELL DEC METH WEI
   Panchendrarajan R, 2023, APPL INTELL, V53, P5998, DOI 10.1007/s10489-022-03831-7
   Peng SC, 2018, J NETW COMPUT APPL, V106, P17, DOI 10.1016/j.jnca.2018.01.005
   Praas J, 2020, PREDICTING INFLUENCE, P1
   Qiu J, 2023, DEEPINF SOCIAL INFLU
   Räbiger S, 2015, EXPERT SYST APPL, V42, P2824, DOI 10.1016/j.eswa.2014.11.006
   Rani S, 2022, INFLUENTIAL NODE DET, P1
   Razis G, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3369780
   Rezaie B, 2020, KNOWL INF SYST, V62, P3481, DOI 10.1007/s10115-020-01459-y
   Riquelme F, 2016, INFORM PROCESS MANAG, V52, P949, DOI 10.1016/j.ipm.2016.04.003
   Saeidi M, 2021, GRAPH CONVOLUTIONAL, P946
   Sarkar Dhrubasish, 2016, International Journal of Virtual Communities and Social Networking, V8, P57, DOI 10.4018/IJVCSN.2016100104
   Sarna S, 2022, QUERY ORIENTED TOPIC, P13415
   Shafiq MZ, 2013, IEEE J SEL AREA COMM, V31, P618, DOI 10.1109/JSAC.2013.SUP.0513054
   Silva A, 2023, PROFILERANK FINDING
   Singh S.S., 2019, Soft Comput., P1
   Srinivasu PN, 2022, J CIRCUIT SYST COMP, V31, DOI 10.1142/S0218126622503030
   Sudar KM, 2023, CLUSTER COMPUT, V26, P1461, DOI 10.1007/s10586-022-03666-4
   Talukder A, 2019, IEEE ACCESS, V7, P105441, DOI 10.1109/ACCESS.2019.2931925
   Tiwary A., 2022, DETERMINATION CATEGO, V13, P2313
   Torino PDI, 2022, MICR INFL CLASS AC E
   Wang F, 2019, IEEE IND ELEC, P6854, DOI 10.1109/IECON.2019.8927419
   Wang N, 2016, CHINESE J ELECTRON, V25, P467, DOI 10.1049/cje.2016.05.012
   Wang Q, 2021, NEURAL PROCESS LETT, V53, P4073, DOI 10.1007/s11063-021-10583-x
   Wei B, 2014, PHYS A
   Wen T, 2020, INFORM SCIENCES, V512, P549, DOI 10.1016/j.ins.2019.10.003
   Weng J, 2010, I KNOWLEDGE SINGAPO
   Yamaguchi Y, 2010, LECT NOTES COMPUT SC, V6488, P240, DOI 10.1007/978-3-642-17616-6_22
   Yin ZB, 2012, Proceedings of 2012 ASE/IEEE International Conference on Privacy, Security, Risk and Trust and 2012 ASE/IEEE International Conference on Social Computing (SocialCom/PASSAT 2012), P502, DOI 10.1109/SocialCom-PASSAT.2012.10
   Yu E, 2022, IDENTIFYING CRITICAL
   Yuan SJ, 2023, COMPUT COMMUN, V199, P62, DOI 10.1016/j.comcom.2022.12.008
   Zareie A, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105580
   Zareie A, 2020, EXPERT SYST APPL, V142, DOI 10.1016/j.eswa.2019.112971
   Zareie A, 2019, INFORM SCIENCES, V493, P217, DOI 10.1016/j.ins.2019.04.033
   Zeng A, 2013, PHYS LETT A, V377, P1031, DOI 10.1016/j.physleta.2013.02.039
   Zhan C., 2022, NUCL ACID BASED IMMU, P1
   Zhang T, 2022, INF FUS, V92, P231
   Zhang W, 2019, EXPERT SYST APPL, V125, P249, DOI 10.1016/j.eswa.2019.02.007
   Zhang Z, 2020, IDENTIFYING FLUENTIA
   Zhao GH, 2020, NEUROCOMPUTING, V414, P18, DOI 10.1016/j.neucom.2020.07.028
   Zhao GH, 2020, IEEE ACCESS, V8, P65462, DOI 10.1109/ACCESS.2020.2984286
   Zhou J, 2012, FUTURE GENER COMP SY
   Zhou S, 2021, J BUS RES, V134, P122, DOI 10.1016/j.jbusres.2021.05.011
   Zhu YQ, 2020, PROC VLDB ENDOW, V13, P1614, DOI 10.14778/3401960.3401961
   Zhuang Y-b, 2021, EXPLORATION, V7
NR 124
TC 2
Z9 2
U1 16
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14671
EP 14714
DI 10.1007/s11042-023-16002-8
EA JUL 2023
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023700800008
DA 2024-07-18
ER

PT J
AU Chen, L
   Zhu, SW
   Andrew, A
   Yin, ZX
AF Chen, Li
   Zhu, Shaowei
   Andrew, Abel
   Yin, Zhaoxia
TI Reversible attack based on local visible adversarial perturbation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible attack; Adversarial attack; Local visible adversarial
   perturbation; Information hiding; Reversible data embedding
ID IMAGE
AB Adding perturbation to images can mislead classification models to produce incorrect results. Based on this, research has exploited adversarial perturbation to protect private images from retrieval by malicious intelligent models. However, adding adversarial perturbation to images destroys the original data, making images useless in digital forensics and other fields. To prevent illegal or unauthorized access to sensitive image data such as human faces without impeding legitimate users, the use of reversible adversarial attack techniques is becoming more widely investigated, where the original image can be recovered from its reversible adversarial examples. However, existing reversible adversarial attack methods are designed for traditional imperceptible adversarial perturbation and ignore the local visible adversarial perturbation. In this paper, we propose a new method for generating reversible adversarial examples based on local visible adversarial perturbation. The information needed for image recovery is embedded into the area beyond the adversarial patch by the reversible data hiding technique. To reduce image distortion, lossless compression and the B-R-G (blue-red-green) embedding principle are adopted. Experiments on CIFAR-10 and ImageNet datasets show that the proposed method can restore the original images error-free while ensuring good attack performance.
C1 [Chen, Li; Zhu, Shaowei] Anhui Univ, Anhui Prov Key Lab Multimodal Cognit Computat, Hefei 230601, Peoples R China.
   [Andrew, Abel] Univ Strathclyde, Comp & Informat Sci, Glasgow, Scotland.
   [Yin, Zhaoxia] East China Normal Univ, Sch Commun & Elect Engn, Shanghai 200241, Peoples R China.
   [Yin, Zhaoxia] East China Normal Univ, Shanghai Key Lab Multidimens Informat Proc, Shanghai 200241, Peoples R China.
C3 Anhui University; University of Strathclyde; East China Normal
   University; East China Normal University
RP Yin, ZX (corresponding author), East China Normal Univ, Sch Commun & Elect Engn, Shanghai 200241, Peoples R China.; Yin, ZX (corresponding author), East China Normal Univ, Shanghai Key Lab Multidimens Informat Proc, Shanghai 200241, Peoples R China.
EM E20201021@stu.ahu.edu.cn; zhusw520@gmail.com; andrew.abel@strath.ac.uk;
   zxyin@cee.ecnu.edu.cn
RI Yin, Zhaoxia/HRD-7425-2023
OI Yin, Zhaoxia/0000-0003-0387-4806
FU National Natural Science Foundation of China [62172001]
FX This work is supported by the National Natural Science Foundation of
   China (No.62172001).
CR Amin MM, 2003, 4TH NATIONAL CONFERENCE ON TELECOMMUNICATION TECHNOLOGY, PROCEEDINGS, P21, DOI 10.1109/NCTT.2003.1188294
   Athalye A, 2018, PR MACH LEARN RES, V80
   Brown, 2017, NEURAL INFORM PROCES
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hou DD, 2018, J VIS COMMUN IMAGE R, V53, P134, DOI 10.1016/j.jvcir.2017.11.014
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Jia XJ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1579, DOI 10.1145/3394171.3413976
   Karmon D., 2018, INT C MACH LEARN, P2507
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Li CY, 2019, INT CONF ACOUST SPEE, P2502, DOI [10.1109/ICASSP.2019.8682225, 10.1109/icassp.2019.8682225]
   Liu AS, 2019, AAAI CONF ARTIF INTE, P1028
   Moosavi-Dezfooli SM, 2017, PROC CVPR IEEE, P86, DOI 10.1109/CVPR.2017.17
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Mopuri KR, 2019, IEEE T PATTERN ANAL, V41, P2452, DOI 10.1109/TPAMI.2018.2861800
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Niu JY, 2022, APPL INTELL, V52, P6181, DOI 10.1007/s10489-021-02721-8
   Qu ZG, 2019, MULTIMED TOOLS APPL, V78, P7981, DOI 10.1007/s11042-018-6476-5
   Rajabi Arezoo, 2021, Proceedings on Privacy Enhancing Technologies, V2021, P85, DOI 10.2478/popets-2021-0006
   Rao Sukrut, 2020, Proceedings of the 16th European Conference on Computer Vision (ECCV 2020) Workshops. Lecture Notes in Computer Science (LNCS 12539), P429, DOI 10.1007/978-3-030-68238-5_32
   Ren H, 2022, MULTIMED TOOLS APPL, V81, P2161, DOI 10.1007/s11042-021-11341-w
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Santos TI, 2021, IEEE W SP LANG TECH, P613, DOI 10.1109/SLT48900.2021.9383540
   Shah Pranit Gopaldas, 2021, Proceedings of 6th International Conference on Recent Trends in Computing. ICRTC 2020. Lecture Notes in Networks and Systems (LNNS 177), P511, DOI 10.1007/978-981-33-4501-0_47
   Shan S, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P1589
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiong LZ, 2022, IEEE T CIRC SYST VID, V32, P75, DOI 10.1109/TCSVT.2021.3055072
   Yan LM, 2021, MULTIMED TOOLS APPL, V80, P30761, DOI 10.1007/s11042-020-10171-6
   Yang Y, 2022, IEEE T CIRC SYST VID, V32, P1860, DOI 10.1109/TCSVT.2021.3084676
   Yin Z, 2019, 2021 INT WORKSH SAF
   Yin ZX, 2020, IEEE T CIRC SYST VID, V30, P2343, DOI 10.1109/TCSVT.2020.2969463
   You Zhengwei, 2021, 2021 IEEE International Workshop on Electromagnetics: Applications and Student Innovation Competition (iWEM), P1, DOI 10.1109/iWEM53379.2021.9790683
   Yu C, 2021, IEEE IMAGE PROC, P494, DOI 10.1109/ICIP42928.2021.9506383
   Zhang XR, 2022, CMC-COMPUT MATER CON, V71, P3035, DOI 10.32604/cmc.2022.022304
NR 40
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11215
EP 11227
DI 10.1007/s11042-023-15383-0
EA JUN 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001021028900001
DA 2024-07-18
ER

PT J
AU Farooq, A
   Tariq, S
   Amin, A
   Qureshi, MA
   Memon, KH
AF Farooq, Anum
   Tariq, Sana
   Amin, Asjad
   Qureshi, Muhammad Ali
   Memon, Kashif Hussain
TI Towards the design of new cryptographic algorithm and performance
   evaluation measures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptography; Encryption algorithms; Decryption algorithms; Security
   evaluation measures; Network security; Privacy
ID ADVANCED ENCRYPTION STANDARD; IMAGE; RSA
AB Security and confidentiality are one of the main concerns when transmitting multimedia data over the Internet. To deal with the arising security issues, many advanced cryptographic algorithms have been proposed in the literature. The efficiency of these encryption algorithms varies according to the application area in which they are deployed. Although there are many objective evaluation metrics available in the literature to measure the performance of the cryptographic algorithms, however, to the best of our knowledge, no survey or review addresses the quality of the metrics for cryptography algorithms. In this paper, we have presented and analyzed the cryptography algorithms and performance evaluation metrics such as resource utilization measure, quality measure, and security measures to evaluate the security performance of different encryption algorithms for multimedia data. Extensive experiments have been carried out to evaluate the performance of the cryptography algorithms for multimedia data such as images and videos. We have also discussed and analyzed in detail the performance of evaluation measures used to validate the cryptography algorithms. Our findings highlight the strength of different cryptography algorithms and performance evaluation metrics. The analysis is expected to contribute to the design of a new and efficient model for multimedia applications. A detailed analysis of major attacks was also presented for each encryption scheme in tabular form.
C1 [Farooq, Anum; Memon, Kashif Hussain] Islamia Univ Bahawalpur, Dept Comp Syst Engn, Bahawalpur, Pakistan.
   [Tariq, Sana] Islamia Univ Bahawalpur, Dept Elect Engn, Bahawalpur, Pakistan.
   [Amin, Asjad; Qureshi, Muhammad Ali] Islamia Univ Bahawalpur, Dept Informat & Commun Engn, Bahawalpur, Pakistan.
C3 Islamia University of Bahawalpur; Islamia University of Bahawalpur;
   Islamia University of Bahawalpur
RP Qureshi, MA (corresponding author), Islamia Univ Bahawalpur, Dept Informat & Commun Engn, Bahawalpur, Pakistan.
EM anum.farooq@iub.edu.pk; sana.tariq@iub.edu.pk; asjad.amin@iub.edu.pk;
   ali.qureshi@iub.edu.pk; kashif.hussain@iub.edu.pk
RI Qureshi, Muhammad Ali/C-3857-2012
OI Qureshi, Muhammad Ali/0000-0003-4390-2461; Memon, Kashif
   Hussain/0000-0002-0677-3480
CR Abbas NA, 2016, EGYPT INFORM J, V17, P139, DOI 10.1016/j.eij.2015.10.001
   Adams, 1997, RFC2144
   Adams C., 1999, Engineering Solutions for the Next Millennium. 1999 IEEE Canadian Conference on Electrical and Computer Engineering (Cat. No.99TH8411), P361, DOI 10.1109/CCECE.1999.807225
   Adams C, 1999, CAST 256 ENCRYPTION
   Ahmad Jawad., 2010, computing, V23, P25
   Ahmad S, 2021, MULTIMED TOOLS APPL, V80, P32071, DOI 10.1007/s11042-021-11152-z
   Ahmed HEH, 2007, 2007 INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, P67
   Ahmed Nisar, 2016, International Journal of Computer Network and Information Security, V8, P18, DOI 10.5815/ijcnis.2016.12.03
   Annapoorna S., 2014, International Journal of Innovative Research in Computer and Communication Engineering, V2, P98
   [Anonymous], 2018, 2018 IEEE Long Island Systems, Applications and Technology Conference (LISAT), IEEE, DOI DOI 10.1109/LISAT.2018.8378034
   Bagherzandi A., 2009, IJ NETWORK SECURITY, V8, P221
   Bala T, 2015, INT C ADV ENG TECHN, P1
   Bhanot R, 2015, INT J SECUR APPL, V9, P289, DOI 10.14257/ijsia.2015.9.4.27
   Biham E, 2008, LECT NOTES COMPUT SC, V5086, P73
   Bleichenbacher D, 1998, LECT NOTES COMPUT SC, V1462, P1, DOI 10.1007/BFb0055716
   Burnwick C., 1999, MARS ENCRYPTION ALGO
   Charbathia S., 2014, INT J INF COMPUT TEC, V4, P1831
   Chen WB, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P94
   1977, FEDERAL INFORM PROCE, V46, P23
   Davida G., 1982, CHOSEN SIGNATURE CRY
   Dehkordi MH., 2018, ELECT ELECT TECH OPE, V2, P251
   Dener M, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/303501
   Elkamchouchi HM, 2005, RAD SCI C 2005 NRSC, P277, DOI DOI 10.1109/NRSC.2005.194011
   Elminaam DSA, 2009, INNOVATION AND KNOWLEDGE MANAGEMENT IN TWIN TRACK ECONOMIES: CHALLENGES & SOLUTIONS, VOLS 1-3, P1001
   Fishawy NFE., 2007, INT J NETWORK SECUR, V5, P241
   Fouque PA, 2003, LECT NOTES COMPUT SC, V2779, P269, DOI 10.1007/978-3-540-45238-6_22
   GIRAULT M, 1988, LECT NOTES COMPUT SC, V330, P129
   Gray RM, 2011, ENTROPY AND INFORMATION THEORY , SECOND EDITION, P395, DOI 10.1007/978-1-4419-7970-4
   Gunasundari T., 2014, International Journal of Computer Science and Mobile Applications, V2, P78
   Hong D, 2006, LECT NOTES COMPUT SC, V4249, P46, DOI 10.1007/11894063_4
   Hunn SAY, 2012, IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS DESIGN, SYSTEMS AND APPLICATIONS (ICEDSA 2012), P45, DOI 10.1109/ICEDSA.2012.6507813
   Jang S.W., 2017, Anal Appl Math, V10, P5
   Junfeng Fan, 2012, Cryptography and Security: From Theory to Applications. Essays Dedicated to Jean-Jacques Quisquater on the Occasion of His 65th Birthday: LNCS 6805, P265, DOI 10.1007/978-3-642-28368-0_18
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Kitsos P, 2004, 2004 IEEE INT S CIRC, pII
   Knudsen L.R., 2005, FAST SOFTWARE ENCRYP, P211, DOI [10.1007/3-540-58108-1_26, DOI 10.1007/3-540-58108-1_26]
   Kumari M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0148-5
   Li JH, 2013, IET INFORM SECUR, V7, P265, DOI 10.1049/iet-ifs.2012.0304
   Lian S., 2008, MULTIMEDIA CONTENT E, DOI [10.1201/9781420065282, DOI 10.1201/9781420065282]
   Luo YL, 2019, SIGNAL PROCESS, V161, P227, DOI 10.1016/j.sigpro.2019.03.022
   Luo YL, 2019, IEEE ACCESS, V7, P38507, DOI 10.1109/ACCESS.2019.2906052
   Mahajan P., 2013, Glob. J. Comput. Sci. Technol.
   Mandal AK., 2012, INT J EMERGING TREND, V1, P166
   Massoudi A, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/179290
   Milad Ali Ahmad, 2012, Journal of Computer Science, V8, P1191, DOI 10.3844/jcssp.2012.1191.1197
   Mohammad O. F., 2017, INT J APPL ENG RES, V12, P13265
   Mohan HS., 2011, INT J COMPUT SCI ISS, V8, P363
   Moriai, 2000, CRYPTANALYSIS TWOFIS, Vii
   Mushtaque MdA, 2014, INT J ENG RES TECHNO, V3
   Naeemabadi M., 2015, Advances in Natural and Applied Sciences, V9, P137
   Nie Tingyuan., 2009, Tencon 2009-2009 IEEE Region 10 Conference, P1
   Padmavathi B., 2013, SURVEY PERFORMANCE A
   Pandey A, 2016, INT CONF RELI INFO, P375, DOI 10.1109/ICRITO.2016.7784984
   Patil P, 2016, PROCEDIA COMPUT SCI, V78, P617, DOI 10.1016/j.procs.2016.02.108
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Rajesh S, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11020293
   Rasoolzadeh Shahram, 2016, Tatra Mountains Mathematical Publications, V67, P135, DOI 10.1515/tmmp-2016-0036
   Rawat N, 2016, OPTIK, V127, P2282, DOI 10.1016/j.ijleo.2015.11.064
   Raza SF, 2019, NONLINEAR DYNAM, V95, P859, DOI 10.1007/s11071-018-4600-8
   Rijmen Vincent., 2001, P FEDERAL INFORM PRO, P19, DOI DOI 10.1007/978-3-662-04722-4_1
   Rinne S., 2007, PROC ECRYPT WORKSHOP, P33
   Saher M, 2018, MEHRAN UNIV RES J EN, V37, P645, DOI 10.22581/muet1982.1804.16
   Saito T., 2011, 2011584 IACR CRYPT E, V2011, P584
   Saleh M, 2021, INT CONF ADV COMMUN, P210, DOI 10.23919/ICACT51234.2021.9370721
   Schneier B., 1996, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Schneier B., 1998, NIST AES Propos, V15, P23
   Shah, 2011, ARXIV
   Shah D, 2020, MULTIMED TOOLS APPL, V79, P28023, DOI 10.1007/s11042-020-09182-0
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Sindhuja K., 2014, IJCSIT, V5, P414
   Soomro S, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTING, ELECTRONICS & COMMUNICATIONS ENGINEERING (ICCECE), P158, DOI 10.1109/iccece46942.2019.8941663
   Stallings W., 2017, Cryptography and Network Security: Principles and Practice, V7th ed.
   Trad A., 2014, Proc. of World Congress on Computer Applications and Information Systems (WCCAIS), P1
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Ya Liu, 2012, Information Security Practice and Experience. Proceedings of the 8th International Conference, ISPEC 2012, P97, DOI 10.1007/978-3-642-29101-2_7
   Zeghid M, 2007, PROC WRLD ACAD SCI E, V21, P206
   Zhou YB, 2014, 2014 5TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING AND SERVICE SCIENCE (ICSESS), P517, DOI 10.1109/ICSESS.2014.6933619
   Zhu LH, 2006, INT J COMPUT SCI NET, V6, P125
NR 78
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9709
EP 9759
DI 10.1007/s11042-023-15673-7
EA JUN 2023
PG 51
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016469800003
DA 2024-07-18
ER

PT J
AU Gao, W
   Yang, BP
   Xiao, Y
   Zeng, P
   Hu, X
   Zhu, X
AF Gao, Wang
   Yang, Baoping
   Xiao, Yue
   Zeng, Peng
   Hu, Xi
   Zhu, Xun
TI Duplicate question detection in community-based platforms via
   interaction networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Duplicate question detection; Siamese networks; Text matching;
   Interaction network; Attention mechanism
AB Community-based Question and Answering (CQA) platforms have a huge number of users, resulting in numerous duplicate questions with similar intent from different users. Effectively detecting duplicate questions can improve the findability of platforms, and enhance the user experience of viewers and writers. Existing state-of-the-art methods focus on designing the structure of multi-layer interaction networks, ignoring the problems of error propagation and loss of low-level semantics. In this paper, we propose a novel Interaction-based Siamese Network (ISN) to address these issues, which utilizes a siamese structure to learn the original semantics of questions and captures interaction information with question interactive units. During the interaction, each interactive unit takes the original semantic representation of another question as an input, thus effectively mitigating the effect of error propagation. Furthermore, we propose an aggregation strategy to propagate low-level interaction features to high-level to preserve low-level semantic information, and introduce self-attention to enhance the model's global interaction information learning ability. Experimental results on a real-world CQA dataset show that ISN outperforms state-of-the-art models for duplicate question detection.
C1 [Gao, Wang; Xiao, Yue; Zeng, Peng; Hu, Xi; Zhu, Xun] Jianghan Univ, Sch Artificial Intelligence, Wuhan 430056, Peoples R China.
   [Gao, Wang; Xiao, Yue; Zeng, Peng; Hu, Xi; Zhu, Xun] Jianghan Univ, Engn Res Ctr Intelligent Decis & Informat Proc, Wuhan 430056, Peoples R China.
   [Yang, Baoping] Huanggang Normal Univ, Phys & Telecommun Coll Engn, Huanggang 438000, Peoples R China.
C3 Jianghan University; Jianghan University; Huanggang Normal University
RP Gao, W (corresponding author), Jianghan Univ, Sch Artificial Intelligence, Wuhan 430056, Peoples R China.; Gao, W (corresponding author), Jianghan Univ, Engn Res Ctr Intelligent Decis & Informat Proc, Wuhan 430056, Peoples R China.
EM gaow@jhun.edu.cn; yangbp@hgnu.edu.cn; 997233426@stu.jhun.edu.cn;
   zengpeng@jhun.edu.cn; huxi027@163.com; zhuxun@jhun.edu.cn
RI Zeng, Peng/IQW-9449-2023; yang, baoping/AAE-3178-2022; GAO,
   WANG/GWU-5411-2022
OI GAO, WANG/0000-0001-9671-489X
FU National Natural Science Foundation of China (NSFC) [62276196]; Key
   Research and Development Program of Hubei Province [2022BAD064];
   Industry-University-Research Project of Wuhan Education Bureau
   [CXY202208]; Special Research Fund for Discipline Characteristics of
   Jianghan University [2022XKZK10]
FX This work is supported by National Natural Science Foundation of China
   (NSFC, No.62276196), Key Research and Development Program of Hubei
   Province (No.2022BAD064) , Industry-University-Research Project of Wuhan
   Education Bureau (No.CXY202208) and Special Research Fund for Discipline
   Characteristics of Jianghan University (No.2022XKZK10).
CR Ahasanuzzaman M, 2016, 13TH WORKING CONFERENCE ON MINING SOFTWARE REPOSITORIES (MSR 2016), P402, DOI 10.1145/2901739.2901770
   [Anonymous], 2017, P 1 WORKSH SUBW CHAR, DOI DOI 10.18653/V1/W17-4121
   Bartoszuk M, 2021, KNOWL-BASED SYST, V231, DOI 10.1016/j.knosys.2021.107427
   Bjerva J., 2016, P COLING 2016 26 INT, P3531
   Bowman S. R., 2015, Proceedings of the 2015 conference on empirical methods in natural language processing, DOI [DOI 10.18653/V1/D15-1075, 10.18653/v1/d15-1075, 10.18653/v1/D15-1075]
   Chen Q, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2406
   Choi J, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2192, DOI 10.1145/3404835.3463076
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dowty D., 2007, DIRECT COMPOSITIONAL, V14, P14
   Duan CQ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4033
   Gao W, 2023, WORLD WIDE WEB, V26, P55, DOI 10.1007/s11280-022-01034-1
   Gao W, 2021, LECT NOTES COMPUT SC, V13080, P370, DOI 10.1007/978-3-030-90888-1_28
   Gao W, 2020, NEUROCOMPUTING, V383, P282, DOI 10.1016/j.neucom.2019.11.077
   Gao W, 2019, KNOWL INF SYST, V61, P1123, DOI 10.1007/s10115-018-1314-7
   Gong Yichen, 2018, INT C LEARN REPR
   Guo SR, 2021, KNOWL-BASED SYST, V232, DOI 10.1016/j.knosys.2021.107454
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Imtiaz Z, 2020, IEEE ACCESS, V8, P21932, DOI 10.1109/ACCESS.2020.2969041
   Kim S, 2019, AAAI CONF ARTIF INTE, P6586
   Kim Y., 2014, P 2014 C EMP METH NA, P1746, DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/D14-1181]
   Liu W, 2022, ABS220206517 CORR, V2202, P1
   Mou LL, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P130
   Neutel S, 2021, P AAAI C ARTIFICIAL, P1
   Othman N, 2022, DATA KNOWL ENG, V138, DOI 10.1016/j.datak.2021.101962
   Peng QW, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5579
   Poerner N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1630
   Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P567
   Sadeghi F, 2022, MULTIMED TOOLS APPL, V81, P33801, DOI 10.1007/s11042-022-12428-8
   Shahmohammadi H, 2021, MULTIMED TOOLS APPL, V80, P6479, DOI 10.1007/s11042-020-09996-y
   Song Y, 2019, KNOWL-BASED SYST, V169, P67, DOI 10.1016/j.knosys.2019.01.028
   Tan ZX, 2018, AAAI CONF ARTIF INTE, P4929
   Vaswani A, 2017, ADV NEUR IN, V30
   Viji D, 2022, MULTIMED TOOLS APPL, V81, P6131, DOI 10.1007/s11042-021-11771-6
   Wan SX, 2016, AAAI CONF ARTIF INTE, P2835
   Wang LT, 2020, IEEE ACCESS, V8, P25964, DOI 10.1109/ACCESS.2020.2968391
   Wang SM, 2017, DESTECH TRANS SOC, P1
   Yu CM, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102738
   Zhang ZS, 2020, AAAI CONF ARTIF INTE, V34, P9628
   Zhou GY, 2016, KNOWL-BASED SYST, V93, P75, DOI 10.1016/j.knosys.2015.11.002
   Zhou QF, 2021, INFORM SCIENCES, V543, P259, DOI 10.1016/j.ins.2020.07.048
   Zilly JG, 2017, PR MACH LEARN RES, V70
NR 41
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10881
EP 10898
DI 10.1007/s11042-023-15974-x
EA JUN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019903000009
DA 2024-07-18
ER

PT J
AU Wang, L
   He, K
   Liu, ZK
AF Wang, Lei
   He, Kai
   Liu, Zikang
TI MCS: a metric confidence selection framework for few shot image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Few shot learning; Metric confidence selection; Classification
   framework; Deep learning
ID NONLINEAR DIMENSIONALITY REDUCTION
AB In the field of image classification, few shot learning (FSL) is to identify the new samples for each category using the extremely limited data. Due to lacking of data, FSL was usually performed by optimizing network or searching for new measurement methods. However, these mechanisms may fail to obtain enough information from the limited test data and then lack of learning ability. To address this problem, we attempt to obtain more information from the unlabeled data using the pseudo labels. In order to improve the reliability of selecting pseudo label data, we propose a new sample selection strategy, named Metric Confidence Selection (MCS), which is more conducive to select the most reliable pseudo-label data. In addition, we propose a new framework to combine our MCS and metric learning together. Our framework tends to get more information from the unlabeled samples, which is helpful to improve utilization efficiency. Extensive experiments on four widely-used benchmark datasets show that our proposed method surpass most state-of-the-art ones in few shot image classification.
C1 [Wang, Lei; He, Kai; Liu, Zikang] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP He, K (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM wl0103@tju.edu.cn; hekai@tju.edu.cn; Zikang_Liu@tju.edu.cn
RI Wang, Lei/A-7836-2018
OI Wang, Lei/0000-0003-1802-7466
FU National Natural Science Foundation of China [62171314]
FX This study was supported by the National Natural Science Foundation of
   China (No. 62171314), and the recipient of the support was Kai He.
CR Abdelaziz M, 2022, MULTIMED TOOLS APPL, V81, P6703, DOI 10.1007/s11042-021-11735-w
   Abdelaziz M, 2021, MULTIMED TOOLS APPL, V80, P10491, DOI 10.1007/s11042-020-09875-6
   Alvarez M, 2006, LECT NOTES COMPUT SC, V4232, P747
   [Anonymous], 2007, P 24 INT C MACHINE L, DOI DOI 10.1145/1273496.1273592
   [Anonymous], 2018, SEMANTIC FEATURE AUG
   Cai Q, 2018, PROC CVPR IEEE, P4080, DOI 10.1109/CVPR.2018.00429
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen W.Y., 2019, ICLR, DOI DOI 10.1109/MSR.2015.54
   Chen ZY, 2021, PROC CVPR IEEE, P13658, DOI 10.1109/CVPR46437.2021.01345
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Chi Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12200, DOI 10.1109/CVPR42600.2020.01222
   Choi J, 2018, PROC CVPR IEEE, P3627, DOI 10.1109/CVPR.2018.00382
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   De Maesschalck R, 2000, CHEMOMETR INTELL LAB, V50, P1, DOI 10.1016/S0169-7439(99)00047-7
   Fei-Fei L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1134, DOI 10.1109/ICCV.2003.1238476
   Finn C, 2017, PR MACH LEARN RES, V70
   Garcia V, 2017, ARXIV
   Gidaris S, 2019, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2019.00011
   Han-Jia Ye, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8805, DOI 10.1109/CVPR42600.2020.00883
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lake B., 2011, P ANN M COGNITIVE SC, P1
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Lee K, 2019, PROC CVPR IEEE, P10649, DOI 10.1109/CVPR.2019.01091
   Li HT, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317874
   Li WB, 2019, PROC CVPR IEEE, P7253, DOI 10.1109/CVPR.2019.00743
   Li WB, 2019, AAAI CONF ARTIF INTE, P8642
   Li YJ, 2019, PR MACH LEARN RES, V97
   Lifchitz Y, 2019, PROC CVPR IEEE, P9250, DOI 10.1109/CVPR.2019.00948
   Liu YH, 2019, INT J PSYCHIAT CLIN, V23, P164, DOI 10.1080/13651501.2019.1569238
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma Y, 2021, INT J OSTEOARCHAEOL, P1
   Mangla P, 2020, IEEE WINT CONF APPL, P2207, DOI [10.1109/wacv45572.2020.9093338, 10.1109/WACV45572.2020.9093338]
   Miller A., 2016, P 2016 C EMP METH NA, P1400, DOI DOI 10.18653/V1/D16-1147
   Mishra N., 2018, INT C LEARNING REPRE
   Munkhdalai T., 2018, INT C MACH LEARN, P3664
   Munkhdalai T, 2017, PR MACH LEARN RES, V70
   Oreshkin BN, 2018, ADV NEUR IN, V31
   Qiao SY, 2018, PROC CVPR IEEE, P7229, DOI 10.1109/CVPR.2018.00755
   Ravi S., 2016, INT C LEARNING REPRE
   Ravichandran A, 2019, IEEE I CONF COMP VIS, P331, DOI 10.1109/ICCV.2019.00042
   Ren M., 2018, INT C LEARNING REPRE, DOI DOI 10.1109/IPFA.2018.8452547
   Rizve MN, 2021, PROC CVPR IEEE, P10831, DOI 10.1109/CVPR46437.2021.01069
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Rusu A.A., 2018, INT C LEARNING REPRE
   Simon C, 2020, PROC CVPR IEEE, P4135, DOI 10.1109/CVPR42600.2020.00419
   Snell J, 2017, ADV NEUR IN, V30
   Sun QR, 2019, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.2019.00049
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Thrun S, 1998, LEARNING TO LEARN, P181
   Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196
   Vilalta R, 2002, ARTIF INTELL REV, V18, P77, DOI 10.1023/A:1019956318069
   Vinyals O., 2016, ADV NEURAL INFORM PR, P3630, DOI DOI 10.48550/ARXIV.1606.04080
   Wah C, 2011, CALTECH UCSD BIRDS 2
   Wertheimer D, 2021, PROC CVPR IEEE, P8008, DOI 10.1109/CVPR46437.2021.00792
   Ye H-J, 2018, LEARNING EMBEDDING A
   Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154
   Zhong XG, 2021, NEUROCOMPUTING, V437, P206, DOI 10.1016/j.neucom.2021.01.029
   Zhou F., 2018, arXiv
NR 60
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10865
EP 10880
DI 10.1007/s11042-023-15892-y
EA JUN 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019903000005
DA 2024-07-18
ER

PT J
AU González-Villa, J
   Cuesta, A
   Spagnolo, M
   Zanotti, M
   Summers, L
   Elms, A
   Dhaya, A
   Jedlicka, K
   Martolos, J
   Cetinkaya, D
AF Gonzalez-Villa, Javier
   Cuesta, Arturo
   Spagnolo, Marco
   Zanotti, Marisa
   Summers, Luke
   Elms, Alexander
   Dhaya, Anay
   Jedlicka, Karel
   Martolos, Jan
   Cetinkaya, Deniz
TI Decision-support system for safety and security assessment and
   management in smart cities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Decision Support System; Evacuation; Fire and Smoke; Security and
   Safety; Simulation; Terrorism; Threats; Traffic
ID EQUILIBRIUM; CITY
AB Counter-terrorism measures and preparedness play a critical role in securing mass gatherings, soft targets, and critical infrastructures within urban environments. This paper introduces a comprehensive Decision Support System developed as part of the S4AllCitites project, designed to seamlessly integrate with existing legacy systems in Smart Cities. The system encompasses urban pedestrian and vehicular evacuation, incorporating predictive models to anticipate the progression of incendiary and mass shooting attacks, alongside a probabilistic model for threat assessment in the case of improvised explosive devices. A notable achievement of this research is the successful implementation and deployment of the system in operational environments through pilot studies. It empowers public and private security operators with real time decision support capabilities during both prevention and intervention stages of potential attacks. The decision support information provided encompasses various aspects, including optimal evacuation strategies, estimated egress times, pedestrian movement profiles, probability assessments, and the potential impact of different terrorist threats in terms of casualties. Additionally, the system offers real-time insights into the status of the traffic network under normal and unusual conditions, enabling efficient emergency management throughout its progression. This includes the ability to identify optimal intervention routes and assess the impact of anomalous traffic resulting from evacuations.
C1 [Gonzalez-Villa, Javier; Cuesta, Arturo] Univ Cantabria, GIDAI Grp, Santander, Spain.
   [Spagnolo, Marco; Zanotti, Marisa] EnginSoft SPA, Trento, Italy.
   [Summers, Luke; Elms, Alexander; Dhaya, Anay] Crowd Dynam Int Ltd, Oxted, England.
   [Jedlicka, Karel] Univ West Bohemia, Plzen, Czech Republic.
   [Martolos, Jan] Plan4All Zs, Horni Briza, Czech Republic.
   [Cetinkaya, Deniz] Bournemouth Univ, Dept Comp & Informat, Poole, England.
C3 Universidad de Cantabria; University of West Bohemia Pilsen; Bournemouth
   University
RP González-Villa, J (corresponding author), Univ Cantabria, GIDAI Grp, Santander, Spain.
EM javier.gonzalezvilla@unican.es
RI Jedlička, Karel/E-6774-2013; cuesta, arturo/K-2246-2014
OI Jedlička, Karel/0000-0001-7399-6951; cuesta, arturo/0000-0002-6366-3982;
   Cetinkaya, Deniz/0000-0002-1047-0685; Gonzalez-Villa,
   Javier/0000-0001-8602-908X; Spagnolo, Marco/0000-0002-5434-607X
FU European Union [883522]
FX The project (S4AllCities) has received funding from the European Union's
   H2020 research and innovation programme under grant agreement No. 883522
CR Abreu O, 2019, SAFETY SCI, V120, P941, DOI 10.1016/j.ssci.2019.08.038
   [Anonymous], 2016, J POLIC INTELL COUNT
   [Anonymous], 2017, 2017 INT SMART CITIE
   Bellini P, 2017, J VISUAL LANG COMPUT, V42, P31, DOI 10.1016/j.jvlc.2017.08.005
   Bonatsos A, 2013, IFIP ADV INF COMM TE, V413, P311
   Cuesta A, 2019, SAFETY SCI, V120, P877, DOI 10.1016/j.ssci.2019.08.019
   DAFERMOS S, 1980, TRANSPORT SCI, V14, P42, DOI 10.1287/trsc.14.1.42
   Dbouk M, 2014, PROCEDIA COMPUT SCI, V37, P72, DOI 10.1016/j.procs.2014.08.014
   Dial RB, 2006, TRANSPORT RES B-METH, V40, P917, DOI 10.1016/j.trb.2006.02.008
   EUROPOL, 2022, EUROPEAN UNION TERRO
   Fernández J, 2013, SENSORS-BASEL, V13, P7414, DOI 10.3390/s130607414
   Global Terrorism Database (GTD), 2022, ABOUT US
   Hartama D., 2018, 2017 2 INT C INFORMA, DOI [10.1109/IAC.2017.8280607, DOI 10.1109/IAC.2017.8280607]
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Herath H., 2022, INT J INFORM MANAGEM, V2, DOI DOI 10.1016/J.JJIMEI.2022.100076
   Jayakrishnan R., 1994, A faster path-based algorithm for traffic assignment
   Jedlicka K, 2020, INT CONF CARTOGR GIS, P510
   Keenan PB, 2019, DECIS SUPPORT SYST, V116, P64, DOI 10.1016/j.dss.2018.10.010
   Kolovsky F, 2018, INT C MATH APPL, P17
   Laufs J, 2020, SUSTAIN CITIES SOC, V55, DOI 10.1016/j.scs.2020.102023
   Martin R. H., 2016, Forensic Research & Criminology International Journal, V3, P1
   Mcgrattan K., 2013, Fire Dynamics Simulator technical reference guide: Validation
   McGrattan K, 2013, VERIFICATION, V2
   Mcgrattan K.B., 2017, Fire Dynamics Simulator Users Guide, V6th, DOI [DOI 10.6028/NIST.SP.1019, 10.6028/NIST.SP.1019]
   Mihinjac M, 2019, SOC SCI-BASEL, V8, DOI 10.3390/socsci8060182
   Nie Y, 2010, TRANSPORT RES B-METH, V44, P73, DOI 10.1016/j.trb.2009.06.005
   Noor NMM, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P225, DOI 10.1109/IC3INA.2013.6819178
   Ortuzar JD, 2011, MODELLING TRANSPORT, 4TH EDITION
   Peto R, 2019, INTERDISCIP DESCR CO, V17, P13, DOI 10.7906/indecs.17.1.3
   Potuzak T, 2022, AIN SHAMS ENG J, V13, DOI 10.1016/j.asej.2021.09.003
   SMITH MJ, 1979, TRANSPORT RES B-METH, V13, P295, DOI 10.1016/0191-2615(79)90022-5
   Spiess H., 1990, A Gradient Approach for the OD Matrix Adjustment Problem
   Truntsevsky YV, 2018, MATEC WEB CONF, V170, DOI 10.1051/matecconf/201817001067
   Tuman JosephS., 2009, Communicating Terror: The Rhetorical Dimensions of Terrorism, V2nd
   Turban E., 1995, Decision support and expert systems: management support systems, V14th
   Ullah F, 2021, TECHNOL FORECAST SOC, V167, DOI 10.1016/j.techfore.2021.120743
   Wardrop J., 1952, P I CIVIL ENG, V1, P325, DOI [10.1680/ipeds.1952.11259, DOI 10.1680/IPEDS.1952.11259]
   Zhang WX, 2018, WINT SIMUL C PROC, P2803, DOI 10.1109/WSC.2018.8632176
NR 38
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 23
PY 2023
DI 10.1007/s11042-023-16020-6
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K2IG6
UT WOS:001014722500007
OA hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Yu, Y
   Chen, WX
   Chen, FX
   Jia, W
   Lu, Q
AF Yu, Ye
   Chen, Weixiao
   Chen, Fengxin
   Jia, Wei
   Lu, Qiang
TI Night-time vehicle model recognition based on domain adaptation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Night-time Vehicle Model Recognition (NVMR); Generative adversarial
   networks; Domain adaptation; Image decomposition
ID HISTOGRAM EQUALIZATION; ENHANCEMENT; ATTENTION
AB Owing to the low brightness, low contrast, and high labeling difficulty of night-time vehicle images, night-time vehicle model recognition (NVMR) faces significant challenges. To address these challenges, this paper proposes the Night-time Vehicle Model Recognition (DA-NVMR) method based on domain adaptation theory and Generative Adversarial Networks (GANs). The proposed method realizes the NVMR based on the VMR model trained on daytime vehicle images. In DA-NVMR, a Domain Adaption Network (DANet) is designed to find the mapping between night-time vehicle images and daytime vehicle images. The DANet consists of two modules: the decomposition module and conversion module. The decomposition module decomposes the vehicle images into reflectance images and illumination images. The conversion module realizes the conversion between the illumination of the night-time and daytime vehicle images. Experiments based on the simulated night-time vehicle dataset and real night-time vehicle dataset confirmed that DA-NVMR can effectively identify night-time vehicle models. Compared with other low-light image enhancement methods and domain adaptation methods, the Top-1 recognition accuracy of the proposed method improved by at least 2% and 1%, respectively.
C1 [Yu, Ye] Hefei Univ Technol, Key Lab Knowledge Engn Big Data, Minist Educ, Hefei 230009, Peoples R China.
   [Yu, Ye; Chen, Weixiao; Chen, Fengxin; Jia, Wei; Lu, Qiang] Hefei Univ Technol, Sch Comp Sci & Informat, Hefei 230009, Peoples R China.
C3 Hefei University of Technology; Hefei University of Technology
RP Jia, W (corresponding author), Hefei Univ Technol, Sch Comp Sci & Informat, Hefei 230009, Peoples R China.
EM yuye@hfut.edu.cn; 379879455@qq.com; 1508298240@qq.com;
   china.jiawei@139.com; luqiang@hfut.edu.cn
RI WANG, YANG/JFA-8821-2023; Yang, Jing/JFK-4046-2023; liu,
   lin/JFK-3401-2023; qi, li/JFE-7167-2023; li, yurong/JMQ-8540-2023; YI,
   J/JJE-7713-2023; Liu, Yuan/JFB-4766-2023; Liu, yujing/JQI-7225-2023;
   Yang, Mei/JNS-2225-2023; Yu, Ye/JDX-1258-2023; Zhang, Han/JMR-0670-2023;
   Zhang, Yanyan/JFA-9161-2023; Yu, ZH/KBC-6889-2024; Chen,
   Yu/JLL-0171-2023; Wang, Han/JJF-2614-2023
OI Yang, Jing/0009-0004-8274-9863; 
FU National Natural Science Foundation of China [62076086, 61906061]; Key
   Research and Development Program in Anhui Province [202004d07020008];
   Scientific and Technological Achievements Cultivation Project of
   Intelligent Manufacturing Institute of HFUT [IMIPY2021022]
FX AcknowledgementsThis study was partly supported by grants from the
   National Natural Science Foundation of China (No.62076086 and
   No.61906061), Key Research and Development Program in Anhui Province
   (No.202004d07020008), and Scientific and Technological Achievements
   Cultivation Project of Intelligent Manufacturing Institute of HFUT (No.
   IMIPY2021022).
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   Anoosheh A, 2019, IEEE INT CONF ROBOT, P5958, DOI [10.1109/ICRA.2019.8794387, 10.1109/icra.2019.8794387]
   Borgwardt KM, 2006, BIOINFORMATICS, V22, pE49, DOI 10.1093/bioinformatics/btl242
   Castellano G, 2020, IEEE ACCESS, V8, P64534, DOI 10.1109/ACCESS.2020.2984768
   Chen C, 2019, IEEE I CONF COMP VIS, P3184, DOI 10.1109/ICCV.2019.00328
   Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347
   Chen Wei WYJL, 2018, BRIT MACHINE VISION
   Fang J, 2017, IEEE T INTELL TRANSP, V18, P1782, DOI 10.1109/TITS.2016.2620495
   Fregier Y, 2019, ARXIV
   Ganin Y, 2016, J MACH LEARN RES, V17
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He HS, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2437998
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hines G, 2005, GLOB SIGN PROC C
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Juefei-Xu F, 2017, ARXIV
   Ke X, 2020, NEUROCOMPUTING, V399, P247, DOI 10.1016/j.neucom.2020.02.101
   Krause J, 2014, INT C PATT RECOG, P26, DOI 10.1109/ICPR.2014.15
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lee S, 2019, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2019.00018
   [李萍 Li Ping], 2020, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V33, P1
   Li Y., 2019, ARXIV
   Lin YL, 2014, LECT NOTES COMPUT SC, V8692, P466, DOI 10.1007/978-3-319-10593-2_31
   Llorca DF, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P3094, DOI 10.1109/ITSC.2014.6958187
   Long M, 2017, ARXIV
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Nadeem Z, 2022, MULTIMED TOOLS APPL, V81, P8429, DOI 10.1007/s11042-022-12177-8
   Pizer S. M., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P337, DOI 10.1109/VBC.1990.109340
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Rahman MM, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107124
   Rahman MM, 2019, IEEE WINT CONF APPL, P579, DOI 10.1109/WACV.2019.00067
   Rahman Z, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P1003, DOI 10.1109/ICIP.1996.560995
   Rassem TH, 2015, MULTIMED TOOLS APPL, V74, P11357, DOI 10.1007/s11042-014-2235-4
   Rodriguez A. L., 2019, ARXIV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shen L., 2017, ARXIV
   Shi Y, 2019, ARXIV
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sochor J, 2019, IEEE T INTELL TRANSP, V20, P97, DOI 10.1109/TITS.2018.2799228
   Sochor J, 2016, PROC CVPR IEEE, P3006, DOI 10.1109/CVPR.2016.328
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Thamizhvani TR, 2021, MULTIMED TOOLS APPL, V80, P12117, DOI 10.1007/s11042-020-10459-7
   Wang P, 2021, MULTIMED TOOLS APPL, V80, P17705, DOI 10.1007/s11042-021-10607-7
   Wang WJ, 2018, IEEE INT CONF AUTOMA, P751, DOI 10.1109/FG.2018.00118
   Wang Y, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-021-3383-y
   Wang Y, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3447530
   Wang Z., 2019, arXiv
   Xue H, 2021, MULTIMED TOOLS APPL, V80, P19057, DOI 10.1007/s11042-021-10611-x
   Yan K, 2018, IEEE T CYBERNETICS, V48, P288, DOI 10.1109/TCYB.2016.2633306
   Yan LY, 2021, MULTIMED TOOLS APPL, V80, P14363, DOI 10.1007/s11042-020-10310-z
   Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023
   Ying ZQ, 2017, LECT NOTES COMPUT SC, V10425, P36, DOI 10.1007/978-3-319-64698-5_4
   Yu CH, 2019, IEEE DATA MINING, P778, DOI 10.1109/ICDM.2019.00088
   Yu CM, 2019, INT J AEROSPACE ENG, V2019, DOI [10.1155/2019/1414279, 10.1109/ichi.2019.8904645]
   Zhang W.-D, 2020, 2020 45th International Conference on Infrared, Millimeter, and Terahertz Waves (IRMMW-THz), DOI 10.1109/IRMMW-THz46771.2020.9370821
   Zhang YB, 2019, PROC CVPR IEEE, P5026, DOI 10.1109/CVPR.2019.00517
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926
   Zhao DB, 2017, IEEE T COGN DEV SYST, V9, P356, DOI 10.1109/TCDS.2016.2614675
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu YC, 2019, NEURAL NETWORKS, V119, P214, DOI 10.1016/j.neunet.2019.07.010
   Zhuang PX, 2020, MULTIMED TOOLS APPL, V79, P17257, DOI 10.1007/s11042-019-08404-4
NR 65
TC 2
Z9 2
U1 5
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9577
EP 9596
DI 10.1007/s11042-023-15447-1
EA JUN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001014467700001
DA 2024-07-18
ER

PT J
AU Lawal, OM
AF Lawal, Olarewaju Mubashiru
TI Study on strawberry fruit detection using lightweight algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE YOLOStrawberry; Fruit detection; Lightweight; Detection performance;
   Mobile-phone application
ID TIME
AB A quicker and easier decision-making detection algorithm is important for mobile-phone application to support strawberry management. However, lightweight is a big challenge, including accuracy, speed, and complex conditions confronted by the fruit detection algorithm. For this reason, a lightweight YOLOStrawberry was proposed in this paper based on modified YOLOv5 architecture and compared to other YOLO-lightweight algorithms. YOLOStrawberry incorporated Conv_Maxpool, Shuffle_Block, ResNet, SElayer and SPPF as Backbone network, FPN as Neck network, and CIoU loss function to improve the detection performance of strawberry fruit. The obtained weight-size of YOLOStrawberry is 3.37 MB, which is in third position compared to 1.57 MB for v5lite-e, 3.19 MB for v5lite-s, 3.56 MB for YOLOv5n, 8.60 MB for v5lite-c and 10.7 MB for v5lite-g. Nevertheless, the required trained time for YOLOStrawberry is 0.93%, 0.69%, 0.62%, 0.71%, 1.14% less than v5lite-c, v5lite-e, v5lite-g, v5lite-s and YOLOv5n, respectively. Meanwhile, the average precision (AP) detection level is measured as 89.7% of YOLOStrawberry is 0.4%, 0.7%, 3%, 3.4% and 9.1% more accurate than v5lite-g, YOLOv5n, v5lite-c, v5lite-s and v5lite-e, respectively. Furthermore, the tested speed time of YOLOStrawberry is 7.30 ms, faster compared to 11.7 ms for YOLOv5n, 13.2 ms for v5lite-g, 13.3 ms for v5lite-e, 14.0 ms for v5lite-s, and 16.2 ms for v5lite-c. Therefore, YOLOStrawberry algorithm is lightweight, robust, accurate, fast, applicable to mobile-phone for real-time and extendable to other fruits for detection.
C1 [Lawal, Olarewaju Mubashiru] Yibin Univ, Sanjiang Inst Artificial Intelligence & Robot, Sichuan 644000, Peoples R China.
C3 Yibin University
RP Lawal, OM (corresponding author), Yibin Univ, Sanjiang Inst Artificial Intelligence & Robot, Sichuan 644000, Peoples R China.
EM olarewajulawal@yahoo.com
FU Sanjiang Institute of Artificial Intelligence and Robotics; Yibin
   University; Shanxi Agricultural University Science and Technology
   Innovation Fund Project in collaboration with Natural Science Foundation
   of Shanxi Province, China [2020BQ34]
FX This research work was funded by Sanjiang Institute of Artificial
   Intelligence and Robotics, Yibin University, and Shanxi Agricultural
   University Science and Technology Innovation Fund Project in
   collaboration with Natural Science Foundation of Shanxi Province, China
   under Grant No. 2020BQ34.
CR Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Elfwing S, 2017, ARXIV
   Fu LH, 2022, AGRONOMY-BASEL, V12, DOI 10.3390/agronomy12020391
   Gevorgyan Z, 2022, arXiv
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jocher G., 2020, YOLOv5
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kamilaris A, 2018, J AGR SCI-CAMBRIDGE, V156, P312, DOI 10.1017/S0021859618000436
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Lawal MO, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-81216-5
   Lawal O. M., 2021, IOP Conference Series: Earth and Environmental Science, V922
   Lawal OM, 2021, IEEE ACCESS, V9, P15221, DOI 10.1109/ACCESS.2021.3053167
   Lawal OM, 2021, IET IMAGE PROCESS, V15, P3071, DOI 10.1049/ipr2.12293
   Lawal OM, 2021, MULTIMED TOOLS APPL, V80, P26751, DOI 10.1007/s11042-021-10933-w
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Ma Ningning, 2018, P EUR C COMP VIS ECC, DOI [10.1007/978-3-030-01264-9_8, DOI 10.1007/978-3-030-01264-9_8]
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Qiao YC, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12122071
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Weng SZ, 2020, INT J FOOD PROP, V23, P269, DOI 10.1080/10942912.2020.1716793
   Xu DF, 2023, AGRONOMY-BASEL, V13, DOI 10.3390/agronomy13020451
   Yan B, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13091619
   Yao J, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10141711
   Zhang B, 2022, FRONT PLANT SCI, V13, DOI 10.3389/fpls.2022.1040923
   Zhang WL, 2021, FRONT PLANT SCI, V12, DOI 10.3389/fpls.2021.740936
   Zheng Z, 2019, ARXIV
NR 30
TC 1
Z9 1
U1 9
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8281
EP 8293
DI 10.1007/s11042-023-16034-0
EA JUN 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012326000001
DA 2024-07-18
ER

PT J
AU Aldin, SSAB
   Aykaç, M
   Aldin, NB
AF Aldin, Shaima Safa Aldin Baha
   Aykac, Mahmut
   Aldin, Noor Baha
TI Quad-color image encryption based on Chaos and Fibonacci Q-matrix
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quad-color fusion; Segmentation; Random assembling; FQ-matrix;
   Hyperchaotic system
ID ALGORITHM; SYSTEM; MAP
AB The Information technology requires the transmission of daily-life images that may reach to millions or even more. Thus, securing them becomes an urgent matter using the encryption technique. Where, a secret key is used for converting the original image into a noisy one and restoring it back using the same key. Confusion and Diffusion are the wildly used steps in such a technique. Therefore, a new algorithm is presented in this work that uses a fusion, segmentation, random assembling, hyperchaotic and Fibonacci Q-matrix (FQ-matrix). A novel fusion method is designed for fusing four color images into four different sequences according to their contained information. Then the resulted four images are each divided into four segments to be assembled randomly into one image using a random-key; which confused later using a six-dimensional hyperchaotic system and diffused using the FQ-matrix. The performance and robustness of the proposed algorithm have been computed based on different tests; where it proved its powerful capability in securing the transmitted images.
C1 [Aldin, Shaima Safa Aldin Baha] Al Nahrain Univ, Continuing Educ Ctr, Baghdad, Iraq.
   [Aykac, Mahmut] Gaziantep Univ, Dept Elect & Elect Engn, Gaziantep, Turkiye.
   [Aldin, Noor Baha] Hasan Kalyoncu Univ, Dept Elect & Elect Engn, Gaziantep, Turkiye.
C3 Al-Nahrain University; Gaziantep University; Hasan Kalyoncu University
RP Aldin, SSAB (corresponding author), Al Nahrain Univ, Continuing Educ Ctr, Baghdad, Iraq.
EM shaima.safaaldin@nahrainuniv.edu.iq; maykac@gantep.edu.tr;
   noor.aldin@hku.edu.tr
RI Baha aldin, Shaima safa aldin/V-3616-2019; BAHA ALDIN,
   NOOR/JES-2617-2023; AYKAÇ, Mahmut/JOJ-8225-2023
OI Baha aldin, Shaima safa aldin/0000-0003-0911-6934; BAHA ALDIN,
   NOOR/0000-0002-7351-4083; AYKAÇ, Mahmut/0000-0003-2977-9719
CR Abdel-Aziz MM, 2021, MULTIMED TOOLS APPL, V80, P12641, DOI 10.1007/s11042-020-10217-9
   Artiles JAP, 2019, SIGNAL PROCESS-IMAGE, V79, P24, DOI 10.1016/j.image.2019.08.014
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Enayatifar R, 2019, OPT LASER ENG, V115, P131, DOI 10.1016/j.optlaseng.2018.11.017
   Hao J, 2022, MULTIMED TOOLS APPL, V81, P559, DOI 10.1007/s11042-021-11431-9
   He Y, 2020, NEURAL COMPUT APPL, V32, P247, DOI 10.1007/s00521-018-3577-z
   Hosny KM, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3325193
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Laiphrakpam DS, 2017, OPTIK, V147, P88, DOI 10.1016/j.ijleo.2017.08.028
   Li M, 2019, IEEE ACCESS, V7, P145798, DOI 10.1109/ACCESS.2019.2945578
   Li N, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107476
   Li YH, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5182
   Luo YL, 2018, NONLINEAR DYNAM, V93, P1165, DOI 10.1007/s11071-018-4251-9
   Molina-Garcia J, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115725
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Premkumar R, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22208044
   Ran B, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24070958
   Sahasrabuddhe A, 2021, INFORM SCIENCES, V550, P252, DOI 10.1016/j.ins.2020.10.031
   Shu XB, 2018, IEEE T PATTERN ANAL, V40, P905, DOI 10.1109/TPAMI.2017.2705122
   Shu XB, 2015, IEEE I CONF COMP VIS, P3970, DOI 10.1109/ICCV.2015.452
   Wang J, 2019, INT J CIRC THEOR APP, V47, P702, DOI 10.1002/cta.2617
   Wang XY, 2021, INFORM SCIENCES, V574, P505, DOI 10.1016/j.ins.2021.06.032
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Yan WH, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23091221
   Ye Guodong, 2022, Alexandria Engineering Journal, V61, P6785, DOI 10.1016/j.aej.2021.12.023
   Ye GD, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107563
   Ye HS, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107652
   Yu SS, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105816
   Zhang XQ, 2021, OPT LASER TECHNOL, V141, DOI 10.1016/j.optlastec.2021.107073
   Zhang XQ, 2019, MULTIMED TOOLS APPL, V78, P7841, DOI 10.1007/s11042-018-6496-1
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P21589, DOI 10.1007/s11042-017-5585-x
   Zhou NR, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-017-1612-0
   Zhou TQ, 2020, FUTURE GENER COMP SY, V108, P1307, DOI 10.1016/j.future.2018.04.008
NR 35
TC 1
Z9 1
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7827
EP 7846
DI 10.1007/s11042-023-15958-x
EA JUN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001006598900006
DA 2024-07-18
ER

PT J
AU Sitaula, C
   Shahi, TB
   Marzbanrad, F
   Aryal, J
AF Sitaula, Chiranjibi
   Shahi, Tej Bahadur
   Marzbanrad, Faezeh
   Aryal, Jagannath
TI Recent advances in scene image representation and classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Classification; Deep learning; Machine learning; Scene
   image representation
ID OBJECT; FEATURES; FUSION; MODEL
AB With the rise of deep learning algorithms nowadays, scene image representation methods have achieved a significant performance boost, particularly in accuracy, in classification. However, the performance is still limited because the scene images are mostly complex having higher intra-class dissimilarity and inter-class similarity problems. To deal with such problems, there have been several methods proposed in the literature with their advantages and limitations. A detailed study of previous works is necessary to understand their advantages and disadvantages in image representation and classification problems. In this paper, we review the existing scene image representation methods that are being widely used for image classification. For this, we, first, devise the taxonomy using the seminal existing methods proposed in the literature to this date using deep learning (DL)-based, computer vision (CV)-based, and search engine (SE)-based methods. Next, we compare their performance both qualitatively (e.g., quality of outputs, pros/cons, etc.) and quantitatively (e.g., accuracy). Last, we speculate on the prominent research directions in scene image representation tasks using keyword growth and timeline analysis. Overall, this survey provides in-depth insights and applications of recent scene image representation methods under three different methods.
C1 [Sitaula, Chiranjibi; Marzbanrad, Faezeh] Monash Univ, Dept Elect & Comp Syst Engn, Wellington Rd, Clayton, VIC 3800, Australia.
   [Shahi, Tej Bahadur] Cent Queensland Univ, Sch Engn & Technol, Rockhampton, QLD 4701, Australia.
   [Shahi, Tej Bahadur] Tribhuvan Univ, Cent Dept Comp Sci & Informat Technol CDCSIT, TU Rd,Kirtipur, Kathmandu 44618, Nepal.
   [Aryal, Jagannath] Univ Melbourne, Dept Infrastructure Engn, Parkville, VIC 3010, Australia.
C3 Monash University; Central Queensland University; Tribhuvan University;
   University of Melbourne
RP Sitaula, C (corresponding author), Monash Univ, Dept Elect & Comp Syst Engn, Wellington Rd, Clayton, VIC 3800, Australia.
EM chiranjibi.sitaula@monash.edu
RI Aryal, Jagannath/E-8529-2012; Shahi, Tej Bahadur/AAG-2552-2020; Sitaula,
   Chiranjibi/AAQ-8207-2021
OI Shahi, Tej Bahadur/0000-0002-0616-3180; Sitaula,
   Chiranjibi/0000-0002-4564-2985
CR Ali N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203339
   [Anonymous], 2010, Advances in Neural Information Processing Systems
   Anu E., 2016, INT J SCI ENG TECHNO, V5, P64
   Aria M, 2017, J INFORMETR, V11, P959, DOI 10.1016/j.joi.2017.08.007
   Ayalew AM, 2022, BIOMED SIGNAL PROCES, V74, DOI 10.1016/j.bspc.2022.103530
   Bai S, 2019, EXPERT SYST APPL, V120, P298, DOI 10.1016/j.eswa.2018.08.056
   Bai S, 2017, EXPERT SYST APPL, V71, P279, DOI 10.1016/j.eswa.2016.10.038
   Banerji S., 2012, 2012 IEEE International Conference on Intelligent Computer Communication and Processing (ICCP 2012). Proceedings, P245, DOI 10.1109/ICCP.2012.6356193
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Chen GW, 2020, IEEE T IMAGE PROCESS, V29, P5877, DOI 10.1109/TIP.2020.2986599
   Chen HY, 2018, MULTIMED TOOLS APPL, V77, P4081, DOI 10.1007/s11042-017-4830-7
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Cheng XJ, 2018, PATTERN RECOGN, V74, P474, DOI 10.1016/j.patcog.2017.09.025
   Choe S, 2022, IEEE T CYBERNETICS, V52, P7265, DOI 10.1109/TCYB.2021.3052499
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dixit M, 2020, IEEE T PATTERN ANAL, V42, P3102, DOI 10.1109/TPAMI.2019.2921960
   Dixit M, 2015, PROC CVPR IEEE, P2974, DOI 10.1109/CVPR.2015.7298916
   Dutta R, 2013, SCI REP-UK, V3, DOI 10.1038/srep03188
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Fornoni M, 2014, INT C PATT RECOG, P3404, DOI 10.1109/ICPR.2014.586
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Griffin G., 2007, CALTECH 256 OBJECT C
   Guo S, 2017, IEEE T IMAGE PROCESS, V26, P808, DOI 10.1109/TIP.2016.2629443
   Guo Y, 2016, P BRIT MACH VIS C BM
   Gupta SK, 2021, MANAG ENVIRON QUAL, V32, P1, DOI 10.1108/MEQ-01-2021-290
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu JL, 2012, 2012 6TH INTERNATIONAL CONFERENCE ON SCIENCES OF ELECTRONICS, TECHNOLOGIES OF INFORMATION AND TELECOMMUNICATIONS (SETIT), P326, DOI 10.1109/SETIT.2012.6481936
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang SQ, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3231738
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Juneja M, 2013, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2013.124
   Khan A, 2021, NEUROCOMPUTING, V440, P111, DOI 10.1016/j.neucom.2021.01.085
   Khan SH, 2016, IEEE T IMAGE PROCESS, V25, P3372, DOI 10.1109/TIP.2016.2567076
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuzborskij I, 2016, PROC CVPR IEEE, P2100, DOI 10.1109/CVPR.2016.231
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li L.-j., 2010, NIPS
   Li LJ, 2007, IEEE I CONF COMP VIS, P345
   Li Q, 2013, IEEE IMAGE PROC, P3254, DOI 10.1109/ICIP.2013.6738670
   Li Q, 2013, IEEE SIGNAL PROC LET, V20, P67, DOI 10.1109/LSP.2012.2228852
   Lin CW, 2021, CMES-COMP MODEL ENG, V128, P985, DOI 10.32604/cmes.2021.014522
   Lin D, 2014, PROC CVPR IEEE, P3726, DOI 10.1109/CVPR.2014.476
   Lin TY, 2018, IEEE T PATTERN ANAL, V40, P1309, DOI 10.1109/TPAMI.2017.2723400
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liu S, 2019, J ROBOT, V2019
   Liu SP, 2022, IEEE T MULTIMEDIA, V24, P2392, DOI 10.1109/TMM.2021.3080076
   Liu SP, 2019, NEUROCOMPUTING, V338, P191, DOI 10.1016/j.neucom.2019.01.090
   Liu WH, 2019, IEEE ACCESS, V7, P4629, DOI 10.1109/ACCESS.2018.2886597
   López-Cifuentes A, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107256
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Margolin R, 2014, LECT NOTES COMPUT SC, V8695, P377, DOI 10.1007/978-3-319-10584-0_25
   McCulloch WS, 2016, EMBODIMENTS OF MIND, P19
   Moller T, 1997, IEEE T VIS COMPUT GR, V3, P184, DOI 10.1109/2945.597800
   Nascimento G, 2017, ARXIV
   Neupane B, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13040808
   Niu Z, 2010, 2010 25 INT C IM VIS, P1
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Oliva Aude, 2005, P251, DOI 10.1016/B978-012375731-9/50045-8
   Parizi SN, 2012, PROC CVPR IEEE, P2775, DOI 10.1109/CVPR.2012.6248001
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Qi MS, 2016, IEEE IMAGE PROC, P1047, DOI 10.1109/ICIP.2016.7532517
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Rasiwasia N, 2008, PROC CVPR IEEE, P243
   Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999
   Ringnér M, 2008, NAT BIOTECHNOL, V26, P303, DOI 10.1038/nbt0308-303
   Roodposhti MS, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21010078
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Shahi TB, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0264586
   Shahi TB, 2022, ARTIF INTELL REV, V55, P3401, DOI 10.1007/s10462-021-10093-1
   Sharma K, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2701, DOI 10.1109/ICASSP.2018.8462429
   Silberman N., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P601, DOI 10.1109/ICCVW.2011.6130298
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh V, 2017, PROC MODERN ARTIFICI, P85
   Sinha A, 2014, IEEE IJCNN, P1614, DOI 10.1109/IJCNN.2014.6889660
   Sinha A, 2014, MACH VISION APPL, V25, P361, DOI 10.1007/s00138-013-0561-6
   Sinha A, 2012, LECT NOTES COMPUT SC, V7626, P584, DOI 10.1007/978-3-642-34166-3_64
   Sitaula C, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/2158184
   Sitaula C, 2022, J MED SYST, V46, DOI 10.1007/s10916-022-01868-2
   Sitaula C, 2021, KNOWL-BASED SYST, V232, DOI 10.1016/j.knosys.2021.107470
   Sitaula C, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115285
   Sitaula C, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207106
   Sitaula C, 2019, LECT NOTES COMPUT SC, V11955, P90, DOI 10.1007/978-3-030-36718-3_8
   Sitaula C, 2019, LECT NOTES COMPUT SC, V11854, P404, DOI 10.1007/978-3-030-34879-3_31
   Sitaula C, 2019, IEEE ACCESS, V7, P84967, DOI 10.1109/ACCESS.2019.2925002
   Sorkhi AG, 2020, MULTIMED TOOLS APPL, V79, P18033, DOI 10.1007/s11042-019-08264-y
   Sun N, 2019, IEEE T CIRC SYST VID, V29, P1715, DOI 10.1109/TCSVT.2018.2848543
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tang PJ, 2017, NEUROCOMPUTING, V225, P188, DOI 10.1016/j.neucom.2016.11.023
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Wai-Shing Cho, 2012, 2012 International Conference on Systems and Informatics (ICSAI 2012), P2153, DOI 10.1109/ICSAI.2012.6223478
   Wang C, 2022, INFORM SCIENCES, V610, P938, DOI 10.1016/j.ins.2022.07.188
   Wang DZ, 2019, IEEE T MULTIMEDIA, V21, P2985, DOI 10.1109/TMM.2019.2920620
   Wang DZ, 2019, NEUROCOMPUTING, V329, P103, DOI 10.1016/j.neucom.2018.09.042
   Wang JZ, 2016, IEEE T MULTIMEDIA, V18, P1000, DOI 10.1109/TMM.2016.2544099
   Wang Z, 2017, IEEE T IMAGE PROCESS, V26, P2028, DOI 10.1109/TIP.2017.2666739
   Wei X, 2016, ARTIF INTELL REV, V45, P333, DOI 10.1007/s10462-015-9448-4
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Wu RB, 2015, IEEE I CONF COMP VIS, P1287, DOI 10.1109/ICCV.2015.152
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Xiao Y, 2014, IEEE T IMAGE PROCESS, V23, P823, DOI 10.1109/TIP.2013.2295756
   Xie GS, 2018, IEEE ACCESS, V6, P69393, DOI 10.1109/ACCESS.2018.2878553
   Xie L, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107205
   Xie L, 2018, PATTERN RECOGN, V82, P118, DOI 10.1016/j.patcog.2018.04.025
   Yang SF, 2015, IEEE I CONF COMP VIS, P1215, DOI 10.1109/ICCV.2015.144
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zeglazi O, 2016, I C COMP GRAPH IM VI, P265, DOI 10.1109/CGiV.2016.58
   Zhang BB, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107167
   Zhang CJ, 2017, INFORM SCIENCES, V376, P125, DOI 10.1016/j.ins.2016.10.019
   Zhang CJ, 2014, NEUROCOMPUTING, V142, P248, DOI 10.1016/j.neucom.2014.03.059
   Zhang CJ, 2013, NEUROCOMPUTING, V120, P318, DOI 10.1016/j.neucom.2012.07.056
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P3241, DOI 10.1109/TIP.2014.2328894
   Zhou B, 2016, ARXIV
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zuo Z, 2015, PATTERN RECOGN, V48, P3004, DOI 10.1016/j.patcog.2015.02.003
NR 120
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 9251
EP 9278
DI 10.1007/s11042-023-15005-9
EA JUN 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001006598900012
DA 2024-07-18
ER

PT J
AU Pandian, AA
   Maheswari, S
AF Pandian, A. Anbarasa
   Maheswari, S.
TI A keyframe selection for summarization of informative activities using
   clustering in surveillance videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Keyframe Extraction; Markov chain based clustering; Adjacent matrix
   based clustering
ID ALGORITHM
AB Video informative activities summarization in surveillance video has become an important approach that leads to object detection, object classification, and multi-event detection, etc. Several approaches such as dictionary learning, representation learning, statistical approach, etc. have been used for identifying important events. However, the efficiency of these methods lack in identifying the important activities in a video effectively. To overcome this challenge, this paper presents a keyframe selection algorithm by adopting multi-level clustering using surveillance video. To efficiently identify the activities, orientation computation, Markov chain based clustering, and adjacent matrix based clustering are used. The Markov chain based clustering is used to analyze and group the adjacent activities efficiently. Adjacent matrix based clustering ensures inter-relationship among the activities and then integrates the positive activities. It leads to an efficient and informative activities summary. The experimental results are tested on the PETS 2009, VIRAT and UCLA datasets. Also, various existing video summarization algorithms are compared with the proposed method for evaluating the performance of the proposed method.
C1 [Pandian, A. Anbarasa] Panimalar Engn Coll, Dept Comp Sci & Business Syst, Chennai, Tamil Nadu, India.
   [Maheswari, S.] SRM Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai
RP Pandian, AA (corresponding author), Panimalar Engn Coll, Dept Comp Sci & Business Syst, Chennai, Tamil Nadu, India.
EM anbuaec@gmail.com
RI A, ANBARASA PANDIAN/IXS-4191-2023
OI A, ANBARASA PANDIAN/0000-0003-0562-8027
CR Benezeth Y., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2458, DOI 10.1109/CVPRW.2009.5206686
   Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524
   Calic J, 2004, P WORKSH IM AN MULT
   Chen BW, 2009, IEEE T MULTIMEDIA, V11, P295, DOI 10.1109/TMM.2008.2009703
   Chen DY, 2011, J VIS COMMUN IMAGE R, V22, P178, DOI 10.1016/j.jvcir.2010.12.004
   Chen F, 2011, IEEE T MULTIMEDIA, V13, P1381, DOI 10.1109/TMM.2011.2166379
   DeMenthon D., 1998, Proceedings ACM Multimedia 98, P211, DOI 10.1145/290747.290773
   Elhoseny M, 2020, CIRC SYST SIGNAL PR, V39, P611, DOI 10.1007/s00034-019-01234-7
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Gianluigi C, 2006, J REAL-TIME IMAGE PR, V1, P69, DOI 10.1007/s11554-006-0001-1
   Guironnet M, 2007, EURASIP J IMAGE VIDE, DOI 10.1155/2007/60245
   Hanjalic R, 1996, 1 INT WORKSH IM DAT, P67
   Hong RC, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2043612.2043613
   Hoon SH, 2000, 12 WORKSH IM PROC IM, P217
   Kim G, 2014, PROC CVPR IEEE, P4225, DOI 10.1109/CVPR.2014.538
   Kim JS, 2011, IEEE T CONSUM ELECTR, V57, P1165, DOI 10.1109/TCE.2011.6018870
   Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350
   Luo JB, 2009, IEEE T CIRC SYST VID, V19, P289, DOI 10.1109/TCSVT.2008.2009241
   Oh SM, 2011, PROC CVPR IEEE
   PAL SK, 1995, J INTELL FUZZY SYST, V3, P247
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Pritch Y, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P195, DOI 10.1109/AVSS.2009.53
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Vennila TJ, 2020, 2020 INT C EM TRENDS, P1, DOI [10.1109/ic-ETITE47903.2020.294, DOI 10.1109/IC-ETITE47903.2020.294]
   Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x
   Zhang S, 2016, IEEE T IMAGE PROCESS, V25, P5469, DOI 10.1109/TIP.2016.2601493
   Zhang XD, 2003, PATTERN RECOGN LETT, V24, P1523, DOI 10.1016/S0167-8655(02)00391-4
   Zhao B, 2014, PROC CVPR IEEE, P2513, DOI 10.1109/CVPR.2014.322
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 30
TC 3
Z9 3
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7021
EP 7034
DI 10.1007/s11042-023-15859-z
EA JUN 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001000907700003
DA 2024-07-18
ER

PT J
AU Inunganbi, S
AF Inunganbi, Sanasam
TI A systematic review on handwritten document analysis and recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Character recognition; Preprocessing; Segmentation; Feature extraction;
   Recognition
ID TEXT LINE SEGMENTATION; CHARACTER-RECOGNITION; WORD RECOGNITION;
   CLASSIFICATION; EXTRACTION; ALGORITHM; FOURIER; COMBINATION; TRANSFORM;
   FEATURES
AB Document Analysis and Recognition (DAR) is ongoing research that has been studied extensively for many decades and it has achieved a substantial level that generates several technology-driven applications. Further, with the advent of high-end computing power, the implementation of advanced character recognition techniques is enabled and creates growing demand on different emerging application domains. The development of such application domains required more advanced techniques and methodologies. The main aim of this paper is to present a manual update for researchers working in the field of character recognition. A brief history of how character recognition has evolved is depicted. Then, general steps involved in character recognition are discussed, and each step is reviewed with the available techniques. The current status and future direction for the character recognition system are discussed. Lastly, the focus is given to the off-line handwritten recognition systems as this research area needs more experiments to attained the machine simulation of human reading capability.
C1 [Inunganbi, Sanasam] Koneru Lakshmaiah Educ Fdn, Guntur, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Inunganbi, S (corresponding author), Koneru Lakshmaiah Educ Fdn, Guntur, India.
EM isanasam@kluniversity.in
OI Inunganbi, Sanasam/0000-0002-7879-1039
CR Abuhaiba I. S. I., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P390, DOI 10.1109/ICDAR.1995.599020
   Akçay S, 2016, IEEE IMAGE PROC, P1057, DOI 10.1109/ICIP.2016.7532519
   Alaei A, 2011, PATTERN RECOGN, V44, P917, DOI 10.1016/j.patcog.2010.10.014
   Alif M. A. R., 2017, 2017 20 INT C COMP I, P1
   Althobaiti H., 2017, P INT C RES ADAPTIVE, P79
   Amin A, 2000, PATTERN ANAL APPL, V3, P243, DOI 10.1007/s100440070009
   [Anonymous], 2005, P INT C COMP SCI RIV
   [Anonymous], 2015, 2015 INT C ELECT ENG, DOI DOI 10.1109/ICEEICT.2015.7307371
   [Anonymous], 2016, IEICE TECHNICAL REPO
   Arica N, 2003, PATTERN RECOGN LETT, V24, P1627, DOI 10.1016/S0167-8655(03)00002-3
   Bag S, 2014, PATTERN RECOGN, V47, P1187, DOI 10.1016/j.patcog.2013.08.026
   Bansal V., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P410, DOI 10.1109/ICDAR.1999.791811
   Bansal V, 2000, IEEE T SYST MAN CY A, V30, P500, DOI 10.1109/3468.852443
   Basu S, 2007, PATTERN RECOGN, V40, P1825, DOI 10.1016/j.patcog.2006.10.002
   Bianne-Bernard AL, 2011, IEEE T PATTERN ANAL, V33, P2066, DOI 10.1109/TPAMI.2011.22
   Blumenstein M, 2003, PROC INT CONF DOC, P137
   BOKSER M, 1992, P IEEE, V80, P1066, DOI 10.1109/5.156470
   Bouchaffra D, 1999, IEEE T PATTERN ANAL, V21, P990, DOI 10.1109/34.799906
   Boufenar C, 2018, COGN SYST RES, V50, P180, DOI 10.1016/j.cogsys.2017.11.002
   Cai JH, 1999, IEEE T PATTERN ANAL, V21, P263, DOI 10.1109/34.754622
   CAO J, 1995, PATTERN RECOGN, V28, P153, DOI 10.1016/0031-3203(94)00094-3
   Chaudhuri BB, 1998, PATTERN RECOGN, V31, P531, DOI 10.1016/S0031-3203(97)00078-2
   Chou CH, 2007, PATTERN RECOGN, V40, P443, DOI 10.1016/j.patcog.2005.10.030
   Daliri MR, 2008, PATTERN RECOGN, V41, P1782, DOI 10.1016/j.patcog.2007.10.020
   Dash KS, 2015, IET IMAGE PROCESS, V9, P874, DOI 10.1049/iet-ipr.2015.0146
   Deshpande PS, 2008, J COMPUT, V3, P11, DOI 10.4304/jcp.3.5.11-17
   Gaurav DD, 2012, Arxiv, DOI arXiv:1202.3884
   dos Santos Rodolfo P., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P651, DOI 10.1109/ICDAR.2009.183
   Elleuch M, 2015, 2015 IEEE 12TH INTERNATIONAL MULTI-CONFERENCE ON SYSTEMS, SIGNALS & DEVICES (SSD)
   Gonwirat S, 2022, IEEE ACCESS, V10, P90133, DOI 10.1109/ACCESS.2022.3201560
   Guyon I., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P454, DOI 10.1109/ICDAR.1995.599034
   Hamamoto Y., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P819, DOI 10.1109/ICDAR.1995.602027
   He J, 2003, PROC INT CONF DOC, P498
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heutte L, 1998, PATTERN RECOGN LETT, V19, P629, DOI 10.1016/S0167-8655(98)00039-7
   Ng HW, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P443, DOI 10.1145/2818346.2830593
   Hsu GS, 2013, IEEE T VEH TECHNOL, V62, P552, DOI 10.1109/TVT.2012.2226218
   Inunganbi S, 2021, VISUAL COMPUT, V37, P291, DOI 10.1007/s00371-020-01799-4
   Iqbal A, 2008, P SCIS ISIS NAG, P1367
   Islam M. M., 2020, Social Netw. Comput. Sci., V1, P1, DOI [10.1007/s42979-020-00223-x, DOI 10.1007/S42979-020-00223-X]
   Islam MR, 2021, IEEE ACCESS, V9, P94601, DOI 10.1109/ACCESS.2021.3091487
   Jain J., 2012, ADV COMPUTER SCI INF, P611
   Jangid M, 2018, J IMAGING, V4, DOI 10.3390/jimaging4020041
   Javed M, 2013, NAT CONF COMPUT VIS
   Jindal P, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN ENGINEERING & COMPUTATIONAL SCIENCES (RAECS)
   Kabbai L, 2019, VISUAL COMPUT, V35, P679, DOI 10.1007/s00371-018-1503-0
   Kale K V, 2014, ZERNIKE MOMENT FEATU
   Kanai J., 1998, International Journal on Document Analysis and Recognition, V1, P43
   Kaufmann G., 2000, International Journal on Document Analysis and Recognition, V2, P211, DOI 10.1007/s100320050007
   Kia MMM, 2018, IEEE ACCESS, V6, P77265, DOI 10.1109/ACCESS.2018.2881050
   Kim G, 1997, IEEE T PATTERN ANAL, V19, P366, DOI 10.1109/34.588017
   Kim G., 1999, International Journal on Document Analysis and Recognition, V2, P37, DOI 10.1007/s100320050035
   Kim KK, 2000, NEURAL NETWORKS FOR SIGNAL PROCESSING X, VOLS 1 AND 2, PROCEEDINGS, P614, DOI 10.1109/NNSP.2000.890140
   KIM WY, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P391, DOI 10.1109/CVPR.1994.323856
   Kise K, 1998, COMPUT VIS IMAGE UND, V70, P370, DOI 10.1006/cviu.1998.0684
   Kishna NPT, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTING AND INFORMATICS (ICICI 2017), P595, DOI 10.1109/ICICI.2017.8365201
   Krizhevsky Alex., NIPS 2012
   KUKICH K, 1992, COMPUT SURV, V24, P377
   Kumar M, 2013, IETE J RES, V59, P687, DOI 10.4103/0377-2063.126961
   Kunte RS, 2007, SADHANA-ACAD P ENG S, V32, P521, DOI 10.1007/s12046-007-0039-1
   Laishram R, 2014, 2014 IEEE INT C COMP, P1
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Legault R, 1997, IEEE T PATTERN ANAL, V19, P801, DOI 10.1109/34.608276
   Li Y., 2006, NEW ALGORITHM DETECT
   Li Y, 2008, IEEE T PATTERN ANAL, V30, P1313, DOI 10.1109/TPAMI.2007.70792
   Li ZC, 2000, PATTERN RECOGN LETT, V21, P701, DOI 10.1016/S0167-8655(00)00037-4
   Likforman-Sulem L., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P774, DOI 10.1109/ICDAR.1995.602017
   Liu CL, 2005, PROC INT CONF DOC, P121, DOI 10.1109/ICDAR.2005.119
   Liu YK, 2007, PATTERN RECOGN, V40, P2908, DOI 10.1016/j.patcog.2007.03.001
   Louloudis G., 2006, BLOCK BASED HOUGH TR
   Lu Y, 2003, PATTERN RECOGN LETT, V24, P2315, DOI 10.1016/S0167-8655(03)00057-6
   MAHMOUD SA, 1994, PATTERN RECOGN, V27, P815, DOI 10.1016/0031-3203(94)90166-X
   Maring KA, 2014, IJCSIT, V1.2
   Marti UV, 2001, PROC INT CONF DOC, P159, DOI 10.1109/ICDAR.2001.953775
   Ming Chen, 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P617, DOI 10.1109/ICDAR.1999.791863
   Mo S, 1998, IEEE T IMAGE PROCESS, V7, P992, DOI 10.1109/83.701155
   MORI S, 1992, P IEEE, V80, P1029, DOI 10.1109/5.156468
   Mowlaei A, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P923, DOI 10.1109/ICDSP.2002.1028240
   NAGY G, 1992, COMPUTER, V25, P10, DOI 10.1109/2.144436
   OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677
   Oh IS, 1999, IEEE T PATTERN ANAL, V21, P1089, DOI 10.1109/34.799913
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pal U, 2004, PATTERN RECOGN, V37, P1887, DOI 10.1016/j.patcog.2004.02.003
   Pal U, 2009, SADHANA-ACAD P ENG S, V34, P755, DOI 10.1007/s12046-009-0044-7
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pan X, 2005, ENG APPL ARTIF INTEL, V18, P963, DOI 10.1016/j.engappai.2005.03.011
   Pirlo G, 2011, IEEE T FUZZY SYST, V19, P780, DOI 10.1109/TFUZZ.2011.2131658
   Polesel A, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P267, DOI 10.1109/ICIP.1997.647756
   Pu Y., 1999, Advances In Handwriting Recognition, P141
   Purkaystha B, 2017, 2017 20TH INTERNATIONAL CONFERENCE OF COMPUTER AND INFORMATION TECHNOLOGY (ICCIT)
   Raja S, 2013, IETE J RES, V59, P569, DOI 10.4103/0377-2063.123763
   Rani M, 2011, LECT NOTES COMPUT SC, V7077, P302, DOI 10.1007/978-3-642-27242-4_35
   Rasheed A, 2022, IEEE ACCESS, V10, P102629, DOI 10.1109/ACCESS.2022.3208959
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Roohi S, 2017, IRAN CONF MACH, P247, DOI 10.1109/IranianMVIP.2017.8342359
   Ryu J, 2015, IEEE SIGNAL PROC LET, V22, P1161, DOI 10.1109/LSP.2015.2389852
   Saba T, 2011, INT J INNOV COMPUT I, V7, P5211
   Saha S, 2010, Arxiv, DOI arXiv:1002.4048
   Sahlol AT, 2020, IEEE ACCESS, V8, P23011, DOI 10.1109/ACCESS.2020.2970438
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Seethalakshmi R., 2005, Journal of Zhejiang University (Science), V6A, P1297, DOI 10.1631/jzus.2005.A1297
   SERRA J, 1994, SIGNAL PROCESS, V38, P3, DOI 10.1016/0165-1684(94)90052-3
   Shabir M, 2021, IEEE ACCESS, V9, P160238, DOI 10.1109/ACCESS.2021.3123726
   Shioyama T, 1998, INT C PATT RECOG, P229, DOI 10.1109/ICPR.1998.711123
   SHRIDHAR M, 1984, PATTERN RECOGN, V17, P515, DOI 10.1016/0031-3203(84)90049-9
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh N, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P894, DOI 10.1109/SPIN.2018.8474282
   Soora NR, 2018, IETE J RES, V64, P280, DOI 10.1080/03772063.2017.1351323
   Su TH, 2007, PROC INT CONF DOC, P899
   Suliman A., 2010, ELECT J COMPUT SCI I, V2, P1
   Surinta O, 2013, PROC INT CONF DOC, P165, DOI 10.1109/ICDAR.2013.40
   Szegedy C, 2015, P IEEE C COMP VIS PA
   Thokchom T, 2010, J COMPUT, V5, P1570, DOI 10.4304/jcp.5.10.1570-1574
   Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2
   WANG SS, 1994, PATTERN RECOGN, V27, P1735, DOI 10.1016/0031-3203(94)90090-6
   Wang YT, 2021, IEEE ACCESS, V9, P132301, DOI 10.1109/ACCESS.2021.3115606
   Weliwitage C, 2005, DIGITAL IMAGE COMPUT, P27
   Yin F, 2009, PATTERN RECOGN, V42, P3146, DOI 10.1016/j.patcog.2008.12.013
   Zahour A, 2001, PROC INT CONF DOC, P281
   Zhang B, 2008, IEEE T IMAGE PROCESS, V17, P664, DOI 10.1109/TIP.2008.919949
   Zhang XY, 2018, IEEE T PATTERN ANAL, V40, P849, DOI 10.1109/TPAMI.2017.2695539
   Zhu B, 2014, PATTERN RECOGN, V47, P685, DOI 10.1016/j.patcog.2013.08.011
NR 122
TC 1
Z9 1
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 2
PY 2023
DI 10.1007/s11042-023-15326-9
EA JUN 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0KI8
UT WOS:000999746300006
DA 2024-07-18
ER

PT J
AU Li, Y
   Huang, JJ
AF Li, Yan
   Huang, Jinjie
TI Explore pretraining for few-shot learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Computer vision; Deep learning; Image classification; Few-shot learning
AB Few-shot learning aims to learn to classify new categories with a few samples. Pretraining the model on the base class can improve the performance of the model on the new category. To further improve the pretraining performance of the model on the base class, we propose a two-stage model pretraining method. In the first stage, we conduct Simsiam contrastive learning pretraining, which can help the model learn invariant knowledge. In the second stage, we conduct multi-task pretraining for general classification tasks and rotation prediction tasks, which can help the model learn the equivalent knowledge. Two pretraining stages can significantly enhance the model's capacity to learn new categories and enhance the effectiveness of few-shot categorization. Experiments show that our method achieves State-of-the-art few-shot classification performance on the mini-ImageNet and FC100 datasets for 1-shot and 5-shot tasks.
C1 [Li, Yan; Huang, Jinjie] Harbin Univ Sci & Technol, Inst Automat, Harbin 150006, Heilongjiang, Peoples R China.
C3 Harbin University of Science & Technology
RP Huang, JJ (corresponding author), Harbin Univ Sci & Technol, Inst Automat, Harbin 150006, Heilongjiang, Peoples R China.
EM 729889442@qq.com; jjhuangps@126.com
CR [Anonymous], 2019, Few-shot learning: A survey
   Caron M., 2020, Advances in neural information processing systems, V33, P9912
   CHEN T, 2020, INT C MACH LEARN, P1597, DOI DOI 10.48550/ARXIV.2002.05709
   Chen WY, 2020, Arxiv, DOI arXiv:1904.04232
   Chen XL, 2021, PROC CVPR IEEE, P15745, DOI 10.1109/CVPR46437.2021.01549
   Chi Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12200, DOI 10.1109/CVPR42600.2020.01222
   Finn C, 2017, PR MACH LEARN RES, V70
   Gidaris S, 2018, Arxiv, DOI arXiv:1803.07728
   Gidaris S, 2019, IEEE I CONF COMP VIS, P8058, DOI 10.1109/ICCV.2019.00815
   Grill J.-B., 2020, P ADV NEUR INF PROC, V33, P21271
   Han-Jia Ye, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8805, DOI 10.1109/CVPR42600.2020.00883
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kim J., 2020, EUR C COMP VIS, P599, DOI DOI 10.1007/978-3-030-58452-8_35
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee K, 2019, PROC CVPR IEEE, P10649, DOI 10.1109/CVPR.2019.01091
   Li WB, 2020, Arxiv, DOI arXiv:2002.00153
   Liu C, 2021, AAAI CONF ARTIF INTE, V35, P8635
   Liu S, 2022, IEEE INTERNET THINGS
   Liu S, 2022, INT J INTELL SYST, V37, P10968, DOI 10.1002/int.23029
   Liu S, 2023, IEEE T RELIAB, V72, P15, DOI 10.1109/TR.2022.3162346
   Loshchilov Ilya, 2016, arXiv
   Lu S, 2021, AAAI CONF ARTIF INTE, V35, P8776
   Oreshkin BN, 2018, ADV NEUR IN, V31
   Raghu A, 2020, Arxiv, DOI arXiv:1909.09157
   Ren MY, 2018, Arxiv, DOI arXiv:1803.00676
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rizve MN, 2021, PROC CVPR IEEE, P10831, DOI 10.1109/CVPR46437.2021.01069
   Rodriguez Pau, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12371), P121, DOI 10.1007/978-3-030-58574-7_8
   Dhillon GS, 2020, Arxiv, DOI arXiv:1909.02729
   Shen ZQ, 2021, AAAI CONF ARTIF INTE, V35, P9594
   Snell J, 2017, ADV NEUR IN, V30
   Sun QR, 2019, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.2019.00049
   Vinyals O, 2016, Advances in neural information processing systems, V29, P3630
   Xie J, 2022, P IEEECVF C COMPUTER, P7972
   Yonglong Tian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P266, DOI 10.1007/978-3-030-58568-6_16
   Zbontar Jure, 2021, ICML
   Zhang BQ, 2021, PROC CVPR IEEE, P3753, DOI 10.1109/CVPR46437.2021.00375
NR 39
TC 0
Z9 0
U1 6
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 27
PY 2023
DI 10.1007/s11042-023-15223-1
EA MAY 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H4OZ4
UT WOS:000995787000006
DA 2024-07-18
ER

PT J
AU Vaidya, SP
   Mouli, PVSSRC
AF Vaidya, S. Prasanth
   Mouli, P. V. S. S. R. Chandra
TI Robust digital color image watermarking based on compressive sensing and
   DWT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Digital watermarking; DWT; Compressive sensing
ID ALGORITHM; SCHEME
AB In this paper, a powerful digital watermarking algorithm derived from compressive sensing and discrete wavelet transform to provide authentication and preserve copyright protection for color images. Initially, host color image is converted into YCbCr. Then Y "luminance image" is decomposed with wavelet transform and its low-frequency subband is selected. The watermark image is divided into non-overlapping blocks which are compressed. Finally, the compressed watermark blocks are embedded in Y. In extracting the watermark, L1 optimization algorithm is utilized. Investigated results convey that the developed algorithm has better performance, high concealment and high durability over various attacks of image.
C1 [Vaidya, S. Prasanth] Aditya Engn Coll, Surampalem, India.
   [Mouli, P. V. S. S. R. Chandra] Cent Univ Tamil Nadu, Dept Comp Sci, Thiruvarur, Tamil Nadu, India.
C3 Aditya Engineering College, Surampalem; Central University of Tamil Nadu
RP Vaidya, SP (corresponding author), Aditya Engn Coll, Surampalem, India.
EM vaidya269@gmail.com; chandramouli@cutn.ac.in
CR [Anonymous], 1997, The Econometrics of Financial Markets
   Ahmadi SBB, 2021, VISUAL COMPUT, V37, P385, DOI 10.1007/s00371-020-01808-6
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571
   Brannock E, 2009, J COMPUT, V4, P554, DOI 10.4304/jcp.4.6.554-566
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Ernawan F, 2020, VISUAL COMPUT, V36, P19, DOI 10.1007/s00371-018-1567-x
   Himthani V, 2022, IEEE ACCESS, V10, P98360, DOI 10.1109/ACCESS.2022.3203173
   Hu YX, 2022, MULTIMED TOOLS APPL, V81, P17729, DOI 10.1007/s11042-022-12719-0
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Kaur M, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/5012496
   Kaur M, 2018, IMAGING SCI J, V66, P453, DOI 10.1080/13682199.2018.1505327
   Lang J, 2023, MULTIMED TOOLS APPL, V82, P4551, DOI 10.1007/s11042-022-13601-9
   Langeland J, 2024, MASS SPECTROM REV, V43, P477, DOI 10.1002/mas.21828
   Liao B., 2015, OPEN CYBERN SYSTEM J, V9, P1, DOI [10.2174/1874110X01509010001, DOI 10.2174/1874110X01509010001]
   Liu DR, 2022, VEHICLE SYST DYN, V60, P433, DOI 10.1080/00423114.2020.1817508
   Liu H, 2016, SIGNAL PROCESS-IMAGE, V45, P41, DOI 10.1016/j.image.2016.04.002
   Liu XY, 2013, OPTIK, V124, P6590, DOI 10.1016/j.ijleo.2013.05.092
   Neetha KK, 2015, 2015 INTERNATIONAL CONFERENCE ON CONTROL COMMUNICATION & COMPUTING INDIA (ICCC), P495, DOI 10.1109/ICCC.2015.7432952
   Prasanth Vaidya S., 2020, Smart Computing Paradigms: New Progresses and Challenges. Proceedings of ICACNI 2018. Advances in Intelligent Systems and Computing (AISC 766), P11, DOI 10.1007/978-981-13-9683-0_2
   Prasanth Vaidya S, 2018, INT C RECENT TRENDS, P203
   Sanivarapu PV, 2020, PHYS ENG SCI MED, V43, P213, DOI 10.1007/s13246-019-00838-2
   Setiadi DIM, 2021, MULTIMED TOOLS APPL, V80, P8423, DOI 10.1007/s11042-020-10035-z
   Sui LS, 2017, OPT LASER ENG, V92, P85, DOI 10.1016/j.optlaseng.2017.01.003
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P15191, DOI 10.1007/s11042-016-3744-0
   Thanki R, 2017, J KING SAUD U COMPUT
   Tong DY, 2019, MULTIMED TOOLS APPL, V78, P16053, DOI 10.1007/s11042-018-7014-1
   Vaidya SP, 2018, MULTIMED TOOLS APPL, V77, P5609, DOI 10.1007/s11042-017-4476-5
   Vaidya SP, 2017, MULTIMED TOOLS APPL, V76, P25623, DOI 10.1007/s11042-017-4355-0
   Vaidya SP, 2015, PROCEDIA COMPUT SCI, V58, P233, DOI 10.1016/j.procs.2015.08.063
   Vaidya S.P., 2018, INT C REC TRENDS IM, P132
   Vaidya SP, 2023, VISUAL COMPUT, V39, P2245, DOI 10.1007/s00371-022-02406-4
   Vaidya SP, 2019, INT J MACH LEARN CYB, V10, P1323, DOI 10.1007/s13042-018-0813-x
   Valenzise G, 2009, IEEE IMAGE PROC, P1265, DOI 10.1109/ICIP.2009.5413615
   Veena VK, 2012, 2012 INTERNATIONAL CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P105, DOI 10.1109/MVIP.2012.6428771
   Wang YR, 2011, EXPERT SYST APPL, V38, P8024, DOI 10.1016/j.eswa.2010.12.129
   Xinpeng Zhang, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P222, DOI 10.1109/IIHMSP.2011.12
   Yang Z, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24101486
   Yuan ZH, 2021, VISUAL COMPUT, V37, P1867, DOI 10.1007/s00371-020-01945-y
   Zhang R, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10081242
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
NR 41
TC 0
Z9 0
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 26
PY 2023
DI 10.1007/s11042-023-15349-2
EA MAY 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3BW9
UT WOS:000994764200001
DA 2024-07-18
ER

PT J
AU Walhazi, H
   Maalej, A
   Ben Amara, NE
AF Walhazi, Hajer
   Maalej, Ahmed
   Ben Amara, Najoua Essoukri
TI A multi-classifier system for automatic fingerprint classification using
   transfer learning and majority voting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Automatic classification; Fingerprint classification; Mlti-Classifier
   system; Transfer learning; Majority voting
ID ENSEMBLES
AB Fingerprints fulfill a critical role in the context of community safety and criminal investigations, especially for forensic investigations, law enforcement, border access and security. For fingerprint analysis, a variety of machine learning and neural network techniques have been presented. Various AI-driven approaches are available to conduct automated activities to maintain biometric systems at the forefront of technological development. In this paper, we propose a framework for automatic classification of fingerprints that combines deep transfer learning and a majority voting system. Our multi-classifier system is capable of efficiently classifying six different types of fingerprints. We build 16 commonly used deep transfer learning models by training them with fingerprint datasets, resulting in 16 fingerprint classifiers. The training and testing phases involve six distinct fingerprint databases consisting of both real and synthetic images. We created sets of fingerprint classifiers and applied a soft majority voting method to each set, aiming to identify the optimal combination of classifiers. This allowed us to determine the most effective set of classifiers for fingerprint classification. The results of our experiments indicate that the majority voting approach of three deep transfer-learning models, namely DenseNet 121, ResNet152V1, and EfficientNetB7, outperforms the individual transfer learning structures in terms of precision in fingerprint classification.
C1 [Walhazi, Hajer] Univ Sousse, Higher Inst Appl Sci & Technol, Sousse 4023, Tunisia.
   [Walhazi, Hajer; Maalej, Ahmed; Ben Amara, Najoua Essoukri] LATIS Lab Adv Technol & Intelligent Syst, Sousse 4023, Tunisia.
   [Maalej, Ahmed] Univ Kairouan, Higher Inst Appl Math & Comp Sci, Kairouan 3100, Tunisia.
   [Ben Amara, Najoua Essoukri] Univ Sousse, Natl Sch Engn Sousse, Sousse 4023, Tunisia.
C3 Universite de Sousse; Universite de Kairouan; Universite de Sousse
RP Walhazi, H (corresponding author), Univ Sousse, Higher Inst Appl Sci & Technol, Sousse 4023, Tunisia.; Walhazi, H (corresponding author), LATIS Lab Adv Technol & Intelligent Syst, Sousse 4023, Tunisia.
EM hajerwalhazi@gmail.com; maalejahmed@gmail.com;
   najoua.benamara@eniso.rnu.tn
OI walhazi, Hajer/0000-0002-3387-0550
FU Tunisian Ministry of Higher Education and Scientific Research
FX This work has been funded by the Tunisian Ministry of Higher Education
   and Scientific Research within the PAQ COLLABORA project "Kit for the
   Detection and Authentication of Fingerprints" led by the GEOGLOB
   Research Lab, Faculty of Sciences of Sfax.
CR Abdulrahman Shaymaa Adnan, 2023, Materials Today: Proceedings, P2642, DOI 10.1016/j.matpr.2021.07.005
   Abou Elassad ZE, 2020, TRANSPORT RES C-EMER, V118, DOI 10.1016/j.trc.2020.102708
   Akhter MP, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.425
   Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   [Anonymous], 2006, International Journal of Hybrid Intelligent Systems, DOI DOI 10.3233/HIS-2006-3104
   Ansari A.H., 2011, ME Thesis
   Behera TK, 2024, IEEE J BIOMED HEALTH, V28, P1218, DOI 10.1109/JBHI.2022.3216270
   Cao K, 2018, INT CONF BIOMETR, P31, DOI 10.1109/ICB2018.2018.00016
   Chicco D, 2020, BMC GENOMICS, V21, DOI 10.1186/s12864-019-6413-7
   Clement D, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13010156
   Dasgupta D, 2022, J DEF MODEL SIMUL-AP, V19, P57, DOI 10.1177/1548512920951275
   de Souza GB, 2019, J ARTIF INTELL SOFT, V9, P41, DOI 10.2478/jaiscr-2018-0023
   dsl, ANG SYNTH FING GEN
   El Hamdi D, 2018, I C CONT AUTOMAT ROB, P1448, DOI 10.1109/ICARCV.2018.8581072
   Elsadai A, 2022, MULTIMED TOOLS APPL, V81, P36715, DOI 10.1007/s11042-021-11581-w
   Fiumara G, 2018, 2002 NAT I STAND TEC
   Garris M.D., 2000, NIST Special Database 27: Fingerprint Minutiae from Latent and Matching Tenprint Images
   Ghiani L, 2017, IMAGE VISION COMPUT, V58, P110, DOI 10.1016/j.imavis.2016.07.002
   Ghiani L, 2013, INT CONF BIOMETR, DOI 10.1109/ICB.2013.6613027
   González S, 2020, INFORM FUSION, V64, P205, DOI 10.1016/j.inffus.2020.07.007
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HENRY ER, 1913, CLASSIFICATION USES
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Huang XJ, 2020, IEEE COMPUT SOC CONF, P3481, DOI 10.1109/CVPRW50498.2020.00408
   Jaafar Roua, 2022, 2022 19th International Multi-Conference on Systems, Signals & Devices (SSD), P485, DOI 10.1109/SSD54932.2022.9955982
   Jain Anil K., 2022, IEEE Transactions on Biometrics, Behavior, and Identity Science, V4, P303, DOI 10.1109/TBIOM.2021.3115465
   Jain AK, 2016, PATTERN RECOGN LETT, V79, P80, DOI 10.1016/j.patrec.2015.12.013
   Jawarneh I, 2021, INT J COMPUT INT SYS, V14, P1208, DOI 10.2991/ijcis.d.210318.002
   Joshi M, 2018, ARXIV
   Jurman G, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0041882
   Kandel I, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103359
   Kumar G, 2021, MULTIMED TOOLS APPL, V80, P16565, DOI 10.1007/s11042-020-08708-w
   Li XR, 2023, AQUAT TOXICOL, V255, DOI 10.1016/j.aquatox.2022.106379
   Maio D, 2004, LECT NOTES COMPUT SC, V3072, P1
   Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144
   Marqués AI, 2012, EXPERT SYST APPL, V39, P10916, DOI 10.1016/j.eswa.2012.03.033
   Militello C, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13050750
   Mo TL, 2023, EXPERT SYST APPL, V222, DOI 10.1016/j.eswa.2023.119845
   Mohammed AM, 2020, APPL SOFT COMPUT, V95, DOI 10.1016/j.asoc.2020.106568
   Nahar P, 2022, MULTIMED TOOLS APPL, V81, P24515, DOI 10.1007/s11042-022-12294-4
   Nist, 2019, BIOM SPEC DAT SOFTW
   Park E, 2018, Arxiv, DOI arXiv:1803.07817
   Predic B, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/4001460
   Rai A, 2023, Arxiv, DOI arXiv:2303.01465
   Raj S, 2020, PATTERN RECOGN LETT, V131, P79, DOI 10.1016/j.patrec.2019.12.003
   Rajasekar V, 2022, COMPUT SCI-AGH, V23, P117, DOI 10.7494/csci.2022.23.1.4315
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shaheed K, 2021, ARCH COMPUT METHOD E, V28, P4917, DOI 10.1007/s11831-021-09560-3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh N, 2022, MULTIMED TOOLS APPL, V81, P38887, DOI 10.1007/s11042-022-13160-z
   SM J., 2022, MULTIMED TOOLS APPL, P1
   Sullabi MA., 2021, J ACAD RES APPL SCI, V17, P1
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tanha J, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00349-y
   Uliyan DM, 2020, ENG SCI TECHNOL, V23, P264, DOI 10.1016/j.jestch.2019.06.005
   Walhazi H, 2020, 2020 5 INT C ADV TEC, P1, DOI [10.1109/ATSIP49331.2020.9231908, DOI 10.1109/ATSIP49331.2020.9231908]
   Walhazi H, 2020, 2020 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2020), P265, DOI 10.1109/CW49994.2020.00049
   Wu FY, 2021, GRANULAR COMPUT, V6, P217, DOI 10.1007/s41066-019-00182-6
   Yambay D., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P208, DOI 10.1109/ICB.2012.6199810
   Zhang RL, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102144
   Zhao QJ, 2010, PATTERN RECOGN, V43, P1050, DOI 10.1016/j.patcog.2009.08.004
   Zhou Y, 2020, Arxiv, DOI arXiv:2012.05429
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 66
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 26
PY 2023
DI 10.1007/s11042-023-15337-6
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3VP4
UT WOS:000995280400010
DA 2024-07-18
ER

PT J
AU Liu, DJ
   Li, LX
AF Liu, Dongjiang
   Li, Leixiao
TI A node clustering algorithm for heterogeneous information networks based
   on node embeddings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Heterogeneous information networks; Graph mining; Target object;
   Meta-path; Clustering
ID FRAMEWORK
AB Clustering is a very important method to analyze HIN. Thus, several HIN clustering algorithms have been proposed and all these algorithms are based on meta-paths. Meta-path can be used to describe the relationship of target objects. Even though the relationship of target objects are fully considered by these meta-path based algorithms, the directly connected neighbors of target objects are neglected by them. These neglected directly connected neighbors are not target objects, but they contain plenty of useful information for finding clusters of target objects. So, while performing clustering based on HIN, these neglected neighbors should be considered. To achieve the goal, in this paper, a new HIN clustering algorithm is proposed. The proposed algorithm tries to build a vector for each target object. The clustering task is fulfilled based on these vectors. During the vector building process, the neighbors of all the target objects are considered. As clustering result of HIN is affected by different factors, such as neighbors of target objects and different kinds of meta-paths, several similarity matrices are built in the proposed algorithm. Each matrix is corresponding to a specific factor. Besides, every matrix will be assigned a weight value. These weight values are used to represent the relative importance of factors. At the same time, in the proposed algorithm, a new training method is adopted to calculate the vectors and the weight values.
C1 [Liu, Dongjiang; Li, Leixiao] Inner Mongolia Univ Technol, Coll Data Sci & Applicat, JinChuan Ind Pk, Hohhot 010080, Inner Mongolia, Peoples R China.
   [Liu, Dongjiang; Li, Leixiao] Inner Mongolia Autonomous Reg Engn & Technol Res C, JinChuan Ind Pk, Hohhot 010080, Inner Mongolia, Peoples R China.
C3 Inner Mongolia University of Technology
RP Liu, DJ (corresponding author), Inner Mongolia Univ Technol, Coll Data Sci & Applicat, JinChuan Ind Pk, Hohhot 010080, Inner Mongolia, Peoples R China.; Liu, DJ (corresponding author), Inner Mongolia Autonomous Reg Engn & Technol Res C, JinChuan Ind Pk, Hohhot 010080, Inner Mongolia, Peoples R China.
EM ldongjiang@yeah.net
FU Inner Mongolia University of Technology Research Fund Key Project
   [ZZ201908]; Inner Mongolia University of Technology Research project
   doctoral fund [BS2020040]; National Natural Science Foundation of China
   [62062054]; Natural Science Foundation of Inner Mongolia Autonomous
   Doctoral Fund [2020BS06007]; Inner Mongolia Key Technological
   Development Program [2019ZD015]; Key Scientific and Technological
   Research Program of Inner Mongolia Autonomous Region [2019GG273]
FX This work is supported by Inner Mongolia University of Technology
   Research Fund Key Project(ZZ201908), Inner Mongolia University of
   Technology Research project doctoral fund(BS2020040), National Natural
   Science Foundation of China(62062054), Natural Science Foundation of
   Inner Mongolia Autonomous Doctoral Fund(2020BS06007), Inner Mongolia Key
   Technological Development Program (2019ZD015), Key Scientific and
   Technological Research Program of Inner Mongolia Autonomous Region
   (2019GG273).
CR Abbe E, 2018, J MACH LEARN RES, V18
   Agbehadji IE, 2021, APPL SOFT COMPUT, V104, DOI 10.1016/j.asoc.2021.107171
   Ahmed U, 2022, FUTURE GENER COMP SY, V130, P106, DOI 10.1016/j.future.2021.12.008
   Andrienko G, 2018, IEEE T VIS COMPUT GR, V24, P34, DOI 10.1109/TVCG.2017.2744322
   Arain QA, 2018, MULTIMED TOOLS APPL, V77, P5563, DOI 10.1007/s11042-017-4469-4
   Chen Luo, 2014, Advances in Knowledge Discovery and Data Mining. 18th Pacific-Asia Conference, PAKDD 2014. Proceedings: LNCS 8444, P548, DOI 10.1007/978-3-319-06605-9_45
   Cuzzocrea A, 2019, J AMB INTEL HUM COMP, V10, P3383, DOI 10.1007/s12652-018-0966-1
   Djenouri Y, 2021, APPL INTELL, V51, P1888, DOI 10.1007/s10489-020-01922-x
   Djenouri Y, 2018, INFORM SCIENCES, V453, P154, DOI 10.1016/j.ins.2018.04.008
   Fortunato S, 2016, PHYS REP, V659, P1, DOI 10.1016/j.physrep.2016.09.002
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Fu TY, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1797, DOI 10.1145/3132847.3132953
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Gupta M, 2017, EXPERT SYST APPL, V68, P106, DOI 10.1016/j.eswa.2016.10.013
   Jialong Jin, 2021, Journal of Physics: Conference Series, V1757, DOI 10.1088/1742-6596/1757/1/012125
   Jian X, 2020, PROC VLDB ENDOW, V13, P1723, DOI 10.14778/3401960.3401969
   Kong X, 2012, P 21 ACM INT C INF K, P1567, DOI DOI 10.1145/2396761.2398474
   Li X, 2019, AAAI CONF ARTIF INTE, P4221
   Li X, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1621, DOI 10.1145/3038912.3052576
   Memon I, 2019, TELECOMMUN SYST, V70, P557, DOI 10.1007/s11235-019-00551-1
   Memon I, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3437
   Mohammadani KH, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147720921624
   Newman MEJ, 2013, PHYS REV E, V88, DOI 10.1103/PhysRevE.88.042822
   Nikolentzos G, 2017, AAAI CONF ARTIF INTE, P2429
   Reichardt J, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.016110
   Sharma R, 2020, MULTIMED TOOLS APPL, V79, P28155, DOI 10.1007/s11042-020-09347-x
   Sun LC, 2018, 2018 9TH IEEE INTERNATIONAL CONFERENCE ON BIG KNOWLEDGE (ICBK), P131, DOI 10.1109/ICBK.2018.00025
   Sun Y., 2009, ACM INT C P SERIES, P565, DOI DOI 10.1145/1516360.1516426
   Sun YZ, 2012, Arxiv, DOI arXiv:1201.6563
   Sun YZ, 2013, ACM T KNOWL DISCOV D, V7, DOI 10.1145/2500492
   Sun YZ, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P797
   Usama M, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719895957
   Wang CG, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1629, DOI 10.1145/3132847.3133029
   Xia ZC, 2021, ACM T INTEL SYST TEC, V12, DOI 10.1145/3451984
   Xu YJ, 2021, IEEE COMMUN SURV TUT, V23, P668, DOI 10.1109/COMST.2021.3059896
   Yu Xiao., 2012, Pro- ceedings of the 21st ACM international conference on Information and knowledge management (CIKM'12), P2025, DOI DOI 10.1145/2396761.2398565
   Zhang BH, 2021, ACM T KNOWL DISCOV D, V15, DOI 10.1145/3441449
   Zheng Y, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2743025
   Zhou Y, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P338
NR 39
TC 3
Z9 3
U1 6
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 19
PY 2023
DI 10.1007/s11042-023-15245-9
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7MY3
UT WOS:000990967600001
DA 2024-07-18
ER

PT J
AU Sivasankari, K
   Karunanithy, K
AF Sivasankari, K.
   Karunanithy, Kalaivanan
TI Epileptic seizure detection using posterior probability-based
   convolutional neural network classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Electroencephalogram (EEG) Signal; Kendall Rank and Pearson Correlation
   (KRPC); Hilbert Huang Transform based on Entropy Features (HHTEF) and
   Posterior Probability CNN classifier (PP-CNN)
ID DIAGNOSIS
AB Epilepsy is the most common neurological disorders affecting 70 million people worldwide. Nowadays, the advanced Epileptic Seizure (ES) detection from EEG (Electroencephalogram) signal plays a crucial role specifically in its diagnosis process. Traditionally, this diagnosis has been performed by experts using EEG signals on the visual inspection of data for detecting ES. Such a costly and slow process prone to have certain human errors. So, various classification approaches have been developed for epilepsy detection. However, those methods have limitations such as minimum accuracy in detection, high complexity to handle dataset, and low classification rate of features. To handle these challenges, automatic classification system is proposed that classifies the EEG signal as normal, interictal or ictal ones. The features extracted from EEG dataset comprises of time-domain features, frequency domain features and HHTEFs (Hilbert Huang Transform based on Entropy Features). Then, the hybrid correlation filter method combining the KRPC (Kendall Rank and Pearson Correlation) method is employed to select only the significant features and essential in extraction process for improving the classification performance, thus by obtaining relevant features to ease feature classification. The selected features undergo the classification task by using proposed PP-CNN (Posterior Probability-based Convolutional Neural Network). Experimental analysis proved the performances of the proposed method in terms of accuracy, sensitivity, specificity, precision, recall and F1-score. From performance analysis, the proposed framework yielded effective detection for non-seizure and seizure patients than existing methods acquiring 99% accuracy, 99% sensitivity, 99% specificity, 98.50% precision, 99% recall and 98% as F1-score rate.
C1 [Sivasankari, K.] Akshaya Coll Engn & Technol, Dept Elect & Commun Engn, Coimbatore, India.
   [Karunanithy, Kalaivanan] Vellore Inst Technol, Sch Elect Engn, Chennai, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai
RP Sivasankari, K (corresponding author), Akshaya Coll Engn & Technol, Dept Elect & Commun Engn, Coimbatore, India.
EM sivasankari@acetcbe.edu.in
CR Aayesha, 2021, MULTIMED TOOLS APPL, V80, P17849, DOI 10.1007/s11042-021-10597-6
   Ahmadi A., 2018, 2018 Electric Electronics, Computer Science, Biomedical Engineerings' Meeting (EBBT), P1, DOI [DOI 10.1109/QOMEX.2018.8463387, DOI 10.1109/EBBT.2018.8391471]
   Boonyakitanont P, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101702
   Chen GY, 2017, J MED BIOL ENG, V37, P123, DOI 10.1007/s40846-016-0214-0
   Dash DP, 2022, MULTIMED TOOLS APPL, V81, P42057, DOI 10.1007/s11042-021-11487-7
   Geng MX, 2020, IEEE T NEUR SYS REH, V28, P573, DOI 10.1109/TNSRE.2020.2966290
   Giannakaki K., 2021, EAI ENDORSED T BIOEN, V1, DOI [10.4108/eai.13-10-2020.166556, DOI 10.4108/EAI.13-10-2020.166556]
   Guo Y, 2018, AUTOMATED EPILEPTIC
   Hussein R, 2020, ENERGY EFFICIENCY ME, P69
   Li Y, 2020, IEEE T NEUR SYS REH, V28, P782, DOI 10.1109/TNSRE.2020.2973434
   Li Y, 2018, IEEE J BIOMED HEALTH, V22, P386, DOI 10.1109/JBHI.2017.2654479
   Lu YA, 2018, TECHNOL HEALTH CARE, V26, pS337, DOI 10.3233/THC-174679
   Mahjoub C, 2020, BIOMED ENG-BIOMED TE, V65, P33, DOI 10.1515/bmt-2019-0001
   Truong ND, 2017, EXPERT SYST APPL, V86, P199, DOI 10.1016/j.eswa.2017.05.055
   Sharma M, 2018, KNOWL-BASED SYST, V160, P265, DOI 10.1016/j.knosys.2018.07.019
   Sharma R, 2020, J INFORM OPTIM SCI, V41, P143, DOI 10.1080/02522667.2020.1715564
   Sharmila A., 2018, Journal of Medical Engineering & Technology, V42, P217, DOI 10.1080/03091902.2018.1464075
   Singh K, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01613-7
   Sriraam N, 2018, Brain Inform, V5, P10, DOI 10.1186/s40708-018-0088-8
   Subasi A, 2019, NEURAL COMPUT APPL, V31, P317, DOI 10.1007/s00521-017-3003-y
   Thilagaraj M, 2018, CLUSTER COMPUT, P1
   Tiwari AK, 2017, IEEE J BIOMED HEALTH, V21, P888, DOI 10.1109/JBHI.2016.2589971
   Tzimourta KD, 2018, ENG TECHNOL APPL SCI, V8, P3093
   van Rikxoort E., 2007, Proc MICCAI Workshop on 3D Segmentation in the Clinic: a Grand Challenge, P101
   Wang LN, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19060222
   Wang RR, 2014, IEEE T INTELL TRANSP, V15, P239, DOI 10.1109/TITS.2013.2277551
   Wang XS, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00052
   Yuan Q, 2017, SEIZURE-EUR J EPILEP, V50, P99, DOI 10.1016/j.seizure.2017.05.018
   Zhang H, 2016, IEEE-ASME T MECH, V21, P1659, DOI 10.1109/TMECH.2016.2522759
   Zhao C, 2019, FRONT NEUROINFORM, V13, DOI 10.3389/fninf.2019.00031
NR 30
TC 0
Z9 0
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 19
PY 2023
DI 10.1007/s11042-023-15816-w
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G5YV6
UT WOS:000989918800002
DA 2024-07-18
ER

PT J
AU Liu, JY
   Zhang, ML
AF Liu, Jiayu
   Zhang, Minglin
TI Formation mechanism of consumers' purchase intention in multimedia live
   platform: a case study of taobao live
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multimedia; E-commerce live stream; Trust; Consumers' purchase intention
ID SOCIAL COMMERCE; BEHAVIOR; IMPACT; TRUST
AB The rapid development of live e-commerce in China in recent years has been accompanied by a change in consumer shopping behavior and a general upgrading of consumption in China. The rise and development of e-commerce live shopping mainly stem from the fact that the multimedia live stream provides consumers with a different shopping experience. Based on this, this paper outlines the meaning and application of multimedia, introduces the application of multimedia technology in live e-commerce platforms, constructs a model of the influence of visibility, authenticity, and interactivity of live platforms on consumers' purchase intention, and explores the role of trust in influencing both, using a questionnaire survey for empirical research. The results show that the characteristics of visibility, authenticity, and interactivity have significant positive effects on consumers' purchase intentions, and that trust partially mediates the relationship between the three characteristics of the live streaming platform and consumers' purchase intentions. In summary, the results of this study not only explore the formation mechanism of consumers' purchase intention from the perspective of the characteristics of multimedia e-commerce live streaming platforms, but also provide developers with further improvement ideas for the design of e-commerce live streaming platforms.
C1 [Liu, Jiayu] Jiangxi Normal Univ, 99,Ziyang Rd, Nanchang 330022, Jiangxi, Peoples R China.
   [Zhang, Minglin] Shunde Polytech, Desheng East Rd, Foshan 528399, Guangdong, Peoples R China.
C3 Jiangxi Normal University; Shunde Polytechnic
RP Zhang, ML (corresponding author), Shunde Polytech, Desheng East Rd, Foshan 528399, Guangdong, Peoples R China.
EM lliu000122@gmail.com; mlzhang03@163.com
RI liu, jiayu/JCP-0511-2023; Liu, Jiayu/JCO-5073-2023
CR Bai Y, 2015, INT J INFORM MANAGE, V35, P538, DOI 10.1016/j.ijinfomgt.2015.04.011
   Beverland MB, 2008, J ADVERTISING, V37, P5, DOI 10.2753/JOA0091-3367370101
   Chang HH, 2008, ONLINE INFORM REV, V32, P818, DOI 10.1108/14684520810923953
   Chen S. C., 2003, Information Technology & Management, V4, P303, DOI 10.1023/A:1022962631249
   Chen Y, 2013, THESIS BEIJING U POS
   Das TK, 1998, ACAD MANAGE REV, V23, P491, DOI 10.5465/AMR.1998.926623
   Deng YL., 2020, NEWS WRITING, V2020, P95
   Dong JJ, 2019, THESIS JILIN U
   Dong XY, 2018, INT J INFORM MANAGE, V42, P49, DOI 10.1016/j.ijinfomgt.2018.06.002
   Eroglu SA, 2001, J BUS RES, V54, P177, DOI 10.1016/S0148-2963(99)00087-9
   Fu YQ., 2017, J CHONGQING U POSTS, V29, P71
   Gao W, 2018, BEHAV INFORM TECHNOL, V37, P786, DOI 10.1080/0144929X.2018.1484514
   Gu YW, 2020, PRICE THEORY PRACTIC, V2020, P124
   Guo QZ., 2020, NEWS WRITING, V2020, P84
   Guo QZ., 2017, MEDIA, V2017, P9
   Guo WJ, 2017, INFORM STUDIES THEOR, P80, DOI 10.16353/j.cnki.1000-7490.2017.10.015
   Hassanein K, 2007, INT J HUM-COMPUT ST, V65, P689, DOI 10.1016/j.ijhcs.2006.11.018
   Huang QD, 2010, THESIS ZHEJIANG U
   IJsselsteijn WA, 2000, PROC SPIE, V3959, P520, DOI 10.1117/12.387188
   Jia X F, 2019, THESIS BEIJING U POS
   Jia Y, 2022, J HENAN U SOCIAL SCI, V62, P126, DOI [10.15991/j.cnki.411028.2022.01.012, DOI 10.15991/J.CNKI.411028.2022.01.012]
   Li Q., 2020, J. Xi'an Jiaotong Univ, V40, P25, DOI [10.15896/j.xjtuskxb.202002004, DOI 10.15896/J.XJTUSKXB.202002004]
   Liang ZX, 2019, THESIS LANZHOU U FIN
   Lin Y, 2021, J MARKETING RES, V58, P417, DOI 10.1177/00222437211002477
   Liu F., 2020, China J. Manag, V17, P94, DOI DOI 10.3969/J.ISSN.1672-884X.2020.01.011
   Liu Y., 2020, SOFT SCI, V34, P108, DOI DOI 10.13956/J.SS.1001-8409.2020.06.17
   Liu Y, 2013, DECIS SUPPORT SYST, V55, P829, DOI 10.1016/j.dss.2013.04.001
   Lu BZ, 2016, COMPUT HUM BEHAV, V56, P225, DOI 10.1016/j.chb.2015.11.057
   Lv ZP, 2018, ELECTRON COMMER R A, V28, P102, DOI 10.1016/j.elerap.2018.01.003
   Meng F, 2012, THESIS NANJING U
   Meng L., 2020, NANKAI BUS REV NT, V23, P131, DOI DOI 10.3969/J.ISSN.1008-3448.2020.01.013
   Ou CX, 2014, MIS QUART, V38, P209, DOI 10.25300/MISQ/2014/38.1.10
   Pavlou PA, 2004, INFORM SYST RES, V15, P37, DOI 10.1287/isre.1040.0015
   Shen J, 2012, J ELECTRON COMMER RE, V13, P198
   Shin DH, 2011, INT J HUM-COMPUT INT, V27, P450, DOI 10.1080/10447318.2011.552060
   Sjöblom M, 2019, COMPUT HUM BEHAV, V92, P20, DOI 10.1016/j.chb.2018.10.012
   Skadberg YX, 2004, COMPUT HUM BEHAV, V20, P403, DOI 10.1016/S0747-5632(03)00050-5
   Sun Y, 2019, ELECTRON COMMER R A, V37, DOI 10.1016/j.elerap.2019.100886
   Tian ZH., 2020, MEDIA, V17, P15
   Wang B., 2021, China Business and Market (in China), V35, P48, DOI [10.14089/j.cnki.cn11-3664/f.2021.04.005, DOI 10.14089/J.CNKI.CN11-3664/F.2021.04.005]
   Wang X.H., 2017, NANKAI BUS REV NT, V20, P27
   Wongkitrungrueng A., 2020, The role of live streaming in building consumer trust and engagement with social commerce sellers
   Xiao JY., 2021, JOURNALISM LOVER, V2021, P32
   [熊英 Xiong Ying], 2016, [包装工程, Packaging Engineering], V37, P88
   Xu XD., 2018, Jinan Journal (philosophy and Social Sciences Edition), V40, P70, DOI [10.3969/j.issn.1000-5072.2018.03.006, DOI 10.3969/J.ISSN.1000-5072.2018.03.006]
   Yang Q., 2020, PACKAGING ENG, V41, P219, DOI [10.19554/j.cnki.1001-3563.2020.08.032, DOI 10.19554/J.CNKI.1001-3563.2020.08.032]
   Zhang B., 2021, China Bus. Market, V35, P52, DOI [10.14089/j.cnki.cn11-3664/f.2021.06.005, DOI 10.14089/J.CNKI.CN11-3664/F.2021.06.005]
   Zhang KZK, 2016, DECIS SUPPORT SYST, V86, P95, DOI 10.1016/j.dss.2016.04.001
   Zhang M, 2021, RETAIN CUSTOMERS UND
   Zhang ML, 2022, COMPUT HUM BEHAV, V127, DOI 10.1016/j.chb.2021.107052
   Zhou L., 2021, J SW MINZU U HUMANIT, V42, P142
   Zhou Y.S., 2021, Contemporary Economic Management, V43, P40
NR 52
TC 7
Z9 8
U1 74
U2 159
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 18
PY 2023
DI 10.1007/s11042-023-15666-6
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G9GJ2
UT WOS:000992151600002
PM 37362664
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Budhathoki, M
   Alsadoon, A
   Dawoud, A
   Al Bassam, N
   Jerew, OD
   Prasad, PWC
AF Budhathoki, Manish
   Alsadoon, Abeer
   Dawoud, Ahmed
   Al Bassam, Nizar
   Jerew, Oday D.
   Prasad, P. W. C.
TI Knowledge graph for recommendation system: enhanced relation reliability
   and prediction probability (ERRaPP)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Recommender system; Knowledge graph; Learning path recommendation; Link
   prediction
AB With the current explosion of information, the end-users find it challenging to filter this information. Recommendation systems present solutions to filter and prioritize the information to overcome the problem of information overloading. However, one of the main challenges associated with RS is accuracy. A knowledge graph (KG) is one solution to improve the recommendation system's performance. The existing solutions do not consider the side information and semantic relationship from the knowledge graph, which results in the problem of accuracy of the recommendation and the processing time. Our proposed solution aims to increase the accuracy and decrease the processing time by exploring semantic relations between entities and considering the importance of relationships. The proposed system consists of a collaborative knowledge graph (GCN) with Enhanced Relation Reliability and Prediction Probability (ERRaPP) algorithm to enhance the recommendation accuracy and minimize the processing time. This algorithm includes the importance of relation specialized in an entity to get more reliable paths. It also has an attention mechanism with a sigmoid function to replace the inner product between entities embedding to improve the prediction. The results are obtained for different model stages (training, evaluation, test) for 4 other datasets (Book-Crossing, MovieLens-20 M, MovieLens-1 M and Last.FM). The results show that the proposed solution achieves better recommendation accuracy with less processing time for all three stages and 4 datasets. The proposed solution provides the recommendation accuracy of 0.705 against the current accuracy of 0.665 on average for the Book-Crossing dataset and a processing time of 7.884 seconds against the current processing time of 12 seconds on average for the testing stage. The proposed solution focuses on enhancing the overall accuracy and reducing the processing time of the knowledge graph-based recommendation system by using the ERRaPP algorithm. Finally, the solution with enhanced relation reliability and score prediction improves the recommendation accuracy by considering semantic relations between entities.
C1 [Budhathoki, Manish; Alsadoon, Abeer; Dawoud, Ahmed; Prasad, P. W. C.] Charles Sturt Univ CSU, Sch Comp Math & Engn, Wagga Wagga, Australia.
   [Alsadoon, Abeer; Dawoud, Ahmed; Prasad, P. W. C.] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Jerew, Oday D.] Asia Pacific Int Coll APIC, Sydney, Australia.
   [Al Bassam, Nizar] Middle East Coll, Muscat, Oman.
C3 Charles Sturt University; Western Sydney University
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp Math & Engn, Wagga Wagga, Australia.; Alsadoon, A (corresponding author), Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Sydney, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; withana,
   chandana/0000-0002-3007-687X
CR Cantador Ivan, 2011, GL
   Chen J, 2020, IEEE ACCESS, V8, P42436, DOI 10.1109/ACCESS.2020.2976884
   Cui ZY, 2019, IEEE ACCESS, V7, P42255, DOI 10.1109/ACCESS.2019.2907728
   Guo ZY, 2020, NEURAL NETWORKS, V122, P239, DOI 10.1016/j.neunet.2019.10.012
   Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872
   Hongwei Wang, 2019, ACM Transactions on Information Systems, V37, DOI 10.1145/3312738
   Khaire UM, 2020, J AMBIENT INTELL HUM, V1, DOI [10.1109/ACCESS.2020.2973923, DOI 10.1109/ACCESS.2020.2973923]
   Khan N, 2023, APPL INTELL, V53, P2295, DOI 10.1007/s10489-022-03235-7
   Lei K, 2020, NEURAL COMPUT APPL, V32, P6957, DOI 10.1007/s00521-019-04181-1
   Lin XX, 2019, NEURAL COMPUT APPL, V31, P5629, DOI 10.1007/s00521-018-3384-6
   Lu WJ, 2021, EXPERT SYST APPL, V163, DOI 10.1016/j.eswa.2020.113759
   Nabizadeh AH, 2020, COMPUT EDUC, V147, DOI 10.1016/j.compedu.2019.103777
   Nabizadeh AH, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12351
   Peng C., 2023, ARTIF INTELL REV, V3, P1
   Seo S, 2020, IEEE ACCESS, V8, P32816, DOI 10.1109/ACCESS.2020.2973923
   Shen Y, 2021, IEEE T KNOWL DATA EN, V33, P3607, DOI 10.1109/TKDE.2020.2970044
   Shen Y, 2018, ACM/SIGIR PROCEEDINGS 2018, P901, DOI 10.1145/3209978.3210081
   Shi C, 2016, KNOWL INF SYST, V49, P835, DOI 10.1007/s10115-016-0925-0
   Shi DQ, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105618
   Shi Y, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2556270
   Son J, 2017, EXPERT SYST APPL, V89, P404, DOI 10.1016/j.eswa.2017.08.008
   Tao SH, 2020, IEEE ACCESS, V8, P146027, DOI 10.1109/ACCESS.2020.3014670
   Towards data science, UND DAT SCI CLASS ME
   Wang HW, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P417, DOI 10.1145/3269206.3271739
   Wang T, 2020, IEEE ACCESS, V8, P134817, DOI 10.1109/ACCESS.2020.3011279
   Wang X, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P878, DOI 10.1145/3442381.3450133
   Wei J, 2017, EXPERT SYST APPL, V69, P29, DOI 10.1016/j.eswa.2016.09.040
   Yan CR, 2019, IEEE ACCESS, V7, P102239, DOI 10.1109/ACCESS.2019.2928848
   Yu HZ, 2020, WORLD WIDE WEB, V23, P735, DOI 10.1007/s11280-019-00765-y
   Zhang LB, 2018, IEEE ACCESS, V6, P9454, DOI 10.1109/ACCESS.2018.2789866
   Zhu HP, 2018, KNOWL-BASED SYST, V143, P102, DOI 10.1016/j.knosys.2017.12.011
   Ziegler CN, 2000, P 14 INT WORLD WIDE
NR 32
TC 0
Z9 0
U1 7
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 17
PY 2023
DI 10.1007/s11042-023-15790-3
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7EQ1
UT WOS:000990751100002
DA 2024-07-18
ER

PT J
AU Yang, AP
   Wang, CC
   Wang, JB
   Wang, Q
   Zhang, TF
AF Yang, Aiping
   Wang, Chaochen
   Wang, Jinbin
   Wang, Qian
   Zhang, Tengfei
TI Zero-reference single underwater image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater image enhancement; Zero reference; Encoder-decoder network
ID COLOR; QUALITY
AB Underwater images play an essential role in acquiring and analyzing underwater information. Autonomous Underwater Vehicles (AUVs) highly rely on the quality of the captured underwater images, in order to carry out several activities. Due to the poor lighting conditions and the limited capacity of the optical imaging device, captured underwater images usually contain severe color distortions and contrast reduction. To this end, most existing deep learning-based underwater image enhancement methods synthesize the pseudo ground-truth, or employ the in-air clear images as references to train the models. However, the synthesized or selected reference images are generally unsatisfying due to the lack of diversity and applicability. This paper presents a novel underwater image enhancement approach based on training an end-to-end underwater image enhancement network, without using any reference image. A novel encoder-decoder network structure and a set of non-reference loss functions are designed to measure the enhancement quality. The subjective and objective evaluations show that the proposed algorithm outperforms the state-of-the-art approaches.
C1 [Yang, Aiping; Wang, Chaochen; Wang, Jinbin; Wang, Qian; Zhang, Tengfei] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
   [Yang, Aiping] Shanghai Artificial Intelligence Lab, Shanghai, Peoples R China.
C3 Tianjin University
RP Yang, AP (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.; Yang, AP (corresponding author), Shanghai Artificial Intelligence Lab, Shanghai, Peoples R China.
EM yangaiping@tju.edu.cn
RI Wang, Jinbin/HPC-5396-2023
OI Wang, Jinbin/0000-0001-8432-7235
FU National Key Research and Development Program of China [2022ZD0160400];
   National Natural Science Foundation of China [62071323, 62176178];
   Shanghai Artificial Intelligence Laboratory
FX This work was supported by the National Key Research and Development
   Program of China (Grant No.2022ZD0160400) and the National Natural
   Science Foundation of China (Grant Nos. 62071323 and~62176178). We
   gratefully acknowledge the support from Shanghai Artificial Intelligence
   Laboratory.
CR [Anonymous], 2007, Color Constancy
   Barbosa WV, 2018, IEEE IMAGE PROC, P3933, DOI 10.1109/ICIP.2018.8451356
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   Chen XY, 2019, IEEE T IND ELECTRON, V66, P9350, DOI 10.1109/TIE.2019.2893840
   Drews PLJ, 2016, IEEE COMPUT GRAPH, V36, P24, DOI 10.1109/MCG.2016.26
   Dudhane A, 2020, IEEE SIGNAL PROC LET, V27, P675, DOI 10.1109/LSP.2020.2988590
   Fabbri C, 2018, IEEE INT CONF ROBOT, P7159
   Fan QN, 2018, LECT NOTES COMPUT SC, V11217, P455, DOI 10.1007/978-3-030-01261-8_27
   Fu XY, 2014, IEEE IMAGE PROC, P4572, DOI 10.1109/ICIP.2014.7025927
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Hamaguchi R, 2018, IEEE WINT CONF APPL, P1442, DOI 10.1109/WACV.2018.00162
   Hamza AB, 2001, ENERGY MINIMIZATION
   Hashisho Y, 2019, INT SYMP IMAGE SIG, P117, DOI [10.1109/ispa.2019.8868679, 10.1109/ISPA.2019.8868679]
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   HUMMEL R, 1977, COMPUT VISION GRAPH, V6, P184, DOI 10.1016/S0146-664X(77)80011-7
   Gulrajani I, 2017, ADV NEUR IN, V30
   Islam M.J., 2020, arXiv
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2018, IEEE SIGNAL PROC LET, V25, P323, DOI 10.1109/LSP.2018.2792050
   Li J, 2018, IEEE ROBOT AUTOM LET, V3, P387, DOI 10.1109/LRA.2017.2730363
   Li X, 2018, LECT NOTES COMPUT SC, V11211, P262, DOI 10.1007/978-3-030-01234-2_16
   LIU YC, 1995, IEEE T CONSUM ELECTR, V41, P460, DOI 10.1109/30.468045
   Ludvigsen M, 2007, OCEANOGRAPHY, V20, P140, DOI 10.5670/oceanog.2007.14
   Nascimento E, 2009, SIBGRAPI, P330, DOI 10.1109/SIBGRAPI.2009.48
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   STRACHAN NJC, 1993, IMAGE VISION COMPUT, V11, P2, DOI 10.1016/0262-8856(93)90027-E
   Wang N., 2019, ARXIV
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang Y, 2017, IEEE IMAGE PROC, P1382, DOI 10.1109/ICIP.2017.8296508
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Yu X, 2018, INT C PATTERN RECOGN
   Zhang SJ, 2014, IEEE IMAGE PROC, P5422, DOI 10.1109/ICIP.2014.7026097
   Zhang S, 2017, NEUROCOMPUTING, V245, P1, DOI 10.1016/j.neucom.2017.03.029
   Zhao H., 2015, arXiv
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 39
TC 0
Z9 0
U1 19
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46423
EP 46438
DI 10.1007/s11042-023-15695-1
EA MAY 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000985244300001
DA 2024-07-18
ER

PT J
AU Sagbas, EA
   Korukoglu, S
   Balli, S
AF Sagbas, Ensar Arif
   Korukoglu, Serdar
   Balli, Serkan
TI Real-time stress detection from smartphone sensor data using genetic
   algorithm-based feature subset optimization and k-nearest neighbor
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Stress detection; Sensor fusion data; Genetic algorithm; Real-time
   application; Feature selection
ID RECOGNITION; ENVIRONMENTS; PREDICTION; KEYBOARD
AB Stress is the mood of pressure and tension that a person feels. Usually, when the pressure on an individual decrease, the body begins to stabilize the state and calm down. Hence, stress detection in real-time is a critical duty in medical systems. However, acquiring physiological data requires additional equipment and is difficult for users to carry with them at all times. Depending on this problem, it is possible to detect stress through behavioral data. Smartphones are devices that provide various behavioral data that people use constantly throughout the day. In this study, a real-time stress detection system based on soft keyboard typing behaviors was developed with the data obtained from linear acceleration, gravity, gyroscope sensors, and a touchscreen panel of the smartphone. 172 attributes were extracted from the raw sensor data. However, such a high number of dimensions could negatively affect the performance of machine learning algorithms. To address this problem, the number of features was reduced by various techniques such as filter-based methods and standard binary-code chromosome Genetic Algorithm as a contribution to this study. Then, writing behaviors were classified with the commonly used machine learning methods namely, C4.5, kNN, and Bayesian Networks. As a result of the experiments, the best classification was obtained from the kNN method using the features selected by the Genetic Algorithm with a classification accuracy of 89.61% and F-Measure of 0.9052. Another contribution of this study is that a mobile service and a relaxation application were developed for stress detection and to reduce stress levels using the selected feature vector.
C1 [Sagbas, Ensar Arif] Mugla Sitki Kocman Univ, Fac Technol, Dept Informat Syst Engn, TR-48000 Mugla, Turkiye.
   [Korukoglu, Serdar] Ege Univ, Fac Engn, Dept Comp Engn, TR-35100 I?zmir, Turkiye.
   [Balli, Serkan] Mehmet Akif Ersoy Univ, Bucak Technol Fac, Dept Software Engn, TR-15300 Burdur, Turkiye.
C3 Mugla Sitki Kocman University; Ege University; Mehmet Akif Ersoy
   University
RP Sagbas, EA (corresponding author), Mugla Sitki Kocman Univ, Fac Technol, Dept Informat Syst Engn, TR-48000 Mugla, Turkiye.
EM arifsagbas@mu.edu.tr; serdar.korukoglu@ege.edu.tr;
   serkanballi@mehmetakif.edu.tr
RI BALLI, Serkan/D-4751-2018
OI BALLI, Serkan/0000-0002-4825-139X; Sagbas, Ensar
   Arif/0000-0002-7463-1150; Korukoglu, Serdar/0000-0002-4230-8447
CR Akkucuk U., 2011, Veri madenciligi: kumeleme ve siniflama algoritmalari
   Akmandor AO, 2017, IEEE T MULTI-SCALE C, V3, P269, DOI 10.1109/TMSCS.2017.2703613
   Alberdi A, 2016, J BIOMED INFORM, V59, P49, DOI 10.1016/j.jbi.2015.11.007
   Ali AB, 2021, INTELL AUTOM SOFT CO, V29, P571, DOI 10.32604/iasc.2021.015913
   Android, 2020, ACC SERV
   Android, 2021, NOT OV
   [Anonymous], 2022, WEK 3 MACH LEARN SOF
   [Anonymous], 2022, WATCHMAKER FRAMEWORK
   Antistres, 2021, ABOUT US
   Arsalan A, 2021, COMPUT BIOL MED, V133, DOI 10.1016/j.compbiomed.2021.104377
   Asif A, 2019, COMPUT BIOL MED, V107, P182, DOI 10.1016/j.compbiomed.2019.02.015
   Asiri Sidath., 2018, Machine learning classifiers
   Bakker Jorn., 2012, Proceedings of the 2nd ACM SIGHIT International health informatics symposium, P673, DOI DOI 10.1145/2110363.2110439
   Balli S, 2021, CHAOS SOLITON FRACT, V150, DOI 10.1016/j.chaos.2021.111119
   Balli S, 2021, CHAOS SOLITON FRACT, V142, DOI 10.1016/j.chaos.2020.110512
   Beyki M, 2015, CHAOS SOLITON FRACT, V77, P247, DOI 10.1016/j.chaos.2015.05.032
   Bogomolov A, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P477, DOI 10.1145/2647868.2654933
   Can YS, 2020, IEEE ACCESS, V8, P38146, DOI 10.1109/ACCESS.2020.2975351
   Can YS, 2019, J BIOMED INFORM, V92, DOI 10.1016/j.jbi.2019.103139
   Chen KM, 2015, 2015 IEEE 12TH INTERNATIONAL CONFERENCE ON WEARABLE AND IMPLANTABLE BODY SENSOR NETWORKS (BSN)
   Cheng Peng., 2016, Proceedings of the 20th International Academic Mindtrek Conference on - AcademicMindtrek'16, P184, DOI [DOI 10.1145/2994310.2994342, 10.1145/2994310.2994342]
   Cho Y, 2017, INT CONF AFFECT, P456, DOI 10.1109/ACII.2017.8273639
   Choi J, 2012, IEEE T INF TECHNOL B, V16, P279, DOI 10.1109/TITB.2011.2169804
   Cinicioglu EN, 2015, BAYES AG YAPISININ O
   Cokuk B., 2018, AKAD YAKLASIMLAR DER, V9, P59
   Coutts LV, 2020, J BIOMED INFORM, V112, DOI 10.1016/j.jbi.2020.103610
   Ferdous R, 2015, INT CONF PER COMP, P225, DOI 10.4108/icst.pervasivehealth.2015.260192
   Gao Y, 2012, ACM T COMPUT-HUM INT, V19, DOI 10.1145/2395131.2395138
   Garcia-Ceja E, 2016, IEEE J BIOMED HEALTH, V20, P1053, DOI 10.1109/JBHI.2015.2446195
   Ghosh S, 2019, INT CONF COMMUN SYST, P531, DOI [10.1109/comsnets.2019.8711078, 10.1109/COMSNETS.2019.8711078]
   Ghosh S, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI '17), DOI 10.1145/3098279.3098564
   Gimpel H, 2015, P 23 EUR C INF SYST, P1
   Gjoreski M, 2016, UBICOMP'16 ADJUNCT: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P1185, DOI 10.1145/2968219.2968306
   Gjoreski M, 2017, J BIOMED INFORM, V73, P159, DOI 10.1016/j.jbi.2017.08.006
   Gjoreski M, 2015, 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT ENVIRONMENTS IE 2015, P132, DOI 10.1109/IE.2015.27
   Gokalp O, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2020.113176
   Hadi W, 2019, COMPUT BIOL MED, V114, DOI 10.1016/j.compbiomed.2019.103474
   Hall M. A., 1999, Proceedings of the Twelfth International Florida AI Research Society Conference, P235
   Han H, 2018, AVSU'18: PROCEEDINGS OF THE 2018 WORKSHOP ON AUDIO-VISUAL SCENE UNDERSTANDING FOR IMMERSIVE MULTIMEDIA, P11, DOI 10.1145/3264869.3264875
   Holland I.H., 1975, ADAPTATION NATURAL A
   Hollis V, 2017, HUM-COMPUT INTERACT, V32, P208, DOI 10.1080/07370024.2016.1277724
   Inner Balance, 2020, ABOUT US
   Karegowda AG, 2010, INT J INF TECHNOL KN, V2, P271, DOI DOI 10.1007/S12031-014-0367-7
   Kim HJ, 2012, CONSUM COMM NETWORK, P245, DOI 10.1109/CCNC.2012.6181095
   Kononenko I., 1994, Machine Learning: ECML-94. European Conference on Machine Learning. Proceedings, P171
   Kostopoulos P, 2017, L N INST COMP SCI SO, V181, P340, DOI 10.1007/978-3-319-49655-9_41
   Lahmiri S, 2020, CHAOS SOLITON FRACT, V133, DOI 10.1016/j.chaos.2020.109641
   Lee H, 2012, CONSUM COMM NETWORK, P260, DOI 10.1109/CCNC.2012.6181098
   Lu H, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P351
   Maxhuni A, 2016, J BIOMED INFORM, V63, P344, DOI 10.1016/j.jbi.2016.08.023
   Minguillon J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082504
   Mou LT, 2021, EXPERT SYST APPL, V173, DOI 10.1016/j.eswa.2021.114693
   Muaremi A, 2013, BIONANOSCIENCE, V3, P172, DOI 10.1007/s12668-013-0089-2
   Onan A, 2016, The analysis of feature selection methods in text classification, P59
   Padmaja B., 2018, International Journal of Machine Learning and Computing, V8, P33, DOI 10.18178/ijmlc.2018.8.1.659
   Pandey PS, 2017, 17 INT C COMPUTATION
   Panganiban FC, 2021, IEEE REGION 10 SYMP, DOI 10.1109/TENSYMP52854.2021.9550905
   Pause, 2020, PAUS DAIL MINF
   Pearl J., 1988, PROBABILISTIC REASON
   Peker M, 2015, 2015 INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA) PROCEEDINGS, P126
   Plarre K., 2011, Proceedings 2011 10th International Conference on Information Processing in Sensor Networks (IPSN 2010), P97
   Prana Breath, 2021, PRAN BREATH GOOGL PL
   Quinlan J. R., 1993, PROGRAMS MACHINE LEA
   Sagbas EA, 2015, ACAD COMPUT, P158
   Sagbas EA., 2019, J DATA SCI, V2, P19
   Sagbas EA, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-1530-z
   Sen B, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0018-0
   Shaikh R., 2018, Feature selection techniques in machine learning with python
   Sharma S, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104450
   Sysoev M, 2015, PERS UBIQUIT COMPUT, V19, P1045, DOI 10.1007/s00779-015-0885-5
   Tervonen J, 2020, COMPUT BIOL MED, V124, DOI 10.1016/j.compbiomed.2020.103935
   Thapliyal H, 2017, IEEE CONSUM ELECTR M, V6, P64, DOI 10.1109/MCE.2017.2715578
   Vildjiounaite E, 2018, PERS UBIQUIT COMPUT, V22, P671, DOI 10.1007/s00779-017-1108-z
   Wang R, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P3, DOI 10.1145/2632048.2632054
   Witten I., 2002, ACM Sigmod Rec., V31, P76, DOI [10.1145/507338.507355, DOI 10.1145/507338.507355]
   Yargholi E, 2019, CHAOS SOLITON FRACT, V123, P263, DOI 10.1016/j.chaos.2019.04.019
   Yazici B, 2015, VERI MADENCILIGINDE, P9
   Yuksel AS., 2018, DICLE U J ENG, V9, P133
   Yuksel AS, 2019, ARAB J SCI ENG, V44, P3929, DOI 10.1007/s13369-018-03703-8
   Zaman N., 2017, 2017 International Conference on Innovations in Electrical Engineering and Computational Technologies (ICIEECT), P1, DOI 10.1109/ICIEECT.2017.7916593
   Zenonos A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATION WORKSHOPS (PERCOM WORKSHOPS)
   Zhang HJ, 2020, J BIOMED INFORM, V106, DOI 10.1016/j.jbi.2020.103427
   Zhang PF, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11093838
   Zhang PF, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11062848
NR 84
TC 4
Z9 4
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 8
PY 2023
DI 10.1007/s11042-023-15706-1
EA MAY 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F6EN1
UT WOS:000983256400001
DA 2024-07-18
ER

PT J
AU Kumar, N
   Manzar, J
   Shivani
   Garg, S
AF Kumar, Naresh
   Manzar, Juveria
   Shivani
   Garg, Shubham
TI Underwater Image Enhancement using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater image enhancement; Deep learning; CNN; ANN; Machine learning
ID NETWORK; DIAGNOSIS
AB Image capture systems fail to capture high-resolution images when used at great depth underwater, and the equipment is also expensive. With the use of image processing algorithms, it is possible to reconstruct and improve image quality without any costly and reliable image acquisition programs. Developing and rebuilding an underwater image is a daunting task and has gained momentum in recent years. The aim is to improve underwater images by removing graininess, fine-tuning, and sharpening the images using deep learning models.In this work, the authors train four Convolution Neural Network (CNN) based models (two 3-layered and two 5-layered) over GAN-augmented datasets viz. EUVP (Enhancing Underwater Visual Perception)and UIEB (Underwater Image Enhancement Benchmark). Comparisons of these four models are done with the state-of-the-art methods with the aim of identifying the best model. The results showed that the 5-layered model with SGD optimizer performs the best.
C1 [Kumar, Naresh; Manzar, Juveria; Shivani; Garg, Shubham] Maharaja Surajmal Inst Technol, Dept Comp Sci & Engn, New Delhi 110058, India.
C3 Maharaja Surajmal Institute of Technology
RP Kumar, N (corresponding author), Maharaja Surajmal Inst Technol, Dept Comp Sci & Engn, New Delhi 110058, India.
EM narsumsaini@gmail.com; juveriamanzar29@gmail.com;
   shivanilathwal1999@gmail.com; shubhamgarg0502@gmail.com
RI kumar, naresh/AAW-8898-2021
OI kumar, naresh/0000-0001-9984-506X
CR Aggarwal K., 2022, IRAQI J COMPUT SCI M, V3, P115, DOI [DOI 10.52866/IJCSM.2022.01.01.013, 10.52866/ijcsm.2022.01.01.013]
   Anwar S., 2018, arXiv
   Cao KM, 2018, IEEE SW SYMP IMAG, P1, DOI 10.1109/SSIAI.2018.8470347
   Chen X, 2018, QUAL RELIAB ENG INT, P1
   DING X, 2017, OCEANS-IEEE, P1, DOI DOI 10.1109/OCEANSE.2017.8084665
   Gupta M, 2022, SOFT COMPUT, V26, P8025, DOI 10.1007/s00500-022-07047-2
   Hu K, 2022, J MAR SCI ENG, V10, DOI 10.3390/jmse10020241
   Hu K, 2021, J MAR SCI ENG, V9, DOI 10.3390/jmse9070691
   Kodepogu KR, 2022, TRAIT SIGNAL, V39, P1873, DOI 10.18280/ts.390548
   Kumar N, 2022, ENG TECHNOL APPL SCI, V12, P7993, DOI 10.48084/etasr.4613
   Li CY, 2021, IEEE T IMAGE PROCESS, V30, P4985, DOI 10.1109/TIP.2021.3076367
   Li CY, 2018, IEEE SIGNAL PROC LET, V25, P323, DOI 10.1109/LSP.2018.2792050
   Li CY, 2017, PATTERN RECOGN LETT, V94, P62, DOI 10.1016/j.patrec.2017.05.023
   Li HY, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116248
   Li J, 2018, IEEE ROBOT AUTOM LET, V3, P387, DOI 10.1109/LRA.2017.2730363
   Liu XD, 2021, NEUROCOMPUTING, V453, P538, DOI 10.1016/j.neucom.2020.07.130
   Sarma K, 2021, INT C IM PROC CAPS N, P1
   Scattering, 2018, US
   Sun X, 2019, IET IMAGE PROCESS, V13, P469, DOI 10.1049/iet-ipr.2018.5237
   Wang KY, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11131591
   Wang YD, 2021, SIGNAL PROCESS-IMAGE, V96, DOI 10.1016/j.image.2021.116250
   Yang M, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115723
   Zhang HQ, 2021, IET IMAGE PROCESS, V15, P2010, DOI 10.1049/ipr2.12172
NR 23
TC 1
Z9 1
U1 12
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46789
EP 46809
DI 10.1007/s11042-023-15525-4
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:001033146000015
DA 2024-07-18
ER

PT J
AU Li, Z
   Lin, HW
   Liu, YY
   Chen, C
   Xia, YF
AF Li, Zhu
   Lin, Hong-wei
   Liu, Yuan-yuan
   Chen, Chong
   Xia, Yun-fei
TI An industrial defect detection algorithm based on CPU-GPU parallel call
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Workpiece positioning; Defect segmentation; CPU-GPU parallel call
   algorithm; Double pyramid method; Lightweight network
AB The workpiece positioning and defect segmentation are two key steps in the workpiece detection process. This paper has designed a CPU-GPU parallel call algorithm based on real industrial quality inspection conditions to realize the high-speed workpiece defect detection. The algorithm can fully utilize all computing resources of the industrial control computer while simultaneously accomplishing the workpiece positioning and defect segmentation tasks. Moreover, to reduce the workpiece defect detection's scope and improve the defect segmentation algorithm's efficiency, the proposed method uses the workpiece positioning results. As for the positioning task, we have designed the double pyramid method to enhance the positioning speed. When it comes to the defect segmentation task, we have introduced the lightweight network to improve the workpiece segmentation speed. Considering that the current general data sets are of the workpiece local image(s) post cutting, we set up a new data set to reflect the situation in the industrial field. It consists of images taken from real industrial fields that can better verify the whole quality inspection algorithm process, including the positioning and segmentation algorithms. According to our experiment, our algorithm accomplished the positioning and defect segmentation tasks at a speed of 116FPS. Additionally, the segmentation accuracy reached 75.12% Mean IoU.
C1 [Li, Zhu; Lin, Hong-wei; Liu, Yuan-yuan; Chen, Chong; Xia, Yun-fei] Hangzhou Dianzi Univ, Sch Elect & Informat, Hangzhou 310000, Peoples R China.
C3 Hangzhou Dianzi University
RP Lin, HW (corresponding author), Hangzhou Dianzi Univ, Sch Elect & Informat, Hangzhou 310000, Peoples R China.
EM zenglingege@163.com
RI liu, yuanyuan/HSG-8372-2023; liu, yuanyuan/GWZ-5838-2022; Xia,
   Yunfei/KIC-0347-2024
OI Li, Zhu/0000-0001-6373-5846; Lin, Hongwei/0000-0002-7107-4440
FU Zhejiang Provincial Key Lab of Equipment Electronics, Hangzhou, China
FX This work was supported by the Zhejiang Provincial Key Lab of Equipment
   Electronics, Hangzhou, China.
CR Bao YQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3083561
   Bulnes FG, 2016, J INTELL MANUF, V27, P431, DOI 10.1007/s10845-014-0876-9
   Chen FJ, 2019, INT J ADV MANUF TECH, V100, P2669, DOI 10.1007/s00170-018-2845-5
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Fuqiang Zhong, 2017, International Journal of Advanced Manufacturing Technology, V93, P55, DOI 10.1007/s00170-015-7638-5
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang YQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3047190
   Huang YB, 2020, VISUAL COMPUT, V36, P85, DOI 10.1007/s00371-018-1588-5
   Jing JF, 2022, TEXT RES J, V92, P30, DOI 10.1177/0040517520928604
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li XF, 2020, IEEE ACCESS, V8, P59934, DOI 10.1109/ACCESS.2020.2982288
   Lin H, 2019, J INTELL MANUF, V30, P2525, DOI 10.1007/s10845-018-1415-x
   Liu JL, 2019, J ENG-JOE, V2019, P9118, DOI 10.1049/joe.2018.9198
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo GF, 2018, INT J THEOR PHYS, V57, P2447, DOI 10.1007/s10773-018-3766-7
   Monari J, 2006, ACTA ASTRONAUT, V58, P230, DOI 10.1016/j.actaastro.2005.09.004
   Oztemel E, 2020, J INTELL MANUF, V31, P127, DOI 10.1007/s10845-018-1433-8
   Paniagua B, 2010, J INTELL MANUF, V21, P745, DOI 10.1007/s10845-009-0251-4
   Racki D, 2018, IEEE WINT CONF APPL, P1331, DOI 10.1109/WACV.2018.00150
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sedaghat A, 2019, INT J REMOTE SENS, V40, P2576, DOI 10.1080/01431161.2018.1528402
   Silvestre-Blanes J, 2019, AUTEX RES J, V19, P363, DOI 10.2478/aut-2019-0035
   Tabernik D, 2020, J INTELL MANUF, V31, P759, DOI 10.1007/s10845-019-01476-x
   Tao X, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8091575
   Weimer D, 2016, CIRP ANN-MANUF TECHN, V65, P417, DOI 10.1016/j.cirp.2016.04.072
   Wolfschläger D, 2022, PRECIS ENG, V75, P129, DOI 10.1016/j.precisioneng.2022.01.010
   Yang YG, 2015, OPTIK, V126, P3340, DOI 10.1016/j.ijleo.2015.08.010
   Yongfei Z, 2021, J PHYS C SER, V1939
   Yu CQ, 2021, INT J COMPUT VISION, V129, P3051, DOI 10.1007/s11263-021-01515-2
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
NR 32
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44191
EP 44207
DI 10.1007/s11042-023-15613-5
EA MAY 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000979963000005
DA 2024-07-18
ER

PT J
AU Guo, JB
   Wang, GQ
   Guan, W
   Chen, ZR
   Liu, ZB
AF Guo, Jianbo
   Wang, Guoqiang
   Guan, Wei
   Chen, Zeren
   Liu, Zhengbin
TI A feasible region detection method for vehicles in unstructured
   environments based on PSMNet and improved RANSAC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unstructured environment; Point cloud; Feasible region; Stereo matching;
   3D reconstruction
ID SEGMENTATION; EXTRACTION; ALGORITHM
AB Feasible region detection is a critical problem in the field of intelligent driving. To solve the problem that the feasible region of vehicles is difficult to identify in the unstructured environment, a detection method based on the improved Random Sample Consensus (RANSAC) algorithm and Pyramidal Stereo Matching Network (PSMNet) is proposed in this paper. To overcome the influence of the complex environment and weather on the detection results, the 3D point cloud of the detection region is established to restore the actual scene. In contrast to the traditional stereo matching algorithm, the disparity map is obtained by the deep learning method PSMNet. Therefore, the 3D reconstruction of the detection region can be realized more accurately. Subsequently, the method of point cloud selection in RANSAC is redefined by constructing the k-dimensional tree (kd-tree) and using radius space density. Finally, the detection results of the feasible region are obtained by the improved RANSAC. It is tested in a variety of scenarios in complex environments and weather. The results demonstrate the high environmental adaptability and stability of the detection method. And compared with another method Segformer, the comparison results indicate that the method is effective in detecting road scenes under multiple weather conditions.
C1 [Guo, Jianbo; Wang, Guoqiang; Guan, Wei; Liu, Zhengbin] Jilin Univ, Sch Mech & Aerosp Engn, Changchun 130025, Peoples R China.
   [Chen, Zeren] Taiyuan Univ Technol, Coll Mech & Vehicle Engn, Taiyuan 030024, Peoples R China.
C3 Jilin University; Taiyuan University of Technology
RP Wang, GQ (corresponding author), Jilin Univ, Sch Mech & Aerosp Engn, Changchun 130025, Peoples R China.
EM guojb20@mails.jlu.edu.cn; wanggqjlu@outlook.com;
   guanwei21@mails.jlu.edu.cn; chenzeren@tyut.edu.cn;
   zbliu20@mails.jlu.edu.cn
OI Guo, Jianbo/0000-0002-2762-7423
FU National Natural Science Foundation of China [51775225]; Graduate
   Innovation Fund of Jilin University [101832020CX111]
FX AcknowledgmentsThe authors gratefully acknowledged the National Natural
   Science Foundation of China (grant number 51775225) and the Graduate
   Innovation Fund of Jilin University (grant number 101832020CX111) for
   the financial support of these studies.
CR Alvarez JM, 2008, IEEE INT VEH SYM, P952
   Baheti B, 2020, PATTERN RECOGN LETT, V138, P223, DOI 10.1016/j.patrec.2020.07.029
   Bellone M., 2013, 2013 IEEE International Conference on Mechatronics (ICM), P225, DOI 10.1109/ICMECH.2013.6518540
   Bento LC, 2005, 2005 IEEE Intelligent Transportation Systems Conference (ITSC), P245
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Chen AH, 2014, APPL MECH MATER, V475-476, P337, DOI 10.4028/www.scientific.net/AMM.475-476.337
   Chen C, 2019, PROCEEDINGS OF 2019 IEEE 8TH JOINT INTERNATIONAL INFORMATION TECHNOLOGY AND ARTIFICIAL INTELLIGENCE CONFERENCE (ITAIC 2019), P1753, DOI [10.1109/ITAIC.2019.8785774, 10.1109/itaic.2019.8785774]
   Chen L, 2012, SENSORS-BASEL, V12, P12386, DOI 10.3390/s120912386
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Gao ZF, 2020, IEEE NETWORK, V34, P216, DOI 10.1109/MNET.001.1900260
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Girisha S, 2019, IEEE ACCESS, V7, P136239, DOI 10.1109/ACCESS.2019.2941026
   Han BG, 2011, MEASUREMENT, V44, P1645, DOI 10.1016/j.measurement.2011.06.014
   He P, 2014, APPL MECH MATER, V678, P35, DOI 10.4028/www.scientific.net/AMM.678.35
   Jebamikyous HH, 2022, IEEE ACCESS, V10, P10523, DOI 10.1109/ACCESS.2022.3144407
   Kendall Alex, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P66, DOI 10.1109/ICCV.2017.17
   Li J, 2019, CHIN CONT DECIS CONF, P3338, DOI [10.1109/ccdc.2019.8833239, 10.1109/CCDC.2019.8833239]
   Li Y, 2018, ROBOT AUTON SYST, V109, P86, DOI 10.1016/j.robot.2018.08.011
   Magrini M, 2015, IEEE INT C INTELL TR, P161, DOI 10.1109/ITSC.2015.35
   Melo J, 2006, IEEE T INTELL TRANSP, V7, P188, DOI 10.1109/TITS.2006.874706
   Niskanen I, 2021, AUTOMAT CONSTR, V121, DOI 10.1016/j.autcon.2020.103429
   Pang JH, 2017, IEEE INT CONF COMP V, P878, DOI 10.1109/ICCVW.2017.108
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Varma G, 2019, IEEE WINT CONF APPL, P1743, DOI 10.1109/WACV.2019.00190
   Wang L, 2016, AUTOMAT CONSTR, V72, P294, DOI 10.1016/j.autcon.2016.05.008
   Xie EZ, 2021, ADV NEUR IN, V34
   Xu HF, 2020, PROC CVPR IEEE, P1956, DOI 10.1109/CVPR42600.2020.00203
   Yang GR, 2019, PROC CVPR IEEE, P899, DOI 10.1109/CVPR.2019.00099
   Yang KL, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16111954
   Zhang ZX, 2011, LECT NOTES COMPUT SC, V7098, P150, DOI 10.1007/978-3-642-25449-9_19
   Zhang ZH, 2019, IOP C SER EARTH ENV, V252, DOI 10.1088/1755-1315/252/4/042089
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhao DX, 2018, MEASUREMENT, V127, P104, DOI 10.1016/j.measurement.2018.05.062
   Zhou T, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION ENGINEERING (ICRAE), P202, DOI 10.1109/ICRAE.2018.8586678
NR 35
TC 3
Z9 3
U1 4
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43967
EP 43989
DI 10.1007/s11042-023-15412-y
EA APR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000976628900003
DA 2024-07-18
ER

PT J
AU Su, YN
   Wang, XY
AF Su, Yining
   Wang, Xingyuan
TI Quantum color image encryption based on controlled two-particle quantum
   walks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quantum walks; Quantum image processing; Quantum image encryption;
   Performance analysis
ID CHAOTIC SYSTEM; REPRESENTATION
AB Because of the impact of quantum computer and quantum algorithm on modern encryption algorithms, especially quantum computing can crack cryptographic protocols based on pseudo-random sequences. Quantum walks are general model in quantum computing. It has nonlinear dynamic behavior and sensitivity to initial values. Therefore, quantum walks can be approximated as chaotic system, which provides a new idea for modern cryptography research. A color quantum image algorithm based on controlled two-particle quantum walks are proposed in this paper. This algorithm protects the privacy of images for people using the Internet. The algorithm uses the sequence generated by quantum walks and quantum rotation to scramble, and controls the NOT gate to perform the diffusion operation. Through the performance analysis, the correlation coefficient of the ciphertext images is close to 0, the NPCR and UACI are close to 99.60%, 33.46%, and the information entropy is close to 8, etc. Therefore, the present algorithm is safe and efficient.
C1 [Su, Yining; Wang, Xingyuan] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian, Peoples R China.
C3 Dalian Maritime University
RP Su, YN (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian, Peoples R China.
EM 2081604413@qq.com
FU National Natural Science Foundation of China [61672124]; Password Theory
   Project of the 13th FiveYear Plan National Cryptography Development Fund
   [MMJJ20170203]; Liaoning Province Science and Technology Innovation
   Leading Talents Program Project [XLYC1802013]; Key R&D Projects of
   Liaoning Province [2019020105-JH2/103]; Jinan City 20 universities'
   Funding Projects Introducing Innovation Team Program [2019GXRC031]
FX This research is supported by the National Natural Science Foundation of
   China (No: 61672124), the Password Theory Project of the 13th FiveYear
   Plan National Cryptography Development Fund (No: MMJJ20170203), Liaoning
   Province Science and Technology Innovation Leading Talents Program
   Project (No: XLYC1802013), Key R&D Projects of Liaoning Province (No:
   2019020105-JH2/103), Jinan City 20 universities' Funding Projects
   Introducing Innovation Team Program (No: 2019GXRC031).
CR Abd EL-Latif AA, 2020, PHYSICA A, V547, DOI 10.1016/j.physa.2019.123869
   Abd El-Latif AA, 2020, IEEE T NETW SERV MAN, V17, P118, DOI 10.1109/TNSM.2020.2969863
   Abd EL-Latif AA, 2020, OPT LASER TECHNOL, V124, DOI 10.1016/j.optlastec.2019.105942
   Abd El-Latif AA, 2019, OPT LASER TECHNOL, V116, P92, DOI 10.1016/j.optlastec.2019.03.005
   Abd-El-Atty B, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-019-2386-3
   Carson GR, 2015, QUANTUM INF PROCESS, V14, P3193, DOI 10.1007/s11128-015-1047-4
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Venegas-Andraca SE, 2012, QUANTUM INF PROCESS, V11, P1015, DOI 10.1007/s11128-012-0432-5
   Gao SK, 2011, OPT EXPRESS, V19, P26161, DOI 10.1364/OE.19.026161
   Jiang N, 2015, QUANTUM INF PROCESS, V14, P4001, DOI 10.1007/s11128-015-1099-5
   Khan M, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-019-2410-7
   Le PQ, 2011, QUANTUM INF PROCESS, V10, P63, DOI 10.1007/s11128-010-0177-y
   Li D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-017-18566-6
   Li HS, 2019, MOD PHYS LETT A, V34, DOI 10.1142/S0217732319502146
   Li Q, 2022, IEEE T CIRC SYST VID, V32, P5695, DOI 10.1109/TCSVT.2021.3138795
   Liu HJ, 2019, MULTIMED TOOLS APPL, V78, P15997, DOI 10.1007/s11042-018-6996-z
   Liu XB, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20110867
   Lovett NB, 2010, PHYS REV A, V81, DOI 10.1103/PhysRevA.81.042330
   Luo GF, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-018-2165-6
   Luo J, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-51598-8
   Ma B, 2016, IEEE T INF FOREN SEC, V11, P1914, DOI 10.1109/TIFS.2016.2566261
   Mavroeidis V, 2018, INT J ADV COMPUT SC, V9, P405
   Su YN, 2022, PHYSICA A, V587, DOI 10.1016/j.physa.2021.126529
   Tan RC, 2016, INT J THEOR PHYS, V55, P5368, DOI 10.1007/s10773-016-3157-x
   Wang L, 2020, MULTIMED TOOLS APPL, V79, P6661, DOI 10.1007/s11042-019-08514-z
   Wang MX, 2019, OPT LASER ENG, V121, P479, DOI 10.1016/j.optlaseng.2019.05.013
   Wang XY, 2022, MULTIMED TOOLS APPL, V81, P13845, DOI 10.1007/s11042-022-12220-8
   Yan F, 2016, QUANTUM INF PROCESS, V15, P1, DOI 10.1007/s11128-015-1195-6
   Yang YG, 2016, INFORM SCIENCES, V345, P257, DOI 10.1016/j.ins.2016.01.078
   Yang YG, 2016, SCI REP-UK, V6, DOI 10.1038/srep20362
   Yang YG, 2016, SCI REP-UK, V6, DOI 10.1038/srep19788
   Yao W, 2015, NONLINEAR DYNAM, V81, P151, DOI 10.1007/s11071-015-1979-3
   Zhang Y, 2013, QUANTUM INF PROCESS, V12, P2833, DOI 10.1007/s11128-013-0567-z
   Zhang YQ, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106040
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1902-1
   Zhou NR, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-017-1612-0
   Zhou Y, 2019, INT J THEOR PHYS, V58, P950, DOI 10.1007/s10773-018-3987-9
NR 37
TC 3
Z9 4
U1 8
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42679
EP 42697
DI 10.1007/s11042-023-15189-0
EA APR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000970708600002
DA 2024-07-18
ER

PT J
AU Asghari, S
   Nematzadeh, H
   Akbari, E
   Motameni, H
AF Asghari, Sadegh
   Nematzadeh, Hossein
   Akbari, Ebrahim
   Motameni, Homayun
TI Mutual information-based filter hybrid feature selection method for
   medical datasets using feature clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clustering; Feature selection; Normalized mutual information;
   High-dimensional medical datasets
ID CLASSIFICATION; ALGORITHM; SEARCH
AB Clustering is regarded as one of the most difficult tasks due to the large search space that must be explored. Feature selection aims to reduce the dimensionality of data, thereby contributing to further processing. The feature subset achieved by any feature selection method should enhance classification accuracy by removing redundant features. To this end, this paper proposes a new model, called Best Clustering Normalized Mutual Information Quantile (BC-NMIQ), to rank the best features using the square root threshold. Finally, the proposed BC-NMIQ is improved with the optimal set of features selected automatically using the Incremental Association Markov Blanket (IAMB) feature selection method. The measurement criteria are applied to BC-NMIQ-IAMB as the main proposed method and to BC-NMIQ as a subsidiary proposed method. In fact, the hybrid BC-NMIQ-IAMB is the combination of the proposed filter method (BC-NMIQ) and the existing automatic filter feature selection approach (IAMB). To test the performance of the proposed BC-NMIQ-IAMB algorithm, its performance is compared with that of some other algorithms recently proposed in the literature. The results of the experiments, which were conducted on ten benchmark high-dimensional medical datasets (including binary and multi-class), confirmed that BC-NMIQ-IAMB increases the average accuracy of existing binary and multi-class algorithms to 0.92 and 0.94, respectively.
C1 [Asghari, Sadegh; Nematzadeh, Hossein; Akbari, Ebrahim; Motameni, Homayun] Islamic Azad Univ, Dept Comp Engn, Sari Branch, Sari, Iran.
C3 Islamic Azad University
RP Nematzadeh, H (corresponding author), Islamic Azad Univ, Dept Comp Engn, Sari Branch, Sari, Iran.
EM hossein.nematzadeh@iau.ac.ir
RI asghari, sadegh/JAC-0789-2023
OI asghari, sadegh/0000-0001-5172-4074; Akbari,
   Ebrahim/0000-0002-4721-049X; Nematzadeh, Hossein/0000-0002-6161-0430
CR Abasabadi S, 2022, J SUPERCOMPUT, V78, P19725, DOI 10.1007/s11227-022-04650-w
   Abasabadi S, 2021, INFORM SYST, V100, DOI 10.1016/j.is.2021.101760
   Ahmed YA, 2020, J NETW COMPUT APPL, V167, DOI 10.1016/j.jnca.2020.102753
   Al-Batah M, 2019, INT J ONLINE BIOMED, V15, P62, DOI 10.3991/ijoe.v15i08.10617
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Ali H, 2018, NEURAL COMPUT APPL, V29, P13, DOI 10.1007/s00521-016-2501-7
   Alirezanejad M, 2020, GENOMICS, V112, P1173, DOI 10.1016/j.ygeno.2019.07.002
   Ankerst M., 1999, SIGMOD Record, V28, P49, DOI 10.1145/304181.304187
   Awan N, 2021, IEEE ACCESS, V9, P26502, DOI 10.1109/ACCESS.2021.3056926
   Nguyen BH, 2020, SWARM EVOL COMPUT, V54, DOI 10.1016/j.swevo.2020.100663
   Blömer J, 2016, LECT NOTES COMPUT SC, V9220, P81, DOI 10.1007/978-3-319-49487-6_3
   Brankovic A, 2019, IEEE ACM T COMPUT BI, V16, P1802, DOI 10.1109/TCBB.2018.2833482
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Chang H, 2008, PATTERN RECOGN, V41, P191, DOI 10.1016/j.patcog.2007.04.010
   Chaudhuri A, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2020.106963
   Chowdhary C.L., 2018, Nature inspired computing, P75
   Chowdhary CL, 2016, INT J HEALTHC INF SY, V11, P38, DOI 10.4018/IJHISI.2016040103
   Debata PP, 2022, J KING SAUD UNIV-COM, V34, P4743, DOI 10.1016/j.jksuci.2020.12.014
   Dimic G, 2019, 2019 14 INT C ADV TE
   Ehlert KM, 2019, 2019 IEEE FRONT ED C, P1
   Estévez PA, 2009, IEEE T NEURAL NETWOR, V20, P189, DOI 10.1109/TNN.2008.2005601
   Fleuret F, 2004, J MACH LEARN RES, V5, P1531
   Gu XY, 2022, APPL INTELL, V52, P1436, DOI 10.1007/s10489-021-02412-4
   Gunasundari S, 2018, COMPUT MED IMAG GRAP, V70, P135, DOI 10.1016/j.compmedimag.2018.10.003
   Hallajian B, 2022, EXPERT SYST APPL, V200, DOI 10.1016/j.eswa.2022.116794
   Hancer E, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103307
   Iqbal T, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1072-9
   Lensen A, 2017, EUR C APPL EV COMP
   Lensen A, 2016, PROCEEDINGS OF 2016 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI)
   Li J, 2020, J INF PROCESS SYST, V16, P718, DOI 10.3745/JIPS.04.0174
   Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133
   Murtagh F, 2012, WIRES DATA MIN KNOWL, V2, P86, DOI 10.1002/widm.53
   Nakariyakul S, 2009, PATTERN RECOGN, V42, P1932, DOI 10.1016/j.patcog.2008.11.018
   Nematzadeh H, 2019, GENOMICS, V111, P1946, DOI 10.1016/j.ygeno.2019.01.006
   Okagbue HI, 2017, LECT NOTES ENG COMP, P477
   Rathod RR, 2017, INT J ENERGY SECT MA, V11, P295, DOI 10.1108/IJESM-02-2016-0005
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Rostami M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-020-00398-3
   Rostami M, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00352-3
   Rostami M, 2020, GENOMICS, V112, P4370, DOI 10.1016/j.ygeno.2020.07.027
   Sadeghian Z, 2021, ENG APPL ARTIF INTEL, V97, DOI 10.1016/j.engappai.2020.104079
   Sanchez Eduardo Hugo, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P205, DOI 10.1007/978-3-030-58542-6_13
   Sheikhpour R, 2017, PATTERN RECOGN, V64, P141, DOI 10.1016/j.patcog.2016.11.003
   Sheng WG, 2008, IEEE T KNOWL DATA EN, V20, P868, DOI 10.1109/TKDE.2008.33
   Sreedhar Kumar S., 2019, Int J Eng Technol (UAE), V8, P29, DOI DOI 10.14419/IJET.V8I1.13971
   Talbi E-G, 2009, Metaheuristics: from Design to Implementation, DOI DOI 10.1002/9780470496916
   Thejas GS, 2019, IEEE ACCESS, V7, P116875, DOI 10.1109/ACCESS.2019.2936346
   Xue B, 2013, IEEE T CYBERNETICS, V43, P1656, DOI 10.1109/TSMCB.2012.2227469
   Yan CH, 2019, ANAL CHIM ACTA, V1080, P35, DOI 10.1016/j.aca.2019.07.012
   Yang J, 2017, NEURAL COMPUT, V29, P3094, DOI [10.1162/neco_a_01014, 10.1162/NECO_a_01014]
   Zhong WC, 2021, INFORM SCIENCES, V566, P178, DOI 10.1016/j.ins.2021.02.035
   Zhou, 2010, P 13 INT C ARTIFICIA
   Zhu JT, 2021, NEURAL PROCESS LETT, V53, P257, DOI 10.1007/s11063-020-10383-9
   Zhu ZX, 2007, PATTERN RECOGN, V40, P3236, DOI 10.1016/j.patcog.2007.02.007
NR 56
TC 2
Z9 2
U1 3
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42617
EP 42639
DI 10.1007/s11042-023-15143-0
EA APR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000970495100003
DA 2024-07-18
ER

PT J
AU Bostan, H
   Bostan, A
AF Bostan, Hakan
   Bostan, Atila
TI Shoulder surfing resistant graphical password schema: Randomized Pass
   Points (RPP)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile security; Shoulder surfing; Security; Authentication
AB Shoulder-surfing attacks are pervading in today's digital environment. With the widespread usage of mobile devices in public and uncontrolled settings, intentional or unintentional observation of user authentication processes is quite frequent. Scientists in the security domain have spent considerable effort in developing shoulder-surfing-resistant authentication mechanisms. In this study, a pass-graph methodology that benefits from randomity and alternative pass-graphs derivation is proposed with the name of Randomized Pass Points. The proposed authentication methodology is scrutinized for its resistance to brute force and shoulder-surfing attacks. Evaluations prove that the proposed alternative is stronger than that of the 8-digit 71-character-set password methodology against brute force attacks and it necessitates at least 5 valid log-ins to be captured by the attacker to derive the pass-graph under given assumptions in shoulder-surfing attack.
C1 [Bostan, Hakan] Middle East Tech Univ, Comp Engn Dept, TR-06800 Ankara, Turkiye.
   [Bostan, Atila] Ankara Sci Univ, Comp Engn Dept, TR-06200 Ankara, Turkiye.
C3 Middle East Technical University; Ankara Science University
RP Bostan, A (corresponding author), Ankara Sci Univ, Comp Engn Dept, TR-06200 Ankara, Turkiye.
EM hbostann@gmail.com; atilabostan@hotmail.com
RI Bostan, Atila/AAY-2187-2020
OI Bostan, Atila/0000-0002-8540-7605
CR Alsuhibany SA, 2020, J AMB INTEL HUM COMP, V11, P1645, DOI 10.1007/s12652-019-01269-3
   Amer MMM., 2022, F1000RESEARCH, V11, P362, DOI [10.12688/f1000research.73691.1, DOI 10.12688/F1000RESEARCH.73691.1]
   Bianchi A, 2011, TEI 2011: PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION, P197
   Binbeshr F, 2021, COMPUT SECUR, V101, DOI 10.1016/j.cose.2020.102116
   Blonder GE, 1996, Graphical Password U.S. Patent, Patent No. [5559961, US 5559961]
   Burks A., 1970, Essays on Cellular Automata, chapter Von Neumann's selfreproducing automata, P3
   Eiband M, 2016, P 2016 CHI C HUM FAC
   Farzand H, 2021, MENSCH AND COMPUTER 2021 (MUC 21), P338, DOI 10.1145/3473856.3474006
   Jermyn IH., 1999, The design and analysis of graphical passwords
   Khedr WI, 2018, J INF SECUR APPL, V39, P41, DOI 10.1016/j.jisa.2018.02.003
   Kumar M., 2007, P 3 S US PRIV SEC, P13, DOI DOI 10.1145/1280680.1280683
   Li Z, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P245
   Luo JN, 2016, MULTIMED TOOLS APPL, V75, P14075, DOI 10.1007/s11042-015-3129-9
   Malek B, 2006, P EUROHAPTICS, V6
   Man S, 2003, SAM'03: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SECURITY AND MANAGEMENT, VOLS 1 AND 2, P105
   Minoofam SAH, 2012, J CELL AUTOM, V7, P321
   Papadopoulos A, 2017, IEEE T INF FOREN SEC, V12, P2875, DOI 10.1109/TIFS.2017.2725199
   Perkovic Toni, 2010, Journal of Communication Software & Systems, V6, P65
   Rajanna Vijay., 2017, P 2017 CHI C EXTENDE, DOI DOI 10.1145/3027063.3053070
   Roth V., 2004, Proceedings of the 11th ACM Conference on Computer and Communications Security, P236
   Sun HM, 2018, IEEE T DEPEND SECURE, V15, P180, DOI 10.1109/TDSC.2016.2539942
   Varshney S, 2020, CYBERNETICS COGNITIO, P79, DOI DOI 10.1007/978-981-15-1632-0_9
   Wang Z, 2022, SECUR COMMUN NETW, V2022
   Wiedenbeck S., 2006, Proceedings of the working conference on Advanced visual interfaces (AVI '06), P177
   Wu TS, 2014, INT J INF SECUR, V13, P245, DOI 10.1007/s10207-013-0216-7
   Yi-Lun Chen, 2013, 2013 2nd International Symposium on Next-Generation Electronics (ISNE 2013), P161, DOI 10.1109/ISNE.2013.6512317
   Yu XJ, 2017, COMPUT SECUR, V70, P179, DOI 10.1016/j.cose.2017.05.006
NR 27
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43517
EP 43541
DI 10.1007/s11042-023-15227-x
EA APR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000970495100009
DA 2024-07-18
ER

PT J
AU Agilandeeswari, L
   Prabukumar, M
   Alenizi, FA
AF Agilandeeswari, L.
   Prabukumar, M.
   Alenizi, Farhan A.
TI A robust semi-fragile watermarking system using Pseudo-Zernike moments
   and dual tree complex wavelet transform for social media content
   authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content authentication; Cuckoo search optimization; Digital
   watermarking; Dual-tree complex wavelet transform; Intentional attacks;
   Pseudo-Zernike moments; Unintentional attacks
ID COPYRIGHT PROTECTION; ALGORITHM; SCHEME; NETWORKS; IMAGES
AB With the growing use of mobile devices and Online Social Networks (OSNs), sharing digital content, especially digital images is extremely high as well as popular. This made us convenient to handle the ongoing COVID-19 crisis which has brought about years of change in the sharing of digital content online. On the other hand, the digital image processing tools which are powerful enough to make the perfect image duplication compromises the privacy of the transmitted digital content. Therefore, content authentication, proof of ownership, and integrity of digital images are considered crucial problems in the world of digital that can be accomplished by employing a digital watermarking technique. On contrary, watermarking issues are to triumph trade-offs among imperceptibility, robustness, and payload. However, most existing systems are unable to handle the problem of tamper detection and recovery in case of intentional and unintentional attacks concerning these trade-offs. Also, the existing system fails to withstand the geometrical attacks. To resolve the above shortcomings, this proposed work offers a new multi-biometric based semi-fragile watermarking system using Dual-Tree Complex Wavelet Transform (DTCWT) and pseudo-Zernike moments (PZM) for content authentication of social media data. In this research work, the DTCWT-based coefficients are used for achieving maximum embedding capacity. The Rotation and noise invariance properties of Pseudo Zernike moments make the system attain the highest level of robustness when compared to conventional watermarking systems. To achieve authentication and proof of identity, the watermarks of about four numbers are used for embedding as a replacement for a single watermark image in traditional systems. Among four watermarks, three are the biometric images namely Logo or unique image of the user, fingerprint biometric of the owner, and the metadata of the original media to be transmitted. In addition, to achieve the tamper localization property, the Pseudo Zernike moments of the original cover image are obtained as a feature vector and also embedded as a watermark. To attain a better level of security, each watermark is converted into Zernike moments, Arnold scrambled image, and SHA outputs respectively. Then, to sustain the trade-off among the watermarking parameters, the optimal embedding location is determined. Moreover, the watermarked image is also signed by the owner's other biometric namely digital signature, and converted into Public key matrix P-km and embedded onto the higher frequency subband namely, HL of the 1-level DWT. The proposed system also accomplishes a multi-level authentication, among that the first level is attained by the decryption of the extracted multiple watermark images with the help of the appropriate decryption mechanism which is followed by the comparison of the authentication key which is extracted using the key which is regenerated at the receiver's end. The simulation outcomes evident that the proposed system shows superior performance towards content authentication, to most remarkable intentional and unintentional attacks among the existing watermarking systems.
C1 [Agilandeeswari, L.; Prabukumar, M.] Vellore Inst Technol, Sch Informat Technol & Engn SITE, Vellore 632014, India.
   [Alenizi, Farhan A.] Prince Sattam Bin Abdulaziz Univ, Dept Elect Engn, Al Kharj 16278, Saudi Arabia.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Prince Sattam Bin
   Abdulaziz University
RP Prabukumar, M (corresponding author), Vellore Inst Technol, Sch Informat Technol & Engn SITE, Vellore 632014, India.
EM agila.l@vit.ac.in; mprabukumar@vit.ac.in; fa.alenizi@psau.edu.sa
RI L, Agilandeeswari/P-8997-2016; Alenizi, Farhan/GRR-2306-2022
OI L, Agilandeeswari/0000-0001-6147-9535; 
FU PSAU - College of Engineering, Saudi Arabia [2018/01/9362]
FX This work is funded by PSAU - College of Engineering, Saudi Arabia
   through the New Faculty Grant Program under grant number (2018/01/9362).
CR Abadi RY, 2022, OPTIK, V261, DOI 10.1016/j.ijleo.2022.169146
   Abdulla A. A., 2015, Ph.D. dissertation
   Agbaje M, 2015, P INF SCI IT ED C IN, P1
   Agilandeeswari L, 2018, MULTIMED TOOLS APPL, V77, P25431, DOI 10.1007/s11042-018-5800-4
   Agilandeeswari L., 2016, International Journal of Information Privacy, Security and Integrity, V2, P257
   Agilandeeswari L, 2016, J ENG SCI TECHNOL, V11, P327
   Agilandeeswari L, 2016, MULTIMED TOOLS APPL, V75, P8745, DOI 10.1007/s11042-015-2789-9
   Agilandeeswari L, 2016, MULTIMED TOOLS APPL, V75, P7211, DOI 10.1007/s11042-015-2642-1
   Agilandeeswari L, 2013, SECURITY COMPUTING C, V377, DOI [10.1007/978-3-642-40576-1_36, DOI 10.1007/978-3-642-40576-1_36]
   Agilandeeswari L, 2013, INT J SECUR APPL, V7, P145
   Ahvanooey MT, 2020, COMPUT SECUR, V90, DOI 10.1016/j.cose.2019.101702
   Ali M., 2014, P 3 INT C SOFT COMP, P413, DOI DOI 10.1007/978-81-322-1771-8_36
   Alsmirat MA, 2017, J REAL-TIME IMAGE PR, V13, P527, DOI 10.1007/s11554-016-0631-x
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2013, 2013 10 INT C EL ENG
   [Anonymous], 2017, INT SEC THREAT REP
   Asikuzzaman Md, 2014, IEEE Transactions on Information Forensics and Security, V9, P1502, DOI 10.1109/TIFS.2014.2338274
   BELKASIM SO, 1991, PATTERN RECOGN, V24, P1117, DOI 10.1016/0031-3203(91)90140-Z
   Benyoussef Meryem, 2014, Journal of Theoretical and Applied Information Technology, V60, P372
   Bosher H., 2019, International Review of Law, Computers Technology, V33, P164, DOI [DOI 10.1080/13600869.2018.1475897, 10.1080/13600869.2018.1475897]
   Cardoso P, 2020, HEALTH EDUC BEHAV, V47, P29, DOI 10.1177/1090198119885433
   Chen CH, 2014, OPTIK, V125, P1134, DOI 10.1016/j.ijleo.2013.07.126
   Chen SY, 2022, OPTIK, V249, DOI 10.1016/j.ijleo.2021.168231
   Domingo-Ferrer J, 2011, P 4 INT WORKSH PRIV, P1
   Gadicha A.B., 2021, MULTIDISCIPLINARY AP, P99, DOI DOI 10.4018/978-1-7998-7160-6.CH005
   Haghighi BB, 2019, INFORM SCIENCES, V486, P204, DOI 10.1016/j.ins.2019.02.055
   Hossain MS, 2018, FUTURE GENER COMP SY, V86, P855, DOI 10.1016/j.future.2017.01.030
   Hsu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P549, DOI 10.1109/ICME.2006.262447
   Huang HC, 2009, SOFT COMPUT, V13, P333, DOI 10.1007/s00500-008-0333-9
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   Koppanati K., 2019, INT C DEEP LEARN ART, P246
   Koppanati RK, 2021, IEEE CONSUM ELECTR M, V10, P41, DOI 10.1109/MCE.2020.3003127
   Koppanati RK, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P1820, DOI 10.1109/ICCONS.2018.8662840
   Kwitt R, 2009, 16 INT C DIG SIGN PR, P1
   Lefèvre P, 2022, SIGNAL PROCESS, V190, DOI 10.1016/j.sigpro.2021.108342
   Li FY, 2016, IEEE T INF FOREN SEC, V11, P344, DOI 10.1109/TIFS.2015.2496910
   Liu, 2003, ELECTIVE ENCRYPTION
   Loganathan A, 2016, EXPERT SYST APPL, V63, P412, DOI 10.1016/j.eswa.2016.05.019
   Loo P, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P29, DOI 10.1109/ICIP.2000.899275
   Luo WM, 2009, EIGHTH IEEE INTERNATIONAL CONFERENCE ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, PROCEEDINGS, P648, DOI 10.1109/DASC.2009.100
   Lutovac B, 2017, MULTIMED TOOLS APPL, V76, P23333, DOI 10.1007/s11042-016-4127-2
   Meet People on Badoo, 2017, MEET PEOPLE ON BADOO
   Moad MS, 2022, MICROPROCESS MICROSY, V90, DOI 10.1016/j.micpro.2022.104490
   Muhammad Khan, 2018, Future Generation Computer Systems, V86, P951, DOI 10.1016/j.future.2016.11.029
   Patsakis C, 2014, COMPUT NETW, V75, P531, DOI 10.1016/j.comnet.2014.08.023
   Purohit Kaustubh, 2020, Soft Computing: Theories and Applications. Proceedings of SoCTA 2019. Advances in Intelligent Systems and Computing (AISC 1154), P135, DOI 10.1007/978-981-15-4032-5_14
   Rathore S, 2017, INFORM SCIENCES, V421, P43, DOI 10.1016/j.ins.2017.08.063
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Sharma Shikhar, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 703), P51, DOI 10.1007/978-981-10-7895-8_5
   Shojanazeri H, 2017, MULTIMED TOOLS APPL, V76, P577, DOI 10.1007/s11042-015-3018-2
   Singh Amit Kumar, 2018, Future Generation Computer Systems, V86, P926, DOI 10.1016/j.future.2016.11.023
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Son YH, 2003, P 2002 INT C CONTR A, P1140
   Stokes K, 2013, ANN CONF PRIV SECUR, P103, DOI 10.1109/PST.2013.6596043
   Su Q, 2022, INFORM SCIENCES
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Velazquez-Garcia L, 2022, SIGNAL PROCESS-IMAGE, V102, DOI 10.1016/j.image.2021.116593
   Venkatachalam N, 2017, MULTIMED TOOLS APPL, V76, P6079, DOI 10.1007/s11042-016-3555-3
   Venkataramana A, 2007, 2007 INT C COMP THEO
   Wang XY, 2010, MULTIDIM SYST SIGN P, V21, P179, DOI 10.1007/s11045-009-0096-1
   Xin-She Yang, 2010, International Journal of Mathematical Modelling and Numerical Optimisation, V1, P330, DOI 10.1504/IJMMNO.2010.035430
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Zebbiche K, 2018, MULTIMED TOOLS APPL, V77, P21281, DOI 10.1007/s11042-017-5451-x
   Zhang ZY, 2018, FUTURE GENER COMP SY, V86, P914, DOI 10.1016/j.future.2016.10.007
   Zigomitros A., 2012, 2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom), P1381, DOI 10.1109/TrustCom.2012.264
NR 65
TC 7
Z9 7
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43367
EP 43419
DI 10.1007/s11042-023-15177-4
EA APR 2023
PG 53
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000984450300003
PM 37362657
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Halidou, A
   Mohamadou, Y
   Ari, AAA
   Zacko, EJG
AF Halidou, Aminou
   Mohamadou, Youssoufa
   Ari, Ado Adamou Abba
   Zacko, Edinio Jocelyn Gbadoubissa
TI Review of wavelet denoising algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Denoising; Discrete wavelet transform (DWT); Block matching and 3D
   filtering (BM3D); Peak signal to noise ratio (PSNR); Thresholding
ID SHRINKAGE FUNCTIONS; IMAGES; SMOOTHNESS; NEIGHBOR; NOISE
AB Although there has been a lot of progress in the general area of signal denoising, noise removal remains a very challenging problem in real-world communication systems. Denoising algorithms are typically used during the image preprocessing phase and are chosen based on the type of image, as a specific algorithm may work for a given noise but not for another one. Moreover, an algorithm can sometimes consider crucial information as being noise and eliminate it, hence the importance of careful selection and tuning of denoising algorithms. Denoising algorithms built on discrete wavelet transform decomposes signals into different frequency resolution levels. Thresholding is then applied to higher frequency components which generally correspond to noise to eliminate this one. In this paper, we review wavelet-based denoising methods and compare their performance based on metrics such as peak signal-to-noise ratio (PSNR) and Structural Similarity (SSIM). This work aims to find the best wavelet denoising algorithm using Peak these metrics. The common Matlab images such as cameraman, barbara, coins, and eight are used for our test. From these tests, the BM3DM_DWT method was found to be the simplest and most efficient for denoising.
C1 [Halidou, Aminou] Univ Yaounde I, Fac Sci, Dept Comp Sci, POB 337, Yaounde, Cameroon.
   [Halidou, Aminou] Univ Johannesburg, Dept Mech & Ind Engn Technol DMIET, POB 524, Johannesburg, South Africa.
   [Mohamadou, Youssoufa] Univ Ngaoundere, Univ Inst Technol, LASE, POB 454, Ngaoundere, Cameroon.
   [Mohamadou, Youssoufa] Univ Montagnes, BEEMo Lab, ISST, POB 208, Bangangte, Cameroon.
   [Ari, Ado Adamou Abba; Zacko, Edinio Jocelyn Gbadoubissa] Univ Maroua, Dept Comp Sci, POB 814, Maroua, Cameroon.
   [Ari, Ado Adamou Abba] Univ Versailles St Quentin En Yvelines, Univ Paris Saclay, DAVID Lab, 45 Ave Etats Unis, F-78000 Versailles, France.
   [Zacko, Edinio Jocelyn Gbadoubissa] African Inst Math Sci AIMS Cameroon, POB 608, Limbe, Cameroon.
C3 University of Yaounde I; University of Johannesburg; Universite Paris
   Saclay; Universite Paris Cite
RP Halidou, A (corresponding author), Univ Yaounde I, Fac Sci, Dept Comp Sci, POB 337, Yaounde, Cameroon.; Halidou, A (corresponding author), Univ Johannesburg, Dept Mech & Ind Engn Technol DMIET, POB 524, Johannesburg, South Africa.
EM halidou.aminou@facsciences-uy1.cm; usufcom@hotmail.com;
   adoadamou.abbaari@gmail.com; jocelyn.zacko@aims-cameroon.org
RI Ari, Ado/AFK-5322-2022; Mohamadou, Youssoufa/JKH-6947-2023
OI Ari, Ado/0000-0001-5660-0660; Mohamadou, Youssoufa/0000-0002-6665-4395;
   Zacko, Edinio/0000-0003-4051-819X; Halidou, Aminou/0000-0002-6863-6887
CR Abramovich F, 1996, COMPUT STAT DATA AN, V22, P351, DOI 10.1016/0167-9473(96)00003-5
   Antoniadis A, 2007, STAT SURV, V1, P16, DOI 10.1214/07-SS014
   Ari AAA, 2019, COMPUT NETW, V165, DOI 10.1016/j.comnet.2019.106957
   Averbuch A, 2020, ARXIV
   Berkner K, 2002, APPL COMPUT HARMON A, V12, P1, DOI 10.1006/acha.2001.0366
   Bhatnagar N., 2020, Introduction to wavelet transforms, DOI DOI 10.1201/9781003006626
   Bhonsle D., 2012, INT J SCI RES PUBLIC, V2, P1
   Bhuiyan MIH, 2007, IEEE T CIRC SYST VID, V17, P500, DOI 10.1109/TCSVT.2006.888020
   Bnou K, 2020, EURASIP J ADV SIG PR, V2020, DOI 10.1186/s13634-020-00693-4
   Brigham E. O., 1988, FAST FOURIER TRANSFO
   BRUCE A, 1995, P SOC PHOTO-OPT INS, V2569, P270, DOI 10.1117/12.217582
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Bui TD, 1998, IEEE T SIGNAL PROCES, V46, P3414, DOI 10.1109/78.735315
   Cai T., 2001, SANKHYA SER B, V63, P127
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1522, DOI 10.1109/83.862630
   Chen G, INTELLIGENT CONTROL
   Chen GY, 2007, PATTERN RECOGN, V40, P578, DOI 10.1016/j.patcog.2006.04.039
   Chen GY, 2013, PROCEEDINGS OF THE 2013 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP), P570
   Chen GY, 2005, INTEGR COMPUT-AID E, V12, P99
   Chen GY, 2005, PATTERN RECOGN, V38, P115, DOI 10.1016/j.patcog.2004.05.009
   Chen GY, 2003, IEEE SIGNAL PROC LET, V10, P211, DOI 10.1109/LSP.2003.811586
   Chen Y, 2017, OPTIK, V132, P243, DOI 10.1016/j.ijleo.2016.12.052
   Cho D, 2005, SIGNAL PROCESS-IMAGE, V20, P77, DOI 10.1016/j.image.2004.10.003
   Cho DW, 2009, INT J WAVELETS MULTI, V7, P299, DOI 10.1142/S0219691309002945
   Chong B, 2013, OPT COMMUN, V291, P461, DOI 10.1016/j.optcom.2012.10.053
   Cui H, 2015, SIGNAL IMAGE VIDEO P, V9, P491, DOI 10.1007/s11760-014-0685-9
   Dixit Arun, 2014, International Journal of Image, Graphics and Signal Processing, V6, P39, DOI 10.5815/ijigsp.2014.12.06
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.1080/01621459.1995.10476626
   Dtissibe FY, 2020, NAT HAZARDS, V104, P1211, DOI 10.1007/s11069-020-04211-5
   Eslami R, 2006, IEEE T IMAGE PROCESS, V15, P3362, DOI 10.1109/TIP.2006.881992
   Fan LW, 2019, VIS COMPUT IND BIOME, V2, DOI 10.1186/s42492-019-0016-7
   Feng XC, 2017, 2017 INTERNATIONAL CONFERENCE ON MACHINE VISION AND INFORMATION TECHNOLOGY (CMVIT), P28, DOI 10.1109/CMVIT.2017.15
   Gao HY, 1998, J COMPUT GRAPH STAT, V7, P469
   Gopi VP, 2013, 2013 SECOND INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING, NETWORKING AND SECURITY (ADCONS 2013), P68, DOI 10.1109/ADCONS.2013.38
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Isogawa K, 2018, IEEE SIGNAL PROC LET, V25, P224, DOI 10.1109/LSP.2017.2782270
   Kudo T., 2018, PROC INT WORKSH ADV, V118, P179
   Luo P, 2018, 2ND INTERNATIONAL CONFERENCE ON DATA SCIENCE AND BUSINESS ANALYTICS (ICDSBA 2018), P287, DOI 10.1109/ICDSBA.2018.00-38
   Maria HH, 2021, OPTIK, V241, DOI 10.1016/j.ijleo.2021.166883
   Mihçak MK, 1999, IEEE SIGNAL PROC LET, V6, P300, DOI 10.1109/97.803428
   Nason G., 1995, Wavelets and statistics, P261, DOI DOI 10.1007/978-1-4612-2544-7_16
   Ogden T., 2012, ESSENTIAL WAVELETS S
   Ouahabi A, 2013, 2013 8TH INTERNATIONAL WORKSHOP ON SYSTEMS, SIGNAL PROCESSING AND THEIR APPLICATIONS (WOSSPA), P19, DOI 10.1109/WoSSPA.2013.6602330
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   PORTNOFF MR, 1980, IEEE T ACOUST SPEECH, V28, P55, DOI 10.1109/TASSP.1980.1163359
   [任超 Ren Chao], 2020, [测绘通报, Bulletin of Surveying and Mapping], P89
   Roy V, 2013, P ALL IND SEM BIOM E, P9
   Ruggeri F, 1999, STAT SINICA, V9, P183
   Sahu S, 2020, LECT NOTES ELECTR EN, V587, P775, DOI 10.1007/978-981-32-9775-3_70
   Saritha C., 2008, Bulgarian Journal of Physics, V35, P68
   Seena V, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON DEVICES, CIRCUITS AND SYSTEMS (ICDCS)
   Sendur L, 2002, IEEE T SIGNAL PROCES, V50, P2744, DOI 10.1109/TSP.2002.804091
   Sharan TS, 2021, J APPL SPECTROSC+, V88, P117, DOI 10.1007/s10812-021-01149-9
   Su MK, 2018, GPS SOLUT, V22, DOI 10.1007/s10291-018-0708-z
   Su QN, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2019), P999, DOI [10.1109/siprocess.2019.8868429, 10.1109/SIPROCESS.2019.8868429]
   Sudha S., 2009, International journal of computer theory and engineering, V1, P7, DOI 10.7763/IJCTE.2009.V1.2
   Tofighi M, 2015, IMAGE RESTORATION RE
   Tofighi M, 2015, SIGNAL IMAGE VIDEO P, V9, P41, DOI 10.1007/s11760-015-0827-8
   Vetterli Martin, 1995, Wavelets and Subband Coding
   Vimala C, 2018, J PHYS CONF SER, V1000, DOI 10.1088/1742-6596/1000/1/012120
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WEAVER JB, 1991, MAGNET RESON MED, V21, P288, DOI 10.1002/mrm.1910210213
   Xiaoyue Sang, 2020, 2020 IEEE 5th Optoelectronics Global Conference (OGC), P190, DOI 10.1109/OGC50007.2020.9260459
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
NR 66
TC 18
Z9 18
U1 33
U2 94
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 41539
EP 41569
DI 10.1007/s11042-023-15127-0
EA APR 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000962689300002
DA 2024-07-18
ER

PT J
AU Lu, KC
   Thamrin, SA
   Chen, ALP
AF Lu, Kuan-Chieh
   Thamrin, Syauki Aulia
   Chen, Arbee L. P.
TI Depression detection via conversation turn classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depression detection; Psychiatric consultations; Turn features; Deep
   learning
AB The fast pace of modern life caused people to experience more pressure from their surrounding environments. As a result, depression has emerged as one of the most common diseases. To detect depression, psychiatrists need to interview patients to understand their mental health condition. However, it may not fully reflect the condition of the patient since some people cannot adequately express their feelings. As an alternative, researchers work on automated depression detection. Our work aims to improve the detection capability by extracting knowledge from psychiatric consultation. Previous studies classified the questions and answers in the interview into categories unrelated directly to depression. In this paper, we implement a novel categorization based on the Patient Health Questionnaire-8 (PHQ-8). The PHQ-8 is commonly used as a screening tool to identify the severity of depression, making it more reliable for detecting depression. Transcribed data is processed using contextual word embedding, BERT, to learn semantic information. In the final step, a transformer encoder is used to get a higher-level representation of turns. Using categorization based on PHQ-8 and BERT as word embedding, we propose a novel deep learning framework with two-level encoding for detecting depression. In the training step, we use Distress Analysis Interview Corpus (DAIC) dataset, a transcript of the interview data. The model is evaluated with different adjustments to achieve the best performance. Various experiments are designed to show the effectiveness of our method for detecting depression from the psychiatric consultation dataset. As a result, our model performs better than others using the same dataset, achieving 0.76 F1-score.
C1 [Lu, Kuan-Chieh] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu, Taiwan.
   [Thamrin, Syauki Aulia; Chen, Arbee L. P.] Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
C3 National Tsing Hua University; Asia University Taiwan
RP Chen, ALP (corresponding author), Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
EM jackhp1994@gmail.com; syauki.aulia@outlook.com; arbee@asia.edu.tw
FU Ministry of Science and Technology, ROC [109-2221-E-468-014-MY3]
FX AcknowledgementsThis work was partially supported by the Ministry of
   Science and Technology, ROC (Grant Number: 109-2221-E-468-014-MY3).
CR Abreu LN, 2018, EUR PSYCHIAT, V47, P19, DOI 10.1016/j.eurpsy.2017.09.005
   Alhanai T, 2018, INTERSPEECH, P1716, DOI 10.21437/Interspeech.2018-2522
   Bai S., 2018, EMPIRICAL EVALUATION
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Borrell-Carrió F, 2004, ANN FAM MED, V2, P576, DOI 10.1370/afm.245
   Coppersmith G., 2014, P WORKSH COMP LING C, P51, DOI [10.3115/v1/w14-3207, DOI 10.3115/V1/W14-3207]
   Devlin J., 2018, BERT PRE TRAINING DE
   Ferrari AJ, 2013, PLOS MED, V10, DOI 10.1371/journal.pmed.1001547
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Gong Y., 2017, Proceedings of the 7th Annual Workshop on Audio/Visual Emotion Challenge, P69, DOI DOI 10.1145/3133944.3133945
   Gratch J, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3123
   Haque A., 2018, arXiv
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   He L, 2022, INFORM FUSION, V80, P56, DOI 10.1016/j.inffus.2021.10.012
   Henry S, 2021, Mental Health Informatics: Enabling a Learning Mental Healthcare System, P317
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Kendell R, 2003, AM J PSYCHIAT, V160, P4, DOI 10.1176/appi.ajp.160.1.4
   Kroenke K, 2010, GEN HOSP PSYCHIAT, V32, P345, DOI 10.1016/j.genhosppsych.2010.03.006
   Lam G, 2019, INT CONF ACOUST SPEE, P3946, DOI 10.1109/ICASSP.2019.8683027
   Mallol-Ragolta A, 2019, INTERSPEECH, P221, DOI 10.21437/Interspeech.2019-2036
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Rinaldi A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P7
   Rude SS, 2004, COGNITION EMOTION, V18, P1121, DOI 10.1080/02699930441000030
   Shrivastava K, 2019, MULTIMED TOOLS APPL, V78, P29607, DOI 10.1007/s11042-019-07813-9
   Tadesse MM, 2019, IEEE ACCESS, V7, P44883, DOI 10.1109/ACCESS.2019.2909180
   Tausczik YR, 2010, J LANG SOC PSYCHOL, V29, P24, DOI 10.1177/0261927X09351676
   Xezonaki D, 2020, INTERSPEECH, P4556, DOI 10.21437/Interspeech.2020-2819
   Zhang YF, 2020, SSPS 2020: 2020 2ND SYMPOSIUM ON SIGNAL PROCESSING SYSTEMS, P101, DOI 10.1145/3421515.3421516
NR 29
TC 0
Z9 0
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39393
EP 39413
DI 10.1007/s11042-023-15103-8
EA APR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000961747500007
DA 2024-07-18
ER

PT J
AU Shekhar, K
   Chittaragi, NB
   Koolagudi, SG
AF Shekhar, Kushan
   Chittaragi, Nagaratna B.
   Koolagudi, Shashidhar G.
TI Automatic diagnosis of COVID-19 related respiratory diseases from speech
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Cough; Breath; Excitation source features; Spectral features;
   Speech-based COVID analysis; Support vector machines
AB In this work, an attempt is made to propose an intelligent and automatic system to recognize COVID-19 related illnesses from mere speech samples by using automatic speech processing techniques. We used a standard crowd-sourced dataset which was collected by the University of Cambridge through a web based application and an android/iPhone app. We worked on cough and breath datasets individually, and also with a combination of both the datasets. We trained the datasets on two sets of features, one consisting of only standard audio features such as spectral and prosodic features and one combining excitation source features with standard audio features extracted, and trained our model on shallow classifiers such as ensemble classifiers and SVM classification methods. Our model has shown better performance on both breath and cough datasets, but the best results in each of the cases was obtained through different combinations of features and classifiers. We got our best result when we used only standard audio features, and combined both cough and breath data. In this case, we achieved an accuracy of 84% and an Area Under Curve (AUC) score of 84%. Intelligent systems have already started to make a mark in medical diagnosis, and this type of study can help better the health system by providing much needed assistance to the health workers.
C1 [Shekhar, Kushan; Koolagudi, Shashidhar G.] Natl Inst Technol Karnataka, Dept CSE, Mangalore, Karnataka, India.
   [Chittaragi, Nagaratna B.] Siddaganga Inst Technol, Dept ISE, B H Rd, Tumakuru, Karnataka, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka; Siddaganga Institute of Technology
RP Chittaragi, NB (corresponding author), Siddaganga Inst Technol, Dept ISE, B H Rd, Tumakuru, Karnataka, India.
EM kushanshekhar007@gmail.com; chittaragi@sit.ac.in; koolagudi@nitk.edu.in
OI B Chittaragi, Nagaratna/0000-0001-6550-198X
CR Bagad P., 2020, arXiv
   Bhuyan HK, 2022, HEALTH TECHNOL-GER, V12, P987, DOI 10.1007/s12553-022-00687-2
   Bhuyan HK, 2024, IEEE T COMPUT SOC SY, V11, P3131, DOI 10.1109/TCSS.2022.3164993
   Bhuyan HK, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12776
   Brown C, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3474, DOI 10.1145/3394486.3412865
   Dash TK, 2021, PATTERN RECOGN, V117, DOI 10.1016/j.patcog.2021.107999
   Hassan A, 2020, PRO BIENN BALT EL C, DOI 10.1109/bec49624.2020.9276993
   Hsu HH., 2017, BIG DATA ANAL SENSOR
   Koolagudi SG, 2012, INT J SPEECH TECHNOL, V15, P495, DOI 10.1007/s10772-012-9150-8
   Kulkarni N., 2018, EEG-based diagnosis of Alzheimer disease: a review and novel approaches for feature extraction and classification techniques
   McFee B., 2015, P 14 PYTH SCI C, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/Majora-7b98e3ed-003]
   McKinney W., 2010, P 9 PYTHON SCI C, P51, DOI DOI 10.25080/MAJORA-92BF1922-00A
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Peter D., 2020, COGNITIVE APPROACH C
   Pramono RXA, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162128
   Schuller B W, 2021, ARXIV
   Vandenberg O, 2021, NAT REV MICROBIOL, V19, P171, DOI 10.1038/s41579-020-00461-z
   Yegnanarayana B, 2009, IEEE T AUDIO SPEECH, V17, P614, DOI 10.1109/TASL.2008.2012194
NR 18
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36599
EP 36614
DI 10.1007/s11042-023-14923-y
EA MAR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000960423600016
PM 37362694
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Durai, BSK
   Raja, JB
AF Durai, B. Sakthi Karthi
   Raja, J. Benadict
TI A bio-inspired fall webworm optimization algorithm for feature selection
   and support vector machine optimization for retinal abnormalities
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bio-inspired algorithm; Parameter optimization; Support vector machine;
   Feature selection; Segmentation
ID BLOOD-VESSEL SEGMENTATION; MATCHED-FILTER; IMAGES; LEVEL
AB The early detection of retinal abnormalities such as diabetic retinopathy (DR) can be performed using the computerized analysis of retinal fundus images. The most significant complications associated with the DR detection are noise artifacts occurred as a result of unsuitable illumination, the overlapping of blood vascular structure and lesions as they have same intensities, and missing of data happened due to the analysis of large amount of data. Hence the improved technique capable of overcoming all these limitations must be presented in early detection of DR and other retinal abnormalities. Some of previous blood vessel segmentation methods provide better accuracy with normal retinal images and requires less computation time. In this work, an automated process using an optimized SVM classifier and a new feature extraction is presented. The proposed feature extraction process is sum of minimum (SOM) local difference pattern (LDP) (SOMLDP) which is developed from the computation of difference between pixels. This feature extraction produces precise feature information with reduced size. In addition, feature selection process is employed to select more important features, using a new optimization algorithm developed from the behavior of fall webworm (FWW) species. FWW optimization algorithm is also applied for the optimal tuning of support vector machine (SVM) classifier. The main objective of the paper is to present an automated detection of DR with more accuracy, less memory and reduced computation time. The performance of proposed technique is validated with publicly available standard dataset Messidor-2 by evaluating the metrics such as sensitivity, specificity and accuracy. The simulation results depict that sensitivity, specificity and accuracy of 0.8235, 0.9892 and 0.9879 is attained respectively. The FWW optimization algorithm is also validated by analyzing the computation time performance and comparing the performance of FWW algorithm with other optimization algorithms.
C1 [Durai, B. Sakthi Karthi] Velammal Coll Engn & Technol, Dept Comp Sci & Engn, Madurai, India.
   [Raja, J. Benadict] PSNA Coll Engn & Technol, Dept Comp Sci & Engn, Dindigul, India.
C3 PSNA College of Engineering & Technology
RP Durai, BSK (corresponding author), Velammal Coll Engn & Technol, Dept Comp Sci & Engn, Madurai, India.
EM b.sakthikarthidurai@gmail.com; jesuraj.benadict@gmail.com
RI J, Benadict Raja/HTT-3885-2023
CR American Academy of Ophthalmology Retina/Vitreous Panel, 2018, DIABETIC RETINOPATHY
   Aslani S, 2016, BIOMED SIGNAL PROCES, V30, P1, DOI 10.1016/j.bspc.2016.05.006
   Azzopardi G, 2015, MED IMAGE ANAL, V19, P46, DOI 10.1016/j.media.2014.08.002
   Budai A, 2013, INT J BIOMED IMAGING, V2013, DOI 10.1155/2013/154860
   Chalakkal RJ, 2017, INT CONF ACOUST SPEE, P886, DOI 10.1109/ICASSP.2017.7952283
   Chen Y, 2017, ARXIV
   Cheng EK, 2014, MACH VISION APPL, V25, P1779, DOI 10.1007/s00138-014-0638-x
   Das S, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102600
   Fitzgerald TD, 2008, J EXP BIOL, V211, P671, DOI 10.1242/jeb.013664
   Gayathri S, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102115
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Huang SZ, 2020, J HYDROL, V584, DOI 10.1016/j.jhydrol.2020.124687
   Imani E, 2015, COMPUT MED IMAG GRAP, V43, P78, DOI 10.1016/j.compmedimag.2015.03.004
   Imani E, 2015, COMPUT METH PROG BIO, V118, P263, DOI 10.1016/j.cmpb.2015.01.004
   Jebakumari VS, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101708
   Kaur D., 2020, COMPUTATIONAL NETWOR, P139
   Kaur J, 2017, BIOCYBERN BIOMED ENG, V37, P184, DOI 10.1016/j.bbe.2016.09.002
   Khalid S, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/7148245
   Kouziokas GN, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106410
   Lahmiri S, 2020, BIOMED SIGNAL PROCES, V60, DOI 10.1016/j.bspc.2020.101978
   Lahmiri S, 2019, BIOMED SIGNAL PROCES, V49, P427, DOI 10.1016/j.bspc.2018.08.029
   Li Q, 2012, EXPERT SYST APPL, V39, P7600, DOI 10.1016/j.eswa.2011.12.046
   Long SC, 2019, BIOMED RES INT, V2019, DOI 10.1155/2019/3926930
   Marín D, 2011, IEEE T MED IMAGING, V30, P146, DOI 10.1109/TMI.2010.2064333
   Rahebi J, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0085-2
   Roychowdhury S, 2015, IEEE T BIO-MED ENG, V62, P1738, DOI 10.1109/TBME.2015.2403295
   Roychowdhury S, 2015, IEEE J BIOMED HEALTH, V19, P1118, DOI 10.1109/JBHI.2014.2335617
   Schowalter TD, 2017, J INTEGR PEST MANAG, V8, DOI 10.1093/jipm/pmw019
   Usha SGA, 2018, MULTIMED TOOLS APPL, V77, P15353, DOI 10.1007/s11042-017-5120-0
   Valarmathi R, 2021, J AMB INTEL HUM COMP, V12, P3633, DOI 10.1007/s12652-019-01617-3
   Wang J, 2020, BIOMED SIGNAL PROCES, V60, DOI 10.1016/j.bspc.2020.101943
   Wang SL, 2015, NEUROCOMPUTING, V149, P708, DOI 10.1016/j.neucom.2014.07.059
   Wang YF, 2013, PATTERN RECOGN, V46, P2117, DOI 10.1016/j.patcog.2012.12.014
   Wang YR, 2020, IEEE ACCESS, V8, P17071, DOI 10.1109/ACCESS.2020.2968390
   World Health Organization, 2020, GLOB PREV DIAB
   Yao C, 2009, J CENT SOUTH UNIV T, V16, P640, DOI 10.1007/s11771-009-0106-3
   Zardadi M, 2016, UNSUPERVISED SEGMENT, P125
   Zhang B, 2010, COMPUT BIOL MED, V40, P438, DOI 10.1016/j.compbiomed.2010.02.008
   Zhang L, 2015, COMPUT MED IMAG GRAP, V45, P47, DOI 10.1016/j.compmedimag.2015.07.006
   Zhao YT, 2015, IEEE T MED IMAGING, V34, P1797, DOI 10.1109/TMI.2015.2409024
   Zhao YQ, 2014, PATTERN RECOGN, V47, P2437, DOI 10.1016/j.patcog.2014.01.006
NR 41
TC 1
Z9 1
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32443
EP 32462
DI 10.1007/s11042-023-14745-y
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000947594500010
DA 2024-07-18
ER

PT J
AU Boudouh, SS
   Bouakkaz, M
AF Boudouh, Saida Sarra
   Bouakkaz, Mustapha
TI Breast cancer: toward an accurate breast tumor detection model in
   mammography using transfer learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Mammography; Transfer learning; MIAS; DDSM; Deep CNN
AB Female breast cancer has now surpassed lung cancer as the most common form of cancer globally. Although several methods exist for breast cancer detection and diagnosis, mammography is the most effective and widely used technique. In this study, our purpose is to propose an accurate breast tumor detection model as the first step into cancer detection. To guarantee diversity and a larger amount of data, we collected samples from three different databases: the Mammographic Image Analysis Society MiniMammographic (MiniMIAS), the Digital Database for Screening Mammography (DDSM), and the Chinese Mammography Database (CMMD). Several filters were used in the pre-processing phase to extract the Region Of Interest (ROI), remove noise, and enhance images. Next, transfer learning, data augmentation, and Global Pooling (GAP/GMP) techniques were used to avoid imagery overfitting and to increase accuracy. To do so, seven pre-trained Convolutional Neural Networks (CNNs) were modified in several trials with different hyper-parameters to determine which ones are the most suitable for our situation and the criteria that influenced our results. The selected pre-trained CNNs were Xception, InceptionV3, ResNet101V2, ResNet50V2, ALexNet, VGG16, and VGG19. The obtained results were satisfying, especially for ResNet50V2 followed by InceptionV3 reaching the highest accuracy of 99.9%, and 99.54% respectively. Meanwhile, the remaining models achieved great results as well, proving that our approach starting from the chosen filters, databases, and pre-trained models with the fine-tuning phase and the used global pooling technique is effective for breast tumor detection. Furthermore, we also managed to determine the most suitable hyper-parameters for each model using our collected dataset.
C1 [Boudouh, Saida Sarra; Bouakkaz, Mustapha] Univ Laghouat Amar Telidji, LIM Lab, Laghouat, Algeria.
RP Boudouh, SS (corresponding author), Univ Laghouat Amar Telidji, LIM Lab, Laghouat, Algeria.
EM s.boudouh@lagh-univ.dz; m.bouakkaz@lagh-univ.dz
RI Boudouh, Saida Sarra/HOF-0638-2023
OI Boudouh, Saida Sarra/0000-0002-2608-747X
CR Agnes SA, 2020, J MED SYST, V44, DOI 10.1007/s10916-019-1494-z
   Albalawi U, 2020, CONCURR COMP-PRACT E
   Alom MZ, 2018, arXiv
   Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   [Anonymous], 2014, ArXiv
   Boudouh SS, 2022, 2022 7 INT C IM SIGN, P1, DOI [10.1109/ISPA54004.2022.9786351, DOI 10.1109/ISPA54004.2022.9786351]
   Charan Saira, 2018, 2018 International Conference on Computing, Mathematics and Engineering Technologies (iCoMET). Proceedings, DOI 10.1109/ICOMET.2018.8346384
   Chollet F., 2016, arXiv
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Dong L., 2020, J Inst Ind Appl Eng, V8, P117
   Gumaei A., 2012, 2012 Symposium on Broadband Networks and Fast Internet (RELABIRA), P97, DOI 10.1109/RELABIRA.2012.6235102
   Harbeck N, 2019, NAT REV DIS PRIMERS, V5, DOI [10.1038/s41572-019-0111-2, 10.1038/s41572-019-0122-z]
   He Kaiming, 2016, arXiv
   Heath M, 2001, IWDM 2000: 5TH INTERNATIONAL WORKSHOP ON DIGITAL MAMMOGRAPHY, P212
   Jafari SH, 2018, J CELL PHYSIOL, V233, P5200, DOI 10.1002/jcp.26379
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Khamparia A, 2021, MULTIDIM SYST SIGN P, V32, P747, DOI 10.1007/s11045-020-00756-7
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Omonigho EL, 2020, 2020 INT C MATH COMP, P1
   Rasheed A, 2021, ARXIV
   Saber A, 2021, IEEE ACCESS, V9, P71194, DOI 10.1109/ACCESS.2021.3079204
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Society medical and editorial content team, 2019, TECHN REP
   Suckling J., 2015, MAMMOGRAPHIC IMAGE A, DOI 10.250394
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tarique M., 2015, J BIOMED ENG MED IMA, V2, P17, DOI [10.14738/jbemi.24.1308, DOI 10.14738/JBEMI.24.1308]
   TensorFlow, 2022, ABOUT US
   Wellings E, 2016, CUREUS J MED SCIENCE, V8, DOI 10.7759/cureus.945
   Xiaomeng Wang, 2020, 2020 IEEE 6th International Conference on Computer and Communications (ICCC), P1461, DOI 10.1109/ICCC51575.2020.9345195
   Zhang C, 2020, PLOS ONE, V15
   Zhou JY, 2020, SHOCK VIB, V2020, DOI 10.1155/2020/8863388
NR 33
TC 7
Z9 7
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34913
EP 34936
DI 10.1007/s11042-023-14410-4
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000946494700010
OA hybrid
DA 2024-07-18
ER

PT J
AU Patel, B
   Sharaff, A
AF Patel, Bharati
   Sharaff, Aakanksha
TI Automatic Rice Plant's disease diagnosis using gated recurrent network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rice disease; Convolutional neural network; Gated recurrent unit;
   Transfer learning; Incremental learning model
ID DATA AUGMENTATION; NEURAL-NETWORK; CLASSIFICATION; SYSTEM
AB Rice crop contains a wide variety of diseases that can affect the entire yield. These infections include but are not limited to fungal blast (Magnaporthe grisea), sheath rot, sheath blight, rice tungro diseases, bacterial blight. Each of these infections is caused by one or another bacterium that affects the rice yield at the molecular level. The effect of this bacterium can be observed via changes in morphology and physiology properties of the rice crop. Mapping these changes to the infection requires a series of image classification and signal processing tasks to be performed with high efficiency. Classification models like convolutional neural networks (CNNs) have proven to be most effective and can achieve accuracy rates up to 98%. The performance of these models largely depends upon physical parameters of input imagery taken for training, testing, and validation. This work proposes an incremental learning model with transfer learning capabilities to stabilize this high accuracy performance for rice grain infection classification. The model uses Residual Network (ResNet) & VGGNet based CNN model for initial training on a custom static dataset, which is followed by a network of Gated Recurrent Units (GRU) for incremental transfer learning. Due to a combination of these networks, an accuracy of 99% is achieved with minimum re-training effort for new image type addition. This reduction in effort is due to an incremental weight update layer derived via Gated Recurrent Unit (GRU), which keeps a consistent classification performance while reducing training delay.
C1 [Patel, Bharati; Sharaff, Aakanksha] Natl Inst Technol, Bhilai, India.
RP Patel, B (corresponding author), Natl Inst Technol, Bhilai, India.
EM bpatel.phd2018.cs@nitrr.ac.in; asharaff.cs@nitrr.ac.in
RI Sharaff, Aakanksha/L-9995-2016
OI Sharaff, Aakanksha/0000-0001-5499-7289; Ph.D. Student, Bharati
   Patel/0000-0003-1878-2269
CR Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   Aravind KR, 2020, AUTOMATIKA-UK, V61, P260, DOI 10.1080/00051144.2020.1728911
   Chen JD, 2021, IET IMAGE PROCESS, V15, P1115, DOI 10.1049/ipr2.12090
   Chen JD, 2021, PLANT PATHOL, V70, P630, DOI 10.1111/ppa.13322
   Chen JD, 2020, J SCI FOOD AGR, V100, P3246, DOI 10.1002/jsfa.10365
   Dai Q, 2020, IEEE ACCESS, V8, P81943, DOI 10.1109/ACCESS.2020.2991552
   Dai Q, 2020, IEEE ACCESS, V8, P55724, DOI 10.1109/ACCESS.2020.2982055
   Fenu G, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/6663442
   Ghazi MM, 2017, NEUROCOMPUTING, V235, P228, DOI 10.1016/j.neucom.2017.01.018
   Ghosal S, 2020, 2020 IEEE CALCUTTA CONFERENCE (CALCON), P230, DOI [10.1109/CALCON49167.2020.9106423, 10.1109/calcon49167.2020.9106423]
   Goluguri NVRR, 2021, ARTIF INTELL REV, V54, P359, DOI 10.1007/s10462-020-09849-y
   Hasan MM, 2019, INT RELIAB PHY SYM, DOI 10.1109/irps.2019.8720586
   He L, 2021, IEEE T GEOSCI REMOTE, V59, P979, DOI 10.1109/TGRS.2020.3000992
   Hu WJ, 2020, IEEE ACCESS, V8, P115287, DOI 10.1109/ACCESS.2020.3001237
   Huang SJ, 2020, IEEE ACCESS, V8, P136421, DOI 10.1109/ACCESS.2020.3011685
   Jadhav Sachin B., 2021, International Journal of Information Technology, P2461, DOI 10.1007/s41870-020-00437-5
   Jiang P, 2019, IEEE ACCESS, V7, P59069, DOI 10.1109/ACCESS.2019.2914929
   Jiang Y, 2020, PLANT PHENOMICS, V2020, DOI 10.34133/2020/4152816
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   knowledgebank, ABOUT US
   Lee SH, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.601250
   Li DS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030578
   Liang WJ, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38966-0
   Liu B, 2020, IEEE ACCESS, V8, P102188, DOI 10.1109/ACCESS.2020.2998839
   Liu J, 2021, PLANT METHODS, V17, DOI 10.1186/s13007-021-00722-9
   Lv MJ, 2020, IEEE ACCESS, V8, P57952, DOI 10.1109/ACCESS.2020.2982443
   Martinelli F, 2015, AGRON SUSTAIN DEV, V35, P1, DOI 10.1007/s13593-014-0246-1
   Mique EL, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND SYSTEM (ICISS 2018), P147, DOI 10.1145/3209914.3209945
   Nagaraju M, 2020, INT J SYST ASSUR ENG, V11, P547, DOI 10.1007/s13198-020-00972-1
   Nghia DT, 2019, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND SOFT COMPUTING (ICMLSC 2019), P27, DOI 10.1145/3310986.3310997
   Le NQK, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2972-5
   Pan WY, 2019, IEEE ACCESS, V7, P87534, DOI 10.1109/ACCESS.2019.2924973
   Rehman ZU, 2021, IET IMAGE PROCESS, V15, P2157, DOI 10.1049/ipr2.12183
   Shrivastava VK, 2021, J PLANT PATHOL, V103, P17, DOI 10.1007/s42161-020-00683-3
   Singh UP, 2019, IEEE ACCESS, V7, P43721, DOI 10.1109/ACCESS.2019.2907383
   Pham TN, 2020, IEEE ACCESS, V8, P189960, DOI 10.1109/ACCESS.2020.3031914
   Teramoto S, 2020, PLANT PHENOMICS, V2020, DOI 10.34133/2020/3194308
   Turkoglu M, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01591-w
   Wang L, 2020, IET COMPUT VIS, V14, P538, DOI 10.1049/iet-cvi.2019.0136
   Wu H., 2019, Plant Phenome Journal, Volume, V2, P1, DOI DOI 10.2135/TPPJ2019.03.0006
   Wu QF, 2020, IEEE ACCESS, V8, P98716, DOI 10.1109/ACCESS.2020.2997001
   Yang GF, 2020, IEEE ACCESS, V8, P211912, DOI 10.1109/ACCESS.2020.3039345
   Yao N, 2021, PLANT METHODS, V17, DOI 10.1186/s13007-021-00736-3
   Zeng QM, 2020, IEEE ACCESS, V8, P172882, DOI 10.1109/ACCESS.2020.3025196
   Zhang DY, 2020, IEEE ACCESS, V8, P109876, DOI 10.1109/ACCESS.2020.3001652
NR 45
TC 5
Z9 5
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 28997
EP 29016
DI 10.1007/s11042-023-14980-3
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000945313000002
DA 2024-07-18
ER

PT J
AU Wei, HL
   Hai, CY
   Shan, DL
   Lyu, B
   Wang, XL
AF Wei, HeLin
   Hai, Chenying
   Shan, Donglu
   Lyu, Bei
   Wang, Xiulai
TI Text recognition and analysis of network public opinion focus events of
   a major epidemic: a case study of "COVID-19" in Sina Microblogs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Keyword co-occurrence; Major epidemic; Network public opinion
ID EBOLA
AB Identifying and analyzing the public's opinion of focal events during a major epidemic can help the government grasp the vicissitudes of network public opinion in a timely manner and provide the appropriate responses. Taking the COVID-19 epidemic as an example, this study begins by using Python-selenium to capture the original text and comment data related to COVID-19 from Sina Microblog's CCTV News from Jan. 19, 2020, to Feb. 20, 2020. The study subsequently uses a manual interpretation method to classify the Weibo content and analyzes the shifting focus phenomena of network public opinion based on the moving average method. Next, the study uses an enhances TF-IDF to extract keywords from the Weibo comment and uses the keywords to construct a word co-occurrence network. The results show that during the epidemic, the network public opinion focus shifted significantly over time. With the progression of the epidemic, the focus of network public opinion diversified, and various categories stabilized. Compared to simple keyword and text classification recognition focus problems, the proposed model, which is highly accurate, identified multiple network public opinion focus problems and described the core contradictions of the different focus problems.
C1 [Wei, HeLin; Shan, Donglu] Guangxi Univ, Sch Business, Nanning, Peoples R China.
   [Wei, HeLin] Guangxi Univ, Educ Dept Guangxi, Key Lab Interdisciplinary Sci Stat & Management, Nanning, Peoples R China.
   [Hai, Chenying] Huazhong Univ Sci & Technol, Sch Management, Wuhan, Peoples R China.
   [Lyu, Bei] Huaibei Normal Univ, Sch Econ & Management, Huaibei, Peoples R China.
   [Lyu, Bei] Panyapiwat Inst management, Nonthaburi, Thailand.
   [Lyu, Bei] Univ Leeds, Leeds Univ, Business Sch, Leeds, England.
   [Wang, Xiulai] Nanjing Univ Informat Sci & Technol, Inst Big Data Talents, Nanjing, Peoples R China.
C3 Guangxi University; Guangxi University; Huazhong University of Science &
   Technology; Huaibei Normal University; University of Leeds; Nanjing
   University of Information Science & Technology
RP Hai, CY (corresponding author), Huazhong Univ Sci & Technol, Sch Management, Wuhan, Peoples R China.; Lyu, B (corresponding author), Huaibei Normal Univ, Sch Econ & Management, Huaibei, Peoples R China.; Lyu, B (corresponding author), Panyapiwat Inst management, Nonthaburi, Thailand.; Lyu, B (corresponding author), Univ Leeds, Leeds Univ, Business Sch, Leeds, England.
EM 893046060@qq.com; peter1983123@hotmail.com
RI Lyu, Peter B./AAE-1496-2020; wei, he/KCY-2550-2024
OI Lyu, Peter B./0000-0001-7023-6009; Shan, Donglu/0000-0002-8098-0111
FU National Natural Science Foundation of China [71662004, 71872055]; Key
   Research Base of Humanities and Social Sciences in Guangxi Universities;
   Project of Guangxi Development Strategy Institute in China
   [2022GDSIYB14, 2021GDSIYB05]; Guangxi philosophy and Social Science
   Planning Research Project [21FMZ050]; Innovation Project of Guangxi
   Graduate Education [JGY2022018]
FX National Natural Science Foundation of China (Grant No. 71662004,
   71872055); Key Research Base of Humanities and Social Sciences in
   Guangxi Universities and the Project of Guangxi Development Strategy
   Institute in China (Grant No. 2022GDSIYB14; 2021GDSIYB05); Guangxi
   philosophy and Social Science Planning Research Project (Grant No.
   21FMZ050); Innovation Project of Guangxi Graduate Education (Grant No.
   JGY2022018).
CR An L, 2018, ONLINE INFORM REV, V42, P821, DOI 10.1108/OIR-04-2016-0100
   [Anonymous], 2016, ONLINE INFORM REV, DOI DOI 10.14120/J.CNKI.CN11-5057/F.2016.08.022
   Ataa Allah F., 2007, LECT NOTES COMPUT SC, DOI [10.1007/978-3-540-73,351-5_10, DOI 10.1007/978-3-540-73,351-5_10]
   Bora K, 2018, PATHOG GLOB HEALTH, V112, P320, DOI 10.1080/20477724.2018.1507784
   Chen S, 2018, JMIR PUBLIC HLTH SUR, V4, P73, DOI 10.2196/10827
   Chua AYK, 2018, COMPUT HUM BEHAV, V87, P1, DOI 10.1016/j.chb.2018.05.021
   Cui JH., 2021, FRONT PEDIATR, V41, P161, DOI [10.3969/j.issn.1008-0821.2021.11.016, DOI 10.3969/J.ISSN.1008-0821.2021.11.016]
   Gil-García R, 2010, PATTERN RECOGN LETT, V31, P469, DOI 10.1016/j.patrec.2009.11.011
   Hadi TA, 2016, DISASTER MED PUBLIC, V10, P775, DOI 10.1017/dmp.2016.39
   He H, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1121636
   [洪巍 Hong Wei], 2016, [中国人口·资源与环境, China Population Resources and Environment], V26, P167
   Huang GJ, 2019, INT J ANTENN PROPAG, V2019, DOI 10.1155/2019/3197497
   Lee JY, 2015, AEROSOL AIR QUAL RES, V15, P673, DOI 10.4209/aaqr.2014.02.0036
   Li Y., 2021, INFORM SCIENCES, V39, P113, DOI [10.13833/j.issn.1007-7634.2021.12.017, DOI 10.13833/J.ISSN.1007-7634.2021.12.017]
   [刘影 Liu Ying], 2016, [复杂系统与复杂性科学, Complex Systems and Complexity Science], V13, P74
   Ma YP, 2014, PROCEDIA ENGINEER, V71, P616, DOI 10.1016/j.proeng.2014.04.088
   Matheson C, 2014, INT J DRUG POLICY, V25, P407, DOI 10.1016/j.drugpo.2013.11.001
   McCauley M, 2013, BMC PUBLIC HEALTH, V13, DOI 10.1186/1471-2458-13-1116
   [祁凯 Qi Kai], 2020, [中国管理科学, Chinese Journal of Management Science], V28, P59
   Schultz F, 2011, PUBLIC RELAT REV, V37, P20, DOI 10.1016/j.pubrev.2010.12.001
   Seltzer EK, 2015, PUBLIC HEALTH, V129, P1273, DOI 10.1016/j.puhe.2015.07.025
   Shuwei Xiao, 2021, Journal of Physics: Conference Series, V1757, DOI 10.1088/1742-6596/1757/1/012089
   Signorini A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019467
   Tocoglu Mansur Alp, 2021, Intelligent and Fuzzy Techniques: Smart and Innovative Solutions. Proceedings of the INFUS 2020 Conference. Advances in Intelligent Systems and Computing (AISC 1197), P1693, DOI 10.1007/978-3-030-51156-2_197
   Trieschnigg D., 2004, TOPIC DETECTION TRAC
   Wang GH, 2019, INFORM PROCESS MANAG, V56, P584, DOI 10.1016/j.ipm.2018.11.010
   Xiao J, 2022, IEEE T COMPUT AID D, V41, P4708, DOI 10.1109/TCAD.2022.3142194
   Yang L, 2016, COGN COMPUT, V8, P577, DOI 10.1007/s12559-015-9380-6
   Zhang YF., 2017, INF THEORY PRACTICE, V40, P82, DOI [10.16353/j.cnki.1000-7490.2017.09.016, DOI 10.16353/J.CNKI.1000-7490.2017.09.016]
NR 29
TC 1
Z9 1
U1 10
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 25811
EP 25827
DI 10.1007/s11042-023-14916-x
EA MAR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000945313000010
PM 37362683
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Kotkar, VA
   Sucharita, V
AF Kotkar, Vijay A. A.
   Sucharita, V.
TI Fast anomaly detection in video surveillance system using robust
   spatiotemporal and deep learning methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Cuboids; Deep learning; Keyframe extraction; Spatio
   temporal; Video surveillance
ID BEHAVIOR RECOGNITION; INTERSECTIONS; TRACKING; LOOKING; ONLINE
AB Since from emergence of deep learning techniques, automatic video surveillance has received researchers' attention. Such deep learning-based methods improve the accuracy but lead to higher computational complexities than the semi-automatic approach. A unique framework is proposed in this study to bridge the gap between automated and semi-automatic operations to save time and boost accuracy. The main advantage of the proposed model is reducing the computational complexity while improving the overall accuracy using the deep learning approach in video anomaly detection applications. The framework consists of keyframe extraction, robust features extraction, automatic features learning, and classification. Extracting keyframes from the input videos reduces the computational burden during features extraction and classification steps. The novel lightweight keyframe extraction algorithm using the histogram and dynamic thresholding technique is proposed in this paper. This research proposes a revolutionary lightweight keyframe extraction approach based on the histogram and dynamic thresholding technique. Efficient motion tracking among frames is a critical research challenge in video anomaly detection. We propose the novel Modified Spatio-Temporal (MST) approach to extract the interest points as features in this paper. Input frames are normalized and pre-processed using Gaussian filtering first in the proposed MST. Then motion tracking and cuboids are estimated from the pre-processed frames. From 3D cuboids, we applied Discrete Wavelet Transform (DWT) with Principal Component Analysis (PCA) to generate the codebook. This codebook passed as sequential input to Recurrent Neural Network (RNN) using Long Term Short Memory (LSTM) classifier called RNN-LSTM. The novel training and classification model of deep learning is designed to estimate the probability of each class (i.e., anomalous or normal) of the video sequence. The experimental results of the proposed MST-RNN-LSTM model achieved significant improvement in computational and detection efficiencies compared to state-of-art methods. The keyframe extraction algorithm discarded 50% of the frames in an input video sequence, resulting in less computing overhead. The accuracy of the proposed model is improved by 4.5% and the processing time is reduced by 21% compared to state-of-art methods.
C1 [Kotkar, Vijay A. A.; Sucharita, V.] PCETs Pimpri Chinchwad Coll Engn & Res, Dept Comp Engn, Pune, Maharashtra, India.
   [Kotkar, Vijay A. A.] Narayana Coll Engn, Dept Comp Sci & Engn, Gudur, India.
RP Kotkar, VA (corresponding author), PCETs Pimpri Chinchwad Coll Engn & Res, Dept Comp Engn, Pune, Maharashtra, India.; Kotkar, VA (corresponding author), Narayana Coll Engn, Dept Comp Sci & Engn, Gudur, India.
EM vijay.kotkar@pccoer.in; jesuchi78@yahoo.com
OI Kotkar, Dr. Vijay/0000-0003-1236-9596
CR Aköz Ö, 2014, MACH VISION APPL, V25, P613, DOI 10.1007/s00138-011-0390-4
   Alhayani B, 2022, APPL NANOSCI, DOI 10.1007/s13204-021-02152-4
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Nievas EB, 2011, LECT NOTES COMPUT SC, V6855, P332, DOI 10.1007/978-3-642-23678-5_39
   Deepak K, 2021, CIRC SYST SIGNAL PR, V40, P1333, DOI 10.1007/s00034-020-01522-7
   Deepak K, 2021, SIGNAL IMAGE VIDEO P, V15, P215, DOI 10.1007/s11760-020-01740-1
   Esen E, 2013, INT WORK CONTENT MUL, P131, DOI 10.1109/CBMI.2013.6576569
   Hospedales TM, 2011, IEEE T PATTERN ANAL, V33, P2451, DOI 10.1109/TPAMI.2011.81
   Hu JT, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19194145
   Huang C, 2022, IEEE T IND INFORM, V18, P5171, DOI 10.1109/TII.2021.3122801
   Jeong H, 2014, MACH VISION APPL, V25, P1501, DOI 10.1007/s00138-014-0629-y
   Kamijo S., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P108, DOI 10.1109/6979.880968
   Khaire P, 2022, FORENS SCI INT-DIGIT, V40, DOI 10.1016/j.fsidi.2022.301346
   Kotkar V., 2020, J ADV RES DYN CONTRO, V12, P395, DOI [10.5373/JARDCS/V12I7/20202020, DOI 10.5373/JARDCS/V12I7/20202020]
   Kotkar V., 2018, J ENG APPL SCI JEAS, V12, P9376, DOI [10.36478/jeasci.2017.9376.9381, DOI 10.36478/JEASCI.2017.9376.9381]
   Lessard A, 2016, IEEE COMPUT SOC CONF, P1592, DOI 10.1109/CVPRW.2016.198
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Liu ZA, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13568, DOI 10.1109/ICCV48922.2021.01333
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2022, IEEE T PATTERN ANAL, V44, P7505, DOI 10.1109/TPAMI.2021.3129349
   Luo WX, 2021, IEEE T PATTERN ANAL, V43, P1070, DOI 10.1109/TPAMI.2019.2944377
   Mahajan HB, 2022, APPL NANOSCI, DOI 10.1007/s13204-021-02164-0
   Mahajan HB, 2021, WIRELESS PERS COMMUN, V121, P3125, DOI 10.1007/s11277-021-08866-6
   Mahajan HB, 2021, J AMB INTEL HUM COMP, V12, P7777, DOI 10.1007/s12652-020-02502-0
   Mikhail A, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, CONTROL AND AUTOMATION (ICCUBEA)
   Mikhail A, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, CONTROL AND AUTOMATION (ICCUBEA)
   Mo X, 2014, IEEE T CIRC SYST VID, V24, P631, DOI 10.1109/TCSVT.2013.2280061
   Mohammadi S, 2016, LECT NOTES COMPUT SC, V9911, P3, DOI 10.1007/978-3-319-46478-7_1
   Narasimhan MG, 2018, MULTIMED TOOLS APPL, V77, P13173, DOI 10.1007/s11042-017-4940-2
   Nasaruddin N, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00365-y
   Nawaratne R, 2020, IEEE T IND INFORM, V16, P393, DOI 10.1109/TII.2019.2938527
   Ngo D, 2016, 2016 INT C EL INF CO, P1, DOI [10.1109/ELINFOCOM.2016.7562953, DOI 10.1109/ELINFOCOM.2016.7562953]
   Patino L, 2014, APPL SOFT COMPUT, V25, P485, DOI 10.1016/j.asoc.2014.08.039
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Ramchandran A, 2020, MULTIMED TOOLS APPL, V79, P35275, DOI 10.1007/s11042-019-7702-5
   Roshtkhari MJ, 2013, COMPUT VIS IMAGE UND, V117, P1436, DOI 10.1016/j.cviu.2013.06.007
   Shirazi MS, 2017, IEEE T INTELL TRANSP, V18, P4, DOI 10.1109/TITS.2016.2568920
   Sivaraman S, 2013, IEEE T INTELL TRANSP, V14, P1773, DOI 10.1109/TITS.2013.2266661
   Sodemann AA, 2012, IEEE T SYST MAN CY C, V42, P1257, DOI 10.1109/TSMCC.2012.2215319
   Srinivasan A, 2019, MULTIMED TOOLS APPL, V78, P7713, DOI 10.1007/s11042-018-6348-z
   Sultani Waqas, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P324, DOI 10.1109/ICPR.2010.88
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Wang J, 2022, J AMB INTEL HUM COMP, V13, P1293, DOI 10.1007/s12652-020-02574-y
   Wang T, 2014, IEEE T INF FOREN SEC, V9, P988, DOI 10.1109/TIFS.2014.2315971
   Wang WQ, 2022, SIGNAL IMAGE VIDEO P, V16, P1747, DOI 10.1007/s11760-021-02131-w
   Wu CK, 2022, CLUSTER COMPUT, V25, P2715, DOI 10.1007/s10586-021-03439-5
   Xue ZX, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-018-9792-8
   Yang B, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/2087574
   Yoa S, 2021, IEEE ACCESS, V9, P147201, DOI 10.1109/ACCESS.2021.3124525
   Yu BS, 2017, IEEE T SYST MAN CY-S, V47, P704, DOI 10.1109/TSMC.2016.2638048
   Yun KM, 2014, INT C PATT RECOG, P3062, DOI 10.1109/ICPR.2014.528
   Zhang QQ, 2022, MULTIMED TOOLS APPL, V81, P27073, DOI 10.1007/s11042-021-11550-3
   ZHANG Y, 2016, PATTERN RECOGN, V51, P443, DOI DOI 10.1016/J.PATC0G.2015.09.005
NR 54
TC 3
Z9 3
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34259
EP 34286
DI 10.1007/s11042-023-14840-0
EA MAR 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000943638900006
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Wang, JL
   Wang, X
   Jing, HN
   Sun, ZS
   Cai, Y
AF Zhang, Yu
   Wang, Junlin
   Wang, Xin
   Jing, Haonan
   Sun, Zhanshuo
   Cai, Yu
TI Static hand gesture recognition method based on the Vision Transformer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand gesture recognition; Vision Transformer; Arm removal; Data
   augmentation
ID CONVOLUTIONAL NEURAL-NETWORKS; AMERICAN SIGN-LANGUAGE
AB Hand gesture recognition (HGR) is the most important part of human-computer interaction (HCI). Static hand gesture recognition is equivalent to the classification of hand gesture images. At present, the classification of hand gesture images mainly uses the Convolutional Neural Network (CNN) method. The Vision Transformer architecture (ViT) proposes not to use the convolutional layers at all but to use the multi-head attention mechanism to learn global information. Therefore, this paper proposes a static hand gesture recognition method based on the Vision Transformer. This paper uses a self-made dataset and two publicly available American Sign Language (ASL) datasets to train and evaluate the ViT architecture. Using the depth information provided by the Microsoft Kinect camera to capture the hand gesture images and filter the background, then use the eight-connected discrimination algorithm and the distance transformation algorithm to remove the redundant arm information. The resulting images constitute a self-made dataset. At the same time, this paper studies the impact of several data augmentation strategies on recognition performance. This paper uses accuracy, F1 score, recall, and precision as evaluation metrics. Finally, the validation accuracy of the proposed model on the three datasets achieves 99.44%, 99.37%, and 96.53%, respectively, and the results obtained are better than those obtained by some CNN structures.
C1 [Zhang, Yu; Wang, Junlin; Wang, Xin; Jing, Haonan; Sun, Zhanshuo; Cai, Yu] Inner Mongolia Univ, Coll Elect Informat Engn, Hohhot 010021, Peoples R China.
C3 Inner Mongolia University
RP Wang, JL; Wang, X (corresponding author), Inner Mongolia Univ, Coll Elect Informat Engn, Hohhot 010021, Peoples R China.
EM 32056139@mail.imu.edu.cn; wangjunlin@imu.edu.cn; wangxin219@imu.edu.cn;
   32056138@mail.imu.edu.cn; 32056106@mail.imu.edu.cn;
   32056096@mail.imu.edu.cn
OI Wang, Junlin/0000-0001-8708-5059
FU National Natural Science Foundation of China [51965047]; Natural Science
   Foundation of Inner Mongolia Autonomous Region of China [2021MS06012];
   Science and Technology Planning Project of Inner Mongolia Autonomous
   Region of China [2020GG0185]
FX AcknowledgementsThis research was supported in part by the National
   Natural Science Foundation of China under Grants 51965047, in part by
   the Natural Science Foundation of Inner Mongolia Autonomous Region of
   China under Grants 2021MS06012, and in part by the Science and
   Technology Planning Project of Inner Mongolia Autonomous Region of China
   under Grants 2020GG0185.
CR Alani AA, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT (ICIM2018), P5, DOI 10.1109/INFOMAN.2018.8392660
   Ameen S, 2017, EXPERT SYST, V34, DOI 10.1111/exsy.12197
   Bendarkar DS, 2021, INT J ONLINE BIOMED, V17, P34, DOI 10.3991/ijoe.v17i01.18585
   Bergstra J., 2011, Adv. Neural Inf. Process. Syst., V24
   Bhojanapalli S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10211, DOI 10.1109/ICCV48922.2021.01007
   Bowles C., 2018, arXiv
   Chen NX, 2021, IEEE SIGNAL PROC LET, V28, P121, DOI 10.1109/LSP.2020.3044547
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Chevtchenko SF, 2018, APPL SOFT COMPUT, V73, P748, DOI 10.1016/j.asoc.2018.09.010
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   DeVries T, 2017, PREPRINT
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Islam MZ, 2019, 2019 JOINT 8TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV) AND 2019 3RD INTERNATIONAL CONFERENCE ON IMAGING, VISION & PATTERN RECOGNITION (ICIVPR) WITH INTERNATIONAL CONFERENCE ON ACTIVITY AND BEHAVIOR COMPUTING (ABC), P324, DOI [10.1109/iciev.2019.8858563, 10.1109/ICIEV.2019.8858563]
   Khari M, 2019, INT J INTERACT MULTI, V5, P22, DOI 10.9781/ijimai.2019.09.002
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li GF, 2019, CLUSTER COMPUT, V22, pS2719, DOI 10.1007/s10586-017-1435-x
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lu DL, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1349, DOI 10.1109/ROBIO.2016.7866514
   Mirsu R, 2020, POINTNET BASED SOLUT, V20
   Modanwal G, 2018, PATTERN RECOGN LETT, V110, P72, DOI 10.1016/j.patrec.2018.03.025
   Mohammed AAQ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235282
   Nagi J., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P342, DOI 10.1109/ICSIPA.2011.6144164
   Naseer M. M., 2021, Advances in Neural Information Processing Systems
   Oyedotun OK, 2017, NEURAL COMPUT APPL, V28, P3941, DOI 10.1007/s00521-016-2294-8
   Ozcan T, 2019, NEURAL COMPUT APPL, V31, P8955, DOI 10.1007/s00521-019-04427-y
   Pan TY, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P64, DOI 10.1109/BigMM.2016.44
   Paul S, 2022, AAAI CONF ARTIF INTE, P2071
   Pigou L, 2015, LECT NOTES COMPUT SC, V8925, P572, DOI 10.1007/978-3-319-16178-5_40
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   Qi JX, 2020, NEURAL COMPUT APPL, V32, P6343, DOI 10.1007/s00521-019-04142-8
   Raghu M, 2021, ADV NEUR IN, V34
   Rao GA, 2018, 2018 CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION ENGINEERING SYSTEMS (SPACES), P194, DOI 10.1109/SPACES.2018.8316344
   Sadeddine K, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103193
   Sharma P, 2020, IET IMAGE PROCESS, V14, P909, DOI 10.1049/iet-ipr.2019.0230
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan YS, 2021, EXPERT SYST APPL, V175, DOI 10.1016/j.eswa.2021.114797
   Tan YS, 2021, NEURAL COMPUT APPL, V33, P5339, DOI 10.1007/s00521-020-05337-0
   Tang A, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2735952
   Tao WJ, 2018, ENG APPL ARTIF INTEL, V76, P202, DOI 10.1016/j.engappai.2018.09.006
   Touvron H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P32, DOI 10.1109/ICCV48922.2021.00010
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Vaswani A, 2017, ADV NEUR IN, V30
   Wadhawan A, 2020, NEURAL COMPUT APPL, V32, P7957, DOI 10.1007/s00521-019-04691-y
   Wang Q, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1810
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Xu BY, 2017, LECT NOTES COMPUT SC, V10261, P180, DOI 10.1007/978-3-319-59072-1_22
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   ZENG RH, 2020, IEEE C EVOL COMPUTAT, pNI224, DOI DOI 10.1109/cec48606.2020.9185510
   Zhou HY, 2021, IEEE INT CONF COMP V, P2230, DOI 10.1109/ICCVW54120.2021.00252
NR 53
TC 0
Z9 1
U1 4
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31309
EP 31328
DI 10.1007/s11042-023-14732-3
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000943009100022
DA 2024-07-18
ER

PT J
AU Zhao, MH
   Zhi, YX
   Yuan, F
   Li, JH
   Hu, J
   Du, SL
   Shi, ZH
AF Zhao, Minghua
   Zhi, Yuxing
   Yuan, Fei
   Li, Junhuai
   Hu, Jing
   Du, Shuangli
   Shi, Zhenghao
TI Deep-block network for AU recognition and expression migration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Expression recognition; Expression migration; Facial action unit coding
ID SYSTEM
AB Human facial behavior is an important information for communication. The study of facial behavior is one of the significant research topics in field of psychology, computer vision and artificial intelligence. In order to improve performance of facial expression and action unit recognition, a face recognition method based on deep-block network proposed in this paper. First, to improve the network performance, we preprocess the input of the network facial image, which includes two operations: face detection and face standardization. Second, deep-block network regards facial parts as the core of expression recognition rather than the whole face and key areas are in charge of specific action units to abate the weak correlation bias, which results in better classification and regression effect. Last, with the purpose of reducing impact of image independent factors, relevant feature map is applied to recognize the associated facial action units, which can promote the accuracy of detection to a certain extent. Experimental results on CK+ and MMI show that proposed method can not only capture the correlation of whole face regions globally, but also can increase network speed caused by too few pooling layers.
C1 [Zhao, Minghua; Zhi, Yuxing; Yuan, Fei; Li, Junhuai; Hu, Jing; Du, Shuangli; Shi, Zhenghao] Xian Univ Technol, Sch Comp Sci & Engn, 5 South Jinhua Rd, Xian 710048, Shaanxi, Peoples R China.
   [Zhao, Minghua] Shaanxi Key Lab Network Comp & Secur Technol, 5 South Jinhua Rd, Xian 710048, Shaanxi, Peoples R China.
C3 Xi'an University of Technology
RP Zhao, MH (corresponding author), Xian Univ Technol, Sch Comp Sci & Engn, 5 South Jinhua Rd, Xian 710048, Shaanxi, Peoples R China.; Zhao, MH (corresponding author), Shaanxi Key Lab Network Comp & Secur Technol, 5 South Jinhua Rd, Xian 710048, Shaanxi, Peoples R China.
EM mh_zhao@126.com; zyxing25@163.com; yuanfei.yanan@qq.com;
   lijunhuai@xaut.edu.cn; jinghu@xaut.edu.cn; dusl@xaut.edu.cn;
   ylshi@xaut.edu.cn
FU National Key Technology Research and Development Program of China
   [2017YFB1402103-3]; National Natural Science Foundation of China
   [61901363, 61901362]; Natural Science Foundation of Shaanxi province,
   China [2020JQ-648,2019JM-381, 2019JQ-729]; Key Laboratory Foundation of
   Shaanxi Education Department [20JS086]
FX The authors wish to thank the editor-in-chief, associate editor and
   reviewers for their insightful comments and suggestions. This work was
   supported by National Key Technology Research and Development Program of
   China(2017YFB1402103-3), National Natural Science Foundation of China
   (61901363, 61901362) and Natural Science Foundation of Shaanxi province,
   China (2020JQ-648,2019JM-381, 2019JQ-729) and Key Laboratory Foundation
   of Shaanxi Education Department (20JS086).Data availability
   statementsThe data that support the findings of this study are available
   from the corresponding author upon reasonable request.
CR Batista JC., 2017, IEEE INT C AUTOMATIC
   Chen D, 2016, LECT NOTES COMPUT SC, V9909, P122, DOI 10.1007/978-3-319-46454-1_8
   Cheok AD, 2004, PERS UBIQUIT COMPUT, V8, P71, DOI 10.1007/s00779-004-0267-x
   Cootes T.F., 1993, 4th British Machine Vision Conference, P639
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Tran DL, 2017, IEEE I CONF COMP VIS, P3209, DOI 10.1109/ICCV.2017.346
   Ekman P., 1978, APA PsycTests, DOI DOI 10.1037/T27734-000
   Ghosh S, 2015, INT CONF AFFECT, P609, DOI 10.1109/ACII.2015.7344632
   Gudi A., 2015, 2015 11 IEEE INT C W, V6, P1
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Liu XF, 2017, IEEE COMPUT SOC CONF, P522, DOI 10.1109/CVPRW.2017.79
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Parr LA, 2010, AM J PHYS ANTHROPOL, V143, P625, DOI 10.1002/ajpa.21401
   Peng GZ, 2018, PROC CVPR IEEE, P2188, DOI 10.1109/CVPR.2018.00233
   Ruiz A, 2015, IEEE I CONF COMP VIS, P3703, DOI 10.1109/ICCV.2015.422
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tong Yan, 2008, IEEE CVPR, P1
   Tser Z., 2016, DEEP LEARNING FACIAL
   Valstar M.F., 2010, P INT C LANG RES EV
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P28, DOI 10.1109/TSMCB.2011.2163710
   van der Maaten L, 2012, COGN PROCESS, V13, P507, DOI 10.1007/s10339-011-0419-7
   Walecki R, 2017, PROC CVPR IEEE, P5709, DOI 10.1109/CVPR.2017.605
   Wang C, 2019, IEEE IMAGE PROC, P56, DOI [10.1109/ICIP.2019.8802914, 10.1109/icip.2019.8802914]
   Wang ZH, 2013, IEEE I CONF COMP VIS, P3304, DOI 10.1109/ICCV.2013.410
   Wongpatikaseree Konlakorn, 2021, 2021 25th International Computer Science and Engineering Conference (ICSEC), P318, DOI 10.1109/ICSEC53205.2021.9684576
   Yan J., 2022, WEAKLY SUPERVISED RE, DOI [10.1109/TMM.2022.3160061.[76]H., DOI 10.1109/TMM.2022.3160061]
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zeng Z, 2009, IEEE T PATTERN ANAL
   Zhang SF, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P1, DOI 10.1109/BTAS.2017.8272675
   Zhang Y, 2018, PROC CVPR IEEE, P2314, DOI 10.1109/CVPR.2018.00246
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhao ZH, 2016, IEEE INT C BIOINFORM, P794, DOI 10.1109/BIBM.2016.7822625
   Zhou YQ, 2017, IEEE INT CONF AUTOMA, P872, DOI 10.1109/FG.2017.112
NR 35
TC 1
Z9 1
U1 7
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 25733
EP 25746
DI 10.1007/s11042-023-14527-6
EA MAR 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000941913300001
DA 2024-07-18
ER

PT J
AU Kollem, S
   Reddy, KR
   Rao, DS
AF Kollem, Sreedhar
   Reddy, Katta Ramalinga
   Rao, Duggirala Srinivasa
TI A novel diffusivity function-based image denoising for MRI medical
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generalized cross-validation; Quaternion Wavelet Transform; Diffusivity
   function; Partial differential equation; Poisson noise
ID ANISOTROPIC DIFFUSION; NOISE REMOVAL; MODEL; FILTER; PDE
AB Medical imaging is essential for accurate diagnosis. In medical imaging, various algorithms for image denoising have been developed. However, some drawbacks have been identified, including the blocking effect, which results in excessive smoothing of the images, and the loss of image detail. To generate noise on images, this article used Poisson noise. We propose a new diffusivity function-based partial differential equation method used for image denoising with the aid of exploiting the statistical properties of observed noisy images. This model involves a Quaternion Wavelet Transform, which is responsible for creating the different coefficients of a noisy image. Utilizing the soft threshold function, an improved generalized cross-validation function is responsible for determining the best threshold value. This optimal threshold value is then used to control the diffusion process by means of a new diffusivity function. Here, we introduce the fourth-order partial differential equation diffusivity function, an unique diffusion coefficient that is more effective than earlier approaches at eliminating noise and maintaining edges. Finally, the experiments of the proposed method are measured using the peak signal-to-noise ratio (42.78 dBs), mean square error (3.4206), structural similarity index (99.645 %), and standard error (peak signal-to-noise ratio (40.677 dBs), mean square error (5.867), and structural similarity index (97.978 %)) as well as compared to the results of other conventional image denoising techniques (improved partial differential equation-based total variation model, Generalization cross-validation with diffusivity function, non-linear nonlocal diffusion equation, Efficient anisotropic diffusion model, and Hessian matrix-based fourth-order anisotropic diffusion filter). The proposed method produces superior qualitative and quantitative results. The MATLAB R2020a version was used to analyze the results.
C1 [Kollem, Sreedhar] SR Univ, Sch Engn, Dept ECE, Warangal, Telangana, India.
   [Reddy, Katta Ramalinga] G Narayanamma Inst Technol & Sci, Dept ETM, Hyderabad, Telangana, India.
   [Rao, Duggirala Srinivasa] JNTUH Coll Engn, Dept ECE, Hyderabad, Telangana, India.
C3 Jawaharlal Nehru Technological University - Hyderabad
RP Kollem, S (corresponding author), SR Univ, Sch Engn, Dept ECE, Warangal, Telangana, India.
EM ksreedhar446@gmail.com
RI Kollem, S/GQQ-3144-2022
OI Kollem, S/0000-0002-9203-0404
CR Barbu T, 2016, COMPUT ELECTR ENG, V54, P345, DOI 10.1016/j.compeleceng.2016.04.012
   Barbu T, 2015, NUMER FUNC ANAL OPT, V36, P1375, DOI 10.1080/01630563.2015.1066388
   Barbu T, 2014, PROCEDIA COMPUT SCI, V35, P522, DOI 10.1016/j.procs.2014.08.133
   BRATS2020, 2023, BRATS2020
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Chao SM, 2010, PATTERN RECOGN LETT, V31, P2012, DOI 10.1016/j.patrec.2010.06.004
   Deng LZ, 2019, OPT LASER TECHNOL, V110, P184, DOI 10.1016/j.optlastec.2018.08.043
   Fletcher P, 2017, SIGNAL PROCESS, V136, P2, DOI 10.1016/j.sigpro.2016.12.025
   Ji X., 2013, P 2013 IEEE INT C ME, V2013, P1
   Khan NU, 2014, MULTIMED TOOLS APPL, V73, P573, DOI 10.1007/s11042-013-1620-8
   Kollem Sreedhar, 2019, International Journal of Machine Learning and Computing, V9, P288, DOI 10.18178/ijmlc.2019.9.3.800
   Kollem S, 2022, INT J IMAG SYST TECH, V32, P1263, DOI 10.1002/ima.22681
   Kollem S, 2021, MULTIMED TOOLS APPL, V80, P2663, DOI 10.1007/s11042-020-09745-1
   Kollem S, 2021, MULTIMED TOOLS APPL, V80, P409, DOI 10.1007/s11042-020-09675-y
   Kollem S, 2020, INT J IMAG SYST TECH, V30, P1271, DOI 10.1002/ima.22429
   Kollem S, 2019, INT J IMAG SYST TECH, V29, P195, DOI 10.1002/ima.22302
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Malathy V, 2020, SOFT COMPUT, V24, P18811, DOI 10.1007/s00500-020-05113-1
   Rafsanjani HK, 2016, COMPUT MATH APPL, V72, P893, DOI 10.1016/j.camwa.2016.06.005
   Rafsanjani HK, 2017, DIGIT SIGNAL PROCESS, V64, P71, DOI 10.1016/j.dsp.2017.02.004
   Riya, 2021, COMPUT MATH APPL, V93, P106, DOI 10.1016/j.camwa.2021.03.029
   Shi KH, 2021, J COMPUT APPL MATH, V395, DOI 10.1016/j.cam.2021.113605
   Tang C, 2008, OPT LETT, V33, P2179, DOI 10.1364/OL.33.002179
   Tebini S, 2016, DIGIT SIGNAL PROCESS, V48, P201, DOI 10.1016/j.dsp.2015.09.013
   Tebini S, 2016, COMPUT MATH APPL, V72, P1369, DOI 10.1016/j.camwa.2016.07.004
   Tsiotsios C, 2013, PATTERN RECOGN, V46, P1369, DOI 10.1016/j.patcog.2012.11.012
   Wang C, 2018, VISUAL COMPUT, V34, P1357, DOI 10.1007/s00371-017-1418-1
   Wang DH, 2016, INT J COMPUT MATH, V93, P942, DOI 10.1080/00207160.2015.1011144
   Wang N, 2018, IEEE ACCESS, V6, P33568, DOI 10.1109/ACCESS.2018.2844163
   Wang YQ, 2013, SIGNAL PROCESS, V93, P2548, DOI 10.1016/j.sigpro.2013.02.020
   Xu JT, 2016, SIGNAL PROCESS, V119, P80, DOI 10.1016/j.sigpro.2015.07.017
   Yin M, 2012, MATH PROBL ENG, V2012, DOI 10.1155/2012/493976
   Zhang CJ, 2016, ENG APPL ARTIF INTEL, V48, P204, DOI 10.1016/j.engappai.2015.10.008
NR 33
TC 4
Z9 4
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32057
EP 32089
DI 10.1007/s11042-023-14457-3
EA MAR 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000941926100016
DA 2024-07-18
ER

PT J
AU Agrawal, J
   Gupta, M
   Garg, H
AF Agrawal, Jharna
   Gupta, Manish
   Garg, Hitendra
TI A review on speech separation in cocktail party environment: challenges
   and approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Cocktail party problem; Speech separation; Computational auditory scene
   analysis; Beamforming; Deep learning
ID NONNEGATIVE MATRIX FACTORIZATION; RECURRENT NEURAL-NETWORKS; DEEP;
   SEGREGATION; RECOGNITION; CONTINUITY; SELECTION; TRACKING
AB The Cocktail party problem, which is tracing and identifying a specific speaker's speech while numerous speakers communicate concurrently is one of the crucial problems still to be addressed for automated speech recognition (ASR) and speaker recognition. In this study, we attempt to thoroughly explore traditional methods for speech separation in a cocktail party environment and further analyze traditional single-channel methods for example source-driven methods like Computational Auditory Scene Analysis (CASA), data-driven methods like non-negative matrix factorization (NMF), model-driven methods, customary multi-channel methods such as beamforming, blind source separation for multi-channel and the newly developed deep learning approaches such as meta-learning based methods, self-supervised learning. This paper further accentuates numerous datasets and evaluation metrics in the domain of speech processing & brings out the comparison between traditional methods and methods based on deep learning for speech separation. This study provides a basic understanding and comprehensive knowledge of state-of-the-art researches in the area of speech separation and serves as a brief overview to new researchers.
C1 [Agrawal, Jharna; Gupta, Manish] GLA Univ, Dept Elect & Commun Engn, Mathura 281406, India.
   [Garg, Hitendra] GLA Univ, Dept Comp Engn & Applicat, Mathura 281406, India.
C3 GLA University; GLA University
RP Agrawal, J (corresponding author), GLA Univ, Dept Elect & Commun Engn, Mathura 281406, India.
EM jharna.agw@gmail.com
RI Agrawal, Jharna/HZJ-7791-2023; Garg, Hitendra/AAV-6756-2020; Agrawal,
   Jharna/IAQ-9322-2023
OI AGRAWAL, JHARNA/0000-0003-3606-1289
CR Abdali S, 2017, BIOMED SIGNAL PROCES, V36, P168, DOI 10.1016/j.bspc.2017.03.010
   Arango-Sanchez JA, 2022, ENHANCED CONV TASNET
   Awotunde JB, 2020, IEEE ACCESS, V8, P169568, DOI 10.1109/ACCESS.2020.3024077
   Boppidi PKR, 2020, IET CIRC DEVICE SYST, V14, P484, DOI 10.1049/iet-cds.2019.0420
   Bronkhorst AW, 2015, ATTEN PERCEPT PSYCHO, V77, P1465, DOI 10.3758/s13414-015-0882-9
   Browns GJ, 2005, SIG COM TEC, P371, DOI 10.1007/3-540-27489-8_16
   Cermak J., 2006, P IWAENC, V2006, P145
   Chen Z, 2014, 15 ANN C INT SPEECH
   Chen Z, 2017, IEEE TRANSP EL ASIA, P437, DOI 10.1109/ASRU.2017.8268969
   Chen Zhuo, 2017, Proc IEEE Int Conf Acoust Speech Signal Process, V2017, P246, DOI 10.1109/ICASSP.2017.7952155
   DeLiang Wang, 2008, Trends Amplif, V12, P332, DOI 10.1177/1084713808326455
   Erdogan H, 2015, INT CONF ACOUST SPEE, P708, DOI 10.1109/ICASSP.2015.7178061
   Ghahramani Z, 1995, ADV NEUR IN, V8
   Guo TW, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6968, DOI 10.1109/ICASSP39728.2021.9414423
   Hansen JHL, 2015, IEEE SIGNAL PROC MAG, V32, P74, DOI 10.1109/MSP.2015.2462851
   He WP, 2018, IEEE INT CONF ROBOT, P74
   Hershey J, 2006, ADV NEURAL INF PROCE, V19
   Hershey J. R., 2014, Deep unfolding: Model-based inspiration of novel deep architectures
   Hershey JR, 2016, INT CONF ACOUST SPEE, P31, DOI 10.1109/ICASSP.2016.7471631
   Hidri A, 2012, MULTICHANNEL SPEECH
   Hu GN, 2010, IEEE T AUDIO SPEECH, V18, P2067, DOI 10.1109/TASL.2010.2041110
   Hu K, 2013, IEEE T AUDIO SPEECH, V21, P120, DOI 10.1109/TASL.2012.2215591
   Huang K., 2022, arXiv
   Huang K-P, 2022, IMPROVING TRANSFERAB
   Huang P.-S., 2014, P ICASSP, DOI DOI 10.1109/ICASSP.2014.6853860
   Huang PS, 2015, IEEE-ACM T AUDIO SPE, V23, P2136, DOI 10.1109/TASLP.2015.2468583
   Huang Z, 2022, ICASSP 2022 2022 IEE
   Isik Y, 2016, INTERSPEECH, P545, DOI 10.21437/Interspeech.2016-1176
   Jafari I, 2010, P 13 AUSTR INT C SPE, P201
   Jan T, 2011, SPEECH COMMUN, V53, P524, DOI 10.1016/j.specom.2011.01.002
   Jesson J.K., 2011, Doing your literature review
   Jiang D, 2021, WIREL COMMUN MOB COM, V2021
   Joder Cyril, 2012, Latent Variable Analysis and Signal Separation. Proceedings 10th International Conference, LVA/ICA 2012, P322, DOI 10.1007/978-3-642-28551-6_40
   Kacur J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051888
   Kamm C, 1997, SPEECH COMMUN, V23, P263, DOI 10.1016/S0167-6393(97)00059-9
   Kammi S., 2015, SINGLE CHANNEL SPEEC
   Kwan C, 2008, IEEE IJCNN, P1644, DOI 10.1109/IJCNN.2008.4634018
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Lee J.-W., 2022, IEEE Access
   Li Y, 2021, NEUROCOMPUTING, V438, P63, DOI 10.1016/j.neucom.2021.01.052
   Liu JL, 2014, ADV INTELL SYST, V275, P43, DOI 10.1007/978-3-319-05951-8_5
   Lluis F, 2018, END TO END MUSIC SOU
   Lu G, 2015, MATH PROBL ENG, V2015
   Luo Y., 2021, END TO END SPEECH SE
   Luo Y, 2020, INT CONF ACOUST SPEE, P46, DOI [10.1109/icassp40776.2020.9054266, 10.1109/ICASSP40776.2020.9054266]
   Luo Y, 2019, IEEE-ACM T AUDIO SPE, V27, P1256, DOI 10.1109/TASLP.2019.2915167
   Luo Y, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P696, DOI 10.1109/ICASSP.2018.8462116
   Marti A, 2012, J ACOUST SOC AM, V131, P1529, DOI 10.1121/1.3675001
   McDermott JH, 2009, CURR BIOL, V19, pR1024, DOI 10.1016/j.cub.2009.09.005
   Moon S, 2020, J COMMUN NETW-S KOR, V22, P177, DOI 10.1109/JCN.2020.000012
   Mowlaee P, 2012, INT CONF ACOUST SPEE, P69, DOI 10.1109/ICASSP.2012.6287819
   Mowlaee P., 2010, THESIS AALBORG U AAL
   Nag NC, 2021, INT J COMPUTING DIGI
   Nakamura T, 2020, INT CONF ACOUST SPEE, P386, DOI [10.1109/icassp40776.2020.9053934, 10.1109/ICASSP40776.2020.9053934]
   Nandakumar M.M., 2014, 2014 IEEE National Conference on Communication, Signal Processing and Networking (NCCSN), P1
   Nassif AB, 2021, APPL SOFT COMPUT, V103, DOI 10.1016/j.asoc.2021.107141
   Ochiai T, 2019, INT CONF ACOUST SPEE, P6975, DOI 10.1109/ICASSP.2019.8683448
   Olsson RK, 2009, DTU INFORMATICS
   Parag P., 2017, 2017 IEEE Wireless Communications and Networking Conference (WCNC)
   Park J, 2018, SEPARATION INSTRUMEN
   Pedersen M.S., 2008, Springer Handbooks, P1065, DOI [DOI 10.1007/978-3-540-49127-952, DOI 10.1007/978-3-540-49127-9_52]
   Pedersen MS, 2008, IEEE T NEURAL NETWOR, V19, P475, DOI 10.1109/TNN.2007.911740
   Peng Zhang, 2021, ICCAI 2021: 2021 7th International Conference on Computing and Artificial Intelligence, P379, DOI 10.1145/3467707.3467764
   Pham T, 2015, PROCEEDINGS OF 2015 INTERNATIONAL CONFERENCE ON ORANGE TECHNOLOGIES (ICOT), P26, DOI 10.1109/ICOT.2015.7498486
   Qian YM, 2018, FRONT INFORM TECH EL, V19, P40, DOI 10.1631/FITEE.1700814
   Qin CX, 2018, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-018-0141-9
   Radfar MH, 2006, 2006 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1 AND 2, P572, DOI 10.1109/ISSPIT.2006.270866
   Radfar MH, 2007, SPEECH COMMUN, V49, P464, DOI 10.1016/j.specom.2007.04.007
   Ranjan S, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P1522
   Rennie SJ, 2010, IEEE SIGNAL PROC MAG, V27, P66, DOI 10.1109/MSP.2010.938081
   Rybach David, 2011, ASRU
   Salman Hussein M., 2021, Journal of Physics: Conference Series, V1804, DOI 10.1088/1742-6596/1804/1/012097
   Shi Z., 2019, FURCANET END TO END
   Song Y., 2018, P C N AM CHAPT ASS C, P175, DOI [DOI 10.18653/V1/N18-2028, 10.18653/v1/n18-2028]
   Souden M, 2013, IEEE T AUDIO SPEECH, V21, P1913, DOI 10.1109/TASL.2013.2263137
   Stark M, 2011, IEEE T AUDIO SPEECH, V19, P242, DOI 10.1109/TASL.2010.2047419
   Stoller D., 2018, P 19 INT SOC MUS INF, P334
   Subakan C, 2022, USING TRANSFORMERS S
   Subakan YC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P26, DOI 10.1109/ICASSP.2018.8461671
   Toroghi RM, 2012, SAPA SCALE C
   Venkatesan R, 2018, MULTIMED TOOLS APPL, V77, P20129, DOI 10.1007/s11042-017-5458-3
   Virtanen T, 2007, IEEE T AUDIO SPEECH, V15, P1066, DOI 10.1109/TASL.2006.885253
   Virtanen T, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P89
   Wang DL, 2018, IEEE-ACM T AUDIO SPE, V26, P1702, DOI 10.1109/TASLP.2018.2842159
   Wang F-L, 2022, DISENTANGLING IMPACT
   Wang L, 2021, SCI PROGRAMMING-NETH, V2021
   Wang YX, 2014, IEEE-ACM T AUDIO SPE, V22, P1849, DOI 10.1109/TASLP.2014.2352935
   Wang ZQ, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1, DOI 10.1109/ICASSP.2018.8461639
   Wang ZQ, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P686, DOI 10.1109/ICASSP.2018.8462507
   Weng C, 2015, IEEE-ACM T AUDIO SPE, V23, P1670, DOI 10.1109/TASLP.2015.2444659
   Wiem B, 2016, CONTR ENG INF TECHN, P1, DOI DOI 10.1109/CEIT.2016.7929095
   Wiklund Karl, 2009, Canadian Acoustics, V37, P80
   Yang CH, 2020, INT CONF ACOUST SPEE, P3107, DOI [10.1109/icassp40776.2020.9053288, 10.1109/ICASSP40776.2020.9053288]
   Yi Luo, 2018, IEEE/ACM Transactions on Audio, Speech and Language Processing, V26, P787, DOI 10.1109/TASLP.2018.2795749
   Yilmaz Ö, 2004, IEEE T SIGNAL PROCES, V52, P1830, DOI 10.1109/TSP.2004.828896
   Yu Y., 2018, P IEEE 87 VEH TECHN, P1, DOI DOI 10.1109/ICME.2018.8486443
   Yuan CM, 2020, DISCRETE DYN NAT SOC, V2020, DOI 10.1155/2020/2196893
   Yul D, 2017, INT CONF ACOUST SPEE, P241, DOI 10.1109/ICASSP.2017.7952154
   Zeghidour N, 2021, IEEE-ACM T AUDIO SPE, V29, P2840, DOI 10.1109/TASLP.2021.3099291
   Zeremdini Jihen, 2015, Brain Inform, V2, P155
   Zhang LW, 2020, LECT NOTES COMPUT SC, V11961, P653, DOI 10.1007/978-3-030-37731-1_53
   Zhang L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10031167
   Zhang XL, 2017, IEEE-ACM T AUDIO SPE, V25, P1075, DOI 10.1109/TASLP.2017.2687104
   Zhao D, 2021, NEURAL PROCESS LETT, V53, P2243, DOI 10.1007/s11063-021-10432-x
NR 104
TC 5
Z9 5
U1 10
U2 64
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31035
EP 31067
DI 10.1007/s11042-023-14649-x
EA FEB 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000936292600001
DA 2024-07-18
ER

PT J
AU Changder, S
   Majumder, A
   Kundu, S
AF Changder, Suvamoy
   Majumder, Anandaprova
   Kundu, Sumana
TI An improved location mapping and cover synthesis based data hiding by
   model SSSP problem generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cover synthesis; Location mapping; Graphs; Security and privacy
   protection; Steganography; No modification based data hiding; SSSP
   problem
ID IMAGE STEGANOGRAPHY; SIGNIFICANT-BIT; ALGORITHM
AB Steganography is the art and science of hiding the secret message in a clandestine communication. Though steganography is an ancient process of data hiding, the methods are mostly cover modification based and they can't resist different statistical steganalysis attacks. So modern no-modification based steganography models have become hot topics for research. More over during this pandemic era teaching learning process is hugely digitized and significant amount of study materials are shared through the web. Considering the advantages of above mentioned scopes, in this paper we have proposed a two-fold secured cover synthesis technique with an intention of generating a simple cost effective method for transmission of low payload secret messages. The secret message bits are mapped in a digital file in the first fold. In the next fold mapped positions are hidden by synthesizing a model teaching-learning problem like finding the Single Source Shortest Path (SSSP) problem between a source and a destination vertex of a digraph. So to extract the message intruders need both the folds even if the existence of any communication is suspected and hence better security is achieved. We have tested and verified this novel algorithm in terms of various parameters and found satisfactory results in every case along with 100% accuracy in embedding success rate and extraction accuracy.
C1 [Changder, Suvamoy] Natl Inst Technol, Dept CSE, Durgapur, India.
   [Majumder, Anandaprova; Kundu, Sumana] Dr BC Roy Engn Coll, Dept CSE, Durgapur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Durgapur; Dr. B. C. Roy Engineering College
RP Changder, S (corresponding author), Natl Inst Technol, Dept CSE, Durgapur, India.
EM suvamoy@cse.nitdgp.ac.in; anandaprova.majumder@bcrec.ac.in;
   sumana.kundu@yahoo.co.in
OI Majumder, Anandaprova/0000-0003-1676-6206; KUNDU,
   SUMANA/0000-0003-0731-8284
CR Ahvanooey MT, 2018, IEEE ACCESS, V6, P65981, DOI 10.1109/ACCESS.2018.2866063
   Baagyere EY, 2020, IEEE ACCESS, V8, P100438, DOI 10.1109/ACCESS.2020.2997838
   Chan CK, 2001, ELECTRON LETT, V37, P1017, DOI 10.1049/el:20010714
   Changder S., 2010, 2nd International Conference on Computer Technology and Development (ICCTD 2010), P501, DOI 10.1109/ICCTD.2010.5645849
   Elshazly E, 2018, J SYST ENG ELECTRON, V29, P639, DOI 10.21629/JSEE.2018.03.21
   Hu DH, 2018, IEEE ACCESS, V6, P38303, DOI 10.1109/ACCESS.2018.2852771
   Kasapbasi MC, 2019, IEEE ACCESS, V7, P148495, DOI 10.1109/ACCESS.2019.2946807
   Kraetzer C, 2019, 13TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY (ARES 2018), DOI 10.1145/3230833.3233263
   Li B, 2015, IEEE T INF FOREN SEC, V10, P1905, DOI 10.1109/TIFS.2015.2434600
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu GJ, 2014, MULTIMEDIA SYST, V20, P227, DOI 10.1007/s00530-013-0313-5
   Liu J, 2020, IEEE ACCESS, V8, P60575, DOI 10.1109/ACCESS.2020.2983175
   Mohar B, 2020, J GRAPH THEOR, V95, P467, DOI 10.1002/jgt.22571
   Niu K, 2019, IEEE ACCESS, V7, P61523, DOI 10.1109/ACCESS.2019.2902464
   Qin JH, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8091394
   Qin JH, 2019, IEEE ACCESS, V7, P171372, DOI 10.1109/ACCESS.2019.2955452
   Roy R, 2014, INT CONF CONTEMP, P218, DOI 10.1109/IC3.2014.6897176
   Saad AS, 2021, IEEE ACCESS, V9, P16522, DOI 10.1109/ACCESS.2021.3050737
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Wang J, 2019, IEEE ACCESS, V7, P119393, DOI 10.1109/ACCESS.2019.2936614
   Wang KX, 2019, IEEE ACCESS, V7, P95665, DOI 10.1109/ACCESS.2019.2929123
   Wu DC, 2020, IEEE ACCESS, V8, P20459, DOI 10.1109/ACCESS.2020.2966889
   Wu N, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147720914257
   Xue YM, 2019, IEEE ACCESS, V7, P153724, DOI 10.1109/ACCESS.2019.2948946
   Ying KY, 2021, IEEE ACCESS, V9, P11705, DOI 10.1109/ACCESS.2021.3050004
   Zhang Z, 2020, TSINGHUA SCI TECHNOL, V25, P516, DOI 10.26599/TST.2019.9010027
   Zhou ZL, 2019, SOFT COMPUT, V23, P4927, DOI 10.1007/s00500-018-3151-8
NR 28
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29255
EP 29281
DI 10.1007/s11042-023-14681-x
EA FEB 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000936195100002
DA 2024-07-18
ER

PT J
AU Shu, HP
   Liu, JX
   Hua, YF
   Chen, JA
   Zhang, SS
   Su, M
   Luo, YL
AF Shu, Haiping
   Liu, Junxiu
   Hua, Yifan
   Chen, Jian
   Zhang, Shunsheng
   Su, Min
   Luo, Yuling
TI A grape disease identification and severity estimation system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crop disease identification; Disease severity estimation; Ensemble
   learning; Deep learning
ID ENSEMBLE
AB It is an important research of automatically identifying the type and severity level of crop diseases, which affects food production, disease control, and economic loss prediction. Deep learning-based methods have achieved successful application for disease identification. However, the method of only using a single network model to identify crop disease is simple and limited since networks vary in complexity and architecture. Furthermore, to measure the effectiveness of the measures taken, precisely quantifying the level of severity is necessary, instead of simply dividing the level into serious or not. In response to these problems, a novel system of disease identification and severity estimation is proposed in this paper. Firstly, an ensemble learning model is proposed to recognize crop diseases, which consider the comprehensive outputs of ResNet50, Inceptionv3, and DenseNet121. The relative majority voting is used as the ensemble classifier to obtain the final identification result. Second, a pixel-level segmentation model is proposed to precisely estimate disease severity after the disease is identified, which can track small changes in infected areas and obtain fine-grained resolutions. DeepLab architecture, encoder-decoder, and dilated convolution are integrated into the proposed segmentation model. Furthermore, an attention mechanism is applied to DeepLabv3+ to improve the performance of severity estimation, which can give more weight to disease areas to achieve more precise segmentation. A public grape disease database is used to verify the performance of the proposed system. Experimental results show that compared with an individual model and other existing studies, the proposed disease identification model has stronger robustness and higher identification accuracy. Furthermore, the proposed severity estimation model also achieves a lower severity error and a higher classification accuracy than baseline models of DeepLabv3+, PspNet, and SegNet.
C1 [Shu, Haiping; Liu, Junxiu; Hua, Yifan; Chen, Jian; Zhang, Shunsheng; Su, Min; Luo, Yuling] Guangxi Normal Univ, Sch Elect & Informat Engn, Guangxi Key Lab Brain inspired Comp & Intelligent, Guilin, Peoples R China.
C3 Guangxi Normal University
RP Liu, JX (corresponding author), Guangxi Normal Univ, Sch Elect & Informat Engn, Guangxi Key Lab Brain inspired Comp & Intelligent, Guilin, Peoples R China.
EM j.liu@ieee.org
FU National Natural Science Foundation of China [61976063]; Guangxi Natural
   Science Foundation [2022GXNSFFA035028]; Guangxi Normal University
   [2021JC006]; AI+Education research project of Guangxi Humanities Society
   Science Development Research Center [ZXZJ202205]; Innovation Project of
   Guangxi Graduate Education [YCSW2021093]
FX This research was partially supported by the National Natural Science
   Foundation of China under Grant 61976063, the Guangxi Natural Science
   Foundation under Grant 2022GXNSFFA035028, research fund of Guangxi
   Normal University under Grant 2021JC006, the AI+Education research
   project of Guangxi Humanities Society Science Development Research
   Center under Grant ZXZJ202205, and the Innovation Project of Guangxi
   Graduate Education under Grant YCSW2021093.
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bock CH, 2010, CRIT REV PLANT SCI, V29, P59, DOI 10.1080/07352681003617285
   Cruz A, 2019, COMPUT ELECTRON AGR, V157, P63, DOI 10.1016/j.compag.2018.12.028
   Esgario JGM., 2020, COMPUT ELECTRON AGR, V169, P1
   Fernández-Díaz M, 2020, ENG APPL ARTIF INTEL, V96, DOI 10.1016/j.engappai.2020.103976
   Hu GS, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2021.107023
   Hughes D., 2015, ABS151108060 CORR
   Jadhav S.B., 2019, IAES Int J Artif Intell Educ, V8, P328
   Kim TH, 2018, LECT NOTES COMPUT SC, V11207, P111, DOI 10.1007/978-3-030-01219-9_7
   Kingma D. P., 2014, arXiv
   Kranz J., 1988, Experimental techniques in plant disease epidemiology., P35
   Kumar A, 2017, IEEE J BIOMED HEALTH, V21, P31, DOI 10.1109/JBHI.2016.2635663
   Liang QK, 2019, COMPUT ELECTRON AGR, V157, P518, DOI 10.1016/j.compag.2019.01.034
   Liang X., 2020, INT C NEURAL INFORM, P168, DOI 10.1007/978-3-030-63820-7_19
   Liu B, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.01082
   Liu J., 2021, COMPUT METH PROG BIO, V203, P1
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shen JL, 2021, INFORM SCIENCES, V569, P469, DOI 10.1016/j.ins.2020.11.026
   Shi YX, 2021, IEEE T MULTIMEDIA, V23, P4376, DOI 10.1109/TMM.2020.3042068
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Tang Z, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105735
   Waghmare Harshal, 2016, 2016 3rd International Conference on Signal Processing and Integrated Networks (SPIN), P513, DOI 10.1109/SPIN.2016.7566749
   Wang CS, 2021, COMPUT ELECTRON AGR, V189, DOI 10.1016/j.compag.2021.106373
   Wang GQ, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/2373818
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yawen Wu, 2020, ICCBDC '20: Proceedings of the 2020 4th International Conference on Cloud and Big Data Computing, P27, DOI 10.1145/3416921.3416927
   Zeng QM, 2020, IEEE ACCESS, V8, P172882, DOI 10.1109/ACCESS.2020.3025196
   Zeng WH, 2020, COMPUT ELECTRON AGR, V172, DOI 10.1016/j.compag.2020.105341
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhu JH, 2020, MULTIMED TOOLS APPL, V79, P14539, DOI 10.1007/s11042-018-7092-0
NR 31
TC 1
Z9 1
U1 4
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23655
EP 23672
DI 10.1007/s11042-023-14755-w
EA FEB 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000936195100016
DA 2024-07-18
ER

PT J
AU Le, D
   Nguyen, L
AF Le, Duy
   Nguyen, Linh
TI Simple linear iterative clustering based low-cost pseudo-LiDAR for 3D
   object detection in autonomous driving
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LiDAR; 3D object detection; Simple linear iterative clustering;
   Superpixel; Autonomous driving
AB The paper presents a low-cost and LiDAR-free approach to efficiently detect 3D objects from stereo camera images, towards autonomous driving applications. It is first proposed to exploit the simple linear iterative clustering algorithm to segment stereo images into superpixel feature maps. The segmented superpixel maps are then used to estimate a depth map. By utilizing the depth map and stereo images, a 3D point cloud can be generated; and the 3D data is considered as pseudo-LiDAR representation as it is similar to measurements collected by a LiDAR sensor. The generated pseudo-LiDAR point cloud can ultimately be fed into any the state-of-the-art LiDAR based 3D object detection techniques to localize objects. By doing this, the proposed approach can effectively detect 3D objects by only employing low-cost stereo cameras, which can save tens of thousands of dollars on LiDAR costs from the existing LiDAR based methods. Effectiveness of the proposed algorithm was evaluated in the real-world KITTI dataset where the obtained results are about 1.33% better than those obtained by the benchmarking pseudo-LiDAR++ method (You et al. 2020).
C1 [Le, Duy] Australian Natl Univ, Coll Engn & Comp Sci, Canberra, ACT 0200, Australia.
   [Nguyen, Linh] Federat Univ Australia, Sch Engn Informat Technol & Phys Sci, Churchill, Vic 3842, Australia.
C3 Australian National University; Federation University Australia
RP Nguyen, L (corresponding author), Federat Univ Australia, Sch Engn Informat Technol & Phys Sci, Churchill, Vic 3842, Australia.
EM tran.le1@anu.edu.au; l.nguyen@federation.edu.au
RI Nguyen, Linh/HZJ-0934-2023
OI Nguyen, Linh/0000-0001-5360-886X
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2014, SPANISH COMPUTER GRA
   Arnold E, 2019, IEEE T INTELL TRANSP, V20, P3782, DOI 10.1109/TITS.2019.2892405
   Ban ZH, 2018, IEEE T IMAGE PROCESS, V27, P4105, DOI 10.1109/TIP.2018.2836306
   Cai YF, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3065438
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Chen X., 2017, PROC CVPR IEEE, V1, P3, DOI DOI 10.1109/CVPR.2017.691
   Chen Xiang., 2015, MULTIMEDIA SIGNAL PR, P1
   Chen XZ, 2018, IEEE T PATTERN ANAL, V40, P1259, DOI 10.1109/TPAMI.2017.2706685
   Concha A, 2014, IEEE INT CONF ROBOT, P365, DOI 10.1109/ICRA.2014.6906883
   Connolly C, 1997, IEEE T IMAGE PROCESS, V6, P1046, DOI 10.1109/83.597279
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Geiger A., 2012, CVPR
   Hsieh Cho-Jui, 2020, INT C LEARNING REPRE
   Hu HY, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3094622
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Ku J, 2018, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2018.8594049
   Li X, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3066542
   Lin CM, 2023, IEEE T NEUR NET LEAR, V34, P10812, DOI 10.1109/TNNLS.2022.3171553
   Ma C, 2019, IEEE T INSTRUM MEAS, V68, P38, DOI 10.1109/TIM.2018.2840598
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Meyer GP, 2019, IEEE COMPUT SOC CONF, P1230, DOI 10.1109/CVPRW.2019.00162
   Pang S, 2022, IEEE WINT CONF APPL, P3747, DOI 10.1109/WACV51458.2022.00380
   Pang S, 2020, IEEE INT C INT ROBOT, P10386, DOI 10.1109/IROS45743.2020.9341791
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Qian R, 2022, PATTERN RECOGN, V130, DOI 10.1016/j.patcog.2022.108796
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Stilgoe J., 2020, Who's driving innovation? New technologies and the Collaborative State, DOI [10.1007/978-3-030-32320-2, DOI 10.1007/978-3-030-32320-2]
   Wang Y, 2019, PROC CVPR IEEE, P8063, DOI 10.1109/CVPR.2019.00826
   Yan Z, 2020, IEEE INT C INT ROBOT, P10697, DOI 10.1109/IROS45743.2020.9341406
   Yang B, 2018, PROC CVPR IEEE, P7652, DOI 10.1109/CVPR.2018.00798
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 35
TC 0
Z9 0
U1 7
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 25253
EP 25269
DI 10.1007/s11042-023-14439-5
EA FEB 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000937945000006
DA 2024-07-18
ER

PT J
AU Wu, Y
   Shi, YC
   Shen, HY
   Tan, YY
   Wang, Y
AF Wu, Yun
   Shi, Yucheng
   Shen, Huaiyan
   Tan, Yaya
   Wang, Yu
TI Light-TBFNet: RGB-D salient detection based on a lightweight two-branch
   fusion strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RGB-D; Salient detection; Lightweight; Two-branch fusion strategy; Depth
   feature enhancement; Hybrid loss function
ID OBJECT DETECTION; NETWORK
AB Aiming at the current large model for salient detection tasks, which leads to a poor balance between performance and efficiency. Therefore, we propose a lightweight and accurate salient object detection framework that adopts a dual-stream coding network to extract the depth and RGB features. For the depth feature extraction stream, the depth feature enhancement module is designed to enhance the depth features and extract valid information before layer-by-layer feature fusion with the RGB feature extraction stream to solve the influence of low-quality depth features on the fused features. Then, from the perspective of lightweight, semantic information is used to locate salient regions, spatial detail information is used to optimize salient regions, the traditional top-down fusion of the U-shaped structure is abandoned, and the decoding network is innovatively divided into a spatial detail branch and semantic information branch. The first three layers of fusion features obtained by the coding network are used to extract spatial detail features, and the last three layers of fusion features are used to extract semantic features. After that, a two-branch fusion strategy is proposed for fusing two different level of features in the way of feature interaction and reconstruction. The framework avoids the traditional top-down fusion of U-shaped structures, which increases the computational complexity and decreases inference speed due to the large resolution of low-level features, and the high-level features may be gradually diluted in the top-down propagation process. Finally, by introducing Dice and SSIM loss functions, the hybrid loss function is proposed to supervise network training. Light-TBFNet performs favorably against state-of-the-art methods on six challenging RGB-D SOD datasets with much faster speed (30FPS for the input size of 384 x 384) and fewer parameters (3.79M).
C1 [Wu, Yun] Guizhou Univ, State Key Lab Publ Big Data, Guiyang 550025, Peoples R China.
   [Wu, Yun; Shi, Yucheng; Shen, Huaiyan; Tan, Yaya; Wang, Yu] Guizhou Univ, Coll Comp Sci & Technol, Guiyang 550025, Peoples R China.
C3 Guizhou University; Guizhou University
RP Shi, YC (corresponding author), Guizhou Univ, Coll Comp Sci & Technol, Guiyang 550025, Peoples R China.
EM wuyun_v@126.com; gs.ycshi19@gzu.edu.cn; gs.hyshen19@gzu.edu.cn;
   tanpangya17@163.com; gs.wangyu19@gzu.edu.cn
FU National Natural Science Foundation of China (NSFC) [62266011]
FX This work was partially supported by the National Natural Science
   Foundation of China (NSFC, No.62266011)
CR Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P4296, DOI 10.1109/TIP.2020.2968250
   Chen H, 2019, PATTERN RECOGN, V86, P376, DOI 10.1016/j.patcog.2018.08.007
   Chen JT, 2021, IEEE ACM T COMPUT BI, V18, P103, DOI 10.1109/TCBB.2020.2991173
   Chen Q, 2021, AAAI CONF ARTIF INTE, V35, P1063
   Chen TT, 2022, IEEE J BIOMED HEALTH, V26, P1411, DOI 10.1109/JBHI.2021.3100367
   Chen ZY, 2021, IEEE T IMAGE PROCESS, V30, P7012, DOI 10.1109/TIP.2020.3028289
   Cheng Y, 2014, IEEE INT CON MULTI
   Deng-Ping Fan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P275, DOI 10.1007/978-3-030-58610-2_17
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Feng RW, 2021, IEEE J BIOMED HEALTH, V25, P3700, DOI 10.1109/JBHI.2020.3040269
   Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312
   Gao HH, 2022, IEEE T COMPUT SOC SY, V9, P336, DOI 10.1109/TCSS.2021.3102591
   Gongyang Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P665, DOI 10.1007/978-3-030-58520-4_39
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Jin WD, 2021, IEEE T IMAGE PROCESS, V30, P3376, DOI 10.1109/TIP.2021.3060167
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li CY, 2021, IEEE T CYBERNETICS, V51, P88, DOI 10.1109/TCYB.2020.2969255
   Li GY, 2021, IEEE T IMAGE PROCESS, V30, P3528, DOI 10.1109/TIP.2021.3062689
   Li GY, 2020, IEEE T IMAGE PROCESS, V29, P4873, DOI 10.1109/TIP.2020.2976689
   Li LS, 2021, PROTEIN CELL, V12, P520, DOI 10.1007/s13238-020-00793-9
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Liu H., 2022, arXiv
   Liu L, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.5.053028
   Liu N, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4702, DOI 10.1109/ICCV48922.2021.00468
   Liu Z., 2022, ARXIV
   Liu ZY, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4481, DOI 10.1145/3474085.3475601
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Paszke A, 2019, ADV NEUR IN, V32
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Piao YR, 2019, IEEE I CONF COMP VIS, P7253, DOI 10.1109/ICCV.2019.00735
   Sun P, 2021, PROC CVPR IEEE, P1407, DOI 10.1109/CVPR46437.2021.00146
   Wang NN, 2019, IEEE ACCESS, V7, P55277, DOI 10.1109/ACCESS.2019.2913107
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao JS, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3419842
   Xiaoqi Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P646, DOI 10.1007/978-3-030-58542-6_39
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhang WH, 2021, IEEE INFOCOM SER, DOI 10.1109/INFOCOM42981.2021.9488834
   Zhao J, 2020, IEEE T FUZZY SYST, V28, P2287, DOI 10.1109/TFUZZ.2019.2930492
   Zhou T, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4661, DOI 10.1109/ICCV48922.2021.00464
NR 45
TC 1
Z9 1
U1 5
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26005
EP 26035
DI 10.1007/s11042-022-14230-y
EA JAN 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000913487000003
DA 2024-07-18
ER

PT J
AU Maurya, R
   Srivastava, A
   Srivastava, A
   Pathak, VK
   Dutta, MK
AF Maurya, Ritesh
   Srivastava, Arti
   Srivastava, Ashutosh
   Pathak, Vinay Kumar
   Dutta, Malay Kishore
TI Computer aided detection of mercury heavy metal intoxicated fish: an
   application of machine vision and artificial intelligence technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Center initialised K-means algorithm; Convolutional neural network; Deep
   learning; Heavy metal intoxicated fish; Transfer learning
ID BIOACCUMULATION; QUALITY; WATER; RIVER; HISTOPATHOLOGY; SEDIMENTS; GILLS
AB Heavy metal pollution in our aquatic bodies is a major health concern in the present scenario. The harmful effect of non-biodegradable toxic and trace metals is more serious than other contaminants. Fishes are more susceptible to various harmful impacts of these pollutants within the aquatic environment. Heavy metal toxicity from fish intake can cause health problems such as multi-organ damage, and serious diseases. Due to bioaccumulation through the food chain and direct absorption of these heavy metals, it is very important to monitor the quality of food fishes. Classical chemical-based methods for the assessment of fish quality are destructive and at the same time, they also require costly machines and expert manpower. In the present work, a machine learning-based methodology has been employed in which the suitable color and texture features have been identified and have been genetically optimised for the classification of heavy metal exposed and non-exposed fish using a machine learning classifier. The performance of the proposed method has also been tested using transfer learning-based approach. The best F1-score of 97.1% and 93.5% have been obtained in the case of the proposed genetically optimised color texture features-based approach and the transfer learning-based approach respectively. Thus, the proposed technique can be utilised to identify heavy metal-contaminated fish and to mitigate possible consequences. The proposed method can also be used for large-scale fish processing.
C1 [Maurya, Ritesh] Manipal Acad Higher Educ, Manipal Inst Technol Bengaluru, Dept Informat Technol, Manipal, India.
   [Srivastava, Arti; Srivastava, Ashutosh] Amity Univ, Amity Inst Biotechnol, Noida, UP, India.
   [Srivastava, Ashutosh] Amity Univ, Amity Inst Marine Sci & Technol, Noida, UP, India.
   [Pathak, Vinay Kumar] Chhatrapati Shahu Ji Maharaj Univ, Kanpur, UP, India.
   [Dutta, Malay Kishore] Dr APJ Abdul Kalam Tech Univ, Ctr Adv Studies, Lucknow, UP, India.
C3 Manipal Academy of Higher Education (MAHE); Amity University Noida;
   Amity University Noida; Dr. A.P.J. Abdul Kalam Technical University
   (AKTU); Centre for Advanced Studies (CAS, AKTU)
RP Dutta, MK (corresponding author), Dr APJ Abdul Kalam Tech Univ, Ctr Adv Studies, Lucknow, UP, India.
EM maurya123ritesh47@gmail.com; asrivastava@amity.edu;
   asrivastava4@amity.edu; vinay@vpathak.in; malaykishoredutta@gmail.com
RI Srivastava, Ashutosh/AAH-9708-2021
OI Srivastava, Ashutosh/0000-0001-7028-4596; MAURYA,
   RITESH/0000-0002-5664-0328; Dutta, Malay Kishore/0000-0003-2462-737X
CR Adebayo J, 2018, ADV NEUR IN, V31
   Amakdouf H, 2021, MULTIMED TOOLS APPL, V80, P3173, DOI 10.1007/s11042-020-09781-x
   Authman MMN, 2013, ENVIRON MONIT ASSESS, V185, P891, DOI 10.1007/s10661-012-2599-8
   Banwari A, 2022, ECOL INFORM, V69, DOI 10.1016/j.ecoinf.2022.101602
   Bose M.T. Jagannath, 2013, Biomedical & Pharmacology Journal, V6, P99
   Boyd CE., 2005, LC 50 CALCULATIONS H, P84
   Cheng JH, 2013, TRENDS FOOD SCI TECH, V34, P18, DOI 10.1016/j.tifs.2013.08.005
   Ching T, 2018, J R SOC INTERFACE, V15, DOI 10.1098/rsif.2017.0387
   Dhanakumar S, 2015, ECOTOX ENVIRON SAFE, V113, P145, DOI 10.1016/j.ecoenv.2014.11.032
   Djedjibegovic J, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-70205-9
   Dowlati M, 2013, J FOOD ENG, V119, P277, DOI 10.1016/j.jfoodeng.2013.05.023
   Dowlati M, 2012, TRAC-TREND ANAL CHEM, V40, P168, DOI 10.1016/j.trac.2012.07.011
   Dutta MK, 2016, J FOOD ENG, V177, P50, DOI 10.1016/j.jfoodeng.2015.12.018
   Ekoputris RO, 2018, MobileNet: Deteksi Objek pada Platform Mobile | by Rizqi Okta Ekoputris | Nodeflux | Medium
   Fazio F, 2014, J AQUAT ANIM HEALTH, V26, P278, DOI 10.1080/08997659.2014.938872
   Fu ZS, 2020, TOXICOL MECH METHOD, V30, P167, DOI 10.1080/15376516.2019.1701594
   Georgieva E, 2014, ACTA ZOOL BULGAR, V66, P277
   Hacon SD, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17155269
   Hashim Rohasliney, 2014, Tropical Life Sciences Research, V25, P21
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Huseen H.M., 2019, J. Phys.: Conf. Ser., V1294, DOI [10.1088/1742-6596/1294/6/062028, DOI 10.1088/1742-6596/1294/6/062028]
   Isangedighi I.A., 2019, Journal of Aquatic Science and Marine Biology, V2, P7
   Ishaq O, 2017, SLAS DISCOV, V22, P102, DOI 10.1177/1087057116667894
   Issac A, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103326
   Järup L, 2003, BRIT MED BULL, V68, P167, DOI 10.1093/bmb/ldg032
   Javed Mehjbeen, 2019, Proceedings of the Indian National Science Academy Part B Biological Sciences, V89, P389, DOI 10.1007/s40011-017-0875-7
   Joshi RC, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104829
   Joshi RC, 2018, 2018 4 INT C COMPUTI
   Kawser Ahmed Md, 2016, Springerplus, V5, P1697
   Lim JW, 2021, BIOSENS BIOELECTRON, V183, DOI 10.1016/j.bios.2021.113228
   Ling HF, 2020, MULTIMED TOOLS APPL, V79, P5595, DOI 10.1007/s11042-019-08422-2
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Maier D, 2015, WATER RES, V72, P127, DOI 10.1016/j.watres.2014.08.050
   Mathivanan R., 2004, Journal of Ecotoxicology & Environmental Monitoring, V14, P57
   Maurya PK, 2019, TOXICOL REP, V6, P472, DOI 10.1016/j.toxrep.2019.05.012
   Mehmood MA, 2019, ENVIRON MONIT ASSESS, V191, DOI 10.1007/s10661-019-7245-2
   Min S, 2017, BRIEF BIOINFORM, V18, P851, DOI 10.1093/bib/bbw068
   Poleksic V, 2010, ENVIRON TOXICOL CHEM, V29, P515, DOI 10.1002/etc.82
   Rehman K, 2018, J CELL BIOCHEM, V119, P157, DOI 10.1002/jcb.26234
   Ribeiro CAO, 2005, AQUAT TOXICOL, V74, P53, DOI 10.1016/j.aquatox.2005.04.008
   Roméo M, 1999, SCI TOTAL ENVIRON, V232, P169, DOI 10.1016/S0048-9697(99)00099-6
   Romero-Romero S, 2022, CHEMOSPHERE, V292, DOI 10.1016/j.chemosphere.2021.133445
   Santhakumar M, 2000, J ENVIRON BIOL, V21, P121
   De Vasconcellos ACS, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18157940
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Sengar N., 2018, 2018 4 INT C COMPUTA, P1, DOI [10.1109/CIACT.2018.8480265, DOI 10.1109/CIACT.2018.8480265]
   Sengar N, 2017, INT J FOOD PROP, V20, P2192, DOI 10.1080/10942912.2017.1368553
   Sfakianakis DG, 2015, ENVIRON RES, V137, P246, DOI 10.1016/j.envres.2014.12.014
   Sharma K, 2022, CHEMOSPHERE, V287, DOI 10.1016/j.chemosphere.2021.132103
   Shen JL, 2021, INFORM SCIENCES, V569, P469, DOI 10.1016/j.ins.2020.11.026
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh A, 2021, J FOOD PROCESS PRES, V45, DOI 10.1111/jfpp.15571
   Swain KK, 2020, PREP BIOCHEM BIOTECH, V50, P1000, DOI 10.1080/10826068.2020.1780611
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Taweel Abdulali K.A., 2012, Journal of Biological Sciences, V12, P138
   Vasanthi N., 2019, RES J LSC BIOIN PHAR, V5, P365, DOI [10.26479/2019.0503.30, DOI 10.26479/2019.0503.30]
   Vinodhini, 2009, INT J ENVIRON RES, DOI [10.22059/ijer.2009.35, DOI 10.22059/IJER.2009.35]
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Xia S, 2017, NEUROCOMPUTING, V228, P11, DOI 10.1016/j.neucom.2016.09.087
NR 59
TC 2
Z9 2
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20517
EP 20536
DI 10.1007/s11042-023-14358-5
EA JAN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000926402900003
DA 2024-07-18
ER

PT J
AU Yang, DX
   Zhao, HD
   Yu, KK
   Geng, LX
AF Yang, Dongxu
   Zhao, Hongdong
   Yu, Kuaikuai
   Geng, Lixin
TI NAUNet: lightweight retinal vessel segmentation network with nested
   connections and efficient attention
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinal vessel; Automatic segmentation; Nested connection; Efficient
   attention
ID NEURAL-NETWORK; BLOOD-VESSELS
AB The state of retinal vessels in fundus images is a reliable biomarker for many diseases, and the accurate segmentation of retinal vessels is important for the diagnosis of related diseases. To address the problem of many layers and high complexity of deep learningbased vascular segmentation network, this paper proposes a lightweight encoderdecoder network NAUNet by reasonably reducing the number of network layers. By introducing the DropBlock regularization strategy, the local semantic information can be discarded more effectively to motivate the network to learn more robust and effective features. Efficient attention module uses appropriate crosschannel interaction to capture richer global information. In the skip connection part, the nested connection strategy is adopted to effectively fuse the feature maps gathered from the intermediate decoder and the original feature maps from the encoder, which makes up for the semantic gap caused by direct simple connection. In addition, data augmentation is performed on the original image to improve the robustness and prevent the overfitting problem caused by insufficient data. A mixed loss function is proposed to solve the problem of class imbalance in vascular images. Finally, NAUNet was tested and achieved F1 scores of 80.92%/81.25%/74.86% and AUC values of 0.9831/0.9849/0.9841 on the DRIVE, STARE and CHASE_DB1 datasets, respectively.The number of parameters for the proposed method was only 2.66 M.
C1 [Yang, Dongxu; Zhao, Hongdong; Geng, Lixin] Hebei Univ Technol, Sch Elect & Informat Engn, Tianjin 300401, Peoples R China.
   [Yang, Dongxu; Zhao, Hongdong; Yu, Kuaikuai; Geng, Lixin] Sci & Technol Electopt Informat Secur Control Lab, Tianjin 300308, Peoples R China.
C3 Hebei University of Technology
RP Zhao, HD (corresponding author), Hebei Univ Technol, Sch Elect & Informat Engn, Tianjin 300401, Peoples R China.; Zhao, HD (corresponding author), Sci & Technol Electopt Informat Secur Control Lab, Tianjin 300308, Peoples R China.
EM tonshy@163.com; zhaohd@hebut.edu.cn; kuaikuaihit@126.com;
   Lx.geng@foxmail.com
FU Science and Technology on Electro-Optical Information Security Control
   Laboratory; Tianjin Science and Technology Plan;  [2021JCJQLB055008]; 
   [21YDTPJC00050]
FX AcknowledgementsThis work was supported in part by the Science and
   Technology on Electro-Optical Information Security Control Laboratory
   (No. 2021JCJQLB055008) and Tianjin Science and Technology Plan
   (No.21YDTPJC00050).
CR Alom MZ, 2018, PREPRINT
   Ambati LS, 2020, ISSUES INF SYST, DOI [10.48009/4/iis2020103-113, DOI 10.48009/4/IIS2020103-113]
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   El-Gayar OmarF., 2020, BIG DATAS POTENTIAL, P104, DOI DOI 10.4018/978-1-5225-9687-5.CH005
   Faisal A, 2020, J SCI APPL TECHNOL, V4, P1, DOI DOI 10.35472/JSAT.V4I1.262
   Fan Z., 2019, PREPRINT
   Feng ST, 2020, NEUROCOMPUTING, V392, P268, DOI 10.1016/j.neucom.2018.10.098
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Ghiasi G, 2018, PREPRINT
   Guo S, 2019, INT J MED INFORM, V126, P105, DOI 10.1016/j.ijmedinf.2019.03.015
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Jin QG, 2019, KNOWL-BASED SYST, V178, P149, DOI 10.1016/j.knosys.2019.04.025
   Lam BSY, 2010, IEEE T MED IMAGING, V29, P1369, DOI 10.1109/TMI.2010.2043259
   Li LZ, 2020, IEEE WINT CONF APPL, P3645, DOI 10.1109/WACV45572.2020.9093621
   Li QL, 2016, IEEE T MED IMAGING, V35, P109, DOI 10.1109/TMI.2015.2457891
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Oliveira A, 2018, EXPERT SYST APPL, V112, P229, DOI 10.1016/j.eswa.2018.06.034
   Owen CG, 2009, INVEST OPHTH VIS SCI, V50, P2004, DOI 10.1167/iovs.08-3018
   Palanivel DA, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106439
   Rezaee K, 2017, APPL SOFT COMPUT, V52, P937, DOI 10.1016/j.asoc.2016.09.033
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saroj SK, 2020, COMPUT METH PROG BIO, V194, DOI 10.1016/j.cmpb.2020.105490
   Setiawan Agung W., 2020, 2020 International Seminar on Application for Technology of Information and Communication (iSemantic), P436, DOI 10.1109/iSemantic50169.2020.9234245
   Soares JVB, 2006, IEEE T MED IMAGING, V25, P1214, DOI 10.1109/TMI.2006.879967
   Soomro TA, 2019, EXPERT SYST APPL, V134, P36, DOI 10.1016/j.eswa.2019.05.029
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Tang XL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106353
   Vaswani A., 2017, P 31 ADV NEUR INF PR, V30, P1
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wu YC, 2020, NEURAL NETWORKS, V126, P153, DOI 10.1016/j.neunet.2020.02.018
   Xiang Y, 2014, PROCEEDINGS OF 2014 IEEE INTERNATIONAL CONFERENCE ON PROGRESS IN INFORMATICS AND COMPUTING (PIC), P316, DOI 10.1109/PIC.2014.6972349
   Yan ZQ, 2019, IEEE J BIOMED HEALTH, V23, P1427, DOI 10.1109/JBHI.2018.2872813
   Yan ZQ, 2018, IEEE T BIO-MED ENG, V65, P1912, DOI 10.1109/TBME.2018.2828137
   Zhang B, 2018, PREPRINT
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
NR 39
TC 3
Z9 3
U1 2
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 25357
EP 25379
DI 10.1007/s11042-022-14319-4
EA JAN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000909488200001
DA 2024-07-18
ER

PT J
AU Francese, R
   Attanasio, P
AF Francese, Rita
   Attanasio, Pasquale
TI Emotion detection for supporting depression screening
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion detection; Depression; User study
ID RECOGNITION; INVENTORY; MODEL
AB Depression is the most prevalent mental disorder in the world. One of the most adopted tools for depression screening is the Beck Depression Inventory-II (BDI-II) questionnaire. Patients may minimize or exaggerate their answers. Thus, to further examine the patient's mood while filling in the questionnaire, we propose a mobile application that captures the BDI-II patient's responses together with their images and speech. Deep learning techniques such as Convolutional Neural Networks analyze the patient's audio and image data. The application displays the correlation between the patient's emotional scores and DBI-II scores to the clinician at the end of the questionnaire, indicating the relationship between the patient's emotional state and the depression screening score. We conducted a preliminary evaluation involving clinicians and patients to assess (i) the acceptability of proposed application for use in clinics and (ii) the patient user experience. The participants were eight clinicians who tried the tool with 21 of their patients. The results seem to confirm the acceptability of the app in clinical practice.
C1 [Francese, Rita] Univ Salerno, Comp Sci Dept, Via Giovanni Paolo II 132, I-84084 Fisciano, SA, Italy.
   [Attanasio, Pasquale] IBM Italia SpA, Via G Porzio, I-80143 Naples, Italy.
C3 University of Salerno
RP Francese, R (corresponding author), Univ Salerno, Comp Sci Dept, Via Giovanni Paolo II 132, I-84084 Fisciano, SA, Italy.
EM francese@unisa.it; pasquale_attanasio@it.ibm.com
OI FRANCESE, Rita/0000-0002-6929-0056
CR Badshah AM, 2017, 2017 INTERNATIONAL CONFERENCE ON PLATFORM TECHNOLOGY AND SERVICE (PLATCON), P125
   Beck A.T., 1979, COGNITIVE THERAPY DE
   BECK AT, 1961, ARCH GEN PSYCHIAT, V4, P561, DOI 10.1001/archpsyc.1961.01710120031004
   Beck AT, 1996, Psychol Assess, DOI [10.1037/t00742-000, DOI 10.1037/T00742-000]
   Bertero D, 2017, INT CONF ACOUST SPEE, P5115, DOI 10.1109/ICASSP.2017.7953131
   cdc.gov, 2022, CDC DEPRESSION EVALU
   de Melo WC, 2019, IEEE IMAGE PROC, P4544, DOI [10.1109/icip.2019.8803467, 10.1109/ICIP.2019.8803467]
   Denecke K, 2021, IEEE T EMERG TOP COM, V9, P1170, DOI 10.1109/TETC.2020.2974478
   Deshpande M, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2017), P858, DOI 10.1109/ISS1.2017.8389299
   Ezz-Eldin M, 2021, IEEE ACCESS, V9, P19999, DOI 10.1109/ACCESS.2021.3054345
   FLINT AJ, 1993, J PSYCHIAT RES, V27, P309, DOI 10.1016/0022-3956(93)90041-Y
   Francese Rita, 2021, CHItaly '21: CHItaly 2021: 14th Biannual Conference of the Italian SIGCHI Chapter, DOI 10.1145/3464385.3464708
   Francese R, 2020, MULTIMED TOOLS APPL, V79, P35885, DOI 10.1007/s11042-020-09576-0
   Hamiditabar N, 2022, 2022 9 IRANIAN JOINT, P1, DOI [10.1109/CFIS54774.2022.9756429, DOI 10.1109/CFIS54774.2022.9756429]
   Hamilton DF, 2014, BONE JOINT J, V96B, P622, DOI 10.1302/0301-620X.96B5.32434
   Hauke J, 2011, QUAEST GEOGR, V30, P87, DOI 10.2478/v10117-011-0021-1
   Hautojrvi P., 1979, Experimentation in software engineering, V1ST, DOI [10.1007/978-3-642-81316-0, 10.1007/978-3-642-29044-2., DOI 10.1007/978-3-642-29044-2]
   He L, 2018, J BIOMED INFORM, V83, P103, DOI 10.1016/j.jbi.2018.05.007
   Jan A, 2018, IEEE T COGN DEV SYST, V10, P668, DOI 10.1109/TCDS.2017.2721552
   Korszun A, 2002, J ORAL PATHOL MED, V31, P615, DOI 10.1034/j.1600-0714.2002.00091.x
   Kowalska M., 2017, HDB COGNITION EMOTIO, P1, DOI [https://doi.org/10.1007/978-3-319-28099-8495-1, DOI 10.1002/0470013494.CH3, 10.1002/0470013494.ch3]
   Laflamme L, 2019, GLOBAL HEALTH ACTION, V12, DOI 10.1080/16549716.2019.1666695
   Lemey C, 2019, J MED INTERNET RES, V21, DOI 10.2196/10111
   Likforman-Sulem L, 2017, IEEE T HUM-MACH SYST, V47, P273, DOI 10.1109/THMS.2016.2635441
   Lu XY, 2021, FRONT BIOSCI-LANDMRK, V26, P1746, DOI 10.52586/5066
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   McPherson A, 2010, J PSYCHIATR MENT HLT, V17, P19, DOI 10.1111/j.1365-2850.2009.01469.x
   Morris RR, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.4167
   Mouchet-Mages S, 2022, SADNESS INTEGRAL PAR
   Mukaka MM, 2012, MALAWI MED J, V24, P69
   Mulay A, 2020, PROCEEDINGS OF THE 2020 FOURTH WORLD CONFERENCE ON SMART TRENDS IN SYSTEMS, SECURITY AND SUSTAINABILITY (WORLDS4 2020), P19, DOI [10.1109/worlds450073.2020.9210301, 10.1109/WorldS450073.2020.9210301]
   Nakamura R, 2018, 2018 IEEE LIFE SCIENCES CONFERENCE (LSC), P53, DOI 10.1109/LSC.2018.8572043
   Niu MY, 2023, IEEE T AFFECT COMPUT, V14, P294, DOI 10.1109/TAFFC.2020.3031345
   Pampouchidou A, 2017, IEEE ENG MED BIO, P1433, DOI 10.1109/EMBC.2017.8037103
   Parada-Cabaleiro E., 2019, LANG RESOUR EVAL, P1
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schrepp M., 2015, USER EXPERIENCE QUES
   Shi DM, 2021, INT CONF ASIAN LANG, P52, DOI 10.1109/IALP54817.2021.9675271
   Sumali B, 2019, 2019 58TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P1376, DOI [10.23919/sice.2019.8859798, 10.23919/SICE.2019.8859798]
   Tadalagi M, 2021, MED BIOL ENG COMPUT, V59, P1339, DOI 10.1007/s11517-021-02358-2
   Tariman JD, 2011, APPL NURS RES, V24, P53, DOI 10.1016/j.apnr.2009.04.003
   Tasnim M, 2019, LECT NOTES ARTIF INT, V11489, P472, DOI 10.1007/978-3-030-18305-9_47
   Torous J, 2017, TRANSL PSYCHIAT, V7, DOI 10.1038/tp.2017.25
   Valstar M., 2014, P 4 INT WORKSH AUD V, P3, DOI 10.1145/2661806.2661807
   Verde L, 2021, PROC INT C TOOLS ART, P330, DOI 10.1109/ICTAI52525.2021.00054
   who.int, 2017, WHO WORLD HLTH DAY 2
   Yang L, 2019, 2019 8TH INTERNATIONAL CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION WORKSHOPS AND DEMOS (ACIIW), P26, DOI [10.1109/aciiw.2019.8925288, 10.1109/ACIIW.2019.8925288]
   Zhou XZ, 2020, IEEE T AFFECT COMPUT, V11, P542, DOI 10.1109/TAFFC.2018.2828819
NR 48
TC 1
Z9 1
U1 4
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 12771
EP 12795
DI 10.1007/s11042-022-14290-0
EA DEC 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000900833900001
PM 36570729
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Kumari, C
   Mustafi, A
AF Kumari, Chandana
   Mustafi, Abhijit
TI CTMFSO algorithm-based efficient color image segmentation by fuzzy order
   entropy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Objective function; Color image segmentation; Optimal threshold
   selection; Fuzzy order entropy (FOE); Chaotic tent map function-based
   sailfish optimization (CTMFSO)
AB Identifying the object on the image or identifying disparate objects or regions independently is the major goal of Image Analysis (IA). Image Segmentation (IS) is implemented extensively in Image Processing (IP) as well as object recognition. In the instance of color images, segmentation is more intricate. To find the optimum Threshold Values (TV) aimed at segmenting an image, disparate techniques are used. The technique encompasses poor PSNR together with higher Execution Time (ET). This research method proposed Chaotic Tent Map function-based Sailfish Optimization (CTMFSO) algorithm-centered color IS by means of considering the proposed Fuzzy Order Entropy (FOE) as the Objective Function (OF) for solving that issue. The proposed work sets the "OF' via FOE. Next, the proposed CTMFSO selects the optimal TV. After that, the image is segmented via the chosen TV. The CTMFSO's performance is compared with the conventional research algorithms rounded on the Structural Similarity Index (SSIM), Peak signal to noises ratio (PSNR), ET, together with fitness vs iteration. The proposed CTMFSO centered color IS attains better performance compared to the prevailing algorithms. Therefore, it proved the proposed work's performance.
C1 [Kumari, Chandana; Mustafi, Abhijit] Birla Inst Technol, Dept Comp Sci & Engn, Mesra, India.
C3 Birla Institute of Technology Mesra
RP Kumari, C (corresponding author), Birla Inst Technol, Dept Comp Sci & Engn, Mesra, India.
EM chandana.jsr@gmail.com; abhijit@bitmesra.ac.in
OI , Chandana Kumari/0000-0002-7808-7594
CR Abd El Aziz M, 2018, STUD COMPUT INTELL, V730, P23, DOI 10.1007/978-3-319-63754-9_2
   Ahmadi M, 2019, MULTIMED TOOLS APPL, V78, P23003, DOI 10.1007/s11042-019-7515-6
   Bao XL, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11050716
   Bhandari AK, 2020, NEURAL COMPUT APPL, V32, P4583, DOI 10.1007/s00521-018-3771-z
   Dhanachandra N., 2017, Int J Appl Eng Res, V12, P10458
   Farshi TR, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113233
   He LF, 2017, NEUROCOMPUTING, V240, P152, DOI 10.1016/j.neucom.2017.02.040
   Houssein EH, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114159
   Jia HM, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091134
   Jia HM, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11080942
   Jia HM, 2019, IEEE ACCESS, V7, P44903, DOI 10.1109/ACCESS.2019.2908653
   Jia HM, 2019, IEEE ACCESS, V7, P44097, DOI 10.1109/ACCESS.2019.2908718
   Resma KPB, 2021, J KING SAUD UNIV-COM, V33, P528, DOI 10.1016/j.jksuci.2018.04.007
   Song SH, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21040398
   Tuba E, 2017, 2017 14TH INTERNATIONAL CONFERENCE ON ENGINEERING OF MODERN ELECTRIC SYSTEMS (EMES), P240, DOI 10.1109/EMES.2017.7980424
   Upadhyay P, 2021, J AMB INTEL HUM COMP, V12, P1081, DOI 10.1007/s12652-020-02143-3
   Xing ZK, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105570
   Xing ZK, 2020, MULTIMED TOOLS APPL, V79, P1137, DOI 10.1007/s11042-019-08229-1
   Yan ZP, 2021, IEEE ACCESS, V9, P41294, DOI 10.1109/ACCESS.2020.3005452
   Yan ZP, 2020, MULTIMED TOOLS APPL, V79, P32415, DOI 10.1007/s11042-020-09664-1
NR 20
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 DEC 14
PY 2022
DI 10.1007/s11042-022-14286-w
EA DEC 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7B4RR
UT WOS:000899122900001
DA 2024-07-18
ER

PT J
AU Kaur, G
   Rana, PS
   Arora, V
AF Kaur, Gurinderjeet
   Rana, Prashant Singh
   Arora, Vinay
TI Extracting Radiomic features from pre-operative and segmented MRI scans
   improved survival prognosis of glioblastoma Multiforme patients through
   machine learning: a retrospective study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D magnetic resonance imaging; Convolutional neural network; Deep
   supervised UNet; Tumor subregion segmentation; Radiomics; Survival
   prediction; BraTS
ID BRAIN-TUMOR SEGMENTATION; GLIOMA; IMPACT
AB The combination of radiomics and artificial intelligence has emerged as a strong technique for building predictive models in radiology. This study aims to address the clinically important issue of whether a radiomic profile can predict the overall survival (OS) time of glioblastoma multiforme (GBM) patients having gross tumor resection (GTR) through pre-operative structural magnetic resonance imaging (MRI) scans. A retrospective analysis was made using data of glioma patients made publicly available by the University of Pennsylvania. The radiomic characteristics were extracted from pre-operative structural multiparametric MRI (mpMRI) sequences after pre-processing and 3D segmentation using deep learning (DL). After removing irrelevant features, regression models based on machine learning (ML) were developed by considering selected features to predict the OS time of GBM patients within a period of days only. The patients were divided into three survivor groups depending on their projected survival time. To validate the significance of the selected feature set, statistical analysis was performed. As many as 494 patients were considered to improve survival prediction (SP) by using more effective feature extraction and selection techniques. The ridge regressor acquired the highest SpearmanR Rank correlation of 0.635 with an accuracy of 69%, the greatest of all the previous works for categorical predictions of such patients. The researchers in the past who used radiomic characteristics for the OS prognosis of GBM patients could yield limited results only. However, the current research work recorded an enhanced accuracy and SpearmanR rank for the three survivor classes of GBM patients using ML, feature selection, and radiomics. The significance of this work lies in the selection of patients with GTR and the extraction of radiomic characteristics through the use of radiomics and artificial intelligence.
C1 [Kaur, Gurinderjeet; Rana, Prashant Singh; Arora, Vinay] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Kaur, G (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM gkaur60_phd18@thapar.edu; prashant.singh@thapar.edu;
   vinay.arora@thapar.edu
RI Rana, Prashant Singh/AAE-1784-2019; Kaur, Gurinderjeet/AGC-8814-2022
OI Rana, Prashant Singh/0000-0002-0142-7925; Kaur,
   Gurinderjeet/0000-0003-0016-1544
CR Aftab K, 2022, J NEURO-ONCOL, V156, P217, DOI 10.1007/s11060-021-03933-1
   Agravat RR, 2021, LECT NOTES COMPUT SC, V12659, P215, DOI 10.1007/978-3-030-72087-2_19
   Akbar AS, 2021, LECT NOTES COMPUT SC, V12659, P374, DOI 10.1007/978-3-030-72087-2_33
   Ali MJ, 2021, LECT NOTES COMPUT SC, V12659, P189, DOI 10.1007/978-3-030-72087-2_17
   Anand VK, 2021, LECT NOTES COMPUT SC, V12659, P310, DOI 10.1007/978-3-030-72087-2_27
   Bakas S., 2018, arXiv
   Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117
   Ben Naceur M, 2018, COMPUT METH PROG BIO, V166, P39, DOI 10.1016/j.cmpb.2018.09.007
   Bennett IE, 2017, J NEURO-ONCOL, V131, P321, DOI 10.1007/s11060-016-2300-0
   Bhuyan HK, 2023, IEEE T ENG MANAGE, V70, P2732, DOI 10.1109/TEM.2021.3098463
   Bhuyan HK, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12776
   Bhuyan HK, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P477, DOI 10.1109/ICICCT.2018.8473206
   Bleeker FE, 2012, J NEURO-ONCOL, V108, P11, DOI 10.1007/s11060-011-0793-0
   Carmo D, 2021, LECT NOTES COMPUT SC, V12658, P424, DOI 10.1007/978-3-030-72084-1_38
   Cepeda S, 2021, CANCERS, V13, DOI 10.3390/cancers13205047
   Chambless LB, 2015, J NEURO-ONCOL, V121, P359, DOI 10.1007/s11060-014-1640-x
   Choi Y, 2021, EUR RADIOL, V31, P2084, DOI 10.1007/s00330-020-07335-1
   cicek Ozgtin, 2016, INT C MED IM COMP CO, P424, DOI DOI 10.1007/978-3-319-46723-8_49
   Clavreul A, 2021, J NEURO-ONCOL, V151, P113, DOI 10.1007/s11060-020-03666-7
   Czarnek N, 2017, J NEURO-ONCOL, V132, P55, DOI 10.1007/s11060-016-2359-7
   Dai CL, 2021, LECT NOTES COMPUT SC, V12658, P514, DOI 10.1007/978-3-030-72084-1_46
   De Barros A, 2019, J NEURO-ONCOL, V142, P489, DOI 10.1007/s11060-019-03120-3
   Ferlay J, 2010, INT J CANCER, V127, P2893, DOI 10.1002/ijc.25516
   Fu J, 2021, ADV RADIAT ONCOL, V6, DOI 10.1016/j.adro.2021.100746
   Fyllingen EH, 2021, ACTA NEUROCHIR, V163, P1895, DOI 10.1007/s00701-021-04802-6
   Gibson E, 2018, COMPUT METH PROG BIO, V158, P113, DOI 10.1016/j.cmpb.2018.01.025
   Gillies RJ, 2016, RADIOLOGY, V278, P563, DOI 10.1148/radiol.2015151169
   González SR, 2021, LECT NOTES COMPUT SC, V12659, P241, DOI 10.1007/978-3-030-72087-2_21
   Hamer PCD, 2019, J NEURO-ONCOL, V144, P313, DOI 10.1007/s11060-019-03229-5
   Han IS, 2021, LECT NOTES COMPUT SC, V12658, P194, DOI 10.1007/978-3-030-72084-1_18
   Henker C, 2019, ACTA NEUROCHIR, V161, P1723, DOI 10.1007/s00701-019-03966-6
   Isensee Fabian, 2018, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. Third International Workshop, BrainLes 2017. Held in Conjunction with MICCAI 2017. Revised Selected Papers: LNCS 10670, P287, DOI 10.1007/978-3-319-75238-9_25
   Jun W, 2021, LECT NOTES COMPUT SC, V12658, P183, DOI 10.1007/978-3-030-72084-1_17
   Kirby J., 2017, CANC IMAGING ARCH, V286, DOI [DOI 10.7937/K9/TCIA.2017.GJQ7R0EF, 10.1038/sdata.2017.117, DOI 10.1038/SDATA.2017.117]
   Kudulaiti N, 2021, BMC SURG, V21, DOI 10.1186/s12893-021-01233-z
   Li HC, 2019, COMPUT BIOL MED, V108, P150, DOI 10.1016/j.compbiomed.2019.03.014
   Liu L, 2021, POSTGRAD MED, V133, P265, DOI 10.1080/00325481.2020.1803666
   Liu LY, 2019, BRAIN IMAGING BEHAV, V13, P1333, DOI 10.1007/s11682-018-9949-2
   Lorenzo PR, 2019, COMPUT METH PROG BIO, V176, P135, DOI 10.1016/j.cmpb.2019.05.006
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Miron R, 2021, LECT NOTES COMPUT SC, V12659, P290, DOI 10.1007/978-3-030-72087-2_25
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nestler U, 2015, ACTA NEUROCHIR, V157, P179, DOI 10.1007/s00701-014-2271-x
   Ostrom QT, 2014, NEURO-ONCOLOGY, V16, P896, DOI 10.1093/neuonc/nou087
   Pang ES, 2021, LECT NOTES COMPUT SC, V12658, P318, DOI 10.1007/978-3-030-72084-1_29
   Parmar B, 2021, LECT NOTES COMPUT SC, V12659, P398, DOI 10.1007/978-3-030-72087-2_35
   Patel J, 2021, LECT NOTES COMPUT SC, V12659, P228, DOI 10.1007/978-3-030-72087-2_20
   Pei LM, 2021, LECT NOTES COMPUT SC, V12658, P367, DOI 10.1007/978-3-030-72084-1_33
   Pei LM, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-74419-9
   Russo C, 2021, LECT NOTES COMPUT SC, V12658, P295, DOI 10.1007/978-3-030-72084-1_27
   Selvapandian A, 2018, COMPUT METH PROG BIO, V166, P33, DOI 10.1016/j.cmpb.2018.09.006
   Sfifou F, 2021, ANN MED SURG, V69, DOI 10.1016/j.amsu.2021.102731
   Sharma A., 2020, J SCI RES, V64, P221, DOI DOI 10.37398/JSR.2020.640232
   Sharma N, 2010, J MED PHYS, V35, P3, DOI 10.4103/0971-6203.58777
   Soltaninejad M, 2021, LECT NOTES COMPUT SC, V12659, P30, DOI 10.1007/978-3-030-72087-2_3
   Soltaninejad M, 2018, COMPUT METH PROG BIO, V157, P69, DOI 10.1016/j.cmpb.2018.01.003
   Suter Y, 2020, CANCER IMAGING, V20, DOI 10.1186/s40644-020-00329-8
   van Griethuysen JJM, 2017, CANCER RES, V77, pE104, DOI 10.1158/0008-5472.CAN-17-0339
   Wang GT, 2018, LECT NOTES COMPUT SC, V10670, P178, DOI 10.1007/978-3-319-75238-9_16
   Whitmire P, 2020, BMC CANCER, V20, DOI 10.1186/s12885-020-06816-2
   Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI [10.1109/CSTIC.2018.8369274, 10.1007/s11263-019-01198-w]
   Zhao GJ, 2021, LECT NOTES COMPUT SC, V12658, P492, DOI 10.1007/978-3-030-72084-1_44
NR 62
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 30003
EP 30038
DI 10.1007/s11042-022-14223-x
EA DEC 2022
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000896363400004
DA 2024-07-18
ER

PT J
AU Bhausaheb, DP
   Kashyap, KL
AF Bhausaheb, Deshmukh Pramod
   Kashyap, Kanchan Lata
TI Detection and classification of breast cancer availing deep canid
   optimization based deep CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Histopathology image; Deer canid optimization based deep
   CNN; V-net architecture; Global best solution
ID MODEL
AB Breast cancer is one of the substantial diseases that affect millions of females each year also the velocity of affected individuals is rising every year. Timely recognition of the illness is the only feasible solution to reduce its influence of the disease. Numerous techniques are invented by researchers in support of the determination of breast cancer and the usage of histopathology descriptions provided the auspicious solution. As an enhancement, in this research, a Deer-Canid based deep CNN is implemented by means of the histopathology images used for the detection of breast cancer through the taxonomy of benign, malignant, and normal regions. The segmentation of the histopathology images is performed using the V-net architecture that segments the image without losing its originality. The primary involvement of the research relies on the Deer-Canid optimization that helps in attaining the global best solution and effectively minimizes the time taken for the classification. The superiority of the research is proved by measuring the values of accuracy, precision, recall, and f1 measure, and the proposed Deer Canid optimization-based deep CNN attained the values of 92.967%, 94.342%, 93.454%, 92.896%, which is more efficient.
C1 [Bhausaheb, Deshmukh Pramod; Kashyap, Kanchan Lata] VIT Univ, SCSE, Bhopal 466114, Madhya Pradesh, India.
C3 VIT Bhopal University
RP Bhausaheb, DP (corresponding author), VIT Univ, SCSE, Bhopal 466114, Madhya Pradesh, India.
EM pramod.deshmukh5@gmail.com; kanchan.k@vitbhopal.ac.in
RI Deshmukh, Pramod/R-9672-2016
OI Deshmukh, Pramod/0000-0002-6622-0749
CR Ahlawat S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123344
   [Anonymous], 2008, Rubins pathology: Clinicopathologic foundations of medicine
   Chen YW, 2020, KNOWL-BASED SYST, V187, DOI 10.1016/j.knosys.2019.06.032
   Das K, 2020, IEEE ACCESS, V8, P213502, DOI 10.1109/ACCESS.2020.3040106
   De Gregorio Giuseppe, 2021, Pattern Recognition. ICPR 2020 International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12661), P559, DOI 10.1007/978-3-030-68763-2_43
   Desai M., 2021, Clinical eHealth, V4, P1, DOI DOI 10.1016/J.CEH.2020.11.002
   Feng YQ, 2020, IEEE ACM T COMPUT BI, V17, P91, DOI 10.1109/TCBB.2018.2858763
   Gurcan Metin N, 2009, IEEE Rev Biomed Eng, V2, P147, DOI 10.1109/RBME.2009.2034865
   Hirra I, 2021, IEEE ACCESS, V9, P24273, DOI 10.1109/ACCESS.2021.3056516
   Li GL, 2021, IEEE ACCESS, V9, P79671, DOI 10.1109/ACCESS.2021.3084360
   Maan J, 2022, IJCST, V10, P53
   Mishra Saurav, 2022, Journal of Electronics, Electromedical Engineering, and Medical Informatics, V4, P1, DOI 10.35882/jeeemi.v4i1.1
   Nadimi-Shahraki MH, 2021, EXPERT SYST APPL, V166, DOI 10.1016/j.eswa.2020.113917
   Ning ZY, 2019, IEEE ACCESS, V7, P150910, DOI 10.1109/ACCESS.2019.2946478
   Qi Q, 2019, IEEE J BIOMED HEALTH, V23, P2108, DOI 10.1109/JBHI.2018.2885134
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sahoo KS, 2020, IEEE ACCESS, V8, P132502, DOI 10.1109/ACCESS.2020.3009733
   Sekaran K, 2020, MULTIMED TOOLS APPL, V79, P10233, DOI 10.1007/s11042-019-7419-5
   Smith RA, 2002, CA-CANCER J CLIN, V52, P8, DOI 10.3322/canjclin.52.1.8
   Tian MW, 2020, J CLEAN PROD, V249, DOI 10.1016/j.jclepro.2019.119414
   Yan R, 2020, METHODS, V173, P52, DOI 10.1016/j.ymeth.2019.06.014
   Zhang HB, 2020, INFORM SCIENCES, V539, P461, DOI 10.1016/j.ins.2020.05.080
NR 22
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18019
EP 18037
DI 10.1007/s11042-022-14268-y
EA NOV 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000889417700001
DA 2024-07-18
ER

PT J
AU Murillo-Escobar, MA
   Quintana-Ibarra, JA
   Cruz-Hernández, C
   López-Gutiérrez, RM
AF Angel Murillo-Escobar, Miguel
   Alfonso Quintana-Ibarra, Jose
   Cruz-Hernandez, Cesar
   Martha Lopez-Gutierrez, Rosa
TI Biosignal encryption algorithm based on Ushio chaotic map for e-health
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Encryption; Security; Biomedical signals; Telemedicine
ID COMMUNICATION SCHEME; IMAGE
AB In last years, chaos-based encryption algorithms have been proposed in the literature to provide information confidentiality in digital images, biometric systems, telemedicine, multiuser networks, among others. In e-health, the confidentiality of biomedical signals is required to avoid illegal activities such as identity theft, wrong medical prescription, fraud or extortion against patients or the healthcare entities. On the other hand, improve the randomness of the chaotic map can increase the randomness of the cryptograms and thus, increase the security of the whole cryptosystem. In this paper, we first propose to improve the randomness of five selected chaotic maps by using trigonometric (sine, cosine and tangent) and the exponential function combined with module one operation. Then, we use the monobit test of NIST 800-22 suite to determine the level of achieved randomness. Finally, we use the selected chaotic map in an encryption algorithm for clinical signals based on improved sequences of two Ushio maps and just one round of confusion-diffusion process. In experimental results, we use electrocardiogram (ECG), electroencephalogram (EEG), and blood pressure signals from PhysioBank ATM data base at different sampling frequency and records of 10 seconds. Based on the simulation results in MATLAB, the main findings are (1) the 2D Ushio map with exponential function and module one achieves the best randomness with 0.9760 in P_value; (2) the encryption scheme presents high robustness against known attacks such extreme sensitivity to plain biosignal and the 128-bit secret key, correlation between plain biosignal and cryptogram close to 0, autocorrelation of cryptogram close to 0, floating frequency of 82.4%, uniform histograms in cryptograms, robustness against noise and occlusion attacks, and high speed of encryption; (3) the cryptosystem can be implemented in (low-cost) limited processing systems such as microcontrollers for wireless body area networks (WBAN) applications in e-health; (4) the propose encryption approach can be used to transmit medical signals securely in e-health for monitoring or diagnosis of diseases.
C1 [Angel Murillo-Escobar, Miguel; Alfonso Quintana-Ibarra, Jose; Martha Lopez-Gutierrez, Rosa] Autonomous Univ Baja California UABC, Engn Architecture & Design Fac, Ensenada 22860, Baja California, Mexico.
   [Cruz-Hernandez, Cesar] Sci Res & Adv Studies Ctr Ensenada CICESE, Elect & Telecommun Dept, Ensenada 22860, Baja California, Mexico.
C3 CICESE - Centro de Investigacion Cientifica y de Educacion Superior de
   Ensenada
RP López-Gutiérrez, RM (corresponding author), Autonomous Univ Baja California UABC, Engn Architecture & Design Fac, Ensenada 22860, Baja California, Mexico.
EM murillo.miguel@uabc.edu.mx; alfonso.quintana@uabc.edu.mx;
   ccruz@cicese.mx; roslopez@uabc.edu.mx
FU CONACYT, Mexico [166654, A1-S-31628]
FX This work was supported by the CONACYT, Mexico under Research Grant
   166654 (A1-S-31628).
CR Al-Zubaidie M, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/3263902
   Algarni AD, 2021, MULTIMED TOOLS APPL, V80, P10679, DOI 10.1007/s11042-020-09369-5
   Bassham III LE, 2010, Sp 800-22 rev. 1a. a statistical test suite for random and pseudorandom number generators for cryptographic applications, DOI DOI 10.6028/NIST.SP.800-22R1A
   Belazi A, 2022, J INF SECUR APPL, V66, DOI 10.1016/j.jisa.2022.103131
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   HENON M, 1976, COMMUN MATH PHYS, V50, P69, DOI 10.1007/BF01608556
   Huang LQ, 2022, OPT COMMUN, V517, DOI 10.1016/j.optcom.2022.128365
   Jiang Q, 2017, COMPUT ELECTR ENG, V63, P182, DOI 10.1016/j.compeleceng.2017.03.016
   Ke G, 2019, MEASUREMENT, V135, P385, DOI 10.1016/j.measurement.2018.11.074
   Kenfack G., 2014, J. Biomedical Science and Engineering, V7, P368, DOI [DOI 10.1007/S10916-016-0433-5, 10.4236/jbise.2014.76039, DOI 10.4236/JBISE.2014.76039]
   Kiryanov A., 2014, REV MEX FIS, V60, P13
   Kocarev L, 2011, STUD COMPUT INTELL, V354, P1, DOI 10.1007/978-3-642-20542-2
   Kumar KBS, 2022, WIRELESS PERS COMMUN, V123, P3597, DOI 10.1007/s11277-021-09305-2
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Lin CF, 2012, ADV ELECT COMMERCE W, V148, DOI [10.1007/978-3-642-28655-1_23, DOI 10.1007/978-3-642-28655-1_23]
   Lin CF, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0049-6
   Lin CF, 2009, MED BIOL ENG COMPUT, V47, P757, DOI 10.1007/s11517-009-0458-8
   Lorenz E. N., 1993, The Essence of Chaos
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Méndez-Ramírez R, 2018, FRONT INFORM TECH EL, V19, P165, DOI 10.1631/FITEE.1601346
   Michel-Macarty JA, 2018, COMPUT METH PROG BIO, V162, P165, DOI 10.1016/j.cmpb.2018.05.021
   Murillo-Escobar MA, 2022, BIOMED SIGNAL PROCES, V78, DOI 10.1016/j.bspc.2022.104001
   Murillo-Escobar MA, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0698-3
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Pandey A, 2019, BIOCYBERN BIOMED ENG, V39, P282, DOI 10.1016/j.bbe.2018.11.012
   Physionet.org, 2016, PHYSIOBANK ATM
   Raeiatibanadkooki M, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0433-5
   Sajedi Hedieh, 2020, Smart Health, V15, P15, DOI 10.1016/j.smhl.2019.100104
   Sen SS, 2021, J BIOMED INFORM, V116, DOI 10.1016/j.jbi.2021.103731
   Soni M, 2022, COMPUT COMMUN, V194, P292, DOI 10.1016/j.comcom.2022.07.046
   Susanto A, 2016, INT C DATA SOFTWARE, P1, DOI [10.1109/ICODSE.2016.7936160, DOI 10.1109/ICODSE.2016.7936160]
   USHIO T, 1995, PHYS LETT A, V198, P14, DOI 10.1016/0375-9601(94)01015-M
   Wang JC, 2020, FUTURE GENER COMP SY, V110, P57, DOI 10.1016/j.future.2020.04.002
   Wolf A, 2014, QUANTIFYING CHAOS LY
NR 36
TC 3
Z9 3
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23373
EP 23399
DI 10.1007/s11042-022-14092-4
EA NOV 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000885231500002
DA 2024-07-18
ER

PT J
AU Li, ZX
   Wang, YL
   Peng, C
   Peng, Y
AF Li, Zi-Xin
   Wang, Yu-Long
   Peng, Chen
   Peng, Yan
TI Laplace dark channel attenuation-based single image defogging in ocean
   scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Laplace dark channel; Transmission value deviation; Image defogging;
   Ocean scenes
ID RESTORATION; REMOVAL
AB Single image defogging is of paramount importance for the perception and recognition tasks of maritime targets since fog can severely degrade the content and details of ocean images. This paper studies the less-touched defogging problem, namely, how to remove the fog in ocean scene images. The physical characteristics of ocean scenes are different from those of land scenes. Some existing methods can not work effectively when processing sea fog images, which are induced by transmission value deviation or atmospheric light misestimation. Motivated by this, a Laplace dark channel attenuation defogging method for sea fog images is proposed. Specifically, a Laplace function attenuation minimum channel is constructed to obtain the Laplace dark channel, which can reduce the transmission value deviation in different regions. Meanwhile, to avoid atmospheric light estimation being affected by the large areas of white objects in sea fog images, an atmospheric light estimation method based on V-component direct current (DC) coefficient block is proposed. Moreover, the glow effect, which is ignored by many defogging methods, is taken into account. A Gaussian function of the brightness component is constructed to suppress the glow-shaped halo effect in the defogged images. The GMSD, sigma, PSNR, and SSIM obtained by our method are 0.036, 0.805, 18.20, and 0.87, respectively. Experimental results show that the proposed defogging method, which effectively improves the poor defogging performance of most existing defogging methods in ocean scenes, can achieve favorable performance compared with the state-of-the-art defogging methods in both qualitative and quantitative comparisons.
C1 [Li, Zi-Xin; Wang, Yu-Long; Peng, Chen; Peng, Yan] Shanghai Univ, Sch Mechatron Engn & Automat, Shanghai 200444, Peoples R China.
   [Li, Zi-Xin; Wang, Yu-Long; Peng, Chen] Shanghai Univ, Shanghai Key Lab Power Stn Automat Technol, Shanghai 200444, Peoples R China.
C3 Shanghai University; Shanghai University
RP Wang, YL (corresponding author), Shanghai Univ, Sch Mechatron Engn & Automat, Shanghai 200444, Peoples R China.; Wang, YL (corresponding author), Shanghai Univ, Shanghai Key Lab Power Stn Automat Technol, Shanghai 200444, Peoples R China.
EM zixinli@shu.edu.cn; yulongwang@shu.edu.cn; c.peng@i.shu.edu.cn;
   pengyan@shu.edu.cn
RI liu, lin/JFK-3401-2023; Wang, Weiyi/JZC-7841-2024; Ding,
   Yang/JUV-4842-2023; Wang, Tianqi/JJD-7473-2023; zhou, han/JUV-0193-2023;
   Zhang, Yuyao/KEH-7175-2024; zhang, yimeng/JLL-7337-2023; Wang,
   Luyao/JLL-2001-2023; peng, yan/JCO-1763-2023; Yang, Mei/JNS-2225-2023;
   Zhang, Lijun/JEZ-7925-2023; Zhang, Xiaofeng/JMC-6060-2023; Zhao,
   Chunxia/KBB-4190-2024; Wang, Zixi/KEI-0077-2024; peng,
   chen/HHS-8720-2022; Li, Jiawei/JOJ-9277-2023; tong, li/KDO-7821-2024;
   qi, li/JFE-7167-2023; yi, li/KFR-6141-2024
OI Zhang, Xiaofeng/0000-0003-2738-3286; peng, chen/0000-0003-3652-2233; 
FU National Science Foundation of China [61873335, 61833011, 62103251];
   Project of Science and Technology Commission of Shanghai Municipality,
   China [20ZR1420200, 21SQBS01600, 22JC1401400, 19510750300, 21190780300];
   111 Project, China [D18003]; China Postdoctoral Science Foundation
   [2021M702075]
FX This work was supported in part by the National Science Foundation of
   China (Grant Nos. 61873335, 61833011, 62103251); the Project of Science
   and Technology Commission of Shanghai Municipality, China (Grant Nos.
   20ZR1420200, 21SQBS01600, 22JC1401400, 19510750300, 21190780300); the
   111 Project, China (Grant No. D18003); and the China Postdoctoral
   Science Foundation (Grant No. 2021M702075).
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Bui TM, 2018, IEEE T IMAGE PROCESS, V27, P999, DOI 10.1109/TIP.2017.2771158
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Changxiu Dai, 2021, 2021 International Conference on Applications and Techniques in Cyber Intelligence: Applications and Techniques in Cyber Intelligence (ATCI 2021). Lecture Notes on Data Engineering and Communications Technologies (81), P301, DOI 10.1007/978-3-030-79197-1_44
   Gao GX, 2022, MULTIMED TOOLS APPL, V81, P15349, DOI 10.1007/s11042-022-12276-6
   Guo F, 2020, NEUROCOMPUTING, V378, P9, DOI 10.1016/j.neucom.2019.09.094
   Guo JM, 2017, IEEE T IMAGE PROCESS, V26, P4217, DOI 10.1109/TIP.2017.2706526
   Guo TT, 2019, IEEE COMPUT SOC CONF, P2122, DOI 10.1109/CVPRW.2019.00265
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He LY, 2017, IEEE T IMAGE PROCESS, V26, P1063, DOI 10.1109/TIP.2016.2644267
   Hu HM, 2019, IEEE T IMAGE PROCESS, V28, P2882, DOI 10.1109/TIP.2019.2891901
   Huang SC, 2014, IEEE T CIRC SYST VID, V24, P1814, DOI 10.1109/TCSVT.2014.2317854
   Huang SC, 2013, ENG APPL ARTIF INTEL, V26, P1487, DOI 10.1016/j.engappai.2012.11.011
   Javaran TA, 2019, MULTIMED TOOLS APPL, V78, P22555, DOI 10.1007/s11042-019-7402-1
   Ju MY, 2021, IEEE T IMAGE PROCESS, V30, P2180, DOI 10.1109/TIP.2021.3050643
   Dhara SK, 2021, IEEE T CIRC SYST VID, V31, P2076, DOI 10.1109/TCSVT.2020.3007850
   Kapoor R, 2019, MULTIMED TOOLS APPL, V78, P23281, DOI 10.1007/s11042-019-7574-8
   Khan MF, 2014, DIGIT SIGNAL PROCESS, V25, P198, DOI 10.1016/j.dsp.2013.10.015
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li Y, 2015, IEEE I CONF COMP VIS, P226, DOI 10.1109/ICCV.2015.34
   Lu ZW, 2020, IEEE SIGNAL PROC LET, V27, P665, DOI 10.1109/LSP.2020.2985570
   Ma ZL, 2016, NEUROCOMPUTING, V173, P1257, DOI 10.1016/j.neucom.2015.08.084
   McCartney E. J., 1976, Optics of the atmosphere. Scattering by molecules and particles
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Naga Srinivasu P, 2021, BIOINSPIRED NEUROCOM, V903, DOI [10.1007/978-981-15-5495-7_1, DOI 10.1007/978-981-15-5495-7_1]
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Nawaz M, 2021, INT BHURBAN C APPL S, P545, DOI 10.1109/IBCAST51254.2021.9393238
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Shanmugavadivu P, 2014, OPT LASER TECHNOL, V57, P243, DOI 10.1016/j.optlastec.2013.07.013
   Shao YJ, 2020, PROC CVPR IEEE, P2805, DOI 10.1109/CVPR42600.2020.00288
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Wang JB, 2018, IEEE T CIRC SYST VID, V28, P2190, DOI 10.1109/TCSVT.2017.2728822
   Wang WC, 2020, MULTIMED TOOLS APPL, V79, P27185, DOI 10.1007/s11042-020-09380-w
   Xu Y, 2016, IEEE ACCESS, V4, P165, DOI 10.1109/ACCESS.2015.2511558
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   [杨燕 Yang Yan], 2019, [自动化学报, Acta Automatica Sinica], V45, P819
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P1975, DOI 10.1109/TCSVT.2019.2912145
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang Y, 2017, OCEAN ENG, V141, P53, DOI 10.1016/j.oceaneng.2017.06.022
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 45
TC 3
Z9 3
U1 6
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21535
EP 21559
DI 10.1007/s11042-022-14103-4
EA NOV 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000884646200001
DA 2024-07-18
ER

PT J
AU Peska, L
   Vomlelová, M
   Vesely, P
   Skrhák, V
   Lokoc, J
AF Peska, Ladislav
   Vomlelova, Marta
   Vesely, Patrik
   Skrhak, Vit
   Lokoc, Jakub
TI Evaluating a Bayesian-like relevance feedback model with text-to-image
   search initialization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia search; Known-item search; Bayesian learning; Deep features;
   Artificial user
ID STATISTICAL FRAMEWORK; VIDEO RETRIEVAL
AB Although interactive video retrieval systems often boost search effectiveness, their smart design and optimal usage remains a true challenge. Since verification of design choices or search strategies with real users is tedious and unwieldy task, research efforts in interactive video search area focus also on options for automatic evaluations. This paper contributes to the area with an analysis of artificial user models for relevance feedback based video retrieval systems. Using a state-of-the-art system SOMHunter utilizing the W2VV++ text-image search model, several studies were performed. First, a study without search guidelines was organized with 34 users trying to solve known-item search tasks in a simplified version of SOMHunter. The results of the study were thoroughly analyzed and its data were used to train several artificial user models simulating relevance feedback. The models were evaluated with respect to a second study, where 50 displays of images were annotated by real users. The most promising artificial user model wPCU was selected for simulations analyzing performance of relevance feedback based browsing with different strategies. In a third study, 17 real users achieved on average 70% success rate for a new set of challenging known-item search tasks, strictly following the recommended search strategy. Furthermore, a similar performance for the same set of tasks was predicted by the wPCU model trained with data from the first study. The results and future challenges are thoroughly discussed.
C1 [Peska, Ladislav; Vomlelova, Marta; Vesely, Patrik; Skrhak, Vit; Lokoc, Jakub] Charles Univ Prague, Fac Math & Phys, Prague, Czech Republic.
C3 Charles University Prague
RP Peska, L (corresponding author), Charles Univ Prague, Fac Math & Phys, Prague, Czech Republic.
EM peska@ksi.mff.cuni.cz; marta@ktiml.mff.cuni.cz; vesely-patrik@email.cz;
   Vitek.skrhak@seznam.cz; lokoc@ksi.mff.cuni.cz
RI Lokoč, Jakub/P-1216-2017; Peška, Ladislav/HTQ-1107-2023; Vomlelova,
   Marta/P-2331-2017
OI Peška, Ladislav/0000-0001-8082-4509; Vomlelova,
   Marta/0000-0001-9104-804X
FU Czech Science Foundation (GAC. R) [19-22071Y]; Charles University
   [SVV-260588]; Charles University Grant Agency (GA UK) [1310920]
FX This paper has been supported by Czech Science Foundation (GAC. R)
   project 19-22071Y, Charles University grant SVV-260588, and by Charles
   University Grant Agency (GA UK) project number 1310920.
CR Arora K., 2018, Handbook of Research on Advanced Concepts in Real-time Image and Video Processing, P28, DOI 10.4018/978-1-5225-2848-7.ch002
   Balcar S, 2022, USER MODEL USER-ADAP, V32, P685, DOI 10.1007/s11257-021-09311-w
   Bdiri T, 2015, STUD COMPUT INTELL, V607, P99, DOI 10.1007/978-3-319-19833-0_5
   Carbonell J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P335, DOI 10.1145/290941.291025
   Chauhan Sumika, 2021, 2021 International Conference on Intelligent Technologies (CONIT), DOI [10.1109/ICEPES52894.2021.9699655, 10.1109/CONIT51480.2021.9498358]
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   Ferecatu M, 2009, IEEE T PATTERN ANAL, V31, P1087, DOI 10.1109/TPAMI.2008.259
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Heller Silvan, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12573), P435, DOI 10.1007/978-3-030-67835-7_41
   Hezel N, 2021, INT C MULT MOD, P484, DOI DOI 10.1007/978-3-030-67835-7_49
   Horváth T, 2017, NAT COMPUT, V16, P441, DOI 10.1007/s11047-016-9540-y
   Jiaxin Wu, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12573), P391, DOI 10.1007/978-3-030-67835-7_34
   Khan Omar Shahbaz, 2020, Advances in Information Retrieval, 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12035), P495, DOI 10.1007/978-3-030-45439-5_33
   Kohonen T., 1998, Neurocomputing, V21, P1, DOI 10.1016/S0925-2312(98)00030-7
   Kratochvíl M, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4481, DOI 10.1145/3394171.3414542
   Kratochvíl M, 2020, LECT NOTES COMPUT SC, V11962, P790, DOI 10.1007/978-3-030-37734-2_71
   Li XR, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1786, DOI 10.1145/3343031.3350906
   Li ZC, 2020, INT J COMPUT VISION, V128, P2265, DOI 10.1007/s11263-020-01331-0
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Lokoc J, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2553, DOI 10.1145/3394171.3414002
   Lokoc J, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3445031
   Lokoc J, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1777, DOI 10.1145/3343031.3351046
   Lokoc J, 2018, LECT NOTES COMPUT SC, V10705, P419, DOI 10.1007/978-3-319-73600-6_44
   Lorigo L, 2008, J AM SOC INF SCI TEC, V59, P1041, DOI 10.1002/asi.20794
   Peska Ladislav, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12573), P467, DOI 10.1007/978-3-030-67835-7_46
   Nguyen PA, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3429457
   Radford A, 2021, PR MACH LEARN RES, V139
   Rossetto L, 2021, IEEE MULTIMEDIA, V28, P18, DOI 10.1109/MMUL.2021.3066779
   Rossetto L, 2021, IEEE T MULTIMEDIA, V23, P243, DOI 10.1109/TMM.2020.2980944
   Rossetto L, 2019, LECT NOTES COMPUT SC, V11295, P349, DOI 10.1007/978-3-030-05710-7_29
   Siu C., 2014, Proceedings of the Human Factors and Ergonomics Society, V58, P1119, DOI DOI 10.1177/1541931214581234
   Suditu N, 2012, P 21 ACM INT C INF K, P1323, DOI DOI 10.1145/2396761.2398435
   Suditu N, 2016, MULTIMED TOOLS APPL, V75, P6777, DOI 10.1007/s11042-015-2610-9
   Suditu N, 2011, IEEE I CONF COMP VIS, P2118, DOI 10.1109/ICCV.2011.6126487
   Trevor Hastie Robert Tibshirani JF, 2009, ELEMENTS STAT LEARNI, DOI [10.1007/978-0-387-84858-7, DOI 10.1007/978-0-387-84858-7]
   Xu P, 2021, IEEE T CIRC SYST VID, V31, P1995, DOI 10.1109/TCSVT.2020.3014491
   Zahálka J, 2021, IEEE T VIS COMPUT GR, V27, P422, DOI 10.1109/TVCG.2020.3030383
   Zahálka J, 2018, IEEE T MULTIMEDIA, V20, P687, DOI 10.1109/TMM.2017.2755986
   Zahálka J, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P231, DOI 10.1145/2733373.2806279
   Zhang YN, 2017, ICTIR'17: PROCEEDINGS OF THE 2017 ACM SIGIR INTERNATIONAL CONFERENCE THEORY OF INFORMATION RETRIEVAL, P193, DOI 10.1145/3121050.3121070
   Zhao Q, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P131, DOI 10.1145/2959100.2959150
NR 41
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22305
EP 22341
DI 10.1007/s11042-022-14046-w
EA NOV 2022
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000878461100002
DA 2024-07-18
ER

PT J
AU Kaur, N
   Jindal, N
   Singh, K
AF Kaur, Navneet
   Jindal, Neeru
   Singh, Kulbir
TI A deep learning framework for copy-move forgery detection in digital
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Copy-move forgery; Classification; Benchmark datasets;
   Geometrical attacks
ID LOCALIZATION
AB Digital images have become widespread in modern life, and they can be modified and produced using an inclusive range of software and hardware tools. Since, digital image forgery can be extremely damaging, thus, understanding the detection and classification of authentic and forged images is of great significance. Without diminishing the importance of other types of forgeries, copy-move forgery (CMF) can be considered among the most widely utilized forgeries because of its ease of implementation. Nowadays, deep learning-based approaches are considered up-to-date for the classification and detection of image forgery owing to their improved accuracy and automated feature extraction skills. A deep learning CMF detection framework is proposed in this paper, which classifies images as authentic or forged using a contrast-limited adaptive histogram equalization (CLAHE) and convolutional neural network (CNN). The CLAHE algorithm makes the hidden features of the image visible, as some of them are hard to detect in CMF. The effectiveness of proposed structure is appraised using benchmark datasets: GRIP, MICC-F2000, IMD and MICC-F220. In terms of various performance metrics, the experimental study demonstrates the effectiveness of the proposed approach among other approaches. Also, the robustness of the proposed technique is demonstrated against several geometrical attacks like scaling, noise addition, JPEG compression, and rotation.
C1 [Kaur, Navneet; Jindal, Neeru; Singh, Kulbir] Thapar Inst Engn & Technol, Elect & Commun Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Jindal, N (corresponding author), Thapar Inst Engn & Technol, Elect & Commun Engn Dept, Patiala, Punjab, India.
EM neeru.jindal@thapar.edu
RI KAUR, NAVNEET/HMP-0723-2023
OI , Navneet Kaur/0000-0001-9575-2982
CR Abd Warif NB, 2016, J NETW COMPUT APPL, V75, P259, DOI 10.1016/j.jnca.2016.09.008
   Abdalla Y, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101280
   Abidin ABZ, 2019, INT CONF RES INNOV, DOI [10.1109/icriis48246.2019.9073569, 10.1109/giots.2019.8766376]
   Agarwal R, 2020, MULTIMED TOOLS APPL, V79, P7355, DOI 10.1007/s11042-019-08495-z
   Al Azrak FM, 2020, MULTIMED TOOLS APPL, V79, P18221, DOI 10.1007/s11042-019-08162-3
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Chen HP, 2020, IEEE ACCESS, V8, P36863, DOI 10.1109/ACCESS.2020.2974804
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Elaskily MA, 2019, MULTIMED TOOLS APPL, V78, P15353, DOI 10.1007/s11042-018-6891-7
   Goel N, 2021, IET IMAGE PROCESS, V15, P656, DOI 10.1049/ipr2.12051
   Hegazi A, 2021, J KING SAUD UNIV-COM, V33, P1055, DOI 10.1016/j.jksuci.2019.07.007
   Kaur N, 2021, TURK J ELECTR ENG CO, V29, P561, DOI 10.3906/elk-2001-138
   Kaur N, 2020, MULTIMED TOOLS APPL, V79, P32037, DOI 10.1007/s11042-020-09275-w
   Liu L, 2018, INT J DIGIT CRIME FO, V10, P140, DOI 10.4018/IJDCF.2018100110
   Liu YQ, 2018, MULTIMED TOOLS APPL, V77, P18269, DOI 10.1007/s11042-017-5374-6
   Meena KB, 2020, MULTIMED TOOLS APPL, V79, P8197, DOI 10.1007/s11042-019-08343-0
   Ning X, 2021, IEEE T CIRC SYST VID, V31, P3391, DOI 10.1109/TCSVT.2020.3043026
   Ning X, 2021, NEUROCOMPUTING, V453, P801, DOI 10.1016/j.neucom.2020.05.106
   Pal KK, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1778, DOI 10.1109/RTEICT.2016.7808140
   Prakash CS, 2019, MULTIMED TOOLS APPL, V78, P23535, DOI 10.1007/s11042-019-7629-x
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Rao Y, 2016, IEEE INT WORKS INFOR
   Rodriguez-Ortega Y, 2021, J IMAGING, V7, DOI 10.3390/jimaging7030059
   Ruder S., 2016, ARXIV
   Tahaoglu G, 2021, MULTIMED TOOLS APPL, V80, P23419, DOI 10.1007/s11042-020-10241-9
   Tinnathi S, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102966
   Wang CY, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10120706
   Wang X., 2020, Advances in Neural information processing systems
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Zhang Z, 2018, J INF PROCESS SYST, V14, P6
   Zhong JL, 2020, IEEE T INF FOREN SEC, V15, P2134, DOI 10.1109/TIFS.2019.2957693
NR 34
TC 1
Z9 1
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 17741
EP 17768
DI 10.1007/s11042-022-14016-2
EA OCT 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000865911600003
DA 2024-07-18
ER

PT J
AU Singh, KK
   Jha, VK
AF Singh, Kishan Kumar
   Jha, Vijay Kumar
TI Security enhancement of the cloud paradigm using a novel optimized
   crypto mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optimization; Elapid model; Cryptosystem; Security; Data sharing; Cloud;
   Big data; Encryption
ID MEDICAL DATA; BLOCKCHAIN; ALGORITHM; WORKFLOW; SCHEME
AB Nowadays, medical enterprises are gradually attracted to store their data in the cloud paradigm and distribute the data between the authorized person due to the enormous growth of cloud computing and big data. However, the rapid growth of these systems has faced some crucial challenges such as data privacy and security. Presently, different cryptography techniques are used in a large amount of data processing and storage, but it is not suitable for the security of big data over cloud-based data transmission. Thus, this article presents the novel African Buffalo-based Elapid Crypto Model (AB-ECM) method for monitoring and securing the data while transferring it to the receiver. Here, the large amount of data from the cloud is compressed by the two-stage compression approach. Then, the system's security has been enhanced by the auditing phase; if the secret key of both auditing stages in the sender and receiver is the same, then only the data is decrypted. The execution of this secure process is done in the MATLAB Platform. The simulation consequences of the proposed system have been compared with the conventional methods in terms of confidential rate, data transfer rate, encryption time, resource usage, and decryption time. The comparison shows that the developed model has attained the finest security function over the existing techniques.
C1 [Singh, Kishan Kumar; Jha, Vijay Kumar] Birla Inst Technol, Dept Comp Sci & Engn, Ranchi 835215, Bihar, India.
C3 Birla Institute of Technology Mesra
RP Singh, KK (corresponding author), Birla Inst Technol, Dept Comp Sci & Engn, Ranchi 835215, Bihar, India.
EM kishansingh.1392@gmail.com; vkjha@bitmesra.ac.in
RI Jha, Vijay Kumar/JAZ-1682-2023
CR Abdulhamid SM, 2018, NEURAL COMPUT APPL, V29, P279, DOI 10.1007/s00521-016-2448-8
   Ahmad S, 2021, 2021 4 INT C COMPUTI, DOI [10.1109/ICCIS54243.2021.9676396, DOI 10.1109/ICCIS54243.2021.9676396]
   Ahmed N, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/6503299
   Alashhab Ziyad R., 2021, Journal of Electronic Science and Technology, P1, DOI 10.1016/j.jnlest.2020.100059
   Chinnasamy P, 2022, J AMB INTEL HUM COMP, V13, P1001, DOI 10.1007/s12652-021-02942-2
   Denis R, 2021, MULTIMED TOOLS APPL, V80, P21165, DOI 10.1007/s11042-021-10723-4
   Ehwerhemuepha L, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01153-7
   Elhoseny M, 2020, NEURAL COMPUT APPL, V32, P10979, DOI 10.1007/s00521-018-3801-x
   Jaleel A, 2020, IEEE ACCESS, V8, P132302, DOI 10.1109/ACCESS.2020.3009783
   Kumari A, 2020, IEEE ACCESS, V8, P107838, DOI 10.1109/ACCESS.2020.3001152
   Lahoura V, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11020241
   Lie WW, 2020, IEEE ACCESS, V8, P78265, DOI 10.1109/ACCESS.2020.2988563
   Mthunzi SN, 2020, FUTURE GENER COMP SY, V107, P620, DOI 10.1016/j.future.2019.11.013
   Muthavhine K, 2022, FUTURE INTERNET, V14, DOI 10.3390/fi14020055
   Niu SF, 2022, COMPUT COMMUN, V192, P33, DOI 10.1016/j.comcom.2022.05.018
   Panhalkar AR, 2022, J KING SAUD UNIV-COM, V34, P4763, DOI 10.1016/j.jksuci.2021.01.011
   Pravin A, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01563-0
   Raj BSS, 2022, WIRELESS PERS COMMUN, V125, P2413, DOI 10.1007/s11277-022-09666-2
   Rani DR, 2020, COMPUT COMMUN, V150, P799, DOI 10.1016/j.comcom.2019.11.048
   Rashid M., 2020, Internet of Things (IoT), P473, DOI DOI 10.1007/978-3-030-37468-6_25
   Sasubilli MK, 2021, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT 2021), P476, DOI 10.1109/ICICT50816.2021.9358709
   Setlur AR, 2020, J PARALLEL DISTR COM, V136, P14, DOI 10.1016/j.jpdc.2019.09.004
   Shi CH, 2021, MULTIMED TOOLS APPL, V80, P25773, DOI 10.1007/s11042-021-10896-y
   Sood SK, 2020, MULTIMED TOOLS APPL, V79, P10717, DOI 10.1007/s11042-019-08573-2
   Sun LF, 2020, IEEE ACCESS, V8, P101079, DOI 10.1109/ACCESS.2020.2997831
   Tahir M, 2021, CLUSTER COMPUT, V24, P739, DOI 10.1007/s10586-020-03157-4
   Tunio M.H., 2021, 2021 18 INT COMPUTER, P525, DOI DOI 10.1109/ICCWAMTIP53232.2021.9674124
   Vengala DVK, 2020, CLUSTER COMPUT, V23, P1683, DOI 10.1007/s10586-020-03114-1
   Wang J, 2015, IEEE T COMPUT, V64, P2545, DOI 10.1109/TC.2014.2366751
   Wang XY, 2022, IEEE T SERV COMPUT, V15, P710, DOI 10.1109/TSC.2019.2959775
   Wu BH, 2019, FUTURE GENER COMP SY, V94, P51, DOI 10.1016/j.future.2018.11.001
   Xu J, 2021, MOBILE NETW APPL, V26, P1475, DOI 10.1007/s11036-019-01484-4
   Xu XL, 2020, MULTIMED TOOLS APPL, V79, P9819, DOI 10.1007/s11042-019-07900-x
   Yang XD, 2020, IEEE ACCESS, V8, P45468, DOI 10.1109/ACCESS.2020.2976894
   Zhang XJ, 2020, IEEE ACCESS, V8, P54402, DOI 10.1109/ACCESS.2020.2981503
   Zhang Y, 2021, IEEE T CLOUD COMPUT, V9, P923, DOI 10.1109/TCC.2019.2908400
NR 36
TC 3
Z9 3
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 15983
EP 16007
DI 10.1007/s11042-022-13960-3
EA OCT 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000862219500002
DA 2024-07-18
ER

PT J
AU Awasthi, D
   Srivastava, VK
AF Awasthi, Divyanshu
   Srivastava, Vinay Kumar
TI Robust, imperceptible and optimized watermarking of DICOM image using
   Schur decomposition, LWT-DCT-SVD and its authentication using SURF
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Schur decomposition; Lifting wavelet transform (LWT); Discrete cosine
   transform (DCT); Singular value decomposition (SVD); Firefly
   optimization; SURF
ID DWT-SVD; LIFTING SCHEME; TRANSFORM; HYBRID; CONSTRUCTION; ALGORITHM;
   DOMAIN
AB In this proposed work, a dual image watermarking algorithm is used to protect the data against copyright violations. In this work, the DICOM image is used as a host image. Two watermark images used are the MNNIT logo and the personal data of the patient. This method utilizes the advantages of Schur decomposition, lifting wavelet transform (LWT), discrete cosine transform (DCT) and singular value decomposition (SVD). The scaling factor is a vital parameter of watermarking technique. The firefly optimization technique is used to get the optimized scaling factor. The Speeded-up robust features (SURF) are used for watermarking authentication. To evaluate the performance of the proposed algorithm, peak signal-to-noise ratio (PSNR), normalized correlation coefficient (NCC), and structural similarity index measurement (SSIM) are used. The proposed method is tested against various attacks such as Salt and Pepper noise, Gaussian noise, Gaussian low pass filter, Average filter, Median filter, Histogram equalization, Sharpening, Rotation and Region of interest filtering. The proposed algorithm shows a high level of robustness and imperceptibility. It is found that the features of the input host image and the watermarked image are matching correctly on applying the SURF technique.
C1 [Awasthi, Divyanshu; Srivastava, Vinay Kumar] Motilal Nehru Natl Inst Technol, Elect & Commun Engn Dept, Prayagraj 211004, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Awasthi, D (corresponding author), Motilal Nehru Natl Inst Technol, Elect & Commun Engn Dept, Prayagraj 211004, Uttar Pradesh, India.
EM divyanshuawasthi83@gmail.com; Vinay@mimitac.in
RI Srivastava, Vinay Kumar/AAL-2501-2021; awasthi, divyanshu/ABX-1965-2022
OI Srivastava, Vinay Kumar/0000-0002-7993-0993; awasthi,
   divyanshu/0000-0002-1764-772X
CR Abdulrahman AK, 2019, MULTIMED TOOLS APPL, V78, P17027, DOI 10.1007/s11042-018-7085-z
   Ahmaderaghi B, 2018, IEEE T COMPUT IMAG, V4, P46, DOI 10.1109/TCI.2018.2794065
   Amirgholipour SK., 2009, JDCTA, V3, P42, DOI DOI 10.4156/JDCTA.VOL3.ISSUE2.AMIRGHOLIPOUR
   Amrit P, 2022, COMPUT COMMUN, V188, P52, DOI 10.1016/j.comcom.2022.02.023
   Anand A, 2023, IEEE T DEPEND SECURE, V20, P859, DOI 10.1109/TDSC.2022.3144657
   Aslantas V, 2008, AEU-INT J ELECTRON C, V62, P386, DOI 10.1016/j.aeue.2007.02.010
   Awasthi D, 2022, MULTIMED TOOLS APPL, V81, P25075, DOI 10.1007/s11042-022-12456-4
   Bao P, 2005, IEEE T CIRC SYST VID, V15, P96, DOI 10.1109/TCSVT.2004.836745
   Bhatnagar G, 2008, 2008 FIRST INTERNATIONAL CONFERENCE ON THE APPLICATIONS OF DIGITAL INFORMATION AND WEB TECHNOLOGIES, VOLS 1 AND 2, P526, DOI 10.1109/ICADIWT.2008.4664404
   Chang TJ, 2019, MULTIMED TOOLS APPL, V78, P9169, DOI 10.1007/s11042-018-6505-4
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Dowling Jason, 2007, Digital Watermarking. Proceedings 6th International Workshop, IWDW 2007, P454
   Ernawan F, 2018, IEEE ACCESS, V6, P20464, DOI 10.1109/ACCESS.2018.2819424
   Furqan A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P638, DOI 10.1109/CICT.2015.74
   Hurrah NN, 2019, FUTURE GENER COMP SY, V94, P654, DOI 10.1016/j.future.2018.12.036
   Jane O, 2014, J APPL RES TECHNOL, V12, P750, DOI 10.1016/S1665-6423(14)70091-4
   Kang XB, 2018, MULTIMED TOOLS APPL, V77, P13197, DOI 10.1007/s11042-017-4941-1
   Khare P, 2021, J INTELL SYST, V30, P297, DOI 10.1515/jisys-2019-0046
   Khare P, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P88, DOI 10.1109/SPIN.2018.8474125
   Kumar A, 2022, MULTIMED TOOLS APPL, V81, P21417, DOI 10.1007/s11042-022-12550-7
   Laxmanika, 2022, MULTIMED TOOLS APPL, V81, P22001, DOI 10.1007/s11042-021-11246-8
   Liu JX, 2019, IEEE ACCESS, V7, P80849, DOI 10.1109/ACCESS.2019.2915596
   Liu XL, 2018, IEEE T CIRC SYST VID, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Nandi S, 2016, ADV INTELL SYST, V394, P69, DOI 10.1007/978-81-322-2656-7_7
   Priyank Khare, 2018, 2018 5 IEEE UTT, P1, DOI DOI 10.1109/UPCON.2018.8597025
   Rao VSV, 2012, 2012 STUD C ENG SYST, P1
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Thakkar F, 2017, TURK J ELECTR ENG CO, V25, P3273, DOI 10.3906/elk-1603-17
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Verma VS, 2015, EXPERT SYST APPL, V42, P8184, DOI 10.1016/j.eswa.2015.06.041
   Wang ZQ, 2007, LECT NOTES COMPUT SC, V4688, P307
   Yang XS, 2009, LECT NOTES COMPUT SC, V5792, P169, DOI 10.1007/978-3-642-04944-6_14
   Zear A, 2018, J INTELL SYST, V27, P5, DOI 10.1515/jisys-2016-0036
NR 36
TC 15
Z9 16
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16555
EP 16589
DI 10.1007/s11042-022-14002-8
EA SEP 2022
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000859866500006
PM 36185319
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Gupta, S
   Vishwakarma, DK
AF Gupta, Shaurya
   Vishwakarma, Dinesh Kumar
TI HISNet: a Human Image Segmentation Network aiding bokeh effect
   generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bokeh; depth effect; Depth estimation; Dice coefficient; Human
   segmentation; IOU score; Transfer learning
ID PORTRAIT SEGMENTATION
AB The bokeh effect in photography has gained unquestionable popularity since improvements in smartphone cameras, for this effect brings out the attention of the image onto the subject and enhances the overall quality of the photo. Generally, these effects are applicable via dual-lens cameras for auto-focusing onto the subject. However, smartphones with a single lens rely on software to generate such an effect. This paper proposes a deep learning pipeline to generate depth-aware segmentation maps in human images via segmentation and depth estimation networks. The given paper provides a concatenations-based decoder for segmentation applying and experimenting with features learned through state-of-the-art encoder architectures, further we form an encoding concatenation between two prominent encoders to provide an ensemble model for learning segments. Adding to the effect we use a prominent depth estimation architecture and combine it with our segmentation results to generate dept-aware segmentation maps for achieving photos with more focus on human subjects, where the out-of-focus regions appear to be blurred out. The methodology produces compelling bokeh effects, comparable with shots taken via a dual-lens mobile camera or DSLR. During the experimentations of human segmentation, some benchmark results are reported with our best-considered model. Training on Supervisely Persons dataset achieved an IOU score of 95.88%, whereas training the same network on the EG1800 dataset achieved a state-of-the-art IOU of 96.89%. The final segmentation model thus provided some very closely accurate segmentation maps suitable for our task.
C1 [Gupta, Shaurya; Vishwakarma, Dinesh Kumar] Delhi Technol Univ, Dept Informat Technol, Biometr Res Lab, Delhi, India.
C3 Delhi Technological University
RP Vishwakarma, DK (corresponding author), Delhi Technol Univ, Dept Informat Technol, Biometr Res Lab, Delhi, India.
EM shaurya62000@gmail.com; dinesh@dtu.ac.in
RI VISHWAKARMA, DINESH KUMAR/L-3815-2018
OI VISHWAKARMA, DINESH KUMAR/0000-0002-1026-0047
CR Alhashim I., 2018, High quality monocular depth estimation via transfer learning
   [Anonymous], 2017, SMARTP CAUS PHOT BOO
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chen JT, 2021, IEEE ACM T COMPUT BI, V18, P103, DOI 10.1109/TCBB.2020.2991173
   Chen JP, 2021, NAT PHOTONICS, V15, P570, DOI 10.1038/s41566-021-00828-5
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Fei-Fei L, 2009, J. Vis., V9, P1037, DOI [DOI 10.1167/9.8.1037, 10.1167/9.8.1037]
   Feng RW, 2022, MULTIMED TOOLS APPL, V81, P41511, DOI 10.1007/s11042-020-10482-8
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao HH, 2022, IEEE T COMPUT SOC SY, V9, P336, DOI 10.1109/TCSS.2021.3102591
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kirkland EJ, 2010, ADVANCED COMPUTING IN ELECTRON MICROSCOPY, SECOND ED, P199, DOI 10.1007/978-1-4419-6533-2_8
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Lee JH, 2019, PROC CVPR IEEE, P9721, DOI 10.1109/CVPR.2019.00996
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu K, 2018, IEEE ACCESS, V6, P23722, DOI 10.1109/ACCESS.2018.2817593
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Martinez M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185202
   Mehta S, 2019, PROC CVPR IEEE, P9182, DOI 10.1109/CVPR.2019.00941
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Park H, 2020, IEEE WINT CONF APPL, P2055, DOI 10.1109/WACV45572.2020.9093588
   Poudel R. P., 2018, ARXIV180504554
   Ranftl R, 2022, IEEE T PATTERN ANAL, V44, P1623, DOI 10.1109/TPAMI.2020.3019967
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shen XY, 2016, COMPUT GRAPH FORUM, V35, P93, DOI 10.1111/cgf.12814
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Xiao JS, 2023, WIREL NETW, V29, P1507, DOI 10.1007/s11276-021-02713-z
   Xiao JS, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3419842
   Xie EZ, 2021, ADV NEUR IN, V34
   Xu XY, 2018, LECT NOTES COMPUT SC, V11213, P36, DOI 10.1007/978-3-030-01240-3_3
   Yang KL, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051506
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Zhang JM, 2021, IEEE INT CONF COMP V, P1760, DOI 10.1109/ICCVW54120.2021.00202
   Zhang SH, 2019, COMPUT GRAPH-UK, V80, P104, DOI 10.1016/j.cag.2019.03.007
   Zhang T, 2019, LNCS, V11296
   Zhang YC, 2018, ICMLC 2020: 2020 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P145, DOI 10.1145/3383972.3383975
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 44
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12469
EP 12492
DI 10.1007/s11042-022-13900-1
EA SEP 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000858393000001
DA 2024-07-18
ER

PT J
AU Paredes-Velasco, M
   Velázquez-Iturbide, JA
   Gómez-Ríos, M
AF Paredes-Velasco, Maximiliano
   Angel Velazquez-Iturbide, J.
   Gomez-Rios, Monica
TI Augmented reality with algorithm animation and their effect on students'
   emotions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Algorithm animation; Augmented reality; Emotions; Dijkstra's algorithm
ID VISUALIZATION; ACHIEVEMENT; EDUCATION; PROGRAM; TIME
AB Algorithm animations are a resource that assists in learning algorithms by visually displaying the behavior of an algorithm at a higher level of abstraction than source code. On the other hand, augmented reality is a technology that allows extending visible reality in a mobile device, which can result in greater emotional well-being for the student. However, it is not clear how to integrate algorithm animations with augmented reality. The article makes two contributions to this concern. On the one hand, we describe an architecture that allows generating interactive algorithm animations, integrating them appropriately in the context of immersive augmented reality. This way the user can watch the source code of the algorithm, augmented with textual explanations, visualizations and animations of its behavior. We illustrate the use of the architecture by instantiating it to the well-known Dijkstra's algorithm, resulting in an augmented reality tool that generates text, 2D and 3D visualizations. On the other hand, the influence of the tool on the user's emotions has been studied by conducting an experience with face-to-face and online students. The results show that, with the joint use of augmented reality and visualizations, the students: experienced significantly more positive than negative emotions, experienced more agitation and stimulation than inactivity or calm, enjoyed as much as they expected, and their feeling of boredom decreased during the experience. However, students felt anxiety from the beginning and it increased with the use of augmented reality. The study also found that the face-to-face or online learning model influences emotions and learning outcomes with augmented reality.
C1 [Paredes-Velasco, Maximiliano; Angel Velazquez-Iturbide, J.] Rey Juan Carlos Univ, Dept Comp & Stat, C Tulipan S-N, Madrid 28933, Spain.
   [Gomez-Rios, Monica] Salesian Polytech Univ, Dept Syst Engn, Guayaquil, Ecuador.
C3 Universidad Rey Juan Carlos
RP Paredes-Velasco, M (corresponding author), Rey Juan Carlos Univ, Dept Comp & Stat, C Tulipan S-N, Madrid 28933, Spain.
EM maximiliano.paredes@urjc.es; angel.velazquez@urjc.es; mgomezr@ims.edu.ec
RI Paredes, Maximiliano/AAM-7011-2020; Paredes, Maximiliano/H-5557-2015
OI Paredes, Maximiliano/0000-0002-4555-3771
FU CRUE-CSIC agreement; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature.
CR Akçayir M, 2017, EDUC RES REV-NETH, V20, P1, DOI 10.1016/j.edurev.2016.11.002
   Amaguaña F, 2018, LECT NOTES COMPUT SC, V10850, P394, DOI 10.1007/978-3-319-95270-3_33
   Velázquez-Iturbide JA, 2021, IEEE GLOB ENG EDUC C, P1186, DOI 10.1109/EDUCON46332.2021.9453904
   Velázquez-Iturbide JA, 2019, PROCEEDINGS OF THE 2019 ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION (ITICSE '19), P464, DOI 10.1145/3304221.3319749
   Velázquez-Iturbide JA, 2017, IEEE T EDUC, V60, P238, DOI 10.1109/TE.2017.2648781
   [Anonymous], 2013, Computer Science Curricula 2013: Curriculum Guidelines for Undergraduate Degree Programs in Computer Science, DOI [DOI 10.1145/2534860, 10.1145/2534860]
   [Anonymous], 2012, P 43 ACM TECHNICAL S, DOI [10.1145/2157136.2157148, DOI 10.1145/2157136.2157148]
   Arguedas M, 2016, COMPUT HUM BEHAV, V63, P517, DOI 10.1016/j.chb.2016.05.068
   Atiq Z, 2018, ICER'18: PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH, P258, DOI 10.1145/3230977.3231014
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bacca J, 2014, EDUC TECHNOL SOC, V17, P133
   Beilock SL, 2010, P NATL ACAD SCI USA, V107, P1860, DOI 10.1073/pnas.0910967107
   Ibáñez MB, 2014, COMPUT EDUC, V71, P1, DOI 10.1016/j.compedu.2013.09.004
   Bosch Nigel, 2013, Artificial Intelligence in Education. Proceedings of 16th International Conference (AIED 2013): LNCS 7926, P11, DOI 10.1007/978-3-642-39112-5_2
   Brassard G., 1996, Fundamentals of Algorithmics
   CC2020 Task Force, 2020, Computing Curricula 2020: Paradigms for Global Computing Education, DOI [10.1145/3467967, DOI 10.1145/3467967]
   Choi HH, 2014, EDUC PSYCHOL REV, V26, P225, DOI 10.1007/s10648-014-9262-6
   Cleto Barbara, 2019, Interactivity, Game Creation, Design, Learning, and Innovation. 7th EAI International Conference, ArtsIT 2018, and 3rd EAI International Conference, DLI 2018, ICTCC 2018. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 265), P538, DOI 10.1007/978-3-030-06134-0_58
   COLBY BN, 1989, CONTEMP SOCIOL, V18, P957, DOI 10.2307/2074241
   Cormen TH, 2009, INTRO ALGORITHMSHE
   Crescenzi P, 2011, BRIT J EDUC TECHNOL, V42, pE145, DOI 10.1111/j.1467-8535.2011.01220.x
   Dass N, 2018, PROCEEDINGS OF CHINESE CHI 2018: SIXTH INTERNATIONAL SYMPOSIUM OF CHINESE CHI (CHINESE CHI 2018), P156, DOI 10.1145/3202667.3202695
   Dirin A, 2018, COMPUTERS, V7, DOI 10.3390/computers7020033
   Ebel G., 2006, Proceedings of the second international workshop on computing education research, P1, DOI DOI 10.1145/1151588.1151590
   ElSayed NAM, 2020, INT CONF INFORM COMM, P143, DOI 10.1109/ICICS49469.2020.239520
   Enström E, 2017, ACM T COMPUT EDUC, V17, DOI 10.1145/3018109
   Estapa A., 2015, Journal of STEM Education: Innovations and Research, V16, P40
   Fang-Chuan Ou Yang, 2019, 2019 8th International Congress on Advanced Applied Informatics (IIAI-AAI), P1055, DOI 10.1109/IIAI-AAI.2019.00224
   Fanselow MS, 2018, CURR OPIN BEHAV SCI, V19, P105, DOI 10.1016/j.cobeha.2017.12.013
   Farghally MF, 2017, PROCEEDINGS OF THE 2017 ACM SIGCSE TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE'17), P207, DOI 10.1145/3017680.3017756
   Figueiredo M, 2016, LECT NOTES COMPUT SC, V9739, P57, DOI 10.1007/978-3-319-40238-3_6
   Finch D, 2015, INT J MANAG EDUC, V13, P23, DOI 10.1016/j.ijme.2014.12.001
   Frenzel AC, 2009, J EDUC PSYCHOL, V101, P705, DOI 10.1037/a0014695
   Gal-Ezer J, 2016, COMPUT SCI EDUC, V26, P89, DOI 10.1080/08993408.2016.1171470
   Gardeli A, 2019, INT CONF GAMES VIRTU, P1, DOI 10.1109/vs-games.2019.8864603
   Glenn T, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376790
   Gloor PA, 1998, SOFTWARE VISUALIZATION, P145
   Gomez Rios Monica, 2021, 2021 IEEE Global Engineering Education Conference (EDUCON), P1635, DOI 10.1109/EDUCON46332.2021.9454149
   Haaranen L, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 2, P428, DOI 10.1109/ICSE.2015.175
   Harley JM, 2016, ETR&D-EDUC TECH RES, V64, P359, DOI 10.1007/s11423-015-9420-7
   Huang JM, 2015, ADV ENG SOFTW, V87, P43, DOI 10.1016/j.advengsoft.2015.04.014
   Hugues O, 2011, HANDBOOK OF AUGMENTED REALITY, P47, DOI 10.1007/978-1-4614-0064-6_2
   Hundhausen CD, 2002, J VISUAL LANG COMPUT, V13, P259, DOI 10.1006/S1045-926X(02)00028-9
   Ishkov A, 2015, PROCEDIA ENGINEER, V117, P148, DOI 10.1016/j.proeng.2015.08.251
   Iskrenovic-Momcilovic O, 2018, INT J ELEC ENG EDUC, V55, P324, DOI 10.1177/0020720918773975
   Kazanidis I, 2018, ADV INTELL SYST, V725, P850, DOI 10.1007/978-3-319-75175-7_83
   Khan T, 2019, ADV HUM-COMPUT INTER, V2019, DOI 10.1155/2019/7208494
   Kim J, 2019, PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019), P574, DOI 10.1145/3311927.3325335
   Kinnunen P., 2010, P 6 INT WORKSH COMP, P77, DOI DOI 10.1145/1839594.1839609
   Kleinberg J., 2006, Algorithm Design
   KLEINGINNA P R JR, 1981, Motivation and Emotion, V5, P345, DOI 10.1007/BF00992553
   Knörzer L, 2016, LEARN INSTR, V44, P97, DOI 10.1016/j.learninstruc.2016.04.002
   Kolikant Y.B.D., 2005, P ICER 05, P37, DOI [10.1145/1089786.1089790, DOI 10.1145/1089786.1089790]
   Krathwohl DR, 2002, THEOR PRACT, V41, P212, DOI 10.1207/s15430421tip4104_2
   Kye B., 2008, International Journal for Education Media and Technology, V2, P4
   Lacave C, 2020, COMPUT EDUC, V149, DOI 10.1016/j.compedu.2020.103817
   Lajoie SP, 2020, LEARN INSTR, V70, DOI 10.1016/j.learninstruc.2019.101272
   Lishinski A, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH (ICER 17), P30, DOI 10.1145/3105726.3106187
   Martin C, 2017, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON COMPUTER SUPPORTED EDUCATION (CSEDU), VOL 1, P162, DOI 10.5220/0006375801620172
   Myller N., 2009, ACM Transactions on Computing Education, V9, P1, DOI DOI 10.1145/1513593.1513600
   Naps T.L., 2002, ACM SIGCSE Bulletin, Volume, V35, P131, DOI DOI 10.1145/960568.782998
   Narman HS, 2020, P IEEE GLOBAL HUMANI, P1
   OpenDSA, 2016, DYNAMIC PROGRAMMING
   Paavilainen J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2493, DOI 10.1145/3025453.3025871
   Park B, 2015, COMPUT EDUC, V86, P30, DOI 10.1016/j.compedu.2015.02.016
   Peercy MM., 2020, Action in Teacher Education, DOI DOI 10.1080/01626620.2019.1675201
   Pekrun R, 2002, EDUC PSYCHOL-US, V37, P91, DOI 10.1207/S15326985EP3702_4
   Pekrun R., 2014, ED PRACTICES SERIES, V24, P1
   Pekrun R., 2007, Emotion in education, P13, DOI DOI 10.1016/B978-012372545-5/50003-4
   Poitras EG, 2019, BRIT J EDUC TECHNOL, V50, P3345, DOI 10.1111/bjet.12738
   Rowe AD, 2018, BEHAV SCI-BASEL, V8, DOI 10.3390/bs8020027
   Saade R.G., 2009, The Journal of Asynchronous Learning, V13, P57, DOI [10.24059/olj.v13i4.1648, DOI 10.24059/OLJ.V13I4.1648]
   Sahni Sartaj., 2005, Data Structures, Algorithms, and Applications in C++
   Sannikov S, 2015, PROCEDIA COMPUT SCI, V66, P720, DOI 10.1016/j.procs.2015.11.082
   Schez-Sobrino S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041518
   Shaffer C.A., 2010, ACM Trans. Comput. Educ., V10, P1, DOI DOI 10.1145/1821996.1821997
   Sidhu MS, 2017, TEM J, V6, P222, DOI 10.18421/TEM62-05
   Singh M, 2013, IEEE INTERNET COMPUT, V17, P66, DOI 10.1109/MIC.2013.107
   Sorva J, 2013, ACM T COMPUT EDUC, V13, DOI 10.1145/2490822
   Taherkhani A, 2012, COMPUT SCI EDUC, V22, P109, DOI 10.1080/08993408.2012.692917
   Tarjan R. E., 1987, Communications of the ACM, V30, P204, DOI 10.1145/214748.214752
   Teng CH, 2018, J EDUC COMPUT RES, V56, P254, DOI 10.1177/0735633117706109
   Um E.R., 2007, Proceedings of World Conference on Educational Multimedia, Hypermedia and Telecommunications, V2007, P4176
   Velazquez-Iturbide J. A., 2011, P 16 ANN C INN TECHN, P8, DOI DOI 10.1145/1999747.1999753
   Paoloni PV, 2014, ELECTRON J RES EDUC, V12, P671, DOI 10.14204/ejrep.34.14088
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Zhu HP, 2014, 2014 IEEE 17th International Conference on Computational Science and Engineering (CSE), P420, DOI 10.1109/CSE.2014.105
NR 87
TC 5
Z9 5
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11819
EP 11845
DI 10.1007/s11042-022-13679-1
EA SEP 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000852464000001
PM 36090153
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Jeong, Y
   Hwang, M
   Sung, W
AF Jeong, Yuna
   Hwang, Myunggwon
   Sung, Wonkyung
TI Training data selection based on dataset distillation for rapid
   deployment in machine-learning workflows
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Core-set; Training data; Data selection; Dataset distillation; Machine
   learning
AB Recently, nonlinear machine-learning models have been effectively applied to multimedia data, contributing greatly to various downstream tasks. However, large amounts of training data are required to properly train many parameters and achieve reasonable performance in nonlinear models. Using a large amount of data significantly increases time and cost, which are limited resources of model development and distribution processes. The goal of our study is to construct a core set that approximates the entire original dataset so that we can quickly observe performance changes caused by model redesign or parameter changes in machine learning deployment. The core set is mainly composed of informative samples with a high contribution to the train. We measure the contribution of the sample based on the dataset distillation and perform area-based sampling for generalization. The core set can be construct in a short time by measuring the learning contribution with only a small number of distilled images. The experimental results showed that our method selects more useful samples compared to random sampling.
C1 [Jeong, Yuna; Hwang, Myunggwon; Sung, Wonkyung] Korea Inst Sci & Technol Informat KISTI, AI Technol Res Ctr, Daejeon 34141, South Korea.
   [Hwang, Myunggwon; Sung, Wonkyung] Univ Sci & Technol UST, Daejeon, South Korea.
C3 University of Science & Technology (UST)
RP Hwang, M (corresponding author), Korea Inst Sci & Technol Informat KISTI, AI Technol Res Ctr, Daejeon 34141, South Korea.; Hwang, M (corresponding author), Univ Sci & Technol UST, Daejeon, South Korea.
EM jeongyuna@kisti.re.kr; mgh@kisti.re.kr; wksung@kisti.re.kr
FU Korea Institute of Science and Technology Information (KISTI)
FX This research was funded by Korea Institute of Science and Technology
   Information (KISTI).
CR AGARWAL P., 2005, COMBINATORIAL COMPUT, V52, P1
   Bermudez I, 2013, IEEE INFOCOM SER, P230
   Chang HS, 2017, ADV NEUR IN, V30
   Coleman C., 2020, INT C LEARNING REPRE
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534
   Fu W, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, P49, DOI 10.1145/3106237.3106256
   Har-Peled S, 2007, DISCRETE COMPUT GEOM, V37, P3, DOI 10.1007/s00454-006-1271-x
   Ho Qirong, 2013, Adv Neural Inf Process Syst, V2013, P1223
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Jeong Y, 2020, P 9 INT C SMART MEDI, DOI [10.1145/3426020.3426051, DOI 10.1145/3426020.3426051]
   Katharopoulos A, 2018, PR MACH LEARN RES, V80
   Kishida I, 2019, COMM COM INF SC, V1142, P179, DOI 10.1007/978-3-030-36808-1_20
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Lewis D. D., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P3
   Li Mu, 2014, USENIX OSDI, P583
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3
   Sener Ozan, 2018, INT C LEARN REPR ICL
   Settles B, 2008, P C EMP METH NAT LAN, P1070, DOI DOI 10.3115/1613715.1613855
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vodrahalli K., 2018, arXiv
   Wang T., 2018, ARXIV
   Yoo D, 2019, PROC CVPR IEEE, P93, DOI 10.1109/CVPR.2019.00018
NR 28
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 9855
EP 9870
DI 10.1007/s11042-022-13701-6
EA SEP 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000850023000001
DA 2024-07-18
ER

PT J
AU Zarraonandia, T
   Díaz, P
   Aedo, I
   Bellucci, A
AF Zarraonandia, Telmo
   Diaz, Paloma
   Aedo, Ignacio
   Bellucci, Andrea
TI Engaging educators in the ideation of scenarios for cross-reality
   game-based learning experiences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cross-reality; Digital game based learning; Prototyping
AB Cross-reality media technology creates alternate reality experiences in which the physical and the virtual world are interconnected and influence each other through a network of sensors and actuators. Despite technological advances, the landscape of cross-reality technology as an enabler of alternate reality educational experiences has not been explored yet. The technical expertise required to set up and program such mixed environments is too high to engage the problem owners (i.e. educational experts) in the design process and, hence, user-driven innovation remains challenging. In this paper we explore the co-creation of cross-reality experiences for educational games. We created a no-programming toolkit that provides a visual language and interface abstractions to quickly build prototypes of cross-reality interactions. The toolkit supports experience prototyping and allows designers to coproduce, with educational experts, meaningful scenarios while they create, try out and reconfigure their prototypes. We report on a workshop with 36 educators where the toolkit was used to ideate cross-reality games for education. We discuss use cases of game-based learning applications developed by the participants that follow different pedagogical strategies and combine different physical and virtual spaces and times. We outline implications for the design of cross-reality interactions in educational settings that trigger further research and technological developments.
C1 [Zarraonandia, Telmo; Diaz, Paloma; Aedo, Ignacio; Bellucci, Andrea] Univ Carlos III Madrid, Comp Sci Dept, DEI Lab, Avda Univ 30, Madrid 28911, Spain.
C3 Universidad Carlos III de Madrid
RP Zarraonandia, T (corresponding author), Univ Carlos III Madrid, Comp Sci Dept, DEI Lab, Avda Univ 30, Madrid 28911, Spain.
EM tzarraon@inf.uc3m.es; pdp@inf.uc3m.es; ia@ia.uc3m.es;
   abellucc@inf.uc3m.es
RI Bellucci, Andrea/L-6374-2014; Zarraonandia, Telmo/K-7177-2012
OI Bellucci, Andrea/0000-0003-4035-5271; Zarraonandia,
   Telmo/0000-0003-3574-0984; DIAZ PEREZ, MARIA PALOMA/0000-0002-9493-7739
FU CRUE-CSIC agreement; project sense2makeSense - Spanish Ministry of
   Science and Innovation [PID2019-109388GB-I00]; project CROSS-COLAB -
   Spanish State Research Agency [PGC2018-101884-B-I00]; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This work is supported by the projects sense2makeSense
   (PID2019-109388GB-I00) funded by the Spanish Ministry of Science and
   Innovation and CROSS-COLAB (PGC2018-101884-B-I00) funded by the Spanish
   State Research Agency.
CR Alvarez J., 2008, Serious games: advergaming, edugaming, training and more
   [Anonymous], 2007, Journal of Science Education and Technology, DOI [DOI 10.1007/S10956-006-9037-Z, 10.1007/s10956-006-9037-z]
   [Anonymous], 2009, HDB RES EFFECTIVE EL, DOI DOI 10.4018/9781599048086.CH057
   Antle A.N., 2007, Proceedings of the 1st international conference on Tangible and embedded interaction, P195, DOI DOI 10.1145/1226969.1227010
   Barati B., 2017, ALIVE ACTIVE ADAPTIV, P50
   Bellucci A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030438
   Benford S, 2005, COMMUN ACM, V48, P54, DOI 10.1145/1047671.1047704
   Bordegoni M.., 2018, P DESIGN 2018 15 INT, P183
   Buchenau M., 2000, DIS2000. Designing Interactive Systems Processes, Practices, Methods, and Techniques. Conference Proceedings, P424, DOI 10.1145/347642.347802
   Chang JSK, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P1239, DOI 10.1145/3064663.3064675
   Coleman B, 2009, IEEE PERVAS COMPUT, V8, P16, DOI 10.1109/MPRV.2009.60
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Dalinger T, 2020, COMPUT EDUC, V144, DOI 10.1016/j.compedu.2019.103696
   Davies CJ, 2012, P POSTGR C CONV NETW
   Daz PA., 2019, Perspect Phycol, V6, P39, DOI DOI 10.1127/PIP/2019/0081
   De Freitas S., 2006, LEARNING IMMERSIVE W
   De Freitas S., 2006, Educational games and simulations: Case studies from adult learning practice
   Dede C., 1995, Educational Technology, V35, P46
   Dow S., 2006, Designing Interactive Systems. DIS2006, P241
   Dunleavy M., 2014, Handbook of Research on Educational Communications and Technology, P735, DOI [DOI 10.1007/978-1-4614-3185-5_59, 10.1007/978-1-4614-3185-5_59]
   Goldin-Meadow S, 2009, CHILD DEV PERSPECT, V3, P106, DOI 10.1111/j.1750-8606.2009.00088.x
   Greenberg S, 2007, MULTIMED TOOLS APPL, V32, P139, DOI 10.1007/s11042-006-0062-y
   Johnson-Glenberg MC, 2019, SMART COMPUT INTELL, P83, DOI 10.1007/978-981-13-8265-9_5
   Jones L, 2020, TEI'20: PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION, P165, DOI 10.1145/3374920.3374954
   K, 2002, Proc. Conf. Designing Interactive Systems, P41, DOI DOI 10.1145/778712.778722
   Kamarainen AM, 2013, COMPUT EDUC, V68, P545, DOI 10.1016/j.compedu.2013.02.018
   Kim B, 2009, COMPUT EDUC, V52, P800, DOI 10.1016/j.compedu.2008.12.004
   Klopfer E, 2008, ETR&D-EDUC TECH RES, V56, P203, DOI 10.1007/s11423-007-9037-6
   Lave J., 1991, SITUATED LEARNING LE, DOI [10.24251/HICSS.2018.457, DOI 10.24251/HICSS.2018.457]
   Lee M, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281533
   Lifton J, 2009, IEEE PERVAS COMPUT, V8, P24, DOI 10.1109/MPRV.2009.49
   Lucke U, 2014, PERVASIVE MOB COMPUT, V14, P3, DOI 10.1016/j.pmcj.2013.12.001
   Mantovani F., 2003, Towards Cyberpsychology: Mind, Cognitions and Society in the Internet Age, P207
   Marshall P., 2003, Proceeding of the 2003 conference on Interaction design and children - IDC '03 (New York, New York, USA, P101
   Mayton B, 2017, PRESENCE-TELEOP VIRT, V26, P182, DOI 10.1162/PRES_a_00292
   Nebeling M, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P333, DOI 10.1109/ISMAR-Adjunct.2018.00098
   Paradiso JA, 2009, IEEE PERVAS COMPUT, V8, P14, DOI 10.1109/MPRV.2009.47
   Peña-Ríos A, 2012, 2012 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY WORKSHOPS (WI-IAT WORKSHOPS 2012), VOL 3, P362, DOI 10.1109/WI-IAT.2012.43
   Porfirio D, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P479, DOI 10.1145/3332165.3347957
   Prensky M., 2003, Computers in Entertainment (CIE), V1, P21, DOI DOI 10.1145/950566.950596
   Reilly D. F, 2010, PROC UIST, DOI [10.1145/1866029.1866050, DOI 10.1145/1866029.1866050]
   Robertson BF, 2009, COMPUT AIDED DESIGN, V41, P136, DOI 10.1016/j.cad.2008.06.007
   Salimian Hossein, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359207
   Sanders EBN, 2000, COLLABORATIVE DESIGN, P3
   Sandford R., 2006, TEACHING GAMES USING
   Shaffer DW, 2005, PHI DELTA KAPPAN, V87, P104, DOI 10.1177/003172170508700205
   Suh A, 2018, COMPUT HUM BEHAV, V86, P77, DOI 10.1016/j.chb.2018.04.019
   Telier A, 2011, DES THINK DES THEOR, P1
   Tomico O, 2015, P 17 INT C HUMAN COM
   WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94
   Wilde D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5158, DOI 10.1145/3025453.3025873
   Zarraonandia T, 2018, INT C GAM LEARN ALL, P297
   Zimmerman J, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P493
NR 53
TC 1
Z9 1
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 AUG 31
PY 2022
DI 10.1007/s11042-022-13632-2
EA AUG 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4E7ET
UT WOS:000847985800004
OA hybrid
DA 2024-07-18
ER

PT J
AU Chung, CY
   Huang, SH
AF Chung, Chieh-Yu
   Huang, Szu-Hao
TI Interactively transforming chinese ink paintings into realistic images
   using a border enhance generative adversarial network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chinese painting; Deep learning; GAN; Interactive; Style transfer
ID STYLE TRANSFER
AB Traditional Chinese painting has a long history. When we appreciate such paintings today, although we can obtain an overview of the landscape and environment of that time, it can be difficult to feel like we are interacting with the paintings. Alongside the rapid rise of deep learning, much research has been conducted on style transfer-for example, transforming photographs into the style of Chinese painting, sketches, or cartoons-but no research has considered the transformation of Chinese paintings into realistic images or even enriching such paintings through user interaction. To address this research gap, we employed a generative adversarial network (GAN), which is a generative model, to create new images that resemble the training data through the process of confrontation. Additionally, compared with general image-to-image translation, converting Chinese ink paintings into realistic images requires additional input because ink paintings contain texture and border features of relatively low quality. We combined cycle-consistent GAN with pix2pix and added a label function to establish a border enhance GAN with the purpose of enhancing the detail of border images and producing more accurate realistic images. In this manner, traditional Chinese paintings can be invigorated. Finally, we compared the image generated using our model with other benchmarks. The results revealed that the image generated using our model exhibited greater similarity to the actual photograph than did the benchmark images. Therefore, our model mitigates a major problem encountered in previous works and renders more realistic results. These interactive images clearly and profoundly convey Chinese culture, offering the user a novel art experience. Moreover, when viewers can interact with the input image by selecting different geologic styles, they can derive a relatively profound immersive experience. Our study can serve as a reference in transforming images (such as watercolor and oil paintings) with blurry borders.
C1 [Chung, Chieh-Yu] Natl Yang Ming Chiao Tung Univ, Inst Informat Management, Hsinchu 30010, Taiwan.
   [Huang, Szu-Hao] Natl Yang Ming Chiao Tung Univ, Dept Informat Management & Finance, Hsinchu 30010, Taiwan.
C3 National Yang Ming Chiao Tung University; National Yang Ming Chiao Tung
   University
RP Huang, SH (corresponding author), Natl Yang Ming Chiao Tung Univ, Dept Informat Management & Finance, Hsinchu 30010, Taiwan.
EM v53828646@gmail.com; szuhaohuang@nycu.edu.tw
OI Huang, Szu-Hao/0000-0002-4073-0652
FU Ministry of Science and Technology, Taiwan [MOST 111-2622-8-A49-013
   -TM1, MOST 111-2221-E-A49 -125 -MY3]; Financial Technology (FinTech)
   Innovation Research Center,National Yang Ming Chiao Tung University
FX This work was supported in part by the Ministry of Science and
   Technology, Taiwan, under MOST 111-2622-8-A49-013 -TM1 and MOST
   111-2221-E-A49 -125 -MY3; and in part by the Financial Technology
   (FinTech) Innovation Research Center,National Yang Ming Chiao Tung
   University.
CR Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chen CF, 2018, IEEE WINT CONF APPL, P485, DOI 10.1109/WACV.2018.00059
   Chen L, 2019, IEEE T MULTIMEDIA, V21, P2664, DOI 10.1109/TMM.2019.2907052
   Chen SS, 2020, SOFT COMPUT, V24, P7873, DOI 10.1007/s00500-019-03985-6
   Cheng Y, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4383
   Ciresan D, 2012, ARXIV
   Dai CQ, 2020, MULTIMED TOOLS APPL, V79, P12597, DOI 10.1007/s11042-019-08604-y
   Dou H, 2019, INT CONF ACOUST SPEE, P1757, DOI [10.1109/icassp.2019.8682600, 10.1109/ICASSP.2019.8682600]
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Gao W, 2020, IEEE WINT CONF APPL, P3211, DOI 10.1109/WACV45572.2020.9093420
   Gatys L. A., 2015, arXiv
   Goodfellow I., 2016, arXiv
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   GUPTA S., 2013, Int. J. Comput. Sci. Manag. Res, V2, P1578
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hensel M, 2017, ADV NEUR IN, V30
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jia Z., 2020, ARXIV
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Khan A, 2019, MULTIMED TOOLS APPL, V78, P19565, DOI 10.1007/s11042-019-7270-8
   Kolkin N, 2019, PROC CVPR IEEE, P10043, DOI 10.1109/CVPR.2019.01029
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larsen A B L, 2015, ARXIV
   Le Zhou, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P819, DOI 10.1109/ICDAR.2019.00136
   Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P5881, DOI 10.1109/TIP.2019.2922854
   Li ZX, 2020, MULTIMED TOOLS APPL, V79, P4347, DOI 10.1007/s11042-018-6929-x
   Liang Y, 2022, MULTIMED TOOLS APPL, V81, P26669, DOI 10.1007/s11042-020-10468-6
   Lin DY, 2018, ALGORITHMS, V11, DOI 10.3390/a11010004
   Liu BC, 2021, AAAI CONF ARTIF INTE, V35, P2073
   Longman R, 2019, IEEE IMAGE PROC, P969, DOI [10.1109/ICIP.2019.8803082, 10.1109/icip.2019.8803082]
   Lu Y., 2017, ARXIV
   Osahor U, 2020, IEEE COMPUT SOC CONF, P3575, DOI 10.1109/CVPRW50498.2020.00418
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Peng CL, 2020, IEEE T IMAGE PROCESS, V29, P8519, DOI 10.1109/TIP.2020.3016502
   Peng F, 2018, ARXIV
   Pesko M, 2018, ARXIV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruder M, 2016, LECT NOTES COMPUT SC, V9796, P26, DOI 10.1007/978-3-319-45886-1_3
   Runtao Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P36, DOI 10.1007/978-3-030-58580-8_3
   Salimans T, 2016, ADV NEUR IN, V29
   Shen YJ, 2018, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2018.00092
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tran L, 2017, PROC CVPR IEEE, P1283, DOI 10.1109/CVPR.2017.141
   Turmukhambetov D, 2015, COMPUT GRAPH FORUM, V34, P130, DOI 10.1111/cgf.12665
   Tylecek R, 2013, LECT NOTES COMPUT SC, V8142, P364, DOI 10.1007/978-3-642-40602-7_39
   Wada K, 2016, Labelme: Image Polygonal Annotation with Python
   Wang WJ, 2020, AAAI CONF ARTIF INTE, V34, P12233
   Wang XL, 2016, LECT NOTES COMPUT SC, V9908, P318, DOI 10.1007/978-3-319-46493-0_20
   Way D.-L., 2019, P 3 INT C ADV IM PRO, P139
   Xue A, 2021, IEEE WINT CONF APPL, P3862, DOI 10.1109/WACV48630.2021.00391
   Yao Y, 2019, PROC CVPR IEEE, P1467, DOI 10.1109/CVPR.2019.00156
   Zhou TH, 2016, PROC CVPR IEEE, P117, DOI 10.1109/CVPR.2016.20
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 60
TC 3
Z9 3
U1 8
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11663
EP 11696
DI 10.1007/s11042-022-13684-4
EA AUG 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000846136800001
DA 2024-07-18
ER

PT J
AU Mittal, U
   Chawla, P
AF Mittal, Usha
   Chawla, Priyanka
TI Vehicle detection and traffic density estimation using ensemble of deep
   learning models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Detection; Traffic density; Ensemble; SSD; Faster R-CNN; Convolutional
   neural network; Deep learning
ID CLASSIFICATION
AB Traffic density estimation can be used for controlling traffic light signals to provide effective traffic management. It can be done in two steps: vehicle recognition and counting. Deep learning (DL) technologies are being explored more and more as CNN grows in popularity. In this study, initially, data was collected from various open-source libraries that is FLIR, KITTI, and MB7500. Vehicles in the images are labelled in six different classes. To deal with an imbalanced dataset, data augmentation techniques were applied. Then, a model based on an ensemble of the faster region-based convolutional neural networks (Faster R-CNN) and Single-shot detector (SSD) were trained on finally processed datasets. The results of the proposed model were compared with base estimators of the FLIR dataset (Thermal and RGB images separately), MB7500, and KITTI dataset. Experimental results depict that the highest mAP obtained was 94% by the proposed Ensemble on FLIR thermal dataset which was 34% better than SSD and 6% from the Faster R-CNN model. Overall, the proposed ensemble achieves better and more promising results as compared to base estimators. Experimental results also show that detection with thermal images was better than visible images. In addition, three algorithms were compared for estimated density and the proposed model shows significant potential for traffic density estimation.
C1 [Mittal, Usha; Chawla, Priyanka] Lovely Profess Univ, Sch Comp Sci & Engn, Phagwara, Punjab, India.
C3 Lovely Professional University
RP Chawla, P (corresponding author), Lovely Profess Univ, Sch Comp Sci & Engn, Phagwara, Punjab, India.
EM priyankachawla.cse@gmail.com
RI mittal, usha/AEF-8897-2022
OI mittal, usha/0000-0001-6143-1312
CR Al-Zu'bi S, 2021, MULTIMED TOOLS APPL, V80, P16887, DOI 10.1007/s11042-020-09160-6
   AlZu'bi S, 2020, 2020 FIFTH INTERNATIONAL CONFERENCE ON FOG AND MOBILE EDGE COMPUTING (FMEC), P306, DOI [10.1109/FMEC49853.2020.9144916, 10.1109/fmec49853.2020.9144916]
   AlZu'bi S, 2019, MULTIMED TOOLS APPL, V78, P29581, DOI 10.1007/s11042-019-7367-0
   AlZu'bi S, 2020, PATTERN RECOGN LETT, V130, P312, DOI 10.1016/j.patrec.2018.07.026
   AlZu'bi S, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, MANAGEMENT AND SECURITY (SNAMS), P172, DOI 10.1109/SNAMS.2018.8554487
   [Anonymous], 2016, IEEE INT C DIG SIGN
   Aqel D, 2022, CLUSTER COMPUT, V25, P2007, DOI 10.1007/s10586-021-03397-y
   Arróspide J, 2013, IEEE T IMAGE PROCESS, V22, P2286, DOI 10.1109/TIP.2013.2249080
   Azimi SM, 2019, LECT NOTES COMPUT SC, V11130, P88, DOI 10.1007/978-3-030-11012-3_7
   Biswas D, 2019, PHYS CHEM EARTH, V110, P176, DOI 10.1016/j.pce.2018.12.001
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Chan YM, 2012, IET INTELL TRANSP SY, V6, P1, DOI 10.1049/iet-its.2011.0019
   Chen YP, 2017, ADV NEUR IN, V30
   Chowdhury PN, 2020, MULTIMED TOOLS APPL, V79, P33303, DOI 10.1007/s11042-020-09681-0
   Dai JF, 2016, ADV NEUR IN, V29
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   de Oliveira DC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072244
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Fidler S, 2013, PROC CVPR IEEE, P3294, DOI 10.1109/CVPR.2013.423
   Gao Y, 2015, ADV SCI TECHNOL, VLett90, P57
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Harsha SS, 2016, INT J ADV COMPUT SC, V7, P17
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jagannathan P, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/5590894
   Jamiya SS, 2021, OPTIK, V225, DOI 10.1016/j.ijleo.2020.165818
   John V, 2015, 2015 14TH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), P246, DOI 10.1109/MVA.2015.7153177
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kembhavi A, 2011, IEEE T PATTERN ANAL, V33, P1250, DOI 10.1109/TPAMI.2010.182
   Keserwani P, 2021, IEEE ACCESS, V9, P36802, DOI 10.1109/ACCESS.2021.3063030
   Kleban J, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1077, DOI 10.1109/ICME.2008.4607625
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Lee JT, 2017, IEEE COMPUT SOC CONF, P920, DOI 10.1109/CVPRW.2017.127
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu W, 2018, KNOWL-BASED SYST, V160, P167, DOI 10.1016/j.knosys.2018.06.035
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Nam YY, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0245-2
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Ozkurt C, 2009, MATH COMPUT APPL, V14, P187, DOI 10.3390/mca14030187
   Kumar CR, 2021, J AMB INTEL HUM COMP, V12, P4269, DOI 10.1007/s12652-020-01824-3
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezaee H., 2011, 2011 IEEE GCC Conference and Exhibition (GCC), P397, DOI 10.1109/IEEEGCC.2011.5752541
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suryanto, 2011, IMAGE VISION COMPUT, V29, P850, DOI 10.1016/j.imavis.2011.09.008
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wu X, 2019, RECENT ADV DEEP LEAR
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang YN, 2021, J REAL-TIME IMAGE PR, V18, P1261, DOI 10.1007/s11554-021-01121-y
   Zhang BL, 2013, IEEE T INTELL TRANSP, V14, P322, DOI 10.1109/TITS.2012.2213814
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhou X., 2019, arXiv
   Zhu JX, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010027
NR 62
TC 4
Z9 4
U1 5
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10397
EP 10419
DI 10.1007/s11042-022-13659-5
EA AUG 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000844934700002
DA 2024-07-18
ER

PT J
AU Blasco, D
   Font, J
   Pérez, F
   Cetina, C
AF Blasco, Daniel
   Font, Jaime
   Perez, Francisca
   Cetina, Carlos
TI Procedural content improvement of game bosses with an evolutionary
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Procedural content generation; Procedural content improvement;
   Evolutionary algorithms; Commercial video games
ID SOFTWARE; DESIGN; TESTS
AB We present our Evolutionary Boss Improvement (EBI) approach, which receives partially complete bosses as input and generates fully equipped bosses that are complete. Additionally, the evolutionary algorithm and the new genetic operations included in EBI favor genetic improvement, which affects the initial partial content of the incomplete bosses originally provided. We evaluate our approach using Kromaia, a commercial video game released on PlayStation 4 and PC. EBI uses an evolutionary algorithm to evolve a population of bosses guided by duels between the bosses being generated and a simulated player. Our approach evaluates the quality, in terms of game experience, of both the bosses generated and those included in Kromaia using six metrics (Completion, Duration, Uncertainty, Killer Moves, Permanence, and Lead Change) from the literature. The results show that the quality of the bosses created by EBI is comparable to the quality of the original bosses that were manually created by the developers of Kromaia. However, the EBI approach reduces the time required to build the bosses from five months (of elapsed time as opposed to dedicated time) to just 100 minutes of unattended run. EBI enables developers to accelerate the creation of content, such as bosses, which is essential to ensure player engagement.
C1 [Blasco, Daniel; Font, Jaime; Perez, Francisca; Cetina, Carlos] Univ San Jorge, SVIT Res Grp, Zaragoza, Spain.
C3 Universidad San Jorge
RP Pérez, F (corresponding author), Univ San Jorge, SVIT Res Grp, Zaragoza, Spain.
EM dblasco@usj.es; jfont@usj.es; mfperez@usj.es; ccetina@usj.es
RI Pérez, Francisca/KPH-0503-2024
FU Ministry of Economy and Competitiveness (MINECO) through the Spanish
   National R+D+i Plan [PID2021-128695OB-I00]; ERDF funds under the Project
   VARIATIVA [PID2021-128695OB-I00]; Gobierno de Aragon (Spain) [S05 20D]
FX This work was supported in part by the Ministry of Economy and
   Competitiveness (MINECO) through the Spanish National R+D+i Plan and
   ERDF funds under the Project VARIATIVA under Grant PID2021-128695OB-I00,
   and in part by the Gobierno de Aragon (Spain) (Research Group S05 20D).
CR Althofer Ingo, 2003, Tech. Rep
   [Anonymous], 2015, Handbook of Genetic Programming Applications, DOI [DOI 10.1007/978-3-319-20883-1_8, DOI 10.1007/978-3-319-20883-18]
   Arcuri A, 2014, SOFTW TEST VERIF REL, V24, P219, DOI 10.1002/stvr.1486
   Arcuri A, 2013, EMPIR SOFTW ENG, V18, P594, DOI 10.1007/s10664-013-9249-9
   Ashley DR, 2019, P 2019 IEEE C GAMES, P1
   Barros Mrciode Oliveira., 2011, RELATE DIA, V5
   Beyer Marlene., 2016, Computational Intelligence and Games (CIG), 2016 IEEE Conference on, P1
   Bhatt A, 2019, PLANT BIOSYST, V153, P280, DOI 10.1080/11263504.2018.1473524
   Blasco D, 2021, J SYST SOFTWARE, V171, DOI 10.1016/j.jss.2020.110804
   Blasco D, 2020, INFORM SOFTWARE TECH, V119, DOI 10.1016/j.infsof.2019.106235
   Boussaïd I, 2017, AUTOMAT SOFTW ENG, V24, P233, DOI 10.1007/s10515-017-0215-4
   Brown JP, 2020, IEEE HAPTICS SYM, P1, DOI [10.1109/haptics45997.2020.ras.hap20.8.0698f2bb, 10.1109/HAPTICS45997.2020.ras.HAP20.8.0698f2bb]
   Browne C., 2005, CONNECTION GAMES VAR
   Browne C, 2010, IEEE T COMP INTEL AI, V2, P1, DOI 10.1109/TCIAIG.2010.2041928
   Cardamone L, 2011, LECT NOTES COMPUT SC, V6624, P63, DOI 10.1007/978-3-642-20525-5_7
   de MesentierSilva., 2019, 2019 IEEE Conference on Games (CoG), P1
   Delarosa Omar, 2021, Artificial Intelligence in Music, Sound, Art and Design. 10th International Conference, EvoMUSART 2021. Held as Part of EvoStar 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12693), P412, DOI 10.1007/978-3-030-72914-1_27
   Eiben A.E., 2015, NAT COMP SER, P223, DOI 10.1007/978-3-662-44874-8_15
   Games E, 1998, UNREAL ENGINE VERSIO
   García S, 2010, INFORM SCIENCES, V180, P2044, DOI 10.1016/j.ins.2009.12.010
   Guzdial M, 2018, ARXIV
   Ha D., 2017, P INT C LEARN REPR
   Hendrikx M, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2422956.2422957
   Iida H, 2004, LECT NOTES COMPUT SC, V3166, P333
   Jaffe Alexander., 2012, AIIDE
   Karapiperis Dimitrios., 2018, IEEE International Smart Cities Conference, P1
   Kent S., 2002, Integrated Formal Methods. Third International Conference, IFM 2002. Proceedings (Lecture Notes in Computer Science Vol.2335), P286
   KOZA JR, 1994, STAT COMPUT, V4, P87, DOI 10.1007/BF00175355
   Kramer W., 2000, The Games Journal
   Lanzi P.L., 2014, PROC IEEE C COMPUT I, P1
   Liapis Antonios, 2013, Evolutionary and Biologically Inspired Music,Sound, Art and Design. Second International Conference, EvoMUSART 2013. Proceedings, P180, DOI 10.1007/978-3-642-36955-1_16
   Liapis A, 2013, P ACM C FDN DIGITAL
   Lim Siew Mooi, 2017, International Journal of Machine Learning and Computing, V7, P9, DOI 10.18178/ijmlc.2017.7.1.611
   Liu JL, 2021, NEURAL COMPUT APPL, V33, P19, DOI 10.1007/s00521-020-05383-8
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Loiacono Daniele, 2017, 2017 IEEE Conference on Computational Intelligence and Games (CIG), P199, DOI 10.1109/CIG.2017.8080436
   Loiacono D, 2019, IEEE T GAMES, V11, P36, DOI 10.1109/TG.2018.2830746
   Olsted PT, 2015, IEEE C EVOL COMPUTAT, P1527, DOI 10.1109/CEC.2015.7257069
   Pantaleev A, 2012, P 3 WORKSH PROC CONT, P1
   Park K, 2019, IEEE CONF COMPU INTE, DOI 10.1109/cig.2019.8848085
   Pavai G, 2017, ACM COMPUT SURV, V49, DOI 10.1145/3009966
   Pérez F, 2022, IEEE T SOFTWARE ENG, V48, P713, DOI 10.1109/TSE.2020.3000520
   Petke J, 2018, IEEE T EVOLUT COMPUT, V22, P415, DOI 10.1109/TEVC.2017.2693219
   Pfau J, 2020, IEEE CONF COMPU INTE, P431, DOI 10.1109/CoG47356.2020.9231958
   Reyno EM., 2009, COMPUTERS ENTERTAINM, V7, P1, DOI DOI 10.1145/1541895.1541909
   Ruela AS, 2017, SOFT COMPUT, V21, P7005, DOI 10.1007/s00500-016-2238-3
   Sarkar A, 2020, ARXIV
   Sarkar A, 2018, AIIDE WORKSHOPS
   Serpa YR, 2019, BRAZIL SYMP GAME DIG, P182, DOI 10.1109/SBGames.2019.00032
   Shaker N., 2016, PROCEDURAL CONTENT G
   Silva F. D. M., 2017, P WORKSH AAAI SAN FR, P959
   Siu K., 2016, P 12 ART INT INT DIG
   Snodgrass S., 2020, PROC 15 INT C FOUND, P1
   Summerville A, 2018, IEEE T GAMES, V10, P257, DOI 10.1109/TG.2018.2846639
   Tang Stephen., 2010, Developments in E-systems Engineering (DESE), P95, DOI DOI 10.1109/DESE.2010.23
   Thompson J.Mark., 2000, GAMES J
   Togelius J, 2011, IEEE T COMP INTEL AI, V3, P172, DOI 10.1109/TCIAIG.2011.2148116
   Van der Ven JS, 2006, RATIONAL MANAGEMENT IN SOFTWARE ENGINEERING, P329, DOI 10.1007/3-5403-0998-5_16
   Vargha A, 2000, J EDUC BEHAV STAT, V25, P101, DOI 10.3102/10769986025002101
   Volz V, 2016, GECCO'16: PROCEEDINGS OF THE 2016 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P269, DOI 10.1145/2908812.2908913
   Yannakakis G. N., 2018, Artificial Intelligence and Games, P259, DOI 10.1007/978-3-319-63519-46
   Yannakakis Georgios N, 2014, Mixed-initiative co-creativity
   Yoo B, 2016, 2016 IEEE C COMP INT, P1
NR 63
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10277
EP 10309
DI 10.1007/s11042-022-13674-6
EA AUG 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000844473700001
DA 2024-07-18
ER

PT J
AU Dewangan, DK
   Sahu, SP
AF Dewangan, Deepak Kumar
   Sahu, Satya Prakash
TI Lane detection in intelligent vehicle system using optimal 2-tier deep
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Road detection; Lane detection; Two-tier lane detection framework; LVP;
   Optimization
ID MARKING DETECTION; ALGORITHM; FRAMEWORK
AB In Advanced Driver Assistance Systems(ADAS) and autonomous vehicles, lane detection is an important module. Most lane detection methods focused on detecting lanes from a single image and the results from unsatisfactory performance under extremely bad climatic changes and attain high accuracy is challenging. In this research work, a novel two-tier deep learning based lane detection framework is introduced for multi images at different weather conditions. In both the tiers, the Local Vector Pattern (LVP) based texture features are extracted and an Optimized Deep Convolutional Neural Network (DCNN) is utilized to classify road and lane as well. The weight corresponding to the second convolutional layer of DCNN (both tiers) is fine-tuned by a novel technique called "Flight Straight of Moth Search (FS-MS) Algorithm" that is an enhanced version of the standard Moth search Algorithm, to create the detection more accurate (MS).With respect of particular metrics, the efficiency of the provided work is compared to that existing lane detecting models.Particularly, the computation time of the proposed model is 31.2%, 20.85%, 10.43%, and 4.53% higher than the existing MS + CNN, LA + CNN, GA + CNN, and PSO + CNN methods respectively.
C1 [Dewangan, Deepak Kumar] Siksha O Anusandhan Deemed Univ, Dept Comp Sci & Engn, Bhubaneswar, Odisha, India.
   [Sahu, Satya Prakash] Natl Inst Technol, Dept Informat Technol, Raipur, Chhattisgarh, India.
C3 Siksha 'O' Anusandhan University; National Institute of Technology (NIT
   System); National Institute of Technology Raipur
RP Dewangan, DK (corresponding author), Siksha O Anusandhan Deemed Univ, Dept Comp Sci & Engn, Bhubaneswar, Odisha, India.
EM deepakdewangan@soa.ac.in; spsahu.it@nitrr.acin
RI Sahu, Satya Prakash/AAY-7426-2020
OI Sahu, Satya Prakash/0000-0002-9886-9518; Dewangan, Deepak
   Kumar/0000-0002-0160-4215
CR Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Asifa MR, 2019, COMPUT ELECTR ENG, V78, P132, DOI 10.1016/j.compeleceng.2019.07.012
   Bhagyalakshmi V., 2018, J NETW COMMUN SYST, V1, P28
   Boothalingam R, 2018, EVOL INTELL, V11, P31, DOI 10.1007/s12065-018-0168-y
   Cadena A, 2016, P WORLD C ENG 2016 V
   Chen K, 2021, ARXIV
   Cheng WC, 2012, SENSORS-BASEL, V12, P17168, DOI 10.3390/s121217168
   Chiu KY, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P706
   Cristin R., 2020, MULTIMEDIA RES, V3, P21
   Daigavane P. M., 2010, Proceedings of the Third International Conference on Emerging Trends in Engineering and Technology (ICETET 2010), P76, DOI 10.1109/ICETET.2010.128
   de Paula MB, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2438714
   Deepak, 2020, COMMUNICATION
   Ding Y, 2017, MULTIMED TOOLS APPL, V76, P22979, DOI 10.1007/s11042-016-4184-6
   Eugenio F, 2015, IEEE T GEOSCI REMOTE, V53, P3539, DOI 10.1109/TGRS.2014.2377300
   Fan C, 2019, IEEE ACCESS, V7, P150833, DOI 10.1109/ACCESS.2019.2947574
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   Fan RC, 2019, COMPUT VIS MEDIA, V5, P417, DOI 10.1007/s41095-019-0160-1
   Gadekallu TR, 2021, COMPLEX INTELL SYST, V7, P1855, DOI 10.1007/s40747-021-00324-x
   Gadekallu TR, 2021, J REAL-TIME IMAGE PR, V18, P1383, DOI 10.1007/s11554-020-00987-8
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Gupta A, 2018, IEEE T INTELL VEHICL, V3, P476, DOI 10.1109/TIV.2018.2873902
   Joshy N., 2014, INT J COMPUT SCI MOB, V3, P507
   Kuqi B, 2023, J SUSTAIN FINANC INV, V13, P92, DOI 10.1080/20430795.2021.1883986
   Lee K, 2019, IEEE T INTELL TRANSP, V20, P3129, DOI 10.1109/TITS.2018.2873101
   Li J, 2017, IEEE T NEUR NET LEAR, V28, P690, DOI 10.1109/TNNLS.2016.2522428
   Li ST, 2017, CHIN CONT DECIS CONF, P75, DOI 10.1109/CCDC.2017.7978069
   Liu JY, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102675
   Lokesh Kumar R., 2019, J COMPUT MECH POWER, V2, P1, DOI [10.46253/jcmps.v2i3.a1, DOI 10.46253/JCMPS.V2I3.A1]
   Mammeri Abdelhamid., 2014, P 17 ACM INT C MODEL, P259, DOI 10.1145/2641798.2641807
   Narote SP, 2018, PATTERN RECOGN, V73, P216, DOI 10.1016/j.patcog.2017.08.014
   Neven D, 2018, IEEE INT VEH SYM, P286
   Nguyen V, 2018, ENG SCI TECHNOL, V21, P822, DOI 10.1016/j.jestch.2018.06.006
   Ozgunalp U, 2017, IEEE T INTELL TRANSP, V18, P621, DOI 10.1109/TITS.2016.2586187
   Rajakumar BR, 2013, AASRI PROC, V4, P288, DOI 10.1016/j.aasri.2013.10.043
   Rajakumar BR, 2014, 2014 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P2116, DOI 10.1109/CEC.2014.6900561
   Rajakumar BR, 2013, INT J COMPUT SCI ENG, V8, P180, DOI 10.1504/IJCSE.2013.053087
   Rajakumar B.R., 2013, International Journal of Hybrid Intelligent Systems, V10, P11, DOI [10.3233/HIS-120161, DOI 10.3233/HIS-120161]
   Roy RG, 2021, ADAPT BEHAV, V29, P39, DOI 10.1177/1059712319882105
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Shukla U, 2019, PROCEDIA COMPUT SCI, V165, P252, DOI 10.1016/j.procs.2020.01.081
   Taghipour Atour, 2013, International Journal of Business Performance and Supply Chain Modelling, V5, P272
   Tian Y, 2018, NEUROCOMPUTING, V280, P46, DOI 10.1016/j.neucom.2017.09.098
   Tian Youjin, 2018, Procedia Computer Science, V131, P354, DOI 10.1016/j.procs.2018.04.174
   Vasan D, 2020, COMPUT NETW, V171, DOI 10.1016/j.comnet.2020.107138
   Venkatraman S, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/1728303
   Wang GG, 2018, MEMET COMPUT, V10, P151, DOI 10.1007/s12293-016-0212-3
   Xiao DG, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105584
   Xiao J, 2016, SENS IMAGING, V17, DOI 10.1007/s11220-016-0133-8
   Xu ZZ, 2015, IEEE T IMAGE PROCESS, V24, P813, DOI 10.1109/TIP.2014.2387020
   Yang WJ, 2019, IEEE ACCESS, V7, P173148, DOI 10.1109/ACCESS.2019.2957053
   Ying ZQ, 2016, INT CONF ACOUST SPEE, P1921, DOI 10.1109/ICASSP.2016.7472011
   Yuan C, 2018, IEEE ACCESS, V6, P49679, DOI 10.1109/ACCESS.2018.2868976
   Zang JJ, 2018, ASIAPAC SIGN INFO PR, P305, DOI 10.23919/APSIPA.2018.8659684
   Zhang A, 2018, MEASUREMENT, V130, P105, DOI 10.1016/j.measurement.2018.07.089
   Zhang G, 2020, SIGNAL PROCESS-IMAGE, V84, DOI 10.1016/j.image.2020.115811
   Zhang XZ, 2019, EXPERT SYST APPL, V121, P38, DOI 10.1016/j.eswa.2018.12.005
   Zou Q, 2020, IEEE T VEH TECHNOL, V69, P41, DOI 10.1109/TVT.2019.2949603
NR 59
TC 20
Z9 20
U1 5
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7293
EP 7317
DI 10.1007/s11042-022-13425-7
EA AUG 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000847198200003
DA 2024-07-18
ER

PT J
AU Anggara, DW
   Rahim, MSM
   Ismail, AW
   Wong, SY
   Ismail, NAF
   Machfiroh, R
   Budiman, A
   Rahmansyah, A
   Dahliyusmanto
AF Anggara, Devi Willieam
   Rahim, Mohd Shafry Mohd
   Ismail, Ajune Wanis
   Wong, Seng Yue
   Ismail, Nor Anita Fairos
   Machfiroh, Runik
   Budiman, Arif
   Rahmansyah, Aris
   Dahliyusmanto
TI Integrated Colormap and ORB detector method for feature extraction
   approach in augmented reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; ORB detector; Colormap; NFT; Augmented reality
ID IMAGE
AB Augmented Reality (AR) is a technology that addition of virtual objects into the real-world environment. AR technology uses images recognition approaches to recognize objects. The objects can be easily recognized if rich in details, have good contrast, and have no repetitive patterns. A feature-based technique called Natural Feature Tracking (NFT) system can be used to recognize physical objects in markerless AR. The features such as blob, edge, and corner in the object are extracted by the feature detector and descriptor before recognizing process. The extraction feature is the most important thing in the recognition process because it can determine accurate results. ORB detector is a feature extractor were suitable for real-time tracking in AR because it has speed, efficiency, and a high quantity of features detected and extracted. However, before detecting and describing the features, ORB detector uses the Grayscale Image Generation (GIG) process to change color images into grayscale images. We found some features extracted using the GIG process not extracted perfectly. ORB detector is influenced by the intensity of the grayscale pixel to find the candidate corner. The proposed integration of the Colormap technique and ORB detector method can enhance feature extraction for improving features detection in AR.
C1 [Anggara, Devi Willieam] Univ Teknol Malaysia, Fac Engn, Sch Comp, Johor Baharu, Malaysia.
   [Rahim, Mohd Shafry Mohd; Ismail, Ajune Wanis; Ismail, Nor Anita Fairos] Univ Teknol Malaysia, UTM IRDA Digital Media Ctr, Inst Human Ctr Engn iHumEn, Media & Game Innovat Excellence MaGICX, Johor Baharu, Malaysia.
   [Wong, Seng Yue] Univ Malaya, Ctr Internship Training & Acad Enrichment CITrA, Kuala Lumpur, Malaysia.
   [Machfiroh, Runik; Budiman, Arif; Rahmansyah, Aris] Telkom Univ, Creat Ind Sch, Design Commun Visual, Bandung, Indonesia.
   [Dahliyusmanto] Univ Riau, Dept Elect Engn, Pekanbaru, Indonesia.
C3 Universiti Teknologi Malaysia; Universiti Teknologi Malaysia; Universiti
   Malaya; Telkom University; Universitas Riau
RP Anggara, DW (corresponding author), Univ Teknol Malaysia, Fac Engn, Sch Comp, Johor Baharu, Malaysia.
EM wadevi@graduate.utm.my
RI Rahmansyah, Aris/ABS-6633-2022; Machfiroh, Runik/AAB-8886-2021; ISMAIL,
   AJUNE WANIS/KDM-6010-2024; ANGGARA, DEVI WILLIEAM/JDD-1488-2023;
   Dahliyusmanto, Dahliyusmanto/JPK-8241-2023; Wong, Seng Yue/L-2218-2016
OI Machfiroh, Runik/0000-0002-1444-154X; ANGGARA, DEVI
   WILLIEAM/0000-0002-5235-4885; Wong, Seng Yue/0000-0001-9278-4348
FU Universiti Teknologi Malaysia [R.J130000.7308.4B429, Q.J130000.3051.01
   M37, Q.J130000.3008.01 M88]; Fundamental Research Grant (FRGS) by
   Ministery of Higher Education Malaysia [FRGS/1/2020/ICT10/UTM/01/1,
   R.J130000.7808.5F368]
FX This work was supported by Universiti Teknologi Malaysia with grant
   numbers: R.J130000.7308.4B429,Q.J130000.3051.01 M37, Q.J130000.3008.01
   M88, and Fundamental Research Grant (FRGS) by Ministery of Higher
   Education Malaysia, FRGS/1/2020/ICT10/UTM/01/1, R.J130000.7808.5F368.
CR Adams M, 2017, FRACTIONAL HARRIS LA, V11603, P3, DOI [10.1007/978-3-030-22368-7_1, DOI 10.1007/978-3-030-22368-7_1]
   Anggara DW., 2020, J THEOR APPL INF TEC, V98, P2671
   Ar Y., 2018, P 2018 2 INT S MULTI, P1
   Bashardoost M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0118-y
   Beier D, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P258, DOI 10.1109/ISMAR.2003.1240709
   Bekele D, 2013, IEEE IMAGE PROC, P3652, DOI 10.1109/ICIP.2013.6738753
   Blanco-Pons S, 2019, MULTIMED TOOLS APPL, V78, P10265, DOI 10.1007/s11042-018-6609-x
   Chen P, 2016, J VIS COMMUN IMAGE R, V37, P63, DOI 10.1016/j.jvcir.2015.06.016
   Cirulis A, 2020, BALT J MOD COMPUT, V8, P174, DOI 10.22364/bjmc.2020.8.1.10
   Cukovic Sasa, 2015, International Conference on Electrical and Bio-Medical Engineering, Clean Energy and Green Computing (EBECEGC 2015). Proceedings, P24
   Dad A., 2017, International journal of engineering research and technology, V5, P1
   Deng G, 2016, EURASIP J ADV SIG PR, DOI 10.1186/s13634-016-0366-7
   Fang WK, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P275, DOI 10.1109/FPT.2017.8280159
   George AP., 2017, INT J PURE APPL MATH, V117, P69
   Gupta S., 2016, INT J COMP SCI INF T, V7, P1372
   Güzel MS, 2016, IMAGING SCI J, V64, P26, DOI 10.1080/13682199.2015.1109783
   Hamidia M, 2015, 9 C GEN EL
   Hashim Mohammed Mahdi, 2017, Journal of Theoretical and Applied Information Technology, V95, P5977
   Hashim MM., 2018, International Journal of Engineering & Technology, V7, P3505, DOI DOI 10.14419/IJET.V7I4.17294
   Hashim MM, 2019, IOP CONF SER-MAT SCI, V518, DOI 10.1088/1757-899X/518/5/052002
   Hassaballah M., 2019, Recent advances in computer vision: theories and applications, P113, DOI DOI 10.1007/978-3-030-03000-1
   Heinly J, 2012, LECT NOTES COMPUT SC, V7573, P759, DOI 10.1007/978-3-642-33709-3_54
   Jabal MFA, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND ENGINEERING, PROCEEDINGS, P709, DOI 10.1109/ICIME.2009.56
   Jakubovic A, 2018, ELMAR PROC, P83, DOI 10.23919/ELMAR.2018.8534641
   Jumarlis M, 2018, IOP C SER EARTH ENV, V156, DOI 10.1088/1755-1315/156/1/012017
   Khan D, 2015, COMPUT STAND INTER, V41, P56, DOI 10.1016/j.csi.2015.02.006
   Krig S., 2014, COMPUTER VISION METR, P217, DOI DOI 10.1007/978-1-4302-5930-5_6
   Lanka S, 2017, 2017 INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC), P770, DOI 10.1109/I-SMAC.2017.8058283
   Lee Haeseong, 2016, IEIE Transactions on Smart Processing & Computing, V5, P153
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marchand E, 2016, IEEE T VIS COMPUT GR, V22, P2633, DOI 10.1109/TVCG.2015.2513408
   McAndrew A., 2004, INTRO DIGITAL IMAGE, P1
   Mentzer N, 2017, RIVER PUBL SER TRANS, P157
   Parmar JK, 2019, ARXIV
   Rad AE, 2017, MULTIMED TOOLS APPL, V76, P2185, DOI 10.1007/s11042-015-3196-y
   Radkowski Rafael, 2013, Virtual, Augmented and Mixed Reality. Systems and Applications. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings, Part II: LNCS 8022, P281, DOI 10.1007/978-3-642-39420-1_30
   Rakhmadi Akmal, 2010, Journal of Computer Sciences, V6, P1099, DOI 10.3844/jcssp.2010.1099.1107
   Ren Xiaokang, 2020, Journal of Physics: Conference Series, V1453, DOI 10.1088/1742-6596/1453/1/012024
   Ruzinoor CM, 2012, GEO-SPAT INF SCI, V15, P105, DOI 10.1080/10095020.2012.714101
   Saipullah Khairulmuzzammil, 2013, Journal of Theoretical and Applied Information Technology, V47, P135
   Salahat E, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1059, DOI 10.1109/ICIT.2017.7915508
   Saravanan C, 2010, INT C COMPUT ENG APP, P196, DOI 10.1109/ICCEA.2010.192
   Selvapriya B., 2018, International Journal of Engineering & Technology, V7, P954
   Setyadi R., 2020, TELKOMNIKA TELECOMMU, V18, P140, DOI [10.12928/telkomnika.v18i1.13039, DOI 10.12928/TELKOMNIKA.V18I1.13039]
   Sharifara A, 2013, 2013 INTERNATIONAL CONFERENCE ON INFORMATICS AND CREATIVE MULTIMEDIA (ICICM), P22, DOI 10.1109/ICICM.2013.13
   Sun RD, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P183, DOI 10.1109/FPT.2017.8280137
   Taha MS, 2019, IOP CONF SER-MAT SCI, V518, DOI 10.1088/1757-899X/518/5/052003
   Tan SY, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0207191
   Tan SY., 2018, INT J ADV SCI ENG IN, V8, P1672, DOI [10.18517/ijaseit.8.4-2.6810, DOI 10.18517/IJASEIT.8.4-2.6810]
   Tareen Shaharyar Ahmed Khan, 2018, 2018 International Conference on Computing, Mathematics and Engineering Technologies (iCoMET). Proceedings, DOI 10.1109/ICOMET.2018.8346440
   Trajkovic M, 1998, IMAGE VISION COMPUT, V16, P75, DOI 10.1016/S0262-8856(97)00056-5
   Wang Chuin-Mu, 2015, J. appl. res. technol, V13, P297
   Yang ZL, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173627
NR 53
TC 1
Z9 1
U1 8
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35713
EP 35729
DI 10.1007/s11042-022-13548-x
EA AUG 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000836524700001
DA 2024-07-18
ER

PT J
AU He, L
   Long, W
   Liu, SX
   Li, YY
   Ding, W
AF He, Lei
   Long, Wei
   Liu, Shouxin
   Li, Yanyan
   Ding, Wei
TI A new grey mapping function and its adaptive algorithm for low-light
   image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brightness enhancement; Contrast enhancement; Adaptive algorithm;
   Low-light image; Mapping function; Noise suppression
ID MULTI-HISTOGRAM EQUALIZATION; CONTRAST ENHANCEMENT
AB When taking images in low light conditions, images often suffer from low visibility. In addition to affecting the sensory quality of images, this poor quality may also significantly limit the performance of various computer vision systems. Many grey-level mapping enhancement algorithms based on classic mapping functions, such as the gamma mapping function, have been proposed in recent years to improve the visual quality of low-light images. However, the classic mapping function cannot coordinate the greyscale distribution of the bright and dark areas of the image well and may easily lead to excessive enhancement. This makes it difficult for the performance of these improved algorithms to be fully utilized. Therefore, this paper proposes a new multiparameter grey mapping method. Unlike the classic mapping function, the new mapping method is based on the enhancement strategy of compressing the bright area and then adjusting the dark area. Thus, the inherent shortcomings of the classic mapping function are fundamentally overcome. The new mapping method can not only directly control the compression of the grey space in the bright area of the image through parameters, but it can also adjust the greyscale distribution of dark areas without changing the greyscale value of the pixels in the bright area. Finally, this paper also designs an adaptive enhancement algorithm with the new mapping method as the core to verify its effectiveness and flexibility. Experimental results showed that the adaptive algorithm had excellent performance in colour rendering, brightness enhancement and noise suppression. It was also obviously better than the current similar algorithms in visual quality and quantitative tests.
C1 [He, Lei; Long, Wei; Liu, Shouxin; Li, Yanyan; Ding, Wei] Sichuan Univ, Sch Mech Engn, Chengdu, Peoples R China.
C3 Sichuan University
RP Li, YY (corresponding author), Sichuan Univ, Sch Mech Engn, Chengdu, Peoples R China.
EM yyl_scu@163.com
FU Science and Technology Department of Sichuan Province, People's Republic
   of China [2020JDRC0026]
FX This work was supported by Science and Technology Department of Sichuan
   Province, People's Republic of China (No. 2020JDRC0026).
CR Aditya KP, 2014, PROC TECH, V14, P236, DOI 10.1016/j.protcy.2014.08.031
   Banik PP, 2018, 2018 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC), P218
   Cai BL, 2017, IEEE I CONF COMP VIS, P4020, DOI 10.1109/ICCV.2017.431
   Chang Y, 2018, IEEE ACCESS, V6, P11782, DOI 10.1109/ACCESS.2018.2797872
   Cheng H, 2021, MULTIMED TOOLS APPL, V80, P7205, DOI 10.1007/s11042-020-09919-x
   Dai Q, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11040574
   DALEJONES R, 1993, PATTERN RECOGN, V26, P1373, DOI 10.1016/0031-3203(93)90143-K
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Hao SJ, 2020, IEEE T MULTIMEDIA, V22, P3025, DOI 10.1109/TMM.2020.2969790
   Khan MF, 2014, DIGIT SIGNAL PROCESS, V25, P198, DOI 10.1016/j.dsp.2013.10.015
   Ko S, 2017, IEEE T IND ELECTRON, V64, P6392, DOI 10.1109/TIE.2017.2682034
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lee HG, 2015, ASIAPAC SIGN INFO PR, P884, DOI 10.1109/APSIPA.2015.7415397
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Li WS, 2017, INT J REMOTE SENS, V38, P7316, DOI 10.1080/01431161.2017.1371863
   Liu HJ, 2016, CHIN CONT DECIS CONF, P3712, DOI 10.1109/CCDC.2016.7531629
   Liu SX, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23060746
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Panetta K, 2011, IEEE T SYST MAN CY B, V41, P460, DOI 10.1109/TSMCB.2010.2058847
   Pisano ED, 1998, J DIGIT IMAGING, V11, P193, DOI 10.1007/BF03178082
   Ren XT, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351427
   Ren YR, 2019, IEEE T CIRC SYST VID, V29, P968, DOI 10.1109/TCSVT.2018.2828141
   Sandoub G, 2021, IET IMAGE PROCESS, V15, P1759, DOI 10.1049/ipr2.12148
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Singh K, 2015, OPTIK, V126, P2619, DOI 10.1016/j.ijleo.2015.06.060
   Singh N, 2020, IET IMAGE PROCESS, V14, P794, DOI 10.1049/iet-ipr.2019.0921
   Srinivas K, 2020, IET IMAGE PROCESS, V14, P668, DOI 10.1049/iet-ipr.2019.0781
   Tan SF, 2019, IEEE ACCESS, V7, P70842, DOI 10.1109/ACCESS.2019.2918557
   Venkatanath N, 2015, NATL CONF COMMUN
   Wang Q, 2007, IEEE T CONSUM ELECTR, V53, P757, DOI 10.1109/TCE.2007.381756
   Wang WC, 2020, IEEE ACCESS, V8, P87884, DOI 10.1109/ACCESS.2020.2992749
   Wang WC, 2017, IEEE T MULTIMEDIA, V19, P1142, DOI 10.1109/TMM.2017.2652069
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wang YF, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2922106
   Yang J, 2016, INT C PATT RECOG, P751, DOI 10.1109/ICPR.2016.7899725
   Yang KF, 2020, IEEE T IMAGE PROCESS, V29, P1493, DOI 10.1109/TIP.2019.2938310
   Yang WH, 2020, PROC CVPR IEEE, P3060, DOI 10.1109/CVPR42600.2020.00313
   Yanqin Zhao, 2011, 2011 Proceedings of IEEE International Conference on Computer Science and Automation Engineering (CSAE), P625, DOI 10.1109/CSAE.2011.5953297
   Yu CY, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/485151
NR 41
TC 1
Z9 1
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 6071
EP 6096
DI 10.1007/s11042-022-13598-1
EA AUG 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000835601400005
DA 2024-07-18
ER

PT J
AU Rajasoundaran, S
   Kumar, SVNS
   Selvi, M
   Ganapathy, S
   Kannan, A
AF Rajasoundaran, S.
   Kumar, Santhosh S. V. N.
   Selvi, M.
   Ganapathy, Sannasi
   Kannan, A.
TI Multi-tier block truncation coding model using genetic auto encoders for
   gray scale images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image compression; ETM; SGA; GSDAE; Machine learning techniques; Support
   vector machines; Deep learning techniques and truncation models
ID COMPOUND IMAGES; SEGMENTATION; COMPRESSION; ALGORITHM; CT
AB Image compression is an important task in most applications to save the storage space and communication cost. In this direction, many researches proposed Block Truncation Coding models to compress the images. However, some limitations are present in the existing image compression algorithms since they do not identify the image block dependencies, pixel value ratings and unimportant regions of an image accurately. To handle these issues, we propose three new image compression algorithms in this paper that have been developed based on ensemble machine learning and using deep learning techniques. Among them, the first algorithm has been developed using an ensemble of machine learning techniques namely multiple Support Vector Machines (SVM), and Genetic SVM called Ensemble based Truncation Model (ETM) for effective image compression. The second algorithm called Spatial and neural Genetic Algorithm (SGA) uses spatial constraints and Genetic Algorithms for performing the weight adjustment in neural networks for the compression of large sized spatial images using a neural and genetic approach. The third algorithm called Genetic Stacked and De-Noised Auto Encoder (GSDAE) proposed in this work is based on Spatial and neural Genetic Algorithm incorporated Stacked and De-Noised Auto Encoder model applies spatial constraints and Genetic Algorithms in the Deep Learning algorithm namely the Auto Encoder Neural Networks for performing the compression based on semantic features. From the experiments carried out in this work, we have proved that all these three proposed algorithms are able to improve the compression ratio and to reduce the Peak Signal to Noise Ratio values and the storage space than the existing works on image compression.
C1 [Rajasoundaran, S.] Vellore Inst Technol, Sch Comp Sci & Engn, Bhopal, India.
   [Kumar, Santhosh S. V. N.] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
   [Selvi, M.; Kannan, A.] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
   [Ganapathy, Sannasi] Vellore Inst Technol, Ctr Cyber Phys Syst, Chennai, Tamil Nadu, India.
C3 VIT Bhopal University; Vellore Institute of Technology (VIT); VIT
   Vellore; Vellore Institute of Technology (VIT); VIT Vellore; Vellore
   Institute of Technology (VIT); VIT Chennai
RP Kumar, SVNS (corresponding author), Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
EM raja.soundaran@vitbhopal.ac.in; santhoshkumar.svn@vit.ac.in;
   selvi.m@vit.ac.in; sganapathy@vit.ac.in; kannan.a@vit.ac.in
OI M, Selvi/0000-0002-1990-7978
CR Agustsson E, 2019, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2019.00031
   Amiri SA, 2018, MULTIMED TOOLS APPL, V77, P8677, DOI 10.1007/s11042-017-4763-1
   Amirpour H, 2019, IEEE DATA COMPR CONF, P553, DOI 10.1109/DCC.2019.00065
   [Anonymous], 2011, INT J COMPUT APPL T
   [Anonymous], 2015, INT J ENG RES
   BHANU B, 1995, IEEE T SYST MAN CYB, V25, P1543, DOI 10.1109/21.478442
   Brinda T, 2021, SOFT COMPUT, V25, P5807, DOI 10.1007/s00500-021-05645-0
   Cai CL, 2019, IEEE T CIRC SYST VID, V29, P3687, DOI 10.1109/TCSVT.2018.2880492
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Cheng ZX, 2018, PICT COD SYMP, P253, DOI 10.1109/PCS.2018.8456308
   Choi Y, 2019, IEEE I CONF COMP VIS, P3146, DOI 10.1109/ICCV.2019.00324
   Darmanayagam SE, 2013, J DIGIT IMAGING, V26, P496, DOI 10.1007/s10278-012-9539-6
   Dumas T, 2017, INT CONF ACOUST SPEE, P1512, DOI 10.1109/ICASSP.2017.7952409
   Elizabeth DS, 2012, ACM J DATA INF QUAL, V3, DOI 10.1145/2184442.2184444
   Ghrare SE, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATIONS, AND CONTROL TECHNOLOGY (I4CT), P477, DOI 10.1109/I4CT.2014.6914230
   Golts A, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103208
   Guo KR, 2019, INT J FUZZY SYST, V21, P263, DOI 10.1007/s40815-018-0567-3
   Hammouche K, 2008, COMPUT VIS IMAGE UND, V109, P163, DOI 10.1016/j.cviu.2007.09.001
   Hemida O, 2020, MULTIMED TOOLS APPL, V79, P18695, DOI 10.1007/s11042-020-08727-7
   Hui Z, 2020, MULTIMED TOOLS APPL, V79, P24241, DOI 10.1007/s11042-020-09015-0
   Jain, 2015, INT J INF THEORY, V4, P11
   Jeromel A, 2020, MULTIMED TOOLS APPL, V79, P433, DOI 10.1007/s11042-019-08126-7
   Jiang F, 2018, IEEE T CIRC SYST VID, V28, P3007, DOI 10.1109/TCSVT.2017.2734838
   Khan A, 2019, SIGNAL IMAGE VIDEO P, V13, P833, DOI 10.1007/s11760-019-01419-2
   Khan ZF, 2014, J ELECTR ENG TECHNOL, V9, P1426, DOI 10.5370/JEET.2014.9.4.1426
   Khan ZF, 2014, MEAS SCI REV, V14, P94, DOI 10.2478/msr-2014-0013
   Kong FQ, 2020, AD HOC NETW, V107, DOI 10.1016/j.adhoc.2020.102272
   Lan CL, 2010, IEEE T IMAGE PROCESS, V19, P946, DOI 10.1109/TIP.2009.2038636
   Liu ZY, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107254
   MA KK, 1991, INT CONF ACOUST SPEE, P2645, DOI 10.1109/ICASSP.1991.150945
   Oh H, 2013, IEEE T IMAGE PROCESS, V22, P189, DOI 10.1109/TIP.2012.2215616
   Patel MI, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), P1103, DOI [10.1109/iccs45141.2019.9065473, 10.1109/ICCS45141.2019.9065473]
   Perfilieva I, 2021, INFORM SCIENCES, V550, P221, DOI 10.1016/j.ins.2020.10.033
   Petrosino A, 2009, FUZZY SET SYST, V160, P1485, DOI 10.1016/j.fss.2008.11.011
   Prakash A, 2017, IEEE DATA COMPR CONF, P250, DOI 10.1109/DCC.2017.56
   Ranjan R, 2021, WIRELESS PERS COMMUN, V117, P2193, DOI 10.1007/s11277-020-07967-y
   Sweetlin JD, 2016, J INF SCI ENG, V32, P1373
   Uma K, 2016, J MED IMAG HEALTH IN, V6, P763, DOI 10.1166/jmihi.2016.1754
   Vijaya K, 2010, INT J DATA MIN MODEL, V2, P388, DOI 10.1504/IJDMMM.2010.035565
   Wang C, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9173580
   Wang JW, 2020, IEEE T CIRC SYST VID, V30, P2736, DOI 10.1109/TCSVT.2019.2922309
   Wang XY, 2011, PATTERN RECOGN, V44, P777, DOI 10.1016/j.patcog.2010.08.008
   Wang X, 2016, IEEE T COMPUT IMAG, V2, P218, DOI 10.1109/TCI.2016.2575741
   Wang ZX, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103226
   Xu S, 2021, COMPUT ELECTR ENG, V91, DOI 10.1016/j.compeleceng.2021.107069
   Yasin H. M., 2021, Asian J. Res. Comput. Sci, V8, P62, DOI DOI 10.9734/AJRCOS/2021/V8I130193
   Zhang M, 2020, IEEE ACCESS, V8, P40838, DOI 10.1109/ACCESS.2020.2976798
   Zhang YM, 2021, IEEE T MULTIMEDIA, V23, P1069, DOI 10.1109/TMM.2020.2992940
   Zhao SH, 2021, KNOWL-BASED SYST, V229, DOI 10.1016/j.knosys.2021.107284
   Zuo ZY, 2015, OPTIK, V126, P2825, DOI 10.1016/j.ijleo.2015.07.005
NR 50
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42621
EP 42647
DI 10.1007/s11042-022-13475-x
EA JUL 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000832565900002
DA 2024-07-18
ER

PT J
AU Chen, RJ
   Liu, LD
   Zhang, ZL
AF Chen, Ruijie
   Liu, Lidong
   Zhang, Zhaolun
TI Cryptanalysis on a permutation-rewriting- diffusion (PRD) structure
   image encryption scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptanalysis; Chosen-plaintext attack; Chaotic system; PRD structure
ID CHAOTIC MAP; BIT-LEVEL; COMBINATION; CIPHERS; SYSTEM
AB Recently, an efficient pixel-level chaotic image encryption algorithm has been proposed. In this encryption algorithm, they adopted a permutation-rewriting-diffusion (PRD) encryption structure, which enhanced the relationship between permutation and diffusion. At the same time, the generation of the keystream is related to the pixels square sum of the plaintext image. However, there are still two security risks in their encryption scheme. First, both the rewriting and the diffusion operations are performed by modular addition, which makes the two operations equivalent to one-step diffusion operation. Second, the rewriting parameters and the diffusion matrix are both independent of the plaintext. Therefore, the rewriting-diffusion process can be represented by an equivalent modular addition formula, and the PRD structure is equal to the classic PD structure. The separate attack method is used in this paper to crack the encryption scheme. At first, the equivalent diffusion process is cracked by performing the modulo subtraction operation on the target deciphered image and the cipher-text of an all-zero image. Then, the permutation rule is deciphered by constructing several images with the same square sum of pixels. In addition, some improvements for Ye' s encryption scheme are provided to enhance the security.
C1 [Chen, Ruijie; Zhang, Zhaolun] Xidian Univ, Sch Commun Engn, Taibai South Rd, Xian, Shaanxi, Peoples R China.
   [Liu, Lidong; Zhang, Zhaolun] Changan Univ, Sch Informat Engn, Middle Sect Naner Huan Rd, Xian, Shaanxi, Peoples R China.
C3 Xidian University; Chang'an University
RP Chen, RJ (corresponding author), Xidian Univ, Sch Commun Engn, Taibai South Rd, Xian, Shaanxi, Peoples R China.
EM chenruijie@stu.xidian.edu.cn
CR Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Cai ST, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040282
   Cao GH, 2019, MULTIMED TOOLS APPL, V78, P10625, DOI 10.1007/s11042-018-6635-8
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Diab H, 2018, IEEE ACCESS, V6, P42227, DOI 10.1109/ACCESS.2018.2858839
   Fan HJ, 2018, MULTIMED TOOLS APPL, V77, P20103, DOI 10.1007/s11042-017-5437-8
   Feng W, 2019, IEEE ACCESS, V7, P12584, DOI 10.1109/ACCESS.2019.2893760
   Feng W, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2880590
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Hraoui S, 2020, LECT NOTES ELECT ENG, V745
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Li CQ, 2018, IEEE ACCESS, V6, P75834, DOI 10.1109/ACCESS.2018.2883690
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Li Z, 2018, NONLINEAR DYNAM, V94, P1319, DOI 10.1007/s11071-018-4426-4
   Liu LD, 2019, IEEE ACCESS, V7, P185796, DOI 10.1109/ACCESS.2019.2961164
   Liu LD, 2020, IEEE ACCESS, V8, P62785, DOI 10.1109/ACCESS.2020.2983716
   Liu LD, 2020, IEEE ACCESS, V8, P27361, DOI 10.1109/ACCESS.2020.2971759
   Liu LD, 2019, IEEE ACCESS, V7, P126450, DOI 10.1109/ACCESS.2019.2938181
   Liu LD, 2019, CIRC SYST SIGNAL PR, V38, P4096, DOI 10.1007/s00034-019-01043-y
   Liu LD, 2017, IET SIGNAL PROCESS, V11, P869, DOI 10.1049/iet-spr.2016.0709
   Luo YL, 2018, NONLINEAR DYNAM, V93, P1165, DOI 10.1007/s11071-018-4251-9
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Norouzi B, 2016, OPTIK, V127, P5695, DOI 10.1016/j.ijleo.2016.03.076
   Özkaynak F, 2016, OPTIK, V127, P5190, DOI 10.1016/j.ijleo.2016.03.018
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Wang XY, 2021, MULTIMED TOOLS APPL, V80, P10301, DOI 10.1007/s11042-020-10101-6
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wu XL, 2017, IEEE ACCESS, V5, P6429, DOI 10.1109/ACCESS.2017.2692043
   Ye GD, 2018, NONLINEAR DYNAM, V94, P745, DOI 10.1007/s11071-018-4391-y
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
   Ye GD, 2016, J VIB CONTROL, V22, P1171, DOI 10.1177/1077546314534717
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P2066, DOI 10.1016/j.cnsns.2012.12.012
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
   Zhu CX, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20110843
NR 38
TC 5
Z9 5
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4289
EP 4317
DI 10.1007/s11042-022-12515-w
EA JUL 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000830853600003
DA 2024-07-18
ER

PT J
AU Yenegeta, B
   Assabie, Y
AF Yenegeta, Belesti
   Assabie, Yaregal
TI TrachomaNet: Detection and grading of trachoma using texture feature
   based deep convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Feature learning; Gabor filter; Segmentation; Trachoma
AB Trachoma is the leading bacterial infectious cause of blindness worldwide. Examination for clinical signs of trachoma involves careful inspection of the lashes, cornea, eversion of the upper lid, and the tarsal conjunctiva. In this paper, we present a system for automatic detection and grading of trachoma using deep convolutional network. Salient texture features that account for the symptom of the disease are extracted from the eye image using Gabor filters. Then, a texture feature based deep convolutional neural network is used for classification. A 4-way Softmax is used for grading into a specific class (normal, trachomatous scarring, trachomatous trichiasis, and corneal opacity). Although deep learning systems are known to extract and learn features from raw image, we also show that extracting characteristic features still improves the learning capability of deep learning systems. Our model is found to be faster to train and has smaller model size as compared to state-of-the-art models such as AlexNet and GoogLeNet. Furthermore, the model achieved a diagnosis accuracy of 97.9% for detecting and grading trachoma, which improves the accuracies obtained by AlexNet and GoogLeNet by 10% and 3%, respectively.
C1 [Yenegeta, Belesti] Debre Berhan Univ, Dept Software Engn, Debre Berhan, Ethiopia.
   [Assabie, Yaregal] Addis Ababa Univ, Dept Comp Sci, Addis Ababa, Ethiopia.
C3 Addis Ababa University
RP Yenegeta, B (corresponding author), Debre Berhan Univ, Dept Software Engn, Debre Berhan, Ethiopia.
EM belestibdu@gmail.com; yaregal.assabie@aau.edu.et
RI Assabie, Yaregal/AAN-2883-2020
OI Assabie, Yaregal/0000-0001-7591-9298
CR Adrian R., 2017, PyImageSearch
   Al-Bander B, 2017, INT MULTICONF SYST, P207, DOI 10.1109/SSD.2017.8166974
   Alemayehu M, 2005, ASSESSING PREVALANCE, P1
   Amit AB, 2016, 016 INT C WIRELESS C
   [Anonymous], 2018, WHO TRACHOMA
   [Anonymous], WHO BLINDN VIS 2020
   [Anonymous], WHO TRACH
   Brian C, EYE INFECT
   CDC, 2008, Guidelines for the Management of Trachoma in the Northern Territory
   Chen XY, 2015, IEEE ENG MED BIO, P715, DOI 10.1109/EMBC.2015.7318462
   Dong YY, 2017, IEEE CONF IMAGING SY, P127, DOI 10.1109/ist.2017.8261463
   Doshi D, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, ANALYTICS AND SECURITY TRENDS (CAST), P261, DOI 10.1109/CAST.2016.7914977
   Gad A.F., 2018, PRACTICAL COMPUTER V, P183
   Gheisari S, 2021, SCI REP-UK
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gulli A., 2017, Deep learning with Keras
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Juneja M, 2020, MULTIMED TOOLS APPL, V79, P15531, DOI 10.1007/s11042-019-7460-4
   Kanungo YS, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P801, DOI 10.1109/RTEICT.2017.8256708
   Kim MC, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0210463
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li Ma, 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P279
   Minhas S, 2009, INT CONF EMERG TECHN, P252, DOI 10.1109/ICET.2009.5353166
   Mrunalini DM, 2017, 3 INT C COMPUTING CO
   National Board for Professional Teaching Standards, 2016, NAT BOARD CERT RED F 2016 IEEE LONG ISLAN
   Oh K, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-81539-3
   Rajak SN, 2012, SURV OPHTHALMOL, V57, P105, DOI 10.1016/j.survophthal.2011.08.002
   Samar KB., 2013, ATLAS CLIN OPHTHALMO
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   THYLEFORS B, 1987, B WORLD HEALTH ORGAN, V65, P477
   Tian Y., 2017, PR MACH LEARN RES
   Walia Anish Singh, 2019, ACTIVATION FUNCTIONS
   West SK, 2004, PROG RETIN EYE RES, V23, P381, DOI 10.1016/j.preteyeres.2004.04.001
   Yagmur Fatma Demirezen, 2008, 2008 First International Conference on the Applications of Digital Information and Web Technologies, P454, DOI 10.1109/ICADIWT.2008.4664391
   Yemane Berhane Yemane Berhane, 2007, Ethiopian Journal of Health Development, V21, P204
   Yemane Berhane Yemane Berhane, 2007, Ethiopian Journal of Health Development, V21, P185
NR 37
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4209
EP 4234
DI 10.1007/s11042-022-13214-2
EA JUL 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000829140300003
DA 2024-07-18
ER

PT J
AU Rani, S
   Ghai, D
   Kumar, S
AF Rani, Shilpa
   Ghai, Deepika
   Kumar, Sandeep
TI Object detection and recognition using contour based edge detection and
   fast R-CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CLAP; Wireframe; 2D objects; 3D objects; Fast R-CNN; ConvLSTM; Object
   detection; Object recognition
ID NETWORK; SYSTEM
AB Object detection is a technique of computer vision whose primary intent is to detect objects. The objects can be detected from any image or video feeds. Now a day's object detection is extensively applied in video surveillance systems, human tracking, and self-driving cars. This paper presented a novel object detection approach that uses only wireframe-based features. The wireframe of the image is identified by using Cellular logical array processing. This technique can determine the visual and geometric features of the image. This paper focuses on a deep neural network framework to detect the target object in the image. Fast R-CNN is used for the detection of objects. The detection speed is fast because only the wireframe of the image is obtained first and then fed into the Fast RCNN model for detection and classification purposes. The performance of the proposed methodology is evaluated on PASCAL VOC, example-based synthesis dataset and real-time dataset. The proposed methodology gives mean average precision (mAP) 89.4%, 91.33% and 88.1% on PASCAL VOC, example-based and real-time dataset. The experimental analysis demonstrated that our proposed detection method achieves better results than the other state of art methods. The approach is helpful to detect the 2D and 3D objects as well.
C1 [Rani, Shilpa] Lovely Profess Univ, Phagwara, Punjab, India.
   [Ghai, Deepika] Lovely Profess Univ, ECE Dept, Phagwara, Punjab, India.
   [Kumar, Sandeep] Sreyas Inst Engn & Technol, ECE Dept, Hyderabad, India.
C3 Lovely Professional University; Lovely Professional University
RP Rani, S (corresponding author), Lovely Profess Univ, Phagwara, Punjab, India.
EM shilpachoudhary2020@gmail.com; deepika.21507@lpu.co.in;
   er.sandeepsahratia@gmail.com
RI Kumar, Sandeep/ADM-4627-2022; choudhary, shilpa/HKV-1084-2023
OI Kumar, Sandeep/0000-0002-4752-7884; choudhary,
   shilpa/0000-0001-5809-6269
CR Ablavatski A, 2017, IEEE WINT CONF APPL, P971, DOI 10.1109/WACV.2017.113
   Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   Araki Ryosuke, 2020, 2020 IEEE International Conference on Robotics and Automation (ICRA), P10487, DOI 10.1109/ICRA40945.2020.9197251
   Baimukashev D, 2019, MACH LEARN KNOW EXTR, V1, P883, DOI 10.3390/make1030051
   Bhuvaneswari R, 2018, COGN SYST RES, V52, P985, DOI 10.1016/j.cogsys.2018.09.022
   Cao CS, 2015, IEEE I CONF COMP VIS, P2956, DOI 10.1109/ICCV.2015.338
   Chen CJ, 2020, J MANUF SYST, V55, P325, DOI 10.1016/j.jmsy.2020.04.018
   Chen XY, 2021, IEEE T CIRC SYST VID, V31, P715, DOI 10.1109/TCSVT.2020.2987465
   Condat R., 2020, 2020 IEEE 23 INT C I, P1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Elaraby AF, 2018, 2018 IEEE 9TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P247, DOI 10.1109/IEMCON.2018.8615020
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Hu QC, 2016, IEEE T INTELL TRANSP, V17, P1002, DOI 10.1109/TITS.2015.2496795
   Ibrahem H, 2021, IEEE ACCESS, V9, P38742, DOI 10.1109/ACCESS.2021.3064372
   Jiang MX, 2018, COMPLEXITY, DOI 10.1155/2018/4695890
   Kim JU, 2019, IEEE IMAGE PROC, P3995, DOI [10.1109/ICIP.2019.8803439, 10.1109/icip.2019.8803439]
   Kumar, 2021, ADV INTELLIGENT SYST, P1
   Min WD, 2018, SIGNAL PROCESS, V144, P238, DOI 10.1016/j.sigpro.2017.09.024
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI [10.1109/ATNAC.2017.8215431, 10.1109/ICPHM.2017.7998297]
   Raghunandan A, 2018, PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P563, DOI 10.1109/ICCSP.2018.8524461
   Raja R, 2020, WIRELESS PERS COMMUN, V112, P169, DOI 10.1007/s11277-019-07021-6
   Ramík DM, 2014, APPL INTELL, V40, P358, DOI 10.1007/s10489-013-0461-5
   Sharma VK, 2022, J KING SAUD UNIV-COM, V34, P1687, DOI 10.1016/j.jksuci.2019.09.012
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yang X, 2019, SIGNAL PROCESS, V160, P202, DOI 10.1016/j.sigpro.2019.02.029
   Yang Y., 2011, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, page, V1385-1392, P2011, DOI DOI 10.1109/CVPR.2011.5995741
   Yao CL, 2020, IEEE ACCESS, V8, P218739, DOI 10.1109/ACCESS.2020.3042203
   Yao XW, 2021, IEEE T GEOSCI REMOTE, V59, P675, DOI 10.1109/TGRS.2020.2991407
   Zhang JL, 2020, CHIN AUTOM CONGR, P7131, DOI 10.1109/CAC51589.2020.9326543
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang S, 2015, IEEE SENS J, V15, P2679, DOI 10.1109/JSEN.2014.2382174
   Zhao SC, 2018, IEEE T CIRC SYST VID, V28, P1839, DOI 10.1109/TCSVT.2017.2682196
   Zhu KL, 2019, IEEE T VEH TECHNOL, V68, P4275, DOI 10.1109/TVT.2019.2907269
NR 33
TC 14
Z9 14
U1 13
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42183
EP 42207
DI 10.1007/s11042-021-11446-2
EA JUL 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000825246000003
DA 2024-07-18
ER

PT J
AU Moratanch, N
   Chitrakala, S
AF Moratanch, N.
   Chitrakala, S.
TI Anaphora resolved abstractive text summarization (AR-ATS) system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Abstractive summarization; Constraints and preferences- based
   resolution; Number and gender agreement; Semantic filtering; Centre
   preferences; Dominant antecedent identification; Attribute extraction as
   semantic cue
ID FUSION
AB Many people in this world are fond of reading, and text format is regarded as the official way of communication. This has resulted in an increased production of text data in a highly exponential way. consequently, people were looking for a way where they need not have to spend much time in reading the entire information provided by articles, books and so on. Moreover, people are compelled to read entire newspapers or desired articles in a short span of time in the middle of their busy schedules. So, people were looking for a simplified strategy of "Read less, get more content". Summarization of books,0 articles and newspapers reduces the time taken to understand the content present in them. Abstractive text summarization involves summarizing the given text by reorganizing the whole text using syntactic and semantic text analysis. It includes the capability of synthesizing a compressed form of the original sentences or it may constitute novel sentences with the same semantic sense, which may not be present in the original source document. This system focusses on the different algorithms that have been developed to deal with the challenging problem of Anaphora Resolved Abstractive Text Summarization. It produces an abstractive summary that has mismatches between anaphors and their antecedents. The problem of the mapping of events with their source is addressed by the AR-ATS method, which resolves several types of anaphora that are present in prominent and common text document. Anaphora resolution involves mapping the anaphors with their antecedents which allows the semantic analysis more effective and thereby increases the efficiency of the summary produced by the method. Then the anaphora resolved words are semantically analyzed and create a flawless summary of the text document with complete analysis of the events and their sources. The whole system was successfully evaluated by various benchmark datasets, and it was shown that algorithms mentioned earlier are efficient for abstractive summarization of text.
C1 [Moratanch, N.; Chitrakala, S.] Anna Univ, Dept Comp Sci & Engn, Coll Engn, Chennai, Tamil Nadu, India.
C3 Anna University; Anna University Chennai
RP Moratanch, N (corresponding author), Anna Univ, Dept Comp Sci & Engn, Coll Engn, Chennai, Tamil Nadu, India.
EM tancyanbil@gmail.com; chitrakala.au@gmail.com
RI S, Chitrakala/T-9631-2019; N, Dr.Moratanch/HMO-6365-2023; S,
   C/JLK-9983-2023
CR [Anonymous], 2013, APPL MATH SCI
   [Anonymous], 2013, INT C IND POS IND NA
   Antony, 2015, P IEEE
   Antunes J, 2018, COMPUT SPEECH LANG, V52, P141, DOI 10.1016/j.csl.2018.05.004
   Athira S, 2014, 2014 FIRST INTERNATIONAL CONFERENCE ON COMPUTATIONAL SYSTEMS AND COMMUNICATIONS (ICCSC), P47, DOI 10.1109/COMPSC.2014.7032619
   Azmi AM, 2018, INFORM PROCESS MANAG, V54, P903, DOI 10.1016/j.ipm.2018.06.002
   Baldwin B, 1997, Proceedings of the ACL-EACL 1997 Workshop on Operational Factors in Practical, Robust Anaphor Resolution for Unrestricted Texts, P38
   Barzilay R, 2005, COMPUT LINGUIST, V31, P297, DOI 10.1162/089120105774321091
   Belkebir R, 2016, EXPERT SYST APPL, V53, P43, DOI 10.1016/j.eswa.2016.01.007
   Charniak Eugene, 1997, AAAI/IAAI, P598
   Chianese A, 2014, 10TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS SITIS 2014, P477, DOI 10.1109/SITIS.2014.16
   Cilibrasi RL, 2007, IEEE T KNOWL DATA EN, V19, P370, DOI 10.1109/TKDE.2007.48
   Cuomo S, 2017, EXPERT SYST APPL, V79, P101, DOI 10.1016/j.eswa.2017.02.034
   Durrett G, 2016, ARXIV 160308887
   Evans R, 2000, P DISC AN REF RES C, P154
   Gambhir M, 2017, ARTIF INTELL REV, V47, P1, DOI 10.1007/s10462-016-9475-9
   Gatt A, 2009, P 12 EUROPEAN WORKSH, P90
   Ge N, 1998, 6 WORKSH VER LARG CO
   Genest P-E, 2010, TAC
   HOBBS JR, 1978, LINGUA, V44, P311, DOI 10.1016/0024-3841(78)90006-2
   Ingria R., 1989, the 27th Annual Meeting of the ACL, P262
   Kamune Kalyani P., 2015, International Journal of Intelligent Systems and Applications, V7, P56, DOI 10.5815/ijisa.2015.02.08
   Karthikeyan K., 2013, Proceedings of the 2013 International Conference on Pattern Recognition, Informatics and Mobile Engineering (PRIME), P346, DOI 10.1109/ICPRIME.2013.6496498
   Kennedy C., 1996, P 16 C COMPUTATIONAL, P113, DOI DOI 10.3115/992628.992651
   Khan A, 2015, APPL SOFT COMPUT, V30, P737, DOI 10.1016/j.asoc.2015.01.070
   Lappin S., 1994, Computational Linguistics, V20, P535
   Liu F, 2018, ARXIV 180510399
   Lloret E, 2012, ARTIF INTELL REV, V37, P1, DOI 10.1007/s10462-011-9216-z
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Mitkov R., 2002, Computational Linguistics and Intelligent Text Processing. Third International Conference, CICLing 2002. Proceedings (Lecture Notes in Computer Science Vol.2276), P168
   Mitkov R., 2002, ANAPHORA RESOLUTION
   Mitkov Ruslan, 2014, Anaphora resolution
   Moratanch N, 2018, J WEB ENG, V17, P675, DOI 10.13052/jwe1540-9589.1784
   Moratanch N, 2016, PROCEEDINGS OF IEEE INTERNATIONAL CONFERENCE ON CIRCUIT, POWER AND COMPUTING TECHNOLOGIES (ICCPCT 2016)
   Orasan C, 2007, J ARTIF INTELL RES, V29, P79, DOI 10.1613/jair.2179
   Orsan C, 2001, WORKSHOP COMPUTATION, V7, P16
   Piccialli F, 2013, PROCEDIA COMPUT SCI, V18, P2643, DOI 10.1016/j.procs.2013.06.001
   Qiu L, 2004, ARXIV CS0406031
NR 38
TC 3
Z9 3
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4569
EP 4597
DI 10.1007/s11042-022-13299-9
EA JUN 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000812603300003
DA 2024-07-18
ER

PT J
AU Liu, K
   Xu, WR
   Wu, HF
   Yahya, AA
AF Liu, Kui
   Xu, Wanru
   Wu, Haifeng
   Yahya, Ali Abdullah
TI Weighted hybrid order total variation model using structure tensor for
   image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Total variation; Split Bregman; High-order total
   variation; Coherence enhancing filtering
ID PARTIAL-DIFFERENTIAL-EQUATION; NOISE REMOVAL; VARIATION REGULARIZATION
AB A total variation filter has the characteristic of edge protection and has been widely used in image denoising for many years. In this study, our aim was to eliminate the staircase effect generated by the total variation model effectively, while also retaining the edge details. Therefore, we propose a weighted hybrid order total variation model which uses the determinant and trace of the structural tensor to control the smoothness. We used the split Bregman iterative algorithm to numerically solve the corresponding discrete problems. A coherent enhanced diffusion filter was used for preprocessing in each iteration; then, the proposed diffusion function was used for denoising. Numerical experiments show that the model has excellent denoising and edge protection performance.
C1 [Liu, Kui; Xu, Wanru; Wu, Haifeng; Yahya, Ali Abdullah] Anqing Normal Univ, Sch Comp & Informat, Anqing 246011, Anhui, Peoples R China.
   [Liu, Kui; Xu, Wanru; Wu, Haifeng; Yahya, Ali Abdullah] Key Lab Intelligent Percept & Comp Anhui Prov, Anqing 246011, Anhui, Peoples R China.
C3 Anqing Normal University
RP Liu, K (corresponding author), Anqing Normal Univ, Sch Comp & Informat, Anqing 246011, Anhui, Peoples R China.; Liu, K (corresponding author), Key Lab Intelligent Percept & Comp Anhui Prov, Anqing 246011, Anhui, Peoples R China.
EM liukui@aqnu.edu.cn
OI , xu/0000-0001-8864-3948
FU Major Special Science and Technology Project of Anhui Province
   [.201903a06020006]; Key Project of Education Natural Science Research of
   Anhui Province of China [KJ2017A353]
FX This work is supported by Major Special Science and Technology Project
   of Anhui Province (No .201903a06020006) and Key Project of Education
   Natural Science Research of Anhui Province of China (No: KJ2017A353).
CR Adam T, 2019, MULTIDIM SYST SIGN P, V30, P503, DOI 10.1007/s11045-018-0567-3
   Chamorro-Servent J, 2013, J BIOMED OPT, V18, DOI 10.1117/1.JBO.18.7.076016
   Chen Q, 2010, IMAGE VISION COMPUT, V28, P298, DOI 10.1016/j.imavis.2009.04.012
   Chen Y, 2002, J MATH ANAL APPL, V272, P117, DOI 10.1016/S0022-247X(02)00141-5
   Chen Y, 2010, INT CONF ACOUST SPEE, P1574, DOI 10.1109/ICASSP.2010.5495528
   Thanh DNH, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2019.163677
   Feng JC, 2012, APPL OPTICS, V51, P4501, DOI 10.1364/AO.51.004501
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Kamalaveni V, 2017, MULTIMED TOOLS APPL, V76, P18815, DOI 10.1007/s11042-016-4341-y
   Li X, 2021, NUMER ALGORITHMS, V86, P1, DOI 10.1007/s11075-020-00876-y
   Liu XW, 2015, COMPUT MATH APPL, V69, P675, DOI 10.1016/j.camwa.2015.02.011
   Liu XW, 2010, J MATH ANAL APPL, V372, P486, DOI 10.1016/j.jmaa.2010.07.013
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Papafitsoros K, 2014, J MATH IMAGING VIS, V48, P308, DOI 10.1007/s10851-013-0445-4
   Khoa PTD, 2020, OPTIK, V217, DOI 10.1016/j.ijleo.2020.164940
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Setzer S, 2011, INT J COMPUT VISION, V92, P265, DOI 10.1007/s11263-010-0357-3
   Steidl Gabriele., 2015, Jahresbericht der Deutschen Mathematiker-Vereinigung, V117, P133, DOI [10.1365/s13291-015-0113-2, DOI 10.1365/S13291-015-0113-2]
   Wang N, 2019, J ENG-JOE, V2019, P8198, DOI 10.1049/joe.2018.5443
   Wang S, 2018, NUMER ALGORITHMS, V78, P513, DOI 10.1007/s11075-017-0386-x
   Wang Y, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.101590
   Weickert J, 1999, INT J COMPUT VISION, V31, P111, DOI 10.1023/A:1008009714131
   Yang XH, 2019, SIGNAL PROCESS-IMAGE, V73, P84, DOI 10.1016/j.image.2018.02.006
   Zhang XJ, 2019, MULTIMED TOOLS APPL, V78, P18095, DOI 10.1007/s11042-019-7170-y
NR 24
TC 7
Z9 7
U1 5
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 927
EP 943
DI 10.1007/s11042-022-12393-2
EA JUN 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000809322700001
DA 2024-07-18
ER

PT J
AU Nie, X
   Li, HM
AF Nie, Xuan
   Li, Hongmei
TI Gait recognition based on margin sample mining loss
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait recognition; MSM loss; New input method; Convolutional neural
   network
AB Gait recognition, as one of the new biometric techniques, mainly judges and identifies a target pedestrian through its walking posture. Gait recognition is effective at long distances, difficult to camouflage and requires no contact or cooperation with the target pedestrian. However, the accuracy of gait recognition is affected by external factors, such as the shooting angle of the video, the clothes and bags worn by the target. In this paper, we solve the above problems based on two aspects. Firstly, a gait recognition method based on MSM Loss is proposed. In this way we are able to extract more discriminative spatio-temporal features; Secondly, we also introduce a new input method, which makes each input sequence more closely related, thus improving the gait recognition rate. Finally, the proposed method is verified on the CASIA-B and OU-MVLP dataset. In CASIA-B, the average recognition rate is obtained under the walking conditions of normal, with bags and with clothes. With rank-1 accuracy under LT, the method proposed in this paper can reach 96.4% under NM, 89.1% under BG and 71.2% under CL. And under the normal walking conditions, our method performs better compared with the best existing gait recognition methods. And in OU-MVLP, we get 87.5% accuracy.
C1 [Nie, Xuan; Li, Hongmei] Northwestern Polytech Univ, Sch Software, Xian, Peoples R China.
C3 Northwestern Polytechnical University
RP Nie, X (corresponding author), Northwestern Polytech Univ, Sch Software, Xian, Peoples R China.
EM xnie@nwpu.edu.cn
FU 2021 Key Research and Development Plan of Shaanxi Province [2021SF-377]
FX This paper is supported by 2021 Key Research and Development Plan of
   Shaanxi Province (no:2021SF-377).
CR [Anonymous], 2009, 3 INT C IM CRIM DET
   Chao Fan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14213, DOI 10.1109/CVPR42600.2020.01423
   Chao HQ, 2019, AAAI CONF ARTIF INTE, P8126
   Cho CW, 2009, EXPERT SYST APPL, V36, P7033, DOI 10.1016/j.eswa.2008.08.076
   Fu Y, CORR ABS180405275 AR
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   He YW, 2019, IEEE T INF FOREN SEC, V14, P102, DOI 10.1109/TIFS.2018.2844819
   Hermans A, CORR ABS170307737 AR
   Hu MD, 2013, IEEE T INF FOREN SEC, V8, P2034, DOI 10.1109/TIFS.2013.2287605
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Kusakunniran W, 2014, IEEE T IMAGE PROCESS, V23, P696, DOI 10.1109/TIP.2013.2294552
   Lai DTH, 2009, IEEE T INF TECHNOL B, V13, P687, DOI 10.1109/TITB.2009.2022913
   Liu H, 2019, PROC CVPR IEEE, P11939, DOI 10.1109/CVPR.2019.01222
   Nixon MS, 1999, IEEE C MOT AN TRACK
   Park SW, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040688
   Park SW, REV GENERATIVE ADVER
   Phillips PJ, 2002, IEEE IMAGE PROC, P49
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Shiraga K, 2016, INT CONF BIOMETR
   Stevenage SV, 1999, APPL COGNITIVE PSYCH, V13, P513, DOI 10.1002/(SICI)1099-0720(199912)13:6<513::AID-ACP616>3.0.CO;2-8
   Sun JN, 2020, IEEE T MULTIMEDIA, V22, P2833, DOI 10.1109/TMM.2020.2966863
   Takemura Noriko, 2018, IPSJ Transactions on Computer Vision and Applications, V10, DOI 10.1186/s41074-018-0039-6
   Tariq M, 2017, 23 INT C AUTOMATION, P17
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Xiang Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13306, DOI 10.1109/CVPR42600.2020.01332
   Xiao Q, CORR ABS171000478 AR
   Xue W, 2020, NEUROCOMPUTING, V380, P95, DOI 10.1016/j.neucom.2019.11.015
   Yu SQ, 2006, INT C PATT RECOG, P441
   Yu SQ, 2017, IEEE COMPUT SOC CONF, P532, DOI 10.1109/CVPRW.2017.80
   Yu SQ, 2017, NEUROCOMPUTING, V239, P81, DOI 10.1016/j.neucom.2017.02.006
NR 30
TC 0
Z9 0
U1 5
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 969
EP 987
DI 10.1007/s11042-022-13019-3
EA JUN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000809534700001
DA 2024-07-18
ER

PT J
AU Dhopavkar, TA
   Nayak, SK
   Roy, S
AF Dhopavkar, Tejas Atul
   Nayak, Sanjeet Kumar
   Roy, Satyabrata
TI IETD: a novel image encryption technique using Tinkerbell map and
   Duffing map for IoT applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic maps; Lightweight image encryption; NPCR and UACI; Zigzag
   scrambling
ID MANAGEMENT; SECURITY
AB In many sensitive Internet-of-Things (IoT) based applications, sensor devices send information in the form of images. Chaos theory is the study of deterministic laws that exhibit characteristics like unpredictability, randomness and irregularity. These characteristics can be used to encrypt images thus providing an extra layer of security over the existing security infrastructure of the IoT application. In this work, we present a symmetric image encryption algorithm called, IETD which is suitable for IoT applications. Here, we propose a new chaotic map named "TD Map" using Tinkerbell Map and Duffing Map. We also propose an advanced zigzag algorithm that can encrypt color images of any resolution. The "TD Map" is used to generate a 2-D chaotic sequence which is utilized by simple operations like scrambling and swapping to encrypt the image. The proposed scheme has undergone many statistical tests and analyses to evaluate its performance against cryptanalysis attacks, noise, data loss, correlation immunity and so on which show that it achieves better values in each of the standard metrics under consideration than the existing ciphers. MSE, PSNR, information entropy, NPCR and UACI values show that the proposed scheme is at par with the existing schemes. Moreover, it has exhibited good energy efficiency and is easy to implement in hardware. These altogether make IETD a suitable lightweight cipher to deploy in real-time IoT applications.
C1 [Dhopavkar, Tejas Atul] Vivekanand Educ Societys Inst Technol, Dept Comp Engn, Mumbai 400074, Maharashtra, India.
   [Nayak, Sanjeet Kumar] Indian Inst Informat Technol Design & Mfg, Dept Comp Sci & Engn, Chennai 600127, Tamil Nadu, India.
   [Roy, Satyabrata] Manipal Univ Jaipur, Dept Comp Sci & Engn, Jaipur, Rajasthan, India.
C3 Indian Institute of Information Technology, Design & Manufacturing,
   Kancheepuram; Manipal University Jaipur
RP Nayak, SK (corresponding author), Indian Inst Informat Technol Design & Mfg, Dept Comp Sci & Engn, Chennai 600127, Tamil Nadu, India.
EM tejasdhopavkar2000@gmail.com; sanjeetn@iiitdm.ac.in;
   satyabrata.roy@jaipur.manipal.edu
OI Nayak, Sanjeet Kumar/0000-0003-4290-0632
FU Research Funding programme of Data Security Council of India (DSCI)
FX This work is supported by Research Funding programme of Data Security
   Council of India (DSCI).
CR Agarwal N, 2019, MULTIMED TOOLS APPL, V78, P8603, DOI 10.1007/s11042-018-7128-5
   Alassaf N, 2019, MULTIMED TOOLS APPL, V78, P32633, DOI 10.1007/s11042-018-6801-z
   Arnold V. I., 1968, ERGODIC PROBLEMS CLA
   Babaei A, 2020, OPTIK, V203, DOI 10.1016/j.ijleo.2019.164000
   Broumandnia A, 2019, FUTURE GENER COMP SY, V99, P489, DOI 10.1016/j.future.2019.04.005
   Choi US, 2020, MULTIMED TOOLS APPL, V79, P22825, DOI 10.1007/s11042-020-09033-y
   Dai JY, 2021, QUANTUM INF PROCESS, V20, DOI 10.1007/s11128-021-03187-w
   Derhamy H, 2017, IEEE INTERNET THINGS, V4, P1754, DOI 10.1109/JIOT.2017.2697718
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Dong CE, 2014, SIGNAL PROCESS-IMAGE, V29, P628, DOI 10.1016/j.image.2013.09.006
   Enayatifar R, 2019, OPT LASER ENG, V115, P131, DOI 10.1016/j.optlaseng.2018.11.017
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Gong LH, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501424
   Griffin J., 2013, The sine map
   Heuer J, 2015, COMPUTER, V48, P34, DOI 10.1109/MC.2015.152
   Hu XC, 2020, IEEE ACCESS, V8, P12452, DOI 10.1109/ACCESS.2020.2965740
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Khan MA, 2018, FUTURE GENER COMP SY, V82, P395, DOI 10.1016/j.future.2017.11.022
   Kimbahune VV, 2017, INT J AMBIENT COMPUT, V8, P50, DOI 10.4018/IJACI.2017010103
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Mhetre NA, 2016, INT J AMBIENT COMPUT, V7, P33, DOI 10.4018/IJACI.2016070102
   Mishra M, 2014, INT J INFORM COMPUTA
   Muñoz-Guillermo M, 2021, INFORM SCIENCES, V552, P352, DOI 10.1016/j.ins.2020.11.045
   Nadeem A, 2005, 2005 INT C INF COMM, P8489
   Nayak P, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P412, DOI 10.1109/ICACCI.2018.8554728
   Nayak SK, 2021, IEEE T SERV COMPUT, V14, P876, DOI 10.1109/TSC.2018.2820713
   Neshenko N, 2019, IEEE COMMUN SURV TUT, V21, P2702, DOI 10.1109/COMST.2019.2910750
   Noura M, 2019, MOBILE NETW APPL, V24, P796, DOI 10.1007/s11036-018-1089-9
   Omoniwa B, 2019, IEEE INTERNET THINGS, V6, P4118, DOI 10.1109/JIOT.2018.2875544
   Parashar Deepika, 2018, Cyber Security. Proceedings of CSI 2015. Advances in Intelligent Systems and Computing (AISC 729), P59, DOI 10.1007/978-981-10-8536-9_7
   Prasithsangaree P, 2003, GLOB TELECOMM CONF, P1445, DOI 10.1109/GLOCOM.2003.1258477
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Roy S, 2021, MULTIMED TOOLS APPL, V80, P31529, DOI 10.1007/s11042-020-09880-9
   Roy S, 2020, J AMB INTEL HUM COMP, V11, P5083, DOI 10.1007/s12652-020-01813-6
   Roy S, 2019, IEEE ACCESS, V7, P39782, DOI 10.1109/ACCESS.2019.2906326
   Roy S, 2016, PROCEDIA COMPUT SCI, V78, P408, DOI 10.1016/j.procs.2016.02.082
   Sanchez-Avila C, 2001, 35TH ANNUAL 2001 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P229, DOI 10.1109/CCST.2001.962837
   Som S, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON BUSINESS AND INFORMATION MANAGEMENT (ICBIM)
   Stoyanov B, 2014, SCI WORLD J, DOI 10.1155/2014/283639
   Tong XJ, 2013, NONLINEAR DYNAM, V72, P229, DOI 10.1007/s11071-012-0707-5
   Wang XY, 2020, OPT LASER TECHNOL, V131, DOI 10.1016/j.optlastec.2020.106366
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Yan LY, 2021, MULTIMED TOOLS APPL, V80, P14363, DOI 10.1007/s11042-020-10310-z
   Yang YC, 2017, IEEE INTERNET THINGS, V4, P1250, DOI 10.1109/JIOT.2017.2694844
   Yuan SL, 2011, INT J BIFURCAT CHAOS, V21, P3137, DOI 10.1142/S0218127411030581
   Zarebnia M, 2019, OPTIK, V179, P761, DOI 10.1016/j.ijleo.2018.10.025
   Zear A, 2022, MULTIMED TOOLS APPL, V81, P26721, DOI 10.1007/s11042-020-10472-w
   Zhang XM, 2004, IEEE T VLSI SYST, V12, P957, DOI 10.1109/TVLSI.2004.832943
   Zhang YQ, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106040
   Zhou J, 2017, IEEE COMMUN MAG, V55, P26, DOI 10.1109/MCOM.2017.1600363CM
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
   Zhou NR, 2020, QUANTUM INF PROCESS, V19, DOI 10.1007/s11128-020-02794-3
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
NR 56
TC 6
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43189
EP 43228
DI 10.1007/s11042-022-13162-x
EA MAY 2022
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800825900006
DA 2024-07-18
ER

PT J
AU Mondal, K
   Rabidas, R
   Dasgupta, R
AF Mondal, Kalimuddin
   Rabidas, Rinku
   Dasgupta, Rajdeep
TI Single image haze removal using contrast limited adaptive histogram
   equalization based multiscale fusion technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image dehazing; Degraded images; Enhancing; Fusion
ID VISIBILITY; MODEL; RESTORATION; WEATHER; FILTER
AB Outdoor photography is often affected by a common problem termed haze which causes poor visibility of distant objects. This occurs mainly due to the absorption and scattering of light by atmospheric particles. To mitigate the issue, this paper proposes a contrast-limited adaptive histogram equalization based multiscale fusion (CLAHEMSF) technique where two images are derived by applying white balance and contrast limited adaptive histogram equalization technique from a hazy image. Although the quality of the image is improved, it still suffers from the noise problem inherent due to adaptive histogram equalization and lower visibility in dense hazy regions. Hence, controlled contrast enhancement inhomogeneous areas are leveraged to overcome the prior issue while the latter one is taken care of by utilizing luminance, chromatic, and saliency weight maps along with an effective fusion technique. Moreover, the guided image filter is employed to preserve the structure and smoothing, which generates images with enhanced visibility as observed after various experimentation. Several empirical analyses are carried out on a large variety of images from hazy datasets, including HazeRD datasets. The proposed technique is evaluated using qualitative and quantitative analyses and obtained the mean square error, structural similarity, and peak signal-to-noise ratio of 1788.63, 0.848, and 15.143, respectively. The proposed technique can achieve enhanced visibility with preserved structure and vivid color compared to other state-of-the-art methods. The algorithm can also be used in several applications such as surveillance, traffic monitoring, runway hazard detection, obstacle tracking, etc.
C1 [Mondal, Kalimuddin; Dasgupta, Rajdeep] Natl Inst Technol Silchar, Dept Elect & Instrumentat Engn, Silchar 788010, Assam, India.
   [Rabidas, Rinku] Assam Univ, Dept Elect & Commun Engn, Silchar 788011, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar; Assam University
RP Mondal, K (corresponding author), Natl Inst Technol Silchar, Dept Elect & Instrumentat Engn, Silchar 788010, Assam, India.
EM kalim008@gmail.com
RI MONDAL, KALIMUDDIN/AAT-4224-2021
OI MONDAL, KALIMUDDIN/0000-0001-8059-6454; Dasgupta,
   Rajdeep/0000-0002-9175-5657
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Al-Ameen Zohair, 2016, International Journal of Intelligent Systems and Applications, V8, P10, DOI 10.5815/ijisa.2016.08.02
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   [Anonymous], 2007, Color Constancy
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chaudhury KN, 2011, IEEE T IMAGE PROCESS, V20, P3376, DOI 10.1109/TIP.2011.2159234
   Fan Guo, 2013, International Journal of Digital Content Technology and its Applications, V7, P19, DOI 10.4156/jdcta.vol7.issue1.3
   Fan XL, 2019, MULTIMED TOOLS APPL, V78, P17653, DOI 10.1007/s11042-018-7103-1
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Finlayson GD, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P37
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He LY, 2018, NEUROCOMPUTING, V293, P29, DOI 10.1016/j.neucom.2018.02.089
   Huang SC, 2014, IEEE T CIRC SYST VID, V24, P1814, DOI 10.1109/TCSVT.2014.2317854
   Huang SQ, 2020, IEEE ACCESS, V8, P100870, DOI 10.1109/ACCESS.2020.2997985
   Jiang B, 2018, MULTIMED TOOLS APPL, V77, P13513, DOI 10.1007/s11042-017-4973-6
   Koschmieder H, 1924, BEITRAGE PHYS FREIEN, V2
   Li Y, 2015, IEEE I CONF COMP VIS, P226, DOI 10.1109/ICCV.2015.34
   Li Y, 2014, LECT NOTES COMPUT SC, V8690, P174, DOI 10.1007/978-3-319-10605-2_12
   Liu PJ, 2019, IEEE T IMAGE PROCESS, V28, P2212, DOI 10.1109/TIP.2018.2823424
   Liu W, 2016, IET IMAGE PROCESS, V10, P996, DOI 10.1049/iet-ipr.2016.0308
   Luan Z, 2017, NEUROCOMPUTING, V245, P10, DOI 10.1016/j.neucom.2017.03.024
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mondal K, 2021, J CIRCUIT SYST COMP, V30, DOI 10.1142/S021812662150078X
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tarel JP, 2010, IEEE INT VEH SYM, P478, DOI 10.1109/IVS.2010.5548128
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   van de Weijer J, 2005, IEEE IMAGE PROC, P2069
   Wang CY, 2020, MIDWEST SYMP CIRCUIT, P1036, DOI [10.1109/MWSCAS48704.2020.9184525, 10.1109/mwscas48704.2020.9184525]
   Wang JB, 2015, NEUROCOMPUTING, V149, P718, DOI 10.1016/j.neucom.2014.08.005
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZY, 2017, COGN COMPUT, V9, P468, DOI 10.1007/s12559-017-9458-4
   Yeh CH, 2020, IEEE T IMAGE PROCESS, V29, P3153, DOI 10.1109/TIP.2019.2957929
   Zhang YF, 2017, IEEE IMAGE PROC, P3205, DOI 10.1109/ICIP.2017.8296874
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu YY, 2018, NEUROCOMPUTING, V275, P499, DOI 10.1016/j.neucom.2017.08.055
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 43
TC 6
Z9 6
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 15413
EP 15438
DI 10.1007/s11042-021-11890-0
EA MAY 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000797759700001
DA 2024-07-18
ER

PT J
AU Hyun, C
   Hur, C
   Park, H
AF Hyun, Changhun
   Hur, Chan
   Park, Hyeyoung
TI An image selection framework for automatic report generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic report generation; Automatic image selection; Image retrieval;
   Image re-ranking; Image filtering
ID TEXT
AB The development of IoT technologies and social network services (SNS) are contributing to the growth of big data. However, the vast amount of data makes it difficult for users to find the information they need, and as a result, the demand for a system that provides the desired information in a well-organized form is increasing. Many studies are being conducted to extract desired information from data, and application studies such as automatic report generation are also being conducted. To generate a report for a given topic, a report generation system is required to extract essential information from big data and re-organize it in a compact form. Image selection system also plays an important role in automatic report generation as insertion of appropriate images can increase the completeness and readability of the report. In this study, we propose an image selection framework for recommending an appropriate image for a part of a report by combining textual information used in text-based image retrieval and visual features used in content-based image retrieval. In addition, the proposed image selection framework adopts an image filtering module that is specially designed for filtering out some images that are not suitable for use in reports. Through experiments on two datasets and comparative experiment with state-of-the-art work, we confirmed that our proposed method recommends images that fit the user's intention, and its practical applicability.
C1 [Hyun, Changhun; Hur, Chan; Park, Hyeyoung] Kyungpook Natl Univ, Comp Sci Engn, Daegu, South Korea.
C3 Kyungpook National University
RP Park, H (corresponding author), Kyungpook Natl Univ, Comp Sci Engn, Daegu, South Korea.
EM chhyun@knu.ac.kr; chanhur94@gmail.com; hypark@knu.ac.kr
FU Human Resources Program in Energy Technology of the Korea Institute of
   Energy Technology Evaluation and Planning (KETEP) from the Ministry of
   Trade, Industry & Energy, Republic of Korea [20204010600060]; Institute
   of Information & communications Technology Planning & Evaluation (IITP)
   - Korea government (MSIT) [2021-0-02068]
FX This work was supported by the Human Resources Program in Energy
   Technology of the Korea Institute of Energy Technology Evaluation and
   Planning(KETEP) granted financial resource from the Ministry of Trade,
   Industry & Energy, Republic of Korea (No. 20204010600060). This work was
   supported by Institute of Information & communications Technology
   Planning & Evaluation (IITP) grant funded by the Korea government(MSIT)
   (No. 2021-0-02068, Artificial Intelligence Innovation Hub).
CR Alkhawlani Mohammed, 2015, International Journal of Computer and Information Technology, V4, P58
   Cer D, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P169
   Chaudhary C, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3375786
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J., 2018, BERT PRE TRAINING DE
   GUDIVADA VN, 1995, COMPUTER, V28, P18, DOI 10.1109/2.410145
   He JR, 2006, IEEE T IMAGE PROCESS, V15, P3170, DOI 10.1109/TIP.2006.877491
   Ide I, 2017, IEEE INT SYM MULTIM, P304, DOI 10.1109/ISM.2017.54
   Jing BY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2577
   Joulin A., 2016, ARXIV PREPREINT ARXI
   Latif A, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/9658350
   Li W, 2011, IEEE I CONF COMP VIS, P2049, DOI 10.1109/ICCV.2011.6126478
   Liang JW, 2018, PROC CVPR IEEE, P6135, DOI 10.1109/CVPR.2018.00642
   Liu FY, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3396520
   Liu PZ, 2017, IEEE T IMAGE PROCESS, V26, P5706, DOI 10.1109/TIP.2017.2736343
   Liu X, 2008, LECT NOTES COMPUT SC, V4987, P141
   Luo B, 2003, P SOC PHOTO-OPT INS, V5018, P123, DOI 10.1117/12.476329
   Mikolov Tomas, 2013, EFFICIENT ESTIMATION
   Neto JL, 2002, LECT NOTES ARTIF INT, V2507, P205
   Noh Y, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P2169, DOI 10.1145/3397271.3401409
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Qian XM, 2017, IEEE T IMAGE PROCESS, V26, P3734, DOI 10.1109/TIP.2017.2699623
   Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13
   Rongrong Ji, 2008, Proceedings of the SPIE - The International Society for Optical Engineering, V6822, P682226, DOI 10.1117/12.767024
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su JH, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P129, DOI 10.1109/BigMM.2016.26
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Vu X.-S., 2015, KNOWLEDGE SYSTEMS EN, P233, DOI DOI 10.1007/978-3-319-11680-8_19
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Yang SJ, 2019, IEEE T MULTIMEDIA, V21, P2916, DOI 10.1109/TMM.2019.2912735
   Yang XP, 2016, IEEE T IMAGE PROCESS, V25, P4617, DOI 10.1109/TIP.2016.2593653
   Yang YF, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P87
   Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763
   Zhao WH, 2018, GEO-SPAT INF SCI, V21, P115, DOI 10.1080/10095020.2018.1441754
   Zhong SH, 2015, EXPERT SYST APPL, V42, P8146, DOI 10.1016/j.eswa.2015.05.034
NR 37
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 41175
EP 41197
DI 10.1007/s11042-022-13120-7
EA MAY 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000797297600001
PM 35600634
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Li, LH
   Luo, YL
   Qiu, SH
   Ouyang, X
   Cao, LC
   Tang, SB
AF Li, Lanhang
   Luo, Yuling
   Qiu, Senhui
   Ouyang, Xue
   Cao, Lvchen
   Tang, Shunbin
TI Image encryption using chaotic map and cellular automata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Cellular automata; SHA-256; Chaotic maps
ID SCHEME; SYSTEM; ROBUST
AB Recent encryption schemes are not sensitive enough to plain-images, which leads to low robustness and easy vulnerability to attacks. By employing chaotic maps and Cellular Automata, a novel image encryption algorithm is proposed in this work to increase the sensitivity to plain-images and improve security. Firstly, initial values of the two-dimensional Logistic-Sine-Coupling Map and the Logistic-Sine-Cosine Map are calculated by the SHA-256 of the original image, and the process of diffusion is conducted. Secondly, the key matrices are produced by iterating chaotic maps in the process of permutation. The diffused image is scrambled by the index matrices, which are produced by sorting every row or column of the key matrices. Finally, the scrambled image is transformed into cipher-image by using Cellular Automata. Experimental results and theoretical analysis show that the proposed scheme has good security as it can effectively resist various attacks.
C1 [Li, Lanhang; Luo, Yuling; Qiu, Senhui; Ouyang, Xue; Cao, Lvchen; Tang, Shunbin] Guangxi Normal Univ, Sch Elect Engn, Guilin, Peoples R China.
C3 Guangxi Normal University
RP Luo, YL (corresponding author), Guangxi Normal Univ, Sch Elect Engn, Guilin, Peoples R China.
EM yuling0616@gxnu.edu.cn
OI Luo, Yuling/0000-0002-0117-4614
FU National Natural Science Foundation of China [61801131]; Overseas 100
   Talents Program of Guangxi Higher Education; 2018 Guangxi One Thousand
   Young and Middle-Aged College; University Backbone Teachers Cultivation
   Program
FX This research was supported by the National Natural Science Foundation
   of China under Grant 61801131, the funding of Overseas 100 Talents
   Program of Guangxi Higher Education, 2018 Guangxi One Thousand Young and
   Middle-Aged College and University Backbone Teachers Cultivation
   Program.
CR Abbasi AA, 2020, OPTIK, V219, DOI 10.1016/j.ijleo.2020.164949
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Babaei A, 2020, OPTIK, V203, DOI 10.1016/j.ijleo.2019.164000
   Chai XL, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/2/020504
   Chai XL, 2021, INFORM SCIENCES, V556, P305, DOI 10.1016/j.ins.2020.10.007
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen JX, 2015, OPT LASER ENG, V66, P1, DOI 10.1016/j.optlaseng.2014.08.010
   Dennunzio A, 2019, INFORM SCIENCES, V486, P73, DOI 10.1016/j.ins.2019.02.023
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Lambic D, 2017, NONLINEAR DYNAM, V89, P2255, DOI 10.1007/s11071-017-3583-1
   Luo YL, 2019, SIGNAL PROCESS, V161, P227, DOI 10.1016/j.sigpro.2019.03.022
   Luo YL, 2019, IEEE ACCESS, V7, P38507, DOI 10.1109/ACCESS.2019.2906052
   Luo YL, 2018, IEEE ACCESS, V6, P77740, DOI 10.1109/ACCESS.2018.2884013
   Luo YL, 2018, MULTIMED TOOLS APPL, V77, P26191, DOI 10.1007/s11042-018-5844-5
   Luo YL, 2018, NONLINEAR DYNAM, V93, P1165, DOI 10.1007/s11071-018-4251-9
   Luo YL, 2016, NONLINEAR DYNAM, V83, P2293, DOI 10.1007/s11071-015-2481-7
   Luo YL, 2015, COMMUN NONLINEAR SCI, V20, P447, DOI 10.1016/j.cnsns.2014.05.022
   Mondal B, 2019, J INF SECUR APPL, V45, P117, DOI 10.1016/j.jisa.2019.01.010
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Ping P, 2018, SIGNAL PROCESS, V150, P233, DOI 10.1016/j.sigpro.2018.04.018
   Ping P, 2014, SIGNAL PROCESS, V105, P419, DOI 10.1016/j.sigpro.2014.06.020
   Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P9355, DOI 10.1007/s11042-018-6516-1
   Su YR, 2019, SIGNAL PROCESS-IMAGE, V72, P134, DOI 10.1016/j.image.2018.12.008
   Wang XY, 2020, CHAOS SOLITON FRACT, V141, DOI 10.1016/j.chaos.2020.110309
   Wang XY, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106501
   Wang XY, 2020, OPT LASER TECHNOL, V131, DOI 10.1016/j.optlastec.2020.106366
   Wang XY, 2018, OPT LASER ENG, V107, P370, DOI 10.1016/j.optlaseng.2017.06.015
   Wang XY, 2018, OPT LASER ENG, V103, P1, DOI 10.1016/j.optlaseng.2017.11.009
   WOLFRAM S, 1986, ADV APPL MATH, V7, P123, DOI 10.1016/0196-8858(86)90028-X
   Wu XJ, 2018, MULTIMED TOOLS APPL, V77, P12349, DOI 10.1007/s11042-017-4885-5
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Zhou MJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107484
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 39
TC 8
Z9 8
U1 4
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40755
EP 40773
DI 10.1007/s11042-022-12621-9
EA MAY 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000795177900006
DA 2024-07-18
ER

PT J
AU Fernandes, FE
   Nonato, LG
   Ueyama, J
AF Fernandes jr, Francisco E.
   Nonato, Luis Gustavo
   Ueyama, Jo
TI A river flooding detection system based on deep learning and computer
   vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE River flooding detection; Semantic segmentation; Deep learning; Computer
   vision
ID NEURAL-NETWORKS; HEALTH; IMPACTS
AB Although floods cause millions of dollars in economic and social losses each year, many people living in developing countries, such as Brazil, do not have access to a flooding alert system because of its cost. To address this issue, we propose a cheap and robust River Flooding Detection System, which can be easily deployed in any river with a flat surface at its bedside. The novelty of our system is the use of raw images from off-the-shelf cameras with no preprocessing required. Hence, our methodology can be deployed using existing surveillance cameras in urban environments. The proposed system measures the river level by first performing a semantic segmentation of the river water blade using Deep Neural Networks (DNNs). Then, it uses Computer Vision (CV) to estimate the water level. If the water level is near or above a dangerous threshold, it sends alerts automatically without human intervention. Moreover, our system can successfully measure a river's water level with a Mean Absolute Error (MAE) of 3.32 cm, which is enough to detect when a river is about to overflow. The system is also reliable in measuring a river's water level from different camera viewpoints and lighting conditions. We show our approach's viability and evaluate our prototype's performance and overhead by deploying it to monitor two urban rivers in the city of Sao Carlos, SP, Brazil.
C1 [Fernandes jr, Francisco E.; Nonato, Luis Gustavo; Ueyama, Jo] Univ Sao Paulo, Inst Math & Comp Sci, Sao Carlos, SP, Brazil.
C3 Universidade de Sao Paulo
RP Fernandes, FE (corresponding author), Univ Sao Paulo, Inst Math & Comp Sci, Sao Carlos, SP, Brazil.
EM feferna@icmc.usp.br; gnonato@icmc.usp.br; joueyama@icmc.usp.br
RI Ueyama, Jo/HHN-1418-2022; Fernandes Junior, Francisco
   Erivaldo/AAH-6055-2019; Nonato, Luis Gustavo/D-5782-2011
OI Ueyama, Jo/0000-0002-5591-3750; Fernandes Junior, Francisco
   Erivaldo/0000-0003-2301-8820; 
FU Sao Paulo Research Foundation (FAPESP) [2020/05426-0]
FX The authors would like to thank the SAo Paulo Research Foundation
   (FAPESP), grant 2020/05426-0, for the financial support used to complete
   this work. The views expressed are those of the authors and do not
   reflect the official policy or position of the SAo Paulo Research
   Foundation.
CR Al Qundus J, 2020, ANN OPER RES, DOI 10.1007/s10479-020-03754-x
   Alderman K, 2012, ENVIRON INT, V47, P37, DOI 10.1016/j.envint.2012.06.003
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   [Anonymous], 2021, IMAGENET BENCHMARK I
   [Anonymous], 2011, Journal of the Brazilian Computer Society, DOI [10.1007/s13173-011-0029-3, DOI 10.1007/S13173-011-0029-3]
   Arshad B, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19225012
   Baczyk A, 2017, ADV INTELL SYST, V543, P610, DOI 10.1007/978-3-319-48923-0_65
   Barratt J, 2019, ARXIV 190704658
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Du WW, 2010, PREHOSP DISASTER MED, V25, P265, DOI 10.1017/S1049023X00008141
   Fernandes FE Jr, 2021, IEEE T NEUR NET LEAR, V32, P5664, DOI 10.1109/TNNLS.2020.3027308
   Fernandes FE Jr, 2021, INFORM SCIENCES, V558, P91, DOI 10.1016/j.ins.2020.12.086
   Furquim G, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030907
   Furquim G, 2015, LECT NOTES COMPUT SC, V9375, P485, DOI 10.1007/978-3-319-24834-9_56
   Geirhos Robert, 2018, Advances in Neural Information Processing Systems, P7549
   Guo Z, 2020, ARXIV 200408340
   Haddad EA, 2015, HABITAT INT, V45, P106, DOI 10.1016/j.habitatint.2014.06.023
   Hagan M. T., 2014, NEURAL NETWORK DESIG
   Hapuarachchi HAP, 2011, HYDROL PROCESS, V25, P2771, DOI 10.1002/hyp.8040
   Kafli N, 2017, 2017 IEEE 7 INT C UN, P16
   Kamilaris A, 2018, ARXIV 180711805
   Kang WC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092915
   Khan T A, 2018, 2018 2 INT C SMART S
   Kim K, 2007, P 6 WSEAS INT C SIGN, P2530
   Krzhizhanovskaya VV, 2011, PROCEDIA COMPUT SCI, V4, P106, DOI 10.1016/j.procs.2011.04.012
   Levine S, 2018, INT J ROBOT RES, V37, P421, DOI 10.1177/0278364917710318
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Y, 2018, PROCEDIA COMPUT SCI, V139, P529, DOI 10.1016/j.procs.2018.10.237
   Liu Y, 2016, PROCEDIA COMPUT SCI, V91, P566, DOI 10.1016/j.procs.2016.07.144
   Lopez-Fuentes L, 2017, 2017 IEEE INT C BIG
   Mahdianpari M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071119
   Noar NAZM, 2017, 2017 IEEE 4TH INTERNATIONAL CONFERENCE ON SMART INSTRUMENTATION, MEASUREMENT AND APPLICATION (ICSIMA 2017)
   Ortigossa E. S., 2015, WORKSH UND WORKS CON
   Pan J, 2018, IEEE ACCESS, V6, P73561, DOI 10.1109/ACCESS.2018.2883702
   Paterson DL, 2018, CLIN INFECT DIS, V67, P1450, DOI 10.1093/cid/ciy227
   Polydoros A S, 2015, 2015 IEEERSJ INT C I
   Popescu D, 2015, 2015 19 INT C SYSTEM
   Redmon J., 2016, 2016 IEEE C COMPUT V
   Roccetti M., 2020, P 6 EAI INT C SMART, P216, DOI [10.1145/3411170.3411254, DOI 10.1145/3411170.3411254]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S P, 2017, 2017 INT C COMPUTER
   Subeesh A, 2019, LECT NOTE NETW SYST, V55, P297, DOI 10.1007/978-981-13-2324-9_30
   Sylvain JD, 2019, ISPRS J PHOTOGRAMM, V156, P14, DOI 10.1016/j.isprsjprs.2019.07.010
   Wirawan W, 2008, 2008 14 AS PAC C COM, P15
   Yang SN, 2020, WATER-SUI, V12, DOI 10.3390/w12061578
   Yosinski J, 2014, ADV NEUR IN, V27
NR 50
TC 4
Z9 4
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40231
EP 40251
DI 10.1007/s11042-022-12813-3
EA MAY 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000791638100008
DA 2024-07-18
ER

PT J
AU Yogeswararao, G
   Malmathanraj, R
   Palanisamy, P
AF Yogeswararao, G.
   Malmathanraj, R.
   Palanisamy, P.
TI Fractional weighted nuclear norm based two dimensional linear
   discriminant features for cucumber leaf disease recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Linear discriminant analysis; Fractional weight; Nuclear norm; Support
   vector machine; Cucumber leaf diseases
ID CLASSIFICATION; IDENTIFICATION; 2DLDA
AB The quality and quantity of agricultural products are significantly affected by plant diseases. The plant diseases could be mitigated if identified at an early stage. In general, the assessment of plant diseases is performed by human raters. There are some disadvantages in recognizing the plant disease in the leaves when observed by human raters. In this research work, an alternate machine learning based feature extraction technique named fractional weighted nuclear norm based two-dimensional linear discriminant analysis (FNN-2DLDA) is proposed to identify the cucumber leaf diseases. The proposed machine learning approach mainly comprises of three phases: firstly, the nuclear norm reveals the spatial relationship between pixels in each leaf image. Secondly, the fractional weight is assigned to weaken the effect of edge class problem (when a greater number of disease classes are present). Finally, the multi-class hierarchical support vector machine (HSVM) classifier is implemented to recognize the cucumber leaf diseases. The proposed machine learning based system contribute to protection and enhancement of leaf species thus resulting in environmental and Gross Domestic Product (GDP) improvement of the nation. The performance metrics, viz. similarity index, recognition rate, confusion matrix based statistical measurements and hypothesis test results of the proposed technique are compared with the existing start-of-the-art techniques. The disease recognition accuracy of the proposed techniques is 87.5%, 88%, 85% and also 95% of confidence in statistical hypothesis testing of unilateral and bilateral procedures. The results show that the proposed FNN-2DLDA technique outperforms the existing techniques which is attributed to the incorporation of nuclear norm and fractional weight into conventional 2DLDA.
C1 [Yogeswararao, G.; Malmathanraj, R.; Palanisamy, P.] Natl Inst Technol Trichy, Dept Elect & Commun Engn, Tiruchirappalli, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Yogeswararao, G (corresponding author), Natl Inst Technol Trichy, Dept Elect & Commun Engn, Tiruchirappalli, India.
EM yogi.gurubelli@gmail.com
RI Yogeswararao, Gurubelli/ADN-0953-2022
CR Aakif A, 2015, BIOSYST ENG, V139, P66, DOI 10.1016/j.biosystemseng.2015.08.003
   Al Bashish Dheeb, 2011, Information Technology Journal, V10, P267, DOI 10.3923/itj.2011.267.275
   Arivazhagan S., 2013, Agricultural Engineering International: CIGR Journal, V15, P211
   Bai XB, 2017, COMPUT ELECTRON AGR, V136, P157, DOI 10.1016/j.compag.2017.03.004
   Chaki J, 2015, PATTERN RECOGN LETT, V58, P61, DOI 10.1016/j.patrec.2015.02.010
   Chouhan SS, 2018, IEEE ACCESS, V6, P8852, DOI 10.1109/ACCESS.2018.2800685
   El Sghair M., 2017, INT J AGR SCI, V2, P1
   Gavhale KR, 2014, IOSR J COMPUT ENG IO, V16, P10, DOI DOI 10.9790/0661-16151016
   Gayathri Devi T., 2018, INT J PURE APPL MATH, V119, P3477
   Gurubelli Y, 2019, COMPUT ELECTRON AGR, V162, P95, DOI 10.1016/j.compag.2019.03.036
   Gutte V. S., 2016, International Journal of Engineering Science, V7100
   Kanjalkar L., 2014, INT J ADV RES COMPUT, V3, P153
   Kaur S, 2018, IET IMAGE PROCESS, V12, P1038, DOI 10.1049/iet-ipr.2017.0822
   Kheirkhah FM, 2019, IET COMPUT VIS, V13, P369, DOI 10.1049/iet-cvi.2018.5028
   Lee S, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI [10.14722/ndss.2017.23457, 10.1016/j.patcog.2017.05.015]
   Li X, 2010, NEUROCOMPUTING, V73, P2571, DOI 10.1016/j.neucom.2010.05.016
   Lu YW, 2019, IEEE T CIRC SYST VID, V29, P941, DOI 10.1109/TCSVT.2018.2822761
   Ma JC, 2018, COMPUT ELECTRON AGR, V154, P18, DOI 10.1016/j.compag.2018.08.048
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Padmanaban K. R. A., 2016, Indian J. Sci. Technol., V9, P1, DOI DOI 10.17485/ijst/2016/v9i29/93880
   Rumpf T, 2010, COMPUT ELECTRON AGR, V74, P91, DOI 10.1016/j.compag.2010.06.009
   Tharwat A, 2017, AI COMMUN, V30, P169, DOI 10.3233/AIC-170729
   Valliammal N., 2012, INT J COMPUT SCI ISS, V9, P212
   Wang HX, 2014, IEEE T CYBERNETICS, V44, P828, DOI 10.1109/TCYB.2013.2273355
   Xu GQ, 2019, IET IMAGE PROCESS, V13, P2328, DOI 10.1049/iet-ipr.2018.6551
   Yang WK, 2010, NEUROCOMPUTING, V73, P1556, DOI 10.1016/j.neucom.2009.12.025
   Yang X., 2017, Eur. J. BioMed. Res., V3, P6, DOI DOI 10.18088/EJBMR.3.1.2017.PP6-9
   Zhang FL, 2015, IEEE T NEUR NET LEAR, V26, P2247, DOI 10.1109/TNNLS.2014.2376530
   Zhang P, 2019, NEUROCOMPUTING, V339, P94, DOI 10.1016/j.neucom.2019.01.066
   Zhang SW, 2015, J ANIM PLANT SCI, V25, P42
   Zhang SW, 2019, COMPUT ELECTRON AGR, V162, P422, DOI 10.1016/j.compag.2019.03.012
   Zhang SW, 2017, COMPUT ELECTRON AGR, V134, P135, DOI 10.1016/j.compag.2017.01.014
   Zhao C, 2015, PATTERN RECOGN, V48, P3203, DOI 10.1016/j.patcog.2015.04.004
   Zhong FJ, 2013, IEEE T IMAGE PROCESS, V22, P3018, DOI 10.1109/TIP.2013.2253476
NR 34
TC 4
Z9 4
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38735
EP 38755
DI 10.1007/s11042-022-13013-9
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787666500004
DA 2024-07-18
ER

PT J
AU Sirajudeen, A
   Balasubramaniam, A
   Karthikeyan, S
AF Sirajudeen, A.
   Balasubramaniam, Anuradha
   Karthikeyan, S.
TI Novel angular binary pattern (NABP) and kernel based convolutional
   neural networks classifier for cataract detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cataract; Novel Angular Binary Pattern (NABP); Kernel Based
   Convolutional Neural Networks; Color features; Texture features and
   Shape features
ID IMAGES
AB Cataract is considered as one of the foremost causes of blindness, especially among older people. In India, by the age 80, nearly half of older population either have cataract or they performed surgery for it. To avoid worse effects in eyesight like complete blindness or blurred vision, it is essential that cataract cases are detected in the initial stages for effective treatment. For detecting eye cataracts, the machines utilizing are exhibiting portability issues. Hence, this study is using digital image processing algorithms for the detection and classification of cataract on eye images along with its severity. Initially, the features such as color, shape and texture are extracted separately. Significantly, Novel Angular Binary Pattern- NABP is proposed for the texture feature extraction. The classification of images are performed in this study using the proposed Kernel Based Convolutional Neural Network after the feature extraction process. For all three feature types, the results are obtained separately. Performance of the proposed system is comparatively analyzed in terms of Accuracy, Sensitivity, Specificity, Precision, Recall and F - measure. In addition, comparative analysis is undertaken with respect to texture, colour and shape features. Classification results of the proposed system for varying epochs are also analyzed. Thus, all the analytical results confirmed the outstanding performance of the proposed system than conventional systems for cataract detection with 97.3% accuracy.
C1 [Sirajudeen, A.] Auroras Sci & Technol Inst, Dept Elect & Commun Engn, Ghatkesar, Telangana, India.
   [Balasubramaniam, Anuradha] Sri Eshwar Coll Engn, Dept ECE, Coimbatore, Tamil Nadu, India.
   [Karthikeyan, S.] Chaitanya Bharathi Inst Technol, Dept ECE, Proddatur, Andhra Pradesh, India.
C3 Chaitanya Bharathi Institute of Technology
RP Sirajudeen, A (corresponding author), Auroras Sci & Technol Inst, Dept Elect & Commun Engn, Ghatkesar, Telangana, India.
EM srjdna@gmail.com; anuradha.b@sece.ac.in; meckarthikkct@gmail.com
RI A, SIRAJUDEEN/IAQ-1443-2023
CR Agarwal S, 2021, ARTIF INTELL, P103
   Ahmad Hanaa Mohsin, 2020, 2020 1st. Information Technology To Enhance e-learning and Other Application (IT-ELA), P93, DOI 10.1109/IT-ELA50150.2020.9253120
   Ahmed H. M., 2021, Engineering and Technology Journal, V39, P11, DOI DOI 10.30684/ETJ.V39I1B.1363
   Amirtha, 2018, CATARACT CLASSIFICAT, P71
   Cao LC, 2020, INFORM FUSION, V53, P196, DOI 10.1016/j.inffus.2019.06.022
   Daruich A, 2018, J AAPOS, V22, P44, DOI 10.1016/j.jaapos.2017.09.009
   Gali HE, 2019, CURR OPIN OPHTHALMOL, V30, P13, DOI 10.1097/ICU.0000000000000542
   Goh JHL, 2020, ASIA-PAC J OPHTHALMO, V9, P88, DOI 10.1097/01.APO.0000656988.16221.04
   Gour N, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2020.102329
   Holennavar V, 2017, INT J RES ADV DEV IJ, V1, P77
   Imran A., 2020, VISUAL COMPUT, V37, P11, DOI [10.1109/IST.2014.6958452, DOI 10.1109/IST.2014.6958452]
   Imran A, 2019, IEEE ACCESS, V7, DOI 10.1109/ACCESS.2019.2935912
   Jiang JW, 2021, FRONT MED-LAUSANNE, V8, DOI 10.3389/fmed.2021.664023
   Kaur J., 2021, Data Intelligence and Cognitive Informatics, P543
   Kim Mingue, 2018, Korean J Ophthalmol, V32, P172, DOI 10.3341/kjo.2017.0067
   Kolhe S., 2016, INT J INNOV RES SCI, V5, P23
   Kumar BR, 2017, J NETW COMMUN EMERG, V7
   Lin H, 2021, ARTIF INTELL OPHTHAL, P203
   Liu YC, 2017, LANCET, V390, P600, DOI 10.1016/S0140-6736(17)30544-5
   Manchalwar M., 2017, INT J ENG TECHNOL IJ
   Ouabida E, 2018, PHYS MEDICA, V48, P37, DOI 10.1016/j.ejmp.2018.03.014
   Pahuja Rahul, 2022, Proceedings of Data Analytics and Management: ICDAM 2021. Lecture Notes on Data Engineering and Communications Technologies (90), P719, DOI 10.1007/978-981-16-6289-8_59
   Podkowinski D, 2017, J OPHTHALMOL, V2017, DOI 10.1155/2017/8148047
   Pratap T, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2021.105927
   Shaheen I, 2019, EAI SPRINGER INNOVAT, P35, DOI 10.1007/978-3-319-96139-2_4
   Shehzad M., 2020, LIFE SCI J, V17, P44, DOI [10.7537/marslsj170820.07, DOI 10.7537/MARSLSJ170820.07]
   Shetty A., 2021, EMERGING TECHNOLOGIE, V3, P919
   Simamora W. S., 2020, Journal of Physics: Conference Series, V1566, DOI 10.1088/1742-6596/1566/1/012037
   Soni Akanksha, 2021, Proceedings of Research and Applications in Artificial Intelligence. RAAI 2020. Advances in Intelligent Systems and Computing (AISC 1355), P267, DOI 10.1007/978-981-16-1543-6_25
   Sreejaya MK, 2017, INT RES J ENG TECHNO, V4, P1517
   Sreejaya MK, 2017, VARIOUS CATARACT DET
   Tawfik H. R., 2018, International Journal of Computer and Information Engineering, V12, P1038
   Tripathi P, 2022, COMPUT VIS IMAGE UND, V214, DOI 10.1016/j.cviu.2021.103303
   Weni I., 2021, IJCCS (Indo. J. Comput. Cyber. Syst.), V15, P75, DOI [10.22146/ijccs.61882, DOI 10.22146/IJCCS.61882]
   Xiong L, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/5645498
   Xu X, 2021, J BIOMED INFORM, V124, DOI 10.1016/j.jbi.2021.103939
   Xu X, 2020, IEEE J BIOMED HEALTH, V24, P556, DOI 10.1109/JBHI.2019.2914690
   Yang JJ, 2016, COMPUT METH PROG BIO, V124, P45, DOI 10.1016/j.cmpb.2015.10.007
   Zafar R, 2018, CURR MED IMAGING REV, V14, P251, DOI 10.2174/1573405613666170331103423
   Zhou Y, 2020, IEEE T MED IMAGING, V39, P436, DOI 10.1109/TMI.2019.2928229
NR 40
TC 2
Z9 2
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38485
EP 38512
DI 10.1007/s11042-022-13092-8
EA APR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787139200001
DA 2024-07-18
ER

PT J
AU Zhang, WW
   Li, JJ
   Hua, Z
AF Zhang, Wanwan
   Li, Jinjiang
   Hua, Zhen
TI Near-infrared shadow detection based on HDR image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Near-infrared information; High dynamic range image; Shadow detection
ID HISTOGRAM EQUALIZATION; FUSION
AB High dynamic range images have higher contrast, which can provide more dynamic range and image details to reflect the visual effects in the real environment better, while dark objects tend to have higher near-infrared reflectivity in the near-infrared spectrum. After studying these two tasks in depth, we propose a novel method for detecting shadows based on high dynamic range images and near-infrared information. The proposed method takes advantage of the characteristics of high dynamic range images for pre-processing before shadow detection. The low dynamic range images are firstly converted into high dynamic range images by increasing the dynamic range and contrast enhancement, and then proceeding to the next step of shadow detection. In this way, we can further perform shadow detection on the basis of establishing an accurate and clear shadow map. The key point of shadow detection is to distinguish between shadows and dark objects, which can be improved by the near-infrared information of images. In the process of shadow detection, high dynamic range image obtained in the previous step and the corresponding near-infrared image undergo some operations to obtain a determined shadow map, which includes the process of images' multiplication and division. Finally, the shadow mask is obtained through adaptive thresholding. Quantitative comparison and qualitative analysis show that our method is superior to other shadow detection methods in accuracy and computational efficiency.
C1 [Zhang, Wanwan] Shandong Technol & Business Univ, Sch Informat & Elect Engn, Yantai 264005, Peoples R China.
   [Li, Jinjiang] Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Peoples R China.
   [Hua, Zhen] ICT, Inst Network Technol, Yantai 264005, Peoples R China.
C3 Shandong Technology & Business University; Shandong Technology &
   Business University
RP Li, JJ (corresponding author), Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Peoples R China.
EM lijinjiang@gmail.com
RI Hua, Zhen/AGN-6068-2022; zhang, wan/AAA-6279-2022
FU National Natural Science Foundation of China [61772319, 62002200,
   62176140, 12001327]; Shandong Natural Science Foundation of China
   [ZR2020QF012, ZR2021MF068]
FX This research was supported by the National Natural Science Foundation
   of China (61772319, 62002200, 62176140, 12001327), Shandong Natural
   Science Foundation of China (ZR2020QF012, ZR2021MF068).
CR [Anonymous], 2020, REMOTE SENS-BASEL, V2864, P17
   Awad M, 2020, IEEE T COMPUT IMAG, V6, P408, DOI 10.1109/TCI.2019.2956873
   Brown M, 2011, PROC CVPR IEEE, P177, DOI 10.1109/CVPR.2011.5995637
   Chen ZH, 2020, PROC CVPR IEEE, P5610, DOI 10.1109/CVPR42600.2020.00565
   Deng JY, 2017, I S INTELL SIG PROC, P554, DOI 10.1109/ISPACS.2017.8266540
   Ding B, 2019, IEEE I CONF COMP VIS, P10212, DOI 10.1109/ICCV.2019.01031
   Fang H, 2019, IEEE J-STARS, V12, P2695, DOI 10.1109/JSTARS.2019.2917605
   Farou B, 2017, COMPUT INFORM, V36, P837, DOI 10.4149/cai_2017_4_837
   Hou L, 2021, IEEE T PATTERN ANAL, V43, P1337, DOI 10.1109/TPAMI.2019.2948011
   Hu XW, 2018, PROC CVPR IEEE, P7454, DOI 10.1109/CVPR.2018.00778
   Huo YQ, 2016, IET IMAGE PROCESS, V10, P198, DOI 10.1049/iet-ipr.2014.0782
   Jang H, 2020, IEEE ACCESS, V8, P38554, DOI 10.1109/ACCESS.2020.2975857
   Johnson AK, 2015, NAT CONF COMPUT VIS
   Ibarra-Arenado MJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041012
   Kandhway P, 2019, MULTIDIM SYST SIGN P, V30, P1859, DOI 10.1007/s11045-019-00633-y
   Khekade Ashwini, 2015, 2015 International Conference on Futuristic Trends on Computational Analysis and Knowledge Management (ABLAZE). Proceedings, P144, DOI 10.1109/ABLAZE.2015.7154984
   Kinoshita Y, 2019, DEEP INVERSE TONE MA
   Lee S, 2018, LECT NOTES COMPUT SC, V11206, P613, DOI 10.1007/978-3-030-01216-8_37
   Lee S, 2018, IEEE ACCESS, V6, P49913, DOI 10.1109/ACCESS.2018.2868246
   Li JJ, 2021, IEEE T CIRC SYST VID, V31, P4227, DOI 10.1109/TCSVT.2021.3049940
   Li JJ, 2020, COMPUT VIS MEDIA, V6, P169, DOI 10.1007/s41095-020-0172-x
   Li Ru, 2021, ARXIV210201850
   Lin YH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19214743
   Liu XX, 2020, COMPUT VIS MEDIA, V6, P467, DOI 10.1007/s41095-020-0181-9
   Luo JS, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420590259
   Macedo MCF, 2020, J REAL-TIME IMAGE PR, V17, P479, DOI 10.1007/s11554-018-0799-3
   Majeed SH, 2020, IEEE ACCESS, V8, P144218, DOI 10.1109/ACCESS.2020.3014453
   Marnerides D, 2018, COMPUT GRAPH FORUM, V37, P37, DOI 10.1111/cgf.13340
   Mertens T, 2009, COMPUT GRAPH FORUM, V28, P161, DOI 10.1111/j.1467-8659.2008.01171.x
   Mohajerani S, 2019, IEEE T IMAGE PROCESS, V28, P4117, DOI 10.1109/TIP.2019.2904267
   Mostafa Y, 2017, IEEE GEOSCI REMOTE S, V14, P494, DOI 10.1109/LGRS.2017.2650996
   Ning SY, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1383, DOI 10.1109/ICASSP.2018.8462444
   Perez-Pellitero E, 2021, IEEE COMPUT SOC CONF, P691, DOI 10.1109/CVPRW53098.2021.00078
   Qiu S, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420540014
   Raheja P., 2020, 2020 IEEE INT C MULT, P1
   Raveendranath A, 2016, INT CONF COMMUN SYST, P120, DOI 10.1109/CSN.2016.7823999
   Rüfenacht D, 2014, IEEE T PATTERN ANAL, V36, P1672, DOI 10.1109/TPAMI.2013.229
   Shao Q, 2020, J SUPERCOMPUT, V76, P3308, DOI 10.1007/s11227-018-2558-4
   Sharif SMA, 2021, IEEE COMPUT SOC CONF, P550, DOI 10.1109/CVPRW53098.2021.00067
   Sharma D, 2019, PFG-J PHOTOGRAMM REM, V87, P103, DOI 10.1007/s41064-019-00070-3
   Shazwani AN, 2016, 2016 6TH IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE), P407, DOI 10.1109/ICCSCE.2016.7893608
   Sheet D, 2010, IEEE T CONSUM ELECTR, V56, P2475, DOI 10.1109/TCE.2010.5681130
   Shor Y, 2008, COMPUT GRAPH FORUM, V27, P577, DOI 10.1111/j.1467-8659.2008.01155.x
   Tian JD, 2016, PATTERN RECOGN, V51, P85, DOI 10.1016/j.patcog.2015.09.006
   Nguyen V, 2017, IEEE I CONF COMP VIS, P4520, DOI 10.1109/ICCV.2017.483
   Wang JF, 2018, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR.2018.00192
   Wang Q, 2013, PATTERN RECOGN LETT, V34, P34, DOI 10.1016/j.patrec.2012.06.002
   Wang TY, 2020, PROC CVPR IEEE, P1877, DOI 10.1109/CVPR42600.2020.00195
   Xie WH, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATIONS (CSA), P95, DOI 10.1109/CSA.2015.60
   Yahya AA, 2019, MULTIMED TOOLS APPL, V78, P15545, DOI 10.1007/s11042-018-6955-8
   Yarlagadda SK, 2018, IEEE SW SYMP IMAG, P9, DOI 10.1109/SSIAI.2018.8470343
   Zhang TL, 2023, CURR PSYCHOL, V42, P21860, DOI 10.1007/s12144-022-03276-8
   Zhang XF, 2021, COMPUT VIS MEDIA, V7, P513, DOI 10.1007/s41095-021-0239-3
   Zheng QL, 2019, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2019.00531
   Zhu L, 2018, LECT NOTES COMPUT SC, V11210, P122, DOI 10.1007/978-3-030-01231-1_8
   Zhu QM, 2020, PATTERN RECOGN LETT, V136, P71, DOI 10.1016/j.patrec.2020.03.030
NR 56
TC 1
Z9 1
U1 3
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38459
EP 38483
DI 10.1007/s11042-022-12996-9
EA APR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787139200007
DA 2024-07-18
ER

PT J
AU Yang, LR
   Zhou, QH
AF Yang, Liran
   Zhou, Qinghua
TI Transfer subspace learning joint low-rank representation and feature
   selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised domain adaptation; Transfer subspace learning; Low-rank
   representation; Feature selection; Graph embedding
ID VISUAL DOMAIN ADAPTATION; KERNEL; ALGORITHM
AB Transfer learning is proposed to solve a general problem in practical applications faced by traditional machine learning methods, that is, the training and test data have different distributions. This paper provides a novel transfer subspace learning method combining low-rank representation (LRR) and feature selection for unsupervised domain adaptation. The core of the proposed method is to map both the source and target data into a latent subspace by a projection such that the discrepancy between domains is reduced. Specifically, by using LRR, a low-rank constraint is imposed on the reconstruction coefficient matrix, and thus the global structure of data can be preserved. Moreover, a structured sparsity-inducing norm based regularization term is introduced into the domain adaptation, which leads to imposing a row-sparsity constraint on the projection matrix. This constraint can enforce rows of the projection matrix corresponding to inessential feature attributes to be all zeros, and thus select relevant features across two domains. As a result, the proposed method has good interpretability and can adaptively perform feature selection. Furthermore, taking into account that the projected samples should be close to each other in the shared subspace if they belong to the same class, regardless of which domain they originally come from, we introduce graph embedding to characterize the local manifold structures of data so as to preserve the relationships between examples in the subspace. Finally, we mathematically formulate the proposed method and derive an iterative algorithm to solve the corresponding problem. The exhaustive experimental evaluations on public datasets confirm the effectiveness of the proposed method in comparison with several state-of-the-art methods.
C1 [Yang, Liran] North China Elect Power Univ, Dept Comp, Baoding 071003, Peoples R China.
   [Zhou, Qinghua] Beijing Normal Univ, Sch Appl Math, Zhuhai 519085, Zhuhai, Peoples R China.
C3 North China Electric Power University; Beijing Normal University;
   Beijing Normal University Zhuhai
RP Zhou, QH (corresponding author), Beijing Normal Univ, Sch Appl Math, Zhuhai 519085, Zhuhai, Peoples R China.
EM qinghua.zhou@gmail.com
FU opening foundation of Engineering Research Center of Intelligent
   Computing for Complex Energy Systems, Ministry of Education; Natural
   Science Foundation of Guangdong province [2018A0303130026]; Teacher
   Research Capacity Promotion Program of Beijing Normal University, Zhuhai
FX The authors would like to thank the editors and reviewers for their
   constructive comments and suggestions which can help improve the quality
   of the paper. This work was supported by the opening foundation of
   Engineering Research Center of Intelligent Computing for Complex Energy
   Systems, Ministry of Education. This work was also supported by the
   Natural Science Foundation of Guangdong province (Grant No.
   2018A0303130026) and the Teacher Research Capacity Promotion Program of
   Beijing Normal University, Zhuhai.
CR [Anonymous], 2001, Proceedings of the 18th International Conference on Machine Learning, ICML '01
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Busto PP, 2020, IEEE T PATTERN ANAL, V42, P413, DOI 10.1109/TPAMI.2018.2880750
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Chen WY, 2019, IEEE T IMAGE PROCESS, V28, P4620, DOI 10.1109/TIP.2019.2912126
   Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPRW.2009.5206747, 10.1109/CVPR.2009.5206747]
   Ganin Y, 2016, J MACH LEARN RES, V17
   Ghifary M, 2017, IEEE T PATTERN ANAL, V39, P1414, DOI 10.1109/TPAMI.2016.2599532
   Gong B., 2013, P INT C MACH LEARN, P222
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   He F, 2020, IEEE T NEUR NET LEAR, V31, P626, DOI 10.1109/TNNLS.2019.2908504
   He ZH, 2020, MULTIMED TOOLS APPL, V79, P33973, DOI 10.1007/s11042-020-08877-8
   Jhuo IH, 2012, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2012.6247924
   Jing MM, 2020, NEURAL NETWORKS, V130, P39, DOI 10.1016/j.neunet.2020.06.016
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu F, 2020, IEEE T NEUR NET LEAR, V31, P5588, DOI 10.1109/TNNLS.2020.2973293
   Liu F, 2018, IEEE T FUZZY SYST, V26, P3555, DOI 10.1109/TFUZZ.2018.2836364
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Long MS, 2018, ADV NEUR IN, V31
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Long MS, 2014, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2014.183
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Lu H, 2018, IEEE T IMAGE PROCESS, V27, P3403, DOI 10.1109/TIP.2018.2819503
   Luo LK, 2020, IEEE T CYBERNETICS, V50, P3914, DOI 10.1109/TCYB.2019.2962000
   Ni J, 2013, PROC CVPR IEEE, P692, DOI 10.1109/CVPR.2013.95
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Peng JT, 2019, IEEE GEOSCI REMOTE S, V16, P972, DOI 10.1109/LGRS.2018.2889789
   Pereira LAM, 2018, PATTERN RECOGN, V75, P235, DOI 10.1016/j.patcog.2017.04.011
   Razzaghi P, 2019, KNOWL-BASED SYST, V163, P174, DOI 10.1016/j.knosys.2018.08.026
   Shao M, 2014, INT J COMPUT VISION, V109, P74, DOI 10.1007/s11263-014-0696-6
   Si S, 2010, IEEE T KNOWL DATA EN, V22, P929, DOI 10.1109/TKDE.2009.126
   Tahmoresnezhad J, 2017, KNOWL INF SYST, V50, P585, DOI 10.1007/s10115-016-0944-x
   Tzeng E., 2014, ARXIV14123474
   Wang JD, 2017, IEEE DATA MINING, P1129, DOI 10.1109/ICDM.2017.150
   Wang W, 2019, PATTERN RECOGN, V85, P185, DOI 10.1016/j.patcog.2018.07.035
   Wang YY, 2020, KNOWL-BASED SYST, V192, DOI 10.1016/j.knosys.2019.105344
   Xiang SM, 2012, IEEE T NEUR NET LEAR, V23, P1738, DOI 10.1109/TNNLS.2012.2212721
   Xie Y, 2020, KNOWL-BASED SYST, V192, DOI 10.1016/j.knosys.2019.105222
   Xu F, 2018, IEEE INTELL SYST, V33, P78, DOI 10.1109/MIS.2018.012001555
   Xu Y, 2016, IEEE T IMAGE PROCESS, V25, P850, DOI 10.1109/TIP.2015.2510498
   Yan HL, 2020, IEEE T MULTIMEDIA, V22, P2420, DOI 10.1109/TMM.2019.2953375
   Yang J., 2007, P 15 ACM INT C MULT, P188
   Yang JF, 2009, SIAM J IMAGING SCI, V2, P569, DOI 10.1137/080730421
   Yang LR, 2020, KNOWL-BASED SYST, V207, DOI 10.1016/j.knosys.2020.106394
   Yang LR, 2020, MULTIMED TOOLS APPL, V79, P3031, DOI 10.1007/s11042-019-08474-4
   Yao Y, 2019, KNOWL-BASED SYST, V163, P656, DOI 10.1016/j.knosys.2018.09.027
   Zhang JX, 2019, PATTERN RECOGN, V90, P196, DOI 10.1016/j.patcog.2019.01.027
   Zhang L, 2019, IEEE T CIRC SYST VID, V29, P1339, DOI 10.1109/TCSVT.2018.2842206
   Zhang WJ, 2020, KNOWL INF SYST, V62, P3641, DOI 10.1007/s10115-020-01466-z
   Zhang YH, 2014, EXPERT SYST APPL, V41, P2372, DOI 10.1016/j.eswa.2013.09.035
   Zhang Z, 2015, IEEE T KNOWL DATA EN, V27, P2362, DOI 10.1109/TKDE.2013.182
NR 54
TC 2
Z9 2
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38353
EP 38373
DI 10.1007/s11042-022-12504-z
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000785933700020
DA 2024-07-18
ER

PT J
AU Dewi, C
   Chen, RC
   Jiang, XY
   Yu, H
AF Dewi, Christine
   Chen, Rung-Ching
   Jiang, Xiaoyi
   Yu, Hui
TI Deep convolutional neural network for enhancing traffic sign recognition
   developed on Yolo V4
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Yolo V4; Yolo V3; Spatial pyramid pooling; Object recognition; CNN
ID IMAGES
AB Traffic sign detection (TSD) is a key issue for smart vehicles. Traffic sign recognition (TSR) contributes beneficial information, including directions and alerts for advanced driver assistance systems (ADAS) and Cooperative Intelligent Transport Systems (CITS). Traffic signs are tough to detect in practical autonomous driving scenes using an extremely accurate real-time approach. Object detection methods such as Yolo V4 and Yolo V4-tiny consolidated with Spatial Pyramid Pooling (SPP) are analyzed in this paper. This work evaluates the importance of the SPP principle in boosting the performance of Yolo V4 and Yolo V4-tiny backbone networks in extracting features and learning object features more effectively. Both models are measured and compared with crucial measurement parameters, including mean average precision (mAP), working area size, detection time, and billion floating-point number (BFLOPS). Experiments show that Yolo V4_1 (with SPP) outperforms the state-of-the-art schemes, achieving 99.4% accuracy in our experiments, along with the best total BFLOPS (127.26) and mAP (99.32%). In contrast with earlier studies, the Yolo V3 SPP training process only receives 98.99% accuracy for mAP with IoU 90.09. The training mAP rises by 0.44% with Yolo V4_1 (mAP 99.32%) in our experiment. Further, SPP can enhance the achievement of all models in the experiment.
C1 [Dewi, Christine; Chen, Rung-Ching] Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan.
   [Dewi, Christine] Satya Wacana Christian Univ, Fac Informat Technol, Central Java, Salatiga, Indonesia.
   [Jiang, Xiaoyi] Univ Munster, Dept Math & Comp Sci, D-48149 Munster, Germany.
   [Yu, Hui] Univ Portsmouth, Sch Creat Technol, Portsmouth, Hants, England.
C3 Chaoyang University of Technology; Universitas Kristen Satya Wacana;
   University of Munster; University of Portsmouth
RP Chen, RC (corresponding author), Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan.
EM crching@cyut.edu.tw
RI Yu, Hui/G-1115-2018; Dewi, Christine/AAL-9605-2021
OI Yu, Hui/0000-0002-7655-9228; Dewi, Christine/0000-0002-1284-234X
FU Ministry of Science and Technology, Taiwan [MOST-107-2221-E-324 -018
   -MY2, MOST-109-2622-E-324 -004]; Chaoyang University of Technology
   (CYUT); Higher Education Sprout Project, Ministry of Education (MOE),
   Taiwan
FX This paper is supported by the Ministry of Science and Technology,
   Taiwan. The Nos are MOST-107-2221-E-324 -018 -MY2 and
   MOST-109-2622-E-324 -004, Taiwan. This research is also partially
   sponsored by Chaoyang University of Technology (CYUT) and Higher
   Education Sprout Project, Ministry of Education (MOE), Taiwan, under the
   project name: "The R&D and the cultivation of talent for
   health-enhancement products."
CR Avramovic A, 2020, IEEE ACCESS, V8, P189855, DOI 10.1109/ACCESS.2020.3031191
   Balali V, 2015, VIS ENG, V3, P1, DOI [DOI 10.1186/S40327-015-0027-1, 10.1186/s40327-015-0027-1]
   Basbug AM, 2019, IEEE INT C SEMANT CO, P128, DOI [10.1109/ICSC.2019.00029, 10.1109/ICOSC.2019.8665547]
   Berkaya SK, 2016, EXPERT SYST APPL, V48, P67, DOI 10.1016/j.eswa.2015.11.018
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Bochkovskiy Alexey, 2020, DARKNET OPEN SOURCE
   Chen HP, 2019, IEEE ACCESS, V7, P157818, DOI 10.1109/ACCESS.2019.2950053
   Chen RC, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00327-4
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Dewi Christine, 2020, ICCMS '20: Proceedings of the 12th International Conference on Computer Modeling and Simulation, P51, DOI 10.1145/3408066.3408078
   Dewi C, 2022, NEURAL COMPUT APPL, V34, P21465, DOI 10.1007/s00521-021-05982-z
   Dewi C, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11072913
   Dewi C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060889
   Dewi C, 2019, INT CONF AWARE SCI, P282, DOI 10.1109/icawst.2019.8923404
   Dewi C, 2019, IEEE SYS MAN CYBERN, P2496, DOI 10.1109/SMC.2019.8913868
   Dewi C, 2019, INT J INNOV COMPUT I, V15, P2027, DOI 10.24507/ijicic.15.06.2027
   Ellahyani A, 2016, APPL SOFT COMPUT, V46, P805, DOI 10.1016/j.asoc.2015.12.041
   Geng KK, 2020, IEEE ACCESS, V8, P88227, DOI 10.1109/ACCESS.2020.2990636
   Ghiasi G, 2018, ADV NEUR IN, V31
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Guo F, 2021, AUTOMAT CONSTR, V125, DOI 10.1016/j.autcon.2021.103596
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Houben S, 2013, IEEE INT C INTELL TR, P7, DOI 10.1109/ITSC.2013.6728595
   Huibai Wang, 2020, 2020 IEEE 9th Joint International Information Technology and Artificial Intelligence Conference (ITAIC), P1946, DOI 10.1109/ITAIC49862.2020.9339181
   Kang HW, 2020, COMPUT ELECTRON AGR, V168, DOI 10.1016/j.compag.2019.105108
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Le QV, 2019, Learning data augmentation strategies for object detection
   Lee HS, 2018, IEEE T INTELL TRANSP, V19, P1652, DOI 10.1109/TITS.2018.2801560
   Liu JY, 2018, IEEE T EMERG TOP COM, V6, P409, DOI 10.1109/TETC.2016.2577538
   Liu Q, 2016, LECT NOTES COMPUT SC, V9950, P405, DOI 10.1007/978-3-319-46681-1_49
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Loshchilov I., 2017, P INT C LEARN REPR
   Mao QC, 2019, IEEE ACCESS, V7, P133529, DOI 10.1109/ACCESS.2019.2941547
   Min WD, 2019, IET IMAGE PROCESS, V13, P1041, DOI 10.1049/iet-ipr.2018.6449
   Misra D., 2019, ARXIV190808681
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Salti S, 2015, PATTERN RECOGN, V48, P1039, DOI 10.1016/j.patcog.2014.05.017
   Shi R, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2020.105214
   Shustanov A, 2017, PROCEDIA ENGINEER, V201, P718, DOI 10.1016/j.proeng.2017.09.594
   Tabernik D, 2020, IEEE T INTELL TRANSP, V21, P1427, DOI 10.1109/TITS.2019.2913588
   Tai SK, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10196997
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tian YN, 2019, COMPUT ELECTRON AGR, V157, P417, DOI 10.1016/j.compag.2019.01.012
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wu F, 2019, IEEE INT C NETW SENS, P363, DOI [10.1109/ICNSC.2019.8743246, 10.1109/icnsc.2019.8743246]
   Xu QW, 2020, IEEE ACCESS, V8, P27574, DOI 10.1109/ACCESS.2020.2966328
   Yang HL, 2019, IEEE ACCESS, V7, P180998, DOI 10.1109/ACCESS.2019.2958614
   Yang TT, 2018, COMPUT NETW, V136, P95, DOI 10.1016/j.comnet.2018.02.026
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhang R, 2020, IEEE T INF FOREN SEC, V15, P1138, DOI 10.1109/TIFS.2019.2936913
   Zhang Z, 2019, ARXIV190204103V3
   Zhu Z., 2016, PROC CVPR IEEE, P2110, DOI DOI 10.1109/CVPR.2016.232
NR 55
TC 57
Z9 57
U1 23
U2 244
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37821
EP 37845
DI 10.1007/s11042-022-12962-5
EA APR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000786824500008
DA 2024-07-18
ER

PT J
AU Pan, SY
   Sheng, B
   He, GQ
   Li, HT
   Xue, GT
AF Pan, Siyuan
   Sheng, Bin
   He, Gaoqi
   Li, Huating
   Xue, Guangtao
TI BAW: learning from class imbalance and noisy labels with batch
   adaptation weighted loss
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Class imbalance; Noisy labels; Batch adaptation weighted; ChestX-ray14
AB Deep learning has made significant achievements in the field of medical image processing. To train a robust model with strong generalization, a large-scale, high-quality dataset with balanced categories and correct labels is required. However, most datasets follow a long-tail distribution that some classes occupy most of the data, and other classes have only a few samples. At the same time, incorrect labels exist in the datasets. The existing methods focus on solving only one of these two problems, such as Focal Loss for class imbalance and mean-absolute error loss function for noisy labels. However, methods that try to alleviate one of the problems will aggravate the other. In order to tackle the class imbalance while avoids fitting the noisy labels, we propose a novel Batch Adaptation Weighted (BAW) loss. It uses the loss weights of known samples to guide the direction of network optimization for next batch training. BAW is easy to implement and can be extended to various deep networks to improve accuracy without any extra cost. We evaluate BAW on a general natural image dataset, CIFAR-10, and verify it on a large-scale medical image dataset, ChestX-ray14. Compared with existing algorithms, BAW gets best results on both datasets. Experiments shows that our algorithm can solve the problem of class imbalance and noisy labels at the same time. The code of our project is available at https://github.com/pansiyuan123/chestnet.
C1 [Pan, Siyuan; Sheng, Bin; Xue, Guangtao] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
   [He, Gaoqi] East China Normal Univ, Shanghai 200241, Peoples R China.
   [Li, Huating] Shanghai Jiao Tong Univ Affiliated Peoples Hosp 6, Shanghai 200233, Peoples R China.
C3 Shanghai Jiao Tong University; East China Normal University; Shanghai
   Jiao Tong University
RP Sheng, B (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.; Li, HT (corresponding author), Shanghai Jiao Tong Univ Affiliated Peoples Hosp 6, Shanghai 200233, Peoples R China.
EM binsheng@sjtu.edu.cn; huarting99@sjtu.edu.cn
OI Sheng, Bin/0000-0001-8678-2784
CR [Anonymous], 2018, LEARNING RECOGNIZE A
   Chawla N., 2004, ANN NUCL ENERGY, V36, P255, DOI [10.1016/j.anucene.2008.11.008, DOI 10.1016/J.ANUCENE.2008.11.008]
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Dan H, 2019, USING PRETRAINING CA
   Ding YF, 2018, IEEE WINT CONF APPL, P1215, DOI 10.1109/WACV.2018.00138
   Durand T, 2017, P IEEE C COMP VIS PA
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Ghosh A, 2017, AAAI CONF ARTIF INTE, P1919
   Haynes D, 2012, EVOL COMPUT
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang JC, 2019, IEEE I CONF COMP VIS, P3325, DOI 10.1109/ICCV.2019.00342
   Jindal I, 2019, P IEEE C COMP VIS PA, P64
   Kim Y, 2021, PATTERN RECOGN LETT, V151, P33, DOI 10.1016/j.patrec.2021.07.017
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   Li BY, 2019, AAAI CONF ARTIF INTE, P8577
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu XY, 2006, IEEE DATA MINING, P965
   Northcutt CG, 2021, J ARTIF INTELL RES, V70, P1373
   Patrini G, 2017, PROC CVPR IEEE, P2233, DOI 10.1109/CVPR.2017.240
   Rajpurkar Pranav, 2017, ARXIV170701836
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tanaka D, 2018, PROC CVPR IEEE, P5552, DOI 10.1109/CVPR.2018.00582
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Vandat A, 2017, ADV NEUR IN, V30
   Voets M, 2018, PLOS ONE
   Wallace BC, 2012, IEEE INT C DATA MINI
   Wang X., 2017, PROC CVPR IEEE, P2097, DOI [DOI 10.1109/CVPR.2017.369, 10.1109/CVPR.2017.369]
   Yao JC, 2019, IEEE T IMAGE PROCESS, V28, P1909, DOI 10.1109/TIP.2018.2877939
   Zhe L, 2018, PROC CVPR IEEE, P8290, DOI 10.1109/CVPR.2018.00865
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
NR 37
TC 2
Z9 2
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13593
EP 13610
DI 10.1007/s11042-022-12323-2
EA APR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000784679300025
DA 2024-07-18
ER

PT J
AU Zhai, ZL
   Feng, S
   Yao, LY
   Li, PH
AF Zhai, ZhengLi
   Feng, Shu
   Yao, Luyao
   Li, Penghui
TI Retinal vessel image segmentation algorithm based on encoder-decoder
   structure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinal blood vessels; Image segmentation; Inception module; Pyramid
   pooling modules; Feature fusion
ID BLOOD-VESSELS; BIT PLANES; NETWORK
AB The accurate segmentation of retinal vessel image is significant for the early diagnosis of some diseases. A retinal vessel image segmentation algorithm based on an encoder-decoder structure is proposed. In the encoding section, the Inception module is used, which uses convolution kernels of different scales to achieve features extract to obtain images multi-scale information. So as to enable the model to perceive blood vessels of various shapes and improve the accuracy of segmentation of small blood vessels, multiple pyramid pooling modules are adopted in the decoding process to aggregate more contextual information, and multi-scale and multi-local area feature fusion is used to improve segmentation effect. In addition, the feature fusion method is applied in the upsampling process to fuse low-order semantic features to obtain more low-level detailed information, thereby further promote the segmentation effect. The experimental results on DRIVE and STAER fundus image datasets show that the algorithm has higher sensitivity, accuracy and AUC value compared with other algorithms, and the segmentation effect is better.
C1 [Zhai, ZhengLi; Feng, Shu; Yao, Luyao; Li, Penghui] Qingdao Univ Technol, Sch Informat & Control Engn, Qingdao 266520, Peoples R China.
C3 Qingdao University of Technology
RP Zhai, ZL (corresponding author), Qingdao Univ Technol, Sch Informat & Control Engn, Qingdao 266520, Peoples R China.
EM zzl@qut.edu.cn
RI bai, yu/KHU-2608-2024
OI Zhai, ZhengLi/0000-0001-5041-1447
FU National Natural Science Foundation of China [61502262]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61502262
CR Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   [曹莹 Cao Ying], 2013, [自动化学报, Acta Automatica Sinica], V39, P745
   CHAUDHURI S, 1989, IEEE T MED IMAGING, V8, P263, DOI 10.1109/42.34715
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Fraz MM, 2013, J DIGIT IMAGING, V26, P274, DOI 10.1007/s10278-012-9513-3
   Fraz MM, 2012, COMPUT METH PROG BIO, V108, P600, DOI 10.1016/j.cmpb.2011.08.009
   Fraz MM, 2012, IEEE T BIO-MED ENG, V59, P2538, DOI 10.1109/TBME.2012.2205687
   Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199
   Gu, 2021, COMPUT SCI EXPLOR, P1
   Hatamizadeh A., 2019, ARXIV PREPRINT ARXIV
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Imani E, 2015, COMPUT METH PROG BIO, V118, P263, DOI 10.1016/j.cmpb.2015.01.004
   Jin QG, 2019, KNOWL-BASED SYST, V178, P149, DOI 10.1016/j.knosys.2019.04.025
   Lechner J, 2017, VISION RES, V139, P7, DOI 10.1016/j.visres.2017.04.003
   Li D, 2019, IEEE IMAGE PROC, P1425, DOI [10.1109/ICIP.2019.8803101, 10.1109/icip.2019.8803101]
   Prokofyeva E, 2012, OPHTHALMIC RES, V47, P171, DOI 10.1159/000329603
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Song J, 2017, IEEE ENG MED BIO, P681, DOI 10.1109/EMBC.2017.8036916
   Wang WH, 2018, J MED IMAG HEALTH IN, V8, P262, DOI 10.1166/jmihi.2018.2288
   Yu J, 2022, IEEE T PATTERN ANAL, V44, P563, DOI 10.1109/TPAMI.2019.2932058
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
NR 21
TC 6
Z9 6
U1 4
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33361
EP 33373
DI 10.1007/s11042-022-13176-5
EA APR 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784122800003
DA 2024-07-18
ER

PT J
AU Huidrom, R
   Chanu, YJ
   Singh, KM
AF Huidrom, Ratishchandra
   Chanu, Yambem Jina
   Singh, Khumanthem Manglem
TI Neuro-evolutional based computer aided detection system on computed
   tomography for the early detection of lung cancer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer aided detection; Lung Cancer; Pulmonary nodules; Regularized
   discriminant features; Cuckoo search algorithm; Particle swarm
   optimization
ID NODULE DETECTION; PULMONARY NODULES; CT IMAGES; AUTOMATIC DETECTION;
   CHEST CT; ALGORITHMS
AB Lung cancer is one of the highest deadly disease which can be treated effectively in its early stage. Computer aided detection (CADe) can detect pulmonary nodules of lung cancer accurately and faster than manual detection. This paper presents a new CADe system using neuro-evolutional approach. The proposed method is focused on machine learning algorithm which is a crucial area of the system. The CADe system extracts lung regions from computed tomography images and detects pulmonary nodules within the lung regions. False positive reduction is performed by using a new neuro-evolutionary approach which consists of a feed-forward neural network and a combination of cuckoo search algorithm and particle swarm optimization. The performance of the proposed method is further improved by using regularized discriminant features and achieves 95.8% sensitivity, 95.3% specificity and 95.5% accuracy.
C1 [Huidrom, Ratishchandra; Chanu, Yambem Jina; Singh, Khumanthem Manglem] Natl Inst Technol, Imphal 795001, Manipur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Manipur
RP Huidrom, R (corresponding author), Natl Inst Technol, Imphal 795001, Manipur, India.
EM ratishchandra.huidrom@gmail.com
CR Arimura H, 2004, ACAD RADIOL, V11, P617, DOI 10.1016/j.acra.2004.02.009
   Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204
   Cao HC, 2020, IEEE J BIOMED HEALTH, V24, P2006, DOI 10.1109/JBHI.2019.2963720
   Cao WB, 2009, ENG APPL ARTIF INTEL, V22, P40, DOI 10.1016/j.engappai.2008.04.008
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Deb K, 1999, SADHANA-ACAD P ENG S, V24, P293, DOI 10.1007/BF02823145
   El-Baz A, 2013, INT J BIOMED IMAGING, V2013, DOI [10.1155/2013/942353, 10.1155/2013/517632]
   Farag A, 2004, LECT NOTES COMPUT SC, V3217, P856
   Farahani FV, 2018, MATH COMPUT SIMULAT, V149, P48, DOI 10.1016/j.matcom.2018.02.001
   FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860
   Golosio B, 2009, MED PHYS, V36, P3607, DOI 10.1118/1.3160107
   Gong J, 2018, PHYS MEDICA, V46, P124, DOI 10.1016/j.ejmp.2018.01.019
   Han H, 2013, IEEE NUCL SCI CONF R
   Hardie RC, 2008, MED IMAGE ANAL, V12, P240, DOI 10.1016/j.media.2007.10.004
   Huidrom R, 2019, SIGNAL IMAGE VIDEO P, V13, P53, DOI 10.1007/s11760-018-1327-4
   Iqbal S, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/241647
   Jacobs C, 2014, MED IMAGE ANAL, V18, P374, DOI 10.1016/j.media.2013.12.001
   Jin X., 2016, ENCY MACHINE LEARNIN, P1, DOI [10.1007/978-1-4899-7502-7_432-1, DOI 10.1007/978-1-4899-7502-7_432-1]
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Ko JP, 2001, RADIOLOGY, V218, P267, DOI 10.1148/radiology.218.1.r01ja39267
   Li W, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6215085
   Messay T, 2010, MED IMAGE ANAL, V14, P390, DOI 10.1016/j.media.2010.02.004
   Murphy K, 2009, MED IMAGE ANAL, V13, P757, DOI 10.1016/j.media.2009.07.001
   Paul R, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.1.011021
   Retico A, 2008, COMPUT BIOL MED, V38, P525, DOI 10.1016/j.compbiomed.2008.02.001
   Setio AAA, 2017, MED IMAGE ANAL, V42, P1, DOI 10.1016/j.media.2017.06.015
   Tartar A, 2013, IEEE ENG MED BIO, P7355, DOI 10.1109/EMBC.2013.6611257
   Teramoto A, 2014, INT J COMPUT ASS RAD, V9, P59, DOI 10.1007/s11548-013-0910-y
   Teramoto A, 2013, INT J COMPUT ASS RAD, V8, P193, DOI 10.1007/s11548-012-0767-5
   van Ginneken B, 2010, MED IMAGE ANAL, V14, P707, DOI 10.1016/j.media.2010.05.005
   Viale Pamela Hallquist, 2020, J Adv Pract Oncol, V11, P135, DOI 10.6004/jadpro.2020.11.2.1
   Wiemker R, 2002, PROC SPIE, V4684, P677, DOI 10.1117/12.467210
   Xin-She Yang, 2010, International Journal of Mathematical Modelling and Numerical Optimisation, V1, P330, DOI 10.1504/IJMMNO.2010.035430
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
NR 34
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32661
EP 32673
DI 10.1007/s11042-022-12722-5
EA APR 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000782544600001
DA 2024-07-18
ER

PT J
AU Ghanbari, H
   Enayatifar, R
   Motameni, H
AF Ghanbari, Hasan
   Enayatifar, Rasul
   Motameni, Homayun
TI Chaos-based image encryption using hybrid model of linear-feedback shift
   register system and deoxyribonucleic acid
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image security; Deoxyribonucleic acid (DNA); Linear-feedback shift
   register (LFSR); Logistic map function
ID PERMUTATION-DIFFUSION; GENETIC ALGORITHM; CRYPTANALYSIS
AB The security of digital images has been under much more attack recently. A novel image security based on a hybrid model of deoxyribonucleic acid (DNA), Linear-Feedback Shift Register (LFSR) and logistic map has been proposed in this study. In the first step each pixel of plain-image converted to DNA sequence using DNA rules and chaotic map, then the four bases DNA have generated using LFSR. These two DNA sequences have been XOR'ed. with each other. Experimental results and computer simulations both confirm that the proposed scheme not only demonstrates excellent encryption but also resists various typical attacks.
C1 [Ghanbari, Hasan; Motameni, Homayun] Islamic Azad Univ, Dept Comp Engn, Sari Branch, Sari, Iran.
   [Enayatifar, Rasul] Islamic Azad Univ, Dept Comp Engn, Firoozkooh Branch, Firoozkooh, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Enayatifar, R (corresponding author), Islamic Azad Univ, Dept Comp Engn, Firoozkooh Branch, Firoozkooh, Iran.
EM r.enayatifar@gmail.com
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Babaei A, 2020, OPTIK, V203, DOI 10.1016/j.ijleo.2019.164000
   Bai T, 2019, FUTURE GENER COMP SY, V92, P800, DOI 10.1016/j.future.2018.01.031
   Chen JX, 2020, INFORM SCIENCES, V520, P130, DOI 10.1016/j.ins.2020.02.024
   Cincotta PM, 2020, PHYSICA D, V402, DOI 10.1016/j.physd.2019.132235
   Enayatifar R, 2019, OPT LASER ENG, V115, P131, DOI 10.1016/j.optlaseng.2018.11.017
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Enayatifar R, 2013, OPT LASER ENG, V51, P1066, DOI 10.1016/j.optlaseng.2013.03.010
   Enayatifar R, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING SYSTEMS, P754, DOI 10.1109/ICSPS.2009.171
   Ghadirli HM, 2019, SIGNAL PROCESS, V164, P163, DOI 10.1016/j.sigpro.2019.06.010
   Guesmi R, 2021, MULTIMED TOOLS APPL, V80, P1925, DOI 10.1007/s11042-020-09672-1
   Guesmi R, 2015, 2015 IEEE 12TH INTERNATIONAL MULTI-CONFERENCE ON SYSTEMS, SIGNALS & DEVICES (SSD)
   Hua ZY, 2021, INFORM SCIENCES, V546, P1063, DOI 10.1016/j.ins.2020.09.032
   Jiang ZT, 2005, APPL MATH COMPUT, V171, P900, DOI 10.1016/j.amc.2005.01.097
   Karunamurthi S, 2019, MICROPROCESS MICROSY, V69, P68, DOI 10.1016/j.micpro.2019.05.015
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Kumar M., 2020, Multimedia Security Using Chaotic Maps: Principles and Methodologies, P1
   Kumari M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0148-5
   Li M, 2018, SIGNAL PROCESS-IMAGE, V62, P164, DOI 10.1016/j.image.2018.01.002
   Luo YQ, 2019, MULTIMED TOOLS APPL, V78, P22023, DOI 10.1007/s11042-019-7453-3
   Ma YL, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102566
   Nematzadeh H, 2020, OPTIK, V202, DOI 10.1016/j.ijleo.2019.163505
   Sankpal PR, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P102, DOI 10.1109/ICSIP.2014.80
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Sudeepa KB, 2020, PATTERN RECOGN LETT, V133, P341, DOI 10.1016/j.patrec.2020.03.015
   Szymanski ES, 2017, BIOPHYS J, V112, p70A, DOI 10.1016/j.bpj.2016.11.419
   Tao Y, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102650
   Tong XJ, 2012, J SYST SOFTWARE, V85, P850, DOI 10.1016/j.jss.2011.10.051
   Wang MM, 2020, OPT LASER TECHNOL, V124, DOI 10.1016/j.optlastec.2019.106001
   Wang T, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106355
   Wang XY, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110102
   Wang XY, 2020, OPT LASER TECHNOL, V131, DOI 10.1016/j.optlastec.2020.106366
   Wang XY, 2020, OPT LASER ENG, V125, DOI 10.1016/j.optlaseng.2019.105851
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Yadollahi M, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102505
   Yang Y, 2021, OPT LASER TECHNOL, V133, DOI 10.1016/j.optlastec.2020.106553
   Zefreh EZ, 2020, MULTIMED TOOLS APPL, V79, P24993, DOI 10.1007/s11042-020-09111-1
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhou KL, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105769
NR 40
TC 7
Z9 7
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31815
EP 31830
DI 10.1007/s11042-022-12188-5
EA APR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781124000022
DA 2024-07-18
ER

PT J
AU Sarkar, A
AF Sarkar, Arindam
TI Development of GAN-based optimal neural network structure for group
   synchronization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neural synchronization; Session key; Three Layer Tree Parity Machine
   (TLTPM); Neural network; Generative Adversarial Network (GAN);
   Simulations
ID EXCHANGE
AB In this paper, a GAN-based optimal neural network structure for group synchronization is proposed. For generating a key between two parties, asymmetric cryptography is commonly used to exchange the key over an unprotected medium. However, as the approaches that used this technique, such as RSA, have been compromised, new ways to produce a key that can provide protection must be found. To address this problem, a new branch of cryptography known as neural cryptography was developed. The main goal of this neural cryptography is to generate a secret key using an insecure medium. This paper gives an analysis of the ideal neural network configuration for generating and establishing a secret key between the two authenticated entities. Also, research into the synchronization of a group of neural networks is rare. For the design of the public key exchange protocol, a Generative Adversarial Network (GAN)-based synchronization of a group of neural networks with three hidden layers is proposed. For neural synchronization, GAN is used for Pseudo-Random Number Generators (PRNG). More than 15 million simulations were performed to determine the coordination time, steps were taken, and the number of times the attacking neural network could reproduce the behavior of the two approved networks. Various parametric experiments have been conducted on the proposed methodology. In terms of the paper's cited findings, simulations of the method indicate that it is accurate.
C1 [Sarkar, Arindam] Ramakrishna Mission Vidyamandira, Dept Comp Sci & Elect, Howrah 711202, W Bengal, India.
RP Sarkar, A (corresponding author), Ramakrishna Mission Vidyamandira, Dept Comp Sci & Elect, Howrah 711202, W Bengal, India.
EM arindam.vb@gmail.com
OI Sarkar, Arindam/0000-0002-4951-4729
FU Ramakrishna Mission Vidyamandira, Belur Math, India
FX The author expressed deep gratitude for the moral and congenial
   atmosphere support provided by Ramakrishna Mission Vidyamandira, Belur
   Math, India.
CR Abadi M, ARXIV, DOI DOI 10.48550/ARXIV.1603.04467
   Abdalrdha Z. K., 2019, INT J SCI RES SCI EN, P230, DOI [10.32628/ijsrset196550, DOI 10.32628/IJSRSET196550]
   Allandadi A, 2013, PROCEEDINGS OF THE 2013 38TH ANNUAL IEEE CONFERENCE ON LOCAL COMPUTER NETWORKS WORKSHOPS (LCN WORKSHOPS), P1, DOI 10.1109/LCNW.2013.6758491
   [Anonymous], 2010, FUZZY INFORM PROCESS
   Bauer FL, 2011, ENCY CRYPTOGRAPHY SE, DOI [10.1007/978-1-4419-5906-5_159, DOI 10.1007/978-1-4419-5906-5_159]
   Desai V, 2011, RECENT ADV INTELLIGE, P251, DOI DOI 10.1109/RAICS.2011.6069312
   Dolecki M, 2015, LECT NOTES COMPUT SC, V9339, P451, DOI 10.1007/978-3-319-24369-6_37
   Dong T, 2020, IEEE T NEUR NET LEAR, V31, P4999, DOI 10.1109/TNNLS.2019.2955165
   Gao J, 2021, IEEE T IND INFORM, V17, P971, DOI 10.1109/TII.2019.2947432
   Goodfellow I., 2014, P 27 INT C NEURAL IN, P2672
   Hadke PP, 2016, 2016 WORLD CONFERENCE ON FUTURISTIC TRENDS IN RESEARCH AND INNOVATION FOR SOCIAL WELFARE (STARTUP CONCLAVE)
   Jeong S, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6680782
   Jeong YS, 2018, INT CONF BIG DATA, P541, DOI 10.1109/BigComp.2018.00091
   Kanso A, 2009, CHAOS SOLITON FRACT, V40, P2557, DOI 10.1016/j.chaos.2007.10.049
   Kanter I, 2002, EUROPHYS LETT, V57, P141, DOI 10.1209/epl/i2002-00552-9
   Karakaya B, 2019, CHAOS SOLITON FRACT, V119, P143, DOI 10.1016/j.chaos.2018.12.021
   Kelsey J, 1998, LECT NOTES COMPUT SC, V1372, P168
   Klimov A, 2002, LECT NOTES COMPUT SC, V2501, P288
   Lindell Y., 2014, INTRO MODERN CRYPTOG
   Liu LF, 2016, IET INFORM SECUR, V10, P87, DOI 10.1049/iet-ifs.2014.0192
   Liu P, 2019, IEEE T NEUR NET LEAR, V30, P2358, DOI 10.1109/TNNLS.2018.2884620
   Lu YL, 2020, IEEE T IND INFORM, V16, P4177, DOI 10.1109/TII.2019.2942190
   Makkar A, 2021, IEEE T IND INFORM, V17, P903, DOI 10.1109/TII.2020.2968927
   Mehic M., 2020, Reversible Computation:Extending Horizons of Computing, P222
   Niemiec M, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-019-2296-4
   Niemiec M, 2018, 2018 26TH TELECOMMUNICATIONS FORUM (TELFOR), P191
   NIST, 2020, NIST STAT TEST
   Pal S. K., 2019, International Journal of Computer Network and Information Security, V11, P45, DOI [10.5815/ijcnis.2019.10.06, DOI 10.5815/IJCNIS.2019.10.06]
   Patidar V, 2009, INFORM-J COMPUT INFO, V33, P441
   Protic D., 2016, Vojnotehnicki glasnik/Military Technical Courier, V64, P483, DOI DOI 10.5937/VOJTEHG64-8877
   Rukhin Andrew L., 2001, A statistical test suite for random and pseudorandom number generators for cryptographic applications, V22
   Ruttor A, 2006, PHYS REV E, V73, DOI 10.1103/PhysRevE.036121
   Ruttor A, 2007, PHYS REV E, V75, DOI 10.1103/PhysRevE.75.056104
   Dorokhin ÉS, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/8214681
   Santhanalakshmi S, 2015, COMM COM INF SC, V536, P207, DOI 10.1007/978-3-319-22915-7_20
   Santhanalakshmi S, 2014, P INT C SEC COMP NET, P422
   Sarkar A., 2019, INT J ARTIF INTELL, V8, P44, DOI DOI 10.11591/IJEECS.V14.I1.PP169-177
   Sarkar A., 2012, INT J COMPUT SCI ENG, V3, P267
   Shacham LN, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.066137
   Shishniashvili E., 2020, INT J SIMUL SYST SCI, V21, P371, DOI [10.5013/ijssst.a.21.02.37, DOI 10.5013/IJSSST.A.21.02.37]
   Srinivas J, 2021, IEEE T IND INFORM, V17, P4425, DOI 10.1109/TII.2020.3011849
NR 41
TC 0
Z9 0
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28999
EP 29025
DI 10.1007/s11042-022-12601-z
EA APR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777241700005
DA 2024-07-18
ER

PT J
AU Otair, M
   Abualigah, L
   Qawaqzeh, MK
AF Otair, Mohammed
   Abualigah, Laith
   Qawaqzeh, Mohammed K.
TI Improved near-lossless technique using the Huffman coding for enhancing
   the quality of image compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Near-lossless technique; Huffman coding; Image quality; Image
   compression
ID ALGORITHM
AB Digital data compression aims to reduce the size of digital files in line with technological development. However, most data is distinguished by its large size, which requires a large storage capacity, and requires a long time in transmission operations via the Internet. Therefore, a new compress files method is needed to reduce the image size, maintain its quality, utilize storage spaces, and minimize time. This paper aims to improve digital image compression's compression rates by dividing the image into several blocks. Thus, a new near-lossless method using the Huffman Coding technique is proposed. Digital image compression techniques are classified as lossless and lossy. Huffman Coding is a lossless-based technique used in the proposed method to maintain image quality during compression. The proposed method consists of several steps, which are dividing the image into blocks, finding the lowest value in each block and subtracting it from the rest of the values in the same block, then subtracting one from the odd numbers, dividing all the values on two, and finally applying the Huffman Coding technique to the block. The proposed method is applied to a well-known gray and color set with different types and different dimensions. Standard evaluation measures are used (i.e., PSNR, MSE, and CR) to evaluate the proposed method's performance. When compressing images using the proposed method, the results demonstrated 0.11% enhancement when used two by two blocks. It also got high compression rates (25%).
C1 [Otair, Mohammed; Abualigah, Laith; Qawaqzeh, Mohammed K.] Amman Arab Univ, Fac Comp Sci & Informat, Amman 11953, Jordan.
   [Abualigah, Laith] Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.
C3 Universiti Sains Malaysia
RP Abualigah, L (corresponding author), Amman Arab Univ, Fac Comp Sci & Informat, Amman 11953, Jordan.; Abualigah, L (corresponding author), Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.
EM Otair@aau.edi.jo; Aligah.2020@gmail.com; Qawaqzeh@aau.edu.jo
RI Abualigah, Laith/ABC-9695-2020
OI Abualigah, Laith/0000-0002-2203-4549
CR Abuowaida SFA, 2021, JORDAN J COMPUT INFO, V7, P74, DOI 10.5455/jjcit.71-1603701313
   Aceves SM, 2010, INT J HYDROGEN ENERG, V35, P1219, DOI 10.1016/j.ijhydene.2009.11.069
   AGARWAL R, 2019, BIOMED PHARMACOL J, V12, P183, DOI DOI 10.13005/bpj/1627
   Al-Khasawneh MA, 2022, CLUSTER COMPUT, V25, P999, DOI 10.1007/s10586-021-03466-2
   Aldemir E, 2019, IMAGING SCI J, V67, P123, DOI 10.1080/13682199.2019.1565695
   Alkhalayleh Mahmoud A., 2015, International Journal of Imaging & Robotics, V15, P79
   Aràndiga F, 2013, J COMPUT APPL MATH, V242, P70, DOI 10.1016/j.cam.2012.10.028
   Balle J, 2018, ICLR
   Chen YY, 2020, IEEE T IMAGE PROCESS, V29, P1426, DOI 10.1109/TIP.2019.2941319
   COSMAN PC, 1994, P IEEE, V82, P919, DOI 10.1109/5.286196
   Dey N, 2020, Appl. Firefly Algorithm Variants, P1, DOI DOI 10.1007/978-981-15-0306-1
   Dhou K, 2021, FUTURE GENER COMP SY, V118, P1, DOI 10.1016/j.future.2020.12.016
   Dhou K, 2019, IEEE INTERNET THINGS, V6, P9308, DOI 10.1109/JIOT.2019.2912984
   Dhou K, 2020, FUTURE GENER COMP SY, V102, P650, DOI 10.1016/j.future.2019.08.021
   Diaz N, 2019, OPT LASER TECHNOL, V117, P147, DOI 10.1016/j.optlastec.2019.03.038
   Ewees AA, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9192363
   Gong LH, 2019, OPT LASER TECHNOL, V115, P257, DOI 10.1016/j.optlastec.2019.01.039
   Houssein EH, 2021, KNOWL-BASED SYST, V229, DOI 10.1016/j.knosys.2021.107348
   Huang LL, 2020, PROC CVPR IEEE, P1310, DOI 10.1109/CVPR42600.2020.00139
   Ibrahim M.B., 2019, Asian Journal of Research in Computer Science (AJRCOS), V3, P1
   Jasmi RP, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND INFORMATICS (ICCCI)
   Kasban H, 2019, J AMB INTEL HUM COMP, V10, P2855, DOI 10.1007/s12652-018-1016-8
   Kumar R, 2019, MULTIMED TOOLS APPL, V78, P32239, DOI 10.1007/s11042-019-07997-0
   Lee C-F, 2020, ICFET 2020 2020 6 IN
   Lin SY, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23121700
   Liu ZH, 2019, PROC CVPR IEEE, P12679, DOI 10.1109/CVPR.2019.01297
   Ma SW, 2020, IEEE T CIRC SYST VID, V30, P1683, DOI 10.1109/TCSVT.2019.2910119
   Mentzer F, 2019, PROC CVPR IEEE, P10621, DOI 10.1109/CVPR.2019.01088
   Morales CN, 2020, COMPOS PART B-ENG, V200, DOI 10.1016/j.compositesb.2020.108307
   Otair M. A., 2016, RES J APPL SCI ENG T, V12, P680
   Poolakkachalil T.K., 2019, INDONESIAN J ELECT E, V7, P564, DOI DOI 10.52549/IJEEI.V7I3.755
   Rahman MA, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101274
   Rawat CS, 2013, INT ARAB J INF TECHN, V10, P553
   Rege S., 2013, ISSN International Journal of Advanced Research in Electrical Electronics and Instrumentation Engineering, V2, P2479
   Santos L, 2020, IEEE T AERO ELEC SYS, V56, P1120, DOI 10.1109/TAES.2019.2929971
   Seeram E, 2019, DIGITAL RADIOGRAPHY, P21
   Setia V., 2012, INT J COMPUTER COMMU, V6, P201
   Shehab M, 2019, INT J BIO-INSPIR COM, V14, P190, DOI 10.1504/IJBIC.2019.103606
   Simpson A.L., 2019, LARGE ANNOTATED MEDI
   Sumari P., 2021, TURK J COMPUT MATH E, V12, P2001, DOI [10.17762/turcomat.v12i6.4804, DOI 10.17762/TURCOMAT.V12I6.4804]
   Talukder KH, 2010, ARXIV PREPRINT ARXIV
   Theis L., 2017, ICLR
   Touil DE, 2021, MULTIMED TOOLS APPL, V80, P9547, DOI 10.1007/s11042-020-09754-0
   Underwood R, 2020, ARXIV PREPRINT ARXIV
   Wang AC, 2019, COMPUT ELECTRON AGR, V158, P226, DOI 10.1016/j.compag.2019.02.005
   Witten I.H., 1999, Managing Gigabytes: Compressing and Indexing Documents and Images
   Yousri D, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107052
NR 47
TC 5
Z9 5
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28509
EP 28529
DI 10.1007/s11042-022-12846-8
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000775769200009
DA 2024-07-18
ER

PT J
AU Zhang, HN
   Dong, B
   Zheng, QH
   Feng, BQ
   Xu, B
   Wu, HY
AF Zhang, Hanning
   Dong, Bo
   Zheng, Qinghua
   Feng, Boqin
   Xu, Bo
   Wu, Haiyu
TI All-content text recognition method for financial ticket images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ticket detection; Image text recognition; Financial accounting; Deep
   learning
ID FEATURES
AB With the development of the economy, the number of financial tickets is increasing. The traditional invoice reimbursement and entry work bring more and more burden to financial accountants. However, standard OCR technology weakly supports financial tickets with various layouts and mixed Chinese and English characters. In view of this problem, this paper designs a method of financial ticket all-content text information detection and recognition based on deep learning. This method can effectively suppress the common noise of ticket image and extract financial information from ticket image in batch. At the same time, aiming at the problem of multi-character mixed character recognition, we propose a financial ticket character recognition framework (FTCRF), which can improve the accuracy of multi-character mixed character recognition and make the detection and recognition of financial ticket surface information more efficient. The experimental results show that the average recognition accuracy of the character sequence is 91.75%. The average recognition accuracy of the whole ticket is 87%, which significantly improves the efficiency of the financial accounting system.
C1 [Zhang, Hanning; Zheng, Qinghua; Feng, Boqin] Xi An Jiao Tong Univ, Sch Comp Sci & Technol, Xian 710049, Peoples R China.
   [Zhang, Hanning] Xi An Jiao Tong Univ, Shaanxi Prov Key Lab Satellite & Terr Network Tec, Xian 710049, Peoples R China.
   [Dong, Bo] Xi An Jiao Tong Univ, Sch Continuing Educ, Xian 710049, Peoples R China.
   [Dong, Bo] Xi An Jiao Tong Univ, Natl Engn Lab Big Data Analyt, Xian 710049, Peoples R China.
   [Xu, Bo; Wu, Haiyu] Xian Network Comp Data Technol Co Ltd, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University; Xi'an Jiaotong
   University; Xi'an Jiaotong University
RP Dong, B (corresponding author), Xi An Jiao Tong Univ, Sch Continuing Educ, Xian 710049, Peoples R China.; Dong, B (corresponding author), Xi An Jiao Tong Univ, Natl Engn Lab Big Data Analyt, Xian 710049, Peoples R China.
EM dong.bo@mail.xjtu.edu.cn
RI zhang, hanning/JJF-4919-2023
OI zhang, hanning/0000-0003-3321-5027
FU National Science Foundation of China [62050194, 62037001, 61721002,
   62002282]; MOE Innovation Research Team [IRT_17R86]; Project of
   XJTU-SERVYOU Joint Tax-AI Lab
FX This research was partially supported by the National Science Foundation
   of China under Grant Nos. 62050194, 62037001, 61721002, and 62002282,
   the MOE Innovation Research Team No. IRT_17R86, and Project of
   XJTU-SERVYOU Joint Tax-AI Lab.
CR [Anonymous], 2015, CVPR
   [Anonymous], 2014, EMPIRICAL EVALUATION
   Awad AI, 2016, STUD COMPUT INTELL, V630, P1, DOI 10.1007/978-3-319-28854-3
   Charniak E., 2019, INTRO DEEP LEARNING
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng D, 2018, AAAI CONF ARTIF INTE, P6773
   Feng X, 2019, INTEGRATION, V69, P309, DOI 10.1016/j.vlsi.2019.07.005
   Hassaballah, 2019, STUDIES COMPUTATIONA, V804
   Hassaballah M, 2016, STUD COMPUT INTELL, V630, P1, DOI 10.1007/978-3-319-28854-3_1
   Hassaballah M., 2020, Deep Learning in Computer Vision: Principles and Applications, DOI DOI 10.1201/9781351003827
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He P, 2017, IEEE I CONF COMP VIS, P3066, DOI 10.1109/ICCV.2017.331
   He WH, 2017, IEEE I CONF COMP VIS, P745, DOI 10.1109/ICCV.2017.87
   Ha HT, 2017, REC ADV SLAVON NAT L, P71
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jha M, 2019, AUTOMATION CHEQUE T
   Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107
   Liao MH, 2017, AAAI CONF ARTIF INTE, P4161
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Miikkulainen R, 2019, ARTIF INTELL
   Palm RB, 2017, PROC INT CONF DOC, P406, DOI 10.1109/ICDAR.2017.74
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Shi CZ, 2013, PROC CVPR IEEE, P2961, DOI 10.1109/CVPR.2013.381
   Shreya S, 2019, PROCEEDINGS OF THE 2019 6TH INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P55
   Simonyan K., 2014, CORR
   Solis AI, 2019, PROC SPIE, V11013, DOI 10.1117/12.2519554
   Srivastava S, 2019, ADV INTELL SYST, V697, P589, DOI 10.1007/978-981-13-1822-1_55
   Sun YY, 2019, IEEE ACCESS, V7, P28392, DOI 10.1109/ACCESS.2019.2901943
   Sutskever I, 2014, ADV NEUR IN, V27
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wang WH, 2019, PROC CVPR IEEE, P9328, DOI 10.1109/CVPR.2019.00956
   Wang YM, 2018, PROC CVPR IEEE, P4148, DOI 10.1109/CVPR.2018.00436
   Xie EZ, 2019, AAAI CONF ARTIF INTE, P9038
   Yi F, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204370
   Zhang Z, 2016, PROC CVPR IEEE, P4159, DOI 10.1109/CVPR.2016.451
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
NR 40
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28327
EP 28346
DI 10.1007/s11042-022-12741-2
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000775769200006
DA 2024-07-18
ER

PT J
AU Bharati, S
   Podder, P
   Thanh, DNH
   Prasath, VBS
AF Bharati, Subrato
   Podder, Prajoy
   Dang Ngoc Hoang Thanh
   Prasath, V. B. Surya
TI Dementia classification using MR imaging and clinical data with voting
   based machine learning models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dementia classification; MR imaging; Random forest; XGB classifier;
   Voting classifiers; Gradient boosting classifier; Feature selection
ID ALZHEIMERS-DISEASE; PREDICTION; PREVALENCE; CONVERSION; DIAGNOSIS
AB Dementia is one of the leading causes of severe cognitive decline, it induces memory loss and impairs the daily life of millions of people worldwide. In this work, we consider the classification of dementia using magnetic resonance (MR) imaging and clinical data with machine learning models. We adapt univariate feature selection in the MR data pre-processing step as a filter-based feature selection. Bagged decision trees are also implemented to estimate the important features for achieving good classification accuracy. Several ensemble learning-based machine learning approaches, namely gradient boosting (GB), extreme gradient boost (XGB), voting-based, and random forest (RF) classifiers, are considered for the diagnosis of dementia. Moreover, we propose voting-based classifiers that train on an ensemble of numerous basic machine learning models, such as the extra trees classifier, RF, GB, and XGB. The implementation of a voting-based approach is one of the important contributions, and the performance of different classifiers are evaluated in terms of precision, accuracy, recall, and F1 score. Moreover, the receiver operating characteristic curve (ROC) and area under the ROC curve (AUC) are used as metrics for comparing these classifiers. Experimental results show that the voting-based classifiers often perform better compared to the RF, GB, and XGB in terms of precision, recall, and accuracy, thereby indicating the promise of differentiating dementia from imaging and clinical data.
C1 [Bharati, Subrato; Podder, Prajoy] Bangladesh Univ Engn & Technol, Inst Informat & Commun Technol, Dhaka, Bangladesh.
   [Dang Ngoc Hoang Thanh] Univ Econ Ho Chi Minh City, Coll Technol & Design, Dept Informat Technol, Ho Chi Minh City, Vietnam.
   [Prasath, V. B. Surya] Univ Cincinnati, Dept Elect Engn & Comp Sci, Cincinnati, OH 45221 USA.
   [Prasath, V. B. Surya] Cincinnati Childrens Hosp Med Ctr, Div Biomed Informat, Cincinnati, OH 45229 USA.
   [Prasath, V. B. Surya] Univ Cincinnati, Dept Pediat, Coll Med, Cincinnati, OH 45257 USA.
   [Prasath, V. B. Surya] Univ Cincinnati, Coll Med, Dept Biomed Informat, Cincinnati, OH 45267 USA.
C3 Bangladesh University of Engineering & Technology (BUET); Ho Chi Minh
   City University Economics; University System of Ohio; University of
   Cincinnati; Cincinnati Children's Hospital Medical Center; University
   System of Ohio; University of Cincinnati; University System of Ohio;
   University of Cincinnati
RP Thanh, DNH (corresponding author), Univ Econ Ho Chi Minh City, Coll Technol & Design, Dept Informat Technol, Ho Chi Minh City, Vietnam.
EM thanhdnh@ueh.edu.vn
RI PODDER, PRAJOY/R-7230-2019; Thanh, Dang Ngoc Hoang/J-4415-2015; Prasath,
   Surya/A-5243-2010; Bharati, Subrato/U-2601-2019
OI PODDER, PRAJOY/0000-0002-7564-4738; Thanh, Dang Ngoc
   Hoang/0000-0003-2025-8319; Prasath, Surya/0000-0001-7163-7453; Bharati,
   Subrato/0000-0001-8849-4313
FU University of Economics Ho Chi Minh City (UEH), Vietnam; NCATS/NIH
   [U2CTR002818]; NHLBI/NIH [U24HL148865]; NIAID/NIH [U01AI150748];
   Cincinnati Children's Hospital Medical Center-Advanced Research Council
   (ARC); Cincinnati Children's Research Foundation-Center for Pediatric
   Genomics (CPG)
FX DNHT: This research was funded by University of Economics Ho Chi Minh
   City (UEH), Vietnam.; VBSP is supported by NCATS/NIH grant U2CTR002818,
   NHLBI/NIH grantU24HL148865, NIAID/NIH grant U01AI150748, Cincinnati
   Children's Hospital Medical Center-Advanced Research Council (ARC)Grants
   2018-2020, and the Cincinnati Children's Research Foundation-Center for
   Pediatric Genomics (CPG) grants 2019-2021.
CR Alok N, 2021, Mach. Learn. Healthc. Appl., P187, DOI DOI 10.1002/9781119792611.CH12
   [Anonymous], 2015, P 1 WHO MIN C GLOB A
   [Anonymous], 2013, P 27 AAAI C ART INT
   Ansari A, 2018, IEEE WRK SIG PRO SYS, P7, DOI 10.1109/SiPS.2018.8598348
   Ansart M, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101848
   Basaia S, 2019, NEUROIMAGE-CLIN, V21, DOI 10.1016/j.nicl.2018.101645
   Bateman RJ, 2011, ALZHEIMERS RES THER, V3, DOI 10.1186/alzrt59
   Battineni G., 2019, Informatics in Medicine Unlocked, V16, P100200, DOI DOI 10.1016/J.IMU.2019.100200
   Bharati Subrato, 2021, International Journal of Computer Information Systems and Industrial Management Applications, V13, P91
   Bharati S., 2021, INT J HYBRID INTELLI, V17, P71, DOI DOI 10.3233/HIS-210008
   Bharati Subrato, 2020, Inform Med Unlocked, V20, P100391, DOI 10.1016/j.imu.2020.100391
   Bharati S, 2018, INT CONF ELECTR ENG, P580, DOI 10.1109/CEEICT.2018.8628084
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Braak H, 1997, NEUROBIOL AGING, V18, pS85, DOI 10.1016/S0197-4580(97)00062-6
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Brickman AM, 2008, ARCH NEUROL-CHICAGO, V65, P1202, DOI 10.1001/archneur.65.9.1202
   Cao JJ, 2015, NEUROCOMPUTING, V149, P275, DOI 10.1016/j.neucom.2014.02.072
   Castellazzi G, 2020, FRONT NEUROINFORM, V14, DOI 10.3389/fninf.2020.00025
   Chen R, 2010, NEUROIMAGE, V52, P234, DOI 10.1016/j.neuroimage.2010.03.084
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Cuijpers Y, 2015, TECHNOL FORECAST SOC, V93, P54, DOI 10.1016/j.techfore.2014.03.006
   Dabral I, 2019, INT C DEEP LEARN ART, P290, DOI DOI 10.1007/978-3-030-67187-7_30
   Darbari A, 2021, CARDIOTHORAC SURG, V29, DOI 10.1186/s43057-021-00053-4
   Datta P., 1996, C P AAAI S, P25
   Davatzikos C, 2008, NEUROIMAGE, V41, P1220, DOI 10.1016/j.neuroimage.2008.03.050
   Delgado Joaquin., 1999, SIGIR WORKSHOP RECOM, P85
   den Heijer Tom, 2006, Arch Gen Psychiatry, V63, P57
   Facal D, 2019, INT J GERIATR PSYCH, V34, P941, DOI 10.1002/gps.5090
   Farid AA, 2020, 9 INT C RES SCI TECH
   Filipovych R, 2011, NEUROIMAGE, V55, P1109, DOI 10.1016/j.neuroimage.2010.12.066
   Fox NC, 2000, ARCH NEUROL-CHICAGO, V57, P339, DOI 10.1001/archneur.57.3.339
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Frozza RL, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00037
   Gill S, 2020, J ALZHEIMERS DIS, V75, P277, DOI 10.3233/JAD-191169
   González-Salvador T, 2000, INT J GERIATR PSYCH, V15, P181, DOI 10.1002/(SICI)1099-1166(200002)15:2<181::AID-GPS96>3.0.CO;2-I
   Herzog NJ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030778
   Hosmer DW, 2013, WILEY SER PROBAB ST, P89
   Joshi S, 2009, FIRST INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING 2009 (ICAC 2009), P154, DOI 10.1109/ICADVC.2009.5378199
   Kang XB, 2020, MULTIMED TOOLS APPL, V79, P1169, DOI 10.1007/s11042-019-08191-y
   Kim KW, 2011, J ALZHEIMERS DIS, V23, P279, DOI 10.3233/JAD-2010-101221
   Korolev IO, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0138866
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P26635, DOI 10.1007/s11042-018-5882-z
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kumari Shreya, 2021, International Conference on Deep Learning, Artificial Intelligence and Robotics ICDLAIR 2019. Proceedings. Lecture Notes in Networks and Systems (LNNS 175), P339, DOI 10.1007/978-3-030-67187-7_35
   Lezak MD, 2004, Neuropsychological Assessment, DOI DOI 10.1017/S0033291718001599
   Mondal MRH, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0259179
   Moradi E, 2015, NEUROIMAGE, V104, P398, DOI 10.1016/j.neuroimage.2014.10.002
   Negi A., 2021, Agricultural Informatics: Automation using the IoT and Machine Learning, P117, DOI [10.1002/9781119769231.ch6, DOI 10.1002/9781119769231.CH6]
   Park JH, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0256-0
   Priya T, 2021, SOFT COMPUT, V25, P10007, DOI 10.1007/s00500-021-05621-8
   Rohini M, 2021, SOFT COMPUT, V25, P2589, DOI 10.1007/s00500-020-05292-x
   Shankle WR, 1998, ST HEAL T, V52, P472
   Shin NY., 2021, RADIOLOGY, V25
   Shree SB, 2004, IEEE INT C COMPUTATI, P1
   Sperling RA, 2011, ALZHEIMERS DEMENT, V7, P280, DOI 10.1016/j.jalz.2011.03.003
   Stamate D., 2020, IFIP Adv. Inf. Commun. Technol, V584, P308, DOI [10.1007/978-3-030-49186-426, DOI 10.1007/978-3-030-49186-426]
   Tian JQ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80312-2
   Trambaiolli LR, 2011, CLIN EEG NEUROSCI, V42, P160, DOI 10.1177/155005941104200304
   ULRICH J, 1985, ANN NEUROL, V17, P273, DOI 10.1002/ana.410170309
   Vossel KA, 2013, JAMA NEUROL, V70, P1158, DOI 10.1001/jamaneurol.2013.136
   Wortmann M, 2013, ALZHEIMERS RES THER, V5, DOI 10.1186/alzrt205
   Wu YT, 2017, NAT REV NEUROL, V13, P327, DOI 10.1038/nrneurol.2017.63
   Ye Dong Hye, 2011, Int Workshop Pattern Recognit Neuroimaging, V2011, P1, DOI 10.1109/PRNI.2011.12
   Young J, 2013, NEUROIMAGE-CLIN, V2, P735, DOI 10.1016/j.nicl.2013.05.004
   Zhang YD, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00066
NR 65
TC 10
Z9 10
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25971
EP 25992
DI 10.1007/s11042-022-12754-x
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000773206100004
DA 2024-07-18
ER

PT J
AU Dantas, AC
   do Nascimento, MZ
AF Dantas, A. C.
   do Nascimento, M. Z.
TI Face emotions: improving emotional skills in individuals with autism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotions; Serious games; Facial expression; Autism spectrum disorder;
   Facial emotion recognition
ID SPECTRUM DISORDER; FACIAL EXPRESSIONS; CHILDREN; NETWORK; RECOGNITION;
   ADOLESCENTS
AB Among the main characteristics of an individual with autism spectrum disorder are repetitive behavioral patterns, deficiencies in social interaction and both verbal and nonverbal communication present since childhood. The ability to recognize mental states from facial expressions plays a vital role in social interaction and interpersonal communication. In recent years, several studies have been carried out with the aim of motivating individuals to use computer technologies to learn emotions in order to improve social interactions. In this paper, a game that can support the development of emotional and social skills is presented for people with autism spectrum disorder. Our game allows people to develop the ability to recognize and express basic emotions: joy, sadness, anger, disgust, surprise and fear. Experiments were performed on a public domain image database and with a group of individuals from an educational institution, in order to evaluate the performance of the proposed tool. The results showed that the use of our approach improved these capabilities in individuals with autism spectrum disorder.
C1 [Dantas, A. C.; do Nascimento, M. Z.] Univ Fed Uberlandia, Av Joao Naves de Avila 2121,Bloco 5K,Sala 1, BR-38400902 Uberlandia, MG, Brazil.
C3 Universidade Federal de Uberlandia
RP Dantas, AC (corresponding author), Univ Fed Uberlandia, Av Joao Naves de Avila 2121,Bloco 5K,Sala 1, BR-38400902 Uberlandia, MG, Brazil.
EM akanehar@gmail.com; marcelo.zanchetta@gmail.com
RI Dantas, Adilmar Coelho/ABA-5392-2020; Zanchetta do Nascimento,
   Marcelo/H-8689-2014
OI Dantas, Adilmar Coelho/0000-0002-7603-1386; Zanchetta do Nascimento,
   Marcelo/0000-0003-3537-0178
FU Anonymous Foundation [001]; National Council for Scientific and
   Technological Development CNPq [304848/2018-2, 311404/2021-9]
FX This study was financed in part by the Anonymous Foundation - Finance
   Code 001. The authors gratefully acknowledge the financial support of
   National Council for Scientific and Technological Development CNPq
   (Grants #304848/2018-2 and #311404/2021-9).
CR Acevedo D, 2017, IEEE INT CONF AUTOMA, P802, DOI 10.1109/FG.2017.101
   Apple AL, 2005, J POSIT BEHAV INTERV, V7, P33, DOI 10.1177/10983007050070010401
   Association AP Staff A P A, 2010, DIAGN STAT MAN MENT
   Azcarate A., 2005, Automatic facial emotion recognition, P1
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A, 2010, LECT NOTES COMPUT SC, V6298, P705, DOI 10.1007/978-3-642-15696-0_65
   Beaudry O, 2014, COGNITION EMOTION, V28, P416, DOI 10.1080/02699931.2013.833500
   Bilkhu Manjot Singh, 2019, Computational Intelligence: Theories, Applications and Future DirectionsVolume II. ICCI-2017. Advances in Intelligent Systems and Computing (AISC 799), P585, DOI 10.1007/978-981-13-1135-2_44
   Black D.W., 2014, DSM-5 TM guidebook the essential companion to the Diagnostic and statistical manual of mental disorders, V5th
   Bosa C., 2002, AUTISMO EDUCA O REFL, P21
   Boucenna S, 2014, COGN COMPUT, V6, P722, DOI 10.1007/s12559-014-9276-x
   Brun P., 2001, ENFANCE, V53, P281
   Castelli F, 2005, AUTISM, V9, P428, DOI 10.1177/1362361305056082
   Chen CH, 2016, COMPUT HUM BEHAV, V55, P477, DOI 10.1016/j.chb.2015.09.033
   Chen CH, 2015, RES DEV DISABIL, V36, P396, DOI 10.1016/j.ridd.2014.10.015
   Constantin A, 2017, COMPUT HUM BEHAV, V75, P404, DOI 10.1016/j.chb.2017.05.030
   Control C D Prevention, 2018, AUTISM SPECTRUM DISO
   da Rocha Gracioso A C N, 2013, 2013 47 INT CARN C S, P1, DOI DOI 10.1109/CCST.2013.6922065
   Dantas A C, 2015, AN S BRAS INF ED, P1102
   Dapogny A, 2018, IEEE INT CONF AUTOMA, P723, DOI 10.1109/FG.2018.00114
   DE King D E, 2015, ARXIV150200046
   Deterding S., 2011, P C HUM FACT CHI 11, P2425, DOI [10.1145/1979742.1979575, DOI 10.1145/1979742.1979575, 10.1145/ 1979742.1979575]
   Ekman P., 2005, WHAT FACE REVEALS BA
   Ekman P., 1978, Facial action coding system
   Elshahawy M, 2020, IEEE GLOB ENG EDUC C, P1862, DOI [10.1109/EDUCON45650.2020.9125196, 10.1109/educon45650.2020.9125196]
   Fei ZX, 2022, NEUROCOMPUTING, V468, P306, DOI 10.1016/j.neucom.2021.10.038
   Fleet D., 2006, OPTICAL FLOW ESTIMAT
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Fridenson-Hayo S, 2017, EUR CHILD ADOLES PSY, V26, P979, DOI 10.1007/s00787-017-0968-0
   Ghimire D., 2015, International Journal of Multimedia and Ubiquitous Engineering, V10, P35
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   Grossard C, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00446
   Grossard C, 2017, COMPUT EDUC, V113, P195, DOI 10.1016/j.compedu.2017.05.002
   Grossard Charline, 2019, Creat. Educ., V10, P2347, DOI [10.4236/ce.2019.1011167, DOI 10.4236/CE.2019.1011167]
   Grossman RB, 2013, J SPEECH LANG HEAR R, V56, P1035, DOI 10.1044/1092-4388(2012/12-0067)
   Hajarian M, 2019, SOC NETW ANAL MIN, V9, DOI 10.1007/s13278-019-0589-3
   Ingersoll B., 2005, FOCUS AUTISM DEV DIS, V20, P213, DOI DOI 10.1177/10883576050200040301
   Jain DK, 2019, PATTERN RECOGN LETT, V120, P69, DOI 10.1016/j.patrec.2019.01.008
   Javarone MA, 2016, STUD COMPUT INTELL, V644, P227, DOI 10.1007/978-3-319-30569-1_17
   Jenhani Y, 2008, INT J APPROX REASON, V48, P784, DOI 10.1016/j.ijar.2007.12.002
   Jones EJH, 2014, NEUROSCI BIOBEHAV R, V39, P1, DOI 10.1016/j.neubiorev.2013.12.001
   Kabir Md Hasanul, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P526, DOI 10.1109/AVSS.2010.9
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lima Antonio Marcos Oliveira de, 2019, Rev. CEFAC, V21, pe12318, DOI 10.1590/1982-02162019/21112318
   Maenner MJ., 2021, MMWR SURVEILL SUMM, V70, P1, DOI [DOI 10.15585/MMWR.SS7011A1, 10.15585/mmwr.ss7011a1, DOI 10.15585/MMWR.SS6904A1]
   Mancini G, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01303
   Manta O, 2020, P 13 ACM INT C PERV, P1
   Modhej N, 2020, IEEE ACCESS, V8, P212803, DOI 10.1109/ACCESS.2020.3040298
   Mozilla, 2018, HTML5 ONLINE
   Noor J, 2020, 2020 INT C ELECT COM, P1
   OMS, 2017, AUTISM SPECTRUM DISO
   Oster H., 2005, Emotional development: Recent research advances, P261
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Pell PJ, 2013, VISION RES, V79, P1, DOI 10.1016/j.visres.2012.12.009
   Pennington RC, 2019, TOP LANG DISORD, V39, P191, DOI 10.1097/TLD.0000000000000181
   Ribu K, 2010, TEACHING COMPUTER SC
   Roccetti M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00428-8
   Ross P, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00309
   Sagayaraj K., 2020, International journal of Innovative Science and Research Technology, V5, P863
   Salmam FZ, 2016, I C COMP GRAPH IM VI, P125, DOI 10.1109/CGiV.2016.33
   Sanchez A, 2011, NEUROCOMPUTING, V74, P1272, DOI 10.1016/j.neucom.2010.07.017
   Sandin S, 2014, JAMA-J AM MED ASSOC, V311, P1770, DOI 10.1001/jama.2014.4144
   Santana Carla C. V. P. de, 2014, Psychol. Neurosci., V7, P73
   Scassellati B, 2012, ANNU REV BIOMED ENG, V14, P275, DOI 10.1146/annurev-bioeng-071811-150036
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Somasundaram A, 2016, PROC 1 INT C RES ENG, P1
   Strickroth Sven, 2020, i-com: Journal of Interactive Media, V19, P17, DOI 10.1515/icom-2020-0003
   Sun YM, 2009, INT J PATTERN RECOGN, V23, P687, DOI 10.1142/S0218001409007326
   Takalkar M, 2018, MULTIMED TOOLS APPL, V77, P19301, DOI 10.1007/s11042-017-5317-2
   Takbiri Y, 2019, 2019 5 IR C SIGN PRO, P1, DOI [10.1109/ICSPIS48872.2019.9066006, DOI 10.1109/ICSPIS48872.2019.9066006]
   Tan JW, 2019, JMIR SERIOUS GAMES, V7, DOI 10.2196/14620
   Trevisan DA, 2018, AUTISM RES, V11, P1586, DOI 10.1002/aur.2037
   Tsangouri C., 2016, MIT UND RES TECHN C, P1, DOI [10.1109/URTC.2016.8284067, DOI 10.1109/URTC.2016.8284067]
   Valstar MF, 2017, IEEE INT CONF AUTOMA, P839, DOI 10.1109/FG.2017.107
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P28, DOI 10.1109/TSMCB.2011.2163710
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wu BF, 2018, IEEE ACCESS, V6, P12451, DOI 10.1109/ACCESS.2018.2805861
   Zavarez MV, 2017, SIBGRAPI, P405, DOI 10.1109/SIBGRAPI.2017.60
   Zichermann G., 2011, GAMIFICATION DESIGN
NR 81
TC 8
Z9 8
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25947
EP 25969
DI 10.1007/s11042-022-12810-6
EA MAR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000773206100005
DA 2024-07-18
ER

PT J
AU Chalabi, NE
   Attia, A
   Bouziane, A
   Akhtar, Z
AF Chalabi, Nour Elhouda
   Attia, Abdelouahab
   Bouziane, Abderraouf
   Akhtar, Zahid
TI Face based person recognition mechanism using monogenic Binarized
   Statistical Image Features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; monogenic signal representation; BSIF; Log Gabor
   filter; Feature extraction
ID PALMPRINT; EIGENFACES; PATTERNS
AB These days, automated face recognition systems are hugely being applied in diverse applications ranging from personal use to border crossing. Feature extraction/representation is extremely vital module in any biometric systems, including face recognition. Thus, the main contribution of this paper is the proposition of a novel descriptor based on monogenic signal representation and Binarized Statistical Image Feature (BSIF) to extract quite distinctive relevant features from face image, named (M-BSIF). In fact, BSIF has not always efficient for face feature extraction, as it was not able to attain the best recognition rates. In order to enhance the capability of BSIF feature representation, our proposed feature description scheme, first applies band pass mechanism via log-Gabor filter on the image, then a monogenic filter is applied to decompose face image into three complementary parts, i.e., local amplitude, local phase, and local orientation. Next, BSIF is utilized to encode these complementary components in order to extract M-BSIF features. Experimental analyses on three publicly available databases (i.e., ORL database, AR database and JAFFE database) demonstrate the efficacy of the proposed M-BSIF descriptor. The proposed system outperforms a framework using only single BSIF.
C1 [Chalabi, Nour Elhouda; Attia, Abdelouahab; Bouziane, Abderraouf] Mohamed El Bachir El Ibrahimi Univ, Comp Sci Dept, Bordj Bou Arreridj 34000, Algeria.
   [Chalabi, Nour Elhouda; Attia, Abdelouahab; Bouziane, Abderraouf] Mohamed El Bachir El Ibrahimi Univ, LMSE Lab, Bordj Bou Arreridj 34000, Algeria.
   [Akhtar, Zahid] State Univ New York Polytech Inst, Dept Network & Comp Secur, Utica, NY 13502 USA.
RP Chalabi, NE (corresponding author), Mohamed El Bachir El Ibrahimi Univ, Comp Sci Dept, Bordj Bou Arreridj 34000, Algeria.; Chalabi, NE (corresponding author), Mohamed El Bachir El Ibrahimi Univ, LMSE Lab, Bordj Bou Arreridj 34000, Algeria.
EM chalabi.houda94@gmail.com
RI ATTIA, Abdelouahab/HJA-2990-2022; ATTIA, Abdelouahab/ADD-8906-2022
OI Chalabi, Nour Elhouda/0000-0001-5231-1597; Akhtar,
   Zahid/0000-0002-5026-5416; ATTIA, Abdelouahab/0000-0003-1558-7273
CR Akhtar Z, 2017, COMPUTER, V50, P80, DOI 10.1109/MC.2017.119
   Akhtar Z, 2011, INT PROC COMPUT SCI, V4, P52
   Annamalai P., 2020, INT J INTELL ENG SYS, V13, P19
   [Anonymous], 2016, Introduction to Fourier analysis on Euclidean spaces
   Attia A, 2021, SIGNAL IMAGE VIDEO P, V15, P851, DOI 10.1007/s11760-020-01806-0
   Attia A, 2021, EVOL SYST-GER, V12, P1015, DOI 10.1007/s12530-020-09359-w
   Attia A, 2020, EVOL SYST-GER, V11, P625, DOI 10.1007/s12530-018-9260-x
   Basu DK, 2020, NEUROCOMPUTING, V408, P273, DOI [DOI 10.1016/J.NEUCOM.2019.10.117, 10.1016/j.neucom.2019.10.117]
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Benavente R, 1998, 24 COMP VIS CTR
   Cambridge A., 2002, The database of faces
   Cheng EJ, 2019, PATTERN RECOGN LETT, V125, P71, DOI 10.1016/j.patrec.2019.03.006
   Doyle JS, 2015, IEEE ACCESS, V3, P1672, DOI 10.1109/ACCESS.2015.2477470
   Dronky MR, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115266
   Felsberg M, 2001, IEEE T SIGNAL PROCES, V49, P3136, DOI 10.1109/78.969520
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Granlund G. H., 2013, Signal Processing for Computer Vision
   Han YJ, 2021, J APPL REMOTE SENS, V15, DOI 10.1117/1.JRS.15.026502
   Huang XH, 2012, IEEE SIGNAL PROC LET, V19, P243, DOI 10.1109/LSP.2012.2188890
   Ji X, 2021, WIREL COMMUN MOB COM
   Kannala J, 2012, INT C PATT RECOG, P1363
   Kovesi P., 1996, Invariant measures of image features from phase information
   Leng L., 2012, P INT C WAV AN PATT, P164, DOI DOI 10.1109/ICWAPR.2012.6294772
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Mishra A, 2019, INT J BIOMETRICS, V11, P389, DOI 10.1504/IJBM.2019.102881
   Munikrishna DC, 2018, INT CONF INTEL INFOR, P321, DOI 10.1109/ICIIBMS.2018.8549957
   Oh YH, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1237, DOI 10.1109/ICDSP.2015.7252078
   Ouamane A., 2015, Pattern Recognition and Image Analysis, V25, P603
   Ouyang AJ, 2020, NEUROCOMPUTING, V393, P214, DOI 10.1016/j.neucom.2019.01.117
   Raja KB, 2014, I W BIOMETRIC FORENS
   Sam Yin Yee, 2020, Advances in Electronics Engineering. Proceedings of the ICCEE 2019. Lecture Notes in Electrical Engineering (LNEE 619), P315, DOI 10.1007/978-981-15-1289-6_29
   Sharma D, 2022, VISUAL COMPUT, V38, P2999, DOI 10.1007/s00371-021-02173-8
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Yan KW, 2017, CHIN CONTR CONF, P4077, DOI 10.23919/ChiCC.2017.8027997
   Yang M, 2012, IEEE T INF FOREN SEC, V7, P1738, DOI 10.1109/TIFS.2012.2217332
   Yang Meng., 2010, INT C PATTERN RECOGN, P2680, DOI DOI 10.1109/ICPR.2010.657
   Ylioinas Juha, 2015, Image Analysis. 19th Scandinavian Conference, SCIA 2015. Proceedings: LNCS 9127, P516, DOI 10.1007/978-3-319-19665-7_44
   Younesi A, 2017, PROCEDIA COMPUT SCI, V108, P2488, DOI 10.1016/j.procs.2017.05.157
NR 42
TC 2
Z9 2
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25657
EP 25674
DI 10.1007/s11042-022-12890-4
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000772288200003
DA 2024-07-18
ER

PT J
AU Asthana, P
   Hanmandlu, M
   Vashisth, S
AF Asthana, Pallavi
   Hanmandlu, Madasu
   Vashisth, Sharda
TI The proposition of Possibilistic sigmoid features and the Shannon-Hanman
   transform classifier along with the pervasive learning model for the
   classification of brain tumor using MRI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor; Classification; Learning model; Feature extraction;
   Shannon-Hanman transform classifier
ID SEGMENTATION; OPTIMIZATION; DESIGN
AB As part of developing a computer-aided diagnosis system for the early detection/classification of brain tumors, this paper presents an Information set-based sigmoid features and a classifier using MR images. A set of information values constituting an Information set springs forth on fitting a membership function to a set of information source (attribute) values, the sum of which gives the certainty/uncertainty in the attribute values to a class, say, the pixel intensities in an MRI to a disease class. This certainty/uncertainty representation is not attempted in the existing methods, thus failing to produce efficient features. To this end, Hanman-Anirban (HA), Mamta-Hanman (MH), and Possibilistic Renyi entropy functions are employed including the pervasive membership function in the generation of four types of sigmoid features. The pervasive Information set results from the use of pervasive membership function that is a combination of the membership function and non-membership function. Furthermore, the Shannon-Hanman Transform classifier is formulated using the t-norm of error vectors between the training and test feature vectors, and its parameters are learned through the Pervasive learning model. The proposed system comprising features, classifier, and the learning model is tested on two Brain MRI's datasets. The t-norm based fusion of two features has also been experimented. The Shannon-Hanman Transform classifier along with the Pervasive learning model is found to outperform the other classifiers in the literature with the highest accuracy of 99.51% for the two-class classification with a fusion of two features and 99.09% for the three-class classification with a sigmoid MH feature.
C1 [Asthana, Pallavi; Vashisth, Sharda] NorthCap Univ, EECE Dept, Gurugram, Haryana, India.
   [Hanmandlu, Madasu] MVSR Engn Coll, CSE Dept, Hyderabad, India.
C3 The Northcap University; Maturi Venkata Subba Rao Engineering College
RP Asthana, P (corresponding author), NorthCap Univ, EECE Dept, Gurugram, Haryana, India.
EM pallaviasthana87@gmail.com
RI Vashisth, Sharda/HHS-8370-2022; Asthana, Pallavi/JMC-3340-2023
OI Asthana, Pallavi/0000-0002-3993-6776
CR Achanta SDM, 2019, INT J INTELL UNMANNE, V8, P43, DOI 10.1108/IJIUS-01-2019-0005
   Achanta SDM, 2019, SOFT COMPUT, V23, P8359, DOI 10.1007/s00500-019-04108-x
   Aggarwal M, 2016, IEEE T FUZZY SYST, V24, P1, DOI 10.1109/TFUZZ.2015.2417593
   Agrawal R, 2018, APPL ARTIF INTELL, V32, P670, DOI 10.1080/08839514.2018.1504500
   Ahmmed R, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND COMMUNICATION ENGINEERING (ECCE), P229, DOI 10.1109/ECACE.2017.7912909
   Alfonse M., 2016, EGY COMP SCI J, V40
   Artzi M, 2019, J MAGN RESON IMAGING, V50, P519, DOI 10.1002/jmri.26643
   Asthana P, 2022, INT J IMAG SYST TECH, V32, P280, DOI 10.1002/ima.22619
   Atanassov K. T., 1986, Fuzzy Sets and Systems, V20, P87, DOI 10.1016/S0165-0114(86)80034-3
   Badza MM, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10061999
   Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117
   Bakas Spyridon, 2018, ARXIV181102629, DOI DOI 10.17863/CAM.38755
   Bhatia Aparna, 2018, J MODERN PHYS, V09, P112, DOI [10.4236/jmp.2018.92008, DOI 10.4236/JMP.2018.92008]
   Bodapati JD, 2021, SIGNAL IMAGE VIDEO P, V15, P753, DOI 10.1007/s11760-020-01793-2
   Calvo T, 2001, FUZZY SET SYST, V120, P385, DOI 10.1016/S0165-0114(99)00125-6
   Cheng J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0115339
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   Grover J, 2021, APPL INTELL, V51, P1513, DOI 10.1007/s10489-020-01881-3
   Grover J, 2018, APPL INTELL, V48, P3394, DOI 10.1007/s10489-018-1154-x
   Gumaei A, 2019, IEEE ACCESS, V7, P36266, DOI 10.1109/ACCESS.2019.2904145
   Hanmandlu M, 2011, DEFENCE SCI J, V61, P415, DOI 10.14429/dsj.61.1177
   Hanmandlu M, 2003, PATTERN RECOGN LETT, V24, P81, DOI 10.1016/S0167-8655(02)00191-5
   Hanmandlu M., 2019, J MOD PHYS, V11, P122, DOI [10.4236/jmp.2020.111008, DOI 10.4236/JMP.2020.111008]
   JUST M, 1991, MAGN RESON IMAGING, V9, P173, DOI 10.1016/0730-725X(91)90007-9
   Kang J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062222
   Kaplan K, 2020, MED HYPOTHESES, V139, DOI 10.1016/j.mehy.2020.109696
   Kazemifar S, 2019, RADIOTHER ONCOL, V136, P56, DOI 10.1016/j.radonc.2019.03.026
   Khan MA, 2019, SUST PLANT CROP PRO, P1, DOI [10.1007/978-3-030-23045-6_1, 10.1002/jemt.23238]
   Kumar RL, 2021, MULTIMED TOOLS APPL, V80, P13429, DOI 10.1007/s11042-020-10335-4
   Kumar S, 2020, BIOCYBERN BIOMED ENG, V40, P1190, DOI 10.1016/j.bbe.2020.05.009
   Mamta, 2014, ENG APPL ARTIF INTEL, V36, P269, DOI 10.1016/j.engappai.2014.06.028
   Menze BH, 2016, IEEE T MED IMAGING, V35, P933, DOI 10.1109/TMI.2015.2502596
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Mohan G, 2018, BIOMED SIGNAL PROCES, V39, P139, DOI 10.1016/j.bspc.2017.07.007
   Mohsen Heba, 2018, Future Computing and Informatics Journal, V3, P68, DOI 10.1016/j.fcij.2017.12.001
   Özyurt F, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109433
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Rao R., 2016, Int J Ind Eng Comput, V7, P19, DOI [DOI 10.5267/J.IJIEC.2015.8.004, 10.5267/j.ijiec.2015.8.004]
   Rao RV, 2011, COMPUT AIDED DESIGN, V43, P303, DOI 10.1016/j.cad.2010.12.015
   Rehman A, 2020, CIRC SYST SIGNAL PR, V39, P757, DOI 10.1007/s00034-019-01246-3
   Renyi A., 1961, P 4 BERK S MATH STAT, V1, P547
   Sauwen N, 2016, NEUROIMAGE-CLIN, V12, P753, DOI 10.1016/j.nicl.2016.09.021
   Sayeed F, 2017, KNOWL INF SYST, V52, P485, DOI 10.1007/s10115-016-1017-x
   Sharif M, 2020, PATTERN RECOGN LETT, V129, P150, DOI 10.1016/j.patrec.2019.11.017
   Sriramakrishnan P., 2018, INT J COMPUT SCI ENG, V6, P191
   Subudhi A, 2020, BIOCYBERN BIOMED ENG, V40, P277, DOI 10.1016/j.bbe.2019.04.004
   Sultan HH, 2019, IEEE ACCESS, V7, P69215, DOI 10.1109/ACCESS.2019.2919122
   Varuna Shree N, 2018, BRAIN INFORM, V5, P23, DOI DOI 10.1007/S40708-017-0075-5
   Zhuge Y, 2020, MED PHYS, V47, P3044, DOI 10.1002/mp.14168
NR 49
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 23913
EP 23939
DI 10.1007/s11042-022-12482-2
EA MAR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000002
DA 2024-07-18
ER

PT J
AU Munir, A
   Martinel, N
   Micheloni, C
AF Munir, Asad
   Martinel, Niki
   Micheloni, Christian
TI Consistent attentive dual branch network for person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person Re-Identification; Attentive networks; Person search
AB Several recent person re-identification methods are focusing on learning discriminative representations by designing efficient metric learning loss functions. Other approaches design part based architectures to compute an informative descriptor based on local features from semantically coherent parts. Few efforts learn the relationship between distant similar regions and parts by adjusting them to their most feasible positions with the help of soft attention. However, they focus on calibrating distant similar parts features and ignore to learn the noise (blur) free and distinct feature representations as the person re-identification datasets contain degraded images. To tackle these issues, we propose a novel Consistent Attention Dual Branch Network (CadNet) that has ability to model long-range dependencies (correlations) between channels as well as feature maps. We adopt multiple classifiers trained to learn the most discriminative global features for a unique representation of a person. Correlation between channels are consistently computed by using channel attention mechanism to make the learned feature noise free and distict from noisy and blurry data. Feature correlations interpret the relationship between distant similarities in the images computed by the self attention mechanism. The proposed CadNet significantly enhances the performance with respect to the baseline on the person re-identification benchmarks.
C1 [Munir, Asad; Martinel, Niki; Micheloni, Christian] Univ Udine, Dept Comp Sci, Udine, Italy.
C3 University of Udine
RP Munir, A (corresponding author), Univ Udine, Dept Comp Sci, Udine, Italy.
EM asad.munir@uniud.it; niki.martinel@uniud.it;
   christian.micheloni@uniud.it
RI Micheloni, Christian/E-5427-2012
FU EU H2020 MSCA [765866]
FX This work was supported by EU H2020 MSCA through Project ACHIEVE-ITN
   (Grant No 765866).
CR [Anonymous], 2015, PROC CVPR IEEE
   Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chen DP, 2018, PROC CVPR IEEE, P8649, DOI 10.1109/CVPR.2018.00902
   [陈珺娴 Chen Junxian], 2020, [高分子通报, Polymer Bulletin], P1
   Chen L., 2020, NEUROCOMPUTING
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hermans Alexander, 2017, ARXIV170307737
   Howard A. G., 2013, Some improvements on deep convolutional neural network based image classification
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Luo CC, 2019, IEEE I CONF COMP VIS, P4975, DOI 10.1109/ICCV.2019.00508
   Martinel N, 2019, IEEE COMPUT SOC CONF, P1544, DOI 10.1109/CVPRW.2019.00196
   Micheloni C, 2010, INTELLIGENT MONITORI
   Munir A, 2020, SPLITECH
   Munir A, 2020, IEEE IMAGE PROC, P2351, DOI [10.1109/icip40778.2020.9191115, 10.1109/ICIP40778.2020.9191115]
   Munir A, 2021, INT C PATT RECOG, P4025, DOI 10.1109/ICPR48806.2021.9413159
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Shen YT, 2018, PROC CVPR IEEE, P6886, DOI 10.1109/CVPR.2018.00720
   Shen YT, 2018, LECT NOTES COMPUT SC, V11219, P508, DOI 10.1007/978-3-030-01267-0_30
   Shu X, 2020, MULTIMED TOOLS APPL, V79, P23617, DOI 10.1007/s11042-020-09018-x
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Wang C, 2020, NEUROCOMPUTING, V382, P64, DOI 10.1016/j.neucom.2019.11.062
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Xiang SC, 2020, MULTIMED TOOLS APPL, V79, P32079, DOI 10.1007/s11042-020-09569-z
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Yu R, 2018, LECT NOTES COMPUT SC, V11220, P196, DOI 10.1007/978-3-030-01270-0_12
   Zhai Y, 2019, IEEE COMPUT SOC CONF, P1526, DOI 10.1109/CVPRW.2019.00194
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang W, 2018, IEEE CONF COMPUT
   Zhang Xiangyu, 2017, CoRRabs/1711.08184
   Zhang YZ, 2020, MULTIMED TOOLS APPL, V79, P28603, DOI 10.1007/s11042-020-09427-y
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zhedong Zheng, 2017, ACM Transactions on Multimedia Computing, Communications and Applications, V14, DOI 10.1145/3159171
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng M, 2019, PROC CVPR IEEE, P5728, DOI 10.1109/CVPR.2019.00588
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong WL, 2020, MULTIMED TOOLS APPL, V79, P22525, DOI 10.1007/s11042-019-08395-2
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
NR 53
TC 2
Z9 2
U1 4
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24431
EP 24448
DI 10.1007/s11042-022-12732-3
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000006
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Taheri, M
   Zhang, CQ
   Berardehi, ZR
   Chen, YC
   Roohi, M
AF Taheri, Mostafa
   Zhang, Chongqi
   Berardehi, Zahra Rasooli
   Chen, Yucheng
   Roohi, Majid
TI No-chatter model-free sliding mode control for synchronization of
   chaotic fractional-order systems with application in image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Model-free sliding mode control; Chaotic fractional-order systems;
   Chattering-free method; Synchronization; Encryption; decryption
ID SECURE COMMUNICATION; TIME SYNCHRONIZATION; STABILIZATION; DESIGN;
   SCHEME
AB Synchronization of different Chaotic dynamical systems is one of the main issues in engineering which has a lot of applications in applied sciences like secure communications and cryptography. In this work, a chattering-free fractional-integral-based sliding mode control (SMC) methodology is proposed for the synchronization of different chaotic fractional-order systems with input saturation. Based on the frequency distributed model and the non-integer version of the Lyapunov stability theorem and using a new continuous function instead of sign function, a novel model-free SMC (MFSMC) method is proposed to overcome the chaotic behavior of the FOSs without any undesired chattering phenomenon. In addition, utilizing the boundedness property of the fractional-order chaotic system is caused to design the method. Then, by operating the proposed scheme on chaotic fractional-order systems, which are applied in electrical systems and secure communications, the effectiveness and applicability of the MFSMC are validated. After that, to show the real-world application, a novel encryption/decryption method for color images is introduced based on the proposed MFSMC. According to an adaption of the pre-diffusion-permutation-diffusion, the structure is adopted to improve the level of security. Furthermore, the performance and security analyses are given to confirm the superiority of the proposed encryption scheme, including histogram analysis, adjacent pixel correlation analysis, and information entropy analysis.
C1 [Taheri, Mostafa; Zhang, Chongqi; Berardehi, Zahra Rasooli; Roohi, Majid] Guangzhou Univ, Sch Econ & Stat, Guangzhou 510006, Peoples R China.
   [Chen, Yucheng] Jiaying Univ, Sch Math, Meizhou 514015, Peoples R China.
C3 Guangzhou University; Jiaying University
RP Zhang, CQ (corresponding author), Guangzhou Univ, Sch Econ & Stat, Guangzhou 510006, Peoples R China.
EM cqzhang@gzhu.edu.cn
RI Chen, Yu-Cheng/ISS-5682-2023; Roohi, Majid/AAW-2928-2020; chen,
   yu-cheng/IQT-1648-2023
OI Chen, Yu-Cheng/0000-0003-1696-4667; Roohi, Majid/0000-0003-4835-269X;
   Rasooli, Zahra/0000-0002-8350-4006; Taheri, Mostafa/0000-0001-7962-2141
FU National Nature Sciences Foundation of China [12071096]
FX This work is supported by the National Nature Sciences Foundation of
   China (Grant No. 12071096).
CR Aghababa MP, 2020, ADV DIFFER EQU-NY, V2020, DOI 10.1186/s13662-020-02829-0
   Aghababa MP, 2021, INT J CONTROL, V94, P2479, DOI 10.1080/00207179.2020.1712478
   Aghababa MP, 2017, NONLINEAR DYNAM, V89, P1357, DOI 10.1007/s11071-017-3520-3
   Aghababa MP, 2015, IET GENER TRANSM DIS, V9, P1883, DOI 10.1049/iet-gtd.2015.0038
   Aghababa MP, 2014, COMPLEXITY, V20, P37, DOI 10.1002/cplx.21502
   Aghababa MP, 2012, NONLINEAR DYNAM, V69, P247, DOI 10.1007/s11071-011-0261-6
   Ahmad WM, 2007, CHAOS SOLITON FRACT, V33, P1367, DOI 10.1016/j.chaos.2006.01.098
   Argyris A, 2005, NATURE, V438, P343, DOI 10.1038/nature04275
   Asgharnia A, 2020, ISA T, V96, P272, DOI 10.1016/j.isatra.2019.07.006
   Asl MS, 2017, J COMPUT APPL MATH, V324, P101, DOI 10.1016/j.cam.2017.04.026
   Babes B., 2019, INT C ADV EL ENG 201
   Babu NR, 2021, MULTIMED TOOLS APPL, V80, P18043, DOI 10.1007/s11042-020-10288-8
   Balamash AS, 2020, CHAOS, V30, DOI 10.1063/1.5142989
   Balasubramaniam P, 2015, NONLINEAR DYNAM, V80, P249, DOI 10.1007/s11071-014-1865-4
   Cai W, 2020, MECH MATER, V145, DOI 10.1016/j.mechmat.2020.103391
   Caponetto R., 2020, 2020 IEEE INT INSTR, P1
   Chen C, 2019, DISCRETE DYN NAT SOC, V2019, DOI 10.1155/2019/8743482
   Chen YC, 2021, J FRANKLIN I, V358, P8109, DOI 10.1016/j.jfranklin.2021.08.007
   Chen YC, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/3026972
   Chen YC, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107286
   Cohen I, 2001, MATH METHOD APPL SCI, V24, P1429, DOI 10.1002/mma.190
   Curran PF, 1997, INT J BIFURCAT CHAOS, V7, P1375, DOI 10.1142/S0218127497001096
   Diethelm K, 2002, NONLINEAR DYNAM, V29, P3, DOI 10.1023/A:1016592219341
   Diethelm K, 2013, NONLINEAR DYNAM, V71, P613, DOI 10.1007/s11071-012-0475-2
   Djimasra F, 2021, MULTIMED TOOLS APPL, V80, P25121, DOI 10.1007/s11042-021-10734-1
   Doubla IS, 2021, NEURAL COMPUT APPL, V33, P14945, DOI 10.1007/s00521-021-06130-3
   Esfahani Z, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163411
   Fradkov AL, 2005, ANNU REV CONTROL, V29, P33, DOI 10.1016/j.arcontrol.2005.01.001
   Haghighi A, 2020, ADV DIFFER EQU-NY, V2020, DOI 10.1186/s13662-020-02954-w
   Javan AAK, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113925
   Jia HY, 2013, NONLINEAR DYNAM, V74, P203, DOI 10.1007/s11071-013-0958-9
   Javan AAK, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010254
   Khan A., 2019, Int J Dyn Control, V7, P1419, DOI [10.1007/s40435-019-00585-y, DOI 10.1007/S40435-019-00585-Y]
   Laskin N, 2002, PHYS REV E, V66, DOI 10.1103/PhysRevE.66.056108
   Li CG, 2004, CHAOS SOLITON FRACT, V22, P549, DOI 10.1016/j.chaos.2004.02.035
   Li CP, 2007, APPL MATH COMPUT, V187, P777, DOI 10.1016/j.amc.2006.08.163
   Li GH, 2020, IEEE ACCESS, V8, P53360, DOI 10.1109/ACCESS.2020.2980935
   Li RG, 2019, ISA T, V92, P35, DOI 10.1016/j.isatra.2019.02.027
   Li Y, 2010, COMPUT MATH APPL, V59, P1810, DOI 10.1016/j.camwa.2009.08.019
   Li Y, 2019, MOD PHYS LETT B, V33, DOI 10.1142/S0217984919502907
   Liu X, 2021, NEURAL COMPUT APPL, V33, P10503, DOI 10.1007/s00521-021-05808-y
   Lu JG, 2006, PHYS LETT A, V354, P305, DOI 10.1016/j.physleta.2006.01.068
   Luo S, 2020, NONLINEAR DYNAM, V100, P523, DOI 10.1007/s11071-020-05518-5
   Modiri A, 2020, ISA T, V105, P33, DOI 10.1016/j.isatra.2020.05.039
   Mofid O, 2019, INT J ADAPT CONTROL, V33, P462, DOI 10.1002/acs.2965
   Mohadeszadeh M, 2021, ASIAN J CONTROL, V23, P412, DOI 10.1002/asjc.2269
   Moon S, 2021, COMMUN NONLINEAR SCI, V96, DOI 10.1016/j.cnsns.2021.105708
   Muñoz-Guillermo M, 2021, INFORM SCIENCES, V552, P352, DOI 10.1016/j.ins.2020.11.045
   Muthukumar P, 2017, MULTIMED TOOLS APPL, V76, P23517, DOI 10.1007/s11042-016-4052-4
   Muthukumar P., 2017, International Journal of Dynamics and Control, V5, P115, DOI DOI 10.1007/S40435-015-0169-Y
   Nassajian G, 2020, NEURAL PROCESS LETT, V52, P221, DOI 10.1007/s11063-020-10261-4
   Njitacke ZT, 2021, NEURAL COMPUT APPL, V33, P6733, DOI 10.1007/s00521-020-05451-z
   Podlubny I., 1998, FRACTIONAL DIFFERENT
   Rajagopal K, 2021, ASIAN J CONTROL, V23, P894, DOI 10.1002/asjc.2261
   Roohi M, 2020, NONLINEAR DYNAM, V100, P3979, DOI 10.1007/s11071-020-05719-y
   Roohi M, 2019, T I MEAS CONTROL, V41, P2932, DOI 10.1177/0142331219834606
   Roohi M, 2015, COMPLEXITY, V21, P211, DOI 10.1002/cplx.21598
   Sabzalian MH, 2019, NONLINEAR DYNAM, V98, P2375, DOI 10.1007/s11071-019-05217-w
   Shao K, 2020, INT J DYN CONTROL, V9, P541
   Shirkavand M, 2018, CHAOS SOLITON FRACT, V113, P135, DOI 10.1016/j.chaos.2018.05.020
   Song L, 2010, COMMUN NONLINEAR SCI, V15, P616, DOI 10.1016/j.cnsns.2009.04.029
   Song S, 2021, IEEE T SYST MAN CY-S, V51, P7238, DOI 10.1109/TSMC.2020.2967425
   Song XN, 2017, J CONTROL SCI ENG, V2017, DOI 10.1155/2017/9562818
   Sun HG, 2018, COMMUN NONLINEAR SCI, V64, P213, DOI 10.1016/j.cnsns.2018.04.019
   Sun ZW, 2018, CHINESE J PHYS, V56, P2553, DOI 10.1016/j.cjph.2018.08.007
   Tang XN, 2020, INT J FUZZY SYST, V22, P943, DOI 10.1007/s40815-020-00814-z
   Tsafack N, 2020, IEEE ACCESS, V8, P137731, DOI 10.1109/ACCESS.2020.3010794
   Vafamand N, 2018, CHAOS SOLITON FRACT, V112, P116, DOI 10.1016/j.chaos.2018.04.035
   Vafamand N, 2018, IJST-T ELECTR ENG, V42, P83, DOI 10.1007/s40998-018-0047-7
   Wang B, 2016, NONLINEAR DYNAM, V85, P2133, DOI 10.1007/s11071-016-2819-9
   Wang JC, 2020, FUTURE GENER COMP SY, V110, P57, DOI 10.1016/j.future.2020.04.002
   Weitzner H, 2003, COMMUN NONLINEAR SCI, V8, P273, DOI 10.1016/S1007-5704(03)00049-2
   Xue W, 2015, J FRANKLIN I, V352, P2887, DOI 10.1016/j.jfranklin.2015.05.025
   Yan Y, 2012, MATH COMPUT SIMULAT, V82, P1572, DOI 10.1016/j.matcom.2012.01.004
   Yin C, 2012, J FRANKLIN I, V349, P3078, DOI 10.1016/j.jfranklin.2012.09.009
   Zhang LZ, 2021, NEURAL NETWORKS, V144, P11, DOI 10.1016/j.neunet.2021.08.004
   Zhao CF, 2020, NONLINEAR DYNAM, V100, P679, DOI 10.1007/s11071-020-05526-5
   Zhou P, 2015, NONLINEAR DYNAM, V82, P519, DOI 10.1007/s11071-015-2172-4
   Zouad F, 2019, ANALOG INTEGR CIRC S, V99, P619, DOI 10.1007/s10470-018-01382-x
NR 79
TC 13
Z9 14
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24167
EP 24197
DI 10.1007/s11042-022-12329-w
EA MAR 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000023
DA 2024-07-18
ER

PT J
AU Khosravanian, A
   Rahmanimanesh, M
   Keshavarzi, P
   Mozaffari, S
   Kazemi, K
AF Khosravanian, Asieh
   Rahmanimanesh, Mohammad
   Keshavarzi, Parviz
   Mozaffari, Saeed
   Kazemi, Kamran
TI Level set method for automated 3D brain tumor segmentation using
   symmetry analysis and kernel induced fuzzy clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic segmentation; 3D brain tumor segmentation; Kernel mapping;
   Level set method; Symmetry analysis
ID ACTIVE CONTOUR MODEL; IMAGE SEGMENTATION; MRI; ENERGY
AB Automatic brain tumor segmentation in magnetic resonance images (MRIs) is an essential stage for treatment planning. However, MR image segmentation is challenging owing to non-uniformity in the intensity distribution, tumor shape, size, and location variation. The paper proposes a new level set method that is called Fuzzy Kernel Level Set (FKLS) for 3D brain tumor segmentation in MR images. To avoid computational complexity, fast bounding box based on symmetry analysis is used to extract the volume of interest (VOI) in brain MRIs. Then, a level set method is proposed based on fuzzy c-means clustering and kernel mapping. A kernel function is used to transfer the image into another domain, where the new proposed functional is minimized. To assess the proposed FKLS method, a synthetic image and natural brain MR images from BraTS 2017 are segmented. Experimental results show that our method is superior to the state-of-the-art segmentation methods regarding the segmentation accuracy based on Dice, Jaccard, Sensitivity, and Specificity metrics. The mean values of these metrics are 97.62% +/- (0.94%), 95.41% +/- (1.8%), 98.79% +/- (0.63%), and 99.85% +/- (0.09%), respectively.
C1 [Khosravanian, Asieh; Rahmanimanesh, Mohammad; Keshavarzi, Parviz; Mozaffari, Saeed] Semnan Univ, Fac Elect & Comp Engn, Semnan, Iran.
   [Kazemi, Kamran] Shiraz Univ Technol, Dept Elect & Elect Engn, Shiraz, Iran.
C3 Semnan University; Shiraz University of Technology
RP Khosravanian, A; Rahmanimanesh, M (corresponding author), Semnan Univ, Fac Elect & Comp Engn, Semnan, Iran.
EM a.khosravanian@semnan.ac.ir; rahmanimanesh@semnan.ac.ir;
   pkeshavarzi@semnan.ac.ir; mozaffari@semnan.ac.ir; kazemi@sutech.ac.ir
RI Keshavarzi, Parviz/M-2641-2017
OI zy, P/0009-0006-2820-8788
CR Aswathy SU., 2015, INDIAN J SCI TECHNOL, V8, P1, DOI 10.17485/ijst/2015/v8i34/85361
   Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117
   Ben Naceur M, 2018, COMPUT METH PROG BIO, V166, P39, DOI 10.1016/j.cmpb.2018.09.007
   Ben Salah M, 2010, IEEE T IMAGE PROCESS, V19, P220, DOI 10.1109/TIP.2009.2032940
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Cata M, 2017, 2017 INT MICCAI BRAT
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen YJ, 2019, SIGNAL IMAGE VIDEO P, V13, P1421, DOI 10.1007/s11760-019-01491-8
   Essadike A, 2018, COMPUT METH PROG BIO, V160, P103, DOI 10.1016/j.cmpb.2018.04.004
   Fang LL, 2020, INFORM SCIENCES, V513, P504, DOI 10.1016/j.ins.2019.10.051
   Hasan AM, 2016, SYMMETRY-BASEL, V8, DOI 10.3390/sym8110132
   Hashemzehi R, 2020, BIOCYBERN BIOMED ENG, V40, P1225, DOI 10.1016/j.bbe.2020.06.001
   Hussain S, 2018, NEUROCOMPUTING, V282, P248, DOI 10.1016/j.neucom.2017.12.032
   Ibrahim RW, 2018, COMPUT METH PROG BIO, V163, P21, DOI 10.1016/j.cmpb.2018.05.031
   Ilunga-Mbuyamba E, 2017, COMPUT BIOL MED, V91, P69, DOI 10.1016/j.compbiomed.2017.10.003
   Ilunga-Mbuyamba E, 2017, NEUROCOMPUTING, V220, P84, DOI 10.1016/j.neucom.2016.07.057
   Isin A, 2016, PROCEDIA COMPUT SCI, V102, P317, DOI 10.1016/j.procs.2016.09.407
   Kamnitsas K, 2018, LECT NOTES COMPUT SC, V10670, P450, DOI 10.1007/978-3-319-75238-9_38
   Karnawat A., 2017, P MICCAI BRATS C CAN
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Kumar S, 2020, BIOCYBERN BIOMED ENG, V40, P1190, DOI 10.1016/j.bbe.2020.05.009
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2014, MAGN RESON IMAGING, V32, P913, DOI 10.1016/j.mri.2014.03.010
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li C, 2007, PROCEEDINGS OF THE 6TH INTERNATIONAL SYMPOSIUM ON COAL COMBUSTION, P1, DOI 10.1145/1329125.1329187
   Li QN, 2018, IEEE ACCESS, V6, P9543, DOI 10.1109/ACCESS.2018.2807698
   Lok KH, 2017, J X-RAY SCI TECHNOL, V25, P301, DOI 10.3233/XST-17261
   Lopez MM, 2017, INT MICCAI BRAINL WO
   Lorenzo PR, 2019, COMPUT METH PROG BIO, V176, P135, DOI 10.1016/j.cmpb.2019.05.006
   Ma DD, 2019, SIGNAL PROCESS-IMAGE, V76, P201, DOI 10.1016/j.image.2019.05.006
   Maharjan S, 2020, J NEUROSCI METH, V330, DOI 10.1016/j.jneumeth.2019.108520
   Mahata N, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106171
   Meng XR, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0183943
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Mittal M, 2019, APPL SOFT COMPUT, V78, P346, DOI 10.1016/j.asoc.2019.02.036
   Naser MA, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103758
   Ozyurt F, 2019, MEASUREMENT, V147, DOI 10.1016/j.measurement.2019.07.058
   Raja PMS, 2020, BIOCYBERN BIOMED ENG, V40, P440, DOI 10.1016/j.bbe.2020.01.006
   Rehman ZU, 2019, EXPERT SYST APPL, V118, P598, DOI 10.1016/j.eswa.2018.10.040
   Saba T, 2020, COGN SYST RES, V59, P221, DOI 10.1016/j.cogsys.2019.09.007
   Saha BN, 2012, COMPUT MED IMAG GRAP, V36, P95, DOI 10.1016/j.compmedimag.2011.06.001
   Shahvaran Z, 2016, SIGNAL IMAGE VIDEO P, V10, P887, DOI 10.1007/s11760-015-0836-7
   Shahvaran Zahra, 2012, J Med Signals Sens, V2, P17
   Castillo LS, 2017, PROC SPIE, V10572, DOI 10.1117/12.2285942
   Sisik F, 2020, MED HYPOTHESES, V136, DOI 10.1016/j.mehy.2019.109507
   Soltaninejad M, 2019, ARXIV PREPRINT ARXIV
   Soltaninejad M, 2018, COMPUT METH PROG BIO, V157, P69, DOI 10.1016/j.cmpb.2018.01.003
   Song YT, 2017, J SIGNAL PROCESS SYS, V87, P249, DOI 10.1007/s11265-016-1188-4
   Virupakshappa, 2019, COGN TECHNOL WORK, V21, P357, DOI 10.1007/s10111-018-0472-4
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
NR 51
TC 11
Z9 11
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21719
EP 21740
DI 10.1007/s11042-022-12445-7
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000769836800001
DA 2024-07-18
ER

PT J
AU Gupta, R
   Mehrotra, D
   Tyagi, RK
AF Gupta, Richa
   Mehrotra, Deepti
   Tyagi, Rajesh Kumar
TI Hybrid edge-based fractal image encoding using K-NN search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive fractal image compression; Edge classification; Frequency
   domain; K- nearest neighbour
ID COMPRESSION; ALGORITHM; STRATEGY
AB A hybrid algorithm is proposed for edge-based image encoding using a fractal paradigm. This algorithm exercises spatial domain adaptive techniques on a fractal image compression (FIC) method which classifies the image according to edge property. A discrete cosine transform (DCT) coordinate system is established to map all the blocks onto the x-axis and y-axis. Range and domain exclusion techniques are used to reduce the search space by restricting the number of blocks in the coordinate system. A lesser number of candidate range and domain block amounts to the accelerated encoding process. The proposed algorithm reduces the number of mean square error (MSE) calculation required to code the image. K- nearest neighbour search method is applied to the search space to find similar blocks. The performance of the proposed algorithm is studied on basis of encoding time, compression ratio and peak signal to noise ratio (PSNR). The proposed algorithm shows significant improvement in the quality of the image in terms of (PSNR) and minor progress in compression ratio and encoding time in comparison to the existing edge-based FIC.
C1 [Gupta, Richa] Amity Univ, Comp Sci & Engn Dept, Noida, Uttar Pradesh, India.
   [Mehrotra, Deepti] Amity Univ, Informat Technol Dept, Noida, Uttar Pradesh, India.
   [Tyagi, Rajesh Kumar] Amity Univ, Comp Sci & Engn Dept, Gurgaon, Haryana, India.
C3 Amity University Noida; Amity University Noida
RP Gupta, R (corresponding author), Amity Univ, Comp Sci & Engn Dept, Noida, Uttar Pradesh, India.
EM richa4483@gmail.com
RI mehrotra, deepti/E-5333-2013; TYAGI, RAJESH/AHC-7988-2022; gupta,
   richa/ABA-4598-2021
OI mehrotra, deepti/0000-0001-5752-9800; gupta, richa/0000-0003-1519-4824;
   TYAGI, RAJESH KUMAR/0000-0003-3608-1351
CR Abedellatif H, 2019, MENOUFIA J ELECT ENG, DOI [10.21608/mjeer.2019.76677, DOI 10.21608/MJEER.2019.76677]
   Barnsley MF., 1993, Fractals Everywhere
   Barnsley MF, 1993, FRACTAL IMAGE COMPRE, V5
   Cao J, 2019, IET IMAGE PROCESS, V13, P1872, DOI 10.1049/iet-ipr.2019.0085
   Cardinal J, 2001, IEEE T IMAGE PROCESS, V10, P159, DOI 10.1109/83.892452
   Distasi R, 2006, IEEE T IMAGE PROCESS, V15, P89, DOI 10.1109/TIP.2005.860334
   Fu C, 2009, 2009 INTERNATIONAL WORKSHOP ON CHAOS-FRACTALS THEORIES AND APPLICATIONS (IWCFTA 2009), P439, DOI 10.1109/IWCFTA.2009.99
   Furao, 2014, ELECTRON LETT, V9, P529, DOI [10.1049/el:19950582, DOI 10.1049/EL:19950582]
   Garg P, 2016, ADAPTIVE FRACTAL IMA, P31
   Gupta R, 2016, IMAGING SCI J, V64, P374, DOI 10.1080/13682199.2016.1219100
   Hasan Taha Mohammed, 2011, Journal of Multimedia, V6, P477, DOI 10.4304/jmm.6.6.477-485
   Ilango SS, 2019, CLUSTER COMPUT, V22, P13473, DOI 10.1007/s10586-018-1982-9
   Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028
   Jaferzadeh K, 2017, PATTERN ANAL APPL, V20, P1119, DOI 10.1007/s10044-016-0551-1
   Kumar RS, 2020, BIOMED SIGNAL PROCES, V58, DOI 10.1016/j.bspc.2020.101862
   Li MW, 2019, NONLINEAR DYNAM, V97, P2579, DOI 10.1007/s11071-019-05149-5
   Li Wang, 2020, Advances in 3D Image and Graphics Representation, Analysis, Computing and Information Technology. Methods and Algorithms. Proceedings of IC3DIT 2019. Smart Innovation, Systems and Technologies (SIST 179), P333, DOI 10.1007/978-981-15-3863-6_37
   Li WJ, 2019, J ALGORITHMS COMPUT, V13, DOI 10.1177/1748302619874196
   Lin YL, 2012, J INF SCI ENG, V28, P17
   Lin YL, 2011, COMPUT MATH APPL, V62, P310, DOI 10.1016/j.camwa.2011.05.011
   Menassel Rafik, 2020, International Journal of Computers and Applications, V42, P697, DOI 10.1080/1206212X.2019.1638631
   Mendivil F, 2021, COMMUN NONLINEAR SCI, V94, DOI 10.1016/j.cnsns.2020.105546
   Muruganandham A, 2010, PROCEDIA COMPUT SCI, V2, P338, DOI 10.1016/j.procs.2010.11.044
   Roy SK, 2018, CHAOS SOLITON FRACT, V106, P16, DOI 10.1016/j.chaos.2017.11.013
   Saad AMHY, 2020, IEEE ACCESS, V8, P52687, DOI 10.1109/ACCESS.2020.2980747
   Saupe D., 1995, Proceedings. DCC '95 Data Compression Conference (Cat. No.95TH8037), P222, DOI 10.1109/DCC.1995.515512
   Sun YY, 2015, IET IMAGE PROCESS, V9, P173, DOI 10.1049/iet-ipr.2014.0224
   Sun YY, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0101697
   Tackie Ammah Paul Nii, 2019, Informatics in Medicine Unlocked, V15, P188, DOI 10.1016/j.imu.2019.100183
   Tong CS, 2002, IEEE T IMAGE PROCESS, V11, P605, DOI 10.1109/TIP.2002.1014992
   Tong CS, 2001, IEEE T IMAGE PROCESS, V10, P1269, DOI 10.1109/83.941851
   Vrscay ER, 2014, APPL MATH COMPUT, V231, P435, DOI 10.1016/j.amc.2014.01.007
   Wang JJ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184408
   Wang Q, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/2159703
   Wang XY, 2008, COMPUT GRAPH-UK, V32, P445, DOI 10.1016/j.cag.2008.02.004
   Wu P-Y, 1993, P INT C INF TECHN CO, V12, P54
   Zhang XP, 2015, MULTIMED TOOLS APPL, V74, P5767, DOI 10.1007/s11042-014-1882-9
   Zhang ZC, 2020, NEUROCOMPUTING, V410, P185, DOI 10.1016/j.neucom.2020.05.075
   Zhao DY, 2016, COMPUT ELECTR ENG, V54, P494, DOI 10.1016/j.compeleceng.2016.03.012
   Zhou J, 2020, IEEE COMPUT SOC CONF, P624, DOI 10.1109/CVPRW50498.2020.00089
   Zhou Y., 2007, TSINGHUA SCI TECHNOL, V12, P602, DOI [10.1016/S1007-0214(07)70139-6, DOI 10.1016/S1007-0214(07)70139-6]
   Zhu SP, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/950357
NR 42
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21135
EP 21154
DI 10.1007/s11042-022-12631-7
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000770061500012
DA 2024-07-18
ER

PT J
AU Benseddik, ML
   Zebbiche, K
   Azzaz, MS
   Sadoudi, S
AF Benseddik, Mohamed Lamine
   Zebbiche, Khalil
   Azzaz, Mohamed Salah
   Sadoudi, Said
TI Interpolation-based reversible data hiding in the transform domain for
   fingerprint images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interpolation; Reversible; Data hiding; Wavelet transform; DM-QIM;
   Embedding; Fingerprint; Perceptual masking
ID WATERMARKING; MASKING
AB One major motivation for introducing Reversible Data Hiding (RDH) techniques in biometric systems is the need to provide a higher security level to biometric images without compromising their recognition accuracy. In this paper, a novel RDH scheme that merges the advantages of both image interpolation approaches and the transform-based data hiding schemes is proposed for fingerprint images. Since the secret data is hidden into the transform coefficients, the proposed scheme relies on setting back the reference pixels to their original values to maintain cover image reversibility. To compensate for the distortions induced by the aforementioned operation, we have adapted the robust DM-QIM embedding method, designed an enhanced perceptual masking model for fingerprint images and developed a novel iterative correction algorithm. As a result, the proposed scheme allows to achieve error-free embedding with no extra information needed for image or secret data recovery. Experimental results show that the proposed scheme can effectively ensure full system reversibility and provides higher performance in terms of embedding capacity and visual quality when compared with recent state-of-the-art techniques.
C1 [Benseddik, Mohamed Lamine; Zebbiche, Khalil; Azzaz, Mohamed Salah] Ecole Mil Polytech, Lab Syst Elect & Numer, BP 17, Algiers 16111, Algeria.
   [Sadoudi, Said] Ecole Mil Polytech, Lab Telecommun, BP 17, Algiers 16111, Algeria.
C3 Ecole Military Polytechnic; Ecole Military Polytechnic
RP Benseddik, ML (corresponding author), Ecole Mil Polytech, Lab Syst Elect & Numer, BP 17, Algiers 16111, Algeria.
EM benseddik.mohamedlamine@gmail.com
OI BENSEDDIK, Mohamed Lamine/0000-0002-8815-106X; zebbiche,
   khalil/0000-0002-6926-8203
CR Agrawal S, 2016, 2016 IEEE STUDENTS' CONFERENCE ON ELECTRICAL, ELECTRONICS AND COMPUTER SCIENCE (SCEECS)
   An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Beegan A. P., 2001, THESIS VIRGINIA POLY
   Benseddik ML., 2020, ADV COMPUTING SYST A, V199, P175, DOI [10.1007/978-3-030-69418-0_16, DOI 10.1007/978-3-030-69418-0_16]
   Caciula I, 2019, SIGNAL PROCESS-IMAGE, V71, P120, DOI 10.1016/j.image.2018.11.005
   Cayre F, 2008, IEEE T INF FOREN SEC, V3, P1, DOI 10.1109/TIFS.2007.916006
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Chang YT, 2013, J SUPERCOMPUT, V66, P1093, DOI 10.1007/s11227-013-1016-6
   Chen YQ, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102584
   Choudhary V, 2019, 4 INT C INF SYST COM, DOI 10.1109/ISCON47742.2019.9036232
   Evsutin O, 2021, SIGNAL PROCESS, V179, DOI 10.1016/j.sigpro.2020.107811
   Golabi S, 2019, MULTIMED TOOLS APPL, V78, P31847, DOI 10.1007/s11042-019-07992-5
   Hassan FS, 2020, MULTIMED TOOLS APPL, V79, P30087, DOI 10.1007/s11042-020-09513-1
   HASSAN FS, 2020, J KING SAUD U COMP I
   Joshi VB, 2016, MULTIMEDIA SYST, V22, P367, DOI 10.1007/s00530-015-0465-6
   Joshi VB, 2016, DIGITAL FORENSICS WA, V9569, DOI 10.1007/978-3-319-31960-5_27
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Kapadia Amishi Mahesh, 2020, International Journal of Information and Computer Security, V12, P70
   Lebcir Mohamed, 2020, IOP Conference Series: Materials Science and Engineering, V769, DOI 10.1088/1757-899X/769/1/012070
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Lee H, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P1590, DOI 10.1109/ICARCV.2008.4795762
   LI F, 2018, MULTIMED TOOLS APPL, V516
   Li Q, 2007, IEEE T INF FOREN SEC, V2, P127, DOI 10.1109/TIFS.2007.897266
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Lin CC, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11060765
   Lin CC, 2015, MULTIMED TOOLS APPL, V74, P3823, DOI 10.1007/s11042-013-1801-5
   Lin YK, 2012, J SYST SOFTWARE, V85, P2395, DOI 10.1016/j.jss.2012.05.032
   Malik A, 2020, MULTIMED TOOLS APPL, V79, P18005, DOI 10.1007/s11042-020-08691-2
   Malik A, 2017, MULTIMED TOOLS APPL, V76, P24107, DOI 10.1007/s11042-016-4186-4
   Maltoni D., 2009, HDB FINGERPRINT RECO, DOI 10.1007/978-1-84882-254-2
   Mandal PC, 2021, MULTIMED TOOLS APPL, V80, P3623, DOI 10.1007/s11042-020-09341-3
   Mohammad AA, 2019, MULTIMED TOOLS APPL, V78, P7181, DOI 10.1007/s11042-018-6465-8
   Nikolaidis A, 2015, IET IMAGE PROCESS, V9, P560, DOI 10.1049/iet-ipr.2014.0689
   Pakdaman Z, 2021, MULTIMED TOOLS APPL, V80, P8931, DOI 10.1007/s11042-020-10058-6
   Pan ZB, 2020, MULTIMED TOOLS APPL, V79, P12569, DOI 10.1007/s11042-019-08335-0
   SHAIK A, 2018, J KING SAUD U COMP I
   Shaik A, 2019, MULTIMED TOOLS APPL, V78, P9717, DOI 10.1007/s11042-018-6544-x
   Taha TB, 2018, IEEE ACCESS, V6, P66254, DOI 10.1109/ACCESS.2018.2878456
   Thampi SM, 2011, INT J IMAGE PROCESS, V5
   Thomas R, 2020, MATER TODAY, DOI 10.1016/j.matpr.2020.09.533
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang WQ, 2017, IET IMAGE PROCESS, V11, P1002, DOI 10.1049/iet-ipr.2017.0151
   Zebbiche K, 2018, MULTIMED TOOLS APPL, V77, P21281, DOI 10.1007/s11042-017-5451-x
   Zebbiche K, 2014, IET IMAGE PROCESS, V8, P23, DOI 10.1049/iet-ipr.2013.0055
   Zhang XQ, 2017, MULTIMED TOOLS APPL, V76, P9195, DOI 10.1007/s11042-016-3521-0
NR 47
TC 6
Z9 6
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 20329
EP 20356
DI 10.1007/s11042-022-12288-2
EA MAR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000767748600021
DA 2024-07-18
ER

PT J
AU Varish, N
AF Varish, Naushad
TI A modified similarity measurement for image retrieval scheme using
   fusion of color, texture and shape moments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Discrete cosine transformation; GLCM;
   Feature extraction; Image pyramid; Statistical moments
ID DESCRIPTOR; FEATURES; FRAMEWORK; CLASSIFICATION
AB In this paper, a simple feature fusion scheme is proposed for content-based image retrieval (CBIR) using color, texture and shape feature moments. The low dimensional feature descriptor is constructed by fusing color, texture and shape moments of an image effectively. The color moments are extracted from the image using probability histogram model while the Gray Level Co-occurrence Matrix (GLCM) based texture moments are computed in a very new fashion by selecting salient components in Discrete Cosine Transform (DCT) domain after determining the inter-relationship between the DCT blocks. Alone, color or texture information is not adequate to produce the desire results in image retrieval system. So, suggested work has also considered the multi-resolution based shape information, since the single resolution level of image does not provide an adequate image information and it may be possible that the fine details may be visualized on other resolution levels of image. Therefore, shape feature descriptor is determined by calculating the invariant moments of multi-resolution based sub-images at the various levels. Finally, fused single feature descriptor is computed by proficient fusion of color, texture and shape feature moments. The modified distance is also suggested for image retrieval task. The proposed feature fusion scheme is implemented on Corel-1K, OT-8 and GHIM-10K image databases to evaluate the retrieval performance and experimental results show the effectiveness of our scheme over the other existing CBIR schemes.
C1 [Varish, Naushad] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Guntur 522502, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Varish, N (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Guntur 522502, Andhra Pradesh, India.
EM naushad.cs88@gmail.com
RI Varish, Naushad/R-4371-2019
OI Varish, Naushad/0000-0002-0088-2213
CR Abbass MY, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0276-8
   AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Ashraf R, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0880-7
   Bai, 2012, INT C COMP VIS THEOR
   Bella MIT, 2019, COMPUT ELECTR ENG, V75, P46, DOI 10.1016/j.compeleceng.2019.01.022
   Chaki J, 2015, PATTERN RECOGN LETT, V58, P61, DOI 10.1016/j.patrec.2015.02.010
   El-Ghazal A, 2009, SIGNAL PROCESS-IMAGE, V24, P572, DOI 10.1016/j.image.2009.04.001
   Fadaei S, 2017, IET IMAGE PROCESS, V11, P89, DOI 10.1049/iet-ipr.2016.0542
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huang M, 2015, OPTIK, V126, P2144, DOI 10.1016/j.ijleo.2015.05.095
   Jiang JM, 2002, IEEE T SIGNAL PROCES, V50, P1160, DOI 10.1109/78.995072
   Khokher A, 2017, MULTIMED TOOLS APPL, V76, P21787, DOI 10.1007/s11042-016-4096-5
   Kothyari P., 2016, INT J INNOV RES COMP, V4
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Li S, 2009, IEEE T SYST MAN CY A, V39, P227, DOI 10.1109/TSMCA.2008.2007988
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Liu YN, 2019, MULTIMED TOOLS APPL, V78, P2525, DOI 10.1007/s11042-018-6386-6
   Malik F, 2013, J KING SAUD UNIV-COM, V25, P207, DOI 10.1016/j.jksuci.2012.11.004
   Mora M, 2005, COMPUT CARDIOL, V32, P235
   Naghashi V, 2018, OPTIK, V157, P877, DOI 10.1016/j.ijleo.2017.11.160
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pavithra LK, 2018, COMPUT ELECTR ENG, V70, P580, DOI 10.1016/j.compeleceng.2017.08.030
   Phadikar BS, 2018, PATTERN ANAL APPL, V21, P469, DOI 10.1007/s10044-016-0589-0
   Rafi Mudassir, 2019, Progress in Advanced Computing and Intelligent Engineering. Proceedings of ICACIE 2017. Advances in Intelligent Systems and Computing (AISC 713), P37, DOI 10.1007/978-981-13-1708-8_4
   Rafi M, 2019, MULTIMED TOOLS APPL, V78, P19735, DOI 10.1007/s11042-019-7153-z
   Raghuwanshi G, 2019, MULTIMED TOOLS APPL, V78, P1889, DOI 10.1007/s11042-018-6333-6
   Rahimi M, 2015, SIGNAL IMAGE VIDEO P, V9, P691, DOI 10.1007/s11760-013-0506-6
   Rahman Alamin A., 2014, J THEORETICAL APPL I, V70, P260
   Rahman MM, 2013, INT J MULTIMED INF R, V2, P159, DOI 10.1007/s13735-013-0038-4
   Rashno A, 2019, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.1902.02059
   Ravisankar P, 2018, MULTIMED TOOLS APPL, V77, P5547, DOI 10.1007/s11042-017-4466-7
   Seetharaman K, 2014, MULTIMED TOOLS APPL, V73, P1943, DOI 10.1007/s11042-013-1637-z
   Singh C, 2016, J VIS COMMUN IMAGE R, V41, P225, DOI 10.1016/j.jvcir.2016.10.002
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Sokic E, 2016, SIGNAL PROCESS-IMAGE, V40, P82, DOI 10.1016/j.image.2015.11.002
   Song W, 2018, EXPERT SYST APPL, V96, P347, DOI 10.1016/j.eswa.2017.12.006
   Tenali, 2018, J ADV RE DYN CONTROL, V10, P773
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Varish N., 2016, INT J IAMGE MINING, V2, P68
   Varish N, 2020, IEEE ACCESS, V8, P117639, DOI 10.1109/ACCESS.2020.3003911
   Varish N, 2018, APPL INTELL, V48, P2930, DOI 10.1007/s10489-017-1125-7
   Vassou S. A., 2018, MULTIMED TOOLS APPL, P1
   Vimina ER, 2019, IET IMAGE PROCESS, V13, P1979, DOI 10.1049/iet-ipr.2018.5381
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P7633, DOI 10.1007/s11042-016-3416-0
   Wang XY, 2011, COMPUT STAND INTER, V33, P59, DOI 10.1016/j.csi.2010.03.004
   Wang XY, 2012, COMPUT STAND INTER, V34, P31, DOI 10.1016/j.csi.2011.05.001
   Yadav AR, 2015, OPTIK, V126, P5570, DOI 10.1016/j.ijleo.2015.09.030
   Yang HY, 2015, COMPUT ELECTR ENG, V46, P273, DOI 10.1016/j.compeleceng.2015.05.008
   Yang P, 2016, NEUROCOMPUTING, V197, P212, DOI 10.1016/j.neucom.2016.02.061
   Zhang J, 2008, HPCC 2008: 10TH IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P782, DOI 10.1109/HPCC.2008.55
   Zhang YD, 2014, J FOOD ENG, V143, P167, DOI 10.1016/j.jfoodeng.2014.07.001
NR 55
TC 10
Z9 10
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20373
EP 20405
DI 10.1007/s11042-022-12289-1
EA MAR 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767748600022
DA 2024-07-18
ER

PT J
AU Hiremath, SC
   Mallapur, JD
AF Hiremath, Shivanand C.
   Mallapur, Jayashree D.
TI Fractional-social ski driver optimization-driven routing protocol for
   routing electric vehicle under server hosted VANET
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VANET; Cloud server; Electric vehicle; Battery charging; Routing
ID STATIONS
AB The modernization in Electric Vehicles (EVs) has acquired immense interest amongst several researchers as the EV is termed a supreme mode of transportation. In addition, EV is imperative to preserve classical fuel, but EV poses short driving that are restricted by insufficient batteries that obstruct reliability, and there exist lesser charging applications, which are irregularly dispersed. A new model is devised for optimal routing to charge EV using server-hosted VANET. The goal is to discover optimal routes to charge EV with Vehicular Adhoc Network (VANET). The server-hosted VANET contains roadside and vehicle units such that roadside and vehicle units are operated with a cloud server. Here, optimal routes for attaining charging stations are discovered using the proposed Fractional-Social Ski Driver (Fractional-SSD), which is obtained by integrating Fractional calculus (FC) and Social Ski Driver optimization (SSD). In addition, the fitness function is newly developed using battery power, traffic density and distance. Thus, routing decisions are made to route the EV for charging the battery by adapting multi-objective factors. Hence, the proposed Fractional-SSD is employed to choose the optimal route for charging EV. As a result, the proposed Fractional-SSD acquired improved performance with the maximal battery power of 13,884.19 J, smallest traffic density of 6.5, delay of 10.973 min, and fitness of 24.800, respectively.
C1 [Hiremath, Shivanand C.] RN Shetty Polytech Coll, Elect & Commun, Belagavi, India.
   [Mallapur, Jayashree D.] Visvesvaraya Technol Univ, Elect & Commun, Basaveshwar Engn Coll, Belagavi, India.
C3 Visvesvaraya Technological University
RP Hiremath, SC (corresponding author), RN Shetty Polytech Coll, Elect & Commun, Belagavi, India.
EM Shivch612@gmail.com; jdmec@becbgk.edu
RI Mallapur, Dr. Jayashree D./AAS-1203-2020; Hiremath, Shivanand
   C/HCP-9020-2022
OI Mallapur, Dr. Jayashree D./0000-0001-8043-7007; Hiremath, Shivanand
   C/0000-0001-8806-4516
CR Adler JD, 2014, THESIS ARIZONA STATE
   Akar F, 2017, IEEE T TRANSP ELECTR, V3, P191, DOI 10.1109/TTE.2016.2638640
   Ammous M, 2019, IEEE T INTELL TRANSP, V20, P2510, DOI 10.1109/TITS.2018.2867519
   Barco J, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/8509783
   Basso R, 2019, TRANSPORT RES D-TR E, V69, P141, DOI 10.1016/j.trd.2019.01.006
   Bhaladhare PR, 2014, ADVANC COMP ENG
   Cao Y., 2018, HDB SMART CITIES, P311
   Cao Y, 2021, IEEE T SYST MAN CY-S, V51, P3026, DOI 10.1109/TSMC.2019.2917149
   Cao Y, 2017, INT WIREL COMMUN, P1471, DOI 10.1109/IWCMC.2017.7986501
   Cao Y, 2017, IEEE T VEH TECHNOL, V66, P2886, DOI 10.1109/TVT.2016.2594241
   Eugster PT, 2003, ACM COMPUT SURV, V35, P114, DOI 10.1145/857076.857078
   Felipe A, 2014, TRANSPORT RES E-LOG, V71, P111, DOI 10.1016/j.tre.2014.09.003
   Garg A, 2016, STATE OF THE ART DES
   Jie WC, 2019, EUR J OPER RES, V272, P879, DOI 10.1016/j.ejor.2018.07.002
   Kancharla SR, 2018, TRANSP DEV ECON, V4, DOI 10.1007/s40890-018-0063-3
   Kaur M, 2020, P REL MAINT S, DOI 10.1109/rams48030.2020.9153643
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kousar Nikhath A., 2021, Intelligent System Design. Proceedings of Intelligent System Design: INDIA 2019. Advances in Intelligent Systems and Computing (AISC 1171), P645, DOI 10.1007/978-981-15-5400-1_62
   Kurtulus C, 2015, IEEE INT C INTELL TR, P1723, DOI 10.1109/ITSC.2015.280
   Liu CY, 2016, ASIA-PAC POWER ENERG, P1158, DOI 10.1109/APPEEC.2016.7779674
   Luo YG, 2020, ENERGY, V194, DOI 10.1016/j.energy.2019.116807
   Mahesh K., 2020, Multimedia Research, V3, P36
   Manvith Vaddeboyina Sri, 2021, Proceedings of the Third International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV 2020), P782, DOI 10.1109/ICICV50876.2021.9388502
   Olivieri M, 2004, IEEE T VLSI SYST, V12, P1374, DOI 10.1109/TVLSI.2004.837998
   Prasanalakshmi B, 2011, COMM COM INF SC, V251, P319
   Pratama M., 2019, J MECHATRONICS ELECT, V10, P7, DOI [10.14203/j.mev.2019.v10.7-16, DOI 10.14203/J.MEV.2019.V10.7-16]
   Ravuri V, 2020, BIG DATA-US, V8, P203, DOI 10.1089/big.2019.0125
   Savyanavar AS, 2019, INT J GRID HIGH PERF, V11, P50, DOI 10.4018/IJGHPC.2019040103
   Smiai O., 2017, INT C APPL EL PERV I, P127
   Tharwat A, 2020, NEURAL COMPUT APPL, V32, P6925, DOI 10.1007/s00521-019-04159-z
   Wang M, 2014, IEEE J SEL AREA COMM, V32, P1344, DOI 10.1109/JSAC.2014.2332078
   Wang T, 2006, LECT NOTES COMPUT SC, V3842, P889
   Zhang S, 2019, J CLEAN PROD, V221, P567, DOI 10.1016/j.jclepro.2019.02.167
   Zhang S, 2018, INT J PROD ECON, V203, P404, DOI 10.1016/j.ijpe.2018.07.016
NR 34
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17437
EP 17456
DI 10.1007/s11042-022-12543-6
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000765701900022
DA 2024-07-18
ER

PT J
AU Wu, R
   Nie, JH
   Gao, H
   Liu, Y
   Lu, HT
AF Wu, Rui
   Nie, Jianhui
   Gao, Hao
   Liu, Ye
   Lu, Haotian
TI Single Match: a point cloud coarse registration method with single match
   point and deep-learning describer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Point cloud; Registration; Deep-learning; Feature points
ID OBJECT RECOGNITION; FEATURE-EXTRACTION; HISTOGRAMS; DESCRIPTOR
AB Point cloud registration is a necessary step of object digitization. In this paper, we propose a coarse registration method with a single match point. To achieve the purpose, feature points with stable orientation are recognized firstly, then descriptors of these points are generated with our Convolution Neural Network (CNN) named PFNet. Finally, candidate solutions are obtained by descriptors matching and the accurate registration is given by a RANSAC-based optimization strategy. As the feature points used are highly directional, a stable Local Coordinate System (LCS) can be constructed by combining the orientation and the normal vector, and thus, the registration can be realized by LCS mapping with single match point. Experiment results show that our algorithm achieves good registration effects in challenging scenes, and is robust to noise, outliers, non-uniform sampling.
C1 [Wu, Rui; Nie, Jianhui; Gao, Hao; Liu, Ye; Lu, Haotian] Nanjing Univ Posts & Telecommun, Sch Automat & Artificial Intelligence, Nanjing, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Nie, JH (corresponding author), Nanjing Univ Posts & Telecommun, Sch Automat & Artificial Intelligence, Nanjing, Peoples R China.
EM njh19@njupt.edu.cn
CR Ai S, 2017, INTELLIGENT ROBOTICS, V10464
   Aiger D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360684
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], 2001, P IMR 2001 NEWP BEAC
   Aoki Y, 2019, PROC CVPR IEEE, P7156, DOI 10.1109/CVPR.2019.00733
   Bai XY, 2020, PROC CVPR IEEE, P6358, DOI 10.1109/CVPR42600.2020.00639
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Feng X, 2019, COMMUNICATIONS COMPU, V1138
   Gao QH, 2019, MULTIMED TOOLS APPL, V78, P15079, DOI 10.1007/s11042-018-6905-5
   Geng N, 2016, MULTIMED TOOLS APPL, V75, P16763, DOI 10.1007/s11042-015-2941-6
   Gojcic Z, 2019, PROC CVPR IEEE, P5540, DOI 10.1109/CVPR.2019.00569
   Guerrero P, 2018, COMPUT GRAPH FORUM, V37, P75, DOI 10.1111/cgf.13343
   Hussnain Z, 2016, INT ARCH PHOTOGRAMM, V41, P609, DOI 10.5194/isprsarchives-XLI-B1-609-2016
   Jiao ZH, 2019, LECT NOTES COMPUT SC, V11345, P24, DOI 10.1007/978-3-662-59351-6_3
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Lai K, 2014, IEEE INT CONF ROBOT, P3050, DOI 10.1109/ICRA.2014.6907298
   Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95
   Li CL, 2018, MULTIMED TOOLS APPL, V77, P14605, DOI 10.1007/s11042-017-5050-x
   [李仁忠 Li Renzhong], 2017, [激光与光电子学进展, Laser & Optoelectronics Progress], V54, P111503
   Lin D, 2019, ISPRS J PHOTOGRAMM, V151, P162, DOI 10.1016/j.isprsjprs.2019.03.010
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lu J, 2019, CHIN CONTR CONF, P4439, DOI 10.23919/ChiCC.2019.8866059
   Mellado N, 2014, COMPUT GRAPH FORUM, V33, P205, DOI 10.1111/cgf.12446
   Mohamad M, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P598, DOI 10.1109/3DV.2015.74
   Nie JH, 2016, GRAPH MODELS, V84, P38, DOI 10.1016/j.gmod.2016.04.001
   Nie Jianhui, 2015, Journal of Computer Aided Design & Computer Graphics, V27, P2332
   Niessner M., 2013, ACM T GRAPHIC, V32, DOI DOI 10.1145/2508363.2508374
   Noh H, 2017, IEEE I CONF COMP VIS, P3476, DOI 10.1109/ICCV.2017.374
   Pauly M, 2003, COMPUT GRAPH FORUM, V22, P281, DOI 10.1111/1467-8659.00675
   Pavel FA, 2009, IEEE INT WORKSH MULT, P368
   Prakhya SM, 2017, AUTON ROBOT, V41, P1501, DOI 10.1007/s10514-016-9612-y
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Rusu RB, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3384, DOI 10.1109/IROS.2008.4650967
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Sharp GC, 2002, IEEE T PATTERN ANAL, V24, P90, DOI 10.1109/34.982886
   Shi WJ, 2019, IEEE ACCESS, V7, P77436, DOI 10.1109/ACCESS.2019.2921828
   Sipiran I, 2011, VISUAL COMPUT, V27, P963, DOI 10.1007/s00371-011-0610-y
   Theiler PW, 2014, ISPRS J PHOTOGRAMM, V96, P149, DOI 10.1016/j.isprsjprs.2014.06.015
   Tombari F, 2011, IEEE IMAGE PROC, P809, DOI 10.1109/ICIP.2011.6116679
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26
   Wan T, 2019, MULTIMED TOOLS APPL, V78, P33223, DOI 10.1007/s11042-019-7159-6
   Wang CY, 2018, IEEE INT CONF ROBOT, P627
   Wang XH, 2020, MULTIMED TOOLS APPL, V79, P11861, DOI 10.1007/s11042-019-08512-1
   Xu ZH, 2019, IEEE GEOSCI REMOTE S, V16, P286, DOI 10.1109/LGRS.2018.2872353
   Yang JL, 2013, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2013.184
   Yew ZJ, 2018, LECT NOTES COMPUT SC, V11219, P630, DOI 10.1007/978-3-030-01267-0_37
   Yu Zhong, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P689, DOI 10.1109/ICCVW.2009.5457637
   Zeng A, 2017, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2017.29
   Zhou QY, 2016, LECT NOTES COMPUT SC, V9906, P766, DOI 10.1007/978-3-319-46475-6_47
NR 51
TC 1
Z9 1
U1 2
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16967
EP 16986
DI 10.1007/s11042-022-12704-7
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000764599600004
DA 2024-07-18
ER

PT J
AU Fang, YX
   Liu, J
   Li, JB
   Cheng, JR
   Hu, JB
   Yi, D
   Xiao, XL
   Bhatti, UA
AF Fang, Yangxiu
   Liu, Jing
   Li, Jingbing
   Cheng, Jieren
   Hu, Jiabin
   Yi, Dan
   Xiao, Xiliang
   Bhatti, Uzair Aslam
TI Robust zero-watermarking algorithm for medical images based on SIFT and
   Bandelet-DCT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Zero-watermarking; Medical images; Bandelet-DCT; Scale invariant feature
   transform; Robustness
AB The gradual improvement of traditional medicare in the cloud has greatly promoted the development of medical enterprise. Meanwhile, problems such as the leakage of patients' personal information, the theft, and tamper of medical images transmitted in the cloud have become increasingly prominent. To solve the above problems, a novel zero-watermarking algorithm for medical images based on bandelet and discrete cosine transform (Bandelet-DCT) is proposed. First, Scale Invariant Feature Transform (SIFT) is performed on the original medical image for extracting the features as the preprocessing step. Second, the chaotic system tent map is used to encrypt the watermark which contained patients' information. Then, Bandelet-DCT is applied to extract the visual feature vectors of medical images. Finally, the watermark embedding and extraction are realized by combining zero-watermarking technology and cryptography related technology. The experimental results show that the proposed algorithm has strong robustness and can effectively solve the problem of information leakage. It has a strong anti-attack ability, good robustness, and certain application prospects.
C1 [Fang, Yangxiu; Li, Jingbing; Hu, Jiabin; Yi, Dan; Xiao, Xiliang] Hainan Univ, Sch Informat & Commun Engn, Haikou, Hainan, Peoples R China.
   [Liu, Jing] Res Ctr Healthcare Data Sci, Zhejiang Lab, Hangzhou, Zhejiang, Peoples R China.
   [Li, Jingbing] Hainan Univ, State Key Lab Marine Resource Utilizat South Chin, Haikou, Hainan, Peoples R China.
   [Cheng, Jieren] Hainan Univ, Sch Comp Sci & Cyberspace Secur, Haikou, Hainan, Peoples R China.
   [Bhatti, Uzair Aslam] Nanjing Normal Univ, Sch Geog, Remote Sensing & GIS Lab, Nanjing, Jiangsu, Peoples R China.
C3 Hainan University; Zhejiang Laboratory; Hainan University; Hainan
   University; Nanjing Normal University
RP Li, JB (corresponding author), Hainan Univ, Sch Informat & Commun Engn, Haikou, Hainan, Peoples R China.; Li, JB (corresponding author), Hainan Univ, State Key Lab Marine Resource Utilizat South Chin, Haikou, Hainan, Peoples R China.
EM FangYangXiu@hainanu.edu.cn; liujinglj@zhejianglab.edu.cn;
   jingbingli2008@hotmail.com; cji22@163.com;
   18085208210009@hainanu.edu.cn; Yidan@hainanu.edu.cn;
   xiaoxiliang1997@163.com; uzairaslambhatti@hotmail.com
RI Liu, Jing/HTN-0709-2023
OI Liu, Jing/0000-0002-9031-6433
FU Natural Science Foundation of China [62063004, 61762033]; Hainan
   Provincial Natural Science Foundation of China [2019RC018, 619QN246];
   Postdoctoral Science Foundation [2020TQ0293]; Science and Technology
   Research Project of Chongqing Education Commission [KJQN201800442];
   General Project of Chongqing Natural Science Foundation
   [cstc2020jcyj-msxmX0422]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant 62063004 and 61762033, in part by the Hainan
   Provincial Natural Science Foundation of China under Grant 2019RC018 and
   619QN246, by the Postdoctoral Science Foundation under Grant 2020TQ0293,
   by the Science and Technology Research Project of Chongqing Education
   Commission Under Grant KJQN201800442, and by the General Project of
   Chongqing Natural Science Foundation Under Grant cstc2020jcyj-msxmX0422.
CR Ahmad RM, 2020, AIPR 2020: 2020 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION, P180, DOI 10.1145/3430199.3430243
   Ambadekar Sarita P., 2019, Recent Trends in Signal and Image Processing. ISSIP 2017. Advances in Intelligent Systems and Computing (AISC 727), P187, DOI 10.1007/978-981-10-8863-6_19
   Aparna P, 2020, J INTELL SYST, V29, P1558, DOI 10.1515/jisys-2018-0370
   Balasamy K, 2023, IETE J RES, V69, P83, DOI 10.1080/03772063.2021.1893231
   Balasamy K, 2021, MULTIMED TOOLS APPL, V80, P7167, DOI 10.1007/s11042-020-09981-5
   Dong S., 2019, COMPUT APPL SOFTW, V36, P302
   Ernawan F, 2018, IEEE ACCESS, V6, P20464, DOI 10.1109/ACCESS.2018.2819424
   Hu YC, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013012
   Khare P, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3918
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Liu JL, 2018, LECT NOTES COMPUT SC, V11066, P334, DOI 10.1007/978-3-030-00015-8_29
   Liu J, 2019, CMC-COMPUT MATER CON, V61, P889, DOI 10.32604/cmc.2019.06034
   Liu Xu-chong, 2010, Journal on Communications, V31, P123
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Luo HJ, 2011, RADIOENGINEERING, V20, P525
   Peyré G, 2005, IEEE IMAGE PROC, P649
   Su QT, 2019, IEEE ACCESS, V7, P30398, DOI 10.1109/ACCESS.2019.2895062
   Swaraja K, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101665
   Thakur S., 2018, Cryptographic and Information Security Approaches for Images and Videos, P467
   Vishwakarma Virendra P., 2018, Procedia Computer Science, V132, P1012, DOI 10.1016/j.procs.2018.05.017
   Wen Quan, 2003, Acta Electronica Sinica, V31, P214
   Wu D., 2020, J YANSHAN U, V44, P38
   Wu XQ, 2019, MULTIMED TOOLS APPL, V78, P8463, DOI 10.1007/s11042-018-6877-5
   [杨岳湘 Yang Yuexiang], 2007, [计算机研究与发展, Journal of Computer Research and Development], V44, P1996, DOI 10.1360/crad20071202
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang LN, 2019, MULTIMED TOOLS APPL, V78, P28003, DOI 10.1007/s11042-019-07902-9
   Zou BJ, 2018, MULTIMED TOOLS APPL, V77, P28685, DOI 10.1007/s11042-018-5995-4
NR 28
TC 23
Z9 24
U1 9
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16863
EP 16879
DI 10.1007/s11042-022-12592-x
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763872100002
DA 2024-07-18
ER

PT J
AU Abdelmalek, R
   Mnasri, Z
   Benzarti, F
AF Abdelmalek, Raja
   Mnasri, Zied
   Benzarti, Faouzi
TI Audio signal reconstruction using phase retrieval: Implementation and
   evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Signal reconstruction; Short-time Fourier transform (STFT); Spectrogram
   inversion; Phase retrieval; Objective evaluation; Subjective evaluation
ID CHANNEL SPEECH ENHANCEMENT; MAGNITUDE; SEPARATION
AB Phase retrieval has been theoretically proved to be an efficient method for signal reconstruction given only the magnitude spectrum of short time Fourier transform (STFT). Recently, this topic has regained increasing interest for its usefulness in several applications such as compressive sensing, speech synthesis, speech enhancement, source separation, etc. Therefore this paper presents an efficient algorithm for audio signal reconstruction using phase retrieval from the STFT magnitude spectrum, based on an explicit relationship between STFT magnitude and phase. First, the performance of the proposed algorithm is studied for different types of audio signals, i.e. monophonic (speech) and polyphonic (music), in order to tune its parameters. Then, a detailed comparison with the state-of-the-art phase retrieval algorithms is presented. Thus, two types of evaluation are carried out: (a) An objective evaluation is performed using the standard metrics in signal reconstruction, i.e. time-domain segmental signal-to-noise ratio (segSNR), time-frequency domain signal-to-error ratio (SER), and cepstrum-related distance measures, namely log-likelihood ratio (LLR), Itakura-Saito distorsion (IS) and cepstrum distance. Such an evaluation was performed first for the proposed algorithm alone, and then in comparison to state-of-the art methods; (b) a subjective evaluation is conducted with a series of listening tests commonly used in audio quality rating, namely Mean Opinion Score (MOS), Degradation Mean Opinion Score (DMOS) and preference tests. The results of both evaluation protocols confirm the improvement brought by the proposed approach.
C1 [Abdelmalek, Raja; Benzarti, Faouzi] Univ Tunis El Manar, SITI Lab, ENIT, Tunis, Tunisia.
   [Mnasri, Zied] Univ Tunis El Manar, Elect Engn Dept, ENIT, Tunis, Tunisia.
   [Mnasri, Zied] Univ Genoa, DIBRIS, Genoa, Italy.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT); Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de
   Tunis (ENIT); University of Genoa
RP Mnasri, Z (corresponding author), Univ Tunis El Manar, Elect Engn Dept, ENIT, Tunis, Tunisia.; Mnasri, Z (corresponding author), Univ Genoa, DIBRIS, Genoa, Italy.
EM raja.abdelmalek@enit.utm.tn; zied.mnasri@enit.utm.tn;
   faouzi.benzarti@ensit.rnu.tn
CR Abdelmalek R, 2018, INT MULTICONF SYST, P1084, DOI 10.1109/SSD.2018.8570580
   Abdelmalek R, 2018, INT J SPEECH TECHNOL, V21, P619, DOI 10.1007/s10772-018-9522-9
   Abdelmalek Raja, 2018, INT C SCI ELEC TRONI, P24
   Alsteris LD, 2007, DIGIT SIGNAL PROCESS, V17, P578, DOI 10.1016/j.dsp.2006.06.007
   Alsteris LD, 2007, COMPUT SPEECH LANG, V21, P174, DOI 10.1016/j.csl.2006.03.001
   Auger F, 2012, IEEE SIGNAL PROC LET, V19, P267, DOI 10.1109/LSP.2012.2190279
   Barnwell III TP, 1988, OBJECTIVE MEASURES S
   Beauregard G.T., 2005, Proceedings of the 8th International Conference on Digital Audio Effects, P116
   Beauregard GT, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P427, DOI 10.1109/ICDSP.2015.7251907
   Bendory T, 2018, IEEE T INFORM THEORY, V64, P467, DOI 10.1109/TIT.2017.2745623
   Davies MEP, 2007, IEEE T AUDIO SPEECH, V15, P1009, DOI 10.1109/TASL.2006.885257
   De Leon PL, 2011, INT CONF ACOUST SPEE, P4844
   Degottex, 2014, 15 ANN C INT SPEECH
   DIMOLITSAS S, 1995, IEEE T SPEECH AUDI P, V3, P421, DOI 10.1109/89.466653
   Emiya V, 2011, IEEE T AUDIO SPEECH, V19, P2046, DOI 10.1109/TASL.2011.2109381
   Garofolo J. S., 1993, Timit acoustic phonetic continuous speech corpus
   GRIFFIN DW, 1984, IEEE T ACOUST SPEECH, V32, P236, DOI 10.1109/TASSP.1984.1164317
   Guido RC, 2020, INT J WAVELETS MULTI, V18, DOI 10.1142/S0219691320300017
   Guido RC, 2017, IEEE SIGNAL PROC MAG, V34, P89, DOI 10.1109/MSP.2017.2672759
   Gunawan D, 2010, IEEE SIGNAL PROC LET, V17, P421, DOI 10.1109/LSP.2010.2042530
   Guo YN, 2019, CIRC SYST SIGNAL PR, V38, P3818, DOI 10.1007/s00034-019-01030-3
   Hansen John H. L., 1998, INT C SPOKEN LANGUAG, P2819
   HAYES MH, 1980, IEEE T ACOUST SPEECH, V28, P672, DOI 10.1109/TASSP.1980.1163463
   HOLZAPFEL A, 2008, P ISMIR INT C MUS IN, P653
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054
   IRINO T, 1993, IEEE T SIGNAL PROCES, V41, P3549, DOI 10.1109/78.258095
   ITU-T RP, 1996, 861 ITUTRP
   Iwen M, 2017, APPL COMPUT HARMON A, V42, P135, DOI 10.1016/j.acha.2015.06.007
   Laroche J., 1997, 1997 IEEE ASSP Workshop on Applications of Signal Processing to Audio and Acoustics (Cat. No.97TH8278), DOI 10.1109/ASPAA.1997.625603
   Le Roux J., 2010, P INT C DIG AUD EFF
   Loizou P. C., 2007, Speech Enhancement: Theory and Practice
   Lopes D, 2000, 2000 10 EUR SIGN PRO, P1
   Magron P, 2020, IEEE SIGNAL PROC LET, V27, P306, DOI 10.1109/LSP.2020.2970310
   Mayer F, 2017, J ACOUST SOC AM, V141, P4668, DOI 10.1121/1.4986647
   Mayer F, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1795
   Moravec ML, 2007, PROC SPIE, V6701, DOI 10.1117/12.736360
   Mowlaee P., 2014, 15 ANN C INT SPEECH
   Mowlaee P, 2017, SPEECH COMMUN, V86, P85, DOI 10.1016/j.specom.2016.11.008
   Mowlaee P, 2015, IEEE-ACM T AUDIO SPE, V23, P1521, DOI 10.1109/TASLP.2015.2439038
   Nakamura T, 2014, INT CONF DIGIT AUDIO, P129
   OHLSSON HENRIK, 2012, Advances in Neural Information Processing Systems, P1367
   Pirker G, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P1520
   Pobloth H, 1999, INT CONF ACOUST SPEE, P29, DOI 10.1109/ICASSP.1999.758054
   Portnoff M. R., 1979, ICASSP 79. 1979 IEEE International Conference on Acoustics, Speech and Signal Processing, P186
   PORTNOFF MR, 1976, IEEE T ACOUST SPEECH, V24, P243, DOI 10.1109/TASSP.1976.1162810
   Prusa Z, 2017, 2017 AES INTERNATIONAL CONFERENCE ON SEMANTIC AUDIO
   Prusa Z, 2016, INT CONF DIGIT AUDIO, P17
   Sanchez J, 2015, IEEE T INF FOREN SEC, V10, P810, DOI 10.1109/TIFS.2015.2398812
   Saratxaga I, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P1095
   Shimauchi S, 2017, INT CONF ACOUST SPEE, P676, DOI 10.1109/ICASSP.2017.7952241
   Smaragdis P, 2011, J SIGNAL PROCESS SYS, V65, P361, DOI 10.1007/s11265-010-0512-7
   Takaki S, 2017, INTERSPEECH, P1128, DOI 10.21437/Interspeech.2017-488
   Tech, 2008, 3253 SOUND QUALITY A
   THORPE LA, 1993, IEEE WORKSH SPEECH C, P73
   VANHOVE PL, 1983, IEEE T ACOUST SPEECH, V31, P1286, DOI 10.1109/TASSP.1983.1164178
   Virtanen T, 2007, IEEE T AUDIO SPEECH, V15, P1066, DOI 10.1109/TASL.2006.885253
   Voiers, 1976, METHODS PREDICTING U
   Waldspurger I, 2017, IEEE T INFORM THEORY, V63, P2993, DOI 10.1109/TIT.2017.2672727
   WANG DL, 1982, IEEE T ACOUST SPEECH, V30, P679, DOI 10.1109/TASSP.1982.1163920
   Yang W, 1999, ENHANCED MODIFIED BA
   YEGNANARAYANA B, 1984, IEEE T ACOUST SPEECH, V32, P610, DOI 10.1109/TASSP.1984.1164365
   Zhu XL, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P229, DOI 10.1109/ICME.2006.262424
NR 62
TC 0
Z9 0
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15919
EP 15946
DI 10.1007/s11042-022-12421-1
EA MAR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000763256600019
DA 2024-07-18
ER

PT J
AU Hou, MZ
   Zhang, X
   Chen, Y
   Dong, PL
   Feng, ZL
AF Hou, Mingzheng
   Zhang, Xin
   Chen, Yang
   Dong, Penglin
   Feng, Ziliang
TI Traffic signs detection and recognition systems by light-weight
   multi-stage network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Advanced Driver Assistance System (ADAS); Traffic signs recognition;
   Traffic signs tracking; Deep learning
AB Traffic sign detection and recognition (TSDR) plays an important role in the fields for assistant driving, autonomous vehicle and so on. However, due to the complexity of real driving scene and variety of traffic signs, many challenging problems occurred, such as inaccurate color segmentation and time consumption of recognition algorithm based on deep learning. This paper describes an approach for efficiently detection and recognizing in real world scenarios. First of all, a traffic sign region of interest extraction algorithm based on multi-color space is proposed, the fusion future of HSV and RGB color space can obtain better color segmentation for the SVM classifier. Next a novel multi-scale two-stage lightweight network (MSTSN) is investigated, which adopts a coarse-to-fine strategy to improve recognition accuracy. Specially, the candidate Region of Interests (ROIs) are fed into a binary classification layer and only positive ones are further classified with multi-class classification network. The deeply separable convolution, residual structure and feature enhancement module is the bottleneck of MSTSN, which obtains more discriminative features and meets requirement for real-time performance. The experimental results successfully demonstrate effectiveness of our method.
C1 [Hou, Mingzheng; Zhang, Xin; Chen, Yang; Dong, Penglin; Feng, Ziliang] Sichuan Univ, Coll Comp Sci, Chengdu, Peoples R China.
   [Hou, Mingzheng; Zhang, Xin; Chen, Yang; Dong, Penglin; Feng, Ziliang] Sichuan Univ, Natl Key Lab Fundamental Sci Synthet Vis, Chengdu, Peoples R China.
C3 Sichuan University; Sichuan University
RP Zhang, X (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu, Peoples R China.; Zhang, X (corresponding author), Sichuan Univ, Natl Key Lab Fundamental Sci Synthet Vis, Chengdu, Peoples R China.
EM houmingzheng@scu.edu.cn; zhangxincd@stu.scu.edu.cn; 505012162@qq.com;
   826431353@qq.com; fengziliang@scu.edu.cn
RI feng, ziliang/AAB-5612-2022
OI zhang, xin/0000-0002-4133-6964
FU National Natural Science Foundation of China [U1833115]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. U1833115).
CR Agrawal S, 2017, INT C GRAPH SIGN PRO
   Akatsuka H., 1987, P SAE VEH HIGHW INFR, P189
   Cheng P., 2018, INT C MULT MOD
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Ellahyani A, 2016, INT J ADV COMPUT SC, V7, P686
   Gao XW, 2006, J VIS COMMUN IMAGE R, V17, P675, DOI 10.1016/j.jvcir.2005.10.003
   Gómez-Moreno H, 2010, IEEE T INTELL TRANSP, V11, P917, DOI 10.1109/TITS.2010.2054084
   Greenhalgh J, 2012, IEEE T INTELL TRANSP, V13, P1498, DOI 10.1109/TITS.2012.2208909
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jia L., 2019, IEEE T INTELL TRANSP, V20, P1, DOI [10.1109/TITS.2018.2849019, DOI 10.1109/TITS.2018.2849019]
   Jin JQ, 2014, IEEE T INTELL TRANSP, V15, P1991, DOI 10.1109/TITS.2014.2308281
   Jung S, 2016, INT CONF UBIQ ROBOT, P31, DOI 10.1109/URAI.2016.7734014
   Luo HL, 2018, IEEE T INTELL TRANSP, V19, P1100, DOI 10.1109/TITS.2017.2714691
   Madani A, 2015, IEEE CONTR C
   Onat E, 2015, SIG PROCESS COMMUN, P2161, DOI 10.1109/SIU.2015.7130301
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sermanet P, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2809, DOI 10.1109/IJCNN.2011.6033589
   Song Qingsong, 2018, Journal of Hunan University (Natural Sciences), V45, P131, DOI 10.16339/j.cnki.hdxbzkb.2018.08.018
   Song W., 2015, ROBOT, V37, P102
   Yang Y, 2016, IEEE T INTELL TRANSP, V17, P2022, DOI 10.1109/TITS.2015.2482461
   Yin SY, 2015, SENSORS-BASEL, V15, P2161, DOI 10.3390/s150102161
   Zhang K, 2015, PHOTOGRAMM REC, V30, P187, DOI 10.1111/phor.12103
   Zhu Z., 2016, PROC CVPR IEEE, P2110, DOI DOI 10.1109/CVPR.2016.232
NR 26
TC 0
Z9 0
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16155
EP 16169
DI 10.1007/s11042-022-12201-x
EA MAR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256600020
DA 2024-07-18
ER

PT J
AU Garcia-Hernandez, N
   Huerta-Cervantes, K
   Muñoz-Pepi, I
   Parra-Vega, V
AF Garcia-Hernandez, Nadia
   Huerta-Cervantes, Karely
   Munoz-Pepi, Iram
   Parra-Vega, Vicente
TI Touch location and force sensing interactive system for upper limb motor
   rehabilitation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contact interaction; Force interaction; Game-based Virtual Environment;
   Upper limb rehabilitation
AB The development of an interactive low-cost system for executing tailored upper limb rehabilitation exercises based on game-based Virtual Environments (VEs) is presented. The distinct features of such exercises demand online measurements of point contact with continuous force sensing, as well upper limb kinematics over a large range within the VEs. To meet such requirements, our proposal accounts for an open architecture system consisting of a custom-made 68 x 122 cm touch panel equipped with 26 x 47 (1222) contact and force sensor units based on Velostat, a low cost piezoresistive material. A VE for performing customized reaching exercises runs in Unity3D and Kinect V2 provides biomechanical data points, overall, running on a unique clock that synchronizes all processes. In this way, score, time, limb position, contact and force are processed online to determine the state and progress of patients' motor function. A user evaluation involving twenty-four healthy people between 18 and 59 years old was conducted to assess, on one hand whether the system elicits natural and appropriate engagement of upper arm movements and contact with virtual objects, and on the other hand how such interaction affects intrinsic motivation, experience and workload. Results show that detecting contact point and applied force induce appropriate upper limb movements at the expense of low levels of frustration and mental demand, in contrast to high levels of interest/enjoyment and perceived competence. Therefore, the proposedsystem stands for a promising low cost tool for conducting upper limb motor rehabilitationexercises.
C1 [Garcia-Hernandez, Nadia; Huerta-Cervantes, Karely; Munoz-Pepi, Iram; Parra-Vega, Vicente] IPN CINVESTAV IPN, Adv Robot & Mfg Dept, Lab Man Robot Interfaces, Ctr Res & Adv Studies, Saltillo, Coahuila, Mexico.
   [Garcia-Hernandez, Nadia] Natl Council Sci & Technol CONACYT, Mexico City, DF, Mexico.
RP Garcia-Hernandez, N (corresponding author), IPN CINVESTAV IPN, Adv Robot & Mfg Dept, Lab Man Robot Interfaces, Ctr Res & Adv Studies, Saltillo, Coahuila, Mexico.; Garcia-Hernandez, N (corresponding author), Natl Council Sci & Technol CONACYT, Mexico City, DF, Mexico.
EM nadia.garcia@cinvestav.mx; karely.huerta@cinvestav.mx;
   iram.munoz@cinvestav.mx; vparra@cinvestav.mx
RI Parra-Vega, Vicente/A-1871-2008
OI Parra-Vega, Vicente/0000-0002-1813-0394
FU Conacyt (National Council on Science and Technology in Mexico) [394844,
   394924, 3309]
FX Authors acknowledge support from Grant 3309, and Graduate Scholarships
   394844 and 394924, all from Conacyt (National Council on Science and
   Technology in Mexico) Research Funding
CR Andrew TL, 2003, J CHIROPRACTIC MED, V2, P78, DOI [10.1016/S0899-3467(07)60047-0, DOI 10.1016/S0899-3467(07)60047-0]
   [Anonymous], 2012, COMPUT AIDED DES APP
   Avola D, 2018, MULTIMED TOOLS APPL, V77, P24955, DOI 10.1007/s11042-018-5730-1
   Batmaz AU, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P184, DOI [10.1109/VR46266.2020.1581205539914, 10.1109/VR46266.2020.00-67]
   Blanquero J, 2019, J PHYSIOTHER, V65, P81, DOI 10.1016/j.jphys.2019.02.008
   Confalonieri Michele, 2012, Stud Health Technol Inform, V177, P139
   Confalonieri Michele, 2013, Stud Health Technol Inform, V189, P158
   Dempsey SJ, 2015, SENSOR ACTUAT A-PHYS, V232, P229, DOI 10.1016/j.sna.2015.05.025
   Dunne A, 2010, IEEE ENG MED BIO, P1751, DOI 10.1109/IEMBS.2010.5626724
   Dzedzickis A, 2020, POLYMERS-BASEL, V12, DOI 10.3390/polym12122905
   Elbæk L, 2018, PROC EUR CONF GAME, P62
   Findlater SE, 2017, J MOTOR BEHAV, V49, P27, DOI 10.1080/00222895.2016.1219303
   Franchak John M, 2015, Cogsci, V2015, P728
   Gála M, 2020, PROCEEDINGS OF 2020 IEEE 21ST INTERNATIONAL CONFERENCE ON COMPUTATIONAL PROBLEMS OF ELECTRICAL ENGINEERING (CPEE), DOI 10.1109/cpee50798.2020.9238739
   HART S G, 1988, P139
   Hidalgo-López JA, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112513
   Holmes D. E., 2017, VIRTUAL REALITY RECE, V1, P83
   Hopkins M, 2020, IEEE SENS J, V20, P6992, DOI 10.1109/JSEN.2020.2978431
   Liu J, 2017, MULTIMED TOOLS APPL, V76, P14847, DOI 10.1007/s11042-016-4067-x
   Llorens Roberto, 2013, 2013 International Conference on Virtual Rehabilitation (ICVR), P134, DOI 10.1109/ICVR.2013.6662064
   MCAULEY E, 1989, RES Q EXERCISE SPORT, V60, P48, DOI 10.1080/02701367.1989.10607413
   MORASSO P, 1983, BIOL CYBERN, V48, P187, DOI 10.1007/BF00318086
   Ntelidakis A, 2017, MULTIMED TOOLS APPL, V76, P12683, DOI 10.1007/s11042-016-3695-5
   PARTRIDGE CJ, 2002, NEUROLOGICAL PHYSIOT
   Rand D, 2015, TRIALS, V16, DOI 10.1186/s13063-015-0796-9
   Roberts AR, 2019, CLIN GERONTOLOGIST, V42, P27, DOI 10.1080/07317115.2018.1442380
   Saxena RS, 2011, IEEE SENS J, V11, P432, DOI 10.1109/JSEN.2010.2060186
   Schafer AY, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-76
   Soechting J.F., 1989, Perspectives on the coordination of movement, P47
   Takahashi Issey., 2017, International Journal of Child-Computer Interaction, DOI DOI 10.1016/J.IJCCI.2017.12.002
   Tamayo-Serrano P, 2018, INT J SERIOUS GAMES, V5, P1, DOI 10.17083/ijsg.v5i1.224
   Ustinova KI, 2010, ACTA PSYCHOL, V133, P180, DOI 10.1016/j.actpsy.2009.11.006
   Walker G, 2012, J SOC INF DISPLAY, V20, P413, DOI 10.1002/jsid.100
   Wilk KE, 1996, J SPORT REHABIL, V5, P88, DOI 10.1123/jsr.5.1.88
   Wu JF, 2017, IEEE SENS J, V17, P914, DOI 10.1109/JSEN.2016.2641001
   Wu JF, 2016, IEEE SENS J, V16, P3084, DOI 10.1109/JSEN.2016.2530692
   Zhang X, 2018, IEEE ENG MED BIO, P5187, DOI 10.1109/EMBC.2018.8513419
NR 37
TC 3
Z9 3
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14133
EP 14152
DI 10.1007/s11042-022-12275-7
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300018
DA 2024-07-18
ER

PT J
AU Nagarajan, R
   Thirunavukarasu, R
AF Nagarajan, Rajganesh
   Thirunavukarasu, Ramkumar
TI A neuro-fuzzy based healthcare framework for disease analysis and
   prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neural networks; Neuro-fuzzy system; Healthcare system; Disease
   prediction
ID BIG DATA; SYSTEM
AB With the augmentation of computing and communication technologies, versatile and huge volume of distinguished data sources, the domain of healthcare evidences various promising use-cases among analytical community. Further, the healthcare systems contains disparate, complex and heterogeneous information resources. It prompts the need for applying novel techniques and computational models for reaping potential patterns of interest from the available healthcare data. This paper proposes a neuro-fuzzy based healthcare framework to preprocess the healthcare records and perform disease prediction. The framework constructs a layered approach for performing the task such as preprocessing of healthcare data, normalization through fuzzification process, disease prediction by applying appropriate rules, and de-fuzzification of output values towards obtaining information pertain to predicted disease. The fuzzy rule base is effectively designed to strengthen the decision process. The efficiency of the proposed system is validated with the experimental setup and compared with the fuzzy based and linguistic neuro-fuzzy with feature extraction models. The proposed neuro-fuzzy based method achieves the accuracy value of 87.7%, which is better than the existing methods.
C1 [Nagarajan, Rajganesh] Sri Venkateswara Coll Engn, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Thirunavukarasu, Ramkumar] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Nagarajan, R (corresponding author), Sri Venkateswara Coll Engn, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM anuvarajganesh@gmail.com; ramkumar.thirunavukarasu@vit.ac.in
RI Nagarajan, Rajganesh/C-8738-2019; Thirunavukarasu,
   Ramkumar/AAA-6850-2019
OI Nagarajan, Rajganesh/0000-0003-0072-7704; Thirunavukarasu,
   Ramkumar/0000-0003-2798-8007
CR Agrawal A, 2020, IEEE ACCESS, V8, P135770, DOI 10.1109/ACCESS.2020.3010729
   Ahmed H, 2020, FUTURE GENER COMP SY, V111, P714, DOI 10.1016/j.future.2019.09.056
   [Anonymous], 2017, HLTH CARE INFORM SYS
   Boyd D, 2012, INFORM COMMUN SOC, V15, P662, DOI 10.1080/1369118X.2012.678878
   Chawla NV, 2013, J GEN INTERN MED, V28, pS660, DOI 10.1007/s11606-013-2455-8
   Cheng CW, 2013, IEEE J TRANSL ENG HE, V1, DOI 10.1109/JTEHM.2013.2290113
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143903
   Chowdhary CL, 2016, INT J HEALTHC INF SY, V11, P38, DOI 10.4018/IJHISI.2016040103
   Das Himansu, 2020, Informatics in Medicine Unlocked, V18, DOI 10.1016/j.imu.2019.100288
   Dencelin XL, 2016, BIOMED RES-INDIA, V27, pS166
   Fatemidokht H, 2018, 2018 6TH IRANIAN JOINT CONGRESS ON FUZZY AND INTELLIGENT SYSTEMS (CFIS), P54, DOI 10.1109/CFIS.2018.8336627
   Hilbert M, 2016, DEV POLICY REV, V34, P135, DOI 10.1111/dpr.12142
   Jindal A, 2018, IEEE J BIOMED HEALTH, V22, P1605, DOI 10.1109/JBHI.2018.2799198
   Kakkanatt C, 2018, IBM J RES DEV, V62, DOI 10.1147/JRD.2017.2756742
   Kreimeyer K, 2017, J BIOMED INFORM, V73, P14, DOI 10.1016/j.jbi.2017.07.012
   Kumar R, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040664
   Lauraitis A, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/4581272
   Manogaran G, 2017, STUD BIG DATA, V23, P133, DOI 10.1007/978-3-319-49736-5_7
   Maragatham G, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1243-3
   McPherson R., 2017, HENRYS CLIN DIAGNOSI
   Nagarajan R, 2019, NOVEL PRACTICES TREN, P325
   Nepal S, 2015, IEEE CLOUD COMPUT, V2, P78, DOI 10.1109/MCC.2015.36
   Omoregbe NAI, 2020, J HEALTHC ENG, V2020, DOI 10.1155/2020/8839524
   Palanisamy V, 2019, J KING SAUD UNIV-COM, V31, P415, DOI 10.1016/j.jksuci.2017.12.007
   Pramanik MI, 2017, EXPERT SYST APPL, V87, P370, DOI 10.1016/j.eswa.2017.06.027
   Raghupathi W, 2014, HEALTH INF SCI SYST, V2, DOI 10.1186/2047-2501-2-3
   Rahmani AM, 2018, FUTURE GENER COMP SY, V78, P641, DOI 10.1016/j.future.2017.02.014
   Reddy G.T., 2020, Int Conf Emerg Trends Inform Technol Eng Ic-ETITE, P1, DOI 10.1109/ic-etite47903.2020.235
   Stojanovic J, 2017, IEEE ACM T COMPUT BI, V14, P545, DOI 10.1109/TCBB.2016.2591523
   Taylor W, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092653
   Vanagas G, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/3846892
   Xavier L., 2017, International Journal of Intelligent Engineering and Systems, V10, P226, DOI DOI 10.22266/IJIES2017.0630.25
   Yager R. R, 2012, An Introduction to Fuzzy Logic Applications in Intelligent Systems, V165
   Youssef A.E., 2014, Int J Ambient Syst Appl, V2, P1, DOI DOI 10.5121/IJASA.2014.2201
   Yuan BC, 2012, PROCEDIA COMPUT SCI, V10, P357, DOI 10.1016/j.procs.2012.06.047
NR 35
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11737
EP 11753
DI 10.1007/s11042-022-12369-2
EA FEB 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757777400013
DA 2024-07-18
ER

PT J
AU Yan, ZW
   Zheng, HC
   Li, Y
AF Yan, Zhiwei
   Zheng, Huicheng
   Li, Ye
TI Detail injection with heterogeneous composite backbone network for
   object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Backbone; Detailed information representation; Object detection; Small
   objects; Receptive field
ID REFINEMENT
AB Current detectors usually rely on backbone networks initially designed for image classification and pretrained on large image classification datasets, making them suitable for modeling global information. The consequence is that most detectors struggle to detect small objects due to rapid loss of local spatial details that are critical for accurate localization. In this work, we propose a backbone network, called the heterogeneous composite backbone, which aims to not only utilize deep features generated by the off-the-shelf classification-oriented backbone network for global information extraction, but also benefit from our re-designed detail extraction backbone network that yields features with more detailed spatial information, which is accomplished through joining two backbones with diverse structures. Our new backbone is shown to be beneficial for modeling fine-grained local information. Furthermore, to guarantee that the features from the randomly initialized detail extraction network are not suppressed in the end-to-end training process, we explore a new training scheme that combines features from a pretrained deep backbone and features generated by a network trained nearly from scratch. We carry out experiments on benchmark datasets including PASCAL VOC and MS COCO, which demonstrate that the proposed backbone network can achieve considerable improvements in object detection.
C1 [Yan, Zhiwei; Zheng, Huicheng; Li, Ye] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
   [Yan, Zhiwei; Zheng, Huicheng; Li, Ye] Minist Educ, Key Lab Machine Intelligence & Adv Comp, Guangzhou, Peoples R China.
   [Yan, Zhiwei; Zheng, Huicheng; Li, Ye] Guangdong Prov Key Lab Informat Secur Technol, 135 West Xingang Rd, Guangzhou 510275, Peoples R China.
   [Li, Ye] Healthcare Secur Bur Shenzhen Municipal, Rongchao Tower,4036 Jintian Rd, Shenzhen 518038, Peoples R China.
C3 Sun Yat Sen University
RP Zheng, HC (corresponding author), Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou, Peoples R China.; Zheng, HC (corresponding author), Minist Educ, Key Lab Machine Intelligence & Adv Comp, Guangzhou, Peoples R China.; Zheng, HC (corresponding author), Guangdong Prov Key Lab Informat Secur Technol, 135 West Xingang Rd, Guangzhou 510275, Peoples R China.
EM zhenghch@mail.sysu.edu.cn
FU National Natural Science Foundation of China [61976231, U1611461,
   61573387, 61172141]; Guangdong Basic and Applied Basic Research
   Foundation [2019A1515011869]; Science and Technology Program of
   Guangzhou [201803030029]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61976231, Grant U1611461, Grant
   61573387, and Grant 61172141, in part by the Guangdong Basic and Applied
   Basic Research Foundation under Grant 2019A1515011869, and in part by
   the Science and Technology Program of Guangzhou under Grant
   201803030029.
CR [Anonymous], COMPUT VIS PATTERN R
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Chi C, 2019, AAAI CONF ARTIF INTE, P8231
   Dai Jifeng, 2016, Advances in Neural Information Processing Systems, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dosovitskiy Alexey, 2021, 2021 INT C LEARN REP
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Dvornik N, 2017, IEEE I CONF COMP VIS, P4174, DOI 10.1109/ICCV.2017.447
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Fu ZH, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P265, DOI 10.1145/3240508.3240544
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Gregory G., 2007, CNSTR2007001 CALTECH
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2019, IEEE I CONF COMP VIS, P4917, DOI 10.1109/ICCV.2019.00502
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kaiwen Duan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P399, DOI 10.1007/978-3-030-58580-8_24
   Kong T, 2017, PROC CVPR IEEE, P5244, DOI 10.1109/CVPR.2017.557
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Le H, 2017, ARXIVABS170507049
   Li JG, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102886
   Li S, 2019, IEEE I CONF COMP VIS, P6608, DOI 10.1109/ICCV.2019.00671
   Li Y, 2019, NEUROCOMPUTING, V359, P209, DOI 10.1016/j.neucom.2019.05.086
   Li ZM, 2018, LECT NOTES COMPUT SC, V11213, P339, DOI [10.1007/978-3-030-01240-3_21, 10.1007/978-3-030-01219-9_23]
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YD, 2020, AAAI CONF ARTIF INTE, V34, P11653
   Pang YW, 2019, PROC CVPR IEEE, P7328, DOI 10.1109/CVPR.2019.00751
   Ran Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P412, DOI 10.1007/978-3-030-58542-6_25
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shen ZQ, 2020, IEEE T PATTERN ANAL, V42, P398, DOI 10.1109/TPAMI.2019.2922181
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tolstikhin I, 2021, ADV NEUR IN, V34
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yuhang Cao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11580, DOI 10.1109/CVPR42600.2020.01160
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang ZS, 2018, PROC CVPR IEEE, P5813, DOI 10.1109/CVPR.2018.00609
   Zhao H, 2020, NEURAL PROCESS LETT, V51, P2789, DOI 10.1007/s11063-020-10228-5
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zheng HC, 2020, NEURAL PROCESS LETT, V51, P1907, DOI 10.1007/s11063-019-10182-x
   Zhou P, 2018, PROC CVPR IEEE, P528, DOI 10.1109/CVPR.2018.00062
   Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094
   Zhu R, 2019, PROC CVPR IEEE, P2263, DOI 10.1109/CVPR.2019.00237
   Zhu YS, 2017, IEEE I CONF COMP VIS, P4146, DOI 10.1109/ICCV.2017.444
NR 58
TC 1
Z9 1
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11621
EP 11637
DI 10.1007/s11042-022-12241-3
EA FEB 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757777400003
DA 2024-07-18
ER

PT J
AU Guo, ZD
   Sun, P
AF Guo, Zhida
   Sun, Peng
TI Improved reverse zigzag transform and DNA diffusion chaotic image
   encryption method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Reverse zigzag traverse; DNA operation; Logistic map;
   Hash function; Diffusion operation
ID PERMUTATION; OPERATION; NETWORK; SYSTEM; MAP
AB In this paper, we propose a chaotic image encryption method based on an improved reverse Zigzag cyclic traversal algorithm combined with DNA coding. The original Zigzag algorithm cannot change all pixel positions at once due to the limitation of the traversal method, and our improved traversal method modifies the original traversal order to reverse zigzag cyclic traversal, after which the image is scrambled with a secondary chaotic sequence. Secondly, the diffusion of DNA pixels is completed after the scrambling operation on the image on the screen. Finally, as an example to further deepen the encryption effect, the image of the chaotic sequence is diffused and the final encrypted image is obtained. Experiments show that the algorithm in this paper has high security. Compared with the original algorithm, the improved reverse Zigzag algorithm has better traversal effect and higher efficiency. Meanwhile, the combination of DNA encoding makes the algorithm more resistant to attacks and can effectively resist common types of attacks.
C1 [Guo, Zhida] Dalian Jiaotong Univ, Dalian 116026, Peoples R China.
   [Sun, Peng] China Acad Railway Sci, Inst Comp Technol, Beijing 100081, Peoples R China.
C3 Dalian Jiaotong University
RP Guo, ZD (corresponding author), Dalian Jiaotong Univ, Dalian 116026, Peoples R China.
EM 694102644@qq.com; kevin102486@163.com
RI Li, Shiyu/KHE-1376-2024; Sun, Peng/KDO-4243-2024
CR Akhshani A, 2012, COMMUN NONLINEAR SCI, V17, P4653, DOI 10.1016/j.cnsns.2012.05.033
   Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chen JX, 2018, NONLINEAR DYNAM, V93, P2399, DOI 10.1007/s11071-018-4332-9
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Li X., 2018, Int. J. Netw. Secur, V20, P110, DOI DOI 10.6633/IJNS.201801
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Ling, 2011, IEEE COMPUT INTELL M, V6, P68, DOI [10.1109/MCI.2010.939582, DOI 10.1109/MCI.2010.939582]
   [刘艮 Liu Gen], 2013, [计算机工程与科学, Computer Engineering and Science], V35, P106
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P4363, DOI 10.1007/s11042-015-2479-7
   Ma J., 2015, J NETWORK NEW MEDIA, V4, P37
   Maddodi G, 2018, MULTIMED TOOLS APPL, V77, P24701, DOI 10.1007/s11042-018-5669-2
   Niu Ying, 2017, Computer Engineering and Applications, V53, P130, DOI 10.3778/j.issn.1002-8331.1702-0122
   Peng J, 2013, PROCEEDINGS OF THE 2013 12TH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI CC 2013), P403, DOI 10.1109/ICCI-CC.2013.6622274
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Toughi S, 2017, SIGNAL PROCESS, V141, P217, DOI 10.1016/j.sigpro.2017.06.010
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wang XY, 2014, NONLINEAR DYNAM, V75, P345, DOI 10.1007/s11071-013-1070-x
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Xu Xiaolin, 2010, Proceedings of the 2010 IEEE International Conference on Granular Computing (GrC-2010), P556, DOI 10.1109/GrC.2010.11
   Yang YY., 2011, NETINFO SECURITY, V11, P57
   Ye GD, 2016, NONLINEAR DYNAM, V83, P2067, DOI 10.1007/s11071-015-2465-7
   Zhang YQ, 2016, OPT LASER ENG, V82, P95, DOI 10.1016/j.optlaseng.2016.02.002
NR 36
TC 8
Z9 9
U1 7
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11301
EP 11323
DI 10.1007/s11042-022-12269-5
EA FEB 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757168400001
DA 2024-07-18
ER

PT J
AU Rani, S
   Kaur, M
   Kumar, M
AF Rani, Shalli
   Kaur, Manpreet
   Kumar, Munish
TI Recommender system: prediction/diagnosis of breast cancer using hybrid
   machine learning algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; Collaborative filtering; Breast cancer; Machine
   learning; Benign and malignant stage
AB Breast cancer is the second popular cause of the women's death. There are some existing techniques for identifying the breast cancer and one of them is mammography screening, for identifying the breast cancer under the age of 40 to 50 years. For medical diagnosis applications such as breast cancer, the recommender system is very helpful. There is a large number of records or datasets available for diagnosis of human diseases. In this article, we have presented an in-depth study of breast cancer predictions to take the remedial actions. Then experiments are carried out in Microsoft Azure on the breast cancer dataset which is available on Kaggle. The training and testing are done on 70% and 30% of the data. The evaluations are conducted by using machine learning algorithms, Locally Deep SVM, Boosted Decision Tree, Averaged Perception, Bayes Point and Decision Forest to predict Breast Cancer. We conducted an experiment on 18 K breast cancer image dataset. A hybrid machine learning algorithm (HMLA) based on decision tree and average perceptron algorithms is proposed. Based on the experimental evaluation, it is analyzed that proposed algorithm has performed well with 98.1% of accuracy and predicting the accurate results with 95.0% of sensitivity and specificity of 99.0% on the Breast Cancer prediction.
C1 [Rani, Shalli; Kaur, Manpreet] Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Bathinda, Punjab, India.
C3 Chitkara University, Punjab
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Bathinda, Punjab, India.
EM munishcse@gmail.com
RI Kaur, Manpreet/HJZ-4398-2023; Kumar, Munish/P-7756-2018; Rani,
   Shalli/AGY-9513-2022
OI Kumar, Munish/0000-0003-0115-1620; Rani, Shalli/0000-0002-8474-9435
CR Assiri AS, 2020, J IMAGING, V6, DOI 10.3390/jimaging6060039
   Batmaz Z, 2020, J AMB INTEL HUM COMP, V11, P2601, DOI 10.1007/s12652-019-01321-2
   Cao GF, 2019, INT J SOFTW ENG KNOW, V29, P1159, DOI 10.1142/S0218194019500360
   Felfernig A, 2007, IEEE INTELL SYST, V22, P18, DOI 10.1109/MIS.2007.52
   Forouzandeh S, 2021, ENG APPL ARTIF INTEL, V104, DOI 10.1016/j.engappai.2021.104325
   Forouzandeh S, 2021, INT J INF TECH DECIS, V20, P399, DOI 10.1142/S0219622020500522
   Forouzandeh S, 2021, MULTIMED TOOLS APPL, V80, P7805, DOI 10.1007/s11042-020-09949-5
   Ha J, 2020, J BIOMED INFORM, V102, DOI 10.1016/j.jbi.2019.103358
   Karthikeyan P, 2017, INT CONF ADV COMPU, P99, DOI 10.1109/ICoAC.2017.7951753
   Khoshgoftaar T.M., 2009, ADV ARTIFICIAL INTEL, DOI [10.1155/2009/421425, DOI 10.1155/2009/421425]
   Kyono T, 2020, J AM COLL RADIOL, V17, P56, DOI 10.1016/j.jacr.2019.05.012
   McKinney SM, 2020, NATURE, V577, P89, DOI 10.1038/s41586-019-1799-6
   Moghaddam BK, 2013, TELECOMMUN POLICY, V37, P1083, DOI 10.1016/j.telpol.2013.02.005
   Pattaraintakorn P, 2007, LECT NOTES ARTIF INT, V4482, P491
   Priya N., 2020, 2020 INT C EM TRENDS, DOI [10.1109/IC-ETITE47903.2020.469, DOI 10.1109/IC-ETITE47903.2020.469]
   Turk AM, 2019, EXPERT SYST APPL, V115, P386, DOI 10.1016/j.eswa.2018.08.001
NR 16
TC 3
Z9 4
U1 3
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9939
EP 9948
DI 10.1007/s11042-022-12144-3
EA FEB 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800021
DA 2024-07-18
ER

PT J
AU He, KJ
   Gong, J
   Xu, D
AF He, Kangjian
   Gong, Jian
   Xu, Dan
TI Focus-pixel estimation and optimization for multi-focus image fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-focus image fusion; Focus pixel estimation; Optimization;
   Focus-measure
ID WAVELET; INFORMATION; PERFORMANCE; DECOMPOSITION; TRANSFORM; FREQUENCY
AB To integrate the effective information and improve the quality of multi-source images, many spatial or transform domain-based image fusion methods have been proposed in the field of information fusion. The key purpose of multi-focus image fusion is to integrate the focused pixels and remove redundant information of each source image. Theoretically, if the focused pixels and complementary information of different images are detected completely, the fusion image with best quality can be obtained. For this goal, we propose a focus-pixel estimation and optimization based multi-focus image fusion framework in this paper. Because the focused pixels of an image are in the same depth of field (DOF), we propose a multi-scale focus-measure algorithm for the focused pixels matting to integrate the focused region firstly. Then, the boundaries of focused and defocused regions are obtained accurately by the proposed optimizing strategy. And the boundaries are also fused to reduce the influence of insufficient boundary precision. The experimental results demonstrate that the proposed method outperforms some previous typical methods in both objective evaluations and visual perception.
C1 [He, Kangjian; Gong, Jian; Xu, Dan] Yunnan Univ, Sch Informat Sci & Engn, Kunming 650091, Yunnan, Peoples R China.
C3 Yunnan University
RP Xu, D (corresponding author), Yunnan Univ, Sch Informat Sci & Engn, Kunming 650091, Yunnan, Peoples R China.
EM danxu@ynu.edu.cn
RI He, Kangjian/R-6183-2016; Xu, Dan/KPA-7396-2024; He,
   Kangjian/CAG-0300-2022
OI He, Kangjian/0000-0001-6207-9728; Xu, Dan/0000-0003-4602-3550; 
FU National Natural Science Foundation of China [62162068, 61761046,
   61540062, 62061049]; Yunling Scholars Special Project
   [YNWR-YLXZ-2018-022]; Yunnan Province Ten Thousand Talents Program
   [YNWR-YLXZ-2018-022]; Yunnan Provincial Science and Technology
   Department [2019FY003012]; Yunnan University [2019FY003012]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62162068, Grant 61761046, Grant
   61540062, and 62061049, in part by the Yunnan Province Ten Thousand
   Talents Program and Yunling Scholars Special Project under Grant
   YNWR-YLXZ-2018-022, in part by the Joint Fund of Yunnan Provincial
   Science and Technology Department and Yunnan University under Grant
   2019FY003012.
CR Aslantas V, 2010, EXPERT SYST APPL, V37, P8861, DOI 10.1016/j.eswa.2010.06.011
   Bai XZ, 2015, INFORM FUSION, V22, P105, DOI 10.1016/j.inffus.2014.05.003
   Chen YB, 2018, IEEE T IMAGE PROCESS, V27, P1526, DOI 10.1109/TIP.2017.2779274
   Chowdhary C.L., 2019, RECENT PAT COMPUT SC, V12, P18, DOI [10.2174/2213275911666180821092033, DOI 10.2174/2213275911666180821092033]
   Cvejic N, 2006, ELECTRON LETT, V42, P626, DOI 10.1049/el:20060693
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Dippel S, 2002, IEEE T MED IMAGING, V21, P343, DOI 10.1109/TMI.2002.1000258
   Du J, 2016, NEUROCOMPUTING, V194, P326, DOI 10.1016/j.neucom.2016.02.047
   Dundar T, 2019, IEEE GEOSCI REMOTE S, V16, P246, DOI 10.1109/LGRS.2018.2871273
   Farid MS, 2019, INFORM FUSION, V45, P96, DOI 10.1016/j.inffus.2018.01.009
   Favaro P, 2005, IEEE T PATTERN ANAL, V27, P406, DOI 10.1109/TPAMI.2005.43
   Gangapure VN, 2015, INFORM FUSION, V23, P99, DOI 10.1016/j.inffus.2014.07.003
   Goshtasby AA, 2007, INFORM FUSION, V8, P114, DOI 10.1016/j.inffus.2006.04.001
   Guo XP, 2019, IEEE T MULTIMEDIA, V21, P1982, DOI 10.1109/TMM.2019.2895292
   Guo XP, 2018, NEURAL COMPUT, V30, P1775, DOI 10.1162/neco_a_01098
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He KJ, 2019, SOFT COMPUT, V23, P4685, DOI 10.1007/s00500-018-3118-9
   He KJ, 2018, NEUROCOMPUTING, V320, P157, DOI 10.1016/j.neucom.2018.09.018
   Huang W, 2007, PATTERN RECOGN LETT, V28, P1123, DOI 10.1016/j.patrec.2007.01.013
   Wei H, 2007, PATTERN RECOGN LETT, V28, P493, DOI 10.1016/j.patrec.2006.09.005
   Ji ZY, 2019, IEEE ACCESS, V7, P123231, DOI 10.1109/ACCESS.2019.2933646
   Kellman P, 2005, MAGNET RESON MED, V54, P1439, DOI 10.1002/mrm.20713
   Khare N, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040692
   Kong WW, 2014, INFRARED PHYS TECHN, V65, P103, DOI 10.1016/j.infrared.2014.04.003
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   Li HG, 2019, IEEE SENS J, V19, P9755, DOI 10.1109/JSEN.2019.2928818
   Li M, 2006, PATTERN RECOGN LETT, V27, P1948, DOI 10.1016/j.patrec.2006.05.004
   Li ST, 2008, PATTERN RECOGN LETT, V29, P1295, DOI 10.1016/j.patrec.2008.02.002
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li S, 2013, INFORM FUSION, V14, P147, DOI 10.1016/j.inffus.2011.07.001
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Liu W, 2020, SIGNAL PROCESS, V166, DOI 10.1016/j.sigpro.2019.107252
   Liu YP, 2014, SIGNAL PROCESS, V97, P9, DOI 10.1016/j.sigpro.2013.10.010
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Ma JL, 2019, NEUROCOMPUTING, V335, P9, DOI 10.1016/j.neucom.2019.01.048
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mitianoudis N, 2007, INFORM FUSION, V8, P131, DOI 10.1016/j.inffus.2005.09.001
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Piella G., 2003, Information Fusion, V4, P259, DOI 10.1016/S1566-2535(03)00046-0
   Pradhan PS, 2006, IEEE T GEOSCI REMOTE, V44, P3674, DOI 10.1109/TGRS.2006.881758
   Qiu XH, 2019, SIGNAL PROCESS-IMAGE, V72, P35, DOI 10.1016/j.image.2018.12.004
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Qu Xiao-bo, 2009, Optics and Precision Engineering, V17, P1203
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shreyamsha Kumar BK, 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI 10.1007/s11760-013-0556-9
   Tsai DY, 2008, J DIGIT IMAGING, V21, P338, DOI 10.1007/s10278-007-9044-5
   Xia XH, 2018, SIGNAL PROCESS, V153, P71, DOI 10.1016/j.sigpro.2018.07.004
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zheng YF, 2007, INFORM FUSION, V8, P177, DOI 10.1016/j.inffus.2005.04.003
   Zhou Z, 2014, INFORM FUSION, V20, P60, DOI 10.1016/j.inffus.2013.11.005
NR 53
TC 2
Z9 2
U1 6
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 7711
EP 7731
DI 10.1007/s11042-022-12031-x
EA JAN 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000750865600003
OA hybrid
DA 2024-07-18
ER

PT J
AU Jain, PK
   Patel, A
   Kumari, S
   Pamula, R
AF Jain, Praphula Kumar
   Patel, Arjav
   Kumari, Saru
   Pamula, Rajendra
TI Predicting airline customers' recommendations using qualitative and
   quantitative contents of online reviews
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; Machine learning; Text mining; Recommendation
   prediction; Online review
ID WORD-OF-MOUTH; CONSUMER REVIEWS; IMPACT; CREDIBILITY; PASSENGER;
   PRODUCT; SALES
AB Customers generally give ratings and reviews for different services that they get online or offline. These reviews and ratings aspects are effectively helpful to both the company and customers to receive feedback and make the right decisions, respectively. However, the number of reviews and ratings can increase exponentially, bringing a new challenge for the company to manage and track. Under these circumstances, it will also be hard for the customer to make the right decision. In this work, we summarize text reviews and ratings given by passengers for different airlines. The objective of this research is to predict whether the recommendation made by the customer is positive or negative. Two types of features, namely, textual feature and explicit ratings, are extracted from the dataset and other attributes. We found the relationship between such sentiments and feelings expressed in online reviews and predictive consumer recommendation decisions. We have considered quantitative content with qualitative content of online reviews in predicting recommendation decisions, which shows the work's novelty. Additionally, the obtained results yield an essential contribution to the existing literature in terms of service evaluation, making managerial policies, and predictive consumer recommendations, etc. Moreover, we hope that this work would be helpful for practitioners who wish to utilize the technique to make the quick and essential hidden information by combining textual reviews and various service aspects ratings.
C1 [Jain, Praphula Kumar; Patel, Arjav; Pamula, Rajendra] Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad 826004, Bihar, India.
   [Kumari, Saru] Chaudhary Charan Singh Univ, Dept Math, Meerut 250004, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad; Chaudhary Charan Singh
   University
RP Jain, PK (corresponding author), Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad 826004, Bihar, India.
EM praphulajn1@gmail.com
RI JAIN, PRAPHULA KUMAR/AAG-7979-2019; Kumari, Saru/K-2038-2019; Pamula,
   Rajendra/V-9454-2019
OI JAIN, PRAPHULA KUMAR/0000-0001-7651-4444; Kumari,
   Saru/0000-0003-4929-5383; Pamula, Rajendra/0000-0002-4806-3495
CR ARNDT J, 1967, J MARKETING RES, V4, P291, DOI 10.1177/002224376700400308
   Ayeh JK, 2013, J TRAVEL RES, V52, P437, DOI 10.1177/0047287512475217
   Braun ML, 2008, J MACH LEARN RES, V9, P1875
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chatterjee S, 2019, DECIS SUPPORT SYST, V119, P14, DOI 10.1016/j.dss.2019.02.008
   Cheung CMY, 2012, J ASSOC INF SYST, V13, P618
   Chevalier JA, 2006, J MARKETING RES, V43, P345, DOI 10.1509/jmkr.43.3.345
   Cooley C.H., 1983, SOCIAL ORG
   Gupta S, 2006, MARKET SCI, V25, P718, DOI 10.1287/mksc.1060.0221
   Hastie T., 2009, The Elements of Statistical Learning
   Jain Praphula Kumar, 2019, 2019 4th International Conference on Information Systems and Computer Networks (ISCON), P376, DOI 10.1109/ISCON47742.2019.9036251
   Jain P. K., 2020, MACHINE LEARNING ALG, P53
   Jain PK, 2021, COMPUT SCI REV, V41, DOI 10.1016/j.cosrev.2021.100413
   Jain PK, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3457206
   Jain PK, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03436-x
   Jang SH, 2012, MARKET LETT, V23, P825, DOI 10.1007/s11002-012-9191-4
   Keiningham T.L., 2007, MANAG SERV QUAL, V17, P361, DOI [https://doi.org/10.1108/09604520710760526, DOI 10.1108/09604520710760526]
   Keiningham TL, 2007, J MARKETING, V71, P39, DOI 10.1509/jmkg.71.3.39
   Kohavi R., 2002, Handbook of data mining and knowledge discovery, P267
   Korfiatis N, 2012, ELECTRON COMMER R A, V11, P205, DOI 10.1016/j.elerap.2011.10.003
   Kuan KKY, 2015, J ASSOC INF SYST, V16, P48, DOI 10.17705/1jais.00386
   Kusumasondjaja S., 2012, Journal of Vacation Marketing, V18, P185, DOI 10.1177/1356766712449365
   Liang XJ, 2018, ELECTRON COMMER R A, V27, P83, DOI 10.1016/j.elerap.2017.12.007
   Lis B, 2014, BUS INFORM SYST ENG+, V6, P63, DOI 10.1007/s12599-013-0306-0
   Lucini FR, 2020, J AIR TRANSP MANAG, V83, DOI 10.1016/j.jairtraman.2019.101760
   Muhammad SS, 2018, INFORM SYST FRONT, V20, P559, DOI 10.1007/s10796-017-9802-y
   Preko A., 2014, European Journal of Business and Management, V6, P71, DOI [10.5539/ijms.v6n4p123, DOI 10.5539/IJMS.V6N4P123]
   Punel A, 2019, TOURISM MANAGE, V75, P491, DOI 10.1016/j.tourman.2019.06.004
   Quamer W, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3426884
   Reichheld F.F., 2011, The Ultimate Question 2.0: How Net Promoter Companies Thrive in a Customer-driven World
   Reichheld FF, 2004, HARVARD BUS REV, V82, P133
   RICHINS ML, 1983, J MARKETING, V47, P68, DOI 10.2307/3203428
   Richins ML, ROLE EVOLVEMENT OPIN
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Sezgen E, 2019, J AIR TRANSP MANAG, V77, P65, DOI 10.1016/j.jairtraman.2019.04.001
   Siering M, 2018, DECIS SUPPORT SYST, V107, P52, DOI 10.1016/j.dss.2018.01.002
   Sparks BA, 2011, TOURISM MANAGE, V32, P1310, DOI 10.1016/j.tourman.2010.12.011
   Tamrakar C., 2018, SOCIAL MEDIA SENTIME
   Verma VK, 2018, ENVIRON DEV SUSTAIN, V20, P1347, DOI 10.1007/s10668-017-9944-6
   Vermeulen IE, 2009, TOURISM MANAGE, V30, P123, DOI 10.1016/j.tourman.2008.04.008
   Zhang W, 2011, EXPERT SYST APPL, V38, P2758, DOI 10.1016/j.eswa.2010.08.066
   Zhu F, 2010, J MARKETING, V74, P133, DOI 10.1509/jmkg.74.2.133
NR 42
TC 10
Z9 10
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6979
EP 6994
DI 10.1007/s11042-022-11972-7
EA JAN 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000744767900002
DA 2024-07-18
ER

PT J
AU Pang, WF
   He, QH
   Chen, YF
   Li, YX
AF Pang, Wenfeng
   He, Qianhua
   Chen, Yuanfeng
   Li, Yanxiong
TI Fall event detection with global and temporal local information in
   real-world videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fall event detection; Temporal local information; Multiple instance
   module; Real-world fall dataset
ID SURVEILLANCE
AB Fall event detection is a task to determine whether a video includes falls, which can offer timely alarms to help reduce fall injury outcomes. This study applied typical 3D-convoultional network (C3D) as the classifier, but the basic C3D tends to extract the global information ignoring frame-wise information, whereas fall events are usually instantaneous. In the case that frame-level labels are difficult to obtain, we treat the problem of extracting temporal local information as a semi-supervised task, and introduce multiple instance (MI) module to construct an additional branch in C3D, which utilizes the multiple instance learning (MIL) to focus on smaller time-scale information. The MI module chooses a segment most likely to contain falls in a video for calculating the MIL loss, which is combined with the original cross-entropy loss as the total loss. In view of the fact fall events in the existing datasets are insufficient and not representative of real-world environments, we built a new dataset called Real-World Fall (RWF) providing a large number of factual fall cases. Experimental results on the RWF dataset indicated that our proposed model achieves superior performance by simultaneously extracting global and temporal local information. Further studies were conducted to assessed factors effect in MI module, including loss functions and pooling methods.
C1 [Pang, Wenfeng; He, Qianhua; Li, Yanxiong] South China Univ Technol, Guangzhou, Peoples R China.
   [Chen, Yuanfeng] Guangzhou City Polytech, Guangzhou, Peoples R China.
C3 South China University of Technology
RP He, QH (corresponding author), South China Univ Technol, Guangzhou, Peoples R China.
EM eeqhhe@scut.edu.cn
FU National Nature Science Foundation of China [61571192, 61771200]
FX The work was supported by the National Nature Science Foundation of
   China (Grant No. 61571192, 61771200).
CR Abou L, 2022, ASSIST TECHNOL, V34, P619, DOI 10.1080/10400435.2021.1923087
   Adhikari K, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P81, DOI 10.23919/MVA.2017.7986795
   Anderson Derek, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P6388
   [Anonymous], 2018, FALLS
   Auvinet E., 2010, MULTIPLE CAMERAS FAL
   Auvinet E, 2011, IEEE T INF TECHNOL B, V15, P290, DOI 10.1109/TITB.2010.2087385
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Botchkarev A., 2018, Performance Metrics (Error Measures) in Machine Learning Regression, Forecasting and Prognostics: Properties and Typology, DOI 10.28945/4184
   Bourke AK, 2008, MED ENG PHYS, V30, P84, DOI 10.1016/j.medengphy.2006.12.001
   Carbonneau MA, 2018, PATTERN RECOGN, V77, P329, DOI 10.1016/j.patcog.2017.10.009
   Charfi E, 2012, PROCEEDINGS OF THE 2012 8TH INTERNATIONAL SYMPOSIUM ON COMMUNICATION SYSTEMS, NETWORKS & DIGITAL SIGNAL PROCESSING (CSNDSP)
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   FARNEBACK G, 2003, 13 SCAND C IM AN HAL
   Galvao YM, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114226
   Gracewell JJ, 2021, J AMB INTEL HUM COMP, V12, P3581, DOI 10.1007/s12652-019-01600-y
   Khraief C, 2020, MULTIMED TOOLS APPL, V79, P19537, DOI 10.1007/s11042-020-08812-x
   Kingma D. P., 2014, arXiv
   Kong YQ, 2019, J VIS COMMUN IMAGE R, V59, P215, DOI 10.1016/j.jvcir.2019.01.024
   Kwolek B, 2015, NEUROCOMPUTING, V168, P637, DOI 10.1016/j.neucom.2015.05.061
   Miaou SG, 2006, 1ST TRANSDISCIPLINARY CONFERENCE ON DISTRIBUTED DIAGNOSIS AND HOME HEALTHCARE, CONFERENCE PROCEEDINGS, P39, DOI 10.1109/DDHH.2006.1624792
   Molchanov P., 2017, INT C LEARN REPR ICL, P1, DOI DOI 10.1002/9781118786352.WBIEG1156
   Mubashir M, 2013, NEUROCOMPUTING, V100, P144, DOI 10.1016/j.neucom.2011.09.037
   Musci M., 2020, IEEE T EMERG TOP COM
   Nogas J, 2020, J HEALTHC INFORM RES, V4, P50, DOI 10.1007/s41666-019-00061-4
   Núñez-Marcos A, 2017, WIREL COMMUN MOB COM, DOI 10.1155/2017/9474806
   Planinc R, 2013, PERS UBIQUIT COMPUT, V17, P1063, DOI 10.1007/s00779-012-0552-z
   Ramon Jan, 2000, P ICML 2000 WORKSH A, P53
   Rothman, 2018, TRAIN CNN MOD
   Rougier C, 2011, IEEE T CIRC SYST VID, V21, P611, DOI 10.1109/TCSVT.2011.2129370
   Sarang P., 2021, Artificial Neural Networks with TensorFlow 2, DOI DOI 10.1007/978-1-4842-6150-7
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Vallejo M, 2013, IEEE ENG MED BIO, P1648, DOI 10.1109/EMBC.2013.6609833
   Wang K, 2016, IEEE INT C BIOINFORM, P1228, DOI 10.1109/BIBM.2016.7822694
   Wang SK, 2016, MULTIMED TOOLS APPL, V75, P11603, DOI 10.1007/s11042-015-2698-y
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wu JS, 2018, NEUROCOMPUTING, V313, P271, DOI 10.1016/j.neucom.2018.06.025
   Yao LY, 2022, MULTIMED TOOLS APPL, V81, P4551, DOI 10.1007/s11042-020-09181-1
   Yazar A, 2013, PATTERN RECOGN LETT, V34, P1945, DOI 10.1016/j.patrec.2012.12.010
NR 41
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6943
EP 6956
DI 10.1007/s11042-022-12018-8
EA JAN 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000744767900001
DA 2024-07-18
ER

PT J
AU Vyas, R
AF Vyas, Ritesh
TI Enhanced near-infrared periocular recognition through collaborative
   rendering of hand crafted and deep features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Near-infrared; Periocular; CNN; Biometrics
ID IRIS
AB Periocular recognition leverage from larger feature region and lesser user cooperation, when compared against the traditional iris recognition. Moreover, in the current scenario of Covid-19, where majority of people cover their faces with masks, potential of recognizing faces gets reduced by a large extent, calling for wide applicability of periocular recognition. In view of these facts, this paper targets towards enhanced representation of near-infrared periocular images, by combined use of hand-crafted and deep features. The hand-crafted features are extracted through partitioning of periocular image followed by obtaining the local statistical properties pertaining to each partition. Whereas, deep features are extracted through the popular convolutional neural network (CNN) ResNet-101 model. The extensive set of experiments performed with a benchmark periocular database validates the promising performance of the proposed method. Additionally, investigation of cross-spectral matching framework and comparison with state-of-the-art, reveal that combination of both types of features employed could prove to be extremely effective.
C1 [Vyas, Ritesh] Univ Lancaster, Lancaster, England.
C3 Lancaster University
RP Vyas, R (corresponding author), Univ Lancaster, Lancaster, England.
EM ritesh.vyas157@gmail.com
OI Vyas, Ritesh/0000-0002-9739-2551
CR Aginako N, 2017, PATTERN RECOGN LETT, V91, P52, DOI 10.1016/j.patrec.2017.01.021
   Ahmed NU, 2017, PATTERN RECOGN LETT, V91, P11, DOI 10.1016/j.patrec.2017.03.003
   Alahmadi A, 2020, J INTELL FUZZY SYST, V38, P3041, DOI 10.3233/JIFS-190834
   Alonso-Fernandez F, 2016, INT CONF BIOMETR THE
   Alonso-Fernandez F, 2016, PATTERN RECOGN LETT, V82, P92, DOI 10.1016/j.patrec.2015.08.026
   [Anonymous], 2010, INT C BIOM THEOR APP
   [Anonymous], 2016, 2016 INT C BIOM SPEC
   Behera SS, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P681, DOI 10.1109/BTAS.2017.8272757
   Bekhet S, 2020, MULTIMED TOOLS APPL, V79, P6265, DOI 10.1007/s11042-019-08539-4
   Bharadwaj Samarth., 2010, 2010 4 IEEE INT C BI, P1, DOI DOI 10.1109/BTAS.2010.5634498
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gangwar A, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), P714, DOI 10.1109/CISP.2014.7003871
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hernandez-Diaz K, 2018, 2018 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG)
   Hollingsworth KP, 2012, IEEE T INF FOREN SEC, V7, P588, DOI 10.1109/TIFS.2011.2173932
   Kumar G, 2021, MULTIMED TOOLS APPL, V80, P16565, DOI 10.1007/s11042-020-08708-w
   Lumini A, 2017, INFORM FUSION, V33, P71, DOI 10.1016/j.inffus.2016.05.003
   Luz E, 2018, PATTERN RECOGN LETT, V114, P2, DOI 10.1016/j.patrec.2017.12.009
   Mahalingam G, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-36
   Park U, 2011, IEEE T INF FOREN SEC, V6, P96, DOI 10.1109/TIFS.2010.2096810
   Park U, 2009, 2009 IEEE 3RD INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P153
   Proença H, 2014, IET BIOMETRICS, V3, P167, DOI 10.1049/iet-bmt.2013.0039
   Raja K, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103979
   Raja KB, 2014, I W BIOMETRIC FORENS
   Raja KB, 2016, IEEE IMAGE PROC, P330, DOI 10.1109/ICIP.2016.7532373
   Raja KB, 2015, INT CONF BIOMETR, P143, DOI 10.1109/ICB.2015.7139044
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Santos G, 2015, PATTERN RECOGN LETT, V57, P52, DOI 10.1016/j.patrec.2014.09.012
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Sequeira AF, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P725, DOI 10.1109/BTAS.2017.8272762
   Sharma A, 2014, IEEE IMAGE PROC, P5007, DOI 10.1109/ICIP.2014.7026014
   Smereka JM, 2013, IEEE COMPUT SOC CONF, P117, DOI 10.1109/CVPRW.2013.25
   Uzair M, 2015, NEUROCOMPUTING, V149, P854, DOI 10.1016/j.neucom.2014.07.049
   Vyas R, 2019, MULTIMED TOOLS APPL, V78, P5681, DOI 10.1007/s11042-018-5689-y
   Zhang Q, 2018, IEEE T INF FOREN SEC, V13, P2897, DOI 10.1109/TIFS.2018.2833033
   Zhao ZJ, 2018, IEEE T INF FOREN SEC, V13, P2937, DOI 10.1109/TIFS.2018.2833018
NR 36
TC 2
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9351
EP 9365
DI 10.1007/s11042-021-11846-4
EA JAN 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000743863400004
PM 35068991
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Wang, YQ
   Li, X
   Nan, FZ
   Liu, F
   Li, H
   Wang, HT
   Qian, YR
AF Wang, Yongqiang
   Li, Xue
   Nan, Fangzhe
   Liu, Feng
   Li, Hua
   Wang, Haitao
   Qian, Yurong
TI Image super-resolution reconstruction based on generative adversarial
   network model with feedback and attention mechanisms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution reconstruction; Generative adversarial network;
   Feedback mechanism; Channel attention; RaLSGAN
AB Despite the rapid development of single-image super-resolution (SISR) methods of generative adversarial networks (GAN), which can reconstruct visually realistic images, the problem of high discrepancy between the recovered details or textures and the ground truth persists. To address this issue, an SISR reconstruction GAN based on a feedback and attention mechanism (FBSRGAN) is proposed. Specifically, we select a network with a feedback mechanism as the generator, which can gradually create high-resolution images through the feedback connection. The attention mechanism is combined with the feedback block to adaptively select useful feature information and effectively process the feedback stream and enhance the image output quality. We use the relative average least squares GAN loss to reduce the instability of the optimization generator process to guide GAN to obtain more realistic results. The results show that compared with the ESRGAN method, when the amplification factor is 4, PSNR and SSIM of the proposed method increase by 0.386 and 0.0141, respectively, and PI decreases by 0.284, while the number of parameters is only 18.5% of that of ESRGAN, when tested on the Set5 dataset. Compared with existing GAN-based SR methods, FBSRGAN achieves superior performance in terms of both perceptual ability and image distortion.
C1 [Wang, Yongqiang] Xinjiang Univ, Sch Informat Sci Engn, Urumqi 830046, Peoples R China.
   [Li, Xue; Nan, Fangzhe; Liu, Feng; Li, Hua; Wang, Haitao; Qian, Yurong] Xinjiang Univ, Sch Software, Urumqi 830046, Peoples R China.
C3 Xinjiang University; Xinjiang University
RP Qian, YR (corresponding author), Xinjiang Univ, Sch Software, Urumqi 830046, Peoples R China.
EM 925968662@qq.com; qyr@xju.edu.cn
OI Wang, Yongqiang/0000-0002-0150-7917
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Blau Y, 2019, LECT NOTES COMPUT SC, V11133, P334, DOI 10.1007/978-3-030-11021-5_21
   Bulat A, 2018, LECT NOTES COMPUT SC, V11210, P187, DOI 10.1007/978-3-030-01231-1_12
   Cao CS, 2015, IEEE I CONF COMP VIS, P2956, DOI 10.1109/ICCV.2015.338
   Cheng Ma, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7766, DOI 10.1109/CVPR42600.2020.00779
   Dai SY, 2009, IEEE T IMAGE PROCESS, V18, P969, DOI 10.1109/TIP.2009.2012908
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Han W, 2018, PROC CVPR IEEE, P1654, DOI 10.1109/CVPR.2018.00178
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG JB, 2015, PROC CVPR IEEE, P5197, DOI DOI 10.1109/CVPR.2015.7299156
   Izonin I, 2015, 2015 10 INT SCI TECH
   Jolicoeur-Martineau A., 2018, The relativistic discriminator: A key element missing from standard GAN
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim SY, 2019, IEEE I CONF COMP VIS, P3116, DOI 10.1109/ICCV.2019.00321
   Lai QX, 2020, IEEE T IMAGE PROCESS, V29, P1113, DOI 10.1109/TIP.2019.2936112
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li Zhen, 2019, PROC CVPR IEEE, P3867, DOI [DOI 10.1109/CVPR.2019.00399, 10.1109/cvpr.2019.00399]
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Ma C, 2020, PROC CVPR IEEE, P5568, DOI 10.1109/CVPR42600.2020.00561
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Nan FZ, 2020, MULTIMED TOOLS APPL, V79, P34459, DOI 10.1007/s11042-020-09053-8
   Peleshko D, 2016, PROCEEDINGS OF THE 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON DATA STREAM MINING & PROCESSING (DSMP), P235, DOI 10.1109/DSMP.2016.7583548
   Rashkevych Y, 2017, 2017 IEEE FIRST UKRAINE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (UKRCON), P944, DOI 10.1109/UKRCON.2017.8100390
   Sajjadi Mehdi S. M., 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P4501, DOI 10.1109/ICCV.2017.481
   Shen JB, 2020, IEEE T CYBERNETICS, V50, P3068, DOI 10.1109/TCYB.2019.2936503
   Soh JW, 2019, PROC CVPR IEEE, P8114, DOI 10.1109/CVPR.2019.00831
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yao XX, 2019, IMAGE VISION COMPUT, V82, P39, DOI 10.1016/j.imavis.2019.02.002
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
NR 39
TC 7
Z9 9
U1 2
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6633
EP 6652
DI 10.1007/s11042-021-11679-1
EA JAN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000742803700003
DA 2024-07-18
ER

PT J
AU Clavero, JG
   Rico, FM
   Rodríguez-Lera, FJ
   Hernandéz, JMG
   Olivera, VM
AF Gines Clavero, Jonatan
   Martin Rico, Francisco
   Rodriguez-Lera, Francisco J.
   Guerrero Hernandez, Jose Miguel
   Matellan Olivera, Vicente
TI Impact of decision-making system in social navigation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social robot; Social navigation; Proxemic; Human-aware navigation;
   Cognitive architecture
AB Facing human activity-aware navigation with a cognitive architecture raises several difficulties integrating the components and orchestrating behaviors and skills to perform social tasks. In a real-world scenario, the navigation system should not only consider individuals like obstacles. It is necessary to offer particular and dynamic people representation to enhance the HRI experience. The robot's behaviors must be modified by humans, directly or indirectly. In this paper, we integrate our human representation framework in a cognitive architecture to allow that people who interact with the robot could modify its behavior, not only with the interaction but also with their culture or the social context. The human representation framework represents and distributes the proxemic zones' information in a standard way, through a cost map. We have evaluated the influence of the decision-making system in human-aware navigation and how a local planner may be decisive in this navigation. The material developed during this research can be found in a public repository (https://github.com/IntelligentRoboticsLabs/social_navigation2_WAF) and instructions to facilitate the reproducibility of the results.
C1 [Gines Clavero, Jonatan] Rey Juan Carlos Univ, Escuela Internac Doctorado, Mostoles, Spain.
   [Martin Rico, Francisco; Guerrero Hernandez, Jose Miguel] Rey Juan Carlos Univ, Intelligent Robot Lab, Fuenlabrada, Spain.
   [Rodriguez-Lera, Francisco J.] Univ Leon, Escuela Ingenierias Ind Informeat, Leon, Spain.
   [Matellan Olivera, Vicente] SCAYLE, Supercomputac Castilla Leon, Leon, Spain.
C3 Universidad Rey Juan Carlos; Universidad Rey Juan Carlos; Universidad de
   Leon
RP Clavero, JG (corresponding author), Rey Juan Carlos Univ, Escuela Internac Doctorado, Mostoles, Spain.
EM j.gines@alumnos.urjc.es
RI Rico, Francisco Martín/G-2516-2016; Matellan, Vicente/L-4309-2014;
   Guerrero Hernandez, Jose Miguel/U-3621-2017
OI Rico, Francisco Martín/0000-0003-3121-5744; Gines Clavero,
   Jonatan/0000-0002-7319-098X; Matellan, Vicente/0000-0001-7844-9658;
   Guerrero Hernandez, Jose Miguel/0000-0003-2521-514X
FU Rey Juan Carlos University [C1PREDOC2020]
FX This work has been partially funded by Rey Juan Carlos University
   through grant C1PREDOC2020.
CR Abiyev RH, 2016, PROCEDIA COMPUT SCI, V102, P477, DOI 10.1016/j.procs.2016.09.430
   Abiyev RH, 2014, INT J ROBOT AUTOM, V29, P44, DOI 10.2316/Journal.206.2014.1.206-3788
   Bera A, 2017, IEEE INT C INT ROBOT, P7018, DOI 10.1109/IROS.2017.8206628
   Billy Okal, 2016, PEDSIM ROS
   Breazeal C., 2004, Designing sociable robots
   Butler JT, 2001, AUTON ROBOT, V10, P185, DOI 10.1023/A:1008986004181
   Canal G, 2019, PROBABILISTIC PLANNI
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Cashmore M, 2015, P I C AUTOMAT PLAN S, P333
   Clavero Jonatan Gines, 2020, WORKSH PHYS AG, P3
   Coles A, 2010, FORWARD CHAINING PAR
   Coles A.J., 2010, P 20 INT C AUT PLANN, P42
   Colledanchise M., 2018, BEHAV TREES ROBOTICS, DOI DOI 10.1201/9780429489105
   Costelha Hugo, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P1449, DOI 10.1109/IROS.2007.4399365
   Cunningham AG., 2019, MPDM MULTIPOLICY DEC, P201
   Fernandez Coleto N, 2019, SOCIALLY ACCEPTABLE
   Foukarakis Michalis, 2014, Universal Access in Human-Computer Interaction. Aging and Assistive Environments. 8th International Conference, UAHCI 2014, Held as Part of HCI International 2014. Proceedings: LNCS 8515, P625, DOI 10.1007/978-3-319-07446-7_60
   Fox D, 1997, IEEE ROBOT AUTOM MAG, V4, P23, DOI 10.1109/100.580977
   Fox M, 2003, J ARTIF INTELL RES, V20, P61, DOI 10.1613/jair.1129
   Ginés J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235189
   Gloor C., 2016, Pedsim: Pedestrian crowd simulation
   Hall Edward Twitchell, 1910, The hidden dimension, V609
   HENDLER J, 1990, AI MAG, V11, P61
   Kirby Rachel, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P607, DOI 10.1109/ROMAN.2009.5326271
   Kirby R., 2010, Social robot navigation
   Kostavelis I, 2017, ROBOTS WORKSPACE ENH
   Kotseruba I, 2020, ARTIF INTELL REV, V53, P17, DOI 10.1007/s10462-018-9646-y
   Kruse T., 2013, Human-aware robot navigation: A survey
   Kwok C., 1998, Pddl-the planning domain definition language
   Lu DV, 2014, IEEE INT C INT ROBOT, P709, DOI 10.1109/IROS.2014.6942636
   Lu DV, 2013, IEEE INT C INT ROBOT, P1707, DOI 10.1109/IROS.2013.6696579
   Macenski S, 2020, IEEE INT C INT ROBOT, P2718, DOI 10.1109/IROS45743.2020.9341207
   Mead, 2015, AISB CONV 2015
   Mirnig N, 2015, IMPACT ROBOT ACTIONS
   Okal B, 2016, IEEE INT CONF ROBOT, P2889, DOI 10.1109/ICRA.2016.7487452
   Pacchierotti E., 2006, ROMAN 2006, P315, DOI [10.1109/ROMAN.2006.314436, DOI 10.1109/ROMAN.2006.314436]
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604
   Raguraman SM, 2009, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION, COMMUNICATION AND ENERGY CONSERVATION INCACEC 2009 VOL 1, P236
   Rico, 2019, ROS2 PLANNING SYSTEM
   Rosmann C., 2012, P ROBOTIK 2012 7 GER, P1
   Vega A, 2019, PATTERN RECOGN LETT, V118, P72, DOI 10.1016/j.patrec.2018.07.015
   Vega-Magro A, 2018, I C CONT AUTOMAT ROB, P1727, DOI 10.1109/ICARCV.2018.8581304
NR 42
TC 0
Z9 0
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3459
EP 3481
DI 10.1007/s11042-021-11454-2
EA JAN 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000742319000011
PM 35043045
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Jain, A
   Rao, ACS
   Jain, PK
   Abraham, A
AF Jain, Arushi
   Rao, Annavarapu Chandra Sekhara
   Jain, Praphula Kumar
   Abraham, Ajith
TI Multi-type skin diseases classification using OP-DNN based feature
   extraction approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-type skin diseases prediction; Optimal probability-based deep
   neural network; Whale optimization algorithm (WOA)
ID LESIONS; SEGMENTATION; IMAGES
AB In the current world, the disorders occurring in dermatological images are among the foremost widespread diseases. Despite being common, its identification is tremendously hard because of the complexities like skin tone and color variation due to the presence of hair regions. Therefore the type of skin disease prediction is not accurately achieved in many pieces of research. To deal with mentioned concerns, a novel optimal probability-based deep neural network is proposed to assist medical professionals in appropriately diagnosing the type of skin disease. Initially, the input dataset is fed into the pre-processing stage, which helps to remove unwanted contents in the image. Afterward, features extracted for all the pre-processed images are subjected to the proposed Optimal Probability-Based Deep Neural Network (OP-DNN) for the training process. This classification algorithm classifies incoming clinical images as different skin diseases with the help of probability values. While learning OP-DNN, it is essential to determine the optimal weight values for reducing the training error. For optimizing weight in OP-DNN structure, an optimization approach is implemented in this research. For that, whale optimization is utilized because it works faster than other methods. The proposed multi-type skin disease prediction model is implemented in MatLab software and achieved 95% of accuracy, 0.97 of specificity, and 0.91 of sensitivity. This exposes the superiority of the proposed multi-type skin disease prediction model using an effective OP-DNN based feature extraction approach to attain a high accuracy rate and also it predict several kinds of skin disease than the previous models, which can protect the patients survives as well as can assist the physicians in making a decision certainly.
C1 [Jain, Arushi; Rao, Annavarapu Chandra Sekhara; Jain, Praphula Kumar] Indian Inst Technol, Dept Comp Sci & Engn, Indian Sch Mines, Dhanbad 826004, JH, India.
   [Abraham, Ajith] Machine Intelligence Res Labs MIR Labs, Auburn, WA 98071 USA.
   [Abraham, Ajith] Innopolis Univ, Ctr Artificial Intelligence, Innopolis, Russia.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad; Innopolis University
RP Jain, PK (corresponding author), Indian Inst Technol, Dept Comp Sci & Engn, Indian Sch Mines, Dhanbad 826004, JH, India.
EM Praphulajn1@gmail.com
RI Abraham, Ajith/A-1416-2008; JAIN, PRAPHULA KUMAR/AAG-7979-2019
OI Abraham, Ajith/0000-0002-0169-6738; JAIN, PRAPHULA
   KUMAR/0000-0001-7651-4444
CR Bacanin N, 2021, J REAL-TIME IMAGE PR, V18, P1085, DOI 10.1007/s11554-021-01106-x
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Bastanfard A, 2006, GRAPP 2006: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P313
   Chen K, 2021, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.1061/(ASCE)EY.1943-7897.0000804
   Elgamal M, 2013, INT J ADV COMPUT SC, V4, P287
   Fan XY, 2020, TSINGHUA SCI TECHNOL, V25, P425, DOI 10.26599/TST.2019.9010029
   Gerhana YA, 2018, IOP CONF SER-MAT SCI, V288, DOI 10.1088/1757-899X/288/1/012153
   Hameed N, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112961
   Jain PK, 2021, COMPUT SCI REV, V41, DOI 10.1016/j.cosrev.2021.100413
   Khan MQ, 2019, IEEE ACCESS, V7, P90132, DOI 10.1109/ACCESS.2019.2926837
   Kharazmi P, 2017, IEEE J BIOMED HEALTH, V21, P1675, DOI 10.1109/JBHI.2016.2637342
   Liu Y, 2020, NAT MED, V26, P900, DOI 10.1038/s41591-020-0842-3
   Modhej N, 2020, IEEE ACCESS, V8, P212803, DOI 10.1109/ACCESS.2020.3040298
   Premaladha J, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0460-2
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Rostami M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-020-00398-3
   Rostami M, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00352-3
   Sumithra R, 2015, PROCEDIA COMPUT SCI, V45, P76, DOI 10.1016/j.procs.2015.03.090
   Tan TY, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105725
   Wu Z, 2019, IEEE ACCESS, V7, P66505, DOI 10.1109/ACCESS.2019.2918221
   Zhang GK, 2019, IEEE ACCESS, V7, P140936, DOI 10.1109/ACCESS.2019.2943628
   Zhang N, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101756
   Zhang XY, 2018, BMC MED INFORM DECIS, V18, DOI 10.1186/s12911-018-0631-9
   Zivkovic M, 2021, SUSTAIN CITIES SOC, V66, DOI 10.1016/j.scs.2020.102669
NR 24
TC 7
Z9 7
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6451
EP 6476
DI 10.1007/s11042-021-11823-x
EA JAN 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000741311700001
PM 35035267
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Sutoyo, E
   Rifai, AP
   Risnumawan, A
   Saputra, M
AF Sutoyo, Edi
   Rifai, Achmad Pratama
   Risnumawan, Anhar
   Saputra, Muhardi
TI A comparison of text weighting schemes on sentiment analysis of
   government policies: a case study of replacement of national
   examinations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; Term weighting schemes; Logistic regression; Naive
   Bayes Classifier; K Nearest Neighbor; Support Vector Classifier; Random
   Forest Classifier; Extreme Gradient Boost
ID CLASSIFICATION; FREQUENCY
AB The National Examination (UN) is a system of evaluation of education standards for elementary and secondary schools conducted nationally and is also used to equalize the quality between education levels. The national examination aims to determine graduation, national education quality mapping, and also for selection to higher education levels. Over the years the UN has become a benchmark for the standardization of education in Indonesia, meaning that the UN is very much needed to find out the size of the quality of student education and the quality of teaching of a school. The government's policy regarding the plan to remove the UN system has received public attention. The removal of the UN is planned to be replaced with a competency assessment and character survey. In order to know the public's sentiments regarding this policy, research needs to be done, one of which is to analyze public sentiment through social media Twitter. In text mining tasks such as text classification and sentiment analysis, careful selection of a term weighting scheme (TWS) can have a significant impact on effectiveness. We tested the effectiveness of six classification algorithms by varying the TWS in the dataset obtained from Twitter. The experimental results showed that overall TF-IGM outperformed TF-IDF on four classification algorithms. Finally, the sentiment analysis of the discourse on the removal of the UN is expected to provide a general picture to the government regarding public opinion from the point of view of data coming from social media.
C1 [Sutoyo, Edi; Saputra, Muhardi] Telkom Univ, Dept Informat Syst, Bandung 40257, West Java, Indonesia.
   [Rifai, Achmad Pratama] Univ Gadjah Mada, Fac Engn, Dept Mech & Ind Engn, Yogyakarta 55281, Indonesia.
   [Risnumawan, Anhar] Politekn Elekt Negeri Surabaya, Mechatron Engn Div, Surabaya 60111, Indonesia.
C3 Telkom University; Gadjah Mada University; Electronic Engineering
   Polytechnic Institute of Surabaya
RP Sutoyo, E (corresponding author), Telkom Univ, Dept Informat Syst, Bandung 40257, West Java, Indonesia.
EM edisutoyo@telkomuniversity.ac.id; achmad.p.rifai@ugm.ac.id;
   anhar@pens.ac.id; muhardi@telkomuniversity.ac.id
RI Risnumawan, Anhar/GQZ-7674-2022; Saputra, Muhardi/AAD-1000-2021;
   Risnumawan, Anhar/GRJ-1061-2022
OI Saputra, Muhardi/0000-0002-7989-4806; 
CR Al Amrani Y., 2018, International Journal of Electrical & Computer Engineering, V8, P4554
   Ali F, 2015, APPL INTELL, V42, P481, DOI 10.1007/s10489-014-0609-y
   Aninditya A, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS AND INTELLIGENCE SYSTEM (IOTAIS), P112, DOI [10.1109/iotais47347.2019.8980428, 10.1109/IoTaIS47347.2019.8980428]
   [Anonymous], 2006, Proceedings of the Workshop on Sentiment and Subjectivity in Text, SST'06, DOI DOI 10.3115/1654641.1654642
   Baeza-Yates R., 1999, Modern information retrieval
   Bhargava K, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING AND COMMUNICATION TECHNOLOGIES FOR SMART NATION (IC3TSN), P332, DOI 10.1109/IC3TSN.2017.8284501
   Biau G, 2016, TEST-SPAIN, V25, P197, DOI 10.1007/s11749-016-0481-7
   Bourequat W., 2021, International Journal of Advances in Data and Information Systems, V2, P36, DOI DOI 10.25008/IJADIS.V2I1.1216
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen KW, 2016, EXPERT SYST APPL, V66, P245, DOI 10.1016/j.eswa.2016.09.009
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Deng XY, 2016, INFORM SCIENCES, V340, P250, DOI 10.1016/j.ins.2016.01.033
   Domeniconi Giacomo, 2015, INT C DATA MANAGEMEN, P39
   El Rahman SA, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P336, DOI 10.1109/iccisci.2019.8716464
   Farooq U, 2017, J COMPUT, V12, P470, DOI 10.17706/jcp.12.5.470-478
   Fauzi M. A., 2019, Int. J. Electr. Comput. Eng., V9, P525, DOI DOI 10.11591/IJECE.V9I1.PP525-530
   Garcia S, 2015, INTEL SYST REF LIBR, V72, P1, DOI 10.1007/978-3-319-10247-4
   García-Díaz V, 2018, APPL SOFT COMPUT, V67, P822, DOI 10.1016/j.asoc.2017.05.038
   Gonen M., 2007, Analyzing Receiver Operating Characteristic Curves with SAS
   Han J, 2012, MOR KAUF D, P1
   Hastie T., 2009, Random forests, P587, DOI [DOI 10.1007/978-0-387-84858-7_15, DOI 10.1007/978-0-387-84858-715]
   Herawan, 2017, TELKOMNIKA TELECOMMU, V15, DOI [10.12928/TELKOMNIKA.v15i3.6382, DOI 10.12928/TELKOMNIKA.V15I3.6382]
   Hossin M., 2015, INT J DATA MIN KNOWL, V5, P1, DOI DOI 10.5121/IJDKP.2015.5201
   Indonesia PR, 2003, UND UND REP IND NOM
   Khairani N.A., 2020, Int. J. Adv. Data Inf. Syst., P9, DOI [10.25008/ijadis.v1i1.13, DOI 10.25008/IJADIS.V1I1.13]
   Kibriya AM, 2004, LECT NOTES ARTIF INT, V3339, P488
   Kohavi R, 1996, P 2 INT C KNOWL DISC, P202, DOI DOI 10.1007/978-3-642-16530-6_42
   Liao YH, 2002, COMPUT SECUR, V21, P439, DOI 10.1016/S0167-4048(02)00514-X
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   LOVINS JB, 1968, MECH TRANSL, V11, P22
   Manning C.D., 1999, FDN STAT NATURAL LAN
   Mustafa RU, 2017, MALAYS J COMPUT SCI, V30, P63
   Novendri R., 2020, B COMPUTER SCI ELECT, V1, P26, DOI [10.25008/bcsee.v1i1.5, DOI 10.25008/BCSEE.V1I1.5]
   Patodkar V.N., 2017, COMPUTER, V5, P320, DOI [DOI 10.1371/JOURNAL.PONE.0026624, 10.17148/ijarcce.2016.51274, DOI 10.17148/IJARCCE.2016.51274]
   Rameshbhai C Jashubhai, 2019, Int. J. Electr. Comput. Eng. (IJECE), V9, P2152, DOI DOI 10.11591/IJECE.V9I3
   Rezaeian G.Novikova, 2020, INDONESIAN J ELECT E, V8, P178
   Rizzo Irfan M., 2018, International Journal of Electrical and Computer Engineering (IJECE), V8, P5409
   Robertson S, 2004, J DOC, V60, P503, DOI 10.1108/00220410410560582
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Shahzad B, 2017, INF DISCOV DELIV, V45, P130, DOI 10.1108/IDD-03-2017-0023
   Stehman SV, 1997, REMOTE SENS ENVIRON, V62, P77, DOI 10.1016/S0034-4257(97)00083-7
   Sutoyo Edi, 2019, International Conference on Data Engineering 2015 (DaEng-2015). Proceedings: Lecture Notes in Electrical Engineering (LNEE 520), P307, DOI 10.1007/978-981-13-1799-6_32
   Sutoyo E., 2020, Bulletin of Electrical Engineering and Informatics, V9, P1620, DOI [10.11591/eei.v9i4.2352, DOI 10.11591/EEI.V9I4.2352]
   Turney PD, 2010, J ARTIF INTELL RES, V37, P141, DOI 10.1613/jair.2934
NR 45
TC 3
Z9 3
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6413
EP 6431
DI 10.1007/s11042-022-11900-9
EA JAN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000741865300001
DA 2024-07-18
ER

PT J
AU Singla, N
   Kaur, M
   Sofat, S
AF Singla, Nancy
   Kaur, Manvjeet
   Sofat, Sanjeev
TI Hybrid framework for identifying partial latent fingerprints using
   minutiae points and pores
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fingerprints; Biometrics; Forensics; Identification; Latent
AB Latent fingerprints play a pivotal role in the forensics for the investigation of the crimes. Mostly, latent fingerprints found at the crime scene are partial prints. Thus, fingerprint features required for identifying the latent fingerprint is not always available. Approaches for reconstructing the partial latent fingerprints to fill the missing area is highly probabilistic. As a result, numerous false features may be extracted during feature extraction, which can affect the identification accuracy. Thus, the paper aims to propose a hybrid framework for identifying partial latent fingerprints using minutiae points (level 2) and pores (level 3), which could increase the identification accuracy. Results are evaluated on the CSRC Latent Fingerprint Touch-less Database created using Reflected Ultra Violet Imaging System (RUVIS), which shows improvement in the Rank-k identification accuracy when similarity scores of both minutiae and pores are combined. Moreover, an analysis of the identification accuracy for the number of minutiae points available in the partial latent fingerprints shows that pores could help in identifying partial latent fingerprints that have less than 5 minutiae points.
C1 [Singla, Nancy; Kaur, Manvjeet] Punjab Engn Coll Deemed Univ, Cyber Secur Res Ctr, Chandigarh 160012, India.
   [Sofat, Sanjeev] Punjab Engn Coll Deemed Univ, Dept Comp Sci & Engn, Chandigarh 160012, India.
C3 Punjab Engineering College (Deemed University); Punjab Engineering
   College (Deemed University)
RP Singla, N (corresponding author), Punjab Engn Coll Deemed Univ, Cyber Secur Res Ctr, Chandigarh 160012, India.
EM ernancysingla17@gmail.com
OI Singla, Nancy/0000-0002-2920-2170
CR [Anonymous], INT PATT REC BIOM LA
   Anthonioz A., 2008, J. Forensic Ident, V58, P562
   Cao K, 2019, IEEE T PATTERN ANAL, V41, P788, DOI 10.1109/TPAMI.2018.2818162
   Castillo-Rosado K, 2019, INFORMATICA-LITHUAN, V30, P431, DOI 10.15388/Informatica.2019.213
   Dabouei A, 2018, IEEE 9 INT C BIOMETR
   Dahia G, 2018, ARXIV PREPRINT ARXIV
   de Assis Angeloni M, 2013, P 7 INT C DIG SOC NI, DOI [10.13140/2.1.4157.9524, DOI 10.13140/2.1.4157.9524]
   Deshpande UU, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00113
   Feng JJ, 2013, IEEE T PATTERN ANAL, V35, P925, DOI 10.1109/TPAMI.2012.155
   Feng JJ, 2011, IEEE T PATTERN ANAL, V33, P209, DOI 10.1109/TPAMI.2010.77
   Feng JJ, 2009, LECT NOTES COMPUT SC, V5558, P695, DOI 10.1007/978-3-642-01793-3_71
   Garris M.D., 2000, NIST SPECIAL DATABAS
   Indovina M, 2010, ELFT EFS NIST EVALUA
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Jain Anil K., 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563117
   Jain AK, 2007, IEEE T PATTERN ANAL, V29, P15, DOI 10.1109/TPAMI.2007.250596
   Kumar S, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1238, DOI 10.1109/ICACCI.2015.7275782
   Lei Z, 2009, HONG KONG POLYTECHNI
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Loyola-González O, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11094187
   Maltoni D., 2009, HDB FINGERPRINT RECO, DOI 10.1007/978-1-84882-254-2
   Neuroshield, GEN VIS
   Nguyen DL, 2019, END TO END PORE EXTR, P1
   Pamplona Segundo Mauricio, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P128, DOI 10.1109/CVPRW.2015.7301328
   Paulino A. A., 2010, Proceedings of the 23rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI 2010), P63, DOI 10.1109/SIBGRAPI.2010.17
   Paulino AA, 2013, IEEE T INF FOREN SEC, V8, P31, DOI 10.1109/TIFS.2012.2223678
   Rahman Md Tajmilur, 2007, 2007 10th International Conference on Computer and Information Technology (ICCIT 2007), P1, DOI 10.1109/ICCITECHN.2007.4579398
   Sankaran A., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P377, DOI 10.1109/BTAS.2012.6374604
   Sankaran A., 2011, Biometrics (IJCB), 2011 International Joint Conference On, P1, DOI [10.1109/IJCB.2011.6117525, DOI 10.1109/IJCB.2011.6117525]
   Singla N, 2020, PROCEDIA COMPUT SCI, V167, P942, DOI 10.1016/j.procs.2020.03.393
   Singla N, 2020, FORENSIC SCI INT, V309, DOI 10.1016/j.forsciint.2020.110187
   Svoboda J, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P429, DOI 10.1109/BTAS.2017.8272727
   Wyzykowski ABV, 2020, ARXIV PREPRINT ARXIV
   Yamashita B, 2010, LATENT PRINT DEV FIN, P1
   Yang X, 2014, IEEE T PATTERN ANAL, V36, P955, DOI 10.1109/TPAMI.2013.184
   Yusof RM, 2012, INT CONF INTERNET, P564
   Zanganeh O, 2014, 2014 INT C DIG IM CO, P1, DOI DOI 10.1109/DICTA.2014.7008121
   Zhao Q, 2010, LATENT FINGERPRINT M
   Zhao QJ, 2009, LECT NOTES COMPUT SC, V5558, P597, DOI 10.1007/978-3-642-01793-3_61
   Zheng FD, 2015, INT CONF BIOMETR, P357, DOI 10.1109/ICB.2015.7139061
NR 40
TC 2
Z9 2
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19525
EP 19542
DI 10.1007/s11042-021-11541-4
EA JAN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000739790800009
DA 2024-07-18
ER

PT J
AU Phatnani, KS
   Patil, HA
AF Phatnani, Kirtana Sunil
   Patil, Hemant A.
TI Music footprint recognition via sentiment, identity, and setting
   identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotional contagion; Emotional influence on choice; Music emotion
   recognition; Sentiment analysis
ID EMOTIONAL CONTAGION; EXPERIENCE; RESPONSES; SYSTEM
AB Emotional contagion is said to occur when an origin (i.e., any sensory stimuli) emanating emotions causes the observer to feel the same emotions. In this paper, we explore the identification and quantification of emotional contagion produced by music in human beings. We survey 50 subjects who answer: what type of music they hear when they are happy, excited, sad, angry, and affectionate. In the analysis of the distribution, we observe that predominantly the emotional state of the subjects does influence the choice of tempo of the musical piece. We define the footprint in three dimensions, namely, sentiment, time, and identification. We unpack each song by unraveling sentiment analysis in time, using lexicons and tenses, along with the identity via pronouns used. In this study, we wish to quantify and visualize the emotional journey of the listener through music. The results of this can be extended to the elicitation of emotional contagion within any story, poem, and conversations.
C1 [Phatnani, Kirtana Sunil] Fractal Analyt, Mumbai 400063, Maharashtra, India.
   [Patil, Hemant A.] DA IICT, Speech Res Lab, Gandhinagar 382007, Gujarat, India.
C3 Dhirubhai Ambani Institute of Information & Communication Technology
RP Phatnani, KS (corresponding author), Fractal Analyt, Mumbai 400063, Maharashtra, India.
EM kirtana.phatnani@fractal.ai; hemant_patil@daiict.ac.in
OI Sunil Phatnani, Kirtana/0000-0001-9988-1167
CR [Anonymous], 2001, B WORLD HEALTH ORGAN, V79, P373, DOI 10.1001/jama.2013.281053
   [Anonymous], 2010, 11 INT SOC MUS INF R
   [Anonymous], 2006, ENCY COGNITIVE SCI
   Asghar MZ, 2021, SOFTWARE PRACT EXPER, V51, P571, DOI 10.1002/spe.2853
   Ayata D, 2018, IEEE T CONSUM ELECTR, V64, P196, DOI 10.1109/TCE.2018.2844736
   AZLyrics, 2020, AZLYRICS SONG LYR A
   Barsade SG, 2002, ADMIN SCI QUART, V47, P644, DOI 10.2307/3094912
   Bharucha JJ, 2008, BEHAV BRAIN SCI, V31, P579, DOI 10.1017/S0140525X08005335
   Choi K, 2017, INT CONF ACOUST SPEE, P2392, DOI 10.1109/ICASSP.2017.7952585
   Doherty RW, 1997, J NONVERBAL BEHAV, V21, P131, DOI 10.1023/A:1024956003661
   Egermann H, 2013, MUSIC PERCEPT, V31, P139, DOI 10.1525/MP.2013.31.2.139
   Garrido S, 2020, MUSIC SCI, V24, P155, DOI 10.1177/1029864918783027
   Geangu E, 2011, SOC DEV, V20, P450, DOI 10.1111/j.1467-9507.2010.00596.x
   Han B.-j., 2009, ISMIR, P651
   Hatfield E, 2011, SOC NEUROSCI EMPATHY, V19
   Hatfield E., 1993, CURR DIR PSYCHOL SCI, V2, P96, DOI [DOI 10.1111/1467-8721.EP10770953, 10.1111/1467-8721.ep10770953]
   Hatfield E, 1992, Review of Personality and Social Psychology, V14, P151
   Hung-Chen Chen, 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P231, DOI 10.1145/502585.502625
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI [DOI 10.1609/ICWSM.V8I1.14550, 10.1609/icwsm.v8i1.14550]
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Kang D, 2019, MULTIMED TOOLS APPL, V78, P3267, DOI 10.1007/s11042-018-6733-7
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Lundqvist LO, 2009, PSYCHOL MUSIC, V37, P61, DOI 10.1177/0305735607086048
   Mandel M., 2005, ISMIR 2005, P594
   Manzelli Rachel., 2018, Proceedings of the 19th International Society for Music Information Retrieval Conference (Paris, France), P182, DOI DOI 10.5281/ZENODO.1492375
   Meng A, 2007, IEEE T AUDIO SPEECH, V15, P1654, DOI 10.1109/TASL.2007.899293
   Meyers OC, 2007, THESIS MIT US
   Nummenmaa L, 2008, NEUROIMAGE, V43, P571, DOI 10.1016/j.neuroimage.2008.08.014
   Patel K, 2020, IEEE ACCESS, V8, P90495, DOI 10.1109/ACCESS.2020.2993803
   Phatnani KS, 2020, ACOUSTIC ANAL PATHOL, V7, P199
   Pugh SD, 2001, ACAD MANAGE J, V44, P1018, DOI 10.5465/3069445
   Rajpura DG, 2020, 2020 INT C SIGN PROC, P1
   Rosenbusch H, 2019, SOC PSYCHOL PERS SCI, V10, P1028, DOI 10.1177/1948550618820309
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Seo YS, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8020164
   Tamietto M, 2009, P NATL ACAD SCI USA, V106, P17661, DOI 10.1073/pnas.0908994106
   Tamietto M, 2008, IEEE INT CONF AUTOMA, P1031
   Turino T, 1999, ETHNOMUSICOLOGY, V43, P221, DOI 10.2307/852734
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Wendell Hicken, 2004, US Patent App, Patent No. [10/917,865, 10917865]
   Williams D, 2019, 2019 AES INTERNATIONAL CONFERENCE ON IMMERSIVE AND INTERACTIVE AUDIO
   Yang YH, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168754
   Yang YH, 2011, IEEE T AUDIO SPEECH, V19, P762, DOI 10.1109/TASL.2010.2064164
   Yuksel A. C., 2011, 2011 International Symposium on Innovations in Intelligent Systems and Applications (INISTA 2011), P354, DOI 10.1109/INISTA.2011.5946091
NR 44
TC 2
Z9 2
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22247
EP 22262
DI 10.1007/s11042-021-11430-w
EA JAN 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000737106100002
DA 2024-07-18
ER

PT J
AU Zahra, A
   Ghafoor, M
   Munir, K
   Ullah, A
   Ul Abideen, Z
AF Zahra, Asma
   Ghafoor, Mubeen
   Munir, Kamran
   Ullah, Ata
   Ul Abideen, Zain
TI Application of region-based video surveillance in smart cities using
   deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Video surveillance; Surveillance cameras; Smart cities
   and towns; Smart city applications
ID CODING HEVC; SEGMENTATION; COMPRESSION
AB Smart video surveillance helps to build more robust smart city environment. The varied angle cameras act as smart sensors and collect visual data from smart city environment and transmit it for further visual analysis. The transmitted visual data is required to be in high quality for efficient analysis which is a challenging task while transmitting videos on low capacity bandwidth communication channels. In latest smart surveillance cameras, high quality of video transmission is maintained through various video encoding techniques such as high efficiency video coding. However, these video coding techniques still provide limited capabilities and the demand of high-quality based encoding for salient regions such as pedestrians, vehicles, cyclist/motorcyclist and road in video surveillance systems is still not met. This work is a contribution towards building an efficient salient region-based surveillance framework for smart cities. The proposed framework integrates a deep learning-based video surveillance technique that extracts salient regions from a video frame without information loss, and then encodes it in reduced size. We have applied this approach in diverse case studies environments of smart city to test the applicability of the framework. The successful result in terms of bitrate 56.92%, peak signal to noise ratio 5.35 bd and SR based segmentation accuracy of 92% and 96% for two different benchmark datasets is the outcome of proposed work. Consequently, the generation of less computational region-based video data makes it adaptable to improve surveillance solution in Smart Cities.
C1 [Zahra, Asma] COMSATS Univ Islamabad, Dept Comp Sci, Islamabad, Pakistan.
   [Ghafoor, Mubeen] Univ Lincoln, Sch Comp Sci, Lincoln, England.
   [Munir, Kamran] Univ West England UWE, Dept Comp Sci & Creat Technol CSCT, Bristol, Avon, England.
   [Zahra, Asma; Ullah, Ata; Ul Abideen, Zain] Natl Univ Modern Languages, Dept Comp Sci, Islamabad, Pakistan.
C3 COMSATS University Islamabad (CUI); University of Lincoln
RP Ghafoor, M (corresponding author), Univ Lincoln, Sch Comp Sci, Lincoln, England.
EM asmazahra3434@gmail.com; mghafoor@lincoln.ac.uk;
   kamran2.munir@uwe.ac.uk; aullah@numl.edu.pk; znabideen@numl.edu.pk
RI Abideen, Zain Ul/H-2006-2017; Ullah, Ata/ABE-6416-2022
OI Abideen, Zain Ul/0000-0002-8941-3615; 
CR [Anonymous], 2018, STUPID DRIVER TRIES
   Azimi M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102778
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Bjontegaard G., 2001, CALCULATION AVERAGE
   BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   Bossen F., 2013, document JCTVC-L1100,, V12
   Calvenn Tsuu, 2017, BUILDING SELF DRIVIN
   Chen CW, 1998, IEEE T IMAGE PROCESS, V7, P1673, DOI 10.1109/83.730379
   Choksi M, 2018, P SAI INT SYST C, P189
   Crazy Rage World, 2018, CRAZ PED ANGR DRIV R
   Dewangan DK, 2021, INTEL SERV ROBOT, V14, P199, DOI 10.1007/s11370-020-00343-6
   Du R, 2019, IEEE COMMUN SURV TUT, V21, P1533, DOI 10.1109/COMST.2018.2881008
   Ester M., 1996, INT C KNOWLEDGE DISC
   Ghosal Attri, 2020, Emerging Technology in Modelling and Graphics. Proceedings of IEM Graph 2018. Advances in Intelligent Systems and Computing (AISC 937), P69, DOI 10.1007/978-981-13-7403-6_9
   Guerrero-Ibañez J, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4169
   Guo J, 2017, IEEE COMMUN SURV TUT, V19, P2662, DOI 10.1109/COMST.2017.2705027
   Hussain AJ, 2018, NEUROCOMPUTING, V300, P44, DOI 10.1016/j.neucom.2018.02.094
   Hwang S, 2016, INT CONF UBIQ ROBOT, P234, DOI 10.1109/URAI.2016.7625744
   Imtiaz, 2016, PEDESTRIAN WALKING H
   Iqbal K, 2018, INT J ADV COMPUT SC, V9, P94
   Kim BG, 2017, J SUPERCOMPUT, V73, P1063, DOI 10.1007/s11227-016-1730-y
   Koziri M, 2017, SOC NETW ANAL MIN, V7, DOI 10.1007/s13278-017-0450-5
   KrazieHeart Blablabla, 2017, CCTV FOOTAGE UNBELIE
   Kumar S, 2018, J PARALLEL DISTR COM, V118, P344, DOI 10.1016/j.jpdc.2017.03.002
   Lateef F, 2019, NEUROCOMPUTING, V338, P321, DOI 10.1016/j.neucom.2019.02.003
   Latif S., 2018, INT C COMP MATH ENG, P1, DOI DOI 10.1109/ICOMET.2018.8346327
   Li SX, 2015, SIGNAL PROCESS-IMAGE, V38, P127, DOI 10.1016/j.image.2015.04.011
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Morkhandikar, 2020, J ADV RES DYN CONTRO, DOI [10.5373/JARDCS/V12SP5/20201732, DOI 10.5373/JARDCS/V12SP5/20201732]
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Nojavanasghari B, 2017, INT CONF AFFECT, P209, DOI 10.1109/ACII.2017.8273602
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sánchez-Corcuera R, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719853984
   Santos, 2017, WEBMEDIA 2017, P409
   Shen Yan-Fei, 2013, Chinese Journal of Computers, V36, P2340, DOI 10.3724/SP.J.1016.2013.02340
   Song H, 2015, INT J REMOTE SENS, V36, P2816, DOI 10.1080/01431161.2015.1043759
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun XB, 2019, IEEE ACCESS, V7, P56308, DOI 10.1109/ACCESS.2019.2910245
   Sushma B, 2021, 2021 SIXTH INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P340, DOI [10.1109/WISPNET51692.2021.9419473, 10.1109/WiSPNET51692.2021.9419473]
   Sze V, 2012, IEEE T CIRC SYST VID, V22, P1778, DOI 10.1109/TCSVT.2012.2221526
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang M, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.3.033009
   Xiao J, 2017, SOFTWARE PRACT EXPER, V47, P1061, DOI 10.1002/spe.2430
NR 47
TC 7
Z9 7
U1 6
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 15313
EP 15338
DI 10.1007/s11042-021-11468-w
EA DEC 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000734718100002
PM 34975282
OA Green Accepted, Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Siddan, G
   Palraj, P
AF Siddan, Gopinath
   Palraj, Pradeepa
TI Foetal neurodegenerative disease classification using improved deep
   ResNet classification based VGG-19 feature extraction network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neurodegenerative disease; Foetal MRI brain; Classification; Feature
   extraction; VGG-19; Deep ResNet
ID DIAGNOSIS
AB Neurodegenerative disease defined about death of some brain parts. This disease is the dangerous disease to cure with devastating results. In addition to the elderly, the neurodegenerative disease threatening the pregnant women since it affects the foetus. The existing studies related with neurodegenerative disease is very few. The diagnosis of the neurodegenerative disease occur in foetal during pregnancy is the major challenge in medical field. In this proposed study, the neurodegenerative disease for foetus are classified based on the novel VGG-19 feature extraction and improved deep ResNet classifier. This proposed concept follows feature extraction and transfer learning based classification. For effective feature extraction, the Visual Geometry Group -VGG-19 has been widely used and for better classification of the neurodegenerative disease in foetal MRI brain the proposed improved Deep Residual Network-ResNet classifier is implemented. ResNet allows the alternate shortcut path and reduces the vanishing gradient problem. If the current layer is not required, CNN weight layer is bypassed by ResNet identity mapping. The training set over fitting problem is thus avoided. The VGG-19 network major role is to increase the CNN depth with the help of 3 x 3 filter size. The proposed study are evaluated in terms of various performance metrics and several activation function compared with proposed swish activation function. The results shows that the proposed method resulted in better values compared with existing studies used the foetal brain images.
C1 [Siddan, Gopinath] Swarnandhra Inst Engn & Technol, Dept Elect & Commun Engn, Narasapur, Andhrapradhesh, India.
   [Palraj, Pradeepa] Jain Deemed Univ, Dept Elect & Elect Engn, Bangalore, Karnataka, India.
C3 Jain University
RP Siddan, G (corresponding author), Swarnandhra Inst Engn & Technol, Dept Elect & Commun Engn, Narasapur, Andhrapradhesh, India.
EM drgopinath2018@gmail.com
CR [Anonymous], 2017, INFORMATION, DOI [DOI 10.3390/info8030091, DOI 10.3390/INFO8030091]
   Attallah O, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10010027
   Attallah O, 2019, BRAIN SCI, V9, DOI 10.3390/brainsci9090231
   Benussi A, 2020, ANN NEUROL, V87, P394, DOI 10.1002/ana.25677
   Beyrami SMG, 2020, MEASUREMENT, V156, DOI 10.1016/j.measurement.2020.107579
   Dessai MA, 2019, AUTOMATIC CLASSIFICA
   Alvarez JD, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-3027-7
   Khater, 2020, APPL ARTIFICIAL INTE
   Lei BY, 2020, MED IMAGE ANAL, V61, DOI 10.1016/j.media.2019.101632
   McKay RD, 2004, PHILOS T R SOC B, V359, P851, DOI 10.1098/rstb.2004.1472
   Myszczynska MA, 2020, NAT REV NEUROL, V16, P440, DOI 10.1038/s41582-020-0377-8
   Nalivaeva NN, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00825
   Naseer A, 2020, NEURAL COMPUT APPL, V32, P839, DOI 10.1007/s00521-019-04069-0
   Pasupa K, WHITE BLOOD CELL CLA
   Patani R, 2012, J NEUROCHEM, V122, P738, DOI 10.1111/j.1471-4159.2012.07825.x
   Plisson F, 2019, MAR DRUGS, V17, DOI 10.3390/md17020081
   Segovia F, 2018, LOG J IGPL, V26, P618, DOI 10.1093/jigpal/jzy026
   Shah SAA, 2020, J PHARM RES INT, V32, P63, DOI 10.9734/JPRI/2020/v32i1130546
   Talo M, 2019, COMPUT MED IMAG GRAP, V78, DOI 10.1016/j.compmedimag.2019.101673
NR 19
TC 5
Z9 5
U1 1
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2393
EP 2408
DI 10.1007/s11042-021-11543-2
EA OCT 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000712480900001
DA 2024-07-18
ER

PT J
AU Ali, M
   Asghar, MZ
   Shah, M
   Mahmood, T
AF Ali, Mushtaq
   Asghar, Muhammad Zubair
   Shah, Mohsin
   Mahmood, Tauqeer
TI A simple and effective sub-image separation method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hough transform; Dynamic programming; Multi-panel image; Image retrieval
   system; Border identification
ID RETRIEVAL
AB Image retrieval system has numerous applications in different domains and generated promising results in each domain in case of single panel images. However, in addition to single panel images, the use of multi-panel images particularly in medical and research domains is increasing tremendously. The image retrieval system treats the multi-panel image as a single image and has no potential to get access to its sub-images, as a result the retrieval accuracy of image retrieval system is affected. The latest sub-image separation methods use edge image for locating the position of lines in the input multi-panel image. The edge image of the low contrast multi-panel image often contains broken lines. These broken lines in the edge image cause misdetection of line(s) in the input multi-panel image which in turn affect the accuracy of sub-image separation. Furthermore, their results are not satisfactory for large scale multi-panel images (i.e., multi-panel images having more than seven sub-images along one of its two sides) and multi-panel images having no solid border line(s). In this paper, an effective sub-image separation method for improving the accuracy of sub-image separation is proposed. The proposed method bridges the gaps in each line of the input image using Hough transform. Next, the positions of all lines (i.e., border lines and sub-image separators) in each image are determined and the true border lines among them are identified using a simple border identification model and detached. A fast sub-image separation method is then employed for separating the sub-images of multi-panel image using the true sub-image separators. We tested our proposed method on testing dataset containing 2225 images. The experimental results show that our proposed method outperforms the latest methods.
C1 [Ali, Mushtaq; Asghar, Muhammad Zubair; Shah, Mohsin; Mahmood, Tauqeer] Hazara Univ, Mansehra, Pakistan.
C3 Hazara University
RP Ali, M (corresponding author), Hazara Univ, Mansehra, Pakistan.
EM mushtaqyaqubi@hotmail.com
RI Asghar, Muhammad Zubair/M-6411-2015
OI Asghar, Muhammad Zubair/0000-0003-3320-2074
CR Akgül CB, 2011, J DIGIT IMAGING, V24, P208, DOI 10.1007/s10278-010-9290-9
   Ali M, 2021, MULTIMED TOOLS APPL, V80, P5449, DOI 10.1007/s11042-020-09950-y
   Ali M, 2018, MULTIMED TOOLS APPL, V77, P20271, DOI 10.1007/s11042-017-5453-8
   Apostolova E, 2013, J AM SOC INF SCI TEC, V64, P893, DOI 10.1002/asi.22810
   Bedrick, 2011, WORKING NOTES CLEF 2
   Bedrick S, 2008, QUERY ANAL IMPROVE M
   Cheng BB, 2011, PROC SPIE, V7874, DOI 10.1117/12.873685
   Clough P, 2003, IMAGECLEF LIFECLEFMU
   De Herrera A.G.S., 2013, CLEF Working Notes
   Demner-Fushman D., 2007, Workshop on Data Mining in Medicine. 7th IEEE Intl Conf on Data Mining, P139
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Eggel I, 2010, P 10 INT C CROSS LAN
   Firschein O, 1997, 4 INT WORKSH INT DIS
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Foncubierta A., 2013, SEPARATING COMPOUND, P1
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   Jhanwar N, 2004, IMAGE VISION COMPUT, V22, P1211, DOI 10.1016/j.imavis.2004.03.026
   Kalpathy-Cramer J, 2007, STUD HEALTH TECHNOL, V129, P1334
   Li J, 2004, IEEE T IMAGE PROCESS, V13, P338, DOI 10.1109/TIP.2003.821349
   Li J, 2008, P SPIE DOCUMENT RECO, VXV, P230
   Li PY, 2018, BIOINFORMATICS, V34, P1192, DOI 10.1093/bioinformatics/btx611
   Muller H., 2012, WORKING NOTES CLEF 2
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Rui Y, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P815, DOI 10.1109/ICIP.1997.638621
   Siggelkow, 2002, FEATURE HISTORGRAMS
   Sreedevi S, 2012, 2012 INTERNATIONAL CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P29, DOI 10.1109/MVIP.2012.6428753
   Steven S, 1992, C45 PROGRAMS MACHINE, P235
   Tagare HD, 1997, J AM MED INFORM ASSN, V4, P184, DOI 10.1136/jamia.1997.0040184
   Tudor CO, 2012, IEEE INT C BIOINF BI
   Zhang H, 1999, CONTENT BASED IMAGE
NR 31
TC 3
Z9 3
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 14893
EP 14910
DI 10.1007/s11042-021-11680-8
EA OCT 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000710918000001
DA 2024-07-18
ER

PT J
AU Kowdiki, M
   Khaparde, A
AF Kowdiki, Manisha
   Khaparde, Arti
TI Adaptive hough transform with optimized deep learning followed by
   dynamic time warping for hand gesture recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic and static hand gestures; Hand gesture recognition; Adaptive
   hough transform; Deep convolutional neural network; Electric fish-based
   whale optimization algorithm; Dynamic time warping
ID HUMAN-COMPUTER INTERACTION; FEATURES; MODEL
AB Hand gesture is a natural interaction method, and hand gesture recognition is familiar in human-computer interaction. Yet, the variations, as well as the complexity of hand gestures such as self-structural characteristics, views, and illuminations, made hand gesture recognition as a challenging task. Nowadays, the human-computer interaction area enhancement leads to putting interest in the dynamic hand gesture segmentation based on the gesture recognition system. Apart from the lengthy clinical success, dynamic hand gesture segmentation through webcam vision seems challenging due to the light effects, partial occlusion, and complicated environment. Hence, to segment the entire hand gesture region and enhance the segmentation accuracy, this paper develops an improved segmentation and deep learning-based strategy for dynamic hand gesture recognition. The data is gathered from the ISL benchmark dataset that consists of both static as well as dynamic images. The initial process of the proposed model is the pre-processing, which is being performed by grey scale conversion and histogram equalization. Further, the segmentation of gestures is done by the novel Adaptive Hough Transform (AHT), where the theta angle is tuned. Once the segmentation of gestures is done, the optimized Deep Convolutional Neural Network (Deep CNN) is used for gesture recognition. The learning rate, epoch count, and hidden neurons are tuned by the same heuristic concept. As the main contribution, the segmentation and classification are enhanced by the hybridization of Electric Fish Optimization (EFO), and Whale Optimization Algorithm (WOA) called Electric Fish-based Whale Optimization Algorithm (E-WOA). The training of optimized Deep CNN is handled by Dynamic Time Warping (DTW) for avoiding redundant frames, thus enhancing the performance of dynamic hand gestures. Quantitative measurement is accomplished for evaluating hand gesture segmentation and recognition, which portrays the superior behaviour of the proposed model.
C1 [Kowdiki, Manisha; Khaparde, Arti] MIT World Peace Univ, Sch Elect, Pune, Maharashtra, India.
   [Kowdiki, Manisha; Khaparde, Arti] MIT World Peace Univ, Commun Engn Dept, Pune, Maharashtra, India.
C3 Dr. Vishwanath Karad MIT World Peace University; Dr. Vishwanath Karad
   MIT World Peace University
RP Kowdiki, M (corresponding author), MIT World Peace Univ, Sch Elect, Pune, Maharashtra, India.; Kowdiki, M (corresponding author), MIT World Peace Univ, Commun Engn Dept, Pune, Maharashtra, India.
EM manisha.kowdiki@mitwpu.edu.in; arti.khaparde@mitwpu.edu.in
RI khaparde, arti/O-5305-2016; Khaparde, Arti/AAY-8397-2021; Kowdiki,
   Manisha/ADK-7057-2022
OI khaparde, arti/0000-0001-8724-1525; Kowdiki, Manisha/0000-0001-8133-8211
CR Ameur S, 2020, ENTERTAIN COMPUT, V35, DOI 10.1016/j.entcom.2020.100373
   [Anonymous], STANFORDEDU
   Bautista Miguel Angel, 2013, Advances in Depth Image Analysis and Applications. International Workshop, WDIA 2012. Selected and Invited Papers: LNCS 7854, P126, DOI 10.1007/978-3-642-40303-3_14
   Beno MM, 2014, INT J IMAG SYST TECH, V24, P129, DOI 10.1002/ima.22087
   Blazkiewicz M, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13050836
   Chen Q, 2008, IEEE T INSTRUM MEAS, V57, P1562, DOI 10.1109/TIM.2008.922070
   Cheng H, 2016, IEEE T CIRC SYST VID, V26, P1659, DOI 10.1109/TCSVT.2015.2469551
   Cheng H, 2016, PATTERN RECOGN, V55, P137, DOI 10.1016/j.patcog.2016.01.011
   Choi HR, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/2404089
   Dardas NH, 2011, IEEE T INSTRUM MEAS, V60, P3592, DOI 10.1109/TIM.2011.2161140
   Dorothy R., 2015, Int J Nano Corros Sci Eng, V2, P21
   Guari Q, 2019, J CANCER, V10, P4876, DOI 10.7150/jca.28769
   Hsieh CC, 2015, J REAL-TIME IMAGE PR, V10, P357, DOI 10.1007/s11554-012-0295-0
   Ibañez R, 2017, PATTERN RECOGN, V62, P73, DOI 10.1016/j.patcog.2016.08.022
   Kollorz Eva, 2008, International Journal of Intelligent Systems Technologies and Applications, V5, P334, DOI 10.1504/IJISTA.2008.021296
   Li F, 2019, J NEUROSCI METH, V323, P108, DOI 10.1016/j.jneumeth.2019.05.006
   Lv W, 2023, INTERNET TECHNOL LET, V6, DOI 10.1002/itl2.311
   Palacios JM, 2013, SENSORS-BASEL, V13, P11842, DOI 10.3390/s130911842
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Murillo-Bracamontes EA, 2012, PROCEDIA ENGINEER, V35, P230, DOI 10.1016/j.proeng.2012.04.185
   Nandy Anup, 2010, 2010 International Conference on Computer and Communication Technology (ICCCT 2010), P712, DOI 10.1109/ICCCT.2010.5640434
   Nandy A, 2010, COMM COM INF SC, V70, P102
   Pedersoli F, 2014, VISUAL COMPUT, V30, P1107, DOI 10.1007/s00371-014-0921-x
   Plouffe G, 2016, IEEE T INSTRUM MEAS, V65, P305, DOI 10.1109/TIM.2015.2498560
   Poularakis S, 2016, IEEE T CYBERNETICS, V46, P2094, DOI 10.1109/TCYB.2015.2464195
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Srivastava R, 2016, IEEE SENS J, V16, P1333, DOI 10.1109/JSEN.2015.2482759
   Tang JR, 2018, PATTERN RECOGN, V80, P21, DOI 10.1016/j.patcog.2018.02.011
   Várkonyi-Kóczy AR, 2011, IEEE T INSTRUM MEAS, V60, P1505, DOI 10.1109/TIM.2011.2108075
   Wang DS, 2018, SOFT COMPUT, V22, P387, DOI 10.1007/s00500-016-2474-6
   Wang HY, 2016, MULTIMED TOOLS APPL, V75, P8637, DOI 10.1007/s11042-015-2775-2
   Yao Y, 2014, IEEE T CIRC SYST VID, V24, P1935, DOI 10.1109/TCSVT.2014.2302538
   Yilmaz S, 2020, NEURAL COMPUT APPL, V32, P11543, DOI 10.1007/s00521-019-04641-8
   Yoon HS, 2001, PATTERN RECOGN, V34, P1491, DOI 10.1016/S0031-3203(00)00096-0
   Zhou YM, 2016, PATTERN RECOGN, V49, P102, DOI 10.1016/j.patcog.2015.07.014
NR 38
TC 6
Z9 6
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2095
EP 2126
DI 10.1007/s11042-021-11469-9
EA OCT 2021
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000708822300001
DA 2024-07-18
ER

PT J
AU Xiao, MH
   Liao, YB
   Bartos, P
   Filip, M
   Geng, GS
   Jiang, ZW
AF Xiao, Maohua
   Liao, Yabing
   Bartos, Petr
   Filip, Martin
   Geng, Guosheng
   Jiang, Ziwei
TI Fault diagnosis of rolling bearing based on back propagation neural
   network optimized by cuckoo search algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rolling bearing; Cuckoo search algorithm; BP neural network; Wavelet
   packet decomposition; Fault diagnosis
ID EMPIRICAL MODE DECOMPOSITION; PREDICTION
AB In order to improve the accuracy of rolling bearing fault diagnosis in mechanical equipment, a new fault diagnosis method based on back propagation neural network optimized by cuckoo search algorithm is proposed. This method use the global search ability of the cuckoo search algorithm to constantly search for the best weights and thresholds, and then give it to the back propagation neural network. In this paper, wavelet packet decomposition is used for feature extraction of vibration signals. The energy values of different frequency bands are obtained through wavelet packet decomposition, and they are input as feature vectors into optimized back propagation neural network to identify different fault types of rolling bearings. Through the three sets of simulation comparison experiments of Matlab, the experimental results show that, Under the same conditions, compared with the other five models, the proposed back propagation neural network optimized by cuckoo search algorithm has the least number of training iterations and the highest diagnostic accuracy rate. And in the complex classification experiment with the same fault location but different bearing diameters, the fault recognition correct rate of the back propagation neural network optimized by cuckoo search algorithm is 96.25%.
C1 [Xiao, Maohua; Liao, Yabing; Geng, Guosheng; Jiang, Ziwei] Nanjing Agr Univ, Coll Engn, Nanjing 210031, Peoples R China.
   [Bartos, Petr; Filip, Martin] Univ South Bohemia, Fac Agr, Studentska 1668, Czech Republic.
C3 Nanjing Agricultural University; University of South Bohemia Ceske
   Budejovice
RP Xiao, MH (corresponding author), Nanjing Agr Univ, Coll Engn, Nanjing 210031, Peoples R China.
EM xiaomaohua@njau.edu.cn
RI Bartos, Petr/A-2860-2010; Filip, Martin/G-5987-2017
OI Filip, Martin/0000-0002-5989-2432
FU Jiangsu International Science and Technology Cooperation Project
   [BZ2021022]; Key Research and Development Program of Jiangsu Province
   [BE2021362]; Program for Student Innovation through Research and
   Training of Nanjing Agricultural University [201910307200P]
FX The research is funded partially by the Jiangsu International Science
   and Technology Cooperation Project (BZ2021022), the Key Research and
   Development Program of Jiangsu Province (BE2021362) and Program for
   Student Innovation through Research and Training of Nanjing Agricultural
   University (201910307200P).
CR Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Ben Ali J, 2015, APPL ACOUST, V89, P16, DOI 10.1016/j.apacoust.2014.08.016
   Cai C, 2020, PROCEDIA COMPUT SCI, V166, P491, DOI 10.1016/j.procs.2020.02.059
   Case Western Reserve University Bearing Data Center, DOWNL DAT FIL
   Chen ZY, 2019, MECH SYST SIGNAL PR, V133, DOI 10.1016/j.ymssp.2019.106272
   Chunrong Q., 2019, ELECT MEAS TECHNOL, V42, P33
   Elfahham Y, 2019, ALEX ENG J, V58, P499, DOI 10.1016/j.aej.2019.05.002
   ElSaid A, 2018, APPL SOFT COMPUT, V73, P969, DOI 10.1016/j.asoc.2018.09.013
   Fuqi Lv., 2015, MACH DES MANUF ENG, V44, P65
   Han Lei Han Lei, 2011, Nongye Jixie Xuebao = Transactions of the Chinese Society for Agricultural Machinery, V42, P109
   Hemanth DJ, 2018, COMPUT ELECTR ENG, V68, P170, DOI 10.1016/j.compeleceng.2018.04.006
   Ismail A, 2013, ENG APPL ARTIF INTEL, V26, P2305, DOI 10.1016/j.engappai.2013.04.007
   Jarusek R, 2019, NEURAL NETWORKS, V116, P150, DOI 10.1016/j.neunet.2019.03.015
   Jiang XX, 2018, J SOUND VIB, V435, P36, DOI 10.1016/j.jsv.2018.07.039
   Joseph SIT, 2019, COMPUT ELECTR ENG, V78, P482, DOI 10.1016/j.compeleceng.2019.08.009
   Li Z., 2019, COMPUT ENG DES, V40, P719
   Ouaarab A, 2014, NEURAL COMPUT APPL, V24, P1659, DOI 10.1007/s00521-013-1402-2
   Rajakarunakaran S, 2008, APPL SOFT COMPUT, V8, P740, DOI 10.1016/j.asoc.2007.06.002
   Shen CQ, 2018, ENG APPL ARTIF INTEL, V76, P170, DOI 10.1016/j.engappai.2018.09.010
   Shuwei W., 2018, J SHANXI DATONG U, V1, P69
   [宋志强 Song Zhiqiang], 2017, [振动与冲击, Journal of Vibration and Shock], V36, P64
   [唐圣学 Tang Shengxue], 2015, [中南大学学报. 自然科学版, Journal of Central South University of Science and Technology], V46, P127
   Tyagi S, 2017, J COMPUT DES ENG, V4, P305, DOI 10.1016/j.jcde.2017.05.002
   Wang SX, 2016, RENEW ENERG, V94, P629, DOI 10.1016/j.renene.2016.03.103
   Xin-She Yang, 2010, International Journal of Mathematical Modelling and Numerical Optimisation, V1, P330, DOI 10.1504/IJMMNO.2010.035430
   Xing YF, 2016, MECH SYST SIGNAL PR, V66-67, P875, DOI 10.1016/j.ymssp.2015.05.003
   Xu XM, 2019, ARAB J SCI ENG, V44, P1365, DOI 10.1007/s13369-018-3527-1
   Yan XA, 2018, NEUROCOMPUTING, V313, P47, DOI 10.1016/j.neucom.2018.05.002
   [杨健健 Yang Jianjian], 2019, [振动、测试与诊断, Journal of Vibration, Measurement and Diagnosis], V39, P130
   Yi JH, 2014, SCI WORLD J, DOI 10.1155/2014/878262
   Yu JB, 2012, IEEE T INSTRUM MEAS, V61, P2200, DOI 10.1109/TIM.2012.2184015
   Zhang ZY, 2013, J INTELL MANUF, V24, P1213, DOI 10.1007/s10845-012-0657-2
   Zhang ZC, 2019, ENG APPL ARTIF INTEL, V85, P254, DOI 10.1016/j.engappai.2019.06.017
NR 34
TC 10
Z9 10
U1 5
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 1567
EP 1587
DI 10.1007/s11042-021-11556-x
EA OCT 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000704942100001
DA 2024-07-18
ER

PT J
AU Haloi, P
   Bhuyan, MK
   Chatterjee, D
   Borah, PR
AF Haloi, Pranabjyoti
   Bhuyan, M. K.
   Chatterjee, Dibyajyoti
   Borah, Pooja Rani
TI Unsupervised story segmentation and indexing of broadcast news video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Commercial filtering; Indexing; Multimodal algorithm; Story segmentation
ID PROGRAM
AB This paper presents a novel technique for story segmentation of news videos. The visual similarity, silence in the audio and the text in text boxes of a news video are used as parameters to define the story boundaries. Each of these parameters is used to create an index and these three indices are fed to a probabilistic multimodal algorithm which then predicts the story breaks. The multimodal algorithm takes account of the previous state of the indices and predicts the present state. It is then compared with the actual present indices and story breaks are determined. The segmented stories are then indexed for easy retrieval of the stories.
C1 [Haloi, Pranabjyoti; Bhuyan, M. K.] Indian Inst Technol Guwahati, Gauhati 781039, India.
   [Chatterjee, Dibyajyoti; Borah, Pooja Rani] Jorhat Engn Coll, Jorhat, Assam, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Haloi, P (corresponding author), Indian Inst Technol Guwahati, Gauhati 781039, India.
EM pranabjyoti@iitg.ac.in; mkb@iitg.ac.in; dibyajyoti.dc@gmail.com;
   poojaraniborah@gmail.com
RI Bhuyan, Manoj Kumar/D-1562-2012
CR Al Mahmood F, 2020, DICTIONARY
   [Anonymous], 2021, PARALLEL COMPUTING T
   [Anonymous], 2006, P HUM LANG TECHN C N
   [Anonymous], 2020, TEXT ANAL TOOLBOX US
   [Anonymous], 2021, IMAGE PROCESSING TOO
   [Anonymous], 2021, CLARO TV T18
   Chaisorn L, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1095, DOI 10.1109/ICME.2004.1394401
   Chaisorn L., 2003, TRECVID
   Dumont É, 2012, INT J DIGIT MULTIMED, V2012, DOI 10.1155/2012/732514
   Feng HM, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND BRAIN, VOLS 1-3, P831
   Goyal A, 2009, LECT NOTES COMPUT SC, V5478, P766, DOI 10.1007/978-3-642-00958-7_82
   Haloi P., 2019, Proceedings of 2nd International Conference on Innovations in Electronics, Signal Processing and Communication, IESC 2019, P243
   Haloi P, 2020, 2020 INTERNATIONAL CONFERENCE ON COMPUTATIONAL PERFORMANCE EVALUATION (COMPE-2020), P751, DOI 10.1109/ComPE49325.2020.9200047
   Haloi P, 2019, 2019 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET 2019): ADVANCING WIRELESS AND MOBILE COMMUNICATIONS TECHNOLOGIES FOR 2020 INFORMATION SOCIETY, P501, DOI [10.1109/WiSPNET45539.2019.9032814, 10.1109/wispnet45539.2019.9032814]
   Hauptmann AG, 1998, P IEEE INT FORUM RES, P168, DOI 10.1109/ADL.1998.670392
   Huayong L, 2005, LECT NOTES COMPUTER, V3739
   Hui PY, 2001, 10TH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P1319, DOI 10.1109/FUZZ.2001.1008901
   Jalil M, 2003, 2013 INT C TECHNOLOG, P208
   Kannao R, 2019, MULTIMED TOOLS APPL, V78, P31925, DOI 10.1007/s11042-019-7699-9
   Kannao R, 2016, INT C PATT RECOG, P2948, DOI 10.1109/ICPR.2016.7900085
   Liu Hua-Yong, 2009, Proceedings of the 2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2009), P423, DOI 10.1109/FSKD.2009.520
   Liu HY, 2009, FIRST IITA INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P124, DOI 10.1109/JCAI.2009.20
   NAGASAKA A, 1992, IFIP TRANS A, V7, P113
   O'Connor N, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P418, DOI 10.1109/ICIP.2001.958140
   Park Y, 2006, P C N AM CHAPT ASS C, P109
   Song Y, 2009, ICCSSE 2009: PROCEEDINGS OF 2009 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE & EDUCATION, P1065, DOI 10.1109/ICCSE.2009.5228544
   Tapu R, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P327, DOI 10.1109/SITIS.2016.60
   Wang JQ, 2008, IEEE T MULTIMEDIA, V10, P393, DOI 10.1109/TMM.2008.917362
   Yeh JH, 2005, IEEE INT SYMP CIRC S, P4594
   Zedan IA, 2018, ADV SOFT COMPUTING M, V730
   Zhai Y, 2005, LECT NOTES COMPUT SC, V3568, P92
NR 31
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8645
EP 8664
DI 10.1007/s11042-021-11490-y
EA SEP 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000696465800002
DA 2024-07-18
ER

PT J
AU Ansari, MA
   Singh, DK
AF Ansari, Mohd Aquib
   Singh, Dushyant Kumar
TI An expert video surveillance system to identify and mitigate shoplifting
   in megastores
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer Vision; Human Activity Recognition; Shoplifting; Video
   Analysis; Deep Neural Network; Recurrent Neural Network
ID OBJECT DETECTION
AB Shoplifting has got serious concern because of a steep surge in these types of cases all around. People are found stealing the items from the store without being noticed, either by putting them in bags or hiding objects inside clothes. CCTV cameras are generally installed at any such site, but evidences suggest that these cameras are not very effective unless the video feeds are constantly monitored. Therefore, we intend to build an automated and intelligent surveillance system to catch these shoplifters by identifying their stealing actions. This article proposes a deep neural network-based solution to identify these shoplifting activities. The model proposed uses a dual-stream fusion-based network that effectively binds appearance and motion dynamics in the temporal domain to efficiently identify the shoplifting actions. The deep Inception V3 model is used to extract activity-specific body posture features from video streams through two deep neural network pipelines, one each corresponding to appearance and motion information. Next, a recurrent neural network, namely Long Short Term Memory (LSTM) network, is used to build a temporal relation between features extracted from consecutive frames in order to distinguish human stealing actions accurately. Added to it, this article introduces a shoplifting dataset synthesized in our lab, which contains normal human actions and object stealing actions. The proposed methodology supported with experimental results demonstrates encouraging outcomes with the accuracy achieved up to 91.48%, which outperforms other existing methods.
C1 [Ansari, Mohd Aquib; Singh, Dushyant Kumar] MNNIT Allahabad, CSED, Prayagraj, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Ansari, MA (corresponding author), MNNIT Allahabad, CSED, Prayagraj, Uttar Pradesh, India.
EM mansari@mnnit.ac.in; dushyant@mnnit.ac.in
RI Singh, Dushyant Kumar/AAD-8512-2021; Ansari, Aquib/AHC-0974-2022
OI ANSARI, MOHD. AQUIB/0000-0002-9083-1523
CR Agarwal A, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P409, DOI 10.1109/IC3I.2016.7917999
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Ansari Mohd Aquib, 2022, International Conference on Innovative Computing and Communications: Proceedings of ICICC 2021. Advances in Intelligent Systems and Computing (1389), P107, DOI 10.1007/978-981-16-3071-2_10
   Arroyo R, 2015, EXPERT SYST APPL, V42, P7991, DOI 10.1016/j.eswa.2015.06.016
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gholamrezaii M, 2021, MULTIMED TOOLS APPL, V80, P19361, DOI 10.1007/s11042-020-10435-1
   Hochreiter S, 1997, ADV NEUR IN, V9, P473
   Ibrahim N, 2012, INT J ADV COMPUT TEC, V4
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Khan NS, 2021, WIRELESS PERS COMMUN, V120, P1593, DOI 10.1007/s11277-021-08525-w
   Kumar KPS, 2020, MULTIMED TOOLS APPL, V79, P3543, DOI 10.1007/s11042-018-6034-1
   KUSHWAHA A, 2021, INT J IMAGE GRAP
   Ladjailia A, 2020, NEURAL COMPUT APPL, V32, P16387, DOI 10.1007/s00521-018-3951-x
   Lalapura VS, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3448974
   Lingaswamy S, 2020, MULTIMED TOOLS APPL, V79, P8519, DOI 10.1007/s11042-018-5843-6
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Martínez-Mascorro GA, 2021, COMPUTATION, V9, DOI 10.3390/computation9020024
   National Retail Federation, 2018, NAT RET SEC SURV
   Nguyen Tam N., 2017, P 8 INT S INF COMM T
   Pienaar SW, 2019, 2019 IEEE 2ND WIRELESS AFRICA CONFERENCE (WAC), P80, DOI [10.1109/africa.2019.8843403, 10.1109/africa.2019.8843417]
   Rashwan HA, 2020, MULTIMED TOOLS APPL, V79, P34141, DOI 10.1007/s11042-020-09194-w
   Singh Dushyant Kumar, 2020, Procedia Computer Science, V171, P350, DOI 10.1016/j.procs.2020.04.036
   Singh D, 2017, PATTERN RECOGN, V65, P265, DOI 10.1016/j.patcog.2017.01.001
   Singh DK., 2018, INT C ADV INF COMP R
   Singh DK, 2016, P 5 INT C SOFT COMP
   Singh T, 2021, NEURAL COMPUT APPL, V33, P469, DOI 10.1007/s00521-020-05018-y
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Wang C, 2019, IEEE ACCESS, V7, P146533, DOI 10.1109/ACCESS.2019.2946000
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Xia K, 2020, IEEE ACCESS, V8, P56855, DOI 10.1109/ACCESS.2020.2982225
NR 32
TC 6
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22497
EP 22525
DI 10.1007/s11042-021-11438-2
EA SEP 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000695454400002
DA 2024-07-18
ER

PT J
AU Debnath, S
   Talukdar, FA
   Islam, M
AF Debnath, Sushanta
   Talukdar, Fazal A.
   Islam, Mohiul
TI Complete 3D brain tumour detection using a two-phase method along with
   confidence function evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MR image; Fuzzy c-means; Confidence function; Segmentation;
   Reconstruction; Dice similarity score
ID SEGMENTATION
AB Manual segmentation of brain tumour is a time-consuming process and the result of segmentation varies from person to person. Also, automated tumour region detection has become very crucial for introducing robotics based treatment in the field of medical application. For a precise detection of the complete tumour region, a two phase technique is developed in this work. In the first phase, 2D Magnetic resonance (MR) image slices of axial plane are segmented by applying Fuzzy c-means (FCM) clustering algorithm. The decision about the presence or absence of tumour has been taken by calculating the Confidence function value for all the positively segmented pixels. Subsequently, in second phase, decision values corresponding to the 2D MR slices have been projected in the 3D plane. Evaluation of Confidence function helps to remove a number of false positive pixels from the FCM clustered image. The proposed method has been verified using BRATS 2013, BRATS 2015 and BRATS 2018 databases. Performance evaluation of complete tumour region with BRATS 2013 dataset produces sensitivity, dice similarity score, and specificity of 0.938, 0.9525 and 0.989 respectively. Similarly, sensitivity, dice similarity score, and specificity of value 0.938, 0.9525 and 0.989 has been obtained respectively in BRATS 2015 dataset verification. Performance evaluation with BRATS 2018 dataset produces average Dice score, sensitivity and specificity of 0.921, 0.940 and 0.980 respectively. Performance analysis of the system indicates that the complete tumour region can be detected with improved accuracy using the proposed two-phase method.
C1 [Debnath, Sushanta; Talukdar, Fazal A.] Natl Inst Technol Silchar, Dept ECE, Cachar, Assam, India.
   [Islam, Mohiul] CMR Coll Engn & Technol, Dept ECE, Hyderabad, Telangana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Debnath, S (corresponding author), Natl Inst Technol Silchar, Dept ECE, Cachar, Assam, India.
EM sushantadebnath020@gmail.com
CR Abdel-Maksoud E, 2015, EGYPT INFORM J, V16, P71, DOI 10.1016/j.eij.2015.01.003
   Ahmed HM, 2019, MULTIMED TOOLS APPL, V78, P27983, DOI 10.1007/s11042-019-07876-8
   Akbar AS, 2020, ICICOS 2020, DOI [10.1109/ICICoS51170.2020.9299072, DOI 10.1109/ICICOS51170.2020.9299072]
   Anitha V, 2016, IET COMPUT VIS, V10, P9, DOI 10.1049/iet-cvi.2014.0193
   [Anonymous], 2015, 2015 8 INT C ADV PAT
   [Anonymous], 2014, P INT ACM SIGIR WORK
   Arulanandam S, 2018, MULTIMED TOOLS APPL, V79, P1
   Aslam A, 2015, PROCEDIA COMPUT SCI, V58, P430, DOI 10.1016/j.procs.2015.08.057
   Begum SS, 2020, MULTIMED TOOLS APPL, V79, P14009, DOI 10.1007/s11042-020-08643-w
   Bharath HN, 2017, IEEE J BIOMED HEALTH, V21, P1124, DOI 10.1109/JBHI.2016.2583539
   Busa Srikanth, 2019, Innovations in Computer Science and Engineering. Proceedings of the Fifth ICICSE 2017. Lecture Notes in Networks and Systems (LNNS 32), P249, DOI 10.1007/978-981-10-8201-6_28
   Chahal PK, 2020, MULTIMED TOOLS APPL, V79, P21771, DOI 10.1007/s11042-020-08898-3
   Chilla GSVN, 2017, IEEE J BIOMED HEALTH, V21, P1617, DOI 10.1109/JBHI.2017.2681688
   Debnath S, 2021, J AMB INTEL HUM COMP, V12, P2421, DOI 10.1007/s12652-020-02366-4
   Debnath S, 2019, MULTIMED TOOLS APPL, V78, P23689, DOI 10.1007/s11042-019-7673-6
   Demirhan A, 2015, IEEE J BIOMED HEALTH, V19, P1451, DOI 10.1109/JBHI.2014.2360515
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Islam M, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.053008
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Lin GC, 2010, MAGN RESON IMAGING, V28, P721, DOI 10.1016/j.mri.2010.03.009
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Mudgal TK, 2017, INT C SOFT COMP ITS, P1, DOI [DOI 10.1109/ICSOFTCOMP.2017.8280091, 10.1109/ICSOFTCOMP.2017.8280091]
   Myronenko A, 2019, LECT NOTES COMPUT SC, V11384, P311, DOI 10.1007/978-3-030-11726-9_28
   Nayak DR, 2018, MULTIMED TOOLS APPL, V77, P3833, DOI 10.1007/s11042-016-4171-y
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   Patel A., 2012, 2012 INT C COMM SYST, P149
   Pereira Sergio, 2016, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. First International Workshop, Brainles 2015, held in conjunction with MICCAI 2015. Revised Selected Papers: LNCS 9556, P131, DOI 10.1007/978-3-319-30858-6_12
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Roslan R., 2010, 2010 IEEE EMBS Conference on Biomedical Engineering and Sciences (IECBES 2010), P26, DOI 10.1109/IECBES.2010.5742193
   Roy A, 2016, SIGNAL PROCESS, V128, P262, DOI 10.1016/j.sigpro.2016.04.007
   Sardi L, 2020, COMPUT METH PROG BIO, V184, DOI 10.1016/j.cmpb.2019.105114
   ShanmugaPriya S, 2018, DES AUTOM EMBED SYST, V22, P81, DOI 10.1007/s10617-017-9200-1
   Sheela CJJ, 2020, MULTIMED TOOLS APPL, V79, P17483, DOI 10.1007/s11042-020-08636-9
   Shivhare SN, 2019, MULTIMED TOOLS APPL, V78, P34207, DOI 10.1007/s11042-019-08048-4
   Singh N, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P1325, DOI 10.1109/ICCSP.2017.8286598
   Sinha A, 2021, IEEE J BIOMED HEALTH, V25, P121, DOI 10.1109/JBHI.2020.2986926
   Soltaninejad M, 2017, INT J COMPUT ASS RAD, V12, P183, DOI 10.1007/s11548-016-1483-3
   Subashini MM., 2012, INT C SUST EN INT SY, P10
   Sujan M., 2016, Int. J. Comput. Appl., V153, P41, DOI DOI 10.5120/IJCA2016912177
   Thara KS, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P1504, DOI 10.1109/WiSPNET.2016.7566388
   Vijay V, 2016, PROCEDIA COMPUT SCI, V92, P475, DOI 10.1016/j.procs.2016.07.370
   Zhu Y, 2012, ACAD RADIOL, V19, P977, DOI 10.1016/j.acra.2012.03.026
NR 42
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 437
EP 458
DI 10.1007/s11042-021-11443-5
EA SEP 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000695102100004
DA 2024-07-18
ER

PT J
AU Lima, ACM
   Braz, G
   de Almeida, JDS
   de Paiva, AC
   Veras, RMS
AF Lima, Alan C. M.
   Braz Junior, Geraldo
   de Almeida, Joao D. S.
   de Paiva, Anselmo C.
   Veras, Rodrigo M. S.
TI An automated CNN architecture search for glaucoma diagnosis based on
   NEAT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Glaucoma diagnosis; Deep learning; Meta learning; Genetic algorithms
ID CONVOLUTIONAL NEURAL-NETWORKS; PREDICTION; MODEL; OPTIMIZATION; SECURITY
AB Glaucoma is an ocular disease that causes damage to the optic nerve, inducing successive narrowing of the visual field in affected patients due to an increased intraocular pressure, which can lead patients to blindness in an advanced stage without clinical reversal. For several years, the use of deep learning with convolutional neural networks (CNNs) has been successfully put into practice for several years. However, building a deep learning network requires an amount of experiments to find the fittest parameters, best choice of layers and an amount of available data. Thus it is not always able to produce satisfactory results due to the amount of parameters that need to be configured to adapt the CNN architecture to the problem in question, in most cases, with small datasets. Based on this scenario, this paper proposes and analyzes a CNN architecture construction from scratch, based on Neuroevolution of Augmenting Topologies for diagnosing glaucoma from fundus images. The method was evaluated with RIM-ONE and the combination of five glaucoma datasets in which we highlight 0.961 and 0.943 of f1-score, respectively for each dataset.
C1 [Lima, Alan C. M.; Braz Junior, Geraldo; de Almeida, Joao D. S.; de Paiva, Anselmo C.] Fed Univ Maranhao UFMA, Comp Appl Grp, Sao Luis, Maranhao, Brazil.
   [Veras, Rodrigo M. S.] Fed Univ Piaui UFPI, IT Dept, Teresina, PI, Brazil.
C3 Universidade Federal do Maranhao; Universidade Federal do Piaui
RP Lima, ACM (corresponding author), Fed Univ Maranhao UFMA, Comp Appl Grp, Sao Luis, Maranhao, Brazil.
EM alanlima@nca.ufma.br
RI Veras, Rodrigo M S/D-7358-2015; Paiva, Anselmo/L-2358-2013; Braz Junior,
   Geraldo/P-3851-2014
OI Veras, Rodrigo M S/0000-0001-8180-4032; Paiva,
   Anselmo/0000-0003-4921-0626; Almeida, Joao Dallyson Sousa de
   Almeida/0000-0001-7013-9700; Braz Junior, Geraldo/0000-0003-3731-6431;
   Lima, Alan/0000-0002-0167-7326
CR Abbas Q, 2017, INT J ADV COMPUT SC, V8, P41
   AHMADI A, 2011, FUEL ENERGY ABSTRACT, V314
   AHMADI A, 2015, INT J LOW-CARBON TEC, V11
   Ahmadi MA, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/706897
   Ahmadi MA, 2011, J PET EXPLOR PROD TE, V1, P99, DOI 10.1007/s13202-011-0013-7
   Ahmadi MA, 2012, FUEL, V102, P716, DOI 10.1016/j.fuel.2012.05.050
   Ahmadi MA, 2014, J PETROL SCI ENG, V123, P183, DOI 10.1016/j.petrol.2014.08.026
   Ahmadi MA, 2015, FUEL, V139, P154, DOI 10.1016/j.fuel.2014.08.044
   Ahmadi MA, 2014, CHEM ENG TECHNOL, V37, P409, DOI 10.1002/ceat.201300155
   Al-Bander B, 2017, INT MULTICONF SYST, P207, DOI 10.1109/SSD.2017.8166974
   [Anonymous], 2013, INT J MATH COMPUTATI
   [Anonymous], Introduction to genetic algorithms
   [Anonymous], 2018, HYPERAS
   Anwar S, 2015, INT CONF ACOUST SPEE, P1131, DOI 10.1109/ICASSP.2015.7178146
   Bajwa MN, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0842-8
   Benzebouchi NE, 2018, INT J ADV ELECT COMP
   Bergstra J, 2013, HYPEROPT DISTRIBUTED
   Bergstra J., 2011, Adv. Neural Inf. Process. Syst., V24
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Bochinski E, 2017, IEEE IMAGE PROC, P3924
   Bottaci L, 1997, LANCET, V350, P469, DOI 10.1016/S0140-6736(96)11196-X
   Brochu E., 2010, arXiv:1012.2599
   Budai A, 2013, INT J BIOMED IMAGING, V2013, DOI 10.1155/2013/154860
   Cerentini A, 2017, STUD HEALTH TECHNOL, V245, P318, DOI 10.3233/978-1-61499-830-3-318
   Chai YD, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105890
   Choi JY, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187336
   Christopher M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-35044-9
   Diaz-Pinto A, 2019, IEEE T MED IMAGING, V38, P2211, DOI 10.1109/TMI.2019.2903434
   Eggensperger K., 2013, NIPS WORKSHOP BAYESI, V10, P3
   Elangovan P, 2021, INT J IMAG SYST TECH, V31, P955, DOI 10.1002/ima.22494
   Fausett L., 1994, FUNDAMENTALS NEURAL
   Fumero F, 2011, COMP MED SY
   Gómez-Valverde JJ, 2019, BIOMED OPT EXPRESS, V10, P892, DOI 10.1364/BOE.10.000892
   Hemelings R, 2020, ACTA OPHTHALMOL, V98, pE94, DOI 10.1111/aos.14193
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kingma D. P., 2014, arXiv
   Kummet C, 2013, THESIS U LOWA LOWA
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Martins J, 2020, COMPUT METH PROG BIO, V192, DOI 10.1016/j.cmpb.2020.105341
   Memon I, 2019, AUTOMATED DIAGNOSIS
   MIIKKULAINEN R, 2019, COMPUTING RES REPOSI, P293
   Moosavi SR, 2019, NAT RESOUR RES, V28, P1619, DOI 10.1007/s11053-019-09459-8
   Mukhopadhyay DM, 2009, INT J GRID DISTRIB, V2, P25
   Myers JS, 2018, CLIN EXP OPHTHALMOL, V46, P169, DOI 10.1111/ceo.13138
   Nattinen J, 2015, THESIS U TAMPERE FIN
   Pelikan M, 1999, GECCO-99: PROCEEDINGS OF THE GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P525
   PLAUT D, 1986, CMUCS86126 CARN MELL
   Popescu V, 2018, P S COMP ARITHM, P1, DOI 10.1109/ARITH.2018.8464801
   Qolomany B, 2017, INT WIREL COMMUN, P1285, DOI 10.1109/IWCMC.2017.7986470
   Qureshi Imran, 2020, International Journal of Intelligent Systems Technologies and Applications, V19, P1
   Raghavendra U, 2018, INFORM SCIENCES, V441, P41, DOI 10.1016/j.ins.2018.01.051
   Rossum Gv., 1991, PYTHON, V2.7
   Ruengkitpinyo W, 2015, 2015 6TH INTERNATIONAL CONFERENCE OF INFORMATION AND COMMUNICATION TECHNOLOGY FOR EMBEDDED SYSTEMS (IC-ICTES)
   Selvaraju RR, 2016, COMPUTING RES REPOSI
   Singh H, 2021, RAPID CLASSIFICATION
   Sivaswamy J, 2014, I S BIOMED IMAGING, P53, DOI 10.1109/ISBI.2014.6867807
   SOBAJIC DJ, 1989, IEEE T POWER SYST, V4, P220, DOI 10.1109/59.32481
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811
   Wang JJ, 2019, IEEE-CAA J AUTOMATIC, V6, P247, DOI 10.1109/JAS.2019.1911348
   Warner B, 1996, AM STAT, V50, P284, DOI 10.2307/2684922
   Weinreb RN, 2004, LANCET, V363, P1711, DOI 10.1016/S0140-6736(04)16257-0
   Xie LX, 2017, IEEE I CONF COMP VIS, P1388, DOI 10.1109/ICCV.2017.154
   Xu B, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/832093
   Yadav SL., 2017, Int. J. Eng. Sci. Math, V6, P174
   Young S. R., 2015, P WORKSH MACH LEARN, P1, DOI DOI 10.1145/2834892.2834896
   Zheng L, 2016, INT J COMPUT VISION, V120, P1, DOI 10.1007/s11263-016-0889-2
   ZHOU Q, 1994, IEEE T POWER SYST, V9, P525, DOI 10.1109/59.317570
   Zhou W, 2019, MED BIOL ENG COMPUT, V57, P2055, DOI 10.1007/s11517-019-02011-z
NR 70
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13441
EP 13465
DI 10.1007/s11042-021-11239-7
EA SEP 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000695631600001
DA 2024-07-18
ER

PT J
AU Tavallali, P
   Tavallali, P
   Khosravi, MR
   Singhal, M
AF Tavallali, Pooya
   Tavallali, Peyman
   Khosravi, Mohammad R.
   Singhal, Mukesh
TI An EM-based optimization of synthetic reduced nearest neighbor model
   towards multiple modalities representation with human interpretability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reduced nearest neighbor; Prototype learning; K-means; EM algorithm;
   Human interpretable model
ID FINDING PROTOTYPES; CLASSIFICATION; RECOGNITION
AB A convenient, accurate and well-known way toward any supervised task is using Nearest Neighbor approach or its variants. However, there has been little attempt toward improving interpretability by human and providing a classical optimization of Synthetic Reduced Nearest Neighbor. To tackle these issues, this paper provides a novel optimization of Synthetic Reduced Nearest Neighbor based on Expectation Maximization (EM-SRNN). Reduced Nearest Neighbor model consists of a subset of the samples from the trainset that has similar accuracy to Nearest Neighbor. Synthetic Reduced Nearest Neighbor relaxes the model to learn K synthetic samples (or prototypes/centroids) in the space of dataset. Therefore, inspired by EM algorithm for K-means, we propose a novel optimization based on EM algorithm to learn EM-SRNN by iterating over the centroids of the model and assignment of training samples to the centroids. The first step consists of optimizing the position of each centroid based on the assignment of the samples to the centroid and the second step consists finding optimal assignments and labels of the centroids. The EM-SRNN is interpretable since the centroids exist inside the space of training samples. Additionally, the centroids represent the multiple modalities (or sub-clusters) of the classes that are interpretable by human. These properties make this type of interpretability unique, hence, making this model suitable for various studies that are related to interpretability by human, such as image processing and epidemiological studies. In this paper, analytical aspects of problem are explored and it is shown that computational complexity of proposed optimization is linear over size of the trainset. Finally, EM-SRNN shows superior or similar performance when compared with several other interpretable and similar state-of-the-art models, such as trees and kernel SVMs.
C1 [Tavallali, Pooya; Singhal, Mukesh] Univ Calif, Elect Engn & Comp Sci EECS, Merced, CA 95343 USA.
   [Khosravi, Mohammad R.] Shiraz Univ Technol, Dept Elect & Elect Engn, Shiraz, Iran.
C3 University of California System; University of California Merced; Shiraz
   University of Technology
RP Singhal, M (corresponding author), Univ Calif, Elect Engn & Comp Sci EECS, Merced, CA 95343 USA.
EM ptavallali@ucmerced.edu; tavallali@gmail.com; m.khosravi@sutech.ac.ir;
   msinghal@ucmerced.edu
RI Khosravi, Mohamadreza (Mohammad Reza)/KOD-0343-2024; Khosravi, Mohammad
   R./ABG-8013-2021
CR Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   [Anonymous], 2005, INT C MACH LEARN ICM, DOI 10.1145/1102351.1102355
   [Anonymous], 1993, Adv. Neural Inform. Process. Syst
   Begon JM, 2017, PR MACH LEARN RES, V70
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bermejo S, 1999, PATTERN RECOGN, V32, P2077, DOI 10.1016/S0031-3203(99)00120-X
   Bertsimas D, 2017, MACH LEARN, V106, P1039, DOI 10.1007/s10994-017-5633-9
   Beygelzimer A., 2006, P 23 INT C MACH LEAR, P97, DOI DOI 10.1145/1143844.1143857
   Carreira-Perpinan MA, 2018, ADV NEURAL INFORM PR, P1219
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179, DOI 10.1109/T-C.1974.223827
   Cheng-Lin Liu, 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P378, DOI 10.1109/ICDAR.1999.791803
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Dasgupta S, 2013, C LEARN THEOR, P317
   Davis J. V., 2007, ICML, P209
   De Berg M, 2008, COMPUTATIONAL GEOMET, P95, DOI DOI 10.1007/978-3-540-77974-2
   Decaestecker C, 1997, PATTERN RECOGN, V30, P281, DOI 10.1016/S0031-3203(96)00072-6
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Frosst N, 2019, PR MACH LEARN RES, V97
   GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Goldberger J., 2004, P 17 INT C NEUR INF, P513
   Gupta C, 2017, INT C MACHINE LEARNI, P1331
   JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181
   Kohonen T., 1990, IJCNN International Joint Conference on Neural Networks (Cat. No.90CH2879-5), P545, DOI 10.1109/IJCNN.1990.137622
   Kusner MJ, 2014, PR MACH LEARN RES, V32, P622
   Li A.H., 2017, International Conference on Machine Learning, P2091
   Liu Ting, 2004, P ADV NEURAL INFORM, V17, P825
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Mathy C, 2015, AAAI CONF ARTIF INTE, P2864
   Nguyen T., 2013, International Conference on Machine Learning, P1085
   Omohundro S. M., 1989, Five balltree construction algorithms
   Park J., 2017, Optimization and Control
   Sarwar Badrul, 2000, ACM WEBKDD 2000 WORK
   Tavallali P, 2020, IEEE IMAGE PROC, P1921, DOI [10.1109/ICIP40778.2020.9190986, 10.1109/icip40778.2020.9190986]
   Tavallali P, 2020, J GRID COMPUT, V18, P847, DOI 10.1007/s10723-020-09517-z
   Tavallali P, 2019, MULTIMED TOOLS APPL, V78, P2599, DOI 10.1007/s11042-018-6385-7
   Tran D, 2008, LECT NOTES COMPUT SC, V5302, P548, DOI 10.1007/978-3-540-88682-2_42
   Uhlmann, 1991, P COMM CONTR S WASH
   Wang W., 2016, ECML-PKDD, P777
   Weinberger K.Q., 2008, Proceedings of the 25th international conference on Machine learning, P1160, DOI DOI 10.1145/1390156.1390302
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Zhong K, 2017, PR MACH LEARN RES, V54, P1255
   Zukhba A. V., 2010, Pattern Recognition and Image Analysis, V20, P484, DOI 10.1134/S1054661810040097
NR 45
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41697
EP 41710
DI 10.1007/s11042-021-11241-z
EA SEP 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000692712900001
DA 2024-07-18
ER

PT J
AU Nasr, N
   Younes, A
   Elsayed, A
AF Nasr, Norhan
   Younes, Ahmed
   Elsayed, Ashraf
TI Efficient representations of digital images on quantum computers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quantum image processing; Quantum mechanics; Digital images; Quantum
   image representation
AB Quantum image processing is the use of quantum computing to store, transmit, and process digital images on quantum computers. This paper introduces two enhanced quantum image representations to store quantum images. The first enhanced quantum representation based on the flexible representation for quantum images (EFRQI) is an amplitude representation that uses the partial negation operator to store the values of the pixels of 2(n) x 2(n) image in the amplitudes of the qubits. The second enhanced quantum representation based on the novel enhanced quantum representation of digital images (ENEQR) is a basis state representation that uses the CNOT gate to store the values of the pixels in a qubit sequence. The proposed methods have better time complexity and quantum cost when compared with related models in the literature.
C1 [Nasr, Norhan; Younes, Ahmed; Elsayed, Ashraf] Alexandria Univ, Fac Sci, Dept Math & Comp Sci, Alexandria, Egypt.
   [Younes, Ahmed] Univ Birmingham, Sch Comp Sci, Birmingham B15 2TT, W Midlands, England.
C3 Egyptian Knowledge Bank (EKB); Alexandria University; University of
   Birmingham
RP Nasr, N (corresponding author), Alexandria Univ, Fac Sci, Dept Math & Comp Sci, Alexandria, Egypt.
EM sci.norhannasr@alexu.edu.eg; ayounes@alexu.edu.eg;
   ashraf.elsayed@alexu.edu.eg
RI ; Younes, Ahmed/O-6505-2017
OI Nasr, Nourhan/0000-0002-5972-5247; Younes, Ahmed/0000-0002-1594-1589
FU Academy of Scientific Research and Technology (ASRT), Egypt, under
   initiatives of Science Up Faculty of Science Grant [6564]
FX This paper is supported financially by the Academy of Scientific
   Research and Technology (ASRT), Egypt, under initiatives of Science Up
   Faculty of Science Grant No 6564. (ASRT) is the 2nd affiliation of this
   research.
CR [Anonymous], 2011, 2011 IEEE 7 INT S IN, DOI DOI 10.1109/WISP.2011.6051718
   Avaliani A, 2004, CSAI0405004 CORR
   BARENCO A, 1995, PHYS REV A, V52, P3457, DOI 10.1103/PhysRevA.52.3457
   Blaschke T., 2000, Environ. Inf. Plan. Politics Public, V2, P555
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Grover LK, 1997, PHYS REV LETT, V79, P325, DOI 10.1103/PhysRevLett.79.325
   Jiang N, 2015, QUANTUM INF PROCESS, V14, P1559, DOI 10.1007/s11128-014-0841-8
   Latorre J I, 2005, Image compression and entanglement
   Le PQ, 2011, QUANTUM INF PROCESS, V10, P63, DOI 10.1007/s11128-010-0177-y
   Li HS, 2019, IEEE T CIRCUITS-I, V66, P341, DOI 10.1109/TCSI.2018.2853655
   Li HS, 2018, IEEE ACCESS, V6, P62396, DOI 10.1109/ACCESS.2018.2871691
   Li PC, 2018, INT J QUANTUM INF, V16, DOI 10.1142/S0219749918500053
   Liu K, 2018, INT J THEOR PHYS, V57, P2938, DOI 10.1007/s10773-018-3813-4
   Liu XB, 2019, IEEE ACCESS, V7, P57188, DOI 10.1109/ACCESS.2019.2914184
   Mandrà S, 2016, NEW J PHYS, V18, DOI 10.1088/1367-2630/18/7/073003
   Maslov, 2014, REVERSIBLE BENCHMARK
   Nielsen M. A., 2010, QUANTUM COMPUTATION, DOI [10.1017/cbo9780511976667, DOI 10.1017/CBO9780511976667]
   Perret B., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4089, DOI 10.1109/ICPR.2010.994
   Sahin E, 2018, TURK J ELECTR ENG CO, V26, P768, DOI 10.3906/elk-1705-396
   Sang JZ, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-016-1463-0
   Tai JC, 2004, IMAGE VISION COMPUT, V22, P485, DOI 10.1016/j.imavis.2003.12.001
   Tolson E, 2001, MACHINE LEARNING ARE
   Venegas-Andraca SE, 2010, QUANTUM INF PROCESS, V9, P1, DOI 10.1007/s11128-009-0123-z
   Venegas-Andraca SE, 2003, PROC SPIE, V5105, P137, DOI 10.1117/12.485960
   Vibhute A., 2012, International Journal of Computer Applications, V52, DOI DOI 10.5120/8176-1495
   Wang B, 2020, INT J THEOR PHYS, V59, P374, DOI 10.1007/s10773-019-04331-0
   Wang L, 2020, MULTIMED TOOLS APPL, V79, P6661, DOI 10.1007/s11042-019-08514-z
   Wang L, 2019, OPT COMMUN, V438, P147, DOI 10.1016/j.optcom.2019.01.015
   Weber A., 1997, The usc-sipi image database
   Xu GL, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-019-2463-7
   Younes A, 2017, ANN PHYS-NEW YORK, V380, P93, DOI 10.1016/j.aop.2017.03.008
   Zhang Y, 2013, QUANTUM INF PROCESS, V12, P3103, DOI 10.1007/s11128-013-0587-8
   Zhang Y, 2013, QUANTUM INF PROCESS, V12, P2833, DOI 10.1007/s11128-013-0567-z
   Zhu H, 2003, MED IMAGE PROCESSING
NR 34
TC 7
Z9 7
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 25
BP 34019
EP 34034
DI 10.1007/s11042-021-11355-4
EA AUG 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WK6LS
UT WOS:000691163200001
DA 2024-07-18
ER

PT J
AU Kumar, A
AF Kumar, Akshi
TI Contextual semantics using hierarchical attention network for sentiment
   classification in social internet-of-things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial intelligence; Sentiment analysis; Social IoT; Deep learning;
   Social media
ID STRENGTH DETECTION
AB To steer impactful data-driven possibilities, Social Internet of Things (SIoT) comes with the collaboration of IoT and social networking and finds deeper insights into consumer behavior for better user experiences. Social networks can permeate intelligence to aid autonomous decision making by enhancing the service needs and communication among object peers in a SIoT. But the user-generated data has multiple layers of meaning which necessitate AI-driven solutions such as sentiment analysis to handle the dynamics. As people express opinions in complex ways and use rhetorical devices like sarcasm, irony, and implication etc., considering only the lexical content can be misleading. Moreover, intra-textual and sub-sentential reversals, topic drift, negation can further misrepresent sentiment, fostering the need to recognize and incorporate contextual semantics for increasing the sentiment classification accuracy. This research evaluates the use of hierarchical attention network (HAN) to classify sentiments in real-time Twitter data, including the multiple sentence tweets and multi-tweet threads. HAN allows differential contribution of various parts of tweet (tweet-sentence-word) to its essential meaning as it introduces two attentive mechanisms and the context-dependent importance of the parts of tweet are considered when constructing the representation of the document. The model is evaluated on two benchmark datasets and compares favorably to state-of-the-art approaches giving an effective solution to tweet-level analysis of sentiments in SIoT.
C1 [Kumar, Akshi] Netaji Subhas Univ Technol, Dept Informat Technol, New Delhi, India.
C3 Netaji Subhas University of Technology
RP Kumar, A (corresponding author), Netaji Subhas Univ Technol, Dept Informat Technol, New Delhi, India.
EM akshi.kumar@nsut.ac.in
OI Kumar, Akshi/0000-0003-4263-7168
CR Baccianella S, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Baziotis C., 2017, P 11 INT WORKSHOP SE, P747, DOI [DOI 10.18653/V1/S17-2126, 10.18653/v1/S17-2126]
   Cliche M., 2017, P 11 INT WORKSHOP SE, P573, DOI [DOI 10.18653/V1/S17-2094, 10.18653/v1/S17-2094]
   Dang NC, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030483
   Nguyen DQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P9
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Islam J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1355
   Jiang N, 2020, IEEE INTERNET THINGS, V7, P2901, DOI 10.1109/JIOT.2020.2963927
   Jin Y, 2016, PROC INT C TOOLS ART, P410, DOI [10.1109/ICTAI.2016.66, 10.1109/ICTAI.2016.0069]
   Kumar Akshi, 2012, International Journal of Intelligent Systems and Applications, V4, P1, DOI 10.5815/ijisa.2012.10.01
   Kumar A, 2022, MULTIMEDIA SYST, V28, P2043, DOI 10.1007/s00530-020-00747-5
   Kumar A, 2021, IEEE T IND INFORM, V17, P2938, DOI 10.1109/TII.2020.3005532
   Kumar A, 2023, MULTIMEDIA SYST, V29, P1799, DOI 10.1007/s00530-020-00741-x
   Kumar A, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102141
   Kumar A, 2019, MULTIMED TOOLS APPL, V78, P29529, DOI 10.1007/s11042-019-7278-0
   Kumar A, 2019, MULTIMED TOOLS APPL, V78, P24103, DOI 10.1007/s11042-019-7390-1
   Kumar A, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5107
   Kumar Akshi, 2012, International Journal of Computer Science Issues (IJCSI), V9, P372
   Kumar A, 2018, P NATL A SCI INDIA A, V88, P95, DOI 10.1007/s40010-017-0369-2
   Otter DW, 2021, IEEE T NEUR NET LEAR, V32, P604, DOI 10.1109/TNNLS.2020.2979670
   Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846
   Roopa MS, 2019, COMPUT COMMUN, V139, P32, DOI 10.1016/j.comcom.2019.03.009
   Rosenthal Sara, 2017, P 11 INT WORKSH SEM, P502
   Saif Hassan, 2014, The Semantic Web: Trends and Challenges. 11th International Conference (ESWC 2014). Proceedings: LNCS 8465, P83, DOI 10.1007/978-3-319-07443-6_7
   Saif H., 2013, 1 INTERANTIONAL WORK
   Saif H, 2016, INFORM PROCESS MANAG, V52, P5, DOI 10.1016/j.ipm.2015.01.005
   Scherer KR, 2006, COGNITION EMOTION, V20, P92, DOI 10.1080/02699930500305016
   Thelwall M, 2012, J AM SOC INF SCI TEC, V63, P163, DOI 10.1002/asi.21662
   Thelwall M, 2010, J AM SOC INF SCI TEC, V61, P2544, DOI 10.1002/asi.21416
   Wilson T., 2005, P C HUM LANG TECHN E, P347, DOI [10.3115/1220575.1220619, DOI 10.3115/1220575.1220619]
   Yang Z., 2016, P 2016 C N AM CHAPT, P1480, DOI [DOI 10.18653/V1/N16-1174, 10.18653/v1/n16-1174]
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhao JQ, 2018, IEEE ACCESS, V6, P23253, DOI 10.1109/ACCESS.2017.2776930
NR 33
TC 6
Z9 7
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 36967
EP 36982
DI 10.1007/s11042-021-11262-8
EA AUG 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000687926200001
DA 2024-07-18
ER

PT J
AU Singh, T
   Vishwakarma, DK
AF Singh, Tej
   Vishwakarma, Dinesh Kumar
TI A deep multimodal network based on bottleneck layer features fusion for
   action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human Activity Recognition (HAR); Deep learning; DCA; SVM
ID LEVEL FUSION; SKELETON; DEPTH; REPRESENTATION; INFORMATION; DESCRIPTOR;
   JOINTS
AB Human Activity Recognition (HAR) in videos using convolution neural network become the preferred choice for researcher due to the tremendous success of deep learning models for visual recognition applications. After the invention of the low-cost depth sensor, multiple modalities based activity recognition systems were successfully developed in the past decade. Although it is always challenging to recognize the complex human activities in videos. In this work, we proposed a deep bottleneck multimodal feature fusion (D-BMFF) framework that fused three different modalities of RGB, RGB-D(depth) and 3D coordinates information for activity classification. It helps to better recognize and make full use of information available simultaneously from a depth sensor. During the training process RGB and depth, frames are fed at regular intervals for an activity video while 3D coordinates are first converted into single RGB skeleton motion history image (RGB-SklMHI). We have extracted the features from multimodal data inputs using the latest deep pre-trained network architecture. The multimodal feature obtained from bottleneck layers before the top layer is fused by using multiset discriminant correlation analysis (M-DCA), which allows for robust visual action modeling. Finally, using a linear multiclass support vector machine (SVM) method, the fused features are categorized. The proposed approach is evaluated over four standard RGB-D datasets: UT-Kinect, CAD-60, Florence 3D and SBU Interaction. Our framework produces outstanding results and outperformed the state-of-the-art methods.
C1 [Singh, Tej; Vishwakarma, Dinesh Kumar] Delhi Technol Univ, Dept Informat Technol, Biometr Res Lab, Delhi 110042, India.
C3 Delhi Technological University
RP Vishwakarma, DK (corresponding author), Delhi Technol Univ, Dept Informat Technol, Biometr Res Lab, Delhi 110042, India.
EM ttomar07@gmail.com; dvishwakarma@gmail.com
RI VISHWAKARMA, DINESH KUMAR/L-3815-2018; Singh, Tej/AGY-9351-2022;
   VISHWAKARMA, DINESH/ABK-7887-2022; Singh, Dr. Tej/HDN-8587-2022
OI VISHWAKARMA, DINESH KUMAR/0000-0002-1026-0047; Singh,
   Tej/0000-0001-6969-3982; 
CR Avola D, 2019, MULTIMED TOOLS APPL, V78, P5919, DOI 10.1007/s11042-018-6875-7
   Ben Amor B, 2016, IEEE T PATTERN ANAL, V38, P1, DOI 10.1109/TPAMI.2015.2439257
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Devanne M, 2015, IEEE T CYBERNETICS, V45, P1340, DOI 10.1109/TCYB.2014.2350774
   Feng J., 2017, MULTIMED TOOLS APPL, P1
   Franco A, 2020, PATTERN RECOGN LETT, V131, P293, DOI 10.1016/j.patrec.2020.01.010
   Ghodsi S, 2018, J VIS COMMUN IMAGE R, V55, P729, DOI 10.1016/j.jvcir.2018.08.001
   Haghighat M, 2016, IEEE T INF FOREN SEC, V11, P1984, DOI 10.1109/TIFS.2016.2569061
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Ijjina EP, 2017, PATTERN RECOGN, V72, P504, DOI 10.1016/j.patcog.2017.07.013
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Ji XP, 2018, SIGNAL PROCESS, V143, P56, DOI 10.1016/j.sigpro.2017.08.016
   Ji YL, 2018, SIGNAL PROCESS, V143, P364, DOI 10.1016/j.sigpro.2017.06.001
   Keçeli AS, 2018, SIGNAL IMAGE VIDEO P, V12, P1197, DOI 10.1007/s11760-018-1271-3
   Khaire P, 2018, PATTERN RECOGN LETT, V115, P107, DOI 10.1016/j.patrec.2018.04.035
   Kong J, 2019, J VIS COMMUN IMAGE R, V59, P537, DOI 10.1016/j.jvcir.2019.02.013
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Li QM, 2018, SIGNAL PROCESS-IMAGE, V68, P265, DOI 10.1016/j.image.2018.06.013
   Li RM, 2019, IEEE ACCESS, V7, P169782, DOI 10.1109/ACCESS.2019.2954744
   Liu TT, 2019, INT J SOC ROBOT, V11, P219, DOI 10.1007/s12369-018-0498-z
   Nguyen XS, 2019, MACH VISION APPL, V30, P321, DOI 10.1007/s00138-018-0989-9
   Phyo CN, 2019, IEEE T CONSUM ELECTR, V65, P243, DOI 10.1109/TCE.2019.2908986
   Prabhakar S, 2002, PATTERN RECOGN, V35, P861, DOI 10.1016/S0031-3203(01)00103-0
   Raman N, 2016, NEUROCOMPUTING, V199, P163, DOI 10.1016/j.neucom.2016.03.024
   Salih AA, 2016, PATTERN RECOGN LETT, V83, P32, DOI 10.1016/j.patrec.2016.05.032
   Seidenari L, 2013, IEEE COMPUT SOC CONF, P479, DOI 10.1109/CVPRW.2013.77
   Shabaninia E, 2019, MULTIMED TOOLS APPL, V78, P31319, DOI 10.1007/s11042-019-7740-z
   She QS, 2020, MULTIMED TOOLS APPL, V79, P12349, DOI 10.1007/s11042-019-08587-w
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh T, 2021, NEURAL COMPUT APPL, V33, P469, DOI 10.1007/s00521-020-05018-y
   Singh T, 2019, ARTIF INTELL REV, V52, P1107, DOI 10.1007/s10462-018-9651-1
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Thien HT, 2018, INFORM SCIENCES, V444, P20, DOI 10.1016/j.ins.2018.02.042
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Vishwakarma DK, 2019, AEU-INT J ELECTRON C, V107, P157, DOI 10.1016/j.aeue.2019.05.023
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Yang YH, 2017, IEEE T CYBERNETICS, V47, P439, DOI 10.1109/TCYB.2016.2519448
   Yun K., 2012, 2012 IEEE COMP SOC C, P28, DOI DOI 10.1109/CVPRW.2012.6239234
   Zhang SY, 2017, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2017.24
   Zhang YP, 2012, IEEE VTS VEH TECHNOL
NR 48
TC 8
Z9 9
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 24
BP 33505
EP 33525
DI 10.1007/s11042-021-11415-9
EA AUG 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WJ3HO
UT WOS:000686840500003
DA 2024-07-18
ER

PT J
AU Samson, GL
   Lu, J
AF Samson, Grace L.
   Lu, Joan
TI PKT: fast color-based spatial model for human skin detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Skin detection; Information retrieval; Spatial data
   Modelling; Interpolation; Classification; Pattern recognition; Tree data
   structure; Computer vision
ID FACE DETECTION; SEGMENTATION; AUTOCORRELATION
AB We present a new detection method for color-based object detection, which can improve the performance of learning procedures in terms of speed, accuracy, and efficiency, using spatial inference, and algorithm. We applied the model to human skin detection from an image; however, the method can also work for other machine learning tasks involving image pixels. We propose (1) an improved RGB/HSL human skin color threshold to tackle darker human skin color detection problem. (2), we also present a new rule-based fast algorithm (packed k-dimensional tree --- PKT) that depends on an improved spatial structure for human skin/face detection from colored 2D images. We also implemented a novel packed quad-tree (PQT) to speed up the quad-tree performance in terms of indexing. We compared the proposed system to traditional pixel-by-pixel (PBP)/pixel-wise (PW) operation, and quadtree based procedures. The results show that our proposed spatial structure performs better (with a very low false hit rate, very high precision, and accuracy rate) than most state-of-the-art models.
C1 [Samson, Grace L.; Lu, Joan] Univ Huddersfield, Dept Comp Sci, Huddersfield, W Yorkshire, England.
   [Samson, Grace L.; Lu, Joan] Univ Abuja, Dept Comp Sci, Abuja, Nigeria.
C3 University of Huddersfield
RP Samson, GL (corresponding author), Univ Huddersfield, Dept Comp Sci, Huddersfield, W Yorkshire, England.; Samson, GL (corresponding author), Univ Abuja, Dept Comp Sci, Abuja, Nigeria.
EM zenhev@gmail.com; j.lu@hud.ac.uk
OI Lu, Joan/0000-0002-0585-2806; SAMSON, GRACE L./0000-0002-7203-0263
FU University of Abuja, Nigeria and Tertiary Education Trust Fund
   (TETF)/Academic Staff Training and Development (ASTD), Nigeria
FX This work was supported by the University of Abuja, Nigeria and Tertiary
   Education Trust Fund (TETF)/Academic Staff Training and Development
   (AST&D), Nigeria.
CR ABBAS AR, 2018, NEW TRENDS INFORM CO, V938
   Albiol A, 2001, IEEE IMAGE PROC, P122, DOI 10.1109/ICIP.2001.958968
   Ali A.A., 2019, Asian Journal of Research in Computer Science, V2, P1, DOI [DOI 10.9734/AJRCOS/2019/V4I230108, DOI 10.9734/AJRCOS/2018/V2I430080]
   [Anonymous], 2014, 20 WORKSH FARB WUPP, DOI DOI 10.13140/2.1.3293.3124
   [Anonymous], 2017, P IEEE 30 CANADIAN C, DOI DOI 10.1109/CCECE.2017.7946699
   Ban Y, 2014, PATTERN RECOGN, V47, P1573, DOI 10.1016/j.patcog.2013.11.005
   Baskan S, 2002, PATTERN RECOGN LETT, V23, P1623, DOI 10.1016/S0167-8655(02)00037-5
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Berchtold S., 2002, Readings in multimedia computing and networking, V12, P451
   Buolamwini J., 2018, P 1 C FAIRNESS ACCOU, P77
   Bush I J, 2018, ITM WEB C EDP SCI
   Chen HH, 2014, MULTIMED TOOLS APPL, V72, P1961, DOI 10.1007/s11042-013-1492-y
   Chen W, 2016, MULTIMED TOOLS APPL, V75, P839, DOI 10.1007/s11042-014-2328-0
   Conci OVA, 2009, WORKSH SIBGR, P1
   Dastane T., 2018, INT J RECENT INNOV T, V6, P182
   Developers, 2019, CLASS ACC MACH LEARN
   Faria RAD, 2018, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2018), VOL 5: VISAPP, P309, DOI 10.5220/0006618003090316
   Ebadati, 2019, PEERJ REPRINTS
   ElFkihi S, 2006, 2 INT S COMM CONTR S
   Hua R, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P1756, DOI 10.1109/CompComm.2017.8322841
   Jablonski NinaG., 2006, SKIN NATURAL HIST
   Jati H, 2008, 2008 INT S INF TECHN, P1
   Jiangping Chen, 2011, Proceedings of the 2011 IEEE International Conference on Spatial Data Mining and Geographical Knowledge Services (ICSDM 2011), P32, DOI 10.1109/ICSDM.2011.5969000
   Jixia Zhang, 2012, 2012 21st International Conference on Pattern Recognition (ICPR 2012), P1711
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Kawulok M, 2014, PATTERN RECOGN LETT, V41, P3, DOI 10.1016/j.patrec.2013.08.028
   Khan R, 2010, IEEE IMAGE PROC, P4613, DOI 10.1109/ICIP.2010.5651638
   Kolkur S, 2017, ADV INTEL SYS RES, V137, P324
   LEGENDRE P, 1993, ECOLOGY, V74, P1659, DOI 10.2307/1939924
   Mahmoodi MR, 2017, MULTIMED TOOLS APPL, V76, P9785, DOI 10.1007/s11042-016-3579-8
   Nikolskaia K., 2018, P 4 URAL WORKSHOP PA, P123
   Nishad P.M., 2013, J GLOBAL RES COMPUTE, V4, P44
   Nixon M.S., 2020, Feature Extraction and Image Processing for Computer Vision, V1, P399, DOI DOI 10.1016/B978-0-12-814976-8.00008-7
   Omer M A, 2018, INT J ADV COMPUT SCI, V9
   Patil P M, 2012, INT J ENG RES TECHNO, V1
   Peer P., 1999, P 4 COMP VIS WINT WO, P122
   Phung SL, 2002, IEEE IMAGE PROC, P289
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Roheda Siddharth, 2017, ELECT IMAGING, P18, DOI DOI 10.2352/ISSN.2470-1173.2017.4.SRV-352
   Rossi JP, 1998, ECOGRAPHY, V21, P117, DOI 10.1111/j.1600-0587.1998.tb00665.x
   Samson G., 2018, INT J SCI RES COMPUT, V3, P759
   Samson G L, 2018, EGYPT COMPUT SCI J, V42, P68
   Samson GL., 2016, STUDIA EKONOMICZNE Z
   SAMSON GL, 2014, J INFORM KNOWLEDGE M, V13, P1
   Samson GL, 2017, ADV INF QUAL MANAGE, P111, DOI 10.4018/978-1-5225-2058-0.ch003
   Shen JF, 2017, PATTERN RECOGN, V63, P127, DOI 10.1016/j.patcog.2016.09.010
   Simonite, 2018, PHOTOALGORITHMS ID W
   Smit AJ, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0065592
   Sun HM, 2010, PATTERN RECOGN, V43, P1413, DOI 10.1016/j.patcog.2009.09.022
   Tan WR, 2012, IEEE T IND INFORM, V8, P138, DOI 10.1109/TII.2011.2172451
   Tavallali P, 2019, MULTIMED TOOLS APPL, V78, P2599, DOI 10.1007/s11042-018-6385-7
   Thakkar D, 2018, TOP 5 BIOMETRICS FAC
   Thao NT, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/5754604
   Vezhnevets V., 2003, GRAPHICON03, P85
   Xu T, 2013, IET IMAGE PROCESS, V7, P751, DOI 10.1049/iet-ipr.2012.0657
   Zortea M, 2017, PATTERN RECOGN, V64, P92, DOI 10.1016/j.patcog.2016.10.031
NR 56
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32807
EP 32839
DI 10.1007/s11042-021-10955-4
EA AUG 2021
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000682643900001
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhou, YF
   Li, J
   Du, B
   Chang, J
   Ding, ZQ
   Qin, TQ
AF Zhou, Yifei
   Li, Jing
   Du, Bo
   Chang, Jun
   Ding, Zhiquan
   Qin, Tianqi
TI Learning adaptive updating siamese network for visual tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Attention mechanism; Template updating; Region proposal
   network
AB Recently, Siamese network (Siam)-based visual tracking describes the tracking problems as the cross-correlation between convolutional features of the target template and searching regions and solves them by similarity learning, which has achieved great success in performance. However, most of the existing Siam-based tracking methods neglect to explore the feature correlations, which is very important to learn more representative features. Moreover, the first frame is used as the fixed template without updating the template, which leads to a reduction in accuracy. To address these issues, in this paper, we propose an Adaptive Updating Siamese Network (AU-Siam) for more powerful feature correlations and adaptive template updating. Specifically, a siamese feature extraction subnetwork is proposed to introduce the attention mechanism for more discriminative representations. Furthermore, an object template updating subnetwork is developed to dynamically learn object appearance changes for robust tracking. It's interesting to show that the proposed AU-Siam can effectively reduce the probability of tracking drift in the case of fast motions and heavy occlusion and improve the tracking accuracy. Experimental results on public tracking benchmarks with challenging sequences demonstrate that our AU-Siam performs favorably against other state-of-the-art methods.
C1 [Zhou, Yifei; Li, Jing; Du, Bo; Chang, Jun] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.
   [Ding, Zhiquan; Qin, Tianqi] Sichuan Inst Aerosp Elect Equipment, Chengdu 610100, Peoples R China.
C3 Wuhan University
RP Li, J (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.
EM leejingcn@whu.edu.cn
FU Science and Technology Major Project of Hubei Province (Next-Generation
   AI Technologies) [2019AEA170]
FX This work was supported in part by the Science and Technology Major
   Project of Hubei Province (Next-Generation AI Technologies) under Grant
   2019AEA170.
CR Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30
   Choi J, 2017, PROC CVPR IEEE, P4828, DOI 10.1109/CVPR.2017.513
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2016.159
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Dong XP, 2021, IEEE T PATTERN ANAL, V43, P1515, DOI 10.1109/TPAMI.2019.2956703
   Dong XP, 2019, IEEE T IMAGE PROCESS, V28, P3516, DOI 10.1109/TIP.2019.2898567
   Dong XP, 2018, LECT NOTES COMPUT SC, V11217, P472, DOI 10.1007/978-3-030-01261-8_28
   Dong XP, 2017, IEEE T MULTIMEDIA, V19, P763, DOI 10.1109/TMM.2016.2631884
   Dong XW, 2018, IEEE CONF COMPUT
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fu K, 2020, ARXIV PREPRINT ARXIV
   Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Gao H, 2013, IEEE SYMP COMMUN VEH
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hu HW, 2019, IEEE T MULTIMEDIA, V21, P510, DOI 10.1109/TMM.2018.2859831
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jianbing S, 2019, IEEE T CYBERNETICS
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Liang ZY, 2020, IEEE T IMAGE PROCESS, V29, P3351, DOI 10.1109/TIP.2019.2959256
   Liu FH, 2018, IEEE T IMAGE PROCESS, V27, P2777, DOI 10.1109/TIP.2018.2813161
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2019, NEUROCOMPUTING, V349, P133, DOI 10.1016/j.neucom.2019.02.021
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shen XQ, 2020, MULTIMED TOOLS APPL, V79, P26661, DOI 10.1007/s11042-020-09294-7
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Tang ZC, 2019, FRONT INFORM TECH EL, V20, P1087, DOI 10.1631/FITEE.1800083
   Tang ZC, 2019, IEEE ACCESS, V7, P128185, DOI 10.1109/ACCESS.2019.2940034
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang Q, 2018, PROC CVPR IEEE, P4854, DOI 10.1109/CVPR.2018.00510
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wang WG, 2019, IEEE T PATTERN ANAL, V41, P1531, DOI 10.1109/TPAMI.2018.2840724
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   XIAO Y, 2020, PATTERN RECOGN, V100
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yunhua Zhang, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11213), P355, DOI 10.1007/978-3-030-01240-3_22
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhang Z, 2019, IEEE T IMAGE PROCESS, V28, P4803, DOI 10.1109/TIP.2019.2912290
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 55
TC 3
Z9 3
U1 1
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29849
EP 29873
DI 10.1007/s11042-021-11154-x
EA JUL 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000673513400003
DA 2024-07-18
ER

PT J
AU Hsu, CY
   Wang, S
   Qiao, Y
AF Hsu, Chih-Yu
   Wang, Shuai
   Qiao, Yu
TI Intrusion detection by machine learning for multimedia platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intrusion detection; Support vector machine; Decision tree; Naive
   Bayesian classifier; Machine learning; Streaming service; Coronavirus
   pandemic
ID FEATURE-SELECTION; POLYNOMIALS; NETWORKS
AB The multimedia service company, Netflix, increased the number of new subscribers during the Coronavirus pandemic age. Intrusion detection systems for multimedia platforms can prevent the platform from network attacks. An intelligent intrusion detection system is proposed for the security IP Multimedia Subsystem (IMS) based on machine learning technology. For increasing the accuracy of the classifiers, it is vital to select the critical features to construct the intrusion detection system. Two-class classifiers, including the Decision Tree, Support Vector Machine, and Naive Bayesian, are selected to evaluate intrusion detection accuracy. According to the three classifiers' accuracy values, the most critical features are selected based on the features' ranking orders. Six critical features are selected:Service, dst_host_same_srv_rate, Flag, Protocol Type, Dst_host_rerror_rate, and Count. Numerical comparison with state_of_the_art shows that critical features improve intrusion detection accuracy, which can be better than the deep learning method.
C1 [Hsu, Chih-Yu] Fujian Univ Technol, Sch Comp Sci & Math, Fujian Prov Key Lab Big Data Min & Applicat, Fuzhou 350118, Peoples R China.
   [Wang, Shuai] Fujian Univ Technol, Comp Sci & Math, Fuzhou 350118, Peoples R China.
   [Qiao, Yu] Univ South Austrilia, STEM, Mawson Lakes, SA 5095, Australia.
C3 Fujian University of Technology; Fujian University of Technology
RP Qiao, Y (corresponding author), Univ South Austrilia, STEM, Mawson Lakes, SA 5095, Australia.
EM 61201903@fjut.edu.cn; 1196154403@qq.com; amberjoe1214@163.com
RI Hsu, Chih-Yu/U-6407-2019
OI Hsu, Chih-Yu/0000-0003-1074-8170; Qiao, Yu/0000-0001-9108-4112
FU Fujian Provincial Key Laboratory of Big Data Mining and Applications
FX Thanks to the Fujian Provincial Key Laboratory of Big Data Mining and
   Applications for supporting the research.
CR ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   [Anonymous], 2008, P 10 ANN C COMP GEN
   [Anonymous], 2013, SMARTCR, DOI DOI 10.6029/SMARTCR.2013.01.001
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Chandra K, 2016, 2016 1ST INTERNATIONAL CONFERENCE ON INNOVATION AND CHALLENGES IN CYBER SECURITY (ICICCS 2016), P115, DOI 10.1109/ICICCS.2016.7542340
   Choudhary S, 2020, PROCEDIA COMPUT SCI, V167, P1561, DOI 10.1016/j.procs.2020.03.367
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Dash M., 1997, Intelligent Data Analysis, V1
   Deng XL, 2019, MULTIMED TOOLS APPL, V78, P3797, DOI 10.1007/s11042-018-6083-5
   Drury B, 2017, ENG APPL ARTIF INTEL, V65, P29, DOI 10.1016/j.engappai.2017.07.003
   Fratello M., 2018, Encyclopedia of Bioinformatics and Computational Biology: ABC of Bioinformatics, P374, DOI DOI 10.1016/B978-0-12-809633-8.20337-3
   Freund Y, 1999, MACHINE LEARNING, PROCEEDINGS, P124
   Huang D.S., 1996, Systematic theory of neural networks for pattern recognition, P201
   Huang DS, 2005, IEEE T NEURAL NETWOR, V16, P721, DOI 10.1109/TNN.2005.844912
   Huang DS, 2004, IEEE T NEURAL NETWOR, V15, P477, DOI 10.1109/TNN.2004.824424
   Huang DS, 1999, INT J PATTERN RECOGN, V13, P1083, DOI 10.1142/S0218001499000604
   Kalousis A, 2007, KNOWL INF SYST, V12, P95, DOI 10.1007/s10115-006-0040-8
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Kumar DA, 2018, ADV INTELL SYST, V564, P59, DOI 10.1007/978-981-10-6875-1_7
   Kumar N, 2016, 2016 1ST INTERNATIONAL CONFERENCE ON INNOVATION AND CHALLENGES IN CYBER SECURITY (ICICCS 2016), P111, DOI 10.1109/ICICCS.2016.7542339
   Marcot BG, 2019, ENVIRON MODELL SOFTW, V111, P386, DOI 10.1016/j.envsoft.2018.09.016
   Marques O, 2005, Third International Conference on Information Technology and Applications, Vol 2, Proceedings, P496
   Molina LC, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P306, DOI 10.1109/ICDM.2002.1183917
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Qi L., 2020, IEEE T IND INFORM
   Qi LY, 2021, IEEE T IND INFORM, V17, P4159, DOI 10.1109/TII.2020.3012157
   Quinlan JR, 1996, ACM COMPUT SURV, V28, P71, DOI 10.1145/234313.234346
   Quinlan JR, 1987, IJCAI, V87, P304
   Rahnema M., 2008, CORE NETWORK TECHNOL
   Rajesh S, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11020293
   Rish Irina, 2001, IJCAI 2001 WORKSHOP, V3, P41
   Russell S., 2016, Artificial intelligence a modern approach
   Schooler E., 2002, 3261 RFC
   Tan P. N., 2016, INTRO DATA MINING
   Trabelsi A, 2019, FUZZY SET SYST, V366, P46, DOI 10.1016/j.fss.2018.11.006
   Wu H., 2019, Int. J. Intell. Inf. Database Syst., V12, P212
   Wu XT, 2020, COMPUT COMMUN, V162, P139, DOI 10.1016/j.comcom.2020.08.015
   Zhang BP, 2019, CLUSTER COMPUT, V22, P827, DOI 10.1007/s10586-017-1330-5
   Zhang YQ, 2019, PATTERN RECOGN, V85, P13, DOI 10.1016/j.patcog.2018.08.003
NR 40
TC 6
Z9 6
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29643
EP 29656
DI 10.1007/s11042-021-11100-x
EA JUL 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000670723300002
PM 34248394
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Wang, YZ
   Gong, TT
   Hassan, M
   Li, Q
   Huang, S
   Zhou, Y
AF Wang, Yizhang
   Gong, Tingting
   Hassan, Muhammad
   Li, Qiang
   Huang, Sa
   Zhou, You
TI A feature extraction based support vector machine model for rectal
   cancer T-stage prediction using MRI images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature extraction; MRI image; Machine learning
ID ARTIFICIAL NEURAL-NETWORKS; CLASSIFICATION; PHENOTYPES; ALGORITHM;
   DISEASE
AB Accurate clinical cancer T-stage diagnosis is crucial for effective treatment. However, it is difficult, time-consuming, and laborious for physicians to recognize T-stage manually using rectal Magnetic Resonance Imaging (MRI) images. Machine learning methods have played important roles in medical image processing. With the goal of automatic rectal cancer T-stage prediction, we train the proposed Feature Extraction based Support Vector Machine (FE-SVM) model with the newly acquired dataset consisting of 147 patients' MRI images with primary rectal cancer. Our method adapts SVM as the training framework as SVM is effective enough for dealing with small datasets as opposed to state-of-the-art deep learning models. FE-SVM firstly extracts image similarity as an initial feature because the feature of image similarity can better reflect the differences among various types of MRI images, and the final 10-dimensional features are obtained by a 5-layers Autoencoder. To evaluate the performance of FE-SVM, we compared it with six benchmark models: CNN, Alexnet, Resnet18, Resnet50, Capsule Network, and Random Forest. FE-SVM outperforms these state-of-the-art models with significant evaluation scores.
C1 [Wang, Yizhang; Hassan, Muhammad; Zhou, You] Jilin Univ, Coll Comp Sci & Technol, Changchun, Peoples R China.
   [Wang, Yizhang] Yangzhou Univ, Coll Informat Engn, Yangzhou, Jiangsu, Peoples R China.
   [Gong, Tingting] Second Hosp Jilin Univ, Dept Radiol, Changchun, Peoples R China.
   [Hassan, Muhammad; Zhou, You] Knowledge Engn Minist Educ, Key Lab Symbol Computat, Changchun, Peoples R China.
   [Li, Qiang; Huang, Sa] Second Hosp Jilin Univ, Changchun, Peoples R China.
C3 Jilin University; Yangzhou University; Jilin University; Jilin
   University
RP Zhou, Y (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun, Peoples R China.; Zhou, Y (corresponding author), Knowledge Engn Minist Educ, Key Lab Symbol Computat, Changchun, Peoples R China.; Huang, S (corresponding author), Second Hosp Jilin Univ, Changchun, Peoples R China.
EM huangsa@jlu.edu.cn; zyou@jlu.edu.cn
RI Hassan, Muhammad/CAJ-4023-2022; wang, yizhang/GQB-2941-2022
OI Hassan, Muhammad/0000-0001-8303-8351; wang, yizhang/0000-0002-0687-7802;
   Huang, Sa/0000-0003-1465-7567; Zhou, You/0000-0003-0013-1281
FU National Natural Science Foundation of China [61772227, 61972174,
   61972175]; Science and Technology Development Foundation of Jilin
   Province [20180201045GX, 20200201300JC, 20200401083GX, 20200201163JC];
   Jilin Development and Reform Commission Fund [2020C020-2]
FX Prof. Wei Pang (School of Mathematical and Computer Sciences,
   Heriot-Watt University, Edinburgh, UK) is participated in writing or
   technical editing of the manuscript. This research is supported by the
   National Natural Science Foundation of China (Grants Nos.61772227,
   61972174, 61972175), Science and Technology Development Foundation of
   Jilin Province (No. 20180201045GX, 20200201300JC,
   20200401083GX,20200201163JC), the Jilin Development and Reform
   Commission Fund(No. 2020C020-2).
CR Abdel-Khalek S, 2017, OPTIK, V131, P414, DOI 10.1016/j.ijleo.2016.11.039
   Ahmed PK, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1497-9
   Attia ZI, 2019, NAT MED, V25, P70, DOI 10.1038/s41591-018-0240-2
   Basheer IA, 2000, J MICROBIOL METH, V43, P3, DOI 10.1016/S0167-7012(00)00201-3
   Cauwenberghs G, 2001, ADV NEUR IN, V13, P409
   Chowdhary C.L., 2018, Nature inspired computing, P75
   Chowdhary CL, 2017, J BIOMIM BIOMATER BI, V30, P12, DOI 10.4028/www.scientific.net/JBBBE.30.12
   Cocosco CA, 2003, MED IMAGE ANAL, V7, P513, DOI 10.1016/S1361-8415(03)00037-9
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   Gurovich Y, 2019, NAT MED, V25, P60, DOI 10.1038/s41591-018-0279-0
   Hannun AY, 2019, NAT MED, V25, P65, DOI 10.1038/s41591-018-0268-3
   Hatt M, 2017, EUR J NUCL MED MOL I, V44, P151, DOI 10.1007/s00259-016-3427-0
   Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891
   Lambin P, 2017, NAT REV CLIN ONCOL, V14, P749, DOI 10.1038/nrclinonc.2017.141
   Magnin B, 2009, NEURORADIOLOGY, V51, P73, DOI 10.1007/s00234-008-0463-x
   Ohri N, 2016, J NUCL MED, V57, P842, DOI 10.2967/jnumed.115.166934
   Rajpurkar Pranav, 2017, ARXIV170701836
   Ravizza S, 2019, NAT MED, V25, P57, DOI 10.1038/s41591-018-0239-8
   Sampat MP, 2009, IEEE T IMAGE PROCESS, V18, P2385, DOI 10.1109/TIP.2009.2025923
   Sánchez VD, 2003, NEUROCOMPUTING, V55, P5, DOI 10.1016/S0925-2312(03)00373-4
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   TIO TL, 1989, GASTROENTEROLOGY, V96, P1478, DOI 10.1016/0016-5085(89)90515-5
   Velazquez ER, 2017, CANCER RES, V77, P3922, DOI 10.1158/0008-5472.CAN-17-0122
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Young AL, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-05892-0
   Zhang L, 2004, IEEE T SYST MAN CY B, V34, P34, DOI 10.1109/TSMCB.2003.811113
   Zhang YD, 2011, EXPERT SYST APPL, V38, P10049, DOI 10.1016/j.eswa.2011.02.012
NR 28
TC 4
Z9 4
U1 4
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30907
EP 30917
DI 10.1007/s11042-021-11165-8
EA JUL 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000669172500003
DA 2024-07-18
ER

PT J
AU Ziadeh, A
   Abualigah, L
   Abd Elaziz, M
   Sahin, CB
   Almazroi, AA
   Omari, M
AF Ziadeh, Ahmad
   Abualigah, Laith
   Abd Elaziz, Mohamed
   Sahin, Canan Batur
   Almazroi, Abdulwahab Ali
   Omari, Mahmoud
TI Augmented grasshopper optimization algorithm by differential evolution:
   a power scheduling application in smart homes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hybrid Method; Grasshopper Optimization Algorithm; Differential
   Evolution; Power scheduling; Smart homes; Smart grid
ID ENERGY MANAGEMENT-SYSTEMS; MULTIOBJECTIVE OPTIMIZATION; GREEN
AB With the increasing number of electricity consumers, production, distribution, and consumption problems of produced energy have appeared. This paper proposed an optimization method to reduce the peak demand using smart grid capabilities. In the proposed method, a hybrid Grasshopper Optimization Algorithm (GOA) with the self-adaptive Differential Evolution (DE) is used, called HGOA. The proposed method takes advantage of the global and local search strategies from Differential Evolution and Grasshopper Optimization Algorithm. Experimental results are applied in two scenarios; the first scenario has universal inputs and several appliances. The second scenario has an expanded number of appliances. The results showed that the proposed method (HGOA) got better power scheduling arrangements and better performance than other comparative algorithms using the classical benchmark functions. Moreover, according to the computational time, it runs in constant execution time as the population is increased. The proposed method got 0.26 % enhancement compared to the other methods. Finally, we found that the proposed HGOA always got better results than the original method in the worst cases and the best cases.
C1 [Ziadeh, Ahmad; Abualigah, Laith; Omari, Mahmoud] Amman Arab Univ, Fac Comp Sci & Informat, Amman 11953, Jordan.
   [Abualigah, Laith] Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.
   [Abd Elaziz, Mohamed] Zagazig Univ, Dept Math, Fac Sci, Zagazig, Egypt.
   [Sahin, Canan Batur] Malatya Turgut Ozal Univ, Fac Engn & Nat Sci, Malatya, Turkey.
   [Almazroi, Abdulwahab Ali] Univ Jeddah, Coll Comp & Informat Technol Khulais, Dept Informat Technol, Jeddah, Saudi Arabia.
C3 Universiti Sains Malaysia; Egyptian Knowledge Bank (EKB); Zagazig
   University; Malatya Turgut Ozal University; University of Jeddah
RP Abualigah, L (corresponding author), Amman Arab Univ, Fac Comp Sci & Informat, Amman 11953, Jordan.; Abualigah, L (corresponding author), Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.
EM Ahmad.ziadeh@gmail.com; Aligah.2020@gmail.com; abd_el_aziz_m@yahoo.com;
   Canan.batur@ozal.edu.tr; Aalmazroi@uj.edu.sa; Omari@aau.edu.jo
RI Abualigah, Laith/ABC-9695-2020; , mohamed/AAH-8886-2019; BATUR ŞAHIN,
   Canan/ABI-2031-2020; Almazroi, Abdulwahab Ali/R-9240-2019
OI Abualigah, Laith/0000-0002-2203-4549; , mohamed/0000-0002-7682-6269;
   BATUR ŞAHIN, Canan/0000-0002-2131-6368; Almazroi, Abdulwahab
   Ali/0000-0001-7181-2100
CR Abd Elaziz M, 2017, EXPERT SYST APPL, V90, P484, DOI 10.1016/j.eswa.2017.07.043
   Abid MMN, 2018, 2018 INT C COMP MATH
   Abualigah L, 2021, COMPUT IND ENG, V157, DOI 10.1016/j.cie.2021.107250
   Abualigah L, 2021, COMPUT METHOD APPL M, V376, DOI 10.1016/j.cma.2020.113609
   Abualigah L, 2021, CLUSTER COMPUT, V24, P205, DOI 10.1007/s10586-020-03075-5
   Abualigah L, 2021, ARCH COMPUT METHOD E, V28, P1397, DOI 10.1007/s11831-020-09420-6
   Abualigah L, 2020, NEURAL COMPUT APPL, V32, P12381, DOI 10.1007/s00521-020-04839-1
   Abualigah LM, 2019, EAI SPRINGER INNOVAT, P205, DOI 10.1007/978-3-319-96451-5_9
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Asgher U, 2018, ENERGIES, V11, DOI 10.3390/en11123494
   Aslam S, 2020, ELECTR POW SYST RES, V182, DOI 10.1016/j.epsr.2020.106232
   Aslam S, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10041245
   Azevedo JPC, 2013, EFFECTIVE SCHEDULING
   Das S, 2009, IEEE T EVOLUT COMPUT, V13, P526, DOI 10.1109/TEVC.2008.2009457
   El-Hawary ME, 2014, ELECTR POW COMPO SYS, V42, P239, DOI 10.1080/15325008.2013.868558
   Erdinc O, 2015, IEEE T SMART GRID, V6, P1281, DOI 10.1109/TSG.2014.2352650
   Fei ZS, 2017, IEEE COMMUN SURV TUT, V19, P550, DOI 10.1109/COMST.2016.2610578
   Gunantara N, 2018, COGENT ENG, V5, DOI 10.1080/23311916.2018.1502242
   Hammid AT, 2020, ENERGIES, V13, DOI 10.3390/en13112787
   Han J, 2020, NEUROCOMPUTING, V382, P12, DOI 10.1016/j.neucom.2019.11.089
   Javaid N, 2017, IEEE ACCESS, V5, P13587, DOI 10.1109/ACCESS.2017.2715225
   Kazmi S, 2019, IEEE ACCESS, V7, P24267, DOI 10.1109/ACCESS.2017.2763624
   Khan ZA, 2019, J AMB INTEL HUM COMP, V10, P4837, DOI 10.1007/s12652-018-01169-y
   Khasawneh AM, 2020, IEEE SYST J, V14, P4735, DOI 10.1109/JSYST.2020.2996421
   Khasawneh AM, 2020, J PHYS C SERIES
   Krishnan R., 2008, IEEE Power and Energy Magazine, V6, P96, DOI DOI 10.1109/MPE.2007.915179
   Le TN, 2017, IEEE COMMUN SURV TUT, V19, P423, DOI 10.1109/COMST.2016.2613892
   Makhadmeh SN, 2019, J AMB INTEL HUM COMP, V10, P3643, DOI 10.1007/s12652-018-1085-8
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Muralitharan K, 2016, NEUROCOMPUTING, V177, P110, DOI 10.1016/j.neucom.2015.11.015
   Naz M, 2018, ENERGIES, V11, DOI 10.3390/en11020384
   Qiu HF, 2020, APPL ENERG, V269, DOI 10.1016/j.apenergy.2020.115146
   Reddy SS., 2017, INT J ELECT COMPUT E, V7, P2359
   Safaldin M, 2021, J AMB INTEL HUM COMP, V12, P1559, DOI 10.1007/s12652-020-02228-z
   Sahin CB, 2021, APPL INTELL, V51, P8271, DOI 10.1007/s10489-021-02324-3
   Samuel O, 2018, ENERGIES, V11, DOI 10.3390/en11113155
   Saremi S, 2017, ADV ENG SOFTW, V105, P30, DOI 10.1016/j.advengsoft.2017.01.004
   Shakeri M, 2017, ENERG BUILDINGS, V138, P154, DOI 10.1016/j.enbuild.2016.12.026
   Shan F, 2019, IEEE INTERNET THINGS, V6, P4411, DOI 10.1109/JIOT.2018.2883903
   Siano P, 2013, J AMB INTEL HUM COMP, V4, P651, DOI 10.1007/s12652-013-0176-9
   Uddin M, 2012, RENEW SUST ENERG REV, V16, P4078, DOI 10.1016/j.rser.2012.03.014
   Yousri D, 2020, ENERG CONVERS MANAGE, V223, DOI 10.1016/j.enconman.2020.113279
   Zhu JW, 2019, ENERGY, V171, P944, DOI 10.1016/j.energy.2019.01.025
NR 46
TC 12
Z9 12
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31569
EP 31597
DI 10.1007/s11042-021-11099-1
EA JUN 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000668056500002
DA 2024-07-18
ER

PT J
AU Jin, X
   He, Z
   Wang, YW
   Yu, JW
   Xu, J
AF Jin, Xiao
   He, Zhen
   Wang, Yongwei
   Yu, Jiawei
   Xu, Jing
TI Towards general object-based video forgery detection via dual-stream
   networks and depth information embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video forensics; Object-based video forgery; Multi-feature fusion;
   Dual-stream
ID IMAGE SPLICING DETECTION; COPY-MOVE FORGERY; LOCALIZATION
AB The object-based video forgery detection aims to expose tampered regions from video sequences without any codec information. However, existing methods mainly focus on manually selected features and models for a specific task, either splicing or copy-move, while the general representation ability of deep learning models and the correlation of different forensic features have not been fully explored. In this letter, we propose a dual-stream framework to jointly discover and integrate effective features for object-based video forgery detection. First, two different types of branches are employed to extract discriminative features. Then, after the dual-stream feature fusion, a Conditional Random Field (CRF) layer is utilized to further refine segmentation results. Finally, we consider temporal consistency by incorporating the video tracking strategy. Depth information is adopted to refine the localization results. Extensive experiments on four datasets show that the proposed method achieves competitive performance against the state-of-the-art methods.
C1 [Jin, Xiao; He, Zhen; Yu, Jiawei; Xu, Jing] Nankai Univ, Coll Artificial Intelligence, Tianjin 300350, Peoples R China.
   [Wang, Yongwei] Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC, Canada.
C3 Nankai University; University of British Columbia
RP Xu, J (corresponding author), Nankai Univ, Coll Artificial Intelligence, Tianjin 300350, Peoples R China.
EM xujing@nankai.edu.cn
RI Jin, Xiao/IVV-4814-2023; xu, jing/GRR-8698-2022; xu,
   jingcheng/HJZ-3124-2023
FU Science and Technology Planning Project of Tianjin, China
   [17JCZDJC30700, 18ZXZNGX00310]; Tianjin Natural Science Foundation
   [19JCQNJC00300]; Fundamental Research Funds for the Central Universities
   of Nankai University [63201192, 63211116]
FX This work was supported in part by the Science and Technology Planning
   Project of Tianjin, China (Grant No. 17JCZDJC30700 and 18ZXZNGX00310),
   the Tianjin Natural Science Foundation (Grant No. 19JCQNJC00300), and
   the Fundamental Research Funds for the Central Universities of Nankai
   University (Grant No. 63201192 and 63211116).
CR Al-Qershi OM, 2013, FORENSIC SCI INT, V231, P284, DOI 10.1016/j.forsciint.2013.05.027
   Aloraini M, 2021, IEEE T CIRC SYST VID, V31, P917, DOI 10.1109/TCSVT.2020.2993004
   Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Bestagini P, 2013, IEEE INT WORKSH MULT, P488, DOI 10.1109/MMSP.2013.6659337
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen SD, 2016, IEEE T CIRC SYST VID, V26, P2138, DOI 10.1109/TCSVT.2015.2473436
   Cong RM, 2020, IEEE T CYBERNETICS, V50, P3627, DOI 10.1109/TCYB.2019.2932005
   Cong RM, 2019, IEEE T MULTIMEDIA, V21, P1660, DOI 10.1109/TMM.2018.2884481
   Congcong Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P481, DOI 10.1007/978-3-030-58601-0_29
   Cozzolino D, 2019, P IEEE C COMPUTER VI, P130, DOI DOI 10.1109/CVPRW47913.2019
   Cozzolino D, 2020, IEEE T INF FOREN SEC, V15, P144, DOI 10.1109/TIFS.2019.2916364
   D'Amiano L, 2019, IEEE T CIRC SYST VID, V29, P669, DOI 10.1109/TCSVT.2018.2804768
   DAvino D., 2017, Media Watermarking, Security, and Forensics 2017, Burlingame, CA, USA, 29 January 2017-2 February 2017, V29, P92
   Dua S, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2020.115778
   Farid H, 2019, ANNU REV VIS SCI, V5, P549, DOI 10.1146/annurev-vision-091718-014827
   Huh M, 2018, LECT NOTES COMPUT SC, V11215, P106, DOI 10.1007/978-3-030-01252-6_7
   Ismael Al-Sanjary Omar, 2016, Forensic Sci Int, V266, P565, DOI 10.1016/j.forsciint.2016.07.013
   Johnston P, 2019, DIGIT INVEST, V29, P67, DOI 10.1016/j.diin.2019.03.006
   Kohli A, 2020, IET IMAGE PROCESS, V14, P947, DOI 10.1049/iet-ipr.2019.0397
   Li CY, 2021, IEEE T CYBERNETICS, V51, P88, DOI 10.1109/TCYB.2020.2969255
   Li HD, 2019, IEEE I CONF COMP VIS, P8300, DOI 10.1109/ICCV.2019.00839
   Lin CS, 2014, DIGIT INVEST, V11, P120, DOI 10.1016/j.diin.2014.03.016
   Liu B, 2018, SIGNAL PROCESS-IMAGE, V66, P103, DOI 10.1016/j.image.2018.04.011
   Liu YQ, 2019, IEEE T INF FOREN SEC, V14, P2551, DOI 10.1109/TIFS.2019.2902826
   Poggi M, 2018, INT CONF 3D VISION, P324, DOI 10.1109/3DV.2018.00045
   Qadir G., 2012, IET C IMAGE PROCESSI
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Shi XJ, 2015, ADV NEUR IN, V28
   Singh RD, 2018, MULTIMEDIA SYST, V24, P211, DOI 10.1007/s00530-017-0538-9
   Sitara K, 2016, DIGIT INVEST, V18, P8, DOI 10.1016/j.diin.2016.06.003
   Su LC, 2018, IEEE T MULTIMEDIA, V20, P825, DOI 10.1109/TMM.2017.2760098
   Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101
   Wang WG, 2019, IEEE T PATTERN ANAL, V41, P985, DOI 10.1109/TPAMI.2018.2819173
   WARIF NBA, 2016, J NETW COMPUT APPL, V75, P259, DOI DOI 10.1016/J.JNCA.2016.09.008
   Wu Y, 2019, PROC CVPR IEEE, P9535, DOI 10.1109/CVPR.2019.00977
   Zhong JL, 2020, INFORM SCIENCES, V537, P184, DOI 10.1016/j.ins.2020.05.134
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhu N, 2018, SIGNAL PROCESS-IMAGE, V68, P181, DOI 10.1016/j.image.2018.07.012
NR 40
TC 9
Z9 9
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35733
EP 35749
DI 10.1007/s11042-021-11126-1
EA JUN 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000662846400001
DA 2024-07-18
ER

PT J
AU Sharma, H
   Mishra, DC
   Sharma, RK
   Kumar, N
AF Sharma, Himani
   Mishra, D. C.
   Sharma, R. K.
   Kumar, Naveen
TI Multi-image steganography and authentication using crypto-stego
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption; Decryption; Arnold transform; Rabin cryptosystem;
   Multi-image steganography; Information security; Secret sharing
ID IMAGE SHARING SCHEME; COLOR IMAGES
AB It is a necessity to protect sensitive information in digital form from an adversary who may indulge in cyber-crimes such as modification, masquerading, and replaying of data. Security systems designed to counter such attacks must keep abreast of the adversary. In this paper, we have proposed a novel multi-image crypto-stego technique using Rabin cryptosystem and Arnold transform that provides a mechanism to hide digital data in the form of text, image, audio, and video. The proposed technique is a novel approach for (n,n) secret sharing that prevents attack by an intruder impersonating as a shareholder. In the proposed technique, the header information is created to retrieve data in the correct order. Randomized encrypted data and partial header information are camouflaged in the edges of multiple images in an adaptive manner. Minimal and distribution sequence keys distribute data in shares. Experimental results yield high values of PSNR and low values of MSE for the audio, image, video signals. Further, as the entropy values for original cover image coincide with the crypto-stego image up to the third place of decimal, the secret message will go unnoticed. Sensitivity analysis reveals that even a minor variation in a single share makes the recovery of the secret message infeasible. Comparison with the state of the art techniques indicates that the proposed technique either scores over its competitors or performs equally well in terms of standard evaluation metrics.
C1 [Sharma, Himani; Kumar, Naveen] Univ Delhi, Dept Comp Sci, Delhi 110007, India.
   [Mishra, D. C.; Sharma, R. K.] Indian Inst Technol Delhi, Dept Math, Delhi 110016, India.
C3 University of Delhi; Indian Institute of Technology System (IIT System);
   Indian Institute of Technology (IIT) - Delhi
RP Sharma, H (corresponding author), Univ Delhi, Dept Comp Sci, Delhi 110007, India.
EM himani.sharma.cs.du@gmail.com; deepiitdelhi@gmail.com;
   rksharma@maths.iitd.ac.in; nk.cs.du@gmail.com
RI Sharma, Himani/JNE-7230-2023
FU University of Delhi, Delhi [RC/2015/9677]
FX Authors thank the referees for their comments and suggestions which
   improved the presentation of the paper. Prof. R. K. Sharma is ConsenSys
   Blockchain Professor. He thanks ConsenSys AG for that previlage. This
   work has been supported for University of Delhi, Delhi-110007 with
   research grant RC/2015/9677.
CR Abdulla A. A., 2015, Ph.D. dissertation
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abdulla AA, 2014, PROC SPIE, V9120, DOI 10.1117/12.2050518
   Abuturab MR, 2012, OPT LASER ENG, V50, P772, DOI 10.1016/j.optlaseng.2011.12.006
   Agarkov AS, 2020, AIP CONF PROC, V2280, DOI 10.1063/5.0018244
   [Anonymous], 1979, Technical Report
   Bai JL, 2017, DISPLAYS, V46, P42, DOI 10.1016/j.displa.2016.12.004
   Balkrishan J, 2016, MULTIMED TOOLS APPL, V75, P7045, DOI 10.1007/s11042-015-2631-4
   Buchmann J. A., 1999, INTRO CRYPTOGRAPHY
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chang CC, 2008, INFORM SCIENCES, V178, P2433, DOI 10.1016/j.ins.2007.12.016
   Chen CC, 2014, J SYST SOFTWARE, V92, P107, DOI 10.1016/j.jss.2014.01.001
   Chen H, 2015, OPT LASER ENG, V66, P144, DOI 10.1016/j.optlaseng.2014.09.003
   Chen LF, 2009, OPT COMMUN, V282, P3433, DOI 10.1016/j.optcom.2009.05.044
   Chien HY, 2013, COMPUT NETW, V57, P2705, DOI 10.1016/j.comnet.2013.06.005
   Elia M, 2013, J DISCRET MATH SCI C, V16, P367, DOI 10.1080/09720529.2013.858478
   Feng JB, 2008, PATTERN RECOGN, V41, P3572, DOI 10.1016/j.patcog.2008.05.031
   Gutub, 2020, MULTIMED TOOLS APPL, P1
   Gutub A, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0216-0
   Hayat U, 2019, SIGNAL PROCESS, V155, P391, DOI 10.1016/j.sigpro.2018.10.011
   Hoffstein J, 2008, An introduction to mathematical cryptography, V1st
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Kabirirad S, 2019, J INF SECUR APPL, V47, P16, DOI 10.1016/j.jisa.2019.03.018
   Kaya K, 2007, INFORM SCIENCES, V177, P4148, DOI 10.1016/j.ins.2007.04.008
   Kim C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040644
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Kurosawa K, 1999, DESIGN CODE CRYPTOGR, V16, P53, DOI 10.1023/A:1008374325369
   Kurosawa K, 2009, IEEE T INFORM THEORY, V55, P4249, DOI 10.1109/TIT.2009.2025532
   Kurosawa Kaoru., 1988, CRYPTOLOGIA, V12, P225
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin PY, 2010, PATTERN RECOGN LETT, V31, P1887, DOI 10.1016/j.patrec.2010.01.019
   Liu YX, 2018, J VIS COMMUN IMAGE R, V55, P766, DOI 10.1016/j.jvcir.2018.08.003
   Logeshwari R, 2020, MULTIMED TOOLS APPL, V79, P22375, DOI 10.1007/s11042-020-08957-9
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Luo YQ, 2019, MULTIMED TOOLS APPL, V78, P22023, DOI 10.1007/s11042-019-7453-3
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH, V1st
   Meng KJ, 2020, INFORM PROCESS LETT, V157, DOI 10.1016/j.ipl.2020.105928
   Mishra DC, 2017, FRACTALS, V25, DOI 10.1142/S0218348X17500116
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Qin, 2020, IEEE T DEPEND SECURE
   Sardar MK, 2020, SIGNAL PROCESS-IMAGE, V87, DOI 10.1016/j.image.2020.115923
   Sarkar S, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON WIRELESS AND MOBILE COMPUTING, NETWORKING AND COMMUNICATIONS, P258, DOI 10.1109/WiMob.2009.51
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Sun SL, 2016, INFORM PROCESS LETT, V116, P93, DOI 10.1016/j.ipl.2015.09.016
   Tang MW, 2014, OPTIK, V125, P3972, DOI 10.1016/j.ijleo.2014.01.149
   Tripathi SK, 2020, OPTIK, V224, DOI 10.1016/j.ijleo.2020.165658
   Tsai DS, 2009, INFORM SCIENCES, V179, P3247, DOI 10.1016/j.ins.2009.05.020
   Wang HQ, 2004, COMMUN ACM, V47, P76, DOI 10.1145/1022594.1022597
   Wu X, 2020, MANAGEMENT TRANSFORMATION OF HUAWEI, P1, DOI 10.1017/9781108550987
   Wu XT, 2019, SIGNAL PROCESS-IMAGE, V78, P437, DOI 10.1016/j.image.2019.08.007
   Wu XT, 2012, J SYST SOFTWARE, V85, P1852, DOI 10.1016/j.jss.2012.02.046
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2016, J SYST SOFTWARE, V116, P22, DOI 10.1016/j.jss.2015.01.031
   Yang CN, 2012, OPT COMMUN, V285, P1725, DOI 10.1016/j.optcom.2011.12.003
NR 57
TC 3
Z9 3
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29067
EP 29093
DI 10.1007/s11042-021-11068-8
EA JUN 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000662846600003
DA 2024-07-18
ER

PT J
AU Shen, ZL
   Niu, YG
   Zuo, Y
   Xie, QY
AF Shen, Zhongli
   Niu, Yuguang
   Zuo, Yi
   Xie, Qiyue
TI Research on local feature indexing of multimedia video based on
   intelligent soft computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent soft computing; Multimedia video; Local features; Index;
   Maximum entropy thresholdmethod
ID SEARCH
AB Aiming at the problems of poor precision and recall, long retrieval time and high energy consumption in current video image indexing methods, a local feature indexing method for multimedia video based on intelligent soft computing is proposed. Video image is segmented by maximum entropy threshold method. Based on the result of segmentation, features are clustered in two-dimensional space. Each video image is divided into several feature groups. Unified descriptors are generated for each feature group. The descriptors of each feature group are coded by binary coding. The similarity between index items and video images in database is calculated, and local feature indexing of media video is realized by looking up tables. The experimental results show that the method has high index precision and recall, low energy consumption and real-time performance. The proposed method has excellent performance and robustness.
C1 [Shen, Zhongli; Niu, Yuguang; Zuo, Yi; Xie, Qiyue] Changsha Univ Sci & Technol, Energy & Power Engn Coll, Changsha 410000, Hunan, Peoples R China.
C3 Changsha University of Science & Technology
RP Zuo, Y (corresponding author), Changsha Univ Sci & Technol, Energy & Power Engn Coll, Changsha 410000, Hunan, Peoples R China.
EM yizuocs@aliyun.com
OI Xie, Qiyue/0000-0002-9107-4149
FU National Key R&D Program of China [2017YFB0902100]
FX This work was supported by National Key R&D Program of China (NO.
   2017YFB0902100).
CR Gifford HC, 2016, MED PHYS, V43, P1563, DOI 10.1118/1.4942485
   Huang Dong-Mei, 2016, Journal of Software, V27, P1729, DOI 10.13328/j.cnki.jos.005039
   Ke SW, 2017, J GUANGXI U NATURAL, V42, P728
   Li Li, 2016, Journal of Dalian University of Technology, V56, P532, DOI 10.7511/dllgxb201605014
   Lu XY, 2017, COMPUTER SIMULATION, V34, P397
   Ming WY, 2016, INT J ADV MANUF TECH, V87, P201, DOI 10.1007/s00170-016-8455-1
   Peng YX, 2016, IEEE T CIRC SYST VID, V26, P583, DOI 10.1109/TCSVT.2015.2400779
   Tolias G, 2016, INT J COMPUT VISION, V116, P247, DOI 10.1007/s11263-015-0810-4
   Wang WH., 2017, J CHINA ACAD ELECT I, V12, P90
   [向宇涵 Xiang Yuhan], 2016, [电源技术, Chinese Journal of Power Sources], V40, P572
   Yan T, 2016, AUTOMATION INSTRUMEN, V75, P212
   Yan Y, 2017, MULTIMEDIA SYST, V23, P41, DOI 10.1007/s00530-014-0419-4
   Yang X, 2018, OPT EXPRESS, V26, P7985, DOI 10.1364/OE.26.007985
   Yu Laihang, 2016, Journal of Computer Aided Design & Computer Graphics, V28, P1250
   Zhao Xiao, 2018, Journal of Applied Sciences - Electronics and Information Engineering, V36, P299, DOI 10.3969/j.issn.0255-8297.2018.02.009
NR 15
TC 0
Z9 0
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22757
EP 22772
DI 10.1007/s11042-019-07770-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UD4ZK
UT WOS:000687215900002
DA 2024-07-18
ER

PT J
AU Man, ZL
   Li, JQ
   Di, XQ
   Liu, X
   Zhou, J
   Wang, J
   Zhang, XX
AF Man, Zhenlong
   Li, Jinqing
   Di, Xiaoqiang
   Liu, Xu
   Zhou, Jian
   Wang, Jia
   Zhang, Xingxu
TI A novel image encryption algorithm based on least squares generative
   adversarial network random number generator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Random number generator; Least squares generative adversarial networks;
   NIST test; Chaotic system; Image encryption
ID CHAOTIC SYSTEM; SCHEME; STEGANOGRAPHY; KEYS
AB In cryptosystems, the generation of random keys is crucial. The random number generator is required to have a sufficiently fast generation speed to ensure the size of the keyspace. At the same time, the randomness of the key is an important indicator to ensure the security of the encryption system. The chaotic random number generator has been widely used in cryptosystems due to the uncertainty, non-repeatability, and unpredictability of chaotic systems. However, chaotic systems, especially high-dimensional chaotic systems, have slow calculation speed and long iteration time. This caused a conflict between the number of random keys and the speed of generation. In this paper, we introduce the Least Squares Generative Adversarial Networks(LSGAN)into random number generation. Using LSGAN's powerful learning ability, a novel learning random number generator is constructed. Six chaotic systems with different structures and different dimensions are used as training sets to realize the rapid and efficient generation of random numbers. Experimental results prove that the encryption key generated by this scheme can pass all randomness tests of the National Institute of Standards and Technology (NIST). Hence, our result shows that LSGAN has the potential to improve the quality of the random number generators. Finally, the results are successfully applied to the image encryption scheme based on selective scrambling and overlay diffusion, and good results are achieved.
C1 [Man, Zhenlong; Li, Jinqing; Di, Xiaoqiang; Liu, Xu; Zhou, Jian; Wang, Jia; Zhang, Xingxu] Changchun Univ Sci & Technol, Sch Comp Sci & Technol, Changchun, Peoples R China.
   [Man, Zhenlong; Li, Jinqing; Di, Xiaoqiang; Liu, Xu; Zhou, Jian; Wang, Jia; Zhang, Xingxu] Jilin Prov Key Lab Network & Informat Secur, Jilin, Jilin, Peoples R China.
   [Di, Xiaoqiang] Changchun Univ Sci & Technol, Informat Ctr, Changchun, Peoples R China.
C3 Changchun University of Science & Technology; Changchun University of
   Science & Technology
RP Li, JQ; Di, XQ (corresponding author), Changchun Univ Sci & Technol, Sch Comp Sci & Technol, Changchun, Peoples R China.; Li, JQ; Di, XQ (corresponding author), Jilin Prov Key Lab Network & Informat Secur, Jilin, Jilin, Peoples R China.; Di, XQ (corresponding author), Changchun Univ Sci & Technol, Informat Ctr, Changchun, Peoples R China.
EM lijinqing@cust.edu.cn; dixiaoqiang@cust.edu.cn
RI 满, 振龙/IZE-3510-2023
OI 满, 振龙/0000-0003-1974-9890
FU China's Natural Science Foundation Project of the Science and Technology
   Department of Jilin Province [20190201188JC]; China's Science and
   Technology Project for the 13th Five-Year Plan of the Education
   Department of Jilin Province [JJKH20181137KJ]
FX This work was supported in part by China's Natural Science Foundation
   Project(20190201188JC) of the Science and Technology Department of Jilin
   Province and China's Science and Technology Project (JJKH20181137KJ) for
   the 13th Five-Year Plan of the Education Department of Jilin Province.
CR Abd El-Latif AA, 2013, AEU-INT J ELECTRON C, V67, P136, DOI 10.1016/j.aeue.2012.07.004
   Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Babbage S., 2009, ECRYPT yearly report on algorithms and keysizes
   Brunk H, 2002, GOOGLE PATENTS
   Cao WJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107457
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Chen WB, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P94
   Di XQ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184586
   Farwa, 2019, ELSEVIER SCI INC 360, V334, P343
   Fathi-Vajargah Behrouz, 2018, Journal of Computers, V13, P309, DOI 10.17706/jcp.13.3.309-326
   Fouda JSAE, 2014, COMMUN NONLINEAR SCI, V19, P578, DOI 10.1016/j.cnsns.2013.07.016
   Ghebleh M, 2014, SIGNAL PROCESS-IMAGE, V29, P618, DOI 10.1016/j.image.2013.09.009
   Gong LH, 2019, OPT LASER TECHNOL, V115, P257, DOI 10.1016/j.optlastec.2019.01.039
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Huang C, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19120656
   Hui Liu, 2017, International Journal of Network Security, V19, P347, DOI 10.6633/IJNS.201703.19(3).04
   Jassim, 2014, INT C RES SEC STAND
   Jayram TS, 2003, GOOGLE PATENTS
   Jun Peng, 2020, 2020 15th IEEE Conference on Industrial Electronics and Applications (ICIEA), P213, DOI 10.1109/ICIEA48937.2020.9248115
   Ke Y, 2019, MULTIMED TOOLS APPL, V78, P13805, DOI 10.1007/s11042-018-6640-y
   Li TY, 2017, COMPLEXITY, DOI 10.1155/2017/9010251
   Li X., 2018, Int. J. Netw. Secur, V20, P110, DOI DOI 10.6633/IJNS.201801
   Liang XD, 2017, IEEE I CONF COMP VIS, P1762, DOI 10.1109/ICCV.2017.194
   Lin JY, 2020, PROC SPIE, V11432, DOI 10.1117/12.2541910
   Liu HJ, 2018, MULTIMED TOOLS APPL, V77, P1391, DOI 10.1007/s11042-016-4288-z
   Liu HJ, 2017, IET IMAGE PROCESS, V11, P324, DOI 10.1049/iet-ipr.2016.0040
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu J, 2020, IEEE ACCESS, V8, P60575, DOI 10.1109/ACCESS.2020.2983175
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P7739, DOI 10.1007/s11042-015-2691-5
   Mahajan, 2020, 2020 10 INT C CLOUD
   Malacaria, 2018, JOINT EUR C MACH LEA
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Parker AT, 2001, IEEE T CIRCUITS-I, V48, P624, DOI 10.1109/81.922466
   Qi-Ling HE, 2017, J CHENGDU U INFORM T
   Schneier B., 2007, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   SK N.K., 2012, Int. J. Comput. Appl., V59
   Sreelaja NK, 2016, SECUR COMMUN NETW, V9, P5733, DOI 10.1002/sec.1732
   Stinson D. R., 2018, Cryptography Theory and Practice
   Sun DG, 2017, PROC INT C TOOLS ART, P441, DOI 10.1109/ICTAI.2017.00074
   Wang HX, 2010, CHINESE PHYS B, V19, DOI 10.1088/1674-1056/19/3/030509
   Wang S, 2007, CHINESE PHYS, V16, P2631, DOI 10.1088/1009-1963/16/9/022
   Wang X, 2018, KDGAN KNOWLEDGE DIST
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wang XY, 2018, MULTIMED TOOLS APPL, V77, P6243, DOI 10.1007/s11042-017-4534-z
   Wang XY, 2015, OPT LASER ENG, V68, P126, DOI 10.1016/j.optlaseng.2014.12.025
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2018, IEEE ACCESS, V6, P23733, DOI 10.1109/ACCESS.2018.2805847
   Wang XY, 2015, NONLINEAR DYNAM, V79, P1141, DOI 10.1007/s11071-014-1729-y
   Wu XL, 2017, IEEE ACCESS, V5, P6429, DOI 10.1109/ACCESS.2017.2692043
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Yang HQ, 2010, COMMUN NONLINEAR SCI, V15, P3507, DOI 10.1016/j.cnsns.2010.01.004
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
   Ye GD, 2016, SECUR COMMUN NETW, V9, P2015, DOI 10.1002/sec.1458
   Yin D, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/9203076
   Yin Q, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500475
   Zhang M, 2015, MULTIMED TOOLS APPL, V74, P11255, DOI 10.1007/s11042-014-2227-4
   Zhang R, 2019, MULTIMED TOOLS APPL, V78, P8559, DOI 10.1007/s11042-018-6951-z
NR 60
TC 13
Z9 13
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27445
EP 27469
DI 10.1007/s11042-021-10979-w
EA MAY 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000652106100002
OA hybrid
DA 2024-07-18
ER

PT J
AU Pu, QM
   Gan, JK
   Qiu, LR
   Duan, JX
   Wang, H
AF Pu, Qiumei
   Gan, Jingkai
   Qiu, Lirong
   Duan, Jiaxin
   Wang, Hui
TI An efficient hybrid approach based on PSO, ABC and k-means for cluster
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Swarm intelligence algorithm; Particle swarm optimization algorithm;
   HPSO algorithm; K-means algorithm; Single point crossover operator
ID SEARCH ALGORITHM; OPTIMIZATION
AB Particle Swarm Optimization (PSO) algorithm is one of the typical example of Swarm Intelligence (SI) algorithm. This article addresses such problems of PSO algorithm as random initial position of each particle, unsmooth speed weight change, and poor search ability, and proposes an optimization algorithm-hybrid PSO (HPSO) algorithm to solve these problems. This algorithm makes comprehensive improvements to the PSO clustering algorithm by using the K-means clustering algorithm to generate initial clustering centers, adopting a negative exponential function model to update the weight of velocity when constructing the "position-velocity" model, and introducing the "search restriction" mechanism, and the "fly-back" mechanism and auxiliary search methods such as the single point crossover operator in the Artificial Bee Colony (ABC) algorithm. Furthermore, experimental results were analyzed and verified. The experiment compares HPSO algorithm with K-Means algorithm, PSO algorithm, and other two typical improved algorithms from the literature on six of the UCI standard clustering test data sets. The results indicate that HPSO algorithm has good performance in stability, clustering effectiveness, robustness and global search ability.
C1 [Pu, Qiumei; Gan, Jingkai; Qiu, Lirong; Duan, Jiaxin; Wang, Hui] Minzu Univ China, Sch Informat Engn, Beijing 100081, Peoples R China.
C3 Minzu University of China
RP Pu, QM (corresponding author), Minzu Univ China, Sch Informat Engn, Beijing 100081, Peoples R China.
EM puqiumei@muc.edu.cn
OI Pu, Qiumei/0000-0002-2106-237X
FU Ministry of Education Humanities and Social Sciences Project
   [18YJAZH087]; National Nature Science Foundation of China [61672553];
   National Social Science Fund of China [20BGL251]
FX This research was supported in part by the Ministry of Education
   Humanities and Social Sciences Project (No.18YJAZH087), in part by the
   National Nature Science Foundation of China (No.61672553), in part by
   the National Social Science Fund of China (No. 20BGL251). The authors
   sincerely thank for the kind reviewers for their wise comments that
   helped us to improve the quality of the paper.
CR Ab Razak MF, 2018, ARAB J SCI ENG, V43, P6963, DOI 10.1007/s13369-017-2951-y
   Abualigah L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10113827
   Abualigah L, 2021, CLUSTER COMPUT, V24, P205, DOI 10.1007/s10586-020-03075-5
   Abuligah, 2020, NEURAL COMPUT APPL
   [Anonymous], 1994, Genetic Algorithms + Data Structures = Evolution Programs
   [Anonymous], 2014, GENETIC EVOLUTIONARY
   Cao Yongchun, 2014, Journal of Computer Applications, V34, P204
   Computer, 2013, COMPUTER SCI
   de Castro LN, 2000, SIXTH BRAZILIAN SYMPOSIUM ON NEURAL NETWORKS, VOL 1, PROCEEDINGS, P84, DOI 10.1109/SBRN.2000.889718
   De Falco I, 2007, APPL SOFT COMPUT, V7, P652, DOI 10.1016/j.asoc.2005.09.004
   El-Gallad AI, 2001, CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING 2001, VOLS I AND II, CONFERENCE PROCEEDINGS, P265, DOI 10.1109/CCECE.2001.933694
   Ganesan T, 2013, APPL ENERG, V103, P368, DOI 10.1016/j.apenergy.2012.09.059
   HARRINGTON P., 2012, Machine Learning in Action
   Hongbiao, 2014, J COMPUTER APPL, V556-562, P3852
   Hou, 2005, SYSTEMS ENG THEORY P
   Jain A K, 1988, ALGORITHMS CLUSTERIN
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Ju, 2012, INT C COMP SCI INF P
   Junfei, 2017, INF CONTROL
   Kader, 2010, 2 INT C MACH LEARN C
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Krishna K, 1999, IEEE T SYST MAN CY B, V29, P433, DOI 10.1109/3477.764879
   Lu HM, 2019, IEEE WIREL COMMUN, V26, P90, DOI 10.1109/MWC.2019.1800325
   Lu HM, 2019, IEEE NETWORK, V33, P65, DOI 10.1109/MNET.2019.1800339
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Lukasik S, 2016, IEEE C EVOL COMPUTAT, P2724, DOI 10.1109/CEC.2016.7744132
   Mao-Xian, 2015, J SHANDONG U TECHNOL
   Omran M, 2005, INT J PATTERN RECOGN, V19, P297, DOI 10.1142/S0218001405004083
   Parvathi, 2013, INT C SWARM EV MEM C
   Prajapati A, 2018, ARAB J SCI ENG, V43, P7083, DOI 10.1007/s13369-017-2989-x
   Qing-Zheng, 2008, J XIAN U TECHNOLOGY
   Sakai Y, 2019, FUTURE GENER COMP SY, V92, P157, DOI 10.1016/j.future.2018.09.068
   Soule, 2005, BREEDING SWARMS
   Sriadhi, 2018, 3 ANN APPL SCI ENG C
   Xiao-Xia, 2017, ELECT DESIGN ENG
   Yan XH, 2012, NEUROCOMPUTING, V97, P241, DOI 10.1016/j.neucom.2012.04.025
   Zhang Chang-sheng, 2008, Journal of Jilin University (Engineering and Technology Edition), V38, P1371
   Zhu GP, 2010, APPL MATH COMPUT, V217, P3166, DOI 10.1016/j.amc.2010.08.049
NR 38
TC 8
Z9 8
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19321
EP 19339
DI 10.1007/s11042-021-11016-6
EA MAY 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000652106200001
DA 2024-07-18
ER

PT J
AU Wang, W
   Li, JJ
   Mo, H
   Chen, JH
AF Wang, Wei
   Li, Jingjian
   Mo, Hong
   Chen, Jianhua
TI Side information hybrid generation based on improved motion vector field
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed video coding; Side information; Motion estimation; Optical
   flow method; Improvement model; Motion vector field; Block matching
AB The quality of side information has an important impact on the performance of a distributed video coding system. At present, the generation of side information is mainly based on the translational motion model using the inter-frame correlation for motion estimation. Considering that the generated side information is prone to block effect and ghosting, as well as the situation that the nonlinear motion is not fully considered and the intra-frame correlation is not fully utilized, a side information hybrid generation algorithm based on an improvement model for the motion vector field is proposed. The side information frame to be generated for the current Wyner-Ziv frame is divided into easy-to-estimate and difficult-to-estimate macroblocks. For difficult-to-estimate macroblocks, the Horn and Schunck dense optical flow method is used to generate reliable motion vectors, for easy-to-estimate macroblocks, the block matching method is used to generate unreliable motion vectors which are modified by the proposed scheme, and then, the improved motion vectors are used for motion compensation to produce the final side information frame. Experiment results show that the quality of side information obtained by using the improved motion vector field for motion compensation has been significantly improved, thus the overall performance of the distributed video coding system has been effectively improved.
C1 [Wang, Wei; Li, Jingjian; Mo, Hong; Chen, Jianhua] Yunnan Univ, Sch Informat Sci & Engn, Kunming 650504, Yunnan, Peoples R China.
C3 Yunnan University
RP Chen, JH (corresponding author), Yunnan Univ, Sch Informat Sci & Engn, Kunming 650504, Yunnan, Peoples R China.
EM weiwang@mail.ynu.edu.cn; li_jingjian@mail.ynu.edu.cn;
   www_mofeng58@163.com; chenjh@ynu.edu.cn
OI Wang, Wei/0000-0002-2129-4736
FU National Natural Science Foundation of China [61861045]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61861045.
CR Aaron A, 2002, CONF REC ASILOMAR C, P240
   ARTIGAS X, 2007, PICT COD S
   Ascenso C., 2005, 5th EURASIP Conference on Speech and Image Processing, Multimedia Communications and Services, P1
   Benierbah S, 2020, IET IMAGE PROCESS, V14, P2301, DOI 10.1049/iet-ipr.2018.5942
   Bouguet, 2001, INTEL CORP, V5, P4, DOI DOI 10.1109/HPDC.2004.1323531
   Cao Y, 2018, IET IMAGE PROCESS, V12, P354, DOI 10.1049/iet-ipr.2017.0892
   Chen J, 2017, MULTIMED TOOLS APPL, V76, P20567, DOI 10.1007/s11042-016-3992-z
   Dash B, 2018, MULTIMED TOOLS APPL, V77, P15221, DOI 10.1007/s11042-017-5103-1
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Goloubentsev AF, 2003, IEEE INT S WORKL CHA
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Imran N, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1300-4
   Jun DS, 2019, DISPLAYS, V59, P21, DOI 10.1016/j.displa.2019.05.002
   Kuo YH, 2016, MULTIMED TOOLS APPL, V75, P2051, DOI 10.1007/s11042-014-2392-5
   Li X, 2007, IEEE T CIRC SYST VID, V17, P953, DOI 10.1109/TCSVT.2007.896656
   Liu H, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21040343
   Liveris AD, 2002, IEEE COMMUN LETT, V6, P440, DOI 10.1109/LCOMM.2002.804244
   Shen YC, 2017, IEEE SENS J, V17, P1872, DOI 10.1109/JSEN.2017.2653100
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Sushma B, 2020, BIOMED SIGNAL PROCES, V60, DOI 10.1016/j.bspc.2020.101940
   Taheri YM, 2019, MULTIMED TOOLS APPL, V78, P20697, DOI 10.1007/s11042-019-7249-5
   Taheri YM, 2018, MULTIMED TOOLS APPL, V77, P7327, DOI 10.1007/s11042-017-4635-8
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Xiong ZX, 2004, IEEE SIGNAL PROC MAG, V21, P80, DOI 10.1109/MSP.2004.1328091
   Zhang YB, 2012, J VIS COMMUN IMAGE R, V23, P229, DOI 10.1016/j.jvcir.2011.10.001
NR 25
TC 5
Z9 6
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26713
EP 26730
DI 10.1007/s11042-021-10870-8
EA MAY 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000648376700004
DA 2024-07-18
ER

PT J
AU Shi, XH
   Li, ZS
   Yu, HH
AF Shi, Xinhong
   Li, Zhanshan
   Yu, Haihong
TI Adaptive threshold cascade faster RCNN for domain adaptive object
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Domain shift; Domain adaptive object detection; Faster RCNN; Cascade;
   Adaptive threshold
AB Object detection usually assumes that training and test data come from the same distribution, but the assumption is not always hold in practice. Due to domain shift problem, applying a trained detector to a new domain will lead to a great decrease in detection accuracy. Domain adaptive object detection has been adopted to maintain high detection accuracy in the face of various domain shift problems. Domain adaptive object detection methods mainly include adversarial-based methods, discrepancy-based methods, reconstruction-based methods, hybrid methods and others. Domain adaptive Faster RCNN is a classical adversarial-based method. In order to further improve the accuracy of domain adaptive object detection, we propose a method based on the Domain adaptive Faster RCNN called adaptive threshold cascade Faster RCNN (ATCFR). The ATCFR introduces the cascade strategy and adaptive threshold strategy. The cascade strategy improves the quality of bounding boxes and solves the problem of overfitting and mismatch in Faster RCNN. The adaptive threshold strategy ensures the balance of positive and negative samples and we don't have to manually set the threshold as we did in cascade RCNN. In the end, we evaluate our new approach by using four classic datasets, including Cityscapes, Foggy Cityscapes, SIM 10k and KITTI. Experimental results show that our method has higher accuracy in variousdomain shift problems, compared with the state-of-the-art methods.
C1 [Shi, Xinhong; Li, Zhanshan; Yu, Haihong] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Shi, Xinhong; Li, Zhanshan; Yu, Haihong] Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China.
C3 Jilin University; Jilin University
RP Yu, HH (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Yu, HH (corresponding author), Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China.
EM shixh18@mails.jlu.edu.cn; zslizsli@163.com; jluyuhh@126.com
FU National Natural Science Foundation of China [61802056]; Natural Science
   Foundation of Jilin Province [20180101043JC]; Development and Reform
   Committee Foundation of Jilin province of China [2019C053-9]; Open
   Research Fund of Key Laboratory of Space Utilization, Chinese Academy of
   Sciences [LSU-KFJJ-2019-08]
FX This work was supported in part by National Natural Science Foundation
   of China under Grant 61802056, in part by Natural Science Foundation of
   Jilin Province under Grant 20180101043JC, in part by Development and
   Reform Committee Foundation of Jilin province of China under Grant
   2019C053-9, and in part by the Open Research Fund of Key Laboratory of
   Space Utilization, Chinese Academy of Sciences, under Grant
   LSU-KFJJ-2019-08.
CR Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Arruda VF, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8852008
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Cai Q, 2019, PROC CVPR IEEE, P11449, DOI 10.1109/CVPR.2019.01172
   Cao YP, 2019, INFORM FUSION, V46, P206, DOI 10.1016/j.inffus.2018.06.005
   Chen Y, 2018, PROC CVPR IEEE, P3339, DOI 10.1109/CVPR.2018.00352
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Ganin Y., 2014, ARXIV
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guo TT, 2019, IEEE IMAGE PROC, P1660, DOI [10.1109/icip.2019.8803104, 10.1109/ICIP.2019.8803104]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hsu HK, 2020, IEEE WINT CONF APPL, P738, DOI [10.1109/WACV45572.2020.9093358, 10.1109/wacv45572.2020.9093358]
   Johnson-Roberson M, 2016, ARXIV 161001983
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Khodabandeh M, 2019, IEEE I CONF COMP VIS, P480, DOI 10.1109/ICCV.2019.00057
   Li WY, 2020, 2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P1808, DOI 10.1109/SSCI47803.2020.9308604
   Lin CT, 2019, IEEE IMAGE PROC, P3029, DOI [10.1109/ICIP.2019.8803261, 10.1109/icip.2019.8803261]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Minghao Xu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12352, DOI 10.1109/CVPR42600.2020.01237
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saito K, 2019, PROC CVPR IEEE, P6949, DOI 10.1109/CVPR.2019.00712
   Sakaridis C, 2018, INT J COMPUT VISION, V126, P973, DOI 10.1007/s11263-018-1072-8
   Shan YH, 2019, NEUROCOMPUTING, V367, P31, DOI 10.1016/j.neucom.2019.08.022
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang T, 2019, PROC CVPR IEEE, P7166, DOI 10.1109/CVPR.2019.00734
   Wei, 2020, EXPLORING CATEGORICA
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zheng Y., 2020, P IEEE CVF C COMP VI, P13766
   Zhenwei He, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P309, DOI 10.1007/978-3-030-58586-0_19
   Zou Z, 2019, ARXIV
NR 38
TC 6
Z9 7
U1 22
U2 114
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 25291
EP 25308
DI 10.1007/s11042-021-10917-w
EA APR 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000640469900003
DA 2024-07-18
ER

PT J
AU Sankaran, KS
   Thangapandian, M
   Vasudevan, N
AF Sankaran, K. Sakthidasan
   Thangapandian, M.
   Vasudevan, N.
TI Brain tumor grade identification using deep Elman neural network with
   adaptive fuzzy clustering-based segmentation approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation; Feature selection; Brain tumor identification; MRI;
   Classifiers; Optimization algorithm; Classification
AB A brain tumor is a collection of anomalous evolution of harmful and unnecessary nerve cells in the brain. For advanced treatment, it is essential to categorize the tumors from the MRI (magnetic resonance imaging). In this paper, develop the adaptive fuzzy Tsallis entropy (FTE) clustering with the improved cuckoo search optimization (ICS) procedure, and the effective feature selection mechanism is proposed in this paper. Initially, the input MRI is pre-processed using the anisotropic diffusion filter and non-parametric region-based techniques to eliminate noise removal and skull stripping. After that, the tumor regions are segmented using the adaptive FTE clustering method with the ICS algorithm. The robust features are attained using the first-order statistical, discrete wavelet transform (DWT), the histogram of oriented gradients (HOG), and intensity histogram. After that, the set of optimal features are selected from the mined features using the black widow optimization (BWO) algorithm in the feature selection (FS) process. Finally, a deep Elman neural network (DENN) structure is utilized to categorize the grade of brain tumor. The suggested approach is simulated using the Matlab environment using the BRATS 2012, BRATS 2019 and BRATS 2020 datasets. The different performances are evaluated, and it is related to other existing classifiers and other approaches. The simulation results verified that the accuracy of developed approach is 99.8% for BRATS 2012, 98.7% for BRATS 2019 and 98% for BRATS 2020 as compared to other classifiers and other existing approaches.
C1 [Sankaran, K. Sakthidasan; Thangapandian, M.; Vasudevan, N.] Hindustan Inst Technol & Sci, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
C3 Hindustan Institute of Technology & Science
RP Sankaran, KS (corresponding author), Hindustan Inst Technol & Sci, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
EM sakthidasan.sankaran@gmail.com
RI Sankaran, Sakthidasan/D-7185-2019
OI Sankaran, Sakthidasan/0000-0002-5905-0809; HITS, Hindustan Institute of
   Technology and Science/0009-0004-3570-2675
CR Abdel-Khalek S, 2017, OPTIK, V131, P414, DOI 10.1016/j.ijleo.2016.11.039
   Akhila DB, 2016, PROCEEDINGS OF 2ND IEEE INTERNATIONAL CONFERENCE ON ENGINEERING & TECHNOLOGY ICETECH-2016, P748, DOI 10.1109/ICETECH.2016.7569348
   Alagarsamy S, 2017, INT J IMAG SYST TECH, V27, P317, DOI 10.1002/ima.22235
   Alhassan AM, 2020, IEEE ACCESS
   Alkhasawneh MS, 2018, ARAB J SCI ENG, V43, P6737, DOI 10.1007/s13369-017-2833-3
   Anitha R, 2018, INT J IMAG SYST TECH, V28, P48, DOI 10.1002/ima.22255
   Anitha V, 2016, IET COMPUT VIS, V10, P9, DOI 10.1049/iet-cvi.2014.0193
   [Anonymous], 2017, J MED BIOL ENG
   Arasi PRE, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1266-9
   Arunkumar N, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4962
   Ayadi W, 2019, BIOMED SIGNAL PROCES, V48, P144, DOI 10.1016/j.bspc.2018.10.010
   Bahadure NB, 2018, J DIGIT IMAGING, V31, P477, DOI 10.1007/s10278-018-0050-6
   Bakhshali MA, 2017, SOFT COMPUT, V21, P6633, DOI 10.1007/s00500-016-2210-2
   Bilenia Aniket, 2019, Information and Communication Technology for Intelligent Systems. Proceedings of ICTIS 2018. Smart Innovation, Systems and Technologies (SIST 106), P229, DOI 10.1007/978-981-13-1742-2_23
   Boushaki SI, 2018, EXPERT SYST APPL, V96, P358, DOI 10.1016/j.eswa.2017.12.001
   Chakraborty S, 2017, MICROSC RES TECHNIQ, V80, P1051, DOI 10.1002/jemt.22900
   Chavan VN, 2015, INT J COMPUTER APPL, V112
   Deb D, 2021, MULTIMED TOOLS APPL, V80, P2621, DOI 10.1007/s11042-020-09810-9
   Deepa SN., 2012, 2012 INT C COMP COMM, P1, DOI DOI 10.1109/ICCCI.2012.6158908
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Gopinath B., 2018, ASIAN J CONVERGENCE, V4
   Iqbal S, 2018, BIOMED ENG LETT, V8, P5, DOI 10.1007/s13534-017-0050-3
   Iqbal S, 2018, MICROSC RES TECHNIQ, V81, P419, DOI 10.1002/jemt.22994
   Iriawan N, 2020, TELKOMNIKA (Telecommun. Comput. Electron. Control.), V18, P1310, DOI [10.12928/telkomnika.v18i3.14753, DOI 10.12928/TELKOMNIKA.V18I3.14753, 10.12928/TELKOMNIKA.v18i3.14753]
   Isensee Fabian, 2018, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. Third International Workshop, BrainLes 2017. Held in Conjunction with MICCAI 2017. Revised Selected Papers: LNCS 10670, P287, DOI 10.1007/978-3-319-75238-9_25
   Kaya IE, 2017, COMPUT METH PROG BIO, V140, P19, DOI 10.1016/j.cmpb.2016.11.011
   Khalil HA, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12081256
   Khosravanian A, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105809
   Lakshmi A, 2018, ARAB J SCI ENG, V43, P7095, DOI 10.1007/s13369-017-2966-4
   M Malathi, 2018, Asian Pac J Cancer Prev, V19, P3257
   Makropoulos A, 2018, NEUROIMAGE, V170, P231, DOI 10.1016/j.neuroimage.2017.06.074
   Mohan G, 2018, BIOMED SIGNAL PROCES, V39, P139, DOI 10.1016/j.bspc.2017.07.007
   Mohsen Heba, 2018, Future Computing and Informatics Journal, V3, P68, DOI 10.1016/j.fcij.2017.12.001
   Mohsen H, 2017, FUTURE COMPUT INFORM
   Naidu M. S. R., 2018, Alexandria Engineering Journal, V57, P1643, DOI 10.1016/j.aej.2017.05.024
   Narmatha C, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02470-5
   Ni K, 2009, INT J COMPUT VISION, V84, P97, DOI 10.1007/s11263-009-0234-0
   Özyurt F, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109433
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Raja PMS, 2020, BIOCYBERN BIOMED ENG, V40, P440, DOI 10.1016/j.bbe.2020.01.006
   Rajan PG, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1368-4
   Raju AR, 2018, BIOCYBERN BIOMED ENG, V38, P646, DOI 10.1016/j.bbe.2018.05.001
   Ren GH, 2018, NEUROCOMPUTING, V286, P11, DOI 10.1016/j.neucom.2018.01.046
   Sarkar S, 2016, EXPERT SYST APPL, V50, P120, DOI 10.1016/j.eswa.2015.11.016
   Sharif Muhammad, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1063, DOI 10.1007/s12652-018-1075-x
   Suhag S., ISER 2 INT C OCT, V3, P55
   Sumathi R, 2018, BIOCYBERN BIOMED ENG, V38, P918, DOI 10.1016/j.bbe.2018.07.005
   Sundaram N., 2015, P INT C SYST SCI CON
   Togaçar M, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113274
   Venkatesan AS, 2014, NEUROQUANTOLOGY, V12, P221, DOI 10.14704/nq.2014.12.2.733
   Vijh S, 2020, LECT NOTE DATA ENG, V32, P171, DOI 10.1007/978-3-030-25797-2_8
   Wang SH, 2016, IEEE ACCESS, V4, DOI 10.1109/ACCESS.2016.2620996
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
NR 53
TC 9
Z9 9
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 25139
EP 25169
DI 10.1007/s11042-021-10873-5
EA APR 2021
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000640172500002
DA 2024-07-18
ER

PT J
AU Kumar, N
   Kumar, R
   Malik, A
   Singh, S
AF Kumar, Neeraj
   Kumar, Rajeev
   Malik, Aruna
   Singh, Samayveer
TI Low bandwidth data hiding for multimedia systems based on bit redundancy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bit redundancy; Secret data; Embedding capacity; Data hiding; AMBTC
AB In recent years, low bandwidth data hiding schemes for multimedia systems are being seen as a promising new technology for multimedia information protection and rights management. More specifically, Absolute moment preserving block truncation coding (AMBTC) based data hiding schemes have gain a wide attraction among the researches due to their low complexity and high compression ratio. One such scheme proposed by Ou et al. has been a breakthrough in the field as the scheme provides high capacity with only slight degradation in image quality. The Ou et al.'s scheme basically divides the AMBTC blocks into smooth and complex categories based on a user-defined threshold and embeds the secret data only into the smooth blocks as data embedding into complex blocks result in severe degradation of image quality. To address this problem of non-embeddability in complex blocks, this paper proposes a high capacity data hiding scheme which efficiently utilizes the complex image blocks for embedding the secret data without any degradation in the image quality unlike the traditional AMBTC based schemes. The proposed scheme basically utilizes the bit redundancy of image blocks for creating a room for secret data bits inside bitmaps of AMBTC codes. Thus, the scheme significantly increases the embedding capacity without any further degradation in image quality. To validate the performance of proposed scheme, experimental results are compared with existing techniques which show significant improvement in embedding capacity while maintaining the stego-image quality.
C1 [Kumar, Neeraj] Nagarjuna Coll Engn & Technol, Dept Elect & Commun Engn, Bengaluru, India.
   [Kumar, Rajeev] Delhi Technol Univ, Dept Dept Comp Sci Engn, Delhi, India.
   [Malik, Aruna; Singh, Samayveer] NIT Jalandhar, Dept Comp Sci & Engn, Jalandhar, Punjab, India.
C3 Delhi Technological University; National Institute of Technology (NIT
   System); Dr B R Ambedkar National Institute of Technology Jalandhar
RP Singh, S (corresponding author), NIT Jalandhar, Dept Comp Sci & Engn, Jalandhar, Punjab, India.
EM neeraj.mohiwal@gmail.com; rajivgarg@outlook.com; arunacsrke@gmail.com;
   samayveersingh@gmail.com
RI Kumar, Neeraj/L-3500-2016; Malik, Aruna/AAL-1997-2020; Singh,
   Samayveer/X-8119-2019; Kumar, Rajeev/IUP-5006-2023; Malik,
   Aruna/GOH-0709-2022
OI Kumar, Neeraj/0000-0002-3020-3947; Singh, Samayveer/0000-0002-4199-721X;
   Kumar, Rajeev/0000-0002-5000-7644; Malik, Aruna/0000-0003-1136-6828
CR [Anonymous], 2018, CITY TERRIT ARCHIT
   Chen J, 2010, IMAGING SCI J, V58, P177, DOI 10.1179/136821910X12651933390629
   Chen Lee Shu-Teng, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P66, DOI 10.1109/IIHMSP.2010.24
   CHENG SC, 1994, PATTERN RECOGN, V27, P1439, DOI 10.1016/0031-3203(94)90123-6
   Christodoulou L, 2016, IEEE T BROADCAST, V62, P540, DOI 10.1109/TBC.2016.2570020
   Chuang J.-C., 2006, International Journal of Computers & Applications, V28, P329, DOI 10.2316/Journal.202.2006.4.202-1735
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Dhara BC, 2004, PATTERN RECOGN, V37, P2131, DOI 10.1016/j.patcog.2004.02.008
   Fraga-Lamas P, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16101644
   Hong W, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P13, DOI 10.1109/CISP.2008.638
   Hong W, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10020036
   Huang YH, 2017, MULTIMED TOOLS APPL, V76, P6159, DOI 10.1007/s11042-015-3208-y
   Kumar Rajeev, 2013, International Journal of Image, Graphics and Signal Processing, V5, P25, DOI 10.5815/ijigsp.2013.06.04
   Kumar R., 2018, INT J MULTIMED INTEL, V3, P146, DOI [10.1504/IJMIS.2018.096356, DOI 10.1504/IJMIS.2018.096356]
   Kumar R, 2019, MULTIMED TOOLS APPL, V78, P32239, DOI 10.1007/s11042-019-07997-0
   Kumar R, 2019, J INF SECUR APPL, V47, P94, DOI 10.1016/j.jisa.2019.04.007
   Kumar R, 2019, MULTIMED TOOLS APPL, V78, P22977, DOI 10.1007/s11042-019-7640-2
   Kumar R, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P854, DOI [10.1109/SPIN.2019.8711774, 10.1109/spin.2019.8711774]
   Kumar R, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P903, DOI [10.1109/SPIN.2019.8711635, 10.1109/spin.2019.8711635]
   Kumar R, 2018, INT ARAB J INF TECHN, V15, P763
   Kumar R, 2018, MULTIMED TOOLS APPL, V77, P13445, DOI 10.1007/s11042-017-4960-y
   Kumar R, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1399, DOI 10.1109/CCAA.2016.7813937
   Kumar R, 2017, MULTIMED TOOLS APPL, V76, P979, DOI 10.1007/s11042-015-3069-4
   Kumar R, 2016, MULTIMED TOOLS APPL, V75, P241, DOI 10.1007/s11042-014-2289-3
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Lin CC, 2015, MULTIMED TOOLS APPL, V74, P3823, DOI 10.1007/s11042-013-1801-5
   Malik A, 2019, INT ARAB J INF TECHN, V16, P148
   Malik A, 2018, MULTIMED TOOLS APPL, V77, P15803, DOI 10.1007/s11042-017-5156-1
   Malik A, 2017, MULTIMED TOOLS APPL, V76, P14151, DOI 10.1007/s11042-016-3815-2
   Ou DH, 2015, MULTIMED TOOLS APPL, V74, P9117, DOI 10.1007/s11042-014-2059-2
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang Y, 2003, PROCEEDINGS OF THE 2003 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING, P339
   YANG CK, 1995, PATTERN RECOGN LETT, V16, P67, DOI 10.1016/0167-8655(94)00068-E
NR 33
TC 3
Z9 3
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35027
EP 35045
DI 10.1007/s11042-021-10832-0
EA APR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000638027700001
DA 2024-07-18
ER

PT J
AU Sahoo, TK
   Banka, H
   Negi, A
AF Sahoo, Tapan Kumar
   Banka, Haider
   Negi, Atul
TI Design and analysis of various bidirectional 2DPCAs in feature
   partitioning framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dimensionality reduction; Face recognition; Feature partitioning; PCA;
   2DPCA
ID PRINCIPAL COMPONENT ANALYSIS; FACE REPRESENTATION; 2-DIMENSIONAL PCA
AB In this paper, we present various of bidirectional 2DPCAs in feature partitioning framework. To capture hybrid variations of images with optimal feature dimensions, we propose bidirectional sub-image PCA (Bi-SIMPCA), bidirectional flexible PCA (Bi-FLPCA), bidirectional extended SIMPCA (Bi-ESIMPCA) and bidirectional extended FLPCA (Bi-EFLPCA). The Bi-SIMPCA operates on a set of partitioned sub-images of original image and extracts the 2DPCA feature by simultaneously considering the row and column directions of sub-images. Bi-SIMPCA neglects the cross-correlation across sub-images. The Bi-FLPCA further improves the Bi-SIMPCA by removing the redundant features using cross-correlation across sub-images. The Bi-ESIMPCA instead operates on the sub-images of an image and the same whole image simultaneously and extracts the 2DPCA features along row and column directions. Bi-ESIMPCA lacks the global cross-correlation across sub-images and whole images. The Bi-EFLPCA further improves the Bi-ESIMPCA by reducing the redundant features using global correlation across sub-images and whole images. The issues, such as summarization of variance, space and time complexities of the proposed methods are investigated as well. The simulation results using YALE and ORL facial datasets with variable image resolutions show the superior performance of Bi-EFLPCA method with respect to feature dimensionality, memory efficiency, recognition accuracy, and speed over the existing variation of bidirectional 2DPCAs.
C1 [Sahoo, Tapan Kumar; Banka, Haider] Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad, Bihar, India.
   [Negi, Atul] Univ Hyderabad, Sch Comp & Informat Sci, Hyderabad, Telangana, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad; University of Hyderabad
RP Sahoo, TK (corresponding author), Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad, Bihar, India.
EM tapan@cse.ism.ac.in; haider@iitism.ac.in; atulcs@uohyd.ernet.in
RI Negi, Atul/ABD-1836-2020
OI Negi, Atul/0000-0001-5707-130X; Sahoo, Dr. Tapan
   Kumar/0000-0002-5838-0742
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   [Anonymous], 1989, Principal Components Analysis
   [Anonymous], 2012, Face recognition: From theory to applications
   [Anonymous], 2012, P 25 IEEE CAN C EL C
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Chen SC, 2004, PATTERN RECOGN, V37, P1081, DOI 10.1016/j.patcog.2003.09.004
   Choi Y, 2014, NEUROCOMPUTING, V134, P280, DOI 10.1016/j.neucom.2013.08.045
   Cormen T.H., 2009, INTRO ALGORITHMS
   Cunningham P., 2007, MULTIPLE CLASSIFIER, V34, P1, DOI DOI 10.1145/3459665
   Dornaika F, 2013, NEUROCOMPUTING, V99, P448, DOI 10.1016/j.neucom.2012.07.016
   Gao QX, 2019, IEEE T CYBERNETICS, V49, P1212, DOI 10.1109/TCYB.2018.2796642
   Gao QX, 2018, IEEE T CYBERNETICS, V48, P1672, DOI 10.1109/TCYB.2017.2712740
   GAUCH HG, 1982, ECOLOGY, V63, P1643, DOI 10.2307/1940105
   Hamdan B, 2018, J KING SAUD UNIV-COM, V30, P141, DOI 10.1016/j.jksuci.2016.10.006
   Huang GH, 2010, APPL MATH COMPUT, V216, P3195, DOI 10.1016/j.amc.2010.04.042
   Huang P, 2017, IEEE ACCESS, V5, P4340, DOI 10.1109/ACCESS.2017.2680437
   Huang SC, 2016, NEUROCOMPUTING, V208, P373, DOI 10.1016/j.neucom.2016.02.063
   Kumar KV, 2008, PATTERN RECOGN LETT, V29, P254, DOI 10.1016/j.patrec.2007.09.014
   Kumar KV, 2008, PATTERN RECOGN, V41, P1398, DOI 10.1016/j.patcog.2007.08.006
   LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Leng L., 2012, P INT C WAV AN PATT, P164, DOI DOI 10.1109/ICWAPR.2012.6294772
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Li T, 2017, NEURAL NETWORKS, V94, P204, DOI 10.1016/j.neunet.2017.07.011
   LUNTZ A, 1969, ESTIMATION CHARACTER
   Luo XL, 2019, PATTERN RECOGN, V93, P283, DOI 10.1016/j.patcog.2019.04.027
   Mashhoori A, 2013, NEUROCOMPUTING, V108, P111, DOI 10.1016/j.neucom.2012.12.005
   Negi Atul, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4170, DOI 10.1109/ICPR.2010.1013
   Ouyang AJ, 2020, NEUROCOMPUTING, V393, P214, DOI 10.1016/j.neucom.2019.01.117
   Pizer S. M., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P337, DOI 10.1109/VBC.1990.109340
   Rejeesh MR, 2019, MULTIMED TOOLS APPL, V78, P22691, DOI 10.1007/s11042-019-7577-5
   Rosen K.H., 2012, DISCRETE MATH ITS AP
   Sahoo TK, 2020, NEURAL COMPUT APPL, V32, P4897, DOI 10.1007/s00521-018-3892-4
   Sahoo TK, 2017, ARAB J SCI ENG, V42, P3337, DOI 10.1007/s13369-017-2493-3
   Sasirekha K, 2019, NEURAL COMPUT APPL, V31, P7935, DOI 10.1007/s00521-018-3624-9
   Scheevel JR, 2001, SPE RESERV EVAL ENG, V4, P64, DOI 10.2118/69739-PA
   Senthilkumar R, 2020, J SUPERCOMPUT, V76, P4476, DOI 10.1007/s11227-018-2408-4
   Tukey J.W., 1977, Exploratory Data Analysis, V2
   Turhal ÜÇ, 2015, APPL SOFT COMPUT, V29, P270, DOI 10.1016/j.asoc.2015.01.016
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Tzeng DY, 2005, COLOR RES APPL, V30, P84, DOI 10.1002/col.20086
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yeung KY, 2001, BIOINFORMATICS, V17, P763, DOI 10.1093/bioinformatics/17.9.763
   Yu Q, 2016, NEUROCOMPUTING, V171, P57, DOI 10.1016/j.neucom.2015.06.011
   Zhang DQ, 2005, NEUROCOMPUTING, V69, P224, DOI 10.1016/j.neucom.2005.06.004
   Zhang DQ, 2006, PATTERN RECOGN, V39, P140, DOI 10.1016/j.patcog.2005.08.002
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
   Zhao QJ, 2007, PATTERN RECOGN, V40, P1334, DOI 10.1016/j.patcog.2006.04.047
NR 49
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24491
EP 24531
DI 10.1007/s11042-021-10535-6
EA APR 2021
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000637685200003
DA 2024-07-18
ER

PT J
AU Haddad, M
   Ghassab, VK
   Najar, F
   Bouguila, N
AF Haddad, Mark
   Ghassab, Vahid K.
   Najar, Fatma
   Bouguila, Nizar
TI A statistical framework for few-shot action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; One-shot learning; K-shot learning; Mixture models;
   Information divergence; Action representation
AB Along with the exponential growth of online video creation platforms such as Tik Tok and Instagram, state of the art research involving quick and effective action/gesture recognition remains crucial. This work addresses the challenge of classifying short video clips, using a domain-specific feature design approach, capable of performing significantly well using as little as one training example per action. The method is based on Gunner Farneback's dense optical flow (GF-OF) estimation strategy, Gaussian mixture models, and information divergence. We first aim to obtain accurate representations of the human movements/actions by clustering the results given by GF-OF using K-means method of vector quantization. We then proceed by representing the result of one instance of each action by a Gaussian mixture model. Furthermore, using Kullback-Leibler divergence (KL-divergence), we attempt to find similarities between the trained actions and the ones in the test videos. Classification is done by matching each test video to the trained action with the highest similarity (a.k.a lowest KL-divergence). We have performed experiments on the KTH and Weizmann Human Action datasets using One-Shot and K-Shot learning approaches, and the results reveal the discriminative nature of our proposed methodology in comparison with state-of-the-art techniques.
C1 [Haddad, Mark; Ghassab, Vahid K.; Najar, Fatma; Bouguila, Nizar] Concordia Univ, Concordia Inst Informat Syst Engn CIISE, Montreal, PQ, Canada.
C3 Concordia University - Canada
RP Haddad, M (corresponding author), Concordia Univ, Concordia Inst Informat Syst Engn CIISE, Montreal, PQ, Canada.
EM mar_had@encs.concordia.ca; vahid.khorasani@concordia.ca;
   f_najar@encs.concordia.ca; nizar.bouguila@concordia.ca
RI Najar, Fatma/ITU-2763-2023
OI Haddad, Mark/0000-0003-3064-2381
CR [Anonymous], ICCV 05
   Avola D, 2019, MULTIMED TOOLS APPL, V78, P5919, DOI 10.1007/s11042-018-6875-7
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Chen YT, 2021, VISUAL COMPUT, V37, P1691, DOI 10.1007/s00371-020-01932-3
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02066-z
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112316
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Darrell T., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P335, DOI 10.1109/CVPR.1993.341109
   Ding L, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8891778
   Farnebäck G, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P171, DOI 10.1109/ICCV.2001.937514
   Farnebäck G, 2000, INT C PATT RECOG, P135
   Fu Y, 2018, ARXIV 180611230V2 CS
   Goldberger J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P487
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hershey JR, 2007, INT CONF ACOUST SPEE, P317, DOI 10.1109/icassp.2007.366913
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Kapsouras I, 2019, MULTIMED TOOLS APPL, V78, P1971, DOI 10.1007/s11042-018-6209-9
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Miller EG, 2000, PROC CVPR IEEE, P464, DOI 10.1109/CVPR.2000.855856
   Najar F, 2019, MULTIMED TOOLS APPL, V78, P18669, DOI 10.1007/s11042-018-7116-9
   Rodriguez M, 2017, IEEE COMPUT SOC CONF, P1259, DOI 10.1109/CVPRW.2017.166
   Rodriguez M, 2017, IEEE T CYBERNETICS, V47, P1769, DOI 10.1109/TCYB.2016.2558447
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Seo HJ, 2011, IEEE T PATTERN ANAL, V33, P867, DOI 10.1109/TPAMI.2010.156
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P1635, DOI 10.1109/TPAMI.2012.253
   Yilmaz A, 2005, IEEE I CONF COMP VIS, P150
   Yilmaz A, 2005, PROC CVPR IEEE, P984
   Yu F, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/4047957
   Yu F, 2019, NEUROCOMPUTING, V350, P108, DOI 10.1016/j.neucom.2019.03.053
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhang JM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041188
   Zhou LY, 2020, IEEE ACCESS, V8, P30436, DOI 10.1109/ACCESS.2020.2972269
NR 45
TC 2
Z9 2
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24303
EP 24318
DI 10.1007/s11042-021-10721-6
EA APR 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000636933000004
DA 2024-07-18
ER

PT J
AU Biswas, R
   Roy, S
AF Biswas, Rajib
   Roy, Sambuddha
TI Botnet traffic identification using neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Botnet; LSTM; GRU; Deep learning; Neural networks; Network intrusion
ID INTERNET
AB Advancement of information and communication techniques have led to share big amount of information which is increasing day by day through online activities and creating new added value over the internet services. At the same time threats to the security of cyber world has been increased with increasing number of heterogeneous connection points having powerful computational capacity. Internet being used to interact and control such automatic network devices connected to it. But hackers/crackers can exploit this network environment by putting malicious dummy node(s) or machine(s) called Botnet(s) to co-ordinate the attacks on security such as Denial of Service (DoS) or Distributed Denial of Service (DDoS). The proposed method attempts to identify those mallicious Botnet traffic from regular traffic using novel deep learning approaches like Artificial Neural Networks (ANN), Gatted Recurrent Units (GRU), Long or Short Term Memory (LSTM) model. The proposed model demonstrates significant improvement of all previous works. The testing dataset, Bot-IoT dataset is the latest and one of the largest public domain dataset used to justify improvement. Testing shows 99.7% classification accuracy which is precise and better than all previous works done. Results analysis and comparison shows the accuracy and supremacy over the latest work done on this field.
C1 [Biswas, Rajib] Heritage Inst Technol, Kolkata, India.
   [Roy, Sambuddha] Tata Consultancy Serv, Mumbai, Maharashtra, India.
C3 Heritage Institute of Technology (HITK); Tata Sons; Tata Consultancy
   Services Limited (TCS)
RP Biswas, R (corresponding author), Heritage Inst Technol, Kolkata, India.
EM rajib.biswas.rd@gmail.com; sambuddhaxroy@gmail.com
RI Biswas, Rajib/H-3561-2013
CR Alomari E, 2014, INT CONF ADV COMMUN, P1265, DOI 10.1109/ICACT.2014.6779162
   [Anonymous], 1997, NEURAL COMPUT
   Apthorpe N.J., 2017, ABS170506805 CORR
   Bartlett G, 2007, ISITR2007642 USC
   Beigi EB, 2014, IEEE CONF COMM NETW, P247, DOI 10.1109/CNS.2014.6997492
   Cabrera JBD, 2000, 8TH INTERNATIONAL SYMPOSIUM ON MODELING, ANALYSIS AND SIMULATION OF COMPUTER AND TELECOMMUNICATION SYSTEMS, PROCEEDINGS, P466, DOI 10.1109/MASCOT.2000.876573
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Cui LZ, 2018, INT J MACH LEARN CYB, V9, P1399, DOI 10.1007/s13042-018-0834-5
   Doshi R, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P29, DOI 10.1109/SPW.2018.00013
   Fernández-Delgado M, 2014, J MACH LEARN RES, V15, P3133
   HADIANTO R., 2018, International Journal of Applied Engineering Research, V13, P483
   Hao S., 2000, USENIX SEC S, V9
   Hoque N, 2014, J NETW COMPUT APPL, V40, P307, DOI 10.1016/j.jnca.2013.08.001
   Jesudoss A., 2014, Indian J. Comput. Sci. Eng., V5, P71
   Kolias C, 2017, COMPUTER, V50, P80, DOI 10.1109/MC.2017.201
   Koroniotis N, 2019, FUTURE GENER COMP SY, V100, P779, DOI 10.1016/j.future.2019.05.041
   Revathi S., 2013, Int. Journal of Engineering Research and Technology, V2
   Sharafaldin I, 2018, ICISSP: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS SECURITY AND PRIVACY, P108, DOI 10.5220/0006639801080116
   Shiravi A, 2012, COMPUT SECUR, V31, P357, DOI 10.1016/j.cose.2011.12.012
   Sivanathan Arunan., 2016, 2016 IEEE International Conference on Advanced Networks and Telecommunications Systems (ANTS), P1, DOI DOI 10.1109/ANTS.2016.7947781
   Soni D., 2017, INT C TEL POW AN COM, V20, P173
   Srivastava T, 2014, SIMPLIFIED 1020
   Tankard Colin, 2011, Network Security, V2011, P16, DOI 10.1016/S1353-4858(11)70086-1
   Tavallaee M., 2009, P 2009 IEEE S COMPUT, P1, DOI DOI 10.1109/CISDA.2009.5356528
   Thomas R, 2018, 2018 FIFTH HCT INFORMATION TECHNOLOGY TRENDS (ITT): EMERGING TECHNOLOGIES FOR ARTIFICIAL INTELLIGENCE, P286, DOI 10.1109/CTIT.2018.8649498
   Wang XZ, 2020, INT J MACH LEARN CYB, V11, P747, DOI 10.1007/s13042-020-01096-5
   Yuan XY, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP), P9, DOI 10.1109/smartcomp.2017.7946998
NR 27
TC 15
Z9 17
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24147
EP 24171
DI 10.1007/s11042-021-10765-8
EA APR 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000635850500001
DA 2024-07-18
ER

PT J
AU Shah, D
   Shah, T
   Ahamad, I
   Haider, MI
   Khalid, I
AF Shah, Dawood
   Shah, Tariq
   Ahamad, Imtiaz
   Haider, Muhammad Imran
   Khalid, Ijaz
TI A three-dimensional chaotic map and their applications to digital audio
   security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic map; Galois field; Symmetric key cryptography; Audio encryption
AB In nonlinear dynamical systems, chaotic behavior is an attractive characteristic that has been broadly examined and researched over the most recent few decades. The chaotic systems are widely used in artificial intelligence and cryptology. Especially, these are considered efficient for multimedia data security. This manuscript has introduced a novel three dimensional (3-D) chaotic systems. The proposed maps are investigated through bifurcation diagrams and phase plots. The resulting diagrams demonstrates the chaotic attractor characteristic and the dynamic behavior of the suggested maps. Furthermore, a lossless audio encryption scheme is introduced utilizing the proposed chaotic maps. In the suggested scheme, the suggested 3-D chaotic sequences are utilized to shuffle the audio data points to achieve the diffusion property. In the confusion module, initially, the sequence of the audio data is divided into 8-bit and 7-bit sequences. Subsequently, the separated sequences are then substituted with different good quality substitution boxes, which are generated through a Mobius transformation over Galois fields. The suggested encryption algorithm is applied to the different audio files of various sizes and characters. The experimental results have revealed that the proposed scheme is capable to secure all kinds of audio files. The security analysis shows that the suggested scheme is capable to withstand differential and statistical attacks.
C1 [Shah, Dawood; Shah, Tariq; Haider, Muhammad Imran; Khalid, Ijaz] Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.
   [Ahamad, Imtiaz] Univ Swabi, Dept Math, Khyber Pakhtunkhwa, Pakistan.
C3 Quaid I Azam University
RP Shah, D (corresponding author), Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.
EM Dawoodshah254@gmail.com
RI Ahmad, Imtiaz/AAY-3657-2020
OI Ahmad, Imtiaz/0000-0002-4023-3293
CR [Anonymous], 2019, PHYSICA A
   Au OC, 2010, IEEE INT C AC SPEECH
   Ben Farah MA, 2020, MULTIMED TOOLS APPL, V79, P19129, DOI 10.1007/s11042-020-08718-8
   Ben Farah MA, 2011, COMMUN NONLINEAR SCI, V16, P2543, DOI 10.1016/j.cnsns.2010.09.005
   Bhargava B, 2004, MULTIMED TOOLS APPL, V24, P57, DOI 10.1023/B:MTAP.0000033983.62130.00
   Conrad E, 1997, CISC VIS NETW IND GL
   De Martin JC, 2003, IEEE INT C AC SPEECH, V5
   Gopakumar K, 2019, APPL COMPUTING INFOR
   Grangetto M, 2006, IEEE T MULTIMEDIA, V8, P905, DOI 10.1109/TMM.2006.879919
   Habib Z, 2017, 4 INT C EL EL ENG IC
   Haider MI, 2021, MULTIMED TOOLS APPL, V80, P4693, DOI 10.1007/s11042-020-09892-5
   Hussain Sadam, 2020, IEEE ACCESS
   Jahangir S, 2020, MULTIMED TOOLS APPL, V79, P26885, DOI 10.1007/s11042-020-08995-3
   Kalpana M, 2019, MULTIMED TOOLS APPL, V78, P5969, DOI 10.1007/s11042-018-6373-y
   Khan M, 2019, INT J THEOR PHYS, V58, P4293, DOI 10.1007/s10773-019-04301-6
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Kordov K, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8050530
   Lima JB, 2016, MULTIMED TOOLS APPL, V75, P8403, DOI 10.1007/s11042-015-2755-6
   Madain A, 2014, MULTIMED TOOLS APPL, V71, P1803, DOI 10.1007/s11042-012-1306-7
   Min L, 2013, 9 INT C COMP INT SEC
   Mosa E, 2011, INT J SPEECH TECHNOL, V14, P285, DOI 10.1007/s10772-011-9103-7
   Naseer Y, 2019, MICROPROCESS MICROSY, V65, P1, DOI 10.1016/j.micpro.2018.12.003
   Naskar PK, 2019, MULTIMED TOOLS APPL, V78, P25019, DOI 10.1007/s11042-019-7696-z
   Rivest, 1994, INT WORKSH FAST SOFT
   Sathiyamurthi P, 2017, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-017-0118-0
   Servetti A, 2002, IEEE T SPEECH AUDI P, V10, P637, DOI 10.1109/TSA.2002.804300
   Shah T, 2020, MICROPROCESSORS
   Shah T, 2020, IEEE ACCESS, V8, P52609, DOI 10.1109/ACCESS.2020.2978083
   Shah T, 2019, MULTIMED TOOLS APPL, V78, P1219, DOI 10.1007/s11042-018-6250-8
   Standard Data Encryption, FEDERAL INFORM PROCE, V46, P23
   Thorwirth NJ, 2000, 34 AS C SIGN SYST CO, V2
   ul Haq T, 2020, OPTIK, V217, DOI 10.1016/j.ijleo.2020.164922
   Ullah A, 2019, MULTIMED TOOLS APPL, V78, P32467, DOI 10.1007/s11042-019-07957-8
   Ullah A, 2018, NONLINEAR DYNAM, V91, P359, DOI 10.1007/s11071-017-3874-6
   Waseem HM, 2020, IEEE ACCESS, V8, P71821, DOI 10.1109/ACCESS.2020.2987097
   Waseem HM, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.6.063022
   Yan WQ, 2008, IEEE T MULTIMEDIA, V10, P960, DOI 10.1109/TMM.2008.2001373
   ZIMMERMANN R, 1994, IEEE J SOLID-ST CIRC, V29, P303, DOI 10.1109/4.278352
NR 38
TC 11
Z9 11
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 22251
EP 22273
DI 10.1007/s11042-021-10697-3
EA MAR 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000633324300002
DA 2024-07-18
ER

PT J
AU Pal, P
   Jana, B
   Bhaumik, J
AF Pal, Pabitra
   Jana, Biswapati
   Bhaumik, Jaydeb
TI A secure reversible color image watermarking scheme based on LBP,
   lagrange interpolation polynomial and weighted matrix
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible watermarking; Weighted matrix; Local binary pattern; Lagrange
   interpolation polynomial; Tamper detection
ID DATA HIDING SCHEME; CLASSIFICATION; STEGANOGRAPHY; PAYLOAD
AB Secure reversible watermarking schemes are essential for image authentication and tamper detection in medical, military and government applications. In this paper, a secure reversible color image watermarking scheme has been proposed considering the merits of three individual tools namely Local Binary Pattern (LBP), Lagrange Interpolation Polynomial (LIP) and Weighted Matrix (WM). The proposed reversible scheme has been designed to address the issues related to image authentication and tamper detection. Here, LBP operator is employed to generate Tamper Detection Code (TDC), LIP and WM are used to embed watermark within the sub-sampled images. Authentication is accomplished by utilizing an Authentication Code (AC), which is generated from binary string of watermark logo using a Secure Hash Algorithm (SHA-512). Repeated entry-wise-multiplication operations have been performed with each sub-sampled image block to increase the payload without affecting visual quality of the watermarked image significantly. Some standard NIST recommended steganalysis and attacks are conducted to evaluate its robustness and imperceptibility. It is observed that the developed scheme is secure and robust against several attacks as well as can detect tampered regions. Experimental results are compared with the state-of-the-art schemes to present the merits of our scheme.
C1 [Pal, Pabitra; Jana, Biswapati] Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
   [Bhaumik, Jaydeb] Jadavpur Univ, Dept ETCE, Kolkata 700032, India.
C3 Vidyasagar University; Jadavpur University
RP Jana, B (corresponding author), Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
EM pabipaltra@gmail.com; biswapatijana@gmail.com; bhaumik.jaydeb@gmail.com
RI Jana, Prof. Biswapati/AAA-2154-2019
OI Jana, Prof. Biswapati/0000-0003-4476-3459
CR Agarwal N, 2019, MULTIMED TOOLS APPL, V78, P8603, DOI 10.1007/s11042-018-7128-5
   Banerjee A, 2019, MULTIMED TOOLS APPL, V78, P24903, DOI 10.1007/s11042-019-7626-0
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Fan L, 2013, COMPUT ELECTR ENG, V39, P873, DOI 10.1016/j.compeleceng.2012.06.014
   Funt, 2017, HDR DATASET COMPUTAT
   Garg P, 2020, MULTIMED TOOLS APPL, V79, P25921, DOI 10.1007/s11042-020-09262-1
   Hu J, 2015, COMPUT ELECTR ENG, V46, P447, DOI 10.1016/j.compeleceng.2015.04.014
   Jana B, 2016, OPTIK, V127, P3347, DOI 10.1016/j.ijleo.2015.12.055
   Jung KH, 2018, MULTIMED TOOLS APPL, V77, P7795, DOI 10.1007/s11042-017-5066-2
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Kumar S, 2020, MULTIMED TOOLS APPL, V79, P20149, DOI 10.1007/s11042-020-08881-y
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin PY, 2010, PATTERN RECOGN LETT, V31, P1887, DOI 10.1016/j.patrec.2010.01.019
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Mohammad AA, 2019, MULTIMED TOOLS APPL, V78, P7181, DOI 10.1007/s11042-018-6465-8
   Nottingham Trent University, 2017, UK UCID IM DAT
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pal P, 2018, MULTIMED TOOLS APPL, V77, P23073, DOI 10.1007/s11042-017-5568-y
   Parah SA, 2017, INTEL SYST REF LIBR, V115, P223, DOI 10.1007/978-3-319-44270-9_10
   Pinjari Shakil A., 2016, 2016 International Conference on Global Trends in Signal Processing, Information Computing and Communication (ICGTSPICC). Proceedings, P194, DOI 10.1109/ICGTSPICC.2016.7955296
   Sarkar D, 2020, MULTIMED TOOLS APPL, V79, P17761, DOI 10.1007/s11042-020-08669-0
   Shin SH, 2016, MULTIMED TOOLS APPL, V75, P13931, DOI 10.1007/s11042-016-3844-x
   Su QT, 2013, OPTIK, V124, P6255, DOI 10.1016/j.ijleo.2013.05.013
   Tseng YC, 2002, IEEE T COMMUN, V50, P1227, DOI 10.1109/TCOMM.2002.801488
   University of California, 2017, SAN DIEG STAR IM DAT
   University of Southern California, 2017, USC SIPI IMAGE DATAB
   Verma VS, 2015, EXPERT SYST APPL, V42, P8184, DOI 10.1016/j.eswa.2015.06.041
   Wang WQ, 2020, MULTIMED TOOLS APPL, V79, P555, DOI 10.1007/s11042-019-08065-3
   WENYIN Z, 2011, OPT COMMUN, V284, P3904, DOI DOI 10.1016/J.OPTCOM.2011.04.004
   Wu X, 2020, MANAGEMENT TRANSFORMATION OF HUAWEI, P1, DOI 10.1017/9781108550987
   Zhang H, 2017, J INF PROCESS SYST, V13, P1382, DOI 10.3745/JIPS.02.0063
NR 33
TC 15
Z9 16
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21651
EP 21678
DI 10.1007/s11042-021-10651-3
EA MAR 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000630281200002
DA 2024-07-18
ER

PT J
AU Kagawade, VC
   Angadi, SA
AF Kagawade, Vishwanath C.
   Angadi, Shanmukhappa A.
TI VISA: a multimodal database of face and iris traits
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face; Iris; Database; VISA; Unimodal; Multimodal; Biometric; FFT; HoG;
   Gabor
ID RECOGNITION; VERIFICATION; ILLUMINATION
AB In this paper, a new realistic and challenging Face-Iris multimodal biometric database called VISA database is described. One significant problem associated with the development and evaluation of multimodal biometric systems using face and iris biometric traits is the lack of publicly available multimodal databases that are acquired in an unconstrained environment. Currently, there exist no multimodal databases containing a sufficient number of common subjects involved in both face and iris data acquisition process under different conditions. The VISA database fulfills these requirements and it will be a useful tool for the design and development of new algorithms for developing multimodal biometric systems. The VISA iris images are acquired using the IriShield camera. Face images are captured using mobile device. The corpus of a new VISA database consists of face images that vary in expression, pose and illumination, and presence of occlusion whereas iris images vary in illumination, eye movement, and occlusion. A total of more than 5000 images of 100 subjects are collated and used to form the new database. The key features of the VISA dataset are the wide and diverse population of subjects (age and gender). The VISA database is able to support face and/or iris unimodal or multimodal biometric recognition. Hence, the VISA database is a useful addition for the purpose of research and development of biometric systems based on face and iris biometrics. This paper also describes the baseline results of state-of-the-art methods on the VISA dataset and other popular similar datasets. The VISA database will be made available to the public through https://vtu.ac.in/en/visa-multimodal-face-and-iris-biometrics-database/
C1 [Kagawade, Vishwanath C.] Basaveshwar Engn Coll, Dept Comp Applicat, Bagalkot, India.
   [Angadi, Shanmukhappa A.] VTU, Dept Comp Sci & Engn, Ctr Post Grad Studies, Belagavi, India.
C3 Visvesvaraya Technological University
RP Kagawade, VC (corresponding author), Basaveshwar Engn Coll, Dept Comp Applicat, Bagalkot, India.
EM vishwanath.1312@gmail.com; vinay_angadi@yahoo.com
RI Kagawade, Vishwanath/J-8227-2019
OI Kagawade, Vishwanath/0000-0002-7934-8629; Angadi,
   Shanmukhappa/0000-0001-9756-9786
CR Angadi SA, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER, AND OPTIMIZATION TECHNIQUES (ICEECCOT - 2018), P172, DOI 10.1109/ICEECCOT43722.2018.9001636
   Angadi SA, 2017, PATTERN RECOGN, V71, P235, DOI 10.1016/j.patcog.2017.06.014
   [Anonymous], 2021, MMU DATABASE
   Benalcazar DP, 2020, IEEE ACCESS, V8, P98584, DOI 10.1109/ACCESS.2020.2996563
   Benavente R, 1998, AR DATABASE
   Bianco S, 2017, PATTERN RECOGN LETT, V90, P36, DOI 10.1016/j.patrec.2017.03.006
   Chen YF, 2020, IEEE ACCESS, V8, P32365, DOI 10.1109/ACCESS.2020.2973433
   Chu CT, 2005, PROC INT C TOOLS ART, P417
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Dessimoz D, 2007, FORENSIC SCI INT, V167, P154, DOI 10.1016/j.forsciint.2006.06.037
   Dobes M, 2006, OPTIK, V117, P468, DOI 10.1016/j.ijleo.2005.11.008
   Dumas B., 2005, 3 COST 275 WORKSH CO, P59
   Eskandari M, 2017, IET BIOMETRICS, V6, P334, DOI 10.1049/iet-bmt.2016.0060
   Fierrez J, 2010, PATTERN ANAL APPL, V13, P235, DOI 10.1007/s10044-009-0151-4
   Fierrez J, 2007, PATTERN RECOGN, V40, P1389, DOI 10.1016/j.patcog.2006.10.014
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gross J., 2001, Tech. Rep. CMU-RI-TR-01-18, V45, P1
   Hassaballah M, 2015, IET COMPUT VIS, V9, P614, DOI 10.1049/iet-cvi.2014.0084
   Hassaballah M., 2011, International Journal of Computer Science Issues (IJCSI), V8, P272
   Hassaballah M., 2019, Recent Advances in Computer Vision, P33
   He LX, 2019, IEEE T IMAGE PROCESS, V28, P791, DOI 10.1109/TIP.2018.2870946
   Ho CC, 2013, PATTERN RECOGN LETT, V34, P2043, DOI 10.1016/j.patrec.2013.01.027
   Hong S, 2020, IEEE SIGNAL PROC LET, V27, P156, DOI 10.1109/LSP.2019.2963001
   Ido S, 2011, MVA2011 IAPR C MACH
   Kagawade VC, 2017, 6 IEEE INT C ADV COM
   Kagawade VC, 2017, INT C SMART TECHN SM
   Kagawade VC, 2019, IMAGE VISION COMPUT, V83-84, P39, DOI 10.1016/j.imavis.2019.02.001
   Khalaf ET, 2018, IET BIOMETRICS, V7, P589, DOI 10.1049/iet-bmt.2017.0130
   Khan MT, 2013, FEATURE EXTRACTION I
   Khanna, 1994, AUTOMATED FINGERPRIN, P188
   Li P, 2019, IEEE T INF FOREN SEC, V14, P2000, DOI 10.1109/TIFS.2018.2890812
   Liu M, 2020, IEEE T FUZZY SYST, V28, P92, DOI 10.1109/TFUZZ.2019.2912576
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2015, INT CONF ACOUST SPEE, P1498, DOI 10.1109/ICASSP.2015.7178220
   Luo ZD, 2019, PROC INT C TOOLS ART, P1237, DOI 10.1109/ICTAI.2019.00-95
   Magalhaes, 2012, LECT NOTES COMPUTER
   Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144
   Mokhayeri F, 2019, IEEE T INF FOREN SEC, V14, P757, DOI 10.1109/TIFS.2018.2866295
   Nguyen K, 2020, IEEE T IMAGE PROCESS, V29, P7166, DOI 10.1109/TIP.2020.2999211
   Ortega-Garcia J, 2010, IEEE T PATTERN ANAL, V32, P1097, DOI 10.1109/TPAMI.2009.76
   Phillips PJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P15
   Poornima S, 2016, SMART INNOV SYST TEC, V51, P287, DOI 10.1007/978-3-319-30927-9_29
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Struc, 2009, GABOR BASED KERNEL P, V20, P115, DOI [10.15388/Informatica.2009.240, DOI 10.15388/INFORMATICA.2009.240]
   Wang CY, 2020, IEEE T INF FOREN SEC, V15, P2944, DOI 10.1109/TIFS.2020.2980791
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Xu X, 2017, INT S INT SIGN PROC
   Yang H, 2020, IEEE ACCESS, V8, P159143, DOI 10.1109/ACCESS.2020.3007205
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhao DD, 2018, IEEE T DEPEND SECURE, V15, P112, DOI 10.1109/TDSC.2015.2507133
   Zheng S, 2011, IEEE IMAGE PROC, DOI 10.1109/ICIP.2011.6115889
NR 53
TC 4
Z9 4
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21615
EP 21650
DI 10.1007/s11042-021-10650-4
EA MAR 2021
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000629886000003
DA 2024-07-18
ER

PT J
AU Charef-Khodja, D
   Toumi, A
   Medouakh, S
   Sbaa, S
AF Charef-Khodja, Djemai
   Toumi, Abida
   Medouakh, Saadia
   Sbaa, Salim
TI Efficient visual tracking approach via whale optimizer and corrected
   background weighted histogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE WOA algorithm; Object tracking; Metaheuristics; CBWH
ID OBJECT TRACKING
AB There are mainly two components in almost every visual object tracking algorithm, which are the object presentation and the searching mechanism. In the literature, metaheuristic algorithms have been recently, widely used as searching method in visual tracking. In fact, the more discriminative is their combined object presentation the better is their precision. Salient background information is often inside the first detected region of the object, which may decrease considerably the tracking performance. In this work, we combine a powerful metaheuristic searching method, whale optimization algorithm (WOA), with the discriminative presentation named as corrected background weighted histogram (CBWH) to improve the tracking accuracy in difficult environments. WOA algorithm is used because of its strong searching ability, which enable it avoid being trapped in local optimum, and also its lowest computation cost compared to other metaheuristic algorithms. The WOA sensitivity parameters are studied experimentally to be adjusted in visual tracking. For a fair assessment of the proposed approach, its performance has been evaluated on 20 video sequences, from the famous object tracking benchmark OTB15, and compared with six (6) other state-of-art trackers. The evaluations were carried quantitatively and qualitatively on challenging situations and have provided satisfying results. The experimental results shows that WOA combined with CBWH can lead to further improvement, and better success rate in tracking.
C1 [Charef-Khodja, Djemai; Toumi, Abida; Sbaa, Salim] Mohamed Khider Univ Biskra, Res Lab Expert Syst Imaging & their Applicat Engn, Biskra, Algeria.
   [Medouakh, Saadia] Mohamed Khider Univ Biskra, Dept Elect Engn, Biskra, Algeria.
C3 Universite Mohamed Khider Biskra; Universite Mohamed Khider Biskra
RP Charef-Khodja, D (corresponding author), Mohamed Khider Univ Biskra, Res Lab Expert Syst Imaging & their Applicat Engn, Biskra, Algeria.
EM djemai.charefkhodja@univ-biskra.dz; a.toumi@univ-Biskra.dz;
   saadia.medouakh@univ-Biskra.dz; s.sbaa@univ-Biskra.dz
OI CHAREF-KHODJA, Djemai/0000-0003-4572-0194
CR Bae C, 2016, EXPERT SYST APPL, V64, P385, DOI 10.1016/j.eswa.2016.08.027
   Charef-Khodja Djemai, 2020, 2020 1st International Conference on Communications, Control Systems and Signal Processing (CCSSP), P180, DOI 10.1109/CCSSP49278.2020.9151714
   Charef-Khodja D, 2021, SIGNAL IMAGE VIDEO P, V15, P331, DOI 10.1007/s11760-020-01748-7
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Gao ML, 2016, NEUROCOMPUTING, V177, P612, DOI 10.1016/j.neucom.2015.11.072
   Gao ML, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.7.073105
   Gao ML, 2013, IET COMPUT VIS, V7, P227, DOI 10.1049/iet-cvi.2012.0207
   Kate P, 2018, INT C PATT RECOG, P2570, DOI 10.1109/ICPR.2018.8546216
   Krishnamoorthy ES, 2017, EPILEPSY: A GLOBAL APPROACH, P1
   Liu G, 2016, IEEE IJCNN, P169, DOI 10.1109/IJCNN.2016.7727195
   Liu TL, 2004, IEEE T PATTERN ANAL, V26, P397, DOI 10.1109/TPAMI.2004.1262335
   Medouakh S, 2018, SIGNAL IMAGE VIDEO P, V12, P583, DOI 10.1007/s11760-017-1196-2
   Meng OK, 2019, APPL SOFT COMPUT, V83, DOI 10.1016/j.asoc.2019.105625
   Meng OK, 2019, J PHYS CONF SER, V1150, DOI 10.1088/1742-6596/1150/1/012023
   Mihaylova L, 2014, DIGIT SIGNAL PROCESS, V25, P1, DOI 10.1016/j.dsp.2013.11.006
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Moghaddasi SS, 2020, EXPERT SYST APPL, V147, DOI 10.1016/j.eswa.2020.113188
   Narayana M, 2019, OPTIK, V193, DOI 10.1016/j.ijleo.2019.06.013
   Nenavath H, 2018, SWARM EVOL COMPUT, V43, P1, DOI 10.1016/j.swevo.2018.02.011
   Ning J, 2012, IET COMPUT VIS, V6, P62, DOI 10.1049/iet-cvi.2009.0075
   Oron S, 2015, INT J COMPUT VISION, V111, P213, DOI 10.1007/s11263-014-0740-6
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Sardari F, 2017, APPL SOFT COMPUT, V50, P280, DOI 10.1016/j.asoc.2016.11.028
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang F, 2014, IEEE T IMAGE PROCESS, V23, P1639, DOI 10.1109/TIP.2014.2300823
   Yeung HWF, 2016, LECT NOTES COMPUT SC, V9947, P213, DOI 10.1007/978-3-319-46687-3_23
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yu S, 2019, IEEE T IMAGE PROCESS, V28, P1513, DOI 10.1109/TIP.2018.2878331
   Zhang H, 2019, LECT NOTES COMPUTER, V11857, DOI 10.1007/978-3-030-31654-9_19
   Zhang HL, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-0491-y
   Zhang HL, 2018, IEEE ACCESS, V6, P75383, DOI 10.1109/ACCESS.2018.2872524
   Zhang HL, 2018, IET COMPUT VIS, V12, P763, DOI 10.1049/iet-cvi.2017.0554
   Zhou ZP, 2017, MULTIMED TOOLS APPL, V76, P2979, DOI 10.1007/s11042-015-3211-3
NR 35
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21381
EP 21407
DI 10.1007/s11042-021-10691-9
EA MAR 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000629494100002
DA 2024-07-18
ER

PT J
AU Zhang, GQ
   Jiang, T
   Yang, JC
   Xu, J
   Zheng, YH
AF Zhang, Guoqing
   Jiang, Tong
   Yang, Junchuan
   Xu, Jiang
   Zheng, Yuhui
TI Cross-view kernel collaborative representation classification for person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Collaborative representation; Cross-view
   learning; Kernel method
AB Currently, person re-identification (re-ID) has been applied in many public security applications. Yet owing to the big visual appearance changes of the same identity under different views, re-ID still faces many challenges. To reduce the intra-person discrepancy, extracting more power feature representations from pedestrian images is a reasonable solution. We propose a cross-view kernel collaborative representation based classification (CV-KCRC) method for person re-ID in our work. Our method aims to find more robust and discriminative feature representations that embody cross-view information to enhance the identification capability of features. We map the image features into a high dimensional feature space first and then use view-specific projection matrices to project the high dimensional features into a common low dimensional subspace. We expect that in the shared subspace the codings of same person from different views have the highest similarity and better performance can be achieved. Experiments on seven commonly used datasets reveal that our algorithm outperforms many state-of-the-art algorithms.
C1 [Zhang, Guoqing; Jiang, Tong; Yang, Junchuan; Xu, Jiang; Zheng, Yuhui] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.
C3 Nanjing University of Information Science & Technology
RP Zhang, GQ (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.
EM xiayang14551@163.com
RI zhang, guoqing/GXG-4800-2022
OI guoqing, zhang/0000-0002-8741-8607
FU National Natural Science Foundation of China [61806099]; Natural Science
   Foundation of Jiangsu Province of China [BK20180790]; Natural Science
   Research of Jiangsu Higher Education Institutions of China [8KJB520033];
   Research Start-up Fund of NUIST [2243141701077]; Priority Academic
   Program Development of Jiangsu Higher Education Institutions (PAPD);
   Engineering Research Center of Digital Forensics, Ministry of Education
FX This research is supported in part by the National Natural Science
   Foundation of China under Grant 61806099; and by the Natural Science
   Foundation of Jiangsu Province of China under Grant BK20180790; and by
   the Natural Science Research of Jiangsu Higher Education Institutions of
   China under Grant 8KJB520033; and by Research Start-up Fund of NUIST
   under Grant 2243141701077. This research is also supported in part by
   the Priority Academic Program Development of Jiangsu Higher Education
   Institutions (PAPD) fund, in part by the Engineering Research Center of
   Digital Forensics, Ministry of Education.
CR An L, 2016, INFORM SCIENCES, V355, P74, DOI 10.1016/j.ins.2016.02.055
   [Anonymous], 2019, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2019.00225
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142
   Chen SZ, 2016, IEEE T IMAGE PROCESS, V25, P2353, DOI 10.1109/TIP.2016.2545929
   Chen YC, 2018, IEEE T PATTERN ANAL, V40, P392, DOI 10.1109/TPAMI.2017.2666805
   Chen YC, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3402
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Dai J, 2018, PATTERN RECOGN, V75, P63, DOI 10.1016/j.patcog.2017.04.022
   Gray D., 2007, P IEEE INT WORKSH PE, V3, P41
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   He SM, 2020, CMC-COMPUT MATER CON, V62, P321, DOI 10.32604/cmc.2020.06130
   Hu HM, 2019, IEEE T CIRC SYST VID, V29, P2809, DOI 10.1109/TCSVT.2018.2869898
   Huang S, 2015, ARXIV 151105169
   Jose C, 2016, LECT NOTES COMPUT SC, V9909, P875, DOI 10.1007/978-3-319-46454-1_53
   Karanam S, 2019, IEEE T PATTERN ANAL, V41, P523, DOI 10.1109/TPAMI.2018.2807450
   Kodirov E, 2015, P BRIT MACH VIS C BM, V3
   Leng QM, 2020, IEEE T CIRC SYST VID, V30, P1092, DOI 10.1109/TCSVT.2019.2898940
   Li HF, 2020, IEEE T IMAGE PROCESS, V29, P7345, DOI 10.1109/TIP.2020.3001424
   Li JB, 2008, INFORM SCIENCES, V178, P1825, DOI 10.1016/j.ins.2007.12.001
   Li K, 2018, AAAI CONF ARTIF INTE, P2331
   Li S, 2018, IEEE T PATTERN ANAL, V40, P2963, DOI 10.1109/TPAMI.2017.2764893
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu C, 2020, PROC CVPR IEEE, P6886, DOI 10.1109/CVPR42600.2020.00692
   Loy CC, 2009, PROC CVPR IEEE, P1988, DOI 10.1109/CVPRW.2009.5206827
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Mika S., 1999, NNSP, V1999, P41, DOI DOI 10.1109/NNSP.1999.788121
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Prates R, 2019, J VIS COMMUN IMAGE R, V58, P304, DOI 10.1016/j.jvcir.2018.12.003
   Prates R, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P249, DOI 10.1109/AVSS.2016.7738030
   Prates RF, 2016, INT C PATT RECOG, P2091, DOI 10.1109/ICPR.2016.7899944
   Roth PM, 2014, ADV COMPUT VIS PATT, P247, DOI 10.1007/978-1-4471-6296-4_12
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Sun XX, 2019, PROC CVPR IEEE, P608, DOI 10.1109/CVPR.2019.00070
   Tian C, 2015, IEEE SIGNAL PROC LET, V22, P1595, DOI 10.1109/LSP.2014.2372338
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu S., 2016, P IEEE WINT C APPL C, P1, DOI [DOI 10.1080/10298436.2016.1248204, DOI 10.1109/WACV.2016.7477681]
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Zhang GQ, 2020, NEUROCOMPUTING, V391, P177, DOI 10.1016/j.neucom.2020.01.101
   Zhang GQ, 2020, IEEE T CIRC SYST VID, V30, P1065, DOI 10.1109/TCSVT.2019.2902672
   Zhang GQ, 2019, MULTIMED TOOLS APPL, V78, P30175, DOI 10.1007/s11042-018-7007-0
   Zhang GQ, 2017, IEEE T IMAGE PROCESS, V26, P5922, DOI 10.1109/TIP.2017.2745684
   Zhang GQ, 2016, PATTERN RECOGN, V60, P613, DOI 10.1016/j.patcog.2016.06.012
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang Y, 2016, PROC CVPR IEEE, P1278, DOI 10.1109/CVPR.2016.143
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zheng Liang, 2017, P IEEE C COMP VIS PA, P3346, DOI DOI 10.1109/CVPR.2017.357
   Zheng W, 2009, P BRIT MACH VIS C BM
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhou Q., 2019, IEEE Transactions on Image Processing, P1
   Zhou Q, 2017, PATTERN RECOGN, V72, P196, DOI 10.1016/j.patcog.2017.06.026
NR 62
TC 5
Z9 5
U1 5
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20687
EP 20705
DI 10.1007/s11042-021-10671-z
EA MAR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000626812700002
DA 2024-07-18
ER

PT J
AU Narang, SR
   Kumar, M
   Jindal, MK
AF Narang, Sonika Rani
   Kumar, Munish
   Jindal, M. K.
TI DeepNetDevanagari: a deep learning model for Devanagari ancient
   character recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Devanagari handwritten character dataset; Devanagari ancient; Deep
   learning; Deep convolutional neural network; Optical character
   recognition
ID NEURAL-NETWORKS; PERFORMANCE; TEXT
AB Devanagari script is the most widely used script in India and other Asian countries. There is a rich collection of ancient Devanagari manuscripts, which is a wealth of knowledge. To make these manuscripts available to people, efforts are being done to digitize these documents. Optical Character Recognition (OCR) plays an important role in recognizing these documents. Convolutional Neural Network (CNN) is a powerful model that is giving very promising results in the field of character recognition, pattern recognition etc. CNN has never been used for the recognition of the Devanagari ancient manuscripts. Our aim in the proposed work is to use the power of CNN for extracting the wealth of knowledge from Devanagari handwritten ancient manuscripts. In addition, we aim is to experiment with various design options like number of layes, stride size, number of filters, kenel size and different functions in various layers and to select the best of these. In this paper, the authors have proposed to use deep learning model as a feature extractor as well as a classifier for the recognition of 33 classes of basic characters of Devanagari ancient manuscripts. A dataset containing 5484 characters has been used for the experimental work. Various experiments show that the accuracy achieved using CNN as a feature extractor is better than other state-of-the-art techniques. The recognition accuracy of 93.73% has been achieved by using the model proposed in this paper for Devanagari ancient character recognition.
C1 [Narang, Sonika Rani] DAV Coll, Dept Comp Sci, Abohar, Punjab, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, India.
   [Jindal, M. K.] Panjab Univ Reg Ctr, Dept Comp Sci & Applicat, Muktsar, Punjab, India.
C3 Panjab University
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, India.
EM sonikanarang@davcollegeabohar.com; munishcse@gmail.com;
   manishphd@rediffmail.com
RI Jindal, Manish/AAU-8820-2021; Kumar, Munish/P-7756-2018
OI Kumar, Munish/0000-0003-0115-1620
CR Acharya J, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, NETWORKING AND COMMUNICATIONS (ICNC), P1, DOI 10.1109/ICCNC.2015.7069284
   Agarwal B, 2018, INFORM PROCESS MANAG, V54, P922, DOI 10.1016/j.ipm.2018.06.005
   Ahlawat S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123344
   Alzubi J, 2018, J PHYS CONF SER, V1142, DOI 10.1088/1742-6596/1142/1/012012
   [Anonymous], 2018, INT J COMPUTER SCI E, DOI DOI 10.26438/IJCSE/V6I6.909914
   Avadesh M, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P447, DOI 10.1109/DAS.2018.50
   Bag S, 2013, SADHANA-ACAD P ENG S, V38, P133, DOI 10.1007/s12046-013-0121-9
   Cecotti H, 2005, PROC INT CONF DOC, P1045, DOI 10.1109/ICDAR.2005.130
   Cireundefinedan D.C., 2011, IJCAI INT JOINT C AR, VTwo, P1237, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-210
   Diem M, 2010, PROC SPIE, V7531, DOI 10.1117/12.843532
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Garz A, 2010, LECT NOTES COMPUT SC, V6455, P29
   Ghosh K, 2016, INFORM PROCESS MANAG, V52, P873, DOI 10.1016/j.ipm.2016.03.006
   Heyong W, 2019, INFORM PROCESS MANAG, V56, P167, DOI 10.1016/j.ipm.2018.09.004
   Jangid M, 2018, J IMAGING, V4, DOI 10.3390/jimaging4020041
   Kavitha AS, 2013, INT CONF COMM SYST, P602, DOI 10.1109/CSNT.2013.129
   Khanduja D, 2016, ACM T ASIAN LOW-RESO, V15, DOI 10.1145/2710018
   Kim MS, 2004, FIRST INTERNATIONAL WORKSHOP ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P321
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar M, 2019, ARTIF INTELL REV, V52, P2235, DOI 10.1007/s10462-017-9607-x
   Kumar S, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1009, DOI 10.1109/ICCSP.2016.7754301
   Lee H., 2009, P 26 ANN INT C MACHI, V382, P609, DOI 10.1145/1553374.1553453
   Narang, 2018, P 5 IEEE INT C PAR D
   Narang S, 2019, SADHANA-ACAD P ENG S, V44, DOI 10.1007/s12046-019-1126-9
   Narang SR, 2020, ARTIF INTELL REV, V53, P5517, DOI 10.1007/s10462-020-09827-4
   Narang SR, 2020, SOFT COMPUT, V24, P17279, DOI 10.1007/s00500-020-05018-z
   Purkaystha B, 2017, 2017 20TH INTERNATIONAL CONFERENCE OF COMPUTER AND INFORMATION TECHNOLOGY (ICCIT)
   Quiles MG., 2006, ABCM S SERIES MECHAT, V2, P661
   Roohi S, 2017, IRAN CONF MACH, P247, DOI 10.1109/IranianMVIP.2017.8342359
   Shah KR, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P656
   Sharma N., 2013, INT J ENG INNOVATIVE, P318
   Shelke Sushama, 2015, 2015 International Conference on Communication, Information & Computing Technology (ICCICT), P1, DOI 10.1109/ICCICT.2015.7045738
   Singh A, 2015, 2015 INTERNATIONAL CONFERENCE ON SUSTAINABLE ENERGY ENGINEERING AND APPLICATION (ICSEEA), P1, DOI 10.1109/ICSEEA.2015.7380736
   Singh J, 2014, INT J ADV COMPUT SC, V5, P37
   Soumya A, 2015, SMART INNOV SYST TEC, V33, DOI 10.1007/978-81-322-2202-6_42
   Sousa JMC, 2005, IEEE INT CONF FUZZY, P833
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sumetphong, 2012, INT C DIG IM COMP TE, P1
   Theeramunkong T, 2005, INFORM PROCESS MANAG, V41, P139, DOI 10.1016/j.ipm.2004.04.011
   Phan TV, 2016, INT J DOC ANAL RECOG, V19, P49, DOI 10.1007/s10032-015-0257-8
   Uysal AK, 2014, INFORM PROCESS MANAG, V50, P104, DOI 10.1016/j.ipm.2013.08.006
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Yang JB, 2009, IEEE T NEURAL NETWOR, V20, P1911, DOI 10.1109/TNN.2009.2032543
NR 44
TC 29
Z9 29
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20671
EP 20686
DI 10.1007/s11042-021-10775-6
EA MAR 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625906400001
DA 2024-07-18
ER

PT J
AU Souri, A
   Ghobaei-Arani, M
AF Souri, Alireza
   Ghobaei-Arani, Mostafa
TI Cloud manufacturing service composition in IoT applications: a formal
   verification-based approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud manufacturing; Service composition; Formal verification; Internet
   of things (IoT)
ID ALGORITHM
AB Nowadays, one of the new solutions to develop Internet of Things (IoT) applications is cloud manufacturing. By increasing the number of actuators, industrial devices and sensors in industry 4.0 technology, the IoT is going to improve the intelligence of the enterprise information systems with a fast transition towards flexible, smarter, automated and reactive services. In order to respond the needs more quickly or matching the cloud services with modified requirements, cloud manufacturing service composition is used to take advantage of several services available in the Industrial IoT applications. The cloud-based manufacturing services can be characterized, published, shared, and retrieved over the cloud infrastructure to provide integrated services according to the user QoS requirements in a collaborative environment. In this work, a service composition approach is provided for cloud manufacturing in IoT applications. For evaluating the correctness of the proposed solution, a formal verification method is presented based on Labeled Transition System (LTS). Also, Whale Optimization Algorithm (WOA) is utilized to enhance the Quality of Service (QoS), when the number of cloud services have been increased. Finally, deadlock-free and reachability factors as important logical problems are satisfied in verification of the proposed approach. The verification results obtained under different Linear Temporal Logic (LTL) properties and various number of cloud providers indicate that the proposed approach is a correct and valid solution and it outperforms in terms of the reachability, verification time, deadlock, and memory usage.
C1 [Souri, Alireza] Halic Univ, Dept Comp Engn, Istanbul, Turkey.
   [Ghobaei-Arani, Mostafa] Islamic Azad Univ, Dept Comp Engn, Qom Branch, Qom, Iran.
C3 Halic University; Islamic Azad University
RP Souri, A (corresponding author), Halic Univ, Dept Comp Engn, Istanbul, Turkey.
EM alirezasouri@halic.edu.tr; m.ghobaei@qom-iau.ac.ir
RI Ghobaei-Arani, Mostafa/K-5058-2015; Souri, Alireza/Y-4580-2018
OI Ghobaei-Arani, Mostafa/0000-0003-2639-0900; Souri,
   Alireza/0000-0001-8314-9051
CR Aljarah I, 2018, SOFT COMPUT, V22, P1, DOI 10.1007/s00500-016-2442-1
   Baker T, 2017, J NETW COMPUT APPL, V89, P96, DOI 10.1016/j.jnca.2017.03.008
   Casadei R, 2019, FUTURE GENER COMP SY, V91, P252, DOI 10.1016/j.future.2018.09.005
   Ghobaei-Arani M, 2019, IEEE ACCESS, V7, P106911, DOI 10.1109/ACCESS.2019.2932462
   Ghobaei-Arani M, 2019, J SUPERCOMPUT, V75, P2603, DOI 10.1007/s11227-018-2656-3
   Ghobaei-Arani M, 2018, SOFTWARE PRACT EXPER, V48, P1865, DOI 10.1002/spe.2598
   Ghobaei-Arani M, 2018, SOFT COMPUT, V22, P8353, DOI 10.1007/s00500-017-2783-4
   Iwendi C, 2021, SOFTWARE PRACT EXPER, V51, P2558, DOI 10.1002/spe.2797
   Khan Gitosree, 2020, Advanced Computing and Systems for Security. Advances in Intelligent Systems and Computing (AISC 995), P53, DOI 10.1007/978-981-13-8962-7_5
   Khansari ME, 2018, J SUPERCOMPUT, V74, P5485, DOI 10.1007/s11227-018-2454-y
   Li YX, 2018, ADV MECH ENG, V10, DOI 10.1177/1687814018781287
   Li Yongxiang, 2014, Information Technology Journal, V13, P1779, DOI 10.3923/itj.2014.1779.1785
   Li YX, 2013, CHIN CONT DECIS CONF, P2806
   Mafarja MM, 2017, NEUROCOMPUTING, V260, P302, DOI 10.1016/j.neucom.2017.04.053
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Pisching MA, 2015, IFIP ADV INF COMM TE, V450, P65, DOI 10.1007/978-3-319-16766-4_7
   Rahmani AM, 2018, FUTURE GENER COMP SY, V78, P641, DOI 10.1016/j.future.2017.02.014
   Souri, 2020, IEEE ACCESS
   Souri A, 2019, INFORM TECHNOL PEOPL
   Souri A, 2020, CLUSTER COMPUT, V23, P2453, DOI 10.1007/s10586-019-03018-9
   Souri A, 2015, INT CONF SOFTW ENG, P44, DOI 10.1109/ICSESS.2015.7339003
   Sun MY, 2019, FUTURE GENER COMP SY, V100, P1017, DOI 10.1016/j.future.2019.05.070
   Yang YF, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.106003
   Yu CX, 2020, INT J COMPUT INTEG M, V33, P701, DOI 10.1080/0951192X.2019.1571234
   Yuan MH, 2020, ROBOT CIM-INT MANUF, V61, DOI 10.1016/j.rcim.2019.101840
   Zhang YJ, 2015, IEEE T VLSI SYST, V23, P1170, DOI 10.1109/TVLSI.2014.2326797
   Zheng, 2019, J PHYS C SERIES
NR 27
TC 12
Z9 12
U1 3
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 26759
EP 26778
DI 10.1007/s11042-021-10645-1
EA FEB 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000621282200001
DA 2024-07-18
ER

PT J
AU Chatterjee, D
   Chowdhury, A
   Gavas, R
   Sinha, A
   Saha, SK
AF Chatterjee, Debatri
   Chowdhury, Anirban
   Gavas, Rahul
   Sinha, Aniruddha
   Saha, Sanjoy Kumar
TI Real time estimation of task specific self-confidence level based on
   brain signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Metacognitive confidence; Self-confidence; EEG; Physiological sensor;
   Brain signal
ID DECISION; PREDICTORS; MARKERS; STRESS; EEG
AB Self-confidence is one's own belief of success with respect to a specific task. Cognitive tasks like decision making, problem solving etc. are influenced a lot by our self-confidence level. Recent studies show possibility of assessing self-confidence level from brain activation patterns. Here, we are proposing a novel metric based on brain signals acquired by Electroencephalogram (EEG) for quantification of self-confidence level of an individual. The EEG signal is recorded using a low cost, low resolution EEG device. Most significant EEG features (with p value <0.05) have been identified and used for formulating a metric for self-confidence level. Training data is refined using Random Sample Consensus (RANSAC) method to remove the outliers. With these stable training data, reference clusters for low and high confidence categories have been formed based on the most significant features. These reference clusters are used thereafter to compute the confidence level quantitatively for the test participants. Results show that the proposed metric can classify low and high self-confidence levels satisfactorily. Thus, the proposed metric provides a quantified measure of self-confidence level with which a task is performed. The metric can also be used in various applications like confidence measurement in academic settings, online tests, cognitive assessment, rehabilitation, therapy design.
C1 [Chatterjee, Debatri; Chowdhury, Anirban; Gavas, Rahul; Sinha, Aniruddha] Tata Consultancy Serv, TCS Res & Innovat, Kolkata, India.
   [Saha, Sanjoy Kumar] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
C3 Tata Sons; Tata Consultancy Services Limited (TCS); Jadavpur University
RP Chatterjee, D (corresponding author), Tata Consultancy Serv, TCS Res & Innovat, Kolkata, India.
EM debatri.chatterjee@tcs.com
RI Sinha, Aniruddha/ABB-2972-2021; Chowdhury, Anirban/AAM-2993-2021
CR [Anonymous], 1944, TEACHERS WORDBOOK 30
   [Anonymous], 2007, ESSENTIAL READINGS S
   Atherton S, 2016, BEHAV COGN PSYCHOTH, V44, P56, DOI 10.1017/S1352465814000496
   Babiker A, 2019, MULTIMED TOOLS APPL, V78, P16261, DOI 10.1007/s11042-018-7016-z
   BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129
   Bénabou R, 2002, Q J ECON, V117, P871, DOI 10.1162/003355302760193913
   Betz NE, 2010, J CAREER ASSESSMENT, V18, P317, DOI 10.1177/1069072710374492
   Boldt A, 2015, J NEUROSCI, V35, P3478, DOI 10.1523/JNEUROSCI.0797-14.2015
   Bornstein BH, 1999, J EXP PSYCHOL-APPL, V5, P76, DOI 10.1037/1076-898X.5.1.76
   Brannan JD, 2008, J NURS EDUC, V47, P495, DOI 10.3928/01484834-20081101-01
   Cheng H, 2002, J ADOLESCENCE, V25, P327, DOI 10.1006/jado.2002.0475
   Clark MM, 2011, AM J HEALTH PROMOT, V26, P21, DOI 10.4278/ajhp.090821-QUAN-272
   CROCKER J, 1989, PSYCHOL REV, V96, P608, DOI 10.1037/0033-295X.96.4.608
   Elfering A, 2011, APPL PSYCHOPHYS BIOF, V36, P93, DOI 10.1007/s10484-011-9152-3
   Flaskerud JH, 1988, NURSING RES
   FLAVELL JH, 1979, AM PSYCHOL, V34, P906, DOI 10.1037/0003-066X.34.10.906
   Fleming SM, 2012, J NEUROSCI, V32, P6117, DOI 10.1523/JNEUROSCI.6489-11.2012
   Galan FC., 2012, INT C US MOD AD PERS
   Gao Q, 2020, MULTIMEDIA TOOLS APP, P1
   Gavas R, 2017, IEEE SYS MAN CYBERN, P1499, DOI 10.1109/SMC.2017.8122826
   Hermans D, 2008, BEHAV RES THER, V46, P98, DOI 10.1016/j.brat.2007.11.001
   Kepecs A, 2008, NATURE, V455, P227, DOI 10.1038/nature07200
   Kiani R, 2009, SCIENCE, V324, P759, DOI 10.1126/science.1169405
   Lempert KM, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0126588
   Liapis A, 2017, MULTIMED TOOLS APPL, V76, P5051, DOI 10.1007/s11042-016-3637-2
   MAYZNER MS, 1958, J EXP PSYCHOL, V56, P376, DOI 10.1037/h0041542
   McKay J M, 1997, Aust J Sci Med Sport, V29, P55
   Robazza C, 2012, PSYCHOL SPORT EXERC, V13, P509, DOI 10.1016/j.psychsport.2012.02.011
   Ruzgiene Birute., 2005, GEODEZIJA IR KARTOGR, V31, P83
   Sander P., 2003, ELECT J RES ED PSYCH, V1, P1
   Sinha A, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P1, DOI 10.1109/ICCUBEA.2015.11
   Sowislo JF, 2013, PSYCHOL BULL, V139, P213, DOI 10.1037/a0028931
   Stankov L, 1997, INTELLIGENCE, V25, P93, DOI 10.1016/S0160-2896(97)90047-7
   Stankov L, 2008, J EDUC PSYCHOL, V100, P961, DOI 10.1037/a0012546
   Stankov L, 2015, MEASURES OF PERSONALITY AND SOCIAL PSYCHOLOGICAL CONSTRUCTS, P158, DOI 10.1016/B978-0-12-386915-9.00007-3
   Stankov L, 2013, PERS INDIV DIFFER, V55, P727, DOI 10.1016/j.paid.2013.07.006
   Williams J.M., 1992, Journal of Applied Sport Psychology, V4, P134, DOI [DOI 10.1080/10413209208406457, 10.1080/10413209208406457]
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P26697, DOI 10.1007/s11042-018-5885-9
NR 38
TC 3
Z9 3
U1 5
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19203
EP 19217
DI 10.1007/s11042-021-10676-8
EA FEB 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000621282300004
DA 2024-07-18
ER

PT J
AU Tur, AO
   Keles, HY
AF Tur, Anil Osman
   Keles, Hacer Yalim
TI Evaluation of hidden Markov models using deep CNN features in isolated
   sign recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Isolated sign recognition; Gesture recognition; CNN; LSTM; HMM; GMM-HMM;
   Deep learning
ID LANGUAGE RECOGNITION
AB Isolated sign recognition from video streams is a challenging problem due to the multi-modal nature of the signs, where both local and global hand features and face gestures needs to be attended simultaneously. This problem has recently been studied widely using deep Convolutional Neural Network (CNN) based features and Long Short-Term Memory (LSTM) based deep sequence models. However, the current literature is lack of providing empirical analysis using Hidden Markov Models (HMMs) with deep features. In this study, we provide a framework that is composed of three modules to solve isolated sign recognition problem using different sequence models. The dimensions of deep features are usually too large to work with HMM models. To solve this problem, we propose two alternative CNN based architectures as the second module in our framework, to reduce deep feature dimensions effectively. After extensive experiments, we show that using pretrained Resnet50 features and one of our CNN based dimension reduction models, HMMs can classify isolated signs with 90.15% accuracy in Montalbano dataset using RGB and Skeletal data. This performance is comparable with the current LSTM based models. HMMs have fewer parameters and can be trained and run on commodity computers fast, without requiring GPUs. Therefore, our analysis with deep features show that HMMs could also be utilized as well as deep sequence models in challenging isolated sign recognition problem.
C1 [Tur, Anil Osman; Keles, Hacer Yalim] Ankara Univ, Comp Engn Dept, Ankara, Turkey.
C3 Ankara University
RP Keles, HY (corresponding author), Ankara Univ, Comp Engn Dept, Ankara, Turkey.
EM aotur@ankara.edu.tr; hkeles@ankara.edu.tr
RI Keles, Hacer Yalim/W-7934-2018
OI Keles, Hacer Yalim/0000-0002-1671-4126; Tur, Anil
   Osman/0000-0001-7772-5235
FU Scientific and Technological Research Council of Turkey (TuBTAK)
   [217E022]
FX The research presented is part of a project funded by The Scientific and
   Technological Research Council of Turkey (TuBTAK) under the grant number
   217E022.
CR Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Combrink JH, 2018, THESIS U CAPE TOWN
   Cooper H, 2012, J MACH LEARN RES, V13, P2205
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   dos Santos CC, 2020, NEUROCOMPUTING, V400, P238, DOI 10.1016/j.neucom.2020.03.038
   Escalera S, 2017, SPRING SER CHALLENGE, P1, DOI 10.1007/978-3-319-57021-1_1
   Escalera S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2522848.2532595
   Escalera S, 2015, LECT NOTES COMPUT SC, V8925, P459, DOI 10.1007/978-3-319-16178-5_32
   FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030
   Grobel K, 1997, IEEE SYS MAN CYBERN, P162, DOI 10.1109/ICSMC.1997.625742
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Keogh E., 2017, ENCY MACHINE LEARNIN, P314, DOI DOI 10.1007/978-1-4899-7687-1_192
   Kingma D. P., 2014, arXiv
   Kjellstrom H, 2012, ARXIV12113901CS
   Koller O, 2018, INT J COMPUT VISION, V126, P1311, DOI 10.1007/s11263-018-1121-3
   Li F, 2017, IEEE INT CONF AUTOMA, P422, DOI 10.1109/FG.2017.59
   Liu L., 2013, 23 INT JOINT C ART I
   Ma WY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), P1, DOI [10.1109/NEBEC.2015.7117114, 10.1109/SmartCity.2015.38]
   Mannor S., 2005, P 22 INT C MACH LEAR, P561
   Mercer S., 2019, Second handbook of English language teaching, DOI [10.1007/978-3-030-02899-240, DOI 10.1007/978-3-030-02899-240]
   Murakami K., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P237, DOI 10.1145/108844.108900
   Neverova N, 2016, IEEE T PATTERN ANAL, V38, P1692, DOI 10.1109/TPAMI.2015.2461544
   Nishida N, 2016, LECT NOTES COMPUT SC, V9431, P682, DOI 10.1007/978-3-319-29451-3_54
   Núñez JC, 2018, PATTERN RECOGN, V76, P80, DOI 10.1016/j.patcog.2017.10.033
   Paszke Adam, 2017, NIPS W
   Pigou L, 2018, INT J COMPUT VISION, V126, P430, DOI 10.1007/s11263-016-0957-7
   Pigou L, 2015, LECT NOTES COMPUT SC, V8925, P572, DOI 10.1007/978-3-319-16178-5_40
   Pisharady PK, 2015, COMPUT VIS IMAGE UND, V141, P152, DOI 10.1016/j.cviu.2015.08.004
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schreiber J, 2018, ARXIV171100131711001
   Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI 10.1002/0471250953.bia03as18
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tsironi E, 2016, COMPUT INTELL-US, V6
   Tur AO, 2019, PROCEEDINGS OF 18TH INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES (IEEE EUROCON 2019), DOI 10.1109/eurocon.2019.8861945
NR 34
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19137
EP 19155
DI 10.1007/s11042-021-10593-w
EA FEB 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000621282300008
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Guan, YP
   Hu, W
   Hu, XY
AF Guan, Yepeng
   Hu, Wei
   Hu, Xunyin
TI Abnormal behavior recognition using 3D-CNN combined with LSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Abnormal behavior recognition; Optical flow; Motion history image; 3D
   convolutional neural networks; Long short-term memory; Spatial temporal
   attention
AB The research of abnormal behavior recognition is critical to personal and property security. In this paper, a 3D-CNN and Long Short-Term Memory (LSTM) based abnormal behavior recognition method has been proposed. The feature image composed of optical flow (OF) and motion history image (MHI) takes place of RGB image as the input of 3D-CNN. Because of the illumination changes and background jitter in complex scenes, a structural similarity background modeling method has been developed to suppress illumination variations. It is applied to updated dynamically both optical flow and motion history image. A new sample expansion method is developed to deal with the problem of abnormal behavior class imbalance. The OF and MHI feature image clips are randomly cropped firstly. Then clustering method is applied and cluster centers are collected to get new samples in quantity. LSTM with spatial temporal attention is developed to extract long-time spatial-temporal features for abnormal behavior recognition. Compared with state-of-the-art methods, our proposed method has excellent performance in abnormal behavior recognition on some challenging datasets.
C1 [Guan, Yepeng; Hu, Wei; Hu, Xunyin] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Guan, Yepeng] Minist Educ, Key Lab Adv Display & Syst Applicat, Shanghai 200072, Peoples R China.
C3 Shanghai University
RP Guan, YP (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.; Guan, YP (corresponding author), Minist Educ, Key Lab Adv Display & Syst Applicat, Shanghai 200072, Peoples R China.
EM ypguan@shu.edu.cn
OI guan, ye-peng/0000-0003-1854-1430
FU National Natural Science Foundation of China [11176016, 60872117];
   National Key R&D Program of China [2019YFC15 2050, 2020YFC1523004];
   Specialized Research Fund for the Doctoral Program of Higher Education
   [20123108110014]
FX This work is supported in part by the National Natural Science
   Foundation of China (Grant no. 11176016, 60872117), National Key R&D
   Program of China (Grant no. 2019YFC15 2050, 2020YFC1523004), and
   Specialized Research Fund for the Doctoral Program of Higher Education
   (Grant no. 20123108110014).
CR Ahmed F, 2015, IEEE I CONF COMP VIS, P1850, DOI 10.1109/ICCV.2015.215
   [Anonymous], 2004, ECCV (4), DOI [10.1007/978-3-540-24673-2_3, DOI 10.1007/978-3-540-24673-2_3]
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Brunet D, 2012, IEEE T IMAGE PROCESS, V21, P1488, DOI 10.1109/TIP.2011.2173206
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dhiman C, 2019, ENG APPL ARTIF INTEL, V77, P21, DOI 10.1016/j.engappai.2018.08.014
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Eum H, 2015, SENSORS-BASEL, V15, P5197, DOI 10.3390/s150305197
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Frederick RI, 2009, ASSESSMENT, V16, P215, DOI 10.1177/1073191108325005
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   Hara K, 2017, IEEE INT CONF COMP V, P3154, DOI 10.1109/ICCVW.2017.373
   How DNT, 2016, INT J ADV ROBOT SYST, V13, DOI 10.1177/1729881416663369
   Ijjina EP, 2016, PATTERN RECOGN, V59, P199, DOI 10.1016/j.patcog.2016.01.012
   Khong V.-M., 2018, PROC 1 INT C MULTIME, P1
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kumaran N, 2018, MULTIMED TOOLS APPL, V77, P23115, DOI 10.1007/s11042-017-5591-z
   Jingen Liu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1996, DOI [10.1109/ICINIS.2009.13, 10.1109/CVPRW.2009.5206744]
   Luo Y, 2015, IET COMPUT VIS, V9, P476, DOI 10.1049/iet-cvi.2014.0261
   Murad A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112556
   Murtaza F, 2016, IET COMPUT VIS, V10, P758, DOI 10.1049/iet-cvi.2015.0416
   Naveenkumar M, 2016, PROCEDIA COMPUT SCI, V89, P759, DOI 10.1016/j.procs.2016.06.053
   Núñez-Marcos A, 2017, WIREL COMMUN MOB COM, DOI 10.1155/2017/9474806
   Shi JX, 2018, HUM BRAIN MAPP, V39, P2269, DOI 10.1002/hbm.24006
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Tay N.C., 2019, 2019 1st International Conference on Electrical, Control and Instrumentation Engineering (ICECIE), P1, DOI DOI 10.1109/ICECIE47765.2019.8974824
   Tay NC, 2019, LECT NOTES ELECTR EN, V481, P37, DOI 10.1007/978-981-13-2622-6_4
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Vadivel, 2019, PROCESSINGS ICD SMLA, V2020, P356
   Xie SY, 2016, MULTIMED TOOLS APPL, V75, P7423, DOI 10.1007/s11042-015-2664-8
NR 32
TC 16
Z9 16
U1 5
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18787
EP 18801
DI 10.1007/s11042-021-10667-9
EA FEB 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000619738400003
DA 2024-07-18
ER

PT J
AU Li, XJ
   Luo, YL
   Bian, WX
AF Li, Xuejing
   Luo, Yonglong
   Bian, Weixin
TI Retracing extended sudoku matrix for high-capacity image steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Embedding capacity; Sudoku matrix; Image steganography
AB Numerous data hiding algorithms have been devised for imperceptibly embedding secret messages into the cover media so as to securely transmit user privacy information over the public communication channels. Among them, the reference matrix-based schemes in spatial domain draw extensive concern on account of the simple but efficient embedding and extraction procedure. The core idea of the planar matrix-based method is let two contiguous cover pixels conceal a base-N secret digit with the guidance of reference matrix, such as Sudoku, Turtle Shell, and so on. A novel image data hiding scheme with great embedding efficiency is presented in this paper, which is based on retracing extended Sudoku (RE-Sudoku) reference matrix. Owing to the number of Sudoku solutions and various extension directions, viz., the multiformity of RE-Sudoku matrix, this scheme is exceedingly more secure than the previous methods. More momentously, the proposed two-dimensional reference matrix can guide two 9-ary notational system secret digits to be embedded into each cover pixel pair simultaneously; thereby resulting in a larger embedding rate which converges to 3.169 bits per pixel. The experimental results reveal that this image steganography outperforms the other related works in terms of hiding capacity while maintaining a desirable image quality around 40 dB. Furthermore, the security of our proposed scheme is verified by demonstrating its resistance to the pixel-value difference histogram (PDH) and regular/singular (RS) steganalysis.
C1 [Li, Xuejing; Luo, Yonglong; Bian, Weixin] Anhui Normal Univ, Sch Comp & Informat, Wuhu, Anhui, Peoples R China.
   [Li, Xuejing; Luo, Yonglong; Bian, Weixin] Anhui Prov Key Lab Network & Informat Secur, Wuhu, Anhui, Peoples R China.
C3 Anhui Normal University
RP Luo, YL (corresponding author), Anhui Normal Univ, Sch Comp & Informat, Wuhu, Anhui, Peoples R China.; Luo, YL (corresponding author), Anhui Prov Key Lab Network & Informat Secur, Wuhu, Anhui, Peoples R China.
EM ylluo@ustc.edu.cn
FU National Natural Science Foundation of China [61972439, 61702010,
   61672039]
FX This research work has been supported by the National Natural Science
   Foundation of China (No.61972439, No.61702010, No.61672039).
CR Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Chang C.-C., 2008, 2008 3 INT C INN COM, P17, DOI 10.1109/ICICIC.2008.149
   Chang CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P89, DOI 10.1109/IIH-MSP.2014.29
   Davis R. M., 1978, IEEE Communications Society Magazine, V16, P5, DOI 10.1109/MCOM.1978.1089771
   Fridrich J, 2002, PROC SPIE, V4675, P1, DOI 10.1117/12.465263
   Hou DD, 2018, SIGNAL PROCESS, V148, P41, DOI 10.1016/j.sigpro.2018.02.002
   Huang CT, 2019, MULTIMED TOOLS APPL, V78, P3131, DOI 10.1007/s11042-018-5811-1
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Hussain M, 2018, IETE TECH REV, V35, P53, DOI 10.1080/02564602.2016.1244496
   Khodaei M, 2012, IET IMAGE PROCESS, V6, P677, DOI 10.1049/iet-ipr.2011.0059
   Kim HJ, 2010, COMPUT MATH APPL, V60, P319, DOI 10.1016/j.camwa.2010.01.006
   Liu YJ, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON VIDEO AND IMAGE PROCESSING (ICVIP 2017), P151, DOI 10.1145/3177404.3177452
   Liu YJ, 2016, IET IMAGE PROCESS, V10, P130, DOI 10.1049/iet-ipr.2014.1015
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Tavares R, 2016, IEEE LAT AM T, V14, P1058, DOI 10.1109/TLA.2016.7437258
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Xia B-B, 2016, J INF HIDING MULTIME, V7, P836
   Yang CH, 2010, J SYST SOFTWARE, V83, P1635, DOI 10.1016/j.jss.2010.03.081
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhang XP, 2004, PATTERN RECOGN LETT, V25, P331, DOI 10.1016/j.patrec.2003.10.014
NR 23
TC 6
Z9 6
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18627
EP 18651
DI 10.1007/s11042-021-10675-9
EA FEB 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000619425300006
DA 2024-07-18
ER

PT J
AU Revathi, A
   Sasikaladevi, N
   Geetha, K
AF Revathi, A.
   Sasikaladevi, N.
   Geetha, K.
TI Forensic investigation for twin identification from speech: perceptual
   and gamma-tone features and models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Twin identification; Gamma-tone energy features; Fuzzy C means
   clustering
AB To assist an investigation process, forensic experts compare and analyze audio recordings. Speech utterances are compared by humans and/or machines for use in court for investigation. Scientific research community insists for specific automatic or human-based approach to identify uniquxy2e audio features from identical twins group. Filters can be employed to enhance an audio recording for improving clarity. This may entail removal of unnecessary noise to enrich the intelligibility of speech. Forensic audio experts can examine a variety of characteristics of the audio recording to decide the possibility of alterations in the collected evidences. This includes confirming the integrity and authenticating that the content is what it purports to be. Thiswork named as FIST(Forensic Investigation for Twin Identification from Speech: Perceptual and Gamma-tone Features and Models) proposes an automated system to identify a twin from identical twin pairs by the use of gamma-tone features and perceptual features.The proposed features are excerpted from the set of training speeches and templates are created for each twin based on vector quantisation (VQ), Fuzzy C means clustering (FCM) and multivariate hidden Markov modelling (MHMM) techniques. For testing, features are extracted from the set of test utterances and worked out to the templates for classification. Based on the type of classifier used, classification of twin is carried out with minimum distance and maximum loglikelihood value. The proposed features are examinedfor sub-optimal and true success rates as key performance metrics to assess the system and also a comparative analysis is made across the proposed features. Among the inspected features, Gammatone energy features expose better performance in comparison to perceptual features by attaining the overall sub-optimal success rate and true success rate as97.8375% and 92.75% for Gammatone energy features with VQ based modelling technique. This work FIST has also been analysed by inducing disturbance in the form of speech interference from their own twin pairs and Gamma-tone energy feature with VQ based modelling technique performs better for twin identification. A high claim of 99.625% and 95.0625% accuracy has been achieved by employing decision level fusion classifier.
C1 [Revathi, A.] SASTRA Deemed Univ, Dept ECE SEEE, Thanjavur, India.
   [Sasikaladevi, N.; Geetha, K.] SASTRA Deemed Univ, Dept CSE SoC, Thanjavur, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Sasikaladevi, N (corresponding author), SASTRA Deemed Univ, Dept CSE SoC, Thanjavur, India.
EM sasikalade@gmail.com
RI KRISHNAN, GEETHA/IUO-9520-2023
OI KRISHNAN, GEETHA/0000-0002-8546-2719
CR [Anonymous], 2013, 8 INT WORKSH MOD AN
   [Anonymous], 2008, 2008 INT C COMP COMM
   Ariyaeeinia A, 2008, SCI JUSTICE, V48, P182, DOI 10.1016/j.scijus.2008.02.002
   Bolt R.H., 1979, On the theory and practice of voice identification
   Debruyne F, 2002, J VOICE, V16, P466, DOI 10.1016/S0892-1997(02)00121-2
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Feiser H. S., 2009, 18 ANN C INT ASS FOR
   Jain, 2010, P SPIE, V7667
   Künzel HJ, 2010, INT J SPEECH LANG LA, V17, P251, DOI 10.1558/ijsll.v17i2.251
   Kunzel, 2005, P IEEE INDOCON 2004, V2, P1
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Nolan Francis., 2013, Int. J. Speech Lang. Law, V3, P39, DOI DOI 10.1558/IJSLL.V3I1.39
   Patil HA, 2004, PROCEEDINGS OF THE IEEE INDICON 2004, P58, DOI 10.1109/INDICO.2004.1497705
   PRZYBYLA BD, 1992, J VOICE, V6, P261, DOI 10.1016/S0892-1997(05)80151-1
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Revathi A, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL I, PROCEEDINGS, P535, DOI 10.1109/ICCIMA.2007.199
   Revathi A, 2018, INT J SPEECH TECHNOL, V21, P723, DOI 10.1007/s10772-018-9546-1
   Rose P, 2002, TAYL & FRAN FORENS S, P1
   Ryalls J, 2004, FOLIA PHONIATR LOGO, V56, P165, DOI 10.1159/000076938
   Sabatier SB, 2019, MEASUREMENT, V134, P385, DOI 10.1016/j.measurement.2018.10.057
   San Segundo E, 2012, 21 ANN C I NT ASS FO
   San Segundo E, 2013, 31 INT C AESLA
   Fernández ES, 2013, PROCD SOC BEHV, V95, P59, DOI 10.1016/j.sbspro.2013.10.622
   Van Gysel W D, 2001, Acta Otorhinolaryngol Belg, V55, P49
   Van Lierde KA, 2005, J VOICE, V19, P511, DOI 10.1016/j.jvoice.2004.10.005
   Zuo DH, 2015, J PHONETICS, V52, P1, DOI 10.1016/j.wocn.2015.03.003
NR 31
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18301
EP 18315
DI 10.1007/s11042-021-10639-z
EA FEB 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000618948700001
DA 2024-07-18
ER

PT J
AU Majhi, M
   Pal, AK
   Pradhan, J
   Islam, SKH
   Khan, MK
AF Majhi, Mukul
   Pal, Arup Kumar
   Pradhan, Jitesh
   Islam, S. K. Hafizul
   Khan, Muhammad Khurram
TI Computational intelligence based secure three-party CBIR scheme for
   medical data for cloud-assisted healthcare applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; Entropy; Hamming distance; Medical image security; Saliency map
ID IMAGE RETRIEVAL; CLASSIFICATION; EFFICIENT; SCALE
AB Medical images with various modalities have become an integral part of the diagnosis and treatment of several diseases. The medical practitioners often use previous case studies to deal with the current medical condition of any particular patient. In such circumstance, they need to securely access medical images of various cases which are generally stored in a network and are vulnerable to malicious attacks. To address these sensitive inadequacies, we have proposed computational intelligence based secure healthcare Content based Image Retrieval (CBIR) for medical image retrieval scheme through which any medical practitioner can retrieve the image in an encrypted domain in cloud environment. In this regard, hamming distance-based similarity matching is the only available technique that effectively handles the comparison between encrypted features. This technique requires binary features to perform similarity matching, and the performance of such features in image retrieval is poor. In this concern, we have suggested a salient component-based binary feature extraction approach to enhance retrieval accuracy. Initially, we have re-arranged the input image using the saliency map, principal texture direction, and entropy to place the salient components at the starting blocks. Subsequently, we have employed a block-level majority voting scheme on the salient blocks of the image to obtain local binary features. As a result, the final feature vector carries more features from the salient part of the image, which propitiously improves the retrieval accuracy. Later, we have encrypted the binary feature vector and performed image retrieval on cloud environment which involve Data Owner, Database Service Provider and Client over encrypted domain to full fill the security aspect. Finally, we have used medical as well as Corel image datasets to validate the retrieval performance accuracy of the proposed scheme. The experimental results obtained from real life datasets exhibit that the proposed method is secure and provides comparable retrieval accuracy concerning other related schemes in the domain.
C1 [Majhi, Mukul; Pal, Arup Kumar; Pradhan, Jitesh] Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad 826004, Jharkhand, India.
   [Islam, S. K. Hafizul] Indian Inst Informat Technol Kalyani, Dept Comp Sci & Engn, Kalyani 741235, W Bengal, India.
   [Khan, Muhammad Khurram] King Saud Univ, Coll Comp & Informat Sci, Ctr Excellence Informat Assurance, Riyadh, Saudi Arabia.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad; King Saud University
RP Islam, SKH (corresponding author), Indian Inst Informat Technol Kalyani, Dept Comp Sci & Engn, Kalyani 741235, W Bengal, India.
EM mukulmajhi@gmail.com; aruplapal@gmail.com; jitpradhan02@gmail.com;
   hafi786@gmail.com; mkhurram@ksu.edu.sa
RI KHAN, MUHAMMAD KHURRAM/E-4836-2014; Nusa, Nuhammad/JXY-5819-2024; Majhi,
   Mukul/ABA-6776-2021; Khan, Muhammad/IXN-8470-2023
OI KHAN, MUHAMMAD KHURRAM/0000-0001-6636-0533; Majhi,
   Mukul/0000-0003-1690-4461; Pradhan, Jitesh/0000-0002-6264-4093
FU Indian Institute of Technology [Indian School of Mines] Dhanbad,
   Jharkhand, India [2015DR0082]; King Saud University, Riyadh, Saudi
   Arabia [RSP-2020/12]
FX The author Ms. Mukul Majhi (Admission No: 2015DR0082) is supported by
   the institute Ph.D. scholarship, Indian Institute of Technology [Indian
   School of Mines] Dhanbad, Jharkhand, India. The author Prof. Muhammad
   Khurram Khan acknowledges that his work is supported by Researchers
   Supporting Project number (RSP-2020/12), King Saud University, Riyadh,
   Saudi Arabia.
CR Ahmed KT, 2019, INFORM FUSION, V51, P76, DOI 10.1016/j.inffus.2018.11.004
   Al Omar A, 2019, FUTURE GENER COMP SY, V95, P511, DOI 10.1016/j.future.2018.12.044
   Almazroa A, 2018, PROC SPIE, V10579, DOI 10.1117/12.2293584
   Amsaleg, 2009, THESIS INRIA
   Avramovic A, 2012, ELEVENTH SYMPOSIUM ON NEURAL NETWORK APPLICATIONS IN ELECTRICAL ENGINEERING (NEUREL 2012)
   Azeez NA, 2019, EGYPT INFORM J, V20, P97, DOI 10.1016/j.eij.2018.12.001
   Baluja S, 1997, ROBOT AUTON SYST, V22, P329, DOI 10.1016/S0921-8890(97)00046-8
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Colonnese S., 2016, 2016 6 EUR WORKSH VI, P1
   Combalia Marc, 2019, ARXIV190802288
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Diaz-Pinto A, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0649-y
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   Dubey SR, 2015, IEEE SIGNAL PROC LET, V22, P1215, DOI 10.1109/LSP.2015.2392623
   Ferreira B, 2019, IEEE T CLOUD COMPUT, V7, P784, DOI 10.1109/TCC.2017.2669999
   Ginneken, 2019, DRIVE DIGITAL RETINA
   Gupta Manu, 2016, 2016 International Conference on Information Technology (ICIT). Proceedings, P129, DOI 10.1109/ICIT.2016.037
   He S, 2009, IEEE T BIO-MED ENG, V56, P1864, DOI 10.1109/TBME.2009.2017508
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Hsu CY, 2011, PROC SPIE, V7880, DOI 10.1117/12.873325
   Huang H.K., 2004, PACS IMAGING INFORM
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jafari-Khouzani K, 2005, IEEE T PATTERN ANAL, V27, P1004, DOI 10.1109/TPAMI.2005.126
   Jiang Q, 2016, J SUPERCOMPUT, V72, P3826, DOI 10.1007/s11227-015-1610-x
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Kokare M, 2005, IEEE T SYST MAN CY B, V35, P1168, DOI 10.1109/TSMCB.2005.850176
   Krishnan KR, 2017, IET IMAGE PROCESS, V11, P530, DOI 10.1049/iet-ipr.2016.1072
   Lehmann TM, 2003, P SOC PHOTO-OPT INS, V5033, P109, DOI 10.1117/12.481942
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li X, 2015, J AMB INTEL HUM COMP, V6, P563, DOI 10.1007/s12652-013-0217-4
   Litjens G, 2018, GIGASCIENCE, V7, DOI 10.1093/gigascience/giy065
   Majhi M, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4013
   Masud M, 2018, MULTIMED TOOLS APPL, V77, P11121, DOI 10.1007/s11042-017-5294-5
   MILANESE R, 1995, OPT ENG, V34, P2428, DOI 10.1117/12.205668
   Müller H, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P683
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Murala S, 2014, IEEE J BIOMED HEALTH, V18, P929, DOI 10.1109/JBHI.2013.2288522
   Nagasubramanian G, 2020, NEURAL COMPUT APPL, V32, P639, DOI 10.1007/s00521-018-3915-1
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pal, 2012, INT C REC TRENDS ENG
   Peng SH, 2010, COMPUT BIOL MED, V40, P931, DOI 10.1016/j.compbiomed.2010.10.005
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Ponraj N, 2017, INT CONF ADV COMPU, P182, DOI 10.1109/ICoAC.2017.7951766
   Qin JH, 2019, IEEE ACCESS, V7, P24626, DOI 10.1109/ACCESS.2019.2894673
   Quellec G, 2010, MED IMAGE ANAL, V14, P227, DOI 10.1016/j.media.2009.11.004
   Ren K, 2012, IEEE INTERNET COMPUT, V16, P69, DOI 10.1109/MIC.2012.14
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Sachnev, 2018, CRYPTOGRAPH DOMAIN I
   Sayood K, 2017, Introduction to data compression
   Shen LX, 2016, IEEE T SYST MAN CY-S, V46, P1148, DOI 10.1109/TSMC.2015.2468192
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Sorensen L, 2010, IEEE T MED IMAGING, V29, P559, DOI 10.1109/TMI.2009.2038575
   Sucharitha G, 2020, MULTIMED TOOLS APPL, V79, P1847, DOI 10.1007/s11042-019-08215-7
   Tagare HD, 1997, J AM MED INFORM ASSN, V4, P184, DOI 10.1136/jamia.1997.0040184
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Thomas, 2009, INT J HEALTHC INF SY, V4, P1
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Wang SG, 2021, IEEE T MOBILE COMPUT, V20, P939, DOI 10.1109/TMC.2019.2957804
   Wang Y., 2017, 14 INT C SERV SYST S
   Weng L, 2016, IEEE T KNOWL DATA EN, V28, P2738, DOI 10.1109/TKDE.2016.2587258
   Weng L, 2015, IEEE T INF FOREN SEC, V10, P152, DOI 10.1109/TIFS.2014.2365998
   Xia Z, 2018, IEEE ACCESS
   Xia ZH, 2017, INFORM SCIENCES, V387, P195, DOI 10.1016/j.ins.2016.12.030
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Xu YY, 2019, IEEE ACCESS, V7, P160082, DOI 10.1109/ACCESS.2019.2951175
   Xu YY, 2017, J VIS COMMUN IMAGE R, V43, P164, DOI 10.1016/j.jvcir.2017.01.006
   Younis, 2017, INTERJ COMPUT APPL, V165
   Zakeri FS, 2012, J MED SYST, V36, P1621, DOI 10.1007/s10916-010-9624-7
NR 71
TC 10
Z9 10
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41545
EP 41577
DI 10.1007/s11042-020-10483-7
EA FEB 2021
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000618600400002
DA 2024-07-18
ER

PT J
AU Singhal, A
   Agarwal, M
   Pachori, RB
AF Singhal, Amit
   Agarwal, Megha
   Pachori, Ram Bilas
TI Directional local ternary co-occurrence pattern for natural image
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color histogram; Corel 1000; Directional filter masks; Image retrieval;
   Local ternary co-occurrence pattern
ID TEXTURE FEATURE DESCRIPTOR; EXTREMA PATTERNS; BINARY PATTERNS; COLOR;
   FACE; SCALE; CLASSIFICATION; RECOGNITION; SPACE
AB Content based image retrieval (CBIR) systems provide a faster way to retrieve images by representing them in terms of their visual contents. In this paper, a novel texture feature, directional local ternary co-occurrence pattern (DLTCoP) is proposed for CBIR. First and second order derivatives of the image are extracted through directional filter masks to capture coarse and fine details of the image in four directions. Thereafter, changes in first and second order filter responses are analyzed simultaneously and co-occurrence is computed based on their inter-relations. The information captured by DLTCoP is further enriched by computing histograms for the gray-scale image and the color information is represented as color histograms. The proposed scheme provides a consolidated feature capable of distinguishing between different images. Experiments are conducted on five benchmark data sets, Corel 1000, Corel 5k, Corel 10k, INRIA Holidays and Salsburg Texture. Significant improvement in average precision and recall is obtained with respect to the existing state-of-the-art features.
C1 [Singhal, Amit] Bennett Univ, Dept Elect & Commun Engn, Greater Noida, India.
   [Agarwal, Megha] Jaypee Inst Informat Technol, Dept Elect & Commun Engn, Noida, India.
   [Pachori, Ram Bilas] Indian Inst Technol Indore, Discipline Elect Engn, Indore, India.
C3 Jaypee Institute of Information Technology (JIIT); Indian Institute of
   Technology System (IIT System); Indian Institute of Technology (IIT) -
   Indore
RP Agarwal, M (corresponding author), Jaypee Inst Informat Technol, Dept Elect & Commun Engn, Noida, India.
EM singhalamit.iitd@gmail.com; drmegha.iit@gmail.com; pachori@iiti.ac.in
RI Singhal, Amit/GQI-4592-2022; Pachori, Ram Bilas/AAO-5839-2020
OI Pachori, Ram Bilas/0000-0002-6061-4309; Agarwal,
   Megha/0000-0003-3434-6555
CR Agarwal M., 2011, TECHNIA INT J COMPUT, V4, P651
   Agarwal M, 2018, INT CONF IND INF SYS, P171
   Agarwal M, 2019, PATTERN ANAL APPL, V22, P1585, DOI 10.1007/s10044-019-00787-2
   Agarwal M, 2018, NEUROCOMPUTING, V313, P333, DOI 10.1016/j.neucom.2018.06.027
   [Anonymous], 2013, P 3 ACM C INT C MULT
   Banerjee P, 2018, EXPERT SYST APPL, V113, P100, DOI 10.1016/j.eswa.2018.06.044
   Beecks C, 2010, IEEE INT CON MULTI, P1552, DOI 10.1109/ICME.2010.5582949
   Bella MIT, 2019, COMPUT ELECTR ENG, V75, P46, DOI 10.1016/j.compeleceng.2019.01.022
   Bhunia AK, 2020, PATTERN ANAL APPL, V23, P703, DOI 10.1007/s10044-019-00827-x
   Chakraborty S, 2018, IEEE T CIRC SYST VID, V28, P171, DOI 10.1109/TCSVT.2016.2603535
   Dey M, 2016, PATTERN ANAL APPL, V19, P1159, DOI 10.1007/s10044-015-0522-y
   Dubey SR, 2019, MULTIMED TOOLS APPL, V78, P16411, DOI 10.1007/s11042-018-7028-8
   Dubey SR, 2015, IEEE SIGNAL PROC LET, V22, P1215, DOI 10.1109/LSP.2015.2392623
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   Heikkilä M, 2006, LECT NOTES COMPUT SC, V4338, P58
   Jacob IJ, 2014, PATTERN RECOGN LETT, V42, P72, DOI 10.1016/j.patrec.2014.01.017
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Kwitt R., 2012, SALZBURG TEXTURE IMA
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu HL, 2017, PROCEDIA COMPUT SCI, V107, P749, DOI 10.1016/j.procs.2017.03.159
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Mary NAB, 2018, MULTIMED TOOLS APPL, V77, P31545, DOI 10.1007/s11042-018-6148-5
   Mary NAB, 2019, MULTIMED TOOLS APPL, V78, P11387, DOI 10.1007/s11042-018-6673-2
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Murala S, 2015, NEUROCOMPUTING, V149, P1502, DOI 10.1016/j.neucom.2014.08.042
   Murala S, 2014, IEEE J BIOMED HEALTH, V18, P929, DOI 10.1109/JBHI.2013.2288522
   Murala S, 2012, INT J MULTIMED INF R, V1, P191, DOI 10.1007/s13735-012-0008-2
   Murala S, 2013, NEUROCOMPUTING, V119, P399, DOI 10.1016/j.neucom.2013.03.018
   Murala S, 2013, PROC SPIE, V8663, DOI 10.1117/12.2002185
   Murala S, 2012, J MED SYST, V36, P2865, DOI 10.1007/s10916-011-9764-4
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Peng SH, 2010, COMPUT BIOL MED, V40, P931, DOI 10.1016/j.compbiomed.2010.10.005
   Rao LK, 2019, MULTIDIM SYST SIGN P, V30, P1413, DOI 10.1007/s11045-018-0609-x
   Raza A, 2019, MULTIMED TOOLS APPL, V78, P2719, DOI 10.1007/s11042-018-5795-x
   Reddy AH, 2015, AEU-INT J ELECTRON C, V69, P290, DOI 10.1016/j.aeue.2014.09.015
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Schmid AM-BV., 2014, PATTERN RECOGNITION
   Sorensen L, 2010, IEEE T MED IMAGING, V29, P559, DOI 10.1109/TMI.2009.2038575
   Subrahmanyam M, 2012, SIGNAL PROCESS, V92, P1467, DOI 10.1016/j.sigpro.2011.12.005
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tiwari AK, 2017, SIGNAL PROCESS-IMAGE, V53, P73, DOI 10.1016/j.image.2017.01.010
   Vadivel A, 2007, PATTERN RECOGN LETT, V28, P974, DOI 10.1016/j.patrec.2007.01.004
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Verma M, 2016, DIGIT SIGNAL PROCESS, V51, P62, DOI 10.1016/j.dsp.2016.02.002
   Verma M, 2015, NEUROCOMPUTING, V165, P255, DOI 10.1016/j.neucom.2015.03.015
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Vipparthi SK, 2016, IET COMPUT VIS, V10, P182, DOI 10.1049/iet-cvi.2015.0035
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Xu X, 2015, INT J PROD RES, V53, P7005, DOI 10.1080/00207543.2014.937013
   Xu Y, 2017, IEEE ACCESS, V5, P8502, DOI 10.1109/ACCESS.2017.2695239
   Yao CH, 2003, PATTERN RECOGN, V36, P913, DOI 10.1016/S0031-3203(02)00124-3
   Yu LH, 2018, SIGNAL IMAGE VIDEO P, V12, P247, DOI 10.1007/s11760-017-1152-1
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang XF, 2015, IEEE T MED IMAGING, V34, P496, DOI 10.1109/TMI.2014.2361481
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 57
TC 12
Z9 12
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15901
EP 15920
DI 10.1007/s11042-020-10319-4
EA FEB 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000615564900007
DA 2024-07-18
ER

PT J
AU Yang, Y
   Wang, ZW
   Hong, WQ
   Yue, H
AF Yang, Yan
   Wang, Zhiwei
   Hong, Wenqiang
   Yue, Hui
TI Single image Dehazing algorithm based on double exponential attenuation
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Dark channel prior; Dehazing; Image restoration;
   Transmission
AB Single image dehazing is a challenging task because haze seriously affect the visibility of images, and it further brings inconvenience to advanced computer vision analysis. In this paper, a novel and efficient algorithm is proposed to remove haze from a single image. Instead of obtaining transmission from fixed priors and constraints, a double exponential attenuation model (DEA model) based on color attenuation prior is established to compute transmission adaptively. DEA model contains two single exponential attenuation parts that can compensate each other. In addition, a normal unilateral constraint rule (NUCR) is designed to make the transmission more accurate. More importantly, DEA model has a dynamic adjustment function with different weights for different inputs. To circumvent distortion in sky and bright areas, an effective and robust approach is introduced to acquire atmospheric light value. Finally, the clear image can be restored with atmospheric scattering model. Several experimental results on synthetic and real-world images show that the proposed algorithm can protect and recover the detailed information excellently. The performance on synthetic datasets I-HAZE, O-HAZE and HazeRD are 0.762/16.598 (SSIM/PSNR),0.787/17.193, and 0.783/17.104, respectively.
C1 [Yang, Yan; Wang, Zhiwei; Hong, Wenqiang] Lanzhou Jiaotong Univ, Sch Elect & Informat Engn, Lanzhou 730070, Peoples R China.
   [Yue, Hui] Lanzhou Jiaotong Univ, Lanzhou 730070, Peoples R China.
C3 Lanzhou Jiaotong University; Lanzhou Jiaotong University
RP Yang, Y (corresponding author), Lanzhou Jiaotong Univ, Sch Elect & Informat Engn, Lanzhou 730070, Peoples R China.
EM yangyantd@mail.lzjtu.cn; 553693618@qq.com; 2389415775@qq.com;
   yuehuitd@mail.lzjtu.cn
RI Wang, ZhiWei/AAE-4028-2019
OI Wang, ZhiWei/0000-0002-9402-4729; Yang, Yan/0000-0001-5338-0762
FU National Natural Science Foundation of China [61561030]
FX The authors would like to thank the anonymous reviews. This study is
   funded by The National Natural Science Foundation of China (61561030).
CR Al-Sammaraie MF, 2015, INT CONF COMP SCI ED, P95, DOI 10.1109/ICCSE.2015.7250224
   Ancuti CO, 2018, IEEE IMAGE PROC, P2850, DOI 10.1109/ICIP.2018.8451523
   Ancuti C, 2016, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP.2016.7532754
   [Anonymous], 2002, IEEE INT C IM PROC
   [Anonymous], 2003, IEEE WORKSHOP COLOR
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Cooper TJ, 2004, J ELECTRON IMAGING, V13, P85, DOI 10.1117/1.1636182
   Dong H, 2020, P IEEE CVF C COMP VI, P2157
   Dudhane A, 2019, IEEE WINT CONF APPL, P1147, DOI 10.1109/WACV.2019.00127
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Kansal I, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500546
   Kansal I, 2018, J MOD OPTIC, V65, P2103, DOI 10.1080/09500340.2018.1499976
   Koschmieder H, 1924, BEITR PHYS FREIEN AT
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Liu RS, 2019, IEEE T NEUR NET LEAR, V30, P2973, DOI 10.1109/TNNLS.2018.2862631
   McCartney EJ., 1975, Optics of Atmosphere: Scattering by Molecules and Particles
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Schechner YY, 2003, APPL OPTICS, V42, P511, DOI 10.1364/AO.42.000511
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Wang WC, 2017, IEEE-CAA J AUTOMATIC, V4, P410, DOI 10.1109/JAS.2017.7510532
   Wang WC, 2017, IEEE T MULTIMEDIA, V19, P1142, DOI 10.1109/TMM.2017.2652069
   Wang WC, 2017, NEUROCOMPUTING, V238, P365, DOI 10.1016/j.neucom.2017.01.075
   Yang D, 2018, LECT NOTES COMPUT SC, V11211, P729, DOI 10.1007/978-3-030-01234-2_43
   Yang XT, 2018, AAAI CONF ARTIF INTE, P7485
   Zhang J, 2020, IEEE T IMAGE PROCESS, V29, P72, DOI 10.1109/TIP.2019.2922837
   Zhang YF, 2017, IEEE IMAGE PROC, P3205, DOI 10.1109/ICIP.2017.8296874
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 31
TC 3
Z9 4
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15701
EP 15718
DI 10.1007/s11042-021-10540-9
EA FEB 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000615564900008
DA 2024-07-18
ER

PT J
AU Zhao, MH
   Wang, Q
   Ning, JW
   Muniru, AN
   Shi, ZH
AF Zhao, Minghua
   Wang, Qin
   Ning, Jiawei
   Muniru, Abdul Nasir
   Shi, Zhenghao
TI A region fusion based split Bregman method for TV Denoising algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Image denoising; Non-local means method; Split Bregman
   method; Total variation method
AB A novel robust image denoising method based Total Variation (TV) model called Region Fusion based Split Bregman (RFSB) method is proposed in this paper. First, the structural characteristics of the edge region and that of the smooth region of the noisy image are analyzed and then separated. Second, split Bregman method is used for calculating two baseline TV-based model, the TV model and TV-penalized least squares functional model, and results of the two models are fused by proposed Region Fusion method. Third, for the fusion denoising result contains a wealth of repetitive redundant information, fast non-local means (FNLM) is introduced for post-processing the denoising result. Our proposed method has three contributions: (i) the use of split Bregman to calculate two baseline TV-based model because of its highly minimization speed; (ii) the proposal of a region fusion method to fuse two baseline models; (iii) the application of the FNLM method as the post-processing. Gray images and color images with different intensities of noise are used to compare our proposed method with other existing classical TV-based method. Experimental results show that Our proposed method has outperformed other TV-based methods in denoising visual effect and objective evaluation for different styles of noised images. The time complexity of our proposed method is about 2% and 50% lower than that of TV and Zhang's Total Variation (ZTV). Our proposed method shows lower time complexity and does not distort the image information compared with two deep learning algorithm.
C1 [Zhao, Minghua; Wang, Qin; Ning, Jiawei; Muniru, Abdul Nasir; Shi, Zhenghao] Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Peoples R China.
   [Zhao, Minghua] Shaanxi Key Lab Network Comp & Secur Technol, Xian, Shaanxi, Peoples R China.
C3 Xi'an University of Technology
RP Zhao, MH (corresponding author), Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Peoples R China.; Zhao, MH (corresponding author), Shaanxi Key Lab Network Comp & Secur Technol, Xian, Shaanxi, Peoples R China.
EM mh_zhao@126.com
FU National Key Technology R&D Program of China; Key Laboratory Foundation
   of Shaanxi Education Department, China [20JS086]; National Natural
   Science Foundation of China [61901363]; Natural Science Foundation of
   Shaanxi province, China [2019JM-381, 2019JQ-729]
FX This work was supported by the National Key Technology R&D Program of
   China (No.2017YFB1402103-3), the Key Laboratory Foundation of Shaanxi
   Education Department, China (No.20JS086), the National Natural Science
   Foundation of China (No. 61901363) and the Natural Science Foundation of
   Shaanxi province, China (No. 2019JM-381, 2019JQ-729).
CR Bregman L. M., 1967, USSR COMP MATH MATH, V7, P200, DOI [10.1016/0041-5553(67)90040-7, DOI 10.1016/0041-5553(67)90040-7]
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Cai JF, 2014, APPL COMPUT HARMON A, V37, P89, DOI 10.1016/j.acha.2013.10.001
   Cattermole, 2002, FOURIER TRANSFORM IT
   Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169
   Darbon, 2005, IB C PATT REC IM AN
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Goto T, 2011, IEEE IMAGE PROC, P1185, DOI 10.1109/ICIP.2011.6115642
   Jiao JB, 2017, IEEE COMPUT SOC CONF, P1034, DOI 10.1109/CVPRW.2017.140
   Khmag A, 2018, VISUAL COMPUT, V34, P1661, DOI 10.1007/s00371-017-1439-9
   Kichenassamy S, 1997, SIAM J APPL MATH, V57, P1328, DOI 10.1137/S003613999529558X
   Lefkimmiatis S, 2017, PROC CVPR IEEE, P5882, DOI 10.1109/CVPR.2017.623
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liu, 2010, COMPUT ENG APPL
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Neelamani R, 1999, INT CONF ACOUST SPEE, P3241, DOI 10.1109/ICASSP.1999.757532
   Osher S, 1994, IM PROC ICIP 94 IEEE
   Perreault S, 2007, IEEE T IMAGE PROCESS, V16, P2389, DOI 10.1109/TIP.2007.902329
   Qu YD, 2005, IMAGE VISION COMPUT, V23, P11, DOI 10.1016/j.imavis.2004.07.003
   Rakshit S, 2007, PATTERN RECOGN, V40, P890, DOI 10.1016/j.patcog.2006.02.008
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shandoosti HR, 2017, DIGIT SIGNAL PROCESS, V67, P17, DOI 10.1016/j.dsp.2017.04.011
   Shao L, 2014, IEEE T CYBERNETICS, V44, P1001, DOI 10.1109/TCYB.2013.2278548
   Vogel, 1995, MULTIGRID METHOD TOT
   Vogel CR, 1996, SIAM J SCI COMPUT, V17, P227, DOI 10.1137/0917016
   Wang J, 2007, IEEE INT C IM PROC I
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao YH, 2012, INVERSE PROBL IMAG, V6, P547, DOI 10.3934/ipi.2012.6.547
   Xiaoxin Sun, 2014, Applied Mechanics and Materials, V644-650, P4112, DOI 10.4028/www.scientific.net/AMM.644-650.4112
   Xu J, 2015, IEEE I CONF COMP VIS, P244, DOI 10.1109/ICCV.2015.36
   Yang QS, 2018, IEEE T MED IMAGING, V37, P1348, DOI 10.1109/TMI.2018.2827462
   [张红英 ZHANG Hongying], 2006, [光电工程, Opto-Electronic Engineering], V33, P50
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
NR 36
TC 4
Z9 4
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15875
EP 15900
DI 10.1007/s11042-020-10407-5
EA FEB 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000615564900006
DA 2024-07-18
ER

PT J
AU Tadeja, SK
   Lu, YP
   Rydlewicz, M
   Rydlewicz, W
   Bubas, T
   Kristensson, PO
AF Tadeja, Slawomir Konrad
   Lu, Yupu
   Rydlewicz, Maciej
   Rydlewicz, Wojciech
   Bubas, Tomasz
   Kristensson, Per Ola
TI Exploring gestural input for engineering surveys of real-life structures
   in virtual reality using photogrammetric 3D models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; Photogrammetry; Industrial visual analytics; Immersive
   analytics; Digital twinning; Virtual reality content
AB Photogrammetry is a promising set of methods for generating photorealistic 3D models of physical objects and structures. Such methods may rely solely on camera-captured photographs or include additional sensor data. Digital twins are digital replicas of physical objects and structures. Photogrammetry is an opportune approach for generating 3D models for the purpose of preparing digital twins. At a sufficiently high level of quality, digital twins provide effective archival representations of physical objects and structures and become effective substitutes for engineering inspections and surveying. While photogrammetric techniques are well-established, insights about effective methods for interacting with such models in virtual reality remain underexplored. We report the results of a qualitative engineering case study in which we asked six domain experts to carry out engineering measurement tasks in an immersive environment using bimanual gestural input coupled with gaze-tracking. The qualitative case study revealed that gaze-supported bimanual interaction of photogrammetric 3D models is a promising modality for domain experts. It allows the experts to efficiently manipulate and measure elements of the 3D model. To better allow designers to support this modality, we report design implications distilled from the feedback from the domain experts.
C1 [Tadeja, Slawomir Konrad; Lu, Yupu; Kristensson, Per Ola] Univ Cambridge, Dept Engn, Cambridge, England.
   [Rydlewicz, Maciej; Rydlewicz, Wojciech; Bubas, Tomasz] Ctr Syst Softdesk, Lodz, Poland.
C3 University of Cambridge
RP Tadeja, SK (corresponding author), Univ Cambridge, Dept Engn, Cambridge, England.
EM skt40@eng.cam.ac.uk; yl737@cam.ac.uk; mry@softdesk.pl; wry@softdesk.pl;
   tbu@softdesk.pl; pok21@cam.ac.uk
RI Tadeja, Sławomir Konrad/ABB-9669-2021
OI Tadeja, Sławomir Konrad/0000-0003-0455-4062
FU Tsinghua Academic Fund for Undergraduate Overseas Studies; Tsien
   Excellence in Engineering Program;  [EPSRC-1788814]
FX This work was supported by an EPSRC-1788814 studentship and the Tsinghua
   Academic Fund for Undergraduate Overseas Studies and the Fund from Tsien
   Excellence in Engineering Program. We would also like to thank Krzysztof
   Kutt for verifying our translations of the questionnaires, to Wioleta
   Cabala, for advice on the SSQ translation, and to Jason Jacques and
   Daria Domagaa for proofreading the manuscript. We are also thankful to
   Bentley Systems Incorporated for the access to the ContextCapture
   package used to generate the 3D models. We would also like to thank
   Jerzy Sokoowski and Roman Gorecki from the Office of Technical
   Inspection (UDT) in od for their support.
CR Aber JS, 2010, SMALL-FORMAT AERIAL PHOTOGRAPHY: PRINCIPLES, TECHNIQUES AND GEOSCIENCE APPLICATIONS, P23, DOI 10.1016/B978-0-444-53260-2.10003-1
   American Society for Photogrammetry and Remote Sensing, WHAT IS ASPRS
   [Anonymous], 1999, P CHI ACM
   Antlej K, 2018, 2018 3RD DIGITAL HERITAGE INTERNATIONAL CONGRESS (DIGITALHERITAGE) HELD JOINTLY WITH 2018 24TH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS & MULTIMEDIA (VSMM 2018), P338
   Azai T, 2018, ACM INT CONF PR SER, DOI 10.1145/3174910.3174929
   Buxton William, 1986, P SIGCHI C HUM FACT, P321, DOI [10.1145/22627.22390, DOI 10.1145/22627.22390, 10.1145/22339.22390]
   Caputo FabioMarco., C PAPER CHITALY 2015, P2
   El Saddik A, 2018, IEEE MULTIMEDIA, V25, P87, DOI 10.1109/MMUL.2018.023121167
   Guan, 2008, P 7 ACM SIGGRAPH INT
   Guiard Y Asymmetric Division of Labor in Human Skilled Bimanual Action, 1987, J MOTOR BEHAV ROUTLE, V19, P486, DOI [10.1080/00222895.1987.10735426, DOI 10.1080/00222895.1987.10735426]
   HART S G, 1988, P139
   Jude A, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P219, DOI 10.1145/2983310.2989209
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Macchi M, 2018, IFAC PAPERSONLINE, V51, P790, DOI 10.1016/j.ifacol.2018.08.415
   Rheinberg F., 2003, DIAGNOSIS MOTIVATION, P261
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   See ZS, 2018, 2018 3RD DIGITAL HERITAGE INTERNATIONAL CONGRESS (DIGITALHERITAGE) HELD JOINTLY WITH 2018 24TH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS & MULTIMEDIA (VSMM 2018), P213
   Sidenmark L, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3361218
   Sidenmark L, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1161, DOI 10.1145/3332165.3347921
   Slambekova Dana., 2012, P 18 ACM S VIRTUAL R, P203, DOI DOI 10.1145/2407336.2407380
   Song Peng., 2012, P 2012 ACM ANN C HUM, P1297, DOI DOI 10.1145/2207676.2208585
   Tadeja, 2021, P 2020 IEEE AER C, DOI [10.17863/CAM.47663, DOI 10.17863/CAM.47663]
   Tadeja SK., 2019, PHOTOTWINVR IMMERSIV
   Thompson MM, 1966, MANUAL PHOTOGRAMMETR
   Vajak D, 2017, 2017 ZOOMING INNOVATION IN CONSUMER ELECTRONICS INTERNATIONAL CONFERENCE (ZINC), P82, DOI 10.1109/ZINC.2017.7968669
NR 26
TC 9
Z9 9
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 31039
EP 31058
DI 10.1007/s11042-021-10520-z
EA JAN 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000613057400010
OA hybrid, Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Dalal, M
   Juneja, M
AF Dalal, Mukesh
   Juneja, Mamta
TI A secure and robust video steganography scheme for covert communication
   in H.264/AVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video steganography; DWT; Object detection; Object tracking; Foreground
   detection; Steganalysis
ID OBJECT TRACKING; TRANSFORM; ALGORITHM
AB The proposed scheme utilized H.264/AVC video format for steganography which is the most common video standard at present. The scheme employed Discrete Wavelet Transform (DWT) on the Region of Interest (ROI) based on multiple moving objects tracking. After tracking multiple objects, each object is embedded with different secret images to improve the capacity. Multiple object tracking helps in achieving robustness and security; in addition, secret data is encrypted before embedding to provide a high level of security. The proposed scheme is tested on numerous video sequences by evaluating both subjective and objective metrics. Different metrics employed for objective evaluation involves Peak Signal to Noise Ratio (PSNR), Mean Square Error (MSE), Structural Similarity (SSIM) Index, Normalized Cross Correlation (NCC) and Bit Error Rate (BER). However, subjective evaluation is carried out by visual inspection. Additionally, the proposed scheme has been tested against noise, compression, frame rate change and scaling attacks to ensure robustness. Further, the security performance has been analysed by testing against three existing steganalysis techniques and histogram analysis. The main aim of the paper is to focus on robustness and security without compromising hiding capacity and imperceptibility. The reckoning result proves not only high robustness and security but also improves imperceptibility and capacity.
C1 [Dalal, Mukesh; Juneja, Mamta] UIET Panjab Univ, Chandigarh, India.
C3 Panjab University
RP Juneja, M (corresponding author), UIET Panjab Univ, Chandigarh, India.
EM mukeshdalal05@gmail.com; mamtajuneja@pu.ac.in
FU Technical Education Quality Improvement Project III (TEQIP III) of MHRD,
   Government of India [P154523]
FX This research work is supported by Technical Education Quality
   Improvement Project III (TEQIP III) of MHRD, Government of India
   assisted by World Bank under Grant Number P154523 and sanctioned to
   UIET, Panjab University, Chandigarh (India).
CR Abhishek S, 2019, BIOMED SIGNAL PROCES, V47, P183, DOI 10.1016/j.bspc.2018.08.011
   Abu-El-Haija Sami, 2016, arXiv
   Ahmed EAE., 2014, INT J SCI RES, V3, P2431
   [Anonymous], 2010, INT J DATABASE MANAG
   Biryukov A., 2005, ENCY CRYPTOGRAPHY SE
   Briechle K, 2001, PROC SPIE, V4387, P95, DOI 10.1117/12.421129
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chantrapornchai C, 2014, INT J MULTIMEDIA UBI, V9, P385
   Da T, 2015, LECT NOTES COMPUTER, V9226, DOI 10.1007/978-3-319-22186-1_5
   Dalal Mukesh, 2018, Proceedings of the International Conference on Computing and Communication Systems. I3CS 2016. Lecture Notes in Networks and Systems (LNNS 24), P705, DOI 10.1007/978-981-10-6890-4_67
   Dalal M, 2020, INF SECUR J, V29, P40, DOI 10.1080/19393555.2020.1714822
   Dalal M, 2019, MULTIMED TOOLS APPL, V78, P5769, DOI 10.1007/s11042-018-6093-3
   Dalal M, 2018, INT J ELECTRON SECUR, V10, P338
   Gaj S, 2016, MULTIMED TOOLS APPL, V75, P3053, DOI 10.1007/s11042-014-2422-3
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   He YL, 2012, AEU-INT J ELECTRON C, V66, P305, DOI 10.1016/j.aeue.2011.08.007
   Hemalatha S, 2016, PERTANIKA J SCI TECH, V24, P411
   Heys HM, 2002, CRYPTOLOGIA, V26, P189, DOI 10.1080/0161-110291890885
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Li FY, 2019, MATH BIOSCI ENG, V16, P4559, DOI 10.3934/mbe.2019228
   Li G, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/293031
   Liu YX, 2013, J SYST SOFTWARE, V86, P2174, DOI 10.1016/j.jss.2013.03.101
   Long M, 2018, J REAL-TIME IMAGE PR, V14, P171, DOI 10.1007/s11554-017-0727-y
   Mohammed AA, 2018, MULTIMED TOOLS APPL, V77, P2791, DOI 10.1007/s11042-017-4427-1
   Moon SK, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P660, DOI 10.1109/ICIIP.2013.6707677
   Morkel T., 2005, ISSA, V1, P1
   Mstafa RJ, 2015, WIREL TELECOMM SYMP
   Mstafa RJ, 2017, IEEE ACCESS, V5, P5354, DOI 10.1109/ACCESS.2017.2691581
   Mstafa RJ, 2016, MULTIMED TOOLS APPL, V75, P10311, DOI 10.1007/s11042-015-3060-0
   Mstafa RJ, 2015, 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P335, DOI 10.1109/ICMLA.2015.117
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Nyo HL., 2019, INT J COMPUTER NETWO, V9, P45, DOI DOI 10.5815/IJCNIS.2019.06.06
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Ramalingam Mritha, 2020, Procedia Computer Science, V171, P1147, DOI 10.1016/j.procs.2020.04.123
   RAMALINGAM M, 2014, INDIAN J SCI TECHNOL, V7, P897
   Rezagholipour K, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT), P183, DOI 10.1109/IKT.2016.7777764
   Sadek MM, 2017, MULTIMED TOOLS APPL, V76, P3065, DOI 10.1007/s11042-015-3170-8
   Salem MA, 2009, DAUBECHIES VERSUS BI, DOI 10.18452/2487
   Weng SK, 2006, J VIS COMMUN IMAGE R, V17, P1190, DOI 10.1016/j.jvcir.2006.03.004
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   STRANG G, 1989, SIAM REV, V31, P614, DOI 10.1137/1031128
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Suresh M, 2020, MULTIMED TOOLS APPL, V79, P27023, DOI 10.1007/s11042-020-09330-6
   Thahab A, 2020, INT ARAB J INF TECHN, V17, P147, DOI 10.34028/iajit/17/2/1
   Usman M, 2017, INT J ADV COMPUT SC, V8, P402
   Wang KR, 2014, MULTIMED TOOLS APPL, V72, P313, DOI 10.1007/s11042-013-1373-4
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
NR 48
TC 3
Z9 3
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14383
EP 14407
DI 10.1007/s11042-020-10364-z
EA JAN 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000611041300003
DA 2024-07-18
ER

PT J
AU Bian, XH
   Li, JW
AF Bian, Xiaohang
   Li, Jianwu
TI Conditional adversarial consistent identity autoencoder for cross-age
   face synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face aging; rejuvenation; Adversarial network; Consistent identity loss
ID PERCEPTION
AB Learning-based face aging/rejuvenation has witnessed rapid progress in recent years. However, existing methods still suffer from the loss of personalized identity information when synthesizing cross-age faces. In this paper, we propose a Conditional Adversarial Consistent Identity AutoEncoder (CACIAE) to revisit this problem. Firstly, a Res-Encoder is designed to better generate powerful face representation. Secondly, the rectangular kernel is introduced into the encoder to make full use of horizontal continuous characteristic information of faces and to make the synthetic face images more natural. Thirdly, a novel consistent identity loss is proposed to learn more face details and produce more natural identity-preserving images. Further, two discriminators are designed to enforce the generator to generate more realistic and more age-accurate images. Experimental results prove the effectiveness of the proposed method, both qualitatively and quantitatively. The code is available at https://github.com/XH-B/CACIAE.
C1 [Bian, Xiaohang; Li, Jianwu] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Li, JW (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
EM xhang.bian@gmail.com; ljw@bit.edu.cn
OI Li, Jianwu/0000-0002-8632-4334
FU Beijing Natural Science Foundation; National Natural Science Foundation
   of China [61271374]
FX This work was supported by the Beijing Natural Science Foundation
   (No.L191004) and the National Natural Science Foundation of China
   (No.61271374).
CR Amos B, OPENFACE GEN PURPOSE
   [Anonymous], FACE TRANSFORMER FT
   Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Bengio Y., 2014, COMMUN ACM, V3, P2672
   Chen BC, 2014, LECT NOTES COMPUT SC, V8694, P768, DOI 10.1007/978-3-319-10599-4_49
   Duong CN, 2017, IEEE I CONF COMP VIS, P3755, DOI 10.1109/ICCV.2017.403
   Dosovitskiy A, 2016, 30 C NEURAL INFORM P, V29
   Duong CN, 2016, PROC CVPR IEEE, P5772, DOI 10.1109/CVPR.2016.622
   Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P488, DOI 10.1007/978-3-319-10605-2_32
   Galton Francis, 1878, Nature, P97, DOI DOI 10.2307/2841021
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Genovese A, 2019, IEEE IMAGE PROC, P3806, DOI [10.1109/icip.2019.8803616, 10.1109/ICIP.2019.8803616]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Kemelmacher-Shlizerman I, 2014, PROC CVPR IEEE, P3334, DOI 10.1109/CVPR.2014.426
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Liu S, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P82, DOI 10.1145/3123266.3123431
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Palsson S, 2018, IEEE COMPUT SOC CONF, P2165, DOI 10.1109/CVPRW.2018.00282
   Park U, 2010, IEEE T PATTERN ANAL, V32, P947, DOI 10.1109/TPAMI.2010.14
   PITTENGER JB, 1975, J EXP PSYCHOL HUMAN, V1, P374, DOI 10.1037/0096-1523.1.4.374
   Ramanathan N, 2008, IEEE INT CONF AUTOMA, P1006
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Shu XB, 2015, IEEE I CONF COMP VIS, P3970, DOI 10.1109/ICCV.2015.452
   Suo JL, 2010, IEEE T PATTERN ANAL, V32, P385, DOI 10.1109/TPAMI.2009.39
   Tiddeman B, 2001, IEEE COMPUT GRAPH, V21, P42, DOI 10.1109/38.946630
   TODD JT, 1980, SCI AM, V242, P132, DOI 10.1038/scientificamerican0280-132
   Wang W, 2016, PROC CVPR IEEE, P2378, DOI 10.1109/CVPR.2016.261
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZW, 2018, PROC CVPR IEEE, P7939, DOI 10.1109/CVPR.2018.00828
   Yang HY, 2021, IEEE T PATTERN ANAL, V43, P499, DOI 10.1109/TPAMI.2019.2930985
   Yang HY, 2018, PROC CVPR IEEE, P31, DOI 10.1109/CVPR.2018.00011
   Yin Wu, 1994, Proceedings of the Second Pacific Conference on Computer Graphics and Applications, Pacific Graphics '94. Fundamentals of Computer Graphics, P201
   Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
   Zhao J, 2019, AAAI CONF ARTIF INTE, P9251
   ZHU H, 2018, ARXIV180402740
NR 36
TC 3
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14231
EP 14253
DI 10.1007/s11042-020-10442-2
EA JAN 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000610019400013
DA 2024-07-18
ER

PT J
AU Geetha, R
   Geetha, S
AF Geetha, R.
   Geetha, S.
TI A multi-layered "plus-minus one" reversible data embedding scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Histogram; ODD; EVEN; Difference expansion; Watermark
AB Reversible Data Hiding (RDH) is one of the most well-known methods adopted for concealed communication. One of the major issues in RDH is the overflow/underflow which exists in almost all the embedding techniques. This is a major issue which hinders the hiding capacity in many existing techniques. In the proposed novel LSB ODD/EVEN embedding algorithm, neither histogram modification (which involves shifting) nor difference expansion (which involves shifting and expansion of error) techniques are involved. No overflow/underflow problem is reported in the proposed method and involves multilayer embedding. Performance of this approach or any data hiding schemes are usually measured in terms of MSE, PSNR, and SSIM. After multiple layer of embedding the PSNR for 1.5 bpp stands at 43 dB approximately. This approach is tested over standard test images that includes medical images also and compared with well-known existing schemes.
C1 [Geetha, R.] VIT Univ, SENSE, Chennai, Tamil Nadu, India.
   [Geetha, S.] VIT Univ, SCOPE, Chennai, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai; Vellore Institute of
   Technology (VIT); VIT Chennai
RP Geetha, R (corresponding author), VIT Univ, SENSE, Chennai, Tamil Nadu, India.
EM rgeetha.mariappan@gmail.com; geetha.s@vit.ac.in
RI R, Geetha/GXH-3505-2022; S, Geetha/IYJ-9136-2023
OI R, Geetha/0000-0002-4451-1844; 
CR Abadi M. A. M., 2010, 2010 5th International Symposium on Telecommunications (IST), P840, DOI 10.1109/ISTEL.2010.5734139
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abdulla AA, 2014, PROC SPIE, V9120, DOI 10.1117/12.2050518
   Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   Arsalan M, 2012, J SYST SOFTWARE, V85, P883, DOI 10.1016/j.jss.2011.11.005
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Bao F, 2005, IEEE T INF TECHNOL B, V9, P554, DOI 10.1109/TITB.2005.855556
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Caldelli R, 2010, EURASIP J INF SECUR, DOI 10.1155/2010/134546
   Cancellaro M, 2011, SIGNAL PROCESS-IMAGE, V26, P1, DOI 10.1016/j.image.2010.11.001
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Celik MU, 2006, IEEE T IMAGE PROCESS, V15, P1042, DOI 10.1109/TIP.2005.863053
   Coatrieux G, 2009, IEEE T INF TECHNOL B, V13, P158, DOI 10.1109/TITB.2008.2007199
   Coltuc D., 2009, P 2009 INT S SIGNALS, P1
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Cox IJ., 2007, DIGITAL WATERMARKING
   Eswaraiah R, 2014, INT J TELEMED APPL, V2014, DOI 10.1155/2014/984646
   Fallahpour M, 2007, IEICE ELECTRON EXPR, V4, P205, DOI 10.1587/elex.4.205
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Fridrich J., 2009, STEGANOGRAPHY DIGITA, DOI [10.1017/CBO9781139192903, DOI 10.1017/CBO9781139192903]
   Geetha R, 2018, INT C NEXT GENERATIO, V9, P601
   Gui XL, 2014, SIGNAL PROCESS, V98, P370, DOI 10.1016/j.sigpro.2013.12.005
   Guorong Xuan, 2007, Digital Watermarking. Proceedings 6th International Workshop, IWDW 2007, P264
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Lee SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1321, DOI 10.1109/icme.2006.262782
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lian SG, 2007, IEEE T CIRC SYST VID, V17, P774, DOI 10.1109/TCSVT.2007.896635
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Maity HK, 2012, PROC TECH, V1, P275, DOI 10.1016/j.protcy.2012.10.033
   Ni ZC, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P912
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Peng F, 2011, COMPUT AIDED DESIGN, V43, P1018, DOI 10.1016/j.cad.2011.03.011
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Schmitz Roland, 2012, Communications and Multimedia Security. 13th IFIP TC 6/TC 11 International Conference, CMS 2012. Proceedings, P117, DOI 10.1007/978-3-642-32805-3_10
   Shi YQ, 2005, LECT NOTES COMPUT SC, V3304, P1
   Shi YQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P33
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tong XF, 2015, LECT NOTES COMPUT SC, V9023, P201, DOI 10.1007/978-3-319-19321-2_15
   Wang X, 2007, IEEE T INF FOREN SEC, V2, P311, DOI 10.1109/TIFS.2007.902677
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Wu HT, 2015, IEEE SIGNAL PROC LET, V22, P81, DOI 10.1109/LSP.2014.2346989
   Yi S, 2018, SIGNAL PROCESS-IMAGE, V64, P78, DOI 10.1016/j.image.2018.03.001
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang WM, 2012, IEEE T IMAGE PROCESS, V21, P2991, DOI 10.1109/TIP.2012.2187667
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 54
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14123
EP 14136
DI 10.1007/s11042-021-10514-x
EA JAN 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000609068400001
DA 2024-07-18
ER

PT J
AU Singhal, A
   Bedi, P
AF Singhal, Anuradha
   Bedi, Punam
TI Multi-class blind steganalysis using deep residual networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; Convolution neural networks; Deep residual networks;
   Bottleneck residual blocks
ID IMAGE ENCRYPTION ALGORITHM
AB Camouflaged communication using a media is known as Steganography. It is different than encryption as the presence of message is also concealed in case of steganography. The message however can be encrypted before hiding in a media. Detection of concealed exchange being carried out or unraveling the details of such transmission is known as Steganalysis. Steganalysis can be detected by classifying the given media file as cover media file or stego media file. Blind steganalysis detects presence of hidden content without any knowledge about the cover media file and steganography algorithm used. Steganalysis plays a vital role in forensics of various media such as text, audio, image, video and network packets. Machine learning techniques have been widely used for steganalysis in literature. These techniques use a three step approach consisting of Feature Extraction, Training and Testing Phases. Deep learning techniques, a subset of machine learning techniques are preferred by researchers over machine learning techniques as (i) they consist of Training and Testing Phases with the feature extraction step done automatically, (ii) they give better accuracy when trained with huge amount of data. This paper proposes novel multi class blind steganalysis technique for images. Convolutional Neural Network (CNN) is one of the best known architecture used with image steganalysis. But as the depth of CNN architecture increases, problem of vanishing descent arise which affects the accuracy. In order to solve the problem of the vanishing/exploding gradient in CNN, concept called Residual Network which use a technique called skip connections is being used. The skip connection skips training from few layers and connects directly to the output. A deep residual network helps to automatically capture complex statistical features of images and preserve weak stego signal in image content making it suitable for multi class blind steganalysis. This paper uses deep residual network for multi-class blind steganalysis. Proposed DRN has been successfully applied for multi class blind steganalysis in spatial and JPEG images. Experimental results demonstrate proposed network is comparable to state or art techniques present in literature.
C1 [Singhal, Anuradha; Bedi, Punam] Univ Delhi, Dept Comp Sci, Delhi, India.
C3 University of Delhi
RP Singhal, A (corresponding author), Univ Delhi, Dept Comp Sci, Delhi, India.
EM anuradhasinghal19@gmail.com
RI Bedi, Punam/GSN-6167-2022; BEDI, PUNAM/A-9474-2010
OI Singhal, Anuradha/0000-0002-0818-6597; BEDI, PUNAM/0000-0002-6007-7961
CR [Anonymous], 2014, Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific, DOI [10.1109/APSIPA.2014, 10.1109/APSIPA.2014.7041565]
   Avcibas I., 2001, PROC SECURITY WATERM, P523
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bedi P, 2014, IEEE SYS MAN CYBERN, P3797, DOI 10.1109/SMC.2014.6974522
   Bhasin V, 2015, IBICA, P393
   Bhasin V, 2015, PROCEEDING OF THE THIRD INTERNATIONAL SYMPOSIUM ON WOMEN IN COMPUTING AND INFORMATICS (WCI-2015), P318, DOI 10.1145/2791405.2791451
   Bhasin V, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2323, DOI 10.1109/ICACCI.2014.6968568
   Bhasin V, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1948, DOI 10.1109/ICACCI.2013.6637480
   Bianchini M, 2014, IEEE T NEUR NET LEAR, V25, P1553, DOI 10.1109/TNNLS.2013.2293637
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Chaumont M., 2020, Digital Media Steganography, P321, DOI [DOI 10.1016/B978-0-12-819438-6.00022-0, 10.1016/B978-0-12-819438-6.00022-0]
   Chaumont M, 2019, ARXIV 190401444
   Chiew KL, 2010, LECT NOTES COMPUT SC, V6047, P341, DOI 10.1007/978-3-642-12827-1_25
   Dong J, 2009, LECT NOTES COMPUT SC, V5703, P199, DOI 10.1007/978-3-642-03688-0_19
   Fridrich J, 2005, PROC SPIE, V5681, P595, DOI 10.1117/12.584426
   Fridrich Jessica, 2013, Information Hiding. 14th International Conference, IH 2012 Revised Selected Papers, P31, DOI 10.1007/978-3-642-36373-3_3
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Fridrich J., 2007, P SPIE ELECT IMAGING
   Fridrich J., 2009, 11 ACM MULT SEC WORK
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   JINDAL H, 2016, P INT C REC COGN WIR, P1
   Jindal H, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500133
   Kaur Sandeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P23, DOI 10.5815/ijigsp.2017.07.03
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li, 2019, INT WORKSH DIG WAT, P84, DOI DOI 10.1007/978-3-030-43575-2_7
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Lu JC, 2014, DIGIT INVEST, V11, P57, DOI 10.1016/j.diin.2013.12.001
   Lubenko I, 2011, PROC SPIE, V7880, DOI 10.1117/12.872245
   Lyu SW, 2006, IEEE T INF FOREN SEC, V1, P111, DOI 10.1109/TIFS.2005.863485
   Mander Kuldeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P17, DOI 10.5815/ijigsp.2017.08.03
   Mittal Archie, 2017, International Journal of Image, Graphics and Signal Processing, V9, P28, DOI 10.5815/ijigsp.2017.05.04
   Nissar A, 2010, DIGIT SIGNAL PROCESS, V20, P1758, DOI 10.1016/j.dsp.2010.02.003
   Pevny T, 2005, LECT NOTES COMPUT SC, V3710, P39
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Savoldi A, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL II, PROCEEDINGS, P93
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Solanki K, 2007, LECT NOTES COMPUT SC, V4567, P16
   Sun ZW, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P1097, DOI 10.1109/IIH-MSP.2008.176
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tang WX, 2016, IEEE T INF FOREN SEC, V11, P734, DOI 10.1109/TIFS.2015.2507159
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wu ST, 2018, MULTIMED TOOLS APPL, V77, P10437, DOI 10.1007/s11042-017-4440-4
   Wu ST, 2017, IEEE INT CON MULTI, P241, DOI 10.1109/ICME.2017.8019304
   Wu ST, 2016, INT C PAR DISTRIB SY, P1233, DOI [10.1109/ICPADS.2016.165, 10.1109/ICPADS.2016.0167]
   Xu G., 2016, P 4 ACM WORKSH INF H, P103, DOI DOI 10.1145/2909827.2930798
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Yedroudj M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2092, DOI 10.1109/ICASSP.2018.8461438
   Zeng LW, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107576
   Zhang S, 2018, INT WORKSH DIG WAT, P40
   Zhang Z, 2013, 2013 9TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P437, DOI 10.1109/CIS.2013.99
   Zhao H, 2011, SIGNAL PROCESS, V91, P2595, DOI 10.1016/j.sigpro.2011.05.015
   Zong H, 2012, DIGIT INVEST, V9, P58, DOI 10.1016/j.diin.2012.02.003
NR 70
TC 11
Z9 11
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13931
EP 13956
DI 10.1007/s11042-020-10353-2
EA JAN 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000608968500002
DA 2024-07-18
ER

PT J
AU Itier, V
   Strauss, O
   Morel, L
   Puech, W
AF Itier, Vincent
   Strauss, Olivier
   Morel, Laurent
   Puech, William
TI Color noise correlation-based splicing detection for image forensics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image splicing detection; Color noise correlation; Image forensics
ID LOCALIZATION; FORGERIES
AB Today, it has become very easy to manipulate digital images using image processing tools and software such as Adobe Photoshop (). Tampering with images by splicing is an operation that consists of cutting-and-pasting an area of an image into another host image. In this paper, we propose to detect and localize such manipulations by analyzing the correlation of the image noise across the three color channels RGB, which is an intrinsic feature of the digital photography acquisition process. More precisely, we propose to detect the border between the background (host image) and the spliced area. Using a sliding window, we detect the blocks that span across the two areas which are characterized by two different color noise correlations. To do this, we propose specific features that are able to highlight these blocks. After the feature extraction, we introduce a learning phase using a Random Forest Classifier. Experimental results, specifically on the Columbia database, show very good results in comparison to other current state of the art methods.
C1 [Itier, Vincent] Univ Lille, CNRS, IMT Lille Douai, CRIStAL, Lille, France.
   [Strauss, Olivier; Puech, William] Univ Montpellier, LIRMM, CNRS, Montpellier, France.
   [Morel, Laurent] Netheos Co, Montpellier, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Lille; Centrale Lille; IMT - Institut Mines-Telecom; IMT Nord Europe;
   Centre National de la Recherche Scientifique (CNRS); Universite
   Paul-Valery; Universite Perpignan Via Domitia; Universite de Montpellier
RP Puech, W (corresponding author), Univ Montpellier, LIRMM, CNRS, Montpellier, France.
EM vincent.itier@imt-lille-douai.fr; olivier.strauss@lirmm.fr;
   l.morel@netheos.net; william.puech@lirmm.fr
OI Puech, William/0000-0001-9383-2401
FU French ANR/DGA challenge DEFALS (DEtection de FALSifications dans des
   images) [ANR-16-DEFA-0001 OEIL]; Agence Nationale de la Recherche (ANR)
   [ANR-16-DEFA-0001] Funding Source: Agence Nationale de la Recherche
   (ANR)
FX We would like to thank ANR-16-DEFA-0001 OEIL (statistiques rObustEs pour
   l'apprentIssage Leger) research project of the French ANR/DGA challenge
   DEFALS (DEtection de FALSifications dans des images) for their financial
   support.
CR Alahmadi AA, 2013, IEEE GLOB CONF SIG, P253, DOI 10.1109/GlobalSIP.2013.6736863
   Amerini I, 2014, IEEE INT WORKS INFOR, P143, DOI 10.1109/WIFS.2014.7084318
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2009, SIGNAL PROCESSING AD
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen YL, 2011, IEEE T INF FOREN SEC, V6, P396, DOI 10.1109/TIFS.2011.2106121
   Chennamma H.R., 2010, International Journal of Computer Science Issues, V7, P149
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cox I.J., 2002, Digital watermarking, V1558607145
   Cozzolino D, 2015, IEEE INT WORKS INFOR
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Destruel C, 2018, IEEE INT WORKSH MULT
   Dias Z, 2012, IEEE T INF FOREN SEC, V7, P774, DOI 10.1109/TIFS.2011.2169959
   Dirik AE, 2009, IEEE IMAGE PROC, P1497, DOI 10.1109/ICIP.2009.5414611
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Hsu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P549, DOI 10.1109/ICME.2006.262447
   Iakovidou C, 2018, J VIS COMMUN IMAGE R, V54, P155, DOI 10.1016/j.jvcir.2018.05.011
   Iuliani M, 2015, IEEE INT WORKS INFOR
   Krawetz N., 2007, HACKER FACTOR SOLUTI, P1
   Li WH, 2009, SIGNAL PROCESS, V89, P1821, DOI 10.1016/j.sigpro.2009.03.025
   Liu Y, 2017, BIOMEDICAL ENG INFOR, P1
   Liu YQ, 2018, MULTIMED TOOLS APPL, V77, P18269, DOI 10.1007/s11042-017-5374-6
   Luo WQ, 2007, INT CONF ACOUST SPEE, P217
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   Mayer O, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2012, DOI 10.1109/ICASSP.2018.8462585
   Pan X, 2012, INT C COMP PHOT ICCP, P1
   Pomari T, 2018, IEEE IMAGE PROC, P3788, DOI 10.1109/ICIP.2018.8451227
   Pun CM, 2016, J VIS COMMUN IMAGE R, V38, P195, DOI 10.1016/j.jvcir.2016.03.005
   Rao Y, 2016, IEEE INT WORKS INFOR
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Simonyan K, 2015, IEEE INT C ICLR
   Wang W, 2009, IEEE IMAGE PROC, P1257, DOI 10.1109/ICIP.2009.5413549
   Wu Y, 2018, IEEE WINT CONF APPL, P1907, DOI 10.1109/WACV.2018.00211
   Zampoglou M, 2017, MULTIMED TOOLS APPL, V76, P4801, DOI 10.1007/s11042-016-3795-2
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
NR 41
TC 10
Z9 11
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13215
EP 13233
DI 10.1007/s11042-020-10326-5
EA JAN 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607504000002
DA 2024-07-18
ER

PT J
AU Chen, XD
   Liang, HT
   Xu, HY
   Ren, SY
   Cai, HY
   Wang, Y
AF Chen, Xiaodong
   Liang, Haitao
   Xu, Huaiyuan
   Ren, Siyu
   Cai, Huaiyu
   Wang, Yi
TI Disocclusion-type aware hole filling method for view synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth-image-based rendering; 3D video; Single view synthesis;
   Disocclusion filling; Foreground removal
ID IMAGE GENERATION; VIDEO; DIBR; COMPRESSION; COMPLETION; MULTIVIEW;
   REMOVAL
AB Depth-image-based rendering is an efficient way to produce content for 3D video and free viewpoint video. However, since the background that is occluded by the foreground objects in the reference view may become visible in the synthesized view, disocclusions are produced. In this paper, a disocclusion-type aware hole filling method is proposed for disocclusion handling. Disocclusions are divided into two types based on the depth value of their boundary pixels: foreground-background (FG-BG) disocclusion and background-background (BG-BG) disocclusion. For FG-BG disocclusion, the depth values of the associated pixels are optimized in the reference image to ensure the removal of ghosts and adaptively divide the disocclusion into some small holes. For BG-BG disocclusion, a foreground removal method is applied to remove the corresponding foreground objects. The removed regions are filled with the surrounding background textures so that the BG-BG disocclusion in the synthesized image can be eliminated. Experimental results indicate that the proposed method outperforms the other methods in the objective and subjective evaluations.
C1 [Chen, Xiaodong; Liang, Haitao; Xu, Huaiyuan; Ren, Siyu; Cai, Huaiyu; Wang, Yi] Tianjin Univ, Sch Precis Instrument & Optoelect Engn, Tianjin, Peoples R China.
   [Chen, Xiaodong; Liang, Haitao; Xu, Huaiyuan; Ren, Siyu; Cai, Huaiyu; Wang, Yi] Tianjin Univ, Minist Educ, Key Lab Optoelect Informat Technol, Tianjin 300072, Peoples R China.
C3 Tianjin University; Tianjin University
RP Wang, Y (corresponding author), Tianjin Univ, Sch Precis Instrument & Optoelect Engn, Tianjin, Peoples R China.; Wang, Y (corresponding author), Tianjin Univ, Minist Educ, Key Lab Optoelect Informat Technol, Tianjin 300072, Peoples R China.
EM koala_wy@tju.edu.cn
FU National Major Project of Scientific and Technical Supporting Programs
   of China during the 13th Five-year Plan Period [2017YFC0109702,
   2017YFC0109901, 2018YFC0116202]
FX This work was funded by the National Major Project of Scientific and
   Technical Supporting Programs of China during the 13th Five-year Plan
   Period (grant numbers 2017YFC0109702, 2017YFC0109901, and
   2018YFC0116202).
CR Ahn I, 2013, IEEE T BROADCAST, V59, P614, DOI 10.1109/TBC.2013.2281658
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Chen WY, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1315
   CHEN XD, 2019, APPL SCI BASEL, V9
   CHEN XD, 2020, APPL SCI BASEL, V10
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Daribo I, 2011, IEEE T BROADCAST, V57, P533, DOI 10.1109/TBC.2011.2125110
   de Oliveira AQ, 2018, IEEE SIGNAL PROC LET, V25, P1705, DOI 10.1109/LSP.2018.2870342
   Deng ZM, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8050823
   Dong GS, 2020, REMOTE SENS ENVIRON, V237, DOI 10.1016/j.rse.2019.111602
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Greene N., 1993, Computer Graphics Proceedings, P231, DOI 10.1145/166117.166147
   Han DX, 2018, J VIS COMMUN IMAGE R, V56, P287, DOI 10.1016/j.jvcir.2018.10.004
   Kao CC, 2017, MULTIMED TOOLS APPL, V76, P12981, DOI 10.1007/s11042-016-3733-3
   Kim S, 2018, J OPT SOC AM A, V35, P1653, DOI 10.1364/JOSAA.35.001653
   Lei JJ, 2017, MULTIMED TOOLS APPL, V76, P7661, DOI 10.1007/s11042-016-3413-3
   Li S, 2018, IEEE T MULTIMEDIA, V20, P1948, DOI 10.1109/TMM.2018.2791810
   Liang ZY, 2020, IEEE T IMAGE PROCESS, V29, P3351, DOI 10.1109/TIP.2019.2959256
   Lie WN, 2018, IEEE T MULTIMEDIA, V20, P1075, DOI 10.1109/TMM.2017.2763319
   Lim H, 2011, IEEE IMAGE PROC, P1089, DOI 10.1109/ICIP.2011.6115615
   Liu SH, 2015, J SUPERCOMPUT, V71, P3353, DOI 10.1007/s11227-015-1413-0
   Liu W, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0175910
   Luo GB, 2020, IEEE T PATTERN ANAL, V42, P1289, DOI 10.1109/TPAMI.2019.2899837
   Luo GB, 2017, IEEE T CIRC SYST VID, V27, P2118, DOI 10.1109/TCSVT.2016.2583978
   Luo GB, 2016, PROC CVPR IEEE, P1781, DOI 10.1109/CVPR.2016.197
   Mori Y, 2009, SIGNAL PROCESS-IMAGE, V24, P65, DOI 10.1016/j.image.2008.10.013
   Muddala SM, 2016, J VIS COMMUN IMAGE R, V38, P351, DOI 10.1016/j.jvcir.2016.02.017
   Nazeri K., 2019, ARXIV190100212
   Ndjiki-Nya P, 2011, IEEE T MULTIMEDIA, V13, P453, DOI 10.1109/TMM.2011.2128862
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Rahmatov N, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719883551
   Shao F, 2017, OPT EXPRESS, V25, P12478, DOI 10.1364/OE.25.012478
   Shen JB, 2007, COMPUT GRAPH-UK, V31, P119, DOI 10.1016/j.cag.2006.10.004
   Shen JB, 2006, VISUAL COMPUT, V22, P936, DOI 10.1007/s00371-006-0079-2
   Shen JB, 2013, IEEE T CYBERNETICS, V43, P1453, DOI 10.1109/TCYB.2013.2273270
   Sun WX, 2012, IEEE IMAGE PROC, P2721, DOI 10.1109/ICIP.2012.6467461
   Tam WJ, 2004, PROC SPIE, V5599, P162, DOI 10.1117/12.583105
   Tech G, 2016, IEEE T CIRC SYST VID, V26, P35, DOI 10.1109/TCSVT.2015.2477935
   Wang LH, 2010, IEEE T BROADCAST, V56, P425, DOI 10.1109/TBC.2010.2053971
   Wang WG, 2019, IEEE T PATTERN ANAL, V41, P1531, DOI 10.1109/TPAMI.2018.2840724
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Wang WG, 2017, IEEE T VIS COMPUT GR, V23, P2014, DOI 10.1109/TVCG.2016.2600594
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhu C, 2016, IEEE T BROADCAST, V62, P82, DOI 10.1109/TBC.2015.2475697
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 48
TC 2
Z9 2
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11557
EP 11581
DI 10.1007/s11042-020-10196-x
EA JAN 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000605548700025
DA 2024-07-18
ER

PT J
AU Dorgham, OM
   Alweshah, M
   Ryalat, MH
   Alshaer, J
   Khader, M
   Alkhalaileh, S
AF Dorgham, O. M.
   Alweshah, Mohammed
   Ryalat, M. H.
   Alshaer, J.
   Khader, M.
   Alkhalaileh, S.
TI Monarch butterfly optimization algorithm for computed tomography image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Classification problems; Metaheuristics; Monarch
   butterfly optimization
ID LOCAL SEARCH
AB In the medical field, image segmentation provides important information for surgical planning and registration, and thus demands accurate segmentation. In order to improve the effectiveness and the threshold accuracy of segmentation, researchers have tended to use a metaheuristic algorithm as the operational algorithm to achieve better exploitation and exploration of the search space and to solve many different medical image problems in an effective manner. This research applies the monarch butterfly optimization (MBO) algorithm for image segmentation at multiple threshold values. To evaluate the performance of the implemented MBO algorithm, a comparison is made with the brute-force (i.e. Otsu) algorithm and two metaheuristic algorithms (i.e. Darwinian particle swarm optimization (DPSO) and fractional-order DPSO). In addition, the quality structural similarity index matrix and the peak signal-to-noise ratio are used to evaluate the accuracy of the resultant segmented images. The experimental results show the advantage of using the MBO algorithm for medical image segmentation in terms of accuracy and speed. Regards the accuracy, MBO algorithm produced an exact match at thresholds 1 and 2 and a very close match at thresholds 3 and 4. Regards the speed, the average of the execution time for threshold 1 was 0.24187 s, for threshold 2 was 0.33831 s, for threshold 3 was 0.95967 s and for threshold 4 it was 1.15308 s.
C1 [Dorgham, O. M.; Alweshah, Mohammed; Ryalat, M. H.; Alshaer, J.; Khader, M.; Alkhalaileh, S.] Al Balqa Appl Univ, Prince Abdullah bin Ghazi Fac Informat & Commun T, Al Salt, Jordan.
C3 Al-Balqa Applied University
RP Dorgham, OM (corresponding author), Al Balqa Appl Univ, Prince Abdullah bin Ghazi Fac Informat & Commun T, Al Salt, Jordan.
EM o.dorgham@bau.edu.jo; weshah@bau.edu.jo; ryalat@bau.edu.jo;
   jawdat_alshaer@bau.edu.jo; mossab.one@gmail.com; saleh.fayez@hotmail.com
RI Ryalat, Mohammad Hashem/AAD-2658-2020; Alweshah, Mohammed/F-9042-2017;
   Dorgham, Osama/F-9617-2017
OI Ryalat, Mohammad Hashem/0000-0002-8726-3406; Alweshah,
   Mohammed/0000-0002-3724-5111; Dorgham, Osama/0000-0001-9807-7820
FU Deanship of Scientific Research at Al-Balqa Applied University in Jordan
FX This research was supported by the Deanship of Scientific Research at
   Al-Balqa Applied University in Jordan.
CR Ahmed PK, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1497-9
   Al-amri S., 2010, International Journal on Computer Science and Engineering, V2, P804
   Alihodzic A, 2014, SCI WORLD J, DOI 10.1155/2014/176718
   Alshareef A M., 2015, International Journal of Big Data Intelligence, P285
   Alweshah M, 2022, NEURAL COMPUT APPL, V34, P11267, DOI 10.1007/s00521-020-05210-0
   Alweshah M, 2021, SOFT COMPUT, V25, P517, DOI 10.1007/s00500-020-05164-4
   Alweshah M, 2020, CLUSTER COMPUT, V23, P2703, DOI 10.1007/s10586-019-03038-5
   Alweshah M, 2020, J AMB INTEL HUM COMP, V11, P3405, DOI 10.1007/s12652-019-01543-4
   Angelina S., 2012, 2012 International Conference on Computing, Electronics and Electrical Technologies (ICCEET 2012), P970, DOI 10.1109/ICCEET.2012.6203833
   Anitha V, 2016, IET COMPUT VIS, V10, P9, DOI 10.1049/iet-cvi.2014.0193
   Anjna E, 2017, INT J, V8, P2017
   [Anonymous], 2013, ARXIV13016011
   Ansar Wazib, 2017, CSI Transactions on ICT, V5, P59, DOI 10.1007/s40012-016-0130-z
   Ansar W, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1004, DOI 10.1109/ICCSP.2016.7754300
   Arora S, 2008, PATTERN RECOGN LETT, V29, P119, DOI 10.1016/j.patrec.2007.09.005
   Batlle J, 2000, IMAGE VISION COMPUT, V18, P515, DOI 10.1016/S0262-8856(99)00040-2
   Cenamor I, 2017, EXPERT SYST APPL, V69, P1, DOI 10.1016/j.eswa.2016.10.030
   Cheng XY, 2009, 2008 INTERNATIONAL WORKSHOP ON EDUCATION TECHNOLOGY AND TRAINING AND 2008 INTERNATIONAL WORKSHOP ON GEOSCIENCE AND REMOTE SENSING, VOL 2, PROCEEDINGS,, P804, DOI 10.1109/ETTandGRS.2008.408
   Chowdhary CL, 2020, PROCEDIA COMPUT SCI, V167, P26, DOI 10.1016/j.procs.2020.03.179
   Chowdhary CL, 2016, ADV INTELL SYST, V411, P325, DOI 10.1007/978-81-322-2731-1_30
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Dehariya V. K., 2010, Proceedings of the 2010 International Conference on Computational Intelligence and Communication Networks (CICN 2010), P386, DOI 10.1109/CICN.2010.80
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   Diwakar M, 2018, IET IMAGE PROCESS, V12, P708, DOI 10.1049/iet-ipr.2017.0639
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Dorgham O, 2020, INFORM MED UNLOCKED, V20, P1
   Dorgham O.M., 2017, 2017 International Conference on Advanced Technologies for Signal and Image Processing (ATSIP), P1
   Feng YH, 2018, NEURAL COMPUT APPL, V30, P3019, DOI 10.1007/s00521-017-2903-1
   Feng Y, 2017, NEURAL COMPUT APPL, V28, P1619, DOI 10.1007/s00521-015-2135-1
   Fisher M, 2013, INT J COMPUT ASS RAD, V8, P313, DOI 10.1007/s11548-012-0783-5
   Han YF, 2007, NEUROCOMPUTING, V70, P665, DOI 10.1016/j.neucom.2006.10.022
   He LF, 2017, NEUROCOMPUTING, V240, P152, DOI 10.1016/j.neucom.2017.02.040
   Holzinger A, 2019, WIRES DATA MIN KNOWL, V9, DOI 10.1002/widm.1312
   Holzinger A, 2019, APPL INTELL, V49, P2401, DOI 10.1007/s10489-018-1361-5
   Holzinger Andreas, 2016, Brain Inform, V3, P119, DOI 10.1007/s40708-016-0042-6
   Kandwal R., 2014, INT J ADV RES COMPUT, V4, P2277
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Khairuzzaman AKM, 2017, EXPERT SYST APPL, V86, P64, DOI 10.1016/j.eswa.2017.04.029
   Khokher MR, 2013, IET IMAGE PROCESS, V7, P201, DOI 10.1049/iet-ipr.2012.0082
   Krishna R. V. V., 2017, Lecture Notes in Engineering and Computer Science, IMECS 2017. International MultiConference of Engineers and Computer Scientists 2017, P395
   Kumar M, 2019, J KING SAUD UNIV-COM, V31, P113, DOI 10.1016/j.jksuci.2016.12.002
   Kumar M, 2018, J KING SAUD UNIV-COM, V30, P41, DOI 10.1016/j.jksuci.2016.03.003
   Lin J, 2019, ENG APPL ARTIF INTEL, V77, P186, DOI 10.1016/j.engappai.2018.10.008
   Lindeberg T, 1997, COMPUT VIS IMAGE UND, V67, P88, DOI 10.1006/cviu.1996.0510
   Maltra M, 2008, EXPERT SYST APPL, V34, P1341, DOI 10.1016/j.eswa.2007.01.002
   Mostafa A, 2018, STUD COMPUT INTELL, V730, P41, DOI 10.1007/978-3-319-63754-9_3
   Mousavirad S. J., 2018, Information Innovation Technology in Smart Cities, P75
   Nandy S, 2015, INTELL AUTOM SOFT CO, V21, P673, DOI 10.1080/10798587.2015.1025480
   Natarajan M., 2019, INT J RECENT TECHNOL, V8, P3958
   Ouadfel S, 2003, IEEE IMAGE PROC, P133
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Pare S, 2017, EXPERT SYST APPL, V87, P335, DOI 10.1016/j.eswa.2017.06.021
   Pereira C, 2015, INFORM SCIENCES, V296, P14, DOI 10.1016/j.ins.2014.10.059
   Rakoth S., 2017, INT J COMPUTER APPL, V164, P28, DOI [10.5120/ijca2017913616, DOI 10.5120/IJCA2017913616]
   Ryalat MH, 2017, ADV INTELL SYST, V539, P61, DOI 10.1007/978-3-319-48944-5_6
   Sambandam RK, 2018, J KING SAUD UNIV-COM, V30, P449, DOI 10.1016/j.jksuci.2016.11.002
   Sammouda R, 2014, COMPUT HUM BEHAV, V30, P436, DOI 10.1016/j.chb.2013.06.025
   Satapathy SC, 2018, NEURAL COMPUT APPL, V29, P1285, DOI 10.1007/s00521-016-2645-5
   Satheesh K. G., 2017, INT J INTELL ENG SYS, V10, P9, DOI DOI 10.22266/IJIES2017.1231.02
   Senthilkumaran N, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN RECENT TECHNOLOGIES IN COMMUNICATION AND COMPUTING (ARTCOM 2009), P844, DOI 10.1109/ARTCom.2009.219
   Shakeel PM, 2022, NEURAL COMPUT APPL, V34, P9579, DOI 10.1007/s00521-020-04842-6
   Shivali, 2018, ADV INTELL SYST, V562, P11, DOI 10.1007/978-981-10-4603-2_2
   Singh BK, 2016, EXPERT SYST APPL, V66, P114, DOI 10.1016/j.eswa.2016.09.006
   Tao WB, 2007, PATTERN RECOGN LETT, V28, P788, DOI 10.1016/j.patrec.2006.11.007
   Thangavel K, 2005, INT J ARTIF INTELL M, V3, P2005
   Luong TV, 2013, IEEE T COMPUT, V62, P173, DOI 10.1109/TC.2011.206
   Tu B, 2018, IEEE J-STARS, V11, P4063, DOI 10.1109/JSTARS.2018.2869376
   Vickers NJ, 2017, CURR BIOL, V27, pR713, DOI 10.1016/j.cub.2017.05.064
   Wang GG, 2019, NEURAL COMPUT APPL, V31, P1995, DOI 10.1007/s00521-015-1923-y
   Wangchamhan T, 2016, INT JOINT CONF COMP, P466
   Xu XL, 2017, 2017 INTERNATIONAL CONFERENCE ON CYBER-ENABLED DISTRIBUTED COMPUTING AND KNOWLEDGE DISCOVERY (CYBERC), P283, DOI 10.1109/CyberC.2017.53
   Yambal M., 2013, International Journal of Advanced Research in Computer and Communication Engineering, V2, P2927
NR 72
TC 20
Z9 21
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30057
EP 30090
DI 10.1007/s11042-020-10147-6
EA JAN 2021
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000605548700013
DA 2024-07-18
ER

PT J
AU Roy, PP
   Kumar, P
   Patidar, S
   Saini, R
AF Roy, Partha Pratim
   Kumar, Pradeep
   Patidar, Shweta
   Saini, Rajkumar
TI 3D word spotting using leap motion sensor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D words; Air-writing; Spotting; HMM; Leap motion; Human computer
   interface
ID RECOGNITION
AB Leap motion sensor provides a new way of interaction with computers or mobile devices. With this sensor, users can write in air by moving palm or finger, thus, avoiding traditional pen and paper for writing. The strokes of air-writing or 3D writing is different from conventional way of writing. In 3D writing, the words are connected by continuous lines instead of space between them. Also, the arbitrary size of characters and presence of frequent jitters in strokes make the recognition tasks of such words and sentences difficult. To understand the semantics of a word without recognizing each character of words, the alternative process called "word-spotting" is being used. Word-spotting is often useful than conventional recognition systems to understand complex handwriting. Hence, we propose a novel word spotting methodology for 3D text using Leap motion sensor data. Spotting/detection of a keyword in 3D sentences is carried out using Hidden Markov Model (HMM) framework. From experimental study, an average of 41.7 is recorded in terms of Mean-Average-Precision (MAP). The efficiency of the system is demonstrated by comparing traditional segmentation based system. The improved performance shows that the system could be used in developing novel applications in Human-Computer-Interaction (HCI) domain.
C1 [Roy, Partha Pratim; Kumar, Pradeep; Patidar, Shweta] IIT Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
   [Saini, Rajkumar] Lulea Tekn Univ, Dept Comp Sci Elect & Space Engn, EISLAB Machine Learning, Lulea, Sweden.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Lulea University of Technology
RP Kumar, P (corresponding author), IIT Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
EM proy.fcs@iitr.ac.in; pradeep.iitr7@gmail.com;
   shweta.patidar24@gmail.com; rajkumar.saini@ltu.se
RI Kumar, Pradeep/GQA-7930-2022; Kumar, Pradeep/GQV-5790-2022; Roy,
   Partha/J-2168-2019
CR Agarwal C, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P539, DOI 10.1109/ACPR.2015.7486561
   Amma C, 2012, IEEE INT SYM WRBL CO, P52, DOI 10.1109/ISWC.2012.21
   Baljekar P, 2014, IEEE W SP LANG TECH, P536, DOI 10.1109/SLT.2014.7078631
   Bassily D., 2014, ISR ROBOTIK 2014, P1
   Behera SK, 2018, EXPERT SYST APPL, V100, P106, DOI 10.1016/j.eswa.2018.01.042
   Bharath A, 2012, IEEE T PATTERN ANAL, V34, P670, DOI 10.1109/TPAMI.2011.234
   Chen MY, 2016, IEEE T HUM-MACH SYST, V46, P403, DOI 10.1109/THMS.2015.2492598
   Chuan CH, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P541, DOI 10.1109/ICMLA.2014.110
   Das A, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P426, DOI 10.1109/ACPR.2015.7486539
   España-Boquera S, 2011, IEEE T PATTERN ANAL, V33, P767, DOI 10.1109/TPAMI.2010.141
   Fischer A., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3416, DOI 10.1109/ICPR.2010.834
   Fischer A, 2012, PATTERN RECOGN LETT, V33, P934, DOI 10.1016/j.patrec.2011.09.009
   Frinken V, 2012, IEEE T PATTERN ANAL, V34, P211, DOI 10.1109/TPAMI.2011.113
   Jaeger S., 2001, International Journal on Document Analysis and Recognition, V3, P169, DOI 10.1007/PL00013559
   Khademi M., 2014, Conference on Human Factors in Computing Systems - Proceedings, (February 2015), P1663, DOI [10.1145/2559206.2581203, DOI 10.1145/2559206.2581203]
   Kovalchuk A, 2014, INT CONF FRONT HAND, P3, DOI 10.1109/ICFHR.2014.9
   Kumar P, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P157, DOI 10.23919/MVA.2017.7986825
   Kumar P, 2017, MULTIMED TOOLS APPL, V76, P16491, DOI 10.1007/s11042-016-3923-z
   Kumar P, 2017, IEEE SENS J, V17, P1293, DOI 10.1109/JSEN.2016.2643165
   Lai CS, 2001, INT CONF ACOUST SPEE, P377, DOI 10.1109/ICASSP.2001.940846
   LeapMotion, 2021, LEAP MOTION CONTROLL
   Lee S., 2014, INT J MULTIMEDIA UBI, V9, P397
   Markussen A, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1073, DOI 10.1145/2556288.2556964
   Mittal A, 2019, IEEE SENS J, V19, P7056, DOI 10.1109/JSEN.2019.2909837
   Mukherjee S, 2019, EXPERT SYST APPL, V136, P217, DOI 10.1016/j.eswa.2019.06.034
   Nigam I, 2014, IEEE IMAGE PROC, P5012, DOI 10.1109/ICIP.2014.7026015
   Ning Xu, 2015, Image and Graphics. 8th International Conference, ICIG 2015. Proceedings: LNCS 9219, P160, DOI 10.1007/978-3-319-21969-1_14
   Potter L.E., 2013, P 25 AUSTR COMPUTER, P175, DOI [10.1145/2541016.2541072, DOI 10.1145/2541016.2541072]
   Rodríguez-Serrano JA, 2009, PATTERN RECOGN, V42, P2106, DOI 10.1016/j.patcog.2009.02.005
   Roy PP, 2017, EXPERT SYST APPL, V76, P113, DOI 10.1016/j.eswa.2017.01.027
   Wang K, 2010, LECT NOTES COMPUT SC, V6311, P591, DOI 10.1007/978-3-642-15549-9_43
   Weichert F, 2013, SENSORS-BASEL, V13, P6380, DOI 10.3390/s130506380
   Xu N, 2015, LECT NOTES COMPUT SC, V9314, P171, DOI 10.1007/978-3-319-24075-6_17
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 34
TC 6
Z9 6
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11671
EP 11689
DI 10.1007/s11042-020-10229-5
EA JAN 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000605548700020
DA 2024-07-18
ER

PT J
AU Cheng, Q
   Wang, GD
AF Cheng, Qi
   Wang, Guodong
TI Shape awareness and structure-preserving network for arbitrary shape
   text detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text detection; Convolutional neural network; Gate convolution; Tree
   filter; Boundary information; Structure-preserving
AB Recently, scene text detection has witnessed rapid advancement. However, there still exits two limitations: (1) boundary information is processed with color, texture information together inside a deep CNN, this however may not be ideal as they have different type of information relevant for adjacent text discrimination; (2) previous methods are lack of text structure preservation, which prevents network to accurately localization when enlarging receptive fields. In this paper, we propose two modules named Gate Convolution Module (GCM) and Tree Filter Module (TFM) respectively. GCM is a separate processing branch which leverages text shape information to split the close text instances. TFM models long-range dependencies while preserving the text details by exploiting the structural property of minimal spanning tree. Benefiting from two modules, our method effectively separates the text instances which are close to each other, while preserving detailed text structure. Extensive experiments on four standard text benchmarks (ICDAR2015, MSRA-TD500, CTW1500 and Total-Text) demonstrate that our method achieves the excellent performance.
C1 [Cheng, Qi; Wang, Guodong] Qingdao Univ, Coll Comp Sci & Technol, Qingdao, Peoples R China.
C3 Qingdao University
RP Wang, GD (corresponding author), Qingdao Univ, Coll Comp Sci & Technol, Qingdao, Peoples R China.
EM doctorwgd@gmail.com
FU Natural Science Foundation of Shandong Province [ZR2019MF050]; Shandong
   Province colleges and universities youth innovation technology plan
   innovation team project [2020KJN011]
FX This work is supported by the Natural Science Foundation of Shandong
   Province (ZR2019MF050), the Shandong Province colleges and universities
   youth innovation technology plan innovation team project under Grant
   (No.2020KJN011).
CR Baek Y, 2019, PROC CVPR IEEE, P9357, DOI 10.1109/CVPR.2019.00959
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Ch'ng CK, 2017, PROC INT CONF DOC, P935, DOI 10.1109/ICDAR.2017.157
   Deng D, 2018, AAAI CONF ARTIF INTE, P6773
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He WH, 2017, IEEE I CONF COMP VIS, P745, DOI 10.1109/ICCV.2017.87
   Hu SY, 2020, MULTIMED TOOLS APPL, V79, P1427, DOI 10.1007/s11042-019-08241-5
   ICDAR, 2019, AOB READ CHALL MULT
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Liao MH, 2020, AAAI CONF ARTIF INTE, V34, P11474
   Liao MH, 2018, PROC CVPR IEEE, P5909, DOI 10.1109/CVPR.2018.00619
   Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu CB, 2020, IEEE T MULTIMEDIA, V22, P1785, DOI 10.1109/TMM.2019.2954747
   Liu YL, 2019, PATTERN RECOGN, V90, P337, DOI 10.1016/j.patcog.2019.02.002
   Liu ZC, 2019, PROC CVPR IEEE, P7261, DOI 10.1109/CVPR.2019.00744
   Liu ZC, 2018, PROC CVPR IEEE, P6936, DOI 10.1109/CVPR.2018.00725
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Long SB, 2018, LECT NOTES COMPUT SC, V11206, P19, DOI 10.1007/978-3-030-01216-8_2
   Lyu PY, 2018, PROC CVPR IEEE, P7553, DOI 10.1109/CVPR.2018.00788
   Lyu PY, 2018, LECT NOTES COMPUT SC, V11218, P71, DOI 10.1007/978-3-030-01264-9_5
   Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020
   Tian CW, 2021, IEEE T MULTIMEDIA, V23, P1489, DOI 10.1109/TMM.2020.2999182
   Tian SX, 2017, IEEE I CONF COMP VIS, P1501, DOI 10.1109/ICCV.2017.166
   Tian ZT, 2019, PROC CVPR IEEE, P4229, DOI 10.1109/CVPR.2019.00436
   van den Oord A, 2016, ADV NEUR IN, V29
   Wang JR, 2019, PROC INT C TOOLS ART, P947, DOI 10.1109/ICTAI.2019.00134
   Wang WH, 2019, IEEE I CONF COMP VIS, P8439, DOI 10.1109/ICCV.2019.00853
   Wang WH, 2019, PROC CVPR IEEE, P9328, DOI 10.1109/CVPR.2019.00956
   Wang Wenjia, 2020, P ECCV
   Wang XB, 2019, PROC CVPR IEEE, P6442, DOI 10.1109/CVPR.2019.00661
   Wang YJ, 2020, MULTIMED TOOLS APPL, V79, P1057, DOI 10.1007/s11042-019-08208-6
   Wang YJ, 2019, MULTIMED TOOLS APPL, V78, P19945, DOI 10.1007/s11042-019-7377-y
   Wang ZS, 2020, IEEE ACCESS, V8, P71353, DOI 10.1109/ACCESS.2020.2986267
   Xie EZ, 2019, AAAI CONF ARTIF INTE, P9038
   Xie LL, 2019, AAAI CONF ARTIF INTE, P9046
   Xu YC, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2900589
   Xue CH, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P989
   Xue CH, 2018, LECT NOTES COMPUT SC, V11220, P370, DOI 10.1007/978-3-030-01270-0_22
   Yang QX, 2015, IEEE T PATTERN ANAL, V37, P834, DOI 10.1109/TPAMI.2014.2353642
   Yang ZL, 2019, IEEE T INF FOREN SEC, V14, P1280, DOI 10.1109/TIFS.2018.2871746
   Yao C, 2014, IEEE T IMAGE PROCESS, V23, P4737, DOI 10.1109/TIP.2014.2353813
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Yuliang Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9806, DOI 10.1109/CVPR42600.2020.00983
   Yuxin Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11750, DOI 10.1109/CVPR42600.2020.01177
   Zhang CQ, 2019, PROC CVPR IEEE, P10544, DOI 10.1109/CVPR.2019.01080
   Zhang S, 2020, IEEE ACCESS, V8, P135524, DOI 10.1109/ACCESS.2020.3011109
   Zhang Shi-Xue, 2020, IEEE C COMPUTER VISI, P9699
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
NR 53
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10761
EP 10775
DI 10.1007/s11042-020-10039-9
EA JAN 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000604203000004
DA 2024-07-18
ER

PT J
AU Pamparau, C
   Vatavu, RD
AF Pamparau, Cristian
   Vatavu, Radu-Daniel
TI FlexiSee: flexible configuration, customization, and control of mediated
   and augmented vision for users of smart eyewear devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Mediated reality; Mediated vision; Smart eyewear;
   Smartglasses; Head-mounted displays; HoloLens; Visual impairments;
   Assisted vision; Prototype; Design space
ID REALITY; REHABILITATION; ENHANCEMENT; SENSECAM
AB Smart eyewear and Augmented Reality technology have been examined closely in the scientific community to provide vision rehabilitation to people with visual impairments as well as augmented vision to people with and without visual impairments for various application scenarios and contexts of use. However, current systems lack flexibility in the configuration and customization of the features and functionalities they present to their users, as we show in this paper by means of a thorough literature review and categorization of prior work on augmented and mediated vision for smart eyewear devices. To address the flexibility aspect that has been missing in prior work, we introduce FlexiSee, an application for smart eyewear devices, such as see-through Augmented Reality glasses and Head-Mounted Mixed Reality Displays, specifically designed to enable flexible configuration, customization, and control of both augmented and mediated vision. FlexiSee achieves this desiderata by implementing visual filters (e.g., color correction, edge highlighting, contrast adjustment, and others) that are coupled with a web-based interface, readily accessible from smartphones, tablets, smartwatches, and other devices with web browsers, where authorized users can specify and apply custom parameters for the visual filters implemented by FlexiSee. We also introduce FlexiSee-DS, a three-dimensional design space for FlexiSee-like applications, that includes mediation & augmentation, user categories, and control design dimensions to specify a variety of FlexiSee-like systems. We show how the dimensions of FlexiSee-DS were applied to inform the design of our FlexiSee system, and we highlight and focus on the distinction between primary users and vision monitors and assistants, where the latter two categories represent new types of users for augmented and mediated vision that have various degrees of control, from their remote locations, over the visual reality delivered to and perceived by the primary users of smart eyewear devices. We conduct a user study to understand the perception of vision monitors and assistants regarding our new FlexiSee concept and system, and we report empirical results about usability aspects (e.g., we found an average SUS score of 75.3 and high ratings for the perceived usefulness of FlexiSee) as well as user feedback and suggestions to inform further developments of FlexiSee-like systems and applications.
C1 [Pamparau, Cristian; Vatavu, Radu-Daniel] Univ Stefan Cel Mare Suceava, MANSiD Res Ctr, MintViz Lab, Suceava 720229, Romania.
C3 Stefan cel Mare University of Suceava
RP Vatavu, RD (corresponding author), Univ Stefan Cel Mare Suceava, MANSiD Res Ctr, MintViz Lab, Suceava 720229, Romania.
EM cristian.pamparau3@student.usv.ro; radu.vatavu@usm.ro
RI Vatavu, Radu-Daniel/AAA-3282-2022; Pamparau, Cristian/AAB-5215-2021;
   Vatavu, Radu-Daniel/F-1820-2017
OI Vatavu, Radu-Daniel/0000-0002-7631-6445
FU Ministry of Research and Innovation, CNCS-UEFISCDI, within PNCDI III
   [PN-III-P1-1.1-TE-2016-2173 (TE141/2018)]; project "Integrated center
   for research, development and innovation in Advanced Materials,
   Nanotechnologies, and Distributed Systems for fabrication and control"
   [671/09.04.2015]; Sectoral Operational Program for Increase of the
   Economic Competitiveness; European Regional Development Fund
FX This work was supported by a grant of the Ministry of Research and
   Innovation, CNCS-UEFISCDI, project no. PN-III-P1-1.1-TE-2016-2173
   (TE141/2018), within PNCDI III. The work was carried out in the Machine
   Intelligence and Information Visualization Lab (MintViz) of the MANSiD
   Research Center. The infrastructure was provided by the University of
   Suceava and was partially supported from the project "Integrated center
   for research, development and innovation in Advanced Materials,
   Nanotechnologies, and Distributed Systems for fabrication and control",
   No. 671/09.04.2015, Sectoral Operational Program for Increase of the
   Economic Competitiveness, co-funded from the European Regional
   Development Fund. Original versions of the icons used in Figures 2 and 4
   were made by Freepik (http://www.freepik.com, "Miscellaneous Elements"
   pack) from Flaticon (http://www.flaticon.com), licensed under Creative
   Commons BY 3.0 (http://creativecommons.org/licenses/by/3.0). The
   HoloLens device used in this work was kindly provided by OSF Global
   Services, the Mobile Division, Suceava.
CR Abdelrahman Y, 2018, 17TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2018), P245, DOI 10.1145/3282894.3282920
   Abdelrahman Y, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC '17 ADJUNCT), P1067, DOI 10.1145/3123024.3124450
   Abdelrahman Y, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC '17 ADJUNCT), P693, DOI 10.1145/3123024.3129269
   Aiordachioae Adrian, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3331157
   Aiordachioae A, 2019, E-HEALTH BIOENG CONF, DOI 10.1109/ehb47216.2019.8969871
   Albouys-Perrois J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174203
   [Anonymous], 2018, ARXIV180408386CS
   Azuma RT, 2016, PRESENCE-TELEOP VIRT, V25, P234, DOI 10.1162/PRES_a_00264
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Brady E., 2013, P SIGCHI C HUM FACT, P2117
   Chaturvedi I, 2019, PROCEEDINGS OF IUI 2019, P625, DOI 10.1145/3301275.3302263
   Coughlan JM, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P288, DOI 10.1109/ISMAR-Adjunct.2017.89
   Epstein Brian, 1998, SCRIPT DIGITAL LIVIN
   Everingham MR., 1998, INT J VIRTUAL REALIT, V3, P1, DOI [10.20870/IJVR.1998.3.4.2629, DOI 10.20870/IJVR.1998.3.4.2629]
   Fan K., 2014, PROC AH, DOI [10.1145/2582051.2582100, DOI 10.1145/2582051.2582100]
   Fuller TL, 2017, IEEE IMAGE PROC, P1985, DOI 10.1109/ICIP.2017.8296629
   Guo AH, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P651, DOI 10.1145/2984511.2984518
   Gurrin Cathal, 2014, Foundations and Trends in Information Retrieval, V8, P5, DOI 10.1561/1500000033
   Harper R, 1999, BRIT J OPHTHALMOL, V83, P495, DOI 10.1136/bjo.83.4.495
   Hicks SL, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0067695
   Hodges S, 2006, LECT NOTES COMPUT SC, V4206, P177
   Huang J, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0210630
   Hwang AD, 2014, OPTOMETRY VISION SCI, V91, P1021, DOI 10.1097/OPX.0000000000000326
   Itoh Yuta, 2015, P 6 AUGM HUM INT C A, P1, DOI [10.1145/2735711.2735787, DOI 10.1145/2735711.2735787]
   Janzen Ryan., 2014, Games Media Entertainment (GEM), 2014 IEEE, P1
   Jordan P.W., 1996, Usability Evaluation in Industry, DOI DOI 10.1201/9781498710411
   Kress B, 2014, PROC SPIE, V9202, DOI 10.1117/12.2064351
   Langlotz T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173964
   Lee H, 2008, MULTIMEDIA SYST, V14, P341, DOI 10.1007/s00530-008-0129-x
   Luo G, 2006, INVEST OPHTH VIS SCI, V47, P4152, DOI 10.1167/iovs.05-1672
   Mann S., 2002, MEDIATED REALITY IMP
   Mann Steve., 1999, LINUX J, V59es, P5
   Marr B, 2019, FORBES
   Marr D., 1982, VISION COMPUTATIONAL, DOI [10.7551/mitpress/9780262514620.001.0001, DOI 10.7551/MITPRESS/9780262514620.001.0001]
   Melillo P, 2017, IEEE J TRANSL ENG HE, V5, DOI 10.1109/JTEHM.2017.2679746
   Milgram P, 1999, MIXED REALITY, P5
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   NIELSEN J, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P206
   Nielsen Jakob, Why You Only Need to Test with 5 Users
   Niforatos E, 2019, PROCEEDINGS OF THE 10TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE 2019 (AH2019), DOI 10.1145/3311823.3311858
   Olson KE, 2011, AGEING INT, V36, P123, DOI 10.1007/s12126-010-9077-9
   Peli E, 2001, OPTOMETRY VISION SCI, V78, P304, DOI 10.1097/00006324-200105000-00014
   Peli E, 2007, J SOC INF DISPLAY, V15, P1037, DOI 10.1889/1.2825088
   Peli E, 2009, INT J ARTIF INTELL T, V18, P365, DOI 10.1142/S0218213009000184
   Peli Eli., 1999, Visual Impairment Research, V1, P3
   Pogorelc B, 2013, MULTIMED TOOLS APPL, V66, P7, DOI 10.1007/s11042-012-1228-4
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P399, DOI 10.1007/s11042-011-0917-8
   Rakkolainen I, 2017, 2017 3DTV C TRUE VIS, DOI 10.1109/3DTV.2017.8280417
   Rusu PP, 2019, E-HEALTH BIOENG CONF, DOI 10.1109/ehb47216.2019.8970074
   Sadri F, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978815
   Sandnes FE, 2016, LECT NOTES COMPUT SC, V9758, P187, DOI 10.1007/978-3-319-41264-1_25
   Satgunam P, 2012, OPTOMETRY VISION SCI, V89, pE1364, DOI 10.1097/OPX.0b013e318266f92f
   Schipor MD, 2017, E-HEALTH BIOENG CONF, P353, DOI 10.1109/EHB.2017.7995434
   Schipor MD, 2017, E-HEALTH BIOENG CONF, P357, DOI 10.1109/EHB.2017.7995435
   Scourboutakos P, 2017, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'17), P751, DOI 10.1145/3024969.3035534
   Speicher M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300767
   Stearns L, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS'17), P361, DOI 10.1145/3132525.3134512
   Stearns L, 2018, ASSETS'18: PROCEEDINGS OF THE 20TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P28, DOI 10.1145/3234695.3236361
   Szpiro S, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P61, DOI 10.1145/2971648.2971723
   Szpiro S, 2016, ASSETS'16: PROCEEDINGS OF THE 18TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P171, DOI 10.1145/2982142.2982168
   Tanuwidjaja E, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P799, DOI 10.1145/2632048.2632091
   Thevin L, 2018, LECT NOTES COMPUT SC, V10897, P193, DOI 10.1007/978-3-319-94274-2_26
   Wobbrock JO, 2018, COMMUN ACM, V61, P62, DOI 10.1145/3148051
   Zhao YH, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P387, DOI 10.1145/3332165.3347906
   Zhao YH, 2019, ACM T ACCESS COMPUT, V12, DOI 10.1145/3361866
   Zhao YH, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300341
   Zhao YH, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173789
   Zhao YH, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4170, DOI 10.1145/3025453.3025949
   Zhao YH, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P73, DOI 10.1145/2971648.2971730
   Zhao YH, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P239, DOI 10.1145/2700648.2809865
   Zhou LT, 2018, LSC '18: PROCEEDINGS OF THE 2018 ACM WORKSHOP ON THE LIFELOG SEARCH CHALLENGE, P9, DOI 10.1145/3210539.3210542
   Zolyomi A, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS'17), P220, DOI 10.1145/3132525.3132552
NR 75
TC 9
Z9 9
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30943
EP 30968
DI 10.1007/s11042-020-10164-5
EA JAN 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000604203000002
OA hybrid
DA 2024-07-18
ER

PT J
AU Anwar, S
   Mehrban, B
   Ali, M
   Hussain, F
   Halim, Z
AF Anwar, Sajid
   Mehrban, Bilal
   Ali, Musawar
   Hussain, Farhan
   Halim, Zahid
TI A novel framework for generating handwritten datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic segmentation; Handwritten character recognition; Deep learning
   algorithms
ID OPTICAL CHARACTER-RECOGNITION
AB The performance of deep learning algorithms is highly dependent on the size and diversity of data. However, for handwritten character recognition, dataset creation, segmentation, and labeling are time consuming and laborious tasks and not much researched. This work proposes a novel and generic framework which automates the segmentation and labeling processes for handwritten datasets. First, a user collects handwritten glyphs on the proposed form. Next, based on a priori knowledge, local peaks from horizontal and vertical projection functions are computed. This helps in locating and segmenting individual samples automatically. To show the effectiveness of the proposed framework, a dataset of 160,000 samples is collected for an oriental language. We profile the segmentation of samples from one sheet with three approaches: manual, semi-automatic, and the proposed fully automatic approach. Compared to the manual and semi-automatic processes, the proposed approach is 120 x and 65 x faster, respectively. Further, we also present the classification of this dataset by traditional and state-of-the-art machine learning algorithms.
C1 [Anwar, Sajid; Ali, Musawar; Halim, Zahid] Ghulam Ishaq Khan Inst Engn Sci & Technol, Swabi, Pakistan.
   [Mehrban, Bilal] Univ AJK, Muzaffarabad, Pakistan.
   [Hussain, Farhan] Natl Univ Sci & Technol, Islamabad, Pakistan.
C3 GIK Institute Engineering Science & Technology; National University of
   Sciences & Technology - Pakistan
RP Mehrban, B (corresponding author), Univ AJK, Muzaffarabad, Pakistan.
EM sajid@giki.edu.pk; bilal.mehrban@ajku.edu.pk; gcs1817@giki.edu.pk;
   farhan.hussain@ceme.nust.edu.pk; zahid.halim@giki.edu.pk
RI Halim, Zahid/AAD-8033-2021; Anwar, Sajid/JBJ-1127-2023
OI Halim, Zahid/0000-0003-3094-3483; Hussain, Farhan/0000-0001-9073-5892
CR Abu-Mostafa YS, 2012, LEARNING FROM DATA, P19
   Acharya J, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, NETWORKING AND COMMUNICATIONS (ICNC), P1, DOI 10.1109/ICCNC.2015.7069284
   Ahmad I, 2017, IEEE ACCESS, V5, P10924, DOI 10.1109/ACCESS.2017.2703155
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Ali H, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-019-1914-1
   Baldominos A, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9153169
   Bin Ahmed S, 2019, NEURAL COMPUT APPL, V31, P1143, DOI 10.1007/s00521-017-3146-x
   Calderon A, 2003, HANDWRITTEN DIGIT RE
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Ebrahimzadeh R., 2014, INT J COMPUT APPL, V104, P10, DOI DOI 10.5120/18229-9167
   Hamid N.A., 2017, HANDWRITTEN RECOGNIT
   Hamida S., 2020, P 2020 IEEE 2 INT C, P1, DOI DOI 10.1109/ICECOCS50124.2020.9314373
   Haque S, 2018, Revised Selected Papers, V2, P108
   Hassaballah M, 2016, STUD COMPUT INTELL, V630, P11, DOI 10.1007/978-3-319-28854-3_2
   Hong WC, 2019, APPL MATH MODEL, V72, P425, DOI 10.1016/j.apm.2019.03.031
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Khan NH, 2018, IEEE ACCESS, V6, P46019, DOI 10.1109/ACCESS.2018.2865532
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lecun Y., 2000, STAT MECH PERSPECTIV
   Liu CL, 2013, PATTERN RECOGN, V46, P155, DOI 10.1016/j.patcog.2012.06.021
   Liu J, 2019, J SUPERCOMPUT, V75, P1922, DOI 10.1007/s11227-017-2218-0
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Min RQ, 2009, IEEE DATA MINING, P357, DOI 10.1109/ICDM.2009.27
   Minoofam SAH, 2010, LECT NOTES COMPUT SC, V6350, P79
   Najadat HM, 2019, INT CONF INFORM COMM, P147, DOI 10.1109/iacs.2019.8809122
   Naz S, 2017, NEUROCOMPUTING, V243, P80, DOI 10.1016/j.neucom.2017.02.081
   Naz S, 2014, PATTERN RECOGN, V47, P1229, DOI 10.1016/j.patcog.2013.09.037
   Niu XX, 2012, PATTERN RECOGN, V45, P1318, DOI 10.1016/j.patcog.2011.09.021
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pakistan Bureau of Statistics, 2018, POP MOTH TONG
   Rabby AKMSA, 2018, PROCEDIA COMPUT SCI, V143, P502, DOI 10.1016/j.procs.2018.10.423
   Registrar General and Census Commissioner of India, 2018, SCHED LANG DESC ORD
   Sagheer MW, 2009, LECT NOTES COMPUT SC, V5716, P538, DOI 10.1007/978-3-642-04146-4_58
   Salahat E, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1059, DOI 10.1109/ICIT.2017.7915508
   Zhang ZC, 2020, IEEE ACCESS, V8, P14642, DOI 10.1109/ACCESS.2020.2966712
NR 36
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9657
EP 9669
DI 10.1007/s11042-020-09545-7
EA NOV 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000589699900006
DA 2024-07-18
ER

PT J
AU Chen, ST
   Huang, TW
   Yang, CT
AF Chen, Shuo-Tsung
   Huang, Tsai-Wei
   Yang, Chao-Tung
TI High-SNR steganography for digital audio signal in the wavelet domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital audio signal; Signal-to-noise ratio; Bit-error-rate; Discrete
   wavelet transform; Scaling factors; Optimization
ID POINT-OF-VIEW; WATERMARKING SCHEME; DECOMPOSITION
AB Imperceptible, robust, and embedding capacity are three main requirements for the steganography of digital audio signal. To enhance them, this study presents a novel steganography for digital audio signal in the wavelet domain. Since the performance of imperceptible and robust are usually in term of signal-to-noise ratio (SNR) and bit-error-rate (BER), we propose a quantization-based optimization model to maximize SNR and reduce BER in embedding secret message. In the proposed model, quantization technique with unknow coefficients of discrete wavelet transform (DWT) is rewritten as the first constraint. The adjustment of scaling DWT coefficients is considered as the second constraint. At the same time, signal-to-noise ratio (SNR) is converted into a performance index. In solving this model, we use matrix operations and Lagrange multiplier to obtain optimal DWT coefficients and scaling factors. Moreover, the invariant feature of the scaling factors against amplitude scaling attack is proved. In extraction, secret message can be detected without original audio signal. Experimental results show that the proposed steganography has high SNR and strong robustness against many malicious attacks when comparing to some exiting methods.
C1 [Chen, Shuo-Tsung] Natl Yunlin Univ Sci & Technol, Dept Comp Sci & Informat Engn, Yunlin 64002, Taiwan.
   [Huang, Tsai-Wei] Taipei Med Univ, Sch Nursing, Coll Nursing, Taipei, Taiwan.
   [Yang, Chao-Tung] Tunghai Univ, Dept Comp Sci, Taichung 40704, Taiwan.
C3 National Yunlin University Science & Technology; Taipei Medical
   University; Tunghai University
RP Yang, CT (corresponding author), Tunghai Univ, Dept Comp Sci, Taichung 40704, Taiwan.
EM shough34@yahoo.com.tw; tsaiwei@tmu.edu.tw; ctyang@thu.edu.tw
RI Huang, Tsai-Wei/A-1690-2019; Yang, Chao-Tung/B-4562-2009
OI Huang, Tsai-Wei/0000-0002-6722-1153; Yang, Chao-Tung/0000-0002-9579-4426
CR [Anonymous], 1976, The Elements of Real Analysis
   [Anonymous], 2000, Digital Watermarking
   Babu L., 2013, INT J COMPUT SCI MOB, V2, P54
   Burrus CS., 1998, INTRO WAVELET THEORY
   Chen ST, 2010, IET SIGNAL PROCESS, V4, P576, DOI 10.1049/iet-spr.2009.0184
   Chen ST, 2010, IET SIGNAL PROCESS, V4, P720, DOI 10.1049/iet-spr.2009.0187
   Chen ST, 2016, MULTIMED TOOLS APPL, V75, P4735, DOI 10.1007/s11042-015-2500-1
   Chen ST, 2015, IET SIGNAL PROCESS, V9, P166, DOI 10.1049/iet-spr.2013.0399
   Chen ST, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0054-9
   Chen ST, 2013, DIGIT SIGNAL PROCESS, V23, P971, DOI 10.1016/j.dsp.2012.12.013
   Dhar PK, 2017, RADIOENGINEERING, V26, P552, DOI 10.13164/re.2017.0552
   Djebbar F., P 8 INT C EM SEC INF
   Djebbar F., 2017, J INF HIDING MULTIME, V8, P168
   Ghosh M, 2015, MADERAS-CIENC TECNOL, V17, P39, DOI 10.4067/S0718-221X2015005000004
   Huang HN, 2015, J SIGNAL PROCESS SYS, V80, P197, DOI 10.1007/s11265-013-0863-y
   Kim C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040644
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Lee MC., 2018, J INFO HIDING MULTIM, V9, P959
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Lewis F.L., 1986, OPTIMAL CONTROL
   Li JF, 2018, MULTIMED TOOLS APPL, V77, P14481, DOI 10.1007/s11042-017-5024-z
   Liu H., 2018, J INFO HIDING MULTIM, V9, P1222
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mishra J., 2013, INT J COMPUT APPL, V70, P6, DOI [10.5120/11980, DOI 10.5120/11980]
   PARNAMI P, 2016, PERFORMANCE EVALUATI, V0003, P00167
   Shankar T., 2017, INT J ELECT ELECT CO, V6, P375
   Tseng KK, 2014, SENSORS-BASEL, V14, P3721, DOI 10.3390/s140203721
   Wu QL, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8050723
   Zhao M, 2015, J INTERNET TECHNOL, V16, P485, DOI 10.6138/JIT.2015.16.3.20150105
NR 31
TC 3
Z9 4
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9597
EP 9614
DI 10.1007/s11042-020-09980-6
EA NOV 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000588614300004
DA 2024-07-18
ER

PT J
AU Rahimizadeh, N
   Hasanzadeh, RPR
   Janabi-Sharifi, F
AF Rahimizadeh, Niloofar
   Hasanzadeh, Reza P. R.
   Janabi-Sharifi, Farrokh
TI An optimized non-local LMMSE approach for speckle noise reduction of
   medical ultrasound images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ultrasound images; Speckle noise; Linear minimum mean square error
   estimator; Data redundancy
ID FILTER; DIFFUSION; DOMAIN; MODEL; ENHANCEMENT; SUPPRESSION; REMOVAL
AB In this paper, a modified linear-minimum-mean-square-error (LMMSE)-based estimator is presented to reduce speckle noise in ultrasound (US) medical images. In order to significantly improve the performance of the LMMSE estimator, we consider the data redundancy feature which naturally exists in the US images. Since the classical LMMSE method, due to the use of local statistics, cannot perform well in areas where the intensity variation is high, we exploit the similarity between pixels to resolve this problem. In this regards, by using characteristics of the second order local statistics and Pearson distance, an optimum set of similar pixels is selected to be used in the proposed LMMSE-based estimator. Therefore, a good balance between maintaining small details and reducing speckle noise in different regions of US images can be achieved. Quantitative and qualitative results on synthetic and real US data demonstrate that the proposed method yields competitive results in despeckling process compared to the state-of-the-art methods.
C1 [Rahimizadeh, Niloofar; Hasanzadeh, Reza P. R.] Univ Guilan, Dept Elect Engn, Rasht, Iran.
   [Janabi-Sharifi, Farrokh] Ryerson Univ, Dept Mech & Ind Engn, Toronto, ON, Canada.
C3 University of Guilan; Toronto Metropolitan University
RP Hasanzadeh, RPR (corresponding author), Univ Guilan, Dept Elect Engn, Rasht, Iran.
EM hasanzadehpak@guilan.ac.ir
RI Hasanzadeh, Reza PR/E-8509-2013; Janabi-Sharifi, Farrokh/AAD-8442-2021
OI Hasanzadeh, Reza PR/0000-0002-6431-758X; 
CR Achim A, 2001, IEEE T MED IMAGING, V20, P772, DOI 10.1109/42.938245
   Aja-Fernández S, 2006, IEEE T IMAGE PROCESS, V15, P2694, DOI 10.1109/TIP.2006.877360
   Argenti F, 2003, EURASIP J APPL SIG P, V2003, P470, DOI 10.1155/S1110865703211136
   Aysal TC, 2007, IEEE T MED IMAGING, V26, P712, DOI 10.1109/TMI.2007.895484
   Balocco S, 2010, ULTRASOUND MED BIOL, V36, P1353, DOI 10.1016/j.ultrasmedbio.2010.05.007
   Behar V, 2003, ULTRASONICS, V41, P377, DOI 10.1016/S0041-624X(03)00105-7
   Bhuiyan MIH, 2007, IEEE INT SYMP CIRC S, P2347, DOI 10.1109/ISCAS.2007.378859
   Binaee K, 2014, BIOMED SIGNAL PROCES, V13, P89, DOI 10.1016/j.bspc.2014.03.013
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   BURCKHARDT CB, 1978, IEEE T SON ULTRASON, V25, P1, DOI 10.1109/T-SU.1978.30978
   Cheng H, 2009, PROCEEDINGS OF THE FIRST INTERNATIONAL WORKSHOP ON EDUCATION TECHNOLOGY AND COMPUTER SCIENCE, VOL I, P933, DOI 10.1109/ETCS.2009.212
   Coupé P, 2008, IEEE T MED IMAGING, V27, P425, DOI 10.1109/TMI.2007.906087
   Coupé P, 2008, I S BIOMED IMAGING, P1291, DOI 10.1109/ISBI.2008.4541240
   Dantas RG, 2005, ULTRASONICS, V43, P405, DOI 10.1016/j.ultras.2004.11.003
   Farouj Y, 2017, IEEE T COMPUT IMAG, V3, P1, DOI 10.1109/TCI.2016.2625740
   Fathi A, 2012, IEEE T IMAGE PROCESS, V21, P3981, DOI 10.1109/TIP.2012.2200491
   FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223
   Gupta S, 2005, IEE P-VIS IMAGE SIGN, V152, P129, DOI 10.1049/ip-vis:20050975
   Jensen J. A., 1996, Medical & Biological Engineering & Computing, V34, P351
   Joel T, 2013, JOIG, P161, DOI [10.12720/joig.1.3.161-165, DOI 10.12720/JOIG.1.3.161-165]
   Karthikeyan K., 2011, INT J COMPUT APPL, V2, P8, DOI DOI 10.5120/2614-3646
   Kay S. M., 1993, FUNDAMENTALS STAT SI
   KOTROPOULOS C, 1994, IEEE T IMAGE PROCESS, V3, P65, DOI 10.1109/83.265980
   Koundal D, 2018, IRBM, V39, P43, DOI 10.1016/j.irbm.2017.11.003
   Krissian K, 2007, IEEE T IMAGE PROCESS, V16, P1412, DOI 10.1109/TIP.2007.891803
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   LOPES A, 1990, IEEE T GEOSCI REMOTE, V28, P992, DOI 10.1109/36.62623
   LOUPAS T, 1989, IEEE T CIRCUITS SYST, V36, P129, DOI 10.1109/31.16577
   Mahmoudi M, 2005, IEEE SIGNAL PROC LET, V12, P839, DOI 10.1109/LSP.2005.859509
   Nadeem M, 2019, MULTIMED TOOLS APPL, V78, P18531, DOI 10.1007/s11042-019-7221-4
   Pishro-Nik H., 2016, Introduction to probability, statistics, and random processes
   Pizurica A, 2003, IEEE T MED IMAGING, V22, P323, DOI 10.1109/TMI.2003.809588
   Ramos-Llordén G, 2015, IEEE T IMAGE PROCESS, V24, P345, DOI 10.1109/TIP.2014.2371244
   Sahu S, 2019, MULTIMED TOOLS APPL, V78, P4089, DOI 10.1007/s11042-017-5221-9
   SAKRISON DJ, 1977, IEEE T COMMUN, V25, P1251, DOI 10.1109/TCOM.1977.1093773
   Shankar PM, 2000, IEEE T ULTRASON FERR, V47, P727, DOI 10.1109/58.842062
   Slabaugh G., 2006, Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, P45, DOI [10.1109/CVPR.2006.318, DOI 10.1109/CVPR.2006.318]
   Sudeep PV, 2016, BIOMED SIGNAL PROCES, V28, P1, DOI 10.1016/j.bspc.2016.03.001
   Tao Z, 2006, IEEE T MED IMAGING, V25, P1483, DOI 10.1109/TMI.2006.881376
   Tay PC, 2006, I S BIOMED IMAGING, P221
   Tian J, 2011, BIOMED SIGNAL PROCES, V6, P432, DOI 10.1016/j.bspc.2010.11.006
   Vegas-Sanchez-Ferrero G, 2010, LECT NOTES COMPUT SC, V6361, P518
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WENG L, 1991, J ACOUST SOC AM, V89, P2992, DOI 10.1121/1.400818
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
   Zhan Y, 2014, SIGNAL PROCESS, V103, P201, DOI 10.1016/j.sigpro.2013.12.019
   Zhang F, 2007, IEEE T MED IMAGING, V26, P200, DOI 10.1109/TMI.2006.889735
   Zhang YT, 2010, IEEE IMAGE PROC, P4161, DOI 10.1109/ICIP.2010.5649132
   Zhou YY, 2019, BIOMED SIGNAL PROCES, V48, P104, DOI 10.1016/j.bspc.2018.09.011
NR 50
TC 11
Z9 12
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9231
EP 9253
DI 10.1007/s11042-020-10051-z
EA NOV 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587972400004
DA 2024-07-18
ER

PT J
AU Hafeez, Y
   Asghar, S
   Arif, B
   Ali, S
AF Hafeez, Yaser
   Asghar, Sohail
   Arif, Bisma
   Ali, Sadia
TI Role of situational method engineering to improve visual information
   systems in agile distributed environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Global software development (GSD); Agile software development; Visual
   information systems; Team coordination; Requirement engineering;
   Multidimensional and situational method engineering (SME)
ID SOFTWARE-DEVELOPMENT; ADAPTATION; DESIGN; GAP
AB Software product prone to continuous evolution due to increase in the use of technology. Therefore, more stakeholders are involved in software evolution increases the cost and complexity. This required optimization of resources and cost to handle evolution with Global Software Development (GSD) to utilize time zones efficiently. The significance challenge of GSD reports: time zone difference, geographical location, communication delays, knowledge sharing, control among stakeholders and development team. Because of these challenges, the requirements for development in GSD environment are also challenge as compared to on site development. Different requirement engineering methods have been used to improve the requirements analysis to deal with ambiguities and inconsistency in large set of requirements. The customization and tailoring of requirements according to changing project's situations required to improve project development with reusing existing agile methods during requirement engineering phase. Moreover, complex information systems where heterogeneity is inevitable that implies the involvement of divergent stakeholders and necessitate a comprehensive framework to capture multidimensional viewpoints and fulfill aforementioned issues. Therefore, a situational multi-dimensional agile requirement engineering method has been proposed to support team and stakeholders' viewpoints. The schema of the proposed method is based on challenges recognized by performing Literature Review. Then proposed method has been evaluated via experimental approach and statistical analysis conducted to validated reliability of data collected. This result is significant approved both practically and statistically that the proposed approach ease to use, implement, trained and increased productivity and performance. Hence, the experimental study for the evaluation of the proposed approach results concluded that, proposed approach is the important multimedia tool for supporting organization and distributed development team for information sharing, collaboration, product development.
C1 [Hafeez, Yaser; Arif, Bisma; Ali, Sadia] PMAS Arid Agr Univ, Univ Inst Informat Technol, Rawalpindi, Pakistan.
   [Asghar, Sohail] COMSATS Univ, Dept Comp Sci, Islamabad Campus, Islamabad, Pakistan.
C3 Arid Agriculture University; COMSATS University Islamabad (CUI)
RP Ali, S (corresponding author), PMAS Arid Agr Univ, Univ Inst Informat Technol, Rawalpindi, Pakistan.
EM sadiaalief@gmail.com
CR Abdellatif A, 2019, J SOFTW-EVOL PROC, V31, DOI 10.1002/smr.2151
   Alsanad AA, 2019, IEEE ACCESS, V7, P49352, DOI 10.1109/ACCESS.2019.2909839
   Alsaqaf W, 2019, INFORM SOFTWARE TECH, V110, P39, DOI 10.1016/j.infsof.2019.01.009
   Alzoubi Yehia Ibrahim, 2018, Journal of Software Engineering Research and Development, V6, DOI 10.1186/s40411-018-0048-2
   Ambler SW, 2016, LECT NOTES BUS INF P, V238, P3, DOI 10.1007/978-3-319-27033-3_1
   Ayed H, 2012, 2012 EIGHTH INTERNATIONAL CONFERENCE ON THE QUALITY OF INFORMATION AND COMMUNICATIONS TECHNOLOGY (QUATIC 2012), P66, DOI 10.1109/QUATIC.2012.11
   Bakhat KA, 2015, SITUATIONAL REQUIREM
   Bhukya SN, 2019, CLUSTER COMPUT, V22, P14789, DOI 10.1007/s10586-018-2417-3
   Bjarnason E, 2016, INFORM SOFTWARE TECH, V77, P61, DOI 10.1016/j.infsof.2016.03.008
   Borrego G, 2019, INFORM SOFTWARE TECH, V112, P68, DOI 10.1016/j.infsof.2019.04.008
   Chaudhary P., 2017, Intelligent Information Management, V09, P133, DOI [DOI 10.4236/IIM.2017, DOI 10.4236/iim.2017.95007]
   da Silva IF, 2015, INFORM SOFTWARE TECH, V57, P527, DOI 10.1016/j.infsof.2014.06.004
   Denèckere R, 2015, INT CONF RES CHAL, P274, DOI 10.1109/RCIS.2015.7128888
   Farwick M, 2016, SOFTW SYST MODEL, V15, P397, DOI 10.1007/s10270-014-0407-3
   Felderer M, 2019, SOFTWARE QUAL J, V27, P125, DOI 10.1007/s11219-018-9407-9
   Giray G, 2018, COMM COM INF SC, V896, P28, DOI 10.1007/978-3-319-97925-0_3
   Giray G, 2018, LECT NOTES BUS INF P, V319, P221, DOI 10.1007/978-3-319-94214-8_14
   Gürses S, 2013, REQUIR ENG, V18, P43, DOI 10.1007/s00766-011-0139-7
   Hafeez Y, 2016, J COMPUT THEOR NANOS, V13, P3238, DOI DOI 10.1166/JCTN.2016.4981
   Hashmi AS, 2019, MEHRAN UNIV RES J EN, V38, P655, DOI 10.22581/muet1982.1903.11
   Heikkilä VT, 2017, EMPIR SOFTW ENG, V22, P2892, DOI 10.1007/s10664-016-9491-z
   Jain R., 2015, ACM SIGSOFT SOFTW EN, V40, P1, DOI [10.1145/2735399.2735408, DOI 10.1145/2735399.2735408]
   Kamal T, 2020, IET SOFTW, V14, P265, DOI 10.1049/iet-sen.2019.0128
   Khan AZ, 2019, J AYUB MED COLL A S1, V31, pS656, DOI DOI 10.1002/smr.1988
   Ko AJ, 2015, EMPIR SOFTW ENG, V20, P110, DOI 10.1007/s10664-013-9279-3
   López-Martínez J, 2018, CLUSTER COMPUT, V21, P715, DOI 10.1007/s10586-017-0996-z
   Lous P, 2018, PROCEEDINGS 2018 ACM/IEEE 13TH INTERNATIONAL CONFERENCE ON GLOBAL SOFTWARE ENGINEERING ICGSE 2018, P102, DOI 10.1145/3196369.3196374
   Nguyen DS, 2016, SUCCESS FACTORS INFL, V17, P51
   Niazi M, 2013, IET SOFTW, V7, P283, DOI 10.1049/iet-sen.2012.0136
   O'Connor R, 2016, 2016 IEEE ACM INT C, DOI [10.1109/ICSSP.2016.009, DOI 10.1109/ICSSP.2016.009]
   Paasivaara M, 2014, INFORM SOFTWARE TECH, V56, P1556, DOI 10.1016/j.infsof.2014.06.008
   Pacheco CL, 2015, J SOFTW-EVOL PROC, V27, P1, DOI 10.1002/smr.1698
   Qureshi M. Rizwan Jameel, 2015, International Journal of Information Engineering and Electronic Business, V7, P1, DOI 10.5815/ijieeb.2015.02.01
   Rasnacis A, 2017, PROCEDIA COMPUT SCI, V104, P43, DOI 10.1016/j.procs.2017.01.055
   Sandkuhl K, 2019, SOFTW SYST MODEL, V18, P1833, DOI 10.1007/s10270-018-0692-3
   Shameem Mohammad, 2019, International Journal of Agile Systems and Management, V12, P199
   Shameem M, 2020, IET SOFTW, V14, P389, DOI 10.1049/iet-sen.2019.0196
   Shameem M, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106122
   Sharma P, 2019, J SOFTW-EVOL PROC, V31, DOI 10.1002/smr.2183
   Shrivastava SV, 2017, INFORM SOFTWARE TECH, V85, P1, DOI 10.1016/j.infsof.2016.12.005
   Shrivastava SV, 2014, PROCD SOC BEHV, V133, P417, DOI 10.1016/j.sbspro.2014.04.208
   Sinha R, 2020, P 13 INN SOFTW ENG C, P1
   Smite D, 2015, IEEE SOFTWARE, V32, P26, DOI 10.1109/MS.2015.102
   Smite D, 2014, EMPIR SOFTW ENG, V19, P105, DOI 10.1007/s10664-012-9217-9
   Spiegler SV, 2019, LECT NOTES BUS INF P, V355, P37, DOI 10.1007/978-3-030-19034-7_3
   Suryaatmaja K, 2019, EURAS STUD BUS ECON, V11, P113, DOI 10.1007/978-3-030-18652-4_9
   Sutanto J, 2015, ACM TRANS MANAG INF, V6, DOI 10.1145/2688489
   Trainer EH, 2018, J SYST SOFTWARE, V144, P328, DOI 10.1016/j.jss.2018.06.028
   Vallon R, 2018, INFORM SOFTWARE TECH, V96, P161, DOI 10.1016/j.infsof.2017.12.004
   Vasquez RO, 2019, EVALUATING MODEL BAS
NR 50
TC 1
Z9 1
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8881
EP 8908
DI 10.1007/s11042-020-09896-1
EA NOV 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000586377600006
DA 2024-07-18
ER

PT J
AU Guo, ZQ
   Hu, LP
   Xia, M
   Yang, GB
AF Guo, Zhiqing
   Hu, Lipin
   Xia, Ming
   Yang, Gaobo
TI Blind detection of glow-based facial forgery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Fake face datasets; Facial forgery;
   Passive image forensics
ID NETWORKS
AB With the rapid development of artificial intelligence technologies, various generative models can synthesize fake face images with photo-realistic effects. Glow, a generative flow using invertible 1x1 convolution, is a state-of-the-art technique for efficient synthesis of face images with high resolution and fidelity. However, facial forgeries bring serious challenges to morality, ethics and public confidence. Especially, facial forgeries might change the semantic content conveyed by a face image. A Convolutional Neural Network (CNN) based model, namely SCnet, is proposed to expose the Glow-based facial forgery. Specifically, an image sharpening operator is embedded in the convolutional layer as the pre-processing layer of the network to highlight the traces left by Glow. Then, SCnet is specifically designed to automatically learn high-level forensics features from pre-processing results. Moreover, a fake face dataset is built by exploiting the CelebA face image dataset and the Glow-based forgery technique. A series of experiments are conducted to prove the effectiveness of the proposed approach. Experimental results show that the proposed approach achieves a classification accuracy up to 95.92% under various post-processing operations.
C1 [Guo, Zhiqing; Hu, Lipin; Xia, Ming; Yang, Gaobo] Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Peoples R China.
   [Xia, Ming] Southwest Minzu Univ, Coll Elect & Informat Engn, Chengdu 610041, Peoples R China.
C3 Hunan University; Southwest Minzu University
RP Yang, GB (corresponding author), Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Peoples R China.
EM yanggaobo@hnu.edu.cn
RI Bueno, Regis Cortez/AAG-3852-2020; Guo, Zhiqing/HHZ-9238-2022
OI Bueno, Regis Cortez/0000-0002-2923-4930; Yang, Gaobo/0000-0003-2734-659X
FU National Key Research & Development Plan [2018YFB1003205]; National
   Natural Science Foundation of China [61972143, 61972142]
FX This work is supported in part by the National Key Research &
   Development Plan (2018YFB1003205) and National Natural Science
   Foundation of China (61972143, 61972142).
CR Afchar D., 2018, 2018 IEEE INT WORKSH, P1, DOI [DOI 10.1109/WIFS.2018.8630761, 10.1109/WIFS.2018.8630761]
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26
   Berthelot David, BEGAN: Boundary equilibrium generative adversarial networks
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Dang LM, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122610
   Ding H, 2018, AAAI CONF ARTIF INTE, P6781
   Dinh L, NICE NONLINEAR INDEP
   Dinh Laurent, 2017, 5 INT C LEARN REPR I
   Do N.-T., 2018, P ISITC, V2018, P376
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo Z, 2020, FAKE FACES DETECTION
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Karras T, 2018, P INT C LEARN REPR I
   Karras T, ANAL IMPROVING IMAGE
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Kingma DP, 2016, 30 C NEURAL INFORM P, V29
   Kingma Durk P., 2018, ADV NEURAL INFORM PR
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li HD, 2018, IEEE T CIRC SYST VID, V28, P31, DOI 10.1109/TCSVT.2016.2599849
   Li L., 2020, P IEEE CVF C COMP VI
   Lin MPH, 2014, DES AUT CON, DOI 10.1145/2593069.2593179
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Mo HX, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P43, DOI 10.1145/3206004.3206009
   Parkhi OM, 2015, Proceedings of the British Machine Vision Conference, DOI DOI 10.5244/C.29.41
   Pumarola A, 2018, LECT NOTES COMPUT SC, V11214, P835, DOI 10.1007/978-3-030-01249-6_50
   Radford A., 2016, INT C LEARN REPR
   Rossler A., FaceForensics: A large-scale video dataset for forgery detection in human faces
   Rossler A., 2019, Faceforensics++: Learning to detect manipulated facial images
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Theobalt Chris- tian, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.262
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Yu N, 2019, IEEE I CONF COMP VIS, P7555, DOI 10.1109/ICCV.2019.00765
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
NR 38
TC 9
Z9 9
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7687
EP 7710
DI 10.1007/s11042-020-10098-y
EA OCT 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000587058000014
DA 2024-07-18
ER

PT J
AU Marwaha, P
   Sunkaria, RK
   Kumar, A
AF Marwaha, Puneeta
   Sunkaria, Ramesh Kumar
   Kumar, Aman
TI Suitability of multiscale entropy for complexity quantification of
   cardiac rhythms in chronic pathological conditions: a similarity
   patterns based investigation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cardiac rhythm; Complexity; Fluctuations; Heart rate variability (HRV);
   Multiscale entropy (MSE)
ID APPROXIMATE ENTROPY; VARIABILITY
AB In this paper, based upon the appearance of patterns derived from a time series, we have investigated the suitability of multiscale entropy (MSE) technique for complexity quantification of cardiac rhythms in chronic pathological conditions. MSE analysis was developed to quantify the complexity of a wide variety of biomedical signals. Here, sample entropy (SampEn) technique was evaluated across multiple spatio-temporal scales. In SampEn, to find the appearance of repetitive patterns in multi-dimensional phase space, the threshold value 's' is pre-fixed as 0.2. However, the cardiac rhythms of some pathologies are characterized with considerable erratic beat-to-beat fluctuations, and hence, in accordance with that, the patterns concealed in the pathologic cardiac rhythms spread across a wider region of multidimensional phase space. But, fixed threshold value 's' assigns a fewer similarity pattern inside a circle of fixed dimensions, and hence, the higher entropy rate is associated with the chronic pathologic cardiac rhythms when compared to healthy cardiac rhythms. This flaw of SampEn is present in MSE, which leads to the wrong estimation of complexity associated with a time series. The outcome of this issue is clearly visible at low time scales, where period-to-period fluctuations in chronic pathologic cardiac rhythms and in randomized time series are significantly increased. In this present study, MSE analysis was performed over synthetic simulated database comprising of (white noise) WN and (power noise) PN signals. Further, MSE analysis was performed on the RR-interval series collected from (normal sinus rhythm) NSR group, and patients affected by (Atrial Fibrillation) AF. A fixed number of data samples 'M' of 10,000 were considered for each type of time series. Here, it is being observed that at some time scales, MSE assigns higher entropy to the WN and AF group, rather than PN and NSR group respectively, which is a wrong estimation of complexity. However, both the groups are discriminated efficiently by this algorithm. Further, it is concluded that MSE measure both the entropy and short term variations associated with a time series, but unable to investigate the real complexity (meaning full structural organization) present in a signal.
C1 [Marwaha, Puneeta; Sunkaria, Ramesh Kumar; Kumar, Aman] Dept Elect & Commun Engn, Hamirpur, India.
   [Marwaha, Puneeta; Kumar, Aman] Natl Inst Technol, Hamirpur, Himanchal Prade, India.
   [Sunkaria, Ramesh Kumar] Dr BR Ambedkar Natl Inst Technol, Jalandhar, Punjab, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur; National Institute of Technology (NIT System); Dr B
   R Ambedkar National Institute of Technology Jalandhar
RP Marwaha, P (corresponding author), Dept Elect & Commun Engn, Hamirpur, India.; Marwaha, P (corresponding author), Natl Inst Technol, Hamirpur, Himanchal Prade, India.
EM puneetamarwaha@gmail.com; sunkariark@gmail.com; amankumar044@gmail.com
RI Kumar, Aman/AAZ-9928-2021
OI Kumar, Aman/0000-0001-9347-2506
CR Buchman TG, 2002, NATURE, V420, P246, DOI 10.1038/nature01260
   Camm AJ, 1996, CIRCULATION, V93, P1043
   Costa M, 2005, PHYS REV E, V71, DOI 10.1103/PhysRevE.71.021906
   Costa M, 2002, PHYS REV LETT, V89, DOI 10.1103/PhysRevLett.89.068102
   Costa MD, 2015, ENTROPY-SWITZ, V17, P1197, DOI 10.3390/e17031197
   FOGEDBY HC, 1992, J STAT PHYS, V69, P411, DOI 10.1007/BF01053799
   Goldberger AL, 2002, NEUROBIOL AGING, V23, P23, DOI 10.1016/S0197-4580(01)00266-4
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   GRASSBERGER P, 1991, NATO ADV SCI I B-PHY, V256, P15
   GRASSBERGER P, 1983, PHYS REV A, V28, P2591, DOI 10.1103/PhysRevA.28.2591
   Hausdorff JM, 1997, J APPL PHYSIOL, V82, P262
   Ivanov PC, 1999, NATURE, V399, P461, DOI 10.1038/20924
   MALIK M, 1990, CLIN CARDIOL, V13, P570, DOI 10.1002/clc.4960130811
   Marwaha P, 2014, ENG TECHNOL INT J BI, V8, P129
   Marwaha P, 2015, INT J MED ENG INFORM, V7, P1, DOI [DOI 10.1504/IJMEI.2015.066239, 10.1504/ijmei.2015.066239]
   Marwaha P, 2017, MED BIOL ENG COMPUT, V55, P191, DOI 10.1007/s11517-016-1476-y
   Marwaha P, 2016, AUSTRALAS PHYS ENG S, V39, P755, DOI 10.1007/s13246-016-0457-7
   Marwaha P, 2015, CARDIOVASC ENG TECHN, V6, P557, DOI 10.1007/s13239-015-0242-x
   Nikulin VV, 2004, PHYS REV LETT, V92, DOI 10.1103/PhysRevLett.92.089803
   PENG CK, 1993, PHYS REV LETT, V70, P1343, DOI 10.1103/PhysRevLett.70.1343
   PINCUS S, 1995, CHAOS, V5, P110, DOI 10.1063/1.166092
   Richman JS, 2000, AM J PHYSIOL-HEART C, V278, pH2039
   Sunkaria R.K., 2011, INT J COMPUT APPL, V35, P39, DOI [10.5120/4417-6138, DOI 10.5120/4417-6138]
   Voss A, 1995, J ELECTROCARDIOL, V28, P81, DOI 10.1016/S0022-0736(95)80021-2
   Zeng WZ, 1996, PHYS REV E, V54, P1779, DOI 10.1103/PhysRevE.54.1779
   ZHANG YC, 1991, J PHYS I, V1, P971, DOI 10.1051/jp1:1991180
NR 26
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7675
EP 7686
DI 10.1007/s11042-020-10104-3
EA OCT 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000587058000004
DA 2024-07-18
ER

PT J
AU Dutta, IN
   Chakraborty, N
   Mollah, AF
   Basu, S
   Sarkar, R
AF Dutta, Indra Narayan
   Chakraborty, Neelotpal
   Mollah, Ayatullah Faruk
   Basu, Subhadip
   Sarkar, Ram
TI BOB: a bi-level overlapped binning procedure for scene word binarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene word; Binarization; Binning; Delta image; Connected component;
   Text; non-text classification
ID TEXT LOCALIZATION; IMAGES; EXTRACTION
AB Scene text analysis involves detecting and processing text/words in natural scene images for serving various purposes. This problem domain intrigues the research fraternity due to challenges like dealing with noise, blur, heterogeneous intensity variation, etc. The ultimate goal is making detected scene word recognizable by any standard Optical Character Recognition system, thereby necessitating effective scene word binarization. Several methods address scene text detection, but comparatively few addresses scene word binarization. These binarization methods, however, have limitations in robustness against image quality-based complexities thus causing low precision. Here, a novel approach is proposed for scene word binarization called Bi-level Overlapped Binning where intensities of color channels R, G and B are grouped or binned to generate several solutions in the form of binary images. The stable binary images are identified such that the image solutions from them can be classified as text or non-text using a standard classifier trained with some popular features. Finally, the resultant text solutions are combined probabilistically to get the binarized output. The proposed method is evaluated on standard datasets such as SVT, ICDAR-2003, ICDAR-2011 (Scene), ICDAR-2011 (BDI), KAIST and Total-Text achieving precisions 0.76, 0.87, 0.89, 0.85, 0.84 and 0.87 respectively, which are mostly better than that of the state-of-the-art.
C1 [Dutta, Indra Narayan; Chakraborty, Neelotpal; Basu, Subhadip; Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
   [Mollah, Ayatullah Faruk] Aliah Univ, Dept Comp Sci & Engn, Kolkata 700160, India.
C3 Jadavpur University; Aliah University
RP Chakraborty, N (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
EM neelotpal_chakraborty@yahoo.com
RI CHAKRABORTY, NEELOTPAL/HNB-7710-2023; Sarkar, Ram/AAX-3822-2020
OI CHAKRABORTY, NEELOTPAL/0000-0003-2723-1434; Sarkar,
   Ram/0000-0001-8813-4086; Mollah, Ayatullah Faruk/0000-0002-3445-7469
FU CMATER research laboratory of the Computer Science and Engineering
   Department, Jadavpur University, India, PURSE-II, project; CMATER
   research laboratory of the Computer Science and Engineering Department,
   Jadavpur University, India, UPE-II, project; DBT
   [BT/PR16356/BID/7/596/2016]; DST [EMR/2016/007213]
FX This work is partially supported by the CMATER research laboratory of
   the Computer Science and Engineering Department, Jadavpur University,
   India, PURSE-II and UPE-II, project. SB is partially funded by DBT grant
   (BT/PR16356/BID/7/596/2016). RS, SB and AFM are partially funded by DST
   grant (EMR/2016/007213).
CR Bai B, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P262, DOI 10.1109/DAS.2014.34
   Bai X, 2016, IEEE T IMAGE PROCESS, V25, P2789, DOI 10.1109/TIP.2016.2555080
   Bhowmik S, 2019, IEEE T IMAGE PROCESS, V28, P1443, DOI 10.1109/TIP.2018.2878959
   Bhunia AK, 2018, MULTIMED TOOLS APPL, V77, P8551, DOI 10.1007/s11042-017-4750-6
   Bonechi S, 2019, LECT NOTES COMPUT SC, V11729, P238, DOI 10.1007/978-3-030-30508-6_20
   Chen H., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2609, DOI 10.1109/ICIP.2011.6116200
   Dai YC, 2018, INT C PATT RECOG, P3604, DOI 10.1109/ICPR.2018.8546066
   Dutta IN, 2019, ADV INTELL SYST, V740, P149, DOI 10.1007/978-981-13-1280-9_15
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Feild J, 2012, UMCS2012021 DEP COMP
   Ghoshal R, 2019, PATTERN ANAL APPL, V22, P1361, DOI 10.1007/s10044-018-0687-2
   Howe NR, 2013, INT J DOC ANAL RECOG, V16, P247, DOI 10.1007/s10032-012-0192-x
   Kasar T., 2007, CAMERA BASED DOCUMEN, P3
   KITTLER J, 1985, COMPUT VISION GRAPH, V30, P125, DOI 10.1016/0734-189X(85)90093-3
   Kumar Deepak., 2012, Proceeding of the workshop on Document Analysis and Recognition, P100
   Li Y, 2014, IEEE T IMAGE PROCESS, V23, P1666, DOI 10.1109/TIP.2014.2302896
   Liao MH, 2020, AAAI CONF ARTIF INTE, V34, P11474
   Lin H, 2020, ARCH COMPUT METHOD E, V27, P433, DOI 10.1007/s11831-019-09315-1
   Malakar S, 2020, NEURAL COMPUT APPL, V32, P2533, DOI 10.1007/s00521-018-3937-8
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Milyaev S, 2015, INT J DOC ANAL RECOG, V18, P169, DOI 10.1007/s10032-015-0240-4
   Mishra A, 2017, INT J DOC ANAL RECOG, V20, P105, DOI 10.1007/s10032-017-0283-9
   Mukhopadhyay Anirban, 2019, International Journal of Computer Vision and Image Processing, V9, P48, DOI 10.4018/IJCVIP.2019040104
   Niblack W, 1985, INTRO DIGITAL IMAGE
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Paul S, 2019, MULTIMED TOOLS APPL, V78, P18017, DOI 10.1007/s11042-019-7178-3
   Paul S, 2015, ADV INTELL SYST, V340, P217, DOI 10.1007/978-81-322-2247-7_23
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Tian CN, 2017, NEUROCOMPUTING, V260, P112, DOI 10.1016/j.neucom.2017.03.078
   Weinman JJ, 2014, IEEE T PATTERN ANAL, V36, P375, DOI 10.1109/TPAMI.2013.126
   Wolf C, 2002, INT C PATT RECOG, P160, DOI 10.1109/ICPR.2002.1047819
   Xie EZ, 2019, AAAI CONF ARTIF INTE, P9038
   Yin XC, 2015, IEEE T PATTERN ANAL, V37, P1930, DOI 10.1109/TPAMI.2014.2388210
   Zhang HG, 2013, NEUROCOMPUTING, V122, P310, DOI 10.1016/j.neucom.2013.05.037
NR 37
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7609
EP 7635
DI 10.1007/s11042-020-09785-7
EA OCT 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000584858300002
DA 2024-07-18
ER

PT J
AU Wischenbart, M
   Firmenich, S
   Rossi, G
   Bosetti, G
   Kapsammer, E
AF Wischenbart, Martin
   Firmenich, Sergio
   Rossi, Gustavo
   Bosetti, Gabriela
   Kapsammer, Elisabeth
TI Engaging end-user driven recommender systems: personalization through
   web augmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web augmentation; Visual programming; Client-side personalization;
   End-user programming; End-user development; Controllability of
   recommender systems; Browser-side trans-coding
AB In the past decades recommender systems have become a powerful tool to improve personalization on the Web. Yet, many popular websites lack such functionality, its implementation usually requires certain technical skills, and, above all, its introduction is beyond the scope and control of end-users. To alleviate these problems, this paper presents a novel tool to empower end-users without programming skills, without any involvement of website providers, to embed personalized recommendations of items into arbitrary websites on client-side. For this we have developed a generic meta-model to capture recommender system configuration parameters in general as well as in a web augmentation context. Thereupon, we have implemented a wizard in the form of an easy-to-use browser plug-in, allowing the generation of so-called user scripts, which are executed in the browser to engage collaborative filtering functionality from a provided external rest service. We discuss functionality and limitations of the approach, and in a study with end-users we assess the usability and show its suitability for combining recommender systems with web augmentation techniques, aiming to empower end-users to implement controllable recommender applications for a more personalized browsing experience.
C1 [Wischenbart, Martin] Johannes Kepler Univ Linz, Linz, Austria.
   [Firmenich, Sergio; Rossi, Gustavo; Bosetti, Gabriela] Univ Nacl La Plata, Lab Invest & Formac Informat Avanzada LIFIA, La Plata, Argentina.
   [Firmenich, Sergio; Rossi, Gustavo] Consejo Nacl Invest Cient & Tecn, La Plata, Argentina.
   [Kapsammer, Elisabeth] Johannes Kepler Univ Linz, Dept Cooperat Informat Syst CIS, Linz, Austria.
C3 Johannes Kepler University Linz; National University of La Plata;
   Consejo Nacional de Investigaciones Cientificas y Tecnicas (CONICET);
   Johannes Kepler University Linz
RP Wischenbart, M (corresponding author), Johannes Kepler Univ Linz, Linz, Austria.
EM k0255857@students.jku.at; sergio.firmenich@lifia.info.unlp.edu.ar;
   gustavo.rossi@lifia.info.unlp.edu.ar;
   gabriela.bosetti@lifia.info.unlp.edu.ar; elisabeth.kapsammer@jku.at
RI Bosetti, Gabriela/D-2702-2017
OI Bosetti, Gabriela/0000-0002-3968-6738; Rossi,
   Gustavo/0000-0002-3348-2144; Firmenich, Sergio/0000-0001-9502-2189
FU Johannes Kepler University Linz
FX Open access funding provided by Johannes Kepler University Linz.
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Aghaee S, 2014, J VISUAL LANG COMPUT, V25, P414, DOI 10.1016/j.jvlc.2013.12.004
   Ankolekar A, 2008, P HYP 2008 HT 08
   [Anonymous], 2017, INT C ART INT STAT A
   Barbosa ADM, 2014, THESIS
   Barrett R, 1998, COMPUT NETWORKS ISDN, V30, P509, DOI 10.1016/S0169-7552(98)00084-1
   Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012
   Bosetti G, 2017, MOB INF SYST, V2017, DOI 10.1155/2017/2525367
   Brusilovsky P., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P263
   Cantador I., 2015, CROSS DOMAIN RECOMME, P919
   Cremonesi P., 2011, CHI'11 extended abstracts on human factors in computing systems, P1927
   Della Penna G, 2010, J VISUAL LANG COMPUT, V21, P23, DOI 10.1016/j.jvlc.2009.06.001
   Diaz O, 2014, LECT NOTES COMPUTER, V8786
   Díaz O, 2015, ACM T WEB, V9, DOI 10.1145/2735633
   Ekstrand M. D., 2015, Proceedings of the 9th ACM Conference on Recommender Systems RecSys'15, P11
   Elmisery AM, 2017, MULTIMED TOOLS APPL, V76, P26103, DOI 10.1007/s11042-017-4950-0
   Eynard D, 2008, TECH REP
   Firmenich D, 2014, LECT NOTES COMPUT SC, V8541, P1, DOI 10.1007/978-3-319-08245-5_1
   Garrido A, 2013, IEEE INTERNET COMPUT, V17, P58, DOI 10.1109/MIC.2012.143
   Gonzalez R, 2020, LECT NOTES COMPUT SC, V12128, P467, DOI 10.1007/978-3-030-50578-3_31
   Harper F. Maxwell, 2015, Proceedings of the 9th ACM Conference on Recommender Systems, RecSys '15, P3
   Hendry, 2015, LECT NOTES ARTIF INT, V9101, P316, DOI 10.1007/978-3-319-19066-2_31
   Hijikata Y., 2014, Journal of information processing, V22, P669
   Isaac Sparling E., 2011, P 5 ACM C REC SYST R, P149, DOI [10.1145/2043932.2043961, DOI 10.1145/2043932.2043961]
   Jawaheer G, 2014, ACM T INTERACT INTEL, V4, DOI 10.1145/2512208
   Kleek MV, 2012, PERSONAL INFORM MANA
   Knijnenburg B, 2012, P 6 ACM C REC SYST
   Kobsa A, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P81, DOI 10.1145/2556288.2557102
   Kolias C, 2013, CLIENT SIDE PRIVACY, P297
   Kotkov D, 2017, LECT NOTES BUS INF P, V292, P105, DOI 10.1007/978-3-319-66468-2_6
   Malle B, 2017, LECT NOTES COMPUT SC, V10410, P367, DOI 10.1007/978-3-319-66808-6_24
   Newell C., 2013, P 7 ACM C RECOMMENDE, P473
   Ricci F, 2015, SOCIAL RECOMMENDER S
   Simpson John E., 2002, XPath and XPointer: Locating Content in XML Documents
   Son LH, 2016, INFORM SYST, V58, P87, DOI 10.1016/j.is.2014.10.001
   Wischenbart Martin, 2015, INTRS RECSYS, P53
   Xiaobin Fu, 2000, IUI 2000. 2000 International Conference on Intelligent User Interfaces, P106
   Xie Q, 2018, WORLD WIDE WEB, V21, P1655, DOI 10.1007/s11280-018-0532-y
   Zhang S, 2009, IONIC LIQUIDS: PHYSICOCHEMICAL PROPERTIES, P1
   Zheng XY, 2018, WORLD WIDE WEB, V21, P985, DOI 10.1007/s11280-017-0494-5
NR 40
TC 5
Z9 5
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 6785
EP 6809
DI 10.1007/s11042-020-09803-8
EA OCT 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000581569800002
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Li, SY
   Lin, YC
   Tam, LM
AF Li, Shih-Yu
   Lin, Yu-Cheng
   Tam, Lap-Mou
TI A smart detection technology for personal ECG monitoring via chaos-based
   data mapping strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart machine; Chaos-based data transform; ECG monitoring
ID KRILL HERD ALGORITHM; MYOCARDIAL-INFARCTION; NEURAL-NETWORK;
   CLASSIFICATION; DECOMPOSITION; ENSEMBLE; SIGNALS
AB This paper presents a smart detection technology for personal Electrocardiography (ECG) monitoring based on data integral-transform of chaotic system. First of all, a set of data-feeding system is developed, ECG data is technically converted into multiple-dimensional phase space, i.e., the dynamics of ECG data in time domain has been mapped into chaotic domain. Further, some effective and potential features in different sub-dimensional phase plane of the data, such as Euclidean Feature Values (EFV), Central Point Distribution (CPD), are captured, which indicates key biomarkers for different ECG states. In the final stage, following the key biomarkers, explicit boundary thresholds are defined for classification of different ECG states. Three ECG states given via open database-PhysioNet are validated, including normal sinus rhythm (NSR), congestive heart failure (CHF) and sleep apnea (SA). The experimental results show that the developed smart detection technology is effective and feasible for detecting and monitoring the states of such personal ECG states.
C1 [Li, Shih-Yu; Lin, Yu-Cheng] Natl Taipei Univ Technol, Grad Inst Mfg Technol, 1,Sec 3,Zhongxiao E Rd, Taipei 10608, Taiwan.
   [Tam, Lap-Mou] Inst Dev & Qual, Macau, Peoples R China.
   [Tam, Lap-Mou] Univ Macau, Fac Sci & Technol, Dept Electromech Engn, Macau, Peoples R China.
C3 National Taipei University of Technology; University of Macau
RP Li, SY (corresponding author), Natl Taipei Univ Technol, Grad Inst Mfg Technol, 1,Sec 3,Zhongxiao E Rd, Taipei 10608, Taiwan.
EM syntut@ntut.edu.tw
RI wen, Wen/KBB-1727-2024
FU Ministry of science and Technology, Taiwan; MOST
   [107-2628-E-027-003-MY3]; Institute for the Development and Quality,
   Macau, Macao
FX This study was funded in part by the Ministry of science and Technology,
   Taiwan, with Grant No. MOST 107-2628-E-027-003-MY3, and funded in part
   by Institute for the Development and Quality, Macau, Macao.
CR Abualigah L, 2021, CLUSTER COMPUT, V24, P205, DOI 10.1007/s10586-020-03075-5
   Abualigah L, 2020, NEURAL COMPUT APPL, V32, P12381, DOI 10.1007/s00521-020-04839-1
   Abualigah LM, 2018, APPL INTELL, V48, P4047, DOI 10.1007/s10489-018-1190-6
   Abualigah LM, 2018, ENG APPL ARTIF INTEL, V73, P111, DOI 10.1016/j.engappai.2018.05.003
   Abualigah LM, 2018, J COMPUT SCI-NETH, V25, P456, DOI 10.1016/j.jocs.2017.07.018
   Abualigah LM, 2017, APPL SOFT COMPUT, V60, P423, DOI 10.1016/j.asoc.2017.06.059
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Abualigah LMQ, 2019, INT J COMPUT SCI ENG, V5, P19
   Abualigah LMQ, 2019, SPRINGER STUDIES COM
   Acharya UR, 2017, INFORM SCIENCES, V415, P190, DOI 10.1016/j.ins.2017.06.027
   Acharya UR, 2017, INFORM SCIENCES, V377, P17, DOI 10.1016/j.ins.2016.10.013
   Ahmed PK, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1497-9
   Ahn JW, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19091991
   Al Rahhal MM, 2016, INFORM SCIENCES, V345, P340, DOI 10.1016/j.ins.2016.01.082
   Alyasseri ZAA, 2018, INFORM SCIENCES, V429, P229, DOI 10.1016/j.ins.2017.11.026
   [Anonymous], CARD DIS CVDS
   [Anonymous], 2011, INT J ARTIFICIAL INT, DOI DOI 10.5121/IJAIA.2011.2204
   Athif M., 2017, P 2017 IEEE INT C IN, P1, DOI [10.1109/ICIINFS.2017.8300342, DOI 10.1109/ICIINFS.2017.8300342]
   BAIM DS, 1986, J AM COLL CARDIOL, V7, P661, DOI 10.1016/S0735-1097(86)80478-8
   Chen HK, 2004, CHAOS SOLITON FRACT, V21, P957, DOI 10.1016/j.chaos.2003.12.034
   de Lannoy G, 2012, IEEE T BIO-MED ENG, V59, P241, DOI 10.1109/TBME.2011.2171037
   Fan GF, 2020, J FORECASTING, V39, P737, DOI 10.1002/for.2655
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Goshvarpour A, 2019, COMPUT METH PROG BIO, V172, P87, DOI 10.1016/j.cmpb.2019.02.009
   Hagiwara Y, 2018, INFORM SCIENCES, V467, P99, DOI 10.1016/j.ins.2018.07.063
   Jiang W, 2007, IEEE T NEURAL NETWOR, V18, P1750, DOI 10.1109/TNN.2007.900239
   Kido K, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071731
   Kim KS, 2011, CURR APPL PHYS, V11, P740, DOI 10.1016/j.cap.2010.11.051
   Kiranyaz S, 2016, IEEE T BIO-MED ENG, V63, P664, DOI 10.1109/TBME.2015.2468589
   Kobayashi M., 2019, 2019 IEEE SENS APPL, P1, DOI DOI 10.1109/sas.2019.8706009
   Krasteva V, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19132920
   Kundra H., 2015, RES J INF TECHNOL, V7, P58, DOI DOI 10.3923/RJIT.2015.58.69
   Li MW, 2019, NONLINEAR DYNAM, V97, P2579, DOI 10.1007/s11071-019-05149-5
   Li SY, 2020, INFORM SCIENCES, V513, P553, DOI 10.1016/j.ins.2019.11.010
   Li W, 2019, IEEE ACCESS, V7, P25627, DOI 10.1109/ACCESS.2018.2877793
   Li ZJ, 2019, IEEE ACCESS, V7, P77849, DOI 10.1109/ACCESS.2019.2920900
   Liew R, 2011, CLIN CARDIOL, V34, P466, DOI 10.1002/clc.20924
   Lynn HM, 2019, IEEE ACCESS, V7, P145395, DOI 10.1109/ACCESS.2019.2939947
   Manna T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1337-y
   Marinho LB, 2019, FUTURE GENER COMP SY, V97, P564, DOI 10.1016/j.future.2019.03.025
   Martis RJ, 2013, INT J NEURAL SYST, V23, DOI 10.1142/S0129065713500147
   Moeyersons J, 2017, COMPUT CARDIOL CONF, V44, DOI 10.22489/CinC.2017.240-159
   Mondéjar-Guerra V, 2019, BIOMED SIGNAL PROCES, V47, P41, DOI 10.1016/j.bspc.2018.08.007
   Pant T, 2019, APPL MATH MODEL, V72, P369, DOI 10.1016/j.apm.2019.03.016
   Penzel T, 2000, COMPUT CARDIOL, V27, P255, DOI 10.1109/CIC.2000.898505
   Pinho A, 2019, APPL SOFT COMPUT, V83, DOI 10.1016/j.asoc.2019.105568
   Seo W, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19133021
   Sharma RR, 2019, IEEE SENS J, V19, P3912, DOI 10.1109/JSEN.2019.2894706
   Srivastva R, 2019, IET BIOMETRICS, V8, P295, DOI 10.1049/iet-bmt.2018.5093
   Zarei A, 2019, IEEE J BIOMED HEALTH, V23, P1011, DOI 10.1109/JBHI.2018.2842919
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
NR 51
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6397
EP 6412
DI 10.1007/s11042-020-09938-8
EA OCT 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577869200003
DA 2024-07-18
ER

PT J
AU Gao, YM
   Kang, XB
   Chen, YJ
AF Gao, Yumei
   Kang, Xiaobing
   Chen, Yajun
TI A robust video zero-watermarking based on deep convolutional neural
   network and self-organizing map in polar complex exponential transform
   domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Zero-watermarking; Convolutional neural network; Self-organizing map;
   Polar complex exponential transform; Chaotic encryption
ID SCHEME; IMAGE
AB In this paper, a robust video zero-watermarking scheme for copyright protection using a combination of convolutional neural network (CNN) and self-organizing map (SOM) in polar complex exponential transform (PCET) space is presented. The scheme is developed not only to remedy the existing problems of lacking in some performance assessments but also to enhance the robustness. It starts with extracting the content feature of each frame by CNN and then some significant frames are selected using SOM clustering and maximum entropy. Secondly, the PCET is applied to all selected frames to abstract invariant moments, and further, is scrambled by a chaotic logistic map and is reduced in dimensions by singular value decomposition (SVD). Next, a binary sequence is generated by comparing adjacent values of the obtained compact PCET moments in the previous step, and further is permuted to produce a binary matrix. Finally, a bitwise exclusive-OR operation is imposed on the binary matrix and the encrypted watermark by the chaotic map to generate a zero-watermark signal. Experimental results demonstrate that the proposed scheme has adequate equalization and distinguishability of zero-watermarks as well as strong robustness against common signal processing, geometric, compression, and inter-frame attacks. Also, compared with existing video zero-watermarking and traditional video watermarking methods, the proposed scheme exhibits superior robustness.
C1 [Gao, Yumei; Kang, Xiaobing; Chen, Yajun] Xian Univ Technol, Fac Printing Packaging Engn & Digital Media Techn, Dept Informat Sci, Xian 710048, Shaanxi, Peoples R China.
C3 Xi'an University of Technology
RP Kang, XB (corresponding author), Xian Univ Technol, Fac Printing Packaging Engn & Digital Media Techn, Dept Informat Sci, Xian 710048, Shaanxi, Peoples R China.
EM kangxb@xaut.edu.cn
OI kang, xiaobing/0000-0003-2537-639X
FU National Key R&D Program of China [2018YFD0700400]; National Natural
   Science Foundation of China [61671374]; Key Research and Development
   Program of Shaanxi Province [2019GY-080]; Shaanxi Provincial Education
   Department [15JK1504, 20JY053]
FX This work was supported by National Key R&D Program of China (Grant No.
   2018YFD0700400), National Natural Science Foundation of China (Grant No.
   61671374), the Key Research and Development Program of Shaanxi Province
   (Grant No. 2019GY-080), and the Scientific Research Program Funded by
   Shaanxi Provincial Education Department (Program Nos. 15JK1504 &
   20JY053).
CR Abpeikar S, 2020, NEURAL NETWORKS, V124, P20, DOI 10.1016/j.neunet.2019.12.029
   [Anonymous], 2001, SELF ORG MAPS
   Asikuzzaman M, 2018, IEEE T CIRC SYST VID, V28, P2131, DOI 10.1109/TCSVT.2017.2712162
   Cao ZL, 2019, MULTIMED TOOLS APPL, V78, P26089, DOI 10.1007/s11042-019-07809-5
   Chen L, 2018, MULTIMED TOOLS APPL, V77, P7187, DOI 10.1007/s11042-017-4628-7
   Gao ZF, 2020, NEURAL NETWORKS, V123, P82, DOI 10.1016/j.neunet.2019.11.017
   Golea Nour El-Houda, 2019, International Journal of High Performance Computing and Networking, V13, P199
   Huaiqiang Zhang, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1141, DOI 10.1109/CECNet.2012.6201983
   Joshi AM, 2017, ADV INTELL SYST, V468, P455, DOI 10.1007/978-981-10-1675-2_45
   Kang XB, 2020, MULTIMED TOOLS APPL, V79, P1169, DOI 10.1007/s11042-019-08191-y
   Li, 2018, MUE FUTURETECH, P565
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Li D, 2016, MULTIMED TOOLS APPL, V75, P13093, DOI 10.1007/s11042-015-2733-z
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Li LD, 2012, INFORM SCIENCES, V199, P1, DOI 10.1016/j.ins.2012.02.062
   Li YT, 2020, ACM T SENSOR NETWORK, V16, DOI 10.1145/3397179
   Liu XY, 2017, SIGNAL PROCESS-IMAGE, V54, P140, DOI 10.1016/j.image.2017.03.002
   Liu XY, 2015, MULTIMED TOOLS APPL, V74, P9157, DOI 10.1007/s11042-014-2073-4
   Qu Z., 2019, INT J HIGH PERFORM C, V14, P121, DOI [10.1504/IJHPCN.2019.10022723, DOI 10.1504/IJHPCN.2019.10022723]
   Raghu S, 2020, NEURAL NETWORKS, V124, P202, DOI 10.1016/j.neunet.2020.01.017
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shukla D, 2018, J INTELL SYST, V27, P47, DOI 10.1515/jisys-2017-0039
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Singh KM, 2018, MULTIMED TOOLS APPL, V77, P16419, DOI 10.1007/s11042-017-5213-9
   Strogatz S., 2015, NONLINEAR DYNAMICS C, V2nd
   Wang CP, 2016, J VIS COMMUN IMAGE R, V41, P247, DOI 10.1016/j.jvcir.2016.10.004
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang YG, 2018, IEEE ACCESS, V6, P15816, DOI 10.1109/ACCESS.2018.2802928
   Wen Quan, 2003, Acta Electronica Sinica, V31, P214
   Xu GJ, 2009, 2009 ASIA-PACIFIC CONFERENCE ON INFORMATION PROCESSING (APCIP 2009), VOL 2, PROCEEDINGS, P15, DOI 10.1109/APCIP.2009.140
   Yang HY, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115747
   Yap PT, 2010, IEEE T PATTERN ANAL, V32, P1259, DOI 10.1109/TPAMI.2009.119
   Yu XY, 2019, IEEE ACCESS, V7, P115708, DOI 10.1109/ACCESS.2019.2936134
   Zhang EH, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9050841
NR 34
TC 11
Z9 12
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6019
EP 6039
DI 10.1007/s11042-020-09904-4
EA OCT 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000578564800003
DA 2024-07-18
ER

PT J
AU Luzardo, G
   Vyvey, T
   Aelterman, J
   Paridaens, T
   Van Wallendael, G
   Lambert, P
   Rousseaux, S
   Luong, H
   Durnez, W
   Van Looy, J
   Philips, W
   Ochoa, D
AF Luzardo, Gonzalo
   Vyvey, Tine
   Aelterman, Jan
   Paridaens, Tom
   Van Wallendael, Glenn
   Lambert, Peter
   Rousseaux, Sven
   Luong, Hiep
   Durnez, Wouter
   Van Looy, Jan
   Philips, Wilfried
   Ochoa, Daniel
TI An experimental study on the perceived quality of natively graded versus
   inverse tone mapped high dynamic range video content on television
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High dynamic range; Inverse tone mapping; Subjective study
ID COMPRESSION
AB High Dynamic Range (HDR) television promises to display higher brightness and deeper black levels and thus more vivid and realistic images. However, home video distribution and video broadcasting were historically designed for what we now call standard dynamic range screens (SDR). In order to display SDR content on an HDR screen, it is explicitly or implicitly converted, in a process called inverse tone mapping (iTMO). This paper's goal is to assess the perceived quality of converted SDR content in comparison to natively graded HDR content. In doing so, this paper aims to enable content creators/distributors to make informed choices between creating/broadcasting HDR content or relying on conversion. To this end, a psychophysical experiment was performed to tests how viewers evaluate the difference between natively graded HDR and a set of SDR to HDR conversion options in a television setup. Results indicate that viewers prefer natively graded HDR content, followed by inverse tone mapping algorithms starting from videos with a compressed dynamic range. When comparing conversion options, users clearly prefer conversion from 'compressed dynamic range' SDR over 'clipped dynamic range' SDR. Users disliked videos that were naively stretched from standard SDR. In addition, a significant effect of type of sequence was found, with a preference for light scenes with low contrast.
C1 [Luzardo, Gonzalo; Vyvey, Tine; Aelterman, Jan; Luong, Hiep; Durnez, Wouter; Van Looy, Jan; Philips, Wilfried] Univ Ghent, Imec IPI UGent, Sint Pietersnieuwstr 41, B-9000 Ghent, Belgium.
   [Paridaens, Tom; Van Wallendael, Glenn; Lambert, Peter] Univ Ghent, Dept Elect & Informat Syst, Sint Pietersnieuwstr 41, B-9000 Ghent, Belgium.
   [Rousseaux, Sven] Vlaamse Radio & Televisieomroeporganisatie, Auguste Reyerslaan 52, Brussels, Belgium.
   [Luzardo, Gonzalo; Ochoa, Daniel] ESPOL Polytech Univ, Fac Ingn Elect & Comp, Campus Gustavo Galindo Km 30-5 Via Perimetral, Guayaquil, Ecuador.
C3 IMEC; Ghent University; Ghent University
RP Luzardo, G (corresponding author), Univ Ghent, Imec IPI UGent, Sint Pietersnieuwstr 41, B-9000 Ghent, Belgium.; Luzardo, G (corresponding author), ESPOL Polytech Univ, Fac Ingn Elect & Comp, Campus Gustavo Galindo Km 30-5 Via Perimetral, Guayaquil, Ecuador.
EM GonzaloRaimundo.LuzardoMorocho@UGent.be; Jan.Aelterman@UGent.be;
   Tom.Paridaens@UGent.be; Glenn.Vanwallendael@UGent.be;
   Peter.Lambert@UGent.be; sven.rousseaux@vrt.be; Hiep.Luong@UGent.be;
   Wouter.Durnez@UGent.be; Wilfried.Philips@UGent.be; dochoa@espol.edu.ec
RI Luong, Hiep/HKN-4631-2023; Van Wallendael, Glenn/H-8315-2015; Luzardo,
   Gonzalo/HGB-9179-2022; Lambert, Peter/D-7776-2016
OI Van Wallendael, Glenn/0000-0001-9530-3466; Luzardo,
   Gonzalo/0000-0002-9757-4507; Lambert, Peter/0000-0001-5313-4158
FU imec-ICON-HD2R project; imec, a digital research institute; Secretaria
   de Educacion Superior, Ciencia, Tecnologia e Innovacion (SENESCYT);
   Escuela Superior Politecnica del Litoral (ESPOL); Ghent University
   [BOF15/PDO/003]
FX This work was supported by the imec-ICON-HD2R project, co-funded by
   imec, a digital research institute founded by the Flemish Government.
   Project partners are Barco, Grass Valley, Limecraft, VRT, and Grid. The
   work of G. Luzardo was supported by Secretaria de Educacion Superior,
   Ciencia, Tecnologia e Innovacion (SENESCYT) and Escuela Superior
   Politecnica del Litoral (ESPOL). Jan Aelterman is currently supported by
   a Ghent University postdoctoral fellowship (BOF15/PDO/003).
CR Abebe MA, 2015, ACM T APPL PERCEPT, V12, DOI 10.1145/2808232
   [Anonymous], 2008, Synthesis Lectures on Computer Graphics and Animation
   [Anonymous], 2005, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting (The Morgan Kaufmann Series in Computer Graphics
   [Anonymous], 2017, SIM2 HDR DISPLAY HDR
   [Anonymous], 2005, Digital Video Quality: Vision Models and Metrics
   [Anonymous], 2017, Quality and User Experience, DOI DOI 10.1007/S41233-017-0007-4
   Aydin TO, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360668
   Banterle F, 2009, COMPUT GRAPH FORUM, V28, P13, DOI 10.1111/j.1467-8659.2008.01176.x
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bist C, 2017, COMPUT GRAPH-UK, V62, P77, DOI 10.1016/j.cag.2016.12.006
   Chalmers A, 2016, 2016 DIGITAL MEDIA INDUSTRY AND ACADEMIC FORUM (DMIAF), P53, DOI 10.1109/DMIAF.2016.7574902
   Chen CR, 2011, AS PAC SIGN INF P AS
   Daly S, 2004, PROC SPIE, V5292, P130, DOI 10.1117/12.526937
   Daly S, 2003, P SOC PHOTO-OPT INS, V5008, P455, DOI 10.1117/12.472016
   Daly S., 2013, SID S DIGEST TECHNIC, V44, P563, DOI DOI 10.1002/J.2168-0159.2013.TB06271.X
   Daly S, 2013, INT SOC OPT PHOTON, V8651
   De Paepe AL, 2017, NEUROPSYCHOLOGIA, V101, P121, DOI 10.1016/j.neuropsychologia.2017.05.015
   Divakaran A., 2001, Computer Analysis of Images and Patterns. 9th International Conference, CAIP 2001. Proceedings (Lecture Notes in Computer Science Vol.2124), P29
   Dong YY, 2016, IEEE T MULTIMEDIA, V18, P549, DOI 10.1109/TMM.2016.2522639
   Durnez W, 2015, J PAIN, V16, P135, DOI 10.1016/j.jpain.2014.10.012
   Hanhart P., 2015, SMPTE MOTION IMAGING, V124, P1
   HOLM S, 1979, SCAND J STAT, V6, P65
   ITU, 2012, INT TELECOMMUN UNION, V13, P1
   Jamieson Susan, 2004, Med Educ, V38, P1217, DOI 10.1111/j.1365-2929.2004.02012.x
   Jeannin S, 2001, IEEE T CIRC SYST VID, V11, P720, DOI 10.1109/76.927428
   Khanh TQ, 2017, LIGHTING RES TECHNOL, V49, P697, DOI 10.1177/1477153516643359
   Kovaleski RP, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P49, DOI 10.1109/SIBGRAPI.2014.29
   Kuzon WM, 1996, ANN PLAS SURG, V37, P265, DOI 10.1097/00000637-199609000-00006
   Ledda P., 2004, Proceedings of the 3rd international conference on Com- puter graphics, virtual reality, visualisation and interaction in Africa, P151
   Lee JS, 2011, IEEE T MULTIMEDIA, V13, P882, DOI 10.1109/TMM.2011.2157333
   Lee S., 2018, ARXIV180106277
   Luthra A, 2016, 1SC29WG11 ISOIEC JTC
   Luzardo G, 2018, PICT COD SYMP, P199, DOI 10.1109/PCS.2018.8456253
   Mai ZC, 2013, IEEE T MULTIMEDIA, V15, P1503, DOI 10.1109/TMM.2013.2266633
   Marnerides D, 2018, COMPUT GRAPH FORUM, V37, P37, DOI 10.1111/cgf.13340
   Masia B, 2017, MULTIMED TOOLS APPL, V76, P631, DOI 10.1007/s11042-015-3036-0
   Masia B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618506
   Mukherjee R, 2016, VISUAL COMPUT, V32, P825, DOI 10.1007/s00371-016-1239-7
   Norman G, 2010, ADV HEALTH SCI EDUC, V15, P625, DOI 10.1007/s10459-010-9222-y
   Pouli T, 2016, ACM SIGGRAPH 2016 CO, P14
   Shokrollahi A, 2017, AEU-INT J ELECTRON C, V77, P61, DOI 10.1016/j.aeue.2017.04.026
   Smith M, 2015, MANAGING HDR CONTENT, P11, DOI [10.1049/ibc.2015.0031, DOI 10.1049/IBC.2015.0031]
   Verbruggen F, 2010, P NATL ACAD SCI USA, V107, P13966, DOI 10.1073/pnas.1001957107
   Wadgave U, 2016, ASIAN J PSYCHIATR, V24, P67, DOI 10.1016/j.ajp.2016.08.016
   Wang TH, 2015, IEEE T MULTIMEDIA, V17, P470, DOI 10.1109/TMM.2015.2403612
   Ward G., 2006, ACM SIGGRAPH 2006 CO, P3
   West BT, 2007, Linear mixed models: a practical guide using statistical software
   You JY, 2011, IEEE T MULTIMEDIA, V13, P1269, DOI 10.1109/TMM.2011.2172591
   Zhang Y, 2011, IEEE IMAGE PROC, P1321, DOI 10.1109/ICIP.2011.6115679
NR 49
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5559
EP 5576
DI 10.1007/s11042-020-09955-7
EA OCT 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000575795400001
DA 2024-07-18
ER

PT J
AU Ji, XG
   Zhang, XX
   Hu, HT
AF Ji, Xiaogang
   Zhang, Xixi
   Hu, Haitao
TI Point cloud segmentation for complex microsurfaces based on feature line
   fitting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reverse engineering; Feature point extraction; Feature line fitting;
   Point cloud data segmentation; Model reconstruction
ID EXTRACTION
AB Surfaces based on feature line constraints have higher accuracy than free-form surfaces and can capture other geometric relations of the model. The parts of complex microsurfaces are formed by arrays and crossings of several small surfaces. Many problems can be encountered in identifying feature points and fitting feature lines, which are difficult to solve by reverse engineering. In this study, feature point extraction, feature line fitting, and three-dimensional segmentation were investigated. First, the connection between two surfaces and the corresponding differential geometric quantities were explored. Then, a feature point extraction method for complex models was proposed. Second, the problems of separation, simplification, and combination of feature points for different models were analyzed, and the feature lines used to segment the point cloud were constructed. Finally, a region growth method based on feature line constraints was proposed to segment the point cloud data. Experimental results show that this method can solve the problem of excessive and insufficient segmentation for complex microsurface point cloud data and thus represents a foundation for high-quality model reconstruction.
C1 [Ji, Xiaogang; Zhang, Xixi; Hu, Haitao] Jiangnan Univ, Sch Mech Engn, Wuxi 214122, Jiangsu, Peoples R China.
   [Ji, Xiaogang] Jiangnan Univ, Jiangsu Key Lab Adv Food Mfg Equipment & Technol, Wuxi 214122, Jiangsu, Peoples R China.
C3 Jiangnan University; Jiangnan University
RP Ji, XG (corresponding author), Jiangnan Univ, Sch Mech Engn, Wuxi 214122, Jiangsu, Peoples R China.; Ji, XG (corresponding author), Jiangnan Univ, Jiangsu Key Lab Adv Food Mfg Equipment & Technol, Wuxi 214122, Jiangsu, Peoples R China.
EM bhearts@jiangnan.edu.cn
OI Ji, Xiaogang/0000-0002-3958-7537
FU National Natural Science Foundation of China [51105175]; Six Talent
   Climax Foundation of Jiangsu Province [JXQC-006]
FX This work was supported by "the National Natural Science Foundation of
   China" under Grant No. 51105175 and "Six Talent Climax Foundation of
   Jiangsu Province" under Grant No. JXQC-006.
CR Abualigah LM, 2018, APPL INTELL, V48, P4047, DOI 10.1007/s10489-018-1190-6
   Altantsetseg E, 2013, VISUAL COMPUT, V29, P617, DOI 10.1007/s00371-013-0800-x
   An Y, 2016, INT J COMPUT APPL T, V54, P51, DOI 10.1504/IJCAT.2016.077790
   Angelina S., 2012, 2012 International Conference on Computing, Electronics and Electrical Technologies (ICCEET 2012), P970, DOI 10.1109/ICCEET.2012.6203833
   Vo AV, 2015, ISPRS J PHOTOGRAMM, V104, P88, DOI 10.1016/j.isprsjprs.2015.01.011
   Anwer N, 2016, CIRP ANN-MANUF TECHN, V65, P165, DOI 10.1016/j.cirp.2016.04.052
   Chen Hua-wei, 2019, Optics and Precision Engineering, V27, P1218, DOI 10.3788/OPE.20192705.1218
   Chen XB, 2017, TRANSP GEOTECH, V11, P27, DOI 10.1016/j.trgeo.2017.04.001
   Daniels J, 2007, ROBUST SMOOTH FEATUR
   Demarsin K, 2007, COMPUT AIDED DESIGN, V39, P276, DOI 10.1016/j.cad.2006.12.005
   Di AL, 2012, COMPUT METHOD BIOMEC, V16, P1213
   Di Angelo L, 2015, COMPUT AIDED DESIGN, V62, P44, DOI 10.1016/j.cad.2014.09.006
   Di Angelo L, 2011, COMPUT AIDED DESIGN, V43, P639, DOI 10.1016/j.cad.2011.02.012
   Gao R., 2017, AERONAUT MANUF TECHN, V60, P60
   Hackel T, 2016, ISPRS ANN PHOTO REM, V3, P177, DOI 10.5194/isprsannals-III-3-177-2016
   Hackel T, 2016, PROC CVPR IEEE, P1610, DOI 10.1109/CVPR.2016.178
   He Tong, 2018, Computer Engineering, V44, P275, DOI 10.3969/j.issn.1000-3428.2018.03.046
   [胡丝兰 Hu Silan], 2015, [系统仿真学报, Journal of System Simulation], V27, P2446
   Huang GZ, 2015, STUDY ALGORITHM DATA
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Lawin FJ, 2017, LECT NOTES COMPUT SC, V10424, P95, DOI 10.1007/978-3-319-64689-3_8
   Li R. Z, 2018, LAS OPTOELECT PROG, V55, P325
   Lu L, 2011, COMPUTATIONAL SCI IT
   Ni H, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090710
   Nie JH, 2015, COMPUT AID DESIG COM, V27, P98
   Tong-guang Ni, 2010, 2010 2nd International Conference on Computer Engineering and Technology (ICCET), P15, DOI 10.1109/ICCET.2010.5485908
   Vaswani N, 2018, P IEEE SPEC ISS RETH
   [王小超 Wang Xiaochao], 2013, [计算机辅助设计与图形学学报, Journal of Compute-Aided Design and Graphics], V25, P659
   Wang XH, 2020, MULTIMED TOOLS APPL, V79, P11861, DOI 10.1007/s11042-019-08512-1
   Weber BR, 2010, OLD AND NEW MEDIA AFTER KATRINA, P175
   Xia SB, 2017, IEEE GEOSCI REMOTE S, V14, P1288, DOI 10.1109/LGRS.2017.2707467
   Xie Xiao-yao, 2014, Journal of Shenyang University of Technology, V36, P308, DOI 10.7688/j.issn.1000-1646.2014.03.13
   Zhang YH, 2016, COMPUT GRAPH-UK, V56, P31, DOI 10.1016/j.cag.2016.01.004
   Zhao H, 2013, PROCEDIA CIRP, V10, P112
NR 34
TC 4
Z9 4
U1 6
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4553
EP 4578
DI 10.1007/s11042-020-09910-6
EA SEP 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000574101100001
DA 2024-07-18
ER

PT J
AU Rani, R
   Lobiyal, DK
AF Rani, Ruby
   Lobiyal, D. K.
TI An extractive text summarization approach using tagged-LDA based topic
   modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Topic modeling; Hindi novel; Topic diversity; Retention ratio;
   Tagged-LDA
ID DOMAIN; REVIEWS
AB Automatic text summarization is an exertion of contriving the abridged form of a text document covering salient knowledge. Numerous statistical, linguistic, rule-based, and position-based text summarization approaches have been explored for different rich-resourced languages. For under-resourced languages such as Hindi, automatic text summarization is a challenging task and still an unsolved problem. Another issue with such languages is the unavailability of corpus and the inadequacy of the processing tools. In this paper, we proposed an extractive lexical knowledge-rich topic modeling text summarization approach for Hindi novels and stories in which we implemented four independent variants using different sentence weighting schemes. We prepared a corpus of Hindi Novels and stories since the absence of a corpus. We used a smoothing technique for edifying and variety summaries followed by evaluating the efficacy of generated summaries against three metrics (gist diversity, retention ratio, and ROUGE score). The results manifest that the proposed model produces abridge, articulate and coherent summaries. To investigate the performance of the proposed model, we simulate the experiments on the English dataset as well. Further, we compare our models with the baselines and traditional topic modeling approach, where we show that the proposed model has confessed optimal results.
C1 [Rani, Ruby; Lobiyal, D. K.] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.
C3 Jawaharlal Nehru University, New Delhi
RP Rani, R (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.
EM ruby73_scs@jnu.ac.in; dkl@mail.jnu.ac.in
CR Aggarwal C. C., 2018, MACHINE LEARNING TEX, P361, DOI [10.1007/978-3-319-73531-3_12, DOI 10.1007/978-3-319-73531-3_12]
   Al-Radaideh QA, 2018, COGN COMPUT, P1
   [Anonymous], 2004, TSBO
   [Anonymous], 2019, PREMCH
   [Anonymous], 2004, P 2004 C EMP METH NA
   [Anonymous], 2014, P 3 JOINT C LEX COMP
   Bairi RB, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P553
   Bamman D., 2013, ARXIV13051319
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Brainy, BRAIN QUEST
   Ceylan H, 2011, INVESTIGATING EXTRAC
   Chi Lianhua., 2014, SDM, P100
   Di Fabbrizio G, 2013, IEEE INTELL SYST, V28, P28, DOI 10.1109/MIS.2013.36
   Elhadad Michael, 2013, P MULTILING 2013 WOR, P13
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   Erkan G., 2004, P 2004 C EMPIRICAL M
   Forascu C., 2013, MULTIDOCUMENT MULT 1
   Gambhir M, 2017, ARTIF INTELL REV, V47, P1, DOI 10.1007/s10462-016-9475-9
   Gupta V, 2016, COGN COMPUT, V8, P261, DOI 10.1007/s12559-015-9359-3
   Hafeez A, 2018, INT COMPUT ENG CONF, P79, DOI 10.1109/ICENCO.2018.8636140
   Hu YH, 2017, INFORM PROCESS MANAG, V53, P436, DOI 10.1016/j.ipm.2016.12.002
   John A, 2017, EXPERT SYST APPL, V86, P385, DOI 10.1016/j.eswa.2017.05.075
   Kabadjov M, 2010, LECT NOTES ARTIF INT, V6323, P591, DOI 10.1007/978-3-642-15939-8_40
   Kazantseva A, 2010, COMPUT LINGUIST, V36, P71, DOI 10.1162/coli.2010.36.1.36102
   Litvak M., 2015, P 2015 WORKSH TOP MO, P39, DOI [10.1145/2809936.2809944, DOI 10.1145/2809936.2809944]
   Litvak M, 2017, INT C COMP LING INT, P522
   Liu D, 2004, MEAD PLATFORM MULTID
   Liu N, 2016, CHIN CONT DECIS CONF, P3847, DOI 10.1109/CCDC.2016.7531656
   Liu N, 2014, INT SYMP PARAL ARCH, P69, DOI 10.1109/PAAP.2014.22
   Liu N, 2014, CHIN CONT DECIS CONF, P5168, DOI 10.1109/CCDC.2014.6853102
   Luhn HP, 1999, ADVANCES IN AUTOMATIC TEXT SUMMARIZATION, P15
   Mendoza M, 2014, EXPERT SYST APPL, V41, P4158, DOI 10.1016/j.eswa.2013.12.042
   Mensah-Darkwa K, 2013, INTERNATIONAL MECHANICAL ENGINEERING CONGRESS AND EXPOSITION - 2012, VOL 3, PTS A-C: DESIGN, MATERIALS, AND MANUFACTURING, P717
   Mishra R, 2014, J BIOMED INFORM, V52, P457, DOI 10.1016/j.jbi.2014.06.009
   Nomoto T, 2003, INFORM PROCESS MANAG, V39, P363, DOI 10.1016/S0306-4573(02)00096-1
   Oufaida H, 2015, LECT NOTES COMPUT SC, V9103, P51, DOI 10.1007/978-3-319-19581-0_4
   Ozsoy MG, 2011, J INF SCI, V37, P405, DOI 10.1177/0165551511408848
   Parveen D., 2015, 24 INT JOINT C ART I
   Patel A., 2007, Large scale semantic access to content (text, image, video, and sound), P123
   Rani R, 2018, INT CONF COMPUT INTE, P15, DOI [10.1109/CICN.2018.8864951, 10.1109/CICN.2018.4]
   Rani R, 2018, LECT NOTES COMPUT SC, V11278, P123, DOI 10.1007/978-3-030-04021-5_12
   Roul RK, 2019, LECT NOTES COMPUT SC, V11319, P212, DOI 10.1007/978-3-030-05366-6_17
   Sanchez-Gomez JM, 2018, KNOWL-BASED SYST, V159, P1, DOI 10.1016/j.knosys.2017.11.029
   Sanghoon Lee, 2013, Machine Learning and Data Mining in Pattern Recognition. 9th International Conference, MLDM 2013. Proceedings: LNCS 7988, P159, DOI 10.1007/978-3-642-39712-7_12
   Sheng Y, 2016, INT CONF COMP SCI ED, P299, DOI 10.1109/ICCSE.2016.7581597
   Singh J, 2017, COGN COMPUT, V9, P671, DOI 10.1007/s12559-017-9479-z
   Torres-Moreno J-M, 2009, ARXIV09052990
   Wang Dengting, 2009, Proceedings of the 5th International Conference on Asian and Pacific Coasts. APAC 2009, P297, DOI 10.1142/9789814287951_0129
   Wu ZD, 2017, EXPERT SYST APPL, V84, P12, DOI 10.1016/j.eswa.2017.04.054
   Yang GB, 2015, EXPERT SYST APPL, V42, P1340, DOI 10.1016/j.eswa.2014.09.015
   Yao J. -g., 2015, 24 INT JOINT C ART I
   Yihong Gong, 2001, SIGIR Forum, P19
   Zhu N, 2015, PROC ANNU SIMUL SYMP, P119
   Zhuang L, 2006, INT C INF KNOWL MAN, V2006, P43, DOI [DOI 10.1145/1183614.1183625, 10.1145/1183614.1183625]
NR 54
TC 33
Z9 35
U1 3
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3275
EP 3305
DI 10.1007/s11042-020-09549-3
EA SEP 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000571253200003
DA 2024-07-18
ER

PT J
AU Dolati, N
   Beheshti, A
   Azadegan, H
AF Dolati, Neda
   Beheshti, Ali
   Azadegan, Hamid
TI A selective encryption for H.264/AVC videos based on scrambling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264/AVC; Selective encryption; DCT coefficients; Zigzag scan; CABAC
   entropy
ID CHAOS; PROTECTION
AB H.264/Advanced Video Coding (H.264/AVC) is one of the video compression standards that is 50% more efficient than previously introduced standards. Given that the H.264/AVC standard is considered and used in a variety of video applications, it is essential to provide a suitable solution for video encryption with good security, high encryption speed, and to prevent bitrate increases. In this paper, we propose a method selective encryption of H.264/AVC for the digital rights management (DRM) applications. In this method, discrete cosine transform (DCT) coefficients, which affect the texture and content of the H.264/AVC video during compression, are encrypted after the zigzag scanning and based on Context-Adaptive Binary Arithmetic Coding (CABAC). The experimental results and encryption efficiency analysis demonstrate that the proposed method with the format compliance has good security and high encryption speed and it can prevent the bitrate from rising and is thus usable in industrial and the DRM applications.
C1 [Dolati, Neda; Beheshti, Ali; Azadegan, Hamid] Iran Univ Sci & Technol, Sch Elect Engn, Tehran, Iran.
C3 Iran University Science & Technology
RP Beheshti, A (corresponding author), Iran Univ Sci & Technol, Sch Elect Engn, Tehran, Iran.
EM abeheshti@iust.ac.ir
RI Azadegan, Hamid/HJG-7117-2022
OI Azadegan, Hamid/0000-0003-3481-9391; Beheshti Shirazi, Seyed Ali
   Asghar/0000-0001-9603-5117
CR Ahn J, 2004, LECT NOTES COMPUT SC, V3333, P386
   Altaf M, 2018, MULTIMED TOOLS APPL, V77, P27981, DOI 10.1007/s11042-018-6022-5
   [Anonymous], 2010, INT COMPUT THEORY EN
   [Anonymous], 2010, The H.264 Advanced Video Compression Standard
   CHENG SL, 2020, SYMMETRY-BASEL, V12, DOI DOI 10.3390/SYM12030332
   Chung Y, 2015, SENSORS-BASEL, V15, P7953, DOI 10.3390/s150407953
   Ding X, 2016, DESIGN NEW SCAN ORDE
   Han QQ, 2020, INT J INTERNET PROTO, V13, P1, DOI 10.1504/IJIPT.2020.105046
   Iyer SC, 2016, INT C INV COMP TECHN
   Jiang Jianguo, 2010, J MULTIMEDIA, V5
   Kong JH, 2013, J ENG-NY, V2013, DOI 10.1155/2013/785126
   Lei T, 1997, P 4 ACM INT C MULT
   Li SJ, 2007, IEEE T CIRC SYST VID, V17, P214, DOI 10.1109/TCSVT.2006.888840
   Martina Podesser A U., 2002, 5th Nordic Signal Processing Symposium, V10, P4
   Massoudi A, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/179290
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Sbiaa F, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (CIT), P391, DOI 10.1109/CIT.2016.53
   Shahid Z, 2011, IEEE T CIRC SYST VID, V21, P565, DOI 10.1109/TCSVT.2011.2129090
   Song YJ, 2019, MULTIMED TOOLS APPL, V78, P18967, DOI 10.1007/s11042-019-7253-9
   Sze V., 2014, High Efficiency Video Coding (HEVC), P209
   Wang YS, 2013, IEEE T CIRC SYST VID, V23, P1476, DOI 10.1109/TCSVT.2013.2248588
   Xu DW, 2020, ETRI J, V42, P446, DOI 10.4218/etrij.2018-0484
   Zhang X., 2013, PROC 2 INT C SYST EN, P148
   Zhu S, 2011, IEEE T CIRCUITS SYST, V21
   Zou YZ, 2006, IEEE T CONSUM ELECTR, V52, P1289, DOI 10.1109/TCE.2006.273147
NR 25
TC 13
Z9 13
U1 3
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2319
EP 2338
DI 10.1007/s11042-020-09654-3
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569366500001
DA 2024-07-18
ER

PT J
AU Tahmasebi, F
   Meghdadi, M
   Ahmadian, S
   Valiallahi, K
AF Tahmasebi, Faryad
   Meghdadi, Majid
   Ahmadian, Sajad
   Valiallahi, Khashayar
TI A hybrid recommendation system based on profile expansion technique to
   alleviate cold start problem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender systems; Collaborative filtering; Cold start; Profile
   expansion; Demographic data
ID SIMILARITY; SPARSITY; TRUST; ALGORITHMS
AB Recommender systems are one of the information filtering tools which can be employed to find interest items of users. Collaborative filtering is one of the recommendation methods to provide suggestions for target users based on the ratings of like-interest users. This method suffers from some shortcomings such as cold start problem leading to reduce the performance of recommender system in predicting unseen items. In this paper, we propose a hybrid recommendation method based on profile expansion technique to alleviate cold start problem in recommender systems. For this purpose, we take into consideration user's demographic data (e.g. age, gender, and occupation) beside user's rating data in order to enrich the neighborhood set of users. Specifically, two different strategies are used to enrich the rating profile of users by adding some additional ratings to them. The proposed rating profile expansion mechanism has a significant effect on the performance improvement of recommender systems especially when they are facing with cold start problem. The reason behind this claim is that the proposed mechanism makes a denser user-item rating matrix than the original one by adding some additional ratings to it. Obviously, providing a rating profile with further ratings for the target user leads to alleviate cold start problem in recommender systems. The expanded rating profiles are used to calculate similarity values between users and predict unseen items. The results of experiments demonstrate that the proposed method can achieve better performance than the other recommendation methods in terms of accuracy and rate coverage measures.
C1 [Tahmasebi, Faryad; Meghdadi, Majid] Univ Zanjan, Dept Comp Engn, Zanjan, Iran.
   [Ahmadian, Sajad] Kermanshah Univ Technol, Fac Informat Technol, Kermanshah, Iran.
   [Valiallahi, Khashayar] Kurdistan Univ, Dept Comp Engn, Sanandaj, Iran.
C3 University Zanjan; Kermanshah University of Technology
RP Meghdadi, M (corresponding author), Univ Zanjan, Dept Comp Engn, Zanjan, Iran.
EM faryadtahmasebi1367@gmail.com; meghdadi@znu.ac.ir;
   s.ahmadian239@gmail.com; khashayar.valiallahi@gmail.com
RI Ahmadian, Sajad/ABE-4624-2021
OI Ahmadian, Sajad/0000-0002-3080-3192
CR Aghdam MH, 2016, J INF SCI
   Ahmadian S, 2020, KNOWL-BASED SYST, V192, DOI 10.1016/j.knosys.2019.105371
   Ahmadian S, 2019, J INF SCI, V45, P607, DOI 10.1177/0165551518808191
   Ahmadian S, 2019, MULTIMED TOOLS APPL, V78, P17763, DOI 10.1007/s11042-018-7079-x
   Ahmadian S, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P1139, DOI 10.1109/ASONAM.2018.8508723
   Ahmadian S, 2018, APPL INTELL, V48, P4448, DOI 10.1007/s10489-018-1219-x
   Ahmadian S, 2018, INFORM PROCESS MANAG, V54, P707, DOI 10.1016/j.ipm.2017.03.002
   Ahmadian S, 2014, 2014 6TH CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT), P98, DOI 10.1109/IKT.2014.7030341
   Ahn HJ, 2008, INFORM SCIENCES, V178, P37, DOI 10.1016/j.ins.2007.07.024
   Al-Shamri MYH, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL I, PROCEEDINGS, P519, DOI 10.1109/ICCIMA.2007.15
   Anand D, 2011, EXPERT SYST APPL, V38, P5101, DOI 10.1016/j.eswa.2010.09.141
   [Anonymous], 2011, INTRO RECOMMENDER SY
   Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012
   Breese J. S., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P43
   Candillier L, 2008, LECT NOTES ARTIF INT, V5077, P242, DOI 10.1007/978-3-540-70720-2_19
   Cheng ZY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P655, DOI 10.1145/3077136.3080772
   Corbellini A, 2015, J INF SCI, V41, P686, DOI 10.1177/0165551515588669
   Cui C., 2017, ACM Transactions on Intelligent Systems and Technology (TIST), V8, P1, DOI DOI 10.1145/3086635
   Formoso V, 2013, INFORM PROCESS MANAG, V49, P659, DOI 10.1016/j.ipm.2012.07.005
   Guo GB, 2014, KNOWL-BASED SYST, V57, P57, DOI 10.1016/j.knosys.2013.12.007
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Jalili M, 2018, IEEE ACCESS, V6, P74003, DOI 10.1109/ACCESS.2018.2883742
   Lai CH, 2015, J INF SCI, V41, P814, DOI 10.1177/0165551515603324
   Lika B, 2014, EXPERT SYST APPL, V41, P2065, DOI 10.1016/j.eswa.2013.09.005
   Liu Y., 2015, J INF SCI
   Luo X, 2012, KNOWL-BASED SYST, V27, P271, DOI 10.1016/j.knosys.2011.09.006
   Mazhari S, 2015, J INF SCI
   Moradi P, 2016, INT CONF ADV ICT, P162, DOI 10.1109/ICTER.2016.7829914
   Nguyen AT, 2007, RECSYS 07: PROCEEDINGS OF THE 2007 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P121
   Papagelis M, 2005, LECT NOTES COMPUT SC, V3477, P224
   Rahmani H. A., 2019, INFORM RETRIEVAL TEC, P66
   Rashid A. M., 2008, SIGKDD Explorations, V10, P90
   Resnick P., 1994, Transcending Boundaries, CSCW '94. Proceedings of the Conference on Computer Supported Cooperative Work, P175, DOI 10.1145/192844.192905
   Safoury Laila, 2013, Lecture Notes on Software Engineering, V1, P303, DOI 10.7763/LNSE.2013.V1.66
   Said A., 2011, USER MODELING ADAPTA, V7
   Son LH, 2016, INFORM SYST, V58, P87, DOI 10.1016/j.is.2014.10.001
   Sridevi MM, SURVEY RECOMMENDER S
   Zheng N, 2010, J INF SCI, V36, P733, DOI 10.1177/0165551510386164
   Ziegler CN, 2004, LECT NOTES COMPUT SC, V2995, P251
NR 39
TC 54
Z9 56
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2339
EP 2354
DI 10.1007/s11042-020-09768-8
EA SEP 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569366500002
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Zhang, S
   He, XZ
   Lu, J
   Gao, XP
AF Zhang, Yuan
   Zhang, Sai
   He, Xizhi
   Lu, Jing
   Gao, Xieping
TI DeepRibSt: a multi-feature convolutional neural network for predicting
   ribosome stalling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ribosome stalling; Prediction; Multi-feature; Deep learning;
   Convolutional neural networks
ID SYNONYMOUS MUTATIONS; TRANSLATION; RNA; PROTEIN; DYSREGULATION;
   SEQUENCE; DATABASE; REVEALS
AB Ribosomes are a kind of organelle in cells, which are mainly involved in the translation process of genetic materials, but the underlying mechanisms associated with ribosome stalling are not fully understood. Thanks to the development of biological experimental techniques, many ribosome footprintings are generated, which can help us to study ribosome stalling. Effectively obtaining a precise ribosome stalling site will be helpful for the treatment of the related diseases, however there is still much room for the improvement of ribosome stalling prediction. In this study, we propose a new deep neural network model named DeepRibSt for the prediction of ribosome stalling sites. We first process the ribosome footprinting data to the training set. Then three new features, including evolutionary conservation, hydrophobicity, and amino dissociation constant, along with the previous sequence features, are extracted as input to the network. To improve the performance of the algorithm in ribosome stalling prediction, we use two convolutional layers and three fully connected layers to design a new network architecture. To verify the validity of our proposed DeepRibSt, we compare DeepRibSt with four popular deep neural networks, i.e., AlexNet, LeNet, ResNet, and LSTM on human (i.e., Battle2015 and Stumpf13) and yeast (i.e., Pop2014, Young15, and Brar12) data. To further demonstrate the effectiveness of DeepRibS, we compare DeepRibSt with the state-of-the-art method. The experimental results show that DeepRibSt outperforms all other methods and achieves the state-of-the-art performance in accuracy, recall, specificity, F1-score, and the area under the receiver operating characteristic curve (AUC).
C1 [Zhang, Yuan] Xiangtan Univ, Sch Math & Computat Sci, Xiangtan 411105, Peoples R China.
   [Zhang, Yuan; He, Xizhi; Lu, Jing; Gao, Xieping] Xiangtan Univ, Minist Educ, Key Lab Intelligent Comp & Informat Proc, Xiangtan 411105, Peoples R China.
   [Zhang, Sai] Stanford Univ, Sch Med, Dept Genet, Stanford, CA 94305 USA.
   [Gao, Xieping] Xiangnan Univ, Coll Med Imaging & Inspect, Chenzhou 423000, Peoples R China.
C3 Xiangtan University; Xiangtan University; Stanford University; Xiangnan
   University
RP Gao, XP (corresponding author), Xiangtan Univ, Minist Educ, Key Lab Intelligent Comp & Informat Proc, Xiangtan 411105, Peoples R China.; Gao, XP (corresponding author), Xiangnan Univ, Coll Med Imaging & Inspect, Chenzhou 423000, Peoples R China.
EM xpgao@xtu.edu.cn
RI Zhang, Sai/ITD-0560-2023
OI Zhang, Sai/0000-0001-5996-6086
FU National Natural Science Foundation of China [61972333, 61802328,
   61771415]; Natural Science Foundation of Hunan Province in China
   [2019JJ50606]; Research Foundation of Education Department of Hunan
   Province of China [19B561]; Baidu Pinecone Program
FX The authors are grateful to Prof. Jianyang Zeng and Dr. Hailin Hu for
   their help with the ideas and code of this work. The authors would like
   to thank Dr. Dapeng Xiong for the helpful discussions about this work.
   The authors would also like to thank the anonymous reviewers for their
   insightful comments, which greatly helped to improve the quality of this
   paper. This work was supported in part by the National Natural Science
   Foundation of China under Grants 61972333, 61802328 and 61771415, in
   part by the Natural Science Foundation of Hunan Province in China under
   Grant 2019JJ50606, in part by the Research Foundation of Education
   Department of Hunan Province of China under Grant 19B561, and in part by
   the Baidu Pinecone Program.
CR Alipanahi B, 2015, NAT BIOTECHNOL, V33, P831, DOI 10.1038/nbt.3300
   Ashkenazy H, 2010, NUCLEIC ACIDS RES, V38, pW529, DOI 10.1093/nar/gkq399
   Battle A, 2015, SCIENCE, V347, P664, DOI 10.1126/science.1260793
   Bazzini AA, 2012, SCIENCE, V336, P233, DOI 10.1126/science.1215704
   Bischoff L, 2014, CELL REP, V9, P469, DOI 10.1016/j.celrep.2014.09.011
   Bjornsti MA, 2004, CANCER CELL, V5, P519, DOI 10.1016/j.ccr.2004.05.027
   Borreca A, 2016, MOL NEUROBIOL, V53, P3227, DOI 10.1007/s12035-015-9229-8
   Bottou L, 1997, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.1997.609370
   Brar GA, 2015, NAT REV MOL CELL BIO, V16, P651, DOI 10.1038/nrm4069
   Brar GA, 2012, SCIENCE, V335, P552, DOI 10.1126/science.1215110
   BRODIE BB, 1960, J PHARMACOL EXP THER, V130, P20
   Chakraborty R, 2020, IEEE ACM T COMPUT BI, V17, P2183, DOI 10.1109/TCBB.2019.2936186
   Chaney JL, 2015, ANNU REV BIOPHYS, V44, P143, DOI 10.1146/annurev-biophys-060414-034333
   Collobert R, 2008, P 25 ICML, P160, DOI 10.1145/1390156.1390177
   Fang SH, 2019, J VOICE, V33, P634, DOI 10.1016/j.jvoice.2018.02.003
   Han YH, 2015, IEEE T NEUR NET LEAR, V26, P252, DOI 10.1109/TNNLS.2014.2314123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu K, 2019, NEUROCOMPUTING, V365, P302, DOI 10.1016/j.neucom.2019.07.079
   Huang Zhiheng., 2015, Bidirectional LSTM-CRF models for sequence tagging
   Hubbard T, 2002, NUCLEIC ACIDS RES, V30, P38, DOI 10.1093/nar/30.1.38
   Ingolia NT, 2016, CELL, V165, P22, DOI 10.1016/j.cell.2016.02.066
   Ingolia NT, 2011, CELL, V147, P789, DOI 10.1016/j.cell.2011.10.002
   Ingolia NT, 2009, SCIENCE, V324, P218, DOI 10.1126/science.1168978
   Johnsson P, 2014, BBA-GEN SUBJECTS, V1840, P1063, DOI 10.1016/j.bbagen.2013.10.035
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lucent D, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000963
   Michel AM, 2014, NUCLEIC ACIDS RES, V42, pD859, DOI 10.1093/nar/gkt1035
   Michel AM, 2012, GENOME RES, V22, P2219, DOI 10.1101/gr.133249.111
   Molchanov P, 2017, ARXIV161106440V2
   Pan XY, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1561-8
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pla A, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1006185
   Pollard KS, 2010, GENOME RES, V20, P110, DOI 10.1101/gr.097857.109
   Pop C, 2014, MOL SYST BIOL, V10, DOI 10.15252/msb.20145524
   Quax TEF, 2015, MOL CELL, V59, P149, DOI 10.1016/j.molcel.2015.05.035
   Sauna ZE, 2011, NAT REV GENET, V12, P683, DOI 10.1038/nrg3051
   Siepel A, 2005, GENOME RES, V15, P1034, DOI 10.1101/gr.3715005
   Stumpf CR, 2013, MOL CELL, V52, P574, DOI 10.1016/j.molcel.2013.09.018
   Tanner DR, 2009, J BIOL CHEM, V284, P34809, DOI 10.1074/jbc.M109.039040
   Tsai CJ, 2008, J MOL BIOL, V383, P281, DOI 10.1016/j.jmb.2008.08.012
   Vazquez-Laslop N, 2008, MOL CELL, V30, P190, DOI 10.1016/j.molcel.2008.02.026
   Vázquez-Laslop N, 2011, P NATL ACAD SCI USA, V108, P10496, DOI 10.1073/pnas.1103474108
   Wang ET, 2016, J NEUROSCI, V36, P11418, DOI 10.1523/JNEUROSCI.2352-16.2016
   Wen M, 2018, BIOINFORMATICS, V34, P3781, DOI 10.1093/bioinformatics/bty424
   Wimley WC, 1996, NAT STRUCT BIOL, V3, P842, DOI 10.1038/nsb1096-842
   Xie SQ, 2016, NUCLEIC ACIDS RES, V44, pD254, DOI 10.1093/nar/gkv972
   Xuan P, 2018, INT J MOL SCI, V19, DOI 10.3390/ijms19123732
   Young DJ, 2015, CELL, V162, P872, DOI 10.1016/j.cell.2015.07.041
   Zeng HY, 2016, BIOINFORMATICS, V32, P121, DOI 10.1093/bioinformatics/btw255
   Zhang S., 2018, ROSE: a deep learning based framework for predicting ribosome stalling, DOI 10.2139/ssrn.3155721
   Zhang S, 2016, NUCLEIC ACIDS RES, V44, DOI 10.1093/nar/gkv1025
   Zhou JY, 2016, IEEE INT C BIOINFORM, P78, DOI 10.1109/BIBM.2016.7822496
   Zhou ZH, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-9801-4
NR 54
TC 1
Z9 1
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17239
EP 17255
DI 10.1007/s11042-020-09598-8
EA SEP 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000568184100013
DA 2024-07-18
ER

PT J
AU Bains, JK
   Singh, S
   Sharma, A
AF Bains, Jasleen Kaur
   Singh, Sukhdeep
   Sharma, Anuj
TI Dynamic features based stroke recognition system for signboard images of
   Gurmukhi text
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Drawing order; Gurmukhi signboard; Chain codes; Trajectory point;
   Offline text recognition; Deep learning
ID CHINESE CHARACTERS; WORD RECOGNITION; HANDWRITTEN; FRAMEWORK; DRIVEN;
   ORDER
AB The computation of correct features is an essential phase for efficient data representation and benchmarked accuracy in text recognition systems. The offline text lacks dynamic information regarding the writing order or nature of trajectories of stroke. Recovery of drawing order technique helps to retrieve trajectory of a stroke. This information aids in computing dynamic feature vector based on chain codes or trajectory points for text recognition. The present work proposes a dynamic feature extraction approach based on recovery of drawing order to understand scene text in Indic script Gurmukhi. An inhouse dataset of strokes was obtained from 820 real time Gurmukhi signboard images. Stroke recognition was performed using Conv1D, SVM and HMM classifiers. Best recognition results were achieved using SVM and Conv1D as 82.88% and 84.67%. The major objective of present study is to propose dynamic features based recognition scheme for Indic scripts signboard images suitable for real-life applications.
C1 [Bains, Jasleen Kaur; Sharma, Anuj] Panjab Univ, Dept Comp Sci & Applicat, Chandigarh, India.
   [Singh, Sukhdeep] DM Coll, Moga, Punjab, India.
C3 Panjab University
RP Bains, JK (corresponding author), Panjab Univ, Dept Comp Sci & Applicat, Chandigarh, India.
EM jasleen@pu.ac.in; sukha13@ymail.com; anujs@pu.ac.in
OI Bains, Jasleen Kaur/0000-0003-4957-9108
CR [Anonymous], 2009, THESIS
   Bharath A, 2012, IEEE T PATTERN ANAL, V34, P670, DOI 10.1109/TPAMI.2011.234
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Fraz M, 2015, INT J DOC ANAL RECOG, V18, P153, DOI 10.1007/s10032-015-0239-x
   Gan J, 2019, INFORM SCIENCES, V478, P375, DOI 10.1016/j.ins.2018.11.035
   Ghosh R, 2015, ICDAR 2015 P 13 INT, DOI [10.1109/ICDAR.2015.7333792, DOI 10.1109/ICDAR.2015.7333792]
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Kasar T, 2011, MOCR AND 2011 P 2011, P14, DOI [10.1145/2034617.2034633, DOI 10.1145/2034617.2034633]
   Kato M, 1999, ICDAR 1999 P 5 INT C, DOI [10.1109/ICDAR.1999.791774, DOI 10.1109/ICDAR.1999.791774]
   Kato Y, 2000, IEEE T PATTERN ANAL, V22, P938, DOI 10.1109/34.877517
   Keysers D, 2017, IEEE T PATTERN ANAL, V39, P1180, DOI 10.1109/TPAMI.2016.2572693
   Kompalli S, 2009, INT J DOC ANAL RECOG, V12, P123, DOI 10.1007/s10032-009-0086-8
   Li Z, 2018, INT CONF FRONT HAND, P205, DOI 10.1109/ICFHR-2018.2018.00044
   Lu SJ, 2015, INT J DOC ANAL RECOG, V18, P125, DOI 10.1007/s10032-015-0237-z
   Dinh M, 2016, EXPERT SYST APPL, V64, P352, DOI 10.1016/j.eswa.2016.08.017
   Namboodiri AM, 2004, IEEE T PATTERN ANAL, V26, P124, DOI 10.1109/TPAMI.2004.1261096
   Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60
   Pal U, 2003, ICDAR 2003 P 7 INT C, DOI [10.1109/ICDAR.2009.36, DOI 10.1109/ICDAR.2009.36]
   Park J, 2010, PATTERN RECOGN LETT, V31, P1728, DOI 10.1016/j.patrec.2010.05.024
   Qiao Y, 2004, IWFHR 9 2004 P 9 INT, DOI [10.1109/IWFHR.2004.87, DOI 10.1109/IWFHR.2004.87]
   Qiao Y, 2005, ICDAR 2005 8 INT C D, DOI [10.1109/ICDAR.2005.25, DOI 10.1109/ICDAR.2005.25]
   Qiao Y, 2006, ICPR 2006 18 INT C P, DOI [10.1109/ICPR.2006.984, DOI 10.1109/ICPR.2006.984]
   Qiao Y, 2006, IEEE T PATTERN ANAL, V28, P1724, DOI 10.1109/TPAMI.2006.216
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rousseau L, 2005, ICDAR 2005 8 INT C D, DOI [10.1109/ICDAR.2005.199, DOI 10.1109/ICDAR.2005.199]
   Roy PP, 2016, PATTERN RECOGN, V60, P1057, DOI 10.1016/j.patcog.2016.04.012
   Sharma A., 2015, VIETNAM J COMPUT SCI, V2, P133, DOI DOI 10.1007/s40595-014-0038-1
   Sharma A, 2013, ICIIP 2013 P 2013 IE, DOI [10.1109/ICIIP.2013.6707630, DOI 10.1109/ICIIP.2013.6707630]
   SharmaA, 2009, 10 INT C DOC AN REC, P1241, DOI DOI 10.1109/ICDAR.2009.36
   Singh S, 2019, ACM T ASIAN LOW-RESO, V18, DOI 10.1145/3282441
   Singh S, 2017, INT J DOC ANAL RECOG, V20, P37, DOI 10.1007/s10032-016-0279-x
   Singh S, 2016, ACM T ASIAN LOW-RESO, V16, DOI 10.1145/2896318
   Tian SX, 2016, PATTERN RECOGN, V51, P125, DOI 10.1016/j.patcog.2015.07.009
   Yamaguchi T, 2003, PROC INT CONF DOC, P359
   Zhang XY, 2018, IEEE T PATTERN ANAL, V40, P849, DOI 10.1109/TPAMI.2017.2695539
NR 36
TC 3
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 665
EP 689
DI 10.1007/s11042-020-09653-4
EA SEP 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566043200002
DA 2024-07-18
ER

PT J
AU Khan, MA
   Akram, T
   Sharif, M
   Saba, T
AF Khan, Muhammad Attique
   Akram, Tallha
   Sharif, Muhammad
   Saba, Tanzila
TI Fruits diseases classification: exploiting a hierarchical framework for
   deep features fusion and selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; Disease segmentation; Deep features; Features
   selection; Image classification; Feature fusion
ID NEURAL-NETWORKS; SEGMENTATION; IDENTIFICATION; AGRICULTURE; RECOGNITION;
   CHALLENGES; TEXTURE
AB In agriculture farming business, plant diseases are one of the reasons for the financial deficits around the globe. It is the fundamental factor, as it causes significant abatement in both capacity and quality of the growing crops. In plants, fruits are amongst the major sources of nutrients, however, there exists a wide range of diseases which adversely affect both quality and production of the fruits. To overcome such predicament, computer vision (CV) based methods are introduced. These methods are quite effective, which not only detect the diseases/infections at the early stages but also assign them a label. In this article, we propose a deep convolutional neural network-based method for the diseases classification of different fruits' leaves. Initially, the deep features are extracted by utilizing pre-trained deep models including VGG-s and AlexNet, which are later fine-tuned by employing a concept of transfer learning. A multi-level fusion methodology is also proposed, prior to the selection step, based on an entropy-controlled threshold value - calculated by averaging the selected features. The resultant final feature vector is later fed into a host classifier, multi-SVM. Five different diseases are considered for experiments including apple black rot, apple scab, apple rust, cherry powdery mildew, and peach bacterial spots, which are collected from a plant village dataset. Classification results clearly reveal the improved performance of proposed method in terms of sensitivity (97.6%), accuracy (97.8%), precision (97.6%), and G-measure (97.6%).
C1 [Khan, Muhammad Attique] HITEC Univ, Dept Comp Sci, Museum Rd, Taxila, Pakistan.
   [Akram, Tallha] COMSATS Univ Islamabad, Dept EE, Wah Cantt, Pakistan.
   [Sharif, Muhammad] COMSATS Univ Islamabad, Dept Comp Sci, Wah Cantt, Pakistan.
   [Saba, Tanzila] Prince Sultan Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
C3 NITEC University; COMSATS University Islamabad (CUI); COMSATS University
   Islamabad (CUI); Prince Sultan University
RP Khan, MA (corresponding author), HITEC Univ, Dept Comp Sci, Museum Rd, Taxila, Pakistan.
EM attique.khan440@gmail.com; tallha@ciitwah.edu.pk;
   muhammadsharifmalik@yahoo.com; tsaba@psu.edu.pk
RI khan, sajid/HGE-2406-2022; Sharif, Muhammad/AAB-8376-2022; Sharif,
   Muhammad/ACD-2598-2022; Saba, Tanzila/D-4593-2018; Akram,
   Tallha/KPB-3017-2024; Khan, Dr. Muhammad Attique/AAX-2644-2021
OI Sharif, Muhammad/0000-0002-7258-8400; Saba, Tanzila/0000-0003-3138-3801;
   Akram, Tallha/0000-0003-4578-3849; Khan, Dr. Muhammad
   Attique/0000-0002-6347-4890
CR Abdel-Hamid O, 2012, INT CONF ACOUST SPEE, P4277, DOI 10.1109/ICASSP.2012.6288864
   Adeel A, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12569
   Ai DN, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0231-0
   Amara J., 2017, Lecture Notes in Informatics (LNI), Gesellschaft fur Informatik, P79
   Barbedo JGA, 2016, BIOSYST ENG, V144, P52, DOI 10.1016/j.biosystemseng.2016.01.017
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Brahimi M, 2017, APPL ARTIF INTELL, V31, P299, DOI 10.1080/08839514.2017.1315516
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Camargo A, 2009, J ARTIFICIAL INTELLI, V66, P121
   Chaib S, 2017, IEEE T GEOSCI REMOTE, V55, P4775, DOI 10.1109/TGRS.2017.2700322
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen Lin, 2017, [Computational Visual Media, 计算可视媒体], V3, P83
   Chen XZ, 2018, IEEE T PATTERN ANAL, V40, P1259, DOI 10.1109/TPAMI.2017.2706685
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Duan YP, 2017, PATTERN RECOGN, V64, P255, DOI 10.1016/j.patcog.2016.11.015
   Dubey SR, 2016, SIGNAL IMAGE VIDEO P, V10, P819, DOI 10.1007/s11760-015-0821-1
   Dubey SR, 2012, 2012 THIRD INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT), P346, DOI 10.1109/ICCCT.2012.76
   El Faouzi NE, 2011, INFORM FUSION, V12, P4, DOI 10.1016/j.inffus.2010.06.001
   Elangovan K., 2017, INT J COMPUTATIONAL, V13, P1821
   Espinosa Jorge E., 2017, Advances in Visual Informatics. 5th International Visual Informatics Conference, IVIC 2017. Proceedings: LNCS 10645, P3, DOI 10.1007/978-3-319-70010-6_1
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fernando B, 2014, INT J COMPUT VISION, V108, P186, DOI 10.1007/s11263-014-0700-1
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Fuentes A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092022
   Gunes H, 2005, IEEE SYS MAN CYBERN, P3437
   Hautamäki V, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P408
   Hedayatnia B, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P2655, DOI 10.1109/BigData.2016.7840908
   Huai L, 2015, INT CONF ASIC
   Hughes D., 2015, ABS151108060 CORR
   Iqbal Z, 2018, COMPUT ELECTRON AGR, V153, P12, DOI 10.1016/j.compag.2018.07.032
   Jeong JH, 2019, MULTIMED TOOLS APPL, P1
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Khan MA, 2017, IMAGE PROCESSING
   Khan MA, 2019, PATTERN ANAL APPL, V22, P1377, DOI 10.1007/s10044-018-0688-1
   Khan MA, 2019, IEEE ACCESS, V7, P46261, DOI 10.1109/ACCESS.2019.2908040
   Khan MA, 2018, COMPUT ELECTRON AGR, V155, P220, DOI 10.1016/j.compag.2018.10.013
   Khan MR, 2020, MYCOLOGIA, V112, P871, DOI 10.1080/00275514.2020.1792263
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar K. S., 2017, CLUSTER COMPUT, P1
   Lad H, 2017, ADV INTELL SYST, V508, P344, DOI 10.1007/978-981-10-2750-5_36
   Li D, 2017, P 2017 INT C ART INT, P29
   Liu B., 2017, ACCOUNTING RES, V10, P11, DOI DOI 10.3390/sym10010011
   Liu B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010011
   Liu Y, 2005, IEEE IJCNN, P849
   Luus FPS, 2015, IEEE GEOSCI REMOTE S, V12, P2448, DOI 10.1109/LGRS.2015.2483680
   Mangai UG, 2010, IETE TECH REV, V27, P293, DOI 10.4103/0256-4602.64604
   Mohanty S. P., 2016, Frontiers in Plant Science, V7, P1419
   Neto A, 2013, 2013 INTERNATIONAL WORKSHOP ON ANTENNA TECHNOLOGY (IWAT), P12, DOI 10.1109/IWAT.2013.6518287
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Parkhi OM, 2015, Proceedings of the British Machine Vision Conference, DOI DOI 10.5244/C.29.41
   Piao Y, EXPLOIT REPLACE ASYM
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salerno VM, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7100235
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sharif M, 2020, PATTERN RECOGN LETT, V139, P50, DOI 10.1016/j.patrec.2018.01.021
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh C, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-35
   Singh M, 2014, INFORM FUSION, V19, P91, DOI 10.1016/j.inffus.2013.05.007
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Strange RN, 2005, ANN REV PHYTOPATHOLO, V43
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tang PJ, 2017, COMPUT ELECTR ENG, V62, P499, DOI 10.1016/j.compeleceng.2017.01.011
   Tri N. C., 2016, INT C ADV INF COMM T, P84
   Van Doorn J., 2014, ANAL DEEP CONVOLUTIO, P9
   Wahba MA, 2017, HEALTH INF SCI SYST, V5, DOI 10.1007/s13755-017-0033-x
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Xie DF, 2017, APPL COMPUT INTELL S, V2017, DOI 10.1155/2017/1320780
   Xu G, 2017, ENVIRON MODELL SOFTW, V91, P127, DOI 10.1016/j.envsoft.2017.02.004
   Xu J, 2017, IEEE T NEUR NET LEAR, V28, P1974, DOI 10.1109/TNNLS.2016.2562670
   Yang J, 2003, PATTERN RECOGN, V36, P1369, DOI 10.1016/S0031-3203(02)00262-5
   Yosinski J., 2014, Adv Neural Inf Process Syst, V2, P3320, DOI DOI 10.48550/ARXIV.1411.1792
   Zhang AS, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122416
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhong Y, 2020, COMPUT ELECTRON AGR, V168, DOI 10.1016/j.compag.2019.105146
   Zhou WX, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050489
NR 77
TC 47
Z9 48
U1 1
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25763
EP 25783
DI 10.1007/s11042-020-09244-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000565043500024
DA 2024-07-18
ER

PT J
AU Peng, B
   Al-Huda, Z
   Xie, ZY
   Wu, X
AF Peng, Bo
   Al-Huda, Zaid
   Xie, Zhuyang
   Wu, Xi
TI Multi-scale region composition of hierarchical image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hierarchical image segmentation; Segmentation evaluation; Graphical
   model; Scale selection
ID NORMALIZED CUTS; APPEARANCE; DRIVEN
AB Hierarchical image segmentation is a prominent trend in the literature as a way to improve the segmentation quality. Generally, meaningful objects in an image are described by segments from different scales. Thus, one may spend extra effort on searching for the best representation of objects in the hierarchical segmentation result. In this paper, a novel algorithm is proposed to optimally select the segmentation scale, which leads to a composite segmentation as the output. To this end, the quality of regions from different scales of the hierarchical segmentation is evaluated. Then, a graphical model is constructed as a set of nodes. The weights among nodes are computed according to the segmentation quality of regions in multiple levels. In order to optimize the labeling of each node in the graph, the composition process is performed twice with two sampling intervals. Comprehensive experiments are conducted on different datasets for popular hierarchical image segmentation algorithms. The results show that the output of the proposed algorithm can improve the quality of hierarchical segmentation in a single scale at a low cost of computation.
C1 [Peng, Bo; Al-Huda, Zaid; Xie, Zhuyang] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 611756, Peoples R China.
   [Peng, Bo; Al-Huda, Zaid; Xie, Zhuyang] Natl Engn Lab Integrated Transportat Big Data App, Chengdu, Peoples R China.
   [Wu, Xi] Chengdu Univ Informat Technol, Sch Comp Sci, Chengdu 610225, Peoples R China.
C3 Southwest Jiaotong University; Chengdu University of Information
   Technology
RP Peng, B (corresponding author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 611756, Peoples R China.; Peng, B (corresponding author), Natl Engn Lab Integrated Transportat Big Data App, Chengdu, Peoples R China.
EM bpeng@swjtu.edu.cn
RI Al-Huda, Zaid/ABG-3639-2021
OI Al-Huda, Zaid/0000-0002-8920-7635
FU National Natural Science Foundation of China [61772435]; Sichuan Highway
   Science and Technology Project [2019-01]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61772435, Sichuan Highway Science and Technology
   Project under Grant 2019-01.
CR Ahmed M, 2019, 2019 IEEE 14 INT C I, P1081
   Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   [Anonymous], 2019, ICCV, DOI DOI 10.1109/ICCV.2019.01037
   [Anonymous], BMVC
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bertasius G, 2015, PROC CVPR IEEE, P4380, DOI 10.1109/CVPR.2015.7299067
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Cai Q, 2018, PATTERN RECOGN, V82, P79, DOI 10.1016/j.patcog.2018.05.008
   Calderero F, 2010, IEEE T IMAGE PROCESS, V19, P1567, DOI 10.1109/TIP.2010.2043008
   Chen YH, 2016, PROC CVPR IEEE, P364, DOI 10.1109/CVPR.2016.46
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   Diwakar M, 2018, IET IMAGE PROCESS, V12, P708, DOI 10.1049/iet-ipr.2017.0639
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Franek L, 2010, P AS C COMP VIS, P373
   Golodetz S, 2017, PATTERN RECOGN, V70, P44, DOI 10.1016/j.patcog.2017.04.007
   Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211
   He JJ, 2019, PROC CVPR IEEE, P7511, DOI 10.1109/CVPR.2019.00770
   Huang Q, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC53
   Isola P, 2014, LECT NOTES COMPUT SC, V8691, P799, DOI 10.1007/978-3-319-10578-9_52
   Khoreva A, 2017, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2017.181
   Kim TH, 2013, IEEE T PATTERN ANAL, V35, P1690, DOI 10.1109/TPAMI.2012.237
   Kumar Manoj, 2018, Journal of King Saud University - Computer and Information Sciences, V30, P41, DOI 10.1016/j.jksuci.2016.03.003
   Kumar M, 2016, J KING SAUD UNIV-COM
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Li H, 2013, IEEE INT CON MULTI
   Li KQ, 2018, PATTERN RECOGN, V76, P69, DOI 10.1016/j.patcog.2017.10.023
   Li YF, 2016, PATTERN RECOGN, V52, P332, DOI 10.1016/j.patcog.2015.10.004
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Malisiewicz T., 2007, Proceedings of the British Machine Vision Conference 2007, DOI DOI 10.5244/C.21.55
   Maninis KK, 2016, LECT NOTES COMPUT SC, V9905, P580, DOI 10.1007/978-3-319-46448-0_35
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Martin D., 2002, THESIS
   Meila M., 2005, P 22 INT C MACH LEAR, P577, DOI DOI 10.1145/1102351.1102424
   Min XK, 2019, IEEE T MULTIMEDIA, V21, P2319, DOI 10.1109/TMM.2019.2902097
   Pagnutti G, 2018, IMAGE VISION COMPUT, V70, P21, DOI 10.1016/j.imavis.2017.12.004
   Pont-Tuset J, 2010, EUR C COMP VIS, P814
   Pont-Tuset J, 2017, IEEE T PATTERN ANAL, V39, P128, DOI 10.1109/TPAMI.2016.2537320
   Ren ZL, 2013, PROC CVPR IEEE, P2011, DOI 10.1109/CVPR.2013.262
   Russell B.C., 2006, Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, V2, P1605, DOI DOI 10.1109/CVPR.2006.326
   Salembier P, 2014, IEEE T IMAGE PROCESS, V71, P561
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shen W, 2015, PROC CVPR IEEE, P3982, DOI 10.1109/CVPR.2015.7299024
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shimoda W, 2020, COMPUT VIS IMAGE UND, V191, DOI 10.1016/j.cviu.2018.08.006
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Syu JH, 2017, IEEE T IMAGE PROCESS, V26, P2246, DOI 10.1109/TIP.2017.2651395
   Unnikrishnan R, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P394
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Wang HJ, 2014, KNOWL-BASED SYST, V71, P162, DOI 10.1016/j.knosys.2014.07.021
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xu CL, 2013, IEEE I CONF COMP VIS, P2240, DOI 10.1109/ICCV.2013.279
   Yin SB, 2017, PATTERN RECOGN, V68, P245, DOI 10.1016/j.patcog.2017.03.012
   Yu ZD, 2017, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2017.191
NR 59
TC 20
Z9 20
U1 4
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32833
EP 32855
DI 10.1007/s11042-020-09346-y
EA AUG 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000563739900012
DA 2024-07-18
ER

PT J
AU Li, J
   Wang, YR
   Fang, GK
   Zeng, ZG
AF Li, Jun
   Wang, Yaoru
   Fang, Guokang
   Zeng, Zhigao
TI Real-time detection tracking and recognition algorithm based on
   multi-target faces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low real-time; Fast detection; Fast tracking; Fast recognition;
   Multi-target face
AB At present, face recognition algorithms are facing some problems with poor face tracking and low real-time performance in multi-target recognition scenarios. This paper details a multi-target face real-time detection tracking and recognition algorithm, including three methods of fast-tracking, fast detection, and quick recognition. The first step offers a new network based on GOTURN for achieving fast face tracking. The prior information of the previous frame image used to predict the position of the face boxes at the current frame. The second step is based on MTCNN for face detection, using the prior information of the present structure to avoid generating massive of invalid candidate boxes, thereby achieving rapid detection of faces. Finally, fast face recognition realized by reduced MobileFaceNet. By avoiding repeated exposure and repeated identification of the same target, the algorithm successfully transforms a multi-target scene into a single-target scene. On the OTB2015 and 300_VW test sets, the evaluation trackers tracked faces with an accuracy rate of 92.2% and 99.6% respectively. On the Xiph test set, multi-target detection and tracking face speed reached 102fps on the CPU. Compared with the original MobileFaceNet, the streamlined network has an accuracy rate of 99.1% on LFW, the feature extraction speed increased by 25%, and the model size reduced by 45%. Experimental results show that the algorithm has high recognition accuracy and real-time performance in multi-target recognition scenes.
C1 [Li, Jun; Wang, Yaoru; Fang, Guokang] Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430065, Hubei, Peoples R China.
   [Li, Jun; Wang, Yaoru; Fang, Guokang] Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan 430065, Hubei, Peoples R China.
   [Zeng, Zhigao] Hunan Univ Technol, Sch Comp Sci, Zhuzhou 412000, Hunan, Peoples R China.
C3 Wuhan University of Science & Technology; Hunan University of Technology
RP Li, J (corresponding author), Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430065, Hubei, Peoples R China.; Li, J (corresponding author), Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan 430065, Hubei, Peoples R China.
EM lijun@wust.edu.cn
FU Hubei Province Key Laboratory of Intelligent Information Processing and
   Real-time Industrial System [znxx2018QN06]; Major Project for New
   Generation of AI [2018AAA0100400]; National Natural Science Foundation
   of Hunan [2018JJ2098]
FX This research is supported by a fund from Hubei Province Key Laboratory
   of Intelligent Information Processing and Real-time Industrial System
   (Grant No. znxx2018QN06), Major Project for New Generation of AI (Grant
   No. 2018AAA0100400) and the National Natural Science Foundation of Hunan
   (Grant No.2018JJ2098).
CR Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Chen S, 2018, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-97909-0_46
   Chollet F., 2017, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2017.195
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Deng J., 2018, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2019.00482
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Fang Guokang, 2019, Journal of Computer Applications, V39, P2217, DOI 10.11772/j.issn.1001-9081.2019010164
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Kwon J, 2011, IEEE I CONF COMP VIS, P1195, DOI 10.1109/ICCV.2011.6126369
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713
   Nam H, 2016, IEEE INFOCOM SER
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Sandler M, 2019, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2018.00474
   Stalder S, 2009, COMP VIS WORKSH ICCV
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang S, 2016, 2016 IEEE C COMPUTER, V2, P3
   Zhang X., 2017, P 2 INT C COMPUTER S, DOI DOI 10.1145/3207677.3277958
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 28
TC 7
Z9 7
U1 5
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17223
EP 17238
DI 10.1007/s11042-020-09601-2
EA AUG 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000560645900008
DA 2024-07-18
ER

PT J
AU Li, RX
   Li, H
   Shi, WB
AF Li, Ruixiang
   Li, Hui
   Shi, Weibin
TI Human activity recognition based on LPA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Linear prediction coefficient; Human activity recognition; Fall
   detection; Feature extraction
ID FEATURES; SENSORS; TIME
AB Human activity recognition and fall detection have been popular research topics because of its wide area of application. Traditional activity recognition methods have complex feature extraction steps. We propose a new feature extraction method based on linear prediction analysis(LPA) to reduce computational complexity involved with engineering features. The feature extraction method we propose establishes a link between human activity and the signal system and regards acceleration signals as the output of the human activity. Using the relationship between the human activity and the output signal, linear predictive analysis can isolate information about human activity and transform it into a compact representation through linear prediction coefficients (LPC). In order to verify the effectiveness of the method, we design an activity recognition system based on linear prediction analysis and feature extraction. At the same time, we study the performance of the combination of linear prediction coefficients and time domain features. We use data from the public dataset SCUT-NAA, which contains ten different activities, and another public dataset, which records people falling. A random forest classification algorithm based on ensemble learning is used for activity recognition and fall detection. The results show that the combined vector of linear prediction coefficient and time domain activity amplitude feature obtained a 93% accuracy rate and the system evaluation index F1 of 0.92 on the SCUT-NAA dataset. Additionally, we achieved an accuracy rate of 97% in fall detection.
C1 [Li, Ruixiang; Li, Hui; Shi, Weibin] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
C3 University of Shanghai for Science & Technology
RP Li, RX (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
EM lrx@usst.eud.cn
OI Li, Ruixiang/0000-0003-1667-1493
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   [Anonymous], 2018, WILEY INTERDISCIPLIN, DOI DOI 10.1002/WIDM.1254
   Ashqar HI, 2019, IEEE T INTELL TRANSP, V20, P244, DOI 10.1109/TITS.2018.2817658
   Attal F, 2015, SENSORS-BASEL, V15, P31314, DOI 10.3390/s151229858
   Chelli A, 2019, IEEE ACCESS, V7, P38670, DOI 10.1109/ACCESS.2019.2906693
   Ermes M, 2008, IEEE T INF TECHNOL B, V12, P20, DOI 10.1109/TITB.2007.899496
   Gao L, 2014, MED ENG PHYS, V36, P779, DOI 10.1016/j.medengphy.2014.02.012
   Guo M, 2019, IEEE T HUM-MACH SYST, V49, P105, DOI 10.1109/THMS.2018.2884717
   Hassan MM, 2018, FUTURE GENER COMP SY, V81, P307, DOI 10.1016/j.future.2017.11.029
   Hsu YL, 2018, IEEE ACCESS, V6, P31715, DOI 10.1109/ACCESS.2018.2839766
   Ignatov A, 2018, APPL SOFT COMPUT, V62, P915, DOI 10.1016/j.asoc.2017.09.027
   Jansi R, 2019, MULTIMED TOOLS APPL, V78, P11027, DOI 10.1007/s11042-018-6662-5
   Kim YM, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8081280
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Morales J, 2017, BIOCYBERN BIOMED ENG, V37, P388, DOI 10.1016/j.bbe.2017.04.004
   Nazábal A, 2016, IEEE J BIOMED HEALTH, V20, DOI 10.1109/JBHI.2015.2458274
   Ojetola O, 2015, DATA SET FALL EVENTS, DOI [10.1145/2713168.2713198, DOI 10.1145/2713168.2713198]
   Pärkkä J, 2006, IEEE T INF TECHNOL B, V10, P119, DOI 10.1109/TITB.2005.856863
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Preece SJ, 2009, IEEE T BIO-MED ENG, V56, P871, DOI 10.1109/TBME.2008.2006190
   Roh J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010208
   San-Segundo R, 2018, ENG APPL ARTIF INTEL, V72, P190, DOI 10.1016/j.engappai.2018.04.002
   San-Segundo R, 2016, PATTERN RECOGN LETT, V73, P60, DOI 10.1016/j.patrec.2016.01.008
   Tao D., 2016, IEEE T IMAGE PROCESS, V25, P1
   Vanrell SR, 2018, IEEE J BIOMED HEALTH, V22, P1001, DOI 10.1109/JBHI.2017.2722870
   Wang J, 2016, IEEE SENSOR
   Wang ZL, 2016, IEEE SENS J, V16, P3198, DOI 10.1109/JSEN.2016.2519679
   Xue Y, 2010, NATURALISTIC 3D ACCE, DOI [10.1109/ICSMC.2010.5641790, DOI 10.1109/ICSMC.2010.5641790]
   Zhang YH, 2018, PR IEEE I C PROGR IN, P15, DOI 10.1109/PIC.2018.8706328
NR 29
TC 5
Z9 6
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31069
EP 31086
DI 10.1007/s11042-020-09150-8
EA AUG 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560297200001
DA 2024-07-18
ER

PT J
AU Sargano, AB
   Gu, XW
   Angelov, P
   Habib, Z
AF Sargano, Allah Bux
   Gu, Xiaowei
   Angelov, Plamen
   Habib, Zulfiqar
TI Human action recognition using deep rule-based classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Deep learning; Fuzzy rule-based classifier
ID HUMAN-BEHAVIOR RECOGNITION; HISTOGRAMS; SYSTEM
AB In recent years, numerous techniques have been proposed for human activity recognition (HAR) from images and videos. These techniques can be divided into two major categories: handcrafted and deep learning. Deep Learning-based models have produced remarkable results for HAR. However, these models have several shortcomings, such as the requirement for a massive amount of training data, lack of transparency, offline nature, and poor interpretability of their internal parameters. In this paper, a new approach for HAR is proposed, which consists of an interpretable, self-evolving, and self-organizing set of 0-order If...THEN rules. This approach is entirely data-driven, and non-parametric; thus, prototypes are identified automatically during the training process. To demonstrate the effectiveness of the proposed method, a set of high-level features is obtained using a pre-trained deep convolution neural network model, and a recently introduced deep rule-based classifier is applied for classification. Experiments are performed on a challenging benchmark dataset UCF50; results confirmed that the proposed approach outperforms state-of-the-art methods. In addition to this, an ablation study is conducted to demonstrate the efficacy of the proposed approach by comparing the performance of our DRB classifier with four state-of-the-art classifiers. This analysis revealed that the DRB classifier could perform better than state-of-the-art classifiers, even with limited training samples.
C1 [Sargano, Allah Bux; Habib, Zulfiqar] COMSATS Univ Islamabad, Dept Comp Sci, Lahore, Pakistan.
   [Sargano, Allah Bux; Gu, Xiaowei; Angelov, Plamen] Univ Lancaster, Sch Comp & Commun Infolab21, Bailrigg, England.
C3 COMSATS University Islamabad (CUI); Lancaster University
RP Sargano, AB (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Lahore, Pakistan.; Sargano, AB (corresponding author), Univ Lancaster, Sch Comp & Commun Infolab21, Bailrigg, England.
EM allahbux@cuilahore.edu.pk
RI Sargana, AllahBux/AFO-1591-2022; Habib, Zulfiqar/B-6355-2013; Angelov,
   Plamen/AAE-8284-2019
OI Sargana, AllahBux/0000-0003-2024-2843; Habib,
   Zulfiqar/0000-0001-9758-9162; Angelov, Plamen/0000-0002-5770-934X; Gu,
   Xiaowei/0000-0001-9116-4761
CR Amodei D, 2016, PR MACH LEARN RES, V48
   An-An Liu, 2017, IEEE Transactions on Pattern Analysis and Machine Intelligence, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Angelov P., 2012, Autonomous learning systems: from data streams to knowledge in real-time
   Angelov P., 2017, PROC EVOLVING ADAPT, P1
   Angelov P, 2017, IEEE SYS MAN CYBERN, P746, DOI 10.1109/SMC.2017.8122697
   Angelov P, 2012, INT J GEN SYST, V41, P163, DOI 10.1080/03081079.2011.634807
   Angelov PP, 2019, EMPIRICAL APPROACH M
   Angelov PP, 2018, INFORM SCI
   Batchuluun G, 2017, EXPERT SYST APPL, V81, P108, DOI 10.1016/j.eswa.2017.03.052
   BILEN H, 2016, PROC CVPR IEEE, P3034, DOI [10.1109/CVPR.2016.331, DOI 10.1109/CVPR.2016.331]
   Bilen H, 2018, IEEE T PATTERN ANAL, V40, P2799, DOI 10.1109/TPAMI.2017.2769085
   Cao XQ, 2015, IEEE T FUZZY SYST, V23, P1581, DOI 10.1109/TFUZZ.2014.2370678
   Chang JY, 2009, IEEE INTL CONF CONTR, P211, DOI 10.1109/CCA.2009.5280999
   Ciresan D, 2012, NEURAL NETWORKS, V32, P333, DOI 10.1016/j.neunet.2012.02.023
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Deng C, 2020, IEEE T MULTIMEDIA, V22, P885, DOI 10.1109/TMM.2019.2934833
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Duta IC, 2017, MULTIMED TOOLS APPL, V76, P22445, DOI 10.1007/s11042-017-4795-6
   Everts I, 2013, PROC CVPR IEEE, P2850, DOI 10.1109/CVPR.2013.367
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gao SH, 2016, IEEE T CIRC SYST VID, V26, P494, DOI 10.1109/TCSVT.2015.2389413
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Gokmen G, 2010, PROCD SOC BEHV, V2, P902, DOI 10.1016/j.sbspro.2010.03.124
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Gu XW, 2018, APPL SOFT COMPUT, V68, P53, DOI 10.1016/j.asoc.2018.03.032
   Gu XW, 2018, IEEE GEOSCI REMOTE S, V15, P345, DOI 10.1109/LGRS.2017.2787421
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang HZ, 2019, IEEE I CONF COMP VIS, P3194, DOI 10.1109/ICCV.2019.00329
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kavukcuoglu K., 2010, Advances in neural information processing systems, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lan ZZ, 2015, PROC CVPR IEEE, P204, DOI 10.1109/CVPR.2015.7298616
   LeCun Y., 2015, Lenet-5, convolutional neural networks
   Li Y, 2019, IEEE W CONTR MODEL, DOI 10.1109/compel.2019.8769706
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Medjahed H, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P2001, DOI 10.1109/FUZZY.2009.5277257
   Nazir S, 2018, PATTERN RECOGN LETT, V103, P39, DOI 10.1016/j.patrec.2017.12.024
   Noori FM, 2019, LECT NOTES COMPUT SC, V11482, P299, DOI 10.1007/978-3-030-20205-7_25
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Rahmani H, 2018, IEEE T PATTERN ANAL, V40, P667, DOI 10.1109/TPAMI.2017.2691768
   Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4
   Sargano AB, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7010110
   Sargano AB, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6100309
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shu Y, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-63649-6
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro K., 2014, COMPUTER VISION SPOR, V71, P181, DOI [DOI 10.1007/978-3-319-09396-3_9, DOI 10.1007/978-3-319-09396-39]
   Sun XD, 2018, NEUROCOMPUTING, V299, P42, DOI 10.1016/j.neucom.2018.03.030
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Ullah A, 2019, FUTURE GENER COMP SY, V96, P386, DOI 10.1016/j.future.2019.01.029
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Wang H, 2016, INT J COMPUT VISION, V119, P219, DOI 10.1007/s11263-015-0846-5
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang S, 2014, IEEE T MULTIMEDIA, V16, P289, DOI 10.1109/TMM.2013.2293060
   Wilson S, 2017, IEEE SIGNAL PROC LET, V24, P698, DOI 10.1109/LSP.2017.2690461
   Yao B, 2015, SOFT COMPUT, V19, P499, DOI 10.1007/s00500-014-1270-4
   Yi Y, 2018, VISUAL COMPUT, V34, P391, DOI 10.1007/s00371-016-1345-6
   Zhang DW, 2020, IEEE T PATTERN ANAL, V42, P1755, DOI 10.1109/TPAMI.2019.2900649
   Zheng JJ, 2016, IEEE T IMAGE PROCESS, V25, P2542, DOI 10.1109/TIP.2016.2548242
   Zhou BL, 2014, ADV NEUR IN, V27
NR 70
TC 10
Z9 11
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30653
EP 30667
DI 10.1007/s11042-020-09381-9
EA AUG 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560297300007
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Xing, TT
   Zeng, Y
   Meng, Z
   Guo, XL
AF Xing, Ting-ting
   Zeng, Yan
   Meng, Zong
   Guo, Xiao-lin
TI A fault diagnosis method of rolling bearing based on VMD Tsallis entropy
   and FCM clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Variational mode decomposition (VMD); Tsallis entropy; Fuzzy C-means
   clustering (FCM) algorithm; Fault diagnosis; Rolling bearing
AB A new fault diagnosis method of rolling bearings was presented based on variational mode decomposition (VMD), Tsallis entropy and Fuzzy C-means clustering (FCM) algorithm. Firstly, the measured vibration signals were decomposed with VMD in different scales to obtain a series of band-limited intrinsic modal function (BIMF). The VMD parameters were determined according to the change of the BIMF center frequency. Then, the Tsallis entropy of BIMF components were calculated and used as the signal features. Finally, the features were put into FCM classifier to recognize different fault types. It is proved by experiments that this method is feasible and the proposed approach could obtain better result compared with the method based on mode decomposition (EMD) and local mean decomposition (LMD).
C1 [Xing, Ting-ting; Meng, Zong; Guo, Xiao-lin] Yanshan Univ, Key Lab Measurement Technol & Instrument HeBei Pr, Qinhuangdao 066004, Hebei, Peoples R China.
   [Xing, Ting-ting; Zeng, Yan] Tangshan Polytech Coll, Tangshan 063299, Hebei, Peoples R China.
C3 Yanshan University
RP Zeng, Y (corresponding author), Tangshan Polytech Coll, Tangshan 063299, Hebei, Peoples R China.
EM zengyan3925@163.com
RI Meng, Zong/AGW-0716-2022
CR Abu Arqub O, 2020, SOFT COMPUT, V24, P12501, DOI 10.1007/s00500-020-04687-0
   Abu Arqub O, 2017, SOFT COMPUT, V21, P7191, DOI 10.1007/s00500-016-2262-3
   Abu Arqub O, 2017, NEURAL COMPUT APPL, V28, P1591, DOI 10.1007/s00521-015-2110-x
   Abu Arqub O, 2016, SOFT COMPUT, V20, P3283, DOI 10.1007/s00500-015-1707-4
   Ahmed HOA, 2019, IEEE T IND ELECTRON, V66, P5516, DOI 10.1109/TIE.2018.2868259
   Brkovic A, 2017, ENERGY, V136, P63, DOI 10.1016/j.energy.2016.08.039
   Cerrada M, 2018, MECH SYST SIGNAL PR, V99, P169, DOI 10.1016/j.ymssp.2017.06.012
   Chellamuthu S, 2019, MULTIMED TOOLS APPL, V78, P27333, DOI 10.1007/s11042-019-07847-z
   Chen F, 2019, MULTIMED TOOLS APPL, V78, P4673, DOI 10.1007/s11042-018-6601-5
   Ding XX, 2019, MEASUREMENT, V141, P380, DOI 10.1016/j.measurement.2019.04.030
   Dragomiretskiy K, 2014, IEEE T SIGNAL PROCES, V62, P531, DOI 10.1109/TSP.2013.2288675
   Furuichi S, 2004, J MATH PHYS, V45, P4868, DOI 10.1063/1.1805729
   Garg S, 2019, IEEE T MULTIMEDIA, V21, P566, DOI 10.1109/TMM.2019.2893549
   Gu XH, 2016, MEAS SCI TECHNOL, V27, DOI 10.1088/0957-0233/27/12/125019
   Hu ZX, 2020, IEEE T IND ELECTRON, V67, P3216, DOI 10.1109/TIE.2019.2912763
   Huang F, 2019, IEEE T CYBERNETICS, P1
   Huang FR, 2019, KNOWL-BASED SYST, V167, P26, DOI 10.1016/j.knosys.2019.01.019
   Huang FR, 2019, IEEE T IMAGE PROCESS, V28, P2008, DOI 10.1109/TIP.2018.2882225
   Kanai RA, 2016, J TRIBOL-T ASME, V138, DOI 10.1115/1.4032525
   Li H, 2020, MEASUREMENT, V152, DOI 10.1016/j.measurement.2019.107293
   Li X, 2019, SIGNAL PROCESS, V161, P136, DOI 10.1016/j.sigpro.2019.03.019
   Li X, 2019, SIGNAL PROCESS, V157, P180, DOI 10.1016/j.sigpro.2018.12.005
   Lu WL, 2019, MEAS SCI TECHNOL, V30, DOI 10.1088/1361-6501/ab2eab
   [孟宗 Meng Zong], 2016, [计量学报, Acta Metrologica Sinica], V37, P406
   [孟宗 Meng Zong], 2015, [计量学报, Acta Metrologica Sinica], V36, P77
   Rai A, 2016, TRIBOL INT, V96, P289, DOI 10.1016/j.triboint.2015.12.037
   Randall Robert B., 2011, MECH SYSTEMS SIGNAL, V25, P485
   Shao HD, 2018, MECH SYST SIGNAL PR, V100, P743, DOI 10.1016/j.ymssp.2017.08.002
   Shao HD, 2015, MEAS SCI TECHNOL, V26, DOI 10.1088/0957-0233/26/11/115002
   [时培明 Shi Peiming], 2016, [计量学报, Acta Metrologica Sinica], V37, P62
   Tian J, 2016, IEEE T IND ELECTRON, V63, P1793, DOI 10.1109/TIE.2015.2509913
   TSALLIS C, 1988, J STAT PHYS, V52, P479, DOI 10.1007/BF01016429
   Tsallis C, 1998, PHYSICA A, V261, P534, DOI 10.1016/S0378-4371(98)00437-3
   Wang FT, 2015, J PHYS CONF SER, V628, DOI 10.1088/1742-6596/628/1/012079
   Wang SZ, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P1246, DOI 10.1145/2623330.2623728
   Wei DD, 2019, MEAS SCI TECHNOL, V30, DOI 10.1088/1361-6501/ab0352
   Wu CX, 2017, J VIBROENG, V19, P3445, DOI 10.21595/jve.2017.18482
   Xia M, 2019, MULTIMED TOOLS APPL, V78, P22601, DOI 10.1007/s11042-019-7611-7
   Xu GW, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051088
   Xu YG, 2019, MEAS SCI TECHNOL, V30, DOI 10.1088/1361-6501/ab231b
   Zan T, 2018, 2018 6TH INTERNATIONAL CONFERENCE ON MECHANICAL, AUTOMOTIVE AND MATERIALS ENGINEERING (CMAME), P41, DOI 10.1109/CMAME.2018.8592450
   Zhang X, 2018, KNOWL-BASED SYST, V143, P236, DOI 10.1016/j.knosys.2017.12.025
NR 42
TC 12
Z9 12
U1 6
U2 60
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 30069
EP 30085
DI 10.1007/s11042-020-09534-w
EA AUG 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559430400009
DA 2024-07-18
ER

PT J
AU Meenakshi, K
   Swaraja, K
   Kora, P
AF Meenakshi, K.
   Swaraja, K.
   Kora, Padmavathi
TI A hybrid matrix factorization technique to free the watermarking scheme
   from false positive and negative problems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rotation crossover; Gaussian Hermite Moments; Differential Evolution;
   Schur Factorization; Singular Value Decomposition
ID SINGULAR-VALUE DECOMPOSITION; DISCRETE WAVELET TRANSFORM; DIFFERENTIAL
   EVOLUTION; IMAGE WATERMARKING; VIDEO WATERMARKING; SECURE; DOMAIN; SVD
AB Optimization techniques are used in watermarking algorithms to balance the trade-off between the two mutually conflicting parameters-imperceptibility and robustness. Differential Evolution (DE) with Rotational Cross over (RCO), namely DE-RCO, is employed in the proposed algorithm to improve the convergence of optimization. The DE-RCO provides a watermarking scheme with the highest robustness preserving the transparency. The watermark encoding and decoding carried in the transform domain with a hybrid combination of Schur Factorization (SF) and Singular Value Decomposition (SVD). Two-fold security provided with the Digital Signature (DS) generation and B-test. The DS is concealed in the watermarked image for authentication purpose of freeing the algorithm from the false-positive problem. When the signature passed through the insecure channel, it may corrupt and lead to the failure of the A-test, even the correct watermark given at the extraction leading to the false-negative problem. B-test is conducted to free the algorithm from a false negative problem. An enhanced authentication framework designed and implemented to make the algorithm free from the false-positive and false-negative issues using DS and the hash generated by Gaussian Hermite Moments (GHMs). The experimental results compared with the related existing watermarking schemes demonstrate that the proposed scheme exhibit strong robustness to attacks, invisible and highly secure against false-positive and false-negative problems.
C1 [Meenakshi, K.; Swaraja, K.; Kora, Padmavathi] GRIET, Dept ECE, Hyderabad, India.
C3 Gokaraju Rangaraju Institute of Engineering & Technology
RP Meenakshi, K (corresponding author), GRIET, Dept ECE, Hyderabad, India.
EM mkollati@gmail.com
RI kuraparthi, swaraja/AAY-9068-2020
OI kora, padmavathi/0000-0002-1145-8442; k, swaraja/0000-0003-2638-2492
CR Ahmed F, 2010, SIGNAL PROCESS, V90, P1456, DOI 10.1016/j.sigpro.2009.05.024
   Al-Haj AM, 2010, ADV TECHNIQUES MULTI
   Ali M, 2018, INT J SYST ASSUR ENG, V9, P602, DOI 10.1007/s13198-014-0288-4
   Ali M, 2015, INFORM SCIENCES, V301, P44, DOI 10.1016/j.ins.2014.12.042
   Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   [Anonymous], 2010, J COMPUT INFORM SYST
   Ansari IA, 2017, PATTERN RECOGN LETT, V94, P228, DOI 10.1016/j.patrec.2016.12.010
   Araghi TK, 2018, EXPERT SYST APPL, V112, P208, DOI 10.1016/j.eswa.2018.06.024
   Aslantas V, 2008, AEU-INT J ELECTRON C, V62, P386, DOI 10.1016/j.aeue.2007.02.010
   Aslantas V, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P241, DOI 10.1109/ICME.2008.4607416
   Aung A, 2011, J SIGNAL PROCESS SYS, V64, P319, DOI 10.1007/s11265-010-0492-7
   Bamal R, 2019, MULTIMED TOOLS APPL, V78, P17899, DOI 10.1007/s11042-018-6820-9
   Berger CEH, 2006, J FORENSIC SCI, V51, P100, DOI 10.1111/j.1556-4029.2005.00020.x
   Chandra Mohan B., 2008, ICGST GVIP J, V8, P17
   Cox IJ., 2007, DIGITAL WATERMARKING
   Delp III EJ, 2003, SECURITY WATERMARKIN, V5020
   Deng LB, 2018, IEEE ACCESS, V6, P2970, DOI 10.1109/ACCESS.2017.2786347
   Flusser J., 2009, Moments and Moment Invariants in Pattern Recognition
   Gonzalez R., 1992, Digital Image Processing, P518
   Grycuk R, 2016, IEEE C EVOL COMPUTAT, P86, DOI 10.1109/CEC.2016.7743782
   Henderson N, 2010, IND ENG CHEM RES, V49, P1872, DOI 10.1021/ie900948z
   Hill DLG, 2001, PHYS MED BIOL, V46, pR1, DOI 10.1088/0031-9155/46/3/201
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Horng SJ, 2011, IEEE MULTIMEDIA
   Hosny KM, 2018, IET IMAGE PROCESS, V12, P2178, DOI 10.1049/iet-ipr.2018.5661
   Hu HT, 2018, 2018 41ST INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P92, DOI 10.1109/TSP.2018.8441406
   Jayalakshmi M, 2006, INT C PATT RECOG, P861
   Kozat SS, 2004, 2004 INT C IM PROC 2, V5
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Loukhaoukha K., 2013, J OPTIMIZATION, V2013, P1
   Meenakshi K., 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 900), P477, DOI 10.1007/978-981-13-3600-3_45
   Meenakshi K, 2017, IEEE COMMUN LETT, V21, P1779, DOI 10.1109/LCOMM.2017.2700461
   Meenakshi K, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY (ICIT), P167, DOI 10.1109/ICIT.2014.53
   Meenakshi K, 2014, IETE J RES, V60, P276, DOI 10.1080/03772063.2014.961570
   Meenakshi K, 2014, 2014 FIRST INTERNATIONAL CONFERENCE ON NETWORKS & SOFT COMPUTING (ICNSC), P309, DOI 10.1109/CNSC.2014.6906697
   Meenakshi K, 2019, INT J INNOV TECHNOL
   Meenakshi K, 2019, 2019 IEEE 5 INT C CO, P1
   Mehta P, 2018, ENERGY ENV SUSTAIN, P343, DOI 10.1007/978-981-10-7431-8_15
   Monga V, 2005, PERPETUALLY BASED ME
   Nilchi ARN, 2008, 2008 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES, P1, DOI 10.1109/WOCN.2008.4542509
   Ramanjaneyulu K, 2012, IET IMAGE PROCESS, V6, P364, DOI 10.1049/iet-ipr.2010.0347
   Recommendation ITU-R BT.500, 2002, Recommendation ITU-R BT. 500-11. ITU Telecom. Standardization Sector of ITU 7, P500
   Sequeira A, 2001, PROC SPIE, V4518, P216, DOI 10.1117/12.448206
   Su QT, 2019, IEEE ACCESS, V7, P4358, DOI 10.1109/ACCESS.2018.2888857
   Swaraja K, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101665
   Swaraja K, 2018, MULTIMED TOOLS APPL, V77, P28249, DOI 10.1007/s11042-018-6020-7
   Swaraja K, 2014, COMP INT COMP RES IC, P1, DOI DOI 10.1109/ICCIC.2014.7238503
   Tang ZJ, 2016, AEU-INT J ELECTRON C, V70, P833, DOI 10.1016/j.aeue.2016.03.010
   Vali MH, 2018, EXPERT SYST APPL, V114, P296, DOI 10.1016/j.eswa.2018.07.004
   WOLFE SJ, 1980, J MULTIVARIATE ANAL, V10, P379, DOI 10.1016/0047-259X(80)90058-5
   Yu F, 2016, SOFT COMPUT, V20, P449, DOI 10.1007/s00500-014-1509-0
   Zheng FF, 2013, J COMPUT CIVIL ENG, V27, P148, DOI 10.1061/(ASCE)CP.1943-5487.0000208
NR 53
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29865
EP 29900
DI 10.1007/s11042-020-09250-5
EA AUG 2020
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000567227300006
DA 2024-07-18
ER

PT J
AU Shaukat, Z
   Ali, S
   Farooq, QU
   Xiao, CB
   Sahiba, S
   Ditta, A
AF Shaukat, Zeeshan
   Ali, Saqib
   Farooq, Qurat ul Ain
   Xiao, Chuangbai
   Sahiba, Sana
   Ditta, Allah
TI Cloud-based efficient scheme for handwritten digit recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional Neural networks; Cloud computing; Handwritten digit
   recognition; Deep learning 4 J
ID DEEP; LOCALIZATION
AB Handwritten character recognition has been acknowledged and achieved more prominent attention in pattern recognition research community due to enormous applications & vagueness in application methods, while cloud computing delivers appropriate, on-demand access of network to a joint tarn of configurable computing resource & digital devices. Principally two steps, feature extraction & character recognition, are required for Handwritten Digit Recognition (HDR), which are primarily based on some classification algorithms. Previous studies show the nonexistence of higher precision and truncated computational swiftness for HDR procedure. "The projected research aimed to make the trail towards digitalization clearer by providing high accuracy and faster cloud-based computational for handwritten digits recognition. The current study utilized a cloud-based neural network (CNN) as a classifier, suitable parameters of dataset MNIST for testing and training purposes as a framework called DL4J for cloud-based handwritten digit recognition. The said system magnificently managed to obtained precision up to 99.41%, which is higher than previously projected systems. Additionally, the proposed method decreases cost and computational time significantly as using cloud-based architecture for testing and training; as a result, the algorithm becomes more efficient.
C1 [Shaukat, Zeeshan; Ali, Saqib; Xiao, Chuangbai; Sahiba, Sana] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
   [Farooq, Qurat ul Ain] Beijing Univ Technol, Fac Life Sci & Bioengn, Beijing 100124, Peoples R China.
   [Ditta, Allah] Univ Educ, Div Sci & Technol, Lahore 54000, Pakistan.
C3 Beijing University of Technology; Beijing University of Technology
RP Shaukat, Z (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
EM zee@emails.bjut.edu.cn
RI Ditta, Allah/JUU-3583-2023; Shaukat, Zeeshan/AAH-5490-2019; AllahDitta,
   Dr/HGU-2563-2022; Ali, Saqib/C-7686-2011; Farooq, Qurat ul
   Ain/AAK-1155-2021
OI Ditta, Allah/0000-0001-6996-2986; Shaukat, Zeeshan/0000-0002-7901-6712;
   Ali, Saqib/0000-0001-5170-7346; Farooq, Qurat ul
   Ain/0000-0001-9951-2388; Ditta, Dr. Allah/0000-0003-1519-5982
CR Abu Ghosh MM, 2017, 2017 INTERNATIONAL CONFERENCE ON PROMISING ELECTRONIC TECHNOLOGIES (ICPET 2017), P77, DOI 10.1109/ICPET.2017.20
   Al-Hmouz R, 2010, MACH VISION APPL, V21, P319, DOI 10.1007/s00138-008-0164-9
   Alani AA, 2017, INFORMATION, V8, DOI 10.3390/info8040142
   Ali S, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1161-5
   [Anonymous], 2019, ARXIV190101007
   [Anonymous], 2008, Advances in Neural Information Processing Systems
   Arica N, 2001, IEEE T SYST MAN CY C, V31, P216, DOI 10.1109/5326.941845
   Barroso J, 1997, ISIE '97 - PROCEEDINGS OF THE IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS, VOLS 1-3, P761, DOI 10.1109/ISIE.1997.648635
   Boukharouba Abdelhak, 2017, Applied Computing and Informatics, V13, P19, DOI 10.1016/j.aci.2015.05.001
   Busta M, 2017, IEEE I CONF COMP VIS, P2223, DOI 10.1109/ICCV.2017.242
   Chen B.-C., 2019, ARXIV PREPRINT ARXIV
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Dutt Anuj., 2017, INT J OF ADV RES IN, V6, P990
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Ercoli S, 2017, IEEE T MULTIMEDIA, V19, P2521, DOI 10.1109/TMM.2017.2697824
   Fang J., 2017, INT C MOB AD HOC SEN
   Goodfellow I.J., 2013, MULTIDIGIT NUMBER RE
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Hanmandlu M, 2007, PATTERN RECOGN, V40, P1840, DOI 10.1016/j.patcog.2006.08.014
   Hanmandlu M, 2007, 9 BIENN C AUSTR PATT
   Jana Ranjan, 2019, Recent Trends in Signal and Image Processing. Proceedings of ISSIP 2018. Advances in Intelligent Systems and Computing (AISC 922), P23, DOI 10.1007/978-981-13-6783-0_3
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee S, 2017, C HUM SYST INTERACT, P239, DOI 10.1109/HSI.2017.8005037
   Liakos KG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082674
   Meier U, 2011, PROC INT CONF DOC, P1250, DOI 10.1109/ICDAR.2011.252
   Mohebi E, 2014, NEURAL NETWORKS, V60, P104, DOI 10.1016/j.neunet.2014.08.001
   Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097
   Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60
   Nielsen M. A., 2015, NEURAL NETWORKS DEEP, DOI DOI 10.1145/2939672.2945397
   OShea K., 2015, ARXIV151108458, DOI DOI 10.48550/ARXIV.1511.08458
   Ososkov G., 2018, EPJ WEB C
   Polanía LF, 2017, IEEE T SIGNAL PROCES, V65, P4538, DOI 10.1109/TSP.2017.2712128
   Raus M., 1995, 38 MIDW S CIRC SYST
   Shastry S., 2013, 2013 INT MUTL AUT CO
   Shaukat Z., 2019, INT C APPL HUM FACT
   Shaukat Z., 2018, P 2018 INT C COMP AR
   Shaukat Z, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-019-1926-x
   Simard PY, 2003, PROC INT CONF DOC, P958
   Singhal V, 2017, IEEE T GEOSCI REMOTE, V55, P5274, DOI 10.1109/TGRS.2017.2704590
   Soundes B, 2019, INT J COMPUT SCI ENG, V19, P274, DOI 10.1504/IJCSE.2019.100231
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan HH, 2017, IEEE IJCNN, P1895, DOI 10.1109/IJCNN.2017.7966081
   Teow MYW, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON AUTOMATIC CONTROL AND INTELLIGENT SYSTEMS (I2CACIS), P167, DOI 10.1109/I2CACIS.2017.8239052
   Toselli AH, 2010, PATTERN RECOGN, V43, P1814, DOI 10.1016/j.patcog.2009.11.019
   Walker BN, 2019, EBIOMEDICINE, V40, P176, DOI 10.1016/j.ebiom.2019.01.028
   Wang T, 2012, INT C PATT RECOG, P3304
   Whatmough PN, 2018, IEEE J SOLID-ST CIRC, V53, P2722, DOI 10.1109/JSSC.2018.2841824
   Xu Q, 2017, ELECTRON LETT, V53, P1246, DOI 10.1049/el.2017.2621
   Yang JB, 2009, IEEE T NEURAL NETWOR, V20, P1911, DOI 10.1109/TNN.2009.2032543
   Younis KS, 2017, P NEW TRENDS INFORM, P157
NR 51
TC 3
Z9 3
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29537
EP 29549
DI 10.1007/s11042-020-09494-1
EA AUG 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559640400006
DA 2024-07-18
ER

PT J
AU Xiao, ZT
   Gao, J
   Wu, DQ
   Zhang, LY
   Chen, X
AF Xiao, Zhengtao
   Gao, Jian
   Wu, Dongqing
   Zhang, Lanyu
   Chen, Xin
TI A fast 3D object recognition algorithm using plane-constrained point
   pair features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D object recognition; Point pair features; Feature descriptor; Feature
   matching; Convex hull
ID CONVEX-HULL ALGORITHM; UNIQUE SIGNATURES; POSE ESTIMATION; SURFACE;
   HISTOGRAMS
AB The point pair feature (PPF) algorithm is one of the best-performing 3D object recognition algorithms. However, the high dimensionality of its search space is a disadvantage of this algorithm. This high dimensionality means the feature matching process contains a large number of uninformative features, which reduces recognition speed. To solve this problem and improve the object recognition speed, this paper proposes a fast 3D object recognition algorithm based on the plane-constrained point pair features. By utilizing the property of the coplanar point pair features and the characteristics of the object placement plane, the proposed algorithm extracts the object placement plane through convex hull area calculation, eliminates irrelevant point pair features, and then performs object recognition with the reduced point pair feature descriptors for the feature matching. Experimental results demonstrate that the proposed algorithm significantly reduces the number of feature descriptors and accelerates the recognition speed of 3D objects in a complex background. Compared to the original point pair feature algorithm, the proposed method can achieve better performance and efficiency for 3D object recognition.
C1 [Xiao, Zhengtao; Gao, Jian; Zhang, Lanyu; Chen, Xin] Guangdong Univ Technol, State Key Lab Precis Elect Mfg Technol & Equipmen, Guangzhou 510006, Peoples R China.
   [Xiao, Zhengtao] Guangdong Polytech Ind & Commerce, Sch Electromech Engn, Guangzhou 510510, Peoples R China.
   [Wu, Dongqing] Zhongkai Univ Agr & Engn, Sch Computat Sci, Guangzhou 510220, Peoples R China.
C3 Guangdong University of Technology; Zhongkai University of Agriculture &
   Engineering
RP Gao, J (corresponding author), Guangdong Univ Technol, State Key Lab Precis Elect Mfg Technol & Equipmen, Guangzhou 510006, Peoples R China.
EM gaojian@gdut.edu.cn
RI chen, xin/IQW-3432-2023; DAI, Jinjia/KCL-5110-2024; yu,
   zhang/JWO-7724-2024; Wu, Dongqing/KFA-3312-2024; Zhang,
   Lanyue/JNS-8209-2023
OI Wu, Dongqing/0000-0002-3861-234X; Chen, Xin/0000-0003-1990-2058
FU National Natural Science Foundation of China [U1601202]; Guangdong
   Provincial RD Project [2018B090906002]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant U1601202, and in part by the Guangdong
   Provincial R&D Project under Grant No. 2018B090906002.
CR Abualigah L. M. Q., 2019, FEATURE SELECTION EN, DOI [10.1007/978-3-030-10674-4, DOI 10.1007/978-3-030-10674-4]
   Abualigah LM, 2018, J COMPUT SCI-NETH, V25, P456, DOI 10.1016/j.jocs.2017.07.018
   [Anonymous], 2009, IEEE INT C ROB AUT
   Awad A. I., 2016, STUDIES COMPUTATIONA
   Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821
   Birdal T, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P527, DOI 10.1109/3DV.2015.65
   Carvajal-Ortiz L, 2019, 2019 XLV LATIN AMERICAN COMPUTING CONFERENCE (CLEI 2019), DOI [10.1109/CLEI47609.2019.235114, 10.1007/s10044-019-00804-4]
   Choi C, 2016, ROBOT AUTON SYST, V75, P595, DOI 10.1016/j.robot.2015.09.020
   de Figueiredo RP, 2015, NEUROCOMPUTING, V150, P126, DOI 10.1016/j.neucom.2014.07.070
   Deng HW, 2018, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2018.00028
   Drost B, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P398, DOI 10.1109/3DV.2015.52
   Drost B, 2010, PROC CVPR IEEE, P998, DOI 10.1109/CVPR.2010.5540108
   Ghorpade VK, 2017, EURASIP J ADV SIG PR, DOI 10.1186/s13634-017-0483-y
   Gomes AJP, 2016, COMPUT AIDED DESIGN, V70, P153, DOI 10.1016/j.cad.2015.07.013
   Graham R. L., 1972, Information Processing Letters, V1, P132, DOI 10.1016/0020-0190(72)90045-2
   Guo YL, 2016, INT J COMPUT VISION, V116, P66, DOI 10.1007/s11263-015-0824-y
   Guo YL, 2014, IEEE T PATTERN ANAL, V36, P2270, DOI 10.1109/TPAMI.2014.2316828
   Hassaballah M, 2016, STUD COMPUT INTELL, V630, P1, DOI 10.1007/978-3-319-28854-3_1
   Hassaballah M., 2020, DEEP LEARNING COMPUT, V1st, DOI [10.1201/9781351003827, DOI 10.1201/9781351003827]
   Hassaballah M, 2018, RECENT ADV COMPUTER, V804, DOI [10.1007/978-3-030-03000-1, DOI 10.1007/978-3-030-03000-1]
   Hinterstoisser S, 2016, LECT NOTES COMPUT SC, V9907, P834, DOI 10.1007/978-3-319-46487-9_51
   Ioannidou A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3042064
   Jarvis R. A., 1973, Information Processing Letters, V2, P18, DOI 10.1016/0020-0190(73)90020-3
   Jorgensen Troels Bo, 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P333
   Kiforenko L, 2018, COMPUT VIS IMAGE UND, V166, P66, DOI 10.1016/j.cviu.2017.09.004
   Lan SY, 2019, PROC CVPR IEEE, P998, DOI 10.1109/CVPR.2019.00109
   López GL, 2017, MULTIMED TOOLS APPL, V76, P6993, DOI 10.1007/s11042-016-3330-5
   Lin BW, 2017, J VIS COMMUN IMAGE R, V48, P136, DOI 10.1016/j.jvcir.2017.05.007
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Liu RZ, 2018, MULTIMED TOOLS APPL, V77, P31221, DOI 10.1007/s11042-018-6185-0
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Rusu RB, 2010, IEEE INT C INT ROBOT, P2155, DOI 10.1109/IROS.2010.5651280
   Salti S, 2014, COMPUT VIS IMAGE UND, V125, P251, DOI 10.1016/j.cviu.2014.04.011
   Shi YF, 2016, COMPUT GRAPH-UK, V55, P55, DOI 10.1016/j.cag.2015.11.003
   Sklansky J, 1982, PATTERN RECOGN LETT, V1, P79, DOI 10.1016/0167-8655(82)90016-2
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Tang ZC, 2019, IEEE ACCESS, V7, P128185, DOI 10.1109/ACCESS.2019.2940034
   ten Pas A, 2017, INT J ROBOT RES, V36, P1455, DOI 10.1177/0278364917735594
   Tombari F., 2010, P ACM WORKSH 3D OBJ, P57, DOI DOI 10.1145/1877808.1877821
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26
   Vidal J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082678
   Zhao H, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107272
NR 43
TC 2
Z9 2
U1 8
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29305
EP 29325
DI 10.1007/s11042-020-09525-x
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559626500004
DA 2024-07-18
ER

PT J
AU Karpagavalli, P
   Ramprasad, AV
AF Karpagavalli, P.
   Ramprasad, A., V
TI Automatic multiple human tracking using an adaptive hybrid GMM based
   detection in a crowd
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tracking by detection; Multiple human tracking; Computer vision;
   Automation; Multiple blob detection; Adaptive hybrid GMM based
   detection; Adaptive hybrid multiple human tracking
ID OBJECT TRACKING; PATTERNS
AB For a visual surveillance in a crowd, multiple human tracking is essential and of course a challenging task. Real-world applications require multiple cameras to capture crowd scenes so that a keen tracking is observed. Automatic tracking in a crowded environment is very important criteria for the surveillance. Accurate and real-time tracking in a crowd, the number of people present in the public places and shopping mall are some of the vital information for monitoring traffic violations. To provide human safety and security, surveillance like theft prevention and automated checkout provides the necessary consumer information to the managers. The conventional tracking algorithm does not handle the complex background, multi-view points, various illumination changes and severe occlusion occurring in a crowd. The above problem can be effectively handled by using the proposed Adaptive Hybrid Multiple Human Tracking (AHMHT) method. The proposed work utilizes the Adaptive Hybrid Gaussian Mixture Model (AHGMM) (Karpagavalli and Ramprasad, International Journal of Multimedia Tools and Application 76(12):14129-14149,12) detected output, so that, the proposed algorithm tracks all the blobs in each frame on the basis of motion information along with the width and height information of exact blob. The experimental results demonstrate that the proposed method performs well compared to other methods. The multiple human tracking rates are improved with maximum of 91%using the proposed frame work compared with other methods. The proposed method is efficient in terms of computational time (CT) using an adaptive hybrid tracking.
C1 [Karpagavalli, P.] KLN Coll Engn, Elect & Commun Engn Dept, Pottapalayam, Tamil Nadu, India.
   [Ramprasad, A., V] KLN Coll Engn, Pottapalayam, Tamil Nadu, India.
RP Karpagavalli, P (corresponding author), KLN Coll Engn, Elect & Commun Engn Dept, Pottapalayam, Tamil Nadu, India.
EM drkarpagam2018@gmail.com
CR Ali I, 2012, IMAGE VISION COMPUT, V30, P966, DOI 10.1016/j.imavis.2012.08.013
   Alper Y, 2006, IEEE T PATTERN ANAL, V36, P1442
   [Anonymous], 2012, LECT NOTES COMPUT SC
   [Anonymous], 2018, 32 AAAI C ART INT
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Chandrajit M., 2016, SIGNAL IMAGE PROCESS, V7, P15, DOI 10.51211sipij.2016.7302
   Chen JH, 2017, IEEE COMPUT SOC CONF, P2143, DOI 10.1109/CVPRW.2017.266
   Collins RT, 2003, PROC CVPR IEEE, P234
   Fernando T, 2018, IEEE WINT CONF APPL, P1122, DOI 10.1109/WACV.2018.00128
   Ferraz MB, 2006, P IEEE INT C IM PROC
   Ferryman J, 2014, PATTERN RECOGN LETT, V44, P3, DOI 10.1016/j.patrec.2014.01.005
   Karpagavalli P, 2017, MULTIMED TOOLS APPL, V76, P14129, DOI 10.1007/s11042-016-3777-4
   Kartheek GCR, 2015, INT J INNOVATIVE RES, V3, P7366
   Kim Z, 2008, PROC CVPR IEEE, P1626
   Lan X, 2016, P 25 INT JOINT C ART, P3403
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2017, AAAI CONF ARTIF INTE, P4118
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Luo W, 2017, COMPUTER VISION PATT
   Mishra R, 2012, INT J ADV RES COMPUT
   Mucherjee S, 2012, J COMPUTER VISION IM
   Nguyen HT, 2004, IEEE T PATTERN ANAL, V26, P1099, DOI 10.1109/TPAMI.2004.45
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sakaino H, 2013, IEEE T CIRC SYST VID, V23, P1661, DOI 10.1109/TCSVT.2013.2255400
   Schulter S, 2017, PROC CVPR IEEE, P2730, DOI 10.1109/CVPR.2017.292
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Venkatesh babu R, 2007, IEEE INT C AC SPEECH
   Zhang Q, 2011, IEEE T IMAGE PROCESS, V20, P3308, DOI 10.1109/TIP.2011.2159228
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 31
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28993
EP 29019
DI 10.1007/s11042-019-08181-0
EA AUG 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000557124000004
DA 2024-07-18
ER

PT J
AU Rejeesh, MR
   Thejaswini, P
AF Rejeesh, M. R.
   Thejaswini, P.
TI MOTF: Multi-objective Optimal Trilateral Filtering based partial moving
   frame algorithm for image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Moving frame; Optimal trilateral filtering; Grey Wolf
   Optimization; PSNR; MSE; Block-matching and 3D filtering (BM3D)
ID BILATERAL FILTER; RANGE
AB In this paper, a novel denoising approach based on optimal trilateral filtering using Grey Wolf Optimization (GWO) is proposed. At first, a database of noisy images are generated by adding Gaussian noise, Salt & Pepper noise and Random noise to the captured image. The filtering of noisy images are performed by Block-matching and 3D filtering (BM3D) algorithm over the components of image obtained through the moving frame approach. Then, using optimal trilateral filtering, the denoised images are reconstructed. Therefore, by using a two-level filtering approach such as Moving frame-based Block-matching and 3D filtering (BM3D) and Optimal trilateral filtering the noisy images are decomposed. The proposed optimal trilateral filter employs Grey Wolf Optimization algorithm for selecting the parameters optimally to improve the efficiency of filtering method which also reduces the time required for manual computation. The performance of the proposed image denoising algorithm is analyzed using multiple datasets and the analysis of results were done in contrast with existing conventional approaches. The results validated that the optimal trilateral filtering approach outperforms other conventional methods in terms of Mean-Square Error (MSE) and the Peak Signal-to-Noise Ratio (PSNR).
C1 [Rejeesh, M. R.] Anna Univ, Nagercoil 600025, Tamil Nadu, India.
   [Thejaswini, P.] JSS Acad Tech Educ Bangalore, Dept ECE, Bengaluru 560060, Karnataka, India.
C3 Anna University; Anna University of Technology Tirunelveli
RP Rejeesh, MR (corresponding author), Anna Univ, Nagercoil 600025, Tamil Nadu, India.
EM rejeeshmr@gmail.com; thejaswinip@jssateb.ac.in
RI M R, Rejeesh/HTN-7964-2023; P, Thejaswini/W-2881-2018
OI M R, Rejeesh/0000-0001-6329-7575; P, Thejaswini/0000-0003-1240-6860
CR Aravindan TE, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1069-4
   Barbu T, 2016, INT CONF SYST THEO, P761, DOI 10.1109/ICSTCC.2016.7790759
   Chato L, 2017, UB COMP EL MOB COMM
   Chen QA, 2010, SIGNAL PROCESS, V90, P2778, DOI 10.1016/j.sigpro.2010.03.016
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Choudhury, 2005, ACM SIGGRAPH 2005 Courses, P5, DOI 10.1145/1198555.1198565
   Cruz C, 2018, IEEE SIGNAL PROC LET, V25, P1216, DOI 10.1109/LSP.2018.2850222
   Dai T, 2017, SIGNAL PROCESS, V137, P223, DOI 10.1016/j.sigpro.2017.02.005
   Dey M, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, ENERGY & COMMUNICATION (CIEC), P202, DOI 10.1109/CIEC.2016.7513830
   Trinh DH, 2014, IEEE T IMAGE PROCESS, V23, P1882, DOI 10.1109/TIP.2014.2308422
   Ghimpeteanu G, 2016, IEEE T IMAGE PROCESS, V25, P388, DOI 10.1109/TIP.2015.2498413
   Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5
   Guo Q, 2016, IEEE T CIRC SYST VID, V26, P868, DOI 10.1109/TCSVT.2015.2416631
   Herng-Hua Chang, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P673, DOI 10.1109/CISP.2010.5647219
   Hsieh PW, 2018, SIGNAL PROCESS, V149, P214, DOI 10.1016/j.sigpro.2017.12.011
   Hu HJ, 2018, J VIS COMMUN IMAGE R, V50, P100, DOI 10.1016/j.jvcir.2017.11.013
   Joseph J, 2018, COMPUT ELECTR ENG, V69, P782, DOI 10.1016/j.compeleceng.2018.02.033
   Kim JH, 2017, EXPERT SYST APPL, V87, P252, DOI 10.1016/j.eswa.2017.06.015
   Kumar A, 2019, IEEE ACCESS, V7, P26200, DOI 10.1109/ACCESS.2019.2901691
   Lee D, 2018, NUCL INSTRUM METH A, V884, P97, DOI 10.1016/j.nima.2017.12.050
   Li YJ, 2017, IET IMAGE PROCESS, V11, P1197, DOI 10.1049/iet-ipr.2016.1110
   Mansoor A, 2014, LECT NOTES COMPUT SC, V8673, P130, DOI 10.1007/978-3-319-10404-1_17
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Onuki M, 2016, IEEE T SIGNAL INF PR, V2, P137, DOI 10.1109/TSIPN.2016.2532464
   Phophalia A, 2015, APPL SOFT COMPUT, V33, P1, DOI 10.1016/j.asoc.2015.04.005
   Rafsanjani HK, 2017, DIGIT SIGNAL PROCESS, V64, P71, DOI 10.1016/j.dsp.2017.02.004
   Rejeesh MR, 2019, MULTIMED TOOLS APPL, V78, P22691, DOI 10.1007/s11042-019-7577-5
   Singh K, 2017, OPTIK, V131, P423, DOI 10.1016/j.ijleo.2016.11.055
   Verma R, 2017, OPTIK, V147, P151, DOI 10.1016/j.ijleo.2017.08.075
   Wong WCK, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P820
   Yang S, 2016, IEEE T IMAGE PROCESS, V25, P2249, DOI 10.1109/TIP.2016.2545248
   Zhang ML, 2018, COMPUT VIS IMAGE UND, V171, P48, DOI 10.1016/j.cviu.2018.05.006
   Zhang YX, 2014, NEUROCOMPUTING, V140, P299, DOI 10.1016/j.neucom.2014.03.008
   Zhang YQ, 2018, INFORM SCIENCES, V462, P402, DOI 10.1016/j.ins.2018.06.028
NR 34
TC 64
Z9 64
U1 5
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28411
EP 28430
DI 10.1007/s11042-020-09234-5
EA AUG 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000554845500001
DA 2024-07-18
ER

PT J
AU Mansour, RF
AF Mansour, Romany F.
TI Evolutionary computing enriched ridge regression model for craniofacial
   reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Craniofacial reconstrction; Statistical method; Evolutionary computing;
   ridge regression; Particle swarm optimization; differential evolution
AB Craniofacial reconstruction is one of the dominating research domains having vital significance towards forensic purposes as well as archaeological investigation needs. With a goal to enable an error-resilient and swift craniofacial reconstruction model, in this paper an evolutionary computing assisted enhanced regression model has been proposed. We have developed an enhanced over-fitting resilient regression model called Ridge Regression (RR) as a statistical method to perform craniofacial reconstruction using landmark points and skull-face/(tissue) skin features. Our proposed model incorporates a hybrid evolutionary computing scheme containing Particle Swarm Optimization (PSO) and Differential Evolution (DE) to perform feature point selection and landmark count reduction. Here, the prime objective is to reduce the feature sets and landmark that can eventually make craniofacial reduction process more time efficient and accurate. The performance assessment reveals that the proposed PSO-DEFS based RRM model outperforms existing approaches such as the least square support vector regression (LSSVR) and partial least square regression (PLSR).
C1 [Mansour, Romany F.] Assiut Univ, Fac Sci, Dept Math, Assiut, Egypt.
C3 Egyptian Knowledge Bank (EKB); Assiut University
RP Mansour, RF (corresponding author), Assiut Univ, Fac Sci, Dept Math, Assiut, Egypt.
EM romanyf@aun.edu.eg
RI Mansour, Romany F./AAB-6085-2021
OI Mansour, Romany F./0000-0001-5857-8495
CR Berar M, 2005, ISPA 2005: PROCEEDINGS OF THE 4TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P365, DOI 10.1109/ISPA.2005.195439
   Berar M, 2011, FORENSIC SCI INT, V210, P228, DOI 10.1016/j.forsciint.2011.03.010
   Claes P., 2006, Journal of Computing and Information Technology - CIT, V14, P21, DOI 10.2498/cit.2006.01.03
   Claes P, 2007, FACULTEITINGENIEURSW
   Claes P, 2006, FORENSIC SCI INT, V159, pS147, DOI 10.1016/j.forsciint.2006.02.035
   Claes P, 2010, FORENSIC SCI INT, V201, P138, DOI 10.1016/j.forsciint.2010.03.008
   Claes P, 2010, FORENSIC SCI INT, V201, P146, DOI 10.1016/j.forsciint.2010.03.009
   De Greef S, 2005, J FORENSIC SCI, V50, P12
   Deng QQ, 2011, FORENSIC SCI INT, V208, P95, DOI 10.1016/j.forsciint.2010.11.011
   Duan FQ, 2014, MULTIMED TOOLS APPL, V73, P809, DOI 10.1007/s11042-012-1351-2
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Li JA, 2009, INT J OPHTHALMOL-CHI, V2, P1
   Li Y, 2014, IEEE SYS MAN CYBERN, P1147, DOI 10.1109/SMC.2014.6974068
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Paysan P, 2009, FACE RECONSTRUCTION, P232
   Roozbeh M, 2016, J MULTIVARIATE ANAL, V147, P127, DOI 10.1016/j.jmva.2016.01.005
   Tilotta F, 2009, FORENSIC SCI INT, V191, P112, DOI 10.1016/j.forsciint.2009.06.017
   Turner WD, 2005, FORENSIC SCI INT, V154, P149, DOI 10.1016/j.forsciint.2004.10.003
   Vigneau E, 2002, COMPUT STAT DATA AN, V41, P231, DOI 10.1016/S0167-9473(02)00071-3
   Wang J, 2011, 2011 INTERNATIONAL CONFERENCE ON EDUCATION SCIENCE AND MANAGEMENT ENGINEERING (ESME 2011), VOLS 1-5, P1118
   Wilkinson C., 2004, Forensic Facial Reconstruction
NR 21
TC 13
Z9 13
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22065
EP 22082
DI 10.1007/s11042-017-5015-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000560560300001
DA 2024-07-18
ER

PT J
AU Nejad, MY
   Mosleh, M
   Heikalabad, SR
AF Nejad, Mohsen Yoosefi
   Mosleh, Mohammad
   Heikalabad, Saeed Rasouli
TI An enhanced LSB-based quantum audio watermarking scheme for nano
   communication networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nano communications; Quantum audio watermarking; Quantum audio
   processing; Gray code; Least-significant-bit
ID REPRESENTATION; IMAGES
AB In recent years, digital multimedia including image, audio, and video are extended to quantum computation and quantum networks. Consequently, copyright protection of digital multimedia in quantum networks becomes a significant issue. As an important security technology, quantum watermarking is an appropriate solution, which embeds copyright information into the carrier signal. This work presents an enhanced least significant bit (LSB) based audio watermarking using reflected gray code. In the presented scheme, the watermark image is first scrambled using a new scrambling method presented in this paper, which modifies pixel values for scrambling instead of changing pixel positions. The scrambled image is then converted into a qubit sequence to comply with one-dimension audio signal, and the qubits are embedded into carrier quantum audio signal using an embedding key. In embedding phase, every four low qubit of target audio sample replaced with their nearest even or odd number in reflected gray code, based on the value of embedded qubit. For every procedure of the proposed scheme, the quantum circuit and complexity analysis is presented. Experimental results prove that the proposed scheme has good transparency, capacity and security.
C1 [Nejad, Mohsen Yoosefi] Payame Noor Univ, Dept Comp Engn & Informat Technol, Tehran, Iran.
   [Mosleh, Mohammad] Islamic Azad Univ, Dept Comp Engn, Dezful Branch, Dezful, Iran.
   [Heikalabad, Saeed Rasouli] Islamic Azad Univ, Dept Comp Engn, Tabriz Branch, Tabriz, Iran.
C3 Payame Noor University; Islamic Azad University; Islamic Azad University
RP Mosleh, M (corresponding author), Islamic Azad Univ, Dept Comp Engn, Dezful Branch, Dezful, Iran.
EM Mosleh@iaud.ac.ir
RI Heikalabad, Saeed Rasouli/F-6452-2011
OI Rasouli Heikalabad, Saeed/0000-0001-9926-5153; Mosleh,
   Mohammad/0000-0002-0991-1623; Yoosefi Nejad, Moshen/0000-0003-4945-804X
CR [Anonymous], 2015, SAMPLE RADAR 235 FRE
   [Anonymous], 2004, CHINESE J STEREOLOGY
   BENIOFF P, 1980, J STAT PHYS, V22, P563, DOI 10.1007/BF01011339
   Chen KH, 2019, INT J THEOR PHYS, V58, P502, DOI 10.1007/s10773-018-3950-9
   Chen KH, 2018, INT J THEOR PHYS, V57, P476, DOI 10.1007/s10773-017-3580-7
   Du B, 2011, ELECTRON J QUAL THEO, P1
   Frank G., 1953, GOOGLE PATENTS
   Heidari S, 2016, INT J THEOR PHYS, V55, P4205, DOI 10.1007/s10773-016-3046-3
   Jiang N, 2016, INT J THEOR PHYS, V55, P107, DOI 10.1007/s10773-015-2640-0
   Jiang N, 2014, INT J THEOR PHYS, V53, P2463, DOI 10.1007/s10773-014-2046-4
   Jiang N, 2014, QUANTUM INF PROCESS, V13, P1223, DOI 10.1007/s11128-013-0721-7
   Latorre J I, 2005, Image compression and entanglement
   Le PQ, 2011, QUANTUM INF PROCESS, V10, P63, DOI 10.1007/s11128-010-0177-y
   Li M., 2013, 3 INT C MULT TECHN
   Li PC, 2018, INT J THEOR PHYS, V57, P3242, DOI 10.1007/s10773-018-3841-0
   Li Zhang, 2011, 2011 International Conference on Multimedia and Signal Processing (CMSP), P312, DOI 10.1109/CMSP.2011.69
   Mondal B., 2017, ICICCS, P261, DOI [10.15439/2017R47, DOI 10.15439/2017R47]
   Nejad MY, 2019, INT J THEOR PHYS, V58, P3828, DOI 10.1007/s10773-019-04251-z
   Nielsen M A., 2002, NORS SOFTW CORP NET
   Qu ZG, 2018, CHINESE PHYS B, V27, DOI 10.1088/1674-1056/27/1/010306
   Song XH, 2013, QUANTUM INF PROCESS, V12, P3689, DOI 10.1007/s11128-013-0629-2
   Vedral V, 1996, PHYS REV A, V54, P147, DOI 10.1103/PhysRevA.54.147
   Venegas-Andraca SE, 2003, PROC SPIE, V5105, P137, DOI 10.1117/12.485960
   Wang J, 2016, INT J THEOR PHYS, V55, P1622, DOI 10.1007/s10773-015-2800-2
   Wang Ning, 2015, Chinese Journal of Quantum Electronics, V32, P263, DOI 10.3969/j.issn.1007-5461.2015.03.002
   Wang S, 2015, CHINESE J ELECTRON, V24, P321, DOI 10.1049/cje.2015.04.016
   Williams C.P., 2010, Explorations in quantum computing
   Yan F., 2017, THEOR COMPUT SCI
   Yang YG, 2014, QUANTUM INF PROCESS, V13, P1931, DOI 10.1007/s11128-014-0783-1
   Zhang WW, 2013, INT J THEOR PHYS, V52, P504, DOI 10.1007/s10773-012-1354-9
   Zhang Y, 2013, QUANTUM INF PROCESS, V12, P2833, DOI 10.1007/s11128-013-0567-z
   Zou JC, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 3, PROCEEDINGS, P965
   Zou Y, 2011, IEEE NUCL SCI CONF R, P3732, DOI 10.1109/NSSMIC.2011.6153704
NR 33
TC 4
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26489
EP 26515
DI 10.1007/s11042-020-09326-2
EA JUL 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000549313700007
OA Bronze
DA 2024-07-18
ER

PT J
AU Wu, C
   Li, YQ
   Zhang, YR
   Liu, J
   Liu, B
AF Wu, Chao
   Li, Yaqian
   Zhang, Yaru
   Liu, Jing
   Liu, Bin
TI Extreme learning machine with coefficient weighting and trained local
   receptive fields for image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Extreme learning machine; Local receptive fields; Coefficient weighting;
   Image classification
ID ALGORITHM
AB Local receptive fields based extreme learning machine (ELM-LRF) is widely used to solve image classification problems. However, the performance of ELM-LRF is limited by the single generation method of local receptive fields and the simple network structure. In order to solve these problems and make full use of image information to improve classification accuracy, extreme learning machine with coefficient weighting and trained local receptive fields (ELM-WLRF) is proposed based on ELM-LRF. The structure is mainly composed of convolution blocks, weighting blocks, dimensionality reduction and classification layers. In the convolution block, the principle of the ELM and the method of grouping calculation are used to train the local receptive fields of the two convolutional layers. The trained local receptive fields are used to extract identifiable feature information in the image more stably and adequately. In the weighting block, the principles of ELM and ELM autoencoder (ELM-AE) are used to train channel and spatial weighting coefficients to improve the recognizability of features. In the dimensionality reduction and classification layers, the approximate empirical kernel map (EKM) is used to train the connection weight matrix between each layer to further improve the network training speed and classification accuracy. To demonstrate the effectiveness of the proposed method, ELM-WLRF is tested on the MNIST, NORB and CIFAR-10 databases. The experimental results show that ELM-WLRF achieves superior classification accuracy, i.e. 99.27%, 98.03% and 60.14% respectively, and requires shorter training time compared with other state-of-the-art ELM-LRF-based algorithms.
C1 [Wu, Chao; Zhang, Yaru; Liu, Bin] Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.
   [Li, Yaqian; Liu, Jing] Yanshan Univ, Sch Elect Engn, Qinhuangdao 066004, Hebei, Peoples R China.
C3 Yanshan University; Yanshan University
RP Li, YQ (corresponding author), Yanshan Univ, Sch Elect Engn, Qinhuangdao 066004, Hebei, Peoples R China.
EM yddqb410@163.com
RI liu, bb/GXA-2527-2022; Zhang, Yaru/JEP-7689-2023
FU National Natural Science Foundation of China [51641609]; Natural Science
   Foundation of Hebei Province of China [F2019203320]
FX This work is supported by National Natural Science Foundation of China
   (No. 51641609), Natural Science Foundation of Hebei Province of China
   (No. F2019203320).
CR Chen J, 2018, NEUROCOMPUTING, V316, P49, DOI 10.1016/j.neucom.2018.07.050
   Vong C, 2018, NEUROCOMPUTING, V310, P265, DOI 10.1016/j.neucom.2018.05.032
   Dai HZ, 2019, NEURAL NETWORKS, V115, P11, DOI 10.1016/j.neunet.2019.03.004
   Deng WY, 2016, NEURAL NETWORKS, V76, P29, DOI 10.1016/j.neunet.2015.10.006
   Ding SF, 2017, NEURAL COMPUT APPL, V28, P1975, DOI 10.1007/s00521-015-2170-y
   dos Santos MM, 2019, NEUROCOMPUTING, V329, P359, DOI 10.1016/j.neucom.2018.10.063
   Franchini G, 2019, 2019 FIFTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP 2019), P1, DOI 10.1109/ICIIP47207.2019.8985831
   Han HG, 2014, NEUROCOMPUTING, V128, P128, DOI 10.1016/j.neucom.2013.01.057
   He B, 2019, MULTIDIM SYST SIGN P, V30, P1149, DOI 10.1007/s11045-018-0598-9
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2015, IEEE COMPUT INTELL M, V10, P18, DOI 10.1109/MCI.2015.2405316
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang JH, 2017, MULTIDIM SYST SIGN P, V28, P995, DOI 10.1007/s11045-016-0414-3
   Iosifidis A, 2016, IEEE T CYBERNETICS, V46, P311, DOI 10.1109/TCYB.2015.2401973
   Jia S, 2018, INT GEOSCI REMOTE SE, P1, DOI 10.1109/IGARSS.2018.8518351
   Jia XB, 2019, COGN COMPUT, V11, P101, DOI 10.1007/s12559-018-9596-3
   Kasun LLC, 2013, IEEE INTELL SYST, V28, P31
   Khellal A, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051490
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2004, PROC CVPR IEEE, P97
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li GQ, 2014, NEURAL COMPUT APPL, V24, P1683, DOI 10.1007/s00521-013-1398-7
   Liu HP, 2018, NEUROCOMPUTING, V277, P4, DOI 10.1016/j.neucom.2017.04.077
   Nayak DR, 2020, MULTIMED TOOLS APPL, V79, P15381, DOI 10.1007/s11042-019-7233-0
   Pan YT, 2020, WORLD WIDE WEB, V23, P2259, DOI 10.1007/s11280-020-00793-z
   Pang S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3049632
   Song G, 2020, APPL INTELL, V50, P1345, DOI 10.1007/s10489-019-01584-4
   Tang JX, 2016, IEEE T NEUR NET LEAR, V27, P809, DOI 10.1109/TNNLS.2015.2424995
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang YQ, 2016, NEUROCOMPUTING, V174, P988, DOI 10.1016/j.neucom.2015.10.035
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Yan DQ, 2018, SOFT COMPUT, V22, P677, DOI 10.1007/s00500-016-2372-y
   Yin YH, 2020, J AMB INTEL HUM COMP, V11, P4337, DOI 10.1007/s12652-018-1067-x
   Yoo YW, 2016, IEEE IJCNN, P1702, DOI 10.1109/IJCNN.2016.7727403
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Yu YL, 2018, IEEE ACCESS, V6, P30424, DOI 10.1109/ACCESS.2018.2845298
   Zhang BY, 2018, NEUROCOMPUTING, V275, P255, DOI 10.1016/j.neucom.2017.07.018
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
   Zhao Y, 2019, PHOSPHORUS CHEMISTRY: THE ROLE OF PHOSPHORUS IN PREBIOTIC CHEMISTRY, P1
NR 45
TC 0
Z9 0
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26389
EP 26410
DI 10.1007/s11042-020-09295-6
EA JUL 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000548791400002
DA 2024-07-18
ER

PT J
AU Muhammad, N
   Bibi, N
   Kamran, M
   Bashir, Y
   Park, S
   Kim, DG
AF Muhammad, Nazeer
   Bibi, Nargis
   Kamran, Muhammad
   Bashir, Yasir
   Park, Sangwoong
   Kim, Dai-Gyoung
TI Image noise reduction based on block matching in wavelet frame domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block mathcing; Edge enhancing; Image denoising; Shear wavelet frames;
   Minimum mean square error
ID REPRESENTATIONS; DICTIONARIES; ALGORITHM
AB This paper describes the shear wavelet frame transform (SWFT) with two sets of block matching for the application of image denoising. Using the SWFT, we can analyze anisotropic features, such as edges in images. To assign the directionality we use a shear matrix for the continuous wavelet transform. Block matching with 3-D collaborative filtering has been incorporated for hard thresholding of reference block. We deploy two sets of the search neighborhood blocks to avoid the artifacts while removing heavy noise. The proposed algorithm is evaluated on standard benchmark images and outperforms the recent state-of-the-art methods in terms of peak signal to noise ratio.
C1 [Muhammad, Nazeer] Pak Austria Fachhsch Inst Appl Sci & Technol, Dept IT & Comp Sci Software Engn, Mang Khanpur Rd, Haripur, Pakistan.
   [Bibi, Nargis] Fatima Jinnah Women Univ, Dept Comp Sci, Rawalpindi, Pakistan.
   [Kamran, Muhammad; Bashir, Yasir] COMSATS Univ Islamabad, Dept Math, Wah Campus, Rawalpindi, Pakistan.
   [Park, Sangwoong; Kim, Dai-Gyoung] Hanyang Univ, Dept Appl Math, Ansan 426791, South Korea.
C3 COMSATS University Islamabad (CUI); Hanyang University
RP Kim, DG (corresponding author), Hanyang Univ, Dept Appl Math, Ansan 426791, South Korea.
EM dnmuhammad@paf-iast.edu.pk; nargis@fjwu.edu.pk;
   m.kamranyasirbashir@ciitwah.edu.pk; yasirbashir@ciitwah.edu.pk;
   swp1111@hanmail.net; dgkim@hanyang.ac.kr
RI Muhammad, Nazeer/M-5653-2018; Bibi, Nargis/ABE-6506-2021; Kamran,
   Muhammad/ABI-1747-2020
OI Kamran, Muhammad/0000-0003-0781-0332
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 1995, OXFORD MATH MONOGRAP
   [Anonymous], 1995, Wavelets and Operators
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Candès EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Easley GR, 2006, CONF REC ASILOMAR C, P974, DOI 10.1109/ACSSC.2006.354897
   Iwata M, 2004, IEICE T FUND ELECTR, VE87A, P929
   Kervrann C, 2007, LECT NOTES COMPUT SC, V4485, P520
   Khalid S, 2019, IET INTELL TRANSP SY, V13, P269, DOI 10.1049/iet-its.2018.5223
   Kutyniok G, 2009, T AM MATH SOC, V361, P2719
   Lebrun M, 2013, SIAM J IMAGING SCI, V6, P1665, DOI 10.1137/120874989
   Lebrun M, 2012, IMAGE PROCESS ON LIN, V2, P175, DOI 10.5201/ipol.2012.l-bm3d
   Levin A, 2013, 2011 IEEE C COMP VIS, P2833
   Lim WQ, 2010, IEEE T IMAGE PROCESS, V19, P1166, DOI 10.1109/TIP.2010.2041410
   Lin CY, 2008, IEICE T INF SYST, VE91D, P836, DOI 10.1093/ietisy/e91-d.3.836
   Lu YX, 2015, J ELECTR COMPUT ENG, V2015, DOI 10.1155/2015/459285
   Mahmoud MI, 2007, PROC WRLD ACAD SCI E, V20, P68
   Muhammad N, 2018, PATTERN ANAL APPL, V21, P997, DOI 10.1007/s10044-017-0613-z
   Pakdelazar O, 2011, ARXIV11122386
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Salmon J, 2010, IEEE SIGNAL PROC LET, V17, P269, DOI 10.1109/LSP.2009.2038954
   Wu Y, 2013, IEEE SIGNAL PROC LET, V20, P763, DOI 10.1109/LSP.2013.2263135
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
NR 25
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26327
EP 26344
DI 10.1007/s11042-020-09158-0
EA JUL 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000548495600002
DA 2024-07-18
ER

PT J
AU Niyishaka, P
   Bhagvati, C
AF Niyishaka, Patrick
   Bhagvati, Chakravarthy
TI Copy-move forgery detection using image blobs and BRISK feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BRISK; Blob; CMF; CMFD; DoG; LoG
AB One of the most frequently used types of digital image forgery is copying one area in the image and pasting it into another area of the same image; this is known as the copy-move forgery. To overcome the limitations of the existing Block-based and Keypoint-based copy-move forgery detection methods, in this paper, we present an effective technique for copy-move forgery detection that utilizes the image blobs and keypoints. The proposed method is based on the image blobs and Binary Robust Invariant Scalable Keypoints (BRISK) feature. It involves the following stages: the regions of interest called image blobs and BRISK feature are found in the image being analyzed; BRISK keypoints that are located within the same blob are identified; finally, the matching process is performed between BRISK keypoints that are located in different blobs to find similar keypoints for copy-move regions. The proposed method is implemented and evaluated on the copy-move forgery standard datasets MICC-F8multi, MICC-F220, and CoMoFoD. The experimental results show that the proposed method is effective for geometric transformation, such as scaling and rotation, and shows robustness to post-processing operation, such as noise addition, blurring, and jpeg compression.
C1 [Niyishaka, Patrick; Bhagvati, Chakravarthy] Univ Hyderabad, Hyderabad, Telangana, India.
C3 University of Hyderabad
RP Niyishaka, P (corresponding author), Univ Hyderabad, Hyderabad, Telangana, India.
EM niyishakapatrick@gmail.com
OI Patrick, Niyishaka/0000-0003-4200-335X
CR Abd Warif NB, 2016, J NETW COMPUT APPL, V75, P259, DOI 10.1016/j.jnca.2016.09.008
   Ai-Jhen C, 2019, COPY MOVE FORGERY DE
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], INT J LATEST ENG RES
   Behnaz E, 2019, MULTIMEDIA TOOLS APP
   Christlein V, 2012, ARXIV12083665
   Dijana T, 2013, COMOFOD NEW DATABASE
   Emre G, 2019, SECURITY COMMUNICATI
   Faten MAA, 2020, MULTIMEDIA TOOLS APP
   Hashmi MF, 2014, AASRI PROC, V9, P84, DOI 10.1016/j.aasri.2014.09.015
   Jun YP, 2020, SYMMETRY
   Kaur H., 2015, INT C J ELECT ELECT, V4, P62
   Kong H, 2013, IEEE T CYBERNETICS, V43, P1719, DOI 10.1109/TSMCB.2012.2228639
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Lin C, 2019, MULTIMED TOOLS APPL, V78, P30081, DOI 10.1007/s11042-018-6922-4
   Lin C, 2018, MULTIMED TOOLS APPL, V77, P14241, DOI 10.1007/s11042-017-5027-9
   Lindeberg T., 2008, Encyclopedia of Computer Science and Engineering, V4, P2495, DOI DOI 10.1002/9780470050118.ECSE609
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahdi M, 2020, DETECTION COPY MOVE
   Mahmood T, 2018, APPL INTELL, V48, P1791, DOI 10.1007/s10489-017-1038-5
   Malviya AV, 2016, PROCEDIA COMPUT SCI, V79, P383, DOI 10.1016/j.procs.2016.03.050
   Niyishaka P, 2018, ICCVG 2018, P472, DOI [10.1007/978-3-030-00692-1_41, DOI 10.1007/978-3-030-00692-1_41]
   Ojeniyi Joseph A., 2018, International Journal of Image, Graphics and Signal Processing, V10, P22, DOI 10.5815/ijigsp.2018.04.03
   Pavlovic A, 2019, MULTIMED TOOLS APPL, V78, P20655, DOI 10.1007/s11042-019-7277-1
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Saini GK, 2016, STUDY COPY MOVE IMAG
   Sobel I, 2014, PRESENTATION STANFOR, V1968, P271
   Soni B, 2018, IET IMAGE PROCESS, V12, P167, DOI 10.1049/iet-ipr.2017.0441
   Tareen Shaharyar Ahmed Khan, 2018, 2018 International Conference on Computing, Mathematics and Engineering Technologies (iCoMET). Proceedings, DOI 10.1109/ICOMET.2018.8346440
   Zhu Y, 2016, MULTIMED TOOLS APPL, V75, P3221, DOI 10.1007/s11042-014-2431-2
NR 30
TC 31
Z9 32
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26045
EP 26059
DI 10.1007/s11042-020-09225-6
EA JUL 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000546532000001
DA 2024-07-18
ER

PT J
AU Jiang, CJ
   Li, HT
   Zhou, SB
   Zhang, ZH
   Yu, J
   Chen, L
   Xie, XZ
AF Jiang, Changjiang
   Li, Hantao
   Zhou, Shangbo
   Zhang, Zihan
   Yu, Jim
   Chen, Long
   Xie, Xianzhong
TI Image interpolation model based on packet losing network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image super-resolution; Packet loss; Packet loss compensation;
   Interpolation; Error hiding; Pixel span
ID REPRESENTATION; CONCEALMENT
AB In this paper, a method combining an error hiding algorithm with image super-resolution reconstruction is proposed, which uses packet loss compensation as an alternative to traditional reconstruction processes. Our algorithm provides an alternative to traditional frameworks by firstly estimating the edge direction of the block and then interpolating along the edge direction. We define a pixel span function to obtain the missing image details, and the pixels are reconstructed using this function to detect their possible textures. Experiments using established image data sets show that comparison with seven other classical image interpolation algorithms, the proposed approach achieves both higher quantitative and qualitative performance results, ultimately providing better visual effects.
C1 [Jiang, Changjiang; Li, Hantao; Zhou, Shangbo; Yu, Jim; Chen, Long; Xie, Xianzhong] Chongqing Univ Posts & Telecommun, Coll Automat, Chongqing 400065, Peoples R China.
   [Zhou, Shangbo; Zhang, Zihan] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
   [Xie, Xianzhong] Chongqing Key Lab Comp Network & Commun Technol, Chongqing 400065, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; Chongqing University
RP Zhou, SB (corresponding author), Chongqing Univ Posts & Telecommun, Coll Automat, Chongqing 400065, Peoples R China.; Zhou, SB (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
EM shbzhou@cqu.edu.cn
RI yu, jim/GWZ-5637-2022
FU Guangxi Colleges and Universitied Key Laboratory of Intelligent
   Processing of Computer Images and Graphics [GIIP1806]; Chongqing Key Lab
   of Computer Network [CY-CNCL-2017-02]
FX This work was supported by Guangxi Colleges and Universitied Key
   Laboratory of Intelligent Processing of Computer Images and Graphics
   (No. GIIP1806) and Chongqing Key Lab of Computer Network and
   Communciation Technologogy (CY-CNCL-2017-02).
CR Akai N, 2017, IEEE INT C INTELL TR
   An FP, 2019, J MATH IMAGING VIS, V61, P1243, DOI 10.1007/s10851-019-00899-8
   [Anonymous], 2013, P 2013 IEEE INT C CO
   [Anonymous], 2018, IEEE T IMAGE PROCESS
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Costarelli D, 2020, APPL MATH COMPUT, V374, DOI 10.1016/j.amc.2020.125046
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1382, DOI 10.1109/TIP.2012.2231086
   DUCHON CE, 1979, J APPL METEOROL, V18, P1016, DOI 10.1175/1520-0450(1979)018<1016:LFIOAT>2.0.CO;2
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Huang J, 2015, IEEE IC COMP COM NET
   Jaehwan, 2015, OPTIK INT J LIGHT EL
   Qaratlu MM, 2011, SIGNAL PROCESS-IMAGE, V26, P304, DOI 10.1016/j.image.2011.04.004
   Romano Y, 2014, IEEE T IMAGE PROCESS, V23, P3085, DOI 10.1109/TIP.2014.2325774
   Singh A, 2020, MULTIMED TOOLS APPL, V79, P1641, DOI 10.1007/s11042-019-08254-0
   Sun D, 2016, DIGIT SIGNAL PROCESS, V49, P33, DOI 10.1016/j.dsp.2015.11.003
   Superiori Luca, 2012, ERROR CONCEALMENT AN
   Timofte R., 2014, ADJUSTED ANCHORED NE
   UNSER M, 1991, IEEE T PATTERN ANAL, V13, P277, DOI 10.1109/34.75515
   van Ouwerkerk JD, 2006, IMAGE VISION COMPUT, V24, P1039, DOI 10.1016/j.imavis.2006.02.026
   Yang J. F. K., 2006, EURASIP J ADV SIGNAL, V2006
   Yilmaz A, 2008, SIGNAL PROCESS-IMAGE, V23, P298, DOI 10.1016/j.image.2008.03.003
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zeyde R., 2010, INTERNATIONAL CONFER
   Zhang LP, 2011, J OPT SOC AM A, V28, P381, DOI 10.1364/JOSAA.28.000381
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
NR 26
TC 2
Z9 2
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25785
EP 25800
DI 10.1007/s11042-020-09255-0
EA JUL 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000546222500002
DA 2024-07-18
ER

PT J
AU Qi, ZM
AF Qi, Zhimin
TI A novel video delivery mechanism for caching-enabled networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Caching-enabled networks; Video delivery; Popularity modelling; Light
   mechanism; DPDK
AB The caching-enabled networks, especially Information-Centric Networking (ICN), have attracted much attention from some global research communities, and the corresponding achievements have been highlighted in the field of video delivery. This paper studies more effective video delivery mechanism in order to guarantee better network performance based on two conceptions, i.e., the intermediate caching of popular video segments and the light delivery of identity object. At first, we evaluate the popularity under the dynamic environment, including descending modelling, ascending modelling and period modelling. Then, we propose identity-based light video delivery mechanism; in particular, we introduce Data Plane Development Kit (DPDK) to ensure that all video segments have the same size and to accelerate video transmission by bypassing the kernel. Finally, the simulation experiments are made based on the real YouTube dataset over CERNET network topology, and the results demonstrate that the proposed video delivery mechanism outperforms two the-state-of-the-art mechanisms in terms of cache hit ratio, routing hop count, delivery delay and network load.
C1 [Qi, Zhimin] Jilin Normal Univ, Sch Media, Siping 136000, Peoples R China.
C3 Jilin Normal University
RP Qi, ZM (corresponding author), Jilin Normal Univ, Sch Media, Siping 136000, Peoples R China.
EM qizhimin1983@sina.com
FU Jilin Provincial Social Science Planning Project [2018JD55]
FX This work is supported by Jilin Provincial Social Science Planning
   Project (Grant No. 2018JD55).
CR Anjum N, 2017, COMPUT NETW, V116, P79, DOI 10.1016/j.comnet.2017.02.008
   Azgin A, 2018, INT CONF COMPUT NETW, P105, DOI 10.1109/ICCNC.2018.8390241
   Baake P, 2019, INF ECON POLICY, V46, P55, DOI 10.1016/j.infoecopol.2019.01.003
   Batista P, 2019, COMPUT NETW, V150, P70, DOI 10.1016/j.comnet.2018.12.013
   Bourtsoulatze E, 2018, IEEE T MULTIMEDIA, V20, P1561, DOI 10.1109/TMM.2017.2767778
   Cheng X, 2008, INT WORKSH QUAL SERV, P249
   Feng ZG, 2017, IEEE T CYBERNETICS, V47, P661, DOI 10.1109/TCYB.2016.2523544
   Frangoudis PA, 2016, COMPUT NETW, V105, P207, DOI 10.1016/j.comnet.2016.06.004
   Garmehi M, 2014, COMPUT COMMUN, V52, P60, DOI 10.1016/j.comcom.2014.06.007
   Ghasemkhani H, 2018, PROD OPER MANAG, V27, P1940, DOI 10.1111/poms.12718
   Gramatikov S, 2012, P INT C ADV MULT, P14
   Gussun G, 2017, COMPUT COMMUN, V106, P86, DOI [10.1016/j.comcom.2017.02.012, DOI 10.1016/J.COMCOM.2017.02.012]
   Haw R, 2012, P AS PAC S NETW OP M, P1
   Ibn-Khedher H, 2017, COMPUT NETW, V120, P12, DOI 10.1016/j.comnet.2017.04.009
   Lai J, 2017, COMPUT NETW, V113, P176, DOI 10.1016/j.comnet.2016.12.010
   Li JN, 2019, FUTURE GENER COMP SY, V100, P759, DOI 10.1016/j.future.2019.05.067
   Lv JH, 2017, COMPUT NETW, V126, P200, DOI 10.1016/j.comnet.2017.07.004
   Matsushita T, 2011, LNCS, P121
   Mawji A, 2011, J ADV RES, V2, P265, DOI 10.1016/j.jare.2011.05.003
   Ren YM, 2017, FUTURE GENER COMP SY, V74, P12, DOI 10.1016/j.future.2017.04.013
   Shehab A, 2018, STUD BIG DATA, V33, P207, DOI 10.1007/978-3-319-63639-9_9
   Shen HY, 2018, ACM T INTERNET TECHN, V18, DOI 10.1145/3137569
   Son J, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P220, DOI 10.1109/ICOIN.2016.7427118
   Tang LP, 2017, 2017 USENIX ANNUAL TECHNICAL CONFERENCE (USENIX ATC '17), P111
   Xylomenos G, 2014, IEEE COMMUN SURV TUT, V16, P1024, DOI 10.1109/SURV.2013.070813.00063
   You W, 2013, 2013 EIGHTH INTERNATIONAL CONFERENCE ON P2P, PARALLEL, GRID, CLOUD AND INTERNET COMPUTING (3PGCIC 2013), P179, DOI 10.1109/3PGCIC.2013.33
   Zhang X, 2015, COMPUT NETW, V91, P577, DOI 10.1016/j.comnet.2015.08.035
   Zhao HK, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/3078848
NR 28
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25535
EP 25549
DI 10.1007/s11042-020-09208-7
EA JUL 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000545292000003
DA 2024-07-18
ER

PT J
AU Wang, C
   Zhu, SF
   Lyu, DS
   Sun, XS
AF Wang, Chen
   Zhu, Shifan
   Lyu, Desheng
   Sun, Xiaoshuai
TI What is damaged: a benchmark dataset for abnormal traffic object
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic object classification; Attention mechanism; Sample pairing
ID DISCOVERY
AB Traffic-related multimedia analysis has become increasingly important in both research community and industry. In this paper, we study the problem of image-based classification of abnormal traffic objects. Different from previous works that focusing on only the normal object categories, our work aims to classify both the category and the working status of a traffic object. We construct a new dataset, namely Abnormal Traffic Object Classification (ATOC), for the study of the above problem. ATOC contains 6 kinds of traffic objects and for each main category there are also two sub-categories covering the normal and abnormal status of the objects. We propose a novel deep-learning based framework to solve our problem and provide a strong baseline for future studies. Specifically, we adopt a pre-trained deep convolutional network for feature extraction and use support vector machine for classification. We also utilize random sample pairing to augment the dataset and introduce attention mechanism to further refine the feature representation. Experimental results demonstrate that the proposed method achieves superior performance than the state-of-art deep learning approaches for the recognition of objects' categories and the corresponding working status in traffic scenarios.
C1 [Wang, Chen] Harbin Engn Univ, Harbin, Peoples R China.
   [Zhu, Shifan] Harbin Engn Univ, Dept Ind Design, Harbin, Peoples R China.
   [Wang, Chen; Lyu, Desheng] Harbin Inst Technol, Key Lab Interact Media Design & Equipment Serv In, Minist Culture, Harbin, Peoples R China.
   [Sun, Xiaoshuai] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Peoples R China.
C3 Harbin Engineering University; Harbin Engineering University; Harbin
   Institute of Technology; Harbin Institute of Technology
RP Wang, C (corresponding author), Harbin Engn Univ, Harbin, Peoples R China.; Wang, C (corresponding author), Harbin Inst Technol, Key Lab Interact Media Design & Equipment Serv In, Minist Culture, Harbin, Peoples R China.
EM chwang@hit.edu.cn; zhushifan@hrbeu.edu.cn; deshengl@hit.edu.cn;
   xiaoshuaisun@hit.edu.cn
CR [Anonymous], 2015, VER DEEP CONV NETW L
   [Anonymous], 2018, COMPUT VIS IMAGE UND
   Bin Y, 2019, IEEE T CYBERNETICS, V49, P2631, DOI 10.1109/TCYB.2018.2831447
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Cheng ZY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3748
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Guo YY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3295822
   Han B, 2018, ADV NEUR IN, V31
   Hu MQ, 2018, IEEE T IMAGE PROCESS, V27, P545, DOI 10.1109/TIP.2017.2749147
   Inoue H., 2018, arXiv
   Khosla A., 2011, P CVPR WORKSH FIN GR
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kümmerer M, 2017, IEEE I CONF COMP VIS, P4799, DOI 10.1109/ICCV.2017.513
   Li C, 2017, IEEE T IMAGE PROCESS, V26, P2149, DOI 10.1109/TIP.2017.2670782
   Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531
   Liao L, 2015, IEEE IMAGE PROC, P745, DOI 10.1109/ICIP.2015.7350898
   Lin YL, 2014, LECT NOTES COMPUT SC, V8692, P466, DOI 10.1007/978-3-319-10593-2_31
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma H, 2009, ICICTA: 2009 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTATION TECHNOLOGY AND AUTOMATION, VOL II, PROCEEDINGS, P541, DOI 10.1109/ICICTA.2009.365
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Shen FM, 2017, IEEE T MULTIMEDIA, V19, P2022, DOI 10.1109/TMM.2017.2699863
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sochor J, 2016, PROC CVPR IEEE, P3006, DOI 10.1109/CVPR.2016.328
   Stark M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.36
   Sun XS, 2017, AAAI CONF ARTIF INTE, P182
   Sun XS, 2017, AAAI CONF ARTIF INTE, P274
   Sun XS, 2014, IEEE T IMAGE PROCESS, V23, P4649, DOI 10.1109/TIP.2014.2337758
   Sun XS, 2013, J VIS COMMUN IMAGE R, V24, P171, DOI 10.1016/j.jvcir.2012.01.014
   Sun XS, 2012, PROC CVPR IEEE, P1552, DOI 10.1109/CVPR.2012.6247846
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023
   Yang Y, 2018, IEEE T IMAGE PROCESS, V27, P5600, DOI 10.1109/TIP.2018.2855422
   Zeng ZQ, 2018, IEEE T IND INFORM, V14, P3179, DOI 10.1109/TII.2017.2767557
   Zhuo T, 2018, ARXIV181003783
NR 45
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18481
EP 18494
DI 10.1007/s11042-019-08265-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800053
DA 2024-07-18
ER

PT J
AU Wong, KW
   Yap, WS
   Wong, DCK
   Phan, RCW
   Goi, BM
AF Wong, Kuan-Wai
   Yap, Wun-She
   Wong, Denis C-K
   Phan, Raphael C-W
   Goi, Bok-Min
TI Cryptanalysis of genetic algorithm-based encryption scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic map; Genetic algorithm; Encryption; Known plaintext attack;
   Pseudorandom bit sequence generator
ID MODEL; MAP
AB Genetic algorithm, a technique inspired by evolutionary biology to mimic the process of natural selection, has been applied in the image encryption due to the confusion and diffusion properties of mutation and crossover processes involved in the genetic algorithm. In this paper, we analyze the security of the image encryption designed based on genetic algorithms. We perform a known plaintext attack on Biswas et al. image encryption scheme designed based on chaotic maps and genetic algorithms. We show that the encryption scheme is not as secure as claimed by Biswas et al. since the proposed attack reduces the claimed 448-bit security to 264.28-bit security. The proposed attack and its analysis can be utilized and extended to other image encryption schemes designed based on genetic algorithms.
C1 [Wong, Kuan-Wai; Yap, Wun-She; Wong, Denis C-K; Goi, Bok-Min] Univ Tunku Abdul Rahman, Lee Kong Chian Fac Engn & Sci, Kajang, Selangor, Malaysia.
   [Phan, Raphael C-W] Monash Univ, Sch IT, Subang Jaya, Selangor, Malaysia.
C3 Universiti Tunku Abdul Rahman (UTAR); Monash University; Monash
   University Malaysia
RP Wong, KW (corresponding author), Univ Tunku Abdul Rahman, Lee Kong Chian Fac Engn & Sci, Kajang, Selangor, Malaysia.
EM wongkw@utar.edu.my
RI Yap, Wun-She/ABB-5158-2021; Phan, Raphael C.-W./I-7266-2013; Wong, Kuan
   Wai/Q-3718-2017
OI Wong, Kuan Wai/0000-0002-5982-873X
FU Universiti Tunku Abdul Rahman (UTAR) under UTAR Research Fund (UTARRF)
   [6200/W60]
FX This research was supported by Universiti Tunku Abdul Rahman (UTAR)
   under UTAR Research Fund (UTARRF) no. 6200/W60.
CR Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Abuhaiba I.S. I., 2011, SIGNAL IMAGE PROCESS, V2, P51, DOI [10.5121/sipij.2011.2105, DOI 10.5121/SIPIJ.2011.2105]
   Biham E., 1994, P FAST SOFTWARE ENCR, P144
   Biswas K, 2015, IEEE SENS J, V15, P2801, DOI 10.1109/JSEN.2014.2380816
   Daemen J., 2013, DESIGN RIJNDAEL AES
   Das Subhajit, 2018, Intelligent Engineering Informatics. Proceedings of the 6th International Conference on FICTA. Advances in Intelligent Systems and Computing (AISC 695), P19, DOI 10.1007/978-981-10-7566-7_3
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Enayatifar R, 2013, OPT LASER ENG, V51, P1066, DOI 10.1016/j.optlaseng.2013.03.010
   Fang Q, 2008, KYBERNETIKA, V44, P522
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Guesmi R, 2016, MULTIMED TOOLS APPL, V75, P4753, DOI 10.1007/s11042-015-2501-0
   Holland J. H., 1992, Scientific American (International Edition), V267, P44, DOI 10.1038/scientificamerican0792-66
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   LAI XJ, 1991, LECT NOTES COMPUT SC, V473, P389
   National Bureau of Standards, 1977, FIPS PUB, V46
   Nematzadeh H, 2018, OPT LASER ENG, V110, P24, DOI 10.1016/j.optlaseng.2018.05.009
   Premkumar R, 2018, MULTIMED TOOLS APPL, P1
   Ravichandran D, 2016, COMPUT BIOL MED, V72, P170, DOI 10.1016/j.compbiomed.2016.03.020
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Sivanandam S., 2008, INTRO GENETIC ALGORI, P15, DOI [10.1007/978-3-540-73190-0_2, DOI 10.1007/978-3-540-73190-0_2]
   Suganthi S, 2012, PR ELECTROMAGN RES S, P783
   Wang XY, 2014, NONLINEAR DYNAM, V78, P2975, DOI 10.1007/s11071-014-1639-z
   Yap WS, 2016, J VIS COMMUN IMAGE R, V40, P51, DOI 10.1016/j.jvcir.2016.06.005
NR 23
TC 11
Z9 11
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25259
EP 25276
DI 10.1007/s11042-020-09191-z
EA JUL 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000544843700007
DA 2024-07-18
ER

PT J
AU Castelló, A
   Chavez, D
   Cladellas, R
AF Castello, Antoni
   Chavez, David
   Cladellas, Ramon
TI Association between slides-format and Major's contents: effects on
   perceived attention and significant learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE University contents; Significant learning; Attention; Format of slides;
   Slide-presentation
ID MEDICAL-STUDENTS; SUBJECT-MATTER; POWERPOINT; DISCIPLINES; TEXT;
   ANIMATIONS; LECTURES; MODALITY
AB The use of slide-presentations has become ubiquitous in university majors. Previous research has focused on its general effectiveness, although results are not clearly consistent. The format of the slides has been analysed in few cases and its correspondence with the specific disciplines has never been considered. This study focuses on the perceived attention and significant learning declared by students, connected with the format of the slides predominantly used in different majors. A sample of 1316 university students, distributed in 54 courses in 11 majors that represent Pure Sciences, Health Sciences, Social Sciences and Engineering was surveyed. Results showed a differential use of visual and textual slides, as well as a clear effect on perceived attention and significant learning when majors were compared. Although the slide-format was expected to be the central variable to explain these results, the complete explanation involves the correspondence of the slide-format with the nature of the contents. In some majors, the use of slides was even counterproductive and the widespread idea that visual format is more effective in general was not supported by results. Conclusions linking format and contents can be generalised to any educational setting.
C1 [Castello, Antoni; Cladellas, Ramon] Univ Autonoma Barcelona, Dept Basic Dev & Educ Psychol, Barcelona, Spain.
   [Chavez, David] Univ Austral Chile, Inst Pedag Specialties, Puerto Mt, Chile.
C3 Autonomous University of Barcelona; Universidad Austral de Chile
RP Cladellas, R (corresponding author), Univ Autonoma Barcelona, Dept Basic Dev & Educ Psychol, Barcelona, Spain.
EM toni.castello@uab.es; dchavez.herting@gmail.com; ramon.cladellas@uab.es
RI Cladellas, Ramon/P-4201-2019; Chavez-Herting, David/AAT-4412-2020
OI Cladellas, Ramon/0000-0002-0801-8462; Chavez-Herting,
   David/0000-0003-4700-0588; Castello, Antoni/0000-0003-1974-5339
CR Amare N., 2006, J TECH WRIT COMMUN, V36, P297
   [Anonymous], 2014, CAMBRIDGE HDB MULTIM, DOI DOI 10.1017/CBO9780511816819.009
   [Anonymous], 2010, The ECAR Study of Undergraduate Students and Information Technology, 2010
   [Anonymous], 1999, INSTRUCTIONAL DESIGN
   Armour C, 2016, ADV PHYSIOL EDUC, V40, P229, DOI 10.1152/advan.00130.2015
   Baker JP, 2018, COMPUT EDUC, V126, P376, DOI 10.1016/j.compedu.2018.08.003
   Bartsch RA, 2003, COMPUT EDUC, V41, P77, DOI 10.1016/S0360-1315(03)00027-7
   BIGLAN A, 1973, J APPL PSYCHOL, V57, P204, DOI 10.1037/h0034699
   BIGLAN A, 1973, J APPL PSYCHOL, V57, P195, DOI 10.1037/h0034701
   Bohay M, 2011, AM J PSYCHOL, V124, P63, DOI 10.5406/amerjpsyc.124.1.0063
   Bolkan S, 2019, COMMUN EDUC, V68, P61, DOI 10.1080/03634523.2018.1517895
   Braxton J.M., 1995, New Directions of Teaching and Learning, V64, P59, DOI [10.1002/tl.37219956409, DOI 10.1002/tl.37219956409]
   Burke LA, 2009, J EDUC BUS, V84, P246, DOI 10.3200/JOEB.84.4.246-251
   Cashin W., 1995, NEW DIRECTIONS TEACH, P81
   Castelló Antoni, 2013, Estud. pedagóg., V39, P41
   Pros RC, 2013, INTANG CAP, V9, P184, DOI 10.3926/ic.370
   CLADELLAS R, 2017, INTANGIBLE CAPITAL, V13, P302, DOI DOI 10.3926/IC.814
   Costa ML, 2007, MED EDUC, V41, P214, DOI 10.1111/j.1365-2929.2006.02677.x
   Franklin J., 1995, Disciplinary differences in teaching and learning: Implications for practice, V64, P41
   Garret N., 2015, Journal of Educational Technology, V44, P69, DOI DOI 10.1177/0047239515598521
   Garrett N, 2016, INNOV HIGH EDUC, V41, P365, DOI 10.1007/s10755-016-9381-8
   Ginns P, 2005, LEARN INSTR, V15, P313, DOI 10.1016/j.learninstruc.2005.07.001
   Gladic-Miralles Jadranka, 2018, Estud. pedagóg., V44, P293
   Hartnett N., 2003, Accounting Education, V12, P313
   Hill A, 2012, TEACH SOCIOL, V40, P242, DOI 10.1177/0092055X12444071
   Hughes I.E., 2003, BEE J, V1, P1, DOI [10.3108/beej.2003.01010001, DOI 10.3108/beej.2003.01010001]
   Koc-Januchta MM, 2019, J COMPUT ASSIST LEAR, V35, P747, DOI 10.1111/jcal.12381
   Koles PG, 2010, ACAD MED, V85, P1739, DOI 10.1097/ACM.0b013e3181f52bed
   Lin LJ, 2011, COMPUT EDUC, V56, P650, DOI 10.1016/j.compedu.2010.10.007
   Mason L, 2013, COMPUT EDUC, V60, P95, DOI 10.1016/j.compedu.2012.07.011
   Mayer R.E., 2014, The Cambridge Handbok of Multimedia Learning, V4th, P43, DOI DOI 10.1017/CBO9781139547369.005
   Mayer R.E., 1999, INT J EDUC RES, V31, P611, DOI DOI 10.1016/S0883-0355(99)00027-0
   Mayer RE, 2002, EDUC PSYCHOL REV, V14, P87, DOI 10.1023/A:1013184611077
   Mayer RE, 2008, J EDUC PSYCHOL, V100, P380, DOI 10.1037/0022-0663.100.2.380
   Mayer RE, 2009, MULTIMEDIA LEARNING, 2ND EDITION, P1
   Moreno R, 1999, J EDUC PSYCHOL, V91, P358, DOI 10.1037/0022-0663.91.2.358
   Paas F, 2003, EDUC PSYCHOL, V38, P1, DOI 10.1207/S15326985EP3801_1
   Paas F., 2014, The Cambridge handbook of multimedia learning, V27, P42
   Paivio A., 1986, Mental representations: A dual coding approach
   Parodi G, 2010, RLA-REV LINGUIST TEO, V48, P33
   Richardson D, 2008, ADV PHYSIOL EDUC, V32, P23, DOI 10.1152/advan.00048.2007
   Rickman J., 2000, EDUCAUSE Q, V23, P24
   Roehling PV, 2011, TECHNOL PEDAGOG EDUC, V20, P113, DOI 10.1080/1475939X.2011.554018
   Schnotz W, 2003, LEARN INSTR, V13, P141, DOI 10.1016/S0959-4752(02)00017-8
   Schnotz W, 2005, CAMBRIDGE HDB MULTIM, V49, P69
   Schüler A, 2015, LEARN INSTR, V35, P62, DOI 10.1016/j.learninstruc.2014.09.005
   Schweppe J, 2016, COMPUT HUM BEHAV, V60, P131, DOI 10.1016/j.chb.2016.02.035
   Seth V, 2010, ADV MED EDUC PRACT, V1, P11, DOI 10.2147/AMEP.S12154
   SMART JC, 1982, RES HIGH EDUC, V17, P213, DOI 10.1007/BF00976699
   SMART JC, 1975, J APPL PSYCHOL, V60, P580, DOI 10.1037/0021-9010.60.5.580
   Sweller J, 1998, EDUC PSYCHOL REV, V10, P251, DOI 10.1023/A:1022193728205
   Sweller J, 2010, COGNITIVE LOAD THEOR, P141
   Sweller J., 1994, Learning and instruction, P295, DOI DOI 10.1016/0959-4752(94)90003-5
   van der Meij J, 2006, LEARN INSTR, V16, P199, DOI 10.1016/j.learninstruc.2006.03.007
   Webber KL, 2012, RES HIGH EDUC, V53, P201, DOI 10.1007/s11162-011-9245-0
   Yang WC, 2015, MULTIMED TOOLS APPL, V74, P1003, DOI 10.1007/s11042-013-1708-1
NR 56
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24969
EP 24992
DI 10.1007/s11042-020-09170-4
EA JUN 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000543678900004
DA 2024-07-18
ER

PT J
AU Ling, HF
   Chen, Y
   Chen, JZ
   Wu, L
   Shi, YX
   Deng, J
AF Ling, Hefei
   Chen, Yao
   Chen, Jiazhong
   Wu, Lei
   Shi, Yuxuan
   Deng, Jing
TI XwiseNet: action recognition with Xwise separable convolutions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Deep learning; Three-dimensional convolutional
   neural networks; Lightweight
AB With the emergence of a large number of video resources, video action recognition is attracting much attention. Recently, realizing the outstanding performance of three-dimensional (3D) convolutional neural networks (CNNs), many works have began to apply it for action recognition and obtained satisfactory results. However, little attention has been paid to reduce the model size and computation cost of 3D CNNs. In this paper, we first propose a novel 3D convolution called the Xwise Separable Convolution, then we construct an original 3D CNN called the XwiseNet. Our work aims to make 3D CNNs lightweight without reducing its recognition accuracy. Our key idea is extremely decoupling the 3D convolution in channel, spatial and temporal dimensions. Experiments have verified that the XwiseNet outperforms 3D-ResNet-50 on the Mini-Kinetics benchmark with only 6% training parameters and 12% computation cost.
C1 [Ling, Hefei; Chen, Yao; Chen, Jiazhong; Wu, Lei; Shi, Yuxuan] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
   [Deng, Jing] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
C3 Huazhong University of Science & Technology; Zhejiang University
RP Chen, Y (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
EM cy423@hust.edu.cn
FU Natural Science Foundation of China [U1536203, 61972169]; National key
   research and development program of China [2016QY01W0200]; Major
   Scientific and Technological Project of Hubei Province [2018AAA068,
   2019AAA051]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant U1536203 and 61972169, in part by the National key
   research and development program of China(2016QY01W0200), in part by the
   Major Scientific and Technological Project of Hubei Province (2018AAA068
   and 2019AAA051).
CR Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen Y, 2019, DROP OCTAVE REDUCING
   Chen YP, 2018, LECT NOTES COMPUT SC, V11205, P364, DOI 10.1007/978-3-030-01246-5_22
   Courtney PG, 2015, IEEE COMP SEMICON
   Diba A, 2017, TEMPORAL 3D CONVNETS
   Dollar P., 2005, Behavior recognition via sparse spatiotemporal feature
   Ekim G, 2008, 2008 IEEE 16TH SIGNAL PROCESSING, COMMUNICATION AND APPLICATIONS CONFERENCE, VOLS 1 AND 2, P18
   Feichtenhofer C, 2019, SLOW FAST NETWORKS V, P16201, DOI [10.1109/ICCV.2019.00630, DOI 10.1109/ICCV.2019.00630]
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jhuang H, 2007, IEEE I CONF COMP VIS, P1253
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kim TT, 2007, INT CONF ACOUST SPEE, P1
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Ma Ningning, 2018, P EUR C COMP VIS ECC, DOI [10.1007/978-3-030-01264-9_8, DOI 10.1007/978-3-030-01264-9_8]
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sifre L., 2014, THESIS, V1, P3
   Simonyan K, 2014, 2 STREAM CONVOLUTION
   Tran D, 2017, CLOSER LOOK SPATIOTE
   Wang LJ, 2021, IEEE T NEUR NET LEAR, V32, P1678, DOI 10.1109/TNNLS.2020.2986281
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2017, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2017.678
   Wong S, 2007, 2007 INTERNATIONAL SYMPOSIUM ON VLSI TECHNOLOGY, SYSTEMS AND APPLICATIONS (VLSI-TSA), PROCEEDINGS OF TECHNICAL PAPERS, P66
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Yang H, 2019, PATTERN RECOGN, V85, P1, DOI 10.1016/j.patcog.2018.07.028
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Zhang Xiangyu, 2018, IEEE C COMP VIS PATT
   Zhou YZ, 2018, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2018.00054
NR 36
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 26913
EP 26926
DI 10.1007/s11042-020-09137-5
EA JUN 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000541402000007
DA 2024-07-18
ER

PT J
AU Hagras, EAA
   Saber, M
AF Hagras, Esam A. A.
   Saber, Mohamed
TI Low power and high-speed FPGA implementation for 4D memristor chaotic
   system for image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Memristor; FPGA; Image encryption; Chaotic system; Randomization tests
ID DESIGN; REALIZATION; PERMUTATION; GENERATOR
AB In this paper, we proposed a novel low power and high-speed FPGA implementation of the 4D memristor chaotic system with cubic nonlinearity based on Xilinx System Generator (XSG) model. Firstly, a pseudo-random number generator based on the proposed XSG FPGA implementation of the proposed 4D memristor chaotic system which implemented into Xilinx Spartan-6 X6SLX45 board with 32 fixed-point format. The aim of the FPGA implementation is increasing the frequency of the memristor chaotic random number generators. The FPGA implementation of the memristor chaotic system results show that the new design approach achieves a maximum frequency of 393 MHz and dissipates 117 m watt. The standard fifteen randomization tests are used to measure the quality of the proposed pseudo-random number generator based on the 4D memristor chaotic system and it gives an excellent randomization analysis. Also, the gray image encryption scheme based on the 4D memristor chaotic system has been introduced. The proposed cryptosystem has a large keyspace, very low correlation values, high entropy which is much closer to the ideal entropy value, a high number of pixels change rate and high unified average changing intensity values. The results and security analysis of the proposed encryption scheme demonstrate that the investigated encryption approach can protect high speed and high security against various attack.
C1 [Hagras, Esam A. A.; Saber, Mohamed] Delta Univ Sci & Technol, Fac Engn, Commun & Comp Dept, Mansoura, Egypt.
C3 Delta University for Science & Technology
RP Hagras, EAA (corresponding author), Delta Univ Sci & Technol, Fac Engn, Commun & Comp Dept, Mansoura, Egypt.
EM essam.hagras@deltauniv.edu.eg; mohamed.saber@deltauniv.edu.eg
RI Saber, Mohamed Saber/AFJ-6910-2022; Hagras, Esam/KCZ-0122-2024
OI Saber, Mohamed Saber/0000-0003-2692-9507; 
CR Akgul A, 2016, NONLINEAR DYNAM, V84, P481, DOI 10.1007/s11071-015-2501-7
   Alçin M, 2016, OPTIK, V127, P5500, DOI 10.1016/j.ijleo.2016.03.042
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 2009, P JOINT IEEE N E WOR
   ANSI N., 1985, 7541985 ANSI N IEEE, V754-1985, P1
   Azzaz MS, 2013, COMMUN NONLINEAR SCI, V18, P1792, DOI 10.1016/j.cnsns.2012.11.025
   Barboza R, 2008, INT J BIFURCAT CHAOS, V18, P943, DOI 10.1142/S0218127408020987
   Cgharles Jr HR, 2017, DIGITAL SYSTEM DESIG
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P9907, DOI 10.1007/s11042-016-3585-x
   CHUA LO, 1971, IEEE T CIRCUITS SYST, VCT18, P507, DOI 10.1109/TCT.1971.1083337
   Churiwala S, 2017, DESIGNING XILINX FPG, DOI [10.1007/978-3-319-42438-5, DOI 10.1007/978-3-319-42438-5]
   Deng ZJ, 2019, J ALGORITHMS COMPUT, V13, DOI 10.1177/1748302619853470
   de la Fraga LG, 2017, NONLINEAR DYNAM, V90, P1661, DOI 10.1007/s11071-017-3755-z
   Guangya P., 2017, CIRCUIT IMPLEMENTATI, V90, P1607, DOI DOI 10.1007/s11071-017-3752-2
   Hidayat O, 2017, TURKISH J SCI TECHNO, V12, P113
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Jakimoski G, 2001, IEEE T CIRCUITS-I, V48, P163, DOI 10.1109/81.904880
   Johnson T, 2017, DIGITAL LOGIC RLT VE
   Johnson T, 2015, DIGITAL LOGIC RLT VE
   Kar M, 2016, IETE TECH REV, V33, P651, DOI 10.1080/02564602.2015.1136245
   Karaca B. K., 2018, 2018 26 SIGN PROC CO, DOI DOI 10.1109/SIU.2018.8404450
   Karakaya B, 2019, CHAOS SOLITON FRACT, V119, P143, DOI 10.1016/j.chaos.2018.12.021
   Kim HI, 2014, INT CONF BIG DATA, P77, DOI 10.1109/BIGCOMP.2014.6741411
   Koppu S, 2017, MOD SIMUL ENG, V2017, DOI 10.1155/2017/7470204
   Koyuncu I, 2014, NONLINEAR DYNAM, V77, P49, DOI 10.1007/s11071-014-1272-x
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liang CD, 2016, Adv Inform Managemen, P1711, DOI 10.1109/IMCEC.2016.7867510
   Lin ZH, 2009, 2009 INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CIRCUITS AND SYSTEMS PROCEEDINGS, VOLUMES I & II, P964, DOI 10.1109/ICCCAS.2009.5250354
   Lin ZH, 2010, IETE TECH REV, V27, P318, DOI 10.4103/0256-4602.64605
   Liu LF, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-1959-1
   Lynch S., 2004, Dynamical Systems with Applications Using MATLAB
   Merah L., 2013, Appl. Math. Sci., V7, P237
   Mishra M, 2012, INT J COMPUT APPL, V37
   Muthuswamy B, 2010, INT J BIFURCAT CHAOS, V20, P1335, DOI 10.1142/S0218127410026514
   NIST, 2010, STAT TEST SUIT RAND
   Rajagopal K, 2017, CHAOS SOLITON FRACT, V103, P476, DOI 10.1016/j.chaos.2017.07.007
   Sadoudi Said., 2009, International Journal of Nonlinear Science, V7, P467
   Tlelo-Cuautle E, 2015, COMMUN NONLINEAR SCI, V27, P66, DOI 10.1016/j.cnsns.2015.03.003
   Tolba MF, 2019, IEEE T CIRCUITS-II, V66, P1381, DOI 10.1109/TCSII.2018.2882496
   Tuna M, 2016, OPTIK, V127, P11786, DOI 10.1016/j.ijleo.2016.09.087
   Venkatachalam S., 2018, 2018 IEEE INT S CIRC, P1
   Wang B, 2017, OPTIK, V154
   Wang QX, 2016, IEEE T CIRCUITS-I, V63, P401, DOI 10.1109/TCSI.2016.2515398
   Wang SB, 2015, ENTROPY-SWITZ, V17, P7628, DOI 10.3390/e17117628
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Xilinx, 2018, DES SUIT US GUID MOD, V2018.1
   Xilinx Inc, 2012, SYNTH SIM DES GUID U, P2012
   Yang CY, 2015, INT SYM COMPUT INTEL, P447, DOI 10.1109/ISCID.2015.156
   Ye GD, 2012, NONLINEAR DYNAM, V69, P2079, DOI 10.1007/s11071-012-0409-z
   Zhang LF, 2017, INTERNATIONAL SYMPOSIUM 2017: SOCIAL SCIENCE MANAGEMENT AND INNOVATION, P1, DOI 10.1109/TSMC.2017.2691909
   Zodpe Harshali, 2018, J KING SAUD U ENG SC
NR 51
TC 22
Z9 22
U1 9
U2 66
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23203
EP 23222
DI 10.1007/s11042-019-08517-w
EA JUN 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000538382000002
DA 2024-07-18
ER

PT J
AU Zhang, XF
   Wang, Y
   Chen, ZX
   Yan, J
   Wang, DH
AF Zhang, Xufan
   Wang, Yong
   Chen, Zhenxing
   Yan, Jun
   Wang, Dianhong
TI Saliency detection via image sparse representation and color features
   combination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Saliency detection; Sparse representation; Linear
   combination
ID MODEL
AB Saliency detection is a technique to analyze image surroundings to extract relevant regions from the background. In this paper, we propose a simple and effective saliency detection method based on image sparse representation and color features combination. First, the input image is segmented into non-overlapping super-pixels, so as to perform the saliency detection at the region level to reduce computational complexity. Then, a background optimization selection scheme is used to construct an appropriate background template. Based on this, a primary saliency map is obtained by using image sparse representation. Next, through the linear combination of color coefficients we generate an improved saliency map with more prominent salient regions. Finally, the two saliency maps are integrated within Bayesian framework to obtain the final saliency map. Experimental results show that the proposed method has desirable detection performance in terms of detection accuracy and running time.
C1 [Zhang, Xufan; Wang, Yong; Chen, Zhenxing; Yan, Jun; Wang, Dianhong] China Univ Geosci, Sch Mech Engn & Elect Informat, Wuhan 430074, Peoples R China.
C3 China University of Geosciences
RP Wang, Y (corresponding author), China Univ Geosci, Sch Mech Engn & Elect Informat, Wuhan 430074, Peoples R China.
EM wy112708@163.com
FU National Natural Science Foundation of China [61771436, 61973283]
FX This work was supported by the National Natural Science Foundation of
   China under grants No. 61771436 and ?61973283.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Elder, 2010, P IEEE C COMP VIS PA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Holzinger A, 2018, LECT NOTES COMPUT SC, V11015, P1, DOI 10.1007/978-3-319-99740-7_1
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Kim J, 2016, IEEE T IMAGE PROCESS, V25, P9, DOI 10.1109/TIP.2015.2495122
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Liu Z, 2012, IEEE T MULTIMEDIA, V14, P1275, DOI 10.1109/TMM.2012.2190385
   Lu S, 2014, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2014.357
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40
   Tavakoli HR, 2011, LECT NOTES COMPUT SC, V6688, P666, DOI 10.1007/978-3-642-21227-7_62
   Wang JD, 2017, INT J COMPUT VISION, V123, P251, DOI 10.1007/s11263-016-0977-3
   Wang L, 2011, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2011.6126231
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
NR 27
TC 7
Z9 7
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23147
EP 23159
DI 10.1007/s11042-020-09073-4
EA JUN 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000538382100001
DA 2024-07-18
ER

PT J
AU Jin, T
   Wang, HJ
   Li, ZJ
AF Jin, Tao
   Wang, Haijun
   Li, Zhaojun (Steven)
TI A personalized cloud engine for multimedia search based on binary ant
   colony algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud engine; Binary ant colony; Search engine; Multimedia search
   engine; Personalized search
ID INDEX
AB At present, the search content and results of common multimedia search engines have gradually failed to meet the personalized search requirements of users. The paper focuses on personalized cloud search engines for multimedia. First, the binary ant colony algorithm is optimized by the cloud model. Then, the binary ant colony algorithm is used to improve the multimedia search engine. Detailedly, a binary directed graph for ant colony traversal is designed in which each ant traverses its own path, and the solution traverses by each ant is integrated to solve the problem. Experiments show that the proposed method effectively improves the query speed of personalized multimedia search engines, reduces redundant information, and improves the user search experience.
C1 [Jin, Tao; Wang, Haijun] Ordos Inst Technol, Ordos 017000, Peoples R China.
   [Li, Zhaojun (Steven)] Western New England Univ, Dept Ind Engn & Engn Management, Springfield, MA 01119 USA.
C3 Western New England University
RP Li, ZJ (corresponding author), Western New England Univ, Dept Ind Engn & Engn Management, Springfield, MA 01119 USA.
EM zhaojun.li@wne.edu
RI Wang, Haijun/A-7691-2016
CR [Anonymous], 2001, ACM T INTERNET TECHN, DOI DOI 10.1145/383034.383035
   [Anonymous], 2016, SEARCH ENG GAIN DAIL
   Bouhana A, 2015, EXPERT SYST APPL, V42, P3724, DOI 10.1016/j.eswa.2014.12.012
   Chang H, 2017, ENRGY PROCED, V105, DOI 10.1016/j.egypro.2017.03.859
   CHEN L, 1998, P 2 INT C AUT AG
   China Internet Information Center, 31 STAT REP DEV CHIN
   Egghe L, 2008, J AM SOC INF SCI TEC, V59, P1608, DOI 10.1002/asi.20845
   Guoyin Wang, 2012, Rough Sets and Current Trends in Computing. Proceedings 8th International Conference, RSCTC 2012, P313, DOI 10.1007/978-3-642-32115-3_37
   Ji J, 2017, J MATER CIVIL ENG, V29, DOI 10.1061/(ASCE)MT.1943-5533.0001769
   Li Li, 2018, Inf. Sci., V36, P90
   Liu GC, 2018, IEEE ACCESS, V6, P29283, DOI 10.1109/ACCESS.2018.2834916
   Liu S, 2018, COMPLEXITY, DOI 10.1155/2018/2016976
   Liu S, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19060269
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   Madhavan J, 2008, PROC VLDB ENDOW, V1, P1241
   Napoles G, 2018, NEURAL NETW, V97
   Pan Z, 2018, J PARALLEL DISTR COM, V120, P182, DOI 10.1016/j.jpdc.2018.06.012
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   S. Insight, 2017, SEARCH ENG STAT
   Schreiber M, 2009, J AM SOC INF SCI TEC, V60, P1274, DOI 10.1002/asi.21057
   Vahid J, 2010, J MED SYST, V35
   Wan YC, 2016, APPL SOFT COMPUT, V49, P248, DOI 10.1016/j.asoc.2016.08.011
   Wang, 2011, INT J INF TECHNOL CO, V3, P36, DOI DOI 10.5815/ijitcs.2011.03.06
   Wang GY, 2014, INFORM SCIENCES, V280, P1, DOI 10.1016/j.ins.2014.04.051
   Wang S. L., 2003, Geographic Information Sciences, V9, P60, DOI [https://doi.org/10.1080/10824000309480589, DOI 10.1080/10824000309480589]
   Xiong W., 2006, Int J Inform Technol, V12, P10
   Yang LZ, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/5620803
   Zhang R., 2013, IEDM, P13
NR 28
TC 0
Z9 0
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16487
EP 16499
DI 10.1007/s11042-019-7372-3
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600038
DA 2024-07-18
ER

PT J
AU Lin, JW
   Yu, L
   Weng, Q
   Zheng, XH
AF Lin, Jiawen
   Yu, Lun
   Weng, Qian
   Zheng, Xianghan
TI Retinal image quality assessment for diabetic retinopathy screening: A
   survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic retinopathy; Screening; Retinal image; Retinal image quality
   assessment
ID CLARITY; SYSTEM
AB Retinal image quality assessment (RIQA) is one of the key components in screening for diabetic retinopathy (DR). As one of the most serious complications of diabetes, DR has become a leading cause of blindness in adults globally. DR screening is essential to achieve early diagnosis so that effective treatment could be provided timely. However, the collected images of medically unsatisfactory quality always lead to failure of diagnosis and waste of ophthalmologists' precious time. Hence, the first step in a good DR screening program is verifying retinal images of good quality. In this paper, we provide a systematic review on automated assessment of retinal image quality for DR screening. Scheme and parameters for RIQA are firstly presented. Next, we provide detailed understanding of the existing RIQA techniques, algorithms and methodologies, including brief description and analysis of each existing state-of-art approaches and comparison between such methods. Datasets and evaluation metrics are also illustrated. Finally, several challenges and future research directions are summarized and discussed.
C1 [Lin, Jiawen; Yu, Lun] Fuzhou Univ, Coll Phys & Informat Engn, Fuzhou, Fujian, Peoples R China.
   [Lin, Jiawen; Weng, Qian; Zheng, Xianghan] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou, Fujian, Peoples R China.
   [Lin, Jiawen; Zheng, Xianghan] Fuzhou Univ, Fujian Key Lab Network Comp & Intelligent Informa, Fuzhou, Fujian, Peoples R China.
C3 Fuzhou University; Fuzhou University; Fuzhou University
RP Lin, JW (corresponding author), Fuzhou Univ, Coll Phys & Informat Engn, Fuzhou, Fujian, Peoples R China.; Lin, JW (corresponding author), Fuzhou Univ, Coll Math & Comp Sci, Fuzhou, Fujian, Peoples R China.; Lin, JW (corresponding author), Fuzhou Univ, Fujian Key Lab Network Comp & Intelligent Informa, Fuzhou, Fujian, Peoples R China.
EM rose_wei7@126.com
OI Lin, Jiawen/0000-0003-2950-1776
CR Abdel-Hamid L, 2017, COMPUT BIOL MED, V90, P68, DOI 10.1016/j.compbiomed.2017.09.012
   Abdel-Hamid L, 2016, J BIOMED OPT, V21, DOI 10.1117/1.JBO.21.9.096007
   Bartling H, 2009, ACTA OPHTHALMOL, V87, P643, DOI 10.1111/j.1755-3768.2008.01321.x
   Chen F, 2015, J VIS COMMUN IMAGE R, V30, P117, DOI 10.1016/j.jvcir.2015.03.005
   Cheng WH, 2016, 2016 IEEE INTERNATIONAL CONFERENCE OF ONLINE ANALYSIS AND COMPUTING SCIENCE (ICOACS), P1, DOI 10.1109/ICOACS.2016.7563036
   Cho NH, 2018, DIABETES RES CLIN PR, V138, P271, DOI 10.1016/j.diabres.2018.02.023
   Cohen A., 1993, Applied and Computational Harmonic Analysis, V1, P54, DOI 10.1006/acha.1993.1005
   Cummings E, 2002, HLTH TECHNOLOGY ASSE
   Das T, 2015, MIDDLE EAST AFR J OP, V22, P174, DOI 10.4103/0974-9233.154391
   Davis H, 2009, 22nd IEEE International Symposium on Computer-Based Medical Systems, P1, DOI [10.1109/CBMS.2009.5255437, DOI 10.1109/CBMS.2009.5255437]
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   F. P. R. C. Dept. of Ophthalmology & Visual Sciences of the University of Wisconsin-Madison, 1995, ARIC GRAD PROT
   Fleming AD, 2006, INVEST OPHTH VIS SCI, V47, P1120, DOI 10.1167/iovs.05-1155
   Fleming AD, 2012, MED ENG PHYS, V34, P849, DOI 10.1016/j.medengphy.2011.09.027
   Fundus disease Group in Ophthalmology Branch of Chinese Medical Association, 2017, Chin J Ophthalmol, V53, P890, DOI DOI 10.3760/CMA.J.ISSN.0412-4081.2017.12.003
   Giancardo L, 2008, IEEE ENG MED BIO, P3534, DOI 10.1109/IEMBS.2008.4649968
   Giancardo L, 2012, MED IMAGE ANAL, V16, P216, DOI 10.1016/j.media.2011.07.004
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Hunter A, 2011, IEEE ENG MED BIO, P5955, DOI 10.1109/IEMBS.2011.6091472
   Hwang SK, 2006, PATTERN RECOGN, V39, P2065, DOI 10.1016/j.patcog.2006.03.004
   Katuwal GJ, 2013, WEST NY IMAGE PROCES, P9, DOI 10.1109/WNYIPW.2013.6890980
   Kawaguchi A, 2018, TELEMED E-HEALTH, V24, P301, DOI 10.1089/tmj.2017.0100
   Lalonde M., 2001, Proceedings of Vision Interface, P259
   Lee SC, 1999, P SOC PHOTO-OPT INS, V3661, P1581, DOI 10.1117/12.348562
   Li BX, 2013, CURR DIABETES REP, V13, P453, DOI 10.1007/s11892-013-0393-9
   Li JJ, 2014, OPHTHALMOL CHINA, V23, P217
   Li YF, 2018, FUTURE GENER COMP SY, V87, P259, DOI 10.1016/j.future.2018.04.012
   Lin KY, 2018, PROC CVPR IEEE, P732, DOI 10.1109/CVPR.2018.00083
   MESSIDOR, 2004, METH EV SEGM IND TEC
   Mora AD, 2013, INT SYMP IMAGE SIG, P717
   Morse SS, 2014, MICROBIOL SPECTR, V2, DOI 10.1128/microbiolspec.OH-0002-2012
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Nayak J, 2009, J MED SYST, V33, P337, DOI 10.1007/s10916-008-9195-z
   NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479
   Niemeijer M, 2004, METHODS EVALUATING S
   Niemeijer M, 2006, MED IMAGE ANAL, V10, P888, DOI 10.1016/j.media.2006.09.006
   Niemeijer M, 2010, IEEE T MED IMAGING, V29, P185, DOI 10.1109/TMI.2009.2033909
   Niu YZ, 2017, MULTIMED TOOLS APPL, V76, P26329, DOI 10.1007/s11042-016-4128-1
   Niu YZ, 2017, IET COMPUT VIS, V11, P161, DOI 10.1049/iet-cvi.2016.0027
   Paulus J, 2010, INT J COMPUT ASS RAD, V5, P557, DOI 10.1007/s11548-010-0479-7
   Pérez J, 2013, J MOD OPTIC, V60, P544, DOI 10.1080/09500340.2013.794394
   Dias JMP, 2014, INFORM FUSION, V19, P73, DOI 10.1016/j.inffus.2012.08.001
   Pires R., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P229, DOI 10.1109/SIBGRAPI.2012.39
   Pratt H, 2016, PROCEDIA COMPUT SCI, V90, P200, DOI 10.1016/j.procs.2016.07.014
   Sevik U, 2014, J BIOMED OPT, V19, DOI 10.1117/1.JBO.19.4.046006
   Shao F, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2776126
   Shen RJ, 2012, STATISTICAL PERFORMANCE ANALYSIS AND MODELING TECHNIQUES FOR NANOMETER VLSI DESIGNS, P127, DOI 10.1007/978-1-4614-0788-1_9
   Sim DA, 2015, CURR DIABETES REP, V15, DOI 10.1007/s11892-015-0577-6
   Sopharak Akara, 2011, IAENG International Journal of Computer Science, V38, P295
   Soto-Pedre E, 2015, ACTA OPHTHALMOL, V93, pE52, DOI 10.1111/aos.12481
   Usher D., 2003, Proceedings of Medical Image Understanding and Analysis, P81
   Wang SP, 2017, IEEE T MULTIMEDIA, V19, P1454, DOI 10.1109/TMM.2017.2663324
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Welikala RA, 2016, COMPUT BIOL MED, V71, P67, DOI 10.1016/j.compbiomed.2016.01.027
   Xia YS, 2016, NEUROCOMPUTING, V198, P155, DOI 10.1016/j.neucom.2015.06.111
   Yin FS, 2014, IEEE ENG MED BIO, P162, DOI 10.1109/EMBC.2014.6943554
   Yu FL, 2017, IEEE ENG MED BIO, P664, DOI 10.1109/EMBC.2017.8036912
NR 58
TC 15
Z9 16
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16173
EP 16199
DI 10.1007/s11042-019-07751-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600021
DA 2024-07-18
ER

PT J
AU Ramasamy, P
   Ranganathan, V
   Palanisamy, V
   Kadry, S
AF Ramasamy, Priya
   Ranganathan, Vidhyapriya
   Palanisamy, Venketesh
   Kadry, Seifedine
TI Securing one-time password generation using elliptic-curve cryptography
   with self-portrait photograph for mobile commerce application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric features; Elliptic curve cryptography; Facial components; Iris
   matching; Spatial histogram
AB Over the decades, the security in mobile commerce application via One Time Password (OTP) plays a vital role. With new developments in mobile wallets, the volume of transactions increase globally and the need for securing transactions is still a challenging aspect. A strong user authentication mechanism is required since many of the attacks take minimum effort to break the security. User Authentication is a critical requirement since many of the attacks take minimum effort to break the security. Hence a novel cryptographic scheme is proposed to bridge the gap between security and authentication mechanisms. Initially, the scheme captures the user image to analyze the face for its structure, texture and feature identification. Once the image components are matched from the available template database user authentication is successful. To avoid conflict during template matching the face components are further subjected to segment location, radius and center of eyeballs at subpixellic accuracy. Iris matching is done via spatial histogram. If the iris information is similar, the Transaction Server (TS) generates OTP and sends it to the user mobile in order to complete the transaction. The proposed model is proven to be highly efficient against False Acceptance Rate (FAR) and False Rejection Rate (FRR) measures and is validated over Q- Fire dataset.
C1 [Ramasamy, Priya] PSG Coll Technol, Dept Appl Math & Computat Sci, Coimbatore, Tamil Nadu, India.
   [Ranganathan, Vidhyapriya] PSG Coll Technol, Dept Biomed Engn, Coimbatore, Tamil Nadu, India.
   [Palanisamy, Venketesh] VIT, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
   [Kadry, Seifedine] Beirut Arab Univ, Fac Sci, Dept Math & Comp Sci, Beirut, Lebanon.
C3 PSG College Technology; PSG College Technology; Vellore Institute of
   Technology (VIT); VIT Vellore; Beirut Arab University
RP Kadry, S (corresponding author), Beirut Arab Univ, Fac Sci, Dept Math & Comp Sci, Beirut, Lebanon.
EM s.kadry@bau.edu.lb
RI Palanisamy, Venketesh/AAA-7373-2019; Kadry, Seifedine/C-7437-2011;
   Ramasamy, Priya/AAC-1199-2019
OI Palanisamy, Venketesh/0000-0001-7967-4638; Kadry,
   Seifedine/0000-0002-1939-4842; Ranganathan,
   Vidhyapriya/0000-0003-0665-6820
CR Ajay AS, 2013, IOSR J ELECT COMMUN, V6, P11, DOI [10.9790/2834-0621114, DOI 10.9790/2834-0621114]
   Alheeti K. M. A, 2011, International Journal on Soft Computing, V2, P1
   [Anonymous], 2013, INT C HET NETW QUAL
   Barker E., 2014, NAT I STANDARDS TECH, P1
   Burke DD, 2010, J LEG STUD EDUC, V27, P1, DOI 10.1111/j.1744-1722.2010.01066.x
   Cha B, 2008, 2008 IEEE 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY, VOLS 1 AND 2, P420, DOI 10.1109/CIT.2008.4594712
   Chen CH, 2006, LECT NOTES COMPUT SC, V3832, P571
   Daftry S, 2012, IMAGE, V16, P17
   Iancu I, 2010, INT J COMPUT COMMUN, V5, P525, DOI 10.15837/ijccc.2010.4.2510
   Lee YC, 2010, ICAART 2010: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL 1: ARTIFICIAL INTELLIGENCE, P644
   Nguyen K, 2012, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2012.6247984
   Ramalho MB, 2012, IET COMPUT VIS, V6, P165, DOI 10.1049/iet-cvi.2011.0095
   Richards G, 2012, 6560 RFC
   Sagayee GMA, 2013, INT J ELECTRON SECUR, V5, P110, DOI 10.1504/IJESDF.2013.055049
   Sheeba T., 2012, INT J COMPUTER APPL, V51, P55
   Shreyal D, 2017, INT J SCI RES, V6, P20
   Tsai CL, 2012, 2012 THIRD FTRA INTERNATIONAL CONFERENCE ON MOBILE, UBIQUITOUS, AND INTELLIGENT COMPUTING (MUSIC), P138, DOI [10.1109/MUSIC.2012.31, 10.1109/ICMA.2012.6282821]
   Wang YH, 2003, LECT NOTES COMPUT SC, V2688, P805
NR 18
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 17081
EP 17099
DI 10.1007/s11042-019-7615-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600071
DA 2024-07-18
ER

PT J
AU Rezaei, M
   Yang, HJ
   Meinel, C
AF Rezaei, Mina
   Yang, Haojin
   Meinel, Christoph
TI Recurrent generative adversarial network for learning imbalanced medical
   image semantic segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Imbalanced medical image semantic segmentation; Recurrent generative
   adversarial network
AB We propose a new recurrent generative adversarial architecture named RNN-GAN to mitigate imbalance data problem in medical image semantic segmentation where the number of pixels belongs to the desired object are significantly lower than those belonging to the background. A model trained with imbalanced data tends to bias towards healthy data which is not desired in clinical applications and predicted outputs by these networks have high precision and low recall. To mitigate imbalanced training data impact, we train RNN-GAN with proposed complementary segmentation mask, in addition, ordinary segmentation masks. The RNN-GAN consists of two components: a generator and a discriminator. The generator is trained on the sequence of medical images to learn corresponding segmentation label map plus proposed complementary label both at a pixel level, while the discriminator is trained to distinguish a segmentation image coming from the ground truth or from the generator network. Both generator and discriminator substituted with bidirectional LSTM units to enhance temporal consistency and get inter and intra-slice representation of the features. We show evidence that the proposed framework is applicable to different types of medical images of varied sizes. In our experiments on ACDC-2017, HVSMR-2016, and LiTS-2017 benchmarks we find consistently improved results, demonstrating the efficacy of our approach.
C1 [Rezaei, Mina; Yang, Haojin; Meinel, Christoph] Hasso Plattner Inst, Prof Dr Helmert St 2-3, Potsdam, Germany.
C3 University of Potsdam
RP Rezaei, M (corresponding author), Hasso Plattner Inst, Prof Dr Helmert St 2-3, Potsdam, Germany.
EM mina.rezaei@hpi.de; haojin.yang@hpi.de; christoph.meinel@hpi.de
RI Rezaei, Mina/GYV-3037-2022
OI Rezaei, Mina/0000-0001-6994-6345
CR Afshin M, 2014, IEEE T MED IMAGING, V33, P481, DOI 10.1109/TMI.2013.2287793
   [Anonymous], 2016, Reconstruction, Segmentation, and Analysis of Medical Images
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], BIORXIV
   [Anonymous], 2015, SOFTWARE
   [Anonymous], 2017, ARXIV170402703
   Avola D, 2011, LECT NOTES COMPUT SC, V6979, P414, DOI 10.1007/978-3-642-24088-1_43
   Avola D, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P1338
   Bernard O, 2018, IEEE T MED IMAGING, V37, P2514, DOI 10.1109/TMI.2018.2837502
   Bulò SR, 2017, PROC CVPR IEEE, P7082, DOI 10.1109/CVPR.2017.749
   Chollet F, 2015, KERAS
   Christ PF, 2017, Case Studies in Clinical Psychological Science: Bridging the Gap from Science to Practice
   Ciecholewski M, 2011, LECT NOTES COMPUT SC, V6636, P432, DOI 10.1007/978-3-642-21073-0_38
   Douzas G, 2018, EXPERT SYST APPL, V91, P464, DOI 10.1016/j.eswa.2017.09.030
   Drozdzal M, 2018, MED IMAGE ANAL, V44, P1, DOI 10.1016/j.media.2017.11.005
   Eslami A, 2013, MED IMAGE ANAL, V17, P236, DOI 10.1016/j.media.2012.10.005
   Fidon L, 2018, LECT NOTES COMPUT SC, V10670, P64, DOI 10.1007/978-3-319-75238-9_6
   Fischl B, 2004, NEUROIMAGE, V23, pS69, DOI 10.1016/j.neuroimage.2004.07.016
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Han X., 2017, AUTOMATIC LIVER LESI, V44, P1408, DOI 10.1002/mp.12155
   Inda Maria-del-Mar RB, 2014, ANCER ARCH, P226
   Isensee F, 2018, LECT NOTES COMPUT SC, V10663, P120, DOI 10.1007/978-3-319-75541-0_13
   Ishida T, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jang J.W., 2014, TRANSFUS APHER SCI, V2014, P1
   Kaur R, 2018, MULTIMED TOOLS APPL, P1
   Kohl Simon., 2017, ARXIV170208014
   Mahapatra D, 2014, J DIGIT IMAGING, V27, P794, DOI 10.1007/s10278-014-9705-0
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Moeskops P, 2017, ARXIV170703195
   Nasr G.E., 2002, Forecasting gasoline demand, P381
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Peng P, 2016, MAGN RESON MATER PHY, V29, P155, DOI 10.1007/s10334-015-0521-4
   Pohl KA, 2006, NEUROIMAGE, V31, P228, DOI 10.1016/j.neuroimage.2005.11.044
   Poudel RPK, 2017, LECT NOTES COMPUT SC, V10129, P83, DOI 10.1007/978-3-319-52280-7_8
   Prabhu V, 2018, MULTIMED TOOLS APPL, V77, P10375, DOI 10.1007/s11042-018-5792-0
   Qiu Q, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS PROCESSING (ICIGP 2018), P78, DOI 10.1145/3191442.3191458
   Rohe MM, 2017, STAT ATLASES COMPUTA
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salehi SSM, 2018, ARXIV180311078
   Shahzad R, 2017, LECT NOTES COMPUT SC, V10129, P147, DOI 10.1007/978-3-319-52280-7_15
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Tustison NJ, 2010, IEEE T MED IMAGING, V29, P1310, DOI 10.1109/TMI.2010.2046908
   Vorontsov E, 2018, I S BIOMED IMAGING, P1332, DOI 10.1109/ISBI.2018.8363817
   Wolterink JM, 2017, P INT WORKSH STAT AT
   Xu J, 2014, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2014.408
   Xue Y, 2018, NEUROINFORMATICS, V16, P383, DOI 10.1007/s12021-018-9377-x
   Yu L., 2016, Reconstruction, Segmentation, and Analysis of Medical Images, P103
   Yu X, 2018, LECT NOTES COMPUT SC, V11213, P219, DOI 10.1007/978-3-030-01240-3_14
   Zhang YS, 2018, MULTIDIM SYST SIGN P, V29, P999, DOI 10.1007/s11045-017-0482-z
   Zhang YB, 2020, MIN PROC EXT MET REV, V41, P75, DOI 10.1080/08827508.2018.1538986
   Zhou YP, 2016, LECT NOTES COMPUT SC, V9912, P262, DOI 10.1007/978-3-319-46484-8_16
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zotti C, 2017, INT WORKSH STAT ATL, P73
NR 55
TC 30
Z9 35
U1 3
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15329
EP 15348
DI 10.1007/s11042-019-7305-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900055
DA 2024-07-18
ER

PT J
AU Sivaranjini, S
   Sujatha, CM
AF Sivaranjini, S.
   Sujatha, C. M.
TI Deep learning based diagnosis of Parkinson's disease using convolutional
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parkinson's disease; MRI; Deep learning; Convolutional neural networks;
   AlexNet
ID MRI; SEGMENTATION; PROGRESSION; ATROPHY
AB Parkinson's disease is the second most common degenerative disease caused by loss of dopamine producing neurons. The substantia nigra region is deprived of its neuronal functions causing striatal dopamine deficiency which remains as hallmark in Parkinson's disease. Clinical diagnosis reveals a range of motor to non motor symptoms in these patients. Magnetic Resonance (MR) Imaging is able to capture the structural changes in the brain due to dopamine deficiency in Parkinson's disease subjects. In this work, an attempt has been made to classify the MR images of healthy control and Parkinson's disease subjects using deep learning neural network. The Convolutional Neural Network architecture AlexNet is used to refine the diagnosis of Parkinson's disease. The MR images are trained by the transfer learned network and tested to give the accuracy measures. An accuracy of 88.9% is achieved with the proposed system. Deep learning models are able to help the clinicians in the diagnosis of Parkinson's disease and yield an objective and better patient group classification in the near future.
C1 [Sivaranjini, S.; Sujatha, C. M.] Anna Univ, Dept Elect & Commun Engn, CEG Campus, Chennai, Tamil Nadu, India.
C3 Anna University; Anna University Chennai; College of Engineering Guindy
RP Sivaranjini, S (corresponding author), Anna Univ, Dept Elect & Commun Engn, CEG Campus, Chennai, Tamil Nadu, India.
EM sivaranjinipragasam@gmail.com
RI C M, Sujatha/AFQ-8824-2022
CR Aarsland D, 2016, PARKINSONISM RELAT D, V22, pS144, DOI 10.1016/j.parkreldis.2015.09.034
   Aderghal K, 2018, COMP MED SY, P345, DOI 10.1109/CBMS.2018.00067
   Amoroso N, 2018, MED IMAGE ANAL, V48, P12, DOI 10.1016/j.media.2018.05.004
   [Anonymous], 2018, NAT C COMM NCC
   [Anonymous], 2018, ARXIV180105968
   [Anonymous], 2017, P 31 AAAI C ART INT
   Chaudhuri KR, 2006, LANCET NEUROL, V5, P235, DOI 10.1016/S1474-4422(06)70373-8
   Cheng HC, 2010, ANN NEUROL, V67, P715, DOI 10.1002/ana.21995
   Cigdem O, 2018, 26 SIGN PROC COMM AP, P1
   Dolz J, 2018, NEUROIMAGE, V170, P456, DOI 10.1016/j.neuroimage.2017.04.039
   Dorsey ER, 2007, NEUROLOGY, V68, P384, DOI 10.1212/01.wnl.0000247740.47667.03
   Gao W, 2016, SCI CHINA INFORM SCI, V59, DOI 10.1007/s11432-015-5470-z
   Ghafoorian M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05300-5
   Hermessi H, 2019, EXPERT SYST APPL, V120, P116, DOI 10.1016/j.eswa.2018.11.025
   Hopes L, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147947
   Kazemi Y, 2018, 2018 IEEE C COMPUTAT, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lebedev AV, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00045
   Li X, 2018, NEUROIMAGE-CLIN, V17, P498, DOI 10.1016/j.nicl.2017.11.009
   Long D, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0047714
   Lu SY, 2019, J COMPUT SCI-NETH, V30, P41, DOI 10.1016/j.jocs.2018.11.008
   Mak E, 2017, NEUROBIOL AGING, V55, P78, DOI 10.1016/j.neurobiolaging.2017.03.012
   Marek K, 2011, PROG NEUROBIOL, V95, P629, DOI 10.1016/j.pneurobio.2011.09.005
   Nemmi F, 2015, NEUROBIOL AGING, V36, P424, DOI 10.1016/j.neurobiolaging.2014.07.010
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Pinter B, 2015, MOVEMENT DISORD, V30, P266, DOI 10.1002/mds.26060
   Poewe W, 2017, NAT REV DIS PRIMERS, V3, DOI 10.1038/nrdp.2017.13
   Prashanth R, 2017, IEEE J BIOMED HEALTH, V21, P794, DOI 10.1109/JBHI.2016.2547901
   Pringsheim T, 2014, MOVEMENT DISORD, V29, P1583, DOI 10.1002/mds.25945
   Provost JS, 2015, FRONT SYST NEUROSCI, V9, DOI 10.3389/fnsys.2015.00140
   Salvatore C, 2014, J NEUROSCI METH, V222, P230, DOI 10.1016/j.jneumeth.2013.11.016
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tagaris A, 2017, COMM COM INF SC, V744, P391, DOI 10.1007/978-3-319-65172-9_33
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Vogado LHS, 2018, ENG APPL ARTIF INTEL, V72, P415, DOI 10.1016/j.engappai.2018.04.024
   Wang SH, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0932-7
   Wang SH, 2018, J MED SYST, V42, DOI [10.1007/s10916-017-0845-x, 10.1007/s10916-018-0932-7]
NR 37
TC 120
Z9 124
U1 6
U2 70
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15467
EP 15479
DI 10.1007/s11042-019-7469-8
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900061
DA 2024-07-18
ER

PT J
AU Zhang, NN
   Wu, CX
   Wu, Y
   Xiong, NN
AF Zhang, Nana
   Wu, Chunxue
   Wu, Yan
   Xiong, Neal N.
TI An improved target tracking algorithm and its application in intelligent
   video surveillance system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent video surveillance; Target tracking; Unscented Kalman
   particle filter; Multimedia surveillance system
ID PARTICLE FILTER; STATE ESTIMATION
AB Target tracking is one of the pivotal technologies in intelligent video surveillance systems. Facing the complex and various scenarios in practical applications, improving the accuracy and real-time of target detection and tracking is has become the goal of current monitoring systems. Firstly, the target feature expression model is established by fusing Sobel Median Binary Pattern (SMBP) and H-S features while the final target probability model is set up by a weighted color kernel function histogram. Secondly, the final target probability model is established by fusing a weighted color kernel function histogram. Thirdly, the improved unscented Kalman particle filtering algorithm proposed in this paper is embedded in the target tracking framework to complete the target tracking. Lastly, compared with the traditional tracking algorithm, the experiments results show that the target tracking algorithm proposed in this paper improves the tracking accuracy by about 4%.
C1 [Zhang, Nana; Wu, Chunxue] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
   [Wu, Yan] Indiana Univ, Sch Publ & Environm Affairs, Bloomington, IN 47405 USA.
   [Xiong, Neal N.] Northeastern State Univ, Dept Math & Comp Sci, Tahlequah, OK USA.
C3 University of Shanghai for Science & Technology; Indiana University
   System; Indiana University Bloomington
RP Wu, CX (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
EM nanazhang_9301@163.com; wcx@usst.edu.cn; wuyan8910@126.com;
   xiongnaixue@gmail.com
RI Chunxue, Wu/L-1972-2019; xiong, naixue/M-4277-2019
OI Chunxue, Wu/0000-0001-8498-3881; xiong, naixue/0000-0002-0394-4635
CR Akhtar and Jahanzeb, 2015, PARTICLE TRACKING US
   Berestycki N, 2017, PROBAB THEORY REL, P1
   Chen J, 2010, BUILD ENVIRON, V45, P1113, DOI 10.1016/j.buildenv.2009.10.017
   Daum F, 2011, SPIE DEF SEC SENS
   Doucet A, 2011, HDB NONLINEAR FILTER, V12
   Hou YM, 2012, ADV MATER RES-SWITZ, V461, P571, DOI 10.4028/www.scientific.net/AMR.461.571
   Huang M, 2015, OPTIK, V126, P2144, DOI 10.1016/j.ijleo.2015.05.095
   Israni S, 2016, INT C EL EL OPT TECH
   Jafarzadeh S, 2012, IEEE T IND ELECTRON, V59, P4207, DOI 10.1109/TIE.2011.2174533
   Khattak AJ, 2017, INTEGRATING BIG DATA
   Kumar DN, 2017, 2017 6 INT C REL INF
   Lutfy OF, 2014, ARAB J SCI ENG, V39, P4737, DOI 10.1007/s13369-014-1088-5
   Menegaz HMT, 2015, IEEE T AUTOMAT CONTR, V60, P2583, DOI 10.1109/TAC.2015.2404511
   Miao Q, 2013, MICROELECTRON RELIAB, V53, P805, DOI 10.1016/j.microrel.2012.12.004
   Milan A, 2016, IEEE T PATTERN ANAL, V38, P2054, DOI 10.1109/TPAMI.2015.2505309
   Min K, 2006, 2006 CIE INT C RAD
   Murangira A, 2011, P INT C INF FUS
   Okuma Kenji, 2004, EUR C COMP VIS
   Poteralski A, 2014, OPTIMIZATION MECH ST
   Saracen M, 2007, TREATMENT TARGET POS, P28
   Suzuki H, 2013, PROCEDIA COMPUT SCI, V24, P30, DOI 10.1016/j.procs.2013.10.025
   Uysal MS, 2015, INT WORK CONTENT MUL
   Vaccarella A, 2013, IEEE T INSTRUM MEAS, V62, P2067, DOI 10.1109/TIM.2013.2248304
   Van Trees Harry L., 2007, A Tutorial on Particle Filters for Online Nonlinear/NonGaussian Bayesian Tracking, P723, DOI [10.1109/9780470544198.ch73, DOI 10.1109/9780470544198.CH73]
   Wang J, 2015, MULTITARGET TRACKING
   Wang Y, 2016, INT C YOUNG COMP SCI
   Xia G, 2016, EVOL COMPUT
   Yadav Kuldeep, 2015, P 20 INT C INTELLIGE, P333, DOI 10
   Yura Y, 2014, J STAT COMPUT SIM, V84, P2073, DOI 10.1080/00949655.2013.781603
   Zhang Min, 2015, Journal of University of Electronic Science and Technology of China, V44, P344, DOI 10.3969/j.issn.1001-0548.2015.03.005
   Zhou C, 2015, PE TLD PARALLEL EXTE
   Zhou Z, 2014, J SOFTW, V9
   Zhu Q, 2014, CROWD TARGET POSITIO
NR 33
TC 3
Z9 6
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 15965
EP 15983
DI 10.1007/s11042-018-6871-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600010
DA 2024-07-18
ER

PT J
AU Perdigao, P
   Lousa, P
   Ascenso, J
   Pereira, F
AF Perdigao, Pedro
   Lousa, Pedro
   Ascenso, Joao
   Pereira, Fernando
TI Visual monitoring of High-Sea fishing activities using deep
   learning-based image processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vessel monitoring systems; Fishing detection; Image compression; Image
   enhancement; Deep learning
AB Due to the increasing shortage of fish in the seas, Vessel Monitoring Systems (VMS) play a very important role in fishing activity monitoring, control and surveillance. In this context, the detection of fishing activities in prohibited zones is a critical task. Although position, speed and other information are provided by the VMS system, detecting fishing activities using only this type of information may be rather ineffective. The purpose of this paper is to propose an intelligent video-surveillance system that is able to automatically detect if (and when) fishing activities occur by automatically visually monitoring the vessel activities. After detection, the Control Center would be informed of relevant events and receive visual data through a low-bandwidth, low-cost satellite link to check if illegal activities are effectively being performed. To achieve this goal, the proposed visual monitoring solution adopts a deep-learning approach twice: First, to detect the fishing activities at the vessel, a well-known convolutional neural network designed for image classification is exploited. Second, to enhance at the Control Center the heavily compressed decoded images, transmitted with a low-bandwidth satellite channel, a convolutional neural network suitable for image restoration is also used. The proposed monitoring system follows a new approach for the problem addressed based on image data and can significantly improve the VMS even detection and validation efficiency by exploiting advanced image processing tools, thus helping to ensure the availability and sustainability of fish stocks for generations to come.
C1 [Perdigao, Pedro; Ascenso, Joao; Pereira, Fernando] Univ Lisbon, Inst Super Tecn, Inst Telecomunicacoes, Lisbon, Portugal.
   [Lousa, Pedro] Xsealance, Queluz, Portugal.
C3 Instituto de Telecomunicacoes; Universidade de Lisboa
RP Ascenso, J (corresponding author), Univ Lisbon, Inst Super Tecn, Inst Telecomunicacoes, Lisbon, Portugal.
EM joao.ascenso@lx.it.pt
RI Pereira, Fernando/K-4046-2012; Pereira, Fernando/HNR-7786-2023; Ascenso,
   Joao/B-9024-2008
OI Ascenso, Joao/0000-0001-9902-5926; Bernardo Pereira, Fernando
   Manuel/0000-0001-6100-947X
CR Amabdiyil S, 2016, INT C WIR COMM SIGN
   Bloisi D, 2011, INTERNATIONAL DEFENSE AND HOMELAND SECURITY SIMULATION WORKSHOP, (DHSS 2011), P141
   Food and Agricultural Organization of the United Nations, 2018, 2018 STAT WORLD FISH
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jiang X., 2016, CAN C ART INT VICT C
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lucas A, 2018, IEEE SIGNAL PROC MAG, V35, P20, DOI 10.1109/MSP.2017.2760358
   Marzuki MI, 2018, IEEE J OCEANIC ENG, V43, P689, DOI 10.1109/JOE.2017.2723278
   Masko D., 2015, Degree Project
   PerdigAo P., 2018, THESIS
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Richter T, 2016, INT C IM PROC AZ PHO
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Tello M., 2005, IEEE GEOSCIENCE REMO, V2
   Wallace G. K., 1991, Communications of the ACM, V34, P30, DOI 10.1145/103085.103089
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zisserman A., 2014, ARXIV14091556
NR 19
TC 6
Z9 6
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22131
EP 22156
DI 10.1007/s11042-020-08949-9
EA MAY 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000533058600002
DA 2024-07-18
ER

PT J
AU Pourhadi, A
   Mahdavi-Nasab, H
AF Pourhadi, Ali
   Mahdavi-Nasab, Homayoun
TI A robust digital image watermarking scheme based on bat algorithm
   optimization and SURF detector in SWT domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Stationary wavelet transform; Speed-up robust
   feature; Bat algorithm; Arnold transform
ID STATIONARY WAVELET TRANSFORM; EFFICIENT; CLASSIFICATION
AB This paper presents an optimized robust digital image watermarking scheme based on Stationary Wavelet Transform (SWT) using Bat optimization Algorithm (BA) and Speed-Up Robust Feature (SURF). The proposed scheme applies high-frequency coefficients of the SWT of the host image in the BA framework to optimize watermark strength factors in the embedding process, considering relevant attacks. On the final step of this process, the SURF detector is employed on the watermarked image for getting point features used for geometric distortion correction. For watermark extracting, the primary step is to correct probable geometrical distortions, utilizing the SURF rotation and scaling invariance property, and the procedure goes on by executing the reverse of embedding phase steps. For evaluating the capabilities of the proposed algorithm, different types of image processing operations such as Gaussian filtering, scaling, rotation and salt and pepper, Poison, speckle, and Gaussian noise, have been used as attacks. According to the experimental results, the proposed combination of techniques exhibits an overall superior performance in both imperceptibility and robustness metrics in various situations compared to state-of-the-art and relevant methods.
C1 [Pourhadi, Ali; Mahdavi-Nasab, Homayoun] Islamic Azad Univ, Dept Elect Engn, Najafabad Branch, Najafabad, Iran.
   [Mahdavi-Nasab, Homayoun] Islamic Azad Univ, Digital Proc & Machine Vis Res Ctr, Najafabad Branch, Najafabad, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Mahdavi-Nasab, H (corresponding author), Islamic Azad Univ, Dept Elect Engn, Najafabad Branch, Najafabad, Iran.; Mahdavi-Nasab, H (corresponding author), Islamic Azad Univ, Digital Proc & Machine Vis Res Ctr, Najafabad Branch, Najafabad, Iran.
EM mahdavinasab62@gmail.com
RI Mahdavi-Nasab, Homayoun/AAN-3772-2021
OI Mahdavi-Nasab, Homayoun/0000-0003-2992-8657
CR Agoyi M, 2015, SIGNAL IMAGE VIDEO P, V9, P735, DOI 10.1007/s11760-014-0624-9
   Ali ES, 2014, INT J ELEC POWER, V61, P683, DOI 10.1016/j.ijepes.2014.04.007
   Ali M, 2018, INT J SYST ASSUR ENG, V9, P602, DOI 10.1007/s13198-014-0288-4
   Amiri T, 2016, MULTIMED TOOLS APPL, V75, P8527, DOI 10.1007/s11042-015-2770-7
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Beheshti Z., 2013, INT J ADV SOFT COMPU, V5, P1
   Behloul A, 2014, P 6 INT C MAN EM DIG
   Bendib MM, 2015, PATTERN ANAL APPL, V18, P829, DOI 10.1007/s10044-014-0373-y
   Cedillo-Hernandez M, 2012, 35 INT C TEL SIGN PR
   Cedillo-Hernandez M, 2013, RADIOENGINEERING, V22, P1057
   Chen YH, 2015, NEURAL COMPUT APPL, V26, P291, DOI 10.1007/s00521-014-1615-z
   Civicioglu P, 2013, ARTIF INTELL REV, V39, P315, DOI 10.1007/s10462-011-9276-0
   Elshazly EH, 2015, SIGNAL IMAGE VIDEO P, V9, P89, DOI 10.1007/s11760-014-0684-x
   Holschneider M, 1990, Wavelets, P286, DOI DOI 10.1007/978-3-642-75988-828
   Huang HN, 2015, J SIGNAL PROCESS SYS, V80, P197, DOI 10.1007/s11265-013-0863-y
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Kaur T, 2019, MULTIMED TOOLS APPL, V78, P21853, DOI 10.1007/s11042-019-7498-3
   Kazemivash B, 2018, SOFT COMPUT, V22, P4083, DOI 10.1007/s00500-017-2617-4
   Kazemivash B, 2017, MULTIMED TOOLS APPL, V76, P20499, DOI 10.1007/s11042-016-3962-5
   Khan M, 2015, NEURAL COMPUT APPL, V26, P845, DOI 10.1007/s00521-014-1747-1
   Kishore P. V. V., 2015, INT C SIGN PROC COMM
   Kumsawat P, 2005, IEEE T SIGNAL PROCES, V53, P4707, DOI 10.1109/TSP.2005.859323
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Loukhaoukha K., 2011, J Inf Hiding Multim Signal Process, V2, P303
   Luo JK, 2020, INTELL DATA ANAL, V24, P581, DOI 10.3233/IDA-194641
   Mehta R, 2017, INT J MACH LEARN CYB, V8, P379, DOI 10.1007/s13042-015-0331-z
   Mehta R, 2018, INT J MACH LEARN CYB, V9, P145, DOI 10.1007/s13042-015-0329-6
   Miller ML, 2002, P INT C IM PROC ROC
   Mirjalili S, 2014, NEURAL COMPUT APPL, V25, P663, DOI 10.1007/s00521-013-1525-5
   Nagarjuna PV, 2013, 6 INT C CONT COMP IC
   Sabba S, 2014, INT J BIO-INSPIR COM, V6, P140, DOI 10.1504/IJBIC.2014.060598
   Shan X, 2016, SCI PROGRAMMING-NETH, V2016, DOI 10.1155/2016/8031560
   Sheikh HR, 2004, IEEE INT C AC SPEECH
   Soliman MM, 2016, NEURAL COMPUT APPL, V27, P469, DOI 10.1007/s00521-015-1868-1
   Su QT, 2015, SIGNAL IMAGE VIDEO P, V9, P991, DOI 10.1007/s11760-013-0534-2
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Wang JW, 2015, MULTIMEDIA SYST, V21, P345, DOI 10.1007/s00530-013-0338-9
   Wu L, 2009, 1 INT C INF SCI ENG
   Wu Yan, 2006, Chinese Journal of Aeronautics, V19, P326, DOI 10.1016/S1000-9361(11)60336-1
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Yong JS, 2019, APPL MATH SER B, V34, P480, DOI 10.1007/s11766-019-3714-1
   Zhang B., 2010, IEEE INT C INF THEOR
   Zhang YD, 2015, J MED IMAG HEALTH IN, V5, P1395, DOI 10.1166/jmihi.2015.1542
   Zhou X., 2006, 2006 IEEE INT S EL I
NR 45
TC 37
Z9 38
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21653
EP 21677
DI 10.1007/s11042-020-08960-0
EA MAY 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000531216800002
DA 2024-07-18
ER

PT J
AU Wang, CY
   Li, C
AF Wang, Caiyin
   Li, Chao
TI Spot color watermarking: the use of the IWT-SVD and tone correction
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spot color printing; Digital image watermarking; Integer wavelet
   transform; Singular value decomposition; Digital signature; Tone
   correction model
ID ROBUST WATERMARKING; WAVELET TRANSFORM; SCHEME
AB Watermarking has long been a necessary technology in the package printing industry for copyright protection and counterfeit prevention. However, A large number of spot colors are used in the industry, which poses a challenge for the watermarking application. In light of the integer wavelet transform (IWT) and singular value decomposition (SVD), we herein present a robust watermarking algorithm for spot color printing based on the color space transformation principle. First, a spot color channel was separated from the original image using the Neugebauer model. The image of the spot color channel was then transformed with the IWT, and the watermark was embedded in singular values of the 1-level IWT decomposed sub-bands. To enhance the security, Arnold scrambling and encryption were adopted, and a digital signature was embedded in the watermarked images. Hence, the extraction of the digital signature is required prior to the extraction of the watermark information. In the extraction stage, the watermark was extracted from the scanned grayscale image. The spot color scale was designed, and the tone correction model was established for the scanned grayscale image. A series of tests were conducted, and the results showed that the method is effective in resisting spot color distortion attacks in the print-scanning process, and the imperceptibility, capacity as well as security in the spot color are also favorable.
C1 [Wang, Caiyin; Li, Chao] Dalian Polytech Univ, Sch Light Ind & Chem Engn, Dalian 116034, Liaoning, Peoples R China.
C3 Dalian Polytechnic University
RP Wang, CY (corresponding author), Dalian Polytech Univ, Sch Light Ind & Chem Engn, Dalian 116034, Liaoning, Peoples R China.
EM wcyvivien@126.com; dlpulc@gmail.com
FU National Natural Science Foundation of China [61802041]; Doctoral
   Scientific Foundation of Liaoning Province of China [1578443378366]
FX This work is supported by the National Natural Science Foundation of
   China [Grant No. 61802041], the Doctoral Scientific Foundation of
   Liaoning Province of China [Grant No. 1578443378366]. The authors would
   like to thank American Journal Experts for language assistance, the
   anonymous reviewers and editors for their very valuable comments and
   suggestions.
CR Abdelhakim AM, 2018, MULTIMED TOOLS APPL, V77, P27895, DOI 10.1007/s11042-018-6014-5
   Al-Haj Ali, 2007, Journal of Computer Sciences, V3, P740, DOI 10.3844/jcssp.2007.740.746
   Alattar OM, 2003, PROC SPIE, V5020, P430, DOI 10.1117/12.477305
   [Anonymous], 2013, Colour Appearance Models
   Baqai FA, 2005, IEEE SIGNAL PROC MAG, V22, P87, DOI 10.1109/MSP.2005.1407718
   Bassia P, 2001, IEEE T MULTIMEDIA, V3, P232, DOI 10.1109/6046.923822
   Benrhouma O, 2016, MULTIMED TOOLS APPL, V75, P8695, DOI 10.1007/s11042-015-2786-z
   Gaur S, 2016, 2016 FOURTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P563, DOI 10.1109/PDGC.2016.7913187
   Gong ZA, 2012, 2012 INTERNATIONAL CONFERENCE ON QUALITY, RELIABILITY, RISK, MAINTENANCE, AND SAFETY ENGINEERING (ICQR2MSE), P1130, DOI 10.1109/ICQR2MSE.2012.6246420
   Guo CQ, 2010, 2010 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, NETWORKING AND INFORMATION SECURITY (WCNIS), VOL 1, P518, DOI 10.1109/WCINS.2010.5541833
   Hersch RD, 2005, PROC SPIE, P434, DOI 10.1117/12.588907
   Hunt R, 2004, REPROD COLOUR 6 EDIT
   Kadian P, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P987, DOI 10.1109/SPIN.2019.8711681
   Lai CC, 2011, DIGIT SIGNAL PROCESS, V21, P522, DOI 10.1016/j.dsp.2011.01.017
   Lee ML, 2015, MULTIMED TOOLS APPL, V75, P1
   Liang X, 2010, J NANJING U SCI TECH, V34, P75
   Makbol NM, 2014, I S INTELL SIG PROC, P48, DOI 10.1109/ISPACS.2014.7024423
   Makbol NM, 2014, DIGIT SIGNAL PROCESS, V33, P134, DOI 10.1016/j.dsp.2014.06.012
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Mizumoto T, 2003, ELECTRON COMM JPN 3, V86, P11, DOI 10.1002/ecjc.10059
   Moeinaddini E, 2018, MULTIMED TOOLS APPL, V77, P26083, DOI 10.1007/s11042-018-5838-3
   Peng J, 2019, 11 INT C DIG IM PROC, V11179
   Pizzolante R, 2018, COMPUT SECUR, V74, P384, DOI 10.1016/j.cose.2017.06.003
   Reed A, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083134
   Rentzeperis I, 2015, J VISION, V15, DOI 10.1167/15.9.13
   Sangmule SL, 2012, J IMAGING SCI TECHN, V56, DOI 10.2352/J.ImagingSci.Technol.2012.56.1.010507
   Song XH, 2013, QUANTUM INF PROCESS, V12, P3689, DOI 10.1007/s11128-013-0629-2
   Song XH, 2014, MULTIMEDIA SYST, V20, P379, DOI 10.1007/s00530-014-0355-3
   Suchy M, 2005, IS&T'S NIP21: INTERNATIONAL CONFERENCE ON DIGITAL PRINTING TECHNOLOGIES, FINAL PROGRAM AND PROCEEDINGS, P93
   Taylor J., 2004, Color Res. Appl., V29, P395, DOI [10.1002/col.20049, DOI 10.1002/COL.20049]
   Thongkor K, 2018, J VIS COMMUN IMAGE R
   Thongkor K, 2017, PROC SPIE, V10420, DOI 10.1117/12.2281668
   Wang CY, 2017, MULTIMED TOOLS APPL, V76, P16291, DOI 10.1007/s11042-016-3909-x
   [王彩印 Wang Caiyin], 2017, [电子科技大学学报, Journal of University of Electronic Science and Technology of China], V46, P529
   Wang YL, 2018, IEEE ACCESS, V6, P8882, DOI 10.1109/ACCESS.2018.2810058
   Wyble DR, 2000, COLOR RES APPL, V25, P4, DOI 10.1002/(SICI)1520-6378(200002)25:1<4::AID-COL3>3.0.CO;2-X
   Yong X, 2014, CYBER ENABLED DISTRI, P286
   Zhang MM, 2019, INT J DIGIT CRIME FO, V11, P28, DOI 10.4018/IJDCF.2019100103
NR 38
TC 1
Z9 1
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21627
EP 21652
DI 10.1007/s11042-020-08981-9
EA MAY 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000531216800001
DA 2024-07-18
ER

PT J
AU Lian, ZC
   Shao, S
   Huang, CY
AF Lian, Zhichao
   Shao, Shuai
   Huang, Chanying
TI A Real Time Face Tracking System based on Multiple Information Fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple object tracking; Feature fusion; Face detection; Machine
   learning
ID MULTITARGET TRACKING
AB Face tracking is one of key steps in real surveillance system. In this paper, a real-time face tracking system using multiple objects tracking algorithm is proposed. Multiple objects tracking algorithms typically consist of two parts: object detection and data association. In our system, we particularly use Multi-task convolutional neural network (MTCNN) to detect faces. Simultaneously, aiming at dealing with the tracking failure caused by object occlusion or rapid object movement, we use multiple features including appearance feature, motion feature, and shape feature for tracking. Furthermore, a judgement method is applied to measure whether tracking is successful or not. After that, depending on the tracking state, we adjust the weights of different features for feature fusion. From the experimental results, it can be concluded that, compared with the traditional tracking algorithms the proposed multi-object tracking algorithm has a better tracking effect in the real scenes.
C1 [Lian, Zhichao; Shao, Shuai; Huang, Chanying] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Key Lab Spectral Imaging & Intelligent Sense, Nanjing, Peoples R China.
C3 Nanjing University of Science & Technology
RP Lian, ZC (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Key Lab Spectral Imaging & Intelligent Sense, Nanjing, Peoples R China.
EM lzcts@163.com
RI shao, shuai/AAX-3627-2020; Lian, Zhichao/E-7660-2012
OI shao, shuai/0000-0002-7655-5630; 
FU Natural Science Foundation of Jiangsu Province [BK20150784]; Fundamental
   Research Funds for the Central Universities [30917011324]; China
   Postdoctoral Foundation [2015 M581800]; National Key Research and
   Development Program of China [2016YFF0103604]; Open Research Fund of
   Jiangsu Key Laboratory of Spectral Imaging and Intelligent Sense
   [3091801410410]
FX This work was supported in part by the Natural Science Foundation of
   Jiangsu Province under Grant No. BK20150784, in part by the Fundamental
   Research Funds for the Central Universities No.30917011324, in part by
   China Postdoctoral Foundation No. 2015 M581800, in part by the National
   Key Research and Development Program of China under Grant
   2016YFF0103604, and in part by the Open Research Fund of Jiangsu Key
   Laboratory of Spectral Imaging and Intelligent Sense No. 3091801410410.
CR [Anonymous], [No title captured]
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bochinski Erik, 2017, 2017 14th IEEE International Conference on Advanced Video and Signal-Based Surveillance (AVSS), DOI 10.1109/AVSS.2017.8078516
   Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232
   Brendel W, 2011, PROC CVPR IEEE, P1273, DOI 10.1109/CVPR.2011.5995395
   Chen PH, 2005, APPL STOCH MODEL BUS, V21, P111, DOI 10.1002/asmb.537
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   FISHER B, 1989, NEW ENGL J MED, V320, P479, DOI 10.1056/NEJM198902233200802
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hu WM, 2012, IEEE T PATTERN ANAL, V34, P2420, DOI 10.1109/TPAMI.2012.42
   Jain V., 2010, Fddb: A benchmark for face detection in unconstrained settings
   Kuo CH, 2010, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2010.5540148
   LINKS IKF, 1995, INTRO KALMAN FILTER
   LUO W, ARXIV14097618V4
   Milan A, 2017, AAAI CONF ARTIF INTE, P4225
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Qin Z, 2012, PROC CVPR IEEE, P1972, DOI 10.1109/CVPR.2012.6247899
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Song B, 2010, LECT NOTES COMPUT SC, V6311, P605, DOI 10.1007/978-3-642-15549-9_44
   Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30
   Sugimura D, 2009, IEEE I CONF COMP VIS, P1467, DOI 10.1109/ICCV.2009.5459286
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   YANG B, 2012, PROC CVPR IEEE, P1918, DOI DOI 10.1109/CVPR.2012.6247892
   Yang B, 2011, PROC CVPR IEEE, P1233, DOI 10.1109/CVPR.2011.5995587
   Yang M, 2007, IEEE I CONF COMP VIS, P897
   YU F, 2016, LECT NOTES COMPUTER, V9914
   Zhang JM, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P379, DOI 10.1109/AVSS.2012.51
   Zhang L, 2014, IEEE T PATTERN ANAL, V36, P756, DOI 10.1109/TPAMI.2013.221
   Zhang L, 2013, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2013.240
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 37
TC 4
Z9 4
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16751
EP 16769
DI 10.1007/s11042-020-08889-4
EA MAY 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000530603300003
DA 2024-07-18
ER

PT J
AU Chatterjee, A
   Ghosal, SK
   Sarkar, R
AF Chatterjee, Agneet
   Ghosal, Sudipta Kumar
   Sarkar, Ram
TI LSB based steganography with OCR: an intelligent amalgamation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; LSB; Optical character recognition; Cover image; Feature
   extraction
ID EXPLORING STEGANOGRAPHY; RECOGNITION
AB Steganography, the art of hiding information within information, has an added advantage over cryptography as the person viewing the object in which the information is hidden has no knowledge of the presence of any hidden information. The Least Significant Bit (LSB) embedding technique which is one of the widely used techniques ensures an indiscernible change in the cover image oblivious to the human eye. In this paper, an Optical Character Recognition (OCR) based Steganographic technique is introduced, in which message, in its feature form, is embedded in the cover image. We extract character level features from images which contain the textual message, and embed these features in the cover image, strengthening the data hiding objective of steganography. This is because an intruder has to know about the presence of features as hidden bits and even thereafter has to have trained OCR model to retrieve the texts from the decoded information i.e. from the features. We validate our results on an English Printed Character dataset (Chars74K Dataset), and present the evaluation results for varied LSBs.
C1 [Chatterjee, Agneet; Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, 188,Raja SC Mallick Rd, Kolkata 700032, W Bengal, India.
   [Ghosal, Sudipta Kumar] Nalhati Govt Polytech, Dept Comp Sci & Technol, Birbhum 731243, India.
C3 Jadavpur University
RP Sarkar, R (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, 188,Raja SC Mallick Rd, Kolkata 700032, W Bengal, India.
EM agneet257@gmail.com; sudipta.ghosal@gmail.com; raamsarkar@gmail.com
RI Sarkar, Ram/AAX-3822-2020
OI Sarkar, Ram/0000-0001-8813-4086
CR [Anonymous], 2009, Character recognition in natural images
   Areepongsa S, 2000, TENCON IEEE REGION, pB250
   Avola D, 2009, P 2 INT C PERV TECHN, P1
   Avola D, 2017, LECT NOTES COMPUTER, V10484
   Avola D, 2020, MULTIMED TOOLS APPL, V79, P4463, DOI 10.1007/s11042-019-7196-1
   Bai JL, 2017, DISPLAYS, V46, P42, DOI 10.1016/j.displa.2016.12.004
   Boehm B., 2014, Stegexpose-a tool for detecting lsb steganography
   Charles PK., 2012, International Journal of Engineering Research and Applications, V2, P659
   Chaudhuri BB, 1998, PATTERN RECOGN, V31, P531, DOI 10.1016/S0031-3203(97)00078-2
   Dumitrescu S, 2002, INT WORKSH INF HID
   Dumitrescu S, 2002, P INT C IM PROC IEEE, V3
   Elhadad A, 2020, SOFT COMPUT, V24, P2101, DOI 10.1007/s00500-019-04041-z
   Elhadad A, 2017, NEURAL COMPUT APPL, V28, pS91, DOI 10.1007/s00521-016-2323-7
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Garg T, 2018, INT J COMPUT SCI ENG, V6, P1267
   Ghazanfari K, 2011, TENCON 2011 2011 IEE
   Hallouli K, 2002, PATT REC 2002 P 16 I, V3
   Hetzl Stefan, 2005, IFIP INT C COMM MULT
   Hinton GE, 1992, ADAPTIVE ELASTIC MOD
   Hussain M, 2016, SYMMETRY-BASEL, V8, DOI 10.3390/sym8060041
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Joshi K., 2017, INT J ENG TECHNOL, V8, P3043, DOI [10.21817/ijet/2016/v8i6/160806266, DOI 10.21817/IJET/2016/V8I6/160806266]
   Jung K.-H., 2014, MULTIMED TOOLS APPL, V74, P2143
   Kawaguchi E, 1999, P SOC PHOTO-OPT INS, V3528, P464, DOI 10.1117/12.337436
   Kruus P., 2011, ADV SECURITY RES J, V05, P41
   Kumar M, 2019, ARTIF INTELL REV, V52, P2235, DOI 10.1007/s10462-017-9607-x
   Lorigo LM, 2006, IEEE T PATTERN ANAL, V28, P712, DOI 10.1109/TPAMI.2006.102
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Patil V., 2011, ELIXIR COMPUT SCI EN, V41, P5587
   Sahu VijayLaxmi., 2013, INT J SCI RES IJSR, V2, P87
   Sallee P, 2004, LECT NOTES COMPUT SC, V2939, P154
   Shah PD, 2018, INT C INT COMP APPL
   Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu HT, 2008, LECT NOTES COMPUT SC, V5284, P236
   Yang CS, 2017, PATTERN RECOGN LETT, V100, P14, DOI 10.1016/j.patrec.2017.08.005
   Yuan HD, 2014, INFORM SCIENCES, V254, P197, DOI 10.1016/j.ins.2013.08.012
NR 38
TC 14
Z9 15
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11747
EP 11765
DI 10.1007/s11042-019-08472-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400022
DA 2024-07-18
ER

PT J
AU Liu, YN
AF Liu, Yane
TI Preparation and electrochemical performance of Lithium sulfur battery
   cathode materials based on wavelet transform image processing technology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wavelet transform; Image processing; Lithium-sulfur battery; Cathode
   material; Electrochemical performance
ID CARBON; LIFEPO4
AB The industrial production of lithium-sulfur batteries has become a problem, and the core problem of lithium-sulfur batteries lies in the positive electrode materials. This paper is mainly to improve the cathode material of lithium-sulfur batteries. In order to improve the conductivity of the positive electrode of sulfur, to solve the volume expansion of sulfur during discharge, to inhibit the dissolution of polysulfide in the electrolyte and the shuttle effect, this paper improved the high electrochemical performance of lithium-sulfur batteries and promoted the industrialization of lithium-sulfur batteries. Simultaneously, combined with wavelet analysis and transform image processing technology, this paper conducted qualitative analysis on the performance of battery materials, and combined experiments to conduct research and analysis. Experiments show that the method proposed in this study is scientific and can provide theoretical reference for subsequent related research.
C1 [Liu, Yane] Lu Liang Univ, Phys Dept, Lvliang 033001, Shanxi, Peoples R China.
RP Liu, YN (corresponding author), Lu Liang Univ, Phys Dept, Lvliang 033001, Shanxi, Peoples R China.
EM liuyane198513@163.com
CR Chen C, 2017, J MATER CHEM A, V5, P1428, DOI 10.1039/c6ta09146f
   Chen S, 2017, ACS APPL MATER INTER, V9, P8669, DOI 10.1021/acsami.6b14862
   Ding Z, 2017, NEW J CHEM, V41
   Guo J, 2018, IONICS, V24, P2219, DOI 10.1007/s11581-017-2351-z
   Kazda T, 2018, J ENERGY STORAGE, V15, P329, DOI 10.1016/j.est.2017.10.011
   Konishi H, 2017, J SOLID STATE CHEM, V249, P80, DOI 10.1016/j.jssc.2017.02.022
   Lang XS, 2018, J ALLOY COMPD, V739, P536, DOI 10.1016/j.jallcom.2017.12.325
   Li L, 2017, CHEMSUSCHEM, V10
   Li W, 2017, J ALLOY COMPD, V693, P1045, DOI 10.1016/j.jallcom.2016.09.235
   Li XL, 2017, J ALLOY COMPD, V692, P40, DOI 10.1016/j.jallcom.2016.09.004
   Li Yongliang, 2017, Journal of Shenzhen University Science and Engineering, V34, P132, DOI 10.3724/SP.J.1249.2017.02132
   Liu C, 2017, CHEMISTRYSELECT, V2, P11030, DOI 10.1002/slct.201702228
   Liu J, 2017, J ALLOY COMPD, V718, P373, DOI 10.1016/j.jallcom.2017.05.206
   Luo J, 2017, ACTA POLYM SIN, P633, DOI 10.11777/j.issn1000-3304.2017.16170
   Mosavati N, 2017, J POWER SOURCES, V340, P210, DOI 10.1016/j.jpowsour.2016.11.033
   Raj H, 2018, IONICS, V26, P1
   Rehman S, 2017, J MATER CHEM A, V5, P3014, DOI 10.1039/c6ta10111a
   Wang YQ, 2017, J APPL ELECTROCHEM, V47, P631, DOI 10.1007/s10800-017-1068-z
   Wu YJ, 2018, INT J HYDROGEN ENERG, V43, P2050, DOI 10.1016/j.ijhydene.2017.12.061
   Xue M, 2018, J MAT SCI, V53
NR 20
TC 0
Z9 0
U1 9
U2 84
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12493
EP 12506
DI 10.1007/s11042-020-08637-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400054
DA 2024-07-18
ER

PT J
AU Pakdaman, F
   Hashemi, MR
   Ghanbari, M
AF Pakdaman, Farhad
   Hashemi, Mahmoud Reza
   Ghanbari, Mohammad
TI A low complexity and computationally scalable fast motion estimation
   algorithm for HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion estimation; Video compression; Power-constrained video coding;
   High efficiency video coding (HEVC); Search range reduction
ID ARCHITECTURE DESIGN; MODE DECISION; REDUCTION; QUALITY; LEVEL
AB Motion Estimation (ME) is one of the most computationally demanding parts of video encoders. The Test Zone (TZ) search is a popular fast ME algorithm, which is recommended for High-Efficiency Video Coding (HEVC). While the TZ search achieves an excellent coding efficiency, it is not a favorable choice for hardware implementations due to 1) a relatively high computational complexity, 2) inducing data dependency among the neighboring blocks, which complicates hardware implementations and parallel processing in software implementations, and 3) lack of computational adjustability, which is required for video encoding in power-constrained devices. This paper diagnoses the cause of these issues to be in the multiple starting search points of the TZ search algorithm. Accordingly, a method is proposed to find a single reliable starting point that replaces the first step of the TZ search algorithm. To do so, both current and reference frames are analyzed using a complex wavelet transform, and similar salient points are identified among the two frames. Then a light-weight process is used to match these points to find a single reliable starting point. The reliability of this point leads to reduced zonal refinement range with negligible cost in compression efficiency. Since adjusting the refinement range can be used as an effective way for adjusting the complexity, this results in a computationally scalable ME algorithm, named FMECWT. In contrast to the existing methods, FMECWT does not rely on neighboring blocks, which eliminates the inherent data dependency of TZ search. Experimental results show that FMECWT achieves ~35% to ~85% ME time reduction compared to TZ search, with only 0.1% to 1.7% increase in BD-Rate.
C1 [Pakdaman, Farhad; Hashemi, Mahmoud Reza; Ghanbari, Mohammad] Univ Tehran, Coll Engn, Sch Elect & Comp Engn, Tehran 14399571, Iran.
   [Ghanbari, Mohammad] Univ Essex, Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, Essex, England.
C3 University of Tehran; University of Essex
RP Hashemi, MR (corresponding author), Univ Tehran, Coll Engn, Sch Elect & Comp Engn, Tehran 14399571, Iran.
EM rhashemi@ut.ac.ir
RI Ghanbari, Mohammad/L-4053-2019; Hashemi, Mahmoud Reza/H-2172-2011;
   Pakdaman, Farhad/L-1457-2019
OI Ghanbari, Mohammad/0000-0002-5482-8378; Pakdaman,
   Farhad/0000-0001-6526-3811
CR [Anonymous], 2017, ALGORITHM DESCRIPTIO
   [Anonymous], HIGH EFFICIENCY VIDE
   [Anonymous], P IEEE 19 INT WORKSH
   [Anonymous], 2016, INTEL 64 IA 32 ARCHI
   [Anonymous], INT C IM PROC
   [Anonymous], 2012, ITU-R BT.500-13
   [Anonymous], 13 VID COD EXP M
   [Anonymous], 2013, S VLSI CIRC
   Chen TC, 2006, IEEE T CIRC SYST VID, V16, P673, DOI 10.1109/TCSVT.2006.873163
   Chien WD, 2014, IEEE IMAGE PROC, P3696, DOI 10.1109/ICIP.2014.7025750
   Corrêa G, 2016, IEEE T CIRC SYST VID, V26, P1734, DOI 10.1109/TCSVT.2015.2469533
   Correa G, 2016, J REAL-TIME IMAGE PR, V12, P107, DOI 10.1007/s11554-013-0392-8
   Correa G, 2013, IEEE DATA COMPR CONF, P43, DOI 10.1109/DCC.2013.12
   Dong M, 2018, APPL COMPUT ELECTROM, V33, P1
   Fernandez DG, 2020, MULTIMED TOOLS APPL, V79, P16001, DOI 10.1007/s11042-018-7033-y
   Goncalves P, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1763, DOI 10.1109/ICASSP.2018.8462580
   Hosseini E, 2019, MULTIMED TOOLS APPL, V78, P11607, DOI 10.1007/s11042-018-6713-y
   Hu N, 2014, IEEE T CIRC SYST VID, V24, P1310, DOI 10.1109/TCSVT.2014.2306035
   Jou SY, 2015, IEEE T CIRC SYST VID, V25, P1533, DOI 10.1109/TCSVT.2015.2389472
   Kalali E, 2016, IEEE T CONSUM ELECTR, V62, P166, DOI 10.1109/TCE.2016.7514716
   Kim KY, 2014, IEEE T CIRC SYST VID, V24, P1723, DOI 10.1109/TCSVT.2014.2308651
   Lee J, 2017, MULTIMED TOOLS APPL, V76, P24749, DOI 10.1007/s11042-017-4645-6
   Lee T, 2016, P IEEE INT FREQ CONT, P9
   Lee TK, 2017, IEEE T CIRC SYST VID, V27, P2216, DOI 10.1109/TCSVT.2016.2583979
   Li XF, 2015, IEEE INT SYMP CIRC S, P2784, DOI 10.1109/ISCAS.2015.7169264
   Liu Q, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P6, DOI 10.1109/ICIVC.2018.8492851
   Lu CY, 2019, IMC'19: PROCEEDINGS OF THE 2019 ACM INTERNET MEASUREMENT CONFERENCE, P22, DOI 10.1145/3355369.3355580
   Magarey J, 1998, IEEE T SIGNAL PROCES, V46, P1069, DOI 10.1109/78.668557
   Medhat A, 2016, IET IMAGE PROCESS, V10, P438, DOI 10.1049/iet-ipr.2015.0666
   Pakdaman F, 2018, P 7 EUR WORKSH VIS I, P1
   Pakdaman F, 2017, MULTIMED TOOLS APPL, V76, P9891, DOI 10.1007/s11042-016-3584-y
   Penny W, 2016, IEEE IMAGE PROC, P814, DOI 10.1109/ICIP.2016.7532470
   Purnachand N., 2012, 2012 IEEE Second International Conference on Consumer Electronics - Berlin (ICCE-Berlin), P34, DOI 10.1109/ICCE-Berlin.2012.6336494
   Rabaey J, 2009, INTEGR CIRCUIT SYST, P1, DOI 10.1007/978-0-387-71713-5
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Shen LQ, 2014, IEEE T CIRC SYST VID, V24, P1709, DOI 10.1109/TCSVT.2014.2313892
   Singh K, 2018, J SIGNAL PROCESS SYS, V90, P1713, DOI 10.1007/s11265-017-1321-z
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tohidypour HR, 2016, IEEE T MULTIMEDIA, V18, P182, DOI 10.1109/TMM.2015.2510332
   Wang CC, 2017, MULTIMED TOOLS APPL, V76, P25285, DOI 10.1007/s11042-017-4500-9
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei Dai, 2012, 2012 Visual Communications and Image Processing (VCIP), DOI 10.1109/VCIP.2012.6410741
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P559, DOI 10.1109/TMM.2013.2291958
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang SH, 2014, ELECTRON LETT, V50, P673, DOI 10.1049/el.2014.0536
   Yu-Kun Lin, 2008, 2008 IEEE International Solid-State Circuits Conference - Digest of Technical Papers, P314
   Zhang J, 2019, IEEE T IND INFORM, V15, P1437, DOI 10.1109/TII.2018.2844214
   Zhang J, 2018, IEEE T MULTIMEDIA, V20, P29, DOI 10.1109/TMM.2017.2723238
   Zhang YH, 2013, IEEE IMAGE PROC, P2000, DOI 10.1109/ICIP.2013.6738412
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
NR 50
TC 6
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11639
EP 11666
DI 10.1007/s11042-019-08593-y
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400017
DA 2024-07-18
ER

PT J
AU Srihari, D
   Kishore, PVV
   Kumar, EK
   Kumar, DA
   Kumar, MTK
   Prase, MVD
   Prasd, CR
AF Srihari, D.
   Kishore, P. V. V.
   Kumar, E. Kiran
   Kumar, D. Anil
   Kumar, M. Teja Kiran
   Prase, M. V. D.
   Prasd, Ch Raghava
TI A four-stream ConvNet based on spatial and depth flow for human action
   classification using RGB-D data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; RGB-D video data; ConvNets; Multi-stream CNNs;
   Spatio-apparent motion models
ID HUMAN ACTION RECOGNITION
AB Appearance and depth-based action recognition has been researched exclusively for improving recognition accuracy by considering motion and shape recovery particulars from RGB-D video data. Convolutional neural networks (CNN) have shown evidences of superiority on action classification problems with spatial and apparent motion inputs. The current generation of CNNs use spatial RGB videos and depth maps to recognize action classes from RGB-D video. In this work, we propose a 4-stream CNN architecture that has two spatial RGB-D video data streams and two apparent motion streams, with inputs extracted from the optical flow of RGB-D videos. Each CNN stream is packed with 8 convolutional layers, 2 dense and one SoftMax layer, and a score fusion model to merge the scores from four streams. Performance of the proposed 4-stream action recognition framework is tested on our own action dataset and three benchmark datasets for action recognition. The usefulness of the proposed model is evaluated with state-of-the-art CNN architectures for action recognition.
C1 [Srihari, D.; Kishore, P. V. V.; Kumar, E. Kiran; Kumar, D. Anil; Kumar, M. Teja Kiran; Prase, M. V. D.; Prasd, Ch Raghava] Koneru Lakshmaiah Educ Fdn, Green Fields, Vaddeswaram, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Kishore, PVV (corresponding author), Koneru Lakshmaiah Educ Fdn, Green Fields, Vaddeswaram, India.
EM pvvkishore@kluniversity.in
RI Eepuri, Kiran Kumar/R-3308-2017; Cataldi, Antonio/AAM-7411-2021; D, Anil
   Kumar/AAY-6919-2020; Maddala, Teja Kiran Kumar/V-1644-2017; , MVD
   Prasad/U-6732-2018; Kishore, P.V.V./R-3293-2017
OI Eepuri, Kiran Kumar/0000-0001-8963-8454; D, Anil
   Kumar/0000-0002-6051-2169; Maddala, Teja Kiran
   Kumar/0000-0002-2345-6647; , MVD Prasad/0000-0003-2410-1175; Kishore,
   P.V.V./0000-0002-3247-3043
CR Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   [Anonymous], P 7 INT C INT MULT C
   [Anonymous], 2016 23 INT C PATT R
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], 2013 6 INT C BIOM EN
   [Anonymous], SPATIOTEMPORAL MULTI
   [Anonymous], 2016 IEEE INT S MULT
   [Anonymous], 2014, ARXIV14062199
   [Anonymous], 2015, 2015 IEEE C COMP VIS
   [Anonymous], 2014, 2014 IEEE C COMP VIS
   [Anonymous], 2017, Proc. IEEE NAPS
   [Anonymous], 2014, P BRIT MACH VIS C 20
   [Anonymous], CHINESE J COMPUT
   [Anonymous], 2 STREAM SRCNNS ACTI
   [Anonymous], 2016 9 INT S COMP IN
   [Anonymous], 2015 IEEE INT C COMP
   [Anonymous], 2016, 23 INT C PATT REC IC
   [Anonymous], P BRIT MACH VIS C 20
   [Anonymous], 2012 IEEE COMP VIS P
   [Anonymous], GAIT POSTURE
   Burghouts GJ, 2013, PATTERN RECOGN LETT, V34, P1861, DOI 10.1016/j.patrec.2013.01.024
   Chai J, 2017, INT J GEOSYNTH GROUN, V3, DOI 10.1007/s40891-016-0079-x
   Chen LL, 2014, PATTERN RECOGN LETT, V50, P159, DOI 10.1016/j.patrec.2013.09.004
   Feichtenhofer Christoph, 2016, 2016 IEEE C COMP VIS
   Gammulle H, 2017, IEEE WINT CONF APPL, P177, DOI 10.1109/WACV.2017.27
   Ghojogh B, 2018, IEEE SENS J, V18, P1612, DOI 10.1109/JSEN.2017.2784425
   Grest D, 2007, LECT NOTES COMPUT SC, V4814, P28
   Herbst E, 2013, IEEE INT CONF ROBOT, P2276, DOI 10.1109/ICRA.2013.6630885
   Ijjina EP, 2016, PATTERN RECOGN, V59, P199, DOI 10.1016/j.patcog.2016.01.012
   Kakadiaris I, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P325, DOI 10.1007/0-387-28831-7_20
   Kishore P, 2018, IEEE SENSORS J, P1
   Koller O., 2016, P BRIT MACHINE VISIO
   Li FF, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING AND COMMUNICATIONS (BIGCOM), P313, DOI 10.1109/BIGCOM.2017.52
   Li M, 2017, PATTERN RECOGN LETT, V87, P195, DOI 10.1016/j.patrec.2016.07.021
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Ma M, 2018, PATTERN RECOGN, V76, P506, DOI 10.1016/j.patcog.2017.11.026
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Qiu ZY, 2015, APPL PHYS EXPRESS, V8, DOI 10.7567/APEX.8.083001
   Rahmani H, 2014, LECT NOTES COMPUT SC, V8690, P742, DOI 10.1007/978-3-319-10605-2_48
   Simonyan K., 2014, 14091556 ARXIV
   Singh B, 2016, PROC CVPR IEEE, P1961, DOI 10.1109/CVPR.2016.216
   Tseng CC, 2012, PATTERN RECOGN, V45, P3611, DOI 10.1016/j.patcog.2012.04.002
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Wang J, 2012, 2012 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Wang LL, 2017, PATTERN RECOGN LETT, V92, P33, DOI 10.1016/j.patrec.2017.04.004
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Xia L, 2012, PROCEEDINGS OF THE ASME/JSME/KSME JOINT FLUIDS ENGINEERING CONFERENCE 2011, VOL 1, PTS A-D, P1
   Xiao T, 2015, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2015.7298885
   Zhang J, 2016, PATTERN RECOGN, V60, P86, DOI 10.1016/j.patcog.2016.05.019
NR 49
TC 9
Z9 9
U1 4
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11723
EP 11746
DI 10.1007/s11042-019-08588-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400021
DA 2024-07-18
ER

PT J
AU Angeli, A
   Marfia, G
   Riedel, N
AF Angeli, Alessia
   Marfia, Gustavo
   Riedel, Norman
TI Using off-the-shelf data-human interface platforms: traps and tricks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data-human-interface; Machine learning; Deep learning
ID ACTIVITY RECOGNITION; BIG DATA; SCIENCE; ORANGE
AB With the development of learning algorithms, the constantly increasing computing power and the available amount of multimedia data, the adoption rate of data science techniques is steadily growing. Machine and deep learning algorithms are already used in a wide variety of ways to solve domain-specific problems. However, the potential of such methodologies will be fulfilled when also non specialized data scientists will be empowered with their use. Focusing on such perspective, this work does not deal with a classical data science problem, but instead exploits existing and available easy to use data-human interfaces. To this aim, we picked an exemplar scenario, amounting to an existing qualitative activity recognition data set that was in the past analyzed utilizing feature selection techniques and custom machine learning paradigms. We here verify how it is today possible, without changing the default settings and/or performing any type of feature selection, to employ the machine and deep learning algorithms provided by different publicly accessible tools (namely, Weka, Orange, Ludwig and KNIME) to address the same problem. Nevertheless, not all of the utilized platforms and algorithms provided satisfactorily results: we here finally discuss the possible issues and opportunities posed by such approach.
C1 [Angeli, Alessia] Univ Bologna, Dept Comp Sci & Engn, Bologna, Italy.
   [Marfia, Gustavo; Riedel, Norman] Univ Bologna, Dept Life Qual Studies, Bologna, Italy.
   Univ Bielefeld, Bielefeld, Germany.
C3 University of Bologna; University of Bologna; University of Bielefeld
EM alessia.angeli2@unibo.it; gustavo.marfia@unibo.it;
   norman.riedel@uni-bielefeld.de
RI Marfia, Gustavo/D-1347-2010
OI MARFIA, GUSTAVO/0000-0003-3058-8004; Angeli,
   Alessia/0000-0002-3572-2076; Riedel, Norman/0000-0002-0025-3791
FU University of Bologna; Golinelli Foundation
FX The authors gratefully thank the University of Bologna for the Alma
   Attrezzature 2017 grant and the Golinelli Foundation for the Data
   Science scholarship.
CR Abadi Martin, 2016, TENSORFLOW LARGE SCA, V16, P265
   ANGELI A, 2019, DATA SCI MODELS
   [Anonymous], 2016, P 30 AAAI C ART INT
   Athey S., 2018, The Impact of Machine Learning on Economics (No. c14009), P507
   Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1
   Bayat A, 2014, PROCEDIA COMPUT SCI, V34, P450, DOI 10.1016/j.procs.2014.07.009
   Bnaben F., 2014, Enterprise Interoperability VI, P13, DOI [DOI 10.1007/978-3-319-04948-9, 10.1007/978-3-319-04948-9_2, DOI 10.1007/978-3-319-04948-9_2]
   Bohanec M, 2017, EXPERT SYST APPL, V71, P416, DOI 10.1016/j.eswa.2016.11.010
   Bujari A, 2012, CONSUM COMM NETWORK, P502, DOI 10.1109/CCNC.2012.6181029
   Bujari A, 2011, IFIP WIREL DAY
   Buscher G, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P42
   Chen D, 2016, S VIS LANG HUM CEN C, P87, DOI 10.1109/VLHCC.2016.7739669
   Chen M, 2017, IEEE ACCESS, V5, P8869, DOI 10.1109/ACCESS.2017.2694446
   Chen YQ, 2015, IEEE SYS MAN CYBERN, P1488, DOI 10.1109/SMC.2015.263
   Chollet F., KERAS
   Cook D, 2013, KNOWL INF SYST, V36, P537, DOI 10.1007/s10115-013-0665-3
   Crisci C, 2012, ECOL MODEL, V240, P113, DOI 10.1016/j.ecolmodel.2012.03.001
   Demsar J, 2004, LECT NOTES ARTIF INT, V3202, P537
   Demsar J, 2013, J MACH LEARN RES, V14, P2349
   Fatima M., 2017, Journal of Intelligent Learning Systems and Applications, V09, P1, DOI DOI 10.4236/JILSA.2017.91001
   Faust O, 2018, COMPUT METH PROG BIO, V161, P1, DOI 10.1016/j.cmpb.2018.04.005
   Fillbrunn A, 2017, J BIOTECHNOL, V261, P149, DOI 10.1016/j.jbiotec.2017.07.028
   GARCIA M, 2018, INT S DISTR COMP ART, P330
   Guyon I., 2016, Workshop on Automatic Machine Learning. p, P21
   Hall M., 2009, SIGKDD EXPLORATIONS, V11, P10, DOI [10.1145/1656274.1656278, DOI 10.1145/1656274.1656278]
   Hammerla NY, 2015, AAAI CONF ARTIF INTE, P1742
   Heaton JB, 2017, APPL STOCH MODEL BUS, V33, P3, DOI 10.1002/asmb.2209
   Holmes G., 1994, Proceedings of the 1994 Second Australian and New Zealand Conference on Intelligent Information Systems (Cat. No.94TH8019), P357, DOI 10.1109/ANZIIS.1994.396988
   Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415
   Ketkar N., 2017, Deep learning with python: a hands-on introduction, P97, DOI [DOI 10.1007/978-1-4842-2766-47, 10.1007/978-1-4842-2766-4_7, DOI 10.1007/978-1-4842-2766-4_7, 10.1007/978-1-4842-2766-47]
   Ketkar N., 2017, Deep Learning with Python, P1
   Khan A, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P1155, DOI 10.1145/2750858.2807534
   Kranz M, 2013, PERVASIVE MOB COMPUT, V9, P203, DOI 10.1016/j.pmcj.2012.06.002
   Kroes M, 2002, DEV MED CHILD NEUROL, V44, P753
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Ladha C, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P235, DOI 10.1145/2493432.2493492
   Lane ND, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P283, DOI 10.1145/2750858.2804262
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Logan B, 2007, LECT NOTES COMPUT SC, V4717, P483
   MALIK F, 2019, NEURAL NETWORKS SOLI
   Marfia G, 2017, MULTIMED TOOLS APPL, V76, P8109, DOI 10.1007/s11042-016-3469-0
   MAURTUA I, 2007, 4 INT FOR APPL WEAR, P1
   MOLINO P, 2019, LUDWIG DEEP LEARNING
   Naik A, 2016, PROCEDIA COMPUT SCI, V85, P662, DOI 10.1016/j.procs.2016.05.251
   Pärkkä J, 2006, IEEE T INF TECHNOL B, V10, P119, DOI 10.1109/TITB.2005.856863
   Patel Kayur, 2010, CHI'10 Extended Abstracts on Human Factors in Computing Systems Georgia-USA Conference Proceedings, (April 10-15), P355
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Plotz N. Y., 2011, P INT C ART INT IJCA, V2, P1729
   Pourbabaee B, 2018, IEEE T SYST MAN CY-S, V48, P2095, DOI 10.1109/TSMC.2017.2705582
   Ravi N., 2005, Aaai, P1541
   Riedel N, 2019, PROCEEDINGS OF THE 5TH EAI INTERNATIONAL CONFERENCE ON SMART OBJECTS AND TECHNOLOGIES FOR SOCIAL GOOD (GOODTECHS 2019), P7, DOI 10.1145/3342428.3342671
   Ronao CA, 2016, EXPERT SYST APPL, V59, P235, DOI 10.1016/j.eswa.2016.04.032
   Rossum G., 1995, Python reference manual
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sian Lun Lau, 2010, 2010 Proceedings of the 7th International Symposium on Wireless Communication Systems (ISWCS 2010), P810, DOI 10.1109/ISWCS.2010.5624490
   Stiefmeier T, 2008, IEEE PERVAS COMPUT, V7, P42, DOI 10.1109/MPRV.2008.40
   Sung Michael, 2005, J Neuroeng Rehabil, V2, P17, DOI 10.1186/1743-0003-2-17
   Tarca AL, 2007, PLOS COMPUT BIOL, V3, P953, DOI 10.1371/journal.pcbi.0030116
   Tessem B, 2011, LECT NOTES BUS INF P, V77, P253
   UGULINO W, 2019, HUMAN ACTIVITY RECOG
   Velloso Eduardo, 2013, P 4 AUGM HUM INT C, P116, DOI DOI 10.1145/2459236.2459256
   Waller MA, 2013, J BUS LOGIST, V34, P77, DOI 10.1111/jbl.12010
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Yang Q, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P573, DOI 10.1145/3196709.3196729
   Zorrilla M, 2013, DECIS SUPPORT SYST, V55, P399, DOI 10.1016/j.dss.2012.05.045
   2006, KNIME OPEN INNOVATIO
   2006, PYTH PROGR LANG
NR 67
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 12907
EP 12929
DI 10.1007/s11042-020-08929-z
EA APR 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000529585600003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Thanh, DNH
   Hai, NH
   Prasath, VBS
   Hieu, LM
   Tavares, JMRS
AF Thanh, Dang N. H.
   Nguyen Hoang Hai
   Prasath, V. B. Surya
   Le Minh Hieu
   Tavares, Joao Manuel R. S.
TI A two-stage filter for high density salt and pepper denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Salt and pepper noise; Image restoration; Image
   processing; Image quality assessment
ID MEDIAN FILTER; NOISE; REMOVAL
AB Image restoration is an important and interesting problem in the field of image processing because it improves the quality of input images, which facilitates postprocessing tasks. The salt-and-pepper noise has a simpler structure than other noises, such as Gaussian and Poisson noises, but is a very common type of noise caused by many electronic devices. In this article, we propose a two-stage filter to remove high-density salt-and-pepper noise on images. The range of application of the proposed denoising method goes from low-density to high-density corrupted images. In the experiments, we assessed the image quality after denoising using the peak signal-to-noise ratio and structural similarity metric. We also compared our method against other similar state-of-the-art denoising methods to prove its effectiveness for salt and pepper noise removal. From the findings, one can conclude that the proposed method can successfully remove super-high-density noise with noise level above 90%.
C1 [Thanh, Dang N. H.] Univ Econ Ho Chi Minh City, Sch Business Informat Technol, Dept Informat Technol, Ho Chi Minh City, Vietnam.
   [Nguyen Hoang Hai] Univ Danang, Vietnam Korea Univ Informat & Commun Technol, Danang, Vietnam.
   [Prasath, V. B. Surya] Cincinnati Childrens Hosp Med Ctr, Div Biomed Informat, Cincinnati, OH 45229 USA.
   [Prasath, V. B. Surya] Univ Cincinnati, Dept Pediat, Cincinnati, OH USA.
   [Prasath, V. B. Surya] Univ Cincinnati, Coll Med, Dept Biomed Informat, Cincinnati, OH USA.
   [Prasath, V. B. Surya] Univ Cincinnati, Dept Elect Engn & Comp Sci, Cincinnati, OH USA.
   [Le Minh Hieu] Univ Danang, Univ Econ, Dept Econ, Danang, Vietnam.
   [Tavares, Joao Manuel R. S.] Univ Porto, Dept Engn Mecan, Fac Engn, Inst Ciencia & Inovacao Engn Mecan & Engn Ind, Porto, Portugal.
C3 Ho Chi Minh City University Economics; University of Danang; Cincinnati
   Children's Hospital Medical Center; University System of Ohio;
   University of Cincinnati; University System of Ohio; University of
   Cincinnati; University System of Ohio; University of Cincinnati;
   University of Danang; Universidade do Porto
RP Thanh, DNH (corresponding author), Univ Econ Ho Chi Minh City, Sch Business Informat Technol, Dept Informat Technol, Ho Chi Minh City, Vietnam.
EM thanhdnh@ueh.edu.vn; nhhai@vku.udn.vn; prasatsa@uc.edu;
   hieulm@due.edu.vn; tavares@fe.up.pt
RI Tavares, João Manuel R.S./M-5305-2013; Thanh, Dang Ngoc
   Hoang/J-4415-2015; Prasath, Surya/A-5243-2010
OI Tavares, João Manuel R.S./0000-0001-7603-6526; Thanh, Dang Ngoc
   Hoang/0000-0003-2025-8319; Prasath, Surya/0000-0001-7163-7453; , Le Minh
   Hieu/0000-0001-5252-199X; Tavares, Joao/0000-0003-3027-7978
FU University of Economics Ho Chi Minh City, Vietnam
FX This research is funded by University of Economics Ho Chi Minh City,
   Vietnam.
CR Ahmed F, 2014, IEEE T FUZZY SYST, V22, P1352, DOI 10.1109/TFUZZ.2013.2286634
   Aiswarya K, 2010, P IEEE 2 INT C COMP
   Bai T, 2015, IET IMAGE PROCESS, V9, P162, DOI 10.1049/iet-ipr.2014.0286
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Chan TF, 2005, SIAM J APPL MATH, V65, P1817, DOI 10.1137/040604297
   Chen JN, 2019, IET IMAGE PROCESS, V13, P2604, DOI 10.1049/iet-ipr.2019.0096
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Thanh DNH, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2019.163677
   Enginoglu S, 2019, MULTIMED TOOLS APPL, V78, P35401, DOI 10.1007/s11042-019-08110-1
   Erkan U, 2019, P IEEE 2019 INT ART
   Erkan U, 2020, IEEE ACCESS, V7
   Erkan U, 2020, IET IMAGE PROCESS, V14, P1291, DOI 10.1049/iet-ipr.2019.0398
   Erkan U, 2018, COMPUT ELECTR ENG, V70, P789, DOI 10.1016/j.compeleceng.2018.01.019
   Erkan U, 2018, TURK J ELECTR ENG CO, V26, P162, DOI 10.3906/elk-1705-256
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Gour N, 2020, MULTIMED TOOLS APPL, V79, P15679, DOI 10.1007/s11042-019-07999-y
   Hai NH, 2019, P IEEE 2019 11 INT C
   Hue NM, 2019, P IEEE 2019 6 NAFOST
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Karthik B, 2021, J AMB INTEL HUM COMP, V12, P3901, DOI 10.1007/s12652-020-01737-1
   Kishorebabu V, 2020, COMPUT COMMUN, V154, P433, DOI 10.1016/j.comcom.2020.02.048
   Knaus C, 2014, IEEE T IMAGE PROCESS, V23, P3114, DOI 10.1109/TIP.2014.2326771
   Lin CH, 2010, IEEE T IMAGE PROCESS, V19, P2307, DOI 10.1109/TIP.2010.2047906
   Lin JH, 1999, IEEE T IMAGE PROCESS, V8, P925, DOI 10.1109/83.772235
   Maggioni M, 2014, IEEE T IMAGE PROCESS, V23, P4282, DOI 10.1109/TIP.2014.2345261
   Nguyen MH, 2020, ICMLSC 2020: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND SOFT COMPUTING, P98, DOI 10.1145/3380688.3380704
   Petrovic NI, 2008, IEEE T IMAGE PROCESS, V17, P1109, DOI 10.1109/TIP.2008.924388
   Prasath VBS, 2019, IEEE T IMAGE PROCESS, V28, P6198, DOI 10.1109/TIP.2019.2924799
   Prasath VBS, 2015, IEEE T IMAGE PROCESS, V24, P5220, DOI 10.1109/TIP.2015.2479471
   Rojas R, 2011, EUR SIGNAL PR CONF, P278
   Sheela CJJ, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101657
   Shukla AK, 2020, MULTIMED TOOLS APPL, V79, P14201, DOI 10.1007/s11042-020-08641-y
   Singh V, 2018, IEEE T FUZZY SYST, V26, P3170, DOI 10.1109/TFUZZ.2018.2805289
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Thanh D, 2015, P 6 INT S INF COMM T, P223, DOI [10.1145/2833258.2833281, DOI 10.1145/2833258.2833281]
   Thanh D. N. H., 2016, Pattern Recognition and Image Analysis, V26, P285, DOI 10.1134/S1054661816020231
   Thanh DNH, 2020, SIGNAL IMAGE VIDEO P, V14, P1189, DOI 10.1007/s11760-020-01657-9
   Thanh DNH, 2018, P IEEE 5 NAFOSTED C
   Thanh DNH, 2019, P 2019 IEEE RIVF INT
   Toh KKV, 2010, IEEE SIGNAL PROC LET, V17, P281, DOI 10.1109/LSP.2009.2038769
   Varghese J, 2015, ARAB J SCI ENG, V40, P3233, DOI 10.1007/s13369-015-1799-2
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yahya AA, 2020, MULTIMED TOOLS APPL, V79, P20391, DOI 10.1007/s11042-020-08815-8
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
NR 45
TC 23
Z9 23
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21013
EP 21035
DI 10.1007/s11042-020-08887-6
EA APR 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000529585600001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Sellam, A
   Azzoune, H
AF Sellam, Abdellah
   Azzoune, Hamid
TI Neighborhood min distance descriptor for kinship verification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kinship verification; Feature engineering; Classification
ID FACE; RECOGNITION
AB The verification of parental and family relationships based on the facial appearance of subjects is a recent topic that attracted the attention of the computer vision research community. So many feature descriptors for facial images have been proposed, yet they are still unable to describe the similarity level of pairs of facial images in kinship datasets, because most of these images suffer from the illumination and expression variations. In this paper we propose a simple and effective descriptor for pairs of images, this descriptor is designed to be more robust to variations in expression, the idea of the descriptor is to compare each pixel in the first image of the pair with the neighboring pixels in the second image in terms of the euclidean distance on the RGB color space, the minimal distance in this neighborhood is then added to the feature vector of the pair. Experiments on the size of the neighborhood with various classifiers were conducted using the KinFaceW and Cornell-KinFace datasets, results demonstrated that this descriptor outperforms state-of-the-art approaches in five out of eight subsets of the KinFaceW and on the Cornell-KinFace dataset.
C1 [Sellam, Abdellah; Azzoune, Hamid] USTHB, Comp Sci Dept, Lab Res Artificial Intelligence, BP 32 El Alia, Algiers 16111, Algeria.
C3 University Science & Technology Houari Boumediene
RP Sellam, A (corresponding author), USTHB, Comp Sci Dept, Lab Res Artificial Intelligence, BP 32 El Alia, Algiers 16111, Algeria.
EM asellam@usthb.dz; hazzoune@usthb.dz
OI Abdellah, Sellam/0000-0002-1930-6283
CR Alirezazadeh P, 2015, IEEE SIGNAL PROC LET, V22, P2459, DOI 10.1109/LSP.2015.2490805
   Alvergne A, 2009, J VISION, V9, DOI 10.1167/9.6.23
   Cao ZM, 2010, PROC CVPR IEEE, P2707, DOI 10.1109/CVPR.2010.5539992
   Chen XJ, 2017, MULTIMED TOOLS APPL, V76, P4105, DOI 10.1007/s11042-015-2930-9
   DeBruine LM, 2009, VISION RES, V49, P38, DOI 10.1016/j.visres.2008.09.025
   Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590
   Fang YM, 2016, IEEE INT CONF MULTI
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Getoor, 2011, P 28 INT C MACH LEAR, P833
   Haibin Yan, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457930
   Hu Junlin., 2014, COMPUTER VISION ACCV, P252
   Kaminski G, 2009, P ROY SOC B-BIOL SCI, V276, P3193, DOI 10.1098/rspb.2009.0677
   Khan FS, 2013, INT J COMPUT VISION, V105, P205, DOI 10.1007/s11263-013-0633-0
   Kohli N, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2609811
   Lan RS, 2017, IEEE T CIRC SYST VID, V27, P261, DOI 10.1109/TCSVT.2015.2492839
   Lan RS, 2016, IEEE T IMAGE PROCESS, V25, P5281, DOI 10.1109/TIP.2016.2605922
   Li XS, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS - COMPUTING TECHNOLOGY, INTELLIGENT TECHNOLOGY, INDUSTRIAL INFORMATION INTEGRATION (ICIICII), P1, DOI 10.1109/ICIICII.2015.88
   Ling HB, 2010, IEEE T INF FOREN SEC, V5, P82, DOI 10.1109/TIFS.2009.2038751
   Liu HJ, 2017, IEEE INT CON MULTI, P319, DOI 10.1109/ICME.2017.8019375
   Liu N, 2016, 2016 URSI ASIA-PACIFIC RADIO SCIENCE CONFERENCE (URSI AP-RASC), P1, DOI 10.1109/URSIAP-RASC.2016.7601259
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   Lu JW, 2012, PROC CVPR IEEE, P2594, DOI 10.1109/CVPR.2012.6247978
   Mahpod S, 2018, COMPUT VIS IMAGE UND, V167, P28, DOI 10.1016/j.cviu.2017.12.003
   Puthenputhussery A, 2016, IEEE IMAGE PROC, P2921, DOI 10.1109/ICIP.2016.7532894
   Qin XQ, 2016, NEUROCOMPUTING, V214, P350, DOI 10.1016/j.neucom.2016.06.027
   Ren X, 2016, ADVANCES OF TRANSPORTATION: INFRASTRUCTURE AND MATERIALS, VOL 1, P535
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Wang W, 2015, IEEE PHOTONICS J, V7, DOI 10.1109/JPHOT.2015.2477607
   Xu M, 2016, IEEE ACCESS, V4, P10280, DOI 10.1109/ACCESS.2016.2635147
   Yan HB, 2017, IMAGE VISION COMPUT, V60, P91, DOI 10.1016/j.imavis.2016.08.009
   Yan HB, 2014, IEEE T INF FOREN SEC, V9, P1169, DOI 10.1109/TIFS.2014.2327757
   Yang Y., 2017, DESTECH T COMPUT SCI
   Zhang K., 2015, Proc. BMVC, DOI [DOI 10.5244/C.29.148, 10.5244/C.29.148]
   Zhao YG, 2018, INFORM SCIENCES, V430, P247, DOI 10.1016/j.ins.2017.11.048
   Zhou X., 2011, ACM Multimedia, P953
   Zhou XZ, 2019, INFORM FUSION, V48, P84, DOI 10.1016/j.inffus.2018.07.011
   Zhou XZ, 2016, INFORM FUSION, V32, P40, DOI 10.1016/j.inffus.2015.08.006
   Zhou XZ, 2016, NEUROCOMPUTING, V197, P136, DOI 10.1016/j.neucom.2016.02.039
   Zhou Xiuzhuang, 2012, P 20 ACM INT C MULT, P725, DOI [DOI 10.1145/2393347, DOI 10.1145/2393347.2396297]
NR 41
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20861
EP 20880
DI 10.1007/s11042-020-08906-6
EA APR 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000528990000004
DA 2024-07-18
ER

PT J
AU Alonso, DG
   Teyseyre, A
   Soria, A
   Berdun, L
AF Alonso, Diego G.
   Teyseyre, Alfredo
   Soria, Alvaro
   Berdun, Luis
TI Hand gesture recognition in real world scenarios using approximate
   string matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural user interfaces; Hand gesture recognition; Machine learning;
   Approximate string matching
AB New interaction paradigms combined with emerging technologies have produced the creation of diverse Natural User Interface (NUI) devices in the market. These devices enable the recognition of body gestures allowing users to interact with applications in a more direct, expressive, and intuitive way. In particular, the Leap Motion Controller (LMC) device has been receiving plenty of attention from NUI application developers because it allows them to address limitations on gestures made with hands. Although this device is able to recognize the position of several parts of the hands, developers are still left with the difficult task of recognizing gestures. For this reason, several authors approached this problem using machine learning techniques. We propose a classifier based on Approximate String Matching (ASM). In short, we encode the trajectories of the hand joints as character sequences using the K-means algorithm and then we analyze these sequences with ASM. It should be noted that, when using the K-means algorithm, we select the number of clusters for each part of the hands by considering the Silhouette Coefficient. Furthermore, we define other important factors to take into account for improving the recognition accuracy. For the experiments, we generated a balanced dataset including different types of gestures and afterwards we performed a cross-validation scheme. Experimental results showed the robustness of the approach in terms of recognizing different types of gestures, time spent, and allocated memory. Besides, our approach achieved higher performance rates than well-known algorithms proposed in the current state-of-art for gesture recognition.
C1 [Alonso, Diego G.; Teyseyre, Alfredo; Soria, Alvaro; Berdun, Luis] CONICET UNCPBA, ISISTAN Res Inst, Campus Univ, Buenos Aires, DF, Argentina.
RP Alonso, DG (corresponding author), CONICET UNCPBA, ISISTAN Res Inst, Campus Univ, Buenos Aires, DF, Argentina.
EM diego.alonso@isistan.unicen.edu.ar
RI ALONSO, DIEGO G./K-2804-2013
OI Teyseyre, Alfredo/0000-0003-3289-5489
FU NVIDIA Corporation
FX We gratefully acknowledge the support of NVIDIA Corporation with the
   donation of the Titan Xp GPU used for this research.
CR [Anonymous], 2013, LEAP MOTION CONTROLL
   [Anonymous], IJCAI 2001 WORKSHOP
   [Anonymous], 2015, IMAGE TAKEN LEAP MOT
   [Anonymous], 2013, International Journal of Computer Applications (0975-8887)
   [Anonymous], 2009, INT J GEOMATH, DOI DOI 10.1007/S13137-020-00149-9
   Bachmann D, 2015, SENSORS-BASEL, V15, P214, DOI 10.3390/s150100214
   Chen YM, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P1419, DOI 10.1109/ICInfA.2015.7279509
   Chuan CH, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P541, DOI 10.1109/ICMLA.2014.110
   Eddy SR, 1996, CURR OPIN STRUC BIOL, V6, P361, DOI 10.1016/S0959-440X(96)80056-X
   Fok KY, 2015, 2015 INTERNATIONAL CONFERENCE ON CYBER-ENABLED DISTRIBUTED COMPUTING AND KNOWLEDGE DISCOVERY, P411, DOI 10.1109/CyberC.2015.81
   Guna J, 2014, SENSORS-BASEL, V14, P3702, DOI 10.3390/s140203702
   HALL PAV, 1980, COMPUT SURV, V12, P381, DOI 10.1145/356827.356830
   Han Jihyun., 2014, LESSONS LEARNED EXPL
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Ibañez R, 2017, PATTERN RECOGN, V62, P73, DOI 10.1016/j.patcog.2016.08.022
   Ibañez R, 2014, ADV ENG SOFTW, V76, P171, DOI 10.1016/j.advengsoft.2014.07.005
   Jacob MG, 2013, J AM MED INFORM ASSN, V20, pE183, DOI 10.1136/amiajnl-2012-001212
   Khelil B, 2016, 3 INT C ACECS 16
   Kumar P, 2017, PATTERN RECOGN LETT, V86, P1, DOI 10.1016/j.patrec.2016.12.004
   Lee B, 2018, J SENSORS, V2018, DOI 10.1155/2018/6073786
   Leitao P.M.O., 2015, P 10 DOCT S INF ENG
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   López G, 2015, LECT NOTES COMPUT SC, V9455, P231, DOI 10.1007/978-3-319-26410-3_22
   Lu W, 2016, IEEE SIGNAL PROC LET, V23, P1188, DOI 10.1109/LSP.2016.2590470
   Marin G, 2014, IEEE IMAGE PROC, P1565, DOI 10.1109/ICIP.2014.7025313
   Marin G, 2016, MULTIMED TOOLS APPL, V75, P14991, DOI 10.1007/s11042-015-2451-6
   McCartney Robert., 2015, Proceedings of the International Conference on Image Processing, Computer Vision, and Pattern Recognition (IPCV), P3
   Mohandes M, 2014, PROC IEEE INT SYMP, P960, DOI 10.1109/ISIE.2014.6864742
   Navarro G., 2002, FLEXIBLE PATTERN MAT
   Regenbrecht H., 2013, 25th Australian Computer-Human Interaction Conference: Augmentation, Application, Innovation, Collaboration, P281, DOI DOI 10.1145/2541016.2541053
   SILVA E.S., 2013, A preliminary evaluation of the leap motion sensor as controller of new digital musical instruments
   Smeragliuolo AH, 2016, J BIOMECH, V49, P1742, DOI 10.1016/j.jbiomech.2016.04.006
   Tao WJ, 2018, ENG APPL ARTIF INTEL, V76, P202, DOI 10.1016/j.engappai.2018.09.006
   Wang QQ, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P654, DOI 10.1109/ROBIO.2014.7090405
NR 34
TC 8
Z9 8
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20773
EP 20794
DI 10.1007/s11042-020-08913-7
EA APR 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000528439200001
DA 2024-07-18
ER

PT J
AU Kumar, A
   Walia, GS
   Sharma, K
AF Kumar, Ashish
   Walia, Gurjit Singh
   Sharma, Kapil
TI Real-time visual tracking via multi-cue based adaptive particle filter
   framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Particle filter; Visual tracking; Fusion model; Cue reliability;
   Resampling
ID OBJECT TRACKING
AB Visual tracking using particle filter has been extensively investigated due to its myriad of application in the field of computer vision. However, particle filter framework performance is heavily impaired due to its inherent problems namely, particle degeneracy and impoverishment. In addition, most of the tracking methods using single cue are greatly affected by dynamic environmental challenges. To address these issues, we propose an adaptive multi-cue particle filter based real-time visual tracking framework. Three complementary cues namely, color histogram, LBP and pyramid of histogram of gradient have been exploited for object's appearance model. These cues are integrated using the proposed adaptive fusion model for the automatic boosting of important particles and suppression of unimportant particles. Resampling method using butterfly search optimization relocate low performing particles to high likelihood area. Proposed outlier detection mechanism not only helps in detecting low performing particles but also aids in updating of the reference dictionary. Online estimation of cue reliability along with its multi-cue fusion leads to quick adaptation of the proposed tracker. On average of the outcome, our tracker achieves average center location error of 6.89 (in pixels) and average F-measure of 0.786 when evaluated on OTB-100 and VOT dataset against 13 others state-of-the-art.
C1 [Kumar, Ashish] Delhi Technol Univ, Delhi, India.
   [Sharma, Kapil] Delhi Technol Univ, Dept Informat Technol, Delhi, India.
   [Walia, Gurjit Singh] Def Res & Dev Org, SAG, New Delhi, India.
C3 Delhi Technological University; Delhi Technological University; Defence
   Research & Development Organisation (DRDO); Scientific Analysis Group
   (SAG)
RP Sharma, K (corresponding author), Delhi Technol Univ, Dept Informat Technol, Delhi, India.
EM ashish.gupta14d@gmail.com; gurjit.walia@gmail.com; kapil@ieee.org
RI KUMAR, ASHISH/AAE-3083-2022
OI Kumar, Ashish/0000-0003-3466-8845; Sharma, Kapil/0000-0002-4412-7690
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   Arora S, 2019, SOFT COMPUT, V23, P715, DOI 10.1007/s00500-018-3102-4
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bhattacharyya Anil, 1943, B CALCUTTA MATH SOC, V35, P99
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Brasnett P, 2007, IMAGE VISION COMPUT, V25, P1217, DOI 10.1016/j.imavis.2006.07.017
   Choe G, 2015, IET COMPUT VIS, V9, P184, DOI 10.1049/iet-cvi.2014.0106
   Dou JF, 2014, OPTIK, V125, P1680, DOI 10.1016/j.ijleo.2013.10.007
   Dou JF, 2014, NEUROCOMPUTING, V135, P118, DOI 10.1016/j.neucom.2013.12.049
   Fan ZH, 2015, SIGNAL PROCESS-IMAGE, V36, P140, DOI 10.1016/j.image.2015.07.001
   Firouznia M, 2018, J VIS COMMUN IMAGE R, V53, P1, DOI 10.1016/j.jvcir.2018.02.014
   Gao ML, 2015, OPTIK, V126, P1705, DOI 10.1016/j.ijleo.2015.05.028
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015
   Han H, 2011, COMPUT MATH APPL, V62, P2685, DOI 10.1016/j.camwa.2011.06.050
   Huan RH, 2018, IET IMAGE PROCESS, V12, P1519, DOI 10.1049/iet-ipr.2017.1068
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kristan M, 2016, IEEE T PATTERN ANAL, V38, P2137, DOI 10.1109/TPAMI.2016.2516982
   Lazarevic-McManus N, 2008, COMPUT VIS IMAGE UND, V111, P74, DOI 10.1016/j.cviu.2007.07.007
   Li TC, 2015, IEEE SIGNAL PROC MAG, V32, P70, DOI 10.1109/MSP.2014.2330626
   Li WY, 2016, SIGNAL PROCESS-IMAGE, V43, P28, DOI 10.1016/j.image.2016.01.001
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Lin SFD, 2015, IET IMAGE PROCESS, V9, P959, DOI 10.1049/iet-ipr.2014.0666
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Qian XY, 2018, SIGNAL PROCESS-IMAGE, V60, P183, DOI 10.1016/j.image.2017.09.001
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Sardari F, 2017, APPL SOFT COMPUT, V50, P280, DOI 10.1016/j.asoc.2016.11.028
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   WALIA GS, 2019, PATTERN ANAL APPL, P1
   Walia GS, 2020, IEEE T CYBERNETICS, V50, P2357, DOI 10.1109/TCYB.2019.2920289
   Walia GS, 2016, MULTIMED TOOLS APPL, V75, P15821, DOI 10.1007/s11042-015-2890-0
   Walia GS, 2016, ARTIF INTELL REV, V46, P1, DOI 10.1007/s10462-015-9454-6
   Walia GS, 2014, EXPERT SYST APPL, V41, P6315, DOI 10.1016/j.eswa.2014.03.012
   Wang FS, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P417
   Wen ZQ, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.271
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiao JJ, 2016, IEEE SENS J, V16, P2639, DOI 10.1109/JSEN.2016.2514704
   Yin MH, 2011, EXPERT SYST APPL, V38, P6313, DOI 10.1016/j.eswa.2010.11.111
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zhang MH, 2013, NEUROCOMPUTING, V122, P163, DOI 10.1016/j.neucom.2013.05.041
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhang T, 2017, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2017.469
NR 44
TC 9
Z9 9
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20639
EP 20663
DI 10.1007/s11042-020-08655-6
EA APR 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000528160800002
DA 2024-07-18
ER

PT J
AU Sharma, MK
   Sheet, D
   Biswas, PK
AF Sharma, M. K.
   Sheet, D.
   Biswas, P. K.
TI Spatiotemporal deep networks for detecting abnormality in videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance; Deep learning; Abnormality detection and
   localization; Adversarial attack and defense
ID ANOMALY DETECTION; OBJECT MOTION; SURVEILLANCE
AB Detecting and localizing anomalous behavior in the surveillance video is explored and spatiotemporal model, which jointly learns the appearance and motion-based feature is proposed. The general solution is to learn from the normal-data as reference models and uses various hands designed features. However, huge variations can occur within normal-behavior patterns. It is a challenge to represent higher-level concepts of a normal or abnormal event explicitly from raw input data. In the proposed framework, spatiotemporal features learned at various hidden layer are analyzed. Based on the learned representation, the reconstruction of video volumes are performed. Finally, the structural distortion based abnormality score is computed by considering luminance, contrast, and structural information to detect the presence of abnormality and localize them. Further, we also explored the performance of GMM and one-class SVM in a given scenario. The proposed structural distortion based abnormality detection and localization are evaluated on the publicly available UCSD and UMN dataset. The performance of the developed system is found to outperform the existing state-of-art methods for detecting and localizing abnormality at the frame as well as pixel-level. Recently, deep architecture is also found to be vulnerable to adversarial attacks and can easily be tricked to fool the system. However, most of the existing attacks are designed for the classification task. In this work, we utilize the gradient-based approach to generate adversarial samples for an abnormality detection system. Finally, we build the defense mechanism to detect the abnormality in the presence of such adversarial attacks.
C1 [Sharma, M. K.; Sheet, D.] IIT Kharagpur, Kharagpur, W Bengal, India.
   [Biswas, P. K.] IIT Kharagpur, Dept Elect & Elect Commun Engn, Kharagpur, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Kharagpur
RP Sharma, MK (corresponding author), IIT Kharagpur, Kharagpur, W Bengal, India.
EM manojsharma.net@gmail.com; debdoot@ee.iitkgp.ernet.in;
   pkb@ece.iitkgp.ernet.in
RI Biswas, Prabir Kumar/AAY-5904-2021; Biswas, Prabir Kumar/AAV-4935-2021
CR Aggarwal Charu C, 2017, OUTLIER ANAL, DOI [DOI 10.1007/978-1-4614-6396-2, 10.1007/978- 1-4614- 6396-2]
   Akhtar N, 2018, IEEE ACCESS, V6, P14410, DOI 10.1109/ACCESS.2018.2807385
   [Anonymous], 2016, INT C MACH LEARN
   [Anonymous], ARXIV161000307
   [Anonymous], 2015, Deep learning
   Basharat A, 2008, PROC CVPR IEEE, P1301
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Biswas S, 2015, MULTIMED TOOLS APPL, V74, P11099, DOI 10.1007/s11042-014-2219-4
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Chalapathy R., 2018, Anomaly detection using one-class neural networks
   Chalapathy Raghavendra, 2019, ARXIV190103407
   Chandola V, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1541880.1541882
   Choi MJ, 2012, PATTERN RECOGN LETT, V33, P853, DOI 10.1016/j.patrec.2011.12.004
   Chong Y. S., 2015, ARXIV150500523
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Deng L., 2012, APSIPA transactions on signal and information processing
   Fawzi Alhussein, 2018, Adv. Neural Inform. Process. Syst, DOI DOI 10.48550/ARXIV.1802.08686
   Fischer A, 2014, PATTERN RECOGN, V47, P25, DOI 10.1016/j.patcog.2013.05.025
   Goodfellow I.J., 2014, ARXIV 14126572
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hawkins S., 2002, International Conference on Data Warehousing and Knowledge Discovery, P170, DOI DOI 10.1007/3-540-46145-0_17
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G. E., 2012, Neural networks: tricks of the trade, P599
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   JAVANROSHTKHARI M, 2014, THESIS
   Kiran BR, 2018, J IMAGING, V4, DOI 10.3390/jimaging4020036
   Kos J, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P36, DOI 10.1109/SPW.2018.00014
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumaran S. Kelathodi, 2019, arXiv, arXiv-1901.
   Kurakin A., 2016, WORKSHOP TRACK P
   Leach MJV, 2014, PATTERN RECOGN LETT, V44, P71, DOI 10.1016/j.patrec.2013.11.018
   Li NN, 2015, NEUROCOMPUTING, V155, P309, DOI 10.1016/j.neucom.2014.12.064
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   MAHADEVAN V, 2010, PROC CVPR IEEE, P1975, DOI DOI 10.1109/CVPR.2010.5539872
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Mo D., 2012, A survey on deep learning: one small step toward AI
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   REDDY V, 2011, COMP VIS PATT REC WO, P55, DOI DOI 10.1109/CVPRW.2011.5981799
   Richardson Iain E, 2004, H. 264 and MPEG-4 Video Compression: Video Coding for Next-Generation Multimedia
   Roshtkhari MJ, 2013, PROC CVPR IEEE, P2611, DOI 10.1109/CVPR.2013.337
   Roshtkhari MJ, 2013, COMPUT VIS IMAGE UND, V117, P1436, DOI 10.1016/j.cviu.2013.06.007
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Ryan D., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P230, DOI 10.1109/AVSS.2011.6027327
   Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006
   Saleh B, 2013, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2013.107
   SHARMA MK, 2016, P INT C ADV INF COMM, P11
   SHARMA MK, 2018, P 3 INT C COMP VIS I, V2, P243
   Sodemann AA, 2012, IEEE T SYST MAN CY C, V42, P1257, DOI 10.1109/TSMCC.2012.2215319
   Tabacof Pedro, 2018, ARXIV180604646
   Tan HL, 2016, INT CONF ACOUST SPEE, P1976, DOI 10.1109/ICASSP.2016.7472022
   Wang C, 2017, MULTIMED TOOLS APPL, V76, P6263, DOI 10.1007/s11042-015-3199-8
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Westberg S., 2018, arXiv preprint arXiv:1803.01164, DOI DOI 10.48550/ARXIV.1803.01164
   Williams G, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P709, DOI 10.1109/ICDM.2002.1184035
   Xu D., 2015, arXiv preprint arXiv:1510.01553
   Yan W., 2019, P ANN C PROGN HLTH M, DOI DOI 10.48550/ARXIV.1908.09238
   Yong SP, 2012, PATTERN RECOGN, V45, P3439, DOI 10.1016/j.patcog.2012.02.036
   Yu XY, 2019, IEEE T NEUR NET LEAR, V30, P2805, DOI 10.1109/TNNLS.2018.2886017
   Zaharescu A, 2010, LECT NOTES COMPUT SC, V6311, P563, DOI 10.1007/978-3-642-15549-9_41
   Zhang TZ, 2009, PROC CVPR IEEE, P1940, DOI 10.1109/CVPRW.2009.5206809
NR 66
TC 6
Z9 6
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 11237
EP 11268
DI 10.1007/s11042-020-08786-w
EA APR 2020
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000523109000001
DA 2024-07-18
ER

PT J
AU Alagarsamy, SB
   Murugan, K
AF Alagarsamy, Santham Bharathy
   Murugan, Kalpana
TI Ear recognition system using adaptive approach Runge-Kutta (AARK)
   threshold segmentation with cart classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information normalization; Ring projection; AARK; DWT; CART classifier
AB In the recent years, researchers have drawn attention towards the human external ear due to being a new class of relative stable biometric. The significant of this paper is to employ an approach in biometric ear recognition. Previously, there have been a number of researchers carried out on ear recognition systems and various methods have achieved good performances. This paper has implemented a modern approach for segmentation of ear images that includes an adaptive approach Runge-Kutta (AARK) segmentation and CART (Classification and Regression Tree) classifier. AARK segmentation is typically used to locate objects and boundaries of ear images. It also increases the speed of segmentation, good shape matching and it results in good shape connectivity. CART classifier is used to produce better accuracy when performing ear classification. Also, this paper consists with preprocessing, ring projection, information normalization and feature extraction of DWT (1D-Discrete Wavelet Transform). The obtained results show that the significance of the proposed method carry out advanced ear recognition techniques, and increases the PSNR values, and consequently improve the accuracy rate.
C1 [Alagarsamy, Santham Bharathy; Murugan, Kalpana] Kalasalingam Acad Res & Educ, Dept Elect & Commun Engn, Virudunagar 626126, TN, India.
C3 Kalasalingam Academy of Research & Education
RP Murugan, K (corresponding author), Kalasalingam Acad Res & Educ, Dept Elect & Commun Engn, Virudunagar 626126, TN, India.
EM santhembharathy@gmail.com; kalpana.m@klu.ac.in
RI Murugan, Kalpana/AAH-4062-2020
OI Murugan, Kalpana/0000-0002-5121-0468; ALAGARSAMY, SANTHAM
   BHARATHY/0000-0003-0978-3905
CR Abate AF, 2006, INT C PATT RECOG, P437
   Abdel-Mottaleb M., 2005, Advances in Biometrics. International Conference, ICB 2006. Proceedings (Lecture Notes in Computer Science Vol.3832), P786
   [Anonymous], NEURAL COMPUTING APP
   [Anonymous], COMPUTER VISION UNDE
   [Anonymous], ORDINARY DIFFERENTIA
   [Anonymous], NEW LOCAL ADAPTIVE T
   [Anonymous], P INT C WAV AN PATT
   [Anonymous], IEEE T CIRCUITS SY 2
   Arunachalam M, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P16, DOI 10.1109/ICICCT.2017.7975188
   Burge M, 2000, INT C PATT RECOG, P822, DOI 10.1109/ICPR.2000.906202
   Choras M, 2008, OPTO-ELECTRON REV, V16, P85, DOI 10.2478/s11772-007-0033-5
   Dewi K, 2006, PROCEEDINGS OF THE SECOND IASTED INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, P361
   Dong JY, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL III, PROCEEDINGS, P771, DOI 10.1109/IITA.2008.325
   ELSEDDAWY AB, 2013, INT J MOD ENG RES, V3, P2139
   GUPTA P., 2007, P 6 INT C ADV PATT R
   Kisku DR, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTATIONAL TOOLS FOR ENGINEERING APPLICATIONS, P380, DOI 10.1109/ACTEA.2009.5227958
   LIU H., 2008, P 7 IEEE WORLD C INT
   MU Z., 2009, P 2 IEEE INT C COMP
   Nanni L, 2007, PATTERN RECOGN LETT, V28, P2219, DOI 10.1016/j.patrec.2007.07.004
   Nanni L, 2009, PATTERN RECOGN, V42, P1906, DOI 10.1016/j.patcog.2008.10.016
   NOSRATI M., 2007, P IEEE INT C INT ADV
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Shashi Kumar D. R., 2011, INT J COMPUTER TECHN, V2, P884
   Timofeev R., 2004, Classification and regression trees (CART) theory and applications
   Vural C, 2007, AIP CONF PROC, V2, P1404, DOI 10.1063/1.2836017
   Wang J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330512
   Xie Z., 2008, PROCEEDING 19 INT C, P1
   Yan Ping, 2005, C COMP VIS PATT REC
   ZHANG D., 2007, SPIE DEF SEC S, V6539
NR 29
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10445
EP 10459
DI 10.1007/s11042-019-7418-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600038
DA 2024-07-18
ER

PT J
AU Martins, GB
   Pereira, DR
   Almeida, JG
   de Albuquerque, VHC
   Papa, JP
AF Martins, Guilherme B.
   Pereira, Danillo R.
   Almeida, Jurandy G.
   de Albuquerque, Victor Hugo C.
   Papa, Joao Paulo
TI OPFSumm: on the video summarization using Optimum-Path Forest
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Optimum-path forest; OPFSumm; Multimedia tools
ID CLASSIFICATION; FRAMEWORK
AB Video summarization attempts at encoding a given video into a compact representation for a better storage and retrieval purposes. This work copes with the problem of static video summarization using the unsupervised Optimum-Path Forest (OPF). We sampled the encoded video sequence into frames and extracted features based on color information or spectral properties. After that, meaningless frames are removed, and OPF models the problem of video summarization as a clustering process. Possible redundant keyframes are filtered, and at last the video summary is created based on non-redundant keyframes. We presented a more in-depth study that also considers temporal information to obtain better video representations. The experiments over three public datasets were analyzed through F-measure evaluation metric and showed the robustness of OPF for automatic video summarization: 0.19 for SumMe dataset, 0.728 concerning Open Video dataset, and 0.451 regarding YouTube dataset..
C1 [Martins, Guilherme B.; Pereira, Danillo R.; Papa, Joao Paulo] Sao Paulo State Univ, Dept Comp, Bauru, SP, Brazil.
   [Almeida, Jurandy G.] Univ Fed Sao Paulo, Inst Sci & Technol, Sao Paulo, Brazil.
   [de Albuquerque, Victor Hugo C.] Univ Fortaleza, Grad Program Appl Informat, Fortaleza, CE, Brazil.
C3 Universidade Estadual Paulista; Universidade Federal de Sao Paulo
   (UNIFESP); Universidade Fortaleza
RP de Albuquerque, VHC (corresponding author), Univ Fortaleza, Grad Program Appl Informat, Fortaleza, CE, Brazil.
EM guilherme_brandao@outlook.com; cotonilo@gmail.com;
   jurandy.almeida@unifesp.br; victor.albuquerque@unifor.br;
   papa@fc.unesp.br
RI de Albuquerque, Victor Hugo C./C-3677-2016; Papa, Joao
   Paulo/ABC-6283-2020; Almeida, Jurandy/I-2177-2012
OI de Albuquerque, Victor Hugo C./0000-0003-3886-4309; Papa, Joao
   Paulo/0000-0002-6494-7514; Almeida, Jurandy/0000-0002-4998-6996
CR Almeida J, 2013, J VIS COMMUN IMAGE R, V24, P729, DOI 10.1016/j.jvcir.2012.01.009
   Almeida J, 2012, PATTERN RECOGN LETT, V33, P397, DOI 10.1016/j.patrec.2011.08.007
   Amorim WP, 2016, PATTERN RECOGN, V60, P72, DOI 10.1016/j.patcog.2016.04.020
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], 2015, CVPR
   [Anonymous], 5 INT C COMP VIS COM
   Castelo-Fernández C, 2015, LECT NOTES COMPUT SC, V9423, P760, DOI 10.1007/978-3-319-25751-8_91
   Choi YS, 2004, LECT NOTES COMPUT SC, V3043, P49
   DeMenthon D., 1998, Proceedings ACM Multimedia 98, P211, DOI 10.1145/290747.290773
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Gong BQ, 2014, ADV NEUR IN, V27
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jacob H, 2017, J INTELL INF SYST, V49, P193, DOI 10.1007/s10844-016-0441-4
   Jacobs C. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P277, DOI 10.1145/218380.218454
   Martins GB, 2014, LECT NOTES COMPUT SC, V8827, P893, DOI 10.1007/978-3-319-12568-8_108
   Martins GB, 2016, SIBGRAPI, P335, DOI [10.1109/SIBGRAPI.2016.50, 10.1109/SIBGRAPI.2016.053]
   Minetto R, 2012, COMPUT VIS IMAGE UND, V116, P274, DOI 10.1016/j.cviu.2011.10.003
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Panda R, 2014, INT C PATT RECOG, P3481, DOI 10.1109/ICPR.2014.599
   Papa JP, 2009, INT J IMAG SYST TECH, V19, P120, DOI 10.1002/ima.20188
   Papa JP, 2012, PATTERN RECOGN, V45, P512, DOI 10.1016/j.patcog.2011.07.013
   Papa JP, 2008, LECT NOTES COMPUT SC, V5358, P935, DOI 10.1007/978-3-540-89639-5_89
   Papa JP, 2017, PATTERN RECOGN LETT, V87, P117, DOI 10.1016/j.patrec.2016.07.026
   Papa JP, 2016, APPL SOFT COMPUT, V46, P875, DOI 10.1016/j.asoc.2015.08.043
   Papa JP, 2009, LECT NOTES COMPUT SC, V5534, P195, DOI 10.1007/978-3-642-02124-4_20
   Pass G., 1996, P 4 ACM INT C MULT, V96, P65, DOI DOI 10.1145/244130.244148
   Pisani RJ, 2014, IEEE T GEOSCI REMOTE, V52, P6075, DOI 10.1109/TGRS.2013.2294762
   Rocha LM, 2009, INT J IMAG SYST TECH, V19, P50, DOI 10.1002/ima.20191
   Rosa GH, 2014, INT C PATT RECOG, P1472, DOI 10.1109/ICPR.2014.262
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Souza GB, 2017, IEEE IJCNN, P1863, DOI 10.1109/IJCNN.2017.7966077
   Stehling R. O., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P102, DOI 10.1145/584792.584812
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Zhang DS, 2002, SIGNAL PROCESS-IMAGE, V17, P825, DOI 10.1016/S0923-5965(02)00084-X
   Zhang K., 2016, Video summarization with long short-term memory, P766
   Zhang K, 2016, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2016.120
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
NR 41
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 11195
EP 11211
DI 10.1007/s11042-018-5874-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600078
DA 2024-07-18
ER

PT J
AU Wu, L
   Han, XL
   Wen, CL
   Li, BQ
AF Wu, Lan
   Han, Xiaolei
   Wen, Chenglin
   Li, Binquan
TI A Steganalysis framework based on CNN using the filter subset selection
   method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; Convolutional neural network; Diversity in features;
   Structural similarity
ID EFFICIENT FEATURE-SELECTION
AB The steganalysis method based on Convolutional Neural Network (CNN) has attracted wide attention in the field of steganalysis. This method typically uses high-pass or derivative filters to pre-process images. Multiple filters can be used to improve the detection accuracy. However, the use of multiple filters may generate redundant residual images and redundant features. Redundant features not only consume computing resources and time but also cause model over-fitting, thus compromising the detection accuracy of the model. Therefore, we proposed a filter subset selection method to develop a well-designed pre-processing layer for CNN-based steganalysis framework. This method discarded many high-pass and derivative filters according to the mechanism of convolution operation and the correlations between pixels. Structural Similarity (SSIM) was used to calculate the similarity between the filtered residual images and arrange them in ascending order. Finally, based on the arranged filters, a series of experiments were conducted to determine the optimal filter subset and the optimal CNN-based steganalysis framework. The experimental results indicate that the proposed method not only guarantees detection accuracy but also improves the training efficiency of the model. Therefore, this method offers an optimized trade-off between computational complexity and detection accuracy.
C1 [Wu, Lan; Han, Xiaolei; Li, Binquan] Henan Univ Technol, Coll Elect Engn, Zhengzhou, Peoples R China.
   [Wen, Chenglin] Hangzhou Dianzi Univ, Inst Informat & Control, Hangzhou, Peoples R China.
C3 Henan University of Technology; Hangzhou Dianzi University
RP Wu, L (corresponding author), Henan Univ Technol, Coll Elect Engn, Zhengzhou, Peoples R China.
EM wulan@haut.edu.cn
RI han, xiao/HDN-9782-2022
OI Han, Xiaolei/0000-0002-8491-7363
FU National Natural Science Foundation of China [61973103, 61751304,
   61603366]; Henan province Central plains thousand talents plan: top
   young talents
FX This work was supported by the National Natural Science Foundation of
   China, No.61973103, 61751304, 61603366, Henan province Central plains
   thousand talents plan: top young talents.
CR [Anonymous], J IMAGE SIGNAL PROCE
   Feng GR, 2020, IEEE T CIRC SYST VID, V30, P376, DOI 10.1109/TCSVT.2019.2891778
   Filler T, 2010, IEEE T INF FOREN SEC, V5, P705, DOI 10.1109/TIFS.2010.2077629
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Goljan M, 2015, IEEE INT WORKSH INF
   Guttikonda JB, 2019, MULTIMED TOOLS APPL, V78, P21113, DOI 10.1007/s11042-019-7168-5
   Guyon I., 2006, FEATURE EXTRACTION F, DOI [DOI 10.1007/978-3-540-35488-8, 10.1007/978-3-540-35488-8]
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Li B, 2018, IEEE T INF FOREN SEC, V13, P1242, DOI 10.1109/TIFS.2017.2780805
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Sebald DJ, 2000, IEEE T SIGNAL PROCES, V48, P3217, DOI 10.1109/78.875477
   Shi Xiao-yu, 2018, Journal of Applied Sciences - Electronics and Information Engineering, V36, P309, DOI 10.3969/j.issn.0255-8297.2018.02.010
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Yu L, 2004, J MACH LEARN RES, V5, P1205
   Yuan YF, 2017, LECT NOTES COMPUT SC, V10602, DOI 10.1007/978-3-319-68505-2_10
NR 19
TC 1
Z9 1
U1 2
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19875
EP 19892
DI 10.1007/s11042-020-08831-8
EA MAR 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000522711000003
DA 2024-07-18
ER

PT J
AU Peng, SS
   Xin, W
AF Peng, Sisi
   Xin, Wang
TI Research on wave image analysis in the implied volatility of stock
   options
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wave image; Image processing; Stock; Implied volatility; Feature
   recognition
ID OIL
AB The study of volatility rarely starts from the perspective of implied volatility, and rarely combines stochastic volatility models with option pricing, which is a major flaw in research. Based on this, this study combined image processing technology to construct the wave image processing model and analyze the implied volatility of stock options and combined the image processing method to construct the implicit volatility surface output model. At the same time, the implied volatility surface model is constructed by mobile phone big data, image segmentation and noise processing are performed by image processing, and the performance of the model is analyzed by regression analysis. Finally, this paper designs experiments to verify the performance of the model. The results show that the model constructed in this paper has certain effects and can provide theoretical reference for subsequent related research.
C1 [Peng, Sisi] Nanchang Univ, Nanchang 330031, Jiangxi, Peoples R China.
   [Xin, Wang] Huazhong Univ Sci & Technol, Sch Engn Specialty, Wuhan 430074, Peoples R China.
C3 Nanchang University; Huazhong University of Science & Technology
RP Peng, SS (corresponding author), Nanchang Univ, Nanchang 330031, Jiangxi, Peoples R China.
EM pengsisi666@163.com
RI XIN, WANG/KGK-5385-2024
CR Anagnostopoulou SC, 2016, J FINANC SERV RES
   Anagnostopoulou SC, 2017, RES INT BUS FINANC, V41, P445, DOI 10.1016/j.ribaf.2017.04.046
   Anoruo E., 2017, J EC FINANCE, V41, P581
   Bouri E, 2017, RESOUR POLICY, V52, P201, DOI 10.1016/j.resourpol.2017.03.003
   Campani CH, 2017, APPL MATH SCI, V11, P651
   Dutta A, 2018, J MULTINATL FINANC M, V44, P61, DOI 10.1016/j.mulfin.2017.12.002
   Han CH, 2017, JPN J IND APPL MATH, V34, P763, DOI 10.1007/s13160-017-0270-z
   Hardle WK, 2017, SFB DISCUS PAP, V18, P97
   Li Y, 2017, INT J FINANC ENG, V4, DOI 10.1142/S2424786317500475
   Lv ZH, 2020, IEEE T IND INFORM, V16, P1957, DOI 10.1109/TII.2019.2913535
   Romo JM, 2015, J IND MANAG OPTIM, V11, P1185, DOI 10.3934/jimo.2015.11.1185
   Marks JM, 2017, J DERIV, V25, P22, DOI 10.3905/jod.2017.25.2.022
   Matic I, 2017, INT J FINANC ENG, V4, DOI 10.1142/S2424786317500323
   Narain, 2016, J ADV MANAG RES, V13, P271, DOI 10.1108/JAMR-09-2015-0062
   Orlando G, 2017, J COMPUT APPL MATH, V320, P202, DOI 10.1016/j.cam.2017.02.002
   Park SY, 2017, PHYSICA A, V482, P638, DOI 10.1016/j.physa.2017.04.023
   Pati PC, 2018, APPL ECON, V50, P2552, DOI 10.1080/00036846.2017.1403557
   Sesana A, 2018, ASTROPHYS J, V856, DOI 10.3847/1538-4357/aaad0f
   Shin JW, 2019, COMMUN STAT-SIMUL C, V48, P1503, DOI 10.1080/03610918.2017.1414250
   Williams M, 2017, INT FINAN MARKETS, V13, P139
   Yepes G, 1997, MON NOT R ASTRON SOC, V284, P235, DOI 10.1093/mnras/284.1.235
NR 21
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6447
EP 6461
DI 10.1007/s11042-019-08503-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900045
DA 2024-07-18
ER

PT J
AU Liu, JC
   Lian, ZH
   Xiao, JG
AF Liu, Juncheng
   Lian, Zhouhui
   Xiao, Jianguo
TI Sketch based modeling and editing via shape space exploration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sketch; Modeling; Shape space
ID RECONSTRUCTION
AB This paper proposes a framework that takes a user provided free-hand sketch as input and realistic 3D shape as result. Specifically, the proposed approach retrieves 3D shape based on a sketch, and then a deformation procedure is carried out for a further consistency with the provided sketch. In the retrieval stage, a locality preserving view selection scheme is proposed, which suggests views that are mostly possible to be views when creating a sketch. The proposed criterion predicates the sketch views accurately while significantly reduces the number of views that need to be rendered. In the deformation stage, retrieved shapes are modified according to sketch. However, it is a tremendously difficult job as free-hand sketches always contain various kinds of drawing errors such as stroke jittering and asymmetry. Extracting plausible deformation from sketch while discarding undesirable drawing errors is difficult. To address these issues, we obtain the plausible deformation contained in sketch by exploring a shape space trained by a collection of shapes in the same category. Furthermore, we also develop a user interface with two different intuitive editing modes based on the shape space established. Experimental results show that more consistent 3D shapes with sketches can be obtained by our method. We also illustrate that our proposed method provides easy and smart ways for both a heuristic and a purposeful shape editing.
C1 [Liu, Juncheng; Lian, Zhouhui; Xiao, Jianguo] Peking Univ, Wangxuan Inst Comp Technol, Beijing, Peoples R China.
C3 Peking University
RP Lian, ZH (corresponding author), Peking Univ, Wangxuan Inst Comp Technol, Beijing, Peoples R China.
EM liujuncheng@pku.edu.cn; lianzhouhui@pku.edu.cn; xiaojianguo@pku.edu.cn
RI Lian, Zhouhui/D-8432-2012; Xiao, Jian/GYU-4351-2022
FU National Natural Science Foundation of China [61672043, 61672056]; Key
   Laboratory of Science, Technology and Standard in Press Industry (Key
   Laboratory of Intelligent Press Media Technology)
FX This work was supported by National Natural Science Foundation of China
   (Grant No.: 61672043 and 61672056 and Key Laboratory of Science,
   Technology and Standard in Press Industry (Key Laboratory of Intelligent
   Press Media Technology).
CR Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   ANDRIY M, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI DOI 10.1109/TPAMI.2010.46
   [Anonymous], 2007, ACM SIGGRAPH 2007 CO
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   Averkiou M, 2014, COMPUTER GRAPHICS FO
   Belongie S., 2000, Conference on Neural Information Processing Systems, V2, P3
   Blanz V, 2015, COMPUTER GRAPHICS P, P187
   Campbell Neill D. F., 2014, ACM Transactions on Graphics, V33, DOI 10.1145/2601097.2601212
   Chaudhuri Siddhartha, 2013, P 26 ANN ACM S USER, P193, DOI [DOI 10.1145/2501988.2502008, 10.1145/2501988.2502008]
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Cook MT, 2009, INTERACT COMPUT, V21, P201, DOI 10.1016/j.intcom.2009.05.004
   Delanoy J, 2017, ARXIV170708390 CORR
   Ding C, 2016, FRONT COMPUT SCI-CHI, V10, P985, DOI 10.1007/s11704-016-5422-9
   Eggli L, 1997, COMPUT AIDED DESIGN, V29, P101, DOI 10.1016/S0010-4485(96)00039-5
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185527
   Fan LB, 2013, COMPUT GRAPH FORUM, V32, P157, DOI 10.1111/cgf.12223
   He XF, 2004, ADV NEUR IN, V16, P153
   Huffman D. A., 1971, Machine Intelligence Volume 6, P295
   Hyo Jong Shin, 2007, Proceedings Graphics Interface 2007, P63, DOI 10.1145/1268517.1268530
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   Kara LeventBurak., 2006, Proceedings of the Third Eurographics Conference on Sketch-Based Interfaces and Modeling, SBM'06, P59
   Kraevoy V, 2007, SHUFFLER MODELING IN
   Lee J., 2008, P EUROGRAPHICS WORKS, P97, DOI DOI 10.2312/SBM/SBM08/097-104
   Li CL, 2017, ACM T INFORM SYST, V36, DOI 10.1145/3091108
   Liu J, 2015, SIGGRAPH ASIA 2015 T
   Mitani J, 2002, INT FED INFO PROC, V80, P85
   Neil D, 2004, ADV NEURAL INFORM PR, V16, P329
   Nishida T, 2007, ECSCW 2007: PROCEEDINGS OF THE 10TH EUROPEAN CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK, P219, DOI 10.1007/978-1-84800-031-5_12
   Pu JT, 2005, LECT NOTES COMPUT SC, V3515, P343
   Secord A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019628
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Smirnov D, 2019, ARXIV190612337 CORR
   Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196
   Wang LJ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1820, DOI 10.1145/3240508.3240699
   Xie XH, 2013, COMPUT GRAPH FORUM, V32, P233, DOI 10.1111/cgf.12200
   Xu BX, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601128
   Xu K., 2015, Data-driven shape analysis and processing
   Xu K, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185553
   Xu K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964975
   Yang C., 2005, Eurographics Workshop on Sketch-Based Interfaces and Modeling, P63
   YOON S.M., 2010, Proceedings of the international conference on Multimedia, P193
   Yumer ME, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766908
NR 42
TC 3
Z9 3
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18121
EP 18142
DI 10.1007/s11042-020-08677-0
EA FEB 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000517016900004
DA 2024-07-18
ER

PT J
AU Mukherjee, H
   Dhar, A
   Obaidullah, SM
   Phadikar, S
   Roy, K
AF Mukherjee, Himadri
   Dhar, Ankita
   Obaidullah, Sk Md
   Phadikar, Santanu
   Roy, Kaushik
TI Image-based features for speech signal classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image-based features; CNN; Speech pattern classification; Language
   identification
ID LANGUAGE IDENTIFICATION
AB Like other applications, under the purview of pattern classification, analyzing speech signals is crucial. People often mix different languages while talking which makes this task complicated. This happens mostly in India, since different languages are used from one state to another. Among many, Southern part of India suffers a lot from this situation, where distinguishing their languages is important. In this paper, we propose image-based features for speech signal classification because it is possible to identify different patterns by visualizing their speech patterns. Modified Mel frequency cepstral coefficient (MFCC) features namely MFCC- Statistics Grade (MFCC-SG) were extracted which were visualized by plotting techniques and thereafter fed to a convolutional neural network. In this study, we used the top 4 languages namely Telugu, Tamil, Malayalam, and Kannada. Experiments were performed on more than 900 hours of data collected from YouTube leading to over 150000 images and the highest accuracy of 94.51% was obtained.
C1 [Mukherjee, Himadri; Dhar, Ankita; Roy, Kaushik] West Bengal State Univ, Dept Comp Sci, Kolkata, India.
   [Obaidullah, Sk Md] Aliah Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Phadikar, Santanu] Maulana Abul Kalam Azad Univ Technol, Dept Comp Sci & Engn, Kolkata, India.
C3 West Bengal State University; Aliah University; Maulana Abul Kalam Azad
   University of Technology
RP Dhar, A (corresponding author), West Bengal State Univ, Dept Comp Sci, Kolkata, India.
EM himadrim027@gmail.com; ankita.ankie@gmail.com; sk.obaidullah@gmail.com;
   sphadikar@yahoo.com; kaushik.mrg@gmail.com
RI Roy, Kaushik/O-7021-2019; Sk, Obaidullah/ABF-9198-2020
OI Roy, Kaushik/0000-0002-3360-7576; Sk, Md Obaidullah/0000-0002-5207-3709
CR Ambikairajah E, 2011, IEEE CIRC SYST MAG, V11, P82, DOI 10.1109/MCAS.2011.941081
   Anjana JS, 2018, 2018 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET)
   [Anonymous], 2006, MULTILINGUAL SPEECH
   [Anonymous], 2018, ARXIV180101627
   Bansal Sheel, 2017, U S Forest Service Pacific Northwest Research Station General Technical Report PNW-GTR, P1
   Bartz C, 2017, LECT NOTES COMPUT SC, V10639, P880, DOI 10.1007/978-3-319-70136-3_93
   Bouguelaa Mohammed, 2017, [مجلة الاقتصاد الصناعي - خزارتك, Industrial Economics Journal -Khezzartech, Khazzartech], P1
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Giwa O, 2017, 2017 PATTERN RECOGNITION ASSOCIATION OF SOUTH AFRICA AND ROBOTICS AND MECHATRONICS (PRASA-ROBMECH), P187, DOI 10.1109/RoboMech.2017.8261145
   Gupta M, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON POWER, CONTROL & EMBEDDED SYSTEMS (ICPCES)
   Hall M., 2009, SIGKDD EXPLORATIONS, V11, P10, DOI [10.1145/1656274.1656278, DOI 10.1145/1656274.1656278]
   Jin M, 2018, IEEE-ACM T AUDIO SPE, V26, P171, DOI 10.1109/TASLP.2017.2766023
   Jothilakshmi S, 2012, DIGIT SIGNAL PROCESS, V22, P544, DOI 10.1016/j.dsp.2011.11.008
   KADAMBE S, 1995, INT CONF ACOUST SPEE, P3507, DOI 10.1109/ICASSP.1995.479742
   MUKHERJEE H, 2018, INT C REC TRENDS IM, P449
   MUKHERJEE H, 2019, INT J PATTERN RECOGN
   Mukherjee H, 2018, 2018 FOURTH IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P135, DOI 10.1109/ICRCICN.2018.8718729
   Mukherjee H, 2018, INT J SPEECH TECHNOL, V21, P753, DOI 10.1007/s10772-018-9525-6
   Mukherjee H, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSPC'17), P300, DOI 10.1109/CSPC.2017.8305857
   Nyodu Karter, 2018, 2018 International Conference on Advances in Computing, Communication Control and Networking (ICACCCN). Proceedings, P213, DOI 10.1109/ICACCCN.2018.8748270
   Obaidullah SM, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.051214
   Rao KS, 2013, INT J SPEECH TECHNOL, V16, P413, DOI 10.1007/s10772-013-9193-5
   Rebai I, 2017, I C COMP SYST APPLIC, P796, DOI 10.1109/AICCSA.2017.119
   Reddy VR, 2013, INT J SPEECH TECHNOL, V16, P489, DOI 10.1007/s10772-013-9198-0
   Revathi A, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTING AND INFORMATICS (ICICI 2017), P693, DOI 10.1109/ICICI.2017.8365224
   Soewito B, 2017, 2017 INTERNATIONAL SEMINAR ON INTELLIGENT TECHNOLOGY AND ITS APPLICATIONS (ISITIA), P1, DOI 10.1109/ISITIA.2017.8124044
   Tang ZY, 2018, IEEE-ACM T AUDIO SPE, V26, P134, DOI 10.1109/TASLP.2017.2764271
   Ukil S, 2020, NEURAL COMPUT APPL, V32, P2829, DOI 10.1007/s00521-019-04111-1
   Vajda S, 2017, COMM COM INF SC, V709, P185, DOI 10.1007/978-981-10-4859-3_17
   Wang JC, 2017, MULTIMED TOOLS APPL, V76, P4055, DOI 10.1007/s11042-016-3335-0
   Zhan QR, 2018, INT CONF SIGN PROCES, P609, DOI 10.1109/ICSP.2018.8652445
NR 31
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 34913
EP 34929
DI 10.1007/s11042-019-08553-6
EA FEB 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000517016900002
DA 2024-07-18
ER

PT J
AU Shakya, S
   Alsadoon, A
   Prasad, PWC
   Haddad, S
   Pham, L
   Alrubaie, A
   Deva, A
   Hsu, JR
AF Shakya, Siddhartha
   Alsadoon, Abeer
   Prasad, P. W. C.
   Haddad, Sami
   Pham, Linh
   Alrubaie, Ahmad
   Deva, Anand
   Hsu, Jeremy
TI Novel secure surgical telepresence using enhanced advanced encryption
   standard: during, pre and post surgery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mixed reality; Telepresence; Security; Authentication; Encryption; Chaos
   theory
ID COMMUNICATION
AB Security during surgical telepresence has not yet been sufficiently considered. This paper aims to propose a solution to enhance security during surgery between the site of surgery (local site) and the site that hosts the expert surgeon (remote site). The proposed system consists of an Enhanced Advanced Encryption Standard, which enhances the confusion and diffusion of the encrypted video. Two-factor authentication have been used biometrics and a one-time password complemented by archiving that are also considered for pre and post-surgery respectively. In the proposed system the substitution box and shift rows are eliminated and replaced with mix row step, this leads to increase the complexity of the proposed system. Also the Henon chaiotic map was used in the key generation process, and this is provided more randomness. The results demonstrate that the proposed encryption method increases the entropy of the encrypted video by 0.25% compared to the Advanced Encryption Standard algorithm. In addition, a reduction in processing time have been achieved, for encryption and decryption by 24% and 38% respectively. For testing the strength of security, we measure the plain-text sensitivity by using the information entropy, Peak Signal-to-Noise Ratio (PSNR) and Mean Square Error (MSE). Also, the encryption/decryption time is measured for the proposed algorithm and state of the art algorithm. The decreasing in PSNR means the stronger encryption algorithm, and while the PSNR of the proposed system was decreased then this leads to better encryption method. The proposed system aims to enhance surgical network security to make it viable for implementation during surgery where data is exchanged under conditions of telepresence. The proposed system eliminates the limitation of the traditional AES algorithm. The proposed EAES provides high security by increasing the entropy while decreasing the encryption and decryption time.
C1 [Shakya, Siddhartha; Alsadoon, Abeer; Prasad, P. W. C.; Pham, Linh] Charles Sturt Univ, Sch Comp & Math, Sydney, NSW, Australia.
   [Haddad, Sami] Greater Western Sydney Area Hlth Serv, Dept Oral & Maxillofacial Serv, Mt Druitt, NSW 2770, Australia.
   [Haddad, Sami] Cent Coast Area Hlth, Dept Oral & Maxillofacial Serv, Gosford, NSW 2250, Australia.
   [Alrubaie, Ahmad] Univ New South Wales, Fac Med, Sydney, NSW, Australia.
   [Deva, Anand; Hsu, Jeremy] Macquarie Univ, Fac Med & Hlth Sci, Sydney, NSW, Australia.
C3 Charles Sturt University; Florey Institute of Neuroscience & Mental
   Health; University of New South Wales Sydney; Macquarie University
RP Alsadoon, A (corresponding author), Charles Sturt Univ, Sch Comp & Math, Sydney, NSW, Australia.
EM sr_shakya@hotmail.com; aalsadoon@studygroup.com;
   cwithana@studygroup.com; drsamihaddad@gmail.com; lpham@studygroup.com;
   ahmadalmusa2@gmail.com; anand.deva@mq.edu.au; jemhsu@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; withana,
   chandana/0000-0002-3007-687X; Pham, Linh/0000-0003-0311-9659; Deva,
   Anand/0000-0002-0314-7177
CR Altaf M, 2018, MULTIMED TOOLS APPL, V77, P27981, DOI 10.1007/s11042-018-6022-5
   Atteya AM, 2014, IEEE INT NEW CIRC, P217, DOI 10.1109/NEWCAS.2014.6934022
   Barakat ML, 2013, ETRI J, V35, P448, DOI 10.4218/etrij.13.0112.0677
   Çavusoglu U, 2018, NONLINEAR DYNAM, V92, P1745, DOI 10.1007/s11071-018-4159-4
   Chuvakin A, 2010, IEEE SECUR PRIV, V8, P82, DOI 10.1109/MSP.2010.127
   Fryberger C.T., 2015, ORTHOP J HARVARD MED, V16, P8
   Hamida A, 2012, IJCSI, V9, P41
   Harba ESI, 2017, ENG TECHNOL APPL SCI, V7, P1781
   Hayajneh T, 2013, INT J SECUR APPL, V7, P355, DOI 10.14257/ijsia.2013.7.6.36
   Hayajneh T, 2017, IEEE SYST J, V11, P2536, DOI 10.1109/JSYST.2015.2424702
   He DB, 2012, J MED SYST, V36, P1989, DOI 10.1007/s10916-011-9658-5
   Hussain M, 2016, MULTIMED TOOLS APPL, V75, P5345, DOI 10.1007/s11042-015-2936-3
   Jevdjic Djordje, 2017, ACM SIGARCH COMPUTER, V45, P361, DOI DOI 10.1145/3093337.3037718
   Khan S, 2013, CONTROL SYST COMPUT, V5062, DOI DOI 10.1109/ICCSCE.2013.6720027
   Kiah MLM, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0133-y
   Kocarev L, 2011, STUD COMPUT INTELL, V354, P1, DOI 10.1007/978-3-642-20542-2
   Kohno T, 2015, P ACM IEEE 6 INT C C, P11
   Li CS, 2011, J STAT COMPUT SIM, V81, P1081, DOI 10.1080/00949651003677410
   Liu CB, 2015, INT J COMPUT SCI NET, V15, P18
   Pratt J, 2012, MARSHALL MED CTR BRI
   Roy S, 2016, DESIGNING IMPLEMENTI, P1, DOI [10.1109/PCCC.2016.7820604, DOI 10.1109/PCCC.2016.7820604]
   Roychoudhuri L., 2005, IEEE TRANS NETW SERV, V2, P29
   Salim E, 2017, TECHNOL APPL SCI RES, V7, P1781
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shenai MB, 2011, NEUROSURGERY, V68, DOI 10.1227/NEU.0b013e3182077efd
   Sun SG, 2016, AER ADV ENG RES, V44, P413
   Tiwari Minu, 2016, 2016 3rd International Conference on Recent Advances in Information Technology (RAIT). Proceedings, P372, DOI 10.1109/RAIT.2016.7507932
   Tozal ME, 2013, MOBILE NETW APPL, V18, P697, DOI 10.1007/s11036-011-0333-3
   Wickramage C, 2016, 2016 IEEE 18TH INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES (HEALTHCOM), P43
   Zhang X, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P889, DOI 10.1109/ICALIP.2008.4590187
   [No title captured]
NR 31
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 14265
EP 14290
DI 10.1007/s11042-020-08656-5
EA FEB 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000520049300002
DA 2024-07-18
ER

PT J
AU Avola, D
   Bernardi, M
   Cinque, L
   Foresti, GL
   Massaroni, C
AF Avola, Danilo
   Bernardi, Marco
   Cinque, Luigi
   Foresti, Gian Luca
   Massaroni, Cristiano
TI Online separation of handwriting from freehand drawing using extreme
   learning machines
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Extreme learning machines; Handwriting; Freehand drawing; Online
   separation algorithm; Sketch-based interfaces
ID RECOGNITION
AB Online separation between handwriting and freehand drawing is still an active research area in the field of sketch-based interfaces. In the last years, most approaches in this area have been focused on the use of statistical separation methods, which have achieved significant results in terms of performance. More recently, Machine Learning (ML) techniques have proven to be even more effective by treating the separation problem like a classification task. Despite this, also in the use of these techniques several aspects can be still considered open problems, including: 1) the trade-off between separation performance and training time; 2) the separation of handwriting from different types of freehand drawings. To address the just reported drawbacks, in this paper a novel separation algorithm based on a set of original features and an Extreme Learning Machine (ELM) is proposed. Extensive experiments on a wide range of sketched schemes (i.e., text and graphical symbols), more numerous than those usually tested in any key work of the current literature, have highlighted the effectiveness of the proposed approach. Finally, measurements on accuracy and speed of computation, during both training and testing stages, have shown that the ELM can be considered, in this research area, the better choice even if compared with other popular ML techniques.
C1 [Avola, Danilo; Bernardi, Marco; Cinque, Luigi; Massaroni, Cristiano] Sapienza Univ, Dept Comp Sci, Via Salaria 113, I-00198 Rome, Italy.
   [Foresti, Gian Luca] Univ Udine, Dept Math Comp Sci & Phys, Via Sci 206, I-33100 Udine, Italy.
C3 Sapienza University Rome; University of Udine
RP Avola, D (corresponding author), Sapienza Univ, Dept Comp Sci, Via Salaria 113, I-00198 Rome, Italy.
EM avola@di.uniroma1.it; bernardi@di.uniroma1.it; cinque@di.uniroma1.it;
   gianluca.foresti@uniud.it; massaroni@di.uniroma1.it
OI Bernardi, Marco/0000-0001-5477-1423
CR Al Kabary I, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1227, DOI 10.1145/2600428.2609551
   Alvarado C., 2004, PROC ACM S USER INTE, P23, DOI DOI 10.1145/1029632.1029637
   Phan AV, 2017, APPL INTELL, V46, P455, DOI 10.1007/s10489-016-0843-6
   Avola D, 2009, P 2 INT C PERV TECHN, P1
   Avola D, 2007, P ANN HAW INT C SYST, P1
   Avola D, 2006, LECT NOTES COMPUT SC, V4277, P904
   Avola D, 2017, LECT NOTES COMPUT SC, V10484, P223, DOI 10.1007/978-3-319-68560-1_20
   Avola D, 2013, LECT NOTES COMPUT SC, V8157, P181, DOI 10.1007/978-3-642-41184-7_19
   Avola D, 2009, STUD COMPUT INTELL, V226, P167
   Avola Danilo, 2007, LECT NOTES COMPUTER, P369
   Bhat A, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1395
   Bishop CM, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P142, DOI 10.1109/IWFHR.2004.34
   Blagojevic R, 2011, COMPUT GRAPH-UK, V35, P976, DOI 10.1016/j.cag.2011.07.002
   Boniardi F, 2016, IEEE INT CONF ROBOT, P2896, DOI 10.1109/ICRA.2016.7487453
   Bucurica M, 2015, INT C INTELL COMP CO, P471, DOI 10.1109/ICCP.2015.7312705
   Cao JW, 2016, NEURAL NETWORKS, V81, P91, DOI 10.1016/j.neunet.2016.06.001
   Costagliola G, 2014, J VISUAL LANG COMPUT, V25, P955, DOI 10.1016/j.jvlc.2014.10.021
   Dahake D, 2017, 2017 2 INT C MAN MAC, P1
   Deufemia V, 2014, PATTERN RECOGN, V47, P1159, DOI 10.1016/j.patcog.2013.09.016
   Ding C, 2016, FRONT COMPUT SCI-CHI, V10, P985, DOI 10.1007/s11704-016-5422-9
   Eglin V, 2004, LECT NOTES COMPUT SC, V3163, P337
   Eitrich T, 2005, LECT NOTES COMPUT SC, V3695, P253
   Hammond Tracy., 2010, CHI 10 EXTENDED ABST, P4213, DOI [10.1145/1753846.1754128, DOI 10.1145/1753846.1754128]
   Herold J, 2014, COMPUT GRAPH-UK, V38, P357, DOI 10.1016/j.cag.2013.10.005
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang GB, 2011, INT J MACH LEARN CYB, V2, P107, DOI 10.1007/s13042-011-0019-y
   Huang ZY, 2017, IEEE T CYBERNETICS, V47, P920, DOI 10.1109/TCYB.2016.2533424
   Hussain T, 2017, IEEE ACCESS, V5, DOI 10.1109/ACCESS.2017.2766675
   Jahani-Fariman H, 2018, MULTIMED TOOLS APPL, V77, P1997, DOI 10.1007/s11042-017-4368-8
   Keysers D, 2017, IEEE T PATTERN ANAL, V39, P1180, DOI 10.1109/TPAMI.2016.2572693
   Kim H., 2013, Proceedings of the International Symposium on Sketch- Based Interfaces and Modeling, Expressive 2013 - The Joint Symposium on Computational Aesthetics and Sketch-Based Interfaces and modeling and Non- Photorealistic Animation and Rendering, P33
   Lan Y, 2013, NEURAL COMPUT APPL, V22, P417, DOI 10.1007/s00521-012-0946-x
   Landay JA, 2001, COMPUTER, V34, P56, DOI 10.1109/2.910894
   Leibowitz ML, 2010, WILEY FINANC SER, P1, DOI 10.1002/9781118266533
   Liu XY, 2012, NEURAL NETWORKS, V33, P58, DOI 10.1016/j.neunet.2012.04.002
   Lu T, 2018, MULTIMED TOOLS APPL, V77, P11219, DOI 10.1007/s11042-017-5475-2
   Machii K., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P710, DOI 10.1109/ICDAR.1993.395638
   Mahdiyah U, 2015, PROCEDIA COMPUT SCI, V59, P221, DOI 10.1016/j.procs.2015.07.561
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Ouyang T. Y., 2007, AAAI, V7, P846
   Parvez MT, 2013, PATTERN RECOGN, V46, P141, DOI 10.1016/j.patcog.2012.07.012
   Patil U., 2012, INT J EMERGING TECHN, V2, P590
   Phang SK, 2015, MECHATRONICS, V30, P65, DOI 10.1016/j.mechatronics.2015.06.006
   Qin SF, 2005, Eurocon 2005: The International Conference on Computer as a Tool, Vol 1 and 2 , Proceedings, P1374
   Shi LC, 2013, NEUROCOMPUTING, V102, P135, DOI 10.1016/j.neucom.2012.02.041
   Sun PH, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P157, DOI 10.1109/DAS.2018.28
   Suresh S, 2009, APPL SOFT COMPUT, V9, P541, DOI 10.1016/j.asoc.2008.07.005
   Tang JX, 2015, IEEE T GEOSCI REMOTE, V53, P1174, DOI 10.1109/TGRS.2014.2335751
   UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P821, DOI 10.1109/78.193220
   Verma K, 2017, NEURAL COMPUT APPL, V28, pS51, DOI 10.1007/s00521-016-2309-5
   Wadhwa D, 2012, INT J COMPUT APPL, V48, P590
   Yanik E, 2015, COMPUT GRAPH-UK, V52, P93, DOI 10.1016/j.cag.2015.07.023
   Zhang XY, 2017, PATTERN RECOGN, V61, P348, DOI 10.1016/j.patcog.2016.08.005
   Zheng X, 2016, MULTIMED TOOLS APPL, V75, P8719, DOI 10.1007/s11042-015-2788-x
NR 55
TC 7
Z9 8
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4463
EP 4481
DI 10.1007/s11042-019-7196-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500013
DA 2024-07-18
ER

PT J
AU Di, GH
   Su, FL
   Yang, HX
   Fu, S
AF Di, Guohui
   Su, Fulin
   Yang, Hongxin
   Fu, Shuang
TI ISAR image scattering center association based on speeded-up robust
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D reconstruction; Scattering centers association; Speeded-up robust
   feature (SURF); Non-cooperative target; Random sample consensus(RANSAC)
ID FOURIER-TRANSFORM; TARGETS; MOTION
AB It is difficult for the imaging radar of the single antenna to correlate the scattering centers in 3D reconstruction. Therefore, an association method of scattering centers is proposed to get the transformational matrix of the adjacent image frames through rough matching of the Speeded-up Robust Features (SURF) and determine the association results of the scattering centers with a minimum of 2 norms after back projection. At last, it is verified through the simulation experiment and the measured data. The experimental results indicate that this method is simple with small computation, strong robustness and stable imaging effect. It is applicable to the association of target scattering centers in multiple perspectives. The experimental results prove the feasibility of the method.
C1 [Di, Guohui; Su, Fulin; Yang, Hongxin] Harbin Inst Technol, Sch Elect & Informat Engn, Harbin, Peoples R China.
   [Di, Guohui; Fu, Shuang] Heilongjiang Bayi Agr Univ, Sch Elect & Informat, Daqing, Peoples R China.
C3 Harbin Institute of Technology; Heilongjiang Bayi Agricultural
   University
RP Su, FL (corresponding author), Harbin Inst Technol, Sch Elect & Informat Engn, Harbin, Peoples R China.
EM 195694781@qq.com
RI Fu, Shuang/AAU-5556-2021
OI Fu, Shuang/0000-0002-8804-4440
CR Bay H., 2006, LECT NOTES COMPUTER
   Chen V., 2001, Time-Frequency Transforms for Radar Imaging and Signal Analysis
   Cui S, 2017, IEEE INT C EL INF CO, P439
   Djukanovic S, 2008, IEEE T SIGNAL PROCES, V56, P1627, DOI 10.1109/TSP.2007.909337
   Ferrara M, 2009, IEEE T PATTERN ANAL, V31, P1906, DOI 10.1109/TPAMI.2008.294
   Fulin S, 2011, 2011 INT C SYST DES, V1, P213
   Karine A, 2016, P 2016 6 EUR WORKSH
   Karine A, 2017, IEEE INT C ADV TECHN
   Laurenti M, 2016, ADV MATER INTERFACES, V3, DOI 10.1002/admi.201600110
   Li A., 2016, J SENS, V2016, P1
   Li A, 2016, OPT REV, V23, P776, DOI 10.1007/s10043-016-0267-x
   Li A, 2016, CIRC SYST SIGNAL PR, V35, P2932, DOI 10.1007/s00034-015-0179-1
   Li G, 2014, PROC SPIE, V9252, DOI 10.1117/12.2067006
   Li JF, 2003, IEEE T AERO ELEC SYS, V39, P343, DOI 10.1109/TAES.2003.1188916
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1740, DOI 10.1109/TIP.2016.2526905
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Martins M.A. P., 2013, IONIC LIQUIDS NEW AS, P1
   McFadden FE, 2002, P SOC PHOTO-OPT INS, V4744, P58, DOI 10.1117/12.488289
   Monells D, 2014, EUSAR 2014 EUR C SYN, P1
   Ruan H, 2014, IEEE GEOSCI REMOTE S, V11, P128, DOI 10.1109/LGRS.2013.2250250
   Shin SY, 2008, MICROW OPT TECHN LET, V50, P2173, DOI 10.1002/mop.23619
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Wang C, 2013, IET RADAR SONAR NAV, V7, P994, DOI 10.1049/iet-rsn.2013.0083
   Wang J, 2016, RAD C 2015 IET INT, P8
   Wang Q, 2008, IEEE T GEOSCI REMOTE, V46, P22, DOI 10.1109/TGRS.2007.909086
   Wang Y, 2014, IEEE J-STARS, V7, P2971, DOI 10.1109/JSTARS.2014.2301158
   Xing MD, 2009, IEEE T GEOSCI REMOTE, V47, P2106, DOI 10.1109/TGRS.2008.2010499
   Xu ZW, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1568, DOI 10.1109/CISP.2013.6743925
   Yun DJ, 2018, IEICE T COMMUN, VE101B, P418, DOI 10.1587/transcom.2017ISP0005
   Yun DJ, 2016, INT S ANT PROP
   Zhang Ying-kang, 2011, Systems Engineering and Electronics, V33, P1988, DOI 10.3969/j.issn.1001-506X.2011.09.14
   Zhang YK, 2011, J SYST ENG ELECTRON, V22, P412, DOI 10.3969/j.issn.1004-4132.2011.03.008
   Zhu Y, IEEE T GEOSCIENCE RE, V48, P3290
NR 33
TC 8
Z9 9
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5065
EP 5082
DI 10.1007/s11042-018-6291-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500047
DA 2024-07-18
ER

PT J
AU Ghatak, S
   Rup, S
   Majhi, B
   Swamy, MNS
AF Ghatak, Subhankar
   Rup, Suvendu
   Majhi, Banshidhar
   Swamy, M. N. S.
TI An improved surveillance video synopsis framework: a HSATLBO
   optimization approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Energy minimization; Optimization; Simulated annealing (SA); Teaching
   learning based optimization (TLBO); Video surveillance; Video synopsis
AB Video surveillance cameras capture huge amount of data 24 hours a day. However, most of these videos contain redundant data which make the process difficult for browsing and analysis. A significant amount of research findings have been made in summarization of recorded video, but such schemes do not have much impact on video surveillance applications. On the contrary, video synopsis is a smart technology that preserves all the activities of every single object and projects them concurrently in a condensed time. The energy minimization module in video synopsis framework plays a vital role, which in turn minimizes the activity loss, number of collision and temporal consistency cost. In most of the reported schemes, Simulated Annealing (SA) algorithm is employed to solve the energy minimization problem. However, it suffers from slow convergence rate resulting in a high computational load to the system. In order to mitigate this issue, this article presents an improved energy minimization scheme using hybridization of SA and Teaching Learning based Optimization (TLBO) algorithms. The suggested framework for static surveillance video synopsis generation consists of four computational modules, namely, Object detection and segmentation, Tube formation, Optimization, and finally Stitching and the central focus is on the optimization module. Thus, the present work deals with an improved hybrid energy minimization problem to achieve global optimal solution with reduced computational time. The motivation behind hybridization (HSATLBO) is that TLBO algorithm has the ability to search rigorously, ensuring to reach the optimum solution with less computation. On the contrary, SA reaches the global optimum solution, but it may get disarrayed and miss some critical search points. Exhaustive experiments are carried out and results compared with that of benchmark schemes in terms of minimizing the activity, collision and temporal consistency costs. All the experiments are conducted on five widely used videos taken from standard surveillance video data set (PETS 2001, MIT Surveillance Dataset, ChangeDetection.Net, PETS 2006 and UMN Dataset) as well as one real generated surveillance video from the IIIT Bhubaneswar Surveillance Dataset. To make a fair comparison, additionally, performance of the proposed hybrid scheme to solve video synopsis optimization problem is also compared with that of the other benchmark functions. Experimental evaluation and analysis confirm that the proposed scheme outperforms other state-of-the-art approaches. Finally, the suggested scheme can be easily and reliably deployed in the off-line video synopsis generation.
C1 [Ghatak, Subhankar; Rup, Suvendu] Int Inst Informat Technol, Dept Comp Sci & Engn, Image & Video Proc Lab, Bhubaneswar 751003, India.
   [Majhi, Banshidhar] IIITDM Kancheepuram, Sch Comp & Elect Engn, Chennai, Tamil Nadu, India.
   [Swamy, M. N. S.] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ, Canada.
C3 International Institute of Information Technology, Bhubaneswar; Indian
   Institute of Information Technology, Design & Manufacturing,
   Kancheepuram; Concordia University - Canada
RP Ghatak, S (corresponding author), Int Inst Informat Technol, Dept Comp Sci & Engn, Image & Video Proc Lab, Bhubaneswar 751003, India.
EM subhankar@iiit-bh.ac.in
RI Rup, Suvendu/AAQ-6535-2021; Ghatak, Dr. Subhankar/ABG-1663-2021
OI Ghatak, Dr. Subhankar/0000-0003-4814-6204; Rup,
   Suvendu/0000-0002-9407-0469
CR [Anonymous], P IEEE C COMPUTER VI
   [Anonymous], P 2006 IEEE COMP SOC
   Bishop Gary., 2001, An Introduction to the Kalman Filter
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chou CK, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/675714
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Ferryman JM, 2001, 2 IEEE INT WORKSH PE
   Ferryman JM, 2006, 9 IEEE INT WORKSH PE
   He Y, 2017, NEUROCOMPUTING, V225, P64, DOI 10.1016/j.neucom.2016.11.011
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   Huang CR, 2014, IEEE T CIRC SYST VID, V24, P1417, DOI 10.1109/TCSVT.2014.2308603
   Jamil M., 2013, ARXIV13084008
   Khadanga RK, 2017, IET GENER TRANSM DIS, V11, P3257, DOI 10.1049/iet-gtd.2016.1542
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Li K, 2016, IEEE SIGNAL PROC LET, V23, P11, DOI [10.1109/LSP.2015.2496558, 10.1109/lsp.2015.2496558]
   Li XL, 2016, IEEE T IMAGE PROCESS, V25, P740, DOI 10.1109/TIP.2015.2507942
   Liao WS, 2017, INT SYMP WIREL, P253, DOI 10.1109/WPMC.2017.8301818
   Lin WY, 2015, NEUROCOMPUTING, V155, P84, DOI 10.1016/j.neucom.2014.12.044
   Liu Y., 2014, Science China Information Sciences, V57, P1
   Lu ML, 2013, INT CONF ACOUST SPEE, P2292, DOI 10.1109/ICASSP.2013.6638063
   METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mishra S. K., 2006, Some new test functions for global optimization and performance of repulsive particle swarm method
   Nie YW, 2013, IEEE T VIS COMPUT GR, V19, P1664, DOI 10.1109/TVCG.2012.176
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Pritch Y, 2007, IEEE I CONF COMP VIS, P833
   Pritch Y, 2008, IEEE T PATTERN ANAL, V30, P1971, DOI 10.1109/TPAMI.2008.29
   Pritch Y, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P195, DOI 10.1109/AVSS.2009.53
   Rao R., 2016, Int J Ind Eng Comput, V7, P19, DOI [DOI 10.5267/J.IJIEC.2015.8.004, 10.5267/j.ijiec.2015.8.004]
   Rao RV, 2011, COMPUT AIDED DESIGN, V43, P303, DOI 10.1016/j.cad.2010.12.015
   Rao RV., 2016, Decis. Sci. Lett, V5, P1
   Shizheng Wang, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1947, DOI 10.1109/ICCVW.2011.6130487
   Simionescu P., 2014, Computer-Aided Graphing and Simulation Tools for AutoCAD Users
   St-Charles PL, 2014, IEEE COMPUT SOC CONF, P414, DOI 10.1109/CVPRW.2014.67
   St-Charles PL, 2014, IEEE WINT CONF APPL, P509, DOI 10.1109/WACV.2014.6836059
   Sun L, 2012, INT C PATT RECOG, P1956
   Tian YM, 2016, IET COMPUT VIS, V10, P868, DOI 10.1049/iet-cvi.2016.0128
   UMN, 2006, UMN UN CROWD ACT DAT
   Vural U, 2009, PATTERN RECOGN LETT, V30, P1151, DOI 10.1016/j.patrec.2009.03.002
   Wang SZ, 2013, J VIS COMMUN IMAGE R, V24, P1431, DOI 10.1016/j.jvcir.2013.10.001
   Wang WC, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P250, DOI 10.23919/MVA.2017.7986848
   Wang Wenguan, 2015, IEEE Trans Image Process, V24, P3137, DOI 10.1109/TIP.2015.2438550
   Wang Y., 2014, P IEEE C COMP VIS PA, P387, DOI 10.1109/ICIP40778.2020.9190887
   Xu M., 2008, P 1 ACM INT C MULT I, P366, DOI DOI 10.1145/1460096.1460156
   Yao T, 2014, PROCEEDINGS OF 2014 IEEE WORKSHOP ON ADVANCED RESEARCH AND TECHNOLOGY IN INDUSTRY APPLICATIONS (WARTIA), P1138, DOI 10.1109/WARTIA.2014.6976479
   YILDIRIM A, 2008, INT J COMPUT MATH, DOI DOI 10.1080/00207160802247646
   Yuan Y, 2015, SIGNAL PROCESS, V110, P94, DOI 10.1016/j.sigpro.2014.08.003
   Zhong R, 2014, IEEE SIGNAL PROC LET, V21, P834, DOI 10.1109/LSP.2014.2317754
   Zhu XB, 2012, INT C PATT RECOG, P2528
NR 51
TC 16
Z9 18
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4429
EP 4461
DI 10.1007/s11042-019-7389-7
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500012
DA 2024-07-18
ER

PT J
AU Krithiga, RR
   Lakshmi, C
AF Krithiga, R. Rani
   Lakshmi, C.
TI A novel automated classification technique for diagnosing liver
   disorders using wavelet and texture features on liver ultrasound images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Random Forest classifier; Shift variant bi-orthogonal wavelet
   decomposition; Gray-level-run-length matrix (GLRLM); Textural features;
   liver diseases; Ultrasound images
ID HIERARCHICAL-CLASSIFICATION; FUSION; DISEASES; LESIONS; FATTY
AB A novel automated classification technique for diagnosing liver disorders is contributed in this paper by utilizing the merits of wavelet and texture features of ultrasound images. In this automated classification technique, initially the diseased part of the ultrasound image is isolated based on the application of improved active contour-based segmentation scheme. Improved active contour-based segmentation is mainly for preventing the issue of worse convergence, which is prevalent in the concave boundary regions of ultrasonic images. After segmentation, shift variant bi-orthogonal wavelet transform is applied for decomposing the region of focus into diagonal, vertical and horizontal component images. This shift variant bi-orthogonal wavelet transform is used in this approach for reducing the degree of prediction errors that are most possible in the classical discrete wavelet transform schemas. Finally, an improved random forest classifier (IRFC) is used for classifying the features that are extracted from the wavelet filtered images using gray level run length matrix (GLRLM). The performance of this scheme is evaluated based on sensitivity, specificity and accuracy metrics and shows the comparison of each classifier performance. The results of the proposed scheme infer an overall classification accuracy rate of 97.8% and confirm better results using GLRLM.
C1 [Krithiga, R. Rani; Lakshmi, C.] SRM Univ, Dept Software Engn, Chennai, Tamilnadu, India.
C3 SRM Institute of Science & Technology Chennai
RP Krithiga, RR (corresponding author), SRM Univ, Dept Software Engn, Chennai, Tamilnadu, India.
EM krithiigaa1112@gmail.com
CR Alivar A, 2016, BIOCYBERN BIOMED ENG, V36, P697, DOI 10.1016/j.bbe.2016.07.003
   Alivar A, 2014, 2014 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P669, DOI 10.1109/ICCKE.2014.6993434
   [Anonymous], J INTELLIGENT SYSTEM
   [Anonymous], NEUR NETW IJCN 2010
   [Anonymous], 2012, ARXIV12107650
   Balaji GN, 2016, ENG SCI TECHNOL, V19, P1871, DOI 10.1016/j.jestch.2016.10.001
   Bolón-Canedo V, 2011, EXPERT SYST APPL, V38, P5947, DOI 10.1016/j.eswa.2010.11.028
   Divya C, 2013, INT C TREND COMPUT C, P611, DOI 10.1109/ICE-CCN.2013.6528572
   Hall M. A., 1999, Proceedings of the Twelfth International Florida AI Research Society Conference, P235
   Hwang YN, 2015, BIO-MED MATER ENG, V26, pS1599, DOI 10.3233/BME-151459
   Kalyan Karthik, 2014, Advances in Bioinformatics, V2014, P708279, DOI 10.1155/2014/708279
   Minhas FUA, 2012, J MED SYST, V36, P3163, DOI 10.1007/s10916-011-9803-1
   Owjimehr M, 2017, ULTRASONIC IMAGING, V39, P79, DOI 10.1177/0161734616649153
   Rastghalam R, 2016, PATTERN RECOGN, V51, P176, DOI 10.1016/j.patcog.2015.09.009
   Singh M, 2014, INFORM FUSION, V19, P91, DOI 10.1016/j.inffus.2013.05.007
   Thangaparvathi B., 2011, 2011 International Conference on Recent Trends in Information Technology (ICRTIT 2011), P695, DOI 10.1109/ICRTIT.2011.5972267
   Uddin MS, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P105, DOI 10.1109/PCS.2015.7170056
   Venkatalakshmi K, 2004, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON INTELLIGENT SENSING AND INFORMATION PROCESSING, P283
   Virmani J, 2013, DEFENCE SCI J, V63, P478, DOI 10.14429/dsj.63.3951
   Zaim A, 2007, IEEE IJCNN, P278, DOI 10.1109/IJCNN.2007.4370968
   Zhu W., 2010, NESUG P HLTH CARE LI, V19, P67
NR 21
TC 1
Z9 1
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3761
EP 3773
DI 10.1007/s11042-018-7045-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700036
DA 2024-07-18
ER

PT J
AU Mao, Y
   Yang, SW
   Li, ZN
   Li, YJ
AF Mao, Yan
   Yang, Shanwen
   Li, Zuning
   Li, Yongjian
TI Personality trait and group emotion contagion based crowd simulation for
   emergency evacuation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion contagion; Crowd simulation; Emergency evacuation; Group
   behavior; Inter-group; Intra-group
ID MODEL
AB Most of current crowd simulation methods have considered the impact of interindividual emotion on the agent's behavior pattern during emergency evacuations. However, the emotion contagion is not only at the individual level, but also at the contagion in groups. Psychological researches show that the third-party authority also has an impact on emotion contagion. For example, security guards can guide individuals to find exits and calms them; and teachers can lead their students safely evacuate from multi-layer teaching buildings, etc. In this paper, we propose a unified framework to simulate the emergency evacuations in virtual environment. This framework considers four kinds of agents: third-party authority agents, group leaders, members and isolated agents. Firstly, we randomly assign each agent a specific personality and initialize its emotion. Secondly, the emotion contagion in this paper is considered with three aspects: intra-group contagion, inter-group contagion and third-party authority based emotion contagion. We simulate inter-group aggregated behaviors by improving the ASCRIBE and provide a threshold model to simulate inter-group switching behaviors. The third-party authorities exhibit a calm effect on the agents during an evacuation, and we set their negative emotion very low and keep unchanged. Meanwhile, we perform high-level path planning to explore the environments and obtain a cognitive map for navigation purposes. Through quantitative and qualitative experiments, simulation results demonstrate that our proposed model can simulate the emotion contagion in groups during emergency evacuations, and our model outperforms some existing works.
C1 [Mao, Yan; Li, Yongjian] Southwest Jiaotong Univ, Sch Econ & Management, Chengdu, Peoples R China.
   [Yang, Shanwen; Li, Zuning] Sichuan Normal Univ, Coll Movie & Media, Chengdu, Peoples R China.
   [Yang, Shanwen; Li, Zuning] Sichuan Normal Univ, Visual Comp & Virtual Real Key Lab Sichuan Prov, Chengdu, Peoples R China.
C3 Southwest Jiaotong University; Sichuan Normal University; Sichuan Normal
   University
RP Li, YJ (corresponding author), Southwest Jiaotong Univ, Sch Econ & Management, Chengdu, Peoples R China.
EM maoyy85@163.com; yongjian_li@outlook.com
RI Yongjian, Li/JED-8005-2023
CR Akpa NAEE, 2015, 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P30, DOI 10.1109/SSCI.2015.15
   [Anonymous], 1996, 5 FACTOR MODEL PERSO
   [Anonymous], 2015, BBC NEWS
   [Anonymous], 2009, 2009 16 INT C SYSTEM, DOI [DOI 10.1109/IWSSIP.2009.5367704, 10.1109/IWSSIP.2009.5367704]
   [Anonymous], 2013, P SCA 2013 12 ACM SI, DOI DOI 10.1145/2485895.2485910
   [Anonymous], 2005, INT JOINT C AUTONOMO, DOI DOI 10.1145/1082473.1082478
   Barsade SG, 2002, ADMIN SCI QUART, V47, P644, DOI 10.2307/3094912
   Barsade SG, 1998, RES MANAG GRP TEAM, V1, P81
   Bellomo N, 2016, COMPUT FLUIDS, V141, P13, DOI 10.1016/j.compfluid.2016.04.022
   Bellomo N, 2016, PHYS LIFE REV, V18, P1, DOI 10.1016/j.plrev.2016.05.014
   BNO news, 2016, BNO NEWS
   BNO news, 2017, BNO NEWS
   Bosse T, 2015, COGN COMPUT, V7, P111, DOI 10.1007/s12559-014-9277-9
   Bruneau J, 2015, IEEE T VIS COMPUT GR, V21, P520, DOI 10.1109/TVCG.2015.2391862
   Cao MX, 2017, PHYSICA A, V483, P250, DOI 10.1016/j.physa.2017.04.137
   Collins A, 1990, The cognitive structure of emotions
   Doulamis N, 2015, 8TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2015), DOI 10.1145/2769493.2769575
   Durupinar F, 2016, IEEE T VIS COMPUT GR, V22, P2145, DOI 10.1109/TVCG.2015.2501801
   Durupinar F, 2011, IEEE COMPUT GRAPH, V31, P22, DOI 10.1109/MCG.2009.105
   Eysenck H.J., 1991, Explorations in temperament: International perspectives on theory and measurement, P87, DOI DOI 10.1007/978-1-4899-0643-47
   Faroqi H, 2015, INT ARCH PHOTOGRAMM, V41, P193, DOI 10.5194/isprsarchives-XL-1-W5-193-2015
   Guy S.J., 2011, P 2011 ACM SIGGRAPH, P43, DOI [10.1145/2019406.2019413, DOI 10.1145/2019406.2019413]
   Hatfield E., 1993, CURR DIR PSYCHOL SCI, V2, P96, DOI [DOI 10.1111/1467-8721.EP10770953, 10.1111/1467-8721.ep10770953]
   He W, 2016, MULTIMED TOOLS APPL, V75, P5981, DOI 10.1007/s11042-015-2561-1
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Hughes RL, 2002, TRANSPORT RES B-METH, V36, P507, DOI 10.1016/S0191-2615(01)00015-7
   Jaklin N., 2015, P ACM S VIRT REAL SO, P163, DOI [10.1145/2821592.2821597, DOI 10.1145/2821592.2821597]
   Kim S., 2012, P ACM SIGGRAPH S INT, P55, DOI [DOI 10.1145/2159616.2159626, 10.1145/2159616.2159626]
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Narain R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618468
   O'Connor S, 2015, IEEE INT CONF INF VI, P494, DOI 10.1109/iV.2015.88
   Parker S, 2012, PHONOL PHONET, V18, P1, DOI 10.1515/9783110261523
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   PelechanoGomez N., 2005, INT WORKSH CROWD SIM, P1
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Sabeur Z, 2015, LECT NOTES COMPUT SC, V9474, P162, DOI 10.1007/978-3-319-27857-5_15
   Staff BP, 2015, BIHARPRABHA NEWS COP
   Stamatopoulou I, 2012, PROC INT C TOOLS ART, P1133, DOI 10.1109/ICTAI.2012.161
   Sung M, 2004, COMPUT GRAPH FORUM, V23, P519, DOI 10.1111/j.1467-8659.2004.00783.x
   Taffou M, 2017, J MULTIMODAL USER IN, V11, P57, DOI 10.1007/s12193-016-0228-5
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   Tsai J., 2011, 10 INT C AUTONOMOUS, V2, P457
   van Toll WG, 2012, COMPUT ANIMAT VIRT W, V23, P59, DOI 10.1002/cav.1424
   Vicovaro M, 2014, ACM T APPL PERCEPT, V11, DOI 10.1145/2617916
   Vreugdenhil B.J., 2015, Using crowd modelling in evacuation decision making
   Wang H, 2016, PROCEEDINGS I3D 2016: 20TH ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, P49, DOI 10.1145/2856400.2856410
   Winch J, 2015, TELEGRAPH
   Wong SK, 2015, COMPUT ANIMAT VIRT W, V26, P387, DOI 10.1002/cav.1636
   Yin Y., 2012, INTELLIGENT INFORM P, VVI, P240
NR 50
TC 31
Z9 32
U1 3
U2 64
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3077
EP 3104
DI 10.1007/s11042-018-6069-3
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700002
DA 2024-07-18
ER

PT J
AU Xu, J
   Park, SH
   Zhang, XQ
AF Xu, Jiawei
   Park, Seop Hyeong
   Zhang, Xiaoqin
TI Improvement of viewing experience on stereoscopic image guided by human
   stereo vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereo vision; Disparity gradient; Random dot stereograms (RDS);
   Stereoscopic image
ID DISPARITY GRADIENT; QUALITY
AB Recent 3D visual quality assessment methods still have difficulties in providing the best viewing experience from the viewer's perspective due to the ambiguous understanding of human stereo vision. One of the key reasons is that the disparity gradient, which affects human depth perception, is hard to control for the input stereo image pair. In this paper, we mathematically formulated the human disparity gradient and optimized the disparity gradients for each stereo image pair. Considering that the disparity gradient needs to be limited to a specific range to satisfy the human visual preference and comfortableness, we proposed a new quantitative definition of disparity gradient and trained the optimal disparity gradients were learned from the pilot study to enhance the viewing experience. Extensive subjective evaluations have demonstrated the competitiveness of this proposed method for the improvement of the viewing experience.
C1 [Xu, Jiawei] Newcastle Univ, Newcastle Upon Tyne NE4 5TG, Tyne & Wear, England.
   [Park, Seop Hyeong] Hallym Univ, Sch Software, Chunchon 200702, South Korea.
   [Zhang, Xiaoqin] Wenzhou Univ, Dept Comp Sci, Wenzhou 325035, Peoples R China.
C3 Newcastle University - UK; Hallym University; Wenzhou University
RP Zhang, XQ (corresponding author), Wenzhou Univ, Dept Comp Sci, Wenzhou 325035, Peoples R China.
EM jxulincoln@gmail.com; spark@hallym.ac.kr; zhangxiaoqinnan@gmail.com
CR [Anonymous], STEREO PHOTOMAKER
   [Anonymous], 11 INT C CONTR AUT R
   [Anonymous], P INT WORKSH VID PRO
   [Anonymous], STEREOSCOPIC DISPLAY
   Bland JM, 1999, STAT METHODS MED RES, V8, P135, DOI 10.1177/096228029900800204
   BULTHOFF H, 1991, PERCEPTION, V20, P145, DOI 10.1068/p200145
   Cao X, 2011, IEEE T BROADCAST, V57, P491, DOI 10.1109/TBC.2011.2127650
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen MJ, 2013, IEEE T IMAGE PROCESS, V22, P3379, DOI 10.1109/TIP.2013.2267393
   Filippini HR, 2009, J VISION, V9, DOI 10.1167/9.1.8
   Howard I.P., 2012, Perceiving in Depth, DOI DOI 10.1093/ACPROF:OSO/9780199764150.001.0001
   Huang WC, 2015, IEEE T IMAGE PROCESS, V24, P724, DOI 10.1109/TIP.2014.2385474
   Jung CK, 2015, DISPLAYS, V40, P17, DOI 10.1016/j.displa.2015.05.006
   Kane D, 2014, J NEUROSCI, V34, P1397, DOI 10.1523/JNEUROSCI.1652-13.2014
   Lambooij M, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.030201
   Li ZY, 2012, INT CONF ACOUST SPEE, P1429, DOI 10.1109/ICASSP.2012.6288159
   McIntire JP, 2014, DISPLAYS, V35, P18, DOI 10.1016/j.displa.2013.10.004
   McKee SP, 2002, VISION RES, V42, P1963, DOI 10.1016/S0042-6989(02)00073-1
   Moorthy AK, 2013, SIGNAL PROCESS-IMAGE, V28, P870, DOI 10.1016/j.image.2012.08.004
   Oh H, 2017, IEEE T IMAGE PROCESS, V26, P3789, DOI 10.1109/TIP.2017.2702383
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Seuntiens P., 2006, ACM T APPL PERCEPT, V3, P95
   Shibata T, 2011, J VISION, V11, DOI 10.1167/11.8.11
   Sun Z, 2012, 2012 INTERNATIONAL CONFERENCE ON WAVELET ACTIVE MEDIA TECHNOLOGY AND INFORMATION PROCESSING (LCWAMTIP), P173, DOI 10.1109/ICWAMTIP.2012.6413467
   TRIVEDI HP, 1985, PERCEPTION, V14, P685, DOI 10.1068/p140685
   Tsutsui KI, 2005, NEUROSCI RES, V51, P221, DOI 10.1016/j.neures.2004.11.006
   TYLER CW, 1975, VISION RES, V15, P583, DOI 10.1016/0042-6989(75)90306-5
   Urvoy M, 2013, ANN TELECOMMUN, V68, P641, DOI 10.1007/s12243-013-0394-3
   Wang J, 2012, SENSORS-BASEL, V12, P5872, DOI 10.3390/s120505872
   Ware C., 2020, INFORM VISUALIZATION
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
   Zhang ZL, 2001, VISION RES, V41, P2995, DOI 10.1016/S0042-6989(01)00179-1
NR 32
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4377
EP 4394
DI 10.1007/s11042-019-7195-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500009
DA 2024-07-18
ER

PT J
AU Zhang, XY
   Li, S
   Jing, XY
   Ma, F
   Zhu, C
AF Zhang, Xinyu
   Li, Sen
   Jing, Xiao-Yuan
   Ma, Fei
   Zhu, Chen
TI Unsupervised domain adaption for image-to-video person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised domain adaption; Image-to-video; Person re-identification;
   GAN; Deep learning
AB Recently, person re-identification technique has been successfully applied to many fields, such as suspect tracking and lost human location. As video always contains more valuable information, more and more researchers focus on video based person re-identification, especially in image-to-video person re-identification (IVPR). However, most of existing IVPR models are under the supervised framework. In fact, marking enough training samples will cost numbers of labors, which limits the practical value of them. At the same time, the 2D features extracted from pedestrian image and 3D features extracted from pedestrian video are heterogeneous, which brings significant challenge for IVPR task. To effective solve the above problems, we propose an unsupervised domain adaption image-to-video person re-identification model by cross-modal feature generating and target information preserving transfer network (CMGTN). On one hand, the designed generator in our model can not only transform target domain unlabeled sample features into source domain feature space, but also can preserve target identity information. On the other hand, we eliminate the gap between pedestrian images and videos by embedding a cross-modal loss term. To evaluate the performance of our approach, we conduct extensive experiments on PRID-2011, iLIDS-VID and MARS datasets, and compare our approach with existing state-of-the-art IVPR models including four unsupervised methods and three supervised methods. Experimental results demonstrate the effectiveness of our approach.
C1 [Zhang, Xinyu; Li, Sen; Jing, Xiao-Yuan; Ma, Fei; Zhu, Chen] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.
   [Jing, Xiao-Yuan] Guangdong Univ Petrochem Technol, Sch Comp, Maoming 525000, Peoples R China.
   [Jing, Xiao-Yuan] Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing 210003, Peoples R China.
C3 Wuhan University; Guangdong University of Petrochemical Technology;
   Nanjing University of Posts & Telecommunications
RP Jing, XY (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.; Jing, XY (corresponding author), Guangdong Univ Petrochem Technol, Sch Comp, Maoming 525000, Peoples R China.; Jing, XY (corresponding author), Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing 210003, Peoples R China.
EM zhangxinyu@whu.edu.cn; senli2018@163.com; jingxy_2000@126.com
RI Zhang, Yunxuan/IXD-9283-2023
OI zhang, xinyu/0000-0002-9109-1889
FU NSFC-Key Project [61933013]; NSFC-Key Project of General Technology
   Fundamental Research United Fund [U1736211]; Key Project of Natural
   Science Foundation of Hubei Province [2018CFA024]; Natural Science
   Foundation of Guangdong Province [2019A1515011076]
FX The authors would like to thank the editor, the associate editor, and
   anonymous reviewers for their constructive comments in helping improve
   our work. This work was supported by the NSFC-Key Project under Grant
   No. 61933013, the NSFC-Key Project of General Technology Fundamental
   Research United Fund under Grant No. U1736211, the Key Project of
   Natural Science Foundation of Hubei Province under Grant No. 2018CFA024,
   the Natural Science Foundation of Guangdong Province under Grant No.
   2019A1515011076.
CR [Anonymous], 2018, P BRIT MACH VIS C
   Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P1, DOI 10.1109/AVSS.2010.68
   Baltieri D., 2013, Proceedings of the 21st ACM International Conference on Multimedia, MM'13, P557
   Chen RL, 2009, ENDOCR RES CLIN DEV, P1
   Dai J, 2019, IEEE T IMAGE PROCESS, V28, P1366, DOI 10.1109/TIP.2018.2878505
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Huang WJ, 2018, AAAI CONF ARTIF INTE, P2273
   Jing Xiao-Yuan., 2019, IEEE transactions on pattern analysis and machine intelligence
   Kodirov E, 2016, LECT NOTES COMPUT SC, V9905, P178, DOI 10.1007/978-3-319-46448-0_11
   Li Y, 2020, WORLD WIDE WEB, V23, P799, DOI 10.1007/s11280-019-00725-6
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liong VE, 2017, IEEE T MULTIMEDIA, V19, P1234, DOI 10.1109/TMM.2016.2646180
   Lisanti G, 2019, IMAGE VISION COMPUT, V83-84, P29, DOI 10.1016/j.imavis.2019.02.009
   Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055
   Liu K, 2015, IEEE I CONF COMP VIS, P3810, DOI 10.1109/ICCV.2015.434
   Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI [10.1109/ICCVW.2017.361, 10.1109/ICCV.2017.478]
   Lv JM, 2018, PROC CVPR IEEE, P7948, DOI 10.1109/CVPR.2018.00829
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Taigman Y., 2016, INT C LEARN REPR
   TIAN J, 2019, ARXIV190405020
   Wang C, 2016, MULTIMED TOOLS APPL, V75, P9255, DOI 10.1007/s11042-016-3380-8
   Wang GC, 2018, IEEE T CIRC SYST VID, V28, P2777, DOI 10.1109/TCSVT.2017.2748698
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wu JL, 2019, IEEE INT CON MULTI, P886, DOI 10.1109/ICME.2019.00157
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966
   Ye M, 2017, IEEE I CONF COMP VIS, P5152, DOI 10.1109/ICCV.2017.550
   Ying Zhang, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P368, DOI 10.1109/ICIG.2011.40
   Yu BZ, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.1.013052
   Yu HX, 2017, IEEE I CONF COMP VIS, P994, DOI 10.1109/ICCV.2017.113
   Zhang DY, 2018, IEEE T CIRC SYST VID, V28, P2622, DOI 10.1109/TCSVT.2017.2723429
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2017, P IEEE C COMP VIS PA, P3346, DOI DOI 10.1109/CVPR.2017.357
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhou Z, 2017, PROC CVPR IEEE, P6776, DOI 10.1109/CVPR.2017.717
   Zhu XK, 2018, IEEE T INF FOREN SEC, V13, P717, DOI 10.1109/TIFS.2017.2765524
   Zhu XY, 2016, IEEE T MAGN, V52, DOI 10.1109/TMAG.2016.2519465
NR 43
TC 12
Z9 15
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33793
EP 33810
DI 10.1007/s11042-019-08550-9
EA JAN 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000507701400002
DA 2024-07-18
ER

PT J
AU Ayadi, LA
   Loukil, H
   Ben Ayed, MA
   Masmoudi, N
AF Ayadi, Lella Aicha
   Loukil, Hassen
   Ben Ayed, Mohamed Ali
   Masmoudi, Nouri
TI Hardware-software implementation of HEVC decoder on Zynq
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; HW; SW co-design; Zynq SoC platform; Embedded linux
ID FRACTIONAL MOTION ESTIMATION; ARCHITECTURE; INTERPOLATION
AB This paper presents an efficient implementation of the High Efficiency Video Coding (HEVC) decoder using Hardware/Software (HW/SW) co-design approach on the Zynq System on Chip (SoC) Platform. The reference software decoder HM 10.0 has been implemented under embedded Linux Operating System (OS). For real-time decoding, we provide hardware acceleration for the most computationally intensive parts of the HEVC decoder, which are the interpolation filters. The proposed design improves the processing throughput targeting on the resolution of 3840 x 2160 at a frame rate of 60 fps. HW/SW validation is achieved and examined in terms of resource utilization, throughput and power consumption. In order to improve the total decoding time, we propose to enable the Direct Memory Access (DMA) mode that can help speed page access and minimize the transfer time between the processor and hardware accelerators.
C1 [Ayadi, Lella Aicha; Loukil, Hassen; Masmoudi, Nouri] Univ Sfax, Natl Sch Engn, Elect & Informat Technol Lab, Sfax 3038, Tunisia.
   [Ben Ayed, Mohamed Ali] Univ Sfax, Natl Sch Elect & Telecommun, New Technol & Telecommun Syst Res Unit, Sfax 3018, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Sfax
RP Ayadi, LA (corresponding author), Univ Sfax, Natl Sch Engn, Elect & Informat Technol Lab, Sfax 3038, Tunisia.
EM aicha.ayadi.aa@gmail.com
RI Loukil, Hassen/AAS-7443-2020; HASSEN, LOUKIL/HTO-1134-2023
OI Loukil, Hassen/0000-0002-2028-3517; HASSEN, LOUKIL/0000-0002-2028-3517
CR Afonso A, 2013, CHANG WELF STATE, P1
   [Anonymous], 2013, P 12 JCT VC M GEN
   Ayadi H, 2018, INT MULTICONF SYST, P1, DOI 10.1109/SSD.2018.8570489
   AYADI LA, 2016, INT REV COMPUTERS SO, V11, P764
   Ayadi LA, 2018, INT MULTICONF SYST, P842, DOI 10.1109/SSD.2018.8570668
   BELGHITH F, 2015, 2015 WORLD C INF TEC, P1
   BROSS B, 2013, HIGH EFFICIENCY VIDE, V10, P1003
   Crockett L.H., 2014, ZYNQ BOOK EMBEDDED P
   Diniz CM, 2015, IEEE T COMPUT AID D, V34, P238, DOI 10.1109/TCAD.2014.2384517
   Diniz CM, 2013, IEEE IMAGE PROC, P2091, DOI 10.1109/ICIP.2013.6738431
   Guo ZY, 2012, INT CONF ACOUST SPEE, P1117, DOI 10.1109/ICASSP.2012.6288083
   He G, 2015, IEEE T VLSI SYST, V23, P3138, DOI 10.1109/TVLSI.2014.2386897
   He G, 2013, IEEE ASIAN SOLID STA, P301, DOI 10.1109/ASSCC.2013.6691042
   Huang CS, 2013, 2013 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE, COGNITIVE ALGORITHMS, MIND, AND BRAIN (CCMB), P1, DOI [10.1109/CCMB.2013.6609157, 10.1109/PLASMA.2013.6634859]
   Kalali E, 2014, IEEE IMAGE PROC, P1218, DOI 10.1109/ICIP.2014.7025243
   Kalali E, 2013, 2013 IEEE THIRD INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS - BERLIN (ICCE-BERLIN), DOI 10.1109/ICCE-Berlin.2013.6698023
   김선철, 2013, Journal of Information and Communication Convergence Engineering, V11, P118, DOI 10.6109/jicce.2013.11.2.118
   Lian XC, 2014, 2014 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (CHINASIP), P384, DOI 10.1109/ChinaSIP.2014.6889269
   Pastuszak G, 2013, 16TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2013), P423, DOI 10.1109/DSD.2013.53
   Pastuszak G, 2016, J REAL-TIME IMAGE PR, V12, P517, DOI 10.1007/s11554-015-0516-4
   Pham CDK, 2019, IEEE ACCESS, V7, P112535, DOI 10.1109/ACCESS.2019.2935378
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Ugur K, 2013, IEEE J-STSP, V7, P946, DOI 10.1109/JSTSP.2013.2272771
   *XIL, 2015, TECHN REF MAN
   Xilinx, 2014, ZYNQ 7000 ALL PROGR
   Yan N, 2019, IEEE T CIRC SYST VID, V29, P840, DOI 10.1109/TCSVT.2018.2816932
   Zhang H, 2019, IEEE IMAGE PROC, P709, DOI [10.1109/icip.2019.8804199, 10.1109/ICIP.2019.8804199]
   Zhou W, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0284-0
   2018, DEVICE DRIVERS USER
NR 29
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7685
EP 7703
DI 10.1007/s11042-019-08548-3
EA JAN 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000505356600014
DA 2024-07-18
ER

PT J
AU Al-Nofaie, SMA
   Gutub, AAA
AF Al-Nofaie, Safia Meteb Awad
   Gutub, Adnan Abdul-Aziz
TI Utilizing pseudo-spaces to improve Arabic text steganography for
   multimedia data communications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information security; Arabic text; Kashida steganography; Pseudo-spaces
   utilization; Text hiding; Data security
ID ALGORITHM; LINE
AB Steganography is used for multimedia data security. It is a process of hiding the data within multimedia communication between the parties embedding the secret data inside a carrier file to be protected during its transmission. The research focus is on hiding within Arabic text steganography as a current challenging research area. The work innovation is utilizing text pseudo-spaces characters for data hiding. We present two studies for this text Steganography utilizing pseudo-spaces alone as well as combined with Kashida (extension character) as the old Arabic text stego techniques. Experimental results have shown that the proposed algorithms achieved high capacity and security ratio as compared to state-of-the-art Steganography methods presented for Arabic language. The proposed pseudo-spaces stego technique is of great benefit that can be further used for languages similar to Arabic such as Urdu and Persian as well as opening direction of text-stego research for other languages of the world.
C1 [Al-Nofaie, Safia Meteb Awad; Gutub, Adnan Abdul-Aziz] Umm Al Qura Univ, Dept Comp Engn, Mecca, Saudi Arabia.
C3 Umm Al Qura University
RP Gutub, AAA (corresponding author), Umm Al Qura Univ, Dept Comp Engn, Mecca, Saudi Arabia.
EM aagutub@uqu.edu.sa
RI Gutub, Adnan Abdul-Aziz/O-1240-2016
OI Gutub, Adnan Abdul-Aziz/0000-0003-0923-202X
FU Umm Al-Qura University (UQU)
FX Thanks to Umm Al-Qura University (UQU) for supporting this work. We
   thank the College of Computers and Information Systems for helping us
   work this contribution through its master graduate program. Many thanks
   for the fruitful graduate course offering by Computer Engineering
   Department (via Prof. Adnan Gutub) for supervising this work.
CR Aabed MA, 2007, ICSPC: 2007 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATIONS, VOLS 1-3, PROCEEDINGS, P756
   Abdallah EE, 2007, LECT NOTES COMPUT SC, V4633, P772
   Abdallah EE, 2010, SIGNAL IMAGE VIDEO P, V4, P233, DOI 10.1007/s11760-009-0114-7
   Adnan G., 2010, Bahria University Journal of Information Communication Technology, V3, P68
   Al-Haidari F, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P396, DOI 10.1109/AICCSA.2009.5069355
   Al-Nazer A, 2009, NSS: 2009 3RD INTERNATIONAL CONFERENCE ON NETWORK AND SYSTEM SECURITY, P447, DOI 10.1109/NSS.2009.21
   Al-Nofaie S., 2016, J COMPUTER SCI COMPU, V6, P59, DOI [10.20967/jcscm.2016.03.004, DOI 10.20967/jcscm.2016.03.004]
   Alassaf N, 2019, MULTIMED TOOLS APPL, V78, P32633, DOI 10.1007/s11042-018-6801-z
   Alattar AM, 2004, P SOC PHOTO-OPT INS, V5306, P685, DOI 10.1117/12.527147
   Alginahi YM, 2013, 2013 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMPUTER AND COMPUTATION (ICECCO), P301, DOI 10.1109/ICECCO.2013.6718288
   Alotaibi RA, 2018, J KING SAUD UNIV-COM, V30, P236, DOI 10.1016/j.jksuci.2016.12.007
   Alotaibi RA, 2016, UKSIM INT CONF COMP, P111, DOI 10.1109/UKSim.2016.34
   [Anonymous], 2004, LINGUISTIC STEGANOGR
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Bensaad ML, 2013, ARAB J SCI ENG, V38, P2035, DOI 10.1007/s13369-013-0576-3
   Gupta B.B., 2018, COMPUTER CYBER SECUR, P666
   Gutub A., 2007, WASET INT C COMP INF
   Gutub A., 2008, WoSPA 2008 - 5th IEEE International Workshop on Signal Processing and its Applications, P18
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P48, DOI 10.4304/jetwi.2.1.48-55
   Gutub A. A. A., 2007, INT J COMPUT ELECT A, V1, P502, DOI DOI 10.5281/ZENODO.1061621
   Gutub A, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0216-0
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Gutub AA, 2010, KUWAIT J SCI ENG, V37, P89
   Gutub AAA, 2021, J KING SAUD UNIV-COM, V33, P1108, DOI 10.1016/j.jksuci.2019.06.014
   Gutub AAA, 2010, ISECURE-ISC INT J IN, V2, P107
   Hahn Eun-Joo, 2003, Journal of Plant Biotechnology, V5, P1
   Hitesh S., 2009, P 3 NATL C, P332
   Khan EA, 2014, ASIAN J COMPUT SCI I, V6, P55
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   LOW SH, 1995, IEEE INFOCOM SER, P853, DOI 10.1109/INFCOM.1995.515956
   Memon M., 2011, Pakistan Journal of Engineering Technology Science (PJETS), V1, P106
   Memos VA, 2018, FUTURE GENER COMP SY, V83, P619, DOI 10.1016/j.future.2017.04.039
   Mersal S., 2014, INT J COMPUT INF TEC, V3, P764
   Microsoft, 2017, INTR C LANG NET FRAM
   NIIMI M, 2003, PAC RIM WORKSH DIG S
   Odeh A., 2012, 25 INT C COMP APPL I, P483
   Odeh A., 2012, Systems, Applications and Technology Conference (LISAT), 2012 IEEE Long Island, Farmingdale State College - State University of New York, P1, DOI DOI 10.1109/LISAT.2012.6223209
   Odeh A., 2012, INT J COMPUT SCI INF, V4, P1, DOI [10.5121/ijcsit.2012.4301, DOI 10.5121/IJCSIT.2012.4301]
   Petty T., 2016, Handbook of Research on Professional Development for Quality Teaching and Learning
   Popa R., 1998, ANAL STEGANOGRAPHIC
   Por L. Y., 2008, WSEAS Transactions on Computers, V7, P735
   Roslan Nuur Alifah, 2011, Journal of Theoretical and Applied Information Technology, V33, P32
   Shirali-Shahreza M., 2008, Journal of Applied Sciences, V8, P4173, DOI 10.3923/jas.2008.4173.4179
   Shirali-Shahreza Mohammad, 2008, 2008 IEEE Joint 6th National Conference on Telecommunication Technologies & 2nd Malaysia Conference on Photonics, P372, DOI 10.1109/NCTT.2008.4814305
   Shirali-Shahreza M, 2006, 2006 INNOVATIONS IN INFORMATION TECHNOLOGY, P310
   Shirali-Shahreza M, 2008, ADVANCES IN COMPUTER AND INFORMATIOM SCIENCES AND ENGINEERING, P339, DOI 10.1007/978-1-4020-8741-7_61
   SHIRALISHAHREZA.MH, 2007, P 3 IEEE IFIP INT C
   Topkara U., 2006, P 8 WORKSHOP MULTIME, P164, DOI DOI 10.1145/1161366.1161397
   Xiang LY, 2018, MULTIMED TOOLS APPL, V77, P28969, DOI 10.1007/s11042-018-6072-8
NR 50
TC 20
Z9 20
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 19
EP 67
DI 10.1007/s11042-019-08025-x
PG 49
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600003
DA 2024-07-18
ER

PT J
AU Chopra, A
   Gupta, S
   Dhall, S
AF Chopra, Anshul
   Gupta, Shailender
   Dhall, Sangeeta
TI Analysis of frequency domain watermarking techniques in presence of
   geometric and simple attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Geometric attack analysis; Simple attack analysis
ID TRANSFORM
AB Protection of manuscript accessible online is always an apprehension for researchers. Many ideas had come up for copyright protection and authentication of such documents. One of the admired keys to provide safety to the owner's data is digital watermarking. It is the process of hiding the secret message (text, audio, image, logo, signature) into the document for providing authentication. A watermarking mechanism is said to be effectual if it offers high imperceptibility, robustness against attacks, security and last but not the least has the high correlation value of extracted watermark with the original one. Numerous survey papers are available in literature taking only a few techniques or parameters into account, but this paper takes almost all frequency domain (standalone and hybrid) methods in absence and presence of geometric and simple attacks and does an exhaustive analysis on the same. MATLAB software is used for implementation. Results illustrate the superlative technique under the influence of simple attacks is DWT-FFT, and under geometric attacks DWT-SVD is preeminent.
C1 [Chopra, Anshul; Gupta, Shailender; Dhall, Sangeeta] JC Bose Univ Sci & Technol, Dept Elect Engn, YMCA, Faridabad, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Chopra, A (corresponding author), JC Bose Univ Sci & Technol, Dept Elect Engn, YMCA, Faridabad, India.
EM Chopraanshul80@gmail.com; Shailender81@gmail.com;
   Sangeeta_dhall@yahoo.co.in
RI gupta, shailender/Y-8231-2019
OI gupta, shailender/0000-0003-1383-7152
CR Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Al-Afandy KA, 2018, MULTIMED TOOLS APPL, V77, P25709, DOI 10.1007/s11042-018-5814-y
   Al-Ataby A, 2010, INT ARAB J INF TECHN, V7, P358
   [Anonymous], INT J EMERG TECHNOL
   [Anonymous], J INF HIDING MULTIME
   [Anonymous], 2013, GLOBAL J COMP SCI TE
   [Anonymous], 2016, INT J COMPUT SCI MOB
   Arya H, 2016, INT J ENG TECHNOL SC, V3, P240
   Asikuzzaman M, 2018, IEEE T CIRC SYST VID, V28, P2131, DOI 10.1109/TCSVT.2017.2712162
   Assini I, 2017, 3 INT C ADV TECHN SI
   Bhaskar T., 2015, INT RES J ENG TECHNO, V2, P738
   Chaudhari MM, 2015, INT J INNOVATIVE RES, V4, P12064
   Dar SB, 2014, INT J ENG COMPUT SCI, V3, P9215
   Dhall Sangeeta, 2016, International Journal of Computer Network and Information Security, V8, P67, DOI 10.5815/ijcnis.2016.06.08
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Favorskaya M, 2015, SMART INNOV SYST TEC, V40, P203, DOI 10.1007/978-3-319-19830-9_19
   Fazlali HR, 2017, MULTIMED TOOLS APPL, V76, P23459
   Guru J., 2014, International Journal of Computer Science Trends and Technology (IJCST) vol, V5, P8
   Hallur SR., 2015, INT J CURR ENG TECHN, V5, P2722
   Hemani, 2017, INT J ENG TRENDS TEC, V46, P128
   Irfan M., 2013, RES J APPL SCI ENG T, V6, P1911
   Islam Md Saiful, 2014, International Journal of Computer and Communication Engineering, V3, P356, DOI 10.7763/IJCCE.2014.V3.349
   J Abraham, 2016, INT J SIGNAL PROCESS, V9, P137
   Jain P, 2018, PROCEDIA COMPUT SCI, V125, P179, DOI 10.1016/j.procs.2017.12.025
   Jain Reema, 2015, INT J COMPUTER APPL, V124, P35, DOI [10.5120/ijca2015905808, DOI 10.5120/IJCA2015905808]
   Jane O, 2014, J APPL RES TECHNOL, V12, P750, DOI 10.1016/S1665-6423(14)70091-4
   Jangde K, 2014, INT J SCI ENG TECHNO, V3, P394
   Katharotiya Anilkumar., 2011, J INFORM ENG APPL, V1, P9
   Kullayamma, 2016, INT J ADV RES COMPUT, V5, P451
   Kumar GD, 2017, PROCEDIA COMPUT SCI, V115, P423, DOI 10.1016/j.procs.2017.09.101
   kumar M, 2011, INDIAN J COMPUT SCI, V2, P31
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Loukhaoukha K., 2015, INT J APPL MATH INFO, V9, P1159, DOI [10.12785/amis/090307, DOI 10.12785/AMIS/090307]
   Manikandaprabu S, 2014, INT J COMPUTER SCI E, V6, P211
   Media K, 2018, ONLINE COPYRIGHT INF
   Nageswara RT, 2008, Computer Sciences and Telecommunications, P35
   ORuanaidh JJK, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P239, DOI 10.1109/ICIP.1996.560428
   Pambi M, 2016, INT J INNOVATIVE ENG, V5, P169
   Pareek S, 2014, HYBRID WATERMARKING, V1, P189
   Parvathavarthini S., 2014, INT J ADV INF TECHNO, V4, P1, DOI [10.5121/ijait.2014.4201, DOI 10.5121/IJAIT.2014.4201]
   Patel MB, 2015, INT J SCI RES DEV, V3, P1060
   Pradhan A., 2016, INDIAN J SCI TECHNOL, V9, P1, DOI [10.17485/ijst/2016/v9i37/88557, DOI 10.17485/ijst/2016/v9i37/88557]
   Pradhan A, 2016, IEEE INT C RES ADV I, P1, DOI 10.1109/RAINS.2016.7764399
   PRAMANIK M, 2014, IJETAE, V4, P174
   Reddy V. Lokeswara, 2011, International Journal of Advanced Networking and Applications, V2, P868
   Sahu A. K., 2017, Int. J. Commun. Antenna Propag, V7, P162, DOI 10.15866/irecap.v7i2.11675
   Sahu AK, 2018, INTERNETWORKING INDO, V10, P17
   Sahu AK, 2018, CYBERN INF TECHNOL, V18, P69, DOI 10.2478/cait-2018-0006
   Saiyyad MAM, 2014, IEEE GLOB CONF WIREL, P254, DOI 10.1109/GCWCN.2014.7030889
   Sangeetha P, 2014, IJAICT, V1, P149
   Senthilkumaran N., 2016, ADV COMPUT INT J ACI, V7, P9
   Singh P. J., 2013, ISRN BIOMATER, P1
   Snehlata Maloo NL, 2017, INFORM COMMUN TECHNO, V1, P509
   Sreenivas K, 2018, INT J MACH LEARN CYB, V9, P1193, DOI 10.1007/s13042-017-0641-4
   Sun Q, 2016, J SUPERCOMPUT, V72, P189
   Swain G, 2016, PROCEDIA COMPUT SCI, V85, P31, DOI 10.1016/j.procs.2016.05.173
   Tejal Rao D, 2017, INT J RES APPL SCI E, V5, P1756
   Tiwari N, 2017, INDIAN J SCI TECHNOL, V10, DOI [10.17485/ijst/2017/v10i3/110624, DOI 10.17485/ijst/2017/v10i3/110624]
   Tyagi S, 2016, INT C EM TRENDS EL E, P380
   Vijay Bendalam, 2015, INT J RES APPL SCI E, V3, P570
   Viraktamath SV, 2011, INT J FUTUR GENER CO, V4, P107
   Waliia E., 2010, GLOBAL J COMPUTER SC, V10, P4
   Yadav K, 2013, INT J ENG TRENDS TEC, V4, P3123
   Yadav M, 2017, INT J ENERG OPTIM EN, V6, P86, DOI 10.4018/IJEOE.2017010105
NR 64
TC 6
Z9 6
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 501
EP 554
DI 10.1007/s11042-019-08087-x
PG 54
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600021
DA 2024-07-18
ER

PT J
AU Wu, XS
   Sun, JD
AF Wu, Xiaosheng
   Sun, Junding
TI Face recognition based on multi-scale local directional value
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Local directional value; Multi-scale; LDP-based
   methods
ID TEXTURE CLASSIFICATION; BINARY PATTERNS
AB This paper presents a simple, yet robust scheme to improve the LDP-based methods in face recognition. Firstly, a generalized operator, called local directional value (LDV), is introduced to reduce the influence of local gray variations on the traditional LDP-based operators. Then, the multi-scale scheme is presented, which extends the local structure of the traditional LDP-based descriptors from 3 x 3 neighborhoods to multi-scale circular neighborhoods. The new scheme is also robust to noise and the gray variations. The proposed scheme is evaluated with the state-of-the-art methods on popular benchmark face databases and the experimental results show that the given method performs better than the traditional techniques.
C1 [Wu, Xiaosheng; Sun, Junding] Henan Polytech Univ, Sch Comp Sci & Technol, Shiji St, Jiaozuo 454000, Henan, Peoples R China.
C3 Henan Polytechnic University
RP Sun, JD (corresponding author), Henan Polytech Univ, Sch Comp Sci & Technol, Shiji St, Jiaozuo 454000, Henan, Peoples R China.
EM sunjd@hpu.edu.cn
CR Abdel-Nasser M, 2015, EXPERT SYST APPL, V42, P9499, DOI 10.1016/j.eswa.2015.07.072
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], IEEE INT C AC SPEECH
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   Faraji MR, 2016, NEUROCOMPUTING, V199, P16, DOI 10.1016/j.neucom.2016.01.094
   Faraji MR, 2015, IET BIOMETRICS, V4, P10, DOI 10.1049/iet-bmt.2014.0033
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Huang DS, 2008, PATTERN RECOGN, V41, P1316, DOI 10.1016/j.patcog.2007.08.016
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Huang XH, 2013, LECT NOTES COMPUT SC, V7944, P1
   Jabid T, 2010, IEEE ICCE
   Jabid T, 2010, ETRI J, V32, P784, DOI 10.4218/etrij.10.1510.0132
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu L, 2014, IEEE T IMAGE PROCESS, V23, P3071, DOI 10.1109/TIP.2014.2325777
   Liu L, 2016, INFORM SCIENCES, V358, P56, DOI 10.1016/j.ins.2016.04.021
   Liu LN, 2019, IMMUNOL INVEST, V48, P107, DOI 10.1080/08820139.2018.1510957
   Liu WW, 2019, IEEE T PATTERN ANAL, V41, P408, DOI 10.1109/TPAMI.2018.2794976
   Liu XZ, 2009, IEEE SIGNAL PROC LET, V16, P1019, DOI 10.1109/LSP.2009.2027636
   Luo YT, 2016, PATTERN RECOGN, V50, P26, DOI 10.1016/j.patcog.2015.08.025
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ou WH, 2014, PATTERN RECOGN, V47, P1559, DOI 10.1016/j.patcog.2013.10.017
   Pan ZB, 2019, EXPERT SYST APPL, V120, P319, DOI 10.1016/j.eswa.2018.11.041
   Pan ZB, 2015, IEEE T IMAGE PROCESS, V24, P5379, DOI 10.1109/TIP.2015.2476955
   Patel VM, 2011, APPL OPTICS, V50, P1425, DOI 10.1364/AO.50.001425
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Rivera AR, 2015, PATTERN RECOGN LETT, V51, P94, DOI 10.1016/j.patrec.2014.08.012
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tolba A. S., 2006, INT J SIGNAL PROCESS, V2, P88
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   ul Hussain S, 2012, LECT NOTES COMPUT SC, V7573, P716, DOI 10.1007/978-3-642-33709-3_51
   Wu XS, 2017, VISUAL COMPUT, V33, P317, DOI 10.1007/s00371-015-1202-z
   Wu XS, 2015, SENSORS-BASEL, V15, P6399, DOI 10.3390/s150306399
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yu YF, 2017, PATTERN RECOGN, V66, P302, DOI 10.1016/j.patcog.2017.01.021
   Zhang LF, 2019, INFORM SCIENCES, V485, P154, DOI 10.1016/j.ins.2019.02.008
   Zhang YD, 2018, J COMPUT SCI-NETH, V28, P1, DOI 10.1016/j.jocs.2018.07.003
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhong FJ, 2013, NEUROCOMPUTING, V119, P375, DOI 10.1016/j.neucom.2013.03.020
NR 40
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2409
EP 2425
DI 10.1007/s11042-019-08245-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000515433000030
DA 2024-07-18
ER

PT J
AU Li, N
   Bi, HB
   Guan, HP
   Li, YL
AF Li, Ning
   Bi, Hongbo
   Guan, Huaping
   Li, Yulong
TI Optimization algorithm on salient detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient detection; Line sketch; Contour; Optimized algorithm
ID IMAGE
AB Current studies on salient detection have combined salient cues, such as contrast, prior information, and object edges, which work by segmenting the foreground from the background. However, existing models mostly lose tiny salient regions in scenes and fail to detect all salient regions. In this paper, we propose an optimization algorithm on salient detection based on line sketch. First, we generate the line sketches of images, which include all edges of the salient objects. Second, the detected line sketches are blended into the original images in soft light mode. Then, the sketch works as a mask to highlight the outlines. Finally, the processed images are used in the existing salient detection models. Our contribution is that the salient detection with the sketches extracting image outline can effectively improve the accuracy. Results prove that the proposed algorithm is efficient and improves the performance of models.
C1 [Li, Ning; Bi, Hongbo] Northeast Petr Univ, Sch Elect & Informat Engn, Daqing 163000, Peoples R China.
   [Guan, Huaping] Sch Fujian Normal Univ, Sch Publ Adm, Fuzhou 350117, Fujian, Peoples R China.
   [Li, Yulong] XJ Elect CO LTD, Xuchang 461000, Peoples R China.
C3 Northeast Petroleum University
RP Bi, HB (corresponding author), Northeast Petr Univ, Sch Elect & Informat Engn, Daqing 163000, Peoples R China.
EM bhbdq@126.com
OI Bi, Hongbo/0000-0003-2442-330X
FU NEPU Natural Science Foundation [2017PY ZL - 05, JY CX_CX06_2018, JY
   CX_JG06_2018]
FX This work is supported by the NEPU Natural Science Foundation under
   Grant No. 2017PY ZL - 05, JY CX_CX06_2018 and JY CX_JG06_2018.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2012, P AS C COMP VIS
   [Anonymous], 2002, P 10 ACM INT C MULT
   [Anonymous], 2012, SALIENT OBJECT DETEC
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Borji A., 2011, INT C ROB AUT
   Borji A., 2012, 2012 IEEE COMPUTER S, P23, DOI 10.1109/CVPRW.2012.6239191
   Borji Ali, 2019, [Computational Visual Media, 计算可视媒体], V5, P117
   Borji A, 2011, MACH VISION APPL, V22, P61, DOI 10.1007/s00138-009-0192-0
   Bousseau A., 2006, P NPAR, P141, DOI [DOI 10.1145/1124728.1124751, 10.1145/1124728.1124751]
   Chansri N, 2012, INT J ADV MANUF TECH, V59, P221, DOI 10.1007/s00170-011-3487-z
   Chen T., 2009, SKETCH2PHOTO INTERNE, P1
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Cui CR, 2019, IEEE T MULTIMEDIA, V21, P1209, DOI 10.1109/TMM.2018.2875357
   Fan D.-P., 2018, EUROPEAN CONFERENCE
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fan Deng-Ping, 2018, FACE SKETCH SYNTHESI
   Frintrop S, 2014, INT C PATT RECOG, P2329, DOI 10.1109/ICPR.2014.404
   Garcia German Martin, 2012, Pattern Recognition. Proceedings Joint 34th DAGM and 36th OAGM Symposium, P357, DOI 10.1007/978-3-642-32717-9_36
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Kanan C, 2010, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2010.5539947
   Klein D. A., 2010, INT ROB SYST IROS 20, P772
   Ko BC, 2006, J OPT SOC AM A, V23, P2462, DOI 10.1364/JOSAA.23.002462
   Lei JJ, 2016, IEEE T MULTIMEDIA, V18, P1783, DOI 10.1109/TMM.2016.2592325
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Lu Cewu., 2012, Proc. NPAR, P65
   Ma YF, 2002, IEEE IMAGE PROC, P129
   Moosmann F., 2006, INT WORKSH REPR US P
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Ren ZX, 2014, IEEE T CIRC SYST VID, V24, P769, DOI 10.1109/TCSVT.2013.2280096
   Rutishauser U., 2004, P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.2004.1315142
   Shen H, 2013, CHINESE J AERONAUT, V26, P1211, DOI 10.1016/j.cja.2013.07.038
   Tang XO, 2004, IEEE T CIRC SYST VID, V14, P50, DOI 10.1109/TCSVT.2003.818353
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Uhl RG, 1996, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.1996.517132
   Wang J., 2000, SOLVING MULTIPLE INS
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zeng K, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640445
   Zhu JY, 2012, PROC CVPR IEEE, P3218, DOI 10.1109/CVPR.2012.6248057
NR 42
TC 1
Z9 1
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6437
EP 6445
DI 10.1007/s11042-019-08381-8
EA DEC 2019
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000502584400003
DA 2024-07-18
ER

PT J
AU Arora, SV
   Vig, R
AF Arora, Sanghamitra V.
   Vig, Rekha
TI An efficient text-independent speaker verification for short utterance
   data from Mobile devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crow search algorithm; Deep hidden markov model; Feature extraction;
   Speaker verification; Utterance partitioning
ID I-VECTOR; SPEECH; RECOGNITION; ADAPTATION; FEATURES; NETWORK
AB Speaker verification is the process used to recognize a speaker from his/her voice characteristics by extracting the features. Speaker verification with text-independent data is a process of verifying the speaker identity without limitation in the speech content. In the speaker verification process, long utterances are normally used but it contains lot of silences leading to complexity and more disruptions. So, we are performing speaker verification method based on short utterance data. The main objective of the research work is to extract, characterize, and recognize the information about speaker identity. Our proposed work contains four stages: 1) utterance partitioning, 2) feature extraction, 3) feature selection, and 4) classification. In our proposed model, an utterance partitioning approach is used to shorten the full-length speech into numerous short-length utterances before the pre-processing stage. In the feature extraction phase, noise removal is carried out with pre-emphasis filter in the pre-processing step. The Mel Advanced Hilbert-Huang Cepstral Coefficients (MAHCC) technique is used for extracting the features from the given input speech signal. Furthermore, the feature selection process is done with the help of a Crow Search Algorithm (CSA) by ranking the given feature set to obtain optimal features for classification. In the classification stage, the Deep Hidden Markov Model (DHMM) method is introduced to classify the features for speaker verification with discriminative pre-training process. Thus, the proposed approach provides an accurate classification and the implementation results show that the performance of the proposed method is better than the existing methods.
C1 [Arora, Sanghamitra V.] DCE, Dept Elect & Commun Engn, Gurgaon, India.
   [Vig, Rekha] NCU, Dept Elect Elect & Commun Engn EECE, Gurgaon, India.
C3 The Northcap University
RP Arora, SV (corresponding author), DCE, Dept Elect & Commun Engn, Gurgaon, India.
EM sanghamitrav.arora@yahoo.com; rekhavig.009@yahoo.com
RI Vig, Rekha/AAQ-7296-2021; Vig, Rekha/KIB-5038-2024
OI Vig, Rekha/0000-0002-0789-8840
CR Al-Ali AKH, 2017, IEEE ACCESS, V5, P15400, DOI 10.1109/ACCESS.2017.2728801
   Chowdhury Md Fozur Rahman, 2010, 2010 10th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA 2010), P57, DOI 10.1109/ISSPA.2010.5605556
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Deng SG, 2017, IEEE T SYST MAN CY-S, V47, P555, DOI 10.1109/TSMC.2016.2521736
   FURUI S, 1986, IEEE T ACOUST SPEECH, V34, P52, DOI 10.1109/TASSP.1986.1164788
   FURUI S, 1981, IEEE T ACOUST SPEECH, V29, P342, DOI 10.1109/TASSP.1981.1163605
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Hori T, 2017, COMPUT SPEECH LANG, V46, P401, DOI 10.1016/j.csl.2017.01.013
   Khodabakhsh A, 2017, COMPUT SPEECH LANG, V42, P20, DOI 10.1016/j.csl.2016.08.004
   Kounoudes A, 2006, 2006 2 INT C INF COM, V1, P1020
   Krothapalli SR, 2013, INT J SPEECH TECHNOL, V16, P181, DOI 10.1007/s10772-012-9175-z
   Kua JMK, 2013, SPEECH COMMUN, V55, P707, DOI 10.1016/j.specom.2013.01.005
   Larcher A, 2014, SPEECH COMMUN, V60, P56, DOI 10.1016/j.specom.2014.03.001
   Li LF, 2013, INT CONF AFFECT, P312, DOI 10.1109/ACII.2013.58
   Liu ZL, 2018, IEEE T IND INFORM, V14, P3244, DOI 10.1109/TII.2018.2799928
   Ma JB, 2018, IEEE SIGNAL PROC LET, V25, P1775, DOI 10.1109/LSP.2018.2874814
   Misra A, 2018, IEEE-ACM T AUDIO SPE, V26, P1549, DOI 10.1109/TASLP.2018.2831460
   Narendra NP, 2019, SPEECH COMMUN, V106, P95, DOI 10.1016/j.specom.2018.12.002
   Ozaydin S, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTING TECHNOLOGIES AND APPLICATIONS (ICECTA), P55
   Rahulamathavan Y, 2019, IEEE-ACM T AUDIO SPE, V27, P496, DOI 10.1109/TASLP.2018.2882731
   Raitio T, 2014, COMPUT SPEECH LANG, V28, P648, DOI 10.1016/j.csl.2013.03.003
   Sarkar S, 2014, APPL SOFT COMPUT, V19, P198, DOI 10.1016/j.asoc.2014.02.016
   Shankar S, 2016, PROCEDIA COMPUT SCI, V89, P597, DOI 10.1016/j.procs.2016.06.020
   Shifani HJM, 2017, MULTIRATE SIGNAL PRO, V4, P1046
   Sigtia S, 2016, IEEE-ACM T AUDIO SPE, V24, P2096, DOI 10.1109/TASLP.2016.2592698
   SOONG FK, 1987, AT&T TECH J, V66, P14, DOI 10.1002/j.1538-7305.1987.tb00198.x
   Sreekumar KT, 2014, 2014 INTERNATIONAL CONFERENCE ON POWER SIGNALS CONTROL AND COMPUTATIONS (EPSCICON)
   Sun LH, 2019, SPEECH COMMUN, V106, P85, DOI 10.1016/j.specom.2018.11.008
   Tan ZL, 2018, IEEE-ACM T AUDIO SPE, V26, P700, DOI 10.1109/TASLP.2018.2791105
   Tan ZL, 2018, IEEE-ACM T AUDIO SPE, V26, P820, DOI 10.1109/TASLP.2018.2796843
   Yao Q, 2018, IEEE SIGNAL PROC LET, V25, P1670, DOI 10.1109/LSP.2018.2870726
   Yao SY, 2018, ELECTRON LETT, V54, P1302, DOI 10.1049/el.2018.6359
   Yu H., 2017, IEEE SYSTEMS J, P1
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Yun Lei, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1695, DOI 10.1109/ICASSP.2014.6853887
   Zhang CL, 2018, IEEE-ACM T AUDIO SPE, V26, P1633, DOI 10.1109/TASLP.2018.2831456
NR 39
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 3049
EP 3074
DI 10.1007/s11042-019-08196-7
EA DEC 2019
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000500863700004
DA 2024-07-18
ER

PT J
AU Carrion, B
   Onorati, T
   Diaz, P
   Triga, V
AF Carrion, Belen
   Onorati, Teresa
   Diaz, Paloma
   Triga, Vasiliki
TI A taxonomy generation tool for semantic visual analysis of large corpus
   of documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Knowledge modelling; Semantic visualization; Taxonomy development
   process; Big data
ID SOCIAL NETWORKS; CONTEXT
AB Taxonomies are semantic resources that help to categorize and add meaning to data. In a hyperconnected world where information is generated at a rate that exceeds human capacities to process and make sense of it, such semantic resources can help to access relevant information more efficiently by extracting knowledge from large and unstructured data sets. Taxonomies are related to specific domains of knowledge in which they identify relevant topics. However, they have to be validated by experts to guarantee that its terms and relations are meaningful. In this paper, we introduce a semiautomatic taxonomy generation tool for supporting domain experts in building taxonomies that are then used to automatically create semantic visualizations of data. Our proposal combines automatic techniques to extract, sort and categorize terms, and empowers domain experts to take part at any stage of the process by providing a visual edition tool. We tested the tool's usability in two use cases from different domains and languages. Results show that all the functionalities are easy to use and interact with. Lessons learned from this experience will guide the design of a utility evaluation involving domain experts interested in data analysis and knowledge modeling.
C1 [Carrion, Belen; Onorati, Teresa; Diaz, Paloma] Univ Carlos III Madrid, Dept Comp Sci, Leganes, Spain.
   [Triga, Vasiliki] Cyprus Univ Technol, Dept Commun & Internet Studies, Limassol, Cyprus.
C3 Universidad Carlos III de Madrid; Cyprus University of Technology
RP Onorati, T (corresponding author), Univ Carlos III Madrid, Dept Comp Sci, Leganes, Spain.
EM bcarrion@pa.uc3m.es; tonorati@inf.uc3m.es; pdp@inf.uc3m.es;
   vasiliki.triga@cut.ac.cy
RI ., TERESA ONORATI/AAA-7118-2019; Triga, Vasiliki/AAE-5861-2020; ONORATI,
   TERESA/AAO-2691-2020
OI ., TERESA ONORATI/0000-0002-3154-249X; Triga,
   Vasiliki/0000-0001-6932-5389; DIAZ PEREZ, MARIA
   PALOMA/0000-0002-9493-7739
FU Spanish Ministry of Economy and Competitivity [TIN2016-77690-R];
   European Union's Horizon 2020 Framework through NOTRE project
   (H2020-TWINN-2015) [692058]
FX This work was supported by the project PACE grant funded by the Spanish
   Ministry of Economy and Competitivity [TIN2016-77690-R]. Authors also
   acknowledge travel funding from the European Union's Horizon 2020
   Framework through NOTRE project (H2020-TWINN-2015, GA Number: 692058).
CR [Anonymous], 1992, COLING 1992, DOI DOI 10.3115/992133.992154
   [Anonymous], INF SYST CRIS RESP
   [Anonymous], 2004, P 4 INT C LANG RES E
   Bello-Orgaz G, 2016, INFORM FUSION, V28, P45, DOI 10.1016/j.inffus.2015.08.005
   Bendle N, 2018, PALGR STUD POLIT MAR, P65, DOI 10.1007/978-3-319-59345-6_5
   Biermann Chris., 2005, LDV Forum, P75
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Castells M., 1997, CITY, V7, P6, DOI DOI 10.1080/13604819708900050
   Centelles M, 2005, HIPERTEXT NET
   Dias G., 2000, P RECH INF ASS ORD, V2, P1473
   Díaz P, 2016, FUTURE INTERNET, V8, DOI 10.3390/fi8030041
   Dokoohaki N, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P1269, DOI 10.1145/2808797.2808915
   Feldman R, 1998, LECT NOTES ARTIF INT, V1510, P65
   Frakes WB., 1992, Information retrieval: Data structures and algorithms
   Gundecha Pritam., 2012, 2012 TUTORIALS OPERA, P1, DOI [10.1287/educ.1120.0105, DOI 10.1287/EDUC.1120.0105]
   Hoang HH, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/813875
   Jung JJ, 2010, J UNIVERS COMPUT SCI, V16, P2099
   Kerschberg L., 2001, WEB INFORM SYSTEMS E, V1, P41
   Kotlerman L, 2011, SUPPORT TOOL DERIVIN
   Lefever E., 2015, P 9 INT WORK SEM EV, P944
   Lewis JR, 2018, J USABILITY STUD, V13, P158
   Lindsay B.R., 2010, J CURRENT ISSUES MED, V2, P287
   Manning C., 2014, The stanford corenlp natural language processing toolkit
   McGregor SC, 2017, J INF TECHNOL POLITI, V14, P154, DOI 10.1080/19331681.2017.1308289
   Miller G.A., 1990, Int. J. Lexicogr, V3, P235, DOI [DOI 10.1093/IJL/3.4.235, 10.1093/ijl/3.4.235]
   Murthy K., 2010, P ACL 2010 C SHORT P, P126
   Navigli R, 2003, IEEE INTELL SYST, V18, P22, DOI 10.1109/MIS.2003.1179190
   Navigli R, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1318
   Onorati T, 2018, ADJUNCT PUBLICATION OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST'18 ADJUNCT), P176, DOI 10.1145/3266037.3271642
   Onorati T, 2019, FUTURE GENER COMP SY, V95, P829, DOI 10.1016/j.future.2018.01.052
   Onorati T, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3384-x
   Park YS, 2002, XI BIENNIAL MEETING OF THE SOCIETY FOR FREE RADICAL RESEARCH INTERNATIONAL, P1
   Ritter A., 2009, Proceedings of AAAI-09 Spring Symposium on Learning by Reading and Learning to Read, P88
   Sang ETK, 2011, THEOR APPL NAT LANG, P223
   Schutze Hinrich, 2008, P INT COMM ASS COMP, P260
   Sujatha R., 2011, INDIAN J COMPUTER SC, V3, P661
   Van de Kauter M., 2013, COMPUT LINGUIST, V3, P103
   Van Der Plas L, 2005, P ONTOLEX 2005 ONT L
   Velardi P, 2007, IEEE T KNOWL DATA EN, V19, P180, DOI 10.1109/TKDE.2007.21
   Vepsäläinen T, 2017, GOV INFORM Q, V34, P524, DOI 10.1016/j.giq.2017.05.004
   Wang W., 2006, P SIGCHI C HUM FACT, DOI 10.1371/journal.pcbi.1004226
   Wilks Y, 1993, PROVIDING MACHINE TR, P341
   Yang H, 2012, CONSTRUCTING TASK SP
   Zamir O., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P46, DOI 10.1145/290941.290956
   Zilli A, 2009, INFORM SCI REFERENCE
NR 45
TC 4
Z9 4
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 32919
EP 32937
DI 10.1007/s11042-019-07880-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600015
OA hybrid
DA 2024-07-18
ER

PT J
AU Garcia, AS
   Fernando, T
   Roberts, DJ
   Bar, C
   Cencetti, M
   Engelke, W
   Gerndt, A
AF Garcia, Arturo S.
   Fernando, Terrence
   Roberts, David J.
   Bar, Christian
   Cencetti, Michele
   Engelke, Wito
   Gerndt, Andreas
TI Collaborative virtual reality platform for visualizing space data and
   mission planning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed meetings; Design science research methodology; Collaborative
   virtual Environments; Telepresence; Space mission planning; Scientific
   data visualization
ID DESIGN SCIENCE; MARS; SELECTION
AB This paper presents the system architecture of a collaborative virtual environment in which distributed multidisciplinary teams involved in space exploration activities come together and explore areas of scientific interest of a planet for future missions. The aim is to reduce the current challenges of distributed scientific and engineering meetings that prevent the exploitation of their collaborative potential, as, at present, expertise, tools and datasets are fragmented. This paper investigates the functional characteristics of a software framework that addresses these challenges following the design science research methodology in the context of the space industry and research. An implementation of the proposed architecture and a validation process with end users, based on the execution of different use cases, are described. These use cases cover relevant aspects of real science analysis and operation, including planetary data visualization, as the system aims at being used in future European missions. This validation suggests that the system has the potential to enhance the way space scientists will conduct space science research in the future.
C1 [Garcia, Arturo S.; Fernando, Terrence] Univ Salford, Salford M5 4WT, Lancs, England.
   [Roberts, David J.] Univ Salford, Telepresence, Salford M5 4WT, Lancs, England.
   [Bar, Christian] Thales Alenia Space, Turin, Italy.
   [Cencetti, Michele] ALTEC Spa, Permanent Multipurpose Module Int Space Stn Progr, Turin, Italy.
   [Engelke, Wito] German Aerosp Ctr DLR, Virtual Real & Sci Visualizat Grp, Lilienthalpl 7, D-38108 Braunschweig, Germany.
   [Gerndt, Andreas] German Aerosp Ctr DLR, Dept Software Space Syst & Interact Visualizat, Lilienthalpl 7, D-38108 Braunschweig, Germany.
C3 University of Salford; University of Salford; Thales Group; Helmholtz
   Association; German Aerospace Centre (DLR); Helmholtz Association;
   German Aerospace Centre (DLR)
RP Garcia, AS (corresponding author), Univ Salford, Salford M5 4WT, Lancs, England.
EM artgarcia@gmail.com
RI Jimenez, Arturo S. Garcia/ABH-3849-2020; Gerndt, Andreas/AAO-2644-2021
OI Jimenez, Arturo S. Garcia/0000-0003-0671-324X; Gerndt,
   Andreas/0000-0002-0409-8573; Fernando, Terrence/0000-0001-5321-9071
FU European Union [607177]
FX The work presented in this publication has received funding from the
   European Union Seventh Framework Programme (FP7/2007-2013) under grant
   agreement no. 607177. We thank all partners in the CROSS DRIVE team for
   their contribution, recommendations, and evaluations of the depicted
   software framework.
CR [Anonymous], 2011, ISO/IEC TR 29110-5-1-2, DOI DOI 10.1109/IEEESTD.2011.6129467
   [Anonymous], TECH REP
   Arvidson R, 2008, J GEOPHYS RES-PLANET, V113, DOI 10.1029/2007JE003021
   Bassanino M, 2010, IEEE INT CONF INF VI, P585, DOI 10.1109/IV.2010.85
   Basso V, 2010, P C SYST CONC ENG SP
   Baur AW, 2017, INFORM SYST FRONT, V19, P231, DOI 10.1007/s10796-016-9681-7
   BENFORD S, 1993, PROCEEDINGS OF THE THIRD EUROPEAN CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK ( ECSCW 93 ), P109
   Bierbaum A, 2001, P IEEE VIRT REAL ANN, P89, DOI 10.1109/VR.2001.913774
   Bowers J., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P58, DOI 10.1145/238386.238404
   Clements P., 2003, SEI S SOFTW
   Fairchild AJ, 2017, IEEE T CIRC SYST VID, V27, P814, DOI 10.1109/TCSVT.2016.2580425
   Fernando T, 2013, DESIGNING NOVEL VIRT
   Fraser M., 2000, CVE 2000. Proceedings of the Third International Conference on Collaborative Virtual Environments, P29, DOI 10.1145/351006.351010
   Fuchs Henry., 1994, PROC 1 INT C MEDICAL, P161
   Garc ia AS, 2015, AEROSPACE I ELECT EL, V2015, DOI [10.1109/AERO.2015.7118994, DOI 10.1109/AERO.2015.7118994]
   Geyer W., 2001, GROUP'01. Proceedings of the 2001 International ACM SIGGROUP Conference on Supporting Group Work, P188, DOI 10.1145/500286.500315
   Golombek M, 2017, SPACE SCI REV, V211, P5, DOI 10.1007/s11214-016-0321-9
   Golombek M, 2012, SPACE SCI REV, V170, P641, DOI 10.1007/s11214-012-9916-y
   Górski KM, 2005, ASTROPHYS J, V622, P759, DOI 10.1086/427976
   Grant JA, 2011, PLANET SPACE SCI, V59, P1114, DOI 10.1016/j.pss.2010.06.016
   Grassi D, 2005, PLANET SPACE SCI, V53, P1017, DOI 10.1016/j.pss.2005.01.006
   Group TO, 2008, COLL OR ARCH
   Gwinner K, 2010, EARTH PLANET SC LETT, V294, P506, DOI 10.1016/j.epsl.2009.11.007
   Hevner AR, 2004, MIS QUART, V28, P75, DOI 10.2307/25148625
   Hofmeister C., 2000, APPL SOFTWARE ARCHIT
   Jaakkola H, 2011, FRONT ARTIF INTEL AP, V225, P97, DOI 10.3233/978-1-60750-690-4-97
   Kobayashi N, 2000, PROC SPIE, V4008, P1056, DOI 10.1117/12.395423
   KRUCHTEN PB, 1995, IEEE SOFTWARE, V12, P42, DOI 10.1109/52.469759
   Maher ML, 2006, P CAADRIA
   Martinez D, 2010, 2010 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2010), P17, DOI 10.1109/CW.2010.63
   MCEWEN AS, 2007, J GEOPHYS RES-PLANET, V112, DOI [DOI 10.1029/2005JE002605, 10.1029/2005JE002605]
   Méndez R, 2018, MULTIMED TOOLS APPL, V77, P18999, DOI 10.1007/s11042-017-5353-y
   Moerland E, 2016, 30 C INT COUNC AER S
   Neary L, 2011, MARS ATMOSPHERE MODE, P68
   Normand V, 1999, PRESENCE-TELEOP VIRT, V8, P218, DOI 10.1162/105474699566189
   Peffers K, 2007, J MANAGE INFORM SYST, V24, P45, DOI 10.2753/MIS0742-1222240302
   Roberts D, 2004, EIGHTH IEEE INTERNATIONAL SYMPOSIUM ON DISTRIBUTED SIMULATION AND REAL-TIME APPLICATIONS, PROCEEDINGS, P46, DOI 10.1109/DS-RT.2004.13
   Roberts DJ, 2015, IEEE J-STSP, V9, P562, DOI 10.1109/JSTSP.2015.2402635
   Russell DM, 2016, PROCEEDINGS OF THE 19TH ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING COMPANION, P201, DOI 10.1145/2818052.2893363
   Russo G, 2008, ACTA HORTIC, P301, DOI 10.17660/ActaHortic.2008.801.30
   Seu R, 2007, J GEOPHYS RES-PLANET, V112, DOI 10.1029/2006JE002745
   Shames P, 2006, AIAA 9 INT C SPAC OP
   Smith DE, 1999, SCIENCE, V284, P1495, DOI 10.1126/science.284.5419.1495
   Sommerville I., 2004, Software engineering, V7th, P784
   Stindt D, 2014, P INT C INF SYST
   Van Steen M., 2017, Distributed systems
   Vandaele A, 2006, ATMOSPHERIC SCI C, V628
   Wang XY, 2014, COMPUT IND, V65, P314, DOI 10.1016/j.compind.2013.11.012
   Westerteiger R, 2012, OASICS OPENACCESS SE, V27
   Zhu Jun, 2012, 2012 9th International Conference on Fuzzy Systems and Knowledge Discovery, P2541, DOI 10.1109/FSKD.2012.6234374
NR 50
TC 7
Z9 7
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33191
EP 33220
DI 10.1007/s11042-019-7736-8
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600027
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Muthuvel, K
   Anto, S
   Alexander, TJ
AF Muthuvel, K.
   Anto, S.
   Alexander, T. Jerry
TI GABC based neuro-fuzzy classifier with hybrid features for ECG Beat
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ECG; Neuro-fuzzy classifier; Artificial bee colony
ID HEARTBEAT CLASSIFICATION; DYNAMIC FEATURES
AB The main objective of the proposed methodology is to classify an ECG signal as normal or abnormal using the optimal neuro-fuzzy classifier. The proposed work consists of two phases namely, feature extraction and neuro-fuzzy classifier based classification. The beat signals are initially taken from the physio-bank ATM. Then, three types of features are extracted from each signal namely, Morphological-based features, Haar wavelet-based features, and Trispectrum based features. After feature extraction, the optimal neuro-fuzzy classifier is classifying the beat signal as normal or abnormal. Here, Artificial Bee Colony (ABC) algorithm is combined with Genetic Algorithm (GA) for training the neuro-fuzzy classifier. For experimental evaluation, the MIT-BIH Arrhythmia Database is utilized and the performances are analyzed in terms of accuracy, sensitivity, and specificity. The experimental results clearly demonstrated that the proposed technique outperformed by having better accuracy of 93% when compared existing technique achieved 84% only.
C1 [Muthuvel, K.] Noorul Islam Univ, Dept Elect & Elect Engn, Kumaracoil, India.
   [Anto, S.] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
   [Alexander, T. Jerry] Sathyabama Univ, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Sathyabama Institute
   of Science & Technology
RP Muthuvel, K (corresponding author), Noorul Islam Univ, Dept Elect & Elect Engn, Kumaracoil, India.
EM muthuvelk0577@gmail.com
RI Alexander, Jerry/A-4872-2017; K, Muthuvel/AAQ-3077-2020
OI Alexander, Jerry/0000-0002-8448-5740; K, Muthuvel/0000-0002-9343-2106
CR [Anonymous], P 2014 IEEE INT C BI
   [Anonymous], 2014, INT C COMPUTER COMMU
   Aramendi E, 2010, PHYSIOL MEAS, V31, P749, DOI 10.1088/0967-3334/31/6/002
   Bianchi D, 2014, HIPPOCAMPUS, V24, P165, DOI 10.1002/hipo.22212
   Carnevale L, 2017, LECT NOTES COMPUT SC, V10465, P229, DOI 10.1007/978-3-319-67262-5_17
   Chen SS, 2017, BIOMED SIGNAL PROCES, V31, P165, DOI 10.1016/j.bspc.2016.07.010
   Cuomo S, 2016, BIOMED SIGNAL PROCES, V27, P134, DOI 10.1016/j.bspc.2016.02.007
   Dong XD, 2017, NEUROCOMPUTING, V240, P1, DOI 10.1016/j.neucom.2017.02.056
   Fang RG, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2932707
   Feng ND, 2019, IEEE ACCESS, V7, P50431, DOI 10.1109/ACCESS.2019.2910880
   Geron A, 2017, HANDS ON MACHINE LEA
   Hanbay K, 2019, IET SIGNAL PROCESS, V13, P165, DOI 10.1049/iet-spr.2018.5103
   Huang HF, 2014, BIOMED ENG ONLINE, V13, DOI 10.1186/1475-925X-13-90
   Isafiade OE, 2016, ADV DATA MIN DATABAS, P1, DOI 10.4018/978-1-5225-0463-4
   Kanaujia M, 2015, NAT C REC ADV EL COM
   Lee JN, 2019, IEEE ACCESS, V7, P48392, DOI 10.1109/ACCESS.2019.2904095
   Llamedo M, 2012, IEEE T BIO-MED ENG, V59, P2312, DOI 10.1109/TBME.2012.2202662
   Llamedo M, 2011, IEEE T BIO-MED ENG, V58, P616, DOI 10.1109/TBME.2010.2068048
   Mar T, 2011, IEEE T BIO-MED ENG, V58, DOI 10.1109/TBME.2011.2113395
   Martis RJ, 2012, EXPERT SYST APPL, V39, P11792, DOI 10.1016/j.eswa.2012.04.072
   Melillo P, 2015, IEEE ENG MED BIO, P7740, DOI 10.1109/EMBC.2015.7320186
   Sannino G, 2018, FUTURE GENER COMP SY, V86, P446, DOI 10.1016/j.future.2018.03.057
   Sannino Giovanna, 2011, Proceedings of the 2011 4th International Conference on Developments in e-systems Engineering (DeSE 2011), P3, DOI 10.1109/DeSE.2011.67
   Shi HT, 2019, COMPUT METH PROG BIO, V171, P1, DOI 10.1016/j.cmpb.2019.02.005
   Shi HT, 2017, 2017 INTERNATIONAL CONFERENCE ON SENSING, DIAGNOSTICS, PROGNOSTICS, AND CONTROL (SDPC), P149, DOI 10.1109/SDPC.2017.37
   SILVA I, 2014, J OPEN RES SOFTW, V0002
   Sun JM, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P1524
   Tripathy RK, 2019, IEEE SENS J, V19, P4509, DOI 10.1109/JSEN.2019.2896308
   Ye C, 2012, IEEE T BIO-MED ENG, V59, P2930, DOI 10.1109/TBME.2012.2213253
   Zhu WL, 2019, IEEE ACM T COMPUT BI, V16, P131, DOI 10.1109/TCBB.2018.2846611
NR 30
TC 5
Z9 5
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35351
EP 35372
DI 10.1007/s11042-019-08132-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800050
DA 2024-07-18
ER

PT J
AU Huo, FC
   Sun, XT
   Ren, WJ
AF Huo, Fengcai
   Sun, Xueting
   Ren, Weijian
TI Multilevel image threshold segmentation using an improved Bloch quantum
   artificial bee colony algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bloch spherical; Quantum computation; IBQABC; Image multilevel threshold
   segmentation
ID PARTICLE SWARM OPTIMIZATION; GENETIC ALGORITHM; PRIORS; OTSU
AB Multilevel threshold segmentation is one of the most broadly used image segmentation methods. The key problem is how to obtain the optimal threshold as soon as possible. So a novel method based on the analysis of artificial bee colony algorithm, quantum Bloch sphere and Kapur's entropy is put forward, and it is applied to the multilevel thresholds of typical images efficiently. In the first place, in order to improve the performance of artificial bee colony (ABC) algorithm, the updating strategy is improved by combining the Bloch spherical coordinates of qubit with ABC algorithm. Then an improved Bloch quantum artificial bee colony (IBQABC) is proposed. There is one more point that IBQABC is applied to the optimization of multidimensional benchmark function, and it is proved that the algorithm has quick convergence speed compared with other algorithms. Finally, IBQABC combined with Kapur's entropy segments the benchmark gray images with different characteristics. After comparing the results of threshold segmentation of different images by using GA, PSO, ABC and IBQABC algorithms, it is verified that the IBQABC algorithm is superior to other conventional algorithms in the overall performance of gray image multilevel threshold segmentation, and it is determined that the improved algorithm has superior segmentation effect and strong generalization ability in gray image multilevel threshold segmentation.
C1 [Huo, Fengcai; Sun, Xueting; Ren, Weijian] Northeast Petr Univ, Sch Elect Informat Engn, Daqing, Peoples R China.
C3 Northeast Petroleum University
RP Sun, XT (corresponding author), Northeast Petr Univ, Sch Elect Informat Engn, Daqing, Peoples R China.
EM 401036190@qq.com
FU National Natural Science Foundation of China [61374127, 51404073];
   Outstanding Youth Science Foundation of National Natural Science
   Foundation of China [61422301]; Chinese Postdoctoral Science Foundation
   [2014 M550180]; Scientific Research Fund of Heilongjiang Provincial
   Department of Education [12541090]; Excellent Youth Foundation of
   Heilongjiang Scientific Committee [JC2015016]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61374127 and 51404073, the Outstanding
   Youth Science Foundation of National Natural Science Foundation of China
   under Grant 61422301, the Chinese Postdoctoral Science Foundation under
   Grant 2014 M550180, the Scientific Research Fund of Heilongjiang
   Provincial Department of Education under Grant 12541090, and the
   Excellent Youth Foundation of Heilongjiang Scientific Committee
   JC2015016.
CR [Anonymous], 2005, PROBLEM DEFINITIONS
   Arthern RJ, 2015, J GLACIOL, V61, P947, DOI 10.3189/2015JoG15J050
   Assad A, 2018, INF SCI, P450
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P1573, DOI 10.1016/j.eswa.2014.09.049
   Bharathi C, 2017, WIRELESS PERS COMMUN, V93, P481, DOI 10.1007/s11277-017-3959-z
   Bose A, 2016, SIGNAL IMAGE VIDEO P, V10, P1089, DOI 10.1007/s11760-016-0863-z
   Cui LZ, 2016, INFORM SCIENCES, V367, P1012, DOI 10.1016/j.ins.2016.07.022
   Feng YC, 2017, DIGIT SIGNAL PROCESS, V60, P186, DOI 10.1016/j.dsp.2016.08.003
   Ghosh P, 2016, NEUROCOMPUTING, V195, P181, DOI 10.1016/j.neucom.2015.09.123
   Hu H, 2019, MULTIMED TOOLS APPL, P1
   Huo F, 2017, SIGNAL IMAGE VIDEO P, V12, P1
   Khan A, 2014, SIGNAL IMAGE VIDEO P, V8, P1233, DOI 10.1007/s11760-012-0347-8
   Kolesnikov A, 2016, LECT NOTES COMPUT SC, V9908, P695, DOI 10.1007/978-3-319-46493-0_42
   Kong HP, 2015, CHINESE J AERONAUT, V28, P214, DOI 10.1016/j.cja.2014.12.010
   Kotrechko Sergiy, 2017, Solid State Phenomena, V258, P281, DOI 10.4028/www.scientific.net/SSP.258.281
   Li HF, 2018, PATTERN RECOGN, V79, P130, DOI 10.1016/j.patcog.2018.02.005
   Lin KC, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0306-3
   Ma XQ, 2019, IEEE T GEOSCI REMOTE, V57, P1585, DOI 10.1109/TGRS.2018.2867570
   Mai T., 2017, SOFT COMPUT, V2, P1
   Matsuyama T., 2016, BIOPHYS J, V89, P2443
   Mozaffari MH, 2017, IET IMAGE PROCESS, V11, P605, DOI 10.1049/iet-ipr.2016.0489
   Nanni L, 2017, PATTERN RECOGN, V71, P158, DOI 10.1016/j.patcog.2017.05.025
   Sag T, 2015, APPL SOFT COMPUT, V34, P389, DOI 10.1016/j.asoc.2015.05.016
   Shuyun Y, 2014, INF CONTROL
   Trelea IC, 2003, INFORM PROCESS LETT, V85, P317, DOI 10.1016/S0020-0190(02)00447-7
   Yi Zheng-jun, 2012, Journal of Computer Applications, V32, P1935, DOI 10.3724/SP.J.1087.2012.01935
   Yuan XH, 2015, ENERG CONVERS MANAGE, V100, P1, DOI 10.1016/j.enconman.2015.04.051
   Zhang LB, 2018, ELECTRON LETT, V54, P870, DOI 10.1049/el.2018.0609
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang ZQ, 2017, EXPERT SYST APPL, V86, P165, DOI 10.1016/j.eswa.2017.05.053
   Zhao JH, 2016, MAR GEOPHYS RES, V37, P229, DOI 10.1007/s11001-016-9276-1
NR 31
TC 28
Z9 30
U1 0
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2447
EP 2471
DI 10.1007/s11042-019-08231-7
EA NOV 2019
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000497812200002
DA 2024-07-18
ER

PT J
AU Mondal, A
AF Mondal, Ajoy
TI Fuzzy energy based active contour model for multi-region image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-phase pseudo level set; Fuzzy energy; Active contour model; Four
   color theorem; Segmentation
ID LEVEL SET; LOCAL INFORMATION; DRIVEN
AB In this article, we present a new multi-phase pseudo 0.5 level set framework on fuzzy energy based active contour model to segment images into more than two regions. The proposed method is a generalization of fuzzy active contour based on 2-phase segmentation (object and background), developed by Krinidis and Chatzis. The proposed method needs only log(2)n pseudo 0.5 level set functions for n phase piece-wise constant case. In piece-wise smooth case, only two pseudo 0.5 level set functions are sufficient to represent any partition based on 'the four colo theorem. The proposed fuzzy active contour model can segment images into multiple regions instead of two regions (object and background) based on curve evolution. In this article, instead of solving the Euler-Lagrange equation, a multi-phase pseudo 0.5 level set based optimization is proposed to speed up the convergence. Finally, the proposed method is compared with state-of-the-art techniques on several images. Analysis (both qualitative and quantitative) of the results concludes that the proposed method segments images into multiple regions in a better way as compared to the existing ones.
C1 [Mondal, Ajoy] Indian Stat Inst, Machine Intelligence Unit, Kolkata 700108, India.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata
RP Mondal, A (corresponding author), Indian Stat Inst, Machine Intelligence Unit, Kolkata 700108, India.
EM ajoy.mondal83@gmail.com
CR Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   [Anonymous], INTRO CALCULUS VARIA
   [Anonymous], DIGITAL IMAGE PROCES
   APPEL K, 1977, ILLINOIS J MATH, V21, P429, DOI 10.1215/ijm/1256049011
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bae E, 2009, LECT NOTES COMPUT SC, V5567, P1, DOI 10.1007/978-3-642-02256-2_1
   Bezdek James C., 1981, PATTERN RECOGN
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   De Santis Alberto, 2007, Signal, Image and Video Processing, V1, P303, DOI 10.1007/s11760-007-0032-5
   Dubrovina-Karni A, 2015, IEEE T PATTERN ANAL, V37, P1585, DOI 10.1109/TPAMI.2014.2385708
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   He L, 2007, LECT NOTES COMPUT SC, V4485, P777
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Krinidis S, 2012, IFIP ADV INFORM COMM, P175
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Krinidis S, 2009, IEEE T IMAGE PROCESS, V18, P2747, DOI 10.1109/TIP.2009.2030468
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Liu WP, 2013, PATTERN RECOGN LETT, V34, P655, DOI 10.1016/j.patrec.2013.01.005
   Lucas BC, 2012, LECT NOTES COMPUT SC, V7510, P495, DOI 10.1007/978-3-642-33415-3_61
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mondal A, 2016, IEEE INT FUZZY SYST, P1341, DOI 10.1109/FUZZ-IEEE.2016.7737845
   Mondal A, 2016, APPL SOFT COMPUT, V47, P191, DOI 10.1016/j.asoc.2016.05.026
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Saraswathi S, 2013, 2013 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES), P331, DOI 10.1109/ICICES.2013.6508376
   Shyu KK, 2012, NONLINEAR DYNAM, V67, P1559, DOI 10.1007/s11071-011-0088-1
   Song B., 2002, UCLA CAM REPORT, V2, P68
   Sun WY, 2018, SIGNAL IMAGE VIDEO P, V12, P91, DOI 10.1007/s11760-017-1134-3
   Nguyen TNA, 2012, IEEE T IMAGE PROCESS, V21, P3734, DOI 10.1109/TIP.2012.2191566
   Tran TT, 2014, J VIS COMMUN IMAGE R, V25, P1732, DOI 10.1016/j.jvcir.2014.06.006
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wu Y, 2015, APPL SOFT COMPUT, V34, P301, DOI 10.1016/j.asoc.2015.04.058
   Xie ZP, 2013, SIGNAL IMAGE VIDEO P, V7, P521, DOI 10.1007/s11760-011-0254-4
   Zhang KH, 2010, IMAGE VISION COMPUT, V28, P668, DOI 10.1016/j.imavis.2009.10.009
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
NR 39
TC 4
Z9 4
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1535
EP 1554
DI 10.1007/s11042-019-08207-7
EA NOV 2019
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000493973100002
DA 2024-07-18
ER

PT J
AU Du, WH
   Zhou, XF
   Wang, CX
   Rong, DL
AF Du, Weihui
   Zhou, Xiaofen
   Wang, Changxiang
   Rong, Donglin
TI Research on ecological logistics evaluation model based on BCPSGA-BP
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ecological logistics; BCPSGA-BP; Evaluation model
AB The realization of ecological logistics evaluation model based on BCPSGA-BP neural network is beneficial to improve the level of logistics management in China, to achieve the purpose of energy saving and emission reduction, environmental protection and sustainable development. This paper discusses the construction of ecological logistics model through green logistics, agile logistics, lean logistics, reverse logistics, environmental protection logistics, recycling logistics, cleaner production and other logistics forms under the background of electronic commerce, Finally, CPSGA-BP neural network is proposed as an evaluation model to achieve the objective and accurate assessment of the ecological logistics performance model, and provides strong evidence and support for the development of ecological logistics.
C1 [Du, Weihui; Zhou, Xiaofen; Wang, Changxiang] Wuhan Technol & Business Univ, Sch Logist, Wuhan 430065, Hubei, Peoples R China.
   [Rong, Donglin] China Univ Geosci, Fac Informat Engn, Wuhan 430074, Hubei, Peoples R China.
C3 China University of Geosciences
RP Zhou, XF (corresponding author), Wuhan Technol & Business Univ, Sch Logist, Wuhan 430065, Hubei, Peoples R China.
EM zxf33079762006@126.com
RI Molina, Nicholle/AAA-7370-2022
FU Education Scientific Planning Project in Hubei Province [2018GB122]
FX This work was supported by projects grant from Education Scientific
   Planning Project in Hubei Province(Grant No.2018GB122).
CR Antai I, 2013, INT J PHYS DISTR LOG, V7, P61
   Burchart-Korol D, 2016, MANAGEMENT, V2
   Burchart-Korol D, 2013, MANAG-POL, V17, P232, DOI 10.2478/manment-2013-0068
   Cui Z, 2014, LOGISTICS TECHNOLOGY, V5, P52
   Fang WW, 2018, IEEE T SYST MAN CY-S, V48, P522, DOI 10.1109/TSMC.2016.2606400
   Fleischmann M., 2005, Supply Chain Management on Demand. Strategies and Technologies, P167, DOI DOI 10.1007/B138951
   Gang H, 2017, LOGISTICS BIG ECOLOG, V9, P69
   Lin B, 2016, IEEE T NETW SERV MAN, V13, P581, DOI 10.1109/TNSM.2016.2554143
   Liu Y, 2015, RES LOGISTICS IND GR, V6, P125
   Merkert R, 2013, TRANSPORT RES A-POL, P122
   Merkert R, 2014, TRANSPORT RES A-POL, V62, P30, DOI 10.1016/j.tra.2014.02.007
   Raeesi Ramin, 2014, International Journal of Business Performance and Supply Chain Modelling, V6, P276, DOI 10.1504/IJBPSCM.2014.065271
   Wang C, 2015, RES LOGISTICS NETWOR, P65
   Zh Cheng, 2017, THEORETICAL EMPIRICA, V6, P109
NR 14
TC 4
Z9 4
U1 30
U2 251
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30271
EP 30295
DI 10.1007/s11042-018-6872-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200036
DA 2024-07-18
ER

PT J
AU Jie, YM
   Li, MC
   Guo, C
   Feng, B
   Tang, TT
AF Jie, Yingmo
   Li, Mingchu
   Guo, Cheng
   Feng, Bin
   Tang, Tingting
TI A new construction of compressed sensing matrices for signal processing
   via vector spaces over finite fields
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing matrices; Vector spaces; Coherence; Restricted
   isometry property; Signal processing
ID HESSIAN PENALTY TERM; DETERMINISTIC CONSTRUCTION; RECOVERY;
   RECONSTRUCTION; PURSUIT; BINARY; BOUNDS
AB As an emerging sampling technique, Compressed Sensing provides a quite masterly approach to data acquisition. Compared with the traditional method, how to conquer the Shannon/Nyquist sampling theorem has been fundamentally resolved. In this paper, first, we provide deterministic constructions of sensing matrices based on vector spaces over finite fields. Second, we analyze two kinds of attributes of sensing matrices. One is the recovery performance with respect to compressing and recovering signals in terms of restricted isometry property. In particular, we obtain a series of binary sensing matrices with sparsity level that are quite better than some existing ones. In order to save the storage space and accelerate the recovery process of signals, another character sparsity of matrices has been taken into account. Third, we merge our binary matrices with some matrices owning low coherence in terms of an embedding manipulation to obtain the improved matrices still having low coherence. Finally, compared with the quintessential binary matrices, the improved matrices possess better character of compressing and recovering signals. The favorable performance of our binary and improved matrices have been demonstrated by numerical simulations.
C1 [Jie, Yingmo; Li, Mingchu; Guo, Cheng; Tang, Tingting] Dalian Univ Technol, Sch Software Technol, Dev Zone, Dalian 116620, Peoples R China.
   [Jie, Yingmo; Li, Mingchu; Guo, Cheng] Key Lab Ubiquitous Network & Serv Software Liaoni, Dalian 116620, Peoples R China.
   [Guo, Cheng] Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Guilin 541004, Peoples R China.
   [Feng, Bin] Taishan Univ, Sch Informat Sci & Technol, Tai An 271000, Shandong, Peoples R China.
C3 Dalian University of Technology; Guilin University of Electronic
   Technology; Taishan University
RP Guo, C (corresponding author), Dalian Univ Technol, Sch Software Technol, Dev Zone, Dalian 116620, Peoples R China.; Guo, C (corresponding author), Key Lab Ubiquitous Network & Serv Software Liaoni, Dalian 116620, Peoples R China.; Guo, C (corresponding author), Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Guilin 541004, Peoples R China.
EM guocheng@dlut.edu.cn
RI Tang, Tingting/HTM-4276-2023
OI Guo, Cheng/0000-0001-7489-7381; Li, Mingchu/0000-0001-8280-2936
FU National Natural Science Foundation of China [61501080, 61572095,
   61871064, 61877007, 61771090]; Fundamental Research Funds for the
   Central Universities [DUT19JC08]; Guangxi Key Laboratory of Trusted
   Software [kx201903]
FX This paper is supported by the National Natural Science Foundation of
   China under grant No. 61501080, 61572095, 61871064, 61877007, 61771090,
   the Fundamental Research Funds for the Central Universities under No.
   DUT19JC08, and the Guangxi Key Laboratory of Trusted Software under No.
   kx201903.
CR Amini A, 2012, IEEE T SIGNAL PROCES, V60, P172, DOI 10.1109/TSP.2011.2169249
   Amini A, 2011, IEEE T INFORM THEORY, V57, P2360, DOI 10.1109/TIT.2011.2111670
   [Anonymous], INT J HYBRID INFORM
   Applebaum L, 2009, APPL COMPUT HARMON A, V26, P283, DOI 10.1016/j.acha.2008.08.002
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718
   Berinde R, 2008, ANN ALLERTON CONF, P798, DOI 10.1109/ALLERTON.2008.4797639
   Bourgain J, 2011, DUKE MATH J, V159, P145, DOI 10.1215/00127094-1384809
   Calderbank R, 2010, IEEE J-STSP, V4, P358, DOI 10.1109/JSTSP.2010.2043161
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Candès EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Chen TS, 2019, IEEE J SOLID-ST CIRC, V54, P307, DOI 10.1109/JSSC.2018.2869887
   Cohen A, 2009, J AM MATH SOC, V22, P211
   Cuomo S, 2018, INT J GRID UTIL COMP, V9, P139, DOI 10.1504/IJGUC.2018.091720
   Dai W, 2009, IEEE T INFORM THEORY, V55, P2230, DOI 10.1109/TIT.2009.2016006
   Davenport MA, 2010, IEEE T INFORM THEORY, V56, P4395, DOI 10.1109/TIT.2010.2054653
   DeVore RA, 2007, J COMPLEXITY, V23, P918, DOI 10.1016/j.jco.2007.04.002
   Donoho DL, 2012, IEEE T INFORM THEORY, V58, P1094, DOI 10.1109/TIT.2011.2173241
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Gilbert A, 2010, P IEEE, V98, P937, DOI 10.1109/JPROC.2010.2045092
   Ionin Y, 2007, CRC HDB COMBINATORIA, P306
   Jie YM, 2018, MULTIMED TOOLS APPL, V77, P30551, DOI 10.1007/s11042-018-6120-4
   Jie YM, 2017, J COMB OPTIM, V34, P245, DOI 10.1007/s10878-016-0068-y
   Karystinos GN, 2003, IEEE T COMMUN, V51, P48, DOI 10.1109/TCOMM.2002.807628
   Li SX, 2014, IEEE T SIGNAL PROCES, V62, P2850, DOI 10.1109/TSP.2014.2318139
   Li SX, 2012, IEEE T INFORM THEORY, V58, P5035, DOI 10.1109/TIT.2012.2196256
   Li X, 2010, THESIS, P25
   Liu XM, 2009, ARS COMBINATORIA, V93, P393
   Naidu RR, 2016, IEEE T SIGNAL PROCES, V64, P3566, DOI 10.1109/TSP.2016.2550020
   NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406
   Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002
   Piccialli F, 2013, PROCEDIA COMPUT SCI, V18, P2643, DOI 10.1016/j.procs.2013.06.001
   Romberg J, 2008, IEEE SIGNAL PROC MAG, V25, P14, DOI 10.1109/MSP.2007.914729
   Strohmer T, 2003, APPL COMPUT HARMON A, V14, P257, DOI 10.1016/S1063-5203(03)00023-X
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Tsaig Y, 2006, SIGNAL PROCESS, V86, P549, DOI [10.1016/j.sigpro.2005.05.029, 10.1016/j.sigpro.2005.05.028]
   Wan Z., 2002, Geometry of Classical Groups over Finite Fields, V2nd
   WELCH LR, 1974, IEEE T INFORM THEORY, V20, P397, DOI 10.1109/tit.1974.1055219
   WOOTTERS WK, 1989, ANN PHYS-NEW YORK, V191, P363, DOI 10.1016/0003-4916(89)90322-9
   Wu H, 2012, J MILITARY COMMUNICA, V33, P90
   Xu L, 2015, SCIENCEWISE
   Xuemei Liu, 2016, WSEAS Transactions on Mathematics, V15, P176
   Yuan Y, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7110270
   Zhang J, 2015, IEEE SIGNAL PROC LET, V22, P1960, DOI 10.1109/LSP.2015.2447934
NR 48
TC 7
Z9 8
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31137
EP 31161
DI 10.1007/s11042-019-07947-w
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000008
DA 2024-07-18
ER

PT J
AU García, FT
   Villalba, LJG
   Orozco, ALS
   Kim, TH
AF Turrado Garcia, Fernando
   Garcia Villalba, Luis Javier
   Sandoval Orozco, Ana Lucila
   Kim, Tai-Hoon
TI A comparison of learning methods over raw data: forecasting cab services
   market share in New York City
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Forecast; Linear regression; Random forest; Support vector machines;
   Time series
ID SUPPORT VECTOR MACHINE; RANDOM FOREST REGRESSION
AB The cab services, present in most of the cities, are one of the most used offerings for passenger transportation. Nowadays their business model is being threatened by the meddling of emerging third parties powered by modern technologies. Based on the New York cab data, we will make a comparison of several machine learning techniques (linear regression, support vector machines and random forest) for forecasting the amount of dollars spent in the cab service. The comparison of those methods will focus on the accuracy of their forecasts under several circumstances: real data applied to all features, some noisy data (real data with some uniform distributed noise added) applied to several key features and some estimated data (obtained from other statistical estimators) applied to the key features. The main goal of this comparison is to provide some data regarding the performance of those methods when they are used in conjunction with other estimators
C1 [Turrado Garcia, Fernando; Garcia Villalba, Luis Javier; Sandoval Orozco, Ana Lucila] Univ Complutense Madrid, Fac Informat Technol & Comp Sci, Off 431, GASS,Dept Software Engn & Artificial Intelligence, Calle Prof Jose Garcia Santesmases,9,Ciudad Univ, E-28040 Madrid, Spain.
   [Kim, Tai-Hoon] Sungshin Womens Univ, Dept Convergence Secur, 249-1 Dongseon Dong 3 Ga, Seoul 136742, South Korea.
C3 Complutense University of Madrid; Sungshin Women's University
RP Villalba, LJG (corresponding author), Univ Complutense Madrid, Fac Informat Technol & Comp Sci, Off 431, GASS,Dept Software Engn & Artificial Intelligence, Calle Prof Jose Garcia Santesmases,9,Ciudad Univ, E-28040 Madrid, Spain.
EM fturrado@fdi.ucm.es; javiergv@fdi.ucm.es; asandoval@fdi.ucm.es;
   taihoonn@daum.net
RI Orozco, Ana Lucila Sandoval/H-4148-2012; Villalba, Luis Javier
   Garcí­a/N-4631-2014
FU Sungshin Women's University; European Commission
   [H2020-ICT-2014-2/671672-SELFNET]
FX This research work was supported by Sungshin Women's University. In
   addition, L.J.G.V. and A.L.S.O thanks the European Commission Horizon
   2020 5G-PPP Programme (Grant Agreement number
   H2020-ICT-2014-2/671672-SELFNET - Framework for Self-Organized Network
   Management in Virtualized and Software-Defined Networks).
CR Aarhaug J., 2014, Transportation Research Procedia, V1, P276, DOI [DOI 10.1016/J.TRPRO.2014.07, 10.1016/j.trpro.2014.07.027, DOI 10.1016/J.TRPRO.2014.07.027]
   Adusumilli S, 2015, NEUROCOMPUTING, V166, P185, DOI 10.1016/j.neucom.2015.03.080
   Ahmed M. S., 1979, ANAL FREEWAY TRAFFIC
   [Anonymous], 2016, DAN WORK CAB DATA PU
   [Anonymous], 2014, SUPPORT VECTOR MACHI
   Azevedo C.L., 2014, TRANSP RES PROCEDIA, P3
   Bloomberg MR, 2014, FACTB
   Brands T., 2014, Transportation Research Procedia, V1, P12, DOI [DOI 10.1016/J.TRPRO.2014.07.003, DOI 10.1016/j.trpro.2014.07.003]
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dai WY, 2015, INT J MED INFORM, V84, P189, DOI 10.1016/j.ijmedinf.2014.10.002
   Dobson A.J., 2002, An Introduction to Generalized Linear Models
   GEURTS M, 1977, J MARKETING RES, V14, P269, DOI 10.2307/3150485
   Hastie T., 2009, The Elements of Statistical Learning
   Hastie TJ, 1992, STAT MODELS S WADSWO
   Hwang RH, 2015, INFORM SCIENCES, V314, P28, DOI 10.1016/j.ins.2015.03.068
   Kumar M, 2015, KNOWL-BASED SYST, V89, P584, DOI 10.1016/j.knosys.2015.09.005
   Lindner C, 2015, IEEE T PATTERN ANAL, V37, P1862, DOI 10.1109/TPAMI.2014.2382106
   Meyer D, 2012, MISC FUNCTIONS DEP S, P1
   NELDER JA, 1972, J R STAT SOC SER A-G, V135, P370, DOI 10.2307/2344614
   Pan XL, 2015, KNOWL-BASED SYST, V88, P34, DOI 10.1016/j.knosys.2015.08.009
   Tomar D, 2015, KNOWL-BASED SYST, V81, P131, DOI 10.1016/j.knosys.2015.02.009
   García FT, 2012, EXPERT SYST APPL, V39, P10590, DOI 10.1016/j.eswa.2012.02.137
   Were K, 2015, ECOL INDIC, V52, P394, DOI 10.1016/j.ecolind.2014.12.028
   Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3
   Wong RCP, 2014, TRANSPORT RES C-EMER, V48, P84, DOI 10.1016/j.trc.2014.08.010
   Wong RCP, 2014, TRANSPORT POLICY, V33, P73, DOI 10.1016/j.tranpol.2014.02.011
   Wu QY, 2014, KNOWL-BASED SYST, V67, P105, DOI 10.1016/j.knosys.2014.06.004
   Yu HL, 2015, KNOWL-BASED SYST, V76, P67, DOI 10.1016/j.knosys.2014.12.007
   Zhang WP, 2013, KNOWL-BASED SYST, V39, P34, DOI 10.1016/j.knosys.2012.10.004
   Zheng BJ, 2015, INT J APPL EARTH OBS, V34, P103, DOI 10.1016/j.jag.2014.07.002
   Zhou QF, 2015, EXPERT SYST APPL, V42, P4840, DOI 10.1016/j.eswa.2014.12.028
NR 32
TC 2
Z9 2
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 29783
EP 29804
DI 10.1007/s11042-018-6285-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200009
DA 2024-07-18
ER

PT J
AU Xie, KF
   Mei, YL
   Gui, P
   Liu, Y
AF Xie, Kefan
   Mei, Yanlan
   Gui, Ping
   Liu, Yang
TI Early-warning analysis of crowd stampede in metro station commercial
   area based on internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Early-warning; Crowd stampede; Metro Station; Intelligent computing;
   Internet of things
ID MANAGEMENT; BEHAVIOR; AHPSORT
AB Crowd stampede has attracted significant attention of emergency management researchers in recent years. Early-warning of crowd stampede in metro station commercial area is discussed in this paper under the context of Internet of Things (IoT). Metro station commercial area is one of the entity carriers of E-commerce. IOT is a new concept of realizing intelligent sense, monitoring, tracking and management, which can be used in early-warning analysis of crowd stampede in metro station. Stampede risk early-warning in commercial area plays an important role in ensuring the operation of e-commerce online. Firstly, the laws and characteristics of the crowd movement in the commercial area of metro station are studied, which include the laeuna effect, block effect and aggravation effect. Secondly, the early-warning paradigm is constructed from four dimensions, ie. function, modules, principle and process. And then, under the IOT environment, the AHPsort II is applied to integrate the early-warning information and classify the stampede risk level. Finally, the paper takes the commercial area of Wuhan A metro station as an example to verify the practicability and effectiveness of the AHPsort II application to early-warning of crowd stampede in metro station commercial area.
C1 [Xie, Kefan; Mei, Yanlan; Gui, Ping] Wuhan Univ Technol, Sch Management, Wuhan, Hubei, Peoples R China.
   [Mei, Yanlan] Wuhan Inst Technol, Sch Management, Wuhan, Hubei, Peoples R China.
   [Liu, Yang] Linkoping Univ, Dept Management & Engn, SE-58183 Linkoping, Sweden.
   [Liu, Yang] Univ Vaasa, Dept Prod, PL 700, Vaasa 65101, Finland.
C3 Wuhan University of Technology; Wuhan Institute of Technology; Linkoping
   University; University of Vaasa
RP Mei, YL (corresponding author), Wuhan Univ Technol, Sch Management, Wuhan, Hubei, Peoples R China.; Mei, YL (corresponding author), Wuhan Inst Technol, Sch Management, Wuhan, Hubei, Peoples R China.
EM xkf@whut.edu.cn; Meiyanlanlan@163.com; guiping518@163.com; yli@uwasa.fi
RI yang, liu/HTN-9175-2023; yang, liu/GVU-8760-2022; Liu, Yang/C-8320-2013;
   Gui, Ping/AAN-2991-2021
OI Liu, Yang/0000-0001-8006-3236; 
FU National Social Science Foundation of China [15AGL021]
FX This research is supported by National Social Science Foundation of
   China (Project no. 15AGL021).
CR [Anonymous], 2012, PESQUISA OPERATIONAL
   Carley KM, 2016, SAFETY SCI, V90, P48, DOI 10.1016/j.ssci.2016.04.002
   Castillo-Manzano JI, 2009, CITIES, V26, P141, DOI 10.1016/j.cities.2009.02.007
   Flamini M, 2008, EUR J OPER RES, V189, P746, DOI 10.1016/j.ejor.2006.09.098
   Haghani M, 2018, TRANSPORT RES B-METH, V107, P253, DOI 10.1016/j.trb.2017.06.017
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   Helbing D, 2001, REV MOD PHYS, V73, P1067, DOI 10.1103/RevModPhys.73.1067
   Henein CM, 2007, PHYSICA A, V373, P694, DOI 10.1016/j.physa.2006.06.023
   Ishizaka A, 2012, INT J PROD RES, V50, P4767, DOI 10.1080/00207543.2012.657966
   Kirchner A, 2002, PHYSICA A, V312, P260, DOI 10.1016/S0378-4371(02)00857-9
   Lee RSC, 2006, ACCIDENT ANAL PREV, V38, P712, DOI 10.1016/j.aap.2006.01.001
   Lee RSC, 2005, J TRANSP ENG, V131, P575, DOI 10.1061/(ASCE)0733-947X(2005)131:8(575)
   Li CP, 2016, SAFETY SCI, V89, P19, DOI 10.1016/j.ssci.2016.05.015
   Li JF, 2016, SAFETY SCI, V89, P114, DOI 10.1016/j.ssci.2016.06.007
   Li Q, 2014, INT J COMPUT INT SYS, V7, P26, DOI 10.1080/18756891.2014.947090
   Lian LP, 2017, FIRE SAFETY J, V91, P918, DOI 10.1016/j.firesaf.2017.04.015
   Lian LP, 2017, PHYSICA A, V469, P265, DOI 10.1016/j.physa.2016.11.048
   Lin JJ, 2008, TUNN UNDERGR SP TECH, V23, P103, DOI 10.1016/j.tust.2006.12.003
   Miccoli F, 2017, ECOL INDIC, V73, P741, DOI 10.1016/j.ecolind.2016.10.034
   Tang XF, 2014, INT J COMPUT INT SYS, V7, P1137, DOI 10.1080/18756891.2014.889858
   Teknomo K., 2002, MICROSCOPIC PEDESTRI
   Wang L, 2018, INT J COMPUT INT SYS, V11, P163, DOI 10.2991/ijcis.11.1.13
   Xie K, 2016, 2016 2 INT C IND INF, P1
   Yang J, 2018, MYCOL PROG, V17, P591, DOI 10.1007/s11557-017-1339-4
   Zhang JG, 2011, IMMUNOPHARM IMMUNOT, V33, P157, DOI 10.3109/08923973.2010.491079
   Zhao YX, 2017, PHYS LETT A, V381, P3149, DOI 10.1016/j.physleta.2017.08.014
   Zhao Z, 2016, PROCEDIA ENGINEER, V135, P602, DOI 10.1016/j.proeng.2016.01.118
   Zhao Z, 2014, PROCEDIA ENGINEER, V71, P81, DOI 10.1016/j.proeng.2014.04.011
   Zhou J., 2018, BIG DATA SUPPORT URB, P19
NR 29
TC 9
Z9 11
U1 6
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30141
EP 30157
DI 10.1007/s11042-018-6982-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200029
OA Green Accepted, Green Submitted, Bronze
DA 2024-07-18
ER

PT J
AU Zhang, GQ
   Zheng, YH
   Xia, GY
AF Zhang, Guoqing
   Zheng, Yuhui
   Xia, Guiyu
TI Domain adaptive collaborative representation based classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Domain adaptation; Collaborative representation; Joint projection and
   dictionary learning; Non-linear representation
ID FACE RECOGNITION; IMAGE; KERNEL; TRANSPORT
AB Conventional representation based classification methods, such as sparse representation based classification (SRC) and collaborative representation based classification (CRC) have been developed and shown great potential due to its effectiveness in various recognition tasks. However, when the test data and training data come from different distribution, the performance of SRC and CRC will be degraded significantly. Recently, several sparse representation based domain adaptation learning (DAL) methods have been proposed and achieve impressive performance. However, these sparse representation based DAL methods need to solve the l(1)-norm optimization problem, which is extremely time-consuming. To address this problem, in this paper, we propose a simple yet much more efficient domain adaptive collaborative representation-based classification method (DACRC). By replacing the l(2)-norm regularization term using the l(2)-norm, we exploit the collaborative representation rather than sparse representation to jointly learn projections of data in the two domains. In addition, a common dictionary is also learned such that in the projected space the learned dictionary can optimal represent both training and test data. Furthermore, the proposed method is effective to deal with multiple domains problem and is easy to kernelized. Compared with other sparse representation based DAL methods, DACRC is computationally efficient and its performance is better or comparable to many state-of-the-art methods.
C1 [Zhang, Guoqing; Zheng, Yuhui] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
   [Xia, Guiyu] Nanjing Univ Informat Sci & Technol, Sch Informat & Control, Nanjing 210044, Jiangsu, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology
RP Zhang, GQ (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
EM xiayang14551@163.com
RI zhang, guoqing/GXG-4800-2022
OI guoqing, zhang/0000-0002-8741-8607
CR [Anonymous], 7694 CIT
   Ben-David S., 2007, NIPS, P137
   Bibi A, 2017, P COMP VIS PATT REC, P1772
   Cai S, 2016, P COMP VIS PATT REC, P5839
   Courty N, 2017, IEEE T PATTERN ANAL, V39, P1853, DOI 10.1109/TPAMI.2016.2615921
   Daume III Hal, 2007, ACL 2007, P256
   Deng W., 2017, IEEE transactions on pattern analysis and machine intelligence
   Gao Y, 2017, IEEE T IMAGE PROCESS, V26, P2545, DOI 10.1109/TIP.2017.2675341
   Gebru T, 2017, IEEE I CONF COMP VIS, P1358, DOI 10.1109/ICCV.2017.151
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344
   Huang W, 2017, P ADV NEUR INF PROC, P3447
   Huang WB, 2016, PROC CVPR IEEE, P3938, DOI 10.1109/CVPR.2016.427
   Jiang XD, 2015, IEEE T PATTERN ANAL, V37, P1067, DOI 10.1109/TPAMI.2014.2359453
   Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702
   Lu B, 2015, P BRIT MACH VIS C BM
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4042, DOI 10.1109/TIP.2017.2713940
   Monga V., 2005, HALFTONING TOOLBOX M
   Ni J, 2017, P INT C COMP VIS PAT, P692
   Panigrahi S., 2021, IEEE Transactions on Knowledge and Data Engineering, V194, P781, DOI [DOI 10.1109/TKDE.2009.191, 10.1007/978-981-15-5971-6_83]
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P53, DOI 10.1109/MSP.2014.2347059
   Qi YK, 2018, IEEE T IMAGE PROCESS, V27, P3857, DOI 10.1109/TIP.2018.2797482
   Qiu Q, 2012, LECT NOTES COMPUT SC, V7575, P631, DOI 10.1007/978-3-642-33765-9_45
   Quan YH, 2016, PROC CVPR IEEE, P5839, DOI 10.1109/CVPR.2016.629
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Shekhar S, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2431440
   Shekhar S, 2013, PROC CVPR IEEE, P361, DOI 10.1109/CVPR.2013.53
   Shi YJ, 2012, INT CONF IMAGE ANAL, P79
   Shrivastava A, 2014, IEEE WINT CONF APPL, P277, DOI 10.1109/WACV.2014.6836088
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Wen ZW, 2013, MATH PROGRAM, V142, P397, DOI 10.1007/s10107-012-0584-1
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xia ZH, 2018, IEEE ACCESS, V6, P30392, DOI 10.1109/ACCESS.2018.2845456
   Xiong NX, 2009, IEEE J SEL AREA COMM, V27, P495, DOI 10.1109/JSAC.2009.090512
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang M, 2017, AAAI CONF ARTIF INTE, P1626
   Yang M, 2010, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2010.5652363
   Zhang GQ, 2017, IEEE T IMAGE PROCESS, V26, P5922, DOI 10.1109/TIP.2017.2745684
   Zhang GQ, 2016, J VIS COMMUN IMAGE R, V40, P470, DOI 10.1016/j.jvcir.2016.07.015
   Zhang GQ, 2016, PATTERN RECOGN, V60, P613, DOI 10.1016/j.patcog.2016.06.012
   Zhang GQ, 2016, NEUROCOMPUTING, V207, P300, DOI 10.1016/j.neucom.2016.04.044
   Zhang GQ, 2016, IEEE T IMAGE PROCESS, V25, P4271, DOI 10.1109/TIP.2016.2587119
   Zhang GQ, 2016, NEUROCOMPUTING, V171, P1193, DOI 10.1016/j.neucom.2015.07.048
   Zhang HM, 2016, ASIA PAC J TOUR RES, V21, P811, DOI 10.1080/10941665.2015.1075566
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang L, 2012, IEEE T SIGNAL PROCES, V60, P1684, DOI 10.1109/TSP.2011.2179539
   Zheng HF, 2018, IEEE T SYST MAN CY-S, V48, P2315, DOI 10.1109/TSMC.2017.2734886
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
NR 48
TC 3
Z9 3
U1 5
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30175
EP 30196
DI 10.1007/s11042-018-7007-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200031
DA 2024-07-18
ER

PT J
AU Zhang, XH
   Ma, C
   Wu, J
AF Zhang, Xiaohuan
   Ma, Chi
   Wu, Jie
TI Multi-batch integrated scheduling algorithm based on time-selective
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Time-selective; Multi-batch; Integrated scheduling; Algorithm
ID OPTIMIZATION; SHOP
AB Based on the problem that the integrated scheduling algorithm cannot fully consider the impact of the scheduling process on the subsequent process so that the scheduling results are impacted, this paper presents a multi-batch integrated scheduling algorithm based on time-selective. This algorithm proposes a process sequence sequencing strategy,it divides the whole structure of the process tree into several process sequences and determines the scheduling order according to the path length. The multi-batch time-selective scheduling strategy generates several process combination plans. It presents the process combination selection strategy chooses the combination plan most close to scheduling targets among the different combination plans. The analysis and example show that this algorithm is better in multi-batch integrated scheduling.
C1 [Zhang, Xiaohuan] Harbin Univ Sci & Technol, Coll Comp Sci & Technol, Harbin 150080, Heilongjiang, Peoples R China.
   [Ma, Chi] Univ Sci & Technol Liaoning, Sch Software Engn, Anshan 114051, Peoples R China.
   [Wu, Jie] Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Beijing 100083, Peoples R China.
C3 Harbin University of Science & Technology; University of Science &
   Technology Liaoning; University of Science & Technology Beijing
RP Ma, C (corresponding author), Univ Sci & Technol Liaoning, Sch Software Engn, Anshan 114051, Peoples R China.
EM huanhuan291@126.com; machi_1975@126.com
FU National Natural Science Foundation of China [U1731128, 51374035];
   Foundation of Liaoning Educational committee [2016HZPY09]
FX This work was supported by the National Natural Science Foundation of
   China(No. U1731128, No. 51374035), Foundation of Liaoning Educational
   committee under the Grant No.2016HZPY09.
CR Baioletti M, 2016, INTELL ARTIF, V10, P81, DOI 10.3233/IA-160097
   Li JQ, 2013, INT J ADV MANUF TECH, V66, P583, DOI 10.1007/s00170-012-4337-3
   Li XP, 2018, INT J PROD ECON, V196, P113, DOI 10.1016/j.ijpe.2017.11.015
   Lin L, 2018, INT J PROD RES, V56, P193, DOI 10.1080/00207543.2018.1437288
   Qiang Lei, 2007, Computer Integrated Manufacturing Systems, V13, P317
   Santucci V, 2016, AI COMMUN, V29, P269, DOI 10.3233/AIC-150695
   Shahvari O, 2018, INT J PROD ECON, V195, P227, DOI 10.1016/j.ijpe.2017.10.015
   Singh MR, 2016, INT J ADV MANUF TECH, V85, P2353, DOI 10.1007/s00170-015-8075-1
   Wang H, 2014, COMPUT INTEGR MANUF, V12, P3000
   Wenbo Liu, 2016, Applied Mechanics and Materials, V835, P847, DOI 10.4028/www.scientific.net/AMM.835.847
   Xie Z, 2011, J BEIJING U TECHNOL, P1470
   Xie Z.Q., 2003, J. Comput. Res. Dev, V40, P977
   Xie Zhi-qiang, 2012, Journal of Shanghai Jiaotong University, V46, P1746
   Xie Zhi-Qiang, 2011, Acta Automatica Sinica, V37, P1332, DOI 10.3724/SP.J.1004.2011.01332
   Xie Zhi-Qiang, 2011, Chinese Journal of Computers, V34, P406, DOI 10.3724/SP.J.1016.2011.00406
   [谢志强 Xie Zhiqiang], 2013, [计算机学报, Chinese Journal of Computers], V36, P818
   Xie Zhiqiang, 2011, Journal of Mechanical Engineering, V47, P139, DOI 10.3901/JME.2011.11.139
   [谢志强 XIE ZhiQiang], 2008, [计算机学报, Chinese Journal of Computers], V31, P502
NR 18
TC 10
Z9 10
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 29989
EP 30010
DI 10.1007/s11042-018-6805-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200020
DA 2024-07-18
ER

PT J
AU Nguyen, TB
   Le, TL
   Devillaine, L
   Pham, TTT
   Ngoc, NP
AF Thuy-Binh Nguyen
   Le, Thi-Lan
   Devillaine, Louis
   Thi Thanh Thuy Pham
   Nam Pham Ngoc
TI Effective multi-shot person re-identification through representative
   frames selection and temporal feature pooling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-shot peron re-identification; Hand designed features; Multi-shot;
   Representative frames
ID VIDEO; FUSION
AB Multi-shot person re-identification (ReID) is a popular case of person ReID in which a set of images are processed for each person. However, using entire image set for person ReID as most experimented proposals is not always effective because of time and memory consuming. The main contribution of this work is the proposed strategies for (1) choosing representative image frames for each individual instead of entire set of frames, and (2) temporal feature pooling in multi-shot person ReID. These strategies are efficiently integrated in a person ReID framework which uses GoG (Gaussian of Gaussian) and XQDA (metric learning Cross-view Quadratic Discriminant Analysis) for person representation and matching. The effectiveness of the proposed framework on two benchmark datasets (PRID 2011 and iLIDS-VID) in terms of re-identification accuracy, computational time, and storage requirements are deeply investigated and analyzed. The experimental results allow to provide several recommendations on the use of these schemes based on the characteristics of the working dataset and the requirement of the applications. Furthermore, the study also offers a desktop-based application for person search and ReID. The implementation of the proposed framework will be made publicly available.
C1 [Thuy-Binh Nguyen; Le, Thi-Lan] Hanoi Univ Sci & Technol, MICA Int Res Inst, Comp Vis Dept, Hanoi, Vietnam.
   [Thuy-Binh Nguyen; Nam Pham Ngoc] Hanoi Univ Sci & Technol, Sch Elect & Telecommun, Hanoi, Vietnam.
   [Thuy-Binh Nguyen] Univ Transport & Commun, Fac Elect & Elect Engn, Hanoi, Vietnam.
   [Devillaine, Louis] Grenoble Inst Technol, Sch Engn Phys Appl Phys Elect & Mat Sci, Grenoble, France.
   [Thi Thanh Thuy Pham] Acad People Secur, Fac Secur & Informat Technol, Hanoi, Vietnam.
C3 Hanoi University of Science & Technology (HUST); Hanoi University of
   Science & Technology (HUST); University of Transport & Communications
   (UTC); Communaute Universite Grenoble Alpes; Institut National
   Polytechnique de Grenoble
RP Le, TL (corresponding author), Hanoi Univ Sci & Technol, MICA Int Res Inst, Comp Vis Dept, Hanoi, Vietnam.
EM thuybinh_ktdt@utc.edu.vn; Thi-Lan.Le@mica.edu.vn;
   louis.devillaine@grenoble-inp.org; thuy3677@gmail.com;
   nam.phamngoc@hust.vn
RI Le, Thi-Lan/AAA-5855-2020
OI Le, Thi-Lan/0000-0001-9541-3905
FU Vietnam National Foundation for Science and Technology Development
   (NAFOSTED) [102.01-2017.315]
FX This research is funded by Vietnam National Foundation for Science and
   Technology Development (NAFOSTED) under grant number 102.01-2017.315
CR Abdeen HAY, 2016, GER MICROW CONF, P341, DOI 10.1109/GEMIC.2016.7461626
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   Avraham T, 2012, LECT NOTES COMPUT SC, V7583, P381
   Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Eisenbach M., 2015, 2015 International Joint Conference on Neural Networks, IJCNN 2015, Killarney, Ireland, July 12-17, 2015, P1, DOI DOI 10.1109/IJCNN.2015.7280360
   FRIKHA M, 2016, INT WORKSH REPR AN R, P97
   Gao CX, 2016, IEEE IMAGE PROC, P4284, DOI 10.1109/ICIP.2016.7533168
   Gao M, 2016, IEEE IMAGE PROC, P4274, DOI 10.1109/ICIP.2016.7533166
   Graves A., 2013, GENERATING SEQUENCES
   HASSEN YH, 2017, INT C INT INT MULT S, P11
   Hassen YH, 2015, PROC SPIE, V9875, DOI 10.1117/12.2228608
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Heidarysafa M., 2018, ARXIV180808121
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Nguyen HG, 2018, IEEE INT C ENG COMP, P1, DOI [10.1109/ICOPS35962.2018.9575287, 10.1109/ICECCS2018.2018.00009]
   Huang ZW, 2015, PROC CVPR IEEE, P140, DOI 10.1109/CVPR.2015.7298609
   JOHNSON J, 2018, ARXIV180310630
   Karanam Srikrishna., 2018, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Kowsari K, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P364, DOI 10.1109/ICMLA.2017.0-134
   LE TL, 2009, P ACM INT C IM VID R, V40, P8
   LEJBOLLE AR, 2017, ENHANCING PERSON REI
   Li MX, 2020, IEEE T PATTERN ANAL, V42, P1770, DOI 10.1109/TPAMI.2019.2903058
   Li MX, 2018, LECT NOTES COMPUT SC, V11208, P772, DOI 10.1007/978-3-030-01225-0_45
   Li YJ, 2017, IEEE COMPUT SOC CONF, P1454, DOI 10.1109/CVPRW.2017.188
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu H, 2018, IEEE T CIRC SYST VID, V28, P2788, DOI 10.1109/TCSVT.2017.2715499
   Liu K, 2015, IEEE I CONF COMP VIS, P3810, DOI 10.1109/ICCV.2015.434
   Liu YG, 2019, J VIS COMMUN IMAGE R, V58, P46, DOI 10.1016/j.jvcir.2018.11.023
   Liu Z, 2016, IEEE IMAGE PROC, P4294, DOI 10.1109/ICIP.2016.7533170
   Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI [10.1109/ICCVW.2017.361, 10.1109/ICCV.2017.478]
   Lu ZQJ, 2010, J R STAT SOC A STAT, V173, P693
   MA B, 2012, P EUR C COMPUT VIS, P413, DOI DOI 10.1007/978-3-642-33863-241
   Ma XL, 2017, PATTERN RECOGN, V65, P197, DOI 10.1016/j.patcog.2016.11.018
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Prosser B., 2010, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.24.21
   Rehman SU, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING (ICALIP), P213, DOI 10.1109/ICALIP.2016.7846523
   SONG J, 2017, ARXIV170802478
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   SONG S, 2018, ARXIV180807272
   Su C, 2015, IEEE I CONF COMP VIS, P3739, DOI 10.1109/ICCV.2015.426
   Nguyen TB, 2019, J INFORM TELECOMMUN, V3, P74, DOI 10.1080/24751839.2018.1531233
   THUYBINH N, 2018, 5 NAFOSTED C INF COM
   Tian H, 2018, OCEANS 2018 MTS/IEEE CHARLESTON
   Wang RP, 2012, PROC CVPR IEEE, P2496, DOI 10.1109/CVPR.2012.6247965
   Wang RP, 2009, PROC CVPR IEEE, P429, DOI 10.1109/CVPRW.2009.5206850
   Wang TQ, 2016, IEEE T PATTERN ANAL, V38, P2501, DOI 10.1109/TPAMI.2016.2522418
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Wu SX, 2016, IEEE WINT CONF APPL
   WU Y, 2014, P 20 KOR JOINT WORKS
   Wu Y, 2012, LECT NOTES COMPUT SC, V7574, P497, DOI 10.1007/978-3-642-33712-3_36
   Yan YC, 2016, LECT NOTES COMPUT SC, V9910, P701, DOI 10.1007/978-3-319-46466-4_42
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Ye M, 2017, IEEE I CONF COMP VIS, P5152, DOI 10.1109/ICCV.2017.550
   Yu-Chen Chang, 2012, 2012 International Symposium on Intelligent Signal Processing and Communications Systems (ISPACS 2012), P1, DOI 10.1109/ISPACS.2012.6473442
   Zeng MY, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1838, DOI 10.1145/3240508.3240717
   Zeng ZQ, 2018, IEEE T IND INFORM, V14, P3179, DOI 10.1109/TII.2017.2767557
   Zhang W, 2018, IEEE T CIRC SYST VID, V28, P2768, DOI 10.1109/TCSVT.2017.2718188
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zhao SC, 2018, IEEE T CIRC SYST VID, V28, P1839, DOI 10.1109/TCSVT.2017.2682196
   ZHENG L, 2015, PROC CVPR IEEE, P1741, DOI DOI 10.1109/CVPR.2015.7298783
   Zheng Liang, 2016, arXiv preprint arXiv
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
NR 70
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33939
EP 33967
DI 10.1007/s11042-019-08183-y
EA OCT 2019
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000492481300001
DA 2024-07-18
ER

PT J
AU Kim, HS
   Jeong, HY
   Joo, HJ
AF Kim, Hye-Sun
   Jeong, Hwa-Young
   Joo, Hae-Jong
TI RETRACTED: The big data visualization technology based ecosystem cycle
   on high speed network (Retracted article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Big data visualization; Big data ecosystem cycle; Big data utilization
   case; BI solution
AB Big Data is becoming a key strategy in the business sector, with the increasing number of corporate customer data tracking and collection practices, and the proliferation of multimedia content, such as the proliferation of multimedia and camera modules, and the proliferation of multimedia content. In this paper, we proposed a Big Data ecosystem cycle to create the data utilization strategies and analytic manpower for the success of data utilization with the data uptake. Big Data growth and investment with visualizations are critical to creating a significant role in the development of various Big Data business models. First of all, it is necessary to improve the data for innovation (Releasing Data for Innovation) and data visualization, to minimize the risk of privacy, and to mitigate the risk of privacy leaks to facilitate the promotion of Big Data utilization. It needs to comply with the standardization of Big Data requirements based on ISO/IEC geurigo 1 SC JTC data, and it has necessary to identify the scale of the existing architectures for the sake of accommodating and supporting the architecture that embrace the benefits of legacy architectures.
C1 [Kim, Hye-Sun] Dongguk Univ, Dept LINC, Seoul, South Korea.
   [Jeong, Hwa-Young] Kyung Hee Univ, Dept Humanitas Coll, Seoul, South Korea.
   [Joo, Hae-Jong] Dongguk Univ, Coll Engn, Dept Comp Sci & Engn, Seoul, South Korea.
C3 Dongguk University; Kyung Hee University; Dongguk University
RP Jeong, HY (corresponding author), Kyung Hee Univ, Dept Humanitas Coll, Seoul, South Korea.
EM daisyhsun@dongguk.edu; hyjeong@khu.ac.kr; hjjoo@dongguk.edu
RI Kim, Hye Sun/J-2752-2012
OI Jeong, Hwa-Young/0000-0002-5017-934X
CR Afrati FN, 2018, J COMPUT SYST SCI, V94, P98, DOI 10.1016/j.jcss.2017.02.007
   [Anonymous], 2014, 2014 INF STAT NAT AP
   [Anonymous], 2012, BIG DAT BAS JOB CREA
   [Anonymous], 2015, BIG DAT PLANN REP BI
   Batra R, 2015, TRENDS DATA MANAGEME
   Big Data Strategy Research Center, 2013, PROT UT PERS DAT BIG
   Big Data Strategy Research Center, 2013, BIG DAT AG NEW ED
   Caro F, 2010, INTERFACES, V40, P71, DOI 10.1287/inte.1090.0472
   Cobb AN, 2018, SURGERY, V164, P640, DOI 10.1016/j.surg.2018.06.022
   D-m Bae, 2013, BIG DATA TRENDS POLI, V25
   Glushkova D, 2019, INFORM SYST, V79, P32, DOI 10.1016/j.is.2017.11.006
   Inoubli W, 2018, FUTURE GENER COMP SY, V86, P546, DOI 10.1016/j.future.2018.04.032
   ISO/IEC, 2014, 1SG2 ISOIEC JTC
   J-g Park, 2012, UTILIZATION ANAL TEC
   Jeong Y-C, 2014, BIG DATA IND PROMOTI
   KB Financial Group Management Research Institute, 2013, KB DAIL KNOWL VIT BI
   Khezrimotlagh D, 2019, EUR J OPER RES, V274, P1047, DOI 10.1016/j.ejor.2018.10.044
   Lee J-H, 2013, 201304 KIPA
   Jimenez-Marquez JL, 2019, INT J INFORM MANAGE, V44, P1, DOI 10.1016/j.ijinfomgt.2018.09.003
   Munshi AA, 2017, ELECTR POW SYST RES, V151, P369, DOI 10.1016/j.epsr.2017.06.006
   Murray AM, 2014, TANGOE BLOG
   Oussous A., 2018, J KING SAUD U COMPUT
   Research Institute for Information and Telecommunication Policy, 2014, BIG DAT IND PROM STR
   Sook KJ, 2012, BIG DATA UTILIZATION
   The Boston Consulting Group, 2013, UNL VAL PERS DAT COL
NR 25
TC 4
Z9 4
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28903
EP 28916
DI 10.1007/s11042-019-08056-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700030
DA 2024-07-18
ER

PT J
AU Luo, JN
   Yang, MH
   Tsai, KY
AF Luo, Jia-Ning
   Yang, Ming-Hour
   Tsai, Kuo-Yu
TI A geographic map-based middleware framework to obfuscate smart vehicles'
   locations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Location-based service; Privacy protection; Obfuscation area; Smart
   vehicle
ID PROTECTION; PRIVACY
AB In the 5G applications, smart vehicles typically use built-in positioning functions to query geographic map information or to access location-based multimedia or service, such as traffic image, 3D graphics or surrounding points of interest (POI) from a location-based service (LBS) provider. However, when a query is submitted, vehicles' information such as their real locations or moving routes may be collected by the service provider. To protect vehicles' privacy, we developed a geographic map-based middleware framework to prevent the service providers from predicting vehicles' location or moving routes by using background information derived from the geographic maps. In addition, the middleware framework uses a caching approach to generate obfuscation areas on the maps to improve performance. The proposed method also considers popular tourist POIs on the maps to enhance the cache data hit ratio and query performance.
C1 [Luo, Jia-Ning] Ming Chuan Univ, Dept Informat & Telecommun Engn, Taoyuan, Taiwan.
   [Yang, Ming-Hour] Chung Yuan Christian Univ, Dept Informat & Comp Engn, Taoyuan, Taiwan.
   [Tsai, Kuo-Yu] Chinese Culture Univ, Dept Appl Math, Taipei, Taiwan.
C3 Ming Chuan University; Chung Yuan Christian University; Chinese Culture
   University
RP Luo, JN (corresponding author), Ming Chuan Univ, Dept Informat & Telecommun Engn, Taoyuan, Taiwan.; Yang, MH (corresponding author), Chung Yuan Christian Univ, Dept Informat & Comp Engn, Taoyuan, Taiwan.
EM deer@mail.mcu.edu.tw; Mhyang@cycu.edu.tw
OI Luo, Jia-Ning/0000-0003-1395-5810
FU Taiwan Information Security Center (TWISC); Ministry of Science and
   Technology [MOST 107-2218-E-011-012-, MOST 1072221-E-033-010-, MOST
   107-2221-E-130-001-]
FX The authors gratefully acknowledge the support from Taiwan Information
   Security Center (TWISC) and Ministry of Science and Technology under the
   grants MOST 107-2218-E-011-012-, MOST 1072221-E-033-010-, and MOST
   107-2221-E-130-001-.
CR [Anonymous], LESSONS IDENTITY TRA
   Ardagna CA, 2012, P CSE DEC 5 7
   Ardagna CA, 2011, IEEE T DEPEND SECURE, V8, P13, DOI 10.1109/TDSC.2009.25
   Chien-Ping Wu, 2011, 2011 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops 2011). PerCom-Workshops 2011: 2011 IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops 2011), P490, DOI 10.1109/PERCOMW.2011.5766939
   Chow C Y, 2011, SIGKDD EXPLOR NEWSL, P19, DOI DOI 10.1145/2031331.2031335
   Chow CY, 2007, P SSTD 2007
   Damiani M.L., 2009, The 2nd SIGSPATIAL ACM GIS 2009 International Workshop on Security and Privacy in GIS and LBS, P32, DOI DOI 10.1145/1667502.1667511
   Domingo-Ferrer J, 2009, DATA KNOWL ENG, V68, P1237, DOI 10.1016/j.datak.2009.06.004
   Duckham M, 2005, P PERVASIVE
   Ghinita G, 2008, P SIGMOD
   GRUTESER M, 2003, P MOBISYS
   Hoh B, 2007, P CCS
   Jung-Ho Um, 2010, Proceedings of the 2010 IEEE Second International Conference on Social Computing (SocialCom 2010). the Second IEEE International Conference on Privacy, Security, Risk and Trust (PASSAT 2010), P1093, DOI 10.1109/SocialCom.2010.162
   Kalnis P, 2007, IEEE T KNOWL DATA EN, V19, P1719, DOI 10.1109/TKDE.2007.190662
   Kaplan E, 2010, DATA KNOWL ENG, V69, P723, DOI 10.1016/j.datak.2010.02.008
   Lu H, 2008, CHANDOS ASIAN STUD, P1
   Mokbel MF, P 32 INT C VER LARG, P763
   Mouratidis K, 2010, IEEE T KNOWL DATA EN, V22, P2, DOI 10.1109/TKDE.2009.48
   Narayanan A, 2011, LOCATION PRIVACY VIA
   Pan X, 2009, P ACM GIS
   Papadias D, 2003, P 29 INT C VERY LARG
   Pfitzmann A, 2001, LECT NOTECOMPUTER, P1, DOI DOI 10.1007/3-540-44702-4_1
   Pingley A, 2011, IEEE INFOCOM SER, P1710, DOI 10.1109/INFCOM.2011.5934968
   Rodden T, 2002, EQUATOR02058 U NOTT
   Phan TN, 2011, SCHRIFTEN INFORMATIK, V36, P281
   Wang T, 2009, P VLDB ENDOWMENT
   Wu M, 2012, 2012 IEEE FIFTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P433, DOI 10.1109/ICACI.2012.6463200
   Xu T, 2007, P ACM GIS
   Yao L, 2012, 2012 SEVENTH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY (ARES), P375, DOI 10.1109/ARES.2012.40
   Zhang CY, 2009, GEOINFORMATICA, V13, P159, DOI 10.1007/s10707-008-0047-2
NR 30
TC 3
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28877
EP 28902
DI 10.1007/s11042-019-7350-9
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700029
DA 2024-07-18
ER

PT J
AU Zhang, MJ
   Zhang, HX
   Lie, JZ
   Fang, YX
   Wang, L
   Shang, F
AF Zhang, Meijia
   Zhang, Huaxiang
   Lie, Junzheng
   Fang, Yixian
   Wang, Li
   Shang, Fei
TI Multi-modal graph regularization based class center discriminant
   analysis for cross modal retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Class center; Cross modal retrieval; Supervised regularization
ID REPRESENTATION; SEARCH; FUSION; SPARSE
AB On the network, a large amount of multi-modal data has emerged. Efficiently utilizing such data to conduct cross modal retrieval has become a hot topic of research. Some solutions have been proposed for this problem. However, many of these methods only considered the local structural information, thus losing sight of the global structural information of data. To overcome this problem and enhance retrieval accuracy, we propose a multi-modal graph regularization based class center discriminant analysis for cross modal retrieval. The core of our method is to maximize the intra-modality distance and minimize the inter-modality distance of class center samples to strengthen the discriminant ability of the model. Meanwhile, a multi-modal graph, which consists of the inter-modality similarity graph, the class center intra-modality graph and the inter-modality graph, is fused into the method to further reinforce the semantic similarity between different modalities. The method considers the local structural information of data together with the global structural information of data. Experimental results on three benchmark datasets demonstrate the superiority of this proposed scheme over several state-of-the-art methods.
C1 [Zhang, Meijia; Zhang, Huaxiang; Fang, Yixian; Wang, Li; Shang, Fei] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Lie, Junzheng] Shandong Management Univ, Informatizat Off, Jinan 250357, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong Management University
RP Zhang, HX (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
EM huaxzhang@163.com
OI zhang, hua xiang/0000-0001-6259-7533
FU National Natural Science Foundation of China [61572298, 61772322,
   U1836216]; Key Research and Development Foundation of Shandong Province
   [2017GGX10117, 2017CXGC0703]; Natural Science Foundation of Shandong
   China [ZR2015PF006]
FX The work is partially supported by the National Natural Science
   Foundation of China (Nos. 61572298, 61772322, U1836216), the Key
   Research and Development Foundation of Shandong Province (Nos.
   2017GGX10117, 2017CXGC0703), and the Natural Science Foundation of
   Shandong China (No. ZR2015PF006).
CR [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247923
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Huang X, 2018, PROC CVPR IEEE, P8837, DOI 10.1109/CVPR.2018.00921
   Ji Z, 2020, IEEE T NEUR NET LEAR, V31, P321, DOI 10.1109/TNNLS.2019.2904991
   Ji Z, 2018, PATTERN RECOGN LETT, V116, P205, DOI 10.1016/j.patrec.2018.10.020
   Ji Z, 2017, INFORM SCIENCES, V378, P48, DOI 10.1016/j.ins.2016.10.025
   Ji Z, 2015, IEEE T IMAGE PROCESS, V24, P4137, DOI 10.1109/TIP.2015.2437198
   Jian M, 2018, MULTIMED TOOLS APPL, V77, P1
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P14343, DOI 10.1007/s11042-017-5032-z
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jian MW, 2014, INFORM SCIENCES, V262, P1, DOI 10.1016/j.ins.2013.12.001
   Kang WC, 2016, AAAI CONF ARTIF INTE, P1230
   Lan XY, 2019, IEEE T IND ELECTRON, V66, P9887, DOI 10.1109/TIE.2019.2898618
   Lan XY, 2020, PATTERN RECOGN LETT, V130, P12, DOI 10.1016/j.patrec.2018.10.002
   Lan XY, 2018, AAAI CONF ARTIF INTE, P7008
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Li D., 2003, P 11 ACM INT C MULTI, P604
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Peng YX, 2018, IEEE T MULTIMEDIA, V20, P405, DOI 10.1109/TMM.2017.2742704
   Peng Yuxin, 2017, ARXIV171005106
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wang K., 2016, A comprehensive survey on cross-modal retrieval
   Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311
   Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261
   Wei YC, 2017, IEEE T CYBERNETICS, V47, P449, DOI 10.1109/TCYB.2016.2519449
   Wei YC, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2775109
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Wu JL, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P917, DOI 10.1145/3077136.3080678
   Wu YL, 2017, IEEE INT CON MULTI, P823, DOI 10.1109/ICME.2017.8019528
   Yan JH, 2018, MULTIMED TOOLS APPL, V77, P3009, DOI 10.1007/s11042-017-4918-0
   Zhai X., 2013, PROC 27 AAAI C ARTIF, P1198
   Zhai XH, 2014, IEEE T CIRC SYST VID, V24, P965, DOI 10.1109/TCSVT.2013.2276704
   Zhang HX, 2014, NEUROCOMPUTING, V139, P289, DOI 10.1016/j.neucom.2014.02.030
   Zhang HX, 2014, PATTERN RECOGN, V47, P3168, DOI 10.1016/j.patcog.2014.04.004
   Zhang HX, 2010, FUZZY SET SYST, V161, P1790, DOI 10.1016/j.fss.2009.11.013
   Zhang HX, 2009, KNOWL-BASED SYST, V22, P477, DOI 10.1016/j.knosys.2009.06.009
   Zhang L, 2018, IEEE T MULTIMEDIA, V20, P128, DOI 10.1109/TMM.2017.2723841
   Zhang L, 2017, IEEE T MULTIMEDIA, V19, P1220, DOI 10.1109/TMM.2016.2646219
   Zhang L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1355, DOI 10.1145/2964284.2964336
   Zhang MJ, 2019, J VIS COMMUN IMAGE R, V58, P1, DOI 10.1016/j.jvcir.2018.11.025
   Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415
   Zhu L., 2016, IJCAI, P3959
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
NR 50
TC 5
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 28285
EP 28307
DI 10.1007/s11042-019-07909-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000067
DA 2024-07-18
ER

PT J
AU Arce, P
   de Fez, I
   Belda, R
   Guerri, JC
   Ferrairó, S
AF Arce, Pau
   de Fez, Ismael
   Belda, Roman
   Carlos Guerri, Juan
   Ferrairo, Salvador
TI Proxy-based near real-time TV content transmission in mobility over 4G
   with MPEG-DASH transcoding on the cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Proxy; 4G; Video streaming; TV; Buffering; Dynamic adaptive streaming
   over HTTP (DASH); Quality of experience; ITU-T P; 1203
ID VIDEO; NETWORKS
AB This paper presents and evaluates a system that provides TV and radio services in mobility using 4G communications. The system has mainly two blocks, one on the cloud and another on the mobile vehicle. On the cloud, a DVB (Digital Video Broadcasting) receiver obtains the TV/radio signal and prepares the contents to be sent through 4G. Specifically, contents are transcoded and packetized using the DASH (Dynamic Adaptive Streaming over HTTP) standard. Vehicles in mobility use their 4G connectivity to receive the flows transmitted by the cloud. The key element of the system is an on-board proxy that manages the received flows and offers them to the final users in the vehicle. The proxy contains a buffer that helps reduce the number of interruptions caused by hand over effects and lack of coverage. The paper presents a comparison between a live transmission using 4G connecting the clients directly with the cloud server and a near real-time transmission based on an on-board proxy. Results prove that the use of the proxy reduces the number of interruptions considerably and, thus, improves the Quality of Experience of users at the expense of slightly increasing the delay.
C1 [Arce, Pau; de Fez, Ismael; Belda, Roman; Carlos Guerri, Juan] Univ Politecn Valencia, Inst Telecommun & Multimedia Applicat iTEAM, Camino Vera, E-46022 Valencia, Spain.
   [Ferrairo, Salvador] Azimut Elect, Carrer Furs 50, Valencia 46701, Spain.
C3 Universitat Politecnica de Valencia
RP Arce, P (corresponding author), Univ Politecn Valencia, Inst Telecommun & Multimedia Applicat iTEAM, Camino Vera, E-46022 Valencia, Spain.
EM paarvi@iteam.upv.es; isdefez@iteam.upv.es; robelor@iteam.upv.es;
   jcguerri@dcom.upv.es; ferrairo@azimut.es
RI de+Fez+Lava, Ismael/AAJ-1048-2020; Belda, Román/IAM-8676-2023; Arce,
   Pedro/L-1268-2014; Guerri, Juan Carlos/K-9659-2014
OI Belda, Roman/0000-0003-2244-2371; Guerri, Juan
   Carlos/0000-0002-5807-1923; de Fez, Ismael/0000-0002-1337-1973; Arce,
   Pau/0000-0001-5726-9228
FU Centro para el Desarrollo Tecnologico Industrial (CDTI) from Government
   of Spain [CDTI IDI-20150126, CDTI TIC-20170102]
FX This work is supported by the Centro para el Desarrollo Tecnologico
   Industrial (CDTI) from the Government of Spain under the project
   "Plataforma avanzada de conectividad en movilidad" (CDTI IDI-20150126)
   and the project "Desarrollo de nueva plataforma de entretenimiento
   multimedia para entornos nauticos" (CDTI TIC-20170102).
CR 3GPP, 2013, 126346 3GPP ETSI TS
   3GPP, 2017, EV UN TERR RAD ACC E
   Acharya S., 1995, SIGMOD Record, V24, P199, DOI 10.1145/568271.223816
   [Anonymous], 2017, ITUTP1203
   [Anonymous], 2012, 36913 3GPP TR
   [Anonymous], 2012, 230091 ISOIEC
   Bangerter B, 2014, IEEE COMMUN MAG, V52, P90, DOI 10.1109/MCOM.2014.6736748
   Chakareski J, 2014, IEEE T COMMUN, V62, P1350, DOI 10.1109/TCOMM.2014.022314.120890
   Chuang MC, 2015, IEEE SYST J, V9, P1264, DOI 10.1109/JSYST.2014.2354435
   Cisco, 2017, Cisco7 Feb.
   Digital Video Broadcasting (DVB), 2009, 102585 ETS ITS
   Digital Video Broadcasting (DVB), 2004, 302304 ETSI EN
   Erman J, 2011, IEEE INTERNET COMPUT, V15, P27, DOI 10.1109/MIC.2010.154
   Evans BG, 2014, ADV SAT MULTMED SYS, P197, DOI 10.1109/ASMS-SPSC.2014.6934544
   Ghadiyaram D, 2019, IEEE T CIRC SYST VID, V29, P183, DOI 10.1109/TCSVT.2017.2768542
   GSMA intelligence, 2018, MAPP WORLDW 4G LTE N
   Gu ZQ, 2004, IEEE T BROADCAST, V50, P113, DOI 10.1109/TBC.2004.828365
   Hu H, 2013, IEEE T MULTIMEDIA, V15, P1638, DOI 10.1109/TMM.2013.2266092
   Int. Telecommun. Union, 2016, P8001 ITUT
   Kumar S, 2017, J NETW COMPUT APPL, V97, P126, DOI 10.1016/j.jnca.2017.08.015
   Lau CP, 2017, IEEE SYST J, V11, P2737, DOI 10.1109/JSYST.2015.2493180
   Malandrino F, 2017, VEH COMMUN, V8, P13, DOI 10.1016/j.vehcom.2016.11.007
   Ramanan BA, 2013, WIREL TELECOMM SYMP
   Robitza W, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P466, DOI 10.1145/3204949.3208124
   Samdanis K, 2012, IEEE COMMUN SURV TUT, V14, P884, DOI 10.1109/SURV.2011.072711.00168
   Tabrizi FM, 2013, IEEE T MOBILE COMPUT, V12, P995, DOI 10.1109/TMC.2012.56
   Taleb T, 2011, LECT NOTES COMPUT SC, V6640, P331, DOI 10.1007/978-3-642-20757-0_26
   Woo S., 2013, Proc. ACM Int. Conf. on Mobile Systems, Applications, P319
   Yrjölä S, 2017, IEEE T VEH TECHNOL, V66, P5422, DOI 10.1109/TVT.2016.2628088
   Zhao MC, 2015, IEEE T CIRC SYST VID, V25, P451, DOI 10.1109/TCSVT.2014.2357094
NR 30
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26399
EP 26425
DI 10.1007/s11042-019-07840-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700051
OA Green Published
DA 2024-07-18
ER

PT J
AU Celdrán, AH
   Pérez, MG
   Clemente, FJG
   Ippoliti, F
   Pérez, GM
AF Celdran, Alberto Huertas
   Gil Perez, Manuel
   Garcia Clemente, Felix J.
   Ippoliti, Fabrizio
   Martinez Perez, Gregorio
TI Dynamic network slicing management of multimedia scenarios for future
   remote healthcare
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Network slicing; SDN; NFV techniques; Dynamic network management;
   Multimedia services
ID 5G
AB ICT solutions must meet the requirements demanded by challenging and complex scenarios such as remote care, which can be viewed as a combination of heterogeneous services using multimedia and home-care tools. Network Slicing emerged to this end, a paradigm tailoring the needs of any scenario whose specifications need to be met at all times. For its implementation, the network flexibility and resource control features provided by the Software-Defined Networking (SDN) and Network Functions Virtualization (NFV) techniques can allow the Network Slicing paradigm to manage the peculiarities established by any given scenario, taking a special consideration to multimedia scenarios with particular needs such as low latency and high bandwidth. However, existing Network Slicing approaches lack management mechanisms to understand when resources and services have to be changed or reconfigured to continue meeting the requirements, what elements would be involved in this updating process, and how changes would have to be performed. This article addresses this challenge by proposing an architecture able to manage the complete life cycle of Network Slices and to determine when, what, and how to dynamically orchestrate the resources and services so as to meet the scenario requirements. This SDN/NFV-enabled architecture allows managing the underlying infrastructure at run-time through policies, which use a formal Network Slicing information model based on ontologies also proposed in this article. Also, a complete use case is exercised to face the specific requirements of a given eHealth scenario with multimedia services, whose feasibility is demonstrated through a number of conducted experiments.
C1 [Celdran, Alberto Huertas] Waterford Inst Technol, Syst Grp, Telecommun Software, Waterford X91 K0EK, Ireland.
   [Gil Perez, Manuel; Martinez Perez, Gregorio] Univ Murcia, Dept Ingn Informac & Comunicac, E-30071 Murcia, Spain.
   [Garcia Clemente, Felix J.] Univ Murcia, Dept Ingn & Tecnol Comp, E-30071 Murcia, Spain.
   [Ippoliti, Fabrizio] Univ Camerino, Sch Sci & Technol, Div Comp Sci, I-62032 Camerino, Italy.
C3 South East Technological University (SETU); University of Murcia;
   University of Murcia; University of Camerino
RP Celdrán, AH (corresponding author), Waterford Inst Technol, Syst Grp, Telecommun Software, Waterford X91 K0EK, Ireland.
EM ahuertas@tssg.org; mgilperez@um.es; fgarcia@um.es;
   fabrizio.ippoliti@unicam.it; gregorio@um.es
RI Clemente, Félix Jesús Garcia/AAM-8396-2020; Perez, Gregorio
   Martinez/I-7620-2013
OI Clemente, Félix Jesús Garcia/0000-0001-6181-5033; Gil Perez,
   Manuel/0000-0002-7768-9665; Huertas Celdran, Alberto/0000-0001-7125-1710
FU Seneca Foundation grant within the Human Resources Researching
   Postdoctoral Program 2018; Irish Research Council, under the government
   of Ireland [GOIPD/2018/466]; post-doctoral INCIBE grants within the
   "Ayudas para la Excelencia de los Equipos de Investigacion Avanzada en
   Ciberseguridad" Program [INCIBEI-2015-27352]
FX This work has been supported by a Seneca Foundation grant within the
   Human Resources Researching Postdoctoral Program 2018; by the Irish
   Research Council, under the government of Ireland post-doc fellowship
   (grant GOIPD/2018/466); and by a post-doctoral INCIBE grants within the
   "Ayudas para la Excelencia de los Equipos de Investigacion Avanzada en
   Ciberseguridad" Program, with code INCIBEI-2015-27352.
CR Afolabi I, 2018, IEEE COMMUN SURV TUT, V20, P2429, DOI 10.1109/COMST.2018.2815638
   [Anonymous], 2016, P VDE 22 EUR WIR C
   [Anonymous], 2004, W3C MEMB SUBMISS
   [Anonymous], 2015, SELFNET FRAM SELF OR
   [Anonymous], 2013, SPARQL 1 1 QUERY LAN
   [Anonymous], PROTEGE FREE OPEN SO
   Awada A, 2017, 2017 IEEE CONFERENCE ON STANDARDS FOR COMMUNICATIONS AND NETWORKING (CSCN), P18, DOI 10.1109/CSCN.2017.8088592
   Cacheda R.A., 2007, Resource Management in Satellite Networks, P67, DOI 10.1007/978-0-387-53991-1_3
   da Silva I, 2016, 2016 EUROPEAN CONFERENCE ON NETWORKS AND COMMUNICATIONS (EUCNC), P153, DOI 10.1109/EuCNC.2016.7561023
   De Turck F, 2015, IEEE T NETW SERV MAN, V12, P114, DOI 10.1109/TNSM.2015.2433899
   Distributed Management Task Force Inc, 2018, CIM STAND COMM INF M
   ETSI TC ITS, 2015, INFR OV ETSI GS NFV, V1, P1
   Ferrús R, 2018, IEEE COMMUN MAG, V56, P184, DOI 10.1109/MCOM.2017.1700268
   Foukas X, 2017, IEEE COMMUN MAG, V55, P94, DOI 10.1109/MCOM.2017.1600951
   Gavras A, 2017, 2017 GLOBAL WIRELESS SUMMIT (GWS), P165, DOI 10.1109/GWS.2017.8300479
   Gutz S., 2012, Proceedings of the first workshop on Hot topics in software defined networks, ACM, P79
   H2020 Euro-5G Project, 2017, DEL 2 6 FIN REP PROG
   H2020 SELFNET Project, 2016, DEL 2 4 PORT TESTB E, DOI [10.18153/SLF-671672-D2_4, DOI 10.18153/SLF-671672-D2_4]
   H2020 SoftFIRE Project, 2017, DEL 3 1 KPIS EV ASS
   Celdrán AH, 2019, MOBILE NETW APPL, V24, P657, DOI 10.1007/s11036-016-0783-8
   Celdrán AH, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON SOFTWARE DEFINED SYSTEMS (SDS), P153, DOI 10.1109/SDS.2018.8370437
   Celdrán AH, 2017, ANN TELECOMMUN, V72, P577, DOI 10.1007/s12243-017-0582-7
   Li X, 2017, IEEE INTERNET COMPUT, V21, P20, DOI 10.1109/MIC.2017.3481355
   Li Z, 2012, 2012 ACM/IEEE 13TH INTERNATIONAL CONFERENCE ON GRID COMPUTING (GRID), P164, DOI 10.1109/Grid.2012.15
   Makhijani K., 2017, NETWORK SLICING USE
   Modi Kirit J., 2019, Progress in Advanced Computing and Intelligent Engineering. Proceedings of ICACIE 2017. Advances in Intelligent Systems and Computing (AISC 714), P63, DOI 10.1007/978-981-13-0224-4_6
   NGMN Alliance, 2016, DESCR NETW SLIC CONC
   OASIS, 2017, TOP ORCH SPEC CLOUD
   Open Baton Project, 2017, ETSI NFV COMPL MANO
   Open Networking Foundation, 2016, TR 526 APPL SDN ARCH
   OpenDaylight Project, 2016, OP SOURC SDN PLATF
   OpenStack Project, 2016, OP SOURC SOFTW CREAT
   Ordonez-Lucena J, 2017, IEEE COMMUN MAG, V55, P80, DOI 10.1109/MCOM.2017.1600935
   Qiang L., 2017, GAP ANAL TRANSPORT N
   Ravindran R, 2017, IEEE COMMUN MAG, V55, P101, DOI 10.1109/MCOM.2017.1600938
   Raza M. T., 2017, PROC IEEE INT C NETW, P1
   Richart M., 2017, 2017 13 INT C NETW S, P1, DOI DOI 10.23919/CNSM.2017.8256046
   Riegel M, 2017, KEY CONCEPTS NETWORK
   Rost P, 2017, IEEE COMMUN MAG, V55, P72, DOI 10.1109/MCOM.2017.1600920
   Schneider P, 2018, IEEE WCNC
   Sherwood R, 2010, ACM SIGCOMM COMP COM, V40, P129, DOI 10.1145/1672308.1672333
   Sirin E, 2007, J WEB SEMANT, V5, P51, DOI 10.1016/j.websem.2007.03.004
   Solozabal R, 2018, IFIP ADV INF COMM TE, V519, P520, DOI 10.1007/978-3-319-92007-8_44
   Soon-Shiong P, 2018, US Patent App, V15, P494, Patent No. 15727494
   Srivats P., 2018, Ostinato packet generator
   Taleb T, 2017, IEEE COMMUN MAG, V55, P88, DOI 10.1109/MCOM.2017.1600947
   University of Murcia, 2018, COMPL DEF NETW SLIC
   W3C, 2012, OWL 2 WEB ONTOLOGY L
   Zhang HJ, 2017, IEEE COMMUN MAG, V55, P138, DOI 10.1109/MCOM.2017.1600940
   Zhou X, 2016, IEEE COMMUN MAG, V54, P146, DOI 10.1109/MCOM.2016.7509393
NR 50
TC 9
Z9 9
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24707
EP 24737
DI 10.1007/s11042-019-7283-3
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900048
DA 2024-07-18
ER

PT J
AU Dvir, A
   Harel, N
   Dubin, R
   Barkan, R
   Shalala, R
   Hadar, O
AF Dvir, Amit
   Harel, Nissim
   Dubin, Ran
   Barkan, Refael
   Shalala, Raffael
   Hadar, Ofer
TI MiSAL-A minimal quality representation switch logic for adaptive
   streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DASH; Adaptation logic; Quality of experience
ID VIDEO; ADAPTATION
AB Quality of Experience is affected by many parameters. For this reason, client-side adaptation logic algorithms often adopt the strategy of optimizing a subset of parameters in the hope of improving the overall QoE. However, as shown here, this approach ends up degrading parameters that are crucial to good Quality of Experience. To resolve this conundrum, we present a new approach for improved Quality of Experience dubbed: Minimal Switch AL (MiSAL). This algorithm substantially reduces the number of quality level switches by monitoring the client buffer level and carefully estimating the channel bandwidth and the Round Trip Time. A comparison of MiSAL against leading ALs demonstrates that this approach successfully in optimizes several important parameters that affect Quality of Experience without negatively affecting other parameters. It is shown that MiSAL can provide a close to optimal QoE under many different network conditions.
C1 [Dvir, Amit; Dubin, Ran] Ariel Univ, Dept Comp Sci, Ariel Cyber Innovat Ctr, Ariel, Israel.
   [Harel, Nissim] Holon Inst Technol, Dept Comp Sci, Holon, Israel.
   [Barkan, Refael] Holon Inst Technol, Dept Appl Math, Holon, Israel.
   [Shalala, Raffael; Hadar, Ofer] Ben Gurion Univ Negev, Commun Syst Engn, Beer Sheva, Israel.
C3 Ariel University; Ben Gurion University
RP Dvir, A (corresponding author), Ariel Univ, Dept Comp Sci, Ariel Cyber Innovat Ctr, Ariel, Israel.
EM amitdv@ariel.ac.il
RI Dubin, Ran/CAF-1102-2022; HADAR, OFER/F-2051-2012; Dubin,
   Ran/HIR-5440-2022; dvir, amit/AAV-5916-2021
OI Dubin, Ran/0000-0002-2055-2211; dvir, amit/0000-0002-3670-0784; Hadar,
   Ofer/0000-0002-6089-8401; Shalala, Rafael/0009-0005-0832-2236
FU Israeli NET-HD consortium
FX This research was partially supported by the Israeli NET-HD consortium.
   The authors wish to thank Ofir Ahrak for his helpful discussions and
   advice.
CR [Anonymous], 2014, P 13 ACM WORKSH HOT
   [Anonymous], 2011, Proc. second annu. acm conf. multimed. syst.-mmsys'11, DOI DOI 10.1145/1943552.1943574
   [Anonymous], 2013, PERF EV WIR HOC SENS
   [Anonymous], METH SUBJ ASS VID QU
   [Anonymous], 6 INT WORKSH QUAL MU
   [Anonymous], 2014, TECHNICAL REPORT
   [Anonymous], 6 INT WORKSH QUAL MU
   [Anonymous], 2016, ARXIV160600341
   [Anonymous], VLC SOURC COD
   [Anonymous], THESIS ICT SWEDEN
   [Anonymous], 2013, White Paper
   [Anonymous], 2013, P IEEE 20 INT PACK V
   [Anonymous], ELECT IMAGING 2007
   [Anonymous], P 4 INT WORKSH PERC
   [Anonymous], IEEE ICC WORKSH QUAL
   Cisco, 2017, CISC VIS NETW IND GL
   Claeys M, 2014, CONNECT SCI, V26, DOI 10.1080/09540091.2014.885273
   Cranley N, 2006, INT J HUM-COMPUT ST, V64, P637, DOI 10.1016/j.ijhcs.2005.12.002
   Dai H., 2011, Acta Horticulturae, P169, DOI 10.1145/1943552.1943575
   De Vriendt J, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P1288
   Dubin R, 2018, MULTIMEDIA SYST, V24, P19, DOI 10.1007/s00530-016-0525-6
   Dubin R, 2013, 2013 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE (WCNC), P2178
   Hossfeld T, 2015, COMPUT NETW, V81, P320, DOI 10.1016/j.comnet.2015.02.015
   Jiang JC, 2014, IEEE ACM T NETWORK, V22, P326, DOI 10.1109/TNET.2013.2291681
   Li YT, 2017, MULTIMED TOOLS APPL, V76, P20781, DOI 10.1007/s11042-016-4002-1
   Li YT, 2014, NEURAL COMPUT APPL, V25, P1845, DOI 10.1007/s00521-014-1674-1
   Mok R.K., 2012, P 3 MULTIMEDIA SYSTE, P11
   Moorthy AK, 2012, IEEE J-STSP, V6, P652, DOI 10.1109/JSTSP.2012.2212417
   Mueller G, 2012, TLS-TIMES LIT SUPPL, P6
   Muller C., 2012, 4th ACM Workshop on Mobile Video (MoVID), P37, DOI DOI 10.1145/2151677.2151686
   Pantos R., 2012, Http live streaming
   Pinson M, 2003, PROC SPIE, V5150, P573, DOI 10.1117/12.509908
   Rickinson M, 2011, IMPROV LEARN TLRP, P1
   Seufert M, 2015, IEEE COMMUN SURV TUT, V17, P469, DOI 10.1109/COMST.2014.2360940
   Sieber C, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P1318
   Streijl RC, 2016, MULTIMEDIA SYST, V22, P213, DOI 10.1007/s00530-014-0446-1
   Tingyao Wu, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P553, DOI 10.1007/978-3-319-04114-8_47
   Thang TC, 2012, 2012 FOURTH INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND ELECTRONICS (ICCE), P130, DOI 10.1109/CCE.2012.6315884
   Zink M, 2005, IEEE T MULTIMEDIA, V7, P75, DOI 10.1109/TMM.2004.840595
   Zink M, 2003, LECT NOTES COMPUT SC, V2707, P137
NR 40
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26483
EP 26508
DI 10.1007/s11042-019-07865-x
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700054
DA 2024-07-18
ER

PT J
AU Mahalingam, T
   Subramoniam, M
AF Mahalingam, T.
   Subramoniam, M.
TI A hybrid gray wolf and genetic whale optimization algorithm for
   efficient moving object analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Detection; Modified kernel fuzzy c-means (MKFCM); Optimal weighted
   centroid (OWC); Whales optimization (WO); Gray wolf optimization (GWO);
   Blob; Classification
ID PARTICLE FILTER; TRACKING; MOTION; VIDEO; MODEL
AB Object detection in realistic situations needs various essential applications. The foremost applications of machine vision like vision based monitoring system, object tracking etc. require background subtraction (BS) complied with identification of motion objects. Segregating forefront from background is a challenging task in videos discovered through motion cam since either forefront or background relevant information varies in each successive frame of the video series; hence a pseudo-motion is sensitive with background. Modified Kernel fuzzy c-means technique still bears a few drawbacks, for example, decreased convergence rate, acquiring stuck in the local minima and also in risk to instatement level of sensitivity. To overcome the above problems, here we recommend a technique for information clustering utilizing the OWC (Optimal Weighted Centroid) procedure that decides the optimum centroid for playing out the clustering procedure. To overcome the issues, here we recommend a technique Optimal Background separation using Optimal Weighted Centroid (OWC) - Modified Kernel Fuzzy C Means Algorithm (MKFCM) for information clustering utilizing the OWC (Optimal Weighted Centroid) procedure that decides the optimum centroid for playing out the clustering procedure. The OWC procedure makes use of the procedural activities of the Whale Optimization algorithm (WOA) with the fusion of the Grey Wolf Optimization (GWO). The prescribed new procedure is dynamic clustering technique for splitting up of moving object. Moving object tracking is accomplished through the blob detection which comes under the tracking stage. The examination stage has attribute extraction and also classification. Appearance-based as well as high quality based attributes are drawn out from the refined frames which are provided for classification. Since classification we are making use of J48 (C4.5) i.e., decision tree based classifier. The efficiency of the recommended strategy is examined with preceding strategies k-NN as well as MLP in regard to accuracy, f-measure, ROC as well as recall.
C1 [Mahalingam, T.] Sathyabama Univ, Chennai, Tamil Nadu, India.
   [Subramoniam, M.] Sathyabama Univ, Deapartment Elect & Commun Engn, Chennai, Tamil Nadu, India.
C3 Sathyabama Institute of Science & Technology; Sathyabama Institute of
   Science & Technology
RP Mahalingam, T (corresponding author), Sathyabama Univ, Chennai, Tamil Nadu, India.
EM lingamdivya17@gmail.com; subramaniam.viru@gmail.com
RI M, Subramoniam/A-4502-2017; Subramoniam, M/ABI-7985-2020; thangaraj,
   mahalingam/AAG-3346-2021
OI M, Subramoniam/0000-0002-3004-5141; 
CR Abdel-Hadi A, 2010, ICCES'2010: THE 2010 INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS, P337, DOI 10.1109/ICCES.2010.5674880
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   Azab MM, 2014, IET IMAGE PROCESS, V8, P794, DOI 10.1049/iet-ipr.2014.0238
   de Lima LM, 2011, ADV INTEL SOFT COMPU, V96, P209
   del Rincón JM, 2011, IEEE T SYST MAN CY B, V41, P26, DOI 10.1109/TSMCB.2010.2044041
   Duffner S, 2016, IEEE T CIRC SYST VID, V26, P2215, DOI 10.1109/TCSVT.2015.2504739
   Gurkan F, 2019, DIGIT SIGNAL PROCESS, V87, P112, DOI 10.1016/j.dsp.2019.01.017
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Hu WC, 2015, J VIS COMMUN IMAGE R, V30, P164, DOI 10.1016/j.jvcir.2015.03.003
   Jadhav AN, 2018, ALEX ENG J, V57, P1569, DOI 10.1016/j.aej.2017.04.013
   Jadhav AN, 2016, J TEKNOL, V78, P65
   Kanagamalliga S, 2018, OPTIK, V157, P787, DOI 10.1016/j.ijleo.2017.11.181
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Kwok N. M., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P2935
   Li LY, 2008, IEEE T SYST MAN CY B, V38, P1254, DOI 10.1109/TSMCB.2008.927265
   Mahalingam T., 2018, APPL COMPUTING INFOR
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirunalini P, 2017, TENCON IEEE REGION, P1290, DOI 10.1109/TENCON.2017.8228056
   Ray KS, 2019, J VIS COMMUN IMAGE R, V58, P662, DOI 10.1016/j.jvcir.2018.12.002
   Rezaei H, 2018, STUDIES COMPUTATIONA, P720
   Shijila B, 2019, FUTURE GENER COMP SY, V90, P198, DOI 10.1016/j.future.2018.07.065
   Shuai H, 2017, IEEE ACCESS
   Tian S, 2016, NEUROCOMPUTING, V171, P768, DOI 10.1016/j.neucom.2015.07.028
   Tsai CY, 2007, LECT NOTES COMPUT SC, V4705, P1107
   Wei YH, 2015, ADV DATA ANAL CLASSI, V9, P197, DOI 10.1007/s11634-014-0182-6
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu-Chih H, 2015, J VIS COMMUN IMAGE R, V30, P64, DOI [10.1016/j.jvcir.2015.03.011, DOI 10.1016/J.JVCIR.2015.03.011]
   Xiao F, 2018, SIGNAL PROCESS, V144, P392, DOI 10.1016/j.sigpro.2017.10.019
   Yin S, 2011, COMPUT VIS IMAGE UND, V115, P885, DOI 10.1016/j.cviu.2011.02.010
   Yu T, 2004, PROC CVPR IEEE, P834
   Zhang B, 2008, AEU-INT J ELECTRON C, V62, P24, DOI 10.1016/j.aeue.2007.01.006
   Zhang S, 2015, IEEE SENS J, V15, P2679, DOI 10.1109/JSEN.2014.2382174
   Zhang X, 2008, PROC CVPR IEEE, P117
   Zhao J, 2010, EXPERT SYST APPL, V37, P8910, DOI 10.1016/j.eswa.2010.05.086
   Zhao T, 2004, IEEE T PATTERN ANAL, V26, P1208, DOI 10.1109/TPAMI.2004.73
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
NR 37
TC 6
Z9 7
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26633
EP 26659
DI 10.1007/s11042-019-07768-x
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700060
DA 2024-07-18
ER

PT J
AU Naqi, SM
   Sharif, M
   Lali, IU
AF Naqi, Syed Muhammad
   Sharif, Muhammad
   Lali, Ikram Ullah
TI A 3D nodule candidate detection method supported by hybrid features to
   reduce false positives in lung nodule detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Computed tomography; False positive reduction; Nodule
   candidate detection; Hybrid features
ID IMAGE DATABASE CONSORTIUM; COMPUTER-AIDED DIAGNOSIS; PULMONARY NODULES;
   AUTOMATIC DETECTION; SEGMENTATION; CLASSIFICATION; ENSEMBLE; SELECTION;
   RESOURCE; LIDC
AB Lungs cancer is a fatal disease. However, its early detection increases the chances of survival among patients. An automated nodule detection system provides the second opinion to radiologists in early diagnosis. In this paper, an automated technique for nodule detection and classification is presented. Firstly, the lung region is extracted on the basis of the optimal gray level threshold. In the next phase, a novel hybrid 3D nodule candidate detection method is presented, comprises of Active Contour Model (ACM), 3D neighborhood connectivity and geometric properties based rules. A hybrid feature vector is created, by combining geometric texture and Histogram of Oriented Gradient reduced by Principle Component Analysis (HOG-PCA) features, for each nodule candidate. After feature extraction, classification is performed by applying four different classifiers including k-Nearest Neighborhood (k-NN), Naive Bayesian, Support Vector Machine (SVM) and AdaBoost. The evaluation is performed over Lung Image Database Consortium (LIDC) database. It is evident that AdaBoost has outperformed all other classifiers regarding accuracy, sensitivity, specificity and FPs/scan. Moreover, the proposed technique has shown significantly better results as compared to other existing methods reported in the literature.
C1 [Naqi, Syed Muhammad; Sharif, Muhammad] COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Wah Cantt, Pakistan.
   [Lali, Ikram Ullah] Univ Gujrat, Dept Comp Sci, Gujrat, Pakistan.
C3 COMSATS University Islamabad (CUI); University of Gujrat
RP Naqi, SM (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Wah Cantt, Pakistan.
EM smnaqi@qau.edu.pk
RI Sharif, Muhammad/AAB-8376-2022; Naqi, Syed Muhammad/JOZ-2015-2023; Lali,
   Ikram Ullah/V-4076-2019; Sharif, Muhammad/ACD-2598-2022
OI Sharif, Muhammad/0000-0002-7258-8400
CR Ali I, 2018, FRONT ONCOL, V8, DOI 10.3389/fonc.2018.00108
   [Anonymous], INT J COMPUTER ASSIS
   [Anonymous], 2019, CANC FACT SHEET
   [Anonymous], J AMBIENT INTELL HUM
   Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204
   Armato SG, 2004, RADIOLOGY, V232, P739, DOI 10.1148/radiol.2323032035
   Armato SG, 2003, INT CONGR SER, V1256, P977, DOI 10.1016/S0531-5131(03)00388-1
   Badura P, 2014, COMPUT BIOL MED, V53, P230, DOI 10.1016/j.compbiomed.2014.08.005
   Netto SMB, 2017, MULTIMED TOOLS APPL, V76, P18929, DOI 10.1007/s11042-017-4414-6
   Netto SMB, 2012, COMPUT BIOL MED, V42, P1110, DOI 10.1016/j.compbiomed.2012.09.003
   Cao P, 2014, COMPUT MED IMAG GRAP, V38, P137, DOI 10.1016/j.compmedimag.2013.12.003
   Choi WJ, 2014, COMPUT METH PROG BIO, V113, P37, DOI 10.1016/j.cmpb.2013.08.015
   Choi WJ, 2012, INFORM SCIENCES, V212, P57, DOI 10.1016/j.ins.2012.05.008
   da Silva GLF, 2017, MULTIMED TOOLS APPL, V76, P19039, DOI 10.1007/s11042-017-4480-9
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   de Carvalho AO, 2014, ARTIF INTELL MED, V60, P165, DOI 10.1016/j.artmed.2013.11.002
   Dehmeshki J, 2007, COMPUT MED IMAG GRAP, V31, P408, DOI 10.1016/j.compmedimag.2007.03.002
   Dou Q, 2017, IEEE T BIO-MED ENG, V64, P1558, DOI 10.1109/TBME.2016.2613502
   Farahani FV, 2018, MATH COMPUT SIMULAT, V149, P48, DOI 10.1016/j.matcom.2018.02.001
   Foody GM, 2004, IEEE T GEOSCI REMOTE, V42, P1335, DOI 10.1109/TGRS.2004.827257
   Han H, 2015, IEEE J BIOMED HEALTH, V19, P648, DOI 10.1109/JBHI.2014.2328870
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huidrom R, 2019, SIGNAL IMAGE VIDEO P, V13, P53, DOI 10.1007/s11760-018-1327-4
   Jaffar A., 2018, Neural Comput & Applic, P1
   Jaffar MA, 2018, MULTIMED TOOLS APPL, P1
   Jemal A, 2010, CA-CANCER J CLIN, V60, P277, DOI 10.3322/caac.20073
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Khan MA, 2019, PATTERN ANAL APPL, V22, P1377, DOI 10.1007/s10044-018-0688-1
   Kuruvilla J, 2014, COMPUT METH PROG BIO, V113, P202, DOI 10.1016/j.cmpb.2013.10.011
   Li GZ, 2008, BMC GENOMICS, V9, DOI 10.1186/1471-2164-9-S2-S24
   Li H, 2001, IEEE T MED IMAGING, V20, P289, DOI 10.1109/42.921478
   Lu L, 2015, MED PHYS, V42, P5042, DOI 10.1118/1.4927573
   Mattoccia S, 2011, PATTERN RECOGN LETT, V32, P694, DOI 10.1016/j.patrec.2010.12.004
   Messay T, 2010, MED IMAGE ANAL, V14, P390, DOI 10.1016/j.media.2010.02.004
   Mukherjee I, 2013, J MACH LEARN RES, V14, P2315
   Mukhopadhyay S, 2016, J DIGIT IMAGING, V29, P86, DOI 10.1007/s10278-015-9801-9
   Naqi SM, 2018, CURR MED IMAGING, V14, P108, DOI 10.2174/1573405613666170306114320
   Naqi SM, 2017, CURR MED IMAGING, V13, P3, DOI 10.2174/1573405612666160610093453
   Naqi SM, 2018, INT J COMPUT ASS RAD, V13, P1083, DOI 10.1007/s11548-018-1715-9
   Rätsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488
   Reeves AP, 2007, ACAD RADIOL, V14, P1475, DOI 10.1016/j.acra.2007.09.005
   Reeves AP, 2000, SEMIN ULTRASOUND CT, V21, P116, DOI 10.1016/S0887-2171(00)90018-0
   Samanthula BK, 2015, IEEE T KNOWL DATA EN, V27, P1261, DOI 10.1109/TKDE.2014.2364027
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Shen SW, 2015, COMPUT BIOL MED, V57, P139, DOI 10.1016/j.compbiomed.2014.12.008
   Sluimer I, 2006, IEEE T MED IMAGING, V25, P385, DOI 10.1109/TMI.2005.862753
   Tasci E, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0231-5
   Teramoto A, 2018, INTEL SYST REF LIBR, V140, P87, DOI 10.1007/978-3-319-68843-5_4
   Ukil S, 2009, IEEE T MED IMAGING, V28, P202, DOI 10.1109/TMI.2008.929101
   Wang ZX, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0164416
   Xue B, 2014, APPL SOFT COMPUT, V18, P261, DOI 10.1016/j.asoc.2013.09.018
   Ye XJ, 2009, IEEE T BIO-MED ENG, V56, P1810, DOI 10.1109/TBME.2009.2017027
   Yim Y, 2008, COMPUT BIOL MED, V38, P845, DOI 10.1016/j.compbiomed.2008.04.012
   Zhang H, 2005, INT J PATTERN RECOGN, V19, P183, DOI 10.1142/S0218001405003983
   Zhang WH, 2018, COMPUT BIOL MED, V92, P64, DOI 10.1016/j.compbiomed.2017.11.008
NR 55
TC 26
Z9 27
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26287
EP 26311
DI 10.1007/s11042-019-07819-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700047
DA 2024-07-18
ER

PT J
AU Oueida, S
   Aloqaily, M
   Ionescu, S
AF Oueida, Soraia
   Aloqaily, Moayad
   Ionescu, Sorin
TI A smart healthcare reward model for resource allocation in smart city
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart healthcare; E-health; Multimedia technologies; Telemedicine;
   Reward system; Resource allocation; Smart city
ID EMERGENCY-DEPARTMENT; DEVICES; MULTIMEDIA; INTERNET; THINGS
AB Today, cities face many significant challenges, and the smart city concept is a promising means to address typical traditional city problems. The wireless e-health technologies is an evolving topic in the area of telemedicine nowadays. Mobile telecommunication and the use of multimedia technologies are the core of providing better access to healthcare personnel on the move. These technologies provide equal access to medical information and expert care leading to a better and a more efficient use of resources. Mobile and Fog computing technologies can also cope with many challenges in smart healthcare resources of mobility, scalability, efficiency, and reliability. Optimal healthcare systems are particularly critical in cities, due to the highly concentrated populations. This high population increases the potential for harm and damage in the case of negligence or improper treatment. This can lead to infections and disease outbreaks, which could become epidemic situations and require containment, which is very costly. Motivated by the need for better usage and management of healthcare resources, which is crucial for reliable healthcare delivery, this paper introduces a model that can provide improved delivery and utilization of resources. The quality reward-based model was developed to study and react to the satisfaction factors of healthcare systems, and proposes an optimization-based algorithm called the Maximum Reward Algorithm (MRA), that enhances the use and delivery of healthcare resources. The algorithm has been tested with multiple experiments and simulations, and has proved that it can provide reliability, efficiency and achieves 50.1% to 77.2% performance improvement.
C1 [Oueida, Soraia] Univ Politehn Bucuresti, Bucharest, Romania.
   [Aloqaily, Moayad] Australian Coll Kuwait, Management Informat Syst, Kuwait, Kuwait.
   [Ionescu, Sorin] Univ Politehn Bucuresti, Dept Ind Engn, Bucharest, Romania.
C3 National University of Science & Technology POLITEHNICA Bucharest;
   National University of Science & Technology POLITEHNICA Bucharest
RP Oueida, S (corresponding author), Univ Politehn Bucuresti, Bucharest, Romania.
EM So.oueida@upb.ro; m.aloqaily@ack.edu.kw; Sc.Ionescu@upb.ro
RI Aloqaily, Moayad/AAV-9016-2021; Oueida, Soraia/ACV-9849-2022; Aloqaily,
   Moayad/AAJ-2598-2020
OI Oueida, Soraia/0000-0002-6720-2307; Aloqaily, Moayad/0000-0003-2443-7234
CR Al Haddad Andre, 2017, 2017 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2017.8087761
   Al Ridhawi I, 2018, T EMERG TELECOMMUN T, V29, DOI 10.1002/ett.3446
   Al-Habashna A, 2018, MOBILE NETW APPL, V23, P543, DOI 10.1007/s11036-017-0906-x
   Andaleeb S S, 1998, Int J Health Care Qual Assur Inc Leadersh Health Serv, V11, P181, DOI 10.1108/09526869810231541
   Anjomshoa F, 2017, IEEE ACCESS, V5, P12199, DOI 10.1109/ACCESS.2017.2719706
   [Anonymous], CLUSTER COMPUTING
   [Anonymous], 2017, INT J USER DRIVEN HE, DOI DOI 10.4018/IJUDH.2017070101
   [Anonymous], HDB RES DATA SCI EFF
   [Anonymous], 2017, CLOUD COMPUTING ADOP
   [Anonymous], CLUSTER COMPUTING
   [Anonymous], INT C MAN IND ENG
   [Anonymous], KEY CONCEPTS HEALTHC
   Buckley BJ, 2010, J EMERG MED, V39, P669, DOI 10.1016/j.jemermed.2008.11.022
   Catarinucci L, 2015, IEEE INTERNET THINGS, V2, P515, DOI 10.1109/JIOT.2015.2417684
   Centeno MA, 2003, PROCEEDINGS OF THE 2003 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P1930, DOI 10.1109/WSC.2003.1261656
   Cook DJ, 2018, P IEEE, V106, P708, DOI 10.1109/JPROC.2017.2787688
   Demirkan H, 2013, IT PROF, V15, P38, DOI 10.1109/MITP.2013.35
   Duguay C, 2007, SIMUL-T SOC MOD SIM, V83, P311, DOI 10.1177/0037549707083111
   Elmisery AM, 2019, CLUSTER COMPUT, V22, P1611, DOI 10.1007/s10586-017-1298-1
   Farahani B, 2018, FUTURE GENER COMP SY, V78, P659, DOI 10.1016/j.future.2017.04.036
   Granados J, 2014, 2014 EAI 4TH INTERNATIONAL CONFERENCE ON WIRELESS MOBILE COMMUNICATION AND HEALTHCARE (MOBIHEALTH), P279, DOI [10.1109/MOBIHEALTH.2014.7015965, 10.4108/icst.mobihealth.2014.257394]
   Hassan MM, 2017, FUTURE GENER COMP SY, V66, P48, DOI 10.1016/j.future.2015.12.016
   Hassanalieragh M, 2015, 2015 IEEE 12TH INTERNATIONAL CONFERENCE ON SERVICES COMPUTING (SCC 2015), P285, DOI 10.1109/SCC.2015.47
   Hignett S, 2018, ERGONOMICS, V61, P5, DOI 10.1080/00140139.2016.1245446
   Holden RJ, 2011, ANN EMERG MED, V57, P265, DOI 10.1016/j.annemergmed.2010.08.001
   Islam SMR, 2015, IEEE ACCESS, V3, P678, DOI 10.1109/ACCESS.2015.2437951
   Jemal H, 2015, LECT NOTES ARTIF INT, V9330, P408, DOI 10.1007/978-3-319-24306-1_40
   Kumar B., 2010, 2010 International Conference on Computer and Communication Technology (ICCCT 2010), P828, DOI 10.1109/ICCCT.2010.5640393
   Kuo Y., 2012, Pro- ceedings of the Winter Simulation Conference, P87
   Manso M, 2018, INTERNET THINGS-TECH, P169, DOI 10.1007/978-3-319-61300-0_9
   Morsing M., 2006, BUSINESS ETHICS EURO, V15, P323, DOI DOI 10.1111/J.1467-8608.2006.00460.X
   Naidu A, 2009, INT J HEALTH CARE Q, V22, P366, DOI 10.1108/09526860910964834
   Nam TaewooTheresa Pardo., 2011, Conceptualizing Smart City with Dimensions of Technology, People, and Institutions, P282
   Obinikpo AA, 2017, J SENS ACTUAT NETW, V6, DOI 10.3390/jsan6040026
   Otoum S, 2017, IEEE SENSOR LETT, V1, DOI 10.1109/LSENS.2017.2752719
   Otoum S, 2015, CAN CON EL COMP EN, P1109, DOI 10.1109/CCECE.2015.7129429
   Samaha S, 2003, PROCEEDINGS OF THE 2003 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P1907, DOI 10.1109/WSC.2003.1261652
   Song H., 2017, SMART CITIES FDN PRI, DOI DOI 10.1002/9781119226444
   Soremekun OA, 2011, J EMERG MED, V41, P686, DOI 10.1016/j.jemermed.2011.01.018
   Wilson A., 2016, Services marketing: Integrating customer focus across the firm
   Yang S, 2013, WIRELESS PERS COMMUN, V69, P229, DOI 10.1007/s11277-012-0570-1
   Zeng Z, 2012, J EMERG NURS, V38, P322, DOI 10.1016/j.jen.2011.03.005
   Ziyu Lv, 2010, Proceedings of the 2010 IEEE/ACM Int'l Conference on Green Computing and Communications (GreenCom) and Int'l Conference on Cyber, Physical and Social Computing (CPSCom), P699, DOI 10.1109/GreenCom-CPSCom.2010.84
NR 43
TC 44
Z9 44
U1 1
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24573
EP 24594
DI 10.1007/s11042-018-6647-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900042
DA 2024-07-18
ER

PT J
AU Wang, D
   Shang, B
   Wang, Q
   Wan, B
AF Wang, Di
   Shang, Bin
   Wang, Quan
   Wan, Bo
TI Semi-paired and semi-supervised multimodal hashing via cross-modality
   label propagation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal hashing; Semi-paired data; Label propagation; Cross-media
   retrieval
ID CODES
AB Due to the fast query speed and low storage cost, multimodal hashing methods have been attracting increasing attention in large-scale cross-media retrieval tasks. Most existing multimodal hashing methods can only handle fully-paired settings, where all data samples with different modalities are well paired. However, in practical applications, such fully-paired multimodal data may not be available. To this end, semi-paired multimodal hashing methods have been proposed by exploiting correlations between unpaired samples. Nevertheless, currently existing semi-paired hashing methods are unsupervised methods. When little supervised information is available, these methods cannot utilize supervised information to enhance the retrieval performance. To effectively utilize the limited supervised information, this paper proposed a novel hashing framework, named semi-paired and semi-supervised multimodal hashing (SSMH), to deal with the scenario where partial pairwise correspondences and labels are provided in advance for cross-media retrieval task. The proposed SSMH propagates the semantic labels from labeled multimodal samples to unlabeled multimodal samples, so that the label information of the entire multimodal training set is available. Then, most existing similarity graph based supervised multimodal hashing methods can be used to learn hashing codes. Therefore, the proposed framework can fully utilize the limited label information and pairwise correspondences to keep the semantic similarity for hashing codes. Thorough experiments on standard datasets show the superior performance of the proposed framework.
C1 [Wang, Di; Shang, Bin; Wang, Quan; Wan, Bo] Xidian Univ, Xian, Shaanxi, Peoples R China.
C3 Xidian University
RP Wang, Q (corresponding author), Xidian Univ, Xian, Shaanxi, Peoples R China.
EM qwang@xidian.edu.cn
RI ARSLAN, Okan/AAA-3232-2020
FU National Natural Science Foundation of China [61702394, 61572385,
   61711530248]; Postdoctoral Science Foundation of China [2018T111021,
   2017M613082]; Aeronautical Science Foundation of China [20171981008];
   Shaanxi Key Research and Development Program [2017ZDXM-GY-002];
   Fundamental Research Funds for the Central Universities [JBX170313,
   XJS17063]
FX This paper was supported in part by the National Natural Science
   Foundation of China under Grant 61702394, Grant 61572385 and Grant
   61711530248, in part by the Postdoctoral Science Foundation of China
   under Grant 2018T111021 and Grant 2017M613082, in part by the
   Aeronautical Science Foundation of China under Grant 20171981008, in
   part by the Shaanxi Key Research and Development Program under Grant
   2017ZDXM-GY-002, and in part by the Fundamental Research Funds for the
   Central Universities under Grant JBX170313 and Grant XJS17063.
CR [Anonymous], 2014, Hashing for similarity search: A survey
   [Anonymous], 2008, ADV NEURAL INFORM PR
   [Anonymous], ACM
   [Anonymous], ONLINE CROSS MODAL H
   [Anonymous], 2012, Book A probabilistic model for multimodal hash function learning, DOI DOI 10.1145/2339530.2339678
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chen L, 2014, IEEE T CYBERNETICS, V44, P1180, DOI 10.1109/TCYB.2013.2281366
   Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Jin ZM, 2014, IEEE T CYBERNETICS, V44, P1362, DOI 10.1109/TCYB.2013.2283497
   Kim S, 2012, LECT NOTES COMPUT SC, V7576, P538, DOI 10.1007/978-3-642-33715-4_39
   Kulis B, 2012, IEEE T PATTERN ANAL, V34, P1092, DOI 10.1109/TPAMI.2011.219
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   Lei Z, 2018, IEEE T NEURAL NETW L, V1, DOI [10.1109/TNNLS.2018.2872595, DOI 10.1109/TNNLS.2018.2872595]
   Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011
   Liu L, 2015, IEEE T IMAGE PROCESS, V24, P956, DOI 10.1109/TIP.2015.2390975
   Liu W., 2014, P NEURAL INF PROCESS, P3419
   Liu W, 2011, SER INF MANAGE SCI, V10, P1
   Liu X., 2012, PROC ACM MULTIMEDIA, P881
   Luo MN, 2017, COMPUT VIS IMAGE UND, V163, P67, DOI 10.1016/j.cviu.2017.07.001
   Luo X, 2018, ACM/SIGIR PROCEEDINGS 2018, P735, DOI 10.1145/3209978.3210035
   Nie LQ, 2017, IEEE T CYBERNETICS, V47, P3680, DOI 10.1109/TCYB.2016.2577590
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Shen XB, 2017, IEEE T CYBERNETICS, V47, P4275, DOI 10.1109/TCYB.2016.2606441
   Shen XB, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P831, DOI 10.1145/2733373.2806342
   Shen XB, 2016, NEUROCOMPUTING, V213, P14, DOI 10.1016/j.neucom.2016.01.121
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Song J., 2011, P 19 ACM INT C MULT, P423, DOI DOI 10.1145/2072298.2072354
   Wang D, 2016, IEEE T IMAGE PROCESS, V25, P4540, DOI 10.1109/TIP.2016.2592800
   Wang D, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3890
   Wang QF, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3904
   Wang S, 2016, IEEE T KNOWL DATA EN, V28, P3191, DOI 10.1109/TKDE.2016.2605687
   Wu BT, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3946
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhou DY, 2004, ADV NEUR IN, V16, P321
   Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
NR 40
TC 3
Z9 4
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24167
EP 24185
DI 10.1007/s11042-018-6858-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900021
DA 2024-07-18
ER

PT J
AU Zhong, JL
   Pun, CM
AF Zhong, Jun-Liu
   Pun, Chi-Man
TI Copy-move forgery detection using adaptive keypoint filtering and
   iterative region merging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive keypoint filtering; Iterative region merging; Copy-move forgery
   detection
AB Copy-move forgery detection can generally be divided into two categories: block-based or keypoint-based methods. However, the existing block-based methods are usually lack of efficiency and the keypoint-based methods have not good detection performance. In this paper, a novel method using the adaptive keypoint filtering and iterative region merging is proposed for copy-move forgery detection. First, a feature extraction algorithm is presented to obtain the candidate keypoint pairs. Subsequently, adaptive keypoint filtering involving adaptive nearest neighbor pair filtering and outlier filtering is proposed to remove the outliers and obtain the inlier (authentic keypoint) pairs. The iterative region merging involving adaptive region iteration and region merging is proposed to iteratively generate more neighboring keypoint pairs and then merge the image segmentations (superpixels) to implement the copy-move region matting. Compared with other state-of-the-art methods, a series of experiments show that the proposed method can overcome defects and achieve better efficiency while keeping the high detection precision in copy-move forgery detection even under conditions that include various post-processing distortions.
C1 [Zhong, Jun-Liu; Pun, Chi-Man] Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
C3 University of Macau
RP Pun, CM (corresponding author), Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
EM cmpun@umac.mo
RI Pun, Chi Man/GRJ-3703-2022; Silva, Isac/AAQ-4462-2021
OI Pun, Chi-Man/0000-0003-1788-3746
FU Research Committee of the University of Macau; Science and Technology
   Development Fund of Macau SAR [041/2017/A1]
FX This work was supported in part by the Research Committee of the
   University of Macau under GrantMYRG2018-00035-FST, and the Science and
   Technology Development Fund of Macau SAR under Grant 041/2017/A1.
CR Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], INT J COMPUT APPL
   [Anonymous], INT J ANTENNAS PROPA
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   Bi XL, 2016, INFORM SCIENCES, V345, P226, DOI 10.1016/j.ins.2016.01.061
   Bi XL., 2016, MULTIMED TOOLS APPL, V77, P1
   Caldelli R., 2012, 2012 5th International Symposium on Communications Control and Signal Processing, P1
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Debbarma S., 2014, 2014 International Conference on Informatics, Electronics Vision, P1
   Emam M, 2016, MULTIMED TOOLS APPL, V75, P11513, DOI 10.1007/s11042-015-2872-2
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Gan YF, 2015, INT J BIFURCAT CHAOS, V25, DOI 10.1142/S0218127415400180
   Huang HL, 2008, PACIIA: 2008 PACIFIC-ASIA WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION, VOLS 1-3, PROCEEDINGS, P1241
   Lee JC, 2015, INFORM SCIENCES, V321, P250, DOI 10.1016/j.ins.2015.03.009
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Liu QZ, 2017, PATTERN RECOGN, V65, P35, DOI 10.1016/j.patcog.2016.12.010
   Moussa AM, 2015, 2015 TENTH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES), P281, DOI 10.1109/ICCES.2015.7393060
   Popescu A., 2004, Hanover, Department of Computer Science, P32
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Saleh SQ, 2013, LECT NOTES COMPUT SC, V8034, P416, DOI 10.1007/978-3-642-41939-3_40
   Shivakumar B.L., 2011, International Journal of Computer Science Issues (IJCSI), V8
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Sudhakar K., 2014, 2014 International Conference on Advances in Electronics, Computers and Communications, P1
   Ustubioglu B, 2015, 2015 38TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P540, DOI 10.1109/TSP.2015.7296321
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Yap PT, 2010, IEEE T PATTERN ANAL, V32, P1259, DOI 10.1109/TPAMI.2009.119
   Zandi M, 2016, IEEE T INF FOREN SEC, V11, P2499, DOI 10.1109/TIFS.2016.2585118
   Zheng JB, 2016, MULTIDIM SYST SIGN P, V27, P989, DOI 10.1007/s11045-016-0416-1
   Zhong JL, 2017, MULTIMED TOOLS APPL, V76, P14887, DOI 10.1007/s11042-016-4201-9
NR 35
TC 6
Z9 8
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26313
EP 26339
DI 10.1007/s11042-019-07817-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700048
DA 2024-07-18
ER

PT J
AU Dhillon, PK
   Kalra, S
AF Dhillon, Parwinder Kaur
   Kalra, Sheetal
TI Secure and efficient ECC based SIP authentication scheme for VoIP
   communications in internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SIP; ECC; Authentication; VoIP; AVISPA
ID IPV4-IPV6 TRANSLATION; ACCESS-CONTROL; IMPROVEMENT; BIOMETRICS; PROTOCOL
AB Since last decade, VoIP is transitioning from being a voice scheme to the most powerful unified communications engine. All VoIP systems uses the Session Initiation Scheme that defines the procedures and messages used to set up a phone call - or any other kind of communication. IoT is another paradigm-shifting idea that is going to change VoIP communications, since it offers a seamless way to connect all of the devices, applications and platforms. Embedding VoIP in IoT solutions provides a competitive advantage over the traditional telephony system of being interconnected to Internet of Things. With the IoT, value proposition of VoIP broadens so with IoT, however, VoIP is vulnerable to all of the intrinsic security problems in IP. In this paper, a new biometrics based authentication scheme using ECC has been proposed. The formal and informal security analysis of the scheme proves the security strength of the scheme. Simulation of the scheme using AVISPA also proves the scheme is secure against potential threats. Comparison of the proposed scheme in terms of computation cost and security features with other related schemes proves the superiority of the scheme.
C1 [Dhillon, Parwinder Kaur; Kalra, Sheetal] Guru Nanak Dev Univ, Dept Comp Sci & Engn, Reg Campus, Jalandhar 144001, Punjab, India.
C3 Guru Nanak Dev University
RP Dhillon, PK (corresponding author), Guru Nanak Dev Univ, Dept Comp Sci & Engn, Reg Campus, Jalandhar 144001, Punjab, India.
EM parwindhillon@gmail.com; sheetal.kalra@gmail.com
RI Dhillon, Parwinder Kaur/I-7807-2019
OI Kalra, Sheetal/0000-0003-0694-7468
CR [Anonymous], 2006, ERCIM NEWS
   [Anonymous], SCREEN
   Arshad H, 2016, MULTIMED TOOLS APPL, V75, P181, DOI 10.1007/s11042-014-2282-x
   Arshad H, 2015, J SUPERCOMPUT, V71, P3163, DOI 10.1007/s11227-015-1434-8
   Arshad R, 2013, MULTIMED TOOLS APPL, V66, P165, DOI 10.1007/s11042-011-0787-0
   Challa S, 2016, SECUR COMMUN NETW, V9, P5412, DOI 10.1002/sec.1707
   Chen MX, 2010, INT J COMMUN SYST, V23, P673, DOI 10.1002/dac.1109
   Chen WE, 2010, INT J COMMUN SYST, V23, P929, DOI 10.1002/dac.1071
   Chen WE, 2010, INT J COMMUN SYST, V23, P919, DOI 10.1002/dac.1040
   Chiang WK, 2010, INT J COMMUN SYST, V23, P1268, DOI 10.1002/dac.1115
   Chiu KL, 2011, INT J COMMUN SYST, V24, P789, DOI 10.1002/dac.1189
   Cho K, 2010, INT J COMMUN SYST, V23, P1093, DOI 10.1002/dac.1073
   Das AK, 2012, INFORM SCIENCES, V209, P80, DOI 10.1016/j.ins.2012.04.036
   Dodis Y, 2004, LECT NOTES COMPUT SC, V3027, P523
   DOLEV D, 1983, IEEE T INFORM THEORY, V29, P198, DOI 10.1109/TIT.1983.1056650
   Eun-Jun Yoon, 2010, Proceedings of the 2010 Fourth International Conference on Network and System Security (NSS 2010), P334, DOI 10.1109/NSS.2010.101
   Farash MS, 2016, PEER PEER NETW APPL, V9, P82, DOI 10.1007/s12083-014-0315-x
   Farash MS, 2016, MULTIMED TOOLS APPL, V75, P4485, DOI 10.1007/s11042-015-2487-7
   Farash MS, 2016, INT J COMMUN SYST, V29, P1956, DOI 10.1002/dac.2848
   He DB, 2012, SECUR COMMUN NETW, V5, P1423, DOI 10.1002/sec.506
   Irshad A, 2017, WIRELESS PERS COMMUN, V97, P2145, DOI 10.1007/s11277-017-4601-9
   Irshad A, 2015, MULTIMED TOOLS APPL, V74, P3967, DOI 10.1007/s11042-013-1807-z
   Jiang Q, 2015, INT J COMMUN SYST, V28, P1340, DOI 10.1002/dac.2767
   Kilinc HH, 2014, IEEE COMMUN SURV TUT, V16, P1005, DOI 10.1109/SURV.2013.091513.00050
   Koblitz N, 2000, DESIGN CODE CRYPTOGR, V19, P173, DOI 10.1023/A:1008354106356
   Kumari S, 2017, PEER PEER NETW APPL, V10, P92, DOI 10.1007/s12083-015-0409-0
   Leach Paul J., 1999, Http authentication: Basic and digest access authentication
   Li JS, 2011, INT J COMMUN SYST, V24, P837, DOI 10.1002/dac.1191
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Odelu V, 2014, INFORM SCIENCES, V269, P270, DOI 10.1016/j.ins.2013.10.022
   Pu Q, 2013, SECUR COMMUN NETW, V6, P340, DOI 10.1002/sec.568
   Sarkar P, 2010, ACM T INFORM SYST SE, V13, DOI 10.1145/1880022.1880027
   Stinson DR, 2006, DESIGN CODE CRYPTOGR, V38, P259, DOI 10.1007/s10623-005-6344-y
   Tang HB, 2013, MULTIMED TOOLS APPL, V65, P321, DOI 10.1007/s11042-012-1001-8
   Tu H, 2015, PEER PEER NETW APPL, V8, P903, DOI 10.1007/s12083-014-0248-4
   Wu LF, 2009, COMPUT STAND INTER, V31, P286, DOI 10.1016/j.csi.2008.01.002
   Xie Q, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2725-0
   Yang CC, 2005, COMPUT SECUR, V24, P381, DOI 10.1016/j.cose.2004.10.007
   Yeh HL, 2014, COMPUT STAND INTER, V36, P397, DOI 10.1016/j.csi.2013.08.010
NR 39
TC 17
Z9 18
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22199
EP 22222
DI 10.1007/s11042-019-7466-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400002
DA 2024-07-18
ER

PT J
AU Essmaeel, K
   Migniot, C
   Dipanda, A
   Gallo, L
   Damiani, E
   De Pietro, G
AF Essmaeel, Kyis
   Migniot, Cyrille
   Dipanda, Albert
   Gallo, Luigi
   Damiani, Ernesto
   De Pietro, Giuseppe
TI A new 3D descriptor for human classification: application for human
   detection in a multi-kinect system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human classification; 3D descriptor; Multi-kinect
ID PEDESTRIAN DETECTION; HISTOGRAMS; TRACKING
AB In this paper we present a new 3D descriptor for human classification and a human detection method based on this descriptor. The proposed 3D descriptor allows classification of an object represented by a point cloud, as human or non-human. It is derived from the well-known Histogram of Oriented Gradient by employing surface normals instead of gradients. The process consists in an appropriate subdivision of the object point cloud into blocks. These blocks provide the spatial distribution modeling of the surface normal orientation into the different parts of the object. This distribution modelling is expressed as a histogram. In addition we have set up a multi-kinect acquisition system that provides us with Complete Point Clouds (CPC) (i.e. 360 degrees view). Such CPCs enable a suitable processing, particularly in case of occlusions. Moreover they allow for the determination of the human frontal orientation. Based on the proposed 3D descriptor, we have developed a human detection method that is applied on CPCs. First, we evaluated the 3D descriptor over a set of CPC candidates by using the Support Vector Machine (SVM) classifier. The learning process was conducted with the original CPC database that we have built. The results are very promising. The descriptor can discriminate human from non-human candidates and provides the frontal direction of humans with high precision. In addition we demonstrated that using the CPCs improves significantly the classification results in comparison with Single Point Clouds (i.e. points clouds acquired with only one kinect). Second, we compared our detection method with two others, namely the HOG detector on RGB images and a 3D HOG-based detection method that is applied on RGB-depth data. The obtained results on different situations show that the proposed human detection method provides excellent performances that outperform the other two detection methods.
C1 [Essmaeel, Kyis; Migniot, Cyrille; Dipanda, Albert] Univ Bourgogne Franche Comte, ImViA, EA 7535, Dijon, France.
   [Gallo, Luigi; De Pietro, Giuseppe] CNR, ICAR, Naples, Italy.
   [Damiani, Ernesto] Univ Milan, Dept Comp Technol, Milan, Italy.
C3 Universite de Bourgogne; Consiglio Nazionale delle Ricerche (CNR);
   Istituto di Calcolo e Reti ad Alte Prestazioni (ICAR-CNR); University of
   Milan
RP Migniot, C (corresponding author), Univ Bourgogne Franche Comte, ImViA, EA 7535, Dijon, France.
EM cyrille.migniot@u-bourgogne.fr
RI Gallo, Luigi/A-2924-2012; De Pietro, Giuseppe/AAZ-1151-2020; damiani,
   ernesto/AAI-5709-2020
OI Gallo, Luigi/0000-0002-1281-404X; damiani, ernesto/0000-0002-9557-6496
CR [Anonymous], CVPR 2011 WORKSHOPS, DOI DOI 10.1109/CVPRW.2011.5981811
   [Anonymous], 2015, BMVC, DOI DOI 10.5244/C.29.32
   [Anonymous], EUR C COMP VIS
   Bajracharya M, 2009, INT J ROBOTICS RES
   Baltieri D, 2012, LECT NOTES COMPUT SC, V7576, P270, DOI 10.1007/978-3-642-33715-4_20
   Campmany V, 2016, PROCEDIA COMPUT SCI, V80, P2377, DOI 10.1016/j.procs.2016.05.455
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cheng CK, 2011, ISPD 11: PROCEEDINGS OF THE 2011 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN, P5, DOI 10.1109/icc.2011.5962933
   Choi B, 2011, C COMP VIS WORKSH, P6
   Choi B, 2013, IEEE INT CONF ROBOT, P1108, DOI 10.1109/ICRA.2013.6630711
   Culhane KM, 2008, AGE AGEING, V6, P556
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deveaux J C, 2013, INT C ADV ROB
   Drory A, 2017, COMPUT VIS IMAGE UND, V159, P116, DOI 10.1016/j.cviu.2016.12.002
   Eichner M, 2012, INT J COMPUT VISION, V99, P190, DOI 10.1007/s11263-012-0524-9
   Engelcke M, 2017, INT C ROB AUT
   Fitte-Duval Laurent, 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P439
   Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7
   Gond L, 2008, LECT NOTES COMPUT SC, V5098, P370, DOI 10.1007/978-3-540-70517-8_36
   Hegger Frederik, 2013, RoboCup 2012: Robot Soccer World Cup XVI: LNCS 7500, P154, DOI 10.1007/978-3-642-39250-4_15
   Herrera DC, 2011, LECT NOTES COMPUTER
   Holz Dirk, 2012, RoboCup 2011: Robot Soccer World Cup XV: LNCS 7416, P306, DOI 10.1007/978-3-642-32060-6_26
   Hosseini JO, 2014, IEEE INT C ROB AUT
   Ikemura S, 2011, LECT NOTES COMPUT SC, V6495, P25, DOI 10.1007/978-3-642-19282-1_3
   Johnson A., 1997, Thesis
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Lai K, 2011, C ART INT
   Li C, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P424, DOI 10.1109/CompComm.2017.8322583
   Liem MC, 2014, IMAGE VISION COMPUT, V32, P728, DOI 10.1016/j.imavis.2014.04.007
   Lin BZ, 2016, INT J NETW DISTRIB C, V4, P252, DOI 10.2991/ijndc.2016.4.4.6
   Liu BZ, 2017, SIGNAL PROCESS-IMAGE, V54, P1, DOI 10.1016/j.image.2017.02.008
   Liu J, 2015, PATTERN RECOGN, P1623
   Maimone A., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P137, DOI 10.1109/ISMAR.2011.6092379
   Mozos OM, 2010, INT J SOC ROBOT, V2, P31, DOI 10.1007/s12369-009-0041-3
   Mattausch O, 2014, EUROGRAPHICS, V33
   Mitzel D, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.8
   Moeslund TB, 2008, COMPUT VIS IMAGE UND, V23, P90
   Munaro M, 2012, IEEE INT C INT ROBOT, P2101, DOI 10.1109/IROS.2012.6385772
   Nakazawa M, 2012, INT C PATT RECOG, P469
   Navarro-Serment LE, 2010, SPRINGER TRAC ADV RO, V62, P103
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Ott Christian, 2008, 2008 8th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2008), P399, DOI 10.1109/ICHR.2008.4755984
   Ouyang WL, 2013, PROC CVPR IEEE, P3222, DOI 10.1109/CVPR.2013.414
   Ouyang WL, 2012, PROC CVPR IEEE, P3258, DOI 10.1109/CVPR.2012.6248062
   Parisot P, 2017, COMPUT VIS IMAGE UND, V159, P74, DOI 10.1016/j.cviu.2017.01.001
   Paul M, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-11
   Plagemann C, 2010, IEEE INT CONF ROBOT, P3108, DOI 10.1109/ROBOT.2010.5509559
   Qing Tian, 2013, Journal of Software, V8, P2223, DOI 10.4304/jsw.8.9.2223-2230
   Raposo C, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P342, DOI 10.1109/3DV.2013.52
   Roetenberg D., 2009, XSENS MVN FULL 6DOF
   Rusu R, 2010, KI KUNSTLICHE INTELL, V24
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Salas Joaquin, 2011, Pattern Recognition. Proceedings Third Mexican Conference, MCPR 2011, P127, DOI 10.1007/978-3-642-21587-2_14
   Satake J, 2009, IAPR C MACH VIS APPL, P8
   Shashua A, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P1
   Shen YJ, 2013, IEEE COMPUT SOC CONF, P535, DOI 10.1109/CVPRW.2013.85
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Spinello L, 2011, IEEE INT C INT ROBOT, P3838, DOI 10.1109/IROS.2011.6048835
   Stone EE, 2012, IEEE ENG MED BIO, P5106, DOI 10.1109/EMBC.2012.6347142
   Tang S., 2012, P AS C COMP VIS, V7725, P525
   Tian Y, 2015, DEEP LEARNING STRONG
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26
   Weinrich C, 2012, IEEE INT C INT ROBOT, P2147, DOI 10.1109/IROS.2012.6386122
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zong C, 2011, EMBEDDED HUMAN MOTIO, P1
NR 65
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22479
EP 22508
DI 10.1007/s11042-019-7568-6
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400014
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Laaroussi, S
   Baataoui, A
   Halli, A
   Satori, K
AF Laaroussi, Saadeddine
   Baataoui, Aziz
   Halli, Akram
   Satori, Khalid
TI Dynamic mosaicking: region-based method using edge detection for an
   optimal seamline
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic mosaicking; Ghosting; Seamline; Canny edge detector
ID QUALITY ASSESSMENT; IMAGE; SCENES
AB Image mosaicking is a process of assembling multiple images to create an image with a larger field of view. It is used in different studies, but some errors, like ghosting or parallax effects, could occur when the images contain dynamic elements. To avoid the failure of the mosaic and to solve these errors, a new method that searches an optimal seamline for dynamic mosaicking is presented. By finding regions that are similar between the images, and regions that are not alike, the seamline was computed by going through the similar regions and by avoiding the not common regions. To achieve this, a combination of Canny edge detector, and the outliers and inliers from the RANSAC method were used to identify these regions. Then, the regions were incorporated in an intensity difference to create a map that reveals them. Thus, the optimal seamline was computed by going through the similar regions and by avoiding the unalike regions. The experimental results show that the proposed approach is capable of generating robust mosaics against ghosting and parallax effects.
C1 [Laaroussi, Saadeddine; Baataoui, Aziz; Satori, Khalid] Sidi Mohammed Ben Abdellah Univ, LIIAN Lab, Atlas Fes 30003, Morocco.
   [Baataoui, Aziz] Moulay Ismail Univ, Fac Sci & Tecch, Dept Comp Sci, 509 Boutalamine, Errachidia 52000, BP, Morocco.
   [Halli, Akram] Moualy Ismail Univ, LERES Lab, OMEGA, Marjane 2,298, Meknes 50050, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Moulay Ismail University of
   Meknes; Moulay Ismail University of Meknes
RP Laaroussi, S (corresponding author), Sidi Mohammed Ben Abdellah Univ, LIIAN Lab, Atlas Fes 30003, Morocco.
EM saadeddine.laaroussi@usmba.ac.ma
RI Laaroussi, Saadeddine/AAE-6328-2019; satori, khalid/GSE-3077-2022
OI Laaroussi, Saadeddine/0000-0002-3608-1354; SATORI,
   khalid/0000-0001-6055-4169
FU national center of scientific and technology research (CNRST, Centre
   National pour la Recherche Scientifique et Technique)
FX This work was supported by the national center of scientific and
   technology research (CNRST, Centre National pour la Recherche
   Scientifique et Technique).
CR [Anonymous], INT J DIGITAL CONTEN
   [Anonymous], 2002, DATA FUSION DEFINITI
   Azzari P, 2008, LECT NOTES COMPUT SC, V5099, P413, DOI 10.1007/978-3-540-69905-7_47
   Baataoui A, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0048-5
   Bartoli A, 2004, COMPUT ANIMAT VIRT W, V15, P501, DOI 10.1002/cav.13
   Bhat KS, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1577, DOI 10.1109/ICME.2000.871070
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247
   BURTSEV SV, 1993, COMPUT GRAPH, V17, P549, DOI 10.1016/0097-8493(93)90006-U
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen S. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P29, DOI 10.1145/218380.218395
   Choi YH, 2002, 2002 INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, DIGEST OF TECHNICAL PAPERS, P74, DOI 10.1109/ICCE.2002.1013933
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Davis J, 1998, PROC CVPR IEEE, P354, DOI 10.1109/CVPR.1998.698630
   Duplaquet ML, 1998, P SOC PHOTO-OPT INS, V3387, P369, DOI 10.1117/12.316427
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gu X., 2016, P 2016 IEEE INT C RO
   IRANI M, 1995, SIGNAL PROCESS-IMAGE, V7, P529, DOI 10.1016/0923-5965(95)00022-1
   Kerschner M, 2001, ISPRS J PHOTOGRAMM, V56, P53, DOI 10.1016/S0924-2716(01)00033-8
   Laaroussi S, 2018, PROCEDIA COMPUT SCI, V127, P344, DOI 10.1016/j.procs.2018.01.131
   Laraqui A, 2017, MULTIMED TOOLS APPL, V76, P8803, DOI 10.1007/s11042-016-3478-z
   Li L, 2017, MACH VISION APPL, V28, P819, DOI 10.1007/s00138-017-0874-y
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo J., 2009, INT J IMAGE PROCESSI, V3, P143, DOI DOI 10.1007/S11270-006-2859-8
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mills A, 2009, IMAGE VISION COMPUT, V27, P1593, DOI 10.1016/j.imavis.2009.03.004
   Pan J, 2014, IEEE GEOSCI REMOTE S, V11, P1335, DOI 10.1109/LGRS.2013.2293197
   Pont-Tuset J., 2017, ARXIV170400675
   Qi Z, 2008, ICPR 08
   Qureshi HS, 2012, IET IMAGE PROCESS, V6, P1348, DOI 10.1049/iet-ipr.2011.0641
   Ramachandran M, 2006, IEEE IMAGE PROC, P345, DOI 10.1109/ICIP.2006.313164
   Rebiere N, 2008, PATTERN RECOGN, P1051
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Sawhney HS, 1996, IEEE T PATTERN ANAL, V18, P814, DOI 10.1109/34.531801
   Szeliski R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P251, DOI 10.1145/258734.258861
   Tang Y, 2009, IM SIGN PROC CISP 09
   Uyttendaele M., 2001, COMPUT VIS PATTERN R, V2, P1063
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu W, 2010, PROC CVPR IEEE, P263, DOI 10.1109/CVPR.2010.5540202
   Yan C, 2014, IEEE T CIRCUITS SYST, V24
   Yan C, 2017, IEEE T INTELL TRANSP, V19
   Yao R, 2017, MULTIMED TOOLS APPL, V76, P13615, DOI 10.1007/s11042-016-3738-y
   Yu L, 2012, INT J REMOTE SENS, V33, P1000, DOI 10.1080/01431161.2010.545083
   Zeng L, 2014, MACH VISION APPL, V25, P1271, DOI 10.1007/s00138-013-0551-8
   Zhang W, 2017, INFORM SCIENCES, V415, P19, DOI 10.1016/j.ins.2017.05.019
   Zhang W, 2017, INFORM SCIENCES, V376, P190, DOI 10.1016/j.ins.2016.10.020
NR 46
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23225
EP 23253
DI 10.1007/s11042-019-7603-7
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400047
DA 2024-07-18
ER

PT J
AU Lakshmi, VS
   Deepthi, PP
AF Lakshmi, V. S.
   Deepthi, P. P.
TI An efficient scheme for secure domain medical image fusion over cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data privacy; Cloud storage; Hill cipher; Homomorphic encryption; Image
   fusion
ID FULLY HOMOMORPHIC ENCRYPTION
AB The exponential growth in the medical images is making the healthcare industry move towards cloud-based paradigm, which has vast storage and high end processing facilities. However, moving medical images containing highly sensitive data to third-party cloud servers brings in serious security threats. Even though encrypting medical images before outsourcing using traditional encryption schemes seem to be a feasible solution, that can not support encrypted domain processing. In this paper, we propose an affine Hill cipher based scheme for encrypted domain medical image fusion. The random vectors used in this scheme are carefully designed to preserve the randomness and security properties when operations are performed on the encrypted data. The proposed scheme offers data privacy and supports encrypted domain processing with no additional storage burden at the cloud side and very low computational burden at the healthcare provider side. The security of the proposed scheme is evaluated through extensive cryptanalysis in terms of resistance against various statistical attacks. The performance of the proposed scheme is analyzed by comparing various metrics of encrypted domain MR-CT/PET image fusion results with those of plaintext domain fusion. The values of structural similarity index, normalized correlation coefficient and structural content are 1 and the image quality index is 0.999, which show that the proposed encrypted domain image fusion provides same accuracy levels as that of plaintext domain image fusion.
C1 [Lakshmi, V. S.; Deepthi, P. P.] Natl Inst Technol, Dept Elect & Commun Engn, Calicut, Kozhikode, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Calicut
RP Lakshmi, VS (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Calicut, Kozhikode, India.
EM lakshmivs23@gmail.com; deepthi@nitc.ac.in
RI S, Lakshmi V/J-7300-2019
OI S, Lakshmi V/0000-0001-6589-711X
CR Acharya B., 2007, INT J SECURITY, V1, P14
   [Anonymous], 1978, FDN SEC COMPUT
   [Anonymous], 2011, P IEEE GLOB TEL C GL
   Bashir R, 2019, MULTIMED TOOLS APPL, V78, P1235, DOI 10.1007/s11042-018-6229-5
   Blum R.S., 2005, MULTISENSOR IMAGE FU
   Brakerski Z, 2014, SIAM J COMPUT, V43, P831, DOI 10.1137/120868669
   Brakerski Z, 2011, LECT NOTES COMPUT SC, V6841, P505, DOI 10.1007/978-3-642-22792-9_29
   Chan ACF, 2009, IEEE ICC, P774
   Du J, 2016, NEUROCOMPUTING, V215, P3, DOI 10.1016/j.neucom.2015.07.160
   Elhoseny M, 2020, NEURAL COMPUT APPL, V32, P10979, DOI 10.1007/s00521-018-3801-x
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Gentry C, 2011, LECT NOTES COMPUT SC, V6632, P129, DOI 10.1007/978-3-642-20465-4_9
   Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440
   GOLDWASSER S, 1984, J COMPUT SYST SCI, V28, P270, DOI 10.1016/0022-0000(84)90070-9
   Haghighat MBA, 2011, COMPUT ELECTR ENG, V37, P744, DOI 10.1016/j.compeleceng.2011.07.012
   Haridas D, 2012, 2012 2ND IEEE INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P491, DOI 10.1109/PDGC.2012.6449870
   Hodges J.H., 1958, AM MATH MON, V65, P518
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Kadhe S., 2014, 2014 International Symposium on Network Coding (NetCod), P1
   MacWilliams F.J., 1971, J COMBIN THEORY A, V10, P1
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH, V1st
   Mishra DC, 2015, OPTIK, V126, P3812, DOI 10.1016/j.ijleo.2015.07.117
   Mohanty M, 2016, IEEE T INF FOREN SEC, V11, P2542, DOI 10.1109/TIFS.2016.2585085
   Mohanty M, 2016, MULTIMED TOOLS APPL, V75, P6207, DOI 10.1007/s11042-015-2567-8
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Pawar S, 2011, IEEE T INFORM THEORY, V57, P6734, DOI 10.1109/TIT.2011.2162191
   Priya S, 2018, PERS UBIQUIT COMPUT, V22, P1141, DOI 10.1007/s00779-018-1131-8
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Rosenthal A, 2010, J BIOMED INFORM, V43, P342, DOI 10.1016/j.jbi.2009.08.014
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Shi H, 2018, MULTIMED TOOLS APPL, V77, P20535, DOI 10.1007/s11042-017-5446-7
   Shim KA, 2015, IEEE T PARALL DISTR, V26, P2128, DOI 10.1109/TPDS.2014.2346764
   Singh P, 2017, MULTIMED TOOLS APPL, V77, P2581
   Stinson D. R., 2005, CRYPTOGRAPHY THEORY
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Toorani M, 2009, IEEE SYMP COMP COMMU, P313, DOI 10.1109/ISCC.2009.5202241
   Vizár D, 2015, STUD SCI MATH HUNG, V52, P288, DOI 10.1556/012.2015.52.2.1311
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
NR 40
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 20609
EP 20636
DI 10.1007/s11042-019-7378-x
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400003
DA 2024-07-18
ER

PT J
AU Ramu, SM
   Rajappa, M
   Krithivasan, K
   Nalluri, MR
AF Ramu, Saru Meena
   Rajappa, Muthaiah
   Krithivasan, Kannan
   Nalluri, Madhusudhana Rao
TI A novel fast medical image segmentation scheme for anatomical scans
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Deformable model; Level set; Variational approach
ID ACTIVE CONTOUR MODEL; LUNG
AB Medical image is the visual representation of anatomy or physiology of internal structures of the body and it is useful for clinical analysis and medical intervention. Modern medical imaging devices provide an excellent view of anatomy and physiology of internal structures of the body non-invasively. However, the usage of computers to measure, examine and determine the state of internal structures of the body with accuracy and efficiency is limited. Automated medical image segmentation techniques have wide range of utility in diagnosis, treatment planning and computer integrated surgery. These automated medical image segmentation techniques could also be used as an assisting tool to radiologists by saving their time in selecting, measuring and classifying various findings. However, automated medical image segmentation is challenging because the quality of the image is low due to the presence of noise, artefacts, partial volume effects etc., low contrast between different structures in an image and intensity variations within a region itself. This research paper focuses on fastening a region based deformable model called Chan-Vese model through various first order optimization techniques. Chan - Vese model can perform segmentation effectively even in low quality images but the limitation of Chan-Vese model is that convergence towards optimal solution is slow. The objective of this work is to fasten the convergence of Chan-Vese model towards optimal solution by using various first order optimization schemes. Chan-Vese model with proposed optimization techniques is tested with X-ray, CT and MRI images of different organs. Comparative study between traditional optimization technique used in Chan-Vese model and proposed optimization techniques has been carried out. From the comparative study, it is found that Chan-Vese model with proposed optimization schemes is efficient in terms of speedy delineation with less number of iterations and processing time. Therefore, this fastened Chan-Vese model is better suited algorithm for fast image segmentation needs such as tracking of region of interest in subsequent frames in a video.
C1 [Ramu, Saru Meena] SASTRA Univ, Dept Comp Sci, Thanjavur, India.
   [Rajappa, Muthaiah; Nalluri, Madhusudhana Rao] SASTRA Univ, Sch Comp, Thanjavur, India.
   [Krithivasan, Kannan] SASTRA Univ, Math Dept, Thanjavur, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Krithivasan, K (corresponding author), SASTRA Univ, Math Dept, Thanjavur, India.
EM ebscharu@yahoo.com; muthaiah66@gmail.com; kkannan_1960@yahoo.com;
   madhu031083@gmail.com
RI su, haobo/JPK-2362-2023; k, k/KFC-0221-2024; K, Kannan/GPK-0744-2022; k,
   k/KFT-2541-2024; k, k/HZK-4476-2023
OI Rajappa, Muthaiah/0000-0002-6659-1961; nalluri, Dr.Madhusudana
   rao/0000-0002-5315-1932
FU DST; SASTRA Deemed University [SR/FST/MSI-107/2015(C)]
FX The authors wish to thank DST and SASTRA Deemed University for providing
   financial support (SR/FST/MSI-107/2015(C)).
CR Achuthan A, 2010, COMPUT BIOL MED, V40, P608, DOI 10.1016/j.compbiomed.2010.04.005
   Airouche M, 2009, LECT NOTES ENG COMP, P846
   [Anonymous], 2016, AM J BIOMED ENG
   Bagci U, 2012, IEEE T BIO-MED ENG, V59, P1620, DOI 10.1109/TBME.2012.2190984
   Bankman IN, 2009, HANDBOOK OF MEDICAL IMAGE PROCESSING AND ANALYSIS, 2ND EDITION, P1
   Baswaraj D., 2012, Global Journal of Computer Science and Technology
   Boussouar A, 2017, COMPUT MED IMAG GRAP, V56, P60, DOI 10.1016/j.compmedimag.2017.02.001
   Boykov Y, 2000, LECT NOTES COMPUT SC, V1935, P276
   Cabezas M, 2011, COMPUT METH PROG BIO, V104, pE158, DOI 10.1016/j.cmpb.2011.07.015
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen YF, 2017, KNOWL-BASED SYST, V120, P57, DOI 10.1016/j.knosys.2016.12.023
   Deserno TM, 2013, CURR MED IMAGING, V9, P79
   Ge Q, 2013, DIGIT SIGNAL PROCESS, V23, P1186, DOI 10.1016/j.dsp.2012.12.015
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Hegadi Ravindra., 2010, INT J COMPUTER APPL, P64
   Hojjatoleslami SA, 1998, IEEE T IMAGE PROCESS, V7, P1079, DOI 10.1109/83.701170
   Hu SY, 2001, IEEE T MED IMAGING, V20, P490, DOI 10.1109/42.929615
   Jiang Xin., 2009, 2009 3rd International Conference on Bioinformatics and Biomedical Engineering, P1, DOI DOI 10.1109/ICBBE.2009.5162922
   Kemerink GJ, 1998, MED PHYS, V25, P2432, DOI 10.1118/1.598454
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li M, 2012, MATH PROBL ENG, V2012
   Li S, 2013, FAST IMAGE SEGMENTAT
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Mansoor A, 2015, RADIOGRAPHICS, V35, P1056, DOI 10.1148/rg.2015140232
   Marques O., Practical Image and Video Processing Using MATLAB
   O'Donoghue B, 2015, FOUND COMPUT MATH, V15, P715, DOI 10.1007/s10208-013-9150-3
   Pham D, 1998, ANN REV BIOMED ENG
   Pratondo A, 2017, J VIS COMMUN IMAGE R, V43, P1, DOI 10.1016/j.jvcir.2016.11.019
   Saini K, 2012, J DIGIT IMAGING, V25, P271, DOI 10.1007/s10278-011-9408-8
   Su W, 2015, DIFFERENTIAL EQUATIO
   Tobias Heimann HD, BIOMEDICAL IMAGE PRO, P279
   Tremeau A, 1997, PATTERN RECOGN, V30, P1191, DOI 10.1016/S0031-3203(96)00147-1
   Vitti A, 2012, ISPRS J PHOTOGRAMM, V69, P50, DOI 10.1016/j.isprsjprs.2012.02.005
   Walia AnishSingh., 2017, Types of Optimization Algorithms used in Neural Networks and Ways to Optimize Gradient Descent
   Wang Y, 2012, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2012-16
   Wibisono A, 2016, ARXIV160304245V1MATH, P1
   Wibisono A, ACCELERATED GRADIENT
   Wilson AC, 2017, ARXIV161102635V3MATH
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Xu Y, 2006, IEEE T MED IMAGING, V25, P464, DOI 10.1109/TMI.2006.870889
   Yao JH, 2011, ACAD RADIOL, V18, P306, DOI 10.1016/j.acra.2010.11.013
   Yin W, 2015, MATH A
   Yu CY, 2013, COMPUT MATH APPL, V65, P1746, DOI 10.1016/j.camwa.2013.03.021
   Yuan Y, 2012, MATH COMPUT MODEL, V55, P1705, DOI 10.1016/j.mcm.2011.11.014
   Zhang L, 2006, IEEE T MED IMAGING, V25, P1, DOI 10.1109/TMI.2005.859209
NR 47
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21391
EP 21422
DI 10.1007/s11042-019-7328-7
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400040
DA 2024-07-18
ER

PT J
AU Saha, P
   Bhattacharjee, D
   De, BK
   Nasipuri, M
AF Saha, Priya
   Bhattacharjee, Debotosh
   De, Barin Kumar
   Nasipuri, Mita
TI A Survey on Image Acquisition Protocols for Non-posed Facial Expression
   Recognition Systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; face image acquisition protocols; feature extraction;
   naturally induced facial expressions; spontaneous facial expression
   recognition
ID AUTOMATIC-ANALYSIS; FEATURE-EXTRACTION; EMOTION; SCHIZOPHRENIA;
   DATABASE; EXPERIENCE; INFORMATION
AB Several research methodologies and human face image databases have been developed based on deliberately produced facial expressions of prototypical emotions. However, real-time and spontaneous facial expression recognition cannot be adequately handled by those existing methods and datasets. To address this problem, research efforts have been made to create spontaneous facial expression image datasets as well as to develop algorithms that can process naturally induced affective behavior. This paper introduces these advances and focuses on a small and specific area of spontaneous facial expression recognition. In this paper, we are concentrating on non-posed image acquisition protocols, which strongly influence the subjects for evoking expressions as natural as possible. We categorize the acquisition protocols into four different parts: image acquisition while playing video games, watching emotional videos, during interviews and from other sources. The taxonomy of facial expression acquisition protocols tells about the typical conditions responsible for producing specific facial expressions in that condition. We also address some important design issues related to spontaneous facial expression recognition systems and list the facial expression databases, which are strictly not acted and non-posed. We also put light on the applications of spontaneously evoked facial expression acquisition and recognition because they have potential medical significance. Moreover, we provide a comprehensive analysis and summary of spontaneous facial expression recognition methods by revealing their pros and cons for future researchers.
C1 [Saha, Priya] Tripura Univ, Comp Sci & Engn Dept, Suryamaninagar 799022, India.
   [Bhattacharjee, Debotosh; Nasipuri, Mita] Jadavpur Univ, Comp Sci & Engn Dept, Kolkata 700032, India.
   [De, Barin Kumar] Tripura Univ, Phys Dept, Suryamaninagar 799022, India.
C3 Tripura University; Jadavpur University; Tripura University
RP Saha, P (corresponding author), Tripura Univ, Comp Sci & Engn Dept, Suryamaninagar 799022, India.
EM priyasaha.cse@gmail.com
RI Bhattacharjee, Debotosh/L-8521-2015; De, Barin Kumar/GRS-7957-2022;
   Bhattacharjee, Debotosh/Q-4065-2019; Saha, Priya/AAA-7464-2019
OI Bhattacharjee, Debotosh/0000-0002-1163-6413; Bhattacharjee,
   Debotosh/0000-0002-1163-6413; 
FU Department of Science and Technology (DST), Government of India under
   DST-INSPIRE fellowship program [IF131067]
FX The first author is grateful to Department of Science and Technology
   (DST), Government of India for providing her Junior Research Fellowship
   (JRF) under DST-INSPIRE fellowship program (No. IF131067).
CR Aghevli MA, 2003, PSYCHIAT RES, V119, P261, DOI 10.1016/S0165-1781(03)00133-1
   Aina S, 2014, EUR SIGNAL PR CONF, P2505
   Alves Nelson Torro, 2013, Estud. psicol. (Natal), V18, P125
   [Anonymous], P IEEE INT C AUT FAC
   [Anonymous], P 2 INT WORKSH STAT
   [Anonymous], NEUR INF PROC SYST N
   [Anonymous], INT J COMPUT THEORY
   [Anonymous], P COMP VIS HUM COMP
   [Anonymous], P IEEE INT C WORKSH
   [Anonymous], P 13 INT C IM AN PRO
   [Anonymous], 2012, 11 WSEAS INT C EL HA
   [Anonymous], P IEEE WORKSH COMP V
   [Anonymous], AGGRESS BEHAV
   [Anonymous], GUIDE VISUAL ANAL HU
   [Anonymous], 2004, P 6 IASTED INT C SIG
   [Anonymous], P 8 IEEE INT C AUT F
   [Anonymous], P 3 INT C AFF COMP I
   [Anonymous], 2012, P ACM ICMI
   [Anonymous], 2014, REAL TIME EMOTION RE
   [Anonymous], FACIAL EXPRESSIONS E
   [Anonymous], P 8 AUSTR C INT ENT
   [Anonymous], P NAT C CLOUD COMP B
   [Anonymous], P INT C ED DAT MIN
   [Anonymous], P ANN SUMM C SIGN IN
   [Anonymous], PSYCHOL INT PERSPECT
   [Anonymous], 2008, INT J COMPUTER GAMES
   Antonini G, 2003, LECT NOTES COMPUT SC, V2688, P111
   Ashraf AB, 2009, IMAGE VISION COMPUT, V27, P1788, DOI 10.1016/j.imavis.2009.05.007
   Bänziger T, 2012, EMOTION, V12, P1161, DOI 10.1037/a0025827
   BaronCohen S, 1997, VIS COGN, V4, P311, DOI 10.1080/713756761
   Bartlett MS, 2005, PROC CVPR IEEE, P568
   BERENBAUM H, 1992, J ABNORM PSYCHOL, V101, P37, DOI 10.1037/0021-843X.101.1.37
   BERENBAUM H, 1992, PSYCHOL MED, V22, P929, DOI 10.1017/S0033291700038502
   Bettadapura V.K., 2012, CoRR, P1
   Blom P. M., 2014, P 10 AAAI C ART INT, P30
   Cerezo E, 2006, LECT NOTES COMPUT SC, V4069, P405
   Cho SY, 2009, STUD COMPUT INTELL, V199, P21
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   COHN JF, 1983, CHILD DEV, V54, P185, DOI 10.2307/1129876
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   Douglas-Cowie E, 2003, SPEECH COMMUN, V40, P33, DOI 10.1016/S0167-6393(02)00070-5
   Edwards G. J., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P581, DOI 10.1007/BFb0054766
   EKMAN P, 1980, CHILD DEV, V51, P886, DOI 10.1111/j.1467-8624.1980.tb02627.x
   EKMAN P, 1981, PSYCHOPHYSIOLOGY, V18, P101, DOI 10.1111/j.1469-8986.1981.tb02919.x
   Ekman P, 2003, ANN NY ACAD SCI, V1000, P205, DOI 10.1196/annals.1280.010
   EKMAN P, 1982, J NONVERBAL BEHAV, V6, P238, DOI 10.1007/BF00987191
   Ekman P., 1982, EMOTION HUMAN FACE, V2nd, P111
   Ekman Paul, 1997, What the Face Reveals: Basic and Applied Studies of Spontaneous Expression using the Facial Action Coding System (FACS)
   el Kaliouby R, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P46
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   FERNANDEZ-DOLS JM, 1993, EUR J SOC PSYCHOL, V23, P195, DOI 10.1002/ejsp.2420230207
   Fridlund A. J., 1994, Human Facial Expression: An Evolutionary View
   Gaebel W, 2004, EUR ARCH PSY CLIN N, V254, P335, DOI 10.1007/s00406-004-0510-5
   Gajsek R, 2009, INFORM-J COMPUT INFO, V33, P101
   Gajsek R, 2009, LECT NOTES ARTIF INT, V5729, P266, DOI 10.1007/978-3-642-04208-9_38
   Gan Q, 2015, INT CONF AFFECT, P643, DOI 10.1109/ACII.2015.7344637
   GILBERT DT, 1988, J PERS SOC PSYCHOL, V54, P193, DOI 10.1037/0022-3514.54.2.193
   Grimm M, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P865, DOI 10.1109/ICME.2008.4607572
   Grites T., 2008, Academic advising: a comprehensive handbook, P1, DOI [10.1109/AFGR.2008.4813379, DOI 10.1109/AFGR.2008.4813379]
   Hager J.C., 1983, SOCIAL PSYCHOPHYSIOL, P287
   Hall J.A., 2005, NEW HDB METHODS NONV, P237
   Hammal Z., 2008, Proceedings of Visions of Computer Science-BCS International Academic Conference, (Swindon, UK), P191
   Happy SL, 2017, IEEE T AFFECT COMPUT, V8, P131, DOI 10.1109/TAFFC.2015.2498174
   He MH, 2013, INT CONF AFFECT, P79, DOI 10.1109/ACII.2013.20
   HESS U, 1990, EUR J SOC PSYCHOL, V20, P369, DOI 10.1002/ejsp.2420200502
   Hess U., 2005, WHAT FACE REVEALS BA, V2nd, P271
   Hoque M, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P697
   Iwase M, 2002, NEUROIMAGE, V17, P758, DOI 10.1006/nimg.2002.1225
   Jakobs E, 1999, PERS SOC PSYCHOL B, V25, P424, DOI 10.1177/0146167299025004003
   Joho H, 2009, P ACM INT C IM VID R, P1
   Kaltwang S, 2012, LECT NOTES COMPUT SC, V7432, P368, DOI 10.1007/978-3-642-33191-6_36
   Kirsh SJ, 2007, AGGRESSIVE BEHAV, V33, P353, DOI 10.1002/ab.20191
   KLECK RE, 1976, J PERS SOC PSYCHOL, V34, P1211, DOI 10.1037/0022-3514.34.6.1211
   Knapp M.L., 2005, Nonverbal communication in human interaction, V6th
   Ko BC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020401
   Kohler CG, 2008, SCHIZOPHR RES, V105, P30, DOI 10.1016/j.schres.2008.05.030
   Korb S, 2008, IEEE INT C AUTOMATIC, P1
   Kring AM, 1996, J ABNORM PSYCHOL, V105, P249, DOI 10.1037/0021-843X.105.2.249
   KRING AM, 1993, J ABNORM PSYCHOL, V102, P507, DOI 10.1037/0021-843X.102.4.507
   Krumhuber EG, 2017, EMOT REV, V9, P280, DOI 10.1177/1754073916670022
   Kunz M, 2007, PAIN, V133, P221, DOI 10.1016/j.pain.2007.09.007
   Lee KK, 2003, IEEE INT CONF ROBOT, P2567
   Lehr VT, 2007, CLIN J PAIN, V23, P417, DOI 10.1097/AJP.0b013e31805476f2
   Li YQ, 2015, PATTERN RECOGN, V48, P3417, DOI 10.1016/j.patcog.2015.04.022
   Ligang Zhang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P1027, DOI 10.1109/ICME.2012.97
   Littlewort G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P298, DOI 10.1109/FG.2011.5771414
   Loconsole C, 2014, LECT NOTES COMPUT SC, V8588, P320, DOI 10.1007/978-3-319-09333-8_35
   Lucey P., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462
   Mahlke S., 2006, P C HUM FACT COMP SY, DOI [DOI 10.1145/1125451.1125653, 10.1145/1125451.1125653]
   Malatesta C.Z., 1984, EMOTION ADULT DEV
   Mandal MK, 1998, SCHIZOPHRENIA BULL, V24, P399, DOI 10.1093/oxfordjournals.schbul.a033335
   Marrero-Fernández P, 2014, IETE TECH REV, V31, P220, DOI 10.1080/02564602.2014.906863
   MARTIN CC, 1990, J COMMUN DISORD, V23, P287, DOI 10.1016/0021-9924(90)90005-J
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   McDuff D, 2013, IEEE COMPUT SOC CONF, P881, DOI 10.1109/CVPRW.2013.130
   McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20
   MEHRABIAN A, 1968, PSYCHOL TODAY, V2, P53
   Michel P., 2003, Proceedings of the 5th international conference on Multimodal interfaces, P258, DOI DOI 10.1145/958432.958479
   Moridis CN, 2012, IEEE T AFFECT COMPUT, V3, P260, DOI 10.1109/T-AFFC.2012.6
   Nakajima T, 2016, INT SYMPOS COMPUT NE, P126, DOI [10.1109/CANDAR.2016.0033, 10.1109/CANDAR.2016.93]
   Nosu K, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P2208
   Nosu K, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3811
   O'Toole AJ, 2005, IEEE T PATTERN ANAL, V27, P812, DOI 10.1109/TPAMI.2005.90
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2
   Petridis S, 2013, IMAGE VISION COMPUT, V31, P186, DOI 10.1016/j.imavis.2012.08.014
   Ryu YS, 2002, APPL INTELL, V17, P171, DOI 10.1023/A:1016160814604
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Scherer KR, 1997, MOTIV EMOTION, V21, P211, DOI 10.1023/A:1024498629430
   Sebe N, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P517, DOI 10.1109/AFGR.2004.1301585
   Seckington M., 2011, THESIS
   Sikka Karan, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P18, DOI 10.1109/CVPRW.2015.7301350
   Sneddon I, 2012, IEEE T AFFECT COMPUT, V3, P32, DOI 10.1109/T-AFFC.2011.26
   Suk M, 2014, IEEE COMPUT SOC CONF, P132, DOI 10.1109/CVPRW.2014.25
   Sun YJ, 2014, 2014 IEEE 15TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P695, DOI 10.1109/IRI.2014.7051957
   Sung J, 2009, IMAGE VISION COMPUT, V27, P1313, DOI 10.1016/j.imavis.2008.11.010
   Tcherkassof A., 2013, International Journal of Multimedia Its Applications, V5, P61, DOI DOI 10.5121/IJMA.2013.5505
   Teijeiro-Mosquera L, 2015, IEEE T AFFECT COMPUT, V6, P193, DOI 10.1109/TAFFC.2014.2370044
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Tzirakis P, 2017, IEEE J-STSP, V11, P1301, DOI 10.1109/JSTSP.2017.2764438
   Valstar M.F., 2006, International Conference on Multimodal Interfaces, P162, DOI DOI 10.1145/1180995.1181031
   Wallhoff F, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P493, DOI 10.1109/ICME.2006.262433
   Wang SF, 2015, MACH VISION APPL, V26, P219, DOI 10.1007/s00138-015-0657-2
   Wang SF, 2013, IEEE T AFFECT COMPUT, V4, P34, DOI 10.1109/T-AFFC.2012.32
   Wild B, 2006, NEUROLOGY, V66, P887, DOI 10.1212/01.wnl.0000203123.68747.02
   Xue Z, 2003, PATTERN RECOGN, V36, P2819, DOI 10.1016/S0031-3203(03)00181-X
   Yannakakis Georgios N., 2005, Proceedings of the Workshop on Reasoning, Representation, and Learning in Computer Games, P119
   Yeasin M, 2006, IEEE T MULTIMEDIA, V8, P500, DOI 10.1109/TMM.2006.870737
   Zaman B., 2006, Proceedings of the 4th Nordic conference on Human-computer interaction: changing roles, P457
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zeng ZH, 2007, LECT NOTES COMPUT SC, V4451, P72
   Zhalehpour S, 2017, IEEE T AFFECT COMPUT, V8, P300, DOI 10.1109/TAFFC.2016.2553038
   Zhang W, 2015, PATTERN RECOGN, V48, P3191, DOI 10.1016/j.patcog.2015.04.012
   Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93
   Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990
   Zhao XM, 2016, IETE TECH REV, V33, P505, DOI 10.1080/02564602.2015.1117403
   Zhou XX, 2004, I C COMP GRAPH IM VI, P144, DOI 10.1109/CGIV.2004.1323975
NR 138
TC 2
Z9 3
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23329
EP 23368
DI 10.1007/s11042-019-7596-2
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400051
DA 2024-07-18
ER

PT J
AU Wang, CP
   Zhang, JS
   Shi, G
AF Wang, Changpeng
   Zhang, Jiangshe
   Shi, Guang
TI Discriminative low-rank representation with Schatten-p norm for image
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-rank representation; Schatten-p norm; Image recognition
ID ALGORITHM
AB Low-rank representation (LRR) has attracted much attention recently due to its efficacy in a rich variety of real world applications. Recently, the non-convex regularization has become widely used in the rank minimization problem. In this paper, we propose a discriminative low-rank representation with Schatten-p norm (DLRR-SPN) to learn a robust and discriminative affinity matrix for image recognition. To this end, we first impose the Schatten-p norm regularization on the representation matrix to learn the global structure of data. Moreover, the adaptive distance penalty is used to preserve the local neighbor relationship of data. The objective function is formulated as a Schatten-p norm minimization problem, which can be solved via alternating direction method of multipliers (ADMM). To enhance the separation ability of the discriminative affinity matrix for semi-supervised recognition problem, the angular information of the principal directions of the low-rank representation is further exploited. Finally, an effective semi-supervised classifier is utilized on the learned affinity matrix for final prediction. Extensive experimental results on image recognition demonstrate the effectiveness of the proposed method and its superiority in performance over the related state-of-the-art methods.
C1 [Wang, Changpeng] Changan Univ, Sch Sci, Xian, Shaanxi, Peoples R China.
   [Zhang, Jiangshe; Shi, Guang] Xi An Jiao Tong Univ, Sch Math & Stat, Xian, Shaanxi, Peoples R China.
C3 Chang'an University; Xi'an Jiaotong University
RP Wang, CP (corresponding author), Changan Univ, Sch Sci, Xian, Shaanxi, Peoples R China.
EM cpwang@chd.edu.cn; jszhang@mail.xjtu.edu.cn; shiguang116@126.com
FU National Basic Research Program of China (973 Program) [2013CB329404];
   National Natural Science Foundation of China [61572393]; Basic Science
   Research of Shaanxi province [2018JQ1038]; Special Fund for Basic
   Scientific Research of Central Colleagues, Chang'an University
   [310812171006]
FX This work was supported by the National Basic Research Program of China
   (973 Program) under Grant no. 2013CB329404, the National Natural Science
   Foundation of China under Grant no. 61572393, the Basic Science Research
   of Shaanxi province under Grant 2018JQ1038, and the Special Fund for
   Basic Scientific Research of Central Colleagues, Chang'an University no.
   310812171006.
CR Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Candès EJ, 2010, IEEE T INFORM THEORY, V56, P2053, DOI 10.1109/TIT.2010.2044061
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Chen J, 2014, J VIS COMMUN IMAGE R, V25, P763, DOI 10.1016/j.jvcir.2014.01.015
   Chen JH, 2014, IEEE T CYBERNETICS, V44, P1432, DOI 10.1109/TCYB.2013.2286106
   Cheng WL, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071633
   Du HS, 2017, J VIS COMMUN IMAGE R, V45, P87, DOI 10.1016/j.jvcir.2017.02.015
   El-Alfy H, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P929, DOI 10.1109/ACPR.2017.153
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Fei LK, 2017, PATTERN RECOGN, V67, P252, DOI 10.1016/j.patcog.2017.02.017
   Feng L, 2016, SIGNAL PROCESS-IMAGE, V47, P28, DOI 10.1016/j.image.2016.05.012
   Glowinski R, 1989, MATH COMPUT, V58
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai MJ, 2013, SIAM J NUMER ANAL, V51, P927, DOI 10.1137/110840364
   Lin Z., 2011, ADV NEURAL INFORM PR, V24, P612, DOI DOI 10.1007/S11263-013-0611-6
   Lin ZC, 2011, PROG MOL BIOL TRANSL, V98, P1, DOI 10.1016/B978-0-12-385506-0.00001-6
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu GC, 2011, IEEE I CONF COMP VIS, P1615, DOI 10.1109/ICCV.2011.6126422
   Liu K, 2018, AAAI CONF ARTIF INTE, P7138
   Liu L, 2014, J COMPUT APPL MATH, V267, P218, DOI 10.1016/j.cam.2014.02.015
   Liu WF, 2019, IEEE T CYBERNETICS, V49, P2927, DOI 10.1109/TCYB.2018.2833843
   Liu WF, 2018, INFORM FUSION, V41, P119, DOI 10.1016/j.inffus.2017.09.001
   Liu WF, 2016, IEEE T IND ELECTRON, V63, P5120, DOI 10.1109/TIE.2016.2552147
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu CY, 2014, PROC CVPR IEEE, P4130, DOI 10.1109/CVPR.2014.526
   Mei T., 2015, PROC CVPR IEEE, P3707
   Nie F., 2012, AAAI, P655
   Nie FP, 2015, KNOWL INF SYST, V42, P525, DOI 10.1007/s10115-013-0713-z
   Peng Y, 2015, NEURAL NETWORKS, V65, P1, DOI 10.1016/j.neunet.2015.01.001
   Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835
   Shang FH, 2016, AAAI CONF ARTIF INTE, P2016
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Xie Y, 2016, IEEE T IMAGE PROCESS, V25, P4842, DOI 10.1109/TIP.2016.2599290
   Yang JF, 2013, MATH COMPUT, V82, P301
   Zhang HY, 2014, NEUROCOMPUTING, V145, P369, DOI 10.1016/j.neucom.2014.05.022
   Zhang XJ, 2016, NEUROCOMPUTING, V182, P36, DOI 10.1016/j.neucom.2015.12.009
   Zhang Z, 2018, IEEE T NEUR NET LEAR, V29, P3111, DOI 10.1109/TNNLS.2017.2712801
   Zhou DY, 2004, ADV NEUR IN, V16, P321
   Zhu X., 2003, P 20 INT C MACH LEAR, V3, P58, DOI DOI 10.1109/18.850663
NR 43
TC 0
Z9 0
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23075
EP 23095
DI 10.1007/s11042-019-7653-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400040
DA 2024-07-18
ER

PT J
AU Afsharirad, H
   Seyedin, SA
AF Afsharirad, Hooman
   Seyedin, Seyed Alireza
TI Salient object detection using the phase information and object model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient regions detection; Fourier transform (FT) phase; Frequency
   domain; Object detection; Ship detection; Optical character recognition
   (OCR); Task simulation
AB One of the most important features of saliency detection algorithms is to reduce the size of processing data for algorithms with higher processing size such as object detection algorithms. A main condition for algorithms of saliency detection to be used in detecting the object in the image is their low processing size and broadness of the application extent while having acceptable precision. In this article we introduce a Salient Object Detection method using Task Simulation (SOD-TS). This method has a low processing size and wide functional domain using task simulation (object model). Our proposed method has a wide range of application including ship detection, words and letter detection in texts, etc. Relying on the task simulation (object model), SOD-TS method detects the salient object which is the best response to the current task. It uses the information of the frequency domain.
C1 [Afsharirad, Hooman] Khorasan Inst Higher Educ, Moalem 77, Mashhad, Razavi Khorasan, Iran.
   [Seyedin, Seyed Alireza] Ferdowsi Univ Mashhad, Fac Engn, Azadi Sq, Mashhad, Razavi Khorasan, Iran.
C3 Ferdowsi University Mashhad
RP Afsharirad, H (corresponding author), Khorasan Inst Higher Educ, Moalem 77, Mashhad, Razavi Khorasan, Iran.
EM hooman.afsharirad@khorasan.ac.ir
CR Achanta R., 2008, COMP VIS SYS
   Achanta R., 2009, IEEE CVPR
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Aiger D, 2010, COMP VIS PATT REC CV
   [Anonymous], 2014, IEEE CVPR
   [Anonymous], 2013, IEEE ICCV
   [Anonymous], 2011, BMVC
   [Anonymous], 2013, IEEE Transactions on Pattern Analysis and Machine Intelligence, DOI DOI 10.1109/TPAMI.2012.89
   [Anonymous], 2013, IEEE CVPR
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Aytekin Ç, 2014, INT C PATT RECOG, P112, DOI 10.1109/ICPR.2014.29
   Bhatnagar G, 2013, INFORM SCIENCES, V223, P297, DOI 10.1016/j.ins.2012.09.053
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Borji A, 2013, VISION RES, V91, P62, DOI 10.1016/j.visres.2013.07.016
   Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333
   Chen TS, 2016, IEEE T NEUR NET LEAR, V27, P1135, DOI 10.1109/TNNLS.2015.2506664
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gue C, 2008, PROC IEEE INT CONF C
   Jia WY, 2018, IEEE T MAGN, V54, DOI 10.1109/TMAG.2018.2845700
   Jiang P, 2013, IEEE ICCV
   Kim J, 2014, IEEE CVPR
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li J., 2007, J LATEX CLASS, V6, P1, DOI DOI 10.1016/J.APPL
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   Liu N, 2018, IEEE T IMAGE PROCESS
   Liu Z, 2013, IEEE TIP
   Margolin R., 2013, VISUAL COMPUT, P1
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Movahedi V., 2010, IEEE CVPRW
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Rahtu E., 2010, ECCV
   Siva P, 2013, PROC CVPR IEEE, P3238, DOI 10.1109/CVPR.2013.416
   Tavakoli HR, 2011, LECT NOTES COMPUT SC, V6688, P666, DOI 10.1007/978-3-642-21227-7_62
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Tong N, 2015, PATTERN RECOGN, V48, P3258, DOI 10.1016/j.patcog.2014.12.005
   Wang JP, 2015, NEUROCOMPUTING, V152, P359, DOI 10.1016/j.neucom.2014.10.056
   Wang JD, 2017, INT J COMPUT VISION, V123, P251, DOI 10.1007/s11263-016-0977-3
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   WANG W, 2013, IEEE ICCV
   Xie Y, 2013, IEEE TIP, V22
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
   Zhang JM, 2018, INT J COMPUT VISION, V126, P1084, DOI 10.1007/s11263-017-1059-x
NR 48
TC 4
Z9 4
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19061
EP 19080
DI 10.1007/s11042-019-7255-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800006
DA 2024-07-18
ER

PT J
AU Bourouis, S
   Laalaoui, Y
   Bouguila, N
AF Bourouis, Sami
   Laalaoui, Yacine
   Bouguila, Nizar
TI Bayesian frameworks for traffic scenes monitoring via view-based 3D cars
   models recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Finite and infinite mixture models; Bayesian framework; Scaled
   Dirichlet; Markov Chain Monte Carlo (MCMC); Reversible jump MCMC
   (RJMCMC); Traffic scenes monitoring
ID DIRICHLET PROCESS MIXTURE; DISTRIBUTIONS; CALIBRATION; SELECTION;
   CAMERAS
AB Traffic Scenes Monitoring has been a topic of large research in the last decade. An important step is the recognition of cars. Indeed, recognizing 3D models of cars could allow efficient tracking and detection. In this work we propose to develop new flexible and powerful nonparametric frameworks for the problem of data modeling and 3D recognition. In particular, we propose a Bayesian inference method via scaled Dirichlet mixture models. The consideration of scaled Dirichlet mixture is encouraged by its flexibility recently obtained in several real-life applications. Moreover, the consideration of Bayesian learning is attractive in several ways. It makes it possible to take uncertainty into account by introducing prior information on the parameters, it permits to overcome learning issues regarding the under and/or over-fitting. and it permits simultaneous parameters estimation and model selection. We investigate in this work the integration of both Markov Chain Monte Carlo (MCMC) and reversible jump MCMC (RJMCMC) techniques for learning the resulting models. Detailed experiments have been conducted to demonstrate the advantages of our Bayesian frameworks.
C1 [Bourouis, Sami; Laalaoui, Yacine] Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, At Taif, Saudi Arabia.
   [Bouguila, Nizar] Concordia Univ, CIISE, Montreal, PQ H3G 1T7, Canada.
C3 Taif University; Concordia University - Canada
RP Bourouis, S (corresponding author), Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, At Taif, Saudi Arabia.
EM s.bourouis@tu.edu.sa; y.laalaoui@tu.edu.sa; nizar.bouguila@concordia.ca
RI Bourouis, Sami/N-4995-2019; Bouguila, Nizar/AGN-5929-2022; Laalaoui,
   Yacine/AGE-3118-2022; Bouguila, Nizar/AAJ-2518-2020
OI Bourouis, Sami/0000-0002-6638-7039; 
FU Deanship of Scientific Research at Taif University, KSA [1-437-5046]
FX We want to thank the Deanship of Scientific Research at Taif University,
   KSA, for their support under grant 1-437-5046. We want to thank also the
   associate editor and all reviewers.
CR Amayri O, 2016, 2016 INTERNATIONAL CONFERENCE ON CONTROL, DECISION AND INFORMATION TECHNOLOGIES (CODIT), P269, DOI 10.1109/CoDIT.2016.7593572
   Amayri O, 2013, ENG APPL ARTIF INTEL, V26, P1386, DOI 10.1016/j.engappai.2012.10.009
   [Anonymous], 1992, Statistical Science, DOI DOI 10.1214/SS/1177011143
   [Anonymous], 2003, STAT ANAL COMPOSITIO
   [Anonymous], 2018, MULTIMEDIA TOOLS APP
   [Anonymous], 2018, PATTERN RECOGNITION
   [Anonymous], 2005, P 2005 INT C IM PROC
   Bertrand Adrien, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10073, P359, DOI 10.1007/978-3-319-50832-0_35
   Beymer D, 1997, PROC CVPR IEEE, P495, DOI 10.1109/CVPR.1997.609371
   Bouguila N, 2005, LECT NOTES ARTIF INT, V3587, P42
   Bouguila N, 2005, LECT NOTES COMPUT SC, V3686, P172
   Bouguila N, 2004, IEEE T IMAGE PROCESS, V13, P1533, DOI 10.1109/TIP.2004.834664
   Bouguila N, 2006, IEEE T KNOWL DATA EN, V18, P993, DOI 10.1109/TKDE.2006.133
   Bouguila N, 2012, EXPERT SYST APPL, V39, P5946, DOI 10.1016/j.eswa.2011.11.122
   Bouguila N, 2010, J APPL STAT, V37, P235, DOI 10.1080/02664760802684185
   Bouguila N, 2010, IEEE T NEURAL NETWOR, V21, P107, DOI 10.1109/TNN.2009.2034851
   Bouguila N, 2008, MACHINE LEARN SIGN P, P297, DOI 10.1109/MLSP.2008.4685496
   Bouguila N, 2009, PATTERN ANAL APPL, V12, P151, DOI 10.1007/s10044-008-0111-4
   Bourouis S, 2018, INT J INTELL ENG INF, V6, P491, DOI 10.1504/IJIEI.2018.094513
   Channoufi I, 2018, 2018 4 INT C ADV TEC, P1
   Chen KY, 2011, 2011 6TH INTERNATIONAL ICST CONFERENCE ON COMMUNICATIONS AND NETWORKING IN CHINA (CHINACOM), P1032, DOI 10.1109/ChinaCom.2011.6158308
   Cho Y, 2006, IEEE T INTELL TRANSP, V7, P463, DOI 10.1109/TITS.2006.883934
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Elguebaly T, 2013, SIGNAL PROCESS, V93, P1531, DOI 10.1016/j.sigpro.2012.07.037
   Fan WT, 2015, COMPUT ELECTR ENG, V43, P48, DOI 10.1016/j.compeleceng.2015.03.018
   Fan WT, 2014, LECT NOTES ARTIF INT, V8779, P1, DOI 10.1007/978-3-319-11298-5_1
   Fan WT, 2013, IEEE T NEUR NET LEAR, V24, P1850, DOI 10.1109/TNNLS.2013.2268461
   Fan WT, 2013, PATTERN RECOGN, V46, P2754, DOI 10.1016/j.patcog.2013.03.026
   Fan WT, 2011, LECT NOTES COMPUT SC, V7063, P276, DOI 10.1007/978-3-642-24958-7_32
   FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360
   Gelfand AE, 2002, J COMPUT GRAPH STAT, V11, P289, DOI 10.1198/106186002760180518
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Jain S, 2004, J COMPUT GRAPH STAT, V13, P158, DOI 10.1198/1061860043001
   Karavasilis V, 2015, COMPUT VIS IMAGE UND, V140, P43, DOI 10.1016/j.cviu.2015.07.003
   Khraief C, 2012, INT CONF MULTIMED, P201, DOI 10.1109/ICMCS.2012.6320172
   Kim S, 2005, IEEE T INTELL TRANSP, V6, P178, DOI 10.1109/TITS.2005.848362
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MacEachern SN, 1998, J COMPUT GRAPH STAT, V7, P223, DOI 10.2307/1390815
   McLachlan G., 2000, WILEY SER PROB STAT, DOI 10.1002/0471721182
   Najar F., 2018, 2018 IEEE CAN C EL C, P1
   Najar F, 2017, I C COMP SYST APPLIC, P704, DOI 10.1109/AICCSA.2017.108
   Oboh ES, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1085, DOI 10.1109/ICIT.2017.7915513
   Rasmussen CE, 2000, ADV NEUR IN, V12, P554
   Richardson S, 1997, J ROY STAT SOC B MET, V59, P731, DOI 10.1111/1467-9868.00095
   Robert Christian P., 1999, Monte Carlo Statistical Methods, V2
   Schoepflin TN, 2003, IEEE T INTELL TRANSP, V4, P90, DOI 10.1109/TITS.2003.821213
   Shastry AC, 2005, IEEE T INTELL TRANSP, V6, P391, DOI 10.1109/TITS.2005.858621
   Song KT, 2006, IEEE T SYST MAN CY B, V36, P1091, DOI 10.1109/TSMCB.2006.872271
   Sun SL, 2006, IEEE T INTELL TRANSP, V7, P124, DOI 10.1109/TITS.2006.869623
   Veeraraghavan H, 2003, IEEE T INTELL TRANSP, V4, P78, DOI 10.1109/TITS.2003.821212
   Wang M, 2013, IEEE T IMAGE PROCESS, V22, P1395, DOI 10.1109/TIP.2012.2231088
   Weil R, 1998, MATH COMPUT MODEL, V27, P257, DOI 10.1016/S0895-7177(98)00064-8
NR 55
TC 8
Z9 8
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18813
EP 18833
DI 10.1007/s11042-019-7275-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200065
DA 2024-07-18
ER

PT J
AU Bulkan, U
   Dagiuklas, T
AF Bulkan, Utku
   Dagiuklas, Tasos
TI Predicting quality of experience for online video service provisioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality of experience (QoE); Machine learning; Online video services;
   Content delivery; QoE modelling; Subjective QoE assessment; H; 264; HTTP
   streaming; MPEG-DASH; VOD
AB The expansion of the online video content continues in every area of the modern connected world and the need for measuring and predicting the Quality of Experience (QoE) for online video systems has never been this important. This paper has designed and developed a machine learning based methodology to derive QoE for online video systems. For this purpose, a platform has been developed where video content is unicasted to users so that objective video metrics are collected into a database. At the end of each video session, users are queried with a subjective survey about their experience. Both quantitative statistics and qualitative user survey information are used as training data to a variety of machine learning techniques including Artificial Neural Network (ANN), K-nearest Neighbours Algorithm (KNN) and Support Vector Machine (SVM) with a collection of cross-validation strategies. This methodology can efficiently answer the problem of predicting user experience for any online video service provider, while overcoming the problematic interpretation of subjective consumer experience in terms of quantitative system capacity metrics.
C1 [Bulkan, Utku; Dagiuklas, Tasos] London South Bank Univ, Div Comp Sci, SuITE Res Grp, London, England.
C3 London South Bank University
RP Bulkan, U (corresponding author), London South Bank Univ, Div Comp Sci, SuITE Res Grp, London, England.
EM bulkanu@lsbu.ac.uk; tdagiuklas@lsbu.ac.uk
OI Bulkan, Utku/0000-0003-1177-0660
CR Akamai, 2016, MAX AUD ENG ONL VID
   Akamai, 2016, AK DEF MEAS ONL VID
   Ancillotti E, 2010, COMPUT COMMUN, P948
   Anegekuh L, 2015, CONTENT BASED VIDEO
   Anegekuh L, 2014, IEEE GLOB COMM CONF, P1152, DOI 10.1109/GLOCOM.2014.7036964
   [Anonymous], WOWZA TECHNOLOGIES W, P167
   [Anonymous], MATHWORKS APPL SUPER
   [Anonymous], 2003, IMPLEMENTATION FAST
   [Anonymous], 2016, MPX VIDEO MANAGEMENT
   Awad M, EFFICIENT LEARNING M, P42
   Ben-Hur A., A user's guide to support vector machines
   Bulkan U, 2017, 19 IEEE INT WORKSH M
   Cheon M, 2015, EVALUATION OBJECTIVE
   Cloudstreet, 2016, MOB OTT SOLV DEL FLA
   David S, KALTURE WHITEPAPER G
   Gardlo B, 2014, COMM QOS REL MOD S A
   Garrido-Cantos R, 2013, MULTIMEDIA SYST, V19, P163, DOI 10.1007/s00530-012-0287-8
   Gomez G, 2014, YOUTUBE QOE EVALUATI
   Heffernan S, 2012, STREAMING MEDIA IND, P166
   Hofeld T, 2011, IEEE INT S MULT GERM
   Hsiao S, 2011, SECURE PROXY BASED C
   ITU-T, 2016, PAR BITSTR BAS QUAL
   ITU-T, 2008, PERC VIS QUAL MEAS T, P246
   Jurgelionis A, 2011, EMPIRICAL STUDY NETE
   Knoll T, ITU STUDY PERIOD 201
   Kornich J, EMBEDDING MPEG DASH
   Larson KH, MOZILLA DEV NETWORK
   Li CL, 2018, IEEE T MULTIMEDIA, V20, P965, DOI 10.1109/TMM.2017.2757761
   Li M, 2013, QUALITY EXPERIENCE S
   Moyano RF, 2017, USER CENTRIC SDN MAN
   Myatt GJ, 2014, MAKING SENSE DATA, P168
   Nourikhah H, 2016, IMPACT SERVICE QUALI
   Ozer J, 2016, STREAMING MEDIA IND, P168
   Raudys A, 2016, TRANSFORM BUS ECON, V15, P480
   Volk T, 2015, CROWDSOURCING VS LAB
   Wamser F, 2016, MODELING YOUTUBE STA
   Xiaohua L, 2013, DESIGN IMPLEMENTATIO
   Zhou L, 2017, IEEE T CIRCUITS SYST, V27
   Zhu Y, 2015, UNDERSTANDING ROLE S
   Zielesny A., 2011, From Curve Fitting to Machine Learning: An Illustrative Guide to Scientific and Computational Intelligence, DOI DOI 10.1007/978-3-642-21280-2
NR 40
TC 7
Z9 7
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18787
EP 18811
DI 10.1007/s11042-019-7164-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200064
OA hybrid
DA 2024-07-18
ER

PT J
AU Chaudhary, C
   Goyal, P
   Tuli, S
   Banthia, S
   Goyal, N
   Chen, YPP
AF Chaudhary, Chandramani
   Goyal, Poonam
   Tuli, Siddhant
   Banthia, Shuchita
   Goyal, Navneet
   Chen, Yi-Ping Phoebe
TI A novel multimodal clustering framework for images with diverse
   associated text
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bipartite graph; Hierarchical agglomerative clustering; Query-log;
   Search result clustering; Tags and surrounding text
ID SEMANTIC GAP; RETRIEVAL; GRAPH
AB With the enormous growth in the number of images on the web, image clustering has become an essential part of any image retrieval system. Since web images are often accompanied by related text or tags, both visual and textual features can be exploited to improve the precision of web image clustering. Existing clustering methods either utilize them separately in a specific order, or use them simultaneously, but independently. In this work, we propose a new framework, Multimodal Hierarchical Clustering for Images (MHCI), which exploits the coexistence of both visual and textual patterns to establish a relationship between them. We propose textual and visual weights to quantify the relationship established between images and their features. The proposed framework can be applied to a wide variety of image datasets with different characteristics, viz., search results with noisy surrounding text, and tagged images. It can also cluster image search queries and their corresponding clicked images. The respective datasets used include image search results, Flicker (NUS-WIDE), and Clickture (Bing query-log). The proposed framework is shown to be versatile on Clickture dataset, which has not been examined by any of the previous approaches. The experimental results show that MHCI significantly improves the quality of image clusters as compared to existing methods.
C1 [Chaudhary, Chandramani; Goyal, Poonam; Tuli, Siddhant; Banthia, Shuchita; Goyal, Navneet] BITS Pilani, Dept Comp Sci & Informat Syst, Pilani Campus, Pilani 333031, Rajasthan, India.
   [Chen, Yi-Ping Phoebe] La Trobe Univ, Dept Comp Sci & Informat Technol, Melbourne, Vic 3086, Australia.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani); La Trobe
   University
RP Chaudhary, C (corresponding author), BITS Pilani, Dept Comp Sci & Informat Syst, Pilani Campus, Pilani 333031, Rajasthan, India.
EM chandramani.chaudhary@pilani.bits-pilani.ac.in;
   poonam@pilani.bits-pilani.ac.in; f2012077@pilani.bits-pilani.ac.in;
   f2012011@pilani.bits-pilani.ac.in; goel@pilani.bits-pilani.ac.in;
   phoebe.chen@latrobe.edu.au
RI Chaudhary, Chandramani/AAZ-2568-2021; Chen, Yi-Ping Phoebe/B-8844-2008
OI Goyal, Poonam/0000-0003-1556-9905; Chen, Yi-Ping
   Phoebe/0000-0002-4122-3767
CR Abebe Minale A., 2016, 2016 19th IEEE International Conference on Computational Science and Engineering (CSE), IEEE 14th International Conference on Embedded and Ubiquitous Computing (EUC), and 15th International Symposium on Distributed Computing and Applications for Business Engineering (DCABES). Proceedings, P512, DOI 10.1109/CSE-EUC-DCABES.2016.234
   Agrawal Rajeev, 2007, IEEE International Symposium on Computational Intelligence in Robotics and Automation, 2007, P49
   [Anonymous], P IEEE SMC
   [Anonymous], MSRTR201375
   [Anonymous], P MULT ACM
   [Anonymous], INF SYST
   [Anonymous], 1988, ALGORITHMS CLUSTERIN
   [Anonymous], P CIVR ACM
   [Anonymous], P MULT ACM
   [Anonymous], IEEE T NEURAL NETWOR
   [Anonymous], P AUSDM
   [Anonymous], 2002, IMAGE DATABASES
   [Anonymous], P ACM INT C MULT, DOI DOI 10.1145/1101149.1101167
   [Anonymous], IEEE T TMM
   [Anonymous], 2017, P ICCV
   Ayoub Issa, 2016, 2016 19th IEEE International Conference on Computational Science and Engineering (CSE), IEEE 14th International Conference on Embedded and Ubiquitous Computing (EUC), and 15th International Symposium on Distributed Computing and Applications for Business Engineering (DCABES). Proceedings, P287, DOI 10.1109/CSE-EUC-DCABES.2016.199
   Beeferman D., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P407, DOI 10.1145/347090.347176
   Broilo M, 2010, IEEE T MULTIMEDIA, V12, P267, DOI 10.1109/TMM.2010.2046269
   Chen Y., 2009, P ACM INT C MULTIMED, P689
   Chen YX, 2005, IEEE T IMAGE PROCESS, V14, P1187, DOI 10.1109/TIP.2005.849770
   CUTTING DR, 1992, SIGIR 92 : PROCEEDINGS OF THE FIFTEENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P318
   Pedronette DCG, 2012, INFORM SCIENCES, V207, P19, DOI 10.1016/j.ins.2012.04.032
   Hamzaoui A, 2011, MULTIMED TOOLS APPL, V51, P479, DOI 10.1007/s11042-010-0637-5
   Hoi S.C., 2008, CVPR, P1, DOI DOI 10.1109/CVPR.2008.4587351
   Hu Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P603
   Kaiqi Zhao, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8726, P369, DOI 10.1007/978-3-662-44845-8_24
   Krishnamachari S, 1999, IEEE SYMP COMP COMMU, P301, DOI 10.1109/ISCC.1999.780837
   Larsen Bjornar., 1999, KDD
   Li HF, 2018, PATTERN RECOGN, V79, P130, DOI 10.1016/j.patcog.2018.02.005
   Li P, 2013, IEEE T MULTIMEDIA, V15, P141, DOI 10.1109/TMM.2012.2199970
   Li X, 2016, MECH MATER, V99, P1, DOI 10.1016/j.mechmat.2016.04.010
   Liang JQ, 2016, MULTIMEDIA SYST, V22, P149, DOI 10.1007/s00530-014-0433-6
   Liu QS, 2017, IEEE T IMAGE PROCESS, V26, P452, DOI 10.1109/TIP.2016.2621671
   Lowe DG, 1999, P 7 IEEE INT C COMP, P1150
   Ma H, 2010, IEEE T MULTIMEDIA, V12, P462, DOI 10.1109/TMM.2010.2051360
   Moellic P., 2008, P CIVR 08 NIAGARA FA, P269
   Nahar J, 2013, EXPERT SYST APPL, V40, P96, DOI 10.1016/j.eswa.2012.07.032
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Priyogi B, 2014, LECT NOTES COMPUT SC, V8407, P179, DOI 10.1007/978-3-642-55032-4_18
   Rege M., 2008, Proceeding of the 17th international conference on World Wide Web, P317
   Tan P. N., 2014, INTRO DATA MINING
   Tang XO, 2012, IEEE T PATTERN ANAL, V34, P1342, DOI 10.1109/TPAMI.2011.242
   Tao D, 2018, IEEE T NEURAL NETWOR, P1
   Tao DP, 2018, IEEE T IMAGE PROCESS, V27, P325, DOI 10.1109/TIP.2017.2762588
   Tsai JT, 2014, IEEE T MULTIMEDIA, V16, P2229, DOI 10.1109/TMM.2014.2359769
   Van Leuken Reinier H, 2009, P 18 INT C WORLD WID, P341, DOI 10.1145/1526709.1526756
   Wang XD, 2017, IMAGE VISION COMPUT, V63, P10, DOI 10.1016/j.imavis.2017.05.004
   Wang XD, 2016, NEUROCOMPUTING, V200, P47, DOI 10.1016/j.neucom.2016.03.017
   Wu F, 2014, TELEMAT INFORM, V31, P477, DOI 10.1016/j.tele.2013.10.002
   Xia DS, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P116, DOI 10.1109/BigMM.2015.35
   Yan Y, 2017, MULTIMEDIA SYST, V23, P41, DOI 10.1007/s00530-014-0419-4
   Yang Y, 2014, IEEE T MULTIMEDIA, V16, P1700, DOI 10.1109/TMM.2014.2326836
   Yu J, 2014, IEEE T MULTIMEDIA, V16, P159, DOI 10.1109/TMM.2013.2284755
   Zhao R, 2002, IEEE T MULTIMEDIA, V4, P189, DOI 10.1109/TMM.2002.1017733
NR 54
TC 6
Z9 6
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17623
EP 17652
DI 10.1007/s11042-018-7131-x
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200015
DA 2024-07-18
ER

PT J
AU Lim, KM
   Tan, AWC
   Lee, CP
   Tan, SC
AF Lim, Kian Ming
   Tan, Alan Wee Chiat
   Lee, Chin Poo
   Tan, Shing Chiang
TI Isolated sign language recognition using Convolutional Neural Network
   hand modelling and Hand Energy Image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sign language recognition; Convolutional Neural Network; Hand Energy
   Image; Hand gesture recognition
ID ROBUST OBJECT TRACKING; VISUAL TRACKING; SEGMENTATION; ARCHITECTURE;
   FILTER
AB This paper presents an isolated sign language recognition system that comprises of two main phases: hand tracking and hand representation. In the hand tracking phase, an annotated hand dataset is used to extract the hand patches to pre-train Convolutional Neural Network (CNN) hand models. The hand tracking is performed by the particle filter that combines hand motion and CNN pre-trained hand models into a joint likelihood observation model. The predicted hand position corresponds to the location of the particle with the highest joint likelihood. Based on the predicted hand position, a square hand region centered around the predicted position is segmented and serves as the input to the hand representation phase. In the hand representation phase, a compact hand representation is computed by averaging the segmented hand regions. The obtained hand representation is referred to as Hand Energy Image (HEI). Quantitative and qualitative analysis show that the proposed hand tracking method is able to predict the hand positions that are closer to the ground truth. Similarly, the proposed HEI hand representation outperforms other methods in the isolated sign language recognition.
C1 [Lim, Kian Ming; Lee, Chin Poo; Tan, Shing Chiang] Multimedia Univ, Fac Informat Sci & Technol, Jalan Ayer Keroh Lama, Melaka 75450, Malaysia.
   [Tan, Alan Wee Chiat] Multimedia Univ, Fac Engn & Technol, Jalan Ayer Keroh Lama, Melaka 75450, Malaysia.
C3 Multimedia University; Multimedia University
RP Lim, KM (corresponding author), Multimedia Univ, Fac Informat Sci & Technol, Jalan Ayer Keroh Lama, Melaka 75450, Malaysia.
EM kmlim@mmu.edu.my
RI Tan, SC/E-6463-2010; /AGV-9105-2022; Lim, Kian Ming/AGV-8623-2022
OI Tan, SC/0000-0002-1267-1894; Lee, Chin Poo/0000-0003-3679-8977; Lim,
   Kian Ming/0000-0003-1929-7978
FU Multimedia University Mini Fund [MMUI/180182]
FX This research is supported by Multimedia University Mini Fund, Grant No.
   MMUI/180182. We gratefully acknowledge the support of NVIDIA Corporation
   with the donation of the Quadro P6000 GPU used for this research.
CR [Anonymous], 2008, IEEE INT C AUTOMATIC, DOI DOI 10.1109/AFGR.2008.4813439
   [Anonymous], 2012, Computer vision: models, learning, and inference
   Aran O, 2009, 4 INT SUMM WORKSH MU, P24
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Assan M., 1997, PROC GESTURE WORKSHO, P97
   Athitsos V, 2008, PROC CVPR IEEE, P1666
   Babu RV, 2004, IMAGE VISION COMPUT, V22, P597, DOI 10.1016/j.imavis.2003.11.004
   Belgacem S, 2012, LECT NOTES COMPUT SC, V7594, P288, DOI 10.1007/978-3-642-33564-8_35
   Chen FS, 2003, IMAGE VISION COMPUT, V21, P745, DOI 10.1016/S0262-8856(03)00070-2
   Chen SY, 2012, IEEE T IND ELECTRON, V59, P4409, DOI 10.1109/TIE.2011.2162714
   Cihan Camgoz N., 2017, IEEE INT C COMP VIS
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Coogan T, 2006, LECT NOTES COMPUT SC, V4291, P495
   Dai Q, 2017, PROCEEDINGS OF THE 23RD ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM '17), P462, DOI 10.1145/3117811.3119853
   Debevc M, 2012, LECT NOTES COMPUT SC, V7383, P213, DOI 10.1007/978-3-642-31534-3_33
   ELMEZAIN M, 2010, WASET, V3, P131
   Fan JL, 2010, IEEE T NEURAL NETWOR, V21, P1610, DOI 10.1109/TNN.2010.2066286
   Fang GL, 2004, IEEE T SYST MAN CY A, V34, P305, DOI 10.1109/TSMCA.2004.824852
   FELS SS, 1993, IEEE T NEURAL NETWOR, V4, P2, DOI 10.1109/72.182690
   Funk N., 2003, A study of the kalman filter applied to visual tracking, V652, P6
   Gattupalli S., 2016, Proceedings of the 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments, P12
   Gaus Y. F. A., 2012, Proceedings of the 2012 3rd International Conference on Intelligent Systems, Modelling and Simulation (ISMS 2012), P262, DOI 10.1109/ISMS.2012.67
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Han J, 2009, IET COMPUT VIS, V3, P24, DOI 10.1049/iet-cvi:20080006
   He T, 2017, NEURAL COMPUT APPL, V28, P3827, DOI 10.1007/s00521-016-2277-9
   Hinton G. E., 2012, 12070580 ARXIV
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Imagawa K, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P462, DOI 10.1109/AFGR.1998.670991
   Jeyakar J, 2008, COMPUT VIS IMAGE UND, V112, P296, DOI 10.1016/j.cviu.2008.05.005
   Jung-Ho Kim, 2016, Journal of Computing Science and Engineering, V10, P95, DOI 10.5626/JCSE.2016.10.3.95
   Kadous M W., 1996, P WORKSHOP INTEGRATI, P165
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kong WW, 2008, PATTERN RECOGN, V41, P1638, DOI 10.1016/j.patcog.2007.10.016
   Kosmidou VE, 2009, IEEE T BIO-MED ENG, V56, P2879, DOI 10.1109/TBME.2009.2013200
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li Y, 2012, IEEE T BIO-MED ENG, V59, P2695, DOI 10.1109/TBME.2012.2190734
   Morshidi M, 2014, PATTERN RECOGN, V47, P194, DOI 10.1016/j.patcog.2013.06.032
   Mujacic S, 2012, MULTIMED TOOLS APPL, V58, P435, DOI 10.1007/s11042-010-0665-1
   Murakami K., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P237, DOI 10.1145/108844.108900
   Nadgeri S. M., 2010, Proceedings of the Third International Conference on Emerging Trends in Engineering and Technology (ICETET 2010), P37, DOI 10.1109/ICETET.2010.63
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Neidle C., 2012, 5 WORKSH REPR PROC S
   Neidle C, 2009, P 21 ESSLLI WORKSH F
   Oliver M. B., 2017, The international encyclopedia of media effects, P1, DOI [10.1002/9781118783764.wbieme0164, DOI 10.1002/9781118783764.WBIEME0164]
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Otsu N., 2007, IEEE T SYS MAN CYBER, V9, P66, DOI [DOI 10.1109/TSMC.1979.4310076, 10.1109/TSMC.1979.4310076]
   Pigou L, 2014, EUR C COMP VIS WORKS
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Ruffieux S, 2014, LECT NOTES COMPUT SC, V8511, P337, DOI 10.1007/978-3-319-07230-2_33
   Rybach D, 2006, THESIS RHENISCH WEST
   Shan CF, 2007, PATTERN RECOGN, V40, P1958, DOI 10.1016/j.patcog.2006.12.012
   Weng SK, 2006, J VIS COMMUN IMAGE R, V17, P1190, DOI 10.1016/j.jvcir.2006.03.004
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Starner T., 1997, Motion-Based Recognit, P227
   Su RL, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010100
   Thangali A, 2011, PROC CVPR IEEE, P521, DOI 10.1109/CVPR.2011.5995718
   Valli C., 2005, GALLAUDET DICT AM SI
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Vogler C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P363, DOI 10.1109/ICCV.1998.710744
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang Q, 2012, IEEE T IMAGE PROCESS, V21, P3296, DOI 10.1109/TIP.2012.2190085
   Wang R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531397
   Welch G., 2001, P SIGGRAPH COURS, V8, P27599
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xiao Zou, 2013, Journal of Multimedia, V8, P1, DOI 10.4304/jmm.8.1.1-7
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zahedi M, 2005, LECT NOTES COMPUT SC, V3663, P401
   Zaki MM, 2011, PATTERN RECOGN LETT, V32, P572, DOI 10.1016/j.patrec.2010.11.013
   Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0
   Zhang W, 2013, IEEE INT CONF CLOUD, P629, DOI 10.1109/CLOUD.2013.34
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
NR 75
TC 35
Z9 42
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19917
EP 19944
DI 10.1007/s11042-019-7263-7
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800045
OA Bronze
DA 2024-07-18
ER

PT J
AU Park, JS
   Soh, JW
   Cho, NI
AF Park, Jae Sung
   Soh, Jae Woong
   Cho, Nam Ik
TI Generation of high dynamic range illumination from a single image for
   the enhancement of undesirably illuminated images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High dynamic range imaging; Single-image high dynamic range imaging;
   Image enhancement; Illumination adjustment; Multi-exposure fusion
ID ADAPTIVE HISTOGRAM EQUALIZATION; EXPOSURE FUSION; FRAMEWORK; ALGORITHM
AB This paper presents an algorithm that enhances undesirably illuminated images by generating and fusing multi-level illuminations from a single image. The input image is first decomposed into illumination and reflectance components by using an edge-preserving smoothing filter. Then the reflectance component is scaled up to improve the image details in bright areas. The illumination component is scaled up and down to generate several illumination images that correspond to certain camera exposure values different from the original. The virtual multi-exposure illuminations are blended into an enhanced illumination, where we also propose a method to generate appropriate weight maps for the tone fusion. Finally, an enhanced image is obtained by multiplying the equalized illumination and enhanced reflectance. Experiments show that the proposed algorithm produces visually pleasing output and also yields comparable objective results to the conventional enhancement methods, while requiring modest computational loads.
C1 [Park, Jae Sung] Samsung Elect, Gyoenggi Do, South Korea.
   [Soh, Jae Woong; Cho, Nam Ik] Seoul Natl Univ, INMC, Dept Elect & Comp Engn, Seoul, South Korea.
C3 Samsung Electronics; Samsung; Seoul National University (SNU)
RP Cho, NI (corresponding author), Seoul Natl Univ, INMC, Dept Elect & Comp Engn, Seoul, South Korea.
EM nicho@snu.ac.kr
RI Cho, Nam Ik/I-5029-2014
FU MSIT(Ministry of Science and ICT), Korea, under the ITRC(Information
   Technology Research Center) support program [IITP-2018-2016-0-00288]
FX This research was supported by the MSIT(Ministry of Science and ICT),
   Korea, under the ITRC(Information Technology Research Center) support
   program(IITP-2018-2016-0-00288) supervised by the IITP(Institute for
   Information & communications Technology Promotion).
CR Ahn B., 2017, ARXIV170400524
   Akyüz AG, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276425
   An J, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-42
   An J, 2012, INT CONF ACOUST SPEE, P1101, DOI 10.1109/ICASSP.2012.6288079
   An J, 2011, INT CONF ACOUST SPEE, P1565
   [Anonymous], SPIE PHOTONICS EUROP
   [Anonymous], IM AN TRANSP APPL IE
   [Anonymous], 2013, Computational Information Systems
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Banterle F, 2011, ADVANCED HIGH DYNAMIC RANGE IMAGING: THEORY AND PRACTICE, P1
   Banterle F., 2006, P 4 INT C COMP GRAPH, P349
   Banterle F., 2008, P 24 SPRING C COMP G, P33, DOI 10.1145/1921264.1921275
   Baxes G. A., 1994, Digital Image Processing-Principles and Applications
   Bennett EP, 2005, ACM T GRAPHIC, V24, P845, DOI 10.1145/1073204.1073272
   Celik T, 2011, IEEE T IMAGE PROCESS, V20, P3431, DOI 10.1109/TIP.2011.2157513
   Chen CR, 2011, P ASS ANN SUMM C AS
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Deng G, 2011, IEEE T IMAGE PROCESS, V20, P1249, DOI 10.1109/TIP.2010.2092441
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Eisemann E, 2004, ACM T GRAPHIC, V23, P673, DOI 10.1145/1015706.1015778
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Gonzalez R.C., 2007, Digital image processing, P2
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Heidrich Wolfgang, ERIK REINHARD
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998
   Lee CH, 2012, IEEE T CONSUM ELECTR, V58, P1253, DOI 10.1109/TCE.2012.6414993
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Mertens T, 2009, COMPUT GRAPH FORUM, V28, P161, DOI 10.1111/j.1467-8659.2008.01171.x
   Messina G, 2003, P 2003 INT C MULT EX, V1, pI
   Meylan L, 2004, CGIV 2004: SECOND EUROPEAN CONFERENCE ON COLOR IN GRAPHICS, IMAGING, AND VISION - CONFERENCE PROCEEDINGS, P359
   Meylan L., 2006, COLOR IMAGING C, V1, P333, DOI [10.2352/CIC.2006.14.1.ART00061, DOI 10.2352/CIC.2006.14.1.ART00061]
   Min DB, 2014, IEEE T IMAGE PROCESS, V23, P5638, DOI 10.1109/TIP.2014.2366600
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Nayar SK, 2000, PROC CVPR IEEE, P472, DOI 10.1109/CVPR.2000.855857
   Pisano ED, 1998, J DIGIT IMAGING, V11, P193, DOI 10.1007/BF03178082
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Rempel AG, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239490
   Tsai DY, 2008, J DIGIT IMAGING, V21, P338, DOI 10.1007/s10278-007-9044-5
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang TH, 2015, IEEE T MULTIMEDIA, V17, P470, DOI 10.1109/TMM.2015.2403612
   Wang YT, 2013, SIGNAL PROCESS, V93, P3227, DOI 10.1016/j.sigpro.2013.04.025
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yoon DI, 2008, CONTRAST ENHANCEMENT
   Zhang E., 2015, Applied Mathematics & Information Sciences, V9, P411
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
NR 49
TC 14
Z9 15
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20263
EP 20283
DI 10.1007/s11042-019-7384-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800060
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Unnikrishnan, A
   Sowmya, V
   Soman, KP
AF Unnikrishnan, Anju
   Sowmya, V.
   Soman, K. P.
TI Deep learning architectures for land cover classification using red and
   near-infrared satellite images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Satellite image classification; SAT-4; SAT-6; Landcover; Trainable
   parameters; Normalized difference vegetation index; Image processing
AB Classification of remotely sensed data requires the modelling of suitable image processing algorithms. The rise of machine learning systems upgraded the viability of satellite image applications. Using Convolutional Neural Networks (CNN), benchmark classification exactness can be accomplished for land cover grouping. Motivated by the concept of Normalized Difference Vegetation Index (NDVI), this paper utilizes only the red and near infrared (NIR) band information for classifying the publicly available SAT-4 and SAT-6 datasets. This is done, since NDVI computation requires only the two band (red and NIR) information and the classes involved in the dataset are types of vegetation. In this work, new deep learning architectures for three different networks (AlexNet, ConvNet, VGG) were proposed by hypertuning the network and the input as two band data. The modified architectures with the two band information along with reduced number of filters were trained and tested model manages to classify the images into different classes. The proposed architectures are compared against the existing architectures in terms of accuracy, precision and trainable parameters. The proposed architecture is found to perform equally efficient by retaining high accuracy with less number of trainable parameters, when compared against the the performance of benchmark deep learning architectures for satellite image classification.
C1 [Unnikrishnan, Anju; Sowmya, V.; Soman, K. P.] Amrita Vishwa Vidyapeetham, Amrita Sch Engn, Ctr Computat Engn & Networking CEN, Coimbatore, Tamil Nadu, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Coimbatore
RP Sowmya, V (corresponding author), Amrita Vishwa Vidyapeetham, Amrita Sch Engn, Ctr Computat Engn & Networking CEN, Coimbatore, Tamil Nadu, India.
EM v_sowmya@cb.amrita.edu
RI V, Sowmya/R-5897-2017
OI V, Sowmya/0000-0003-3745-6944
CR [Anonymous], 2017, INT S SIGN PROC INT
   Audebert N, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9040368
   Basu S, 2015, 23RD ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2015), DOI 10.1145/2820783.2820816
   Bragilevsky L, 2017, COMMUN COMPUT PHYS, P1
   Chen HN, 2017, INT GEOSCI REMOTE SE, P4878, DOI 10.1109/IGARSS.2017.8128096
   Dahigamuwa T, 2016, GEOSCIENCES, V6, DOI 10.3390/geosciences6040045
   Dev S, 2016, IEEE GEOSC REM SEN M, V4, P79, DOI 10.1109/MGRS.2015.2510448
   Dixon K, 2016, INDIAN J SCI TECHNOL, V9, P1
   Dutta Suvajit, 2017, IOP Conference Series: Materials Science and Engineering, V263, DOI 10.1088/1757-899X/263/4/042097
   Haridas N, 2016, ADV INTELL SYST, V384, P521, DOI 10.1007/978-3-319-23036-8_45
   Jayaprakash C, 2017, PROCEDIA COMPUT SCI, V115, P399, DOI 10.1016/j.procs.2017.09.098
   Jeevalakshmi D, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1332, DOI 10.1109/ICCSP.2016.7754369
   Kaiser P, 2017, IEEE T GEOSCI REMOTE, V55, P6054, DOI 10.1109/TGRS.2017.2719738
   Li H., 2017, ARXIV170510450
   Liu QS, 2018, IEEE T GEOSCI REMOTE, V56, P117, DOI 10.1109/TGRS.2017.2743243
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Lunga D, 2018, IEEE J-STARS, V11, P962, DOI 10.1109/JSTARS.2018.2795753
   Makantasis K, 2015, INT GEOSCI REMOTE SE, P4959, DOI 10.1109/IGARSS.2015.7326945
   Manthira Moorthi S., 2011, 2011 IEEE Recent Advances in Intelligent Computational Systems (RAICS 2011), P107, DOI 10.1109/RAICS.2011.6069282
   Nath SS, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICCICCT), P554, DOI 10.1109/ICCICCT.2014.6993023
   Nie LQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1192, DOI 10.1145/3123266.3123313
   Özbay B, 2017, SIG PROCESS COMMUN
   Paisitkriangkrai S, 2016, IEEE J-STARS, V9, P2868, DOI 10.1109/JSTARS.2016.2582921
   Papadomanolaki M, 2016, ISPRS ANN PHOTO REM, V3, P83, DOI 10.5194/isprsannals-III-7-83-2016
   Song XM, 2018, ACM/SIGIR PROCEEDINGS 2018, P5, DOI 10.1145/3209978.3209996
   Srivatsa S, 2016, P INT C ADV COMP NET, P22
   Nguyen VH, 2017, INT CONF SYST SCI EN, P753, DOI 10.1109/ICSSE.2017.8030977
   Xu Dong, 2013, MATH PROBLEMS ENG
   Zhang C, 2014, HYPERSPECTRAL IMAGE, P1, DOI 10.1002/9783527671403.hlc072
NR 29
TC 20
Z9 20
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18379
EP 18394
DI 10.1007/s11042-019-7179-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200047
DA 2024-07-18
ER

PT J
AU Vakaimalar, E
   Mala, K
   Babu, RS
AF Vakaimalar, E.
   Mala, K.
   Babu, Suresh R.
TI Multifocus image fusion scheme based on discrete cosine transform and
   spatial frequency
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; DCT; Spatial frequency; Min-Max normalization
ID WAVELET TRANSFORM; PARALLEL FRAMEWORK; FOCUS IMAGES
AB Multifocus images are different images of the same scene captured with different focus in the cameras. These images when considered individually may not give good quality. Hence to obtain a good quality image, this work proposes an algorithm for fusing multifocus images using Discrete Cosine Transform and spatial frequency. The proposed algorithm works for fusing any number of images. The second step calculates the average and maximum of all the source images and reduces the source images to be processed as two. Then Discrete Cosine Transform (DCT) is applied over the two input images. Min-Max normalization is done on the DCT coefficients and fusion is done using spatial frequency. Inclusion of the second step of the proposed algorithm in some existing algorithms such as Stationary Wavelet Transform, Principal Component Analysis and spatial fusion improves the performance. The metrics used for evaluation proves that the proposed algorithm gives better results than the other algorithms using DCT and state of the art techniques.
C1 [Vakaimalar, E.] Kamaraj Coll Engn & Technol, Informat Technol, Virudunagar, Tamil Nadu, India.
   [Mala, K.] Mepco Schlenk Engn Coll, Comp Sci & Engn, Sivakasi, Tamil Nadu, India.
   [Babu, Suresh R.] Kamaraj Coll Engn & Technol, Elect & Commun Engn, Virudunagar, Tamil Nadu, India.
C3 Kamaraj College of Engineering & Technology; Mepco Schlenk Engineering
   College; Kamaraj College of Engineering & Technology
RP Vakaimalar, E (corresponding author), Kamaraj Coll Engn & Technol, Informat Technol, Virudunagar, Tamil Nadu, India.
EM vakaimalarit@kamarajengg.edu.in; kmalaudhaya@gmail.com;
   hodece@kamarajengg.edu.in
RI Mala, Kaliappan/GOP-1003-2022
OI Mala, Kaliappan/0000-0003-2717-6404
CR Aishwarya N, 2017, MULTIMED TOOLS APPL, V76, P21869, DOI 10.1007/s11042-017-4583-3
   Aslantas V, 2010, EXPERT SYST APPL, V37, P8861, DOI 10.1016/j.eswa.2010.06.011
   Cao L, 2015, IEEE SIGNAL PROC LET, V22, P220, DOI 10.1109/LSP.2014.2354534
   Darji AD, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-47
   Ellmauthaler A, 2013, IEEE T IMAGE PROCESS, V22, P1005, DOI 10.1109/TIP.2012.2226045
   Esteban J, 2005, NEURAL COMPUT APPL, V14, P273, DOI 10.1007/s00521-004-0463-7
   Haghighat MBA, 2011, COMPUT ELECTR ENG, V37, P789, DOI 10.1016/j.compeleceng.2011.04.016
   Han J., 2006, Data Mining, Southeast Asia Edition, V2nd, P70
   Hang RL, 2016, IEEE T GEOSCI REMOTE, V54, P783, DOI 10.1109/TGRS.2015.2465899
   Hongbo Wu, 2010, Proceedings 2010 International Conference on Progress in Informatics and Computing (PIC 2010), P936, DOI 10.1109/PIC.2010.5687880
   Jagalingam P, 2015, AQUAT PR, V4, P133, DOI 10.1016/j.aqpro.2015.02.019
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li S, 2013, INFORM FUSION, V14, P147, DOI 10.1016/j.inffus.2011.07.001
   Liu CP, 2016, OPTIK, V127, P11354, DOI 10.1016/j.ijleo.2016.09.038
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Lu QK, 2016, IEEE GEOSCI REMOTE S, V13, P515, DOI 10.1109/LGRS.2016.2521418
   Naidu VPS, 2011, DEFENCE SCI J, V61, P479, DOI 10.14429/dsj.61.705
   Petrovic VS, 2004, IEEE T IMAGE PROCESS, V13, P228, DOI 10.1109/tip.2004.823821
   Raol JitendraR., 2010, MULTISENSOR DATA FUS
   Siddiqui AB, 2010, P INT C IEEE, P6949
   Teng JH, 2010, LECT NOTES COMPUT SC, V6146, P627, DOI 10.1007/978-3-642-13498-2_82
   Vijayarajan R, 2015, AEU-INT J ELECTRON C, V69, P896, DOI 10.1016/j.aeue.2015.02.007
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang Y, 2015, IEEE SENS J, V15, P2824, DOI 10.1109/JSEN.2014.2380153
   Yang Y, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/579341
   Yu NN, 2011, IEEE J-STSP, V5, P1074, DOI 10.1109/JSTSP.2011.2112332
   Zhang YJ, 2009, DIGIT SIGNAL PROCESS, V19, P186, DOI 10.1016/j.dsp.2008.11.002
   Zhang YX, 2016, OPTIK, V127, P1291, DOI 10.1016/j.ijleo.2015.10.098
   Zhang YD, 2010, J BIOL SYST, V18, P115, DOI 10.1142/S0218339010003652
   Zhao HJ, 2013, PATTERN RECOGN, V46, P1002, DOI 10.1016/j.patcog.2012.09.012
   Zheng S, 2007, IEEE T IMAGE PROCESS, V16, P1831, DOI 10.1109/TIP.2007.896687
   Zhou Z, 2014, INFORM FUSION, V20, P60, DOI 10.1016/j.inffus.2013.11.005
NR 38
TC 14
Z9 15
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17573
EP 17587
DI 10.1007/s11042-018-7124-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200012
DA 2024-07-18
ER

PT J
AU Xu, LH
   Chen, JY
   Gan, YL
AF Xu, Luhui
   Chen, Jingying
   Gan, Yanling
TI Head pose estimation using improved label distribution learning with
   fewer annotations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Head pose estimation; Weak learning; Regularization; Fine-tune
AB Head pose estimation in unconstrained environment remains a challenging task due to background clutter, illumination changes, and appearance variabilities. Multivariate label distribution has been successfully applied to head pose estimation. However, it is not applicable to unconstrained environments where assigning reasonable label distributions for images is difficult, and its performance significantly degrades when accurate grid information is unavailable (e.g., only yaw angles are known). To alleviate these problems, we propose an improved label distribution learning approach with fewer annotations. A data-driven weak learning strategy is first developed to construct label distributions to alleviate the problem of unreasonable label distributions. Regularization terms (e.g., L-1,L-2 norm) are then introduced into the loss function induced by weighted Jeffreys divergence to avoid over-fitting. To further ameliorate the performance, positive correlation and negative competition are also introduced into the loss function to fine-tune the parameters of the corresponding model. Extensive experiments have been conducted on public databases: LFW and Pointing04. The proposed method achieves comparable performance over the state-of-art and possesses good generalization ability, but uses only fewer annotations, which suggests that it has strong potential for head pose estimation in unconstrained environments where sufficient annotations are routinely unavailable.
C1 [Xu, Luhui; Chen, Jingying; Gan, Yanling] Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan, Hubei, Peoples R China.
C3 Central China Normal University
RP Chen, JY (corresponding author), Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan, Hubei, Peoples R China.
EM chenjy@mail.ccnu.edu.cn
FU National Key Research and Development Program of China [2018YFB1004504];
   Research Funds of CCNU from the Colleges' Basic Research and Operation
   of MOE [CCNU17ZDJC04]
FX This work was supported by the National Key Research and Development
   Program of China (Grant No. 2018YFB1004504), Research Funds of CCNU from
   the Colleges' Basic Research and Operation of MOE (Grant No.
   CCNU17ZDJC04).
CR [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Bao J, 2016, CYBERN INF TECHNOL, V16, P133, DOI 10.1515/cait-2016-0083
   Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Chen JW, 2016, IEEE SW SYMP IMAG, P65, DOI 10.1109/SSIAI.2016.7459176
   Chen X, 2009, IEEE DATA MINING, P746, DOI 10.1109/ICDM.2009.128
   Dantone M, 2012, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2012.6247976
   Eleftheriadis S, 2014, LECT NOTES COMPUT SC, V8888, P292, DOI 10.1007/978-3-319-14364-4_28
   Fanelli G, 2011, PROC CVPR IEEE, P617, DOI 10.1109/CVPR.2011.5995458
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Fu Y, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P3
   Geng X, 2016, IEEE T KNOWL DATA EN, V28, P1734, DOI 10.1109/TKDE.2016.2545658
   Geng X, 2014, PROC CVPR IEEE, P1837, DOI 10.1109/CVPR.2014.237
   Gourier N., 2004, Proceedings of the Pointing 2004 Workshop: Visual Observation of Deictic Gestures, P17
   Guo XN, 2017, IEEE INFOCOM SER
   Hara K, 2017, INT J COMPUT VISION, V122, P292, DOI 10.1007/s11263-016-0942-1
   Hara K, 2014, LECT NOTES COMPUT SC, V8690, P552, DOI 10.1007/978-3-319-10605-2_36
   Hu CL, 2014, MULTIMED TOOLS APPL, V73, P1863, DOI 10.1007/s11042-013-1676-5
   Huang G. B., 2007, Technical Report, DOI 10.1.1. 122.8268
   Huttunen Heikki, 2015, Image Analysis. 19th Scandinavian Conference, SCIA 2015. Proceedings: LNCS 9127, P65, DOI 10.1007/978-3-319-19665-7_6
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee D, 2015, IEEE I CONF COMP VIS, P1958, DOI 10.1109/ICCV.2015.227
   Ma BP, 2015, NEUROCOMPUTING, V148, P455, DOI 10.1016/j.neucom.2014.07.019
   Murphy-Chutorian E, 2007, 2007 IEEE INTELLIGENT TRANSPORTATION SYSTEMS CONFERENCE, VOLS 1 AND 2, P1049
   Patacchiola M, 2017, PATTERN RECOGN, V71, P132, DOI 10.1016/j.patcog.2017.06.009
   Rajamanoharan G, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P971, DOI 10.1109/ICCVW.2015.128
   Ranjan R., 2016, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Sang GL, 2016, FRONT INFORM TECH EL, V17, P516, DOI 10.1631/FITEE.1500235
   Sundararajan Kalaivani, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P50, DOI 10.1109/CVPRW.2015.7301354
   Vieriu Radu-Laurentiu, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163098
   Woo-Han Yun, 2015, International Journal of Machine Learning and Computing, V5, P148, DOI 10.7763/IJMLC.2015.V5.499
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhao KL, 2015, PROC CVPR IEEE, P2207, DOI 10.1109/CVPR.2015.7298833
   Zheng WM, 2014, IEEE T AFFECT COMPUT, V5, P71, DOI 10.1109/TAFFC.2014.2304712
   Zhong L, 2012, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR.2012.6247974
NR 34
TC 8
Z9 9
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19141
EP 19162
DI 10.1007/s11042-019-7284-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800010
DA 2024-07-18
ER

PT J
AU Ge, M
   Zhuang, CY
   Ma, Q
AF Ge, Min
   Zhuang, Chenyi
   Ma, Qiang
TI Robust visual object clustering and its application to sightseeing spot
   assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object discovery; Clustering; Sightseeing spot assessment
AB In this paper, we propose a robust visual object clustering approach based on bounding box ranking to discover the characteristics of objects from real-world datasets containing a large number of noisy images, and apply it to sightseeing spot assessment. The purpose is to develop a diversity of resources for sightseeing from images available on social network services (SNS). Objects appearing frequently in images captured in a certain city may represent a certain characteristic of it (local culture, architecture, and so on). Such knowledge can be used to discover various sightseeing resources from the perspective of the user rather than that of the provider (e.g., a travel agency). However, owing to the variable quality of images on SNS, it is challenging to identify objects common to several images by using conventional object discovery methods, and this is where the proposed approach is useful. Extensive experiments on standard and extended benchmarks verified its effectiveness. We also tested the proposed method on an application where the characteristics of a city (i.e., cultural elements) were discovered from a set of images of it. Moreover, by utilizing the objects discovered from images on SNS, we propose an object-level assessment framework to rank sightseeing spots by assigning scores and verify its performance.
C1 [Ge, Min; Ma, Qiang] Kyoto Univ, Kyoto, Japan.
   [Zhuang, Chenyi] Natl Inst Adv Ind Sci & Technol, Tokyo, Japan.
C3 Kyoto University; National Institute of Advanced Industrial Science &
   Technology (AIST)
RP Ma, Q (corresponding author), Kyoto Univ, Kyoto, Japan.
EM gemin@db.soc.i.kyoto-u.ac.jp
RI Zhuang, Chenyi/L-6992-2018
OI Ma, Qiang/0000-0003-3430-9244
FU JSPS KAKENHI [16K12532]; MIC SCOPE [172307001]; Grants-in-Aid for
   Scientific Research [16K12532] Funding Source: KAKEN
FX This work was partly supported by JSPS KAKENHI (16K12532) and MIC SCOPE
   (172307001).
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Chen MF, 2018, PROCEEDINGS OF INTERNATIONAL SYMPOSIUM - EDUCATIONAL RESEARCH AND EDUCATIONAL TECHNOLOGY, P66
   CHO M, 2015, PROC CVPR IEEE, P1201, DOI DOI 10.1109/CVPR.2015.7298724
   Cho MS, 2015, INT CONF UBIQ ROBOT, P292, DOI 10.1109/URAI.2015.7358956
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dhillon IS, 2001, P 7 ACM SIGKDD INT C, P269, DOI DOI 10.1145/502512.502550
   Doersch C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185597
   Everingham M., 2007, The PASCAL Visual Object Classes Chal- lenge (VOC) Results, DOI 10.1007/s11263-009-0275-4
   Felzenszwalb P. F., 2009, PAMI, V32, P1627, DOI [DOI 10.1109/TPAMI.2009.167, 10.1109/TPAMI.2009.167]
   Girshick R., 2015, IEEE I CONF COMP VIS, DOI [DOI 10.1109/ICCV.2015.169, 10.1109/ICCV.2015.169]
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hochman N., 2012, Proceedings of the Association for the Advancement of Artificial Intelligence, P6
   Jin-Woo Jeong, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P538, DOI 10.1109/ICME.2012.196
   Kwak S, 2015, IEEE I CONF COMP VIS, P3173, DOI 10.1109/ICCV.2015.363
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Manen S, 2013, IEEE I CONF COMP VIS, P2536, DOI 10.1109/ICCV.2013.315
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rosenberg A., 2007, EMNLP CONLL, P410, DOI DOI 10.7916/D80V8N84
   Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253
   San Pedro Jose., 2009, WWW, P771, DOI DOI 10.1145/1526709.1526813
   Shen YZ, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P117, DOI 10.1109/BigMM.2016.34
   Shen Yizhu, 2018, INT J BIG DATA INTEL, V5, P31
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S, 2012, LECT NOTES COMPUT SC, V7573, P73, DOI 10.1007/978-3-642-33709-3_6
   Sivic J, 2008, PROC CVPR IEEE, P2182
   Tang K, 2014, PROC CVPR IEEE, P1464, DOI 10.1109/CVPR.2014.190
   Zhuang CY, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P590, DOI 10.1145/2808797.2809386
   Zhuang J, 2014, INT CONF COMPUT INFO, P3, DOI 10.1109/CIT.2014.124
NR 30
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 17135
EP 17164
DI 10.1007/s11042-018-7066-2
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500063
DA 2024-07-18
ER

PT J
AU Kishi, RM
   Trojahn, TH
   Goularte, R
AF Kishi, Rodrigo Mitsuo
   Trojahn, Tiago Henrique
   Goularte, Rudinei
TI Correlation based feature fusion for the temporal video scene
   segmentation task
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Video; Temporal scene segmentation; Early fusion
ID MOVIE; RECOGNITION
AB The available automatic temporal video scene segmentation methods still lack efficacy to be employed in most practical multimedia systems. The ones showing better results are multimodal and based on late fusion. On the other hand, early fusion has not been sufficiently investigated in this task because of the well known barriers of this approach: correlation identification, temporal synchronization and unique representation. This work presents a feature fusion method which deals with the mentioned difficulties and produces features which can enhance the efficacy of existing temporal video scene segmentation methods. This feature fusion process is performed on singlemodal Bag of Features feature vectors and is intended to enrich previously captured latent semantics by performing temporal clustering of features, providing an unified representation of multiple temporal related features. This feature fusion process have been coupled with two of-the-shelf scene segmentation algorithms, presenting competitive results when compared with two other state-of-the-art multimodal temporal scene segmentation methods. The results indicate that the proposed early fusion feature representation method is a promising alternative in helping to boost video retrieval related tasks.
C1 [Kishi, Rodrigo Mitsuo; Trojahn, Tiago Henrique; Goularte, Rudinei] Univ Sao Paulo, 400 Trabalhador Sao Carlense Ave, BR-13560970 Sao Carlos, SP, Brazil.
   [Kishi, Rodrigo Mitsuo] Univ Fed Mato Grosso do Sul, 3484 Ranulpho Marques Leal Ave, BR-79613000 Tres Lagoas, MS, Brazil.
   [Trojahn, Tiago Henrique] Fed Inst Sao Paulo, 235 Washington Luis Hwy, BR-13565905 Sao Carlos, SP, Brazil.
C3 Universidade de Sao Paulo; Universidade Federal de Mato Grosso do Sul;
   Instituto Federal de Sao Paulo (IFSP)
RP Kishi, RM (corresponding author), Univ Sao Paulo, 400 Trabalhador Sao Carlense Ave, BR-13560970 Sao Carlos, SP, Brazil.; Kishi, RM (corresponding author), Univ Fed Mato Grosso do Sul, 3484 Ranulpho Marques Leal Ave, BR-79613000 Tres Lagoas, MS, Brazil.
EM rodrigokishi@usp.br; ttrojahn@icmc.usp.br; rudinei@icmc.usp.br
RI Goularte, Rudinei/E-2441-2011
OI Goularte, Rudinei/0000-0003-1531-1576
FU Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPq);
   Fundacao de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP);
   Universidade Federal de Mato Grosso do Sul (UFMS); Universidade de Sao
   Paulo (USP); Instituto Federal de Sao Paulo (IFSP); Coordenacao de
   Aperfeicoamento de Pessoal de Nivel Superior - Brasil (CAPES) [001];
   FAPESP
FX Authors of this work would like to thank Conselho Nacional de
   Desenvolvimento Cientifico e Tecnologico (CNPq), Fundacao de Amparo a
   Pesquisa do Estado de Sao Paulo (FAPESP), Universidade Federal de Mato
   Grosso do Sul (UFMS), Universidade de Sao Paulo (USP) and Instituto
   Federal de Sao Paulo (IFSP) for financial support. This study was
   financed in part by the Coordenacao de Aperfeicoamento de Pessoal de
   Nivel Superior - Brasil (CAPES) - Finance Code 001. The authors also
   like to thank Dr Lorenzo Baraldi for providing evaluation scripts. This
   research have been developed using computational resources from Centro
   de Ciencias Matematicas Aplicadas a Industria (CeMEAI) financed by
   FAPESP.
CR [Anonymous], 1998, HDB BRAIN THEORY NEU
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Baraldi L, 2015, MEASURING SCENE DETE, P395
   Baraldi L, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1199, DOI 10.1145/2733373.2806316
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chasanis V., 2009, Proceedings of the ACM International Conference on Image and Video Retrieval, p35:1, DOI DOI 10.1145/1646396.1646439
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Del Fabro M, 2013, MULTIMEDIA SYST, V19, P427, DOI 10.1007/s00530-013-0306-4
   Ellouze M, 2010, MULTIMED TOOLS APPL, V47, P325, DOI 10.1007/s11042-009-0325-5
   Gao GY, 2012, INT C PATT RECOG, P3074
   Gauch JM, 1999, INFORM PROCESS MANAG, V35, P381, DOI 10.1016/S0306-4573(98)00067-3
   Haghighat M, 2016, IEEE T INF FOREN SEC, V11, P1984, DOI 10.1109/TIFS.2016.2569061
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hare J.S., 2011, Proceedings of the 19th ACM International Conference on Multimedia, P691, DOI 10.1145/2072298.2072421
   Jhuo IH, 2014, MACH VISION APPL, V25, P33, DOI 10.1007/s00138-013-0567-0
   Kender JR, 1998, PROC CVPR IEEE, P367, DOI 10.1109/CVPR.1998.698632
   Koprinska I, 2001, SIGNAL PROCESS-IMAGE, V16, P477, DOI 10.1016/S0923-5965(00)00011-4
   Kurcius JJ, 2014, 2014 INT WORKSH COMP, P1, DOI [10.1109/IWCIM.2014.7008808, DOI 10.1109/IWCIM.2014.7008808]
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lopes BL., 2014, J INFORM DATA MANAGE, V5, P194
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Rao K.S., 2012, Emotion recognition using speech features
   Rasheed Z, 2003, PROC CVPR IEEE, P343
   Rasiwasia N, 2014, JMLR WORKSH CONF PRO, V33, P823
   Saraceno C, 1997, INT CONF ACOUST SPEE, P2597, DOI 10.1109/ICASSP.1997.595320
   Sidiropoulos P, 2011, IEEE T CIRC SYST VID, V21, P1163, DOI 10.1109/TCSVT.2011.2138830
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Snoek CGM, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA21
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Vendrig J, 2002, IEEE T MULTIMEDIA, V4, P492, DOI 10.1109/TMM.2002.802021
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Wang XH, 2018, NEUROCOMPUTING, V275, P438, DOI 10.1016/j.neucom.2017.08.063
   Wu S, 2015, INT J APPL MATH INF, V9, P361, DOI [10.12785/amis/090142, DOI 10.12785/AMIS/090142]
   Xi W., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P130, DOI 10.1145/1076034.1076059
   Xie F, 2016, 2016 INTERNATIONAL CONFERENCE ON MECHANICAL ENGINEERING AND CONTROL AUTOMATION (ICMECA 2016), P294
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Xie RF, 2011, IEEE INT C BIO BIO W, P165, DOI 10.1109/BIBMW.2011.6112370
   Xu S, 2012, INT CONF ACOUST SPEE, P1413, DOI 10.1109/ICASSP.2012.6288155
   Xu Z, 2013, 2013 8TH INTERNATIONAL ICST CONFERENCE ON COMMUNICATIONS AND NETWORKING IN CHINA (CHINACOM), P374, DOI 10.1109/ChinaCom.2013.6694624
   Xuanhan Wang, 2017, IEEE Signal Processing Letters, V24, P510, DOI 10.1109/LSP.2016.2611485
   Yeung M, 1998, COMPUT VIS IMAGE UND, V71, P94, DOI 10.1006/cviu.1997.0628
   Yu Stella X., 2001, ADV NEURAL INFORM PR, V14, P1327
   Zhu L, 2017, IEEE T CYBERNETICS, V47, P3941, DOI 10.1109/TCYB.2016.2591068
NR 46
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15623
EP 15646
DI 10.1007/s11042-018-6959-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700065
OA Bronze
DA 2024-07-18
ER

PT J
AU Rashid, M
   Khan, MA
   Sharif, M
   Raza, M
   Sarfraz, MM
   Afza, F
AF Rashid, Muhammad
   Khan, Muhammad Attique
   Sharif, Muhammad
   Raza, Mudassar
   Sarfraz, Muhammad Masood
   Afza, Farhat
TI Object detection and classification: a joint selection and fusion
   strategy of deep convolutional neural network and SIFT point features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Hand crafted features; Deep CNN; Features fusion;
   Features reduction; Classification
ID IMAGE RETRIEVAL; RECOGNITION; SEGMENTATION; EXTRACTION; DISEASES; SYSTEM
AB In the area of machine learning and pattern recognition, object classification is getting an attraction due to its range of applications such as visual surveillance. In recent times, numerous deep learning-based methods are presented for object classification but still, set of problems/concerns exists which reduce the overall classification accuracy. Complex background, congest situtaions, and similarity among different objects are few challenging issues. To tackle such problems, we propose a technique by using deep convolutional neural network (DCNN) and scale invariant features transform (SIFT). First, an improved saliency method is implemented, and the point features are extracted. Then, DCNN features are extracted from two deep CNN models like VGG and AlexNet. Thereafter, Reyni entropy-controlled method is implemented on DCNN pooling and the SIFT point matrix to select the robust features. Finally, the selected robust features are fused in a matrix by a serial approach, which is later fed to ensemble classifier for recognition. The proposed method is evaluated on three publically available datasets including Caltech101, Barkley 3D, and Pascal 3D and obtained classification accuracy of 93.8%, 99%, and 88.6% - clearly showing the exceptional performance compared to existing methods.
C1 [Rashid, Muhammad; Sharif, Muhammad; Raza, Mudassar; Afza, Farhat] COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Islamabad, Pakistan.
   [Khan, Muhammad Attique] HITEC Univ, Dept Comp Sci & Engn, Museum Rd, Taxila, Pakistan.
   [Sarfraz, Muhammad Masood] COMSATS Univ Islamabad, Dept Elect Engn, Wah Campus, Islamabad, Pakistan.
C3 COMSATS University Islamabad (CUI); NITEC University; COMSATS University
   Islamabad (CUI)
RP Khan, MA (corresponding author), HITEC Univ, Dept Comp Sci & Engn, Museum Rd, Taxila, Pakistan.
EM attique.khan440@gmail.com
RI Rashid, Muhammad/KSM-3480-2024; Raza, Mudassar/I-4000-2015; Afza,
   Farhat/ABG-6364-2021; khan, sajid/HGE-2406-2022; Sharif,
   Muhammad/ACD-2598-2022; Sharif, Muhammad/AAB-8376-2022; Khan, Dr.
   Muhammad Attique/AAX-2644-2021
OI Rashid, Muhammad/0000-0002-2557-6845; Raza,
   Mudassar/0000-0001-9124-9298; Sharif, Muhammad/0000-0002-7258-8400;
   Khan, Dr. Muhammad Attique/0000-0002-6347-4890
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Agrawal S, 2018, NEURAL COMPUT APPL, V29, P245, DOI 10.1007/s00521-016-2446-x
   Akcay S, 2018, IEEE T INF FOREN SEC, V13, P2203, DOI 10.1109/TIFS.2018.2812196
   Akram T., 2018, J AMB INTEL HUM COMP, P1, DOI DOI 10.1007/S12652-018-1051-5
   [Anonymous], COMP VIS ICCV 2011 I
   [Anonymous], OBJECT CLASSIFICATIO
   [Anonymous], INFORMATION
   [Anonymous], COMPUT SCI ENG
   [Anonymous], 2018, PATTERN RECOGN LETT
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], FTRA INT C SEC TRUST
   [Anonymous], APPL SOFT COMPUT
   [Anonymous], 2018, IEEE T NEUR NET LEAR
   [Anonymous], MULT EXP WORKSH ICME
   [Anonymous], 2006, COMP VIS PATT REC 20
   [Anonymous], 2016, EUR C COMP VIS
   [Anonymous], IM SIGN PROC CISP 20
   [Anonymous], 2018, COMPUT VIS IMAGE UND
   [Anonymous], 2011, 2011 INT C COMP SCI
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2012, NIPS 1106 1114
   [Anonymous], NEUROCOMPUTING
   Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364
   Cheng G, 2016, MEASUREMENT, V91, P140, DOI 10.1016/j.measurement.2016.05.059
   Ejbali R, 2018, MULTIMED TOOLS APPL, V77, P6149, DOI 10.1007/s11042-017-4523-2
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fondón I, 2018, COMPUT BIOL MED, V96, P41, DOI 10.1016/j.compbiomed.2018.03.003
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Janoch A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Khan MA, 2018, BMC CANCER, V18, DOI 10.1186/s12885-018-4465-8
   Khan MA, 2019, PATTERN ANAL APPL, V22, P1377, DOI 10.1007/s10044-018-0688-1
   Khan MA, 2018, COMPUT ELECTRON AGR, V155, P220, DOI 10.1016/j.compag.2018.10.013
   Khan MA, 2018, IET IMAGE PROCESS, V12, P200, DOI 10.1049/iet-ipr.2017.0368
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Leng L., 2012, P INT C WAV AN PATT, P164, DOI DOI 10.1109/ICWAPR.2012.6294772
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li K, 2018, PATTERN RECOGN, V73, P1, DOI 10.1016/j.patcog.2017.06.036
   Liaqat A, 2018, J MECH MED BIOL, V18, DOI 10.1142/S0219519418500380
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Liu WF, 2018, INFORM FUSION, V41, P119, DOI 10.1016/j.inffus.2017.09.001
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Naeini AA, 2018, IEEE GEOSCI REMOTE S, V15, P379, DOI 10.1109/LGRS.2017.2789194
   Qin C, 2018, SIGNAL PROCESS, V142, P194, DOI 10.1016/j.sigpro.2017.07.019
   Raza M, 2018, FUTURE GENER COMP SY, V88, P28, DOI 10.1016/j.future.2018.05.002
   Roy PK, 2018, STUD COMPUT INTELL, V730, P277, DOI 10.1007/978-3-319-63754-9_13
   Sankar AS, 2015, PROCEDIA COMPUT SCI, V46, P1476, DOI 10.1016/j.procs.2015.02.067
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Sharif M, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0236-8
   Siddiqui S, 2018, INT J APPL PATTERN R, V5, P206, DOI 10.1504/IJAPR.2018.094815
   Simonyan K., 2014, 14091556 ARXIV
   Singh C, 2018, OPTIK, V158, P127, DOI 10.1016/j.ijleo.2017.11.202
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wei GH, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0874-5
NR 58
TC 64
Z9 67
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 15751
EP 15777
DI 10.1007/s11042-018-7031-0
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500002
DA 2024-07-18
ER

PT J
AU Damiano, R
   Gena, C
   Venturini, G
AF Damiano, Rossana
   Gena, Cristina
   Venturini, Giulia
TI Testing web-based solutions for improving reading tasks in dyslexic and
   neuro-typical users
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Accessibility; Dyslexia; Learning disorders; Reading
ID EXECUTIVE FUNCTIONS; CHILDREN
AB This study investigates the readability of web sites for users with dyslexia as well as neuro-typical readers. The aim of the paper is twofold: on the one hand, it is aimed at assessing whether and how we can improve the level of web pages accessibility for users with dyslexia, and to determine which new requisites could be added to the current ones proposed from the WCAG guidelines for web accessibility. In order to achieve this goal, we designed a test targeted to students diagnosed with dyslexia (N=26). Results showed that further modifications to the page style beyond those considered by WCAG (e.g., font type, size and column width) were appreciated by users with dyslexia and may be considered as additional personalization options for this kind of users. On the other hand, we would like to discover if the exploitation of a specific font designed for users with dyslexia would be also welcomed by neuro-typical users in reading tasks. The results of a second on line experiment highlight that neuro-typical users (N=199) and users with dyslexia (N=30) prefer this font for reading tasks, compared to a regular sans-serif font.
C1 [Damiano, Rossana; Gena, Cristina; Venturini, Giulia] Univ Torino, Dipartimento Informat, Via Pessinetto 12, I-10134 Turin, Italy.
C3 University of Turin
RP Gena, C (corresponding author), Univ Torino, Dipartimento Informat, Via Pessinetto 12, I-10134 Turin, Italy.
EM rossana.damiano@unito.it; cristina.gena@unito.it;
   giulia.venturini@unito.it
RI Damiano, Rossana/C-6288-2011
OI GENA, Cristina/0000-0003-0049-6213
CR Altemeier LE, 2008, J CLIN EXP NEUROPSYC, V30, P588, DOI 10.1080/13803390701562818
   Anmarkrud O, 2018, HDB MULTIPLE SOURCE
   [Anonymous], 1991, Design and Analysis: A Researchers Handbook
   [Anonymous], THESIS
   Bachmann C, 2013, GIORNALE ITALIANO RI, V10
   Barbiero Barbiero C, PLOS ONE, V7
   Beattie RL, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027893
   Berenson MarkL., 2014, Basic business statistics : concepts and applications, VThirteenth
   CASTIELLO U, 1990, ACTA PSYCHOL, V73, P195, DOI 10.1016/0001-6918(90)90022-8
   De Beni R., 2003, Nuova guida alla comprensione del testo, Vol. 1: Introduzione teorica generale al programma: le prove criteriali livello A e B, V1
   De Lima RSalgadoC, 2010, RIV NEUROSCIENZE
   de Santana Vagner Figueredo, 2012, P INT CROSS DISC C W, P35
   Evett L, 2005, INTERACT COMPUT, V17, P453, DOI 10.1016/j.intcom.2005.04.001
   Facoetti A, 2000, CORTEX, V36, P109, DOI 10.1016/S0010-9452(08)70840-2
   Freire A. P., 2011, P WORKSH ACC DES DIG, P41
   Hardy S, 2010, ADV MENT HEALTH INTE, V4, P2, DOI 10.5042/amhld.2010.0051
   Harrison C, 2011, MULTIPLE PERSPECTIVES ON DIFFICULTIES IN LEARNING LITERACY AND NUMERACY, P111, DOI 10.1007/978-1-4020-8864-3_5
   Kurniawan Sri., 2007, ADV UNIVERSAL WEB DE
   Kuster SM, 2017, ANN DYSLEXIA, P1
   Lyon GR, 2003, ANN DYSLEXIA, V53, P1, DOI 10.1007/s11881-003-0001-9
   Marinus E, 2016, DYSLEXIA, V22, P233, DOI 10.1002/dys.1527
   McCardle P., 2005, Learning Disabilities Research Practice, V20, P68, DOI DOI 10.1111/J.1540-5826.2005.00122.X
   Miniukovich A., 2018, P 2018 INT C ADV VIS
   Moura O, 2015, CLIN NEUROPSYCHOL, V28, P20, DOI 10.1080/13854046.2014.964326
   Pennington B.F., 2008, DIAGNOSING LEARNING, V2nd
   Radovan M, 2016, INT REV RES OPEN DIS, V17, P166
   Reiter A, 2005, DYSLEXIA, V11, P116, DOI 10.1002/dys.289
   Rello L., 2013, P 15 INT ACM SIGACCE, V15, P14
   Rello Luz, 2012, P INT CROSS DISC C W, P36
   Royce A, 1999, APPROACHES SOCIAL RE
   Siegel Linda S, 2006, Paediatr Child Health, V11, P581
   Venturini D, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0178597
   Wehmeyer M. L., 2017, The Praeger international handbook of special education: Volume 3- Asia and Oceania
NR 33
TC 2
Z9 2
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13489
EP 13515
DI 10.1007/s11042-019-7273-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900040
DA 2024-07-18
ER

PT J
AU Mehmood, I
   Sajjad, M
   Muhammad, K
   Shah, SIA
   Sangaiah, AK
   Shoaib, M
   Baik, SW
AF Mehmood, Irfan
   Sajjad, Muhammad
   Muhammad, Khan
   Shah, Syed Inayat Ali
   Sangaiah, Arun Kumar
   Shoaib, Muhammad
   Baik, Sung Wook
TI An efficient computerized decision support system for the analysis and
   3D visualization of brain tumor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image processing; Tumor segmentation and classification; MRI
   images; Medical imaging; MRI 3D visualization
ID CLASSIFICATION
AB The quality of health services provided by medical centers varies widely, and there is often a large gap between the optimal standard of services when judged based on the locality of patients (rural or urban environments). This quality gap can have serious health consequences and major implications for patient's timely and correct treatment. These deficiencies can manifest, for example, as a lack of quality services, misdiagnosis, medication errors, and unavailability of trained professionals. In medical imaging, MRI analysis assists radiologists and surgeons in developing patient treatment plans. Accurate segmentation of anomalous tissues and its correct 3D visualization plays an important role inappropriate treatment. In this context, we aim to develop an intelligent computer-aided diagnostic system focusing on human brain MRI analysis. We present brain tumor detection, segmentation, and its 3D visualization system, providing quality clinical services, regardless of geographical location, and level of expertise of medical specialists. In this research, brain magnetic resonance (MR) images are segmented using a semi-automatic and adaptive threshold selection method. After segmentation, the tumor is classified into malignant and benign based on a bag of words (BoW) driven robust support vector machine (SVM) classification model. The BoW feature extraction method is further amplified via speeded up robust features (SURF) incorporating its procedure of interest point selection. Finally, 3D visualization of the brain and tumor is achieved using volume marching cube algorithm which is used for rendering medical data. The effectiveness of the proposed system is verified over a dataset collected from 30 patients and achieved 99% accuracy. A subjective comparative analysis is also carried out between the proposed method and two state-of-the-art tools ITK-SNAP and 3D-Doctor. Experimental results indicate that the proposed system performed better than existing systems and assists radiologist determining the size, shape, and location of the tumor in the human brain.
C1 [Mehmood, Irfan; Baik, Sung Wook] Sejong Univ, Dept Software, Seoul, South Korea.
   [Sajjad, Muhammad; Shoaib, Muhammad] Islamia Coll Peshawar, Dept Comp Sci, Digital Image Proc Lab, Peshawar, Pakistan.
   [Muhammad, Khan] Sejong Univ, Digital Contents Res Inst, Intelligent Media Lab, Seoul, South Korea.
   [Shah, Syed Inayat Ali] Islamia Coll Peshawar, Dept Math, Peshawar, Pakistan.
   [Sangaiah, Arun Kumar] VIT Univ, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
C3 Sejong University; University of Peshawar; Sejong University; University
   of Peshawar; Vellore Institute of Technology (VIT); VIT Vellore
RP Sajjad, M (corresponding author), Islamia Coll Peshawar, Dept Comp Sci, Digital Image Proc Lab, Peshawar, Pakistan.
EM muhammad.sajjad@icp.edu.pk; khan.muhammad.icp@gmail.com
RI Sajjad, Muhammad/L-5269-2016; Muhammad, Khan/L-9059-2016; Sajjad,
   Muhammad/GZL-4962-2022; Baik, Sung Wook/AAR-8236-2020; Khan,
   Muhammad/IXN-8470-2023; Sangaiah, Arun Kumar/U-6785-2019; Shah, Syed
   Imran Abbas/HSA-9971-2023
OI Sajjad, Muhammad/0000-0001-5646-0338; Muhammad,
   Khan/0000-0003-4055-7412; Sajjad, Muhammad/0000-0003-0006-1156;
   Sangaiah, Arun Kumar/0000-0002-0229-2460; Shah, Syed Imran
   Abbas/0000-0001-9934-3633; Muhammad, Khan/0000-0002-5302-1150
FU Korean MSIT (Ministry of Science and ICT) under the National Program for
   Excellence in SW [2015-0-00938]
FX This research was supported by the Korean MSIT (Ministry of Science and
   ICT), under the National Program for Excellence in SW (2015-0-00938),
   supervised by the IITP (Institute for Information & communications
   Technology Promotion).
CR Abdellah M., 2015, INT J BIOMEDICAL IMA, V2015, P2
   Aggarwal AK, 2014, SCI WORLD J, DOI 10.1155/2014/240954
   Ahmad A, 2007, DATA KNOWL ENG, V63, P503, DOI 10.1016/j.datak.2007.03.016
   AJ Das, 2014, AUTOMATIC DETECTION
   Algohary AO, 2010, BIOM ENG C CIBEC 201
   [Anonymous], COMPUT ELECT ENG
   [Anonymous], 1987, ACM SIGGRAPH 87
   Bagheri MA, 2012, ART INT SIGN PROC AI
   Bozorgi M, 2015, INT J COMPUT ASS RAD, V10, P293, DOI 10.1007/s11548-014-1069-x
   Chen Y-T, 2012, WAV AN PATT REC ICWA
   Dai Y, 2013, COMPUT MATH METHODS
   Deng W, 2010, BIOM ENG INF BMEI 20
   Despotovic I, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/450341
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   Ghosh S, 2013, INT J ADV COMPUT SC, V4, P35
   Gong F, 2010, MACH VIS HUM MACH IN
   Har-Peled S., 2003, ADV NEURAL INFORM PR
   Höhne KH, 2002, IEEE T MED IMAGING, V21, P713, DOI 10.1109/TMI.2002.801364
   Jaffar MA, 2012, INT J COMPUT INT SYS, V5, P494, DOI 10.1080/18756891.2012.696913
   Juan-Albarracín J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0125143
   Khotanlou H, 2009, FUZZY SET SYST, V160, P1457, DOI 10.1016/j.fss.2008.11.016
   Louis DN, 2016, ACTA NEUROPATHOL, V131, P803, DOI 10.1007/s00401-016-1545-1
   Mehmood I, 2014, SENSORS-BASEL, V14, P17112, DOI 10.3390/s140917112
   Mehmood I, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0109-y
   Mehmood I, 2013, COMPUT BIOL MED, V43, P1471, DOI 10.1016/j.compbiomed.2013.07.001
   Natarajan P, 2012, COMP INT COMP RES IC
   Ray D, 2012, REC ADV INF TECHN RA
   Vrji KA, 2011, SIGN PROC COMM COMP
   Wang T, 2010, PROTEIN PEPTIDE LETT, V17, P32, DOI 10.2174/092986610789909494
   Yang GL, 2016, MULTIMED TOOLS APPL, V75, P15601, DOI [10.1007/s11042-015-2649-7, 10.1155/2015/932029]
   Yazdani S, 2014, DIAGN PATHOL, V9, DOI 10.1186/s13000-014-0207-7
   Zakeri FS, 2012, J MED SYST, V36, P1621, DOI 10.1007/s10916-010-9624-7
   Zhang HY, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-81
   Zhang YD, 2017, CNS NEUROL DISORD-DR, V16, P3, DOI 10.2174/187152731601170111214648
NR 34
TC 18
Z9 18
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 12723
EP 12748
DI 10.1007/s11042-018-6027-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900005
DA 2024-07-18
ER

PT J
AU Jindal, N
   Singh, K
AF Jindal, Neeru
   Singh, Kulbir
TI Applicability of fractional transforms in image processing - review,
   technical challenges and future trends
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Fractional transforms; Image; Compression; Encryption; Other
   applications
ID FOURIER-TRANSFORM; ENCRYPTION; COMPRESSION; RESTORATION; ALGORITHM
AB Fractional transforms not only enhance the overall signal processing applications but also improved the efficacy of systems. In this paper, we focus to present several image processing techniques using fractional transforms under one umbrella. The primary motive of this paper is to study the image related literature survey, formats, noises, performance parameters, websites and open issues to encourage further research in this area. The paper first describes fractional transforms and in the second part, we provide comprehensive and exhaustive details on the use of these transforms in image processing. Specific topics include image compression, encryption, enhancement, rotation, watermarking etc. Some technical image processing challenges like thresholding, CPU time etc., are also discussed with a future scope.
C1 [Jindal, Neeru; Singh, Kulbir] Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Jindal, N (corresponding author), Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
EM neeru.jindal@thapar.edu; ksingh@thapar.edu
RI Singh, Kulbir/T-7453-2019
OI Singh, Kulbir/0000-0001-8070-3395
CR Abbasi A, 2016, INT J ADV COMPUT SC, V7, P184
   Ahuja B, 2013, INT J COMPUT SCI ENG, V4, P861
   Anaz AS, 2015, AL RAFIDAIN ENG, V23, P183, DOI DOI 10.33899/RENGJ.2015.105955
   [Anonymous], IEEE 11 INT C ASIC
   [Anonymous], 1994, Mathematica Journal, DOI DOI 10.1016/0165-1684(90
   [Anonymous], 2011, 2011 7 INT C EL EL E
   Arivazhagan S, 2015, INT J APPL INFORM SY, V8, P25
   Aryal V, 2016, IMPERIAL J INTERDIS, V2, P199
   Bagul SJ, 2014, INT J ENG INNOV TECH, V3, P96
   Balle J, 2017, 5 INT C LEARN REPR I
   Barbu M, 2005, P SOC PHOTO-OPT INS, V5807, P170, DOI 10.1117/12.604625
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Bracewell R.N., 2000, FOURIER TRANSFORM IT
   Candan Ç, 2000, IEEE T SIGNAL PROCES, V48, P1329, DOI 10.1109/78.839980
   Chao-Jun Li B.M.T., 2014, Modern Alkyne Chemistry, P1
   Chauhan P, 2014, FRACT FOURIER TRANSF, V5, P45
   Chen CC, 1998, INT C PATT RECOG, P1500, DOI 10.1109/ICPR.1998.711991
   Chen JJ, 2015, IEEE INT CONF COMM, P1, DOI [10.1109/ChinaSIP.2015.7230350, 10.1109/ICCW.2015.7247066]
   Condon EU, 1937, P NATL ACAD SCI USA, V23, P158, DOI 10.1073/pnas.23.3.158
   Cox Ingemar J., 1997, IEEE T IMAGE PROCESS, V6, P1673
   Desai SA, 2013, INT J ADV SCI TECHN, V3, P91
   Djurovic I, 2001, J NETW COMPUT APPL, V24, P167, DOI 10.1006/jnca.2000.0128
   El-Mashed MG, 2012, SENS IMAGING, V13, P37, DOI 10.1007/s11220-011-0069-y
   Elsheh E., 2010, Proceedings 2010 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT 2010), P97, DOI 10.1109/ISSPIT.2010.5711735
   Gewei T., 2014, OPEN AUTOM CONTROL S, V6, P503, DOI DOI 10.2174/1874444301406010503
   Ghatwary N, 2016, P WORLD C ENG WCE 20, V1, P1
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Goswami GH, 2015, INT J ADV ENG RES DE, V2, P860
   Grgic S, 2001, IEEE T IND ELECTRON, V48, P682, DOI 10.1109/41.925596
   Guven HE, 2008, IET SIGNAL PROCESS, V2, P15, DOI 10.1049/iet-spr:20070017
   Hangun B., 2017, INT J ENG SCI APPL, V1, P34
   Hennelly B, 2003, OPT COMMUN, V226, P61, DOI 10.1016/j.optcom.2003.08.030
   Hennelly B, 2003, OPT LETT, V28, P269, DOI 10.1364/OL.28.000269
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Jain Reema, 2015, INT J COMPUTER APPL, V124, P35, DOI [10.5120/ijca2015905808, DOI 10.5120/IJCA2015905808]
   Jayaraman S, 2011, DIGITAL IMAGE PROCES
   Jindal N, 2014, IMAGING SCI J, V62, P265, DOI 10.1179/1743131X13Y.0000000062
   Jindal N, 2014, SIGNAL IMAGE VIDEO P, V8, P1543, DOI 10.1007/s11760-012-0391-4
   Jindal N, 2013, J ELECTR ENG-SLOVAK, V64, P250, DOI 10.2478/jee-2013-0036
   Joshi M, 2007, OPT COMMUN, V279, P35, DOI 10.1016/j.optcom.2007.07.012
   Kalotra R., 2014, INT J ADV RES COMPUT, V3, P7116
   Killian CJ, 1990, INT C IM PROC, P243
   Kim S, 2010, IEEE T CONSUM ELECTR, V56, P1063, DOI 10.1109/TCE.2010.5506040
   Kober H., 1939, Q J MATH OXF SER, V10, P45
   Kotkar SR, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING (ICIP), P664, DOI 10.1109/INFOP.2015.7489466
   Kumar CNV, 2017, INT J ADV RES COMPUT, V7, P213, DOI [10.23956/ijarcsse/V7I3/0128, DOI 10.23956/IJARCSSE/V7I3/0128]
   Kumar MS, 2013, IEEE WORKSHOP COMPU, P1, DOI 10.1109/CIBIM.2013.6607906
   Kumar R, 2015, INT J EMERG RES MANA, V4, P223
   Kumar R, 2012, INT J COMPUT APPL, V50, P20
   Kumar S, 2017, CIRC SYST SIGNAL PR, V36, P1493, DOI 10.1007/s00034-016-0364-x
   Kutay MA, 1998, J OPT SOC AM A, V15, P825, DOI 10.1364/JOSAA.15.000825
   Kutay MA, 1997, IEEE T SIGNAL PROCES, V45, P1129, DOI 10.1109/78.575688
   Larnier S., 2012, Proceedings of the 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2012), P1057, DOI 10.1109/ICASSP.2012.6288068
   LI XM, 2013, CISP, V1, P299
   LI XM, 2014, 7TH INT CONGRESS IMA, P148
   LIU XL, 2008, TSP, V65, P1894, DOI DOI 10.1109/TSP.2017.2652383
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lohmann AW, 1996, OPT COMMUN, V125, P18, DOI 10.1016/0030-4018(95)00748-2
   MAJUMDAR A, 1977, IMAGE, V3, P27, DOI DOI 10.1007/S11760-008-0056-5
   Mala PS, 2016, INT J APPL ENG RES I, V11, P3347
   Matuska S., 2012, 2012 Proceedings of the 9th Conference of ELEKTRO (ELEKTRO 2012), P75, DOI 10.1109/ELEKTRO.2012.6225575
   McIntyre KA, 2006, U. S. Patent, Patent No. [US20030039398, 20030039398]
   Mendlovic D, 1997, APPL OPTICS, V36, P4801, DOI 10.1364/AO.36.004801
   Mittal K, 2015, INT J ENGG SCI ADV R, V1, P19
   Murty S., 2011, The International Journal of Multimedia & Its Applications (IJMA), V3, P61
   NAMIAS V, 1980, J I MATH APPL, V25, P241
   Naveen Kumar Nishchal, 2003, Optical Memory & Neural Networks (Information Optics), V12, P139
   Nishchal NK, 2009, J OPT-INDIA, V38, P22, DOI 10.1007/s12596-009-0003-z
   Nishchal NK, 2009, INTRO SQLITE, P1
   Nishchal NK, 2010, 9 EUR WORKSH INF OPT, P1
   Ozaktas H.M., 2001, FRACTIONAL FOURIER T
   Parenti RR, 1994, LINCOLN LAB J, V8, P29
   Patel MB, 2015, INT J SCI RES DEV, V3, P1060
   Patel PM, 2016, INT J ENG SCI COMPUT, V6, P6664
   Pei SC, 1999, IEEE T SIGNAL PROCES, V47, P1335, DOI 10.1109/78.757221
   Pei SC, 2001, IEEE T SIGNAL PROCES, V49, P1198, DOI 10.1109/78.923302
   Pei SC, 2000, IEEE T SIGNAL PROCES, V48, P1338, DOI 10.1109/78.839981
   PEI SC, 2007, SIG PROCESS, V67, P99
   Prasad A, 2012, OPT COMMUN, V285, P1005, DOI 10.1016/j.optcom.2011.10.019
   Raja SS, 2014, AUST J BASIC APPL SC, V8, P528
   Rajput A, 2013, INT J ENG ADV TECHNO, V2, P886
   Rajput SK, 2012, OPT LASER ENG, V50, P1474, DOI 10.1016/j.optlaseng.2012.03.018
   Reddy VR, 2014, INT J ADV RES COMPUT, V3, P4891
   Rein S, 2011, AD HOC NETW, V9, P482, DOI 10.1016/j.adhoc.2010.08.004
   Sahnoun K., 2014, INT J MULTIMED APPL, V6, P301, DOI [10.5121/ijma.2014.6106, DOI 10.5121/IJMA.2014.6106]
   Santhanam B, 1996, IEEE T SIGNAL PROCES, V44, P994, DOI 10.1109/78.492554
   Shahane PR, 2012, DIGIT IMAGE PROCESS, V4, P1
   Sharma Deepak, 2014, International Journal of Computer Network and Information Security, V6, P1, DOI 10.5815/ijcnis.2014.10.01
   Sharma D, 2014, INT J COMPUT APPL, V93, P975
   Sharma D, 2013, ADVMICROELECTRON ENG, V1, P1
   Sharma D, 2014, INT J SIG PROCESS IM, V7, P453
   Sharma KK, 2013, P INT C COMM EL SYST, V8760
   Sharma M, 2013, INT J ENHANCED RES S, V2, P28
   Sharma M, 2010, INT J COMPUT SCI NET, V10, P133
   Sharma P, 2012, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON SECURITY OF INFORMATION AND NETWORKS, P153, DOI 10.1109/ISPTS.2012.6260906
   Shukla Jaya, 2010, 2010 2nd International Conference on Computer Engineering and Technology (ICCET), P136, DOI 10.1109/ICCET.2010.5486344
   Singh H, 2014, J COMMUN TECHNOL EL+, V59, P1234, DOI 10.1134/S1064226914110199
   SINGH H, 1922, INDIAN ACAD SCI, V39, P345, DOI DOI 10.1007/S12046-013-0217-2
   Singh K, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN RECENT TECHNOLOGIES IN COMMUNICATION AND COMPUTING (ARTCOM 2009), P411, DOI 10.1109/ARTCom.2009.185
   Singh N, 2008, OPT LASER ENG, V46, P117, DOI 10.1016/j.optlaseng.2007.09.001
   Singh P, 2017, AIP CONF PROC, V1802, DOI 10.1063/1.4973267
   Singh S, 2013, INT J COMPUT APPL, V77, P16
   Singh SK, 2010, MAEJO INT J SCI TECH, V4, P235
   Sinha A, 2005, OPT ENG, V44, DOI 10.1117/1.1906240
   Skirnevskiy P, 2016, P INT C INF TECHN BU
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Srivastava R, 2014, 2 INT C EM TRENDS EN, P17
   Tao R, 2006, SCI CHINA SER F, V49, P1, DOI 10.1007/s11432-005-0240-y
   Tiwari N, 2017, INDIAN J SCI TECHNOL, V10, DOI [10.17485/ijst/2017/v10i3/110624, DOI 10.17485/ijst/2017/v10i3/110624]
   Vasant PM, 2013, META-HEURISTICS OPTIMIZATION ALGORITHMS IN ENGINEERING, BUSINESS, ECONOMICS, AND FINANCE, P1, DOI 10.4018/978-1-4666-2086-5
   Vashisth S, 2014, OPTIK, V125, P5309, DOI 10.1016/j.ijleo.2014.06.068
   Vij B, 2015, INT J COMPUT APPL, V113, P41
   Vijaya C, 2006, SIGNAL PROCESS, V86, P1976, DOI 10.1016/j.sigpro.2005.09.025
   Vilardy Juan M., 2011, Journal of Physics: Conference Series, V274, DOI 10.1088/1742-6596/274/1/012047
   Voyatzis G, 1999, IEEE COMPUT GRAPH, V19, P18, DOI 10.1109/38.736465
   Wiener N., 1929, MIT J. Math.Phys., V18, P70
   Yadav N, 2015, SIGNAL IMAGE VIDEO P, V9, P1531, DOI 10.1007/s11760-013-0607-2
   Yadav N, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P1121, DOI 10.1109/CCAA.2015.7148543
   Yadav P, 2016, INT J COMPUT SCI MOB, V5, P650
   Yan PM, 2001, PROC SPIE, V4552, P280
   Yang Wentao, 2007, Wuhan University Journal of Natural Sciences, V12, P496, DOI 10.1007/s11859-006-0086-1
   Yetik IS, 2001, OPT COMMUN, V197, P275, DOI 10.1016/S0030-4018(01)01462-6
   Yetik IS, 2000, INT CONF ACOUST SPEE, P93, DOI 10.1109/ICASSP.2000.861872
   Yi JW, 2015, APPL OPTICS, V54, P10650, DOI 10.1364/AO.54.010650
   Yng TLB, 2008, IEEE T CONSUM ELECTR, V54, P1453, DOI 10.1109/TCE.2008.4637640
   Yu J, 2017, OPT APPL, V47, P141, DOI 10.5277/oa170113
   Zhang JP, 2015, SIAM J IMAGING SCI, V8, P2487, DOI 10.1137/14097121X
   Zhang YS, 2018, MULTIDIM SYST SIGN P, V29, P999, DOI 10.1007/s11045-017-0482-z
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
NR 131
TC 5
Z9 6
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10673
EP 10700
DI 10.1007/s11042-018-6594-0
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400051
DA 2024-07-18
ER

PT J
AU Gao, H
   Gao, TG
AF Gao, Hang
   Gao, Tiegang
TI Double verifiable image encryption based on chaos and reversible
   watermarking algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Verifiable image encryption; Reversible watermarking; Chaos
   optimization; Image hash
ID PERMUTATION; SEARCH
AB The integrity of image is the premise for various applications. The existing image encryption algorithms rarely have the function of verifying the integrity for the decrypted image. To cope with this problem, a novel double verifiable image encryption algorithm based on chaos and reversible watermarking is proposed. In the proposed scheme, the 256-bit hash of original image is firstly calculated and embedded into the pixel-level permutated image by histogram shifting based reversible watermarking, then image diffusion is conducted based on hyper-chaos. Lastly, the hash values of diffused image and original image are embedded into the diffused image itself using difference expansion based reversible watermarking, thus the verifiable encrypted image (VEI) is generated. The secret key of the algorithm depends on the image itself; this makes the brute-force attacks impossible, and the application of reversible watermarking guarantees that the integrity of the VEI and decrypted image can be verified. Experiments and analysis are given to demonstrate that the proposed scheme has better performances, and it has good potential in the application of medical and military image.
C1 [Gao, Hang] Nankai Univ, Coll Comp & Control Engn, Tianjin 300350, Peoples R China.
   [Gao, Tiegang] Nankai Univ, Coll Software, 38 Tongyan Rd,Haihe Educ Pk, Tianjin 300350, Peoples R China.
C3 Nankai University; Nankai University
RP Gao, TG (corresponding author), Nankai Univ, Coll Software, 38 Tongyan Rd,Haihe Educ Pk, Tianjin 300350, Peoples R China.
EM gaotiegang@nankai.edu.cn
RI Gao, Tiegang/AAT-9599-2021
FU Program of Natural Science Fund of Tianjin, China [16JCYBJC15700]
FX The work was supported by the Program of Natural Science Fund of
   Tianjin, China (Grant NO. 16JCYBJC15700).
CR [Anonymous], 2002, FEDERAL INFORM PROCE, V180-2
   Belazi A, 2014, NONLINEAR DYNAM, V76, P1989, DOI 10.1007/s11071-014-1263-y
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Chen BY, 2017, IEEE IPCCC
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JX, 2015, NONLINEAR DYNAM, V81, P1151, DOI 10.1007/s11071-015-2057-6
   Ding M, 2016, IEEE T IMAGE PROCESS, V25, P776, DOI 10.1109/TIP.2015.2507445
   Ding M, 2015, IEEE T CYBERNETICS, V45, P2413, DOI 10.1109/TCYB.2014.2373393
   Dong CE, 2014, SIGNAL PROCESS-IMAGE, V29, P628, DOI 10.1016/j.image.2013.09.006
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P8759, DOI 10.1007/s11042-017-4772-0
   Gao TG, 2008, CHAOS SOLITON FRACT, V38, P213, DOI 10.1016/j.chaos.2006.11.009
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Gao TG, 2006, INT J MOD PHYS C, V17, P471, DOI 10.1142/S0129183106008625
   Gu QL, 2013, DIGIT SIGNAL PROCESS, V23, P213, DOI 10.1016/j.dsp.2012.07.013
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Hu YJ, 2008, IEEE T MULTIMEDIA, V10, P1500, DOI 10.1109/TMM.2008.2007341
   Li CQ, 2016, SIGNAL PROCESS, V118, P203, DOI 10.1016/j.sigpro.2015.07.008
   Li CQ, 2013, NONLINEAR DYNAM, V73, P2083, DOI 10.1007/s11071-013-0924-6
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu Q, 2015, COMMUN NONLINEAR SCI, V20, P506, DOI 10.1016/j.cnsns.2014.06.005
   Liu XY, 2015, APPL MATH COMPUT, V266, P1083, DOI 10.1016/j.amc.2015.06.041
   Rostami MJ, 2017, COMPUT ELECTR ENG, V62, P384, DOI 10.1016/j.compeleceng.2017.04.004
   Sui LS, 2014, OPT LASER ENG, V56, P1, DOI 10.1016/j.optlaseng.2013.12.001
   Wang XY, 2016, NONLINEAR DYNAM, V83, P333, DOI 10.1007/s11071-015-2330-8
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wang Y, 2009, CHAOS SOLITON FRACT, V41, P1773, DOI 10.1016/j.chaos.2008.07.031
   Wu XJ, 2016, INFORM SCIENCES, V349, P137, DOI 10.1016/j.ins.2016.02.041
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yanchuk S, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.056235
   Yuan XF, 2014, APPL SOFT COMPUT, V17, P12, DOI 10.1016/j.asoc.2013.12.016
   Zhang S, 2016, MULTIMED TOOLS APPL, V75, P17157, DOI 10.1007/s11042-015-2982-x
   Zhang S, 2016, NONLINEAR DYNAM, V84, P833, DOI 10.1007/s11071-015-2530-2
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   Zhu HG, 2017, NONLINEAR DYNAM, V89, P61, DOI 10.1007/s11071-017-3436-y
NR 39
TC 9
Z9 10
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7267
EP 7288
DI 10.1007/s11042-018-6461-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700039
DA 2024-07-18
ER

PT J
AU Li, F
   Xu, LX
   Duan, SH
   Wu, WF
   Zhao, HF
   Ling, Q
AF Li, Feng
   Xu, Lixiang
   Duan, Shihui
   Wu, Wenfu
   Zhao, Haifeng
   Ling, Qiang
TI Improving hierarchical mobile video caching through distributed
   cross-layer coordination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile caching; Video-on-demand; Hierarchical; Coordination
ID WIRELESS; ALGORITHMS; REPLICATION; PROXY
AB When videos are watched through mobile networks, their request delay may be long and could seriously degrade the quality of experience of users. One promising way to resolve this issue is to introduce cache systems into the concerned mobile networks. Cache systems are typically composed of three layers, the top layer of online video service providers, the middle layer of core networks to transmit the requested videos, and the bottom layer of base stations which directly provide users the requested videos. These layers are equipped with different types of caches and form a hierarchical mobile video caching system to provide videos requested by mobile users. As the concerned cache systems at all layers have limited space, we have to solve two critical problems: 1) how to make wise caching decision regarding the most popular videos, 2) how to efficiently coordinate caches at the same layer and different layers for better caching performance. We formulate these two problems into an integer optimization. To solve this optimization, we define a cache benefit for each video in each cache, which quantitatively measures the performance benefit of caching that video in the concerned cache. Based on that cache benefit, we propose a distributed cross-layer coordination algorithm to solve the caching optimization problem. Moreover, a video migration algorithm between different caching layers is proposed to further improve the caching performance. Simulations were done to confirm that our caching algorithms outperform the popular Inclusive Cache Hierarchy and Exclusive Cache Hierarchy algorithms.
C1 [Li, Feng; Xu, Lixiang; Ling, Qiang] Univ Sci & Technol China, Dept Automat, Hefei 230027, Anhui, Peoples R China.
   [Duan, Shihui] Minist Ind & Informat Technol Peoples Republ Chin, CAICT, Key Lab Internet & Ind Integrat Innovat, Beijing 100191, Peoples R China.
   [Wu, Wenfu; Zhao, Haifeng] Huawei Technol Co Ltd, Shanghai 201206, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Huawei Technologies
RP Ling, Q (corresponding author), Univ Sci & Technol China, Dept Automat, Hefei 230027, Anhui, Peoples R China.
EM qling@ustc.edu.cn
RI zhao, haifeng/JNX-7170-2023; LI, feng/HIR-1703-2022
OI Ling, Qiang/0000-0001-5688-4130
FU "Internet plus" major projects for the "Internet plus" coordinated
   manufacturing cloud service support platform
FX This work was partially supported by the "Internet plus" major projects
   for the "Internet plus" coordinated manufacturing cloud service support
   platform.
CR Abhari A, 2010, MULTIMED TOOLS APPL, V46, P91, DOI 10.1007/s11042-009-0309-5
   Ahlehagh H., 2012, IEEE International Conference on Communications (ICC 2012), P7082, DOI 10.1109/ICC.2012.6364966
   Ahmed E, 2017, IEEE COMMUN MAG, V55, P138, DOI 10.1109/MCOM.2017.1700120
   Choi J, 2012, IEEE COMMUN SURV TUT, V14, P156, DOI 10.1109/SURV.2011.030811.00051
   Cisco SJ, 2013, CISCO PUBLIC INF
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dai J, 2012, IEEE J SEL AREA COMM, V30, P458, DOI 10.1109/JSAC.2012.120226
   Das SM, 2007, AD HOC NETW, V5, P680, DOI 10.1016/j.adhoc.2006.11.004
   Dimokas N, 2008, MOBILE NETW APPL, V13, P337, DOI 10.1007/s11036-008-0063-3
   ElBamby MS, 2014, 2014 11TH INTERNATIONAL SYMPOSIUM ON WIRELESS COMMUNICATIONS SYSTEMS (ISWCS), P945, DOI 10.1109/ISWCS.2014.6933489
   Fan XP, 2013, J PARALLEL DISTR COM, V73, P653, DOI 10.1016/j.jpdc.2013.01.006
   Gupta M., 2014, INT J COMPUTER SCI I, V5, P5441
   Hennessy John L, 2011, Computer Architecture: A Quantitative Approach
   Kang HJ, 2014, J COMMUN NETW-S KOR, V16, P568, DOI 10.1109/JCN.2014.000095
   Li YH, 2013, CHINA INT J, V11, P104
   Li Z, 2015, J NETW SYST MANAG, V23, P445, DOI 10.1007/s10922-014-9300-1
   Ling Q, 2016, MULTIMED TOOLS APPL, V75, P165, DOI 10.1007/s11042-014-2281-y
   Ling Q, 2015, MULTIMED TOOLS APPL, V74, P11117, DOI 10.1007/s11042-014-2220-y
   Liu A, 2015, IEEE T SIGNAL PROCES, V63, P57, DOI 10.1109/TSP.2014.2367473
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu YJ, 2016, J CHEM-NY, V2016, DOI 10.1155/2016/6903524
   Molisch A. F., 2014, ADV ELECT ENG, V2014, P1, DOI DOI 10.1155/2014/261390
   Neves T.A., 2010, ELECT NOTES DISCRETE, V36, P89
   Neves T, 2015, OPTIM LETT, V9, P677, DOI 10.1007/s11590-014-0770-6
   Pack S, 2008, IEEE T VEH TECHNOL, V57, P3165, DOI 10.1109/TVT.2008.917238
   Pallis G, 2006, COMMUN ACM, V49, P101, DOI 10.1145/1107458.1107462
   Shen HP, 2004, LECT NOTES COMPUT SC, V3042, P841
   Shuja J, 2017, IEEE ACCESS, V5, P24542, DOI 10.1109/ACCESS.2017.2713818
   Tenzakhti F, 2004, J SYST ARCHITECT, V50, P591, DOI 10.1016/j.sysarc.2003.12.003
   Wang JZ, 2005, MASCOTS 2005:13th IEEE International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems, P311, DOI 10.1109/MASCOTS.2005.43
   Wolman A, 1999, OPERATING SYSTEMS REVIEW, VOL 33, NO 5, DECEMBER 1999, P16, DOI 10.1145/319344.319153
   Xiang Z, 2001, 2001 P ICII 2001 BEI, V5, P328
   Yang B, 2006, 2 LEVEL PROXY MEDIA, P852
   Zhang Q, 2004, IEEE T MULTIMEDIA, V6, P587, DOI [10.1109/TMM.2004.830816, 10.1109/tmm.2004.830816]
   Zhou XB, 2007, J NETW COMPUT APPL, V30, P515, DOI 10.1016/j.jnca.2006.03.001
NR 37
TC 0
Z9 0
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 6049
EP 6071
DI 10.1007/s11042-018-6351-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100050
DA 2024-07-18
ER

PT J
AU Neha,
   Chatterjee, K
AF Neha
   Chatterjee, Kakali
TI Biometric re-authentication: an approach towards achieving transparency
   in user authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; Keystroke dynamics; Behavioral biometrics; Security
ID KEYSTROKE DYNAMICS; IDENTIFICATION; SCHEME
AB Providing fixed re-authentication attempts to the user in case of password mismatch is a very old concept. But as password based authentication mechanisms are prone to many security attacks, user's biometric properties along with passwords are highly in use for user authentication these days. It will be more secure and convenient if re-authentication influenced by the biometric behavior of the user is applied in the authentication system. It is a challenging task to identify a genuine user using behavioral biometric due to its low repeatability and wide variation. So, to increase the efficiency and robustness of the authentication system in case of score mismatch, the clustering of user's behavior and assigning different re-authentication attempt to different cluster is needed. In this paper, we have proposed a transparent fixed text, keystroke based user authentication framework, which will enhance the security of traditional password based authentication mechanism. A new classification algorithm and dynamic attempt allocation algorithm have been proposed which will make the authentication system smart enough to provide the genuine user a fare authentication attempt.
C1 [Neha; Chatterjee, Kakali] Natl Inst Technol, Dept Comp Sci & Engn, Patna, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Neha, (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Patna, Bihar, India.
EM neha.cse14@nitp.ac.in; kakali@nitp.ac.in
RI Chatterjee, Kakali/AAC-3782-2019
OI Chatterjee, Kakali/0000-0003-3522-2044
CR Ahmed AAE, 2007, IEEE T DEPEND SECURE, V4, P165, DOI 10.1109/TDSC.2007.70207
   [Anonymous], 2011, CLIMATE CHANGE HINDU, DOI DOI 10.1109/PACCS.2011.5990168
   Azevedo GLFBG, 2007, IEEE C EVOL COMPUTAT, P3577, DOI 10.1109/CEC.2007.4424936
   Balagani KS, 2011, PATTERN RECOGN LETT, V32, P1070, DOI 10.1016/j.patrec.2011.02.014
   Bhattacharyya D, 2009, INT J GRID DISTRIB, V2, P13
   Chandrasekar V, 2016, STOCH ANAL APPL, V34, P155, DOI 10.1080/07362994.2015.1112291
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   Davoudi H., 2009, 2009 14th International CSI Computer Conference (CSICC 2009) (Postponed from July 2009), P570, DOI 10.1109/CSICC.2009.5349640
   Garcia J. D., 1986, United States patent US Patent, Patent No. [4621334, 4,621,334]
   Giot R, 2011, COMPUT SECUR, V30, P427, DOI 10.1016/j.cose.2011.03.004
   Gong LY, 2013, J COMPUT SYST SCI, V79, P122, DOI 10.1016/j.jcss.2012.06.002
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hempstalk K, 2008, LECT NOTES ARTIF INT, V5211, P505, DOI 10.1007/978-3-540-87479-9_51
   Ho J, 2018, APPL INTELL, V48, P1547, DOI 10.1007/s10489-017-1020-2
   Hocquet S, 2005, Fourth IEEE Workshop on Automatic Identification Advanced Technologies, Proceedings, P224, DOI 10.1109/AUTOID.2005.30
   Hocquet S, 2007, LECT NOTES COMPUT SC, V4642, P531
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P1295, DOI 10.1109/34.735803
   Huang Y, 2013, IERI PROC, V4, P32, DOI 10.1016/j.ieri.2013.11.006
   Im SK, 2001, J KOREAN PHYS SOC, V38, P268
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Kolakowska A, 2018, ADV INTELL SYST, V551, P42, DOI 10.1007/978-3-319-62120-3_4
   Kukula E., 2001, P 35 ANN INT CARN C, P83
   Kumar A, 2003, LECT NOTES COMPUT SC, V2688, P668
   Lee NY, 2005, COMPUT STAND INTER, V27, P177, DOI 10.1016/j.csi.2004.06.001
   Liew K-M, 2004, PAR DISTR COMP APPL, V3320
   Marcolin F, 2017, MULTIMED TOOLS APPL, V76, P13805, DOI 10.1007/s11042-016-3741-3
   Mariño C, 2006, PATTERN ANAL APPL, V9, P21, DOI 10.1007/s10044-005-0022-6
   Matsumoto T, 2002, P SOC PHOTO-OPT INS, V4677, P275, DOI 10.1117/12.462719
   Monrose F, 2000, FUTURE GENER COMP SY, V16, P351, DOI 10.1016/S0167-739X(99)00059-X
   Prabhakar S., 2003, IEEE Security & Privacy, V1, P33, DOI 10.1109/MSECP.2003.1193209
   Revett K, 2009, INT J CONTROL AUTOM, V7, P7, DOI [10.1007/S12555-009-0102-2, 10.1007/s12555-009-0102-2]
   Rybnik M, 2008, SEVENTH INTERNATIONAL CONFERENCE ON COMPUTER INFORMATION SYSTEMS AND INDUSTRIAL MANAGEMENT APPLICATIONS, PROCEEDINGS, P225, DOI 10.1109/CISIM.2008.8
   Sanchez-Reillo R, 2000, IEEE T PATTERN ANAL, V22, P1168, DOI 10.1109/34.879796
   Shen C, 2010, IEEE INT C INF THEOR, p349e53
   Shimshon T., 2010, EL EL ENG ISR IEEEI
   Song RG, 2010, COMPUT STAND INTER, V32, P321, DOI 10.1016/j.csi.2010.03.008
   Stockton GR, 1980, RANDR2526NSF RAND CO
   Sungzoon Cho, 2005, Advances in Biometrics. International Conference, ICB 2006. Proceedings (Lecture Notes in Computer Science Vol.3832), P626
   Vezzetti E, 2018, MULTIMED TOOLS APPL, V77, P14177, DOI 10.1007/s11042-017-5025-y
   Viju Prakash, 2010, U J COMPUT SCI ENG T, V1, P133
   Visumathi J, 2015, J APPL SEC RES, V10, P375, DOI 10.1080/19361610.2015.1038767
   Wan MH, 2017, FUZZY SET SYST, V318, P120, DOI 10.1016/j.fss.2016.06.001
   Wan MH, 2017, MULTIMED TOOLS APPL, V76, P355, DOI 10.1007/s11042-015-3057-8
   Wan MH, 2014, INFORM SCIENCES, V274, P55, DOI 10.1016/j.ins.2014.02.145
   Xu J, 2009, COMPUT STAND INTER, V31, P723, DOI 10.1016/j.csi.2008.09.006
   Yu E, 2003, LECT NOTES COMPUT SC, V2690, P1016
   Zheng N, 2011, ACM C COMP COMM SEC, p1e12
NR 47
TC 7
Z9 8
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6679
EP 6700
DI 10.1007/s11042-018-6448-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700012
DA 2024-07-18
ER

PT J
AU Salim, C
   Makhoul, A
   Darazi, R
   Couturier, R
AF Salim, Christian
   Makhoul, Abdallah
   Darazi, Rony
   Couturier, Raphael
TI Similarity based image selection with frame rate adaptation and local
   event detection in wireless video sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless video sensor networks; Shot similarity; Video aggregation;
   Frames similarity; Event detection
AB Wireless Video Sensor Networks (WVSNs7unding environmental information. Those sensor nodes can locally process the information and then wirelessly transmit it to the coordinator and to the sink to be further processed. As a consequence, more abundant video and image data are collected. In such densely deployed networks, the problem of data redundancy arises when information are gathered from neighboring nodes. To overcome this problem, one important enabling technology for WVSN is data aggregation, which is essential to be cost-efficient. In this paper, we propose a new approach for data aggregation in WVSN based on images and shot similarity functions. It is deployed on two levels: the video-sensor node level and the coordinator level. At the sensor node level the proposed algorithms aim at reducing the number of frames sensed by the sensor nodes and sent to the coordinator. At the coordinator level, after receiving shots from different neighbouring sensor nodes, the similarity between these shots is computed to eliminate redundancies and to only send the frames which meet a certain condition to the sink. The similarity between shots is evaluated based on their color, edge and motion information. We evaluate our approach on a live scenario and compare the results with another approach from the literature in terms of data reduction and energy consumption. The results show that the two approaches have a significant data reduction to reduce the energy consumption, thus our approach tends to overcome the other one in terms of reducing the energy consumption related to the sensing process, and to the transmitting process while guaranteeing the detection of all the critical events at the node and the coordinator levels.
C1 [Salim, Christian; Makhoul, Abdallah; Couturier, Raphael] Univ Bourgogne Franche Comte, Femto St Inst, Belfort, France.
   [Salim, Christian; Darazi, Rony] Antonine Univ, TICKET Lab, Hadat Baabda, Lebanon.
C3 Universite de Franche-Comte; Centre National de la Recherche
   Scientifique (CNRS); Universite de Technologie de Belfort-Montbeliard
   (UTBM)
RP Salim, C (corresponding author), Univ Bourgogne Franche Comte, Femto St Inst, Belfort, France.; Salim, C (corresponding author), Antonine Univ, TICKET Lab, Hadat Baabda, Lebanon.
EM christian.salim@univ-fcomte.fr; abdallaj.makhoul@univ-fcomte.fr;
   rony.darazi@ua.edu.lb; raphael.couturier@univ-fcomte.fr
RI Makhoul, Abdallah/K-7535-2018; Salim, Christian/ABA-1243-2020;
   Couturier, Raphaël/C-1095-2013
OI Salim, Christian/0000-0002-7553-1987; Couturier,
   Raphaël/0000-0003-1490-9592
FU Labex ACTION program [ANR-11-LABX-0001-01]; National Council for
   Scientific Research in Lebanon CNRS-L; Hubert Curien CEDRE programme
   [40283YK]; Agence Universitaire de la Francophonie AUF-PCSI programme
FX This project has been performed in cooperation with the Labex ACTION
   program (contract ANR-11-LABX-0001-01) and this work is partially funded
   with support from the National Council for Scientific Research in
   Lebanon CNRS-L, the Hubert Curien CEDRE programme no 40283YK, and the
   Agence Universitaire de la Francophonie AUF-PCSI programme.
CR Akyildiz IF, 2008, P IEEE, V96, P1588, DOI 10.1109/JPROC.2008.928756
   Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   Alaei M, 2010, SENSORS-BASEL, V10, P3145, DOI 10.3390/s100403145
   Alippi C, 2010, IEEE T INSTRUM MEAS, V59, P335, DOI 10.1109/TIM.2009.2023818
   [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   Bahi Jacques M., 2014, ADHOC NOW, V11, P153
   Benzerbadj A, 2013, PROCEDIA COMPUT SCI, V21, P234, DOI 10.1016/j.procs.2013.09.031
   Boluk P., 2015, INT J DISTRIB SENSOR, V2015, P1
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Choi J, 2007, IEEE J SOLID-ST CIRC, V42, P2978, DOI 10.1109/JSSC.2007.908716
   Dai R, 2009, IEEE T MULTIMEDIA, V11, P1148, DOI 10.1109/TMM.2009.2026100
   Jbeily T, 2015, IJSR, V4
   Jiang B, 2013, IEEE T MOBILE COMPUT, V12, P735, DOI 10.1109/TMC.2012.44
   Kyrkou C, 2016, IEEE EMBED SYST LETT, V8, P37, DOI 10.1109/LES.2016.2526071
   Liang Y, 2010, ACM SIGCOMM COMP COM, V40, P13
   Luo Wusheng, 2012, DISTRIBUTED SENSOR N, V12, P1
   Newell A, 2011, AD HOC NETW, V9, P514, DOI 10.1016/j.adhoc.2010.08.003
   Nguyen HT, 2000, IEEE T IMAGE PROCESS, P1
   Pham C, 2011, J NETW COMPUT APPL, V34, P783, DOI 10.1016/j.jnca.2010.10.002
   Politis I, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.30
   Prieto MS, 2003, IEEE T PATTERN ANAL, V25, P1265, DOI 10.1109/TPAMI.2003.1233900
   Priyadarshini SBB, 2013, IJERT, V2
   QIN Z, 2013, INT J DISTRIB SENS N, V2013
   Rasheed Z, 2005, IEEE T MULTIMEDIA, V7, P1097, DOI 10.1109/TMM.2005.858392
   Sahasrabudhe N, 1999, STRUCTURED SPATIAL D, P97
   Shahab MB, 2017, IEEE COMMUN LETT, V21, P310, DOI 10.1109/LCOMM.2016.2620979
   Spagnolo P, 2006, IMAGE VISION COMPUT, V24, P411, DOI 10.1016/j.imavis.2006.01.001
   Stewart R, 2003, PATENT APPL PUBL, V21, P234
   Usman MR, 2015, SUBJECTIVE QUALITY A, V9, P1574
   Usman M, 2020, IEEE T NETW SCI ENG, V7, P274, DOI 10.1109/TNSE.2018.2863680
   Usman MA, 2016, INT CONF UBIQ FUTUR, P839, DOI 10.1109/ICUFN.2016.7537155
   Yao Yingwei, 2005, IEEE T COMMUN, V53, P1, DOI DOI 10.1109/TCOMM.2005.852834
   Zeng XL, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1285, DOI 10.1109/ICME.2008.4607677
NR 33
TC 7
Z9 7
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5941
EP 5967
DI 10.1007/s11042-018-6376-8
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100045
DA 2024-07-18
ER

PT J
AU Youn, J
   Cho, D
AF Youn, Jonghee
   Cho, Doosan
TI A spill data aware memory assignment technique for improving power
   consumption of multimedia memory systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia application; Energy consumption; Hybrid cache; Embedded
   system; Nonvolatile memory; Scratchpad memory
AB As embedded memory technology evolves, the traditional Static Random Access Memory (SRAM) technology has reached the end of development. For deepening the manufacturing process technology, the next generation memory technology is highly required because of the exponentially increasing leakage current of SRAM. Non-volatile memories such as STT-MRAM (Spin Torque Transfer Magnetic Random Access Memory), PCM (Phase Change Memory) are good candidates for replacing SRAM technology in embedded memory systems. They have many advanced characteristics in the perspective of power consumption, leakage power, size (density) and latency. Nonetheless, nonvolatile memories have two major problems that hinder their use it the next-generation memory. First, the lifetime of the nonvolatile memory cell is limited by the number of write operations. Next, the write operation consumes more latency and power than the same size of the read operation. This study describes a compiler optimization technique to overcome such disadvantages of a nonvolatile memory component in hybrid cache memories. A hybrid cache is proposed to overcome the disadvantages using a compiler. Specifically, to minimize the number of write operations for nonvolatile memory, we present a data replacement technique that considers the locations of the register spill data. Many portions of the memory accesses are yielded by the spill data of a register allocator in an optimizing compiler. Such spill data can be partially removed using a recalculation method. Thus, we implemented an optimization technique that rearranges the data placement with recalculation to minimize the write instructions on the nonvolatile memory. Our experimental results show that the proposed technique can reduce the average number of spill codes by 20%, and improves the energy consumption by 20.2% on average.
C1 [Youn, Jonghee] Yeungnam Univ, Dept Comp Engn, Gyongsan, Gyeongsangbuk D, South Korea.
   [Cho, Doosan] Sunchon Natl Univ, Dept Elect & Elect Engn, Sunchon, Jeollanam Do, South Korea.
C3 Yeungnam University; Sunchon National University
RP Cho, D (corresponding author), Sunchon Natl Univ, Dept Elect & Elect Engn, Sunchon, Jeollanam Do, South Korea.
EM dscho@scnu.ac.kr
OI Cho, Doosan/0000-0002-1681-432X
FU MSIT(Ministry of Science, ICT), Korea, under the ITRC(Information
   Technology Research Center) support program [IITP-2018-2016-0-00313];
   National Research Foundation of Korea(NRF) - Korea government (MSIT)
   [2018R1D1A1B0705647]; National Research Foundation of Korea(NRF) -
   Ministry of Education [NRF-2018R1D1A1B07050054]; Yeungnam University
FX This research was supported by the MSIT(Ministry of Science, ICT),
   Korea, under the ITRC(Information Technology Research Center) support
   program(IITP-2018-2016-0-00313) supervised by the IITP(Institute for
   Information & communications Technology Promotion), the National
   Research Foundation of Korea(NRF) grant funded by the Korea government
   (MSIT) (No. 2018R1D1A1B0705647), and Basic Science Research Program
   through the National Research Foundation of Korea(NRF) funded by the
   Ministry of Education(NRF-2018R1D1A1B07050054), and the Yeungnam
   University Research Grant.
CR [Anonymous], 1992, THESIS
   [Anonymous], 2015, ACM T ARCHIT CODE OP
   Cho DS, 2009, IEEE T COMPUT AID D, V28, P554, DOI 10.1109/TCAD.2009.2014002
   Cho H, 2007, ACM LCTES, P13
   Chu YS, 2009, DES AUT TEST EUROPE, P405
   Gebotys CH, 1997, DES AUT CON, P435, DOI 10.1145/266021.266192
   Guthaus MR, 2001, WWC-4: IEEE INTERNATIONAL WORKSHOP ON WORKLOAD CHARACTERIZATION, P3, DOI 10.1109/WWC.2001.990739
   Hu J., 2010, P 8 IEEE S APPL SPEC, P7
   Hu JT, 2010, DES AUT CON, P350
   Kang S, 2012, IEEE REAL TIME, P119, DOI 10.1109/RTAS.2012.22
   KENNEDY K, 1978, COMPUT LANG, V3, P163, DOI 10.1016/0096-0551(78)90009-7
   Lee BC, 2010, IEEE MICRO, V30, P131, DOI 10.1109/MM.2010.24
   M. Inc, 2000, MOT DSP 563000 FAM M
   Park Chanik, 2004, P 4 ACM INT C EMB SO, P114, DOI [10.1145/1017753.1017775, DOI 10.1145/1017753.1017775]
   Puhr Westerheide, 1979, IFAC P, V12, P117, DOI [10.1016/S1474-6670(17)65880-4, DOI 10.1016/S1474-6670(17)65880-4]
   Shi L., 2010, GLVLSI '10: Proceedings of the 20th ACM/IEEE Great Lakes Symposium on VLSI, 2010, P91
   Thammanur S, 2004, ACM T PROGR LANG SYS, V26, P938, DOI 10.1145/1034774.1034776
   Youfeng Wu, 1994, Proceedings of the 27th Annual International Symposium on Microarchitecture. MICRO 27, P1, DOI 10.1109/MICRO.1994.717399
   Zhang H, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND NATURAL COMPUTING, VOL I, P262, DOI 10.1109/CINC.2009.108
   Zhou P, 2009, CONF PROC INT SYMP C, P14, DOI 10.1145/1555815.1555759
NR 20
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5463
EP 5478
DI 10.1007/s11042-018-6783-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100022
DA 2024-07-18
ER

PT J
AU Zhang, K
   Zhou, WG
   Sun, SY
   Li, B
AF Zhang, Kai
   Zhou, Wengang
   Sun, Shaoyan
   Li, Bin
TI Multiple complementary inverted indexing based on multiple metrics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Inverted indexing; Nearest neighbor search; Image retrieval; Multiple
   metrics; Latin hypercube sampling
ID PRODUCT QUANTIZATION
AB Inverted indexing based on vector quantization has been a popular technique in large scale information retrieval. With vector quantization based on a certain similarity metric, the sample space is partitioned into some voronoi cells, and samples in each cell are indexed by an inverted list. The nearest neighbors of a query are efficiently identified by looking up the cell where the query is located. To improve the recall, the sample space partitioning has been performed multiple times with different initializations of k-means to build multiple inverted indexes. While with the single similarity metric, e.g., Euclidean distance, high correlation may exist between multiple inverted indexes, which constrains the possible gain in recall. A new multiple inverted indexing method based on multiple sample space partitioning with multiple different similarity metrics is presented in this paper. Furthermore, several techniques for defining multiple metrics are investigated empirically. Experiments are conducted on 3 representative datasets, million-scale SIFT and GIST feature sets and a deep-learning-produced feature set, to properly evaluate the effectiveness of the proposed method. Experiment results show that the proposed method has competitive performance compared with the state-of-the-art inverted indexing methods in terms of recall and retrieval time, and the Latin-Hypercube weighting method can generate better diverse multiple metrics and get better gain in recall.
C1 [Zhang, Kai; Zhou, Wengang; Sun, Shaoyan; Li, Bin] Univ Sci & Technol China, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Li, B (corresponding author), Univ Sci & Technol China, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei, Anhui, Peoples R China.
EM forever1@mail.ustc.educn; zhwg@ustc.edu.cn; sunshy@mail.ustc.edu.cn;
   binli@ustc.edu.cn
RI Zhang, Kailin/H-7768-2016
OI Zhang, Kailin/0000-0002-2106-7293
FU National Natural Science Foundation of China [61473271, 61331015]
FX The work is supported by the National Natural Science Foundation of
   China under grand No. 61473271 and No. 61331015.
CR Anh NT, 2015, ACM MULT C
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], IEEE INT C COMP VIS
   Babenko A, 2012, IEEE C COMP VIS PATT
   Babenko A, 2015, IEEE T PATTERN ANAL, V37, P1247, DOI 10.1109/TPAMI.2014.2361319
   Cai DF, 2014, IET GENER TRANSM DIS, V8, P1539, DOI 10.1049/iet-gtd.2013.0649
   Charikar MS, 2002, 34 ACM S THEOR COMP
   Chávez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808
   Dasgupta S, 2017, SCIENCE, V358, P793, DOI 10.1126/science.aam9868
   David N, 2015, INT C RES DEV INF RE
   David N, 2006, IEEE C COMP VIS PATT
   FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297
   GE T, 2014, TPAMI, V36, P744, DOI DOI 10.1109/TPAMI.2013.240
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   He KM, 2013, PROC CVPR IEEE, P2938, DOI 10.1109/CVPR.2013.378
   Helton JC, 2003, RELIAB ENG SYST SAFE, V81, P23, DOI 10.1016/S0951-8320(03)00058-9
   Herve J, 2011, IEEE INT C AC SPEECH
   Hoi SCH, 2006, IEEE C COMP VIS PATT
   Hoi SCH, 2008, PROC CVPR IEEE, P71
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Josef S, 2003, IEEE INT C COMP VIS
   Kalantidis Y, 2014, PROC CVPR IEEE, P2329, DOI 10.1109/CVPR.2014.298
   Kevin L, 2015, ACM INT C MULT RETR
   Kyriakidis PC, 2005, QUANT GEO G, V14, P65
   Lei Z, 2013, IEEE C COMP VIS PATT
   Lejsek H, 2009, IEEE T PATTERN ANAL, V31, P869, DOI 10.1109/TPAMI.2008.130
   Liang Z, 2013, IEEE C COMP VIS PATT
   Liang Z, 2014, IEEE C COMP VIS PATT
   Liu HM, 2008, LECT NOTES COMPUT SC, V4993, P44
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marius M, 2009, INT C COMP VIS THEOR
   MCKAY MD, 1979, TECHNOMETRICS, V21, P239, DOI 10.2307/1268522
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Oren B, 2008, IEEE C COMP VIS PATT
   Pauleve L, 2010, PATTERN RECOGN LETT, V31, P1348, DOI 10.1016/j.patrec.2010.04.004
   Preetha MMSJ, 2016, IEEE INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGICAL TRENDS IN COMPUTING, COMMUNICATIONS AND ELECTRICAL ENGINEERING (ICETT)
   Santini S, 1999, IEEE T PATTERN ANAL, V21, P871, DOI 10.1109/34.790428
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Sravanthi B, 2016, ACM INT C MULT RETR
   Wang D, 2015, IEEE T IMAGE PROCESS, V24, P2646, DOI 10.1109/TIP.2015.2427518
   Weiss Yair., 2009, NIPS
   Wengang Z, 2010, ACM MULT C
   Yan X, 2013, IEEE INT C COMP VIS
   Yannis K, 2014, IEEE C COMP VIS PATT
   Yu H, 2009, IEEE T POWER SYST, V24, P661, DOI 10.1109/TPWRS.2009.2016589
   Yu LT, 2017, IEEE T IMAGE PROCESS, V26, P5057, DOI 10.1109/TIP.2017.2722224
   Yu SY, 2015, J RECEPT SIG TRANSD, V35, P458, DOI 10.3109/10799893.2015.1006332
   Zhaohua Z, 2016, ACM INT C RES DEV IN
   Zhou WG, 2016, IEEE T PATTERN ANAL, V38, P159, DOI 10.1109/TPAMI.2015.2430329
NR 50
TC 2
Z9 3
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7727
EP 7747
DI 10.1007/s11042-018-6439-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700059
DA 2024-07-18
ER

PT J
AU Rebai, I
   Ben Ayed, Y
   Mahdi, W
AF Rebai, Ilyes
   Ben Ayed, Yassine
   Mahdi, Walid
TI Spoken keyword search system using improved ASR engine and novel
   template-based keyword scoring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech recognition; Keyword spotting; Template-based keyword rescoring;
   Acoustic model fusion; Score normalization
ID DATA AUGMENTATION
AB Keyword search for spoken documents has become more and more important nowadays due to the increasing amount of spoken data. The typical system makes use of an Automatic Speech Recognition system (ASR) and information retrieval methods. While a number of studies have been done to get the optimal system performance, KeyWord Search (KWS) systems still suffer from two main drawbacks. First, the system performance depends strongly on the ASR transcripts which are inherently inexact. Due to the speech signal variabilities, ASR systems are far from being powerful. Second, KWS systems make detection decisions based on the lattice-based posterior probability which is incomparable across keywords. In addition, posterior probabilities of true detection usually fall into different ranges which decrease the spotting performance. This paper considers the problems of ASR transcriptions and keyword detection decision based on posterior probabilities. More specifically, we propose to enhance the ASR transcripts accuracy by introducing a new ASR architecture in which we integrate data augmentation and ensemble learning techniques into a single framework. In addition, we proposed a novel keyword rescoring method that provides scores from a new perspective. Precisely, inspired by template-based KWS approach, scores of similarity between the detected keywords are computed by computing the distance between the acoustic features and are used as new scores for decision. Experiments on French and English datasets show that the proposed KWS system potentially leads to more accurate keyword results than the conventional systems.
C1 [Rebai, Ilyes; Ben Ayed, Yassine] Univ Sfax, MIRACL Multimedia InfoRmat Syst & Adv Comp Lab, Sfax, Tunisia.
   [Mahdi, Walid] Taif Univ, Coll Comp & Informat Technol, At Taif, Saudi Arabia.
C3 Multimedia, InfoRmation Systems & Advancing Computing Laboratory
   (MIRACL); Universite de Sfax; Taif University
RP Rebai, I (corresponding author), Univ Sfax, MIRACL Multimedia InfoRmat Syst & Adv Comp Lab, Sfax, Tunisia.
EM rebai_ilyes@hotmail.fr; yassine.benayed@isims.usf.tn;
   walid.mahdi@isimsf.rnu.tn
RI MAHDI, Walid/HOF-7688-2023
OI MAHDI, Walid/0000-0003-3465-0397; rebai, ilyes/0000-0003-4504-3146
CR Abdullah A, 2009, 2009 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION, P301, DOI 10.1109/SoCPaR.2009.67
   Allauzen C., 2004, P WORKSH INT APPR SP, P33
   [Anonymous], 2017, CHIN J OCEANOL LIMNO
   [Anonymous], 1997, Tech. Rep.
   [Anonymous], TECH REP
   [Anonymous], 9 EUR C SPEECH COMM
   Banfield RE, 2007, IEEE T PATTERN ANAL, V29, P173, DOI 10.1109/TPAMI.2007.250609
   Can D, 2011, IEEE T AUDIO SPEECH, V19, P2338, DOI 10.1109/TASL.2011.2134087
   Ceamanos X, 2010, INT J IMAGE DATA FUS, V1, P293, DOI 10.1080/19479832.2010.485935
   Chen GG, 2014, ICASSP, V2014, P4087, DOI DOI 10.1109/ICASSP.2014.6854370
   Chen GG, 2015, INT CONF ACOUST SPEE, P5236, DOI 10.1109/ICASSP.2015.7178970
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Deng L, 2013, INT CONF ACOUST SPEE, P8604, DOI 10.1109/ICASSP.2013.6639345
   Deng L, 2012, INT CONF ACOUST SPEE, P2133, DOI 10.1109/ICASSP.2012.6288333
   Fiscus J. G., 2007, P ACM SIGIR WORKSH S, P51
   Graves A, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P273, DOI 10.1109/ASRU.2013.6707742
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Jaitly N., 2013, Proc. ICML Workshop Deep. Learn. Audio Speech Lang, V117
   Jaitly N, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P2577
   Karakos D, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P210, DOI 10.1109/ASRU.2013.6707731
   Ko T, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3586
   Mamou Jonathan, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P615, DOI 10.1145/1277741.1277847
   Mamou J, 2013, INT CONF ACOUST SPEE, P8272, DOI 10.1109/ICASSP.2013.6639278
   Miller DRH, 2007, INTERSPEECH 2007: 8TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION, VOLS 1-4, P1965
   Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382
   Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964
   Ragni A, 2014, INTERSPEECH, P810
   Rebai I, 2017, PROCEDIA COMPUT SCI, V112, P316, DOI 10.1016/j.procs.2017.08.003
   Saraclar M, 2004, URBANA, V51, P801
   Szoke I, 2006, NIST SPOK TERM DET E
   Szöke I, 2008, 2008 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY: SLT 2008, PROCEEDINGS, P273, DOI 10.1109/SLT.2008.4777893
   Van Tung Pham, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7078, DOI 10.1109/ICASSP.2014.6854973
   Wang SH, 2018, J MED SYST, V42, DOI [10.1007/s10916-017-0845-x, 10.1007/s10916-018-0932-7]
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Xiaohui Zhang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P215, DOI 10.1109/ICASSP.2014.6853589
   Yu RP, 2008, SEARCH SPONT CONV SP, P54
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22821, DOI 10.1007/s11042-018-5765-3
NR 37
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1495
EP 1510
DI 10.1007/s11042-018-6276-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700013
DA 2024-07-18
ER

PT J
AU Loh, WT
   Bong, DBL
AF Loh, Woei-Tan
   Bong, David Boon Liang
TI An error-based video quality assessment method with temporal information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video quality; Temporal effects; Temporal distortions; Multimedia
   content
ID MODEL
AB Videos are amongst the most popular online media for Internet users nowadays. Thus, it is of utmost importance that the videos transmitted through the internet or other transmission media to have a minimal data loss and acceptable visual quality. Video quality assessment (VQA) is a useful tool to determine the quality of a video without human intervention. A new VQA method, termed as Error and Temporal Structural Similarity (EaTSS), is proposed in this paper. EaTSS is based on a combination of error signals, weighted Structural Similarity Index (SSIM) and difference of temporal information. The error signals are used to weight the computed SSIM map and subsequently to compute the quality score. This is a better alternative to the usual SSIM index, in which the quality score is computed as the average of the SSIM map. For the temporal information, the second-order time-differential information are used for quality score computation. From the experiments, EaTSS is found to have competitive performance and faster computational speed compared to other existing VQA algorithms.
C1 [Loh, Woei-Tan; Bong, David Boon Liang] Univ Malaysia Sarawak, Fac Engn, Kota Samarahan, Malaysia.
C3 University of Malaysia Sarawak
RP Bong, DBL (corresponding author), Univ Malaysia Sarawak, Fac Engn, Kota Samarahan, Malaysia.
EM davidblbong@yahoo.com
RI Bong, David/I-8735-2016
OI Bong, David/0000-0002-9027-8422
FU Ministry of Higher Education Malaysia [F02/FRGS/1492/2016]
FX This work was supported by Ministry of Higher Education Malaysia through
   the provision of research grant: F02/FRGS/1492/2016.
CR Akramullah Shahriar, 2014, Digital Video Concepts, Methods, and Metrics: Quality, Compression, Performance, and Power Trade-Off Analysis, DOI DOI 10.1007/978-1-4302-6713-3
   [Anonymous], P 4 WORKSH MOB VID
   [Anonymous], 2005, 1 INT WORKSHOP VIDEO
   [Anonymous], 31 BRAZ TEL S SBRT20
   [Anonymous], PROCEEDINGS OF THE 2, DOI DOI 10.1145/2502081.2502168
   [Anonymous], 2003, Final report from the video quality experts group on the validation of objective models of video quality assessment
   [Anonymous], MEAS TECHN DIG AG TE
   Banno H, 2015, J VISION, V15, DOI 10.1167/15.2.4
   Bong DBL, 2015, MULTIMED TOOLS APPL, V74, P7355, DOI 10.1007/s11042-014-1983-5
   Cardoso JVM, 2014, IEEE SW SYMP IMAG, P57, DOI 10.1109/SSIAI.2014.6806028
   Chaofeng Li, 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7242, DOI 10.1117/12.811821
   Choi LK, 2016, IEEE SW SYMP IMAG, P29, DOI 10.1109/SSIAI.2016.7459167
   HALL CF, 1977, IEEE T SYST MAN CYB, V7, P161, DOI 10.1109/TSMC.1977.4309680
   ITU-T, 2016, ITU T REC H 264 ADV
   ITU-T, 1999, ITU T REC P 910 SUBJ
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Lee S, 2002, IEEE T MULTIMEDIA, V4, P129, DOI 10.1109/6046.985561
   Li PH, 2017, IEEE I CONF COMP VIS, P2089, DOI 10.1109/ICCV.2017.228
   LIMB JO, 1979, IEEE T SYST MAN CYB, V9, P778, DOI 10.1109/TSMC.1979.4310129
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Loh WT, 2015, IEEE ICCE, P290, DOI 10.1109/ICCE-TW.2015.7216904
   Ooyala, 2016, OOYAL GLOB VID IND Q
   Pinson MH, 2014, IEEE T BROADCAST, V60, P637, DOI 10.1109/TBC.2014.2365260
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Rimac-Drlje S, 2010, MULTIMED TOOLS APPL, V49, P425, DOI 10.1007/s11042-009-0442-1
   Seshadrinathan K, 2010, PROC SPIE, V7527, DOI 10.1117/12.845382
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Soundararajan R, 2013, IEEE T CIRC SYST VID, V23, P684, DOI 10.1109/TCSVT.2012.2214933
   Suchow JW, 2011, CURR BIOL, V21, P140, DOI 10.1016/j.cub.2010.12.019
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Vo DT, 2008, IEEE T CIRC SYST VID, V18, P609, DOI 10.1109/TCSVT.2008.918807
   Vranjes M, 2013, SIGNAL PROCESS-IMAGE, V28, P1, DOI 10.1016/j.image.2012.10.003
   Vu PV, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.013016
   Wandell B. A, 1995, Foundations of vision
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Watson AB, 2001, J ELECTRON IMAGING, V10, P20, DOI 10.1117/1.1329896
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
NR 45
TC 7
Z9 7
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30791
EP 30814
DI 10.1007/s11042-018-6107-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600030
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Qian, K
   Li, YH
   Su, KH
   Zhang, JL
AF Qian, Kun
   Li, Yinghua
   Su, Kehua
   Zhang, Jialing
TI A measure-driven method for normal mapping and normal map design of 3D
   models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Normal mapping; Normal map design; Measure-driven; Parameterization
ID OPTIMAL TRANSPORT; SURFACE; REGISTRATION
AB Normal mapping is one of the most important methods for photorealistic rendering. It preserves geometric attribute values on a simplified mesh. A normal map stores normal vectors for high-quality meshes in a 2D form. A simplified model is then rendered using these normal vectors. To keep a surface's normal property in a map it first of all requires 2D parameterization. The most common approach to this is to divide the surface into several patches, where each patch has its own parameterization. However, this approach has some weakness when it comes to designing global normal maps. This paper presents a measure-driven method that can interactively direct design of normal maps on a 2D plane. This 2D plane has minimal distortion and, more importantly, it is possible to zoom in or shrink the area of interest. The resulting, novel framework serves as a powerful tool for normal mapping and normal map design. We provide a variety of experimental results to demonstrate the efficiency, robustness and efficacy of our approach.
C1 [Qian, Kun; Zhang, Jialing] Kunming Univ Sci & Technol, Sch Civil Engn & Architecture, 727 South Jingming Rd, Kunming 650500, Yunnan, Peoples R China.
   [Qian, Kun; Li, Yinghua; Zhang, Jialing] Kunming Univ Sci & Technol, Fac Sci, 727 South Jingming Rd, Kunming 650500, Yunnan, Peoples R China.
   [Su, Kehua] Wuhan Univ, Sch Comp Sci, 299 Bayi Rd, Wuhan 430072, Peoples R China.
   [Qian, Kun] Kunming Univ Sci & Technol, Ctr Engn Math, 727 South Jingming Rd, Kunming 650500, Yunnan, Peoples R China.
C3 Kunming University of Science & Technology; Kunming University of
   Science & Technology; Wuhan University; Kunming University of Science &
   Technology
RP Li, YH (corresponding author), Kunming Univ Sci & Technol, Fac Sci, 727 South Jingming Rd, Kunming 650500, Yunnan, Peoples R China.
EM yinghuali@kmust.edu.cn
RI Li, Yinghua/AAU-7351-2021
FU National Natural Science Foundation of China [61772379]
FX This work is partially supported by National Natural Science Foundation
   of China(Project Number:61772379).
CR Alexandrov AD., 2005, CONVEX POLYHEDRA
   [Anonymous], 1974, Tech. rep.
   Becker B. G., 1993, Computer Graphics Proceedings, P183, DOI 10.1145/166117.166141
   Blinn J., 1978, Proceedings of the 5th annual conference on Computer graphics and interactive techniques-SIGGRAPH'78, V12, P286
   BRENIER Y, 1991, COMMUN PUR APPL MATH, V44, P375, DOI 10.1002/cpa.3160440402
   Chow B, 2003, J DIFFER GEOM, V63, P97
   Cignoni P, 1998, VISUALIZATION '98, PROCEEDINGS, P59, DOI 10.1109/VISUAL.1998.745285
   Cohen J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P115, DOI 10.1145/280814.280832
   Cook R. L., 1984, Computers & Graphics, V18, P223
   de Goes F, 2011, COMPUT GRAPH FORUM, V30, P1593, DOI 10.1111/j.1467-8659.2011.02033.x
   Desbrun M, 2002, COMPUT GRAPH FORUM, V21, P209, DOI 10.1111/1467-8659.00580
   Doggett Michael, 2000, P ACM SIGGRAPH EUROG, P59
   Dominitz A, 2010, IEEE T VIS COMPUT GR, V16, P419, DOI 10.1109/TVCG.2009.64
   Dongmei Zhang, 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P524, DOI 10.1109/CVPR.1999.784731
   Floater MS, 1997, COMPUT AIDED GEOM D, V14, P231, DOI 10.1016/S0167-8396(96)00031-3
   Gehling MB, 2007, VISUAL COMPUT, V23, P897, DOI 10.1007/s00371-007-0132-9
   Gu X., 2003, COMMUNICATION INFORM, V3, P171
   Gu X.D., 2008, Computational Conformal Geometry
   Gu XF, 2004, IEEE T MED IMAGING, V23, P949, DOI 10.1109/TMI.2004.831226
   Gu XF, 2016, ASIAN J MATH, V20, P383
   Gumhold S., 1999, Proceedings 1999 EUROGRAPHICS/SIGGRAPH Workshop on Graphics Hardware, P55, DOI 10.1145/311534.311578
   Guskov I, 2000, COMP GRAPH, P95, DOI 10.1145/344779.344831
   Haker S, 2004, INT J COMPUT VISION, V60, P225, DOI 10.1023/B:VISI.0000036836.66311.97
   Heidrich W, 2000, COMP GRAPH, P455, DOI 10.1145/344779.344984
   Heidrich W, 1998, LANGUAGE, V20, P24
   Hirche J, 2004, PROC GRAPH INTERF, P153
   Hormann K., 2007, ACM SIGGRAPH COURSE
   Jin M, 2008, IEEE T VIS COMPUT GR, V14, P1030, DOI 10.1109/TVCG.2008.57
   Joshi AA, 2007, IEEE T MED IMAGING, V26, P1657, DOI 10.1109/TMI.2007.901432
   Kautz J., 2001, HWWS'01: Proceedings of the ACM SIGGRAPH/EUROGRAPHICS Workshop on Graphics Hardware, (New York, NY, USA), P109
   Kautz Jan., 2001, GRIN'01, P61
   Krishnamurthy V., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P313, DOI 10.1145/237170.237270
   Levy B., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P343, DOI 10.1145/280814.280930
   Lévy B, 2002, ACM T GRAPHIC, V21, P362, DOI 10.1145/566570.566590
   Lipman Y., 2009, ARXIV09123488
   Litke Nathan, 2005, Symposium on Geometry Processing, P207
   Max N. L., 1988, Visual Computer, V4, P109, DOI 10.1007/BF01905562
   Mérigot Q, 2011, COMPUT GRAPH FORUM, V30, P1583, DOI 10.1111/j.1467-8659.2011.02032.x
   Meyer A., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P157
   Niessner M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487234
   Pharr M., 1996, Rendering Techniques '96. Proceedings of the Eurographics Workshop. Eurographics, P31
   Rehman TU, 2009, MED IMAGE ANAL, V13, P931, DOI 10.1016/j.media.2008.10.008
   Sander PV, 2001, COMP GRAPH, P409, DOI 10.1145/383259.383307
   Shi R, 2013, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2013.327
   Su KH, 2017, COMPUT AIDED DESIGN, V82, P42, DOI 10.1016/j.cad.2016.05.020
   Su KH, 2016, COMPUT AIDED GEOM D, V46, P76, DOI 10.1016/j.cagd.2016.05.005
   Su KH, 2016, COMPUT AIDED DESIGN, V78, P188, DOI 10.1016/j.cad.2016.04.007
   Su ZY, 2014, ENG COMPUT-GERMANY, V30, P475, DOI 10.1007/s00366-014-0354-1
   Szirmay-Kalos L, 2008, COMPUT GRAPH FORUM, V27, P1567, DOI 10.1111/j.1467-8659.2007.01108.x
   Wang LF, 2003, ACM T GRAPHIC, V22, P334, DOI 10.1145/882262.882272
   Wang Y, 2008, INT J COMPUT VISION, V76, P283, DOI 10.1007/s11263-007-0063-y
   Xianfeng Gu, 2003, Symposium on Geometry Processing, P127
   Zhao X, 2013, IEEE T VIS COMPUT GR, V19, P2838, DOI 10.1109/TVCG.2013.135
   Zhu L, 2003, LECT NOTES COMPUT SC, V2879, P277
NR 54
TC 1
Z9 2
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31969
EP 31989
DI 10.1007/s11042-018-6207-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000021
DA 2024-07-18
ER

PT J
AU Vishwakarma, A
   Bhuyan, MK
   Iwahori, Y
AF Vishwakarma, Amit
   Bhuyan, M. K.
   Iwahori, Yuji
TI Non-subsampled shearlet transform-based image fusion using modified
   weighted saliency and local difference
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; NSST; Canny edge detector; Local difference; Weighted
   salience
ID CONTOURLET TRANSFORM; WAVELET; FRAMEWORK; SCALE; REGISTRATION
AB Existing image fusion methods can not efficiently capture significant edges, texture and fine details of the source images due to inefficient fusion framework. In addition, for objective evaluation of fusion algorithms, not much attention is given to simultaneously measure both texture and structural information of the source images which are preserved in the fused image. To address these issues, non-subsampled shearlet transform (NSST) is used to decompose pre-registered source images into low- and high-frequency components. These low- and high-frequency coefficients are fused by using our proposed modified weighted salience and local difference fusion rules, respectively. To enrich edge information in the fused image, Canny edge detector with scale multiplication is employed. Moreover, a metric Q(TS) is proposed to jointly measure both texture and structural information present in the fused image. The proposed metric is formulated on the basis of local standard deviation filtering, local information entropy, and local difference filtering. Both subjective and objective results validate the proposed fusion framework and the metric Q(TS).
C1 [Vishwakarma, Amit; Bhuyan, M. K.] Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
   [Iwahori, Yuji] Chubu Univ, Dept Comp Sci, Kasugai, Aichi 4878501, Japan.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati; Chubu University
RP Bhuyan, MK (corresponding author), Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
EM a.vishwakarma@iitg.ac.in; mkb@iitg.ac.in; iwahori@cs.chubu.ac.jp
RI Iwahori, Yuji/AAH-4257-2020; Vishwakarma, Amit/ABE-7268-2020
OI Iwahori, Yuji/0000-0002-6421-8186; Vishwakarma, Amit/0000-0002-0591-8940
CR Aishwarya N, 2017, MULTIMED TOOLS APPL, V76, P21869, DOI 10.1007/s11042-017-4583-3
   Bao P, 2005, IEEE T PATTERN ANAL, V27, P1485, DOI 10.1109/TPAMI.2005.173
   Bavirisetti DP, 2016, IEEE SENS J, V16, P203, DOI 10.1109/JSEN.2015.2478655
   Bhateja V, 2015, IEEE SENS J, V15, P6783, DOI 10.1109/JSEN.2015.2465935
   Bhatnagar G, 2013, IEEE T MULTIMEDIA, V15, P1014, DOI 10.1109/TMM.2013.2244870
   Burt P. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P173, DOI 10.1109/ICCV.1993.378222
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Cao L, 2015, IEEE SIGNAL PROC LET, V22, P220, DOI 10.1109/LSP.2014.2354534
   Choi M., 2004, ISPRS J. Photogramm. Remote Sens., V35, P59
   COLLIGNON A, 1995, COMP IMAG VIS, V3, P263
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Feng FB, 2017, MULTIMED TOOLS APPL, V76, P22959, DOI 10.1007/s11042-016-4183-7
   Geng P, 2016, MULTIMED TOOLS APPL, V75, P10583, DOI 10.1007/s11042-014-1942-1
   Huang R, 2008, LINEAR ALGEBRA APPL, V428, P1551, DOI 10.1016/j.laa.2007.10.001
   Ji XX, 2017, MULTIMED TOOLS APPL, V76, P17633, DOI 10.1007/s11042-015-2879-8
   Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855
   Kanmani M, 2017, MULTIMED TOOLS APPL, V76, P20989, DOI 10.1007/s11042-016-4030-x
   Kong WW, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.1.017001
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li ST, 2002, PATTERN RECOGN LETT, V23, P985, DOI 10.1016/S0167-8655(02)00029-6
   Lim WQ, 2010, IEEE T IMAGE PROCESS, V19, P1166, DOI 10.1109/TIP.2010.2041410
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Ma JY, 2017, INFORM SCIENCES, V417, P128, DOI 10.1016/j.ins.2017.07.010
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Ma JY, 2015, PATTERN RECOGN, V48, P772, DOI 10.1016/j.patcog.2014.09.005
   Miao QG, 2011, OPT COMMUN, V284, P1540, DOI 10.1016/j.optcom.2010.11.048
   Mital M. E. G., 2017, 2017 IEEE INT C IM V, P1
   Mitianoudis N, 2008, IEEE SENS J, V8, P2016, DOI 10.1109/JSEN.2008.2007678
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Petrovic VS, 2004, IEEE T IMAGE PROCESS, V13, P228, DOI 10.1109/tip.2004.823821
   Prabhakar S, 2002, PATTERN RECOGN, V35, P861, DOI 10.1016/S0031-3203(01)00103-0
   Summers D, 2003, J NEUROL NEUROSUR PS, V74, P288, DOI 10.1136/jnnp.74.3.288
   Tang WJ, 2017, MULTIMED TOOLS APPL, V76, P22725, DOI 10.1007/s11042-017-4343-4
   Wang RS, 2007, INT EL DEVICES MEET, P821
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang C, 2008, INFORM FUSION, V9, P156, DOI 10.1016/j.inffus.2006.09.001
   Yang Y, 2016, IEEE SENS J, V16, P3735, DOI 10.1109/JSEN.2016.2533864
   Yin M, 2014, OPTIK, V125, P2274, DOI 10.1016/j.ijleo.2013.10.064
   Zhang XL, 2017, MULTIMED TOOLS APPL, V76, P8175, DOI 10.1007/s11042-016-3453-8
   Zhao SH, 2003, RAST 2003: RECENT ADVANCES IN SPACE TECHNOLOGIES, PROCEEDINGS, P91
NR 44
TC 11
Z9 12
U1 6
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 32013
EP 32040
DI 10.1007/s11042-018-6254-4
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000023
DA 2024-07-18
ER

PT J
AU Wang, CM
   He, C
AF Wang, Chunmeng
   He, Chen
TI A novel deghosting method for exposure fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compression; HDR; Deghosting; Exposure fusion; Photometric relation
ID GHOST REMOVAL
AB A novel ghost-free exposure fusion method for generating an HDR image of a dynamic scene is presented in this paper. Given a sequence of input images with gradually increased exposures, due to the theory that the luminance is linearly depended on the exposure time (Mertens et al. Comput Graph Forum 28(1):161-171, 2009), each input image is normalized to make it have consistent luminance with a reference image. Then moving objects in the dynamic scene are detected using a modified difference method for further exposure fusion. Experiments and comparisons show that our method has advantage in deghosting when the reference image contains saturated regions and generate high-quality results with natural textures. Furthermore, our method has a largely improved timing performance compared with previous reference-guided methods.
C1 [Wang, Chunmeng] Jinling Inst Technol, Sch Comp Engn, Nanjing 211169, Jiangsu, Peoples R China.
   [He, Chen] Weifang Univ, Coll Comp Engn, Weifang 261061, Shandong, Peoples R China.
C3 Jinling Institute of Technology; Weifang University
RP Wang, CM (corresponding author), Jinling Inst Technol, Sch Comp Engn, Nanjing 211169, Jiangsu, Peoples R China.
EM wchm87@jit.edu.cn
RI Chen, Xupeng/KFA-5959-2024; He, Chen/JLM-5059-2023
FU Project of High-level Talents Research Foundation of Jinling Institute
   of Technology [jit-b-201802]; Project of Shandong Province Higher
   Educational Science and Technology Program [J17 KB184]
FX This work is supported by the Project of High-level Talents Research
   Foundation of Jinling Institute of Technology (jit-b-201802) and the
   Project of Shandong Province Higher Educational Science and Technology
   Program under grant (No.J17 KB184).
CR [Anonymous], 2005, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting (The Morgan Kaufmann Series in Computer Graphics
   [Anonymous], COMPUTER RES DEV
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2008, P GRAPHICS INTERFACE
   Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2
   Gallo O, 2015, CVPR WORKSH
   Gallo O., 2009, P IEEE INT C COMP PH
   Granados M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508410
   GROSCH T, 2006, VISION MODELING VISU, P277
   Hu J, 2012, LECT NOTES COMPUT SC, V7572, P499, DOI 10.1007/978-3-642-33718-5_36
   Hu J, 2013, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2013.154
   Jacobs K, 2008, IEEE COMPUT GRAPH, V28, P84, DOI 10.1109/MCG.2008.23
   Kalantari N. K., 2017, ACM Trans. Graph., V36, DOI DOI 10.1145/3072959.3073609
   Kang SB, 2003, ACM T GRAPHIC, V22, P319, DOI 10.1145/882262.882270
   Kanita KH, 2014, 2 INT C SME WORKSH H
   Karaduzovic-Hadziabdic K, 2017, COMPUT GRAPH-UK, V63, P1, DOI 10.1016/j.cag.2017.01.002
   Khan EA, 2006, IEEE IMAGE PROC, P2005, DOI 10.1109/ICIP.2006.312892
   Mertens T, 2009, COMPUT GRAPH FORUM, V28, P161, DOI 10.1111/j.1467-8659.2008.01171.x
   Min TH, 2009, IEEE INT CON MULTI, P530, DOI 10.1109/ICME.2009.5202550
   Pedone M, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P36
   Seetzen H, 2004, ACM T GRAPHIC, V23, P760, DOI 10.1145/1015706.1015797
   Sen P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366222
   Sidibe D, 2009, GHOST DETECTION REMO
   Srikantha A, 2012, SIGNAL PROCESS-IMAGE, V27, P650, DOI 10.1016/j.image.2012.02.001
   Tocci Michael D., 2011, SIGGRAPH
   Tursun OT, 2016, COMPUT GRAPH FORUM, V35, P139, DOI 10.1111/cgf.12818
   Tursun OT, 2015, COMPUT GRAPH FORUM, V34, P683, DOI 10.1111/cgf.12593
   Zhang W, 2012, J VIS COMMUN IMAGE R, V23, P467, DOI 10.1016/j.jvcir.2012.01.006
   Zhang W, 2010, PROC CVPR IEEE, P530, DOI 10.1109/CVPR.2010.5540168
   Zimmer H, 2011, COMPUT GRAPH FORUM, V30, P405, DOI 10.1111/j.1467-8659.2011.01870.x
NR 30
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31911
EP 31928
DI 10.1007/s11042-018-6261-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000018
DA 2024-07-18
ER

PT J
AU Jin, X
   Su, YT
   Zou, L
   Zhang, CQ
   Jing, PG
   Song, XM
AF Jin, Xiao
   Su, Yuting
   Zou, Liang
   Zhang, Chengqian
   Jing, Peiguang
   Song, Xuemeng
TI Video logo removal detection based on sparse representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video forensics; Video inpainting detection; Sparse representation; Logo
   removal operation
ID FORGERY
AB With the popularity of multimedia editing tools, more and more forged multimedia content appeared on the network. Thus, the legal authorities need novel techniques to distinguish copyright infringements from a large number of videos on the Internet. Since logo removal is a common editing operation during unauthorized reproduction, logo removal detection is often equivalent to copyright infringements detection to some extent. In this paper, we proposed a video forensics framework for logo removal detection. Our framework mainly contains two stages: the removal traces detection and the removal region location. In the first stage, we use sparse representation to show the difference between the tampered areas and the original areas in sparsity. In the second stage, spatial priors and temporal correlations are used to refine the location of the removal regions. Finally, a spatio-temporal suspected region can obviously show the edited regions. The proposed method is validated on our video logo removal dataset by extensive experiments, showing promising results.
C1 [Jin, Xiao; Su, Yuting; Jing, Peiguang] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
   [Jin, Xiao; Zou, Liang] Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC, Canada.
   [Zhang, Chengqian] Southwest Petr Univ, Sch Elect Engn & Informat, Chengdu, Sichuan, Peoples R China.
   [Song, Xuemeng] Shandong Univ, Sch Comp Sci & Technol, Jinan, Shandong, Peoples R China.
C3 Tianjin University; University of British Columbia; Southwest Petroleum
   University; Shandong University
RP Su, YT (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM ytsu@tju.edu.cn
RI zou, liang/AAX-4969-2021
OI zou, liang/0000-0001-7322-5735
FU National Natural Science Foundation of China [61572356, 61303208];
   Tianjin Research Program of Application Foundation and Advanced
   Technology [15JCQNJC41600]; China Scholarship Council [201706250187]
FX This work was supported in part by the National Natural Science
   Foundation of China (61572356 and 61303208) and the Tianjin Research
   Program of Application Foundation and Advanced Technology
   (15JCQNJC41600) and a grant from the China Scholarship Council
   (201706250187).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Akbari M, 2016, AAAI CONF ARTIF INTE, P87
   [Anonymous], 2014, P 16 INT C MULT INT
   [Anonymous], 2006, P 8 WORKSHOP MULTIME, DOI DOI 10.1145/1161366.1161375
   Bestagini P, 2013, IEEE IMAGE PROC, P4457, DOI 10.1109/ICIP.2013.6738918
   Bestagini P, 2013, IEEE INT WORKSH MULT, P488, DOI 10.1109/MMSP.2013.6659337
   Chen J, 2013, P ACM INT C MULT, P493
   Chen SD, 2016, IEEE T CIRC SYST VID, V26, P2138, DOI 10.1109/TCSVT.2015.2473436
   Costa FO, 2015, IEEE IMAGE PROC, P301, DOI 10.1109/ICIP.2015.7350808
   COSTA FDO, 2016, P IEEE NPSS REAL TIM, P1
   DAvino D., 2017, Media Watermarking, Security, and Forensics 2017, Burlingame, CA, USA, 29 January 2017-2 February 2017, V29, P92
   Dias Z., 2011, IEEE INT WORKSH INF, P1
   Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P1, DOI 10.1007/978-1-4419-7011-4
   Feng C, 2014, P 2 ACM WORKSH INF H, P171, DOI DOI 10.1145/2600918.2600923
   Feng FL, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P455, DOI 10.1145/3077136.3080773
   Gironi A., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6226, DOI 10.1109/ICASSP.2014.6854801
   Han YH, 2015, IEEE T NEUR NET LEAR, V26, P252, DOI 10.1109/TNNLS.2014.2314123
   Han YH, 2014, IEEE T MULTIMEDIA, V16, P1665, DOI 10.1109/TMM.2014.2321530
   Han YH, 2014, IEEE T MULTIMEDIA, V16, P1115, DOI 10.1109/TMM.2014.2306092
   Han YH, 2012, IEEE T CIRC SYST VID, V22, P1485, DOI 10.1109/TCSVT.2012.2202075
   He PS, 2017, NEUROCOMPUTING, V228, P84, DOI 10.1016/j.neucom.2016.09.084
   He PS, 2016, J VIS COMMUN IMAGE R, V35, P55, DOI 10.1016/j.jvcir.2015.11.014
   Hsu CC, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P170, DOI 10.1109/MMSP.2008.4665069
   Jiang YG, 2014, LECT NOTES COMPUT SC, V8692, P357, DOI 10.1007/978-3-319-10593-2_24
   Jing PG, 2017, IEEE T MULTIMEDIA, V19, P1050, DOI 10.1109/TMM.2016.2644866
   Kobayashi M, 2010, IEEE T INF FOREN SEC, V5, P883, DOI 10.1109/TIFS.2010.2074194
   Labartino D, 2013, IEEE INT WORKSH MULT, P494, DOI 10.1109/MMSP.2013.6659338
   Lee JW, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P49
   Lin CS, 2014, DIGIT INVEST, V11, P120, DOI 10.1016/j.diin.2014.03.016
   Lin Huijie, 2016, P 25 INT JOINT C ART, P3775
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Mondaini N, 2007, PROC SPIE, V6505, DOI 10.1117/12.704924
   Nie LQ, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2963105
   Nie LQ, 2016, IEEE T CYBERNETICS, V46, P2991, DOI 10.1109/TCYB.2015.2493558
   Song XM, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2832907
   Sun TF, 2012, INT CONF ACOUST SPEE, P1389, DOI 10.1109/ICASSP.2012.6288150
   Visentini-Scarzanella M, 2013, IEEE INT WORKSH MULT, P412, DOI 10.1109/MMSP.2013.6659324
   Wang JQ, 2007, LECT NOTES COMPUT SC, V4352, P63
   Wang WH, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P39
   Wang WH, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P35
   Wang XY, 2015, IEEE T MULTIMEDIA, V17, P409, DOI 10.1109/TMM.2014.2385473
   Yan WQ, 2005, MULTIMEDIA SYST, V10, P379, DOI 10.1007/s00530-005-0167-6
   Yuxing Wu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2674, DOI 10.1109/ICASSP.2014.6854085
   Zhang DX, 2017, ACM T INFORM SYST, V35, DOI 10.1145/3052771
   Zhang J, 2009, 2009 INTERNATIONAL CONFERENCE ON INDUSTRIAL MECHATRONICS AND AUTOMATION, P32, DOI 10.1109/ICIMA.2009.5156553
   Zhu L., 2016, IJCAI, P3959
NR 46
TC 6
Z9 7
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29303
EP 29322
DI 10.1007/s11042-018-5959-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800007
DA 2024-07-18
ER

PT J
AU Sallam, AI
   El-Rabaie, ESM
   Faragallah, OS
AF Sallam, Ahmed, I
   El-Rabaie, El-Sayed M.
   Faragallah, Osama S.
TI CABAC-based selective encryption for HEVC using RC6 in different
   operation modes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Discrete cosine transform (DCT); Motionvector difference(MVD);
   CABAC; RC6 block cipher; PSNR
ID VIDEO; PROTECTION; TRANSFORM
AB This paper proposes a selective encryption (SE) algorithm for the almost recently video compressing technique that is called High-Efficiency Video Coding (HEVC). The improvement of our HEVC SE algorithm is to secure real-time HEVC streaming using low computational overhead, same bit rate and ensuring the video format compliance. This contribution is achieved with low computational RC6 algorithm to encrypt subset of binstrings that is binarized using the bypass binary arithmetic coding mode in the context adaptive binary arithmetic coding (CABAC) process of HEVC. This binstrings subset is the non-zero discrete cosine transform (DCT) coefficients sign bits, motion vector difference (MVD) sign bits, remaining absolute values suffix of DCT, MVD absolute values suffix, Sample adaptive offset (SAO) sign bit, residual size, reference picture index and the delta Quantization Parameter (QP). Also, this paper investigates the performance evaluation of using the RC6 with its operation modes within the proposed HEVC CABAC SE. This investigation is done for choosing the best operation mode for RC6 to be suitable for being used in the HEVC real-time application. The security analysis like histogram analysis, correlation coefficients test and key sensitivity test are presented to make sure the protection of HEVC CABAC SE algorithm against brute force and statistical attacks. The performance analysis results prove that the HEVC CABAC SE is highly secure and can be used in real-time HEVC applications.
C1 [Sallam, Ahmed, I; Faragallah, Osama S.] Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia 32952, Egypt.
   [El-Rabaie, El-Sayed M.] Menoufia Univ, Fac Elect Engn, Dept Elect & Commun Engn, Menoufia 32952, Egypt.
   [Faragallah, Osama S.] Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, POB 888, Al Hawiya 21974, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Menofia University; Taif University
RP Faragallah, OS (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia 32952, Egypt.; Faragallah, OS (corresponding author), Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, POB 888, Al Hawiya 21974, Saudi Arabia.
EM a_sallam82@hotmail.com; srabiel@yahoo.com; osam_sal@yahoo.com
RI Faragallah, Osama S./AHB-8031-2022
OI Faragallah, Osama S./0000-0003-1982-335X; EL-Rabaie,
   El-Sayed/0000-0001-6854-5881
CR Abdallah EE, 2007, LECT NOTES COMPUTER, V4633
   Ahmad J., 2012, International Journal of Video and Image Processing and Network Security, V12, P18
   Ahmed HEDH, 2007, INFORM-J COMPUT INFO, V31, P121
   Avneetkaur Lakhwinderkaur, 2012, P INT J COMPUT APPL, V59, P32
   Bjontegaard G., 2001, SG16Q6 ITUT
   Bross B, 2012, 10 M STOCKH
   Chen XF, 2015, IEEE T INF FOREN SEC, V10, P69, DOI 10.1109/TIFS.2014.2363765
   Elsheh E, 2011, EXPERT SYST APPL, V38, P13906, DOI 10.1016/j.eswa.2011.04.197
   Fraunhofer Heinrich Hertz Institute, 2015, HIGH EFF VID COD HEV
   Hofbauer Heinz, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1986, DOI 10.1109/ICASSP.2014.6853946
   Huang ZA, 2017, INFORM SCIENCES, V412, P223, DOI 10.1016/j.ins.2017.05.031
   Jolfaei Alireza, 2010, International Journal of Computer and Network Security, V2, P38
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Li J, 2015, IEEE T COMPUT, V64, P425, DOI 10.1109/TC.2013.208
   Li J, 2014, IEEE T PARALL DISTR, V25, P2201, DOI 10.1109/TPDS.2013.271
   Liu FW, 2010, COMPUT SECUR, V29, P3, DOI 10.1016/j.cose.2009.06.004
   MSU Graphics and Media Lab Video Group, 2016, MSU COD
   Rivest R, 1998, RC6 BLOCK CIPHER SIM
   Shahid Z, 2014, IEEE T MULTIMEDIA, V16, P24, DOI 10.1109/TMM.2013.2281029
   Tew Y, 2015, ASIAPAC SIGN INFO PR, P963, DOI 10.1109/APSIPA.2015.7415415
   Tew Y, 2014, IEEE T CIRC SYST VID, V24, P305, DOI 10.1109/TCSVT.2013.2276710
   Van Wallendael G, 2013, IEEE T CONSUM ELECTR, V59, P634, DOI 10.1109/TCE.2013.6626250
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
NR 23
TC 17
Z9 18
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28395
EP 28416
DI 10.1007/s11042-018-5994-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500027
DA 2024-07-18
ER

PT J
AU Sun, LY
   Zhou, YZ
   Hansen, P
   Geng, WD
   Li, XD
AF Sun, Lingyun
   Zhou, Yunzhan
   Hansen, Preben
   Geng, Weidong
   Li, Xiangdong
TI Cross-objects user interfaces for video interaction in virtual reality
   museum context
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-objects user interfaces; Video interaction; Virtual reality
   museum; Museum learning experience; Perceived usability
AB Museums are good places for learning and nowadays many museums are integrating digital media such as video and increasingly moving towards using virtual reality. In the physical world people used to seek information from object surfaces e.g. posters on the wall and this has been used as a metaphor in the virtual reality museum: numerous videos were inhabited within virtual objects and shaped cross-objects user interfaces (COUIs). However, how such interfaces perform for video interactions still needs more investigations. In this study we implemented and investigated COUIs in comparison with the conventional card-style user interfaces and the plain virtual reality user interfaces in the virtual reality museum. The results reported no significant differences in the perceived usability or learning experience between these user interfaces, except the COUIs had a lower level of satisfaction than the card-style user interfaces. However, the COUIs showed greater efficiency with shorter eye fixation durations and higher saccade frequencies, and within these COUIs instances, namely the fully-detached, semi-attached, and fully-attached COUIs, the fully-attached instance was closest to the form of interacting with physical object surfaces and it reported highest efficiency as well. Rationales behind these results and implications generalising for the future design of COUIs, are discussed.
C1 [Sun, Lingyun; Zhou, Yunzhan] Zhejiang Univ, Int Design Inst, Hangzhou, Zhejiang, Peoples R China.
   [Zhou, Yunzhan; Li, Xiangdong] Alibaba Zhejiang Univ Joint Inst Frontier Technol, Hangzhou, Zhejiang, Peoples R China.
   [Hansen, Preben] Stockholm Univ, Dept Comp Sci & Syst, Kista, Sweden.
   [Geng, Weidong; Li, Xiangdong] Zhejiang Univ, Dept Digital Media, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University; Stockholm University; Zhejiang University
RP Li, XD (corresponding author), Alibaba Zhejiang Univ Joint Inst Frontier Technol, Hangzhou, Zhejiang, Peoples R China.; Li, XD (corresponding author), Zhejiang Univ, Dept Digital Media, Hangzhou, Zhejiang, Peoples R China.
EM sunly@zju.edu.cn; zyzbilly@zju.edu.cn; preben@dsv.su.se;
   gengwd@zju.edu.cn; axli@zju.edu.cn
RI Yang, Li/JMP-4403-2023
FU National Key RD program [2016YFB1001304]
FX The authors thank the reviewers for their helpful comments. The research
   is supported by the funding of "National Key R&D program"
   (2016YFB1001304).
CR Alexandri E., 2014, World Transactions on Engineering and Technology Education, V12, P317
   [Anonymous], TECHNOLOGY GUIDE
   [Anonymous], 2014, ARXIV14081173
   Baraldi L, 2015, IEEE SENS J, V15, P2705, DOI 10.1109/JSEN.2015.2411994
   Barbieri L, 2017, INT J INTERACTIVE DE
   Beer S., 2015, P 2015 VIRT REAL INT, P1
   Branch P., 1999, 1999 IEEE International Conference on Communications (Cat. No. 99CH36311), P978, DOI 10.1109/ICC.1999.765419
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Carrozzino M, 2010, J CULT HERIT, V11, P452, DOI 10.1016/j.culher.2010.04.001
   Chang C-M, 2013, SIGGRAPH AS 2013 POS
   Ciolfi L., 2015, P 7 INT C COMM TECHN, P149
   Clini P, 2014, ADV MULTIMED, V2014, DOI 10.1155/2014/597476
   Cuendet S, 2015, INT J COMP-SUPP COLL, V10, P183, DOI 10.1007/s11412-015-9213-3
   Davis MM, 2016, P IEEE VIRT REAL ANN, P169, DOI 10.1109/VR.2016.7504707
   Deuschel T, 2014, P EUR WORKSH GRAPH C, P97
   Diaz P, 2015, 2015 DIGITAL HERITAGE INTERNATIONAL CONGRESS, VOL 1: DIGITIZATION & ACQUISITION, COMPUTER GRAPHICS & INTERACTION, P345, DOI 10.1109/DigitalHeritage.2015.7413898
   Robles-Ortega MD, 2012, J CULT HERIT, V13, P326, DOI 10.1016/j.culher.2011.10.001
   Falk J.H., 2016, MUSEUM EXPERIENCE RE
   Fasel B, 2007, P 4 INT C AD MULT RE
   Fukkink RG, 2010, TEACH TEACH EDUC, V26, P1652, DOI 10.1016/j.tate.2010.06.016
   Ghinea G, 2008, COMPUT HUM BEHAV, V24, P1317, DOI 10.1016/j.chb.2007.07.013
   Hou H-T, 2014, J ED TECHNOLOGY SOC, V17
   Hsu CH, 2017, MULTIMED TOOLS APPL, V76, P9099, DOI 10.1007/s11042-016-3502-3
   Ishii H., 1997, P ACM SIGCHI C HUM F, P234, DOI DOI 10.1145/258549.258715
   Kim J, 2014, P CHI 2014 LEARN SC
   Kiourt C, 2016, J CULT HERIT, V22, P984, DOI 10.1016/j.culher.2016.06.007
   Koskenranta O, 2013, P 2013 ACM C PERV UB
   Lee J., 2016, Proceedings of the 29th Annual Symposium on User Interface Software and Technology, UIST'16 Adjunct, (New York, NY, USA), P207
   Luyten K., 2005, Multimedia, Seventh IEEE International Symposium on, P8
   McAllister G, 2015, HUM-COMPUT INT-SPRIN, P11, DOI 10.1007/978-3-319-15985-0_2
   Nguyen C, 2017, CHI 2017
   Pallavicini F, 2018, ADV INTELL SYST, V608, P225, DOI 10.1007/978-3-319-60639-2_23
   Papaefthymiou M., 2015, MOBILE VIRTUAL REALI
   Partarakis N., 2016, CEUR Workshop Proceedings, P5
   Proctor R., 1999, GROUP'99. Proceedings of the International ACM SIGGROUP Conference on Supporting Group Work, P160, DOI 10.1145/320297.320315
   Ragan ED, 2015, IEEE T VIS COMPUT GR, V21, P794, DOI 10.1109/TVCG.2015.2403312
   Rieh SY, 2016, J INF SCI, V42, P19, DOI 10.1177/0165551515615841
   Schaper M-M, 2017, P 2016 CHI C HUM FAC
   Seidel N, 2014, P 19 EUR C PATT LANG
   Sidorakis N, 2015, 2015 IEEE 1ST WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P15, DOI 10.1109/WEVR.2015.7151689
   Stawniak M, 2006, P 7 INT C VIRT REAL
   SU YC, 2016, EUR C COMP VIS, V9909, P454, DOI DOI 10.1007/978-3-319-46454-1_28
   Sylaiou S., 2008, Computers in Entertainment, V6, P1, DOI DOI 10.1145/1371216.1371226
   Sylaiou S, 2009, J CULT HERIT, V10, P520, DOI 10.1016/j.culher.2009.03.003
   Toril P, 2014, PSYCHOL AGING, V29, P706, DOI 10.1037/a0037507
   van der Meij H, 2017, COMPUT EDUC, V114, P164, DOI 10.1016/j.compedu.2017.07.002
   Wang Ruguang., 2014, Advanced Materials Research, Vols, V926-930, P2516
   WEISER M, 1993, COMMUN ACM, V36, P75, DOI 10.1145/159544.159617
   Wibirama S, 2017, ENTERTAIN COMPUT, V21, P11, DOI 10.1016/j.entcom.2017.04.003
   Wisneski C.A., 1999, DESIGN PERSONAL AMBI
   Wyman SM, 2016, J LEARNING ARTS, V12, pn1
   Yoo ByungIn., 2010, CHI EXTENDED ABSTRAC, P3709
   Yoshimura Y, 2014, ENVIRON PLANN B, V41, P1113, DOI 10.1068/b130047p
   Zhang T, 2015, MOBICOM '15: PROCEEDINGS OF THE 21ST ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P426, DOI 10.1145/2789168.2790123
NR 54
TC 12
Z9 12
U1 3
U2 64
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 29013
EP 29041
DI 10.1007/s11042-018-6091-5
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500052
DA 2024-07-18
ER

PT J
AU Zhu, SQ
   Zhu, CX
AF Zhu, Shuqin
   Zhu, Congxu
TI Image encryption algorithm with an avalanche effect based on a
   six-dimensional discrete chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Six dimensional discrete chaotic system; Pseudo random
   number generator; Avalanche effect; SHA-256; Chosen-plaintext attack
ID GENERATOR; ATTRACTOR
AB This paper introduces a six-dimensional discrete chaotic systems (SDDCS) with some simple sine functions and a chaotic pseudorandom number generator (CPRNG) that is designed based on the SDDCS. A encryption scheme with both key avalanche effect and plaintext avalanche effect (SESKPAE) is proposed by using the random sequence generated by the CPRNG. The algorithm has three advantages: First, the initial values of the chaotic system are calculated by using the SHA-256 hash value of the plain image and the given values, there are different initial values for different plain images. Thus, our algorithm can resist against the chosen-plaintext and known-plaintext attacks effectively. Second, the new algorithm adopts ciphertext feedback mechanism to further strengthen the safety. Third, our new algorithm has an "avalanche effect", in other words, the decrypted ciphertext will become a "white" image with a few "black spots" rather than a random chaotic image as a result of the wrong key. The experimental results and security analysis show that the algorithm has the advantages of large key space, no obvious statistical characteristics of ciphertext, sensitive to plaintext and keys, and able to resist chosen-plaintext attack and active attacks.
C1 [Zhu, Shuqin] Liaocheng Univ, Sch Comp Sci, Liaocheng 252059, Peoples R China.
   [Zhu, Congxu] Cent S Univ, Sch Informat Sci & Engn, Changsha 410083, Hunan, Peoples R China.
   [Zhu, Congxu] Yulin Normal Univ, Guangxi Coll & Univ Key Lab Complex Syst Optimiza, Yulin 537000, Peoples R China.
C3 Liaocheng University; Central South University; Yulin Normal University
RP Zhu, CX (corresponding author), Cent S Univ, Sch Informat Sci & Engn, Changsha 410083, Hunan, Peoples R China.; Zhu, CX (corresponding author), Yulin Normal Univ, Guangxi Coll & Univ Key Lab Complex Syst Optimiza, Yulin 537000, Peoples R China.
EM shuqinzhu2008@163.com; zhucx@csu.edu.cn
FU National Natural Science Foundation of China [61472451]; Open Project of
   Guangxi Colleges and Universities Key Laboratory of Complex System
   Optimization and Big Data Processing [2016CSOBDP0103]; Shan Dong
   Province Nature Science Foundation [ZR2017MEM019]; Science Research Fund
   of Liaocheng University [318011606]
FX This work was supported by National Natural Science Foundation of China
   (No. 61472451), the Open Project of Guangxi Colleges and Universities
   Key Laboratory of Complex System Optimization and Big Data Processing
   (No. 2016CSOBDP0103), the Shan Dong Province Nature Science Foundation
   (Grant. ZR2017MEM019) and the Science Research Fund of Liaocheng
   University (No. 318011606).
CR Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   [Anonymous], 2003, CITESEER
   Chen E, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S0218127417500468
   Chen XF, 2015, IEEE T INF FOREN SEC, V10, P69, DOI 10.1109/TIFS.2014.2363765
   FEISTEL H, 1973, SCI AM, V228, P15, DOI 10.1038/scientificamerican0573-15
   Hamza R, 2017, J INF SECUR APPL, V35, P119, DOI 10.1016/j.jisa.2017.06.005
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Huang ZA, 2017, INFORM SCIENCES, V412, P223, DOI 10.1016/j.ins.2017.05.031
   Jain A, 2016, MULTIMED TOOLS APPL, V75, P5455, DOI 10.1007/s11042-015-2515-7
   Lai Q, 2016, OPTIK, V127, P3000, DOI 10.1016/j.ijleo.2015.12.089
   Lambic D, 2017, NONLINEAR DYNAM, V89, P2255, DOI 10.1007/s11071-017-3583-1
   Li J, 2015, IEEE T PARALL DISTR, V26, P1206, DOI 10.1109/TPDS.2014.2318320
   Li J, 2015, IEEE T COMPUT, V64, P425, DOI 10.1109/TC.2013.208
   Li J, 2014, IEEE T PARALL DISTR, V25, P2201, DOI 10.1109/TPDS.2013.271
   Li P, 2017, FUTURE GENER COMP SY, V74, P76, DOI 10.1016/j.future.2017.02.006
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu Q, 2017, COMPUT ELECTR ENG, V59, P153, DOI 10.1016/j.compeleceng.2016.10.005
   Liu Y, 2014, OPT LASER ENG, V60, P1
   Min LQ, 2013, EUR PHYS J B, V86, DOI 10.1140/epjb/e2013-40199-7
   Murillo-Escobar MA, 2017, NONLINEAR DYNAM, V87, P407, DOI 10.1007/s11071-016-3051-3
   Pang SQ, 2011, J COMPUT APPL MATH, V235, P2775, DOI 10.1016/j.cam.2010.11.029
   Qi GY, 2008, CHAOS SOLITON FRACT, V38, P705, DOI 10.1016/j.chaos.2007.01.029
   Rukhin R, 2001, NIST SPECIAL PUBLICA
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Spillman Richard., 2005, CLASSICAL CONT CRYPT
   Sprott JC, 2013, INT J BIFURCAT CHAOS, V23, DOI 10.1142/S0218127413500934
   Sun KH, 2012, NONLINEAR DYNAM, V69, P1383, DOI 10.1007/s11071-012-0354-x
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wu XL, 2017, IEEE ACCESS, V5, P6429, DOI 10.1109/ACCESS.2017.2692043
   Wu Y, 2016, IEEE T CYBERNETICS, V46, P2622, DOI 10.1109/TCYB.2015.2483621
   Yang XP, 2015, CHAOS, V25, DOI 10.1063/1.4917380
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yu S, 2015, IEEE NETWORK, V29, P83, DOI 10.1109/MNET.2015.7340429
   Zarei A, 2015, NONLINEAR DYNAM, V81, P585, DOI 10.1007/s11071-015-2013-5
   Zhang XP, 2014, NONLINEAR DYNAM, V78, P359, DOI 10.1007/s11071-014-1445-7
   Zhang XP, 2014, SIGNAL PROCESS-IMAGE, V29, P902, DOI 10.1016/j.image.2014.06.012
   Zhu CX, 2012, ACTA PHYS SIN-CH ED, V61, DOI 10.7498/aps.61.120503
   Zhu CX, 2018, IEEE ACCESS, V6, P18759, DOI 10.1109/ACCESS.2018.2817600
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
NR 41
TC 30
Z9 30
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 29119
EP 29142
DI 10.1007/s11042-018-6078-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500057
DA 2024-07-18
ER

PT J
AU Makbol, NM
   Khoo, BE
   Rassem, TH
AF Makbol, Nasrin M.
   Khoo, Bee Ee
   Rassem, Taha H.
TI Security analyses of false positive problem for the SVD-based hybrid
   digital image watermarking techniques in the wavelet transform domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Singular value decomposition; Wavelet transform;
   False positive problem; Copyright protection
ID SINGULAR-VALUE DECOMPOSITION; DIFFERENTIAL EVOLUTION; SCHEME; ROBUST;
   ALGORITHM; OWNERSHIP; SYSTEM
AB Singular Value Decomposition (SVD) comprises many important mathematical properties that are useful in numerous applications. Newly developed SVD-based watermarking schemes can effectively maintain minor changes despite the large altered singular values S caused by the attacks. Due to the stability and the properties of S, most of the researchers prefer to embed into S. However, despite satisfying the stability and robustness criteria, SVD-based image watermarking can still encounter false positive problems (FPP). Avoiding FPPs is one of the popular research topics in the field of SVD-based image watermarking. Satisfying robustness and imperceptibility requirements, as well as preventing FPPs, in SVD-based image watermarking is crucial in applications such as copyright protection and authentication. In this paper, false positive problem is studied, analysed and presented in detail. Different schemes are studied and classified based on the probability of exposure to false positive problem. All types of SVD-based embedding algorithms that leads to false positive problem and the related potential attacks has been evaluated using the reliability test as well as all solutions to false positive problem are reviewed. To understand how the attacks can threaten the rightful ownership and how to avoid these attacks, the three potential attacks of false positive problem has been demonstrated using recent proposed watermarking schemes. The main perspective of this paper is to gather all the issues belong to the false positive problem with SVD-based schemes.
C1 [Makbol, Nasrin M.; Khoo, Bee Ee] Univ Sains Malaysia, Sch Elect & Elect Engn, Engn Campus, Nibong Tebal 14300, Penang, Malaysia.
   [Rassem, Taha H.] UMP, Fac Comp Syst & Software Engn, Gambang 26300, Kuantan, Malaysia.
C3 Universiti Sains Malaysia; Universiti Malaysia Pahang Al-Sultan Abdullah
   (UMPSA)
RP Khoo, BE (corresponding author), Univ Sains Malaysia, Sch Elect & Elect Engn, Engn Campus, Nibong Tebal 14300, Penang, Malaysia.
EM nasrin_makbol@usm.my; beekhoo@usm.my; tahahussein@ump.edu.my
RI Khoo, Bee Ee/D-8730-2011; Rassem, Taha/L-8250-2016
OI Khoo, Bee Ee/0000-0002-3492-2551; Rassem, Taha/0000-0001-6259-0622
FU Universiti Sains Malaysia, Malaysia
FX The first-named author is grateful to Universiti Sains Malaysia,
   Malaysia for providing postdoctoral fellowship.
CR Ali M, 2015, INFORM SCIENCES, V301, P44, DOI 10.1016/j.ins.2014.12.042
   Ali M, 2014, ENG APPL ARTIF INTEL, V31, P15, DOI 10.1016/j.engappai.2013.07.009
   Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   Ali M, 2014, SIGNAL PROCESS, V94, P545, DOI 10.1016/j.sigpro.2013.07.024
   [Anonymous], 2008, ARXIV PREPRINT ARXIV
   Ansari IA, 2016, ENG APPL ARTIF INTEL, V49, P114, DOI 10.1016/j.engappai.2015.12.004
   Ansari IA, 2017, PATTERN RECOGN LETT, V94, P228, DOI 10.1016/j.patrec.2016.12.010
   Aslantas V, 2009, OPT COMMUN, V282, P769, DOI 10.1016/j.optcom.2008.11.024
   Bianchi T, 2013, IEEE SIGNAL PROC MAG, V30, P87, DOI 10.1109/MSP.2012.2228342
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chung KL, 2007, APPL MATH COMPUT, V188, P54, DOI 10.1016/j.amc.2006.09.117
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Fan MQ, 2008, APPL MATH COMPUT, V203, P926, DOI 10.1016/j.amc.2008.05.003
   Ganic E, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2137650
   Guo JM, 2014, AEU-INT J ELECTRON C, V68, P816, DOI 10.1016/j.aeue.2014.03.008
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Gupta AK, 2012, SADHANA-ACAD P ENG S, V37, P425, DOI 10.1007/s12046-012-0089-x
   Lagzian S., 2011, 2011 International Symposium on Artificial Intelligence and Signal Processing (AISP), P48, DOI 10.1109/AISP.2011.5960985
   Lagzian S., 2011, International Journal of Intelligent Information Processing, V2, P22, DOI DOI 10.4156/IJIIP
   Lai CC, 2011, DIGIT SIGNAL PROCESS, V21, P522, DOI 10.1016/j.dsp.2011.01.017
   Lai CC, 2011, OPT COMMUN, V284, P938, DOI 10.1016/j.optcom.2010.10.047
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Ling HC, 2011, AEU-INT J ELECTRON C, V65, P958, DOI 10.1016/j.aeue.2011.06.008
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Loukhaoukha K, 2014, OPTO-ELECTRON REV, V22, P45, DOI 10.2478/s11772-014-0177-z
   Loukhaoukha K., 2012, J INF HIDING MULTIME, V3, P135
   Loukhaoukha K., 2011, J Inf Hiding Multim Signal Process, V2, P303
   Loukhaoukha K, 2013, J OPTIM, V2013, DOI 10.1155/2013/921270
   Loukhaoukha K, 2010, LECT NOTES COMPUT SC, V6134, P394, DOI 10.1007/978-3-642-13681-8_46
   Loukhaoukha K, 2009, 2009 11TH CANADIAN WORKSHOP ON INFORMATION THEORY, P177, DOI 10.1109/CWIT.2009.5069549
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Makbol NM, 2014, DIGIT SIGNAL PROCESS, V33, P134, DOI 10.1016/j.dsp.2014.06.012
   Makbol NM, 2013, LECT NOTES COMPUT SC, V8237, P36, DOI 10.1007/978-3-319-02958-0_4
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Pandey P, 2014, MULTIMED TOOLS APPL, V72, P723, DOI 10.1007/s11042-013-1375-2
   Rastegar S, 2011, AEU-INT J ELECTRON C, V65, P658, DOI 10.1016/j.aeue.2010.09.008
   Roy S, 2017, MULTIMED TOOLS APPL, V76, P3577, DOI 10.1007/s11042-016-3902-4
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Rykaczewski R, 2007, IEEE T MULTIMEDIA, V9, P421, DOI 10.1109/TMM.2006.886297
   Tareef A, 2015, EXPERT SYST APPL, V42, P2224, DOI 10.1016/j.eswa.2014.09.055
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Xiao L, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.3041170
   Zhou B., 2004, CHINESE J IMAGE GRAP, V9, P506
NR 43
TC 39
Z9 40
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26845
EP 26879
DI 10.1007/s11042-018-5891-y
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500028
DA 2024-07-18
ER

PT J
AU Nasir, Q
   Khalil, E
AF Nasir, Qassim
   Khalil, Enas
TI Experimental evaluation of haptic data communication with prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Haptics; Haptic data; Tele-presence; Tele-interaction; Just noticeable
   difference
ID TRANSPARENT DATA REDUCTION; NETWORKED TELEPRESENCE; TELEACTION SYSTEMS
AB The transmission of haptic data is relatively challenging in multimedia communication. In this research study, the methods are presented for exploiting the properties of human haptic perception for data reduction of haptic data transmission. Packet-switched communication of haptic data is characterized by high packet rates on the communication channel. The quality of the internet-based haptic tele-control/tele-presence systems is highly dependent on the quality of the communication channel between the operator and the remote site, and on the delay jitter in the data exchange. The proposed research work is evaluated experimentally using a Geomagic Touch (previously PHANTOM Sensable Omni) haptic device with a sphere as a virtual model. Four experiments were conducted to evaluate the proposed research study. In the first experiment the JND Weber's law is applied on sent force values only, while in the second experiment, the force calculation algorithm has been modified to include human movement velocity. The third experiment discusses the use of JND on the sent velocity values. The evaluation of the human's perception shows that the proposed modification to the basic dead-band approach highly reduces the number of sent packets with minimal disturbance in haptic feeling. Further enhancements using prediction techniques have also been introduced in the fourth experimental evaluation. The linear predictions are added to the above proposed reduction methods. Combining the dead-band approach with a fast, configurable and accurate prediction algorithm enables a significant reduction in the amount of data sent across the network. The reduction is estimated to be 85%, while preserving the original data structure.
C1 [Nasir, Qassim] Univ Sharjah, Dept Elect Engn, Sharjah, U Arab Emirates.
   [Khalil, Enas] Univ Sharjah, ITC MIS, Sharjah, U Arab Emirates.
C3 University of Sharjah; University of Sharjah
RP Nasir, Q (corresponding author), Univ Sharjah, Dept Elect Engn, Sharjah, U Arab Emirates.
EM nasir@sharjah.ac.ae; enas@sharjah.ac.ae
RI Nasir, Qassim/AEM-3023-2022
OI Nasir, Qassim/0000-0002-2837-3402
CR Al Osman H, 2008, IEEE ACM DIS SIM, P181, DOI 10.1109/DS-RT.2008.23
   Awed J, 2013, COMPUT COMMUN, V36, P1621, DOI 10.1016/j.comcom.2013.06.006
   Boukerche A, 2008, MULTIMEDIA SYST, V13, P283, DOI 10.1007/s00530-007-0104-y
   Boukherche A, 2006, 39 SIM S HUNTSV US A
   Brandi F, 2013, 2013 IEEE INTERNATIONAL SYMPOSIUM ON HAPTIC AUDIO-VISUAL ENVIRONMENTS AND GAMES (HAVE 2013), P63, DOI 10.1109/HAVE.2013.6679612
   Cha J, 2009, IEEE MULTIMEDIA, V16, P16, DOI 10.1109/MMUL.2009.42
   Eid M, 2011, IEEE T INSTRUM MEAS, V60, P21, DOI 10.1109/TIM.2010.2065530
   Haykin S, 2009, COMMUNICATION SYSTEM, P5
   Hinterseer P, 2008, IEEE T SIGNAL PROCES, V56, P588, DOI 10.1109/TSP.2007.906746
   Hirche S, 2007, PRESENCE-TELEOP VIRT, V16, P532, DOI 10.1162/pres.16.5.532
   Hirche S, 2007, PRESENCE-TELEOP VIRT, V16, P523, DOI 10.1162/pres.16.5.523
   Hosseini ZM, 2009, THESIS
   Janabi-Sharifi F, 2000, IEEE T CONTR SYST T, V8, P1003, DOI 10.1109/87.880606
   Kammerl J, 2011, IEEE T INSTRUM MEAS, V60, P57, DOI 10.1109/TIM.2010.2065670
   Kammerl J, 2010, PRESENCE-TELEOP VIRT, V19, P450, DOI 10.1162/pres_a_00008
   Klatzky R., 2003, EXPT PSYCHOL, V4, P147
   Kron A, 2004, IEEE INT CONF ROBOT, P1968, DOI 10.1109/ROBOT.2004.1308112
   Mirfakhrai T, 2005, ROBOTICA, V23, P809, DOI 10.1017/S0263574705001736
   Nakagawa T, 2015, 2015 3RD INTERNATIONAL CONFERENCE ON ELECTRIC POWER EQUIPMENT - SWITCHING TECHNOLOGY (ICEPE-ST), P6, DOI 10.1109/ICEPE-ST.2015.7368325
   Ortega A, 2002, PREN HAL IMSC P MULT, P119
   Osman HA, 2007, P IEEE INT WORKSH HA
   Otanez PG, 2002, P AMER CONTR CONF, V1-6, P3015, DOI 10.1109/ACC.2002.1025251
   Shahabi C, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P657, DOI 10.1109/ICME.2002.1035867
   Souayed RT, 2003, P 7 IEEE INT S DISTR
   Tee TH, 2014, P 16 INT C ADV COMM
   Tee TH, 2014, 16 INT C ADV COMM TE
   Tsuji T, 2013, J ROBOT MECHATRON, V25, P515, DOI 10.20965/jrm.2013.p0515
   Vittorias I, 2009, 3 JOINT EUROHAPTICS
   Vittorias I, 2009, WORLD HAPTICS 2009: THIRD JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P208, DOI 10.1109/WHC.2009.4810811
   Xu X, 2015, 2015 I E WORLD HAPT
   You Y, 2007, P IEEE INT C MULT EX
   You Y, 2008, IEEE ICC, P1824, DOI 10.1109/ICC.2008.350
NR 32
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25005
EP 25025
DI 10.1007/s11042-018-5743-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400019
DA 2024-07-18
ER

PT J
AU Radman, A
   Suandi, SA
AF Radman, Abduljalil
   Suandi, Shahrel Azmin
TI Robust face pseudo-sketch synthesis and recognition using
   morphological-arithmetic operations and HOG-PCA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face sketch recognition; Face pseudo-sketch synthesis; Photo-sketch
   matching; Histograms of oriented gradients (HOG)
ID COUPLED DICTIONARY; IMAGES
AB In this paper, we propose a simple but yet effective method for synthesizing a pseudo face sketch (pseudo-sketch) from a photo, to be used for face recognition based on sketches drawn by a forensic artist. In contrast to current methods, the proposed method does not require training samples while fairly maintains the salient facial features as the artist do. We also propose a matching method on the basis of the Histograms of Oriented Gradients (HOG) descriptor and Principal Component Analysis (PCA), called HOG-PCA, to handle the similarities between a forensic sketch and a synthesized pseudo-sketch. In this method, we first extract the HOG features for the sketch and pseudo-sketch at regular grid and overlapped patches. The PCA is then applied to address the redundancy in feature representation due to several overlapped patches. Finally, the Nearest Neighbors Classifier (NNC) with the cosine distance is used to classify the sketch and pseudo-sketch pairs as matched or mismatched. Experimental results on CUHK and AR face sketch databases demonstrate that our proposed methods outperform state-of-the-art methods.
C1 [Radman, Abduljalil; Suandi, Shahrel Azmin] Univ Sains Malaysia, Sch Elect & Elect Engn, Intelligent Biometr Grp, Engn Campus, Nibong Tebal 14300, Pulau Pinang, Malaysia.
C3 Universiti Sains Malaysia
RP Radman, A (corresponding author), Univ Sains Malaysia, Sch Elect & Elect Engn, Intelligent Biometr Grp, Engn Campus, Nibong Tebal 14300, Pulau Pinang, Malaysia.
EM abdurad@usm.my; shahrel@usm.my
RI Suandi, Shahrel Azmin/D-1776-2009; Radman, Abduljalil/A-1722-2012
OI Suandi, Shahrel Azmin/0000-0001-9980-7426; Radman,
   Abduljalil/0000-0002-6317-9752
FU Universiti Sains Malaysia [1001/PELECT/814208]
FX The authors highly acknowledge Universiti Sains Malaysia for its fund
   Universiti Sains Malaysia Research University Grant (RUI) no.
   1001/PELECT/814208. We also thank the Chinese University of Hong Kong
   and the Ohio State University for their CUHK and AR face sketch
   databases.
CR Ahonen T, 2008, ICPR2009, P1, DOI DOI 10.1109/ICPR.2008.4761847
   [Anonymous], 1998, TECH REP
   [Anonymous], 2002, P INT C IM PROC
   [Anonymous], IEEE C AC SPEECH SIG
   [Anonymous], 2012, TECH REP
   Bhatt HS, 2012, IEEE T INF FOREN SEC, V7, P1522, DOI 10.1109/TIFS.2012.2204252
   Bhatt Himanshu S., 2010, 2010 Fourth IEEE International Conference on Biometrics: Theory, Applications and Systems (BTAS), P1, DOI DOI 10.1109/BTAS.2010.5634507
   Chen H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P433, DOI 10.1109/ICCV.2001.937657
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gao XB, 2012, IEEE T CIRC SYST VID, V22, P1213, DOI 10.1109/TCSVT.2012.2198090
   Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2
   Huang DA, 2013, IEEE I CONF COMP VIS, P2496, DOI 10.1109/ICCV.2013.310
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998
   Klare BF, 2011, IEEE T PATTERN ANAL, V33, P639, DOI 10.1109/TPAMI.2010.180
   LAND EH, 1983, P NATL ACAD SCI USA, V80, P5163, DOI 10.1073/pnas.80.16.5163
   Liu QS, 2005, PROC CVPR IEEE, P1005
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mittal P, 2017, INFORM FUSION, V33, P86, DOI 10.1016/j.inffus.2016.04.003
   Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   PAIGE CC, 1982, ACM T MATH SOFTWARE, V8, P43, DOI 10.1145/355984.355989
   Phillips PJ, 1998, FACE RECOGNITION THE, P244
   Radman A, 2017, DIGIT SIGNAL PROCESS, V64, P60, DOI 10.1016/j.dsp.2017.02.003
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shi ZH, 2016, MULTIMED TOOLS APPL, V75, P12245, DOI 10.1007/s11042-016-3421-3
   Song YB, 2014, LECT NOTES COMPUT SC, V8694, P800, DOI 10.1007/978-3-319-10599-4_51
   Struc V, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/847680
   Struc V, 2009, INFORMATICA-LITHUAN, V20, P115
   Tang XO, 2004, IEEE T CIRC SYST VID, V14, P50, DOI 10.1109/TCSVT.2003.818353
   Tang XO, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P687, DOI 10.1109/ICCV.2003.1238414
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Wang NN, 2017, SIGNAL PROCESS, V130, P1, DOI 10.1016/j.sigpro.2016.06.014
   Wang NN, 2014, INT J COMPUT VISION, V106, P9, DOI 10.1007/s11263-013-0645-9
   Wang NN, 2013, IEEE T NEUR NET LEAR, V24, P1364, DOI 10.1109/TNNLS.2013.2258174
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222
   Xiao B, 2009, SIGNAL PROCESS, V89, P1576, DOI 10.1016/j.sigpro.2009.02.008
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yang MH, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P215
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang SC, 2016, IEEE T IMAGE PROCESS, V25, P220, DOI 10.1109/TIP.2015.2501755
   Zhang SC, 2015, IEEE T IMAGE PROCESS, V24, P2466, DOI 10.1109/TIP.2015.2422578
   Zhou H, 2012, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2012.6247788
NR 47
TC 15
Z9 15
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25311
EP 25332
DI 10.1007/s11042-018-5786-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400032
DA 2024-07-18
ER

PT J
AU Singh, S
   Kasana, SS
AF Singh, Simranjit
   Kasana, Singara Singh
TI Efficient classification of the hyperspectral images using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Auto Encoders; LPP; DCNN; HSI; Neural networks; PCA; SVM
ID SUPPORT VECTOR MACHINES; PARALLEL FRAMEWORK; BELIEF NETWORKS;
   DISCRIMINATION
AB Classification techniques applicable to the hyperspectral images do not extract deep features from the hyperspectral image efficiently. In this work, a deep learning approach is proposed to extract the deep features, and these features are utilized to propose a novel framework for classification of the hyperspectral image. The framework uses LPP, DCNN and logistic regression. Data of a hyperspectral image is processed by LPP for dimensionality reduction as it contains a large number of dimensions. Afterward, a DCNN is constructed with Autoencoders which is then passed to the logistic regression for classification. Proposed framework is tested on Indian Pines and Salinas data sets. High accuracy is achieved using the proposed framework in comparison of existing machine learning models.
C1 [Singh, Simranjit; Kasana, Singara Singh] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Singh, S (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM id-simranjit_singh@thapar.edu; singara@thapar.edu
RI Singh, Simranjit/J-5957-2013
OI Singh, Simranjit/0000-0002-6245-1590; Singh,
   Simranjit/0000-0001-5324-2116
CR Aldrich J, 1997, STAT SCI, V12, P162
   Andrychowicz M., 2016, P NIPS, P1
   [Anonymous], WORKSH HYP IM SIGN P
   [Anonymous], 2012, PRINCIPAL COMPONENT
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Camps-Valls G, 2005, IEEE T GEOSCI REMOTE, V43, P1351, DOI 10.1109/TGRS.2005.846154
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Du YZ, 2004, OPT ENG, V43, P1777, DOI 10.1117/1.1766301
   Fagan ME, 2015, REMOTE SENS-BASEL, V7, P5660, DOI 10.3390/rs70505660
   Greene W.W. H. ., 2012, Econometric analysis, V97
   He XF, 2004, ADV NEUR IN, V16, P153
   Hecht-Nielsen R., 1989, IJCNN: International Joint Conference on Neural Networks (Cat. No.89CH2765-6), P593, DOI 10.1109/IJCNN.1989.118638
   Ivakhnenko A.G., 1965, Cybernetic predicting devices
   KOHONEN T, 1988, NEURAL NETWORKS, V1, P3, DOI 10.1016/0893-6080(88)90020-2
   Krizsan A, 2012, GENDER POLIT, P1
   Krüger N, 2013, IEEE T PATTERN ANAL, V35, P1847, DOI 10.1109/TPAMI.2012.272
   Kruse FA, 2003, IEEE T GEOSCI REMOTE, V41, P1388, DOI 10.1109/TGRS.2003.812908
   KRUSE FA, 1993, REMOTE SENS ENVIRON, V44, P145, DOI 10.1016/0034-4257(93)90013-N
   Kumar MN, 2011, INT J REMOTE SENS, V32, P4041, DOI 10.1080/01431161.2010.484431
   Le Roux N, 2010, NEURAL COMPUT, V22, P2192, DOI 10.1162/neco.2010.08-09-1081
   Melgani F, 2002, INT GEOSCI REMOTE SE, P506, DOI 10.1109/IGARSS.2002.1025088
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sutskever I, 2008, NEURAL COMPUT, V20, P2629, DOI 10.1162/neco.2008.12-07-661
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tobergte DavidR., 2013, J CHEM INF MODEL, V53, P1689, DOI DOI 10.1017/CBO9781107415324.004
   VANE G, 1993, REMOTE SENS ENVIRON, V44, P127, DOI 10.1016/0034-4257(93)90012-M
   Wu ST, 2018, MULTIMED TOOLS APPL, V77, P10437, DOI 10.1007/s11042-017-4440-4
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang C, 2008, T ASABE, V51, P729, DOI 10.13031/2013.24370
   Yue J, 2016, REMOTE SENS LETT, V7, P875, DOI 10.1080/2150704X.2016.1193793
   Zanaty EA, 2012, EGYPT INFORM J, V13, P177, DOI 10.1016/j.eij.2012.08.002
NR 34
TC 21
Z9 21
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27061
EP 27074
DI 10.1007/s11042-018-5904-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500037
DA 2024-07-18
ER

PT J
AU Tous, R
   Gomez, M
   Poveda, J
   Cruz, L
   Wust, O
   Makni, M
   Ayguadé, E
AF Tous, Ruben
   Gomez, Mauro
   Poveda, Jonatan
   Cruz, Leonel
   Wust, Otto
   Makni, Mouna
   Ayguade, Eduard
TI Automated curation of brand-related social media images with deep
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media; Instagram; Twitter; User generated content; Deep learning;
   Marketing
AB This paper presents a work consisting in using deep convolutional neural networks (CNNs) to facilitate the curation of brand-related social media images. The final goal is to facilitate searching and discovering user-generated content (UGC) with potential value for digital marketing tasks. The images are captured in real time and automatically annotated with multiple CNNs. Some of the CNNs perform generic object recognition tasks while others perform what we call visual brand identity recognition. When appropriate, we also apply object detection, usually to discover images containing logos. We report experiments with 5 real brands in which more than 1 million real images were analyzed. In order to speed-up the training of custom CNNs we applied a transfer learning strategy. We examine the impact of different configurations and derive conclusions aiming to pave the way towards systematic and optimized methodologies for automatic UGC curation.
C1 [Tous, Ruben; Cruz, Leonel; Makni, Mouna] UPC, Barcelona, Spain.
   [Gomez, Mauro; Poveda, Jonatan; Wust, Otto] Adsmurai, Barcelona, Spain.
   [Ayguade, Eduard] BSC, Barcelona, Spain.
C3 Universitat Politecnica de Catalunya
RP Tous, R (corresponding author), UPC, Barcelona, Spain.
EM rtous@ac.upc.edu
RI Ayguadé, Eduard/D-8933-2014; Tous, Ruben/N-5610-2014
OI Tous, Ruben/0000-0002-1409-5843; Poveda-Pena,
   Jonatan/0000-0002-5911-1982
FU Spanish Ministry of Economy and Competitivity [TIN2015-65316-P]; SGR
   programme of the Catalan Government [2014-SGR-1051]
FX This work is partially supported by the Spanish Ministry of Economy and
   Competitivity under contract TIN2015-65316-P and by the SGR programme
   (2014-SGR-1051) of the Catalan Government.
CR [Anonymous], 2014, P INT C MULT RETR
   [Anonymous], P INT C LEARN REPR I
   [Anonymous], 2021, P THEINTERNATIONAL A
   [Anonymous], 2014, P 31 INT C INT C MAC
   Clark M, 2017, J RES INTERACT MARK, V11, P39, DOI 10.1108/JRIM-07-2015-0047
   Clarke T, 2008, COLOR RES APPL, V33, P406, DOI 10.1002/col.20435
   Denton E, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1731, DOI 10.1145/2783258.2788576
   Gao Y, 2016, IEEE T MULTIMEDIA, V18, P2115, DOI 10.1109/TMM.2016.2581483
   Nguyen D. T., 2017, CORR
   Park M., 2016, CORR
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tous R, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P2535, DOI 10.1109/BigData.2016.7840893
   Tous R, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P144, DOI 10.1109/BigMM.2015.39
   Wang FL, 2016, MULTIMEDIA SYST, V22, P63, DOI 10.1007/s00530-014-0393-x
   Yue Gao, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P269, DOI 10.1007/978-3-319-14445-0_24
   Zhao SC, 2016, MULTIMED TOOLS APPL, V75, P8921, DOI 10.1007/s11042-014-2342-2
   Zhao Sicheng, 2016, P 24 ACM INT C MULT, P1385, DOI DOI 10.1145/2964284.2964289
NR 18
TC 10
Z9 11
U1 2
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27123
EP 27142
DI 10.1007/s11042-018-5910-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500041
DA 2024-07-18
ER

PT J
AU Dai, P
   Wang, X
   Zhang, WH
   Zhang, PB
   You, W
AF Dai, Peng
   Wang, Xue
   Zhang, Weihang
   Zhang, Pengbo
   You, Wei
TI Implicit relative attribute enabled cross-modality hashing for face
   image-video retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face image-video retrieval; Human attribute; Cross-modality similarity
   search; Hashing
AB Face image-video retrieval refers to retrieving videos of a specific person with image query or searching face images of one person by using a video clip query. It has attracted much attention for broad applications like suspect tracking and identifying. This paper proposes a novel implicit relative attribute enabled cross-modality hashing (IRAH) method for large-scale face image-video retrieval. To cope with large-scale data, the proposed IRAH method facilitates fast cross-modality retrieval through embedding two entirely heterogeneous spaces, i.e., face images in Euclidean space and face videos on a Riemannian manifold, into a unified compact Hamming space. In order to resolve the semantic gap, IRAH maps the original low-level kernelized features to discriminative high-level implicit relative attributes. Therefore, the retrieval accuracy can be improved by leveraging both the label information across different modalities and the semantic structure obtained from the implicit relative attributes in each modality. To evaluate the proposed method, we conduct extensive experiments on two publicly available databases, i.e., the Big Bang Theory (BBT) and Buffy the Vampire Slayer (BVS). The experimental results demonstrate the superiority of the proposed method over different state-of-the-art cross-modality hashing methods. The performance gains are especially significant in the case that the hash code length is 8 bits, up to 12% improvements over the second best method among tested methods.
C1 [Dai, Peng; Wang, Xue; Zhang, Weihang; Zhang, Pengbo; You, Wei] Tsinghua Univ, Dept Precis Instrument, State Key Lab Precis Measurement Technol & Instru, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Wang, X (corresponding author), Tsinghua Univ, Dept Precis Instrument, State Key Lab Precis Measurement Technol & Instru, Beijing 100084, Peoples R China.
EM daip13@mails.tsinghua.edu.cn; wangxue@mail.tsinghua.edu.cn
OI Wang, Xue/0000-0003-4842-3160
FU National Natural Science Foundation of China [61472216]
FX This paper is supported by National Natural Science Foundation of China
   under Grant #61472216.
CR An L, 2016, NEUROCOMPUTING, V172, P215, DOI 10.1016/j.neucom.2014.09.098
   [Anonymous], 2016, ARXIV161009462
   [Anonymous], ARXIV161201657
   [Anonymous], 2017, PATTERN RECOGNITION
   [Anonymous], 2016, AAAI
   [Anonymous], P INT JOINT C ART IN
   Araujo Andre, 2015, 2015 IEEE International Conference on Image Processing (ICIP). Proceedings, P1519, DOI 10.1109/ICIP.2015.7351054
   Araujo A, 2017, IEEE T CIRCUITS SYST
   Bäuml M, 2013, PROC CVPR IEEE, P3602, DOI 10.1109/CVPR.2013.462
   Cevikalp H, 2010, PROC CVPR IEEE, P2567, DOI 10.1109/CVPR.2010.5539965
   Chakraborty S, 2016, IEEE T CIRCUITS SYST
   Chen BC, 2016, IEEE T CIRCUITS SYST
   Chen BC, 2013, IEEE T MULTIMEDIA, V15, P1163, DOI 10.1109/TMM.2013.2242460
   Chen ZX, 2017, IEEE T MULTIMEDIA, V19, P123, DOI 10.1109/TMM.2016.2620604
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Dai P, 2017, MULTIMED TOOLS APPL, V2017, P1
   Ding GG, 2016, IEEE T IMAGE PROCESS, V25, P5427, DOI 10.1109/TIP.2016.2607421
   Ding K, 2017, IEEE T MULTIMEDIA, V19, P571, DOI 10.1109/TMM.2016.2625747
   Ding S, 2016, MULTIMED TOOLS APPL, V2016, P1
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Hu Y, 2011, PROC CVPR IEEE, P121, DOI 10.1109/CVPR.2011.5995500
   Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Kafai M, 2014, IEEE T MULTIMEDIA, V16, P1090, DOI 10.1109/TMM.2014.2305633
   Korman S, 2016, IEEE T PATTERN ANAL, V38, P1099, DOI 10.1109/TPAMI.2015.2477814
   Kumar Neeraj, 2011, IEEE Trans Pattern Anal Mach Intell, V33, P1962, DOI 10.1109/TPAMI.2011.48
   Li QF, 2018, NEURAL COMPUT APPL, V30, P463, DOI 10.1007/s00521-016-2680-2
   Li Y, 2016, IEEE T IMAGE PROCESS, V25, P5905, DOI 10.1109/TIP.2016.2616297
   Li Y, 2015, PROC CVPR IEEE, P4758, DOI 10.1109/CVPR.2015.7299108
   Li YS, 2018, IEEE T GEOSCI REMOTE, V56, P950, DOI 10.1109/TGRS.2017.2756911
   Liang R, 2016, IEEE INT C PATT REC
   Lin KC, 2016, MULTIMED TOOLS APPL, V75, P11469, DOI 10.1007/s11042-015-2864-2
   Lin ZJ, 2017, IEEE T CYBERNETICS, V47, P4342, DOI 10.1109/TCYB.2016.2608906
   Liu B, 2012, PROC INT CONF ANTI
   Liu HB, 2016, SHOCK VIB, V2016, DOI 10.1155/2016/4792786
   Liu HY, 2016, PROC CVPR IEEE, P2167, DOI 10.1109/CVPR.2016.238
   Liu L, 2017, IEEE T IMAGE PROCESS, V26, P107, DOI 10.1109/TIP.2016.2619262
   Liu M, 2017, COMPUTER VISION IMAG
   Liu XL, 2016, IEEE T IMAGE PROCESS, V25, P907, DOI 10.1109/TIP.2015.2505180
   Liu XL, 2015, IEEE T CYBERNETICS, V45, P1811, DOI 10.1109/TCYB.2014.2360856
   Liu Y, 2016, FORTUNE TELLER PREDI
   Lu JW, 2013, IEEE I CONF COMP VIS, P329, DOI 10.1109/ICCV.2013.48
   Nie LQ, 2016, IEEE T CYBERNETICS, V46, P2991, DOI 10.1109/TCYB.2015.2493558
   Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281
   Park U, 2010, IEEE T INF FOREN SEC, V5, P406, DOI 10.1109/TIFS.2010.2049842
   Pavan M, 2007, IEEE T PATTERN ANAL, V29, P167, DOI 10.1109/TPAMI.2007.250608
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Qiao S, 2016, P AS C COMP VIS
   Qin J, 2017, PROC CVPR IEEE, P6728, DOI 10.1109/CVPR.2017.712
   Scholkopf B, 2002, LEARNING KERNELS 200
   Shan CF, 2010, STUD COMPUT INTELL, V287, P235
   Tang J, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2564638
   Wang D, 2016, IEEE T IMAGE PROCESS, V25, P4540, DOI 10.1109/TIP.2016.2592800
   Wang J, 2016, P IEEE, V104, P34, DOI 10.1109/JPROC.2015.2487976
   Wang RP, 2012, PROC CVPR IEEE, P2496, DOI 10.1109/CVPR.2012.6247965
   Wu Z, 2011, IEEE T PATTERN ANAL, V33, P1991, DOI 10.1109/TPAMI.2011.111
   Xu Z, 2016, MULTIMED TOOLS APPL, V75, P12155, DOI 10.1007/s11042-015-3112-5
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhang JJ, 2016, IEEE INT POWER ELEC
   Zhang LM, 2017, IEEE T CYBERNETICS, V47, P3866, DOI 10.1109/TCYB.2016.2585764
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P5738, DOI 10.1109/TIE.2015.2410766
   Zhang N, 2016, MULTIMED TOOLS APPL, V2016, P1
   Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415
NR 64
TC 2
Z9 2
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23547
EP 23577
DI 10.1007/s11042-018-5684-3
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900022
DA 2024-07-18
ER

PT J
AU Lu, HM
   Li, YJ
   Uemura, T
   Ge, ZY
   Xu, X
   He, L
   Serikawa, S
   Kim, H
AF Lu, Huimin
   Li, Yujie
   Uemura, Tomoki
   Ge, Zongyuan
   Xu, Xing
   He, Li
   Serikawa, Seiichi
   Kim, Hyoungseop
TI FDCNet: filtering deep convolutional network for marine organism
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Filtering deep convolutional network; Marine organism classification;
   Artificial intelligence; Deep learning
ID ENHANCEMENT
AB Convolutional networks are currently the most popular computer vision methods for a wide variety of applications in multimedia research fields. Most recent methods have focused on solving problems with natural images and usually use a training database, such as Imagenet or Openimage, to detect the characteristics of the objects. However, in practical applications, training samples are difficult to acquire. In this study, we develop a powerful approach that can accurately learn marine organisms. The proposed filtering deep convolutional network (FDCNet) classifies deep-sea objects better than state-of-the-art classification methods, such as AlexNet, GoogLeNet, ResNet50, and ResNet101. The classification accuracy of the proposed FDCNet method is 1.8%, 2.9%, 2.0%, and 1.0% better than AlexNet, GooLeNet, ResNet50, and ResNet101, respectively. In addition, we have built the first marine organism database, Kyutech10K, with seven categories (i.e., shrimp, squid, crab, shark, sea urchin, manganese, and sand).
C1 [Lu, Huimin; Li, Yujie; Uemura, Tomoki; Serikawa, Seiichi; Kim, Hyoungseop] Kyushu Inst Technol, Fukuoka, Fukuoka, Japan.
   [Lu, Huimin] Chinese Acad Sci, Beijing, Peoples R China.
   [Li, Yujie] Yangzhou Univ, Yangzhou, Jiangsu, Peoples R China.
   [Ge, Zongyuan] IBM Australia Inc, West Pennant Hills, Australia.
   [Xu, Xing] Univ Elect Sci & Technol China, Chengdu, Sichuan, Peoples R China.
   [He, Li] Qualcomm Inc, San Diego, CA USA.
C3 Kyushu Institute of Technology; Chinese Academy of Sciences; Yangzhou
   University; University of Electronic Science & Technology of China;
   Qualcomm
RP Lu, HM (corresponding author), Kyushu Inst Technol, Fukuoka, Fukuoka, Japan.; Lu, HM (corresponding author), Chinese Acad Sci, Beijing, Peoples R China.
EM luhuimin@ieee.org; liyujie@yzu.edu.cn
RI Li, Yujie/AAH-3298-2019; Li, YuJie/HGT-8657-2022; Li,
   YuJie/JAC-4451-2023
OI Li, Yujie/0000-0002-0275-2797; Ge, Zongyuan/0000-0002-5880-8673
FU JSPS KAKENHI [15F15077, 15K12562, 16H05913]; Leading Initiative for
   Excellent Young Researcher (LEADER) of Ministry of Education, Culture,
   Sports, Science and Technology-Japan [16809746]; Open Research Fund of
   the Key Laboratory of Marine Geology and Environment in Chinese Academy
   of Sciences [MGE2015KG02]; Research Fund of State Key Laboratory of
   Marine Geology in Tongji University [1608]; Research Fund of State Key
   Laboratory of Ocean Engineering in Shanghai Jiaotong University [1301,
   1510]; Grants-in-Aid for Scientific Research [15F15077, 16H05913,
   15K12562] Funding Source: KAKEN
FX This work was supported by JSPS KAKENHI (15F15077, JSPS KAKENHI Grant
   Number 15K12562, 15F15077, 16H05913), Leading Initiative for Excellent
   Young Researcher (LEADER) of Ministry of Education, Culture, Sports,
   Science and Technology-Japan (16809746), Open Research Fund of the Key
   Laboratory of Marine Geology and Environment in Chinese Academy of
   Sciences (No.MGE2015KG02), Research Fund of State Key Laboratory of
   Marine Geology in Tongji University (1608), Research Fund of State Key
   Laboratory of Ocean Engineering in Shanghai Jiaotong University (1301;
   1510).
CR [Anonymous], P ACM C KNOWL DISC D
   [Anonymous], NIPS
   [Anonymous], 2015, P ITS WORLD C
   [Anonymous], ABS13106343 CORR
   [Anonymous], ENCY DISTANCES
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], COMPUT VIS ECCV
   [Anonymous], CVPR
   [Anonymous], 2016, CONCURR COMPUT PRACT
   Bell Robert M, 2007, Acm Sigkdd Explorations Newsletter, V9, P75, DOI [10.1145/1345448.1345465, DOI 10.1145/1345448.1345465]
   Carlevaris-Bianco N., 2010, OCEANS, P1, DOI DOI 10.1109/OCEANS.2010.5664428
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Gibson KB, 2012, IEEE T IMAGE PROCESS, V21, P662, DOI 10.1109/TIP.2011.2166968
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lee Y, 2014, IEEE IMAGE PROC, P5427, DOI 10.1109/ICIP.2014.7026098
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Lu HM, 2016, IEICE T INF SYST, VE99D, P219, DOI 10.1587/transinf.2014EDP7405
   Lu HM, 2015, J OPT SOC AM A, V32, P886, DOI 10.1364/JOSAA.32.000886
   Maji S., 2008, PROC IEEE COMPUT VIS, P1
   Maji S, 2013, IEEE T PATTERN ANAL, V35, P66, DOI 10.1109/TPAMI.2012.62
   Ren JSJ, 2015, AAAI CONF ARTIF INTE, P1840
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Simonyan K., 2014, 14091556 ARXIV
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tarel JP, 2012, IEEE INTEL TRANSP SY, V4, P6, DOI 10.1109/MITS.2012.2189969
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Wang N., 2013, Advances in Neural Information Processing Systems, P809
   Wang SH, 2016, PROG ELECTROMAGN RES, V156, P105
   Zhang Y, 2016, IEEE T SERV COMPUT, V9, P786, DOI 10.1109/TSC.2016.2592520
   Zhang YL, 2016, CURR OPIN CHEM ENG, V12, P1, DOI 10.1016/j.coche.2016.01.004
NR 36
TC 44
Z9 46
U1 2
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 21847
EP 21860
DI 10.1007/s11042-017-4585-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500003
DA 2024-07-18
ER

PT J
AU Pal, P
   Chowdhuri, P
   Jana, B
AF Pal, Pabitra
   Chowdhuri, Partha
   Jana, Biswapati
TI Weighted matrix based reversible watermarking scheme using color image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible watermarking; Weighted matrix; Watermarked image; Payload;
   Steganographic attacks; Tampered image
ID DATA HIDING SCHEME; DIGITAL WATERMARKING; TAMPER DETECTION;
   AUTHENTICATION; SECRET; ROBUST
AB High capacity, secure, reversible watermarking scheme using a color image for image authentication and tampered detection is still an important area of research. In this investigation, we have proposed a weighted matrix based reversible watermarking scheme using the color image which provides image authentication and tampered detection. Here, we decomposed the original image into R, G, B color components and partitioned into (3 x 3) pixel blocks then we performed the sum of entry-wise-multiplication operations using a modified weighted matrix to embed the watermark. The watermark embedding locations are stored within an index file to enhance security, increase data hiding capacity, gain good visual quality, achieve reversibility and confirm authenticity. The proposed watermarking scheme not only perform authentication and tampered detection but also improved both data embedding capacity up to 8.00 (bpp) as well as increase visual quality measured by PSNR, 50.03 (dB). Finally, the scheme is compared with other existing state-of-the-art methods and gives a reasonably better performance in terms of visual quality and hiding capacity. Our scheme has been evaluated through various steganographic analysis and observed that the scheme is secure and robust against various attacks.
C1 [Pal, Pabitra; Chowdhuri, Partha; Jana, Biswapati] Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
C3 Vidyasagar University
RP Jana, B (corresponding author), Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
EM pabipaltra@gmail.com; prc.email@gmail.com; biswapatijana@gmail.com
RI Jana, Prof. Biswapati/AAA-2154-2019; Pal, Pabitra/AAA-1391-2020
OI Jana, Prof. Biswapati/0000-0003-4476-3459; Pal,
   Pabitra/0000-0002-2866-7320; Chowdhuri, Partha/0000-0002-1702-5939
CR Abadi M. A. M., 2010, 2010 5th International Symposium on Telecommunications (IST), P840, DOI 10.1109/ISTEL.2010.5734139
   An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   [Anonymous], 2016, INT C EM TRENDS ENG
   [Anonymous], HDR DATASET COMPUTAT
   [Anonymous], P 18 IPPR C COMP VIS
   [Anonymous], P 1 INT C INF MAN BU
   [Anonymous], IOP C SERIES EARTH E
   [Anonymous], INT J COMPUT APPL
   [Anonymous], CHINESE J ENG GEOPHY
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Chamlawi R, 2010, INFORM SCIENCES, V180, P4909, DOI 10.1016/j.ins.2010.08.039
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Etemad E., 2017, MULTIMED TOOLS APPL, V77, P1, DOI DOI 10.1007/S11042-017-5543-7
   Fan L, 2013, COMPUT ELECTR ENG, V39, P873, DOI 10.1016/j.compeleceng.2012.06.014
   Fridrich J, 2000, IEEE IMAGE PROC, P446, DOI 10.1109/ICIP.2000.900991
   Fridrich J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P404, DOI 10.1109/ICIP.1998.723401
   He Hong-jie, 2005, Acta Electronica Sinica, V33, P1557
   Holliman M, 2000, IEEE T IMAGE PROCESS, V9, P432, DOI 10.1109/83.826780
   Hsia SC, 2002, IEICE T FUND ELECTR, VE85A, P463
   Hu MC, 2007, COMPUT SECUR, V26, P319, DOI 10.1016/j.cose.2006.11.007
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hwang J, 2006, LECT NOTES COMPUT SC, V4283, P348
   Jana B, 2016, OPTIK, V127, P3347, DOI 10.1016/j.ijleo.2015.12.055
   Jung KH, 2018, MULTIMED TOOLS APPL, V77, P6225, DOI 10.1007/s11042-017-4533-0
   Kundur D, 1999, P IEEE, V87, P1167, DOI 10.1109/5.771070
   Kuo WC, 2016, OPTIK, V127, P1762, DOI 10.1016/j.ijleo.2015.08.056
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Li KF, 2001, 2001 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING, VOLS I AND II, CONFERENCE PROCEEDINGS, P164, DOI 10.1109/PACRIM.2001.953548
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Lou DC, 2003, 37TH ANNUAL 2003 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P370
   Lu CS, 2001, IMAGE PROC SER, P507
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Nemade HS, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P2664
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Pal P, 2017, INT C COMP INT COMM, P511
   Panchal UH, 2015, INT CONF COMM SYST, P591, DOI 10.1109/CSNT.2015.165
   Phen-Lan Lin, 2004, Proceedings. IEEE Sixth International Symposium on Multimedia Software, P146
   Potdar VA, 2005, 2005 3RD IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS (INDIN), P709
   Roldan LR, 2016, IEEE LAT AM T, V14, P1050, DOI 10.1109/TLA.2016.7437257
   Soleymani SH, 2017, MULTIMED TOOLS APPL, V76, P20847, DOI 10.1007/s11042-016-4009-7
   Sreenivas K, 2018, INT J MACH LEARN CYB, V9, P1193, DOI 10.1007/s13042-017-0641-4
   Suthaharan S, 2004, PATTERN RECOGN LETT, V25, P1893, DOI 10.1016/j.patrec.2004.08.017
   Tseng YC, 2002, IEEE T COMMUN, V50, P1227, DOI 10.1109/TCOMM.2002.801488
   Vaishnavi D, 2015, PROCEDIA COMPUT SCI, V46, P1770, DOI 10.1016/j.procs.2015.02.130
   Wo Yan, 2005, Chinese Journal of Computers, V28, P105
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Wong PW, 2000, P SOC PHOTO-OPT INS, V3971, P417, DOI 10.1117/12.384996
   Wong PW, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P455, DOI 10.1109/ICIP.1998.723526
   Yang CN, 2017, COMPUT STAND INTER, V50, P209, DOI 10.1016/j.csi.2016.10.005
NR 51
TC 14
Z9 14
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23073
EP 23098
DI 10.1007/s11042-017-5568-y
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900001
DA 2024-07-18
ER

PT J
AU Shandoosti, HR
   Javaheri, N
AF Shandoosti, Hamid Reza
   Javaheri, Nayereh
TI A fast algorithm for feature extraction of hyperspectral images using
   the first order statistics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fast classification; First-order statistics; Limited training samples;
   Kernel trick; Supervised feature extraction; Hyperspectral imaging
ID LINEAR DISCRIMINANT-ANALYSIS; PRINCIPAL COMPONENT ANALYSIS; SPATIAL
   FEATURE-EXTRACTION; SUPPORT VECTOR MACHINES; SAMPLE-SIZE PROBLEM; FACE
   RECOGNITION; TRAINING SAMPLES; CLASSIFICATION; SELECTION; DECOMPOSITION
AB A new supervised feature extraction method appropriate for small sample size situations is proposed in this work. The proposed method is based on the first-order statistics, in which there is no need to estimate the scatter matrices. Thus, the presented method not only can avoid the singularity problem in small sample size situations but also can achieve high performance in such situations. In addition, due to the fact that the proposed algorithm only exploits the first order statistical moments, it is very fast making it suitable for real-time hyperspectral scene analysis. The proposed method makes a matrix whose columns are obtained by averaging training samples of different classes. Then, a new transform is used to map the features from the original space into a new low-dimensional space such that the new features are as different from each other as possible. Subsequently, to capture the inherent nonlinearity of the original data, the algorithm is improved using the kernel trick. In experiments, four widely-used hyperspectral datasets, namely, Indian Pines, University of Pavia, Salinas, and Botswana are classified. The experimental results show that the proposed algorithm achieves state-of-the-art results in small sample size situations.
C1 [Shandoosti, Hamid Reza; Javaheri, Nayereh] Hamedan Univ Technol, Dept Elect Engn, Hamadan 65155, Iran.
RP Shandoosti, HR (corresponding author), Hamedan Univ Technol, Dept Elect Engn, Hamadan 65155, Iran.
EM h.doosti@hut.ac.ir
RI Shahdoosti, Hamid/U-1005-2019
CR Bo CJ, 2018, MULTIMED TOOLS APPL, V77, P10419, DOI 10.1007/s11042-017-4403-9
   Camps-Valls G, 2010, IEEE GEOSCI REMOTE S, V7, P741, DOI 10.1109/LGRS.2010.2046618
   Cao X, 2017, IEEE GEOSCIENCE REMO
   Cao XH, 2016, INT J REMOTE SENS, V37, P4501, DOI 10.1080/01431161.2016.1214301
   Chang C. C., 2008, LIBSVM LIB SUPPORT V
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Cui Y, 2012, NEUROCOMPUTING, V86, P52, DOI 10.1016/j.neucom.2011.12.031
   Dehghan H, 2006, INT J REMOTE SENS, V27, P4005, DOI 10.1080/01431160600647225
   Foody GM, 2004, PHOTOGRAMM ENG REM S, V70, P627, DOI 10.14358/PERS.70.5.627
   Ghimire D, 2017, MULTIMED TOOLS APPL, V76, P7803, DOI 10.1007/s11042-016-3418-y
   HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456
   Howland P, 2004, IEEE T PATTERN ANAL, V26, P995, DOI 10.1109/TPAMI.2004.46
   Imani M, 2015, INT J REMOTE SENS, V36, P1728, DOI 10.1080/01431161.2015.1024894
   Imani M, 2015, IEEE GEOSCI REMOTE S, V12, P1387, DOI 10.1109/LGRS.2015.2402167
   Imani M, 2014, IEEE GEOSCI REMOTE S, V11, P1986, DOI 10.1109/LGRS.2014.2316134
   Imani M, 2014, IEEE GEOSCI REMOTE S, V11, P1325, DOI 10.1109/LGRS.2013.2292892
   Ji SW, 2008, IEEE T NEURAL NETWOR, V19, P1768, DOI 10.1109/TNN.2008.2002078
   Jiang JJ, 2017, IEEE GEOSCI REMOTE S, V14, P404, DOI 10.1109/LGRS.2016.2645708
   Jiang XW, 2017, IEEE GEOSCI REMOTE S, V14, P1760, DOI 10.1109/LGRS.2017.2734680
   Kamandar M, 2013, IEEE GEOSCI REMOTE S, V10, P702, DOI 10.1109/LGRS.2012.2219575
   Landgrebe D, 2002, IEEE SIGNAL PROC MAG, V19, P17, DOI 10.1109/79.974718
   Li J, 2015, IEEE T GEOSCI REMOTE, V53, P1592, DOI 10.1109/TGRS.2014.2345739
   Lu JW, 2005, PATTERN RECOGN LETT, V26, P181, DOI 10.1016/j.patrec.2004.09.014
   Marconcini M, 2009, IEEE GEOSCI REMOTE S, V6, P234, DOI 10.1109/LGRS.2008.2009324
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Ren YM, 2017, IEEE GEOSCI REMOTE S, V14, P1431, DOI 10.1109/LGRS.2017.2686878
   Schacke K., 2004, THESIS
   Shahdoosti HR, 2018, INT J REMOTE SENS, V39, P101, DOI 10.1080/01431161.2017.1381353
   Shahdoosti HR, 2017, EUR J REMOTE SENS, V50, P111, DOI 10.1080/22797254.2017.1279821
   Shahdoosti HR, 2017, IEEE GEOSCI REMOTE S, V14, P826, DOI 10.1109/LGRS.2017.2682122
   SHAHSHAHANI BM, 1994, IEEE T GEOSCI REMOTE, V32, P1087, DOI 10.1109/36.312897
   Sharma A, 2010, NEUROCOMPUTING, V73, P1868, DOI 10.1016/j.neucom.2009.10.027
   Tang WJ, 2017, MULTIMED TOOLS APPL, V76, P22725, DOI 10.1007/s11042-017-4343-4
   Tong F, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9090872
   Wang JG, 2008, PATTERN RECOGN LETT, V29, P1832, DOI 10.1016/j.patrec.2008.05.010
   Xia JS, 2014, IEEE J-STARS, V7, P2224, DOI 10.1109/JSTARS.2013.2279693
   Xue B, 2013, IEEE T CYBERNETICS, V43, P1656, DOI 10.1109/TSMCB.2012.2227469
   Yan DQ, 2018, MULTIMED TOOLS APPL, V77, P5803, DOI 10.1007/s11042-017-4494-3
   Ye JP, 2006, J MACH LEARN RES, V7, P1183
   Ye JP, 2005, IEEE T PATTERN ANAL, V27, P929, DOI 10.1109/TPAMI.2005.110
   Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X
   Zhou XC, 2017, IEEE GEOSCI REMOTE S, V14, P97, DOI 10.1109/LGRS.2016.2630045
   Zhu M., 2006, IEEE C COMPUTER VISI, V1, P132, DOI DOI 10.1109/CVPR.2006.271
NR 43
TC 4
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23633
EP 23650
DI 10.1007/s11042-018-5695-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900025
DA 2024-07-18
ER

PT J
AU Xu, X
   Wu, HP
   Yang, Y
   Shen, FM
   Xie, N
   Ji, YL
AF Xu, Xing
   Wu, Haiping
   Yang, Yang
   Shen, Fumin
   Xie, Ning
   Ji, Yanli
TI Semantic binary coding for visual recognition via joint
   concept-attribute modelling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual computing; Binary representation; Semantics; Attributes
ID IMAGE ANNOTATION; WEB
AB Recent years have witnessed the unprecedented efforts of visual representation for enabling various efficient and effective multimedia applications. In this paper, we propose a novel visual representation learning framework, which generates efficient semantic hash codes for visual samples by substantially exploring concepts, semantic attributes as well as their inter-correlations. Specifically, we construct a conceptual space, where the semantic knowledge of concepts and attributes is embedded. Then, we develop an effective on-line feature coding scheme for visual objects by leveraging the inter-concept relationships through the intermediate representative power of attributes. The code process is formulated as an overlapping group lasso problem, which can be efficiently solved. Finally, we may binarize the visual representation to generate efficient hash codes. Extensive experiments have been conducted to illustrate the superiority of our proposed framework on visual retrieval task as compared to state-of-the-art methods.
C1 [Xu, Xing] Guizhou Univ, Guizhou Prov Key Lab Publ Big Data, Guiyang, Guizhou, Peoples R China.
   [Xu, Xing; Wu, Haiping; Yang, Yang; Shen, Fumin; Xie, Ning; Ji, Yanli] Univ Elect Sci & Technol China, Ctr Future Media, Chengdu, Sichuan, Peoples R China.
   [Xu, Xing; Wu, Haiping; Yang, Yang; Shen, Fumin; Xie, Ning; Ji, Yanli] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu, Sichuan, Peoples R China.
C3 Guizhou University; University of Electronic Science & Technology of
   China; University of Electronic Science & Technology of China
RP Xu, X (corresponding author), Guizhou Univ, Guizhou Prov Key Lab Publ Big Data, Guiyang, Guizhou, Peoples R China.; Xu, X (corresponding author), Univ Elect Sci & Technol China, Ctr Future Media, Chengdu, Sichuan, Peoples R China.; Xu, X (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu, Sichuan, Peoples R China.
EM xing.xu@uestc.edu.cn; haipingwoo@gmail.com; dlyyang@gmail.com;
   fumin.shen@gmail.com; seanxiening@gmail.com; yanliji@uestc.edu.cn
RI Lang, Ming/HIK-0758-2022; yang, yang/HGT-7999-2022; yang,
   yang/GVT-5210-2022
FU National Science Foundation of China [61572108, 61602089, 61502081,
   61632007]; Fundamental Research Funds for the Central Universities
   [ZYGX2014Z007, ZYGX2015J055]; 111 Project [B17008]
FX This work was supported in part by the National Science Foundation of
   China under Project 61572108, Project 61602089, Project 61502081,
   Project 61632007, and the Fundamental Research Funds for the Central
   Universities under Project ZYGX2014Z007, Project ZYGX2015J055 and the
   111 Project No. B17008.
CR [Anonymous], ICIMCS
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], 2013, P INT ACM C MULTIMED, DOI DOI 10.1145/2502081.2502093
   [Anonymous], CVPR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2009, NEURIPS
   Chiang CK, 2013, IEEE I CONF COMP VIS, P1137, DOI 10.1109/ICCV.2013.145
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Farhadi A, 2010, PROC CVPR IEEE, P2352, DOI 10.1109/CVPR.2010.5539924
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   Hu MQ, 2018, IEEE T IMAGE PROCESS, V27, P545, DOI 10.1109/TIP.2017.2749147
   Hu MQ, 2017, IEEE T IMAGE PROCESS, V26, P4871, DOI 10.1109/TIP.2017.2717185
   Jacob L., 2009, P 26 ANN INT C MACH, P433, DOI DOI 10.1145/1553374.1553431
   Kang WC, 2016, AAAI CONF ARTIF INTE, P1230
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Li C, 2016, MULTIMED TOOLS APPL, V75, P7029, DOI 10.1007/s11042-015-2630-5
   Liu J., 2013, SLEP: Sparse Learning with Efficient Projections
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Luo YD, 2018, PATTERN RECOGN, V75, P128, DOI 10.1016/j.patcog.2017.02.034
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Ouyang WL, 2015, IEEE I CONF COMP VIS, P1895, DOI 10.1109/ICCV.2015.220
   Ri CY, 2015, MULTIMED TOOLS APPL, V74, P4965, DOI 10.1007/s11042-014-1858-9
   Shenghua Gao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2809, DOI 10.1109/CVPR.2011.5995454
   Shih T.K., 2002, DISTRIBUTED MULTIMED
   Simonyan K., 2014, 14091556 ARXIV
   Tang J, 2014, COMPUT VIS IMAGE UND, V124, P91, DOI 10.1016/j.cviu.2014.02.007
   Tibshirani R, 2011, J R STAT SOC B, V73, P273, DOI 10.1111/j.1467-9868.2011.00771.x
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wu L, 2017, IEEE T CYBERNETICS, V47, P4497, DOI 10.1109/TCYB.2016.2612686
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   Yang BQ, 2017, MULTIMED TOOLS APPL, V76, P8969, DOI 10.1007/s11042-016-3492-1
   Yang Y, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1286, DOI 10.1145/2964284.2964319
   Yang Y, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P59, DOI 10.1145/2733373.2806244
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yang Y, 2012, IEEE T IMAGE PROCESS, V21, P1339, DOI 10.1109/TIP.2011.2169269
   Yuan M., 2006, Journal of the Royal Statistical Society, Series B, V70, P53
   Zhang HW, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P325, DOI 10.1145/2911451.2911502
   Zhang ST, 2012, IEEE T SYST MAN CY B, V42, P838, DOI 10.1109/TSMCB.2011.2179533
NR 41
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22185
EP 22198
DI 10.1007/s11042-018-5796-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500024
DA 2024-07-18
ER

PT J
AU Zhang, YD
   Zhao, GH
   Sun, JD
   Wu, XS
   Wang, ZH
   Liu, HM
   Govindaraj, VV
   Zhan, TM
   Li, JW
AF Zhang, Yu-Dong
   Zhao, Guihu
   Sun, Junding
   Wu, Xiaosheng
   Wang, Zhi-Heng
   Liu, Hong-Min
   Govindaraj, Vishnu Varthanan
   Zhan, Tianmin
   Li, Jianwu
TI Smart pathological brain detection by synthetic minority oversampling
   technique, extreme learning machine, and Jaya algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pathological brain detection; Synthetic minority oversampling; Extreme
   learning machine; Jaya algorithm
ID OPTIMIZATION; ENTROPY; MODEL
AB Pathological brain detection is an automated computer-aided diagnosis for brain images. This study provides a novel method to achieve this goal.We first used synthetic minority oversampling to balance the dataset. Then, our system was based on three components: wavelet packet Tsallis entropy, extreme learning machine, and Jaya algorithm. The 10 repetitions of K-fold cross validation showed our method achieved perfect classification on two small datasets, and achieved a sensitivity of 99.64 +/- 0.52%, a specificity of 99.14 +/- 1.93%, and an accuracy of 99.57 +/- 0.57% over a 255-image dataset. Our method performs better than six state-of-the-art approaches. Besides, Jaya algorithm performs better than genetic algorithm, particle swarm optimization, and bat algorithm as ELM training method.
C1 [Zhang, Yu-Dong; Sun, Junding; Wu, Xiaosheng; Wang, Zhi-Heng; Liu, Hong-Min] Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454000, Henan, Peoples R China.
   [Zhao, Guihu] Cent S Univ, Sch Informat Sci & Engn, Changsha 410083, Hunan, Peoples R China.
   [Govindaraj, Vishnu Varthanan] Kalasalingam Univ, Dept Instrumentat & Control Engn, Virudunagar, Tamil Nadu, India.
   [Zhan, Tianmin] Nanjing Audit Univ, Sch Technol, Nanjing 211815, Jiangsu, Peoples R China.
   [Li, Jianwu] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
C3 Henan Polytechnic University; Central South University; Kalasalingam
   Academy of Research & Education; Nanjing Audit University; Beijing
   Institute of Technology
RP Zhang, YD (corresponding author), Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454000, Henan, Peoples R China.; Govindaraj, VV (corresponding author), Kalasalingam Univ, Dept Instrumentat & Control Engn, Virudunagar, Tamil Nadu, India.; Zhan, TM (corresponding author), Nanjing Audit Univ, Sch Technol, Nanjing 211815, Jiangsu, Peoples R China.; Li, JW (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
EM yudongzhang@ieee.org; gvvarthanan@gmail.com; ztm@ujs.edu.cn;
   ljw@bit.edu.cn
RI ZHU, JIALI/JNE-3065-2023; Govindaraj, Vishnuvarthanan/AAE-7400-2020;
   Zhang, Yudong/I-7633-2013
OI Liu, Hongmin/0000-0001-9834-4087; Zhang, Yudong/0000-0002-4870-1493;
   govindaraj, vishnuvarthanan/0000-0001-9136-3461
FU Natural Science Foundation of China [61602250]; Natural Science
   Foundation of Jiangsu Province [BK20150983]; Key Laboratory of Guangxi
   High Schools Complex System and Computational Intelligence [2016CSCI01];
   Open fund for Jiangsu Key Laboratory of Advanced Manufacturing
   Technology [HGAMTL1601]
FX The paper is supported by Natural Science Foundation of China
   (61602250), Natural Science Foundation of Jiangsu Province (BK20150983),
   Open fund of Key Laboratory of Guangxi High Schools Complex System and
   Computational Intelligence (2016CSCI01), Open fund for Jiangsu Key
   Laboratory of Advanced Manufacturing Technology (HGAMTL1601).
CR Chen K, 2017, NEUROCOMPUTING, V230, P345, DOI 10.1016/j.neucom.2016.12.029
   Das S, 2013, PROG ELECTROMAGN RES, V137, P1, DOI 10.2528/PIER13010105
   Doreswamy, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT), P501, DOI 10.1109/ICATCCT.2015.7456936
   Hazlett HC, 2017, NATURE, V542, P348, DOI 10.1038/nature21369
   Huo Y, 2016, C MED IM IM PROC SAN
   Huo YK, 2017, HUM BRAIN MAPP, V38, P599, DOI 10.1002/hbm.23432
   Huo Y, 2016, NEUROIMAGE, V138, P197, DOI 10.1016/j.neuroimage.2016.05.030
   Li H, 2015, VLDB J, V24, P117, DOI 10.1007/s00778-014-0366-x
   Lu ZH, 2016, J MED IMAG HEALTH IN, V6, P1218, DOI 10.1166/jmihi.2016.1901
   Mavaddaty S, 2017, COMPUT SPEECH LANG, V44, P22, DOI 10.1016/j.csl.2017.01.009
   Mustafa N, 2017, INT J ADV COMPUT SC, V8, P61
   Oyedotun O, 2017, TURK J ELECTR ENG CO, V25, P1106, DOI 10.3906/elk-1507-190
   Rao RV, 2011, COMPUT AIDED DESIGN, V43, P303, DOI 10.1016/j.cad.2010.12.015
   Rong YM, 2016, INT J ADV MANUF TECH, V87, P2943, DOI 10.1007/s00170-016-8649-6
   Tsallis C, 2009, EUR PHYS J A, V40, P257, DOI 10.1140/epja/i2009-10799-0
   Wang HN, 2018, MULTIMED TOOLS APPL, V77, P3871, DOI 10.1007/s11042-016-4242-0
   Wang M, 2016, IEEE T KNOWL DATA EN, V28, P3068, DOI 10.1109/TKDE.2016.2580138
   Wang SH, 2017, FUND INFORM, V151, P275, DOI 10.3233/FI-2017-1492
   Wang SH, 2016, PROG ELECTROMAGN RES, V156, P105
   Wang SH, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6060169
   Wang SH, 2015, ENTROPY-SWITZ, V17, P6663, DOI 10.3390/e17106663
   Yadav B, 2016, J HYDROL, V543, P373, DOI 10.1016/j.jhydrol.2016.10.013
   Ying ZB, 2016, SCI CHINA INFORM SCI, V59, DOI 10.1007/s11432-015-5428-1
   Yüksel T, 2017, EXPERT SYST APPL, V72, P344, DOI 10.1016/j.eswa.2016.10.048
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P10521, DOI 10.1007/s11042-017-4554-8
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P21825, DOI 10.1007/s11042-017-4383-9
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22589, DOI 10.1007/s11042-017-4703-0
   Zhang YD, 2016, IEEE ACCESS, V4, P5937, DOI 10.1109/ACCESS.2016.2611530
   Zhang YD, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1523-4
   Zhang YD, 2017, CNS NEUROL DISORD-DR, V16, P122, DOI 10.2174/1871527315666161026115046
   Zhang YD, 2016, SIMUL-T SOC MOD SIM, V92, P861, DOI 10.1177/0037549716666962
   Zhang YD, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0525-2
   Zhang YD, 2015, PROG ELECTROMAGN RES, V152, P41, DOI 10.2528/PIER15040602
   Zhang YD, 2015, BIO-MED MATER ENG, V26, pS1283, DOI 10.3233/BME-151426
   Zhang YD, 2015, BIOMED SIGNAL PROCES, V21, P58, DOI 10.1016/j.bspc.2015.05.014
   Zhang YD, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00066
   Zhang YD, 2015, ENTROPY-SWITZ, V17, P1795, DOI 10.3390/e17041795
   Zhou XX, 2016, IEEJ T ELECTR ELECTR, V11, P364, DOI 10.1002/tee.22226
NR 38
TC 96
Z9 97
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22629
EP 22648
DI 10.1007/s11042-017-5023-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500047
DA 2024-07-18
ER

PT J
AU Zhou, JS
   Narentuya
   Tang, S
   Liu, J
AF Zhou, Jianshe
   Narentuya
   Tang, Sheng
   Liu, Jie
TI Hierarchical BoW with segmental sparse coding for large scale image
   classification and retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bag of words; Dictionary learning; Sparse coding; Image retrieval; Image
   classification
AB The bag-of-words (BoW) has been widely regarded as the most successful algorithms for content-based image related tasks, such as large scale image retrieval, classification, and object categorization. Large visual words acquired by BoW quantization through large vocabulary or codebooks have been receiving much attention in the past years. However, not only construction of large vocabulary but also the quantization process impose a heavy burden in terms of time and memory complexities. In order to tackle this issue, we propose an efficient hierarchical BoW (HBoW) to achieve large visual words through quantization by a compact vocabulary instead of large vocabulary. Our vocabulary is very compact since it is only composed of two small dictionaries which is learned through segmental sparse decomposition of local features. To generate the BoW with large size, we first divide the local features into two half parts, and use the two small dictionaries to compute their sparse codes. Then, we map the two indices of the maximum elements of the two sparse codes to a large set of visual words based upon the fact that data with similar properties will share the same base weighted with the largest sparse coefficient. To further make similar patches have higher probability of select the same dictionary base to get similar BoW vectors, we propose a novel collaborative dictionary learning method by imposing the similarity regularization factor together with the row sparsity regularization across data instances during group sparse coding. Additionally, based on index combination of top-2 large sparse codes of local descriptors, we propose a soft BoW assignment method so that our proposed HBoW can tolerate different word selection for similar patches. By employing the inverted file structure built through our HBoW, K-nearest neighbors (KNN) can be efficiently retrieved. After incorporation of our fast KNN search into the SVM-KNN classification method, our HBoW can be used for efficient image classification and logo recognition. Experiments on serval well-known datasets show that our approach is effective for large scale image classification and retrieval.
C1 [Zhou, Jianshe; Narentuya] Capital Normal Univ, Beijing Adv Innovat Ctr Imaging Technol, Beijing 100048, Peoples R China.
   [Tang, Sheng] Chinese Acad Sci, Inst Comp Technol, Beijing 100190, Peoples R China.
   [Liu, Jie] Capital Normal Univ, Coll Informat & Engn, Beijing 100048, Peoples R China.
C3 Capital Normal University; Chinese Academy of Sciences; Institute of
   Computing Technology, CAS; Capital Normal University
RP Liu, J (corresponding author), Capital Normal Univ, Coll Informat & Engn, Beijing 100048, Peoples R China.
EM cnu_zhoujianshe@126.com; nrty0910@163.com; ts@ict.ac.cn;
   liujie@cnu.edu.cn
FU National Nature Science Foundation of China [61371194, 61672361];
   Beijing Natural Science Foundation [4152012]; Beijing Advanced
   Innovation Center for Imaging Technology [BAICIT-2016009]
FX This work was supported by National Nature Science Foundation of China
   (61371194, 61672361), Beijing Natural Science Foundation (4152012),
   Beijing Advanced Innovation Center for Imaging Technology
   (BAICIT-2016009)
CR [Anonymous], P 21 ACM INT C MULT
   [Anonymous], 2007, P 2007 IEEE C COMPUT
   [Anonymous], P ECCV
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], ACM MULTIMEDIA 10
   [Anonymous], IEEE SIGNAL PROCESSI
   [Anonymous], P TRECVID 2008 WORKS
   [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   Chua Tat-Seng, 2009, P ACM MULT 2009 WORK
   Deng J, 2010, LECT NOTES COMPUT SC, V6315, P71, DOI 10.1007/978-3-642-15555-0_6
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Girod B, 2011, IEEE SIGNAL PROC MAG, V28, P61, DOI 10.1109/MSP.2011.940881
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jégou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2
   Jiang YG, 2010, IEEE T MULTIMEDIA, V12, P42, DOI 10.1109/TMM.2009.2036235
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li PH, 2015, PROC CVPR IEEE, P2348, DOI 10.1109/CVPR.2015.7298848
   Li Y, 2018, IEEE T IMAGE PROCESS, V27, P1561, DOI 10.1109/TIP.2017.2779270
   Liu J, 2017, LECT NOTES COMPUT SC, V10132, P443, DOI 10.1007/978-3-319-51811-4_36
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Mikulik A, 2013, INT J COMPUT VISION, V103, P163, DOI 10.1007/s11263-012-0600-1
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Nie L, 2012, P ACM MULT 2012 C
   Nister David, 2006, CVPR
   Philbin J., 2008, P C COMP VIS PATT RE
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Strelow D, 2009, NEURAL INFORM PROCES
   Tang J, 2015, IEEE ICC, P1, DOI 10.1109/ICC.2015.7248289
   Tang S, 2017, IEEE T MULTIMEDIA, V19, P2105, DOI 10.1109/TMM.2017.2729786
   Tang S, 2015, IEEE IMAGE PROC, P1170, DOI 10.1109/ICIP.2015.7350984
   Tang S, 2015, NEUROCOMPUTING, V169, P124, DOI 10.1016/j.neucom.2014.09.100
   Tang S, 2012, IEEE T MULTIMEDIA, V14, P43, DOI 10.1109/TMM.2011.2168198
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Wu C., 2007, Siftgpu: A gpu implementation of david lowe's scale invariant feature transform (sift)
   Xie HT, 2011, IEEE T MULTIMEDIA, V13, P1319, DOI 10.1109/TMM.2011.2167224
   Yang J., 2009, P C COMP VIS PATT RE
   Zhang H., 2006, 2006 IEEE COMP SOC C, V2, P2126, DOI DOI 10.1109/CVPR.2006.301
   Zhang YD, 2014, COMPUT VIS IMAGE UND, V124, P3, DOI 10.1016/j.cviu.2014.01.011
NR 38
TC 2
Z9 2
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22319
EP 22338
DI 10.1007/s11042-018-5955-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500032
DA 2024-07-18
ER

PT J
AU Ahmed, T
   Sarma, M
AF Ahmed, Tauheed
   Sarma, Monalisa
TI An advanced fingerprint matching using minutiae-based indirect local
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Image processing; Minutiae triplet; Feature extraction;
   Fingerprint identification
ID SYSTEM
AB Biometric systems examine the uniqueness of an individual based on physical and behavioral characteristics. Among the known traits, fingerprint is the most significant biometric trait due to its ease of use and high accuracy. However, the efficiency of the fingerprint matching technique depends on the feature vector it uses. The ideal feature vector should be invariant to several common transformations, which usually a fingerprint capturing system is subjected to. Current work focuses to achieve such an invariance by extracting the features based on the spatial relationship among minutiae points. We propose a minutiae point based 4-dimensional local feature vector, which simultaneously satisfies six desirable feature vector properties. This feature vector definition helps us to deal with problem of missing and spurious minutiae and thus enables us to design a robust authentication system. We have substantiated the efficacy of the proposed approach with the help of a number of fingerprint instances available in FVC and NIST databases.
C1 [Ahmed, Tauheed; Sarma, Monalisa] IIT Kharagpur, Subir Chowdhury Sch Qual & Reliabil, Kharagpur, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Ahmed, T (corresponding author), IIT Kharagpur, Subir Chowdhury Sch Qual & Reliabil, Kharagpur, W Bengal, India.
EM tauheed.ahmd@iitkgp.ac.in
RI Ahmed, Tauheed/S-7335-2019; Ahmed, Tauheed/HGE-4543-2022
OI Ahmed, Tauheed/0000-0003-0447-7343
CR Abe N, 2015, INT CONF BIOMETR, P408, DOI 10.1109/ICB.2015.7139103
   Medina-Pérez MA, 2012, SENSORS-BASEL, V12, P3418, DOI 10.3390/s120303418
   [Anonymous], 2012, MINUTIAE BASED FINGE
   [Anonymous], ARXIV160908417
   [Anonymous], 2000, P WORKSH CIRC SYST S
   Barman S, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY (ICIT), P179, DOI 10.1109/ICIT.2014.46
   Bazen A.M., 2002, KLUWER INT SER ENG C, P23
   Bebis G., 1999, Proceedings 1999 International Conference on Information Intelligence and Systems (Cat. No.PR00446), P452, DOI 10.1109/ICIIS.1999.810315
   Cappelli R, 2010, IEEE T PATTERN ANAL, V32, P2128, DOI 10.1109/TPAMI.2010.52
   Chau AC, 2011, LECT NOTES COMPUT SC, V7042, P692, DOI 10.1007/978-3-642-25085-9_82
   Chen W., 2007, PROC IEEE C DIGITAL, P233
   Chen XJ, 2006, IEEE T INF FOREN SEC, V1, P169, DOI 10.1109/TIFS.2006.873605
   Fan LL, 2008, IEEE T PATTERN ANAL, V30, P929, DOI 10.1109/TPAMI.2008.31
   Feng YS, 2006, INT C PATT RECOG, P374
   Fernandez-Saavedra B, 2016, IET BIOMETRICS, V5, P28, DOI 10.1049/iet-bmt.2015.0018
   Hoyle K., 2011, THESIS
   HRECHAK AK, 1990, PATTERN RECOGN, V23, P893, DOI 10.1016/0031-3203(90)90134-7
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996
   Jain A.K., 2013, Security and Privacy in Biometrics, P187
   Jain AK, 1997, P IEEE, V85, P1365, DOI 10.1109/5.628674
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jain A, 2006, INT C PATT RECOG, P477
   Jayaraman U, 2014, NEUROCOMPUTING, V137, P115, DOI 10.1016/j.neucom.2013.02.059
   Jea TY, 2005, PATTERN RECOGN, V38, P1672, DOI 10.1016/j.patcog.2005.03.016
   Jiang XD, 2000, INT C PATT RECOG, P1038, DOI 10.1109/ICPR.2000.906252
   Khodadoust J, 2017, PATTERN RECOGN, V67, P110, DOI 10.1016/j.patcog.2017.01.022
   Li QF, 2018, NEURAL COMPUT APPL, V30, P463, DOI 10.1007/s00521-016-2680-2
   Liang RZ, 2016, INT C PATT RECOG, P2954, DOI 10.1109/ICPR.2016.7900086
   Lindoso A., 2007, LECT NOTES COMPUTER, V4642
   Liu LM, 2008, INT J PATTERN RECOGN, V22, P347, DOI 10.1142/S0218001408006211
   Liu N, 2005, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - PROCEEDINGS, P591, DOI 10.1109/CIT.2005.9
   Maltoni D., 2009, HDB FINGERPRINT RECO
   Moon YS, 2000, 2000 CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING, CONFERENCE PROCEEDINGS, VOLS 1 AND 2, P108, DOI 10.1109/CCECE.2000.849680
   NBIS, NBIS TECHN POC NIST
   Ratha NK, 1996, IEEE T PATTERN ANAL, V18, P799, DOI 10.1109/34.531800
   RAVI J., 2009, INT J ENG SCI TECHNO, V1, P35
   Reisman J, 2005, LECT NOTES COMPUT SC, V3546, P720
   Tiwari K, 2015, IEEE IMAGE PROC, P4773, DOI 10.1109/ICIP.2015.7351713
   Wahab A, 1998, IEE P-VIS IMAGE SIGN, V145, P160, DOI 10.1049/ip-vis:19981809
   Wang X, 2004, LECT NOTES COMPUTER, V3072
   Wang XY, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 4, P189, DOI 10.1109/ICICISYS.2009.5357702
   Watson C., 1992, NIST special database 4: 8-bit gray images of fingerprint image groups
   Weisstein EW, CIRCUMRADIUS MATHWOR
   Weisstein EW, INRADIUS MATHWORLD A
   Xu W, 2007, LECT NOTES COMPUTER, V4642
   Yao ZG, 2016, IET BIOMETRICS, V5, P243, DOI 10.1049/iet-bmt.2015.0027
NR 47
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19931
EP 19950
DI 10.1007/s11042-017-5444-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500047
DA 2024-07-18
ER

PT J
AU Gupta, B
   Singh, AK
AF Gupta, Bhupendra
   Singh, Anuj Kumar
TI A new computational approach for edge-preserving image decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image decomposition; Cartoon part; Texture part; DCT (discrete cosine
   transform); Joint bilateral filter
ID MINIMIZATION; CARTOON
AB Decomposition of an image into its cartoon part and texture part has been an interesting area of research. It is an important pre-processing step in many computer vision and image processing techniques such as image segmentation, pattern matching, object recognition, tone mapping as both cartoon and texture parts contain two different kinds of information. Significant work is already available in the literature. At the time of decomposition of an input image into its cartoon and texture part, we required texture-smoothing along with edge-preservation. Most of the approaches available in the literature establish a trade-off between the edge preservation and the texture-smoothing. This common drawback of the existing approaches motivates us to design a new image decomposition method by which we can achieve texture-smoothing without having any loss of edge information in cartoon part. To achieve this aim we introduce a new approach based on Joint bilateral filter and DCT (Discrete cosine transform). We show experimental results on several images to show the effectiveness of our method and comparison with some state-of-the-art methods.
C1 [Gupta, Bhupendra; Singh, Anuj Kumar] Indian Inst Informat Technol Design & Mfg, Jabalpur 482005, MP, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Gupta, B (corresponding author), Indian Inst Informat Technol Design & Mfg, Jabalpur 482005, MP, India.
EM gupta.bhupendra@gmail.com
RI Gupta, Bhupendra/ABD-4884-2020
OI Gupta, Bhupendra/0000-0001-5293-4401
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Aujol JF, 2006, INT J COMPUT VISION, V67, P111, DOI 10.1007/s11263-006-4331-z
   Aujol JF, 2003, LECT NOTES COMPUT SC, V2695, P297
   Buades A, 2010, IEEE T IMAGE PROCESS, V19, P1978, DOI 10.1109/TIP.2010.2046605
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Fattal R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531328
   Feng L, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013027
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Karacan L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508403
   Le Guen V, 2014, IMAGE PROCESS ON LIN, V4, P204, DOI 10.5201/ipol.2014.103
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   [冷璐 LENG Lu], 2010, [微电子学与计算机, Microelectronics & Computer], V27, P38
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Meyer Y., 2001, OSCILLATING PATTERNS, V22
   Mohanaiah P, 2013, INT J SCI RES PUBL, V3, P122
   Ono S, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2299067
   Paris S, 2009, INT J COMPUT VISION, V81, P24, DOI 10.1007/s11263-007-0110-8
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Su Z, 2013, VISUAL COMPUT, V29, P1011, DOI 10.1007/s00371-012-0753-5
   Subr K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618493
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Vese LA, 2003, J SCI COMPUT, V19, P553, DOI 10.1023/A:1025384832106
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiaolei Jiang, 2013, Advances in Multimedia Information Processing - PCM 2013. 14th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8294, P190, DOI 10.1007/978-3-319-03731-8_18
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
NR 27
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19527
EP 19546
DI 10.1007/s11042-017-5401-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500029
DA 2024-07-18
ER

PT J
AU Kok, VJ
   Chan, CS
AF Kok, Ven Jyn
   Chan, Chee Seng
TI Granular-based dense crowd density estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dense crowd analysis; Density estimation; Texture features; Visual
   surveillance
ID SCALE
AB Dense crowd density estimation is one of the fundamental tasks in crowd analysis. While tremendous progress has been made to understand crowd scenes along with the rise of Convolutional Neural Networks (CNNs), research work on dense crowd density estimation is still an ongoing process. In this paper, we propose a novel approach to learn discriminative crowd features from granules, that conforms to the outline between crowd and background (i.e. non-crowd) regions, for density estimation. It shows that by studying the inner statistics of granules for density estimation, this approach is adaptive to arbitrary distribution of crowd (i.e. scene independent). Multiple features fusion is proposed to learn discriminative crowd features from granules. This is to be used as description of the crowd where a direct mapping between the features and crowd density is learned. Extensive experiments on public benchmark datasets demonstrate the effectiveness of our novel approach for scene independent dense crowd density estimation.
C1 [Kok, Ven Jyn] Natl Univ Malaysia, Fac Informat Sci & Technol, Bangi 43600, Selangor, Malaysia.
   [Chan, Chee Seng] Univ Malaya, Fac Comp Sci & Informat Technol, Ctr Image & Signal Proc, Kuala Lumpur 50603, Malaysia.
C3 Universiti Kebangsaan Malaysia; Universiti Malaya
RP Kok, VJ (corresponding author), Natl Univ Malaysia, Fac Informat Sci & Technol, Bangi 43600, Selangor, Malaysia.
EM vj.kok@ukm.edu.my; cs.chan@um.edu.my
RI Chan, Chee Seng/B-9754-2011; Kok, Ven Jyn/AAB-8493-2019
OI Chan, Chee Seng/0000-0001-7677-2865; 
FU GGPM grant from the National University of Malaysia (UKM)
   [GGPM-2017-024]; Fundamental Research Grant Scheme (FRGS) MoHE Grant
   from the Ministry of Education Malaysia [FP070-2015A]
FX This research is supported by the GGPM grant GGPM-2017-024, from the
   National University of Malaysia (UKM); and Chee Seng Chan is supported
   by the Fundamental Research Grant Scheme (FRGS) MoHE Grant FP070-2015A,
   from the Ministry of Education Malaysia.
CR Ali S., 2013, Modeling, Simulation and Visual Analysis of Crowds, P1, DOI DOI 10.1007/978-1-4614-8483-7
   Ali S, 2007, PROC CVPR IEEE, P65
   [Anonymous], 1997, Image Processing for Security Applications, DOI DOI 10.1049/IC:19970387
   [Anonymous], BUSINESS INSIDER
   [Anonymous], WORLD POP PROSP 2012
   [Anonymous], 2013, Modeling, Simulation and Visual Analysis of Crowds: A Multidisciplinary Perspective
   [Anonymous], 2014, FULLY CONVOLUTIONAL
   [Anonymous], ANAL CROWDED SCENES
   [Anonymous], 2014, REV WORLD URB PROSP
   [Anonymous], 2006, COMPUTER VISION PATT, DOI 10.1109/CVPR.2006.92
   Bolei Zhou, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3441, DOI 10.1109/CVPR.2011.5995459
   Chan A. B., 2008, IEEE C COMPUTER VISI, P1
   Chan AB, 2012, IEEE T IMAGE PROCESS, V21, P2160, DOI 10.1109/TIP.2011.2172800
   Chan AB, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995688
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Chen K, 2013, PROC CVPR IEEE, P2467, DOI 10.1109/CVPR.2013.319
   DAVIES AC, 1995, ELECTRON COMMUN ENG, V7, P37, DOI 10.1049/ecej:19950106
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Fu HY, 2014, MULTIMED TOOLS APPL, V73, P273, DOI 10.1007/s11042-013-1608-4
   Ge Weina, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2913, DOI 10.1109/CVPRW.2009.5206621
   Grant JM, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3052930
   Helbing D, 2015, J STAT PHYS, V158, P735, DOI 10.1007/s10955-014-1024-9
   Helbing D, 2012, EPJ DATA SCI, V1, DOI 10.1140/epjds7
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Kae A, 2013, PROC CVPR IEEE, P2019, DOI 10.1109/CVPR.2013.263
   Kaiman J, 2015, GUARDIAN
   Kok VJ, 2017, IEEE T CYBERNETICS, V47, P1157, DOI 10.1109/TCYB.2016.2538765
   Kok VJ, 2016, NEUROCOMPUTING, V177, P342, DOI 10.1016/j.neucom.2015.11.021
   Kovesi P.D., 1999, Videre: Journal of Computer Vision Research, V1
   Lempitsky V., 2010, P ADV NEUR INF PROC, V23, P1, DOI DOI 10.5555/2997189.2997337
   Lim MK, 2014, INT C PATT RECOG, P3957, DOI 10.1109/ICPR.2014.678
   Liu LW, 2012, INT C PATT RECOG, P2222
   Lloyd CD., 2006, Local models for spatial statistics
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marana AN, 1998, SAFETY SCI, V28, P165, DOI 10.1016/S0925-7535(97)00081-7
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   MORRONE MC, 1987, PATTERN RECOGN LETT, V6, P303, DOI 10.1016/0167-8655(87)90013-4
   Mousse MA, 2017, MULTIMED TOOLS APPL, V76, P6801, DOI 10.1007/s11042-016-3352-z
   OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022
   Rodriguez M, 2011, IEEE I CONF COMP VIS, P2423, DOI 10.1109/ICCV.2011.6126526
   Ryan D, 2015, COMPUT VIS IMAGE UND, V130, P1, DOI 10.1016/j.cviu.2014.07.008
   Shao J, 2015, PROC CVPR IEEE, P4657, DOI 10.1109/CVPR.2015.7299097
   Shawe-Taylor J., 2004, KERNEL METHODS PATTE
   Solmaz B, 2012, IEEE T PATTERN ANAL, V34, P2064, DOI 10.1109/TPAMI.2012.123
   Tuytelaars T, 2010, PROC CVPR IEEE, P2281, DOI 10.1109/CVPR.2010.5539911
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
NR 51
TC 3
Z9 3
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 20227
EP 20246
DI 10.1007/s11042-017-5418-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500059
DA 2024-07-18
ER

PT J
AU Rodríguez, A
   Boada, I
   Sbert, M
AF Rodriguez, Antonio
   Boada, Imma
   Sbert, Mateu
TI An Arduino-based device for visually impaired people to play videogames
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interacion devices; Video games; Visually impaired
ID TRAVEL AID; BLIND; MOBILITY; TECHNOLOGY; VISION
AB Blind players have many difficulties to access video games since most of them rely on impressive graphics and immersive visual experiences. To overcome this limitation, we propose a device designed for visually impaired people to interact with virtual scenes of video games. The device has been designed considering usability, economic cost, and adaptability as main features. To ensure usability, we considered the white cane paradigm since this is the most used device by the blind community. Our device supports left to right movements and collision detection as well as actions to manipulate scene objects such as drag and drop. To enhance realism, it also integrates a library with sounds of different materials to reproduce object collision. To reduce the economic cost, we used Arduino as the basis of our development. Finally, to ensure adaptability, we created an application programming interface that supports the connection with different games engines and different scenarios. To test the acceptance of the device 12 blind participants were considered (6 males and 6 females). In addition, we created three mini-games in Unity3D that require navigation and walking as principal actions. After playing, participants filled a questionnaire related to usability and suitability to interact with games, among others. They scored well in all features without distinction among player gender and being blind from birth. The relationship between device responsiveness and user interaction has been considered satisfactory. Despite our small test sample, our main goal has been accomplished, the proposed device prototype seems to be useful to visually impaired people.
C1 [Rodriguez, Antonio; Boada, Imma; Sbert, Mateu] Univ Girona, Graph & Imaging Lab, Girona, Spain.
   [Sbert, Mateu] Dept Comp Sci & Technol, Tianjin, Peoples R China.
C3 Universitat de Girona
RP Boada, I (corresponding author), Univ Girona, Graph & Imaging Lab, Girona, Spain.
EM antonio.rodriguez@udg.edu; imma.boada@udg.edu; mateu.sbert@udg.edu
RI Boada, Imma/M-2877-2018; Rodriguez Benitez, Antonio/GNM-7508-2022;
   Sbert, Mateu/G-6711-2011
OI Boada, Imma/0000-0002-0001-8193; Rodriguez Benitez,
   Antonio/0000-0002-2437-618X; 
FU Catalan Government [2014-SGR-1232]; Spanish Government
   [TIN2016-75866-C3-3-R]
FX This work was supported by the Catalan Government (Grant No.
   2014-SGR-1232) and by the Spanish Government (Grant No.
   TIN2016-75866-C3-3-R).
CR Abdel-Wahab A.G., 2011, MOBILE INFORM COMMUN
   [Anonymous], 2010, Wearable and Autonomous Biomedical Devices and Systems for Smart Environment: Issues and Characterization, DOI DOI 10.1007/978-3-642-15687-8_17
   Archambault D, 2004, LECT NOTES COMPUT SC, V3118, P248
   Archambault D., Computer Games and Visually Impaired People
   BACH P, 1969, NATURE, V221, P963, DOI 10.1038/221963a0
   Balan Oana., 2015, International Journal_on_Disability_and_Human_Development, V14, P109, DOI DOI 10.1515/IJDHD-2014-0018
   Brewster S. A., 1998, ACM Transactions on Computer-Human Interaction, V5, P224, DOI 10.1145/292834.292839
   Card S. K., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P181, DOI 10.1145/108844.108874
   Csapó A, 2015, J MULTIMODAL USER IN, V9, P275, DOI 10.1007/s12193-015-0182-7
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cuturi LF, 2016, NEUROSCI BIOBEHAV R, V71, P240, DOI 10.1016/j.neubiorev.2016.08.019
   Dabrowski J, 2011, INTERACT COMPUT, V23, P555, DOI 10.1016/j.intcom.2011.05.008
   Damaschini R, 2005, ASSIST TECHN RES SER, V16, P251
   El Saddik Abdulmotaleb, 2012, HAPTICS RENDERING AP
   Farcy R, 2003, ASSIST TECHN RES SER, V12, P113
   Friberg Johnny., 2004, ACE 04, P148
   Ghali NI, 2012, INTEL SYST REF LIBR, V26, P363
   Gori M, 2016, NEUROSCI BIOBEHAV R, V69, P79, DOI 10.1016/j.neubiorev.2016.06.043
   Gutschmidt R, 2010, P 3 INT C PERV TECHN
   Hakobyan L, 2013, SURV OPHTHALMOL, V58, P513, DOI 10.1016/j.survophthal.2012.10.004
   Heuten W, 2007, AUD MOSTL P C INT SO
   Hossain Eklas, 2011, International Journal of Biomechatronics and Biomedical Robotics, V1, P232, DOI 10.1504/IJBBR.2011.043751
   Kajimoto H, 2003, 11TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS - HAPTICS 2003, PROCEEDINGS, P40, DOI 10.1109/HAPTIC.2003.1191225
   Kay L, 2000, J ACOUST SOC AM, V107, P3266, DOI 10.1121/1.429399
   Kim J, 2011, ASSETS 11: PROCEEDINGS OF THE 13TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P285
   Kim S., 2016, P 2016 CHI C HUM FAC, P1922, DOI [10.1145/2851581.2892510, DOI 10.1145/2851581.2892510]
   Lacey G, 1995, TCDCS9518
   Leonard R., 2002, Statistics on Vision Impairment: A Resource Manual
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2010, INT C VIRT SYST MULT
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Magnusson C, 2002, P EUR  2002 ED
   Maidenbaum S, 2014, EFFECT EXPANDED SENS
   Manduchi R., 2018, Assistive technology for blindness and low vision
   Manduchi R., 2011, INSIGHT RES PRACTICE, V4, P44
   Manduchi R, 2012, COMMUN ACM, V55, P96, DOI 10.1145/2063176.2063200
   Mau S, 2008, CMURITR0739
   Miller D, 2007, ASSETS'07: PROCEEDINGS OF THE NINTH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P253
   Miller R.B., 1968, ASS COMPUTING MACHIN, P267, DOI [10.1109/afips.1968.149, DOI 10.1109/AFIPS.1968.149, 10.1145/1476589.1476628, DOI 10.1145/1476589.1476628]
   Milne LR., 2014, Proceedings of the 16th International ACM SIGACCESS Conference on Computers Accessibility, P137, DOI [10.1145/2661334.2661377, DOI 10.1145/2661334.2661377]
   Morelli T., 2010, P 5 INT C FDN DIG GA, P147, DOI [10.1145/1822348.1822368, DOI 10.1145/1822348.1822368]
   Morelli T, 2010, ASSETS 2010: PROCEEDINGS OF THE 12TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P179
   Nagarajan R, 2003, IEEE TENC IEEE REG 1, P15
   Neilson J., 1993, Usability Engineering
   Nikolakis G, 2004, C SPEECH COMPUT, P20
   Rempel J, 2012, AFB ACCESS WORLD MAG, V13, P9
   Rodriguez-Sanchez MC, 2014, EXPERT SYST APPL, V41, P7210, DOI 10.1016/j.eswa.2014.05.031
   Roentgen U.R., 2008, J. Vis. Impair. Blind, V102, P702, DOI [DOI 10.1177/0145482X0810201105, 10.1177/0145482X0810201105]
   Sakhardande J, J SCI ENG RES, V4, P4
   Sanchez J, 2010, TACCESS, V3, P2010
   Sanchez Jaime, 2014, IUI, V2014, P199
   Sánchez J, 2009, ASSETS'09: PROCEEDINGS OF THE 11TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P35
   Sanz PR, 2014, J AUDIO ENG SOC, V62, P161, DOI 10.17743/jaes.2014.0009
   Savidis A, 2007, LECT NOTES COMPUT SC, V4397, P405
   Shoval S, 1998, IEEE T BIO-MED ENG, V45, P1376, DOI 10.1109/10.725334
   Sohl-Dickstein Jascha, 2015, IEEE Trans Biomed Eng, V62, P1526, DOI 10.1109/TBME.2015.2393371
   Sudhanthiradevi M, 2016, INT J ADV RES TRENDS, V5, P4
   Sung-Yeon K, 2013, INT J DES, V7, P1
   Torres-Gil M. A., 2010, WSEAS Transactions on Computers, V9, P184
   Tzovaras D, 2009, PERS UBIQUIT COMPUT, V13, P51, DOI 10.1007/s00779-007-0171-2
   Vorderer P., 2006, PLAYING VIDEO GAMES
   Wood J, 2003, DESIGN EVALUATION CO
   Yuan B, 2011, UNIVERSAL ACCESS INF, V10, P81, DOI 10.1007/s10209-010-0189-5
   Yuan Bei, 2008, P 10 INT ACM SIGACCE, P169, DOI [10.1145/1414471.1414503, DOI 10.1145/1414471.1414503]
   Zhao Sicheng, 2016, P 24 ACM INT C MULT, P1385, DOI DOI 10.1145/2964284.2964289
NR 69
TC 5
Z9 6
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19591
EP 19613
DI 10.1007/s11042-017-5415-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500032
DA 2024-07-18
ER

PT J
AU Lang, B
   Wu, B
   Liu, Y
   Liu, XL
   Zhang, BY
AF Lang, Bo
   Wu, Bo
   Liu, Yang
   Liu, Xianglong
   Zhang, Boyu
TI Fast graph similarity search via hashing and its application on image
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph similarity search; Locality sensitive hashing; Graph prototypes;
   Graph vectorial representation; Image retrieval
ID DESCRIPTOR; COLOR
AB Similarity search in graph databases has been widely investigated. It is worthwhile to develop a fast algorithm to support similarity search in large-scale graph databases. In this paper, we investigate a k-NN (k-Nearest Neighbor) similarity search problem by locality sensitive hashing (LSH). We propose an innovative fast graph search algorithm named LSH-GSS, which first transforms complex graphs into vectorial representations based on prototypes in the database and later accelerates a query in Euclidean space by employing LSH. Because images can be represented as attributed graphs, we propose an approach to transform attributed graphs into n-dimensional vectors and apply LSH-GSS to execute further image retrieval. Experiments on three real graph datasets and two image datasets show that our methods are highly accurate and efficient.
C1 [Lang, Bo; Wu, Bo; Liu, Yang; Liu, Xianglong; Zhang, Boyu] Beihang Univ, State Key Lab Software Dev Environm, Beijing, Peoples R China.
C3 Beihang University
RP Wu, B (corresponding author), Beihang Univ, State Key Lab Software Dev Environm, Beijing, Peoples R China.
EM langbo@buaa.edu.cn; wubo@nlsde.buaa.edu.cn; blonster@nlsde.buaa.edu.cn;
   xlliu@nlsde.buaa.edu.cn; zby@nlsde.buaa.edu.cn
RI Lang, Bo/AAA-7966-2022; wu, bo/GZN-0213-2022
OI wu, bo/0000-0002-0214-234X; Liu, Xianglong/0000-0002-7618-3275
FU National Natural Science Foundation of China [61370125, 61402026,
   SKLSDE-2017ZX-03]
FX This work is supported in part by the National Natural Science
   Foundation of China (61370125 and 61402026), SKLSDE-2017ZX-03.
CR [Anonymous], 2007, SIGMOD
   [Anonymous], IMAGE SEGMENTATION U
   [Anonymous], 2009, NIPS
   [Anonymous], 2011, SDM
   [Anonymous], 2011, PROC 17 ACM SIGKDD I
   Baeza-Yates R, 2000, SPIRE 2000: SEVENTH INTERNATIONAL SYMPOSIUM ON STRING PROCESSING AND INFORMATION RETRIEVAL - PROCEEDINGS, P28, DOI 10.1109/SPIRE.2000.878177
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng C, 2015, SIGNAL PROCESS, V112, P137, DOI 10.1016/j.sigpro.2014.07.017
   Fan JP, 2001, IEEE T IMAGE PROCESS, V10, P1454, DOI 10.1109/83.951532
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Fischer B, 2004, PROC SPIE, V5370, P598, DOI 10.1117/12.535294
   Gao XB, 2010, PATTERN ANAL APPL, V13, P113, DOI 10.1007/s10044-008-0141-y
   Ge TZ, 2014, IEEE T PATTERN ANAL, V36, P744, DOI 10.1109/TPAMI.2013.240
   He H., 2006, ICDE
   Ji TX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1005, DOI 10.1145/2647868.2655018
   Jiang HL, 2007, PROC INT CONF DATA, P541
   Jouili S, 2012, PATTERN RECOGN, V45, P4054, DOI 10.1016/j.patcog.2012.04.016
   Jouili S, 2009, LECT NOTES COMPUT SC, V5534, P154, DOI 10.1007/978-3-642-02124-4_16
   Kailing K, 2004, LECT NOTES COMPUT SC, V3214, P982
   Koch I, 2001, THEOR COMPUT SCI, V250, P1, DOI 10.1016/S0304-3975(00)00286-3
   Li CY, 2008, IEEE T MULTIMEDIA, V10, P447, DOI 10.1109/TMM.2008.917421
   Li CY, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1417
   Li Y, 2017, IEEE SIGNAL PROC LET, V24, P609, DOI 10.1109/LSP.2017.2665522
   Liu XL, 2015, IEEE I CONF COMP VIS, P1107, DOI 10.1109/ICCV.2015.132
   Liu XL, 2014, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2014.275
   Liu Xianglong., 2013, AAAI
   Lv Q, 2007, P 33 INT C VER LARG, P950
   Mongiovi Misael, 2010, Journal of Bioinformatics and Computational Biology, V8, P199, DOI 10.1142/S021972001000477X
   Mu YD, 2012, INT J MULTIMED INF R, V1, P59, DOI 10.1007/s13735-012-0003-7
   Niepert M, 2016, PR MACH LEARN RES, V48
   REGNERI M., 2007, Seminar current trends in IE WS jun
   Riesen K, 2009, INT J PATTERN RECOGN, V23, P1053, DOI 10.1142/S021800140900748X
   Riesen K, 2009, IMAGE VISION COMPUT, V27, P950, DOI 10.1016/j.imavis.2008.04.004
   Riesen K, 2008, LECT NOTES COMPUT SC, V5342, P287
   Wale N, 2008, KNOWL INF SYST, V14, P347, DOI 10.1007/s10115-007-0103-5
   Wang GR, 2012, IEEE T KNOWL DATA EN, V24, P440, DOI 10.1109/TKDE.2010.28
   Wang XL, 2012, PROC INT CONF DATA, P210, DOI 10.1109/ICDE.2012.28
   Wang YL, 2009, NUCLEIC ACIDS RES, V37, pW623, DOI 10.1093/nar/gkp456
   Yan X., 2005, Proceedings of the 2005 ACM SIGMOD international conference on Management of data, P766, DOI DOI 10.1145/1066157.1066244
   Yan Xifeng, 2004, P ACM INT C MAN DAT, P335
   Zhang BY, 2015, LECT NOTES COMPUT SC, V9314, P623, DOI 10.1007/978-3-319-24075-6_60
   Zhao P., 2007, VLDB
NR 44
TC 3
Z9 3
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16177
EP 16198
DI 10.1007/s11042-017-5194-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300009
DA 2024-07-18
ER

PT J
AU Schoeffmann, K
   Husslein, H
   Kletz, S
   Petscharnig, S
   Muenzer, B
   Beecks, C
AF Schoeffmann, Klaus
   Husslein, Heinrich
   Kletz, Sabrina
   Petscharnig, Stefan
   Muenzer, Bernd
   Beecks, Christian
TI Video retrieval in laparoscopic video recordings with dynamic content
   descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video retrieval; Video descriptor; Surgical quality assessment;
   Laparoscopic video; Medical multimedia; Similarity search
ID CLASSIFICATION; FEASIBILITY; ENDOSCOPY
AB In the domain of gynecologic surgery an increasing number of surgeries are performed in a minimally invasive manner. These laparoscopic surgeries require specific psychomotor skills of the operating surgeon, which are difficult to learn and teach. This is the reason why an increasing number of surgeons promote checking video recordings of laparoscopic surgeries for the occurrence of technical errors with surgical actions. This manual surgical quality assessment (SQA) process, however, is very cumbersome and time-consuming when carried out without any support from content-based video retrieval. In this work we propose a video content descriptor called MIDD (Motion Intensity and Direction Descriptor) that can be effectively used to find similar segments in a laparoscopic video database and thereby help surgeons to more quickly inspect other instances of a given error scene. We evaluate the retrieval performance of MIDD with surgical actions from gynecologic surgery in direct comparison to several other dynamic content descriptors. We show that the MIDD descriptor significantly outperforms the state-of-the-art in terms of retrieval performance as well as in terms of runtime performance. Additionally, we release the manually created video dataset of 16 classes of surgical actions from medical laparoscopy to the public, for further evaluations.
C1 [Schoeffmann, Klaus; Kletz, Sabrina; Petscharnig, Stefan; Muenzer, Bernd] Alpen Adria Univ Klagenfurt, Inst Informat Technol, Univ Str 65-67, A-9020 Klagenfurt, Austria.
   [Husslein, Heinrich] Med Univ Vienna, Univ Klin Frauenheilkunde, Waehringer Guertel 18-20, A-1097 Vienna, Austria.
   [Beecks, Christian] Fraunhofer, Inst Appl Informat Technol FIT, Schloss Birlinghoven, D-53754 St Augustin, Germany.
C3 University of Klagenfurt; Medical University of Vienna
RP Schoeffmann, K (corresponding author), Alpen Adria Univ Klagenfurt, Inst Informat Technol, Univ Str 65-67, A-9020 Klagenfurt, Austria.
EM ks@itec.aau.at; heinrich@husslein.at; sabrina@itec.aau.at;
   spetsch@itec.aau.at; bernd@itec.aau.at;
   christian.beecks@fit.fraunhofer.de
OI Husslein, Heinrich/0000-0003-0585-7444
FU University of Klagenfurt; Lakeside Labs GmbH, Klagenfurt, Austria;
   European Regional Development Fund; Carinthian Economic Promotion Fund
   (KWF) [KWF-20214 U. 3520/26336/38165]
FX Open access funding provided by University of Klagenfurt. This work was
   supported by Universitat Klagenfurt and Lakeside Labs GmbH, Klagenfurt,
   Austria and funding from the European Regional Development Fund and the
   Carinthian Economic Promotion Fund (KWF) under grant KWF-20214 U.
   3520/26336/38165.
CR Mesa FA, 2015, WORLD J SURG, V39, P536, DOI 10.1007/s00268-014-2827-1
   [Anonymous], 2013, THESIS
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], P 1 ACM INT C MULT R
   [Anonymous], CONTENT BASED PROCES
   [Anonymous], 2015, P 2015 13 INT WORKSH
   [Anonymous], 2001, PYRAMIDAL IMPLEMENTA
   [Anonymous], 2013, P 3 ACM C INT C MULT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], BMJ QUALITY SAFETY
   [Anonymous], 2014, P 31 INT C INT C MAC
   [Anonymous], 2005, P IMAGE VISION COMPU
   [Anonymous], 2017, DEEP LEARNING SHOT C
   [Anonymous], J SURG ED
   [Anonymous], 2011, 2011 E HLTH BIOENGIN
   Atasoy S, 2010, LECT NOTES COMPUT SC, V6362, P437
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Beecks C, 2015, IEEE INT SYM MULTIM, P33, DOI 10.1109/ISM.2015.21
   Beecks C, 2014, MULTIMED TOOLS APPL, V71, P349, DOI 10.1007/s11042-012-1334-3
   Bonrath EM, 2013, BRIT J SURG, V100, P1080, DOI 10.1002/bjs.9168
   Bonrath EM, 2015, ANN SURG, V262, P205, DOI 10.1097/SLA.0000000000001214
   Bonrath EM, 2014, SURG ENDOSC, V28, P1535, DOI 10.1007/s00464-013-3348-y
   Dahyot R, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/139429
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dedy N.J., 2015, Annals of Surgery, P1
   DeMenthon D., 2003, P 11 ACM INT C MULTI, P508
   Droueche Z, 2012, IEEE ENG MED BIO, P4962, DOI 10.1109/EMBC.2012.6347106
   Duta I.C., 2016, Proc. IEEE Int. Work. Content. Mul. Indexing, P1
   Fried Gerald M, 2007, Mcgill J Med, V10, P140
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krapac J, 2011, IEEE I CONF COMP VIS, P1487, DOI 10.1109/ICCV.2011.6126406
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Lin Henry C, 2006, Comput Aided Surg, V11, P220, DOI 10.1080/10929080600989189
   Makary MA, 2013, JAMA-J AM MED ASSOC, V309, P1591, DOI 10.1001/jama.2013.595
   Münzer B, 2013, IEEE INT SYM MULTIM, P84, DOI 10.1109/ISM.2013.22
   Oh J, 2007, MED IMAGE ANAL, V11, P110, DOI 10.1016/j.media.2006.10.003
   Petscharnig S, 2018, MULTIMED TOOLS APPL, V77, P8061, DOI 10.1007/s11042-017-4699-5
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Saint-Pierre CA, 2011, MACH VISION APPL, V22, P171, DOI 10.1007/s00138-007-0099-6
   Schoeffmann K, 2015, MULTIMED TOOLS APPL, V74, P11187, DOI 10.1007/s11042-014-2224-7
   Schoeffmann K, 2009, IEEE INT CON MULTI, P658, DOI 10.1109/ICME.2009.5202582
   Schulmann K, 2005, AM J GASTROENTEROL, V100, P27, DOI 10.1111/j.1572-0241.2005.40102.x
   Summers RM, 2001, RADIOLOGY, V219, P51, DOI 10.1148/radiology.219.1.r01ap0751
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Twinanda AP, 2015, INT J COMPUT ASS RAD, V10, P1449, DOI 10.1007/s11548-015-1183-4
   Twinanda AP, 2014, LECT NOTES COMPUT SC, V8675, P409, DOI 10.1007/978-3-319-10443-0_52
   Uijlings J, 2015, INT J MULTIMED INF R, V4, P33, DOI 10.1007/s13735-014-0069-5
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Wang Y, 2013, IEEE J BIOMED HEALTH, V17, P143, DOI 10.1109/TITB.2012.2226595
NR 50
TC 15
Z9 15
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16813
EP 16832
DI 10.1007/s11042-017-5252-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300037
OA hybrid
DA 2024-07-18
ER

PT J
AU Birajdar, GK
   Mankar, VH
AF Birajdar, Gajanan K.
   Mankar, Vijay H.
TI Blind image forensics using reciprocal singular value curve based local
   statistical features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forgery detection; Passive contrast enhancement detection; SVD;
   DWT; Reciprocal singular value curve
ID WATERMARKING ALGORITHM; SELECTION; FORGERY
AB In this article, passive contrast enhancement detection technique is presented using block based reciprocal singular value curve features. Contrast enhancement operation changes the natural statistics of the image and variation in singular value curve is exploited for constructing the feature vector for forgery detection. Various statistical features using reciprocal singular value curve are extracted after multilevel 2-Dimensional wavelet decomposition. Fisher criterion is employed to choose the most discriminating and to discard the redundant features. Experimental results are presented using gray scale, G component and C (b) image database and support vector machine classifier. Robustness against anti-forensic algorithm and JPEG compression is also presented. The algorithm outperforms all the existing feature based blind contrast enhancement detection methods in terms of detection accuracy.
C1 [Birajdar, Gajanan K.] Ramrao Adik Inst Technol, Dept Elect Engn, Navi Mumbai 400706, Maharashtra, India.
   [Mankar, Vijay H.] Govt Polytech Ahmednagar, Dept Elect & Commun Engn, Ahmednagar 414001, Maharashtra, India.
RP Birajdar, GK (corresponding author), Ramrao Adik Inst Technol, Dept Elect Engn, Navi Mumbai 400706, Maharashtra, India.
EM gajanan123@gmail.com; vhmankar@gmail.com
RI Birajdar, Gajanan/Z-1937-2018; Mankar, Vijay H/G-2293-2012
OI Birajdar, Gajanan/0000-0003-3531-3958; 
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   [Anonymous], ALTERNATIVE ANTIFORE
   [Anonymous], 2010, INT WORKSHOP VIDEO P
   [Anonymous], 2007, DELIVERING ACCESS SA
   [Anonymous], WOSPA 2008 5 IEEE IN
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 2011, ACM T INTEL SYST TEC
   [Anonymous], 2014, INT C ADV ENG TECHN
   Avcibas I, 2004, IEEE IMAGE PROC, P2645
   Bayram Sevinc, 2005, 2005 13th European Signal Processing Conference, P1
   Bayram S, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2401138
   Birajdar GK, 2016, ADV INTELL SYST, V408, P447, DOI 10.1007/978-981-10-0129-1_47
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Chandra DVS, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, CONFERENCE PROCEEDINGS, P264
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Gul G, 2010, IEEE IMAGE PROC, P1765, DOI 10.1109/ICIP.2010.5652854
   Gul G, 2010, IEEE T INF FOREN SEC, V5, P349, DOI 10.1109/TIFS.2010.2041826
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616
   Lin XF, 2013, IEEE IMAGE PROC, P4467, DOI 10.1109/ICIP.2013.6738920
   Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491, DOI 10.1109/TKDE.2005.66
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Lu JC, 2014, DIGIT INVEST, V11, P57, DOI 10.1016/j.diin.2013.12.001
   Mahdian B, 2010, SIGNAL PROCESS-IMAGE, V25, P389, DOI 10.1016/j.image.2010.05.003
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Nouri R, 2017, MULTIMED TOOLS APPL, V76, P8745, DOI 10.1007/s11042-016-3507-y
   Pandey P, 2014, MULTIMED TOOLS APPL, V72, P723, DOI 10.1007/s11042-013-1375-2
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Sacchi DLM, 2007, APPL COGNITIVE PSYCH, V21, P1005, DOI 10.1002/acp.1394
   Sang QB, 2014, SIGNAL PROCESS-IMAGE, V29, P1149, DOI 10.1016/j.image.2014.09.005
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   Staroszczyk Tomasz, 2012, Machine Learning and Data Mining in Pattern Recognition. Proceedings 8th International Conference, MLDM 2012, P467, DOI 10.1007/978-3-642-31537-4_37
   Wang DS, 2013, TELECOMMUN SYST, V54, P359, DOI 10.1007/s11235-013-9739-5
   Wang R, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P879, DOI 10.1109/ICIG.2009.46
   Zhang X, 2014, IEEE IMAGE PROC, P4472, DOI 10.1109/ICIP.2014.7025907
   Zontone P, 2010, IEEE IMAGE PROC, P1757, DOI 10.1109/ICIP.2010.5651509
NR 43
TC 5
Z9 5
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 14153
EP 14175
DI 10.1007/s11042-017-5021-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900047
DA 2024-07-18
ER

PT J
AU Boididou, C
   Middleton, SE
   Jin, ZW
   Papadopoulos, S
   Dang-Nguyen, DT
   Boato, G
   Kompatsiaris, Y
AF Boididou, Christina
   Middleton, Stuart E.
   Jin, Zhiwei
   Papadopoulos, Symeon
   Duc-Tien Dang-Nguyen
   Boato, Giulia
   Kompatsiaris, Yiannis
TI Verifying information with multimedia content on twitter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fake detection; Verification; Credibility; Veracity; Trust; Social
   media; Twitter; Multimedia
ID MOVE FORGERY DETECTION; TRENDING TOPICS; IMAGE; LOCALIZATION
AB An increasing amount of posts on social media are used for disseminating news information and are accompanied by multimedia content. Such content may often be misleading or be digitally manipulated. More often than not, such pieces of content reach the front pages of major news outlets, having a detrimental effect on their credibility. To avoid such effects, there is profound need for automated methods that can help debunk and verify online content in very short time. To this end, we present a comparative study of three such methods that are catered for Twitter, a major social media platform used for news sharing. Those include: a) a method that uses textual patterns to extract claims about whether a tweet is fake or real and attribution statements about the source of the content; b) a method that exploits the information that same-topic tweets should be also similar in terms of credibility; and c) a method that uses a semi-supervised learning scheme that leverages the decisions of two independent credibility classifiers. We perform a comprehensive comparative evaluation of these approaches on datasets released by the Verifying Multimedia Use (VMU) task organized in the context of the 2015 and 2016 MediaEval benchmark. In addition to comparatively evaluating the three presented methods, we devise and evaluate a combined method based on their outputs, which outperforms all three of them. We discuss these findings and provide insights to guide future generations of verification tools for media professionals.
C1 [Boididou, Christina; Papadopoulos, Symeon; Kompatsiaris, Yiannis] CERTH, Inst Informat Technol, Thessaloniki, Greece.
   [Middleton, Stuart E.] Univ Southampton, IT Innovat Ctr, Southampton, England.
   [Jin, Zhiwei] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Boato, Giulia] Univ Trento, Dept Informat Engn & Comp Sci DISI, Trento, Italy.
   [Duc-Tien Dang-Nguyen] Dublin City Univ, Dublin, Ireland.
C3 Centre for Research & Technology Hellas; University of Southampton;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; University of Trento; Dublin City University
RP Papadopoulos, S (corresponding author), CERTH, Inst Informat Technol, Thessaloniki, Greece.
EM boididou@iti.gr; sem@it-innovation.soton.ac.uk; jinzhiwei@ict.ac.cn;
   papadop@iti.gr; dangnguyen@disi.unitn.it; giulia.boato@unitn.it;
   ikom@iti.gr
RI Kompatsiaris, Ioannis/P-8594-2015; Papadopoulos, Symeon/AET-0683-2022
OI Kompatsiaris, Ioannis/0000-0001-6447-9020; Papadopoulos,
   Symeon/0000-0002-5441-7341; Middleton, Stuart/0000-0001-8305-8176
FU REVEAL project; InVID project; European Commission [FP7-610928,
   H2020-687786]
FX This work has been supported by the REVEAL and InVID projects, partially
   funded by the European Commission (FP7-610928 and H2020-687786
   respectively).
CR [Anonymous], P MED 2015 WORKSH WU
   [Anonymous], 2017, ARXIV170400656
   [Anonymous], P WORKSH INF FOR SEC
   [Anonymous], 2016, P MEDIAEVAL 2016 WOR
   [Anonymous], 2012, P ISCRAM
   [Anonymous], 9 INT AAAI C WEB SOC
   [Anonymous], AAAI 2016
   [Anonymous], P MEDIAEVAL 2015 WOR
   [Anonymous], MED 2015 WORKSH SEPT
   [Anonymous], 2012, IIITDTR2011005
   [Anonymous], 2014, P 6 INT C SOC INF SO
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Boididou C, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P283, DOI 10.1145/3078971.3078979
   Boididou C, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P743, DOI 10.1145/2567948.2579323
   Canini K. R., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P1, DOI 10.1109/PASSAT/SocialCom.2011.91
   Castillo C., 2011, P 20 INT C WORLD WID, P675, DOI DOI 10.1145/1963405.1963500
   Conotter V., 2014, Proceedings of the 2014 International ACM Workshop on Crowdsourcing for Multimedia, CrowdMM '14, P49
   Conotter V, 2010, IEEE IMAGE PROC, P1741, DOI 10.1109/ICIP.2010.5652906
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Gupta A, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P729
   Jin ZW, 2014, IEEE DATA MINING, P230, DOI 10.1109/ICDM.2014.91
   Kee E, 2011, IEEE T INF FOREN SEC, V6, P1066, DOI 10.1109/TIFS.2011.2128309
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li WH, 2009, SIGNAL PROCESS, V89, P1821, DOI 10.1016/j.sigpro.2009.03.025
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   Aiello LM, 2013, IEEE T MULTIMEDIA, V15, P1268, DOI 10.1109/TMM.2013.2265080
   Martinez-Romo J, 2013, EXPERT SYST APPL, V40, P2992, DOI 10.1016/j.eswa.2012.12.015
   Middleton S, 2015, Extracting attributed verification and debunking reports from social media: mediaeval-2015 trust and credibility analysis of image and video
   Middleton SE, 2014, IEEE INTELL SYST, V29, P9, DOI 10.1109/MIS.2013.126
   O'Brien JF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2077341.2077345
   O'Donovan J, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, SECURITY, RISK AND TRUST AND 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM/PASSAT 2012), P293, DOI 10.1109/SocialCom-PASSAT.2012.128
   Pasquini C, 2014, IEEE IMAGE PROC, P5322, DOI 10.1109/ICIP.2014.7026077
   Procter R, 2013, INT J SOC RES METHOD, V16, P197, DOI 10.1080/13645579.2013.774172
   Ratkiewicz J, 2011, P 20 INT C COMP WORL
   Silverman C., 2014, Verification Handbook: A definitive guide to verifying digital content for emergency coverage
   Stringhini G, 2010, 26TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2010), P1
   Tsakalidis A, 2014, LECT NOTES COMPUT SC, V8787, P168, DOI 10.1007/978-3-319-11746-1_12
   Zampoglou M, 2017, MULTIMED TOOLS APPL, V76, P4801, DOI 10.1007/s11042-016-3795-2
   Zampoglou M, 2015, IEEE INT CONF MULTI
   Zhao Z, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1395, DOI 10.1145/2736277.2741637
NR 41
TC 29
Z9 31
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15545
EP 15571
DI 10.1007/s11042-017-5132-9
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200049
OA Green Published, Green Accepted, Green Submitted
DA 2024-07-18
ER

PT J
AU Chen, GL
   Wang, AG
   Zhao, SH
   Liu, L
   Chang, CY
AF Chen, Guilin
   Wang, Aiguo
   Zhao, Shenghui
   Liu, Li
   Chang, Chih-Yung
TI Latent feature learning for activity recognition using simple sensors in
   smart homes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Activity recognition; Smart home; Feature learning; Autoencoder; Shallow
   model
ID TRACKING
AB Activity recognition is an important step towards monitoring and evaluating the functional health of an individual, and it potentially promotes human-centric ubiquitous applications in smart homes particularly for senior healthcare. The nature of human activity characterized by a high degree of complexity and uncertainty, however, poses a great challenge to the design of good feature representations and the optimization of classifiers towards building a robust model for human activity recognition. In this study, we propose to exploit deep learning techniques to automatically learn high-level features from the binary sensor data under the assumption that there exist discriminative latent patterns inherent in the simple low-level features. Specifically, we extract high-level features with a stacked autoencoder that has a deep and hierarchy architecture, and combine feature learning and classifier construction into a unified framework to obtain a jointly optimized activity recognizer. Besides, we investigate two different original feature representations of the sensor data for latent feature learning. To evaluate the performance of the proposed method, we conduct extensive experiments on three publicly available smart home datasets, and compare it with a range of shallow models in terms of time-slice accuracy and class accuracy. Experimental results show that our proposed model achieves better recognition rates and generalizes better across different original feature representations, indicating its applicability to the real-world activity recognition.
C1 [Chen, Guilin; Zhao, Shenghui] Chuzhou Univ, Sch Comp & Informat Engn, Chuzhou 239000, Peoples R China.
   [Wang, Aiguo] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
   [Liu, Li] Chongqing Univ, Sch Software Engn, Chongqing 400044, Peoples R China.
   [Chang, Chih-Yung] Tamkang Univ, Dept Comp Sci & Informat Engn, Taipei 25157, Taiwan.
C3 Chuzhou University; Hefei University of Technology; Chongqing
   University; Tamkang University
RP Wang, AG (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
EM wangaiguo2546@163.com
OI wang, aiguo/0000-0001-6150-8068
FU Natural Science Foundation of China [61472057]; Fundamental Research
   Funds for the Central Universities [JZ2016HGBH1053]; China Postdoctoral
   Science Foundation [2016 M592046]
FX This work was supported partially by the Natural Science Foundation of
   China (No. 61472057), the Fundamental Research Funds for the Central
   Universities (No. JZ2016HGBH1053), and the China Postdoctoral Science
   Foundation (No. 2016 M592046).
CR Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bhattacharya S, 2014, PERVASIVE MOB COMPUT, V15, P242, DOI 10.1016/j.pmcj.2014.05.006
   Chen LM, 2012, IEEE T SYST MAN CY C, V42, P790, DOI 10.1109/TSMCC.2012.2198883
   Cook DJ, 2012, IEEE INTELL SYST, V27, P32, DOI 10.1109/MIS.2010.112
   Dernbach S., 2012, Proceedings of the Eighth International Conference on Intelligent Environments (IE 2012), P214, DOI 10.1109/IE.2012.39
   Figo D, 2010, PERS UBIQUIT COMPUT, V14, P645, DOI 10.1007/s00779-010-0293-9
   Fleury A, 2010, IEEE T INF TECHNOL B, V14, P274, DOI 10.1109/TITB.2009.2037317
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Ordóñez FJ, 2015, PERS UBIQUIT COMPUT, V19, P259, DOI 10.1007/s00779-014-0820-1
   Kim SC, 2013, PERS UBIQUIT COMPUT, V17, P1699, DOI 10.1007/s00779-012-0604-4
   Krishnan NC, 2014, PERVASIVE MOB COMPUT, V10, P138, DOI 10.1016/j.pmcj.2012.07.003
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Minor B, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P805, DOI 10.1145/2783258.2783408
   Okeyo G, 2014, PERVASIVE MOB COMPUT, V10, P155, DOI 10.1016/j.pmcj.2012.11.004
   Ordóñez FJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010115
   Philipose M, 2004, IEEE PERVAS COMPUT, V3, P50, DOI 10.1109/MPRV.2004.7
   Plotz N. Y., 2011, P INT C ART INT IJCA, V2, P1729
   Ronao CA, 2016, EXPERT SYST APPL, V59, P235, DOI 10.1016/j.eswa.2016.04.032
   Suryadevara NK, 2014, IEEE INTELL SYST, V29, P30, DOI 10.1109/MIS.2014.16
   Tapia EM, 2004, LECT NOTES COMPUT SC, V3001, P158, DOI 10.1007/978-3-540-24646-6_10
   Tapia EM, 2007, ELEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P37
   van Kasteren TLM, 2010, PERS UBIQUIT COMPUT, V14, P489, DOI 10.1007/s00779-009-0277-9
   van Kasteren T.L.M., 2011, Activity recognition for health monitoring elderly using temporal probabilistic models
   van Kasteren T, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P1, DOI 10.1145/1409635.1409637
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Wang AG, 2016, IEEE SENS J, V16, P4566, DOI 10.1109/JSEN.2016.2545708
   Wang LK, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16020189
   Wilson DH, 2005, LECT NOTES COMPUT SC, V3468, P62
   Yang JB, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3995
NR 32
TC 23
Z9 24
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15201
EP 15219
DI 10.1007/s11042-017-5100-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200035
DA 2024-07-18
ER

PT J
AU Kang, XB
   Zhao, F
   Lin, GF
   Chen, YJ
AF Kang, Xiao-bing
   Zhao, Fan
   Lin, Guang-feng
   Chen, Ya-jun
TI A novel hybrid of DCT and SVD in DWT domain for robust and invisible
   blind image watermarking with optimal embedding strength
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robust blind watermarking; Discrete wavelet transform; Discrete cosine
   transform; Singular value decomposition; Least squares curve fitting;
   Logistic chaotic map
ID SINGULAR-VALUE DECOMPOSITION; OPTIMIZED COMPENSATION; MULTIPLE
   WATERMARKING; SCHEME; ALGORITHM
AB To optimize the tradeoff between imperceptibility and robustness properties, this paper proposes a robust and invisible blind image watermarking scheme based on a new combination of discrete cosine transform (DCT) and singular value decomposition (SVD) in discrete wavelet transform (DWT) domain using least-square curve fitting and logistic chaotic map. Firstly cover image is decomposed into four subbands using DWT and the low frequency subband LL is partitioned into non-overlapping blocks. Then DCT is applied to each block and several particular middle frequency DCT coefficients are extracted to form a modulation matrix, which is used to embed watermark signal by modifying its largest singular values in SVD domain. Optimal embedding strength for a specific cover image is obtained from an estimation based on least-square curve fitting and provides a good compromise between transparency and robustness of watermarking scheme. The security of the watermarking scheme is ensured by logistic chaotic map. Experimental results demonstrate the better effectiveness of the proposed watermarking scheme in the perceptual quality and the ability of resisting to conventional signal processing and geometric attacks, in comparison with the related existing methods.
C1 [Kang, Xiao-bing; Zhao, Fan; Lin, Guang-feng; Chen, Ya-jun] Xian Univ Technol, Fac Printing Packaging Engn & Digital Media Techn, Dept Informat Sci, Xian 710048, Shaanxi, Peoples R China.
C3 Xi'an University of Technology
RP Kang, XB (corresponding author), Xian Univ Technol, Fac Printing Packaging Engn & Digital Media Techn, Dept Informat Sci, Xian 710048, Shaanxi, Peoples R China.
EM kangxb@xaut.edu.cn; vcu@xaut.edu.cn; lgf78103@xaut.edu.cn;
   chenyajun@xaut.edu.cn
RI ZHAO, Fan/AEZ-4761-2022; Lin, Guangfeng/AAA-8654-2021; Lin,
   Guangfeng/E-4420-2013
OI ZHAO, Fan/0000-0001-6672-7948; Lin, Guangfeng/0000-0002-6191-1102; Lin,
   Guangfeng/0000-0002-6191-1102; kang, xiaobing/0000-0003-2537-639X
FU Scientific Research Program - Shaanxi Provincial Education Department
   [15JK1504]; National Natural Science Foundation of China [61671376,
   61671374]; Natural Science Basic Research Plan in Shaanxi Province of
   China [2016JM6045]
FX This work was supported by the Scientific Research Program Funded by
   Shaanxi Provincial Education Department (Program No. 15JK1504), the
   National Natural Science Foundation of China (Grant No. 61671376 &
   61671374) and the Natural Science Basic Research Plan in Shaanxi
   Province of China (Program No. 2016JM6045).
CR Agoyi M, 2015, SIGNAL IMAGE VIDEO P, V9, P735, DOI 10.1007/s11760-014-0624-9
   AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Ali M, 2015, INFORM SCIENCES, V301, P44, DOI 10.1016/j.ins.2014.12.042
   Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   Ansari IA, 2016, ADV INTELL SYST COMP, V437, P411, DOI 10.1007/978-981-10-0451-3_38
   Benoraira A, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0239-5
   Chung KL, 2007, APPL MATH COMPUT, V188, P54, DOI 10.1016/j.amc.2006.09.117
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Elayan MA, 2016, LECT NOTES COMPUT SC, V9680, P317, DOI 10.1007/978-3-319-33618-3_32
   Fan MQ, 2008, APPL MATH COMPUT, V203, P926, DOI 10.1016/j.amc.2008.05.003
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   Hu HT, 2017, MULTIMED TOOLS APPL, V76, P6575, DOI 10.1007/s11042-016-3332-3
   Hu HT, 2015, COMPUT ELECTR ENG, V41, P52, DOI 10.1016/j.compeleceng.2014.08.001
   Huang HC, 2009, STUD COMPUT INTELL, V227, P1, DOI 10.1080/13651500903056533
   Kumar A, 2016, USNC-URSI RADIO SCI, P21, DOI 10.1109/USNC-URSI.2016.7588492
   Lai CC, 2011, OPT COMMUN, V284, P938, DOI 10.1016/j.optcom.2010.10.047
   Lin SD, 2010, COMPUT STAND INTER, V32, P54, DOI 10.1016/j.csi.2009.06.004
   Ling HC, 2011, LECT NOTES COMPUT SC, V7087, P257, DOI 10.1007/978-3-642-25367-6_23
   Madhuri AJ, 2015, IMAGE VIDEO COMPRESS
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Parah SA, 2018, MULTIMED TOOLS APPL, V77, P185, DOI 10.1007/s11042-016-4253-x
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P16657, DOI 10.1007/s11042-016-3942-9
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P8627, DOI 10.1007/s11042-016-3501-4
   Roy S, 2017, MULTIMED TOOLS APPL, V76, P3577, DOI 10.1007/s11042-016-3902-4
   Shieh CS, 2004, PATTERN RECOGN, V37, P555, DOI 10.1016/j.patcog.2003.07.003
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Singh AK, 2013, LECT NOTES COMPUT SC, V8271, P235, DOI 10.1007/978-3-642-44949-9_22
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Singh S, 2017, MULTIMED TOOLS APPL, V76, P3557, DOI 10.1007/s11042-016-3885-1
   Srdjan S, 2016, MULTIMEDIA SIGNALS S
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Su QT, 2013, AEU-INT J ELECTRON C, V67, P652, DOI 10.1016/j.aeue.2013.01.009
   Tao P., 2006, J Multimed, V1, P36, DOI 10.4304/jmm.1.6.36-45
   Tsui TK, 2008, IEEE T INF FOREN SEC, V3, P16, DOI 10.1109/TIFS.2007.916275
   Verma VS, 2015, J VIS COMMUN IMAGE R, V31, P75, DOI 10.1016/j.jvcir.2015.06.001
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zheng PP, 2014, NEUROCOMPUTING, V142, P520, DOI 10.1016/j.neucom.2014.04.005
NR 46
TC 77
Z9 79
U1 3
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13197
EP 13224
DI 10.1007/s11042-017-4941-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900007
DA 2024-07-18
ER

PT J
AU Singh, VP
   Srivastava, R
AF Singh, Vibhav Prakash
   Srivastava, Rajeev
TI Improved image retrieval using fast Colour-texture features with varying
   weighted similarity measure and random forests
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ensemble Classification; Content-Based Image Retrieval; Feature
   Extraction; Random Forest Classifier; Chromaticity Moments; Similarity
   Measure
ID CLASSIFICATION; SHAPE
AB Content-based image retrieval (CBIR) retrieves images from image database based on the visual similarity of query image. For the implementation of CBIR, feature extraction plays a significant role, where colour feature is quite remarkable. But, due to achromatic surfaces or unevenly colored, the role of texture is also important. This paper introduced an efficient and fast CBIR system, which is based on the combination of computationally light weighted colour and texture features viz. chromaticity moment, colour percentile, and local binary pattern. For searching, this paper proposes inverse variance based varying weighted similarity measure (low for high variance feature and high for low variance feature), which reduces the effect of redundancy by assigning the priority to each feature, and effectively retrieves relevant images. In addition, this paper also proposes query image classification and retrieval model by filtering out irrelevant class images using Random Forests (RF) classifier, which recovers the class of a query image based on distinct learning (supervised) of various decision trees. This successful ensemble classification of query images reduces the semantic gap, searching space, and enhances the retrieval performance. Extensive experimental analyses on benchmark databases confirm the usefulness and effectiveness of this work.
C1 [Singh, Vibhav Prakash; Srivastava, Rajeev] Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Singh, VP (corresponding author), Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
EM vpsingh.rs.cse13@itbhu.ac.in; rajeev.cse@iitbhu.ac.in
RI Singh, Vibhav/AAE-1779-2021; Srivastava, Rajeev/C-7906-2016
OI Singh, Vibhav/0000-0002-6823-2524; Srivastava,
   Rajeev/0000-0002-0165-1556
CR Acharya T., 2005, IMAGE PROCESSING PRI
   Amanatiadis A, 2011, IET IMAGE PROCESS, V5, P493, DOI 10.1049/iet-ipr.2009.0246
   [Anonymous], 2016, INT J SIGNAL PROCESS
   Bianconi F, 2011, THEORETICAL EXPT COM, P1
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hiremath H. S., 2007, INT C ADV COMPUT COM, P780
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Irtaza A, 2014, MULTIMED TOOLS APPL, V72, P1911, DOI 10.1007/s11042-013-1489-6
   Jalab A., 2011, IEEE C OPEN SYSTEM I, P32
   Lin HC, 2009, IMAGE VISION COMPUT, V27, P658
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Mandal MK, 1996, IEEE T CONSUM ELECTR, V42, P557, DOI 10.1109/30.536156
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mistry Y, 2017, J ELECT SYSTEMS INFO
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Palm C, 2004, PATTERN RECOGN, V37, P965, DOI 10.1016/j.patcog.2003.09.010
   Park SB, 2004, PATTERN RECOGN LETT, V25, P287, DOI 10.1016/j.patrec.2003.10.015
   Paschos G, 2003, IEEE T KNOWL DATA EN, V15, P1069, DOI 10.1109/TKDE.2003.1232264
   Raghupathi G., 2010, 2 INT C MULT CONT BA, V3, P39
   Rahimi M, 2015, SIGNAL IMAGE VIDEO P, V9, P691, DOI 10.1007/s11760-013-0506-6
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Shen LG, 2013, IEEE INT WORKSHOP SI, V1, P1
   Singh VP., 2015, DESIGN PERFORMANCE A, P664
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2410, P381, DOI 10.1117/12.205308
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   Walia E, 2014, J VIS COMMUN IMAGE R, V25, P1335, DOI 10.1016/j.jvcir.2014.05.005
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Won CS, 2002, ETRI J, V24, P23, DOI 10.4218/etrij.02.0102.0103
   Yildizer E, 2012, EXPERT SYST APPL, V39, P2385, DOI 10.1016/j.eswa.2011.08.086
   Yue J, 2011, MATH COMPUT MODEL, V54, P1121, DOI 10.1016/j.mcm.2010.11.044
   Zhang M, 2014, J VIS COMMUN IMAGE R, V25, P1574, DOI 10.1016/j.jvcir.2014.06.016
   Zhang YJ, 2008, HDB RES TEXT WEB MIN, P96, DOI DOI 10.4018/978-1-59904-990-8.CH006
NR 38
TC 9
Z9 9
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 14435
EP 14460
DI 10.1007/s11042-017-5036-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900059
DA 2024-07-18
ER

PT J
AU Aljawarneh, S
   Yassein, MB
   Talafha, WA
AF Aljawarneh, Shadi
   Yassein, Muneer Bani
   Talafha, We'am Adel
TI A multithreaded programming approach for multimedia big data: encryption
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia big data; AES; Mars; RC6; Blowfish; Des; Encryption;
   Decryption; GPU; Multithreading
ID CRYPTOGRAPHY; ALGORITHM
AB Multimedia is currently seen to dominate the internet network and the mobile network traffic; hence, it is seen as the largest Big data. Generally, the symmetric encryption algorithms are applied to the 'big multimedia data'; however, these algorithms are thought as very slow. In our study, we developed and designed a resource-efficient encryption algorithm system which applies the multithreaded programming process for the encryption of the big multimedia data. This proposed system describes a multi-level encryption model which uses the Feistel Encryption Scheme, genetic algorithms and the Advanced Encryption Standard (AES). Our system has been assessed for actual medical-based big multimedia data and compared to the benchmarked encryption algorithms like the RC6, MARS, 3-DES, DES, and Blowfish with regards to the computational run time and its throughput for the encryption and decryption procedures. In addition, the multithreaded programming approach is adopted to implement the proposed encryption system in order to enhace the system effeciencey and porfermance. Furthermore, we also compared our system with its sequential version for showing its resource efficiency. Our results indicated that our system had the least run time and a higher throughput for the encryption and decryption processes in comparison to the already existing standard encryption algorithms. Also, our system could improve the computation run time by approximately 75% and its throughput was also increased by 4-times in comparison to its sequential version. For fulfilling the security objectives, our algorithm showed a better Avalanche Effect in comparison to the existing algorithms and therefore, could be included in any encryption/decryption process of a big plain multimedia data.
C1 [Aljawarneh, Shadi; Yassein, Muneer Bani; Talafha, We'am Adel] Jordan Univ Sci & Technol, Fac Comp & Informat Technol, Irbid, Jordan.
C3 Jordan University of Science & Technology
RP Aljawarneh, S (corresponding author), Jordan Univ Sci & Technol, Fac Comp & Informat Technol, Irbid, Jordan.
EM saaljawarneh@just.edu.jo; masadeh@just.edu.jo;
   Watalafha13@cit.just.edu.jo
RI Aljawarneh, Shadi/ABD-6329-2021
OI Aljawarneh, Shadi/0000-0001-5748-4921; Bani Yassein,
   Muneer/0000-0001-5030-6196
CR Abd Elminaam DiaaSalama., 2010, IJ NETWORK SECURITY, V10, P216
   Aljawarneh Shadi, 2010, Network Security, V2010, P6, DOI 10.1016/S1353-4858(10)70081-7
   Aljawarneh Shadi, 2010, J. theor. appl. electron. commer. res., V5, P39, DOI 10.4067/S0718-18762010000100005
   Aljawarneh S, 2017, MULTIMED TOOLS APPL, V76, P22703, DOI 10.1007/s11042-016-4333-y
   Aljawarneh SA, 2016, FUTURE GENER COMP SY, V60, P67, DOI 10.1016/j.future.2016.01.020
   Bhandari Lekha., 2013, International Journal of Emerging Research in Management and Technology, V2, P24
   Chen M, 2014, MOBILE NETW APPL, V19, P171, DOI 10.1007/s11036-013-0489-0
   De Mauro A, 2015, AIP CONF PROC, V1644, P97, DOI 10.1063/1.4907823
   Fifer R M., 1989, Planning Review, V17, Iss, P18
   Hayes Jer., 2015, Big-Data Analytics and Cloud Computing, P37
   HEYS HM, 1995, IEEE T COMPUT, V44, P1131, DOI 10.1109/12.464391
   Jindal P, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P326, DOI 10.1109/CCAA.2015.7148425
   Kurniawan Y, 2011, EL ENG INF ICEEI 201, P1
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH, V1st
   Mitchell M., 1998, INTRO GENETIC ALGORI
   Nadeem A., 2005, Information and Communication Technologies, ICICT, V2005, P84, DOI DOI 10.1109/ICICT.2005.1598556
   Reddy MIS, 2016, PROCEDIA COMPUT SCI, V85, P62, DOI 10.1016/j.procs.2016.05.177
   Schneier B, 1997, COMMUN ACM, V40, P138, DOI 10.1145/242857.263692
   Schweitzer Dino, 2009, J COMPUT SCI COLL, V25, P39
   Sindhuja K., 2014, IJCSIT, V5, P414
   Wang W.J., 2012, METAL MINE, V10, P1
   Yadav A, 2016, EFFICIENT VIDEO DATA
NR 22
TC 60
Z9 60
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10997
EP 11016
DI 10.1007/s11042-017-4873-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900037
DA 2024-07-18
ER

PT J
AU Crisci, A
   Grasso, V
   Nesi, P
   Pantaleo, G
   Paoli, I
   Zaza, I
AF Crisci, Alfonso
   Grasso, Valentina
   Nesi, Paolo
   Pantaleo, Gianni
   Paoli, Irene
   Zaza, Imad
TI Predicting TV programme audience by using twitter based metrics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Twitter monitoring; Social media monitoring; Predicting audience;
   Twitter data analysis
ID REGRESSION; SELECTION
AB The predictive capabilities of metrics based on Twitter data have been stressed in different fields: business, health, market, politics, etc. In specific cases, a deeper analysis is required to create useful metrics and models with predicting capabilities. In this paper, a set of metrics based on Twitter data have been identified and presented in order to predict the audience of scheduled television programmes, where the audience is highly involved such as it occurs with reality shows (i.e., X Factor and Pechino Express, in Italy). Identified suitable metrics are based on the volume of tweets, the distribution of linguistic elements, the volume of distinct users involved in tweeting, and the sentiment analysis of tweets. On this ground a number of predictive models have been identified and compared. The resulting method has been selected in the context of a validation and assessment by using real data, with the aim of building a flexible framework able to exploit the predicting capabilities of social media data. Further details are reported about the method adopted to build models which focus on the identification of predictors by their statistical significance. Experiments have been based on the collected Twitter data by using Twitter Vigilance platform, which is presented in this paper, as well.
C1 [Crisci, Alfonso; Grasso, Valentina] CNR, IBIMET, Natl Res Council, Florence, Italy.
   [Crisci, Alfonso] Tuscany Reg CNR, LAMMA Consortium, Sesto Fiorentino, Italy.
   [Nesi, Paolo; Pantaleo, Gianni; Paoli, Irene; Zaza, Imad] Univ Florence, Dept Informat Engn DINFO, Distributed Syst & Internet Data Intelligence & T, DISIT Lab, Florence, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Biometeorologia
   (IBIMET-CNR); University of Florence
RP Nesi, P (corresponding author), Univ Florence, Dept Informat Engn DINFO, Distributed Syst & Internet Data Intelligence & T, DISIT Lab, Florence, Italy.
EM a.crisci@ibimet.cnr.it; grasso@lamma.rete.toscana.it;
   paolo.nesi@unifi.it
RI Crisci, Alfonso/AAX-3314-2020; Pantaleo, Gianni/J-1864-2016
OI Pantaleo, Gianni/0000-0002-9235-437X; PAOLI, IRENE/0000-0003-2018-3871;
   GRASSO, VALENTINA/0000-0002-1433-1674; nesi, paolo/0000-0003-1044-3107;
   Crisci, Alfonso/0000-0002-5495-6695
CR Achrekar Harshavardhan, 2012, Proceedings of the International Conference on Health Informatics. HEALTHINF 2012, P61
   AKAIKE H, 1987, PSYCHOMETRIKA, V52, P317, DOI 10.1007/BF02294359
   [Anonymous], ED PSYCHOL MEAS
   [Anonymous], SOC SCI COMPUT REV
   [Anonymous], INT C LANG RES EV IS
   [Anonymous], 2002, P 1 INT WORDNET C MY
   [Anonymous], 2006, AAAI 2006 SPRING S C
   [Anonymous], PEER J PREPRINTS
   [Anonymous], P 5 INT C UB INF MAN
   [Anonymous], 2012, INT J COMPUT APPL, DOI DOI 10.5120/8852-2794
   [Anonymous], KNOWL INF SYST
   [Anonymous], J COMPUTATIONAL SCI
   [Anonymous], 6 INT JOINT C NAT LA
   [Anonymous], MUST SEE TV TWITT AC
   [Anonymous], SOCIAL COMPUTING LAB
   [Anonymous], 2011, P ICWSM
   [Anonymous], ARXIV13106998V1CSSI
   [Anonymous], 2011, P 20 INT C COMP WORL
   [Anonymous], 2005, Proceedings 11th International Conference Knowledge Discovery in Data Mining, DOI DOI 10.1145/1081870.1081883
   [Anonymous], OFFICIAL GOOGLE RES
   [Anonymous], 16 EMS ANN M 11 EUR
   Asur S., 2010, CORR
   Bermingham Adam, 2011, On using twitter to monitor political sentiment and predict election results, P2
   Botta F, 2015, ROY SOC OPEN SCI, V2, DOI 10.1098/rsos.150162
   Broniatowski David Andre, 2015, JMIR Public Health Surveill, V1, pe5
   Esuli Andrea., 2006, LREC 2006 Proceedings, 2006, S, P417
   Everitt B, 2011, USE R, P1, DOI 10.1007/978-1-4419-9650-3
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Garikar DD, 2015, IND MANAGE DATA SYST, V115, P1604, DOI 10.1108/IMDS-04-2015-0145
   Giglietto F, 2013, Exploring correlations between TV viewership and Twitter conversations in Italian political talk shows
   Grolemond G, 2011, J STAT SOFTW, V40, P1
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Hyndman RJ, 2008, J STAT SOFTW, V27, P1, DOI 10.18637/jss.v027.i03
   Jain Vasu, 2013, International Journal of Soft Computing and Software Engineering, V3, P308, DOI 10.7321/jscse.v3.n3.46
   Kupavskii A, 2013, ICWSM
   Lampos V, 2010, LECT NOTES ARTIF INT, V6323, P599, DOI 10.1007/978-3-642-15939-8_42
   Lochrie M, 2012, CONSUM COMM NETWORK, P729, DOI 10.1109/CCNC.2012.6181037
   Lu YF, 2014, IEEE CONF VIS ANAL, P193, DOI 10.1109/VAST.2014.7042495
   Madlberger L, INDATA SOFTWARE ENG, P1
   Molteni L, 2016, Int J Design Nature Ecodyn, V11, P220
   Moreno JJM, 2013, PSICOTHEMA, V25, P500, DOI 10.7334/psicothema2013.23
   Nesi P, 2015, J VISUAL LANG COMPUT, V31, P130, DOI 10.1016/j.jvlc.2015.10.017
   OConnor B, 2010, ICWSM, P122, DOI DOI 10.1609/ICWSM.V4I1.14031
   Oussalah M, 2013, KNOWL-BASED SYST, V37, P105, DOI 10.1016/j.knosys.2012.07.017
   Ritterman Joshua., 2009, 1 INT WORKSHOP MININ, V9, P9
   Shimshoni Y., 2009, On the predictability of search trends
   Signorini A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019467
   Sikdar S., 2014, 2014 17th International Conference on Information Fusion (FUSION 2014)
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tumasjan A, 2010, 4 INT AAAI C WEBL SO, V10, P178, DOI 10.1074/jbc.M501708200
   Venables WN., 2002, MODERN APPL STAT S
   Xiaofeng Wang, 2012, Social Computing, Behavioral-Cultural Modeling and Prediction. Proceedings of the 5th International Conference, SBP 2012, P231, DOI 10.1007/978-3-642-29047-3_28
   Zaman T, 2014, ANN APPL STAT, V8, P1583, DOI 10.1214/14-AOAS741
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 54
TC 13
Z9 15
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12203
EP 12232
DI 10.1007/s11042-017-4880-x
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100027
OA hybrid
DA 2024-07-18
ER

PT J
AU Ramalingam, B
   Ravichandran, D
   Annadurai, AA
   Rengarajan, A
   Rayappan, JBB
AF Ramalingam, Balakrishnan
   Ravichandran, Dhivya
   Annadurai, Arun Adhithiya
   Rengarajan, Amirtharajan
   Rayappan, John Bosco Balaguru
TI Chaos triggered image encryption - a reconfigurable security solution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; FPGA; Chaos; Multiple chaotic maps; Image encryption
ID ONE-TIME KEYS; CIPHER; PERMUTATION; ALGORITHM; STANDARD; SYSTEM
AB Recently, diverse types of chaotic image encryption algorithms have been explored to meet the high demands in realizing secured real time image sharing applications. In this context, to achieve high sensitivity and superior key space, a multiple chaotic map based image encryption algorithm has been proposed. The proposed algorithm employs three-stage permutation and diffusion to withstand several attacks and the same is modelled in reconfigurable platform namely Field Programmable Gate Array (FPGA). The comprehensive analysis is done with various parameters to exhibit the robustness of the proposed algorithm and its ability to withstand brute-force, differential and statistical attacks. The synthesized result demonstrates that the reconfigurable hardware architecture takes approximately 0.098 ms for encrypting an image of size 256 x 256. Further the resource utilization and timing analyzer results are reported.
C1 [Ramalingam, Balakrishnan; Ravichandran, Dhivya; Annadurai, Arun Adhithiya; Rengarajan, Amirtharajan; Rayappan, John Bosco Balaguru] SASTRA Univ, SEEE, Thanjavur 613401, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Rayappan, JBB (corresponding author), SASTRA Univ, SEEE, Thanjavur 613401, India.
EM rjbosco@ece.sastra.edu
RI Amirtharajan, Rengarajan/C-6471-2011; Ramalingam,
   Balakrishnan/L-1383-2019; RAVICHANDRAN, Dr DHIVYA/S-7457-2019; Rayappan,
   John Bosco Balaguru/K-6842-2013
OI Amirtharajan, Rengarajan/0000-0003-1574-3045; Ramalingam,
   Balakrishnan/0000-0002-3243-9814; RAVICHANDRAN, Dr
   DHIVYA/0000-0002-0312-4880; Rayappan, John Bosco
   Balaguru/0000-0003-4641-9870
FU SASTRA University, Thanjavur
FX The authors wish to express their sincere thanks to SASTRA University,
   Thanjavur for their financial support and extending infrastructural
   facilities to carry out this work.
CR Aneesh R, 2012, ANNU IEEE IND CONF, P427
   Azzaz MS, 2013, J REAL-TIME IMAGE PR, V8, P297, DOI 10.1007/s11554-011-0219-4
   Barakat ML, 2014, IET IMAGE PROCESS, V8, P33, DOI 10.1049/iet-ipr.2012.0586
   Dong CE, 2014, SIGNAL PROCESS-IMAGE, V29, P628, DOI 10.1016/j.image.2013.09.006
   El-Samie FEA, 2013, IMAGE ENCRYPTION COM, P3
   Ferguson N., 2003, Practical cryptography, VVolume 141
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Kocarev L., 2001, IEEE Circuits and Systems Magazine, V1, P6, DOI 10.1109/7384.963463
   Li CQ, 2011, COMMUN NONLINEAR SCI, V16, P837, DOI 10.1016/j.cnsns.2010.05.008
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Nemade V.S., 2012, WORLD J SCI TECHNOL, V2, P95
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Ou SC, 2006, MULTIMED TOOLS APPL, V28, P5, DOI 10.1007/s11042-006-5117-6
   Pande A, 2013, TELECOMMUN SYST, V52, P551, DOI 10.1007/s11235-011-9460-1
   Pareek NK, 2011, COMM COM INF SC, V131, P413
   Pareek NK, RANDOM BIT GENERATOR, V10, P32
   Pareek NK, 2010, IMAGE VISION COMPUT, V24, P926
   Patidar V, 2009, COMMUN NONLINEAR SCI, V14, P3056, DOI 10.1016/j.cnsns.2008.11.005
   Ponomarenko VI, 2002, PHYS REV E, V66, P262
   Sadoudi S, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-43
   Schneier B, 1996, APPL CRYPTOGRAPHY PR, P13
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Wang XY, 2016, OPT LASER ENG, V82, P79, DOI 10.1016/j.optlaseng.2015.12.006
   Wang Y, 2015, COMPUT ELECTR ENG, V46, P433, DOI 10.1016/j.compeleceng.2015.03.011
   Wang Y, 2009, CHAOS SOLITON FRACT, V41, P1773, DOI 10.1016/j.chaos.2008.07.031
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Yavuz E, 2016, COMPUT ELECTR ENG, V54, P471, DOI 10.1016/j.compeleceng.2015.11.008
   Zhang XP, 2014, SIGNAL PROCESS-IMAGE, V29, P902, DOI 10.1016/j.image.2014.06.012
   Zhang XP, 2014, COMPUT ELECTR ENG, V40, P931, DOI 10.1016/j.compeleceng.2013.08.008
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 32
TC 17
Z9 17
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 11669
EP 11692
DI 10.1007/s11042-017-4811-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100004
DA 2024-07-18
ER

PT J
AU Rui, T
   Zou, JH
   Zhou, Y
   Fei, JC
   Yang, CS
AF Rui, Ting
   Zou, Junhua
   Zhou, You
   Fei, Jianchao
   Yang, Chengsong
TI Convolutional neural network feature maps selection based on LDA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature maps selection; Convolutional neural network; Separability;
   Structure simplification
AB Convolutional neural network (CNN), as widely applied to vision and speech, has developed lager and lager network size in last few years. In this paper, we propose a CNN feature maps selection method which can simplify CNN structure on the premise of stabilize the classifier performance. Our approach aims to cut the feature map number of the last subsampling layer and achieves shortest runtime on the basis of Linear Discriminant Analysis (LDA). We rebuild feature maps selection formula based on the between-class scatter matrix and within-class scatter matrix, because LDA can lead to information loss in the dimension-reduction process. Our experiments measure on two standard datasets and a dataset made by ourselves. According to the separability value of each feature map, we suggest the least number of feature maps which can keep the classifier performance. Furthermore, we prove that separability value is an effective indicator for reference to select feature maps.
C1 [Rui, Ting] PLA Univ Sci & Technol, Dept Informat Technol, 1 Haifu Lane,Guanghua Rd, Nanjing, Jiangsu, Peoples R China.
   [Zou, Junhua; Fei, Jianchao] PLA Univ Sci & Technol, 1 Haifu Lane,Guanghua Rd, Nanjing, Jiangsu, Peoples R China.
   [Yang, Chengsong] PLA Univ Sci & Technol, Inst Field Engn, 1 Haifu Lane,Guanghua Rd, Nanjing, Jiangsu, Peoples R China.
   [Rui, Ting] Nanjing Univ, State Key Lab Novel Software Technol, 1 Haifu Lane,Guanghua Rd, Nanjing, Jiangsu, Peoples R China.
   [Zhou, You] Jiangsu Inst Commerce, 180 Longmian Rd, Nanjing, Jiangsu, Peoples R China.
C3 Army Engineering University of PLA; Army Engineering University of PLA;
   Army Engineering University of PLA; Nanjing University
RP Zou, JH (corresponding author), PLA Univ Sci & Technol, 1 Haifu Lane,Guanghua Rd, Nanjing, Jiangsu, Peoples R China.
EM rtinguu@sohu.com; zoujhzz@gmail.com; 354442511@qq.com; 349318312@qq.com;
   278287847@qq.com
OI Zou, Junhua/0000-0003-4655-7173
FU National Natural Science Foundation of China [61472444, 61472392]
FX This work was supported in part by National Natural Science Foundation
   of China: 61472444, 61472392.
CR [Anonymous], 2014, ARXIV14044316
   [Anonymous], NEUROCOMPUTING
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], 2016, INT C LEARNING REPRE
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2015, CORR
   [Anonymous], SALIENT OBJECT DETEC
   [Anonymous], PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2014, ABS14053531 CORR
   [Anonymous], ARXIV151201891
   [Anonymous], COMPUT SCI
   [Anonymous], 2013, ARXIV PREPRINT ARXIV
   [Anonymous], 2014, COMPUT SCI
   [Anonymous], CONCURRENCY COMPUTAT
   Chen WL, 2015, PR MACH LEARN RES, V37, P2285
   Courbariaux M., 2016, BinaryNet: Training deep neural networks with weights and activa
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Loog M, 2004, IEEE T PATTERN ANAL, V26, P732, DOI 10.1109/TPAMI.2004.13
   Lu HP, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/348036
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Redmon J., 2016, P IEEE C COMP VIS PA, P779, DOI DOI 10.1109/CVPR.2016.91
   Ren TW, 2016, MULTIMED TOOLS APPL, V75, P2543, DOI 10.1007/s11042-015-2875-z
   Ren TW, 2015, MULTIMEDIA SYST, V21, P189, DOI 10.1007/s00530-014-0384-y
   Scholkopft B., 1999, Neural networks for signal processing IX, V1, P1
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang N, 2014, PROC CVPR IEEE, P1637, DOI 10.1109/CVPR.2014.212
NR 34
TC 9
Z9 9
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10635
EP 10649
DI 10.1007/s11042-017-4684-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900015
DA 2024-07-18
ER

PT J
AU Tao, Y
   Wang, XD
   Xu, XW
AF Tao, Ye
   Wang, Xiaodong
   Xu, Xiaowei
TI Containerized resource provisioning framework for multimedia big data
   application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Containerized computing; Fuzzy inference system; Intuitionistic fuzzy
   value; User preference; Resouce provisioning
ID JOB MIGRATION; CLOUD
AB Container, as a light-weight virtualization solution, provides secure and effective approaches to control and limit access to resources for multimedia data and applications. However, due to the complexity of the containerized computing environment, setting up runtime configuration presents a great challenge for non-computational domain specialists without much knowledge of service-oriented computing and virtualization. In this paper, fuzzy-logic-based approaches are proposed to simplify the user preferences representation and automate the processes of container environment setup. By using fuzzy inference techniques, the approach allows users to define non-quantifiable factors and policies to represent their preferences, and automatically converts the vague requirements to numeric parameters and runtime deployment. Compared to classical methods, the proposed approach presents only the information relevant to user's requirements and preferences. The validation results show that with appropriate customization steps and natural interfaces, user preferences can be reflected effectively in the final configurations of containers. Furthermore, a fuzzy-logic-based schedule algorithm for global container resource allocation is also proposed, and the effectiveness of the provisioning policies are validated by sample use cases.
C1 [Tao, Ye; Wang, Xiaodong] Qingdao Univ Sci & Technol, Sch Informat & Technol, Qingdao, Peoples R China.
   [Xu, Xiaowei] Ocean Univ China, Dept Comp Sci & Technol, Qingdao, Peoples R China.
C3 Qingdao University of Science & Technology; Ocean University of China
RP Xu, XW (corresponding author), Ocean Univ China, Dept Comp Sci & Technol, Qingdao, Peoples R China.
EM xuxw525@ouc.edu.cn
RI Li, June/JEF-1173-2023; wang, xiao/HZI-9156-2023
OI Tao, Ye/0000-0001-5470-9451
FU National Key Research Development Program of China [2016YFB1001103];
   Shandong Province Key Research and Development Program [2016GGX103006];
   Natural Science Foundation of Shandong Province [ZR2014FM015]
FX This research is supported by the National Key Research Development
   Program of China (No. 2016YFB1001103), Shandong Province Key Research
   and Development Program (No. 2016GGX103006), and Natural Science
   Foundation of Shandong Province (No. ZR2014FM015).
CR Akgun A, 2012, COMPUT GEOSCI-UK, V38, P23, DOI 10.1016/j.cageo.2011.04.012
   [Anonymous], 2012, J SOFTWARE ENG APPL, DOI DOI 10.4236/JSEA.2012.512B029
   ATANASSOV KT, 1986, FUZZY SET SYST, V20, P87, DOI 10.1016/S0165-0114(86)80034-3
   Bernstein D, 2015, IEEE CLOUD COMPUT, V2, P69, DOI 10.1109/MCC.2015.10
   Bernstein D, 2014, IEEE CLOUD COMPUT, V1, P57, DOI 10.1109/MCC.2014.32
   Bhushan K, 2018, MULTIMED TOOLS APPL, V77, P4609, DOI 10.1007/s11042-017-4742-6
   Dragovic I, 2014, INT J COMPUT INT SYS, V7, P84, DOI 10.1080/18756891.2014.853935
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Gupta S, 2018, MULTIMED TOOLS APPL, V77, P4829, DOI 10.1007/s11042-016-3735-1
   Hu DD, 2013, AASRI PROC, V5, P235, DOI 10.1016/j.aasri.2013.10.084
   Ismail BI, 2015, IEEE CONF OPEN SYST, P130, DOI 10.1109/ICOS.2015.7377291
   Kang D, 2016, IEEE REG 10 C TENCON, P2159, DOI [10.1109/TENCON.2016.7848467, DOI 10.1109/TENCON.2016.7848467]
   Karun AK, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P132
   Kokkonis G, 2017, J SUPERCOMPUT, V73, P1044, DOI 10.1007/s11227-016-1769-9
   Luo X, 2015, IEEE ACCESS, V3, P2260, DOI 10.1109/ACCESS.2015.2498191
   Ma H, 2015, J CENT SOUTH UNIV, V22, P3495, DOI 10.1007/s11771-015-2889-8
   Mallayya Deivamani, 2015, Scientific World Journal, V2015, DOI 10.1155/2015/207174
   Martínez LG, 2013, COMPUT APPL ENG EDUC, V21, P596, DOI 10.1002/cae.20504
   McDaniel S, 2015, IEEE INT C CL COMP, P490, DOI 10.1109/CLUSTER.2015.77
   Memos VA, 2017, FUTURE GENERATION CO
   Merkel D., 2014, LINUX J, V2014, P2, DOI DOI 10.5555/2600239.2600241
   Monsalve J, 2015, IEEE INT C CL COMP, P535, DOI 10.1109/CLUSTER.2015.99
   Nine Z., 2013, IEEE International Conference, P1
   Rathore N. K, 2015, I MANAGERS J COMPUTE, V3, P7
   Rathore N, 2014, J INTELL FUZZY SYST, V27, P2821, DOI 10.3233/IFS-141243
   Rathore N, 2014, WIRELESS PERS COMMUN, V79, P2089, DOI 10.1007/s11277-014-1975-9
   Saraswathi AT, 2015, PROCEDIA COMPUT SCI, V47, P30, DOI 10.1016/j.procs.2015.03.180
   Singh S, 2016, KNOWL INF SYST, V49, P1005, DOI 10.1007/s10115-016-0922-3
   Tao Y, 2016, INT J SIMULATION PRO
   Tsai WT, 2016, CAAI T INTELL TECHNO, V1, P150, DOI 10.1016/j.trit.2016.08.002
   Turnbull James, 2015, THE DOCKER BOOK
   Wickremasinghe B, 2010, INT CON ADV INFO NET, P446, DOI 10.1109/AINA.2010.32
   Yinong C, 2015, SERVICE ORIENTED COM
   Yu G, 2016, SOFT COMPUT, V20, P4005, DOI 10.1007/s00500-015-1736-z
   Zhang R, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON CLOUD ENGINEERING (IC2E 2015), P365, DOI 10.1109/IC2E.2015.101
NR 35
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11439
EP 11457
DI 10.1007/s11042-017-5366-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900058
DA 2024-07-18
ER

PT J
AU Wang, MH
   Mai, JM
   Liang, Y
   Cai, RC
   Fu, TZ
   Zhang, ZJ
AF Wang, Meihua
   Mai, Jiaming
   Liang, Yun
   Cai, Ruichu
   Fu, Tom Zhengjia
   Zhang, Zhenjie
TI A component-driven distributed framework for real-time video dehazing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video dehazing; Image restoration; Image enhancement; Distributed
   computing
ID IMAGE; ALGORITHM; MANAGEMENT
AB Traditional dehazing techniques, as a well studied topic in image processing, are now widely used to eliminate the haze effects from individual images. However, the state-of-the-art dehazing algorithms may not provide sufficient support to video analytics, as a crucial pre-processing step for video-based decision making systems (e.g., robot navigation), due to poor coherence and low processing efficiency of the present algorithms. This paper presents a new framework, particularly designed for video dehazing, to output coherent results in real time, with two novel techniques. Firstly, we decompose the dehazing algorithms into three generic components, namely transmission map estimator, atmospheric light estimator and haze-free image generator. They can be simultaneously processed by multiple threads in the distributed system, such that the processing efficiency is optimized by automatic CPU resource allocation based on the workloads. Secondly, a cross-frame normalization scheme is proposed to enhance the coherence among consecutive frames, by sharing the parameters of atmospheric light from consecutive frames in the distributed computation platform. The combination of the above three components enables our framework to generate highly consistent and accurate dehazing results in real-time, by using only 5 PCs connected by Ethernet.
C1 [Wang, Meihua; Mai, Jiaming; Liang, Yun] South China Agr Univ, Coll Math & Informat, Guangzhou, Guangdong, Peoples R China.
   [Cai, Ruichu] Guangdong Univ Technol, Sch Comp Sci & Technol, Guangzhou, Guangdong, Peoples R China.
   [Fu, Tom Zhengjia; Zhang, Zhenjie] Illinois Singapore Pte Ltd, Adv Digital Sci Ctr, Singapore, Singapore.
C3 South China Agricultural University; Guangdong University of Technology
RP Mai, JM (corresponding author), South China Agr Univ, Coll Math & Informat, Guangzhou, Guangdong, Peoples R China.
EM wangmeihua@scau.edu.cn; jiamingmai@163.com; sdliangyun@163.com;
   cairuichu@gmail.com; tom.fu@adsc.com.sg; zhenjie@adsc.com.sg
RI cai, ruichu/AAX-7200-2021
FU National Natural Science Foundation of China [61202269, 61472089,
   61202293, 31600591]; Science and Technology Plan Project of Guangdong
   Province [2014A0050503057, 2015A020209124, 2016A020210087]
FX This work is financially supported by National Natural Science
   Foundation of China (61202269, 61472089, 61202293, 31600591), Science
   and Technology Plan Project of Guangdong Province (2014A0050503057,
   2015A020209124, 2016A020210087).
CR Ancuti Codruta O., 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P501, DOI 10.1007/978-3-642-19309-5_39
   [Anonymous], ACM INT C MULT
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], ACM SIGMOD INT C MAN
   Dong XM, 2010, IEEE IMAGE PROC, P3593, DOI 10.1109/ICIP.2010.5651965
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Ge C, 2014, IEEE T NETW SERV MAN, V11, P264, DOI 10.1109/TNSM.2014.2346956
   Gibson KB, 2012, IEEE T IMAGE PROCESS, V21, P662, DOI 10.1109/TIP.2011.2166968
   Gulisano V, 2012, IEEE T PARALL DISTR, V23, P2351, DOI 10.1109/TPDS.2012.24
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Kim JY, 2001, IEEE T CIRC SYST VID, V11, P475, DOI 10.1109/76.915354
   Kim TK, 1998, IEEE T CONSUM ELECTR, V44, P82, DOI 10.1109/30.663733
   Kokkonis G, 2017, J SUPERCOMPUT, V73, P1044, DOI 10.1007/s11227-016-1769-9
   Kokkonis G, 2016, J REAL-TIME IMAGE PR, V12, P343, DOI 10.1007/s11554-015-0505-7
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Kratz L, 2009, IEEE I CONF COMP VIS, P1701, DOI 10.1109/ICCV.2009.5459382
   Kulkarni S, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P239, DOI 10.1145/2723372.2742788
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li ZW, 2015, PROC CVPR IEEE, P4988, DOI 10.1109/CVPR.2015.7299133
   Lu HM, 2016, MULTIMED TOOLS APPL, V75, P17081, DOI 10.1007/s11042-015-2977-7
   Memos VA, 2016, J REAL-TIME IMAGE PR, V12, P473, DOI 10.1007/s11554-015-0509-3
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan S. G., 2003, Interactive (de) weathering of an image using physical models, V6, P1
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Nishino K, 2012, INT J COMPUT VISION, V98, P263, DOI 10.1007/s11263-011-0508-1
   Pei SC, 2012, IEEE IMAGE PROC, P957, DOI 10.1109/ICIP.2012.6467020
   Psannis KE, 2006, IEEE T CIRC SYST VID, V16, P280, DOI 10.1109/TCSVT.2005.859933
   Psannis K, 2008, IEICE T COMMUN, VE91B, P2692, DOI 10.1093/ietcom/e91-b.8.2692
   Psannis K, 2009, IEICE ELECTRON EXPR, V6, P1497, DOI [10.1587/elex.6.1497, 10.1587/elex.6.1437]
   Psannis K, 2008, IEICE ELECTRON EXPR, V5, P827, DOI 10.1587/elex.5.827
   Psannis KE, 2006, EURASIP J WIREL COMM, DOI 10.1155/WCN/2006/24616
   Psannis KE, 2016, J REAL-TIME IMAGE PR, V12, P509, DOI 10.1007/s11554-015-0514-6
   Psannis KE, 2009, TELECOMMUN SYST, V41, P65, DOI 10.1007/s11235-009-9151-3
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Tan HL, 2017, MULTIMED TOOLS APPL, V76, P23413, DOI 10.1007/s11042-016-4036-4
   Tan R. T., 2008, IEEE COMPUTER SOC C, P1
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Toshniwa A, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P147, DOI 10.1145/2588555.2595641
   Treibitz T, 2009, IEEE T PATTERN ANAL, V31, P385, DOI 10.1109/TPAMI.2008.85
   Wu JS, 2016, IEEE SYST J, V10, P873, DOI 10.1109/JSYST.2016.2550538
   Wu JS, 2014, IEEE COMMUN MAG, V52, P14, DOI 10.1109/MCOM.2014.6829939
   Xiao CX, 2012, VISUAL COMPUT, V28, P713, DOI 10.1007/s00371-012-0679-y
   Xingyong Lv, 2010, 2010 Pacific Graphics (PG). Proceedings 18th Pacific Conference on Computer Graphics and Applications, P62, DOI 10.1109/PacificGraphics.2010.16
   Yu J, 2010, INT CONF SIGN PROCES, P1048, DOI 10.1109/ICOSP.2010.5655901
   Zhang JW, 2011, VISUAL COMPUT, V27, P749, DOI 10.1007/s00371-011-0569-8
   Zhang WS, 2016, IEEE SOFTWARE, V33, P44, DOI 10.1109/MS.2016.31
   Zhang WS, 2014, 2014 IEEE 11TH INTL CONF ON UBIQUITOUS INTELLIGENCE AND COMPUTING AND 2014 IEEE 11TH INTL CONF ON AUTONOMIC AND TRUSTED COMPUTING AND 2014 IEEE 14TH INTL CONF ON SCALABLE COMPUTING AND COMMUNICATIONS AND ITS ASSOCIATED WORKSHOPS, P732, DOI 10.1109/UIC-ATC-ScalCom.2014.115
   Zhang WB, 2018, MULTIMED TOOLS APPL, V77, P2947, DOI 10.1007/s11042-017-4547-7
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 51
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11259
EP 11276
DI 10.1007/s11042-017-5518-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900049
DA 2024-07-18
ER

PT J
AU Chu, TW
   Shen, CA
   Wu, CW
AF Chu, Teng-Wei
   Shen, Chung-An
   Wu, Chun-Wei
TI The hardware and software co-design of a configurable QoS for video
   streaming based on OpenFlow protocol and NetFPGA platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video streaming; QoS; Configurability; Software Defined Networking
   (SDN); OpenFlow switch; NetFPGA
ID NETWORK; MANAGEMENT
AB In order to guarantee the Quality of Service (QoS) requirements of multimedia network, based on the concept of Software Defined Networking (SDN) and OpenFlow protocol, this paper presents the hardware and software co-design of a configurable QoS scheme for video streaming. Specifically, we present the architecture of an OpenFlow switch where the allocated network bandwidth for each multimedia traffic can be dynamically configured by the SDN controller. The detailed structures of software and hardware components are illustrated in this paper. For proof of concept, we realize the proposed switch based on a System on Chip (SoC) platform. We first implement a basic OpenFlow switch based on the state-of-the-art NetFPGA-CML platform. This design occupies 40% of total resources, and is promising for further researches and developments of multimedia networks. We realize the proposed OpenFlow switch with configurable QoS on this platform and carry practical experiments and measurements. The experimental results show that the proposed configurable QoS scheme enhances the QoS and received PSNR of the video streaming.
C1 [Chu, Teng-Wei; Shen, Chung-An; Wu, Chun-Wei] Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology
RP Shen, CA (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, Taipei, Taiwan.
EM cashen@mail.ntust.edu.tw
FU Ministry of Science and Technology (MOST), Taiwan, R.O.C. [MOST
   105-2218-E-002-014]
FX This work is supported in part by the Ministry of Science and Technology
   (MOST), Taiwan, R.O.C., under Grant MOST 105-2218-E-002-014.
CR Almadani B, 2016, MULTIMED TOOLS APPL, V75, P5841, DOI 10.1007/s11042-015-2551-3
   [Anonymous], 2009, P INFOCOM KEY NOT, DOI [DOI 10.1109/CC.2014.6821732, 10.1109/CC.2014.6821732]
   [Anonymous], 2012, NEW NORM NETW
   López LIB, 2015, IET NETW, V4, P255, DOI 10.1049/iet-net.2014.0117
   Doulamis AD, 2003, IEEE T NEURAL NETWOR, V14, P150, DOI 10.1109/TNN.2002.806645
   Frias VC, 2005, INT C COMP TOOL BELG, DOI [10.1109/EURCON.2005.1630011, DOI 10.1109/EURCON.2005.1630011]
   Gharakheili HH, 2015, 25TH INTERNATIONAL TELECOMMUNICATION NETWORKS AND APPLICATIONS CONFERENCE (ITNAC 2015), P214, DOI 10.1109/ATNAC.2015.7366815
   Gibb G, 2008, IEEE T EDUC, V51, P364, DOI 10.1109/TE.2008.919664
   Ishimori Airton, 2013, 2013 Second European Workshop on Software Defined Networks (EWSDN), P81, DOI 10.1109/EWSDN.2013.20
   Kim H, 2013, IEEE COMMUN MAG, V51, P114, DOI 10.1109/MCOM.2013.6461195
   Kimiyama H, 2015, ASIA-PAC CONF COMMUN, P338, DOI 10.1109/APCC.2015.7412535
   Kurose .J., 2000, COMPUTER NETWORKING
   Liu Y, 2008, PEER PEER NETW APPL, V1, P18, DOI 10.1007/s12083-007-0006-y
   McKeown N, 2008, ACM SIGCOMM COMP COM, V38, P69, DOI 10.1145/1355734.1355746
   Naous Jad., 2008, P 4 ACMIEEE S ARCHIT, P1, DOI DOI 10.1145/1477942.1477944
   Narisetty R, 2013, 2013 SECOND GENI RESEARCH AND EDUCATIONAL EXPERIMENT WORKSHOP (GREE), P66, DOI 10.1109/GREE.2013.21
   Nunes BAA, 2014, IEEE COMMUN SURV TUT, V16, P1617, DOI 10.1109/SURV.2014.012214.00180
   Pereini Peter, 2013, 2013 Second European Workshop on Software Defined Networks (EWSDN), P44, DOI 10.1109/EWSDN.2013.14
   Seok Hong Min, 2011, 2011 International Conference on ICT Convergence, P597, DOI 10.1109/ICTC.2011.6082692
   Sivaraman A., 2013, P 12 ACM WORKSH HOT, V19, P1
   Tatsuya Y, 2010, NETFPGA 10G OPENFLOW
   Hieu TT, 2013, J SYST ARCHITECT, V59, P202, DOI 10.1016/j.sysarc.2013.03.013
   Wang WD, 2014, CHINA COMMUN, V11, P13, DOI 10.1109/CC.2014.6895381
   Yen TC, 2014, ELEKTRON ELEKTROTECH, P1728
NR 24
TC 5
Z9 5
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 9071
EP 9091
DI 10.1007/s11042-017-4806-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800058
DA 2024-07-18
ER

PT J
AU Himeur, Y
   Boukabou, A
AF Himeur, Yassine
   Boukabou, Abdelkrim
TI A robust and secure key-frames based video watermarking system using
   chaotic encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video watermarking; Shot detection; Key-frames; Chaotic encryption;
   Blind; DWT-SVD
ID SINGULAR-VALUE DECOMPOSITION; DISCRETE WAVELET TRANSFORM; IMAGE
   WATERMARKING; DIGITAL IMAGE; EFFICIENT; COLOR; SCHEME; MAP
AB Currently we are facing a wide interest in multimedia security and copyright protection due to the explosion of data exchange in the Internet and the extensive use of digital media. In this paper, we propose a video watermarking method in which watermark information are encrypted using a new chaotic encryption, and then, embedded in the key-frames extracted from the video stream. Under this framework, a simple and fast key-frames extraction algorithm based on gradient magnitude similarity deviation (GMSD) is used. This algorithm can significantly decrease the complexity of video watermarking systems. In order to insert the watermark in a blind manner, new insertion and extraction functions are designed by means of a quantization process. A double transformation domain based on discrete wavelet transform (DWT) and singular value decomposition (SVD) is adopted to robustly embed the watermark with low visual distortion. Evaluation study is conducted to verify the performance through a series of experiments. The proposed system outperforms several recent algorithms found in the literature in terms of the robustness and imperceptibility under potential attacks. Furthermore, the security requirement of the proposed algorithm is achieved with the proposed chaotic encryption procedure.
C1 [Himeur, Yassine] Ctr Dev Adv Technol CDTA, Telecom Div, Algiers 16303, Algeria.
   [Himeur, Yassine; Boukabou, Abdelkrim] Univ MSB Jijel, Dept Elect, BP 98, Ouled Aissa 18000, Jijel, Algeria.
RP Himeur, Y (corresponding author), Ctr Dev Adv Technol CDTA, Telecom Div, Algiers 16303, Algeria.; Himeur, Y (corresponding author), Univ MSB Jijel, Dept Elect, BP 98, Ouled Aissa 18000, Jijel, Algeria.
EM yhimeur@cdta.dz
RI Himeur, Yassine/AAK-7814-2021
OI Himeur, Yassine/0000-0001-8904-5587
CR Abdallah HA, 2014, INFORM PROCESS MANAG, V50, P909, DOI 10.1016/j.ipm.2014.07.001
   Agilandeeswari L, 2016, MULTIMED TOOLS APPL, V75, P8745, DOI 10.1007/s11042-015-2789-9
   [Anonymous], 1977, FIPS PUB
   [Anonymous], 2001, FIPS PUB
   Chen HY, 2014, MULTIMED TOOLS APPL, V71, P991, DOI 10.1007/s11042-012-1238-2
   Cisco visual networking index, 2012, FOR METH 2011 2016
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Dang C, 2015, IEEE T IMAGE PROCESS, V24, P3742, DOI 10.1109/TIP.2015.2445572
   Dutta T, 2013, MULT EXP ICME 2013 I, P1, DOI DOI 10.1109/ICME.2013.6607430
   Ejaz N, 2014, COMPUT ELECTR ENG, V40, P993, DOI 10.1016/j.compeleceng.2013.10.005
   El'Arbi M, 2011, MULTIMED TOOLS APPL, V55, P579, DOI 10.1007/s11042-010-0580-5
   Faragallah OS, 2013, AEU-INT J ELECTRON C, V67, P189, DOI 10.1016/j.aeue.2012.07.010
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Fu C, 2012, OPT EXPRESS, V20, P2363, DOI 10.1364/OE.20.002363
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Gaj S, 2016, MULTIMED TOOLS APPL, V75, P3053, DOI 10.1007/s11042-014-2422-3
   Ganic Emir., 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Himeur Y, 2012, MICROELECTRONICS, P1
   Himeur Y, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS (SIGMAP), P40
   Himeur Y, 2015, IEEE INT SYMP SIGNAL, P495, DOI 10.1109/ISSPIT.2015.7394386
   Hu HT, 2015, COMPUT ELECTR ENG, V41, P52, DOI 10.1016/j.compeleceng.2014.08.001
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Jiang XM, 2013, MULTIMED TOOLS APPL, V62, P545, DOI 10.1007/s11042-011-0857-3
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Li Z, 2015, MULTIMED TOOLS APPL, V74, P2781, DOI 10.1007/s11042-013-1678-3
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Lin WY, 2012, IEEE T BROADCAST, V58, P34, DOI 10.1109/TBC.2011.2170611
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Muhammad K, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0473-x
   Muhammad N, 2015, IET IMAGE PROCESS, V9, P795, DOI 10.1049/iet-ipr.2014.0395
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Preda RO, 2011, J ELECTRON IMAGING, V20, P13
   Ren JC, 2009, IEEE T CIRC SYST VID, V19, P1234, DOI 10.1109/TCSVT.2009.2022707
   Sarkar A, 2010, IEEE T CIRC SYST VID, V20, P870, DOI 10.1109/TCSVT.2010.2046056
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Shahid Z, 2013, SIGNAL IMAGE VIDEO P, V7, P679, DOI 10.1007/s11760-013-0483-9
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Singh TR, 2013, AEU-INT J ELECTRON C, V67, P645, DOI 10.1016/j.aeue.2013.01.008
   Sprott JC., 2003, CHAOS TIME SERIES AN
   Stinson D. R., 2006, Cryptography Theory and Practice, V3rd
   Wang XY, 2015, COMPUT ELECTR ENG, V46, P403, DOI 10.1016/j.compeleceng.2015.04.001
   Wu Y, 2014, INFORM SCIENCES, V264, P317, DOI 10.1016/j.ins.2013.11.027
   Xu DW, 2014, IEEE T INF FOREN SEC, V9, P596, DOI 10.1109/TIFS.2014.2302899
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yavuz E, 2016, COMPUT ELECTR ENG, V54, P471, DOI 10.1016/j.compeleceng.2015.11.008
   Youssef SM, 2014, MULTIMED TOOLS APPL, V73, P1545, DOI 10.1007/s11042-013-1515-8
   Zhang M, 2014, J SYST SOFTWARE, V98, P140, DOI 10.1016/j.jss.2014.08.066
   Zhou GM, 2015, NEUROCOMPUTING, V169, P150, DOI 10.1016/j.neucom.2014.11.095
NR 51
TC 49
Z9 50
U1 2
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8603
EP 8627
DI 10.1007/s11042-017-4754-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800037
DA 2024-07-18
ER

PT J
AU Peng, F
   Qin, L
   Long, M
AF Peng, Fei
   Qin, Le
   Long, Min
TI Face presentation attack detection using guided scale texture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face presentation attack detection; Guided scale; Guided scale based
   local binary pattern; Local guided binary pattern
ID SPOOFING DETECTION; IMAGE QUALITY; RECOGNITION; SYSTEMS; IRIS
AB Aiming to counter presentation attack (also known as spoofing attack) in face recognition system, a face presentation attack detection (also known as spoofing detection or liveness detection) scheme based on guided scale texture is proposed. In order to minimize the influence of the redundant noise contamination, guided scale space is proposed to reduce the redundancy of the original facial texture and to extract more powerful facial edges. Based on the guided scale space, two guided scale texture descriptors are proposed to extract liveness detection features, and they are guided scale based local binary pattern (GS-LBP) and local guided binary pattern (LGBP). GS-LBP takes advantage of the edge-preserving property of the guided scale space, and joint quantization is used in LGBP to encode the neighboring relationships of the original face and the guided scale face without using additional features. With the guided scale texture features, presentation attack detection is accomplished by the use of a linear support vector machine classifier. Experiments are done with public MSU MFSD, CASIA FASD, Replay-Attack and Replay-Mobile databases, and the results indicate its effectiveness. The proposed method can effectively be applied for countering photo attack and video attack in face recognition systems.
C1 [Peng, Fei; Qin, Le] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Long, Min] Changsha Univ Sci & Technol, Coll Comp & Commun Engn, Changsha 410014, Hunan, Peoples R China.
C3 Hunan University; Changsha University of Science & Technology
RP Peng, F (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
EM eepengf@gmail.com; qinle@hnu.edu.cn; caslongm@gmail.com
RI Long, Min/AGW-6059-2022; Peng, Fei/H-6951-2017
OI Peng, Fei/0000-0001-8053-4587
FU National Natural Science Foundation of China [61572182, 61370225]; Hunan
   Provincial Natural Science Foundation of China [15JJ2007]; Scientific
   Research Plan of Hunan Provincial Science and Technology Department of
   China [2014FJ4161]
FX This work was supported in part by project supported by National Natural
   Science Foundation of China (Grant No. 61572182, 61370225), project
   supported by Hunan Provincial Natural Science Foundation of China (Grant
   No. 15JJ2007), and supported by the Scientific Research Plan of Hunan
   Provincial Science and Technology Department of China (2014FJ4161).
CR Alotaibi A, 2017, SIGNAL IMAGE VIDEO P, V11, P713, DOI 10.1007/s11760-016-1014-2
   Anjos A, 2014, IET BIOMETRICS, V3, P147, DOI 10.1049/iet-bmt.2012.0071
   [Anonymous], P INT C BIOM SPEC IN
   [Anonymous], 2014, ABS14085601 CORR
   [Anonymous], 2015, 301073 ISOIEC WD
   [Anonymous], P INT WORKSH DIG WAT
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2015, 301071 ISOIEC WD
   [Anonymous], EUR PEAN C COMP
   Arashloo SR, 2015, IEEE T INF FOREN SEC, V10, P2396, DOI 10.1109/TIFS.2015.2458700
   Bharadwaj S, 2014, IIITDTR2014002
   Biggio B, 2017, IEEE T PATTERN ANAL, V39, P561, DOI 10.1109/TPAMI.2016.2558154
   Blasco J, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2968215
   Boulkenafet Z, 2016, INT CONF BIOMETR
   Boulkenafet Z, 2017, IEEE SIGNAL PROC LET, V24, P141, DOI 10.1109/LSP.2016.2630740
   Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286
   Boulkenafet Z, 2015, IEEE IMAGE PROC, P2636, DOI 10.1109/ICIP.2015.7351280
   Chierchia Giovanni, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6231, DOI 10.1109/ICASSP.2014.6854802
   Chingovska I, 2014, IEEE T INF FOREN SEC, V9, P2264, DOI 10.1109/TIFS.2014.2349158
   Chingovska Ivana, 2012, BIOSIG
   de Freitas Pereira Tiago, 2013, Biometrics (ICB), 2013 International Conference on, DOI DOI 10.1109/ICB.2013.6612981
   Erdogmus N, 2014, IEEE T INF FOREN SEC, V9, P1084, DOI 10.1109/TIFS.2014.2322255
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Farmanbar M, 2017, SIGNAL IMAGE VIDEO P, V11, P1253, DOI 10.1007/s11760-017-1082-y
   Feng LT, 2016, J VIS COMMUN IMAGE R, V38, P451, DOI 10.1016/j.jvcir.2016.03.019
   Galbally J, 2014, INT C PATT RECOG, P1173, DOI 10.1109/ICPR.2014.211
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Garcia DC, 2015, IEEE T INF FOREN SEC, V10, P778, DOI 10.1109/TIFS.2015.2411394
   Gomez-Barrero M, 2014, PATTERN RECOGN LETT, V36, P243, DOI 10.1016/j.patrec.2013.04.029
   Hadid A, 2015, IEEE SIGNAL PROC MAG, V32, P20, DOI 10.1109/MSP.2015.2437652
   Hadid A, 2014, IEEE COMPUT SOC CONF, P113, DOI 10.1109/CVPRW.2014.22
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Ji Z, 2016, IEEE IMAGE PROC, P1474, DOI 10.1109/ICIP.2016.7532603
   Kim W, 2015, IEEE T IMAGE PROCESS, V24, P2456, DOI 10.1109/TIP.2015.2422574
   Labati RD, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2933241
   Lei Z, 2011, IEEE T IMAGE PROCESS, V20, P247, DOI 10.1109/TIP.2010.2060207
   Li Y., 2014, P 9 ACM S INFORM COM, P413
   Li Y, 2018, IEEE T DEPEND SECURE, V15, P231, DOI 10.1109/TDSC.2016.2550459
   Li Y, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1558, DOI 10.1145/2810103.2813612
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Määttä J, 2012, IET BIOMETRICS, V1, P3, DOI 10.1049/iet-bmt.2011.0009
   Maatta J., 2011, 2011 INT JOINT C BIO, P1
   Manjani I, 2017, IEEE T INF FOREN SEC, V12, P1713, DOI 10.1109/TIFS.2017.2676720
   Marcel S, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6524-8
   Marcialis GL, 2014, ENCY BIOMETRICS, P1
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Patel K, 2016, IEEE T INF FOREN SEC, V11, P2268, DOI 10.1109/TIFS.2016.2578288
   Peng F, 2017, AEU-INT J ELECTRON C, V71, P72, DOI 10.1016/j.aeue.2016.11.009
   Pereira TD, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-2
   Pinto A, 2015, IEEE T IMAGE PROCESS, V24, P4726, DOI 10.1109/TIP.2015.2466088
   Pinto A, 2015, IEEE T INF FOREN SEC, V10, P1025, DOI 10.1109/TIFS.2015.2395139
   Phan QT, 2016, IEEE IMAGE PROC, P404, DOI 10.1109/ICIP.2016.7532388
   Raghavendra R, 2015, IEEE T IMAGE PROCESS, V24, P1060, DOI 10.1109/TIP.2015.2395951
   Rajoub BA, 2014, IEEE T INF FOREN SEC, V9, P1015, DOI 10.1109/TIFS.2014.2317309
   Ramachandra R, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3038924
   Steiner H., 2016, em 2016 International Conference on Biometrics (ICB), P1
   Tirunagari S, 2015, IEEE T INF FOREN SEC, V10, P762, DOI 10.1109/TIFS.2015.2406533
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   Wild P, 2016, PATTERN RECOGN, V50, P17, DOI 10.1016/j.patcog.2015.08.007
   Xu Y, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P497
   Zeng H, 2016, J FORENSIC SCI, V61, P520, DOI 10.1111/1556-4029.13017
   Zhang LB, 2017, J VIS COMMUN IMAGE R, V48, P471, DOI 10.1016/j.jvcir.2016.12.013
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
NR 65
TC 36
Z9 38
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8883
EP 8909
DI 10.1007/s11042-017-4780-0
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800049
DA 2024-07-18
ER

PT J
AU Venkatesan, C
   Karthigaikumar, P
   Varatharajan, R
AF Venkatesan, C.
   Karthigaikumar, P.
   Varatharajan, R.
TI A novel LMS algorithm for ECG signal preprocessing and KNN classifier
   based abnormality detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ECG noise removal; Adaptive filter; Least mean square algorithm;
   Discrete wavelet transform; Machine learning; KNN classifier
ID R-PEAK DETECTION; NOISE REMOVAL; IMPLEMENTATION; SYSTEM
AB ECG signal abnormality detection is useful for identifying heart related problems. Two popular abnormality detection techniques are ischaemic beat classification and arrhythmic beat classification. In this work, ECG signal preprocessing and KNN based arrhythmic beat classification are performed to categorize into normal and abnormal subjects. LMS based adaptive filters are used in ECG signal preprocessing, but they consume more time for processing due to long critical path. To overcome this problem, a novel adaptive filter with delayed error normalized LMS algorithm is utilized to attain high speed and low latency design. Low power design is achieved in this design by applying pipelining concept in the error feedback path. R-peak detection is carried out in the preprocessed signal using wavelets for HRV feature extraction. Arrhythmic beat classification is carried out by KNN classifier on HRV feature extracted signal. Classification performance reveals that the proposed DWT with KNN classifier provides the accuracy of 97.5% which is better than other machine leaning techniques.
C1 [Venkatesan, C.] Anna Univ, Fac Informat & Commun Engn, Chennai, Tamil Nadu, India.
   [Karthigaikumar, P.] Karpagam Coll Engn, Dept Elect & Commun Engn, Coimbatore, Tamil Nadu, India.
   [Varatharajan, R.] Sri Ramanujar Engn Coll, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
C3 Anna University; Anna University Chennai; Karpagam College of
   Engineering
RP Varatharajan, R (corresponding author), Sri Ramanujar Engn Coll, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
EM varathu21@yahoo.com
RI VENKATESAN, Dr. C./ADY-1844-2022; Palanivel,
   Karthigaikumar/AAR-5414-2020; Venkatesan, C./AAO-2581-2021
OI VENKATESAN, Dr. C./0000-0002-5577-5239; Venkatesan,
   C./0000-0002-1308-6400; P, Karthigaikumar/0000-0003-4850-0090
CR [Anonymous], 2014, J APPL SCI, DOI [10.3923/jas.2014.1628.1632, DOI 10.3923/jas.2014.1628.1632]
   [Anonymous], P WORLD ACAD SCI ENG
   Chawla MPS, 2011, APPL SOFT COMPUT, V11, P2216, DOI 10.1016/j.asoc.2010.08.001
   Elgendi M, 2009, 2009 35TH ANNUAL NORTHEAST BIOENGINEERING CONFERENCE, P78
   Gupta A, 2008, IEEE T SIGNAL PROCES, V56, P1411, DOI 10.1109/TSP.2007.909374
   Jubairahmed L, 2019, CLUSTER COMPUT, V22, P11237, DOI 10.1007/s10586-017-1370-x
   Köhler BU, 2002, IEEE ENG MED BIOL, V21, P42, DOI 10.1109/51.993193
   Kumar M, 2007, IEEE T FUZZY SYST, V15, P791, DOI 10.1109/TFUZZ.2006.889825
   Langley P, 2003, COMPUT CARDIOL, V30, P239, DOI 10.1109/CIC.2003.1291135
   Osowski S, 2004, IEEE T BIO-MED ENG, V51, P582, DOI 10.1109/TBME.2004.824138
   PARHI KK, 1989, IEEE T ACOUST SPEECH, V37, P1099, DOI 10.1109/29.32286
   Petkovic D, 2013, EXPERT SYST APPL, V40, P4490, DOI 10.1016/j.eswa.2013.01.055
   Rahman MZU, 2012, IEEE SENS J, V12, P566, DOI 10.1109/JSEN.2011.2111453
   Rooijakkers MJ, 2012, PHYSIOL MEAS, V33, P1135, DOI 10.1088/0967-3334/33/7/1135
   Satheeskumaran S, 2016, INT J ELECTRON, V103, P975, DOI 10.1080/00207217.2015.1082204
   Satheeskumaran S, 2014, NATL ACAD SCI LETT, V37, P341, DOI 10.1007/s40009-014-0238-3
   Stolojescu C, 2010, P INT CONF OPTIM EL, P932, DOI 10.1109/OPTIM.2010.5510403
   Szilágyi SM, 2000, P ANN INT IEEE EMBS, V22, P1267, DOI 10.1109/IEMBS.2000.897966
   Ting LK, 2005, IEEE T VLSI SYST, V13, P86, DOI 10.1109/TVLSI.2004.840403
   Tsipouras MG, 2005, ARTIF INTELL MED, V33, P237, DOI 10.1016/j.artmed.2004.03.007
   Venkatesan C, 2019, CLUSTER COMPUT, V22, P12233, DOI 10.1007/s10586-017-1602-0
   Wiggins M, 2008, APPL SOFT COMPUT, V8, P599, DOI 10.1016/j.asoc.2007.03.009
   Zhang JS, 2010, DIGIT SIGNAL PROCESS, V20, P23, DOI 10.1016/j.dsp.2009.06.006
   Zhou DY, 2006, INT CONF ACOUST SPEE, P5135
NR 24
TC 41
Z9 44
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 10365
EP 10374
DI 10.1007/s11042-018-5762-6
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200062
DA 2024-07-18
ER

PT J
AU Wang, L
   Lu, ZM
   Ma, LH
   Feng, YP
AF Wang, Lang
   Lu, Zhe-Ming
   Ma, Long-Hua
   Feng, Ya-Pei
TI VQ codebook design using modified K-means algorithm with feature
   classification and grouping based initialization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vector quantization; Codebook design; Initial codebook generation;
   K-means algorithm; Image compression
ID VECTOR QUANTIZER DESIGN; GENERATION; PATTERN
AB Vector quantization (VQ) has been successfully used in data compression and feature extraction areas. Codebook design is the essential step of VQ. The K-means algorithm is a famous data clustering technique which is also an efficient codebook design scheme. The main disadvantages of K-means algorithm lie in that the initial cluster centroids greatly affect the convergence speed and the final clustering performance. In the past two decades, many codebook initialization techniques have been proposed. However, most of these techniques do not make full use of the features of the training vectors, and some techniques require high extra computational load. This paper presents an efficient and simple technique for the conventional K-means algorithm based on feature classification and grouping. Firstly, all training vectors are classified into sixteen categories based on a two-level classifier including an edge classifier and a contrast classifier. Then, the training vectors in each category are sorted based on their norm values and divided into groups. Each group has the same size, and the centroid vector of each group is calculated as an initial codeword. Experimental results show that, compared with several typical initialization techniques, our technique can obtain a better codebook along with a faster convergence speed in a shorter time.
C1 [Wang, Lang; Ma, Long-Hua] Zhejiang Univ, Ningbo Inst Technol, Sch Informat Sci & Engn, Ningbo 315100, Zhejiang, Peoples R China.
   [Lu, Zhe-Ming; Feng, Ya-Pei] Zhejiang Univ, Sch Aeronaut & Astronaut, Room 105,Teaching Bldg 5,Yuquan Campus, Hangzhou 310027, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Lu, ZM (corresponding author), Zhejiang Univ, Sch Aeronaut & Astronaut, Room 105,Teaching Bldg 5,Yuquan Campus, Hangzhou 310027, Peoples R China.
EM zheminglu@zju.edu.cn
FU National Nature Science Foundation of China [61633019, 61272020];
   Zhejiang Provincial Natural Science Foundation of China [LZ15F030004];
   Ningbo Science & Technology Plan Project [2014B82015]
FX This work was supported partially by the financial support from the
   National Nature Science Foundation of China under grants No. 61633019
   and No. 61272020 and Zhejiang Provincial Natural Science Foundation of
   China under grant No. LZ15F030004 and Ningbo Science & Technology Plan
   Project (2014B82015).
CR [Anonymous], IEEE INT C FUZZ SYST
   Chang CC, 2006, PATTERN RECOGN LETT, V27, P1077, DOI 10.1016/j.patrec.2005.12.017
   Chen SX, 2010, ELECTRON LETT, V46, P630, DOI 10.1049/el.2010.3573
   Chen SX, 2008, IEICE T INF SYST, VE91D, P2189, DOI 10.1093/ietisy/e91-d.8.2189
   EQUITZ WH, 1989, IEEE T ACOUST SPEECH, V37, P1568, DOI 10.1109/29.35395
   Estevao RD, 2016, IEEE T CIRC SYST VID, V26, P750, DOI 10.1109/TCSVT.2015.2424053
   Gersho A., 2012, Vector Quantization and Signal Compression
   Hong YWP, 2017, IEEE T INF FOREN SEC, V12, P1170, DOI 10.1109/TIFS.2017.2656459
   Horng MH, 2011, 2011 4TH IEEE INTERNATIONAL CONFERENCE ON BROADBAND NETWORK AND MULTIMEDIA TECHNOLOGY (4TH IEEE IC-BNMT2011), P319, DOI 10.1109/ICBNMT.2011.6155949
   Kang GY, 2013, IEICE T INF SYST, VE96D, P1230, DOI 10.1587/transinf.E96.D.1230
   Katsavounidis I, 1994, IEEE SIGNAL PROC LET, V1, P144, DOI 10.1109/97.329844
   Lai JZC, 2008, PATTERN RECOGN, V41, P315, DOI 10.1016/j.patcog.2007.04.015
   Lee D, 1997, IEEE SIGNAL PROC LET, V4, P2, DOI 10.1109/97.551685
   Leitao HAS, 2015, IEEE LAT AM T, V13, P961, DOI 10.1109/TLA.2015.7106343
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Mirzaei B., 2014, P IR C INT SYST ICIS, P1
   Oliveira FDVR, 2013, IEEE T CIRCUITS-I, V60, P1331, DOI 10.1109/TCSI.2012.2226505
   Pal A. K., 2011, INT J COMPUT SCI ENG, V1, P72
   Paliwal KK, 2000, IEEE T IMAGE PROCESS, V9, P1964, DOI 10.1109/83.877216
   Qin C, 2016, SIGNAL PROCESS, V129, P48, DOI 10.1016/j.sigpro.2016.05.032
   Somasundaram K., 2010, INT J COMPUTER SCI E, V2, P1807
   Vasuki A, 2006, IEEE POTENTIALS, V25, P39, DOI 10.1109/MP.2006.1664069
   Xiong HL, 2004, IEEE SIGNAL PROC LET, V11, P474, DOI 10.1109/LSP.2004.824054
   Yang PY, 2016, IEEE ACCESS, V4, P1332, DOI 10.1109/ACCESS.2016.2548664
   Yu FX, 2011, ELECTRON LETT, V47, P100, DOI 10.1049/el.2010.3232
   Zhao WW, 2016, IEEE T SIGNAL INF PR, V2, P105, DOI 10.1109/TSIPN.2016.2524572
NR 26
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8495
EP 8510
DI 10.1007/s11042-017-4747-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800032
DA 2024-07-18
ER

PT J
AU Xie, C
   Zeng, WL
   Jiang, SQ
   Lu, XB
AF Xie, Chao
   Zeng, Weili
   Jiang, Shengqin
   Lu, Xiaobo
TI Bidirectionally aligned sparse representation for single image
   super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single imagesuper-resolution; Sparse representation; Sparse coefficient
   alignment; Bidirectional similarities
ID HIGH-RESOLUTION IMAGE; THRESHOLDING ALGORITHM; PARALLEL FRAMEWORK;
   RECONSTRUCTION; HEVC; PREDICTION; RECOVERY; DECISION; LIMITS; NOISY
AB It has been demonstrated that the sparse representation based framework is one of the most popular and promising ways to handle the single image super-resolution (SISR) issue. However, due to the complexity of image degradation and inevitable existence of noise, the coding coefficients produced by imposing sparse prior only are not precise enough for faithful reconstructions. In order to overcome it, we present an improved SISR reconstruction method based on the proposed bidirectionally aligned sparse representation (BASR) model. In our model, the bidirectional similarities are first modeled and constructed to form a complementary pair of regularization terms. The raw sparse coefficients are additionally aligned to this pair of standards to restrain sparse coding noise and therefore result in better recoveries. On the basis of fast iterative shrinkage-thresholding algorithm, a well-designed mathematic implementation is introduced for solving the proposed BASR model efficiently. Thorough experimental results indicate that the proposed method performs effectively and efficiently, and outperforms many recently published baselines in terms of both objective evaluation and visual fidelity.
C1 [Xie, Chao; Jiang, Shengqin; Lu, Xiaobo] Southeast Univ, Sch Automat, Nanjing, Jiangsu, Peoples R China.
   [Xie, Chao; Jiang, Shengqin; Lu, Xiaobo] Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Jiangsu, Peoples R China.
   [Zeng, Weili] Nanjing Univ Aeronaut & Astronaut, Coll Civil Aviat, Nanjing 210016, Jiangsu, Peoples R China.
C3 Southeast University - China; Nanjing University of Aeronautics &
   Astronautics
RP Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing, Jiangsu, Peoples R China.; Lu, XB (corresponding author), Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Jiangsu, Peoples R China.
EM xblu2013@126.com
OI Zeng, Weili/0000-0002-5266-2423; Xie, Chao/0000-0001-7542-1270
FU National Natural Science Foundation of China [61374194, 61403081];
   National Key Science & Technology Pillar Program of China
   [2014BAG01B03]; Key Research and Development Program of Jiangsu Province
   [BE2016739]; Priority Academic Program Development of Jiangsu Higher
   Education Institutions
FX This work was supported by the National Natural Science Foundation of
   China (No.61374194, No.61403081), the National Key Science & Technology
   Pillar Program of China (No.2014BAG01B03), the Key Research and
   Development Program of Jiangsu Province (No. BE2016739), and a Project
   Funded by the Priority Academic Program Development of Jiangsu Higher
   Education Institutions.
CR Aguena MLS, 2006, COMPUT VIS IMAGE UND, V102, P178, DOI 10.1016/j.cviu.2006.01.001
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319
   Bose N. K., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P269, DOI 10.1109/ICASSP.1993.319799
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2011, IEEE T IMAGE PROCESS, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Dong WS, 2011, IEEE I CONF COMP VIS, P1259, DOI 10.1109/ICCV.2011.6126377
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Elad M, 1997, IEEE T IMAGE PROCESS, V6, P1646, DOI 10.1109/83.650118
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Elad M, 2009, IEEE T INFORM THEORY, V55, P4701, DOI 10.1109/TIT.2009.2027565
   Farsiu S, 2004, INT J IMAG SYST TECH, V14, P47, DOI 10.1002/ima.20007
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   He Y, 2009, IMAGE VISION COMPUT, V27, P364, DOI 10.1016/j.imavis.2008.05.010
   Huang T.S., 1984, ADV COMPUTER VISION, V1, P317
   Kim SP, 1993, IEEE T IMAGE PROCESS, V2, P534, DOI 10.1109/83.242363
   KIM SP, 1990, IEEE T ACOUST SPEECH, V38, P1013, DOI 10.1109/29.56062
   Li XL, 2010, SIGNAL PROCESS, V90, P405, DOI 10.1016/j.sigpro.2009.05.028
   Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081
   Lu XQ, 2012, PROC CVPR IEEE, P1648, DOI 10.1109/CVPR.2012.6247858
   Mishra D, 2016, NEUROCOMPUTING, V202, P49, DOI 10.1016/j.neucom.2016.04.013
   Nasrollahi K, 2014, MACH VISION APPL, V25, P1423, DOI 10.1007/s00138-014-0623-4
   Nguyen N, 2001, IEEE T IMAGE PROCESS, V10, P573, DOI 10.1109/83.913592
   Omer OA, 2011, DIGIT SIGNAL PROCESS, V21, P508, DOI 10.1016/j.dsp.2011.02.005
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Peleg T, 2014, IEEE T IMAGE PROCESS, V23, P2569, DOI 10.1109/TIP.2014.2305844
   Purkait P, 2014, IEEE T IMAGE PROCESS, V23, P2277, DOI 10.1109/TIP.2014.2312289
   Qin FQ, 2009, J ELECTRON IMAGING, V18, DOI 10.1117/1.3091936
   STARK H, 1989, J OPT SOC AM A, V6, P1715, DOI 10.1364/JOSAA.6.001715
   Tian J, 2011, SIGNAL IMAGE VIDEO P, V5, P329, DOI 10.1007/s11760-010-0204-6
   Timofte R, 2016, PROC CVPR IEEE, P1865, DOI 10.1109/CVPR.2016.206
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Vrigkas M, 2013, SIGNAL PROCESS-IMAGE, V28, P494, DOI 10.1016/j.image.2012.12.008
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang SY, 2011, NEUROCOMPUTING, V74, P3193, DOI 10.1016/j.neucom.2011.04.014
   Yue LW, 2014, SIGNAL PROCESS, V105, P156, DOI 10.1016/j.sigpro.2014.04.031
   Zeng WL, 2015, NEUROCOMPUTING, V162, P218, DOI 10.1016/j.neucom.2015.03.049
   Zeng WL, 2012, IEEE T INTELL TRANSP, V13, P828, DOI 10.1109/TITS.2011.2180714
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
   Zhang XD, 2013, IEEE T IMAGE PROCESS, V22, P408, DOI 10.1109/TIP.2012.2214043
   Zhou L, 2014, MULTIMED TOOLS APPL, V71, P1879, DOI 10.1007/s11042-012-1311-x
NR 58
TC 4
Z9 5
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 7883
EP 7907
DI 10.1007/s11042-017-4689-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800005
DA 2024-07-18
ER

PT J
AU Yang, JQ
   Ren, HL
   Zhu, GP
   Huang, JW
   Shi, YQ
AF Yang, Jianquan
   Ren, Honglei
   Zhu, Guopu
   Huang, Jiwu
   Shi, Yun-Qing
TI Detecting median filtering via two-dimensional AR models of multiple
   filtered residuals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Median filtering detection; Autoregressive (AR) model;
   Filtered residual
ID DIGITAL IMAGES; ANTI-FORENSICS; IDENTIFICATION; COMPRESSION; TRACES
AB Median filtering, being an order statistic filtering, has been widely used in image denoising and recently also in image anti-forensics and anti-steganalysis. In the past few years, several methods have been developed for median filtering detection. However, it is still a challenging task to detect median filtering in JPEG compressed images. In this paper, we propose a novel method to solve this challenging task. We first generate median filtered residual (MFR), average filtered residual (AFR) and Gaussian filtered residual (GFR) by calculating the differences between an original image and its filtered images. Then, we propose to use two-dimensional autoregressive (2D-AR) model to characterize MFR, AFR and GFR separately, and further combine the 2D-AR coefficients of these three residuals into a set of features. Finally, the extracted feature set is fed into a support vector machine classifier for training and detection. Extensive experiments have demonstrated that compared with existing methods, the proposed one can achieve a considerable improvement in detecting median filtering in heavily compressed images.
C1 [Yang, Jianquan; Ren, Honglei; Zhu, Guopu] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, GD, Peoples R China.
   [Yang, Jianquan] Univ Chinese Acad Sci, Shenzhen Coll Adv Technol, Shenzhen 518055, GD, Peoples R China.
   [Zhu, Guopu] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [Huang, Jiwu] Shenzhen Univ, Coll Informat Engn, Shenzhen 518055, GD, Peoples R China.
   [Shi, Yun-Qing] New Jersey Inst Technol, Dept Elect & Comp Engn, Newark, NJ 07102 USA.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; Chinese Academy of Sciences; University of Chinese Academy of
   Sciences, CAS; Chinese Academy of Sciences; Institute of Information
   Engineering, CAS; Shenzhen University; New Jersey Institute of
   Technology
RP Zhu, GP (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, GD, Peoples R China.; Zhu, GP (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
EM gp.zhu@siat.ac.cn
RI zhen, wang/KBA-3844-2024; ouyang, jianquan/HTN-9999-2023; Shi,
   Yun/JWP-3360-2024; huang, jw/KVY-9917-2024
OI ouyang, jianquan/0000-0002-7518-5156; Zhu, Guopu/0000-0001-7956-5343;
   Yang, Jianquan/0000-0003-2613-8975
FU National Natural Science Foundation of China [61572489, 61672554]; Youth
   Innovation Promotion Association of CAS [2015299]
FX The authors appreciate the anonymous reviewers for their constructive
   comments. This work was supported in part by the National Natural
   Science Foundation of China under Grant 61572489 and Grant 61672554, and
   in part by the Youth Innovation Promotion Association of CAS under Grant
   2015299.
CR [Anonymous], 2002, NATURAL RESOURCES CO
   [Anonymous], 2007, P SPIE
   [Anonymous], 2011, P 13 INF HID C PRAG
   BOVIK AC, 1987, IEEE T ACOUST SPEECH, V35, P493, DOI 10.1109/TASSP.1987.1165153
   Cao G, 2010, IEEE INT CON MULTI, P89, DOI 10.1109/ICME.2010.5583869
   Chen CL, 2013, IEEE T IMAGE PROCESS, V22, P4699, DOI 10.1109/TIP.2013.2277814
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Dang-Nguyen DT, 2013, IEEE INT WORKSH MULT, P260, DOI 10.1109/MMSP.2013.6659298
   Dang-Nguyen D.T., 2015, P ACM MULT SYST C, P219
   Dirik AE, 2009, IEEE IMAGE PROC, P1497, DOI 10.1109/ICIP.2009.5414611
   Fan W, 2015, IEEE T INF FOREN SEC, V10, P1076, DOI 10.1109/TIFS.2015.2398362
   Fan ZG, 2003, IEEE T IMAGE PROCESS, V12, P230, DOI 10.1109/TIP.2002.807361
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Fontani M, 2012, P 20 EUR SIGN PROC C, P1239
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Furon T, 2008, EURASIP J INF SECUR, V2008, P3
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hui Zeng, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2704, DOI 10.1109/ICASSP.2014.6854091
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Kang XG, 2012, IEEE T INF FOREN SEC, V7, P393, DOI 10.1109/TIFS.2011.2168214
   KASHYAP RL, 1984, IEEE T INFORM THEORY, V30, P736, DOI 10.1109/TIT.1984.1056955
   Kee E, 2011, P NATL ACAD SCI USA, V108, P19907, DOI 10.1073/pnas.1110747108
   Kirchberg M., 2010, System Sciences (HICSS), 2010 43rd Hawaii International Conference on, P1
   Kirchner M, 2008, IEEE T INF FOREN SEC, V3, P582, DOI 10.1109/TIFS.2008.2008214
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Pasquini C, 2016, IEEE T INF FOREN SEC, V11, P1425, DOI 10.1109/TIFS.2016.2530636
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Piva A., 2013, Int. Scholarly Res. Notices, V2013
   Popescu A.C., 2004, Exposing digital forgeries by detecting duplicated image regions
   Qiu X., 2014, P 2 ACM WORKSH INF H, P165, DOI DOI 10.1145/2600918.2600941
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Stamm MC, 2011, IEEE T INF FOREN SEC, V6, P1050, DOI 10.1109/TIFS.2011.2119314
   Wu ZH, 2013, INT CONF ACOUST SPEE, P3043, DOI 10.1109/ICASSP.2013.6638217
   Yang JQ, 2014, IEEE T INF FOREN SEC, V9, P1933, DOI 10.1109/TIFS.2014.2359368
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
   Yun-Ni Lai, 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9225, P421, DOI 10.1007/978-3-319-22180-9_41
   Zhang YJ, 2014, IEEE SIGNAL PROC LET, V21, P275, DOI 10.1109/LSP.2013.2295858
NR 40
TC 39
Z9 41
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 7931
EP 7953
DI 10.1007/s11042-017-4691-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800008
DA 2024-07-18
ER

PT J
AU Deng, R
   Liu, GZ
AF Deng, Rui
   Liu, Guizhong
TI QoE driven cross-layer scheme for DASH-based scalable video transmission
   over LTE
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-layer; Dash; Scalable video; LTE; Adaption; Optimization
ID RESOURCE-ALLOCATION; DESIGN
AB Recently using Scalable Video Coding (SVC) in Dynamic Adaptive Streaming of over HTTP (DASH) has attracted more and more attention. In this paper, we present a Quality-of-Experience (QoE) driven Cross-Layer Scheme (QCLS) for DASH-based scalable video transmission over LTE. Specifically, assuming the priority-based extraction be exploited for bitstream adaption, we first propose a new continuous Rate-Distortion (RD) model for scalable video stream. Then to guarantee continuous playback, a two-level rate adaption algorithm is presented: a novel throughput-based algorithm is implemented for dynamic selection of segment bitrate on the DASH client side at the first level, and the second level applies the rate adaption by designing a suitable packet scheduling strategy at the Base Station. The packets of each segment with lower priority that are still left in the packet queues when their playback deadline is missed, would be considered as the ones that are beyond the actual transmission ability and discarded by the second-level rate adaption. Furthermore, in order to reasonably utilize the wireless resources in LTE (Long-Term Evolution) system, a cross-layer optimization problem that maximizes the total weighted received quality of the currently transmitted segments for all clients is formulated. In view of its high complexity of obtaining the optimal solution, we develop an approach of the suboptimal solution, which can determine a locally optimal transmission strategy in resource allocation as well as the corresponding Modulation and Coding Scheme. Accordingly, the transmission rate of each client can be obtained. Simulation results show that our proposed cross-layer scheme can provide better performance than the existing ones for DASH-based scalable video transmission over LTE.
C1 [Deng, Rui; Liu, Guizhong] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
   [Liu, Guizhong] Xi An Jiao Tong Univ, Sch Informat & Commun Engn, W Xianning St 28, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University
RP Liu, GZ (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.; Liu, GZ (corresponding author), Xi An Jiao Tong Univ, Sch Informat & Commun Engn, W Xianning St 28, Xian 710049, Shaanxi, Peoples R China.
EM dengrui618@stu.xjtu.edu.cn; liugz@xjtu.edu.cn
CR Andelin T., 2012, Proceedings of the 3rd ACM Multimedia Systems Conference, P149
   [Anonymous], COMM SOFTW SERV MULT
   [Anonymous], 36300V870 3GPP TS
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], THESIS
   Basukala R., 2009, AH ICI 2009, P1, DOI DOI 10.1109/AHICI.2009.5340336
   Choi JG, 2007, IEEE T VEH TECHNOL, V56, P766, DOI 10.1109/TVT.2006.889570
   Cicalò S, 2014, IEEE T MULTIMEDIA, V16, P848, DOI 10.1109/TMM.2014.2300442
   de Oliveira DFB, 2009, IEEE 2 IFIP WIRELESS
   Dianati M, 2005, IEEE WCNC, P712
   Fattah Hossam, 2009, 2009 IEEE 6th International Conference on Mobile Adhoc and Sensor Systems. MASS 2009, P929, DOI 10.1109/MOBHOC.2009.5337027
   Guo JJ, 2015, IEEE WCNC, P1, DOI 10.1109/WCNC.2015.7127435
   Guo Yan, 2016, Instrument Technique and Sensor, P1
   He LJ, 2014, IEEE T WIREL COMMUN, V13, P6768, DOI 10.1109/TWC.2014.2364603
   Huysegems R, 2012, BELL LABS TECH J, V16, P25, DOI 10.1002/bltj.20532
   Ji X, 2009, IEEE T CIRC SYST VID, V19, P1549, DOI 10.1109/TCSVT.2009.2026812
   Josep C, 2010, IEEE 71 VEH TECHN C, P1471
   JSVM, 2011, JSVM 9 19 11 REFEREN
   Kela P, 2008, 2008 3RD INTERNATIONAL SYMPOSIUM ON WIRELESS PERVASIVE COMPUTING, VOLS 1-2, P308, DOI 10.1109/ISWPC.2008.4556220
   Le HT, 2013, P IEEE ATC2013 HOCHI
   Li F, 2009, COMPUT COMMUN NETW S, P211, DOI 10.1007/978-1-84800-328-6_9
   Lin YB, 2009, IEEE T WIREL COMMUN, V8, P4066, DOI 10.1109/TWC.2009.080221
   Liu C, 2011, P ACMMMSYS
   Liu Y, 2015, IEEE T BROADCAST, V61, P651, DOI 10.1109/TBC.2015.2460611
   Luo HY, 2010, IEEE COMMUN MAG, V48, P102, DOI 10.1109/MCOM.2010.5402671
   M. of WINNER, 2005, IST2003507581 WINNER
   Mansour H, 2009, IEEE T MULTIMEDIA, V11, P1478, DOI 10.1109/TMM.2009.2032682
   Meng SB, 2016, IEEE T MULTIMEDIA, V18, P1124, DOI 10.1109/TMM.2016.2535270
   Miller K., 2012, 2012 Proceedings of the 19th International Packet Video Workshop (PV 2012), P173, DOI 10.1109/PV.2012.6229732
   Oo MZ, 2016, J COMMUN NETW-S KOR, V18, P238, DOI 10.1109/JCN.2016.000033
   Piro G, 2011, IEEE T MULTIMEDIA, V13, P1052, DOI 10.1109/TMM.2011.2152381
   Seema A, 2015, IEEE T BROADCAST, V61, P346, DOI 10.1109/TBC.2015.2400816
   Thang TC, 2014, IEEE J SEL AREA COMM, V32, P693, DOI 10.1109/JSAC.2014.140403
   Tuomaala E, 2005, IEEE 2 INT C MOB TEC
   Ye Z, 2016, 2016 IFIP NETWORKING CONFERENCE (IFIP NETWORKING) AND WORKSHOPS, P494, DOI 10.1109/IFIPNetworking.2016.7497215
   Yin XQ, 2015, ACM SIGCOMM COMP COM, V45, P325, DOI 10.1145/2785956.2787486
   Zhao M, 2014, IEEE T CIRCUITS SYST, P451
NR 37
TC 7
Z9 8
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6445
EP 6469
DI 10.1007/s11042-017-4551-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700002
DA 2024-07-18
ER

PT J
AU Farajzadeh, N
   Karamiani, A
   Hashemzadeh, M
AF Farajzadeh, Nacer
   Karamiani, Aziz
   Hashemzadeh, Mahdi
TI A fast and accurate moving object tracker in active camera model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moving object; Active camera; Tracking; k-means clustering; DBSCAN
   clustering; Frame difference
ID HUMAN MOTION ANALYSIS; VISUAL TRACKING; MULTIPLE; SURVEILLANCE
AB Detecting and tracking moving objects within a scene is an essential step for high-level machine vision applications such as video content analysis. In this paper, we propose a fast and accurate method for tracking an object of interest in a dynamic environment (active camera model). First, we manually select the region of the object of interest and extract three statistical features, namely the mean, the variance and the range of intensity values of the feature points lying inside the selected region. Then, using the motion information of the background's feature points and k-means clustering algorithm, we calculate camera motion transformation matrix. Based on this matrix, the previous frame is transformed to the current frame's coordinate system to compensate the impact of camera motion. Afterwards, we detect the regions of moving objects within the scene using our introduced frame difference algorithm. Subsequently, utilizing DBSCAN clustering algorithm, we cluster the feature points of the extracted regions in order to find the distinct moving objects. Finally, we use the same statistical features (the mean, the variance and the range of intensity values) as a template to identify and track the moving object of interest among the detected moving objects. Our approach is simple and straightforward yet robust, accurate and time efficient. Experimental results on various videos show an acceptable performance of our tracker method compared to complex competitors.
C1 [Farajzadeh, Nacer; Karamiani, Aziz; Hashemzadeh, Mahdi] Azarbaijan Shahid Madani Univ, Dept IT & Comp Engn, Tabriz, Iran.
C3 Azarbaijan Shahid Madani University
RP Farajzadeh, N (corresponding author), Azarbaijan Shahid Madani Univ, Dept IT & Comp Engn, Tabriz, Iran.
EM n.farajzadeh@azaruniv.edu; a.karamiani@azaruniv.edu;
   hashemzadeh@azaruniv.edu
RI Farajzadeh, Nacer/ACM-0675-2022; Hashemzadeh, Mahdi/ABD-1813-2020
OI Farajzadeh, Nacer/0000-0001-7590-0503; Hashemzadeh,
   Mahdi/0000-0003-0506-3513
CR Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   Akay B, 2015, SIGNAL IMAGE VIDEO P, V9, P967, DOI 10.1007/s11760-015-0758-4
   [Anonymous], 1995, CANADIAN IMAGE PROCE
   [Anonymous], P INT C IM SIGN PROC
   Argyros AA, 2004, LECT NOTES COMPUT SC, V3023, P368
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Doyle DD, 2014, MEASUREMENT, V48, P195, DOI 10.1016/j.measurement.2013.10.025
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Harris C., 1988, P ALV VIS C, P5210
   He SF, 2013, PROC CVPR IEEE, P2427, DOI 10.1109/CVPR.2013.314
   Hsieh YS, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P696, DOI 10.1109/ICCE.2012.6162066
   Jung B., 2004, International Conference on Intelligent Autonomous Systems, P980
   Jung YK, 2002, LECT NOTES COMPUT SC, V2532, P1137
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Karamiani A, 2016, MULTIMED TOOLS APPL, V75, P10999, DOI 10.1007/s11042-015-2823-y
   Kim IS, 2010, INT J CONTROL AUTOM, V8, P926, DOI 10.1007/s12555-010-0501-4
   Kundu A., 2010, 2010 IEEE International Conference on Robotics and Biomimetics (ROBIO), P1635, DOI 10.1109/ROBIO.2010.5723575
   Lefèvre S, 2004, LECT NOTES COMPUT SC, V3212, P606
   Lim J, 2013, MULTIMED TOOLS APPL, V65, P161, DOI 10.1007/s11042-012-1156-3
   Lim JS, 2005, LECT NOTES COMPUT SC, V3804, P527
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Rosenberg Y, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P238, DOI 10.1109/ACV.1998.732887
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Siam M., 2012, Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO), P2399, DOI 10.1109/ROBIO.2012.6491329
   Teng F, 2014, SIGNAL IMAGE VIDEO P, V8, P1069, DOI 10.1007/s11760-014-0629-4
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zaki M, 2009, SIGNAL IMAGE VIDEO P, V3, P145, DOI 10.1007/s11760-008-0066-3
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhao Tao., 2004, P 2004 IEEE COMPUTER, P406
NR 44
TC 6
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6775
EP 6797
DI 10.1007/s11042-017-4597-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700016
DA 2024-07-18
ER

PT J
AU Fernández, DG
   Del Barrio, AA
   Botella, G
   García, C
AF Fernandez, D. G.
   Del Barrio, A. A.
   Botella, G.
   Garcia, C.
TI Fast and effective CU size decision based on spatial and temporal
   homogeneity detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; CUsize decision; Spatial homogeneity; Temporal homogeneity; GPU
ID MODE DECISION; HEVC; ALGORITHM; SELECTION
AB High-Efficiency Video Coding (HEVC) is the latest video coding standard of the Joint Collaborative Team on Video Coding (JCT-VC). HEVC noticeably improves compression performance when compared with previous standards such as H264, and represents a major step forward in video compression technology. However, this improvement is achieved by increasing the complexity of the encoding process. HEVC employs a novel flexible quad-tree coding block partitioning structure that enables the use of large and multi-sized coding, prediction, and transform blocks. This system is more efficient but also more computationally demanding. In this article an optimized CU size decision algorithm is proposed to reduce the computational cost of quad-tree partitioning by means of spatial and temporal homogeneity analysis and classification, which are directly applied to the input image. If a CU is classified as spatially or temporally homogeneous the quad-tree recursive process is stopped. Furthermore, this image pre-analysis is performed using logic units and embedded hardware on a GPU, thus avoiding unnecessary waiting states, so the computational cost associated with this process is zero for the processor in charge of the encoding process. In comparison with the reference HM16.2 test model, the encoding time is reduced by up to 32.69%, with negligible quality loss and a maximum BD-Rate increase of 1.2% for low-delay P configuration.
C1 [Fernandez, D. G.] Procesamiento Digital & Sistemas SL Prodys, Video Proc Dept, Madrid, Spain.
   [Del Barrio, A. A.; Botella, G.; Garcia, C.] Univ Complutense Madrid, Comp Architecture & Automat Dept, Jose Garcia Santesmases 9, E-28040 Madrid, Spain.
C3 Complutense University of Madrid
RP Del Barrio, AA (corresponding author), Univ Complutense Madrid, Comp Architecture & Automat Dept, Jose Garcia Santesmases 9, E-28040 Madrid, Spain.
EM gfernandez@prodys.net; abarriog@ucm.es; gbotella@ucm.es; garsanca@ucm.es
RI Botella, Guillermo/H-1877-2015; Garcia Sanchez, Carlos/R-5056-2018; Del
   Barrio Garcia, Alberto Antonio/G-9962-2015
OI Garcia Sanchez, Carlos/0000-0002-3470-1097; Del Barrio Garcia, Alberto
   Antonio/0000-0002-6769-1200
FU EU (FEDER); Spanish MINECO [TIN 2015-65277-R, TIN2012-32180]
FX This paper has been supported by the EU (FEDER) and the Spanish MINECO,
   under grants TIN 2015-65277-R and TIN2012-32180.
CR Ahn S, 2015, IEEE T CIRC SYST VID, V25, P422, DOI 10.1109/TCSVT.2014.2360031
   Angelescu N, 2015, SCI B ELECT ENG FACU, V1
   [Anonymous], 2012, Document JCTVC-K1100
   [Anonymous], 2 NAT C TEL CONATEL
   [Anonymous], P 5 INT C INT MULT C
   [Anonymous], IEEE INT C IM PROC I
   [Anonymous], IEEE 10 INT C ASIC A
   [Anonymous], 2012, MATH PROBL ENG, DOI DOI 10.1371/J0URNAL.P0NE.0029654
   Bjontegarrd G, 2001, 13 VCEG M AUST
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Das I, 1999, STRUCT OPTIMIZATION, V18, P107, DOI 10.1007/s001580050111
   Intel Corporation, 2016, INTR ADV MOT EXT OPE
   Intel Corporation, 2016, CISC VIS NETW IND GL
   Khan MUK, 2013, DES AUT TEST EUROPE, P125
   Khronos OpenCLWorking Group, 2016, ONL DOC CL INT ADV M
   Khronos OpenCLWorking Group, 2016, OPENCL SPEC VERS 1 1
   Koumaras H., 2012, FUTURE NETWORK MOBIL
   Lee JH, 2013, IEEE INT C IM PROC I
   Lim K, 2015, IEEE T CIRC SYST VID, V25, P1335, DOI 10.1109/TCSVT.2014.2380194
   Liu X., 2016, IEEE T CIRCUITS SYST, P1
   MALLIKARACHCHI T, 2014, IEEE INT CON MULTI, DOI DOI 10.1109/ICME.2014.6890319
   McCann K., 2014, High Efficiency Video Coding (HEVC) Test Model 14 (HM 14) Encoder Description
   Min B, 2014, IEEE T CIRCUITS SYST, V25, P1
   Sangkwon Na, 2014, 2014 IEEE International Conference on Consumer Electronics (ICCE), P11, DOI 10.1109/ICCE.2014.6775887
   Shen LQ, 2008, IEEE T MULTIMEDIA, V10, P1208, DOI 10.1109/TMM.2008.2001358
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Shen LQ, 2010, IEEE T CIRC SYST VID, V20, P925, DOI 10.1109/TCSVT.2010.2045910
   Shen LQ, 2009, IEEE T BROADCAST, V55, P761, DOI 10.1109/TBC.2009.2030453
   Smith S.W., 1997, SCI ENG GUIDE DIGITA
   Sullivan G.J., 2014, High Efficiency Video Coding (HEVC)"
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tian GF, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P405, DOI 10.1109/PCS.2012.6213317
   Ting YC, 2014, IEEE INT SYMP CIRC S, P1929, DOI 10.1109/ISCAS.2014.6865538
   Wang HM, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P709, DOI 10.1109/ICME.2006.262412
   Wei Jiang, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1836, DOI 10.1109/CECNet.2012.6201851
   Wu D, 2005, IEEE T CIRC SYST VID, V15, P953, DOI 10.1109/TCSVT.2005.848304
   Xiong J, 2015, IEEE T MULTIMEDIA, V17, P2147, DOI 10.1109/TMM.2015.2491018
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P2141, DOI 10.1109/TMM.2014.2356795
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P559, DOI 10.1109/TMM.2013.2291958
   xiph.Org, 2017, DERFS TEST MED COLL
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhang HC, 2017, IEEE T SMART GRID, V8, P2119, DOI 10.1109/TSG.2016.2517026
NR 44
TC 12
Z9 12
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5907
EP 5927
DI 10.1007/s11042-017-4503-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800035
DA 2024-07-18
ER

PT J
AU Hanis, S
   Amutha, R
AF Hanis, S.
   Amutha, R.
TI Double image compression and encryption scheme using logistic mapped
   convolution and cellular automata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cellular automata; Chaotic logistic mapping; Convolution; Compression;
   Diffusion; Encryption
ID TRANSFORMS; SYSTEM; MAPS
AB Due to the availability and increased usage of multimedia applications, features such as compression and security has gained more importance. Here, we propose a key generation algorithm and a double image encryption scheme with combined compression and encryption. The keys for encryption are generated using a novel modified convolution and chaotic mapping technique. First, the four least significant bits of the two images were truncated and then combined after permutation using the proposed logistic mapping. Also, cellular automata based diffusion is performed on the resultant image to strengthen the security further. Here, both confusion and diffusion seem to be integrated thus improvising the encryption scheme. The performance results and the test of randomness of the key and the algorithm were found to be successful. Since two images are compressed and encrypted simultaneously, it is useful in real - time scenarios.
C1 [Hanis, S.; Amutha, R.] SSN Coll Engn, Dept Elect & Commun, Chennai, Tamil Nadu, India.
C3 SSN College of Engineering
RP Hanis, S (corresponding author), SSN Coll Engn, Dept Elect & Commun, Chennai, Tamil Nadu, India.
EM haniss@ssn.edu.in
RI S, Hanis/JUU-3411-2023; Amutha, R./AAB-9399-2020
CR Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Abdo AA, 2013, COMMUN NONLINEAR SCI, V18, P136, DOI 10.1016/j.cnsns.2012.05.023
   Ahmad J, 2016, MULTIMED TOOLS APPL, V75, P12669, DOI 10.1007/s11042-016-3436-9
   Aljawarneh Shadi, 2010, Network Security, V2010, P6, DOI 10.1016/S1353-4858(10)70081-7
   Aljawarneh S, 2011, INT J CLOUD APPL COM, V1, P64, DOI 10.4018/ijcac.2011040105
   Aljawarneh SA, 2016, FUTURE GENER COMP SY, V60, P67, DOI 10.1016/j.future.2016.01.020
   Annaby MH, 2016, SIGNAL PROCESS-IMAGE, V49, P25, DOI 10.1016/j.image.2016.09.006
   Bakhshandeh A, 2013, OPT LASER ENG, V51, P665, DOI 10.1016/j.optlaseng.2013.01.001
   Chen RJ, 2010, SIGNAL PROCESS-IMAGE, V25, P413, DOI 10.1016/j.image.2010.03.002
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   HUNT BR, 1971, IEEE T ACOUST SPEECH, VAU19, P285, DOI 10.1109/TAU.1971.1162202
   Kizza J.M., 2005, Computer network security
   Kocarev L., 2011, STUDIES COMPUTATIONA
   Li XW, 2015, OPT LASER ENG, V66, P112, DOI 10.1016/j.optlaseng.2014.08.016
   Lima JB, 2013, SIGNAL PROCESS-IMAGE, V28, P1537, DOI 10.1016/j.image.2013.05.008
   Liu ZJ, 2012, OPT LASER ENG, V50, P248, DOI 10.1016/j.optlaseng.2011.08.006
   Maniccam SS, 2004, PATTERN RECOGN, V37, P725, DOI 10.1016/j.patcog.2003.08.011
   Mount DM, 2001, IEEE T IMAGE PROCESS, V10, P1826, DOI 10.1109/83.974567
   NANDI S, 1994, IEEE T COMPUT, V43, P1346, DOI 10.1109/12.338094
   Shih T.K., 2002, DISTRIBUTED MULTIMED
   Sui LS, 2015, OPT COMMUN, V343, P140, DOI 10.1016/j.optcom.2015.01.021
   Sui LS, 2014, OPT LASER ENG, V56, P1, DOI 10.1016/j.optlaseng.2013.12.001
   Tao R, 2010, IEEE T INF FOREN SEC, V5, P734, DOI 10.1109/TIFS.2010.2068289
   Wang Q, 2012, OPT COMMUN, V285, P4317, DOI 10.1016/j.optcom.2012.07.033
   Xu Y, 2014, COMMUN NONLINEAR SCI, V19, P3735, DOI 10.1016/j.cnsns.2014.02.029
   Zhao TY, 2016, OPT COMMUN, V376, P47, DOI 10.1016/j.optcom.2016.05.016
   Zhong Z, 2012, OPT COMMUN, V285, P584, DOI 10.1016/j.optcom.2011.11.025
   Zhou NR, 2015, OPT COMMUN, V354, P112, DOI 10.1016/j.optcom.2015.05.043
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   [No title captured]
NR 30
TC 29
Z9 31
U1 2
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6897
EP 6912
DI 10.1007/s11042-017-4606-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700021
DA 2024-07-18
ER

PT J
AU Li, Z
   Lu, W
   Sun, ZQ
   Xing, WW
AF Li, Zhao
   Lu, Wei
   Sun, Zhanquan
   Xing, Weiwei
TI Improving multi-label classification using scene cues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
AB Multi-label classification is one of the most challenging tasks in the computer vision community, owing to different composition and interaction (e.g. partial visibility or occlusion) between objects in multi-label images. Intuitively, some objects usually co-occur with some specific scenes, e.g. the sofa often appears in a living room. Therefore, the scene of a given image may provides informative cues for identifying those embedded objects. In this paper, we propose a novel scene-aware deep framework for addressing the challenging multi-label classification task. In particular, we incorporate two sub-networks that are pre-trained for different tasks (i.e. object classification and scene classification) into a unified framework, so that informative scene-aware cues can be leveraged for benefiting multi-label object classification. In addition, we also present a novel one vs. all multiple-cross-entropy (MCE) loss for optimizing the proposed scene-aware deep framework by independently penalizing the classification error for each label. The proposed method can be learned in an end-to-end manner and extensive experimental results on Pascal VOC 2007 and MS COCO demonstrate that our approach is able to make a noticeable improvement for the multi-label classification task.
C1 [Li, Zhao; Lu, Wei; Xing, Weiwei] Beijing Jiaotong Univ, Sch Software Engn, Beijing, Peoples R China.
   [Li, Zhao; Sun, Zhanquan] Natl Supercomp Ctr Jinan, Shandong Prov Key Lab Comp Networks, Shandong Comp Sci Ctr, Jinan, Shandong, Peoples R China.
C3 Beijing Jiaotong University; Qilu University of Technology
RP Li, Z (corresponding author), Beijing Jiaotong Univ, Sch Software Engn, Beijing, Peoples R China.; Li, Z (corresponding author), Natl Supercomp Ctr Jinan, Shandong Prov Key Lab Comp Networks, Shandong Comp Sci Ctr, Jinan, Shandong, Peoples R China.
EM 11112095@bjtu.edu.cn; luwei@bjtu.edu.cn; sunzhq@sdas.org;
   wwxing@bjtu.edu.cn
FU Scientic and Technological Research of Shandong, China [2016GGX101029];
   National Natural Science Foundation of China [61370128, 61428201,
   61272353]; Program for New Century Excellent Talents in University
   [NCET-13-0659]
FX This work was supported in part by National Natural Science Foundation
   of China (No.61272353, 61370128, 61428201), Program for New Century
   Excellent Talents in University (NCET-13-0659), Scientic and
   Technological Research of Shandong, China (NO.2016GGX101029).
CR [Anonymous], 2014, INT C LEARN REPR
   [Anonymous], ARXIV14112861
   [Anonymous], TECH REP
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], P CVPR
   [Anonymous], 2013, ARXIV 1310 1531
   [Anonymous], 2014, CORR
   [Anonymous], 2015, ARXIV150903150
   [Anonymous], 2013, Caffe: An open source convolutional architecture for fast feature embedding
   [Anonymous], 2013, ARXIV PREPRINT ARXIV
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   [Anonymous], 2014, CORR
   Chatfield K., 2014, P BRIT MACH VIS C 20
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Girshick R., 2017, rich feature hierarchies for accurate object detection and semantic segmentation tech report (v5)
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Johnson J, 2015, IEEE I CONF COMP VIS, P4624, DOI 10.1109/ICCV.2015.525
   Kordumova S, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P143, DOI 10.1145/2911996.2912007
   Lai HJ, 2016, IEEE T IMAGE PROCESS, V25, P2469, DOI 10.1109/TIP.2016.2545300
   Li XR, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2906152
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Simonyan K., 2014, 14091556 ARXIV
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Verma Y, 2017, COMPUT VIS IMAGE UND, V154, P48, DOI 10.1016/j.cviu.2016.10.001
   Wei YC, 2017, IEEE T CYBERNETICS, V47, P449, DOI 10.1109/TCYB.2016.2519449
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   Williams C.K.I., PASCAL VISUAL OBJECT
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Zhou BL, 2014, ADV NEUR IN, V27
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 33
TC 4
Z9 5
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 6079
EP 6094
DI 10.1007/s11042-017-4517-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800043
DA 2024-07-18
ER

PT J
AU Charfi, S
   El Ansari, M
AF Charfi, Said
   El Ansari, Mohamed
TI Computer-aided diagnosis system for colon abnormalities detection in
   wireless capsule endoscopy images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless capsule endoscopy; Gastrointestinal tract; Discrete wavelet
   transform (DWT); Local binary pattern (LBP); LBP variance
ID CLASSIFICATION; TRANSFORM
AB Wireless capsule endoscopy (WCE) is a novel imaging technique that can travel through human body and image the small bowel entirely. Therefore, it has been gradually adopted compared with traditional endoscopies for gastrointestinal diseases. However, the big number of the produced images by a WCE test makes their review exhaustive for the physicians. It is helpful for clinicians if we can develop a computer-aided diagnosis system for the task of identifying the images with potential problems. The aim of this paper is to automatize the process of WCE images abnormalities detection by presenting a new texture extraction scheme for pathological inflammation, polyp, and bleeding regions discrimination in WCE images. A new approach based on local binary pattern variance and discrete wavelet transform is proposed. The new textural features scheme has many advantages, e.g., it detects multi-directional characteristics and overcomes the illuminations changes in WCE images. Intensive experiments are conducted on two datasets constructed from several WCE exams. The promising results make the presented method suitable for abnormalities detection in WCE images.
C1 [Charfi, Said; El Ansari, Mohamed] Ibn Zohr Univ, Dept Comp Sci, LabSIV, Fac Sci, BP 8106, Agadir 80000, Morocco.
C3 Ibn Zohr University of Agadir
RP Charfi, S (corresponding author), Ibn Zohr Univ, Dept Comp Sci, LabSIV, Fac Sci, BP 8106, Agadir 80000, Morocco.
EM charfisaid@gmail.com; melansari@gmail.com
RI El Ansari, Mohamed/L-9738-2016
OI El Ansari, Mohamed/0000-0001-5394-9066
FU National Center for Scientific and technical Research (CNRST) in Rabat
FX We gratefully acknowledge and express our thanks to the National Center
   for Scientific and technical Research (CNRST) in Rabat for its research
   grant.
CR Akansu A.N., 2001, Multiresolution signal decomposition: transforms, subbands, and wavelets, V2nd
   Ameling S., 2009, Texture-Based Polyp Detection in Colonoscopy, P346, DOI DOI 10.1007/978-3-540-93860-6_70
   [Anonymous], 2003, Hosp Physician
   [Anonymous], 2016, MULTIMED TOOLS APPL
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], SPIE C SERIES
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], OMICS J RADIOL
   [Anonymous], WEO CLIN END ATL
   Barbosa DJC, 2009, IEEE ENG MED BIO, P6683, DOI 10.1109/IEMBS.2009.5334013
   Barbosa DJC, 2008, IEEE ENG MED BIO, P3012, DOI 10.1109/IEMBS.2008.4649837
   Charisis VS, 2012, COMPUT METH PROG BIO, V107, P61, DOI 10.1016/j.cmpb.2011.10.004
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Ellahyani A, 2017, MULTIMED TOOLS APPL, V76, P24495, DOI 10.1007/s11042-016-4207-3
   Ellahyani A, 2016, APPL SOFT COMPUT, V46, P805, DOI 10.1016/j.asoc.2015.12.041
   Girgis HZ, 2010, I S BIOMED IMAGING, P1373, DOI 10.1109/ISBI.2010.5490253
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Haji Maghsoudi Omid, 2013, 2013 20th Iranian Conference on Biomedical Engineering (ICBME). Proceedings, P286, DOI 10.1109/ICBME.2013.6782236
   Haykin S., 1998, NEURAL NETWORKS COMP
   Iakovidis DK, 2014, IEEE IMAGE PROC, P2236, DOI 10.1109/ICIP.2014.7025453
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Kodogiannis VS, 2007, NEUROCOMPUTING, V70, P704, DOI 10.1016/j.neucom.2006.10.024
   Kodogiannis VS, 2007, ENG APPL ARTIF INTEL, V20, P539, DOI 10.1016/j.engappai.2006.09.006
   Leggett CL, 2016, GASTROINTEST ENDOSC, V84, P842, DOI 10.1016/j.gie.2016.07.045
   Li BP, 2015, MED PHYS, V42, P645, DOI 10.1118/1.4905164
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2011, ARTIF INTELL MED, V52, P11, DOI 10.1016/j.artmed.2011.01.003
   Li BP, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P498, DOI 10.1109/IROS.2009.5354726
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Liu G, 2016, COMPUT BIOL MED, V70, P131, DOI 10.1016/j.compbiomed.2016.01.021
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Mitselos IV, 2015, WORLD J GASTRO ENDOS, V7, P643, DOI 10.4253/wjge.v7.i6.643
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Omidyeganeh M, 2013, MULTIMED TOOLS APPL, V65, P441, DOI 10.1007/s11042-012-1012-5
   Saurin JC, 2016, CLIN ENDOSC, V49, P26, DOI 10.5946/ce.2016.49.1.26
   Wang A, 2013, GASTROINTEST ENDOSC, V78, P805, DOI 10.1016/j.gie.2013.06.026
   Wang SH, 2015, ENTROPY-SWITZ, V17, P6663, DOI 10.3390/e17106663
   Yang G, 2015, APPLICATIONS, P1
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Zhang GS, 2015, MULTIMED TOOLS APPL, V74, P3783, DOI 10.1007/s11042-013-1799-8
   Zhang L, 2016, KNOWL-BASED SYST, V111, P248, DOI 10.1016/j.knosys.2016.08.018
   Zhang YD, 2016, ADV MECH ENG, V8, DOI 10.1177/1687814016634243
   Zhang YD, 2015, J MED IMAG HEALTH IN, V5, P1395, DOI 10.1166/jmihi.2015.1542
   Zhang YD, 2015, INFORM SCIENCES, V322, P115, DOI 10.1016/j.ins.2015.06.017
NR 46
TC 45
Z9 45
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 4047
EP 4064
DI 10.1007/s11042-017-4555-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600062
DA 2024-07-18
ER

PT J
AU Wang, M
   Chen, WT
   Wang, S
   Liu, J
   Li, X
   Stantic, B
AF Wang, Meng
   Chen, Weitong
   Wang, Sen
   Liu, Jun
   Li, Xue
   Stantic, Bela
TI Answering why-not questions on semantic multimedia queries
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Why-not; Multimedia; RDF graph; SPARQL; Ontology
ID PROVENANCE
AB Linked data is a promising way to publish media data as resources on the Web and interlink them with other resources. While significant amounts of image, audio and video fragments have been tagged and exposed as linked data, searching and explaining the unexpected query results have been rarely studied. To improve the functionality and usability of SPARQL-based multimedia search engines, we focus on explaining missing items in the query results, or the so-called why-not question in this paper. We first formalize why-not questions on multimedia SPARQL queries and then propose a novel explanation model to answer why-not questions. Our model adopts a to generate logical explanations at the basic graph pattern level, the filter constraint level, or the multimedia function level, respectively, which helps users refine their initial queries. Extensive experimental results on two real-world RDF datasets show that the proposed model and algorithms can provide high-quality explanations both in terms of effectiveness and efficiency.
C1 [Wang, Meng; Liu, Jun] Xi An Jiao Tong Univ, MOEKLINNS Lab, Xian, Shaanxi, Peoples R China.
   [Chen, Weitong] Univ Queensland, Brisbane, Qld, Australia.
   [Li, Xue] Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld, Australia.
   [Wang, Sen; Stantic, Bela] Griffith Univ, Sch Informat & Commun Technol, Gold Coast Campus, Southport, Qld, Australia.
C3 Xi'an Jiaotong University; University of Queensland; University of
   Queensland; Griffith University; Griffith University - Gold Coast Campus
RP Wang, M (corresponding author), Xi An Jiao Tong Univ, MOEKLINNS Lab, Xian, Shaanxi, Peoples R China.
EM wangmengsd@stu.xjtu.edu.cn; w.chen9@uq.edu.au; sen.wang@griffith.edu.au;
   liukeen@xjtu.edu.cn; xue.li@itee.uq.edu.au; b.stantic@griffith.edu.au
RI wu, sen/HKE-6181-2023; Liu, Jun/JHU-0288-2023
OI Liu, Jun/0000-0002-0867-8153; LI, Xue/0000-0002-4515-6792; Wang,
   Sen/0000-0002-5414-8276; Chen, Tony Weitong/0000-0003-1001-7925
FU Fundamental Theory and Applications of Big Data with Knowledge
   Engineering under the National Key Research and Development Program of
   China [2016YFB1000903]; National Science Foundation of China [61672419,
   61532004, 61532015]; MOE Research Center for Online Education Funds
   [2016YB165]; Ministry of Education Innovation Research Team [IRT17R86]
FX This work is sponsored by The Fundamental Theory and Applications of Big
   Data with Knowledge Engineering under the National Key Research and
   Development Program of China with grant number 2016YFB1000903; National
   Science Foundation of China under Grant Nos. 61672419, 61532004, and
   61532015; MOE Research Center for Online Education Funds under Grant No.
   2016YB165; Ministry of Education Innovation Research Team No. IRT17R86.
CR Bhowmick S.S., 2013, ACM Multimedia Conference, MM'13, Barcelona, Spain, October 21-25, 2013, P917
   Bidoit Nicole, 2014, EXTENDING DATABASE T
   Bizer C, 2011, SEMANTIC SERVICES, INTEROPERABILITY AND WEB APPLICATIONS: EMERGING CONCEPTS, P205, DOI 10.4018/978-1-60960-593-3.ch008
   Calvanese D, 2013, J ARTIF INTELL RES, V48, P635, DOI 10.1613/jair.3870
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chapman A, 2009, ACM SIGMOD/PODS 2009 CONFERENCE, P523
   Chen L, 2015, PROC INT CONF DATA, P279, DOI 10.1109/ICDE.2015.7113291
   Cui YW, 2003, VLDB J, V12, P41, DOI 10.1007/s00778-002-0083-8
   Dividino R, 2009, J WEB SEMANT, V7, P204, DOI 10.1016/j.websem.2009.07.004
   Gao YJ, 2015, PROC VLDB ENDOW, V8, P738, DOI 10.14778/2752939.2752943
   Hausenblas M, 2009, P 2 INT WORKSH LINK
   He ZA, 2014, IEEE T KNOWL DATA EN, V26, P1300, DOI 10.1109/TKDE.2012.158
   Herschel M, 2010, PROC VLDB ENDOW, V3, P185, DOI 10.14778/1920841.1920869
   Hu CP, 2014, IEEE T EMERG TOP COM, V2, P376, DOI 10.1109/TETC.2014.2316525
   Huang JS, 2008, PROC VLDB ENDOW, V1, P736, DOI 10.14778/1453856.1453936
   Islam MS, 2015, IEEE T KNOWL DATA EN, V27, P2672, DOI 10.1109/TKDE.2015.2432798
   Islam MS, 2013, PROC INT CONF DATA, P973, DOI 10.1109/ICDE.2013.6544890
   Kurz T, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P721, DOI 10.1145/2740908.2742914
   Li Y, 2012, P 5 WORKSH LINK DAT
   Luo M, 2017, SYSTEMS MAN CYBERN A
   Luo MN, 2018, IEEE T NEUR NET LEAR, V29, P944, DOI 10.1109/TNNLS.2017.2650978
   Ma ZG, 2018, IEEE T NEUR NET LEAR, V29, P2921, DOI 10.1109/TNNLS.2017.2709308
   Pérez J, 2009, ACM T DATABASE SYST, V34, DOI 10.1145/1567274.1567278
   Shvaiko P, 2005, LECT NOTES COMPUT SC, V3730, P146
   ten Cate B, 2015, PODS'15: PROCEEDINGS OF THE 33RD ACM SYMPOSIUM ON PRINCIPLES OF DATABASE SYSTEMS, P31, DOI 10.1145/2745754.2745765
   The W3C SPARQL Working Group, 2013, SPARQL 1 1 OV
   Theoharis Y, 2011, IEEE INTERNET COMPUT, V15, P31, DOI 10.1109/MIC.2010.127
   Tran Q. T., 2010, P ACM SIGMOD INT C M, P15, DOI DOI 10.1145/1807167.1807172
   Viegas Damasio Carlos, 2012, The Semantic Web. 11th International Semantic Web Conference (ISWC 2012). Proceedings, P625, DOI 10.1007/978-3-642-35176-1_39
   Zhang DW, 2017, IEEE T IMAGE PROCESS, V26, P1746, DOI 10.1109/TIP.2017.2658957
NR 33
TC 4
Z9 4
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3405
EP 3429
DI 10.1007/s11042-017-5151-6
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600028
DA 2024-07-18
ER

PT J
AU Wang, XD
   Chen, RC
   Yan, F
   Zeng, ZQ
   Hong, CQ
AF Wang, Xiao-dong
   Chen, Rung-Ching
   Yan, Fei
   Zeng, Zhi-qiang
   Hong, Chao-qun
TI Semi-supervised adaptive feature analysis and its application for
   multimedia understanding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE feature selection; semi-supervised learning; adaptive learning; image
   annotation; 3D human action recognition
ID FEATURE-SELECTION; INFORMATION; FRAMEWORK
AB Multimedia understanding for high dimensional data is still a challenging work, due to redundant features, noises and insufficient label information it contains. Graph-based semi-supervised feature learning is an effective approach to address this problem. Nevertheless, Existing graph-based semi-supervised methods usually depend on the pre-constructed Laplacian matrix but rarely modify it in the subsequent classification tasks. In this paper, an adaptive local manifold learning based semi-supervised feature selection is proposed. Compared to the state-of-the-art, the proposed algorithm has two advantages: 1) Adaptive local manifold learning and feature selection are integrated jointly into a single framework, where both the labeled and unlabeled data are utilized. Besides, the correlations between different components are also considered. 2) A group sparsity constraint, i.e. l (2 , 1)-norm, is imposed to select the most relevant features. We also apply the proposed algorithm to serval kinds of multimedia understanding applications. Experimental results demonstrate the effectiveness of the proposed algorithm.
C1 [Wang, Xiao-dong; Yan, Fei; Zeng, Zhi-qiang; Hong, Chao-qun] Xiamen Univ Technol, Coll Comp & Informat Engn, Xiamen 361024, Peoples R China.
   [Wang, Xiao-dong; Chen, Rung-Ching] Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan.
C3 Xiamen University of Technology; Chaoyang University of Technology
RP Chen, RC (corresponding author), Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan.
EM xdwangjsj@xmut.edu.cn; crching@cyut.edu.tw
RI wang, xiao/HZI-9156-2023
FU National Natural Science Foundation of China [61502405]; National
   Natural Science Foundation of Fujian Province, China [2016 J01324,
   2016J01327, 2017 J01511]; International Science and Technology
   Cooperation Program of Xiamen university of technology [E201400400];
   Xiamen Science and Technology Planning Project [3502Z20143030,
   3502Z20103037, 3502Z20133043]; Scientific Research Fund of Fujian
   Provincial Education Department [JA15385, JAT160357]; Ministry of
   Science and Technology, Taiwan [MOST-104-2221-E-324-019-MY2,
   MOST-103-2632-E-324-001-MY3]
FX This paper is supported by National Natural Science Foundation of China
   (Grant No. 61502405), National Natural Science Foundation of Fujian
   Province, China (Grant Nos. 2016 J01324, 2016J01327, 2017 J01511), the
   International Science and Technology Cooperation Program of Xiamen
   university of technology (No. E201400400), Xiamen Science and Technology
   Planning Project (Nos. 3502Z20143030, 3502Z20103037, 3502Z20133043),
   Scientific Research Fund of Fujian Provincial Education Department (Nos.
   JA15385, JAT160357), and Ministry of Science and Technology, Taiwan,
   (Grant Nos. MOST-104-2221-E-324-019-MY2, MOST-103-2632-E-324-001-MY3).
CR [Anonymous], 2005, ADV NEURAL INF PROCE
   Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009
   Cai D., 2010, KDD, P333
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2016, ACM T KNOWL DISCOV D, V11, DOI 10.1145/2910585
   Chang XJ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2234
   Chang XJ, 2014, AAAI CONF ARTIF INTE, P1171
   Chen BJ, 2017, NEUROCOMPUTING, V266, P293, DOI 10.1016/j.neucom.2017.05.047
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Du L, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P209, DOI 10.1145/2783258.2783345
   Duda R., 1973, Pattern Classification and Scene Analysis
   Hou CP, 2015, IEEE T NEUR NET LEAR, V26, P1287, DOI 10.1109/TNNLS.2014.2337335
   Hou CP, 2014, IEEE T CYBERNETICS, V44, P793, DOI 10.1109/TCYB.2013.2272642
   Li H, 2009, INT CONF DAT MIN WOR, P164, DOI 10.1109/ICDMW.2009.46
   Li Z., 2012, P AAAI C ART INT, P1026
   Liu Y, 2013, NEUROCOMPUTING, V105, P12, DOI 10.1016/j.neucom.2012.05.031
   Luo MN, 2018, IEEE T CYBERNETICS, V48, P648, DOI 10.1109/TCYB.2017.2647904
   Ma ZG, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P77, DOI 10.1145/2647868.2654907
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1662, DOI 10.1109/TMM.2012.2199293
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1021, DOI 10.1109/TMM.2012.2187179
   Nene SA, 1996, COIL20 COL U IM LIB
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1302
   Nie FP, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P977, DOI 10.1145/2623330.2623726
   Nie FP, 2011, IEEE I CONF COMP VIS, P2268
   Nie FP, 2010, IEEE T IMAGE PROCESS, V19, P1921, DOI 10.1109/TIP.2010.2044958
   Siddiqi MH, 2016, MULTIMED TOOLS APPL, V75, P935, DOI 10.1007/s11042-014-2333-3
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Song JK, 2013, IEEE T MULTIMEDIA, V15, P1997, DOI 10.1109/TMM.2013.2271746
   Wang XD, 2017, IMAGE VISION COMPUT, V63, P10, DOI 10.1016/j.imavis.2017.05.004
   Wang XD, 2016, NEUROCOMPUTING, V200, P47, DOI 10.1016/j.neucom.2016.03.017
   Xiaojun Chang, 2014, Advances in Knowledge Discovery and Data Mining. 18th Pacific-Asia Conference, PAKDD 2014. Proceedings: LNCS 8444, P74, DOI 10.1007/978-3-319-06605-9_7
   Yang XH, 2016, OXID MED CELL LONGEV, V2016, DOI 10.1155/2016/2968462
   Yang Y., 2011, PROC INT JOINT C ART, P1589
   Yang Y, 2015, INT J COMPUT VISION, V113, P113, DOI 10.1007/s11263-014-0781-x
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yuan CS, 2016, CHINA COMMUN, V13, P60, DOI 10.1109/CC.2016.7559076
   Zeng ZQ, 2016, NEUROCOMPUTING, V173, P102, DOI 10.1016/j.neucom.2015.05.119
   Zhang ZH, 2015, LECT NOTES COMPUT SC, V9279, P130, DOI 10.1007/978-3-319-23231-7_12
   Zhao Z, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P641
   Zhou Z.-H., 2007, P ADV NEUR INF PROC, P1609, DOI DOI 10.1016/J.PATCOG.2006.12.019
NR 43
TC 4
Z9 5
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3083
EP 3104
DI 10.1007/s11042-017-4990-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600010
DA 2024-07-18
ER

PT J
AU Yang, JF
   Li, JJ
   Liu, SQ
AF Yang, Jinfei
   Li, Jiajia
   Liu, Shouqiang
TI RETRACTED: A novel technique applied to the economic investigation of
   recommender system (Retracted article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Recommender method; Data mining; Money flow; Price fluctuations; Western
   region
ID EQUATION; QUEUE
AB Recommender system has emerged as a new research concept in the economic field, in which a new recommend algorithm such as stock data mining plays an important role in studying the level of economic development in a region. A novel recommends method of big data analysis method based on singular value decomposition is proposed. The proposed algorithm exploits the historical data of stocks in the western region, the regional leading stock average data and volatility of individual stocks data. Then volatility charts could be gotten from data mining. The stability of the western region stock could be drawn by comparison between leading stocks and common stocks. Money flow of stocks can also be calculated by new recommender system algorithm. The experimental results show that our approach has ability to forecast the economic development of the western region by the perspective of stock data mining. It could effectively recommend investors to identify the economic development of the western region, obtaining higher returns, and avoiding unnecessary losses.
C1 [Yang, Jinfei] Minzu Univ China, Sch Econ, Beijing 100081, Peoples R China.
   [Li, Jiajia] South China Normal Univ, Sch Comp Sci, Guangzhou 510631, Guangdong, Peoples R China.
   [Liu, Shouqiang] South China Normal Univ, Sch Phys & Telecommun Engn, Guangzhou 510006, Guangdong, Peoples R China.
C3 Minzu University of China; South China Normal University; South China
   Normal University
RP Yang, JF (corresponding author), Minzu Univ China, Sch Econ, Beijing 100081, Peoples R China.
EM yangjinfeijiang@126.com
RI Li, Wang/M-1612-2019; Yang, Jinfei/N-1840-2018
OI Yang, Jinfei/0000-0002-1650-1761
FU Guangdong Provincial Public Research and Capacity Building Foundation
   [2015A020217011, 2016A020223012]; Science Foundation of Guangdong
   Provincial Communications Department [2015-02-064]; National Natural
   Science Foundation of China [61402185]; Natural Science Foundation of
   Guangdong Province [2015A030313382]
FX This work was supported by Guangdong Provincial Public Research and
   Capacity Building Foundation funded project under Grant No.
   2015A020217011, & 2016A020223012, Science Foundation of Guangdong
   Provincial Communications Department under Grant No. 2015-02-064, the
   National Natural Science Foundation of China under Grant No. 61402185,
   and Natural Science Foundation of Guangdong Province under Grant No.
   2015A030313382. The authors would like to thank the anonymous reviewers
   and the editor for the very instructive suggestions that led to the much
   improved quality of this paper.
CR [Anonymous], 2012, APPL ANAL
   [蔡红 Cai Hong], 2011, [计算机仿真, Computer Simulation], V28, P365
   Chen B, 2015, APPL MATH MODEL, V39, P3227, DOI 10.1016/j.apm.2014.11.023
   Chen B, 2012, APPL MATH MODEL, V36, P1197, DOI 10.1016/j.apm.2011.07.073
   Chen B, 2011, APPL ANAL, V90, P1243, DOI 10.1080/00036811003717939
   Chen ZM, 2016, J MATH ANAL APPL, V444, P1403, DOI 10.1016/j.jmaa.2016.07.021
   Chengying H, 2013, EC RES, V10, P29
   Chengying H, 2014, MANAGEMENT WORLD, V11, P44
   Fangli Y, 2011, MATH PRACTICE THEORY, V41, P171
   Guo YH, 2016, VISUAL COMPUT, V32, P1151, DOI 10.1007/s00371-015-1199-3
   Jia N, 2016, MOB INF SYST, V2016, DOI 10.1155/2016/8586493
   Li FS, 2016, APPL MATH COMPUT, V274, P383, DOI 10.1016/j.amc.2015.11.018
   Li Q, 2016, NEUROCOMPUTING, V173, P1422, DOI 10.1016/j.neucom.2015.09.014
   Lin XL, 2016, ELECTRON J QUAL THEO, P1, DOI 10.14232/ejqtde.2016.1.12
   Lin XL, 2014, BOUND VALUE PROBL, DOI 10.1186/1687-2770-2014-132
   Lin XL, 2013, APPL MATH LETT, V26, P692, DOI 10.1016/j.aml.2013.01.007
   [刘涵 Liu Han], 2015, [自动化学报, Acta Automatica Sinica], V41, P439
   Lv Yong-le, 2009, Application Research of Computers, V26, P3253, DOI 10.3969/j.issn.1001-3695.2009.09.014
   Ma ZY, 2008, APPL MATH COMPUT, V204, P478, DOI 10.1016/j.amc.2008.07.004
   Qingzhen X, 2016, INT J DATABASE THEOR, V9, P37, DOI DOI 10.14257/IJDTA.2016.9.5.04
   Sun X, 2001, PHYSICA A, V291, P553, DOI 10.1016/S0378-4371(00)00606-3
   [孙晓莹 Sun Xiaoying], 2012, [计算机仿真, Computer Simulation], V29, P375
   Tian NS, 2008, APPL MATH MODEL, V32, P2941, DOI 10.1016/j.apm.2007.10.005
   Wang PH, 2017, J DIFFER EQUATIONS, V262, P5534, DOI 10.1016/j.jde.2017.02.010
   Wang PH, 2016, NONLINEAR ANAL-THEOR, V130, P1, DOI 10.1016/j.na.2015.09.021
   Wang Yun-Hong, 2000, Chinese Journal of Computers, V23, P649
   Xiangyang D, 2009, J VIBRATION SHOCK, V28, P30
   Xu Q, 2014, MATH PROBL ENG, V2014
   Xu QZ, 2007, STOCH ANAL APPL, V25, P127, DOI 10.1080/07362990601052102
   Xu QZ, 2018, MULTIMED TOOLS APPL, V77, P6311, DOI 10.1007/s11042-017-4537-9
   Xu QZ, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/659809
   [杨震 Yang Zhen], 2012, [计算机仿真, Computer Simulation], V29, P378
   Yuejuan J, 2016, COMPUT INTEGR MANUF, V22, P1424
   Yurong C, 2003, J U ELECT SCI TECHNO, V32, P469
   Zhongxin J, 2008, CHINESE BUSINESS COM, V14, P32
   Zhu J, 2016, SCI ENG ETHICS, V22, P1073, DOI 10.1007/s11948-015-9683-8
NR 36
TC 7
Z9 7
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4237
EP 4252
DI 10.1007/s11042-017-4752-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500010
DA 2024-07-18
ER

PT J
AU Bi, XL
   Pun, CM
   Yuan, XC
AF Bi, XiuLi
   Pun, Chi-Man
   Yuan, Xiao-Chen
TI Multi-scale feature extraction and adaptive matching for copy-move
   forgery detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-Move Forgery Detection; Multi-Scale Feature Extraction; Adaptive
   Patch Matching
AB A copy-move forgery detection scheme by using multi-scale feature extraction and adaptive matching is proposed in this paper. First, the host image is segmented into the non-overlapping patches of irregular shape in different scales. Then, Scale Invariant Feature Transform is applied to extract feature points from all patches, to generate the multi-scale features. An Adaptive Patch Matching algorithm is subsequently proposed for finding the matching that indicate the suspicious forged regions in each scale. Finally, the suspicious regions in all scales are merged to generate the detected forgery regions in the proposed Matched Keypoints Merging algorithm. Experimental results show that the proposed scheme performs much better than the existing state-of-the-art copy-move forgery detection algorithms, even under various challenging conditions, including the geometric transforms, such as scaling and rotation, and the common signal processing, such as JPEG compression and noise addition; in addition, the special cases such as the multiple copies and the down-sampling are also evaluated, the results indicate the very good performance of the proposed scheme.
C1 [Bi, XiuLi; Pun, Chi-Man] Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
   [Yuan, Xiao-Chen] Macau Univ Sci & Technol, Fac Informat Technol, Macau, Peoples R China.
C3 University of Macau; Macau University of Science & Technology
RP Pun, CM (corresponding author), Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
EM cmpun@umac.mo; yb47429@umac.mo; xcyuan@must.edu.mo
RI Yuan, Xiaochen/ABH-5255-2020; Pun, Chi Man/GRJ-3703-2022
OI Yuan, Xiaochen/0000-0002-7490-6695; Pun, Chi-Man/0000-0003-1788-3746
FU Research Committee of the University of Macau [MYRG2015-00011-FST,
   MYRG2015-00012-FST]; Science and Technology Development Fund of Macau
   SAR [008/2013/A1, 093-2014-A2]
FX This research was supported in part by the Research Committee of the
   University of Macau (MYRG2015-00011-FST, MYRG2015-00012-FST) and the
   Science and Technology Development Fund of Macau SAR (008/2013/A1,
   093-2014-A2).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Bi XL, 2016, INFORM SCIENCES, V345, P226, DOI 10.1016/j.ins.2016.01.061
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Costanzo A, 2014, IEEE T INF FOREN SEC, V9, P1450, DOI 10.1109/TIFS.2014.2337654
   Emam M, 2016, MULTIMED TOOLS APPL, V75, P11513, DOI 10.1007/s11042-015-2872-2
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Huang HL, 2008, PACIIA: 2008 PACIFIC-ASIA WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION, VOLS 1-3, PROCEEDINGS, P1241
   Hwei-Jen Lin, 2009, WSEAS Transactions on Signal Processing, V5, P188
   Kakar P, 2012, IEEE T INF FOREN SEC, V7, P1018, DOI 10.1109/TIFS.2012.2188390
   Li GH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1750
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Luo WQ, 2006, INT C PATT RECOG, P746
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Popescu A.C., 2004, Comput. Sci. Tech. Rep, P1
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Sekhar R., 2016, The International Conference on Soft Computing Systems, P223
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Wang Jun-Wen, 2009, Acta Automatica Sinica, V35, P1488, DOI 10.3724/SP.J.1004.2009.01488
   Wang JW, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P25, DOI 10.1109/MINES.2009.142
   XiaoBing Kang, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P926, DOI 10.1109/CSSE.2008.876
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Yu LY, 2016, MULTIMED TOOLS APPL, V75, P1159, DOI 10.1007/s11042-014-2362-y
   Zhu Y, 2016, MULTIMED TOOLS APPL, V75, P3221, DOI 10.1007/s11042-014-2431-2
NR 31
TC 23
Z9 26
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 363
EP 385
DI 10.1007/s11042-016-4276-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400016
DA 2024-07-18
ER

PT J
AU Li, YX
   Zhang, X
   Jin, H
   Li, XK
   Wang, Q
   He, QH
   Huang, Q
AF Li, Yanxiong
   Zhang, Xue
   Jin, Hai
   Li, Xianku
   Wang, Qin
   He, Qianhua
   Huang, Qian
TI Using multi-stream hierarchical deep neural network to extract deep
   audio feature for acoustic event detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio feature; Acoustic event; Deep neural network
ID CLASSIFICATION
AB Extraction of effective audio features from acoustic events definitely influences the performance of Acoustic Event Detection (AED) system, especially in adverse audio situations. In this study, we propose a framework for extracting Deep Audio Feature (DAF) using multi-stream hierarchical Deep Neural Network (DNN). The DAF outputted from the proposed framework fuses the potential complementary information of multiple input feature streams and thus could be more discriminative than those input features for AED. We take two input feature streams and the hierarchical DNNs with two stages as an example for showing the extraction of DAF. The effectiveness of different audio features for AED is evaluated on two audio corpora, i.e. BBC (British Broadcasting Corporation) audio dataset and TV audio dataset with different signal-to-noise ratios. Experimental results show that DAF outperforms other features for AED under several experimental conditions.
C1 [Li, Yanxiong; Zhang, Xue; Jin, Hai; Li, Xianku; Wang, Qin; He, Qianhua; Huang, Qian] South China Univ Technol, Sch Elect & Informat Engn, 381 Wushan Rd, Guangzhou, Guangdong, Peoples R China.
C3 South China University of Technology
RP Li, YX (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, 381 Wushan Rd, Guangzhou, Guangdong, Peoples R China.
EM eeyxli@scut.edu.cn
FU National Natural Science Foundation of China [61101160, 61271314,
   61571192]; Fundamental Research Funds for the Central Universities;
   South China University of Technology, China [2015ZZ102]; Project of the
   Pearl River Young Talents of Science and Technology in Guangzhou, China
   [2013J2200070]; Science and Technology Planning Project of Guangdong
   Province [2014A050503022, 2015A010103003]; Foundation of China
   Scholarship Council [201208440078]
FX The work was supported by the National Natural Science Foundation of
   China (61101160, 61271314, 61571192), the Fundamental Research Funds for
   the Central Universities, South China University of Technology, China
   (2015ZZ102), Project of the Pearl River Young Talents of Science and
   Technology in Guangzhou, China (2013J2200070), Science and Technology
   Planning Project of Guangdong Province (2014A050503022, 2015A010103003)
   and the Foundation of China Scholarship Council (201208440078).
CR [Anonymous], 2015, P IEEE INT JOINT C N, DOI DOI 10.1109/IJCNN.2015.7280624
   [Anonymous], 2006, PROC IEEE INT C ACOU
   [Anonymous], 2009, INTERSPEECH
   [Anonymous], 2013, IEEE Workshop on WASPAA, DOI DOI 10.1109/WASPAA.2013.6701819
   [Anonymous], 2013, P 21 EUR SIGN PROC C
   [Anonymous], P INT
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], BBBC SOUND EFF LIB
   [Anonymous], IEEE AASP CHALL DET
   [Anonymous], INTERSPEECH 2011 12
   [Anonymous], IEEE AASP CHALL DET
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   [Anonymous], PROGRAMMING ANAL DIG
   CHILDERS DG, 1977, P IEEE, V65, P1428, DOI 10.1109/PROC.1977.10747
   Diment A., 2013, P IEEE AASP CHALL DE
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Gencoglu O, 2014, EUR SIGNAL PR CONF, P506
   Grézl F, 2007, INT CONF ACOUST SPEE, P757
   Heittola T, 2008, LECT NOTES COMPUT SC, V4625, P364
   Heittola T, 2013, INT CONF ACOUST SPEE, P8677, DOI 10.1109/ICASSP.2013.6639360
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Phan H, 2015, IEEE-ACM T AUDIO SPE, V23, P20, DOI 10.1109/TASLP.2014.2367814
   Jin F, 2012, INT CONF ACOUST SPEE, P597, DOI 10.1109/ICASSP.2012.6287954
   Lin KZ, 2010, LECT NOTES COMPUT SC, V6297, P481, DOI 10.1007/978-3-642-15702-8_44
   Lu L, 2008, IEEE T MULTIMEDIA, V10, P74, DOI 10.1109/TMM.2007.911304
   Ma L., 2006, ACM Trans. Speech Lang. Process, V3, P1, DOI [DOI 10.1145/1149290.1149292, 10.1145/1149290.1149292]
   McLoughlin I, 2015, IEEE-ACM T AUDIO SPE, V23, P540, DOI 10.1109/TASLP.2015.2389618
   Moritz N, 2011, INT CONF ACOUST SPEE, P5492
   Niessen ME, 2013, IEEE WORK APPL SIG
   Okuyucu Ç, 2013, IEEE INT SYM MULTIM, P125, DOI 10.1109/ISM.2013.29
   Qiu AQ, 2003, J NEUROPHYSIOL, V90, P456, DOI 10.1152/jn.00851.2002
   Schädler MR, 2012, J ACOUST SOC AM, V131, P4134, DOI 10.1121/1.3699200
   Schröder J, 2015, IEEE-ACM T AUDIO SPE, V23, P2198, DOI 10.1109/TASLP.2015.2467964
   Temko A, 2007, LECT NOTES COMPUT SC, V4122, P311
   Temko A, 2009, HUM-COMPUT INT-SPRIN, P61, DOI 10.1007/978-1-84882-054-8_7
   Temko A, 2009, PATTERN RECOGN LETT, V30, P1281, DOI 10.1016/j.patrec.2009.06.009
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   Vesely K, 2010, LECT NOTES ARTIF INT, V6231, P439, DOI 10.1007/978-3-642-15760-8_56
   Wang SH, 2015, ENTROPY-SWITZ, V17, P6663, DOI 10.3390/e17106663
   Wijitha Senadeera Wijitha Senadeera, 2006, International Journal of Food Engineering, V2, P7
   Zhang XY, 2015, INT CONF ACOUST SPEE, P166, DOI 10.1109/ICASSP.2015.7177953
   Zhang YD, 2015, INT J IMAG SYST TECH, V25, P317, DOI 10.1002/ima.22144
   Zhang YD, 2012, SENSORS-BASEL, V12, P12489, DOI 10.3390/s120912489
NR 45
TC 11
Z9 14
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 897
EP 916
DI 10.1007/s11042-016-4332-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400038
DA 2024-07-18
ER

PT J
AU Qiao, T
   Zhu, AC
   Retraint, F
AF Qiao, Tong
   Zhu, Aichun
   Retraint, Florent
TI Exposing image resampling forgery by using linear parametric model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image resampling forensics; Linear parametric model; Bayes' rule;
   Hypothesis testing
ID DIGITAL FORGERIES
AB Resampling forgery generally refers to as the technique that utilizes interpolation algorithm to maliciously geometrically transform a digital image or a portion of an image. This paper investigates the problem of image resampling detection based on the linear parametric model. First, we expose the periodic artifact of one-dimensional 1-D) resampled signal. After dealing with the nuisance parameters, together with Bayes' rule, the detector is designed based on the probability of residual noise extracted from resampled signal using linear parametric model. Subsequently, we mainly study the characteristic of a resampled image. Meanwhile, it is proposed to estimate the probability of pixels' noise and establish a practical Likelihood Ratio Test (LRT). Comparison with the state-of-the-art tests, numerical experiments show the relevance of our proposed algorithm with detecting uncompressed/compressed resampled images.
C1 [Qiao, Tong] Hangzhou Dianzi Univ, Sch Cyberspace, Hangzhou, Zhejiang, Peoples R China.
   [Zhu, Aichun] Nanjing Tech Univ, Sch Comp Sci & Technol, Nanjing, Jiangsu, Peoples R China.
   [Qiao, Tong; Zhu, Aichun; Retraint, Florent] Univ Technol Troyes, LM2S, Troyes, France.
C3 Hangzhou Dianzi University; Nanjing Tech University; Universite de
   Technologie de Troyes
RP Qiao, T (corresponding author), Hangzhou Dianzi Univ, Sch Cyberspace, Hangzhou, Zhejiang, Peoples R China.; Qiao, T (corresponding author), Univ Technol Troyes, LM2S, Troyes, France.
EM tong.qiao@hdu.edu.cn; aichun.zhu@utt.fr; florent.retraint@utt.fr
FU State Key Program of Zhejiang Province Natural Science Foundation of
   China [LZ15F020003]; Natural Science Foundation of China [61602295];
   Natural Science Foundation of Shanghai [16ZR1413100]; China Scholar
   Council (CSC); region Champagne-Ardenne, IDENT project
FX This work is funded by the State Key Program of Zhejiang Province
   Natural Science Foundation of China under Grant No. LZ15F020003 and the
   Natural Science Foundation of China (No. 61602295) and the Natural
   Science Foundation of Shanghai (No. 16ZR1413100). The Ph.D thesis of
   Tong Qiao is funded by the China Scholar Council (CSC) and the region
   Champagne-Ardenne, IDENT project.
CR Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], DETECTING DIGITAL IM
   [Anonymous], 2005, Testing Statistical Hypothesis
   [Anonymous], 2013, 2013 21 EUR SIGN PRO
   [Anonymous], 2004, ELECT IMAGING
   [Anonymous], 13 INT WORKSH INF HI
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cogranne Remi, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P178, DOI 10.1007/978-3-642-24178-9_13
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Feng X., 2011, 2011 IEEE International Conference on Multimedia and Expo, P1
   Feng XY, 2012, IEEE T MULTIMEDIA, V14, P536, DOI 10.1109/TMM.2012.2191946
   Fridrich J., 2003, P DIG FOR RES WORKSH, P133
   Gallagher A. C., 2008, IEEE COMPUTER SOC C, P1
   Gallagher AC, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P65, DOI 10.1109/CRV.2005.33
   Kirchner M, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P13
   Kirchner M, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P11, DOI 10.1145/1411328.1411333
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Mahdian B, 2008, IEEE T INF FOREN SEC, V3, P529, DOI 10.1109/TIFS.2004.924603
   Oppenheim A.V., 1989, OTHERS DISCRETE TIME, V2
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Qiao T., 2014, P 2 ACM WORKSHOP INF, P3
   Qiao T, 2015, IEEE IMAGE PROC, P3812, DOI 10.1109/ICIP.2015.7351518
   Qiao T, 2014, IEEE IMAGE PROC, P5517, DOI 10.1109/ICIP.2014.7026116
   Qiao T, 2015, EURASIP J INF SECUR, DOI 10.1186/s13635-015-0019-7
   Qin C, 2016, INFORM SCIENCES, V361, P84, DOI 10.1016/j.ins.2016.04.036
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Ryu SJ, 2014, PATTERN RECOGN LETT, V36, P89, DOI 10.1016/j.patrec.2013.09.028
   Sencar HusrevTaha., 2012, Digital Image Forensics - There is More to a Picture than Meets the Eye, DOI DOI 10.1007/978-1-4614-0757-7
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Thai TH, 2014, IEEE T IMAGE PROCESS, V23, P250, DOI 10.1109/TIP.2013.2290596
   Wei WM, 2010, IEEE T INF FOREN SEC, V5, P507, DOI 10.1109/TIFS.2010.2051254
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Zitzmann Cathel, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P163, DOI 10.1007/978-3-642-24178-9_12
NR 36
TC 23
Z9 23
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1501
EP 1523
DI 10.1007/s11042-016-4314-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400001
DA 2024-07-18
ER

PT J
AU Zhang, LL
   Wang, ZY
   Yao, TT
   Staoh, S
   Mei, T
   Feng, DD
AF Zhang, Lelin
   Wang, Zhiyong
   Yao, Tingting
   Staoh, Shin'ichi
   Mei, Tao
   Feng, David Dagan
TI Exploiting spatial-temporal context for trajectory based action video
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatial-temporal information; Descriptor coding; Trajectory matching;
   Bag-of-visual-words; Action video retrieval
ID EXTRACTION; SELECTION; MODEL
AB Retrieving videos with similar actions is an important task with many applications. Yet it is very challenging due to large variations across different videos. While the state-of-the-art approaches generally utilize the bag-of-visual-words representation with the dense trajectory feature, the spatial-temporal context among trajectories is overlooked. In this paper, we propose to incorporate such information into the descriptor coding and trajectory matching stages of the retrieval pipeline. Specifically, to capture the spatial-temporal correlations among trajectories, we develop a descriptor coding method based on the correlation between spatial-temporal and feature aspects of individual trajectories. To deal with the mis-alignments between dense trajectory segments, we develop an offset-aware distance measure for improved trajectory matching. Our comprehensive experimental results on two popular datasets indicate that the proposed method improves the performance of action video retrieval, especially on more dynamic actions with significant movements and cluttered backgrounds.
C1 [Zhang, Lelin; Wang, Zhiyong; Yao, Tingting; Feng, David Dagan] Univ Sydney, Sch Informat Technol, Sydney, NSW, Australia.
   [Yao, Tingting] Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
   [Staoh, Shin'ichi] Natl Inst Informat, Tokyo, Japan.
   [Mei, Tao] Microsoft Res, Beijing, Peoples R China.
C3 University of Sydney; Hefei University of Technology; Research
   Organization of Information & Systems (ROIS); National Institute of
   Informatics (NII) - Japan; Microsoft
RP Zhang, LL (corresponding author), Univ Sydney, Sch Informat Technol, Sydney, NSW, Australia.
EM lzha1533@uni.sydney.edu.au
RI Mei, Tao/GQZ-0596-2022
OI Mei, Tao/0000-0002-5990-7307; Zhang, Lelin/0000-0003-0613-1362; Feng,
   Dagan/0000-0002-3381-214X
FU ARC (Australian Research Council); National Institute of Informatics,
   Japan; China Scholarship Council [201406690011]; HPC (High Performance
   Computing) service at the University of Sydney
FX This work was partially supported by ARC (Australian Research Council)
   grants, the National Institute of Informatics, Japan, the China
   Scholarship Council (201406690011), and the HPC (High Performance
   Computing) service at the University of Sydney.
CR [Anonymous], CORR
   [Anonymous], UT-Interaction Dataset, ICPR contest on Semantic Description of Human Activities (SDHA)
   [Anonymous], 2010, LECT NOTES COMPUT SC
   [Anonymous], P IEEE 7 WORKSH MULT
   [Anonymous], 2015, IEEE 17 INT WORKSH M
   [Anonymous], INT JOINT C ART INT
   [Anonymous], ACM INT C MULT RETR
   [Anonymous], IEEE T KNOWLEDGE DAT
   Bashir FI, 2007, IEEE T MULTIMEDIA, V9, P58, DOI 10.1109/TMM.2006.886346
   Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779
   Buzan D, 2004, INT C PATT RECOG, P521, DOI 10.1109/ICPR.2004.1334287
   Cao LJ, 2013, NEUROCOMPUTING, V105, P61, DOI 10.1016/j.neucom.2012.06.044
   Cao Y, 2010, PROC CVPR IEEE, P3352, DOI 10.1109/CVPR.2010.5540021
   Caspi Y, 2006, INT J COMPUT VISION, V68, P53, DOI 10.1007/s11263-005-4842-z
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gerónimo D, 2014, INT C PATT RECOG, P4630, DOI 10.1109/ICPR.2014.792
   Hu WM, 2007, IEEE T IMAGE PROCESS, V16, P1168, DOI 10.1109/TIP.2006.891352
   Jones S, 2013, INFORM SCIENCES, V236, P56, DOI 10.1016/j.ins.2013.02.018
   Keogh E. J., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P285, DOI 10.1145/347090.347153
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Li T, 2011, IEEE T CIRC SYST VID, V21, P381, DOI 10.1109/TCSVT.2010.2041828
   Liu AA, 2017, IEEE T CYBERNETICS, V47, P1781, DOI 10.1109/TCYB.2016.2582918
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu L, 2016, IEEE T CYBERNETICS, V46, P158, DOI 10.1109/TCYB.2015.2399172
   Liu L, 2013, PATTERN RECOGN, V46, P1810, DOI 10.1016/j.patcog.2012.10.004
   Liu LQ, 2011, IEEE I CONF COMP VIS, P2486, DOI 10.1109/ICCV.2011.6126534
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu SY, 2015, IEEE T CIRC SYST VID, V25, P1190, DOI 10.1109/TCSVT.2014.2372272
   Lu SY, 2014, IEEE T MULTIMEDIA, V16, P1497, DOI 10.1109/TMM.2014.2319778
   Lu SY, 2013, J VIS COMMUN IMAGE R, V24, P127, DOI 10.1016/j.jvcir.2012.07.008
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Meng JJ, 2016, IEEE T MULTIMEDIA, V18, P116, DOI 10.1109/TMM.2015.2500734
   Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154
   Palou G, 2013, PROC CVPR IEEE, P2099, DOI 10.1109/CVPR.2013.273
   Poullot S, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P381, DOI 10.1145/2733373.2806228
   Revaud J, 2013, PROC CVPR IEEE, P2459, DOI 10.1109/CVPR.2013.318
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Savarese S., 2006, P 2006 IEEE COMPUTER, V2, P2033, DOI DOI 10.1109/CVPR.2006.102
   Savarese S., 2008, 2008 ieee workshop on motion and video computing, DOI DOI 10.1109/WMVC.2008.4544068
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Sivic J, 2006, LECT NOTES COMPUT SC, V4170, P127
   Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang L., 2012, P 21 ACM INT C INF K, P1303
   Wu JX, 2016, IEEE T CYBERNETICS, V46, P2978, DOI 10.1109/TCYB.2015.2493538
   Wu QX, 2013, J VIS COMMUN IMAGE R, V24, P1064, DOI 10.1016/j.jvcir.2013.07.001
   Wu XM, 2013, IEEE T CIRC SYST VID, V23, P1054, DOI 10.1109/TCSVT.2013.2248991
   Zhang Shiliang., 2009, MM 09 P 17 ACM INT C, P75, DOI DOI 10.1145/1631272.1631285
   Zhen XT, 2016, IMAGE VISION COMPUT, V50, P1, DOI 10.1016/j.imavis.2016.02.006
   Zhou Z, 2015, IEEE T MULTIMEDIA, V17, P512, DOI 10.1109/TMM.2015.2404779
NR 56
TC 4
Z9 4
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2057
EP 2081
DI 10.1007/s11042-017-4353-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400027
DA 2024-07-18
ER

PT J
AU Bai, D
   Chen, XL
   Tian, M
AF Bai, Di
   Chen, XiaoLi
   Tian, Mao
TI A satellite communication zero steganography algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Zero steganography; Satellite communication; Robustness
AB In order to solve the problem of the secret transmission of important or low speed data on the satellite, the SCZS (satellite communication zero steganography) algorithm for covert communication is proposed with the satellite communication characters of mass data and high security. Firstly, the payload data was encrypted by the AES algorithm. Secondly, the multi-dimension features of the carrier image were extracted from the spatial or frequency domain. Thirdly, the relationship between the features and the payload information was established. The imperceptibility analysis showed that the algorithm brings no distortion to the cover image because there was no change to the cover image and it has a perfect invisibility. The robustness test showed that the proposed SCZS algorithm workd well in the tests of salt and pepper noise attack, the speckle noise and the low pass filtering attack, which achieves 95 % data recovery rate. Therefore the proposed SCZS algorithm has strong applicability for secret transmission of important or low speed data on the satellite.
C1 [Bai, Di; Chen, XiaoLi; Tian, Mao] Wuhan Univ, Sch Elect Informat, Wuhan, Hubei, Peoples R China.
C3 Wuhan University
RP Chen, XL (corresponding author), Wuhan Univ, Sch Elect Informat, Wuhan, Hubei, Peoples R China.
EM doctorbai@whu.edu.cn; cxl@whu.edu.cn
FU National Nature Science Foundation of China [62161010]
FX This work is supported by the National Nature Science Foundation of
   China (No. 62161010).
CR Bandyopadhyay SK., 2010, COMPUT INF SCI, V3, P229
   Bilal M., 2013, 2013 ACS INT C COMP
   Bilal M, 2014, MULTIMED TOOLS APPL, V72, P1073, DOI 10.1007/s11042-013-1415-y
   [冯新岗 Feng Xingang], 2010, [宇航学报, Journal of Chinese Society of Astronautics], V31, P1850
   Ishizuka H., 2014, DIGITAL FORENSICS WA, P613
   Ishizuka H, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P459, DOI 10.1109/IIH-MSP.2014.121
   Li X., 2013, COMPUT ENG DES, V7
   [李晓博 Li Xiaobo], 2013, [宇航学报, Journal of Chinese Society of Astronautics], V34, P686
   Muhammad K, 2015, KSII T INTERNET INF, V9, P1938
   Nutzinger M., 2012, Journal of Information Hiding and Multimedia Signal Processing, V3, P47
   Pingshui Wang, 2013, Information Technology Journal, V12, P5681, DOI 10.3923/itj.2013.5681.5684
   Singh S, 2012, IJCSI, V9, P131
   Song J, 2012, ADV INF SCI SERV SCI, V4
   Sun Q, 2013, TELKOMNIKA INDONESIA, V11, P4151
   Wu N.-I., 2007, IJ Network Security, V4, P1
   Xie JQ, 2014, COMPUT SCI
   Xie Tiecheng, 2014, Information and Control, V43, P524, DOI 10.13976/j.cnki.xk.2014.0524
   Yi Ke-chu, 2015, Journal on Communications, V36, DOI 10.11959/j.issn.1000-436x.2015223
NR 18
TC 2
Z9 2
U1 2
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26447
EP 26462
DI 10.1007/s11042-016-4169-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500042
DA 2024-07-18
ER

PT J
AU Chakraverty, S
   Saraswat, M
AF Chakraverty, Shampa
   Saraswat, Mala
TI Review based emotion profiles for cross domain recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; Cross domain; Emotion; Lexicons; Online content;
   Collaborative filtering
ID SYSTEM
AB Several e-commerce sites are reaping the benefits of Cross-Domain Recommendation (CDR) systems to cross-sell products, guide new users and increase revenues. Current research works augment user-item ratings with a variety of auxiliary information such as location, personality, geo-tags and multimedia content that link multiple domains to provide effective CDR. In this paper, we propose a fresh perspective for generating recommendations across different domains by tapping the emotions that are encapsulated within user generated textual content such as reviews, blogs and comments. Such emotions serve as strong socio-psychological links between various entertainments domains and have the potential to obviate the cold start problems. Our CDR scheme uses an enriched emotion lexicon to analyze the emotions in online content expressed by users in the source and target domains and generates emotion-profiles of items and users in both domains. Subsequently, it applies collaborative filtering to match these profiles in order to recommend items in the target domain. We illustrate the working of our emotion-based CDR scheme using the movie and book domains as a case study. Experimental results on Movielens and Bookcrossing datasets yield 28.9% F1-measure which is a marked improvement of 71.1% as compared with a recently reported topic modeling approach to CDR for entertainment domains.
C1 [Chakraverty, Shampa; Saraswat, Mala] Netaji Subhas Inst Technol, Dept Comp Engn, Delhi, India.
C3 Netaji Subhas University of Technology
RP Saraswat, M (corresponding author), Netaji Subhas Inst Technol, Dept Comp Engn, Delhi, India.
EM malasaraswat@gmail.com
OI Saraswat, Mala/0000-0002-6620-5098
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Alderson M, 2016, CONNECTING AUDIENCES
   AMAN S, 2007, INT C TEXT SPEECH, V4629, P196
   [Anonymous], 2001, TECHNICAL REPORT
   [Anonymous], 1999, P 1 ACM C EL COMM
   Banerjee S., 2002, Computational Linguistics and Intelligent Text Processing. Third International Conference, CICLing 2002. Proceedings (Lecture Notes in Computer Science Vol.2276), P136
   Bill Robert W, 2012, AMIA Annu Symp Proc, V2012, P43
   Cantador Ivan, 2015, RECOMMENDER SYSTEMS, P919, DOI DOI 10.1007/978-1-4899-7637-6_27
   Chakraverty S, 2015, J INF KNOWL MANAG, V14, DOI 10.1142/S0219649215500227
   Chiang HS, 2015, INFORM FUSION, V21, P3, DOI 10.1016/j.inffus.2013.05.011
   Chung R., 2007, 9th International Conference on Electronic Commerce, P65
   Cremonesi P., 2011, 2011 IEEE International Conference on Data Mining Workshops, P496, DOI 10.1109/ICDMW.2011.57
   Derks T, FILMSITE HORROR FILM
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Fernandez-Tobias Ignacio., 2011, Proceedings of the Second International Workshop on Information Heterogeneity and Fusion in Recommender Systems as the Fifth ACM Conference on Recommender Systems, HetRec'11, P25
   Fernandez-Tobias Ignacio, 2015, USER MODEL USER-ADAP, P1
   FERNANDEZTOBIAS I, 2013, PROC SPRING BERL, V152, P88
   Franzoni V., 2013, CEUR WORKSHOP PROC, V1096, P83, DOI [10.13140/RG.2.1.3194.7689, DOI 10.13140/RG.2.1.3194.7689]
   Handel S., 2011, CLASSIFICATION EMOTI
   Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872
   Kaminskas M, 2011, LECT NOTES COMPUT SC, V6787, P183, DOI 10.1007/978-3-642-22362-4_16
   Karthik K, 2011, LECT NOTES COMPUT SC, V6763, P552, DOI 10.1007/978-3-642-21616-9_62
   Kumar A, 2014, 2014 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING (CIDM), P137, DOI 10.1109/CIDM.2014.7008659
   Li B., 2009, P 26 ANN INT C MACH, P617, DOI DOI 10.1145/1553374.1553454
   Low Yucheng., 2011, P 17 ACM SIGKDD INT, P123
   Majid A, 2013, INT J GEOGR INF SCI, V27, P662, DOI 10.1080/13658816.2012.696649
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Pan W, 2012, TRANSFER LEARNING CO
   Pan Weike, 2011, P 22 INT JOINT C ART, P2318
   Pazzani MJ, 2007, ADAPTIVE WEB, P25
   Rawashdeh M, 2016, MULTIMED TOOLS APPL, V75, P13299, DOI 10.1007/s11042-015-2813-0
   Reddy S, 2010, P GLOB WORDNET C, P448
   Redfern N, 1995, EMOTION GENRE HOLLYW
   Resnick P., 1994, Transcending Boundaries, CSCW '94. Proceedings of the Conference on Computer Supported Cooperative Work, P175, DOI 10.1145/192844.192905
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Saraswat M, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P3656
   Schafer JB, 2007, COLLABORATIVE FILTER, P91
   Sheng Gao, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference (ECML PKDD 2013). Proceedings: LNCS 8189, P161, DOI 10.1007/978-3-642-40991-2_11
   Shi Y, 2013, CORR, DOI DOI 10.1145/0000000.0000000
   Shi Y, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2556270
   Shi Y, 2010, PROCEEDINGS OF THE RECSYS'2010 ACM CHALLENGE ON CONTEXT-AWARE MOVIE RECOMMENDATION (CAMRA2010), P34, DOI 10.1145/1869652.1869658
   Tang Jie, 2012, P 18 ACM SIGKDD INT, P1285, DOI DOI 10.1145/2339530.2339730
   Thayer R.E., 1990, BIOPSYCHOLOGY MOOD A, V1
   Winoto P, 2010, EXPERT SYST APPL, V37, P6086, DOI 10.1016/j.eswa.2010.02.117
   Yang YH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P208
   Zhang DS, 2014, IEEE T EMERG TOP COM, V2, P254, DOI 10.1109/TETC.2014.2356493
   Ziegler Cai-Nicolas, 2005, P 14 INT C WORLD WID, P22, DOI DOI 10.1145/1060745.1060754
NR 47
TC 6
Z9 7
U1 1
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 25827
EP 25850
DI 10.1007/s11042-017-4767-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500016
DA 2024-07-18
ER

PT J
AU Pleva, M
   Bours, P
   Ondás, S
   Juhár, J
AF Pleva, Matus
   Bours, Patrick
   Ondas, Stanislav
   Juhar, Jozef
TI Improving static audio keystroke analysis by score fusion of acoustic
   and timing data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Keystroke dynamics; Timing analysis; Acoustical analysis;
   Authentication; Identification
ID AUTHENTICATION
AB In this paper we investigate the capacity of sound & timing information during typing of a password for the user identification and authentication task. The novelty of this paper lies in the comparison of performance between improved timing-based and audio-based keystroke dynamics analysis and the fusion for the keystroke authentication. We collected data of 50 people typing the same given password 100 times, divided into 4 sessions of 25 typings and tested how well the system could recognize the correct typist. Using fusion of timing (9.73%) and audio calibration scores (8.99%) described in the paper we achieved 4.65% EER (Equal Error Rate) for the authentication task. The results show the potential of using Audio Keystroke Dynamics information as a way to authenticate or identify users during log-on.
C1 [Pleva, Matus; Ondas, Stanislav; Juhar, Jozef] Tech Univ Kosice, Dept Elect & Multimedia Commun, FEI Letna 9, Kosice 04120, Slovakia.
   [Bours, Patrick] NISlab Norwegian Informat Secur Lab, Dept Informat Secur & Commun Technol, Postboks 191, N-2802 Gjovik, Norway.
C3 Technical University Kosice
RP Pleva, M (corresponding author), Tech Univ Kosice, Dept Elect & Multimedia Commun, FEI Letna 9, Kosice 04120, Slovakia.
EM matus.pleva@tuke.sk; patrick.bours@ntnu.no; stanislav.ondas@tuke.sk;
   jozef.juhar@tuke.sk
RI Ondáš, Stanislav/AAA-2381-2020; Juhár, Jozef/B-2803-2014; Pleva,
   Matúš/H-7209-2012
OI Ondáš, Stanislav/0000-0002-0075-3788; Juhár, Jozef/0000-0002-1596-9258;
   Pleva, Matúš/0000-0003-4380-0801
FU Ministry of Education, Science, Research and Sport of the Slovak
   Republic [VEGA 1/0075/15]; Slovak Research and Development Agency
   [APVV-15-0517, APPV-15-0731]
FX This publication was supported partially by the Ministry of Education,
   Science, Research and Sport of the Slovak Republic under the projects
   VEGA 1/0075/15 & partially by the Slovak Research and Development Agency
   under the contracts No. APVV-15-0517 & APPV-15-0731.
CR [Anonymous], 2012, INF SECUR TECH REP, DOI [DOI 10.1016/J.ISTR.2012.02.001, 10.1016/j.istr.2012.02.001]
   [Anonymous], 2010, TECHNICAL REPORT
   [Anonymous], 2013, ARXIV13042865
   Asonov D, 2004, P IEEE S SECUR PRIV, P3
   Banerjee SP, 2012, J PATTERN RECOGNIT R, V7, P116, DOI 10.13176/11.427
   Barisani A., 2009, P BLACK HAT US
   Bours P, 2015, COMM COM INF SC, V566, P159, DOI 10.1007/978-3-319-26404-2_13
   Dozono H., 2007, International Journal of Computers and Communications, V1, P108
   Kiktova E, 2013, COMM COM INF SC, V368, P288
   Killourhy KS, 2009, I C DEPEND SYS NETWO, P125, DOI 10.1109/DSN.2009.5270346
   Liang Wu, 2014, 2014 Fifth International Conference on Emerging Security Technologies (EST). Proceedings, P13, DOI 10.1109/EST.2014.15
   Luo JN, 2016, MULTIMED TOOLS APPL, V75, P14075, DOI 10.1007/s11042-015-3129-9
   Mondal S, 2017, NEUROCOMPUTING, V230, P1, DOI 10.1016/j.neucom.2016.11.031
   Nakakuni M, 2008, MATH COMPUT SCI ENG, P277
   Novotny O, 2016, INTERSPEECH, P828, DOI 10.21437/Interspeech.2016-981
   Peng JL, 2015, MULTIMED TOOLS APPL, V74, P4469, DOI 10.1007/s11042-013-1817-x
   Rao KR, 2014, ADV INTELL SYST, V248, P781, DOI 10.1007/978-3-319-03107-1_86
   Rodriguez-Fuentes L J, 2013, WORK NOT P MEDIAEVAL
   Roth J, 2015, IEEE T INF FOREN SEC, V10, P333, DOI 10.1109/TIFS.2014.2374424
   Roth J, 2013, INT CONF BIOMETR
   Tasia CJ, 2014, SECUR COMMUN NETW, V7, P750, DOI 10.1002/sec.776
   Teh PS, 2013, SCI WORLD J, DOI 10.1155/2013/408280
   Traore I, 2014, MULTIMED TOOLS APPL, V71, P575, DOI 10.1007/s11042-013-1518-5
   Wijitha Senadeera Wijitha Senadeera, 2006, International Journal of Food Engineering, V2, P7
   Zhuang L, 2009, ACM T INFORM SYST SE, V13, DOI 10.1145/1609956.1609959
NR 25
TC 10
Z9 10
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 25749
EP 25766
DI 10.1007/s11042-017-4571-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500013
OA hybrid
DA 2024-07-18
ER

PT J
AU Rathore, MM
   Ahmad, A
   Paul, A
   Hong, WH
   Seo, H
AF Rathore, M. Mazhar
   Ahmad, Awais
   Paul, Anand
   Hong, Won-Hwa
   Seo, HyunCheol
TI Advanced computing model for geosocial media using big data analytics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Geosocial network; Big data; Hadoop; Spark
ID SOCIAL MEDIA; INFORMATION
AB Social media has drastically entered into a new concept by empowering people to publish their data along with their locations in order to provide benefits to the community and the country overall. There is a significant increase in the use of geosocial networks, such as Twitter, Facebook, Foursquare, and Flickr. Therefore, people worldwide can now voice their opinion, report an event instantly, and connect with others while sharing their views. Thus, geosocial network data provides full information on human current trends in terms of behavior, lifestyle, incidents and events, disasters, current medical infections, and much more with respect to location. Hence, current geosocial media can serve as data assets for countries and their government by analyzing geosocial data in a real time. However, there are millions of geosocial network users who generate terabytes of heterogeneous data with a variety of information every day and at high speed; such information is called "Big Data." Analyzing such a significant amount of data and making real-time decisions regarding event detection is a challenging task. Therefore, in this paper, we propose an efficient system for exploring geosocial networks while harvesting data in order to make real-time decisions while detecting various events. A novel system architecture is proposed and implemented in a real environment in order to process an abundant amount of various social network data to monitor Earth events, incidents, medical diseases, user trends, and views to make future real-time decisions and facilitate future planning. The proposed system consists of five layers, i.e., data collection, data processing, application, communication, and data storage. The system deploys Spark at the top of the Hadoop ecosystem to run a real-time analysis. Twitter and Flickr data are analyzed using the proposed architecture in order to identify current events or disasters, such as earthquakes, fires, Ebola virus contagion, and snow. The system is evaluated on the Tweeter's data by considering the recent earthquake detection occurred in New Zealand. The system is also evaluated with respect to efficiency while considering system throughput on large datasets. We prove that the system has higher throughput and is capable of analyzing a huge amount of geosocial network data at a real time while detecting any event.
C1 [Rathore, M. Mazhar; Paul, Anand] Kyungpook Natl Univ, Sch Comp Sci & Engn, 80,Daehak Ro, Daegu 702701, South Korea.
   [Ahmad, Awais] Yeungnam Univ, Dept Informat & Commun Engn, Seoul, South Korea.
   [Hong, Won-Hwa; Seo, HyunCheol] Kyungpook Natl Univ, Sch Architectural Civil Environm & Energy Engn, 80,Daehak Ro, Daegu 702701, South Korea.
C3 Kyungpook National University; Yeungnam University; Kyungpook National
   University
RP Paul, A (corresponding author), Kyungpook Natl Univ, Sch Comp Sci & Engn, 80,Daehak Ro, Daegu 702701, South Korea.; Hong, WH (corresponding author), Kyungpook Natl Univ, Sch Architectural Civil Environm & Energy Engn, 80,Daehak Ro, Daegu 702701, South Korea.
EM rathoremazhar@gmail.com; awais.ahmad@live.com; paul.editor@gmail.com;
   hongwh@knu.ac.kr; notsools@gmail.com
RI Seo, Hyuncheol/ABC-5117-2020; Ahmad, Awais/AAA-4504-2019; Paul,
   Anand/V-6724-2017
OI Paul, Anand/0000-0002-0737-2021; Seo, HyunCheol/0000-0002-3361-2316;
   Paul, Anand/0000-0003-3115-2325
FU National Research Foundation of Korea (NRF) - Korea government (MSIP)
   [NRF- 2016R1A2A1A05005459]
FX This work is also supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIP) (NRF-
   2016R1A2A1A05005459).
CR Anisetti M, 2012, MULTIMED TOOLS APPL, V59, P89, DOI 10.1007/s11042-010-0721-x
   [Anonymous], 2011, Power Electronics: Power Electronic Conversion and Control Technology
   [Anonymous], 2000, ARCHITECTURAL STYLES
   [Anonymous], 2004, APPL SPATIAL STAT PU
   [Anonymous], 2012, Proceedings of the First ACM SIGSPATIAL International Workshop on Use of GIS in Public Health
   Becker RA, 2011, IEEE PERVAS COMPUT, V10, P18, DOI 10.1109/MPRV.2011.44
   Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012
   Bodnar T., 2016, IEEE T SYST MAN CYB, V99, P1
   Chow C. Y., 2010, P 2 ACM SIGSPATIAL I, P31, DOI DOI 10.1145/1867699.1867706
   Crooks A., 2012, GEOJOURNAL, V78, P1
   Crooks A, 2012, EARTHQUAKE TWITTER D
   Eriksson B, 2010, LECT NOTES COMPUT SC, V6032, P171, DOI 10.1007/978-3-642-12334-4_18
   Ferrari L., 2011, P 3 ACM LBSN
   Haklay M, 2010, ENVIRON PLANN B, V37, P682, DOI 10.1068/b35097
   Hefez I., 2011, P 19 ACM SIGSPATIAL, P517
   Hern, 2013, GUARDIAN
   Kanza Y., 2014, Proceedings of the 22Nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, P597
   Lan R., 2014, P 3 ACM SIGSPATIAL I, P31
   Levin R, 2014, GEOINFORMATICA, V18, P461, DOI 10.1007/s10707-013-0185-z
   Middleton SE, 2014, IEEE INTELL SYST, V29, P9, DOI 10.1109/MIS.2013.126
   O'Connor M. Krieger, 2010, ICWSM
   Papadimitriou P. Symeonidis, 2011, ACM REC SYST 2011 RE
   Paul A, 2016, IEEE WIREL COMMUN, V23, P68, DOI 10.1109/MWC.2016.7721744
   Poese I, 2011, ACM SIGCOMM COMP COM, V41, P53, DOI 10.1145/1971162.1971171
   Rathore MM, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0647-6
   Rathore MM, 2016, J SUPERCOMPUT, V72, P3489, DOI 10.1007/s11227-015-1615-5
   Ratti C, 2006, ENVIRON PLANN B, V33, P727, DOI 10.1068/b32047
   Shafiq MZ, 2015, IEEE T MOBILE COMPUT, V14, P1369, DOI 10.1109/TMC.2014.2350981
   Xia C, 2014, P INT WORLD WID WEB
   Zheng Y, 2009, MDM: 2009 10TH INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT, P357, DOI 10.1109/MDM.2009.50
   Zhou XM, 2014, VLDB J, V23, P381, DOI 10.1007/s00778-013-0320-3
   Zook M, 2010, WORLD MED HEALTH POL, V2, P7, DOI 10.2202/1948-4682.1069
NR 32
TC 8
Z9 10
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 24767
EP 24787
DI 10.1007/s11042-017-4644-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300011
DA 2024-07-18
ER

PT J
AU Bhatia, M
   Sood, SK
AF Bhatia, Munish
   Sood, Sandeep K.
TI Game theoretic decision making in IoT-assisted activity monitoring of
   defence personnel
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things (IoT) Suspicion Index (SI); Degree of suspiciousness
   (DoS); Game theory
ID CO-LOCATION; PARALLEL FRAMEWORK; INTERNET; REPRESENTATION; MAPREDUCE;
   ATTACKS; SYSTEM
AB Innovative growth of IoT Technology has enhanced the service delivery aspects of defence sector in terms of high-tech surveillance, and reliable defence mechanisms. Along with the sensing capability for ubiquitous events, IoT Technology provides means to deliver services in time sensitive and information intensive manner. In this paper, a framework for IoT based activity monitoring of defence personnel is presented to detect the precursors of suspiciousness in terms of information outflow that can compromise the national security. Though maintaining intellectual defence personnel remained a major area of concern for every nation, still investigating reports of recent terrorist attacks in different countries have discovered the number of suspicion factors from their daily activities. The work presented in this study focuses on these factors in terms of efficient monitoring of social activities and analyzing it over suspicious scale. Moreover, Suspicious Index (SI) is defined for every personnel on the basis of their activities that can compromise national security directly or indirectly. Furthermore, automated game theoretic decision making model is presented to aid the monitoring officials in suppressing the probability of information outflow. In order to validate the system, two types of evaluations are performed. In one case, an imitative environment is considered to monitor 10 college students' daily engagements for 7 days. The results are compared with the state-of-the-art techniques of data assessment. In the second case, a mathematical evaluation for the game theoretic decision making is performed. Results in both cases show that the proposed model achieves better performance in efficient monitoring of suspicious activities and effective decision making.
C1 [Bhatia, Munish] Guru Nanak Dev Univ, Reg Campus, Gurdaspur, India.
   [Sood, Sandeep K.] Guru Nanak Dev Univ, Comp Sci & Engn, Reg Campus, Gurdaspur, India.
C3 Guru Nanak Dev University; Guru Nanak Dev University
RP Bhatia, M (corresponding author), Guru Nanak Dev Univ, Reg Campus, Gurdaspur, India.
EM munishbhatia90@gmail.com
RI Bhatia, Munish/Y-4267-2018
OI Bhatia, Munish/0000-0001-9878-7646; K. Sood, Sandeep/0000-0002-8196-5503
CR Acampora G, 2010, ACM T AUTON ADAP SYS, V5, DOI 10.1145/1740600.1740604
   Al-Fuqaha A, 2015, IEEE COMMUN SURV TUT, V17, P2347, DOI 10.1109/COMST.2015.2444095
   [Anonymous], 2012, MINING TEXT DATA
   Antonic A, 2016, FUTURE GENER COMP SY, V56, P607, DOI 10.1016/j.future.2015.08.005
   Azzedin F, 2016, FUTURE GENER COMP SY, V55, P255, DOI 10.1016/j.future.2015.02.007
   Baba AI, 2013, 21 ACM INT C ADV GEO, DOI [10.1145/2525314.2525461, DOI 10.1145/2525314.2525461]
   Barua S, 2014, IEEE T KNOWL DATA EN, V26, P1185, DOI 10.1109/TKDE.2013.88
   Bjelopera JP, 2011, C RES SERV LIB C
   Bosch X, 2012, INTERN EMERG MED, V7, P159, DOI 10.1007/s11739-011-0748-7
   Castillejo P, 2013, IEEE WIREL COMMUN, V20, DOI 10.1109/MWC.2013.6590049
   Chen C, 2014, PROC CVPR IEEE, P2713, DOI 10.1109/CVPR.2014.353
   Chen G., 2000, SURVEY CONTEXT AWARE
   Chen ZK, 2013, J SUPERCOMPUT, V63, P657, DOI 10.1007/s11227-011-0693-2
   De Martino B, 2006, SCIENCE, V313, P684, DOI 10.1126/science.1128356
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Ding GG, 2016, IEEE T IMAGE PROCESS, V25, P5427, DOI 10.1109/TIP.2016.2607421
   Fang SF, 2014, IEEE T IND INFORM, V10, P548, DOI 10.1109/TII.2013.2257807
   Flouvat F, 2015, GEOINFORMATICA, V19, P147, DOI 10.1007/s10707-014-0209-3
   Ganz F, 2013, IEEE SENS J, V13, P3793, DOI 10.1109/JSEN.2013.2271562
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Harwood B, 2016, PROC CVPR IEEE, P5713, DOI 10.1109/CVPR.2016.616
   He CG, 2013, IEEE T BIO-MED ENG, V60, P230, DOI 10.1109/TBME.2012.2222404
   Hirsch M, 2015, LANCET, V386, P2535, DOI 10.1016/S0140-6736(15)01063-6
   Huang Y, 2006, GEOINFORMATICA, V10, P239, DOI 10.1007/s10707-006-9827-8
   Kaur N, 2015, COMPUT IND, V74, P151, DOI 10.1016/j.compind.2015.06.006
   Kelly SDT, 2013, IEEE SENS J, V13, P3846, DOI 10.1109/JSEN.2013.2263379
   Kontschieder P, 2015, IEEE I CONF COMP VIS, P1467, DOI 10.1109/ICCV.2015.172
   Kronstadt KA, 2008, LIB C WASH DC C RES
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   Lauría EJM, 2006, DECIS SUPPORT SYST, V42, P1573, DOI 10.1016/j.dss.2006.01.003
   Leye W, 2016, THESIS
   Li SC, 2013, IEEE T IND INFORM, V9, P2177, DOI 10.1109/TII.2012.2189222
   LIANG M, 2015, PROC CVPR IEEE, P3367, DOI [10.1109/CVPR.2015.7298958, DOI 10.1109/CVPR.2015.7298958]
   Lin J, 2007, DATA MIN KNOWL DISC, V15, P107, DOI 10.1007/s10618-007-0064-z
   Lin ZJ, 2017, IEEE T CYBERNETICS, V47, P4342, DOI 10.1109/TCYB.2016.2608906
   Liu Y, 2017, INT J PARALLEL PROG, V45, P760, DOI 10.1007/s10766-016-0401-1
   Lu G, 2014, BMVC, DOI [10.5244/C.28.125, DOI 10.5244/C.28.125]
   Manikonda L, 2010, IMAGE VISION COMPUT, DOI [10.1109/IVCNZ.2010.6148859, DOI 10.1109/IVCNZ.2010.6148859]
   Moreira-Matias L, 2012, INT WORKSH MACH LEAR, DOI [10.1007/978-3-642-31537-441, DOI 10.1007/978-3-642-31537-441]
   Najafi B, 2003, IEEE T BIO-MED ENG, V50, P711, DOI 10.1109/TBME.2003.812189
   NASH J, 1951, ANN MATH, V54, P286, DOI 10.2307/1969529
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   St J, 2015, REAL TIME HUMAN ACTI, V44
   Takabi H, 2010, IEEE SECUR PRIV, V8, P24, DOI 10.1109/MSP.2010.186
   Tan J, 2017, IEEE T SMART GRID, V8, P2358, DOI 10.1109/TSG.2016.2524020
   Tang JH, 2009, IEEE T SYST MAN CY B, V39, P409, DOI 10.1109/TSMCB.2008.2006045
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   Wang FL, 2016, MULTIMEDIA SYST, V22, P63, DOI 10.1007/s00530-014-0393-x
   Wang LZ, 2013, FUTURE GENER COMP SY, V29, P739, DOI 10.1016/j.future.2012.09.001
   Wang YZ, 2016, FUTURE GENER COMP SY, V55, P87, DOI 10.1016/j.future.2015.08.010
   Xu BY, 2014, IEEE T IND INFORM, V10, P1578, DOI 10.1109/TII.2014.2306382
   Xu LD, 2014, IEEE T IND INFORM, V10, P2233, DOI 10.1109/TII.2014.2300753
   Xu Y, 2017, IEEE INTERNET THINGS, V4, P713, DOI 10.1109/JIOT.2017.2661326
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zayani MH, 2012, 8 INT WIR COMM MOB C
   Zhang GA, 2014, T EMERG TELECOMMUN T, V25, P294, DOI 10.1002/ett.2560
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao SC, 2013, NEUROCOMPUTING, V119, P101, DOI 10.1016/j.neucom.2012.04.042
   Zhao Sicheng, 2016, P 24 ACM INT C MULT, P1385, DOI DOI 10.1145/2964284.2964289
   Zheng JC, 2015, IEEE T WIREL COMMUN, V14, P4391, DOI 10.1109/TWC.2015.2420233
NR 62
TC 16
Z9 16
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 21911
EP 21935
DI 10.1007/s11042-017-4611-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200005
DA 2024-07-18
ER

PT J
AU Isa, MRM
   Aljareh, S
   Yusoff, Z
AF Isa, Mohd Rizal Mohd
   Aljareh, Salem
   Yusoff, Zaharin
TI A watermarking technique to improve the security level in face
   recognition systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric systems; Face recognition systems; Principal Component
   Analysis (PCA); Discrete Cosine Transform(DCT)
AB This paper presents a proposal for a suitable and viable combination of a face recognition system and a watermarking system, namely a PCA-DCT combination, as a new watermarked face recognition scheme that will ensure the authenticity of the data being transmitted in the face recognition system, which will then increase its level of security. The emphasis is on recognizing and rejecting stolen biometric data reintroduced into the system. The research begins with an analysis of biometric systems, with an emphasis on face recognition systems, and in particular with reference to the recorded threats on such systems, Biometric watermarking algorithms proposed by previous researchers within the face recognition environment are then studied, noting their proposed solutions to the said threats. This would then give a good idea towards a watermarked face recognition scheme to be proposed to enhance the security of face recognition systems, especially in terms of the authenticity of the data being transmitted. This watermarked face recognition scheme is the main objective, which will be then worked into the PCA-DCT combination, followed by a check on all the 8 possible locations where data may be intercepted and/or reintroduced. All the results produced are positive, apart from a few situations that will have to be left for future work. Non degradation of the individual PCA and DCT systems due to the combination is also checked and experimented on, again with positive results. Finally, the robustness of the watermarked face recognition scheme is experimented on to evaluate its resilience against attacks.
C1 [Isa, Mohd Rizal Mohd; Aljareh, Salem] Univ Portsmouth, Sch Engn, Portsmouth, Hants, England.
   [Yusoff, Zaharin] Natl Def Univ Malaysia, Comp Sci Dept, Fac Def Sci & Technol, Kuala Lumpur 57000, Malaysia.
C3 University of Portsmouth; Universiti Pertahanan Nasional Malaysia
RP Aljareh, S (corresponding author), Univ Portsmouth, Sch Engn, Portsmouth, Hants, England.; Yusoff, Z (corresponding author), Natl Def Univ Malaysia, Comp Sci Dept, Fac Def Sci & Technol, Kuala Lumpur 57000, Malaysia.
EM up630277@myport.ac.uk; salem.aljareh@port.ac.uk; zarinby@gmail.com
OI Isa, Rizal/0000-0002-0204-9014
CR Adler A, 2003, SAMPLE IMAGES CAN BE
   Al-Haj Ali, 2007, Journal of Computer Sciences, V3, P740, DOI 10.3844/jcssp.2007.740.746
   Aljareh S, 2016, IEEE INT C INF COMM
   [Anonymous], 2010, INT BIOMETRIC PERFOR
   Bansal R, 2012, PROCEEDINGS OF THE 2012 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI'12), P557
   Bedi P, 2012, PROC TECH, V4, P612, DOI 10.1016/j.protcy.2012.05.098
   Behera Bairagi Nath, 2013, INT J COMPUTER SCI N, V2, P123
   Bin Ma, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1277, DOI 10.1109/ICPR.2010.318
   Chen CH, 2004, LECT NOTES COMPUT SC, V3333, P410
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Gunsel B, 2002, PATTERN RECOGN, V35, P2739, DOI 10.1016/S0031-3203(01)00250-3
   Hill C. J., 2001, THESIS
   Hoang T, 2008, INT C PATT RECOG, P2861
   Inamdar VS, 2014, SADHANA-ACAD P ENG S, V39, P3, DOI 10.1007/s12046-013-0208-3
   Isa M.R.M., 2012, ENG TECHN ICET 2012, P1
   Jafri R, 2009, J INF PROCESS SYST, V5, P41, DOI 10.3745/JIPS.2009.5.2.041
   Jain AK, 2003, IEEE T PATTERN ANAL, V25, P1494, DOI 10.1109/TPAMI.2003.1240122
   Jain AK, 2002, INT C PATT RECOG, P756, DOI 10.1109/ICPR.2002.1048100
   Kekre HB, 2015, 25 3 INT C IM INF PR
   Li CL, 2010, LECT NOTES COMPUT SC, V6297, P709
   Lingling Wu, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P1164, DOI 10.1109/ICISE.2009.347
   Moon D, 2005, LECT NOTES ARTIF INT, V3802, P635
   ORL, 2002, DAT FAC
   Park KR, 2007, LECT NOTES COMPUT SC, V4432, P415
   Rajibul Islam Md., 2008, Journal of Applied Sciences, V8, P2939, DOI 10.3923/jas.2008.2939.2948
   Ratha N.K., 2000, P ACM MULTIMEDIA, P127
   Ratha NK, 2001, LECT NOTES COMPUT SC, V2091, P223
   Salahi E, 2008, P IIHMSP
   Sangeeta J, 2010, INT J IMAGE PROCESS, V4, P77
   Tzouveli P, 2002, P 9 INT WORKSH SYST, P101
   van der Putte T, 2000, INT FED INFO PROC, V52, P289
   VATSA M, 2004, P IEEE INT C SYST MA
   Vatsa M, 2007, IMAGE VIS COMPUT
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weilong C., 2005, J PATTERN RECOGNITIO, V26, P2474
   Yan J, 2010, 2 INT C SIGN PROC SY, V3, P597
   Zhang Z, 2011, INTECH
NR 38
TC 8
Z9 8
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23805
EP 23833
DI 10.1007/s11042-016-4109-4
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700032
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Soumya, T
   Thampi, SM
AF Soumya, T.
   Thampi, Sabu M.
TI Recolorizing dark regions to enhance night surveillance video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Night video surveillance; Video enhancement; Colorization; No-Reference
   objective quality measure
ID CONTRAST ENHANCEMENT; QUALITY ASSESSMENT; IMAGE
AB Security surveillance cameras are widely deployed to ensure secure banking, entertainment, and assisted living. Surveillance videos captured by these cameras are considered as forensic evidence for detecting crimes such as ATM robbery and vehicle theft. The videos captured under low lighting conditions are insufficient to identify a theft or robbery happened in the dark regions of a surveillance area. In this paper, we propose a recolorization based night video enhancement to increase the visual perception of surveillance videos. The day background illumination and tone adjusted night video frames are combined to reduce the darkness of the night video frame. Subsequently, chromatic colors of the day image regions are selected corresponding to the dark regions of night frame for the optimization based colorization by using white edge scribbles. The proposed algorithm significantly enhanced the perceptual quality of the video frames compared with existing algorithms. The no-reference based objective evaluation approaches are used for comparing and evaluating the performance of the proposed method with the existing methods. The experimental results indicated that the method improved the visual perception of the night surveillance video compared to the existing methods.
C1 [Soumya, T.] LBS Inst Sci & Technologoly, Coll Engn Trivandrum, Thiruvananthapuram 695016, Kerala, India.
   [Thampi, Sabu M.] Indian Inst Informat Technol & Management Kerala, Thiruvananthapuram 695581, Kerala, India.
C3 College of Engineering, Trivandrum; Kerala University of Digital
   Sciences, Innovation & Technology (Digital University Kerala)
RP Soumya, T (corresponding author), LBS Inst Sci & Technologoly, Coll Engn Trivandrum, Thiruvananthapuram 695016, Kerala, India.
EM tsoumyabaiju@gmail.com; sabu.thampi@iiitmk.ac.in
RI Thampi, Sabu/O-2118-2019
OI Thampi, Sabu/0000-0001-6453-5520
CR Agrawal A, 2005, ACM T GRAPHIC, V24, P828, DOI 10.1145/1073204.1073269
   [Anonymous], EUR S REND CIT
   [Anonymous], 2 JOINT IEEE INT WOR
   [Anonymous], DAY COLOR TRANSFER B
   [Anonymous], SIVIP
   [Anonymous], P IS T SID 8 COL IM
   [Anonymous], P 2008 IEEE C COMP V
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cheng HD, 2004, DIGIT SIGNAL PROCESS, V14, P158, DOI 10.1016/j.dsp.2003.07.002
   Chouhan R, 2013, IET IMAGE PROCESS, V7, P174, DOI 10.1049/iet-ipr.2012.0114
   Dabov K, 2006, PROC SPIE, V6064, DOI 10.1117/12.643267
   Honda Hiroto, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P82, DOI 10.1109/CVPRW.2015.7301300
   Kirk AG, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964937
   Lai YR, 2015, MULTIMED TOOLS APPL, P1
   Lee S, 2007, IEEE T CIRC SYST VID, V17, P199, DOI 10.1109/TCSVT.2006.887078
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Loza A, 2013, DIGIT SIGNAL PROCESS, V23, P1856, DOI 10.1016/j.dsp.2013.06.002
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Petit J, 2010, VISUAL COMPUT, V26, P533, DOI 10.1007/s00371-010-0430-5
   Rao YB, 2010, OPT ENG, V49, DOI 10.1117/1.3520553
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Wang Z, 2002, IEEE IMAGE PROC, P477
   Xu Q, 2014, SIGNAL PROCESS, V103, P309, DOI 10.1016/j.sigpro.2014.02.013
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
NR 27
TC 2
Z9 2
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24477
EP 24493
DI 10.1007/s11042-016-4141-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700060
DA 2024-07-18
ER

PT J
AU Wang, CQ
   Zhang, X
   Zheng, ZM
AF Wang, Chengqi
   Zhang, Xiao
   Zheng, Zhiming
TI An efficient image encryption algorithm based on a novel chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaotic map; Compounded piecewise linear map; Initial
   value distribution
ID SCHEME; PERMUTATION; SYSTEM; BREAKING
AB In this paper, we propose a novel low dimensional chaotic map, namely, compounded piecewise linear map (CPLM) in order to balance between security and computational complexity. Then we prove the chaotic properties of CPLM theoretically and numerically. Based on the CPLM, an efficient chaotic image encryption algorithm is presented, in which the self-adaptive model and feedback mechanism are initially mingled to enhance the security. Besides, initial values of iteration are generated in a new way to ensure the sensitivity for the changes of plain-image. Simulation results show that our scheme possesses the high key sensitivity, large key space, fast encryption speed and resists the common attacks, especially differential attack. In addition, our algorithm satisfies the applicabilities of all-zero image and binary image which are seldom considered in the existing algorithms. The proposed algorithm justifies the superior security and good efficiency, which can be regarded as an excellent candidate for practical applications of image encryption.
C1 [Wang, Chengqi; Zhang, Xiao; Zheng, Zhiming] Beihang Univ, Key Lab Math Informat & Behav Semant, Minist Educ, Beijing 100191, Peoples R China.
   [Wang, Chengqi; Zhang, Xiao; Zheng, Zhiming] Beihang Univ, Sch Math & Syst Sci, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University
RP Zhang, X (corresponding author), Beihang Univ, Key Lab Math Informat & Behav Semant, Minist Educ, Beijing 100191, Peoples R China.; Zhang, X (corresponding author), Beihang Univ, Sch Math & Syst Sci, Beijing 100191, Peoples R China.
EM 09621@buaa.edu.cn; zzheng@pku.edu.cn
FU National Natural Science Foundation of China [11290141, 61402030];
   Fundamental Research of Civil Aircraft [MJ-F-2012-04]
FX Authors thank the editor and reviewers a lot for their valuable
   suggestions. This research is supported by the Major Program of National
   Natural Science Foundation of China (No.: 11290141), the National
   Natural Science Foundation of China (No.: 61402030), and the Fundamental
   Research of Civil Aircraft (No.: MJ-F-2012-04).
CR Abderrahim NW, 2014, NONLINEAR DYNAM, V78, P197, DOI 10.1007/s11071-014-1432-z
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], MOL BIOL INT
   [Anonymous], MULTIMEDIA TOOLS APP
   Azzaz MS, 2013, COMMUN NONLINEAR SCI, V18, P2035, DOI 10.1016/j.cnsns.2012.12.018
   Chen RJ, 2007, PATTERN RECOGN, V40, P1621, DOI 10.1016/j.patcog.2006.11.011
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu C, 2012, OPT EXPRESS, V20, P2363, DOI 10.1364/OE.20.002363
   Fu C, 2011, OPT COMMUN, V284, P5415, DOI 10.1016/j.optcom.2011.08.013
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   Huang R, 2014, MULTIMED TOOLS APPL, V72, P71, DOI 10.1007/s11042-012-1337-0
   Huang XL, 2014, COMMUN NONLINEAR SCI, V19, P4094, DOI 10.1016/j.cnsns.2014.04.012
   Jeng FG, 2015, SIGNAL PROCESS-IMAGE, V34, P45, DOI 10.1016/j.image.2015.03.003
   Khan M, 2015, NEURAL COMPUT APPL, V26, P1137, DOI 10.1007/s00521-014-1800-0
   Kwok HS, 2007, CHAOS SOLITON FRACT, V32, P1518, DOI 10.1016/j.chaos.2005.11.090
   Li SJ, 2005, INT J BIFURCAT CHAOS, V15, P3119, DOI 10.1142/S0218127405014052
   Li SJ, 2003, INT J BIFURCAT CHAOS, V13, P3063, DOI 10.1142/S0218127403008442
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Luo YL, 2015, COMMUN NONLINEAR SCI, V20, P447, DOI 10.1016/j.cnsns.2014.05.022
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Pan S., 2016, MULTIMED TOOLS APPL, P1
   Pareek N. K., 2005, Communications in Nonlinear Science and Numerical Simulation, V10, P715, DOI 10.1016/j.cnsns.2004.03.006
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Patidar V, 2011, OPT COMMUN, V284, P4331, DOI 10.1016/j.optcom.2011.05.028
   Ping P, 2014, SIGNAL PROCESS, V105, P419, DOI 10.1016/j.sigpro.2014.06.020
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Sui LS, 2015, OPT COMMUN, V343, P140, DOI 10.1016/j.optcom.2015.01.021
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   Tang ZJ, 2015, MULTIMED TOOLS APPL, V74, P5429, DOI 10.1007/s11042-014-1861-1
   Wang SH, 2004, INT J MOD PHYS B, V18, P2617, DOI 10.1142/S0217979204025798
   Wang XY, 2015, OPT COMMUN, V338, P209, DOI 10.1016/j.optcom.2014.10.042
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wang XY, 2014, NONLINEAR DYNAM, V78, P2975, DOI 10.1007/s11071-014-1639-z
   Wang XY, 2014, NONLINEAR DYNAM, V76, P1943, DOI 10.1007/s11071-014-1259-7
   Wang XY, 2012, OPT COMMUN, V285, P412, DOI 10.1016/j.optcom.2011.10.010
   Wen WY, 2015, OPT COMMUN, V341, P131, DOI 10.1016/j.optcom.2014.12.026
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Yao W, 2015, NONLINEAR DYNAM, V81, P151, DOI 10.1007/s11071-015-1979-3
   Yap WS, 2015, NONLINEAR DYNAM, V80, P1483, DOI 10.1007/s11071-015-1956-x
   Yuan M., 2016, MULTIMED TOOLS APPL, P1
   Zhang LY, 2014, COMMUN NONLINEAR SCI, V19, P3653, DOI 10.1016/j.cnsns.2014.03.016
   Zhang LY, 2012, J SYST SOFTWARE, V85, P2077, DOI 10.1016/j.jss.2012.04.002
   Zhang X, 2012, SCI CHINA INFORM SCI, V55, P2508, DOI 10.1007/s11432-012-4646-z
   Zhang XP, 2014, SIGNAL PROCESS-IMAGE, V29, P902, DOI 10.1016/j.image.2014.06.012
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
   Zhenjun Tang, 2011, Journal of Multimedia, V6, P202, DOI 10.4304/jmm.6.2.202-206
   Zhu CX, 2015, NONLINEAR DYNAM, V79, P1511, DOI 10.1007/s11071-014-1757-7
   Zhu CX, 2013, NONLINEAR DYNAM, V71, P25, DOI 10.1007/s11071-012-0639-0
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 53
TC 10
Z9 10
U1 1
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24251
EP 24280
DI 10.1007/s11042-016-4102-y
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700050
DA 2024-07-18
ER

PT J
AU Zhang, WJ
   Xiong, QY
AF Zhang, Wenjie
   Xiong, Qingyu
TI Image registration via low-rank factorization and maximum rank resolving
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image registration; Geometrical transform parameter; Low-rank
   factorization; Maximum rank resolving
AB The feature-based image registration method has a better performance in terms of robustness to the intensity variance, but its accuracy of the feature-based image registration still could be improved. This paper utilizes the low-rank factorization and maximum rank resolving to improve the accuracy of image registration. In detail, the proposed method extracts coarse geometrical transform parameters based on the feature point pairs between images, then constructs low-rank model to optimize the geometrical transform parameters and estimate the inliers. Finally, an iterative optimization strategy is introduced to acquire the optimized transform parameters by maximum rank resolving. Experimental results illustrate that the proposed approach presents a good performance in terms with the root residual mean squares error and the entropy of image difference.
C1 [Zhang, Wenjie] Chongqing Univ, Sch Automat, Chongqing 400044, Peoples R China.
   [Zhang, Wenjie; Xiong, Qingyu] Chongqing Univ, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400044, Peoples R China.
   [Xiong, Qingyu] Chongqing Univ, Sch Software Engn, Chongqing 400044, Peoples R China.
C3 Chongqing University; Chongqing University; Chongqing University
RP Xiong, QY (corresponding author), Chongqing Univ, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400044, Peoples R China.; Xiong, QY (corresponding author), Chongqing Univ, Sch Software Engn, Chongqing 400044, Peoples R China.
EM daaiyiyejian@cqu.edu.cn; cquxqy@163.com
FU China 973 Program [2013CB328903]; China Internet of Things development
   of Ministry of Industry and Information Technology [2011BAJ03B13-2];
   Chongqing Key Project of Science and Technology of China
   [cstc2012gg-yyjs40008]
FX The authors thank the anonymous reviewers for helping to review this
   paper. This work was supported by China 973 Program Grant (no.
   2013CB328903), China 2011 Internet of Things development of Ministry of
   Industry and Information Technology (2011BAJ03B13-2) and Chongqing Key
   Project of Science and Technology of China (cstc2012gg-yyjs40008).
CR An J, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.3.033007
   Bogun I, 2014, IMAGE REGISTRATION U
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Cao T, 2014, MED IMAGE ANAL, V18, P914, DOI 10.1016/j.media.2013.12.005
   Chi JN, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/283629
   Fan JW, 2015, IEEE GEOSCI REMOTE S, V12, P562, DOI 10.1109/LGRS.2014.2351396
   Gonçalves H, 2011, IEEE T IMAGE PROCESS, V20, P776, DOI 10.1109/TIP.2010.2076298
   Guizar-Sicairos M, 2008, OPT LETT, V33, P156, DOI 10.1364/OL.33.000156
   Han Jiale, 2011, Proceedings of the 2011 IEEE 10th International Conference on Electronic Measurement & Instruments (ICEMI 2011), P337, DOI 10.1109/ICEMI.2011.6037919
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Jia L, 2015, IEEE T GEOSCI REMOTE, V53, P3960, DOI 10.1109/TGRS.2015.2388495
   Kim H, 2014, OPT EXPRESS, V22, P28606, DOI 10.1364/OE.22.028606
   Kim T, 2003, IEEE T GEOSCI REMOTE, V41, P1111, DOI 10.1109/TGRS.2003.811994
   Matas J, 2004, IMAGE VISION COMPUT, V22, P837, DOI 10.1016/j.imavis.2004.02.009
   Molina E, 2014, IEEE T IMAGE PROCESS, V23, P2184, DOI 10.1109/TIP.2014.2313183
   Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282
   Reddy BS, 1996, IEEE T IMAGE PROCESS, V5, P1266, DOI 10.1109/83.506761
   Spiclin Z, 2012, IEEE T IMAGE PROCESS, V21, P2546, DOI 10.1109/TIP.2012.2186145
   Toga A. W., 2008, CVPR, P1
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Wang Q, 2013, PROCEEDINGS OF THE 2013 8TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE & EDUCATION (ICCSE 2013), P80
   Wang XJ, 2015, REMOTE SENS-BASEL, V7, P7044, DOI 10.3390/rs70607044
   Xing C, 2011, IEEE T PATTERN ANAL, V33, P2081, DOI 10.1109/TPAMI.2011.26
   Zheng JA, 2011, IEEE T INF TECHNOL B, V15, P221, DOI 10.1109/TITB.2010.2091145
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 25
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23643
EP 23659
DI 10.1007/s11042-016-4125-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700024
DA 2024-07-18
ER

PT J
AU Zhao, WQ
   Luo, HZ
   Peng, JY
   Fan, JP
AF Zhao, Wanqing
   Luo, Hangzai
   Peng, Jinye
   Fan, Jianping
TI MapReduce-based clustering for near-duplicate image identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Near-duplicate identification; Image clustering; Representative image;
   MapReduce; Large-scale photos
ID SEARCH; DISCOVERY
AB In this paper, an effective algorithm is developed for tackling the problem of near-duplicate image identification from large-scale image sets, where the LLC (locality-constrained linear coding) method is seamlessly integrated with the maxIDF cut model to achieve more discriminative representations of images. By incorporating MapReduce framework for image clustering and pairwise merging, the near duplicates of images can be identified effectively from large-scale image sets. An intuitive strategy is also introduced to guide the process for parameter selection. Our experimental results on large-scale image sets have revealed that our algorithm can achieve significant improvement on both the accuracy rates and the computation efficiency as compared with other baseline methods.
C1 [Zhao, Wanqing; Luo, Hangzai; Peng, Jinye] Northwest Univ China, Sch Informat & Technol, Xian, Shaanxi, Peoples R China.
   [Fan, Jianping] UNC Charlotte, Dept Comp Sci, Charlotte, NC 28223 USA.
C3 Northwest University Xi'an; University of North Carolina; University of
   North Carolina Charlotte
RP Luo, HZ (corresponding author), Northwest Univ China, Sch Informat & Technol, Xian, Shaanxi, Peoples R China.
EM zhaowanqing@stumail.nwu.edu.cn; hzluo@nwu.edu.cn; pjy@nwu.edu.cn;
   jfan@uncc.edu
RI Peng, Jin/HZH-6965-2023; Zhao, Wanqing/ADL-9932-2022
OI Zhao, Wanqing/0000-0001-7622-0665
FU National Science Foundation of China [61272285]; National
   High-Technology Program of China (863 Program) [2014AA015201]; Program
   for Changjiang Scholars and Innovative Research Team in University
   [IRT13090]; Program of Shaanxi Province Innovative Research Team
   [2014KCT-17]
FX This research is partly supported by National Science Foundation of
   China under Grant 61272285, National High-Technology Program of China
   (863 Program, Grant No. 2014AA015201), Program for Changjiang Scholars
   and Innovative Research Team in University (No. IRT13090), and Program
   of Shaanxi Province Innovative Research Team (No. 2014KCT-17).
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   Bayardo R. J., 2007, P 16 INT C WORLD WID, P131, DOI [DOI 10.1145/1242572.1242591, 10.1145/1242572.1242591]
   Broder AZ, 1998, COMPRESSION AND COMPLEXITY OF SEQUENCES 1997 - PROCEEDINGS, P21, DOI 10.1109/SEQUEN.1997.666900
   Broder AZ, 1997, COMPUT NETWORKS ISDN, V29, P1157, DOI 10.1016/S0169-7552(97)00031-7
   Cherian A, 2012, IEEE IMAGE PROC, P2417, DOI 10.1109/ICIP.2012.6467385
   Chum O., 2008, BMVC, P812, DOI DOI 10.5244/C.22.50
   Chum O, 2009, PROC CVPR IEEE, P17, DOI 10.1109/CVPRW.2009.5206531
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Dong W., 2012, P 2 ACM INT C MULT R
   Elsayed T., 2008, P 46 ANN M ASS COMPU, P265, DOI DOI 10.3115/1557690.1557767
   Foo JunJie., 2007, MIR 07, P21
   Hama H, 2009, INT J INNOV COMPUT I, V5, P4041
   Hsieh LC, 2014, J VIS COMMUN IMAGE R, V25, P384, DOI 10.1016/j.jvcir.2013.12.010
   Hsieh TJ, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND CYBERNETICS (CYBERNETICSCOM), P133, DOI 10.1109/CyberneticsCom.2012.6381633
   Kim S, 2015, IEEE WINT CONF APPL, P943, DOI 10.1109/WACV.2015.130
   Lee DC, 2010, LECT NOTES COMPUT SC, V6311, P648, DOI 10.1007/978-3-642-15549-9_47
   Liu Ting, 2007, 2007 IEEE WORKSHOP A, P28, DOI DOI 10.1109/WACV.2007.18
   Peng JY, 2013, J VIS COMMUN IMAGE R, V24, P895, DOI 10.1016/j.jvcir.2013.06.004
   Salakhutdinov R., 2007, PMLR, P412
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Thomee Bart, 2015, ARXIV150301817
   Vonikakis V, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P153
   Wang H, 2014, MULTIMED TOOLS APPL, V74
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wang XJ, 2013, IEEE COMPUT SOC CONF, P429, DOI 10.1109/CVPRW.2013.71
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Xie LX, 2014, COMPUT VIS IMAGE UND, V124, P31, DOI 10.1016/j.cviu.2013.12.011
   Yang CL, 2012, PROC CVPR IEEE, P1122, DOI 10.1109/CVPR.2012.6247792
   Zheng L, 2013, PROC CVPR IEEE, P1626, DOI 10.1109/CVPR.2013.213
NR 30
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23291
EP 23307
DI 10.1007/s11042-016-4060-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700008
DA 2024-07-18
ER

PT J
AU Aghamaleki, JA
   Behrad, A
AF Aghamaleki, Javad Abbasi
   Behrad, Alireza
TI Malicious inter-frame video tampering detection in MPEG videos using
   time and spatial domain analysis of quantization effects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video forgery detection; Passive forensics; Frame deletion/insertion;
   Residual error; First digit distribution; Benford's law
ID DOUBLE COMPRESSION; FORENSICS
AB In this paper, a new algorithm is proposed for forgery detection in MPEG videos using spatial and time domain analysis of quantization effect on DCT coefficients of I and residual errors of P frames. The proposed algorithm consists of three modules, including double compression detection, malicious tampering detection and decision fusion. Double compression detection module employs spatial domain analysis using first significant digit distribution of DCT coefficients in I frames to detect single and double compressed videos using an SVM classifier. Double compression does not necessarily imply the existence of malignant tampering in the video. Therefore, malicious tampering detection module utilizes time domain analysis of quantization effect on residual errors of P frames to identify malicious inter-frame forgery comprising frame insertion or deletion. Finally, decision fusion module is used to classify input videos into three categories, including single compressed videos, double compressed videos without malicious tampering and double compressed videos with malicious tampering. The experimental results and the comparison of the results of the proposed method with those of other methods show the efficiency of the proposed algorithm.
C1 [Aghamaleki, Javad Abbasi; Behrad, Alireza] Shahed Univ, Dept Elect Engn, Tehran, Iran.
C3 Shahed University
RP Behrad, A (corresponding author), Shahed Univ, Dept Elect Engn, Tehran, Iran.
EM behrad@shahed.ac.ir
RI Behrad, Alireza/F-8795-2018
OI Behrad, Alireza/0000-0002-1990-6668
CR [Anonymous], 2014, APSIPA Trans. Signal Inf. Process, DOI DOI 10.1017/ATSIP.2014.19
   [Anonymous], 2006, P 8 WORKSHOP MULTIME, DOI DOI 10.1145/1161366.1161375
   Arab F, 2016, MULTIMED TOOLS APPL, V75, P10855, DOI 10.1007/s11042-015-2800-5
   Bestagini P, 2013, IEEE INT WORKSH MULT, P488, DOI 10.1109/MMSP.2013.6659337
   Carter T., 2007, INTRO INFORM THEORY
   Chen PH, 2005, APPL STOCH MODEL BUS, V21, P111, DOI 10.1002/asmb.537
   Chen W, 2009, LECT NOTES COMPUT SC, V5450, P16, DOI 10.1007/978-3-642-04438-0_2
   Dong Q, 2012, DIGIT INVEST, V9, P151, DOI 10.1016/j.diin.2012.07.002
   Dueck D, 2001, MPEG 2 VIDEO TRANSCO
   Feng C, 2014, P 2 ACM WORKSH INF H, P171, DOI DOI 10.1145/2600918.2600923
   Gironi A., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6226, DOI 10.1109/ICASSP.2014.6854801
   Jiang XH, 2013, IEEE SIGNAL PROC LET, V20, P447, DOI 10.1109/LSP.2013.2251632
   Junyu Xu, 2012, 2012 International Conference on Audio, Language and Image Processing (ICALIP 2012). Proceedings, P160, DOI 10.1109/ICALIP.2012.6376604
   Kang XG, 2016, MULTIMED TOOLS APPL, V75, P13833, DOI 10.1007/s11042-015-2762-7
   Li F., 2014, Proceedings of the 3rd International Conference on Multimedia Technology (ICMT 2013), P63
   Liao D, 2011, IS T SPIE ELECT IMAG
   Lin CS, 2014, DIGIT INVEST, V11, P120, DOI 10.1016/j.diin.2014.03.016
   Milani S, 2012, APSIPA TRANS SIGNAL, V1, DOI 10.1017/ATSIP.2012.2
   Ravi H, 2014, IEEE IMAGE PROC, P5352, DOI 10.1109/ICIP.2014.7026083
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Shanableh T, 2013, DIGIT INVEST, V10, P350, DOI 10.1016/j.diin.2013.10.004
   Stamm MC, 2012, IEEE T INF FOREN SEC, V7, P1315, DOI 10.1109/TIFS.2012.2205568
   Sun TF, 2012, INT CONF ACOUST SPEE, P1389, DOI 10.1109/ICASSP.2012.6288150
   Tian LH, 2015, MULTIMED TOOLS APPL, V74, P2991, DOI 10.1007/s11042-013-1765-5
   Union IT, 1995, 138182 ITU ISOIEC
   Vázquez-Padín D, 2012, IEEE INT WORKS INFOR, P151, DOI 10.1109/WIFS.2012.6412641
   Wang WH, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P39
   Yang JM, 2016, MULTIMED TOOLS APPL, V75, P1793, DOI 10.1007/s11042-014-2374-7
   Yuting Su, 2011, 2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference (ITAIC 2011), P461, DOI 10.1109/ITAIC.2011.6030373
   Yuxing Wu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2674, DOI 10.1109/ICASSP.2014.6854085
NR 30
TC 18
Z9 19
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20691
EP 20717
DI 10.1007/s11042-016-4004-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400014
DA 2024-07-18
ER

PT J
AU Jakus, G
   Stojmenova, K
   Tomazic, S
   Sodnik, J
AF Jakus, Grega
   Stojmenova, Kristina
   Tomazic, Saso
   Sodnik, Jaka
TI A system for efficient motor learning using multimodal augmented
   feedback
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motor learning; Feedback; Visualization; Sonification; Golf swing
ID VIRTUAL ENVIRONMENT; CONCURRENT FEEDBACK; BIOFEEDBACK; TASK; BENEFITS;
   GAIT
AB Numerous studies have established that using various forms of augmented feedback improves human motor learning. In this paper, we present a system that enables real-time analysis of motion patterns and provides users with objective information on their performance of an executed set of motions. This information can be used to identify individual segments of improper motion early in the learning process, thus preventing improperly learned motion patterns that can be difficult to correct once fully learned. The primary purpose of the proposed system is to serve as a general tool in the research on impact of different feedback modalities on the process of motor learning, for example, in sports or rehabilitation. The key advantages of the system are high-speed and high-accuracy tracking, as well as its flexibility, as it supports various types of feedback (auditory and visual, concurrent or terminal). The practical application of the proposed system is demonstrated through the example of learning a golf swing.
C1 [Jakus, Grega; Stojmenova, Kristina; Tomazic, Saso; Sodnik, Jaka] Univ Ljubljana, Fac Elect Engn, Trzaska Cesta 25, Ljubljana 1000, Slovenia.
C3 University of Ljubljana
RP Jakus, G (corresponding author), Univ Ljubljana, Fac Elect Engn, Trzaska Cesta 25, Ljubljana 1000, Slovenia.
EM grega.jakus@fe.uni-lj.si
RI Tomazic, Saso/A-2018-2008
OI Tomazic, Saso/0000-0002-2968-8879
CR Arvind D., 2008, P ICST 3 INT C BOD A, P28
   Baudry L, 2006, J SPORT SCI, V24, P149, DOI 10.1080/02640410500130979
   Chollet D., 1992, SWIMMING SCI, VVI, P48
   Chollet D., 1988, Swimming Science V, P389
   CLARKSON PM, 1986, RES Q EXERCISE SPORT, V57, P33, DOI 10.1080/02701367.1986.10605386
   Crowell HP, 2011, CLIN BIOMECH, V26, P78, DOI 10.1016/j.clinbiomech.2010.09.003
   Dozza M, 2007, EXP BRAIN RES, V178, P37, DOI 10.1007/s00221-006-0709-y
   Effenberg A. O., 2000, LEISTUNGSSPORT, V5, P19
   Femery VG, 2004, ARCH PHYS MED REHAB, V85, P1724, DOI 10.1016/j.apmr.2003.11.031
   Godbout A., 2010, Proceedings of the 16th international conference on auditory display, P23
   Holden MK., 2002, Neurol Rep, V26, P62, DOI DOI 10.1097/01253086-200226020-00003
   Jakus G., 2015, P 24 INT EL COMP SCI, P103
   Kirby R., 2009, Sports Technology, V2, P43, DOI DOI 10.1080/19346182.2009.9648498
   Kleiman-Weiner M., 2006, The sound of one arm swinging: a model for multidimensional auditory display of physical motion
   Koch K, 2006, CURR BIOL, V16, P1428, DOI 10.1016/j.cub.2006.05.056
   Konttinen M, 2004, J SPORT EXERCISE PSY, V26, P306, DOI 10.1123/jsep.26.2.306
   Koritnik T, 2008, GAIT POSTURE, V27, P323, DOI 10.1016/j.gaitpost.2007.04.015
   Krascek A., 2014, PROBL PERSP MICR NAN, P155
   Mullineaux DR, 2012, APPL ERGON, V43, P109, DOI 10.1016/j.apergo.2011.04.003
   Nilsson L, 2011, QTM REAL TIME SERVER
   PERROTT DR, 1991, HUM FACTORS, V33, P389, DOI 10.1177/001872089103300402
   Petrofsky JS, 2001, EUR J APPL PHYSIOL, V85, P491, DOI 10.1007/s004210100466
   Schmidt R. A., 2008, Motor Learning and Performance: A Situation-Based Learning Approach
   Schmidt R.A., 1991, CONT MANAGEMENT MOTO, P49
   Shea CH, 1999, HUM MOVEMENT SCI, V18, P553, DOI 10.1016/S0167-9457(99)00031-7
   Sigrist R, 2015, EXP BRAIN RES, V233, P909, DOI 10.1007/s00221-014-4167-7
   Sigrist R, 2013, PSYCHON B REV, V20, P21, DOI 10.3758/s13423-012-0333-8
   Sigrist R, 2011, PRESENCE-TELEOP VIRT, V20, P15, DOI 10.1162/pres_a_00032
   Smith RM, 2002, J SPORT SCI, V20, P783, DOI 10.1080/026404102320675639
   Snodgrass SJ, 2010, MANUAL THER, V15, P19, DOI 10.1016/j.math.2009.05.011
   Takahata M., 2004, Proceedings of the 2004 conference on New interfaces for musical expression, P13
   Todorov E, 1997, J MOTOR BEHAV, V29, P147, DOI 10.1080/00222899709600829
   Wulf G, 2002, PSYCHON B REV, V9, P185, DOI 10.3758/BF03196276
   Wulf G, 1999, J MOTOR BEHAV, V31, P95, DOI 10.1080/00222899909601895
NR 34
TC 10
Z9 10
U1 4
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20409
EP 20421
DI 10.1007/s11042-016-3774-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400002
DA 2024-07-18
ER

PT J
AU Jiang, WC
   Yin, ZZ
AF Jiang, Wenchao
   Yin, Zhaozheng
TI Indoor localization with a signal tree
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Indoor localization; Multimodal information fusion; Cross-media data
   analytics
AB Smartphones embedded with cameras and other sensors offer possibilities to attack the problem of indoor localization where GPS is not reliable. In this paper, a novel tree-based localization system is proposed based on WiFi, inertial and visual signals. There are three levels in the tree: (1) WiFi-based coarse positioning. The WiFi database of a building is clustered into several branches for coarse positioning; (2) Orientation pruning. Images collected in a building are tagged with camera orientations towards which they are taken, so when inferring a user's location by comparing the query image the user takes with the reference image dataset, the image branches tagged with unmatched orientation will not be searched; (3) Fine visual localization. The user's location is accurately determined by matching the query image with the reference image dataset based on a multi-level image description method. Our signal tree based method is compared with other methods in terms of the localization accuracy, localization efficiency and time cost to build the reference database. Experimental results on four large university buildings show that our indoor localization system is efficient and accurate for indoor environments.
C1 [Jiang, Wenchao; Yin, Zhaozheng] Missouri Univ Sci & Technol, Rolla, MO 65409 USA.
C3 University of Missouri System; Missouri University of Science &
   Technology
RP Yin, ZZ (corresponding author), Missouri Univ Sci & Technol, Rolla, MO 65409 USA.
EM yinz@mst.edu
RI jiang, wen/GYI-9662-2022
FU NSF [CNS-1205695, CMMI-1646162]; Intelligent Systems Center at Missouri
   University of Science and Technology; Office Of The Director; Office of
   Integrative Activities [1355406] Funding Source: National Science
   Foundation
FX This work was supported by NSF grant CNS-1205695 on social intelligent
   computing and NSF grant CMMI-1646162 on cyber-physical systems, and
   Intelligent Systems Center at Missouri University of Science and
   Technology. Any opinions, findings, and conclusions or recommendations
   expressed in this material are those of the author(s) and do not
   necessarily reflect the views of the National Science Foundation.
CR [Anonymous], 2013, International Journal of Software Engineering and Its Applications
   [Anonymous], 2010, P 8 INT C MOBILE SYS
   Azizyan M, 2009, FIFTEENTH ACM INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM 2009), P261
   Biswas J, 2010, IEEE INT CONF ROBOT, P4379, DOI 10.1109/ROBOT.2010.5509842
   Chen Y., 2012, P 10 INT C MOBILE SY, P169, DOI DOI 10.1145/2307636.2307653
   Chintalapudi K, 2010, MOBICOM 10 & MOBIHOC 10: PROCEEDINGS OF THE 16TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING AND THE 11TH ACM INTERNATIONAL SYMPOSIUM ON MOBILE AD HOC NETWORKING AND COMPUTING, P173, DOI 10.1145/1859995.1860016
   Constandache I., 2010, IEEE Infocom, P1
   Deak G, 2012, COMPUT COMMUN, V35, P1939, DOI 10.1016/j.comcom.2012.06.004
   Esteves JS, 2003, 2003 IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS, VOLS 1 AND 2, P346
   Fallah N, 2013, INTERACT COMPUT, V25, P21, DOI 10.1093/iwc/iws010
   Granados-Cruz M., 2014, Em: 2014 11th International Conference on Electrical Engineering, Computing Science and Automatic Control, P1, DOI [10.1109/ICEEE.2014. 6978256, DOI 10.1109/ICEEE.2014.6978256]
   Jang GJ, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1037, DOI 10.1109/ROBOT.2002.1013492
   Jiang YF, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P441
   Kim J, 2008, IEEE T CONSUM ELECTR, V54, P954, DOI 10.1109/TCE.2008.4637573
   Koide S, 2005, IEEE SYS MAN CYBERN, P859
   Koweerawong C., 2013, 2013 International Conference on Information Networking (ICOIN), P412, DOI 10.1109/ICOIN.2013.6496414
   Liu H, 2009, IEEE SYS MAN CYBERN, P4043, DOI 10.1109/ICSMC.2009.5346684
   Liu H, 2007, IEEE T SYST MAN CY C, V37, P1067, DOI 10.1109/TSMCC.2007.905750
   Liu RP, 2013, IEEE T COMPUT, V62, P589, DOI 10.1109/TC.2011.253
   Martin E., 2010, Proc. 18th ACM Int. Conf. Multimedia, P787, DOI [DOI 10.1145/1873951.1874078, 10.1145/1873951.1874078]
   Moghtadaiee V., 2011, INDOOR LOCALIZATION, P1, DOI [10.1109/IPIN.2011.6071932, DOI 10.1109/IPIN.2011.6071932]
   Pomárico-Franquiz J, 2014, MEASUREMENT, V50, P236, DOI 10.1016/j.measurement.2013.12.045
   Rai A, 2012, MOBICOM 12: PROCEEDINGS OF THE 18TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P293
   Shizhe Zhang, 2011, Proceedings of 2011 International Conference on Computer Science and Network Technology, P2640
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Wang JQ, 2005, IEEE INT CONF ROBOT, P4230
   Wang JQ, 2006, IEEE T SYST MAN CY B, V36, P413, DOI 10.1109/TSMCB.2005.859085
   Wang YP, 2013, 2013 IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE (CCNC), P837, DOI 10.1109/CCNC.2013.6488558
   Wu Hua., 2007, PATH PLANNING FOLLOW, P38
   Xu Rui, 2008, CLUSTERING, V10
   Yang Z, 2012, MOBICOM 12: PROCEEDINGS OF THE 18TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P269
NR 32
TC 3
Z9 5
U1 0
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 20317
EP 20339
DI 10.1007/s11042-017-4779-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500056
DA 2024-07-18
ER

PT J
AU Soleymani, SH
   Taherinia, AH
AF Soleymani, Seyyed Hossein
   Taherinia, Amir Hossein
TI High capacity image steganography on sparse message of scanned document
   image (SMSDI)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; High capacity; Sparse message; Document
ID MATCH VECTOR QUANTIZATION; DATA HIDING SCHEME; WATERMARKING; ROBUST;
   AUTHENTICATION; MODULATION; DCT
AB This paper presents a novel algorithm for high capacity image steganography, whose aim is to hide a scanned document as a message into a host image. In this approach, halftoning algorithm is applied to convert the gray-scale scanned document into a binary image, which is a sparse matrix. In the next step, an algorithm is proposed to read the the halftone image, and to convert each bit-stream of the sparse matrix into some meaningful decimal numbers, which are then to be embedded in 3-LSB bits of concealable pixels. Standard deviation is used in order to filter the concealable pixels of stego image and to preserve the quality of stego image. As a result, the smoother area that is sensitive to human visual system will not be chosen for embedding. The experiment results on 20 standard image, indicate that the PSNR measure and the embedding rate are 36.86 dB and 5.25 bpp in average, respectively, which are great progresses in comparison to the state-of-the-art.
C1 [Soleymani, Seyyed Hossein; Taherinia, Amir Hossein] Ferdowsi Univ Mashhad, Dept Comp Engn, Fac Engn, Mashhad, Iran.
C3 Ferdowsi University Mashhad
RP Taherinia, AH (corresponding author), Ferdowsi Univ Mashhad, Dept Comp Engn, Fac Engn, Mashhad, Iran.
EM seyyedhosein.soleymani@stu.um.ac.ir; taherinia@um.ac.ir
RI Taherinia, Amir Hossein/AAC-9575-2020; Taherinia, Amir
   Hossein/HTP-1792-2023
OI Taherinia, Amir Hossein/0000-0002-5103-4812; 
CR AbdAllah MM, 2011, AFRICAN J MATH COMPU, V4, P286
   Alasseur C, 2003, IEEE IMAGE PROC, P469
   [Anonymous], 2015, MULTIMEDIA TOOLS APP
   [Anonymous], 2016, SIPI IM DAT, P2016
   Balasubramanian C, 2014, MULTIMED TOOLS APPL, V73, P2223, DOI 10.1007/s11042-013-1640-4
   Borges PVK, 2008, IEEE T MULTIMEDIA, V10, P1479, DOI 10.1109/TMM.2008.2007294
   Chang CC, 2013, J SYST SOFTWARE, V86, P389, DOI 10.1016/j.jss.2012.09.001
   Huo YR, 2014, MULTIMED TOOLS APPL, V72, P123, DOI 10.1007/s11042-012-1317-4
   Jana B, 2016, OPTIK, V127, P3347, DOI 10.1016/j.ijleo.2015.12.055
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2179, DOI 10.1007/s11042-014-2081-4
   Kim HY, 2007, SIBGRAPI, P105, DOI 10.1109/SIBGRAPI.2007.31
   Kumar R, 2015, MULTIMED TOOLS APPL, P1
   Kurilin I. V., 2011, Pattern Recognition and Image Analysis, V21, P511, DOI 10.1134/S1054661811020660
   Laouamer L, 2015, ARAB J SCI ENG, V40, P1097, DOI 10.1007/s13369-015-1596-y
   Li X, 2006, IEEE SIGNAL PROC LET, V13, P688, DOI 10.1109/LSP.2006.879465
   Li X, 2011, IEEE IMAGE PROC, P1717, DOI 10.1109/ICIP.2011.6115789
   Liu L, 2015, MICROSYST TECHNOL, P1
   Liu LY, 2014, VISUAL COMPUT, V30, P1145, DOI 10.1007/s00371-013-0895-0
   Lu TC, 2014, MULTIMED TOOLS APPL, V72, P417, DOI 10.1007/s11042-013-1369-0
   Ma XX, 2016, MULTIMED TOOLS APPL, V75, P71, DOI 10.1007/s11042-014-2268-8
   Preda RO, 2013, MEASUREMENT, V46, P367, DOI 10.1016/j.measurement.2012.07.010
   Qazanfari K, 2014, INFORM SCIENCES, V277, P90, DOI 10.1016/j.ins.2014.02.007
   Rosales-Roldan L, 2013, SIGNAL PROCESS-IMAGE, V28, P69, DOI 10.1016/j.image.2012.11.006
   Shi H, 2016, MULTIMED TOOLS APPL, V75, P465, DOI 10.1007/s11042-014-2301-y
   Singh YK, 2015, IEEE INT C EL COMP C, P1
   Soleymani S.H., 2016, MULTIMED TOOLS APPL, P1
   Soleymani SH, 2015, 2015 5TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P18, DOI 10.1109/ICCKE.2015.7365856
   Stevenson RL, 1997, IEEE T IMAGE PROCESS, V6, P574, DOI 10.1109/83.563322
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Taherinia AH, 2010, INT J ELECTRON SECUR, V3, P1, DOI 10.1504/IJESDF.2010.032328
   Tang MW, 2016, OPTIK, V127, P471, DOI 10.1016/j.ijleo.2015.09.216
   Tang MW, 2014, OPTIK, V125, P3972, DOI 10.1016/j.ijleo.2014.01.149
   Tsang PWM, 1996, IEEE T CONSUM ELECTR, V42, P112, DOI 10.1109/30.485468
   Villan R, 2006, INT SOC OPTICS PHOTO
   Yang J, 2015, IEEE IMAGE PROC, P1463, DOI 10.1109/ICIP.2015.7351043
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 36
TC 12
Z9 12
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20847
EP 20867
DI 10.1007/s11042-016-4009-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400022
DA 2024-07-18
ER

PT J
AU Zhu, WZ
   Jiang, HL
   Zhou, SW
   Addison, M
AF Zhu, Wenzhong
   Jiang, Hualong
   Zhou, Shuwen
   Addison, Mike
TI An optimal resources scheduling strategy on multimedia cloud computing
   under multi- device constraint
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud resources; Multi-device; High dimension; Regression dimensionality
   reduction
AB In view of the problem of inaccurate scheduling by using traditional resource scheduling method, because the method is mainly based on extracting and classifying the resource features to make scheduling, ignoring the effect of the feature relevance between the resources on the scheduling results. This paper presents a model for multimedia cloud resource scheduling based on multi- device constraint. In this method the objective function is no longer constrained only by the CPU computing capacity and the minimized completion time, but to achieve a minimum time-consuming of CPU, memory and other peripherals operation are considered as the scheduling objectives. Then the utilization of solving constrained jointly is employed to obtain the mapping relationship of the optimal virtual and physical machine. Moreover, a regressive dimensionality reduction algorithm is designed for this scheduling model to solve the high dimensional problems aroused by multi-device constraints. Simulation results show that the improved algorithm has a better performance than the traditional algorithm, has a good efficiency and has a certain convergence.
C1 [Zhu, Wenzhong; Jiang, Hualong; Zhou, Shuwen] Sichuan Univ Sci & Engn, Sch Comp Sci, 180 Xueyuan Jie, Zigong 643000, Sichuan, Peoples R China.
   [Zhu, Wenzhong] Sichuan Prov Academician Expert Workstn Integrate, Zigong 643000, Peoples R China.
   [Addison, Mike] Calif Miramar Univ, Informat Management & Analyt, 644 Herry St, Atlanta, GA USA.
   [Zhu, Wenzhong] Sichuan Inst Technol, Comp Technol, 180 Sch St, Zigong City, Sichuan, Peoples R China.
C3 Sichuan University of Science & Engineering
RP Zhu, WZ (corresponding author), Sichuan Univ Sci & Engn, Sch Comp Sci, 180 Xueyuan Jie, Zigong 643000, Sichuan, Peoples R China.; Zhu, WZ (corresponding author), Sichuan Prov Academician Expert Workstn Integrate, Zigong 643000, Peoples R China.; Zhu, WZ (corresponding author), Sichuan Inst Technol, Comp Technol, 180 Sch St, Zigong City, Sichuan, Peoples R China.
EM zhuwenzhong_zwz@163.com
FU Scientific Research Fund of Jiangxi Provincial Education Department of
   China [GJJ13704]; Key Laboratory Higher Education of Sichuan Province
   for Enterprise Informationalization and Internet of Things [2014WYJ06];
   Sichuan Provincial Key Research Base of Intelligent Tourism [ZHZ14-02]
FX This work is supported by the Scientific Research Fund of Jiangxi
   Provincial Education Department of China (Grant No. GJJ13704). Funding
   Support By Key Laboratory Higher Education of Sichuan Province for
   Enterprise Informationalization and Internet of Things (No. 2014WYJ06);
   Sichuan Provincial Key Research Base of Intelligent Tourism (No.
   ZHZ14-02).
CR Ahn H, 2014, J CONVERG, V3, P17
   Beloglazov A, 2011, FUTURE GENER COMP SY, V5, P94
   Fang Y, 2010, WEB INF SYST MIN, V8, P59
   Gueguen C, 2012, J ELECT COMPUT ENG, V10, P466
   Gupta GP, 2015, J INF PROCESS SYST, V11, P148, DOI 10.3745/JIPS.03.0018
   [胡光波 Hu Guangbo], 2011, [计算机仿真, Computer Simulation], V28, P22
   Kang HS, 2015, J INF PROCESS SYST, V11, P39, DOI 10.3745/JIPS.02.0011
   Li C, 2013, J SUPERCOMPUT, V2, P134
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   Liu S, 2014, APPL MATH COMPUT, V243, P767, DOI 10.1016/j.amc.2014.06.016
   Lui S., 2017, Multimedia Tools and Applications, V76, P5787, DOI DOI 10.1007/S11042-014-2408-1
   Luo L, 2012, B SCI TECHNOLOGY, V28, P113
   Manvi SS, 2013, J NETW COMPUT APPL, V8, P312
   Motavaselalhagh F, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0031-4
   Pan Yi, 2012, J. Converg., V3, P23
   Park JH, 2014, J CONVERG, V4, P1
   Silachan K, 2014, J INF PROCESS SYST, V10, P395, DOI 10.3745/JIPS.04.0007
   Sinha A, 2013, HUMAN CENTRIC COMPUT, V6, P3
   Valêncio CR, 2012, HUM-CENTRIC COMPUT I, V2, DOI 10.1186/2192-1962-2-4
   Wang W-J, 2013, J SUPERCOMPUT, V2, P15
   Wang W-J, 2013, J SUPERCOMPUT, V2, P28
   Warneke D, 2011, IEEE T PARALL DISTR, V10, P136
   Wickboldt JA, 2014, COMPUT NETW, V5, P125
   Zhang L, 2008, INT J COMPUT INTELL, V12, P26
   [张人上 Zhang Renshang], 2012, [计算机仿真, Computer Simulation], V29, P162
NR 25
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19429
EP 19444
DI 10.1007/s11042-015-3140-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500006
DA 2024-07-18
ER

PT J
AU Muhammad, K
   Ahmad, J
   Rho, S
   Baik, SW
AF Muhammad, Khan
   Ahmad, Jamil
   Rho, Seungmin
   Baik, Sung Wook
TI Image steganography for authenticity of visual contents in social
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information security; Authenticity of visual contents; Steganography;
   Multimedia security; Crystography
ID FRAMEWORK; CAPACITY
AB Social networks are major sources of image sharing and secret messaging among the people. To date, such networks are not strictly bounded by copyright laws due to which image sharing, secret messaging, and its authentication is vulnerable to many risks. In addition to this, maintaining the confidentiality, integrity, and authenticity of secret messages is an open challenge of today's communication systems. Steganography is one of the solutions to tackle these problems. This paper proposes a secure crystographic framework for authenticity of visual contents using image steganography, utilizing color model transformation, three-level encryption algorithm (TLEA), and Morton scanning (MS)-directed least significant bit (LSB) substitution. The method uses I-plane of the input image in HSI for secret data embedding using MS-directed LSB substitution method. Furthermore, the secret data is encrypted using TLEA prior to embedding, adding an additional level of security for secure authentication. The qualitative and quantitative results verify the better performance of the proposed scheme and provide one of the best mechanisms for authenticity of visual contents in social networks.
C1 [Muhammad, Khan; Ahmad, Jamil; Baik, Sung Wook] Sejong Univ, Digital Contents Res Inst, Coll Elect & Informat Engn, Intelligent Media Lab, Seoul, South Korea.
   [Rho, Seungmin] Sungkyul Univ, Dept Media Software, Anyang, South Korea.
C3 Sejong University; Sungkyul University
RP Baik, SW (corresponding author), Sejong Univ, Digital Contents Res Inst, Coll Elect & Informat Engn, Intelligent Media Lab, Seoul, South Korea.
EM khan.muhammad.icp@gmail.com; jamilahmad@sju.ac.kr; smrho@sungkyul.edu;
   sbaik@sejong.ac.kr
RI Ahmad, Jamil/H-6264-2019; Baik, Sung Wook/AAR-8236-2020; Khan,
   Muhammad/IXN-8470-2023; Muhammad, Khan/L-9059-2016; Rho,
   Seungmin/HTP-6683-2023
OI Ahmad, Jamil/0000-0001-8407-5971; Muhammad, Khan/0000-0003-4055-7412;
   Muhammad, Khan/0000-0002-5302-1150; Baik, Sung Wook/0000-0002-6678-7788
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2016R1D1A1A09919551]
FX This work was supported by Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education (NRF-2016R1D1A1A09919551).
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Amirtharajan R, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P1064
   [Anonymous], WOSPA 2008
   [Anonymous], 2014, INT C ADV ENG TECHN
   [Anonymous], 2015, ME SMART CITIES 2015
   Ao BK, 2015, CHINA COMMUN, V12, P1, DOI 10.1109/CC.2015.7114054
   Bailey K, 2006, MULTIMED TOOLS APPL, V30, P55, DOI 10.1007/s11042-006-0008-4
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Grover N, 2013, 2013 SECOND INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING, NETWORKING AND SECURITY (ADCONS 2013), P238, DOI 10.1109/ADCONS.2013.45
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Hamza R, 2016, INF SECUR J, V25, P162, DOI 10.1080/19393555.2016.1212954
   Ioannidou A, 2012, EXPERT SYST APPL, V39, P11517, DOI 10.1016/j.eswa.2012.02.106
   Jan Z, 2012, J CHIN INST ENG, V35, P85, DOI 10.1080/02533839.2012.625146
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Ker AD, 2005, LECT NOTES COMPUT SC, V3727, P296
   Liu ZH, 2016, SIGNAL PROCESS, V123, P157, DOI 10.1016/j.sigpro.2015.10.023
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Masud Karim S. M., 2011, 2011 14th International Conference on Computer and Information Technology (ICCIT), P286, DOI 10.1109/ICCITechn.2011.6164800
   Mehmood I, 2014, SENSORS-BASEL, V14, P17112, DOI 10.3390/s140917112
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Mstafa RJ, 2017, MULTIMED TOOLS APPL, V76, P21749, DOI 10.1007/s11042-016-4055-1
   Mstafa RJ, 2016, MULTIMED TOOLS APPL, V75, P10311, DOI 10.1007/s11042-015-3060-0
   Muhammad Khan, 2015, NED University Journal of Research, V12, P81
   Muhammad K., 2015, ARXIV, V19, P57
   Muhammad K, 2018, FUTURE GENER COMP SY, V86, P951, DOI 10.1016/j.future.2016.11.029
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Muhammad K, 2017, BIOMED SIGNAL PROCES, V33, P161, DOI 10.1016/j.bspc.2016.11.011
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Muhammad K, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3171-8
   Muhammad K, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0473-x
   Muhammad K, 2015, KSII T INTERNET INF, V9, P1938
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Parvez MT, 2008, 2008 IEEE ASIA-PACIFIC SERVICES COMPUTING CONFERENCE, VOLS 1-3, PROCEEDINGS, P1322, DOI 10.1109/APSCC.2008.105
   Patsakis C, 2015, COMPUT J, V58, P518, DOI 10.1093/comjnl/bxu066
   Qazanfari K, 2014, INFORM SCIENCES, V277, P90, DOI 10.1016/j.ins.2014.02.007
   Sheikh H. R., 2003, Image and video quality assessment research at live
   Swain G., 2012, Int Arab J Technol, V2, P181
   Tang MW, 2014, OPTIK, V125, P3972, DOI 10.1016/j.ijleo.2014.01.149
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu N.-I., 2007, IJ Network Security, V4, P1
NR 43
TC 47
Z9 48
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18985
EP 19004
DI 10.1007/s11042-017-4420-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800039
DA 2024-07-18
ER

PT J
AU Zheng, LX
   Ruan, XY
   Chen, YB
   Huang, MZ
AF Zheng, Lingxiang
   Ruan, Xiaoyang
   Chen, Yunbiao
   Huang, Minzheng
TI Shadow removal for pedestrian detection and tracking in indoor
   environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background elimination; Shadow removal; Gray histogram space; Pedestrian
   detectiing; Pedestrian tracking
AB This paper presents a method of shadow removal to improve the accuracy of pedestrian detection and tracking in indoor environments. The proposed method can be divided into four steps: building a background model which can be automatically updated, extract moving objects region, eliminating moving objects shadows, classifying and track pedestrians. The background model is built with pixel value and the updating of Gussian. The approach for real time background-foreground extraction is used to extract pedestrian region that may contains multiple shadows. In the gray histogram space, based on the depth value of the gray images, a reasonable threshold is set to remove shadows from various pedestrians. In this work, we propose a methodology using the foreground frames without shadows to detect and track the pedestrians across training datasets. Comparative experimental results show that our method is capable of dealing with shadows and detecting moving pedestrians in cluttered environments.
C1 [Zheng, Lingxiang; Ruan, Xiaoyang; Chen, Yunbiao; Huang, Minzheng] Xiamen Univ, Sch Informat Sci & Engn, Xiamen, Peoples R China.
C3 Xiamen University
RP Zheng, LX (corresponding author), Xiamen Univ, Sch Informat Sci & Engn, Xiamen, Peoples R China.
EM lxzheng@xmu.edu.cn
CR Chen B, 2004, CIT04
   Chen C, 2010, 20 INT C PATT REC IC
   Cheng HD, 2000, IEEE T IMAGE PROCESS, V9, P732, DOI 10.1109/83.841949
   Cheung S.S., 2004, P SPIE
   Choi J, 2010, COMPUT VIS IMAGE UND, V114, P1017, DOI 10.1016/j.cviu.2010.06.003
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Gavrila DM, 2004, INT VEH S IEEE
   Guo L, 2010, 2  INT C COMP TECHN
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hsieh JW, 2003, IMAGE VISION COMPUT, V21, P505, DOI 10.1016/S0262-8856(03)00030-1
   Huerta I, 2007, COMP VIS IEEE 12 INT
   Hurney P, 2015, IET INTELL TRANSP SY, V9, P75, DOI 10.1049/iet-its.2013.0163
   Jeong S, 2013, PROC SPIE, V8878, DOI 10.1117/12.2030790
NR 15
TC 6
Z9 7
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18321
EP 18337
DI 10.1007/s11042-016-3880-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800007
DA 2024-07-18
ER

PT J
AU Khan, NH
   Adnan, A
AF Khan, Naila Habib
   Adnan, Awais
TI Ego-motion estimation concepts, algorithms and challenges: an overview
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camera motion; Ego-motion; Motion estimation; Visual odometry
ID OPTICAL-FLOW; VISUAL ODOMETRY; STEREO; PERCEPTION; EGOMOTION
AB Ego-motion technology holds great significance for computer vision applications, robotics, augmented reality and visual simultaneous localization and mapping. This paper is a study of ego-motion estimation basic concepts, equipment, algorithms, challenges and its real world applications. First, we provide an overview for motion estimation in general with special focus on ego-motion estimation and its basic concepts. For ego-motion estimation it's necessary to understand the notion of independent moving objects, focus of expansion, motion field, and optical flow. Vital algorithms that are used for ego-motion estimation are critically discussed in the following section of the paper. Various camera setups and their potential weakness and strength are also studied in context of ego-motion estimation. We also briefly specify some ego-motion applications used in the real world. We conclude the paper by discussing some open problems, provide some future directions and finally summarize the entire paper in the conclusions.
C1 [Khan, Naila Habib; Adnan, Awais] Inst Management Sci, Dept Comp Sci, Peshawar, Pakistan.
RP Khan, NH (corresponding author), Inst Management Sci, Dept Comp Sci, Peshawar, Pakistan.
EM naila.khancs@yahoo.com; awais.adnan@imsciences.edu.pk
OI Khan, Naila Habib/0000-0002-4822-6725
CR Agrawal P, 2015, IEEE I CONF COMP VIS, P37, DOI 10.1109/ICCV.2015.13
   Alvarez L., 1999, PROC CONGRESO ECUACI, P1349
   [Anonymous], CHANCE
   [Anonymous], INF ACQ 2005 IE INT
   [Anonymous], BINOCULAR EGO MOTION
   [Anonymous], 2006, PROC IEEE 4 INT C CO, DOI DOI 10.1109/ICVS.2006.3
   [Anonymous], SPATIAL VISION HUMAN
   [Anonymous], IEEE INT C ROB AUT I
   [Anonymous], AM CONTR C
   [Anonymous], IMAGE
   [Anonymous], 2010, THESIS
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], THESIS
   [Anonymous], 2007, APPL COMP VIS 2007 W
   [Anonymous], INT VEH S 2006 IEEE
   [Anonymous], THESIS
   Ayvaci A, 2012, INT J COMPUT VISION, V97, P322, DOI 10.1007/s11263-011-0490-7
   Badino H, 2007, LECT NOTES COMPUT SC, V3417, P198
   Baik YK, 2013, IMAGE VISION COMPUT, V31, P565, DOI 10.1016/j.imavis.2013.04.004
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   BRANDT T, 1977, EXP BRAIN RES, V30, P331
   Briod A, 2016, AUTON ROBOT, V40, P789, DOI 10.1007/s10514-015-9494-4
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7
   Burger W., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P563, DOI 10.1109/CVPR.1989.37902
   BURGER W, 1990, IEEE T PATTERN ANAL, V12, P1040, DOI 10.1109/34.61704
   Campbell J, 2005, IEEE INT CONF ROBOT, P3421
   Cao YP, 2007, IMVIP 2007: INTERNATIONAL MACHINE VISION AND IMAGE PROCESSING CONFERENCE, PROCEEDINGS, P185, DOI 10.1109/IMVIP.2007.36
   Chang P, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P127, DOI 10.1109/OMNVIS.2000.853819
   Cheng Y, 2005, IEEE SYS MAN CYBERN, P903
   Costante G, 2016, IEEE ROBOT AUTOM LET, V1, P18, DOI 10.1109/LRA.2015.2505717
   Deriche R., 1996, RECENT DEV COMPUTER, P69
   Dornaika F, 2003, IEEE T SYST MAN CY B, V33, P308, DOI 10.1109/TSMCB.2002.805698
   Dornaika F, 2007, LECT NOTES COMPUT SC, V4633, P469
   Endres F, 2014, IEEE INT C INT ROBOT, P466, DOI 10.1109/IROS.2014.6942600
   Ess A., 2008, COMPUTER VISION PATT, V2008, P1, DOI [10.1109/CVPR.2008.4587581, DOI 10.1109/CVPR.2008.4587581]
   Franke U, 2005, LECT NOTES COMPUT SC, V3663, P216
   Fredriksson J, 2015, PROC CVPR IEEE, P2684, DOI 10.1109/CVPR.2015.7298884
   Fredriksson J, 2014, PROC CVPR IEEE, P1606, DOI 10.1109/CVPR.2014.208
   Gandhi T, 2005, MACH VISION APPL, V16, P85, DOI 10.1007/s00138-004-0168-z
   GIBSON JJ, 1970, SCAND J PSYCHOL, V11, P75, DOI 10.1111/j.1467-9450.1970.tb00720.x
   Gillner W. J., 1995, Proceedings of the Intelligent Vehicles '95. Symposium (Cat. No.95TH8132), P483, DOI 10.1109/IVS.1995.528329
   Gluckman J, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P999, DOI 10.1109/ICCV.1998.710838
   Goecke Roland, 2007, Proceedings of the 2007 IEEE Intelligent Vehicles Symposium, P450
   Hariyono J, 2014, LECT NOTES COMPUT SC, V8397, P553, DOI 10.1007/978-3-319-05476-6_56
   HEEGER DJ, 1992, INT J COMPUT VISION, V7, P95, DOI 10.1007/BF00128130
   HILDRETH EC, 1992, VISION RES, V32, P1177, DOI 10.1016/0042-6989(92)90020-J
   HORN BKP, 1988, INT J COMPUT VISION, V2, P51, DOI 10.1007/BF00836281
   HORN BKP, 1981, P SOC PHOTO-OPT INST, V281, P319
   Humayun A, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995517
   IRANI M, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P454, DOI 10.1109/CVPR.1994.323866
   JAIN R, 1987, IEEE T PATTERN ANAL, V9, P356, DOI 10.1109/TPAMI.1987.4767919
   Jain R., 1995, MACHINE VISION
   Jayaraman D, 2015, IEEE I CONF COMP VIS, P1413, DOI 10.1109/ICCV.2015.166
   Jepson A. D., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P124, DOI 10.1109/WVM.1991.212779
   Jung B., 2004, International Conference on Intelligent Autonomous Systems, P980
   KANATANI K, 1993, INT J COMPUT VISION, V11, P267, DOI 10.1007/BF01469345
   Karlsson N, 2005, IEEE INT CONF ROBOT, P24
   Kellner D, 2014, IEEE INT CONF ROBOT, P1592, DOI 10.1109/ICRA.2014.6907064
   Kim JH, 2010, IEEE T PATTERN ANAL, V32, P1044, DOI 10.1109/TPAMI.2009.82
   Konolige K, 2010, SPRINGER TRAC ADV RO, V66, P201
   Lauer M, 2007, LECT NOTES ARTIF INT, V4434, P466
   MacLean W.J., 1994, British Machine Vision Conference, P1
   Maimone M, 2007, J FIELD ROBOT, V24, P169, DOI 10.1002/rob.20184
   Maki A, 2000, LECT NOTES COMPUT SC, V1842, P725
   Mandelbaum R., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P544, DOI 10.1109/ICCV.1999.791270
   McQuirk IS, 1997, ISSCC DIG TECH PAP I, V40, P40, DOI 10.1109/ISSCC.1997.585567
   Milella Annalisa., 2006, IEEE International Conference on Computer Vision Systems, P21
   Munguia R, 2007, INTELLIGENT SIGNAL P, P1
   NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833
   Nayar SK, 1997, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1997.609369
   NEGAHDARIPOUR S, 1989, COMPUT VISION GRAPH, V46, P303, DOI 10.1016/0734-189X(89)90035-2
   NEISSER U, 1977, J THEOR SOC BEHAV, V7, P17, DOI 10.1111/j.1468-5914.1977.tb00375.x
   Nistér D, 2004, PROC CVPR IEEE, P652
   Olson CF, 2003, ROBOT AUTON SYST, V43, P215, DOI 10.1016/S0921-8890(03)00004-6
   Olson CF, 2001, IEEE INT CONF ROBOT, P1099, DOI 10.1109/ROBOT.2001.932758
   Olson CF, 2000, PROC CVPR IEEE, P453, DOI 10.1109/CVPR.2000.854879
   PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077
   Prazdny K., 1979, Proceedings of the 6th international joint conference on Artificial intelligence-Volume, V2, P702
   Raudies F, 2012, COMPUT VIS IMAGE UND, V116, P606, DOI 10.1016/j.cviu.2011.04.004
   Raudies F, 2009, LECT NOTES COMPUT SC, V5748, P11, DOI 10.1007/978-3-642-03798-6_2
   RIEGER JH, 1985, J OPT SOC AM A, V2, P354, DOI 10.1364/JOSAA.2.000354
   Scaramuzza D, 2008, IEEE T ROBOT, V24, P1015, DOI 10.1109/TRO.2008.2004490
   Schmid K, 2013, IEEE INT CONF ROBOT, P4671, DOI 10.1109/ICRA.2013.6631242
   Schnorr C., 1994, Proceedings of the 12th IAPR International Conference on Pattern Recognition (Cat. No.94CH3440-5), P661, DOI 10.1109/ICPR.1994.576391
   Seki A, 2006, IEEE INT CONF ROBOT, P901, DOI 10.1109/ROBOT.2006.1641824
   Shafait F, 2004, INMIC 2004: 8TH INTERNATIONAL MULTITOPIC CONFERENCE, PROCEEDINGS, P131
   Shakernia O., 1999, Asian Journal of Control, V1, P128, DOI 10.1111/j.1934-6093.1999.tb00014.x
   Shulman D., 1989, Proceedings. Workshop on Visual Motion (IEEE Cat. No.89CH2716-9), P81, DOI 10.1109/WVM.1989.47097
   Sivaraman S, 2011, IEEE INT C INTELL TR, P1249, DOI 10.1109/ITSC.2011.6082916
   Srinivasan Natesh, 2013, Computer Vision Systems. 9th International Conference, ICVS 2013. Proceedings: LNCS 7963, P183, DOI 10.1007/978-3-642-39402-7_19
   Stein GP, 2000, PROCEEDINGS OF THE IEEE INTELLIGENT VEHICLES SYMPOSIUM 2000, P362, DOI 10.1109/IVS.2000.898370
   Stephens M. J., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P556, DOI 10.1109/CVPR.1989.37901
   Strelow D, 2001, PROC CVPR IEEE, P689
   Sun DQ, 2014, INT J COMPUT VISION, V106, P115, DOI 10.1007/s11263-013-0644-x
   Tian TY, 1996, PROC CVPR IEEE, P315, DOI 10.1109/CVPR.1996.517091
   Tomasi C., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P422, DOI 10.1109/CVPR.1993.341096
   Trucco E., 1998, INTRO TECHNIQUES 3 D, V201
   Tsao AT, 1997, PROC CVPR IEEE, P457, DOI 10.1109/CVPR.1997.609365
   Tsotsos K, 2012, IEEE-RAS INT C HUMAN, P704, DOI 10.1109/HUMANOIDS.2012.6651597
   van der Mark W, 2002, IV'2002: IEEE INTELLIGENT VEHICLE SYMPOSIUM, PROCEEDINGS, P58
   Vassallo RF, 2002, THIRD WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P97, DOI 10.1109/OMNVIS.2002.1044502
   VERRI A, 1989, IEEE T PATTERN ANAL, V11, P490, DOI 10.1109/34.24781
   WARREN R, 1976, J EXP PSYCHOL HUMAN, V2, P448, DOI 10.1037/0096-1523.2.3.448
   Weickert J, 2001, INT J COMPUT VISION, V45, P245, DOI 10.1023/A:1013614317973
   Wu Y, 2001, PROC CVPR IEEE, P252
   Yamaguchi K., 2006, Intelligent Vehicles Symposium, 2006 IEEE, P288
   Yamaguchi K, 2006, INT C PATT RECOG, P610
   Yamaguchi K, 2014, LECT NOTES COMPUT SC, V8693, P756, DOI 10.1007/978-3-319-10602-1_49
   Yamamoto Y, 2005, 2005 IEEE WORKSHOP ON ADVANCED ROBOTICS AND ITS SOCIAL IMPACTS, P14
   Yang B, 2014, SCI CHINA INFORM SCI, V57, DOI 10.1007/s11432-013-5011-6
   Yang M, 2002, IV'2002: IEEE INTELLIGENT VEHICLE SYMPOSIUM, PROCEEDINGS, P44
   ZHUANG XH, 1988, COMPUT VISION GRAPH, V42, P334, DOI 10.1016/S0734-189X(88)80043-4
NR 114
TC 4
Z9 4
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16581
EP 16603
DI 10.1007/s11042-016-3939-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100023
DA 2024-07-18
ER

PT J
AU Zhu, GX
   Cao, J
   Li, CS
   Wu, Z
AF Zhu, Guixiang
   Cao, Jie
   Li, Changsheng
   Wu, Zhiang
TI A recommendation engine for travel products based on topic sequential
   patterns
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Travel recommendation; Frequent sequential pattern; Cold-start users;
   Web server logs; Long tail items; Recommender system
AB Travel products recommendation has become one of emerging issues in the realm of recommendation systems. The widely-used collaborative filtering algorithms are usually difficult to be used for recommending travel products due to a number of reasons, including (1) the content of travel products is very complex, (2) the user-item matrix is extremely sparse, and (3) the cold-start users are widely existing. To tackle these issues, we try to exploit Web server logs for generating recommendation, and present a novel recommendation engine (SECT for short) for travel products based on topic sequential patterns. In detail, we first extract topics from semantic description of every Web page. Then, we mine topic frequent sequential patterns and their target products to form click patterns library. At last, we propose a Markov n-gram model for matching the real-time click-stream of users with the click patterns library and thus computing recommendation scores. Experimental results on a real-world travel dataset demonstrate that the SECT prevails over the state-of-art baseline algorithms. In particular, SECT shows merits in improving the both coverage and accuracy for recommending products to cold-start users. Also, SECT is effective to recommend long tail items and outperform baseline algorithms.
C1 [Zhu, Guixiang] Nanjing Univ Sci & Technol, Coll Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China.
   [Cao, Jie; Li, Changsheng; Wu, Zhiang] Nanjing Univ Finance & Econ, Jiangsu Prov Key Lab E Business, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology; Nanjing University of
   Finance & Economics
RP Cao, J (corresponding author), Nanjing Univ Finance & Econ, Jiangsu Prov Key Lab E Business, Nanjing, Jiangsu, Peoples R China.
EM zgx881205@gmail.com; Jie.Cao@njue.edu.cn
RI Cao, jie/JXR-6551-2024; Cao, Jie/AAD-1518-2019
OI Cao, Jie/0000-0002-9942-3243
FU National Key Research and Development Program of China [2016YFB1000901];
   National Natural Science Foundation of China [91646204, 71571093,
   71372188]; National Center for International Joint Research on
   E-Business Information Processing [2013B01035]; Industry Projects in
   Jiangsu S&T Pillar Program [BE2014141]
FX This work was partially supported by the National Key Research and
   Development Program of China (2016YFB1000901), National Natural Science
   Foundation of China (91646204, 71571093, 71372188), National Center for
   International Joint Research on E-Business Information Processing
   (2013B01035), and Industry Projects in Jiangsu S&T Pillar Program
   (BE2014141).
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   [Anonymous], 2011, DATA MINING ICDM
   [Anonymous], 2010, P 17 INT C WORLD WID, DOI DOI 10.1145/1772690.1772732
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Burke R., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P377
   Cao X, 2010, PROC VLDB ENDOW, V3, P1009, DOI 10.14778/1920841.1920968
   Chen S.F., 1996, P ACL, DOI DOI 10.3115/981863.981904
   Cheng A.-J., 2011, P 19 ACM INT C MULTI, P83
   Drosatos G, 2015, P INT COMP SOFTW APP, P822, DOI 10.1109/COMPSAC.2015.88
   Fu AWC, 2008, VLDB J, V17, P899, DOI 10.1007/s00778-006-0040-z
   Ge Y., 2010, P 16 ACM SIGKDD INT, P899, DOI [DOI 10.1145/1835804.1835918, 10.1145/1835804.1835918]
   Ge Y., 2011, P 17 ACM SIGKDD INT, P735
   Ge Y, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2559169
   Hariri N., 2012, P 6 ACM C RECOMMENDE, P131, DOI DOI 10.1145/2365952.2365979
   Jannach D., 2009, Information Technology and Tourism, V11, P139, DOI 10.3727/109830509789994784
   Jarvelin K., 2000, SIGIR Forum, V34, P41
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Letham B, 2013, MACH LEARN, V93, P357, DOI 10.1007/s10994-013-5356-5
   Liu Q, 2014, IEEE T KNOWL DATA EN, V26, P278, DOI 10.1109/TKDE.2012.233
   Lu X., 2010, Proceedings of the 18th ACM International Conference on Multimedia, Firenze Italy, 25 October 2010, DOI [19.1145/1873951.1873972, DOI 10.1145/1873951.1873972]
   Majid A, 2012, AAAI
   Majid A, 2013, INT J GEOGR INF SCI, V27, P662, DOI 10.1080/13658816.2012.696649
   Mouzhi Ge, 2010, P 4 ACM C REC SYST B, P257, DOI [10.1145/1864708.1864761, DOI 10.1145/1864708.1864761]
   NEY H, 1994, COMPUT SPEECH LANG, V8, P1, DOI 10.1006/csla.1994.1001
   Pazzani M. J., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P325
   Peng FC, 2004, INFORM RETRIEVAL, V7, P317, DOI 10.1023/B:INRT.0000011209.19643.e2
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Rudin C., 2011, Proceedings of the 24th Annual Conference on Learning Theory, COLT '11, P615
   Schafer J. B., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P291
   Sun Aixin, 2007, P 16 ACM C INF KNOWL, P243
   Tan C, 2014, ACM T INTEL SYST TEC, V5, DOI 10.1145/2542665
   Xie M., 2010, P 4 ACM C REC SYST, P151, DOI DOI 10.1145/1864708.1864739
   Xing Z., 2010, ACM SIGKDD EXPLOR NE, V12, P40, DOI [DOI 10.1145/1882471.1882478, 10.1145/1882471.1882478]
   Yin Z., 2011, SIAM, P980
   Yuan J., 2010, P 18 SIGSPATIAL INT, P99, DOI DOI 10.1145/1869790.1869807
   Zaki MJ, 2000, IEEE T KNOWL DATA EN, V12, P372, DOI 10.1109/69.846291
   [张玉洁 Zhang Yujie], 2016, [计算机学报, Chinese Journal of Computers], V39, P745
   Zheng Y., 2009, WWW, P791, DOI [10.1145/1526709.1526816, DOI 10.1145/1526709.1526816]
   Zheng Y, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1889681.1889683
   Zheng Y, 2011, ACM T WEB, V5, DOI 10.1145/1921591.1921596
NR 41
TC 17
Z9 17
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17595
EP 17612
DI 10.1007/s11042-017-4406-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500040
DA 2024-07-18
ER

PT J
AU Jang, BJ
   Lee, SH
   Lee, EJ
   Lim, S
   Kwon, KR
AF Jang, Bong-Joo
   Lee, Suk-Hwan
   Lee, Eung-Joo
   Lim, Sanghun
   Kwon, Ki-Ryong
TI A crypto-marking method for secure vector map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secure vector map; GIS security; Perceptual encryption; Watermarking;
   Crypto-marking
ID WATERMARKING SCHEME; ENCRYPTION; ALGORITHM
AB A crypto-marking technique can be used to provide a solution to the secure transmission and storage of highly valuable and detailed vector maps. Such a solution would fulfill the requirements for integrity verification, content security, copyright protection, and authentication. However, existing methods cannot ensure the perceptual invisibility of the watermarking in the encryption domain and can leak the encryption key while decrypting a crypto-marked map. In response to these issues, we present a vector map crypto-marking method using both watermarking and progressive perceptual encryption that are independent of each other. The first watermarking step embeds the watermark using the mean of the Euclidian distance (MED) while preserving the object shape and being robust to geometric attacks. The second perceptual encryption step encrypts the progressive regions in a layer, the objects of a region, and the vertices in an object so that a direct random-access object can be enabled in the encryption/decryption processes. To attain the mutual independence of watermarking and encryption, we encrypted the attributes of objects by using random permutations of the position and orientation of the vertices while preserving the SEDs of all the objects. Hence, the watermark can be extracted in a crypto-marked map or progressive encrypted map without decrypting all the objects. From the experimental results, we found that our method is robust to attacks that damage the vector map during the decryption step and does not produce a leakage of the encryption key during the watermark detecting step. Furthermore, we found that the time required by our method is proportional to the number of objects in vector maps, 0.59 [s] for 7,765 objects and 3.52 [s] for 50,679 objects. Our MED-based watermarking takes less time (about 0.07-0.43 [s] than conventional watermarking methods while our progressive encryption takes less time, at about 0.09 [s] - 0.37 [s], than conventional encryption methods.
C1 [Jang, Bong-Joo; Lim, Sanghun] Korea Inst Civil Engn & Bldg Technol KICT, Water Resources Res Div, 283 Goyang Daero, Goyang Si, Gyeonggi Do, South Korea.
   [Lee, Suk-Hwan] Tongmyong Univ, Dept Informat Secur, 428 Sinseonno, Busan, South Korea.
   [Lee, Eung-Joo] Tongmyong Univ, Dept Informat Commun Engn, 428 Sinseonno, Busan, South Korea.
   [Kwon, Ki-Ryong] Pukyong Natl Univ, Dept IT Convergence & Applicat Engn, 599-1 Daeyeon Dong, Busan, South Korea.
C3 Korea Institute of Civil Engineering & Building Technology (KICT);
   Tongmyong University; Tongmyong University; Pukyong National University
RP Kwon, KR (corresponding author), Pukyong Natl Univ, Dept IT Convergence & Applicat Engn, 599-1 Daeyeon Dong, Busan, South Korea.
EM roachjbj@kict.re.kr; skylee@tu.ac.kr; ejlee@tu.ac.kr; slim@kict.re.kr;
   krkwon@pknu.ac.kr
RI Jang, Bongjoo/KSM-3832-2024
OI Lim, Sanghun/0000-0002-0545-9369; Lee, Suk-Hwan/0000-0003-4779-2888
FU National Research Foundation of Korea (NRF) - Ministry of Education
   [NRF-2014R1A1A4A01006663]; Strategic Research Project; Korea Institute
   of Civil Engineering and Building Technology; Brain Busan Project [BB21]
FX This research was supported by This research was supported by Basic
   Science Research Program through the National Research Foundation of
   Korea (NRF) funded by the Ministry of Education
   (NRF-2014R1A1A4A01006663) and supported by a grant from the Strategic
   Research Project (Development of Driving Environment Observation,
   Prediction and Safety Technology Based on Automotive Sensors), which is
   funded by the Korea Institute of Civil Engineering and Building
   Technology and also supported by BB21 (Brain Busan) Project partially.
CR Abubahia AM, 2015, PROC INT C TOOLS ART, P575, DOI 10.1109/ICTAI.2015.89
   Airport Integrated Mapping System (AIMS), 2003, SJCACMAIMS2611
   [Anonymous], P WORKSH MULT SEC MM
   Autrusseau F, 2003, PROC SPIE, V5032, P958, DOI 10.1117/12.480296
   Cancellaro M, 2008, ELECT IMAGING
   Cao LJ, 2015, SIGNAL IMAGE VIDEO P, V9, P1387, DOI 10.1007/s11760-013-0606-3
   Cao LJ, 2013, DIGIT SIGNAL PROCESS, V23, P912, DOI 10.1016/j.dsp.2012.11.007
   Dakroury Y, 2010, INT J COMPUT SCI NET, V10, P75
   Deng S, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P1236
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Hu WH, 2010, 2010 INTERNATIONAL CONFERENCE ON ENGINEERING COMPUTATION (ICEC 2010), P1
   Huber WA, 2002, DIRECTIONS MAGAZINE
   Jang BJ, 2014, DIGIT SIGNAL PROCESS, V25, P224, DOI 10.1016/j.dsp.2013.09.013
   Kang H, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P234, DOI 10.1109/ITCC.2001.918797
   장봉주, 2011, [Computer and Information, 전자공학회논문지 - CI], V48, P88
   Lee SH, 2014, IEICE T INF SYST, VE97D, P34, DOI 10.1587/transinf.E97.D.34
   Lee SH, 2014, MULTIMED TOOLS APPL, V73, P1913, DOI 10.1007/s11042-013-1661-z
   Lee SH, 2013, MULTIMED TOOLS APPL, V63, P757, DOI 10.1007/s11042-011-0894-y
   Lian SG, 2007, IEEE T CIRC SYST VID, V17, P774, DOI 10.1109/TCSVT.2007.896635
   Lian SG, 2009, MULTIMED TOOLS APPL, V43, P91, DOI 10.1007/s11042-008-0258-4
   Lipmaa H., 2000, 1 NIST WORKSH MOD OP
   Merhav N, 2006, IEEE T INFORM THEORY, V52, P190, DOI 10.1109/TIT.2005.860427
   Ngoc GP, 2015, INT J SECUR APPL, V9, P61, DOI 10.14257/ijsia.2015.9.2.07
   Ohbuchi R, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P577, DOI 10.1109/ICME.2002.1035847
   Park KT, 2002, LECT NOTES COMPUT SC, V2532, P58
   Peng ZY, 2015, MULTIMED TOOLS APPL, V74, P11721, DOI 10.1007/s11042-014-2259-9
   Schmitz Roland, 2012, Communications and Multimedia Security. 13th IFIP TC 6/TC 11 International Conference, CMS 2012. Proceedings, P117, DOI 10.1007/978-3-642-32805-3_10
   Sonnet H, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P73, DOI 10.1109/PCCGA.2003.1238249
   Wang N, 2015, INT J DIGIT CRIME FO, V7, P60, DOI [10.4018/ijdcf.2015070104, 10.4018/IJDCF.2015070104]
   Wang NN, 2013, MULTIMED TOOLS APPL, V67, P709, DOI 10.1007/s11042-012-1333-4
   Zhang D, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL II, PROCEEDINGS, P469
NR 31
TC 13
Z9 17
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 16011
EP 16044
DI 10.1007/s11042-016-3893-1
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900034
DA 2024-07-18
ER

PT J
AU Raghuwanshi, G
   Tyagi, V
AF Raghuwanshi, Ghanshyam
   Tyagi, Vipin
TI A novel technique for location independent object based image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tetrolet; Image retrieval; CBIR; OBIR; RBIR
ID REGION
AB This paper proposes an approach of object based image retrieval to retrieve the images based on location independent region of interest (ROI). In this approach, instead of extracting the features of the whole query image, features of the objects of interest are extracted. For this, some morphological operations are performed on the image. First, background subtraction is performed to reduce the effect of background intensities, then segmentation is performed and the regions are extracted. To minimize the number of comparisons in image retrieval process, the image is categorized into texture and non texture regions. This reduces the retrieval time by comparing the ROI on the basis of its category. During the feature extraction process, a flag is set to indicate the category of the image i.e. texture image or non-texture (natural) image. Feature vector of an image is stored along with respective objects within the image. Tetrolet transform is used to retrieve the texture features for the texture regions while moment invariants and edge features are used for non-texture regions. The performance and efficiency of the proposed system is tested on COREL and CIFAR databases. Experimental results show that the retrieval performance of the proposed algorithm is better in comparison to other state-of-the-art methods.
C1 [Raghuwanshi, Ghanshyam; Tyagi, Vipin] Jaypee Univ Engn & Technol, Dept CSE, Guna 473226, MP, India.
RP Tyagi, V (corresponding author), Jaypee Univ Engn & Technol, Dept CSE, Guna 473226, MP, India.
EM dr.vipin.tyagi@gmail.com
RI Tyagi, Vipin/I-2451-2013
OI Tyagi, Vipin/0000-0003-4994-3686
CR [Anonymous], 1992, Computer and Robot Vision, DOI DOI 10.1109/MRA.2011.941638
   Belongie C, 2002, IEEE T PATTERN ANAL, V24, P1026
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Jian M, 2015, IEEE T CIRC SYST VID, V25, P1761, DOI 10.1109/TCSVT.2015.2400772
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jian MW, 2014, SIGNAL PROCESS, V100, P9, DOI 10.1016/j.sigpro.2014.01.004
   Kanimozhi T, 2015, NEUROCOMPUTING, V151, P1099, DOI 10.1016/j.neucom.2014.07.078
   Karakasis EG, 2015, PATTERN RECOGN LETT, V55, P22, DOI 10.1016/j.patrec.2015.01.005
   Kimura M, 2006, IEEE T CONSUM ELECTR, V52, P312, DOI 10.1109/TCE.2006.1649643
   Lee J, 2011, ADV ELECTR COMPUT EN, V11, P85, DOI 10.4316/AECE.2011.03014
   Li J, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P754, DOI 10.1109/ICIP.2000.899564
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Moghaddam B, 2001, MULTIMED TOOLS APPL, V14, P201, DOI 10.1023/A:1011355417880
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Prasad BG, 2004, COMPUT VIS IMAGE UND, V94, P193, DOI 10.1016/j.cviu.2003.10.016
   Raghuwanshi G, 2016, ADV INTELL SYST, V381, P427, DOI 10.1007/978-81-322-2526-3_44
   Raghuwanshi G, 2016, DIGIT SIGNAL PROCESS, V48, P50, DOI 10.1016/j.dsp.2015.09.003
   Shrivastava N, 2015, ADV INTELL SYST COMP, V328, P509, DOI 10.1007/978-3-319-12012-6_56
   Shrivastava N, 2014, INFORM SCIENCES, V259, P212, DOI 10.1016/j.ins.2013.08.043
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   Vu K, 2003, IEEE T KNOWL DATA EN, V15, P1045, DOI 10.1109/TKDE.2003.1209021
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Wood M. E. J., 1998, Proceedings ACM Multimedia 98, P13, DOI 10.1145/290747.290750
NR 27
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 13741
EP 13759
DI 10.1007/s11042-016-3747-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800003
DA 2024-07-18
ER

PT J
AU Gadeski, E
   Le Borgne, H
   Popescu, A
AF Gadeski, Etienne
   Le Borgne, Herve
   Popescu, Adrian
TI Fast and robust duplicate image detection on the web
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media intelligence; Near duplicate detection; Copy detection;
   Visual web data; Image retrieval
AB Social media intelligence is interested in detecting the massive propagation of similar visual content. It can be seen, under certain conditions, as a problem of detecting near duplicate images in a stream of web data. However, in the context considered, it requires not only an efficient indexing and searching algorithm but also to be fast to compute the image description, since the total time of description and searching must be short enough to satisfy the constraint induced by the web stream flow rate. While most of methods of the state of the art focus on the efficiency at searching time, we propose a new descriptor satisfying the aforementioned requirements. We evaluate our method on two different datasets with the use of different sets of distractor images, leading to large-scale image collections (up to 100 million images). We compare our method to the state of the art and show it exhibits among the best detection performances but is much faster (one to two orders of magnitude).
C1 [Gadeski, Etienne; Le Borgne, Herve; Popescu, Adrian] CEA, Vis & Content Engn Lab, LIST, Gif Sur Yvette, France.
C3 Universite Paris Saclay; CEA
RP Le Borgne, H (corresponding author), CEA, Vis & Content Engn Lab, LIST, Gif Sur Yvette, France.
EM herve.le-borgne@cea.fr
CR [Anonymous], SIGIR WORKSH INF RET
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   BERRANI S.-A., 2003, Proceedings of the 1st ACM international workshop on Multimedia databases, P70, DOI DOI 10.1145/951676.951690
   Chang EY, 1998, P SOC PHOTO-OPT INS, V3527, P58, DOI 10.1117/12.325852
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Dohring I, 2009, CIVR
   Douze M, 2009, INT C IM VID RETR
   Douze M, 2010, IEEE T MULTIMEDIA, V12, P257, DOI 10.1109/TMM.2010.2046265
   Gadeski E, 2015, 13 INT WORKSH CONT B, P1
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Huang YZ, 2014, IEEE T PATTERN ANAL, V36, P493, DOI 10.1109/TPAMI.2013.113
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Joly A, 2007, IEEE T MULTIMEDIA, V9, P293, DOI 10.1109/TMM.2006.886278
   Kim BS, 2002, LECT NOTES COMPUT SC, V2613, P202
   Law-To Julien., 2007, P 6 ACM INT C IMAGE, P371
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Naturel X, 2005, P 2 INT WORKSH COMP, P21, DOI DOI 10.1145/1160939.1160947
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Razavian A. S., 2014, Workshop on IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2014), P806, DOI [10.1109/cvprw.2014.131, DOI 10.1109/CVPRW.2014.131]
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salakhutdinov R., 2007, PMLR, P412
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   Thomee B, 2013, EVALUATION CONTENT B, V2013
   Thomee B., 2010, P INT C MULTIMEDIA M, P1473
   Torralba A, 2008, PROC CVPR IEEE, P2269
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Williams C.K.I., PASCAL VISUAL OBJECT
   Xie L, 2011, P 19 ACM INT C MULT, P53, DOI DOI 10.1145/2072298.2072307
NR 37
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11839
EP 11858
DI 10.1007/s11042-016-3619-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000039
DA 2024-07-18
ER

PT J
AU Kumara, WGCW
   Yen, SH
   Hsu, HH
   Shih, TK
   Chang, WC
   Togootogtokh, E
AF Kumara, W. G. C. W.
   Yen, Shwu-Huey
   Hsu, Hui-Huang
   Shih, Timothy K.
   Chang, Wei-Chun
   Togootogtokh, Enkhtogtokh
TI Real-time 3D human objects rendering based on multiple camera details
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model; Virtual reality; Kinect; Point cloud; Registration
AB 3D model construction techniques using RGB-D information have been gaining a great attention of the researchers around the world in recent decades. The RGB-D sensor, Microsoft Kinect is widely used in many research fields, such as in computer vision, computer graphics, and human computer interaction, due to its capacity of providing color and depth information. This paper presents our research finding on calibrating information from several Kinects in order to construct a 3D model of a human object and to render texture captured from RGB camera. We used multiple Kinect sensors, which are interconnected in a network. High bit rate streams captured at each Kinect are first sent to a centralized PC for the processing. This even can be extended to a remote PC in the Internet. Main contributions of this work include calibration of the multiple Kinects, properly aligning point clouds generated from multiple Kinects, and generation of the 3D shape of the human objects. Experimental results demonstrate that the proposed method provides a better 3D model of the human object being captured.
C1 [Kumara, W. G. C. W.; Shih, Timothy K.; Chang, Wei-Chun; Togootogtokh, Enkhtogtokh] Natl Cent Univ, Dept Comp Sci & Informat Engn, MINE Lab, 300 Jhongda Rd, Jhongli 32001, Taoyuan County, Taiwan.
   [Yen, Shwu-Huey; Hsu, Hui-Huang] Tamkang Univ, Dept Comp Sci & Informat Engn, New Taipei, Taiwan.
C3 National Central University; Tamkang University
RP Shih, TK (corresponding author), Natl Cent Univ, Dept Comp Sci & Informat Engn, MINE Lab, 300 Jhongda Rd, Jhongli 32001, Taoyuan County, Taiwan.
EM chinthakawk@gmail.com; 105390@mail.tku.edu.tw; h_hsu@mail.tku.edu.tw;
   timothykshih@gmail.com; tuwulisu6110@hotmail.com;
   enkhtogtokh.java@gmail.com
RI Kumara, W. G. C. W./AAU-8923-2021
OI Kumara, W. G. C. W./0000-0002-4613-275X
CR Alexander O, 2009, 6 EUR C VIS MED PROD
   [Anonymous], CVPR 2011 WORKSHOPS, DOI DOI 10.1109/CVPRW.2011.5981811
   [Anonymous], CVPR
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Cappelletto E, 2016, MULTIMED TOOLS APPL, V75, P3631, DOI 10.1007/s11042-014-2065-4
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   Dayrit FL, 2017, MULTIMED TOOLS APPL, V76, P1291, DOI 10.1007/s11042-015-3116-1
   Essmaeel K, 2015, MULTIMED TOOLS APPL, V74, P7331, DOI 10.1007/s11042-014-1982-6
   Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016
   Gallup David, 2007, CVPR
   Geng N, 2016, MULTIMED TOOLS APPL, V75, P16763, DOI 10.1007/s11042-015-2941-6
   Goesele M., 2006, COMP VIS PATT REC 20, P2402, DOI DOI 10.1109/CVPR.2006.199
   Harris M., 2007, GPU GEMS, V3, P851
   Huhle Benjamin, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563158
   Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954
   Kutulakos KN, 2000, LECT NOTES COMPUT SC, V1842, P67
   Li X, 2015, J COMPUT INF SYST, V11, P27, DOI DOI 10.1016/J.TALANTA.2015.11.027
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Reisner-Kollmann I., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1120, DOI 10.1109/ICCVW.2011.6130375
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Seitz SM, 1999, INT J COMPUT VISION, V35, P151, DOI 10.1023/A:1008176507526
   Song W, 2016, MULTIMED TOOLS APPL, V75, P8569, DOI 10.1007/s11042-015-2772-5
   Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56
   Xu Hongyi, 2014, Proceedings of Graphics Interface 2014, P35
   Zabulis X, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P733, DOI 10.1109/TDPVT.2004.1335388
   Zhang L, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P24, DOI 10.1109/TDPVT.2002.1024035
NR 26
TC 9
Z9 11
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11687
EP 11713
DI 10.1007/s11042-016-3327-0
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000032
DA 2024-07-18
ER

PT J
AU Angeluci, ACB
   Calixto, GM
   Bevilaqua, LM
   Bernardini, G
   Gobbi, MC
AF Belo Angeluci, Alan Cesar
   Calixto, Gustavo Moreira
   Bevilaqua, Leire Mara
   Bernardini, Gleice
   Gobbi, Maria Cristina
TI QRcode, hashtag or audio watermark? A case study on second screening
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Second screen; TV; QRcode; Hashtag; Audio watermark; Content recognition
AB Combining television and a second, web-connected screen, is challenging both in technical and production content issues, as they can influence users' engagement with the content. The case study presented in this paper aims to discuss how the use of different content recognition techniques for TV set and mobile devices synchronization can impact for better or worse the users' interactive experience. From a triangulation method approach, using a prototype, quantitative and qualitative questionnaires and focus groups, user test sessions were carried out in order to collect perceptions and reactions from participants using variations of QRcode, hashtag and audio watermark markers when second screening. Data analysis showed that a key factor for a fruitful content recognition for dual screening is not only the seamless communication by itself, but the influence level of each specific characteristics of a marker, such as size of images, number of characters and noises.
C1 [Belo Angeluci, Alan Cesar] Univ Municipal Sao Caetano Sul, USCS, Programa Pos Graduacao Comunicacao, Rua Santo Antonio 50 Ctr, BR-09521160 Sao Caetano do Sul, SP, Brazil.
   [Calixto, Gustavo Moreira] Ctr Univ Senac Santo Amaro, Ave Engenheiro Eusebio Stevaux 823, BR-04696000 Santo Amaro, SP, Brazil.
   [Bevilaqua, Leire Mara] Televisao Univ UNESP, Rua Jacy Stevaux Villaca 2-99, BR-17047250 Bauru, SP, Brazil.
   [Bernardini, Gleice; Gobbi, Maria Cristina] Univ Estadual Paulista, UNESP, Programa Pos Graduacao Comunicacao, Ave Engenheiro Luiz Edmundo Carrijo Coube 14-01, BR-17047250 Bauru, SP, Brazil.
C3 Universidade Municipal de Sao Caetano do Sul; Centro Universitario
   Senac; Universidade Estadual Paulista
RP Angeluci, ACB (corresponding author), Univ Municipal Sao Caetano Sul, USCS, Programa Pos Graduacao Comunicacao, Rua Santo Antonio 50 Ctr, BR-09521160 Sao Caetano do Sul, SP, Brazil.
EM aangeluci@uscs.edu.br; gustavo.mcalixto@sp.senac.br; leire@tvu.unesp.br;
   gleicebernardini@hotmail.com; mcgobbi@faac.unesp.br
RI Angeluci, Alan/A-7454-2011; Gobbi, Maria Cristina/A-2365-2015;
   Bernardini, Gleice/N-1289-2014
OI Angeluci, Alan/0000-0002-4093-0590; Gobbi, Maria
   Cristina/0000-0001-5629-5010; Bernardini, Gleice/0000-0003-3122-0260
CR Angeluci ACB, 2013, REV GEMINIS, V1, P75
   [Anonymous], CONFRONTING CHALLENG
   Arnold M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1013, DOI 10.1109/ICME.2000.871531
   Boney L, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P473, DOI 10.1109/MMCS.1996.535015
   Brown A., 2014, Proceedings of Human Factors in Computing Systems Conference Extended Abstracts (CHI EA '14). ACM Press, P665
   Bruns Axel., 2008, BLOGS WIKIPEDIA 2 LI
   Caldas CHS, 2015, VERSO REVERSO, V29, P24
   Calixto G., 2014, PHARM DEV TECHNOL, V20, P1, DOI DOI 10.3109/10837450.2014.882941
   Cameron J, 2014, J BROADCAST ELECT ME, V58
   Das D., 2011, 2011 IEEE 15th International Symposium on Consumer Electronics, P397, DOI 10.1109/ISCE.2011.5973857
   Doughty M., 2012, P 10 EUR C INT TV VI, P79, DOI [DOI 10.1145/2325616.2325635, 10.1145/2325616.2325635]
   Doughty Mark., 2011, P 9 EUROPEAN C INTER, P141
   Duong N. Q. K., 2012, 2012 IEEE Second International Conference on Consumer Electronics - Berlin (ICCE-Berlin), P241, DOI 10.1109/ICCE-Berlin.2012.6336458
   Galindo Rubio Fernando, 2014, Cuad.inf., P159, DOI 10.7764/cdi.35.565
   Giglietto F, 2014, J COMMUN, V64, P260, DOI 10.1111/jcom.12085
   Hirsch E., 2003, Consuming technologies: Media and information in domestic spaces
   Holmes M.E., 2012, S EYE TRACKING RES A, P397, DOI DOI 10.1145/2168556.2168646
   Howson C., 2011, Proceedings of the 1st IEEE First International Conference on Consumer Electronics - Berlin (IEEE ICCE-Berlin 2011), P361, DOI 10.1109/ICCE-Berlin.2011.6031815
   Katz E., 1999, Sources notable selections in mass media, P51
   Lemma A, 2008, 2008 2 INT C EL ENG
   Wohn D.Y., 2011, 1 MONDAY, V16
   Ziegler C, 2013, P IEEE 3 INT C CONS, P1
NR 22
TC 1
Z9 1
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7519
EP 7534
DI 10.1007/s11042-016-3417-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400063
DA 2024-07-18
ER

PT J
AU Chakraborty, S
   Jalal, AS
   Bhatnagar, C
AF Chakraborty, Soumendu
   Jalal, Anand Singh
   Bhatnagar, Charul
TI LSB based non blind predictive edge adaptive image steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Edge adaptive; High level bit plane; Low level bit plane; Predictive
   image
ID ALGORITHM
AB Image steganography is the art of hiding secret message in grayscale or color images. Easy detection of secret message for any state-of-art image steganography can break the stego system. To prevent the breakdown of the stego system data is embedded in the selected area of an image which reduces the probability of detection. Most of the existing adaptive image steganography techniques achieve low embedding capacity. In this paper a high capacity Predictive Edge Adaptive image steganography technique is proposed where selective area of cover image is predicted using Modified Median Edge Detector (MMED) predictor to embed the binary payload (data). The cover image used to embed the payload is a grayscale image. Experimental results show that the proposed scheme achieves better embedding capacity with minimum level of distortion and higher level of security. The proposed scheme is compared with the existing image steganography schemes. Results show that the proposed scheme achieves better embedding rate with lower level of distortion.
C1 [Chakraborty, Soumendu] Indian Inst Informat Technol, Dept Informat Technol, Allahabad, Uttar Pradesh, India.
   [Jalal, Anand Singh; Bhatnagar, Charul] GLA Univ, Dept Comp Engn & Applicat, Mathura, UP, India.
C3 Indian Institute of Information Technology Allahabad; GLA University
RP Chakraborty, S (corresponding author), Indian Inst Informat Technol, Dept Informat Technol, Allahabad, Uttar Pradesh, India.
EM soum.uit@gmail.com; anandsinghjalal@gmail.com; charul@gla.ac.in
RI Chakraborty, Soumendu/ABA-2031-2020
OI Chakraborty, Soumendu/0000-0002-8778-8229; Jalal,
   Anand/0000-0002-7469-6608
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Böhme R, 2010, ADVANCED STATISTICAL STEGANALYSIS, P11
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Farid H, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P905
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Harmsen JJ, 2003, PROC SPIE, V5020, P131, DOI 10.1117/12.476813
   HEMPSTALK K, 2006, COMP WOM C P HAM NZ
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   Huang FJ, 2007, IEEE IMAGE PROC, P401
   Huang FJ, 2014, LECT NOTES COMPUT SC, V8389, P19, DOI 10.1007/978-3-662-43886-2_2
   Hwang J, 2006, LECT NOTES COMPUT SC, V4283, P348
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Khosravi MJ, 2014, MULTIMEDIA SYST, V20, P215, DOI 10.1007/s00530-013-0341-1
   Kim KS, 2009, PATTERN RECOGN, V42, P3083, DOI 10.1016/j.patcog.2009.04.004
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Luo WQ, 2011, MULTIMED TOOLS APPL, V52, P407, DOI 10.1007/s11042-009-0440-3
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Luo XY, 2008, SIGNAL PROCESS, V88, P2138, DOI 10.1016/j.sigpro.2008.03.016
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou DH, 2015, MULTIMED TOOLS APPL, V74, P9117, DOI 10.1007/s11042-014-2059-2
   Roy R, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTING, MANAGEMENT AND TELECOMMUNICATIONS (COMMANTEL), P309, DOI 10.1109/ComManTel.2013.6482411
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Ulutas G., 2012, INT J INTERNET TECHN, V4, P1
   VETTERLI M, 1987, IEEE T ACOUST SPEECH, V35, P356, DOI 10.1109/TASSP.1987.1165137
   WALTON S, 1995, DR DOBBS J, V20, P18
   Wu HC, 2010, DISPLAYS, V31, P35, DOI 10.1016/j.displa.2009.10.002
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
NR 33
TC 44
Z9 45
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 7973
EP 7987
DI 10.1007/s11042-016-3449-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800017
DA 2024-07-18
ER

PT J
AU Kim, SM
   Jung, ES
   Park, J
AF Kim, Seong M.
   Jung, Eui S.
   Park, Jaekyu
TI Effective quality factors of multimodal interaction in simple and
   complex tasks of using a smart television
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal interaction; User interface; Smart television; Quality
   factors
ID HUMAN-COMPUTER INTERACTION; INTERFACES; TV; SYSTEM
AB Influencing quality factors, related to the user and system, need to be considered when building a well-designed multimodal interaction system. User groups, access to input modes and tasks were defined as the user and system factors to examine effective factors of multimodal interaction with a smart TV, and its input modes consisted of voice, arrow key, and motion-based pointer modes and their combinations. User group 1 had experience of multimodal interaction with another device, while user group 2 had only experience of unimodal interaction. In addition, the sequential/simultaneous input modes and simple/complex tasks were considered as the system factors. Depending on the task complexity, two experiments were conducted. Nine input modes (three unimodes and six multimodes), sequentially and simultaneously given to both user groups, were investigated for the simple task of menu traversal and the complex task of manipulating broadcasting content, menu traversal, and web content navigation. A subjective rating of the level of preference was recorded in the sequential input mode using a modified Likert-type rating scale, while each participant's preferred mode was observed in the simultaneous scenario. Additionally, the completion time and error rate were measured in both experiments. When performing the simple task, user group 1 used multimodes more so than group 2. However, in the complex task, both user groups preferred multimodes when modes were simultaneously presented. Considering effective quality factors, input modes of a smart TV should be simultaneously provided with a voice and motion-based pointer multimode.
C1 [Kim, Seong M.; Jung, Eui S.; Park, Jaekyu] Korea Univ, Dept Ind Management Engn, Anam Ro, Seoul 02841, South Korea.
C3 Korea University
RP Jung, ES (corresponding author), Korea Univ, Dept Ind Management Engn, Anam Ro, Seoul 02841, South Korea.
EM ejung@korea.ac.kr
OI Park, Jaekyu/0000-0003-0065-9318
FU Korea University
FX This research was supported by a Korea University grant.
CR Alepis E, 2012, MULTIMED TOOLS APPL, V59, P41, DOI 10.1007/s11042-011-0744-y
   [Anonymous], 2010, FOUND TRENDS HUM COM
   [Anonymous], SPOKEN MULTILINGUAL
   [Anonymous], IEEE ICCE
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Bangalore S, 2009, COMPUT LINGUIST, V35, P345, DOI 10.1162/coli.08-022-R2-06-26
   Barthelmess P, 2008, MORG KAUF SER INTER, P391, DOI 10.1016/B978-0-12-374017-5.00012-2
   Bellik Y, 2009, LECT NOTES COMPUT SC, V5727, P89, DOI 10.1007/978-3-642-03658-3_13
   Chbeir R, 2011, MULTIMED TOOLS APPL, V54, P1, DOI 10.1007/s11042-010-0543-x
   Chen F., 2012, ACM T INTERACT INTEL, V2, P1, DOI DOI 10.1145/2395123.2395127
   Chittaro L, 2010, J MULTIMODAL USER IN, V3, P157, DOI 10.1007/s12193-010-0036-2
   Dumas B, 2009, LECT NOTES COMPUT SC, V5440, P3, DOI 10.1007/978-3-642-00437-7_1
   Dumas J.S., 2008, The Human-Computer Interaction Handbook, Vsecond, P1129
   Elouali N, 2013, J MULTIMODAL USER IN, V7, P351, DOI 10.1007/s12193-013-0126-z
   Gürkök H, 2012, INT J HUM-COMPUT INT, V28, P292, DOI 10.1080/10447318.2011.582022
   Herrera-Acuña R, 2015, J MULTIMODAL USER IN, V9, P121, DOI 10.1007/s12193-014-0173-0
   Hornbæk K, 2006, INT J HUM-COMPUT ST, V64, P79, DOI 10.1016/j.ijhcs.2005.06.002
   Hürst W, 2013, MULTIMED TOOLS APPL, V62, P233, DOI 10.1007/s11042-011-0983-y
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   유정일, 2013, [Journal of the ergonomics society of Korea, 대한인간공학회지], V32, P517
   Karray F, 2008, INT J SMART SENS INT, V1, P137, DOI 10.21307/ijssis-2017-283
   König WA, 2010, J MULTIMODAL USER IN, V3, P197, DOI 10.1007/s12193-010-0044-2
   Lee MK, 2014, J APPL MATH, DOI 10.1155/2014/784386
   Lee WP, 2014, KNOWL-BASED SYST, V56, P167, DOI 10.1016/j.knosys.2013.11.007
   Li BF, 2012, INT J IND ERGONOM, V42, P156, DOI 10.1016/j.ergon.2011.10.003
   Liu SF, 2016, MULTIMED TOOLS APPL, V75, P6143, DOI 10.1007/s11042-015-2564-y
   Möller S, 2010, HUMAN-CENTRIC INTERFACES FOR AMBIENT INTELLIGENCE, P347, DOI 10.1016/B978-0-12-374708-2.00014-0
   Moller A, 2014, P MENSCH COMP INT UN, P355
   Nogueira PA, 2015, J MULTIMODAL USER IN, V9, P105, DOI 10.1007/s12193-014-0172-1
   Osafo-Yeboah B, 2013, INT J IND ERGONOM, V43, P197, DOI 10.1016/j.ergon.2013.02.005
   Oviatt S, 2003, IEEE COMPUT GRAPH, V23, P62, DOI 10.1109/MCG.2003.1231179
   Oviatt S, 1999, COMMUN ACM, V42, P74, DOI 10.1145/319382.319398
   Oviatt S, 2000, COMMUN ACM, V43, P45, DOI 10.1145/330534.330538
   Oviatt S., 2004, P 6 INT C MULT INT, P129, DOI DOI 10.1145/1027933.1027957
   Oviatt S., 2006, Proc. 14th Annu. ACM Int. Conf. Multimed.-Multimed. '06, P871, DOI [10.1145/1180639.1180831, DOI 10.1145/1180639.1180831]
   Oviatt Sharon., 2003, Proc. of the 5th International Conference on Multimodal Interfaces - ICMI'03, P44
   OVIATT SL, 2003, P ACM S US INT SOFTW, P21
   Plimmer B, 2008, J MULTIMODAL USER IN, V2, P13, DOI 10.1007/s12193-008-0002-4
   Ratzka Andreas, 2013, Transactions on Pattern Languages of Programming III, P111, DOI 10.1007/978-3-642-38676-3_4
   Reeves LM, 2004, COMMUN ACM, V47, P57, DOI 10.1145/962081.962106
   SAKAMOTO K., 2009, COMM 2009 ICC 09 IEE, P1
   Schüssel F, 2013, J MULTIMODAL USER IN, V7, P299, DOI 10.1007/s12193-012-0117-5
   Sheu JS, 2016, MULTIMED TOOLS APPL, V75, P9685, DOI 10.1007/s11042-015-2739-6
   Shin DH, 2013, BEHAV INFORM TECHNOL, V32, P156, DOI 10.1080/0144929X.2011.603360
   Soysal M, 2014, MULTIMED TOOLS APPL, V72, P2787, DOI 10.1007/s11042-013-1564-z
   Wechsung I, 2012, J MULTIMODAL USER IN, V6, P73, DOI 10.1007/s12193-011-0088-y
   Wickens C. D., 2002, Theor Issues Ergon Sci, V3, P159, DOI [10.1080/14639220210123806, DOI 10.1080/14639220210123806]
   WICKENS CD, 1983, HUM FACTORS, V25, P227, DOI 10.1177/001872088302500209
   Wickens CD, 2008, HUM FACTORS, V50, P397, DOI 10.1518/001872008X288420
   Xie L, 2014, MULTIMED TOOLS APPL, V73, P267, DOI 10.1007/s11042-013-1748-6
NR 50
TC 0
Z9 0
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6447
EP 6471
DI 10.1007/s11042-016-3333-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400017
DA 2024-07-18
ER

PT J
AU Sharif, A
   Mollaeefar, M
   Nazari, M
AF Sharif, Ami
   Mollaeefar, Majid
   Nazari, Mahboubeh
TI A novel method for digital image steganography based on a new
   three-dimensional chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information hiding; LSBs; 3-dimensional chaotic map; Statistical
   analysis; Imperceptibilty
ID ALGORITHM
AB This paper, presents a novel chaos-based image steganography algorithm. Because of efficient property of chaos based security systems besides steganography applicability in providing secure communication, chaos based steganography algorithms served as a hot topic in recent researches. The proposed scheme possess novelties and advantageous such as: 1) Introducing a novel 3-dimensional chaotic map (LCA map) with strong chaotic characteristics and maximum Lyapunov exponent 20.58, which is used for generating three chaotic sequences, each of them represents the number of row, column, and colour component, respectively. 2) Utilizing random selection procedure for selecting subsequences with length of 2L, which L is the length of secret message 3) Specifying L pairs of triples host positions for embedding LSBs and MSBs of secret message by using three high level chaotic maps. 4) Entering some parameters dependent on elementary initial values, host image, and secret message features as a key point for adding additional layer of security alongside providing high sensitivity. 5) Providing high capacity for embedding secret message, which is equal to 50 % of whole image capacity (MxNx12). The proposed method could be applied in different criterion such as, confidential communication and data storing, protection of data alteration, and etc. Our experimental results guarantees that our scheme is not only robust against differential attacks, but also has promising results such as highly sensitive keys, Quality index, PSNR, MSE, and hiding capacity as shown in statistical security analysis.
C1 [Sharif, Ami; Mollaeefar, Majid] Int Univ Imam Reza, Dept Comp & Informat Technol, Mashhad, Iran.
   [Nazari, Mahboubeh] Ferdowsi Univ Mashhad, Dept Math, Mashhad, Iran.
C3 Ferdowsi University Mashhad
RP Mollaeefar, M (corresponding author), Int Univ Imam Reza, Dept Comp & Informat Technol, Mashhad, Iran.
EM amir-sharif@hotmail.com; majid.mollaeefar@gmail.com;
   ma.am.math@gmail.com
RI Sharif, Amir/Y-7447-2019
OI Sharif, Amir/0000-0001-6290-3588; /0000-0002-0277-3029
CR Alam S, 2014, INT C ADV COMPUT COM, P85, DOI 10.1109/ACCT.2014.72
   Anees A, 2014, NONLINEAR DYNAM, V75, P807, DOI 10.1007/s11071-013-1105-3
   Arshad H, 2016, MULTIMED TOOLS APPL, V75, P181, DOI 10.1007/s11042-014-2282-x
   Arshad H, 2015, J SUPERCOMPUT, V71, P3163, DOI 10.1007/s11227-015-1434-8
   Arshad H, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0259-6
   Arshad H, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0136-8
   Aziz M, 2015, NONLINEAR DYNAM, V80, P1271, DOI 10.1007/s11071-015-1943-2
   Bandyopadhyay D., 2014, Int J Secur Priv Trust Manage (IJSPTM), V3, P11, DOI [10.5121/ijsptm.2014.3102, DOI 10.5121/IJSPTM.2014.3102]
   Bilal M, 2014, MULTIMED TOOLS APPL, V72, P1073, DOI 10.1007/s11042-013-1415-y
   Das P., 2014, INT C EL COMM SYST I, P1, DOI DOI 10.1109/ICECI.2014.6767371
   Ghebleh M, 2014, COMMUN NONLINEAR SCI, V19, P1898, DOI 10.1016/j.cnsns.2013.10.014
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Judge J.C., 2001, Steganography: Past, Present, Future
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P3287, DOI 10.1016/j.cnsns.2011.12.012
   Mollaeefar M, 2015, MULTIMEDIA TOOLS APP, V1-23
   Potdar VM, 2005, 2005 3RD IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS (INDIN), P717
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Provos N., 2001, Detecting steganographic content on the internet
   Roy R, 2013, PROC TECH, V10, P138, DOI 10.1016/j.protcy.2013.12.346
   Sabery M, 2008, 2008 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER THEORY AND ENGINEERING, P623, DOI 10.1109/ICACTE.2008.178
   Shirali-Shahreza M. H., 2006, IEEEACIS INT C COMPU, P310
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
NR 23
TC 28
Z9 30
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 7849
EP 7867
DI 10.1007/s11042-016-3398-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800012
DA 2024-07-18
ER

PT J
AU Singh, P
   Agarwal, S
AF Singh, Priyanka
   Agarwal, Suneeta
TI A self recoverable dual watermarking scheme for copyright protection and
   integrity verification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Self recoverable; Dual watermarking; Copyright protection; Integrity
   verification; Normalized cross correlation (NCC); Probability of false
   rejection (PFR); Probability of false acceptance (PFA); Peak signal to
   noise ratio (PSNR)
ID ROBUST IMAGE WATERMARKING; VISUAL-CRYPTOGRAPHY; TAMPER DETECTION;
   DIGITAL IMAGE; WAVELET; TRANSFORM; AUTHENTICATION; CHAOS
AB Dual watermarking implies embedding of robust as well as fragile watermarks into the same cover image. It facilitates integration of copyright protection and integrity verification into the same scheme. However, most of such existing state of art approaches either lacked the feature of tamper detection and original content recovery or provided an approximation using coarser block level approach. The proposed self recoverable dual watermarking scheme integrates all the aforementioned functionalities of copyright protection, tamper detection and recovery into one scheme. The scheme is independent of the order of embedding of robust and fragile watermarks as these are embedded in different regions of the cover image. It performs tamper detection and recovery, both at the pixel level. The scheme obtains recovery information for each 2x2 image block in just eight bits which are further encoded to only four bits via mapping table. This reduction in recovery bits allows efficient embedding of copyright information which is tested against comprehensive set of attacks. The scheme is found to be robust against noises, filtering, histogram equalization, rotation, jpeg compression, motion blur etc. Besides the normalized cross correlation value, the evaluation of the extracted copyright information is also being done using various objective error metrics based on mutual relation between pixels, their values and locations respectively. The imperceptibility and visual quality of the watermarked as well as recovered image is found to be satisfactorily high. Three major categories of images: natural, texture as well as satellite have been tested in the proposed scheme. Even minute alterations can be chalked out as the detection accuracy rate has been enumerated on pixel basis. The scheme can tolerate tampering ratios upto 50 percent though the visual quality of the recovered image deteriorates with increasing tampering ratio. Comparative results based on normalized cross correlation, probability of false acceptance, probability of false rejection and peak signal to noise ratio metrics validate the efficacy of the proposed scheme over other existing state of art approaches.
C1 [Singh, Priyanka; Agarwal, Suneeta] Motilal Nehru Natl Inst Technol, Allahabad, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Singh, P (corresponding author), Motilal Nehru Natl Inst Technol, Allahabad, Uttar Pradesh, India.
EM priyankaap@gmail.com; suneeta@mnnit.ac.in
RI Singh, Priyanka/N-1372-2018; Singh, Priyanka/GRF-6098-2022; singh,
   priyanka/JWP-2636-2024
OI Singh, Priyanka/0000-0003-0841-1544; Singh,
   Priyanka/0000-0001-7874-7778; SINGH, PRIYANKA/0000-0001-5002-8800
CR Agreste S, 2008, J COMPUT APPL MATH, V221, P274, DOI 10.1016/j.cam.2007.10.057
   Chamlawi R, 2010, INFORM SCIENCES, V180, P4909, DOI 10.1016/j.ins.2010.08.039
   Chemak C, 2007, P 2007 SUMM COMP SIM, P1201
   Chen BJ, 2014, DIGIT SIGNAL PROCESS, V28, P106, DOI 10.1016/j.dsp.2014.02.010
   Chen F, 2014, MULTIMED TOOLS APPL, V72, P41, DOI 10.1007/s11042-012-1332-5
   Cox I., 2001, Digital Watermarking
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Farfoura ME, 2012, EXPERT SYST APPL, V39, P3185, DOI 10.1016/j.eswa.2011.09.005
   Feng LP, 2010, INT CONF COMP SCI, P455, DOI 10.1109/ICCSIT.2010.5565101
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Guo J, 2007, OPT COMMUN, V272, P344, DOI 10.1016/j.optcom.2006.11.034
   Habib M, 2005, LECT NOTES ARTIF INT, V3682, P548
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   He HJ, 2008, IHW, P137
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P2469, DOI 10.1007/s11042-013-1561-2
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Hsia CH, 2014, SIGNAL PROCESS, V96, P138, DOI 10.1016/j.sigpro.2013.09.007
   Hsu CS, 2005, OPT ENG, V44, DOI 10.1117/1.1951647
   Huo YR, 2012, OPT COMMUN, V285, P1759, DOI 10.1016/j.optcom.2011.12.044
   Katzenbeisser SC, 2000, ART H COMP SCI LIBR, P17
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Li C, 2014, MULTIMED TOOLS APPL, P1380
   Li CL, 2012, COMPUT STAND INTER, V34, P367, DOI 10.1016/j.csi.2012.01.003
   Li GB, 2009, INT C COMP SUPP COOP, P107, DOI 10.1109/CSCWD.2009.4968043
   Li QH, 2013, OPTIK, V124, P1836, DOI 10.1016/j.ijleo.2012.05.045
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lu Haiping, 2004, IEEE SIGNAL PROCESSI, V11
   Mohan B. Chandra, 2008, Journal of Multimedia, V3, P7, DOI 10.4304/jmm.3.1.7-15
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Niu SZ, 2009, J COMPUT RES DEV, V46, P6
   Peng ZN, 2008, CHAOS SOLITON FRACT, V36, P946, DOI 10.1016/j.chaos.2006.07.015
   Phadikar A, 2012, J VIS COMMUN IMAGE R, V23, P454, DOI 10.1016/j.jvcir.2012.01.005
   Rawat S, 2011, INT J IMAGE GRAPH, V11, P471, DOI 10.1142/S0219467811004263
   Rawat S, 2013, INT J SIGNAL IMAGING, V6, P158, DOI 10.1504/IJSISE.2013.054794
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Singh P, 2016, MULTIMED TOOLS APPL, V75, P8165, DOI 10.1007/s11042-015-2736-9
   Tsai MJ, 2008, OPT ENG, V47, DOI 10.1117/1.2947580
   Wang MS, 2009, COMPUT STAND INTER, V31, P757, DOI 10.1016/j.csi.2008.09.003
   Young DP, 2005, P 2 JOINT IEEE INT C
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
NR 43
TC 16
Z9 16
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6389
EP 6428
DI 10.1007/s11042-015-3198-9
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400015
DA 2024-07-18
ER

PT J
AU Liu, SA
   Fu, WN
   He, LQ
   Zhou, JT
   Ma, M
AF Liu, Shuai
   Fu, Weina
   He, Liqiang
   Zhou, Jiantao
   Ma, Ming
TI Distribution of primary additional errors in fractal encoding method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enoding; Fractal encoding; Primary additional error; Distribution;
   Edge
ID WAVELET TRANSFORM; COMPRESSION; SEARCH; IMAGES
AB Today, fractal image encoding method becomes an effective loss compression method in multimedia without resolution, and its negativeness is that its high computational complexity. So many approximate methods are given to decrease the computation time. So the distribution of error points is valued to research. In this paper, by extracted primary additional error values, we first present a novel fast fractal encoding method. Then, with the extracted primary additional error values,we abstract the distribution of these values.We find that the different distribution of values denotes the different parts in images. Finally, we analyze the experimental results and find some properties of these values.The experimental results also show the effectiveness of the method.
C1 [Liu, Shuai; Fu, Weina; He, Liqiang; Zhou, Jiantao; Ma, Ming] Inner Mongolia Univ, Coll Comp Sci, Hohhot 010012, Peoples R China.
   [Liu, Shuai] Inner Mongolia Univ, Sch Phys Sci & Technol, Hohhot 010012, Peoples R China.
   [He, Liqiang] Inner Mongolia Univ, Room A311,Comp Bldg,235 Western Univ St, Hohhot 010012, Peoples R China.
C3 Inner Mongolia University; Inner Mongolia University; Inner Mongolia
   University
RP He, LQ (corresponding author), Inner Mongolia Univ, Room A311,Comp Bldg,235 Western Univ St, Hohhot 010012, Peoples R China.
EM Cs_liushuai@imu.edu.cn; Wn_fu@sohu.com; liqiang@imu.edu.cn;
   cszjtao@imu.edu.cn; csmaming@imu.edu.cn
RI Liu, Shuai/AAX-1239-2021; Liu, Shuai/P-3939-2017; Liu,
   Shuai/AAB-1960-2019; Fu, Weina/AAF-5699-2020
OI Liu, Shuai/0000-0001-9909-0664; Liu, Shuai/0000-0001-9909-0664; 
FU Postgraduate Scientific Research Innovation Foundation of Inner Mongolia
   [B20141012610Z]; Higher-level talents of Inner Mongolia University
   [125126, 115117, 135103]; higher school of Inner Mongolia [NJZY13004];
   Natural Science Foundation of Inner Mongolia [2014BS0606, 2014BS0602];
   National Natural Science Foundation of China [61261019, 61262082]
FX This work is supported by Grants Postgraduate Scientific Research
   Innovation Foundation of Inner Mongolia [B20141012610Z], Programs of
   Higher-level talents of Inner Mongolia University [No. 125126, 115117,
   135103], Scientific projects of higher school of Inner Mongolia [No.
   NJZY13004], Natural Science Foundation of Inner Mongolia [No.
   2014BS0606, 2014BS0602], National Natural Science Foundation of China
   [No. 61261019, 61262082].
CR [Anonymous], 1980, FIXED POINT THEOREMS
   BARNSLEY MF, 1988, P SOC PHOTO-OPT INS, V1001, P122
   BEDFORD T, 1994, SIGNAL PROCESS-IMAGE, V6, P405, DOI 10.1016/0923-5965(94)90003-5
   Belloulata K, 2005, J VIS COMMUN IMAGE R, V16, P55, DOI 10.1016/j.jvcir.2004.02.001
   Bhavani S, 2013, IET IMAGE PROCESS, V7, P686, DOI 10.1049/iet-ipr.2012.0041
   Chang HT, 2000, IEEE T IMAGE PROCESS, V9, P329, DOI 10.1109/83.826772
   Falconer K., 2003, FRACTAL GEOMETRY MAT, V2, DOI DOI 10.1002/0470013850
   GOEBEL K, 1972, P AM MATH SOC, V35, P171, DOI 10.2307/2038462
   He JR, 2014, PHYS REV E, V90, DOI 10.1103/PhysRevE.90.013202
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Ilday FO, 2004, PHYS REV LETT, V92, DOI 10.1103/PhysRevLett.92.213902
   Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028
   Kim CS, 1998, IEEE T IMAGE PROCESS, V7, P601, DOI 10.1109/83.663508
   Kim IK, 1996, IEEE T IMAGE PROCESS, V5, P587, DOI 10.1109/83.491335
   Lai CM, 2003, IEEE T IMAGE PROCESS, V12, P1398, DOI 10.1109/TIP.2003.817246
   Li JL, 2002, IEEE T IMAGE PROCESS, V11, P636, DOI 10.1109/TIP.2002.1014995
   Liu M, 2014, CHINESE J ELECT
   Liu S, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/503924
   Liu S, 2013, INT J DISTRIB SENS N, DOI 10.1155/2013/281707
   Liu S, 2013, APPL MATH COMPUT, V220, P668, DOI 10.1016/j.amc.2013.06.096
   Lu J, 2013, IEEE T IMAGE PROCESS, V22, P134, DOI 10.1109/TIP.2012.2215619
   Mandelbrot B. B., 1982, FRACTAL GEOMETRY NAT
   MONRO DM, 1992, ELECTRON LETT, V28, P1053, DOI 10.1049/el:19920667
   PRESS WH, 1974, ASTROPHYS J, V187, P425, DOI 10.1086/152650
   Rao K.R, 2014, DISCRETE COSINE TRAN
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Turaga DS, 2004, SIGNAL PROCESS-IMAGE, V19, P173, DOI 10.1016/j.image.2003.09.001
   Wang XY, 2008, COMPUT GRAPH-UK, V32, P445, DOI 10.1016/j.cag.2008.02.004
   Wang XY, 2014, NONLINEAR DYNAM, V75, P439, DOI 10.1007/s11071-013-1076-4
   Wang XY, 2010, IMAGE VISION COMPUT, V28, P1303, DOI 10.1016/j.imavis.2010.01.008
   Yang GL, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/398583
   Zhang Y, 2012, NONLINEAR ANAL-REAL, V13, P106, DOI 10.1016/j.nonrwa.2011.07.017
NR 32
TC 103
Z9 105
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5787
EP 5802
DI 10.1007/s11042-014-2408-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500048
DA 2024-07-18
ER

PT J
AU Singh, S
   Rathore, VS
   Singh, R
AF Singh, Siddharth
   Rathore, Vivek Singh
   Singh, Rajiv
TI Hybrid NSCT domain multiple watermarking for medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image watermarking; Nonsubsampled contourlet transform; Singular
   value decomposition; Discrete cosine transform; Hybrid medical image
   watermarking
ID IMPERCEPTIBLE DUAL WATERMARKING; REVERSIBLE WATERMARKING; ROBUST;
   SCHEME; TRANSFORM; ALGORITHM; SECURITY
AB Medical image watermarking is a challenging area of research. High bandwidth, secure transmission of patient's data among hospitals and hiding capacity are major concerns in medical image watermarking. Recently, wavelet transforms and their hybrid combinations have been widely used for this purpose. The conventional wavelet transforms suffer from shift sensitivity and have low hiding capacity. Therefore, the performance of hybrid combinations of wavelet transforms for image watermarking is limited. The shortcomings of wavelet transforms can be overcome with the use of Nonsubsampled contourlet transform (NSCT) which is shift invariant in nature and provides rich directional information. For these reasons, in this work we propose NSCT based technique for medical image watermarking which combines discrete cosine transform (DCT) along with Multiresolution Singular value decomposition (MSVD) and Arnold transform in order to increase robustness, capacity and imperceptibility. In the proposed work, multiple (three) image watermarks have been used for a single cover medical image. We have embedded three image watermarks into NSCT coefficients of the cover image. Among which two of them are image watermarks and third is encrypted text watermark. By using NSCT, embedding capacity has been increased and it becomes more resistant to geometrical attacks. Also, hybrid combination of NSCT with DCT, MSVD and Arnold transform increases the perceptual quality and security of watermarked image. Experimental results showed that the proposed method provides high robustness against attacks like JPEG compression, Rotation, Resizing, noise, Blurring and found better than existing hybrid methods for medical image watermarking.
C1 [Singh, Siddharth; Rathore, Vivek Singh] Natl Inst Technol, Dept Elect & Commun Engn, Delhi, India.
   [Singh, Rajiv] Banasthali Univ, Dept Comp Sci, Vanasthali, Rajasthan, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Delhi; Banasthali Vidyapith
RP Singh, S; Rathore, VS (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Delhi, India.; Singh, R (corresponding author), Banasthali Univ, Dept Comp Sci, Vanasthali, Rajasthan, India.
EM siddharthjnp@gmail.com; singhrathorevivek1@gmail.com;
   jkrajivsingh@gmail.com
RI Singh/AAK-2624-2020; Singh, Rajiv/H-2377-2014
OI Singh, Rajiv/0000-0003-4022-9945
CR Al-Haj Ali, 2007, Journal of Computer Sciences, V3, P740, DOI 10.3844/jcssp.2007.740.746
   [Anonymous], INT J COMPUT APPL
   [Anonymous], STAT SIGN PROC 2003
   [Anonymous], 2013, IOSR J COMPUTER ENG
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2012, CHOICE WAVELET WAVEL
   [Anonymous], INFORM SECURITY DIVE
   Arsalan M, 2012, J SYST SOFTWARE, V85, P883, DOI 10.1016/j.jss.2011.11.005
   Bhatnagar G, 2015, MULTIMED TOOLS APPL, V74, P8421, DOI 10.1007/s11042-013-1681-8
   Cao F, 2003, COMPUT MED IMAG GRAP, V27, P185, DOI 10.1016/S0895-6111(02)00073-3
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen J.M., 2013, Adv. Inf. Sci. Serv. Sci, V5, P629
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Das S, 2011, LECT NOTES COMPUT SC, V6744, P286
   Kakarala R, 2001, IEEE T IMAGE PROCESS, V10, P724, DOI 10.1109/83.918566
   Khalighi S, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/540723
   Kutter M, 1999, PROC SPIE, V3657, P226, DOI 10.1117/12.344672
   Lei BY, 2014, EXPERT SYST APPL, V41, P3178, DOI 10.1016/j.eswa.2013.11.019
   Mohanty S. P., 1999, P 7 ACM INT C MUL OC, P49
   Mousavi SM, 2014, J DIGIT IMAGING, V27, P714, DOI 10.1007/s10278-014-9700-5
   Nyeem H, 2013, J DIGIT IMAGING, V26, P326, DOI 10.1007/s10278-012-9527-x
   Pandey P, 2014, MULTIMED TOOLS APPL, V72, P723, DOI 10.1007/s11042-013-1375-2
   Po DDY, 2003, PROCEEDINGS OF THE 2003 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING, P262
   Rahimi F, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-53
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Sheppard N., 2001, WORKSHOP SECURITY MU, P3
   Singh A., 2016, Microscale Technologies for Cell Engineering, DOI [10.1007/978-3-319-20726-1, DOI 10.1007/978-3-319-20726-1, DOI 10.1007/S11042015-27547]
   Singh A. K., 2016, MULTIMED TOOL APPL, P1
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2014, INT J ELECTRON SECUR, V6, P285, DOI 10.1504/IJESDF.2014.065739
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh AK, 2014, P NATL A SCI INDIA A, V84, P345, DOI 10.1007/s40010-014-0140-x
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Singh S, 2012, IJCSI, V9, P131
   Thabit R., 2015, MULTIMED TOOL APPL, P1
   Ulutas M, 2011, J SYST SOFTWARE, V84, P341, DOI 10.1016/j.jss.2010.11.928
   Zhenjun Tang, 2011, Journal of Multimedia, V6, P202, DOI 10.4304/jmm.6.2.202-206
NR 38
TC 23
Z9 24
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3557
EP 3575
DI 10.1007/s11042-016-3885-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200020
DA 2024-07-18
ER

PT J
AU Lee, MF
   Chen, GS
   Hung, J
   Lin, KC
   Wang, JC
AF Lee, Min-Feng
   Chen, Guey-Shya
   Hung, Jason C.
   Lin, Kuan-Cheng
   Wang, Jen-Chieh
TI Data mining in emotion color with affective computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data mining; Affective computing; FCM; Neural network; Detecting
   emotion; Color; Emotion classification
ID BACKPROPAGATION NEURAL-NETWORK; GENETIC ALGORITHM; PREDICTION;
   OPTIMIZATION
AB This research applies an innovative way to measure and identify user's emotion with different ingredient color. How to find an intuitive way to understand human emotion is the key point in this research. The RGB color system that is widely used of all forms computer system is an accumulative color system in which red, green, and blue light are added together showing entire color. This study was based on Thayer's emotion model which classifies the emotions with two vectors, valence and arousal, and gathers the emotion color with RGB as input for calculating and forecasting user's emotion. In this experiment, using 320 data divide to quarter into emotion groups to train the weight in the neural network and uses 160 data to prove the accuracy. The result reveals that this model can be valid reckon the emotion by reply color response from user. In other hand, this experiment found that trend of the different ingredient of color on Cartesian coordinate system figures out the distinguishing intensity in RGB color system. Via the foregoing detect emotion model is going to design an affective computing intelligence framework try to embed the emotion component in it.
C1 [Lee, Min-Feng; Chen, Guey-Shya] Natl Taichung Univ Educ Taichung, Grad Inst Educ Measurement & Stat, Taichung, Taiwan.
   [Hung, Jason C.] Overseas Chinese Univ Taichung, Dept Informat Technol, Taichung, Taiwan.
   [Lin, Kuan-Cheng] Natl Cheng Hsing Univ, Dept Management Informat Syst, Taichung, Taiwan.
   [Wang, Jen-Chieh] Overseas Chinese Univ Taichung, Dept Business Adm, Taichung, Taiwan.
C3 National Taichung University of Education
RP Lee, MF (corresponding author), Natl Taichung Univ Educ Taichung, Grad Inst Educ Measurement & Stat, Taichung, Taiwan.
EM antonio6561@gmail.com; grace@mail.ntcu.edu.tw; jhungc.hung@gmail.com;
   kclin@nchu.edu.tw; friend22895586@yahoo.com.tw
CR Aarts R, 2010, IEEE T INF TECHNOL B, V14, P1483
   Acampora G, 2011, SERV ORIENTED COMPUT, V5, P17, DOI 10.1007/s11761-011-0078-7
   [Anonymous], 2008, DESCARTES ERROR EMOT
   [Anonymous], J CONVERGENCE
   Castellano G, 2007, LECT NOTES COMPUT SC, V4738, P71
   Cheng BHC, 2009, SOFTWARE ENG SELF AD, P48
   Choi Y, 2005, J INF PROCESS SYST, V1, P107
   D'Mello S., 2007, P 29 ANN COGNITIVE S, P905
   Fayyad U, 1996, AI MAG, V17, P37
   Goleman D., 2006, Working with emotional intelligence. pp, P317
   Grimm M, 2007, LECT NOTES COMPUT SC, V4738, P126
   Han J., 2006, DATA MINING CONCEPTS, DOI 10.1016/C2009-0-61819-5
   Hofmann M., 2005, CONTENT NETWORKING A, P179, DOI [10.1016/B978-155860834-4/50026-3, DOI 10.1016/B978-155860834-4/50026-3]
   Holden R., 2013, OXFORD DICT
   Izard CarrollE., 1984, Emotions, Cognition, and Behavior
   Jaques PA, 2007, COMPUT EDUC, V49, P360, DOI 10.1016/j.compedu.2005.09.002
   Kapoor A, 2007, INT J HUM-COMPUT ST, V65, P724, DOI 10.1016/j.ijhcs.2007.02.003
   Komatsu T, 2007, LECT NOTES COMPUT SC, V4738, P266
   KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2
   Levine DS, 2007, PHYS LIFE REV, V4, P37, DOI 10.1016/j.plrev.2006.10.001
   Liu CC, 2008, INT J HUM-COMPUT ST, V66, P662, DOI 10.1016/j.ijhcs.2008.04.003
   Liu QF, 2009, SEP PURIF TECHNOL, V70, P96, DOI 10.1016/j.seppur.2009.08.017
   Loia V, 2013, KNOWLEDGE BASED SYST
   Malkawi M., 2013, J HUMAN CENTRIC COMP, V3, P1
   Mandryk RL, 2007, INT J HUM-COMPUT ST, V65, P329, DOI 10.1016/j.ijhcs.2006.11.011
   Pantic M, 2003, P IEEE, V91, P1370, DOI 10.1109/JPROC.2003.817122
   Peña-Ayala A, 2014, EXPERT SYST APPL, V41, P1432, DOI 10.1016/j.eswa.2013.08.042
   PhridviRaj MSB, 2014, PROC TECH, V12, P255, DOI 10.1016/j.protcy.2013.12.483
   Picard R.W., 2000, Affective Computing
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Pittman RE, TAXONOMY OF LEARNING
   Power M, 2000, HDB COGNITION EMOTIO, P45
   Rezazadeh IM, 2011, AUTOMAT CONSTR, V20, P289, DOI 10.1016/j.autcon.2010.10.005
   Sexton RS, 1998, DECIS SUPPORT SYST, V22, P171, DOI 10.1016/S0167-9236(97)00040-7
   Sexton RS, 2000, INFORM SCIENCES, V129, P45, DOI 10.1016/S0020-0255(00)00068-2
   Shetty GR, 2003, J MEMBRANE SCI, V217, P69, DOI 10.1016/S0376-7388(03)00075-9
   Stach W, 2010, FUZZY SET SYST, V161, P2515, DOI 10.1016/j.fss.2010.04.008
   Tan M, 2014, J TAIWAN INST CHEM E, V45, P68, DOI 10.1016/j.jtice.2013.04.004
   Tan M, 2012, SEP PURIF TECHNOL, V89, P142, DOI 10.1016/j.seppur.2012.01.011
   Tao JH, 2005, LECT NOTES COMPUT SC, V3784, P981
   Thayer Robert E., 1990, The Biopsychology of Mood and Arousal
   Vlahos GE, 2004, INFORM MANAGE-AMSTER, V41, P763, DOI 10.1016/j.im.2003.06.003
   Wagner J, 2007, LECT NOTES COMPUT SC, V4738, P114
   Yang YH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P208
   Zhou F, 2011, INT J HUM-COMPUT ST, V69, P801, DOI 10.1016/j.ijhcs.2011.07.005
NR 45
TC 5
Z9 5
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15185
EP 15198
DI 10.1007/s11042-014-2231-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700004
DA 2024-07-18
ER

PT J
AU Liu, S
   Fan, YY
   Samal, A
   Guo, Z
AF Liu, Shu
   Fan, Yang-Yu
   Samal, Ashok
   Guo, Zhe
TI Advances in computational facial attractiveness methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face attractiveness; Facial attractiveness prediction; Facial
   attractiveness enhancement; Lateral facial attractiveness; 3D facial
   attractiveness
ID BEAUTY; FACE; SHAPE; SYMMETRY; CLASSIFICATION; AESTHETICS; PREDICTION;
   JUDGMENTS; SELECTION; TEXTURE
AB Attractiveness of a face plays an important role in many social endeavors. It influences careers like digital entertainment, modeling and acting, as well as person's career prospect, financial status, and personal relationships. Computational approaches to exploring the nature and components of face attractiveness have been proposed, and have become an emerging topic in facial analysis research. Integrating techniques from image processing, computer vision and machine learning, this subarea aims to develop computational methods to quantify and investigate the attractiveness of a face. This paper summarizes the most recent advances in four related aspects of face attractiveness: (a) facial attractiveness prediction, (b) facial attractiveness enhancement, (c) lateral facial attractiveness and (d) 3D facial attractiveness. The motivations, innovative techniques, and significant results are summarized and discussed. The open problems in these areas and directions for future work are also briefly stated.
C1 [Liu, Shu; Fan, Yang-Yu; Guo, Zhe] Northwestern Polytech Univ, Sch Elect & Informat, Xian, Shaanxi, Peoples R China.
   [Liu, Shu; Samal, Ashok] Univ Nebraska, Dept Comp Sci & Engn, Lincoln, NE 68588 USA.
C3 Northwestern Polytechnical University; University of Nebraska System;
   University of Nebraska Lincoln
RP Liu, S (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian, Shaanxi, Peoples R China.; Liu, S (corresponding author), Univ Nebraska, Dept Comp Sci & Engn, Lincoln, NE 68588 USA.
EM liushu0922@mail.nwpu.edu.cn; fan_yangyu@nwpu.edu.cn; samal@cse.unl.edu;
   guozhe@nwpu.edu.cn
FU China Scholarship Council (CSC) [201306290099]; National Natural Science
   Foundation of China [61402371]; Science and Technology Innovation
   Engineering Plan in Shaanxi Province of China [2013SZS15-K02]; Natural
   Science Basic Research Plan in Shaanxi Province of China [2015JM6317];
   Fundamental Research Funds for the Central Universities
   [3102014JCQ01060]
FX This work is supported in part by China Scholarship Council (CSC) under
   Grant No. 201306290099, the National Natural Science Foundation of China
   under Grant 61402371, Science and Technology Innovation Engineering Plan
   in Shaanxi Province of China under Grant 2013SZS15-K02, Natural Science
   Basic Research Plan in Shaanxi Province of China under Grant 2015JM6317,
   the Fundamental Research Funds for the Central Universities under Grant
   3102014JCQ01060.
CR Adamson Peter A, 2006, Facial Plast Surg, V22, P188, DOI 10.1055/s-2006-950176
   ALLEY TR, 1991, PSYCHOL SCI, V2, P123, DOI 10.1111/j.1467-9280.1991.tb00113.x
   [Anonymous], TECHNICAL REPORT
   [Anonymous], 2006, P 19 INT C NEUR INF
   [Anonymous], 2014, PLAST SURG STAT REP
   [Anonymous], THE PERFECT FACE
   [Anonymous], 2008, 2008 8 IEEE INT C
   [Anonymous], HUMAN FACE GOLDEN RA
   [Anonymous], 2013, International Conference on Multimedia
   [Anonymous], C P IEEE INT C SYST
   Arakawa K, 2005, I S INTELL SIG PROC, P9
   Barash D., 1982, SOCIOBIOLOGY BEHAV
   Bashour M, 2006, PLAST RECONSTR SURG, V118, P741, DOI 10.1097/01.prs.0000233051.61512.65
   Bashour M, 2006, PLAST RECONSTR SURG, V118, P757, DOI 10.1097/01.prs.0000207382.60636.1c
   Berscheid E., 1974, ADV EXP SOC PSYCHOL, V7, P157, DOI [DOI 10.1016/S0065-2601(08)60037-4, 10.1016/S00652601, DOI 10.1016/S00652601]
   Bottino A, 2012, IEEE T BIO-MED ENG, V59, P3439, DOI 10.1109/TBME.2012.2217496
   Bottino Andrea, 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P59, DOI 10.1007/978-3-642-33275-3_7
   Bottino A, 2010, LECT NOTES COMPUT SC, V6111, P425, DOI 10.1007/978-3-642-13772-3_43
   Bottino A, 2008, WSCG 2008, COMMUNICATION PAPERS, P183
   Caers R, 2011, SOC SCI COMPUT REV, V29, P437, DOI 10.1177/0894439310386567
   Calder A., 2011, Oxford handbook of face perception
   Chen FM, 2010, LECT NOTES COMPUT SC, V6165, P21, DOI 10.1007/978-3-642-13923-9_3
   Chiang WC, 2014, PATTERN RECOGN, V47, P1249, DOI 10.1016/j.patcog.2013.09.007
   CUNNINGHAM MR, 1995, J PERS SOC PSYCHOL, V68, P261, DOI 10.1037/0022-3514.68.2.261
   Davis BC, 2008, IEEE IMAGE PROC, P109, DOI 10.1109/ICIP.2008.4711703
   Devcic Z, 2011, LARYNGOSCOPE, V121, P1388, DOI 10.1002/lary.21804
   Duan Hongshuai, 2012, Journal of Data Acquisition & Processing, V27, P105
   Eisenthal Y, 2006, NEURAL COMPUT, V18, P119, DOI 10.1162/089976606774841602
   Etcoff N., 1999, SURVIVAL PRETTIEST S
   Fan JT, 2012, PATTERN RECOGN, V45, P2326, DOI 10.1016/j.patcog.2011.11.024
   Farkas LG, 2005, J CRANIOFAC SURG, V16, P615, DOI 10.1097/01.scs.0000171847.58031.9e
   FARKAS LG, 1985, PLAST RECONSTR SURG, V75, P328, DOI 10.1097/00006534-198503000-00005
   Farkas LG, 1994, Anthropometry of Head and Face, Vsecond
   Feser DK, 2007, AESTHET PLAST SURG, V31, P154, DOI 10.1007/s00266-006-0149-x
   Fink B, 2001, J COMP PSYCHOL, V115, P92, DOI 10.1037//0735-7036.115.1.92
   Galton F., 1879, The Journal of the Anthropological Institute of Great Britain and Ireland, V8, P132, DOI [10.2307/2841021, DOI 10.2307/2841021]
   Gan JY, 2014, NEUROCOMPUTING, V144, P295, DOI 10.1016/j.neucom.2014.05.028
   GRAMMER K, 1994, J COMP PSYCHOL, V108, P233, DOI 10.1037/0735-7036.108.3.233
   Gray D, 2010, LECT NOTES COMPUT SC, V6316, P434, DOI 10.1007/978-3-642-15567-3_32
   Gunes H., 2011, P JOINT ACM WORKSH H, P19
   Gunes H, 2006, INT J HUM-COMPUT ST, V64, P1184, DOI 10.1016/j.ijhcs.2006.07.004
   Guo D, 2009, PROC CVPR IEEE, P73, DOI 10.1109/CVPRW.2009.5206833
   Hara K, 2009, IEEE T CONSUM ELECTR, V55, P855, DOI 10.1109/TCE.2009.5174466
   Joy KL, 2006, FOURTH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT AND APPLICATIONS, PROCEEDINGS, P82, DOI 10.1109/SERA.2006.2
   Kakadiaris IA, 2008, IEEE INT C AUTOMATIC, P1
   Karimi K, 2010, LARYNGOSCOPE, V120, pS157, DOI 10.1002/lary.21621
   Kim JS, 2009, COMPUT ANIMAT VIRT W, V20, P289, DOI 10.1002/cav.294
   LANGLOIS JH, 1990, PSYCHOL SCI, V1, P115, DOI 10.1111/j.1467-9280.1990.tb00079.x
   Laurentini A, 2014, COMPUT VIS IMAGE UND, V125, P184, DOI 10.1016/j.cviu.2014.04.006
   Lee C, 2009, P 16 IEEE INT C IM P, P3113
   Leyvand T., 2008, ACM T GRAPHICS SIGGR, V27, P55
   Liao QQ, 2012, IEEE T VIS COMPUT GR, V18, P1704, DOI 10.1109/TVCG.2012.26
   Liu S, 2015, LECT NOTES COMPUT SC, V9242, P564, DOI 10.1007/978-3-319-23989-7_57
   Mao HY, 2009, IEEE SYS MAN CYBERN, P4842, DOI 10.1109/ICSMC.2009.5346057
   Marquardt Stephen R, 2002, J Clin Orthod, V36, P339
   McCurdy John A Jr, 2006, Facial Plast Surg, V22, P204, DOI 10.1055/s-2006-950179
   Melacci S, 2010, PATTERN ANAL APPL, V13, P289, DOI 10.1007/s10044-009-0155-0
   Mu YD, 2013, NEUROCOMPUTING, V99, P59, DOI 10.1016/j.neucom.2012.06.020
   Naini FB, 2012, OR SURG OR MED OR PA, V114, P303, DOI 10.1016/j.tripleo.2011.07.031
   Naini FB, 2010, ARCH FACIAL PLAST S, V12, P141, DOI 10.1001/archfacial.2010.29
   O'Toole AJ, 1999, IMAGE VISION COMPUT, V18, P9, DOI 10.1016/S0262-8856(99)00012-8
   Ohchi S., 2010, 2010 10th International Symposium on Communications and Information Technologies (ISCIT 2010), P13, DOI 10.1109/ISCIT.2010.5664921
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ozkul T, 2004, COMPUT BIOL MED, V34, P697, DOI 10.1016/j.compbiomed.2003.10.006
   Pantic M, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P37, DOI 10.1109/ICME.2002.1035712
   Penton-Voak IS, 2006, SOC COGNITION, V24, P607, DOI 10.1521/soco.2006.24.5.607
   PERRETT DI, 1994, NATURE, V368, P239, DOI 10.1038/368239a0
   Perrett DI, 1998, NATURE, V394, P884, DOI 10.1038/29772
   Scheib JE, 1999, P ROY SOC B-BIOL SCI, V266, P1913, DOI 10.1098/rspb.1999.0866
   Schmid K, 2008, PATTERN RECOGN, V41, P2710, DOI 10.1016/j.patcog.2007.11.022
   Seo M., 2011, J INFORM HIDING MULT, V2, P192
   Slater A, 1998, INFANT BEHAV DEV, V21, P345, DOI 10.1016/S0163-6383(98)90011-X
   Springer IN, 2008, PLAST RECONSTR SURG, V121, P629, DOI 10.1097/01.prs.0000298095.18943.72
   Sun MM, 2011, 2011 FIRST ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P283, DOI 10.1109/ACPR.2011.6166544
   Sutic Davor, 2010, 2010 33rd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO), P1339
   SWADDLE JP, 1995, P ROY SOC B-BIOL SCI, V261, P111, DOI 10.1098/rspb.1995.0124
   Tariq U, 2009, IEEE IMAGE PROC, P2441, DOI 10.1109/ICIP.2009.5414117
   THAKERAR JN, 1979, J SOC PSYCHOL, V108, P121, DOI 10.1080/00224545.1979.9711969
   Todd SA, 2005, EUR J ORTHODONT, V27, P363, DOI 10.1093/ejo/cji024
   Torsello Ferruccio, 2010, Prog Orthod, V11, P13, DOI 10.1016/j.pio.2010.04.003
   Valenzano DR, 2006, VISION RES, V46, P1282, DOI 10.1016/j.visres.2005.10.024
   Wang SY, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P805, DOI 10.1145/2647868.2654986
   Winston JS, 2007, NEUROPSYCHOLOGIA, V45, P195, DOI 10.1016/j.neuropsychologia.2006.05.009
   Xie D., 2015, ARXIV PREPRINT ARXIV
   Xie DR, 2015, IEEE SYS MAN CYBERN, P1821, DOI 10.1109/SMC.2015.319
   Yin B., 2005, BJUT 3D LARGE SCALE
   Zaidel DW, 2005, INT J NEUROSCI, V115, P1165, DOI 10.1080/00207450590914464
NR 87
TC 34
Z9 35
U1 2
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16633
EP 16663
DI 10.1007/s11042-016-3830-3
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700078
DA 2024-07-18
ER

PT J
AU Saha, P
   Bhowmik, MK
   Bhattacharjee, D
   De, BK
   Nasipuri, M
AF Saha, Priya
   Bhowmik, Mrinal Kanti
   Bhattacharjee, Debotosh
   De, Barin Kumar
   Nasipuri, Mita
TI Expressions Recognition of North-East Indian (NEI) Faces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual face image; Facial expressions; Pose and illumination variations;
   NEI facial expression database; Baseline algorithms
AB Facial expression is one of the major distracting factors for face recognition performance. Pose and illumination variations on face images also influence the performance of face recognition systems. The combination of three variations (facial expression, pose and illumination) seriously degrades the recognition accuracy. In this paper, three experimental protocols are designed in such a way that the successive performance degradation due to the increasing variations (expressions, expressions with illumination effect and expressions with illumination and pose effect) on face images can be examined. The whole experiment is carried out using North-East Indian (NEI) face images with the help of four well-known classification algorithms namely Linear Discriminant Analysis (LDA), K-Nearest Neighbor algorithm (KNN), combination of Principal Component Analysis and Linear Discriminant Analysis (PCA + LDA), combination of Principal Component Analysis and K-Nearest Neighbor algorithm (PCA + KNN). The experimental observations are analyzed through confusion matrices and graphs. This paper also describes the creation of NEI facial expression database, which contains visual static face images of different ethnic groups of the North-East states. The database is useful for future researchers in the area of forensic science, medical applications, affective computing, intelligent environments, lie detection, psychiatry, anthropology, etc.
C1 [Saha, Priya; Bhowmik, Mrinal Kanti] Tripura Univ, Dept Comp Sci & Engn, Suryamaninagar 799022, Tripura, India.
   [De, Barin Kumar] Tripura Univ, Dept Phys, Suryamaninagar 799022, Tripura, India.
   [Bhattacharjee, Debotosh; Nasipuri, Mita] Jadavpur Univ, Kolkata 700032, W Bengal, India.
C3 Tripura University; Tripura University; Jadavpur University
RP Bhowmik, MK (corresponding author), Tripura Univ, Dept Comp Sci & Engn, Suryamaninagar 799022, Tripura, India.
EM mkb_cse@yahoo.co.in
RI De, Barin Kumar/GRS-7957-2022; Saha, Priya/AAA-7464-2019; Bhowmik,
   Mrinal Kanti/AAY-8356-2020; Bhattacharjee, Debotosh/L-8521-2015;
   Bhattacharjee, Debotosh/Q-4065-2019
OI Bhowmik, Mrinal Kanti/0000-0003-3451-191X; Bhattacharjee,
   Debotosh/0000-0002-1163-6413; Bhattacharjee,
   Debotosh/0000-0002-1163-6413
FU Biometrics Laboratory of Tripura University [12(2)/2011-ESD]; DeitY;
   MCIT; Government of India; Department of Science and Technology (DST);
   Government of India for providing her Junior Research
   Fellowship-Professional (JRF-Professional) under DST INSPIRE fellowship
   [IF131067]
FX The work presented here is being conducted in the Biometrics Laboratory
   of Tripura University, under the research project supported by the Grant
   No. 12(2)/2011-ESD, dated 29/03/2011, from DeitY, MCIT, Government of
   India. The first author is grateful to Department of Science and
   Technology (DST), Government of India for providing her Junior Research
   Fellowship-Professional (JRF-Professional) under DST INSPIRE fellowship
   program (No. IF131067). The authors would like to thank anonymous
   reviewers for their comments/suggestions to improve the quality of the
   paper.
CR Bhowmik MK, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.10.102106
   Cao B, 2004, LECT NOTES COMPUT SC, V3338, P370
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dasarathy B.V., 1990, NEAREST NEIGHBOR NN
   Ekman P., 1971, Nebraska symposium on motivation, V19, P207
   Gross R, 2005, HANDBOOK OF FACE RECOGNITION, P301, DOI 10.1007/0-387-27257-7_14
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Li T, 2006, KNOWL INF SYST, V10, P453, DOI 10.1007/s10115-006-0013-y
   Lucey P, 2010, P IEEE INT C COMP VI
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Majumder G, 2012, 1 INT C INT INFR, P286
   Martinez A., 1998, AR FACE DATABASE
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Roh MC, 2007, INT J PATTERN RECOGN, V21, P1017, DOI 10.1142/S0218001407005818
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
NR 17
TC 3
Z9 3
U1 4
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 16781
EP 16807
DI 10.1007/s11042-015-2945-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600004
DA 2024-07-18
ER

PT J
AU Xu, Z
   Zhang, Y
   Xu, XY
AF Xu, Zhao
   Zhang, Yang
   Xu, Xiayan
TI 3D visualization for building information models based upon IFC and
   WebGL integration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BIM; IFC; WebGL; 3D visualization; Information management
ID FRAMEWORK; EXCHANGE
AB Building Information Modeling (BIM) technology provides broad-ranging support of AEC (architecture, engineering, and construction) industry needs. The inclusion of a web display provides increased support to BIM users and it is desirable that global CAD (computer-aided design) and BIM design software should provide increased access to building product specifications via web browser. Recent actions towards to develop a BIM-based Web3D environments evidence the effort of facing the situation which request to integrate IFC (Industry Foundation Classes) with web technology, such as WebGL. This paper discusses a method to create 3D visualization for BIM models in web browser by combining IFC standard and WebGL technology. The solution is developed based upon a conversion of IFC text into object file (OBJ) and a subsequent OBJ compilation in WebGL. The main work consists of three parts. First, based on IFC standard, the IFC-to-OBJ transforming method is constructed for encoding specific IFC attributes into the OBJ file. Second, through WebGL programming, a visualization method is presented for creating 3D performance in web browser. Thirdly, a visualization platform with three-layered structure is designed based on IFC and WebGL integration for BIM data. The testing of the approach and the platform suggested demonstrated consistency in the conversion process and stability and rendering quality in the display of models over the Web browser. The method may be applied in planning and design workflows, particularly in multiuser, multi-BIM-application and real-time environments, which require BIM models or exported IFC files to be visualized easily in the web browser.
C1 [Xu, Zhao; Xu, Xiayan] Southeast Univ, Dept Civil Engn, Nanjing 210096, Jiangsu, Peoples R China.
   [Zhang, Yang] Beijing Forestry Univ, Dept Property Management, Beijing 100083, Peoples R China.
C3 Southeast University - China; Beijing Forestry University
RP Xu, Z (corresponding author), Southeast Univ, Dept Civil Engn, Nanjing 210096, Jiangsu, Peoples R China.
EM bernardos@163.com
OI XU, ZHAO/0000-0003-2060-1068
FU National Science Council of P. R. C. [NSFC-71302138, NSFC-71573019,
   NSFC-71540015]; Priority Academic Program Development of JiangSu Higher
   Education Institutions [CE01-2-2]
FX The authors' special thanks go to all survey participants and reviewers
   of the paper, and appreciation to the National Science Council of P. R.
   C. for financially supporting this research (NSFC-71302138,
   NSFC-71573019 and NSFC-71540015), and fund by the Priority Academic
   Program Development of JiangSu Higher Education Institutions (CE01-2-2).
CR Allemang D., 2011, SEMANTIC WEB WORKING, V2nd ed., P249, DOI [10.1016/B978-0-12-385965-5.10012-3, DOI 10.1016/B978-0-12-385965-5.10012-3]
   [Anonymous], 2007, THESIS
   [Anonymous], 2013, ITCON, DOI DOI 10.1016/j.jnucmat.2012.08.049
   Anttonen M, 2011, BUILDING 3D WEBGL AP
   Costa G, 2015, AUTOMAT CONSTR, V57, P239, DOI 10.1016/j.autcon.2015.05.007
   Davood S, 2015, INT J DIGIT EARTH, V8, P538
   Eastman CM, 2010, J COMPUT CIVIL ENG, V24, P25, DOI 10.1061/(ASCE)0887-3801(2010)24:1(25)
   Fazio P, 2007, J ARCHIT ENG, V13, P44, DOI 10.1061/(ASCE)1076-0431(2007)13:1(44)
   Gao G, 21 INT WORKSH INT CO
   Gökçe KU, 2013, J COMPUT CIVIL ENG, V27, P36, DOI 10.1061/(ASCE)CP.1943-5487.0000194
   HANSEN SM, 2005, P WORKSH ISS THEOR S, P27
   He GP, 2011, BIM INTRO
   Juan D., 2014, Journal of Service Science and Management, V7, P47
   Kim I, 2008, J COMPUT CIVIL ENG, V22, P159, DOI 10.1061/(ASCE)0887-3801(2008)22:3(159)
   Lee G, 2012, J COMPUT CIVIL ENG, V28, P210
   Liebich T., 2013, Industry Foundation Classes IFC4 Official Release
   Liebich T, 2004, IFC 2X MODEL IMPLEME
   Liu Zhao-qiu, 2010, Journal of South China University of Technology, V38, P122, DOI 10.3969/j.issn.1000-565X.2010.07.022
   Niknam M, 2015, AUTOMAT CONSTR, V57, P222, DOI 10.1016/j.autcon.2015.04.003
   Nour M., 2009, ITcon, V14, P736
   Nyamsuren P, 2013, INT J PRECIS ENG MAN, V14, P1797, DOI 10.1007/s12541-013-0240-6
   Ortiz S, 2010, COMPUTER, V43, P14, DOI 10.1109/MC.2010.15
   Pauwels P, 2011, AUTOMAT CONSTR, V20, P506, DOI 10.1016/j.autcon.2010.11.017
   Purevdorj N, 2014, INT J ADV MANUF TECH, V74, P851, DOI 10.1007/s00170-014-6000-7
   Resch B, 2014, CARTOGR GEOGR INF SC, V41, P235, DOI 10.1080/15230406.2014.901901
   Simman MA, 2011, P 11 INT C CONSTR AP
   Stefano B., 2014, P 6 WORKSH FORM ONT
   Terkaj W, 2015, AUTOMAT CONSTR, V57, P188, DOI 10.1016/j.autcon.2015.04.010
   Torma S, 2014, ECPPM 2014 EWORK EBU
   Zhang XY, 2014, COMP CIV BUILD ENG 2
   Zhang Yinong, 2009, THESIS
NR 31
TC 23
Z9 26
U1 10
U2 169
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17421
EP 17441
DI 10.1007/s11042-016-4104-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600030
DA 2024-07-18
ER

PT J
AU Yoon, SM
   Yoon, J
AF Yoon, Sang Min
   Yoon, Jungho
TI Depth map enhancement using adaptive moving least squares method with a
   total variation minimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Total variation minimization
ID IMAGE
AB Accurate and fast depth map acquisition and enhancement is an important issue in the area of computer vision and image processing. In this study, we present a novel method for enhancing noisy depth maps using adaptive total variation minimization, which facilitates noise smoothing and boundary sharpening for a given depth map image but without previous information. We filter the noise in the depth map with a refined total variation minimization technique. Our experimental results demonstrate that the proposed method outperforms other competitive methods in both objective and subjective comparisons of depth map enhancement and denoising.
C1 [Yoon, Sang Min] Kookmin Univ, Sch Comp Sci, 77,Jeongneung Ro, Seoul 136702, South Korea.
   [Yoon, Jungho] Ewha Womans Univ, Dept Math, 52 Ewhayeodae Gil, Seoul 120750, South Korea.
C3 Kookmin University; Ewha Womans University
RP Yoon, SM (corresponding author), Kookmin Univ, Sch Comp Sci, 77,Jeongneung Ro, Seoul 136702, South Korea.
EM sangmin.yoon@gmail.com; yoon@ewha.ac.kr
FU ICT RAMP;D program of MSIP/IITP, Korea [B0101-15-1347]; Basic Science
   Research Program through the National Research Foundation of Korea (NRF)
   - Ministry of Science, ICT AMP; Future Planning [NRF-2014R1A1A1002890];
   Science Research Center Program through the National Research Foundation
   of Korea [NRF20151009350]; Priority Research Centers Program through the
   National Research Foundation of Korea [2009-0093827]
FX S. M. Yoon was supported by the ICT R&D program of MSIP/IITP, Korea
   (B0101-15-1347), A Study on the Key Technology of Optical Modulation and
   Signal Processing for Implementation of 400 Gb/s Optical Transmission.
   S. M. Yoon was also supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Science, ICT & Future Planning (NRF-2014R1A1A1002890). Jungho Yoon
   was supported by NRF20151009350 (Science Research Center Program) and
   2009-0093827 (Priority Research Centers Program) through the National
   Research Foundation of Korea.
CR Balanna P, 2013, INT J COMPUT ELECT R, V2, P183
   Bose NK, 2006, IEEE T IMAGE PROCESS, V15, P2239, DOI 10.1109/TIP.2006.877406
   Caselles V, 2007, MULTISCALE MODEL SIM, V6, P879, DOI 10.1137/070683003
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chan TF, 2007, J VIS COMMUN IMAGE R, V18, P464, DOI 10.1016/j.jvcir.2006.12.004
   Danielyan A, 2012, IEEE T IMAGE PROCESS, V21, P1715, DOI 10.1109/TIP.2011.2176954
   Eisemann E, 2004, ACM T GRAPHIC, V23, P673, DOI 10.1145/1015706.1015778
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Hu JH, 2013, IEEE IMAGE PROC, P1090, DOI 10.1109/ICIP.2013.6738225
   Jung SW, 2013, IEEE T CIRC SYST VID, V23, P269, DOI 10.1109/TCSVT.2012.2203734
   Jung SW, 2012, IEEE SIGNAL PROC LET, V19, P303, DOI 10.1109/LSP.2012.2191616
   Kim SM, 2006, IEICE T INF SYST, VE89D, P37, DOI 10.1093/ietisy/e89-d.1.37
   Lee YJ, 2014, J MATH IMAGING VIS, V48, P566, DOI 10.1007/s10851-013-0428-5
   Levin D, 1998, MATH COMPUT, V67, P1517, DOI 10.1090/S0025-5718-98-00974-0
   Needell D, 2012, SIAM J NUMER ANAL, V50, P1162
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Nikolova M, 2004, J MATH IMAGING VIS, V21, P155, DOI 10.1023/B:JMIV.0000035180.40477.bd
   Nikolova M, 2000, SIAM J APPL MATH, V61, P633, DOI 10.1137/S0036139997327794
   Rana PK, 2013, P ICASSP
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Stefanoski N, 2013, IEEE IMAGE PROC, P1247, DOI 10.1109/ICIP.2013.6738257
   Subedar MM, 2010, P SPIE
   Swenson D, 2011, UC MERCED APPL MATH
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Tepper M, 2013, IEEE IMAGE PROC, P504, DOI 10.1109/ICIP.2013.6738104
   ZHANG Q, 2012, J MULTIMED, V7, P415
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 27
TC 1
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15929
EP 15938
DI 10.1007/s11042-015-2905-x
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700046
DA 2024-07-18
ER

PT J
AU Karam, M
   Safa, H
   Masud, M
AF Karam, Marcel
   Safa, Haidar
   Masud, Mehedi
TI WhatsUpNow: urban social application with real-time peer-to-peer ambient
   and sensory data exchanges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia and sensory ambient data; Visual ambient representation;
   Caching; Service discovery; Social urban applications
AB Having the ability to generate, share, and use ambient multimedia and sensory data in real-time using both traditional sensors as well as non-traditional ones (such as smart device users) is a pioneering practice that requires specialized network capabilities and visualization metaphors. The network must support both service discovery and cache sharing to allow users to generate real-time sensory data, upload them or share them with end-users searching for the same data. Visualization and coloring schemes must support both streaming and stored sensory data to allow users to interact with either recent or up-to-the-minute ambient sensory data on either smart devices or the server. This article describes the design and reports on the simulation performance of a social network application that allows a group of users on an ad-hoc network to share real-time multimedia and ambient data with respect to venues of potential interest. At the graphical interface level, we present an intuitive interface that allows users to capture and share, often with a single hand, an array of sensory data comfortably and efficiently using touch screen smart devices. At the network level, we describe an architectural model that is supported by a specific design strategy for service discovery and caching to facilitate data sharing. The performance of the architectural model is then evaluated to show that it can efficiently handle bulk of sensory data, when accessed using smart devices in a peer-to-peer environment.
C1 [Karam, Marcel; Safa, Haidar] Amer Univ Beirut, Dept Comp Sci, Beirut, Lebanon.
   [Masud, Mehedi] Taif Univ, Dept Comp Sci, At Taif, Saudi Arabia.
C3 American University of Beirut; Taif University
RP Karam, M (corresponding author), Amer Univ Beirut, Dept Comp Sci, Beirut, Lebanon.
EM mk62@aub.edu.lb; hs33@aub.edu.lb; mmasud@tu.edu.sa
RI Masud, Mehedi/AAZ-7022-2020
OI Masud, Mehedi/0000-0001-6019-7245
CR Alt Florian, 2010, 2010 8th IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops), P788, DOI 10.1109/PERCOMW.2010.5470542
   ANDREL T, 2006, IEEE COMPUT, P48
   [Anonymous], 2004, AD HOC NETW, DOI DOI 10.1016/S1570-8705(03)00043-X
   [Anonymous], 2002, AD HOC MOBILE WIRELE
   ARTAIL H, 2007, P 3 IEEE INT C WIR M
   Artail H, 2008, IEEE T MOBILE COMPUT, V7, P961, DOI 10.1109/TMC.2008.18
   Breslau L, 1999, IEEE INFOCOM SER, P126, DOI 10.1109/INFCOM.1999.749260
   Cadiz J, 1998, AWARENESS MONI UNPUB
   Chakraborty D, 2006, IEEE T MOBILE COMPUT, V5, P97, DOI 10.1109/TMC.2006.26
   Chand N, 2007, WIRELESS PERS COMMUN, V43, P41, DOI 10.1007/s11277-006-9238-z
   Chow CY, 2007, IEEE J SEL AREA COMM, V25, P179, DOI 10.1109/JSAC.2007.070118
   Consolvo S, 2004, LECT NOTES COMPUT SC, V3205, P1
   de Santis F, 2014, J COMPUT NETW COMMUN, V2014, DOI 10.1155/2014/450194
   Elfaki MA, 2014, J NETW COMPUT APPL, V40, P85, DOI 10.1016/j.jnca.2013.08.013
   Fogarty J., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P141, DOI 10.1145/502348.502369
   Gao Z, 2006, J COMPUT NETW
   Gao Zhen-guo, 2005, Journal of the Harbin Institute of Technology, V37, P1256
   Geurts J, 2005, WORKSH MULT SEM WEB, P4
   Ishii H., 1997, P ACM SIGCHI C HUM F, P234, DOI DOI 10.1145/258549.258715
   Koodli R., 2002, SERVICE DIS IN PRESS
   Majd NE, 2014, IEEE GLOBECOM
   Manka JS, 2003, PROCEEDINGS OF THE TWENTY-NINTH ANNUAL CONFERENCE ON EXPLOSIVES AND BLASTING TECHNIQUE, VOL 1, P169
   Matthews T, 2007, HUM-COMPUT INTERACT, V22, P221
   Metaxas G, 2007, AMI 09, P88
   Miller T., 2002, AVI '02: Proceedings of the Working Conference on Advanced Visual Interfaces, P43
   Pousman Z., 2006, P WORK C ADV VIS INT, DOI [https://doi.org/10.1145/1133265.1133277, DOI 10.1145/1133265.1133277]
   Safa H, 2010, IGI GLOB, P217
   Safa H, 2007, LECT NOTES COMPUTER
   Safa H, 2010, J NETW COMPUT APPL, V33, P168, DOI 10.1016/j.jnca.2009.08.003
   Skog T, 2002, SIGGRAPH 02 ABSTRACT, P153
   Sukthankar R, 2005, CV4IIE 05, P172
   Teichrieb V, 2007, LECT NOTES COMPUT SC, V4555, P565
   Torres DA, 2005, ISSADS 05 P 5 INT C
NR 33
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13349
EP 13374
DI 10.1007/s11042-015-2846-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800021
DA 2024-07-18
ER

PT J
AU Munea, TL
   Lim, H
   Shon, T
AF Munea, Tewodros Legesse
   Lim, Hyunwoo
   Shon, Taeshik
TI Network protocol fuzz testing for information systems and applications:
   a survey and taxonomy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzing; Fuzz-testing; Network protocol fuzzing; Vulnerability detection
AB Fuzzing or fuzz testing has been introduced as a software testing technique to reduce vulnerabilities in software systems or given targets. To achieve a maximum benefit-to-cost ratio and without complication, we use fuzz testing [11]. In addition, during the development and debugging of a system, we may fail to notice the kinds of shortcoming that fuzz testing can expose. Fuzz testing types are different depending on the target they fuzz. Application, file format, and protocol fuzzing are the most common fuzzing types. A protocol fuzzer sends counterfeit packets to a target system while changing the normal packet en-route and sometimes replaying them. In addition, a protocol fuzzer sometimes acts as proxy server for clients. This survey study examines network protocol fuzz testing. We identified several studies on network protocol fuzzing. Most focus on application layers of the Open Systems Interconnection model. We primarily review the approaches of five studies and the targets and protocol layers they fuzz. We then develop criteria to compare these approaches in detail.
C1 [Munea, Tewodros Legesse; Lim, Hyunwoo; Shon, Taeshik] Ajou Univ, Div Comp Engn, Suwon 443749, Gyeonggi Do, South Korea.
C3 Ajou University
RP Shon, T (corresponding author), Ajou Univ, Div Comp Engn, Suwon 443749, Gyeonggi Do, South Korea.
EM proesta@gmail.com; tsshon@ajou.ac.kr
RI Munea, Tewodros Legesse/ABC-4618-2021
OI Munea, Tewodros Legesse/0000-0001-9777-6961
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Science, ICT & Future Planning
   [NRF-2015R1A1A1A05001238]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Science, ICT & Future Planning (NRF-2015R1A1A1A05001238).
CR Allar J, 2013, PRACTICAL FILE FORMA
   [Anonymous], 2008, Fuzzing for Software Security
   Gorbunov S., 2010, AUTOFUZZ AUTOMATED N
   Han X, 2012, MUTATION BASED FUZZ
   Kitagawa T, 2010, ASPFUZZ STATE AWARE
   Lee DH, 2008, FILE FUZZING SYSTEM
   Ma R, 2014, FUZZ TESTING DATA GE
   onl, 2010, FUZZ TEST FUZZ
   Park KC, 2014, MULTIMEDIA TOOLS APP
   Shu G, 2008, DETECTING COMMUNICAT
   Sutten M, 2005, ART FILE FORMAT FUZZ
   Sutton M., 2007, Fuzzing: brute force vulnerability discovery
   Tsankov P, 2012, SECFUZZ FUZZ TESTING
   Wang JJ, 2013, INT CONF INSTR MEAS, P1129, DOI 10.1109/IMCCC.2013.250
   Zhao J, 2013, RFSM SMART FUZZING A
NR 15
TC 12
Z9 15
U1 3
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14745
EP 14757
DI 10.1007/s11042-015-2763-6
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500043
DA 2024-07-18
ER

PT J
AU Lei, JS
   Jiang, T
   Wu, K
   Du, HZ
   Zhu, GK
   Wang, ZQ
AF Lei, Jingsheng
   Jiang, Teng
   Wu, Kui
   Du, Haizhou
   Zhu, Guokang
   Wang, Zhaoqing
TI Robust <i>K</i>-means algorithm with automatically splitting and merging
   clusters and its applications for surveillance data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE K-means; Robust; Cluster centers selection; Automatically splitting and
   merging; Data mining; Video surveillance
ID EM ALGORITHM; MAXIMUM-LIKELIHOOD; CENTERS; MOTION
AB With the pervasive of the definition of the smart city, the data volume of the surveillance system, huge number of video surveillance devices is now rapidly expanding. The research to surveillance data mining and analytics has attracted increasing attention due to its applications. Cluster analysis as an important task of data mining in video surveillance has recently been highly explored. K-means algorithm is the most popular and widely-used partitional clustering algorithm in practice. However, traditional k-means algorithm suffers from sensitive initial selection of cluster centers, and it is not easy to specify the number of clusters in advance. In this paper, we propose a robust k-means algorithm that can automatically split and merge clusters which incorporates the new ideas in dealing with huge scale of video data. This novel algorithm not only addresses the sensitivity in selecting initial cluster centers, but also is resilient to the initial number of clusters. The performance is experimentally verified using synthetic and publicly available datasets. The experiments demonstrate the effectiveness and robustness of the proposed algorithm. Moreover, experiment is conducted on a real video surveillance dataset and the result shows that the novel approach can be applicated friendly in video surveillance.
C1 [Lei, Jingsheng; Du, Haizhou; Zhu, Guokang] Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 200090, Peoples R China.
   [Jiang, Teng] Shanghai Univ Elect Power, Coll Elect & Informat Engn, Shanghai 200090, Peoples R China.
   [Wu, Kui] Univ Victoria, Dept Comp Sci, Victoria, BC V8W 3P6, Canada.
   [Wang, Zhaoqing] Hainan Univ, Coll Humanities & Commun, Haikou 570228, Peoples R China.
C3 Shanghai University of Electric Power; Shanghai University of Electric
   Power; University of Victoria; Hainan University
RP Lei, JS (corresponding author), Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 200090, Peoples R China.
EM jshlei@126.com
RI du, haizhou/AAE-6856-2022
FU Natural Science Foundation of China [61272437, 61472236]; Innovation
   Program of Shanghai Municipal Education Commission [14ZZ150]; Project of
   Shanghai Science and Technology Committee [14110500800]; Natural Science
   Foundation of Hainan [20156235]
FX This work is supported by Natural Science Foundation of China (No.
   61272437, 61472236), Innovation Program of Shanghai Municipal Education
   Commission (No. 14ZZ150), Project of Shanghai Science and Technology
   Committee (14110500800) and Natural Science Foundation of Hainan (No.
   20156235).
CR Abubaker Mohamed, 2013, International Journal of Intelligent Systems and Applications, V5, P37, DOI 10.5815/ijisa.2013.03.04
   Agha Mohammed EI, 2012, I J INTELLIGENT SYST, V4, P21
   [Anonymous], 2012, P 2012 C INF COMP NE
   Arai Kohei, 2007, Reports of the Faculty of Science and Engineering, Saga University, V36, P25
   Bennewitz M, 2005, INT J ROBOT RES, V24, P31, DOI 10.1177/0278364904048962
   Chadha A, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON RELIABILTY, OPTIMIZATION, & INFORMATION TECHNOLOGY (ICROIT 2014), P136, DOI 10.1109/ICROIT.2014.6798312
   Dahlbom A, 2007, FUSION 2007
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Deng A, 2012, ADV MAT RES, V532-533, P1373
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Fan Jiang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P145
   Han J, 2006, DATA MINING CONCEPTS, P251
   Hunter DR, 2004, AM STAT, V58, P30, DOI 10.1198/0003130042836
   Jain A. K., 1988, Algorithms for Clustering Data, P446
   Jamshidian M, 1997, J ROY STAT SOC B MET, V59, P569, DOI 10.1111/1467-9868.00083
   Katsavounidis I, 1994, IEEE SIGNAL PROC LET, V1, P144, DOI 10.1109/97.329844
   Kaufman L., 2009, FINDING GROUPS DATA
   Kwedlo W, 2010, LECT NOTES ARTIF INT, V6114, P165, DOI 10.1007/978-3-642-13232-2_20
   Leela V., 2013, INT J ENG TECHNOLOGY, V5, P245
   MACQUEEN JB, 1967, SOME METHODS CLASSIF, P281
   Matsuyama Y, 2003, IEEE T INFORM THEORY, V49, P692, DOI 10.1109/TIT.2002.808105
   Matsuyama Y, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P808, DOI 10.1109/IJCNN.2011.6033304
   Mehar Arshad Muhammad, 2013, 2013 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), P51, DOI 10.1109/BIBM.2013.6732734
   MENG XL, 1993, BIOMETRIKA, V80, P267, DOI 10.2307/2337198
   Piciarelli C, 2006, PATTERN RECOGN LETT, V27, P1835, DOI 10.1016/j.patrec.2006.02.004
   Radhakrishna Rao C, 1999, LINEAR MODELS LEAST, P70
   Shehroz Ahmad, 2004, PATTERN RECOGN, V25, P1293
   Sung C, 2012, IEEE INT C INT ROBOT, P1547, DOI 10.1109/IROS.2012.6386017
   Vasquez D, 2009, INT J ROBOT RES, V28, P1486, DOI 10.1177/0278364909342118
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Yadav J, 2013, 2013 INTERNATIONAL CONFERENCE ON MACHINE INTELLIGENCE AND RESEARCH ADVANCEMENT (ICMIRA 2013), P269, DOI 10.1109/ICMIRA.2013.57
   Yang H, 2007, 2006 IE INT C IND IN, P1171
   Ye YM, 2006, LECT NOTES ARTIF INT, V3918, P189
   Yin JT, 2012, IEEE INT C CL COMP, P275, DOI 10.1109/CLUSTER.2012.81
   Zhu J, 2010, IMPROVED K MEANS CLU
   于剑, 2002, [中国科学. E辑, 技术科学, Science in China], V32, P274
NR 36
TC 24
Z9 24
U1 0
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 12043
EP 12059
DI 10.1007/s11042-016-3322-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200026
DA 2024-07-18
ER

PT J
AU Aqeel-ur-Rehman
   Liao, XF
   Kulsoom, A
   Ullah, S
AF Aqeel-ur-Rehman
   Liao, Xiaofeng
   Kulsoom, Ayesha
   Ullah, Sami
TI A modified (Dual) fusion technique for image encryption using SHA-256
   hash and multiple chaotic maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 2D logistic map; Chaos theory; DNA; SHA-256; Noise resistance; MDF
ID RANDOM NUMBER GENERATORS; DNA-SEQUENCE OPERATION; ALGORITHM;
   CRYPTANALYSIS
AB A Modified Dual Fusion (MDF) technique of image encryption is proposed in this paper to overcome the limitations that exist in the original research work of Q. Zhang et al. (Optik 124: 3596-3600, 2013). A novel technique of DNA encoding is applied through chaotic maps on pixel level and SHA-256 hash of the plain image is used to generate secret keys to avoid chosen-plaintext attack. Also, in the modified scheme, two random images are generated from chaotic maps to fuse with the plain image after permutation in digital and DNA domains using XOR and addition operations respectively. The simulated experimental results and security analysis show that the proposed cryptosystem has fairly good encryption effect than the original fusion scheme but also has the capability to sustain noise which gets add during transmission over noisy channel. Besides, the paramount factor of improved scheme is suitable for the real time applications.
C1 [Aqeel-ur-Rehman; Ullah, Sami] COMSTAS Inst Informat Technol, Dept Comp Sci, Vehari, Pakistan.
   [Liao, Xiaofeng] Chongqing Univ, Coll Comp Sci & IT, Chongqing, Peoples R China.
   [Kulsoom, Ayesha] Ctr Adv Studies Engn, Dept Comp Sci, Islamabad, Pakistan.
C3 Chongqing University
RP Aqeel-ur-Rehman (corresponding author), COMSTAS Inst Informat Technol, Dept Comp Sci, Vehari, Pakistan.
EM rehmancqu@gmail.com
RI Rehman, Aqeel ur/R-4559-2018; Ullah, Sami/IAM-8005-2023; Liao,
   Xiaofeng/HPD-6655-2023
OI Rehman, Aqeel ur/0000-0002-3083-6066; 
FU National Natural Science Foundation of China [61003247, 61170249]
FX National Natural Science Foundation of China Grant Nos. provided
   financial support for the work described here. (61003247 and 61170249),
   Computer Science and Engineering Department, Chongqing University,
   People Republic of China.
CR ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   Ahmad M., 2009, Int. J. Comput. Sci. Eng., V2, P46
   Awad A, 2010, ETRI J, V32, P774, DOI 10.4218/etrij.10.1510.0063
   Baum EB, 1996, P 2 DIMACS WORKSH DN, P122
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Biham E, 1991, P 10 ANN INT CRYPT C
   Biham E, 1991, LNCS, V547, P532
   Biham E, 1993, P 12 ANN INT CRYPT C
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Fournier D, 2003, 0304059 EPRINTARXIV
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Gaborit P, 2005, THEOR COMPUT SCI, V334, P99, DOI 10.1016/j.tcs.2004.11.004
   Gotz M, 1997, IEEE T CIRCUITS-I, V44, P963, DOI 10.1109/81.633885
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   King OD, 2007, DISCRETE APPL MATH, V155, P831, DOI 10.1016/j.dam.2005.07.015
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Liu H., 2009, 9 INT C YOUNG COMP S, P3016
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Pisarchik AN, 2006, CHAOS, V16, DOI 10.1063/1.2242052
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Stojanovski T, 2001, IEEE T CIRCUITS-I, V48, P382, DOI 10.1109/81.915396
   Stojanovski T, 2001, IEEE T CIRCUITS-I, V48, P281, DOI 10.1109/81.915385
   Wang X., 2008, Electromagnetic compatibility, P1
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2011, CORR
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Xiao GZ, 2006, CHINESE SCI BULL, V51, P1413, DOI 10.1007/s11434-006-2012-5
   Zhang Q, 2009, 4 INT C BIOINSP COMP
   Zhang Q, 2014, AEU-INT J ELECTRON C, V68, P186, DOI 10.1016/j.aeue.2013.08.007
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang W, 2012, OPT COMMUN, V285, P2343, DOI 10.1016/j.optcom.2012.01.029
   Zhang YS, 2014, OPTIK, V125, P1562, DOI 10.1016/j.ijleo.2013.09.018
NR 37
TC 36
Z9 36
U1 2
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11241
EP 11266
DI 10.1007/s11042-015-2851-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900019
DA 2024-07-18
ER

PT J
AU Ding, XS
   Lei, H
   Rao, YB
AF Ding, Xianshu
   Lei, Hang
   Rao, Yunbo
TI Sparse codes fusion for context enhancement of night video surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video enhancement; Sparse codes fusion (SCF); Daytime dictionary;
   Nighttime dictionary; Mutual coherence learning (MCL); Enhanced
   background; Motion extraction
AB Fusion-based method for video enhancement has been playing a basic but significant role, which is also proved high-efficiency. Still, there are some open questions, such as lamp-off problem, over-enhanced moving objects and night shadow. To resolve the problems, a novel method-sparse codes fusion (SCF) is proposed. With plenty of samples from daytime videos and nighttime videos of the same scene, we learn and obtain a daytime dictionary and a nighttime dictionary using the proposed mutual coherence learning (MCL) algorithm. These two dictionaries are utilized for fusion and extracting context enhanced background. Moreover, we reconstruct the nighttime dictionary to get nighttime background that would be applied in motion extraction. Then the moving objects are added into the enhanced background. Extensive experimental results show a highly comprehensive description of video frames that leads to improvements over the state of the art on many usual public video datasets.
C1 [Ding, Xianshu] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 610054, Sichuan, Peoples R China.
   [Lei, Hang; Rao, Yunbo] Univ Elect Sci & Technol China, Sch Informat & Software Engn, Chengdu 610054, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China
RP Ding, XS (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 610054, Sichuan, Peoples R China.
EM smalltree_ding@126.com
FU National Science Foundation of China [61300092]; Fundamental Research
   Funds for the Central Universities [ZYGX2013J068]; Sichuan Province
   Science and Technology Support Program Project [2013GZ0151]
FX The authors would like to thank the anonymous reviewers for their
   helpful comments. This work is partly supported by National Science
   Foundation of China (Grant No. 61300092), Fundamental Research Funds for
   the Central Universities (Grant No. ZYGX2013J068), and Sichuan Province
   Science and Technology Support Program Project (Grant No. 2013GZ0151).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2012, Journal of Information Hiding and Multimedia Signal Processing
   [Anonymous], LECT NOTES COMPUT SC
   [Anonymous], P SIGGRAPH 2005
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Bennett EP, 2005, ACM T GRAPHIC, V24, P845, DOI 10.1145/1073204.1073272
   Cai YH, 2006, INT C PATT RECOG, P980
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Harandi MT, 2012, LECT NOTES COMPUT SC, V7573, P216, DOI 10.1007/978-3-642-33709-3_16
   Ilie A, 2005, INT J PATTERN RECOGN, V19, P533, DOI 10.1142/S0218001405004137
   Lee C, 2012, IEEE T IMAGE PROCESS, V21, P80, DOI 10.1109/TIP.2011.2159387
   Lin WY, 2010, IEEE T CIRC SYST VID, V20, P1057, DOI 10.1109/TCSVT.2010.2057013
   Paris S, 2012, INT C PATT RECOG, P2817
   Qinghua Ji, 2013, 2013 Fifth International Conference on Computational and Information Sciences (ICCIS 2013), P1202, DOI 10.1109/ICCIS.2013.318
   Rao YB, 2012, MULTIMED TOOLS APPL, V70, P2235
   Rao YB, 2013, ETRI J, V35, P923, DOI 10.4218/etrij.13.0212.0550
   Saponara S, 2013, J REAL-TIME IMAGE PR, V8, P111, DOI 10.1007/s11554-011-0215-8
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
   Tsai CY, 2012, IEEE T MULTIMEDIA, V14, P1140, DOI 10.1109/TMM.2012.2190390
   Vollmer C, 2013, LECT NOTES COMPUT SC, V8131, P367, DOI 10.1007/978-3-642-40728-4_46
   Wang Q, 2007, IEEE T CONSUM ELECTR, V53, P757, DOI 10.1109/TCE.2007.381756
   Yamasaki A, 2008, INT C PATT RECOG, P1267
   Zhu QD, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P6183, DOI 10.1109/WCICA.2010.5554431
NR 23
TC 6
Z9 6
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11221
EP 11239
DI 10.1007/s11042-015-2844-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900018
DA 2024-07-18
ER

PT J
AU Lopatka, K
   Kotus, J
   Czyzewski, A
AF Lopatka, K.
   Kotus, J.
   Czyzewski, A.
TI Detection, classification and localization of acoustic events in the
   presence of background noise for acoustic surveillance of hazardous
   situations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sound detection; Sound source localization; Audio surveillance
ID AUDIO CLASSIFICATION; RECOGNITION
AB Evaluation of sound event detection, classification and localization of hazardous acoustic events in the presence of background noise of different types and changing intensities is presented. The methods for discerning between the events being in focus and the acoustic background are introduced. The classifier, based on a Support Vector Machine algorithm, is described. The set of features and samples used for the training of the classifier are introduced. The sound source localization algorithm based on the analysis of multichannel signals from the Acoustic Vector Sensor is presented. The methods are evaluated in an experiment conducted in the anechoic chamber, in which the representative events are played together with noise of differing intensity. The results of detection, classification and localization accuracy with respect to the Signal to Noise Ratio are discussed. The results show that the recognition and localization accuracy are strongly dependent on the acoustic conditions. We also found that the engineered algorithms provide a sufficient robustness in moderately intense noise in order to be applied to practical audio-visual surveillance systems.
C1 [Lopatka, K.; Kotus, J.; Czyzewski, A.] Gdansk Univ Technol, Multimedia Syst Dept, Fac Elect Telecommun & Informat, Gdansk, Poland.
C3 Fahrenheit Universities; Gdansk University of Technology
RP Lopatka, K (corresponding author), Gdansk Univ Technol, Multimedia Syst Dept, Fac Elect Telecommun & Informat, Gdansk, Poland.
EM klopatka@sound.eti.pg.gda.pl; joseph@multimed.org; andcz@multimed.org
RI Czyzewski, Andrzej/JXN-0946-2024
OI Czyzewski, Andrzej/0000-0001-9159-8658
FU European Commission within FP7 project "INDECT" [218086]; European
   Regional Development Fund under the Innovative Economy Operational
   Programme, INSIGMA project [POIG.01.01.02-00-062/09]
FX Research is subsidized by the European Commission within FP7 project
   "INDECT" (Grant Agreement No. 218086). The presented work has been also
   co-financed by the European Regional Development Fund under the
   Innovative Economy Operational Programme, INSIGMA project no.
   POIG.01.01.02-00-062/09.
CR Basten T., 2007, 33 EUR ROT FOR KAZ
   Basten T., 2009, Multiple Incoherent Sound Source Localization Using a Single Vector Sensor
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cowling M, 2003, PATTERN RECOGN LETT, V24, P2895, DOI 10.1016/S0167-8655(03)00147-8
   de Bree DH, 2005, P INT C FORUM ACUSTI
   de Bree H.-E., 2003, Acoustics Australia, V31, P91
   Dennis J, 2013, PATTERN RECOGN LETT, V34, P1085, DOI 10.1016/j.patrec.2013.02.015
   Donzier A, 2005, P SOC PHOTO-OPT INS, V5778, P245, DOI 10.1117/12.607128
   George J, 2011, 14 INT C INF FUS CHI
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Tran HD, 2011, IEEE T AUDIO SPEECH, V19, P1556, DOI 10.1109/TASL.2010.2093519
   Jacobsen F, 2005, J ACOUST SOC AM, V118, P1510, DOI 10.1121/1.1984860
   Kiktova-Vozarikova E, 2013, MULTIMED TOOLS APPL
   Kim HG, 2004, IEEE T CIRC SYST VID, V14, P716, DOI 10.1109/TCSVT.2004.826766
   Kotus J, 2016, MULTIMED TOOLS APPL, V75, P10787, DOI 10.1007/s11042-014-2264-z
   Kotus J., 2010, INFORM TECHNOLOGIES, V18, P111
   KOTUS J., 2010, IEEE INT C MULT COMM, P140
   Kotus J, 2015, MULTIMED TOOLS APPL, V74, P4235, DOI 10.1007/s11042-013-1549-y
   Kotus J, 2014, MULTIMED TOOLS APPL, V68, P5, DOI 10.1007/s11042-012-1183-0
   Kotus J, 2011, COMM COM INF SC, V149, P55
   Krijnders JD, 2010, PATTERN RECOGN LETT, V31, P1552, DOI 10.1016/j.patrec.2009.11.004
   Lojka Martin, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P199
   Lopatka K, 2015, 138 AUD ENG SOC CONV
   Lopatka K, 2014, INFORM SCIENCES, V285, P223, DOI 10.1016/j.ins.2013.11.030
   Lopatka K, 2010, ADV INTEL SOFT COMPU, V80, P49, DOI 10.1007/978-3-642-14989-4_5
   Lu L, 2002, IEEE T SPEECH AUDI P, V10, P504, DOI 10.1109/TSA.2002.804546
   Machine Learning Group at University of Waikato, 2012, WAIK ENV KNOWL AN
   Mesaros A, 2010, EUR SIGNAL PR CONF, P1267
   Millet J, 2006, BATTLEFIELD ACOUSTIC
   Ntalampiras S, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/594103
   Ntalampiras S, 2011, IEEE T MULTIMEDIA, V13, P713, DOI 10.1109/TMM.2011.2122247
   Peeters G., 2004, CUIDADO Ist Project Report, V54, P1
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Raangs R., 2002, SOUND SOURCE LOCALIZ
   Rabaoui A, 2008, 2008 3RD INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING, VOLS 1-3, P594, DOI 10.1109/ISCCSP.2008.4537294
   Rabaoui A, 2008, IEEE T INF FOREN SEC, V3, P763, DOI 10.1109/TIFS.2008.2008216
   Raytheon BBN Technologies, BOOM
   Safety Dynamics Systems, SENTRI
   Temko A, 2009, PATTERN RECOGN LETT, V30, P1281, DOI 10.1016/j.patrec.2009.06.009
   Tijs E, 2010, INTERNOISE 2010
   Valenzise G, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P21, DOI 10.1109/AVSS.2007.4425280
   Wind J.W., 2009, THESIS
   Wind J.W., 2009, SOURCE LOCALIZATION
   Yoo IC, 2009, ETRI J, V31, P451, DOI 10.4218/etrij.09.0209.0104
   Zhuang XD, 2010, PATTERN RECOGN LETT, V31, P1543, DOI 10.1016/j.patrec.2010.02.005
   Zwan P., 2010, J DIGITAL FORENSIC P, V3, P33
NR 46
TC 40
Z9 42
U1 2
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10407
EP 10439
DI 10.1007/s11042-015-3105-4
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800016
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, HJ
   Guan, Y
   Liu, LJ
   Wang, FL
   Wang, L
AF Li, Haojie
   Guan, Yue
   Liu, Lijuan
   Wang, Fanglin
   Wang, Ling
TI Re-ranking for microblog retrieval via multiple graph model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Weibo retrieval; Multiple graph learning
ID RELEVANCE FEEDBACK; IMAGES
AB As a new information sharing platform, microblog has got explosive growth in recent years and has become an important source for public opinion mining. A variety of information like the reviews of brands/products or the trends of events can be socially sensed from such kind of data. However, it is still a challenging task to search relevant microblogs as the user generated content tends to be mixed with noise. Besides short text, image is getting popular in microblogs due to its power in visual information conveying. In this paper, we leverage textual and visual cues integratedly and propose a general re-ranking approach for microblog retrieval viamulti-graph semi-supervised learning. We argue that the different types of information in microblogs correspond to different relationships among microblogs and each type of the relationship can be represented as a similarity graph. We then integrate different graphs into a unified framework and solve them simultaneously for microblog re-ranking. Extensive experiments on a recently published Brand-Social-Net dataset showed the effectiveness of the proposed method and marginal improvements have been achieved in accuracy as compared to the single graph model based method.
C1 [Li, Haojie; Guan, Yue; Liu, Lijuan; Wang, Ling] Dalian Univ Technol, Sch Software, Dalian, Peoples R China.
   [Wang, Fanglin] Natl Univ Singapore, Sch Comp, Singapore, Singapore.
C3 Dalian University of Technology; National University of Singapore
RP Li, HJ (corresponding author), Dalian Univ Technol, Sch Software, Dalian, Peoples R China.
EM hjli@dlut.edu.cn; worm004@hotmail.com; liulijuan0105@qq.com;
   hardegg@gmail.com; ssdutwl@mail.dlut.edu.cn
FU Natural Science Foundation of China [61173104, 61472059]; Fundamental
   Research Funds for the Central Universities [DUT13JR03, DUT14QY03]
FX This work was supported by the Natural Science Foundation of China
   (61173104, 61472059) and the Fundamental Research Funds for the Central
   Universities (DUT13JR03, DUT14QY03).
CR Angelini M, 2013, CUMULATED RELATIVE P, P57
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI [10.1145/1899412.1899418, DOI 10.1145/1899412.1899418]
   [Anonymous], 2012, P 20 ACM INT C MULT
   Duan Y, 2010, P 23 INT C COMP LING, P295
   Frakes WB., 1992, Information retrieval: Data structures and algorithms
   Ganainy E, 2013, QCRI TREC 2013 MICRO
   Gao Y, 2014, BRAND DATA GATHERING
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Han ZY, 2012, HIT TREC 2012 MICROB
   He J., P 12 ANN ACM INT C M, P9, DOI 10.1145/1027527.1027531
   Hong RC, 2014, IEEE T CYBERNETICS, V44, P669, DOI 10.1109/TCYB.2013.2265601
   Jia D, 2011, PROC CVPR IEEE, P785, DOI 10.1109/CVPR.2011.5995516
   Li HJ, 2013, MULTIMEDIA SYST, V19, P37, DOI 10.1007/s00530-012-0265-1
   Manning C. D., 2008, Introduction to Information Retrieval, P1, DOI [10.1017/CBO9780511809071.002, DOI 10.1017/CBO9780511809071.002]
   Martins F, 2013, TREC 2013 MICROBLOG
   Naveed Nasir., 2011, Proceedings of the 20th ACM international conference on Information and knowledge management, P183
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Siddiquie B, 2011, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2011.5995329
   Tang S, 2012, IEEE T MULTIMEDIA, V14, P43, DOI 10.1109/TMM.2011.2168198
   Teevan J., 2011, P 4 ACM INT C WEB SE, P35, DOI DOI 10.1145/1935826.1935842
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Wang XG, 2011, PROC CVPR IEEE, P857, DOI 10.1109/CVPR.2011.5995399
   Wu HC, 2008, ACM T INFORM SYST, V26, P4290
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang Y, 2014, IEEE T MULTIMEDIA, V16, P1677, DOI 10.1109/TMM.2014.2323014
   Yang Y, 2011, PROC CVPR IEEE, P881, DOI 10.1109/CVPR.2011.5995499
   Yang Y, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2457450.2457456
   Yang Y, 2014, INFORM SCIENCES, V281, P601, DOI 10.1016/j.ins.2014.03.016
   Zhou DY, 2004, ADV NEUR IN, V16, P321
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 31
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 8939
EP 8954
DI 10.1007/s11042-014-2336-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500007
DA 2024-07-18
ER

PT J
AU Zhang, LY
   Denney, B
   Lu, JW
AF Zhang, Liyan
   Denney, Bradley
   Lu, Juwei
TI Sub-event recognition and summarization for structured scenario photos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Structured scenario photos; Sub-event recognition; Photo summarization
AB Structured scenario photos, referring to the images which capture important events that usually follow specific routines/structures (such as wedding ceremonies, graduation ceremonies, etc.), account for a significant proportion in personal photo collections. Conventional image analysis techniques without considering the event routines/structures are not sufficient to handle these photos. In this paper, we explore the appropriate framework to learn and utilize the specific routines for understanding these structure scenario photos. Specifically, we propose a novel framework which can systematically integrate Hidden Markov Model and Gaussian Mixture Model to recognize sub-events from structured scenario photos. Then we present a comprehensive criterion to select representative images to summarize the whole photo collection. Experimental results conducted on the real-world datasets demonstrate the superiority of our framework in both of sub-event recognition and photo summarization tasks.
C1 [Zhang, Liyan] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing, Jiangsu, Peoples R China.
   [Denney, Bradley] Canon Informat & Imaging Solut Inc, Irvine, CA USA.
   [Lu, Juwei] Nymi Inc, Toronto, ON, Canada.
C3 Nanjing University of Aeronautics & Astronautics
RP Zhang, LY (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing, Jiangsu, Peoples R China.
EM zhangliyan.uci@gmail.com
RI lu, juwei/I-4077-2016
FU National Science Foundation of China [61572252]; National Science
   Foundation of Jiangsu Province [BK20150755]
FX This work was supported in part by the National Science Foundation of
   China under Grants No. 61572252, and National Science Foundation of
   Jiangsu Province under Grants No. BK20150755.
CR CHENG WH, 2007, P 9 ACM INT WORKSH M, P95
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Denney B, 2014, USPTO application, Patent No. [US 12/906,107, 12906107]
   Gatica-Perez D, 2003, FINDING STRUCTURE HO
   Ghahramani Z, 1997, MACH LEARN, V29, P245, DOI 10.1023/A:1007425814087
   Hua X.S., 2003, P 11 ACM INT C MULTI, P490
   Jiang YG, 2015, IEEE T MULTIMEDIA, V17, P1174, DOI 10.1109/TMM.2015.2436813
   Kennedy L.S., 2008, P ACM INT C WORLD WI, P297
   Pearson K., 1905, NATURE
   Shaked D, 2005, IEEE IMAGE PROC, P841
   Sinha P, 2011, P 20 INT C COMP WORL, P127
   Sinha Pinaki., 2009, P 17 ACM INT C MULTI, P1131
   Tang J., 2009, ACM Multimedia
   Tang JH, 2014, MULTIMED TOOLS APPL, V70, P647, DOI 10.1007/s11042-011-0892-0
   Tang JH, 2012, MULTIMED TOOLS APPL, V56, P1, DOI 10.1007/s11042-011-0822-1
   Zhang L., 2013, ACM INT C MULT RETR
   Zhang L, 2011, PERCOM WORKSH
   Zhang L, 2014, Patent No. [USPTO application US 13/639,948, 13639948]
   Zhang LY, 2013, NEUROCOMPUTING, V120, P391, DOI 10.1016/j.neucom.2012.06.062
NR 19
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9295
EP 9314
DI 10.1007/s11042-016-3346-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500026
DA 2024-07-18
ER

PT J
AU Agarwal, H
   Sen, D
   Raman, B
   Kankanhalli, M
AF Agarwal, Himanshu
   Sen, Debashis
   Raman, Balasubramanian
   Kankanhalli, Mohan
TI Visible watermarking based on importance and just noticeable distortion
   of image regions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information-content-weighted-structural-similarity-index (IW-SSIM); Just
   noticeable distortion (JND); Visual saliency; Visible watermarking; Eye
   fixation density
AB Visible watermarking is the process of embedding data (watermark) into a multimedia object (video/image) such that the embedded watermark is perceptible to a human observer. Many times, visible watermarks occlude important portion of multimedia objects. This paper introduces a visible watermarking algorithm to embed a binary logo watermark at N non-overlapping positions in an image such that important portions of the image are not occluded. The important portions are found through visual saliency computation or available human eye fixation density maps. In the proposed visible watermarking, just noticeable distortion is used to adaptively filter the watermark embedding energy based on the image content. A mathematical model in terms of information-content-weighted-structural-similarity-index and visual importance is proposed to find optimal watermark embedding strength. We tested the algorithm on several color images of different sizes and on several binary watermarks of different sizes and found the results to be very promising as per the requirements in visible watermarking. When compared to the state-of-the-art, we also found that the proposed technique does better in not hiding the details of any test image.
C1 [Agarwal, Himanshu] Indian Inst Technol Roorkee, Dept Math, Roorkee 247667, Uttar Pradesh, India.
   [Sen, Debashis; Kankanhalli, Mohan] Natl Univ Singapore, Sch Comp, Singapore, Singapore.
   [Raman, Balasubramanian] Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee 247667, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; National University of Singapore; Indian
   Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Agarwal, H (corresponding author), Indian Inst Technol Roorkee, Dept Math, Roorkee 247667, Uttar Pradesh, India.
EM himanshu203@gmail.com; send@comp.nus.edu.sg; balarfma@iitr.ac.in;
   mohan@comp.nus.edu.sg
RI Agarwal, Himanshu/D-2825-2017; Kankanhalli, Mohan/Q-9284-2019; Sen,
   Debashis/R-3236-2016
OI Agarwal, Himanshu/0000-0002-9950-7447; Kankanhalli,
   Mohan/0000-0002-4846-2015; Sen, Debashis/0000-0002-9756-1191
FU University Grant Commission (UGC) of New Delhi, India
FX One of the authors, Himanshu Agarwal, acknowledges the University Grant
   Commission (UGC) of New Delhi, India for granting him a scholarship
   under the JRF scheme for his research, and Maharaja Agrasen Technical
   Education Society of India for providing facilities for research.
CR [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Chandler D. M., 2013, ISRN SIGNAL PROCESS, V2013
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Cox IJ., 2007, DIGITAL WATERMARKING
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hsu FH, 2014, J SUPERCOMPUT, V1-22
   Hu Y, 2006, IEEE T CIRC SYST VID, V16, P1423, DOI 10.1109/TCSVT.2006.884011
   Huang BB, 2006, IEEE MULTIMEDIA, V13, P60, DOI 10.1109/MMUL.2006.23
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kankanhalli MS, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P568, DOI 10.1109/MMCS.1999.779263
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Lin PY, 2014, J SYST SOFTWARE, V95, P194, DOI 10.1016/j.jss.2014.04.038
   Liu TY, 2010, IEEE T IMAGE PROCESS, V19, P1224, DOI 10.1109/TIP.2010.2040757
   Lumini A, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P967, DOI 10.1109/ICME.2004.1394363
   Memon N, 1998, COMMUN ACM, V41, P34
   Mintzer F, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P9, DOI 10.1109/ICIP.1997.631957
   Mohanty SP, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1029, DOI 10.1109/ICME.2000.871535
   Qi HY, 2008, SIGNAL PROCESS, V88, P174, DOI 10.1016/j.sigpro.2007.07.020
   Tsai HM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2106
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Yang H. R., 2013, MULTIMED TOOLS APPL, P1
   Yeung MM, 1997, 1997 IEEE FIRST WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P357, DOI 10.1109/MMSP.1997.602661
NR 23
TC 14
Z9 16
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7605
EP 7629
DI 10.1007/s11042-015-2685-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600008
DA 2024-07-18
ER

PT J
AU Aujeszky, T
   Eid, M
AF Aujeszky, Tamas
   Eid, Mohamad
TI A gesture recogintion architecture for Arabic sign language
   communication system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia Systems and Tools; Sign language Communication Systems;
   Gesture recognition; Avatar animation; Usability study
ID RECOGNITION
AB Sign language is the most natural and expressive way for the hearing impaired to communicate. With technological advances in multimedia systems and applications, technology-mediated sign language communication systems have long attracted researchers to enhance the communication capabilities for the speech and hearing impaired, promising improved social opportunities and integration. This paper introduces a framework for Arabic sign language communication using Microsoft Kinect device. The merit of the proposed framework is twofold: first, the framework supports an affordable and easily deployable real-time communication system using Arabic sign language, and secondly, it provides a real-time feedback about the signer performance via real-time avatar animation. A prototype application is developed to demonstrate the merits of the proposed framework. Experimental results show that the proposed Arabic sign language method enjoys a sign detection rate of 96 %. Furthermore, the average task completion time to complete an Arabic sign was about 2.2 s. This implies that the proposed method can be used to create a real-time Arabic sign language communication system. Finally, participants of the study highlighted that the proposed system is user-friendly and easy to use, and can be used at low cost to recognize and display Arabic signs.
C1 [Aujeszky, Tamas] New York Univ Abu Dhabi, New York, NY USA.
   [Eid, Mohamad] New York Univ Abu Dhabi, Div Engn, Elect Engn, New York, NY USA.
RP Eid, M (corresponding author), New York Univ Abu Dhabi, Div Engn, Elect Engn, New York, NY USA.
EM mohamad.eid@nyu.edu
CR Agarwal Anant, 2013, 2013 Sixth International Conference on Contemporary Computing (IC3), P181, DOI 10.1109/IC3.2013.6612186
   [Anonymous], QUICK REF KIN 1 VS K
   [Anonymous], 2008, The global burden of disease: 2004 update, P35
   [Anonymous], BEST DEV PLATF CREAT
   Assaleh K, 2008 5 INT S MECH IT, P1
   Buttussi F, 2007, WEB3D 2007 - 12TH INTERNATIONAL CONFERENCE ON 3D WEB TECHNOLOGY, PROCEEDINGS, P61
   El-Bendary Nashwa, 2011, International Journal of Computer Information Systems and Industrial Management Applications, V3, P498
   Halawani S.M., 2012, Int. J. Inf. Sci. Educ., V2, P13
   Jiang YJ, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ENGINEERING (CSE), P21, DOI 10.1109/CSE.2014.38
   Memis A, 2013, P 21 IEEE C SIGN P C, P1
   Memis A, 2013 21 SIGN PROC CO, P1
   Mohammed M., 2014, MULT SYST SIGN DEV S, P1, DOI DOI 10.1109/ICI-CDT.2014.6838605
   Mohandes M, 2014, IEEE T HUM-MACH SYST, V44, P551, DOI 10.1109/THMS.2014.2318280
   Mohandes M, 2007, 2007 21 INT C ADV IN, P272
   Oszust M, 2013, C HUM SYST INTERACT, P219, DOI 10.1109/HSI.2013.6577826
   Sagawa H, 2012 P 10 ACM INT C, P137
   Samir A, 2012, 2012 SEVENTH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES'2012), P117, DOI 10.1109/ICCES.2012.6408496
   Shanableh T, 2007, EURASIP J IMAGE VIDE, DOI 10.1155/2007/87929
   Sun C, 2013, IEEE IMAGE PROC, P4190, DOI 10.1109/ICIP.2013.6738863
   Sun C, 2013, IEEE T CYBERNETICS, V43, P1418, DOI 10.1109/TCYB.2013.2265337
   Tennant, 1998, AM SIGN LANGUAGE HAN, P407
   Tolba M. F., 2012, P 8 INT C INF SYST I, P14
   Tolba MF, 2012 8 INT C INF SYS, pMM
   Vatavu RD, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P273
   Verma HV, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P96, DOI 10.1109/ICIIP.2013.6707563
   Yang Q, 2010 5 IEEE C IND EL, P1537
NR 26
TC 13
Z9 13
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8493
EP 8511
DI 10.1007/s11042-015-2767-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300016
DA 2024-07-18
ER

PT J
AU Espejel-Trujillo, A
   Nakano-Miyatake, M
   Olivares-Mercado, J
   Perez-Meana, H
AF Espejel-Trujillo, Angelina
   Nakano-Miyatake, Mariko
   Olivares-Mercado, Jesus
   Perez-Meana, Hector
TI A cheating-prevention mechanism for hierarchical secret-image-sharing
   using robust watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret sharing; Secret image sharing; Hierarchical secret image sharing;
   Cheating prevention; Watermarking; Authentication
ID AUTHENTICATION; STEGANOGRAPHY; SCHEME
AB Secret image sharing (SIS) techniques allow visual secrets to be shared between multiple people. These techniques require a predetermined access structure to be satisfied to reveal the secret. SIS schemes have the potential to increase security in several applications including telemedicine and image transfer in the cloud computing environment, providing controlled access to confidential images. To date, a significant number of SIS schemes with various properties and access structures have been proposed. Among them, hierarchical SIS (HSIS) is considered foremost since almost all organizations and associations manage their secret information in a hierarchical manner. However, the HSIS scheme tends to suffer from security flaws as the secret image can often be visually leaked, even when the access structure is not properly satisfied. To avoid this security flaw, we propose a cheating prevention mechanism by introducing a robust watermarking technique based on the Quantization Index Modulation-Dither Modulation (QIM-DM) algorithm in the discrete cosine transform (DCT) domain. Experimental results demonstrate the superior effectiveness of our proposed cheating prevention mechanism. Furthermore, our approach retains all of the desirable properties of the HSIS scheme.
C1 [Espejel-Trujillo, Angelina; Nakano-Miyatake, Mariko; Olivares-Mercado, Jesus; Perez-Meana, Hector] Inst Politecn Nacl, Mech Elect Engn Sch, Postgrad & Res Sect, Av Santa Ana 1000, Mexico City, DF, Mexico.
C3 Instituto Politecnico Nacional - Mexico
RP Nakano-Miyatake, M (corresponding author), Inst Politecn Nacl, Mech Elect Engn Sch, Postgrad & Res Sect, Av Santa Ana 1000, Mexico City, DF, Mexico.
EM angelina.et@gmail.com; mnakano@ipn.mx; jolivares@ipn.mx; hmperezm@ipn.mx
RI Espejel Trujillo, Angelina/F-5139-2018; Perez-Meana, Hector/N-1624-2019;
   Nakano, Mariko/N-4075-2019; Olivares-Mercado, Jesus/G-3829-2018; Nakano,
   Mariko/O-2954-2017
OI Espejel Trujillo, Angelina/0000-0001-6563-1346; Perez-Meana,
   Hector/0000-0002-7786-2050; Olivares-Mercado, Jesus/0000-0002-0337-5364;
   Nakano, Mariko/0000-0003-1346-7825
CR Alvarez G, 2008, INFORM SCIENCES, V178, P4382, DOI 10.1016/j.ins.2008.07.010
   Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Eslami Z, 2010, PATTERN RECOGN, V43, P397, DOI 10.1016/j.patcog.2009.06.007
   Guo C, 2014, MULTIMED TOOLS APPL, V72, P2195, DOI 10.1007/s11042-013-1510-0
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin PY, 2010, PATTERN RECOGN LETT, V31, P1887, DOI 10.1016/j.patrec.2010.01.019
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Tassa T, 2007, J CRYPTOL, V20, P237, DOI 10.1007/s00145-006-0334-8
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Ulutas G, 2013, PATTERN RECOGN LETT, V34, P283, DOI 10.1016/j.patrec.2012.10.017
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
NR 16
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7855
EP 7873
DI 10.1007/s11042-015-2701-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600019
DA 2024-07-18
ER

PT J
AU Li, C
   Feng, ZY
   Han, YH
AF Li, Chao
   Feng, Zhiyong
   Han, Yahong
TI Image attribute learning with ontology guided fused lasso
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image attribute learning; Ontology; Graph-guided fused lasso; Transfer
   learning
ID OBJECT CLASSES; CLASSIFICATION
AB Extended from the traditional pure statistical learning methods, we propose to augment the statistical learning methods with ontology and apply this idea for image attribute learning. In order to capture structural information among attributes, the graph-guided fused lasso model is adopted and improved by a new distance metric based on WordNet. The novelty of our method is that we find the semantic correlation with the ontology-guided attribute space and integrate inter-attribute similarity information into the learning model. The hierarchy of ImageNet is exploited to define the image attributes and a dataset from ImageNet including over 30,000 images is collected. The experimental results show that this method can both improve the accuracy and accelerate the algorithm convergency. Moreover, the learned semantic correlation owns transfer ability to related applications.
C1 [Li, Chao; Feng, Zhiyong; Han, Yahong] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
   [Han, Yahong] Tianjin Univ, Tianjin Key Lab Cognit Comp & Applicat, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin University
RP Han, YH (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.; Han, YH (corresponding author), Tianjin Univ, Tianjin Key Lab Cognit Comp & Applicat, Tianjin, Peoples R China.
EM qizuma@tju.edu.cn; zyfeng@tju.edu.cn; yahong@tju.edu.cn
RI Gulliver, Aaron/K-7925-2012
FU NSFC [61202166, 61472276]; Ministry of Education of China
   [20120032120042]
FX This work was partly supported by the NSFC (under Grant 61202166,
   61472276) and Doctoral Fund of Ministry of Education of China (under
   Grant 20120032120042).
CR [Anonymous], P ACM MULT C MM 12 N
   [Anonymous], IMAGE RANKING RETRIE
   [Anonymous], 2013, P INT ACM C MULTIMED, DOI DOI 10.1145/2502081.2502093
   [Anonymous], TRENDS TOPICS COMPUT
   Benitez AB, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P613
   Breen C, 2002, 13TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P98
   Chen X, 2012, ANN APPL STAT, V6, P719, DOI 10.1214/11-AOAS514
   CLANCEY WJ, 1993, INT J INTELL SYST, V8, P33, DOI 10.1002/int.4550080104
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fan JP, 2008, IEEE T IMAGE PROCESS, V17, P407, DOI 10.1109/TIP.2008.916999
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Ferrari V., 2007, P 20 INT C NEUR INF, P433
   GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008
   Guarino N, 1995, INT J HUM-COMPUT ST, V43, P625, DOI 10.1006/ijhc.1995.1066
   Hwang SJ, 2011, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2011.5995543
   Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353
   JOLICOEUR P, 1984, COGNITIVE PSYCHOL, V16, P243, DOI 10.1016/0010-0285(84)90009-4
   Kankuekul P, 2012, PROC CVPR IEEE, P3657, DOI 10.1109/CVPR.2012.6248112
   Kim S, 2009, BIOINFORMATICS, V25, pI204, DOI 10.1093/bioinformatics/btp218
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Li LJ, 2009, PROC CVPR IEEE, P2036, DOI 10.1109/CVPRW.2009.5206718
   Mahajan D, 2011, IEEE I CONF COMP VIS, P1227, DOI 10.1109/ICCV.2011.6126373
   Maillot NE, 2008, IMAGE VISION COMPUT, V26, P102, DOI 10.1016/j.imavis.2005.07.027
   Marszalek Marcin, 2007, CVPR '07. IEEE Conference on Computer Vision and Pattern Recognition, P1
   Mezaris V, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P511
   Sharmanska V, 2012, LECT NOTES COMPUT SC, V7576, P242, DOI 10.1007/978-3-642-33715-4_18
   Shi R., 2007, Proceedings of the 15th International Conference on Multimedia, P341
   Srikanth M., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P552, DOI 10.1145/1076034.1076128
   Tibshirani R, 2011, J R STAT SOC B, V73, P273, DOI 10.1111/j.1467-9868.2011.00771.x
   Tousch AM, 2012, PATTERN RECOGN, V45, P333, DOI 10.1016/j.patcog.2011.05.017
   Wang CH, 2009, INT CONF ACOUST SPEE, P3709, DOI 10.1109/ICASSP.2009.4960432
   Wang M, 2010, IEEE T MULTIMEDIA, V12, P829, DOI 10.1109/TMM.2010.2055045
   Wang Y, 2010, LECT NOTES COMPUT SC, V6315, P155, DOI 10.1007/978-3-642-15555-0_12
   Yu FLX, 2013, PROC CVPR IEEE, P771, DOI 10.1109/CVPR.2013.105
   Yu FX, 2012, PROC CVPR IEEE, P2949, DOI 10.1109/CVPR.2012.6248023
   Yu XD, 2010, LECT NOTES COMPUT SC, V6315, P127
NR 38
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 7029
EP 7043
DI 10.1007/s11042-015-2630-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400017
DA 2024-07-18
ER

PT J
AU Liu, SF
   Cheng, JH
   Chen, WJ
AF Liu, Shuo-Fang
   Cheng, Jui-Hung
   Chen, Wan-Jiun
TI A study of product experience obtained from multimodal interactive
   displays
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive display; Multimedia interactive system; Multimedia
   cognition; User experience; Multi-sensory mode
ID OBJECT RETRIEVAL
AB Experiencing a product by human-computer interactions can effectively convey valid information to users, and a surreal experience can be simulated by multi-sensory interactions. The effects of multimodal interactive displays on the cognition of products have been investigated in this study. The effects of multimodal human-computer interactions on multi-sensory modal applications have also been investigated by a questionnaire survey. And the effect of multimodal interactive displays on users' cognition can be further realized. The results indicated that the exhibit scenario display can assist users in simulating the real feeling of usage and understanding the displayed products. For the feedback stereoscopic display, it is harder for users to perceive the authenticity of product usage. For the simulation of reality, external links supply more product information, and users' cognition of products has been strengthened. The panoramic view is for the display only but fails to assist users in determining the quality of products.
C1 [Liu, Shuo-Fang; Cheng, Jui-Hung; Chen, Wan-Jiun] Natl Cheng Kung Univ, Dept Ind Design, Tainan 701, Taiwan.
C3 National Cheng Kung University
RP Liu, SF (corresponding author), Natl Cheng Kung Univ, Dept Ind Design, Tainan 701, Taiwan.
EM liusf@mail.ncku.edu.tw; rick.cheng88@gmail.com; ms159357@hotmail.com
FU National Science Council of Republic of China [NSC 99-2221-E-006-168]
FX The expenditure of this study is supported by the National Science
   Council of Republic of China under the project number of NSC
   99-2221-E-006-168.
CR [Anonymous], 2003, Funology: From Usability to Enjoyment vol, DOI [DOI 10.1007/1-4020-2967-5_5, 10.1007/1-4020-2967-5_5]
   Austin KA, 2009, COMPUT EDUC, V53, P1339, DOI 10.1016/j.compedu.2009.06.017
   Bruno F, 2010, INT J HUM-COMPUT ST, V68, P254, DOI 10.1016/j.ijhcs.2009.12.004
   Chang D, 2009, TECHNOL MUSEUM REV, V13, P1
   Charfi S, 2007, LECT NOTES COMPUT SC, V4849, P70
   Chen F, 2006, MULTIMODAL INTERACTI, P212
   Chen LF, 2006, P S INF MAN RES APPL, P135
   Fiore AM, 2005, PSYCHOL MARKET, V22, P669, DOI 10.1002/mar.20079
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gosling DC, 1990, MUSEOL Q, V4, P49
   Grundy SM, 1999, J AM COLL CARDIOL, V34, P1348, DOI 10.1016/S0735-1097(99)00387-3
   Hassenzahl M, 2010, INTERACT COMPUT, V22, P353, DOI 10.1016/j.intcom.2010.04.002
   Jhang HM, 1994, PRACTICE DISPLAY DES
   Kaplan AM, 2009, BUS HORIZONS, V52, P563, DOI 10.1016/j.bushor.2009.07.002
   Kim JH, 2007, J RETAIL CONSUM SERV, V14, P95, DOI 10.1016/j.jretconser.2006.05.001
   Lin MH, 2001, J DES, V7, P1
   Lucquiaud V, 2005, THESIS, DOI University of Poitiers
   Mayer RE, 2002, PSYCHOL LEARN MOTIV, V41, P85, DOI 10.1016/S0079-7421(02)80005-6
   Messinger PR, 2009, DECIS SUPPORT SYST, V47, P204, DOI 10.1016/j.dss.2009.02.014
   O'Brien HL, 2010, INTERACT COMPUT, V22, P344, DOI 10.1016/j.intcom.2010.04.001
   Olson J.C., 1972, 3 ANN C ASS CONSUMER, P167
   Oviatt S., 2003, HUM FAC ER, P286
   Pegler M., 2001, VISUAL MERCHANDISING
   Reddy BS, 2010, APPL SOFT COMPUT, V10, P567, DOI 10.1016/j.asoc.2009.08.026
   RICHARDSON PS, 1994, J MARKETING, V58, P28, DOI 10.2307/1251914
   Sen S., 2002, Journal of Retailing and Consumer Services, V9, P277, DOI DOI 10.1016/S0969-6989(01)00037-6
   Shen ES, 2000, J ED MEDIA LIB SCI, V37, P275
   Then N.K., 1999, J FAMILY CONSUMER SC, V91, P65
   Xu X., 2001, THESIS
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
NR 31
TC 1
Z9 2
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6143
EP 6172
DI 10.1007/s11042-015-2564-y
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700006
DA 2024-07-18
ER

PT J
AU Weng, SW
   Pan, JS
AF Weng, Shaowei
   Pan, Jeng-Shyang
TI Reversible watermarking based on two embedding Schemes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible watermarking; Two embedding Schemes; Local
   variance-controlled mechanism; High-performance predictor; Embedding
   strategy
ID DIFFERENCE EXPANSION; IMAGE WATERMARKING; ALGORITHM
AB Two different embedding schemes are presented in this paper. One aims to increase rate-distortion performance at low embedding rates. It will increase performance at low embedding rates from the following three main aspects: 1) a local variance-controlled mechanism, 2) a better predictor and 3) a new embedding scheme which can decrease the number of the pixels to be modified on the basis of providing a certain embedding capacity. Since the first scheme is only to provide low embedding rate with high visual quality, another scheme is designed to achieve higher embedding rate with good visual quality. In the second scheme, the center pixel of a three-pixel set is the prediction of a pixel, and thus any modification to it is meaningless. Each three-pixel set contains two differences. Based on the fact that the center pixel can not be modified, the remaining two pixels must be modified so that both of difference are shifted by 1. For instance, if both of pixels can carry 1-bit watermark and to-be-embedded bits are both 1, then two pixels must be shifted left or right by 1. Since we can not shift two difference by modifying only the center pixel, the distortion is high. To decrease distortion, the possibility that two bits are both equal to 1 is discarded in this paper. Experimental results also demonstrate the proposed method is effective.
C1 [Weng, Shaowei] Guangdong Univ Technol, Sch Informat Engn, Guangzhou, Peoples R China.
   [Pan, Jeng-Shyang] Harbin Inst Technol Shenzhen, Grad Sch, Shenzhen, Peoples R China.
C3 Guangdong University of Technology; Harbin Institute of Technology
RP Weng, SW (corresponding author), Guangdong Univ Technol, Sch Informat Engn, Guangzhou, Peoples R China.
EM wswweiwei@126.com
RI Pan, Jeng-Shyang/AEO-3450-2022
OI Pan, Jeng-Shyang/0000-0002-3128-9025
FU National NSF of China [61201393, 61272498, 61001179]; New Star of Pearl
   River on Science and Technology of Guangzhou [2014J2200085]
FX This work was supported in part by National NSF of China (No. 61201393,
   No. 61272498, No. 61001179), New Star of Pearl River on Science and
   Technology of Guangzhou (No. 2014J2200085).
CR Alattar AM, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P377
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Alattar AM, 2003, IEEE IMAGE PROC, P501
   Celik MU, 2005, IEEE T IMAGE PROCESS, V12, P157
   Coatrieux G, 2009, IEEE T INF TECHNOL B, V13, P158, DOI 10.1109/TITB.2008.2007199
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Hong W., 2010, EURASIP J ADV SIGNAL
   Hong W, 2013, OPT COMMUN, V291, P87, DOI 10.1016/j.optcom.2012.10.081
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin CC, 2008, PATTERN RECOGN, V41, P1415, DOI 10.1016/j.patcog.2007.09.005
   Lin S. L., 2013, J INF HIDING MULTIME, V1, P19
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Marin J., 2014, J INFORM HIDING MULT, V5, P451
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, J SYST SOFTWARE, V86, P2700, DOI 10.1016/j.jss.2013.05.077
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang X, 2010, P ICIP
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Weng SW, 2009, IET ELECT LETT, V1, P91
   Weng SW, 2008, IEEE SIG PROCESS LET, V45, P1022
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Xuan GR, 2004, P IWDW, V5, P23
NR 41
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 7129
EP 7157
DI 10.1007/s11042-015-2639-9
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400022
DA 2024-07-18
ER

PT J
AU Aherrahrou, N
   Tairi, H
AF Aherrahrou, N.
   Tairi, H.
TI The efficiency of PDE decomposition in images watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; DCT; PDE; FABEMD
ID SPECTRUM
AB The Discrete Cosine Transform (DCT) based watermarking scheme is a common and popular technique that has been used for long time for image watermarking. In this work, we aimed to further improve the commonly used DCT based watermarking method by combining the DCT with the PDE (Partial Differential Equation) method or with the FABEMD (Fast and Adaptive Bidimensional Empirical Mode Decomposition). Our experimental results and comparison analysis for the two proposed FABEMD-DCT and PDE-DCT methods demonstrated a better performance in terms of invisibility and the robustness of the watermark compared to some DCT based watermarking schemes. Furthermore, our method based on DCT and PDE model shows highest performance compared to other methods.
C1 [Aherrahrou, N.; Tairi, H.] Univ Sidi Mohamed Ben Abdellah, Dept Informat, LIIAN, BP 1796Atlas Fez, Fes 30000, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP Aherrahrou, N (corresponding author), Univ Sidi Mohamed Ben Abdellah, Dept Informat, LIIAN, BP 1796Atlas Fez, Fes 30000, Morocco.
EM noura.ah@hotmail.fr
OI Tairi, Hamid/0000-0002-5445-0037
CR Aherrahrou Noura, 2012, Image and Signal Processing. Proceedings 5th International Conference, ICISP 2012, P307, DOI 10.1007/978-3-642-31254-0_35
   Aherrahrou N, 2014, LECT NOTES COMPUT SC, V8509, P304, DOI 10.1007/978-3-319-07998-1_35
   Al-Haj Ali, 2007, Journal of Computer Sciences, V3, P740, DOI 10.3844/jcssp.2007.740.746
   Amirgholipour SK., 2009, JDCTA, V3, P42, DOI DOI 10.4156/JDCTA.VOL3.ISSUE2.AMIRGHOLIPOUR
   Aujol JF, 2005, INT J COMPUT VISION, V63, P85, DOI 10.1007/s11263-005-4948-3
   Bhuiyan S, 2008, EURASIP J ADV SIG PR, V2008, P164
   Bhuiyan SMA, 2008, INT CONF ACOUST SPEE, P1313, DOI 10.1109/ICASSP.2008.4517859
   Bi N, 2007, IEEE T IMAGE PROCESS, V16, P1956, DOI 10.1109/TIP.2007.901206
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Deng C, 2009, SIGNAL PROCESS, V89, P1531, DOI 10.1016/j.sigpro.2009.02.005
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P278, DOI 10.1109/TSMCC.2009.2037512
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   Huang NE, 1999, ANNU REV FLUID MECH, V31, P417, DOI 10.1146/annurev.fluid.31.1.417
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Lin SD, 2010, COMPUT STAND INTER, V32, P54, DOI 10.1016/j.csi.2009.06.004
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Nikolaidis A, 2001, IEEE T IMAGE PROCESS, V10, P1726, DOI 10.1109/83.967400
   Parthasarathy AK, 2007, IEEE T BROADCAST, V53, P468, DOI 10.1109/TBC.2007.894947
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Riffi J, 2014, MULTIDIM SYST SIGN P, P1
   Tewari TK, 2010, INT J COMPUT APPL, V3
   Vikas S, 2007, IAENG INT J COMPUT S, V34, P1
   Zebbiche K, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/918601
NR 24
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4593
EP 4614
DI 10.1007/s11042-015-2494-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700021
DA 2024-07-18
ER

PT J
AU Zhang, XM
   Li, ZJ
   Lv, XQ
   Chen, XM
AF Zhang, Xiaoming
   Li, Zhoujun
   Lv, Xueqiang
   Chen, Xiaoming
TI Integrating multiple types of features for event identification in
   social images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image tag; Feature correlation; Topic detection; Event identification
AB With the rapidly increasing popularity of social media sites, a large amount of user-generated data has been injected into the web. The data include a wide variety of real-world events. As a consequence, especially for social multimedia objects, it has become increasingly difficult to allow the browsing and organization of multimedia collections in a more effective manner. The approach we propose in this study addresses this problem, thus enabling the browsing and organization of multimedia collections in a natural way, i.e., by events. There have been some research studies on this problem. However, most of the previous approaches merge multiple types of features (e.g., textual content, visual content, user information and temporal information) of social media using a relatively simple mechanism. In this study, we merge multiple types of features in an integrated manner to identify the event associated with user-contributed social multimedia objects. We exploit the correlations between different types of features, i.e., textual content, visual content, user information and temporal information, to classify new social multimedia objects into their corresponding event categories. We accomplish this through a feature correlation graph (FCG) that uses features as nodes and the correlations among these features as edges for each event and individual multimedia object. We then employ a probabilistic model based on Markov random field to connect each new multimedia object with the correct event. We evaluate the algorithm on large-scale, real-world datasets of event images downloaded from Flickr, and the experimental results confirm the superiority of our approach over state-of-the-art approaches.
C1 [Zhang, Xiaoming; Li, Zhoujun; Chen, Xiaoming] Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
   [Li, Zhoujun] Beihang Univ, State Key Lab Software Dev Environm, Beijing 100191, Peoples R China.
   [Lv, Xueqiang] Beijing Key Lab Internet Culture & Digital Dissem, Beijing, Peoples R China.
C3 Beihang University; Beihang University
RP Zhang, XM (corresponding author), Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
EM yolixs@buaa.edu.cn; lxq@bistu.edu.cn
RI chen, xia/GXM-5435-2022; chen, xi/GXH-3653-2022; Chen,
   Xiao/JBJ-7561-2023; chen, xia/GYR-3948-2022
OI Chen, Xiao/0000-0002-9797-8384; Li, Zhoujun/0000-0002-9603-9713
FU National Natural Science Foundation of China [61170189, 61202239,
   61003111]; Fundamental Research Funds for the Central Universities;
   Opening Project of Beijing Key Laboratory of Internet Culture and
   Digital Dissemination Research [ICDD201403]
FX This work was supported by the National Natural Science Foundation of
   China (NO. 61170189, NO. 61202239 and NO. 61003111), the Fundamental
   Research Funds for the Central Universities, and the Opening Project of
   Beijing Key Laboratory of Internet Culture and Digital Dissemination
   Research (NO. ICDD201403).
CR Ah-Pine J, 2009, MULTIMED TOOLS APPL, V42, P31, DOI 10.1007/s11042-008-0246-8
   Amigó E, 2009, INFORM RETRIEVAL, V12, P461, DOI 10.1007/s10791-008-9066-8
   [Anonymous], 2011, P 24 CVPR
   [Anonymous], 2005, P 22 INT C MACH LEAR, DOI DOI 10.1145/1102351.1102418?CASA_TOKEN=93GP6KZPVIEAAAAA%3AR7O8Y2ERGYVAOKETYDCVMLZLU_KTH5VCLYIHYXQ9A0TIFR7EEYRELYJWHASDPNQNHO34TEDNNNK
   [Anonymous], P INT WORLD WID WEB
   Bao B-K, 2013, P ACM INT C MULT RET
   Becker H, 2010, P INT C WEB SEARCH D
   Becker H, 2010, P 3 ANN WORKSH SEARC
   Blake A, 2011, MARKOV RANDOM FIELDS FOR VISION AND IMAGE PROCESSING, P1
   Brenner M, 2013, P ACM INT C MULT RET
   Budanitsky A, 2006, COMPUT LINGUIST, V32, P13, DOI 10.1162/coli.2006.32.1.13
   Chen L, 2009, P C INF KNOWL MAN CI
   Clinchant S, 2011, P 1 ACM INT C MULT R, P44
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cui B, 2010, P ACM C MAN DAT SIGM
   Feng H, 2004, P 12 ANN ACM INT C M
   Firan CS, 2010, P C INF KNOWL MAN CI
   He X, 2004, MSRTR200438
   Ji Ming, 2011, P ACM INT C KNOWL DI
   Jiang J, 1997, INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, 1997 DIGEST OF TECHNICAL PAPERS, P94
   Kannan A, 2011, P IEEE INT C DAT MIN
   Kindermann R., 1980, Markov random fields and their applications, V547, DOI DOI 10.1090/CONM/001
   Kumaran G, 2004, P ACM INT C INF RETR
   Lafferty John, 2001, INT C MACH LEARN ICM
   Li Z, 2005, P ACM INT C INF RETR
   Liu H, 2004, P ACM INT WORKSH MUL
   Luo J, 2008, P ACM INT C MULT MM
   Metzler D, 2005, P ACM INT C INF RETR
   Pan J-Y, 2004, P ACM INT C KNOWL DI
   Ruocco M, 2012, MULTIMED TOOLS APPL, P1
   Shen Y, 2010, P ACM INT C MULT MM
   Strehl A, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P93, DOI 10.1162/153244303321897735
   Suchanek FM, 2007, P INT WORLD WID WEB
   Wang X, 2006, P ACM INT C INF RETR
   Wu L, 2007, P INT WORKSH MULT IN
   Yang Y, 1998, P ACM INT C INF RETR
   Yang YM, 1999, IEEE INTELL SYST APP, V14, P32, DOI 10.1109/5254.784083
   Zhang K, 2007, P ACM INT C INF RETR
   Znaidia A, 2012, P 2 ACM INT C MULT R
   Zwol RV, 2008, P ACM INT C MULT INF
NR 40
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3301
EP 3322
DI 10.1007/s11042-014-2436-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600018
DA 2024-07-18
ER

PT J
AU Xu, WW
   Chen, YW
AF Xu, Weiwei
   Chen, Yaowu
TI Error resilience video coding parameters and mechanisms selection with
   End-to-End rate-distortion analysis at frame level
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video coding; Error resilient; End-to-End distortion; Rate-distortion
   optimization; Reference frame selection; Redundant picture
ID MOTION-COMPENSATED PREDICTION; ALLOCATION; EFFICIENCY; H.264/AVC
AB To improve the quality of video transmission, a fast error resilience coding method based on frame level rate-distortion analysis is proposed. To constrain the accumulated error propagation distortion and error concealment distortion simultaneously, reference frame selection and intra/inter mode decision are jointly used with redundant pictures. An adaptive multiple redundant picture (AMRP) coding mechanism is used for redundant picture coding with the adaptively estimated number of redundant pictures and encoding parameter for each specific redundant picture. The encoding parameters of different frames are adjusted based on the distortion propagation. We propose a statistical model for efficiently estimating the distortion and rate of the primary and the redundant picture. The total distortion and rate of the primary and the redundant picture are then formulated as a function of the quantization parameter, the temporal prediction distance, and the error resilient configuration. Lastly, the end-to-end rate-distortion optimized selection of the encoding parameters and coding structure is efficiently performed considering error propagation. Experimental results demonstrate that the proposed algorithm exhibits significant performance gains over the state-of-the-art error-resilient encoding methods.
C1 [Xu, Weiwei; Chen, Yaowu] Zhejiang Univ, Inst Adv Digital Technol & Instrument, Hangzhou 310003, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Xu, WW (corresponding author), Zhejiang Univ, Inst Adv Digital Technol & Instrument, Hangzhou 310003, Zhejiang, Peoples R China.
EM xuweiweimilk@zju.edu.cn; cyw@mail.bme.zju.edu.cn
FU project of Key Scientific and Technological Innovation Team of Zhejiang
   Province [2011R09021-06]; Fundamental Research Funds for the Central
   Universities, China
FX This work was supported by the project of Key Scientific and
   Technological Innovation Team of Zhejiang Province, (Grant No.
   2011R09021-06), the Fundamental Research Funds for the Central
   Universities, China.
CR Chen ZF, 2012, IEEE T IMAGE PROCESS, V21, P1123, DOI 10.1109/TIP.2011.2168411
   Ferré P, 2010, SIGNAL PROCESS-IMAGE, V25, P163, DOI 10.1016/j.image.2009.12.005
   Frossard P, 2001, IEEE T CIRC SYST VID, V11, P989, DOI 10.1109/76.946516
   Girod B, 2000, IEEE T IMAGE PROCESS, V9, P173, DOI 10.1109/83.821595
   Haskell P., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P545, DOI 10.1109/ICASSP.1992.226155
   Katz B, 2007, IEEE T BROADCAST, V53, P308, DOI 10.1109/TBC.2006.889694
   Kazemi M, 2014, MULTIMEDIA SYST, V20, P283, DOI 10.1007/s00530-013-0319-z
   Kung WY, 2006, IEEE T CIRC SYST VID, V16, P146, DOI 10.1109/TCSVT.2005.857817
   Leontaris A, 2007, IEEE T IMAGE PROCESS, V16, P1726, DOI 10.1109/TIP.2007.896681
   Lin CY, 2011, IEEE T CIRC SYST VID, V21, P589, DOI 10.1109/TCSVT.2011.2129270
   Moiron S, 2011, ELECTRON LETT, V47, P103, DOI 10.1049/el.2010.3018
   Psannis KE, 2009, TELECOMMUN SYST, V41, P65, DOI 10.1007/s11235-009-9151-3
   Rane S, 2008, IEEE T CIRC SYST VID, V18, P1347, DOI 10.1109/TCSVT.2008.929135
   Shu HY, 2008, IEEE T MULTIMEDIA, V10, P97, DOI 10.1109/TMM.2007.911300
   Stockhammer T, 2002, P PACK VID WORKSH PI
   Sun YC, 2014, MULTIMED TOOLS APPL, V72, P1411, DOI 10.1007/s11042-013-1434-8
   Tianwu Yang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P85, DOI 10.1109/ICME.2012.171
   Tillo T, 2008, IEEE T CIRC SYST VID, V18, P59, DOI 10.1109/TCSVT.2007.913751
   Wan S, 2007, IEEE T IMAGE PROCESS, V16, P1327, DOI 10.1109/TIP.2007.894230
   Xiao JM, 2013, IEEE T CIRC SYST VID, V23, P1825, DOI 10.1109/TCSVT.2013.2248235
   Xiao JM, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-80
   Xu YY, 2013, IEEE T CIRC SYST VID, V23, P1523, DOI 10.1109/TCSVT.2013.2249018
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
   Zhou YR, 2010, OPT ENG, V49, DOI 10.1117/1.3467462
   Zhu CB, 2009, IEEE T CIRC SYST VID, V19, P3, DOI 10.1109/TCSVT.2008.2005802
NR 25
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 2347
EP 2366
DI 10.1007/s11042-014-2409-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000028
DA 2024-07-18
ER

PT J
AU Boughrara, H
   Chtourou, M
   Ben Amar, C
   Chen, LM
AF Boughrara, Hayet
   Chtourou, Mohamed
   Ben Amar, Chokri
   Chen, Liming
TI Facial expression recognition based on a mlp neural network using
   constructive training algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Constructive training algorithm; MLP;
   Back-propagation; Feature extraction; Perceived facial images; PCA
ID FEATURES; EMOTION; FUSION
AB This paper presents a constructive training algorithm for Multi Layer Perceptron (MLP) applied to facial expression recognition applications. The developed algorithm is composed by a single hidden-layer using a given number of neurons and a small number of training patterns. When the Mean Square Error MSE on the Training Data TD is not reduced to a predefined value, the number of hidden neurons grows during the neural network learning. Input patterns are trained incrementally until all patterns of TD are presented and learned. The proposed MLP constructive training algorithm seeks to find synthesis parameters as the number of patterns corresponding for subsets of each class to be presented initially in the training step, the initial number of hidden neurons, the number of iterations during the training step as well as the MSE predefined value. The suggested algorithm is developed in order to classify a facial expression. For the feature extraction stage, a biological vision-based facial description, namely Perceived Facial Images PFI has been applied to extract features from human face images. To evaluate, the proposed approach is tested on three databases which are the GEMEP FERA 2011, the Cohn-Kanade facial expression and the facial expression recognition FER-2013 databases. Compared to the fixed MLP architecture and the literature review, experimental results clearly demonstrate the efficiency of the proposed algorithm.
C1 [Boughrara, Hayet; Chtourou, Mohamed] Univ Sfax, ENIS, Control & Energy Management Lab, BP 1173, Sfax 3038, Tunisia.
   [Ben Amar, Chokri] Univ Sfax, ENIS, Res Grp Intelligent Machines, BP 1173, Sfax 3038, Tunisia.
   [Chen, Liming] Univ Lyon, Lab InfoRmat Image & Syst Informat, F-69134 Ecully, France.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Boughrara, H (corresponding author), Univ Sfax, ENIS, Control & Energy Management Lab, BP 1173, Sfax 3038, Tunisia.
EM hayet.boughrara@laposte.net; mohamed.chtourou@enis.rnu.tn;
   chokri.benamar@ieee.org; liming.chen@ec-lyon.fr
RI Chokri, BEN AMAR/K-5237-2012
CR [Anonymous], 2013, INT J DISTRIBUTED SE
   [Anonymous], 2013, WORKSH CHALL REPR LE
   [Anonymous], INT C IM PROC
   [Anonymous], 2005, HDB FACE RECOGNITION
   Banziger T., 2010, Blueprint for affective computing: A sourcebook, P271, DOI DOI 10.1037/A0025827
   Bejani M, 2012, METHOD AUDIOVISUAL E
   Boughrara H., 2012, INT C INF TECHN E SE, P1
   Boughrara H, 2013, LECT NOTES COMPUT SC, V8157, P591, DOI 10.1007/978-3-642-41184-7_60
   Boughrara H, 2012, INT CONF MULTIMED, P233, DOI 10.1109/ICMCS.2012.6320263
   Chakrabarti D, 2013, PROC TECH, V10, P755, DOI 10.1016/j.protcy.2013.12.419
   Chumkamon S, 2013, 2013 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P382, DOI 10.1109/SII.2013.6776626
   Dahmane Mohamed, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P884, DOI 10.1109/FG.2011.5771368
   Danisman T, 2013, SIGNAL PROCESS, V93, P1547, DOI 10.1016/j.sigpro.2012.08.007
   Dhall A, 2011, 1PQ IEEE INT C AUT F, P878
   Edelman S, 1997, COMPLEX CELLS OBJECT
   EKMAN P, 1992, PHILOS T ROY SOC B, V335, P63, DOI 10.1098/rstb.1992.0008
   Eskil MT, 2014, COMPUT VIS IMAGE UND, V119, P1, DOI 10.1016/j.cviu.2013.11.002
   Fan W, 2013, MULTIMED TOOLS APPL
   Fang H, 2014, PATTERN RECOGN, V47, P1271, DOI 10.1016/j.patcog.2013.09.023
   Farajzadeh N, 2013, PATTERN ANAL APPL
   Gizatdinova Y, 2006, IEEE T PATTERN ANAL, V28, P135, DOI 10.1109/TPAMI.2006.10
   Gu WF, 2012, PATTERN RECOGN, V45, P80, DOI 10.1016/j.patcog.2011.05.006
   Han Honggui, 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P1245, DOI 10.1109/IJCNN.2009.5178581
   Hongying Meng, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P854, DOI 10.1109/FG.2011.5771362
   Huang D., 2011, P CVPR WORKSH BIOM C
   Huang D., 2011, THESIS U LYON
   Ionescu R. T., 2013, WORKSH CHALL REPR LE
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   Kaburlasos VG, 2013, IEEE T NEUR NET LEAR, V24, P1526, DOI 10.1109/TNNLS.2012.2237038
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Khan RA, 2013, PATTERN RECOGNIT LET, V34
   Lajevardi SM, 2012, SIGNAL IMAGE VIDEO P, V6, P159, DOI 10.1007/s11760-010-0177-5
   Lee CC, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/596842
   LIPPMANN RP, 1989, IEEE COMMUN MAG, V27, P47, DOI 10.1109/35.41401
   Littlewort G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P897, DOI 10.1109/FG.2011.5771370
   Liu DR, 2002, IEEE T CIRCUITS-I, V49, P1876, DOI 10.1109/TCSI.2002.805733
   Liu S, 2012, IMAGE VISION COMPUT, V30, P535, DOI 10.1016/j.imavis.2012.05.004
   Long F, 2012, NEUROCOMPUTING, V93, P126, DOI 10.1016/j.neucom.2012.04.017
   Luo Y, 2013, OPTIK, V124, P2767, DOI 10.1016/j.ijleo.2012.08.040
   Ma L, 2004, IEEE T SYST MAN CY B, V34, P1588, DOI 10.1109/TSMCB.2004.825930
   Majumder A, 2014, PATTERN RECOGN, V47, P1282, DOI 10.1016/j.patcog.2013.10.010
   Masmoudi S, 2011, INT J SPEECH TECHNOL, V14, P1, DOI 10.1007/s10772-010-9082-0
   Mohseni Sina, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P361
   Niese R, 2012, IET COMPUT VIS, V6, P79, DOI 10.1049/iet-cvi.2011.0064
   Owusu E, 2014, EXPERT SYST APPL, V41, P3383, DOI 10.1016/j.eswa.2013.11.041
   Pratama M, 2014, IEEE T NEUR NET LEAR, V25, P55, DOI 10.1109/TNNLS.2013.2271933
   Puma-Villanueva WJ, 2012, NEUROCOMPUTING, V75, P14, DOI 10.1016/j.neucom.2011.05.025
   Sadeghi H, 2013, IRAN CONF MACH, P159, DOI 10.1109/IranianMVIP.2013.6779970
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Sharma S.K., 2010, International Journal of Engineering and Service and Technology, V2, P7847
   Songfan Yang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P866, DOI 10.1109/FG.2011.5771364
   Sridhar SS, 2011, INT J COMPUT ELECT E, V3, P1793
   Srivastava Ruchir, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P903, DOI 10.1109/FG.2011.5771371
   Tariq U., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P872, DOI 10.1109/FG.2011.5771365
   Valstar MF, 2011, 9 IEEE C AUT FAC GES
   Villegas M, 2011, PATTERN RECOGN LETT, V32, P633, DOI 10.1016/j.patrec.2010.12.002
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wan SH, 2014, PATTERN RECOGN, V47, P1859, DOI 10.1016/j.patcog.2013.11.025
   Wang SF, 2013, IEEE T AFFECT COMPUT, V4, P34, DOI 10.1109/T-AFFC.2012.32
   Wang Z, 2012, INT CONF SIGN PROCES, P1226, DOI 10.1109/ICoSP.2012.6491797
   Wang Z, 2012, 2012 IEEE INFORMATION THEORY WORKSHOP (ITW), P222, DOI [10.1109/ICNC.2012.6234551, 10.1109/ITW.2012.6404663]
   Wu HC, 2013, ADV INTELLIGENT SYST, P259
   Yang P, 2010, PROC CVPR IEEE, P2638, DOI 10.1109/CVPR.2010.5539978
   Zavaschi THH, 2013, EXPERT SYST APPL, V40, P646, DOI 10.1016/j.eswa.2012.07.074
   Zhao X, 2012, EURASIP J ADV SIG PR, V10, P1687
   Zhaozhao Zhang, 2010, Proceedings of the 2010 International Conference on Intelligent Control and Information Processing (ICICIP 2010), P406, DOI 10.1109/ICICIP.2010.5564272
NR 66
TC 57
Z9 57
U1 2
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 709
EP 731
DI 10.1007/s11042-014-2322-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700002
DA 2024-07-18
ER

PT J
AU Kulsoom, A
   Xiao, D
   Aqeel-Ur-Rehman
   Abbas, SA
AF Kulsoom, Ayesha
   Xiao, Di
   Aqeel-Ur-Rehman
   Abbas, Syed Ali
TI An efficient and noise resistive selective image encryption scheme for
   gray images based on chaotic maps and DNA complementary rules
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stream cipher; Logistic; PWLCM; MD5; DNA
ID SEQUENCE OPERATION; ALGORITHM; ROBUST
AB A novel image encryption algorithm in streaming mode is proposed which exhaustively employs an entire set of DNA complementary rules alongwith one dimensional chaotic maps. The proposed algorithm is highly efficient due to encrypting the subset of digital image which contains 92.125 % of information. DNA addition operation is carried out on this MSB part. The core idea of the proposed scheme is to scramble the whole image by means of piecewise linear chaotic map (PWLCM) followed by decomposition of image into most significant bits (MSB) and least significant bits (LSB). The logistic sequence is XORed with the decoded MSB and LSB parts separately and finally these two parts are combined to get the ciphered image. The parameters for PWLCM, logistic map and selection of different DNA rules for encoding and decoding of both parts of an image are derived from 128-bit MD5 hash of the plain image. Simulated experimental results in terms of quantitative and qualitative ways prove the encryption quality. Efficiency and robustness against different noises make the proposed cipher a good candidate for real time applications.
C1 [Kulsoom, Ayesha; Xiao, Di; Aqeel-Ur-Rehman; Abbas, Syed Ali] Chongqing Univ, Coll Comp Sci & Engn, Chongqing 630044, Peoples R China.
C3 Chongqing University
RP Kulsoom, A (corresponding author), Chongqing Univ, Coll Comp Sci & Engn, Chongqing 630044, Peoples R China.
EM ayeshakhattak1@yahoo.com
RI Rehman, Aqeel ur/R-4559-2018
OI Rehman, Aqeel ur/0000-0002-3083-6066
FU Natural Science Foundation Project of CQ CSTC [201440001]; National
   Natural Science Foundation of China [61070246]
FX This work was supported in part by Natural Science Foundation Project of
   CQ CSTC under Grant No. 201440001 and National Natural Science
   Foundation of China under Grant No. 61070246.
CR [Anonymous], 2016, HDB APPL CRYPTOGRAPH
   [Anonymous], 1977, FIPS PUB
   [Anonymous], 2001, FIPS PUB
   [Anonymous], 2000, DIMACS SERIES DISCRE
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Behnia S, 2007, PHYS LETT A, V366, P391, DOI 10.1016/j.physleta.2007.01.081
   Biham E, 1991, P 10 ANN INT CRYPT C
   Biham E, 1993, P 12 ANN INT CRYPT C
   Brown R, 1996, INT J BIFURCAT CHAOS, V6, P219, DOI 10.1142/S0218127496000023
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen W, 2011, OPT ENG, V50, DOI 10.1117/1.3643724
   Chen W, 2010, OPT EXPRESS, V18, P27095, DOI 10.1364/OE.18.027095
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Furht B., 2006, Multimedia encryption and authentication techniques and applications
   Gao TG, 2008, CHAOS SOLITON FRACT, V38, P213, DOI 10.1016/j.chaos.2006.11.009
   Head T, 2000, BIOSYSTEMS, V57, P87, DOI 10.1016/S0303-2647(00)00091-5
   Hennelly B, 2003, OPT LETT, V28, P269, DOI 10.1364/OL.28.000269
   Hui CG, 2012, IPCSIT, V52
   King OD, 2007, DISCRETE APPL MATH, V155, P831, DOI 10.1016/j.dam.2005.07.015
   Kumar A, 2011, COMMUN NONLINEAR SCI, V16, P372, DOI 10.1016/j.cnsns.2010.04.010
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Mao YB, 2005, HANDBOOK OF GEOMETRIC COMPUTING: APPLICATIONS IN PATTERN RECOGNITION, COMPUTER VISION, NEURALCOMPUTING, AND ROBOTICS, P231, DOI 10.1007/3-540-28247-5_8
   Patidar V, 2011, OPT COMMUN, V284, P4331, DOI 10.1016/j.optcom.2011.05.028
   Pisarchik AN, 2006, CHAOS, V16, DOI 10.1063/1.2242052
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Schneier B., 1994, Fast Software Encryption. Cambridge Security Workshop Proceedings, P191
   Schneier B., 1999, 2 FISH ENCRYPTION AL
   Shi XY, 2011, APPL OPTICS, V50, P2134, DOI 10.1364/AO.50.002134
   Shiu HJ, 2010, INFORM SCIENCES, V180, P2196, DOI 10.1016/j.ins.2010.01.030
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xiao D, 2008, PHYS LETT A, V372, P4682, DOI 10.1016/j.physleta.2008.04.060
   Yang M, 2004, IEEE POTENTIALS, V23, P28
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang W, 2012, OPT COMMUN, V285, P2343, DOI 10.1016/j.optcom.2012.01.029
   Zhu BH, 2000, OPT LETT, V25, P1159, DOI 10.1364/OL.25.001159
NR 42
TC 114
Z9 117
U1 0
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 1
EP 23
DI 10.1007/s11042-014-2221-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500001
DA 2024-07-18
ER

PT J
AU Serón, FJ
   Bobed, C
AF Seron, Francisco J.
   Bobed, Carlos
TI VOX system: a semantic embodied conversational agent exploiting linked
   data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic embodied conversational agents; Semantic knowledge; Semantic
   Web
ID INTERFACE AGENTS; USER ADOPTION; WEB; DESIGN; ART
AB In the last few years, the use of ontologies has spread thanks to the irruption of the Semantic Web. They have become a crucial tool in information systems as they explicitly state the meaning of information, making it possible to share it and to achieve higher levels of interoperability. However, being knowledge representation models as they are, other fields can take advantage of their characteristics to extend their capabilities. In particular, in the context of Embodied Conversational Agents, they can be used to provide them with semantic knowledge and, therefore, enhance their intellectual skills. In this paper, we propose an approach to explore the synergies between these technologies. Thus, we have developed a multimodal ECA that exploits the knowledge provided by the Linked Data initiative to help users in their search information tasks. Based on a semantic-guided keyword search, our approach is flexible enough to: 1) deal with different Linked Data repositories and 2) handle different search/knowledge domains in a multilingual way. To illustrate the potential of our approach, we have focused on the case of DBpedia, as it mirrors the information stored in the Wikipedia, providing a semantic entry to it.
C1 [Seron, Francisco J.; Bobed, Carlos] Univ Zaragoza, Dept Comp Sci & Syst Engn, Zaragoza 50018, Spain.
C3 University of Zaragoza
RP Bobed, C (corresponding author), Univ Zaragoza, Dept Comp Sci & Syst Engn, Zaragoza 50018, Spain.
EM seron@unizar.es; cbobed@unizar.es
RI Bobed, Carlos/AAP-8288-2020; Seron Arbeloa, Francisco Jose/L-3146-2014
OI Bobed, Carlos/0000-0003-4239-8785; Seron Arbeloa, Francisco
   Jose/0000-0003-1683-4694
FU Spanish "Direccion General de Investigacion, Ministerio de Economia y
   Competitividad" [TIN2011-24660/REPLIKANTS]; Spanish "Ministerio de
   Economia y Competitividad", CICYT projects [TIN2010-21387-C02-02,
   TIN2013-46238-C4-4-R]; Spanish "Ministerio de Industria, Energia y
   Turismo" [AVANZA TSI-020606-2012-4/CONTSEM]; European Commission
   [ALFA_GAVIOTA DCI-ALA/19.09.01/10/21526/245-654/ALFAIII (2010) 149,
   519332-LLP-1-2011-1-PT-KA3-KA3NW/SEGAN]; DGA (Aragonese Gobern)
   [INNOVA-A1-064/13]; DGA-FSE
FX This work has been partly financied by:; - The Spanish "Direccion
   General de Investigacion, Ministerio de Economia y Competitividad",
   contract number: TIN2011-24660/REPLIKANTS.; - The Spanish "Ministerio de
   Economia y Competitividad", CICYT projects TIN2010-21387-C02-02 and
   TIN2013-46238-C4-4-R.; - The Spanish "Ministerio de Industria, Energia y
   Turismo", contract number: AVANZA TSI-020606-2012-4/CONTSEM.; - European
   Commission: ALFA_GAVIOTA DCI-ALA/19.09.01/10/21526/245-654/ALFAIII
   (2010) 149.; - European Commission:
   519332-LLP-1-2011-1-PT-KA3-KA3NW/SEGAN.; - The DGA (Aragonese Gobern),
   projects INNOVA-A1-064/13 and DGA-FSE.
CR Androutsopoulos I., 1995, Natural Language Engineering, V1, P29, DOI [DOI 10.1017/S135132490000005X, 10.1017/S0269888900005476]
   [Anonymous], 2012, P WORKSHOP QUESTION
   Baader F., 2003, DESCRIPTION LOGIC HD
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Baldassarri S, 2008, COMPUT GRAPH-UK, V32, P430, DOI 10.1016/j.cag.2008.04.006
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Berry DC, 2005, INT J HUM-COMPUT ST, V63, P304, DOI 10.1016/j.ijhcs.2005.03.006
   Beun RJ, 2003, LECT NOTES ARTIF INT, V2792, P315
   Bizer C, 2009, INT J SEMANT WEB INF, V5, P1, DOI 10.4018/jswis.2009081901
   Bizer C, 2009, J WEB SEMANT, V7, P154, DOI 10.1016/j.websem.2009.07.002
   Bobed C, 2013, INT J KNOWL-BASED IN, V17, P67, DOI 10.3233/KES-130255
   Breuing A., 2010, Proceedings of the 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology - Workshops (WI-IAT 2010), P428, DOI 10.1109/WI-IAT.2010.231
   Cassell J, 2001, AI MAG, V22, P67
   Cassell J., 2000, Embodied Conversational Agents
   Cerezo E, 2008, AFFECTIVE COMPUTING
   Cimiano P, 2010, SEMANT WEB, V1, P83, DOI 10.3233/SW-2010-0008
   Cochran W.G., 1957, Experimental designs, V2nd
   D'Ulizia A, 2010, IEEE T SYST MAN CY A, V40, P1130, DOI 10.1109/TSMCA.2010.2041227
   Duckhorn F, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P1002
   Garcia A, 2005, P IADAT E2005 INT C, P117
   Graesser AC, 2005, IEEE T EDUC, V48, P612, DOI 10.1109/TE.2005.856149
   GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008
   Gruber TR, 1995, INT J HUM-COMPUT ST, V43, P907, DOI 10.1006/ijhc.1995.1081
   Kalwick DJ, 2006, ANIMATING FACIAL FEA
   Kim H, 2012, COMM COM INF SC, V352, P116
   Kimura M, 2006, LECT NOTES ARTIF INT, V4088, P734
   Kipp M, 2006, LECT NOTES ARTIF INT, V4133, P434
   Lester J., 1999, INT J ARTIFICIAL INT, V10, P278
   Li HF, 2012, ENRGY PROCED, V17, P1843, DOI 10.1016/j.egypro.2012.02.321
   Lopez V, 2011, SEMANT WEB, V2, P125, DOI 10.3233/SW-2011-0041
   Marsella S. C., 2000, Proceedings of the Fourth International Conference on Autonomous Agents, P301, DOI 10.1145/336595.337507
   Marsi Erwin., 2007, Proceedings of the Workshop on Multimodal Output Generation (MOG 2007), P105
   Mignonneau L, 2005, COMPUT GRAPH-UK, V29, P837, DOI 10.1016/j.cag.2005.09.001
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Motik B, 2009, J ARTIF INTELL RES, V36, P165, DOI 10.1613/jair.2811
   Mulken SV, 1998, PEOPL COMP 13 P HCI, P3
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72, DOI 10.1145/191666.191703
   Ortiz A, 2003, P TIDSE03 TECHN INT, P322
   Reeves B., 2000, BENEFITS INTERACTIVE
   Rieger T, 2003, WSCG'2003, VOL 11, NO 2, CONFERENCE PROCEEDINGS, P379
   Serenko A, 2008, INTERACT COMPUT, V20, P461, DOI 10.1016/j.intcom.2008.04.004
   Serenko A, 2007, BEHAV INFORM TECHNOL, V26, P119, DOI 10.1080/01449290500260538
   Shadbolt N, 2006, IEEE INTELL SYST, V21, P96, DOI 10.1109/MIS.2006.62
   Sirin E, 2007, J WEB SEMANT, V5, P51, DOI 10.1016/j.websem.2007.03.004
   SNEDECOR G W, 1980
   VOLKEL M., 2006, Proceedings of the International Conference on World Wide Web (WWW), P585
   Waltinger U., 2011, IJCAI, P1896
   Yuan X, 2005, COMPUT ANIMAT VIRT W, V16, P109, DOI 10.1002/cav.65
NR 48
TC 8
Z9 9
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 381
EP 404
DI 10.1007/s11042-014-2295-5
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500019
DA 2024-07-18
ER

PT J
AU Herrero, G
   Barbancho, I
   Tardón, LJ
   Rosa-Pujazón, A
   Barbancho, AM
AF Herrero, Giacomo
   Barbancho, Isabel
   Tardon, Lorenzo J.
   Rosa-Pujazon, Alejandro
   Barbancho, Ana M.
TI Drumkit simulator from everyday desktop objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Drumkit simulator; Audio features; Classification techniques
ID MUSIC; SYSTEM
AB In this paper, an augmented reality application for drumkit simulation is presented. The system is capable of classifying any percussive sounds produced by the user from an everyday desktop environment, e.g. clapping, snapping, stroking different objects with a pencil, etc., recognizing up to six different classes of drum hits. These different types of user-generated sounds will subsequently be associated to predefined drumkit sounds, resulting in a natural and intuitive audio interface for drummers and percussionists, which only requires a computer with a built-in microphone. A set of audio features and classification techniques are evaluated for the implementation of the aforementioned system.
C1 [Herrero, Giacomo; Barbancho, Isabel; Tardon, Lorenzo J.; Rosa-Pujazon, Alejandro; Barbancho, Ana M.] Univ Malaga, ATIC Res Grp, ETSI Telecomunicac, Dept Ingn Comunicac, E-29071 Malaga, Spain.
C3 Universidad de Malaga
RP Barbancho, AM (corresponding author), Univ Malaga, ATIC Res Grp, ETSI Telecomunicac, Dept Ingn Comunicac, E-29071 Malaga, Spain.
EM giacomoherrero@gmail.com; ibp@ic.uma.es; lorenzo@ic.uma.es;
   alejandror@uma.es; abp@ic.uma.es
RI Barbancho, Ana M./L-7156-2014; Barbancho, Isabel/L-7244-2014; Tardon,
   Lorenzo J./M-4492-2014
OI Barbancho, Ana M./0000-0002-3283-5905; Barbancho,
   Isabel/0000-0001-7002-9106; Tardon, Lorenzo J./0000-0002-5441-225X
FU Junta de Andalucia [P11-TIC-7154]; Ministerio de Educacion, Cultura y
   Deporte through Programa Nacional de Movilidad de Recursos Humanos del
   Plan Nacional de I-D+i; prorrogado por Acuerdo de Consejo de Ministros
   de 7 de octubre de
FX This work has been funded by the Junta de Andalucia under Project No.
   P11-TIC-7154 and by the Ministerio de Educacion, Cultura y Deporte
   through the Programa Nacional de Movilidad de Recursos Humanos del Plan
   Nacional de I-D+i 2008-2011, prorrogado por Acuerdo de Consejo de
   Ministros de 7 de octubre de 2011. The work has been done in the context
   of Campus de Excelencia Internacional Andalucia Tech, Universidad de
   Malaga.
CR Agostini G, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P97, DOI 10.1109/MMSP.2001.962718
   [Anonymous], 2000, USE ZERO CROSSING RA
   Antle Alissa N., 2008, P 7 INT C INT DES CH, DOI [DOI 10.1145/1463689.1463754, DOI 10.1145/1463689.146375]
   Bakanas P, 2012, ECLAP 2012 C INF TEC, P107
   BAKKER S, 2011, P 5 INT C TANG EMB E, P85
   Basili R., 2004, P ISMIR
   Borchers J, 2004, MULTIMEDIA SYST, V9, P458, DOI 10.1007/s00530-003-0119-y
   BRADSHAW D, 2008, P EVA LOND 2008 INT
   Breebaart J., 2002, P PHIL S INT ALG EIN
   Brown JC, 1999, J ACOUST SOC AM, V105, P1933, DOI 10.1121/1.426728
   Castellano Ginevra, 2007, P 7 INT C NEW INTERF, P390
   de Dreu M J, 2012, Parkinsonism Relat Disord, V18 Suppl 1, pS114, DOI 10.1016/S1353-8020(11)70036-0
   Deng JD, 2008, IEEE T SYST MAN CY B, V38, P429, DOI 10.1109/TSMCB.2007.913394
   ERONEN A, 2001, P IEEE WORKSH APPL S
   Essl G, 2009, ORGAN SOUND, V14, P197, DOI 10.1017/S1355771809000302
   Gillet O, 2004, IEEE INT C AC SPEECH, V4, DOI [10.1109/ICASSP.2004.1326815, DOI 10.1109/ICASSP.2004.1326815]
   Gower L, 2012, BRIT J MUSIC EDUC, V29, P91, DOI 10.1017/S0265051711000398
   Halpern M, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P557
   Herrera P., 2002, Music and Artificial Intelligence. Second International Conference, ICMAI 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2445), P69, DOI 10.1007/3-540-45722-4_8
   Herrera-Boyer P, 2003, J NEW MUSIC RES, V32, P3, DOI 10.1076/jnmr.32.1.3.16798
   Holland S, 2010, TEI 2010, P21
   Hoofer A, 2009, P INT C NEW INT MUS, P175
   Ihara Mizuki, 2007, 2007 IEEE International Symposium on Signal Processing and Information Technology, P595, DOI 10.1109/ISSPIT.2007.4458100
   Je HM, 2007, 2007 RO-MAN: 16TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1-3, P163
   Jorda Sergi., 2010, CHI 2010: Media Showcase Session 1, P2989, DOI [10.1145/1753846.1753903, DOI 10.1145/1753846.1753903]
   Khoo ET, 2008, SANDBOX SYMPOSIUM 2008: 3RD ACM SIGGRAPH VIDEOGAME SYMPOSIUM, PROCEEDINGS, P35
   Lee Eric., 2004, INT C NEW INTERFACES, P68
   Levin G., 2004, Proceedings of the 3rd International Symposium on Non-photorealistic Animation and Rendering, P7, DOI [10. 1145/987657.987659, DOI 10.1145/987657.987659]
   Livshin AA, 2004, P DAFX
   Mandanici M, 2012, DISEMBODIED VOICES K
   MORITA H, 1991, COMPUTER, V24, P44, DOI 10.1109/2.84835
   Nakra T, 2009, NIME2009
   Ng KC, 2004, P IEEE, V92, P645, DOI 10.1109/JPROC.2004.825885
   Padmavathi G, 2010, 3 INT C ADV COMP THE, V2
   Parton K., 2009, 2 INT C MUS COMM SCI
   Peng L, 2009, P 2009 C NEW INT MUS
   Qin Y, STUDY WII KINECT CON
   Rosa-Pujazon A, 2013, SMAC 2013 STOCKH MUS, P284
   Rosa-Pujazon A, 2013, 1 S ESP ENTR DIG SEE, P108
   Tardon LJ, 2010, ACOUST SOC AM
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1
   Todoroff T, 2011, QPSR NUMEDIART RES P, V4
   TRAIL Shawn, 2012, NEW INTERFACES MUSIC
   Wang CH, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-92
NR 44
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10195
EP 10213
DI 10.1007/s11042-014-2159-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700002
DA 2024-07-18
ER

PT J
AU Huang, W
   Li, J
   Zhang, P
   Wan, M
   Fang, C
   Shen, MM
AF Huang, Wei
   Li, Jing
   Zhang, Peng
   Wan, Min
   Fang, Can
   Shen, Minmin
TI A novel marker-less lung tumor localization strategy on low-rank
   fluoroscopic images with similarity learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tumor localization; Low-rank and sparse decomposition; Similarity
   learning; Spectral clustering
ID NONLINEAR DIMENSIONALITY REDUCTION; REAL-TIME TUMOR; TRACKING; MOTION;
   RADIOTHERAPY
AB Fluoroscopic images depicting the movement of lung tumor lesions along with patients' respirations are essential in contemporary image-guided lung cancer radiotherapy, as the accurate delivery of radiation dose on lung tumor lesions can be facilitated with the help of fluoroscopic images. However, the quality of fluoroscopic images is often not high, and several factors including image noise, artifact, ribs occlusion often prevent the tumor lesion from being accurate localized. In this study, a novel marker-less lung tumor localization strategy is proposed. Unlike conventional lung tumor localization strategies, it doesn't require placing external surrogates on patients or implanting internal fiducial markers in patients. Thus ambiguous movement correlations between moving tumor lesions and surrogates as well as the risk of patients pneumothorax can be totally avoided. In this new strategy, fluoroscopic images are first decomposed into low-rank and sparse components via the split Bregman method, and then spectral clustering techniques are incorporated for similarity learning to realize the tumor localization task. Clinical data obtained from 60 patients with lung tumor lesions is utilized for experimental evaluation, and promising results obtained by the new strategy are demonstrated from the statistical point of view.
C1 [Huang, Wei; Li, Jing; Wan, Min] Nanchang Univ, Sch Informat Engn, Nanchang, Peoples R China.
   [Zhang, Peng] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
   [Fang, Can] Southwestern Univ, Sch Comp & Informat Sci, Chongqing, Peoples R China.
   [Shen, Minmin] S China Univ Technol, Sch Software Engn, Guangzhou, Guangdong, Peoples R China.
   [Shen, Minmin] Univ Konstanz, INCIDE Ctr, Constance, Germany.
C3 Nanchang University; Northwestern Polytechnical University; Southwest
   University - China; South China University of Technology; University of
   Konstanz
RP Huang, W (corresponding author), Nanchang Univ, Sch Informat Engn, Nanchang, Peoples R China.
EM huangwei@ncu.edu.cn; jing.li.2003@gmail.com; zh0036ng@nwpu.edu.cn;
   wanmin1983@gmail.com; canfang@swu.edu.cn; minmin.shen@uni-konstanz.de
RI zhang, yueqi/JXM-4287-2024; wan, min/KLC-3833-2024; Zhang,
   Penghui/HGB-7353-2022
OI Zhang, Penghui/0000-0002-9518-7079
FU NWPU [3102014JSJ0014];  [61363046];  [61301194];  [61302121]
FX This work is supported by 61363046, 61301194, and 61302121 approved by
   National Natural Science Foundation China, 20142BBE50023, 20142BAB217033
   and 20142BAB217030 approved by Jiangxi Provincial Department of Science
   and Technology, as well as NWPU grant 3102014JSJ0014.
CR [Anonymous], IEEE COMPUT
   [Anonymous], STABLE PRINCIPAL COM
   [Anonymous], ADV NEURAL INF PROCE
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], ADV NEURAL INF PROCE
   [Anonymous], SEGMENTATION CONSIST
   [Anonymous], INT J RAD ONCOL BIOL
   [Anonymous], INT J RAD ONCOL BIOL
   Bach FR, 2006, J MACH LEARN RES, V7, P1963
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Bishop C.M., 2006, J ELECTRON IMAGING, V16, P049901, DOI DOI 10.1117/1.2819119
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Ferlay J, 2010, INT J CANCER, V127, P2893, DOI 10.1002/ijc.25516
   Ferrell B, 2011, SURG CLIN N AM, V91, P403, DOI 10.1016/j.suc.2010.12.003
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hsu D, 2011, IEEE T INFORM THEORY, V57, P7221, DOI 10.1109/TIT.2011.2158250
   Huang W, 2013, IEEE IMAGE PROC, P1399, DOI 10.1109/ICIP.2013.6738288
   Ionascu D, 2008, MED PHYS, V35, P2893, DOI 10.1118/1.2962477
   Isaksson M, 2005, MED PHYS, V32, P3801, DOI 10.1118/1.2134958
   Kothary N, 2009, AM J ROENTGENOL, V192, P1090, DOI 10.2214/AJR.08.1399
   McNair HA, 2012, BRIT J RADIOL, V85, P168, DOI 10.1259/bjr/14026195
   Mountain CF, 1997, CHEST, V111, P1710, DOI 10.1378/chest.111.6.1710
   Riaz N, 2009, PHYS MED BIOL, V54, P5735, DOI 10.1088/0031-9155/54/19/005
   Rice J. A., 2006, MATH STAT DATA ANAL
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Ruan D, 2007, PHYS MED BIOL, V52, P7137, DOI 10.1088/0031-9155/52/23/024
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shimizu S, 2001, INT J RADIAT ONCOL, V51, P304, DOI 10.1016/S0360-3016(01)01641-8
   Shirato H, 2000, INT J RADIAT ONCOL, V48, P435, DOI 10.1016/S0360-3016(00)00625-8
   Zhang TZ, 2012, LECT NOTES COMPUT SC, V7577, P470, DOI 10.1007/978-3-642-33783-3_34
   Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154
   Zhou Tianyi, 2013, Proceedings of the Twenty-Third international joint conference on Artificial Intelligence, P1946
NR 35
TC 0
Z9 0
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10535
EP 10558
DI 10.1007/s11042-014-2186-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700018
DA 2024-07-18
ER

PT J
AU Kuang, ZZ
   Li, ZM
   Jiang, XX
   Liu, YJ
AF Kuang, Zhenzhong
   Li, Zongmin
   Jiang, Xiaxia
   Liu, Yujie
TI Exploration in improving retrieval quality and robustness for deformable
   non-rigid 3D shapes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-rigid 3D shape retrieval; Query quality; Shape representation;
   Retrieval guidance
ID FEATURES; KERNELS
AB Improving query quality and robustness is a hot topic in information and image retrieval field, which has resulted in many interesting works. To address the same problem for deformable non-rigid 3D shape retrieval, two topics are considered in this paper. The first one we discussed is shape representation, which is related to feature extraction and fusion. For feature extraction, we create a global feature to achieve a coarser-scale shape appearance description. Then, to alleviate the drawbacks of retrieval by single feature, we develop a novel fusion method for multiple feature fusion, which turns out to be superior to weighted sum approach with a low complexity. The second topic studied in this paper is to further refine the retrieval results by introducing a new retrieval guidance algorithm based on category prediction. To evaluate the proposed methods, experiments on three popular non-rigid datasets are carried out. The evaluation results suggest that our shape representation method has achieved state-of-the-art performance. Then, by adjusting the retrieval results of existing methods, our retrieval guidance algorithm has promoted the accuracy with nice effects.
C1 [Kuang, Zhenzhong] China Univ Petr Huadong, Sch Geosci, Qingdao Econ & Technol Dev Zone, Jinan 266580, Shandong, Peoples R China.
   [Li, Zongmin] China Univ Petr Huadong, Coll Comp & Commun Engn, Sch Geosci, Qingdao Econ & Technol Dev Zone, Jinan 266580, Shandong, Peoples R China.
   [Jiang, Xiaxia; Liu, Yujie] China Univ Petr Huadong, Coll Comp & Commun Engn, Qingdao Econ & Technol Dev Zone, Jinan 266580, Shandong, Peoples R China.
C3 China University of Petroleum; China University of Petroleum; China
   University of Petroleum
RP Li, ZM (corresponding author), China Univ Petr Huadong, Coll Comp & Commun Engn, Sch Geosci, Qingdao Econ & Technol Dev Zone, 66 Changjiang West Rd, Jinan 266580, Shandong, Peoples R China.
EM zzkuang@foxmail.com; lizongmin@upc.edu.cn; jiangxiax@gmail.com;
   liuyujie@upc.edu.cn
OI Ghanbari, Mohammad/0000-0002-5482-8378
FU National Natural Science Foundation of China [61379106]; Scientific
   Research Foundation for Excellent Middle-Aged and Youth Scientists of
   Shandong Province of China [BS2010DX037]; Shandong Provincial Natural
   Science Foundation [ZR2009GL014, ZR2013FM036]; Open Project Program of
   State Key Lab of CAD&CG, Zhejiang University [A1315]; Fundamental
   Research Funds for Central Universities [10CX04043A, 10CX04014B,
   11CX04053A, 11CX06086A, 12CX06083A, 12CX06086A, 13CX06007A, 14CX06010A,
   14CX06012A]
FX This work is partly supported by National Natural Science Foundation of
   China (Grant No. 61379106), the Scientific Research Foundation for the
   Excellent Middle-Aged and Youth Scientists of Shandong Province of China
   (Grant No. BS2010DX037), the Shandong Provincial Natural Science
   Foundation (Grant No. ZR2009GL014, ZR2013FM036), the Open Project
   Program of the State Key Lab of CAD&CG (Grant No. A1315), Zhejiang
   University, the Fundamental Research Funds for the Central Universities
   (Grant No. 10CX04043A, 10CX04014B, 11CX04053A, 11CX06086A, 12CX06083A,
   12CX06086A, 13CX06007A, 14CX06010A, 14CX06012A).
CR Abdelrahman M., 2012, 2012 Canadian Conference on Computer and Robot Vision, P153, DOI 10.1109/CRV.2012.28
   Abdelrahman M, 2012, LECT NOTES COMPUT SC, V7583, P22, DOI 10.1007/978-3-642-33863-2_3
   Amati G, 2004, LECT NOTES COMPUT SC, V2997, P127
   Barra V, 2013, PATTERN RECOGN, V46, P2985, DOI 10.1016/j.patcog.2013.03.019
   Boutin M, 2004, ADV APPL MATH, V32, P709, DOI 10.1016/S0196-8858(03)00101-5
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Bronstein MM, 2011, IEEE T PATTERN ANAL, V33, P1065, DOI 10.1109/TPAMI.2010.210
   Carpineto C, 2001, ACM T INFORM SYST, V19, P1, DOI 10.1145/366836.366860
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chum O, 2011, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2011.5995601
   Cui J., 2008, MM 08, P729
   Daras P, 2012, IEEE T MULTIMEDIA, V14, P374, DOI 10.1109/TMM.2011.2176111
   dos Santos Joyce M., 2013, Advances in Information Retrieval. 35th European Conference on IR Research, ECIR 2013. Proceedings, P62, DOI 10.1007/978-3-642-36973-5_6
   Elad A, 2003, IEEE T PATTERN ANAL, V25, P1285, DOI 10.1109/TPAMI.2003.1233902
   Fernando B, 2012, PROC CVPR IEEE, P3434, DOI 10.1109/CVPR.2012.6248084
   Knopp Jan., 2013, Eurographics Workshop on 3D Object Retrieval (3DOR), P1
   Li B, 2013, MULTIMED TOOLS APPL, P1
   Li B, 2013, MULTIMED TOOLS APPL, V62, P821, DOI 10.1007/s11042-011-0873-3
   Lian Z, 2010, 3DOR, P79
   Lian ZH, 2013, MACH VISION APPL, V24, P1685, DOI 10.1007/s00138-013-0501-5
   Liang Z., 2010, IEEE International Conference on Communications ICC, P1
   Lipman Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1805964.1805971
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Memoli Facundo, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P256, DOI 10.1109/ICCVW.2009.5457690
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011
   Rustamov Raif M, 2007, P S GEOM PROC, V257, P225
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Ye J., 2013, Proceedings of the 3rd ACM conference on International conference on multimedia retrieval, P121
NR 30
TC 1
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10335
EP 10366
DI 10.1007/s11042-014-2170-4
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700009
DA 2024-07-18
ER

PT J
AU Sur, A
   Krishna, SVM
   Sahu, N
   Rana, S
AF Sur, Arijit
   Krishna, Sista Venkat Madhav
   Sahu, Nilkanta
   Rana, Shuvendu
TI Detection of motion vector based video steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video steganography; Steganalysis; Motion vector
ID STEGANALYSIS
AB In this paper, a new steganalysis technique is proposed to detect the motion vector based steganography for the compressed videos. The proposed scheme explores the flickering effect, the changes in the prediction error and statistical anomalies in the motion vectors due to embedding to detect the presence of steganographic messages. The experimental results show that the proposed method effectively detects the data embedded in motion vector based steganographic techniques more accurately than the already existing schemes.
C1 [Sur, Arijit; Krishna, Sista Venkat Madhav; Sahu, Nilkanta; Rana, Shuvendu] IIT Guwahati, Dept Comp Sci & Engn, Gauhati 781039, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Sahu, N (corresponding author), IIT Guwahati, Dept Comp Sci & Engn, Gauhati 781039, India.
EM arijit@iitg.ac.in; sista@iitg.ac.in; nilkanta@iitg.ernet.in;
   shuvendu@iitg.ac.in
RI Sur, Arijit/AAB-4216-2020; Rana, Shuvendu/ACC-7002-2022; Rana,
   Shuvendu/J-5190-2019
OI Rana, Shuvendu/0000-0002-8372-5669; Rana, Shuvendu/0000-0002-8372-5669;
   Sur, Arijit/0000-0002-9038-8138
CR Aly HA, 2011, IEEE T INF FOREN SEC, V6, P14, DOI 10.1109/TIFS.2010.2090520
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Avcibas I, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P517, DOI 10.1109/MMSP.2001.962785
   Budhia U, 2006, IEEE T INF FOREN SEC, V1, P502, DOI 10.1109/TIFS.2006.885020
   Chebbo S, 2010, IEEE INT C IM PROC T, P177, DOI DOI 10.1109/IPTA.2010.5586728
   Chen B, 2001, J VLSI SIG PROCESS S, V27, P7, DOI 10.1023/A:1008107127819
   Chen CH, 2006, IEEE IMAGE PROC, P105, DOI 10.1109/ICIP.2006.312383
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Fang D., 2006, 2006 IEEE International Symposium on Circuits and Systems (pp. -), DOI DOI 10.1109/ISCAS.2006.1692862
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Huang FJ, 2007, IEEE IMAGE PROC, P401
   Jainsky JS, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P161
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Marvel LM, 1999, IEEE T IMAGE PROCESS, V8, P1075, DOI 10.1109/83.777088
   Pankajakshan V, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P287
   Solanki K., 2007, 9 INT WORKSH INF HID
   Tasdemir Kasim, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P260
   Wang Jue, 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P500, DOI 10.1109/ICCSN.2011.6013642
   Wang KR, 2014, MULTIMED TOOLS APPL, V72, P313, DOI 10.1007/s11042-013-1373-4
   Wang P, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P1555, DOI 10.1109/ICALIP.2008.4590271
   WESTFELD A, 2000, P 3 INT WORKSH INF H
   Xu CY, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 1, PROCEEDINGS, P269
   Xuansen He, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P822, DOI 10.1109/CSSE.2008.359
   Yun Cao, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P193, DOI 10.1007/978-3-642-24178-9_14
   Zhang C, 2008, P 4 INT C WIR COMM N, P1
   Zhang J, 2001, XIV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P179, DOI 10.1109/SIBGRAPI.2001.963053
NR 27
TC 7
Z9 7
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10479
EP 10494
DI 10.1007/s11042-014-2181-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700015
DA 2024-07-18
ER

PT J
AU Yan, SF
   Tang, GM
   Sun, YF
   Gao, ZZ
   Shen, LQ
AF Yan, Shufan
   Tang, Guangming
   Sun, Yifeng
   Gao, Zhanzhan
   Shen, Liuqing
TI A triple-layer steganography scheme for low bit-rate speech streams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low bit-rate speechstreams; G.729 codec; Triple-layer steganography;
   Pitch period prediction; Pitch parameter
ID VOICE
AB With the wide application of low bit-rate codecs in speech communication systems, low bit-rate speech streams have become new cover media of great potential for steganography. In this paper, through analyzing the pitch period prediction process in G.729 codec, the pitch parameter of the second speech subframe is found suitable for performing embedding. Then a novel triple-layer steganography method is proposed for low bit-rate speech streams. In this method, modification directions (adding or subtracting one) of the pitch parameter are selected adaptively in order to achieve a high embedding efficiency. Based on the "Hamming + 1" scheme, we use the matrix encoding method twice to increase the hiding capacity. Experimental results show that while keeping a good perceived quality of the synthetic speech, the proposed method has a good real-time performance and a satisfactory steganography security.
C1 [Yan, Shufan; Gao, Zhanzhan; Shen, Liuqing] Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Henan, Peoples R China.
   [Tang, Guangming; Sun, Yifeng] Zhengzhou Informat Sci & Technol Inst, Dept Informat Secur, Zhengzhou, Peoples R China.
C3 PLA Information Engineering University; PLA Information Engineering
   University
RP Yan, SF (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Henan, Peoples R China.
EM yansfluk@163.com
RI TANG, Guang-Ming/E-5315-2013
CR [Anonymous], IEEE INT S CIRC SYST
   Crandall R., 1998, SOME NOTES STEGANOGR
   Dittmann J, 2005, P SOC PHOTO-OPT INS, V5681, P607, DOI 10.1117/12.586579
   Huang YF, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P1512, DOI 10.1109/IIH-MSP.2008.174
   Huang YF, 2012, IEEE T INF FOREN SEC, V7, P1865, DOI 10.1109/TIFS.2012.2218599
   Liu LH, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P406, DOI 10.1109/IIH-MSP.2008.297
   Liu QZ, 2009, IEEE T INF FOREN SEC, V4, P359, DOI 10.1109/TIFS.2009.2024718
   Mazurczyk W, 2008, LECT NOTES COMPUT SC, V5332, P1001
   Tian H, 2010, J CENT SOUTH UNIV T, V17, P1285, DOI 10.1007/s11771-010-0633-y
   Xiao B, 2008, GLOBAL TELECOMMUNICA, P1
   Yu Chi, 2012, Journal of Chinese Computer Systems, V33, P1445
   Zhang WM, 2007, IEEE COMMUN LETT, V11, P680, DOI 10.1109/LCOMM.2007.070438
NR 12
TC 14
Z9 14
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11763
EP 11782
DI 10.1007/s11042-014-2265-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600035
DA 2024-07-18
ER

PT J
AU Yao, YZ
   Zhang, WM
   Yu, NH
   Zhao, XF
AF Yao, Yuanzhi
   Zhang, Weiming
   Yu, Nenghai
   Zhao, Xianfeng
TI Defining embedding distortion for motion vector-based video
   steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Steganalysis; Motion vector; Embedding distortion;
   Prediction error
AB This paper presents an effective methodology for motion vector-based video steganography. The main principle is to design a suitable distortion function expressing the embedding impact on motion vectors by exploiting the spatial-temporal correlation based on the framework of minimal-distortion steganography. Two factors are considered in the proposed distortion function, which are the statistical distribution change (SDC) of motion vectors in spatial-temporal domain and the prediction error change (PEC) caused by modifying the motion vectors. The practical embedding algorithm is implemented using syndrome-trellis codes (STCs). Experimental results show that the proposed method can enhance the security performance significantly compared with other existing motion vector-based video steganographic approaches, while obtaining the higher video coding quality as well.
C1 [Yao, Yuanzhi; Zhang, Weiming; Yu, Nenghai] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei 230027, Peoples R China.
   [Zhao, Xianfeng] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; Institute of Information
   Engineering, CAS
RP Zhang, WM (corresponding author), Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei 230027, Peoples R China.
EM yaoyz@mail.ustc.edu.cn; zhangwm@ustc.edu.cn; ynh@ustc.edu.cn;
   zhaoxianfeng@iie.ac.cn
RI Zhao, Xianfeng/AAE-7278-2021; Yao, Yuanzhi/JZS-9170-2024
OI Zhao, Xianfeng/0000-0002-5617-8399; Yao, Yuanzhi/0000-0003-1965-7670
FU Natural Science Foundation of China [61170234, 60803155]; Strategic
   Priority Research Program of the Chinese Academy of Sciences
   [XDA06030601]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant 61170234 and Grant 60803155, and in part by the
   Strategic Priority Research Program of the Chinese Academy of Sciences
   under Grant XDA06030601.
CR Aly HA, 2011, IEEE T INF FOREN SEC, V6, P14, DOI 10.1109/TIFS.2010.2090520
   [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   Bellifemine F., 1992, Signal Processing: Image Communication, V4, P477, DOI 10.1016/0923-5965(92)90032-B
   Cao Y, 2012, IEEE SIGNAL PROC LET, V19, P35, DOI 10.1109/LSP.2011.2176116
   Crandall R, 1998, SOME NOTES ON STEGAN
   Fang DY, 2006, IEEE INT SYMP CIRC S, P1422
   Filler T, 2010, PROCEEDINGS OF SPIE, V7541, P05
   Filler T, FRIDRICH J SYNDROME
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Filler T, 2010, IEEE T INF FOREN SEC, V5, P705, DOI 10.1109/TIFS.2010.2077629
   Fridrich J, 2005, IEEE T SIGNAL PROCES, V53, P3923, DOI 10.1109/TSP.2005.855393
   GORMISH MJ, 1993, P SOC PHOTO-OPT INS, V1903, P146, DOI 10.1117/12.143123
   Guo LJ, 2012, IEEE INT WORKS INFOR, P169, DOI 10.1109/WIFS.2012.6412644
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Huang FJ, 2012, IEEE T INF FOREN SEC, V7, P1181, DOI 10.1109/TIFS.2012.2198213
   Ker A.D., 2013, P 1 ACM WORKSH INF H, P4558, DOI DOI 10.1145/2482513.2482965
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Sachnev V, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-89
   Shanableh T, 2012, IEEE T INF FOREN SEC, V7, P455, DOI 10.1109/TIFS.2011.2177087
   Su YT, 2011, SIGNAL PROCESS, V91, P1901, DOI 10.1016/j.sigpro.2011.02.012
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu C., 2006, P INT C INN COMP INF, VII, P803
   Yang XY, 2012, ADV MATER RES-SWITZ, V433-440, P5384, DOI 10.4028/www.scientific.net/AMR.433-440.5384
   Yun Cao, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P193, DOI 10.1007/978-3-642-24178-9_14
   Zhang WM, 2007, IEEE SIGNAL PROC LET, V14, P848, DOI 10.1109/LSP.2007.903255
   Zhang X, 2007, ELECTRON LETT, V43, P482, DOI 10.1049/el:20070248
NR 27
TC 48
Z9 48
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11163
EP 11186
DI 10.1007/s11042-014-2223-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600010
DA 2024-07-18
ER

PT J
AU Asaari, MSM
   Rosdi, BA
   Suandi, SA
AF Asaari, Mohd Shahrimie Mohd
   Rosdi, Bakhtiar Affendi
   Suandi, Shahrel Azmin
TI Adaptive Kalman Filter Incorporated Eigenhand (AKFIE) for real-time hand
   tracking system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand tracking; Adaptive Kalman Filter; Eigenspace; Eigenhand
ID GESTURE RECOGNITION
AB Hand tracking is one of the essential elements in vision-based hand gesture recognition systems. It has a great potential as a tool for better human-computer interaction (HCI) by means of communicating in natural and articulate ways. This has motivated an active research concerning with the interpretation of hand tracking for gesture recognition system. However, due to the nature of hand motion which is flexible, erratic and always varies in its appearance, the tracking of human hand using vision-based remains a complex problem. In this paper, we present an efficient method to overcome such difficulties using integration of Adaptive Kalman Filter (AKF) and Eigenhand method. In the proposed method, the tracking task is first carried out by running the Region of Interest (ROI) based tracker. Here, by fusing the skin and motion cues as the main tracking features, the actual hand position in the current frame is measured. This initial measurement is rather inconsistent due to the working principle of ROI based tracker which greatly depends on how effectively the extracted tracking features are. To reduce this inconsistency, the measurement error is minimized by employing the AKF prediction. After the hand position is effectively estimated by the AKF tracker, a low dimensional eigenspace representation, i.e., the Eigenhand, is employed to further improve the tracking performance. This representation is necessary as the AKF tracker only treats the hand image as a set of moving pixel which consequently disregards the detail appearance of the target. Therefore, the incorporated eigenspace representation provides a compact description of the internal target appearance for better object recognition. This eigenspace adaptively learns the current state to reflect the appearance changes of the target image in each frame. The experimental results demonstrate the effectiveness of the proposed tracking algorithm in indoor and outdoor environments where the target objects undergo large pose changes, lighting variation, fast motion and partial occlusion with average detection rate above 97 % at the speed of 35 frame/second (fps).
C1 [Asaari, Mohd Shahrimie Mohd; Rosdi, Bakhtiar Affendi; Suandi, Shahrel Azmin] Univ Sains Malaysia, Sch Elect & Elect Engn, Intelligent Biometr Grp, Nibong Tebal 14300, Pulau Pinang, Malaysia.
C3 Universiti Sains Malaysia
RP Suandi, SA (corresponding author), Univ Sains Malaysia, Sch Elect & Elect Engn, Intelligent Biometr Grp, Engn Campus, Nibong Tebal 14300, Pulau Pinang, Malaysia.
EM mohdshahrimie@yahoo.com; eebakhtiar@usm.my; shahrel@usm.my
RI Suandi, Shahrel Azmin/D-1776-2009; Asaari, Mohd Shahrimie
   Mohd/U-5561-2019; Rosdi, Bakhtiar Affendi/O-9017-2019
OI Suandi, Shahrel Azmin/0000-0001-9980-7426; Asaari, Mohd Shahrimie
   Mohd/0000-0002-0225-4819; Rosdi, Bakhtiar Affendi/0000-0002-0917-3886
CR [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], INT C GRAPH VIS IM
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2010, INT J INF TECHNOL
   [Anonymous], INT C OPT TECHN APPL
   [Anonymous], 2010, WORLD ENG C
   [Anonymous], 2006, TR 95-041
   [Anonymous], 2009, 2009 IEEE 13 INT S C
   Asaari Mohd Shahrimie Mohd, 2010, Proceedings 10th International Conference on Intelligent Systems Design and Applications (ISDA 2010), P166, DOI 10.1109/ISDA.2010.5687273
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Black MJ, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P660, DOI 10.1109/ICCV.1998.710788
   Bradski GaryR., 1998, Computer vision face tracking for use in a perceptual user interface
   Chen FS, 2003, IMAGE VISION COMPUT, V21, P745, DOI 10.1016/S0262-8856(03)00070-2
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Feng ZQ, 2011, PATTERN RECOGN, V44, P1089, DOI 10.1016/j.patcog.2010.08.007
   Ge SS, 2008, IMAGE VISION COMPUT, V26, P1607, DOI 10.1016/j.imavis.2008.03.004
   Guan C, 2007, J VIS COMMUN IMAGE R, V18, P141, DOI 10.1016/j.jvcir.2006.11.006
   Hee SK, 2008, INT C IND TECHNOLOGY, P1
   Ho J, 2004, PROC CVPR IEEE, P782
   Imagawa K, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P462, DOI 10.1109/AFGR.1998.670991
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Ishida H, 2010, PATTERN RECOGN, V43, P2799, DOI 10.1016/j.patcog.2010.02.021
   KAISER HF, 1960, EDUC PSYCHOL MEAS, V20, P141, DOI 10.1177/001316446002000116
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Li H, 2011, PATTERN RECOGN, V44, P1614, DOI 10.1016/j.patcog.2010.12.014
   McAllister G, 2002, IMAGE VISION COMPUT, V20, P827, DOI 10.1016/S0262-8856(02)00093-8
   Moon H., 1998, EMPIRICAL EVALUATION
   Oka K, 2002, IEEE COMPUT GRAPH, V22, P64, DOI 10.1109/MCG.2002.1046630
   Pan ZG, 2010, P IEEE VIRT REAL ANN, P219, DOI 10.1109/VR.2010.5444787
   Park CB, 2011, IMAGE VISION COMPUT, V29, P51, DOI 10.1016/j.imavis.2010.08.006
   Porikli F., 2006, 2006 IEEE COMPUTER S, V1, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]
   Qiu-yu Zhang, 2009, Journal of Multimedia, V4, P349, DOI 10.4304/jmm.4.6.349-355
   Ross D, 2004, LECT NOTES COMPUT SC, V3022, P470
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Shan CF, 2007, PATTERN RECOGN, V40, P1958, DOI 10.1016/j.patcog.2006.12.012
   Weng SK, 2006, J VIS COMMUN IMAGE R, V17, P1190, DOI 10.1016/j.jvcir.2006.03.004
   Suk HI, 2010, PATTERN RECOGN, V43, P3059, DOI 10.1016/j.patcog.2010.03.016
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Utsumi A, 2002, IEEE WORKSHOP ON KNOWLEDGE MEDIA NETWORKING, PROCEEDINGS, P31, DOI 10.1109/KMN.2002.1115159
   Zhai HT, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND BRAIN, VOLS 1-3, P1233
   Zheng WL, 2009, J VIS COMMUN IMAGE R, V20, P9, DOI 10.1016/j.jvcir.2008.09.001
NR 42
TC 9
Z9 11
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9231
EP 9257
DI 10.1007/s11042-014-2078-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200008
DA 2024-07-18
ER

PT J
AU Buso, V
   Benois-Pineau, J
   Domenger, JP
AF Buso, Vincent
   Benois-Pineau, Jenny
   Domenger, Jean-Philippe
TI Geometrical cues in visual saliency models for active object recognition
   in egocentric videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Egocentric vision; Saliency maps; Object recognition; Spatio-temporal
   model
ID SPATIOTEMPORAL SALIENCY
AB In the problem of "human sensing", videos recorded with wearable cameras give an "egocentric" view of the world, capturing details of human activities. In this paper we continue research on visual saliency for such kind of content with the goal of "active" objects recognition in egocentric videos. In particular, a geometrical cue is considered in case when the central-bias hypothesis does not hold. The proposed visual saliency models are trained based on eye fixations of observers and incorporated into spatio-temporal saliency models. The proposed models have been compared to state of the art visual saliency models using a metric based on target object recognition performances. The results are promising:they highlight the necessity of a non-centered geometric saliency cue.
C1 [Buso, Vincent; Benois-Pineau, Jenny; Domenger, Jean-Philippe] Lab Bordelais Rech Informat LaBRI, Talence, France.
C3 Universite de Bordeaux
RP Buso, V (corresponding author), Lab Bordelais Rech Informat LaBRI, Talence, France.
EM vbuso@labri.fr; jenny.benois@labri.fr; domenger@labri.fr
RI Benois-Pineau, Jenny/ABG-6325-2020; Domenger,
   jean-philippe/AAX-5021-2021
OI Benois-Pineau, Jenny/0000-0003-0659-8894; Domenger,
   Jean-philippe/0000-0001-5398-9340
FU EU FP7 PI Dem@Care project [288199]
FX This research is supported by the EU FP7 PI Dem@Care project under grant
   agreement #288199.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 1935, How people look at pictures: A study of the psychology and perception in art
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Boujut H, 2012, PROC SPIE, V8293, DOI 10.1117/12.905379
   Boujut H, 2012, LECT NOTES COMPUT SC, V7585, P436, DOI 10.1007/978-3-642-33885-4_44
   Brouard O., 2009, COMPRESSION REPRESEN
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Daly SJ, 1998, IS T SPIE C HUM VIS
   Dorr M, 2010, J VISION, V10, DOI 10.1167/10.10.28
   Duan LJ, 2011, IEEE SIGNAL PROC LET, V18, P690, DOI 10.1109/LSP.2011.2167752
   Farnebäck G, 2000, INT C PATT RECOG, P135
   Fathi A, 2012, LECT NOTES COMPUT SC, V7572, P314, DOI 10.1007/978-3-642-33718-5_23
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gonzalez Diaz I., 2013, Proceedings of the 1st ACM international workshop on Multimedia indexing and information retrieval for healthcare, P11, DOI DOI 10.1145/2505323.2505328
   Hae Jong Seo, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P45, DOI 10.1109/CVPR.2009.5204207
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kim H, 2014, IEEE T IMAGE PROCESS, V23, P1476, DOI 10.1109/TIP.2014.2303640
   Komogortsev OV, 2009, J ELECTRON IMAGING, V18, DOI 10.1117/1.3158609
   Land M, 1999, PERCEPTION, V28, P1311, DOI 10.1068/p2935
   Le Meur O, 2013, BEHAV RES METHODS, V45, P251, DOI 10.3758/s13428-012-0226-9
   Li J, 2009, IEEE INT CON MULTI, P442, DOI 10.1109/ICME.2009.5202529
   Liu C., 2009, Beyond pixels: Exploring new representations and applications for motion analysis
   Marat S, 2009, INT J COMPUT VISION, V82, P231, DOI 10.1007/s11263-009-0215-3
   Mayol WW, 2005, NINTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P122, DOI 10.1109/ISWC.2005.57
   Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010
   Ren XF, 2009, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2009.5204360
   Riche N, 2013, IEEE I CONF COMP VIS, P1153, DOI 10.1109/ICCV.2013.147
   Rudoy D, 2013, PROC CVPR IEEE, P1147, DOI 10.1109/CVPR.2013.152
   Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4
   Tilke J, 2009, IEEE INT C COMP VIS
   Tilke JuddFredo Durand Antonio Torralba., 2012, A benchmark of computational models of saliency to predict human fixations
   Tong YB, 2011, COGN COMPUT, V3, P241, DOI 10.1007/s12559-010-9094-8
   Vig E, 2012, LECT NOTES COMPUT SC, V7578, P84, DOI 10.1007/978-3-642-33786-4_7
   Yamada K, 2011, LNCS, V7087, P1627
   Zhong S. H., 2013, AAAI
NR 39
TC 5
Z9 6
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 22
BP 10077
EP 10095
DI 10.1007/s11042-015-2803-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV1LQ
UT WOS:000364019400014
DA 2024-07-18
ER

PT J
AU Dong, P
   Xia, Y
   Wang, SS
   Zhuo, L
   Feng, DD
AF Dong, Pei
   Xia, Yong
   Wang, Shanshan
   Zhuo, Li
   Feng, David Dagan
TI An iteratively reweighting algorithm for dynamic video summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Semantic indicator of video segment (SEDOG);
   Iterative weight estimation; Multimodal features; Saliency ranking
ID EVENT DETECTION; VISUAL-ATTENTION; SCENE DETECTION; FRAMEWORK; SALIENCY;
   FUSION; MODEL
AB Information explosion has imposed unprecedented challenges on the conventional ways of video data consumption. Hence providing condensed and meaningful video summary to viewers has been recognized as a beneficial and attractive research in the multimedia community in recent years. Analyzing both the visual and textual modalities proves essential for an automatic video summarizer to pick up important contents from a video. However, most established studies in this direction either use heuristic rules or rely on simple ways of text analysis. This paper proposes an iteratively reweighting dynamic video summarization (IRDVS) algorithm based on the joint and adaptive use of the visual modality and accompanying subtitles. The proposed algorithm takes advantage of our developed SEmantic inDicator of videO seGment (SEDOG) feature for exploring the most representative concepts for describing the video. Meanwhile, the iteratively reweighting scheme effectively updates the dynamic surrogate of the original video by combining the high-level features in an adaptive manner. The proposed algorithm has been compared to four state-of-the-art video summarization approaches, namely the speech transcript-based (STVS) algorithm, attention model-based (AMVS) algorithm, sparse dictionary selection-based (DSVS) algorithm and heterogeneity image patch index-based (HIPVS) algorithm, on different video genres, including documentary, movie and TV news. Our results show that the proposed IRDVS algorithm can produce summarized videos with better quality.
C1 [Dong, Pei; Xia, Yong; Wang, Shanshan; Feng, David Dagan] Univ Sydney, Sch Informat Technol, Biomed & Multimedia Informat Technol BMIT Res Grp, Sydney, NSW 2006, Australia.
   [Dong, Pei; Zhuo, Li] Beijing Univ Technol, Signal & Informat Proc Lab, Beijing 100124, Peoples R China.
   [Xia, Yong] Northwestern Polytech Univ, Sch Comp Sci, Shaanxi Key Lab Speech & Image Informat Proc, Xian 710072, Peoples R China.
   [Wang, Shanshan] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
   [Wang, Shanshan] Shanghai Jiao Tong Univ, Sch Biomed Engn, Shanghai 200240, Peoples R China.
C3 University of Sydney; Beijing University of Technology; Chinese Academy
   of Sciences; Shenzhen Institute of Advanced Technology, CAS; Shanghai
   Jiao Tong University
RP Dong, P (corresponding author), Beijing Univ Technol, Signal & Informat Proc Lab, Beijing 100124, Peoples R China.
EM dongpei_3203@hotmail.com; yxia@nwpu.edu.cn
RI Wang, Shanshan/T-6972-2017
OI Wang, Shanshan/0000-0002-0575-6523; Feng, Dagan/0000-0002-3381-214X
FU Australian Research Council grants; China Scholarship Council
   [2011623084]; National Natural Science Foundation of China [61372149,
   61370189, 61100212]; Program for New Century Excellent Talents in
   University [NCET-11-0892]; Specialized Research Fund for Doctoral
   Program of Higher Education [20121103110017]; Natural Science Foundation
   of Beijing [4142009]; Importation and Development of High-Caliber
   Talents Project of Beijing Municipal Institutions [CITTCD201304036,
   CITTCD201404043]; Science and Technology Development Program of Beijing
   Education Committee [KM201410005002]
FX This work was supported in part by the Australian Research Council
   grants, in part by the China Scholarship Council under Grant 2011623084,
   in part by the National Natural Science Foundation of China (No.
   61372149, No. 61370189, No. 61100212), in part by the Program for New
   Century Excellent Talents in University (No. NCET-11-0892), in part by
   the Specialized Research Fund for the Doctoral Program of Higher
   Education (No. 20121103110017), in part by the Natural Science
   Foundation of Beijing (No. 4142009), in part by the Importation and
   Development of High-Caliber Talents Project of Beijing Municipal
   Institutions (No. CIT&TCD201304036, No. CIT&TCD201404043), and in part
   by the Science and Technology Development Program of Beijing Education
   Committee (No. KM201410005002). We appreciate the anonymous reviewers
   for their constructive comments. Copyrights of images, videos and
   subtitles used in this work are the property of their respective owners.
CR Ahmad, 1991, ADV NEURAL INFORM PR, V4, P420
   Alatan AA, 2001, MULTIMED TOOLS APPL, V14, P137, DOI 10.1023/A:1011395131992
   Almeida J, 2013, J VIS COMMUN IMAGE R, V24, P729, DOI 10.1016/j.jvcir.2012.01.009
   Almeida J, 2012, PATTERN RECOGN LETT, V33, P397, DOI 10.1016/j.patrec.2011.08.007
   [Anonymous], 2007, CIVR '07
   [Anonymous], 2013, Social Media Retrieval, DOI [10.1007/978-1-4471-4555-4_10, DOI 10.1007/978-1-4471-4555-4_10]
   Bai L, 2010, MULTIMED TOOLS APPL, V49, P63, DOI 10.1007/s11042-009-0398-1
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Chen BW, 2009, IEEE T MULTIMEDIA, V11, P295, DOI 10.1109/TMM.2008.2009703
   Chen BW, 2014, LECT NOTES ELECT ENG, V260, P1031
   Choudary C, 2007, IEEE T MULTIMEDIA, V9, P1443, DOI 10.1109/TMM.2007.906602
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   Dang CT, 2014, IEEE T IMAGE PROCESS, V23, P2704, DOI 10.1109/TIP.2014.2320814
   Dong P, 2010, LECT NOTES COMPUT SC, V6297, P203, DOI 10.1007/978-3-642-15702-8_19
   Ejaz N, 2013, SIGNAL PROCESS-IMAGE, V28, P34, DOI 10.1016/j.image.2012.10.002
   Ejaz N, 2012, J VIS COMMUN IMAGE R, V23, P1031, DOI 10.1016/j.jvcir.2012.06.013
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Evangelopoulos G, 2009, INT CONF ACOUST SPEE, P3553, DOI 10.1109/ICASSP.2009.4960393
   Evangelopoulos G, 2008, IEEE IMAGE PROC, P2528, DOI 10.1109/ICIP.2008.4712308
   Evangelopoulos G, 2013, IEEE T MULTIMEDIA, V15, P1553, DOI 10.1109/TMM.2013.2267205
   Fersini E, 2012, PROGRAM-ELECTRON LIB, V46, P199, DOI 10.1108/00330331211221846
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Garestier F, 2010, IEEE T GEOSCI REMOTE, V48, P3340, DOI 10.1109/TGRS.2010.2046669
   Hauptmann A, 2007, IEEE T MULTIMEDIA, V9, P958, DOI 10.1109/TMM.2007.900150
   Hauptmann Alexander., 2007, CIVR 07, P627
   Hung MH, 2008, IEEE T CIRC SYST VID, V18, P1713, DOI 10.1109/TCSVT.2008.2004934
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   James W., 1890, The Principles of Psychology, V1
   Jiang YG, 2013, INT J MULTIMED INF R, V2, P73, DOI 10.1007/s13735-012-0024-2
   Jiang YG, 2010, IEEE T MULTIMEDIA, V12, P42, DOI 10.1109/TMM.2009.2036235
   KENNEDY L, 2006, DTO CHALL WORKSH LAR
   Kim JN, 2000, IEEE T CIRC SYST VID, V10, P1040, DOI 10.1109/76.875508
   Kleban J., 2007, P INT WORKSH TRECVID, P84
   Knudsen EI, 2007, ANNU REV NEUROSCI, V30, P57, DOI 10.1146/annurev.neuro.30.051606.094256
   Koral KF, 2004, IEEE T NUCL SCI, V51, P611, DOI 10.1109/TNS.2004.829605
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lin L, 2011, IEEE MULTIMEDIA, V18, P32, DOI 10.1109/MMUL.2011.35
   Loui Alexander., 2007, MIR 07, P245
   Luo JB, 2009, IEEE T CIRC SYST VID, V19, P289, DOI 10.1109/TCSVT.2008.2009241
   Ma Y.-F., 2002, ACM MULTIMEDIA, P533
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Matos N, 2008, SIGNAL PROCESS-IMAGE, V23, P581, DOI 10.1016/j.image.2008.05.003
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Money AG, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823751
   Mylonas P, 2009, IEEE T MULTIMEDIA, V11, P229, DOI 10.1109/TMM.2008.2009681
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Over P., 2008, Proc. of the 2nd ACM TRECVid Video Summarization Workshop, P1, DOI [DOI 10.1145/1463563.1463564, 10.1145/1463563.1463564]
   Over P., 2007, TVS '07: Proc. of the International Workshop on TRECVID Video Summarization, P1, DOI DOI 10.1145/1290031.1290032
   Pal R, 2012, HDB SOFT COMPUTING V, P79
   Pedersen T, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P1024
   Peng WT, 2011, IEEE T MULTIMEDIA, V13, P539, DOI 10.1109/TMM.2011.2131638
   POSNER MI, 1990, ANNU REV NEUROSCI, V13, P25, DOI 10.1146/annurev.ne.13.030190.000325
   Pritch Y, 2008, IEEE T PATTERN ANAL, V30, P1971, DOI 10.1109/TPAMI.2008.29
   Rapantzikos K, 2011, COGN COMPUT, V3, P167, DOI 10.1007/s12559-011-9097-0
   Ren JC, 2009, IEEE T MULTIMEDIA, V11, P906, DOI 10.1109/TMM.2009.2021782
   Tamrakar A, 2012, PROC CVPR IEEE, P3681, DOI 10.1109/CVPR.2012.6248114
   Tang S, 2012, IEEE T MULTIMEDIA, V14, P43, DOI 10.1109/TMM.2011.2168198
   Taskiran CM, 2006, IEEE T MULTIMEDIA, V8, P775, DOI 10.1109/TMM.2006.876282
   Tavassolipour M, 2014, IEEE T CIRC SYST VID, V24, P291, DOI 10.1109/TCSVT.2013.2243640
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang F, 2012, IEEE T MULTIMEDIA, V14, P76, DOI 10.1109/TMM.2011.2165531
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Wang SF, 2014, MULTIMED TOOLS APPL, V72, P1257, DOI 10.1007/s11042-013-1450-8
   Wei XY, 2011, IEEE T CIRC SYST VID, V21, P62, DOI 10.1109/TCSVT.2011.2105597
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Xu G, 2005, IEEE T CIRC SYST VID, V15, P1422, DOI 10.1109/TCSVT.2005.856903
   Yuan Z, 2011, P 10 INT C MOB UB MU, P109
   Zhu SA, 2012, IEEE T MULTIMEDIA, V14, P1068, DOI 10.1109/TMM.2012.2190387
NR 69
TC 7
Z9 7
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9449
EP 9473
DI 10.1007/s11042-014-2126-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200018
DA 2024-07-18
ER

PT J
AU Hahn, WE
   Lewkowitz, S
   Lacombe, DC
   Barenholtz, E
AF Hahn, William Edward
   Lewkowitz, Stephanie
   Lacombe, Daniel C., Jr.
   Barenholtz, Elan
TI Deep learning human actions from video via sparse filtering and locally
   competitive algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neuroscience; Computer vision; Sparse coding; Sparse filtering; Locally
   competitive algorithms
AB Physiological and psychophysical evidence suggest that early visual cortex compresses the visual input on the basis of spatial and orientation-tuned filters. Recent computational advances have suggested that these neural response characteristics may reflect a 'sparse coding' architecture-in which a small number of neurons need to be active for any given image-yielding critical structure latent in natural scenes. Here we present a novel neural network architecture combining a sparse filter model and locally competitive algorithms (LCAs), and demonstrate the network's ability to classify human actions from video. Sparse filtering is an unsupervised feature learning algorithm designed to optimize the sparsity of the feature distribution directly without having the need to model the data distribution. LCAs are defined by a system of differential equations where the initial conditions define an optimization problem and the dynamics converge to a sparse decomposition of the input vector. We applied this architecture to train a classifier on categories of motion in human action videos. Inputs to the network were small 3D patches taken from frame differences in the videos. Dictionaries were derived for each action class and then activation levels for each dictionary were assessed during reconstruction of a novel test patch. Overall, classification accuracy was at a parts per thousand 97 %. We discuss how this sparse filtering approach provides a natural framework for multi-sensory and multimodal data processing including RGB video, RGBD video, hyper-spectral video, and stereo audio/video streams.
C1 [Hahn, William Edward; Barenholtz, Elan] Florida Atlantic Univ, Ctr Complex Syst & Brain Sci, Boca Raton, FL 33431 USA.
   [Lacombe, Daniel C., Jr.; Barenholtz, Elan] Florida Atlantic Univ, Dept Psychol, Boca Raton, FL 33431 USA.
   [Lewkowitz, Stephanie] Florida Atlantic Univ, Dept Phys, Boca Raton, FL 33431 USA.
C3 State University System of Florida; Florida Atlantic University; State
   University System of Florida; Florida Atlantic University; State
   University System of Florida; Florida Atlantic University
RP Hahn, WE (corresponding author), Florida Atlantic Univ, Ctr Complex Syst & Brain Sci, Boca Raton, FL 33431 USA.
EM williamedwardhahn@gmail.com; elanbarenholtz@gmail.com
CR [Anonymous], 2010, P 27 INT C MACHINE L
   Atick JJ, 1990, NEURAL COMPUT, V2, P308, DOI 10.1162/neco.1990.2.3.308
   ATKINSON J, 1988, PERCEPTION, V17, P587, DOI 10.1068/p170587
   Blakemore C., 1970, DEV BRAIN DEPENDS VI
   Blakemore Colin., 1969, On the existence of neurones in the human visual system selectively sensitive to the orientation and size of retinal images
   Boyd S., 2004, CONVEX OPTIMIZATION
   CANDY JC, 1971, AT&T TECH J, V50, P1889, DOI 10.1002/j.1538-7305.1971.tb02587.x
   Castrodad A, 2012, INT J COMPUT VISION, V100, P1, DOI 10.1007/s11263-012-0534-7
   JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233
   LEGGE GE, 1980, J OPT SOC AM, V70, P1458, DOI 10.1364/JOSA.70.001458
   Ngiam J., 2011, Advances in Neural Information Processing Systems, V24
   Olshausen BA, 2004, CURR OPIN NEUROBIOL, V14, P481, DOI 10.1016/j.conb.2004.07.007
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Rozell Christopher, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P169
   Rozell CJ, 2008, NEURAL COMPUT, V20, P2526, DOI 10.1162/neco.2008.03-07-486
   SACHS MB, 1971, J OPT SOC AM, V61, P1176, DOI 10.1364/JOSA.61.001176
   Schmidt M., 2009, Tech.Rep. TR-2009-19
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
NR 18
TC 5
Z9 7
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 22
BP 10097
EP 10110
DI 10.1007/s11042-015-2808-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV1LQ
UT WOS:000364019400015
DA 2024-07-18
ER

PT J
AU Huang, TH
   Yeh, SL
   Yang, YH
   Liao, HI
   Tsai, YY
   Chang, PJ
   Chen, HH
AF Huang, Tai-Hsiang
   Yeh, Su-Ling
   Yang, Yung-Hao
   Liao, Hsin-I
   Tsai, Ya-Yeh
   Chang, Pai-Ju
   Chen, Homer H.
TI Method and experiments of subliminal cueing for real-world images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual attention; Eye movements; Eye tracking experiment; Subliminal
   cue; Human visual system
ID OBJECT-BASED ATTENTION; TOP-DOWN MODULATION; VISUAL-ATTENTION;
   EYE-MOVEMENTS; TRACKING; FEATURES; CAPTURE; MODEL; TIME; CUES
AB Unconscious attention shift triggered by a subliminal cue has been shown to be automatic; however, whether it can be brought into effect for images of real-world scenes remains to be investigated. We present a subliminal cueing method that flashes briefly a visual cue before presenting a real-world image to the viewer. The effectiveness of the method is verified by experiments using three types of cues (spatial cue, face cue, and object cue) of varied durations. Results show that depending on the cue type, the viewer's visual attention is directed to the cued visual hemifield or the cued location without engaging the viewer's awareness. The experiments demonstrate that a brief subliminal cue presented prior to the color image of a real-world complex scene can attract human visual attention. The method is useful for many applications that require efficient, unresisting attention shift to a target image area.
C1 [Huang, Tai-Hsiang] Natl Taiwan Univ, Grad Inst Commun Engn, Taipei 10617, Taiwan.
   [Yeh, Su-Ling] Natl Taiwan Univ, Grad Inst Brain & Mind Sci, Dept Psychol, Taipei 10617, Taiwan.
   [Yeh, Su-Ling] Natl Taiwan Univ, Neurobiol & Cognit Sci Ctr, Taipei 10617, Taiwan.
   [Yang, Yung-Hao; Liao, Hsin-I; Tsai, Ya-Yeh; Chang, Pai-Ju] Natl Taiwan Univ, Dept Psychol, Taipei 10617, Taiwan.
   [Chen, Homer H.] Natl Taiwan Univ, Dept Elect Engn, Grad Inst Commun Engn, Taipei 10617, Taiwan.
   [Chen, Homer H.] Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei 10617, Taiwan.
C3 National Taiwan University; National Taiwan University; National Taiwan
   University; National Taiwan University; National Taiwan University;
   National Taiwan University
RP Huang, TH (corresponding author), Natl Taiwan Univ, Grad Inst Commun Engn, Taipei 10617, Taiwan.
EM tshuang1983@gmail.com; suling@ntu.edu.tw; yunghaoyang@gmail.com;
   irisliao0111@gmail.com; r00227103@ntu.edu.tw; b97207003@ntu.edu.tw;
   homer@ntu.edu.tw
RI ; Yeh, Su-Ling/D-6089-2016
OI Chen, Homer/0000-0002-8795-1911; Yeh, Su-Ling/0000-0003-4597-8697
CR Alvarez GA, 2005, PSYCHOL SCI, V16, P637, DOI 10.1111/j.1467-9280.2005.01587.x
   [Anonymous], 1999, Kodak lossless true color image database
   Blanchfield A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00967
   Burnett KE, 2013, Q J EXP PSYCHOL, V66, P2363, DOI 10.1080/17470218.2013.780086
   Busse L, 2006, VISION RES, V46, P2019, DOI 10.1016/j.visres.2005.12.016
   Chalfoun P, 2011, ADV HUM-COMPUT INTER, V2011, DOI 10.1155/2011/968753
   CHEESMAN J, 1984, PERCEPT PSYCHOPHYS, V36, P387, DOI 10.3758/BF03202793
   Chou WL, 2012, PSYCHON B REV, V19, P225, DOI 10.3758/s13423-011-0207-5
   Chou WL, 2011, CONSCIOUS COGN, V20, P1265, DOI 10.1016/j.concog.2011.03.007
   Chou WL, 2008, Q J EXP PSYCHOL, V61, P1761, DOI 10.1080/17470210802194308
   Creative Commons, 2012, FLICK CREAT COMM
   Culibrk D, 2011, IEEE T IMAGE PROCESS, V20, P948, DOI 10.1109/TIP.2010.2080279
   Duc AH, 2008, PROG BRAIN RES, V171, P403, DOI 10.1016/S0079-6123(08)00659-6
   DUNCAN J, 1984, J EXP PSYCHOL GEN, V113, P501, DOI 10.1037/0096-3445.113.4.501
   EGLY R, 1994, J EXP PSYCHOL GEN, V123, P161, DOI 10.1037/0096-3445.123.2.161
   Fractal coding and analysis group, 2009, REPOSITORY
   Fuller S, 2009, VISION RES, V49, P1825, DOI 10.1016/j.visres.2009.04.019
   Gibson BS, 2005, PERCEPT PSYCHOPHYS, V67, P749, DOI 10.3758/BF03193530
   GRONER R, 1989, EUR ARCH PSY CLIN N, V239, P9, DOI 10.1007/BF01739737
   Huang TH, 2012, IEEE IMAGE PROC, P1081, DOI 10.1109/ICIP.2012.6467051
   Huth AG, 2012, NEURON, V76, P1210, DOI 10.1016/j.neuron.2012.10.014
   Itti L, 2003, PROC SPIE, V5200, P64, DOI 10.1117/12.512618
   Jiang Y, 2006, P NATL ACAD SCI USA, V103, P17048, DOI 10.1073/pnas.0605678103
   Jin SM, 2008, PROC SPIE, V6806, DOI 10.1117/12.766312
   Jonides J., 1981, ATTENTION PERFORM, P187, DOI DOI 10.1037/0096-1523.29.5.835
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Karremans JC, 2006, J EXP SOC PSYCHOL, V42, P792, DOI 10.1016/j.jesp.2005.12.002
   Lee WF, 2011, IEEE T IMAGE PROCESS, V20, P3028, DOI 10.1109/TIP.2011.2144610
   Li HL, 2008, J VIS COMMUN IMAGE R, V19, P320, DOI 10.1016/j.jvcir.2008.04.001
   Liao HI, 2011, ACTA PSYCHOL, V138, P52, DOI 10.1016/j.actpsy.2011.05.005
   LIBET B, 1985, BEHAV BRAIN SCI, V8, P529, DOI 10.1017/S0140525X00044903
   Likert R., 1932, TECHNIQUE MEASUREMEN, DOI 1933-01885-001
   Lo SY, 2008, CONSCIOUS COGN, V17, P1169, DOI 10.1016/j.concog.2008.03.020
   Maioli C, 2001, EUR J NEUROSCI, V13, P364, DOI 10.1046/j.1460-9568.2001.01381.x
   McAuliffe J, 2005, PSYCHOL RES-PSYCH FO, V69, P285, DOI 10.1007/s00426-004-0179-4
   McCormick PA, 1997, J EXP PSYCHOL HUMAN, V23, P168, DOI 10.1037/0096-1523.23.1.168
   Mulckhuyse M, 2007, VIS COGN, V15, P779, DOI 10.1080/13506280701307001
   Mulckhuyse M, 2010, ACTA PSYCHOL, V134, P299, DOI 10.1016/j.actpsy.2010.03.002
   MULLER HJ, 1989, J EXP PSYCHOL HUMAN, V15, P315, DOI 10.1037/0096-1523.15.2.315
   Nilsson M, 2007, INT CONF ACOUST SPEE, P589
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   Pratt J, 2001, PSYCHON B REV, V8, P489, DOI 10.3758/BF03196183
   Reif F., 2008, APPL COGNITIVE SCI E
   Ritter W, 2011, ADV HUM-COMPUT INTER, V2011, DOI 10.1155/2011/346492
   Sebastiani M, 2009, COGN PROCESS, V10, pS302, DOI 10.1007/s10339-009-0316-5
   Soto D, 2004, VISION RES, V44, P69, DOI 10.1016/j.visres.2003.08.013
   Sun Database, 2012, SCEN UND
   Tang CW, 2006, IEEE T MULTIMEDIA, V8, P11, DOI 10.1109/TMM.2005.861295
   Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4
   The USC-SIPI Image Database, 1999, SIPI IM DAT
   Theeuwes J, 2010, ACTA PSYCHOL, V135, P77, DOI 10.1016/j.actpsy.2010.02.006
   Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766
   Trochim M., 2006, T TEST
   Tsuchiya N, 2005, NAT NEUROSCI, V8, P1096, DOI 10.1038/nn1500
   Wang Y, 2008, CELL POLYM, V27, P1
   Wikimedia Foundation, 2012, AN VAR
   Wikimedia Foundation, 2012, CONF INT
   Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411
   Yang YH, 2011, CONSCIOUS COGN, V20, P223, DOI 10.1016/j.concog.2010.07.005
   Yarbus A. L., 1967, Eye Movements and Vision
   Yeh SL, 2012, PSYCHOL SCI, V23, P608, DOI 10.1177/0956797611434746
NR 61
TC 3
Z9 4
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 22
BP 10111
EP 10135
DI 10.1007/s11042-015-2804-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA CV1LQ
UT WOS:000364019400016
DA 2024-07-18
ER

PT J
AU Khatoonabadi, SH
   Bajic, IV
   Shan, YF
AF Khatoonabadi, Sayed Hossein
   Bajic, Ivan V.
   Shan, Yufeng
TI Compressed-domain correlates of human fixations in dynamic scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed-domain video processing; Visual saliency; Human fixations
ID SPATIOTEMPORAL SALIENCY DETECTION; VISUAL-ATTENTION; DETECTION MODEL;
   GRAPHENE; OXYGEN; BORON; MECHANISMS; EFFICIENCY; CLUSTERS; IMAGE
AB In this paper we present two compressed-domain features that are highly indicative of saliency in natural video. We demonstrate the potential of these two features to indicate saliency by comparing their statistics around human fixation points against their statistics at control points away from fixations. Then, using these features, we construct a simple and effective saliency estimation method for compressed video, which utilizes only motion vectors, block coding modes and coded residuals from the bitstream, with partial decoding. The proposed algorithm has been extensively tested on two ground truth datasets using several accuracy metrics. The results indicate its superior performance over several state-of-the-art compressed-domain and pixel-domain algorithms for saliency estimation.
C1 [Khatoonabadi, Sayed Hossein; Bajic, Ivan V.] Simon Fraser Univ, Burnaby, BC V5A 1S6, Canada.
   [Shan, Yufeng] Cisco Syst, Boxboro, MA USA.
C3 Simon Fraser University; Cisco Systems Inc
RP Khatoonabadi, SH (corresponding author), Simon Fraser Univ, Burnaby, BC V5A 1S6, Canada.
EM skhatoon@sfu.ca; ibajic@ensc.sfu.ca; yshan@cisco.com
RI Bajic, Ivan/I-1241-2013
OI Bajic, Ivan/0000-0003-3154-5743; Khatoonabadi, Sayed
   Hossein/0000-0002-9927-9595
FU Cisco Research Award CG [573690]; NSERC [RGPIN 327249]
FX This work was supported in part by the Cisco Research Award CG# 573690
   and NSERC Grant RGPIN 327249.
CR Agarwal G, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P133
   [Anonymous], 2004, OPT SCI TECHNOL
   [Anonymous], 1996, J ECON LIT
   [Anonymous], SIGNAL DETECTION THE
   Arvanitidou MG, 2009, 2009 10TH INTERNATIONAL WORKSHOP ON IMAGE ANALYSIS FOR MULTIMEDIA INTERACTIVE SERVICES, P173, DOI 10.1109/WIAMIS.2009.5031460
   BLOCHL PE, 1994, PHYS REV B, V50, P17953, DOI 10.1103/PhysRevB.50.17953
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Chakrabarty S, 2015, AIP ADV, V5, DOI 10.1063/1.4929576
   Dagan I, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P56, DOI 10.3115/979617.979625
   Einhäuser W, 2008, J VISION, V8, DOI 10.1167/8.2.2
   Faccio R, 2010, J PHYS CHEM C, V114, P18961, DOI 10.1021/jp106764h
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Ferrighi L, 2014, J PHYS CHEM C, V118, P223, DOI 10.1021/jp410966r
   Garcia-Diaz A, 2012, IMAGE VISION COMPUT, V30, P51, DOI 10.1016/j.imavis.2011.11.007
   Grimme S, 2006, J COMPUT CHEM, V27, P1787, DOI 10.1002/jcc.20495
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hadizadeh H, 2013, IEEE T MULTIMEDIA, V15, P2099, DOI 10.1109/TMM.2013.2281024
   Hadizadeh H, 2014, IEEE T IMAGE PROCESS, V23, P19, DOI 10.1109/TIP.2013.2282897
   Hadizadeh H, 2012, IEEE T IMAGE PROCESS, V21, P898, DOI 10.1109/TIP.2011.2165292
   Han S, 2010, VISION RES, V50, P2295, DOI 10.1016/j.visres.2010.05.034
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Itti L, 2005, PROC CVPR IEEE, P631
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, J ELECTRON IMAGING, V10, P161, DOI 10.1117/1.1333677
   Itti L, 2009, Advances in neural information processing systems, V49, P1295, DOI [10.1016/j.visres.2008.09.007, DOI 10.1016/J.VISRES.2008.09.007]
   Itti L, 2009, VISION RES, V49, P1295, DOI 10.1016/j.visres.2008.09.007
   Ji QG, 2013, SIGNAL PROCESS-IMAGE, V28, P241, DOI 10.1016/j.image.2012.11.008
   Keith JA, 2010, ANGEW CHEM INT EDIT, V49, P9521, DOI 10.1002/anie.201004794
   Khalilian H, 2013, IEEE T IMAGE PROCESS, V22, P4825, DOI 10.1109/TIP.2013.2278463
   Kim W, 2011, IEEE T CIRC SYST VID, V21, P446, DOI 10.1109/TCSVT.2011.2125450
   Kresse G, 1996, COMP MATER SCI, V6, P15, DOI 10.1016/0927-0256(96)00008-0
   Lazar P, 2014, PHYS CHEM CHEM PHYS, V16, P14231, DOI 10.1039/c4cp01638f
   Liu Z, 2009, PROCEEDINGS OF THE 8TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE, P568, DOI 10.1109/ICIS.2009.165
   Ma YF, 2002, IEEE IMAGE PROC, P129
   Mahadevan V, 2013, IEEE T PATTERN ANAL, V35, P541, DOI 10.1109/TPAMI.2012.98
   Moorthy AK, 2009, IEEE J-STSP, V3, P193, DOI 10.1109/JSTSP.2009.2015374
   Muthuswamy K, 2013, IEEE SIGNAL PROC LET, V20, P996, DOI 10.1109/LSP.2013.2277884
   Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019
   Radovic LR, 2011, CARBON, V49, P4218, DOI 10.1016/j.carbon.2011.05.059
   Segall MD, 2002, J PHYS-CONDENS MAT, V14, P2717, DOI 10.1088/0953-8984/14/11/301
   Sinha A, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P161
   Sljivancanin Z, 2013, CARBON, V54, P482, DOI 10.1016/j.carbon.2012.12.008
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhang LP, 2015, PHYS CHEM CHEM PHYS, V17, P16733, DOI 10.1039/c5cp02014j
NR 48
TC 18
Z9 19
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 22
BP 10057
EP 10075
DI 10.1007/s11042-015-2802-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV1LQ
UT WOS:000364019400013
DA 2024-07-18
ER

PT J
AU Tom, M
   Babu, RV
   Praveen, RG
AF Tom, Manu
   Babu, R. Venkatesh
   Praveen, R. Gnana
TI Compressed domain human action recognition in H.264/AVC video streams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264/AVC; Human action recognition; Compressed domain video analysis;
   Motion vectors; Quantization parameters
AB This paper discusses a novel high-speed approach for human action recognition in H.264/AVC compressed domain. The proposed algorithm utilizes cues from quantization parameters and motion vectors extracted from the compressed video sequence for feature extraction and further classification using Support Vector Machines (SVM). The ultimate goal of the proposed work is to portray a much faster algorithm than pixel domain counterparts, with comparable accuracy, utilizing only the sparse information from compressed video. Partial decoding rules out the complexity of full decoding, and minimizes computational load and memory usage, which can result in reduced hardware utilization and faster recognition results. The proposed approach can handle illumination changes, scale, and appearance variations, and is robust to outdoor as well as indoor testing scenarios. We have evaluated the performance of the proposed method on two benchmark action datasets and achieved more than 85 % accuracy. The proposed algorithm classifies actions with speed (> 2,000 fps) approximately 100 times faster than existing state-of-the-art pixel-domain algorithms.
C1 [Tom, Manu; Babu, R. Venkatesh; Praveen, R. Gnana] Indian Inst Sci, SERC, Video Analyt Lab, Bangalore 560012, Karnataka, India.
C3 Indian Institute of Science (IISC) - Bangalore
RP Babu, RV (corresponding author), Indian Inst Sci, SERC, Video Analyt Lab, Bangalore 560012, Karnataka, India.
EM venky@serc.iisc.in
RI Tom, Manu/ABV-9231-2022; Tom, Manu/AAJ-3815-2020; Radhakrishnan,
   Venkatesh Babu/D-5313-2009; Rajasekar, Gnana Praveen/ABI-4362-2020
OI Tom, Manu/0000-0002-0352-7153; Tom, Manu/0000-0002-0352-7153; Rajasekar,
   Gnana Praveen/0000-0002-4698-9198; Radhakrishnan, Venkatesh
   Babu/0000-0002-1926-1804
FU CARS (CARS-25) project from Centre for Artificial Intelligence and
   Robotics; Defence Research and Development Organization (DRDO), Govt. of
   India
FX This work was supported by CARS (CARS-25) project from Centre for
   Artificial Intelligence and Robotics, Defence Research and Development
   Organization (DRDO), Govt. of India.
CR Amiri S. M., 2012, P IEEE INT C IM PROC
   [Anonymous], 2012, INT J INTELLIGENCE S
   [Anonymous], BRIT MACH VIS C
   Babu RV, 2004, IMAGE VISION COMPUT, V22, P597, DOI 10.1016/j.imavis.2003.11.004
   Babu RV, 2002, PATTERN RECOGN LETT, V23, P1203, DOI 10.1016/S0167-8655(02)00067-3
   Biswas S, 2013, INT CONF ACOUST SPEE, P2040, DOI 10.1109/ICASSP.2013.6638012
   Blank M, 2005, P 10 INT C COMP VIS
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Kuehne H, P INT C COMP VIS ICC
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Li Z, 2008, P 16 ACM INT C MULT
   Lin Chin-An, 2012, P IEEE INT C IM PROC
   Liu C, 2010, IMAGE VISION COMPUT, V28, P825, DOI 10.1016/j.imavis.2009.07.009
   Ozer B., 2000, P WORKSH HUM MOT
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Schuldt C., 2004, P 17 INT C PATT REC, V3, P32
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tom M, 2013, NAT CONF COMPUT VIS
   Wang H., 2009, BMVC
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu B, 2012, P IEEE INT C IM PROC
   Yeo CH, 2008, IEEE T CIRC SYST VID, V18, P1006, DOI 10.1109/TCSVT.2008.927112
   Zhang H, 2012, P IEEE INT C E-SCI
NR 28
TC 12
Z9 14
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9323
EP 9338
DI 10.1007/s11042-014-2083-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200012
DA 2024-07-18
ER

PT J
AU Bhatnagar, G
   Wu, QMJ
AF Bhatnagar, Gaurav
   Wu, Q. M. Jonathan
TI A new robust and efficient multiple watermarking scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Multiple watermarks; DCT energy; Space filling
   curve; Essentially non-oscillatory point-value decomposition; Singular
   value decomposition
ID ENO SCHEMES; IMAGE
AB This paper presents a novel multiple watermarking scheme for copyright protection and authentication. The core idea is to segment the host image into non-overlapping blocks by the means of space filling curve and based on the amount of DCT energy in the blocks. The threshold values are then selected to embed multiple watermarks in different blocks. The watermarks are embedded into the image by modifying the singular values of the blocks. Finally, modified blocks are mapped back to their original positions using inverse space filling curve to get the watermarked image. A reliable extraction algorithm is finally developed for the extraction of watermarks from the distorted image. The feasibility of this method and its robustness against the different kind of attacks are verified by different computer simulations and analysis.
C1 [Bhatnagar, Gaurav; Wu, Q. M. Jonathan] Univ Windsor, Dept Elect & Comp Engn, Windsor, ON N9B 3P4, Canada.
C3 University of Windsor
RP Bhatnagar, G (corresponding author), Univ Windsor, Dept Elect & Comp Engn, Windsor, ON N9B 3P4, Canada.
EM goravdma@gmail.com; jwu@uwindsor.ca
RI Wu, Q.M.Jonathan/O-3234-2017; Bhatnagar, Gaurav/O-5817-2019
OI Bhatnagar, Gaurav/0000-0002-0282-3372; Wu, Q.M.
   Jonathan/0000-0002-5208-7975
FU Canada Chair Research Program; Natural Sciences and Engineering Research
   Council of Canada
FX This work was supported in part by the Canada Chair Research Program and
   the Natural Sciences and Engineering Research Council of Canada.
CR Amat S, 2001, APPL COMPUT HARMON A, V11, P273, DOI 10.1006/acha.2001.0356
   Bhatnagar G, 2009, J DIGITAL INFORM MAN, V7, P2
   Bhatnagar G, 2011, MULTIMED TOOLS APPL, V52, P621, DOI 10.1007/s11042-009-0433-2
   Bhatnagar G, 2009, COMPUT STAND INTER, V31, P1002, DOI 10.1016/j.csi.2008.09.031
   CANDES EJ, 2006, CURVES SURFACES, P105
   Choi Y., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P133, DOI 10.1109/ITCC.2000.844196
   Cintra RJ, 2009, SIGNAL PROCESS-IMAGE, V24, P587, DOI 10.1016/j.image.2009.04.003
   Cohen A, 2002, IEEE T INFORM THEORY, V48, P1895, DOI 10.1109/TIT.2002.1013132
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Djurovic I, 2001, J NETW COMPUT APPL, V24, P167, DOI 10.1006/jnca.2000.0128
   Ganic E, 2004, NEW YORK METR AR NET, P1
   Ghouti L, 2006, IEEE T SIGNAL PROCES, V54, P1519, DOI 10.1109/TSP.2006.870624
   HARTEN A, 1993, APPL NUMER MATH, V12, P153, DOI 10.1016/0168-9274(93)90117-A
   HARTEN A, 1989, J COMPUT PHYS, V83, P148, DOI 10.1016/0021-9991(89)90226-X
   HARTEN A, 1987, J COMPUT PHYS, V71, P231, DOI [10.1016/0021-9991(87)90031-3, 10.1006/jcph.1996.5632]
   Harten A, 1996, SIAM J NUMER ANAL, V33, P1205, DOI 10.1137/0733060
   Harten Ami., 1994, UCLA Computational and Applied Mathematics Report, P94
   Hu YJ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 5, PROCEEDINGS, P584
   Huang WL, 2006, IEEE INT C NETW SENS, P266
   Kallel M., 2007, GVIP J, V7, P37
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Liu CC, 2006, OPT ENG, V45, DOI 10.1117/1.2227370
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Liu Y, 2010, SIGNAL PROCESS, V90, P626, DOI 10.1016/j.sigpro.2009.08.001
   Lu W, 2012, MULTIMED TOOLS APPL, V60, P31, DOI 10.1007/s11042-011-0794-1
   Luo WB, 2002, FIFTH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, PROCEEDINGS, P158, DOI 10.1109/IAI.2002.999910
   Mallat S, 1998, IEEE T SIGNAL PROCES, V46, P1027, DOI 10.1109/78.668554
   Mintzer F, 1999, INT CONF ACOUST SPEE, P2067, DOI 10.1109/ICASSP.1999.758338
   Mohanty S. P., 1999, P 7 ACM INT C MUL OC, P49
   Peng ZN, 2008, CHAOS SOLITON FRACT, V36, P946, DOI 10.1016/j.chaos.2006.07.015
   Rui Chen, 2013, Journal of Convergence Information Technology, V8, P530, DOI 10.4156/jcit.vol8.issue5.60
   Shih F.Y., 2008, Digital Watermarking and Steganography: Fundamentals and Techniques
   Song CL, 2012, J VIS COMMUN IMAGE R, V23, P549, DOI 10.1016/j.jvcir.2012.01.017
   Tao PN, 2004, PROC SPIE, V5601, P133, DOI 10.1117/12.569641
   Tsai MJ, 2011, MULTIMED TOOLS APPL, V52, P347, DOI 10.1007/s11042-010-0475-5
   Wang S, 2007, IEEE T CIRC SYST VID, V17, P98, DOI 10.1109/TCSVT.2006.887086
   Wong PHW, 2003, IEEE T CIRC SYST VID, V13, P813, DOI 10.1109/TCSVT.2003.815948
   Yao T, 2013, ADV SCI LETT, V19, P1234
NR 38
TC 17
Z9 18
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8421
EP 8444
DI 10.1007/s11042-013-1681-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600011
DA 2024-07-18
ER

PT J
AU Choe, GM
   Wang, TJ
   Liu, F
   Choe, CH
   So, HS
AF Choe, Gwangmin
   Wang, Tianjiang
   Liu, Fang
   Choe, Chunhwa
   So, Hyoson
TI Visual tracking based on particle filter with spline resampling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spline resampling; Point spread function; Particle filter;
   Impoverishment; Visual tracking
ID ALGORITHM
AB We introduce the concept of a spline resampling in the particle filter to deal with the high accuracy and the sample impoverishment. The resampling is usually based on a linear transformation on the weights of the particles, so it affects the accurate filtering. The spline resampling consists of two parts: the spline transformation of weights and the spread transformation of states. The former is based on a spline transformation on the weights of the particles to obtain the high accuracy of particle filtering, and the latter is based on a point spread transformation on states of particles to prevent the sample impoverishment due to decline of the diversity of hypothesis after resampling. Two transformations are sequentially implemented to incorporate with each other. Then, we propose a global transition model in the particle filter, which takes account of the background variation caused by the camera motion model of object itself, to decrease error from real object position. We test the performance of our spline resampling and the global transition model in the particle filter in object tracking scenario. Experimental results demonstrate that particle filter with the spline resampling and the global transition model has the promising discriminative capability in comparison with other ones.
C1 [Choe, Gwangmin; Wang, Tianjiang; Liu, Fang] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Intelligent & Distributed Comp Lab, Wuhan 430074, Peoples R China.
   [Choe, Chunhwa; So, Hyoson] Kim Il Sung Univ, Sch Comp Sci & Technol, Visual Informat Proc Lab, Pyongyang, North Korea.
C3 Huazhong University of Science & Technology
RP Choe, GM (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Intelligent & Distributed Comp Lab, Wuhan 430074, Peoples R China.
EM cca2005@foxmail.com; tjwang@hust.edu.cn; Fang.Liu@hust.edu.cn
CR Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Douc R, 2005, ISPA 2005: Proceedings of the 4th International Symposium on Image and Signal Processing and Analysis, P64, DOI 10.1109/ISPA.2005.195385
   Fu XY, 2010, IEEE T SIGNAL PROCES, V58, P5414, DOI 10.1109/TSP.2010.2053031
   Gilks WR, 2001, J ROY STAT SOC B, V63, P127, DOI 10.1111/1467-9868.00280
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015
   Hearn D., 1997, Computer graphics
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Kotecha JH, 2003, IEEE T SIGNAL PROCES, V51, P2592, DOI 10.1109/TSP.2003.816758
   Liang J, 2008, ELECTRON LETT, V44, P1275, DOI 10.1049/el:20082403
   Liang J, 2008, ELECTRON LETT, V44, P553, DOI 10.1049/el:20080179
   Liang J., 2010, Recent Patents on Electrical Engineering, V3, P43, DOI 10.2174/1874476111003010043
   Musso C., 2001, IMPROVING REGULARIZE
   Pitt MK, 1999, J AM STAT ASSOC, V94, P590, DOI 10.2307/2670179
   Wu G, 2009, ICICTA: 2009 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTATION TECHNOLOGY AND AUTOMATION, VOL I, PROCEEDINGS, P507, DOI 10.1109/ICICTA.2009.129
   Yao AB, 2012, PATTERN RECOGN, V45, P2584, DOI 10.1016/j.patcog.2012.01.016
NR 16
TC 5
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 7195
EP 7220
DI 10.1007/s11042-014-1960-z
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800028
DA 2024-07-18
ER

PT J
AU Huang, H
   Li, XJ
   Zhao, HL
   Nie, GZ
   Hu, ZY
   Xiao, L
AF Huang, Hui
   Li, Xujie
   Zhao, Hanli
   Nie, Guizhi
   Hu, Zhongyi
   Xiao, Lei
TI Manifold-preserving image colorization with nonlocal estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Colorization; Recoloring; Manifold-preserving; KNN
ID COLOR
AB In this paper, we propose a novel scribble-based colorization method which embeds colors using reconstruction weights from nonlocal nearest texture-similar neighbors in image lightness channel. Our main idea is to exploit image textural features to optimize the color distribution with an energy minimization between a pixel and K nonlocal nearest texture-similar neighbors in the feature space. A manifold structure of image lightness channel is embedded into the color channel which best preserves the geometric properties of the original space. Our method is actually the combine of global and local optimum of the cost function, which can be solved with a sparse linear system. Experimental results show that the proposed method can produce higher-quality colorizations than existing methods with sparse constraints, while having better performance in color bleeding. Moreover, simplicity and ease of implementation of our method achieves good runtime performance.
C1 [Huang, Hui; Li, Xujie; Zhao, Hanli; Nie, Guizhi; Hu, Zhongyi; Xiao, Lei] Wenzhou Univ, Intelligent Informat Syst Inst, Wenzhou 325035, Peoples R China.
C3 Wenzhou University
RP Li, XJ (corresponding author), Wenzhou Univ, Intelligent Informat Syst Inst, Wenzhou 325035, Peoples R China.
EM huanghui@wzu.edu.cn; lixujie@aliyun.com; hanlizhao@gmail.com;
   nieguizhiwz@gmail.com; hujunyi@163.com; xiaolei@wzu.edu.cn
FU National Natural Science Foundation of China [61100146]; Zhejiang
   Provincial Natural Science Foundation of China [LQ12F02010]; Science and
   Technology Plan Program of Wenzhou, China [G20130017, S20100053]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61100146), the Zhejiang Provincial Natural Science
   Foundation of China (Grant No. LQ12F02010), and the Science and
   Technology Plan Program of Wenzhou, China(Grant No. G20130017 and No.
   S20100053).
CR An XB, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360639
   Bhat P, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731048
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Buatois L, 2009, INT J PARALLEL EMERG, V24, P205, DOI 10.1080/17445760802337010
   Chang H, 2006, PATTERN RECOGN, V39, P1053, DOI 10.1016/j.patcog.2005.07.011
   Chen QF, 2013, IEEE T PATTERN ANAL, V35, P2175, DOI 10.1109/TPAMI.2013.18
   Chen XW, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366151
   Criminisi A, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1857907.1857910
   Fattal R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531328
   Krishnan D, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024211
   Lagodzinski P., 2012, MULTIMED TOOLS APPL, P1
   Lee P., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2193, DOI 10.1109/CVPR.2011.5995665
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Lin S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461988
   Liu XP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409105
   Luan Q., 2007, P 18 EUR C CREND TEC, P309
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Qu YG, 2006, ACM T GRAPHIC, V25, P1214, DOI 10.1145/1141911.1142017
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sheng B, 2011, IEEE COMPUT GRAPH, V31, P24, DOI 10.1109/MCG.2011.18
   Wang BY, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964959
   Wang BY, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866172
   Xu L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508404
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
NR 24
TC 14
Z9 14
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7555
EP 7568
DI 10.1007/s11042-014-1991-5
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200007
DA 2024-07-18
ER

PT J
AU Ramakanth, SA
   Babu, RV
AF Ramakanth, S. Avinash
   Babu, R. Venkatesh
TI Synthetic image super resolution using FeatureMatch
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super resolution; PatchMatch; Synthetic images; Approximate
   nearest-neighbour field
ID SUPERRESOLUTION; DICTIONARY
AB In this paper, we propose a super resolution (SR) method for synthetic images using FeatureMatch. Existing state-of-the-art super resolution methods are learning based methods, where a pair of low-resolution and high-resolution dictionary pair are trained, and this trained pair is used to replace patches in low-resolution image with appropriate matching patches from the high-resolution dictionary. In this paper, we show that by using Approximate Nearest Neighbour Fields (ANNF), and a common source image, we can by-pass the learning phase, and use a single image for dictionary. Thus, reducing the dictionary from a collection obtained from hundreds of training images, to a single image. We show that by modifying the latest developments in ANNF computation, to suit super resolution, we can perform much faster and more accurate SR than existing techniques. To establish this claim we will compare our algorithm against various state-of-the-art algorithms, and show that we are able to achieve better and faster reconstruction without any training phase.
C1 [Ramakanth, S. Avinash; Babu, R. Venkatesh] Indian Inst Sci, Video Analyt Lab, SERC, Bangalore 560012, Karnataka, India.
C3 Indian Institute of Science (IISC) - Bangalore
RP Babu, RV (corresponding author), Indian Inst Sci, Video Analyt Lab, SERC, Bangalore 560012, Karnataka, India.
EM avinashrs@ssl.serc.iisc.in; venky@serc.iisc.ernet.in
RI Radhakrishnan, Venkatesh Babu/D-5313-2009
OI Radhakrishnan, Venkatesh Babu/0000-0002-1926-1804
FU Joint Advanced Technology Programme (JATP), Indian Institute of Science,
   Bangalore, India
FX This work was supported by Joint Advanced Technology Programme (JATP),
   Indian Institute of Science, Bangalore, India.
CR [Anonymous], 2009, INT C COMP VIS
   [Anonymous], P IND C COMP VIS GRA
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Borman S, 1999, 1998 MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, PROCEEDINGS, P374, DOI 10.1109/MWSCAS.1998.759509
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Gao XB, 2011, IEEE T IMAGE PROCESS, V20, P2738, DOI 10.1109/TIP.2011.2134859
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Kim SP, 1993, IEEE T IMAGE PROCESS, V2, P534, DOI 10.1109/83.242363
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Li XL, 2010, SIGNAL PROCESS, V90, P405, DOI 10.1016/j.sigpro.2009.05.028
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Ramakanth SA, 2014, IEEE T IMAGE PROCESS, V23, P2193, DOI 10.1109/TIP.2014.2309436
   Ramakanth SA, 2014, IEEE INT C EL COMP C
   Sudarshan S, 2012, ICVGIP
   Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang HC, 2010, LECT NOTES COMPUT SC, V6313, P566
   Zhang KB, 2012, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR.2012.6247791
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
NR 26
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 6691
EP 6707
DI 10.1007/s11042-014-1925-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800006
DA 2024-07-18
ER

PT J
AU Shi, C
   Liu, F
   Miao, QG
AF Shi, Cheng
   Liu, Fang
   Miao, Qiguang
TI Pan-sharpening via regional division and NSST
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pan-sharpening; NSST; Regional division; Similarity measure
ID IMAGE FUSION
AB In this paper, a novel Pan-sharpening algorithm for high resolution Panchromatic (HR PAN) and low resolution multispectral image (LR MS) via regional division and Non-sampled shift-invariance shearlet transform (NSST) is proposed. The purpose of our algorithm is to fuse the LR MS and the HR PAN image for different objects respectively, in order to solve the spectral distortion and spatial resolution problems in the Pan-sharpened image. Firstly, the LR MS and the HR PAN images are divided into structure and non-structure regions respectively, and a regional association map is set according to the division result. A regional similarity measure, degree of regional match (DRM), is proposed to evaluate the correction of the two regions. And a fusion rule is designed based on DRM. Because of the flexibility direction features, NSST can represent the edge information of the image better. Hence the LR MS and the HR PAN images are decomposed by the NSST, and the Pan-sharpened image can be obtained by the designed rule. Experimental results have proved that the proposed algorithm has a better Pan-sharpening result than other methods do.
C1 [Shi, Cheng; Liu, Fang; Miao, Qiguang] Xidian Univ, Sch Comp Sci & Technol, Xian, Shaanxi, Peoples R China.
   [Shi, Cheng; Liu, Fang] Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian, Shaanxi, Peoples R China.
   [Shi, Cheng; Liu, Fang] Xidian Univ, Int Res Ctr Intelligent Percept & Computat, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University; Xidian University
RP Miao, QG (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian, Shaanxi, Peoples R China.
EM qgmiao@163.com
OI Miao, Qiguang/0000-0002-2872-388X
FU National Basic Research Program (973 Programs) of China [2013CB329402];
   National Natural Science Foundations of China [61173090, 61072109,
   61272280, 41271447, 61272195]; Program for New Century Excellent Talents
   in Universtity [NCET-12-0919]; Fundamental Research Funds for the
   Central Universities [K5051203020, K5051203001, K5051303016,
   K5051303018, K50513100006]; Creative Project of Science and Technology
   State of xi'an [CXY1341(6)]; National Research Foundation for the
   Doctoral Program of Higher Education of China [20110203110006]; Fund for
   Foreign Scholars in University Research and Teaching Programs (the 111
   Project) [B07048]; Program for Cheung Kong Scholars and Innovative
   Research Team University [IRT1170]; EU [247619]
FX The work was jointly supported by the National Basic Research Program
   (973 Programs) of China (No. 2013CB329402), the National Natural Science
   Foundations of China (No. 61173090, 61072109, 61272280, 41271447,
   61272195), the Program for New Century Excellent Talents in Universtity
   (NCET-12-0919), The Fundamental Research Funds for the Central
   Universities (No. K5051203020, K5051203001, K5051303016, K5051303018 and
   K50513100006), the Creative Project of Science and Technology State of
   xi'an (No. CXY1341(6)), the National Research Foundation for the
   Doctoral Program of Higher Education of China (No. 20110203110006), the
   Fund for Foreign Scholars in University Research and Teaching Programs
   (the 111 Project) (No. B07048), the Program for Cheung Kong Scholars and
   Innovative Research Team University (NO. IRT1170). An EU FP7 IRSES grant
   (No. 247619) on "Nature Inspired Computation and its Applications
   (NICaiA)".
CR Antoine JP, 1999, APPL COMPUT HARMON A, V6, P314, DOI 10.1006/acha.1998.0255
   Ballester C, 2006, INT J COMPUT VISION, V69, P43, DOI 10.1007/s11263-006-6852-x
   Candès EJ, 1999, PHILOS T R SOC A, V357, P2495, DOI 10.1098/rsta.1999.0444
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chen SH, 2008, SENSORS-BASEL, V8, P520, DOI 10.3390/s8010520
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   El-Mezouar MC, 2011, IEEE T GEOSCI REMOTE, V49, P1590, DOI 10.1109/TGRS.2010.2087029
   Guo K, 2007, SIAM J MATH ANAL, V39, P298, DOI 10.1137/060649781
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Lim W Q, 2009, SAMPTA 09 INT C SAMP
   Lim WQ, 2010, IEEE T IMAGE PROCESS, V19, P1166, DOI 10.1109/TIP.2010.2041410
   Miao QG, 2011, OPT COMMUN, V284, P1540, DOI 10.1016/j.optcom.2010.11.048
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Rahmani S, 2010, IEEE GEOSCI REMOTE S, V7, P746, DOI 10.1109/LGRS.2010.2046715
   Ranchin T, 2000, PHOTOGRAMM ENG REM S, V66, P49
   Saeedi J, 2011, ISPRS J PHOTOGRAMM, V66, P365, DOI 10.1016/j.isprsjprs.2011.01.006
   Shah VP, 2008, IEEE T GEOSCI REMOTE, V46, P1323, DOI 10.1109/TGRS.2008.916211
   Shahdoosti H R, 2012, ART INT SIGN PROC AI, P090
   Shi C, 2013, NEUROCOMPUTING, V117, P47, DOI 10.1016/j.neucom.2012.10.025
   Te-Ming Tu, 2001, Information Fusion, V2, P177, DOI 10.1016/S1566-2535(01)00036-7
   Tu TM, 2004, IEEE GEOSCI REMOTE S, V1, P309, DOI 10.1109/LGRS.2004.834804
   Wang ZJ, 2005, IEEE T GEOSCI REMOTE, V43, P1391, DOI 10.1109/TGRS.2005.846874
   Zhang Y, 2005, INFORM FUSION, V70, P225
NR 25
TC 1
Z9 2
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7843
EP 7857
DI 10.1007/s11042-014-2027-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200020
DA 2024-07-18
ER

PT J
AU Park, KC
   Shin, H
   Park, WH
   Lim, JI
AF Park, Kwang Cheol
   Shin, Hoon
   Park, Won Hyung
   Lim, Jong In
TI New detection method and countermeasure of cyber attacks in mix networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mix networks; TOR; Cyber attack; Ext node; Blacklist IP
AB Recently, studies on the Mixed Networking which guarantees the anonymity in Internet environment are actively carried. Since this technology uses the coded communication and its communication paths are changed frequently, it is difficult to detect attacks of the hackers. In this situation, if the cyber-attack occurs between countries, there shall be a high potential for the hackers to use the anonymous network technology in order to hide themselves. Anyway, the anonymous network technology is continuously being updated by the hackers and a new technology is under development. Thus, this paper verified statistically the attacking methods which the hackers shall create by increasing the data transmission rate of TOR through manipulating the speed of the anonymous network, and proposed political countermeasures to detect hacker's attacks effectively which use this technology.
C1 [Park, Kwang Cheol; Shin, Hoon; Lim, Jong In] Korea Univ, Grad Sch Informat Secur, Ctr Informat Secur Technol, Seoul, South Korea.
   [Park, Won Hyung] Far East Univ, Dept Cyber Secur, Chungbuk 369700, South Korea.
C3 Korea University
RP Park, KC (corresponding author), Korea Univ, Grad Sch Informat Secur, Ctr Informat Secur Technol, Anam 5ga, Seoul, South Korea.
EM muryo@naver.com; kadosu@daum.net; whpark@kdu.ac.kr; jilim@korea.ac.kr
CR [Anonymous], 2007, RECHTENFORUM
   Bauer K, 2007, WPES'07: PROCEEDINGS OF THE 2007 ACM WORKSHOP ON PRIVACY IN ELECTRONIC SOCIETY, P11
   Kim Jeong Wook, 2009, J BIOL ENG, P3
   Murdoch Steven J., 2006, TOR ANONYMOUS INTERN
   Murdoch Steven J., 2007, IEEE S SEC PRIV
   PERRY M, 2009, HOTPETS 2009, P14
   Suess Martin, 2008, BREAKING TOR ANONYMI
   Timothy G., 2007, BROWSER BASED ATTACK
NR 8
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6509
EP 6518
DI 10.1007/s11042-014-2127-7
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700027
DA 2024-07-18
ER

PT J
AU Hassan, MM
AF Hassan, Mohammad Mehedi
TI Cost-effective resource provisioning for multimedia cloud-based e-health
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia cloud; e-health system; Resource allocation; Optimization;
   Game theory
ID VIRTUAL MACHINES; CONSOLIDATION; OPTIMIZATION; MANAGEMENT; ALLOCATION
AB Recently, multimedia cloud is being considered as a new effective serving mode in e-Health area that meets the requirement of scalable and economic multimedia service for e-health. It can provide a flexible stack of powerful Virtual Machine (VM) resources of cloud like CPU, memory, storage, network bandwidth etc. on demand to manage e-health media services and applications (e.g. medical image/video retrieval, health video transcoding, streaming, video rendering, sharing and delivery) at lower cost. However, one major issue here is how to efficiently allocate VM resources dynamically based on e-health applications' QoS demands and support energy and cost savings by optimizing the number of servers in use. In order to solve this problem, we propose a cost effective and dynamic VM allocation model based on Nash bargaining solution. With extensive simulations it is shown that the proposed mechanism can reduce the overall cost of running servers while at the same time guarantee QoS demand and maximize resource utilization in various dimensions of server resources.
C1 [Hassan, Mohammad Mehedi] King Saud Univ, Coll Comp & Informat Sci, Dept Informat Syst, Riyadh, Saudi Arabia.
   [Hassan, Mohammad Mehedi] King Saud Univ, Coll Comp & Informat Sci, Chair Pervas & Mobile Comp, Riyadh, Saudi Arabia.
C3 King Saud University; King Saud University
RP Hassan, MM (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Dept Informat Syst, Riyadh, Saudi Arabia.
EM mmhassan@ksu.edu.sa
RI Hassan, Mohammad Mehedi/D-4946-2016; Hassan, Mohammad/KDM-9524-2024;
   Hassan, Mohammad/GZA-7507-2022
OI Hassan, Mohammad/0000-0002-1712-0004
FU Research Center of College of Computer and Information Sciences, King
   Saud University, Riyadh, Kingdom of Saudi Arabia
FX This work was supported by the Research Center of College of Computer
   and Information Sciences, King Saud University, Riyadh, Kingdom of Saudi
   Arabia. The author is grateful for this support.
CR Aisopos F, 2013, INT J PROD ECON, V141, P465, DOI 10.1016/j.ijpe.2011.12.011
   [Anonymous], 2010, 2010 IEEE INT C COMP
   [Anonymous], 2010, 10 IEEE INT C INFORM
   [Anonymous], 2008, P INT S WORLD WIRELE, DOI DOI 10.1109/W0WM0M.2008.4594857
   Beloglazov A, 2012, CONCURR COMP-PRACT E, V24, P1397, DOI 10.1002/cpe.1867
   Beloglazov A, 2012, FUTURE GENER COMP SY, V28, P755, DOI 10.1016/j.future.2011.04.017
   Biao Song, 2010, Proceedings of the 2010 IEEE 2nd International Conference on Cloud Computing Technology and Science (CloudCom 2010), P360, DOI 10.1109/CloudCom.2010.53
   Bohai Hong, 2013, 2013 IEEE 4th International Conference on Software Engineering and Service Science (ICSESS), P841, DOI 10.1109/ICSESS.2013.6615436
   Borwein JonathanM., 2010, Convex analysis and nonlinear optimization: theory and examples, V3
   Calheiros RN, 2011, SOFTWARE PRACT EXPER, V41, P23, DOI 10.1002/spe.995
   Fei Teng, 2010, Proceedings of the 2010 IEEE 10th International Conference on Computer and Information Technology (CIT 2010), P195, DOI 10.1109/CIT.2010.70
   Feng Y, 2012, IEEE INFOCOM SER, P1134, DOI 10.1109/INFCOM.2012.6195472
   Ferreto TC, 2011, FUTURE GENER COMP SY, V27, P1027, DOI 10.1016/j.future.2011.04.016
   Goiri I, 2012, FUTURE GENER COMP SY, V28, P718, DOI 10.1016/j.future.2011.12.002
   Hassan MM, 2014, INFORM SYST FRONT, V16, P523, DOI 10.1007/s10796-012-9357-x
   Hossain MS, 2008, MULTIMEDIA SYST, V14, P135, DOI 10.1007/s00530-008-0124-2
   Hossain MS, 2012, IEEE INT CONF MULTI, P408, DOI 10.1109/ICMEW.2012.77
   Hossain MS, 2010, IEEE T INSTRUM MEAS, V59, P1498, DOI 10.1109/TIM.2009.2024338
   Hossain MS, 2009, CONCURR COMP-PRACT E, V21, P1450, DOI 10.1002/cpe.1400
   Hui Wen, 2011, 2011 International Conference on Electronic & Mechanical Engineering and Information Technology (EMEIT 2011), P165, DOI 10.1109/EMEIT.2011.6022888
   Jain Navendu., 2012, Proceedings of the Twenty-fourth Annual ACM Symposium on Parallelism in Algorithms and Architectures, SPAA '12, P255
   Jinman Kim, 2002, Proceedings 2002 IEEE International Conference on Multimedia and Expo (Cat. No.02TH8604), P341, DOI 10.1109/ICME.2002.1035599
   Jones VM, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P824
   Li Y, 2013, PROCEEDINGS OF THE 2013 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP), P247
   Lin W.P., 2010, IPFA, P1, DOI [DOI 10.1109/ITAPP.2010.5566394, 10.1109/POWERCON.2010.5666123, DOI 10.1109/ICVES.2010.5550951]
   Miao Dan., 2011, Proceedings of the 19th ACM international conference on Multimedia, P1237
   Myerson Roger B., 1997, Game theory: analysis of conflict
   Nan XM, 2014, J VIS COMMUN IMAGE R, V25, P928, DOI 10.1016/j.jvcir.2014.02.008
   Nan XM, 2013, IEEE INT SYMP CIRC S, P2872, DOI 10.1109/ISCAS.2013.6572478
   Nan XM, 2011, IEEE INT WORKSH MULT
   Nan XM, 2012, IEEE INT SYMP CIRC S, P1111
   Nan XM, 2012, IEEE INT WORKSH MULT, P175, DOI 10.1109/MMSP.2012.6343436
   Nkosi M. T., 2010, Proceedings of the 2010 IEEE 2nd International Conference on Cloud Computing Technology and Science (CloudCom 2010), P629, DOI 10.1109/CloudCom.2010.31
   Oikonomou A, 2003, P ANN INT IEEE EMBS, V25, P1295, DOI 10.1109/IEMBS.2003.1279506
   Rolim CO, 2010, SECOND INTERNATIONAL CONFERENCE ON EHEALTH, TELEMEDICINE, AND SOCIAL MEDICINE: ETELEMED 2010, PROCEEDINGS, P95, DOI 10.1109/eTELEMED.2010.19
   Sembiring K, 2013, P INT WORKSHOP NETWO, P49, DOI DOI 10.1145/2460782.2460791
   Sittig DF, 2009, JAMA-J AM MED ASSOC, V302, P1111, DOI 10.1001/jama.2009.1311
   Stillwell M, 2010, J PARALLEL DISTR COM, V70, P962, DOI 10.1016/j.jpdc.2010.05.006
   Timar Y, 2010, 2010 SECOND INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, COMMUNICATION SYSTEMS AND NETWORKS (CICSYN), P37, DOI 10.1109/CICSyN.2010.60
   Van HN, 2009, CLOUD: 2009 ICSE WORKSHOP ON SOFTWARE ENGINEERING CHALLENGES OF CLOUD COMPUTING, P1, DOI 10.1109/CLOUD.2009.5071526
   Wei GY, 2010, J SUPERCOMPUT, V54, P252, DOI 10.1007/s11227-009-0318-1
   Wong KKL, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010331
   Xiao Z, 2013, IEEE T PARALL DISTR, V24, P1107, DOI 10.1109/TPDS.2012.283
   Yuan-Chu Hwang, 2010, Proceedings of the 2010 Sixth International Conference on Networked Computing and Advanced Information Management (NCM 2010), P700
   Zhou L, 2013, IEEE WIREL COMMUN, V20, P54, DOI 10.1109/MWC.2013.6549283
   Zhu WW, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2011.940269
NR 46
TC 17
Z9 18
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 14
BP 5225
EP 5241
DI 10.1007/s11042-014-2040-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XU
UT WOS:000358214900016
DA 2024-07-18
ER

PT J
AU An, NT
   Huynh, CT
   Lee, B
   Hong, CS
   Huh, EN
AF Nguyen Thuy An
   Cong-Thinh Huynh
   Lee, ByungKwan
   Hong, Choong Seon
   Huh, Eui-Nam
TI An efficient block classification for media healthcare service in mobile
   cloud computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Healthcare; Mobile thin client; Image processing; Remote protocol;
   Visualization; Block classification
ID COMPOUND IMAGES; COMPRESSION
AB Recently, the strict investment in healthcare domain achieves the professional quality and convenient demands of customers. Especially, with the rapid growth of modern high technology, healthcare is providing many kinds of services for patients. One of those is mobile healthcare that is the integration of mobile computing and health monitoring. By using remote protocol, the service via mobile can directly send the patient heart failure sign to the doctor. Among the existing client-server protocols, Remote Desktop Protocol (RDP) is the typical method but it needs enhancement to adapt for more rigorous requirements: real time, quality of service (QoS), etc. In this paper, we present the architecture with flexibly coding screen image to improve quality of experience (QoE) of users and ensure low bandwidth services. Besides, in order to guarantee the best image quality and reduce redundant communication by using different compression encoding techniques for movies, images and other formats. Based on the edge detection Sobel operator that strongly focuses through horizontal, vertical direction and low complexity computation, our proposed method introduces the efficient block classification for the media healthcare services.
C1 [Nguyen Thuy An; Cong-Thinh Huynh; Hong, Choong Seon; Huh, Eui-Nam] Kyung Hee Univ, Dept Comp Engn, Yongin, Gyeonggi, South Korea.
   [Lee, ByungKwan] Kwandong Univ, Dept Comp, Kangnung 210701, Gangwo, South Korea.
C3 Kyung Hee University; Catholic Kwandong University
RP An, NT (corresponding author), Kyung Hee Univ, Dept Comp Engn, 1 Seocheon, Yongin, Gyeonggi, South Korea.
EM thuyannguyen306@gmail.com; thinhhc@gmail.com; bklee@kd.ac.kr;
   cshong@khu.ac.kr; johnhuh@khu.ac.kr
RI Hong, Choong Seon/ABF-5527-2020
OI Hong, Choong Seon/0000-0003-3484-7333
FU MSIP (Ministry of Science, ICT & Future Planning), Korea, under the ITRC
   (Information Technology Research Center) [NIPA-2013-H0301-13-4006];
   Kyung Hee University [KHU-20111209]; National Research Foundation of
   Korea [21A20131612192] Funding Source: Korea Institute of Science &
   Technology Information (KISTI), National Science & Technology
   Information Service (NTIS)
FX This research was supported by the MSIP (Ministry of Science, ICT &
   Future Planning), Korea, under the ITRC (Information Technology Research
   Center) support program (NIPA-2013-H0301-13-4006) supervised by the NIPA
   (National IT Industry Promotion Agency) and was partially supported by a
   grant from the Kyung Hee University in 2011 (KHU-20111209). Professor
   Eui-Nam Huh is corresponding author.
CR [Anonymous], CUCS02704
   [Anonymous], MULTISENSOR MULTISOU
   [Anonymous], REMOTE DISPLAY SOLUT
   [Anonymous], PERV COMP COMM 9 13
   [Anonymous], VIRTUALIZED SCREEN 3
   [Anonymous], P 16 INT C 3D WEB TE
   Bottou L, 1998, J ELECTRON IMAGING, V7, P410, DOI 10.1117/1.482609
   Imai T, 2010, IEEE GLOBE WORK, P1136, DOI 10.1109/GLOCOMW.2010.5700112
   Juliet SE, 2011, IET IMAGE PROCESS, V5, P306, DOI 10.1049/iet-ipr.2009.0237
   Kaplinsky KV, 2001, MODERN TECHNIQUES AND TECHNOLOGY, P155, DOI 10.1109/MTT.2001.983781
   Keslassy I, 2001, IEEE IMAGE PROC, P750, DOI 10.1109/ICIP.2001.959154
   Kumar K, 2010, COMPUTER, V43, P51, DOI 10.1109/MC.2010.98
   Lin T, 2005, IEEE T IMAGE PROCESS, V14, P993, DOI 10.1109/TIP.2005.849776
   Richardson T, 1998, IEEE INTERNET COMPUT, V2, P33, DOI 10.1109/4236.656066
   Said A, 2004, PROC SPIE, V5308, P69, DOI 10.1117/12.532433
   Simoens P, 2008, ATNAC: 2008 AUSTRALASIAN TELECOMMUNICATION NETWOKS AND APPLICATIONS CONFERENCE, P391, DOI 10.1109/ATNAC.2008.4783356
   Tan KJ, 2010, IEEE INT CON MULTI, P992, DOI 10.1109/ICME.2010.5582993
   Yang C, 2007, IEEE INT S WORLD WIR, P1
NR 18
TC 4
Z9 5
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 14
BP 5209
EP 5223
DI 10.1007/s11042-014-2039-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XU
UT WOS:000358214900015
DA 2024-07-18
ER

PT J
AU Chang, B
   Park, S
   Ihm, I
AF Chang, Byungjoon
   Park, Sanghun
   Ihm, Insung
TI Diffuse global illumination in particle spaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Global illumination; Diffuse interreflection; Particle space; Ray
   tracing; Photon mapping and final gathering; Multiple bounces
AB Despite substantial efforts in recent years to accelerate rendering methods, the traditional method, based on a combination of recursive ray tracing (RT), photon mapping (PM), and final gathering (FG), is still regarded as computationally intensive. In this paper, we propose a practical ray tracing model that can be readily implemented on a graphics processing unit (GPU) to provide high-speed generation of global illumination, whose quality is comparable to that generated through the traditional time-consuming RT/PM/FG rendering method. Our method employs two particle spaces to generate computationally intensive diffuse interreflection more efficiently. The complexity of light transport within a scene is simulated in one particle space by using indirect light scattering and gathering operations. The calculation that estimates the reflected radiance caused by diffuse interreflection is optimized by using a second particle space, where only the radiance required for final rendering can be rapidly approximated, based on the simulated light flux in the first particle space. We present several example scenes to demonstrate that our ray tracing scheme enables the use of a rendering pipeline that fully exploits the computing architecture of current manycore processors to reproduce effective high-quality global illumination.
C1 [Chang, Byungjoon] Samsung Elect, Digital Media & Commun R&D Ctr, Graph Lab, Suwon 443742, South Korea.
   [Park, Sanghun] Dongguk Univ, Dept Multimedia, Seoul 100715, South Korea.
   [Ihm, Insung] Sogang Univ, Dept Comp Sci & Engn, Seoul 121742, South Korea.
C3 Samsung Electronics; Samsung; Dongguk University; Sogang University
RP Park, S (corresponding author), Dongguk Univ, Dept Multimedia, Seoul 100715, South Korea.
EM bj81.chang@samsung.com; mshpark@dongguk.edu; ihm@sogang.ac.kr
FU National Research Foundation of Korea (NRF) - Korea government (MOE)
   [2012R1A1A2008958]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MOE) (No. 2012R1A1A2008958).
CR [Anonymous], ACM T GRAPH
   Arikan O, 2005, ACM T GRAPHIC, V24, P1108, DOI 10.1145/1073204.1073319
   Christensen P, 2008, 0801 PIX
   Dachsbacher C., 2005, Proc. Symp. Interactive Graph. and Games, P203, DOI DOI 10.1145/1053427.1053460
   Dachsbacher C., 2006, Proc. Symp. Interactive 3D Graph. and Games, Redwood City, P93, DOI DOI 10.1145/1111411.1111428
   Dachsbacher C, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239512
   Dong Z, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P77, DOI 10.1109/PG.2007.37
   Drettakis G., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P57, DOI 10.1145/258734.258772
   Fabianowski B, 2009, COMPUT GRAPH FORUM, V28, P1151, DOI 10.1111/j.1467-8659.2009.01492.x
   Gautron Pascal., 2005, Proceedings of the Eurographics Symposium on Rendering, P55
   Granier X, 2001, COMPUT GRAPH FORUM, V20, pC268, DOI 10.1111/1467-8659.00519
   Hasan M, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239477
   Jensen H. W., 1996, Rendering Techniques '96. Proceedings of the Eurographics Workshop. Eurographics, P21
   Jensen HW., 2001, REALISTIC IMAGE SYNT, DOI [10.1201/9780429294907, DOI 10.1201/9780429294907]
   Jin B., 2009, P C HIGH PERFORMANCE, P117
   Kajiya J. T., 1986, SIGGRAPH, P143, DOI 10.1145/15886.15902
   Keller A., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P49, DOI 10.1145/258734.258769
   Krivánek J, 2005, IEEE T VIS COMPUT GR, V11, P550, DOI 10.1109/TVCG.2005.83
   Laine S., 2007, P EUR S REND, P277, DOI DOI 10.2312/EGWR/EGSR07/277-286
   Larsen BentDalgaard., 2004, Rendering Techniques, P123
   Lehtinen J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360636
   McGuire Morgan., 2009, Proceedings of the Conference on High Performance Graphics, P77, DOI [10.1145/1572769.1572783, DOI 10.1145/1572769.1572783]
   Nichols G., 2009, P 2009 S INTERACTIVE, P83, DOI DOI 10.1145/1507149.1507162
   Nichols G, 2009, COMPUT GRAPH FORUM, V28, P1141, DOI 10.1111/j.1467-8659.2009.01491.x
   NVIDIA, 2012, NVIDIA CUDA NVIDA CU
   Purcell T., 2003, SIGGRAPHEUROGRAPHICS, P41
   Ritschel T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618478
   Ritschel T, 2012, COMPUT GRAPH FORUM, V31, P160, DOI 10.1111/j.1467-8659.2012.02093.x
   Ritschel Tobias., 2008, Proceedings of Graphics Interface, P185
   Schmitz A, 2008, COMPUT GRAPH FORUM, V27, P1979, DOI 10.1111/j.1467-8659.2008.01347.x
   Sloan PP, 2002, ACM T GRAPHIC, V21, P527, DOI 10.1145/566570.566612
   Tabellion E, 2004, ACM T GRAPHIC, V23, P469, DOI 10.1145/1015706.1015748
   Umenhoffer T, 2007, P WSCG
   Walter B, 2005, ACM T GRAPHIC, V24, P1098, DOI 10.1145/1073204.1073318
   Walter B, 2006, ACM T GRAPHIC, V25, P1081, DOI 10.1145/1141911.1141997
   Wang R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531397
   Ward G. J., 1992, Proceedings of the Third Eurographics Workshop on Rendering, P85
   Ward G. J., 1988, Computer Graphics, V22, P85, DOI 10.1145/378456.378490
   Yao CH, 2010, COMPUT GRAPH FORUM, V29, P1315, DOI 10.1111/j.1467-8659.2010.01727.x
   Zhou K, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409079
NR 40
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4987
EP 5006
DI 10.1007/s11042-014-2132-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400026
DA 2024-07-18
ER

PT J
AU Li, Z
   Peng, JY
   Geng, GH
   Chen, XJ
   Zheng, PP
AF Li, Zhan
   Peng, Jin-Ye
   Geng, Guo-Hua
   Chen, Xiao-Jiang
   Zheng, Pan-Pan
TI Video recommendation based on multi-modal information and multiple
   kernel
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video recommendation; Multi-modal information; Multiple kernel;
   Collaborative filtering
AB Collaborative Filter (CF) algorithms often suffer from data sparsity and item cold start problem, for the user-item matrix is insufficient and extremely sparse especially when new item is added to recommendation system. These two problems also exist in video recommendation process. We propose two methods to solve them by incorporating multimodal information and multiple kernel together. To solve item cold start problem, we learn a user taste hyper-plane by using multiple kernel SVM to represent the user taste, which is further used to predict the recommendation of new added videos. We combine the different user taste hyper-plane similarity and the traditional cosine similarity with a trade-off between them to address the data sparse problem. Experimental results show that our proposed algorithm can alleviate the data sparsity and item cold start problems.
C1 [Li, Zhan; Peng, Jin-Ye; Geng, Guo-Hua; Chen, Xiao-Jiang; Zheng, Pan-Pan] Northwest Univ, Sch Informat Sci & Technol, Xian 710069, Peoples R China.
C3 Northwest University Xi'an
RP Li, Z (corresponding author), Northwest Univ, Sch Informat Sci & Technol, Xian 710069, Peoples R China.
EM lizhan@nwu.edu.cn
RI Peng, Jin/HZH-6965-2023
FU Special Prophase Project on special fund (973 Program) [2011CB311802];
   Research Fund for the Doctoral Program of Higher Education of China
   [20106102110028, 20116102110027, 20126101110022]; Natural Science
   Foundation of Shaanxi Province of China [2013JQ8022, 2013JM8031];
   National Natural Science Foundation of China [61172123, 61373117,
   61172170]; Excellent Youth Research Star of Shaanxi Province of China
   [2012KJXX-35]
FX This research is partly supported by the Special Prophase Project on
   special fund (973 Program) (Grant No. 2011CB311802), by the Research
   Fund for the Doctoral Program of Higher Education of China (Grant No.
   20106102110028. 20116102110027 and 20126101110022), by Natural Science
   Foundation of Shaanxi Province of China (Grant No. 2013JQ8022 and
   2013JM8031). National Natural Science Foundation of China (Grant No.
   61172123,61373117,61172170), Excellent Youth Research Star of Shaanxi
   Province of China (Grant No. 2012KJXX-35). And we would also like to
   thank Jun-li Liang for his help during the revision process and the
   editors and anonymous reviewers for their valuable comments and helpful
   suggestions, which greatly improved the quality of this paper.
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   [Anonymous], 2011, P 5 ACM C REC SYST, DOI 10.1145/2043932.2043979
   [Anonymous], 2007, P 6 ACM INT C IM VID
   [Anonymous], P 4 INT C INT ENV
   Bach Francis R, 2004, P 21 INT C MACH LEAR, P6, DOI 10.1145/1015330.1015424
   Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124
   Baluja S, 2008, WORLD WID WEB C, P895
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   Eck D., 2007, Advances in Neural Information Processing Systems, P385
   Gao Y, 2009, IEEE T CIRC SYST VID, V19, P120
   Grauman K, 2007, J MACH LEARN RES, V8, P725
   Grcar M, 2006, STUD CLASS DATA ANAL, P251, DOI 10.1007/3-540-34416-0_27
   Gu Q., 2010, P SIAM INT C DAT MIN, P199, DOI 10.1137/1.9781611972801.18
   Guibing Guo, 2012, User Modeling, Adaptation, and Personalization. Proceedings 20th International Conference, UMAP 2012, P361, DOI 10.1007/978-3-642-31454-4_36
   Konstan JA, 1997, COMMUN ACM, V40, P77, DOI 10.1145/245108.245126
   Li B., 2009, P 26 ANN INT C MACH, P617, DOI DOI 10.1145/1553374.1553454
   Luo HZ, 2009, LECT NOTES COMPUT SC, V5371, P459
   MacQueen J, 1999, BERK S MATH STAT PRO, P281
   Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159
   Purushotham S, 2012, INT C MACH LEARN ICM, P223
   SARWAR BM, 2000, ACM WEBKDD 2000 WEB
   Shardanand U., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P210, DOI 10.1145/223904.223931
   Xia Z, 2006, 44 ANN SE REG C MELB, DOI [10.1145/1185448.1185487, DOI 10.1145/1185448.1185487]
   Xu JA, 2006, 12TH INTERNATIONAL MULTI-MEDIA MODELLING CONFERENCE PROCEEDINGS, P401
   Zhang DQ, 2007, IEEE VTS VEH TECHNOL, P267, DOI 10.1109/VETECS.2007.67
   Zhang ML, 2009, APPL INTELL, V31, P47, DOI 10.1007/s10489-007-0111-x
NR 26
TC 3
Z9 3
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4599
EP 4616
DI 10.1007/s11042-013-1825-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400007
DA 2024-07-18
ER

PT J
AU Hamghalam, M
   Mirzakuchaki, S
   Akhaee, MA
AF Hamghalam, Mohammad
   Mirzakuchaki, Sattar
   Akhaee, Mohammad Ali
TI Vertex angle image watermarking with optimal detector
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Vertex angle; Maximum likelihood detector; Gain
   attack
ID QUANTIZATION INDEX MODULATION; EMBEDDING SCHEME; ROBUST; INVARIANT
AB This paper presents a robust image watermarking method based on geometric modeling. Four samples of wavelet approximation transform on each image block along with the mean value of other coefficients on that block are modeled as three points in 2-D space. The length and width coordinate of the point associated with the mean value are equal. Two line segments with a shared endpoint can be drawn using these three points. The vertex angle formed between the line segments is utilized as a watermarking variable. In order to embed message bits, the vertex angle is altered by displacing of points. To preserve the imperceptibility of the watermark, geometrical tools are elegantly used to minimize the embedding distortion. Moreover, Maximum likelihood decoder is implemented at the receiver side. To this end, the probability density function of the noisy embedded angles is well approximated by the Beta distribution for wavelet approximation coefficients of images. Due to embedding in the vertex angle, the proposed scheme is not vulnerable to the gain attack. Using the low frequency components of the image blocks and the mean value of each block makes the proposed method robust to the noise and compression attacks. Experimental results confirm the validity of the theoretical analyses given in the paper and show the superiority of the method in contrast to similar techniques in this field.
C1 [Hamghalam, Mohammad; Mirzakuchaki, Sattar] Iran Univ Sci & Technol, Dept Elect Engn, Tehran 1684613114, Iran.
   [Akhaee, Mohammad Ali] Univ Tehran, Dept Elect & Comp Engn, Coll Engn, Tehran 1458889694, Iran.
C3 Iran University Science & Technology; University of Tehran
RP Hamghalam, M (corresponding author), Iran Univ Sci & Technol, Dept Elect Engn, Tehran 1684613114, Iran.
EM m.hamghalam@gmail.com; m_kuchaki@iust.ac.ir; akhaee@ut.ac.ir
RI Mirzakuchaki, Sattar/JCO-4452-2023; Hamghalam, Mohammad/X-7134-2019;
   Mirzakuchaki, Sattar/I-8764-2016
OI Hamghalam, Mohammad/0000-0003-2543-0712; Mirzakuchaki,
   Sattar/0000-0003-0232-9267
CR Akhaee MA, 2010, INT CONF ACOUST SPEE, P1746, DOI 10.1109/ICASSP.2010.5495452
   Akhaee MA, 2011, IEEE T INF FOREN SEC, V6, P883, DOI 10.1109/TIFS.2011.2146250
   Akhaee MA, 2010, SIGNAL PROCESS, V90, P2487, DOI 10.1016/j.sigpro.2010.02.013
   Akhaee MA, 2009, IEEE T MULTIMEDIA, V11, P822, DOI 10.1109/TMM.2009.2012922
   Balado F, 2005, LECT NOTES COMPUT SC, V3710, P336
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Conway J. H., 1998, Sphere Packings, Lattices and Groups, V3rd
   COSTA MHM, 1983, IEEE T INFORM THEORY, V29, P439, DOI 10.1109/TIT.1983.1056659
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Eggers JJ, 2002, P SOC PHOTO-OPT INS, V4675, P387, DOI 10.1117/12.465297
   Guccione P, 2009, IEEE T INF FOREN SEC, V4, P25, DOI 10.1109/TIFS.2008.2011080
   Kalantari NK, 2010, IEEE T IMAGE PROCESS, V19, P1504, DOI 10.1109/TIP.2010.2042646
   LEE K, 2003, P 2 INT WORKSH DIG W, P316
   Li Q, 2007, IEEE T INF FOREN SEC, V2, P127, DOI 10.1109/TIFS.2007.897266
   Marsaglia G., 2003, Journal of Statistical Software, V8, P1, DOI DOI 10.18637/JSS.V008.I18
   MASSEY FJ, 1951, J AM STAT ASSOC, V46, P68, DOI 10.2307/2280095
   Miller ML, 2004, IEEE T IMAGE PROCESS, V13, P792, DOI 10.1109/TIP.2003.821551
   Nezhadarya E, 2011, IEEE T INF FOREN SEC, V6, P1200, DOI 10.1109/TIFS.2011.2163627
   Oostveen J, 2004, P SOC PHOTO-OPT INS, V5306, P296, DOI 10.1117/12.526586
   Ourique F, 2005, INT CONF ACOUST SPEE, P797
   Pearson K., 1895, Philos. Trans. R. Soc. London, Ser. A., V186, P343, DOI [10.1098/rsta.1895.0010, DOI 10.1098/RSTA.1895.0010]
   Pérez-González F, 2005, IEEE T SIGNAL PROCES, V53, P3960, DOI 10.1109/TSP.2005.855407
   Pérez-González F, 2008, IEEE T INF FOREN SEC, V3, P137, DOI 10.1109/TIFS.2008.922057
   Phadikar A, 2011, COMPUT ELECTR ENG, V37, P339, DOI 10.1016/j.compeleceng.2011.02.002
   Shterev ID, 2006, IEEE T SIGNAL PROCES, V54, P4146, DOI 10.1109/TSP.2006.881216
   Valizadeh A, 2012, IEEE T INF FOREN SEC, V7, P1127, DOI 10.1109/TIFS.2012.2199312
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P685, DOI 10.1109/TIP.2003.810588
NR 29
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 9
BP 3077
EP 3098
DI 10.1007/s11042-013-1769-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CF7NI
UT WOS:000352742800011
DA 2024-07-18
ER

PT J
AU Yeo, HS
   Lee, BG
   Lim, H
AF Yeo, Hui-Shyong
   Lee, Byung-Gook
   Lim, Hyotaek
TI Hand tracking and gesture recognition system for human-computer
   interaction using low-cost hardware
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture recognition; Hand/Finger tracking; HCI; Kinect; Motion game; NUI
AB Human-Computer Interaction (HCI) exists ubiquitously in our daily lives. It is usually achieved by using a physical controller such as a mouse, keyboard or touch screen. It hinders Natural User Interface (NUI) as there is a strong barrier between the user and computer. There are various hand tracking systems available on the market, but they are complex and expensive. In this paper, we present the design and development of a robust marker-less hand/finger tracking and gesture recognition system using low-cost hardware. We propose a simple but efficient method that allows robust and fast hand tracking despite complex background and motion blur. Our system is able to translate the detected hands or gestures into different functional inputs and interfaces with other applications via several methods. It enables intuitive HCI and interactive motion gaming. We also developed sample applications that can utilize the inputs from the hand tracking system. Our results show that an intuitive HCI and motion gaming system can be achieved with minimum hardware requirements.
C1 [Yeo, Hui-Shyong] Dongseo Univ, Dept Ubiquitous IT, Pusan 617716, South Korea.
   [Lee, Byung-Gook] Dongseo Univ, Dept Visual Contents, Pusan 617716, South Korea.
   [Lim, Hyotaek] Dongseo Univ, Div Comp & Informat Engn, Pusan 617716, South Korea.
C3 Dongseo University; Dongseo University; Dongseo University
RP Lim, H (corresponding author), Dongseo Univ, Div Comp & Informat Engn, Pusan 617716, South Korea.
EM hsyeo@dongseo.ac.kr; lbg@dongseo.ac.kr; htlim@dongseo.ac.kr
FU National Research Foundation of Korea [2011-0009349]
FX This work was supported in part by the National Research Foundation of
   Korea under Grant 2011-0009349. The authors wish to thank Mr. Dylan Zhu
   for the language editing. Thanks are also due to all reviewers for their
   comments and recommendations, which have greatly improved the
   manuscript.
CR [Anonymous], 2005, PROC GW 2005
   [Anonymous], 2009, The Universal Access Handbook
   [Anonymous], VISION BASED HAND TR
   [Anonymous], 1995, INTRO KALMAN FILTER
   [Anonymous], MOT NONR ART OBJ 199
   [Anonymous], ARXIV10120467
   [Anonymous], MOTION CONTROLS MOVE
   [Anonymous], MULTIMED TOOLS APPL
   Barczak AndreL. C., 2005, Res. Lett. Inf. Math. Sci, V7, P29
   Bradski G., 2008, LEARNING OPENCV
   Bretzner L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P423, DOI 10.1109/AFGR.2002.1004190
   Buchmann V., 2004, VIRTUAL REAL-LONDON, V1, P212
   Burns AM, 2006, LECT NOTES ARTIF INT, V3881, P156
   Carter C., 2007, MICROSOFT XNA UNLEAS
   Chai D, 1999, IEEE T CIRC SYST VID, V9, P551, DOI 10.1109/76.767122
   Chen Q., 2007, Instrumentation and Measurement Technology Conference Proceedings (IMTC), P1
   Chen Q., 2008, Real-time vision-based hand tracking and gesture recognition
   Dardas NH, 2011, IEEE T INSTRUM MEAS, V60, P3592, DOI 10.1109/TIM.2011.2161140
   Dardas Nasser H, 2011, The Research Bulletin of Jordan ACM, V2, P86
   Dias JMS, 2004, XVII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P33, DOI 10.1109/SIBGRA.2004.1352940
   Hürst W, 2013, MULTIMED TOOLS APPL, V62, P233, DOI 10.1007/s11042-011-0983-y
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Keskin C., 2003, ICANNICONIPP, V2003, P26
   Mahmoud T.M., 2008, WORLD ACAD SCI ENG T, V43, P501
   Mahmoudi F., 2006, Geometric Modeling and Imaging-New Trends, P228
   Malik S., 2004, ACM INT C MULTIMODAL, P289, DOI DOI 10.1145/1027933.1027980
   Manresa C., 2005, ELECT LETT COMPUTER, V3, P96, DOI DOI 10.5565/REV/ELCVIA.109
   Mokhtar Hasan., 2012, INT J COMPUTER APPL, V41, P33
   Oka K, 2002, IEEE COMPUT GRAPH, V22, P64, DOI 10.1109/MCG.2002.1046630
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   QUAM DL, 1990, PROC NAECON IEEE NAT, P755, DOI 10.1109/NAECON.1990.112862
   Segen J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P188, DOI 10.1109/ICIP.1998.727164
   Singh S.K., 2003, TAMKANG J SCI ENG, V6, P227
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Von Hardenberg Christian, 2001, Proceedings of the 2001 workshop on Perceptive user interfaces, PUI'01, P1, DOI DOI 10.1145/971478.971513
   Wang RY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531369
NR 36
TC 100
Z9 112
U1 0
U2 85
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 8
BP 2687
EP 2715
DI 10.1007/s11042-013-1501-1
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE2ZL
UT WOS:000351692300007
DA 2024-07-18
ER

PT J
AU Younessian, E
   Rajan, D
AF Younessian, Ehsan
   Rajan, Deepu
TI Multi-modal fusion for associated news story retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic signature; Scene signature; Visual concept signature; News
   story retrieval
AB In this paper, we investigate multi-modal approaches to retrieve associated news stories sharing the same main topic. In the visual domain, we employ near duplicate keyframe/scene detection method using local signatures to identify stories with mutual visual cues. Further, to improve the effectiveness of visual representation, we develop a semantic signature that contains pre-defined semantic visual concepts in a news story. We propose a visual concept weighting scheme to combine local and semantic signature similarities to obtain the enhanced visual content similarity. In the textual domain, we utilize Automatic Speech Recognition (ASR) and refined Optical Character Recognition (OCR) transcripts and determine the enhanced textual similarity using the proposed semantic similarity measure. To fuse textual and visual modalities, we investigate different early and late fusion approaches. In the proposed early fusion approach, we employ two methods to retrieve the visual semantics using textual information. Next, using a late fusion approach, we integrate uni-modal similarity scores and the determined early fusion similarity score to boost the final retrieval performance. Experimental results show the usefulness of the enhanced visual content similarity and the early fusion approach, and the superiority of our late fusion approach.
C1 [Younessian, Ehsan; Rajan, Deepu] Nanyang Technol Univ, Sch Comp Engn, Ctr Multimedia & Network Technol, Nanyang 639798, Singapore.
C3 Nanyang Technological University
RP Younessian, E (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Ctr Multimedia & Network Technol, Nanyang 639798, Singapore.
EM ehsa0001@e.ntu.edu.sg
RI Rajan, Deepu/A-3666-2011
CR [Anonymous], MEDIAEVAL
   [Anonymous], P NIST TREC VID RETR
   [Anonymous], P 16 ACM INT C MULT
   [Anonymous], TECHNICAL REPORT
   [Anonymous], BROADCAST JOURNALISM
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Aytar Y, 2008, P IEEE C COMPUTER VI, P1
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hauptmann A. G., 2002, JCDL 2002. Proceedings of the Second ACM/IEEE-CS Joint Conference on Digital Libraries, P160, DOI 10.1145/544220.544252
   Jiang YG, 2010, IEEE T MULTIMEDIA, V12, P42, DOI 10.1109/TMM.2009.2036235
   Kolb Peter., 2009, Proceedings of Nordic Conference on Computational Linguistics, V4, P81
   Lan ZZ, 2012, LECT NOTES COMPUT SC, V7131, P173
   McDonald K, 2005, LECT NOTES COMPUT SC, V3568, P61
   Rice JA., 2007, MATH STAT DATA ANAL
   Sargin ME, 2007, IEEE T MULTIMEDIA, V9, P1396, DOI 10.1109/TMM.2007.906583
   Stark M. M., 1998, P 11 EUR WORKSH REND
   Wu A. G., 2007, P ACM MM, P218
   Yan R., 2004, PROC ACM INT C MULTI, P548
   Younessian E, 2012, LECT NOTES COMPUT SC, V7131, P186
   Younessian E, 2012, LECT NOTES COMPUT SC, V7131, P77
   Younessian E, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P298, DOI 10.1109/ISM.2009.19
NR 23
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 8
BP 2563
EP 2585
DI 10.1007/s11042-013-1404-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE2ZL
UT WOS:000351692300002
DA 2024-07-18
ER

PT J
AU Xie, L
   Pan, P
   Lu, YS
AF Xie, Liang
   Pan, Peng
   Lu, Yansheng
TI Markov random field based fusion for supervised and semi-supervised
   multi-modal image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-modal classification; Image classification; Semi-supervised
   learning; Markov random field
ID FEATURES
AB In recent years, there has been a massive explosion of multimedia content on the web, multi-modal examples such as images associated with tags can be easily accessed from social website such as Flickr. In this paper, we consider two classification tasks: supervised and semi-supervised multi-modal image classification, to take advantage of the increasing multi-modal examples on the web. We first propose a Markov random field (MRF) based fusion method: discriminative probabilistic graphical fusion (DPGF) for the supervised multi-modal image classification, which can make use of the associated tags to enhance the classification performance. Based on DPGF, we then propose a three-step learning procedure: DPGF+RLS+SVM, for the semi-supervised multi-modal image classification, which uses both the labeled and unlabeled examples for training. Experimental results on two datasets: PASCAL VOC'07 and MIR Flickr, show that our methods can well exploit the multi-modal data and unlabeled examples, and they also outperform previous state-of-the-art methods in both two multi-modal image classification. Finally we consider the weakly supervised condition where class labels are from image tags which are noisy. Our semi-supervised approach also improves the classification performance in this case.
C1 [Xie, Liang; Pan, Peng; Lu, Yansheng] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Pan, P (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM whutxl@hotmail.com; panpeng@mail.hust.edu.cn; lys@mail.hust.edu.cn
RI Pan, Feng/IXN-2297-2023
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], P ACM INT C IM VID R
   [Anonymous], 2011, 2011 IEEE WORKSHOP A
   [Anonymous], IEEE MULTIMEDIA
   [Anonymous], 1995, Markov random field modeling in computer vision
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Bach Francis R, 2004, P 21 INT C MACH LEAR, P6, DOI 10.1145/1015330.1015424
   Baluja S, 1998, NIPS
   Barla A, 2003, ICIP 2003 IEEE, V3
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Cai D, 2007, IEEE C COMP VIS ICCV, P1, DOI DOI 10.1109/CVPR.2007.383054
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang S-F, 2005, P IEEE INT C AC SPEE, V5
   Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646
   Chapelle O., 2006, SEMISUPERVISED LEARN
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Everingham M., 2007, The PASCAL Visual Object Classes Chal- lenge (VOC) Results, DOI 10.1007/s11263-009-0275-4
   Gao Y, 2013, VISUAL TEXTUAL JOINT, P1
   Goumehei E, 2010, CONTEXTUAL IMAGE CLA
   Guillaumin M, 2010, PROC CVPR IEEE, P902, DOI 10.1109/CVPR.2010.5540120
   Hammersley J. M., 1968, MARKOV FIELDS FINITE
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Iyengar G, 2002, P IEEE ICME, V2, P369
   Lin HT, 2007, MACH LEARN, V68, P267, DOI 10.1007/s10994-007-5018-6
   Liu NN, 2012, LECT NOTES COMPUT SC, V7585, P426, DOI 10.1007/978-3-642-33885-4_43
   Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pang YW, 2011, IEEE IMAGE PROC, P1797, DOI 10.1109/ICIP.2011.6115811
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Sindhwani V., 2005, ICML, V2005, P74
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Srivastava N., 2012, ADV NEURAL INFORM PR, P25
   Sun SL, 2011, LECT NOTES ARTIF INT, V7121, P209
   Verbeek J., 2010, Proc. ACM Multimedia Information Retrieval, P537
   Wang G, 2009, PROC CVPR IEEE, P1367, DOI 10.1109/CVPRW.2009.5206816
   Xiang Y, 2009, PROC CVPR IEEE, P1153, DOI 10.1109/CVPRW.2009.5206518
   Yang JJ, 2009, IEEE I CONF COMP VIS, P436, DOI 10.1109/ICCV.2009.5459172
   Yibin Li, 2009, 2009 IEEE International Conference on Automation and Logistics (ICAL), P1957, DOI 10.1109/ICAL.2009.5262626
   Znaidia A, 2012, ACM INT C MULT RETR
NR 43
TC 6
Z9 6
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 2
BP 613
EP 634
DI 10.1007/s11042-014-2018-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ8DP
UT WOS:000348445300017
DA 2024-07-18
ER

PT J
AU Benmokhtar, R
   Huet, B
AF Benmokhtar, Rachid
   Huet, Benoit
TI An ontology-based evidential framework for video indexing using
   high-level multimodal fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video shots indexing; Semantic gap; Classification; Classifier fusion;
   Inter-concepts similarity; Ontology; LSCOM-lite; TRECVid
ID SEMANTIC SIMILARITY; CLASSIFIER FUSION; DESCRIPTOR; COLOR
AB This paper deals with information retrieval and semantic indexing of multimedia documents. We propose a generic scheme combining an ontology-based evidential framework and high-level multimodal fusion, aimed at recognising semantic concepts in videos. This work is represented on two stages: First, the adaptation of evidence theory to neural network, thus giving Neural Network based on Evidence Theory (NNET). This theory presents two important information for decision-making compared to the probabilistic methods: belief degree and system ignorance. The NNET is then improved further by incorporating the relationship between descriptors and concepts, modeled by a weight vector based on entropy and perplexity. The combination of this vector with the classifiers outputs, gives us a new model called Perplexity-based Evidential Neural Network (PENN). Secondly, an ontology-based concept is introduced via the influence representation of the relations between concepts and the ontological readjustment of the confidence values. To represent this relationship, three types of information are computed: low-level visual descriptors, concept co-occurrence and semantic similarities. The final system is called Ontological-PENN. A comparison between the main similarity construction methodologies are proposed. Experimental results using the TRECVid dataset are presented to support the effectiveness of our scheme.
C1 [Benmokhtar, Rachid; Huet, Benoit] Eurecom, Dept Commun Multimedia, F-06904 Sophia Antipolis, France.
C3 IMT - Institut Mines-Telecom; EURECOM
RP Benmokhtar, R (corresponding author), Eurecom, Dept Commun Multimedia, 2229 Route Cretes, F-06904 Sophia Antipolis, France.
EM rachid.benmokhtar@eurecom.fr; benoit.huet@eurecom.fr
OI Huet, Benoit/0000-0002-0608-6939
FU Ascom; Bouygues Telecom; Cegetel; France Telecom; Hitachi; ST
   Microelectronics; Motorola; Swisscom; Texas Instruments; Thales
FX This research was supported by Eurecom's industrial members: Ascom,
   Bouygues Telecom, Cegetel, France Telecom, Hitachi, ST Microelectronics,
   Motorola, Swisscom, Texas Instruments and Thales.
CR Adamek T, 2007, FP6027026 KSPACE
   AIGRAIN P, 1994, COMPUT GRAPH, V18, P93, DOI 10.1016/0097-8493(94)90120-1
   [Anonymous], 2009, Proc. ACM International Confence on Multimedia
   [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   [Anonymous], 1997, P 10 RES COMPUTATION
   [Anonymous], 2000, Em: Proceedings of the 2000 ACM workshops on Multimedia, DOI DOI 10.1145/357744.357758
   Ayache S, 2007, TRECID 11 INT WORKSH
   Benmokhtar R., 2008, ACM INT C MULT INF R, P336
   Benmokhtar R, 2007, LECT NOTES COMPUT SC, V4352, P196
   Benmokhtar R, 2006, LECT NOTES COMPUT SC, V4132, P65
   Benmokhtar R, 2009, INT WORK CONTENT MUL, P195, DOI 10.1109/CBMI.2009.18
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Chang SF, 1998, IEEE T CIRC SYST VID, V8, P602, DOI 10.1109/76.718507
   Deng YN, 1998, IEEE T CIRC SYST VID, V8, P616, DOI 10.1109/76.718508
   DENOEUX T, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS, VOLS 1-5, P712, DOI 10.1109/ICSMC.1995.537848
   Dimitrova N, 2003, LECT NOTES COMPUTER, V25, P8
   Duin RPW, 2000, LECT NOTES COMPUT SC, V1857, P16
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   Gao J, 2001, ACM T ASIAN LANGUAGE
   HAUPTMANN AG, 2005, TREC VID RETR EV ONL
   *ISO IEC, 2001, 144962 ISOIEC
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jianping Fan, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P111
   Kasutani E, 2001, IEEE IMAGE PROC, P674, DOI 10.1109/ICIP.2001.959135
   Koskela M, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P45, DOI 10.1109/ICME.2006.262546
   Koskela M, 2007, IEEE T MULTIMEDIA, V9, P912, DOI 10.1109/TMM.2007.900137
   Kotsiantis S. B., 2007, Emerging artificial intelligence applications in computer engineering, DOI DOI 10.31449/INF.V31I3.148
   Kuncheva LI, 2003, IEEE T FUZZY SYST, V11, P729, DOI 10.1109/TFUZZ.2003.819842
   Kuncheva LI, 2001, PATTERN RECOGN, V34, P299, DOI 10.1016/S0031-3203(99)00223-X
   Laaksonen JT, 2004, NEURAL NETWORKS, V17, P1121, DOI 10.1016/j.neunet.2004.07.007
   Li Beitao., 2003, Proceedings of the Eleventh ACM International Conference on Multimedia, P195
   Li YH, 2003, IEEE T KNOWL DATA EN, V15, P871, DOI 10.1109/TKDE.2003.1209005
   Lin D, 1998, P 15 INT C MACH LEAR, V98, P296
   Messing DS, 2001, IEEE IMAGE PROC, P670, DOI 10.1109/ICIP.2001.959134
   Naphade M.R., 2005, A light scale concept ontology for multimedia understanding for trecvid 2005
   Naphade MR, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P536, DOI 10.1109/ICIP.1998.999041
   NAPHADE MR, 2000, P NEUR INF PROC SYST, V13, P967
   OpenCV, 2010, INT OP SOURC COMP VI
   PENTLAND A, 1994, P SPIE C STOR RETR I
   RADA R, 1989, IEEE T SYST MAN CYB, V19, P17, DOI 10.1109/21.24528
   Resnik P, 1995, INT JOINT CONF ARTIF, P448
   Seco N, 2004, P EUR C ART INT
   Shankar Vembu, 2006, P 1 INT WORKSH SEM W
   Slimani T., 2007, P SETIT, P110
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Snoek C, 2004, TREC VIDEO RETRIEVEL
   Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5
   Souvannavong F, 2005, THESIS EURECOM FRANC
   Sun XD, 2002, IEEE IMAGE PROC, P149
   TRECVID, 2010, DIG VID RETR NIST
   Tsinaraki C, 2004, P 3 INT C IM VID RET
   Vapnik V.N., 2000, The Nature of Statistical Learning Theory, DOI DOI 10.1007/978-1-4757-3264-1_1
   Wactlar H, 1996, IEEE COMPUTER, V29
   Wu Y, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1003, DOI 10.1109/ICME.2004.1394372
   WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P133
   Xu F, 2006, J VIS COMMUN IMAGE R, V17, P701, DOI 10.1016/j.jvcir.2005.10.002
   XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943
NR 57
TC 5
Z9 5
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 663
EP 689
DI 10.1007/s11042-011-0936-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700004
DA 2024-07-18
ER

PT J
AU Ramos, F
   Ripolles, O
   Chover, M
AF Ramos, Francisco
   Ripolles, Oscar
   Chover, Miguel
TI Efficient visualization of 3D models on hardware-limited portable
   devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D; Level-of-detail; Mobile; Tablet
ID DRIVEN SIMPLIFICATION; CONTINUOUS LEVEL; DETAIL; GPU
AB Managing the geometry of a 3D scene efficiently is a key aspect of an interactive 3D application. This aspect is more important if we target at portable devices, which have limited hardware capabilities. Developing new means for improving the interaction with 3D content in mobile devices is key. The aim of this work is to present a technique which can manage the level-of-detail of 3D meshes in portable devices. This solution has been devised considering the restrictions that this kind of devices poses. The results section shows how the integration has been successful while obtaining good performance.
C1 [Ramos, Francisco; Chover, Miguel] Univ Jaume 1, Inst New Imaging Technol, Castellon de La Plana, Spain.
   [Ripolles, Oscar] Neuroelect Barcelona, Barcelona 08022, Spain.
C3 Universitat Jaume I
RP Ramos, F (corresponding author), Univ Jaume 1, Inst New Imaging Technol, Av Vicent Sos Baynat S-N, Castellon de La Plana, Spain.
EM francisco.ramos@uji.es; oscar.ripolles@neuroelectrics.com; chover@uji.es
RI Ramos, Francisco/AAA-7780-2019; Chover Sellés, Miguel/P-9933-2018;
   Ramos, Francisco/L-5911-2018; Ramos, Francisco/L-7228-2014
OI Ramos, Francisco/0000-0003-2540-4741; Chover Sellés,
   Miguel/0000-0002-0525-7038; Ripolles, Oscar/0000-0002-5450-6758
FU Spanish Ministry of Science and Technology [TIN2010-21089-C03-03]; Feder
   Funds; Bancaixa [P1.1B2010-08]; Generalitat Valenciana
   [PROMETEO/2010/028]
FX This work was supported by the Spanish Ministry of Science and
   Technology (Project TIN2010-21089-C03-03) and Feder Funds, Bancaixa
   (Project P1.1B2010-08) and Generalitat Valenciana (Project
   PROMETEO/2010/028).
CR [Anonymous], 2003, LEVEL DETAIL 3D GRAP
   Baek N, 2012, MULTIMED TOOLS APPL, V57, P669, DOI 10.1007/s11042-010-0662-4
   Boubekeur T, 2008, COMPUT GRAPH FORUM, V27, P102, DOI 10.1111/j.1467-8659.2007.01040.x
   Castello P, 2007, EUROGRAPHICS TUTORIA, V2, P891
   Chan MC, 2009, MULTIMED TOOLS APPL, V45, P369, DOI 10.1007/s11042-009-0294-8
   CLARK JH, 1976, COMMUN ACM, V19, P547, DOI 10.1145/360349.360354
   COHEN J, 1998, SIGGRAPH 98, P115
   Cyberware, 2012, 3D SCANN SAMPL
   Giegl M, 2007, COMPUT GRAPH FORUM, V26, P46, DOI 10.1111/j.1467-8659.2007.00943.x
   González C, 2008, WSCG 2008, COMMUNICATION PAPERS, P87
   HOPPE H, 1993, ACM COMPUTER GRAPHIC, P19
   HU L, 2009, I3D 09, P169
   Kim SK, 2010, MULTIMED TOOLS APPL, V47, P147, DOI 10.1007/s11042-009-0411-8
   Lindstrom P, 2000, ACM T GRAPHIC, V19, P204, DOI 10.1145/353981.353995
   Luebke D, 2001, SPRING EUROGRAP, P223
   Ramos F, 2004, ICCS, V3039, P107
   Ripollés O, 2008, COMPUT GRAPH-UK, V32, P307, DOI 10.1016/j.cag.2008.02.003
   Ripolles O, 2011, VISUAL COMPUT, V27, P793, DOI 10.1007/s00371-011-0554-2
   Sander PV, 2001, COMP GRAPH, P409, DOI 10.1145/383259.383307
   Shafae M, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P271, DOI 10.1109/PCCGA.2003.1238269
   Southern R, 2003, COMPUT GRAPH FORUM, V22, P35, DOI 10.1111/1467-8659.t01-1-00644
   STANFORD, 2012, STANF 3D SCANN REP
   Turchyn P, 2007, WSCG 2007, FULL PAPERS PROCEEDINGS I AND II, P33
   Wikipedia, 2011, APPL A5
   Wikipedia, 2011, APPL A4
   Xia JC, 1997, IEEE T VIS COMPUT GR, V3, P171, DOI 10.1109/2945.597799
   Zach C, 2002, SCCG 2002
NR 27
TC 6
Z9 7
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 961
EP 976
DI 10.1007/s11042-012-1200-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700021
DA 2024-07-18
ER

PT J
AU Zarri, GP
AF Zarri, Gian Piero
TI Conceptual and content-based annotation of (multimedia) documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Annotation systems; Binary and n-ary conceptual representations;
   Ontologies; Elementary and complex events; Narratives; Querying and
   inference procedures
ID SEMANTIC WEB; INFRASTRUCTURE; MANAGEMENT; ONTOLOGY; NKRL
AB This paper focuses on the techniques used in an NKRL environment (NKRL = Narrative Knowledge Representation Language) to deal with a general problem affecting the so-called "semantic/conceptual annotations" techniques. These last, mainly ontology-based, aim at "annotating" multimedia documents by representing, in some way, the "inner meaning/deep content" of these documents. For documents of sufficient size, the content modeling operations are separately executed on 'significant fragments' of the documents, e. g., "sentences" for natural language texts or "segments" (minimal units for story advancement) in a video context. The general problem above concerns then the possibility of collecting all the partial conceptual representations into a global one. This integration operation must, moreover, be carried out in such a way that the meaning of the full document could go beyond the simple addition of the 'meanings' conveyed by the single fragments. In this context, NKRL makes use of second order knowledge representation structures, "completive construction" and "binding occurrences", for collecting within the conceptual annotation of a whole "narrative" the basic building blocks corresponding to the representation of its composing elementary events. These solutions, of a quite general nature, are discussed in some depth in this paper. This last includes also a short "state of the art" in the annotation domain and some comparisons with the different methodologies proposed in the past for solving the above 'integration' problem.
C1 Univ Sorbonne, LaLIC STIH Lab, F-75006 Paris, France.
C3 Sorbonne Universite
RP Zarri, GP (corresponding author), Univ Sorbonne, LaLIC STIH Lab, Maison Rech,28 Rue Serpente, F-75006 Paris, France.
EM zarri@noos.fr
CR Acciarri A., 2005, PROC NATL CONF ARTIF, V20, P1670
   Adida B, 2012, RDFA 1 1 PRIMER RICH
   [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   [Anonymous], 2011, LINKED DATA EVOLVING
   [Anonymous], 2003, WONDERWEB DELIVERABL
   [Anonymous], 2010, Synthesis Lectures on Human Language Technology Series
   [Anonymous], 1984, Conceptual Structures: Information Processing in Mind and Machine
   [Anonymous], 2011, Text Processing with GATE (Version 6)
   [Anonymous], P 24 INT FLOR AI RES
   [Anonymous], 24707 ISOIEC
   [Anonymous], P 1 SEM AUTH ANN WOR
   [Anonymous], NEW TRENDS RES ONTOL
   [Anonymous], 1990, Building Large Knowledge-Based Systems: Representation and Inference in the CYC Project
   Arndt R., 2009, HDB ONTOLOGIES, P403, DOI DOI 10.1007/9783-54092673-3_18
   Athanasiadis T, 2005, P 5 INT WORKSH KNOWL, P59
   Ayari N, 2012, P 2012 INT WORKSH HU, P61
   Bagdanov AD, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P713, DOI 10.1109/ICSC.2007.30
   Bal Mieke, 1985, Narratology: Introduction to the Theory of Narrative
   Bechhofer S., 2004, W3C recommendation
   Benmokhtar R, 2011, MULTIMEDIA SEMANTICS: METADATA, ANALYSIS AND INTERACTION, P35
   Bertini M, 2011, P 2011 IEEE INT C MU
   BLACK WJ, 2004, P 4 INT WORKSH KNOWL
   BOLL S, 1998, MULTIMEDIA DATA MANA
   CECCATO S, 1961, RADCTR6018
   CHAUDHRI VK, 1998, P 1998 NAT C ART INT
   Cole K, 2009, GUIDELINES DUBLIN CO
   CORBETT D, 2003, REASONING UNIFICATIO
   [Crofts Nick. ICOM/CIDOC Documentation Standards Group ICOM/CIDOC Documentation Standards Group], 2011, Definition of the CIDOC conceptual reference model
   Cunningham H, 2002, COMPUT HUMANITIES, V36, P223, DOI 10.1023/A:1014348124664
   DCMI Usage Board, 2010, DCMI MET TERMS
   Dyer M., 1983, IN DEPTH UNDERSTANDI, DOI [10.6084/m9.figshare.c.6216268, DOI 10.6084/M9.FIGSHARE.C.6238436]
   ELLIS G, 1995, IEEE T KNOWL DATA EN, V7, P68, DOI 10.1109/69.368517
   Federal Geographic Data Committee, 2000, CONT STAND DIG GEOSP
   Finlayson MA, 2010, COMPUTATIONAL MODELS
   Fritz DA, 2003, MARC 21 EVERYONE PRA
   Gangemi A, 2003, LECT NOTES COMPUT SC, V2888, P689
   Guza T, 2010, SAN JOS STAT U LIBR
   HAUPTMANN A, 2008, SEMANTIC MULTIMEDIA, P253
   Higginbotham J, 2000, SPEAKING OF EVENTS, P49
   Hitzler P., 2009, W3C RECOMM, V27
   Hyvönen E, 2008, LECT NOTES COMPUT SC, V5021, P95
   Jahn Manfred., 2005, NARRATOLOGY GUIDE TH
   Jonquet C, 2008, LECT N BIOINFORMAT, V5109, P144, DOI 10.1007/978-3-540-69828-9_14
   Kahan J, 2002, COMPUT NETW, V39, P589, DOI 10.1016/S1389-1286(02)00220-7
   Kamp Hans, 1993, DISCOURSE LOGIC INTR, DOI 10.1007/978-94-017-1616-1
   Katz B., 2006, Proceedings of 19th International FLAIRS Conference, P303
   Klarman S., 2011, P 25 AAAI C ART INT, P215
   Klein D, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P423, DOI 10.3115/1075096.1075150
   Knublauch H, 2004, LECT NOTES COMPUT SC, V3298, P229
   Kolodner J.L., 1984, RETRIEVAL ORG STRATE
   Lanfranchi V, 2005, LECT NOTES COMPUT SC, V3532, P623
   LENAT DB, 1990, COMMUN ACM, V33, P30, DOI 10.1145/79173.79176
   Levin B., 1993, English Verb Classes and Alternations: A Preliminary Investigation
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li Q, 2010, PATTERN RECOGN, V43, P378, DOI 10.1016/j.patcog.2009.06.003
   Lombardo V, 2010, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT AND SOFTWARE INTENSIVE SYSTEMS (CISIS 2010), P706, DOI 10.1109/CISIS.2010.181
   Mäkelä E, 2012, SEMANT WEB, V3, P85, DOI 10.3233/SW-2012-0049
   Mani I., 2004, Proceedings of the 2004 ACL Workshop on Discourse Annotation, P57
   McCarthy H., 1993, IJCAI-93. Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, P555
   McShane M., 2011, ADV COGNITIVE SYSTEM, P232
   National Information Standards Organization NISO, 2007, Z39852007 ANSINISO
   Nazarenko A., 1993, Conceptual Graphs for Knowledge Representation. First International Conference on Conceptual Structures, ICCS '93 Proceeding, P205
   Nirenburg S., 2004, ONTOLOGICAL SEMANTIC
   Noy NF, 2000, LECT NOTES ARTIF INT, V1937, P17
   Parson T., 1990, EVENTS SEMANTICS ENG
   Pepper S., 2010, Encyclopedia of Library and Information Sciences, V3rd, P5247
   Pustejovsky J., 2005, The language of time: A reader, P545
   Reiterer B, 2010, USER CTR MEDIA REVIS, P87
   Rubiera Emilio, 2012, The Semantic Web: Research and Applications. Proceedings 9th Extended Semantic Web Conference (ESWC 2012), P195, DOI 10.1007/978-3-642-30284-8_20
   Saggion H, 2004, DATA KNOWL ENG, V48, P247, DOI 10.1016/S0169-023X(03)00108-3
   Sanderson R., 2012, OPEN ANNOTATION CORE
   Sarraf Q, 2006, BUS RULES J, V7
   Schank Roger C., 1977, SCRIPTS PLANS GOALS
   Schubert LK, 2000, NATURAL LANGUAGE PROCESSING AND KNOWLEDGE REPRESENTATION, P111
   Shapiro StuartC., 1979, ASSOCIATIVE NETWORKS, P179
   Sirin E, 2007, J WEB SEMANT, V5, P51, DOI 10.1016/j.websem.2007.03.004
   Soergel D., 1995, VIS RESOUR, V10, P369, DOI [10.1080/01973762.1995.9658306, DOI 10.1080/01973762.1995.9658306]
   Sowa J. F., 1999, Knowledge Representation: Logical, Philosophical, and Computational Foundations
   Spiliopoulou M, 2004, RIAO, P156
   Stojanovic N., 2009, P 2009 AAAI SPRING S
   Todorov K, 2011, MULTIMED TOOLS APPL, V55, P1
   Uren V, 2006, J WEB SEMANT, V4, P14, DOI 10.1016/j.websem.2005.10.002
   Wang C., 2008, ACM SIGIR, P355, DOI DOI 10.1145/1390334.1390396
   Westermann U, 2006, INT J SEMANT WEB INF, V2, P1, DOI 10.4018/jswis.2006040101
   Wielinga B. J., 2001, Proceedings of the First International Conference on Knowledge Capture, P194, DOI 10.1145/500737.500767
   Wittern C, 2009, LIT LINGUIST COMPUT, V24, P281, DOI 10.1093/llc/fqp017
   Zarri Gian Piero, 2011, International Journal of Metadata, Semantics and Ontologies, V6, P10, DOI 10.1504/IJMSO.2011.042487
   Zarri G. P., 1983, Conference on Applied Natural Language Processing. Proceedings of the Conference, P143
   Zarri G. P., 1998, CURRICULUM INQ, V7, P213
   Zarri GP, 2013, EXPERT SYST APPL, V40, P2872, DOI 10.1016/j.eswa.2012.12.005
   Zarri GP, 2009, ADV INFORM KNOWL PRO, P1, DOI 10.1007/978-1-84800-078-0_1
   Zarri GP, 2011, KNOWL-BASED SYST, V24, P989, DOI 10.1016/j.knosys.2011.04.010
   Zarri GP, 2005, LECT NOTES COMPUT SC, V3730, P304
   Zarri GP, 2009, HDB RES EMERGING RUL, V1, P50
   Zarri GP, 2012, P COLABTKR 2012 TERM, P19
NR 95
TC 8
Z9 8
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2359
EP 2391
DI 10.1007/s11042-013-1463-3
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300015
DA 2024-07-18
ER

PT J
AU Espina, F
   Morato, D
   Izal, M
   Magaña, E
AF Espina, Felix
   Morato, Daniel
   Izal, Mikel
   Magana, Eduardo
TI Analytical model for MPEG video frame loss rates and playback
   interruptions on packet networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality of service; Quality of experience; Video communications;
   Decodable frame rate; Video cut durations
ID SINGLE-LAYER; QUALITY
AB This paper presents and studies objective video quality evaluation techniques for a network where frame losses can be considered independent, for example a best effort not heavy loaded packet switching network. The total or partial loss of a frame's information affects the quality of video playback, as the frame cannot be decoded and other frames that depend on it cannot be correctly decoded too. Therefore, during some time the video playback has errors in the image and the user will perceive them as interruptions. In this paper, the total number of decoded frames and the video playback interruptions duration will be considered important parameters to quantify the video quality. The analytical formulation for them will be presented and the importance of considering them together will be highlighted.
C1 [Espina, Felix; Morato, Daniel; Izal, Mikel; Magana, Eduardo] Univ Publ Navarra, Pamplona 31006, Spain.
C3 Universidad Publica de Navarra
RP Espina, F (corresponding author), Univ Publ Navarra, Campus Arrosadia S-N, Pamplona 31006, Spain.
EM felix.espina@unavarra.es
RI Espina, Felix/E-1858-2013; Morato, Daniel/G-9406-2015; Magana,
   Eduardo/I-2648-2015; Izal, Mikel/I-2503-2015
OI Morato, Daniel/0000-0002-0831-4042; Magana, Eduardo/0000-0002-6851-3414;
   Izal, Mikel/0000-0002-2770-912X
FU Spanish Ministry of Science and Innovation through research project
   INSTINCT [TEC-2010-21178-C02-01]
FX This work was supported by the Spanish Ministry of Science and
   Innovation through the research project INSTINCT
   (TEC-2010-21178-C02-01). The authors would also like to thank the
   Spanish thematic network FIERRO (TEC2010-12250-E).
CR [Anonymous], 2009, 1449622004 ISO IEC
   [Anonymous], 2000, 1381822000 ISO IEC
   [Anonymous], 2012, 1449610210 ISO IEC
   Bikfalvi A, 2011, COMPUT NETW, V55, P1310, DOI 10.1016/j.comnet.2010.12.020
   Borgnat P, 2009, IEEE INFOCOM SER, P711, DOI 10.1109/INFCOM.2009.5061979
   Cheng RS, 2012, J SUPERCOMPUT, V62, P68, DOI 10.1007/s11227-011-0624-2
   Cisco Visual Networking Index, 2011, FOR METH 2010 2015
   Espina F, 2012, SURVEY CURRENT USES
   Fiedler M, 2010, IEEE NETWORK, V24, P36, DOI 10.1109/MNET.2010.5430142
   Heyman DP, 1996, IEEE ACM T NETWORK, V4, P40, DOI 10.1109/90.503760
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Kei CH, 2008, J INF SCI ENG, V24, P425
   Kusuma TIM, 2003, SYMPOTIC'03: JOINT IST WORKSHOP ON MOBILE FUTURE & SYMPOSIUM ON TRENDS IN COMMUNICATIONS, PROCEEDINGS, P71, DOI 10.1109/TIC.2003.1249092
   Lin CH, 2006, 20TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1, PROCEEDINGS, P565
   Lotfallah OA, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/42083
   MAWI (Measurement and Analysis on the WIDE Internet) Working Group, 2012, 150 MEG ETH AN PACK
   Pastrana-Vidal R, 2007, 3 INT WORKSH VID PRO, V7, P25
   Pastrana-Vidal RR, 2004, P SOC PHOTO-OPT INS, V5292, P182, DOI 10.1117/12.525746
   PASTRANAVIDAL R, 2006, P INT WORKSH VID PRO
   PASTRANAVIDAL RR, 2004, 5 INT WORKSH IM AN M
   Reisslein M., 2002, TRAFFIC QUALITY CHAR
   Seeling P, 2004, IEEE COMMUN SURV TUT, V6, P58, DOI 10.1109/COMST.2004.5342293
   Tionardi L, 2003, TENCON IEEE REGION, P364, DOI 10.1109/TENCON.2003.1273346
   Van der Auwera G, 2008, IEEE T BROADCAST, V54, P698, DOI 10.1109/TBC.2008.2000422
   Varga A., 2008, An Overview of the Omnet++ Simulation Environment, P1
   Ziviani A, 2005, MULTIMED TOOLS APPL, V26, P59, DOI 10.1007/s11042-005-6849-4
NR 26
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 361
EP 383
DI 10.1007/s11042-012-1344-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800017
DA 2024-07-18
ER

PT J
AU Jang, H
   Jeon, J
   Sohn, E
   Lim, SB
   Choy, YC
AF Jang, Hyunho
   Jeon, Jaewoong
   Sohn, Eisung
   Lim, Soon-Bum
   Choy, Yoon-Chul
TI A sketch-based interface to modify and reproduce motion sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sketch-based interface; Multiple-pass sketching; Computer animation;
   Human computer interaction
AB We present a sketch-based user interface, which was designed to help novices to create 3D character animations by multi-pass sketching, avoiding the ambiguities usually present in sketch input. Our system also contains sketch-based editing and reproducing tools, which allow paths and motions to be partially updated rather than wholly redrawn; and graphical block interface permits motion sequences to be organized and reconfigured easily. A user evaluation with participants of different skill levels suggest that novices using this sketch interface can produce animations almost as quickly as users who are experienced in 3D animation.
C1 [Jang, Hyunho; Jeon, Jaewoong; Sohn, Eisung; Choy, Yoon-Chul] Yonsei Univ, Dept Comp Sci, Multimedia Graph Lab, Seoul 120749, South Korea.
   [Lim, Soon-Bum] Sookmyung Womens Univ, Dept Multimedia Sci, Seoul, South Korea.
C3 Yonsei University; Sookmyung Women's University
RP Jeon, J (corresponding author), Yonsei Univ, Dept Comp Sci, Multimedia Graph Lab, 134 Shinchon Dong, Seoul 120749, South Korea.
EM demiblue@gmail.com
FU Seoul RBD Program [PA110072]; National Research Foundation of Korea -
   Korean Government(Ministry of Education, Science and Technology)
   [NRF-2011-355-D00059]
FX We would like to thank Minwoo Kim and Hyowoo Kim for valuable
   suggestions. We appreciate NCORE games Inc. for their 3D models and
   discussions. This research was supported by Seoul R&BD Program(PA110072)
   and the National Research Foundation of Korea Grant funded by the Korean
   Government(Ministry of Education, Science and Technology).
   [NRF-2011-355-D00059].
CR Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606
   BALAGUER JF, 1995, COMPUT GRAPH FORUM, V14, pC241, DOI 10.1111/j.1467-8659.1995.cgf143_0241.x
   Chetverikov D, 2003, LECT NOTES COMPUT SC, V2756, P746
   Dontcheva M, 2003, ACM T GRAPHIC, V22, P409, DOI 10.1145/882262.882285
   Igarashi T., 1998, 11th Annual Symposium on User Interface Software and Technology. UIST. Proceedings of the ACM Symposium, P173, DOI 10.1145/288392.288599
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   Igarashi T., 2005, Proceedings of the 2005 acm siggraph/eurographics symposium on computer animation, P107, DOI DOI 10.1145/1073368.1073383
   Jeon J, 2010, COMPUT ANIMAT VIRT W, V21, P423, DOI 10.1002/cav.353
   Kim M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531385
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kwon T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360679
   Lee J, 1999, COMP GRAPH, P39
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Lo WY, 2010, COMPUT GRAPH FORUM, V29, P563, DOI 10.1111/j.1467-8659.2009.01626.x
   McCann J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276385, 10.1145/1239451.1239457]
   Min JY, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640452
   Popovic J, 2003, ACM T GRAPHIC, V22, P1034, DOI 10.1145/944020.944025
   Sutherland I. E., 1964, P SHAR DES AUT WORKS, DOI [DOI 10.1177/003754976400200514, 10.1177/003754976400200514]
   Terra S.C. L., 2004, Proceedings of ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P253, DOI DOI 10.1145/1028523.1028556
   Thorne M, 2004, ACM T GRAPHIC, V23, P424, DOI 10.1145/1015706.1015740
   vandePanne M, 1997, COMPUT GRAPH FORUM, V16, P211, DOI 10.1111/1467-8659.00181
   Zeleznik R. C., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P163, DOI 10.1145/237170.237238
NR 22
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 591
EP 612
DI 10.1007/s11042-013-1394-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800027
DA 2024-07-18
ER

PT J
AU Li, AX
   Bonner, JVH
AF Li, Andol X.
   Bonner, John V. H.
TI Using wizard-of-oz method to build multipurpose platform for domestic
   ambient media research and applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wizard-of-oz; Ubiquitous computing; Ambient media; Domestic
   communication; Ambient media platform
ID INTELLIGENCE; FRAMEWORK; INTERFACE
AB This paper presents the design and evaluation of the multipurpose platform for domestic ambient media research and applications through an improved method called wizard-of-oz. Inspired by the increasing requirements for the reuse of valuable development work in intelligent ambient media system and service design, we propose a different approach to construct a high-level pseudo platform to support flexible and cost-economic prototype mock-up and test. Based on the platform three incremental ambient media applications were developed for empirical studies, and a number of studies were carried out to assess the applicability, effectiveness and reusability of this platform within domestic settings. The results showed that this platform has great advantages over conventional systems specifically developed for ambient media research in above aspects. Also, the results have provided secondary understanding in the design of future ambient media applications for domestic use, including the guidelines for the design of domestic smart conversational system interfaces and user interactions with ambient media.
C1 [Li, Andol X.; Bonner, John V. H.] Univ Huddersfield, Live Lab, Dept Informat, Sch Comp & Engn, Huddersfield HD1 3DH, W Yorkshire, England.
C3 University of Huddersfield
RP Li, AX (corresponding author), Univ Huddersfield, Live Lab, Dept Informat, Sch Comp & Engn, Huddersfield HD1 3DH, W Yorkshire, England.
EM a.x.li@acm.org
CR Aarts E, 2004, IEEE MULTIMEDIA, V11, P12, DOI 10.1109/MMUL.2004.1261101
   [Anonymous], 1991, SCI AM
   Aroyo L, 2008, MULTIMED TOOLS APPL, V36, P71, DOI 10.1007/s11042-006-0078-3
   Bailey BP, 2008, PERS UBIQUIT COMPUT, V12, P269, DOI 10.1007/s00779-007-0147-2
   Bradley J, 2009, HCI 2009 PEOPL COMP, P313
   Carbini S, 2006, SIGNAL PROCESS, V86, P3559, DOI 10.1016/j.sigpro.2006.04.001
   Chaparro BS, 2008, J USABILITY STUD, V4, P31
   Dahlback N., 1993, P 1 INT C INT US INT
   de Ruyter B, 2005, INTERACT COMPUT, V17, P522, DOI 10.1016/j.intcom.2005.03.003
   Edlund J, 2008, SPEECH COMMUN, V50, P630, DOI 10.1016/j.specom.2008.04.002
   Forbes-Riley K, 2011, COMPUT SPEECH LANG, V25, P105, DOI 10.1016/j.csl.2009.12.002
   Fraser N. M., 1991, Computer Speech and Language, V5, P81, DOI 10.1016/0885-2308(91)90019-M
   Hossain MA, 2009, MULTIMED TOOLS APPL, V44, P407, DOI 10.1007/s11042-009-0285-9
   Howard S, 2007, PERS UBIQUIT COMPUT, V11, P329, DOI 10.1007/s00779-006-0081-8
   Jefferson Gail, 2004, PRAGMATICS NEW SERIE
   Kristina H, 1999, P 4 INT C INT US INT
   Liu C, 2009, 1 INT WORKSH SPOK DI
   Lugmayr A, 2007, INTERACTIVE DIGITAL
   Lugmayr A, 2009, P 1 ACM INT WORKSH E
   Mavrikis M, 2010, COMPUT EDUC, V54, P641, DOI 10.1016/j.compedu.2009.08.033
   Meyer GG, 2009, COMPUT IND, V60, P137, DOI 10.1016/j.compind.2008.12.005
   Novielli N, 2010, J PRAGMATICS, V42, P2385, DOI 10.1016/j.pragma.2009.12.016
   PEDERSEN ER, 1997, P SIGCHI C HUM FACT
   Plaue C, 2004, P GRAPH INT 2004 LON
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P399, DOI 10.1007/s11042-011-0917-8
   Redstrom J, 2000, P DARE 2000 DES AUGM
   Satoh I, 2009, P 13 INT MINDTREK C
   Shirehjini AAN, 2014, MULTIMED TOOLS APPL, V70, P1637, DOI 10.1007/s11042-012-1137-6
   Taylor A. S., 2007, PERS UBIQUIT COMPUT
   Tollmar K., 2000, DIS2000. Designing Interactive Systems Processes, Practices, Methods, and Techniques. Conference Proceedings, P83, DOI 10.1145/347642.347670
   Wakkary R, 2007, C C 2007 WASH USA 13
   Wakkary R, 2008, INT J HUM-COMPUT INT, V24, P478, DOI 10.1080/10447310802142276
   Xu Y, 2007, AI SOC, V23, P201, DOI [10.1007/s00146-007-0134-1, DOI 10.1007/S00146-007-0134-1]
NR 33
TC 0
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1011
EP 1026
DI 10.1007/s11042-013-1370-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300001
DA 2024-07-18
ER

PT J
AU Le, TA
   Nguyen, H
AF Tien Anh Le
   Hang Nguyen
TI End-to-end transmission of scalable video contents: performance
   evaluation over EvalSVC-a new open-source evaluation platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scalable Video Coding; Video evaluation platform; QoS metrics and
   measurement; SVC performance evaluation; Evaluation tools
ID H.264/AVC
AB Scalable Video Coding (SVC) is the latest extension of the famous Advance Video Coding (AVC) standard. Scalability is important and useful because it is dedicated to the transmission of video contents over heterogeneous network conditions and terminals' capabilities. Nevertheless, the multimedia service research community and industry have not been able to fully utilize the entire potential of this video coding standard extension because of the lack of a platform for evaluating the end-to-end transmission of SVC-contents. EvalSVC aims to foster SVC-based applications and research in multimedia services. It is capable of evaluating the end-to-end transmission of SVC bit-streams encoded with enhanced features (spatial, temporal, SNR, and combined scalability). The output results are both objective and subjective metrics of the video transmission. Interfaces with real networks and an overlay simulation platform are presented. Through these interfaces, the transmission performance of different types of SVC scalability and AVC bit-streams can be evaluated easily.
C1 [Tien Anh Le; Hang Nguyen] Telecom Sud Paris, Dept Wireless Networks & Mobile Multimedia Serv, F-91011 Evry, Ile De France, France.
C3 IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; Telecom
   SudParis
RP Le, TA (corresponding author), Telecom Sud Paris, Dept Wireless Networks & Mobile Multimedia Serv, F-91011 Evry, Ile De France, France.
EM letienanh@gmail.com; hang_nguyen@it-sudparis.eu
CR [Anonymous], FUTURE WIRELESS NETW
   Baumgart I, 2007, 2007 IEEE GLOBAL INTERNET SYMPOSIUM, P79, DOI 10.1109/GI.2007.4301435
   Bouras C., 2011, 2011 International Conference on Broadband, Wireless Computing, Communication and Applications, P270, DOI 10.1109/BWCCA.2011.40
   Constantinescu D, 2007, 4 EUR FGI WORKSH NEW
   Feuvre JL, 2007, MULTIMEDIA07 P 15 IN
   Hu MK, 2010, IEEE GLOBE WORK, P898, DOI 10.1109/GLOCOMW.2010.5700454
   Kei CH, 2008, J INF SCI ENG, V24, P425
   Klaue J, 2003, LECT NOTES COMPUT SC, V2794, P255, DOI 10.1007/978-3-540-45232-4_16
   Le T.A., 2009, EVALSVC TOOL SET
   Le TienAnh., 2010, CONSUMER ELECT ISCE, P1, DOI DOI 10.1109/ISCE.2010.5523712
   McDonagh P, 2011, QUALITY ORIENTED SCA
   Pande A, 2011, QUALITY ORIENTED VID
   Quoc Tuan Tran, 2011, 2011 15th International Conference on Intelligence in Next Generation Networks (ICIN): "From Bits to Data, from Pipes to Clouds", P17, DOI 10.1109/ICIN.2011.6081069
   Rec I, 1996, P 800 METHODS SUBJEC, P800
   Reichel J, 2006, ISOIECJTCISC29WG11
   Reisslein M, 2009, H 264AVC SVC VIDEO T
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Skupin R, 2011, J INTERNET SERV APPL, V2, P129, DOI 10.1007/s13174-011-0025-z
   Stephan W., 2006, Journal of Zhejiang University (Science), V7, P657, DOI 10.1631/jzus.2006.A0657
   Team JV, 2013, ITU T RECOMM H, V264, P14496
   Tien Anh Le, 2010, 2010 Second International Conference on Ubiquitous and Future Networks (ICUFN), P394, DOI 10.1109/ICUFN.2010.5547169
   Tien Anh Le, 2010, Proceedings of the Second International Conference on Advances in Multimedia (MMEDIA 2010), P180, DOI 10.1109/MMEDIA.2010.32
   Wang YK, 2007, IEEE T CIRC SYST VID, V17, P1149, DOI 10.1109/TCSVT.2007.906827
   Wenger S, 2003, IEEE T CIRC SYST VID, V13, P645, DOI 10.1109/TCSVT.2003.814966
   WENGER S, 2009, RTP PAYLOAD FORMAT S
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 26
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1239
EP 1256
DI 10.1007/s11042-013-1444-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300011
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yin, L
   Dong, MZ
   Duan, Y
   Deng, WH
   Zhao, KL
   Guo, J
AF Yin, Liang
   Dong, Mingzhi
   Duan, Ying
   Deng, Weihong
   Zhao, Kaili
   Guo, Jun
TI A high-performance training-free approach for hand gesture recognition
   with accelerometer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Training-free; Gesture recognition; Accelerometer
ID COMPUTER; MODELS
AB In previous research on human machine interaction, parameters or templates of gestures are always learnt from training samples first and then a certain kind of matching is conducted. For these training-required methods, a small number of training samples always result in poor or user-independent performance, while a large quantity of training samples lead to time-consuming and laborious sample collection processes. In this paper, a high-performance training-free approach for hand gesture recognition with accelerometer is proposed. First, we determine the underlining space for gesture generation with the physical meaning of acceleration direction. Then, the template of each gesture in the underlining space can be generated from the gesture trails, which are frequently provided in the instructions of gesture recognition devices. Thus, during the gesture template generation process, the algorithm does not require training samples any more and fulfills training-free gesture recognition. After that, a feature extraction method, which transforms the original acceleration sequence into a sequence of more user-invariant features in the underlining space, and a more robust template matching method, which is based on dynamic programming, are presented to finish the gesture recognition process and enhance the system performance. Our algorithm is tested in a 28-user experiment with 2,240 gesture samples and this training-free algorithm shows better performance than the traditional training-required algorithms of Hidden Markov Model (HMM) and Dynamic Time Warping (DTW).
C1 [Yin, Liang; Dong, Mingzhi; Zhao, Kaili] Beijing Univ Posts & Telecommun, Informat & Telecommun Engn Sch, Beijing 100088, Peoples R China.
   [Duan, Ying; Deng, Weihong; Guo, Jun] Beijing Univ Posts & Telecommun, Beijing 100088, Peoples R China.
   [Guo, Jun] Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing 100088, Peoples R China.
   [Duan, Ying] Beijing Normal Univ, Sch Math, Beijing 100875, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beijing University of
   Posts & Telecommunications; Beijing University of Posts &
   Telecommunications; Beijing Normal University
RP Deng, WH (corresponding author), Beijing Univ Posts & Telecommun, Beijing 100088, Peoples R China.
EM Yin@bupt.edu.cn; 2008dmz@gmail.com; whdeng@bupt.edu.cn
RI Guo, Jun/AAB-9166-2022; Deng, Wei/GWC-9207-2022
OI Guo, Jun/0000-0001-6944-0731; Deng, Weihong/0000-0001-5952-6996
CR Akl A, 2010, INT CONF ACOUST SPEE, P2270, DOI 10.1109/ICASSP.2010.5495895
   [Anonymous], GESTURE RECOGNITION
   [Anonymous], 8 IEEE INT C AUT FAC
   Brezmes T, 2009, LECT NOTES COMPUT SC, V5518, P796, DOI 10.1007/978-3-642-02481-8_120
   Brindza J., 2009, Proceedings of IEEE Frontiers in Education Conference, P1, DOI [DOI 10.1109/FIE.2009.5350509, 10.1109/FIE.2009.5350509]
   Byrne D, 2010, MULTIMED TOOLS APPL, V49, P119, DOI 10.1007/s11042-009-0403-8
   Chen Yan Chen Yan, 2011, Guizhou Agricultural Sciences, P1
   Cho S., 2004, MAGIC WAND HAND DRAW
   Choi ES, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY - (ICIT), VOLS 1 AND 2, P161
   Farella E, 2008, MULTIMED TOOLS APPL, V38, P337, DOI 10.1007/s11042-007-0189-5
   Flórez F, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P318, DOI 10.1109/AFGR.2002.1004173
   Holzinger A, 2006, DIGITAL MEDIA, P20
   Holzinger A, 2010, COMPUT INFORM, V29, P601
   Holzinger A, 2009, LECT NOTES COMPUT SC, V5616, P44, DOI 10.1007/978-3-642-02713-0_5
   Hürst W, 2013, MULTIMED TOOLS APPL, V62, P233, DOI 10.1007/s11042-011-0983-y
   Kettebekov S., 2000, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V9, P205, DOI 10.1142/S021821300000015X
   Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904
   Liu JY, 2009, PERVASIVE MOB COMPUT, V5, P657, DOI 10.1016/j.pmcj.2009.07.007
   Mantyjarvi J, 2004, ACM INT C P SERIES
   Mäntylä VM, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P281, DOI 10.1109/ICME.2000.869596
   Montoliu R., 2010, P 9 INT C MOB UB MUL, P12
   Montoliu R, 2013, MULTIMED TOOLS APPL, V62, P179, DOI 10.1007/s11042-011-0982-z
   Muller M., 2007, INFORM RETRIEVAL MUS, V6
   Park C., 2008, IEEE International Conference on Automatic Face and Gesture Recognition, P1, DOI DOI 10.1109/AFGR.2008.4813448
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Pei MT, 2011, IEEE I CONF COMP VIS, P487, DOI 10.1109/ICCV.2011.6126279
   Peng XM, 2011, PATTERN RECOGN, V44, P544, DOI 10.1016/j.patcog.2010.09.015
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rajko Stjepan., 2008, Automatic Face Gesture Recognition, P1
   Seo HJ, 2010, IEEE T PATTERN ANAL, V32, P1688, DOI 10.1109/TPAMI.2009.153
   Sminchisescu C, 2005, IEEE I CONF COMP VIS, P1808
   Song Y., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P388, DOI 10.1109/FG.2011.5771431
   Suk H.I., 2008, 8 IEEE INT C AUTOMAT, P1
   Takahashi M, 2013, MULTIMED TOOLS APPL, V62, P761, DOI 10.1007/s11042-011-0870-6
   Tsukada K, 2002, ASIA PACIFIC COMPUTE
   Wang DX, 2012, MULTIMED TOOLS APPL, V58, P497, DOI 10.1007/s11042-011-0730-4
   Wilson A., 2003, P ACM C SIGCHI, V1, P545, DOI DOI 10.1145/642611.642706
   Wu JH, 2009, LECT NOTES COMPUT SC, V5585, P25
   Zhu YX, 2002, COMPUT VIS IMAGE UND, V85, P189, DOI 10.1006/cviu.2002.0967
   2006, ADXL330 DATASHEET
NR 41
TC 10
Z9 11
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 843
EP 864
DI 10.1007/s11042-013-1368-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800038
DA 2024-07-18
ER

PT J
AU Amriki, KA
   Atrey, PK
AF Amriki, Khaled A.
   Atrey, Pradeep K.
TI Bus surveillance: how many and where cameras should be placed
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bus surveillance; Camera placement; Public transport safety
AB Public transport safety is an important issue that has recently gained substantial attention, especially with the increasing number of violent incidents occurring abroad. To avoid such incidents and to perform post-incident investigations, many buses today are equipped with surveillance cameras. These cameras are usually installed in key places such as doors, the front and the middle of the bus. This camera placement is often performed manually based on human intuition and knowledge; however, there is no scientific basis to justify: (1) how many cameras would be sufficient, and (2) where (location) and how (with what orientation) they should be placed, to increase the area of coverage at the minimum cost. This paper addresses this issue by breaking it down into two separate problems: MaxGain and MinCost. The MaxGain problem is aimed to maximize the overall coverage with a specific number of cameras; while the MinCost problem attempts to minimize the number of cameras to cover a specified area in the bus. The solutions to these two problems are presented. The proposed method computes the approximate coverage of a camera inside the 3D bus model. Furthermore, in order to improve the efficiency of the solution, an algorithm called "SmartMax" is proposed. The proposed solution advises precise locations and orientations (pan and tilt angles) of required cameras and can be used to validate the current camera installations in various types of public transit buses.
C1 [Amriki, Khaled A.; Atrey, Pradeep K.] Univ Winnipeg, Dept Appl Comp Sci, Winnipeg, MB R3B 2E9, Canada.
C3 University of Winnipeg
RP Atrey, PK (corresponding author), Univ Winnipeg, Dept Appl Comp Sci, Winnipeg, MB R3B 2E9, Canada.
EM k-amriki@webmail.uwinnipeg.ca; p.atrey@uwinnipeg.ca
FU Natural Sciences and Engineering Research Council of Canada; Government
   of Saudi Arabia
FX Authors thank the Natural Sciences and Engineering Research Council of
   Canada and the Government of Saudi Arabia for their support in this
   research.
CR Alam SMN, 2006, MOBICOM 2006, P346
   Amriki K, 2011, P IEEE ICME WORKSH A, P1
   [Anonymous], 2011, PUBL TRANSP FACT BOO
   [Anonymous], P IEEE INT WORKSH HA
   Becker E, 2009, P 2 INT C PERV TECHN, P36
   Bodor R, 2007, J INTELL ROBOT SYST, V50, P257, DOI 10.1007/s10846-007-9164-7
   Caprara A, 2000, ANN OPER RES, V98, P353, DOI 10.1023/A:1019225027893
   Chee BC, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P143, DOI 10.1109/ICIAP.2007.4362771
   COWAN CK, 1988, IEEE T PATTERN ANAL, V10, P407, DOI 10.1109/34.3905
   COWAN CK, 1991, P IEEE WORKSHOP DIRE, P22
   Erdem UM, 2004, P WORKSH OMN VIS CAM
   Fehr D, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3780, DOI 10.1109/IROS.2009.5354252
   Globe T, 2008, DECAPITATED BUS PASS
   Gonzalez-Barbosa JJ, 2009, IEEE INT CONF ROBOT, P3672
   Lavee G, 2007, MULTIMED TOOLS APPL, V35, P109, DOI 10.1007/s11042-007-0117-8
   Leoputra WS, 2009, INT CONF ACOUST SPEE, P3525, DOI 10.1109/ICASSP.2009.4960386
   Leoputra WS, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P726, DOI 10.1109/ICARCV.2008.4795607
   Leoputra WS, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P719, DOI 10.1109/ICARCV.2008.4795606
   News C, 2008, 40 YEAR OLD SUSPECT
   Sivaram GSVS, ACM T MULTIMEDIA COM, V5, P23
   Transport Canada, 2007, EV TRANSP CAN IN ENH
   Trucco E., 1998, Introductory techniques for 3-D computer vision, V201
   Valera M, 2005, IEE P-VIS IMAGE SIGN, V152, P192, DOI 10.1049/ip-vis:20041147
   Yabuta K, 2008, IEEE INT SYMP CIRC S, P2114
   Yao Y, 2010, IEEE T SYST MAN CY B, V40, P101, DOI 10.1109/TSMCB.2009.2017507
NR 25
TC 9
Z9 12
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1051
EP 1085
DI 10.1007/s11042-012-1247-1
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000005
DA 2024-07-18
ER

PT J
AU Yu, J
   Lee, BB
   Park, D
AF Yu, Jaehak
   Lee, Byung-Bok
   Park, DaeHeon
TI Real-time cooling load forecasting using a hierarchical multi-class SVDD
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cooling load forecasting; Real-time prediction; Support vector machine;
   Support vector data description
AB In this paper, we propose a real-time cooling load forecasting system in order to overcome the problems of the conventional methods. The proposed system is a new load forecasting model that hierarchically combines Support Vector Data Descriptions (SVDDs). The proposed system selects an optimal attribute subset by our cooling load forecasting system that enables real-time load data generation and collection. The system is composed of two layers: The first layer predicts the time slots in three representative forms: morning, midday and afternoon. The second layer performs specialized prediction of each individual time slot. Since the proposed system enables both coarse-and fine-grained forecasting, it can efficient cooling load management. Moreover, even when a new time slot emerges, it can be easily adapted for incremental updating and scaling. The performance of the proposed system is validated via experiments which confirm that the recall and precision measures of the method are satisfactory.
C1 [Yu, Jaehak; Lee, Byung-Bok; Park, DaeHeon] Elect & Telecommun Res Inst, Taejon 305700, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI)
RP Park, D (corresponding author), Elect & Telecommun Res Inst, Taejon 305700, South Korea.
EM dbzzang@etri.re.kr; bblee40@etri.re.kr; dhpark82@etri.re.kr
FU Ministry of Knowledge Economy, and Development of USN/WoT Convergence
   Platform for Internet of Reality Service Provision [13ZC1130,
   10035310-2010-35, 10040125-2011-199]
FX This work was Development of Smart Plant Safety Framework based on
   Reliable-Secure USN(10035310-2010-35), Development of the Integrated
   Environment Control S/W Platform for Constructing an Urbanized Vertical
   Farm(10040125-2011-199) funded by the Ministry of Knowledge Economy, and
   Development of USN/WoT Convergence Platform for Internet of Reality
   Service Provision(13ZC1130).
CR [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], THESIS WAIKATO U HAM
   Cover T. M., 1991, ELEMENTS INFORM THEO
   Dong B, 2005, ENERG BUILDINGS, V37, P545, DOI 10.1016/j.enbuild.2004.09.009
   Erman Jeffrey., 2006, P 49 IEEE GLOBAL TEL, P1, DOI DOI 10.1109/GLOCOM.2006.443
   Fleuret F, 2004, J MACH LEARN RES, V5, P1531
   HAIDA T, 1994, IEEE T POWER SYST, V9, P1788, DOI 10.1109/59.331433
   HAN JW, 2007, DATA MINING CONCEPT
   Ji Xunsheng, 2011, 2011 International Conference on Measuring Technology and Mechatronics Automation (ICMTMA), P640, DOI 10.1109/ICMTMA.2011.445
   Lee H, 2005, LECT NOTES ARTIF INT, V3642, P511
   Leung MC, 2012, ENERG BUILDINGS, V55, P151, DOI 10.1016/j.enbuild.2012.08.032
   Li Q, 2009, APPL ENERG, V86, P2249, DOI 10.1016/j.apenergy.2008.11.035
   Li Xuemei, 2010, 2010 International Symposium on Computer, Communication, Control and Automation (3CA), P528, DOI 10.1109/3CA.2010.5533863
   Li XM, 2009, 2009 ASIA-PACIFIC CONFERENCE ON INFORMATION PROCESSING (APCIP 2009), VOL 1, PROCEEDINGS, P55, DOI 10.1109/APCIP.2009.22
   OK V, 1992, ENERG BUILDINGS, V19, P11, DOI 10.1016/0378-7788(92)90032-C
   RODGERS JL, 1988, AM STAT, V42, P59, DOI 10.2307/2685263
   Senjyu T, 2002, IEEE T POWER SYST, V17, P113, DOI 10.1109/59.982201
   Seok I, 2006, J IEEE T PATTERN ANA, V26, P1424
   Sharifi M, 2012, ETRI J, V34, P330, DOI [10.4218/etrij.11.0111.0366, 10.4218/etrij.12.0111.0366]
   Song KB, 2005, IEEE T POWER SYST, V20, P96, DOI 10.1109/TPWRS.2004.835632
   Sun Y., 2006, Proceedings of the 23rd international conference on Machine learning, P913, DOI [10.1145/1143844.1143959, DOI 10.1145/1143844.1143959]
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Vapnik V., 1999, NATURE STAT LEARNING
   Yao Y, 2004, INT J THERM SCI, V43, P1107, DOI 10.1016/j.ijthermalsci.2004.02.009
   Yu J, 2010, KSII T INTERNET INF, V4, P859, DOI 10.3837/tiis.2010.10.009
   Yu J, 2008, COMPUT COMMUN, V31, P4212, DOI 10.1016/j.comcom.2008.09.018
NR 26
TC 8
Z9 9
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 1
BP 293
EP 307
DI 10.1007/s11042-013-1412-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK0QX
UT WOS:000338120700017
DA 2024-07-18
ER

PT J
AU Puig-Centelles, A
   Varley, PAC
   Ripolles, O
   Chover, M
AF Puig-Centelles, Anna
   Varley, Peter A. C.
   Ripolles, Oscar
   Chover, Miguel
TI Automatic terrain generation with a sketching tool
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Terrain generation; Sketching interface; Virtual environment; Simulation
AB Nowadays, applications such as scientific simulations, virtual reality or computer games are increasing the detail of their environments with the aim of offering more realism. Terrain is a very important element in these outdoor scenarios. Artists are currently requiring a higher level of customization. In this sense, the objective of the work presented in this paper is to provide the final user with an easy-to-use terrain generation application. More precisely, our aim is to ease the creation of islands. We propose a sketching solution which, combined with a simple terrain algorithm, is capable of suiting the user needs. The application is composed of two windows, which offer 2D and 3D representations of the terrain respectively. These windows are sufficient for providing the user with an interactive feedback about the island that is being designed. We try to show that relatively simple algorithms can be combined and improved to provide successful results.
C1 [Puig-Centelles, Anna] Starlab Barcelona, Barcelona 08022, Spain.
   [Varley, Peter A. C.; Chover, Miguel] Univ Jaume 1, Inst New Imaging Technol, Castellon de La Plana, Spain.
   [Ripolles, Oscar] Neuroelect Barcelona, Barcelona 08022, Spain.
C3 Universitat Jaume I
RP Puig-Centelles, A (corresponding author), Starlab Barcelona, Barcelona 08022, Spain.
EM anna.puig-centelles@starlab.es; varley@uji.es;
   oscar.ripolles@neuroelectrics.com; chover@uji.es
RI Chover Sellés, Miguel/P-9933-2018
OI Chover Sellés, Miguel/0000-0002-0525-7038; Varley,
   Peter/0000-0003-4181-9234; Ripolles, Oscar/0000-0002-5450-6758
FU Spanish Ministry of Science and Technology [TIN2010-21089-C03-03,
   TSI-020400-2009-0133]; Generalitat Valenciana [PROMETEO/2010/028]; Ramon
   y Cajal Scholarship Programme; FEDER funds
FX This work has been funded by the Spanish Ministry of Science and
   Technology (TIN2010-21089-C03-03 and TSI-020400-2009-0133), by the
   Generalitat Valenciana (PROMETEO/2010/028 and BEST/2011), by the Ramon y
   Cajal Scholarship Programme and by FEDER funds.
CR Anastacio F., 2006, PROC 4 INT S NONPHOT, P105
   Autodesk Inc, 2010, AUT 3DS MAX
   Belhadj F, 2007, AFRIGRAPH 2007: 5TH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY, COMPUTER GRAPHICS, VISUALIZATION AND INTERACTION IN AFRICA, P197
   Cao LL, 2008, IEEE T PATTERN ANAL, V30, P507, DOI 10.1109/TPAMI.2007.1185
   Cohen J.M., 2000, Proceedings of the 1st international symposium on Nonphotorealistic animation and rendering, NPAR '00, P83
   Cook MT, 2009, INTERACT COMPUT, V21, P201, DOI 10.1016/j.intcom.2009.05.004
   Dachsbacher C., 2006, THESIS U ERLANGEN NU
   Digital Element, 2006, WORLDBUILDER
   Fefilatyev S, 2006, ICMLA 2006: 5TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P17
   Frade M, 2009, INT J COMPUT GAMES T, V2009, DOI 10.1155/2009/125714
   Gain J., 2009, P 2009 S INT 3D GRAP, V1, P31, DOI [10.1145/1507149.1507155, DOI 10.1145/1507149.1507155]
   Garage Games, 2008, TORQ GAM ENG ADV
   Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232
   Hormann K, 2003, VISION, MODELING, AND VISUALIZATION 2003, P289
   KARA LB, 2006, EUR WORKSH SKETCH BA, P59
   Kelley A. D., 1988, Computer Graphics, V22, P263, DOI 10.1145/378456.378519
   Kosara R, 2003, IEEE COMPUT GRAPH, V23, P20, DOI 10.1109/MCG.2003.1210860
   Maurina E.F., 2006, The game programmer's guide to Torque: under the hood of the Torque Game Engine
   Mori Y, 2007, ACM SIGGRAPH PAPERS, P45
   Musgrave F. K., 1989, Computer Graphics, V23, P41, DOI 10.1145/74334.74337
   Neidhold B, 2006, EUR WORKSH NAT PHEN, P25
   NIELSEN J, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P206
   Olsen L, 2009, COMPUT GRAPH-UK, V33, P85, DOI 10.1016/j.cag.2008.09.013
   Ong TJ, 2005, GECCO 2005: Genetic and Evolutionary Computation Conference, Vols 1 and 2, P1463
   Owada Shigeru., 2007, ACM SIGGRAPH 2007 CO, P38
   Planetside, 2008, TERRAGEN
   Quad, 2008, GROME
   Rusnell B, 2009, VISUAL COMPUT, V25, P573, DOI 10.1007/s00371-009-0332-6
   Schmitt S, 2006, WORLD MACHINE
   Schneider J., 2006, Vision, modeling, and BIBLIOGRAPHY 131 visualization 2006: proceedings, November 22-24, 2006, Aachen, Germany, IOS Press, P145
   Stachowski K, 2006, TERRAINEER
   Teoh ST, 2009, LECT NOTES COMPUT SC, V5875, P468, DOI 10.1007/978-3-642-10331-5_44
   Torpy A, 2009, LARGE 3D TERRAIN GEN
   United States Geological Survey, 2003, NAT MAPP PROGR STAND
   Varley P, 2008, 5 EUR C VIS MED PROD, P1
   Watanabe N, 2004, ACM SIGGRAPH 2004 PO, P73
   Wind Erosion Research Unit Kansas State University, 2003, WIND ER SIM MOD
   Wither J, 2008, EUR WORKSH SKETCH BA
   Worboys M.F., 1995, GIS: A Computing Perspective
   Wunsche B, 2010, P 11 INT C NZ CHAPT
   Zhou H, 2007, IEEE T VIS COMPUT GR, V13, P834, DOI 10.1109/TVCG.2007.1027
NR 41
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1957
EP 1986
DI 10.1007/s11042-012-1214-x
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500026
OA Green Published
DA 2024-07-18
ER

PT J
AU El-Khoury, V
   Coquil, D
   Bennani, N
   Brunie, L
AF El-Khoury, Vanessa
   Coquil, David
   Bennani, Nadia
   Brunie, Lionel
TI Personalized video adaptation framework (PIAF): high-level semantic
   adaptation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Universal multimedia experience; Personalized video; Semantic
   adaptation; MPEG-7; MPEG-21; Semantic constraint
ID MULTIMEDIA; IMAGE
AB Despite much work on Universal Multimedia Experience (UME), existing video adaptation approaches cannot yet be considered as truly user-centric, mostly due to their poor handling of semantic user preferences. Indeed, these works mainly concentrate on lower-level user preferences but do neither consider any fine-grained object-level adaptation nor evaluate different adaptation options based on predicted user expectations. Moreover, these works do not provide owners with property rights that enable them to place restrictions on the types of modifications to be made to the video content. To address these shortcomings, we propose the Personalized vIdeo Adaptation Framework (PIAF) for high-level semantic video adaptation. PIAF is a fully integrated framework providing all the requirements for a semantic video adaptation. It defines a video annotation model and a user profile model comprising semantic constraints that are delineated in a consistent way, based on the standards MPEG-7 and MPEG-1. 21. At the heart of the framework, the Adaptation Decision Taking Engine (ADTE) computes utility values for different adaptation options, considering each shot separately. The corresponding utility function evaluates the possible choices by evaluating multiple parameters that capture different dimensions of a multimedia experience: amount of modified content, modifications to key objects and shots with respect to the semantic integrity of the original content, expected processing cost of the adaptation, and the anticipated visual and temporal quality of the adapted content. Furthermore, the ADTE can deal with intellectual property issues by selecting an adaptation plan of good quality that also satisfies constraints specified by the content owner. This paper places a significant emphasis on theoretical details of the utility function and the computation of the adaptation plan. It also presents the results and evaluation of the adaptation process both in simulation and user study.
C1 [El-Khoury, Vanessa; Bennani, Nadia; Brunie, Lionel] Lyon Univ, CNRS, INSA Lyon, LIRIS,UMR5205, F-69621 Villeurbanne, France.
   [Coquil, David] Univ Passau, Fac Informat & Math, D-94032 Passau, Germany.
C3 Institut National des Sciences Appliquees de Lyon - INSA Lyon; Centre
   National de la Recherche Scientifique (CNRS); University of Passau
RP El-Khoury, V (corresponding author), Lyon Univ, CNRS, INSA Lyon, LIRIS,UMR5205, 7 Ave Jean Capelle, F-69621 Villeurbanne, France.
EM vanessa.el-khoury@insa-lyon.fr; david.coquil@uni-passau.de;
   nadia.bennani@insa-lyon.fr; lionel.brunie@insa-lyon.fr
RI Coquil, David/G-7283-2011
FU Universite Franco-Allemande [CDFA-05-08]
FX This work was conducted in the framework of the Multimedia Distributed
   and Pervasive Secure Systems (MDPS) doctoral college. The MDPS is a
   doctoral college supported by the "Universite Franco-Allemande"
   (CDFA-05-08).
CR Adzic V, 2011, MULTIMED TOOLS APPL, V51, P379, DOI 10.1007/s11042-010-0669-x
   [Anonymous], P WORKSH INT SOC MUL
   [Anonymous], P 7 IEEE WORKSH MULT
   [Anonymous], 210007 ISOIEC
   [Anonymous], 2010, P 12 INT C INF INT W, DOI DOI 10.1145/1967486.1967649
   [Anonymous], J SIGNAL PROCESSING
   [Anonymous], MOV CONT AN
   [Anonymous], MOMM 2012 10 INT C A
   [Anonymous], P 48 INT S ELMAR 200
   [Anonymous], JTC1SC29WG11N5525 IS
   [Anonymous], WORKSH MULT WEB CONJ
   [Anonymous], J IMAGE GRAPHICS
   [Anonymous], P 1 INT C AMB MED SY
   [Anonymous], MEDIA FRAGMENTS URI
   [Anonymous], 2010, THESIS U KENTUCKY
   Chan T, 1999, LECT NOTES COMPUT SC, V1682, P141
   Chan TF, 2006, J MATH IMAGING VIS, V26, P85, DOI 10.1007/s10851-006-6865-7
   Dasiopoulou S, 2011, LECT NOTES ARTIF INT, V6050, P196, DOI 10.1007/978-3-642-20795-2_8
   De Bruyne S, 2011, MULTIMED TOOLS APPL, V55, P307, DOI 10.1007/s11042-010-0575-2
   De Cock J, 2010, MULTIMEDIA SYST, V16, P139, DOI 10.1007/s00530-009-0180-2
   Kellerer H., 2010, KNAPSACK PROBLEMS
   Lankton S., 2009, SPARSE FIELD METHODS
   Lee W., 2012, Ontology for Media Resouces 1.0
   López F, 2009, LECT NOTES COMPUT SC, V5887, P114, DOI 10.1007/978-3-642-10543-2_12
   Magalhaes J, 2004, SIGNAL PROCESS-IMAGE, V19, P437, DOI 10.1016/j.image.2004.02.004
   Nielsen F., 2005, 13th Annual ACM International Conference on Multimedia, P315, DOI 10.1145/1101149.1101214
   Pereira F, 2003, IEEE SIGNAL PROC MAG, V20, P63, DOI 10.1109/MSP.2003.1184340
   PISINGER D, 1995, EUR J OPER RES, V83, P394, DOI 10.1016/0377-2217(95)00015-I
   Shi YG, 2005, PROC CVPR IEEE, P34
   Shih TK, 2005, THIRD INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND APPLICATIONS, VOL 1, PROCEEDINGS, P15
   SINHA P, 1979, OPER RES, V27, P503, DOI 10.1287/opre.27.3.503
   Sofokleous AA, 2008, MULTIMED TOOLS APPL, V40, P151, DOI 10.1007/s11042-008-0198-z
   Stamou G, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.15
   Van Deursen D, 2010, MULTIMED TOOLS APPL, V46, P371, DOI 10.1007/s11042-009-0354-0
   Van Rijsselbergen D, 2012, MULTIMED TOOLS APPL, V59, P307, DOI 10.1007/s11042-010-0710-0
NR 35
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 1099
EP 1140
DI 10.1007/s11042-012-1225-7
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900023
DA 2024-07-18
ER

PT J
AU Meixner, B
   Matusik, K
   Grill, C
   Kosch, H
AF Meixner, Britta
   Matusik, Katarzyna
   Grill, Christoph
   Kosch, Harald
TI Towards an easy to use authoring tool for interactive non-linear video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authoring; Interactive video; Non-linear video; Video annotations; Scene
   graph; Usability
ID HYPERVIDEO; SYSTEM; ITV
AB With growing bandwidths in the Internet and seemingly unlimited storage capacities on web servers, media became more and more important in the daily use of the World Wide Web. While about ten years ago only text and images with small file sizes (and as a result small resolutions) could be used, it is possible to watch high quality multimedia presentations nowadays. But those rarely exist because of tedious to learn authoring tools. A specialization to one main medium, in our case video, allows creating efficient authoring tools using well known paradigms. This work introduces an authoring tool called SIVA Producer. An iterative process for improving the usability of the authoring tool is described. Furthermore, a distinction of the terms "interactive video", "annotated video", "non-linear video" and "hypervideo" is given.
C1 [Meixner, Britta; Matusik, Katarzyna; Grill, Christoph; Kosch, Harald] Univ Passau, D-94032 Passau, Germany.
C3 University of Passau
RP Meixner, B (corresponding author), Univ Passau, Innstr 43, D-94032 Passau, Germany.
EM meixner@fim.uni-passau.de; matusik@gmx.de; christoph.grill@web.de;
   harald.kosch@uni-passau.de
RI Meixner, Britta/T-7013-2017
OI Kosch, Harald/0000-0002-7090-1133
FU European Social Fonds; Bayrisches Staatsministerium fur Wissenschaft,
   Forschung und Kunst (Bavarian State Ministry of Sciences, Research and
   the Arts)
FX This work was partially supported by European Social Fonds and the
   Bayrisches Staatsministerium fur Wissenschaft, Forschung und Kunst
   (Bavarian State Ministry of Sciences, Research and the Arts) under
   project names "iVi-Pro" and "iVi-Pro 2.0". We thank all former and
   present colleagues, research assistants and students for their
   contributions to this work.
CR Abowd G.D., 2003, Proceedings of the 5th ACM SIGMM international workshop on Multimedia information retrieval, P1, DOI DOI 10.1145/973264.973266
   [Anonymous], 2011, 9241210201101 DIN EN
   AUBERT O., 2005, P 16 ACM C HYPERTEXT, P235
   Aubert Olivier, 2007, MULTIMEDIA 07, P1005, DOI 10.1145/1291233.1291451
   Baecker R., 1996, Proceedings ACM Multimedia 96, P31, DOI 10.1145/244130.244142
   Bouyakoub S, 2011, ACM T MULTIM COMPUT, V7
   Bulterman DCA, 1998, COMPUT NETWORKS ISDN, V30, P519, DOI 10.1016/S0169-7552(98)00128-7
   Bulterman DCA, 2005, ACM T MULTIM COMPUT, V1, P89, DOI 10.1145/1047936.1047943
   Büring T, 2006, IEEE T VIS COMPUT GR, V12, P829
   Carlsson N, 2008, IEEE T MULTIMEDIA, V10, P871, DOI 10.1109/TMM.2008.922847
   Chambel T, 2004, IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P345, DOI 10.1109/ICALT.2004.1357433
   DAVENPORT G, 1991, IEEE COMPUT GRAPH, V11, P67, DOI 10.1109/38.126883
   Finke M, 2004, COMPUT GRAPH-UK, V28, P179, DOI 10.1016/j.cag.2003.12.005
   Francisco-Revilla L., 1998, A Picture of Hypervideo Today
   Frisch M, 2008, SOFTVIS 2008: PROCEEDINGS OF THE 4TH ACM SYMPOSIUM ON SOFTWARE VISUALIZATION, P207
   Gotz D., 2006, Proceedings of the 14th annual ACM international conference on Multimedia, P357, DOI DOI 10.1145/1180639.1180717
   Guimaraes RL, 2008, LECT NOTES COMPUT SC, V5066, P61, DOI 10.1007/978-3-540-69478-6_7
   Guimaraes RL, 2010, DOCENG2010: PROCEEDINGS OF THE 2010 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P27
   Hammoud RI, 2006, SIG COM TEC, P3
   Han-Bin Chang, 2004, 2004 IEEE International Conference on Multimedia and Expo (ICME) (IEEE Cat. No.04TH8763), P2219, DOI 10.1109/ICME.2004.1394711
   Heeter Carrie., 1989, MEDIA USE INFORM AGE, P217
   Hoffmann P, 2008, LECT NOTES COMPUT SC, V5066, P51
   Hoffmann P, 2006, LECT NOTES COMPUT SC, V4326, P37
   Hofmann C, 2009, MENSCH COMPUTER, P173
   Hung YC, 1997, SOFTWARE PRACT EXPER, V27, P1263, DOI 10.1002/(SICI)1097-024X(199711)27:11<1263::AID-SPE129>3.0.CO;2-3
   Kipp M., 2001, Proceedings of the European Conference on Speech Communication and Technology, P1367
   Kozuch M, 2000, MULTIMEDIA SYST, V8, P135, DOI 10.1007/s005300050156
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   Lugmayr A., 2004, SIGNALS COMMUNICATIO
   Luo HT, 2002, SIGNAL PROCESS-IMAGE, V17, P559, DOI 10.1016/S0923-5965(02)00036-X
   MACKAY WE, 1989, COMMUN ACM, V32, P802, DOI 10.1145/65445.65447
   Mayer-Patel K, 2007, IEEE MULTIMEDIA, V14, P68, DOI 10.1109/MMUL.2007.63
   Meixner B., 2010, Proceedings of the 18th ACM international conference on Multimedia, P1563, DOI [https://doi.org/10.1145/1873951.1874287, DOI 10.1145/1873951.1874287]
   Meixner B., 2009, P I KNOW 9 INT C KNO, P215
   Meixner Britta, 2011, P 19 ACM INT C MULT, P779, DOI DOI 10.1145/2072298.2072453
   Mujacic Samra, 2007, 2007 14th International Workshop in Systems, Signals and Image Processing and 6th EURASIP Conference focused on Speech and Image Processing, Multimedia Communications and Services - EC-SIPMCS 2007, P189, DOI 10.1109/IWSSIP.2007.4381185
   Naphade M. R., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4676, P264, DOI 10.1117/12.451096
   NIELSEN J, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P206
   Nielsen Jakob, 2000, WHY YOU ONLY NEED TE
   Nielsen Jakob, 1994, USABILITY ENG
   Ogawa R., 1992, Proceeding of the ACM Conference on Hypertext, P71, DOI 10.1145/168466.168494
   Pagani M., 2003, Multimedia and Interactive Digital TV: Managing the Opportunities Created by Digital Convergence
   Pea R, 2004, IEEE MULTIMEDIA, V11, P54, DOI 10.1109/MMUL.2004.1261108
   Psannis KE, 2006, IEEE T CIRC SYST VID, V16, P280, DOI 10.1109/TCSVT.2005.859933
   Satoh S, 1999, P 7 ACM INT C MULT 1, P75
   Sawhney N., 1996, Seventh ACM Conference on Hypertext. Hypertext '96, P1, DOI 10.1145/234828.234829
   Shen EYT, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P809
   Shipman F., 2003, P 11 ACM INT C MULT, P392, DOI DOI 10.1145/957013.957096
   Shipman F, 2008, ACM T MULTIM COMPUT, V5, DOI 10.1145/1413862.1413868
   Soares L. F. G., 2005, NESTED CONTEXT MODEL
   Soares LFG, 2000, MULTIMEDIA SYST, V8, P118, DOI 10.1007/s005300050155
   Spaniol M, 2006, LECT NOTES COMPUT SC, V4181, P249
   Stenzler M. K., 1996, SIGCHI Bulletin, V28, P76, DOI 10.1145/226650.226676
   van Rossum G., 1993, Proceedings ACM Multimedia 93, P183, DOI 10.1145/166266.166287
   Volkmer T., 2005, 13th Annual ACM International Conference on Multimedia, P892, DOI 10.1145/1101149.1101341
   W3C, 2008, Synchronized multimedia integration language (SMIL 3.0)
   W3C, 2011, W3C CONF MAY 2011 HT
   Xu CZ, 2009, 2009 IEEE THIRD INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING (ICSC 2009), P670, DOI 10.1109/ICSC.2009.53
   Yang CC, 2003, MULTIMED TOOLS APPL, V21, P243, DOI 10.1023/A:1025770817293
   Yatabe T, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P194, DOI 10.1109/MMCS.1999.778255
   Yoo B., 2008, 17 INT WORLD WID WEB, P1019
   Zhang K., 2010, P 19 INT C WORLD WID, P1329, DOI DOI 10.1145/1772690.1772914
   Zhao YP, 2007, IEEE ACM T NETWORK, V15, P1149, DOI 10.1109/TNET.2007.896534
   Zhou T. T., 2005, 13th Annual ACM International Conference on Multimedia, P379, DOI 10.1145/1101149.1101230
NR 64
TC 21
Z9 23
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 1251
EP 1276
DI 10.1007/s11042-012-1218-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900029
DA 2024-07-18
ER

PT J
AU van Rest, J
   Grootjen, FA
   Grootjen, M
   Wijn, R
   Aarts, O
   Roelofs, ML
   Burghouts, GJ
   Bouma, H
   Alic, L
   Kraaij, W
AF van Rest, J.
   Grootjen, F. A.
   Grootjen, M.
   Wijn, R.
   Aarts, O.
   Roelofs, M. L.
   Burghouts, G. J.
   Bouma, H.
   Alic, L.
   Kraaij, W.
TI Requirements for multimedia metadata schemes in surveillance
   applications for security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surveillance; Human behaviour; Annotation; Metadata representation
   scheme; Event; Action; Multimodal; Multi-sensor; ONVIF; MPEG-7; PETS
AB Surveillance for security requires communication between systems and humans, involves behavioural and multimedia research, and demands an objective benchmarking for the performance of system components. Metadata representation schemes are extremely important to facilitate (system) interoperability and to define ground truth annotations for surveillance research and benchmarks. Surveillance places specific requirements on these metadata representation schemes. This paper offers a clear and coherent terminology, and uses this to present these requirements and to evaluate them in three ways: their fitness in breadth for surveillance design patterns, their fitness in depth for a specific surveillance scenario, and their realism on the basis of existing schemes. It is also validated that no existing metadata representation scheme fulfils all requirements. Guidelines are offered to those who wish to select or create a metadata scheme for surveillance for security.
C1 [van Rest, J.; Grootjen, M.; Wijn, R.; Aarts, O.; Roelofs, M. L.; Burghouts, G. J.; Bouma, H.; Alic, L.; Kraaij, W.] TNO, The Hague, Netherlands.
   [Grootjen, F. A.] Radboud Univ Nijmegen, NL-6525 ED Nijmegen, Netherlands.
C3 Netherlands Organization Applied Science Research; Radboud University
   Nijmegen
RP van Rest, J (corresponding author), TNO, The Hague, Netherlands.
EM jeroen.vanrest@tno.nl
RI Alic, Lejla/N-9589-2019; Bouma, Henri/F-1567-2010; Kraaij,
   Wessel/S-2071-2016
OI Kraaij, Wessel/0000-0001-7797-619X; Bouma, Henri/0000-0002-9363-6870
CR Alexander C., 1977, PATTERN LANGUAGE TOW
   Annesley J, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P482, DOI 10.1109/AVSS.2007.4425358
   [Anonymous], P SPIE
   [Anonymous], I LIDS IM LIB INT DE
   [Anonymous], 2011, EVALUATING USE PUBLI
   [Anonymous], 1996, PATTERN ORIENTED SOF
   [Anonymous], 1990, Building Large Knowledge-Based Systems: Representation and Inference in the CYC Project
   Burghouts GJ, 2011, IEEE T SYST MAN CY C, V41, P608, DOI 10.1109/TSMCC.2011.2135344
   SanMiguel JC, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P220, DOI 10.1109/AVSS.2009.28
   Doermann D, 2000, INT C PATT RECOG, P167, DOI 10.1109/ICPR.2000.902888
   Fisher R.B., 2004, IEEE International Workshop on Performance Evaluation of Tracking and Surveillance (PETS), P1
   François ARJ, 2005, IEEE MULTIMEDIA, V12, P76, DOI 10.1109/MMUL.2005.87
   Kester Leon J. H. M., 2008, 2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2008), P516, DOI 10.1109/MFI.2008.4648047
   Kipp M, 2013, ANVIL 4 0 ANNOTATION
   Kipp M, 2013, ANVIL VIDEO RES ANNO
   List T, 2004, INT C PATT RECOG, P789, DOI 10.1109/ICPR.2004.1334335
   Lyon D., 2007, SURVEILLANCE STUDIES
   Mariano VY, 2002, INT C PATT RECOG, P965, DOI 10.1109/ICPR.2002.1048198
   Masolo Claudio, 2003, TECHNICAL REPORT 1 P
   Neely H, 2010, IEEE AER C
   Nghiem AT, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P476, DOI 10.1109/AVSS.2007.4425357
   Niles I., 2001, Formal Ontology in Information Systems. Collected Papers from the Second International Conference, P2, DOI 10.1145/505168.505170
   Over P, 2011, P TRECVID 2010 OV GO
   Schallauer P., 2009, P SPIE, V7344
   SOWA JF, 1976, IBM J RES DEV, V20, P336, DOI 10.1147/rd.204.0336
   Sowa JohnF., 1984, Information Processing in Mind and Machine, P39
   Steinberg A., 1999, Revisions to the jdl data fusion model
   Surveillance of Unattended Baggage and the Identification and Tracking of the Owner (SUBITO) consortium, 2011, SURV UN BAGG ID TRAC
   Suzic R, 2005, P SPIE
   Westermann U, 2007, IEEE MULTIMEDIA, V14, P19, DOI 10.1109/MMUL.2007.23
NR 30
TC 6
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 1
BP 573
EP 598
DI 10.1007/s11042-013-1575-9
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI4AK
UT WOS:000336807300027
DA 2024-07-18
ER

PT J
AU Tsai, YY
AF Tsai, Yuan-Yu
TI An adaptive steganographic algorithm for 3D polygonal models using
   vertex decimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D Polygonal Models; Steganography; Adaptability; Vertex decimation
ID WATERMARKING; CAPACITY
AB Most 3D steganographic algorithms emphasize high data capacity, low distortion, and correct data extraction. However, their disadvantage is in the existence of the same embedding capacity for each data-embedded vertex in the 3D models. Embedding the same capacity in the vertex located on the surface with different properties may cause obvious distortion, making it difficult to achieve the initial goal of information-hiding techniques. This study proposes a new and adaptive 3D steganographic algorithm that considers the surface complexity. To increase the accuracy of the complexity estimation for each embedding vertex, the proposed algorithm adopts a vertex decimation process to determine its referencing neighbors. Thereafter, different amounts of the secret messages are embedded according to the surface properties of each vertex. This approach preserves important shape features and produces a more imperceptible result. Experimental results show that the proposed adaptive algorithm can achieve more accurate estimation results with a higher data capacity and acceptable distortion. The proposed technique is feasible in 3D steganography.
C1 Asia Univ, Dept Appl Informat & Multimedia, Taichung 413, Taiwan.
C3 Asia University Taiwan
RP Tsai, YY (corresponding author), Asia Univ, Dept Appl Informat & Multimedia, Taichung 413, Taiwan.
EM yytsai@asia.edu.tw
FU National Science Council of Taiwan [NSC 98-2221-E-468-017]; Asia
   University [100-A-04]
FX The author would like to thank the anonymous reviewers for their
   constructive comments. This work was supported by the National Science
   Council of Taiwan (Grant No. NSC 98-2221-E-468-017) and the research
   project of Asia University (Grant No. 100-A-04).
CR Benedens O, 1999, IEEE COMPUT GRAPH, V19, P46, DOI 10.1109/38.736468
   Bogomjakov A, 2008, COMPUT GRAPH FORUM, V27, P637, DOI 10.1111/j.1467-8659.2008.01161.x
   Bors AG, 2006, IEEE T IMAGE PROCESS, V15, P687, DOI 10.1109/TIP.2005.863116
   Cayre F, 2003, IEEE T SIGNAL PROCES, V51, P939, DOI 10.1109/TSP.2003.809380
   Chao MW, 2009, IEEE T VIS COMPUT GR, V15, P274, DOI 10.1109/TVCG.2008.94
   Cheng YM, 2007, VISUAL COMPUT, V23, P721, DOI 10.1007/s00371-007-0147-2
   Cheng YM, 2006, VISUAL COMPUT, V22, P845, DOI 10.1007/s00371-006-0069-4
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Huang NC, 2009, IEEE SIGNAL PROC LET, V16, P802, DOI 10.1109/LSP.2009.2024794
   Kim K, 2010, IEEE T INF FOREN SEC, V5, P721, DOI 10.1109/TIFS.2010.2068546
   Konstantinides JM, 2009, IEEE T MULTIMEDIA, V11, P23, DOI 10.1109/TMM.2008.2008913
   Li MT, 2011, INT J INNOV COMPUT I, V7, P1055
   Lin HYS, 2005, IEEE T MULTIMEDIA, V7, P997, DOI 10.1109/TMM.2005.858412
   Ohbuchi R, 2002, COMPUT GRAPH FORUM, V21, P373, DOI 10.1111/1467-8659.t01-1-00597
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Rencher A. C., 1995, Methods of Multivariate Analysis
   SCHROEDER WJ, 1992, COMP GRAPH, V26, P65, DOI 10.1145/142920.134010
   Wang CM, 2005, COMPUT GRAPH FORUM, V24, P591, DOI 10.1111/j.1467-8659.2005.00884.x
   Wang K, 2008, IEEE T INF FOREN SEC, V3, P620, DOI 10.1109/TIFS.2008.2007229
   Wang K, 2008, IEEE T MULTIMEDIA, V10, P1513, DOI 10.1109/TMM.2008.2007350
   Yang Y, 2010, COMPUT GRAPH FORUM, V29, P1585, DOI 10.1111/j.1467-8659.2010.01767.x
   Zafeiriou S, 2005, IEEE T VIS COMPUT GR, V11, P596, DOI 10.1109/TVCG.2005.71
NR 23
TC 20
Z9 20
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 859
EP 876
DI 10.1007/s11042-012-1135-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300014
DA 2024-07-18
ER

PT J
AU Li, Y
   Sun, ZX
AF Li, Yi
   Sun, Zhengxing
TI Generative tracking of 3D human motion in latent space by sequential
   clonal selection algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human motion analysis; Pose estimation; Human motion tracking; Manifold
   learning; Clonal selection algorithm
ID CAPTURE; POSE
AB High dimensional pose state space is the main challenge in articulated human pose tracking which makes pose analysis computationally expensive or even infeasible. In this paper, we propose a novel generative approach in the framework of evolutionary computation, by which we try to widen the bottleneck with effective search strategy embedded in the extracted state subspace. Firstly, we use ISOMAP to learn the low-dimensional latent space of pose state in the aim of both reducing dimensionality and extracting the prior knowledge of human motion simultaneously. Then, we propose a manifold reconstruction method to establish smooth mappings between the latent space and original space, which enables us to perform pose analysis in the latent space. In the search strategy, we adopt a new evolutionary approach, clonal selection algorithm (CSA), for pose optimization. We design a CSA based method to estimate human pose from static image, which can be used for initialization of motion tracking. In order to make CSA suitable for motion tracking, we propose a sequential CSA (S-CSA) algorithm by incorporating the temporal continuity information into the traditional CSA. Actually, in a Bayesian inference view, the sequential CSA algorithm is in essence a multilayer importance sampling based particle filter. Our methods are demonstrated in different motion types and different image sequences. Experimental results show that our CSA based pose estimation method can achieve viewpoint invariant 3D pose reconstruction and the S-CSA based motion tracking method can achieve accurate and stable tracking of 3D human motion.
C1 [Li, Yi; Sun, Zhengxing] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210008, Jiangsu, Peoples R China.
C3 Nanjing University
RP Sun, ZX (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210008, Jiangsu, Peoples R China.
EM njulanty@gmail.com; szx@nju.edu.cn
RI Sun, Zhengxing/A-7411-2011
OI Sun, Zhengxing/0000-0001-7137-6169
FU National High Technology Research and Development Program of China
   [2007AA01Z334]; National Natural Science Foundation of China [61272219,
   61021062, 61100110]; Program for New Century Excellent Talents in
   University of China [NCET-04-04605]; Natural Science Foundation of
   Jiangsu Province [BK2010375]; Key Technology R&D Program of Jiangsu
   Province [BY2012190, BE2010072, BE2011058]
FX This work is supported by The National High Technology Research and
   Development Program of China (2007AA01Z334), National Natural Science
   Foundation of China (61272219, 61021062 and 61100110), Program for New
   Century Excellent Talents in University of China (NCET-04-04605),
   Natural Science Foundation of Jiangsu Province (BK2010375), Key
   Technology R&D Program of Jiangsu Province (BY2012190, BE2010072 and
   BE2011058).
CR Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   Agarwal A, 2005, IEEE WORKSH VIS HUM
   [Anonymous], P IEEE INT C COMP VI, DOI DOI 10.1109/CVPR.2000.854758
   de Castro LN, 2002, IEEE T EVOLUT COMPUT, V6, P239, DOI 10.1109/TEVC.2002.1011539
   El-Nady KE, 2011, INT J OPEN PROBL COM, V4, P37
   Elgammal A, 2004, PROC CVPR IEEE, P681
   Gong MG, 2010, INFORM SCIENCES, V180, P1218, DOI 10.1016/j.ins.2009.12.007
   Howe NR, 2000, ADV NEUR IN, V12, P820
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   John V, 2010, IMAGE VISION COMPUT, V28, P1530, DOI 10.1016/j.imavis.2010.03.008
   Krzeszowski T, 2010, LECT NOTES COMPUT SC, V6374, P147, DOI 10.1007/978-3-642-15910-7_17
   Lawrence ND, 2003, ADV NEURAL INF PROCE, P329
   Lee CS, 2010, INT J COMPUT VISION, V87, P118, DOI 10.1007/s11263-009-0266-5
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Mori G, 2006, IEEE T PATTERN ANAL, V28, P1052, DOI 10.1109/TPAMI.2006.149
   Ormoneit D, 2001, ADV NEUR IN, V13, P894
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Raskin L, 2011, COMPUT VIS IMAGE UND, V115, P503, DOI 10.1016/j.cviu.2010.12.002
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Sminchisescu C, 2003, INT J ROBOT RES, V22, P371, DOI 10.1177/0278364903022006003
   Sminchisescu C., 2004, Proc. 21st International Conference on Machine Learning, P96
   Sminchisescu C., 2007, Human Motion Understanding, Modeling, Capture and Animation
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tian T-P, 2005, BUCSTR2005029
   Urtasun R, 2005, PROC CVPR IEEE, P932
   Zhang XY, 2008, PROCEEDINGS OF THE 13TH INTERNATIONAL SYMPOSIUM ON 3D WEB TECHNOLOGY (WEB3D 2008), P23, DOI 10.1145/1394209.1394216
   Zhao X, 2008, PATTERN RECOGN, V41, P2470, DOI 10.1016/j.patcog.2008.01.004
NR 27
TC 6
Z9 7
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 1
BP 79
EP 109
DI 10.1007/s11042-012-1251-5
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AB3UH
UT WOS:000331715200005
DA 2024-07-18
ER

PT J
AU Lee, D
   Kim, KJ
AF Lee, DongHwi
   Kim, Kuinam J.
TI A study on malicious codes pattern advanced analysis using visualization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Malicious codes; Visualization
AB The expansion of internet technology has made convenience. On the one hand various malicious code is produced. The number of malicious codes occurrence has dramatically increasing, and new or variant malicious code circulation very serious, So it is time to require analysis about malicious code. The being so malicious code pattern extract for malicious code properties of anti-virus company. Visualization possible to make one image for thousands upon thousands of malicious code. and It is possible to extract unseen pattern. Therefore this paper of object is various malicious code analysis besides new or variant malicious code type or form deduction using visualization of strong. Thus this paper proposes unseen malicious code pattern extract.
C1 [Lee, DongHwi] Univ Colorado, Dept Comp Sci & Engn, Denver, CO 80204 USA.
   [Kim, Kuinam J.] Kyonggi Univ, Dept Convergence Secur, Suwon, Gyeonggi Do, South Korea.
C3 University of Colorado System; University of Colorado Denver; Kyonggi
   University
RP Lee, D (corresponding author), Univ Colorado, Dept Comp Sci & Engn, 1200 Larimer St NC 2605-C,Campus Box 109, Denver, CO 80204 USA.
EM dhclub@naver.com; Harap123@daum.net
FU Gyeonggi-do Technology Development Project [A10101110]
FX This work was supported by a grant from Gyeonggi-do Technology
   Development Project (No A10101110).
CR Ahn Lab, 2009, ASEC ANN REP
   Bae S-J, 2008, INF PROT SOC PAP, V18, P115
   Choi H, 2005, PCAV INTERNET ATTACK
   Few S, 2006, PERCEPTUAL EDGE 0912
   Jang Y-J, 2008, INF PROT SOC PAP, V18, P1
   KASEMSRI RR, 2005, SURVEY TAXONOMY ANAL
   Keim DA, 2002, IEEE T VIS COMPUT GR, V8, P1, DOI 10.1109/2945.981847
   Nwokedi I, 2007, SURVEY MALWARE DETEC
   Seo H-S, 2009, PROT SOC PAP, V19, P88
   Seo H-S, 2009, KOREAN SIMUL ACAD PA, V18, P63
   Skoudis Ed., 2004, MALWARE FIGHTING MAL
   [No title captured]
NR 12
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 2
BP 253
EP 263
DI 10.1007/s11042-011-0907-x
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RI
UT WOS:000331083400004
DA 2024-07-18
ER

PT J
AU Müller, D
   Yi, MY
AF Mueller, David
   Yi, Mun Yong
TI Annotating korean text documents with linked data resources
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic annotation; Entity linking; Linked data; Korean; LOD
AB Semantic annotation approaches link entities from a knowledge base to mentions of entities in text to provide additional content-related information. Recently increasing use of resources from the Linked Open Data (LOD) Cloud has been made to annotate text documents thanks to the network of machine-understandable, interlinked data. While existing approaches to semantic annotation in the LOD context have been proven to be well performing with the English language, many other languages in general and the Korean language in particular are still underrepresented. We investigate the applicability of existing semantic annotation approaches to the Korean language by adapting two popular approaches in the semantic annotation field and evaluating those approaches on an English-Korean bilingual sense-tagged corpus. Further, general challenges in internationalization of annotation approaches are summarized.
C1 [Mueller, David] Karlsruhe Inst Technol, D-76021 Karlsruhe, Germany.
   [Yi, Mun Yong] Korea Adv Inst Sci & Technol, Dept Knowledge Serv Engn, Taejon 305701, South Korea.
C3 Helmholtz Association; Karlsruhe Institute of Technology; Korea Advanced
   Institute of Science & Technology (KAIST)
RP Yi, MY (corresponding author), Korea Adv Inst Sci & Technol, Dept Knowledge Serv Engn, Taejon 305701, South Korea.
EM munyi@kaist.ac.kr
RI Yi, Mun Yong/C-2065-2011
FU Korean Ministry of Knowledge Economy
FX This research was conducted by the International Collaborative Research
   and Development Program (Creating Knowledge out of Interlinked Data) and
   funded by the Korean Ministry of Knowledge Economy.
CR [Anonymous], 6 INT SEM WEB C ISWC
   Auer S, 2010, 9 INT SEM WEB C ISWC
   Benjamins V, 2002, KR2002 WORKSH FORM O
   Chai H, 2010, P 21 PAC AS C LANG I
   Chai H, 2007, DATABASE EXPERT SYST
   Chung T, 2010, NAACL HLT 2010 1 WOR
   Djioua B, 2006, P FLAIRS C 2006
   Ferragina P, 2010, 19 ACM C INF KNOWL M
   Gerber A, 2011, SCOPING STUDY WHO WH
   Halpern J, 2006, 5 INT C CHIN SPOK LA
   Heath T., 2011, SYNTH LECT SEM WEB
   Kim E, 2010, P 5 OP KNOWL C
   Medelyan O., 2008, P AAAI WIKIAI WORKSH
   Meij E, 2012, 5 ACM INT C WEB SEAR
   Mendes P. N., 2011, 7 INT C SEM SYST I S
   MIHALCEA R, 2007, P 16 ACM C INF KNOWL
   Milne D, 2009, P NZ COMP SCI RES
   Milne D, 2008, 17 ACM C INF KNOWL M
   Ratinov L., 2011, P 49 ANN M ASS COMP
   Rizzo G., 2011, 10 INT SEM WEB C ISW
   Zheng H, 2006, MOL NEURODEGENER, V1, DOI 10.1186/1750-1326-1-5
NR 21
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 2
BP 413
EP 427
DI 10.1007/s11042-012-1339-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RI
UT WOS:000331083400015
DA 2024-07-18
ER

PT J
AU Szczuko, P
AF Szczuko, Piotr
TI Genetic programming extension to APF-based monocular human body pose
   estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pose estimation; Evolutionary optimization
ID MOTION CAPTURE; TRACKING
AB New method of the human body pose estimation based on a single camera 2D observation is presented, aimed at smart surveillance related video analysis and action recognition. It employs 3D model of the human body, and genetic algorithm combined with annealed particle filter for searching the global optimum of model state, best matching the object's 2D observation. Additionally, new motion cost metric is employed, considering current pose and history of the body movement, favouring the estimates with the lowest changes of motion speed comparing to previous poses. The "genetic memory" concept is introduced for the genetic processing of both current and past states of 3D model. State-of-the-art in the field of human body tracking is presented and discussed. Details of implemented method are described. Results of experimental evaluation of developed algorithm are included and discussed.
C1 Gdansk Univ Technol, Multimedia Syst Dept, PL-80233 Gdansk, Poland.
C3 Fahrenheit Universities; Gdansk University of Technology
RP Szczuko, P (corresponding author), Gdansk Univ Technol, Multimedia Syst Dept, Narutowicza 11-12, PL-80233 Gdansk, Poland.
EM szczuko@sound.eti.pg.gda.pl
RI Szczuko, Piotr/AAB-4822-2020
OI Szczuko, Piotr/0000-0003-3703-8734
FU European regional development fund; Polish State budget; 
   [POIG.02.03.03-00-008/08]
FX Research funded within the project No. POIG.02.03.03-00-008/08, entitled
   "MAYDAY EURO 2012-the supercomputer platform of context-depended
   analysis of multimedia data streams for identifying specified objects or
   safety threats" subsidized by the European regional development fund and
   by the Polish State budget.
CR [Anonymous], 1998, Genetic algorithms+Data Structures=Evolution Programs
   [Anonymous], P IEEE INT C COMP VI, DOI DOI 10.1109/CVPR.2000.854758
   Back T, 1998, GENETIC ALGORITHMST
   Czyzewski A, 2010, P KES IIMSS 2010 BAL
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Kakadiaris I, 2000, IEEE T PATTERN ANAL, V22, P1453, DOI 10.1109/34.895978
   Kehl R, 2006, COMPUT VIS IMAGE UND, V104, P190, DOI 10.1016/j.cviu.2006.07.010
   Lech M, 2010, P INT C MULT NETW IN
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Ong EJ, 2006, COMPUT VIS IMAGE UND, V104, P178, DOI 10.1016/j.cviu.2006.08.004
   Sidenbladh H., 2000, Lecture Notes in Computer Science, P702
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Wachter S, 1999, COMPUT VIS IMAGE UND, V74, P174, DOI 10.1006/cviu.1999.0758
NR 18
TC 7
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 1
BP 177
EP 192
DI 10.1007/s11042-012-1147-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 283JZ
UT WOS:000329243600011
OA hybrid
DA 2024-07-18
ER

PT J
AU Taneja, N
   Bhatnagar, G
   Raman, B
   Gupta, I
AF Taneja, Nidhi
   Bhatnagar, Gaurav
   Raman, Balasubramanian
   Gupta, Indra
TI Joint watermarking and encryption for still visual data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Joint watermarking and encryption; Singular value decomposition; Set
   partitioning in hierarchical trees
ID SELECTIVE ENCRYPTION; VIDEO
AB Joint watermarking and encryption is an upcoming security solution that combines leading but complementary techniques to achieve an enhanced security level. Real time applications using joint watermarking and encryption framework has three requirements: data to be efficiently compressed, watermarking technique to sustain compression, and encryption technique to be developed in a way so as not to disturb the compression efficiency. Finding an optimal solution that combines the three techniques while fulfilling these requirements is a challenging problem. This paper thus, proposes a wavelet domain based joint watermarking and encryption framework that employs singular value decomposition based watermark embedding and sign bit encryption prior to compression. The varying significance of different subbands has been considered to encrypt the data without adversely effecting the compression ratio. Experimental analysis using various evaluation parameters and attack scenarios has revealed the ability of the proposed framework to prove content-ownership, even from the encrypted data. Comparative analysis with the existing techniques reflect its ability to provide better security with less computational resources. This makes it a preferable solution for data security at all stages of data archival, transmission or distribution.
C1 [Taneja, Nidhi; Gupta, Indra] Indian Inst Technol, Dept Elect Engn, Roorkee 247667, Uttar Pradesh, India.
   [Bhatnagar, Gaurav] Univ Windsor, Dept Elect & Comp Engn, Windsor, ON N9B 3P4, Canada.
   [Raman, Balasubramanian] Indian Inst Technol, Dept Math, Roorkee 247667, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; University of Windsor; Indian Institute of
   Technology System (IIT System); Indian Institute of Technology (IIT) -
   Roorkee
RP Taneja, N (corresponding author), Indian Inst Technol, Dept Elect Engn, Roorkee 247667, Uttar Pradesh, India.
EM nidhi.iitr@gmail.com; goravdma@iitr.ernet.in; balarfma@iitr.ernet.in;
   indrafee@iitr.ernet.in
RI Bhatnagar, Gaurav/O-5817-2019
OI Bhatnagar, Gaurav/0000-0002-0282-3372
CR [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   Boato G, 2008, ELECTRON LETT, V44, P601, DOI 10.1049/el:20080492
   Chang FC, 2007, J VLSI SIG PROC SYST, V49, P443, DOI 10.1007/s11265-007-0095-0
   *COMM INT PROP RIG, 2000, DIG DIL INT PROP INF
   Dewilde P., 1988, SVD SIGNAL PROCESSIN, P3
   Eskicioglu AM, 2003, MULTIMEDIA SYST, V9, P239, DOI 10.1007/s00530-003-0095-2
   Eskicioglu AM, 2003, COMPUTER, V36, P39, DOI 10.1109/MC.2003.1212689
   Huang HC, 2009, SOFT COMPUT, V13, P383, DOI 10.1007/s00500-008-0326-8
   Kundur D, 2004, IEEE T MULTIMEDIA, V6, P185, DOI 10.1109/TMM.2003.819747
   Lian SG, 2007, IEEE T CIRC SYST VID, V17, P774, DOI 10.1109/TCSVT.2007.896635
   Lian SG, 2009, MULTIMED TOOLS APPL, V43, P91, DOI 10.1007/s11042-008-0258-4
   Lian SG, 2006, OPT ENG, V45, DOI 10.1117/1.2333510
   Liu JL, 2006, PATTERN RECOGN, V39, P1509, DOI 10.1016/j.patcog.2006.02.013
   Mao YN, 2006, IEEE T IMAGE PROCESS, V15, P2061, DOI 10.1109/TIP.2006.873426
   Peterson G, 1997, ARNOLDS CAT MAP
   Pommer A, 2003, MULTIMEDIA SYST, V9, P279, DOI 10.1007/s00530-003-0099-y
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Schneier B., 1995, APPL CRYPTOGRAPHY 2
   Simitopoulos D, 2003, MULTIMEDIA SYST, V9, P217, DOI 10.1007/s00530-003-0093-4
   Su K, 2005, IEEE T MULTIMEDIA, V7, P43, DOI 10.1109/TMM.2004.840617
   WU TL, 1997, P INT C IM SCI SYST
NR 21
TC 7
Z9 7
U1 1
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2013
VL 67
IS 3
BP 593
EP 606
DI 10.1007/s11042-012-1037-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 209JD
UT WOS:000323750900004
DA 2024-07-18
ER

PT J
AU Zhang, YY
   Li, XZ
   Yang, JC
   Liu, YN
   Xiong, NX
   Vasilakos, AV
AF Zhang, Yiying
   Li, Xiangzhen
   Yang, Jucheng
   Liu, Yuanan
   Xiong, Naixue
   Vasilakos, Athanasios V.
TI A real-time dynamic key management for hierarchical wireless multimedia
   sensor network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real time key management; Rekey; Wireless sensor network; Security;
   Splay tree
AB With the recent fast growth in the electronics industry and potential customers, communication managements in interactive Wireless Multimedia Sensor Networks (WMSNs) are increasingly ubiquitous, such as retrieving images, audio streams, video streams, and scalar sensor data, etc. However, due to restricted resources and operation in a hostile environment, WMSNs are usually subjected to numerous threats and vulnerable to various attacks. In this paper, we present a Real-time Dynamic Key Management (RDKM), a splay tree-based rekey management, which can efficiently enhance the network security and survivability in the LEACH-like protocol. Compared to other LEACH-like security solutions, our work offers some salient advantages. First, it establishes a real-time rekey mechanism based on the access-triggered splay tree architecture. In the mechanism, the keys will be changed during messages exchanging phase. To the best of our knowledge, RDKM is the first real-time key management for security in WMSNs. Second, it designs and realizes the rekey mechanism based on the splay tree, which can provide dynamic architecture to generate new keys and make the dynamic key management feasible without any overhead. The novel mechanism can efficiently protect the network against attacks from eavesdropping or captured nodes compromise and address challenging security issues of runtime in WMSNs. Experimental analysis shows that our solution has high security levels as well as good performance.
C1 [Zhang, Yiying] Beijing Univ Posts & Telecommun, Beijing 100088, Peoples R China.
   [Liu, Yuanan] Beijing Univ Posts & Telecommun, Wireless Commun Ctr, Beijing 100088, Peoples R China.
   [Zhang, Yiying; Li, Xiangzhen] State Grid Informat & Telecommun Co Ltd, Beijing, Peoples R China.
   [Yang, Jucheng] Tianjin Univ Sci & Technol, Inst Comp Sci & Informat Engn, Tianjin, Peoples R China.
   [Xiong, Naixue] Georgia State Univ, Dept Comp Sci, Atlanta, GA 30303 USA.
   [Vasilakos, Athanasios V.] Univ Western, Dept Comp & Telecommun Engn, Macedonia, Greece.
C3 Beijing University of Posts & Telecommunications; Beijing University of
   Posts & Telecommunications; State Grid Corporation of China; Tianjin
   University Science & Technology; University System of Georgia; Georgia
   State University
RP Zhang, YY (corresponding author), Beijing Univ Posts & Telecommun, Beijing 100088, Peoples R China.
EM zhangyiying1973@hotmail.com; xzli@sgcc.com.cn; yangjucheng@hotmail.com;
   yuliu@bupt.edu.cn; nxiong@cs.gsu.edu; vasilako@ath.forthnet.gr
RI xiong, naixue/M-4277-2019; vasilakos, athanasios/J-2824-2017; Li,
   Xiangzhen/AAN-8359-2020; Chen, John/GPW-8839-2022; Liu,
   Youning/JTS-8003-2023
OI xiong, naixue/0000-0002-0394-4635; Vasilakos,
   Athanasios/0000-0003-1902-9877
FU Doctoral Start-up Fund of Liaoling Province, Liaoning, China [20101074];
   Important National Science & Technology Specific Projects of China
   [2010ZX03006-005-02]; National Basic Research Program of China (973
   Program) [2011CB302900]
FX This research work was supported by Doctoral Start-up Fund of Liaoling
   Province (20101074), Liaoning, China. This work was also supported by
   the foundation: Important National Science & Technology Specific
   Projects of China: Research, development, and application validation of
   sensor network for smart grid security monitoring, transmission
   efficiency, measurement and user interaction (2010ZX03006-005-02); the
   National Basic Research Program of China (973 Program): Basic theory and
   practice research of Internet of Things (2011CB302900).
CR Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   [Anonymous], 2007, P 6 INT C INF PROC S
   Bandyopadhyay S, 2003, P IEEE INFOCOM 03 SA
   Chan H., 2003, P IEEE S SEC PRIV MA
   Chen Jong-Shin, 2010, Journal Of Networks, V5
   Chen M, 2010, J SUPERCOMPUT
   Chen M, 2007, COMPUT COMMUN, V30, P3368, DOI 10.1016/j.comcom.2007.01.016
   Chen M, 2011, MOBILE NETW APPL, V16, P171, DOI 10.1007/s11036-010-0260-8
   Chen M, 2011, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2011-159
   Chen M, 2011, IEEE T VEH TECHNOL, V60, P3290, DOI 10.1109/TVT.2011.2134116
   Chen M, 2009, IEEE T VEH TECHNOL, V58, P4976, DOI 10.1109/TVT.2009.2025767
   Chen M, 2009, MOBILE NETW APPL, V14, P220, DOI 10.1007/s11036-008-0133-6
   Deng J, 2005, First International Conference on Security and Privacy for Emerging Areas in Communications Networks, Proceedings, P289, DOI 10.1109/SECURECOMM.2005.6
   Eltoweissy M, 2006, IEEE COMMUN MAG, V44, P122, DOI 10.1109/MCOM.2006.1632659
   Grieco Luigi Alfredo, 2009, Proceedings of the 2009 Third International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies (UBICOMM 2009), P194, DOI 10.1109/UBICOMM.2009.27
   Jiang YX, 2006, SECURITY SENSOR NETW, P113
   Jolly G, 2003, IEEE SYMP COMP COMMU, P335, DOI 10.1109/ISCC.2003.1214142
   Kong Fan-Rui, 2010, Journal of Software, V21, P1679, DOI 10.3724/SP.J.1001.2010.03585
   Kuo C.J., 2006, ADV INF NETW APPL AI, P18
   Lai R, 2011, IEEE MMTC LETT, V6
   Manjeshwar A., 2001, P 1 INT WORKSHOP PAR, P2009, DOI DOI 10.1109/IPDPS.2001.925197
   Min Chen, 2008, International Journal of Sensor Networks, V4, P104, DOI 10.1504/IJSNET.2008.019256
   OLIVEIRA LB, 2006, 5 IEEE INT S NETW CO
   Shu L, 2010, IEEE COMSOC MMTC SEP
   Tang W, 2011, SENSORS-BASEL, V11, P6743, DOI 10.3390/s110706743
   Xiong NX, 2009, IEEE J SEL AREA COMM, V27, P495, DOI 10.1109/JSAC.2009.090512
   YU Z, 2008, IEEE T PARALLEL DIST, V19
   Zhang YY, 2010, IET INFORM SECUR, V4, P361, DOI 10.1049/iet-ifs.2009.0192
   Zhang YC, 2006, IEEE J SEL AREA COMM, V24, P247, DOI 10.1109/JSAC.2005.861382
   Zhang YY, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P298, DOI 10.1109/IIH-MSP.2008.138
   Zhang YY, 2011, 2011 INT C EN SYST E
   Zhu SC, 2006, ACM T SENSOR NETWORK, V2
NR 32
TC 16
Z9 16
U1 0
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 1
BP 97
EP 117
DI 10.1007/s11042-012-1054-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 196PN
UT WOS:000322787800006
DA 2024-07-18
ER

PT J
AU Liu, YJ
   Zhang, XD
   Li, ZM
   Li, H
AF Liu, YuJie
   Zhang, XiaoDong
   Li, ZongMin
   Li, Hua
TI Extended cone-curvature based salient points detection and 3D model
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model retrieval; Extended cone-curvature; Salient points; Earth
   mover's distance
ID SEARCH
AB Local feature extraction of 3D model has become a more and more important aspect in terms of 3D model shape feature extraction. Compared with the global feature, it is more suitable to do the partial retrieval and more robust to the model deformation. In this paper, a local feature called extended cone-curvature feature is proposed to describe the local shape feature of 3D model mesh. Based on the extended cone-curvature feature, salient points and salient regions are extracted by using a new salient point detection method. Then extended cone-curvature feature and local shape distribution feature calculated on the salient regions are used together as shape index, and the earth mover's distance is employed to accomplish similarity measure. After many times' retrieval experiments, the new extended cone-curvature descriptor we propose has more efficient and effective performance than shape distribution descriptor and light field descriptor especially on deformable model retrieval.
C1 [Liu, YuJie; Li, ZongMin] China Univ Petr, Sch Comp Sci & Commun Engn, Qingdao 266555, Peoples R China.
   [Zhang, XiaoDong] Shenzhen Inst Adv Integrat Technol, Ctr Human Comp Interact, Qingdao 266555, Peoples R China.
   [Li, Hua] Chinese Acad Sci, Inst Comp Technol, Natl Res Ctr Intelligent Comp Syst, Beijing 100190, Peoples R China.
C3 China University of Petroleum; Chinese Academy of Sciences; Shenzhen
   Institute of Advanced Technology, CAS; Chinese Academy of Sciences;
   Institute of Computing Technology, CAS
RP Liu, YJ (corresponding author), China Univ Petr, Sch Comp Sci & Commun Engn, Qingdao 266555, Peoples R China.
EM bilin_2008@163.com
FU National Natural Science Foundation of China [60873164]; National
   High-Tech RD Plan [2009AA062802]; Shandong Provincial Natural Science
   Foundation [ZR2009GL014]; Scientific Research Foundation for the
   Excellent Middle-Aged and Youth Scientists of Shandong Province of China
   [BS2010DX037]; Ministry of Culture Science and Technology Innovation
   Project [46-2010]; Fundamental Research Funds for the Central
   Universities [09CX04044A, 10CX04043A, 10CX04014B, 11CX04053A,
   11CX06086A, 12CX06083A, 12CX06086A]
FX This work is partly supported by National Natural Science Foundation of
   China (Grant No.60873164),National High-Tech R&D Plan (Grant No.
   2009AA062802), the Shandong Provincial Natural Science Foundation(Grant
   No.ZR2009GL014),the Scientific Research Foundation for the Excellent
   Middle-Aged and Youth Scientists of Shandong Province of China (Grant
   No.BS2010DX037), Ministry of Culture Science and Technology Innovation
   Project(Grant No. 46-2010),the Fundamental Research Funds for the
   Central Universities(Grant No. 09CX04044A, 10CX04043A, 10CX04014B,
   11CX04053A, 11CX06086A, 12CX06083A, 12CX06086A).
CR Adán A, 2004, IEEE T PATTERN ANAL, V26, P1507, DOI 10.1109/TPAMI.2004.94
   Adán A, 2008, LECT NOTES COMPUT SC, V5342, P644, DOI 10.1007/978-3-540-89689-0_68
   Amenta N., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P415, DOI 10.1145/280814.280947
   Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207
   [Anonymous], EUR WORKSH 3D OBJ RE
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073
   Kuo CT, 2007, PATTERN RECOGN, V40, P742, DOI 10.1016/j.patcog.2006.06.006
   Liu Y., 2006, Computer Vision and Pattern Recognition, P2025, DOI DOI 10.1109/CVPR.2006.278
   Ohbuchi R., 2003, P 5 ACM SIGMM INT WO, P39, DOI DOI 10.1145/973264.973272
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   PAQUET E, 1997, P INT C REC ADV 3 D
   Rubner Y., 1998, P 6 INT C COMP VIS I
   Shilane P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1243980.1243981
   Shilane P, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P108
   Tam GKL, 2007, IEEE T VIS COMPUT GR, V13, P470, DOI 10.1109/TVCG.2007.1011
NR 18
TC 4
Z9 6
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2013
VL 64
IS 3
BP 671
EP 693
DI 10.1007/s11042-011-0950-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126IV
UT WOS:000317608600008
DA 2024-07-18
ER

PT J
AU Hogenboom, A
   Hogenboom, F
   Frasincar, F
   Schouten, K
   van der Meer, O
AF Hogenboom, Alexander
   Hogenboom, Frederik
   Frasincar, Flavius
   Schouten, Kim
   van der Meer, Otto
TI Semantics-based information extraction for detecting economic events
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event detection; Semantics; Natural language processing; Information
   extraction
AB As today's financial markets are sensitive to breaking news on economic events, accurate and timely automatic identification of events in news items is crucial. Unstructured news items originating from many heterogeneous sources have to be mined in order to extract knowledge useful for guiding decision making processes. Hence, we propose the Semantics-Based Pipeline for Economic Event Detection (SPEED), focusing on extracting financial events from news articles and annotating these with meta-data at a speed that enables real-time use. In our implementation, we use some components of an existing framework as well as new components, e.g., a high-performance Ontology Gazetteer, a Word Group Look-Up component, a Word Sense Disambiguator, and components for detecting economic events. Through their interaction with a domain-specific ontology, our novel, semantically enabled components constitute a feedback loop which fosters future reuse of acquired knowledge in the event detection process.
C1 [Hogenboom, Alexander; Hogenboom, Frederik; Frasincar, Flavius; Schouten, Kim; van der Meer, Otto] Erasmus Univ, Inst Econometr, NL-3000 DR Rotterdam, Netherlands.
C3 Erasmus University Rotterdam; Erasmus University Rotterdam - Excl
   Erasmus MC
RP Hogenboom, F (corresponding author), Erasmus Univ, Inst Econometr, POB 1738, NL-3000 DR Rotterdam, Netherlands.
EM hogenboom@ese.eur.nl; fhogenboom@ese.eur.nl; frasincar@ese.eur.nl;
   288054ks@student.eur.nl; 276933rm@student.eur.nl
RI Frasincar, Flavius/D-3171-2011; Frasincar, Flavius/AAC-8253-2021
OI Frasincar, Flavius/0000-0002-8031-758X; Hogenboom,
   Alexander/0000-0002-2250-5507
FU NWO [612.001.009]; Dutch national program COMMIT
FX The authors are partially sponsored by the NWO Physical Sciences Free
   Competition project 612.001.009: Financial Events Recognition in News
   for Algorithmic Trading (FERNAT) and the Dutch national program COMMIT.
CR Allen F, 1999, J FINANC ECON, V51, P245, DOI 10.1016/S0304-405X(98)00052-X
   [Anonymous], 1998, Computational Linguistics
   [Anonymous], 1994, P WORKSHOP HUMAN LAN, DOI DOI 10.3115/1075812.1075866
   [Anonymous], 2000, CS0010 U SHEFF DEP C
   Bechhofer Sean, 2004, OWL Web Ontology Language Reference
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Black WJ, 2005, TRU431 UMIST DEP COM
   Borsje Jethro, 2010, International Journal of Web Engineering and Technology, V6, P115, DOI 10.1504/IJWET.2010.038242
   Borsje J, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P2415
   BROCK W, 1992, J FINANC, V47, P1731, DOI 10.2307/2328994
   Cunningham H, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P168
   Cunningham H, 2002, COMPUT HUMANITIES, V36, P223, DOI 10.1023/A:1014348124664
   Decadt B., 2004, Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, P108
   Dijkstra E. W., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   Finin T., 2006, P 21 NATL C ARTIFICI
   Guarino N, 2002, COMMUN ACM, V45, P61, DOI 10.1145/503124.503150
   Hellstrom T, 1999, P 6 INT C COMP FIN C, P343
   Hogenboom F, 2010, LECT NOTES COMPUT SC, V6412, P452, DOI 10.1007/978-3-642-16373-9_34
   Hollander M, 2000, J AM STAT ASSOC, V95, P333
   HP Labs, 2009, JEN SEM WEB FRAM JAV
   Jiang J, 1997, INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, 1997 DIGEST OF TECHNICAL PAPERS, P94
   Kearns M, 2003, IEEE INTELL SYST, V18, P22, DOI 10.1109/MIS.2003.1249166
   Kim J.-D., 2002, Workshop on Semantic Authoring, Annotation Knowledge Markup (SAAKM 2002), P1
   Leslie J., 1986, J R STAT SOC A, V149, P275
   Lin D, 1998, P 15 INT C MACH LEAR, V98, P296
   Lösch U, 2009, LECT NOTES COMPUT SC, V5554, P278, DOI 10.1007/978-3-642-02121-3_23
   Maguitman AnaGabriela., 2005, PROC 14 INT C WORLD, P107
   Mihalcea R., 2005, Proceedings of the ACL 2005 on Interactive poster and demonstration sessions - ACL '05, P53
   MIKROYANNIDIS A, 2005, P TEXT MIN RES PRACT, P23
   Navigli R, 2005, IEEE T PATTERN ANAL, V27, P1075, DOI 10.1109/TPAMI.2005.149
   Navigli R, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459355
   Nirenburg S., 2001, Formal Ontology in Information Systems. Collected Papers from the Second International Conference, P151, DOI 10.1145/505168.505183
   Nirenburg S, 2008, RES COMPUTATIONAL SE, V1, P179
   Popov B., 2004, Natural Language Engineering, V10, P375, DOI 10.1017/S135132490400347X
   PRIM RC, 1957, AT&T TECH J, V36, P1389, DOI 10.1002/j.1538-7305.1957.tb01515.x
   Resnik P, 1995, INT JOINT CONF ARTIF, P448
   Rinaldi F., 2003, P K CAP2003 WORKSH K, P33
   Rinaldi F., 2004, P 2 EUROPEAN WORKSHO, P61
   Schouten Kim, 2010, P 2010 ACM S APPL CO, P854, DOI [10.1145/1774088.1774264, DOI 10.1145/1774088.1774264]
   Taddesse FG, 2009, WORLD WID WEB INT WE, V13, P169
   Theobald M., 2003, PROC WEBDB, P1
   Vargas-Vera M, 2004, IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2004), PROCEEDINGS, P615, DOI 10.1109/WI.2004.10148
   Winer D., 2003, RSS 2 0 SPECIFICATIO
   Yuret D, 2004, P 3 ACL SIGLEX INT W, P265
NR 44
TC 35
Z9 39
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 1
BP 27
EP 52
DI 10.1007/s11042-012-1122-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 114SU
UT WOS:000316763600003
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Hong, KS
   Lee, C
AF Hong, Ki-sung
   Lee, Chulung
TI Integrated pricing and capacity decision for a telecommunication service
   provider
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Price and time sensitive market; Time-based competition; Guaranteed
   service time; Pricing; Capacity decision; Lateness penalty
ID DELIVERY-TIME; INVENTORY; COMPETITION
AB This paper studies a price and capacity decision for a telecommunications service provider that differentiates its products based on price and quality of service to maximize revenue. We assume the market is segmented into two customer classes. Time sensitive customers are willing to pay a price premium for a shorter service time, while price sensitive customers are willing to accept a longer service time in return for a lower price. The service provider offers products and services that differ only in their guaranteed service times and prices. We first develop a mathematical model to determine the optimal product price and optimal capacity necessary for maximizing total profit. We then consider a case where a service provider can marginally increase or decrease the capacity, and compute the optimal price and optimal capacity.
C1 [Hong, Ki-sung] Korea Univ, Grad Sch Informat Management & Secur, Seoul 136713, South Korea.
   [Lee, Chulung] Korea Univ, Div Ind Management Engn, Seoul 136713, South Korea.
   [Lee, Chulung] Korea Univ, Grad Sch Management Technol, Seoul 136713, South Korea.
C3 Korea University; Korea University; Korea University
RP Lee, C (corresponding author), Korea Univ, Div Ind Management Engn, Anamdong 5 Ga, Seoul 136713, South Korea.
EM justlikewind@korea.ac.kr; leecu@korea.ac.kr
RI Lee, Chulung/O-6205-2018
OI Lee, Chulung/0000-0002-2041-0221
FU National Research Foundation of Korea(NRF); Ministry of Education,
   Science and Technology [2009-0068528]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Education, Science and Technology (2009-0068528)
CR Allon G., 2008, WORKING PAPER
   Blackburn J.D., 1991, Time-Based Competition
   Boyaci T., 2003, Manufacturing & Service Operations Management, V5, P18, DOI 10.1287/msom.5.1.18.12757
   Boyaci T, 2006, PROD OPER MANAG, V15, P179, DOI 10.1111/j.1937-5956.2006.tb00239.x
   Chew EP, 2009, INT J PROD ECON, V120, P139, DOI 10.1016/j.ijpe.2008.07.018
   Hill A. V., 1992, Production and Operations Management, V1, P185, DOI 10.1111/j.1937-5956.1992.tb00351.x
   Hong K-S, 2011, INT J IND E IN PRESS
   Hopp W.J., 2000, Factory Physics
   Hum SH, 1996, INT J OPER PROD MAN, V16, P75, DOI 10.1108/01443579610106373
   KASPI M, 1991, INT J PROD RES, V29, P107, DOI 10.1080/00207549108930051
   Kryvinska Natalia, 2010, International Journal of Information Technology, Communications and Convergence, V1, P77, DOI 10.1504/IJITCC.2010.035228
   LI L, 1992, MANAGE SCI, V38, P182, DOI 10.1287/mnsc.38.2.182
   Mirceva G, 2010, J CONVERGENCE, V1, P57
   Palaka KS, 1998, IIE T, V30, P51
   Pekgun P., 2006, WORKING PAPER
   Prahmkaew S, 2010, J CONVERGENCE, V1, P101
   Rahman Mohammad Ziaur, 2010, International Journal of Information Technology, Communications and Convergence, V1, P108, DOI 10.1504/IJITCC.2010.035230
   Ray S, 2004, EUR J OPER RES, V153, P769, DOI 10.1016/S0377-2217(02)00655-0
   So K. C., 2000, Manufacturing & Service Operations Management, V2, P392, DOI 10.1287/msom.2.4.392.12336
   So KC, 1998, EUR J OPER RES, V111, P28, DOI 10.1016/S0377-2217(97)00314-7
   Stalk G., 1990, COMPETING TIME
   Suri S., 1998, PROBL SESS 14 ACM S
   Tsay A. A., 2000, Manufacturing & Service Operations Management, V2, P372, DOI 10.1287/msom.2.4.372.12342
   Urban TL, 2009, EUR J OPER RES, V196, P959, DOI 10.1016/j.ejor.2008.04.030
   VANBEEK P, 1987, EUR J OPER RES, V31, P52, DOI 10.1016/0377-2217(87)90136-6
NR 25
TC 4
Z9 4
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 2
BP 389
EP 406
DI 10.1007/s11042-012-1030-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 116IM
UT WOS:000316876200010
DA 2024-07-18
ER

PT J
AU Lee, KD
   Nam, MY
   Chung, KY
   Lee, YH
   Kang, UG
AF Lee, Kang-Dae
   Nam, Mi Young
   Chung, Kyung-Yong
   Lee, Young-Ho
   Kang, Un-Gu
TI Context and profile based cascade classifier for efficient people
   detection and safety care system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Context-awareness; Feature selection; Human detection; Tracking
ID TRACKING
AB This study propose a system of extracting and tracking objects for a multimedia system and addresses how to extract the head feature from an object area. It is observed in images taken from real-time records like a video, there is always a variance in human behavior, such as the position, size, etc. of the person being tracked or recorded. This study discusses how to extract and track multiple objects based on context as opposed to a single object. Via cascade extraction, the proposed system allows tracking of more than one human at a time. For this process, an extraction method based on internal and external contexts, which defines features to distinguish a human, is proposed. The proposed method defines shapes of shoulder and head area to recognize the head-shape of a human, and creates an extractor according to its edge information and geometrical shapes context. In this paper, humans in images are extracted and recognized using contexts and profiles. The proposed method is compared with a single face detector system and it shows better performance in terms of precision and speed. This trace information can be applied in safety care system. Extractions can be improved by validating the image using a context based detector when there are duplicated images.
C1 [Lee, Kang-Dae] Yonsei Univ, Dept Packaging, Wonju, South Korea.
   [Nam, Mi Young] YM Naeultech, Multimodal & Human Interact Lab, Inchon, South Korea.
   [Chung, Kyung-Yong] Sangji Univ, Dept Comp Informat Engn, Wonju, South Korea.
   [Lee, Young-Ho; Kang, Un-Gu] Gachon Univ, Dept Comp Sci, Inchon, South Korea.
   [Lee, Young-Ho; Kang, Un-Gu] Gachon Univ, Sch Comp Informat Engn, Inchon, South Korea.
C3 Yonsei University; Sangji University; Gachon University; Gachon
   University
RP Nam, MY (corresponding author), YM Naeultech, Multimodal & Human Interact Lab, Inchon, South Korea.
EM pimeson@yonsei.ac.kr; nammiyoung@gmail.com; dragonhci@gmail.com;
   lyh@gachon.ac.kr; ugkang@gachon.ac.kr
RI Chung, Kyungyong/JAC-2276-2023
CR [Anonymous], 2005, P IEEE COMP SOC C CO
   [Anonymous], 2006, COMPUTER VISION PATT, DOI 10.1109/CVPR.2006.92
   Brostow G.J., 2006, CVPR, P594, DOI DOI 10.1109/CVPR.2006.320
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Edwards GJ, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P300, DOI 10.1109/AFGR.1998.670965
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   Fieguth P, 1997, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.1997.609292
   Huazhong Xu, 2010, 2010 International Conference on Computer Design and Applications (ICCDA 2010), P394, DOI 10.1109/ICCDA.2010.5540833
   Jia HX, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P683, DOI 10.1109/ICIG.2007.53
   Li M, 2009, IEEE IMAGE PROC, P2545, DOI 10.1109/ICIP.2009.5414008
   Liu CJ, 2003, IEEE T PATTERN ANAL, V25, P725, DOI 10.1109/TPAMI.2003.1201822
   Nam MY, 2006, LECT NOTES CONTR INF, V345, P201
   Nam MY, 2005, LECT NOTES ARTIF INT, V3682, P327
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Ramanan D, 2007, IEEE T PATTERN ANAL, V29, P65, DOI 10.1109/TPAMI.2007.250600
   Sangmin Oh, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3579, DOI 10.1109/ICPR.2010.873
   Sigal L, 2006, MEASURE LOCALLY REAS
   Sminchisescu C, 2007, IEEE T PATTERN ANAL, V29, P2030, DOI 10.1109/TPAMI.2007.1111
   Teknomo K, 2009, P E ASIA SOC TRANSP, V7
   Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
NR 22
TC 34
Z9 35
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 1
BP 27
EP 44
DI 10.1007/s11042-012-1020-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105KY
UT WOS:000316069400003
DA 2024-07-18
ER

EF