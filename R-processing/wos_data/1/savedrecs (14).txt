FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Maronidis, A
   Voutounos, C
   Lanitis, A
AF Maronidis, A.
   Voutounos, C.
   Lanitis, A.
TI Designing and evaluating an expert system for restoring damaged
   byzantine icons
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Damage detection; Shape restoration; Texture restoration; Expert system;
   Icon restoration; Statistical appearance models
ID VIRTUAL RESTORATION; FACE RECOGNITION; REMOVAL; IMAGES
AB The use of image processing techniques in cultural heritage applications has been gaining increasing interest in the research community. In this paper, an integrated framework that can be used for virtual restoration of the facial region of damaged Byzantine icons is presented. A key aspect of the proposed methodology is the integration of practices adopted by expert icon restorers into a machine-based expert system that incorporates the modules of damage detection, shape and texture restoration. Damage detection is performed based on a residual-based approach, while the shape restoration method utilizes a 3D shape model generated by incorporating a set of geometrical rules defined by expert Byzantine style iconographers. Texture restoration is based on the recursive Principal Component Analysis (PCA) technique so that combinations of colors learned from a training set are applied to the damaged icon regions. All modules, developed as part of this framework, are incorporated into a user-friendly application that can be used by amateurs or professional Byzantine icon restorers and conservators. The potential of the developed tool has been validated through a quantitative experimental process and a user-based evaluation.
C1 [Maronidis, A.; Voutounos, C.; Lanitis, A.] Cyprus Univ Technol, Dept Multimedia & Graph Arts, Visual Media Comp Lab, CY-3603 Lemesos, Cyprus.
C3 Cyprus University of Technology
RP Maronidis, A (corresponding author), Cyprus Univ Technol, Dept Multimedia & Graph Arts, Visual Media Comp Lab, 31 Archbishop Kyprianos St,POB 50329, CY-3603 Lemesos, Cyprus.
EM anastasios.maronidis@cut.ac.cy; c.voutounos@cut.ac.cy;
   andreas.lanitis@cut.ac.cy
RI Lanitis, Andreas/AGB-4263-2022
OI Lanitis, Andreas/0000-0001-6841-8065
FU Cyprus Research Promotion Foundation; European Union Structural Funds
   [THE/HAHPO/0609(BIE)/05]
FX This work was supported by the Cyprus Research Promotion Foundation and
   the European Union Structural Funds (project THE/HAHPO/0609(BIE)/05). We
   would also like to thank the iconographers Dr. D. Demosthenous and Mr.
   C. Karis and the 3D modeler Mr. A. El Kater for their contribution.
CR Anagnostopoulos CN, 2007, FRONT ARTIF INTEL AP, V160, P351
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2006, 2006 IEEE COMP SOC C
   Barni M, 2000, IEEE MULTIMEDIA, V7, P34, DOI 10.1109/93.848424
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Bruni V, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/986183
   Clapham C, 2009, CONCISE OXFORD DICT
   Colombo A, 2011, J MATH IMAGING VIS, V40, P105, DOI 10.1007/s10851-010-0252-0
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Del Mastio A, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P471, DOI 10.1109/ICDSP.2007.4288621
   Drago F, 2005, INT J IMAGE GRAPH, V5, P617, DOI 10.1142/S0219467805001914
   Edwards GJ, 1998, IMAGE VISION COMPUT, V16, P203, DOI 10.1016/S0262-8856(97)00069-3
   Falcao G., 2008, PLANE BASED CALIBRAT
   Giakoumis I, 2006, IEEE T IMAGE PROCESS, V15, P178, DOI 10.1109/TIP.2005.860311
   Hays J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239455
   Hwang BW, 2003, IEEE T PATTERN ANAL, V25, P365, DOI 10.1109/TPAMI.2003.1182099
   Jayne C, 2012, EXPERT SYST APPL, V39, P9778, DOI 10.1016/j.eswa.2012.02.177
   Kammerer P, 2000, CZECH PATT REC WORKS, P2
   Kim G, 2010, I C CONT AUTOMAT ROB, P627, DOI 10.1109/ICARCV.2010.5707762
   Kumar G. S., 2012, INT J COMPUTER APPL, V41, P11
   Landon GV, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/217016
   Lanitis A., 2004, P ACM S APPL COMP, V1, P5
   Lanitis A, 2008, 14 INT C VIRT SYST M
   Lanitis A, 2012, J CULT HERIT, V13, P404, DOI 10.1016/j.culher.2012.01.001
   Lanitis A, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/239480
   Maronidis A, 2013, P 4 INT C INF INT SY
   Maronidis A., 2012, LNCS, V7616, P320
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   Papantoniou G., 2012, LNCS, V7616, P543
   Park JS, 2003, LECT NOTES COMPUT SC, V2688, P369
   Raftopoulos K, 2008, 14 INT C VIRT SYST M
   Sablatnig R, 1998, INT C PATT RECOG, P172, DOI 10.1109/ICPR.1998.711107
   Sikudová E, 2006, COMPUT IMAGING VIS, V32, P394, DOI 10.1007/1-4020-4179-9_57
   Spagnolo GS, 2010, J PHYS C SERIES, V249
   Venkat I, 2013, PATTERN RECOGN LETT, V34, P903, DOI 10.1016/j.patrec.2012.05.003
   Vranos IC, 2001, H TECHNIKI TIS AGIOG
   Wang Z.M., 2007, INT C COMP INT SEC W
   Wu CY, 2004, IEEE T PATTERN ANAL, V26, P322, DOI 10.1109/TPAMI.2004.1262319
   Yang M, 2010, LECT NOTES COMPUT SC, V6316, P448, DOI 10.1007/978-3-642-15567-3_33
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 40
TC 3
Z9 3
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9747
EP 9770
DI 10.1007/s11042-014-2149-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200032
DA 2024-07-18
ER

PT J
AU Eun, SJ
   Whangbo, TK
AF Eun, Sung-Jong
   Whangbo, Taeg-Keun
TI Efficient circular-shape object segmentation method for adjacent objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object recognition; Adjacent circular-shape objects; Local feature;
   Curve fitting
AB The general object recognition method is based on the various area segmentation algorithm. With these methods, segmentation is not very difficult if the boundaries between objects are clear, but if the boundaries are vague, the segmentation of the adjacent objects becomes inaccurate. So in order to solve this problem, we propose an efficient method of dividing adjacent circular-shape objects into single object. For segmentation into single object, the final segmentation object is determined in the following three steps: detection of the ROI, determination of the candidate segmentation points, and creation of a segmentation boundary. As a result, robust performance of average 6.2 % difference compared to the existing methods were derived in the experiments, even with severe SNR case.
C1 [Eun, Sung-Jong; Whangbo, Taeg-Keun] Gachon Univ, Dept Comp Sci, Songnam, Gyunggi Do, South Korea.
C3 Gachon University
RP Whangbo, TK (corresponding author), Gachon Univ, Dept Comp Sci, Songnam, Gyunggi Do, South Korea.
EM asclephios@hotmail.com; tkwhangbo@gachon.ac.kr
FU MSIP (the Ministry of Science, ICT and Future Planning), Korea under
   IT-CRSP(IT Convergence Research Support Program)
   [NIPA-2013-H0401-13-1001]
FX This research was supported by MSIP (the Ministry of Science, ICT and
   Future Planning), Korea, under the IT-CRSP(IT Convergence Research
   Support Program) (NIPA-2013-H0401-13-1001) supervised by the
   NIPA(National IT Industry Promotion Agency).
CR Catmull E, 1974, inCom-puter Aided Geometric Design, P317, DOI [DOI 10.1016/B978-0-12-079050-0.50020-5, 10.1016/B978-0-12-079050-0.50020-5]
   CHANDA B, 1988, SIGNAL PROCESS, V15, P149, DOI 10.1016/0165-1684(88)90067-9
   Comaniciu D, 1997, 7 INT C COMP VIS PAT, P750
   Kang CC, 2007, PATTERN RECOGN, V40, P609, DOI 10.1016/j.patcog.2006.03.016
   Kang DJ, 1999, PATTERN RECOGN LETT, V20, P1069, DOI 10.1016/S0167-8655(99)00127-0
   Kass M., 2004, INT J COMPUTER VISIO, V1, P321
   Li W, 2004, 5 WORLD C INT CONTR, P15
   Muerle J. L, 1968, EXPT EVALUATION TECH
   Murphy TM, 2003, I IEEE EMBS C NEUR E, P16, DOI 10.1109/CNE.2003.1196744
   NAJMAN L, 1994, SIGNAL PROCESS, V38, P99, DOI 10.1016/0165-1684(94)90059-0
   Ng EYK, 2006, J MECH MED BIOL, V6, P123, DOI 10.1142/S021951940600190X
   Norio B, ELECT MICROSE, V45, P298
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936
   Yan PK, 2008, IEEE T INF TECHNOL B, V12, P109, DOI 10.1109/TITB.2007.898006
   Zabih R, 2004, PROC CVPR IEEE, P437
NR 17
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 8951
EP 8959
DI 10.1007/s11042-013-1695-2
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600018
DA 2024-07-18
ER

PT J
AU Lee, Y
   Cho, J
AF Lee, Youngseok
   Cho, Jungwon
TI Personalized item generation method for adaptive testing systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personalized learning; Computerized adaptive test; Estimation of
   learners' level; Item response theory; Intelligent tutoring system
ID RESPONSE THEORY
AB An Intelligent Tutoring System (ITS) must provide suitable feedback to learners based on tests adapted to the learners' ability levels. An ITS selects the item and content based on what it knows about the learners from previous items. Previous research has focused on estimating a learner's ability accurately or providing adequate feedback based on an analysis of the learner's ability. However, it is often difficult to make customized learning continuously available in ITSs. In the present study, we used adaptive testing to estimate a learner's ability and to determine a number of learner characteristics to create a learner profile. This method selects items and creates a customized assessment sheet for adaptive testing that considers both the learner's level and characteristics. The proposed method assesses a learner's weak subject areas and item types by studying available information and analyzing individual abilities to guide learners as to which fields of study would be suitable and which courses they should take. We tested our customized learning module at an actual educational institution. The group that used our recommendation module learned more effectively than the control group (the mean test scores of the group that used the module were high and the deviations were low). Using the learner model, teachers will be able to analyze learners in detail, enabling customized learning that allows learners to study effectively without requiring a great effort to search for learning materials. Customized learning will increase interest in learning and understanding.
C1 [Lee, Youngseok] Hanyang Univ, Res Inst Elect & Comp Engn, Seoul 133791, South Korea.
   [Cho, Jungwon] Jeju Natl Univ, Dept Comp Educ, Jeju Do 690756, South Korea.
C3 Hanyang University; Jeju National University
RP Cho, J (corresponding author), Jeju Natl Univ, Dept Comp Educ, 102 Jejudaehakno, Jeju Do 690756, South Korea.
EM yslee38@hanyang.ac.kr; jwcho@jejunu.ac.kr
OI Lee, Youngseok/0000-0002-5335-3120; Cho, Jungwon/0000-0001-5746-9596
CR Barrera-Sanabria G, 2004, IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P973, DOI 10.1109/ICALT.2004.1357732
   Crocker L., 1986, INTRO CLASSICAL MODE
   Das BK, 2011, INT J MULTIMED UBIQU, V6, P43
   de la Chica S, 2006, P ECAI WORKSH LANG E
   Ebel R. L., 1991, Essentials of educational measurement
   Guzmán E, 2005, IEEE T EDUC, V48, P688, DOI 10.1109/TE.2005.854571
   Johns J, 2006, LECT NOTES COMPUT SC, V4053, P473
   Ju GFN, 2005, 5th IEEE International Conference on Advanced Learning Technologies, Proceedings, P822
   Lee Y, 2006, LECT NOTES COMPUT SC, V4053, P778
   Lee Y, 2010, LECT NOTES COMPUT SC, V6483, P381, DOI 10.1007/978-3-642-17407-0_40
   Murase T, 2006, LECT NOTES COMPUT SC, V4053, P695
   Ounaies HZ, 2012, INT J SOFTW ENG APPL, V6, P23
   Papanikolaou KA, 2003, 3RD IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P120, DOI 10.1109/ICALT.2003.1215039
   Sung J-S, 2009, INT J ADV SCI TECHNO, V9, P19
   WANG FH, 2006, P 6 INT C ADV LEARN, P237
   Wang TH, 2004, J COMPUT ASSIST LEAR, V20, P59, DOI 10.1111/j.1365-2729.2004.00066.x
NR 16
TC 5
Z9 6
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8571
EP 8591
DI 10.1007/s11042-013-1421-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600021
DA 2024-07-18
ER

PT J
AU Schaefer, G
   Tallyn, M
   Felton, D
   Plant, W
   Edmundson, D
AF Schaefer, Gerald
   Tallyn, Matthew
   Felton, Daniel
   Plant, William
   Edmundson, David
TI Interactive browsing of image collections on mobile devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image databases; Image database browsing; Mobile computing; Mobile image
   browsing
ID VISUALIZATION
AB Image collections are growing at a rapid rate and hence visual information is becoming more and more important. Clearly, these image repositories need to be managed, and tools for effectively and efficiently searching image databases are highly sought after, especially on mobile devices where more and more images are being stored. In this paper, we present an image browsing system for interactive exploration of image collections on mobile devices. Images are arranged so that visually similar images are grouped together while large image repositories become accessible through a hierarchical, browsable tree structure, arranged on a hexagonal lattice. The developed system provides an intuitive and fast interface for navigating through image databases using a variety of touch gestures.
C1 [Schaefer, Gerald; Tallyn, Matthew; Felton, Daniel; Edmundson, David] Univ Loughborough, Dept Comp Sci, Loughborough, Leics, England.
   [Plant, William] Aston Univ, Sch Engn & Appl Sci, Birmingham B4 7ET, W Midlands, England.
C3 Loughborough University; Aston University
RP Schaefer, G (corresponding author), Univ Loughborough, Dept Comp Sci, Loughborough, Leics, England.
EM gerald.schaefer@ieee.org
RI Felton, Daniel/HNR-9111-2023
CR Ahlstroem D., 2012, 20 ACM INT C MULT
   [Anonymous], 2008, ACM INT C MULT INF R
   Bärecke T, 2006, LECT NOTES COMPUT SC, V4071, P340
   Barthel Kai Uwe, 2005, WORKSH IMM COMM BROA
   Bartolini I, 2006, MULTIMED TOOLS APPL, V31, P269, DOI 10.1007/s11042-006-0044-0
   Chaomei Chen, 2000, 16th World Computer Congress 2000. Proceedings of Conference on Intelligent Information Processing, P206
   Chen JY, 2000, IEEE T IMAGE PROCESS, V9, P442, DOI 10.1109/83.826781
   Dontcheva M., 2005, 18 ANN ACM S US INT
   Eidenberger H, 2004, INT J FUZZY SYST, V6, P124
   Fan L, 2010, 17 IEEE INT C IM PRO
   Gomi A, 2008, IEEE INT CONF INF VI, P82, DOI 10.1109/IV.2008.8
   Heesch D, 2004, LECT NOTES COMPUT SC, V2997, P253
   Heesch D, 2008, MULTIMED TOOLS APPL, V40, P261, DOI 10.1007/s11042-008-0207-2
   Keller I, 2001, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P102, DOI 10.1109/IVL.2001.990863
   Krishnamachari S, 1999, IEEE SYMP COMP COMMU, P301, DOI 10.1109/ISCC.1999.780837
   Moghaddam B, 2004, INT J COMPUT VISION, V56, P109, DOI 10.1023/B:VISI.0000004834.62090.74
   Moving Picture Experts Group, 1999, JTC1SC29WG11N2929 IS
   Nguyen GP, 2008, J VISUAL LANG COMPUT, V19, P203, DOI 10.1016/j.jvlc.2006.09.002
   Plant William, 2009, Proceedings of the 2009 International Conference on Image Processing, Computer Vision, & Pattern Recognition. IPCV 2009, P248
   Plant W, 2009, IEEE INT WORKSH MULT, P1
   Plant W, 2011, STUD COMPUT INTELL, V346, P3
   Plant W, 2010, IEEE IMAGE PROC, P3161, DOI 10.1109/ICIP.2010.5648905
   Plant W, 2009, 2009 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION, P750, DOI 10.1109/SoCPaR.2009.152
   Rodden K., 2003, P SIGCHI C HUMAN FAC, P409, DOI DOI 10.1145/642611.642682
   RODDEN K, 2001, THESIS U CAMBRIDGE
   Rubner L. J., 1997, P ARPA IM UND WORKSH, P661
   SANGWINE J, 1998, COLOUR IMAGE PROCESS
   Schaefer G., 2012, VISUAL COMMUNICATION
   Schaefer G., 2012, 20 ACM INT C MULT
   Schaefer G, 2006, LECT NOTES COMPUT SC, V4174, P304
   Schaefer G, 2012, IEEE MEDITERR ELECT, P141, DOI 10.1109/MELCON.2012.6196399
   Schaefer G, 2010, MULTIMED TOOLS APPL, V47, P105, DOI 10.1007/s11042-009-0409-2
   Schoeffmann K, 2011, IEEE INT S MULT
   Sheridan P, 2000, IMAGE VISION COMPUT, V18, P907, DOI 10.1016/S0262-8856(00)00036-6
   Worring Marcel., 2007, International Workshop on Multimedia Information Retrieval, P307
NR 35
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8267
EP 8277
DI 10.1007/s11042-014-1875-8
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600002
DA 2024-07-18
ER

PT J
AU Lee, JS
   Wong, HS
   Chen, YR
   Wang, YH
AF Lee, Jung-San
   Wong, Hsiao-Shan
   Chen, You-Ren
   Wang, Yi-Hua
TI Stable watermarking technique based on XNOR operation and scale
   relationship
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mage watermarking; Discrete cosine transform (DCT); XNOR operation;
   Coordinate system
ID IMAGE; PERFORMANCE
AB Digital watermark technique is often used to solve these problems and protect the copyright of multimedia transferred over the Internet. Most watermark methods use pixel values or coefficients as the judgment condition to embed or extract a watermark image. The variation of these values may lead to the inaccurate condition such that an incorrect judgment has been laid out. To avoid this problem, we design a stable judgment mechanism, in which the outcome will not be seriously influenced by the variation. The principle of judgment depends on the scale relationship of two pixels. From the observation of common signal processing operations, we can find that the pixel value of processed image usually keeps stable unless an image has been manipulated by cropping attack or halftone transformation. In the watermark embedding process, we use the XNOR operation to record the outcome to form a secret key instead of modifying pixel values. This can greatly help reduce the modification strength from image processing operations. Experiment results show that the proposed method can resist various attacks and keep the image quality friendly.
C1 [Lee, Jung-San; Wong, Hsiao-Shan; Chen, You-Ren; Wang, Yi-Hua] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 407, Taiwan.
C3 Feng Chia University
RP Lee, JS (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 407, Taiwan.
EM leejs@fcu.edu.tw
CR Aslantas V, 2009, OPT COMMUN, V282, P2806, DOI 10.1016/j.optcom.2009.04.034
   Bao P, 2005, IEEE T CIRC SYST VID, V15, P96, DOI 10.1109/TCSVT.2004.836745
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Deng C, 2009, SIGNAL PROCESS, V89, P1531, DOI 10.1016/j.sigpro.2009.02.005
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P278, DOI 10.1109/TSMCC.2009.2037512
   Hernández JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598
   Jong Ryul Kim, 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P226, DOI 10.1109/ICIP.1999.822889
   Lai CC, 2011, OPT COMMUN, V284, P938, DOI 10.1016/j.optcom.2010.10.047
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Leng XX, 2012, COMM COM INF SC, V289, P484
   Lin SD, 2010, COMPUT STAND INTER, V32, P54, DOI 10.1016/j.csi.2009.06.004
   Lu W, 2009, COMPUT ELECTR ENG, V35, P183, DOI 10.1016/j.compeleceng.2008.09.004
   Nikolaidis A, 2012, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2012-97
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Run RS, 2011, EXPERT SYST APPL, V38, P14357, DOI 10.1016/j.eswa.2011.03.024
   Swanson MD, 1998, P IEEE, V86, P1064, DOI 10.1109/5.687830
   Wang XK, 2013, SIGNAL PROCESS, V93, P913, DOI 10.1016/j.sigpro.2012.11.003
NR 18
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 6797
EP 6826
DI 10.1007/s11042-014-1930-5
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800011
DA 2024-07-18
ER

PT J
AU Liu, C
   Ling, HF
   Zou, FH
   Wang, YF
   Feng, H
   Yan, LY
AF Liu, Cong
   Ling, Hefei
   Zou, Fuhao
   Wang, Yunfei
   Feng, Hui
   Yan, Lingyu
TI Local and global structure preserving hashing for fast digital
   fingerprint tracing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia security; Digital fingerprinting; Hash-Based similarity
   search; Neighborhood preserving hashing
AB Digital fingerprinting is a promising approach to protect multimedia contents from unauthorized redistribution. Whereas, large scale and high dimensionality make existing fingerprint detection methods fail to trace the traitors efficiently. To handle this problem, we propose a novel local and global structure preserving hashing to conduct fast fingerprint detection. This is the first work that introduces hash-based similarity search method to perform fingerprint detection. Applying the hashing method, we obtain a neighborhood-preserving low-dimensional representation (e. g. hash code) for each fingerprint. Through hash codes, we can find the nearest neighbors of the extracted fingerprint, thereby tracing the real traitors within a small range. Preserving the local structure facilitates to find the nearest neighbors of the query fingerprint efficiently, and preserving the global structure ensures hash codes of fingerprints as discriminative as possible. These properties make the proposed approach efficient to trace the real traitors. Extensive experiments demonstrate that the proposed approach outperforms traditional linear scan detection methods in term of efficiency.
C1 [Liu, Cong; Ling, Hefei; Zou, Fuhao; Wang, Yunfei; Yan, Lingyu] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
   [Feng, Hui] Wuhan Univ Technol, Sch Transportat, Minist Educ, Key Lab High Performance Ship Technol, Wuhan 430074, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology; Wuhan University of
   Technology
RP Ling, HF (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
EM liucongwust@gmail.com; lhefei@hust.edu.cn; fuhao_zou@hust.edu.cn;
   feiyunwangysm@gmail.com; Huifeng.email@gmail.com; yanranyaya@gmail.com
RI feng, hui/I-8659-2018
OI feng, hui/0000-0001-6696-3094
FU NSF of China [61272409]; Fundamental Research Funds for the Central
   Universities [WUT: 133102002]; Wuhan Youth Science and Technology
   Chenguang Program
FX This work is supported by the NSF of China under Grant No. 61272409, the
   Fundamental Research Funds for the Central Universities(WUT: 133102002)
   and Wuhan Youth Science and Technology Chenguang Program.
CR [Anonymous], 1996, 96045 NEC RES I
   Barg A, 2003, IEEE T INFORM THEORY, V49, P852, DOI 10.1109/TIT.2003.809570
   Boneh D, 1998, IEEE T INFORM THEORY, V44, P1897, DOI 10.1109/18.705568
   Cha BH, 2009, IEEE T INF FOREN SEC, V4, P302, DOI 10.1109/TIFS.2009.2025849
   Chen X., 2011, P 25 AAAI C ART INT, P313
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Dittmann J, 2000, J ELECTRON IMAGING, V9, P456, DOI 10.1117/1.1287729
   Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745
   Guttman A., 1984, SIGMOD Record, V14, P47, DOI 10.1145/971697.602266
   Hartigan J, 1979, J R STAT SOC C-APPL, V28, P100
   He S, 2006, IEEE T INF FOREN SEC, V1, P231, DOI 10.1109/TIFS.2006.873597
   Kulis B., 2009, Learning to hash with binary reconstructive embeddings
   Lin RS, 2010, PROC CVPR IEEE, P848, DOI 10.1109/CVPR.2010.5540129
   Lin Yue, 2012, P 26 AAAI C ART INT
   Ling HF, 2011, LECT NOTES COMPUT SC, V6526, P224, DOI 10.1007/978-3-642-18405-5_19
   Liu W, 2011, SER INF MANAGE SCI, V10, P1
   Mayur D, P 20 SCG, P253
   Poor H.V., 1999, INTRO SIGNAL DETECIO
   Sakai Tomoya, 2009, P 3 INT C MACH LEARN
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   Tô VT, 2002, LECT NOTES COMPUT SC, V2551, P149
   Wang ZJ, 2005, IEEE T IMAGE PROCESS, V14, P804, DOI 10.1109/TIP.2005.847284
   Wang ZJ, 2009, EUPASIP J APPL SIG P, V14
   Weiss Y., 2008, NIPS, V21, P1753
   Yan DH, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P907
   Zeng WJ, 1999, IEEE T IMAGE PROCESS, V8, P1534, DOI 10.1109/83.799882
   Zhang D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P18
   Zhao HV, 2005, IEEE T IMAGE PROCESS, V14, P646, DOI 10.1109/TIP.2005.846035
NR 28
TC 2
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 8003
EP 8023
DI 10.1007/s11042-014-2035-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200027
DA 2024-07-18
ER

PT J
AU Ryang, H
   Yun, U
   Pyun, G
   Lee, G
   Kim, J
AF Ryang, Heungmo
   Yun, Unil
   Pyun, Gwangbum
   Lee, Gangin
   Kim, Jiwon
TI Ranking algorithm for book reviews with user tendency and collective
   intelligence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Book review; Information retrieval; Ranking technique; Collective
   intelligent
ID FREQUENT PATTERNS; DATA STREAMS; RETRIEVAL
AB IR (Information Retrieval) systems search for important documents on the internet by measuring the importance of them. For this purpose, various ranking techniques were proposed. In this paper, we propose ReviewRank and ReviewRank(+), which are ranking techniques for estimating usefulness of book reviews based on the tendency of users. With an increasing number of people buying books online, reviews written by other people have become more significant. General ranking techniques measure the importance of documents based on references or quotations between them through hyperlinks. However, the techniques are not suitable for ranking book reviews since they were developed for general purposes. In this paper, we analyze the characteristics of meaningful book reviews based on voluntary evaluation of people and propose measures for considering the importance. We also suggest an algorithm for ranking reviews. Experimental results show that our approaches outperform both previous general and specific (searching book reviews) ranking techniques.
C1 [Ryang, Heungmo; Yun, Unil; Pyun, Gwangbum; Lee, Gangin; Kim, Jiwon] Sejong Univ, Dept Comp Engn, Seoul 143747, South Korea.
C3 Sejong University
RP Yun, U (corresponding author), Sejong Univ, Dept Comp Engn, 98 Gunja Dong, Seoul 143747, South Korea.
EM ryang@sju.ac.kr; yunei@sejong.ac.kr; gbpyun@sju.ac.kr;
   ganginlee@sju.ac.kr; jiwonkim@sju.ac.kr
FU National Research Foundation of Korea (NRF) - Ministry of Education,
   Science and Technology (NRF) [2013-005682, 2008-0062611]
FX This research was supported by the National Research Foundation of Korea
   (NRF) funded by the Ministry of Education, Science and Technology (NRF
   No. 2013-005682 and 2008-0062611).
CR Aboulmagd H, 2009, TELECOMMUN SYST, V40, P55, DOI 10.1007/s11235-008-9142-9
   Aizawa A, 2003, INFORM PROCESS MANAG, V39, P45, DOI 10.1016/S0306-4573(02)00021-3
   Alyguliev RM, 2007, AUTOM CONTROL COMPUT, V41, P44, DOI 10.3103/S0146411607010075
   [Anonymous], 1999, WWW 1999
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Chang Y, 2013, ACM TIST, V4
   Ciszkowski T, 2012, TELECOMMUN SYST, V51, P283, DOI 10.1007/s11235-011-9435-2
   Curran K, 2009, TELECOMMUN SYST, V40, P27, DOI 10.1007/s11235-008-9128-7
   Dou ZC, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P227, DOI 10.1145/1571941.1571982
   Duan Y, 2010, EMPIRICAL STUDY LEAR, P295
   Egghe L, 2009, RELATION PEARSONS CO
   Gayo-Avello Daniel., 2010, CORR
   Gupta P, 2013, J INF PROCESS SYST, V9, P217, DOI 10.3745/JIPS.2013.9.2.217
   Huang Jeff J. S., 2010, International Journal of Organizational and Collective Intelligence, V1, P83, DOI 10.4018/joci.2010040105
   Janik Maciej, 2011, Informatik Spektrum, V34, P469, DOI 10.1007/s00287-011-0535-x
   JARVELIN K, 2000, IR EVALUATION METHOD, P41
   Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140
   Król D, 2012, INFORM SCIENCES, V182, P1, DOI 10.1016/j.ins.2011.10.001
   Lee G, 2014, EXPERT SYST APPL, V41, P694, DOI 10.1016/j.eswa.2013.07.094
   Leimeister JM, 2010, BUS INFORM SYST ENG+, V2, P245, DOI 10.1007/s12599-010-0114-8
   Momma M., 2012, CORR
   Paik JH, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P343
   Pióro M, 2013, TELECOMMUN SYST, V52, P931, DOI 10.1007/s11235-011-9601-6
   Pyun G, 2014, KNOWL-BASED SYST, V55, P125, DOI 10.1016/j.knosys.2013.10.013
   Ryang H, 2012, LECT NOTE COMPUTER S, P550
   Ryang H, 2011, ICHIT, P360
   Ryang H, 2013, LECT NOTES ELECT ENG, P7
   Teevan J., 2011, TWITTERSEARCH COMP M, P35
   Tumer D, 2011, COLLECTIVE INTELLIGE
   WEERKAMP W, 2012, CREDIBILITY INSPIRED, V15, P243, DOI DOI 10.1007/S10791-011-9182-8
   Wu SL, 2012, EXPERT SYST APPL, V39, P1346, DOI 10.1016/j.eswa.2011.08.015
   Yun U, 2014, EXPERT SYST APPL, V41, P3861, DOI 10.1016/j.eswa.2013.11.038
   Yun U, 2014, KNOWL-BASED SYST, V55, P49, DOI 10.1016/j.knosys.2013.10.011
   Yun U, 2013, INTELL DATA ANAL, V17, P917, DOI 10.3233/IDA-130612
   Zhou L, 2013, TELECOMMUN SYST, V52, P1235, DOI 10.1007/s11235-011-9638-6
NR 35
TC 2
Z9 2
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6209
EP 6227
DI 10.1007/s11042-014-2101-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700006
DA 2024-07-18
ER

PT J
AU Malloch, J
   Sinclair, S
   Wanderley, MM
AF Malloch, Joseph
   Sinclair, Stephen
   Wanderley, Marcelo M.
TI Distributed tools for interactive design of heterogeneous signal
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Media mapping; Networking
AB We introduce libmapper, an open source, cross-platform software library for flexibly connecting disparate interactive media control systems at run-time. This library implements a minimal, openly-documented protocol meant to replace and improve on existing schemes for connecting digital musical instruments and other interactive systems, bringing clarified, strong semantics to system messaging and description. We use automated discovery and message translation instead of imposed system-representation standards to approach "plug-and-play" usability without sacrificing design flexibility. System modularity is encouraged, and data are transported between peers without centralized servers.
C1 [Malloch, Joseph; Sinclair, Stephen; Wanderley, Marcelo M.] McGill Univ, CIRMMT, IDMIL, Montreal, PQ, Canada.
C3 McGill University
RP Malloch, J (corresponding author), McGill Univ, CIRMMT, IDMIL, 527 Sherbrooke St West, Montreal, PQ, Canada.
EM joseph.malloch@mail.mcgill.ca; stephen.sinclair@mail.mcgill.ca;
   marcelo.wanderley@mcgill.ca
OI Wanderley, Marcelo/0000-0002-9169-4313; Malloch,
   Joseph/0000-0001-9684-2269
FU Fonds de recherche sur la societe et la culture (FQRSC) of the Quebec
   government; Natural Sciences and Engineering Research Council of Canada
   (NSERC); NSERC/Canada Council for the Arts New Media Initiative
FX Development of libmapper has been supported by funds from the Fonds de
   recherche sur la societe et la culture (FQRSC) of the Quebec government,
   the Natural Sciences and Engineering Research Council of Canada (NSERC),
   and the NSERC/Canada Council for the Arts New Media Initiative.
CR [Anonymous], 2005, PROC GW 2005
   [Anonymous], 2007, IEEE STD 14515 2007, pC1, DOI DOI 10.1109/IEEESTD.2007.4346346
   [Anonymous], 2009, P C NEW INTERFACES M
   [Anonymous], 2007, Protocols and Architectures for Wireless Sensor Networks
   [Anonymous], 2005, PEER TO PEER SYSTEMS
   Apple, 2005, BONJ PRINT SPEC
   Bevilacqua F., 2005, P C NEW INTERFACES M, P85
   Bullock J, 2011, P INT COMP MUS C U H
   COOK P. R, 1999, P INT COMP MUS C, P164
   Cronin E, 2004, MULTIMED TOOLS APPL, V23, P7, DOI 10.1023/B:MTAP.0000026839.31028.9f
   ESTA, 2011, E1172010 ESTA ANSI
   ESTA, 2004, E1112004 ESTA ANSI
   Fiebrink R., 2011, THESIS PRINCETON U P
   Holleczek A., 2013, 2013 Conference on Lasers & Electro-Optics. Europe & International Quantum Electronics Conference (CLEO EUROPE/IQEC), DOI 10.1109/CLEOE-IQEC.2013.6801690
   Hunt A., 1999, THESIS U YORK UK
   Hunt Andy, 2002, Organised Sound, V7, P97, DOI [DOI 10.1017/S1355771802002030, 10.1017/S135577180 2002030, 10.1017/S1355771802002030]
   Jensenius A.R., 2006, P 2006 C NEW INTERFA, P176
   Malloch J, 2007, P INT C NEW INT MUS
   Malloch J., 2013, PROC INT C HUMAN FAC, P3087, DOI DOI 10.1145/2468356
   Malloch J, 2008, LECT NOTES COMPUT SC, V4969, P401
   MCMILLEN K, 1994, COMPUT MUSIC J, V18, P47, DOI 10.2307/3681357
   MMA, 1996, COMPL MIDI 1 0 DET S
   MOORE FR, 1988, COMPUT MUSIC J, V12, P19, DOI 10.2307/3679834
   Muller R., 2006, OSCBONJOUR
   Open Geospatial Consortium, 2006, TRANSD MARK LANG
   Place T, 2006, P INT COMP MUS C TUL
   Ressel M., 1999, GROUP'99. Proceedings of the International ACM SIGGROUP Conference on Supporting Group Work, P131, DOI 10.1145/320297.320312
   Schiesser S., 2009, PROC NEW INTERFACES, P165
   Schmeder A, 2009, P INT COMP MUS C
   Sinclair S, 2009, INTERACT COMPUT, V21, P54, DOI 10.1016/j.intcom.2008.10.012
   Soucy R.P., 2012, IP MULTICAST EXPLAIN
   Steiner H.-C., 2009, NIME, P125, DOI 10.5281/zenodo.1177689
   Taylor R.M., 2001, Proceedings of the ACM Symposium on Virtual Reality Software and Technology - VRST '01, P55, DOI [10.1145/505008.505019, DOI 10.1145/505008.505019, 10.1145/505008.505019., DOI 10.1145/505008.5050192]
   WRIGHT M, 1994, COMPUT MUSIC J, V18, P86, DOI 10.2307/3681361
   Wright M., 2003, Conf. New Interfaces Music. Expr, P153, DOI DOI 10.1007/978-3-319-47214-0_9
NR 35
TC 9
Z9 9
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5683
EP 5707
DI 10.1007/s11042-014-1878-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100015
DA 2024-07-18
ER

PT J
AU Pandit, S
   Sarker, K
   Razzaque, MA
   Sarkar, AMJ
AF Pandit, Sharbani
   Sarker, Krishanu
   Razzaque, Md Abdur
   Sarkar, A. M. Jehad
TI An energy-efficient multiconstrained QoS aware MAC protocol for body
   sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Body sensor network; Quality of services; Medium access control; Energy
   efficiency; Ontime reachability; Multimedia
AB One of the most challenging jobs in designing a Medium Access Control (MAC) protocol for Body Sensor Networks (BSNs) is to achieve QoS requirements for heterogeneous traffics generated from various sensors. Increasing the energy-efficiency of the network should be kept in mind while doing this. Physiological data monitoring applications generate different types of traffic including multimedia data packets. These heterogeneous traffics should be treated differently by an underlying communication protocol, allowing the transmission schedule of these traffic types based on their priorities. In this paper, we present an energy-efficient multiconstrained QoS aware MAC protocol, namely eMC-MAC, wherein the medium access control is designed based on traffic prioritization. We have redefined the superframe structure in such a way that the critical data packets are transmitted earlier than other packets. In our proposed eMC-MAC protocol, we have introduced minislots during CFP (Contention Free Period), where requests for urgent packets are collected to the coordinator node in an energy-efficient way. We also develop an energy-efficient algorithm for preempting allocated data transmission slots to facilitate transmission of packets with higher priority. Thus, the proposed eMC-MAC protocol delivers emergency data packets to the coordinator with reduced delay. We have evaluated the effectiveness of our eMC-MAC protocol through extensive simulations in ns-3. The simulation results have shown that it outperforms a number of state-of-the-art MAC protocols for BSNs.
C1 [Pandit, Sharbani; Sarker, Krishanu; Razzaque, Md Abdur] Univ Dhaka, Dept Comp Sci & Engn, Dhaka 1000, Bangladesh.
   [Sarkar, A. M. Jehad] Hankuk Univ Foreign Studies, Dept Digital Informat Engn, Coll Engn, Seoul, South Korea.
C3 University of Dhaka; Hankuk University Foreign Studies
RP Razzaque, MA (corresponding author), Univ Dhaka, Dept Comp Sci & Engn, Dhaka 1000, Bangladesh.
EM sarbanipandit@gmail.com; rksarker006@gmail.com;
   razzaque@cse.univdhaka.edu; jehad@hufs.ac.kr
OI , Krishanu/0000-0002-4935-2686
FU Hankuk University of Foreign Studies
FX We would like to pay our highest level of gratitude to the anonymous
   reviewers for their valuable comments and suggestions that helped a lot
   to enrich the quality of the paper. This work was supported by Hankuk
   University of Foreign Studies Research Fund of 2014.
CR Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   Akyildiz IF, 2002, COMPUT NETW, V38, P393, DOI 10.1016/S1389-1286(01)00302-4
   Alemdar H, 2010, COMPUT NETW, V54, P2688, DOI 10.1016/j.comnet.2010.05.003
   Ameen M.A., 2008, 3 2008 INT C CONV HY
   Anjum I, 2013, INT J DISTRIB SENS N, DOI 10.1155/2013/205192
   [Anonymous], BIOINFORMATICS BIOME, DOI DOI 10.1109/TBCAS.2009.2031627
   Beck C, 2012, INT J WIREL INF NETW, V19, P163, DOI 10.1007/s10776-012-0185-1
   Chen C, 2010, INT J COMPUT SCI INF, V2
   Gopalan SA, 2010, ULTRAMODERN TELECOMM
   Hayat S, 2012, ENERGY EFFICIENT MAC, P1185
   Hossain MS, 2010, IEEE T INSTRUM MEAS, V59, P1498, DOI 10.1109/TIM.2009.2024338
   Lai X, 2013, SURVEY BODY SENSOR N
   Latré B, 2011, WIREL NETW, V17, P1, DOI 10.1007/s11276-010-0252-4
   Li CL, 2011, J MED SYST, V35, P1265, DOI 10.1007/s10916-011-9682-5
   Min Chen, 2011, Mobile Networks and Applications, V16, P171, DOI 10.1007/s11036-010-0260-8
   Monowar M. M., 2012, MCMAC MAC PROTOCOL M
   Otto C., 2006, J MOBILE MULTIMEDIA, V1, P307
   Rahman MO, 2011, SENSORS-BASEL, V11, P11560, DOI 10.3390/s111211560
   Razzaque Abdur, QOS PROVISIONING WIR
   Sanchez DS, 2011, EURASIP J WIREL COMM, DOI 10.1155/2011/797931
   Stojev MK, 2011, SER ELEC ENERG, V24, P183
   Suriyachai P, 2012, IEEE COMMUN SURV TUT, V14, P240, DOI 10.1109/SURV.2011.020211.00036
   Timmons NF, 2004, ANAL PERFORMANCE IEE, P16
   Wireless Medium Access Control (MAC) and Physical Layer (PHY), 2003, 8021542006 IEEE
   Yoon J. S., 2010, PNP MAC PREEMPT SLOT
   Zhang X, 2009, CIRC SYST 2009 ISCAS
   Zhou G, 2008, 27 C COMP COMM IEEE
NR 27
TC 20
Z9 20
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 14
BP 5353
EP 5374
DI 10.1007/s11042-014-1999-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XU
UT WOS:000358214900023
DA 2024-07-18
ER

PT J
AU Sun, YJ
   Dong, JY
   Jian, MW
   Qi, L
AF Sun, Yujuan
   Dong, Junyu
   Jian, Muwei
   Qi, Lin
TI Fast 3D face reconstruction based on uncalibrated photometric stereo
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photometric stereo; Face surface normal; Face albedo; Lambertian model
ID SINGLE IMAGE; SHAPE
AB This paper proposes a fast algorithm for three-dimensional face reconstruction using uncalibrated Photometric Stereo. With a reference face model, lighting parameters are estimated from input face images lighted by unknown illumination, which can be used in classical photometric stereo to estimate surface normal and albedo. The estimated results are used in turn to refine the lighting parameters until an optimal estimation of the surface normal is achieved. Differing from traditional optimization algorithms, the iteration method used in this paper is a unified process thus results accurate lighting estimation. The proposed method relaxes lighting constraints and simplifies the image acquisition procedure. The reconstructed results tested on YaleB and BU3D databases show the effectiveness of our method.
C1 [Sun, Yujuan; Dong, Junyu; Qi, Lin] Ocean Univ China, Dept Comp Sci & Technol, Qingdao, Peoples R China.
   [Sun, Yujuan] Ludong Univ, Dept Informat & Elect Engn, Yantai, Peoples R China.
   [Jian, Muwei] Hong Kong Polytech Univ, Dept Elect & Informat Engn, Ctr Signal Proc, Kowloon, Hong Kong, Peoples R China.
C3 Ocean University of China; Ludong University; Hong Kong Polytechnic
   University
RP Dong, JY (corresponding author), Ocean Univ China, Dept Comp Sci & Technol, Qingdao, Peoples R China.
EM dongjunyu@ouc.edu.cn
RI Jian, Muwei/Q-8319-2018
OI Jian, Muwei/0000-0002-4249-2264; Dong, Junyu/0000-0001-7012-2087
CR Agrawal A, 2005, IEEE I CONF COMP VIS, P174, DOI 10.1109/ICCV.2005.31
   [Anonymous], 2007, CVPR
   Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7
   Belhumeur PN, 1999, INT J COMPUT VISION, V35, P33, DOI 10.1023/A:1008154927611
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Castelan M, 2007, IEEE T IMAGE PROCESS, V16, P1139, DOI 10.1109/TIP.2006.891351
   Castelán M, 2009, LECT NOTES COMPUT SC, V5876, P662, DOI 10.1007/978-3-642-10520-3_63
   Chen CP, 2006, LECT NOTES COMPUT SC, V3953, P72, DOI 10.1007/11744078_6
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Hertzmann A, 2003, PROC CVPR IEEE, P533
   Jang IY, 2012, MULTIMED TOOLS APPL, V58, P267, DOI 10.1007/s11042-010-0719-4
   Jian MW, 2011, MULTIMED TOOLS APPL, V53, P237, DOI 10.1007/s11042-010-0509-z
   Kemelmacher-Shlizerman I, 2011, IEEE T PATTERN ANAL, V33, P394, DOI 10.1109/TPAMI.2010.63
   Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971
   Koch A, 2012, MULTIMED TOOLS APPL, V57, P565, DOI 10.1007/s11042-010-0657-1
   Lee SW, 2008, INT J PATTERN RECOGN, V22, P389, DOI 10.1142/S0218001408006272
   Li A.H.L., 2008, P 8 IEEE INT C AUT F, P1
   Malzbender T., 2006, Rendering Techn., P245
   McGunnigle G, 2011, IET COMPUT VIS, V5, P33, DOI 10.1049/iet-cvi.2009.0038
   Metz CE, 1998, STAT MED IN PRESS
   Nehab D, 2005, ACM T GRAPHIC, V24, P536, DOI 10.1145/1073204.1073226
   Ramamoorthi R, 2001, COMP GRAPH, P497, DOI 10.1145/383259.383317
   Seitz S. M., 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), V1, P519
   Shashua A, 1992, THESIS MIT
   Song ML, 2012, IEEE T IMAGE PROCESS, V21, P2887, DOI 10.1109/TIP.2012.2183882
   Wenger A, 2005, ACM T GRAPHIC, V24, P756, DOI 10.1145/1073204.1073258
   WOODHAM RJ, 1994, J OPT SOC AM A, V11, P3050, DOI 10.1364/JOSAA.11.003050
   WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Zhang XF, 2012, SCI CHINA INFORM SCI, V55, P1052, DOI 10.1007/s11432-012-4556-0
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 31
TC 13
Z9 13
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 3635
EP 3650
DI 10.1007/s11042-013-1791-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800002
DA 2024-07-18
ER

PT J
AU Baldassarri, S
   Hupont, I
   Abadía, D
   Cerezo, E
AF Baldassarri, Sandra
   Hupont, Isabelle
   Abadia, David
   Cerezo, Eva
TI Affective-aware tutoring platform for interactive digital television
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective computing; Learning technologies; Facial recognition; Facial
   expressions; Emotions; Interactive digital tv
ID RECOGNITION; CLASSIFICATION; EMOTION; FUTURE; SYSTEM; MODEL
AB Interactive Digital TeleVision (IDTV) is emerging as a potentially important medium for learning at home. This paper presents a novel affective-aware tutoring platform for IDTV which makes use of automatic facial emotion recognition to improve the tutor-student relationship. The system goes further than simply broadcasting an interactive educational application by allowing the personalization of the course content. The tutor can easily access academic information relating to the students and also emotional information captured from learners' facial expressions. In this way, depending on their academic and affective progress, the tutor can send personal messages or extra educational contents for improving students' learning. In order to include these features it was necessary to address some important technical challenges derived from IDTV hardware and software restrictions. The system has been successfully tested with real students and tutors in a non-laboratory environment. Our system tries to advance in the challenge of providing to distance learning systems with the perceptual abilities of human teachers with the final aim of improving students learning experience and outcome. Nevertheless, there is still relatively little understanding of the impact of affect on students' behaviour and learning and of the dynamics of affect during learning with software. Systems like ours would make it possible to attack these relevant open questions.
C1 [Baldassarri, Sandra; Cerezo, Eva] Univ Zaragoza, Engn Res Inst Aragon I3A, Dept Comp Sci, GIGA AffectiveLab, Zaragoza, Spain.
   [Hupont, Isabelle; Abadia, David] Aragon Inst Technol, Multimedia Technol Div, Zaragoza, Spain.
C3 University of Zaragoza
RP Baldassarri, S (corresponding author), Univ Zaragoza, Engn Res Inst Aragon I3A, Dept Comp Sci, GIGA AffectiveLab, Zaragoza, Spain.
EM sandra@unizar.es; ihupont@ita.es; dabadia@ita.es; ecerezo@unizar.es
RI Cerezo, Eva/L-6095-2014; Hupont, Isabelle/AAZ-9821-2020; Hupont,
   Isabelle/T-8908-2019; Baldassarri, Sandra/L-6033-2014
OI Cerezo, Eva/0000-0003-4424-0770; Hupont, Isabelle/0000-0002-9811-9397;
   Abadia, David/0000-0002-6005-3863; Baldassarri,
   Sandra/0000-0002-9315-6391
FU Spanish "Direccion General de Investigacion" [TIN2011-24660]; CYTED
   [512RT0461]; Mechatronics and Systems Group (SISTRONIC) of the Aragon
   Institute of Technology; Spanish "Ministerio de Ciencia e Innovacion" in
   the context of the QuEEN project [IPT-2011-1235-430000]
FX This work has been partly financed by the Spanish "Direccion General de
   Investigacion", contract number TIN2011-24660, by the CYTED, contract
   number 512RT0461, by the Mechatronics and Systems Group (SISTRONIC) of
   the Aragon Institute of Technology and by the Spanish "Ministerio de
   Ciencia e Innovacion" in the context of the QuEEN project, contract
   number IPT-2011-1235-430000.
CR Abadía D, 2009, I SYMP CONSUM ELECTR, P957
   Alexander S, 2004, LECT NOTES COMPUT SC, V3101, P641
   An KH, 2009, IEEE T CONSUM ELECTR, V55, P2271, DOI 10.1109/TCE.2009.5373798
   [Anonymous], 1953, KATHIMERINI
   [Anonymous], 2006, P 8 INT C MULT INT, DOI [10.1145/1180995.1181029, DOI 10.1145/1180995.1181029]
   Baker RSJD, 2010, INT J HUM-COMPUT ST, V68, P223, DOI 10.1016/j.ijhcs.2009.12.003
   BATES PJ, 2005, EUR C INT TEL APR, P137
   Bellotti F, 2010, CASES ON TRANSNATIONAL LEARNING AND TECHNOLOGICALLY ENABLED ENVIRONMENTS, P118, DOI 10.4018/978-1-61520-749-7.ch007
   Brusilovsky P., 2003, International Journal of Continuing Engineering Education and Life-Long Learning, V13, P75
   Brusilovsky Peter., 1996, P 3 INT C INTELLIGEN, P261, DOI DOI 10.1007/3-540-61327-7_123
   BURLESON W, 2006, THESIS MIT
   Chen CM, 2008, COMPUT EDUC, V51, P787, DOI 10.1016/j.compedu.2007.08.004
   Clark D., 2013, MOOCS TAXONOMY 8 TYP
   Cmolik L, 2007, IADIS INT C WWW INT, P35
   Conati C, 2002, APPL ARTIF INTELL, V16, P555, DOI 10.1080/08839510290030390
   Conati C., 2004, P IUI 04 INT C INTEL, P6, DOI DOI 10.1145/964442.964446
   D'Mello S., 2008, Workshop on emotional and cognitive issues at the international conference on intelligent tutoring systems, P306
   D'Mello SK, 2011, NEW PERSPECTIVES ON AFFECT AND LEARNING TECHNOLOGIES, P113, DOI 10.1007/978-1-4419-9625-1_9
   Damasio MJ, 2004, ED-MEDIA 2004: WORLD CONFERENCE ON EDUCATIONAL MULTIMEDIA, HYPERMEDIA & TELECOMMUNICATIONS, VOLS. 1-7, P4511
   De Vicente A, 2002, LECT NOTES COMPUT SC, V2363, P933
   Desmarais MC, 2012, USER MODEL USER-ADAP, V22, P9, DOI 10.1007/s11257-011-9106-8
   Dosi AI, 2004, ED-MEDIA 2004: World Conference on Educational Multimedia, Hypermedia & Telecommunications, Vols. 1-7, P4831
   DOSSANTOS DT, 2007, P 36 ANN C FRONT ED, P1
   Ekman P., 2002, FACIAL ACTION CODING
   Fragopanagos N, 2005, NEURAL NETWORKS, V18, P389, DOI 10.1016/j.neunet.2005.03.006
   Gee J.P., 2004, Situated language and learning: A critique of traditional schooling, DOI DOI 10.4324/9780203594216
   Graesser A.C., 2009, Handbook of metacognition in education, P361
   Hammal Z, 2007, INT J APPROX REASON, V46, P542, DOI 10.1016/j.ijar.2007.02.003
   HENZE N., 2001, IJAIED, Special Issue on Adaptive and Intelligent Web-based Systems, V12, P325
   Hone K, 2006, INTERACT COMPUT, V18, P227, DOI 10.1016/j.intcom.2005.05.003
   Hubscher R., 2000, Adaptive Hypermedia and Adaptive Web-Based Systems. International Conference, AH 2000. Proceedings (Lecture Notes in Computer Science Vol.1892), P121
   Hupont I., 2013, ADV EMOTION RECOGNIT
   Hupont I., 2011, P IEEE WORKSH AFF CO, P68, DOI DOI 10.1109/WACI.2011.5953150
   Hupont I, 2013, PATTERN ANAL APPL, V16, P41, DOI 10.1007/s10044-012-0286-6
   IPEA: Instituto de Pesquisa Economica Aplicada, 2013, PAN COMM TEL BRAS
   Isen A.M., 2000, HDB EMOTIONS, V2nd, P417, DOI DOI 10.1111/J.1745-6916.2007.00035
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kapoor A, 2007, INT J HUM-COMPUT ST, V65, P724, DOI 10.1016/j.ijhcs.2007.02.003
   Kim J, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P895, DOI 10.1109/ICCE.2011.5722924
   Kort B, 2001, IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P43, DOI 10.1109/ICALT.2001.943850
   Kumar P, 2005, J OPTIMIZ THEORY APP, V126, P1, DOI 10.1007/s10957-005-2653-6
   López-Nores M, 2009, MULTIMED TOOLS APPL, V41, P407, DOI 10.1007/s11042-008-0239-7
   Mandryk RL, 2007, INT J HUM-COMPUT ST, V65, P329, DOI 10.1016/j.ijhcs.2006.11.011
   McDuff D, 2012, IEEE T AFFECT COMPUT, V3, P456, DOI 10.1109/T-AFFC.2012.19
   Merrill DC., 1992, J LEARN SCI, V2, P277, DOI [10.1207/s15327809jls0203_2, DOI 10.1207/S15327809JLS0203_2]
   Montpetit MJ, 2011, MULTIMED TOOLS APPL, V53, P519, DOI 10.1007/s11042-010-0504-4
   MORRELL DR, 2003, P ISIPTA, P396
   Nicolaou MA, 2011, IEEE T AFFECT COMPUT, V2, P92, DOI 10.1109/T-AFFC.2011.9
   Papanikolaou KA, 2002, COMPUT EDUC, V39, P333, DOI 10.1016/S0360-1315(02)00067-2
   Picard R.W., 2000, Affective Computing
   Picard RW, 2004, BT TECHNOL J, V22, P253, DOI 10.1023/B:BTTJ.0000047603.37042.33
   Plutchik R., 1980, EMOTION PSYCHOEVOLUT
   Porayska-Pomsta K, 2008, USER MODEL USER-ADAP, V18, P125, DOI 10.1007/s11257-007-9041-x
   Rey-López M, 2008, MULTIMED TOOLS APPL, V40, P409, DOI 10.1007/s11042-008-0213-4
   Rey-López M, 2006, LECT NOTES COMPUT SC, V4018, P457
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Russell ThomasL., 1997, Educom Review, V32, P44
   Sarrafzadeh A, 2008, COMPUT HUM BEHAV, V24, P1342, DOI 10.1016/j.chb.2007.07.008
   Schiaffino S, 2008, COMPUT EDUC, V51, P1744, DOI 10.1016/j.compedu.2008.05.008
   Smith ASG, 2003, INT J ARTIFICIAL INT, V13, P233
   Snow R.E., 1987, Aptitude, learning, and instruction volume 3: Conative and affective process analysis, P1
   Soleymani M, 2013, P TVUX 2013 WORKSH
   Soyel H, 2007, LECT NOTES COMPUT SC, V4633, P831
   Suraweera P, 2002, LECT NOTES COMPUT SC, V2363, P377
   VanLehn K., 2006, International journal of artificial intelligence in education, V16, P227
   Wallhoff F., 2006, Facial Expressions and Emotion Database
   Whissell C., 1989, Emotion: Theory, Research and Experience: vol. 4, V4
   WHISSELL C, WHISSELLS DICT AFFEC
   Witten I. H., 2005, DATA MINING PRACTICA
   Yeasin M, 2006, IEEE T MULTIMEDIA, V8, P500, DOI 10.1109/TMM.2006.870737
   Zapata-Ros M, 2013, DISENO INSTRUCCIONAL
NR 71
TC 9
Z9 12
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 9
BP 3183
EP 3206
DI 10.1007/s11042-013-1779-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA CF7NI
UT WOS:000352742800017
DA 2024-07-18
ER

PT J
AU Guesmi, H
   Trichili, H
   Alimi, AM
   Solaiman, B
AF Guesmi, Hanene
   Trichili, Hanene
   Alimi, Adel M.
   Solaiman, Basel
TI Fingerprint verification system based on curvelet transform and
   possibility theory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fingerprint verification; Possibility theory; Curvelet transform;
   Fingerprint feature extraction
AB A fingerprint feature extraction step represents the success key of the fingerprint verification process. In a matching step, the good processing of those features would generate a measure that reflects more accurately the similarity degree between the input fingerprint and the template. In our study, we propose a novel fingerprint feature extraction method based on the Curvelet transform to reduce the dimensionality of the fingerprint image and to improve the verification rate. Like all extractors, the features which are generated by the Curvelet transform are usually imprecise and reflect an uncertain representation. Therefore, we proposed to analyze these features by a possibility theory to deal with imprecise and uncertain aspect in our novel fingerprint matching method. Thus, this paper focused on presenting a novel fingerprint features extraction method and a novel matching method. The features extraction method consists of two main steps: decompose the fingerprint image into a set of sub-bands by the Curvelet transform and extract the most discriminative statistical features of these sub-bands. A possibility based representation of those statistical features would be achieved by a possibility theory. So, the proposed fingerprint matching method is based on the use of the possibility theory as a global framework, including knowledge representation (as a possibility measure); in order to build a possibility fingerprint knowledge basis to be exploited in order to make a fingerprint verification decision. An extensive experimental evaluation shows that the proposed fingerprint verification approach is effective in terms of fingerprint image representation and possibility verification reasoning.
C1 [Guesmi, Hanene; Trichili, Hanene; Alimi, Adel M.] Natl Engn Sch Sfax, REGIM REs Grp Intelligent Machines, Sfax, Tunisia.
   [Guesmi, Hanene; Trichili, Hanene; Solaiman, Basel] Telecom Bretagne, Dept Image & Informat Proc ITI, Brest, France.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS); IMT -
   Institut Mines-Telecom; IMT Atlantique
RP Guesmi, H (corresponding author), Natl Engn Sch Sfax, REGIM REs Grp Intelligent Machines, Sfax, Tunisia.
EM guesmi.hanen@gmail.com; hanene.trichili@telecom-bretagne.eu;
   adel.alimi@ieee.org; basel.solaiman@telecom-bretagne.eu
RI Alimi, Adel M./A-5697-2012
OI Alimi, Adel M./0000-0002-0642-3384; TRICHILI, Hanene/0000-0003-4834-8658
CR [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 8 INT C NAT COMP ICN
   [Anonymous], P PRORISC 12 ANN WOR
   [Anonymous], P IEEE COMP SOC C CO
   [Anonymous], 2012, PROC INT C BIOMETRIC
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], INT WORKSH PATT REC
   [Anonymous], P C BMVC 98
   Bhanu B, 2003, IEEE T PATTERN ANAL, V25, P616, DOI 10.1109/TPAMI.2003.1195995
   Candes E.J., 1999, CURVE SURFACE FITTIN
   Candes E.J., 1998, Ridgelets: theory and applications
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Dubois D., 1988, Computational Intelligence, V4, P244, DOI 10.1111/j.1467-8640.1988.tb00279.x
   DUBOIS D, 1985, THEORIE POSSIBILITES
   Guttman A., 1984, ACM SIGMOD INT C MAN, P47, DOI DOI 10.1145/602259.602266
   Holzinger A, 2012, ENTROPY-SWITZ, V14, P2324, DOI 10.3390/e14112324
   Jeon B, 1999, IEEE T GEOSCI REMOTE, V37, P1227, DOI 10.1109/36.763278
   Liu MH, 2007, PATTERN RECOGN, V40, P1793, DOI 10.1016/j.patcog.2006.11.007
   Lumini A, 2006, PATTERN RECOGN, V39, P714, DOI 10.1016/j.patcog.2005.11.003
   MAIO D, 2003, HDB FINGERPRINT RECO
   Nanni L, 2007, PATTERN RECOGN, V40, P3146, DOI 10.1016/j.patcog.2007.02.018
   Ross A, 2003, PATTERN RECOGN, V36, P1661, DOI 10.1016/S0031-3203(02)00349-7
   Sasikala KR, 2001, FUZZY SET SYST, V118, P121, DOI 10.1016/S0165-0114(99)00064-0
   Solaiman B, 1999, IEEE T GEOSCI REMOTE, V37, P1316, DOI 10.1109/36.763295
   YAGER RR, 1982, FUZZY SETS POSSIBILI, P90
   Yang JC, 2008, NEUROCOMPUTING, V71, P1939, DOI 10.1016/j.neucom.2007.12.034
   Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, P3, DOI 10.1016/0165-0114(78)90029-5
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   ZAHZAH E, 1992, THESIS U P SABATIER
NR 29
TC 7
Z9 9
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 9
BP 3253
EP 3272
DI 10.1007/s11042-013-1785-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CF7NI
UT WOS:000352742800020
DA 2024-07-18
ER

PT J
AU Rokanujjaman, M
   Islam, MS
   Hossain, MA
   Islam, MR
   Makihara, Y
   Yagi, Y
AF Rokanujjaman, Md.
   Islam, Md. Shariful
   Hossain, Md. Altab
   Islam, Md. Rezaul
   Makihara, Yashushi
   Yagi, Yasushi
TI Effective part-based gait identification using frequency-domain gait
   entropy features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait; Identification; Effective part; EnDFT
ID RECOGNITION; REPRESENTATION; MODEL
AB Gait identification task becomes more difficult due to the change of appearance by different cofactors (e.g., shoe, surface, carrying, view, and clothing). The cofactors may affect some parts of gait while other parts remain unchanged and can be used for recognition. We propose a robust technique to define which parts are more effective and which parts are less effective for cofactors like clothing, carrying objects etc. To find out the effective body parts, the whole body is divided into small segments where each segment is a single row in this paper. Based on positive and negative effect of each segment, three most effective parts and two less effective parts are defined. Usually, the dynamic areas (e.g., legs, arms swing) are comparatively less affected than static areas (e.g., torso) for different cofactors in appearance based gait representation. To give more emphasis on dynamic areas and less on static areas, frequency-domain gait entropy termed as EnDFT representation is computed and used as gait features. Experiments are conducted on two comprehensive benchmarking databases: The OU-ISIR Gait Database, the Treadmill dataset B with clothing variations and CASIA Gait Database, Dataset B with clothing and carrying conditions. The proposed method shows better results in comparison with other existing gait recognition approaches.
C1 [Rokanujjaman, Md.; Hossain, Md. Altab] Rajshahi Univ, Dept Comp Sci & Engn, Rajshahi 6205, Bangladesh.
   [Islam, Md. Shariful] Pabna Univ Sci & Technol, Dept Comp Sci & Engn, Pabna, Bangladesh.
   [Islam, Md. Rezaul] Rajshahi Univ, Dept Appl Phys & Elect Engn, Rajshahi 6205, Bangladesh.
   [Makihara, Yashushi; Yagi, Yasushi] Osaka Univ, Inst Ind & Sci Res, Osaka, Japan.
C3 University of Rajshahi; University of Rajshahi; Osaka University
RP Hossain, MA (corresponding author), Rajshahi Univ, Dept Comp Sci & Engn, Rajshahi 6205, Bangladesh.
EM rokon_cstru@yahoo.com; sharif@pust.ac.bd; altab_ru@yahoo.com;
   rima@ru.ac.bd; makihara@am.sanken.osaka-u.ac.jp;
   yagi@am.sanken.osaka-u.ac.jp
CR [Anonymous], 1 WORKSH IM PROC THE
   [Anonymous], 2007, P BIOM S
   Ariyanto Gunawan, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P354, DOI 10.1109/ICB.2012.6199832
   Bashir K., 2010, the British Machine Vision Conference, P1, DOI DOI 10.1049/IC.2009.0230
   Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BENABDELKADER C, 2001, P INT C AUD VID BAS, P284
   Boulgouris NV, 2007, PATTERN RECOGN, V40, P1763, DOI 10.1016/j.patcog.2006.11.012
   Boulgouris NV, 2005, IEEE SIGNAL PROC MAG, V22, P78, DOI 10.1109/MSP.2005.1550191
   Chellappa R., 2010, HUMAN IDENTIFICATION
   Cuntoor N, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P33
   Dawson M, 2002, GAIT RECOGNITION FIN
   DEMPSTER WT, 1967, AM J ANAT, V120, P33, DOI 10.1002/aja.1001200104
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hossain MA, 2010, PATTERN RECOGN, V43, P2281, DOI 10.1016/j.patcog.2009.12.020
   Kuncheva LI, 2001, P 2 INT WORKSH MULT, V2096, P349
   Lam THW, 2011, PATTERN RECOGN, V44, P973, DOI 10.1016/j.patcog.2010.10.011
   Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148
   Li XL, 2008, IEEE T SYST MAN CY C, V38, P145, DOI 10.1109/TSMCC.2007.913886
   Liu YX, 2002, LECT NOTES COMPUT SC, V2351, P657
   Liu ZY, 2004, INT C PATT RECOG, P211, DOI 10.1109/ICPR.2004.1333741
   Makihara Yasushi, 2012, IPSJ Transactions on Computer Vision and Applications, V4, P42, DOI 10.2197/ipsjtcva.4.53
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Nixon MS, 2006, P IEEE, V94, P2013, DOI 10.1109/JPROC.2006.886018
   Rogers E, BELL CANADA CHAIR MU
   Rokanujjaman M., 2012, 2012 7th International Conference on Electrical & Computer Engineering (ICECE), P17, DOI 10.1109/ICECE.2012.6471473
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Urtasun R, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P17, DOI 10.1109/AFGR.2004.1301503
   Wagg DK, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P11, DOI 10.1109/AFGR.2004.1301502
   Wang C, 2012, IEEE T PATTERN ANAL, V34, P2164, DOI 10.1109/TPAMI.2011.260
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wang N, 2010, PROCEEDINGS OF THE 2ND (2010) INTERNATIONAL CONFERENCE ON FINANCIAL RISK AND CORPORATE FINANCE MANAGEMENT, P320
   Yam CY, 2004, PATTERN RECOGN, V37, P1057, DOI 10.1016/j.patcog.2003.09.012
   Yu Guan, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P321, DOI 10.1109/IIH-MSP.2012.84
   Yu SQ, 2006, INT C PATT RECOG, P441
NR 35
TC 33
Z9 37
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 9
BP 3099
EP 3120
DI 10.1007/s11042-013-1770-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CF7NI
UT WOS:000352742800012
DA 2024-07-18
ER

PT J
AU Zhang, MM
   Lin, L
   Pan, ZG
   Xiang, N
AF Zhang, Mingmin
   Lin, Ling
   Pan, Zhigeng
   Xiang, Nan
TI Topology-independent 3D garment fitting for virtual clothing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fit; Dressing; Virtual try-on; Clothing simulation
AB ]Using computer-aided design system to design an elegant 3D garment for a virtual human is often tedious and labor-intensive. Moreover, the garment is usually designed for a reference human model and generally not fitted to other individuals, which largely reduces the reusability of existing 3D garments. In this paper, we introduce proxy mesh to fit 3D garment to another human model whose topology or shape is different from the garment's reference human model. Firstly, a proxy mesh is generated for the reference human model and the specified human model respectively. Secondly, the garment is parameterized based on the proxy mesh of the reference model and an independent dataset is obtained. Thirdly, the dataset is decoded to the proxy mesh of the other human model and a roughly fitted garment is gained. Lastly, local shape constrains are enforced to the fitted garment and garment-body penetrations are resolved to get a well fitted garment. Our approach is efficient, simple to implement and is potential to be applied to existing applications such as virtual try-on and virtual clothing design.
C1 [Zhang, Mingmin; Lin, Ling] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310003, Zhejiang, Peoples R China.
   [Pan, Zhigeng] Hangzhou Normal Univ, DMI Ctr, Hangzhou, Zhejiang, Peoples R China.
   [Xiang, Nan] Chongqing Univ Technol, Coll Comp Sci, Chongqing, Peoples R China.
C3 Zhejiang University; Hangzhou Normal University; Chongqing University of
   Technology
RP Pan, ZG (corresponding author), Hangzhou Normal Univ, DMI Ctr, Hangzhou, Zhejiang, Peoples R China.
EM zmm@cad.zju.edu.cn; linling158@163.com; zgpan@hznu.edu.cn;
   xiangnan@zjucadcg.cn
RI zhang, mm/IWV-4201-2023; Zhang, Miao/JXY-8985-2024; DAI,
   Jinjia/KCL-5110-2024
OI Pan, Zhi-geng/0000-0003-0717-5850
FU NSFC [61173124, 61170318, 611332017]
FX The work presented in this paper was supported by NSFC Grant 61173124,
   61170318 and 611332017.
CR Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Choi KJ, 2002, ACM T GRAPHIC, V21, P604, DOI 10.1145/566570.566624
   Cordier F, 2003, IEEE COMPUT GRAPH, V23, P38, DOI 10.1109/MCG.2003.1159612
   Decaudin P, 2006, COMPUT GRAPH FORUM, V25, P625, DOI 10.1111/j.1467-8659.2006.00982.x
   Desbrun M, 1999, PROC GRAPH INTERF, P1
   Fuhrmann A., 2003, P GRAPHICON 2003, P58
   HASEGAWA S, 2003, P 11 S HAPT INT VIRT
   Igarashi T, 2007, P 15 ACM S US INT SO, P91
   Kim S, 2007, INT J CLOTH SCI TECH, V19, P7, DOI 10.1108/09556220710717017
   Luo ZG, 2005, COMPUT AIDED DESIGN, V37, P623, DOI 10.1016/j.cad.2004.09.005
   Meng YW, 2010, COMPUT AIDED DESIGN, V42, P310, DOI 10.1016/j.cad.2009.12.004
   Mori Y, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239496
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56
   Turquin E, 2007, IEEE COMPUT GRAPH, V27, P72, DOI 10.1109/MCG.2007.1
   Umetani N, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964985
   Volino P., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P137, DOI 10.1145/218380.218432
   Volino P, 2007, VISUAL COMPUT, V23, P669, DOI 10.1007/s00371-007-0152-5
   Wang CCL, 2005, COMPUT AIDED DESIGN, V37, P675, DOI 10.1016/j.cad.2004.08.007
   Wang CCL, 2003, COMPUT AIDED DESIGN, V35, P241, DOI 10.1016/S0010-4485(01)00209-3
   Zhang D, 2001, COMPUT GRAPH-UK, V25, P383, DOI 10.1016/S0097-8493(01)00062-0
NR 21
TC 14
Z9 18
U1 5
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 9
BP 3137
EP 3153
DI 10.1007/s11042-013-1774-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CF7NI
UT WOS:000352742800014
DA 2024-07-18
ER

PT J
AU Soysal, M
   Alatan, AA
AF Soysal, Medeni
   Alatan, A. Aydin
TI Joint utilization of local appearance and geometric invariants for 3D
   object recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local features; Geometric descriptors; Geometric invariants; Multi-view
   object recognition
AB This article introduces a novel method for 3D object recognition, which utilizes well-known local features in a more efficient way, without any reliance on partial or global planarity. Geometrically consistent local features, which form the crucial basis for object recognition, are identified using affine 3D geometric invariants. The utilization of 3D geometric invariants replaces the classical 2D affine transform estimation/verification step, and provides the ability to directly verify 3D geometric consistency. The main contribution of the proposed approach lies in this ability of incorporating highly discriminative affine invariant 3D information much earlier in the process of matching in comparison with its counterparts. The accuracy and robustness of the method in highly cluttered scenes, without any prior segmentation or post 3D reconstruction requirements, are presented in the experiments.
C1 [Soysal, Medeni] Middle East Tech Univ Campus, TUBITAK Space Technol Res Inst, Ankara, Turkey.
   [Alatan, A. Aydin] Middle E Tech Univ, Elect & Elect Engn Dept, TR-06531 Ankara, Turkey.
C3 Middle East Technical University; Turkiye Bilimsel ve Teknolojik
   Arastirma Kurumu (TUBITAK); Middle East Technical University
RP Soysal, M (corresponding author), Middle East Tech Univ Campus, TUBITAK Space Technol Res Inst, Ankara, Turkey.
EM medenis@gmail.com; alatan@eee.metu.edu.tr
RI Alatan, A. Aydin/E-3927-2012
OI Soysal, Medeni/0000-0002-7846-7052
CR [Anonymous], 2007, Computer Vision
   [Anonymous], 2009, P 17 ACM INT C MULTI, DOI DOI 10.1145/1631272.1631361
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   BURNS JB, 1992, ARTIF INT, P120
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Chen H, 2009, IEEE T PATTERN ANAL, V31, P172, DOI 10.1109/TPAMI.2008.176
   Chen H, 2007, IEEE T PATTERN ANAL, V29, P718, DOI 10.1109/TPAMI.2007.1005
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Ferrari V, 2006, INT J COMPUT VISION, V67, P159, DOI 10.1007/s11263-005-3964-7
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   FORSYTH DA, 2003, PRENTICE HALL SERIES
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Gao Y, 2011, SIGNAL PROCESS-IMAGE, V26, P39, DOI 10.1016/j.image.2010.10.006
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hinterstoisser S, 2008, BMVC BRIT MACH VIS C
   Hinterstoisser S, 2011, IEEE I CONF COMP VIS, P858, DOI 10.1109/ICCV.2011.6126326
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Li WJ, 2008, IEEE T IMAGE PROCESS, V17, P2236, DOI 10.1109/TIP.2008.2003404
   Liang Z., 2010, IEEE International Conference on Communications ICC, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maybank SJ, 1998, IMAGE VISION COMPUT, V16, P13, DOI 10.1016/S0262-8856(97)00048-6
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1
   Mundy JL, 2006, LECT NOTES COMPUT SC, V4170, P3
   Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1
   Rui Y, 2000, COMPUTER VISION PATT
   Song BS, 2001, COMPUT VIS IMAGE UND, V84, P361, DOI 10.1006/cviu.2001.0954
   Soysal M, 2010, INT S COMP INF SCI I, V62, P305
   Soysal M, 2011, COMPUT J, V54, P1221, DOI 10.1093/comjnl/bxq093
   Soysal M, 2009, 2009 24TH INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, P60, DOI 10.1109/ISCIS.2009.5291918
   TOLA E, 2008, C COMP VIS PATT REC
   Torr PHS, 1998, COMPUT VIS IMAGE UND, V71, P312, DOI 10.1006/cviu.1997.0559
   Weiss I, 2001, IEEE T PATTERN ANAL, V23, P116, DOI 10.1109/34.908963
   ZISSERMAN A, 1995, ARTIF INTELL, V78, P239, DOI 10.1016/0004-3702(95)00023-2
NR 38
TC 3
Z9 3
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 8
BP 2611
EP 2637
DI 10.1007/s11042-013-1622-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE2ZL
UT WOS:000351692300004
DA 2024-07-18
ER

PT J
AU Park, H
   Park, S
   Shon, T
   Kim, EJ
AF Park, Hyunhee
   Park, Seunghyun
   Shon, Taeshik
   Kim, Eui-Jik
TI Multi-hop-based opportunistic concurrent directional transmission in 60
   GHz WPANs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Directional antenna; mmWave network; Concurrent transmission; Multicast
   communication; Relay protocol
ID MAC PROTOCOL; SCHEME; ANTENNAS
AB In millimeter Wave wireless personal area networks (mmWave WPANs), the design of efficient concurrent transmission considered high modulations up to a few Gbps is one of the most challenging issues. Even for the concurrent transmission over mmWave networks, the use of directional antenna is highly recommended to guarantee high modulations and to overcome short propagation range caused to high path loss in mmWave frequency. Nevertheless the directional antenna has many advantages, users may suffer from performance degradation due to coverage limitation of wide beamwidth, when the concurrent transmission supports the multicast communication for the target applications such as conference room, wireless displays and room gaming. In this paper, we propose a multihop-based opportunistic concurrent directional transmission (M-OCDT) scheme for the directional multicast communication where the relay mechanism is generated depending on the locations of multicast users to maximize the sum rate. The proposed M-OCDT scheme is designed based on the IEEE 802.15.3c standard and supports the optimized searching algorithm for the relay users. Extensive simulation results demonstrate that the M-OCDT scheme can improve the average overall throughput by 81 to 89 % compared with the conventional non-relay directional multicast procedure.
C1 [Park, Hyunhee] INRIA, DIONYSOS Res Grp, Rennes, France.
   [Park, Seunghyun] Korea Univ, Ctr Informat Secur & Technol, Seoul, South Korea.
   [Shon, Taeshik] Ajou Univ, Div Informat & Comp Engn, Suwon 441749, South Korea.
   [Kim, Eui-Jik] Hallym Univ, Dept Ubiquitous Comp, Chuncheon Si 200702, Gangwon Do, South Korea.
C3 Inria; Universite de Rennes; Korea University; Ajou University; Hallym
   University
RP Kim, EJ (corresponding author), Hallym Univ, Dept Ubiquitous Comp, 39 Hallymdaehak Gil, Chuncheon Si 200702, Gangwon Do, South Korea.
EM ejkim32@hallym.ac.kr
RI Park, Hyunhee/F-5289-2017; Park, Seunghyun/AFH-6389-2022; Park,
   Seunghyun/AAO-9144-2021
OI Park, Hyunhee/0000-0003-3810-7367; Park, Seunghyun/0000-0001-5260-1252;
   Park, Seunghyun/0000-0001-5260-1252
FU Hallym University Research Fund [HRF-201402-009]; National Research
   Foundation of Korea [22A20130000118] Funding Source: Korea Institute of
   Science & Technology Information (KISTI), National Science & Technology
   Information Service (NTIS)
FX This research was supported by Hallym University Research Fund, 2014
   (HRF-201402-009).
CR [Anonymous], 2009, PROC IEEE VEH TECHNO
   [Anonymous], P IEEE 2013 STUDENTS
   [Anonymous], 2009, IEEE 802 15 WPAN MIL
   [Anonymous], 2012, IEEE Std 802.11ad-2012
   Cai LX, 2010, IEEE T WIREL COMMUN, V9, P113, DOI 10.1109/TWC.2010.01.070503
   Hou YT, 2007, IEEE T VEH TECHNOL, V56, P1333, DOI 10.1109/TVT.2007.895478
   Kim Y, 2010, IEICE T COMMUN, VE93B, P2808, DOI 10.1587/transcom.E93.B.2808
   Liu P, 2007, IEEE J SEL AREA COMM, V25, P340, DOI 10.1109/JSAC.2007.070210
   Park H, 2013, IEEE COMMUN LETT, V17, P616, DOI 10.1109/LCOMM.2013.011513.122519
   Park H, 2012, WIREL NETW, V18, P771, DOI 10.1007/s11276-012-0432-5
   Park H, 2011, KSII T INTERNET INF, V5, P1028, DOI 10.3837/tiis.2011.05.009
   Park H, 2011, IEICE ELECTRON EXPR, V8, P378, DOI 10.1587/elex.8.378
   Park H, 2011, IEEE T CONSUM ELECTR, V57, P28, DOI 10.1109/TCE.2011.5735477
   Park Y, 2006, P 2006 ODS C MONTR Q, P1
   Rong Peng, 2006, 2006 3rd Annual IEEE Communications Society Conference on Sensor and Ad Hoc Communications and Networks (IEEE Cat. No. 06EX1523), P374
   Shah SFA, 2010, IEEE T WIREL COMMUN, V9, P1044, DOI 10.1109/TWC.2010.03.081204
   Shen XM, 2005, IEEE T VEH TECHNOL, V54, P1663, DOI 10.1109/TVT.2005.853888
   Shihab E, 2009, IEEE T VEH TECHNOL, V58, P5124, DOI 10.1109/TVT.2009.2024085
   Singh S, 2007, IEEE INFOCOM SER, P2336, DOI 10.1109/INFCOM.2007.276
   Sun Y, 2013, INT J DISTRIB SENS N, V2013, P1
   Wang WD, 2005, LECT NOTES COMPUT SC, V3794, P580
   Wang X, 2004, VTC2004-FALL: 2004 IEEE 60TH VEHICULAR TECHNOLOGY CONFERENCE, VOLS 1-7, P5292
   Zhang HH, 2011, IEEE INFOCOM SER, P1107, DOI 10.1109/INFCOM.2011.5934886
NR 23
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 5
BP 1627
EP 1644
DI 10.1007/s11042-014-1959-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CC7UC
UT WOS:000350572900007
DA 2024-07-18
ER

PT J
AU Li, ZY
   Zhang, WQ
   Liu, J
AF Li, Zhi-Yi
   Zhang, Wei-Qiang
   Liu, Jia
TI Multi-resolution time frequency feature and complementary combination
   for short utterance speaker recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-resolution time frequency feature; I-vector; Complementary
   combination; Speaker recognition; Short utterance
ID JOINT FACTOR-ANALYSIS
AB A human speaker recognition expert often observes the speech spectrogram in multiple different scales for speaker recognition, especially under the short utterance condition. Inspired by this action, this paper proposes a novel multi-resolution time frequency feature (MRTF) extraction method, which is obtained by performing a 2-Dimensional discrete cosine transform (DCT) in multi-scale on the time frequency spectrogram matrix and then selecting and combining to the final multi-scaled transformed elements. Compared to the traditional Mel-Frequency Cepstral Coefficient (MFCC) feature extraction, the proposed method can make better use of multi-resolution temporal-frequency information. Beyond this, we also proposed three complementary combination strategies of MFCC and MRTF: in feature level, in i-vector level and in score level. Comparing their performance. We found the best results are obtained by combination in i-vector level. In the three NIST 2008 Speaker Recognition Evaluation datasets, the proposed method is the most effective for improving the performance under short utterance than under long utterance. And after the combination, we can achieve an EER of 11.32 % and MinDCF of 0.054 in the 10sec-10sec trials on the male dataset, which is an absolute 3 % improvement of EER than the best reported result in this field.
C1 [Li, Zhi-Yi; Zhang, Wei-Qiang; Liu, Jia] Tsinghua Univ, Dept Elect Engn, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Li, ZY (corresponding author), Tsinghua Univ, Dept Elect Engn, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
EM lizhiyi.china@gmail.com; wqzhang@tsinghua.edu.cn; liuj@tsinghua.edu.cn
RI Zhang, Wei-Qiang/A-7088-2008
FU National Natural Science Foundation of China [61370034, 61273268,
   61005019, 90920302]; Beijing Natural Science Foundation Program
   [KZ201110005005]
FX This work is supported by National Natural Science Foundation of China
   (Project 61370034, 61273268, 61005019, 90920302) and by Beijing Natural
   Science Foundation Program (Project KZ201110005005).
CR Ajmera Pawan K., 2009, Proceedings of the 2009 International Conference on Advances in Computing, Control, & Telecommunication Technologies (ACT 2009), P333, DOI 10.1109/ACT.2009.89
   Dehak N., 2009, ECOLE TECHNOLOGIE SU
   Dehak N, 2010, ODYSSEY 2010 THE SPE
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Dehak N, 2009, INT CONF ACOUST SPEE, P4237, DOI 10.1109/ICASSP.2009.4960564
   Hatch AO, 2006, NINTH INTERNATIONAL
   Impedovo D, 2012, EXPERT SYST, V29, P442, DOI 10.1111/j.1468-0394.2011.00603.x
   Jayanna HS, 2010, SADHANA-ACAD P ENG S, V35, P525, DOI 10.1007/s12046-010-0043-8
   Kanagasundaram A., 2011, INTERSPEECH 2011 12, V2011, P2341
   Kenny P, 2005, IEEE T SPEECH AUDI P, V13, P345, DOI 10.1109/TSA.2004.840940
   Kenny P, 2007, IEEE T AUDIO SPEECH, V15, P1435, DOI 10.1109/TASL.2006.881693
   Kenny P, 2007, IEEE T AUDIO SPEECH, V15, P1448, DOI 10.1109/TASL.2007.894527
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Li ZY, 2012, ODYSSEY 2012 THE SPE
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Mclaren M, 2010, ODYSSEY 2012 THE SPE
   NIST, 2008, THE NIST YEAR 2008 S
   Pelecanos J, 2001, ODYSSEY 2001 THE SPE
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Shan YX, 2011, MULTIMED TOOLS APPL, V52, P159, DOI 10.1007/s11042-009-0456-8
   Stafylakis T., 2012, INTERSPEECH
   Zhang WQ, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2122
   Zhang WQ, 2011, IEEE T AUDIO SPEECH, V19, P266, DOI 10.1109/TASL.2010.2047680
   Zhi-Yi Li, 2010, Proceedings 7th International Symposium on Chinese Spoken Language Processing (ISCSLP 2010), P318, DOI 10.1109/ISCSLP.2010.5684885
NR 24
TC 16
Z9 17
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 3
BP 937
EP 953
DI 10.1007/s11042-013-1705-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZO
UT WOS:000349356400013
DA 2024-07-18
ER

PT J
AU Tsai, TH
   Huang, YS
   Liu, PY
   Chen, DM
AF Tsai, Tsung-Han
   Huang, Yu-Siang
   Liu, Pei-Yun
   Chen, De-Ming
TI Content-based singer classification on compressed domain audio data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MP3; MDCT; MFCC; GMM
AB In this paper, we proposed a singer identification approach to automatically identify the singer of an unknown MP3 audio data. Differing from previous researches for singer identification in MP3 compressed domain, we use Mel-Frequency Cepstral Coefficients (MFCC) as the feature instead of MDCT (modified discrete cosine transform) coefficients. Although MFCC is often used in music classification and speaker recognition, it cannot be directly obtained from compressed music data such as MP3 format. We introduce a modified method for calculating MFCC vector in MP3 compressed domain. For describing the distribution of MFCC vector, the Gaussian mixture model (GMM) is applied. To find the nearest singer, we use maximum likelihood classification (MLC) to allot each input MFCC vector to its nearest group. The experimental result verifies the feasibility of the proposed approach.
C1 [Tsai, Tsung-Han; Huang, Yu-Siang; Liu, Pei-Yun; Chen, De-Ming] Natl Cent Univ, Dept Elect Engn, Jhongli 32001, Taoyuan County, Taiwan.
C3 National Central University
RP Liu, PY (corresponding author), Natl Cent Univ, Dept Elect Engn, 300 Jhongda Rd, Jhongli 32001, Taoyuan County, Taiwan.
EM han@dsp.ee.ncu.edu.tw; huangsh@dsp.ee.ncu.edu.tw;
   daisyliu@dsp.ee.ncu.edu.tw; chen0327@dsp.ee.ncu.edu.tw
CR Abesser J., 2009, P ISMIR, P453
   [Anonymous], 2006, P ISMIR VICT CAN
   [Anonymous], AUDIO SIGNAL PROCESS
   Bouman C.A., 2005, CLUSTER UNSUPERVISED
   Cai Wei, 2011, P 7 INT C NAT COMP
   Chang Liao-yu, 2009, Journal of Computer Applications, V29, P1188, DOI 10.3724/SP.J.1087.2009.01188
   Chih-Chin Liu, 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P506
   Chin-Chin Liu, 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P438
   Gu HY, 2008, P 13 TAIW ASS ART IN
   Hasan MR, 2004, P 3 INT C EL COMP EN, P566
   Jadhav1 Suraj, 2013, INT J EMERGING TECHN
   Jia YH, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P381
   Jiao Y. H., P IEEE WORKSH MULT S, P381
   Khine SZK, 2008, LECT NOTES COMPUT SC, V4969, P159
   Langlois T, 2009, P 1 INT C ADV MULT
   Langlois T., 2009, ISMIR, P81
   Lidy T, 2005, P 6 INT C MUS INF RE, P34
   Lie WN, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P929
   Logan B., 2000, ISMIR, V270, P11
   Maddage NC, 2004, INT C PATT RECOG, P375, DOI 10.1109/ICPR.2004.1334225
   Mesaros A, 2005, P 6 INT C MUS INF RE
   Mesaros Annamaria., 2007, P 8 INT C MUSIC INFO, P375
   moo Young, ISMIR 2002
   Nwe Tin Lay, ISMIR 2004, P138
   Panagakis I., 2008, ISMIR, P583
   Panagakis Y., 2009, P INT SOC MUSIC INFO, P249
   Patil H.A., AS LANG PROC IALP 20
   Peng X, 2005, PROCEEDINGS OF THE 2005 IEEE INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND KNOWLEDGE ENGINEERING (IEEE NLP-KE'05), P111
   Pye D., 2000, P IEEE INT C AC SPEE, P24
   Shen J., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P59, DOI 10.1145/1148170.1148184
   Sridhar1 R., COMP EL ENG 2008 ICC
   Tsai W.-H., 2008, P 9 INT S MUS INF RE, P115
   Tsai WH, 2006, IEEE T AUDIO SPEECH, V14, P330, DOI 10.1109/TSA.2005.854091
   Wang Y, 2000, 2000 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I-III, P44
   Zhang T., 2003, ICME, V1
   Zhen Chao, 2010, P 3 IEEE INT C COMP
NR 36
TC 2
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 4
BP 1489
EP 1509
DI 10.1007/s11042-014-2189-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZN
UT WOS:000349356300017
DA 2024-07-18
ER

PT J
AU Khil, AR
   Lee, KH
AF Khil, A-Ra
   Lee, Kang-Hee
TI Optimization of a robot-served cart capacity using the three-dimensional
   single bin packing problem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Three-dimensional single bin packing problem; Three-dimensional knapsack
   problem; Serving robot; Optimization; Cart; Tray
AB Given a set of rectangular-shaped items such as dishes, cups, saucers, or forks and a rectangular tray of a cart, the three-dimensional single bin packing problem (3D-BPP) involves orthogonally packing a subset of the items within the tray. If the value of an item is given by its volume, the objective is to maximize the covered volume of the tray. Thus, this paper aims to optimize the transport capacity of a serving robot carrying a cart. This experiment, the first of its type, proves the feasibility of this endeavor efficiently.
C1 [Khil, A-Ra] Soongsil Univ, Sch Comp Sci & Engn, Coll Informat Technol, Seoul, South Korea.
   [Lee, Kang-Hee] Soongsil Univ, Global Sch Media, Coll Informat Technol, Seoul, South Korea.
C3 Soongsil University; Soongsil University
RP Lee, KH (corresponding author), Soongsil Univ, Global Sch Media, Coll Informat Technol, 511 Sangdo Dong, Seoul, South Korea.
EM ara@ssu.ac.kr; kanghee.lee@ssu.ac.kr
FU National Research Foundation of Korea - Korean Government
   [NRF-2013-S1A5A8020988]
FX This research was supported by the National Research Foundation of Korea
   Grant funded by the Korean Government (NRF-2013-S1A5A8020988).
CR BERKEY JO, 1987, J OPER RES SOC, V38, P423, DOI 10.2307/2582731
   CHUNG FRK, 1982, SIAM J ALGEBRA DISCR, V3, P66, DOI 10.1137/0603007
   Kuffner J., 2010, P HUM ROB HUM 2010 1
   Martello S, 1998, MANAGE SCI, V44, P388, DOI 10.1287/mnsc.44.3.388
   Martello S, 2000, OPER RES, V48, P256, DOI 10.1287/opre.48.2.256.12386
NR 5
TC 1
Z9 1
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 1
BP 185
EP 198
DI 10.1007/s11042-013-1843-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ6UP
UT WOS:000348356300012
DA 2024-07-18
ER

PT J
AU Wang, JJY
   Sun, YJ
   Gao, X
AF Wang, Jim Jing-Yan
   Sun, Yijun
   Gao, Xin
TI Sparse structure regularized ranking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia database retrieval; Ranking score; Sparse representation
ID LOCAL BINARY PATTERNS; INFORMATION-RETRIEVAL; ROC CURVE; AREA;
   SEMANTICS; CLASSIFICATION; ALGORITHM
AB Learning ranking scores is critical for the multimedia database retrieval problem. In this paper, we propose a novel ranking score learning algorithm by exploring the sparse structure and using it to regularize ranking scores. To explore the sparse structure, we assume that each multimedia object could be represented as a sparse linear combination of all other objects, and combination coefficients are regarded as a similarity measure between objects and used to regularize their ranking scores. Moreover, we propose to learn the sparse combination coefficients and the ranking scores simultaneously. A unified objective function is constructed with regard to both the combination coefficients and the ranking scores, and is optimized by an iterative algorithm. Experiments on two multimedia database retrieval data sets demonstrate the significant improvements of the propose algorithm over state-of-the-art ranking score learning algorithms.
C1 [Wang, Jim Jing-Yan] SUNY Buffalo, New York State Ctr Excellence Bioinformat & Life, Buffalo, NY 14203 USA.
   [Wang, Jim Jing-Yan] Soochow Univ, Prov Key Lab Comp Informat Proc Technol, Suzhou 215006, Peoples R China.
   [Sun, Yijun] SUNY Buffalo, Dept Biostat, Dept Comp Sci & Engn, Dept Microbiol & Immunol, Buffalo, NY 14203 USA.
   [Gao, Xin] KAUST, Comp Elect & Math Sci & Engn Div, Thuwal 239556900, Saudi Arabia.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Buffalo; Soochow University - China; State University of New York
   (SUNY) System; State University of New York (SUNY) Buffalo; King
   Abdullah University of Science & Technology
RP Wang, JJY (corresponding author), SUNY Buffalo, New York State Ctr Excellence Bioinformat & Life, Buffalo, NY 14203 USA.
EM jimjywang@gmail.com; yijunsun@buffalo.edu; xin.gao@kaust.edu.sa
RI Gao, Xin/D-5487-2013
OI Gao, Xin/0000-0002-7108-3574
FU US National Science Foundation [DBI-1062362]; Provincial Key Laboratory
   for Computer Information Processing Technology, Soochow University,
   China; King Abdullah University of Science and Technology (KAUST), Saudi
   Arabia; Direct For Biological Sciences; Div Of Biological Infrastructure
   [1322212] Funding Source: National Science Foundation
FX Jim Jing-Yan Wang and Yijun Sun are in part supported by US National
   Science Foundation under grant No. DBI-1062362. The study is supported
   by grants from Provincial Key Laboratory for Computer Information
   Processing Technology, Soochow University, China, and King Abdullah
   University of Science and Technology (KAUST), Saudi Arabia.
CR Agichtein E., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P19, DOI 10.1145/1148170.1148177
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Bian W, 2010, IEEE T IMAGE PROCESS, V19, P545, DOI 10.1109/TIP.2009.2035223
   Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   BREU H, 1995, IEEE T PATTERN ANAL, V17, P529, DOI 10.1109/34.391389
   Clausi DA, 2000, PATTERN RECOGN, V33, P1835, DOI 10.1016/S0031-3203(99)00181-8
   Cook NR, 2007, CIRCULATION, V115, P928, DOI 10.1161/CIRCULATIONAHA.106.672402
   Davis Jesse, 2006, P 23 INT C MACH LEAR, P233, DOI [DOI 10.1145/1143844.1143874, 10.1145/1143844.1143874]
   De Maesschalck R, 2000, CHEMOMETR INTELL LAB, V50, P1, DOI 10.1016/S0169-7439(99)00047-7
   DING K., 2013, Computer Vision ACCV 2012, P536
   Euzenat J, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P348
   Feng D., 2003, Multimedia Information Retrieval and Management: Technological Fundamentals and Applications
   FORTI M, 1995, IEEE T CIRCUITS-I, V42, P354, DOI 10.1109/81.401145
   Gao XB, 2008, PATTERN RECOGN, V41, P3179, DOI 10.1016/j.patcog.2008.03.025
   Grigorescu SE, 2002, IEEE T IMAGE PROCESS, V11, P1160, DOI 10.1109/TIP.2002.804262
   Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   Haveliwala TH, 2003, IEEE T KNOWL DATA EN, V15, P784, DOI 10.1109/TKDE.2003.1208999
   He R, 2010, AAAI CONF ARTIF INTE, P475
   Hiremath PS, 2007, ADCOM 2007: PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATIONS, P780, DOI 10.1109/ADCOM.2007.21
   Hotho A, 2006, LECT NOTES COMPUT SC, V4011, P411
   Huang YJ, 2005, J AM CHEM SOC, V127, P1665, DOI 10.1021/ja047109h
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Kapela R, 2007, J SYST ARCHITECT, V53, P602, DOI 10.1016/j.sysarc.2006.12.004
   Kim JH, 2011, INT J INNOV COMPUT I, V7, P6289
   Kim YW, 2004, PATTERN RECOGN LETT, V25, P1243, DOI 10.1016/j.patrec.2004.04.002
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1021, DOI 10.1109/TMM.2012.2187179
   Mangai MA, 2013, COMPUT ELECTR ENG, V39, P809, DOI 10.1016/j.compeleceng.2013.01.004
   Momoh JA, 1999, IEEE T POWER SYST, V14, P105, DOI 10.1109/59.744495
   Myerson J, 2001, J EXP ANAL BEHAV, V76, P235, DOI 10.1901/jeab.2001.76-235
   Naphade MR, 2002, IEEE T NEURAL NETWOR, V13, P793, DOI 10.1109/TNN.2002.1021881
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6
   Pass G, 1996, HISTOGRAM REFINEMENT, P96
   PASS G, 1996, COMPARING IMAGES USI, P65
   Pencina MJ, 2008, STAT MED, V27, P157, DOI 10.1002/sim.2929
   Perkins NJ, 2006, AM J EPIDEMIOL, V163, P670, DOI 10.1093/aje/kwj063
   Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Wang JJY, 2014, NEURAL NETWORKS, V51, P9, DOI 10.1016/j.neunet.2013.11.009
   Wang JJY, 2013, KNOWL-BASED SYST, V54, P199, DOI 10.1016/j.knosys.2013.09.004
   Wang JJY, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-307
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang M, 2013, IEEE T IMAGE PROCESS, V22, P1395, DOI 10.1109/TIP.2012.2231088
   Yanagawa A., 2006, BRIEF DESCRIPTIONS V
   Yang Y, 2009, RANKING LOCAL REGRES, P175
   Yang Y, 2008, IEEE T MULTIMEDIA, V10, P437, DOI 10.1109/TMM.2008.917359
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yisong Yue, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P271
   YuJie L, 2013, INT ARAB J INF TECH, V10
   Zhang DS, 2003, MULTIMEDIA SYST, V9, P15, DOI 10.1007/s00530-002-0075-y
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhou DY, 2004, ADV NEUR IN, V16, P169
   Zhu XF, 2013, ACM T INFORM SYST, V31, DOI 10.1145/2457465.2457469
   Zhu XF, 2013, PATTERN RECOGN, V46, P215, DOI 10.1016/j.patcog.2012.07.018
   Zhuang YT, 2008, IEEE T MULTIMEDIA, V10, P221, DOI 10.1109/TMM.2007.911822
NR 57
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 2
BP 635
EP 654
DI 10.1007/s11042-014-1939-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ8DP
UT WOS:000348445300018
DA 2024-07-18
ER

PT J
AU Yahya, AA
   Tan, JQ
   Hu, M
AF Yahya, Ali Abdullah
   Tan, Jieqing
   Hu, Min
TI A blending method based on partial differential equations for image
   denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Isotropic diffusion (ID) model; PM model; TV model; image features
ID EDGE-DETECTION; DIFFUSION; MIXTURES; WAVELETS; SPACE
AB In this paper we proposed a new de-noising technique based on combination of isotropic diffusion model, anisotropic diffusion (PM) model, and total variation model. The proposed model is able to be adaptive in each region depending on the information of the image. More precisely, the model performs more diffusion in the flat areas of the image, and less diffusion in the edges of the image. And so we can get rid of the noise, and preserve the edges of the image simultaneously. To verify that, we did several experiments, which showed that our algorithm is the best method for edge preserving and noise removing, compared with the isotropic diffusion, anisotropic diffusion, and total variation methods.
C1 [Yahya, Ali Abdullah; Tan, Jieqing; Hu, Min] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China.
C3 Hefei University of Technology
RP Yahya, AA (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China.
EM aselwey1@hotmail.com; jieqingtan@yahoo.com.cn; uhnim@163.com
RI Hu, Min/HLH-2112-2023; Tan, Jie/IVV-5250-2023
FU NSFC-Guangdong Joint Foundation (Key Project) [U1135003]; National
   Natural Science Foundation of China [61070227]
FX This work is supported by the NSFC-Guangdong Joint Foundation (Key
   Project) under Grant No. U1135003 and the National Natural Science
   Foundation of China under Grant No. 61070227.
CR Andreu F, 2005, ASYMPTOTIC ANAL, V43, P9
   Aubert G., 2006, MATH PROBLEMS IMAGE
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Bijaoui A, 2002, SIGNAL PROCESS, V82, P709, DOI 10.1016/S0165-1684(02)00137-8
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1522, DOI 10.1109/83.862630
   Chatterjee P, 2010, IEEE T IMAGE PROCESS, V19, P895, DOI 10.1109/TIP.2009.2037087
   Gallouët T, 2004, CR MATH, V338, P81, DOI 10.1016/j.crma.2003.11.024
   Garamendi JF, 2013, IEEE T IMAGE PROCESS, V22, P2030, DOI 10.1109/TIP.2013.2244220
   Gilboa G, 2002, IEEE T IMAGE PROCESS, V11, P689, DOI 10.1109/TIP.2002.800883
   Guo ZC, 2012, IEEE T IMAGE PROCESS, V21, P958, DOI 10.1109/TIP.2011.2169272
   Jing Liu, 2011, 2011 International Conference on Multimedia Technology, P1892
   Kanagaraj K., 2010, SERBIAN J ELECT ENG, V7, P1, DOI [10.2298/SJEE1001081K, DOI 10.2298/SJEE1001081K]
   Li F, 2011, J INFORM COMPUT SCI, V8, P3819
   Lysaker M, 2006, INT J COMPUT VISION, V66, P5, DOI 10.1007/s11263-005-3219-7
   Lysaker M, 2004, IEEE T IMAGE PROCESS, V13, P1345, DOI 10.1109/TIP.2004.834662
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Mendrik AM, 2009, IEEE T MED IMAGING, V28, P1585, DOI 10.1109/TMI.2009.2022368
   Perona P., 1988, 1988 IEEE International Symposium on Circuits and Systems. Proceedings (Cat. No.88CH2458-8), P2565, DOI 10.1109/ISCAS.1988.15465
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Perona P, 1987, P IEEE COMP SOC WORK
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Ram I, 2011, IEEE T SIGNAL PROCES, V59, P4199, DOI 10.1109/TSP.2011.2158428
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Scherzer O, 2000, J MATH IMAGING VIS, V12, P43, DOI 10.1023/A:1008344608808
   Sorzano COS, 2006, PATTERN RECOGN, V39, P1205, DOI 10.1016/j.patcog.2005.12.009
   Tikhonov A., 1977, Solution of Ill-Posed Problems
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   Witkin A.P., 1983, P INT JOINT C ART IN, P1019, DOI DOI 10.1007/978-3-8348-9190-729
   Yahya AA, 2012, P 4 IEEE INT C DIG H, P46
   Zhu L, 2011, 2011 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTATION AND INDUSTRIAL APPLICATION (ICIA2011), VOL III, P1
NR 32
TC 22
Z9 24
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1843
EP 1862
DI 10.1007/s11042-013-1586-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200033
DA 2024-07-18
ER

PT J
AU Alcoverro, M
   Suau, X
   Morros, JR
   López-Méndez, A
   Gil, A
   Ruiz-Hidalgo, J
   Casas, JR
AF Alcoverro, Marcel
   Suau, Xavier
   Morros, Josep R.
   Lopez-Mendez, Adolfo
   Gil, Albert
   Ruiz-Hidalgo, Javier
   Casas, Josep R.
TI Gesture control interface for immersive panoramic displays
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactivity; Panoramic display; Human-machine interfaces
ID RECOGNITION
AB In this paper, we propose a gesture-based interface designed to interact with panoramic scenes. The system combines novel static gestures with a fast hand tracking method. Our proposal is to use static gestures as shortcuts to activate functionalities of the system (i.e. volume up/down, mute, pause, etc.), and hand tracking to freely explore the panoramic video. The overall system is multi-user, and incorporates a user identification module based on face recognition, which is able both to recognize returning users and to add new users online. The system exploits depth data, making it robust to challenging illumination conditions. We show through experimental results the performance of every component of the system compared to the state of the art. We also show the results of a usability study performed with several untrained users.
C1 [Alcoverro, Marcel; Suau, Xavier; Morros, Josep R.; Lopez-Mendez, Adolfo; Gil, Albert; Ruiz-Hidalgo, Javier; Casas, Josep R.] Univ Politecn Cataluna, Dept Signal Theory & Commun, Barcelona, Spain.
C3 Universitat Politecnica de Catalunya
RP Suau, X (corresponding author), Univ Politecn Cataluna, Dept Signal Theory & Commun, Barcelona, Spain.
EM marcel.alcoverro@upc.edu; xavier.suau@upc.edu; ramon.morros@upc.edu;
   albert.gil@upc.edu; j.ruiz@upc.edu; josep.ramon.casas@upc.edu
RI Ruiz-Hidalgo, Javier/F-8137-2013; Morros, Josep Ramon/F-8227-2013;
   Casas, Josep R./A-2851-2010
OI Morros, Josep Ramon/0000-0002-1395-487X; Casas, Josep
   R./0000-0003-4639-6904
FU European Union [248138]; Spanish Ministerio de Ciencia e Innovacion
   [TEC2010-18094]
FX The research leading to these results has received funding from the
   European Union's Seventh Framework Programme (FP7/2007-2013) under grant
   agreement no. 248138. This work has been partially supported by the
   Spanish Ministerio de Ciencia e Innovacion, under project TEC2010-18094.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], P ICCV
   Bhuiyan M., 2011, J. Softw. Eng. Appl., V4, P513
   Bradski G., 2000, Opencv. Dr. Dobb's journal of software tools
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Demirdjian David., 2009, Proceedings of the 2009 International Conference on Multimodal Inter-faces, P293
   Duda R. O., 2001, PATTERN CLASSIFICATI, P517
   Francese R, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P116, DOI 10.1145/2254556.2254580
   Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745
   Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   Lausberg H, 2009, BEHAV RES METHODS, V41, P841, DOI 10.3758/BRM.41.3.841
   Liu JY, 2009, PERVASIVE MOB COMPUT, V5, P657, DOI 10.1016/j.pmcj.2009.07.007
   Lopez-Mendez A, 2012, P 9 EUR C VIS MED PR, P18, DOI [10.1145/2414688.2414691, DOI 10.1145/2414688.2414691]
   Nielsen M, 2003, LECT NOTES ARTIF INT, V2915, P409
   Norman Donald A., 2010, interactions, V17, P6, DOI [DOI 10.1145/1744161.1744163, 10.1145/1744161.1744163]
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Potamianos G., 2004, ISSUES VISUAL AUDIO
   Pugeault N, 2011, ICCV CDC4CV
   Ren Z., 2011, P 19 ACM INT C MULTI, P1093
   Schlmer T., 2008, Second International Conference on Tangible and Embedded Interaction, P11, DOI [DOI 10.1145/1347390.1347395, 10.1145/1347390.1347395]
   Sebe N, 2009, J AMB INTEL SMART EN, V1, P23, DOI 10.3233/AIS-2009-0003
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Stern HI, 2008, INT J SEMANT COMPUT, V2, P137, DOI 10.1142/S1793351X08000385
   Suau X, 2012, IEEE T MULTIMEDIA, V1, P1
   Turk M., 2001, Handbook of Virtual Environment Technology
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wachs JP, 2011, COMMUN ACM, V54, P60, DOI 10.1145/1897816.1897838
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhu ZW, 2005, COMPUT VIS IMAGE UND, V98, P124, DOI 10.1016/j.cviu.2004.07.012
   Zigfu, MOT CONTR WEB
NR 33
TC 6
Z9 8
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 491
EP 517
DI 10.1007/s11042-013-1605-7
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700024
OA Green Published
DA 2024-07-18
ER

PT J
AU Han, J
   Choi, N
   Chung, T
   Kwon, TT
   Choi, Y
AF Han, Jinyoung
   Choi, Nakjung
   Chung, Taejoong
   Kwon, Ted Taekyoung
   Choi, Yanghee
TI A target-centric surveillance system based on localization and social
   networking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surveillance system; Diary service; Video content; Social networking;
   Localization
AB Surveillance systems are developed to enhance security and safety by constantly observing locations of interest. Although those systems can observe scenes of individual cameras separately, it is difficult to figure out what happened to the target moving across multiple cameras. This paper first proposes Video Diary Service (VDS) to solve this problem. VDS is an automatic video-oriented diary service, which keeps track of users' lives. In addition, VDS can identify social networking relationships among the users, as well as record videos of the users. By exploiting these properties of VDS, we extend VDS into a new surveillance system called S-VDS. S-VDS is a target-centric surveillance system which focuses on the target, not the area, with its comprehensive information including the location, time, social relationship, and preferences. We then develop the basic functions of the proposed system and demonstrate its feasibility. We also illustrate three applications (i.e., a remote healthcare system, an anti-crime system, and a system for finding missing children), where the proposed system can enhance security and safety by considering individual surveillance purposes.
C1 [Han, Jinyoung; Chung, Taejoong; Kwon, Ted Taekyoung; Choi, Yanghee] Seoul Natl Univ, Sch Comp Sci & Engn, Seoul, South Korea.
   [Choi, Nakjung] Alcatel Lucent, Bell Labs, Networking, Seoul, South Korea.
C3 Seoul National University (SNU); Alcatel-Lucent
RP Han, J (corresponding author), Seoul Natl Univ, Sch Comp Sci & Engn, Seoul, South Korea.
EM jyhan@mmlab.snu.ac.kr; nakjung.choi@alcatel-lucent.com;
   tjchung@mmlab.snu.ac.kr; tkkwon@snu.ac.kr; yhchoi@snu.ac.kr
FU KCC (Korea Communications Commission), Korea [KCA-2012-11-911-05-002];
   Seoul R&BD Program by Seoul Metropolitan Government [WR080951]
FX We would like to thank Jihoon Lee, Xiaofei Wang, Yongrok Kim, Mingu Cho,
   Wonyoung Kwak, Shinhaeng Oh, and Hyeseok Oh for their help in developing
   the proposed system and demonstrating its feasibility. This work was
   supported by the KCC (Korea Communications Commission), Korea, under the
   R&D program supervised by the KCA (Korea Communications Agency)
   (KCA-2012-11-911-05-002) and Seoul R&BD Program (WR080951) by Seoul
   Metropolitan Government. The ICT at Seoul National University provides
   research facilities.
CR Becker J.V., 1986, J FAM VIOLENCE, V1, P85
   Best J., 1990, THREATENED CHILDREN
   Chen CD, 2010, PAC RIM C MULT PCM 2
   Chen HC, 2005, IEEE INTELL SYST, V20, P12
   Chen MY, 2006, INT C UB COMP UBICOM
   Cheng YC, 2005, ACM INT C MOB SYST A
   Fong ACM, 2001, COMPUT CONTROL ENG J, V12, P263, DOI 10.1049/cce:20010603
   Han J, 2010, IEEE PERVAS COMPUT, V9, P20, DOI 10.1109/MPRV.2010.6
   Hjelmås E, 2001, COMPUT VIS IMAGE UND, V83, P236, DOI 10.1006/cviu.2001.0921
   Hodges S, 2006, INT C UB COMP UBICOM
   Hossain SKA, 2011, IEEE INT CON MULTI
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Lerner JS, 2003, PSYCHOL SCI, V14, P144, DOI 10.1111/1467-9280.01433
   Li LY, 2008, IEEE T SYST MAN CY B, V38, P1254, DOI 10.1109/TSMCB.2008.927265
   Räty TD, 2010, IEEE T SYST MAN CY C, V40, P493, DOI 10.1109/TSMCC.2010.2042446
   Saini M, 2011, P INT C MULT EXP, P1
   Tseng YC, 2007, COMPUTER, V40, P60, DOI 10.1109/MC.2007.211
   Valera M, 2005, IEE P-VIS IMAGE SIGN, V152, P192, DOI 10.1049/ip-vis:20041147
   Zhang Y, 2007, INT S LOC CONT AW LO
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 20
TC 2
Z9 3
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 241
EP 265
DI 10.1007/s11042-012-1285-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700012
DA 2024-07-18
ER

PT J
AU Han, YC
   Han, BJ
AF Han, Yoon Chung
   Han, Byeong-jun
TI Virtual pottery: a virtual 3D audiovisual interface using natural hand
   motions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio sonification; Virtual pottery; Virtual musical instrument; Hand
   gesture recognition
AB In this paper, we present our approach towards designing and implementing a virtual 3D sound sculpting interface that creates audiovisual results using hand motions in real time. In the interface "Virtual Pottery," we use the metaphor of pottery creation in order to adopt the natural hand motions to 3D spatial sculpting. Users can create their own pottery pieces by changing the position of their hands in real time, and also generate 3D sound sculptures based on pre-existing rules of music composition. The interface of Virtual Pottery can be categorized by shape design and camera sensing type. This paper describes how we developed the two versions of Virtual Pottery and implemented the technical aspects of the interfaces. Additionally, we investigate the ways of translating hand motions into musical sound. The accuracy of the detection of hand motions is crucial for translating natural hand motions into virtual reality. According to the results of preliminary evaluations, the accuracy of both motion-capture tracking system and portable depth sensing camera is as high as the actual data. We carried out user studies, which took into account information about the two exhibitions along with the various ages of users. Overall, Virtual Pottery serves as a bridge between the virtual environment and traditional art practices, with the consequence that it can lead to the cultivation of the deep potential of virtual musical instruments and future art education programs.
C1 [Han, Yoon Chung] Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA.
   [Han, Byeong-jun] Korea Univ, Sch Elect Engn, Seoul, South Korea.
C3 University of California System; University of California Santa Barbara;
   Korea University
RP Han, YC (corresponding author), Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA.
EM yoon@mat.ucsb.edu; hbj1147@korea.ac.kr
FU TransLab, University of California, Santa Barbara (UCSB)
FX These works have been supported by TransLab, University of California,
   Santa Barbara (UCSB), under the guidance of Prof. Marcos Novak.
CR [Anonymous], 2001, P 2001 S INT 3D GRAP
   Beyer, 2011, P INT C NEW INT MUS
   Blake A., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P185, DOI 10.1145/192161.192197
   Cani Marie-Paule, 2006, ACM SIGGRAPH 2006 CO, P67, DOI [10.1145/1185657.1185676, DOI 10.1145/1185657.1185676]
   Costa L. da F., 2001, SHAPE ANAL CLASSIFIC
   Han Y, 2012, P 12 INT C NEW INT M
   Holz C, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P811
   Ip HHS, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P46, DOI 10.1109/MMMC.2005.32
   Ip HHS, 2005, P 2005 ACM SIGCHI IN, P342
   Kameyama K., 1997, VRST'97. ACM Symposium on Virtual Reality Software and Technology 1997, P197, DOI 10.1145/261135.261171
   Knopf GK, 2005, ROBOT CIM-INT MANUF, V21, P302, DOI 10.1016/j.rcim.2004.11.002
   Korida K, 1997, INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA - VSMM'97, PROCEEDINGS, P227, DOI 10.1109/VSMM.1997.622351
   Lee J, 2008, LECT NOTES COMPUT SC, V5024, P668
   Levin G., 2005, P 2005 C NEW INT MUS, P115
   Mulder, 1998, P W COMP GRAPH S
   Vinayak Murugappan S., 2012, P ASME 2012 INT DES
   Young Diana, 2002, P 2002 C NEW INSTR M
NR 17
TC 18
Z9 19
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 917
EP 933
DI 10.1007/s11042-013-1382-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700018
DA 2024-07-18
ER

PT J
AU Lee, MH
   Rho, S
   Choi, EI
AF Lee, Moo-Hun
   Rho, Seungmin
   Choi, Eui-In
TI Ontology based user query interpretation for semantic multimedia
   contents retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic search; Ontology; Knowledge base; Query interpretation
ID SEARCH
AB Users who are familiar with the existing keyword-based search have problems of not being able to configure the formal query because they don't have generic knowledge on knowledge base when using the semantic-based retrieval system. User wants the search results which are more accurate and match the user's search intents with the existing keyword-based search and the same search keyword without the need to recognize what technology the currently used retrieval system is based on to provide the search results. In order to do the semantic analysis of the ambiguous search keyword entered by users who are familiar with the existing keyword-based search, ontological knowledge base constructed based on refined meta-data is necessary, and the keyword semantic analysis technique which reflects user's search intents from the well-established knowledge base and can generate accurate search results is necessary. In this paper, therefore, by limiting the knowledge base construction to multimedia contents meta-data, the applicable prototype has been implemented and its performance in the same environment as Smart TV has been evaluated. Semantic analysis of user's search keyword is done, evaluated and recommended through the proposed ontological knowledge base framework so that accurate search results that match user's search intents can be provided.
C1 [Lee, Moo-Hun] Elect & Telecommun Res Inst, Taejon, South Korea.
   [Rho, Seungmin] Sungkyul Univ, Dept Multimedia, Anyang Si, South Korea.
   [Choi, Eui-In] Hannam Univ, Dept Comp Engn, Taejon, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Sungkyul University; Hannam University
RP Choi, EI (corresponding author), Hannam Univ, Dept Comp Engn, Taejon, South Korea.
EM smrho@sungkyul.edu; eichoi@hnu.kr
RI Rho, Seungmin/HTP-6683-2023
FU Ministry of Education, Science Technology (MEST); National Research
   Foundation of Korea(NRF) through the Human Resource Training Project for
   Regional Innovation
FX This research was financially supported by the Ministry of Education,
   Science Technology (MEST) and National Research Foundation of Korea(NRF)
   through the Human Resource Training Project for Regional Innovation
CR [Anonymous], P SEM KNOWL MAN SEM
   Chen, 2010, P 11 INT C WEB INF S
   D-G Lee, 2011, J KOREAN I INF TECHN, V9, P187
   El Sayad I, 2012, MULTIMED TOOLS APPL, V60, P455, DOI 10.1007/s11042-010-0596-x
   J-m Kim, 2011, J KOREAN I INF TECHN, V9, P161
   Lei YG, 2006, LECT NOTES ARTIF INT, V4248, P238
   Parthasarathy K, 2011, P INT WORLD WID WEB
   Rotter P, 2012, MULTIMED TOOLS APPL, V60, P573, DOI 10.1007/s11042-011-0828-8
   Tran T, 2007, LNCS, V4825, P238
   Tran T, 2007, LECT NOTES COMPUT SC, V4825, P523
   Tran T, 2009, LECT NOTES ARTIF INT, V5662, P48, DOI 10.1007/978-3-642-03079-6_5
   Tran T, 2009, PROC INT CONF DATA, P405, DOI 10.1109/ICDE.2009.119
   Wang HF, 2008, LECT NOTES COMPUT SC, V5021, P584
   Zhou Q, 2007, LECT NOTES COMPUT SC, V4825, P694
NR 14
TC 6
Z9 7
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 901
EP 915
DI 10.1007/s11042-013-1383-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700017
DA 2024-07-18
ER

PT J
AU Al Osman, H
   Eid, M
   El Saddik, A
AF Al Osman, Hussein
   Eid, Mohamad
   El Saddik, Abdulmotaleb
TI U-biofeedback: a multimedia-based reference model for ubiquitous
   biofeedback systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biofeedback; Multimedia health systems; Heart rate variability; Stress
   management; Health monitoring; Occupancy-based services
ID HEART-RATE-VARIABILITY; PSYCHOLOGICAL STRESS; MENTAL STRESS; RELAXATION;
   SYMPTOMS; BODY
AB Biofeedback is a well-accepted approach in preventative and alternative healthcare. It is known to promote wellbeing and help prevent and treat a wide variety of disorders related to the human physiology and psychology. With the exceptional growth of wearable sensor technologies, the potential for devising biofeedback systems that blend into everyday living is immense. Therefore, we present our vision for U-Biofeedback, a reference model for systems designed to continuously monitor our physiology and convey to us important messages regarding our status. Also, we present a case study for an application that implements our reference model. The application is designed to monitor the stress of individuals working in an office setting and provide an assistive response whenever stress reaches elevated levels. By devising an algorithm for stress detection that makes use of Heart Rate Variability (HRV) measures, we were able to identify negative stress situations with an accuracy of 89.63 % and a false positive detection rate of 5.55 % during our evaluation.
C1 [Al Osman, Hussein; El Saddik, Abdulmotaleb] Univ Ottawa, Multimedia Commun Res Lab, Ottawa, ON, Canada.
   [Eid, Mohamad; El Saddik, Abdulmotaleb] New York Univ Abu Dhabi, Div Engn, Abu Dhabi, U Arab Emirates.
C3 University of Ottawa; New York University Abu Dhabi
RP El Saddik, A (corresponding author), Univ Ottawa, Multimedia Commun Res Lab, 550 Cumberland, Ottawa, ON, Canada.
EM halos072@uottawa.ca; Mohamad.eid@nyu.edu; elsaddik@site.uottawa.ca
RI /D-4159-2009
OI /0000-0002-7690-8547
CR [Anonymous], BIOFEEDBACK BOOK INT
   Arora Sarika, 2008, Int J Yoga, V1, P45, DOI 10.4103/0973-6131.43541
   BADIA P, 1984, PSYCHOPHYSIOLOGY, V21, P494, DOI 10.1111/j.1469-8986.1984.tb00231.x
   Basmajian J.V., 1989, BIOFEEDBACK PRINCIPL
   BAUM A, 1993, PSYCHOSOM MED, V55, P274, DOI 10.1097/00006842-199305000-00005
   BENSON H, 1974, PSYCHIATRY, V37, P37, DOI 10.1080/00332747.1974.11023785
   Bernardi L, 2000, J AM COLL CARDIOL, V35, P1462, DOI 10.1016/S0735-1097(00)00595-7
   BUDZYNSKI TH, 1973, PSYCHOSOM MED, V35, P484, DOI 10.1097/00006842-197311000-00004
   Budzynski TH, 1984, PRINCIPLES PRACTICE
   Camm AJ, 1996, CIRCULATION, V93, P1043
   CLARK DM, 1985, J BEHAV THER EXP PSY, V16, P23, DOI 10.1016/0005-7916(85)90026-6
   Colombo R., 1989, IEEE COMPUT CARDIOL, V1990, P475
   Conner SJ, 2006, J FAM PRACTICE, V55, P429
   Cook DJ, 2009, J AMB INTEL SMART EN, V1, P83, DOI 10.3233/AIS-2009-0014
   Cooperstein M. A., 1998, PENNSYLVANIA PSYCHOL, V58, P17
   Elliot GR, 2008, STRESS HUMAN HLTH AN
   FEHRING RJ, 1983, NURS RES, V32, P362
   Franco C, 2013, IEEE T BIO-MED ENG, V60, P211, DOI 10.1109/TBME.2012.2222640
   Green E.E., 1970, Journal of Transpersonal Psychology, V2, P1
   Healey JA, 2005, IEEE T INTELL TRANSP, V6, P156, DOI 10.1109/TITS.2005.848368
   Hjortskov N, 2004, EUR J APPL PHYSIOL, V92, P84, DOI 10.1007/s00421-004-1055-z
   HON EH, 1963, AM J OBSTET GYNECOL, V87, P814
   Jacobson E., 1938, PROGR RELAXATION, V2nd
   Jovanov E, 2003, IEEE ENG MED BIOL, V22, P49, DOI 10.1109/MEMB.2003.1213626
   Kamiya J., 1969, Altered States of Consciousness
   Katta R, 2002, P SOC PHOTO-OPT INS, V4730, P305, DOI 10.1117/12.460240
   LANYON RI, 1977, J CONSULT CLIN PSYCH, V45, P860
   Liu GZ, 2011, TELEMED E-HEALTH, V17, P348, DOI 10.1089/tmj.2010.0182
   Luthe W, 1969, AUTOGENIC THERAPY ME
   MALLIANI A, 1994, BRIT HEART J, V71, P1
   Medicore, SA 3000P CLIN MAN VE
   Miller N, 1976, BIOFEEDBACK SELF CON, P367
   Moleiro MA, 2001, APPL PSYCHOPHYS BIOF, V26, P279, DOI 10.1023/A:1013149703402
   NurrieStearns M, 2010, YOGA ANXIETY MEDITAT, P25
   Pantelopoulos A, 2008, IEEE ENG MED BIO, P4887, DOI 10.1109/IEMBS.2008.4650309
   PELLETIER KR, 1975, J CONTEMP PSYCHOTHER, V7, P29, DOI 10.1007/BF01668361
   Qian S, 1999, IEEE SIGNAL PROC MAG, V16, P52, DOI 10.1109/79.752051
   Qunxi Dong, 2010, Proceedings 2010 5th International Conference on Pervasive Computing and Applications (ICPCA 2010), P32, DOI 10.1109/ICPCA.2010.5704071
   Radespiel-Tröger M, 2003, CLIN AUTON RES, V13, P99, DOI 10.1007/s10286-003-0085-7
   Salahuddin L, 2006, 2006 International Conference on Hybrid Information Technology, Vol 2, Proceedings, P453
   Scharff L, 2002, J PEDIATR PSYCHOL, V27, P109, DOI 10.1093/jpepsy/27.2.109
   Seaward B.L., 2002, MANAGING STRESS PRIN, V3rd
   Segerstrom SC, 2004, PSYCHOL BULL, V130, P601, DOI 10.1037/0033-2909.130.4.601
   Shearn D.W., 1972, HDB PSYCHOPHYSIOLOGY
   Söderman ACH, 2004, LARYNGOSCOPE, V114, P1843
   STEPTOE A, 1981, J PSYCHOSOM RES, V25, P541, DOI 10.1016/0022-3999(81)90108-2
   Thought Technology Ltd, GSR2 PROD OV
   TRICHOPOULOS D, 1983, LANCET, V1, P441
   van Praag HM, 2004, PROG NEURO-PSYCHOPH, V28, P891, DOI [10.1016/j.pnpbp.2004.05.031, 10.1080/15622970510030018]
   Zucker TL, 2009, APPL PSYCHOPHYS BIOF, V34, P135, DOI 10.1007/s10484-009-9085-2
NR 50
TC 23
Z9 23
U1 0
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 3143
EP 3168
DI 10.1007/s11042-013-1590-x
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300045
DA 2024-07-18
ER

PT J
AU Hu, WK
   Wu, CH
   Lin, CH
AF Hu, Wei-Kai
   Wu, Chih Hung
   Lin, Chang Hong
TI Economic approximate-K color printing algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HSV color model; Color Printing; PSNR; DSCQS
AB This article describes a novel scheme to save the usage of ink or toner by an approximate-K algorithm for color printers. Existing printers use the mixtures of three color toners (Cyan, Magenta and Yellow) to print all the pixels for color images, and it makes color printing 4-4.5 times more expensive than monochromic printing. Since human eyes are not sensitive to distinguish neighboring colors in the color space, we can use the K (blackK) toner to replace the colors close to gray-scale. We can then reduce the ink usage without affecting the image visual qualities. We use the saturation in the HSV (hue, saturation, value) color model to discover the near gray-scale pixels and transform those pixels to gray level. We then evaluate the objective image quality using the PSNR (Peak Signal Noise Ratio) and use the DSCQS (Double Stimulus Continuous Quality Scale) as the subjective evaluation method. From our experimental results, printing a color image using our algorithm needs only 84 % of the original price in average.
C1 [Hu, Wei-Kai; Wu, Chih Hung; Lin, Chang Hong] Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, Taipei 106, Taiwan.
C3 National Taiwan University of Science & Technology
RP Lin, CH (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
EM chlin@mail.ntust.edu.tw
RI Lin, Chang Hong/GRE-7807-2022
OI Lin, Chang Hong/0000-0003-3646-3261
FU National Science Council [98-2221-E-011-103-]
FX This work was supported by the National Science Council under project
   98-2221-E-011-103-.
CR Almohammad A., 2010, 2010 2nd International Conference on Image Processing Theory, Tools and Applications (IPTA 2010), P215, DOI 10.1109/IPTA.2010.5586786
   [Anonymous], 14 INT C IM PROC
   Chen Kun, 2010, 2010 2nd International Conference on Education Technology and Computer (ICETC 2010), P491, DOI 10.1109/ICETC.2010.5529336
   Chen Yutuo, 2010, 2010 2nd International Conference on Education Technology and Computer (ICETC 2010), P562, DOI 10.1109/ICETC.2010.5529319
   Das S, 2009, 2009 IEEE INTERNATIONAL ADVANCE COMPUTING CONFERENCE, VOLS 1-3, P1224, DOI 10.1109/IADCC.2009.4809190
   Dusek J, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 2, PROCEEDINGS, P621, DOI 10.1109/ISSPA.2003.1224956
   Gang Chen, 2010, 2010 2nd International Conference on Software Technology and Engineering (ICSTE 2010), P372, DOI 10.1109/ICSTE.2010.5608785
   Gonzalez RC, 2008, DIGITAL IMAGE PROCES, P295
   Grgic S., 2004, Journal of Electrical Engineering, V55, P3
   Harris AW, 2008, US Patent, Patent No. [2008/0175641 A1, 20080175641]
   Jari K, 2010, 5 INT WORKSH VID PRO
   Kekre HB, 2009, 2009 IEEE INTERNATIONAL ADVANCE COMPUTING CONFERENCE, VOLS 1-3, P1218, DOI 10.1109/IADCC.2009.4809189
   Klíma M, 2005, CAR C SECUR, P19, DOI 10.1109/CCST.2005.1594824
   Klima M, 2001, 35TH ANNUAL 2001 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P108, DOI [10.1109/CCST.2001.962821, 10.1109/.2001.962821]
   Liao HY, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 5, PROCEEDINGS, P626
   Nohara F, 2009, IEEE IMAGE PROC, P485, DOI 10.1109/ICIP.2009.5414355
   Ortiz Segovia MV, 2012, P SPIE IMAGE QUAL SY, V8293
   Safonov IV, 2012, P SPIE COLOR IMAGING, V8292
   Segovia M.V. Ortiz., 2012, P SPIE COLOR IMAGING, V8292
   Son CH, 2006, J IMAGING SCI TECHN, V50, P25, DOI 10.2352/J.ImagingSci.Technol.(2006)50:1(25)
   Son CH, 2011, J IMAGING SCI TECHN, V55, DOI 10.2352/J.ImagingSci.Technol.2011.55.1.010505
   Son CH, 2010, IEEE T CONSUM ELECTR, V56, P280, DOI 10.1109/TCE.2010.5505929
   Song ML, 2010, IEEE T PATTERN ANAL, V32, P1537, DOI 10.1109/TPAMI.2009.74
   Stoica A, 2003, SCS 2003: INTERNATIONAL SYMPOSIUM ON SIGNALS, CIRCUITS AND SYSTEMS, VOLS 1 AND 2, PROCEEDINGS, P137
   Tanaka G, 2007, INT S INT SIGN PROC, P112
   Tkalcic M, 2003, IEEE REGION 8 EUROCON 2003, VOL A, PROCEEDINGS, P304
   Tseng SS, 2010, THESIS TAIWAN U SCI
   Wang SM, 2009, 2 INT C IM SIGN PROC, P1
   Weber E.H., 1996, EH WEBER TACTILE SEN
   Wei-Kai Hu, 2011, 2011 IEEE 15th International Symposium on Consumer Electronics, P379, DOI 10.1109/ISCE.2011.5973853
   Wharton E, 2008, IEEE SYS MAN CYBERN, P685, DOI 10.1109/ICSMC.2008.4811357
   Zhang F, 2009, CCDC 2009: 21ST CHINESE CONTROL AND DECISION CONFERENCE, VOLS 1-6, PROCEEDINGS, P1487, DOI 10.1109/CCDC.2009.5192184
NR 32
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 151
EP 166
DI 10.1007/s11042-012-1345-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800008
DA 2024-07-18
ER

PT J
AU Khan, R
   Hanbury, A
   Stöttinger, J
   Khan, FA
   Khattak, AU
   Ali, A
AF Khan, Rehanullah
   Hanbury, Allan
   Stoettinger, Julian
   Khan, Farman Ali
   Khattak, Amjad Ullah
   Ali, Amjad
TI Multiple color space channel fusion for skin detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin detection; Color space fusion; Markowitz model
ID FACE DETECTION; MODELS; SEGMENTATION; SELECTION
AB Skin detection is used in applications ranging from face detection, tracking body parts and hand gesture analysis, to retrieval and blocking of objectionable content. We investigate color based skin detection. We linearly merge different color space channels representing it as a fusion process. The aim of fusing different color space channels is to achieve invariance against varying imaging and illumination conditions. The non-perfect correlation between the color spaces is exploited by learning weights based on an optimization for a particular color space channel using the mathematical financial model of Markowitz. The weight learning process develops a color weighted model using positive training data only. Experiments on a database of 8991 images with annotated pixel-level ground truth show that the fusion of color space channels approach is well suited to stable and robust skin detection. In terms of precision and recall, the fusion approach provides a competitive performance to other state-of-the-art approaches which require negative and positive training data with the exception of the decision tree based classifier (J48). As a real-time application, we show that the weight based color channel fusion approach can be used for learning of weights for skin detection based on detected faces in image sequences.
C1 [Khan, Rehanullah; Ali, Amjad] Sarhad Univ Sci & IT, Peshawar, Pakistan.
   [Hanbury, Allan] TU Wien, Inst Software Technol & Interact Syst, Vienna, Austria.
   [Stoettinger, Julian] Univ Trent, Dept Informat Engn & Comp Sci, Trento, Italy.
   [Khan, Farman Ali] COMSATS Inst Informat Technol, Attock, Pakistan.
C3 Technische Universitat Wien; University of Trento; COMSATS University
   Islamabad (CUI)
RP Khan, R (corresponding author), Sarhad Univ Sci & IT, Peshawar, Pakistan.
EM rehanmarwat1@gmail.com; hanbury@ifs.tuwien.ac.at; julian@disi.unitn.it;
   farman_marwat@ciit-attock.edu.pk; amjad67@gmail.com;
   amjadalikhalil@gmail.com
CR [Anonymous], 2003, PROC GRAPHICON
   Argyros AA, 2004, LECT NOTES COMPUT SC, V3023, P368
   Brown D.A., 2001, Proceedings of the 2001 British Machine Vision Conference, V1, P491
   Cai J, 1999, IMAGE VISION COMPUT, V18, P63, DOI 10.1016/S0262-8856(99)00006-2
   Chai D, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P124, DOI 10.1109/AFGR.1998.670936
   Fleck M. M., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P593
   Fu ZY, 2004, INT C PATT RECOG, P549, DOI 10.1109/ICPR.2004.1333831
   Garcia C, 1999, IEEE T MULTIMEDIA, V1, P264, DOI 10.1109/6046.784465
   Hanbury A, 2003, LECT NOTES COMPUT SC, V2749, P804
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Jie Yang, 1997, Computer Vision - ACCV '98. Third Asian Conference on Computer Vision. Proceedings, P687
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Khan R., 2012, MULTIMED TOOLS APPL, P1
   Khan R., 2008, P 1 ACM WORKSH AN RE, P89, DOI 10.1145/1463542.1463557
   Khan R, 2012, PATTERN RECOGN LETT, V33, P157, DOI 10.1016/j.patrec.2011.09.032
   Khan R, 2010, LECT NOTES COMPUT SC, V6454, P75, DOI 10.1007/978-3-642-17274-8_8
   Khan R, 2010, IEEE IMAGE PROC, P4613, DOI 10.1109/ICIP.2010.5651638
   Kovac J, 2003, IEEE REGION 8 EUROCON 2003, VOL B, PROCEEDINGS, P144
   Lee JS, 2007, PATTERN RECOGN, V40, P2261, DOI 10.1016/j.patcog.2006.11.016
   Markowitz H, 1952, J FINANC, V7, P77, DOI 10.1111/j.1540-6261.1952.tb01525.x
   Phung SL, 2005, IEEE T PATTERN ANAL, V27, P148, DOI 10.1109/TPAMI.2005.17
   Sigal L, 2004, IEEE T PATTERN ANAL, V26, P862, DOI 10.1109/TPAMI.2004.35
   Stöttinger J, 2009, LECT NOTES COMPUT SC, V5876, P303, DOI 10.1007/978-3-642-10520-3_28
   Stokman H, 2005, PROC CVPR IEEE, P560
   Stokman H, 2007, IEEE T PATTERN ANAL, V29, P371, DOI 10.1109/TPAMI.2007.58
   Storring M., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P64, DOI 10.1109/AFGR.2000.840613
   Wong KW, 2003, SIGNAL PROCESS-IMAGE, V18, P103, DOI 10.1016/S0923-5965(02)00088-7
   Yang M.-H., 1999, Proceedings o f SPIE: Conference on Storage and Retrievalfor Image and Video Databases, P458
NR 29
TC 10
Z9 12
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1709
EP 1730
DI 10.1007/s11042-013-1443-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300030
DA 2024-07-18
ER

PT J
AU Lou, ZY
   Jiang, G
   Wu, CK
AF Lou, Zhongyu
   Jiang, Guang
   Wu, Chengke
TI 2D scale-adaptive tracking based on projective geometry
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mean-shift; Projective geometry; Tracking; Scale adaptation
ID MEAN-SHIFT
AB Object tracking is a fundamental challenge in computer vision. For real-time tracking, the efficiency and robustness of the Mean-shift algorithm makes it a popular choice. However, the scale of the Mean-shift kernel is a crucial parameter and no clear mechanism exists presently for updating the scale when a size-changing object is tracked. In this paper, a new method is introduced using projective geometry to determine the size of the object, and in turn the scale of the Mean-shift kernel. In the initial step of the algorithm, the geometric information of the scene is obtained automatically (or manually). With the geometric information, the size of the object is updated. The experimental results show that this algorithm is stable, efficient and outperforms the Mean-shift baseline and other kernel updating methods, such as CAMSHIFT.
C1 [Lou, Zhongyu; Jiang, Guang; Wu, Chengke] Xidian Univ, Sch Telecommun Engn, State Key Lab Integrated Serv Networks, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Lou, ZY (corresponding author), Xidian Univ, Sch Telecommun Engn, State Key Lab Integrated Serv Networks, Xian 710071, Shaanxi, Peoples R China.
EM zyulou@gmail.com; gjiang@mail.xidian.edu.cn; ckwu@mail.xidian.edu.cn
CR Ben Benfold, 2011, ICCV
   Bradski GR, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P214, DOI 10.1109/ACV.1998.732882
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Chu D. M., 2010, IEEE WORKSH PERF EV
   Collins RT, 2003, PROC CVPR IEEE, P234
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P438, DOI 10.1109/ICCV.2001.937550
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Everts I, 2012, EUR C COMP VIS
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hedau V., 2009, P ICCV
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Lou Z, 2009, INT C IM SIGN PROC T
   Lou Z, 2010, INT C MULT TECHN NIN
   Lucena M, 2010, MULTIMED TOOLS APPL, V49, P371, DOI 10.1007/s11042-009-0376-7
   Peng Ning-Song, 2005, Journal of Software, V16, P1542, DOI 10.1360/jos161542
   [齐苏敏 Qi Sumin], 2007, [电子与信息学报, Journal of Electronics & Information Technology], V29, P686
   Sicre R, 2011, 14 INT C COMP AN IM
   Sotelo MA, 2004, AUTON ROBOT, V16, P95, DOI 10.1023/B:AURO.0000008673.96984.28
   Tyagi A, 2006, IEEE C COMP VIS PATT
   Yilmaz A, 2007, PROC CVPR IEEE, P140
   Zhou HY, 2009, COMPUT VIS IMAGE UND, V113, P345, DOI 10.1016/j.cviu.2008.08.006
   Zhu S, 2006, THESIS ZHEJIANG U
   [朱胜利 ZHU Shengli], 2006, [光电工程, Opto-Electronic Engineering], V33, P11
   Zivkovic Z, 2004, PROC CVPR IEEE, P798
   ZIVKOVIC Z, 2004, P 6 IEEE INT WORKSH
NR 27
TC 2
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 905
EP 924
DI 10.1007/s11042-013-1407-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800041
DA 2024-07-18
ER

PT J
AU Kang, SH
   Park, KY
   Kim, J
AF Kang, Seung-Hoon
   Park, Keun-Young
   Kim, Juho
TI Cost effective data wiping methods for mobile phone
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Forensics; Filesystem; Wiping
AB Thanks to the supply of smartphones, mobile phones have come to store increasingly more personal information of users. To protect users' information, the information stored in mobile phones should not only be managed safety but also be deleted not to allow restoration. In the filesystems that have been applied to existing mobile phones, even when users have deleted information, data are not completely wiped from the storage. Therefore, the data can be easily recovered by using forensics tools. Considering that mobile phones are always exposed to the risk of robberies and loss, this situation can be misused for personal information spill. The present paper points out problems in the methods of data deleting from smartphones, proposes an efficient data deleting method considering mobile device environments with limitations in battery and hardware performance such as smartphones, and analyzes the efficiency of the techniques in relation to the types of filesystems and data formats.
C1 [Kang, Seung-Hoon; Park, Keun-Young; Kim, Juho] Sogang Univ, Dept Comp Sci & Engn, Seoul, South Korea.
C3 Sogang University
RP Kim, J (corresponding author), Sogang Univ, Dept Comp Sci & Engn, Shinsu Dong 1, Seoul, South Korea.
EM chuck@sogang.ac.kr; kypark@sogang.ac.kr; jhkim@sogang.ac.kr
RI Koo, Bon Heun/AGG-1647-2022
CR [Anonymous], 2005, File System Forensic Analysis
   Hoog A, 2001, ANDROID FORENSICS IN
   Jahankhani H, 2006, INFORM SECUR
   Jansen W., 2007, NIST Special Publication, V800
   Lessard J, 2010, SMALL SCALE DIGIT DE, V4
   Park S, 2011, J SUPERCOMPUT    OCT
   Quick D, 2011, P AUST DIG FOR C DEC
   Shin I, 2012, INT J NETW SECUR APP, V6
   Spanjer E., 2009, FLASH MANAGEMENT WHY
   Watson Andrew, 1994, Math. J., V4
   Wright C, 2008, LNCS, V5352
   Zdziarski J., 2008, IPHONE FORENSICS REC
NR 12
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 643
EP 655
DI 10.1007/s11042-013-1603-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400016
DA 2024-07-18
ER

PT J
AU Kim, J
   Lee, D
   Chung, KY
AF Kim, Jonghun
   Lee, Daesung
   Chung, Kyung-Yong
TI Item recommendation based on context-aware model for personalized
   u-healthcare service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Context-aware; Collaborative filtering; Item recommendation;
   Personalized service; U-healthcare service
ID SYSTEM
AB A personalized service in the ubiquitous environment is to provide services or items, which reflect personal tastes, attitudes, and contexts. It is impossible to reflect the context information generated in u-healthcare environments due to the existing recommendation system performing the recommendation using the information directly input by users and application usage record only. This study develops a context-aware model using the context information provided by the context information model. The study applies it to the extraction of the missing value in a collaborative filtering process. The context-aware model reflects the information that selects items by users according to the appropriate context using the C-HMM and provides it to users. The solution of the missing value in the preference significantly affects the recommendation accuracy in a preference based item supply method. Thus, this study developed a new collaborative filtering for ubiquitous environments by reflecting the missing preference value and reflecting it to the collaborative filtering using the context-aware model. Also, the validity of this method will be evaluated by applying it to menu services in u-healthcare services.
C1 [Kim, Jonghun] BIT Comp Co Ltd, U Healthcare Dept, Seoul, South Korea.
   [Lee, Daesung] Kyonggi Univ, Dept Ind Secur, Seoul, South Korea.
   [Chung, Kyung-Yong] Sangji Univ, Sch Comp Informat Engn, Wonju, South Korea.
C3 Kyonggi University; Sangji University
RP Chung, KY (corresponding author), Sangji Univ, Sch Comp Informat Engn, Wonju, South Korea.
EM kimjh@bit.kr; xdilemma@naver.com; dragonhci@gmail.com
RI Chung, Kyungyong/JAC-2276-2023; Lee, Daesung/P-7946-2018
OI Lee, Daesung/0000-0002-2435-6867
FU Basic Science Research Program through the National Research Foundation
   of Korea - Ministry of Education, Science and Technology [2011-0008934]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea funded by the Ministry of
   Education, Science and Technology. (No. 2011-0008934).
CR Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124
   Breese J., 1998, P 14 C UNC ART INT, P43
   Brown PJ, 1997, IEEE PERS COMMUN, V4, P58, DOI 10.1109/98.626984
   Burchfield T. Ryan, 2007, 1 ACM SIGMOBILE INT
   Foster D. P., 1998, AAAI WORKSH REC SYST, P114
   Gong L, 2001, IEEE INTERNET COMPUT, V5, P64, DOI 10.1109/4236.895144
   Good N, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P439
   Jang S, 2003, LECT NOTES ARTIF INT, V2680, P178
   Jeong K, 2008, IEEE INT C MULT FUS
   Jung KY, 2004, IEICE T INF SYST, VE87D, P2781
   Jung KY, 2003, LECT NOTES COMPUT SC, V2911, P100
   McDonald D.W., 2000, CSCW 00, P231, DOI [DOI 10.1145/358916.3589941, 10.1145/358916.358994, DOI 10.1145/358916.358994]
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Ravi N., 2005, Aaai, P1541
   WOJEK C, 2006, IEEE INT C MULT FUS
NR 15
TC 67
Z9 78
U1 3
U2 56
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 855
EP 872
DI 10.1007/s11042-011-0920-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400029
DA 2024-07-18
ER

PT J
AU Wu, YL
   Yeh, CT
   Hung, WC
   Tang, CY
AF Wu, Yi-Leh
   Yeh, Chun-Tsai
   Hung, Wei-Chih
   Tang, Cheng-Yuan
TI Gaze direction estimation using support vector machine with active
   appearance model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-computer interaction; Eye gaze detection; Active appearance
   models; Support vector machine
ID EYE-TRACKING
AB In recent years, research on human-computer interaction is becoming popular, most of which uses body movements, gestures or eye gaze direction. Until now, gazing estimation is still an active research domain. We propose an efficient method to solve the problem of the eye gaze point. We first locate the eye region by modifying the characteristics of the Active Appearance Model (AAM). Then by employing the Support Vector Machine (SVM), we estimate the five gazing directions through classification. The original 68 facial feature points in AAM are modified into 36 eye feature points. According to the two-dimensional coordinates of feature points, we classify different directions of eye gazing. The modified 36 feature points describe the contour of eyes, iris size, iris location, and the position of pupils. In addition, the resolution of cameras does not affect our method to determine the direction of line of sight accurately. The final results show the independence of classifications, less classification errors, and more accurate estimation of the gazing directions.
C1 [Wu, Yi-Leh; Yeh, Chun-Tsai; Hung, Wei-Chih] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Tang, Cheng-Yuan] Huafan Univ, Dept Informat Management, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology; Huafan University
RP Wu, YL (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
EM ywu@csie.ntust.edu.tw
FU National Science Council, Taiwan [NSC101-2221-E-011-141,
   NSC100-2221-E-011-121, NSC101-2221-E-211-011]
FX This work was partially supported by the National Science Council,
   Taiwan, under the Grants No. NSC101-2221-E-011-141,
   NSC100-2221-E-011-121, and NSC101-2221-E-211-011.
CR [Anonymous], INT C AFF COMP INT I
   [Anonymous], AAM LIB
   [Anonymous], IEEE T BIOMEDICAL EN
   [Anonymous], COMP VISION IMAGE UN
   [Anonymous], IEEE T BIOMEDICAL EN
   [Anonymous], INT WORKSH GAZ SENS
   [Anonymous], 2011, ACM T INTEL SYST TEC
   [Anonymous], J OPTICAL ENG
   [Anonymous], ISM IEEE INT S MULT
   [Anonymous], AAM TOOL
   [Anonymous], P DS RT
   [Anonymous], CHARGE COUPLED DEVIC
   [Anonymous], 2011, OpenCV
   [Anonymous], IEEE T INTELLIGENT T
   Bacivarov I, 2008, IEEE T CONSUM ELECTR, V54, P1312, DOI 10.1109/TCE.2008.4637622
   Beymer D, 2003, PROC CVPR IEEE, P451
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Coutinho FL, 2006, SIBGRAPI, P171
   Duchowski AT, 2002, BEHAV RES METH INS C, V34, P455, DOI 10.3758/BF03195475
   Ebisawa Y, 1998, IEEE T INSTRUM MEAS, V47, P948, DOI 10.1109/19.744648
   Edwards G., 1998, PROC 5 EUROPEAN C CO, V2, P581
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Morimoto CH, 2005, COMPUT VIS IMAGE UND, V98, P4, DOI 10.1016/j.cviu.2004.07.010
   Cuong NH, 2010, I C CONT AUTOMAT ROB, P2507, DOI 10.1109/ICARCV.2010.5707319
   Ohtani M., 1995, Proc. of the 17th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, V2, P1623
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Zhao YS, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MEASUREMENT SYSTEMS AND APPLICATIONS (CIMSA), P7
   Zhu J, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P131, DOI 10.1109/AFGR.2002.1004144
NR 30
TC 29
Z9 34
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 2037
EP 2062
DI 10.1007/s11042-012-1220-z
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500029
DA 2024-07-18
ER

PT J
AU Tazaree, A
   Eftekhari-Moghadam, AM
   Sajjadi-Ghaem-Maghami, S
AF Tazaree, Abolfazl
   Eftekhari-Moghadam, Amir-Masud
   Sajjadi-Ghaem-Maghami, Saeedeh
TI A semantic image classifier based on hierarchical fuzzy association rule
   mining
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic image classifier; Hierarchical fuzzy classification; Fuzzy
   Association Rule; Fuzzy expert systems
ID RETRIEVAL
AB One of the major challenges in the content-based information retrieval and machine learning techniques is to-build-the-so-called "semantic classifier" which is able to effectively and efficiently classify semantic concepts in a large database. This paper dealt with semantic image classification based on hierarchical Fuzzy Association Rules (FARs) mining in the image database. Intuitively, an association rule is a unique and significant combination of image features and a semantic concept, which determines the degree of correlation between features and concept. The main idea behind this approach is that any image visual concept has some associated features, so that, there are strong correlations between the concepts and their corresponding features. Regardless of the semantic gap, an image concept appears when the corresponding features emerge in an image and vice versa. Specially, this paper's contribution was to propose a novel Fuzzy Association Rule for improving traditional association rules. Moreover, it was concerned with establishing a hierarchical fuzzy rule base in the training phase and setup corresponding fuzzy inference engine in order to classify images in the testing phase. The presented approach was independent from image segmentation and can be applied on multi-label images. Experimental results on a database of 6000 general-purpose images demonstrated the superiority of the proposed algorithm.
C1 [Tazaree, Abolfazl; Eftekhari-Moghadam, Amir-Masud; Sajjadi-Ghaem-Maghami, Saeedeh] Islamic Azad Univ, Qazvin Branch, Fac Elect Comp & IT Engn, Qazvin, Iran.
C3 Islamic Azad University
RP Sajjadi-Ghaem-Maghami, S (corresponding author), Islamic Azad Univ, Qazvin Branch, Fac Elect Comp & IT Engn, Qazvin, Iran.
EM tazaree@gmail.com; eftekhari@qiau.ac.ir; s.ghaemmaghami@qiau.ac.ir
RI Moghadam, Amir Masoud Eftekhari/ABA-5362-2021
OI Eftekhari Moghadam, Amir-Masoud/0000-0003-3413-0607
CR Alcalá-Fdez J, 2011, IEEE T FUZZY SYST, V19, P857, DOI 10.1109/TFUZZ.2011.2147794
   [Anonymous], 1996, COURSE FUZZY SYSTEMS, DOI DOI 10.5555/248374
   Chang FC, 2003, P SOC PHOTO-OPT INS, V5022, P890, DOI 10.1117/12.476512
   Chen Xiao-Yun, 2006, Journal of Software, V17, P1017, DOI 10.1360/jos171017
   Chen ZL, 2008, INT J COMPUT INT SYS, V1, P262
   Fan JP, 2008, IEEE T MULTIMEDIA, V10, P167, DOI 10.1109/TMM.2007.911775
   Hu YC, 2002, COMPUT IND ENG, V43, P735, DOI 10.1016/S0360-8352(02)00136-5
   Jing WW, 2006, DASC 2006: 2ND IEEE INTERNATIONAL SYMPOSIUM ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, PROCEEDINGS, P315
   Konstantinidis K, 2005, OPT COMMUN, V248, P375, DOI 10.1016/j.optcom.2004.12.029
   Kuok CM, 2008, ACM SIGMOD, V27, P159
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Malathi G., 2011, Journal of Information Hiding and Multimedia Signal Processing, V2, P332
   Manglem Singh Kh., 2011, J INF HIDING MULTIME, V2, P108
   Marszalek M, 2008, LECT NOTES COMPUT SC, V5305, P479, DOI 10.1007/978-3-540-88693-8_35
   Silla CN, 2011, DATA MIN KNOWL DISC, V22, P31, DOI 10.1007/s10618-010-0175-9
   Sun AX, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P521, DOI 10.1109/ICDM.2001.989560
   Thilagam PS, 2008, PATTERN ANAL APPL, V11, P159, DOI 10.1007/s10044-007-0090-x
   Wang F, 2006, LECT NOTES COMPUT SC, V4071, P473
   Wang W, 2006, MULTIMEDIA SYST, V11, P352, DOI 10.1007/s00530-006-0029-x
   Zimek A, 2008, IEEE ACM T COMPUT BI, V7, P563
NR 21
TC 8
Z9 9
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 921
EP 949
DI 10.1007/s11042-012-1123-z
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300017
DA 2024-07-18
ER

PT J
AU Grega, M
   Bryk, D
   Napora, M
AF Grega, Michal
   Bryk, Damian
   Napora, Maciej
TI INACT-INDECT Advanced Image Cataloguing Tool
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Live forensics; Query by example; Bees Algorithm; Child pornography
AB Child pornography possession and distribution are crimes which are prosecuted in most countries around the world. In some cases the law is so strict that even police forces are not allowed to gather and catalogue evidence for future reference. This paper presents an innovative solution to this problem. The authors present tools for cataloguing high- and low-level metadata of the evidence material. Furthermore, a tool for fast and accurate search for such evidence in suspects' file systems is proposed.
C1 [Grega, Michal; Bryk, Damian; Napora, Maciej] AGH Univ Sci & Technol, PL-30059 Krakow, Poland.
C3 AGH University of Krakow
RP Grega, M (corresponding author), AGH Univ Sci & Technol, Al Mickiewicza 30, PL-30059 Krakow, Poland.
EM grega@kt.agh.edu.pl; dmn.bryk@gmail.com; napora.maciej@gmail.com
FU European Commission [218086]
FX The presented work was supported by the European Commission, in an
   integrated project INDECT (Grant number 218086).
CR AccessData, FOR TOOLK FTK COMP F
   [Anonymous], 15938 ISOIEC
   [Anonymous], COMP FOR SOL DIG INV
   [Anonymous], 2011, OPERATING SYSTEM MAR
   [Anonymous], 2006, Intelligent Production Machines and Systems
   Casey E, 2010, HANDBOOK OF DIGITAL FORENSICS AND INVESTIGATION, P1
   Eleuterio P, 2010, P 5 INT C FOR COMP S
   International Center for Missing and Exploited Children, 2006, CHILD PORN MOD LEG G
   Lüdtke A, 2009, PROCEEDINGS OF THE 20TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATION, P269, DOI 10.1109/DEXA.2009.93
   Manjunath BS, 2002, INTRO MPEG 7 MEDIA C
   Nadernejad E., 2008, Appl. Math. Sci, V2, P1507
   Pardo A, 2006, LECT NOTES COMPUT SC, V4225, P726
   Pham D. T., 2007, INN PROD MACH SYST V
   Rogers MK, 2006, C DIG FOR SEC LAW
   Shilov A, 2010, MICROPROCESSOR MARKE
   Wong KM, 2005, IEEE INT SYMP CIRC S, P1541
NR 16
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 1
BP 95
EP 110
DI 10.1007/s11042-012-1164-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 283JZ
UT WOS:000329243600007
OA hybrid
DA 2024-07-18
ER

PT J
AU Kang, SJ
   Kim, YB
   Park, T
   Kim, CH
AF Kang, Shin-Jin
   Kim, Young Bin
   Park, Taejung
   Kim, Chang-Hun
TI Automatic player behavior analysis system using trajectory data in a
   massive multiplayer online game
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Trajectory clustering; Behavior analysis; World of Warcraft; MMORPG;
   MMOG
ID CLASSIFICATION
AB This paper presents a new automated behavior analysis system using a trajectory clustering method for massive multiplayer online games (MMOGs). The description of a player's behavior is useful information in MMOG development, but the monitoring and evaluation cost of player behavior is expensive. In this paper, we suggest an automated behavior analysis system using simple trajectory data with few monitoring and evaluation costs. We used hierarchical classification first, then applied an extended density based clustering algorithm for behavior analysis. We show the usefulness of our system using trajectory data from the commercial MMOG World of Warcraft (WOW). The results show that the proposed system can analyze player behavior and automatically generate insights on players' experience from simple trajectory data.
C1 [Kang, Shin-Jin] Hongik Univ, Korea NCsoft, Sch Games, Seoul, South Korea.
   [Kim, Young Bin; Park, Taejung; Kim, Chang-Hun] Korea Univ, Dept Comp Sci, Seoul, South Korea.
C3 Hongik University; Korea University
RP Kim, CH (corresponding author), Korea Univ, Dept Comp Sci, Seoul, South Korea.
EM directx@hongik.ac.kr; chkim@korea.ac.kr
RI Park, Taejung/GYU-9638-2022
OI Park, Taejung/0000-0001-5118-3271; Kim, YoungBin/0000-0002-2114-0120
FU National Research Foundation of Korea (NRF); Ministry of Education,
   Science and Technology [2011-0017595]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (No. 2011-0017595).
CR Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49
   [Anonymous], 9906010 NW U
   [Anonymous], P 5 ACM SIGCOMM WORK
   [Anonymous], P 15 IEEE VIS C
   [Anonymous], TRACKING PLAYER FEED
   [Anonymous], P SIGMOD
   [Anonymous], ADV SOFT COMPUT
   [Anonymous], P SIGMOD
   [Anonymous], AI GAME PROGRAMMING
   [Anonymous], GAME DEV MAGAZINE
   Bartle R, 1996, HEARTS CLUBS DIAMOND
   Borner K., 2003, Information Visualization, V2, P182, DOI 10.1057/palgrave.ivs.9500050
   Charles D., 2004, P INT C COMPUTER GAM, P29
   Chittaro L, 2006, IEEE T VIS COMPUT GR, V12, P1475, DOI 10.1109/TVCG.2006.109
   Cowley B., 2008, COMPUT ENTERTAINMENT, V6, P1, DOI [10.1145/1371216.1371223, DOI 10.1145/1371216.1371223]
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   FRANKLIN SE, 1991, COMPUT GEOSCI, V17, P1151, DOI 10.1016/0098-3004(91)90075-O
   Guha S, 2000, INFORM SYST, V25, P345, DOI 10.1016/S0306-4379(00)00022-3
   Hinneburg A, 2007, LECT NOTES COMPUT SC, V4723, P70
   Kim JH, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P443
   Lee J-G, 2007, SIGMOD C, P593, DOI DOI 10.1145/1247480.1247546
   Matsumoto Y, 2004, LECT NOTES COMPUT SC, V3166, P429
   Ng RT, 2002, IEEE T KNOWL DATA EN, V14, P1003, DOI 10.1109/TKDE.2002.1033770
   Sheikholeslami G., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P428
   Thawonmas Ruck., 2007, The International Journal of Virtual Reality, V6, P11
   Zhang T., 1996, BIRCH EFFICIENT DATA, V25, P103, DOI [DOI 10.1145/233269.233324, 10.1145/235968.233324]
NR 26
TC 14
Z9 14
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2013
VL 66
IS 3
BP 383
EP 404
DI 10.1007/s11042-012-1052-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 179TX
UT WOS:000321545300003
DA 2024-07-18
ER

PT J
AU Rodríguez-Sánchez, R
   Martínez, JL
   Fernández-Escribano, G
   Sánchez, JL
   Claver, JM
AF Rodriguez-Sanchez, Rafael
   Luis Martinez, Jose
   Fernandez-Escribano, Gerardo
   Luis Sanchez, Jose
   Manuel Claver, Jose
TI H.264/AVC inter prediction on accelerator-based multi-core systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AVC; Motion estimation; Inter prediction; Heterogeneous computing
ID MOTION ESTIMATION
AB The AVC video coding standard adopts variable block sizes for inter frame coding to increase compression efficiency, among other new features. As a consequence of this, an AVC encoder has to employ a complex mode decision technique that requires high computational complexity. Several techniques aimed at accelerating the inter prediction process have been proposed in the literature in recent years. Recently, with the emergence of many-core processors or accelerators, a new way of supporting inter frame prediction has presented itself. In this paper, we present a step forward in the implementation of an AVC inter prediction algorithm in a graphics processing unit, using Compute Unified Device Architecture. The results show a negligible drop in rate distortion with a time reduction, on average, of over 98.8 % compared with full search and fast full search, and of over 80 % compared with UMHexagonS search.
C1 [Rodriguez-Sanchez, Rafael; Fernandez-Escribano, Gerardo; Luis Sanchez, Jose] Univ Castilla La Mancha, Inst Invest Informat Albacete, Albacete 02071, Spain.
   [Luis Martinez, Jose] Univ Complutense Madrid, Architecture & Technol Comp Syst Grp, E-28040 Madrid, Spain.
   [Manuel Claver, Jose] Univ Valencia, Dept Informat, E-46100 Valencia, Spain.
C3 Universidad de Castilla-La Mancha; Complutense University of Madrid;
   University of Valencia
RP Rodríguez-Sánchez, R (corresponding author), Univ Castilla La Mancha, Inst Invest Informat Albacete, Ave Espana S-N, Albacete 02071, Spain.
EM rrsanchez@dsi.uclm.es; joseluis.martinez@fdi.ucm.es;
   gerardo@dsi.uclm.es; jsanchez@dsi.uclm.es; jose.claver@uv.es
RI Fernández-Escribano, Gerardo/I-1167-2015; Martinez, Jose
   Luis/ABA-2535-2021; Claver, José M./A-9778-2013; Sánchez, José
   L./M-3057-2019; Rodríguez-Sánchez, Rafael/ABB-8227-2021
OI Fernández-Escribano, Gerardo/0000-0002-0037-2061; Martinez, Jose
   Luis/0000-0001-5119-2418; Claver, José M./0000-0002-9617-3453; Sánchez,
   José L./0000-0002-3498-9174; Rodríguez-Sánchez,
   Rafael/0000-0001-8789-3953
FU Spanish MEC; MICINN; European Commission [CSD2006-00046,
   TIN2009-14475-C04]; Council of Science and Technology of Castilla-La
   Mancha [PEII09-0037-2328, PII2I09-0045-9916, PCC08-0078-9856]
FX This work was supported by the Spanish MEC and MICINN, as well as
   European Commission FEDER funds, under Grants CSD2006-00046 and
   TIN2009-14475-C04. It was also partly supported by The Council of
   Science and Technology of Castilla-La Mancha under Grants
   PEII09-0037-2328, PII2I09-0045-9916, and PCC08-0078-9856.
CR [Anonymous], 2001, P 13 VCEG M33 M AUST
   [Anonymous], 2003, ADV VID COD GEN AUD
   [Anonymous], 1999, 144862 ISOIEC
   Chen WN, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P697
   Cheung NM, 2010, IEEE SIGNAL PROC MAG, V27, P79, DOI 10.1109/MSP.2009.935416
   Feng WC, 2007, PARALLEL COMPUT, V33, P645, DOI 10.1016/j.parco.2007.10.001
   Ho CW, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P2049, DOI 10.1109/ICME.2006.262617
   Joint Video Team (JVT) of ISO/IEC MPEG and ITU-T VCEG, 2010, REF SOFTW C IN PRESS
   JVT Test Model Ad Hoc Group, 2003, EV SHEET MO IN PRESS
   Kelly F, 2004, P SOC PHOTO-OPT INS, V5297, P184, DOI 10.1117/12.526400
   Kung MC, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P599, DOI 10.1109/ICALIP.2008.4590176
   Lee CY, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1603
   Momcilovic S, 2009, IEEE WRK SIG PRO SYS, P291, DOI 10.1109/SIPS.2009.5336269
   Richardson IEG, 2003, VIDEO CODEC DESIGN
   Schwalb M, 2009, IEEE T MULTIMEDIA, V11, P1, DOI 10.1109/TMM.2008.2008873
   Sullivan G., 2001, VCEGN81 ITUT
   Yen-Kuang Chen, 2004, Proceedings. 18th International Parallel and Distributed Processing Symposium
NR 17
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2013
VL 66
IS 3
BP 361
EP 381
DI 10.1007/s11042-012-1056-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 179TX
UT WOS:000321545300002
OA Green Published
DA 2024-07-18
ER

PT J
AU Daeinabi, A
   Rahbar, AG
AF Daeinabi, Ameneh
   Rahbar, Akbar Ghaffarpour
TI Detection of malicious vehicles (DMV) through monitoring in Vehicular
   Ad-Hoc Networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicular Ad Hoc Networks; Secure communication; Monitoring; Honest
   vehicle; Abnormal behavior; Malicious vehicle
ID COMMUNICATION SCHEME; SECURE
AB Vehicular Ad Hoc Networks (VANETs) are appropriate networks that can be applied to intelligent transportation systems. In VANET, messages exchanged among vehicles may be damaged by attacker nodes. Therefore, security in message forwarding is an important factor. We propose the Detection of Malicious Vehicles (DMV) algorithm through monitoring to detect malicious nodes that drop or duplicate received packets and to isolate them from honest vehicles, where each vehicle is monitored by some of it trustier neighbors called verifier nodes. If a verifier vehicle observes an abnormal behavior from vehicle V, it increases distrust value of vehicle V. The ID of vehicle V is then reported to its relevant Certificate Authority (CA) as a malicious node when its distrust value is higher than a threshold value. Performance evaluation shows that DMV can detect most existence abnormal and malicious vehicles even at high speeds.
C1 [Daeinabi, Ameneh; Rahbar, Akbar Ghaffarpour] Sahand Univ Technol, Dept Elect Engn, Comp Networks Res Lab, Tabriz, Iran.
C3 Sahand University of Technology
RP Rahbar, AG (corresponding author), Sahand Univ Technol, Dept Elect Engn, Comp Networks Res Lab, Tabriz, Iran.
EM a_daeinabi@sut.ac.ir; ghaffarpour@sut.ac.ir
OI Ghaffarpour Rahbar, Akbar/0000-0002-0902-379X
FU Research Institute for ICT, Iran
FX This research was supported by Research Institute for ICT, Iran.
CR Abdulhamid H, 2007, AEU-INT J ELECTRON C, V61, P556, DOI 10.1016/j.aeue.2006.10.005
   [Anonymous], P VANETS 04
   Artimy M, 2007, IEEE T INTELL TRANSP, V8, P400, DOI 10.1109/TITS.2007.895290
   BETTSTETTER C, 2001, 4 ACM INT WORKSH MOD
   Blum J, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P150, DOI 10.1109/IVS.2003.1212900
   DaeiNabi A, 2009, 17 IR C EL ENG ICEE2, P380
   Dillenburg J, 2007, TRANSP RES BOARD 86
   Fan P, 2005, LECT NOTES COMPUT SC, V3738, P32, DOI 10.1007/11561354_5
   Fonseca E., 2006, SURVEY EXISTING APPR
   Ghosh M, 2010, AD HOC NETW, V8, P778, DOI 10.1016/j.adhoc.2010.02.008
   Ghosh Mainak., 2009, Proceedings of IEEE WCNC, P2909
   Guo JH, 2007, 2007 MOBILE NETWORKING FOR VEHICULAR ENVIRONMENTS, P103, DOI 10.1109/MOVE.2007.4300813
   Li CT, 2008, COMPUT COMMUN, V31, P2803, DOI 10.1016/j.comcom.2007.12.005
   Nadeem T., 2006, 2006 Third Annual International Conference on Mobile and Ubiquitous Systems: Networking Services, P1
   Picconi Fabio., 2006, Proceedings of the 3rd ACM international workshop on Vehicular ad hoc networks, P76
   Raya M, 2007, J COMPUT SECUR, V15, P39, DOI 10.3233/JCS-2007-15103
   Raya M, 2007, IEEE J SEL AREA COMM, V25, P1557, DOI 10.1109/JSAC.2007.071006
   Seskar I, 1992, IEEE VEH TECHN C VTC
   Wang NW, 2008, COMPUT COMMUN, V31, P2827, DOI 10.1016/j.comcom.2007.12.003
   Wang Z, 2007, IEEE ICC, P3959, DOI 10.1109/ICC.2007.652
   Wex P, 2008, IEEE VTS VEH TECHNOL, P2800, DOI 10.1109/VETECS.2008.611
   Wu B, 2007, J NETW COMPUT APPL, V30, P937, DOI 10.1016/j.jnca.2005.07.008
   Yan GJ, 2008, COMPUT COMMUN, V31, P2883, DOI 10.1016/j.comcom.2008.01.009
NR 23
TC 62
Z9 65
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2013
VL 66
IS 2
BP 325
EP 338
DI 10.1007/s11042-011-0789-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 170PJ
UT WOS:000320865000011
DA 2024-07-18
ER

PT J
AU Aghaahmadi, M
   Dehshibi, MM
   Bastanfard, A
   Fazlali, M
AF Aghaahmadi, Mohammad
   Dehshibi, Mohammad Mahdi
   Bastanfard, Azam
   Fazlali, Mahmood
TI Clustering Persian viseme using phoneme subspace for developing visual
   speech application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio/visual processing; Computer assisted pronunciation training; Eigen
   space; Multimedia systems; Persian viseme clustering
ID COARTICULATION; CLASSIFICATION
AB There are numerous multimedia applications such as talking head, lip reading, lip synchronization, and computer assisted pronunciation training, which entices researchers to bring clustering and analyzing viseme into focus. With respect to the fact that clustering and analyzing visemes are language dependent process, we concentrated our research on Persian language, which indeed has suffered from the lack of such study. To this end, we proposed a novel adopting image-based approach which consists of four main steps including (a) extracting the lip region, (b) obtaining Eigenviseme of each phoneme considering coarticulation effect, (c) mapping each viseme into its subspace and other phonemes' subspaces in order to create the distance matrix so as to calculate the distance between viseme's cluster, and finally (d) comparing similarity of each viseme based on the weight value of reconstructed one. In order to indicate the robustness of the proposed algorithm, three sets of experiments were conducted on Persian and English databases in which Consonant/Vowel and Consonant/Vowel/Consonant syllables were examined. The results indicated that the proposed method outperformed the observed state-of-the-art algorithms in feature extraction, and it had a comparable efficiency in generating adequate clusters. Moreover, obtained results reached a milestone in grouping Persian visemes with respect to the perceptual test given by volunteers.
C1 [Aghaahmadi, Mohammad] Islamic Azad Univ, Qazvin Branch, Dept Elect Comp & Biomed Engn, Qazvin, Iran.
   [Dehshibi, Mohammad Mahdi] Islamic Azad Univ, Parand Branch, Dept IT, Fac Comp & IT, Parand, Iran.
   [Bastanfard, Azam] Islamic Azad Univ, Comp Engn Fac, Karaj, Iran.
   [Fazlali, Mahmood] Shahid Beheshti Univ, GC, Dept Comp Sci, Tehran, Iran.
C3 Islamic Azad University; Islamic Azad University; Islamic Azad
   University; Shahid Beheshti University
RP Aghaahmadi, M (corresponding author), Islamic Azad Univ, Qazvin Branch, Dept Elect Comp & Biomed Engn, Qazvin, Iran.
EM m.aghaahmadi@qiau.ac.ir; mohammad.dehshibi@piau.ac.ir;
   bastanfard@kiau.ac.ir; Fazlali@sbu.ac.ir
RI Dehshibi, Mohammad Mahdi/S-9946-2017; Fazlali, Mahmood/JCP-3157-2023;
   Bastanfard, Azam/AAX-8571-2020
OI Dehshibi, Mohammad Mahdi/0000-0001-8112-5419; Bastanfard,
   Azam/0000-0002-7935-819X; Fazlali, Mahmood/0000-0002-1701-5562
CR BALTER O, 2005, P 7 INT ACM SIGACCES
   Bastanfard A, 2010, P ADV MULT INF PROC
   Bastanfard A, 2009, P 2009 IEEE INT C SY
   Bastanfard A, 2009, LECT NOTES COMPUT SC, V5879, P1080, DOI 10.1007/978-3-642-10467-1_104
   Bastanfard A, 2010, LECT NOTES COMPUT SC, V5916, P284, DOI 10.1007/978-3-642-11301-7_30
   Belkin M, 2002, ADV NEUR IN, V14, P585
   BENGUEREL AP, 1982, J SPEECH HEAR RES, V25, P600, DOI 10.1044/jshr.2504.600
   Ezzat T, 2000, INT J COMPUT VISION, V38, P45, DOI 10.1023/A:1008166717597
   FISHER CG, 1968, J SPEECH HEAR RES, V11, P796, DOI 10.1044/jshr.1104.796
   Garcia C, 1998, WORKSH ADV FAC IM AN
   Harris CG, 1988, P ALV VIS C
   Hartigan J, 1979, J R STAT SOC C-APPL, V28, P100
   Henton C, 1996, MULTIMED TOOLS APPL, V3, P105, DOI 10.1007/BF00429747
   Karabalkan H, 2007, DSP IN VEH MOB SYST
   Kjellstrm H, 2007, 8 ANN C INT SPEECH C
   Kjellström H, 2009, SPEECH COMMUN, V51, P195, DOI 10.1016/j.specom.2008.07.005
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Krnoul Z, 2005, SPECOM MOSC RUSS
   LEHISTE I, 1972, J ACOUST SOC AM, V51, P101, DOI 10.1121/1.1981245
   Leszczynski M, 2005, LECT NOTES COMPUT SC, V3691, P773
   Löfqvist A, 2009, J ACOUST SOC AM, V125, P636, DOI 10.1121/1.2973234
   Mansoorizadeh M, 2010, MULTIMED TOOLS APPL, V49, P277, DOI 10.1007/s11042-009-0344-2
   Melenchon J., 2007, INT C AUD VIS SPEECH
   Mottonen R, 2000, P EUSIPCO 2000 TAMP
   Nefian A.V., 2002, P ICASSP 02
   Potamianos G, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P173, DOI 10.1109/ICIP.1998.999008
   Potamianos G, 2004, ISSUES INB VISUAL AU
   Safabakhsh R, 2006, INF COMM TECHN 2006, P2994
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Shaw R, 1996, MULTIMED TOOLS APPL, V3, P55, DOI 10.1007/BF00403084
   Tiddeman B., 2002, P COMP AN
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Visser M, 1999, P 2 INT WORKSH TEXT
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967
   Waters K., 1995, Multimedia Tools and Applications, V1, P349, DOI 10.1007/BF01215883
   Werda S., 2007, International Journal of Computing Information Sciences, V5, P62
   Williams JJ, 1998, J VLSI SIG PROCESS S, V20, P7, DOI 10.1023/A:1008062122135
   Yu K., 2002, HIDDEN MARKOV MODELS, P161
NR 38
TC 12
Z9 14
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2013
VL 65
IS 3
BP 521
EP 541
DI 10.1007/s11042-012-1128-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 144EO
UT WOS:000318922600009
DA 2024-07-18
ER

PT J
AU Hürst, W
   van Wezel, C
AF Huerst, Wolfgang
   van Wezel, Casper
TI Gesture-based interaction via finger tracking for mobile augmented
   reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Augmented reality on mobile devices; Finger tracking;
   Gesture interaction; Interaction design
ID PHONES
AB The goal of this research is to explore new interaction metaphors for augmented reality on mobile phones, i.e. applications where users look at the live image of the device's video camera and 3D virtual objects enrich the scene that they see. Common interaction concepts for such applications are often limited to pure 2D pointing and clicking on the device's touch screen. Such an interaction with virtual objects is not only restrictive but also difficult, for example, due to the small form factor. In this article, we investigate the potential of finger tracking for gesture-based interaction. We present two experiments evaluating canonical operations such as translation, rotation, and scaling of virtual objects with respect to performance (time and accuracy) and engagement (subjective user feedback). Our results indicate a high entertainment value, but low accuracy if objects are manipulated in midair, suggesting great possibilities for leisure applications but limited usage for serious tasks.
C1 [Huerst, Wolfgang; van Wezel, Casper] Univ Utrecht, Dept Informat & Comp Sci, NL-3584 CC Utrecht, Netherlands.
C3 Utrecht University
RP Hürst, W (corresponding author), Univ Utrecht, Dept Informat & Comp Sci, Princetonpl 5, NL-3584 CC Utrecht, Netherlands.
EM huerst@uu.nl
FU Yahoo!
FX This work was partially supported by a Yahoo! Faculty Research Grant.
CR Andel M, 2006, LECT NOTES COMPUT SC, V4282, P1008
   [Anonymous], EYESIGHTS TOUCH FREE
   [Anonymous], ACM SIGGRAPH 2010 EM
   Atchison DA, 2000, OPTICS HUMAN EYE, V1
   Baldauf M., 2011, Proceedings of the 13th International Conference on Human Computer Interaction with Mobile Devices and Services, P539, DOI DOI 10.1145/2037373.2037457
   Bergig O, 2009, INT SYM MIX AUGMENT, P87, DOI 10.1109/ISMAR.2009.5336490
   Billinghurst M, 2009, LECT NOTES COMPUT SC, V5622, P13, DOI 10.1007/978-3-642-02771-0_2
   Caballero Maria Luz, 2010, P 12 INT C HUMAN COM, P451
   Callahan J., 1988, P SIGCHI C HUM FACT
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Chehimi Fadi, 2008, International Symposium on Ubiquitous Virtual Reality - ISUVR 2008, P67, DOI 10.1109/ISUVR.2008.23
   Chehimi F, 2008, P 2008 INT C ADV COM
   Crowley J., 1995, International Workshop on Gesture and Face Recognition, P195
   Dorfmüller-Ulhaas K, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P55, DOI 10.1109/ISAR.2001.970515
   Gilbertson P., 2008, COMPUTER ENTERTAINME, V6
   Grandhi SA, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P821
   Ha T, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P91, DOI 10.1109/3DUI.2010.5444713
   Hagbi N, 2009, INT SYM MIX AUGMENT, P65, DOI 10.1109/ISMAR.2009.5336498
   Henrysson A., 2005, Proceedings of the 4th international conference on Mobile and ubiquitous multimedia, P95, DOI [DOI 10.1145/1149488.1149504, 10.1145/1149488.1149504]
   HENRYSSON A, 2007, P 7 ACM SIGCHI NZ CH, P9
   Henrysson A., 2005, Proc. 2005 Int. Conf. Augment. tele-existence - ICAT '05, P164, DOI [DOI 10.1145/1152399.1152430, 10.1145/1152399.1152430]
   Hürst W, 2011, LECT NOTES COMPUT SC, V6524, P157
   Huynh D.-N.T., 2009, Proceed- ings of the 2009 ACM SIGGRAPH Symposium on Video Games, Sandbox '09, P135, DOI [DOI 10.1145/1581073.1581095, 10.1145/1581073.1581095]
   Jung J, 2009, P 8 INT C VIRT REAL, P203
   Kato H, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P111, DOI 10.1109/ISAR.2000.880934
   Koike H., 2001, ACM Transactions on Computer-Human Interaction, V8, P307, DOI 10.1145/504704.504706
   KUMAR A, 1981, J MECH DES-T ASME, V103, P665, DOI 10.1115/1.3254968
   Lee M, 2008, LINC NZ 23 INT C IM
   Mistry P., 2009, SIGGRAPH ASIA Art Gallery Emerging Technologies, page, P85, DOI [10.1145/1667146.1667160, DOI 10.1145/1667146.1667160]
   Mistry P., 2009, P CHI 09 EXTENDED AB, P4111, DOI [DOI 10.1145/1520340.1520626, 10.1145/1520340.1520626]
   Rico J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P887
   Rohs M, 2005, 25TH IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, PROCEEDINGS, P506, DOI 10.1109/ICDCSW.2005.140
   Rohs M., 2004, Proc. 2nd International Symposium on Ubiquitous Computing Systems, P74
   Rohs M, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2725
   Ruiz J, ADJ P 23 ANN ACM S U, P449
   Ruiz J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2717
   Schmalstieg D., 2007, 6 IEEE ACM INT S MIX, P1
   Seo Byung-Kuk, 2008, P 7 ACM SIGGRAPH INT, P8
   Shaer Orit, 2010, Foundations and Trends in Human-Computer Interaction, V3, P1, DOI 10.1561/1100000026
   Terajima K., 2009, P CHI HUM FACT COMP, P3739, DOI [10.1145/1520340.1520564, DOI 10.1145/1520340.1520564]
   Wagner D, 2009, INT SYM MIX AUGMENT, P57, DOI 10.1109/ISMAR.2009.5336497
   Wagner D, 2008, INT SYM MIX AUGMENT, P121, DOI 10.1109/ISMAR.2008.4637337
   Wagner D, 2009, IEEE COMPUT GRAPH, V29, P6, DOI 10.1109/MCG.2009.67
   Wagner D, 2009, IEEE COMPUT GRAPH, V29, P12, DOI 10.1109/MCG.2009.46
   Wang R., 2011, Proceedings of the 24th annual ACM symposium on User interface software and technology. UIST '11, P549
   Wright M, 2011, LECT NOTES COMPUT SC, V6696, P294, DOI 10.1007/978-3-642-21726-5_19
   Yousefi S, 2011, LECT NOTES COMPUT SC, V6855, P555, DOI 10.1007/978-3-642-23678-5_66
NR 47
TC 102
Z9 117
U1 2
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2013
VL 62
IS 1
BP 233
EP 258
DI 10.1007/s11042-011-0983-y
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 076OL
UT WOS:000313965800011
OA hybrid
DA 2024-07-18
ER

PT J
AU Qian, XM
   Wang, H
   Liu, GZ
   Hou, XS
AF Qian, Xueming
   Wang, Huan
   Liu, Guizhong
   Hou, Xingsong
TI HMM based soccer video event detection using enhanced mid-level semantic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hidden Markov model; Highlight; Event detection; Shot classification;
   Soccer video
ID SHOT CLASSIFICATION; TEXT DETECTION; FRAMEWORK; LOCALIZATION
AB Highlight detection is a fundamental step in semantics based video retrieval and personalized sports video browsing. In this paper, an effective hidden Markov models (HMMs) based soccer video event detection method based on a hierarchical video analysis framework is proposed. Soccer video shots are classified into four coarse mid-level semantics: global, median, close-up and audience. Global and local motion information is utilized for the refinement of coarse mid-level semantics. Sequential soccer video is segmented into event clips. Both the temporal transitions of the mid-level semantics and the overall features of an event clip are fused using HMMs to determine the type of event. Highlight detection performance of dynamic Bayesian networks (DBN), conditional random fields (CRF) and the proposed HMM based approach are compared. The average F-score of our highlights (including goal, shoot, foul and placed kick) detection approach is 82.92%, which outperforms that of DBN and CRF by 9.85% and 11.12% respectively. The effects of number of hidden states, overall features, and the refinement of mid-level semantics on the event detection performance are also discussed.
C1 [Qian, Xueming; Wang, Huan; Liu, Guizhong; Hou, Xingsong] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Qian, XM (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM qianxm@mail.xjtu.edu.cn; houxs@mail.xjtu.edu.cn
RI Qian, Xueming/E-9867-2015
FU National Natural Science Foundation of China [60903121]; Chinese Center
   University Foundation [XJTU-HRT-002]; Microsoft Research Foundation
   [FY11-RES-THEME-052]
FX This work is supported by the National Natural Science Foundation of
   China No. 60903121, Chinese Center University Foundation XJTU-HRT-002,
   and Microsoft Research Foundation FY11-RES-THEME-052. The authors give
   their special thanks to Wenjun Zeng with the Computer Science Department
   of University of Missouri for proof reading the paper and discussion.
CR [Anonymous], 2020, INVENTIONS-BASEL
   [Anonymous], 2008, CIVR 08
   Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   Chen S., 2006, P ISM
   Cheng CC, 2006, IEEE T MULTIMEDIA, V8, P585, DOI 10.1109/TMM.2006.870726
   Dao M.-S., 2008, Proceeding of the 1st ACM workshop on Analysis and retrieval of events/actions and workflows in video streams - AREA'08, P33
   Duan L., 2003, P ACM MULT, P29
   Duan LY, 2005, IEEE T MULTIMEDIA, V7, P1066, DOI 10.1109/TMM.2005.858395
   Duan LY, 2003, PROC SPIE, V5021, P300, DOI 10.1117/12.476259
   Ekin A, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P169
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Hanjialic A., 2003, P IEEE INT C IM PROC, V1, P1
   Huang CL, 2006, IEEE T MULTIMEDIA, V8, P749, DOI 10.1109/TMM.2006.876289
   Jin GY, 2004, LECT NOTES COMPUT SC, V3211, P605
   Li BX, 2004, J VIS COMMUN IMAGE R, V15, P393, DOI 10.1016/j.jvcir.2004.04.006
   Lien CC, 2007, J VIS COMMUN IMAGE R, V18, P1, DOI 10.1016/j.jvcir.2006.09.002
   Lyu MR, 2005, IEEE T CIRC SYST VID, V15, P243, DOI 10.1109/TCSVT.2004.841653
   Minh-Son Dao, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P616, DOI 10.1109/MMSP.2008.4665150
   Mittal A, 2001, PROC CVPR IEEE, P110
   Nan N, 2008, SVM BASED SOCCER VID
   Pan H, 2002, INT CONF ACOUST SPEE, P3385
   Pan H, 2001, INT CONF ACOUST SPEE, P1649, DOI 10.1109/ICASSP.2001.941253
   Qian X, 2007, SIGNAL IMAGE VIDEO P
   Qian X, 2010, P ICIMCS
   Qian XM, 2007, SIGNAL PROCESS-IMAGE, V22, P752, DOI 10.1016/j.image.2007.06.005
   Qian XM, 2010, LECT NOTES COMPUT SC, V6298, P439, DOI 10.1007/978-3-642-15696-0_41
   Qian XM, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P44, DOI 10.1109/ISM.2009.14
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Sadlier D., 2005, IEEE T CIRCUITS SYST, V15, P602
   Snoek CGM, 2005, IEEE T MULTIMEDIA, V7, P638, DOI 10.1109/TMM.2005.850966
   Su YB, 2005, IEEE T CIRC SYST VID, V15, P232, DOI 10.1109/TCSVT.2004.841656
   Tjondronegoro DW, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P579, DOI 10.1109/ICME.2004.1394258
   Wang F, 2004, IEEE IMAGE PROC, P633
   Wang F., 2005, P INT C MULT MOD, P29
   Wang T., 2006, Computer Vision and Pattern Recognition Workshop, P109
   WANG Y, 2000, IEEE SIGNAL PROCESSI
   Wickramaratna K, 2005, IEEE INT SYM MULTIM, P21
   Xie LX, 2002, INT CONF ACOUST SPEE, P4096
   Xiong ZY, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P29
   Xu CS, 2008, IEEE T MULTIMEDIA, V10, P421, DOI 10.1109/TMM.2008.917346
   Xu CS, 2008, IEEE T MULTIMEDIA, V10, P1342, DOI 10.1109/TMM.2008.2004912
   Xu G, 2005, IEEE T CIRC SYST VID, V15, P1422, DOI 10.1109/TCSVT.2005.856903
   XU P, 2001, P INT C MULT EXP, P184
   Zhang D., 2002, ACM Multimedia, P315
   Zhao Z, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1613, DOI 10.1109/ICME.2006.262855
   Zhu GY, 2009, IEEE T MULTIMEDIA, V11, P49, DOI 10.1109/TMM.2008.2008918
   Zhu XQ, 2005, IEEE T KNOWL DATA EN, V17, P665, DOI 10.1109/TKDE.2005.83
NR 47
TC 22
Z9 26
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2012
VL 60
IS 1
BP 233
EP 255
DI 10.1007/s11042-011-0817-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 951FY
UT WOS:000304707500011
DA 2024-07-18
ER

PT J
AU Grana, C
   Borghesani, D
   Cucchiara, R
AF Grana, Costantino
   Borghesani, Daniele
   Cucchiara, Rita
TI Automatic segmentation of digitalized historical manuscripts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Manuscript; Image segmentation; Texture analysis
AB The artistic content of historical manuscripts provides a lot of challenges in terms of automatic text extraction, picture segmentation and retrieval by similarity. In particular this work addresses the problem of automatic extraction of meaningful pictures, distinguishing them from handwritten text and floral and abstract decorations. The proposed solution firstly employs a circular statistics description of a directional histogram in order to extract text. Then visual descriptors are computed over the pictorial regions of the page: the semantic content is distinguished from the decorative parts using color histograms and a novel texture feature called Gradient Spatial Dependency Matrix. The feature vectors are finally processed using an embedding procedure which allows increased performance in later SVM classification. Results for both feature extraction and embedding based classification are reported, supporting the effectiveness of the proposal on high resolution replicas of artistic manuscripts.
C1 [Grana, Costantino; Borghesani, Daniele; Cucchiara, Rita] Univ Modena & Reggio Emilia, I-41100 Modena, Italy.
C3 Universita di Modena e Reggio Emilia
RP Grana, C (corresponding author), Univ Modena & Reggio Emilia, Via Vignolese 905-B, I-41100 Modena, Italy.
EM costantino.grana@unimore.it
RI Grana, Costantino/B-4555-2012; Cucchiara, Rita/L-3006-2015
OI Grana, Costantino/0000-0002-4792-2358; Cucchiara,
   Rita/0000-0002-2239-283X
CR BARBU A, COMPUTER VISION PATT
   BIGUN J, 1996, ORIENTATION RADIOGRA, V3, P346
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Chen N, 2007, INT J DOC ANAL RECOG, V10, P1, DOI 10.1007/s10032-006-0020-2
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   Diligenti M, 2003, IEEE T PATTERN ANAL, V25, P519, DOI 10.1109/TPAMI.2003.1190578
   Fataicha Y, 2002, INT C PATT RECOG, P335, DOI 10.1109/ICPR.2002.1047861
   GILL G, 1981, ACM T MATH SOFTWARE, V7, P199
   GRANA C, 2007, INT C IM VID RETR, P302
   GRANA C, 2009, P IEEE INT C IM PROC
   Grana C, 2008, INT C PATT RECOG, P2677
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hjaltason GR, 2003, IEEE T PATTERN ANAL, V25, P530, DOI 10.1109/TPAMI.2003.1195989
   HU J, 1999, INT WORKSH DAT EXP S, P556
   Jain A K, 1988, ALGORITHMS CLUSTERIN
   Joachims T., 2002, LEARNING CLASSIFY TE
   Joachims Thorsten, 1998, EUROPEAN C MACHINE L, P137, DOI 10.1007/
   Journet N, 2008, INT J DOC ANAL RECOG, V11, P9, DOI 10.1007/s10032-008-0064-6
   Kavallieratou E, 2005, PROC INT CONF DOC, P463, DOI 10.1109/ICDAR.2005.1
   Kitamoto A, 2006, SECOND INTERNATIONAL CONFERENCE ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P133, DOI 10.1109/DIAL.2006.15
   KITTLER J, 1985, IMAGE VISION COMPUT, V3, P206, DOI 10.1016/0262-8856(85)90009-5
   Konidaris T, 2007, INT J DOC ANAL RECOG, V9, P167, DOI 10.1007/s10032-007-0042-4
   Le Bourgeois F, 2007, INT J DOC ANAL RECOG, V9, P193, DOI 10.1007/s10032-006-0030-0
   Le Bourgeois F, 2004, FIRST INTERNATIONAL WORKSHOP ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P2, DOI 10.1109/DIAL.2004.1263233
   MENG G, 2007, INT C DOC AN REC, V1, P143
   Nagy G, 2000, IEEE T PATTERN ANAL, V22, P38, DOI 10.1109/34.824820
   Nicolas S, 2007, PROC INT CONF DOC, P407
   OGIER J, 2006, P 1 EVA C OEST COMP, P107
   Pekalska E, 2002, PATTERN RECOGN LETT, V23, P943, DOI 10.1016/S0167-8655(02)00024-7
   Prati A., 2008, 2008 IEEE C COMP VIS, P1
   Ramel JY, 2006, SECOND INTERNATIONAL CONFERENCE ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P145, DOI 10.1109/DIAL.2006.2
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Shih FY, 2005, IMAGE VISION COMPUT, V23, P877, DOI 10.1016/j.imavis.2005.05.015
NR 33
TC 16
Z9 18
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2011
VL 55
IS 3
BP 483
EP 506
DI 10.1007/s11042-010-0561-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 815CV
UT WOS:000294504600006
DA 2024-07-18
ER

PT J
AU Zeng, W
   Hu, RM
   Ai, HJ
AF Zeng, Wei
   Hu, Ruimin
   Ai, Haojun
TI Audio steganalysis of spread spectrum information hiding based on
   statistical moment and distance metric
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Steganalysis; Audio; Spread spectrum
AB Audio information hiding has attracted more attentions recently. Spread spectrum (SS) technique has developed rapidly in this area due to the advantages of good robustness and immunity to noise attack. Accordingly detecting the SS hiding effectively and verifying the presence of the secrete message are important issues. In this paper we present two steganalysis algorithms for SS hiding. Both the two methods are based on machine learning theory and discrete wavelet transform (DWT). In the algorithm I, we introduce Gaussian mixture model (GMM) and generalize Gaussian distribution (GGD) to character the probability distribution of wavelet sub-band. Then the absolute probability distribution function (PDF) moment is extracted as feature vectors. In the algorithm II, we propose distance metric between GMM and GGD of wavelet sub-band to distinguish cover and stego audio. Four distance metrics (Kullback-Leibler Distance, Bhattacharyya Distance, Earth Mover's Distance, L2 Distance) are calculated as feature vectors. The support vector machine (SVM) classifier is utilized for classification. The experiment results of both two proposed algorithms can achieve better detecting performance. Even when embedding strength gets 0.0005, the correct detection rate can reach up to 90%. Its simplicity and extensibility indicate further application in other audio steganalysis.
C1 [Zeng, Wei; Hu, Ruimin; Ai, Haojun] Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.
   [Hu, Ruimin] Wuhan Univ, Dept Comp Sci, Wuhan 430072, Peoples R China.
C3 Wuhan University; Wuhan University
RP Zeng, W (corresponding author), Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.
EM eric.zengw@gmail.com; hrm1964@public.wh.hb.cn; ai.haojun@gmail.com
FU National Science Foundation of China [60832002]; Important National
   Science & Technology Specific Projects [2010ZX03004-003]; Wuhan
   University [6081012]
FX This work reported is supported by the National Science Foundation of
   China (grant 60832002), Important National Science & Technology Specific
   Projects (grant 2010ZX03004-003) and self-research program of Wuhan
   University (grant 6081012). We thank the anonymous reviewers for their
   insightful comments that help improve the presentation.
CR Abramovich F, 1998, J ROY STAT SOC B, V60, P725, DOI 10.1111/1467-9868.00151
   Altun O, 2005, INT CONF ACOUST SPEE, P21
   Avcibas I, 2006, IEEE SIGNAL PROC LET, V13, P92, DOI 10.1109/LSP.2005.862152
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   BAPTISTE J, 2004, FUNDAMENTALS CONVEX
   BASSEVILLE M, 1992, IEEE T INFORM THEORY, V38, P766, DOI 10.1109/18.119735
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Chang C., 2010, LIBSVM: A library for support vector machines 2010
   Chipman HA, 1997, J AM STAT ASSOC, V92, P1413, DOI 10.2307/2965411
   Chou K. C., 1994, Proceedings of the IEEE-SP International Symposium on Time-Frequency and Time-Scale Analysis (Cat. No.94TH8007), P25, DOI 10.1109/TFSA.1994.467371
   CHRISTIAN K, 2009, P MEDIA FORENSICS SE, V11
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   CVEJIC N, 2004, THESIS U OULU
   Daudet L, 2002, SIGNAL PROCESS, V82, P1595, DOI 10.1016/S0165-1684(02)00304-3
   Farid H, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P905
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Goljan M, 2006, PROC SPIE, V6072, DOI 10.1117/12.643254
   Gordy JD, 2000, PROCEEDINGS OF THE 43RD IEEE MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS I-III, P456, DOI 10.1109/MWSCAS.2000.951682
   HAMZA O, 2003, P SPIE SEC WAT MULT, P55
   Harmsen JJ, 2003, PROC SPIE, V5020, P131, DOI 10.1117/12.476813
   He JH, 2006, SCI CHINA SER F, V49, P273, DOI 10.1007/s11432-006-0273-x
   Holotyak T, 2005, LECT NOTES COMPUT SC, V3677, P273
   Johnson MK, 2005, PROC SPIE, V5681, P664, DOI 10.1117/12.586941
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   KALPANA S, 2005, P IEEE INT C IM PROC, V2, P1106
   KORZHIK VI, 1975, ERROR CORRECTING COD
   Kraetzer C, 2007, LECT NOTES COMPUT SC, V4567, P359
   Kraetzer C, 2007, PROC SPIE, V6505, DOI 10.1117/12.704040
   LANG A, 2006, SPIE C SECURITY STEG, V8
   LI JQ, 2000, ADV NEURAL INFORM PR
   Liu Q, 2008, IEEE IC COMP COM NET, P1
   Liu QZ, 2006, INT C PATT RECOG, P267
   Liu QZ, 2009, IEEE T INF FOREN SEC, V4, P359, DOI 10.1109/TIFS.2009.2024718
   Liu QZ, 2008, IEEE IJCNN, P3352, DOI 10.1109/IJCNN.2008.4634274
   LIU SH, 2004, P 5 WORLD C INT CONT, P4066
   Liu YL, 2008, LECT NOTES COMPUT SC, V5222, P487, DOI 10.1007/978-3-540-85886-7_33
   LIU ZL, 2006, INT C COMP INT SEC, V2, P1195
   Lyu SW, 2006, IEEE T INF FOREN SEC, V1, P111, DOI 10.1109/TIFS.2005.863485
   MARRON JS, 1992, ANN STAT, V20, P712, DOI 10.1214/aos/1176348653
   Qiao MY, 2009, 2009 INTERNATIONAL JOINT CONFERENCE ON BIOINFORMATICS, SYSTEMS BIOLOGY AND INTELLIGENT COMPUTING, PROCEEDINGS, P627, DOI 10.1109/IJCBS.2009.119
   Ru Xue-min, 2006, Journal of Zhejiang University (Science), V7, P577, DOI 10.1631/jzus.2006.A0577
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Sfikas G, 2005, LECT NOTES COMPUT SC, V3697, P835
   Shi YQ, 2005, ITCC 2005: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 1, P768, DOI 10.1109/ITCC.2005.138
   SHI YQ, 2007, 8 INT WORKSH INF HID, P249
   Sullivan K, 2005, PROC SPIE, V5681, P38, DOI 10.1117/12.588121
   SUN YF, 2008, LNCS, V5450, P184
   SURAJIT R, 2003, THESIS U PENNSYLVANI
   Ten Daubechies I., 1992, lecture on wavelets
   VANTREES HL, 1973, DETECTION ESTIMATI 1
   Vlassis N, 2002, NEURAL PROCESS LETT, V15, P77, DOI 10.1023/A:1013844811137
   Wang Y, 2003, PROCEEDINGS OF THE 2003 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING, P339
   Wang Y, 2008, IEEE T INFORM THEORY, V54, P2706, DOI 10.1109/TIT.2008.921684
   WEI QQ, 2007, J TSINGHUA U SCI TEC, V47, P595
   Xuan GR, 2005, LECT NOTES COMPUT SC, V3727, P262
   Zhai Wei-dong, 2004, Journal of China Institute of Communications, V25, P33
   2010, WAV SURFER DATABASE
NR 57
TC 4
Z9 5
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2011
VL 55
IS 3
BP 525
EP 556
DI 10.1007/s11042-010-0564-5
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 815CV
UT WOS:000294504600008
DA 2024-07-18
ER

PT J
AU Sun, J
   Xu, ZQ
   Liu, J
   Yao, Y
AF Sun, Jing
   Xu, Zhengquan
   Liu, Jin
   Yao, Ye
TI An objective visual security assessment for cipher-images based on local
   entropy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual security; Encryption; Objective assessment; Local entropy
ID VIDEO; SCHEME; CRYPTANALYSIS
AB In recent years, many practical algorithms have been put forward for images and videos encryption. Security analysis on these encryption algorithms focuses research on cryptographic security, and few work relate to visual security. Visual security means that the encrypted video content is unintelligible to human vision. The higher visual security the encryption algorithm can provide, the less information an attacker from the cipher-images to obtain, the greater the difficulty of attack is. Therefore, visual security assessment for cipher-images is a very important indicator in security evaluation of visual media. So far, systematic research on visual security assessment for cipher-images is far from enough. Moreover, there are no practical objective indicators or evaluation methods on visual security have been proposed at present. According to the changes on image information entropy between cipher-images and original images, we present a visual security assessment algorithm based on local entropy. The experiments result shows that the scheme can provide an efficient objective assessment which is match up to subjective assessment, and is also suitable for security assessment of other selective encryption algorithms.
C1 [Sun, Jing; Xu, Zhengquan; Liu, Jin; Yao, Ye] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
C3 Wuhan University
RP Xu, ZQ (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
EM sunjing528@163.com; xuzq@whu.edu.cn
FU National Basic Research Program of China [2006CB303104]; National
   Natural Science Foundation of China [40871200]
FX The work was supported by the National Basic Research Program of China
   (Grant No. 2006CB303104) and the National Natural Science Foundation of
   China (Grant No. 40871200).
CR Ahn J, 2004, LECT NOTES COMPUT SC, V3333, P386
   Bhargava B, 2004, MULTIMED TOOLS APPL, V24, P57, DOI 10.1023/B:MTAP.0000033983.62130.00
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kwon SG, 2005, LECT NOTES COMPUT SC, V3656, P207, DOI 10.1007/11559573_26
   Lee C, 2006, OPT ENG, V45, DOI 10.1117/1.2160515
   Li SJ, 2008, IEEE T CIRC SYST VID, V18, P338, DOI 10.1109/TCSVT.2008.918116
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Lian S., 2008, Multimedia Content Encryption: Techniques And Applications
   Lian SG, 2005, LECT NOTES COMPUT SC, V3768, P281, DOI 10.1007/11582267_25
   Lian SG, 2008, MULTIMED TOOLS APPL, V38, P75, DOI 10.1007/s11042-007-0150-7
   Mollin R.A., 2006, An introduction to cryptography
   NIKHIL R, 1991, IEEE T SYST MAN CY, V21, P1260
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Stuetz T, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P97
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Yao Y, 2009, INFORM-J COMPUT INFO, V33, P69
   Zhou JT, 2007, IEEE SIGNAL PROC LET, V14, P201, DOI 10.1109/LSP.2006.884012
   Zou YZ, 2006, IEEE T CONSUM ELECTR, V52, P1289, DOI 10.1109/TCE.2006.273147
NR 18
TC 28
Z9 30
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2011
VL 53
IS 1
BP 75
EP 95
DI 10.1007/s11042-010-0491-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 746AZ
UT WOS:000289214700004
DA 2024-07-18
ER

PT J
AU Amerini, I
   Ballocca, G
   Becarelli, R
   Borri, R
   Caldelli, R
   Filippini, F
AF Amerini, Irene
   Ballocca, Giovanni
   Becarelli, Rudy
   Borri, Roberto
   Caldelli, Roberto
   Filippini, Francesco
TI A DVB-MHP web browser to pursue convergence between Digital Terrestrial
   Television and Internet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital TV; XHTML; Web browser; DVB-MHP; Set-top-box; Design pattern;
   Java
ID ARCHITECTURE
AB In the last decade with the growth of Interactive Digital Television (IDTV) we have seen the end of passive television. An example of this trend is Internet access through television by means of the last generation Set Top Boxes (STBs). The chance to enjoy web contents through digital television Set Top Boxes, delivering a satisfying browsing experience across this platform, could provide the opportunity to promote social inclusion and bridging the "digital divide". In this paper we present WebClimb, a web browser that would pursue an effective integration of Digital Terrestrial Television (DTT) and Internet in the DVB-MHP platform. WebClimb is a Java-based web browser that enables users to browse the web by interacting with an easy to use Graphical User Interface (GUI), driven by a common TV remote control without asking for reformatting such a content on the server side. In addition to this, the main requirement has been to design and develop an MHP browser application to be broadcast through a TV channel and not embedded in a specific device, though it could be too. Experimental results and a comparison with other possible solutions are provided.
C1 [Amerini, Irene; Becarelli, Rudy; Caldelli, Roberto; Filippini, Francesco] Univ Florence, Media Integrat & Commun Ctr, Image & Commun Lab, Florence, Italy.
   [Ballocca, Giovanni; Borri, Roberto] CSP, Turin, Italy.
C3 University of Florence
RP Amerini, I (corresponding author), Univ Florence, Media Integrat & Commun Ctr, Image & Commun Lab, Florence, Italy.
EM irene.amerini@unifi.it; giovanni.ballocca@csp.it;
   rudy.becarelli@unifi.it; roberto.borri@csp.it;
   roberto.caldelli@unifi.it; francesco.filippini@unifi.it
RI Caldelli, Roberto/AAP-1708-2020; Amerini, Irene/AAD-4527-2019
OI Caldelli, Roberto/0000-0003-3471-1196; Amerini,
   Irene/0000-0002-6461-1391
FU Tuscany Region (Italy)
FX The authors would like to thank Tuscany Region (Italy) for supporting
   the DTT Competence Center which has carried out such a research.
CR *AMB DIG, RACC INT SERV INT TE
   ANDREADIS A, 2007, 15 INT C SOFTW TEL C, P1, DOI DOI 10.1109/SOFTCOM.2007.4446096
   [Anonymous], 1994, ADDISON WESLEY PROFE
   BERNARDINI A, 2005, EUROITV USER CTR ITV, P151
   Cesar P, 2006, MULTIMED TOOLS APPL, V30, P189, DOI 10.1007/s11042-006-0019-1
   CESAR P, 2007, EURO ITV, P11, DOI DOI 10.1007/978-3-540-72559-6_2
   CESAR P, 2005, THESIS HELSINKI U TE
   Cesar P, 2006, ACM T MULTIM COMPUT, V2, P343, DOI 10.1145/1201730.1201735
   Cho S, 2005, 7th International Conference on Advanced Communication Technology, Vols 1 and 2, Proceedings, P1089, DOI 10.1109/ICACT.2005.246148
   *DVB, 2003, 103 DVB ETSI
   *DVB, 2005, 112 DVB ETSI
   *DVB, 2008, 103 DVB ETSI
   Farias MCQ, 2008, IEEE MULTIMEDIA, V15, P64, DOI 10.1109/MMUL.2008.25
   Ferrandina G, 2006, BMC CANCER, V6, DOI 10.1186/1471-2407-6-169
   Ferretti S, 2007, ADV MULTIMED, V2007, DOI 10.1155/2007/16296
   Geleijnse G, 2009, EUROITV'09: PROCEEDINGS OF THE SEVENTH EUROPEAN INTERACTIVE TELEVISION CONFERENCE, P145
   Gil A, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA285
   GIL A, 2002, VID IM PROC MULT COM, P447, DOI DOI 10.1109/VIPROM.2002.1026700
   Grosskurth A, 2005, PROC IEEE INT CONF S, P661
   HONKALA M, 2004, IEEE 6 INT S MULT SO, P116
   IATRINO A, 2006, EURO ITV
   *INT INT TV GROUP, DIG TERR TEL DTT ACC
   *MHP KNOWL PROJ, 2006, MHP GUID
   Monroe RT, 1997, IEEE SOFTWARE, V14, P43, DOI 10.1109/52.566427
   *MOZ, 2009, MOZ LAYOUT ENG
   NEWELL J, 2002, INTRO MHP 1 0 MHP 1
   PABLO C, 2008, UXTV 08, P125, DOI DOI 10.1145/1453805.1453830
   PATERNO F, 2006, MODELS 06 WORKSH MOD
   Peng C., 2002, THESIS HELSINKI U TE
   Reimers U., 2005, DVB: The Family of International Standards for Digital Video Broadcasting, V2nd
   SEDLMEYER R, 2001, MULTIMEDIA HOME PLAT
   SOUZA GLF, 2007, J BRAZ COMPUT SOC, V13, P47
   STEVEN M, 2005, INTERACTIVE TV STAND
   VUORIMAA P, 2002, SAC 02, P1094, DOI DOI 10.1145/508791.509007
   W3C, 2000, XHTML 1 0 EXT HYP MA
   *W3C, 1998, CASC STYL SHEETS LEV
   Yamakami T, 2005, IEEE I C EMBED SOFTW, P102
NR 37
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2010
VL 50
IS 2
BP 381
EP 414
DI 10.1007/s11042-009-0415-4
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 622XE
UT WOS:000279698700005
DA 2024-07-18
ER

PT J
AU Simon, C
   Meessen, J
   De Vleeschouwer, C
AF Simon, Cedric
   Meessen, Jerome
   De Vleeschouwer, Christophe
TI Visual event recognition using decision trees
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Randomized decision trees; Automated visual surveillance system;
   Activity recognition
ID SURVEILLANCE; TRACKING
AB This paper presents a classifier-based approach to recognize dynamic events in video surveillance sequences. The goal of this work is to propose a flexible event recognition system that can be used without relying on a long-term explicit tracking procedure. It is composed of three stages. The first one aims at defining and building a set of relevant features describing the shape and movements of the foreground objects in the scene. To this aim, we introduce new motion descriptors based on space-time volumes. Second, an unsupervised learning-based method is used to cluster the objects, thereby defining a set of coarse to fine local patterns of features, representing primitive events in the video sequences. Finally, events are modeled as a spatio-temporal organization of patterns based on an ensemble of randomized trees. In particular, we want this classifier to discover the temporal and causal correlations between the most discriminative patterns. Our system is experimented and validated both on simulated and real-life data.
C1 [Simon, Cedric; De Vleeschouwer, Christophe] UCL, Commun & Remote Sensing Lab, Louvain, Belgium.
   [Meessen, Jerome] Multitel, Image Proc Dept, Res Inst, Mons, Belgium.
C3 Universite Catholique Louvain; University of Mons
RP Simon, C (corresponding author), UCL, Commun & Remote Sensing Lab, Louvain, Belgium.
EM cedric.simon@uclouvain.be; jerome.meessen@multitel.be;
   christophe.devleeschouwer@uclouvain.be
CR Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Buxton H, 2003, IMAGE VISION COMPUT, V21, P125, DOI 10.1016/S0262-8856(02)00127-0
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   DEE H, 2007, MACHINE VISION APPL
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Haering N, 2008, MACH VISION APPL, V19, P279, DOI 10.1007/s00138-008-0152-0
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Kadous MW, 2005, MACH LEARN, V58, P179, DOI 10.1007/s10994-005-5826-5
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Lin WY, 2008, IEEE INT SYMP CIRC S, P2737, DOI 10.1109/ISCAS.2008.4542023
   McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870
   Medioni G, 2001, IEEE T PATTERN ANAL, V23, P873, DOI 10.1109/34.946990
   Moosmann F, 2008, IEEE T PATTERN ANAL, V30, P1632, DOI 10.1109/TPAMI.2007.70822
   Nascimento JC, 2006, IEEE T MULTIMEDIA, V8, P761, DOI 10.1109/TMM.2006.876287
   OHTA N, 2001, ICCVO01, V1, P481
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Orrite C., 2008, P 1 INT WORKSH MACH, P185
   PEREZ O, 2007, IWINAC 2, P192
   Remagnino P, 1998, IMAGE VISION COMPUT, V16, P529, DOI 10.1016/S0262-8856(98)00099-7
   RIBEIRO PC, 2005, P INT WORKSH HUM ACT, P61
   SIMON C, 2009, VISUAL EVENT RECOGNI
   SIMON C, 2007, INT WORKSH IM AN MUL
   STAUFFER C, 1999, IEEE COMPUT VIS PATT, V2, P25
   VEERARAGHAVAN H, 2007, CVPR
   Wang L, 2007, IEEE T IMAGE PROCESS, V16, P1646, DOI 10.1109/TIP.2007.896661
   Wehenkel L., 1998, KLUW POWER
   Xiang T, 2006, INT J COMPUT VISION, V67, P21, DOI 10.1007/s11263-006-4329-6
   Yilmaz A, 2005, PROC CVPR IEEE, P984
   Zhang D, 2005, PROC CVPR IEEE, P611
NR 34
TC 16
Z9 19
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2010
VL 50
IS 1
SI SI
BP 95
EP 121
DI 10.1007/s11042-009-0364-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 616HE
UT WOS:000279198900006
DA 2024-07-18
ER

PT J
AU Rimac-Drlje, S
   Vranjes, M
   Zagar, D
AF Rimac-Drlje, Snjezana
   Vranjes, Mario
   Zagar, Drago
TI Foveated mean squared error-a novel video quality metric
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Foveated vision; Retinal image velocity; Spatio-temporal activity;
   Subjective quality assessment; Video quality metric
ID ALGORITHMS; VISION; MODEL
AB Efficiency of a video coding process, as well as accuracy of an objective video quality evaluation can be significantly improved by introduction of the human visual system (HVS) characteristics. In this paper we analyze one of these characteristics; namely, visual acuity reduction due to the foveated vision and object movements in a video sequence. We propose a new video quality metric called Foveated Mean Squared Error (FMSE) that takes into account a variable resolution of the HVS across the visual field. The highest visual acuity is at the point of fixation that falls into fovea, an area at retina with the highest density of photoreceptors. Visual acuity decreases rapidly for image regions which are further with respect to the fixation point. FMSE also utilizes the effect of additional spatial acuity reduction due to motion in a video sequence. The quality measures calculated by FMSE have shown a high correlation with experimental results obtained by subjective video quality assessment.
C1 [Rimac-Drlje, Snjezana; Vranjes, Mario; Zagar, Drago] Univ JJ Strossmayer Osijek, Fac Elect Engn, Osijek 31000, Croatia.
C3 University of JJ Strossmayer Osijek
RP Rimac-Drlje, S (corresponding author), Univ JJ Strossmayer Osijek, Fac Elect Engn, Kneza Trpimira 2B, Osijek 31000, Croatia.
EM snjezana.rimac@etfos.hr; mario.vranjes@etfos.hr; drago.zagar@etfos.hr
RI Rimac-Drlje, Snjezana/ACP-5982-2022
OI Rimac-Drlje, Snjezana/0000-0003-3081-6214; Vranjes,
   Mario/0000-0003-3563-4735
FU Croatian Ministry of Education, Science and Sports [165-0361630-1636,
   165-0362027-1479]
FX This work is supported by the Croatian Ministry of Education, Science
   and Sports through the projects 165-0361630-1636 and 165-0362027-1479.
CR Albanese M, 2004, MULTIMED TOOLS APPL, V24, P253, DOI 10.1023/B:MTAP.0000039421.91449.10
   [Anonymous], 2005, Digital Video Quality: Vision Models and Metrics
   [Anonymous], 2006, Digital Video Image Quality and Perceptual Coding
   [Anonymous], 2020, INT TELECOMMUNICATIO
   Arnow TL, 1996, P SOC PHOTO-OPT INS, V2674, P119, DOI 10.1117/12.237500
   BANKS MS, 1991, J OPT SOC AM A, V8, P1775, DOI 10.1364/JOSAA.8.001775
   Barten Peter G. J, 1999, Contrast sensitivity of the human eye and its effects on image quality
   Boccignone G, 2005, IEEE T CIRC SYST VID, V15, P365, DOI 10.1109/TCSVT.2004.842603
   Boccignone G, 2008, IEEE T CIRC SYST VID, V18, P1727, DOI 10.1109/TCSVT.2008.2005798
   Daly S, 1998, P SOC PHOTO-OPT INS, V3299, P180, DOI 10.1117/12.320110
   Eckert Michael P., 1993, P89
   Geisler WS, 1998, P SOC PHOTO-OPT INS, V3299, P294, DOI 10.1117/12.320120
   Ho CC, 2005, IEEE T CIRC SYST VID, V15, P1365, DOI 10.1109/TCSVT.2005.856929
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Le Meur O, 2007, VISION RES, V47, P2483, DOI 10.1016/j.visres.2007.06.015
   Lee H, 2006, IEEE SIGNAL PROC LET, V13, P553, DOI 10.1109/LSP.2006.874464
   Lee JW, 2002, QUANTUM INF PROCESS, V1, P129, DOI 10.1023/A:1019645000745
   Lee S, 2003, IEEE T CIRC SYST VID, V13, P149, DOI 10.1109/TCSVT.2002.808441
   LINDE I, 2008, SPATIAL VISION, V22, P161
   LISBERGER SG, 1981, J NEUROPHYSIOL, V46, P229, DOI 10.1152/jn.1981.46.2.229
   Masry M, 2006, IEEE T CIRC SYST VID, V16, P260, DOI 10.1109/TCSVT.2005.861946
   Privitera CM, 2000, IEEE T PATTERN ANAL, V22, P970, DOI 10.1109/34.877520
   Rajashekar U, 2008, IEEE T IMAGE PROCESS, V17, P564, DOI 10.1109/TIP.2008.917218
   Recommendation ITU-T P.910, 1999, P910 ITUT
   RIMACDRLJE S, 2009, P IWSSIP 2009 CHALK
   ROBSON JG, 1981, VISION RES, V21, P409, DOI 10.1016/0042-6989(81)90169-3
   STELMACH LB, 1994, P SOC PHOTO-OPT INS, V2179, P90, DOI 10.1117/12.172660
   Vranjes M, 2009, ELMAR PROC, P29
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Wang Z, 2001, PROC SPIE, V4472, P42, DOI 10.1117/12.449797
   Wang Z, 2001, IEEE T IMAGE PROCESS, V10, P1397, DOI 10.1109/83.951527
   Watson A.B., 1993, DIGITAL IMAGES HUMAN, P179
   Watson AB, 2001, J ELECTRON IMAGING, V10, P20, DOI 10.1117/1.1329896
   Xiao F., DCT BASED VIDEO QUAL
NR 34
TC 30
Z9 34
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2010
VL 49
IS 3
SI SI
BP 425
EP 445
DI 10.1007/s11042-009-0442-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 608ZF
UT WOS:000278623800003
DA 2024-07-18
ER

PT J
AU Batko, M
   Falchi, F
   Lucchese, C
   Novak, D
   Perego, R
   Rabitti, F
   Sedmidubsky, J
   Zezula, P
AF Batko, Michal
   Falchi, Fabrizio
   Lucchese, Claudio
   Novak, David
   Perego, Raffaele
   Rabitti, Fausto
   Sedmidubsky, Jan
   Zezula, Pavel
TI Building a web-scale image similarity search system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Similarity search; Content-based image retrieval; Metric space; MPEG-7
   descriptors; Peer-to-peer search network
ID IMPLEMENTATION
AB As the number of digital images is growing fast and Content-based Image Retrieval (CBIR) is gaining in popularity, CBIR systems should leap towards Web-scale datasets. In this paper, we report on our experience in building an experimental similarity search system on a test collection of more than 50 million images. The first big challenge we have been facing was obtaining a collection of images of this scale with the corresponding descriptive features. We have tackled the non-trivial process of image crawling and extraction of several MPEG-7 descriptors. The result of this effort is a test collection, the first of such scale, opened to the research community for experiments and comparisons. The second challenge was to develop indexing and searching mechanisms able to scale to the target size and to answer similarity queries in real-time. We have achieved this goal by creating sophisticated centralized and distributed structures based purely on the metric space model of data. We have joined them together which has resulted in an extremely flexible and scalable solution. In this paper, we study in detail the performance of this technology and its evolvement as the data volume grows by three orders of magnitude. The results of the experiments are very encouraging and promising for future applications.
C1 [Batko, Michal; Novak, David; Sedmidubsky, Jan; Zezula, Pavel] Masaryk Univ, Fac Informat, Brno, Czech Republic.
   [Falchi, Fabrizio; Lucchese, Claudio; Perego, Raffaele; Rabitti, Fausto] CNR, ISTI, I-56100 Pisa, Italy.
C3 Masaryk University Brno; Consiglio Nazionale delle Ricerche (CNR);
   Istituto di Scienza e Tecnologie dell'Informazione "Alessandro Faedo"
   (ISTI-CNR)
RP Sedmidubsky, J (corresponding author), Masaryk Univ, Fac Informat, Brno, Czech Republic.
EM batko@fi.muni.cz; fabrizio.falchi@isti.cnr.it;
   claudio.lucchese@isti.cnr.it; david.novak@fi.muni.cz;
   raffaele.perego@isti.cnr.it; fausto.rabitti@isti.cnr.it;
   xsedmid@fi.muni.cz; zezula@fi.muni.cz
RI Batko, Michal/D-9889-2012; Sedmidubsky, Jan/J-3195-2013; Falchi,
   Fabrizio/J-2920-2012; Perego, Raffaele/Q-4712-2019; Novak,
   David/C-3621-2012; Lucchese, Claudio/G-3947-2012; Lucchese,
   Claudio/B-6410-2015
OI Sedmidubsky, Jan/0000-0002-7668-8521; Falchi,
   Fabrizio/0000-0001-6258-5313; Perego, Raffaele/0000-0001-7189-4724;
   Lucchese, Claudio/0000-0002-2545-0425
FU EU [045128]; IBM SUR;  [GACR 201/08/P507];  [GACR 201/09/0683];  [GACR
   102/09/H042];  [MSMT 1M0545]
FX This research was supported by the EU IST FP6 project 045128 (SAPIR) and
   national projects GACR 201/08/P507, GACR 201/09/0683, GACR 102/09/H042,
   and MSMT 1M0545. Hardware infrastructure was provided by
   MetaCenter<SUP>17</SUP> and by IBM SUR Award.
CR Amato G, 2003, ACM T INFORM SYST, V21, P192, DOI 10.1145/763693.763696
   AMATO G, 2004, P WORKSH MULT INF SY, P139
   [Anonymous], P SIGCOMM 01, DOI DOI 10.1145/383059.383071
   Aspnes J, 2003, SIAM PROC S, P384
   BAEZAYATES RA, 2004, CIVR, P189
   BATKO M, 2006, P 1 INT C SCAL INF S, P1
   Batko M, 2007, LECT NOTES COMPUT SC, V4877, P1
   Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426
   Datta AK, 2008, OPT LASER TECHNOL, V40, P1, DOI 10.1016/j.optlastec.2007.04.006
   DOHNAL V, 2008, 1 INT WORKSH SIM SEA, P1
   GELASCA ED, 2007, CORTINA SEARCHING 10
   *ISO IEC, 2003, 1593862003 ISOIEC
   Jagadish HV, 2005, ACM T DATABASE SYST, V30, P364, DOI 10.1145/1071610.1071612
   Kumar R., 2006, P 12 ACM SIGKDD INT, P611, DOI DOI 10.1007/978-1-4419-6515-8_13
   LI J, 2006, MULTIMEDIA 06, P911, DOI DOI 10.1145/1180639.1180841
   MANJUNATH B, 2002, INTRO MPEG 7 MUTIMED
   *MPEG 7, 2002, 1593832002 MPEG7 ISO
   Novak D., 2006, Proceedings of the 1st international conference on Scalable Information Systems, V1, P1
   NOVAK D, 2008, P 6 INT WORKSH CONT, P8
   NOVAK D, 2009, P 32 ACM SIGIR C RES
   SKOPAL T, 2004, P ADBIS BUD
   Traina C, 2000, LECT NOTES COMPUT SC, V1777, P51
   VELTKAMP RC, 2002, UUCS200034
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Zezula P, 1998, VLDB J, V7, P275, DOI 10.1007/s007780050069
   Zezula P., 2006, Advances in Database Systems, V32, DOI [DOI 10.1007/0-387-29151-2, 10.1007/0-387-29151-2]
NR 26
TC 8
Z9 9
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 47
IS 3
SI SI
BP 599
EP 629
DI 10.1007/s11042-009-0339-z
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 572BC
UT WOS:000275800200012
DA 2024-07-18
ER

PT J
AU Piro, P
   Anthoine, S
   Debreuve, E
   Barlaud, M
AF Piro, Paolo
   Anthoine, Sandrine
   Debreuve, Eric
   Barlaud, Michel
TI Combining spatial and temporal patches for scalable video indexing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scalable video indexing; Sparse multiscale patches descriptors; Motion
   patches descriptors; Kullback-Leibler divergence
AB This paper tackles the problem of scalable video indexing. We propose a new framework combining spatial and motion patch descriptors. The spatial descriptors are based on a multiscale description of the image and are called Sparse Multiscale Patches. We propose motion patch descriptors based on block motion that describe the motion in a Group of Pictures. The distributions of these sets of patches are compared combining weighted Kullback-Leibler divergences between spatial andmotion patches. These divergences are estimated in a non-parametric framework using a k-th Nearest Neighbor estimator. We evaluate this weighted dissimilarity measure on selected videos from the ICOS-HD ANR project. Experiments show that the spatial part of the measure is relevant to detect different sequences, while its motion part allows to detect clips within a sequence. Experiments combining the spatial and temporal parts of the dissimilarity measure show its robustness to resampling and compression; thus exhibiting the spatial scalability of the method on heterogeneous networks.
C1 [Piro, Paolo; Anthoine, Sandrine; Debreuve, Eric; Barlaud, Michel] Univ Nice, I3S Lab, CNRS, F-06903 Sophia Antipolis, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite Cote
   d'Azur
RP Anthoine, S (corresponding author), Univ Nice, I3S Lab, CNRS, 2000 Route Lucioles,Bat Euclide B,BP 121, F-06903 Sophia Antipolis, France.
EM piro@i3s.unice.fr; anthoine@i3s.unice.fr; debreuve@i3s.unice.fr;
   barlaud@i3s.unice.fr
FU French ANR
FX This work is supported by the French ANR grant "ICOS-HD".
CR BOLTZ S, 2007, CVPR
   Hero A. O., 2001, Technical Report CSPL-328
   Laptev I, 2007, IEEE I CONF COMP VIS, P2165
   LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079
   Mezaris V, 2006, MULTIMED TOOLS APPL, V30, P255, DOI 10.1007/s11042-006-0028-0
   MORAND C, 2007, IEEE VMDL ICIAP
   PIRO P, 2009, LNCS, V5416
   PIRO P, 2008, CBMI
   Rothganger F, 2007, IEEE T PATTERN ANAL, V29, P477, DOI 10.1109/TPAMI.2007.57
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   TERRELL GR, 1992, ANN STAT, V20, P1236, DOI 10.1214/aos/1176348768
   ZHAI Y, 2005, TRECVID05
   Zhong D, 1999, IEEE T CIRC SYST VID, V9, P1259, DOI 10.1109/76.809160
NR 13
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 48
IS 1
SI SI
BP 89
EP 104
DI 10.1007/s11042-009-0350-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 575PM
UT WOS:000276079400006
DA 2024-07-18
ER

PT J
AU Tsai, MF
   Shieh, CK
   Ke, CH
   Deng, DJ
AF Tsai, Ming-Fong
   Shieh, Ce-Kuen
   Ke, Chih-Heng
   Deng, Der-Jiunn
TI Sub-packet forward error correction mechanism for video streaming over
   wireless networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sub-packet; Forward error correction; Video streaming; Wireless networks
ID TRANSMISSION; INTERNET; SCHEME; ARQ
AB Traditional Forward Error Correction (FEC) mechanisms can be divided into Packet level FEC (PFEC) mechanisms and Byte level FEC (BFEC) mechanisms. The PFEC mechanism of recovering from errors in a source packet requires an entire FEC redundant packet even though the error involves a few bit errors. The recovery capability of the BFEC mechanism is only half of the FEC redundancy. Accordingly, an adaptive Sub-Packet FEC (SPFEC) mechanism is proposed in this paper to improve the quality of video streaming data over wireless networks, simultaneously enhancing the recovery performance and reducing the end-to-end delay jitter. The SPFEC mechanism divides a packet into n sub-packets by means of the concept of a virtual packet. The SPFEC mechanism uses a checksum in each sub-packet to identify the position of the error sub-packet. Simulation experiments show the adaptive SPFEC mechanism achieves high recovery performance and low end-to-end delay jitter. The SPFEC mechanism outperforms traditional FEC mechanism in terms of packet loss rate and video Peak Signal-to-Noise Ratio (PSNR). SPFEC offers an alternative for improved efficiency video streaming that will be of interest to the designers of the next generation environments.
C1 [Deng, Der-Jiunn] Natl Changhua Univ Educ, Dept Comp Sci & Informat Engn, Changhua, Taiwan.
   [Tsai, Ming-Fong; Shieh, Ce-Kuen] Natl Cheng Kung Univ, Dept Elect Engn, Inst Comp & Commun Engn, Tainan 70101, Taiwan.
   [Ke, Chih-Heng] Natl Kinmen Inst Technol, Dept Comp Sci & Informat Engn, Jinning, Kinmen, Taiwan.
   [Shieh, Ce-Kuen] Natl Cheng Kung Univ, Ctr Comp, Network Grp, Tainan 70101, Taiwan.
C3 National Changhua University of Education; National Cheng Kung
   University; National Cheng Kung University
RP Deng, DJ (corresponding author), Natl Changhua Univ Educ, Dept Comp Sci & Informat Engn, Bao Shan Campus,2 Shi Da Rd, Changhua, Taiwan.
EM fone@hpds.ee.ncku.edu.tw; shieh@ee.ncku.edu.tw; smallko@gmail.com;
   djdeng@cc.ncue.edu.tw
CR Agrawal P, 2008, IEEE COMMUN MAG, V46, P138, DOI 10.1109/MCOM.2008.4427242
   Argyriou A, 2008, IEEE T MULTIMEDIA, V10, P1121, DOI 10.1109/TMM.2008.2001371
   Bai C, 2008, IEICE T COMMUN, VE91B, P1375, DOI 10.1093/ietcom/e91-b.5.1375
   Barakat C, 2004, PERFORM EVALUATION, V57, P453, DOI 10.1016/j.peva.2004.03.002
   Choi JY, 2007, COMPUT COMMUN, V30, P1476, DOI 10.1016/j.comcom.2006.12.027
   Choi S, 2006, IEEE T WIREL COMMUN, V5, P203, DOI 10.1109/TWC.2006.01014
   Choi S, 2002, GLOB TELECOMM CONF, P773
   Ding JW, 2003, MULTIMED TOOLS APPL, V21, P281, DOI 10.1023/A:1025727002272
   Girod B, 2002, WIREL COMMUN MOB COM, V2, P573, DOI 10.1002/wcm.87
   Huang YF, 2008, MULTIMED TOOLS APPL, V36, P267, DOI 10.1007/s11042-007-0146-3
   Kantarci A, 2008, MULTIMED TOOLS APPL, V36, P303, DOI 10.1007/s11042-007-0147-2
   Korhonen J, 2006, MULTIMED TOOLS APPL, V29, P305, DOI 10.1007/s11042-006-0016-4
   Lin CH, 2008, IEEE T BROADCAST, V54, P517, DOI 10.1109/TBC.2008.2001713
   Luo HL, 2008, MULTIMED TOOLS APPL, V40, P111, DOI 10.1007/s11042-007-0187-7
   Nafaa A, 2008, IEEE COMMUN MAG, V46, P72, DOI 10.1109/MCOM.2008.4427233
   Naor Z, 2007, WIREL COMMUN MOB COM, V7, P173, DOI 10.1002/wcm.472
   SCHULZRINNE H, 1996, 1889 RFC
   Shu Lin., 1983, ERROR CONTROL CODING
   Sun HF, 2007, WIREL COMMUN MOB COM, V7, P159, DOI 10.1002/wcm.471
   Taubman D, 2005, IEEE T IMAGE PROCESS, V14, P1006, DOI 10.1109/TIP.2005.846028
   TSAI M, 2008, IEEE INT C HIGH PERF, P625
   Tsai M.-F., 2008, IEEE INT C TEL RUSS, P1
   Tunali ET, 2005, MULTIMED TOOLS APPL, V27, P431, DOI 10.1007/s11042-005-4090-9
   Zhou YQ, 2006, IEEE T COMMUN, V54, P934, DOI 10.1109/TCOMM.2005.863724
   Ziviani A, 2005, MULTIMED TOOLS APPL, V26, P59, DOI 10.1007/s11042-005-6849-4
   MPEG TRACE
NR 26
TC 23
Z9 26
U1 7
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2010
VL 47
IS 1
BP 49
EP 69
DI 10.1007/s11042-009-0406-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 554LV
UT WOS:000274437400004
DA 2024-07-18
ER

PT J
AU Lin, CS
   Syu, WT
AF Lin, Chow-Sing
   Syu, Wei-Ting
TI A fine-grained balancing scheme for improved scalability in P2P
   streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Peer-to-peer; Streaming; Multiple description coding; Load balancing;
   Scalability
AB In this paper, we relax the restriction imposed in our previously proposed balancing scheme that a peer is allowed to forward only one specific description to others, and propose the fine-grained balancing scheme to further improve the scalability of P2P live streaming systems based on multiple description coding (MDC) techniques. Like the balancing scheme, the fine-grained balancing scheme is capable of balancing the distribution of descriptions and streaming workload among peers by means of a centralized description allocation scheme. Moreover, relaxing the restriction on peers' description provision enables the proposed fine-grained balancing scheme to utilize peers' outbound bandwidth more flexibly and efficiently than the balancing scheme. The experiment results show that with the proposed scheme the utilization of peers' bandwidth can be greatly improved, thereby reducing the server bandwidth consumption and the rejection rate. As a result, more peers can be served and peers are enabled to recover from failure mostly by themselves with little server involvement.
C1 [Lin, Chow-Sing] Natl Univ Tainan, Dept Comp Sci & Informat Engn, Tainan 700, Taiwan.
   [Syu, Wei-Ting] So Taiwan Univ, Dept Informat Management, Yung Kang 710, Tainan Shien, Taiwan.
C3 National University Tainan; Southern Taiwan University of Science &
   Technology
RP Lin, CS (corresponding author), Natl Univ Tainan, Dept Comp Sci & Informat Engn, 33 Sec 2,Shu Lin St, Tainan 700, Taiwan.
EM mikelin@mail.nutn.edu.tw; swkca@hotmail.com
RI Lin, Chow-Sing/JPX-6621-2023
FU National Science Council, Taiwan [95-2221-E-218-015-MY2]
FX This work has been partially supported by the National Science Council,
   Taiwan, under Contract 95-2221-E-218-015-MY2.
CR [Anonymous], P ACM NOSSDAV 2003 M
   Banerjee S, 2002, ACM SIGCOMM COMP COM, V32, P205, DOI 10.1145/964725.633045
   Castro M., 2003, Operating Systems Review, V37, P298, DOI 10.1145/1165389.945474
   Chu Y., 2001, P ACM SIGCOMM, P55
   CLARKE I, 2000, P WORKSH DES ISS AN, P311
   Cui Y, 2004, IEEE J SEL AREA COMM, V22, P91, DOI 10.1109/JSAC.2003.818799
   Dan A., 1994, Proceedings ACM Multimedia '94, P15, DOI 10.1145/192593.192614
   Deshpande H., 2001, STREAMING LIVE MEDIA
   Do TT, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P1467, DOI 10.1109/ICC.2004.1312755
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   Guo Y., 2003, Proceedings of the 12th International Conference on World Wide Web, P301, DOI DOI 10.1145/775152.775195
   Hua K. A., 1998, Proceedings ACM Multimedia 98, P191, DOI 10.1145/290747.290771
   Hua KA, 1997, IEEE INFOCOM SER, P990, DOI 10.1109/INFCOM.1997.631037
   JIN S, 2002, P INT WORKSH NETW GR
   Juhn LS, 1997, IEEE T BROADCAST, V43, P268, DOI 10.1109/11.632927
   LIN CS, 2007, P INT C HIGH PERF CO, P104
   Padmanabhan V.N., 2002, P 12 INT WORKSHOP NE, P177
   Padmanabhan VN, 2003, 11TH IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P16, DOI 10.1109/ICNP.2003.1249753
   Rejaie R, 2000, IEEE J SEL AREA COMM, V18, P2530, DOI 10.1109/49.898735
   Ripeanu M, 2002, FIRST INTERNATIONAL CONFERENCE ON PEER-TO-PEER COMPUTING, P99, DOI 10.1109/P2P.2001.990433
   SAROIU S, 2002, P MULT COMP NETW
   Sheu S, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P110, DOI 10.1109/MMCS.1997.609583
   Tran DA, 2003, IEEE INFOCOM SER, P1283
   Viswanathan S, 1996, MULTIMEDIA SYST, V4, P197, DOI 10.1007/s005300050023
   Wang Y, 2005, P IEEE, V93, P57, DOI 10.1109/JPROC.2004.839618
   ZENG M, 2006, P IEEE GCCW, P143
NR 26
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2010
VL 46
IS 1
BP 71
EP 90
DI 10.1007/s11042-009-0308-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 537DQ
UT WOS:000273093600004
DA 2024-07-18
ER

PT J
AU Zhang, YF
   Xu, CS
   Zhang, XY
   Lu, HQ
AF Zhang, Yi-Fan
   Xu, Changsheng
   Zhang, Xiaoyu
   Lu, Hanqing
TI Personalized retrieval of sports video based on multi-modal analysis and
   user preference acquisition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic annotation; Video indexing; Video retrieval
ID SOCCER VIDEO
AB In this paper, we present a novel framework on personalized retrieval of sports video, which includes two research tasks: semantic annotation and user preference acquisition. For semantic annotation, web-casting texts which are corresponding to sports videos are firstly captured from the webpages using data region segmentation and labeling. Incorporating the text, we detect events in the sports video and generate video event clips. These video clips are annotated by the semantics extracted from web-casting texts and indexed in a sports video database. Based on the annotation, these video clips can be retrieved from different semantic attributes according to the user preference. For user preference acquisition, we utilize click-through data as a feedback from the user. Relevance feedback is applied on text annotation and visual features to infer the intention and interested points of the user. A user preference model is learned to re-rank the initial results. Experiments are conducted on broadcast soccer and basketball videos and show an encouraging performance of the proposed method.
C1 [Zhang, Yi-Fan; Xu, Changsheng; Zhang, Xiaoyu; Lu, Hanqing] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
   [Zhang, Yi-Fan; Xu, Changsheng; Zhang, Xiaoyu; Lu, Hanqing] China Singapore Inst Digital Media, Singapore 119615, Singapore.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Zhang, YF (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
EM yfzhang@nlpr.ia.ac.cn; csxu@nlpr.ia.ac.cn; xyzhang@nlpr.ia.ac.cn;
   luhq@nlpr.ia.ac.cn
RI Wang, Zixuan/HZJ-2348-2023; Zhang, xiaoyu/GXA-3206-2022; xiaoyu,
   zhang/JXY-7226-2024; xu, cj/HJZ-3488-2023; zhang, yifan/ABB-5853-2021;
   Zhang, Xiaoyu/N-6847-2014; Zhang, Xiaoyu/ISV-0984-2023; zhang,
   xiaoyu/HJI-4374-2023
FU National Natural Science Foundation of China [60833006]; 863 Program of
   China [2006AA01Z315]
FX This work is supported by National Natural Science Foundation of China (
   Grant No. 60833006) and the 863 Program of China ( Grant No.
   2006AA01Z315).
CR [Anonymous], 1995, P IEEE INT C MULT CO
   Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   Babaguchi N, 2004, IEEE T MULTIMEDIA, V6, P575, DOI [10.1109/TMM.2004.830811, 10.1109/tmm.2004.830811]
   Bertini M, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING WORKSHOPS, PROCEEDINGS, P160, DOI 10.1109/ICIAPW.2007.43
   Cai Deng., 2004, P 27 ANN INT ACM SIG, P456
   CHESHIRE D, 1990, COMPLETE BOOK VIDEO
   DAHYOT R, 2003, P INT C AC SPEECH SI
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Duan LY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P709
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   FLEISCHMAN M, 2007, HUMAN LANGUAGE TECHN, P37
   Han M., 2002, Proc. ACM Multimedia, P347, DOI [DOI 10.1145/641007.641081, 10.1145/641007.641081]
   HSU WH, 2006, P 14 ACM INT C MULT, P22
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Kokaram A, 2006, IEEE SIGNAL PROC MAG, V23, P47, DOI 10.1109/MSP.2006.1621448
   Lafferty John, 2001, INT C MACH LEARN ICM
   Leonardi R, 2004, IEEE T CIRC SYST VID, V14, P634, DOI 10.1109/TCSVT.2004.826751
   Li Y, 2004, IEEE T CIRC SYST VID, V14, P1073, DOI 10.1109/TCSVT.2004.831968
   Li YQ, 2006, INT C PATT RECOG, P128
   LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116
   McDonald K, 2005, LECT NOTES COMPUT SC, V3568, P61
   Nepal S., 2001, ACM Multimedia, P261
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rocha L., 2003, A Practical Approach to Microarray Data Analysis, P91, DOI [10.1007/0-306-47815-3, DOI 10.1007/0-306-47815-35, 10.1007/0-306-47815-3_5, DOI 10.1007/0-306-47815-3_5]
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Rui Y., 2000, Proceedings ACM Multimedia 2000, P105, DOI 10.1145/354384.354443
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Sebe N, 2003, LECT NOTES COMPUT SC, V2728, P1
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   VELTKAMP RC, 2001, STATE OF THE ART CON
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   WANG J, 2005, P INT C AC SPEECH SI
   Xie LX, 2004, PATTERN RECOGN LETT, V25, P767, DOI 10.1016/j.patrec.2004.01.005
   XIONG Z, 2003, P INT C AC SPEECH SI
   Xu C., 2006, PROC 14 ANN ACM INT, P221, DOI DOI 10.1145/1180639.1180699
   XU H, 2005, P IEEE ICME 05 AMST, P1242
   XUE GR, 2004, P 13 ACM INT C INF K, P118
   Yan R., 2004, PROC ACM INT C MULTI, P548
   Zhang D., 2002, ACM Multimedia, P315
   Zhang J, 2007, PROCEEDINGS OF 2007 INTERNATIONAL WORKSHOP ON SIGNAL DESIGN AND ITS APPLICATIONS IN COMMUNICATIONS, P313
NR 40
TC 7
Z9 9
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2009
VL 44
IS 2
BP 305
EP 330
DI 10.1007/s11042-009-0291-y
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 464ED
UT WOS:000267487100007
DA 2024-07-18
ER

PT J
AU Guerri, J
   Antón, AB
   Pajares, A
   Monfort, M
   Sánchez, D
AF Guerri, Juan C.
   Anton, Ana Belen
   Pajares, Ana
   Monfort, Manuel
   Sanchez, Daniel
TI A mobile device application applied to low back disorders
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless telemedicine; Handheld devices; Multimedia; Health monitoring;
   Electromyography; Usability
ID USABILITY; SYSTEM; RELIABILITY; HEALTH
AB Many muscular function assessments require the monitoring of muscular activity in different environments. This can happen in the gymnasium during a training session or while practising a sport; at work, where movements and specific actions are executed; at school, where the child adopts an incorrect posture, or even while we walk. In this paper, we propose a system to allow the assessment of the muscular condition in any of these environments in a comfortable and simple way for the patient and using the advances in wireless communications. Just a wireless biomonitor (we have used the ME6000 biomonitor, a medical portable equipment of very small dimensions) and one PDA or mobile phone with wireless interface are needed. The medical device is configured from the mobile device. Then, wireless communications are used to transmit online the electromyographic signals registered by the medical equipment to a mobile device. The specific protocol used by the medical device is implemented to carry out the communication. There are two ways to configure the system: offline and online. In offline mode, once all the information is received, it is sent to a server using a connection to the Internet instead of the online way, where this information is sent simultaneously. The server includes a background application to process the information in real-time with the aim to evaluate the function of the muscle during the exercise and to establish healthy behaviours for the patient. Then, this information can be consulted by the specialist and also by the client using the PDA or mobile phone to show the report. A prototype of this system has been developed and implemented. The system has been evaluated by a preliminary usability, reliability, feasibility and communication performance study.
C1 [Guerri, Juan C.; Anton, Ana Belen; Pajares, Ana] Univ Politecn Valencia, Inst Telecommun & Multimedia Applicat iTEAM, E-46071 Valencia, Spain.
   [Monfort, Manuel] Univ Valencia, Unidad Docente Educ Fis, Dept Didact Expres Corporal, Valencia, Spain.
   [Sanchez, Daniel] Univ Valencia, Dept Anat & Embriol Humana, Valencia 46010, Spain.
C3 Universitat Politecnica de Valencia; University of Valencia; University
   of Valencia
RP Guerri, J (corresponding author), Univ Politecn Valencia, Inst Telecommun & Multimedia Applicat iTEAM, E-46071 Valencia, Spain.
EM jcguerri@dcom.upv.es; anangi@iteam.upv.es; apajares@dcom.upv.es;
   manuel.monfort@uv.es; Daniel.Sanchez@uv.es
RI Monfort-Pañego, Manuel/A-8851-2009; Guerri, Juan Carlos/K-9659-2014
OI Monfort-Pañego, Manuel/0000-0002-3181-2170; Guerri, Juan
   Carlos/0000-0002-5807-1923
FU Spanish Ministerio de Educacion y Ciencia [TEC2007-68119-C02-01/TCM]
FX This work was supported by the Spanish Ministerio de Educacion y Ciencia
   within the MIQUEL (TEC2007-68119-C02-01/TCM) project.
CR [Anonymous], 1985, Muscle alive: their functions revealed by electromyography
   Borenstein D G., 1995, Low Back Pain, Medical diagnosis and comprehensive management, P183
   Budinger TE, 2003, ANNU REV BIOMED ENG, V5, P383, DOI 10.1146/annurev.bioeng.5.040202.121653
   Choi J, 2006, IEEE T INF TECHNOL B, V10, P627, DOI 10.1109/TITB.2006.874201
   Chu YC, 2004, IEEE T INF TECHNOL B, V8, P456, DOI 10.1109/TITB.2004.837893
   Conforto S, 1999, J ELECTROMYOGR KINES, V9, P47, DOI 10.1016/S1050-6411(98)00023-6
   DURRESI M, 2007, P 27 INT C DISTR COM, P37
   FLOYD W, 1995, J PHYSIOL-LONDON, V129, P184
   GUERRI JC, 2003, IEEE INT C MULT EXP
   GUERRI JC, 2000, COMPUTER METHODS PRO, P51
   Husemann D, 2004, EIGHTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P85, DOI 10.1109/ISWC.2004.35
   Istepanian RSH, 2004, IEEE T INF TECHNOL B, V8, P405, DOI 10.1109/TITB.2004.840019
   JONSSON B, 1973, NEW DEV EMG CLIN NEU, P498
   KATARZYNA W, 2005, MULT COMP NETW C, V5680, P176
   Kaufman DR, 2003, J BIOMED INFORM, V36, P45, DOI 10.1016/S1532-0464(03)00056-X
   KIMM H, 2005, IEEE INT C EL INF TE, P113
   Korhonen I, 2003, IEEE ENG MED BIOL, V22, P66, DOI 10.1109/MEMB.2003.1213628
   Lin YH, 2004, IEEE T INF TECHNOL B, V8, P439, DOI 10.1109/TITB.2004.837829
   Lubrin E., 2006, BioMed'06: Proceedings of the 2fourth IASTED international conference on Biomedical engineering, P60
   MOHOMED I, 2006, 4 INT WORKSH UB COMP
   Nazeran H, 2004, P ANN INT IEEE EMBS, V26, P2200
   PALMBLAD M, 2004, ELECT DIARIES QUESTI, P1199
   PAQUET N, 1994, SPINE, V19, P596, DOI 10.1097/00007632-199403000-00016
   Rankin G, 1998, CLIN REHABIL, V12, P187, DOI 10.1191/026921598672178340
   Riggs R., 2001, Programming for wireless devices with the java platform
   SAKAMOTO T, 2006, 6 IEEE INT C COMP IN, P83
   SARTI MA, 2000, EUROPEAN J ANATOMY, P34
   Scholtz J., 2004, DISCIPLINE EVALUATIN
   SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037/0033-2909.86.2.420
   SLEIVERT GG, 1994, ARCH PHYS MED REHAB, V75, P1315
   Stanford V., 2002, IEEE Pervasive Computing, V1, P10, DOI 10.1109/MPRV.2002.993139
   Tsai CC, 2007, MOBILE NETW APPL, V12, P173, DOI 10.1007/s11036-007-0014-4
   Navarro EAV, 2006, CONSUM COMM NETWORK, P1023
   VONTETSIANOS T, 2006, P INT ED NETW FOR EH
   WARREN S, 2003, PRE ICADI WORKSH TEC, P26
   Winters JM, 2003, IEEE ENG MED BIOL, V22, P56, DOI 10.1109/MEMB.2003.1213627
   Woolf AD, 2003, B WORLD HEALTH ORGAN, V81, P646
   Wooton R., 2006, INTRO TELEMEDICINE
   Xu BN, 2003, 2003 INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY, VOL 1 AND 2, PROCEEDINGS, P1353
   Zhang T, 2007, LECT NOTES COMPUT SC, V4550, P662
NR 40
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2009
VL 42
IS 3
BP 317
EP 340
DI 10.1007/s11042-008-0252-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 423HN
UT WOS:000264487500003
DA 2024-07-18
ER

PT J
AU Battiato, S
   Farinella, G
   Giuffrida, G
   Sismeiro, C
   Tribulato, G
AF Battiato, Sebastiano
   Farinella, Giovanni Maria
   Giuffrida, Giovanni
   Sismeiro, Catarina
   Tribulato, Giuseppe
TI Using visual and text features for direct marketing on multimedia
   messaging services domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual and text features; Learning in time and space constrained
   domains; Multimedia messaging services; Direct marketing
ID SCENE; CLASSIFICATION; PERCEPTION
AB Traditionally, direct marketing companies have relied on pre-testing to select the best offers to send to their audience. Companies systematically dispatch the offers under consideration to a limited sample of potential buyers, rank them with respect to their performance and, based on this ranking, decide which offers to send to the wider population. Though this pre-testing process is simple and widely used, recently the industry has been under increased pressure to further optimize learning, in particular when facing severe time and learning space constraints. The main contribution of the present work is to demonstrate that direct marketing firms can exploit the information on visual content to optimize the learning phase. This paper proposes a two-phase learning strategy based on a cascade of regression methods that takes advantage of the visual and text features to improve and accelerate the learning process. Experiments in the domain of a commercial Multimedia Messaging Service (MMS) show the effectiveness of the proposed methods and a significant improvement over traditional learning techniques. The proposed approach can be used in any multimedia direct marketing domain in which offers comprise both a visual and text component.
C1 [Battiato, Sebastiano; Farinella, Giovanni Maria; Giuffrida, Giovanni; Tribulato, Giuseppe] Univ Catania, Dept Math & Comp Sci, I-95125 Catania, Italy.
   [Sismeiro, Catarina] Univ London Imperial Coll Sci Technol & Med, Imperial Coll Business Sch, London SW7 2AZ, England.
C3 University of Catania; Imperial College London
RP Battiato, S (corresponding author), Univ Catania, Dept Math & Comp Sci, Viale A Doria 6, I-95125 Catania, Italy.
EM battiato@dmi.unict.it; gfarinella@dmi.unict.it; ggiuffrida@dmi.unict.it;
   sismeiro@imperial.ac.uk; tribulato@dmi.unict.it
RI Battiato, Sebastiano/ABI-1584-2020; Battiato, Sebastiano/O-7799-2019;
   GIUFFRIDA, Giovanni/AAN-3229-2020; FARINELLA, Giovanni Maria/L-8555-2015
OI Battiato, Sebastiano/0000-0001-6127-2470; GIUFFRIDA,
   Giovanni/0000-0001-5490-779X; FARINELLA, Giovanni
   Maria/0000-0002-6034-0432
CR Alpaydin E, 2004, INTRO MACHINE LEARNI
   [Anonymous], 2007, MIR
   [Anonymous], IEEE C COMP VIS PAT, DOI DOI 10.1109/CVPR.2006.68
   Barnard K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P408, DOI 10.1109/ICCV.2001.937654
   BATTIATO S, 2008, INT C IM PROC ICIP S
   BATTIATO S, 2007, SPIE IS T 19 ANN S E
   BERGEN JR, 1983, IEEE T SYST MAN CYB, V13, P857, DOI 10.1109/TSMC.1983.6313080
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   BIEDERMAN I, 1982, COGNITIVE PSYCHOL, V14, P143, DOI 10.1016/0010-0285(82)90007-X
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CLEVELAND WS, 1988, J ECONOMETRICS, V37, P87, DOI 10.1016/0304-4076(88)90077-2
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   *DIR MARK ASS, 2007, POW DIR MARK ROI SAL
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   FLORENT P, 2008, IEEE T PATTERN ANAL, V53, P1243
   Hull DA, 1996, J AM SOC INFORM SCI, V47, P70, DOI 10.1002/(SICI)1097-4571(199601)47:1<70::AID-ASI7>3.0.CO;2-#
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   LIM JH, 1999, VISUAL 99, P367
   Mairal J, 2008, PROC CVPR IEEE, P2415
   Moosmann F, 2007, Adv Neural Inf Process Syst, P985
   Naccari F, 2005, IEEE T CONSUM ELECTR, V51, P234, DOI 10.1109/TCE.2005.1405725
   Nash E., 2000, DIRECT MARKETING
   *NETS, 2007, CONV EV IS GOING MOB
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   OREN N, 2002, SAICSIT 02, P224
   Oza NC, 2005, IEEE SYS MAN CYBERN, P2340
   POTTER MC, 1975, SCIENCE, V187, P965, DOI 10.1126/science.1145183
   Prinzie A, 2005, EXPERT SYST APPL, V29, P630, DOI 10.1016/j.eswa.2005.04.022
   Renninger LW, 2004, VISION RES, V44, P2301, DOI 10.1016/j.visres.2004.04.006
   Roberts M., 1989, Direct Marketing Management
   Schapire R., 2001, BOOSTING APPROACH MA
   Schölkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   TAYLOR P, 1999, WAGON
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Winn J, 2005, IEEE I CONF COMP VIS, P1800
NR 38
TC 12
Z9 16
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2009
VL 42
IS 1
SI SI
BP 5
EP 30
DI 10.1007/s11042-008-0250-z
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 403XX
UT WOS:000263116400002
DA 2024-07-18
ER

PT J
AU Liu, YA
   Wu, F
AF Liu, Yanan
   Wu, Fei
TI Multi-modality video shot clustering with tensor representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-modality video shot clustering; TensorShot; Temporal-sequenced
   associated cooccurrence (TSAC) Dimensionality reduction; Affinity
   propagation clustering
AB Video analysis and understanding is a challenging issue nowadays. Video data has multiple media modalities, which present a characteristic of temporal-sequenced associated cooccurrence (TSAC). Traditionally, videos are represented as vectors in the Euclidean space. Many learning algorithms are then applied to these vectors in a high dimensional space for dimensionality reduction, classification, clustering and recognition as well. However, the multiple modalities in video not only have their own properties, but also have correlations between them; whereas the simple vector representation weakens the power of these relatively independent modalities and even ignores their relations to some extent. Clustering is an important technique for multimedia data management. Recently, a powerful clustering algorithm named Affinity Propagation is devised. In this paper, we introduce a higher-order tensor framework for video analysis. In this framework, we represent image frame, audio stream and transcript text which are the three modalities in video shots as data points by the third-order tensor. Besides, we present a dimension reduction method for the high-dimensional features of video shots which explicitly considers the manifold structure of the tensor space from temporal-sequenced associated co-occurring multimodal media data. We call it TensorShot approach. Then we utilize the effective Affinity Propagation to cluster video shots that are in tensor form. Our algorithm preserves the intrinsic structure of the submanifold where tensorshots are sampled. The experiments on TRECVID2005 news video data set show that our algorithm achieves improved performance.
C1 [Liu, Yanan; Wu, Fei] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Wu, F (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.
EM liu.yanan@yahoo.com; wufei@zju.edu.cn
FU National Natural Science Foundation of China [60603096, 60533090]; Key
   Technology RD Program [2006BAH02A13-4]; National High Technology
   Research and Development Program of China [2006AA010107]; Program for
   Changjiang Scholars and Innovative Research Team in University [IRT0652,
   PCSIRT]; Cultivation Fund of the Key Scientific and Technical Innovation
   Project; Ministry of Education of China [706033]
FX This work is supported by National Natural Science Foundation of China
   (No. 60603096, No. 60533090), Key Technology R&D Program
   (2006BAH02A13-4), The National High Technology Research and Development
   Program of China (2006AA010107), Program for Changjiang Scholars and
   Innovative Research Team in University (IRT0652, PCSIRT), The
   Cultivation Fund of the Key Scientific and Technical Innovation Project,
   Ministry of Education of China (No. 706033).
CR [Anonymous], P 13 ANN ACM INT C M
   [Anonymous], P ACM C MULT
   [Anonymous], UNDERSTANDING BELIEF
   [Anonymous], 1991, P 1991 IEEE COMP SOC, DOI DOI 10.1109/CVPR.1991.139758
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], IEEE INT C AOUST SPE
   [Anonymous], 1988, P SIGCHI C HUMAN FAC, DOI DOI 10.1145/57167.57214
   [Anonymous], IMAGE VIDEO PROCESSI
   [Anonymous], 2000, SIAM journal on Matrix Analysis and Applications
   [Anonymous], LNCS, DOI DOI 10.1007/3-540-47969-4_30
   Babaguchi N, 2002, IEEE T MULTIMEDIA, V4, P68, DOI 10.1109/6046.985555
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Ngo CW, 2002, IEEE T MULTIMEDIA, V4, P446, DOI 10.1109/TMM.2002.802022
   Snoek CGM, 2005, IEEE T MULTIMEDIA, V7, P638, DOI 10.1109/TMM.2005.850966
   Zhang JP, 2004, CHINESE MED J-PEKING, V117, P120
   Zheng Xin., 2004, MULTIMEDIA 04, P885, DOI [10.1145/1027527.1027731, DOI 10.1145/1027527.1027731]
NR 20
TC 9
Z9 10
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2009
VL 41
IS 1
BP 93
EP 109
DI 10.1007/s11042-008-0220-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 387LJ
UT WOS:000261953400004
DA 2024-07-18
ER

PT J
AU Liu, B
   Gupta, A
   Jain, R
AF Liu, Bin
   Gupta, Amarnath
   Jain, Ramesh
TI MedSMan: a live multimedia stream querying system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Workshop on Computer Vision Meets Databases
CY JUN 17, 2005
CL Baltimore, MD
DE live multimedia; feature; data stream; continuous queries; data
   management
AB Querying live media streams is a challenging problem that is becoming an essential requirement in a growing number of applications. Research in multimedia information systems has addressed and made good progress in dealing with archived data. Meanwhile, research in stream databases has received significant attention for querying alphanumeric symbolic streams. The lack of a data model capable of representing different multimedia data in a declarative way, hiding the media heterogeneity and providing reasonable abstractions for querying live multimedia streams poses the challenge of how to make the best use of data in video, audio and other media sources for various applications. In this paper we propose a system that enables directly capturing media streams from sensors and automatically generating more meaningful feature streams that can be queried by a data stream processor. The system provides an effective combination between extendible digital processing techniques and general data stream management research. Together with other query techniques developed in related data stream management streams, our system can be used in those application areas where multifarious live media senors are deployed for surveillance, disaster response, live conferencing, telepresence, etc.
C1 [Liu, Bin] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
   [Gupta, Amarnath] Univ Calif San Diego, San Diego Supercomp Ctr, La Jolla, CA 92093 USA.
   [Jain, Ramesh] Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92697 USA.
C3 University System of Georgia; Georgia Institute of Technology;
   University of California System; University of California San Diego;
   University of California System; University of California Irvine
RP Liu, B (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM bliu@ece.gatech.edu
RI xu, mingyu/KMX-9517-2024
CR Abadi DJ, 2003, VLDB J, V12, P120, DOI 10.1007/s00778-003-0095-z
   [Anonymous], OP SOURC COMP VIS LI
   [Anonymous], 1993, Temporal Databases: Theory, Design, and Implementation
   Arasu A., 2003, The cql continuous query language: Semantic foundations and query execution
   Aref W, 2004, MULTIMEDIA SYST, V9, P575, DOI 10.1007/s00530-003-0129-9
   Babcock B., 2002, P 21 ACM SIGMOD SIGA, P1, DOI [DOI 10.1145/543613.543615, 10.1145/543613]
   Bonnet P., 2001, Mobile Data Management. Second International Conference, MDM 2001. Proceedings (Lecture Notes in Computer Science Vol.1987), P3
   Chen JJ, 2000, SIGMOD REC, V29, P379, DOI 10.1145/335191.335432
   ELMASRI R, 1990, VERY LARGE DATA BASES, P1
   ENDERLE J, 2004, P ACM SIGMOD
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Golab L, 2003, SIGMOD REC, V32, P5, DOI 10.1145/776985.776986
   Hongeng S, 2004, COMPUT VIS IMAGE UND, V96, P129, DOI 10.1016/j.cviu.2004.02.005
   Jain R, 2003, COMMUN ACM, V46, P48, DOI 10.1145/792704.792729
   Lillethun DJ, 2007, 13TH IEEE INTERNATIONAL CONFERENCE ON EMBEDDED AND REAL-TIME COMPUTING SYSTEMS AND APPLICATIONS, PROCEEDINGS, P241, DOI 10.1109/RTCSA.2007.47
   LIU B, 2005, P 13 ANN ACM INT C M, P171
   LIU B, 2006, INT C SEM NETW WORLD
   Liu L, 1999, IEEE T KNOWL DATA EN, V11, P610, DOI 10.1109/69.790816
   LIU X, 2005, P 13 ACM INT C MULT, P171
   MADDEN S, 2002, ACM SIGMOD INT C MAN
   RAMACHANDRAN U, 2005, IN PRESS PERVASIVE M, V2
   SALEMIER P, 2002, INTRO MPEG, V7
   SESHADRI P., 1995, Proceedings of the 11th International Conference on Data Engineering (ICDE), P232
   SESHADRI P, 1994, ACM SIGMOD, P430
   Soo M. D., 1994, Proceedings. The 10th International Conference Data Engineering (Cat. No.94CH3383-7), P282, DOI 10.1109/ICDE.1994.283042
   Steinmetz R., 1995, MULTIMEDIA COMPUTING
   VINOD VV, 1997, ICMCS 97 OTT ONT CAN
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
NR 28
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2008
VL 38
IS 2
BP 209
EP 232
DI 10.1007/s11042-007-0177-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 301NV
UT WOS:000255903800003
DA 2024-07-18
ER

PT J
AU Macedo, AA
   Baldochi, L
   Camacho-Guerrero, JA
   Cattelan, RG
   Pimentel, MDC
AF Macedo, Alessandra A.
   Baldochi, Laercio
   Camacho-Guerrero, Jose A.
   Cattelan, Renan G.
   Pimentel, Maria da Graca C.
TI Automatically linking live experiences captured with a ubiquitous
   infrastructure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ubiquitous computing; capture and access applications; hypermedia
ID SYSTEM
AB Ubiquitous computing aims at providing services to users in everyday environments such as the home. One research theme in this area is that of building capture and access applications which support information to be recorded ( captured) during a live experience toward automatically producing documents for review (accessed). The recording demands instrumented environments with devices such as microphones, cameras, sensors and electronic whiteboards. Since each experience is usually related to many others ( e. g. several meetings of a project), there is a demand for mechanisms supporting the automatic linking among documents relative to different experiences. In this paper we present original results relative to the integration of our previous efforts in the Infrastructure for Capturing, Accessing, Linking, Storing and Presenting information (CALiSP). Ubiquitous computing aims at providing services to users in everyday environments such as the home. One research theme in this area is that of building capture and access applications which support information to be recorded (captured) during a live experience toward automatically producing documents for review (accessed). The recording demands instrumented environments with devices such as microphones, cameras, sensors and electronic whiteboards. Since each experience is usually related to many others (e.g. several meetings of a project), there is a demand for mechanisms supporting the automatic linking among documents relative to different experiences. In this paper we present original results relative to the integration of our previous efforts in the Infrastructure for Capturing, Accessing, Linking, Storing and Presenting information (CALiSP).
C1 [Macedo, Alessandra A.; Baldochi, Laercio; Camacho-Guerrero, Jose A.; Cattelan, Renan G.; Pimentel, Maria da Graca C.] Univ Sao Paulo, BR-05508 Sao Paulo, Brazil.
C3 Universidade de Sao Paulo
RP Pimentel, MDC (corresponding author), Univ Sao Paulo, BR-05508 Sao Paulo, Brazil.
EM ale.alaniz@usp.br; baldochi@icmc.usp.br; jcamacho@icmc.usp.br;
   renan@icmc.usp.br; mgp@icmc.usp.br
RI Pimentel, Maria G C/D-2875-2009; Macedo, Alessandra/AAV-8224-2020;
   Macedo, Alessandra Alaniz/K-7109-2012; Baldochi, Laercio/C-8744-2014
OI Pimentel, Maria G C/0000-0001-8264-5811; Macedo,
   Alessandra/0000-0001-5271-3086; Macedo, Alessandra
   Alaniz/0000-0001-5271-3086; Baldochi, Laercio/0000-0001-5740-096X;
   Cattelan, Renan/0000-0001-9993-8469
CR Abowd G. D., 2002, IEEE Pervasive Computing, V1, P48, DOI 10.1109/MPRV.2002.993144
   Abowd G. D., 1999, Proceedings of the 1999 International Conference on Software Engineering (IEEE Cat. No.99CB37002), P75, DOI 10.1109/ICSE.1999.840997
   ALLAN J, 1996, P 7 ACM C HYP, P42
   [Anonymous], P 11 ANN INT ACM SIG
   *AP, 2002, AP COC 2 0
   BALDOCHI L, 2003, P SEMISH 03, P1
   BLUSTEIN J, 2000, P 11 ACM HYP C SAN A, P201
   BOAG S, 2004, XQUERY 1 0 XML QUERY
   Brumitt B, 2000, LECT NOTES COMPUT SC, V1927, P12
   Cahill V, 2004, IEEE PERVAS COMPUT, V3, P20, DOI 10.1109/MPRV.2004.1321023
   Calado P, 2003, ACM T INFORM SYST, V21, P42, DOI 10.1145/635484.635486
   CAMACHOGUERRERO JA, 2004, P ACM DOCENG 04, P74
   CATTELAN R, 2003, COMP P 2003 ACM IFIP, P315
   CHIU P, 2000, P HYP 00, P244
   Chiu Patrick, 2001, P 10 INT C WORLD WID, P140
   Clarke I, 2002, IEEE INTERNET COMPUT, V6, P40, DOI 10.1109/4236.978368
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   DOORNIK J, 2004, OX OBJECT ORIENTED M
   ELBELTAGY SR, 2001, P 12 ACM C HYP HYP, P151
   Esler M., 1999, MobiCom'99. Proceedings of Fifth Annual ACM/IEEE International Conference on Mobile Computing and Networking, P256, DOI 10.1145/313451.313553
   Garlan D., 2002, IEEE Pervasive Computing, V1, P22, DOI 10.1109/MPRV.2002.1012334
   GOLOVCHINSKY G, 1997, P 8 ACM C HYP, P67
   Green SJ, 1999, IEEE T KNOWL DATA EN, V11, P713, DOI 10.1109/69.806932
   Gronbaek K., 2003, P 14 ACM INT C HYP H, P10
   HAAKE J, 1994, P ECHT 94 ED SEPT, P1
   Henzigner MR, 2001, IEEE INTERNET COMPUT, V5, P45, DOI 10.1109/4236.895141
   Hess C. K., 2002, Pervasive Computing. First International Conference, Pervasive 2002. Proceedings (Lecture Notes in Computer Science Vol.2414), P16
   HUANG AC, 2001, MOBICOM 01, P108
   JOHANSON B., 2002, IEEE PERVAS COMPUT, V1, P71
   Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140
   Leung WH, 2003, MULTIMED TOOLS APPL, V20, P7, DOI 10.1023/A:1023466231968
   LIN TW, 2002, JAVA ARCHITECTURE XM
   Lutfi R, 2004, MULTIMED TOOLS APPL, V24, P105, DOI 10.1023/B:MTAP.0000036839.24141.9e
   Macedo A. A., 2001, Proceedings of the ACM Symposium on Document Engineering (DocEng '01), P144, DOI 10.1145/502187.502209
   Macedo A. A., 2002, P 13 ACM C HYP HYP, P107
   MACEDO AA, 2003, P ACM C HYP HYP, P48
   Makkonen J, 2004, INFORM RETRIEVAL, V7, P347, DOI 10.1023/B:INRT.0000011210.12953.86
   MEIER W, 2003, EXIST OPEN SOURCE XM
   Müller R, 2000, MULTIMEDIA SYST, V8, P158, DOI 10.1007/s005300000042
   Mynatt E.D., 2001, PROC CHI 2001, P333
   Mynatt Elizabeth D., 1999, P SIGCHI C HUM FACT, P346, DOI DOI 10.1145/302979.303108
   *NCSA, 1996, HAB TM NCSA
   NETO RFB, 2002, P ACM DOCENG, P66
   ORR RJ, 2000, ACM CHI 00, P275
   OSTERBYE K, 1996, P 7 ACM C HYP WASH D, P129
   Pimentel MDC, 2007, IEEE PERVAS COMPUT, V6, P93
   Pimentel MD, 2001, INTERACT COMPUT, V13, P353, DOI 10.1016/S0953-5438(00)00042-4
   PRICE M.N., 1998, P C HYPERTEXT HYPERM, P30
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   SALTON G, 1993, P HYPERTEXT 93, P131
   Satyanarayanan M, 2005, IEEE PERVAS COMPUT, V4, P4, DOI 10.1109/MPRV.2005.61
   Satyanarayanan M, 2002, ACM T COMPUT SYST, V20, P85, DOI 10.1145/507052.507053
   Shi YC, 2003, IEEE PERVAS COMPUT, V2, P47, DOI 10.1109/MPRV.2003.1203753
   Shirmohammadi S, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P541, DOI 10.1109/MMCS.1997.609767
   SILVA I, 2000, P 23 ANN INT ACM SIG, P96, DOI DOI 10.1145/345508.345554
   SMALL H, 1973, J AM SOC INFORM SCI, V24, P265, DOI 10.1002/asi.4630240406
   Stanford V., 2002, IEEE Pervasive Computing, V1, P10, DOI 10.1109/MPRV.2002.993139
   SUGIYAMA K, 2003, P 14 ACM C HYP HYP, P198
   TREVOR J, 2004, P IUI 04, P337
   Truong K.N., 2001, 3 INT C UBIQUITOUS C, P209, DOI DOI 10.1007/3-540-45427-6_17
   Truong KN, 2004, LECT NOTES COMPUT SC, V3001, P140
   WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94
NR 62
TC 5
Z9 5
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2008
VL 37
IS 2
BP 93
EP 115
DI 10.1007/s11042-007-0131-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 267PV
UT WOS:000253522600001
DA 2024-07-18
ER

PT J
AU Knoche, H
   McCarthy, JD
   Sasse, MA
AF Knoche, Hendrik
   McCarthy, John D.
   Sasse, M. Angela
TI How low can you go? The effect of low resolutions on shot types in
   mobile TV
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE shot types; mobile TV; low resolutions
AB The advent of mobile TV which is often viewed on small screens with low resolution has made TV content producers think about refraining from using shots that depict subjects from a great distance. Shot types where the object of interest fills the screen are deemed to be more appropriate for mobile devices. This paper reports a study on how shot types used in regular broadcast television are affected when shown on mobile devices at reduced levels of resolution. Seventy-two native speakers judged the acceptability of four different content types at four resolutions (240 x 180, 208 x 156, 168 x 126, 120 x 90). The results show that acceptability of shot types depends on the content and the resolution. Extreme long shots of football content were only less acceptable than other shot types at resolutions smaller than 240 x 180. The medium shot which portrays the upper half of a subject's body was the most acceptable for news content but for football content was judged worse than shot types that showed less detail. Our results suggest that for a young audience extreme long shots may be used with no detrimental effect for resolutions of 240 x 180 and higher. At lower resolutions and for content with a high degree of dynamism both the medium shot and the extreme long shot might render poorly for the audience. Service providers are well advised to include the results at hand to customize content in terms of shot type use for their audience that will watch the content at very low resolutions. Further research should assess older audiences and the effectiveness of cropping schemes that zoom in on part of the content for low target resolutions.
C1 [Knoche, Hendrik; McCarthy, John D.; Sasse, M. Angela] UCL, London, England.
C3 University of London; University College London
RP Knoche, H (corresponding author), UCL, London, England.
EM h.knoche@cs.ucl.ac.uk
RI Knoche, Hendrik/AAD-4754-2019; Sasse, Angela M/G-8628-2013
OI Knoche, Hendrik/0000-0003-3950-8453; 
CR ANKRUM DR, 1996, VIEWING DISTANCE COM, P10
   [Anonymous], 2004, P 2004 C HUM FACT CO
   [Anonymous], 1998, MEDIA EQUATION MEDIA
   [Anonymous], 2006, PROC 2 INT WORKSHOP
   BACHMANN T, 1991, European Journal of Cognitive Psychology, V3, P87, DOI 10.1080/09541449108406221
   BARBER P, 1994, P IEEE INT S MULT TE, P163
   BATHIA S, 1995, J VIS COMMUN IMAGE R, V6, P280
   CAMPBELL FW, 1965, J PHYSIOL-LONDON, V181, P576, DOI 10.1113/jphysiol.1965.sp007784
   DALLAGO G, 2006, MICRODISPLAY EMOTION
   *ETSI, 2005, DVB H IMPL GUID
   GWINN E, 2005, MOBILE TV YOUR CELL
   HOLMSTROM D, 2003, THESIS UMEA U
   HORN DB, 2002, P CHI 02
   JESTY LC, 1958, P I ELECTR ENG, P425
   KIES JK, 1996, 9602 HCIL
   KNOCHE H, 2004, P WWRF12
   KNOCHE H, 2005, ACM MULTIMEDIA ACM
   LOMBARD M, 1996, ANN C ASS ED JOURN M
   NEMETHOVA O, 2004, P CIC 2004 9 CDMA IN
   *OD SOFTW INC, 2003, CFCOM
   Okada K., 1994, ACM CSCW, P385
   OWENS DA, 1987, INVEST OPHTH VIS SCI, V28, P743
   Reeves B., 1999, MEDIA PSYCHOL, V1, P49, DOI [DOI 10.1207/S1532785XMEP0101_4, https://doi.org/10.1207/s1532785xmep01014]
   Silbergleid Michael, 2000, GUIDE DIGITAL TELEVI
   Sodergard C., 2003, Mobile television - technology and user experiences. Report on the Mobile-TVproject
   SONG S, 2004, P 10 ACM INT C MULT, P327
   STEEDMAN WC, 1960, HUM FACTORS, V2, P121
   THOMPSON R, 1998, GRAMMER SHOT
   Weiner Richard., 1996, Webster's New World Dictionary of Media and Communications
   WESTERNIK JH, 1989, SUBJECTIVE IMAGE QUA
   WESTHEIMER G, 1992, ADLERS PHYSL EYE CLI
NR 31
TC 19
Z9 20
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2008
VL 36
IS 1-2
BP 145
EP 166
DI 10.1007/s11042-006-0076-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 241LT
UT WOS:000251658600009
DA 2024-07-18
ER

PT J
AU Shen, HC
   Lee, CN
AF Shen, Hung-Che
   Lee, Chungnan
TI Whistle for music: using melody transcription and approximate string
   matching for content-based query over a MIDI database
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE query-by-whistling; melody transcription; melodic AGREP; pitch-to-MIDI;
   melodic descriptions; MIDI preprocessor
AB In this paper, we present a "Whistle for Music" system which enables users to retrieve MIDI format music by whistling a melodic fragment. Three essential components are query processing, MIDI preprocessing and an approximate search engine. For query processing, we have achieved a real-time and robust whistle-to-MIDI converter. For feature extraction, the proposed MIDI preprocessing can extract individual, local and global melodic descriptions from MIDI files. In order to match query with target, we extend an existing search engine into a fast approximate melodic matching engine. Based on the integration of those three components, the system can return a list of MIDI files that are ranked by how closely they match the whistling. The systematic evaluation for the query-by-whistling system is finally performed. The results show that careful measurement and objective comparisons can lead us to know the scaling trend about query and target. One encouraging aspect is that the performance can be predicted based on the evaluation methods.
C1 I Shou Univ, Inst Comp & Informat Engn, Ta Hsu Hsiang 840, Kaohsiung Cty, Taiwan.
   Natl Sun Yat Sen Univ, Dept Comp Sci & Engn, Kaohsiung 804, Taiwan.
C3 I Shou University; National Sun Yat Sen University
RP Shen, HC (corresponding author), I Shou Univ, Inst Comp & Informat Engn, 1 Sect 1,Hsueh Cheng Rd, Ta Hsu Hsiang 840, Kaohsiung Cty, Taiwan.
EM shungch@isu.edu.tw; cnlee@mail.cse.nsysu.edu.tw
CR Blackburn S., 1998, Proceedings ACM Multimedia 98, P361, DOI 10.1145/290747.290802
   Dannenberg RB, 2004, COMPUT MUSIC J, V28, P34, DOI 10.1162/014892604323112239
   DIXON S, 1999, P DID FOR MATH MUS A, P101
   DOWLING WJ, 1978, PSYCHOL REV, V85, P341, DOI 10.1037/0033-295X.85.4.341
   DOWNIE JS, 2000, P 23 ANN INT ACM SIG, P73
   Ghias A., 1995, PROC ACM MULTIMEDIA, P231
   HARRISON M, 1999, CONT MUSIC THEORY
   HURON D, 2000, THEMEFINDER
   JEAN TS, 1992, INFORM PROCESS MANAG, V28
   Kline Richard L., 2003, P 11 ACM INT C MULT, P130
   KOMSTADT A, 1998, COMPUTING MUSICOLOGY, V11, P231
   Lu L., 2004, PROC ACM MULTIMEDIA, P275
   LU L, 2001, P IEEE INT C MULT EX
   McNab R. J., 1996, Proceedings of the 1st ACM International Conference on Digital Libraries, P11, DOI 10.1145/226931.226934
   McNab RJ, 2000, MULTIMED TOOLS APPL, V10, P113, DOI 10.1023/A:1009606600500
   MEEK C, 2001, 2 ANN INT S MUS INF, P119
   MENAB RJ, 1997, NZ DIGITAL LIB MELOD
   Parsons D., 1975, DIRECTORY TUNES MUSI
   Prechelt L., 2001, ACM Transactions on Computer-Human Interaction, V8, P133, DOI 10.1145/376929.376978
   Tao D.-C., 2004, P 12 ANN ACM INT C M, P464
   Tonta Y., 1992, PUBLIC ACCESS COMPUT, V3, P4
   Uitdenbogerd A, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P57, DOI 10.1145/319463.319470
   Uitdenbogerd A, 2002, ISMIR 2002, P204
   Unal E., 2004, MIR '04: Proceedings of the Sixth ACM SIGMM International Workshop on Multimedia Information Retrieval, New York, P113
   Wild Jonathan., 1996, Music Theory Online, V2/7
   WU S, 1992, COMMUN ACM, V35, P83, DOI 10.1145/135239.135244
   YIP CL, 1999, P DEX 99 FLOR IT, P724
NR 27
TC 4
Z9 7
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2007
VL 35
IS 3
BP 259
EP 283
DI 10.1007/s11042-007-0128-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 228XS
UT WOS:000250766500002
DA 2024-07-18
ER

PT J
AU Gavrilovska, A
   Kumar, S
   Sundaragopalan, S
   Schwan, K
AF Gavrilovska, Ada
   Kumar, Sanjay
   Sundaragopalan, Srikanth
   Schwan, Karsten
TI Advanced networking services for distributed multimedia streaming
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 4th International Conference on Intelligent Multimedia Computing and
   Networking
CY JUL, 2005
CL Salt Lake City, UT
DE network processors; IXP; application-specific network services;
   application-level multicast; streaming applications; fast path
   processing
AB Increased network speeds coupled with new services delivered via the Internet have increased the demand for intelligence and flexibility in network systems. This paper argues that both can be provided by new hardware platforms comprised of heterogeneous multi-core systems with specialized communication support. We present and evaluate an experimental network service platform that uses an emergent class of devices-network processors-as its communication support, coupled via a dedicated interconnect to a host processor acting as a computational core. A software infrastructure spanning both enables the dynamic creation of application-specific services on the network processor, mediated by middleware and controlled by kernel-level communication support. Experimental evaluations use a Pentium IV-based computational core coupled with an IXP 2400 network processor. The sample application services run on both include an image manipulation application and application-level multicasting.
C1 Georgia Inst Technol, Ctr Expt Res Comp Syst, Atlanta, GA 30332 USA.
C3 University System of Georgia; Georgia Institute of Technology
RP Sundaragopalan, S (corresponding author), Microsoft Corp, 1 Microsoft Way, Redmond, WA 98052 USA.
EM ada@cc.gatech.edu; ksanjay@cc.gatech.edu; sriks@microsoft.com;
   schwan@cc.gatech.edu
OI Gavrilovska, Ada/0000-0003-4199-2512
CR APOSTOLOPOULOS G, 2000, P IEEE INFOCOM 2000
   Braun F, 2002, IEEE MICRO, V22, P66, DOI 10.1109/40.988691
   BUSTAMANTE F, 2000, SUPERCOMPUTING 2000
   CARZAGINA A, 2001, ACM T COMPUTER SYSTE, V19
   CLARK C, 2004, P 3 WORKSH NETW PROC
   CONSEL C, 2003, P 2 INT C GEN PROGR
   DIOT L, 1999, NETWORK, V13
   EISENHAUER G, 2000, 9 S HIGH PERF DISTR
   FENG WC, 2003, SC2003 HIGH PERF NET
   FENG WC, 2005, ACM NOSSDAV 2005 STE
   GAVRILOVSKA A, 2004, OASIS 2004 HELD ASPL
   GAVRILOVSKA A, 2002, 22 IEEE INT C DISTR
   GAVRILOVSKA A, 2005, 15 WORKSH NETW OP SY
   GAVRILOVSKA A, 2003, HOT INTERCONNECTS
   GUO J, 2005, IEEE INF MARCH
   *IBM, IBM MQSERIES
   *INT, IXP INT NETW PROC FA
   *INT CORP, 2001, INT 9A PROGR FRAM
   KONG J, 2005, 15 WORKSH NETW OP SY
   KRISHNAMURTHY R, 2002, P HOT INT STANF CA A, V10
   KUMAR S, 2005, 4 IEEE C NETW COMP A
   KUMAR V, 2005, 25 IEEE INT C DISTR
   LIAO C, 1998, ACM SIGM S PAR DISTR
   *LIN, LINK HOM ROUT LINK B
   LIN YD, 2002, P HOT INT AUG, V10
   LIU L, 2001, WORLD WIDE WEB J, V4
   MEHRA P, 2003, P NETW COMP APPL NCA
   OLESON V, 2000, 1 WORKSH IND EXP SYS
   OTEY M, 2002, P WORKSH DAT MIN CYB
   PAI V, 2003, P 4 USENIX S INT TEC
   *PATH 1 NETW TECHN, 2002, PROF DIG VID GAT BRO
   REGNIER G, 2003, ETA EXPERIENCE INTEL, V11
   ROSU MC, 1998, CLUSTER COMPUTING SP, V1
   ROWSTRON A, 2001, P 3 INT WORKSH NETW
   ROY S, 2003, P IEEE INT C MULT EX
   Shah N., 2003, 2 WORKSH NETW PROC N
   SHIVAM P, 2002, INT PAR DISTR PROC S
   SPALINK T, 2001, SOSP 2001 BANFF CAN
   SUNDARAGOPALAN S, 2005, IMMCN 05 APR
   Taylor D., 2002, P IEEE INFOCOM 2002
   *TEJ, TEJ NP SOFTW PLATF I
   THIES W, 2002, INT C COMP CONSTR IC
   WEST R, 1999, P 6 INT C MULT COMP
   WOLF M, 2002, SUP 2002 NOV
   YOCUM K, 2001, P USENIX TECHN C USE
   ZHAO Y, 2001, P ACM S PRINC DISTR
   ZHUANG X, 2002, P MULT NETW SYST MM
NR 47
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2007
VL 34
IS 2
BP 179
EP 200
DI 10.1007/s11042-006-0089-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 178AX
UT WOS:000247194700004
DA 2024-07-18
ER

PT J
AU Ghafoor, A
AF Ghafoor, Arif
TI Distributed multimedia information systems: an end-to-end perspective
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 9th International Conference on Distributed Multimedia Systems (DMS
   03)/6th International Conference on Visual Information Systems (VIS
   2003)
CY SEP 24-26, 2003-2006
CL Miami, FL
DE multimedia documents; semantic web; resource allocations; QoS
   management; distributed systems; information security; broadband
   networking
ID SYNCHRONIZATION PROTOCOLS; COMMUNICATION; MODELS
AB Emerging Web-based applications require distributed multimedia information system (DMIS) infrastructures. Examples of such applications abound in the domains of medicine, entertainment, manufacturing, e-commerce, as well as military and critical national infrastructures. Development of DMIS for such applications need a broad range of technological solutions for organizing, storing, and delivering multimedia information in an integrated, secure and timely manner with guaranteed end-to-end (E2E) quality of presentation (QoP). DMIS are viewed as catalysts for new research in many areas, ranging from basic research to applied technology. This view is a result of the fact that no single monolithic end-to-end architecture for DMIS can meet the wide spectrum of characteristics and requirements of various Web-based multimedia applications. One size does not fit all in this medium of communication. Management of integrated end-to-end QoP and ensuring information security in DMIS, when viewed in conjunction with real world constraints and system-wide performance requirements, present formidable research and implementation challenges. These challenges encompass all the sub-system components of a DMIS. The ultimate objective of achieving a comprehensive end-to-end QoP management relies on the performance and allocation of resources of each of the DMIS sub-system components including networks, databases, and end-systems. In this paper, we elaborate on these challenges and present a high level distributed architecture aimed at providing the critical functionality for a DMIS.
C1 Purdue Univ, Sch Elect & Comp Engn, Distributed Multimedia Syst Lab, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University
RP Ghafoor, A (corresponding author), Purdue Univ, Sch Elect & Comp Engn, Distributed Multimedia Syst Lab, W Lafayette, IN 47907 USA.
EM ghafoor@ecn.purdue.edu
CR Atrey PK, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P330, DOI 10.1109/MULMM.2004.1265004
   Baqai S, 1996, IEEE COMMUN MAG, V34, P78, DOI 10.1109/35.482250
   Baqai S, 1996, IEEE J SEL AREA COMM, V14, P1388, DOI 10.1109/49.536487
   Bashandy AR, 2005, IEEE J SEL AREA COMM, V23, P450, DOI 10.1109/JSAC.2004.839423
   BERTINO E, 2000, 200004 CERIAS TR PUR
   Canós JH, 2004, IEEE MULTIMEDIA, V11, P106, DOI 10.1109/MMUL.2004.2
   Dilley J, 2002, IEEE INTERNET COMPUT, V6, P50, DOI 10.1109/MIC.2002.1036038
   Dimitrova N, 2004, IEEE MULTIMEDIA, V11, P7, DOI 10.1109/MMUL.2004.6
   Fahmi H, 2001, COMPUTER, V34, P54, DOI 10.1109/2.947092
   Ferraiolo D. F., 2001, ACM Transactions on Information and Systems Security, V4, P224, DOI 10.1145/501978.501980
   FOSTER I, 2000, P 8 INT WORKSH QUAL, P81
   Georganas ND, 1996, IEEE J SEL AREA COMM, V14, P1, DOI 10.1109/JSAC.1996.481690
   Hung JC, 2002, FIRST INTERNATIONAL SYMPOSIUM ON CYBER WORLDS, PROCEEDINGS, P346, DOI 10.1109/CW.2002.1180900
   Iannella Renato., 2001, D-Lib Magazine, V7
   Joshi JBD, 2004, IEEE INTERNET COMPUT, V8, P40, DOI 10.1109/MIC.2004.53
   Joshi JBD, 2002, IEEE T MULTIMEDIA, V4, P215, DOI 10.1109/TMM.2002.1017735
   Joshi JBD, 2001, COMMUN ACM, V44, P38, DOI 10.1145/359205.359224
   *JSTOR, 2004, CHALL DIG PRES JAST
   Kim JH, 1999, IEEE VTS VEH TECHNOL, P1525, DOI 10.1109/VETEC.1999.780602
   LI B, 1999, IEEE J SEL AREAS COM, V17
   LITTLE TDC, 1990, IEEE J SEL AREA COMM, V8, P413, DOI 10.1109/49.53017
   LITTLE TDC, 1991, IEEE J SEL AREA COMM, V9, P1368, DOI 10.1109/49.108675
   LITTLE TDC, 1991, COMPUTER, V24, P42, DOI 10.1109/2.97250
   Lu GJ, 2002, IEEE T MULTIMEDIA, V4, P372, DOI 10.1109/TMM.2002.802831
   MALIK H, 2004, IEEE INT C MULT EXP
   MALIK H, 2004, IEEE INT C AC SPEECH, V5, P385
   MANIATIS P, 2003, P ACM SOSP BOLT LAND
   Moni S, 1996, IEEE J SEL AREA COMM, V14, P1472, DOI 10.1109/49.536492
   Orda A, 2003, IEEE ACM T NETWORK, V11, P578, DOI 10.1109/TNET.2003.815299
   ROSENBERG J, 2002, SIP SESS IN PROT JUN
   Royer EM, 1999, IEEE PERS COMMUN, V6, P46, DOI 10.1109/98.760423
   Shafiq B, 2003, IEEE COMMUN MAG, V41, P138, DOI 10.1109/MCOM.2003.1186558
   Shah SH, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-5, CONFERENCE PROCEEDINGS, P1022, DOI 10.1109/ICC.2002.997009
   SHYU ML, 2007, IN PRESS IEEE T SYST
   SU W, 2000, P IEEE MILCOM 2000 O
   Wolfgang RB, 1999, P IEEE, V87, P1108, DOI 10.1109/5.771067
   WOO M, 1994, IEEE NETWORK, V8, P52, DOI 10.1109/65.260079
   WOO M, 1995, IEEE J SEL AREA COMM, V13, P913, DOI 10.1109/49.391743
   WOO M, 1999, J PARALLEL DISTR APR
   YE J, 2002, IEEE T MOBILE COMPUT, V1, P249, DOI DOI 10.1109/TMC.2002.1175539
   ZHENG L, 1993, IEEE NETW        SEP, V7, P8
   [No title captured]
NR 42
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2007
VL 33
IS 1
BP 31
EP 56
DI 10.1007/s11042-006-0099-y
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 149FZ
UT WOS:000245133800004
DA 2024-07-18
ER

PT J
AU Bartolini, I
   Ciaccia, P
   Patella, M
AF Bartolini, Ilaria
   Ciaccia, Paolo
   Patella, Marco
TI Adaptively browsing image databases with PIBE
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 1st International Workshop on Computer Vision Meets Databases
CY JUN 13, 2004
CL Paris, FRANCE
DE image databases; browsing; personalization; similarity criteria
ID RETRIEVAL
AB Browsing large image collections is a complex and often tedious task, due to the semantic gap existing between the user subjective notion of similarity and the one according to which a browsing system organizes the images. In this paper we propose PIBE, an adaptive image browsing system, which provides users with a hierarchical view of images (the Browsing Tree) that can be customized according to user preferences. A key feature of PIBE is that it maintains local similarity criteria for each portion of the Browsing Tree. This makes it possible both to avoid costly global reorganization upon execution of user actions and, combined with a persistent storage of the Browsing Tree, to efficiently support multiple browsing tasks. We present the basic principles of PIBE and report experimental results showing the effectiveness of its browsing and personalization functionalities.
C1 Univ Bologna, DEIS, I-40126 Bologna, Italy.
C3 University of Bologna
RP Bartolini, I (corresponding author), Univ Bologna, DEIS, I-40126 Bologna, Italy.
EM ibartolini@deis.unibo.it; pciaccia@deis.unibo.it; mpatella@deis.unibo.it
RI BARTOLINI, ILARIA/AAA-9455-2019
OI BARTOLINI, ILARIA/0000-0002-8074-1129; CIACCIA,
   PAOLO/0000-0002-1794-6244
CR Bartolini I., 2001, Proceedings of the 27th International Conference on Very Large Data Bases, P201
   BARTOLINI I, 2004, P 1 INT WORKSH COMP, P43
   Chakrabarti K, 2004, IEEE T KNOWL DATA EN, V16, P256, DOI 10.1109/TKDE.2004.1269602
   Chen JY, 1999, P INT C STOR RETR IM, P144
   COMBS TTA, 1999, P 4 ACM C DIG LIB, P130
   Graham A., 2002, Proceedings of the second ACM/IEEE-CS joint conference on Digital libraries, P326
   Jain A. K., 1988, Algorithms for Clustering Data, P446
   Laaksonen J, 2001, PATTERN ANAL APPL, V4, P140, DOI 10.1007/PL00014575
   Loui AC, 1999, P ACM MULT 99 ORL FL, P159
   Platt JC, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P6
   RODDEN K, 2001, P SIGCHI C HUM FACT, P190, DOI DOI 10.1145/365024.365097
   Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701
   Santini S, 2000, IEEE MULTIMEDIA, V7, P26, DOI 10.1109/93.879766
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Wallace M, 2003, IEEE MULTIMEDIA, V10, P49, DOI 10.1109/MMUL.2003.1237550
   WOJNA A, 2003, FUNDAM INFORM, V56, P1
NR 16
TC 18
Z9 20
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2006
VL 31
IS 3
BP 269
EP 286
DI 10.1007/s11042-006-0044-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 119XW
UT WOS:000243048800003
DA 2024-07-18
ER

PT J
AU Chung, J
   Claypool, M
AF Chung, Jae
   Claypool, Mark
TI Empirical evaluation of the congestion responsiveness of RealPlayer
   video streams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE streaming media; protocols; RealPlayer; TCP-friendly; unresponsive flows
AB Increasingly popular commercial streaming media applications over the Internet often use UDP as the underlying transmission protocol for performance reasons. Hand-in-hand with the increase in streaming media comes the impending threat of unresponsive UDP traffic, often cited as the major threat to the stability of the Internet. Unfortunately, there are few empirical studies that analyze the responsiveness, or lack of it, of commercial streaming media applications. In this work, we evaluate the responsiveness of RealNetworks' RealVideo over UDP by measuring the performance of numerous streaming video clips selected from a variety of RealServers on the Internet, analyze the TCP-Friendliness of the UDP streams and correlate the results with network and application layer statistics. We find that most RealVideo UDP streams respond to Internet congestion by reducing the application layer encoding rate, and streams with a minimum encoding rate less than the fair share of the capacity often achieve a TCP-Friendly rate. In addition, our results suggest that a reason streaming applications choose not to use TCP is that the TCP API hides network information, such as loss rate and round-trip time, making it difficult to estimate the available capacity for effective media scaling.
C1 Worcester Polytech Inst, Dept Comp Sci, Worcester, MA 01609 USA.
C3 Worcester Polytechnic Institute
RP Chung, J (corresponding author), Worcester Polytech Inst, Dept Comp Sci, 100 Inst Rd, Worcester, MA 01609 USA.
EM goos@cs.wpi.edu; claypool@cs.wpi.edu
RI Claypool, Mark/ABC-5316-2020
CR AKELLA A, 2003, P ACM INT MEAS C IMC
   BOCHECK P, 1999, P INT WORKSH NETW OP
   BOLOT JCC, 1999, P IEEE INFOCOM
   Boyce J. M., 1998, Proceedings ACM Multimedia 98, P181, DOI 10.1145/290747.290770
   Cao Z., 2000, P IEEE INFOCOM
   CHESIRE M, 2001, P USENIX S INT TECHN
   CHUNG J, 2002, WPICSTR0217 WORC POL
   Conklin GJ, 2001, IEEE T CIRC SYST VID, V11, P269, DOI 10.1109/76.911155
   Feng W.C., 2001, P IEEE INFOCOM
   Floyd S, 1999, IEEE ACM T NETWORK, V7, P458, DOI 10.1109/90.793002
   Floyd S., 2000, P ACM SIGCOMM C, P45
   GOEL A, 2002, P INT WORKSH QUAL SE
   *JUP MED METR, 2001, US MED PLAYER APPL
   KUANG T, 2002, P SPIE ITCOM BOST US, P68
   LAKSHMINARAYANA.K, 2003, P INT MEAS C IMC MIA
   LI M, 2002, P ACM SIGCOMM INT ME
   LIN D, 1997, P ACM SIGCOMM C
   LIU YL, 2000, P IS T SPIE ACM MULT
   MAHAJAN R, 2001, P 9 INT C NETW PROT
   Mena A., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), P101, DOI 10.1109/INFCOM.2000.832178
   MITRA D, 2000, P IEEE INFOCOM MAR
   Nichols J., 2004, PROC 14 INT WORKSHOP, P146
   PADHYE C, 2000, P IEEE INT PERF COMP
   Park KH, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P426, DOI 10.1109/MMCS.1999.778482
   *REAL NETW INC, 2000, REALPRODUCER US GUID
   *REAL NETW INC, 2000, REALPLAYER 8 US MAN
   *REAL NETW INC, 2001, REALNETWORKS FACTS
   Rejaie R., 1999, P IEEE INFOCOM
   STOICA I., 1998, P ACM SIGCOMM C
   TRIPATHI A, 2002, WORKSH INT MULT COMP
   VANDERMERWE J, 2000, ACM COMPUT COMMUN RE, V30
   VELOSO E, 2002, P ACM SIGCOMM INT ME
   WALPOLE J, 1997, P SPIE APPL IM PATT
   WANG Y, 2001, P ACM SIGCOMM INT ME
NR 34
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2006
VL 31
IS 2
BP 171
EP 193
DI 10.1007/s11042-006-0040-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 103MP
UT WOS:000241890500003
DA 2024-07-18
ER

PT J
AU Park, G
   Baek, Y
   Lee, HK
AF Park, Gunhan
   Baek, Yunju
   Lee, Heung-Kyu
TI Web image retrieval using majority-based ranking approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE web image retrieval; content-based image retrieval; image clustering;
   image ranking; graph/picture classifier
ID CLASSIFICATION; SEMANTICS
AB Web image retrieval has characteristics different from typical content-based image retrieval; web images have associated textual cues. However, a web image retrieval system often yields undesirable results, because it uses limited text information such as surrounding text, URLs, and image filenames. In this paper, we propose a new approach to retrieval, which uses the image content of retrieved results without relying on assistance from the user. Our basic hypothesis is that more popular images have a higher probability of being the ones that the user wishes to retrieve. According to this hypothesis, we propose a retrieval approach that is based on a majority of the images under consideration. We define four methods for finding the visual features of majority of images; (1) majority-first method, (2) centroid-of-all method, (3) centroid-of-top K method, and (4) centroid-of-largest-cluster method. In addition, we implement a graph/picture classifier for improving the effectiveness of web image retrieval. We evaluate the retrieval effectiveness of both our methods and conventional ones by using precision and recall graphs. Experimental results show that the proposed methods are more effective than conventional keyword-based retrieval methods.
C1 NHN Corp, R&D Ctr, Multimedia Search Team, Seongnam City 463825, Gyeonggi Do, South Korea.
   Pusan Natl Univ, Div Comp Sci & Engn, Pusan 609735, South Korea.
   Korea Adv Inst Sci & Technol, Dept Elect Engn & Comp Sci, Div Comp Sci, Taejon 305701, South Korea.
C3 Pusan National University; Korea Advanced Institute of Science &
   Technology (KAIST)
RP Park, G (corresponding author), NHN Corp, R&D Ctr, Multimedia Search Team, 6th Floor Chorim Bldg,6-3 Sunae Dong, Seongnam City 463825, Gyeonggi Do, South Korea.
EM ghpark@kaist.ac.kr; yunju@pusan.ac.kr; hklee@rtlab.kaist.ac.kr
RI Lee, Heung Kyu/C-1941-2011
CR [Anonymous], NATURE STAT LEARNING
   Athitsos V, 1997, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P10, DOI 10.1109/IVL.1997.629715
   BALLARD DH, 1982, COMPUTER VISION, P181
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   CELEBI E, 2000, P INT C ADV INF SYST, P216
   CHEN Y, 2003, 5 ACM SIGMM INT WORK, P193
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   FRAKES WB, 1992, INFORMATION RETRIEVA, P419
   FRANKEL C, 1996, TR9614 U CHIC
   GEVERS T, 1997, P INT C VIS INF SYST, P93
   HARALICK RM, 1992, COMPUTER ROBOT VISIO, P453
   Hartmann A, 2002, PROC SPIE, V4676, P31
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   Lee SM, 2001, SAMPE J, V37, P14
   Li J, 2000, IEEE T IMAGE PROCESS, V9, P1604, DOI 10.1109/83.862641
   Ma WY, 1999, MULTIMEDIA SYST, V7, P184, DOI 10.1007/s005300050121
   Mukherjea S, 1999, J VISUAL LANG COMPUT, V10, P585, DOI 10.1006/jvlc.1999.0147
   MUKHERJEA S, 1998, P 1998 WORKSH NEW PA, P29
   PARK G, 2002, P CHALL IM VID RETR, P316
   Parker J.R., 1997, ALGORITHMS IMAGE PRO, P23
   Partio M., 2002, P 5 NORD SIGN PROC S
   Sclaroff S, 1999, COMPUT VIS IMAGE UND, V75, P86, DOI 10.1006/cviu.1999.0765
   Serrano N, 2002, INT C PATT RECOG, P146, DOI 10.1109/ICPR.2002.1047420
   SMITH JR, 1997, THESIS COLUMBIA U
   STOLLNITZ EJ, 1995, IEEE COMPUT GRAPH, V15, P76, DOI 10.1109/38.376616
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Szummer M, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P42, DOI 10.1109/CAIVD.1998.646032
   Tombros A, 2002, INFORM PROCESS MANAG, V38, P559, DOI 10.1016/S0306-4573(01)00048-6
   Vailaya A, 1998, PATTERN RECOGN, V31, P1921, DOI 10.1016/S0031-3203(98)00079-X
   Voorhees E.M., 1985, SIGIR '85 Proceedings of the 8th annual international ACM SIGIR conference on Research and development in information retrieval, P188, DOI [DOI 10.1145/253495.253524, 10.1145/253495.253524]
   VOORHEES EM, 1986, 86765 TR CORN U DEP
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   WILLETT P, 1988, INFORM PROCESS MANAG, V24, P577, DOI 10.1016/0306-4573(88)90027-1
NR 34
TC 7
Z9 7
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2006
VL 31
IS 2
BP 195
EP 219
DI 10.1007/s11042-006-0039-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 103MP
UT WOS:000241890500004
DA 2024-07-18
ER

PT J
AU Urban, J
   Jose, JM
   van Rijsbergen, CJ
AF Urban, Jana
   Jose, Joemon M.
   van Rijsbergen, Cornelis J.
TI An adaptive technique for content-based image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA Slovenian
DT Article
DE content-based image retrieval; adaptive retrieval; ostensive relevance;
   relevance feedback; user evaluation
ID PERFORMANCE
AB We discuss an adaptive approach towards Content-Based Image Retrieval. It is based on the Ostensive Model of developing information needs-a special kind of relevance feedback model that learns from implicit user feedback and adds a temporal notion to relevance. The ostensive approach supports content-assisted browsing through visualising the interaction by adding user-selected images to a browsing path, which ends with a set of system recommendations. The suggestions are based on an adaptive query learning scheme, in which the query is learnt from previously selected images. Our approach is an adaptation of the original Ostensive Model based on textual features only, to include content-based features to characterise images. In the proposed scheme textual and colour features are combined using the Dempster-Shafer theory of evidence combination. Results from a user-centred, work-task oriented evaluation show that the ostensive interface is preferred over a traditional interface with manual query facilities. This is due to its ability to adapt to the user's need, its intuitiveness and the fluid way in which it operates. Studying and comparing the nature of the underlying information need, it emerges that our approach elicits changes in the user's need based on the interaction, and is successful in adapting the retrieval to match the changes. In addition, a preliminary study of the retrieval performance of the ostensive relevance feedback scheme shows that it can outperform a standard relevance feedback strategy in terms of image recall in category search.
C1 Univ Glasgow, Dept Comp Sci, Glasgow G12 8RZ, Lanark, Scotland.
C3 University of Glasgow
RP Urban, J (corresponding author), Univ Glasgow, Dept Comp Sci, Glasgow G12 8RZ, Lanark, Scotland.
EM jana@dcs.gla.ac.uk; jj@dcs.gla.ac.uk; keith@dcs.gla.ac.uk
OI Jose, Joemon/0000-0001-9228-1759
CR [Anonymous], 1998, Image processing, analysis, and machine vision
   Black JA, 2002, LECT NOTES COMPUT SC, V2383, P356
   Campbell I., 2000, Information Retrieval, V2, P87, DOI 10.1023/A:1009902203782
   Campbell I, 1996, COLIS 2 - SECOND INTERNATIONAL CONFERENCE ON CONCEPTIONS OF LIBRARY AND INFORMATION SCIENCE: INTEGRATION IN PERSPECTIVE, PROCEEDINGS, P251
   CAMPBELL I, 2000, THESIS U GLASGOW
   Chalmers M, 1998, COMPUT NETWORKS ISDN, V30, P359, DOI 10.1016/S0169-7552(98)00069-5
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   Dunlop M, 2000, J AM SOC INFORM SCI, V51, P1269, DOI 10.1002/1097-4571(2000)9999:9999<::AID-ASI1042>3.0.CO;2-7
   GARBER SR, 1992, P ACM INT C HUM FACT, P157
   HUMK, 1962, IEEE T INFORM THEORY, V8, P179
   INGWERSEN P, 1992, INFORAMTION RETRIEVA
   Ishikawa Y., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P218
   Jose J. M., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P232, DOI 10.1145/290941.291000
   JOSE JM, 1998, THESIS R GORDON U AB
   JOSE JM, 1997, P INT C DAT EXP SYST, P276
   Jose R. W., 2003, P 12 INT C INF KNOWL, P504, DOI [10.1145/956958.956959White, DOI 10.1145/956958.956959]
   Markkula M., 2000, Information Retrieval, V1, P259, DOI 10.1023/A:1009995816485
   MCDONALD S, 2001, P 24 ANN INT ACM SIG, P232
   Peng J, 1999, COMPUT VIS IMAGE UND, V75, P150, DOI 10.1006/cviu.1999.0770
   Porkaew K, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P235, DOI 10.1145/319463.319613
   Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313
   Rui Y, 2000, PROC CVPR IEEE, P236, DOI 10.1109/CVPR.2000.855825
   SALTON G, 1990, J AM SOC INFORM SCI, V41, P288, DOI 10.1002/(SICI)1097-4571(199006)41:4<288::AID-ASI8>3.0.CO;2-H
   SALTON G, 1983, INTRO MODERN INFORMA
   Santini S, 2001, IEEE T KNOWL DATA EN, V13, P337, DOI 10.1109/69.929893
   Squire DM, 1998, PATTERN RECOGN, V31, P1905, DOI 10.1016/S0031-3203(98)00028-4
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2420, P381
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TerHofstede AHM, 1996, COMPUT J, V39, P255, DOI 10.1093/comjnl/39.4.255
   Tieu K, 2000, PROC CVPR IEEE, P228, DOI 10.1109/CVPR.2000.855824
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   Urban J., 2003, PROC 3 INT WORKSHOP, P119
   White R. W., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval
   Wood M. E. J., 1998, Proceedings ACM Multimedia 98, P13, DOI 10.1145/290747.290750
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 35
TC 29
Z9 33
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2006
VL 31
IS 1
BP 1
EP 28
DI 10.1007/s11042-006-0035-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 092QK
UT WOS:000241112200001
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Celentano, A
   Gaggi, O
AF Celentano, Augusto
   Gaggi, Ornbretta
TI Context-aware design of adaptable multimodal documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT International Workshop on Multimedia and Web Design
CY DEC 13, 2004
CL Miami, FL
DE hypermedia design; adaptation; rule system
AB In this paper we present a model and an adaptation architecture for context-aware multimodal documents. A compound virtual document describes the different ways in which multimodal information can be structured and presented. Physical features are associated to media instances, while properties describe the context. Concrete documents are instantiated from virtual documents by selecting and synchronizing proper media instances based on the user context: the situation, the environment, the device and the available communication resources. The relations between the context features and the media properties are described by a rule based system.
C1 Univ Ca Foscari Venezia, Dipartimento Informat, I-30172 Venice, VE, Italy.
C3 Universita Ca Foscari Venezia
RP Celentano, A (corresponding author), Univ Ca Foscari Venezia, Dipartimento Informat, Via Torino 155, I-30172 Venice, VE, Italy.
EM auce@dsi.unive.it; gaggi@math.unipd.it
OI Celentano, Augusto/0000-0002-8574-4935
CR Abowd GD, 1997, WIREL NETW, V3, P421, DOI 10.1023/A:1019194325861
   [Anonymous], P WORKSH MOB COMP SY
   [Anonymous], 2000, SURVEY CONTEXT AWARE
   [Anonymous], CALCULATION NEXT 50
   Bertino E, 2000, IEEE T KNOWL DATA EN, V12, P102, DOI 10.1109/69.842254
   BERTOLOTTI P, 2004, P INT WORKSH MULT IN, P96
   Boll S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P37, DOI 10.1145/319463.319468
   Brusilovsky P, 1996, USER MODEL USER-ADAP, V6, P87, DOI 10.1007/BF00143964
   Celentano A, 2004, MULTIMEDIA SYST, V10, P72, DOI 10.1007/s00530-004-0138-3
   Davies N, 2001, COMPUTER, V34, P35, DOI 10.1109/2.940011
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   DIAS V, 2003, P 18 INT JOINT C ART, P31
   Elouazizi N., 2004, Proceedings. IEEE Sixth International Symposium on Multimedia Software, P418
   Fink J., 1998, New Review of Hypermedia and Multimedia, V4, P163, DOI 10.1080/13614569808914700
   GAGGI O, 2002, MULTIMED TOOLS APPL, V27, P53
   Harter A., 1999, Proceedings of the 5th Annual ACM/IEEE International Conference on Mobile Computing and Networking. MobiCom'99, P59, DOI DOI 10.1145/313451.313476
   Klyne G., COMPOSITE CAPABILITY
   KRAUS M, 2003, P WORKSH PRINC PRACT
   Lemlouma T, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT, P106
   Lemlouma T, 2003, 2003 SYMPOSIUM ON APPLICATIONS AND THE INTERNET, PROCEEDINGS, P190, DOI 10.1109/SAINT.2003.1183048
   Ossenbruggen Jaccovan., 2001, The 10th International World Wide Web Conference on World Wide Web (WWW10), Hong Kong, P479
   Petrelli D, 2001, PERS UBIQUIT COMPUT, V5, P20, DOI 10.1007/s007790170023
   Ranganathan A, 2003, PERS UBIQUIT COMPUT, V7, P353, DOI 10.1007/s00779-003-0251-x
   SCHMIDT A, 1999, COMPUT GRAPH, V23
   Schneider-Hufschmidt Matthias., 1993, ADAPTIVE USER INTERF
   STEELE R, 2004, INT C INF TECHN COD, V2, P410
   *SUN MICR, JAV ARCH XML BIND JA
   *SWED I COMP SCI, SICSTUS PROL
   *SYNCHR MULT WORK, 2001, SYNCHR MULT INT LANG
   Villard L., 2001, Proceedings of the ACM Symposium on Document Engineering (DocEng '01), P125, DOI 10.1145/502187.502206
   VILLARD L, 2000, LNCS MUNICH GERMANY, V2023
   WIRAG S, 1997, P 4 INT WORKSH INT D, P220
NR 32
TC 7
Z9 7
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2006
VL 29
IS 1
BP 7
EP 28
DI 10.1007/s11042-006-7811-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 061AH
UT WOS:000238843100002
DA 2024-07-18
ER

PT J
AU Geyer, W
   Richter, H
   Abowd, GD
AF Geyer, W
   Richter, H
   Abowd, GD
TI Towards a smarter meeting record - Capture and access of meetings
   revisited
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE capture; access; multimedia meeting record; indexing; domain-specific
   artifact; teamwork; distributed meetings
AB Multimedia records of meetings contain a rich amount of project information. However, finding detailed information in a meeting record can be difficult because there is no structural information other than time to aid navigation. In this paper we survey and discuss various ways of indexing meeting records by categorizing existing approaches along multiple dimensions. We then introduce the notion of creating indices based upon user interaction with domain-specific artifacts. As an example to illustrate the use of domain-specific artifacts to create meaningful pointers into the meeting record, we describe capture and access in a prototype system that supports general meeting artifacts.
C1 IBM Corp, TJ Watson Res Ctr, Cambridge, MA 02142 USA.
   Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA.
   Georgia Inst Technol, GVU Ctr, Atlanta, GA 30332 USA.
   Univ N Carolina, Dept Software & Informat Syst, Charlotte, NC 28223 USA.
C3 International Business Machines (IBM); University System of Georgia;
   Georgia Institute of Technology; University System of Georgia; Georgia
   Institute of Technology; University of North Carolina; University of
   North Carolina Charlotte
RP IBM Corp, TJ Watson Res Ctr, 1 Rogers St, Cambridge, MA 02142 USA.
EM werner.geyer@us.ibm.com; hrichter@cc.gatech.edu; abowd@cc.gatech.edu
CR *3M, 2002, 3M M NETW
   ABOUWD G, 1998, P CHI 98
   [Anonymous], 1992, COMPUT SUPP COOP W J, DOI DOI 10.1007/BF00752449
   [Anonymous], 1998, P JOINT DARPA NIST S
   Arons B., 1992, P 1992 C AM VOIC I O, P169
   BORGHOFF S, 2000, COMPUTER SUPPORTED C
   BURMITT B, 2000, HANDHELD UBIQUITOUS
   CHIU P, 2001, P WWW10 MAY
   CHIU P, 1999, P ACM MULT 99 NEW YO
   Conklin E.J., 1996, DESIGNING ORG MEMORY
   COOK P, 1987, ACM T INFORM SYST, V5, P132, DOI 10.1145/27636.27638
   Cruz G., 1994, Proceedings ACM Multimedia '94, P193, DOI 10.1145/192593.192654
   DEGEN L, 1992, P CHI 92, P413
   FUCHS L, 2001, P IEEE 10 INT WORKSH
   GEYER W, 2001, 21961 IBM RC
   GEYER W, 2001, P GROUP2001 ACM 2001
   GINSBERG A, 1995, P ACM MULT 95 SAN FR
   GROSS R, 2000, P IEEE ICME 2000 NEW
   HE L, 1995, P ACM MULT 99 ORL FL, P489
   HINDUS D, 1992, P 1992 ACM C COMP SU, P210
   Khan F, 1992, SURVEY NOTE TAKING P
   MINNEMAN S, 1995, P ACM C MULT SAN FRA, P523
   MORAN TP, 1998, P CSCW 98, P295
   MORAN TP, 1997, P CHI 97 ATL GA
   Muller M., 1991, P SIGCHI C HUMAN FAC, P225, DOI DOI 10.1145/108844.108896
   OMOIGUI N, 1999, P ACM C COMP HUM INT
   POLTROCK SE, 1997, P GROUP 97, P61
   Richter H., 2001, P UB 2001 ACM C UB C
   Slaney M., 2001, P 9 ACM INT C MULTIM, P29
   SRINIVASAN S, 1999, P IEEE INT C MULT CO, V1
   Steinmetz A., 2001, P SPIE C MULTIMEDIA, P25
   Syeda-Mahmood T., 2000, Proceedings ACM Multimedia 2000, P85, DOI 10.1145/354384.354433
   WACTLER HD, 2000, P IM 2000 C MON
   WHITTAKER S, 1994, P CHI 94 C HUM FACT, P271
   WILCOX L, 1994, P SOC PHOTO-OPT INS, V2277, P149, DOI 10.1117/12.191878
   WILCOX LD, 1997, P CHI 97 ATL GA MARC
   WOLF CG, 1992, 19811 RC IBM TJ WATS
   WOLF CG, 1992, P ACM CSCW92 C COMP, P322
NR 38
TC 20
Z9 26
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2005
VL 27
IS 3
BP 393
EP 410
DI 10.1007/s11042-005-3815-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 988CF
UT WOS:000233568300005
DA 2024-07-18
ER

PT J
AU Ma, HD
   Shin, GG
   Wu, WB
AF Ma, HD
   Shin, GG
   Wu, WB
TI Best-effort patching for multicast true VoD service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QoS; VCR interaction; Best-Effort Patching (BEP); Video-on-Demand (VoD);
   multicast
AB A multicast Video-on-Demand (VoD) system allows clients to share a server stream by batching their requests, and hence, improves channel utilization. However, it is very difficult to equip such a VoD system with full support for interactive VCR functions which are important to a growing number of Internet applications. In order to eliminate service (admission) latency, patching was proposed to enable an existing multicast session to dynamically add new clients, and requests can be served without delay if patching channels are available. A true VoD (TVoD) service should support not only zero-delay client admission but also continuous VCR-like interactivity. However, the conventional patching is only suitable for admission control. We propose a new patching scheme, called Best-Effort Patching (BEP), that offers a TVoD service in terms of both request admission and VCR interactivity. Moreover, by using a novel dynamic merging algorithm, BEP significantly improves the efficiency of TVoD interactivity, especially for popular videos. We also model and evaluate the efficiency of the dynamic merging algorithm. It is shown that BEP outperforms the conventional TVoD interaction protocols.
C1 Beijing Univ Posts & Telecommun, Sch Comp Sci & Technol, Beijing 100876, Peoples R China.
   Univ Michigan, Dept Elect Engn & Comp Sci, Real Time Comp Lab, Ann Arbor, MI 48109 USA.
   Univ Chicago, Dept Stat, Chicago, IL 60637 USA.
C3 Beijing University of Posts & Telecommunications; University of Michigan
   System; University of Michigan; University of Chicago
RP Beijing Univ Posts & Telecommun, Sch Comp Sci & Technol, Beijing 100876, Peoples R China.
EM mhd@bupt.edu.cn; kgshin@eecs.umich.edu; wbwu@galton.uchicago.edu
CR ABRAMPROFETA EL, 1998, THESIS U MICHIGAN AN
   ABRAMPROFETA EL, 1998, P IEEE INT C MULT CO
   Almeroth KC, 1996, IEEE J SEL AREA COMM, V14, P1110, DOI 10.1109/49.508282
   BRADSHAW MK, 2001, P ACM MULT 2001 OTT
   Cai Y, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P211
   CAI Y, 1999, P SPIE ACM C MULT CO, P204
   Dan A., 1994, Proceedings ACM Multimedia '94, P15, DOI 10.1145/192593.192614
   Dey-Sircar J. K., 1994, Proceedings ACM Multimedia '94, P25, DOI 10.1145/192593.192615
   Eager D, 2001, IEEE T KNOWL DATA EN, V13, P742, DOI 10.1109/69.956098
   Eager D, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P199, DOI 10.1145/319463.319601
   EAGER DL, 2000, P MMCN 2000 SAN JOS
   EAGER DL, 1998, P 4 INT WORKSH MULT, P18
   GAO L, 1998, P NOSSDAV CAMBR UK J
   Gao LX, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P117, DOI 10.1109/MMCS.1999.778179
   GOLUBCHIK L, 1996, MULTIMEDIA SYSTEMS, V4
   Hua K., 1997, PROC SIGCOMM, P89
   Hua K. A., 1998, Proceedings ACM Multimedia 98, P191, DOI 10.1145/290747.290771
   Li VOK, 1996, IEEE J SEL AREA COMM, V14, P1099, DOI 10.1109/49.508281
   Liao W, 1997, IEEE MULTIMEDIA, V4, P51, DOI 10.1109/93.641879
   Little T. D. C., 1994, IEEE Multimedia, V1, P14, DOI 10.1109/MMUL.1994.318978
   Ma HD, 2002, ACM SIGCOMM COMP COM, V32, P31, DOI 10.1145/510726.510729
   Ma HD, 2001, LECT NOTES COMPUT SC, V2195, P708
   Ma HD, 2002, J COMPUT SCI TECH-CH, V17, P397, DOI 10.1007/BF02943280
   SEN S, 1999, P NOSSDAV 99 BASK RI
   TAN H, 2002, P ACM SIGMETRICS 200
   Viswanathan S, 1996, MULTIMEDIA SYST, V4, P197, DOI 10.1007/s005300050023
   [No title captured]
NR 27
TC 17
Z9 19
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2005
VL 26
IS 1
BP 101
EP 122
DI 10.1007/s11042-005-6851-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 915EU
UT WOS:000228281600005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Khan, AAR
   Nisha, SS
AF Khan, A. Ameer Rashed
   Nisha, S. Shajun
TI Efficient hybrid optimization based feature selection and classification
   on high dimensional dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Optimal feature selection; Swarm models; High dimensionality data; Slime
   mould algorithm; Binary grey wolf optimization; K-nearest neighbor
ID PARTICLE SWARM OPTIMIZATION; ALGORITHM; WOLF
AB With the vast usage of intelligent information systems (ISs), the tremendous increase in data volume creates numerous problems and challenges, such as high dimensionality, noisy and irrelevant data. These issues lead to high computational costs and greatly affect the accuracy and efficiency of machine learning (ML) algorithms. Feature selection (FS) is one of the most important concepts used effectively to boost the classification's accuracy and minimize computational costs. However, finding an effective FS approach is challenging, and numerous swarm-based algorithms inspired by biological systems have been developed. Feature selection aims to determine the best subset of features for categorizing the class labels by eliminating irrelevant data. This paper introduces the hybrid optimization approach to solve the problems in the feature selection process. The input data is obtained from several datasets, and the data cleaning is performed in the pre-processing stage. Initially, eight different optimization techniques are executed and depending on the results attained from performance metrics, the best two algorithms are selected. The selected best algorithms are combined together to generate a hybrid process. The proposed work hybridizes a Slime Mould Algorithm (SMA) with Binary Grey Wolf Optimization (BGWO) for feature selection. The selected features from the hybrid algorithms are fed to the K-nearest neighbor (KNN) classifier, which is analyzed to be effective compared to the other classifier. Finally, the hybrid SMA + BGWO based feature selection with the KNN classifier effectively solves the FS problems on high dimensional data with remarkable accuracy and convergence speed. Performance metrics like accuracy, precision, F-measure, computational time, recall, RMSE and MAE are utilized to evaluate the efficacy of classifiers. The proposed SMA + BGWO approach with KNN classification in the CICDDoS2019 dataset attains an accuracy of 99.83%, and CICMalDroid2020 attains an accuracy of 99.30%. The experimental analysis proves that the proposed hybrid technique is better than the existing techniques.
C1 [Khan, A. Ameer Rashed] New Coll, Dept Data Sci, Chennai 600014, Tamil Nadu, India.
   [Nisha, S. Shajun] Sadakathullah Appa Coll, PG & Res Dept Comp Sci, Tirunelveli 627011, Tamil Nadu, India.
RP Khan, AAR (corresponding author), New Coll, Dept Data Sci, Chennai 600014, Tamil Nadu, India.
EM ameerkhan.a1694@gmail.com
CR Adeli A, 2018, APPL INTELL, V48, P1609, DOI 10.1007/s10489-017-0989-x
   Agrawal RK, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106092
   Allam M, 2020, INT ARAB J INF TECHN, V17, P885, DOI 10.34028/iajit/17/6/7
   Asgarnezhad R, 2021, J SUPERCOMPUT, V77, P5806, DOI 10.1007/s11227-020-03490-w
   Aydilek IB, 2018, APPL SOFT COMPUT, V66, P232, DOI 10.1016/j.asoc.2018.02.025
   Bolón-Canedo V, 2020, ARTIF INTELL REV, V53, P2905, DOI 10.1007/s10462-019-09750-3
   Cai J, 2018, NEUROCOMPUTING, V300, P70, DOI 10.1016/j.neucom.2017.11.077
   Chantar Hamouda, 2021, SN Comput Sci, V2, P295, DOI 10.1007/s42979-021-00687-5
   Chitara D, 2018, IEEE T IND APPL, V54, P3056, DOI 10.1109/TIA.2018.2811725
   Deng XL, 2019, MULTIMED TOOLS APPL, V78, P3797, DOI 10.1007/s11042-018-6083-5
   El-Kenawy ES, 2020, INT J INNOV COMPUT I, V16, P831, DOI 10.24507/ijicic.16.03.831
   Ewees AA, 2022, ENG COMPUT-GERMANY, V38, P2407, DOI 10.1007/s00366-021-01342-6
   Ge DD, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031398
   Ghojogh B, 2019, Arxiv, DOI arXiv:1905.02845
   Ghosh M, 2020, NEURAL COMPUT APPL, V32, P7839, DOI 10.1007/s00521-019-04171-3
   Hussien Abdelazim G., 2019, Recent Trends in Signal and Image Processing. ISSIP 2017. Advances in Intelligent Systems and Computing (AISC 727), P79, DOI 10.1007/978-981-10-8863-6_9
   Kang XD, 2017, IEEE T GEOSCI REMOTE, V55, P7140, DOI 10.1109/TGRS.2017.2743102
   Khan AAR., 2022, Int. J. Health Sci, VI, P7657, DOI DOI 10.53730/IJHS.V6NS1.6667
   Khanna M, 2023, Multimed Tools Appl, P1
   Kumar A, 2022, P I MECH ENG O-J RIS, V236, P529, DOI 10.1177/1748006X20916953
   Li SM, 2020, FUTURE GENER COMP SY, V111, P300, DOI 10.1016/j.future.2020.03.055
   Madasu A, 2020, MULTIMED TOOLS APPL, V79, P6313, DOI 10.1007/s11042-019-08409-z
   Mafarja M, 2020, COGN COMPUT, V12, P150, DOI 10.1007/s12559-019-09668-6
   Mafarja M, 2018, KNOWL-BASED SYST, V161, P185, DOI 10.1016/j.knosys.2018.08.003
   Mafarja M, 2018, APPL SOFT COMPUT, V62, P441, DOI 10.1016/j.asoc.2017.11.006
   Nie FP, 2019, IEEE T IMAGE PROCESS, V28, P2428, DOI 10.1109/TIP.2018.2886761
   Parvathavarthini S., 2021, IOP Conference Series: Materials Science and Engineering, V1055, DOI 10.1088/1757-899X/1055/1/012107
   Pathak Y, 2019, MULTIMED TOOLS APPL, V78, P1473, DOI 10.1007/s11042-018-6155-6
   Raj RJS, 2020, IEEE ACCESS, V8, P58006, DOI 10.1109/ACCESS.2020.2981337
   Rostami M, 2020, GENOMICS, V112, P4370, DOI 10.1016/j.ygeno.2020.07.027
   Sathiyabhama B, 2021, NEURAL COMPUT APPL, V33, P14583, DOI 10.1007/s00521-021-06099-z
   Shanthi S, 2021, NEURAL PROCESS LETT, V53, P2617, DOI 10.1007/s11063-020-10192-0
   Singh LK, 2023, MEASUREMENT, V221, DOI 10.1016/j.measurement.2023.113525
   Singh LK, 2024, SOFT COMPUT, V28, P2431, DOI 10.1007/s00500-023-08449-6
   Singh LK, 2022, ADV ENG SOFTW, V173, DOI 10.1016/j.advengsoft.2022.103283
   Tawhid M.A., 2018, Applied Computing and Informatics
   Venkatesh B, 2019, CYBERN INF TECHNOL, V19, P3, DOI 10.2478/cait-2019-0001
   Zawbaa HM, 2018, SWARM EVOL COMPUT, V42, P29, DOI 10.1016/j.swevo.2018.02.021
   Zhang YX, 2017, SCI REP-UK, V7, DOI [10.1038/srep40290, 10.1038/srep42085]
   Zhou T, 2019, APPL SOFT COMPUT, V75, P323, DOI 10.1016/j.asoc.2018.11.001
NR 40
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 23
PY 2023
DI 10.1007/s11042-023-17724-5
EA DEC 2023
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB6G7
UT WOS:001129606100001
DA 2024-07-18
ER

PT J
AU Nagaraju, T
   Murugeswari, R
AF Nagaraju, Thandu
   Murugeswari, R.
TI Self-attention-based multimodality convolutional volcano eruption
   network based indoor localization and wayfinding for blind people
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fingerprint database; Received signal strength indicator; Positioning
   system; Normalization; Cluster centroid
AB The ability to navigate and precisely locate a visually challenged people within a building is significantly important for a wide variety of location services and public safety. Also, Indoor Localization (IL) for blind people is an open research challenge and the individual localization algorithm failed to achieve accurate location results. To overcome this problem, in this research work, a novel hybrid indoor localization strategy using a WiFi fingerprint database is proposed. It includes two stages such as Offline Phase (OP) and Online Phase (OnP). In the OF, this system employs a Min-Max Normalization approach to normalize the fingerprint database. Then, the Fractional Sparse Fuzzy C-Means Clustering method (FSFCC) is proposed to retrieve the Validation Set (VS) from all the Training Sets (TS) in the ratio of 4:1. In the online stage, the received signal strength indicator (RSSI) data value in dBm is reconstructed and key features such as longitude, latitude, floor ID and building ID are extracted by using Self-Attention-Based Multimodality Convolutional Volcano Eruption Network (Se-AMCVE). Hence, the weight parameters of the proposed network are optimized by applying Volcano Eruption Optimization (VEO). Finally, the accurate estimated location data is the outcome of the proposed network which helps the blind to find the path. The achieved accuracy is 94%, mean positioning error is 3.01 m and floor hit rate is 97.08% which is implemented in the python flask framework.
C1 [Nagaraju, Thandu; Murugeswari, R.] Kalasalingam Acad Res & Educ, Dept Comp Sci & Engn, Krishnankoil 626126, Tamil Nadu, India.
C3 Kalasalingam Academy of Research & Education
RP Nagaraju, T (corresponding author), Kalasalingam Acad Res & Educ, Dept Comp Sci & Engn, Krishnankoil 626126, Tamil Nadu, India.
EM nagarajuthandu@gmail.com; r.murugeswari@klu.ac.in
CR Agah N, 2023, SOUTHEASTCON 2023, P240, DOI 10.1109/SoutheastCon51012.2023.10115169
   AL-Madani B, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092114
   Alitaleshi A, 2023, ENG APPL ARTIF INTEL, V117, DOI 10.1016/j.engappai.2022.105509
   Chen MZ, 2020, IEEE INTERNET THINGS, V7, P11851, DOI 10.1109/JIOT.2020.3004240
   Chen X, 2022, IEEE INTERNET THINGS, V9, P9872, DOI 10.1109/JIOT.2022.3163391
   del-Blanco CR, 2021, SIGNAL PROCESS-IMAGE, V93, DOI 10.1016/j.image.2021.116135
   Dou F, 2021, IEEE INTERNET THINGS, V8, P6519, DOI 10.1109/JIOT.2020.3041204
   Ebaid E, 2022, AUSTRA TELEC N A C, P280, DOI 10.1109/ITNAC55475.2022.9998385
   Fan SK, 2021, IEEE J SEL AREA COMM, V39, P2226, DOI 10.1109/JSAC.2021.3078491
   Gharghan SK, 2023, ARAB J SCI ENG, V48, P6025, DOI 10.1007/s13369-022-07188-4
   Hosseini E, 2021, NEURAL COMPUT APPL, V33, P2321, DOI 10.1007/s00521-020-05124-x
   Hou CJ, 2023, IEEE SENS J, V23, P7153, DOI 10.1109/JSEN.2022.3229476
   Jia B, 2022, FUTURE GENER COMP SY, V137, P380, DOI 10.1016/j.future.2022.07.021
   Jia MH, 2022, MULTIMED TOOLS APPL, V81, P42497, DOI 10.1007/s11042-021-11214-2
   Kim HG, 2020, IEEE T CONSUM ELECTR, V66, P271, DOI 10.1109/TCE.2020.3015197
   Koike-Akino T, 2020, IEEE ACCESS, V8, P84879, DOI 10.1109/ACCESS.2020.2991129
   Kulkarni O, 2020, IET IMAGE PROCESS, V14, P2719, DOI 10.1049/iet-ipr.2019.0899
   Labinghisa BA, 2021, J SUPERCOMPUT, V77, P638, DOI 10.1007/s11227-020-03272-4
   Laska M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062000
   Ma L, 2022, ISPRS INT J GEO-INF, V11, DOI 10.3390/ijgi11010071
   Duong-Bao N, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22155709
   Njima W, 2022, IEEE ACCESS, V10, P69896, DOI 10.1109/ACCESS.2022.3187837
   Qin F, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041114
   Shu MC, 2022, ISPRS J PHOTOGRAMM, V185, P85, DOI 10.1016/j.isprsjprs.2022.01.010
   Song XD, 2019, 2019 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI 2019), P589, DOI 10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00139
   Sulaiman B, 2022, PERVASIVE MOB COMPUT, V81, DOI 10.1016/j.pmcj.2022.101548
   Sun MY, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3081178
   Torres-Sospedra J, 2014, INT C INDOOR POSIT, P261, DOI 10.1109/IPIN.2014.7275492
   Hoang MT, 2020, Arxiv, DOI arXiv:2005.06394
   Wang C, 2022, IEEE INTERNET THINGS, V9, P22291, DOI 10.1109/JIOT.2021.3079151
   Wang YJ, 2021, WIREL NETW, V27, P1739, DOI 10.1007/s11276-020-02483-0
   Zhang L., 2021, EURASIP J Adv Signal Process, V2021, P1, DOI [10.1186/s13634-021-00758-y, DOI 10.1186/S13634-021-00758-Y]
   Zhang LJ, 2020, IEEE COMMUN LETT, V24, P1437, DOI 10.1109/LCOMM.2020.2984036
   Zhang Y, 2021, IEEE SENS J, V21, P18156, DOI 10.1109/JSEN.2021.3082553
   Zhang ZY, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15143520
   Zhou M, 2021, IEEE T VEH TECHNOL, V70, P5057, DOI [10.1109/TVT.2021.3076269, 10.1109/TEVC.2021.3085906]
   Zhu QW, 2020, J FRANKLIN I, V357, P1420, DOI 10.1016/j.jfranklin.2019.10.028
   Zhu XQ, 2020, IEEE COMMUN SURV TUT, V22, P2634, DOI 10.1109/COMST.2020.3014304
NR 38
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 22
PY 2023
DI 10.1007/s11042-023-17274-w
EA DEC 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB8U4
UT WOS:001129672000009
DA 2024-07-18
ER

PT J
AU Kanadath, A
   Jothi, JAA
   Urolagin, S
AF Kanadath, Anusree
   Jothi, J. Angel Arul
   Urolagin, Siddhaling
TI AIR-UNet plus plus : a deep learning framework for histopathology image
   segmentation and detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Encoder-decoder models; Image segmentation;
   Histopathology; UNet models
ID NUCLEAR SEGMENTATION
AB Cancer was found to be a leading cause of human mortality in the year 2020, accounting for one in six deaths worldwide, as per data published by the World Health Organization. Early detection and treatment can play a major role in averting these deaths. Delayed cancer care often leads to lower chances of survival, greater complications associated with treatment and higher costs. Histopathology image analysis is a technology that plays a vital role in the early detection and diagnosis of cancer. The segmentation of regions of interest (RoIs) from whole slide images (WSIs) provides useful information for differentiating diseased tissues from normal ones. A strong segmentation framework is required in this case due to the rich and irregular mix of visual patterns of the RoIs. In this work, we present an atrous inception-resnet based UNet model with dense skip connections (AIR-UNet++) for the effective segmentation and detection of various RoIs from histopathology images stained with Hematoxylin and Eosin (H &E). To test the performance of the proposed method, experiments are carried out on five different datasets, including nuclei segmentation, TNBC, MoNuSeg, lymphocyte detection and MoNuSAC (Lymphocyte, Neutrophils, Macrophages, Epithelial). Experimental results show that the proposed AIR-UNet++ method outperforms other UNet variants, pre-trained models. Specifically, for the nuclei segmentation dataset, we achieved a Dice coefficient (DC) of 0.74 and a Jaccard Index (JI) of 0.64. For the TNBC dataset, our method achieved a DC of 0.88 and a JI of 0.79, while on the MoNuSeg dataset, we obtained a DC of 0.79 and a JI of 0.67. For the Lymphocyte detection dataset, we achieved an accuracy of 0.98 and an F1 score of 0.88. Notably, in the MoNuSAC-Lymphocyte dataset, our model achieved a DC of 0.85 and a JI of 0.75. Similarly, for the MoNuSAC-Neutrophils dataset, the DC was 0.83 with a JI of 0.72, for MoNuSAC-Macrophages, the DC was 0.82 with a JI of 0.72, and for MoNuSAC-Epithelial, we achieved a DC of 0.73 and a JI of 0.61. The AIR-Unet++ performs on par with other state-of-the-art methods.
C1 [Kanadath, Anusree; Jothi, J. Angel Arul; Urolagin, Siddhaling] Birla Inst Technol & Sci Pilani, Dept Comp Sci, Dubai Campus, Dubai, U Arab Emirates.
RP Jothi, JAA (corresponding author), Birla Inst Technol & Sci Pilani, Dept Comp Sci, Dubai Campus, Dubai, U Arab Emirates.
EM anusreek25anu@gmail.com; angeljothi@dubai.bits-pilani.ac.in;
   siddhaling@dubai.bits-pilani.ac.in
OI Kanadath, Anusree/0009-0004-0954-8424
CR Akbas GE, 2020, I S BIOMED IMAGING, P446, DOI [10.1109/isbi45749.2020.9098351, 10.1109/ISBI45749.2020.9098351]
   Al-Milaji Z, 2019, PATTERN RECOGN LETT, V119, P214, DOI 10.1016/j.patrec.2017.09.015
   Baxi V, 2022, MODERN PATHOL, V35, P23, DOI 10.1038/s41379-021-00919-2
   Bulten W, 2018, SPIE, V10581, P219
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Y, 2019, Ant-unet: Accurate and noise-tolerant segmentation for pathology image processing, P1
   Dolz J, 2018, Arxiv, DOI arXiv:1810.07003
   Graham S, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101563
   Hassan L, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10080954
   Hu XG, 2020, IET IMAGE PROCESS, V14, P192, DOI 10.1049/iet-ipr.2019.0025
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jahn SW, 2020, J CLIN MED, V9, DOI 10.3390/jcm9113697
   Janowczyk A, 2022, How to select the correct magnification and patch size for digital pathology projects
   Janowczyk A, 2018, COMP M BIO BIO E-IV, V6, P270, DOI 10.1080/21681163.2016.1141063
   Janowczyk Andrew, 2016, J Pathol Inform, V7, P29, DOI 10.4103/2153-3539.186902
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jothi JAA, 2017, ARTIF INTELL REV, V48, P31, DOI 10.1007/s10462-016-9494-6
   Kablan EB, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106533
   Kanadath Anusree, 2023, SN Comput Sci, V4, P427, DOI 10.1007/s42979-023-01915-w
   Komura D, 2018, COMPUT STRUCT BIOTEC, V16, P34, DOI 10.1016/j.csbj.2018.01.001
   Kong Y, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.573866
   Korman S, 2019, KIDNEY INT REP, V4, P955, DOI 10.1016/j.ekir.2019.04.008
   Kumar N, 2020, IEEE T MED IMAGING, V39, P1380, DOI 10.1109/TMI.2019.2947628
   Kumar N, 2017, IEEE T MED IMAGING, V36, P1550, DOI 10.1109/TMI.2017.2677499
   Lagree A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-87496-1
   Lan HR, 2020, PHOTOACOUSTICS, V20, DOI 10.1016/j.pacs.2020.100197
   Li XY, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207047
   LiS CR XuJ, 2020, Lect Notes Comput Sci, V12532
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Meng C, 2020, NEUROCOMPUTING, V373, P123, DOI 10.1016/j.neucom.2019.10.035
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Nam S, 2020, J PATHOL TRANSL MED, V54, P125
   Naylor P, 2019, IEEE T MED IMAGING, V38, P448, DOI 10.1109/TMI.2018.2865709
   Naylor P, 2017, I S BIOMED IMAGING, P933, DOI 10.1109/ISBI.2017.7950669
   O'Mahony N, 2020, ADV INTELL SYST COMP, V943, P128, DOI 10.1007/978-3-030-17795-9_10
   Overton T, 2020, LECT NOTES COMPUT SC, V12080, P391, DOI 10.1007/978-3-030-44584-3_31
   Oyedotun OK, 2023, IEEE T NEUR NET LEAR, V34, P5961, DOI 10.1109/TNNLS.2021.3131813
   Rad RM, 2020, MED IMAGE ANAL, V62, DOI 10.1016/j.media.2019.101612
   Ravi S, 2019, UEEE INT SYM PERS IN, P715, DOI [10.1109/pimrc.2019.8904109, 10.1109/bhi.2019.8834582]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sahasrabudhe Mihir, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12265), P393, DOI 10.1007/978-3-030-59722-1_38
   Saukko P, 2013, Encyclopedia of Forensic Sciences, P210
   Shahin AH, 2019, I S BIOMED IMAGING, P451, DOI [10.1109/ISBI.2019.8759172, 10.1109/isbi.2019.8759172]
   Silva JP, 2020, IEEE WRK SIG PRO SYS, P1, DOI [10.1109/sips50750.2020.9195214, 10.1007/978-3-030-62362-3_1]
   Slaoui M, 2011, METHODS MOL BIOL, V691, P69, DOI 10.1007/978-1-60761-849-2_4
   Song Y, 2019, Curr Signal Transduct Ther, V15, P1
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   van der Laak J, 2021, NAT MED, V27, P775, DOI 10.1038/s41591-021-01343-4
   Verma R, 2021, IEEE T MED IMAGING, V40, P3413, DOI 10.1109/TMI.2021.3085712
   Wan T, 2020, NEUROCOMPUTING, V408, P144, DOI 10.1016/j.neucom.2019.08.103
   Wang EK, 2019, CELLS-BASEL, V8, DOI 10.3390/cells8050499
   Wang HT, 2020, I S BIOMED IMAGING, P266, DOI [10.1109/ISBI45749.2020.9098611, 10.1109/isbi45749.2020.9098611]
   Wang Y, 2020, Segment Medical Image Using U-Net Combining Recurrent Residuals and Attention, P77
   Wang ZH, 2019, IEEE IMAGE PROC, P1415, DOI [10.1109/ICIP.2019.8803103, 10.1109/icip.2019.8803103]
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wibowo A., 2021, Inform Med Unlocked, V25, P100640, DOI DOI 10.1016/J.IMU.2021.100640
   Xing F, 2020, Artificial intelligence for pathology. Artificial intelligence in medicine: technical basis and clinical applications, DOI [10.1016/B978-0-12-821259-2.00011-9, DOI 10.1016/B978-0-12-821259-2.00011-9]
   Alom MZ, 2019, Arxiv, DOI arXiv:1904.09075
   Zeng ZT, 2019, IEEE ACCESS, V7, P21420, DOI 10.1109/ACCESS.2019.2896920
   Zhao BC, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101786
   Zhao HL, 2017, LECT NOTES COMPUT SC, V10667, P496, DOI 10.1007/978-3-319-71589-6_43
   Zhou TX, 2019, ARRAY-NY, V3-4, DOI 10.1016/j.array.2019.100004
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 66
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 14
PY 2023
DI 10.1007/s11042-023-17768-7
EA DEC 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU3L5
UT WOS:001155145700003
DA 2024-07-18
ER

PT J
AU Mukherjee, H
   Dhar, A
   Obaidullah, SM
   Santosh, KC
   Phadikar, S
   Roy, K
   Pal, U
AF Mukherjee, Himadri
   Dhar, Ankita
   Obaidullah, Sk Md
   Santosh, K. C.
   Phadikar, Santanu
   Roy, Kaushik
   Pal, Umapada
TI LIFA: Language identification from audio with LPCC-G features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Language identification; LPCC-G; Random forest; Indian spoken language
AB In Western countries, speech recognition-based technologies have significantly developed compared to the countries of the South Asian subcontinent like India. India is a multilingual country (22 scheduled languages) with over 1.3 Billion population of which a major percentage faces difficulty with the user interface of different technological advancements and therefore speech recognition tools are very useful. In this paper, we propose LIFA: Language Identification From Audio - a fully automated tool that can identify the spoken language (phrases/words) and invoke the language-specific recognition engine. Experiments were performed on more than 2200 hours of data from the top-11 spoken languages in India. The clips were parameterized with a novel linear predictive cepstral coefficient (LPCC)-based features, which we call LPCC-Grade (LPCC-G). The proposed feature is capable of focusing on the distribution of energy across different frequency ranges in an audio clip for better classification while avoiding high dimensionality issues. Using a random forest-based classifier, we achieved the highest accuracy of 99.01%. Further, we tested the robustness of the system with different noisy scenarios on multiple datasets wherein accuracies in the range of 79%-98% were obtained. We also studied other popular existing features in our comparison where accuracies of 96.37%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$96.37\%$$\end{document} and 92.48%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$92.48\%$$\end{document} were obtained for LSF and MFCC-based features.
C1 [Mukherjee, Himadri; Roy, Kaushik] West Bengal State Univ, Dept Comp Sci, Kolkata, India.
   [Dhar, Ankita] Brainware Univ, Dept Computat Sci, Kolkata, India.
   [Obaidullah, Sk Md] Aliah Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Santosh, K. C.] Univ South Dakota, Dept Comp Sci, Appl AI Res Lab, Vermillion, SD USA.
   [Phadikar, Santanu] Maulana Abul Kalam Azad Univ Technol, Dept Comp Sci & Engn, Kolkata, India.
   [Pal, Umapada] Indian Stat Inst, CVPR Unit, Kolkata, India.
C3 West Bengal State University; Aliah University; University of South
   Dakota; Maulana Abul Kalam Azad University of Technology; Indian
   Statistical Institute; Indian Statistical Institute Kolkata
RP Roy, K (corresponding author), West Bengal State Univ, Dept Comp Sci, Kolkata, India.
EM himadrim027@gmail.com; ankita.ankie@gmail.com; sk.obaidullah@gmail.com;
   santosh.kc@iusd.edu; sphadikar@yahoo.com; kaushik.mrg@gmail.com;
   umapada@isical.ac.in
RI Santosh, K.C./H-1363-2012; Roy, Kaushik/O-7021-2019
OI Roy, Kaushik/0000-0002-3360-7576
CR Akkem Y, 2023, ENG APPL ARTIF INTEL, V120, DOI 10.1016/j.engappai.2023.105899
   Alashban AA, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12189181
   Albadr MAA, 2020, CIRC SYST SIGNAL PR, V39, P4596, DOI 10.1007/s00034-020-01388-9
   Ambikairajah E, 2011, IEEE CIRC SYST MAG, V11, P82, DOI 10.1109/MCAS.2011.941081
   Ambili AR, 2022, 2022 INT C COMP COMM, P1
   Bartley TM, 2023, ICASSP 2023, P1
   Berkling KM, 1994, INT C AC SPEECH SIGN, V1, pI
   Biswas M, 2023, MULTIMED TOOLS APPL, V82, P9565, DOI 10.1007/s11042-021-11439-1
   Ethnologue, About Us
   Garain A, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114416
   Gaur L, 2021, HUM-CENT COMPUT INFO, V11, DOI 10.22967/HCIS.2021.11.024
   Ghozi R., 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P1531
   Griol D, 2013, APPL INTELL, V38, P620, DOI 10.1007/s10489-012-0390-8
   Gupta M, 2017, INT C POW CONTR EMB, P1
   Haldar R., 2016, Int J Recent Innov Trends Comput Commun, V4, P312
   Ijaz MF, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8081325
   Irtza S, 2016, INT CONF ACOUST SPEE, P5820, DOI 10.1109/ICASSP.2016.7472793
   Liu H., 2022, P SPEAK LANG REC WOR, P248, DOI [10.21437/Odyssey.2022-35, DOI 10.21437/ODYSSEY.2022-35]
   Liu HX, 2022, IEEE J-STSP, V16, P1296, DOI 10.1109/JSTSP.2022.3201445
   Liu SH, 2017, ACM T ASIAN LOW-RESO, V16, DOI 10.1145/3099472
   Madhu C, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, INFORMATICS, COMMUNICATION AND ENERGY SYSTEMS (SPICES)
   Manwani N, 2007, LECT NOTES COMPUT SC, V4815, P463
   Masumura R, 2017, INT CONF ACOUST SPEE, P5260, DOI 10.1109/ICASSP.2017.7953160
   Mohanty S., 2011, Int J Comput Appl, V19, P18
   Montalvo A, 2015, LECT NOTES COMPUT SC, V9423, P543, DOI 10.1007/978-3-319-25751-8_65
   Mukherjee Himadri, 2018, 2018 24th International Conference on Pattern Recognition (ICPR), P2654, DOI 10.1109/ICPR.2018.8545406
   Mukherjee H, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420580069
   Mukherjee H, 2020, MULTIMED TOOLS APPL, V79, P34913, DOI 10.1007/s11042-019-08553-6
   Mukherjee H, 2020, LECT NOTES ELECTR EN, V602, P441, DOI 10.1007/978-981-15-0829-5_43
   Mukherjee H, 2020, INT J MACH LEARN CYB, V11, P1, DOI 10.1007/s13042-019-00928-3
   Mukherjee H, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSPC'17), P300, DOI 10.1109/CSPC.2017.8305857
   Nercessian S, 2016, IEEE W SP LANG TECH, P335, DOI 10.1109/SLT.2016.7846286
   Nie YT, 2022, 2022 13TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP), P384, DOI 10.1109/ISCSLP57327.2022.10038152
   Rao KS., 2015, Language identification using spectral and prosodic features, DOI [10.1007/978-3-319-17725-0, DOI 10.1007/978-3-319-17725-0]
   Rebai I, 2017, I C COMP SYST APPLIC, P796, DOI 10.1109/AICCSA.2017.119
   Sadjadi SO, 2015, SPEECH COMMUN, V72, P138, DOI 10.1016/j.specom.2015.04.005
   Sahoo KK, 2021, IEEE ACCESS, V9, P166518, DOI 10.1109/ACCESS.2021.3135658
   Saikia R, 2017, INT CONF ASIAN LANG, P214, DOI 10.1109/IALP.2017.8300582
   Sangeetha J, 2017, APPL INTELL, V46, P534, DOI 10.1007/s10489-016-0846-3
   Shen HP, 2015, ACM T ASIAN LOW-RESO, V14, DOI 10.1145/2661637
   Singer E., 2003, P INTERSPEECH, P1345
   Thukroo Irshad Ahmad, 2021, 2021 7th International Conference on Signal Processing and Communication (ICSC), P250, DOI 10.1109/ICSC53193.2021.9673212
   Thukroo IA, 2022, MULTIMED TOOLS APPL, V81, P32593, DOI 10.1007/s11042-022-13054-0
   Tjandra A, 2022, INT CONF ACOUST SPEE, P6877, DOI 10.1109/ICASSP43922.2022.9747667
   Vuddagiri RK, 2018, EXPERT SYST APPL, V110, P290, DOI 10.1016/j.eswa.2018.06.004
   Wong K, 2004, INT C SPOK LANG PROC, P1633
   Yasmin G, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113575
   Yeh CF, 2015, IEEE-ACM T AUDIO SPE, V23, P1144, DOI 10.1109/TASLP.2015.2425214
   Zissman MA, 2001, SPEECH COMMUN, V35, P115, DOI 10.1016/S0167-6393(00)00099-6
NR 49
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 14
PY 2023
DI 10.1007/s11042-023-17782-9
EA DEC 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU3L5
UT WOS:001155145700006
DA 2024-07-18
ER

PT J
AU Ullah, MS
   Ghosh, R
AF Ullah, Md Shaquib
   Ghosh, Rajib
TI An approach combining convolutional layers and gated recurrent unit to
   recognize human activities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Artificial intelligence; Human activity recognition; Hybrid deep
   learning model; Convolutional recurrent neural network; Inception V3
   Net; Gated recurrent unit
ID HANDWRITTEN WORD RECOGNITION; DEVANAGARI
AB Human activity recognition (HAR) involves the prediction of movement type of a human, based on raw data being captured from wearable sensors or vision based sensors. HAR systems have sapped great interest over the period of time due to its wide applications in the field of healthcare, surveillance and also in the coming generation of metaverse. This article proposes an artificial intelligence (AI) based system using hybrid deep learning model to recognise various human activities from the video footages. The deep convolutional layers and recurrent neural network (RNN) have been combined to generate the hybrid deep learning model known as convolutional recurrent neural network (CRNN). The deep convolutional layers of deep convolutional neural network Inception V3 Net have been used to extract the feature values from the video frames corresponding to each human activity and each generated feature vector has been classified to the appropriate activity class by the gated recurrent unit (GRU) variant of RNN classifier. The performance of the proposed HAR system has been evaluated on the three widely used public datasets-KTH, UCF101, and UCF sports action dataset. GRU variant of RNN classifier is capable to store and remember a long temporal sequence of video frames, generating the pattern of any human activity, over a long duration and so experimental results exhibit that the proposed hybrid deep learning based HAR system outperforms the state-of-the-art methods available in this research domain.
C1 [Ullah, Md Shaquib; Ghosh, Rajib] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Ghosh, R (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, India.
EM rajib.ghosh@nitp.ac.in
RI GHOSH, RAJIB/C-9927-2017
OI GHOSH, RAJIB/0000-0002-8553-8656
CR Baccouche Moez, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, P29, DOI 10.1007/978-3-642-25446-8_4
   Baccouche M, 2010, LECT NOTES COMPUT SC, V6353, P154
   Bondugula RK, 2023, APPL INTELL, V53, P14400, DOI 10.1007/s10489-022-04250-4
   Dalal N., 2005, IEEE C COMP VIS PATT
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Gao LL, 2022, IEEE T MULTIMEDIA, V24, P4493, DOI 10.1109/TMM.2021.3119177
   Gedamu K, 2023, PATTERN RECOGN, V139, DOI 10.1016/j.patcog.2023.109455
   Gedamu K, 2021, PATTERN RECOGN, V118, DOI 10.1016/j.patcog.2021.108043
   Ghosh R, 2022, EXPERT SYST APPL, V205, DOI 10.1016/j.eswa.2022.117730
   Ghosh R, 2022, MULTIMED TOOLS APPL, V81, P38643, DOI 10.1007/s11042-022-13068-8
   Ghosh R, 2019, INT J MACH LEARN CYB, V10, P2467, DOI 10.1007/s13042-018-0883-9
   Ghosh R, 2019, PATTERN RECOGN, V92, P203, DOI 10.1016/j.patcog.2019.03.030
   Ghosh R, 2018, INT CONF FRONT HAND, P517, DOI 10.1109/ICFHR-2018.2018.00096
   Ghosh R, 2018, INT J INF SYST MODEL, V9, P21, DOI 10.4018/IJISMD.2018010102
   Hang R., 2022, P AS C COMP VIS, P1265
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hu LY, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104255
   Ijjina EP, 2016, PATTERN RECOGN, V59, P199, DOI 10.1016/j.patcog.2016.01.012
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Jalal A, 2017, PATTERN RECOGN, V61, P295, DOI 10.1016/j.patcog.2016.08.003
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Ji YL, 2021, PATTERN RECOGN, V113, DOI 10.1016/j.patcog.2020.107807
   Jindal Amar, 2023, International Journal of Information Technology, P1975, DOI 10.1007/s41870-023-01247-1
   Joshi S., 2020, Int J Future Gener Commun Netw, V13, P196
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kuehne H, 2020, IEEE T PATTERN ANAL, V42, P765, DOI 10.1109/TPAMI.2018.2884469
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Li XH, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.103853
   Ma M, 2018, PATTERN RECOGN, V76, P506, DOI 10.1016/j.patcog.2017.11.026
   Majd M, 2020, NEUROCOMPUTING, V396, P224, DOI 10.1016/j.neucom.2018.10.095
   Mliki H, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107140
   Mojarad R, 2018, IEEE INT C INT ROBOT, P5660, DOI 10.1109/IROS.2018.8594173
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Nguyen K, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patog.2020.107358
   Plizzari C, 2021, COMPUT VIS IMAGE UND, V208, DOI 10.1016/j.cviu.2021.103219
   Robertson N, 2006, COMPUT VIS IMAGE UND, V104, P232, DOI 10.1016/j.cviu.2006.07.006
   Sargano AB, 2017, IEEE IJCNN, P463, DOI 10.1109/IJCNN.2017.7965890
   Schuldt Laptev I, 2005, KTH dataset
   Soomro K, 2012, UCF101 dataset
   Soomro K, 2014, UCF sports action dataset
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Ullah A, 2021, APPL SOFT COMPUT, V103, DOI 10.1016/j.asoc.2021.107102
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang ZL, 2017, INFORM FUSION, V37, P1, DOI 10.1016/j.inffus.2017.01.004
   Xiao QK, 2018, MULTIMED TOOLS APPL, V77, P6955, DOI 10.1007/s11042-017-4614-0
   Xu TT, 2016, IMAGE VISION COMPUT, V55, P127, DOI 10.1016/j.imavis.2016.01.001
   Yang H, 2019, PATTERN RECOGN, V85, P1, DOI 10.1016/j.patcog.2018.07.028
   Yu JH, 2022, IEEE T COGN DEV SYST, V14, P1654, DOI 10.1109/TCDS.2021.3131253
   Zhao R, 2017, IEEE INT C INT ROBOT, P4260, DOI 10.1109/IROS.2017.8206288
NR 56
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 12
PY 2023
DI 10.1007/s11042-023-17697-5
EA DEC 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CG2W2
UT WOS:001124043200006
DA 2024-07-18
ER

PT J
AU Fatima, Z
   Rehman, AU
   Hussain, R
   Karim, S
   Shakir, M
   Soomro, KA
   Laghari, AA
AF Fatima, Zaheen
   Rehman, Aqeel Ur
   Hussain, Rashid
   Karim, Shahid
   Shakir, Muhammad
   Soomro, Kashif Ahmed
   Laghari, Asif Ali
TI Mobile crowdsensing with energy efficiency to control road congestion in
   internet cloud of vehicles: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mobile Crowd Sensing; Traffic Congestion; Vehicular Cloud; Internet of
   Vehicles; Energy Efficient
ID THINGS IOT; SIMULATORS; SERVICES; PLATFORM; NETWORK
AB Traveling demand increased rapidly on the roads of big cities. Traffic congestion is observed on a regular basis and causes serious problems for citizens. It is a vital need in larger cities to deal with the problem of overcrowded roads because Traffic congestion has negative consequences on daily routines and activities. All of the factors that cause traffic-jam affect our lives physically, mentally, and economically. It has been observed that one of the factors of the traffic jam is traffic diversion. Traffic diversion reroutes all the traffic towards alternative tracks that causes traffic jams to the diverted road. It has been observed in the past that the researchers less considered traffic congestion due to traffic diversion. There is a need for analysis to determine the risk factor related to traffic diversion that impacts the causes of traffic jams. This paper focuses on proposing an architecture based on the Internet Cloud of Vehicles for traffic congestion control through the mobile crowdsensing technique.
C1 [Fatima, Zaheen; Shakir, Muhammad] Hamdard Univ, Fac Engn Sci & Technol, Dept Comp Engn, Karachi, Pakistan.
   [Rehman, Aqeel Ur] Sohail Univ, Karachi, Pakistan.
   [Hussain, Rashid] Hamdard Univ, Fac Engn Sci & Technol, Dept Elect Engn, Karachi, Pakistan.
   [Karim, Shahid] ILMA Univ, Fac Sci & Technol, Karachi, Pakistan.
   [Karim, Shahid] Northwestern Polytech Univ Shenzhen, Res & Dev Inst, Shenzhen 518057, Peoples R China.
   [Soomro, Kashif Ahmed] Hamdard Univ, Dept Mech Engn, Karachi, Pakistan.
   [Laghari, Asif Ali] Sindh Madressatul Islam Univ, Dept Comp Sci, Karachi, Pakistan.
C3 Hamdard University; Hamdard University; Northwestern Polytechnical
   University; Hamdard University
RP Karim, S (corresponding author), ILMA Univ, Fac Sci & Technol, Karachi, Pakistan.; Karim, S (corresponding author), Northwestern Polytech Univ Shenzhen, Res & Dev Inst, Shenzhen 518057, Peoples R China.
EM shahid@nwpu.edu.cn
RI Hussain, Rashid/KOD-3085-2024; Karim, Shahid/AAO-1087-2020; Laghari,
   Asif Ali/AAF-5893-2020
OI Karim, Shahid/0000-0001-9986-5052; Laghari, Asif Ali/0000-0001-5831-5943
CR Aarika K., 2020, Procedia Computer Science, V175, P591
   Abdelrahman A, 2020, IEEE NETWORK, V34, P216, DOI 10.1109/MNET.001.1900368
   Adedoyin M., 2020, Eng. Technol. Res. J, V5, P25, DOI [10.47545/etrj.2020.5.2.062, DOI 10.47545/ETRJ.2020.5.2.062]
   Aftabuzzaman M., 2007, 30 AUSTRALASIAN TRAN, P1
   Alam T, 2021, IAIC T SUSTAINABLE D, V1, P108, DOI [10.34306/itsdi.v1i2.103, DOI 10.34306/ITSDI.V1I2.103, 10.2139/ssrn.3639063, DOI 10.2139/SSRN.3639063]
   Ali A, 2021, SUSTAIN COMPUT-INFOR, V32, DOI 10.1016/j.suscom.2021.100608
   Ali Hussien N, 2020, Int J Interact Mob Technol (iJIM), V14
   Ali MS, 2014, PROCEDIA ENGINEER, V77, P37, DOI 10.1016/j.proeng.2014.07.030
   Ali N., 2021, J Appl Eng Sci, V19, P125, DOI [10.5937/jaes0-27534, DOI 10.5937/JAES0-27534]
   Alsaawy Y, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12042043
   [Anonymous], 2020, Trans Emerging Tel Techn, V31, P3961
   [Anonymous], 2013, P 2013 ACM C PERV UB, DOI DOI 10.1145/2494091.2499575
   Arain S, 2017, MEHRAN UNIV RES J EN, V36, P139, DOI 10.22581/muet1982.1701.13
   Ayu V, 2021, CS IT C P, V11
   Balan RK, 2014, INT CONF COMMUN SYST
   Baofeng Ji, 2020, IEEE Communications Standards Magazine, V4, P34, DOI 10.1109/MCOMSTD.001.1900053
   Bauza R, 2010, C LOCAL COMPUT NETW, P606, DOI 10.1109/LCN.2010.5735780
   Bhatia Tarandeep Kaur, 2020, 2020 7th International Conference on Signal Processing and Integrated Networks (SPIN), P234, DOI 10.1109/SPIN48934.2020.9070933
   Bhattacharya K., 2021, Int J Res Appl Sci Eng Technol (IJRASET), V9, P289
   Bhatti UA, 2022, SCIENCE, V377, P585, DOI 10.1126/science.add9065
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3059703
   Bhatti UA, 2021, IEEE ACCESS, V9, P41019, DOI 10.1109/ACCESS.2021.3060744
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhoraskar R., 2012, COMMUNICATION SYSTEM, P1
   Bitam S., 2012, GLOBECOM 2012 - 2012 IEEE Global Communications Conference, P2054, DOI 10.1109/GLOCOM.2012.6503418
   Boukerche A, 2017, INT WIREL COMMUN, P159, DOI 10.1109/IWCMC.2017.7986279
   Cakija K., 2021, inTransfor-mation of Transportation, P15
   Cappiello AG, 2019, 2019 INTERNATIONAL SYMPOSIUM ON SIGNALS, CIRCUITS AND SYSTEMS (ISSCS 2019), DOI [10.1109/isscs.2019.8801767, 10.1109/COMST.2019.2914030]
   Chen J, 2023, SPIE, V12609, P364
   Chen YK, 2012, ASIA S PACIF DES AUT, P383, DOI 10.1109/ASPDAC.2012.6164978
   Barbosa FED, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3961
   Dan Yi, 2021, Innovation in Medicine and Healthcare. Proceedings of 9th KES-InMed 2021. Smart Innovation, Systems and Technologies (SIST 242), P101, DOI 10.1007/978-981-16-3013-2_9
   Dandala TT, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATION AND SIGNAL PROCESSING (ICCCSP), P201
   de Souza AM, 2015, CIT/IUCC/DASC/PICOM 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - UBIQUITOUS COMPUTING AND COMMUNICATIONS - DEPENDABLE, AUTONOMIC AND SECURE COMPUTING - PERVASIVE INTELLIGENCE AND COMPUTING, P497, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.71
   Dewi N.K., 2021, INT J ENG MANUFACTUR, V11, P29
   Emara K., 2021, Int J Intell Comput Inf Sci, V21, P95
   Farhan L., 2018, 2018 11 INT S COMMUN
   Firdhous MFM., 2021, Int J Electr Comput Eng (IJECE), V11, P518, DOI [10.11591/ijece.v11i1.pp518-527, DOI 10.11591/IJECE.V11I1.PP518-527]
   Gasmi R, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON NETWORKING AND ADVANCED SYSTEMS (ICNAS 2019), P1, DOI 10.1109/icnas.2019.8807870
   Gerla M, 2014, 2014 IEEE WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P241, DOI 10.1109/WF-IoT.2014.6803166
   Ghose A, 2012, PERVASIVE COMPUTING
   Gong Yikai., 2015, P ACM 1 INT WORKSHOP, P7
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Guidoni DL, 2020, IEEE ACCESS, V8, P45167, DOI 10.1109/ACCESS.2020.2978700
   Handong Zhang, 2011, 2011 IEEE International Conference on Computer Science and Automation Engineering (CSAE), P507, DOI 10.1109/CSAE.2011.5952899
   He W, 2014, IEEE T IND INFORM, V10, P1587, DOI 10.1109/TII.2014.2299233
   Heiskala M, 2016, RES TRANSP BUS MANAG, V18, P38, DOI 10.1016/j.rtbm.2016.03.006
   Hull B., 2006, SENSYS, DOI DOI 10.1145/1182807.1182821
   Hussien N, 2020, Smart shopping system with RFID technology based on internet of things, P17
   Ibáñez JAG, 2015, IEEE WIREL COMMUN, V22, P122
   Kanarachos S, 2018, TRANSPORT RES C-EMER, V95, P867, DOI 10.1016/j.trc.2018.03.023
   Khan UA, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8020204
   Khan WZ, 2013, IEEE COMMUN SURV TUT, V15, P402, DOI 10.1109/SURV.2012.031412.00077
   Khandelwal SA, 2015, 2015 INTERNATIONAL CONFERENCE ON TECHNOLOGY FOR SUSTAINABLE DEVELOPMENT (ICTSD-2015)
   Khanna A, 2020, WIRELESS PERS COMMUN, V114, P1687, DOI 10.1007/s11277-020-07446-4
   Kim H., 2007, A simulation framework for traffic information dissemination in ubiquitous vehicular ad hoc networks
   Kim H, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SERVICES COMPUTING (SCC), P434, DOI 10.1109/SCC.2017.62
   Ksouri C, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.5994
   Laghari AA, 2023, ARCH COMPUT METHOD E, V30, P5105, DOI 10.1007/s11831-023-09985-y
   Lane ND, 2013, P 11 ACM C EMBEDDED, P1
   Lane ND, 2010, IEEE COMMUN MAG, V48, P140, DOI 10.1109/MCOM.2010.5560598
   Li TF, 2022, EURASIP J WIREL COMM, V2022, DOI 10.1186/s13638-022-02106-6
   Li Y, 2022, LECT NOTES COMPUT SC, V13340, P386, DOI 10.1007/978-3-031-06791-4_31
   Liu JX, 2016, ACSR ADV COMPUT, V68, P1, DOI 10.1145/3185504
   Liu Wenyi, 2022, Advances in Artificial Intelligence and Security: 8th International Conference on Artificial Intelligence and Security, ICAIS 2022, Proceedings. Communications in Computer and Information Science (1588), P350, DOI 10.1007/978-3-031-06764-8_28
   Liu W, 2022, INT C ARTIFICIAL INT
   Dongre MM, 2016, Arxiv, DOI arXiv:1605.03393
   Madakam S., 2015, J COMPUT COMMUN, V3, P164, DOI [10.4236/jcc.2015.35021, DOI 10.4236/JCC.2015.35021]
   Mantouka E, 2021, INT J TRANSP SCI TEC, V10, P266, DOI 10.1016/j.ijtst.2020.07.001
   Martin P.T., 2003, DETECTOR TECHNOLOGY
   Martinez FJ, 2011, WIREL COMMUN MOB COM, V11, P813, DOI 10.1002/wcm.859
   Matin F., 2012, KASBIT Business Journal, V5, P25
   Mehmood K., 2013, WIRELESS SENSOR NETW, P14
   Milojevic Milos, 2014, 2014 13th Annual Mediterranean Ad Hoc Networking Workshop (MED-HOC-NET), P203, DOI 10.1109/MedHocNet.2014.6849125
   Nguyen DC, 2022, IEEE INTERNET THINGS, V9, P359, DOI 10.1109/JIOT.2021.3103320
   Nizetic S, 2020, J CLEAN PROD, V274, DOI 10.1016/j.jclepro.2020.122877
   Patil E, 2021, Turk J Comput Math Educ, V12, P1995, DOI 10.17762/turcomat.v12i2.1503
   Pavan Kumar VSVSR., 2016, Int J Sci Eng Technol Res (IJSETR), V5, P2477
   Perera C, 2015, IEEE TRANS COMPUT SO, V2, P171, DOI 10.1109/TCSS.2016.2515844
   Pereral C, 2012, 2012 IEEE 23RD INTERNATIONAL SYMPOSIUM ON PERSONAL INDOOR AND MOBILE RADIO COMMUNICATIONS (PIMRC), P24, DOI 10.1109/PIMRC.2012.6362778
   Podnar Zarko I, 2013, C PERVASIVE UBIQUITO
   Poonia RC, 2018, J INFORM OPTIM SCI, V39, P1583, DOI 10.1080/02522667.2017.1406580
   Raja Kumar K, 2021, DATA ENG COMMUNICATI, P337, DOI [10.1007/978-981-16-0081-4_33/FIGURES/6, DOI 10.1007/978-981-16-0081-4_33/FIGURES/6]
   Ramson SRJ, 2020, PR INT CONF DEVICE C, P92, DOI 10.1109/ICDCS48716.2020.243556
   Ramson SRJ, 2020, 2020 5 INT C DEV CIR
   Raza M, 2020, INT C UK CHINA EMERG, P1
   Reis L. A., 2020, Int. J. Adv. Eng. Res. Sci., V7, P253
   Sadiku M.N., 2018, Int. J. Adv. Res. Comput. Sci. Softw. Eng, V8, P11, DOI [10.23956/ijarcsse.v8i1.512, DOI 10.23956/IJARCSSE.V8I1.512]
   Said O., 2013, International Journal of Computer Networks, V5, P1
   Shah IH., 2016, Acad J Environ Sci, V4, P105
   Sharma MK, 2015, 2015 1ST INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P67, DOI 10.1109/NGCT.2015.7375084
   Sharma S, 2019, VEH COMMUN, V20, DOI 10.1016/j.vehcom.2019.100182
   Singh RP, 2020, DIABETES METAB SYND, V14, P521, DOI 10.1016/j.dsx.2020.04.041
   Srinivasan P., 2021, Ann Romanian Soc Cell Biol, V25, P7834
   Srivastava A, 2021, Mathematics in Engineering, Science & Aerospace, V12, P953
   Stoyanova M, 2020, IEEE COMMUN SURV TUT, V22, P1191, DOI 10.1109/COMST.2019.2962586
   Suma S, 2022, Meas: Sensors, V24
   Syed WH, 2014, PROCEDIA COMPUT SCI, V32, P413, DOI 10.1016/j.procs.2014.05.442
   Tasgaonkar PP, 2020, SENS IMAGING, V21, DOI 10.1007/s11220-020-00295-2
   Tausif M., 2014, J PLATFORM TECHNOLOG, P19
   Thiagarajan A, 2009, SENSYS 09: PROCEEDINGS OF THE 7TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P85
   Thopate K, 2023, Int J Intell Syst Appl Eng, V11, P316
   Vermesan O, 2014, RIVER PUBL SER COMM, P1
   Vershinin Yu A., 2020, 2020 SYSTEMS SIGNALS, P1
   Wan JF, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010088
   Wang S, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P2541, DOI 10.1109/ITSC.2014.6958097
   Xiliang Xiao, 2021, Innovation in Medicine and Healthcare. Proceedings of 9th KES-InMed 2021. Smart Innovation, Systems and Technologies (SIST 242), P75, DOI 10.1007/978-981-16-3013-2_7
   Xu H, 2017, LECT NOTE DATA ENG, V1, P447, DOI 10.1007/978-3-319-49109-7_42
   Xu SY, 2021, WIREL NETW, DOI 10.1007/s11276-021-02638-7
   Yan GJ, 2013, IEEE T INTELL TRANSP, V14, P284, DOI [10.1109/TITS.2012.2211870, 10.1109/MITS.2012.2217571]
   Yan HH, 2017, MOBILE NETW APPL, V22, P1212, DOI 10.1007/s11036-017-0873-2
   Yilmaz Ö, 2021, IEEE ACCESS, V9, P157984, DOI 10.1109/ACCESS.2021.3129932
   Zamora W, 2016, MOB INF SYST, V2016, DOI 10.1155/2016/9681842
   Zeeshan Z, 2021, INTELL DATA ANAL, V25, P1013, DOI 10.3233/IDA-205388
   Zeng C, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03539-5
   Zhang L., 2022, J Adv Math Comput Sci, V37, P21, DOI [10.9734/jamcs/2022/v37i230433, DOI 10.9734/JAMCS/2022/V37I230433]
   Zhang PF, 2021, SCI CHINA INFORM SCI, V64, DOI 10.1007/s11432-019-2891-3
   Zhihong Yang, 2011, 2011 International Conference on Multimedia Technology, P747
NR 119
TC 2
Z9 2
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 28
PY 2023
DI 10.1007/s11042-023-17611-z
EA NOV 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY2E0
UT WOS:001142422400001
DA 2024-07-18
ER

PT J
AU Agarwal, D
   Singh, V
   Singh, AK
   Madan, P
AF Agarwal, Divya
   Singh, Vijay
   Singh, Ashwini Kumar
   Madan, Parul
TI Stacked ensemble model for analyzing mental health disorder from social
   media data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mental health disorder; Social media; Improved semantic similarity;
   Improved CNN; Optimization
AB Mental health issues are detrimental to quality of life and frequently increase the dangers of mental disease like suicidal thoughts, depression, and many are frequently misdiagnosed and remain untreated. Accurate diagnosis of indicators of mental health disorders is especially crucial because they may be life-threatening when left untreated. Therefore, it is essential to have a thorough understanding of the sources to recognize a person's mental illness. Social media is the major source of identifying individual mental diseases, and hence their needs a sophisticated analysis from several angles to prevent death. On the other hand, researchers are examining whether computer methods could track the communication on social networks, which might help in the early identification of mental health issues. This paper creates a new system for analyzing mental health disorders via social media data that avoids the problem from becoming serious. Preprocessing, feature extraction, and classification are the three steps of this approach. First, stemming and stop word removal will be processed as the preprocessing step of input text. From the preprocessed text, Improved Semantic Similarity features, content features, BoVW, features like n-grams, LIWC features, and are extracted. The ensemble classifier, which includes the classifiers from the Bidirectional Gated Recurrent Unit (Bi-GRU), Deep Maxout, and Improved Convolution Neural Network (ICNN), performs a categorization using the extracted characteristics. Also, to improve the efficiency of classification, a training model is introduced in the ICNN termed as self-adaptive Shuffled shepherd optimization method (SASSOA) that tunes the optimal weights. Finally, the efficacy of the projected method is verified to the convolutional procedures.
C1 [Agarwal, Divya; Singh, Vijay; Singh, Ashwini Kumar; Madan, Parul] Graph Era Deemed Be Univ, Dept Comp Sci & Engn, 566-6 Bell Rd, Dehra Dun 248002, Uttarakhand, India.
C3 Graphic Era University
RP Singh, V (corresponding author), Graph Era Deemed Be Univ, Dept Comp Sci & Engn, 566-6 Bell Rd, Dehra Dun 248002, Uttarakhand, India.
EM vijaysingh_agra@hotmail.com
OI Singh, Ashwini Kumar/0000-0002-5346-412X; Agarwal,
   Divya/0009-0007-1374-3275
CR Abiddine Fares Zine El, 2022, Sleep Epidemiol, V2, P100030, DOI 10.1016/j.sleepe.2022.100030
   Azhari A, 2022, ACTA PSYCHOL, V229, DOI 10.1016/j.actpsy.2022.103706
   Basabi Chakraborty, 2019, Multimedia Res, V2, P37
   Beeres DT, 2021, J ADOLESCENT HEALTH, V68, P953, DOI 10.1016/j.jadohealth.2020.07.042
   Boer M, 2021, COMPUT HUM BEHAV, V116, DOI 10.1016/j.chb.2020.106645
   Boniel-Nissim M, 2022, COMPUT HUM BEHAV, V129, DOI 10.1016/j.chb.2021.107144
   Chandanapalli S.B., 2019, Journal of Networking and Communication Systems, V2, P40, DOI DOI 10.46253/JNACS.V2I3.A5
   Cleofas JV, 2022, ARCH PSYCHIAT NURS, V40, P97, DOI 10.1016/j.apnu.2022.06.003
   Dewangan DK, 2023, MULTIMED TOOLS APPL, V82, P7293, DOI 10.1007/s11042-022-13425-7
   Dewangan DK, 2022, INT J PATTERN RECOGN, V36, DOI 10.1142/S0218001422520024
   Goodfellow I., 2013, P 30 INT C MACH LEAR, P1319
   Hattingh M, 2022, TECHNOL FORECAST SOC, V185, DOI 10.1016/j.techfore.2022.122099
   Hidayatullah AF, 2017, J PHYS CONF SER, V801, DOI 10.1088/1742-6596/801/1/012072
   Jia GZ, 2022, COMPR PSYCHIAT, V116, DOI 10.1016/j.comppsych.2022.152328
   Joshi D, 2020, COMPUT HUM BEHAV REP, V2, DOI 10.1016/j.chbr.2020.100036
   Kaveh A, 2022, ENG COMPUT-GERMANY, V38, P1505, DOI 10.1007/s00366-021-01292-z
   Kim J, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-68764-y
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Lee DS, 2021, BRAIN BEHAV IMMUN-HL, V16, DOI 10.1016/j.bbih.2021.100300
   Lee ERS, 2022, IEEE ACCESS, V10, P9717, DOI 10.1109/ACCESS.2022.3144266
   Liang LL, 2022, ARCH PSYCHIAT NURS, V40, P8, DOI 10.1016/j.apnu.2022.03.007
   Liu JF, 2022, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.802821
   Mann RB, 2022, ACTA PSYCHOL, V228, DOI 10.1016/j.actpsy.2022.103629
   Mhd Furqan, 2017, IOSR J Comput Eng (IOSR-JCE), V19, P31
   Nasrullah S, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/9404242
   Precht L-M, 2022, J Affect Disord Rep, V8
   Rao T.C.S., 2019, Journal of Computational Mechanics, Power System, and Control, V2, P39, DOI DOI 10.46253/JCMPS.V2I3.A5
   Ríssola EA, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.102890
   Roberts SR, 2022, BODY IMAGE, V41, P239, DOI 10.1016/j.bodyim.2022.03.002
   Sanchez C, 2020, COMPR PSYCHIAT, V103, DOI 10.1016/j.comppsych.2020.152197
   Sharma A., 2022, International Journal of Information Management Data Insights, V2, P100057, DOI [DOI 10.1016/J.JJIMEI.2022.100057, 10.1016/j.jjimei.2022.100057]
   Stanculescu E, 2022, TELEMAT INFORM, V74, DOI 10.1016/j.tele.2022.101879
   Stieger S, 2022, BODY IMAGE, V43, P232, DOI 10.1016/j.bodyim.2022.09.009
   Tyagi T, 2022, Clin Epidemiol Global Health, V17
   Uban AS, 2021, FUTURE GENER COMP SY, V124, P480, DOI 10.1016/j.future.2021.05.032
   Wartberg L, 2021, COMPUT HUM BEHAV, V121, DOI 10.1016/j.chb.2021.106788
   Wheatley C, 2021, MENT HEALTH PHYS ACT, V21, DOI 10.1016/j.mhpa.2021.100429
   Zhao D, 2019, J BIOMED INFORM, V99, DOI 10.1016/j.jbi.2019.103295
   Zhao L, 2021, COMPUT HUM BEHAV REP, V4, DOI 10.1016/j.chbr.2021.100122
   Zhong B, 2021, COMPUT HUM BEHAV, V114, DOI 10.1016/j.chb.2020.106524
NR 40
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 27
PY 2023
DI 10.1007/s11042-023-17395-2
EA NOV 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AW8T3
UT WOS:001121585200002
DA 2024-07-18
ER

PT J
AU Bindhya, PS
   Chitra, R
   Raj, VSB
AF Bindhya, P. S.
   Chitra, R.
   Raj, V. S. Bibin
TI Microaneurysms detection using fundus images based on deep convolutional
   neural network enabled fractional hunter osprey optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fractional Calculus (FC); Bayesian U-Net; Hunter-Prey Optimizer (HPO);
   Osprey Optimization Algorithm (OOA); Adaptive wiener filter
ID DIABETIC-RETINOPATHY; DIAGNOSIS; PATTERN
AB Diabetic Retinopathy (DR) is one of the foremost reasons for poor eyesight in the modern globe. An earlier detection of DR is vital in offering effectual treatment. Moreover, detecting the severity levels of DR, such as Microaneurysms (MA), Hemorrhages (HMs), Exudates (EXs) and extra development of blood vessel recognition using fundus images are challenging chores owing to the complex structures and shapes of lesions in the fundus image. This paper aims to develop a technique for DR detection at an early stage. MA is the first symptom of DR that leads to blood leakage in the retina. Here, Fractional Hunter Osprey Optimization-Deep Convolutional Neural Network (FHOO-DCNN) is introduced for MA detection. An input image pre-processing is executed by an adaptive wiener filter and then, optic disc (OD) detection is accomplished. The Bayesian U-Net is used for OD detection, which is tuned by Hunter Osprey Optimization (HOO). The HOO is modelled by combining Hunter-Prey Optimizer (HPO) with the Osprey Optimization Algorithm (OOA). Blood vessel segmentation is conducted utilizing morphological Top-Hat transform. Thereafter, features from the input image, blood vessel segmented image, and OD-detected image are extracted. At last, MA detection is performed by DCNN that is tuned using FHOO. Furthermore, FHOO is joining of Fractional Calculus (FC) concept with HOO. In addition, FHOO-DCNN has acquired high accuracy, sensitivity and specificity of 91.1%, 91.2% and 90.4%. The proposed method is applicable in primary screening and regular clinical work for the monitoring of the progression of DR.
C1 [Bindhya, P. S.] Noorul Islam Ctr Higher Educ, Dept Comp Sci & Engn, Thuckalay 629180, Tamil Nadu, India.
   [Chitra, R.] Karunya Inst Technol & Sci, Dept Comp Sci & Engn, Coimbatore 641114, Tamil Nadu, India.
   [Raj, V. S. Bibin] Kattaikonam A P J Abdul Kalam Technol Univ, St Thomas Inst Sci & Technol, Dept Elect & Elect Engn, Thiruvananthapuram 695584, Kerala, India.
C3 Karunya Institute of Technology & Sciences
RP Bindhya, PS (corresponding author), Noorul Islam Ctr Higher Educ, Dept Comp Sci & Engn, Thuckalay 629180, Tamil Nadu, India.
EM bindhya.cs@stisttvm.edu.in
FU I would like to express my very great appreciation to the co-authors of
   this manuscript for their valuable and constructive suggestions during
   the planning and development of this research work.
FX I would like to express my very great appreciation to the co-authors of
   this manuscript for their valuable and constructive suggestions during
   the planning and development of this research work.
CR Abbas Q, 2017, MED BIOL ENG COMPUT, V55, P1959, DOI 10.1007/s11517-017-1638-6
   Al Rasyid MB, 2018, 2018 1ST INTERNATIONAL ECTI NORTHERN SECTION CONFERENCE ON ELECTRICAL, ELECTRONICS, COMPUTER AND TELECOMMUNICATIONS ENGINEERING (ECTI-NCON, P120, DOI 10.1109/ECTI-NCON.2018.8378294
   AlBalushi FM., 2020, Multimed. Res, V3, P20, DOI 10.46253/j.mr.v3i2.a3
   Alsattar HA, 2020, ARTIF INTELL REV, V53, P2237, DOI 10.1007/s10462-019-09732-5
   Asia AO, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11172740
   Bachrach Y, 2017, arXiv, DOI DOI 10.48550/ARXIV.1707.01378
   Bhaladhare PR., 2014, Adv Comput Eng, V2014, P1, DOI [DOI 10.1155/2014/396529, 10.1155/2014/396529]
   Butt MM, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12071607
   Chakraborti T, 2018, IEEE SIGNAL PROC LET, V25, P635, DOI 10.1109/LSP.2018.2817176
   Dehghani M, 2023, FRONT MECH ENG-SWITZ, V8, DOI 10.3389/fmech.2022.1126450
   Deng LZ, 2022, IEEE T AERO ELEC SYS, V58, P962, DOI 10.1109/TAES.2021.3117085
   Dutta Anirban, 2021, Research on Biomedical Engineering, P641, DOI 10.1007/s42600-021-00177-w
   Gandomi AH, 2013, ENG COMPUT-GERMANY, V29, P17, DOI 10.1007/s00366-011-0241-y
   Hung TY, 2014, IEEE IMAGE PROC, P239, DOI 10.1109/ICIP.2014.7025047
   Hutchinson A, 2000, DIABETIC MED, V17, P495, DOI 10.1046/j.1464-5491.2000.00250.x
   IDRiD, ABOUT US
   Islam MR, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105602
   Kaushik H, 2021, IEEE ACCESS, V9, P108276, DOI 10.1109/ACCESS.2021.3101142
   Kayadibi H, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/758634
   Lala H, 2017, Int J Eng Res Technol, V4, P1682
   Abdulhamid IMA, 2020, BIOMED RES INT, V2020, DOI 10.1155/2020/5345923
   Nair A.T., 2019, Multi Res, V2, P43
   Naruei I, 2022, SOFT COMPUT, V26, P1279, DOI 10.1007/s00500-021-06401-0
   Qureshi I, 2021, MULTIMED TOOLS APPL, V80, P11691, DOI 10.1007/s11042-020-10238-4
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Tan JH, 2017, INFORM SCIENCES, V420, P66, DOI 10.1016/j.ins.2017.08.050
   Vijayan T, 2023, IETE J RES, V69, P987, DOI 10.1080/03772063.2020.1844082
   Wang SQ, 2021, IEEE T AUTOM SCI ENG, V18, P574, DOI 10.1109/TASE.2020.2981637
   Wu F, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9101634
   Xiong H, 2022, ARTIF INTELL MED, V126, DOI 10.1016/j.artmed.2022.102261
   Xu YF, 2021, BIOMED RES INT, V2021, DOI 10.1155/2021/6644071
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhou L, 2018, IET IMAGE PROCESS, V12, P563, DOI 10.1049/iet-ipr.2017.0636
NR 33
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 11
PY 2023
DI 10.1007/s11042-023-17350-1
EA NOV 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y0ZQ9
UT WOS:001102641900003
DA 2024-07-18
ER

PT J
AU Samanta, S
   Ajij, M
   Chatterji, S
   Pratihar, S
AF Samanta, Sourav
   Ajij, Md.
   Chatterji, Sanjay
   Pratihar, Sanjoy
TI Fast and robust monitoring of broken rice kernels in the course of
   milling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Estimation of rice quality; Rice grading; Separation of attached rice
   kernels
ID POLYGONAL-APPROXIMATION; IMAGE-ANALYSIS; QUALITY; CLASSIFICATION;
   SEGMENTATION; STRAIGHTNESS; ALGORITHM; CURVES
AB Rice milling industries are seen in large numbers in the eastern and southern parts of India. Like the other industries, this is also going through changes because of the introduction of automation using machine vision technologies. In the consumer market, buyers consider that a good quality rice bag must not contain broken kernels. Considering this commercial aspect, during rice production, the estimation of broken rice kernels mixed with whole rice kernels is an essential grading task in the husking mills. In this paper, we propose a method for monitoring the presence of broken rice kernels in the rice outputs during milling. In our proposed method, duringmilling, rice kernel samples are captured, and image understanding-based processing is applied to realize broken and whole rice kernels. A whole-grain kernel is distinguishable from a broken-grain kernel in terms of its size, perimeter length, etc. Butmany times, several kernels get attached to one another during image capturing. These attached kernel groups need to be separated into single kernels so that the shape and size information of kernels may be used to estimate the amount of presence of broken rice kernels. Hence, the proposed method works in two stages. In the first stage, attached rice kernels are accurately separated using geometric analysis of the boundary edges of the attached kernel groups, and then, in the second stage, all individual kernels are clustered into either broken or whole kernel categories based on their shape and size information. The proposed method identifies the broken kernels with accuracy of 98.25%, 96.54%, and 98.52% for Shamashri, Lalswarno, and Basmati rice kernel respectively. Finally, we present statistics of the estimation depicting the percentage of broken and whole rice grains in the sample images. Our test results indicate the effectiveness and applicability of the proposed method.
C1 [Samanta, Sourav; Chatterji, Sanjay; Pratihar, Sanjoy] Indian Inst Informat Technol Kalyani, Dept Comp Sci & Engn, Kalyani 741235, India.
   [Ajij, Md.] Natl Inst Technol Meghalaya, Dept Comp Sci & Engn, Shillong, Meghalaya, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Meghalaya
RP Pratihar, S (corresponding author), Indian Inst Informat Technol Kalyani, Dept Comp Sci & Engn, Kalyani 741235, India.
EM sourav.uit@gmail.com; mdajij@nitm.ac.in; sanjayc@iiitkalyani.ac.in;
   sanjoy.pratihar@gmail.com
RI Samanta, Sourav/C-4619-2018; Pratihar, Sanjoy/K-8029-2017; Pratihar,
   Sanjoy/Q-3547-2016
OI Pratihar, Sanjoy/0000-0002-0833-6989
CR Aghayeghazvini H, 2009, INT FED INFO PROC, V295, P1019
   Al Ohali Y, 2011, J KING SAUD UNIV-COM, V23, P29, DOI 10.1016/j.jksuci.2010.03.003
   Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   Asif MJ, 2018, 2018 INTERNATIONAL SYMPOSIUM ON RECENT ADVANCES IN ELECTRICAL ENGINEERING (IEEE RAEE)
   Bhowmick P, 2007, IEEE T PATTERN ANAL, V29, P1590, DOI 10.1109/TPAMI.2007.1082
   Chen TC, 2001, REAL-TIME IMAGING, V7, P473, DOI 10.1006/rtim.2001.0233
   Chen XA, 2012, COMM COM INF SC, V307, P104
   Chibbar RN, 2012, QUAL ASSUR SAF CROP, V4, P116, DOI 10.1111/j.1757-837X.2012.00134.x
   Devi TG, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON POWER, CONTROL, SIGNALS AND INSTRUMENTATION ENGINEERING (ICPCSI), P1052, DOI 10.1109/ICPCSI.2017.8391871
   Fatima Maryam, 2022, Comput Intell Neurosci, V2022, P1339469, DOI 10.1155/2022/1339469
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Gujjar HS, 2013, INT J ENG RES APPL, V3, P268
   Guzman JD., 2014, Proceedings of the world conference on agricultural information and IT, V90, P41
   Habib G, J King Saud Univ-Comput Inf Sci
   Javaid M., 2022, Int. J. Intell. Netw, V3, P150, DOI DOI 10.1016/J.IJIN.2022.09.004
   Kleawphaipan T, 2019, J PHYS CONF SER, V1380, DOI 10.1088/1742-6596/1380/1/012076
   Klette R., 2004, DIGITAL GEOMETRY GEO
   Koklu M, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106285
   Kuo TY, 2016, COMPUT ELECTRON AGR, V127, P716, DOI 10.1016/j.compag.2016.07.020
   Lin P, 2014, COMPUT ELECTRON AGR, V109, P124, DOI 10.1016/j.compag.2014.09.015
   Liu JP, 2016, INT J COMPUT INT SYS, V9, P120, DOI 10.1080/18756891.2016.1144158
   Loftus J., 2014, IFAC Proc, V47, P10610
   Lu L, 2021, SENSOR ACTUAT B-CHEM, V329, DOI 10.1016/j.snb.2020.129254
   Momin MA., 2011, Inf Process Agricult, V4, P150
   Ngampak D, 2015, INT CONF KNOWL SMART, P115, DOI 10.1109/KST.2015.7051471
   Payman SH, 2018, QUAL ASSUR SAF CROP, V10, P103, DOI 10.3920/QAS2017.1109
   Pothen Z, 2016, IFAC PAPERSONLINE, V49, P72, DOI 10.1016/j.ifacol.2016.10.014
   Pratihar S, 2016, INT J IMAGE GRAPH, V16, DOI 10.1142/S0219467816500078
   ROSENFELD A, 1974, IEEE T COMPUT, VC 23, P1264, DOI 10.1109/T-C.1974.223845
   Rosenfeld A., 2001, Theor Comput Sci, V46, P1
   ROSIN PL, 1995, IEEE T PATTERN ANAL, V17, P1140, DOI 10.1109/34.476507
   Rosin PL, 1988, P ALV VIS C MANCH, P1
   Sakai N, 1996, J FOOD ENG, V27, P397, DOI 10.1016/0260-8774(95)00022-4
   Singh CB, 2010, COMPUT ELECTRON AGR, V73, P118, DOI 10.1016/j.compag.2010.06.001
   Son NH, 2019, 2019 INT C ADV COMP
   Sunoj S, 2018, POSTHARVEST BIOL TEC, V138, P19, DOI 10.1016/j.postharvbio.2017.12.006
   Tin MM, 2019, ADV INTELL SYST, V744, P324, DOI 10.1007/978-981-13-0869-7_36
   Verma B, 2010, P INT C COMP COMM TE, P220
   Visen NS, 2001, J AGR ENG RES, V79, P159, DOI 10.1006/jaer.2000.0690
   VOSS K, 1991, COMPUT ARTIF INTELL, V10, P75
   WALL K, 1984, COMPUT VISION GRAPH, V28, P220, DOI 10.1016/S0734-189X(84)80023-7
   Wang L, 2015, FOOD ANAL METHOD, V8, P515, DOI 10.1007/s12161-014-9916-5
   Wang YC, 2004, T ASAE, V47, P1803, DOI 10.13031/2013.17597
   Wu Y, 2018, 2018 IEEE INT C INF
   Yadav BK, 2001, COMPUT ELECTRON AGR, V33, P19, DOI 10.1016/S0168-1699(01)00169-7
   Yu LJ, 2021, CROP J, V9, P42, DOI 10.1016/j.cj.2020.06.009
NR 46
TC 0
Z9 0
U1 7
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 11
PY 2023
DI 10.1007/s11042-023-17455-7
EA NOV 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y0ZQ9
UT WOS:001102641900002
DA 2024-07-18
ER

PT J
AU Shen, J
   Liao, HS
   Zheng, L
AF Shen, Jie
   Liao, Hengsong
   Zheng, Li
TI A lightweight method for small scale traffic sign detection based on
   YOLOv4-Tiny
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lightweight models; Small targets; Traffic sign detection; YOLOv4-Tiny
AB Automatic driving requires real-time consideration for traffic sign target detection algorithms while ensuring the accuracy. However, the current one-stage target detection algorithm mainly used for real-time detection is not focused on the characteristics of traffic signs, and the relevant research is insufficient. Aiming at this problem and ensure the accuracy of light-weight network in traffic sign detection task, an improved lightweight traffic sign recognition algorithm based on YOLOv4-Tiny was proposed, with improved backbone feature extraction and detection head using CBAM attention mechanism and depth-wise separable convolution, known as CDYOLO. Based on CDYOLO, we further proposed CDYOLO-SP, which can perform well in complex multi-category detection tasks. In terms of training methods, we adopt the transfer learning mode of "CCTSDB + TT100K" to improve performance. Compared with the original YOLOv4-Tiny, the improved algorithm has achieved better results. In the CCTSDB three-classification task, the mAP of CDYOLO improved by 6.52% and FPS maintained at about 82.5 FPS. The model size is only 4.1 MB. In the TT100K complex multi-classification task, the mAP of CDYOLO-SP improved by 48.59% and FPS maintained at about 60.2 FPS, and the model size is only 10.0 MB. Furthermore, the experiments show that compared with different CNN-based methods our methods outperforms them significantly. In summary, the improved model can meet the accuracy and real-time requirements of traffic sign detection and can be deployed on low-performance devices.
C1 [Shen, Jie; Zheng, Li] Wuhan Univ, Sch Geodesy & Geomat, Wuhan 430079, Peoples R China.
   [Liao, Hengsong] Yunnan Acad Agr Sci, Inst Agr Econ & Informat, Kunming 630000, Peoples R China.
C3 Wuhan University; Yunnan Academy of Agricultural Sciences
RP Zheng, L (corresponding author), Wuhan Univ, Sch Geodesy & Geomat, Wuhan 430079, Peoples R China.
EM Jieshen@whu.edu.cn; butter_cat@whu.edu.cn; lzheng@sgg.whu.edu.cn
FU National Natural Science Foundation of China [42071412]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 42071412
CR Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Chen LJ, 2023, ENG STRUCT, V275, DOI 10.1016/j.engstruct.2022.115291
   Chen WX, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/3749635
   Dai JF, 2016, ADV NEUR IN, V29
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Ding P, 2023, J REAL-TIME IMAGE PR, V20, DOI 10.1007/s11554-023-01263-1
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   He L., 2023, Wirel. Commun. Mob. Comput, V2023, P2520933, DOI [10.1155/2023/2520933, DOI 10.1155/2023/2520933]
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu LN, 2021, ICAART: PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE - VOL 2, P151, DOI 10.5220/0010234401510158
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jiang K, 2021, IEEE T IMAGE PROCESS, V30, P7404, DOI 10.1109/TIP.2021.3102504
   Jiang K, 2022, IEEE T NEUR NET LEAR, V33, P378, DOI 10.1109/TNNLS.2020.3027849
   Jiang K, 2020, IEEE T MULTIMEDIA, V22, P2734, DOI 10.1109/TMM.2019.2960586
   Jiang K, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111700
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li JQ, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13074402
   [李旭东 Li Xudong], 2020, [计算机研究与发展, Journal of Computer Research and Development], V57, P1022
   Li ZS, 2022, INT CONF ACOUST SPEE, P2235, DOI 10.1109/ICASSP43922.2022.9747406
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lv P., 2021, J Commun, V42, P190
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Spring R, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P445, DOI 10.1145/3097983.3098035
   Termritthikun C, 2023, MULTIMED TOOLS APPL, V82, P23917, DOI 10.1007/s11042-022-14187-y
   Springenberg JT, 2015, Arxiv, DOI [arXiv:1412.6806, DOI 10.48550/ARXIV.1412.6806]
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu YH, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23052522
   Xiao Y, 2024, IEEE T CIRC SYST VID, V34, P2789, DOI 10.1109/TCSVT.2023.3312321
   Xiao Y, 2023, IEEE T GEOSCI REMOTE, V61, DOI 10.1109/TGRS.2023.3291822
   Xiao Y, 2023, INFORM FUSION, V96, P297, DOI 10.1016/j.inffus.2023.03.021
   Xiao Y, 2022, INT J APPL EARTH OBS, V108, DOI 10.1016/j.jag.2022.102731
   Xiao Y, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3107352
   Yao ZX, 2021, P I MECH ENG D-J AUT, V235, P1978, DOI 10.1177/0954407020980559
   Yurtsever E, 2020, IEEE ACCESS, V8, P58443, DOI 10.1109/ACCESS.2020.2983149
   Zhang JL, 2023, FRONT MAR SCI, V9, DOI 10.3389/fmars.2022.1058401
   Zhang JM, 2017, ALGORITHMS, V10, DOI 10.3390/a10040127
   Zhang S, 2023, MULTIMED TOOLS APPL, V82, P26063, DOI 10.1007/s11042-023-14342-z
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhu YZ, 2022, MULTIMED TOOLS APPL, V81, P17779, DOI 10.1007/s11042-022-12163-0
   Zhu Z, 2016, PROC CVPR IEEE, P2110, DOI 10.1109/CVPR.2016.232
NR 56
TC 0
Z9 0
U1 9
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 10
PY 2023
DI 10.1007/s11042-023-17146-3
EA NOV 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9QP0
UT WOS:001101716100003
DA 2024-07-18
ER

PT J
AU Asghar, HA
   Khan, B
   Zafar, Z
   Sabri, AQM
   Fraz, MM
AF Asghar, Hasan Ali
   Khan, Bostan
   Zafar, Zuhair
   Sabri, Aznul Qalid Md
   Fraz, Muhammad Moazam
TI PakVehicle-ReID: a multi-perspective benchmark for vehicle
   re-identification in unconstrained urban road environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Vehicle re-identification; Intelligent transportation system; Vehicle
   public datasets
ID SIMILARITY
AB The challenge of re-identifying vehicles in urban city surveillance systems and major traffic arteries such as highways and roads is an important area of research. The advent of large-scale benchmarks such as VeRI-776 and Vehicle-ID has propelled efforts to enhance search operations from large databases for re-identification. However, several unresolved challenges associated with vehicle re-identification in unconstrained environments remain to be explored. In order to foster research in this field, we have compiled a new multi-perspective dataset, PAKVehicle-ReId, captured by real-world surveillance cameras in urban cities of the developing country of Pakistan. To the best of our knowledge, this is the first such dataset collected under unconstrained conditions in a developing Asian region. The dataset comprises 80,000 images of 20,000 unique vehicles. Additionally, a deep learning-based technique for extracting multi-dimensional robust features for vehicle re-identification using convolutional neural networks has been proposed. The results show the effectiveness of the proposed method on the PAKVehicle-ReId dataset as well as on two other existing datasets, VeRI-776 and VehicleID. The code and link to the dataset can be obtained from the following GitHub repository: https://github.com/Vision-At-SEECS/PakvehicleReId.
C1 [Asghar, Hasan Ali; Khan, Bostan; Zafar, Zuhair; Fraz, Muhammad Moazam] Natl Univ Sci & Technol NUST, Islamabad, Pakistan.
   [Sabri, Aznul Qalid Md] Univ Malaya, Fac Comp Sci, Kuala Lumpur, Malaysia.
C3 National University of Sciences & Technology - Pakistan; Universiti
   Malaya
RP Fraz, MM (corresponding author), Natl Univ Sci & Technol NUST, Islamabad, Pakistan.
EM hasghar.mscs19seecs@seecs.edu.pk; bkhan.mscs19seecs@seecs.edu.pk;
   zuhair.zafar@seecs.edu.pk; aznulqalid@um.edu.my;
   moazam.fraz@seecs.edu.pk
RI MD SABRI, AZNUL QALID/AGY-6106-2022
OI MD SABRI, AZNUL QALID/0000-0002-4758-5400; Fraz, Muhammad
   Moazam/0000-0003-0495-463X
CR Alfasly S, 2019, IEEE ACCESS, V7, P162605, DOI 10.1109/ACCESS.2019.2948965
   Bashir RMS, 2019, PATTERN RECOGN, V90, P52, DOI 10.1016/j.patcog.2019.01.008
   Bashir RMS, 2018, LECT NOTES COMPUT SC, V11241, P286, DOI 10.1007/978-3-030-03801-4_26
   Butt MA, 2022, SIGNAL PROCESS-IMAGE, V104, DOI 10.1016/j.image.2022.116667
   Chen DP, 2015, PROC CVPR IEEE, P1565, DOI 10.1109/CVPR.2015.7298764
   Chung D, 2017, IEEE I CONF COMP VIS, P1992, DOI 10.1109/ICCV.2017.218
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Guo HY, 2018, AAAI CONF ARTIF INTE, P6853
   Huynh SV, 2021, IEEE COMPUT SOC CONF, P4142, DOI 10.1109/CVPRW53098.2021.00468
   Liu HY, 2016, PROC CVPR IEEE, P2167, DOI 10.1109/CVPR.2016.238
   Liu XC, 2016, LECT NOTES COMPUT SC, V9906, P869, DOI 10.1007/978-3-319-46475-6_53
   Lou YH, 2019, PROC CVPR IEEE, P3230, DOI 10.1109/CVPR.2019.00335
   Luo H, 2021, IEEE COMPUT SOC CONF, P4090, DOI 10.1109/CVPRW53098.2021.00462
   Ma X, 2021, ICC 2021 IEEE INT C
   Moral P, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-14511-0
   Peng JJ, 2020, NEUROCOMPUTING, V401, P133, DOI 10.1016/j.neucom.2020.02.112
   Rasib M, 2021, IEEE ACCESS, V9, P167855, DOI 10.1109/ACCESS.2021.3134889
   Shankar A., 2019, CVPR WORKSH, V2, P6
   Shen YT, 2017, IEEE I CONF COMP VIS, P1918, DOI 10.1109/ICCV.2017.210
   Taufique AMN, 2021, NEUROCOMPUTING, V463, P122, DOI 10.1016/j.neucom.2021.07.082
   Wang XL, 2017, PROC CVPR IEEE, P3039, DOI 10.1109/CVPR.2017.324
   Yan K, 2017, IEEE I CONF COMP VIS, P562, DOI 10.1109/ICCV.2017.68
   Yang KS, 2021, IEEE COMPUT SOC CONF, P3978, DOI 10.1109/CVPRW53098.2021.00449
   Zahra A, 2023, PATTERN RECOGN, V142, DOI 10.1016/j.patcog.2023.109669
   Zhang C, 2022, APPL INTELL, V52, P14799, DOI 10.1007/s10489-022-03349-y
   Zhang F, 2023, Multimedia Tools Appl, P1
   Zhang FK, 2021, APPL INTELL, V51, P5665, DOI 10.1007/s10489-020-02171-8
   Zhang RM, 2015, IEEE T IMAGE PROCESS, V24, P4766, DOI 10.1109/TIP.2015.2467315
   Zhu JQ, 2018, IEEE ACCESS, V6, P43724, DOI 10.1109/ACCESS.2018.2862382
   Zhu JQ, 2018, IEEE T CIRC SYST VID, V28, P3183, DOI 10.1109/TCSVT.2017.2734740
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 32
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 9
PY 2023
DI 10.1007/s11042-023-17070-6
EA NOV 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9MX6
UT WOS:001101620700009
DA 2024-07-18
ER

PT J
AU Boudjema, A
   Titouna, F
   Titouna, C
AF Boudjema, Ali
   Titouna, Faiza
   Titouna, Chafiq
TI AReNet: Cascade learning of multibranch convolutional neural networks
   for human activity recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Convolutional neural network; Fusion operator; Human activity
   recognition; Time series classification; Wearable sensors
AB Human Activity Recognition (HAR) has become a crucial area of research, driven by the advancements in wearable device sensors. HAR finds widespread applications, including elderly monitoring, security, and human-computer interaction. However, the nature of sensor-based HAR with time series data poses significant challenges in extracting relevant features, which hampers conventional methods' effectiveness, raises a substantial allocation of resources, and prolonged convergence time. researchers have proposed several techniques to solve time series classifiaciton. Deep Learning (DL) models are the most powerful and promising in terms of classification performance. Despite this, they also present challenges in the areas of hyperparameter tuning, training, and the decision models' complexity. This paper proposes AReNet, a light deep learning model for HAR that is composed of two main parts. The first involves a deep neural network architecture integrating 1D CNN blocks, and a fusion operator that aggregates convolution outputs at multiple levels. The second component employs a progressive cascade training during the learning process. This strategic approach reduces the parameters number and minimizes the training time, contributing to a more efficient and simpler model. AReNet achieves remarkable performances in accurately recognizing human activities when experimental analysis is conducted on five publicly available benchmark datasets.
C1 [Boudjema, Ali; Titouna, Faiza] Univ Batna2, LaSTIC Lab Comp Sci, Batna, Algeria.
   [Titouna, Chafiq] Univ Gustave Eiffel, LIGM, ESIEE, Champs Sur Marne, France.
C3 Universite Gustave-Eiffel; ESIEE Paris; Ecole des Ponts ParisTech
RP Boudjema, A (corresponding author), Univ Batna2, LaSTIC Lab Comp Sci, Batna, Algeria.
EM a.boudjema@univ-batna2.dz; f.titouna@univ-batna2.dz;
   chafiq.titouna@esiee.fr
CR Ai DH, 2023, ENG APPL ARTIF INTEL, V117, DOI 10.1016/j.engappai.2022.105478
   Akter M, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23125715
   Al-qaness MAA, 2022, BIOSENSORS-BASEL, V12, DOI 10.3390/bios12100821
   Al-qaness MAA, 2023, IEEE T IND INFORM, V19, P144, DOI 10.1109/TII.2022.3165875
   Anguita Davide, 2012, INT WORKSH AMB ASS L, V2012, P216, DOI DOI 10.1007/978-3-642-35395-6_30
   Ankalaki S., 2023, MULTIMED TOOLS APPL
   Balaha HM, 2023, NEURAL COMPUT APPL, V35, P12793, DOI 10.1007/s00521-023-08374-7
   Brishtel I, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23020818
   Chavarriaga R, 2013, PATTERN RECOGN LETT, V34, P2033, DOI 10.1016/j.patrec.2012.12.014
   Chen L, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3381012
   Cheng X, 2020, Arxiv, DOI arXiv:2006.03259
   Dahou A, 2022, MEASUREMENT, V199, DOI 10.1016/j.measurement.2022.111445
   Dallel M, 2023, ENG APPL ARTIF INTEL, V118, DOI 10.1016/j.engappai.2022.105655
   Ferrari A, 2023, J CHEMOTHERAPY, V35, P163, DOI [10.1080/1120009X.2022.2067706, 10.1007/s40860-021-00167-w]
   Gao WB, 2021, APPL SOFT COMPUT, V111, DOI 10.1016/j.asoc.2021.107728
   Gao WB, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3102735
   Huang WB, 2021, IEEE J BIOMED HEALTH, V25, P3834, DOI 10.1109/JBHI.2021.3092396
   Islam Md Milon, 2023, Inf. Fusion
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Khan ZN, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107671
   Khatun MA, 2022, IEEE J TRANSL ENG HE, V10, DOI 10.1109/JTEHM.2022.3177710
   Kolkar R, 2023, MULTIMED TOOLS APPL, V82, P47253, DOI 10.1007/s11042-023-15007-7
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Li Y, 2023, INFORM FUSION, V91, P47, DOI 10.1016/j.inffus.2022.10.015
   Liu H, 2023, Sensor-Based Human Activity and Behavior Research: Where Advanced Sensing and Recognition Technologies Meet
   Liu T, 2021, J Supercomput, P1
   Liu TY, 2022, J SUPERCOMPUT, V78, P6696, DOI 10.1007/s11227-021-04140-5
   Long J, 2019, INFORMATION, V10, DOI 10.3390/info10060203
   Lu LM, 2022, IEEE ACCESS, V10, P66797, DOI 10.1109/ACCESS.2022.3185112
   Powers DMW, 2020, Arxiv, DOI arXiv:2010.16061
   Mehrish A, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101869
   Mukherjee D, 2020, MULTIMED TOOLS APPL, V79, P31663, DOI 10.1007/s11042-020-09537-7
   Murphy RM, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0279842
   Mutegeki Ronald, 2020, 2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC), P362, DOI 10.1109/ICAIIC48513.2020.9065078
   Prajapati JB, 2023, Applying Drone Technologies and Robotics for Agricultural Sustainability, P155
   RAY A, 2023, INT J INFORM MANAGEM, V0003
   Reiss A, 2012, IEEE INT SYM WRBL CO, P108, DOI 10.1109/ISWC.2012.13
   Rueda FM, 2018, INFORMATICS-BASEL, V5, DOI 10.3390/informatics5020026
   Saleem G, 2023, NEURAL COMPUT APPL, V35, P4145, DOI 10.1007/s00521-022-07937-4
   Sarkar A, 2023, NEURAL COMPUT APPL, V35, P12239, DOI 10.1007/s00521-022-08189-y
   Sarkar A, 2023, NEURAL COMPUT APPL, V35, P5165, DOI 10.1007/s00521-022-07911-0
   Shan CY, 2020, 2020 8 INT C INF COM, P1
   Shanmugam JV, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103217
   Shoaib M, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16040426
   Singh R, 2023, COGN SYST RES, V77, P30, DOI 10.1016/j.cogsys.2022.10.003
   SinghRawat A, 2023, Innovations in Information and Communication Technologies, P57
   Subasi A, 2020, Innovation in Health Informatics, P123, DOI DOI 10.1016/B978-0-12-819043-2.00005-8
   Tang Y, 2021, IEEE SENS J, V21, P581, DOI 10.1109/JSEN.2020.3015521
   Teng Q, 2020, IEEE SENS J, V20, P7265, DOI 10.1109/JSEN.2020.2978772
   Terreran M, 2023, LECT NOTE NETW SYST, V577, P29, DOI 10.1007/978-3-031-22216-0_3
   Thakur D, 2022, IEEE ACCESS, V10, P4137, DOI 10.1109/ACCESS.2022.3140373
   Voicu RA, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030458
   Wan SH, 2020, MOBILE NETW APPL, V25, P743, DOI 10.1007/s11036-019-01445-x
   Wang K, 2019, IEEE SENS J, V19, P7598, DOI 10.1109/JSEN.2019.2917225
   Xia K, 2020, IEEE ACCESS, V8, P56855, DOI 10.1109/ACCESS.2020.2982225
   Xu C, 2019, IEEE ACCESS, V7, P9893, DOI 10.1109/ACCESS.2018.2890675
   Yang X, 2021, J ARTIFICIAL INTELLI, V1, P51, DOI [DOI 10.37965/JAIT.2020.0051, 10.37965/jait.2020.0051]
   Zhang Y, 2023, COMPUT COMMUN, V197, P87, DOI 10.1016/j.comcom.2022.10.027
   Zou ZX, 2023, P IEEE, V111, P257, DOI 10.1109/JPROC.2023.3238524
NR 60
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 9
PY 2023
DI 10.1007/s11042-023-17496-y
EA NOV 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9MX6
UT WOS:001101620700001
DA 2024-07-18
ER

PT J
AU Patel, I
   Kulkarni, M
   Mehendale, N
AF Patel, Iftekar
   Kulkarni, Makarand
   Mehendale, Ninad
TI Review of sensor-driven assistive device technologies for enhancing
   navigation for the visually impaired
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Navigation systems; Obstacle detection; Visually impaired; RGB depth
   sensing cameras; LiDAR navigation
ID DISTANCE MEASUREMENT; LIDAR
AB Most of our daily activities hinge on our ability to perceive our surroundings, with our eyes serving as pivotal sensory receptors. Our brain processes the visual data captured by our eyes, crafting a three-dimensional representation of our environment that empowers us to navigate and execute tasks. However, individuals dealing with visual impairments experience either partial or complete absence of this visual perception. In the past, conditions like myopia and astigmatism also lacked effective treatments, yet advancements in science and technology have enabled the creation of corrective aids like eyeglasses or even minor surgical interventions for vision enhancement. Over the years, researchers have conducted extensive investigations to devise devices catering to the needs of the visually impaired. This manuscript focuses on diverse sensors applicable in navigation systems tailored for this demographic. The review delves into recent advancements in navigation tools designed for the visually impaired, encompassing sensors such as visual, proximity, and LiDAR sensors, among others. Sensors generate copious amounts of data, which undergo processing to simulate the surrounding environment. We underscore the unique capabilities of each sensor, as well as optimal combinations of sensors that yield superior results. The challenges associated with sensor utilization are also addressed, accompanied by potential strategies for overcoming them. Our survey reveals a prevalent trend in utilizing RGB-depth sensing cameras and ultrasonic sensors in tandem with other sensor types for navigation purposes. This study aims to furnish a comprehensive overview of contemporary progress within the realm of navigation aids for the visually impaired, ultimately aiding researchers in discerning the most suitable technological approaches based on specific applications.
C1 [Patel, Iftekar; Kulkarni, Makarand; Mehendale, Ninad] Somaiya Vidyavihar Univ, KJ Somaiya Coll Engn, Mumbai, India.
C3 Somaiya Vidyavihar University; K J Somaiya College of Engineering
RP Mehendale, N (corresponding author), Somaiya Vidyavihar Univ, KJ Somaiya Coll Engn, Mumbai, India.
EM ninad@somaiya.edu
RI Patel, Iftekar/KFB-2102-2024; Mehendale, Ninad Dileep/Y-2455-2018
OI Mehendale, Ninad Dileep/0000-0003-3037-5076; Iftekar, Iftekar
   Patel/0009-0004-5716-0125
FU Somaiya Vidyavihar University (SVU) [21-22]
FX This research is funded by Somaiya Vidyavihar University (SVU), research
   project 21-22.
CR Ahsbahs T, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9060552
   Akkamis M, 2021, AGRIENGINEERING, V3, P423, DOI 10.3390/agriengineering3020028
   Castillo AB, 2018, EUR J SPORT SCI, V18, P450, DOI 10.1080/17461391.2018.1427796
   Bourne RRA, 2020, INVEST OPHTH VIS SCI, V61
   Bouteraa Y, 2021, MICROMACHINES-BASEL, V12, DOI 10.3390/mi12091082
   Bylow E., 2013, Robotics: Science and Systems, V2, P2
   Cao Z, 2021, IEEE INT VEH SYM, P122, DOI 10.1109/IV48863.2021.9575925
   Carullo A, 2001, IEEE SENS J, V1, P143, DOI 10.1109/JSEN.2001.936931
   Chai A., 2020, EAI Endorsed Trans Pervasive Health Technol, V6, pe2, DOI [10.4108/eai.13-7-2018.165498, DOI 10.4108/EAI.13-7-2018.165498]
   Chen CH, 2020, 2020 IEEE INT C CONS, P1
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Chitra P., 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P911, DOI 10.1109/ICAIS50930.2021.9395981
   Chokron S, 2021, FRONT HUM NEUROSCI, V15, DOI 10.3389/fnhum.2021.713316
   Díaz AA, 2020, 2020 3RD INTERNATIONAL CONFERENCE ON INFORMATION AND COMPUTER TECHNOLOGIES (ICICT 2020), P205, DOI 10.1109/ICICT50521.2020.00039
   Emmanuel Gbenga Dada., 2017, International Journal of Engineering and Technology, P3435, DOI [DOI 10.21817/IJET/2017/V9I5/170905302, 10.21817/ijet/2017/v9i5/170905302]
   Frizziero L, 2021, INVENTIONS-BASEL, V6, DOI 10.3390/inventions6030058
   Hakim H, 2021, P 1 INT C MATH MODEL, P661
   Innet S, 2009, 2008 INT S INT SIGN, P1
   Jain M., 2023, SN Computer Science, V4, P323, DOI DOI 10.1007/S42979-023-01735-Y
   Jang YS, 2017, INT J PRECIS ENG MAN, V18, P1881, DOI 10.1007/s12541-017-0217-y
   Javed Z, 2022, J SUPERCOMPUT, V78, P8247, DOI 10.1007/s11227-021-04198-1
   Kayukawa S, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382925
   Kayukawa S, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3411825
   Khaitan R, 2020, Real-time mobility assistance for the legally blind, P213
   Kuribayashi Masaki, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445451
   Kuriya R, 2015, 2015 24TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P450, DOI 10.1109/ROMAN.2015.7333607
   Latha N. Anju, 2016, Int J Adv Res Innov Ideas Educ, V2, P1
   Lemmens M., 2007, GIM International, V21, P24
   Liu HY, 2021, IEEE INT CONF COMP V, P1780, DOI 10.1109/ICCVW54120.2021.00204
   Maryono D., 2021, Adv Sustain Syst, V1, P10
   Mastorakis G, 2014, J REAL-TIME IMAGE PR, V9, P635, DOI 10.1007/s11554-012-0246-9
   Meier L., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P2992, DOI 10.1109/ICRA.2011.5980229
   Mostofa N, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21103488
   Nada AA, 2015, 2015 SCIENCE AND INFORMATION CONFERENCE (SAI), P1149, DOI 10.1109/SAI.2015.7237289
   Pallejà T, 2010, SENSORS-BASEL, V10, P11322, DOI 10.3390/s101211322
   Papagianopoulos I, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23167198
   Premebida C, 2014, IEEE INT C INT ROBOT, P4112, DOI 10.1109/IROS.2014.6943141
   Rahman MA., 2022, Bull Electr Eng Inform, V11, P201, DOI [10.11591/eei.v11i1.3452, DOI 10.11591/EEI.V11I1.3452]
   Real S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19153404
   Rogalski A, 2002, OPTO-ELECTRON REV, V10, P111
   Sasaki N, 2017, INT C CONTR AUTOMAT, P994, DOI 10.23919/ICCAS.2017.8204367
   Setiadi B., 2020, International Journal of Applied Technology Research, V1, P56, DOI [10.35313/ijatr.v1i1.24, DOI 10.35313/IJATR.V1I1.24]
   Sinha BB, 2022, FUTURE GENER COMP SY, V126, P169, DOI 10.1016/j.future.2021.08.006
   Tang L, 2020, TRANSPORT RES REC, V2674, P319, DOI 10.1177/0361198120901681
   Ton C, 2018, IEEE T NEUR SYS REH, V26, P1727, DOI 10.1109/TNSRE.2018.2859800
   Vorapatratorn S., 2021, Eng. Appl. Sci. Res, V48, P593, DOI DOI 10.14456/EASR.2021.61
   Xu QG, 2022, AAAI CONF ARTIF INTE, P2893
   Yasir M, 2021, 2021 7 INT C WIR TEL, P1
   Young J, 2015, PROCEDIA COMPUT SCI, V60, P1423, DOI 10.1016/j.procs.2015.08.218
   Zhang H, 2021, IEEE-CAA J AUTOMATIC, V8, P1389, DOI 10.1109/JAS.2021.1004084
   Zhao XM, 2020, IEEE SENS J, V20, P4901, DOI 10.1109/JSEN.2020.2966034
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 52
TC 0
Z9 0
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 9
PY 2023
DI 10.1007/s11042-023-17552-7
EA NOV 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9MX6
UT WOS:001101620700003
DA 2024-07-18
ER

PT J
AU Li, YC
   Qian, QL
   Duan, HY
   Min, XK
   Xu, YP
   Jiang, XC
AF Li, Yaocheng
   Qian, Qinglin
   Duan, Huiyu
   Min, Xiongkuo
   Xu, Yongpeng
   Jiang, Xiuchen
TI Boosting power line inspection in bad weather: Removing weather noise
   with channel-spatial attention-based UNet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Power line inspection; Bad weather; Image deraining; Image desnowing;
   Image dehazing; Dataset
ID MODEL
AB Power line inspection based on UAVs can effectively improve the inspection efficiency. With the development of object detection algorithms, automatic detection and recognition for power line components based on UAVs can further improve inspection speed. However, the performance most object detection methods are easily affected by noise, which is commonly encountered in the natural world such as rain, snow, haze, etc. In this paper, we aim at improving the power line detection performance of UAV inspections in bad weather. Specifically, we first construct a power line components detection (PLCD) dataset, which includes 1943 power line images captured by UAVs and corresponding annotated bounding boxes. Then we generate three sub-datasets named PLCD-R, PLCD-S, PLCD-H to simulate captured images under rain, snow, and haze conditions, respectively. A new image restoration model termed CSUNet is proposed for better remove the noise and restore images. Extensive experimental results demonstrate our CSUNet can well remove the noise captured in bad weather and improve the downstream object detection performance. The PLCD dataset and the codes will be publicly available to facilitate future research.
C1 [Li, Yaocheng; Qian, Qinglin; Duan, Huiyu; Min, Xiongkuo; Xu, Yongpeng; Jiang, Xiuchen] Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Duan, HY (corresponding author), Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
EM huiyuduan@sjtu.edu.cn
RI Duan, Huiyu/N-7039-2018; Li, Yaocheng/HTR-6709-2023; Xu,
   Yongpeng/H-5585-2017
OI Duan, Huiyu/0000-0003-1755-0431; Li, Yaocheng/0000-0003-3557-7275; Duan,
   Huiyu/0000-0002-6519-4067
CR Ansith S, 2022, DISPLAYS, V74, DOI 10.1016/j.displa.2022.102229
   Vieira-e-Silva ALB, 2021, SIBGRAPI, P215, DOI 10.1109/SIBGRAPI54419.2021.00037
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen Q, 2022, IEEE I C VI COM I PR, DOI 10.1109/VCIP56404.2022.10008885
   Chen Q, 2021, IEEE IMAGE PROC, P2958, DOI 10.1109/ICIP42928.2021.9506431
   Chen WT, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4176, DOI 10.1109/ICCV48922.2021.00416
   Duan H, 2023, arXiv
   Duan H, 2023, IEEE J Sel Top Signal Process
   Duan H., 2019, ZTE Communications, V17, P38
   Duan H, 2022, IEEE Trans Multimed
   Duan H, 2022, P IEEE INT S BROADB, P1
   Duan HY, 2017, INT CONF SYST SIGNAL
   Duan HY, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P6549, DOI 10.1145/3503161.3547955
   Duan HY, 2022, INT CONF ACOUST SPEE, P2065, DOI 10.1109/ICASSP43922.2022.9746606
   Duan HY, 2022, IEEE T IMAGE PROCESS, V31, P7206, DOI 10.1109/TIP.2022.3220404
   Duan HY, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351786
   Duan HY, 2018, LECT NOTES COMPUT SC, V10735, P662, DOI 10.1007/978-3-319-77380-3_63
   Ducut JD, 2022, DISPLAYS, V73, DOI 10.1016/j.displa.2022.102208
   Fu XY, 2017, IEEE T IMAGE PROCESS, V26, P2944, DOI 10.1109/TIP.2017.2691802
   Haijun Zhang, 2019, 2019 IEEE 17th International Conference on Industrial Informatics (INDIN). Proceedings, P886, DOI 10.1109/INDIN41052.2019.8972320
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hu MH, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0190466
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kui Jiang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8343, DOI 10.1109/CVPR42600.2020.00837
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li RT, 2020, PROC CVPR IEEE, P3172, DOI 10.1109/CVPR42600.2020.00324
   Li X, 2018, LECT NOTES COMPUT SC, V11211, P262, DOI 10.1007/978-3-030-01234-2_16
   Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Liang YB, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102042
   Liao L., 2023, PROC AAAI C ARTIF IN, V37, P1558
   Liao L, 2022, IEEE T IMAGE PROCESS, V31, P3525, DOI 10.1109/TIP.2022.3172208
   Lin X, 2021, IEEE T MULTIMEDIA, V23, P664, DOI 10.1109/TMM.2020.2987703
   Liu YF, 2018, IEEE T IMAGE PROCESS, V27, P3064, DOI 10.1109/TIP.2018.2806202
   Liu ZF, 2021, DISPLAYS, V68, DOI 10.1016/j.displa.2021.102008
   Lyu Z, 2022, DISPLAYS, V74, DOI 10.1016/j.displa.2022.102174
   Mansouri A, 2022, DISPLAYS, V74, DOI 10.1016/j.displa.2022.102275
   Menghan Hu, 2017, 2017 IEEE International Conference on Multimedia and Expo: Workshops (ICMEW), P97, DOI 10.1109/ICMEW.2017.8026243
   Min XK, 2020, IEEE T IMAGE PROCESS, V29, P6054, DOI 10.1109/TIP.2020.2988148
   Min XK, 2018, IEEE T MULTIMEDIA, V20, P2049, DOI 10.1109/TMM.2017.2788206
   Min XK, 2019, IEEE T MULTIMEDIA, V21, P2319, DOI 10.1109/TMM.2019.2902097
   Min XK, 2018, IEEE T BROADCAST, V64, P508, DOI 10.1109/TBC.2018.2816783
   Quan JN, 2022, DISPLAYS, V72, DOI 10.1016/j.displa.2022.102162
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sakaridis C, 2018, INT J COMPUT VISION, V126, P973, DOI 10.1007/s11263-018-1072-8
   Shih MJ, 2022, DISPLAYS, V74, DOI 10.1016/j.displa.2022.102273
   Song YD, 2023, IEEE T IMAGE PROCESS, V32, P1927, DOI 10.1109/TIP.2023.3256763
   Suryarasmi A, 2022, DISPLAYS, V73, DOI 10.1016/j.displa.2022.102241
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tao X, 2020, IEEE T SYST MAN CY-S, V50, P1486, DOI 10.1109/TSMC.2018.2871750
   Tomaszewski M, 2018, DATA BRIEF, V18, P765, DOI 10.1016/j.dib.2018.03.063
   Tu D, 2022, LECT NOTES COMPUT SC, V13664, P87, DOI 10.1007/978-3-031-19772-7_6
   Tu DY, 2022, PROC CVPR IEEE, P2192, DOI 10.1109/CVPR52688.2022.00224
   Nguyen VN, 2018, INT J ELEC POWER, V99, P107, DOI 10.1016/j.ijepes.2017.12.016
   Wang CS, 2021, DISPLAYS, V70, DOI 10.1016/j.displa.2021.102080
   Wang J, 2023, arXiv
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang YM, 2021, IEEE T MULTIMEDIA, V23, P1466, DOI 10.1109/TMM.2020.2999187
   Wang YL, 2017, IEEE T IMAGE PROCESS, V26, P3936, DOI 10.1109/TIP.2017.2708502
   Wei LS, 2022, DISPLAYS, V74, DOI 10.1016/j.displa.2022.102212
   Wei-Ting Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P754, DOI 10.1007/978-3-030-58589-1_45
   Wu SJ, 2021, IEEE IMAGE PROC, P604, DOI 10.1109/ICIP42928.2021.9506094
   Yang J., 2019, P IEEE VIS COMM IM P, P1
   Yang WH, 2021, IEEE T PATTERN ANAL, V43, P4059, DOI 10.1109/TPAMI.2020.2995190
   Yang WH, 2017, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2017.183
   Ye J, 2022, DISPLAYS, V74, DOI 10.1016/j.displa.2022.102197
   Zamir SW, 2021, PROC CVPR IEEE, P14816, DOI 10.1109/CVPR46437.2021.01458
   Zhang H., 2019, IEEE Trans Circ Syst Vid Technol
   Zhang H, 2018, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2018.00079
   Zhang H, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111342
   Zhang L, 2022, DISPLAYS, V74, DOI 10.1016/j.displa.2022.102194
   Zhang QH, 2022, DISPLAYS, V75, DOI 10.1016/j.displa.2022.102328
   Zhou G, 2016, IEEE IMAGE PROC, P744, DOI 10.1109/ICIP.2016.7532456
   Zhou H, 2022, DISPLAYS, V72, DOI 10.1016/j.displa.2021.102137
   Zhu X, 2018, SPIE, V10806, P342
NR 76
TC 0
Z9 0
U1 9
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 6
PY 2023
DI 10.1007/s11042-023-17554-5
EA NOV 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X6AZ8
UT WOS:001099271500003
DA 2024-07-18
ER

PT J
AU Bali, A
   Mansotra, V
AF Bali, Akanksha
   Mansotra, Vibhakar
TI Multiclass multilabel ophthalmological fundus image classification based
   on optimised deep feature space evolutionary model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fundus images; Machine Learning; Deep Learning; Convolutional Generative
   Adversarial Network (CGAN); Particle Swarm Optimization (PSO); Ocular
   Disease Intelligent Recognition (ODIR); Retinal Fundus Multi-Disease
   Image Dataset (RFMiD)
ID AREAS
AB Primary care doctors have been fighting against ocular illnesses for more than 37% of the world's population. This demonstrates the need for an autonomous and intelligent technological solution to improve the accessibility and convenience of categorising retinal pathology. The lab technician examines around 80 control individuals each day in addition to hospitalised patients for an average of 12 minutes to identify each disease. The study suggests using DFex-BeeHive, or deep feature extraction through the Bee Hive network, to categorise DR lessons across several labels. The evaluation of cutting-edge deep learning, machine learning, and algorithmic techniques is performed using the proposed DFex-BeeHivearchitectureIn order to reduce the inherent multicollinearity in deep learning, the research recommends using CGAN to flatten the distribution function of probabilities and PSO to synchronise the selection of heuristic-based features. The work uses a hybrid approach of CGAN, PSO, and DFex-BeeHive architecture to obtain 98.79% accuracy, 95.99% sensitivity, and 99.79% specificity in the RFMiD dataset and 97.16% accuracy and 96.81% F1 score in the ODIR dataset. In addition to improving classification precision over earlier lesion classifiers, the work reduces computation by 47% when compared to other cutting-edge designs using feature selection techniques.
C1 [Bali, Akanksha; Mansotra, Vibhakar] Univ Jammu, Dept Comp Sci & IT, Jammu 180016, J&K, India.
C3 University of Jammu
RP Bali, A (corresponding author), Univ Jammu, Dept Comp Sci & IT, Jammu 180016, J&K, India.
EM akankshabali5@gmail.com
CR Alippi C, 2018, 2018 17TH ACM/IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN), P212, DOI 10.1109/IPSN.2018.00049
   Bali Akanksha, 2022, Rising Threats in Expert Applications and Solutions: Proceedings of FICR-TEAS 2022. Lecture Notes in Networks and Systems (434), P63, DOI 10.1007/978-981-19-1122-4_8
   Bali Akanksha, 2021, 2021 3rd International Conference on Advances in Computing, Communication Control and Networking (ICAC3N), P351, DOI 10.1109/ICAC3N53548.2021.9725464
   Bali A, 2021, 2021 1 INT C ADV COM, P91, DOI [10.1109/ICACFCT53978.2021.9837371, DOI 10.1109/ICACFCT53978.2021.9837371]
   Bali A, 2024, ARCH COMPUT METHOD E, V31, P487, DOI 10.1007/s11831-023-09989-8
   Bali A, 2021, INT J ADV COMPUT SC, V12, P537
   Ben Sayadia S, 2022, MED BIOL ENG COMPUT, V60, P1449, DOI 10.1007/s11517-022-02546-8
   Charbuty B., 2021, J APPL SCI TECHNOL T, VVol. 2, P20, DOI [10.38094/jastt20165, DOI 10.38094/JASTT20165]
   Colucciello M, 2004, POSTGRAD MED, V116, P57, DOI 10.3810/pgm.2004.07.1558
   Corbilla J, 2020, GitHub
   Dodo Y, 2015, INVEST OPHTH VIS SCI, V56, P2012, DOI 10.1167/iovs.14-15924
   Fujita H, 2008, COMPUT METH PROG BIO, V92, P238, DOI 10.1016/j.cmpb.2008.04.003
   Gour N, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2020.102329
   Harsh Purvi Prajapati, 2018, International Journal of Computer Sciences and Engineering, V6, P74, DOI [DOI 10.26438/IJCSE/V6I10.7478, 10.26438/ijcse/v6i10.7478]
   Hernan M., 1967, GastronomiaEcuatoriana y Turismo Local, V1, P5
   Ho E, 2022, TRANSL VIS SCI TECHN, V11, DOI 10.1167/tvst.11.10.39
   Hridoy RH, 2021, 2021 5 INT C EL ENG, P1, DOI [10.1109/ICEEICT53905.2021.9667825, DOI 10.1109/ICEEICT53905.2021.9667825]
   Islam Md Tariqul, 2019, 2019 IEEE International Conference on Signal Processing, Information, Communication & Systems (SPICSCON), P59, DOI 10.1109/SPICSCON48833.2019.9065162
   Jiang YY, 2017, SatFormer: Saliency-Guided Abnormality-Aware Transformer for Retinal Disease Classification in Fundus Image, P987, DOI [10.24963/ijcai.2022/138, DOI 10.24963/IJCAI.2022/138]
   Khan MSM, 2021, 2021 IEEE WORLD AI IOT CONGRESS (AIIOT), P209, DOI [10.1109/AIIoT52608.2021.9454244, 10.1109/AIIOT52608.2021.9454244]
   Kong XN, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P614
   Kordos M., 2010, Artificial Intelligence and Soft Computing. ICAISC 2010. Lecture Notes in Computer Science(), DOI [10.1007/978-3-642-13208-7_52, DOI 10.1007/978-3-642-13208-7_52]
   Kumar ES., 2021, J Jilin Univ, V40, P35
   Li N., 2021, Revised Selected Papers, P177, DOI [10.1007/978-3-030-71058-3_11, DOI 10.1007/978-3-030-71058-3_11]
   Li ZW, 2022, MICROMACHINES-BASEL, V13, DOI 10.3390/mi13060947
   Liu ZG, 2019, KNOWL-BASED SYST, V164, P336, DOI 10.1016/j.knosys.2018.11.001
   Lumbantoruan AA, 2020, 2021 4TH INTERNATIONAL SEMINAR ON RESEARCH OF INFORMATION TECHNOLOGY AND INTELLIGENT SYSTEMS (ISRITI 2021), DOI 10.1109/ISRITI54043.2021.9702861
   Luo J, 2021, J INTELL MANUF, V32, P407, DOI 10.1007/s10845-020-01579-w
   Lyu Linquan, 2022, Annu Int Conf IEEE Eng Med Biol Soc, V2022, P1818, DOI 10.1109/EMBC48229.2022.9871762
   Muller Dominik, 2021, Stud Health Technol Inform, V283, P23, DOI 10.3233/SHTI210537
   Nisar DEM, 2021, IEEE ACCESS, V9, P98523, DOI 10.1109/ACCESS.2021.3095312
   Omar MA, 2017, INT C CONTROL DECISI, P202, DOI 10.1109/CoDIT.2017.8102591
   Ouda O, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11131966
   Pachade S, 2021, DATA-BASEL, V6, DOI 10.3390/data6020014
   Paul A, 2018, IEEE T IMAGE PROCESS, V27, P4012, DOI 10.1109/TIP.2018.2834830
   Pérez A, 2006, INT J APPROX REASON, V43, P1, DOI 10.1016/j.ijar.2006.01.002
   Rodríguez MA, 2023, IEEE J BIOMED HEALTH, V27, P2739, DOI 10.1109/JBHI.2022.3214086
   Sakri SB, 2018, IEEE ACCESS, V6, P29637, DOI 10.1109/ACCESS.2018.2843443
   Sengar N, 2021, 2021 12 INT C COMP C, P1, DOI [10.1109/ICCCNT51525.2021.9579546, DOI 10.1109/ICCCNT51525.2021.9579546]
   Smitha A, 2022, SN Comput Sci, V59, DOI [10.1007/s42979-021-00945-6, DOI 10.1007/S42979-021-00945-6]
   Sokolova M, 2006, LECT NOTES COMPUT SC, V4304, P1015
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Srinivas K., 2020, Adv Math: Scientific J, V9, P3407, DOI [10.37418/amsj.9.6.21, DOI 10.37418/AMSJ.9.6.21]
   Sun K, 2022, COMPUT BIOL MED, V149, DOI 10.1016/j.compbiomed.2022.105909
   Sun K, 2022, BIOMED SIGNAL PROCES, V77, DOI 10.1016/j.bspc.2022.103768
   Tammina S, 2019, Int. J. Sci. Res. Publ, V9, P143, DOI DOI 10.29322/IJSRP.9.10.2019.P9420
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tu Chengsheng, 2017, MATEC Web of Conferences, V139, DOI 10.1051/matecconf/201713900222
   Unoki N, 2007, AM J OPHTHALMOL, V144, P755, DOI 10.1016/j.ajo.2007.07.011
   Wang J, 2020, IEEE ACCESS, V8, P212499, DOI 10.1109/ACCESS.2020.3040275
   Wu SQ, 2014, IEEE SIGNAL PROC LET, V21, P687, DOI 10.1109/LSP.2014.2313570
   Xu K, 2020, PROC CVPR IEEE, P1737, DOI 10.1109/CVPR42600.2020.00181
   Zhang XH, 2004, IEEE IMAGE PROC, P139
NR 53
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-17530-z
EA NOV 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2PW2
UT WOS:001096936900006
DA 2024-07-18
ER

PT J
AU Liang, ZH
   Lu, HJ
   Zhou, RJ
   Yao, YD
   Zhu, WJ
AF Liang, Zhihao
   Lu, Huijuan
   Zhou, Rongjing
   Yao, Yudong
   Zhu, Wenjie
TI CMFuse: Correlation-based multi-scale feature fusion network for the
   detection of COVID-19 from Chest X-ray images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; COVID-19; Image classification; Chest X-ray images
ID CLASSIFICATION
AB COVID-19 broke out in 2019, seriously affecting people's health and life. Recent studies have indicated that radiological images carry crucial information about COVID-19. Hence, automatic image classification assisted by artificial intelligence (AI) can be employed as a potential diagnostic tool. Nonetheless, in the task of COVID-19 X-ray image recognition, there are local features, including local vascular dilatation, as well as global features, including large ground glass-like shadows, traditional deep neural networks cannot effectively extract features, and the significance of distinct scale features for the task is also divergent, feature element-wise adding or feature concatenating to fuse features from various branches do not consider the internal correlation between features. In view of the above problems, we propose a Correlation-based Multi-scale Feature Fusion Network (CMFuse), combining the advantages of Convolutional Neural Network (CNN) and Transformer. The model captures local spatial contextual features and global semantic information representation of features at different scales in parallel, and the extracted features are adaptively fused at distinct levels through the feature fusion module, down-sampling and other steps to obtain the final classification results. We evaluated CMFuse on the integrated COVID-19 X-ray image dataset, and the results showed that our model attains 97.36% Accuracy, 99.15% Specificity, 97.27% Recall, 97.17% Precision, and 97.22% F1-score, which outperforms other previous related works.
C1 [Liang, Zhihao; Lu, Huijuan; Zhu, Wenjie] China Jiliang Univ, Coll Informat Engn, Key Lab Electromagnet Wave Informat Technol & Met, Hangzhou, Zhejiang, Peoples R China.
   [Zhou, Rongjing] Hangzhou Canc Hosptial, Dept Pathol, Hangzhou, Zhejiang, Peoples R China.
   [Yao, Yudong] Stevens Inst Technol, Dept Elect & Comp Engn, Hoboken, NJ USA.
C3 China Jiliang University; Stevens Institute of Technology
RP Lu, HJ (corresponding author), China Jiliang Univ, Coll Informat Engn, Key Lab Electromagnet Wave Informat Technol & Met, Hangzhou, Zhejiang, Peoples R China.; Zhou, RJ (corresponding author), Hangzhou Canc Hosptial, Dept Pathol, Hangzhou, Zhejiang, Peoples R China.
EM s21030812007@cjlu.edu.cn; hjlu@cjlu.edu.cn; zrjsh711@163.com;
   yyao@stevens.edu; zhuwj@cjlu.edu.cn
FU This work was supported by the National Natural Science Foundation of
   China (61272315), the Natural Science Foundation of Zhejiang
   Province(LY21F020028, LQ20F030015). Thanks to Yudong Yao academician,
   one of the IEEE Fellow, for his valuable comments [61272315]; National
   Natural Science Foundation of China [LY21F020028, LQ20F030015]; Natural
   Science Foundation of Zhejiang Province
FX This work was supported by the National Natural Science Foundation of
   China (61272315), the Natural Science Foundation of Zhejiang
   Province(LY21F020028, LQ20F030015). Thanks to Yudong Yao academician,
   one of the IEEE Fellow, for his valuable comments
CR Afshar P, 2020, PATTERN RECOGN LETT, V138, P638, DOI 10.1016/j.patrec.2020.09.010
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Calli E, 2021, MED IMAGE ANAL, V72, DOI 10.1016/j.media.2021.102125
   Christodoulidis S, 2017, IEEE J BIOMED HEALTH, V21, P76, DOI 10.1109/JBHI.2016.2636929
   Fan XL, 2022, DISPLAYS, V72, DOI 10.1016/j.displa.2022.102150
   Fang ZY, 2022, IEEE T MOL BIO MULT, V8, P17, DOI 10.1109/TMBMC.2021.3099367
   Hafeez A, 2020, EURASIAN J MED ONCOL, V4, P116, DOI 10.14744/ejmo.2020.90853
   Huang CL, 2020, LANCET, V395, P497, DOI [10.1016/S0140-6736(20)30183-5, 10.1016/S0140-6736(20)30211-7]
   Hussain E, 2021, CHAOS SOLITON FRACT, V142, DOI 10.1016/j.chaos.2020.110495
   Ibrahim AU, 2021, COGN COMPUT, DOI 10.1007/s12559-020-09787-5
   Jacobi A, 2020, CLIN IMAG, V64, P35, DOI 10.1016/j.clinimag.2020.04.001
   Jin Y, 2023, Multimed Tools Appl, P1
   Kim HE, 2022, BMC MED IMAGING, V22, DOI 10.1186/s12880-022-00793-7
   Kong LZ, 2022, BIOMED SIGNAL PROCES, V77, DOI 10.1016/j.bspc.2022.103772
   Li GL, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104181
   Liu JY, 2022, BIOMED SIGNAL PROCES, V76, DOI 10.1016/j.bspc.2022.103677
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Nasiri H, 2022, 2022 IEEE WORLD AI IOT CONGRESS (AIIOT), P201, DOI [10.1109/AIIOT54504.2022.9817375, 10.1109/AIIoT54504.2022.9817375]
   Nur-A-Alam, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041480
   Quan H, 2021, COMPUT BIOL MED, V133, DOI 10.1016/j.compbiomed.2021.104399
   Raveendran AV, 2021, DIAB MET SYND CLIN R, V15, P869, DOI 10.1016/j.dsx.2021.04.007
   Sharma A, 2022, BIOMED SIGNAL PROCES, V77, DOI 10.1016/j.bspc.2022.103778
   Shi Y, 2020, J ZHEJIANG UNIV-SC B, V21, P343, DOI 10.1631/jzus.B2000083
   Shivadekar S., 2023, International Journal of Intelligent Systems and Applications in Engineering, V11, P241
   Shuja J, 2021, APPL INTELL, V51, P1296, DOI 10.1007/s10489-020-01862-6
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Wang SH, 2021, INFORM FUSION, V67, P208, DOI 10.1016/j.inffus.2020.10.004
   World Health Organization (WHO), 2020, LAB TEST STRAT REC C
   Zhang J, 2020, ARXIV, V27, P141, DOI [10.48550/arXiv.2003.12338, DOI 10.48550/ARXIV.2003.12338]
   Zhang JP, 2020, Arxiv, DOI arXiv:2003.12338
   Zunair H, 2021, SOC NETW ANAL MIN, V11, DOI 10.1007/s13278-021-00731-5
NR 31
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 31
PY 2023
DI 10.1007/s11042-023-17431-1
EA OCT 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XH9
UT WOS:001090305500003
DA 2024-07-18
ER

PT J
AU Sivanagireddy, K
   Jagadeesh, S
   Narmada, A
AF Sivanagireddy, K.
   Jagadeesh, S.
   Narmada, A.
TI Identification of criminal & non-criminal faces using deep learning and
   optimization of image processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE ACO; Classification; Densenet 169; Deep learning; Face recognition; Face
   identification
AB Since identifying criminals is a crucial function of intelligent surveillance systems, it has attracted a lot of attention. Although various approaches are developed for criminal face recognition, they cannot accurately identify the criminal faces. In this study, a novel advanced deep learning model was designed for accurate identification of criminal face from the CCTV images. The developed model utilizes five major phases namely, data collection, pre-processing, feature extraction, feature selection and classification. The study utilizes the data collected from the National Institute of Standards and Technology (NIST) containing criminal and non-criminal face images. The developed model employs Haarcascade algorithm for scaling and transforming the raw images into appropriate format for subsequent analysis. Further, the designed model utilizes Principal Component Analysis (PCA) and Ant Colony Optimization (ACO) for feature extraction and selection, respectively. Finally, the face recognition task was performed using the DenseNet 169 classifier. The developed framework was designed and implemented in Pytorch software and the result metrics are estimated. Furthermore, a comprehensive comparative study was conducted to validate the performances of the developed model with the conventional deep learning models. The experimental results and comparative study illustrate that the designed model outperformed the traditional models.
C1 [Sivanagireddy, K.; Jagadeesh, S.; Narmada, A.] Sridevi Womens Engn Coll, Dept Elect & Commun Engn, Hyderabad 500075, Telangana, India.
RP Sivanagireddy, K (corresponding author), Sridevi Womens Engn Coll, Dept Elect & Commun Engn, Hyderabad 500075, Telangana, India.
EM sivangireddyjournal@gmail.com
RI jagadeesh, saggurthi/KVX-7979-2024; KALLI, SIVANAGIREDDY/B-8697-2012;
   Alaparthi, Narmada/KVX-8849-2024
OI KALLI, SIVANAGIREDDY/0000-0002-2333-0438; 
CR AbdAlmageed W, 2016, IEEE WINT CONF APPL
   Afra S, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123151
   Albahli S, 2021, CMC-COMPUT MATER CON, V67, P1333, DOI 10.32604/cmc.2021.014691
   Amjad K., 2020, Lahore Garrison Univ Res J Comput Sci Inf Technol, V4, P47
   Anwarul S, 2022, J ELECTRON IMAGING, V31, DOI 10.1117/1.JEI.31.4.043055
   Bansal A, 2017, IEEE INT CONF COMP V, P2545, DOI 10.1109/ICCVW.2017.299
   Barnouti NH, 2016, INT J ADV COMPUT SC, V7, P371
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Chackravarthy S, 2018, 2018 4TH IEEE INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC 2018), P399, DOI 10.1109/CIC.2018.00060
   Chatfield K, 2014, Arxiv, DOI arXiv:1405.3531
   Chaves D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164491
   Chen J, 2015, IEEE ICC, P1801, DOI 10.1109/ICC.2015.7248586
   Chen JC, 2016, IEEE WINT CONF APPL
   Crosswhite N, 2018, IMAGE VISION COMPUT, V79, P35, DOI 10.1016/j.imavis.2018.09.002
   Dadaneh BZ, 2016, EXPERT SYST APPL, V53, P27, DOI 10.1016/j.eswa.2016.01.021
   Dulhanty C, 2020, PROCEEDINGS OF THE 3RD AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY AIES 2020, P244, DOI 10.1145/3375627.3375875
   Goel R, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21155068
   Hussain SA., 2020, Journal of physics: conference series
   Jayaswal R, 2020, INT CONF COMM SYST, P66, DOI [10.1109/CSNT.2020.13, 10.1109/CSNT48778.2020.9115779]
   Karve A., 2019, International conference on intelligent computing, information and control systems, P566
   Masi I, 2019, IEEE T PATTERN ANAL, V41, P379, DOI 10.1109/TPAMI.2018.2792452
   Mathur R., 2022, 2022 international conference on advances in computing, communication and applied informatics (ACCAI), P1
   Mehedi Shamrat F. M. Javed, 2021, Proceedings of the 5th International Conference on Trends in Electronics and Informatics (ICOEI 2021), P760, DOI 10.1109/ICOEI51242.2021.9452896
   Mishra NK, 2021, IMAGE VISION COMPUT, V115, DOI 10.1016/j.imavis.2021.104290
   Nandhini S, 2022, NEURAL COMPUT APPL, V34, P5513, DOI 10.1007/s00521-021-06714-z
   Phornchaicharoen Amornpan, 2019, 2019 Joint International Conference on Digital Arts, Media and Technology with ECTI Northern Section Conference on Electrical, Electronics, Computer and Telecommunications Engineering (ECTI DAMT-NCON), P304, DOI 10.1109/ECTI-NCON.2019.8692306
   Raju K., 2022, A Fusion Artif. Intell. Internet Things Emerg. Cyber Syst., V6, P203, DOI [10.1007/978-3-030-76653-5, DOI 10.1007/978-3-030-76653-5]
   Ratnaparkhi ST, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P773, DOI 10.1109/Confluence51648.2021.9377205
   Sankaranarayanan S, 2016, INT CONF BIOMETR THE
   Sowmeya V, 2022, AIP Conf Proc, V2393
   Tabakhi S, 2015, PATTERN RECOGN, V48, P2798, DOI 10.1016/j.patcog.2015.03.020
   Taigman Y, 2015, PROC CVPR IEEE, P2746, DOI 10.1109/CVPR.2015.7298891
   Wu Y, 2018, IEEE T PATTERN ANAL, V40, P3067, DOI 10.1109/TPAMI.2017.2787130
   Wu Y, 2019, INT J COMPUT VISION, V127, P115, DOI 10.1007/s11263-018-1097-z
   Xu X, 2019, Arxiv, DOI arXiv:1901.09447
NR 35
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 26
PY 2023
DI 10.1007/s11042-023-17471-7
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2WU9
UT WOS:001090292500004
DA 2024-07-18
ER

PT J
AU Zhang, M
   Zhao, YF
   Yang, LM
AF Zhang, Min
   Zhao, Yifeng
   Yang, Liming
TI Robust twin support vector regression with correntropy-based metric
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Twin support vector regression (TSVR); Similarity measure; Correntropy;
   Robustness; DC programming algorithm; Near-infrared (NIR) spectral
   technique
ID MACHINE
AB Machine learning methods have been widely used control and information systems. Robust learning is an important issue in machine learning field. In this work, we propose a novel robust regression framework. Specifically, we propose a robust similarity measure induced by correntropy, and its important properties are demonstrated theoretically such as symmetry, boundedness, nonnegativity, consistency, smoothness and approximation behaviors. Moreover, the proposed robust metric extends the traditional metrics such as the l(2)-norm and l(0)-norm as the kernel parameter approaches different values. Then with the proposed similarity metric and epsilon-insensitive pinball loss, a new robust twin support vector regression framework (RTSVR) is proposed to handle robust regression problems. The linear RTSVR model is first built, and a kernelled RTSVR version is developed to deal with nonlinear regressions. To handle the nonconvexity of the proposed RTSVR, we use DC (different of convex function) programming algorithm to iteratively solve the problem, and the resulting algorithm converges linearly. To test the proposed RTSVR, numerical experiments are implemented on two databases including a public benchmark database and a practical application database. Experiments on benchmark data with different types of noise illustrate that the proposed methods achieve better performance than the traditional methods in most cases. Experiments on the application database, the proposed RTSVR is combined with near-infrared (NIR) spectral technique to analyze the hardness of licorice seeds in low frequency,intermediate frequency and high frequency spectral regions respectively. Experiments on different spectral regions show that the performance of the RTSVR is better than that of the traditional methods in all spectral regions.
C1 [Zhang, Min; Yang, Liming] China Agr Univ, Coll Sci, Beijing, Peoples R China.
   [Zhao, Yifeng] China Agr Univ, Coll Informat & Elect Engn, Beijing, Peoples R China.
C3 China Agricultural University; China Agricultural University
RP Yang, LM (corresponding author), China Agr Univ, Coll Sci, Beijing, Peoples R China.
EM cauyanglm@163.com
FU This work is supported by National Nature Science Foundation of China
   (No. 11471010 and No. 11271367). Moreover, the authors thank the
   referees for their constructive comments to improve paper. [11471010,
   11271367]; National Nature Science Foundation of China
FX This work is supported by National Nature Science Foundation of China
   (No. 11471010 and No. 11271367). Moreover, the authors thank the
   referees for their constructive comments to improve paper.
CR Anagha P, 2018, J INTELL FUZZY SYST, V35, P5231, DOI 10.3233/JIFS-169807
   Balasundaram S, 2020, NEURAL COMPUT APPL, V32, P11285, DOI 10.1007/s00521-019-04625-8
   Balasundaram S., 2018, Neural Process Lett, V3, P1
   Bamakan SMH, 2017, KNOWL-BASED SYST, V126, P113, DOI 10.1016/j.knosys.2017.03.012
   Ghosh A, 2023, MULTIMED TOOLS APPL, V82, P29227, DOI 10.1007/s11042-023-14689-3
   Gupta D, 2021, APPL SOFT COMPUT, V102, DOI 10.1016/j.asoc.2021.107099
   Hazarika BB, 2022, NEURAL PROCESS LETT, V54, P1091, DOI 10.1007/s11063-021-10671-y
   Jayadeva, 2007, IEEE T PATTERN ANAL, V29, P905, DOI 10.1109/TPAMI.2007.1068
   Le Thi HA, 2015, EUR J OPER RES, V244, P26, DOI 10.1016/j.ejor.2014.11.031
   Liu DL, 2015, KNOWL-BASED SYST, V85, P224, DOI 10.1016/j.knosys.2015.05.008
   Liu WF, 2007, IEEE T SIGNAL PROCES, V55, P5286, DOI 10.1109/TSP.2007.896065
   López J, 2018, KNOWL-BASED SYST, V152, P83, DOI 10.1016/j.knosys.2018.04.005
   Newman D., 1998, UCI REPOSITORY MACHI
   Peng XJ, 2016, INFORM SCIENCES, V340, P86, DOI 10.1016/j.ins.2016.01.023
   Peng XJ, 2010, NEURAL NETWORKS, V23, P365, DOI 10.1016/j.neunet.2009.07.002
   Qi ZQ, 2013, PATTERN RECOGN, V46, P305, DOI 10.1016/j.patcog.2012.06.019
   Randles RH, 2006, Wilcoxon signed rank test
   Ren QQ, 2022, APPL INTELL, V52, P2154, DOI 10.1007/s10489-021-02480-6
   Ren Z, 2018, NEUROCOMPUTING, V313, P74, DOI 10.1016/j.neucom.2018.05.100
   Singh A, 2014, PATTERN RECOGN, V47, P441, DOI 10.1016/j.patcog.2013.07.017
   Singla M, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107395
   Suykens JAK., 2002, INT J CIRC THEOR APP, V27, P605, DOI DOI 10.1002/(SICI)1097-007X(199911/12)27:6<605::AID-CTA86>3.0.CO;2-Z
   Vapnik VN., 1995, NATURE STAT LEARNING, DOI DOI 10.1007/978-1-4757-2440-0
   Wang YQ, 2023, MULTIMED TOOLS APPL, V82, P26527, DOI 10.1007/s11042-023-14864-6
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Xiang DH, 2012, J APPL MATH, DOI 10.1155/2012/902139
   Xu GB, 2017, PATTERN RECOGN, V63, P139, DOI 10.1016/j.patcog.2016.09.045
   Yan H, 2022, IEEE T INTELL TRANSP, V23, P14542, DOI 10.1109/TITS.2021.3130264
   Yang LM, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.105483
   Yang LM, 2018, CHEMOMETR INTELL LAB, V177, P89, DOI 10.1016/j.chemolab.2018.04.003
   Yang LM, 2017, NEURAL COMPUT, V29, P3014, DOI [10.1162/neco_a_01002, 10.1162/NECO_a_01002]
   Yang LM, 2016, ENG APPL ARTIF INTEL, V53, P176, DOI 10.1016/j.engappai.2016.04.003
   Yang LM, 2016, ANAL METHODS-UK, V8, P1914, DOI 10.1039/c5ay01304f
   Yuan C, 2021, NEURAL NETWORKS, V142, P457, DOI 10.1016/j.neunet.2021.06.028
   Yuan C, 2021, INFORM SCIENCES, V545, P82, DOI 10.1016/j.ins.2020.07.068
   Zhao YP, 2013, NEUROCOMPUTING, V118, P225, DOI 10.1016/j.neucom.2013.03.005
NR 36
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 23
PY 2023
DI 10.1007/s11042-023-17315-4
EA OCT 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U9NV8
UT WOS:001088011000009
DA 2024-07-18
ER

PT J
AU Nagaraju, K
   Reddy, MB
AF Nagaraju, Katta
   Reddy, M. Babu
TI Automated handcrafted features with deep learning based age group
   estimation model using facial profiles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Facial images; Age group estimation; Classification process; Deep
   learning; Handcrafted features; Deep belief network
AB At present times, there have been many studies on the automated extraction of facial information using machine learning. Age Group Estimation (AGE) from frontal face images becomes useful in several application areas. The AGE technique aims to classify the age group of the person using the facial image. The stochastic behavior of aging between individuals makes AGE depending upon facial images a tedious process. Faces from distinct age groups have alike features making the facial AGE more difficult. Therefore, this paper considers AGE as a multi-class classification issue and designs an Automated Deep Learning-based Age Group Estimation Model (ADL-AGEM) using facial images. Primarily, the Bilateral Filtering (BF) technique is employed as an image pre-processing technique to boost the facial image quality. In addition, Linear Discriminant Analysis (LDA) technique is applied for the facial component detection process. Besides, a fusion of handcrafted features with deep features takes place to derive a useful set of feature vectors from the facial images. The Local Diagonal Extreme Pattern (LDEP) based handcrafted and Inception v3-based deep features are fused for a facial component before the classification process. In the final stage, the Deep Belief Network (DBN) model is applied as the classifier to determine the appropriate age groups for the applied facial images. To validate the effectiveness of the ADL-AGEM model, a set of experimentations take place on three benchmark databases. The experimental results ensured that the ADL-AGEM model has accomplished promising results over the existing techniques in terms of different measures.
C1 [Nagaraju, Katta] Krishna Univ, Machilipatnam, India.
   [Reddy, M. Babu] Krishna Univ, Dept Comp Sci, Machilipatnam, India.
C3 Krishna University Machilipatnam; Krishna University Machilipatnam
RP Nagaraju, K (corresponding author), Krishna Univ, Machilipatnam, India.
EM kattanagaraju.vital@gmail.com
CR Abu Nada A. M., 2020, International Journal of Academic Engineering Research (IJAER), V4, P21
   Al-Shannaq A, 2020, Jordanian J Comput Inform Technol, V6
   Angulu R, 2019, COMPUT J, V62, P346, DOI 10.1093/comjnl/bxy050
   Anoop V, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1370-x
   Bukar AM, 2017, IET COMPUT VIS, V11, P650, DOI 10.1049/iet-cvi.2016.0486
   Choi Y, 2019, IEEE ACCESS, V7, P75143, DOI 10.1109/ACCESS.2019.2920932
   Dagher I, 2021, MULTIMED TOOLS APPL, V80, P20369, DOI 10.1007/s11042-021-10739-w
   Gupta SK, 2023, MULTIMED TOOLS APPL, V82, P1289, DOI 10.1007/s11042-022-12678-6
   Hassan MM, 2021, CMC-COMPUT MATER CON, V68, P1637, DOI 10.32604/cmc.2021.016467
   He Y, 2017, Comput Math Methods Med.
   Kim S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80182-8
   Kumar Y, 2018, BIOMED SIGNAL PROCES, V39, P459, DOI 10.1016/j.bspc.2017.08.018
   Lakshmanaprabu SK, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.105487
   Liu H, 2017, PATTERN RECOGN, V66, P82, DOI 10.1016/j.patcog.2016.10.026
   Madhan E., 2020, Journal of Computational and Theoretical Nanoscience, V17, P2237, DOI DOI 10.1166/JCTN.2020.8877
   MuruganK FD., 2020, Int J Adv Sci Technol, V29, P1473
   Muthuvel S., 2016, Adv Nat Appl Sci, V10, P534
   Neelakandan S., 2015, International Journal for Scientific Research Development, V3, P2016
   Neggaz I, 2022, SOFT COMPUT, V26, P10435, DOI 10.1007/s00500-022-06886-3
   Nguyen Dat Tien, 2014, ScientificWorldJournal, V2014, P905269, DOI 10.1155/2014/905269
   Othmani A, 2020, COMPUT VIS IMAGE UND, V196, DOI 10.1016/j.cviu.2020.102961
   Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3
   Schwartz HA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0073791
   Shejul AA, 2021, J SIGNAL PROCESS SYS, V93, P879, DOI 10.1007/s11265-020-01609-z
   Shu XB, 2015, IEEE I CONF COMP VIS, P3970, DOI 10.1109/ICCV.2015.452
   Sucharitha G, 2019, 2019 2 INT C ADV COM
   Taheri S, 2019, APPL ARTIF INTELL, V33, P379, DOI 10.1080/08839514.2019.1577009
   Umapathy S, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12747
   Vasavi S., 2021, SN Computer Science, V2, P249
   Xia M, 2020, IEEE T INF FOREN SEC, V15, P2417, DOI 10.1109/TIFS.2020.2969552
   Zhang HY, 2021, FRONT COMPUT SCI-CHI, V15, DOI 10.1007/s11704-020-8272-4
   Zhang K, 2020, IEEE T CIRC SYST VID, V30, P3140, DOI 10.1109/TCSVT.2019.2936410
NR 32
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17332-3
EA OCT 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU6A2
UT WOS:001155212900004
DA 2024-07-18
ER

PT J
AU Shi, H
   Zhou, ZY
   Qin, JH
   Geng, JN
   Li, MC
AF Shi, Hui
   Zhou, Ziyi
   Qin, Jianhao
   Geng, Jianing
   Li, Mingchu
TI A reversible data hiding in encrypted image based on additive secret
   sharing with adaptive bit-plane prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Reversible data hiding in encrypted image (RDHEI); Additive secret
   sharing (ASS); Multi-party copyright protection;
   Several-Parts-Disposable Strategy(SPDS); Adaptive bit-plane prediction
   (ABPP)
AB With the rapid development of 5G network, protecting multimedia data security has attracted a lot of attentions, and Reversible Data Hiding in Encrypted Image (RDHEI) has become a research hotspot, since it has the ability of hiding information while protecting the privacy of original cover images. RDHEI remains a challenging task to improve the embedding capacity under the premise of real reversibility. In this paper, we propose a RDHEI scheme with multiple data hiders based on Additive Secret Sharing (ASS) and Adaptive Bit-Plane Prediction (ABPP). First, ASS and bit-plane separation techniques are developed to encrypt an original image. It can encrypt an original image into n encrypted image shares with an encryption key and send each encrypted image share to one data hider. Then, we propose a Several-Parts-Disposable Strategy (SPDS) which is developed to generate the encrypted secret data with multiple data hiders. SPDS makes our scheme have the ability to resist collusive analysis and cooperative attacks. Finally, each data hider can embed encrypted secret data independently using ABPP embedding strategy. Furthermore, our scheme is separable and can be applied to multiparty copyright protection. In addition, we present a Shared No Key (SNK) based on secret sharing, which costs much lower computation than the literature works proposed SNK-type schemes by using homomorphic encryption. The experimental results and theoretical analysis show that our scheme is secure, high capacity and significantly outperforms previous schemes.
C1 [Shi, Hui; Zhou, Ziyi; Qin, Jianhao; Geng, Jianing] Liaoning Normal Univ, Sch Comp Sci & Artificial Intelligence, Dalian 116029, Peoples R China.
   [Li, Mingchu] Dalian Univ Technol, Sch Software Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University; Dalian University of Technology
RP Shi, H (corresponding author), Liaoning Normal Univ, Sch Comp Sci & Artificial Intelligence, Dalian 116029, Peoples R China.
EM shihui_jiayou@126.com
RI 周, 梓怡/JGM-2983-2023
OI 周, 梓怡/0009-0009-0367-7256; Shi, Hui/0000-0001-5029-7461
FU Supported by National Science Foundation of China (No.61976109,
   62006108, 61601214); Liaoning Provincial Education Department (Grant No.
   WQ2020014); Liaoning Revitalization Talents Program (No.XLYC2006005);
   Scientific Research Project of Liaoning Province( [61976109, 62006108,
   61601214]; National Science Foundation of China [WQ2020014]; Liaoning
   Provincial Education Department; Liaoning Revitalization Talents
   Program; Scientific Research Project of Liaoning Province; Key Ramp;D
   projects of Liaoning Provincial Department of Science and Technology;
   Liaoning Provincial Key Laboratory Special Fund
FX Supported by National Science Foundation of China (No.61976109,
   62006108, 61601214); Liaoning Provincial Education Department (Grant No.
   WQ2020014); Liaoning Revitalization Talents Program (No.XLYC2006005);
   Scientific Research Project of Liaoning Province(No.LJKZ0963); Key R & D
   projects of Liaoning Provincial Department of Science and Technology;
   Liaoning Provincial Key Laboratory Special Fund.
NR 0
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 12
PY 2023
DI 10.1007/s11042-023-16984-5
EA OCT 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ4S3
UT WOS:001142752200012
DA 2024-07-18
ER

PT J
AU Rajendran, S
   Doraipandian, M
   Seethalakshmi, R
   Kirthivasan, K
AF Rajendran, Sujarani
   Doraipandian, Manivannan
   Seethalakshmi, R.
   Kirthivasan, Kannan
TI An image cipher based on bio-molecular hyper chaotic system with dual
   diffusion scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lorenz chaotic map; DNA 4-bit encoding; DNA-Reverse-Compliment; Dual
   diffusion; Hyper chaotic system
ID DNA-SEQUENCE OPERATION; HENON-SINE MAP; ENCRYPTION ALGORITHM;
   HYPERCHAOTIC SYSTEM; LORENZ; CRYPTANALYSIS; PERMUTATION
AB Sensitive images are being transmitted over insecure media as network and information technology evolve at a rapid pace. As a result, people are becoming more concerned about information security, particularly digital image protection. Numerous image encryption algorithms have been proposed for securing digital images. From that, a chaotic map and DNA computing has proved as a perfect tools for image protection as it contains efficient random behavior and parallelism. Even DNA computing provide sufficient security, it's consume high amount of time for the process of DNA encoding itself, because in most of the research work 2-bit based DNA encoding have been utilized which require high computational time. In order to overwhelm this problem and to provide efficient security with reasonable time consumption, a new methodology of 4-bit DNA encoding is proposed. Performance of the proposed model is analysed and proved that the 50% of execution time is reduced for DNA encoding and a random DNA reverse-compliment diffusion increased the security complexity then the existing state of the art. Experimental results of the proposed cryptosystem achieved the following results. Average RGB benchmark Lena image results of Histogram Variance (262.42 > 250),Correlation Coefficients (-0.011 < 0), Entropy ( 7.9971 approximate to 8), NPCR ( 99.62 approximate to 99.67), UACI ( 33.49 > 33.47), and key sensitivity (> 99%), which satisfied the security requirements. Further, robustness proved by crop and noise attack analyses. SHA-256 hash function is utilized to feed the seed value of Lorenz map to resist plaintext attacks. Results of these analyses proved that the proposed cryptosystem is fast and secure. Hence it can be adoptable for secure storage and transfer of images in real-time applications.
C1 [Rajendran, Sujarani] SASTRA Deemed Univ, Srinivasa Ramanujan Ctr, Dept Comp Sci & Engn, Kumbakonam, Tamil Nadu, India.
   [Doraipandian, Manivannan; Kirthivasan, Kannan] SASTRA Deemed Univ, Sch Comp, Thanjavur, Tamil Nadu, India.
   [Seethalakshmi, R.] SASTRA Deemed Univ, Sch Arts Sci & Humanities, Thanjavur, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Doraipandian, M (corresponding author), SASTRA Deemed Univ, Sch Comp, Thanjavur, Tamil Nadu, India.
EM rsujarani@src.sastra.edu; dmv@cse.sastra.edu; kkannan@maths.sastra.edu
OI Rajendran, Sujarani/0000-0001-9827-0807
FU The Authors gratefully acknowledge the Department of Science and
   Technology, India for Fund for Improvement of Samp;T Infrastructure in
   Universities and Higher Educational Institutions (SR/FST/ETI-371/2014),
   (SR/FST/MSI-107/2015) and Tata Realty- IT City [SR/FST/ETI-371/2014,
   SR/FST/MSI-107/2015]; Department of Science and Technology, India for
   Fund for Improvement of Samp;T Infrastructure in Universities
FX The Authors gratefully acknowledge the Department of Science and
   Technology, India for Fund for Improvement of S & T Infrastructure in
   Universities and Higher Educational Institutions (SR/FST/ETI-371/2014),
   (SR/FST/MSI-107/2015) and Tata Realty- IT City - SASTRA Srinivasa
   Ramanujan Research Cell of our University for the financial support
   extended to us in carrying out this research work.
CR Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Amina S, 2018, COMMUN NONLINEAR SCI, V60, P12, DOI 10.1016/j.cnsns.2017.12.017
   Aqeel-ur-Rehman, 2018, OPTIK, V153, P117, DOI 10.1016/j.ijleo.2017.09.099
   Attaullah, 2019, MULTIMED TOOLS APPL, V78, P31467, DOI 10.1007/s11042-019-07981-8
   Babaei A, 2020, OPTIK, V203, DOI 10.1016/j.ijleo.2019.164000
   Banu SA, 2020, MED BIOL ENG COMPUT, V58, P1445, DOI 10.1007/s11517-020-02178-w
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Ben Slimane N, 2018, MULTIMED TOOLS APPL, V77, P30993, DOI 10.1007/s11042-018-6145-8
   Cao WJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107457
   Casillo M, 2021, TH CO SC GE ISS, V13116, P330, DOI 10.1007/978-3-030-91434-9_29
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen H, 2017, OPT QUANT ELECTRON, V49, DOI 10.1007/s11082-017-0995-6
   Dagadu JC, 2019, WIRELESS PERS COMMUN, V108, P591, DOI 10.1007/s11277-019-06420-z
   Firdous A, 2021, IEEE ACCESS, V9, P11675, DOI 10.1109/ACCESS.2021.3049791
   Gan ZH, 2021, NEURAL COMPUT APPL, V33, P16251, DOI 10.1007/s00521-021-06225-x
   Girdhar A, 2018, MULTIMED TOOLS APPL, V77, P27017, DOI 10.1007/s11042-018-5902-z
   Guesmi R, 2021, MULTIMED TOOLS APPL, V80, P1925, DOI 10.1007/s11042-020-09672-1
   Gupta S., 2019, Handbook of Research on Cloud Computing and Big Data Applications in IoT, P82, DOI [DOI 10.4018/978-1-5225-84070.CH005, 10.4018/978-1-5225-8407-0.ch005, DOI 10.4018/978-1-5225-8407-0.CH005]
   Huang LQ, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20070535
   Iqbal N, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2021.102809
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Kamal ST, 2021, IEEE ACCESS, V9, P37855, DOI 10.1109/ACCESS.2021.3063237
   Karmakar J, 2020, MULTIMED TOOLS APPL, V79, P28277, DOI 10.1007/s11042-020-09125-9
   Kaur M, 2021, IEEE T GREEN COMMUN, V5, P1223, DOI 10.1109/TGCN.2021.3081616
   Kessler GC, 2013, An overview of cryptography
   Kumari E, 2020, RESULTS OPT, V1, DOI 10.1016/j.rio.2020.100005
   Li M, 2019, IEEE ACCESS, V7, P63336, DOI 10.1109/ACCESS.2019.2916402
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501734
   Liu HJ, 2019, OPT LASER ENG, V122, P123, DOI 10.1016/j.optlaseng.2019.05.027
   Liu HJ, 2019, MULTIMED TOOLS APPL, V78, P15997, DOI 10.1007/s11042-018-6996-z
   Liu LT, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102971
   Liu P, 2019, MULTIMED TOOLS APPL, V78, P14823, DOI 10.1007/s11042-018-6758-y
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P21579, DOI 10.1007/s11042-020-08880-z
   Maddodi G, 2018, MULTIMED TOOLS APPL, V77, P24701, DOI 10.1007/s11042-018-5669-2
   Man ZL, 2021, CHAOS SOLITON FRACT, V152, DOI 10.1016/j.chaos.2021.111318
   Muhammad ZMZ, 2020, IEEE ACCESS, V8, P56581, DOI 10.1109/ACCESS.2020.2982827
   Nezhad SYD, 2020, OPTIK, V224, DOI 10.1016/j.ijleo.2020.165661
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Patel S, 2020, MULTIMED TOOLS APPL, V79, P31739, DOI 10.1007/s11042-020-09551-9
   Rajendran S, 2021, MULTIMED TOOLS APPL, V80, P24221, DOI 10.1007/s11042-021-10798-z
   Rajendran S, 2020, MULTIMED TOOLS APPL, V79, P12447, DOI 10.1007/s11042-019-08396-1
   Rakheja P, 2019, MULTIMED TOOLS APPL, V78, P20809, DOI 10.1007/s11042-019-7406-x
   Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P9355, DOI 10.1007/s11042-018-6516-1
   Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P2105, DOI 10.1007/s11042-018-6346-1
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   SIPI, 2019, Image database
   Sridhar S, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102996
   Su X, 2017, MULTIMED TOOLS APPL, V76, P14021, DOI 10.1007/s11042-016-3800-9
   Suri S, 2020, NEURAL COMPUT APPL, V32, P11859, DOI 10.1007/s00521-019-04668-x
   Vijayakumar S., 2020, Eur J Mol Clin Med, V7, P2077
   Wang XY, 2018, MULTIMED TOOLS APPL, V77, P6243, DOI 10.1007/s11042-017-4534-z
   Wang XY, 2008, PHYSICA A, V387, P3751, DOI 10.1016/j.physa.2008.02.020
   Wang XY, 2022, NONLINEAR DYNAM, V107, P1277, DOI 10.1007/s11071-021-07017-7
   Wang XY, 2016, OPT LASER ENG, V82, P79, DOI 10.1016/j.optlaseng.2015.12.006
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2017, NONLINEAR DYNAM, V90, P855, DOI 10.1007/s11071-017-3698-4
   Wu XT, 2019, J VIS COMMUN IMAGE R, V61, P74, DOI 10.1016/j.jvcir.2019.03.020
   Xie T, 2014, OPTIK, V125, P7166, DOI 10.1016/j.ijleo.2014.07.111
   Yang YG, 2021, MULTIMED TOOLS APPL, V80, P691, DOI 10.1007/s11042-020-09779-5
   Yin SL, 2021, EVOL INTELL, V14, P1817, DOI 10.1007/s12065-020-00440-6
   Zeng L, 2015, OPTIK, V126, P5022, DOI 10.1016/j.ijleo.2015.09.219
   [张健 Zhang Jian], 2018, [西南交通大学学报, Journal of Southwest Jiaotong University], V53, P1142
   Zhang Q, 2013, OPTIK, V124, P6276, DOI 10.1016/j.ijleo.2013.05.009
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang Q, 2013, J COMPUT THEOR NANOS, V10, P341, DOI 10.1166/jctn.2013.2702
   Zhang XQ, 2021, OPT LASER TECHNOL, V141, DOI 10.1016/j.optlastec.2021.107073
   Zhang Y., 2016, J Comput Theor Nanosci, V13, P4025, DOI [10.1166/jctn.2016.5244, DOI 10.1166/JCTN.2016.5244]
   Zhang Y., 2017, Optik (Stuttg), V8, P223, DOI [10.1007/s13319-017-0126-y, DOI 10.1007/S13319-017-0126-Y]
   Zhang YS, 2014, OPTIK, V125, P1562, DOI 10.1016/j.ijleo.2013.09.018
   Zhao HX, 2021, OPTIK, V230, DOI 10.1016/j.ijleo.2021.166307
   Zhen P., 2017, Multimed Tools Appl, V76, P14021, DOI [10.1007/s11042-016-3800-9, DOI 10.1007/S11042-016-3800-9]
NR 77
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 10
PY 2023
DI 10.1007/s11042-023-16935-0
EA OCT 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2RB1
UT WOS:001083315100010
DA 2024-07-18
ER

PT J
AU Azuddin, KA
   Junoh, AK
   Zakaria, A
   Rahman, MTA
   Nor, NMIM
   Nishizaki, H
   Latiffah, Z
   Azuddin, NF
   Abdullah, MZ
   Terna, TP
AF Azuddin, K. A.
   Junoh, A. K.
   Zakaria, A.
   Rahman, M. T. A.
   Nor, N. M. I. M.
   Nishizaki, H.
   Latiffah, Z.
   Azuddin, N. F.
   Abdullah, M. Z.
   Terna, T. P.
TI Supervised segmentation on fusarium macroconidia spore in microscopic
   images via analytical approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Artificial Intelligence; Machine Learning; Pattern Recognition;
   Supervised and Unsupervised Learning Methods
ID FUNGI; SOLANI; PLANTS
AB Fungi are one of the major causes that contributed to plant diseases. There are lots of fungi species but it is estimated that only 10% have been described. There are two major approaches to identifying fungi species, morphological identification, and molecular test which need cautious clarification to make good interpretations and are time-consuming. In this paper, we propose a Machine Learning approach that involves the use of the K-Means clustering technique, and Decision Tree to highlight the observed fungi spore images taken under the microscopic view and discard background pixels to produce digital images database which later can be used for Deep Learning.
C1 [Azuddin, K. A.; Zakaria, A.; Rahman, M. T. A.] Univ Malaysia Perlis, Fac Elect Engn Technol, Arau, Perlis, Malaysia.
   [Junoh, A. K.] Univ Malaysia Perlis, Inst Engn Math, Arau, Perlis, Malaysia.
   [Nor, N. M. I. M.; Latiffah, Z.; Azuddin, N. F.; Terna, T. P.] Univ Sains Malaysia, Sch Biol Sci, Gelugor, Malaysia.
   [Nishizaki, H.] Univ Yamanashi, Dept Mechatron, Kofu, Yamanashi, Japan.
   [Abdullah, M. Z.] Univ Malaysia Perlis, Fac Mech Engn & Technol, Arau, Malaysia.
C3 Universiti Malaysia Perlis; Universiti Malaysia Perlis; Universiti Sains
   Malaysia; University of Yamanashi; Universiti Malaysia Perlis
RP Junoh, AK (corresponding author), Univ Malaysia Perlis, Inst Engn Math, Arau, Perlis, Malaysia.
EM kadri@unimap.edu.my
FU The writing of this report is fully funded by Malaysia's Ministry of
   Higher Education under Fundamental Research Grant Scheme
   (FRGS/1/2022/STG01/UNIMAP/02/1) and with the collaboration and
   assistance of Universiti Sains Malaysia, Universiti of Yamanashi, J
   [FRGS/1/2022/STG01/UNIMAP/02/1]; Malaysia's Ministry of Higher Education
   under Fundamental Research Grant Scheme
FX The writing of this report is fully funded by Malaysia's Ministry of
   Higher Education under Fundamental Research Grant Scheme
   (FRGS/1/2022/STG01/UNIMAP/02/1) and with the collaboration and
   assistance of Universiti Sains Malaysia, Universiti of Yamanashi, Japan,
   and Nandemo Dagang Sdn. Bhd.
CR Blackwell M, 2011, AM J BOT, V98, P426, DOI 10.3732/ajb.1000298
   Dhanachandra N., 2017, Int J Appl Eng Res, V12, P10458
   Gherbawy Y, 2010, MOLECULAR IDENTIFICATION OF FUNGI, P1, DOI 10.1007/978-3-642-05042-8
   Günlük O, 2021, J GLOBAL OPTIM, V81, P233, DOI 10.1007/s10898-021-01009-y
   Havrlentová M, 2021, MICROORGANISMS, V9, DOI 10.3390/microorganisms9102108
   Jain A, 2019, BIOENGINEERED, V10, P409, DOI 10.1080/21655979.2019.1649520
   Khan N, 2018, TOXICOL REP, V5, P970, DOI 10.1016/j.toxrep.2018.08.016
   Kim KG, 2016, HEALTHC INFORM RES, V22, P351
   Liu XB, 2024, NEURAL COMPUT APPL, V36, P133, DOI 10.1007/s00521-022-07317-y
   Mahesh B., 2020, nternational Journal of Science and Research (IJSR), V9, P381, DOI [DOI 10.21275/ART20203995, 10.21275/ART20203995]
   Manamgoda DS, 2012, FUNGAL DIVERS, V56, P131, DOI 10.1007/s13225-012-0189-2
   Mao LC, 2019, IEEE ACCESS, V7, P172231, DOI 10.1109/ACCESS.2019.2956508
   Maryani N, 2019, PERSOONIA, V43, P48, DOI 10.3767/persoonia.2019.43.02
   Mumtaz F, 2018, BIOMED PHARMACOTHER, V105, P1205, DOI 10.1016/j.biopha.2018.05.086
   Nazarov PA, 2020, ACTA NATURAE, V12, P46
   O'Brien HE, 2005, APPL ENVIRON MICROB, V71, P5544, DOI 10.1128/AEM.71.9.5544-5550.2005
   QUINLAN JR, 1990, IEEE T SYST MAN CYB, V20, P339, DOI 10.1109/21.52545
   Rokach L, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P165, DOI 10.1007/0-387-25465-X_9
   Seifert KA, 2010, IMA FUNGUS, V1, P109, DOI 10.5598/imafungus.2010.01.02.02
   Sukmawati D, 2017, ASIAN J AGR BIOL, V5, P202
   Tahir MW, 2016, PR INT CONF AUTONOM, P227, DOI 10.1109/ICAC.2016.50
   Taylor DL, 2014, ECOL MONOGR, V84, P3, DOI 10.1890/12-1693.1
   Truong C, 2017, NEW PHYTOL, V214, P913, DOI 10.1111/nph.14509
   Wei Z, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aaw0759
   Yoo SH, 2020, FRONT MED-LAUSANNE, V7, DOI 10.3389/fmed.2020.00427
   Zhang N, 2006, J CLIN MICROBIOL, V44, P2186, DOI 10.1128/JCM.00120-06
   Zielinski B, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0234806
NR 27
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 9
PY 2023
DI 10.1007/s11042-023-17008-y
EA OCT 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2OJ4
UT WOS:001083245400013
DA 2024-07-18
ER

PT J
AU Yang, K
   Zhang, Y
   Zhang, X
   Zheng, L
AF Yang, Kai
   Zhang, Yu
   Zhang, Xin
   Zheng, Lu
TI YOLOX with CBAM for insulator detection in transmission lines
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Insulator detection; Deep learning; Object detection; YOLOX; CBAM
AB The traditional manual inspection mode is inefficient for detecting transmission line insulators. Even in the case of the detection system generated by combining aerial images by unmanned aerial vehicles with traditional machine vision algorithms, the detection accuracy and response speed have been increasingly unable to meet the requirements of modern power-grid construction. However, with the development of deep learning image processing technology, its deep level neural network can simulate the human brain to automatically extract the rich feature expression of the insulator image coupled with network training to quickly provide the final recognition results, improving the detection performance of the insulator defect detection technology based on this optimization method. Therefore, this study uses the deep learning object detection network YOLOX to classify and locate transmission line insulators. Accordingly, this study introduces the convolutional block attention module (CBAM) theory to optimize the YOLOX network, further enhancing the performance of the network model. The experimental results show that after introducing the CBAM, the detection accuracy of YOLOX on the insulator dataset herein has been improved by similar to 3% and the performance of the model has been optimized to some extent.
C1 [Yang, Kai; Zhang, Yu; Zhang, Xin] Taiyuan Inst Technol, Dept Automat, Taiyuan 030008, Peoples R China.
   [Zhang, Yu] Taiyuan Univ Technol, Coll Elect & Power Engn, Taiyuan 030024, Peoples R China.
   [Zhang, Yu] Shanxi Energy Internet Res Inst, Taiyuan 030024, Peoples R China.
   [Zheng, Lu] China Univ Min & Technol, Sch Elect & Power Engn, Xuzhou 221116, Peoples R China.
C3 Taiyuan Institute of Technology; Taiyuan University of Technology; China
   University of Mining & Technology
RP Yang, K (corresponding author), Taiyuan Inst Technol, Dept Automat, Taiyuan 030008, Peoples R China.
EM yangkai0529@126.com; Zhang.yu.edu@163.com; 39396455@qq.com;
   125027176@qq.com
FU This work was sponsored by Shanxi Provincial Higher Education Science
   and Technology Innovation Project (Grant no. 2022L524) and Shanxi
   Provincial Basic Research Program(Grant no. 202103021223048).
   [2022L524]; Shanxi Provincial Higher Education Science and Technology
   Innovation Project [202103021223048]; Shanxi Provincial Basic Research
   Program
FX This work was sponsored by Shanxi Provincial Higher Education Science
   and Technology Innovation Project (Grant no. 2022L524) and Shanxi
   Provincial Basic Research Program(Grant no. 202103021223048).
CR Aboah A, 2023, Arxiv, DOI [arXiv:2304.08256, 10.48550/arXiv.2304.08256]
   Ahmed KT, 2021, IEEE ACCESS, V9, P41934, DOI 10.1109/ACCESS.2021.3063545
   Al-Wajih Ebrahim, 2021, 2021 International Conference on Data Analytics for Business and Industry (ICDABI), P587, DOI 10.1109/ICDABI53623.2021.9655977
   Al-wajih E, 2023, KNOWL-BASED SYST, V259, DOI 10.1016/j.knosys.2022.110079
   Alkentar B., 2021, J. Eng., V27, P19, DOI [DOI 10.31026/J.ENG.2021.08.02, 10.31026/j.eng.2021.08.02.23J, DOI 10.31026/J.ENG.2021.08.02.23J]
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Cao ZH, 2020, IET IMAGE PROCESS, V14, P4359, DOI 10.1049/iet-ipr.2020.1119
   Chen JD, 2021, IET IMAGE PROCESS, V15, P1115, DOI 10.1049/ipr2.12090
   Chen ZY, 2022, AGRONOMY-BASEL, V12, DOI 10.3390/agronomy12020365
   Einy S., 2023, Sci Program, V2023, P11, DOI [10.1155/2023/2426601, DOI 10.1155/2023/2426601]
   Fan P., 2021, Journal of Physics: Conference Series, V1828, DOI 10.1088/1742-6596/1828/1/012019
   Feng Xingjie, 2021, Journal of Computer Applications, P2054, DOI 10.11772/j.issn.1001-9081.2020091523
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   Hripcsak G, 2005, J AM MED INFORM ASSN, V12, P296, DOI 10.1197/jamia.M1733
   Ikechukwu Victor, 2021, Global Transitions Proceedings, V2, P375
   Li Y, 2022, ENERGY REP, V8, P807, DOI 10.1016/j.egyr.2022.08.027
   Lin F, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23091111
   Lin J, 2023, FORESTS, V14, DOI 10.3390/f14030619
   Loukas C, 2022, J MAGN RESON IMAGING, V56, P182, DOI 10.1002/jmri.28014
   Malini A, 2021, J INTELL FUZZY SYST, V40, P11411, DOI 10.3233/JIFS-202596
   Mehta P., 2021, Comput Rev, V7, P62
   Mei HW, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3075031
   Nawwar NM, 2021, ARAB J NUCL SCI APPL, V54, P135, DOI 10.21608/ajnsa.2021.70450.1460
   Rojas-Perez LO, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21227436
   Park J, 2022, J MANUF SYST, V63, P539, DOI 10.1016/j.jmsy.2022.05.011
   Rahman S., 2021, IOP Conference Series: Materials Science and Engineering, V1087, DOI 10.1088/1757-899X/1087/1/012084
   Siddiqui ZA, 2020, ENERGIES, V13, DOI 10.3390/en13133348
   Tan YS, 2021, NEURAL COMPUT APPL, V33, P5339, DOI 10.1007/s00521-020-05337-0
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang K, 2022, ADV THEOR SIMUL, V5, DOI 10.1002/adts.202200002
   Wang P, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11111059
   Wang XK, 2023, J CIRCUIT SYST COMP, V32, DOI 10.1142/S0218126623500809
   Xing ZQ, 2022, IET COMPUT VIS, V16, P418, DOI 10.1049/cvi2.12097
   Xu H, 2022, IEEE T INTELL TRANSP, V23, P19760, DOI 10.1109/TITS.2021.3137253
   Zhang ZD, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3194909
   Zheng LB, 2020, FRONT ONCOL, V10, DOI 10.3389/fonc.2020.01238
   Zhou HB, 2022, PROCEDIA COMPUT SCI, V199, P1355, DOI 10.1016/j.procs.2022.01.171
NR 37
TC 0
Z9 0
U1 15
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 9
PY 2023
DI 10.1007/s11042-023-17245-1
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2OJ4
UT WOS:001083245400004
DA 2024-07-18
ER

PT J
AU Kamrani, A
   Zenkouar, K
   Najah, S
   El Fadili, H
AF Kamrani, Abdelhalim
   Zenkouar, Khalid
   Najah, Said
   El Fadili, Hakim
TI Fast chaotic encryption scheme based on separable moments and parallel
   computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image encryption; Separable moments; Chaos cryptography; Parallel
   computing
ID DISCRETE ORTHOGONAL MOMENTS; IMAGE ENCRYPTION; MAP; PERMUTATION;
   KRAWTCHOUK; ALGORITHMS
AB In this paper, we propose three novel image encryption algorithms. Separable moments and parallel computing are combined in order to enhance the security aspect and time performance. The three proposed algorithms are based on TKM (Tchebichef-Krawtchouk moments), THM (Tchebichef-Hahn moments) and KHM (Krawtchouk-Hahn moments) respectively. A novel chaotic scheme is introduced, that enhances security by adding a layer of block permutation on top of the classical confusion/diffusion scheme, and reduces time cost through parallel computing. This approach offers improved security and faster performance compared to classical encryption schemes. The proposed algorithms are tested under several criteria and the experimental results show a remarkable resilience against all well-known attacks. Furthermore, the novel parallel encryption scheme exhibits a drastic improvement in the time performance. The proposed algorithms are compared to the state-of-the-art methods and they stand out as a promising choice for reliable use in real world applications.
C1 [Kamrani, Abdelhalim; Zenkouar, Khalid; Najah, Said] Sidi Mohamed Ben Abdellah Univ, Fac Sci & Technol, Lab Intelligent Syst & Applicat LSIA, Fes, Morocco.
   [El Fadili, Hakim] Univ Sidi Mohamed Ben Abdellah, Ecole Natl Sci Appl Fez, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Kamrani, A (corresponding author), Sidi Mohamed Ben Abdellah Univ, Fac Sci & Technol, Lab Intelligent Syst & Applicat LSIA, Fes, Morocco.
EM abdelhalim.kamrani@usmba.ac.ma; khalid.zenkouar@usmba.ac.ma;
   said.najah@usmba.ac.ma; hakim.elfadili@usmba.ac.ma
FU The authors thankfully acknowledge the Laboratory of Intelligent Systems
   and Applications (LSIA) for his support to achieve this work.;
   Laboratory of Intelligent Systems and Applications (LSIA)
FX The authors thankfully acknowledge the Laboratory of Intelligent Systems
   and Applications (LSIA) for his support to achieve this work.
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Batioua I, 2017, PATTERN RECOGN, V71, P264, DOI 10.1016/j.patcog.2017.06.013
   Chai XL, 2022, NONLINEAR DYNAM, V108, P2671, DOI 10.1007/s11071-022-07328-3
   Guan MM, 2019, IET IMAGE PROCESS, V13, P1535, DOI 10.1049/iet-ipr.2019.0051
   Hankerson D., 2000, Coding theory and cryptography: the essentials, DOI [10.1201/b16944, DOI 10.1201/B16944]
   Henon M., 2004, The theory of chaotic attractors, V21, P94
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hu GZ, 2021, NONLINEAR DYNAM, V103, P2819, DOI 10.1007/s11071-021-06228-2
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hua ZY, 2021, INFORM SCIENCES, V546, P1063, DOI 10.1016/j.ins.2020.09.032
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Janakiraman S, 2018, MICROPROCESS MICROSY, V56, P1, DOI 10.1016/j.micpro.2017.10.013
   Jiang NZX, 2006, INT WORKSH INT COMP
   Kamrani A, 2020, MULTIMED TOOLS APPL, V79, P20263, DOI 10.1007/s11042-020-08879-6
   Khedr WI, 2019, Multimed Tools Appl, P1
   Li S, 2004, IACR's Crypto ePrint Arch Rep, V374, P2004
   Li SJ, 2007, IEEE T CIRC SYST VID, V17, P214, DOI 10.1109/TCSVT.2006.888840
   Lin HB, 2008, IEEE T IMAGE PROCESS, V17, P272, DOI 10.1109/TIP.2007.916157
   Liu HJ, 2021, SOFT COMPUT, V25, P11077, DOI 10.1007/s00500-021-05849-4
   Liu HJ, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501734
   Liu HJ, 2020, APPL MATH COMPUT, V376, DOI 10.1016/j.amc.2020.125153
   Liu HJ, 2019, MULTIMED TOOLS APPL, V78, P15997, DOI 10.1007/s11042-018-6996-z
   Liu S, 2014, OPT LASER TECHNOL, V57, P327, DOI 10.1016/j.optlastec.2013.05.023
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Lu Q, 2020, IEEE ACCESS, V8, P25664, DOI 10.1109/ACCESS.2020.2970806
   MARKANDEY V, 1992, IEEE T ROBOTIC AUTOM, V8, P186, DOI 10.1109/70.134273
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Muñoz-Rodríguez JA, 2010, IMAGING SCI J, V58, P61, DOI 10.1179/136821909X12520525092765
   Ping P, 2018, NEUROCOMPUTING, V283, P53, DOI 10.1016/j.neucom.2017.12.048
   Ravichandran D, 2021, MED BIOL ENG COMPUT, V59, P589, DOI 10.1007/s11517-021-02328-8
   Sankpal PR, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P102, DOI 10.1109/ICSIP.2014.80
   Sayyouri M, 2016, MULTIMED TOOLS APPL, V75, P547, DOI 10.1007/s11042-014-2307-5
   Shah AA, 2020, J REAL-TIME IMAGE PR, V17, P2139, DOI 10.1007/s11554-020-01008-4
   Si YY, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S021812742250095X
   Si YY, 2021, INT J BIFURCAT CHAOS, V31, DOI 10.1142/S0218127421501467
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Teng L, 2022, INFORM SCIENCES, V605, P71, DOI 10.1016/j.ins.2022.05.032
   Tsougenis ED, 2015, MULTIMED TOOLS APPL, V74, P3985, DOI 10.1007/s11042-013-1808-y
   von Solms R, 2013, COMPUT SECUR, V38, P97, DOI 10.1016/j.cose.2013.04.004
   VonSolms R, 1998, Inf Manag omput Secur
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Wu GC, 2019, CHAOS, V29, DOI 10.1063/1.5096645
   Xiao B, 2020, INFORM SCIENCES, V516, P545, DOI 10.1016/j.ins.2019.12.044
   Yamni M, 2021, J FRANKLIN I, V358, P2535, DOI 10.1016/j.jfranklin.2021.01.011
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Ye GD, 2018, NONLINEAR DYNAM, V94, P745, DOI 10.1007/s11071-018-4391-y
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhao HY, 2022, CHAOS SOLITON FRACT, V164, DOI 10.1016/j.chaos.2022.112742
   Zhao MD, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S021812742250081X
   Zhong HY, 2022, MULTIMED TOOLS APPL, V81, P24757, DOI 10.1007/s11042-022-12479-x
   Zhou J, 2005, LECT NOTES COMPUT SC, V3656, P524, DOI 10.1007/11559573_65
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   Zhu HQ, 2012, PATTERN RECOGN, V45, P1540, DOI 10.1016/j.patcog.2011.10.002
   Zhu SL, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21080790
NR 57
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
DI 10.1007/s11042-023-17034-w
EA OCT 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U0GP6
UT WOS:001081680200001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Modak, SKS
   Jha, VK
AF Modak, Sandip Kumar Singh
   Jha, Vijay Kumar
TI Diabetes prediction model using machine learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Diabetes; Machine learning; SVM; Random Forest and Naive Bayes
AB Diabetes has emerged as a significant global health concern, contributing to various severe complications such as kidney disease, vision loss, and coronary issues. Leveraging machine learning algorithms in medical services has shown promise in accurate disease diagnosis and treatment, thereby alleviating the burden on healthcare professionals. The field of diabetes forecasting has rapidly evolved, offering the potential for early intervention and patient empowerment. To this end, our study presents an innovative diabetes prediction model employing a range of machine learning techniques, including Logistic Regression, SVM, Naive Bayes, and Random Forest. In addition to these foundational techniques, we harness the power of ensemble learning to further enhance prediction accuracy and robustness. Specifically, we explore ensemble methods such as XGBoost, LightGBM, CatBoost, Adaboost, and Bagging. These techniques amalgamate predictions from multiple base learners, yielding a more precise and resilient final prediction. Our proposed framework is developed and trained using Python, utilizing a real-world dataset sourced from Kaggle. Our methodology is rigorously examined through performance evaluation metrics, including the confusion matrix, sensitivity, and accuracy measurements. Among the ensemble techniques tested, CatBoost emerges as the most effective, boasting an impressive accuracy rate of 95.4% compared to XGBoost's 94.3%. Furthermore, CatBoost's higher AUC-ROC score of 0.99 reinforces its potential superiority over XGBoost, which achieved an AUC-ROC score of 0.98.
C1 [Modak, Sandip Kumar Singh] Sarla Birla Univ, Dept Comp Sci & Engn, Ranchi, Jharkhand, India.
   [Jha, Vijay Kumar] Birla Inst Technol, Dept Comp Sci & Engn, Ranchi, India.
C3 Birla Institute of Technology Mesra
RP Modak, SKS (corresponding author), Sarla Birla Univ, Dept Comp Sci & Engn, Ranchi, Jharkhand, India.
EM modaknit@gmail.com; vkjha@bitmesra.ac.in
OI Modak, Sandip Kumar Singh/0000-0001-7985-4161
CR Abdollahi J., 2022, Iran J. Comput. Sci., V5, P205, DOI DOI 10.1007/S42044-022-00100-1
   Alcalá-Fdez J, 2011, IEEE T FUZZY SYST, V19, P857, DOI 10.1109/TFUZZ.2011.2147794
   Aldallal A, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON FRONTIERS OF SIGNAL PROCESSING (ICFSP 2018), P150, DOI 10.1109/ICFSP.2018.8552051
   Resende PAA, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3178582
   Amer Diabet Assoc, 2005, DIABETES CARE, V28, pS37
   Anil Kavyasree S., 2022, 2022 6th International Conference on Trends in Electronics and Informatics (ICOEI), P1696, DOI 10.1109/ICOEI53556.2022.9776754
   Arumugam S.S., 2022, AIP Conference Proceedings, V2405
   Chatrati SP, 2022, J KING SAUD UNIV-COM, V34, P862, DOI 10.1016/j.jksuci.2020.01.010
   Chen H, 2021, EURASIP J ADV SIG PR, V2021, DOI 10.1186/s13634-021-00742-6
   Febrian Muhammad Exell, 2023, Procedia Computer Science, P21, DOI 10.1016/j.procs.2022.12.107
   Fiarni C, 2019, PROCEDIA COMPUT SCI, V161, P449, DOI 10.1016/j.procs.2019.11.144
   Grossi E, 2007, EUR J GASTROEN HEPAT, V19, P1046, DOI 10.1097/MEG.0b013e3282f198a0
   Hammad M, 2022, COMPUT ELECTR ENG, V100, DOI 10.1016/j.compeleceng.2022.108011
   Han Wu, 2018, Informatics in Medicine Unlocked, V10, P100, DOI 10.1016/j.imu.2017.12.006
   Hasan MK, 2020, IEEE ACCESS, V8, P76516, DOI 10.1109/ACCESS.2020.2989857
   Idicula-Thomas S, 2006, BIOINFORMATICS, V22, P278, DOI 10.1093/bioinformatics/bti810
   Islam M. M. Faniqul, 2020, Computer Vision and Machine Intelligence in Medical Image Analysis. International Symposium, ISCMM 2019. Advances in Intelligent Systems and Computing (AISC 992), P113, DOI 10.1007/978-981-13-8798-2_12
   Kalyankar GD, 2017, 2017 INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC), P619, DOI 10.1109/I-SMAC.2017.8058253
   Kaur H, 2022, APPL COMPUT INFORM, V18, P90, DOI 10.1016/j.aci.2018.12.004
   Kavakiotis I, 2017, COMPUT STRUCT BIOTEC, V15, P104, DOI 10.1016/j.csbj.2016.12.005
   Khan FA, 2021, IEEE ACCESS, V9, P43711, DOI 10.1109/ACCESS.2021.3059343
   Khanam JJ, 2021, ICT EXPRESS, V7, P432
   Kumar A, 2020, Advances in Computing and Data Sciences, V4, P507
   Kumari S., 2021, INT J COGN COMPUT EN, V2, P40, DOI [10.1016/j.ijcce.2021.01.001, DOI 10.1016/J.IJCCE.2021.01.001]
   Lee M, 2010, SENSORS-BASEL, V10, P3934, DOI 10.3390/s100403934
   Luo J, 2022, BMC MED INFORM DECIS, V22, DOI 10.1186/s12911-022-02022-1
   Luo J, 2022, DIGEST LIVER DIS, V54, P1513, DOI 10.1016/j.dld.2022.04.025
   Mahesh T R, 2022, Comput Intell Neurosci, V2022, P9005278, DOI 10.1155/2022/9005278
   Maniruzzaman M, 2020, HEALTH INF SCI SYST, V8, DOI 10.1007/s13755-019-0095-z
   Mavrogiorgou A, 2021, INT CONF INFORM COMM, P49, DOI 10.1109/ICICS52457.2021.9464551
   Oza Ami, 2022, Congress on Intelligent Systems: Proceedings of CIS 2021. Lecture Notes on Data Engineering and Communications Technologies (111), P407, DOI 10.1007/978-981-16-9113-3_30
   Paisanwarakiat R, 2022, LECT NOTE NETW SYST, V453, P88, DOI 10.1007/978-3-030-99948-3_9
   Pathoee K., 2022, Int J Cloud Appl Comput (IJCAC), V12, P1
   Rastogi R., 2023, Meas. Sens, V25, P100605, DOI [10.1016/j.measen.2022.100605, DOI 10.1016/J.MEASEN.2022.100605]
   Saeedi P, 2019, DIABETES RES CLIN PR, V157, DOI 10.1016/j.diabres.2019.107843
   Sarstedt M., 2014, Regression Analysis, DOI [10.1007/978-3-642-53965-7_7, DOI 10.1007/978-3-642-53965-7_7]
   Sedik A, 2022, NEURAL COMPUT APPL, V34, P11423, DOI 10.1007/s00521-020-05410-8
   Seka S, 2021, Webology, V18, P6
   Shi N, 2010, 2010 THIRD INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY AND SECURITY INFORMATICS (IITSI 2010), P63, DOI 10.1109/IITSI.2010.74
   Sisodia Deepti, 2018, Procedia Computer Science, V132, P1578, DOI 10.1016/j.procs.2018.05.122
   Song Yan-Yan, 2015, Shanghai Arch Psychiatry, V27, P130, DOI 10.11919/j.issn.1002-0829.215044
   Sun YL, 2019, TEH VJESN, V26, P872, DOI 10.17559/TV-20190421122826
   Tasin I, 2023, HEALTHC TECHNOL LETT, V10, P1, DOI 10.1049/htl2.12039
   Woldemichael F. G., 2018, P 2 INT C TRENDS EL, P414, DOI [DOI 10.1109/ICOEI.2018.8553959, 10.1109/ICOEI.2018.8553959]
   Yoo I, 2012, J MED SYST, V36, P2431, DOI 10.1007/s10916-011-9710-5
   Zamzami IF, 2022, INT J INTELL SYST, V37, P11742, DOI 10.1002/int.23061
   Zhang Y, 2012, INFORM COMPUTING APP
NR 47
TC 2
Z9 2
U1 20
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 5
PY 2023
DI 10.1007/s11042-023-16745-4
EA OCT 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T4FV3
UT WOS:001077571000001
DA 2024-07-18
ER

PT J
AU Rani, M
   Yadav, J
   Rathee, N
   Goyal, S
AF Rani, Mamta
   Yadav, Jyoti
   Rathee, Neeru
   Goyal, Sonal
TI Efficient fused convolution neural network (EFCNN) for feature level
   fusion of medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Medical image fusion; Evaluation metrics; CNN; De-Noising filters;
   Fusion rule
AB This paper proposes an Efficient Fused Convolution Neural Network (EFCNN) for feature-level fusion of medical images. The proposed network architecture leverages the strengths of both deep Convolution Neural Networks (CNNs) and fusion techniques to achieve improved efficiency in medical image fusion. Image fusion of CT and MRI images can help medical professionals to make more informed diagnosis, plan more effective treatments, and ultimately improve patient outcomes. Recently many researchers are working to develop efficient medical fusion technique. To contribute to this field, authors have attempted to fuse images at feature level using Bilinear Activation Function (BAM) for feature extraction and softmax based Soft Attention (SA) fusion rule for fusion. The EFCNN model uses a two-stream CNN architecture to process input images, which are then fused at the feature level using an attention mechanism. The proposed approach is evaluated on Whole Brain Atlas Harvard dataset. The EFCNN model demonstrated superior performance in various performance indices, including ISSIM, MI, and PSNR, with respective values of 0.41, 4.42, and 57.21 when SA was utilized. Furthermore, the proposed model exhibited favourable performance in terms of Spatial Frequency, Average Gradient, and Edge-intensity, with corresponding values of 57.3, 16.83, and 157.72 on a medical dataset when EFCNN was applied without SA fusion. However, subjective evaluation indicated that images were improved with SA fusion. These results indicate that the EFCNN model surpasses state-of-the-art methods. An exhaustive ablation study was conducted to investigate the efficacy of the proposed model, which further confirmed its accuracy. The significance of this work is its potential implications for medical diagnosis and treatment planning, where precise and efficient image analysis is crucial.
C1 [Rani, Mamta; Yadav, Jyoti; Goyal, Sonal] Netaji Subhash Univ Technol, ICE Dept, Dwarka Main campus, New Delhi 110059, India.
   [Rani, Mamta] Maharaja Surajmal Inst Technol, EEE, Fire Stn Rd,c-4 janakpuri, New Delhi 110058, India.
   [Rathee, Neeru] Maharaja Surajmal Inst Technol, ECE, Fire Stn Rd,c-4 janakpuri, New Delhi 110058, India.
C3 Netaji Subhas University of Technology; Maharaja Surajmal Institute of
   Technology; Maharaja Surajmal Institute of Technology
RP Rani, M (corresponding author), Netaji Subhash Univ Technol, ICE Dept, Dwarka Main campus, New Delhi 110059, India.; Rani, M (corresponding author), Maharaja Surajmal Inst Technol, EEE, Fire Stn Rd,c-4 janakpuri, New Delhi 110058, India.
EM mamtatholia@gmail.com; bmjyoti@gmail.com; neeru1rathee@gmail.com;
   sonal.goyal@nsut.ac.in
RI yadav, jyoti/K-7924-2012
OI Rani, mamta/0000-0001-5213-261X
CR Bavirisetti DP, 2016, IEEE SENS J, V16, P203, DOI 10.1109/JSEN.2015.2478655
   Cheng CY, 2023, INFORM FUSION, V92, P80, DOI 10.1016/j.inffus.2022.11.010
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding ZS, 2023, COMPUT BIOL MED, V159, DOI 10.1016/j.compbiomed.2023.106923
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Goyal S, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103214
   He KM, 2015, Arxiv, DOI [arXiv:1512.03385, 10.48550/arxiv.1512.03385]
   Jin ZR, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4315, DOI 10.1145/3474085.3475571
   Johnson KA., 2001, The whole brain atlas
   Lahoud F, 2019, 2019 22ND INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION 2019), DOI 10.23919/fusion43075.2019.9011178
   Li H, 2021, PATTERN RECOGN LETT, V141, P45, DOI 10.1016/j.patrec.2020.11.014
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Li WS, 2022, BIOMED SIGNAL PROCES, V74, DOI 10.1016/j.bspc.2022.103534
   Li XS, 2021, INFORM SCIENCES, V569, P302, DOI 10.1016/j.ins.2021.04.052
   Liu JY, 2023, INFORM FUSION, V91, P205, DOI 10.1016/j.inffus.2022.09.030
   Liu Y, 2022, INFORM FUSION, V86-87, P1, DOI 10.1016/j.inffus.2022.06.001
   Liu Y, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500182
   Liu Y, 2017, 2017 20TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1070
   Ma JY, 2020, IEEE T IMAGE PROCESS, V29, P4980, DOI 10.1109/TIP.2020.2977573
   Naidu VPS, 2010, DEFENCE SCI J, V60, P48, DOI 10.14429/dsj.60.105
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Rajalingam B, 2022, MULTIMEDIA SYST, V28, P1449, DOI 10.1007/s00530-020-00706-0
   Rajalingam B, 2018, Int J Eng Sci Invent, V2, P5260
   Rani M, 2022, 2022 IEEE DELH SECT, P1
   Reddy MG, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102618
   Roberts JW, 2008, J APPL REMOTE SENS, V2, DOI 10.1117/1.2945910
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Si YC, 2021, J APPL SCI ENG, V24, P299, DOI 10.6180/jase.202106_24(3).0004
   Wang CJ, 2021, INFORM FUSION, V67, P147, DOI 10.1016/j.inffus.2020.10.015
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang C, 2008, INFORM FUSION, V9, P156, DOI 10.1016/j.inffus.2006.09.001
   Zhang GC, 2023, BIOMED SIGNAL PROCES, V81, DOI 10.1016/j.bspc.2022.104545
   Zhang XC, 2020, IEEE COMPUT SOC CONF, P468, DOI 10.1109/CVPRW50498.2020.00060
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhang Y, 2017, INFRARED PHYS TECHN, V83, P227, DOI 10.1016/j.infrared.2017.05.007
   Zhao WD, 2019, IEEE T CIRC SYST VID, V29, P1102, DOI 10.1109/TCSVT.2018.2821177
   Zhao Zixiang, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P5906, DOI 10.1109/CVPR52729.2023.00572
   Zhou TF, 2023, MED IMAGE ANAL, V83, DOI 10.1016/j.media.2022.102599
   Zhou TF, 2020, AAAI CONF ARTIF INTE, V34, P13066
   Zhou ZQ, 2016, INFORM FUSION, V30, P15, DOI 10.1016/j.inffus.2015.11.003
NR 40
TC 1
Z9 1
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 2
PY 2023
DI 10.1007/s11042-023-16872-y
EA OCT 2023
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1KJ9
UT WOS:001082459100003
DA 2024-07-18
ER

PT J
AU Liu, ZQ
AF Liu, Zhiqiang
TI Unsupervised clustering for intrinsic mode functions selection in
   Hyperspectral image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hyperspectral image classification; Intrinsic mode function; Ensemble
   empirical model decomposition; K-means; Hierarchical clustering
ID NEURAL-NETWORK; DECOMPOSITION; ALGORITHM
AB In the realm of hyperspectral image classification, traditional methods typically eliminate spectrum noise to enhance spectral features, followed by the application of supervised techniques to improve classification efficiency. However, the use of ensemble empirical model decomposition (EEMD) has gained attention in recent years for its ability to select intrinsic mode functions (IMFs) and reconstruct a new spectrum. Nevertheless, concerns arise regarding the potential suboptimality of selected IMFs and their impact on classification accuracy. To address this issue, our study leverages EEMD to decompose each substance's spectrum into multiple IMFs, which are then clustered using K-means and hierarchical clustering. The proposed unsupervised clustering approach combines IMFs with similar features to create a new spectrum. Notably, our model surpasses the limitations of suboptimal IMF selection, leading to enhanced classification accuracy. Extensive experiments were conducted on hyperspectral data contaminated with high noise signals. The evaluation metrics employed encompassed accuracy as the primary measure. Our model demonstrated superior performance, achieving a significant improvement in accuracy from 0.6640 to 0.9177 compared to previous approaches. In conclusion, our proposed model introduces advancements by incorporating EEMD and unsupervised clustering techniques. The experimental results substantiate its superiority in achieving higher classification accuracy, overcoming the limitations of traditional methods. This study contributes to the field of hyperspectral image classification by offering an effective solution that addresses the challenges posed by suboptimal IMF selection.
C1 [Liu, Zhiqiang] Putian Univ, Dept Mech Elect & Informat Engn, Putian 351100, Fujian, Peoples R China.
C3 Putian University
RP Liu, ZQ (corresponding author), Putian Univ, Dept Mech Elect & Informat Engn, Putian 351100, Fujian, Peoples R China.
EM zchxliu@126.com
CR Ashouri M, 2018, SSRN Electron. J., DOI [10.2139/ssrn.3282849, DOI 10.2139/SSRN.3282849]
   Aydemir MS, 2019, IEEE J-STARS, V12, P3615, DOI 10.1109/JSTARS.2019.2921033
   Boudraa AO, 2005, Int J Signal Process, DOI [10.1063/1.3271040, DOI 10.1063/1.3271040]
   Cavallo B, 2015, QUAL QUANT, V49, P1647, DOI 10.1007/s11135-014-0077-9
   Chang C. I., 2003, HYPERSPECTRAL IMAGIN
   [杜云朋 Du Yunpeng], 2013, [电子测量与仪器学报, Journal of Electronic Measurement and Instrument], V27, P683
   Du YZ, 2003, P SOC PHOTO-OPT INS, V5093, P430, DOI 10.1117/12.487044
   Fan F, 2017, INFORM SCIENCES, V397, P48, DOI 10.1016/j.ins.2017.02.044
   Gavrovska A, 2013, Signals, Circuits and Systems (ISSCS), P1, DOI [10.1109/isscs.2013.6651264, DOI 10.1109/ISSCS.2013.6651264]
   Ghodratigohar M, 2020, IEEE SENS J, V20, P1400, DOI 10.1109/JSEN.2019.2946132
   Hawinkel P, 2015, REMOTE SENS ENVIRON, V169, P375, DOI 10.1016/j.rse.2015.08.024
   He Z, 2014, IEEE T INSTRUM MEAS, V63, P1041, DOI 10.1109/TIM.2014.2298153
   Jiang JJ, 2019, IEEE T GEOSCI REMOTE, V57, P851, DOI 10.1109/TGRS.2018.2861992
   Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637
   Krishnan A, 2019, Hyperspectral Imaging Analysis and Applications for Food Quality, P195
   Li JW, 2018, RSC ADV, V8, P8558, DOI 10.1039/c7ra13202f
   Li Y, 2019, IEEE ACCESS, V7, P72647, DOI 10.1109/ACCESS.2019.2920436
   Li YX, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9110256
   Likas A, 2003, PATTERN RECOGN, V36, P451, DOI 10.1016/S0031-3203(02)00060-2
   Lv XW, 2019, INT J REMOTE SENS, V40, P506, DOI 10.1080/01431161.2018.1513666
   Peng T, 2017, ENERG CONVERS MANAGE, V153, P589, DOI 10.1016/j.enconman.2017.10.021
   Rakshit M, 2018, BIOMED SIGNAL PROCES, V40, P140, DOI 10.1016/j.bspc.2017.09.020
   Ramirez A, 2012, PROC SPIE, V8401, DOI 10.1117/12.926417
   Ren H, 2014, REMOTE SENS-BASEL, V6, P2069, DOI 10.3390/rs6032069
   Shen Y, 2012, Hyperspectral image classification based on ensemble empirical mode decomposition, DOI [10.1007/978-3-642-27329-2_72, DOI 10.1007/978-3-642-27329-2_72]
   [孙曙光 Sun Shuguang], 2016, [电力系统保护与控制, Power System Protection and Control], V44, P42
   Tao XM, 2019, KNOWL-BASED SYST, V170, P26, DOI 10.1016/j.knosys.2019.01.026
   Wang AL, 2019, REMOTE SENS LETT, V10, P1086, DOI 10.1080/2150704X.2019.1649736
   Wang K, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8040344
   Wang WC, 2015, WATER RESOUR MANAG, V29, P2655, DOI 10.1007/s11269-015-0962-6
   Wu ZH, 2009, ADV DATA SCI ADAPT, V1, P1, DOI 10.1142/S1793536909000047
   Xie FD, 2019, INT J REMOTE SENS, V40, P3344, DOI 10.1080/01431161.2018.1541366
   Yan Q, 2019, COGN SYST RES, V53, P98, DOI 10.1016/j.cogsys.2018.01.003
   Yang GL, 2015, SIGNAL PROCESS, V109, P95, DOI 10.1016/j.sigpro.2014.10.038
   Zhang Y, 2016, MECH SYST SIGNAL PR, V68-69, P316, DOI 10.1016/j.ymssp.2015.06.020
   Zheng L, 2018, KNOWL-BASED SYST, V141, P200, DOI 10.1016/j.knosys.2017.11.017
NR 36
TC 0
Z9 0
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 30
PY 2023
DI 10.1007/s11042-023-16884-8
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T4DY8
UT WOS:001077522300010
DA 2024-07-18
ER

PT J
AU Mahadik, SS
   Pawar, PM
   Muthalagu, R
AF Mahadik, Shalaka S.
   Pawar, Pranav M.
   Muthalagu, Raja
TI Heterogeneous IoT (HetIoT) security: techniques, challenges and open
   issues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Heterogeneous IoT; Lightweight cryptography; Intelligent security; Deep
   learning; Deep reinforcement learning; Lightweight access control
ID INDUSTRIAL INTERNET; INTRUSION DETECTION; THINGS; PRIVACY; ATTACKS;
   AUTHENTICATION; TECHNOLOGIES; MECHANISM; FRAMEWORK; NETWORKS
AB The HetIoT is a new emergent technology widely used to offer QoS to applications such as health monitoring systems, agriculture 4.0, traffic monitoring, industry 4.0, and civil defense, to name a few. These applications are in high demand as the world is heading towards 6G technology that facilitates a high data transfer rate and faster connectivity. However, technological leaps open the door to invaders, triggering security breaches. Therefore, the article aims to entail security challenges and issues from the HetIoT viewpoint. The conventional approaches need to be revised to handle new trends of security holes and demand advancement in them. As a result, the article systematically reviews the current state-of-the-art traditional techniques, including cryptography, privacy and trust, and access control mechanism. The article exhibits its challenges, open issues, and solution as lightweight protocols and lightweight cryptography concerning traditional approaches. In recent years, a lot of concentration is towards developing intelligent security (IS) mechanisms for HetIoT. Intelligent techniques are data-hungry, and HetIoT emits massive amounts of data, so the use of IS techniques to safeguard the HetIoT is an ideal solution. Therefore, the article also concentrates on IS techniques, including machine learning (ML), deep learning (DL), and deep reinforcement learning (DRL), along with their challenges and open issues. Further, the article details the available benchmarking security-based dataset and experimental tools, platforms, and simulators for the HetIoT. Finally, the review article discusses open research issues and future trends for achieving high security in the HetIoT context.
C1 [Mahadik, Shalaka S.; Pawar, Pranav M.; Muthalagu, Raja] Birla Inst Technol & Sci Pilani, Dept Comp Sci, Dubai Campus, Dubai, U Arab Emirates.
RP Pawar, PM (corresponding author), Birla Inst Technol & Sci Pilani, Dept Comp Sci, Dubai Campus, Dubai, U Arab Emirates.
EM pranav@dubai.bits-pilani.ac.in
RI Pawar, Pranav M/G-8657-2019
OI Pawar, Pranav M/0000-0001-8193-7388; Mahadik, Dr.
   Shalaka/0000-0001-8230-8161
CR Abdullahi M, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11020198
   Ahmad K, 2022, COMPUT SCI REV, V43, DOI 10.1016/j.cosrev.2021.100452
   Al-Hawawreh M, 2021, IEEE T NETW SCI ENG, V8, P2968, DOI 10.1109/TNSE.2020.3032415
   Alaba FA, 2017, J NETW COMPUT APPL, V88, P10, DOI 10.1016/j.jnca.2017.04.002
   Alamri HA, 2020, IEEE ACCESS, V8, P194269, DOI 10.1109/ACCESS.2020.3033942
   Amanullah MA, 2020, COMPUT COMMUN, V151, P495, DOI 10.1016/j.comcom.2020.01.016
   [Anonymous], 2020, IoT-cyber stories
   [Anonymous], 2021, Cloud related threats to IoT Technology
   Assis MVO, 2021, J NETW COMPUT APPL, V177, DOI 10.1016/j.jnca.2020.102942
   Aubet F.-X., 2018, DS2os traffic traces: IoT traffic
   Aydos M, 2019, MEAS CONTROL-UK, V52, P338, DOI 10.1177/0020294019837991
   Badamasi UM., 2020, INT J COMPUT NETW CO, V8, P93
   Bhoyar P, 2019, AEU-INT J ELECTRON C, V99, P81, DOI 10.1016/j.aeue.2018.11.031
   Borgini J, 2021, Machine learning in IoT security
   Chaudhry SA, 2021, SUSTAIN CITIES SOC, V75, DOI 10.1016/j.scs.2021.103322
   Chen IR, 2016, IEEE T DEPEND SECURE, V13, P684, DOI 10.1109/TDSC.2015.2420552
   Chen ZY, 2021, DIGIT COMMUN NETW, V7, P317, DOI 10.1016/j.dcan.2021.04.001
   Chesney Steve, 2021, Intelligent Systems and Applications. Proceedings of the 2020 Intelligent Systems Conference (IntelliSys). Advances in Intelligent Systems and Computing (AISC 1252), P679, DOI 10.1007/978-3-030-55190-2_53
   Dankwa S, 2021, IEEE INT SYM BROADB, DOI 10.1109/BMSB53066.2021.9547185
   Dao N-N, 2021, IEEE Systems Journal IEEE, P1
   Das AK, 2019, IEEE ACCESS, V7, P55382, DOI 10.1109/ACCESS.2019.2912998
   de Assis MVO, 2020, COMPUT ELECTR ENG, V86, DOI 10.1016/j.compeleceng.2020.106738
   De Rango F, 2020, IEEE CONF COMPUT, P842, DOI 10.1109/INFOCOMWKSHPS50562.2020.9162902
   Dhillon PK, 2017, J INF SECUR APPL, V34, P255, DOI 10.1016/j.jisa.2017.01.003
   Du M, 2018, IEEE COMMUN MAG, V56, P62, DOI 10.1109/MCOM.2018.1701148
   Elsayed MS, 2020, I S WORLD WIREL MOBI, P391, DOI 10.1109/WoWMoM49955.2020.00072
   Faheem M, 2022, DATA BRIEF, V42, DOI 10.1016/j.dib.2022.108026
   Faheem M, 2021, J IND INF INTEGR, V24, DOI 10.1016/j.jii.2021.100236
   Faheem M, 2021, DATA BRIEF, V35, DOI 10.1016/j.dib.2021.106854
   Farris I, 2019, IEEE COMMUN SURV TUT, V21, P812, DOI 10.1109/COMST.2018.2862350
   Feng WJ, 2017, IEEE IJCNN, P681, DOI 10.1109/IJCNN.2017.7965918
   Ferrag MA, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10111257
   Frikha MS, 2021, COMPUT COMMUN, V178, P98, DOI 10.1016/j.comcom.2021.07.014
   Frustaci M, 2018, IEEE INTERNET THINGS, V5, P2483, DOI 10.1109/JIOT.2017.2767291
   Garcia S, 2023, IoT23: A labeled dataset with malicious and benign IoT network traffic (version 1.0. 0)
   Gu Z, 2020, Convolution neural network-based higher accurate intrusion identification system for the network security and communication, V2020
   Guo C, 2020, IEEE INTERNET THINGS, V7, P3104, DOI 10.1109/JIOT.2020.2964412
   Guo XC, 2020, IEEE INTERNET THINGS, V7, P6242, DOI 10.1109/JIOT.2019.2960033
   HaddadPajouh H, 2021, INTERNET THINGS-NETH, V14, DOI 10.1016/j.iot.2019.100129
   Hafeez I, 2019, INT CONF PERVAS COMP, P196, DOI [10.1109/PERCOMW.2019.8730787, 10.1109/percomw.2019.8730787]
   Hasan M, 2019, INTERNET THINGS-NETH, V7, DOI 10.1016/j.iot.2019.100059
   Hassija V, 2019, IEEE ACCESS, V7, P82721, DOI 10.1109/ACCESS.2019.2924045
   Himeur Y, 2022, COMPUT SCI REV, V43, DOI 10.1016/j.cosrev.2021.100439
   Hussain H, 2022, ARTIF INTELL REV, V55, P5109, DOI 10.1007/s10462-022-10138-z
   Iqbal MA, 2017, Global Journal of Computer Science and Technology
   Islam N, 2021, CMC-COMPUT MATER CON, V69, P1801, DOI 10.32604/cmc.2021.018466
   Ahmed KI, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21155122
   Jaikla T, 2019, 2019 INT C SOFTW TEL, P1
   Javeed D, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10080918
   Jia YZ, 2020, IEEE INTERNET THINGS, V7, P9552, DOI 10.1109/JIOT.2020.2993782
   Joseph DS, 2023, MULTIMED TOOLS APPL, V82, P21415, DOI 10.1007/s11042-022-14004-6
   Kang Hyunjae, 2019, IEEE DataPort
   kaspersky, 2016, Kaspersky security
   Kavianpour S, 2019, J COMPUT NETW COMMUN, V2019, DOI 10.1155/2019/5747136
   Kodys M, 2021, 2021 18TH INTERNATIONAL CONFERENCE ON PRIVACY, SECURITY AND TRUST (PST), DOI 10.1109/PST52912.2021.9647828
   Kouicem DE, 2018, 2018 13TH ANNUAL CONFERENCE ON SYSTEM OF SYSTEMS ENGINEERING (SOSE), P138, DOI 10.1109/SYSOSE.2018.8428732
   Kumar S, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0268-2
   Latif S, 2020, IEEE ACCESS, V8, P89337, DOI 10.1109/ACCESS.2020.2994079
   Li J, 2017, IEEE ACCESS, V5, P19154, DOI 10.1109/ACCESS.2017.2756446
   Liang W, 2020, IEEE INTERNET THINGS, V7, P6392, DOI 10.1109/JIOT.2020.2974281
   Lin C, 2020, IEEE INTERNET THINGS, V7, P818, DOI 10.1109/JIOT.2019.2944400
   Lin J, 2017, IEEE INTERNET THINGS, V4, P1125, DOI 10.1109/JIOT.2017.2683200
   Liu D, 2019, IEEE INTERNET THINGS, V6, P4946, DOI 10.1109/JIOT.2019.2897619
   Liu J, 2019, IEEE INT C COMM ICC, P1
   Liu X, 2021, COMPUT COMMUN, V168, P20, DOI 10.1016/j.comcom.2020.12.013
   Loffi L, 2021, J NETW COMPUT APPL, V176, DOI 10.1016/j.jnca.2020.102932
   Lu JQ, 2022, IEEE T IND INFORM, V18, P5422, DOI 10.1109/TII.2021.3112601
   Lu Y, 2019, IEEE INTERNET THINGS, V6, P2103, DOI 10.1109/JIOT.2018.2869847
   Luo M, 2019, WIRELESS PERS COMMUN, V109, P505, DOI 10.1007/s11277-019-06576-8
   Luo X, 2020, IEEE ACCESS, V8, P67192, DOI 10.1109/ACCESS.2020.2978525
   Lv ZH, 2021, IEEE INTERNET THINGS, V8, P9531, DOI 10.1109/JIOT.2020.3007130
   Mahadik S, 2023, J NETW SYST MANAG, V31, DOI 10.1007/s10922-022-09697-x
   Mahadik SS, 2022, INT SYMP WIREL, DOI 10.1109/WPMC55625.2022.10014866
   Malina L, 2016, COMPUT NETW, V102, P83, DOI 10.1016/j.comnet.2016.03.011
   Meidan Y, 2018, IEEE PERVAS COMPUT, V17, P12, DOI 10.1109/MPRV.2018.03367731
   Miao QY, 2021, COMPUT NETW, V197, DOI 10.1016/j.comnet.2021.108327
   Moh M, 2018, PROCEEDINGS 2018 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), P709, DOI 10.1109/HPCS.2018.00116
   Moustafa N, 2019, IEEE INTERNET THINGS, V6, P4815, DOI 10.1109/JIOT.2018.2871719
   Muthalagu Raja, 2021, International Journal of Computers and Applications, V43, P805, DOI 10.1080/1206212X.2019.1619988
   networksimulationtools, 2023, Mininet network creation
   Nie LS, 2022, IEEE T COMPUT SOC SY, V9, P134, DOI 10.1109/TCSS.2021.3063538
   Noor MBM, 2019, COMPUT NETW, V148, P283, DOI 10.1016/j.comnet.2018.11.025
   Özçelik M, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (CIT), P308, DOI 10.1109/CIT.2017.61
   Patidar Sanjay, 2020, 2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT), P848, DOI 10.1109/ICSSIT48917.2020.9214114
   Pawar PM, 2018, IEEE GLOB CONF WIREL, P119, DOI 10.1109/GCWCN.2018.8668613
   Pawar Pranav M, 2012, Journal of Cyber Security and Mobility, V1, P205, DOI [10.13052/jcsm2245-1439.1234, DOI 10.13052/JCSM2245-1439.1234]
   Perez AJ, 2022, COMPUT SCI REV, V43, DOI 10.1016/j.cosrev.2021.100450
   Pohrmen FH, 2019, T EMERG TELECOMMUN T, V30, DOI 10.1002/ett.3741
   Pourghebleh B, 2019, IEEE INTERNET THINGS, V6, P9326, DOI 10.1109/JIOT.2019.2933518
   Qiu T, 2018, IEEE COMMUN SURV TUT, V20, P2011, DOI 10.1109/COMST.2018.2803740
   Qiu T, 2017, AD HOC NETW, V55, P143, DOI 10.1016/j.adhoc.2016.11.001
   Rahman O, 2019, IEEE WORLD CONGR SER, P184, DOI 10.1109/SERVICES.2019.00051
   Ray PP, 2018, J KING SAUD UNIV-COM, V30, P291, DOI 10.1016/j.jksuci.2016.10.003
   Rehman SU, 2021, FUTURE GENER COMP SY, V118, P453, DOI 10.1016/j.future.2021.01.022
   Remesh A, 2020, IEEE 826-830
   Ring M, 2019, COMPUT SECUR, V86, P147, DOI 10.1016/j.cose.2019.06.005
   Samaila MG, 2018, P 13 INT C AV REL SE
   Sánchez-Arias G, 2017, FUTURE GENER COMP SY, V74, P444, DOI 10.1016/j.future.2017.01.033
   Sasirekha S, 2018, Advances in electronics, communication and computing, P351
   Sharma A, 2020, COMPUT COMMUN, V160, P475, DOI 10.1016/j.comcom.2020.06.030
   Shin H, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN INFORMATION AND COMMUNICATION (ICAIIC 2019), P381, DOI [10.1109/ICAIIC.2019.8669029, 10.1109/icaiic.2019.8669029]
   Shu L, 2018, IEEE SYST J, V12, P2509, DOI 10.1109/JSYST.2017.2700268
   Siddiqui F, 2021, INTERNET THINGS-NETH, V14, DOI 10.1016/j.iot.2019.100093
   Singh D., 2020, Int J Sci Technol Res, V9, P2762, DOI 10.13140/RG.2.2.32754.04803
   snort, 2023, Snort tool
   Sumathi S, 2021, J AMB INTEL HUM COMP, V12, P5943, DOI 10.1007/s12652-020-02144-2
   Tewari A, 2020, FUTURE GENER COMP SY, V108, P909, DOI 10.1016/j.future.2018.04.027
   Nguyen TT, 2023, IEEE T NEUR NET LEAR, V34, P3779, DOI 10.1109/TNNLS.2021.3121870
   Nguyen TD, 2018, IEEE T GREEN COMMUN, V2, P1115, DOI 10.1109/TGCN.2018.2839593
   Thorat P, 2020, 2020 IEEE INT C EL C, P1
   Tzagkarakis C, 2019, 2019 GLOBAL IOT SUMMIT (GIOTS), DOI 10.1109/giots.2019.8766388
   Ubale Tushar, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P956, DOI 10.1109/ICECA.2018.8474561
   Ullah F, 2019, IEEE ACCESS, V7, P124379, DOI 10.1109/ACCESS.2019.2937347
   Ullah I, 2020, IEEE SYS MAN CYBERN, P134, DOI [10.1109/SMC42975.2020.9283220, 10.1109/smc42975.2020.9283220]
   Ullah I, 2022, CMC-COMPUT MATER CON, V70, P4307, DOI 10.32604/cmc.2022.017380
   Uprety A, 2021, IEEE INTERNET THINGS, V8, P8693, DOI 10.1109/JIOT.2020.3040957
   Venkatesh Raghav, 2020, Journal of Physics: Conference Series, V1706, DOI 10.1088/1742-6596/1706/1/012167
   Vijayakumar P, 2022, IEEE T INTELL TRANSP, V23, P1630, DOI 10.1109/TITS.2021.3099488
   Vijayakumar P, 2020, IEEE T IND INFORM, V16, P2603, DOI 10.1109/TII.2019.2925071
   Wang D, 2019, IEEE ACCESS, V7, P54508, DOI 10.1109/ACCESS.2019.2913438
   Wani Azka, 2020, Journal of the Institution of Engineers (India): Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V101, P117, DOI 10.1007/s40031-020-00442-z
   Wazid M, 2020, IEEE GLOB COMM CONF, DOI 10.1109/GLOBECOM42002.2020.9322212
   Xia XY, 2021, INT J DISTRIB SENS N, V17, DOI 10.1177/15501477211026804
   Yang B, 2019, IEEE T WIREL COMMUN, V18, P3697, DOI 10.1109/TWC.2019.2917131
   Yang YC, 2017, IEEE INTERNET THINGS, V4, P1250, DOI 10.1109/JIOT.2017.2694844
   Younan M, 2020, MEASUREMENT, V151, DOI 10.1016/j.measurement.2019.107198
   Yue YW, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/8873195
   Zecheng He, 2017, 2017 IEEE 4th International Conference on Cyber-Security and Cloud Computing (CSCloud), P114, DOI 10.1109/CSCloud.2017.58
   Zhang SB, 2020, IEEE INTERNET THINGS, V7, P3404, DOI 10.1109/JIOT.2020.2969466
   Zhao R, 2020, PHYS COMMUN-AMST, V43, DOI 10.1016/j.phycom.2020.101184
   Zheng SX, 2017, PR MACH LEARN RES, V70
NR 131
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-16715-w
EA SEP 2023
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600024
DA 2024-07-18
ER

PT J
AU Pradhan, A
   Srivastava, S
AF Pradhan, Anushka
   Srivastava, Subodh
TI Hybrid densenet with long short-term memory model for multi-modal
   emotion recognition from physiological signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-modal signals; Emotion recognition; Channel attention; Squeezenet;
   Arithmetic optimization algorithm; Densenet; Long short term memory
   network
AB Recognition of emotions from multi-modal physiological signals is one among the toughest tasks prevailing amid the research communities. Most existing works have focused on emotion recognition (ER) from single modal signals, which is now ineffective. Certain models considered multiple modalities, but the results obtained are not satisfactory, and there is still a possibility for improvement in accuracy. Therefore, this work introduces a novel and effective mechanism by embedding multiple techniques to achieve the required task. The projected approach includes stages like pre-processing, signal-to-image conversion, feature extraction, feature selection and classification. Each signal modality is separately pre-processed, and the results are provided to a complex dual tree with fast lifting wavelet transform (CTFL-WT) to convert the signals into images. The converted images are sent to the channel attentive squeezenet (CASN) model for feature extraction. The obtained features are then reduced with the help of an adaptive arithmetic optimization algorithm (AAOA). The reduced features are then provided to the hybrid densenet with long short term memory (DLSTM) for accurate labelling. The projected work resulted in the classification of three different emotions such as neutral, stress and amusement. The implementations are performed in the Python platform, and the evaluations are done using the wearable stress and affect detection (WESAD) dataset. In comparison, the proposed work resulted in an overall accuracy value of 99% and an overall F1-score value of 97.84%.
C1 [Pradhan, Anushka; Srivastava, Subodh] Natl Inst Technol Patna, Dept ECE, Patna 800005, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Pradhan, A (corresponding author), Natl Inst Technol Patna, Dept ECE, Patna 800005, Bihar, India.
EM anushkap.phd19.ec@nitp.ac.in
CR Abdullah SMSA., 2021, Journal of Applied Science and Technology Trends, V2, P52
   Abualigah L, 2021, COMPUT METHOD APPL M, V376, DOI 10.1016/j.cma.2020.113609
   Ahmad Z, 2022, BIOENGINEERING-BASEL, V9, DOI 10.3390/bioengineering9110688
   Aung ST, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/6000989
   Baghizadeh M, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101902
   Bhatti A, 2021, 2021 9TH INTERNATIONAL CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION WORKSHOPS AND DEMOS (ACIIW), DOI 10.1109/ACIIW52867.2021.9666360
   Bhatti A, 2022, Arxiv, DOI arXiv:2206.04625
   Jimenez IAC, 2023, INT J INTERACT DES M, V17, P45, DOI 10.1007/s12008-022-01087-6
   Chatterjee D, 2022, INNOV SYST SOFTW ENG, DOI 10.1007/s11334-022-00470-6
   Cheng WX, 2022, ENG APPL ARTIF INTEL, V116, DOI 10.1016/j.engappai.2022.105349
   Dissanayake V, 2022, IEEE ACCESS, V10, P18105, DOI 10.1109/ACCESS.2022.3149509
   Fouladgar N, 2022, NEURAL COMPUT APPL, V34, P2157, DOI 10.1007/s00521-021-06516-3
   Hasnul MA, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21155015
   Hassan MM, 2019, INFORM FUSION, V51, P10, DOI 10.1016/j.inffus.2018.10.009
   Jiang YY, 2020, INFORM FUSION, V53, P209, DOI 10.1016/j.inffus.2019.06.019
   Li W, 2021, MEASUREMENT, V172, DOI 10.1016/j.measurement.2020.108747
   Liakopoulos L., 2021, 2021 12 INT C INF IN, P1
   Liapis A, 2021, LECT NOTES COMPUT SC, V12934, P238, DOI 10.1007/978-3-030-85613-7_17
   Maria E, 2019, ELECTRON NOTES THEOR, V343, P35, DOI 10.1016/j.entcs.2019.04.009
   Mekruksavanich S, 2022, 2022 19 INT C EL ENG, P1
   Mendoza A, 2020, INF MAN BIG DAT 7 AN, P90
   Nigam K, 2021, EAI ENDORSED TRANS S, V8, DOI 10.4108/eai.14-5-2021.169919
   Quispe KGM, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22239102
   Saganowski S, 2020, INT CONF PERVAS COMP, DOI 10.1109/percomworkshops48775.2020.9156096
   Sarkar P, 2022, IEEE T AFFECT COMPUT, V13, P1541, DOI 10.1109/TAFFC.2020.3014842
   Schmidt P, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P400, DOI 10.1145/3242969.3242985
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Suhaimi NS, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8875426
   Theerthagiri P, 2023, MULTIMED TOOLS APPL, V82, P5949, DOI [10.1007/S11042-022-13593-6, 10.1007/s11042-022-13593-6]
   Tuncer T, 2022, BIOMED SIGNAL PROCES, V72, DOI 10.1016/j.bspc.2021.103331
   Valens C., 1999, The math forum, P10
   Wan EA, 2001, ADAPT LEARN SYST SIG, P221
   Wan EA, 2000, IEEE 2000 ADAPTIVE SYSTEMS FOR SIGNAL PROCESSING, COMMUNICATIONS, AND CONTROL SYMPOSIUM - PROCEEDINGS, P153, DOI 10.1109/ASSPCC.2000.882463
   Weinert HL, 2007, COMPUT STAT DATA AN, V52, P959, DOI 10.1016/j.csda.2006.11.038
   Wen WH, 2014, IEEE T AFFECT COMPUT, V5, P126, DOI 10.1109/TAFFC.2014.2327617
   WIDROW B, 1975, P IEEE, V63, P719, DOI 10.1109/PROC.1975.9807
   Widrow B., 1960, IRE WESCON Conv. Rec
   Wijasena HZ, 2021, 2021 INT C ART INT M, P1
   Yamada H, 2020, COMMUN STAT-THEOR M, V49, P1629, DOI 10.1080/03610926.2018.1563183
   Yan MS, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103235
   Zhang JH, 2020, INFORM FUSION, V59, P103, DOI 10.1016/j.inffus.2020.01.011
NR 41
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-16933-2
EA SEP 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600023
DA 2024-07-18
ER

PT J
AU Rimal, Y
   Paudel, S
   Sharma, N
   Alsadoon, A
AF Rimal, Yagyanath
   Paudel, Siddhartha
   Sharma, Navneet
   Alsadoon, Abeer
TI Machine learning model matters its accuracy: a comparative study of
   ensemble learning and AutoML using heart disease prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Ensemble learning; Artificial neural network; Support vector machine; K
   nearest neighbors; Random forest; AutoML
ID HEALTH-CARE; SYSTEM
AB Ensemble machine learning is the concept of using multiple models to gain better performance from the combination of weak individual models. New researchers focus on improving machine learning models for accurate classification and prediction on test data, highlighting the critical issue of overall model quality. Once weak learners' ensembles for making strong models were compared separately, the precision, accuracy, and f1 model score were compared separately, and the majority of voting aggregation recommended the best mode for deployment. The model accuracy and their performances of the decision tree, logistic regression, support vector machine, random forest, artificial neural network, gaussian, k nearest neighbor, and multilayer perception were compared for the best model prediction. Similarly, Auto Machine Learning (AutoML) supports both binary classifications and regression problems that can be applied instantly without feature engineering directly. AutoML tries to develop a list of more robust models in tabular form and then determine whose accuracy prediction is the best. This research compares the eighteen (18) different machine learning models, i.e., eight (8) different models that were individually trained and ten (10) from AutoML, whose accuracy, mse, and r2 scores were compared with the same open-source heart disease data set. The support vector, logistic regression, and neural network models produced the highest 80% accuracy result compared to the gaussian, k nearest neighbors, and multilayer perception algorithms, which scored a 76% accuracy score. Similarly, after using AutoML, the generalized linear model (88%), gradient boosting model (87%), distributed random forest model (87%), extra tree model score (82%), and accuracy scores (82%), which ultimately mattered for model accuracy of prediction, were recommended for heart disease classification.
C1 [Rimal, Yagyanath] Pokhara Univ, Pokhara, Nepal.
   [Paudel, Siddhartha] IOE, Pulchowk Campus, Patan, Nepal.
   [Sharma, Navneet] IIS, Jaipur, India.
   [Alsadoon, Abeer] Charles Sturt Univ, Dubbo, Australia.
C3 Tribhuvan University; Institute of Engineering (IOE) - Nepal; Charles
   Sturt University
RP Rimal, Y (corresponding author), Pokhara Univ, Pokhara, Nepal.
EM rimal.yagya@gmail.com; paudelsiddhartha36@gmail.com;
   navneet.sharma@iisuniv.ac.in; alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; Rimal,
   Yagyanath/0000-0003-1045-7728
CR Ahmed H, 2020, FUTURE GENER COMP SY, V111, P714, DOI 10.1016/j.future.2019.09.056
   Ali F, 2020, INFORM FUSION, V63, P208, DOI 10.1016/j.inffus.2020.06.008
   Antoniou Athanas.ios, 2017, Proceedings of the first international workshop on human-centered sensing, networking, and systems, P25, DOI DOI 10.1145/3144730.3144736
   Banerjee M, 2019, CIRC-CARDIOVASC QUAL, V12, DOI 10.1161/CIRCOUTCOMES.118.004879
   Belkin M, 2019, P NATL ACAD SCI USA, V116, P15849, DOI 10.1073/pnas.1903070116
   Chen A, 2023, J ENERGY CHEM, V78, P268, DOI 10.1016/j.jechem.2022.11.035
   Dalal S, 2022, WORLD J GASTROENTERO, V28, P6551, DOI 10.3748/wjg.v28.i46.6551
   Edeh MO, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-25109-1
   Farooq F, 2021, J CLEAN PROD, V292, DOI 10.1016/j.jclepro.2021.126032
   Ganaie MA, 2022, Arxiv, DOI [arXiv:2104.02395, 10.48550/arXiv.2104.02395]
   Hassan M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-69813-2
   Kerwin KR, 2021, J DEF MODEL SIMUL-AP, V18, P175, DOI 10.1177/1548512920962219
   Khourdifi Youness., 2019, International Journal of Intelligent Engineering Systems, V12, P242
   Kulkarni Gururaj N., 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P842, DOI 10.1109/ICAIS50930.2021.9395775
   Liu GB, 2021, CPT-PHARMACOMET SYST, V10, P478, DOI 10.1002/psp4.12621
   Miao KH, 2016, INT J ADV COMPUT SC, V7, P30
   Michael Onyema E., 2023, Measurement: Sensors, V27, DOI [10.1016/j.measen.2023.100718, DOI 10.1016/J.MEASEN.2023.100718]
   Princy RJP, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P570, DOI [10.1109/ICICCS48265.2020.9121169, 10.1109/iciccs48265.2020.9121169]
   Rashidi HH, 2021, INT J LAB HEMATOL, V43, P15, DOI 10.1111/ijlh.13537
   Sanghera DK, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-33981-z
   Shah D., 2020, SN Comput Sci, V1, P345, DOI DOI 10.1007/S42979-020-00365-Y
   Shukla N, 2018, COMPUT METH PROG BIO, V155, P199, DOI 10.1016/j.cmpb.2017.12.011
   Shukla S, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0224934
   Siriborvornratanakul T, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00646-8
   Smirani LK, 2022, SCI PROGRAMMING-NETH, V2022, DOI 10.1155/2022/3805235
   Sudhir, 2022, MATER TODAY-PROC, V50, P1793, DOI 10.1016/j.matpr.2021.09.202
   Tougui I, 2020, HEALTH TECHNOL-GER, V10, P1137, DOI 10.1007/s12553-020-00438-1
   Tuli S, 2020, FUTURE GENER COMP SY, V104, P187, DOI 10.1016/j.future.2019.10.043
   Wang T, 2019, Machine learning for constraint programming
   Wu S., 2022, 2022 INT SEM COMP SC, P1, DOI [10.1109/SCSET55041.2022.00010, DOI 10.1109/SCSET55041.2022.00010]
   Zounemat-Kermani M, 2020, ADV ENG INFORM, V43, DOI 10.1016/j.aei.2019.101030
NR 31
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 28
PY 2023
DI 10.1007/s11042-023-16380-z
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM7
UT WOS:001076639200003
DA 2024-07-18
ER

PT J
AU Hire, DN
   Patil, AV
   Charles, P
AF Hire, D. N.
   Patil, A. V.
   Charles, Priya
TI Efficient rotated and scaled digital image retrieval model using deep
   learning-based hybrid features extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Color features; Digital image retrieval; Deep learning; Handcrafted
   features; Rotation; Scaling
ID ALGORITHM
AB The previous couple decades have seen extensive study in digital image recovery. Content-based image retrieval finds intellectually and aesthetically similar images to the query image. Recent deep learning (DL) approaches enhanced CBIR automation accuracy. After improving accuracy, such systems have failed to overcome image threats such scaling and rotation. Present methods severely decrease scaled and rotated query image performance. The Rotation and Scaling aware Digital Image Retrieval (RS-DIR) system is our unique CBIR framework. The main objective of RS-DIR is to enhance query image retrieval for rotated and scaled images. We build a hybrid feature extraction technique for scaled and rotated images. Image pre-processing, hybrid feature extraction, and retrieval are all processes in the RS-DIR system. In a pre-processing step, the input query image is transformed into the standard size followed by either rotation or scaling threat. The hybrid feature extraction is performed by extracting the DL features and handcrafted (HC) features. We designed a modified 18-layer fast SqueezeNet DL model to extract the high-level image features automatically. However, retrieval efficiency for rotated and scaled input query images cannot be reached using solely high-level characteristics. Therefore, we extracted HC features and combined them with DL features in the RS-DIR model. The features such as color histogram, color auto-correlogram, color moments, and wavelet moments are extracted to build HC features. The experimental results show the efficiency of the proposed model compared to underlying solutions using different datasets.
C1 [Hire, D. N.] DYPCOE, Pune, India.
   [Patil, A. V.; Charles, Priya] DYPIEMR, Pune, India.
RP Hire, DN (corresponding author), DYPCOE, Pune, India.
EM dnyanadahire@gmail.com; anupamav4@gmail.com; prinnu@yahoo.com
CR Abdullah M. N., 2021, Journal of Materials Science and Chemical Engineering, V09, P29, DOI [10.4236/msce.2021.97003, DOI 10.4236/MSCE.2021.97003]
   Ahmed A, 2021, INT J ADV COMPUT SC, V12, P200
   Ahmed KT, 2021, IEEE ACCESS, V9, P57215, DOI 10.1109/ACCESS.2021.3071581
   Al-Mohamade A, 2020, J IMAGING, V6, DOI 10.3390/jimaging6010002
   Alhayani BA, 2023, WIRELESS PERS COMMUN, DOI 10.1007/s11277-023-10587-x
   Alsmadi MK, 2018, J KING SAUD UNIV-COM, V30, P373, DOI 10.1016/j.jksuci.2017.05.002
   Choras Ryszard S, 2007, Int J Biol Biomed Eng, V1
   Dubey SR, 2022, IEEE T CIRC SYST VID, V32, P2687, DOI 10.1109/TCSVT.2021.3080920
   Fan LL, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8090393
   Gassner Mathias, 2023, JMIR Dermatol, V6, pe42129, DOI 10.2196/42129
   Hameed IM, 2021, COGENT ENG, V8, DOI 10.1080/23311916.2021.1927469
   Jardim S, 2022, J IMAGING, V8, DOI 10.3390/jimaging8090238
   Jiang DY, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11125701
   Sikha OK, 2021, MULTIMED TOOLS APPL, V80, P15937, DOI 10.1007/s11042-020-10315-8
   Kale M, 2022, MULTIMED TOOLS APPL, V81, P37263, DOI 10.1007/s11042-022-13529-0
   Khan A, 2021, IEEE ACCESS, V9, P135608, DOI 10.1109/ACCESS.2021.3116225
   Khayyat MM, 2020, IEEE ACCESS, V8, P136460, DOI 10.1109/ACCESS.2020.3010882
   Kumar S, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/4395646
   Latif A, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/9658350
   Luo YM, 2022, INFORMATION, V13, DOI 10.3390/info13100446
   Mahajan H, 2024, CLUSTER COMPUT, V27, P2785, DOI 10.1007/s10586-023-04123-6
   Mahajan HB, 2023, MULTIMED TOOLS APPL, V82, P23251, DOI 10.1007/s11042-022-14253-5
   Mahajan HB, 2023, MULTIMED TOOLS APPL, V82, P44335, DOI 10.1007/s11042-023-15204-4
   Mane Pranoti P., 2016, Pattern Recognition and Image Analysis, V26, P597, DOI 10.1134/S1054661816030159
   Monowar MM, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062188
   Mutasem K.A., 2017, Egyptian Journal of Basic and Applied Sciences, V4, P112, DOI 10.1016/j.ejbas.2017.02.004
   Niu PP, 2021, MULTIMED TOOLS APPL, V80, P29893, DOI 10.1007/s11042-021-11124-3
   Patil S, 2023, SOFT COMPUT, DOI 10.1007/s00500-023-08914-2
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   Raghuwanshi G, 2021, MULTIMED TOOLS APPL, V80, P2295, DOI 10.1007/s11042-020-09618-7
   Rai D, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2022.3223141
   Rajput S, 2019, Face Image Super-Resolution Using Differential Evolutionary Algorithm, DOI [10.1007/978-981-13-1135-2_48, DOI 10.1007/978-981-13-1135-2_48]
   Rajput S, 2018, Face hallucination techniques: A survey, P1, DOI [10.1109/INFOCOMTECH.2018.8722416, DOI 10.1109/INFOCOMTECH.2018.8722416]
   Rajput SS, 2022, SOFT COMPUT, V26, P9323, DOI 10.1007/s00500-022-07250-1
   Rajput SS, 2022, MULTIMED TOOLS APPL, V81, P15997, DOI 10.1007/s11042-022-12154-1
   Rajput SS, 2019, APPL INTELL, V49, P1324, DOI 10.1007/s10489-018-1340-x
   Rajput SS, 2018, INFORM SCIENCES, V463, P227, DOI 10.1016/j.ins.2018.06.050
   Rajput SS, 2018, SIGNAL PROCESS, V147, P233, DOI 10.1016/j.sigpro.2018.01.030
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Renita DB, 2020, MULTIMED TOOLS APPL, V79, P17227, DOI 10.1007/s11042-019-07777-w
   Safaei A, 2021, MED BIOL ENG COMPUT, V59, P1993, DOI 10.1007/s11517-021-02392-0
   Sarwar A, 2019, J INF SCI, V45, P117, DOI 10.1177/0165551518782825
   Simran Arshiya, 2021, IOP Conference Series: Materials Science and Engineering, V1084, DOI 10.1088/1757-899X/1084/1/012026
   Tascini G, 2006, Systemics of Emergence: Research and Development, DOI [10.1007/0-387-28898-8_45, DOI 10.1007/0-387-28898-8_45]
   Tian C, 2020, MULTIMED TOOLS APPL, V79, P9387, DOI 10.1007/s11042-019-7725-y
   Tzelepi M, 2018, 10TH HELLENIC CONFERENCE ON ARTIFICIAL INTELLIGENCE (SETN 2018), DOI 10.1145/3200947.3201007
   Vassilieva NS, 2009, PROGRAM COMPUT SOFT+, V35, P158, DOI 10.1134/S0361768809030049
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Yan R, 2007, INFORM RETRIEVAL, V10, P445, DOI 10.1007/s10791-007-9031-y
   Zare MR, 2008, 4 KUAL LUMP INT C BI, V21, DOI [10.1007/978-3-540-69139-6_209, DOI 10.1007/978-3-540-69139-6_209]
   Zeng FC, 2019, MULTIMED TOOLS APPL, V78, P24023, DOI 10.1007/s11042-019-7161-z
   Zhang F, 2017, Cloud-Based Benchmarking of Medical Image Analysis, DOI [10.1007/978-3-319-49644-3_14, DOI 10.1007/978-3-319-49644-3_14]
NR 52
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 27
PY 2023
DI 10.1007/s11042-023-17016-y
EA SEP 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T1YW6
UT WOS:001076019000007
DA 2024-07-18
ER

PT J
AU Keles, A
   Keles, A
   Keles, MB
   Okatan, A
AF Keles, Ali
   Keles, Ayturk
   Keles, Mustafa Berk
   Okatan, Ali
TI PARNet: Deep neural network for the diagnosis of parkinson's disease
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep neural network; SPECT; Parkinson's disease; Diagnosis; Image
   classification
ID CLASSIFICATION
AB In this study, the successful network architecture we developed from scratch to diagnose COVID-19 has been retrained, using single photon emission computed tomography (SPECT) images to detect Parkinson's disease (PD). We aim to investigate whether a network trained on medical images can be adapted for the diagnosis of another disease successfully. This retrained neural network, PARNet, can detect PD patients. In this study, we use 1213 SPECT images as a dataset. The number of PD and healthy control (HC) group images is 1000 and 213, respectively. We divided the dataset into training (70%), validation (10%), and test (20%) sets. Our network shows outstanding performance with an accuracy of 95.43%, a sensitivity of 95.25%, a specificity of 95.70%, a precision of 97%, and an f1-score of 96%. Our method has the potential to improve the diagnosis and treatment of PD. PARNet, with high diagnosis performance, can contribute to assisting clinicians in diagnosing PD at an earlier. PARNet network based on COV19-ResNet architecture showed performance similar to even high to that of the larger pre-trained models of ImageNet in diagnosing PD. This network can be easily retrained with images from different medical domains to detect various diseases.
C1 [Keles, Ali; Keles, Ayturk] Agri Ibrahim Cecen Univ, Fac Educ, Dept Comp Educ & Instructional Technol, TR-04100 Agri, Turkiye.
   [Keles, Mustafa Berk] TUBITAK BILGEM, Kocaeli, Turkiye.
   [Okatan, Ali] Istanbul Aydin Univ, Fac Engn, Dept Software Engn, Istanbul, Turkiye.
C3 Agri Ibrahim Cecen University; Turkiye Bilimsel ve Teknolojik Arastirma
   Kurumu (TUBITAK); Istanbul Aydin University
RP Keles, A (corresponding author), Agri Ibrahim Cecen Univ, Fac Educ, Dept Comp Educ & Instructional Technol, TR-04100 Agri, Turkiye.
EM alakmus@hotmail.com
CR Adams MP, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104312
   Akdemir ÜÖ, 2021, TURK J MED SCI, V51, P400, DOI 10.3906/sag-2008-253
   Almeida JS, 2019, PATTERN RECOGN LETT, V125, P55, DOI 10.1016/j.patrec.2019.04.005
   Alzubaidi L, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030445
   Ba F, 2015, PARKINSONISM RELAT D, V21, P87, DOI 10.1016/j.parkreldis.2014.11.007
   Choi H, 2017, NEUROIMAGE-CLIN, V16, P586, DOI 10.1016/j.nicl.2017.09.010
   Cummings JL, 2011, BRAIN, V134, P3146, DOI 10.1093/brain/awr177
   de la Fuente-Fernández R, 2012, NEUROLOGY, V78, P696, DOI 10.1212/WNL.0b013e318248e520
   De Venuto D, 2017, 2017 12TH IEEE INTERNATIONAL CONFERENCE ON DESIGN & TECHNOLOGY OF INTEGRATED SYSTEMS IN NANOSCALE ERA (DTIS 2017)
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hathaliya JJ, 2022, COMPUT ELECTR ENG, V101, DOI 10.1016/j.compeleceng.2022.107946
   Holloway R, 2000, CLIN NEUROPHARMACOL, V23, P34
   Hsu SY, 2020, MOLECULES, V25, DOI 10.3390/molecules25204792
   info, Parkinson's Progression Markers Initiative
   Jothi S., 2021, Intl J Modern Trends Sci Technol, V7, P144
   Keles A, 2021, COGN COMPUT, DOI 10.1007/s12559-020-09795-5
   Kotsavasiloglou C, 2017, BIOMED SIGNAL PROCES, V31, P174, DOI 10.1016/j.bspc.2016.08.003
   Kurmi A, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12051173
   Leung KH, 2021, EJNMMI RES, V11, DOI 10.1186/s13550-021-00795-6
   Marek K, 2018, ANN CLIN TRANSL NEUR, V5, P1460, DOI 10.1002/acn3.644
   Marek K, 2014, NEUROLOGY, V82, P1791, DOI 10.1212/WNL.0000000000000424
   Martinez-Murcia FJ., 2017, IWINAC 2017. Lecture Notes in Computer Science, V10337
   Modi Hetav, 2021, 2021 IEEE 6th International Conference on Computing, Communication and Automation (ICCCA), P837, DOI 10.1109/ICCCA52192.2021.9666251
   Moetesum M, 2019, PATTERN RECOGN LETT, V121, P19, DOI 10.1016/j.patrec.2018.04.008
   Nazari M, 2022, EUR J NUCL MED MOL I, V49, P1176, DOI 10.1007/s00259-021-05569-9
   nih, About Us
   Ortiz A, 2019, FRONT NEUROINFORM, V13, DOI 10.3389/fninf.2019.00048
   Parkinson Study Group, 2002, JAMA (Journal of the American Medical Association), V287, P1653, DOI 10.1001/jama.287.13.1653
   Pianpanit T, 2021, IEEE SENS J, V21, P22304, DOI 10.1109/JSEN.2021.3077949
   Prashanth R, 2016, INT J MED INFORM, V90, P13, DOI 10.1016/j.ijmedinf.2016.03.001
   Prashanth R, 2014, EXPERT SYST APPL, V41, P3333, DOI 10.1016/j.eswa.2013.11.031
   Raghu M, 2019, Arxiv, DOI arXiv:1902.07208
   Rodriguez-Porcel F, 2016, EXPERT REV NEUROTHER, V16, P23, DOI 10.1586/14737175.2015.1120160
   Schwingenschuh P, 2010, MOVEMENT DISORD, V25, P560, DOI 10.1002/mds.23019
   Sivaranjini S, 2020, MULTIMED TOOLS APPL, V79, P15467, DOI 10.1007/s11042-019-7469-8
   Wenzel M, 2019, EUR J NUCL MED MOL I, V46, P2800, DOI 10.1007/s00259-019-04502-5
   Wisniewski G., 2013, Tech. Rep
   World Health Organization Neurological Disorders: Public Health Challenges, 2006, World Health Organization
   Yeo S, 2018, MEDICINE, V97, DOI 10.1097/MD.0000000000013434
   Zanini RA, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092605
NR 40
TC 2
Z9 2
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 27
PY 2023
DI 10.1007/s11042-023-16940-3
EA SEP 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T1YW6
UT WOS:001076019000008
DA 2024-07-18
ER

PT J
AU Kuo, LW
   Lin, YX
   Chang, TY
   Lai, CC
AF Kuo, Lungwen
   Lin, Yixin
   Chang, Tsuiyueh
   Lai, Chih-Chun
TI Test the configuration and color of 3D model space design with web
   multimedia interface
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interior; Design; 3D model; Multimedia; Color
ID INTERIOR; PREFERENCES; HARMONY
AB Color has the function of conveying information and presenting psychological feelings. Different space colors are matched with 3D models to present different interior design styles. The interior space color is a 3D color expression. Psychological perception effects. The theme of this study is the color matching emotion of interior space design color, and the 3D model design and bedroom design experiment is used to study the emotional design elements and various emotional evaluations of 3D model design and bedroom color. It is divided into 2 experiments: Experiment 1, The most suitable 3D model design furniture experiment, test the most suitable 4 kinds of 3D model design samples. Experiment 2, Bedroom color suitability experiment, study the most suitable bedroom color, and finally experiment and analyze the results to determine the most suitable bedroom color design. The research results show that the most suitable bedroom room color design is Cream, followed by Dark gray, Baby blue, and Pale Denim. Although this study takes 3D model and bedroom as the experimental object, the results of the experiment have more theoretical and practical reference basis for the future color and furniture style design of other interior spaces, and provide reference directions for researchers.
C1 [Kuo, Lungwen] Sanming Univ, Dept Prod Design, Sanming, Fujian, Peoples R China.
   [Lin, Yixin] Sanming Univ, Dept Ind Design, Sanming, Fujian, Peoples R China.
   [Chang, Tsuiyueh] Tzu Chi Acad, Dept Educ, Cupertino, CA 95129 USA.
   [Lai, Chih-Chun] Tatung Univ, Dept Ind Design, Taipei, Taiwan.
C3 Sanming University; Sanming University; Tatung University
RP Chang, TY (corresponding author), Tzu Chi Acad, Dept Educ, Cupertino, CA 95129 USA.
EM yueh5031162@yahoo.com.tw
RI lai, chih chun/AAE-6772-2021
OI Kuo, Lungwen/0000-0001-9894-2706; Lai, Chih-Chun/0000-0003-4261-6228
FU Fujian Province Science, Sanming University [21YG02S]; Research
   Foundation for Advanced Talent [FJ2022B112]
FX Supported by Fujian Province Science, Grant Number: FJ2022B112 Sanming
   University, Research Foundation for Advanced Talent, Grant Number:
   21YG02S.
CR Chang A, 2017, ARXIV
   Chang YC, 2018, MULTIMED TOOLS APPL, V77, P6531, DOI 10.1007/s11042-017-4564-6
   Chen K, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818096
   Edwards R., 2013, WHAT IS QUALITATIVE
   Fisher M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366154
   Fisher M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866204
   Günes E, 2020, COLOR RES APPL, V45, P129, DOI 10.1002/col.22443
   Guo L, 2022, MULTIMED TOOLS APPL, V81, P35751, DOI 10.1007/s11042-021-11145-y
   Guo XK, 2014, GRAPH MODELS, V76, P376, DOI 10.1016/j.gmod.2014.03.019
   Hamada K, 2018, ASIAPAC SIGN INFO PR, P317, DOI 10.23919/APSIPA.2018.8659497
   Hayat M, 2016, IEEE T IMAGE PROCESS, V25, P4829, DOI 10.1109/TIP.2016.2599292
   Izadinia H, 2017, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2017.260
   Kauppinen-Räisänen H, 2010, QUAL MARK RES, V13, P287, DOI 10.1108/13522751011053644
   Kwallek N, 2007, COLOR RES APPL, V32, P130, DOI 10.1002/col.20298
   López GL, 2017, MULTIMED TOOLS APPL, V76, P6993, DOI 10.1007/s11042-016-3330-5
   Lee HS, 2005, COLOR RES APPL, V30, P135, DOI 10.1002/col.20092
   Liang Y, 2019, MULTIMED TOOLS APPL, V78, P5003, DOI 10.1007/s11042-018-6004-7
   Lind C., 1993, Clothing and Textiles Research Journal, V12, P57, DOI DOI 10.1177/0887302X9301200108
   Liu TQ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766898
   López-Tarruella J, 2019, HERD-HEALTH ENV RES, V12, P55, DOI 10.1177/1937586718796593
   Müezzinoglu MK, 2021, COLOR RES APPL, V46, P1006, DOI 10.1002/col.22654
   Nóbrega R, 2017, MULTIMED TOOLS APPL, V76, P163, DOI 10.1007/s11042-015-3031-5
   Oh J, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18179136
   Osgood C. E., 1957, The measurement of meaning
   Patel TA, 2020, INT CONF ADVAN COMPU, P452, DOI [10.1109/icaccs48705.2020.9074460, 10.1109/ICACCS48705.2020.9074460]
   Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Savva M, 2017, ARXIV
   Shen YC, 1996, COLOR RES APPL, V21, P353, DOI 10.1002/(SICI)1520-6378(199610)21:5<353::AID-COL5>3.0.CO;2-X
   Shen YC, 2000, COLOR RES APPL, V25, P20, DOI 10.1002/(SICI)1520-6378(200002)25:1<20::AID-COL4>3.0.CO;2-5
   Shi J, 2019, IEEE ACCESS, V7, P45230, DOI 10.1109/ACCESS.2019.2908448
   Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1
   Smith D, 2008, COLOR RES APPL, V33, P312, DOI 10.1002/col.20424
   Taft C, 1997, COLOR RES APPL, V22, P40, DOI 10.1002/(SICI)1520-6378(199702)22:1<40::AID-COL7>3.0.CO;2-4
   Torres A, 2020, FRONT ARCHIT RES, V9, P739, DOI 10.1016/j.foar.2020.06.002
   Uluçay NÖ, 2019, COLOR RES APPL, V44, P132, DOI 10.1002/col.22268
   Ulusoy B, 2021, COLOR RES APPL, V46, P1079, DOI 10.1002/col.22640
   Ulusoy B, 2017, COLOR RES APPL, V42, P261, DOI 10.1002/col.22072
   van der Voordt T, 2017, FACILITIES, V35, P155, DOI 10.1108/F-06-2015-0043
   Wagner AS, 2018, COLOR RES APPL, V43, P471, DOI 10.1002/col.22218
   Xu K., 2013, ACM Trans. Graph., V32, P1
   Xu K, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185553
   Yu LF, 2016, IEEE T VIS COMPUT GR, V22, P1138, DOI 10.1109/TVCG.2015.2417575
   Zahariadis T, 2008, NEM SUMMIT, P13
   Zhang SY, 2017, VISUAL COMPUT, V33, P925, DOI 10.1007/s00371-017-1394-5
   Zheng CX, 2018, VISUAL COMPUT, V34, P735, DOI 10.1007/s00371-017-1411-8
   Zhu J, 2017, IEEE T WIREL COMMUN, V16, P2001, DOI 10.1109/TWC.2017.2659724
NR 47
TC 0
Z9 0
U1 5
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33107
EP 33121
DI 10.1007/s11042-023-17000-6
EA SEP 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001075272400003
DA 2024-07-18
ER

PT J
AU Xun, Z
   Baoqing, H
   Dian, L
   Jingyuan, W
   Chenchen, Y
   Yu, W
   Qiong, M
   Henggang, X
   Hongxiang, K
AF Xun, Zhou
   Baoqing, Huang
   Dian, Luan
   Jingyuan, Wu
   Chenchen, Yang
   Yu, Wei
   Qiong, Ma
   Henggang, Xue
   Hongxiang, Kang
TI Eye behavior recognition of eye-computer interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eye-computer interaction; Eye behavior recognition; YOLO; Human-computer
   interaction; Deep learning
AB Eye behavior recognition has found widespread applications in augmented reality devices and simplified traditional human-computer interaction methods. However, several eye-machine interaction methods currently studied, such as pupil detection and gaze tracking, may not be well-suited for practical applications. Wearable devices or portable outdoor equipment require eye movement recognition in close proximity to the eyes, demanding rich eye-machine interaction commands and strong robustness. In this context, it is crucial to achieve eye behavior recognition that is suitable for practical application scenarios. To achieve this objective, the current study employs three enhancement strategies to modify YOLOv5 into YOLOv5-Eye State Recognition (YOLOv5-ESR) and trains it on a dataset of human eye images captured by intelligent eyeglasses to obtain an eye state recognition model. The study categorizes the eye states detected by the model into three types: "open," "closed," and "squint." Additionally, the user's eye behaviors are classified into four categories: "gaze," "long blink," "long squint," and "double blink." Through experimental testing, the average recognition accuracy of eye behavior reaches 96.25%, with a detection speed of 78.66 frames per second (fps). Moreover, this eye behavior recognition technology demonstrates its applicability in various application environments. The proposed technology is characterized by its suitability for wearable devices, high detection accuracy, real-time performance, strong robustness, and excellent human-computer interaction capabilities.
C1 [Xun, Zhou; Baoqing, Huang; Dian, Luan; Jingyuan, Wu; Chenchen, Yang; Yu, Wei; Qiong, Ma; Henggang, Xue; Hongxiang, Kang] Beijing Inst Radiat Med, Beijing, Peoples R China.
   [Xun, Zhou] Nanjing Univ, Nanjing, Jiangsu, Peoples R China.
C3 Academy of Military Medical Sciences - China; Nanjing University
RP Hongxiang, K (corresponding author), Beijing Inst Radiat Med, Beijing, Peoples R China.
EM zx66patrol@163.com; 1213083884@qq.com; 510123613@qq.com;
   a1582335968@163.com; Chen01282022@163.com; 2399716360@qq.com;
   maqiong666@163.com; henggang.xue@qq.com; khx007@163.com
CR Choi JH, 2020, MULTIMED TOOLS APPL, V79, P32563, DOI 10.1007/s11042-020-09711-x
   Donuk K, 2022, MULTIMED TOOLS APPL, V81, P39103, DOI 10.1007/s11042-022-13085-7
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Korda AI, 2018, BIOMED SIGNAL PROCES, V41, P10, DOI 10.1016/j.bspc.2017.11.004
   Laddi A, 2019, MULTIMED TOOLS APPL, V78, P31215, DOI 10.1007/s11042-019-07940-3
   Liu ZT, 2021, APPL SOFT COMPUT, V109, DOI 10.1016/j.asoc.2021.107565
   Yilmaz CM, 2019, 2019 MEDICAL TECHNOLOGIES CONGRESS (TIPTEKNO), P326, DOI 10.1109/tiptekno.2019.8895170
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
NR 10
TC 0
Z9 0
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32655
EP 32671
DI 10.1007/s11042-023-16763-2
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069966300002
DA 2024-07-18
ER

PT J
AU Zhao, JQ
   Chen, Y
   Zhong, YF
   Zhou, Y
   Yao, R
   Zhang, LX
   Xia, SX
AF Zhao, Jiaqi
   Chen, Ying
   Zhong, Yufeng
   Zhou, Yong
   Yao, Rui
   Zhang, Lixu
   Xia, Shixiong
TI Filter pruning based on evolutionary algorithms for person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Filter pruning; Optimization problem;
   Evolutionary algorithm
ID NEURAL-NETWORKS
AB Filter pruning has drawn much attention for releasing the limitations of person re-identification (ReID) in resource-constrained platforms due to the large parameters and high computational consumption. Filter pruning is depended on the given combination of pruning ratios to trim off unimportant filters, therefore, we define filter pruning as optimization problem. Existing strategies generally retrain all the pruning results and compare their performance iteratively, representing a major expenditure of time and effort. In this paper, we formally put forward a scheme of filter pruning based on evolutionary algorithms (EAFPruner) for ReID task for the first time, which automatically finds the optimal pruning structure in the pruning space with the better trade-off between computational cost and identification accuracy. Specifically, multiple evolutionary algorithms are adopted to solve the optimization problem by using mean average precision (mAP) as the fitness for filter-level sparsity. In addition, the adaptive batch normalization strategy is adopted to evaluate the pruned candidates generated by evolutionary algorithm without fine-tuning them to speed up training process. The experimental results are carried out on four person ReID datasets, and the number of parameters required by ResNet50 architecture is reduced by half while maintaining a comparable Rank-1 accuracy, which demonstrates the effectiveness of our proposed method.
C1 [Zhao, Jiaqi; Zhou, Yong; Yao, Rui; Xia, Shixiong] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
   [Zhao, Jiaqi; Zhou, Yong; Yao, Rui; Xia, Shixiong] Minist Educ Peoples Republ China, Engn Res Ctr Mine Digitizat, Xuzhou 221116, Jiangsu, Peoples R China.
   [Zhao, Jiaqi] Disaster Intelligent Prevent & Control & Emergenc, Xuzhou 221116, Jiangsu, Peoples R China.
   [Chen, Ying] Heze Univ, Sch Comp, Comp Informat Proc Lab, Heze 274015, Shandong, Peoples R China.
   [Zhong, Yufeng] Univ Chinese Acad Sci, Sch Astron & Space Sci, Beijing 100049, Peoples R China.
   [Zhang, Lixu] Jiangsu Junsheng Wanbang Holding Grp Co Ltd, Xuzhou 221116, Jiangsu, Peoples R China.
C3 China University of Mining & Technology; Heze University; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Xia, SX (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.; Xia, SX (corresponding author), Minist Educ Peoples Republ China, Engn Res Ctr Mine Digitizat, Xuzhou 221116, Jiangsu, Peoples R China.
EM chenying@hezeu.edu.cn; shixiongxia.cumt@outlook.com
FU National Natural Science Foundation of China
FX No Statement Available
CR Bailin Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P639, DOI 10.1007/978-3-030-58536-5_38
   Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chen F, 2021, INFORM SCIENCES, V549, P1, DOI 10.1016/j.ins.2020.11.004
   Chen HR, 2018, 2018 IEEE FOURTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM)
   Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304
   Denil M., 2013, ADV NEURAL INFORM PR
   Fernandes FE Jr, 2021, INFORM SCIENCES, V552, P29, DOI 10.1016/j.ins.2020.11.009
   Graf, 2017, ARXIV160808710, P1, DOI DOI 10.48550/ARXIV.1608.08710
   Han S, 2015, ADV NEUR IN, V28
   Hermans Alexander, 2017, ARXIV170307737
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Kim Y.D, 2016, P 4 INT C LEARN REPR
   Leng C, 2018, AAAI CONF ARTIF INTE, P3466
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Ponce-Lopez V, 2018, P 2018 IEEE 88 VEH T, P1
   Ren P, 2018, ARXIV
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Ustinova E, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang K, 2021, INFORM SCIENCES, V565, P196, DOI 10.1016/j.ins.2021.02.066
   Wang Y, 2018, PROC CVPR IEEE, P8042, DOI [10.1109/CVPR.2018.00839, 10.1109/CVPR.2018.00736]
   Wen W, 2016, ADV NEUR IN, V29
   Xie H, 2021, J AMB INTEL HUM COMP, V12
   Xie HN, 2021, J AMB INTEL HUM COMP, V12, P2149, DOI 10.1007/s12652-020-02312-4
   Xie ZH, 2022, MULTIMED TOOLS APPL, V81, P19151, DOI 10.1007/s11042-021-10537-4
   Ye JM, 2018, PROC CVPR IEEE, P9378, DOI 10.1109/CVPR.2018.00977
   Yuan X, 2019, PROC CVPR IEEE, P6939, DOI 10.1109/CVPR.2019.00711
   Zhang SZ, 2021, IEEE T MULTIMEDIA, V23, P281, DOI 10.1109/TMM.2020.2977528
   Zhang X, 2017, ARXIV
   Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zhedong Zheng, 2017, ACM Transactions on Multimedia Computing, Communications and Applications, V14, DOI 10.1145/3159171
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhou TF, 2014, INFORM SCIENCES, V279, P604, DOI 10.1016/j.ins.2014.04.014
   Zou GF, 2021, MULTIMED TOOLS APPL, V80, P26855, DOI 10.1007/s11042-021-10953-6
NR 45
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32569
EP 32586
DI 10.1007/s11042-023-16731-w
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069968300008
DA 2024-07-18
ER

PT J
AU Yang, PX
AF Yang, Peixuan
TI An imaging algorithm for high-resolution imaging sonar system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multireceiver; Synthetic aperture sonar; Loffeld's bistatic formula;
   Imaging; CS algorithm
AB Multireceiver synthetic aperture sonar (SAS) can produce high-resolution images by coherently superposing successive echoed signal. However, multireceiver SAS imaging is a difficult issue since the system can be divided into many bistatic SASs. Traditional imaging algorithms cannot be directly used to process the multireceiver SAS echoed signal, as they are just applied to monostatic sonar system. In order to solve this issue, this paper proposes an imaging algorithm based on Loffeld's bistatic formula (LBF) for multireceiver SAS system. With the LBF method, the point target reference spectrum (PTRS) of multireceiver SAS system can be split into quasi-monostatic term and the bistatic deformation term. The quasi-monostatic term is similar to the spectrum of monostatic SAS while the bistatic deformation term is caused by the displacement of transmitter and receiver. In this paper, the data of multireceiver SAS is firstly coerced into monostatic one by compensating the bistatic deformation term. After this step, the chirp scaling (CS) algorithm based on monostatic SAS can be directly applied. At last, simulations are exploited to demonstrate the presented method. Compared to traditional multireceiver SAS CS algorithms, the presented method significantly improves the imaging performance. Both ghosts target and higher sidelobes that traditional multireceiver SAS CS algorithms suffer from can be successfully suppressed. Furthermore, the presented method can obtain high-resolution results which are nearly identical to the benchmark of BP algorithm.
C1 [Yang, Peixuan] Acoust Signal & Elect Sci & Technol Corp, Xijin Rd, Lanzhou 730050, Peoples R China.
RP Yang, PX (corresponding author), Acoust Signal & Elect Sci & Technol Corp, Xijin Rd, Lanzhou 730050, Peoples R China.
EM peixuan_yang@126.com
RI Yang, Peixuan/JWO-8384-2024
FU The authors are very grateful for reviewers' comments improving this
   paper. Besides, the authors are very grateful for Prof. Dr. Haixin Sun'
   s technical editing of the manuscript. Furthermore, the authors are very
   grateful for Dr. Mingzhang Zhou' s proofre
FX The authors are very grateful for reviewers' comments improving this
   paper. Besides, the authors are very grateful for Prof. Dr. Haixin Sun'
   s technical editing of the manuscript. Furthermore, the authors are very
   grateful for Dr. Mingzhang Zhou' s proofreading of the manuscript.
CR Belkacem A, 2020, INT MULTICONF SYST, P933, DOI 10.1109/SSD49366.2020.9364123
   Berthomier T, 2019, OCEANS-IEEE, DOI 10.23919/oceans40490.2019.8962774
   Berthomier T, 2020, OCEANS-IEEE, DOI 10.1109/IEEECONF38699.2020.9389138
   Bonifant W.W., 1999, INTERFEROMETRIC SYNT
   Bonifant WW, 2000, IEE P-RADAR SON NAV, V147, P322, DOI 10.1049/ip-rsn:20000618
   Callow HJ, 2002, ELECTRON LETT, V38, P336, DOI 10.1049/el:20020219
   Carballini J, 2015, 2015 IEEE/OES ACOUSTICS IN UNDERWATER GEOSCIENCES SYMPOSIUM
   Clemente C, 2012, IEEE GEOSCI REMOTE S, V9, P682, DOI 10.1109/LGRS.2011.2178812
   Denos K, 2017, OCEANS-IEEE
   Ding JS, 2008, PROG NAT SCI-MATER, V18, P1271, DOI 10.1016/j.pnsc.2008.03.022
   Duersch M.I., 2013, BACKPROJECTION SYNTH
   Fernandes VH, 2020, MAR GEOD, V43, P376, DOI 10.1080/01490419.2020.1755916
   Geng XP, 2008, IEEE T GEOSCI REMOTE, V46, P2216, DOI 10.1109/TGRS.2008.918015
   Gough PT, 2005, Oceans 2005 - Europe, Vols 1 and 2, P563
   Gough PT, 2000, P 5 EUR C UND AC ECU, P395
   Hawkins DW, 1997, INT GEOSCI REMOTE SE, P471, DOI 10.1109/IGARSS.1997.615918
   Hayes MP, 2009, IEEE J OCEANIC ENG, V34, P207, DOI 10.1109/JOE.2009.2020853
   Hughes R, 1977, 1977 OC C LOS ANG, P102
   Hunter A, 2003, 5 WORLD C ULTR PAR, P527
   Klausner NH, 2020, IEEE J OCEANIC ENG, V45, P534, DOI 10.1109/JOE.2018.2881527
   Köhntopp D, 2019, IEEE J OCEANIC ENG, V44, P767, DOI 10.1109/JOE.2018.2835218
   Larsen LJ, 2010, OCEANS-IEEE
   Li F, 2009, J SYST ENG ELECTRON, V20, P291
   Liu BC, 2010, IEEE GEOSCI REMOTE S, V7, P831, DOI 10.1109/LGRS.2010.2048888
   Llort-Pujol G, 2007, 2006 OC C SING, P1
   Loffeld O, 2004, IEEE T GEOSCI REMOTE, V42, P2031, DOI 10.1109/TGRS.2004.835295
   Neo YL, 2008, IEEE T GEOSCI REMOTE, V46, P2481, DOI 10.1109/TGRS.2008.919018
   Neo YL, 2008, IEEE T GEOSCI REMOTE, V46, P14, DOI 10.1109/TGRS.2007.909090
   Neo YL, 2007, IEEE GEOSCI REMOTE S, V4, P93, DOI 10.1109/LGRS.2006.885862
   Nikolovska A, 2015, OCEANS 2015 - GENOVA, DOI 10.1109/OCEANS-Genova.2015.7271651
   Qiu XL, 2008, IEEE T GEOSCI REMOTE, V46, P2224, DOI 10.1109/TGRS.2008.917497
   Rodriguez-Cassola M, 2012, IEEE GEOSCI REMOTE S, V9, P33, DOI 10.1109/LGRS.2011.2158984
   Rodriguez-Cassola M, 2011, IEEE T AERO ELEC SYS, V47, P2949, DOI 10.1109/TAES.2011.6034676
   ROLT KD, 1992, IEEE J OCEANIC ENG, V17, P73, DOI 10.1109/48.126956
   Romaine PD, 2019, OCEANS-IEEE
   SATO T, 1973, J ACOUST SOC AM, V54, P799, DOI 10.1121/1.1913664
   Shin HS, 2009, IEEE T GEOSCI REMOTE, V47, P238, DOI 10.1109/TGRS.2008.2002954
   Sledge IJ, 2022, IEEE J OCEANIC ENG, V47, P1099, DOI 10.1109/JOE.2022.3152863
   Steele S, 2019, MTS IEEE OC C SEATTL, P1
   Tan C, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19225052
   Wang F, 2010, IEEE GEOSCI REMOTE S, V7, P483, DOI 10.1109/LGRS.2009.2039695
   Wang R, 2009, IEEE T GEOSCI REMOTE, V47, P2275, DOI 10.1109/TGRS.2008.2010852
   Wang XH, 2015, ACSR ADV COMPUT, P1610
   Williams DP, 2019, INT GEOSCI REMOTE SE, P78, DOI [10.1109/IGARSS.2019.8898611, 10.1109/igarss.2019.8898611]
   Williams DP, 2016, INT C PATT RECOG, P2497, DOI 10.1109/ICPR.2016.7900011
   Wong FH, 2008, IEEE T GEOSCI REMOTE, V46, P2493, DOI 10.1109/TGRS.2008.917599
   Xuebo Zhang, 2021, 2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS, P5167, DOI 10.1109/IGARSS47720.2021.9553688
   Zhang Xue-bo, 2014, Journal of Naval University of Engineering, V26, P20, DOI 10.7495/j.issn.1009-3486.2014.02.005
   Zhang XB, 2023, ELECTRON LETT, V59, DOI 10.1049/ell2.12859
   Zhang XB, 2023, IEEE GEOSCI REMOTE S, V20, DOI 10.1109/LGRS.2023.3286180
   Zhang XB, 2022, J MAR SCI ENG, V10, DOI 10.3390/jmse10060718
   Zhang XB, 2022, IET RADAR SONAR NAV, V16, P1470, DOI 10.1049/rsn2.12274
   Zhang XB, 2022, ELECTRON LETT, V58, P995, DOI 10.1049/ell2.12513
   [张学波 Zhang Xuebo], 2022, [武汉大学学报. 信息科学版, Geomatics and Information Science of Wuhan University], V47, P133
   Zhang XB, 2022, CURR SCI INDIA, V122, P461, DOI 10.18520/cs/v122/i4/461-464
   Zhang XB, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13245008
   Zhang XB, 2022, IET RADAR SONAR NAV, V16, P531, DOI 10.1049/rsn2.12200
   Zhang XB, 2021, IEEE J-STARS, V14, P10835, DOI 10.1109/JSTARS.2021.3121405
   Zhang XB, 2021, I C COMM SOFTW NET, P357, DOI 10.1109/ICCSN52437.2021.9463601
   Zhang XB, 2020, IET RADAR SONAR NAV, V14, P1055, DOI 10.1049/iet-rsn.2019.0477
   Zhang XB, 2019, CIRC SYST SIGNAL PR, V38, P2607, DOI 10.1007/s00034-018-0982-6
   Zhang XB, 2019, IET RADAR SONAR NAV, V13, P830, DOI 10.1049/iet-rsn.2018.5468
   Zhang XB, 2019, J ELECTR ENG TECHNOL, V14, P471, DOI 10.1007/s42835-018-00046-0
   Zhang XB, 2018, IET RADAR SONAR NAV, V12, P1276, DOI 10.1049/iet-rsn.2018.5040
   Zhang XB, 2017, 2017 17TH IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT 2017), P1601, DOI 10.1109/ICCT.2017.8359901
   Zhang XB, 2017, IEEE T GEOSCI REMOTE, V55, P3572, DOI 10.1109/TGRS.2017.2676339
   [张学波 Zhang Xuebo], 2014, [电子与信息学报, Journal of Electronics & Information Technology], V36, P1592
   [张学波 Zhang Xuebo], 2014, [哈尔滨工程大学学报, Journal of Harbin Engineering University], V35, P93
   [张学波 Zhang Xuebo], 2013, [高技术通讯, Chinese High Technology Letters], V23, P927
   [张学波 Zhang Xuebo], 2013, [系统工程与电子技术, Systems Engineering & Electronics], V35, P1415
   [张学波 Zhang Xuebo], 2013, [哈尔滨工程大学学报, Journal of Harbin Engineering University], V34, P240
   Zhu KQ, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P301, DOI 10.1109/SIPROCESS.2018.8600472
NR 72
TC 27
Z9 27
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31957
EP 31973
DI 10.1007/s11042-023-16757-0
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069156900019
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Aslan, M
   Baykara, M
   Alakus, TB
AF Aslan, Musa
   Baykara, Muhammet
   Alakus, Talha Burak
TI LSTMNCP: lie detection from EEG signals with novel hybrid deep learning
   method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EEG; Signal processing; Lie detection; Deep learning; LSTM; NCP
ID CLASSIFICATION
AB Lying has become an element of human nature. People lie intentionally or unintentionally at any point in their lives. Human beings can deceive by lying to justify themselves about something or to get rid of a wrongdoing. This lie can result in various consequences, including health deterioration, loss of life, a sense of insecurity, criminal behaviors, and more. Such situations are more common especially in daily life, security, and criminology. In these cases, lie detection is of vital importance. With the development of technology, lie detection becomes a more important issue. People can manipulate others and provide information by lying. This situation has led researchers to turn to more alternative ways and the importance of EEG signals has increased. Since EEG signals are difficult to manipulate, there has been an increase in their use and analysis in lie detection studies. In this study, lie detection was performed with EEG signals and the importance of EEG signals was demonstrated. Within the scope of this study, a novel hybrid deep learning method was designed on the Bag-of-Lies dataset, which was created using different methods, and lie detection was carried out. The study consisted of four stages. In the first stage, EEG data were obtained from the Bag-of-Lies dataset. In the second stage, the data were decomposed into sub-signals by DWT method. These signals, which were separated in the third stage, were classified with the designed novel hybrid deep learning model. At the last stage of the study, the performance of the classifier was determined by accuracy, precision, recall, F1-score, and AUC score. At the conclusion of the research, an accuracy score of 97.88% was achieved, demonstrating the significance of EEG signals in this domain.
C1 [Aslan, Musa] Karadeniz Tech Univ, Fac Technol, Dept Software Engn, Trabzon, Turkiye.
   [Baykara, Muhammet] Firat Univ, Fac Technol, Dept Software Engn, Elazig, Turkiye.
   [Alakus, Talha Burak] Kirklareli Univ, Dept Software Engn, Fac Engn, Kirklareli, Turkiye.
C3 Karadeniz Technical University; Firat University; Kirklareli University
RP Alakus, TB (corresponding author), Kirklareli Univ, Dept Software Engn, Fac Engn, Kirklareli, Turkiye.
EM talhaburakalakus@klu.edu.tr
RI ALAKUS, Talha Burak/ABI-1288-2020; BAYKARA, Muhammet/V-8965-2018; Aslan,
   Musa/HTR-2535-2023
OI BAYKARA, Muhammet/0000-0001-5223-1343; Aslan, Musa/0000-0003-1659-5048
CR Akyol K, 2020, EXPERT SYST APPL, V148, DOI 10.1016/j.eswa.2020.113239
   Alakus TB, 2020, BIOMED SIGNAL PROCES, V60, DOI 10.1016/j.bspc.2020.101951
   AlArfaj AA, 2022, CMC-COMPUT MATER CON, V73, P5655, DOI 10.32604/cmc.2022.031135
   Alex SA, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11172737
   Anwar S, 2019, INT BHURBAN C APPL S, P543, DOI [10.1109/IBCAST.2019.8667131, 10.1109/ibcast.2019.8667131]
   Anzanello MJ, 2011, INT J IND ERGONOM, V41, P573, DOI 10.1016/j.ergon.2011.05.001
   Avola D, 2020, PATTERN RECOGN LETT, V138, P455, DOI 10.1016/j.patrec.2020.08.014
   Baghel N, 2020, 2020 43RD INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P550, DOI [10.1109/tsp49548.2020.9163497, 10.1109/TSP49548.2020.9163497]
   Bala Ruchi, 2019, 2019 URSI Asia-Pacific Radio Science Conference (AP-RASC), DOI 10.23919/URSIAP-RASC.2019.8738689
   Bell MA, 2012, J COGN DEV, V13, P281, DOI 10.1080/15248372.2012.691143
   Bond CF, 2006, PERS SOC PSYCHOL REV, V10, P214, DOI 10.1207/s15327957pspr1003_2
   Budahazi A, 2022, BELUGYI SZEMLE, V70, P69, DOI [10.38146/BSZ.SPEC.2022.1.4, DOI 10.38146/BSZ.SPEC.2022.1.4]
   Chen G, 2021, J PERFORM CONSTR FAC, V35, DOI 10.1061/(ASCE)CF.1943-5509.0001641
   Chuin Cheong L, 2015, ARPN J ENG APPL SCI, V10, P533
   Edla DR, 2021, ACM TRANS MANAG INF, V12, DOI 10.1145/3458791
   FARWELL LA, 1991, PSYCHOPHYSIOLOGY, V28, P531, DOI 10.1111/j.1469-8986.1991.tb01990.x
   Gallardo-Antolín A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11146393
   Gao JF, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0109700
   Gupta VK, 2019, ADV INTELL SYST, V981, P83, DOI 10.1007/978-3-030-19494-9_8
   Hasani R, 2020, PR MACH LEARN RES, V119
   Hosmer DW, 2013, WILEY SER PROBAB ST, P1, DOI 10.1002/9781118548387
   Iacono WG, 2019, LAW HUMAN BEHAV, V43, P86, DOI 10.1037/lhb0000307
   Javaid H, 2022, PROCEEDINGS OF 2ND IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (ICAI 2022), P71, DOI 10.1109/ICAI55435.2022.9773469
   Kaplan HS, 2020, NEURON, V105, P562, DOI 10.1016/j.neuron.2019.10.037
   Karnati M, 2022, IEEE T COGN DEV SYST, V14, P971, DOI 10.1109/TCDS.2021.3086011
   Krishnamurthy Gangeshwar, 2023, Computational Linguistics and Intelligent Text Processing: 19th International Conference, CICLing 2018, Revised Selected Papers. Lecture Notes in Computer Science (13396), P87, DOI 10.1007/978-3-031-23793-5_8
   KUMAR N, 2017, BIOMED PHARMACOL J, V10, P2061, DOI DOI 10.13005/bpj/1328
   Kumar R, 2021, INT J SIGNAL IMAGING, V12, P71, DOI 10.1504/IJSISE.2021.117901
   Lechner M, 2020, NAT MACH INTELL, V2, P642, DOI 10.1038/s42256-020-00237-3
   Lechner M, 2019, IEEE INT CONF ROBOT, P87, DOI [10.1109/ICRA.2019.8793840, 10.1109/icra.2019.8793840]
   Liu Y, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9061108
   Nagabushanam P, 2020, SOFT COMPUT, V24, P9981, DOI 10.1007/s00500-019-04515-0
   Naveena S, 2023, COMPUT METHOD BIOMEC, V26, P1834, DOI 10.1080/10255842.2022.2149263
   Naveena S, 2022, BIOMED SIGNAL PROCES, V77, DOI 10.1016/j.bspc.2022.103748
   Ogiela L, 2008, LECT NOTES ARTIF INT, V5177, P394, DOI 10.1007/978-3-540-85563-7_51
   Ogiela L, 2010, STUD COMPUT INTELL, V309, P347
   Ogiela L, 2008, LECT NOTES ARTIF INT, V5314, P456, DOI 10.1007/978-3-540-88513-9_49
   Oravec JA, 2022, ETHICS INF TECHNOL, V24, DOI 10.1007/s10676-022-09621-6
   Osadchiy Andrey, 2021, Designs, V5, DOI 10.3390/designs5030041
   Petoft A, 2019, BIOETHICS, V9, P95, DOI [10.22037/BJ.V9I34.30574, DOI 10.22037/BJ.V9I34.30574]
   Rizal A, 2019, J INF PROCESS SYST, V15, P1068, DOI 10.3745/JIPS.02.0116
   Rosset S., 2004, P 21 INT C MACH LEAR, P89, DOI [DOI 10.1145/1015330.1015400, 10.1145/1015330.1015400]
   Staudemeyer RC, 2023, ARXIV
   Tuckett AG, 2012, NURS ETHICS, V19, P7, DOI 10.1177/0969733011412104
   Yan G, 2017, NATURE, V550, P519, DOI 10.1038/nature24056
NR 45
TC 0
Z9 0
U1 16
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31655
EP 31671
DI 10.1007/s11042-023-16847-z
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001067934200010
DA 2024-07-18
ER

PT J
AU Kavitha, D
   Geetha, S
   Geetha, R
AF Kavitha, D.
   Geetha, S.
   Geetha, R.
TI An adaptive neuro fuzzy methodology for the diagnosis of prenatal
   hypoplastic left heart syndrome from ultrasound images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Maximum likelihood; Morphological operations; Neuro fuzzy; Classifier;
   Computer aided decision support system
ID SPECKLE REDUCTION; SEGMENTATION
AB Congenital heart defect (CHD) is one of the most serious congenital deformities in a fetus. About 31% to 55% of CHDs are the primary cause that leads to life-threatening problem among neonates, hence sonographers emphasize the importance of prenatal CHD screening. Among 18 types of CHDs, the asymmetric appearance of the heart seems to be a challenging part. Hypoplastic left heart syndrome (HLHS) is a critical and rare CHD, with an underdeveloped left heart chamber of the fetus. This prenatal CHD can be diagnosed between 17 to 21 weeks of gestation period. Though ultrasound provides a good diagnostic result, prenatal diagnosis is still a challenging area due to its speckle noise and irregular appearance of the heart chambers. In this context, the basic step is to appropriately select the pre-processing algorithm, one such algorithm is the Fuzzy based maximum likelihood estimation technique (FMLET). Right ventricle left ventricle ratio (RVLVR) and cardiac thoracic ratio (CTR) are the two important features required for manual diagnosis of the ultrasound images. Hence, morphological operations such as open, close, thinning and thickening helps to extract the diagnostically important features inherent in the images. Finally, the computer aided decision support (CADS) system is designed with pre-processing module, morphological module and adaptive neuro fuzzy (ANFC) classifier module. ANFC is investigated as the good classifiers to help the experts in terms of self-learning with higher diagnostic rate. The proposed CADS proven with 91% of diagnostic accuracy and the standardized area under the ROC curve obtained was 0.9137.
C1 [Kavitha, D.] CMR Inst Technol, Dept Elect & Commun Engn, Bangalore, India.
   [Geetha, S.] VIT Univ Chennai, Sch Comp Sci & Engn, Chennai, India.
   [Geetha, R.] Saveetha Univ, Saveetha Sch Engn, Dept Biomed Engn, Chennai, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai; Saveetha Institute
   of Medical & Technical Science; Saveetha School of Engineering
RP Geetha, R (corresponding author), Saveetha Univ, Saveetha Sch Engn, Dept Biomed Engn, Chennai, India.
EM kavithad0612@gmail.com; geethabaalan@gmail.com;
   rgeetha.mariappan@gmail.com
RI R, Geetha/GXH-3505-2022
OI R, Geetha/0000-0002-4451-1844
CR Abdulshahed AM, 2015, APPL SOFT COMPUT, V27, P158, DOI 10.1016/j.asoc.2014.11.012
   Aysal TC, 2007, IEEE T MED IMAGING, V26, P712, DOI 10.1109/TMI.2007.895484
   Banon GJF, 2007, P 8 INT S MATH OCT 1
   Bellsham-Revell H, 2021, FRONT CARDIOVASC MED, V8, DOI 10.3389/fcvm.2021.637838
   Bonnet D, 2021, TRANSL PEDIATR, V10, P2241, DOI 10.21037/tp-20-267
   Carvalho JS, 2002, HEART, V88, P387, DOI 10.1136/heart.88.4.387
   Ciurte A, 2012, P CHALL US BIOM MEAS, P13
   Coupé P, 2009, IEEE T IMAGE PROCESS, V18, P2221, DOI 10.1109/TIP.2009.2024064
   De Marsico M, 2015, LECT NOTES COMPUT SC, V9257, P195, DOI 10.1007/978-3-319-23117-4_17
   FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223
   Fruitman D S, 2000, Paediatr Child Health, V5, P219
   Gobergs Roberts, 2016, Acta Med Litu, V23, P86, DOI 10.6001/actamedica.v23i2.3325
   Hoffman JIE, 2002, J AM COLL CARDIOL, V39, P1890, DOI 10.1016/S0735-1097(02)01886-7
   Huang QH, 2023, EXPERT SYST APPL, V229, DOI 10.1016/j.eswa.2023.120450
   Huang QH, 2020, IEEE T FUZZY SYST, V28, P259, DOI 10.1109/TFUZZ.2019.2904920
   Huiling W, 2023, HINDAWI
   LEE JS, 1986, OPT ENG, V25, P636, DOI 10.1117/12.7973877
   Loizou CP, 2006, MED BIOL ENG COMPUT, V44, P414, DOI 10.1007/s11517-006-0045-1
   Luo YZ, 2023, BIOMED SIGNAL PROCES, V84, DOI 10.1016/j.bspc.2023.104784
   Macedo A J, 1993, Acta Med Port, V6 Suppl 1, pI9
   Michielsen K., 2001, Physics Reports, V347, P461, DOI 10.1016/S0370-1573(00)00106-X
   Mohammed NB, 2011, J PAK MED ASSOC, V61, P904
   Nirmala S, 2016, PROCEDIA COMPUT SCI, V79, P344, DOI 10.1016/j.procs.2016.03.045
   Pouch AM, 2017, LECT NOTES COMPUT SC, V10263, P95, DOI 10.1007/978-3-319-59448-4_10
   Sadek S, 2015, Int J Comput Vis Signal Process, V5, P1
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   Sridevi S, 2016, J INTELL FUZZY SYST, V31, P433, DOI 10.3233/IFS-162157
   Sridevi S, 2016, APPL SOFT COMPUT, V46, P577, DOI 10.1016/j.asoc.2015.09.002
NR 28
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30755
EP 30772
DI 10.1007/s11042-023-16682-2
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066976400001
DA 2024-07-18
ER

PT J
AU Xu, HX
   Wang, W
   Wang, SL
   Zhou, W
   Chen, Q
   Peng, W
AF Xu, Haixia
   Wang, Wei
   Wang, Shuailong
   Zhou, Wei
   Chen, Qi
   Peng, Wei
TI PPNet : pooling position attention network for semantic segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Semantic segmentation network; Attention module; PCAM- PPAM
AB Semantic segmentation with attention module has made great progress in many computer vision tasks. However, attention modules ignore some boundary information. To explore a more comprehensive map of context features, we propose a pooling position attention network (PPNet) for semantic segmentation. Based on the Encoder-Decoder structure, we import attention modules into the encoder to enhance the correlation between deep information. Pooling cross attention module (PCAM) aims to weight deep semantic information and expands the feature recognition area, and pooling position attention module (PPAM) calculates the weighted features to generate features with strong semantic information. Finally, the enhanced deep features and shallow features are fused by decoder to enhance the dependency between pixels and to achieve better semantic segmentation. Experiments show that of our proposed PPNet is superior to other state-of-the-art models in the performance of segmentation accuracy on datasets PACSCAL VOC 2012 and Cityscapes.
C1 [Xu, Haixia; Wang, Wei; Wang, Shuailong; Zhou, Wei; Chen, Qi; Peng, Wei] XiangTan Univ, Sch Automat & Elect Informat, Xiangtan, Peoples R China.
C3 Xiangtan University
RP Xu, HX (corresponding author), XiangTan Univ, Sch Automat & Elect Informat, Xiangtan, Peoples R China.
EM xhxia2002@126.com
OI xu, haixia/0000-0001-8587-7044
FU This work was supported in part by Key Program of Hunan Provincial
   Department of Education ( 22A0127), and by Key Laboratory Fund Project
   (No.2023ICIP07, No.2023ICIP03), and in part by the Natural Science
   Foundation of China (No.62003288). [2023ICIP07]; Key Program of Hunan
   Provincial Department of Education [2023ICIP03, 62003288]; Key
   Laboratory Fund Project; Natural Science Foundation of China;  [22A0127]
FX This work was supported in part by Key Program of Hunan Provincial
   Department of Education ( 22A0127), and by Key Laboratory Fund Project
   (No.2023ICIP07, No.2023ICIP03), and in part by the Natural Science
   Foundation of China (No.62003288).
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Chen LC, 2016, Arxiv, DOI arXiv:1412.7062
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan MY, 2021, PROC CVPR IEEE, P9711, DOI 10.1109/CVPR46437.2021.00959
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Ghiasi G, 2016, LECT NOTES COMPUT SC, V9907, P519, DOI 10.1007/978-3-319-46487-9_32
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Kreso I, 2016, LECT NOTES COMPUT SC, V9796, P64, DOI 10.1007/978-3-319-45886-1_6
   Li X, 2021, MULTIMED TOOLS APPL, V80, P10323, DOI 10.1007/s11042-020-09283-w
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin GS, 2016, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2016.348
   Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mostajahi M, 2015, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2015.7298959
   Ng HP, 2006, 7TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P61
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Vemulapalli R, 2016, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2016.351
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wu T, 2021, PROC CVPR IEEE, P16760, DOI 10.1109/CVPR46437.2021.01649
   Yu FS, 2016, Arxiv, DOI [arXiv:1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Yuhui Yuan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P173, DOI 10.1007/978-3-030-58539-6_11
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 37
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 2
PY 2023
DI 10.1007/s11042-023-16230-y
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5AJ3
UT WOS:001057641700003
DA 2024-07-18
ER

PT J
AU Ibrahim, SI
   El-Tawel, GS
   Makhlouf, MA
AF Ibrahim, Sa. I.
   El-Tawel, Gh. S.
   Makhlouf, M. A.
TI Brain image fusion using the parameter adaptive-pulse coupled neural
   network (PA-PCNN) and non-subsampled contourlet transform (NSCT)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image fusion; Computed tomography; Magnetic resonance image;
   Parameter adaptive pulse coupled neural networks; Nonsubsampled
   contourlet transform
AB Medical imaging has played an essential role in medicine and disease diagnosis. Medical images from a single modality contain limited data about the organ. On the other hand, images from different modalities contain valuable structural and functio nal data about an organ. Medical image fusion (MIF) strategies integrate complementary information from two medical images captured using distinct modalities. This paper offered a new multimodalMIF approach using the parameter-adaptive pulse-coupled neural networks (PA-PCNN) within the non-subsampled contourlet transform (NSCT). The NSCT decomposes those images into high- and low-frequency bands. PA-PCNN combines those bands. The fused image was created using the inverse of the NSCT approach. To prove the proposed approach's performance, we appoint a variety of medical images like computed tomography (CT), magnetic resonance imaging (MRI), single-photon emission CT (SPECT), and positron emission tomography (PET). Our experiments use five fusion metrics to validate the proposed approach's performance, such as entropy (EN), mutual information (MI), weighted edge information (QAB/ F), nonlinear correlation information entropy (Qncie), and average gradient (AG). Outcomes show that the proposed approach achieves high overall performance in visual and objective characteristics when compared with five well-known MIF methods. The average values for EN, MI, QAB/ F, Qncie, and AG with the proposed approach are 5.2144,3.1282,.6600,.8071, and 8.9874, respectively.
C1 [Ibrahim, Sa. I.; Makhlouf, M. A.] Suez Canal Univ, Fac Comp & Informat, Informat Syst Dept, Ismailia, Egypt.
   [El-Tawel, Gh. S.] Suez Canal Univ, Fac Comp & Informat, Comp Sci Dept, Ismailia, Egypt.
C3 Egyptian Knowledge Bank (EKB); Suez Canal University; Egyptian Knowledge
   Bank (EKB); Suez Canal University
RP Ibrahim, SI (corresponding author), Suez Canal Univ, Fac Comp & Informat, Informat Syst Dept, Ismailia, Egypt.
EM sara_hassan@ci.suez.edu.eg; ghada@ci.suez.edu.eg;
   m.abdallah@ci.suez.edu.eg
RI makhlouf, Mohamed/AAE-8613-2022
OI makhlouf, Mohamed/0000-0002-8854-4912; Ibrahim Ibrahim,
   Sara/0000-0003-1328-3217
CR Bavirisetti DP, 2017, INT J IMAG SYST TECH, V27, P227, DOI 10.1002/ima.22228
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Ding ZS, 2020, BIOMED RES INT, V2020, DOI 10.1155/2020/6265708
   Du J, 2016, NEUROCOMPUTING, V215, P3, DOI 10.1016/j.neucom.2015.07.160
   Eckhorn R, 1990, NEURAL COMPUT, V2, P293, DOI 10.1162/neco.1990.2.3.293
   Hermessi H, 2018, NEURAL COMPUT APPL, V30, P2029, DOI 10.1007/s00521-018-3441-1
   Huang B, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/8279342
   Ibrahim SI, 2023, MED BIOL ENG COMPUT, V61, P155, DOI 10.1007/s11517-022-02697-8
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Johnson KA, 2023, WHOLE BRAIN ATLAS
   Kaur H, 2021, ARCH COMPUT METHOD E, V28, P4425, DOI 10.1007/s11831-021-09540-7
   Li LL, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23050591
   Li LL, 2020, MULTIMED TOOLS APPL, V79, P24303, DOI 10.1007/s11042-020-09154-4
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Liu Y, 2017, 2017 20TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1070
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Mei Q, 2022, J APPL SCI ENG, V26, P213
   Polinati Srinivasu, 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0554, DOI 10.1109/ICCSP.2019.8697906
   Tan W, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102280
   Tan W, 2020, NEURAL COMPUT APPL, DOI 10.1007/s00521-020-05173-2
   Tawfik N, 2021, MULTIMED TOOLS APPL, V80, P6369, DOI 10.1007/s11042-020-08834-5
   Tian Y, 2016, INT CONF SIGN PROCES, P799, DOI 10.1109/ICSP.2016.7877941
   Vanitha K., 2022, Soft Computing and Signal Processing: Proceedings of 4th ICSCSP 2021. Advances in Intelligent Systems and Computing (1413), P457, DOI 10.1007/978-981-16-7088-6_42
   Vanitha K, 2021, CURR MED IMAGING, V17, P634, DOI 10.2174/1573405616666201118123220
   Wang ZB, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103823
   Xia JM, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/3290136
   Yin M, 2019, IEEE T INSTRUM MEAS, V68, P49, DOI 10.1109/TIM.2018.2838778
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zhu ZQ, 2019, IEEE ACCESS, V7, P20811, DOI 10.1109/ACCESS.2019.2898111
NR 29
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27379
EP 27409
DI 10.1007/s11042-023-16515-2
EA SEP 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001059921400007
OA hybrid
DA 2024-07-18
ER

PT J
AU Matsuhira, C
   Kastner, MA
   Komamizu, T
   Ide, I
   Hirayama, T
   Kawanishi, Y
   Doman, K
   Deguchi, D
AF Matsuhira, Chihaya
   Kastner, Marc A.
   Komamizu, Takahiro
   Ide, Ichiro
   Hirayama, Takatsugu
   Kawanishi, Yasutomo
   Doman, Keisuke
   Deguchi, Daisuke
TI Computational measurement of perceived pointiness from pronunciation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Phonetic impression; Pronunciation; Vision and language; Image
   generation; Affective computing; Psycholinguistics
ID SOUND SYMBOLISM; SHAPE; CORRESPONDENCES
AB Sound symbolism is a well-researched topic of psycholinguistics, which tries to comprehend the connection between the sound of a word and its meanings. The Bouba-Kiki effect, one form of sound symbolism, claims that people perceive the pronunciation of "Kiki" as pointier than that of "Bouba." There is no research that focuses on modeling such perception, i.e., how pointy a pronunciation sounds to humans, through computational and data-driven approaches. To address this, this paper first proposes the novel concept of "phonetic pointiness" defined as how pointy a shape humans are most likely to associate with a given pronunciation. We then model this phonetic pointiness from computational and data-driven approaches to calculate a score for an arbitrary pronunciation. There are three proposed models: a referential model, an expressive model, and a combined model, which integrates the previous two. The idea comes from an existing psycholinguistic classification of two types of sound symbolisms: referential symbolism and expressive symbolism, where the former relates to vocabulary knowledge, while the latter is based on pure human intuition. The proposed models are constructed only with image and language data available on the Web, therefore not requiring task-specific human annotations. We evaluate these models through a crowd-sourced user study, finding a promising correlation between human perception and the phonetic pointiness calculated by the proposed models. The results indicate that human perception can be modeled better by combining both types of sound symbolisms. Furthermore, by observing the behaviors of the models, we show several possible use-cases, such as product naming and psycholinguistic research, which can be a useful insight to further studies and applications.
C1 [Matsuhira, Chihaya; Ide, Ichiro; Deguchi, Daisuke] Nagoya Univ, Grad Sch Informat, Furo Cho,Chikusa Ku, Nagoya, Aichi 4648601, Japan.
   [Kastner, Marc A.] Kyoto Univ, Grad Sch Informat, Yoshida Honmachi,Sakyo Ku, Kyoto 6068501, Japan.
   [Komamizu, Takahiro] Nagoya Univ, Math & Data Sci Ctr, Furo Cho,Chikusa Ku, Nagoya, Aichi 4648601, Japan.
   [Hirayama, Takatsugu] Univ Human Environm, Fac Environm Sci, 6-2 Kami Sanbonmatsu,Motojuku Cho, Okazaki, Aichi 4443505, Japan.
   [Kawanishi, Yasutomo] RIKEN, Informat R&D & Strategy Headquarters, 2-2-2 Hikaridai, Seika, Kyoto 6190288, Japan.
   [Doman, Keisuke] Chukyo Univ, Sch Engn, 101 Tokodachi,Kaizu Cho, Toyota, Aichi 4700393, Japan.
C3 Nagoya University; Kyoto University; Nagoya University; RIKEN; Chukyo
   University
RP Matsuhira, C (corresponding author), Nagoya Univ, Grad Sch Informat, Furo Cho,Chikusa Ku, Nagoya, Aichi 4648601, Japan.
EM matsuhirac@cs.is.i.nagoya-u.ac.jp; mIcastner@LIcyoto-u.ac.jp;
   talca-coma@acm.org; ide@inagoya-u.ac.jp; t-hirayama@uhe.ac.jp;
   yasutomo.kawanishi@riken.jp; kdotnan@sist.chukyo-u.ac.jp;
   ddeguchi@nagoya-u.jp
RI Ide, Ichiro/M-4863-2014; Kawanishi, Yasutomo/AAF-9529-2019
OI Ide, Ichiro/0000-0003-3942-9296; Kawanishi,
   Yasutomo/0000-0002-3799-4550; Kastner, Marc/0000-0002-9193-5973;
   Deguchi, Daisuke/0000-0003-0603-8790; Matsuhira,
   Chihaya/0000-0003-2453-4560; Komamizu, Takahiro/0000-0002-3041-4330
FU Microsoft Research CORE16 program; JSPS [22H03612]; Japan Science and
   Technology Agency and Nagoya University
FX This work was partly supported by Microsoft Research CORE16 program,
   JSPS Grant-in-aid for Scientific Research (22H03612), and Nagoya
   University Interdisciplinary Frontier Fellowship supported by Japan
   Science and Technology Agency and Nagoya University. This work is a
   fruit of a joint research project between Nagoya University and the
   National Institute of Informatics. The computation was carried out using
   the General Projects on supercomputer "Flow" at Information Technology
   Center, Nagoya University.
CR Bremner AJ, 2013, COGNITION, V126, P165, DOI 10.1016/j.cognition.2012.09.007
   Chen YC, 2016, SCI REP-UK, V6, DOI 10.1038/srep26681
   Cwiek A, 2021, Philos. Trans. Royal Soc. B
   Fort M, 2015, LANG SPEECH, V58, P247, DOI 10.1177/0023830914534951
   Fukusato T, 2014, PROC 7 INT C MOTION, P161, DOI [10.1145/2668064.2668096, DOI 10.1145/2668064.2668096]
   Gillet O, 2005, J INTELL INF SYST, V24, P159, DOI 10.1007/s10844-005-0321-9
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hensel M, 2017, ADV NEUR IN, V30
   Hinton L., 1995, Cambridge University Press, Cambridge, England, UK, DOI [10.1017/CBO9780511751806, DOI 10.1017/CBO9780511751806]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   International Phonetic Association, 1999, Handbook of the International Phonetic Association: A guide to the use of the International Phonetic Alphabet
   Knoeferle K, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05965-y
   Kohler W. W., 1929, Gestalt Psychology
   Kolachina S, 2019, 16TH SIGMORPHON WORKSHOP ON COMPUTATIONAL RESEARCH IN PHONETICS PHONOLOGY, AND MORPHOLOGY (SIGMORPHON 2019), P160
   Matsuhira C, 2021, HCI INT C 2021 POSTE, V1419, P137, DOI [10.1007/978-3-030, DOI 10.1007/978-3-030]
   Maurer D, 2006, DEVELOPMENTAL SCI, V9, P316, DOI 10.1111/j.1467-7687.2006.00495.x
   McCormick K, 2015, P 37 ANN M COGN SCI, P1565
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Monaghan P, 2012, J EXP PSYCHOL LEARN, V38, P1152, DOI 10.1037/a0027747
   Ozturk O, 2013, J EXP CHILD PSYCHOL, V114, P173, DOI 10.1016/j.jecp.2012.05.004
   Papantoniou K, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2154
   Ramachandran V, 2001, J CONSCIOUSNESS STUD, V8, P3
   ROGERS SK, 1975, PERCEPTION, V4, P105, DOI 10.1068/p040105
   Sabbatino V, 2022, PROCEEDINGS OF THE 12TH WORKSHOP ON COMPUTATIONAL APPROACHES TO SUBJECTIVITY, SENTIMENT & SOCIAL MEDIA ANALYSIS, P37
   Sapir E, 1929, J EXP PSYCHOL, V12, P225, DOI 10.1037/h0070931
   Styles SJ, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517724807
   Sundaram S, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1341, DOI 10.1109/ICME.2008.4607691
   Tao M, 2022, Arxiv, DOI arXiv:2008.05865
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wells J.C., 1982, Accents of English, V1, DOI [10.1017/CBO9780511611759, DOI 10.1017/CBO9780511611759]
NR 31
TC 1
Z9 1
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26183
EP 26210
DI 10.1007/s11042-023-15732-z
EA AUG 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001063783300001
OA hybrid
DA 2024-07-18
ER

PT J
AU Khosla, T
   Verma, OP
AF Khosla, Tejna
   Verma, Om Prakash
TI Optimal threshold selection for segmentation of Chest X-Ray images using
   opposition-based swarm-inspired algorithm for diagnosis of pneumonia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chameleon swarm algorithm; Cross entropy thresholding; Medical imaging;
   Particle swarm optimization algorithm; Pneumonia; Segmentation
ID WOLF OPTIMIZER; ENTROPY; CLASSIFICATION
AB Image Segmentation using thresholding is one of the most significant areas of image processing. However, the challenge lies in accurately and effectively segmenting medical images, which is a crucial step in many applications of medical image analysis. It necessitates the development of an effective and robust segmentation approach that can handle the complexity and diversity of medical images. To address this problem, we propose a novel image segmentation technique based on minimizing the cross-entropy function using a hybrid approach that combines the features of Opposition-Based Learning (OBL), Chameleon Swarm Algorithm (CSA), and Particle Swarm Optimization Algorithm (PSO). The opposition-based technique generates the initial population and improves convergence. Then, PSO and CSA are run in parallel on an unequal population set to improve the optimal results. The proposed approach, named the Opposition-based Chameleon Swarm Algorithm improved by Particle Swarm Algorithm (CSAPSO), is evaluated on twelve Chest X-Ray (CXR) images of patients for the detection of Pneumonia. It is further tested on a large data set related to COVID-19. We conducted extensive comparisons with other state-of-the-art methods and the Deep Learning Algorithms and used the performance indicators, namely Root Mean Square Error (RMSE), Peak Signal to Noise Ratio (PSNR) and Structure Similarity Index (SSIM), Classification Accuracy, Area Under Curve for evaluating the performance. The proposed approach is statically analyzed using the Friedman rank-sum test. Through the analysis, CSAPSO demonstrates better global optimal results compared to state-of-the-art techniques.
C1 [Khosla, Tejna] Delhi Technol Univ, Comp Sci Engn Dept, Bawana, Delhi, India.
   [Verma, Om Prakash] Delhi Technol Univ, Elect & Commun Engn Dept, Bawana, Delhi, India.
C3 Delhi Technological University; Delhi Technological University
RP Khosla, T (corresponding author), Delhi Technol Univ, Comp Sci Engn Dept, Bawana, Delhi, India.
EM patoditejna@gmail.com; opverma.dce@gmail.com
RI Verma, Om/AAD-1007-2019
OI Verma, Om/0000-0002-7421-295X; Khosla, Tejna/0000-0001-7189-891X
CR Abbas Q, 2013, INT J INNOV COMPUT I, V9, P2155
   Abd El Aziz M, 2017, EXPERT SYST APPL, V83, P242, DOI 10.1016/j.eswa.2017.04.023
   Abd ElAziz M, 2016, HYBRID SOFT COMPUTIN, P1, DOI DOI 10.1007/978-3-319-47223-2_1
   Ahmed HM, 2018, APPL OPTICS, V57, pB25, DOI 10.1364/AO.57.000B25
   Alwerfali HSN, 2019, IEEE ACCESS, V7, P181405, DOI 10.1109/ACCESS.2019.2959325
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P8707, DOI 10.1016/j.eswa.2015.07.025
   Bhandari AK, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.105515
   Bhuyan Hemanta Kumar, 2022, 2022 International Conference on Advancements in Smart, Secure and Intelligent Computing (ASSIC), P1, DOI 10.1109/ASSIC55218.2022.10088325
   Bhuyan HK, 2022, HEALTH TECHNOL-GER, V12, P987, DOI 10.1007/s12553-022-00687-2
   Bhuyan HK, 2021, IEEE T ENG MANAG
   Brahma B, 2022, CONNECTED E HLTH INT, P83
   Braik MS, 2021, EXPERT SYST APPL, V174, DOI 10.1016/j.eswa.2021.114685
   Breve F, 2019, EXPERT SYST APPL, V123, P18, DOI 10.1016/j.eswa.2019.01.031
   Chatterjee A, 2012, ENG APPL ARTIF INTEL, V25, P1698, DOI 10.1016/j.engappai.2012.02.007
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cleverley J, 2020, BMJ-BRIT MED J, V370, DOI 10.1136/bmj.m2426
   Ewees AA, 2020, IEEE ACCESS, V8, P26304, DOI 10.1109/ACCESS.2020.2971249
   Hammouche K, 2008, COMPUT VIS IMAGE UND, V109, P163, DOI 10.1016/j.cviu.2007.09.001
   Jiang ZQ, 2021, ARAB J SCI ENG, V46, P8371, DOI 10.1007/s13369-021-05483-0
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kermany Daniel, 2018, Mendeley Data, V3
   Khairuzzaman AKM, 2017, EXPERT SYST APPL, V86, P64, DOI 10.1016/j.eswa.2017.04.029
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Kullback S., 1959, STAT INFORM THEORY
   Ladgham A, 2015, SIGNAL IMAGE VIDEO P, V9, P1113, DOI 10.1007/s11760-013-0546-y
   Lee SH, 2010, PATTERN RECOGN LETT, V31, P2325, DOI 10.1016/j.patrec.2010.07.004
   LI CH, 1993, PATTERN RECOGN, V26, P617, DOI 10.1016/0031-3203(93)90115-D
   Li CH, 1998, PATTERN RECOGN LETT, V19, P771, DOI 10.1016/S0167-8655(98)00057-9
   Li YY, 2017, APPL SOFT COMPUT, V56, P345, DOI 10.1016/j.asoc.2017.03.018
   Li YY, 2015, INFORM SCIENCES, V294, P408, DOI 10.1016/j.ins.2014.10.005
   Nie FY, 2017, SIGNAL PROCESS, V134, P23, DOI 10.1016/j.sigpro.2016.11.004
   Oliva D, 2017, EXPERT SYST APPL, V79, P164, DOI 10.1016/j.eswa.2017.02.042
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Panda R, 2017, APPL SOFT COMPUT, V50, P94, DOI 10.1016/j.asoc.2016.11.011
   Pare S, 2018, COMPUT ELECTR ENG, V70, P476, DOI 10.1016/j.compeleceng.2017.08.008
   Pare S, 2017, APPL SOFT COMPUT, V61, P570, DOI 10.1016/j.asoc.2017.08.039
   PUN T, 1981, COMPUT VISION GRAPH, V16, P210, DOI 10.1016/0146-664X(81)90038-1
   Farshi TR, 2021, MULTIMEDIA SYST, V27, P125, DOI 10.1007/s00530-020-00716-y
   Raj A, 2019, IMAGE VISION COMPUT, V91, DOI 10.1016/j.imavis.2019.07.004
   Raja N., 2018, INNOVATIONS ELECT CO, P229, DOI [10.1007/978-981-10-3812-9_24, DOI 10.1007/978-981-10-3812-9_24]
   Raja N. Sri Madhava, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P961, DOI 10.1007/s12652-018-0854-8
   Rajinikanth V, 2015, PROCEDIA COMPUT SCI, V46, P1449, DOI 10.1016/j.procs.2015.02.064
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sarkar S, 2017, APPL SOFT COMPUT, V50, P142, DOI 10.1016/j.asoc.2016.10.032
   Shao DG, 2019, IET IMAGE PROCESS, V13, P998, DOI 10.1049/iet-ipr.2018.6150
   Sun GY, 2016, APPL SOFT COMPUT, V46, P703, DOI 10.1016/j.asoc.2016.01.054
   Tang N, 2018, NEUROCOMPUTING, V318, P261, DOI 10.1016/j.neucom.2018.08.064
   Tizhoosh HR, 2006, INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING, CONTROL & AUTOMATION JOINTLY WITH INTERNATIONAL CONFERENCE ON INTELLIGENT AGENTS, WEB TECHNOLOGIES & INTERNET COMMERCE, VOL 1, PROCEEDINGS, P695, DOI 10.1109/cimca.2005.1631345
   Tuba E., 2017, SUPPORT VECTOR MACHI
   Upadhyay P, 2021, J AMB INTEL HUM COMP, V12, P1081, DOI 10.1007/s12652-020-02143-3
   Wang R, 2015, BIO-MED MATER ENG, V26, pS1345, DOI 10.3233/BME-151432
   Wang SK, 2020, MATH BIOSCI ENG, V17, P700, DOI 10.3934/mbe.2020036
   Yin PY, 2007, APPL MATH COMPUT, V184, P503, DOI 10.1016/j.amc.2006.06.057
   Yue XF, 2019, ARAB J SCI ENG, V44, P9221, DOI 10.1007/s13369-019-03874-y
NR 56
TC 1
Z9 1
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27089
EP 27119
DI 10.1007/s11042-023-16494-4
EA AUG 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060295500003
DA 2024-07-18
ER

PT J
AU Jemal, MA
   Sallami, MM
   Ghorbel, F
AF Jemal, Maroua Affes
   Sallami, Mallek Mziou
   Ghorbel, Faouzi
TI Robust watermarking method based on the Analytical Clifford Fourier
   Mellin Transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Geometric attacks; Colour images; Analytical Clifford
   Fourier Mellin transform
ID COLOR IMAGE WATERMARKING; DIGITAL WATERMARKING; QUATERNION; ALGORITHM;
   SCHEME; SVD
AB In this paper, we intend to introduce a semi-blind watermarking algorithm for colour images according to the RGB standard, which takes into account the interdependence of the three planes. In this context, it is often desirable that these algorithms verify certain independency with respect to the pose difference and a robustness with respect to the attacks caused by the compression. On the other hand, the inversion properties and the compressive power of the algorithms are also required criteria. The approach based on the Analytical Fourier Mellin Transform (AFMT) confirms all these recommendations. However, its scalar character can only result in a separate watermark within the meaning of RGB planes. In a recent work, we were able to show that the Fourier transform defined on the Clifford algebra is suitable for joint watermarking of colour images. However, its numerical approximations presents a problem of convergence in neighbour the origin. This results in digital instability in the frame of the image data. Inspired by the work carried out on the Mellin Analytical Fourier transform (AFMT), we propose here the construction of an analytical extension of the Clifford transform which we propose to call the Analytical Mellin Clifford Transform (ACMT). An approximation is given guaranteeing its convergent and its numerical stability in the context of watermarking of images. Furthermore, the properties of invariance with respect to rigid geometric transformations and its robustness with respect to certain compression algorithm are proven by simulations. Thus, its good performances in terms of imperceptibility and robustness against JPEG compression and geometric attacks are demonstrated on the BSD300 and USC-SIPI databases.
C1 [Jemal, Maroua Affes; Ghorbel, Faouzi] Ecole Natl Sci Informat, CRISTAL Lab, GRIFT Grp, Campus Univ, Manouba 2010, Manouba, Tunisia.
   [Sallami, Mallek Mziou] CEA, French Alternat Energies & Atom Energy Commiss, F-91000 Evry, France.
C3 Universite de la Manouba; CEA
RP Sallami, MM (corresponding author), CEA, French Alternat Energies & Atom Energy Commiss, F-91000 Evry, France.
EM maroua.affes@ensi-uma.tn; mallek.mziou@cea.fr;
   faouzi.ghorbel@ensi.rnu.tn
OI Ghorbel, Faouzi/0000-0002-6364-1089
CR Affes M, 2016, LECT NOTES COMPUT SC, V10016, P453, DOI 10.1007/978-3-319-48680-2_40
   Bamatraf A., 2010, 2010 International Conference on Computer Applications and Industrial Electronics (ICCAIE), P155, DOI 10.1109/ICCAIE.2010.5735066
   Bas P, TATOUAGE IMAGES COUL
   Burgett S, 1998, IEEE COMMUN MAG, V36, P94, DOI 10.1109/35.663333
   Chen BJ, 2014, DIGIT SIGNAL PROCESS, V28, P106, DOI 10.1016/j.dsp.2014.02.010
   Chou CH, 2010, IEEE T IMAGE PROCESS, V19, P2966, DOI 10.1109/TIP.2010.2052261
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Dhaked DK, 2021, EMERGING TRENDS DATA, P169
   Ghorbel F, 1998, ANN TELECOMMUN, V53, P242
   GHORBEL F, 1994, PATTERN RECOGN LETT, V15, P1043, DOI 10.1016/0167-8655(94)90037-X
   Gohil J, 2021, ADV SEC SOLUT MULTIM, P2053
   Guo LQ, 2011, PATTERN RECOGN, V44, P187, DOI 10.1016/j.patcog.2010.08.017
   Hosny KM, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3325193
   Hwang J, 2006, LECT NOTES COMPUT SC, V4283, P348
   Ketipearachchi T., 2020, INT J ADV ICT EMERG, V13, P2
   KUMAR A, 1994, INT J DEV NEUROSCI, V12, P31, DOI 10.1016/0736-5748(94)90093-0
   Kutter M, 1998, J ELECTRON IMAGING, V7, P326, DOI 10.1117/1.482648
   Lang J, 2014, OPT LASER ENG, V53, P112, DOI 10.1016/j.optlaseng.2013.08.021
   Liu JX, 2019, IEEE ACCESS, V7, P80849, DOI 10.1109/ACCESS.2019.2915596
   Lusson F, 2013, SIGNAL PROCESS, V93, P1268, DOI 10.1016/j.sigpro.2012.10.018
   M'Hiri S, 2012, TRAIT SIGNAL, V29, P123, DOI 10.3166/TS.29.123-142
   Maweheb Saidani, 2016, Digital Applications in Archaeology and Cultural Heritage, V3, P99, DOI 10.1016/j.daach.2016.10.001
   Mennesson J, 2014, PATTERN RECOGN LETT, V40, P27, DOI 10.1016/j.patrec.2013.12.014
   MEZGHICH MA, 2013, 21 EUR SIGN PROC C, P1
   Nagaraju G, 2019, INT J INNOV ENG MANA, P118
   Niu PP, 2016, MULTIMED TOOLS APPL, V75, P7655, DOI 10.1007/s11042-015-2687-1
   Niu PP, 2011, EXPERT SYST APPL, V38, P2081, DOI 10.1016/j.eswa.2010.07.147
   ORuanaidh JJK, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P239, DOI 10.1109/ICIP.1996.560428
   Pandey P, 2014, MULTIMED TOOLS APPL, V72, P2653, DOI 10.1007/s11042-013-1577-7
   Pandey P, 2014, MULTIMED TOOLS APPL, V72, P723, DOI 10.1007/s11042-013-1375-2
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Piva A., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P306, DOI 10.1109/ICIP.1999.821619
   Sangwine SJ, 1996, ELECTRON LETT, V32, P1979, DOI 10.1049/el:19961331
   Sellami M, 2012, EUR SIGNAL PR CONF, P390
   Sellami M, 2012, IEEE MEDITERR ELECT, P125, DOI 10.1109/MELCON.2012.6196395
   Shih FY, 2016, INFORM SCIENCES, V367, P648, DOI 10.1016/j.ins.2016.07.015
   Singh Shalu, 2016, 2016 International Conference on Computational Techniques in Information and Communication Technologies (ICCTICT). Proceedings, P141, DOI 10.1109/ICCTICT.2016.7514568
   Taha DB, 2019, J ENG SCI TECHNOL, V14, P3347
   Tsui TK, 2008, IEEE T INF FOREN SEC, V3, P16, DOI 10.1109/TIFS.2007.916275
   Wang XY, 2013, J SYST SOFTWARE, V86, P255, DOI 10.1016/j.jss.2012.08.015
   YAO Z, 2020, SIGNAL IMAGE VIDEO P, P1
   Zhang LN, 2020, DIGIT SIGNAL PROCESS, V106, DOI 10.1016/j.dsp.2020.102805
   Zhang LN, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107421
   Zhao J., 1995, Intellectual Property Rights and New Technologies. Proceedings of the KnowRight'95 Conference, P242
NR 44
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25901
EP 25922
DI 10.1007/s11042-023-16482-8
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060201500001
DA 2024-07-18
ER

PT J
AU Wang, ZX
   Zheng, CY
   Wang, CL
   Wang, JY
   Yu, SS
   Nie, J
AF Wang, Zhaoxin
   Zheng, Chengyu
   Wang, Chenglong
   Wang, Jingyu
   Yu, Shusong
   Nie, Jie
TI Statistical texture involved multi-granularity attention network for
   remote sensing semantic segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Statistical textures; Multi-granularity; Remote sensing images; Semantic
   segmentation; Attention mechanism
ID CLASSIFICATION
AB In recent years,semantic segmentation technology plays an important role in land resource management tasks. However, many classic semantic segmentation models often fail to obtain satisfactory results for remote sensing images with large difference of object scale span. The statistical texture involved multi-granularity attention network has been proposed to improve this situation. Statistical texture involved multi-granularity attention network has an encoder-decoder structure which is similar to DeeplabV3+ 2018. On this basis,texture excitation module and multi-granularity attention module are proposed to improve the accuracy of semantic segmentation. Texture excitation module is designed to extract statistical texture feature that are hidden in the image so that they can be combined with spatial structure feature for better prediction. Specifically, this module calculates the pixel co-occurrence matrix in the horizontal, vertical, diagonal, and anti diagonal directions. Multi-granularity attention module provides a more comprehensive understanding of the image by simultaneously focusing on the image at coarse,medium and fine granularity. Specifically, this module designs coarse granularity, medium granularity, and fine granularity spatial attention mechanisms and coarse granularity, medium granularity, and fine granularity channel attention mechanisms based on the core idea of self attention mechanism. Statistical texture involved multi-granularity attention network is compared with several of the most advanced deep learning methods on the Vaihingen data set and Potsdam data set.Compared with the best performing method, our method has increased by 0.73%, 1.88% and 0.013 in pixel accuracy,mean intersection over union and F1 score respectively on Vaihingen data set; our method improves the pixel accuracy from 87.82% to 88.50%, the mean intersection over union from 74.53% to 75.82%, and the F1 score from 0.8488 to 0.8573 on Potsdam data set.
C1 [Wang, Zhaoxin; Zheng, Chengyu; Wang, Chenglong; Wang, Jingyu; Yu, Shusong; Nie, Jie] Ocean Univ China, Fac Informat Sci & Engn, 238 Songling Rd, Qingdao 266100, Shandong Provin, Peoples R China.
C3 Ocean University of China
RP Nie, J (corresponding author), Ocean Univ China, Fac Informat Sci & Engn, 238 Songling Rd, Qingdao 266100, Shandong Provin, Peoples R China.
EM wangzhaoxin@stu.ouc.edu.cn; zhengchengyu@stu.ouc.edu.cn;
   wangchenglong@stu.ouc.edu.cn; wangjingyu3186@stu.ouc.edu.cn;
   yushusong@ouc.edu.cn; niejie@ouc.edu.cn
RI Wang, Huiyan/JXW-9178-2024; wang, chenglong/GQQ-2852-2022; LIU,
   JIALIN/JXN-8034-2024; Li, Xiaoli/JVZ-4089-2024; Nie, Jie/ABG-9228-2021
OI wang, chenglong/0000-0002-3567-5759; Nie, Jie/0000-0003-4952-7666
FU Fundamental Research Funds for the Central Universities [202042008];
   National Natural Science Foundation of China [62172376, 62072418]; Major
   Scientific and Technological Innovation Project of Shandong
   [2019JZZY020705]; Key Research and Development Program of Qingdao
   Science and Technology Plan [21-1-2-18-xx]
FX This work was supported in part by the Fundamental Research Funds for
   the Central Universities (202042008), the National Natural Science
   Foundation of China (62172376, 62072418), the Major Scientific and
   Technological Innovation Project of Shandong (2019JZZY020705), and the
   Key Research and Development Program of Qingdao Science and Technology
   Plan (21-1-2-18-xx)
CR Adede C, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091099
   Bacanin N, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09744-2
   Bacanin N, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9212705
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Cao Hu, 2023, Computer Vision - ECCV 2022 Workshops: Proceedings. Lecture Notes in Computer Science (13803), P205, DOI 10.1007/978-3-031-25066-8_9
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen YP, 2019, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2019.00052
   Deng GH, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3055950
   Ding L, 2021, IEEE T GEOSCI REMOTE, V59, P426, DOI 10.1109/TGRS.2020.2994150
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Fu YY, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9030261
   Guo ZL, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112487
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang B, 2018, REMOTE SENS ENVIRON, V214, P73, DOI 10.1016/j.rse.2018.04.050
   Huang ZJ, 2014, OPTIK, V125, P516, DOI 10.1016/j.ijleo.2013.07.010
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Kampffmeyer M, 2016, IEEE COMPUT SOC CONF, P680, DOI 10.1109/CVPRW.2016.90
   KANOPOULOS N, 1988, IEEE J SOLID-ST CIRC, V23, P358, DOI 10.1109/4.996
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu QH, 2020, IEEE COMPUT SOC CONF, P199, DOI 10.1109/CVPRW50498.2020.00030
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Malakar S, 2020, NEURAL COMPUT APPL, V32, P2533, DOI 10.1007/s00521-018-3937-8
   Pan XR, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11080917
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   ROSENFELD A, 1981, IEEE T PATTERN ANAL, V3, P101, DOI 10.1109/TPAMI.1981.4767056
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun WW, 2018, IEEE GEOSCI REMOTE S, V15, P474, DOI 10.1109/LGRS.2018.2795531
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tatsumi K, 2015, COMPUT ELECTRON AGR, V115, P171, DOI 10.1016/j.compag.2015.05.001
   Wang ZW, 2010, ENVIRON MODELL SOFTW, V25, P1149, DOI 10.1016/j.envsoft.2010.03.019
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie EZ, 2021, ADV NEUR IN, V34
   Zhang C, 2020, REMOTE SENS ENVIRON, V237, DOI 10.1016/j.rse.2019.111593
   Zhang WX, 2017, COMPUT ENVIRON URBAN, V64, P215, DOI 10.1016/j.compenvurbsys.2017.03.001
   Zhang Y., 2022, PROC IEEECVF C COMPU, P1258
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 44
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25817
EP 25841
DI 10.1007/s11042-023-16500-9
EA AUG 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001064537600005
DA 2024-07-18
ER

PT J
AU Rai, HM
AF Rai, Hari Mohan
TI Cancer detection and segmentation using machine learning and deep
   learning techniques: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Cancer detection; Machine learning; Deep learning; Feature extraction;
   State-of-art analysis; Brain tumor; Leukemia; Blood cancer; Colorectal
   cancer; Prostate cancer; Lung cancer; Skin cancer; Breast cancer
ID COLORECTAL-CANCER; CLASSIFICATION; IMAGES; TUMOR; ALGORITHMS; FEATURES;
   SYSTEM
AB Cancer is the most fatal diseases in the world which has highest mortality rate as compared to other type's human diseases. The most common and dangerous types of cancers are lung cancer, skin cancer, brain tumors, breast cancer, Colorectal cancer, Prostate Cancer, Blood cancer and many other. The millions of person lose their life due to these highly dangerous, fatal types of disease. Hence it is required to provide the solution using computer added automatic cancer detection technique in early stage, for the research gap analysis is required. In this paper we have studied the various cancer detection techniques based on traditional machine learning (ML) and deep learning (DL) techniques and summarize the research gap for the various cancers detection techniques. The study has been conducted based the types of technique uses, types of features utilized, dataset used and accuracy of the cancer detection achieved using best technique. In this study we have conducted the reviewed over 100 recently published research papers and focused on 7 types of most fatal cancer types such as lung cancer, breast cancer, skin cancer, brain tumor, colorectal, prostate, and Leukemia (Blood cancer). The study also used the state-of-art table to compare the previous and current study conducted on cancer detection techniques. We have visualized using separate comparison table for 7 types of cancer detection using traditional ML method and DL methods also visualized through the bar chart. The best accuracy result obtained using ML and DL methods are 100% and the most commonly used ML classifier is Support Vector Machine whereas CNN is most commonly used DL classifier. The main challenges we observed are the data imbalance issue, varieties of feature extraction techniques, small medical dataset, classifier parameters optimizations, Execution time, Adaptive classifier, and common technique for segmentation and classification. The main objective of this review is to investigate the existing methods used for the various types of cancer detection and finding the research gap, challenges, and recent advancement mainly in the use of ML and DL models which may help the researchers to find the better solutions.
C1 [Rai, Hari Mohan] Gachon Univ, Sch Comp, 1342 Seongnam daero, Seongnam si 13120, Gyeonggi do, South Korea.
C3 Gachon University
RP Rai, HM (corresponding author), Gachon Univ, Sch Comp, 1342 Seongnam daero, Seongnam si 13120, Gyeonggi do, South Korea.
EM harimohanrai@gmail.com
RI Rai, Dr. Hari Mohan/L-8104-2015
OI Rai, Dr. Hari Mohan/0000-0003-2557-3510
CR Abdel-Zaher AM, 2016, EXPERT SYST APPL, V46, P139, DOI 10.1016/j.eswa.2015.10.015
   Abdelhafeez A, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1123581
   Abdelmaksoud IR, 2023, STATE ART NEURAL NET, P83, DOI [10.1016/B978-0-12-819872-8.00011-2, DOI 10.1016/B978-0-12-819872-8.00011-2]
   Abhishek A, 2023, BIOMED SIGNAL PROCES, V83, DOI 10.1016/j.bspc.2023.104722
   Abiwinanda N, 2019, IFMBE PROC, V68, P183, DOI 10.1007/978-981-10-9035-6_33
   Akinnuwesi BA, 2023, Data Sci Manag, V6, P1
   Alboaneen D, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7020074
   Alfian G, 2022, COMPUTERS, V11, DOI 10.3390/computers11090136
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   [Anonymous], 2019, The Indian Express
   Arooj S, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.924432
   Arowolo M.O, 2023, Data Science for Genomics, P205, DOI [10.1016/b978-0-323-98352-5.00004-5, DOI 10.1016/B978-0-323-98352-5]
   Asadi B., 2023, Int. J. Intell. Networks, V4, P46, DOI DOI 10.1016/J.IJIN.2023.02.001
   Barlow H, 2019, DATA, V4, DOI 10.3390/data4030129
   Battista A, 2021, COMPUT METH PROG BIO, V212, DOI 10.1016/j.cmpb.2021.106494
   Bebas E, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102446
   Bhargav Setlem, 2022, 2022 International Conference on Disruptive Technologies for Multi-Disciplinary Research and Applications (CENTCON), P119, DOI 10.1109/CENTCON56610.2022.10051495
   Bhatia S, 2019, ADV INTELL SYST COMP, V817, P699, DOI 10.1007/978-981-13-1595-4_55
   Bi DZ, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102631
   Brockmoeller S, 2022, J PATHOL, V256, P269, DOI 10.1002/path.5831
   Bukhari M, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/2801227
   Bulten W, 2022, NAT MED, V28, P154, DOI 10.1038/s41591-021-01620-2
   Chakravarthy SRS, 2022, IRBM, V43, P49, DOI 10.1016/j.irbm.2020.12.004
   Chehade AH, 2022, PHYS ENG SCI MED, DOI 10.1007/s13246-022-01139-x
   Dabass M., 2023, Intelligence-Based Medicine, V7, DOI DOI 10.1016/J.IBMED.2023.100094
   Das PK, 2022, IEEE ACCESS, V10, P81741, DOI 10.1109/ACCESS.2022.3196037
   Depto DS, 2023, COMPUT BIOL MED, V152, DOI 10.1016/j.compbiomed.2022.106372
   Din NMU, 2022, COMPUT BIOL MED, V149, DOI 10.1016/j.compbiomed.2022.106073
   Ferlay J, 2019, INT J CANCER, V144, P1941, DOI 10.1002/ijc.31937
   Goerner F, 2011, MED PHYS, V38, DOI 10.1118/1.3611705
   Gomathi E, 2023, BIOMED SIGNAL PROCES, V84, DOI 10.1016/j.bspc.2023.104968
   Gupta N, 2017, SIGNAL PROCESS-IMAGE, V59, P18, DOI 10.1016/j.image.2017.05.013
   Hamid MAA, 2020, J MED BIOL ENG, V40, P307, DOI 10.1007/s40846-020-00510-1
   Hamm CA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.222276
   Han SS, 2018, J INVEST DERMATOL, V138, P1529, DOI 10.1016/j.jid.2018.01.028
   Hasan M, 2019, ICCAI '19 - PROCEEDINGS OF THE 2019 5TH INTERNATIONAL CONFERENCE ON COMPUTING AND ARTIFICIAL INTELLIGENCE, P254, DOI 10.1145/3330482.3330525
   Hassan MR, 2022, FUTURE GENER COMP SY, V127, P462, DOI 10.1016/j.future.2021.09.030
   Ho CW, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-06264-x
   Hosni M, 2019, COMPUT METH PROG BIO, V177, P89, DOI 10.1016/j.cmpb.2019.05.019
   Hosseinzadeh M, 2019, J PHOTOCH PHOTOBIO B, V199, DOI 10.1016/j.jphotobiol.2019.111590
   Ibrahim A, 2022, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.884749
   Imran A, 2022, IEEE ACCESS, V10, P118198, DOI 10.1109/ACCESS.2022.3220329
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Jusman Y, 2021, 2021 11TH IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2021), P137, DOI 10.1109/ICCSCE52189.2021.9530974
   Karayegen G, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102458
   Kaur R, 2022, BMC MED IMAGING, V22, DOI 10.1186/s12880-022-00829-y
   Kavitha MS, 2022, CANCERS, V14, DOI 10.3390/cancers14153707
   Kazemi Fatemeh, 2016, J Med Signals Sens, V6, P183
   Kennion O, 2022, HLTH SCI REV, V4, DOI DOI 10.1016/J.HSR.2022.100041
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P77, DOI 10.1016/j.patrec.2019.11.014
   Khan MBS, 2022, MATH BIOSCI ENG, V19, P7978, DOI 10.3934/mbe.2022373
   Kim J, 2023, AM J PATHOL, V193, P332, DOI 10.1016/j.ajpath.2022.12.003
   Kumar R. Senthil, 2022, 2022 International Conference on Electronics and Renewable Systems (ICEARS), P1724, DOI 10.1109/ICEARS53579.2022.9751826
   Kumar S, 2017, PROCEDIA COMPUT SCI, V122, P510, DOI 10.1016/j.procs.2017.11.400
   Kumar Vinay, 2023, Comput Intell Neurosci, V2023, P9739264, DOI 10.1155/2023/9739264
   Li Z, 2021, IEEE J BIOMED HEALTH, V25, P429, DOI 10.1109/JBHI.2020.3039741
   Liu K, 2022, COMPUT BIOL MED, V147, DOI 10.1016/j.compbiomed.2022.105741
   Malarvizhi A. B., 2022, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/2318/1/012042
   Marrón-Esquivel JM, 2023, COMPUT BIOL MED, V159, DOI 10.1016/j.compbiomed.2023.106856
   Massari Hakim El, 2023, Procedia Computer Science, P2392, DOI 10.1016/j.procs.2023.01.214
   Masud M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030748
   Mokoatle M, 2023, BMC BIOINFORMATICS, V24, DOI 10.1186/s12859-023-05235-x
   Myronenko A, 2019, LECT NOTES COMPUT SC, V11384, P311, DOI 10.1007/978-3-030-11726-9_28
   Nair, 2019, 2019 IEEE INT C EL C, P1, DOI DOI 10.1109/ICECCT.2019.8869001
   Nanglia P, 2021, ICT EXPRESS, V7, P335, DOI 10.1016/j.icte.2020.06.007
   Naqi SM, 2019, MULTIMED TOOLS APPL, V78, P26287, DOI 10.1007/s11042-019-07819-3
   Narayanan DL, 2010, INT J DERMATOL, V49, P978, DOI 10.1111/j.1365-4632.2010.04474.x
   Naseer I, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22124426
   Nasir MU, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5918686
   Nassif AB, 2022, ARTIF INTELL MED, V127, DOI 10.1016/j.artmed.2022.102276
   Nazari E, 2021, GENE REP, V25, DOI 10.1016/j.genrep.2021.101419
   Nazari Elham, 2020, J Med Life, V13, P382, DOI 10.25122/jml-2019-0090
   Neema M., 2020, INT J APPL ENG RES, V15, P11
   Owobu CI, 2020, INT J TROP INSECT SC, VDisHealth42, P14, DOI [10.9734/ijtdh/2021/v42i730468, DOI 10.9734/IJTDH/2021/V42I730468]
   Ozdemir O, 2020, IEEE T MED IMAGING, V39, P1419, DOI 10.1109/TMI.2019.2947595
   Patel N, 2015, PROCEDIA COMPUT SCI, V58, P635, DOI 10.1016/j.procs.2015.08.082
   Pradhan KS, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.118956
   Prakash TS, 2023, BIOMED SIGNAL PROCES, V84, DOI 10.1016/j.bspc.2023.104948
   Premaladha J, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0460-2
   Qarmiche N., 2022, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2022.101070
   Rahman MM, 2021, IRBM, V42, P215, DOI 10.1016/j.irbm.2020.05.005
   Rai HM, 2021, ADV SOFT COMPUTING T, P215, DOI [10.1007/978-3-030-75657-4_10, DOI 10.1007/978-3-030-75657-4_10]
   Ramani VK, 2022, EURASIAN J MED ONCOL, V6, P50, DOI 10.14744/ejmo.2022.18855
   Ramkumar G, 2022, CONTRAST MEDIA MOL I, V2022, DOI 10.1155/2022/6862083
   Ramtekkar PK, 2023, MULTIMED TOOLS APPL, V82, P44623, DOI 10.1007/s11042-023-15239-7
   Roy PS, 2016, INDIAN J CANCER, V53, P441, DOI 10.4103/0019-509X.200658
   Ruan JR, 2022, ACAD RADIOL, V29, P1541, DOI 10.1016/j.acra.2021.12.001
   Rupapara V, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-04835-6
   Saba T, 2020, J INFECT PUBLIC HEAL, V13, P1274, DOI 10.1016/j.jiph.2020.06.033
   Sadad T, 2018, J COMPUT SCI-NETH, V29, P34, DOI 10.1016/j.jocs.2018.09.015
   Saeedi S, 2023, BMC MED INFORM DECIS, V23, DOI 10.1186/s12911-023-02114-6
   Sampathila N, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10101812
   Sannasi Chakravarthy S. R., 2023, AIP Conference Proceedings, DOI 10.1063/5.0125243
   Sarkar A, 2023, J SENSORS, V2023, DOI 10.1155/2023/1224619
   Sarkar A, 2023, COMPUT BIOL CHEM, V104, DOI 10.1016/j.compbiolchem.2023.107859
   Selvanayaki K, 2010, REV, V2, P5890
   Selvaraj D., 2013, International Journal of Computer Science & Engineering Technology, V4, P1313
   Senan EM., 2021, Glob. Transit. Proc, V2, P1, DOI [10.1016/j.gltp.2021.01.001, DOI 10.1016/J.GLTP.2021.01.001]
   Sert E, 2019, MED HYPOTHESES, V133, DOI 10.1016/j.mehy.2019.109413
   Setio AAA, 2017, MED IMAGE ANAL, V42, P1, DOI 10.1016/j.media.2017.06.015
   Shafi ASM, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-3051-2
   Sharma R, 2019, NOVEL APPROACH CLASS, V46, DOI [10.1007/978-981-13-1217-5_68, DOI 10.1007/978-981-13-1217-5_68]
   Sharma S, 2020, J DIGIT IMAGING, V33, P632, DOI 10.1007/s10278-019-00307-y
   Sheeba A, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104048
   Shehzad K, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12061342
   Shen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48995-4
   Shetty Bhuvaneshwari, 2022, 2022 International Conference on Artificial Intelligence and Data Engineering (AIDE), P86, DOI 10.1109/AIDE57180.2022.10060254
   Shim SO, 2022, BIG DATA RES, V29, DOI 10.1016/j.bdr.2022.100331
   Shimanto Shahriar Alam, 2023, 2023 International Conference on Electrical, Computer and Communication Engineering (ECCE), P1, DOI 10.1109/ECCE57851.2023.10101618
   Singh D, 2020, BIOCYBERN BIOMED ENG, V40, P337, DOI 10.1016/j.bbe.2019.12.004
   Singh D, 2020, COMPUT METH PROG BIO, V183, DOI 10.1016/j.cmpb.2019.105074
   Steck SE, 2020, NAT REV CANCER, V20, P125, DOI 10.1038/s41568-019-0227-4
   Su Y, 2022, COMPUT BIOL MED, V145, DOI 10.1016/j.compbiomed.2022.105409
   Tharwat M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22239250
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Tsuneki M, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12030768
   Tufail Ahsan Bin, 2021, Comput Math Methods Med, V2021, P9025470, DOI 10.1155/2021/9025470
   Tumpa P, 2021, Sens Int, V2, DOI [10.1016/j.sintl.2021.100128, DOI 10.1016/J.SINTL.2021.100128]
   Vankdothu R., 2022, Measurement: Sensors Journal, V24, P100440, DOI DOI 10.1016/J.MEASEN.2022.100440
   Vatekar K, 2023, INT J ADV RES SCI CO, P570, DOI [10.48175/ijarsct-8541, DOI 10.48175/IJARSCT-8541]
   Virupakshappa, 2020, MULTIMED TOOLS APPL, V79, P3571, DOI 10.1007/s11042-018-6176-1
   Wang Chun, 2022, Chinese Medical Sciences Journal, V37, DOI 10.24920/004086
   Wong MCS, 2021, CLIN GASTROENTEROL H, V19, P955, DOI 10.1016/j.cgh.2020.02.026
   Yadav Rahul Kumar, 2023, Procedia Computer Science, P1434, DOI 10.1016/j.procs.2023.01.122
   Yamashita R, 2021, LANCET ONCOL, V22, P132, DOI 10.1016/S1470-2045(20)30535-0
   Yan F, 2023, EXPERT SYST APPL, V227, DOI 10.1016/j.eswa.2023.120282
   Ye LY, 2022, COMPUT METH PROG BIO, V221, DOI 10.1016/j.cmpb.2022.106770
   Yoo S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-55972-4
   Yu JZ, 2023, PROC SPIE, V12601, DOI 10.1117/12.2667179
   Zafar M, 2023, LIFE-BASEL, V13, DOI 10.3390/life13010146
   Zeng W, 2023, OPT LASER TECHNOL, V158, DOI 10.1016/j.optlastec.2022.108810
   Zhang CH, 2020, MED PHYS, V47, P3732, DOI 10.1002/mp.14144
   Zhang ZJ, 2021, NEUROCOMPUTING, V437, P339, DOI 10.1016/j.neucom.2021.01.083
   Zhao DD, 2019, MED BIOL ENG COMPUT, V57, P901, DOI 10.1007/s11517-018-1930-0
NR 137
TC 3
Z9 3
U1 12
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27001
EP 27035
DI 10.1007/s11042-023-16520-5
EA AUG 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001052828600002
DA 2024-07-18
ER

PT J
AU Musala, S
   Gajula, RM
   Reddy, SVRS
   Reddy, PP
AF Musala, Sarada
   Gajula, Ramana Murthy
   Reddy, S. V. Raghu Sekhar
   Reddy, P. Prakash
TI High-speed low power energy efficient 1-trit multiplier with less number
   of CNTFETs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE CNTFETS; Ternary multiplexer; Hybrid design; Ternary decoder
ID LOGIC GATES; DESIGNS; ADDER
AB Ternary logic has an advantage over conventional binary logic since it uses less power and promises to take up less space on chips and in interconnects. When ternary logic is used to design multiplier circuits, they exhibit good efficiency. A device known as a carbon nanotube field-effect transistor (CNTFET) offers more benefits than a MOSFET, including low off-current characteristics like low power and good performance. In this paper, a new 1-trit multiplier design is suggested along with a comparison of four 1-trit multiplier ideas based on CNTFETs. Power, latency, PDP, and the number of transistors is compared. Power, speed, and PDP are all improved by the suggested 1-trit multiplier. There are fewer transistors required. The Cadence Virtuoso Tool simulates each of these circuits using CNTFET 32 nm technology.
C1 [Musala, Sarada; Reddy, S. V. Raghu Sekhar; Reddy, P. Prakash] Vignans Fdn Sci Technol & Res, Dept ECE, Vadlamudi, India.
   [Gajula, Ramana Murthy] Alliance Univ, Dept ECE, ACED, Bangalore, Karnataka, India.
C3 Vignan's Foundation for Science, Technology & Research (VFSTR); Alliance
   University
RP Gajula, RM (corresponding author), Alliance Univ, Dept ECE, ACED, Bangalore, Karnataka, India.
EM ramana.murthy@alliance.edu.in
CR Aljaam JM, 2021, IEEE ACCESS, V9, P56726, DOI 10.1109/ACCESS.2021.3072567
   Bachtold A, 2001, SCIENCE, V294, P1317, DOI 10.1126/science.1065824
   Das D, 2018, POLITICS OF SWIDDEN FARMING: ENVIRONMENT AND DEVELOPMENT IN EASTERN INDIA, P1
   Doaa K., 2020, INTERNATION C MICROE, V19, P159
   Geunho Cho, 2009, 2009 IEEE Instrumentation and Measurement Technology Conference (I2MTC), P909, DOI 10.1109/IMTC.2009.5168580
   Jaber RA, 2019, IEEE ACCESS, V7, P93871, DOI 10.1109/ACCESS.2019.2928251
   Liang JH, 2012, IEEE INT SYMP NANO, P131
   Lin S, 2011, IEEE T NANOTECHNOL, V10, P217, DOI 10.1109/TNANO.2009.2036845
   Lin S, 2009, MIDWEST SYMP CIRCUIT, P435, DOI 10.1109/MWSCAS.2009.5236063
   McEuen PL, 2002, IEEE T NANOTECHNOL, V1, P78, DOI 10.1109/TNANO.2002.1005429
   Nepal Kundan, 2010, 2010 8th IEEE International NEWCAS Conference (NEWCAS 2010), P53, DOI 10.1109/NEWCAS.2010.5603726
   Pan JS, 2019, IEEE T VLSI SYST, V27, P1614, DOI 10.1109/TVLSI.2019.2903289
   Pan JS, 2013, IEEE T CIRCUITS-I, V60, P3195, DOI 10.1109/TCSI.2013.2264694
   Raychowdhury A, 2005, IEEE T NANOTECHNOL, V4, P168, DOI 10.1109/TNANO.2004.842068
   Tabrizchi S, 2017, FRONT INFORM TECH EL, V18, P423, DOI 10.1631/FITEE.1500366
   Vani H., 2015, INT J COMPUT APPL, V975, P8887
   Vudadha C, 2012, MULTIPLEXER BASED DE, P139
   Vudadha C, 2013, 2013 IEEE ASIA PACIFIC CONFERENCE ON POSTGRADUATE RESEARCH IN MICROELECTRONICS & ELECTRONICS (PRIMEASIA), P46, DOI 10.1109/PrimeAsia.2013.6731176
NR 18
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 14
PY 2023
DI 10.1007/s11042-023-16403-9
EA AUG 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P2HF6
UT WOS:001048894900012
DA 2024-07-18
ER

PT J
AU Tanwar, L
   Panda, J
AF Tanwar, Lavi
   Panda, Jeebananda
TI Hybrid reversible watermarking algorithm using histogram shifting and
   pairwise prediction error expansion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Prediction error expansion; Histogram shifting; Steganography;
   Reversible watermarking; Hybrid predictor
ID SCHEME
AB The exact retrieval of both i.e., watermark and host data using reversible watermarking makes it more suitable for applications like medical, military etc. The techniques which are considered most efficient and are being most widely used to implement it (reversible watermarking) are Prediction Error Expansion and Histogram Shifting as they offer higher embedding capacity with lesser distortion. The methodology proposed in this work is a hybrid one that utilizes the best of both. The algorithm starts with splitting the image into two regions and further processing is done on them one by one thereby covering each pixel for embedding thus amounting to enhanced capacity. The proposed work exploits the histogram of prediction errors instead of difference of adjacent pixels as it is more sharply distributed. This leads to lesser distortion in watermarked image. In this paper, the sorting of prediction errors is done in accordance with the calculated variance values of their prediction context followed by pairwise payload embedding. The results have substantiated the fact that for the smaller variance, prediction errors are also small. The proposed methodology is tested against the standard test images and real life applications such as medical, biomedical, aerial, military and colour images of Kodak image dataset. The experimental results demonstrate the superiority of the proposed work over the existing ones in terms of embedding capacity and distortion.
C1 [Tanwar, Lavi; Panda, Jeebananda] Delhi Technol Univ, Dept Elect & Commun Engn, Delhi, India.
C3 Delhi Technological University
RP Tanwar, L (corresponding author), Delhi Technol Univ, Dept Elect & Commun Engn, Delhi, India.
EM lavi.tanwar@dtu.ac.in; jpanda@dce.ac.in
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Agilandeeswari L, 2018, MULTIMED TOOLS APPL, V77, P25431, DOI 10.1007/s11042-018-5800-4
   Agilandeeswari L, 2016, J ENG SCI TECHNOL, V11, P327
   Agilandeeswari L, 2016, MULTIMED TOOLS APPL, V75, P8745, DOI 10.1007/s11042-015-2789-9
   Ahmaderaghi B, 2018, IEEE T COMPUT IMAG, V4, P46, DOI 10.1109/TCI.2018.2794065
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CS, 2017, IEEE T IMAGE PROCESS, V26, P3921, DOI 10.1109/TIP.2017.2706502
   Dragoi IC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549458
   Fallahpour M, 2008, IEICE ELECTRON EXPR, V5, P870, DOI 10.1587/elex.5.870
   Feng B, 2019, IEEE ACCESS, V7, P28031, DOI 10.1109/ACCESS.2018.2875923
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Honsinger C W, 2001, U.S. Patent, Patent No. [6,278,791, 6278791]
   Hu J, 2015, COMPUT ELECTR ENG, V46, P447, DOI 10.1016/j.compeleceng.2015.04.014
   Ishtiaq M, 2018, IEEE ACCESS, V6, P13213, DOI 10.1109/ACCESS.2018.2803301
   Jung KH, 2018, MULTIMED TOOLS APPL, V77, P7795, DOI 10.1007/s11042-017-5066-2
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Kouhi A, 2022, INFORM SCIENCES, V589, P46, DOI 10.1016/j.ins.2021.12.092
   Lee CF, 2012, DIGIT SIGNAL PROCESS, V22, P941, DOI 10.1016/j.dsp.2012.05.015
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li YC, 2010, DIGIT SIGNAL PROCESS, V20, P1116, DOI 10.1016/j.dsp.2009.10.025
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Mandal PC, 2022, INFORM SCIENCES, V609, P1451, DOI 10.1016/j.ins.2022.07.120
   Memon NA, 2011, INT J COMPUT MATH, V88, P1573, DOI 10.1080/00207160.2010.509429
   Menendez-Ortiz A, 2019, IEEE ACCESS, V7, P132662, DOI 10.1109/ACCESS.2019.2940972
   Naskar R, 2012, IET IMAGE PROCESS, V6, P507, DOI 10.1049/iet-ipr.2011.0244
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2016, J VIS COMMUN IMAGE R, V39, P12, DOI 10.1016/j.jvcir.2016.05.005
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Poonam, 2018, Procedia Computer Science, V132, P1441, DOI 10.1016/j.procs.2018.05.076
   Rad RM, 2016, SIGNAL PROCESS, V125, P315, DOI 10.1016/j.sigpro.2016.02.001
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Samee R, 2018, MULTIMED TOOLS APPL, V77, P26821, DOI 10.1007/s11042-018-5890-z
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wahed MA, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212093
   Xiong XG, 2019, IEEE ACCESS, V7, P136592, DOI 10.1109/ACCESS.2019.2942449
   Yang CH, 2010, IET IMAGE PROCESS, V4, P223, DOI 10.1049/iet-ipr.2009.0316
   Yanga C N, 2017, IMPROVING STEGO IMAG, V50
   Zhang C, 2022, IEEE T CIRC SYST VID, V32, P4174, DOI 10.1109/TCSVT.2021.3125711
   Zhou JT, 2012, IEEE SIGNAL PROC LET, V19, P287, DOI 10.1109/LSP.2012.2190508
NR 41
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 12
PY 2023
DI 10.1007/s11042-023-15508-5
EA AUG 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O9LJ2
UT WOS:001046958100003
DA 2024-07-18
ER

PT J
AU Bansal, K
   Singhrova, A
AF Bansal, Komal
   Singhrova, Anita
TI Review on intrusion detection system for IoT/IIoT -brief study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Internet of Things (IoT); Industrial Internet of Things (IIoT);
   Intrusion Detection System (IDS); Signature-based (IDS); Anomaly-based
   (IDS); Security; Machine learning; Deep learning
ID INDUSTRIAL IOT NETWORKS; ATTACK DETECTION SCHEME; DETECTION FRAMEWORK;
   ANOMALY DETECTION; INTERNET; MODEL
AB Recently, the Internet of Thing's (IoT's) rising popularity is offering a promising opportunity not just aimed at the diverse home automation systems' expansion however as well aimed at diverse industrial applications. By leveraging these advantages, automation is implemented in the industries resulting in the Industrial IoT (IIoT). Even though IoT/IIoT simplifies the daily activities that benefit human operations, they cause severe security challenges that are worth focusing on. Consequently, IoT/IIoT yields effective and efficient solutions by implementing an Intrusion Detection System (IDS). The IDS is a solution aimed at addressing the security and privacy challenges of detecting diverse IoT/IIoT attacks. Diverse IDS methodologies are employed aimed at identifying intrusion within the data however still require enhancement on the detection system. A literature survey regarding the IDS in the IoT/IIoT topic is offered that largely concentrated on the research's present state by evaluating the literature, discovering the existent trends, and offering open problems and upcoming directions.
C1 [Bansal, Komal; Singhrova, Anita] Deenbandhu Chhotu Ram Univ Sci & Technol, CSE Dept, Murthal, Haryana, India.
C3 Deenbandhu Chhotu Ram University of Science & Technology
RP Bansal, K (corresponding author), Deenbandhu Chhotu Ram Univ Sci & Technol, CSE Dept, Murthal, Haryana, India.
EM komal.bansal22@gmail.com; nidhianita@gmail.com
CR Aboelwafa MMN, 2020, IEEE INTERNET THINGS, V7, P8462, DOI 10.1109/JIOT.2020.2991693
   Abu Al-Haija Q, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11040556
   Al-Abassi A, 2020, IEEE ACCESS, V8, P83965, DOI 10.1109/ACCESS.2020.2992249
   Al-Garadi MA, 2020, IEEE COMMUN SURV TUT, V22, P1646, DOI 10.1109/COMST.2020.2988293
   Al-Hamadi H, 2020, IEEE ACCESS, V8, P168994, DOI 10.1109/ACCESS.2020.3023616
   Alghanmi N, 2019, IEEE ACCESS, V7, P179492, DOI 10.1109/ACCESS.2019.2959739
   Alghuried A, 2017, THESIS DUBLIN I TECH
   Alghuried A, 2017, THESIS TECHNOLOGICAL, DOI [10.21427/D7WK7S, DOI 10.21427/D7WK7S]
   Alhakami W, 2019, IEEE ACCESS, V7, P52181, DOI 10.1109/ACCESS.2019.2912115
   Aljawarneh SA, 2020, J SUPERCOMPUT, V76, P4376, DOI 10.1007/s11227-018-2397-3
   Alkadi O, 2021, IEEE INTERNET THINGS, V8, P9463, DOI 10.1109/JIOT.2020.2996590
   Almiani M, 2020, SIMUL MODEL PRACT TH, V101, DOI 10.1016/j.simpat.2019.102031
   Altunay HC, 2023, ENG SCI TECHNOL, V38, DOI 10.1016/j.jestch.2022.101322
   Arshad J, 2020, MECH SYST SIGNAL PR, V136, DOI 10.1016/j.ymssp.2019.106436
   Arshad J, 2019, IET NETW, V8, P3, DOI 10.1049/iet-net.2018.5036
   Babu MJ, 2020, WIRELESS PERS COMMUN, V112, P2023, DOI 10.1007/s11277-020-07137-0
   Bagaa M, 2020, IEEE ACCESS, V8, P114066, DOI 10.1109/ACCESS.2020.2996214
   Balakrishnan N, 2021, INTERNET THINGS-NETH, V14, DOI 10.1016/j.iot.2019.100112
   Dawoud A, 2018, INTERNET THINGS-NETH, V3-4, P82, DOI 10.1016/j.iot.2018.09.003
   de Souza CA, 2020, COMPUT NETW, V180, DOI 10.1016/j.comnet.2020.107417
   Diro AA, 2018, FUTURE GENER COMP SY, V82, P761, DOI 10.1016/j.future.2017.08.043
   Dua D, 2019, UCI MACHINE LEARNING
   Gassais R, 2020, J CLOUD COMPUT-ADV S, V9, DOI 10.1186/s13677-020-00206-6
   George G, 2018, IEEE ACCESS, V6, P43586, DOI 10.1109/ACCESS.2018.2863244
   Guo YF, 2020, IEEE T NETW SCI ENG, V7, P2231, DOI 10.1109/TNSE.2020.3027543
   Hasan M, 2019, INTERNET THINGS-NETH, V7, DOI 10.1016/j.iot.2019.100059
   Hassan MM, 2021, IEEE INTERNET THINGS, V8, P9611, DOI 10.1109/JIOT.2020.3019225
   Hassan MM, 2020, IEEE T IND INFORM, V16, P6154, DOI 10.1109/TII.2020.2970074
   Hwang RH, 2020, IEEE ACCESS, V8, P30387, DOI 10.1109/ACCESS.2020.2973023
   Jan SU, 2019, IEEE ACCESS, V7, P42450, DOI 10.1109/ACCESS.2019.2907965
   Khan B, 2020, IEEE ACCESS, DOI [10.1109/ACCESS.2017, DOI 10.1109/ACCESS.2017]
   Latif S, 2020, IEEE ACCESS, V8, P89337, DOI 10.1109/ACCESS.2020.2994079
   Li BB, 2021, IEEE T IND INFORM, V17, P5615, DOI 10.1109/TII.2020.3023430
   Li DM, 2019, INT J INFORM MANAGE, V49, P533, DOI 10.1016/j.ijinfomgt.2019.04.006
   Li WJ, 2020, J NETW COMPUT APPL, V161, DOI 10.1016/j.jnca.2020.102631
   Liang W, 2020, IEEE T IND INFORM, V16, P2063, DOI 10.1109/TII.2019.2946791
   Liu Y, 2021, IEEE INTERNET THINGS, V8, P6348, DOI 10.1109/JIOT.2020.3011726
   Mandal K., 2020, Materials Today: Proceedings, DOI [10.1016/j.matpr.2020.10.187, DOI 10.1016/J.MATPR.2020.10.187]
   Manimurugan S, 2020, IEEE ACCESS, V8, P77396, DOI 10.1109/ACCESS.2020.2986013
   Mansour RF, 2022, EXPERT SYST APPL, V207, DOI 10.1016/j.eswa.2022.117995
   McCulloch JR., 2019, J NETW COMPUT APPL, V128, P54, DOI [10.1016/j.jnca.2018.11.008, DOI 10.1016/J.JNCA.2018.11.008]
   Mendonça RV, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12917
   Mirsky Y, 2020, J PARALLEL DISTR COM, V145, P75, DOI 10.1016/j.jpdc.2020.06.008
   Moustafa N, 2019, IEEE INTERNET THINGS, V6, P4815, DOI 10.1109/JIOT.2018.2871719
   N-BaIoT Dataset to Detect IoT Botnet Attacks, N BAIOT DAT DET IOT
   Natarajan Y, 2022, IET COMMUN, V16, P464, DOI 10.1049/cmu2.12266
   Othman SM, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0145-4
   Otoum Safa, 2019, IEEE Networking Letters, V1, P68, DOI 10.1109/LNET.2019.2901792
   Pajouh NH, 2019, IEEE T EMERG TOP COM, V7, P314, DOI 10.1109/TETC.2016.2633228
   Parra GD, 2020, J NETW COMPUT APPL, V163, DOI 10.1016/j.jnca.2020.102662
   Prabavathy S, 2018, J COMMUN NETW-S KOR, V20, P291, DOI 10.1109/JCN.2018.000041
   Qureshi KN, 2020, SUSTAIN CITIES SOC, V61, DOI 10.1016/j.scs.2020.102343
   Rahman MA, 2020, SUSTAIN CITIES SOC, V61, DOI 10.1016/j.scs.2020.102324
   Rathore S, 2019, J NETW COMPUT APPL, V143, P167, DOI 10.1016/j.jnca.2019.06.019
   Ravi N, 2020, IEEE INTERNET THINGS, V7, P11041, DOI 10.1109/JIOT.2020.2993410
   Sadikin F, 2020, INTERNET THINGS-NETH, V12, DOI 10.1016/j.iot.2020.100306
   Samy A, 2020, IEEE ACCESS, V8, P74571, DOI 10.1109/ACCESS.2020.2988854
   Shafi Q, 2018, IEEE ACCESS, V6, P73713, DOI 10.1109/ACCESS.2018.2884293
   Sharafaldin I, 2018, ICISSP: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS SECURITY AND PRIVACY, P108, DOI 10.5220/0006639801080116
   Siddiqui AJ, 2021, CLUSTER COMPUT, V24, P17, DOI 10.1007/s10586-020-03153-8
   Singh K, 2020, J INFORM OPTIM SCI, V41, P1715, DOI 10.1080/02522667.2020.1799515
   Suthaharan Shan, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP 2010), P269, DOI 10.1109/ISSNIP.2010.5706782
   Tavallaee M., 2009, P 2009 IEEE S COMPUT, P1, DOI DOI 10.1109/CISDA.2009.5356528
   Waskle Subhash, 2020, 2020 International Conference on Electronics and Sustainable Communication Systems (ICESC). Proceedings, P803, DOI 10.1109/ICESC48915.2020.9155656
   Wu D, 2020, IEEE T IND INFORM, V16, P5244, DOI 10.1109/TII.2019.2952917
   Yang AM, 2019, IEEE ACCESS, V7, P106043, DOI 10.1109/ACCESS.2019.2929919
   Yao HP, 2019, IEEE NETWORK, V33, P75, DOI 10.1109/MNET.001.1800479
   Zarpelao BB, 2017, J NETW COMPUT APPL, V84, P25, DOI 10.1016/j.jnca.2017.02.009
   Zhang Y, 2019, IEEE ACCESS, V7, P31711, DOI 10.1109/ACCESS.2019.2903723
   Zhao SC, 2017, 2017 IEEE 15TH INTL CONF ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, 15TH INTL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING, 3RD INTL CONF ON BIG DATA INTELLIGENCE AND COMPUTING AND CYBER SCIENCE AND TECHNOLOGY CONGRESS(DASC/PICOM/DATACOM/CYBERSCI, P836, DOI 10.1109/DASC-PICom-DataCom-CyberSciTec.2017.141
NR 70
TC 0
Z9 0
U1 8
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 11
PY 2023
DI 10.1007/s11042-023-16395-6
EA AUG 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O6QY1
UT WOS:001045042100001
DA 2024-07-18
ER

PT J
AU Ding, N
   Takeda, K
   Jin, WH
   Bei, YJ
   Fujii, K
AF Ding, Ning
   Takeda, Kazuya
   Jin, Wenhui
   Bei, Yingjiu
   Fujii, Keisuke
TI Estimation of control area in badminton doubles with pose information
   from top and back view drone videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Visual tracking; Deep learning; Drone dataset; Racket sports
ID VISUALIZATION
AB The application of visual tracking to the performance analysis of sports players in dynamic competitions is vital for effective coaching. In doubles matches, coordinated positioning is crucial for maintaining control of the court and minimizing opponents' scoring opportunities. The analysis of such teamwork plays a vital role in understanding the dynamics of the game. However, previous studies have primarily focused on analyzing and assessing singles players without considering occlusion in broadcast videos. These studies have relied on discrete representations, which involve the analysis and representation of specific actions (e.g., strokes) or events that occur during the game while overlooking the meaningful spatial distribution. In thiswork, we present the first annotated drone dataset from top and back views in badminton doubles and propose a framework to estimate the control area probability map, which can be used to evaluate teamwork performance. We present an efficient framework of deep neural networks that enables the calculation of full probability surfaces. This framework utilizes the embedding of a Gaussian mixture map of players' positions and employs graph convolution on their poses. In the experiment, we verify our approach by comparing various baselines and discovering the correlations between the score and control area. Additionally, we propose a practical application for assessing optimal positioning to provide instructions during a game. Our approach offers both visual and quantitative evaluations of players' movements, thereby providing valuable insights into doubles teamwork. The dataset and related project code is available at https:// github.com/Ning- D/ Drone_BD_ControlArea
C1 [Ding, Ning; Takeda, Kazuya; Fujii, Keisuke] Nagoya Univ, Grad Sch Informat, Chikusa Ku, Nagoya, Aichi, Japan.
   [Jin, Wenhui] Wuhu Inst Technol, Dept Phys Educ, Wenjinxi Rd, Wuhu, Anhui, Peoples R China.
   [Bei, Yingjiu] Anhui Normal Univ, Sch Sports Sci, East Jiuhua Rd, Wuhu, Anhui, Peoples R China.
   [Fujii, Keisuke] RIKEN Ctr Adv Intelligence Project, 1-5,Yamadaoka, Suita, Osaka, Japan.
   [Fujii, Keisuke] Japan Sci & Technol Agcy, PRESTO, Kawaguchi, Saitama, Japan.
C3 Nagoya University; Wuhu Institute of Technology; Anhui Normal
   University; RIKEN; Japan Science & Technology Agency (JST)
RP Ding, N (corresponding author), Nagoya Univ, Grad Sch Informat, Chikusa Ku, Nagoya, Aichi, Japan.
EM ding.ning@g.sp.m.is.nagoya-u.ac.jp; kazuya.takeda@nagoya-u.jp;
   jinwenhui@whit.edu.cn; beibei@mail.ahnu.edu.cn; fujii@i.nagoya-u.ac.jp
OI Ding, Ning/0000-0002-3067-7341
FU JST SPRING [JPMJSP2125]; JSPS [20H04075]; JST PRESTO [JPMJPR20CA];
   Scientific Research Project of Higher Education Institutions of Anhui
   Province of China [2022AH052181]
FX This work was financially supported by JST SPRING, Grant Number
   JPMJSP2125, JSPS Grant Number 20H04075, JST PRESTO Grant Number
   JPMJPR20CA, and Scientific Research Project of Higher Education
   Institutions of Anhui Province of China Grant Number 2022AH052181. The
   author (ND) would like to take this opportunity to thank the
   "Interdisciplinary Frontier Next-Generation Researcher Program of the
   Tokai Higher Education and Research System." The authors would also like
   to thank Yundong Yu for his valuable comments on this work.
CR Archana M, 2016, ADV INTELL SYST, V384, P427, DOI 10.1007/978-3-319-23036-8_37
   Blank P, 2015, ISWC 2015: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P93, DOI 10.1145/2802083.2802087
   Boutteau R, 2020, J INTELL ROBOT SYST, V99, P359, DOI 10.1007/s10846-019-01114-x
   Cho H, 2022, INT J SPORTS SCI COA, V17, P355, DOI 10.1177/17479541211033078
   Chu XT, 2022, IEEE T VIS COMPUT GR, V28, P118, DOI 10.1109/TVCG.2021.3114861
   Contributors M., 2020, Openmmlab pose estimation toolbox and benchmark
   Dasgupta K, 2022, IEEE T INTELL TRANSP, V23, P15940, DOI 10.1109/TITS.2022.3146575
   Deliege A, 2021, IEEE COMPUT SOC CONF, P4503, DOI 10.1109/CVPRW53098.2021.00508
   Ding N, 2022, IEEE ACCESS, V10, P54764, DOI 10.1109/ACCESS.2022.3175314
   Du M, 2021, J VISUAL-JAPAN, V24, P47, DOI 10.1007/s12650-020-00687-2
   Fernandez J., 2018, SLOAN SPORTS ANALYTI, VVolume 2018
   Fernández J, 2021, LECT NOTES ARTIF INT, V12461, P491, DOI 10.1007/978-3-030-67670-4_30
   Ghosh A, 2018, IEEE WINT CONF APPL, P296, DOI 10.1109/WACV.2018.00039
   Giancola S, 2021, IEEE COMPUT SOC CONF, P4485, DOI 10.1109/CVPRW53098.2021.00506
   Goldsberry Kirk., 2012, 2012 MIT Sloan Sports Analytics Conference, V9, P12
   Haq Muhammad Abdul, 2022, 2022 International Electronics Symposium (IES), P627, DOI 10.1109/IES55876.2022.9888717
   Hsu T.-H., 2019 20 AS PAC NETW, P1
   Huang Y.-C., 2019, 2019 16 IEEE INT C A, P1
   JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588
   Kim W, 2020, IEEE T IMAGE PROCESS, V29, P8055, DOI 10.1109/TIP.2020.3011269
   Kulkarni KM, 2021, IEEE COMPUT SOC CONF, P4571, DOI 10.1109/CVPRW53098.2021.00515
   Legg PA, 2012, COMPUT GRAPH FORUM, V31, P1255, DOI 10.1111/j.1467-8659.2012.03118.x
   Mueller F, 2018, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2018.00013
   Perin C, 2018, COMPUT GRAPH FORUM, V37, P663, DOI 10.1111/cgf.13447
   Perin C, 2013, IEEE T VIS COMPUT GR, V19, P2506, DOI 10.1109/TVCG.2013.192
   Pileggi H, 2012, IEEE T VIS COMPUT GR, V18, P2819, DOI 10.1109/TVCG.2012.263
   Polk T, 2020, IEEE T VIS COMPUT GR, V26, P397, DOI 10.1109/TVCG.2019.2934243
   Polk T, 2014, IEEE T VIS COMPUT GR, V20, P2339, DOI 10.1109/TVCG.2014.2346445
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Scott A, 2022, IEEE COMPUT SOC CONF, P3568, DOI 10.1109/CVPRW56347.2022.00401
   Spearman W., 2017, P MIT SLOAN SPORTS A
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Voeikov R, 2020, IEEE COMPUT SOC CONF, P3857, DOI 10.1109/CVPRW50498.2020.00450
   Wang JC, 2021, IEEE T VIS COMPUT GR, V27, P2770, DOI 10.1109/TVCG.2021.3074576
   Wang JC, 2020, IEEE T VIS COMPUT GR, V26, P407, DOI 10.1109/TVCG.2019.2934630
   Wawrzyniak N, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235230
   Wu Y, 2018, IEEE T VIS COMPUT GR, V24, P709, DOI 10.1109/TVCG.2017.2744218
   Yeh RA, 2019, PROC CVPR IEEE, P4605, DOI 10.1109/CVPR.2019.00474
   Zhang YF, 2022, LECT NOTES COMPUT SC, V13682, P1, DOI 10.1007/978-3-031-20047-2_1
NR 39
TC 0
Z9 0
U1 6
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 11
PY 2023
DI 10.1007/s11042-023-16362-1
EA AUG 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O9TM0
UT WOS:001047169200002
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Cha, EY
   Piran, MJ
   Suh, DY
AF Cha, Eun Young
   Piran, Md. Jalil
   Suh, Doug Young
TI A Gaze-based Real-time and Low Complexity No-reference Video Quality
   Assessment Technique for Video Gaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video gaming; Video quality assessment; Complexity; Real-time streaming;
   Gaze; Mean Opinion Score (MOS); Peak Signal-to-Noise Ratio (PSNR)
AB Various types of online video gaming services have emerged as video game popularity have increased. Network fluctuations, however, greatly affect the quality of service (QoS) in such gaming services. In addition, video gaming requires a faster response time than general video services. A real-time assessment of quality based on each genre's specific characteristics is another challenge. The objective of this paper is to provide an assessment method based on the user's gaze for the quality of experience (QoE) associated with no-reference video gaming. By exploiting the fact that delay requirements and gaze patterns (e.g., times) differ based on the game genre, the proposed model extracts video features and assesses video quality in real-time. By extracting image features through the human visual system (HVS) approach, we improve the performance of low-performing image features. The proposed model is then trained and verified on popular video gaming datasets (e.g., GamingVideoSET and KUGVD). Through extensive simulation results, we show that certain image features have a higher correlation with the actual mean opinion score (MOS) when HVS is applied. The correlation of some image features is reduced when using the entire frame, but it is not significant, and the calculation time is reduced. Additionally, we demonstrate that the predicted MOS shows a correlation of 0.9 or more with the actual MOS.
C1 [Cha, Eun Young; Suh, Doug Young] Kyung Hee Univ, Dept Elect & Informat Convergence Engn, Yongin 17035, South Korea.
   [Piran, Md. Jalil] Sejong Univ, Dept Comp Sci & Engn, Seoul 05006, South Korea.
C3 Kyung Hee University; Sejong University
RP Piran, MJ (corresponding author), Sejong Univ, Dept Comp Sci & Engn, Seoul 05006, South Korea.
EM piran@sejong.ac.kr
RI Jalil Piran, Md./I-2070-2018
OI Jalil Piran, Md./0000-0003-3229-6785
FU MSIT (Ministry of Science and ICT), Korea under Grand Information
   Technology Research Center support program [IITP-2021-2015-0-00742]
FX This research was supported by the MSIT (Ministry of Science and ICT),
   Korea, under the Grand Information Technology Research Center support
   program (IITP-2021-2015-0-00742) supervised by the IITP(Institute for
   Information & Communications Technology Planning & Evaluation).
CR Abu Layek M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030296
   Ahmadi H, 2021, IEEE ACCESS, V9, P12332, DOI 10.1109/ACCESS.2021.3050489
   Banitalebi-Dehkordi M, 2019, MULTIMED TOOLS APPL, V78, P11507, DOI 10.1007/s11042-018-6700-3
   BARMAN N, 2018, NETW SYST SUPP GAM N
   Barman N, 2019, IEEE ACCESS, V7, P74511, DOI 10.1109/ACCESS.2019.2920477
   Bezryadin S., 2007, INT S TECHN DIG PHOT, V1, P10, DOI DOI 10.2352/ISSN.2169-4672.2007.1.0.10
   Cisco, 2020, CISC ANN INT REP 201
   Claypool M, 2006, COMMUN ACM, V49, P40, DOI 10.1145/1167838.1167860
   Daly S, 2001, VISION MODELS AND APPLICATIONS TO IMAGE AND VIDEO PROCESSING, P179
   Greenfield DN, 2022, CHILD ADOL PSYCH CL, V31, P99, DOI 10.1016/j.chc.2021.09.003
   Hallur GG, 2023, DIGITAL ENTERTAINMEN, ppp35, DOI DOI 10.1007/978-981-19-8121-0_3
   Hu XW, 2021, IEEE T CIRC SYST VID, V31, P1079, DOI 10.1109/TCSVT.2020.2995220
   ITU-T RECOMMENDATION P, 1999, SUBJ VID QUAL ASS ME
   Jarschel M., 2011, Proceedings of the 2011 Fifth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing (IMIS), P330, DOI 10.1109/IMIS.2011.92
   Jin YZ, 2022, IEEE T IMAGE PROCESS, V31, P4571, DOI 10.1109/TIP.2022.3185738
   Kenny A, 2005, P 19 EUR C MOD SIM E
   Lee DY, 2022, IEEE T IMAGE PROCESS, V31, P3644, DOI 10.1109/TIP.2022.3173810
   Li Z., 2016, NETFLIX TECH BLOG, V6
   Liu HT, 2011, IEEE T CIRC SYST VID, V21, P971, DOI 10.1109/TCSVT.2011.2133770
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   PELI E, 1990, J OPT SOC AM A, V7, P2032, DOI 10.1364/JOSAA.7.002032
   Porcu S, 2020, IEEE T NETW SERV MAN, V17, P2702, DOI 10.1109/TNSM.2020.3018303
   Ramli TS, 2023, J TELECOMMUNICATIONS, V11, P44
   Sabet SS, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P75, DOI 10.1109/MIPR.2018.00021
   Sjöblom M, 2017, COMPUT HUM BEHAV, V75, P985, DOI 10.1016/j.chb.2016.10.019
   Slivar I, 2016, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON MULTIMEDIA SYSTEMS (MMSYS'16), P185, DOI 10.1145/2910017.2910602
   Sundstedt Veronica., 2013, GAME ANAL, P543
   Tsiami A, 2020, PROC CVPR IEEE, P4765, DOI 10.1109/CVPR42600.2020.00482
   Utke M, 2022, MULTIMED TOOLS APPL, V81, P3181, DOI 10.1007/s11042-020-09144-6
   Wahab A., 2021, J, V3, P404
   Wang WG, 2018, PROC CVPR IEEE, P4894, DOI 10.1109/CVPR.2018.00514
   Wang X, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P467, DOI 10.1109/CISP.2008.371
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HR, 1997, IEEE SIGNAL PROC LET, V4, P317, DOI 10.1109/97.641398
   Zadtootaghaj S, 2018, IEEE INT SYM MULTIM, P131, DOI 10.1109/ISM.2018.00031
   Zhang Y, 2020, IEEE T NEUR NET LEAR, V31, P2716, DOI 10.1109/TNNLS.2018.2890310
NR 36
TC 1
Z9 1
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20889
EP 20908
DI 10.1007/s11042-023-16184-1
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001043063500001
DA 2024-07-18
ER

PT J
AU Karmakar, P
   Murshed, M
   Paul, M
   Taubman, D
AF Karmakar, Priyabrata
   Murshed, Manzur
   Paul, Manoranjan
   Taubman, David
TI Efficient motion modelling with variable-sized blocks from hierarchical
   cuboidal partitioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video coding; Motion modelling; Cuboidal partitioning; Scalable HEVC
ID VIDEO; HEVC; EXTENSION
AB This paper explores the potential of cuboidal partitioning in motion modelling compared to the commonly used fixed-sized block-based architecture in scalable video coding. The traditional approach of dividing frames into fixed-sized blocks for independent motion compensation often results in coding inefficiency due to poor alignment with object boundaries. Hierarchical block partitioning has been introduced as a solution, but it suffers from an increased number of motion vectors, limiting its effectiveness. In contrast, cuboidal partitioning offers a promising alternative. It involves approximate segmentation of images into variable-sized rectangular segments (cuboids) that align well with object boundaries. The segmentation is based on a homogeneity constraint, minimizing the sum of squared errors (SSE). This property makes cuboidal partitioning compatible with block-based video coding techniques. In this paper, we investigate the potential of cuboids in motion modelling, specifically comparing them to fixed-sized blocks used in scalable video coding. Our approach involves constructing a motion-compensated current frame using the cuboidal partitioning information from the anchor frame within a group-of-pictures (GOP). The predicted current frame serves as the base layer, while the current frame is encoded as an enhancement layer using the scalable High Efficiency Video Coding (HEVC) encoder. Experimental results demonstrate significant bitrate savings ranging from 6.71% to 10.90% on 4 K video sequences. These savings highlight the superiority of our proposed model, which leverages cuboidal partitioning to improve coding efficiency and alignment with object boundaries. By adopting this approach, we mitigate the limitations of fixed-sized blocks and offer a more effective solution for motion modelling in scalable video coding.
C1 [Karmakar, Priyabrata; Murshed, Manzur] Federat Univ, Inst Innovat, Sci & Sustainabil, Ballarat, Australia.
   [Murshed, Manzur] Deakin Univ, Sch Informat Technol, Burwood, Australia.
   [Paul, Manoranjan] Charles Sturt Univ, Sch Comp & Math, Bathurst, Australia.
   [Taubman, David] Univ New South Wales, Sch Elect Engn & Telecommun, Sydney, Australia.
C3 Federation University Australia; Deakin University; Charles Sturt
   University; University of New South Wales Sydney
RP Karmakar, P (corresponding author), Federat Univ, Inst Innovat, Sci & Sustainabil, Ballarat, Australia.
EM p.karmakar@federation.edu.au; manzur.murshed@federation.edu.au;
   mpaul@csu.edu.au; d.taubman@unsw.edu.au
OI Taubman, David/0000-0002-8458-6402; Karmakar,
   Priyabrata/0000-0001-8015-1375; Paul, Manoranjan/0000-0001-6870-5056
FU Australian Research Council (ARC) [DP190102574]
FX AcknowledgementsThis work was supported by Australian Research Council
   (ARC) Discovery Project Grant DP190102574.
CR Ahmmed A., 2020, IEEE INT WORKSH MULT, P1, DOI DOI 10.1109/mmsp48831.2020.9287138
   Ahmmed A, 2022, IEEE T MULTIMEDIA, V24, P4446, DOI 10.1109/TMM.2021.3117397
   Badry E, 2020, IEEE ACCESS, V8, P143437, DOI 10.1109/ACCESS.2020.3014163
   Bjotegaard G., 2001, VCEGM33
   Bossen F., 2013, document JCTVC-L1100,, V12
   Boyce J., 2018, JVET-J1010: JVET common test conditions and software reference configurations
   Boyce JM, 2016, IEEE T CIRC SYST VID, V26, P20, DOI 10.1109/TCSVT.2015.2461951
   Cetinkaya E, 2021, SIGNAL PROCESS-IMAGE, V99, DOI 10.1016/j.image.2021.116442
   Chauhan Sumika, 2021, 2021 International Conference on Intelligent Technologies (CONIT), DOI [10.1109/ICEPES52894.2021.9699655, 10.1109/CONIT51480.2021.9498358]
   Correa G, 2015, IEEE T CIRC SYST VID, V25, P660, DOI 10.1109/TCSVT.2014.2363753
   DUFAUX F, 1995, P IEEE, V83, P858, DOI 10.1109/5.387089
   Helle P, 2013, IEEE DATA COMPR CONF, P201, DOI 10.1109/DCC.2013.28
   hevc, 2022, HEVC SCAL EXT SHVC
   Itu-T I., 1995, ITU T RECOMMENDATION, V262, P13818
   Jakubowski M, 2013, OPTO-ELECTRON REV, V21, P86, DOI 10.2478/s11772-013-0071-0
   Karczewicz M, 1997, SIGNAL PROCESS-IMAGE, V10, P63, DOI 10.1016/S0923-5965(97)00019-2
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Kwon H, 1997, IEEE J SEL AREA COMM, V15, P1714, DOI 10.1109/49.650045
   Ma S, 2007, VISUAL COMMUN-US, V6508, P417
   Murshed M., 2018, 2018 DIGITAL IMAGE C, P1
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Paul M, 2010, IEEE T IMAGE PROCESS, V19, P691, DOI 10.1109/TIP.2009.2033406
   Paul M, 2009, IEEE T MULTIMEDIA, V11, P581, DOI 10.1109/TMM.2009.2017610
   Podder PK, 2017, 2017 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING - TECHNIQUES AND APPLICATIONS (DICTA), P187
   Song L, 2013, INT WORK QUAL MULTIM, P34, DOI 10.1109/QoMEX.2013.6603201
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wang J., 2015, INT J HYBRID INF TEC, V8, P319, DOI [10.14257/ijhit.2015.8.7.29, DOI 10.14257/IJHIT.2015.8.7.29]
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yoo SB, 2014, IEEE T MULTIMEDIA, V16, P1536, DOI 10.1109/TMM.2014.2327563
NR 29
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20743
EP 20757
DI 10.1007/s11042-023-16249-1
EA AUG 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001042601200016
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chlubna, T
   Milet, T
   Zemcik, P
AF Chlubna, Tomas
   Milet, Tomas
   Zemcik, Pavel
TI How Capturing Camera Trajectory Distortion Affects User Experience on
   Looking Glass 3D Display
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Looking Glass; 3D Display; Holography; Stereoscopic Display
ID REDUCING VISUAL DISCOMFORT; AUGMENTED REALITY; PARAMETERS; DISTANCE
AB This paper proposes an evaluation method for an optimal scene capture for a 3D display. The method analyzes multi-view data to determine capture guidelines. An user study was conducted to verify the proposed method and to discover the distortion limits of the optimal capturing camera positions. The discovered limits are 0.3. in rotations and 4px in the translation of the area of interest. Different variants of distortions were compared and their significance in visual degradation was evaluated. Rotational distortions were the most tolerated by users, followed by translational and combined. The solid-color background and suppressed head motion increase the user's tolerance to the artifacts. The paper also proposes a 2D-reprojection-based correction method for unsuitably captured scenes. In some cases, this reprojection increased the measured limits by up to 60x compared to the uncorrected distortions and proved to be effective. This study supplements existing studies with a large set of previously unexplored measurements and provides results relevant to current state-of-the-art 3D displays. It reveals important information for possible future 3D display rendering or capture methods. The images captured and corrected according to the proposed method can be displayed directly on a 3D display by Looking Glass Factory, creating a 3D effect without additional VR or AR equipment.
C1 [Chlubna, Tomas; Milet, Tomas; Zemcik, Pavel] Brno Univ Technol, Fac Informat Technol, Dept Comp Graph & Multimedia, Bozetechova 2-1, Brno 61200, Czech Republic.
C3 Brno University of Technology
RP Chlubna, T (corresponding author), Brno Univ Technol, Fac Informat Technol, Dept Comp Graph & Multimedia, Bozetechova 2-1, Brno 61200, Czech Republic.
EM ichlubna@fit.vutbr.cz; imilet@fit.vutbr.cz; zemcik@fit.vutbr.cz
RI Chlubna, Tomáš/AAX-5104-2021; Chlubna, Tomáš/Y-7496-2018
OI Chlubna, Tomáš/0000-0003-3126-0545
FU KDT JU project AIDOaRt [101007350]
FX This work was supported by the KDT JU project AIDOaRt, grant agreement
   No 101007350.
CR Alhassan M., 2021, Int J Ophthalmol. Vis. Sci, V6, P10, DOI [10.11648/j.ijovs.20210601.12, DOI 10.11648/J.IJOVS.20210601.12]
   Balogh T, 2007, 3DTV CONF, P17
   Campos Carlos, 2021, IEEE Transactions on Robotics, V37, P1874, DOI 10.1109/TRO.2021.3075644
   Choudhary R., 2019, SSRN ELECT J, DOI [10.2139/ssrn.3356307, DOI 10.2139/SSRN.3356307]
   El Jamiy F, 2019, IET IMAGE PROCESS, V13, P707, DOI 10.1049/iet-ipr.2018.5920
   Frayne S., 2018, US Patent App, Patent No. [10/012,841, 10012841]
   Frayne S., 2019, US Patent, Patent No. [10,298,921, 10298921]
   Gao ZP, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0205032
   Guo H, 2018, IEEE T COMPUT IMAG, V4, P573, DOI 10.1109/TCI.2018.2866227
   Held RT, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P23
   Ijsselsteijn WA, 2000, P SOC PHOTO-OPT INS, V3957, P12, DOI 10.1117/12.384448
   IJsselsteijn WA, 2000, IEEE T CIRC SYST VID, V10, P225, DOI 10.1109/76.825722
   Jung YJ, 2013, IEEE T CIRC SYST VID, V23, P1408, DOI 10.1109/TCSVT.2013.2244796
   Karpicka E, 2013, OPHTHAL PHYSL OPT, V33, P604, DOI 10.1111/opo.12081
   Keane S.F., 2019, US Patent, Patent No. [10,401,636, 10401636]
   Kim D, 2011, IEEE T CIRC SYST VID, V21, P231, DOI 10.1109/TCSVT.2011.2106275
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Li Q., 2014, GEN STEREOSCOPIC DIS, V9011, DOI [10.1117/12.2038282, DOI 10.1117/12.2038282]
   Liu F, 2013, IEEE I CONF COMP VIS, P73, DOI 10.1109/ICCV.2013.16
   Liu Y, 2021, J SOC INF DISPLAY, V29, P497, DOI 10.1002/jsid.991
   Livingston MA, 2006, P IEEE VIRT REAL ANN, P287, DOI 10.1109/VR.2006.142
   MehrabiM Peek E, 2013, 3D DISPLAY TECHNOLOG, P91
   Mohona SS, 2021, J SOC INF DISPLAY, V29, P591, DOI 10.1002/jsid.1002
   Moreau Guillaume, 2013, 2013 26th Conference on Graphics, Patterns and Images - Tutorials (SIBGRAPI-T), P6, DOI 10.1109/SIBGRAPI-T.2013.9
   Rempel D, 2007, HUM FACTORS, V49, P830, DOI 10.1518/001872007X230208
   Seuntiens P., 2006, ACM T APPL PERCEPT, V3, P95
   Speranza F., 2006, P SOC PHOTO-OPT INS, V6055, P94
   Sugita N, 2019, DISPLAYS, V58, P20, DOI 10.1016/j.displa.2018.10.007
   Terzic K, 2016, SIGNAL PROCESS-IMAGE, V47, P402, DOI 10.1016/j.image.2016.08.002
   Tullis T., 2013, Meas. User Exp, P1, DOI [10.1016/B978-0-12-415781-1.00001-7, DOI 10.1016/B978-0-12-415781-1.00001-7]
   Wang Q., 2023, ASSESSMENT INDIVIDUA
   Wetzstein G, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185576
   WOODS A, 1993, P SOC PHOTO-OPT INS, V1915, P36, DOI 10.1117/12.157041
   Yang L, 2016, MULTIMED TOOLS APPL, V75, P17121, DOI 10.1007/s11042-015-2981-y
NR 34
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20265
EP 20287
DI 10.1007/s11042-023-16350-5
EA JUL 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040925900007
DA 2024-07-18
ER

PT J
AU Alghamdi, J
   Al-Dala'in, T
AF Alghamdi, Jawaher
   Al-Dala'in, Thair
TI Towards spatio-temporal crime events prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Future crime prediction; Deep neural networks; Spatio-temporal;
   Synthetic minority oversampling technique
ID SMOTE
AB The importance of early prediction in reducing the impact of crime cannot be overstated. Machine learning algorithms have proven to be effective in this regard, but their inability to capture key features automatically can be a hindrance. To overcome this challenge, we propose a deep neural network model that is capable of extracting salient features automatically for predicting crime categories using real-world crime data sourced from the Chicago open data portal. To ensure the robustness of our proposed model, we carried out an extensive exploratory data analysis to determine the impact of socioeconomic indicators on crime occurrences. Additionally, we implemented a data upsampling technique to handle class imbalance issues, and we leveraged hyperparameter optimization algorithms to fine-tune the model. The results of our study were impressive. Our proposed model outperformed the baseline model and other algorithms, with an average improvement of 6% in macro F1 score. This suggests that our model is highly effective, if not superior, in predicting crime categories accurately. Overall, our study provides a solid framework for using deep neural network models in crime prediction, while highlighting the importance of automatic feature extraction in enhancing the accuracy of predictions. By reducing the impact of crime through early prediction, we can help to create a safer and more secure society.
C1 [Alghamdi, Jawaher] Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld, Australia.
   [Alghamdi, Jawaher] King Khalid Univ, Dept Comp Sci, Abha, Saudi Arabia.
   [Al-Dala'in, Thair] Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, Australia.
   [Al-Dala'in, Thair] Southern Cross Univ SCU, Sch Informat Technol, Sydney, Australia.
   [Al-Dala'in, Thair] Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, Australia.
C3 University of Queensland; King Khalid University; Western Sydney
   University; Southern Cross University
RP Al-Dala'in, T (corresponding author), Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, Australia.; Al-Dala'in, T (corresponding author), Southern Cross Univ SCU, Sch Informat Technol, Sydney, Australia.; Al-Dala'in, T (corresponding author), Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, Australia.
EM j.alghamdi@uqconnect.edu.au; t.aldalain@city.westernsydney.edu.au
CR Al Boni M, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P32, DOI [10.1109/ICMLA.2016.0015, 10.1109/ICMLA.2016.50]
   Alghamdi J, 2021, LECT NOTES COMPUT SC, V12610, P192, DOI 10.1007/978-3-030-69377-0_16
   Almanie T., 2015, International Journal of Data Mining Knowledge Management Process, V5, P01, DOI [10.5121/ijdkp.2015.5401, DOI 10.5121/IJDKP.2015.5401, 10.5121/ijdkp.2015, https://doi.org/10.5121/ijdkp.2015.5401]
   Bappee FK, 2020, ANAL IMPACT FOURSQUA
   Benevenuto Fabricio., 2010, COLL EL MESS ANT SPA, V6, P12
   Bogomolov A, 2014, ARXIV
   Braga AA, 2001, ANN AM ACAD POLIT SS, V578, P104, DOI 10.1177/0002716201578001007
   Brown DE, 1998, IEEE SYS MAN CYBERN, P2848, DOI 10.1109/ICSMC.1998.725094
   Buczak AL, 2010, ACM SIGKDD WORKSH IN, DOI 10.1145/1938606.1938608
   Chainey S, 2008, SECUR J, V21, P4, DOI 10.1057/palgrave.sj.8350066
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chicago Data Portal, US
   Dong Y, 2009, STUDY RANDOM SMOTE C
   Gerber MS, 2014, DECIS SUPPORT SYST, V61, P115, DOI 10.1016/j.dss.2014.02.003
   Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91
   He HB, 2013, IMBALANCED LEARNING: FOUNDATIONS, ALGORITHMS, AND APPLICATIONS, P1
   Hu T, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206215
   Huang YY, 2015, WIRELESS OPTIC COMM, P185, DOI 10.1109/WOCC.2015.7346202
   Iqbal Rizwan., 2013, INDIAN J SCI TECHNOL, V6, P4219, DOI https://doi.org/10.17485/ijst/2013/v6i3.6
   Kang HW, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176244
   Kumar Ravi, 2019, International Journal of Information Technology, V11, P799, DOI 10.1007/s41870-018-0260-7
   Leong K, 2015, INT E-J CRIM SCI
   Mansour AL, 2019, ADV DATA SCI CYBER S, P260, DOI DOI 10.1007/978-3-030
   McCue Colleen., 2014, Data mining and predictive analysis: Intelligence gathering and crime analysis
   Mohler GO, 2011, J AM STAT ASSOC, V106, P100, DOI 10.1198/jasa.2011.ap09546
   Mohler G, 2014, INT J FORECASTING, V30, P491, DOI 10.1016/j.ijforecast.2014.01.004
   Mustaffa Z, 2011, INT P ECON DEV RES, V1, P345
   Nakaya T, 2010, T GIS, V14, P223, DOI 10.1111/j.1467-9671.2010.01194.x
   PATTERSON EB, 1991, CRIMINOLOGY, V29, P755, DOI 10.1111/j.1745-9125.1991.tb01087.x
   Potdar K., 2017, International journal of computer applications, V175, P7, DOI 10.5120/ijca2017915495
   Sengupta A, 2014, CRIME ANAL USING R
   Soares A, 2020, ANAL IMPACT FOURSQUA
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Traunmueller M, 2014, LECT NOTES COMPUT SC, V8851, P396, DOI 10.1007/978-3-319-13734-6_29
   Wang HJ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P635, DOI 10.1145/2939672.2939736
   Weisburd D., 2008, Ideas in American Policing
   Xiaofeng Wang, 2012, Social Computing, Behavioral-Cultural Modeling and Prediction. Proceedings of the 5th International Conference, SBP 2012, P231, DOI 10.1007/978-3-642-29047-3_28
   Xinyu Chen, 2015, 2015 Systems and Information Engineering Design Symposium. proceedings, P63, DOI 10.1109/SIEDS.2015.7117012
   Yu CH, 2016, IEEE T KNOWL DATA EN, V28, P979, DOI 10.1109/TKDE.2015.2507570
   Yu LT, 2016, NEUROCOMPUTING, V213, P48, DOI 10.1016/j.neucom.2016.03.102
   Zhao XY, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P497, DOI 10.1145/3132847.3133024
NR 41
TC 0
Z9 0
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 18721
EP 18737
DI 10.1007/s11042-023-16188-x
EA JUL 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040015500005
OA hybrid
DA 2024-07-18
ER

PT J
AU Lan, LB
   Ye, CX
   Liao, C
   Wang, CL
   Feng, X
AF Lan, Libin
   Ye, Chunxiao
   Liao, Chao
   Wang, Chengliang
   Feng, Xin
TI De-redundancy in wireless capsule endoscopy video sequences using
   correspondence matching and motion analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless capsule endoscopy; Self-supervised learning; Correspondence
   matching; Flow estimation; Motion intensity; Redundancy removal
AB Handling wireless capsule endoscopy (WCE) de-redundancy is a challenging task. This paper proposes a scheme, called SS-VCF-Der, to consider applying a flow field estimation between two successive WCE frames to WCE imaging motion analysis and then address the WCE de-redundancy problem based on the results of the motion analysis. To this end, we intend to exploit a self-supervised technique to learn interframe visual correspondence representations from large amounts of raw WCE videos without manual human supervision, and predict the flow field. Our key idea is to use the natural spatial-temporal coherence in color and cycle consistency in time in WCE videos as free supervisory signal to learn WCE visual correspondence relations from scratch. We call this procedure self-supervised visual correspondence flow learning (SS-VCF). At training time, we use three losses: forward-backward cycle-consistency loss, visual similarity loss, and color loss, to train and optimize model. At test time, we use the acquired representation to generate a flow field for analyzing pixel movement between two successive WCE frames. Furthermore, according to the resulting flow field estimation, we compute the motion intensity of motion fields between two successive frames, and use our proposed de-redundancy method, namely SS-VCF-MI, to select some frames as key ones with distinct scene changes in local neighborhood so as to achieve the purpose of de-redundancy. Extensive experiments on our collected WCE-2019-Video dataset show that our scheme can achieve a promising result, verifying its effectiveness on the visual correspondence representation and redundancy removal for WCE videos.
C1 [Lan, Libin; Feng, Xin] Chongqing Univ Technol, Coll Comp Sci & Engn, 69 Hongguang Ave, Chongqing 400054, Peoples R China.
   [Lan, Libin; Ye, Chunxiao; Liao, Chao; Wang, Chengliang] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
   [Lan, Libin; Ye, Chunxiao; Liao, Chao; Wang, Chengliang] Chongqing Univ, Key Lab Dependable Serv Comp Cyber Phys Soc, Minist Educ, 174 ShaZheng St, Chongqing 400044, Peoples R China.
C3 Chongqing University of Technology; Chongqing University; Chongqing
   University
RP Ye, CX (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.; Ye, CX (corresponding author), Chongqing Univ, Key Lab Dependable Serv Comp Cyber Phys Soc, Minist Educ, 174 ShaZheng St, Chongqing 400044, Peoples R China.
EM lanlbn@cqu.edu.cn; yecx@cqu.edu.cn; liaochaocqu@outlook.com;
   wangcl@cqu.edu.cn; xfeng@cqut.edu.cn
RI Lan, Libin/JDM-7455-2023
OI Lan, Libin/0000-0003-4754-813X; Ye, Chunxiao/0000-0002-6736-1025
FU Scientific Research Foundation of Chongqing University of Technology
   [0103210650]; National Key Research and Development Program of China
   [2017YFB0802400]; National Natural Science Foundation of China research
   fund [61672115]; Chongqing Social Undertakings and Livelihood Security
   Science and Technology Innovation Project Special Program
   [cstc2017shmsA30003]; Humanity and Social Science Youth Foundation,
   Ministry of Education [17YJCZH043]
FX This work is supported in part by the Scientific Research Foundation of
   Chongqing University of Technology (0103210650), in part by the National
   Key Research and Development Program of China (Grant No.
   2017YFB0802400), in part by the National Natural Science Foundation of
   China research fund (61672115), in part by the Chongqing Social
   Undertakings and Livelihood Security Science and Technology Innovation
   Project Special Program (cstc2017shmsA30003), and in part by the
   Humanity and Social Science Youth Foundation, Ministry of Education
   (Grant No. 17YJCZH043). In addition, we thank Juan Zhou and her
   colleagues from the Second Affiliated Hospital, Third Military Medical
   University, for the helpful discussions and suggestions. We also thank
   the Chongqing Jinshan Science & Technology (Group) Co., Ltd., for
   providing vital support with raw WCE videos. We would also like to thank
   the anonymous reviewers for their helpful comments which have led to
   many improvements in this paper.
CR Al-shebani Q, 2019, ARTIF INTELL MED, V94, P18, DOI 10.1016/j.artmed.2018.12.008
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Baopu Li, 2011, Proceedings of the 2011 IEEE International Conference on Automation and Logistics (ICAL), P46, DOI 10.1109/ICAL.2011.6024682
   Baopu Li, 2011, Proceedings 2011 International Conference on Information and Automation (ICIA 2011), P373, DOI 10.1109/ICINFA.2011.5949020
   Baopu Li, 2010, 2010 IEEE International Conference on Robotics and Biomimetics (ROBIO), P454, DOI 10.1109/ROBIO.2010.5723369
   Beg S, 2021, DIGEST LIVER DIS, V53, P1028, DOI 10.1016/j.dld.2021.04.024
   Biniaz A, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101897
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Chen J, 2016, INT C PATT RECOG, P1303, DOI 10.1109/ICPR.2016.7899817
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Divakaran A, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P287, DOI 10.1109/ICIP.2000.899359
   Divakaran A, 2000, P SOC PHOTO-OPT INS, V3972, P392
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Dray X, 2021, J GASTROEN HEPATOL, V36, P12, DOI 10.1111/jgh.15341
   Drozdzal M., 2010, Proceedings of the 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P117, DOI 10.1109/CVPRW.2010.5543456
   Dwibedi D, 2019, PROC CVPR IEEE, P1801, DOI 10.1109/CVPR.2019.00190
   Figueiredo IN, 2017, COMP MED SY, P702, DOI 10.1109/CBMS.2017.18
   Figueiredo IN, 2018, BIOMED SIGNAL PROCES, V39, P486, DOI 10.1016/j.bspc.2017.08.019
   Fu YA, 2012, PROCEEDINGS OF THE 10TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2012), P5030, DOI 10.1109/WCICA.2012.6359431
   Han K, 2017, IEEE I CONF COMP VIS, P1849, DOI 10.1109/ICCV.2017.203
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Huilai Li, 2014, 2014 17th International Symposium on Electromagnetic Launch Technology (EML), P1, DOI 10.1109/EML.2014.6920169
   Iakovidis DK, 2010, COMPUT MED IMAG GRAP, V34, P471, DOI 10.1016/j.compmedimag.2009.11.005
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Jaderberg M, 2015, ARXIV
   Jani KK, 2019, CURR MED IMAGING, V15, P622, DOI 10.2174/1573405614666181102152434
   Karargyris A, 2009, 2009 IEEE/NIH LIFE SCIENCE SYSTEMS AND APPLICATIONS WORKSHOP, P74, DOI 10.1109/LISSA.2009.4906713
   Kim S, 2019, IEEE T PATTERN ANAL, V41, P581, DOI 10.1109/TPAMI.2018.2803169
   Kingma D. P., 2014, arXiv
   Koulaouzidis A, 2021, THER ADV GASTROINTES, V14, DOI 10.1177/26317745211001983
   Lai Z, 2019, ARXIV
   Lan LB, 2021, KNOWL-BASED SYST, V222, DOI 10.1016/j.knosys.2021.106971
   Larsson G, 2017, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2017.96
   Lee HG, 2013, COMPUT BIOL MED, V43, P670, DOI 10.1016/j.compbiomed.2013.02.009
   Lee J, 2019, PROC CVPR IEEE, P2273, DOI 10.1109/CVPR.2019.00238
   Li CY, 2014, SIGNAL IMAGE VIDEO P, V8, P1497, DOI 10.1007/s11760-012-0384-3
   Li S., 2020, P IEEE CVF C COMP VI, P10196
   Liao C, 2021, COMPUT METH PROG BIO, V208, DOI 10.1016/j.cmpb.2021.106189
   Lien GS, 2012, IEEE T BIO-MED ENG, V59, P2068, DOI 10.1109/TBME.2012.2198061
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Liu H, 2013, J DIGIT IMAGING, V26, P287, DOI 10.1007/s10278-012-9519-x
   Liu XY, 2019, PROC CVPR IEEE, P4268, DOI 10.1109/CVPR.2019.00440
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B. D., 1981, P 7 INT JOINT C ART, V81, P674, DOI DOI 10.5555/1623264.1623280
   Mahasseni B, 2017, PROC CVPR IEEE, P2077, DOI 10.1109/CVPR.2017.224
   Meister S, 2017, ARXIV
   Muhammad K, 2020, FUTURE GENER COMP SY, V113, P266, DOI 10.1016/j.future.2020.06.048
   Nie R, 2020, ARXIV
   Paszke Adam, 2017, NIPSW
   Rocco I, 2019, IEEE T PATTERN ANAL, V41, P2553, DOI 10.1109/TPAMI.2018.2865351
   Rondonotti E, 2020, ENDOSC INT OPEN, V08, pE1220, DOI 10.1055/a-1210-4830
   Schoeffmann K, 2015, MULTIMED TOOLS APPL, V74, P11187, DOI 10.1007/s11042-014-2224-7
   Spyrou E, 2013, 2013 8TH INTERNATIONAL WORKSHOP ON SEMANTIC AND SOCIAL MEDIA ADAPTATION AND PERSONALIZATION (SMAP 2013), P41, DOI 10.1109/SMAP.2013.21
   Spyrou E, 2014, MEAS SCI TECHNOL, V25, DOI 10.1088/0957-0233/25/1/015002
   Sushma B, 2021, IEEE ACCESS, V9, P13691, DOI 10.1109/ACCESS.2020.3044759
   Vondrick C, 2018, LECT NOTES COMPUT SC, V11217, P402, DOI 10.1007/978-3-030-01261-8_24
   Wang N, 2019, PROC CVPR IEEE, P1308, DOI 10.1109/CVPR.2019.00140
   Wang XL, 2019, PROC CVPR IEEE, P2561, DOI 10.1109/CVPR.2019.00267
   Xu YX, 2021, IEEE T AUTOM SCI ENG, V18, P1640, DOI 10.1109/TASE.2020.3013954
   Yuan YX, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P225, DOI 10.1109/ICMA.2013.6617922
   Zhang K, 2016, ARXIV
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
NR 65
TC 1
Z9 1
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21171
EP 21195
DI 10.1007/s11042-023-15530-7
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037378900005
DA 2024-07-18
ER

PT J
AU Mahto, D
   Yadav, SC
AF Mahto, Dashrath
   Yadav, Subhash Chandra
TI Emotion prediction for textual data using GloVe based HeBi-CuDNNLSTM
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural language processing; Deep neural network; Emotion prediction;
   Sentiment analysis; Bidirectional-LSTM
ID RECOMMENDATION SYSTEM; SENTIMENT; RECOGNITION
AB In the digital era, social media websites have emerged as powerful tools for sharing emotions worldwide, and significantly impacting people's social and personal lives. People share their feelings and perspectives in the form of texts, images, emojis, audio, emoticons, and videos. Among the popular social media platforms, Twitter stands out, generating an enormous quantity of unstructured textual data. Due to its strict character limit of 280, Tweets are particularly prone to information diversity, text sarcasm, word sense ambiguity, indirect negation, and other problems. Consequently, identifying and categorizing actual emotions from these textual data becomes a challenging task. To address these challenges; this research paper improved the performance accuracy of the existing HeBiLSTM model by adding one additional Bi-LSTM hidden layer, named as Improved GloVe-HeBiLSTM model. Additionally, the Authors proposed a Hierarchical Bi-CuDNNLSTM with NVIDIA CUDA deep neural network library (named HeBi-CuDNNLSTM) as a practical framework for analyzing actual emotions of textual data. The Improved GloVe-HeBiLSTM and proposed HeBi-CuDNNLSTM models have been trained and validated with emotions-dataset-for-NLP dataset and evaluated with various performance measures such as accuracy, recall, precision, and F-1-score. Performance accuracy of the Improved GloVe-HeBiLSTM and the proposed HeBi-CuDNNLSTM frameworks have been compared with existing HeBiLSTM (89%) and recent baseline models, mainly GloVe-CNN-LSTM (92.75%), GloVe-BiLSTM (93.10%), GloVe-CNN-BiLSTM (92.65%), and GloVe-CNN-BiGRU (93.25%). Therefore the Improved GloVe-HeBiLSTM and proposed HeBi-CuDNNLSTM models outperform the existing HeBiLSTM and other baseline models with an accuracy rate of 93.70% and 94.20%, respectively.
C1 [Mahto, Dashrath; Yadav, Subhash Chandra] Cent Univ Jharkhand, Dept Comp Sci & Engn, Ranchi 835205, Jharkhand, India.
C3 Central University of Jharkhand
RP Mahto, D (corresponding author), Cent Univ Jharkhand, Dept Comp Sci & Engn, Ranchi 835205, Jharkhand, India.
EM dashrathmahto12@gmail.com; dr.scyadav@cuj.ac.in
RI Mahto, Dr. Dashrath/AHB-0746-2022
OI Mahto, Dr. Dashrath/0000-0002-7604-4291
CR Abid F, 2020, COMPUT COMMUN, V157, P102, DOI 10.1016/j.comcom.2020.04.002
   Ahmad Z, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112851
   Alotaibi FM, 2021, COGN COMPUT, V13, P709, DOI 10.1007/s12559-021-09836-7
   Ankita, 2022, EXPERT SYST APPL, V193, DOI 10.1016/j.eswa.2021.116256
   Barbu E, 2015, EXPERT SYST APPL, V42, P3501, DOI 10.1016/j.eswa.2014.11.070
   Batbaatar E, 2019, IEEE ACCESS, V7, P111866, DOI 10.1109/ACCESS.2019.2934529
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Chatterjee A., 2019, P 13 INT WORKSH SEM, P39, DOI DOI 10.18653/V1/S19-2005
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen K, 2020, ENERGIES, V13, DOI 10.3390/en13174522
   Chen M, 2017, IEEE ACCESS, V5, P8869, DOI 10.1109/ACCESS.2017.2694446
   Chollet F., 2015, KERAS PYTHON DEEP LE
   Devlin J., 2018, BERT PRE TRAINING DE
   Faruqui M, 2014, PREPRINT
   Gao ZW, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12052707
   Gers FA, 2001, IEEE T NEURAL NETWOR, V12, P1333, DOI 10.1109/72.963769
   Hegde S, 2021, VEH TECHNOL CONFE, DOI 10.1109/VTC2021-Spring51267.2021.9449009
   Hinton G. E., 2012, ARXIV PREPRINT ARXIV
   Jayakrishnan R., 2018, 2018 INT C COMPUTER, P1
   Kamyab M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112311255
   Kingma D. P., 2014, arXiv
   Kratzwald B, 2018, DECIS SUPPORT SYST, V115, P24, DOI 10.1016/j.dss.2018.09.002
   Kumar Pushpendra, 2023, Key Digital Trends Shaping the Future of Information and Management Science: Proceedings of 5th International Conference on Information Systems and Management Science (ISMS) 2022. Lecture Notes in Networks and Systems (671), P60, DOI 10.1007/978-3-031-31153-6_6
   Li A, 2022, COMPUT INTEL NEUROSC, V2022
   Li WM, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102818
   MA L, 2019, P 13 INT WORKSHOP SE, P287, DOI DOI 10.18653/V1/S19-2049
   Mahto D, 2022, MOB INF SYST, V2022, DOI 10.1155/2022/1068554
   Mahto D, 2022, B POL ACAD SCI-TECH, V70, DOI 10.24425/bpasts.2022.141001
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Nandanwar AK, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13101772
   Pei YJ, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031182
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Pimpalkar A, 2022, EXPERT SYST APPL, V203, DOI 10.1016/j.eswa.2022.117581
   Radford A., 2019, LANGUAGE MODELS ARE
   Ragheb W, 2019, PREPRINT
   Ramachandran P., 2017, PREPRINT
   Rao GZ, 2018, NEUROCOMPUTING, V308, P49, DOI 10.1016/j.neucom.2018.04.045
   Serrano-Guerrero J, 2022, ARTIF INTELL MED, V128, DOI 10.1016/j.artmed.2022.102298
   Sundaram V, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P292, DOI 10.1109/Confluence51648.2021.9377159
   Tam S, 2021, IEEE ACCESS, V9, P41283, DOI 10.1109/ACCESS.2021.3064830
   Turian J, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P384
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang J, 2018, NEUROCOMPUTING, V322, P93, DOI 10.1016/j.neucom.2018.09.049
   Wu JL, 2020, IEEE ACCESS, V8, P66638, DOI 10.1109/ACCESS.2020.2985228
   Yu LC, 2020, IEEE T AFFECT COMPUT, V11, P447, DOI 10.1109/TAFFC.2018.2807819
   Yu LC, 2018, IEEE-ACM T AUDIO SPE, V26, P671, DOI 10.1109/TASLP.2017.2788182
   Zhang W, 2022, ALEX ENG J, V61, P6755, DOI 10.1016/j.aej.2021.12.022
   Zhao JH, 2021, J INTELL FUZZY SYST, V40, P3097, DOI 10.3233/JIFS-189348
   Zhou JH, 2019, IEEE ACCESS, V7, P38856, DOI 10.1109/ACCESS.2019.2905048
NR 54
TC 4
Z9 4
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 18943
EP 18968
DI 10.1007/s11042-023-16062-w
EA JUL 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001035725000002
DA 2024-07-18
ER

PT J
AU Rodrigo, M
   Cuevas, C
   Berjón, D
   García, N
AF Rodrigo, Marcos
   Cuevas, Carlos
   Berjon, Daniel
   Garcia, Narciso
TI Automatic highlight detection in videos of martial arts tricking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Highlight event detection; Automatic video summary; Temporal
   segmentation; Martial arts tricking
ID SPORTS VIDEO; RECOGNITION
AB We propose a novel strategy for the automatic detection of highlight events in user-generated tricking videos, to the best of our knowledge, the first one specifically tailored for this complex sport. Most current methods for related sports leverage high-level semantics such as predefined camera angles or common editing practices, or rely on depth cameras to achieve automatic detection. However, our approach only relies on the contents (themselves) in the frames of a given video, and consists in a four stage pipeline. The first stage identifies foreground key points of interest along with an estimation of their motion in the video frames. In the second stage, these points are grouped into regions of interest based on their proximity and motion. Their behavior over time is evaluated in the third stage to generate an attention map indicating the regions participating in the most relevant events. The fourth and final stage provides the extracted video sequences where highlights have been identified. Experimental results attest to the effectiveness of our approach, which shows high recall and precision values at frame level, with detections that fit well the ground truth events.
C1 [Rodrigo, Marcos; Cuevas, Carlos; Berjon, Daniel; Garcia, Narciso] Univ Politecn Madrid UPM, Informat Proc & Telecommun Ctr IPTC, Grp Tratamiento Imagenes GTI, ETSI Telecomunicac, Madrid 28040, Spain.
C3 Universidad Politecnica de Madrid
RP Rodrigo, M (corresponding author), Univ Politecn Madrid UPM, Informat Proc & Telecommun Ctr IPTC, Grp Tratamiento Imagenes GTI, ETSI Telecomunicac, Madrid 28040, Spain.
EM marcos.rodrigo@upm.es; carlos.cuevas@upm.es; daniel.berjon@upm.es;
   narciso.garcia@upm.es
RI García, Narciso/E-8603-2011
OI García, Narciso/0000-0002-0397-894X
FU Spanish Government [PID2020-115132RB, MCIN/AEI/10.13039/501100011033]
FX AcknowledgementsThis work has been partially supported by project
   PID2020-115132RB (SARAOS) funded by MCIN/AEI/10.13039/501100011033 of
   the Spanish Government.
CR Alcantarilla PF, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.13
   Amri-Dardari A, 2020, SCI GYMNAST J, V12, P325
   Badamdorj T., 2021, P IEEECVF INT C COMP, P8127
   Badamdorj T, 2022, PROC CVPR IEEE, P14022, DOI 10.1109/CVPR52688.2022.01365
   Basavarajaiah M, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3355398
   Bouguet, 2001, INTEL CORP, V5, P4, DOI DOI 10.1109/HPDC.2004.1323531
   Cheng Yan, 2021, 2021 16th International Conference on Computer Science & Education (ICCSE), P653, DOI 10.1109/ICCSE51940.2021.9569708
   Connolly PW, 2017, PREPRINT
   Cuevas C, 2020, MULTIMED TOOLS APPL, V79, P29685, DOI 10.1007/s11042-020-09409-0
   Dange B, 2022, 2022 INT C SMART TEC, P1
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Grassie KP, 2017, HONORS SCHOLAR THESE, V522
   Han B., 2011, 2011 IEEE WORKSH APP, P51
   Haq Hafiz Burhan Ul, 2020, Int. J. Sci. Technol. Res, V9, P146
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   He LF, 2017, PATTERN RECOGN, V70, P25, DOI 10.1016/j.patcog.2017.04.018
   Hnitetska T, 2017, PHYS ED SPORT HLTH C, V3, P29, DOI DOI 10.29038/2220-7481-2017-03-29-33
   Hussain T, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107567
   Kong YQ, 2018, MULTIMED TOOLS APPL, V77, P13643, DOI 10.1007/s11042-017-4979-0
   Lei Q, 2021, SIGNAL IMAGE VIDEO P, V15, P1575, DOI 10.1007/s11760-021-01890-w
   Li S, 2022, PREPRINT
   Lienhart R, 2000, PROC SPIE, V3972, P378
   Liu MM, 2022, DISPLAYS, V72, DOI 10.1016/j.displa.2021.102138
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Meng JJ, 2016, PROC CVPR IEEE, P1039, DOI 10.1109/CVPR.2016.118
   Pan H, 2001, INT CONF ACOUST SPEE, P1649, DOI 10.1109/ICASSP.2001.941253
   Díaz-Pereira MP, 2014, HUM MOVEMENT SCI, V34, P63, DOI 10.1016/j.humov.2014.01.001
   Raval KR, 2022, MULTIMED TOOLS APPL, V81, P29253, DOI 10.1007/s11042-022-12834-y
   Reily B, 2017, COMPUT VIS IMAGE UND, V159, P154, DOI 10.1016/j.cviu.2016.11.006
   Senior A., 2002, PROC IEEE INT WORKSH, P48
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Shih HC, 2018, IEEE T CIRC SYST VID, V28, P1212, DOI 10.1109/TCSVT.2017.2655624
   Sun M, 2014, LECT NOTES COMPUT SC, V8689, P787, DOI 10.1007/978-3-319-10590-1_51
   Sun SW, 2013, J VIS COMMUN IMAGE R, V24, P232, DOI 10.1016/j.jvcir.2012.12.003
   Tejero-de-Pablos A, 2018, IEEE T MULTIMEDIA, V20, P2000, DOI 10.1109/TMM.2018.2794265
   Thanh N.T., 2019, Journal on Information Technologies & Communications, V2019, P114, DOI 10.32913/mic-ict-research.v2019.n2.864
   Tiwari V, 2021, MULTIMED TOOLS APPL, V80, P27187, DOI 10.1007/s11042-021-10977-y
   Vasudevan Vani, 2021, Advances and Trends in Artificial Intelligence. From Theory to Practice: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021, Proceedings. Lecture Notes in Computer Science. Lecture Notes in Artifical Intelligence (12799), P347, DOI 10.1007/978-3-030-79463-7_29
   Voronina M, 2019, THESIS TALLINN U TEC
   Wei FY, 2022, PROC CVPR IEEE, P3063, DOI 10.1109/CVPR52688.2022.00308
   Xu Mengmeng, 2021, P IEEE CVF INT C COM
   Zahan S, 2023, PREPRINT
NR 42
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17109
EP 17133
DI 10.1007/s11042-023-16003-7
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035582300003
OA hybrid
DA 2024-07-18
ER

PT J
AU Seeli, DJJ
   Thanammal, KK
AF Seeli, D. Jeni Jeba
   Thanammal, K. K.
TI Quantitative Analysis of Gradient Descent Algorithm using scaling
   methods for improving the prediction process based on Artificial Neural
   Network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial Neural Network; Logistic Regression; Gradient Descent
   Algorithm; Scaling Methods; Statistical Test; Ensemble Normalization and
   Standardization
AB The health development is one of the most important challenges in the world today. All human beings are affected by many diseases due to various circumstances like pollution, climate change, living habits, etc. Therefore, the improvement of predicting diseases is a very essential process in medical management. Prediction refers to the results of an algorithm after it has been trained on a dataset. It is a mathematical process that seeks to predict future outcomes by analyzing methods. Classification methods of machine learning can be used to find accurate prediction of disease by the symptoms. This paper reviews the gradient descent algorithm such as Logistic Regression and Artificial Neural Network. These models are highly applicable and deliver reliable prediction accuracy with the help of a dataset. The survey indicates that the most popular classification techniques are Artificial Neural Network and Logistic Regression. The major purpose of this study is to investigate the performance of various scaling methods, including ensemble normalization and standardization methods, for improving disease prediction. The study also presents a performance comparison of classification algorithms, with and without applying the feature scaling of the data preprocessing techniques. In the proposed system, two algorithms, Artificial Neural Network and Logistic Regression, were used for the classification. Firstly, the accuracy of Artificial Neural Network and Logistic Regression without scaling method was calculated. The results show that Artificial Neural Network produces the highest accuracy of 86.13% in predicting heart disease. Next, various scaling methods were applied with Artificial Neural Network and Logistic Regression algorithms to improve the accuracy of the prediction process. The experimental results show that the accuracy of Artificial Neural Network using Ensemble Normalization and Standardization is 98.81%, which is greater than the other accuracies. Finally, a statistical test was used to assess the significance of the difference in performance among the classifiers.
C1 [Seeli, D. Jeni Jeba] Scott Christian Coll Autonomous, Dept Comp Sci, Nagercoil, India.
   [Thanammal, K. K.] ST Hindu Coll, Dept Comp Sci, Nagercoil, India.
RP Seeli, DJJ (corresponding author), Scott Christian Coll Autonomous, Dept Comp Sci, Nagercoil, India.
EM jeniseeli@gmail.com; thanaravindran@gmail.com
CR Bashir S, 2019, INT BHURBAN C APPL S, P619, DOI 10.1109/IBCAST.2019.8667106
   Battineni G, 2020, J PERS MED, V10, DOI 10.3390/jpm10020021
   Dahiwade D, 2019, PROCEEDINGS OF THE 2019 3RD INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC 2019), P1211, DOI [10.1109/ICCMC.2019.8819782, 10.1109/iccmc.2019.8819782]
   Dey Samrat Kumar, 2018, 2018 21st International Conference of Computer and Information Technology (ICCIT), DOI 10.1109/ICCITECHN.2018.8631968
   Diwakar M, 2021, MATER TODAY-PROC, V37, P3213, DOI 10.1016/j.matpr.2020.09.078
   Jamal S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62368-2
   Javeed A, 2020, MOB INF SYST, V2020, DOI 10.1155/2020/8843115
   Kasasbeh AS, 2019, STROKE, V50, P1578, DOI 10.1161/STROKEAHA.118.022649
   Khan Y, 2019, ICMLC 2019: 2019 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P21, DOI 10.1145/3318299.3318343
   Mary MMA., 2020, INT J RES APPL SCI E, V8, P441, DOI [10.22214/ijraset.2020.31917, DOI 10.22214/IJRASET.2020.31917]
   Meshref H, 2019, IJACSA INT J ADV COM, V10
   Mhatre T, 2019, INT J ENG RES TECHNO, V8
   Muhammad W, 2019, FRONT ARTIF INTELL, V2, DOI 10.3389/frai.2019.00002
   Musleh MM, 2019, IJAISR, P1
   Prasanth K, 2019, INT J INTELL ENG SYS, V12, DOI [10.22266/ijies2019.1031.28, DOI 10.22266/IJIES2019.1031.28]
   Rani S, 2020, J DISCRET MATH SCI C, V23, P293, DOI 10.1080/09720529.2020.1721862
   Razia S., 2018, Int. J. Eng. Technol., V7, P315, DOI [10.14419/ijet.v7i2.8.10432, DOI 10.14419/IJET.V7I2.8.10432]
   Salehi M, 2021, ANN WORK EXPOS HEAL, V65, P346, DOI 10.1093/annweh/wxaa097
   Salim NAM, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-79193-2
   Spann A, 2020, HEPATOLOGY, V71, P1093, DOI 10.1002/hep.31103
   Subhadra K., 2019, International Journal of Innovative Technology and Exploring Engineering (IJITEE), V8, P484
   Terrada O, 2020, SUPERVISED MACHINE L, DOI [10.25046/aj050533, DOI 10.25046/AJ050533]
   Vallée A, 2019, J HYPERTENS, V37, P1682, DOI 10.1097/HJH.0000000000002075
NR 23
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 15677
EP 15691
DI 10.1007/s11042-023-16136-9
EA JUL 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001031478800001
DA 2024-07-18
ER

PT J
AU Zhang, X
   Wang, Y
   Yang, Q
   Shen, YR
   Wen, HK
AF Zhang, Xian
   Wang, Yong
   Yang, Qing
   Shen, Yiran
   Wen, Hongkai
TI EV-Perturb: event-stream perturbation for privacy-preserving
   classification with dynamic vision sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event camera; Differential privacy; Video reconstruction
AB The dynamic vision sensors or event-cameras are bio-inspired vision platforms with independent and asynchronous pixels. Their unique design enables a number of advantages over traditional RGB cameras, including high temporal resolution for capturing high speed motion without blur and high dynamic range for sensing under challenging lighting conditions. As the outputs of the event-cameras are discrete and asynchronous events, termed as event-streams, rather than traditional high-quality video frames, they are regarded as low privacy-intrusive. However, research on reconstruction from events has revealed that event-streams can be converted to high quality video frames by sophisticated reconstruction algorithms, so that the claim on privacy-preserving does not hold anymore. In this paper, we focus on the privacy issue of event-streams used in EV-based classification tasks and propose, EV-Perturb, an event-stream perturbation mechanism to protect event-streams from reconstruction attacks. EV-Perturb flips polarities of events in a random manner and the theoretical proof shows that it provides differential-private guarantee on the perturbed event-streams. We also evaluate the utility (classification accuracy) and privacy (video reconstruction error) of EV-Perturb on EV-based classification tasks with multiple publicly available datasets using deep learning models. In summary, this work has several technical contributions. First, by proposing EV-Perturb, we consider the privacy issue of event-streams under reconstruction attack, which is the first piece of work focusing on solving this specific privacy issue. The approach is based on randomized response, which is both efficient and effective, shown as our evaluation. We also provide a theoretical proof that EV-Perturb is differential-private and derive the strict privacy guarantee with respect to the probability of change. Lastly, the results of the extensive evaluations show that EV-Perturb is can effectively protect event-streams from reconstruction attacks while preserving comparable accuracy on classification.
C1 [Zhang, Xian; Wang, Yong] Harbin Engn Univ, Coll Comp Sci & Technol, 145 Nantong St, Harbin 150001, Heilongjiang, Peoples R China.
   [Yang, Qing] Capital Univ Econ & Business, Sch Management & Engn, 121 Shoujingmao S Rd, Beijing 100070, Peoples R China.
   [Shen, Yiran] Shandong Univ, Sch Software, 27 Shanda S Rd, Jinan 250100, Shandong, Peoples R China.
   [Wen, Hongkai] Univ Warwick, Dept Comp Sci, Coventry CV4 7AL, England.
C3 Harbin Engineering University; Capital University of Economics &
   Business; Shandong University; University of Warwick
RP Wang, Y (corresponding author), Harbin Engn Univ, Coll Comp Sci & Technol, 145 Nantong St, Harbin 150001, Heilongjiang, Peoples R China.
EM zhangxian_tech@163.com; wangyongcs@hrbeu.edu.cn; yangqing@cueb.edu.cn;
   yiran.shen@sdu.edu.cn; hongkai.wen@dcs.warwick.ac.uk
RI Wen, Hongkai/GLN-4621-2022
OI Wen, Hongkai/0000-0003-1159-090X; Yang, Qing/0000-0002-2772-4813
FU Shandong Provincial Natural Science Foundation, China [2022HWYQ-040];
   Youth Fund Project of Humanities and Social Sciences Research of the
   Ministry of Education of China [20YJCZH172]
FX AcknowledgementsThis work is partially supported by Shandong Provincial
   Natural Science Foundation, China, Grant No. 2022HWYQ-040 and the Youth
   Fund Project of Humanities and Social Sciences Research of the Ministry
   of Education of China under Grant No.20YJCZH172.
CR Amir Arnon, 2017, CVPR, DOI DOI 10.1109/CVPR.2017.781
   BARDOW P, 2016, PROC CVPR IEEE, P884, DOI DOI 10.1109/CVPR.2016.102
   Bi Y, 2020, IEEE T IMAGE PROCESS, V29, P9084, DOI 10.1109/TIP.2020.3023597
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dwork C, 2013, FOUND TRENDS THEOR C, V9, P211, DOI 10.1561/0400000042
   Falanga D, 2020, SCI ROBOT, V5, DOI 10.1126/scirobotics.aaz9712
   Gallego G, 2019, ARXIV
   Gupta BB, 2018, MULTIMED TOOLS APPL, V77, P9203, DOI 10.1007/s11042-017-5301-x
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kasiviswanathan SP, 2008, ANN IEEE SYMP FOUND, P531, DOI 10.1109/FOCS.2008.27
   Kim H, 2016, LECT NOTES COMPUT SC, V9910, P349, DOI 10.1007/978-3-319-46466-4_21
   Kowalczuk Z, 2019, IFAC PAPERSONLINE, V52, P416, DOI 10.1016/j.ifacol.2019.08.099
   Kueng B, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P16, DOI 10.1109/IROS.2016.7758089
   Lagorce X, 2017, IEEE T PATTERN ANAL, V39, P1346, DOI 10.1109/TPAMI.2016.2574707
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee KH, 2001, INT J ADV MANUF TECH, V18, P201, DOI 10.1007/s001700170075
   Lichtsteiner Patrick, 2008, IEEE Journal of Solid-State Circuits, V43, P566, DOI 10.1109/JSSC.2007.914337
   Lin Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8312, DOI 10.1109/CVPR42600.2020.00834
   Liu SC, 2010, CURR OPIN NEUROBIOL, V20, P288, DOI 10.1016/j.conb.2010.03.007
   Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576
   Mostafavi ISM, 2020, PROC CVPR IEEE, P2765, DOI 10.1109/CVPR42600.2020.00284
   Munda G, 2018, INT J COMPUT VISION, V126, P1381, DOI 10.1007/s11263-018-1106-2
   Orchard G, 2015, FRONT NEUROSCI-SWITZ, V9, DOI [10.3389/fnins.2015.00437, 10.3389/fhins.2015.00437]
   Paikin G, 2021, IEEE COMPUT SOC CONF, P1291, DOI 10.1109/CVPRW53098.2021.00142
   Paszke A, 2019, ADV NEUR IN, V32
   Rebecq H, 2021, IEEE T PATTERN ANAL, V43, P1964, DOI 10.1109/TPAMI.2019.2963386
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Simonovsky M, 2017, PROC CVPR IEEE, P29, DOI 10.1109/CVPR.2017.11
   Sironi A, 2018, PROC CVPR IEEE, P1731, DOI 10.1109/CVPR.2018.00186
   Wang QY, 2019, IEEE WINT CONF APPL, P1826, DOI 10.1109/WACV.2019.00199
   Wang YX, 2019, PROC CVPR IEEE, P6351, DOI 10.1109/CVPR.2019.00652
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WARNER SL, 1965, J AM STAT ASSOC, V60, P63, DOI 10.2307/2283137
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhu AZ, 2018, ARXIV
NR 35
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16823
EP 16847
DI 10.1007/s11042-023-15743-w
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001032703400003
DA 2024-07-18
ER

PT J
AU Sivakumar, MS
   Leo, LM
   Gurumekala, T
   Sindhu, V
   Priyadharshini, AS
AF Sivakumar, M. Senthil
   Leo, L. Megalan
   Gurumekala, T.
   Sindhu, V.
   Priyadharshini, A. Saraswathi
TI Deep learning in skin lesion analysis for malignant melanoma cancer
   identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial neural network; Convolutional neural network; Machine
   learning; ResNet50; Benign; Malignant
ID CLASSIFICATION; FRAMEWORK
AB The higher rate of skin diseases caused by infections, allergies, lifestyle changes, increased use of chemicals, unhealthy food habits, and hereditary reactions, among other factors demand effective diagnostic mechanisms. These mechanisms should facilitate and expedite the precise diagnosis of malignant melanoma. In addition, the existing technology-assisted tests require elaborate procedures to accurately diagnose the skin disease to be treated. The deep learning-enhanced inspection involves neural networks that diagnose skin diseases by analyzing data for skin lesions such as rashes, boils, and cancer growth. This paper proposes an automated high-precision diagnostic model with the web application to identify Malignant Melanoma Cancer. The diagnostic model framework employs a convolutional neural network (CNN) with ResNet50 for data collection, preprocessing, segmentation, enhancement, feature extraction, classification, and malignant melanoma identification to improve accuracy. The proposed model eliminates unwanted noise, enhances spectral image information, and improves classification accuracy through preprocessing and mixed hybrid pooling phases. Performance analysis shows that the proposed Malignant Melanoma Cancer detection model achieves the highest accuracy of 94% and an F1-score of 93.9%. Results from a training and testing dataset of images from the International Skin Image Collaboration (ISIC) demonstrate a significant improvement over traditional methods. Further, the web application developed for this model accelerates the precise diagnosis of Malignant Melanoma Cancer with accurate information compared to other methods in practice. The potential of applying the proposed skin cancer classification model automates the malignant and benign image classification process, speeds up diagnosis and treatment, and reduces the risk of misdiagnosis.
C1 [Sivakumar, M. Senthil; Sindhu, V.] Indian Inst Informat Technol Tiruchirappalli, Tiruchirappalli, Tamil Nadu, India.
   [Leo, L. Megalan] Sathyabama Inst Sci & Technol, Chennai, Tamil Nadu, India.
   [Gurumekala, T.] MIT Campus Anna Univ, Chennai, Tamil Nadu, India.
   [Priyadharshini, A. Saraswathi] Vellore Inst Technol, Vellore, Tamil Nadu, India.
C3 Sathyabama Institute of Science & Technology; Anna University; Anna
   University Chennai; Vellore Institute of Technology (VIT); VIT Vellore
RP Sivakumar, MS (corresponding author), Indian Inst Informat Technol Tiruchirappalli, Tiruchirappalli, Tamil Nadu, India.
EM msenthilsivakumar@gmail.com
RI M, Senthil Sivakumar/J-4177-2015; L, MEGALAN LEO/I-4403-2018
OI M, Senthil Sivakumar/0000-0002-7715-1216; L, MEGALAN
   LEO/0000-0002-6179-1411
CR Adegun A, 2021, ARTIF INTELL REV, V54, P811, DOI 10.1007/s10462-020-09865-y
   Adegun AA, 2020, IEEE ACCESS, V8, P150377, DOI 10.1109/ACCESS.2020.3016651
   Ashraf R, 2020, IEEE ACCESS, V8, P147858, DOI 10.1109/ACCESS.2020.3014701
   Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Ballerini L., 2013, Color medical image analysis, P63
   Barhoumi W, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104825
   Chaturvedi SS, 2020, MULTIMED TOOLS APPL, V79, P28477, DOI 10.1007/s11042-020-09388-2
   Dhivyaa CR, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02675-8
   Dorj UO, 2018, MULTIMED TOOLS APPL, V77, P9909, DOI 10.1007/s11042-018-5714-1
   Goyal M, 2020, COMPUT BIOL MED, V127, DOI 10.1016/j.compbiomed.2020.104065
   Hatem MQ, 2022, VIS COMPUT IND BIOME, V5, DOI 10.1186/s42492-022-00103-6
   Jaisakthi SM, 2023, MULTIMED TOOLS APPL, V82, P15763, DOI 10.1007/s11042-022-13847-3
   Kadampur Mohammad Ali, 2020, Informatics in Medicine Unlocked, V18, P119, DOI 10.1016/j.imu.2019.100282
   Monika MK, 2020, MATER TODAY-PROC, V33, P4266, DOI 10.1016/j.matpr.2020.07.366
   Olusola OA., 2021, TURK J ELECTR ENG CO, V29, P2600
   Raajan NR, 2021, NATL ACAD SCI LETT, V44, P347, DOI 10.1007/s40009-020-01009-8
   Shanthi T, 2020, MICROPROCESS MICROSY, V76, DOI 10.1016/j.micpro.2020.103074
   Tanaka T, 2018, J CANCER RES CLIN, V144, P607, DOI 10.1007/s00432-018-2589-5
   Tumpa P, 2021, Sens Int, V2, DOI [10.1016/j.sintl.2021.100128, DOI 10.1016/J.SINTL.2021.100128]
   Wei LS, 2020, IEEE ACCESS, V8, P99633, DOI 10.1109/ACCESS.2020.2997710
   Xin C, 2022, COMPUT BIOL MED, V149, DOI 10.1016/j.compbiomed.2022.105939
NR 22
TC 2
Z9 2
U1 7
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17833
EP 17853
DI 10.1007/s11042-023-16273-1
EA JUL 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001029126000007
DA 2024-07-18
ER

PT J
AU Liang, Y
   Hao, Y
   Liao, JC
   Deng, ZR
   Wen, X
   Zheng, ZF
   Pan, JH
AF Liang, Yan
   Hao, Yan
   Liao, Jiacheng
   Deng, Zhuoran
   Wen, Xing
   Zheng, Zefeng
   Pan, Jiahui
TI A spatiotemporal network using a local spatial difference stack block
   for facial micro-expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Micro-expression; Local spatial difference stack; Spatiotemporal
   network; Center loss
ID EXTRACTION; ATTENTION; FUSION
AB Recently, video-based micro-expression recognition (MER) applications have attracted attention in various scenarios. However, current deep learning-based MER methods frequently struggle with several challenges, such as insufficient data, difficulty in capturing subtle facial motions, and keyframe recognition. In this paper, we propose a robust MER solution without prior annotation of keyframes. To prevent traditional data augmentation techniques from destroying the slight motion information in the sequence frames, stride sampling is designed to increase the number of samples while preserving the important motion features of the micro-expression (ME). Moreover, to capture facial rapid and subtle changes to enhance the accuracy of ME classification, we construct a local spatial difference stack (LSDS) block and incorporate it into the lightweight spatiotemporal network VGGFace-TCN. Experiments demonstrate that our proposed algorithm can effectively detect the local facial movement details of MEs from original frames without additional visual features, e.g., optical flow, and minimize the risk of overfitting. Compared with other state-of-the-art methods, the proposed method obtained the best performance under the holdout database evaluation (HDE) strategy with an accuracy and F1-score of 57.46% and 0.3734, respectively. Furthermore, it attained an accuracy of 61.27% and an F1-score of 0.5343 on the Spontaneous Actions and Micro-movements (SAMM) dataset, which is significantly higher than other state-of-the-art methods.
C1 [Liang, Yan; Hao, Yan; Liao, Jiacheng; Deng, Zhuoran; Wen, Xing; Zheng, Zefeng; Pan, Jiahui] South China Normal Univ, Sch Software, Foshan 528200, Nanhai, Peoples R China.
C3 South China Normal University
RP Pan, JH (corresponding author), South China Normal Univ, Sch Software, Foshan 528200, Nanhai, Peoples R China.
EM liangyan@m.scnu.edu.cn; yanhao@m.scnu.edu.cn; panjiahui@m.scnu.edu.cn
RI Pan, Jiahui/ADI-3371-2022
OI Pan, Jiahui/0000-0002-7576-6743
FU National Natural Science Foundation of China [62076103]; Guangzhou
   Science and Technology Plan Project Key Field R amp;D Project
   [202007030005]; Guangdong Natural Science Foundation of China
   [2019A1515011375]
FX AcknowledgementsThis work was supported in part by the National Natural
   Science Foundation of China under grant 62076103, the Guangzhou Science
   and Technology Plan Project Key Field R &D Project under grant
   202007030005, and the Guangdong Natural Science Foundation of China
   under grant 2019A1515011375.
CR Ahmad S, 2022, CLUSTER COMPUT, V25, P3733, DOI 10.1007/s10586-022-03598-z
   Bai S., 2018, An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling, DOI [10.48550/arXiv.1803.01271, DOI 10.48550/ARXIV.1803.01271]
   Chang S, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2103.16024
   Davison AK, 2018, J IMAGING, V4, DOI 10.3390/jimaging4100119
   Ding CY, 2021, AAAI CONF ARTIF INTE, V35, P1227
   EKMAN P, 1969, PSYCHIATR, V32, P88, DOI 10.1080/00332747.1969.11023575
   Han JL, 2022, PR MACH LEARN RES
   Happy SL, 2019, IEEE T AFFECT COMPUT, V10, P394, DOI 10.1109/TAFFC.2017.2723386
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Kanmani M, 2020, MULTIMED TOOLS APPL, V79, P17859, DOI 10.1007/s11042-020-08628-9
   Kanmani M, 2019, MULTIDIM SYST SIGN P, V30, P1911, DOI 10.1007/s11045-019-00636-9
   Khor HQ, 2019, IEEE IMAGE PROC, P36, DOI [10.1109/icip.2019.8802965, 10.1109/ICIP.2019.8802965]
   Khor HQ, 2018, IEEE INT CONF AUTOMA, P667, DOI 10.1109/FG.2018.00105
   Le Ngo AC, 2018, IEEE INT CONF AUTOMA, P650, DOI 10.1109/FG.2018.00102
   Lei L, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2237, DOI 10.1145/3394171.3413714
   Li QY, 2019, MULTIMED TOOLS APPL, V78, P29307, DOI 10.1007/s11042-018-6857-9
   Li RL, 2022, IEEE J BIOMED HEALTH, V26, P4996, DOI 10.1109/JBHI.2022.3185587
   Liong ST, 2018, J SIGNAL PROCESS SYS, V90, P601, DOI 10.1007/s11265-017-1276-0
   Liong ST, 2018, SIGNAL PROCESS-IMAGE, V62, P82, DOI 10.1016/j.image.2017.11.006
   Mustageem, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8122133
   Mustaqeem, 2021, APPL SOFT COMPUT, V102, DOI 10.1016/j.asoc.2021.107101
   Mustaqeem, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114177
   Mustaqeem, 2020, IEEE ACCESS, V8, P79861, DOI 10.1109/ACCESS.2020.2990405
   Nie X, 2021, NEUROCOMPUTING, V427, P13, DOI 10.1016/j.neucom.2020.10.082
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Oh TH, 2018, LECT NOTES COMPUT SC, V11208, P663, DOI 10.1007/978-3-030-01225-0_39
   Peng M, 2019, INT CONF AFFECT, DOI [10.1109/ACII.2019.8925525, 10.1109/acii.2019.8925525]
   Peng M, 2018, IEEE INT CONF AUTOMA, P657, DOI 10.1109/FG.2018.00103
   Peng Wenshu., 2019, IEEE INT CONF AUTOMA, P1, DOI [DOI 10.1109/FG.2019.8756541, DOI 10.1109/fg.2019.8756541]
   Reddy SPT, 2019, IEEE IJCNN
   Shreve M, 2013, AUTOMATIC MACRO MICR
   Sun B, 2022, IEEE T AFFECT COMPUT, V13, P1037, DOI 10.1109/TAFFC.2020.2986962
   Wadhwa Neal, 2013, ACM Transactions on Graphics, V32, DOI 10.1145/2461912.2461966
   Wang CY, 2020, NEUROCOMPUTING, V410, P354, DOI 10.1016/j.neucom.2020.06.005
   Wang F, 2018, IEEE SIGNAL PROC LET, V25, P926, DOI 10.1109/LSP.2018.2822810
   Wang L, 2019, SIGNAL PROCESS-IMAGE, V78, P246, DOI 10.1016/j.image.2019.07.011
   Wei MT, 2022, INT CONF ACOUST SPEE, P2420, DOI 10.1109/ICASSP43922.2022.9747232
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu HY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185561
   Xiao-Bin Huang, 2015, 2015 Asia-Pacific Microwave Conference (APMC). Proceedings, P1, DOI 10.1109/APMC.2015.7413025
   Xie HX, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2871, DOI 10.1145/3394171.3414012
   Xie SY, 2019, PATTERN RECOGN, V92, P177, DOI 10.1016/j.patcog.2019.03.019
   Xu F, 2017, IEEE T AFFECT COMPUT, V8, P254, DOI 10.1109/TAFFC.2016.2518162
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yap MH, 2018, IEEE INT CONF AUTOMA, P675, DOI 10.1109/FG.2018.00106
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao SR, 2021, NEUROCOMPUTING, V448, P276, DOI 10.1016/j.neucom.2021.03.058
   Zhi RC, 2019, IEICE T INF SYST, VE102D, P1054, DOI 10.1587/transinf.2018EDP7153
   Zhu CL, 2017, FRONT BEHAV NEUROSCI, V11, DOI 10.3389/fnbeh.2017.00199
NR 51
TC 0
Z9 0
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11593
EP 11612
DI 10.1007/s11042-023-16033-1
EA JUN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001022136100002
DA 2024-07-18
ER

PT J
AU Zhang, YB
   Xu, TX
   Tian, K
AF Zhang, YuBo
   Xu, Tongxiang
   Tian, Kang
TI PSPAN:pyramid spatially weighted pixel attention network for image
   dehazing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image dehazing; The feature pyramid; Multi feature extraction; Spatially
   weighted pixel attention
AB Haze-free images are the prerequisites for many high-level visual tasks, and thus image dehazing has become an active topic in computer vision. However, the existing image dehazing algorithms are limited in face of unevenly distributed haze and dense haze in some scenes. In this paper, we propose a Pyramid Spatially Weighted Pixel Attention Network (PSPAN) for single image dehazing by leveraging complementarity among different levels of features in a pyramid manner with unique attention methods. The proposed PSPAN utilizes the feature pyramid as the core network and consists of three modules: an efficient Multi-scale Feature Extraction Attention module, a pyramid Spatially Weighted Pixel Attention module, and an image reconstruction module. Specifically, PSPAN preprocesses hazy images first before acquiring abundant shared features. After that, these features are sent to different branches. To effectively fuse useful information from these different branches and obtain better-dehazed results, we propose an efficient feature aggregation attention module. Finally, the image reconstruction module is used to restore clear images. Meanwhile, a loss function that combines a mean square error loss part, an edge loss part, and a perceptual loss part is employed in PSPAN which can better preserve image details. Experimental results demonstrate that the proposed PSPAN achieves superior performance to other existing state-of-the-art algorithms in terms of accuracy and visual effect.
C1 [Zhang, YuBo; Xu, Tongxiang; Tian, Kang] Northeast Petr Univ, Sch Elect Informat Engn, Daqing 163319, Peoples R China.
C3 Northeast Petroleum University
RP Xu, TX (corresponding author), Northeast Petr Univ, Sch Elect Informat Engn, Daqing 163319, Peoples R China.
EM zhangyubo@nepu.edu.cn; xutongxiang521@gmail.com; tiankangg@163.com
RI zhang, yubo/I-4301-2016
OI xu, tongxiang/0000-0001-7571-257X
FU Heilongjiang Province Natural Science Foundation [LH2022F005]; Northeast
   Petroleum University Guiding Innovation Fund [15071202202]
FX AcknowledgementsThis work is partially supported by Heilongjiang
   Province Natural Science Foundation (LH2022F005) and Northeast Petroleum
   University Guiding Innovation Fund (No.15071202202).
CR Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Dong Y, 2020, AAAI CONF ARTIF INTE, V34, P10729
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Gilbarg D., 1983, ELLIPTIC PARTIAL DIF, DOI 10.1007/978-3-642-61798-0
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hong M, 2020, PROC CVPR IEEE, P3459, DOI 10.1109/CVPR42600.2020.00352
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kansal I, 2020, MULTIMED TOOLS APPL, V79, P12069, DOI 10.1007/s11042-019-08240-6
   Kansal I, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500546
   Kansal I, 2018, J MOD OPTIC, V65, P2103, DOI 10.1080/09500340.2018.1499976
   Lan YW, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-19132-5
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li CY, 2018, IEEE ACCESS, V6, P24877, DOI 10.1109/ACCESS.2018.2818882
   Lu HM, 2016, MULTIMED TOOLS APPL, V75, P17081, DOI 10.1007/s11042-015-2977-7
   Mei KF, 2019, LECT NOTES COMPUT SC, V11361, P203, DOI 10.1007/978-3-030-20887-5_13
   Mnih V, 2014, ADV NEUR IN, V27
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Simonyan K, 2014, ARXIV, DOI DOI 10.48550/ARXIV:1409.1556
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang H, 2017, ARXIV, DOI DOI 10.48550/ARXIV.1710.00279
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang XQ, 2021, NEUROCOMPUTING, V453, P865, DOI 10.1016/j.neucom.2020.04.147
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 36
TC 1
Z9 1
U1 5
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11367
EP 11385
DI 10.1007/s11042-023-15844-6
EA JUN 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001018078900007
DA 2024-07-18
ER

PT J
AU Shang, ZY
   Wang, PH
   Li, XF
AF Shang, Ziyang
   Wang, Penghai
   Li, Xinfu
TI Micro-expression recognition based on differential feature fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Micro-expression recognition; CapsuleNet; SE-ResNet50; Deep learning
   feature; Differential feature fusion
ID LBP-TOP; DYNAMICS; SYSTEM
AB Micro-expressions (MEs) are natural facial mechanisms with short duration and subtle changes. It has attracted much attention in the real world due to its accuracy and uncontrollability of mental expression. With the development of computer vision, micro-expression Recognition (MER) methods have been continuously proposed and improved by scholars. However, the existing MER methods still have some deficiencies in processing Spatio-temporal redundant information and feature extraction. This paper proposes an MER network based on Differential Feature Fusion (DFF) method to solve this problem. First, inputs the onset frame and apex frame of the face, divide each image into small blocks, and uses part of the SE-ResNet50 model for feature extraction. Second, the Spatio-Temporal information of the features is extracted by using a DFF module composed of a differential feature module, CapsuleNet, and a Fully Connected (FC) layer. Finally, inputs the feature vector to the FC module for classification. This study is based on the Leave One Subject Out (LOSO) cross-validation protocol and uses the CASMEII dataset. Experiments and comparisons show the effectiveness of the algorithm.
C1 [Shang, Ziyang; Wang, Penghai; Li, Xinfu] Hebei Univ, Sch Cyber Secur & Comp, Baoding, Hebei, Peoples R China.
C3 Hebei University
RP Li, XF (corresponding author), Hebei Univ, Sch Cyber Secur & Comp, Baoding, Hebei, Peoples R China.
EM shangziyang@stumail.hbu.edu.cn; wph@stumail.hbu.edu.cn; mc_lxf@126.com
RI Wang, Penghai/HGD-1854-2022; Li, Xinfu/AAL-4461-2021
OI Wang, Penghai/0000-0002-6187-4858; 
FU Key Project of the Science and Technology Research Program in University
   of Hebei Province of China [ZD2017209]; Natural Science Foundation of
   Hebei Province of China [F2019201329]
FX AcknowledgementsThis work is supported by the Key Project of the Science
   and Technology Research Program in University of Hebei Province of China
   (Grant No. ZD2017209), the Natural Science Foundation of Hebei Province
   of China (Grant No. F2019201329).
CR Ngo ACL, 2017, IEEE T AFFECT COMPUT, V8, P396, DOI 10.1109/TAFFC.2016.2523996
   Bai MJ, 2020, COMPANION PUBLICATON OF THE 2020 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION (ICMI '20 COMPANION), P7, DOI 10.1145/3395035.3425248
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Cheng G, 2021, IEEE GEOSCI REMOTE S, V18, P431, DOI 10.1109/LGRS.2020.2975541
   EKMAN P, 1969, PSYCHIATR, V32, P88, DOI 10.1080/00332747.1969.11023575
   Frank MG, 1997, J PERS SOC PSYCHOL, V72, P1429, DOI 10.1037/0022-3514.72.6.1429
   Han JW, 2022, IEEE T PATTERN ANAL, V44, P579, DOI 10.1109/TPAMI.2019.2933510
   He JC, 2017, PATTERN RECOGN, V66, P44, DOI 10.1016/j.patcog.2016.11.029
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2000, ADV NEUR IN, V12, P463
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang XH, 2019, IEEE T AFFECT COMPUT, V10, P32, DOI 10.1109/TAFFC.2017.2713359
   Huang XH, 2016, NEUROCOMPUTING, V175, P564, DOI 10.1016/j.neucom.2015.10.096
   Jovanovic MR, 2014, PHYS FLUIDS, V26, DOI 10.1063/1.4863670
   Khor HQ, 2018, IEEE INT CONF AUTOMA, P667, DOI 10.1109/FG.2018.00105
   Kosiorek AR, 2019, ADV NEUR IN, V32
   Lei L, 2021, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW53098.2021.00173
   Li J, 2019, PATTERN ANAL APPL, V22, P1331, DOI 10.1007/s10044-018-0757-5
   Li JT, 2020, IEEE INT CONF AUTOMA, P777, DOI 10.1109/FG47880.2020.00035
   Li k, 2019, INT C NEURAL INFORM
   Li XB, 2018, IEEE T AFFECT COMPUT, V9, P563, DOI 10.1109/TAFFC.2017.2667642
   Li XB, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553717
   Liong ST, 2018, SIGNAL PROCESS-IMAGE, V62, P82, DOI 10.1016/j.image.2017.11.006
   Liu N, 2020, INT CONF INTEL INFOR, P236, DOI 10.1109/ICIIBMS50712.2020.9336412
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Masi I, 2018, SIBGRAPI, P471, DOI 10.1109/SIBGRAPI.2018.00067
   Merghani W, 2018, IEEE INT CONF AUTOMA, P662, DOI 10.1109/FG.2018.00104
   Peng M, 2018, IEEE INT CONF AUTOMA, P657, DOI 10.1109/FG.2018.00103
   Peng Wenshu., 2019, IEEE INT CONF AUTOMA, P1, DOI [DOI 10.1109/FG.2019.8756541, DOI 10.1109/fg.2019.8756541]
   Pfister T, 2011, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2011.6126401
   POLIKOVSKY S., 2009, 3 INT C IM CRIM DET, P1, DOI [10.1049/ic.2009.0244, DOI 10.1049/IC.2009.0244]
   Polikovsky S, 2013, IEICE T INF SYST, VE96D, P81, DOI 10.1587/transinf.E96.D.81
   Russell TA, 2006, BRIT J CLIN PSYCHOL, V45, P579, DOI 10.1348/014466505X90866
   Sabour S, 2017, ARXIV
   See J, 2019, IEEE INT CONF AUTOMA, P647
   Soh XR, 2017, ASIAPAC SIGN INFO PR, P309, DOI 10.1109/APSIPA.2017.8282041
   Su Y, 2022, INT J OCCUP SAF ERGO, V28, P1533, DOI 10.1080/10803548.2021.1904652
   Takalkar MA, 2020, MULTIMEDIA SYST, V26, P535, DOI 10.1007/s00530-020-00663-8
   Takalkar MA, 2017, 2017 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING - TECHNIQUES AND APPLICATIONS (DICTA), P688
   Van Quang N., 2019, IEEE INT CONF AUTOMA, DOI [10.1109/FG.2019.8756544, DOI 10.1109/fg.2019.8756544]
   Wang CY, 2020, NEUROCOMPUTING, V410, P354, DOI 10.1016/j.neucom.2020.06.005
   Wang SJ, 2021, IEEE T IMAGE PROCESS, V30, P3956, DOI 10.1109/TIP.2021.3064258
   Wang SJ, 2015, IEEE T IMAGE PROCESS, V24, P6034, DOI 10.1109/TIP.2015.2496314
   Wang SJ, 2015, LECT NOTES COMPUT SC, V8925, P325, DOI 10.1007/978-3-319-16178-5_23
   Wang Y, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/7799100
   Wang YD, 2015, LECT NOTES COMPUT SC, V9003, P525, DOI 10.1007/978-3-319-16865-4_34
   Wang YD, 2020, IEEE WORLD CONGR SER, P266, DOI [10.1109/SERVICES48979.2020.00059, 10.1007/978-3-030-37731-1_22]
   Wang YF, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124812
   Wu C, 2021, IEEJ T ELECTR ELECTR, V16, P98, DOI 10.1002/tee.23272
   Xia ZQ, 2020, IEEE T MULTIMEDIA, V22, P626, DOI 10.1109/TMM.2019.2931351
   Xiao-Bin Huang, 2015, 2015 Asia-Pacific Microwave Conference (APMC). Proceedings, P1, DOI 10.1109/APMC.2015.7413025
   Xie HX, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2871, DOI 10.1145/3394171.3414012
   Xu F, 2017, IEEE T AFFECT COMPUT, V8, P254, DOI 10.1109/TAFFC.2016.2518162
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yang B, 2021, MULTIMED TOOLS APPL, V80, P16125, DOI 10.1007/s11042-019-07896-4
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhou L, 2021, ARXIV
   Zhou L, 2021, IMAGE VISION COMPUT, V105, DOI 10.1016/j.imavis.2020.104043
   Zhou ZH, 2011, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.2011.5995345
   Zong Y, 2018, IEEE T MULTIMEDIA, V20, P3160, DOI 10.1109/TMM.2018.2820321
NR 60
TC 0
Z9 0
U1 8
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11111
EP 11126
DI 10.1007/s11042-023-15626-0
EA JUN 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001021028900011
DA 2024-07-18
ER

PT J
AU Tiwari, U
   Vollala, S
   Ramasubramanian, N
   Begum, S
AF Tiwari, Utkarsh
   Vollala, Satyanarayana
   Ramasubramanian, N.
   Begum, Shameedha
TI Improving the performance of authentication protocols using efficient
   modular multi exponential technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security and privacy; Authentication; Hardware security; Public-key
   cryptography; NIST; Modular multi exponentiation; Montgomery
   multiplication; Side-channel attacks
AB Efficient and secure authentication of the user in today's world, where most of the multimedia data is shared over the public network, is essential. The verification step of the multi-user applications like OTT(over-the-top) platforms has modular-multi exponentiation(MME) as its vital operation. This article presents an efficient MME which uses Multiplication and Forwarding technique (MFW). MFW technique efficiently computes the MME and also avoids side-channel attacks (SCAs) using the integrated multi-level confusion mechanisms. Mostly, SCAs are secured by hardware means only. This article presents a novel algorithmic way of counteracting the SCAs. The proposed technique is more efficient (efficiency 1.109) than the state-of-the-art. Another advantage of the designed MFW MME technique is that it is directly implementable in hardware. We have implemented the techniques on FPGA using Vivado 21.2 on Virtex-7 evaluation boards. The compatibility has also been verified using Cadence for ASIC.
C1 [Tiwari, Utkarsh; Vollala, Satyanarayana] IIIT Naya Raipur, Comp Sci Engn, Sect 24, Atal Nagar 493661, Chhattisgarh, India.
   [Ramasubramanian, N.; Begum, Shameedha] Nit Trichy, Comp Sci Engn, Tanjore Main Rd,NH67, Tiruchirappalli 620015, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Vollala, S (corresponding author), IIIT Naya Raipur, Comp Sci Engn, Sect 24, Atal Nagar 493661, Chhattisgarh, India.
EM utkarsh@iiitnr.edu.in; satya@iiitnr.edu.in; nrs@nitt.edu;
   shameedha@nitt.edu
OI Tiwari, Utkarsh/0000-0003-3360-6538; Vollala,
   Satyanarayana/0000-0003-3727-7081
CR Anderson D.R., 2007, Model based inference in the life sciences: a primer on evidence
   Attias V, 2020, ARXIV
   Attias V, 2023, J CRYPTOGR ENG, V13, P57, DOI 10.1007/s13389-022-00287-w
   Boneh D, 2018, LECT NOTES COMPUT SC, V10991, P757, DOI 10.1007/978-3-319-96884-1_25
   Borges F, 2017, APPL MATH COMPUT, V292, P406, DOI 10.1016/j.amc.2016.07.036
   Gornik A, 2015, IEEE T COMPUT AID D, V34, P1308, DOI 10.1109/TCAD.2015.2423274
   Harn L, 1998, ELECTRON LETT, V34, P870, DOI 10.1049/el:19980620
   Nist A, 1692, FED REGISTER, V56, p42,980
   PEKMESTZI KZ, 1989, IEE PROC-E, V136, P70, DOI 10.1049/ip-e.1989.0010
   Ramezanpour K, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P176, DOI [10.1109/HOST45689.2020.9300266, 10.1109/host45689.2020.9300266]
   Saha S, 2020, IEEE T INF FOREN SEC, V15, P1905, DOI 10.1109/TIFS.2019.2952262
   Sayakkara A, 2019, DIGIT INVEST, V29, P43, DOI 10.1016/j.diin.2019.03.002
   Schnorr C. P., 1991, Journal of Cryptology, V4, P161, DOI 10.1007/BF00196725
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shao ZH, 2001, COMPUT NETW, V37, P383, DOI 10.1016/S1389-1286(01)00220-1
   Sun Y, 2016, LECT NOTES COMPUT SC, V9722, P310, DOI 10.1007/978-3-319-40253-6_19
   Wei LX, 2018, 34TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2018), P393, DOI 10.1145/3274694.3274696
   Xia F, 2017, COMPUTER, V50, P34, DOI 10.1109/MC.2017.3001246
NR 18
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11061
EP 11076
DI 10.1007/s11042-023-15726-x
EA JUN 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001021028900005
DA 2024-07-18
ER

PT J
AU Zhou, JY
   Xu, T
   Guo, WT
   Zhao, WS
   Cai, L
AF Zhou, Jiyong
   Xu, Tao
   Guo, Wantao
   Zhao, Weishuo
   Cai, Lei
TI Underwater occluded object recognition with two-stage image
   reconstruction strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater occluded object; Image reconstruction; Object recognition;
   Two-stage
ID NEURAL-NETWORK; DEEP
AB The complex underwater environment, such as foreign object occlusion and dim light, causes the feature of underwater objects to be seriously missing. And ripple causes deformation of objects, which greatly increases the difficulty of feature extraction. Existing object recognition models cannot accurately recognize obscured objects due to incomplete features of underwater objects. To solve the above problems, this paper proposes an underwater occlusion object recognition method based on two-stage image reconstruction strategy. Firstly, the salient feature extraction network and the relevant environment feature extraction network are constructed to extract the salient feature and the relevant environment feature respectively. Secondly, the two-stage image reconstruction model with gradient penalty constraints is constructed to obtain finely reconstructed images. Finally, the object recognition with feature adaptive boundary regression is constructed to realize the recognition of finely reconstructed images. To prove the effectiveness of the proposed algorithm, it is compared with the existing object recognition model in datasets with different levels of complexity. The average recognition accuracy of the proposed model is 78.36%, and the recognition rate is improved by 14.16% compared to the original image. Experiments show that the object recognition algorithm proposed in this paper is effective and superior to the existing algorithms.
C1 [Zhou, Jiyong] Henan Inst Sci & Technol, Sch Mechatron Elect Engn, Xinxiang 453003, Henan, Peoples R China.
   [Xu, Tao; Cai, Lei] Henan Inst Sci & Technol, Sch Artificial Intelligence, Xinxiang 453003, Henan, Peoples R China.
   [Guo, Wantao] China North Standardizat Ctr, Standardizat Lab 1, Beijing 100089, Peoples R China.
   [Zhao, Weishuo] Henan Inst Sci & Technol, Sch Informat Engn, Xinxiang 453003, Henan, Peoples R China.
C3 Henan Institute of Science & Technology; Henan Institute of Science &
   Technology; Henan Institute of Science & Technology
RP Xu, T (corresponding author), Henan Inst Sci & Technol, Sch Artificial Intelligence, Xinxiang 453003, Henan, Peoples R China.
EM xutao1206@qq.com
OI Xu, Tao/0000-0002-8821-4550
FU Major Science and Technology Project in Henan Province [221100110500];
   Science and Technology Project of Henan Province [232102320338,
   222102210157]
FX AcknowledgementsThis work was supported by the Major Science and
   Technology Project in Henan Province [221100110500], Science and
   Technology Project of Henan Province [232102320338, 222102210157].
CR Arora S., 2019, 36th International Conference on Machine Learning, P9904
   Ben Tamou A, 2021, APPL INTELL, V51, P5809, DOI 10.1007/s10489-020-02155-8
   Berman D, 2021, IEEE T PATTERN ANAL, V43, P2822, DOI 10.1109/TPAMI.2020.2977624
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Cai L, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/4193625
   Cai L, 2020, IEEE ACCESS, V8, P39273, DOI 10.1109/ACCESS.2020.2976121
   Chen Z, 2018, LECT NOTES COMPUT SC, V11212, P74, DOI 10.1007/978-3-030-01237-3_5
   Dai B, 2017, ADV NEUR IN, V30
   Garcia R., 2017, Computer Vision in Vehicle Technology, P75, DOI [10.1002/9781118868065.ch4, DOI 10.1002/9781118868065.CH4]
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Guo YL, 2016, OPT EXPRESS, V24, P13101, DOI 10.1364/OE.24.013101
   He YH, 2019, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2019.00300
   Huo GY, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103570
   Ji DX, 2018, INT J ADV ROBOT SYST, V15, DOI 10.1177/1729881418808991
   Jia S, 2018, MULTIMED TOOLS APPL, V77, P14859, DOI 10.1007/s11042-017-5070-6
   Kamalyan AG., 2002, J SHELLFISH RES, V21, P201
   Knausgård KM, 2022, APPL INTELL, V52, P6988, DOI 10.1007/s10489-020-02154-9
   Langis KD, 2021, ANAL DEEP OBJECT DET
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li MD, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010313
   Li TY, 2020, OPT ENG, V59, DOI 10.1117/1.OE.59.8.083102
   Liu HY, 2019, IEEE I CONF COMP VIS, P4169, DOI 10.1109/ICCV.2019.00427
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Pfeffer A, 2019, IEEE SOFTWARE, V36, P91, DOI 10.1109/MS.2018.2886815
   Raihan AJ, 2019, IET IMAGE PROCESS, V13, P1587, DOI 10.1049/iet-ipr.2019.0117
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shi TC, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.4.043013
   Tianning Y, 2021, COMPUTER VISION PATT
   Tuncel E., 2002, ACM MULTIMEDIA, P543
   Wang DD, 2021, BIOSYST ENG, V210, P271, DOI 10.1016/j.biosystemseng.2021.08.015
   Wang JQ, 2019, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2019.00308
   Wang XH, 2019, J OCEAN U CHINA, V18, P376, DOI 10.1007/s11802-019-3858-x
   Wang YJ, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P994
   Wynn RB, 2014, MAR GEOL, V352, P451, DOI 10.1016/j.margeo.2014.03.012
   Yamashita A, 2007, IEEE INT CONF ROBOT, P4570, DOI 10.1109/ROBOT.2007.364183
   Yang S., 2019, IEEE T CYBERNETICS, P1, DOI [DOI 10.1109/TCYB.2019.2906497, DOI 10.1177/0898264319844088, DOI 10.1109/icce.2019.8662071]
   Yang S, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.591018
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P4398, DOI [10.1109/TNNLS.2021.3057070, 10.4018/IJCINI.20211001.oa2]
   Yang X, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116225
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Yu X, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1852, DOI 10.1109/ICASSP.2018.8461549
   Zhang Y, 2021, COMPUT GRAPH FORUM, V40, P179, DOI 10.1111/cgf.142624
NR 45
TC 1
Z9 1
U1 10
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11127
EP 11146
DI 10.1007/s11042-023-15658-6
EA JUN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001021028900015
DA 2024-07-18
ER

PT J
AU Moghaddam, AH
   Momtazi, S
AF Moghaddam, Arya Hadizadeh
   Momtazi, Saeedeh
TI A semantic modular framework for events topic modeling in social media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event detection; Natural language processing; Topic modeling; Deep
   learning
ID TWITTER; TIME; LDA
AB The advancement of social media contributes to the growing amount of content they share frequently. This framework provides a sophisticated place for people to report various real-life events. Detecting these events with the help of natural language processing has received researchers' attention, and various algorithms have been developed for this goal. In this paper, we propose a Semantic Modular Model (SMM) consisting of 5 different modules, namely Distributional Denoising Autoencoder, Incremental Clustering, Semantic Denoising, Defragmentation, and Ranking and Processing. The proposed model aims to (1) cluster various documents and ignore the documents that might not contribute to the identification of events, (2) identify more important and descriptive keywords. Compared to the state-of-the-art methods, the results show that the proposed model has a higher performance in identifying events with lower ranks and extracting keywords for more important events in three English Twitter datasets: FACup, SuperTuesday, and USElection. The proposed method outperformed the best-reported results in the mean keyword-precision metric by 7.9%.
C1 [Moghaddam, Arya Hadizadeh; Momtazi, Saeedeh] Amirkabir Univ Technol, Comp Engn Dept, Hafez Ave,Valiasr Sq, Tehran, Iran.
C3 Amirkabir University of Technology
RP Momtazi, S (corresponding author), Amirkabir Univ Technol, Comp Engn Dept, Hafez Ave,Valiasr Sq, Tehran, Iran.
EM aryahadizadehm@aut.ac.ir; momtazi@aut.ac.ir
OI Momtazi, Saeedeh/0000-0002-8110-1342; Hadizadeh Moghaddam,
   Arya/0000-0003-0935-4756
CR Adedoyin-Olowe M, 2016, EXPERT SYST APPL, V55, P351, DOI 10.1016/j.eswa.2016.02.028
   Afyouni I, 2022, INFORM FUSION, V79, P279, DOI 10.1016/j.inffus.2021.10.013
   Agrawal S, 2015, PROCEDIA COMPUT SCI, V60, P708, DOI 10.1016/j.procs.2015.08.220
   Ali F, 2021, ACCIDENT ANAL PREV, V151, DOI 10.1016/j.aap.2021.105973
   [Anonymous], 2000, P TOP DET TRACK WORK
   Asgari-Chenaghlu M, 2021, CHAOS SOLITON FRACT, V151, DOI 10.1016/j.chaos.2021.111274
   Baynazarov R., 2019, Artificial Intelligence and Natural Language Communications in Computer and Information Science, P139
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Devlin J., 2018, BERT PRE TRAINING DE
   Eken S, 2019, IEEE ACCESS, V7, P97996, DOI 10.1109/ACCESS.2019.2930339
   Ekinci E, 2020, TURK J ELECTR ENG CO, V28, P2244, DOI 10.3906/elk-1912-62
   Ekinci E, 2020, J INF SCI, V46, P406, DOI 10.1177/0165551519845854
   Elbagoury A, 2015, P INT AAAI C WEB SOC
   Fedoryszak M, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2774, DOI 10.1145/3292500.3330689
   Hasan M, 2019, INFORM PROCESS MANAG, V56, P1146, DOI 10.1016/j.ipm.2018.03.001
   Hettiarachchi H, 2022, MACH LEARN, V111, P49, DOI 10.1007/s10994-021-05988-7
   Huang LD, 2021, J SAF SCI RESIL, V2, P11, DOI 10.1016/j.jnlssr.2020.11.003
   Jagannatha Abhyuday N, 2016, Proc Conf, V2016, P473
   Kwon D, 2019, CLUSTER COMPUT, V22, P949, DOI 10.1007/s10586-017-1117-8
   Li Z., 2011, P 19 ACM INT C MULTI, P133
   Li ZF, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2807705
   Aiello LM, 2013, IEEE T MULTIMEDIA, V15, P1268, DOI 10.1109/TMM.2013.2265080
   Martínez-Rojas M, 2018, INT J INFORM MANAGE, V43, P196, DOI 10.1016/j.ijinfomgt.2018.07.008
   Mazoyer B, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6220
   Moghaddam Arya Hadizadeh, 2023, Information Design Journal, P33, DOI 10.1075/idj.22015.had
   Momtazi S, 2018, INFORM PROCESS MANAG, V54, P380, DOI 10.1016/j.ipm.2018.01.001
   Momtazi S, 2016, J INF SCI, V42, P437, DOI 10.1177/0165551515594723
   Momtazi S, 2013, WIRES DATA MIN KNOWL, V3, P346, DOI 10.1002/widm.1102
   Nugent T, 2017, IEEE INT CONF BIG DA, P3750, DOI 10.1109/BigData.2017.8258374
   Nur'aini K, 2015, INT C ADV COMP SCI I, P123, DOI 10.1109/ICACSIS.2015.7415168
   OConnor B., 2010, P INT AAAI C WEBLOGS, P1
   Özgüven YM, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03328-0
   Peng Hao, 2022, IEEE T PATTERN ANAL
   Petrovic Sasa, 2010, Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, P181
   Phuvipadawat S., 2010, Proceedings of the 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology - Workshops (WI-IAT 2010), P120, DOI 10.1109/WI-IAT.2010.205
   Prabandari RD, 2017, AIP CONF PROC, V1862, DOI 10.1063/1.4991248
   Reimers N, 2019, ARXIV
   Repp O, 2018, J STAT MANAG SYST, V21, P695, DOI 10.1080/09720510.2018.1486273
   Saeed Z, 2019, EXPERT SYST APPL, V136, P115, DOI 10.1016/j.eswa.2019.06.005
   Sehgal A, 2019, 2019 THIRD IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC 2019), P596, DOI 10.1109/IRC.2019.00121
   Vongkusolkit J, 2021, ANN GIS, V27, P5, DOI 10.1080/19475683.2020.1817146
   Weiler A, 2016, INFORM SYST, V62, P207, DOI 10.1016/j.is.2016.01.003
   Weng J., 2011, P INT AAAI C WEB SOC, VVolume 5
   Xia XJ, 2018, PATTERN RECOGN, V81, P1, DOI 10.1016/j.patcog.2018.03.025
   Xu XW, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P824, DOI 10.1145/1281192.1281280
NR 45
TC 0
Z9 0
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10755
EP 10778
DI 10.1007/s11042-023-15745-8
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019903000018
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Damasceno, EF
   da Silva, AP
   Barbosa Jr, JDB
AF Damasceno, Eduardo Filgueiras
   da Silva, Armando Paulo
   Barbosa Jr, Jose Dias
TI A serious game-based platform for measuring treatment adherence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Childhood Cancer; Treatment Adherence; Serious Game; Educational Game
   Application; Health Informatics; Software Development
ID CANCER; CHILDREN; CARE
AB Cancer is a devastating disease that remains one of the leading causes of death worldwide. Children are particularly vulnerable due to their difficulty expressing symptoms and articulating their emotional experiences. The psychological barriers accompanying a cancer diagnosis can affect a child's adherence to treatment, which is essential for recovery. However, managing these barriers can be challenging for psychologists and psychotherapists. This study proposes a tool to aid psychologists and psychotherapists in observing and measuring treatment adherence in children's oncology. Unlike traditional observation methods, this tool uses games to engage children more effectively. The GOO platform captures data from game partners to identify hidden and recurring behaviors that may impact treatment adherence. This information helps psychologists and psychotherapists develop more efficient and effective interventions. The GOO platform was tested by ten psychotherapy professionals working with children undergoing oncological treatment, and the results were promising. The platform allowed the researchers to identify emotional fragilities in children using digital games as a plat- form for data analysis. This knowledge can be used to provide more personalized and effective care for these patients. Overall, this study demonstrates the potential of using technology to improve the care of children with cancer. By engaging children with games and using digital tools to capture their emotional responses, psychologists and psychotherapists can gain valuable insights into these patients' challenges and develop better ways to support them. This paper addresses ten professionals in psychotherapy with children in oncological treatment who tested the platform's usability. Thus, based on this technological acceptance research, it is possible to identify the emotional fragilities of children using the digital game as a platform for data analysis and thus act more efficiently in caring for the emotions of these patients.
C1 [Damasceno, Eduardo Filgueiras; da Silva, Armando Paulo] Univ Tecnol Fed Parana, Cornelio Procopio, Brazil.
   [Barbosa Jr, Jose Dias] Fed Inst Educ Sci & Technol Parana, Paranavai, Brazil.
C3 Universidade Tecnologica Federal do Parana
RP Damasceno, EF (corresponding author), Univ Tecnol Fed Parana, Cornelio Procopio, Brazil.
EM damasceno@utfpr.edu.br; armando@utfpr.edu.br; jose.dias@ifpr.edu.br
RI Damasceno, Eduardo Filgueiras/AAE-3462-2020
OI Damasceno, Eduardo Filgueiras/0000-0002-6246-1246; Paulo da Silva,
   Armando/0000-0001-8186-051X
CR Altay N, 2017, EUR J ONCOL NURS, V28, P1, DOI 10.1016/j.ejon.2017.02.007
   Barzelloni M. L., 2017, Annals of Oncology, V28, pvi84, DOI [10.1093/annonc/mdx434.010, DOI 10.1093/ANNONC/MDX434.010]
   Bettini A, 2019, SUPPORT CARE CANCER, V27, P4479, DOI 10.1007/s00520-019-04755-8
   Brega, 2019, BRAZILIAN S COMPUTER, V30, P1704, DOI [10.5753/cbie.sbie.2019.704, DOI 10.5753/CBIE.SBIE.2019.704]
   Chai Carmen WE., 2020, MALAYSIAN J PAEDIAT, V26, P6, DOI [10.51407/mjpch.v26i2.101, DOI 10.51407/MJPCH.V26I2.101]
   Chung G.K., 2015, Serious Games Analytics, P59
   Da Rosa RCLF, 2020, J HLTH INFORM, V12, P3
   Dowding D, 2018, APPL CLIN INFORM, V9, P511, DOI 10.1055/s-0038-1666842
   Drachen A., 2013, GAME DATA MINING GAM, P205, DOI DOI 10.1007/978-1-4471-4769-5_12
   Driscoll C, 2019, INT J CULTURAL STUD, V22, P383, DOI 10.1177/1367877918784606
   Fuchslocher A, 2011, ENTERTAIN COMPUT, V2, P97, DOI 10.1016/j.entcom.2010.12.001
   Hoffmann S, 2018, ECANCERMEDICALSCIENC, V12, DOI 10.3332/ecancer.2018.850
   Kato PM, 2008, PEDIATRICS, V122, pE305, DOI 10.1542/peds.2007-3134
   Lapointe L, 2014, HEALTH TECHNOL-GER, V4, P43, DOI 10.1007/s12553-013-0068-1
   Linder LA, 2018, ONCOL NURS FORUM, V45, P290, DOI 10.1188/18.ONF.290-300
   Loh C. S., 2015, Serious Games Analytics: Methodologies for Performance Measurement, Assessment, and Improvement, P3, DOI [DOI 10.1007/978-3-319-05834-41, DOI 10.1007/978-3-319-05834-4, 10.1007/978-3-319-05834-4_1, DOI 10.1007/978-3-319-05834-4_1]
   Majumdar D, 2013, GAMES HEALTH J, V2, P280, DOI 10.1089/g4h.2013.0045
   McCann L, 2019, JMIR CANCER, V5, DOI 10.2196/12071
   Moran K., 2019, Usability Testing 101
   Moreno PI, 2018, CANCER-AM CANCER SOC, V124, P1770, DOI 10.1002/cncr.31263
   Oliemat E, 2018, CHILD YOUTH SERV REV, V88, P591, DOI 10.1016/j.childyouth.2018.03.028
   Partridge AH, 2002, JNCI-J NATL CANCER I, V94, P652
   Rollins J, 2020, J CHILD FAM STUD, V29, P2218, DOI 10.1007/s10826-020-01738-w
   Rubin J., 2008, Handbook of Usability Testing: how to Plan, Design, and Conduct Effective Tests, V2nd ed.
   Ruland CM, 2008, J BIOMED INFORM, V41, P624, DOI 10.1016/j.jbi.2007.10.004
   Siepmann M, 2008, ENCY PUBLIC HLTH, P515, DOI 10.1007/978-1-4020-5614-7_1359
   Stoyanov SR, 2015, JMIR MHEALTH UHEALTH, V3, DOI 10.2196/mhealth.3422
   Tan AJQ, 2017, INT CONF GAMES VIRTU, P187, DOI 10.1109/VS-GAMES.2017.8056599
   Thorlacius L, 2007, NORDICOM REV, V28, P1
   Tong T, 2016, JMIR SERIOUS GAMES, V4, pE7, DOI 10.2196/games.5006
   Villani D, 2018, GAMES HEALTH J, V7, P85, DOI 10.1089/g4h.2017.0108
   Vingen D, 2020, INFORMATICS-BASEL, V7, DOI 10.3390/informatics7040042
   Vitorino LM, 2018, PSYCHO-ONCOLOGY, V27, P1900, DOI 10.1002/pon.4739
   Wattanasoontorn V, 2013, ENTERTAIN COMPUT, V4, P231, DOI 10.1016/j.entcom.2013.09.002
   Wilson AS, 2015, GAMIFICATION CONCEPT, P1312, DOI [10.4018/978-1-4666-6206-3.ch005, DOI 10.4018/978-1-4666-6206-3.CH005]
NR 35
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 12017
EP 12033
DI 10.1007/s11042-023-15988-5
EA JUN 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019116600011
DA 2024-07-18
ER

PT J
AU Liu, LQ
   Wang, XH
   Huang, XF
   Bao, QF
   Li, XS
   Wang, YR
AF Liu, Linqi
   Wang, Xiuhui
   Huang, Xiaofang
   Bao, Qifu
   Li, Xuesheng
   Wang, Yaru
TI Abnormal operation recognition based on a spatiotemporal residual
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Abnormal operation recognition; Residual network; Artificial
   intelligence
AB Artificial intelligence technologies have been widely used in many scenarios, however, the detection of abnormal actions in most industrial applications still depends on the recognition of static behaviors, such as smoking and phone calling.In order to improve the automatic identification of abnormal operation in industrial process control, we propose a new solution based on artificial intelligence model. First, a context-sensitive template segmentation mechanism is designed, which uses an operation point template to segment sub-samples to improve the stability and practicability of the sequential operation evaluation. Second, a new spatiotemporal residual network (STRN) is proposed to identify different operation actions. Furthermore, a process evaluation algorithm is described, which analyzes the prediction results from the STRN network to identify the early warning of dangerous operations. The experimental results show that the proposed method has clear advantages over other abnormal operation recognition methods.
C1 [Liu, Linqi; Wang, Xiuhui] China Jiliang Univ, Coll Informat Engn, Hangzhou 310018, Peoples R China.
   [Huang, Xiaofang] China Jiliang Univ, Coll Art & Commun, Hangzhou 310018, Peoples R China.
   [Bao, Qifu; Li, Xuesheng; Wang, Yaru] Key Lab Safety Engn & Technol Res Zhejiang Prov, Hangzhou 310027, Peoples R China.
C3 China Jiliang University; China Jiliang University
RP Wang, XH (corresponding author), China Jiliang Univ, Coll Informat Engn, Hangzhou 310018, Peoples R China.
EM wangxiuhui@cjlu.edu.cn
OI Wang, Xiuhui/0000-0003-1773-9760
FU Key Ramp;D project of Zhejiang Province, China [2021C03151]; Natural
   Science Foundation of Zhejiang Province [LY20F020018]
FX This research was funded by the Key R & amp;D project of Zhejiang
   Province, China, grant number No. 2021C03151 and the Natural Science
   Foundation of Zhejiang Province, grant number No.LY20F020018.
CR Andrienko N, 2020, IEEE T INTELL TRANSP, V21, P3196, DOI 10.1109/TITS.2019.2924796
   Bi X, 2022, SENSORS-BASEL, P22
   Bolle RM, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P15, DOI 10.1109/AUTOID.2005.48
   Bondalapati A, 2021, J AMBIENT INTELL HUM, V12
   Delibasoglu I, 2023, SIGNAL IMAGE VIDEO P, V17, P2415, DOI 10.1007/s11760-022-02458-y
   Ding YX, 2019, INT CONF MACH LEARN, P547, DOI 10.1109/icmlc48188.2019.8949298
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hossain MA, 2020, IEEE ACCESS, V8, P186756, DOI 10.1109/ACCESS.2020.3030108
   Kang M, 2019, 2019 3RD INTERNATIONAL CONFERENCE ON IMAGING, SIGNAL PROCESSING AND COMMUNICATION (ICISPC), P101, DOI [10.1109/icispc.2019.8935825, 10.1109/ICISPC.2019.8935825]
   Mingrui Zhang, 2020, 2020 IEEE 9th Joint International Information Technology and Artificial Intelligence Conference (ITAIC), P1983, DOI 10.1109/ITAIC49862.2020.9338958
   Mohanty Subrata Kumar, 2019, 2019 International Conference on Information Technology (ICIT), P420, DOI 10.1109/ICIT48102.2019.00080
   Ou XF, 2019, IEEE ACCESS, V7, P108152, DOI 10.1109/ACCESS.2019.2931922
   Pang YT, 2018, IEEE GLOB CONF CONSU, P802, DOI 10.1109/GCCE.2018.8574512
   Premachandra C, 2019, IEEE INT C NETW SENS, P369, DOI [10.1109/icnsc.2019.8743319, 10.1109/ICNSC.2019.8743319]
   Qi W, 2022, J COMPUT METHODS SCI, V22, P2149, DOI 10.3233/JCM-226342
   Rui Li, 2020, 2020 International Conference on Artificial Intelligence and Education (ICAIE), P103, DOI 10.1109/ICAIE50891.2020.00031
   Seo JM, 2018, 2018 IEEE FIRST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE), P172, DOI 10.1109/AIKE.2018.00040
   Shahbaz A, 2020, PROC IEEE INT SYMP, P67, DOI [10.1109/ISIE45063.2020.9152237, 10.1109/isie45063.2020.9152237]
   Virupakshappa K, 2019, IEEE INT ULTRA SYM, P647, DOI [10.1109/ultsym.2019.8926078, 10.1109/ULTSYM.2019.8926078]
   Wan W, 2019, PROCEEDINGS OF 2019 IEEE 8TH JOINT INTERNATIONAL INFORMATION TECHNOLOGY AND ARTIFICIAL INTELLIGENCE CONFERENCE (ITAIC 2019), P906, DOI [10.1109/itaic.2019.8785810, 10.1109/ITAIC.2019.8785810]
   Wang FY, 2019, CHIN CONTR CONF, P7774, DOI [10.23919/chicc.2019.8865491, 10.23919/ChiCC.2019.8865491]
   Wu YW, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P982, DOI 10.1109/ICIVC.2018.8492904
   YiWen Zhang, 2020, 2020 International Conference on Artificial Intelligence and Education (ICAIE), P93, DOI 10.1109/ICAIE50891.2020.00029
   Zhao XY, 2022, NEUROCOMPUTING, V503, P28, DOI 10.1016/j.neucom.2022.06.104
   Zhen HL, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P705, DOI 10.1109/ITNEC48623.2020.9084913
   Zhou WQ, 2019, PROCEEDINGS OF 2019 IEEE 8TH JOINT INTERNATIONAL INFORMATION TECHNOLOGY AND ARTIFICIAL INTELLIGENCE CONFERENCE (ITAIC 2019), P741, DOI [10.1109/itaic.2019.8785803, 10.1109/ITAIC.2019.8785803]
   Zhou ZG, 2018, CHIN CONT DECIS CONF, P5520, DOI 10.1109/CCDC.2018.8408093
   Zhu HD, 2020, IEEE ACCESS, V8, P29729, DOI 10.1109/ACCESS.2020.2972562
   Zhu Y., 2021, IEEE Power and Energy Society General Meeting, P1
NR 30
TC 0
Z9 0
U1 5
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 19
PY 2023
DI 10.1007/s11042-023-15875-z
EA JUN 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K2RY1
UT WOS:001014975000007
DA 2024-07-18
ER

PT J
AU Luo, YY
   Wu, R
   Liu, JF
   Tang, XL
AF Luo, Yuanyi
   Wu, Rui
   Liu, Jiafeng
   Tang, Xianglong
TI Attention fusion network for multimodal sentiment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal sentiment analysis; Attention mechanism; Multimodal fusion
AB The main research problem in multimodal sentiment analysis is to model inter-modality dynamics. However, most of the current work cannot consider enough in this aspect. In this study, we propose a multimodal fusion network MSA-AFN, which considers both multimodal relationships and differences in modal contributions to the task. Specifically, in the feature extraction process, we consider not only the relationship between audio and text, but also the contribution of temporal features to the task. In the process of multimodal fusion, based on the soft attention mechanism, the feature representation of each modality is weighted and connected according to their contribution to the task. We evaluate our proposed approach on the Chinese multimodal sentiment analysis dataset: CH-SIMS. Results show that our model achieves better results than comparison models. Moreover, the performance of some baselines has been improved by 0.28% to 9.5% after adding the component of our network.
C1 [Luo, Yuanyi; Wu, Rui; Liu, Jiafeng; Tang, Xianglong] Harbin Inst Technol, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology
RP Wu, R (corresponding author), Harbin Inst Technol, Harbin 150001, Peoples R China.
EM simple@hit.edu.cn
RI YY, Luo/AAX-2606-2021
FU National Natural Science Foundation of China [61672190]
FX AcknowledgementsThis research is supported by the National Natural
   Science Foundation of China (No: 61672190)
CR Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Cambria E, 2017, COMPUT LINGUIST, ppp17
   Ghosal D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3454
   Huddar MG, 2021, MULTIMED TOOLS APPL, V80, P13059, DOI 10.1007/s11042-020-10285-x
   Ling HF, 2020, MULTIMED TOOLS APPL, V79, P5595, DOI 10.1007/s11042-019-08422-2
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Liu ZY, 2021, IEEE INTELL SYST, V36, P122, DOI 10.1109/MIS.2020.3042253
   Liu Z, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2247
   Long X, 2018, AAAI CONF ARTIF INTE, P7202
   Sahay S, 2018, FIRST GRAND CHALLENGE AND WORKSHOP ON HUMAN MULTIMODAL LANGUAGE (CHALLENGE-HML), P20
   Tembhurne JV, 2021, MULTIMED TOOLS APPL, V80, P6871, DOI 10.1007/s11042-020-10037-x
   Tsai YHH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6558, DOI 10.18653/v1/p19-1656
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Ye JJ, 2022, KNOWL-BASED SYST, V258, DOI 10.1016/j.knosys.2022.110021
   You QZ, 2015, AAAI CONF ARTIF INTE, P381
   Yu WM, 2021, AAAI CONF ARTIF INTE, V35, P10790
   Yu WM, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3718
   Zadeh A., 2017, P 2017 C EMP METH NA, P1103, DOI 10.18653/v1/D17-1115
   Zadeh A, 2018, AAAI CONF ARTIF INTE, P5634
NR 20
TC 1
Z9 1
U1 27
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8207
EP 8217
DI 10.1007/s11042-023-15762-7
EA JUN 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001010465000003
DA 2024-07-18
ER

PT J
AU Singh, KK
   Makhania, J
   Mahapatra, M
AF Singh, Krishna Kumar
   Makhania, Jeroz
   Mahapatra, Madhumita
TI Impact of ratings of content on OTT platforms and prediction of its
   success rate
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE OTT; Analytics; Random forest; Regression; KNN
ID LOGISTIC-REGRESSION
AB The world of media and entertainment is evolving significantly. The popularity of newly released movies or TV shows significantly depends on public opinion. The general audience and critics have different ways of expressing their views, and one such method is rating a film or a TV show on platforms such as IMDb or Rotten Tomatoes. With the inception of Over-The-Top (OTT) platforms and their releasing new content on a routine basis, they must garner good ratings from the public to retain their audience. This study uses random forest, k-nearest neighbors, and logistic regression models to predict the IMDb and Rotten Tomatoes ratings. The outcome of these ratings can also be used to predict further the amount a film might gross. Linear Regression predicts the inflation-adjusted amount grossed by a particular film based on its IMDb ratings. After implementing algorithms, KNN, Random Forest, and logistic Regression have 89%, 91%, and 86% accuracy. The main results reveal that the random forest model gives the best accuracy for predicting IMDb and Rotten Tomatoes ratings. Linear Regression also shows promising results for predicting the inflation-adjusted amount grossed by a particular film. With the help of this methodology, OTT platforms will be able to see the impact of content on the viewers using this result for various means like designing new content, increasing profit by showing the most demanding content, etc. Finally, this study offers some clues to OTT platforms about how users might react to new content released. The results can also give an economic advantage to OTT platforms.
C1 [Singh, Krishna Kumar; Makhania, Jeroz] Symbiosis Ctr Informat Technol, Pune, India.
   [Mahapatra, Madhumita] Delhi Technol Campus, Greater Noida, UP, India.
C3 Symbiosis International University; Symbiosis Centre for Information
   Technology (SCIT)
RP Singh, KK (corresponding author), Symbiosis Ctr Informat Technol, Pune, India.
EM krishnakumar@scit.edu
RI Singh, Krishna Kumar/N-9355-2013
OI Singh, Krishna Kumar/0000-0003-3849-5945
CR Abu Amra Ihsan A., 2017, 2017 8th International Conference on Information Technology (ICIT). Proceedings, P909, DOI 10.1109/ICITECH.2017.8079967
   [Anonymous], 1998, J MARK CHENNALS
   [Anonymous], 2004, J UNDERGRAD RES
   Bagkar P, 2021, ICONIC RES ENG J, V4, P121
   Bayramli I, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00558-0
   Chen X, 2017, RNA BIOL, V14, P952, DOI 10.1080/15476286.2017.1312226
   Daniel Demetrios., 2021, Disney Plus: Launch Beyond
   Gururaj Vaishnavi., 2019, International Journal of Applied Engineering Research, V14, P1931
   Havard CT, 2021, FINDINGS SPORT HOSPI
   Huang W, 2022, NATURE PORTFOLIO SCI, V1, P1, DOI [10.1155/2021/6663455, DOI 10.1155/2021/6663455]
   Kouloumpis E., 2011, P INT AAAI C WEB SOC
   Kumar HIK, 2019, INT J INTERACT MULTI, V5, P109, DOI 10.9781/ijimai.2018.12.005
   Lee K, 2022, NPJ COMPUT MATER, V8, DOI 10.1038/s41524-022-00704-y
   Mahapatra M., 2022, OBES MED, V34, DOI [10.1016/j.obmed.2022.100436, DOI 10.1016/J.OBMED.2022.100436]
   Moochhala Q, 2018, FUTURE ONLINE OTT EN, V1, P2
   Mood C, 2010, EUR SOCIOL REV, V26, P67, DOI 10.1093/esr/jcp006
   Nanehkaran FH, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6538
   Park EA, 2017, DIGIT POLICY REGUL G, V19, P21, DOI 10.1108/DPRG-08-2016-0041
   Pritam N, 2019, IEEE ACCESS, V7, P37414, DOI 10.1109/ACCESS.2019.2905133
   Putri DA., 2021, CUSTOMER SATISFACTIO
   Singh KK., 2023, IIMS J MANAG SCI, V14, P9, DOI [10.1177/0976030X221112529, DOI 10.1177/0976030X221112529]
   Singh T, 2016, PROCEDIA COMPUT SCI, V89, P549, DOI 10.1016/j.procs.2016.06.095
   Sperandei S, 2014, BIOCHEM MEDICA, V24, P12, DOI 10.11613/BM.2014.003
   Vadloori KB, 2021, INT J ENG RES TECHNO, V10, P9
   Vimal S, 2020, COMPUT COMMUN, V151, P355, DOI 10.1016/j.comcom.2020.01.018
   Zhang L, 2013, PROCD SOC BEHV, V96, P653, DOI 10.1016/j.sbspro.2013.08.076
NR 26
TC 1
Z9 1
U1 7
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 29
PY 2023
DI 10.1007/s11042-023-15887-9
EA MAY 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H8LP5
UT WOS:000998414300013
DA 2024-07-18
ER

PT J
AU Panjeta, M
   Reddy, A
   Shah, RS
   Shah, JS
AF Panjeta, Manisha
   Reddy, Aryan
   Shah, Rushabh
   Shah, Jash
TI Artificial intelligence enabled COVID-19 detection: techniques,
   challenges and use cases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Artificial intelligence; Deep learning; Covid-19; Machine learning;
   Convolutional neural network
ID LEARNING FRAMEWORK; CLASSIFICATION; DIAGNOSIS; EFFICIENT; NETWORK
AB Deep Learning and Machine Learning are becoming more and more popular as their algorithms get progressively better, and their use is expected to have the large effect on improving the health care system. Also, the pandemic was a chance to show how adding AI to healthcare infrastructure could help, since infrastructures around the world are overworked and falling apart. These new technologies can be used to fight COVID-19 because they are flexible and can be changed. Based on these facts, we looked at how the ML and DL-based models can be used to deal with the COVID-19 pandemic problem and what the pros and cons of each are. This paper gives a full look at the different ways to find COVID-19. We looked at the COVID-19 issues in a systematic way and then rated the methods and techniques for finding it based on their availability, ease of use, accuracy, and cost. We have also shown in pictures how well each of the detection techniques works. We did a comparison of different detection models based on the above factors. This helps researchers understand the different methods and the pros and cons of using them as the basis for their research. In the last part, we talk about the open challenges and research questions that come with putting these techniques together with other detection methods.
C1 [Panjeta, Manisha] Thapar Inst Engn Technol, Dept Comp Sci & Engn, Patiala 147004, Punjab, India.
   [Reddy, Aryan; Shah, Rushabh; Shah, Jash] NMIMS Univ, Comp Sci Dept, Mumbai, India.
C3 Thapar Institute of Engineering & Technology; SVKM's NMIMS (Deemed to be
   University)
RP Panjeta, M (corresponding author), Thapar Inst Engn Technol, Dept Comp Sci & Engn, Patiala 147004, Punjab, India.
EM manisha.panjeta@thapar.edu; aryan61101@gmail.com; rushabhns75@gmail.com;
   jashshah269@gmail.com
CR Akhtar Asma, 2021, International Journal of Technology, Innovation and Management (IJTIM), V1, P65, DOI DOI 10.54489/IJTIM.V1I2.22
   Alazab Moutaz, 2020, International Journal of Computer Information Systems and Industrial Management Applications, P168
   Alves MA, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104335
   Awal MA, 2021, IEEE ACCESS, V9, P10263, DOI 10.1109/ACCESS.2021.3050852
   Awasthi N, 2021, IEEE T ULTRASON FERR, V68, P2023, DOI 10.1109/TUFFC.2021.3068190
   Basu A, 2022, EXPERT SYST APPL, V193, DOI 10.1016/j.eswa.2021.116377
   Bhowal P, 2021, IEEE J BIOMED HEALTH, V25, P4328, DOI 10.1109/JBHI.2021.3111415
   Brinati D, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-01597-4
   Cabitza F, 2021, CLIN CHEM LAB MED, V59, P421, DOI 10.1515/cclm-2020-1294
   Chandra TB, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113909
   Ghosh S, 2021, IEEE OPEN J SIGNAL P, V2, P248, DOI 10.1109/OJSP.2021.3075913
   Giri B, 2021, ANAL BIOANAL CHEM, V413, P35, DOI 10.1007/s00216-020-02889-x
   Guo GY, 2021, IEEE J BIOMED HEALTH, V25, P1347, DOI 10.1109/JBHI.2021.3060035
   Ismael AM, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.114054
   Jain G, 2020, BIOCYBERN BIOMED ENG, V40, P1391, DOI 10.1016/j.bbe.2020.08.008
   Jamshidi MB, 2020, IEEE ACCESS, V8, P109581, DOI 10.1109/ACCESS.2020.3001973
   Karmore S, 2020, IEEE SENS J
   Karthikeyan A, 2021, FRONT PUBLIC HEALTH, P9
   Kukar M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-90265-9
   Lee Y, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-05069-2
   Li YX, 2020, IEEE J BIOMED HEALTH, V24, P2787, DOI 10.1109/JBHI.2020.3018181
   Minaee S, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101794
   Mondal AK, 2022, IEEE J TRANSL ENG HE, V10, DOI 10.1109/JTEHM.2021.3134096
   Nayak J, 2021, APPL INTELL, V51, P2908, DOI 10.1007/s10489-020-02102-7
   Ohata EF, 2021, IEEE-CAA J AUTOMATIC, V8, P239, DOI 10.1109/JAS.2020.1003393
   Oyelade ON, 2021, IEEE ACCESS, V9, P77905, DOI 10.1109/ACCESS.2021.3083516
   Panetta K, 2021, IEEE J BIOMED HEALTH, V25, P1852, DOI 10.1109/JBHI.2021.3069798
   Panwar H, 2020, CHAOS SOLITON FRACT, V138, DOI 10.1016/j.chaos.2020.109944
   Pathak Y, 2021, IEEE ACM T COMPUT BI, V18, P1234, DOI 10.1109/TCBB.2020.3009859
   Rasheed J, 2021, INTERDISCIP SCI, V13, P103, DOI 10.1007/s12539-020-00403-6
   Rikan SB, 2022, BIOMED SIGNAL PROCES, V72, DOI 10.1016/j.bspc.2021.103263
   Roberts M, 2021, NAT MACH INTELL, V3, P199, DOI 10.1038/s42256-021-00307-0
   Shah H, 2022, MULTIMEDIA SYST, V28, P1189, DOI 10.1007/s00530-021-00818-1
   Skibinska J, 2021, IEEE ACCESS, V9, P119476, DOI 10.1109/ACCESS.2021.3106255
   Srivastava M, 2021, SCI TOTAL ENVIRON, V754, DOI 10.1016/j.scitotenv.2020.142363
   Tabik S, 2020, IEEE J BIOMED HEALTH, V24, P3595, DOI 10.1109/JBHI.2020.3037127
   Udugama B, 2020, ACS NANO, V14, P3822, DOI 10.1021/acsnano.0c02624
   Wu YH, 2021, IEEE T IMAGE PROCESS, V30, P3113, DOI 10.1109/TIP.2021.3058783
   Yan QS, 2021, IEEE T BIG DATA, V7, P13, DOI 10.1109/TBDATA.2021.3056564
   Zhang WS, 2021, IEEE INTERNET THINGS, V8, P15884, DOI 10.1109/JIOT.2021.3056185
NR 40
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 27
PY 2023
DI 10.1007/s11042-023-15247-7
EA MAY 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H4OZ4
UT WOS:000995787000005
PM 37362659
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Wu, D
   Wang, ZY
   Zhao, WC
AF Wu, Di
   Wang, Ziyu
   Zhao, Weichao
TI XLNet-CNN-GRU dual-channel aspect-level review text sentiment
   classification method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Aspect-level sentiment classification; Review text; Deep learning;
   Attention mechanism; Stack embedding
AB Aiming at the problem that the feature information of review text is not fully captured and the aspect information extraction ability is poor in the traditional aspect-level sentiment classification model, an XLNet-CNN-GRU dual-channel aspect-level review text sentiment classification method is proposed. The static and dynamic word vectors generated by Glove and the XLNet model are stacked and embedded. It can carry more semantic information and effectively solve the problem of polysemy. In order to extract global and local features of the review text, the word vectors generated by stacking are input to the GRU and CNN dual-channel of the fused attention mechanism. The experimental results show that XLNET-CNN-GRU on the Restaurant, Laptop and ACL 14 Twitter datasets of SemEVAL-2014, compared with TD-LSTM, AE-LSTM, ATAE-LSTM, ATBL-MHMN, and ON-LSTM-SA, the accuracy of the model is improved by 2.04%, 2.3%, and 2.33%, the F1 value is improved by 2.18%, 1.94%, and 2.77%. Higher accuracy and F1 value are obtained, and the effect of aspect-level sentiment classification is improved.
C1 [Wu, Di; Wang, Ziyu; Zhao, Weichao] Hebei Univ Engn, Sch Informat & Elect Engn, 19 Taiji Rd, Handan 056038, Hebei, Peoples R China.
C3 Hebei University of Engineering
RP Wu, D (corresponding author), Hebei Univ Engn, Sch Informat & Elect Engn, 19 Taiji Rd, Handan 056038, Hebei, Peoples R China.
EM wudiwudi@hebeu.edu.cn; 741479872@qq.com; 707534641@qq.com
RI Zhao, Weichao/JBS-0073-2023
FU National Natural Science Foundation of China [62101174]; Nature Science
   Foundation of Hebei Province [F2020402003, F2021402005]
FX AcknowledgmentsThis work was supported in part by the National Natural
   Science Foundation of China under Grant 62101174, the Nature Science
   Foundation of Hebei Province (F2020402003, F2021402005).
CR Chen YZ, 2021, APPL INTELL, V51, P4287, DOI 10.1007/s10489-020-02069-5
   Dai J., 2021, J PHYS C SERIES, V1827
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   [何丽 He Li], 2021, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V34, P157
   Li B, 2021, J PHYS C SERIES
   Liao WZ, 2022, ARTIF INTELL REV, V55, P3727, DOI 10.1007/s10462-021-10080-6
   Liu J, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11041528
   Liu ZY, 2021, IEEE INTELL SYST, V36, P122, DOI 10.1109/MIS.2020.3042253
   [卢天兰 Lu Tianlan], 2021, [计算机应用研究, Application Research of Computers], V38, P1409
   Pang GY, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/5534615
   Sweidan AH, 2021, IEEE ACCESS, V9, P90828, DOI 10.1109/ACCESS.2021.3091394
   Tang C, 2021, IEEE T MULTIMEDIA, V23, P624, DOI 10.1109/TMM.2020.2985541
   Tang C, 2022, IEEE T PATTERN ANAL, V44, P955, DOI 10.1109/TPAMI.2020.3014629
   Wahid JA, 2021, 2021 INT C COMP ENG
   [杨春霞 Yang Chunxia], 2022, [小型微型计算机系统, Journal of Chinese Computer Systems], V43, P1432
   Yang Z, 2021, J INTELL FUZZY SYST, V41, P867, DOI 10.3233/JIFS-202747
   Yang ZL, 2020, Arxiv, DOI arXiv:1906.08237
   [张忠林 Zhang Zhonglin], 2020, [小型微型计算机系统, Journal of Chinese Computer Systems], V41, P1839
   ZHENG Cheng, 2020, Computer Engineering and Applications, V56, P176
   Zhou LX, 2022, J INTELL FUZZY SYST, V42, P1445, DOI 10.3233/JIFS-210632
   Zhou ZY, 2021, NEUROCOMPUTING, V441, P214, DOI 10.1016/j.neucom.2021.02.041
   Zhu XF, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115712
   Zhu YL, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8858717
NR 23
TC 2
Z9 2
U1 15
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 26
PY 2023
DI 10.1007/s11042-023-15026-4
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3VP4
UT WOS:000995280400005
DA 2024-07-18
ER

PT J
AU Vu, V
AF Vu, Van-Hieu
TI Content-based image retrieval with fuzzy clustering for feature vector
   normalization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Content based image retrieval; Relevant feedback; Normalized feature
ID SCALE; COLOR; REPRESENTATION; PERFORMANCE
AB In content-based image retrieval using combine multiple low-level features or deep learning features, data imbalance after normalization often occurs. Usually, the distance function is usually like the L1 or L2 norm. When the feature vector value is considered as a cluster to compute the similarity measure between feature vectors, it leads to significant deviations in the retrieval results. To ensure the data is distributed balance, we propose to use data clustering based on fuzzy clustering and then perform Gaussian normalization (feature normalization on fuzzy clustering- GFFC). Experimental results over the benchmark Corel10, Oxford5k, Paris6k datasets demonstrate the effectiveness of this propose method.
C1 [Vu, Van-Hieu] Vietnam Acad Sci & Technol, Inst Informat Technol, 18 Hoang Quoc Viet, Hanoi 123080, Vietnam.
C3 Vietnam Academy of Science & Technology (VAST)
RP Vu, V (corresponding author), Vietnam Acad Sci & Technol, Inst Informat Technol, 18 Hoang Quoc Viet, Hanoi 123080, Vietnam.
EM vvhieu@ioit.ac.vn
CR Aggarwal AK, 2015, IMAGE BASED METHODS, DOI [10.15662/IJAREEIE.2015.0410023, DOI 10.15662/IJAREEIE.2015.0410023]
   Alzu'bi A, 2016, INT J MULTIMED INF R, V5, P237, DOI 10.1007/s13735-016-0109-4
   Anandh A, 2020, MEAS CONTROL-UK, V53, P3, DOI 10.1177/0020294018824122
   [Anonymous], 2013, PATTERN RECOGN, DOI DOI 10.1007/978-1-4757-0450-1
   Arora K, 2018, APPROACHES IMAGE DAT
   Bengio Y, 2014, Arxiv, DOI [arXiv:1206.5538, 10.48550/arXiv.1206.5538, DOI 10.48550/ARXIV.1206.5538]
   Bezdek J. C., 1973, Journal of Cybernetics, V3, P58, DOI 10.1080/01969727308546047
   Cao B, 2020, EUROPEAN C COMPUTER
   Chu K, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/1461459
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Daisy MMH, 2013, PROCEEDINGS OF 2013 INTERNATIONAL CONFERENCE ON CIRCUITS, POWER AND COMPUTING TECHNOLOGIES (ICCPCT 2013), P912, DOI 10.1109/ICCPCT.2013.6528956
   Desai P., 2021, SN Comput Sci, V2, P170, DOI [10.1007/s42979-021-00529-4, DOI 10.1007/S42979-021-00529-4]
   Giveki D, 2017, OPTIK, V131, P242, DOI 10.1016/j.ijleo.2016.11.046
   Guo JM, 2013, J VIS COMMUN IMAGE R, V24, P1360, DOI 10.1016/j.jvcir.2013.09.005
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jayadevappa D, 2015, COMP STUDY CONTENT B
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2013, GLOBAL COORDINATE AD
   Kumar A, 2014, IMPROVING GPS POSITI, DOI [10.11188/seisankenkyu.66.101, DOI 10.11188/SEISANKENKYU.66.101]
   Kumar A, 2018, Arxiv, DOI [arXiv:1812.04215, 10.48550/arXiv.1812.04215, DOI 10.48550/ARXIV.1812.04215]
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Liu H, 2016, IMAGE RETRIEVAL ALGO, DOI [10.2991/aiie-16.2016.64, DOI 10.2991/AIIE-16.2016.64]
   Liu S, 2019, COMPUT ASSIST SURG, V24, P72, DOI 10.1080/24699322.2018.1560087
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu X, 2017, HIERARCHICAL IMAGE R, DOI [10.1007/978-3-642-39402-7_33, DOI 10.1007/978-3-642-39402-7_33]
   Maji Subhadip, 2021, ACM/IMS Transactions on Data Science, V2, DOI 10.1145/3470568
   Misra S., 2018, INT J APPL ENG RES, V13, P5562, DOI [10.37622/IJAER/13.7.2018.5562-5564, DOI 10.37622/IJAER/13.7.2018.5562-5564]
   Mohamed Ouhda, 2019, Lecture Notes in Real-Time Intelligent Systems. Advances in Intelligent Systems and Computing (AISC 756), P463, DOI 10.1007/978-3-319-91337-7_41
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Philbin J, 2008, PROC CVPR IEEE, P2285
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Radenovic F, 2018, PROC CVPR IEEE, P5706, DOI 10.1109/CVPR.2018.00598
   Rana SP, 2019, J VIS COMMUN IMAGE R, V58, P205, DOI 10.1016/j.jvcir.2018.11.015
   Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saritha RR, 2019, CLUSTER COMPUT, V22, pS4187, DOI 10.1007/s10586-018-1731-0
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Stephane M, 1999, WAVELET TOUR SIGNAL, DOI [10.1016/B978-0-12-374370-1.X0001-8, DOI 10.1016/B978-0-12-374370-1.X0001-8]
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   VAN-HIEU V, 2016, CONTENT BASED IMAGE, DOI [10.15625/1813-9663/32/2/8611, DOI 10.15625/1813-9663/32/2/8611]
   Venkataramanan S., 2021, ARXIV
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang X, 2019, PROC CVPR IEEE, P5017, DOI 10.1109/CVPR.2019.00516
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
NR 53
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 24
PY 2023
DI 10.1007/s11042-023-15215-1
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H2CU8
UT WOS:000994104400003
DA 2024-07-18
ER

PT J
AU Poonkodi, S
   Kanchana, M
AF Poonkodi, S.
   Kanchana, M.
TI Lung cancer segmentation from CT scan images using modified mayfly
   optimization and particle swarm optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lung cancer; Automatic segmentation; Lung computed tomography; Ensemble
   Deep Convolutional Neural Network; Modified mayfly optimization
ID NETWORK; MODEL
AB The development of a computer-aided detection system is a critical component of clinical decision-making As the death rate grows, cancer has become a major concern for both men and women. The radiologists need to accurately pinpoint the region of the lung tumor to offer proper radiation therapy for lung cancer patients. Due to low-image quality, higher computational difficulties, and other reasons, the existing lung cancer segmentation methods failed to provide better segmentation accuracy. To overcome these challenges, we proposed a novel approach for lung tumor segmentation. Initially, the input CT scan image contrast level is increased using histogram equalization (HE) during pre-processing. The adaptive bilateral filter (ABF) provides enhanced CT scan images for de-noising. Next to pre-processing, we introduced an ensemble deep convolutional neural network (EDNN) based on Modified mayfly optimization and modified particle swarm optimization ((MPSO)-P-2) algorithm for the segmentation of lung cancer from the pre-processed CT images. The proposed model accurately segments the lung disease tumor without manual supervision and the need for fully annotated data. Finally, the measures like dice similarity score (DSS), precision, sensitivity, dice loss, and generalized dice loss analyze the performance of the proposed model. Based on the experimental investigations, the proposed EDCNN- (MPSO)-P-2 algorithm demonstrated superior performance in terms of lung tumor segmentation than other existing techniques. The proposed model has average accuracy, sensitivity, and precision scores of 97%, 98%, and 98%, respectively. The proposed model's DSS value is 98.6%, which is relatively higher than the existing approaches.
C1 [Poonkodi, S.; Kanchana, M.] SRM Inst Sci & Technol, Sch Comp, Dept Comp Technol, Kattankulathur, India.
C3 SRM Institute of Science & Technology Chennai
RP Poonkodi, S (corresponding author), SRM Inst Sci & Technol, Sch Comp, Dept Comp Technol, Kattankulathur, India.
EM rkpoonkodi@gmail.com
RI S, Poonkodi/HZI-0265-2023
OI S, Poonkodi/0000-0002-8989-0155
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Ait Skourt B, 2018, PROCEDIA COMPUT SCI, V127, P109, DOI 10.1016/j.procs.2018.01.104
   Akter O, 2021, APPL INTELL, V51, P3391, DOI 10.1007/s10489-020-02046-y
   Albahli S, 2020, IEEE ACCESS, V8, P198403, DOI 10.1109/ACCESS.2020.3035345
   Anita R., 2018, International Journal of Mobile Network Design and Innovation, V8, P7
   Aristophanous M, 2007, MED PHYS, V34, P4223, DOI 10.1118/1.2791035
   Baek S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-53461-2
   Chen K, 2021, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.1061/(ASCE)EY.1943-7897.0000804
   Chen W, 2019, IEEE ACCESS, V7, P75591, DOI 10.1109/ACCESS.2019.2921434
   Chen XD, 2021, J RADIAT RES APPL SC, V14, P396, DOI 10.1080/16878507.2021.1981753
   Gordienko Y, 2018, P INT C COMP SCI ENG, P638
   Jia HZ, 2018, NEUROCOMPUTING, V275, P1358, DOI 10.1016/j.neucom.2017.09.084
   Kamal Uday, 2020, Thoracic Image Analysis. Second International Workshop, TIA 2020. Held in Conjunction with MICCAI 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12502), P36, DOI 10.1007/978-3-030-62469-9_4
   Kavitha P., 2019, A novel hybrid segmentation method with particle swarm optimization and fuzzy c-mean based on partitioning the image for detecting lung cancer
   Li Z, 2020, IEEE J BIOMED HEALTH
   Liu X, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.717039
   Manoharan D. S., 2020, J. Artif. Intell., V2, P201, DOI [10.36548/jaicn.2020.4.002, DOI 10.36548/JAICN.2020.4.002]
   Mary NAB, 2017, J VIS COMMUN IMAGE R, V49, P225, DOI 10.1016/j.jvcir.2017.09.008
   Men K, 2020, FRONT ONCOL, V10, DOI 10.3389/fonc.2020.00986
   Mukilan K, 2021, MATER TODAY-PROC, V42, P786, DOI 10.1016/j.matpr.2020.11.315
   Muller D., 2020, Automated chest ct image segmentation of covid-19 lung infection based on 3d u-net
   Mutiullah, 2019, MEHRAN UNIV RES J EN, V38, P351, DOI 10.22581/muet1982.1902.10
   Onyema EM, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/5196000
   Onyema EM, 2020, INT J INNOV SCI ENG, V7, P91, DOI DOI 10.1109/TENSYMP50017.2020.9230464
   Shaheen MAM, 2021, INT J ENERG RES, V45, P18754, DOI 10.1002/er.6987
   Sun SH, 2012, IEEE T MED IMAGING, V31, P449, DOI 10.1109/TMI.2011.2171357
   Xu MJ, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-018-0619-9
   Yadav SS, 2019, J BIG DATA-GER, V6, DOI [10.12921/jas.v6i1.14911, 10.1186/s40537-019-0276-2]
   Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015
   Zhang B, 2008, IEEE T IMAGE PROCESS, V17, P664, DOI 10.1109/TIP.2008.919949
NR 30
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 18
PY 2023
DI 10.1007/s11042-023-15688-0
EA MAY 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G9GJ2
UT WOS:000992151600003
DA 2024-07-18
ER

PT J
AU Zhao, WY
   Zhou, D
   Cao, BQ
   Zhang, K
   Chen, JJ
AF Zhao, Wenyu
   Zhou, Dong
   Cao, Buqing
   Zhang, Kai
   Chen, Jinjun
TI Efficient low-rank multi-component fusion with component-specific
   factors in image-recipe retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cross-modal recipe retrieval; Cross-modal food domain retrieval;
   Image-recipe retrieval; Low-rank
ID FOOD; INFORMATION
AB Image-Recipe retrieval is the task of retrieving closely related recipes from a collection given a food image and vice versa. The modality gap between images and recipes makes it a challenging task. Recent studies usually focus on learning consistent image and recipe representations to bridge the semantic gap. Though the existing methods have significantly improved image-recipe retrieval, several challenges still remain: 1) Previous studies usually directly concatenate the textual embeddings of different recipe components to generate recipe presentations. Only simple interactions rather than complex interactions are considered. 2) They commonly focus on textual feature extraction from recipes. The methods to extract image features are relatively simple, and most studies utilize the ResNet-50 model. 3) Apart from the retrieval learning loss (triplet loss, for example), several auxiliary loss functions (such as adversarial loss and reconstruction loss) are commonly used to match the recipe and image representations. To deal with these issues, we introduce a novel Low-rank Multi-component Fusion method with Component-Specific Factors (LMF-CSF) to model the different textual components in a recipe for producing superior textual representations. Furthermore, try to pay some attention to image feature extraction. A visual transformer is used to learn better image representations. Then the enhanced representations from two modalities are directly fed into a triplet loss function for image-recipe retrieval learning. Experimental results conducted on the Recipe1M dataset indicate that our LMF-CSF method can outperform the current state-of-the-art image-recipe retrieval baselines.
C1 [Zhao, Wenyu; Cao, Buqing] Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan, Peoples R China.
   [Zhao, Wenyu; Zhang, Kai; Chen, Jinjun] Swinburne Univ Technol, Dept Comp Technol, Melbourne, Australia.
   [Zhou, Dong] Guangdong Univ Foreign Studies, Sch Informat Sci & Technol, Guangzhou, Peoples R China.
C3 Hunan University of Science & Technology; Swinburne University of
   Technology; Guangdong University of Foreign Studies
RP Zhou, D (corresponding author), Guangdong Univ Foreign Studies, Sch Informat Sci & Technol, Guangzhou, Peoples R China.
EM wenyuzhao1993@hotmail.com; dongzhou1979@hotmail.com;
   buqingcao@gmail.com; kevin.zhang0522@gmail.com; jinjun.chen@gmail.com
RI LIU, JIALIN/JXN-8034-2024; yan, yan/JVN-1800-2024; Chen,
   Jin/KBQ-0163-2024; Li, Yuanxiang/KCX-8706-2024; Chen,
   Fang/JZE-4446-2024; lan, lan/JWO-3679-2024; lu, yuan/JZD-0832-2024; Hui,
   Yang/KGL-7041-2024
OI Chen, Jin/0009-0005-5844-635X; 
FU National Natural Science Foundation of China [61876062, 61873316];
   Guangdong Basic and Applied Basic Research Foundation of China
   [2023A1515012718]; Scientific Research Fund of Hunan Provincial
   Education Department [21A0319]; Hunan Provincial Natural Science
   Foundation of China [2022JJ30020, 2021JJ30274]; Hunan Provincial
   Innovation Foundation for Postgraduate [CX20210986]
FX AcknowledgementsThis work was supported in part by the National Natural
   Science Foundation of China (No. 61876062 & 61873316), the Guangdong
   Basic and Applied Basic Research Foundation of China (No.
   2023A1515012718), the Scientific Research Fund of Hunan Provincial
   Education Department (No. 21A0319), the Hunan Provincial Natural Science
   Foundation of China (No. 2022JJ30020 & 2021JJ30274), and Hunan
   Provincial Innovation Foundation for Postgraduate (No. CX20210986).
CR Achlioptas D, 2007, J ACM, V54, DOI 10.1145/1219092.1219097
   Cai MJ, 2023, ACM T INTEL SYST TEC, V14, DOI 10.1145/3582698
   Carvalho M, 2018, ACM/SIGIR PROCEEDINGS 2018, P35, DOI 10.1145/3209978.3210036
   Chen JJ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1771, DOI 10.1145/3123266.3123428
   Chen JJ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P32, DOI 10.1145/2964284.2964315
   Chen Y, 2021, LECT NOTES COMPUT SC, V12859, P253, DOI 10.1007/978-3-030-85899-5_19
   Dosovitskiy Alexey, 2021, 2021 INT C LEARN REP
   Elsweiler D, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P575, DOI 10.1145/3077136.3080826
   Freyne J, 2010, IUI 2010, P321
   Fu H., 2020, P IEEE CVF C COMP VI, P14570
   Guerrero R, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3192, DOI 10.1145/3474085.3475465
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Helmy T, 2015, PROCEDIA COMPUT SCI, V52, P1071, DOI 10.1016/j.procs.2015.05.114
   Hui KF, 2022, KNOWL-BASED SYST, V241, DOI 10.1016/j.knosys.2022.108230
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li J, 2021, PROCEEDINGS OF THE 2021 INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR '21), P173, DOI 10.1145/3460426.3463618
   Li J, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P244, DOI 10.1145/3404835.3462965
   Li L, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P3211, DOI 10.1145/3459637.3482149
   Liu Z, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2247
   Martinel N, 2015, P 2015 IEEE INT C CO, P92
   Martinel N, 2018, IEEE WINT CONF APPL, P567, DOI 10.1109/WACV.2018.00068
   Min WQ, 2018, IEEE T MULTIMEDIA, V20, P950, DOI 10.1109/TMM.2017.2759499
   Min WQ, 2017, IEEE T MULTIMEDIA, V19, P1100, DOI 10.1109/TMM.2016.2639382
   Pham HX, 2021, AAAI CONF ARTIF INTE, V35, P2423
   Salvador A, 2021, PROC CVPR IEEE, P15470, DOI 10.1109/CVPR46437.2021.01522
   Salvador A, 2017, PROC CVPR IEEE, P3068, DOI 10.1109/CVPR.2017.327
   Teng CY, 2012, PROCEEDINGS OF THE 3RD ANNUAL ACM WEB SCIENCE CONFERENCE, 2012, P298
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H, 2019, PROC CVPR IEEE, P3522, DOI 10.1109/CVPR.2019.00364
   Wang ZY, 2021, IET IMAGE PROCESS, V15, P3573, DOI 10.1049/ipr2.12232
   Wang ZY, 2021, IEEE INFOCOM SER, DOI 10.1109/INFOCOM42981.2021.9488756
   Xie ZW, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P2221, DOI 10.1145/3459637.3482270
   Zadeh A., 2017, P 2017 C EMP METH NA, P1103, DOI 10.18653/v1/D17-1115
   Zhang FZ, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P725, DOI 10.1145/2872427.2882995
   Zhao Wenyu, 2024, IEEE Transactions on Artificial Intelligence, P278, DOI 10.1109/TAI.2023.3254518
   Zhu B, 2019, PROC CVPR IEEE, P11469, DOI 10.1109/CVPR.2019.01174
   Zichen Zan, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P117, DOI 10.1145/3372278.3390681
NR 37
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 18
PY 2023
DI 10.1007/s11042-023-15819-7
EA MAY 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G9GJ2
UT WOS:000992151600007
DA 2024-07-18
ER

PT J
AU Zhang, DZ
   Chen, LX
   Li, TY
AF Zhang, Duzhong
   Chen, Lexing
   Li, Taiyong
TI Hyper-chaotic color image encryption based on 3D orthogonal Latin cubes
   and RNA diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hyper-chaotic system; RNA diffusion; Latin cubes; Color image encryption
ID ALGORITHM; SCHEME; SYSTEM; CRYPTANALYSIS; COMBINATION; OPERATION
AB This paper presents a new image encryption algorithm based on hyper-chaotic system, three-dimensional (3D) orthogonal Latin cube transformation and RNA diffusion, which is so-called HCLRNA. The HCLRNA consists of three main steps. First, a 6D hyper-chaotic system is utilized to produce two chaotic matrices for scrambling and diffusion. Second, the plaintext image is transformed into cubes for 3D orthogonal Latin cubes transformation scrambling. Finally, the scrambled pixel values are converted into RNA codons and diffused over two rounds to obtain the cipher image. Experiments and simulations were conducted on images of sizes 256 x 256 x 3 and 512 x 512 x 3 to evaluate key space, key sensitivity, histogram, etc. The results indicate that the proposed HCLRNA satisfies the requirements of different evaluation indicators, which proves that HCLRNA can resist common attacks effectively. Moreover, compared with other studies, the HCLRNA performs significantly better in resisting differential attacks.
C1 [Zhang, Duzhong; Chen, Lexing; Li, Taiyong] Southwestern Univ Finance & Econ, Chengdu 611130, Peoples R China.
C3 Southwestern University of Finance & Economics - China
RP Li, TY (corresponding author), Southwestern Univ Finance & Econ, Chengdu 611130, Peoples R China.
EM litaiyong@gmail.com
RI Li, Taiyong/ABG-3630-2020; Li, Taiyong/ABE-4602-2021
OI Li, Taiyong/0000-0002-1546-8015; Li, Taiyong/0000-0002-1546-8015
FU Ministry of Education of Humanities and Social Science Project
   [19YJAZH047]; Social Practice Research for Teachers of Southwestern
   University of Finance and Economics [2022JSSHSJ11]; Scientific Research
   Fund of Sichuan Provincial Education Department [17ZB0433]
FX AcknowledgementsThis work was supported by the Ministry of Education of
   Humanities and Social Science Project (Grant no. 19YJAZH047), the Social
   Practice Research for Teachers of Southwestern University of Finance and
   Economics (Grant no. 2022JSSHSJ11), and the Scientific Research Fund of
   Sichuan Provincial Education Department (Grant no. 17ZB0433).
CR Abbasi AA, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106465
   Alexan W, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14030443
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Bouslehi H, 2018, MULTIMED TOOLS APPL, V77, P30841, DOI 10.1007/s11042-018-5997-2
   Chai XL, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108041
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Dhiman G, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106560
   Dhiman G, 2021, J AMB INTEL HUM COMP, V12, P8457, DOI 10.1007/s12652-020-02580-0
   Dhiman G, 2019, ENG APPL ARTIF INTEL, V82, P148, DOI 10.1016/j.engappai.2019.03.021
   Gadicha A.B., 2021, MULTIDISCIPLINARY AP, P99, DOI DOI 10.4018/978-1-7998-7160-6.CH005
   Guan MM, 2019, IET IMAGE PROCESS, V13, P1535, DOI 10.1049/iet-ipr.2019.0051
   Hu GQ, 2017, NONLINEAR DYNAM, V88, P1305, DOI 10.1007/s11071-016-3311-2
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Jeng FG, 2015, SIGNAL PROCESS-IMAGE, V34, P45, DOI 10.1016/j.image.2015.03.003
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Kadir A, 2017, OPTIK, V129, P231, DOI 10.1016/j.ijleo.2016.10.036
   Kaur S, 2021, ENG COMPUT-GERMANY, V37, P3167, DOI 10.1007/s00366-020-00989-x
   Koppanati RK, 2021, IEEE CONSUM ELECTR M, V10, P41, DOI 10.1109/MCE.2020.3003127
   Koppanati RK, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P1820, DOI 10.1109/ICCONS.2018.8662840
   Kumar K, 2021, MULTIMED TOOLS APPL, V80, P11079, DOI 10.1007/s11042-020-10157-4
   Li CQ, 2012, NONLINEAR DYNAM, V70, P2383, DOI 10.1007/s11071-012-0626-5
   Li TY, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.108032
   Li TY, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23050510
   Li TY, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.1.013008
   Li TY, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030319
   Li TY, 2017, COMPLEXITY, DOI 10.1155/2017/9010251
   Li YZ, 2015, COMM COM INF SC, V557, P3, DOI 10.1007/978-3-662-48683-2_1
   Li ZF, 2021, PHYS SCRIPTA, V96, DOI 10.1088/1402-4896/abdf0c
   Liu LD, 2019, IEEE ACCESS, V7, P185796, DOI 10.1109/ACCESS.2019.2961164
   Liu LD, 2017, IET SIGNAL PROCESS, V11, P869, DOI 10.1049/iet-spr.2016.0709
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P4363, DOI 10.1007/s11042-015-2479-7
   Luo YL, 2015, COMMUN NONLINEAR SCI, V20, P447, DOI 10.1016/j.cnsns.2014.05.022
   Mahmud M, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105818
   Manupriya P, 2017, 2017 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT), DOI 10.1109/INFOCOMTECH.2017.8340639
   Mohamed HG, 2020, ENTROPY BASEL SWITZE, V22
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Sharma Shikhar, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 703), P51, DOI 10.1007/978-981-10-7895-8_5
   Sneha PS, 2020, J AMB INTEL HUM COMP, V11, P1289, DOI 10.1007/s12652-019-01385-0
   SriI&DDAG niI&DDAG, 2021, GAZI U J SCI
   Toughi S, 2017, SIGNAL PROCESS, V141, P217, DOI 10.1016/j.sigpro.2017.06.010
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wang XY, 2020, OPT LASER TECHNOL, V131, DOI 10.1016/j.optlastec.2020.106366
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Wu Y, 2014, INFORM SCIENCES, V264, P317, DOI 10.1016/j.ins.2013.11.027
   Xian ZH, 2011, ADV MATER RES-SWITZ, V171-172, P299, DOI 10.4028/www.scientific.net/AMR.171-172.299
   Xu M, 2019, INFORM SCIENCES, V478, P1, DOI 10.1016/j.ins.2018.11.010
   Yadollahi M, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102505
   Yang Y, 2021, OPT LASER TECHNOL, V133, DOI 10.1016/j.optlastec.2020.106553
   Zhang DZ, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23030361
   Zhang LH, 2005, CHAOS SOLITON FRACT, V24, P759, DOI 10.1016/j.chaos.2004.09.035
   Zhang YS, 2014, OPTIK, V125, P1562, DOI 10.1016/j.ijleo.2013.09.018
   Zhou J, 2020, OPT LASER TECHNOL, V131, DOI 10.1016/j.optlastec.2020.106437
   Zhou YC, 2015, IEEE T CYBERNETICS, V45, P2001, DOI 10.1109/TCYB.2014.2363168
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 56
TC 0
Z9 0
U1 5
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 17
PY 2023
DI 10.1007/s11042-023-15284-2
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7EQ1
UT WOS:000990751100001
DA 2024-07-18
ER

PT J
AU Sharma, P
   Jindal, R
   Borah, MD
AF Sharma, Pratima
   Jindal, Rajni
   Borah, Malaya Dutta
TI Blockchain-based distributed application for multimedia system using
   Hyperledger Fabric
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Blockchain; Multimedia data; Hyperledger; Energy efficient
AB Over the past few years, blockchain technology has acquired good faith as a modern, secure distributed network in the form of a ledger to conduct and store records of transactions. Blockchain is an evolving technological innovation that can offer solutions to real-world problems of various domains such as cloud computing, the Internet of Things, supply chain, and multimedia. In multimedia, there is an increased requirement for security due to various threats, including replicating digital data without any information loss and manipulating the same without any detection. Moreover, the security of personal multimedia systems is perceived as one of the fundamental human rights concerns. Therefore, this paper proposed a blockchain-based distributed application to secure personal multimedia data such as images, text, videos, etc. The proposed work maintains personal multimedia data's security, privacy, and integrity to meet multimedia security requirements and address the above issues. The blockchain architecture is developed on Hyperledger Fabric, a permissioned blockchain structure using Hyperledger Composer, and stores multimedia data by utilizing SWARM decentralized storage system. The proposed architecture provides a cross-platform, low-cost, and energy-efficient blockchain prototype to manage and secure personal multimedia data. Many experimental tests are conducted to evaluate the performance of the proposed work based on various parameters such as transaction latency, asset latency, throughput, power consumption, upload, and download time for multimedia data. Finally, the proposed work's robustness, feasibility, and reliability are proved by comparing it with the existing works. Results and discussion show that the proposed scheme is more efficient than the existing schemes.
C1 [Sharma, Pratima; Jindal, Rajni] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
   [Borah, Malaya Dutta] Natl Inst Technol Silchar, Dept Comp Sci & Engn, Silchar, Assam, India.
C3 Delhi Technological University; National Institute of Technology (NIT
   System); National Institute of Technology Silchar
RP Sharma, P (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
EM pratimasharma1114@gmail.com
OI Sharma, Pratima/0000-0002-1990-1533
CR Androulaki E, 2018, EUROSYS '18: PROCEEDINGS OF THE THIRTEENTH EUROSYS CONFERENCE, DOI 10.1145/3190508.3190538
   Bui T, 2020, IEEE T MULTIMEDIA, V22, P2858, DOI 10.1109/TMM.2020.2967640
   CHO S, 2019, ICEIC 2019 INT C EL, P1, DOI DOI 10.23919/ELINFOCOM.2019.8706434
   Dhillon V., 2017, Blockchain Enabled Applications, P139, DOI [DOI 10.1007/978-1-4842-3081-7_10, DOI 10.1007/978-1-4842-3081-7]
   Dobre RA, 2018, 2018 INTERNATIONAL CONFERENCE ON CONTROL, ARTIFICIAL INTELLIGENCE, ROBOTICS & OPTIMIZATION (ICCAIRO), P211, DOI 10.1109/ICCAIRO.2018.00042
   Du MX, 2017, IEEE SYS MAN CYBERN, P2567, DOI 10.1109/SMC.2017.8123011
   Ghimire S, 2020, IEEE T MULTIMEDIA, V22, P108, DOI 10.1109/TMM.2019.2925961
   Gupta BB, 2018, MULTIMED TOOLS APPL, V77, P9203, DOI 10.1007/s11042-017-5301-x
   Han DZ, 2022, IEEE T IND INFORM, V18, P3530, DOI 10.1109/TII.2021.3114621
   Jan MA, 2021, J NETW COMPUT APPL, V175, DOI 10.1016/j.jnca.2020.102918
   Khan AA, 2021, IEEE ACCESS, V9, P103637, DOI 10.1109/ACCESS.2021.3099037
   Khan G, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106524
   Kumar R, 2021, J PARALLEL DISTR COM, V152, P128, DOI 10.1016/j.jpdc.2021.02.022
   Liang HR, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3415151
   Liu JX, 2021, MULTIMED TOOLS APPL, V80, P30691, DOI 10.1007/s11042-021-10513-y
   Liu Y, 2021, MULTIMED TOOLS APPL, V80, P30707, DOI 10.1007/s11042-021-10558-z
   Ma SG, 2019, IEEE ACCESS, V7, P114131, DOI 10.1109/ACCESS.2019.2935513
   Nakamoto S, 2008, BITCOIN PEER TO PEER, DOI DOI 10.1007/S10838-008-9062-0
   Namasudra S, 2022, IEEE T SERV COMPUT, V15, P2289, DOI 10.1109/TSC.2020.3046471
   Nandakumar K, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P151, DOI 10.1145/3335203.3335729
   Refaeilzadeh P, 2009, NARROWED EXTENDED XP, DOI [10.1007/978-0-387-39940-9_565, DOI 10.1007/978-0-387-39940-9_242, 10.1007/978-0-387-39940-9]
   Sharma P., 2021, J. Inform. Secur. Appl, V62, P1
   Sharma PK, 2021, WAVE RANDOM COMPLEX, DOI 10.1080/17455030.2021.1983232
   Sharma P, 2023, CLUSTER COMPUT, V26, P395, DOI 10.1007/s10586-021-03491-1
   Sharma P, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3403954
   Shi KX, 2020, MULTIMED TOOLS APPL, V79, P8085, DOI 10.1007/s11042-019-08284-8
   Dinh TTA, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1085, DOI 10.1145/3035918.3064033
   Tron V., 2020, CISC VIS NETW IND GL
   Vishwa A, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P1941, DOI 10.1109/SSCI.2018.8628636
   Zhang SJ, 2020, ICT EXPRESS, V6, P93, DOI 10.1016/j.icte.2019.08.001
NR 30
TC 3
Z9 3
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 15
PY 2023
DI 10.1007/s11042-023-15690-6
EA MAY 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3ZW1
UT WOS:000988586700001
DA 2024-07-18
ER

PT J
AU Ashok, P
   Latha, B
AF Ashok, P.
   Latha, B.
TI Absorption of echo signal for underwater acoustic signal target system
   using hybrid of ensemble empirical mode with machine learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater; Acoustic Sensor signal; Echo Removal; Ensemble Sensor
   signals; Empirical Mode Decomposition; Optimization
AB Underwater acoustic sensor signal processing relies on sound absorption of underwater acoustic energy. Echo absorption of underwater acoustic waves is a challenging area because of the complexity of a marine ecosystem and the uniqueness of an underwater acoustic route. We developed Improved Weighed Quantum Particle Swarm Optimization-based Ensembles Empirical Mode Decomposition (IWQPSO-EEMD), Mean Square Variance (MSV), & Least Mean Squares Algorithm (LMSA) driven echoes absorbing underwater acoustic waves to address the problem. Initially, the original data was divided into Intrinsic Mode Functions (IMF) separated into noise IMFs and actual IMFs. Next, noise IMFs detected the echo elements and removed them using MSV and LMSA. The final denoised sensor signal was received after reconstructing both genuine and removed noise IMFs. Lastly, we employ a fusion approach that surpasses the Blind Source Separator & Categorization method. Examine simulation sounds with actual underwater sound waves compared to many other echo absorption methods. We demonstrate the validity of the IWQPSO-EEMD-MSV-LMSA with superior echo absorption efficiency and real application potential.
C1 [Ashok, P.] Anna Univ, Sri Sai Ram Inst Technol, Dept Comp Sci & Engn, Chennai, India.
   [Latha, B.] Sri Sairam Engn Coll, Dept Comp Sci & Engn, Chennai, India.
C3 Anna University; Anna University Chennai; Sri Sai Ram Engineering
   College
RP Ashok, P (corresponding author), Anna Univ, Sri Sai Ram Inst Technol, Dept Comp Sci & Engn, Chennai, India.
EM ashokit009@gmail.com
RI P, Ashok/O-2874-2015; B, Dr. Latha/ABD-5887-2021
OI P, Ashok/0000-0002-7509-8060; B, Dr. Latha/0000-0001-5818-5042
CR Azam A, 2021, J CLEAN PROD, V295, DOI 10.1016/j.jclepro.2021.126496
   Buenau KE, 2022, J MAR SCI ENG, V10, DOI 10.3390/jmse10010094
   Campanella S, 2021, 3D WORKSH HPC TRES 1
   Cen Y, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062252
   Choi DH, 2022, AM J EMERG MED, V53, P86, DOI 10.1016/j.ajem.2021.12.065
   Das N, 2021, INT J SPEECH TECHNOL, V24, P883, DOI 10.1007/s10772-020-09674-2
   El-Rashidy N, 2022, NEURAL COMPUT APPL, V34, P3603, DOI 10.1007/s00521-021-06631-1
   Fezzani R, 2018, MAR GEOPHYS RES, V39, P169, DOI 10.1007/s11001-018-9342-y
   Fine J, 2021, BIOSENSORS-BASEL, V11, DOI 10.3390/bios11040126
   Fromant G, 2021, APPL ACOUST, V180, DOI 10.1016/j.apacoust.2021.108107
   Gazagnaire J, 2021, THESIS FLORIDA ATLAN
   Gentil M, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12182875
   Ghias N, 2022, MEDRXIV
   Jones HW., 2020, ARCH ACOUST, V13, P3
   Khishe M, 2020, APPL ACOUST, V157, DOI 10.1016/j.apacoust.2019.107005
   Klausner V, 2018, RECONSTRUCTION
   Lagrois D, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-16060-2
   Li YL, 2022, BMC INFECT DIS, V22, DOI [10.1186/s12879-022-07125-8, 10.1186/s12913-022-07604-3, 10.1186/s12906-021-03483-z]
   Liao ZQ, 2022, NEUROCOMPUTING, V468, P137, DOI 10.1016/j.neucom.2021.09.074
   Lin XT, 2022, OPT EXPRESS, V30, P23270, DOI 10.1364/OE.461007
   Liu S, 2020, ARXIV
   Malikov AKU, 2021, COATINGS, V11, DOI 10.3390/coatings11080909
   Parady BE, 2018, INTRAANNUAL FJORD CI
   Rong MF, 2022, THESIS U BERGEN
   Shi MJ, 2022, PLOS NEGLECT TROP D, V16, DOI 10.1371/journal.pntd.0010388
   Srinivasu PN, 2022, MOBILE INFORM SYST
   Srinivasu PN, 2022, MOB INF SYST
   Thorne PD, 2018, CONT SHELF RES, V166, P119, DOI 10.1016/j.csr.2018.07.008
   Yang Haesang, 2020, [Journal of Ocean Engineering and Technology, 한국해양공학회지], V34, P227, DOI 10.26748/KSOE.2020.017
   Zhu L, 2022, IEEE INTERNET THINGS, V9, P24281, DOI 10.1109/JIOT.2022.3190268
NR 30
TC 1
Z9 1
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47291
EP 47311
DI 10.1007/s11042-023-15543-2
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000985452800010
DA 2024-07-18
ER

PT J
AU Cheng, XL
   Geng, KK
   Wang, ZW
   Wang, JH
   Sun, YX
   Ding, PB
AF Cheng, Xiaolong
   Geng, Keke
   Wang, Ziwei
   Wang, Jinhu
   Sun, Yuxiao
   Ding, Pengbo
TI SLBAF-Net: Super-Lightweight bimodal adaptive fusion network for UAV
   detection in low recognition environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE UAV detection; Bi-modal network; Adaptive fusion; Infrared image;
   SLBAF-Net
ID ATTENTION
AB Unmanned aerial vehicle (UAV) detection has significant research value in the field of military and civilian applications. However, the traditional object detection algorithms commonly lack satisfying accuracy and robustness due to the intense illumination changes and extremely small size of UAVs on the remote sensor images with the sky background. This paper proposes a super-lightweight bimodal network SLBAF-Net with the adaptive fusion of visible light and infrared images for UAV detection under complex illumination and weather conditions. To handle complex illumination environments and meeting the low computing requirements of airborne computers, a super-lightweight bimodal UAV detection network inspired by YOLO's network structure is developed. In order to fuse bimodal features more effectively, the bimodal adaptive fusion module (BAFM) is proposed to perform an adaptive fusion of visible and infrared feature maps for the purpose of improving detection robustness in complex environments. To verify the superiority of our method, we build a complex dual-modal UAV dataset and conduct comprehensive comparison experiments with various state-of-art object detection networks. The experimental results show that the proposed SLBAF-Net outperforms other algorithms in terms of detection performance and robustness in harsh environments, with a precision rate of 0.909 and a recall rate of 0.912. Moreover, the SLBAF-Net can meet the real-time requirements of airborne computers, and the network size is only 5.6 MB.
C1 [Cheng, Xiaolong; Geng, Keke; Wang, Ziwei; Wang, Jinhu; Sun, Yuxiao; Ding, Pengbo] Southeast Univ, Dept Mech Engn, Nanjing, Peoples R China.
C3 Southeast University - China
RP Geng, KK (corresponding author), Southeast Univ, Dept Mech Engn, Nanjing, Peoples R China.
EM jsgengke@seu.edu.cn
RI wang, wenjing/KEH-0575-2024; chen, xiao/KFQ-6812-2024; Wen,
   Jing/KCL-6614-2024; ZHANG, JING/KHY-1073-2024; wang, wei/JYP-7819-2024;
   Li, Bo/KHX-7246-2024; zhang, zheng/KHY-8870-2024; Zhang,
   Yansong/KHW-4097-2024; Liu, Xiaohan/KBB-4246-2024; Pan,
   Yue/KFS-4602-2024
OI Liu, Xiaohan/0009-0009-5291-2494; 
FU National Natural Science Foundation of China [52272414, 51905095]
FX AcknowledgementsThis work was supported in part by National Natural
   Science Foundation of China (Grant no. 52272414 and 51905095).
CR Alsanad HR, 2022, MULTIMED TOOLS APPL, V81, P26185, DOI 10.1007/s11042-022-12939-4
   Andrasi P, 2017, TRANSP RES PROC, V28, P183, DOI 10.1016/j.trpro.2017.12.184
   Bai Z, 2021, 2021 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT DESIGN (ICID 2021), P208, DOI 10.1109/ICID54526.2021.00048
   Bolya D, 2019, IEEE I CONF COMP VIS, P9156, DOI 10.1109/ICCV.2019.00925
   Cui GM, 2015, OPT COMMUN, V341, P199, DOI 10.1016/j.optcom.2014.12.032
   Dai JF, 2016, ADV NEUR IN, V29
   Du L, 2017, COMM COM INF SC, V773, P187, DOI 10.1007/978-981-10-7305-2_17
   Guang J, YOLOV5 RELEASE V6 1
   Guang JZ, 2022, J INTELL FUZZY SYST, V43, P4023, DOI 10.3233/JIFS-213314
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hu C, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-9598-x
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jamil S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143923
   Jin X, 2017, INFRARED PHYS TECHN, V85, P478, DOI 10.1016/j.infrared.2017.07.010
   Li CY, 2019, PATTERN RECOGN, V85, P161, DOI 10.1016/j.patcog.2018.08.005
   Li H, 2018, INT C PATT RECOG, P2705, DOI 10.1109/ICPR.2018.8546006
   Liu BL, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11152330
   Liu MJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082238
   Liu T, 2018, AGR FOREST METEOROL, V252, P144, DOI 10.1016/j.agrformet.2018.01.021
   Luo FY, 2022, IEEE T INTELL TRANSP, V23, P15808, DOI 10.1109/TITS.2022.3145476
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   McKenna P, 2017, INT J REMOTE SENS, V38, P4244, DOI 10.1080/01431161.2017.1317942
   Peng P, 2021, CHIN J MECH ENG-EN, V34, DOI 10.1186/s10033-021-00602-2
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Semsch E, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 2, P82
   Sun H, 2020, IEEE ACCESS, V8, P130697, DOI 10.1109/ACCESS.2020.3009518
   Thiel Christian, 2017, International Journal of Remote Sensing, V38, P2411, DOI 10.1080/01431161.2016.1225181
   Verykokou S, 2018, MULTIMED TOOLS APPL, V77, P9691, DOI 10.1007/s11042-017-5450-y
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Woo S., 2018, P EUR C COMP VIS ECC, DOI DOI 10.1007/978-3-030-01234-2_1
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xue YJ, 2021, INFRARED PHYS TECHN, V118, DOI 10.1016/j.infrared.2021.103906
   Yang Y, 2022, MOL SIMULAT, V48, P1426, DOI 10.1080/08927022.2022.2095375
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang BH, 2015, INFRARED PHYS TECHN, V73, P286, DOI 10.1016/j.infrared.2015.10.004
   Zhang YF, 2022, NEUROCOMPUTING, V506, P146, DOI 10.1016/j.neucom.2022.07.042
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
NR 42
TC 4
Z9 4
U1 15
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47773
EP 47792
DI 10.1007/s11042-023-15333-w
EA MAY 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000985452800013
DA 2024-07-18
ER

PT J
AU Zhang, ZZ
   Chen, Y
   Zhu, AC
   Liu, HX
AF Zhang, Zhizhou
   Chen, Yang
   Zhu, Aichun
   Liu, Hanxi
TI Deformable multi-scale fusion network for non-uniform single image
   deblurring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image deblurring; Deformable convolution; Multi-scale; Multi-patch
AB Non-uniform image deblurring is an ill-posed problem. Previous research efforts attempt to solve this problem by increasing the number of scales processed in the model, including but not limited to multi-scale methods, multi-patch methods, and atrous convolution. However, these methods are still subject to the fixed geometric structures, which are inherently unable to adequately handle complex blur. This paper proposes a novel residual block called Deform-ResBlock that is composed of traditional convolution and deformable convolution to enhance the model's capability of modeling geometric transformations. Then, we design parallel multi-scale convolution streams composed of densely Deform-ResBlock for extracting multi-scale features. Finally, we apply the multi-patch approach stacking two stages to deblur images gradually. The overall method is named deformable multi-scale fusion network (DMSFN). Compared to the previous methods, our method combines the advantages of multi-scale and multi-patch approaches and has better modeling geometric transformation capability. Extensive experimental results on the GoPro, HIDE, and RealBlur datasets demonstrate that the proposed method performs favorably against the state-of-the-art in the non-uniform image deblurring.
C1 [Zhang, Zhizhou; Chen, Yang; Liu, Hanxi] Southeast Univ, Sch Comp Sci & Engn, Nanjing 210096, Peoples R China.
   [Zhu, Aichun] Nanjing Tech Univ, Sch Comp Sci & Technol, Nanjing 211816, Peoples R China.
C3 Southeast University - China; Nanjing Tech University
RP Zhang, ZZ (corresponding author), Southeast Univ, Sch Comp Sci & Engn, Nanjing 210096, Peoples R China.
EM 220201874@seu.edu.com; chenyang.list@seu.edu.cn;
   aichun.zhu@njtech.edu.cn; 220201858@seu.edu.cn
RI Zhao, Xuan/JMR-2135-2023; zhang, zheng/KHY-8870-2024; Zhang,
   Zixuan/JSL-3603-2023; Wang, Junzhe/KCK-4991-2024; chen,
   xiao/KFQ-6812-2024; li, chunlin/KFS-0761-2024; Wang, Yue/JRY-8962-2023;
   ZHANG, JING/KHY-1073-2024; Wang, Jiawei/KHC-8971-2024; Wang,
   Yitong/KBA-1959-2024; Zhang, Wenkai/JWO-2030-2024; Zhu,
   Aichun/AAC-2002-2022; Cheng, Lin/KFQ-3111-2024
OI Wang, Yue/0000-0001-8673-6358; Zhang, Zhizhou/0000-0001-9546-2010
FU Key R&D Programs in Jiangsu Province of China [BE2021703, BE2022768];
   National Natural Science Foundation of China
FX AcknowledgementsThis research is partly supported by the Key R&D
   Programs in Jiangsu Province of China (No. BE2021703 and BE2022768), and
   partly supported by the National Natural Science Foundation of China
   under Grant T2225025.We thank the Big Data Computing Center of Southeast
   University for providing the facility support on the numerical
   calculations in this paper.
CR Brehm S, 2020, IEEE COMPUT SOC CONF, P1872, DOI 10.1109/CVPRW50498.2020.00237
   Chakrabarti A, 2016, LECT NOTES COMPUT SC, V9907, P221, DOI 10.1007/978-3-319-46487-9_14
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dongwon Park, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P327, DOI 10.1007/978-3-030-58539-6_20
   Gao HY, 2019, PROC CVPR IEEE, P3843, DOI 10.1109/CVPR.2019.00397
   Gupta A, 2010, LECT NOTES COMPUT SC, V6311, P171, DOI 10.1007/978-3-642-15549-9_13
   Hu Z, 2014, PROC CVPR IEEE, P3382, DOI 10.1109/CVPR.2014.432
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jaesung Rim, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P184, DOI 10.1007/978-3-030-58595-2_12
   Jin QG, 2019, KNOWL-BASED SYST, V178, P149, DOI 10.1016/j.knosys.2019.04.025
   Kingma D. P., 2014, arXiv
   Kupyn O, 2019, IEEE I CONF COMP VIS, P8877, DOI 10.1109/ICCV.2019.00897
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Lei P, 2018, PROC CVPR IEEE, P6742, DOI 10.1109/CVPR.2018.00705
   Liao X, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Loshchilov I., 2017, P INT C LEARN REPR
   Ma C, 2018, MULTIMED TOOLS APPL
   Ma TH, 2017, INFORM SCIENCES, V408, P213, DOI 10.1016/j.ins.2017.04.049
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180
   Park, 2019, ARXIV
   Schuler CJ, 2014, ARXIV
   Shen ZY, 2019, IEEE I CONF COMP VIS, P5571, DOI 10.1109/ICCV.2019.00567
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Suin M, 2020, PROC CVPR IEEE, P3603, DOI 10.1109/CVPR42600.2020.00366
   Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677
   Sun YX, 2020, MULTIMED TOOLS APPL, V79, P27659, DOI 10.1007/s11042-020-08626-x
   Tang K, 2021, NEURAL PROCESS LETT, V53, P211, DOI 10.1007/s11063-020-10370-0
   Tang S, 2017, 2017 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P256, DOI 10.1109/SPAC.2017.8304286
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Tian CW, 2021, IEEE T MULTIMEDIA, V23, P1489, DOI 10.1109/TMM.2020.2999182
   Tian YP, 2020, PROC CVPR IEEE, P3357, DOI 10.1109/CVPR42600.2020.00342
   Tsai FJ, 2022, IEEE T IMAGE PROCESS, V31, P6789, DOI 10.1109/TIP.2022.3216216
   Wang XT, 2019, IEEE COMPUT SOC CONF, P1954, DOI 10.1109/CVPRW.2019.00247
   Wang Y, 2021, MULTIMED TOOLS APPL, P1
   Whyte O, 2010, PROC CVPR IEEE, P491, DOI 10.1109/CVPR.2010.5540175
   Wu HY, 2021, PROC CVPR IEEE, P10546, DOI 10.1109/CVPR46437.2021.01041
   Xu DJ, 2020, IEEE COMPUT SOC CONF, P1943, DOI 10.1109/CVPRW50498.2020.00244
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu XQ, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P681, DOI 10.1109/ICDSP.2016.7868645
   Ye MY, 2020, IEEE ACCESS, V8, P18316, DOI 10.1109/ACCESS.2020.2967823
   Yu X, 2014, IEEE T MULTIMEDIA, V16, P1510, DOI 10.1109/TMM.2014.2321734
   Zamir Syed Waqas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P492, DOI 10.1007/978-3-030-58595-2_30
   Zamir SW, 2021, PROC CVPR IEEE, P14816, DOI 10.1109/CVPR46437.2021.01458
   Zhang C, 2019, PROC CVPR IEEE, P9444, DOI 10.1109/CVPR.2019.00968
   Zhang FJ, 2018, MULTIMED TOOLS APPL, V77, P26239, DOI 10.1007/s11042-018-5847-2
   Zhang HG, 2019, PROC CVPR IEEE, P5971, DOI 10.1109/CVPR.2019.00613
   Zhang JW, 2018, PROC CVPR IEEE, P2521, DOI 10.1109/CVPR.2018.00267
   Zhang KH, 2020, PROC CVPR IEEE, P2734, DOI 10.1109/CVPR42600.2020.00281
   Zhang QL, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2235, DOI 10.1109/ICASSP39728.2021.9414568
   Zhao B, 2013, COGN COMPUT, V5, P3, DOI 10.1007/s12559-012-9139-2
   Zhao G, 2017, MULTIMED TOOLS APPL
   Zhao Z., 2020, IEEE ACCESS, VPP, P1, DOI [10.1109/ACCESS.2020.2993285, DOI 10.1109/ACCESS.2020.2993285]
NR 53
TC 0
Z9 0
U1 7
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45621
EP 45638
DI 10.1007/s11042-023-14818-y
EA MAY 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000983013200003
DA 2024-07-18
ER

PT J
AU Fan, MQ
AF Fan, MingQuan
TI Blind Dual Image Watermarking for Copyright Protection, Tamper Proofing
   and Self-Recovery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dual watermarking; Copyright protection; Tamper discrimination; Set
   partitioning in hierarchical trees(SPIHT); Dual tree complex wavelet
   transform (DT-CWT)
ID SCHEME
AB In this paper, a blind dual image watermarking scheme for copyright protection, tamper proofing and self-recovery is proposed. For purpose of copyright protection, we use binary handwritten signature, a high correlative biometric to owner as robust watermark, and embed it into hybrid domain constructed by dual tree complex wavelet transform (DT-CWT) and discrete cosine transform (DCT). For purpose of tamper proofing and self-recovery, source encoding output bits generated by set partitioning in hierarchical trees (SPIHT) encoding are embedded into image based on least significant bits (LSB) replacement, moreover, in order to enhance the robustness of self-recovery, repeated encoding technique is adopted, and hash-based check bits are used for tamper proofing. Experimental results indicate the proposed watermarking mechanism can withstand various image processing attacks, accurately locate and recover the tampered area of an image, especially it has the ability of tamper discrimination that other existing schemes do not have. It can find application for joint ownership and content authentication synchronously.
C1 [Fan, MingQuan] Southwest China Res Inst Elect Equipment, Chengdu, Peoples R China.
RP Fan, MQ (corresponding author), Southwest China Res Inst Elect Equipment, Chengdu, Peoples R China.
EM 1147955679@qq.com
CR Ahmad F, 2018, SIGNAL PROCESS, V148, P322, DOI 10.1016/j.sigpro.2018.02.029
   Ahmaderaghi B, 2018, IEEE T COMPUT IMAG, V4, P46, DOI 10.1109/TCI.2018.2794065
   Ansari IA, 2017, PATTERN RECOGN LETT, V94, P228, DOI 10.1016/j.patrec.2016.12.010
   Chen B, 2022, IEEE T DEPEND SECURE, V19, P978, DOI 10.1109/TDSC.2020.3011923
   Chen Y, 2021, SIGNAL PROCESS, V185, DOI 10.1016/j.sigpro.2021.108088
   Chen ZG, 2018, IEEE T MULTIMEDIA, V20, P1973, DOI 10.1109/TMM.2018.2794985
   Divya Shivani JL, 2017, FUTURE INTERNET, V33, pp1
   Ernawan F, 2018, IEEE ACCESS, V6, P20464, DOI 10.1109/ACCESS.2018.2819424
   Fan MQ, 2020, MULTIMED TOOLS APPL, V79, P1037, DOI 10.1007/s11042-019-08095-x
   Fan MQ, 2018, SIGNAL PROCESS-IMAGE, V66, P19, DOI 10.1016/j.image.2018.04.003
   Guo YF, 2018, IEEE T IMAGE PROCESS, V27, P3387, DOI 10.1109/TIP.2018.2815181
   Haghighi BB, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107029
   Hurrah NN, 2019, FUTURE GENER COMP SY, V94, P654, DOI 10.1016/j.future.2018.12.036
   Jamali M, ARXIV
   Laouamer L, 2018, IEEE ACCESS, V6, P26144, DOI 10.1109/ACCESS.2018.2831599
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Loukhaoukha Khaled, 2017, Journal of Electrical Systems and Information Technology, V4, P359, DOI 10.1016/j.jesit.2016.12.011
   Magdy M, 2022, IEEE ACCESS, V10, P38821, DOI 10.1109/ACCESS.2022.3165813
   Rudman K., 2016, SMPTE Motion Imaging Journal, V125, P34, DOI 10.5594/j18662
   Sarreshtedari S, 2015, IEEE T IMAGE PROCESS, V24, P2266, DOI 10.1109/TIP.2015.2414878
   Sehra K, 2021, IEEE ACCESS, V9, P72465, DOI 10.1109/ACCESS.2021.3079319
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Singh P, 2017, MULTIMED TOOLS APPL, V76, P6389, DOI 10.1007/s11042-015-3198-9
   Sinhal R, 2022, CIRC SYST SIGNAL PR, V41, P3199, DOI 10.1007/s00034-021-01926-z
   Sk A, 2018, COMPUT ELECTR ENG, V72, P589, DOI 10.1016/j.compeleceng.2018.02.045
   Su QT, 2019, IEEE ACCESS, V7, P30398, DOI 10.1109/ACCESS.2019.2895062
   Subramanian N, 2021, IEEE ACCESS, V9, P23409, DOI 10.1109/ACCESS.2021.3053998
   Tohidi F, 2021, IEEE ACCESS, V9, P57510, DOI 10.1109/ACCESS.2021.3072314
   Wu YD, 2023, IEEE T DEPEND SECURE, V20, P1744, DOI 10.1109/TDSC.2022.3162623
   Xiao-Long Liu, 2018, IEEE Transactions on Circuits and Systems for Video Technology, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
NR 30
TC 1
Z9 1
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45503
EP 45518
DI 10.1007/s11042-023-15261-9
EA MAY 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000981387900001
DA 2024-07-18
ER

PT J
AU Padmavathi, P
   Harikiran, J
   Vijaya, J
AF Padmavathi, Panguluri
   Harikiran, Jonnadula
   Vijaya, J.
TI Effective deep learning based segmentation and classification in
   wireless capsule endoscopy images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless capsule endoscopy; Gastrointestinal tracts; Time-consuming;
   Expectation maximum algorithm; Segmentation; Lenet 5; Kvasir-V2 dataset;
   Performances
AB Wireless capsule endoscopy is a noninvasive wireless imaging method that has grown in popularity over the last several years. One of the efficient and effective ways for examining the gastrointestinal system is using WCE. It sends a huge number of images in a single examination cycle, making abnormality analysis and diagnosis extremely difficult and time-consuming. As a result, in this research, we provide the Expectation maximum (EM) algorithm, a revolutionary deep-learning-based segmentation approach for GI tract recognition in WCE images. DeepLap v3+ can extract a variety of features including colour, shape, and geometry, as well as SURF (speed-up robust features). Thus the Lenet 5 based classification can be made in the extracted images. The effectiveness of the performances is carried out on a publicly available Kvasir-V2 dataset, on which our proposed approach achieves 99.12% accuracy 98.79% of precision, 99.05% of recall and 98.49% of F1- score when compared to existing approaches. Effectiveness benefits are demonstrated over multiple current state-of-the-art competing techniques on all performance variables we evaluated, especially mean of Intersection Over Union (IoU), IoU for background, and IoU for the entire class.
C1 [Padmavathi, Panguluri; Harikiran, Jonnadula] VIT AP Univ, Vellore Inst Technol, Sch Comp Sci Engn, Amaravathi, Andhra Pradesh, India.
   [Vijaya, J.] Int Inst Informat Technol, Naya Raipur, Chhattisgarh, India.
C3 VIT-AP University
RP Harikiran, J (corresponding author), VIT AP Univ, Vellore Inst Technol, Sch Comp Sci Engn, Amaravathi, Andhra Pradesh, India.; Vijaya, J (corresponding author), Int Inst Informat Technol, Naya Raipur, Chhattisgarh, India.
EM padmavathi.20phd7169@vitap.ac.in; harikiran.j@vitap.ac.in;
   vijaya@iiitnr.edu.in
RI padmavathi, panguluri/JCE-7185-2023
OI padmavathi, panguluri/0009-0006-7945-4823
CR Al Mamun A., 2021, INT J EL COMP ENG SY, V11, P11, DOI DOI 10.11591/IJECE.V11I3.PP2688-2695
   Alam MW, 2020, CANCERS, V12, DOI 10.3390/cancers12040890
   Alaskar H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061265
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Gao Y, 2020, IEEE ACCESS, V8, P81621, DOI 10.1109/ACCESS.2020.2991115
   Ghosh T, 2018, IEEE J TRANSL ENG HE, V6, DOI 10.1109/JTEHM.2017.2756034
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   Jain S, 2020, COMPUT BIOL MED, V127, DOI 10.1016/j.compbiomed.2020.104094
   JANI KK, 2021, INFORM SYST FRONT, P1
   Jani KK, 2019, J INTELL FUZZY SYST, V37, P1491, DOI 10.3233/JIFS-182883
   Khan MA, 2020, IEEE ACCESS, V8, P132850, DOI 10.1109/ACCESS.2020.3010448
   Lu F, 2022, ACM T INTERNET THING, V3, DOI 10.1145/3477540
   Oleksy P, 2020, INT J ELECTRON TELEC, V66, P45, DOI 10.24425/ijet.2019.130264
   Pogorelov K, 2019, J APPL CLIN MED PHYS, V20, P141, DOI 10.1002/acm2.12662
   Ponnusamy R., 2020, INT J FUTURE GENER C, V13, P985
   Prasath VBS, 2020, PATTERN RECOGN IMAGE, V30, P280, DOI 10.1134/S1054661820030219
   Rathnamala S, 2021, MED BIOL ENG COMPUT, V59, P969, DOI 10.1007/s11517-021-02352-8
   Rustam F, 2021, IEEE ACCESS, V9, P33675, DOI 10.1109/ACCESS.2021.3061592
   Saito H, 2020, GASTROINTEST ENDOSC, V92, P144, DOI 10.1016/j.gie.2020.01.054
   Shrivastava A, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P366, DOI 10.1109/ICIVC.2017.7984579
   Singh NP, 2020, TRAIT SIGNAL, V37, P855, DOI 10.18280/ts.370519
   Sivakumar P, 2019, CLUSTER COMPUT, V22, P12219, DOI 10.1007/s10586-017-1584-y
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Souaidi M, 2019, MULTIMED TOOLS APPL, V78, P13091, DOI 10.1007/s11042-018-6086-2
   Wang S, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab5086
   Wang S, 2019, COMPUT MATH METHOD M, V2019, DOI 10.1155/2019/7546215
NR 27
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47109
EP 47133
DI 10.1007/s11042-023-14621-9
EA MAY 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000981387900007
DA 2024-07-18
ER

PT J
AU Kamal, R
   Hemdan, EE
   El-Fishway, N
AF Kamal, Randa
   Hemdan, Ezz El-Din
   El-Fishway, Nawal
TI An efficient security system based on cancelable face recognition with
   blockchain over cognitive IoT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Cancelable biometrics; Image authentication; Machine
   learning; Face recognition
ID INTERNET; THINGS
AB This paper presents a new authentication framework for cancelable face recognition biometrics. In recent years, biometric plays a pivotal role in Cognitive Internet of Things (C-IoT) security. The face trait solves a lot of security issues; it increases the resistance of these systems against severe authentication attacks especially in smart IoT-based applications. The proposed scheme runs in two phases; The first phase (enrollment), in which the face image of the person is hashed using SHA256, is passed to an algorithm to extract the main features. Then the image is decomposed using a wavelet transform algorithm. Wavelet transform is applied to hide the face details from the image. This step is done to protect the image against being stolen or modified by external hackers. The image, hash, and wavelet transform are passed through the raspberry Pi to be stored in a database. A block is added to the private blockchain with these files. In the second phase (authentication) the test image is hashed, passed to the system to extract the features, and compared with the stored images in the database. Then the decision is stored in a new block in the chain, whether the two images are identical or not. The simulation results based demonstrate that the proposed cancelable biometric system gives a very reliable and secure performance for securing the IoT applications.
C1 [Kamal, Randa; Hemdan, Ezz El-Din; El-Fishway, Nawal] Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP Kamal, R (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia, Egypt.
EM randa.soltan@te.eg; ezzvip@yahoo.com; nelfishawy@hotmail.com
RI Kamal, Randa/JXH-1587-2024
OI kamal, randa/0000-0002-3028-6834
CR Abdellatef E, 2019, MULTIMED TOOLS APPL, V78, P31557, DOI 10.1007/s11042-019-07848-y
   Abou Elazm LA, 2020, MULTIMED TOOLS APPL, V79, P14053, DOI 10.1007/s11042-019-08462-8
   Ashiba HI, 2021, MULTIMED TOOLS APPL, V80, P13677, DOI 10.1007/s11042-020-10291-z
   Ashiba HI, 2020, MULTIMED TOOLS APPL, V79, P30813, DOI 10.1007/s11042-020-09529-7
   Atlam HF, 2020, INTERNET THINGS-NETH, V11, DOI 10.1016/j.iot.2020.100220
   Danko D, 2019, IEEE INT CONF MOB, P48, DOI 10.1109/MASSW.2019.00016
   Dirgantoro Kevin Putra, 2020, 2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC), P039, DOI 10.1109/ICAIIC48513.2020.9065231
   El-Din HE, 2017, STUD BIG DATA, V25, P109, DOI 10.1007/978-3-319-53472-5_5
   El-Din HE, 2017, STUD BIG DATA, V25, P299, DOI 10.1007/978-3-319-53472-5_15
   El-Shafai W, 2021, J AMB INTEL HUM COMP, V12, P9007, DOI 10.1007/s12652-020-02597-5
   Gao JQ, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2019.164123
   Hemdan E. E. D., 2020, Deep Learning and Neural Networks: Concepts, Methodologies, Tools, and Applications
   Hu J, 2022, IEEE T CIRC SYST VID, V32, P1089, DOI 10.1109/TCSVT.2021.3074259
   Kak Shakir Fattah, 2019, 2019 International Conference on Advanced Science and Engineering (ICOASE), P40, DOI 10.1109/ICOASE.2019.8723673
   Kamal R, 2021, 2021 INT C EL ENG IC
   Khan PW, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030484
   Kortli Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020342
   Li XQ, 2020, FUTURE GENER COMP SY, V107, P841, DOI 10.1016/j.future.2017.08.020
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2012, IEICE T FUND ELECTR, VE95A, P1189, DOI 10.1587/transfun.E95.A.1189
   Manisha, 2020, ARTIF INTELL REV, V53, P3403, DOI 10.1007/s10462-019-09767-8
   Mercan S, 2021, SECUR PRIVACY, V4, DOI 10.1002/spy2.143
   MICHELIN RA, 2020, 2020 IEEE INT C BLOC, P1
   Muniz A. L. M., 2019, 2019 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2019.8873106
   Qianwen Wang, 2020, Journal of Physics: Conference Series, V1437, DOI 10.1088/1742-6596/1437/1/012007
   Raspberry Pi Foundation, 2020, RASPB PI 2
   Shalaby AS, 2021, MULTIMED TOOLS APPL, V80, P26273, DOI 10.1007/s11042-021-10932-x
   Shankar S, 2020, CCIS, P449, DOI DOI 10.1007/978-981-15-6318-8-37
   Shetty A. B., 2021, GLOBAL TRANSITIONS P, V2, P330, DOI DOI 10.1016/J.GLTP.2021.08.044
   Surve M., 2020, CURR CONTENTS, V9, P2134, DOI [10.35940/ijrte.A2644.059120, DOI 10.35940/IJRTE.A2644.059120]
   Tseng L, 2020, CLUSTER COMPUT, V23, P2151, DOI 10.1007/s10586-020-03138-7
   Wang S, 2017, PATTERN RECOGN, V61, P447, DOI 10.1016/j.patcog.2016.08.017
   Yang WC, 2018, PATTERN RECOGN, V78, P242, DOI 10.1016/j.patcog.2018.01.026
   Zakaria Y, 2019, MULTIMED TOOLS APPL, V78, P32333, DOI 10.1007/s11042-019-07824-6
NR 34
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 44741
EP 44761
DI 10.1007/s11042-023-15534-3
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000982739000007
DA 2024-07-18
ER

PT J
AU Zaferani, H
   Kiani, K
   Rastgoo, R
AF Zaferani, Hosein
   Kiani, Kourosh
   Rastgoo, Razieh
TI Real-time face verification on mobile devices using margin distillation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face verification; Face recognition; Mobile devices; Deep learning;
   Real-time
AB Face verification is an attractive yet challenging research area in computer vision. To make an improvement in the existing models for face verification, we proposed a CNN-based model for face verification on Mobile devices. The Multi-Task Convolutional Neural Network (MTCNN), as a pretrained model, is used for face detection. Some modifications are applied to the MobileFaceNet model and trained using the Margin Distillation cost function. To boost the model performance, the Dense Block and Depthwise separable convolutions are used in the model. Results on seven datasets confirm that the proposed model obtained the relative accuracy improvements of 0.017%, 1.384%, 0.483%, 0.124%, 2.185%, 0.684%, and 1.34%, compared to the baseline model, on the LFW, CPLFW, CPLFW, CFP FF, CFP FP, AGEDB_30, and VGG2_FP datasets, respectively. Furthermore, we collected a dataset, including a total of 4800 samples, with 80 sample images of 60 celebrities. Images are downloaded from Google Image Search. The proposed model obtained a verification accuracy of 99.760 on the collected dataset.
C1 [Zaferani, Hosein; Kiani, Kourosh; Rastgoo, Razieh] Semnan Univ, Elect & Comp Engn Dept, Semnan 3513119111, Iran.
C3 Semnan University
RP Kiani, K (corresponding author), Semnan Univ, Elect & Comp Engn Dept, Semnan 3513119111, Iran.
EM HZaaferani@semnan.ac.ir; Kourosh.kiani@semnan.ac.ir;
   rrastgoo@semnan.ac.ir
RI Rastgoo, Razieh/AFO-9957-2022; Kiani, Kourosh/T-7468-2019
OI Rastgoo, Razieh/0000-0001-7963-9461; Kiani, Kourosh/0000-0001-6582-8691
CR An X, 2021, IEEE INT CONF COMP V, P1445, DOI 10.1109/ICCVW54120.2021.00166
   andreearaicu, About Us
   Boutros F, 2021, ARXIV
   Cao Q, 2018, ARXIV
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Chrysos GG, IEEE T PATTERN ANAL
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   github, about us
   Guo GD, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102805
   Guo Y, 2016, ARXIV
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hua Q, 2018, COMPLEXITY, DOI 10.1155/2018/2861695
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang Y, 2022, EVALUATION ORIENTED
   Huang YG, 2020, PROC CVPR IEEE, P5900, DOI 10.1109/CVPR42600.2020.00594
   Iandola Forrest N, 2016, SQUEEZENET ALEXNET L
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Kim Y, 2020, PROC CVPR IEEE, P5620, DOI 10.1109/CVPR42600.2020.00566
   Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250
   Nekhaev D, 2020, PROC SPIE, V11433, DOI 10.1117/12.2557244
   Rastgoo R, 2019, J MED IMAG HEALTH IN, V17, P103
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sengupta S, 2016, IEEE WINT CONF APPL
   Shi W., 2020, ARXIV
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Wu B., 2017, arXiv
   Wu X., 2016, ARXIV
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhao F, 2020, FUTURE GENER COMP SY, V111, P375, DOI 10.1016/j.future.2020.05.002
   Zheng T., 2018, Tech. Rep., V5
   Zheng T., 2017, ARXIV
   Zoph B., 2017, ARXIV
NR 38
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44155
EP 44173
DI 10.1007/s11042-023-15510-x
EA APR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000978477000005
DA 2024-07-18
ER

PT J
AU Ramu, B
   Bansal, S
AF Ramu, B.
   Bansal, Sandeep
TI Highly accurate tumour region segmentation from magnetic resonance
   images using customized convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Magnetic resonance imaging; Computer vision; MRI segmentation; Tumour
   region segmentation; Sensitivity analysis; Enhanced adaptive gamma
   correction; UNET
AB Nowadays, brain tumour is one of the biggest health difficulties across many nations in the globe owing to global warming, heredity, career, etc. The most aggressive kind of brain tumour is gliomas, which lead to a high-grade life. The early detection and diagnosis of a brain tumour can save a life. Identifying the tumour location through Magnetic Resonance Imaging (MRI) is quite straightforward. However, MRI's vast volume of data hinders manual segmentation in a reasonable period, reducing the application of reliable quantitative measures in clinical practice. An autonomous and reliable approach is needed that can segment tumours properly. This work proposes a new technique for brain tumour segmentation using cascaded UNET architecture. Initially, the images are resized into 128 x 128 pixels to obtain optimum computational time. Further, enhanced adaptive gamma correction is applied in the input images to improve the pixel quality. Selected slices with tumour regions are used to perform the training and validation. The proposed model has been validated on the BraTS 2020 dataset. The proposed work achieved an accuracy of 99.56%, 99.71% specificity, 96.43% sensitivity, and 98.49% precision. The performance of the proposed method outperforms with good accuracy compared to previous methods.
C1 [Ramu, B.] Lovely Profess Univ, Sch Elect & Elect Engn, Jalandhar, Punjab, India.
   [Ramu, B.; Bansal, Sandeep] Geethanjali Coll Engn & Technol, Dept Elect & Commun Engn, Hyderabad, Telangana, India.
C3 Lovely Professional University; Geethanjali College of Engineering &
   Technology
RP Ramu, B (corresponding author), Lovely Profess Univ, Sch Elect & Elect Engn, Jalandhar, Punjab, India.; Ramu, B (corresponding author), Geethanjali Coll Engn & Technol, Dept Elect & Commun Engn, Hyderabad, Telangana, India.
EM ramu0604@gmail.com; sandeep.15732@lpu.co.in
CR Abbas HK, 2021, J PHYS C SER, V1892
   Abd El Kader I, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11091589
   Aghalari M, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102841
   Akbar AS, 2022, J KING SAUD UNIV-COM, V34, P3247, DOI 10.1016/j.jksuci.2022.03.022
   Alqazzaz S, 2019, COMPUT VIS MEDIA, V5, P209, DOI 10.1007/s41095-019-0139-y
   Arif M., 2022, J HEALTHC ENG, V2022, P1
   Arora A, 2021, COMPUTERS, V10, DOI 10.3390/computers10110139
   Aswathy SU, 2019, CLUSTER COMPUT, V22, P13369, DOI 10.1007/s10586-018-1914-8
   Biswas Angona, 2021, 2021 2nd International Conference on Robotics, Electrical and Signal Processing Techniques (ICREST), P654, DOI 10.1109/ICREST51555.2021.9331115
   Cao G, 2018, COMPUT ELECTR ENG, V66, P569, DOI 10.1016/j.compeleceng.2017.09.012
   Chakraborty C, 2022, IEEE T COMPUT SOC SY, V9, P1613, DOI 10.1109/TCSS.2022.3170375
   Chakraborty C, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107778
   Chen J, 2022, IEEE J BIOMED HEALTH, V26, P103, DOI 10.1109/JBHI.2021.3077469
   Chen SC, 2019, PATTERN RECOGN, V88, P90, DOI 10.1016/j.patcog.2018.11.009
   Chetty Girija, 2022, Int J Inf Technol, V14, P95, DOI 10.1007/s41870-021-00850-4
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Duan FF, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1054-z
   Guan X, 2022, BMC MED IMAGING, V22, DOI 10.1186/s12880-021-00728-8
   Gull S, 2021, BIOMED RES INT-UK, V2021, DOI 10.1155/2021/3365043
   Havaei M, 2016, INT J COMPUT ASS RAD, V11, P777, DOI 10.1007/s11548-015-1311-1
   Hossain T., 2019, 2019 1 INT C ADV SCI, P1, DOI [DOI 10.1109/ICASERT.2019.8934561, 10.1109/ICASERT.2019.8934561]
   Huang CB, 2022, MULTIMED TOOLS APPL, V81, P12543, DOI 10.1007/s11042-022-12335-y
   Huang H, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.690244
   Ilhan A, 2022, INT J COMPUT ASS RAD, V17, P589, DOI 10.1007/s11548-022-02566-7
   Ilhan U, 2017, PROCEDIA COMPUT SCI, V120, P580, DOI 10.1016/j.procs.2017.11.282
   Iriawan N, 2020, TELKOMNIKA (Telecommun. Comput. Electron. Control.), V18, P1310, DOI [10.12928/telkomnika.v18i3.14753, DOI 10.12928/TELKOMNIKA.V18I3.14753, 10.12928/TELKOMNIKA.v18i3.14753]
   Isensee F, 2021, LECT NOTES COMPUT SC, V12659, P118, DOI 10.1007/978-3-030-72087-2_11
   Jin Y, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104160
   Kabir MA., 2020, GLOBAL SCI RES J, V8, P695
   Kamnitsas K, 2016, LECT NOTES COMPUT SC, V10154, P138, DOI 10.1007/978-3-319-55524-9_14
   Latif U, 2021, INT J IMAG SYST TECH, V31, P1803, DOI 10.1002/ima.22585
   Li M, 2019, IEEE ACCESS, V7, P180134, DOI 10.1109/ACCESS.2019.2958370
   Liu YK, 2020, IEEE ACCESS, V8, P151817, DOI 10.1109/ACCESS.2020.3017168
   Liu YK, 2019, IEEE ACCESS, V7, P163626, DOI 10.1109/ACCESS.2019.2952534
   Luu HM, 2021, ARXIV
   Nan Y, 2022, INFORM FUSION, V82, P99, DOI 10.1016/j.inffus.2022.01.001
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Soltaninejad M, 2018, LECT NOTES COMPUT SC, V10670, P204, DOI 10.1007/978-3-319-75238-9_18
   Soltaninejad M, 2018, COMPUT METH PROG BIO, V157, P69, DOI 10.1016/j.cmpb.2018.01.003
   Soltaninejad M, 2017, INT J COMPUT ASS RAD, V12, P183, DOI 10.1007/s11548-016-1483-3
   Vijh S, 2023, NEURAL COMPUT APPL, V35, P7315, DOI 10.1007/s00521-021-06709-w
   Wang G, 2022, NEURAL COMPUT APPL, V2203
   Wang GT, 2018, LECT NOTES COMPUT SC, V10670, P178, DOI 10.1007/978-3-319-75238-9_16
   Wang WX, 2021, LECT NOTES COMPUT SC, V12901, P109, DOI 10.1007/978-3-030-87193-2_11
   Wu YZ, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11020346
   Yang G, 2022, INFORM FUSION, V77, P29, DOI 10.1016/j.inffus.2021.07.016
   Yang G, 2020, FUTURE GENER COMP SY, V107, P215, DOI 10.1016/j.future.2020.02.005
   Ye QH, 2021, COMP MED SY, P521, DOI 10.1109/CBMS52027.2021.00103
   Zhou CH, 2019, LECT NOTES COMPUT SC, V11384, P497, DOI 10.1007/978-3-030-11726-9_44
NR 49
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14423
EP 14445
DI 10.1007/s11042-023-15480-0
EA APR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000979936300001
DA 2024-07-18
ER

PT J
AU Rastgoo, R
   Kiani, K
   Escalera, S
AF Rastgoo, Razieh
   Kiani, Kourosh
   Escalera, Sergio
TI ZS-GR: zero-shot gesture recognition from RGB-D videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture recognition; Zero-shot learning; Vision transformer; Lingual
   embedding; BERT; Action recognition
AB Gesture Recognition (GR) is a challenging research area in computer vision. To tackle the annotation bottleneck in GR, we formulate the problem of Zero-Shot Gesture Recognition (ZS-GR) and propose a two-stream model from two input modalities: RGB and Depth videos. To benefit from the vision Transformer capabilities, we use two vision Transformer models, for human detection and visual features representation. We configure a transformer encoder-decoder architecture, as a fast and accurate human detection model, to overcome the challenges of the current human detection models. Considering the human keypoints, the detected human body is segmented into nine parts. A spatio-temporal representation from human body is obtained using a vision Transformer and a LSTM network. A semantic space maps the visual features to the lingual embedding of the class labels via a Bidirectional Encoder Representations from Transformers (BERT) model. We evaluated the proposed model on five datasets, Montalbano II, MSR Daily Activity 3D, CAD-60, NTU-60, and isoGD obtaining state-of-the-art results compared to state-of-the-art ZS-GR models as well as the Zero-Shot Action Recognition (ZS-AR).
C1 [Rastgoo, Razieh; Kiani, Kourosh] Semnan Univ, Semnan, Iran.
   [Escalera, Sergio] Univ Barcelona & Comp Vis Ctr, Barcelona, Spain.
C3 Semnan University
RP Rastgoo, R (corresponding author), Semnan Univ, Semnan, Iran.
EM rrastgoo@semnan.ac.ie; Kourosh.kiani@semnan.ac.ir; sescalera@ub.edu
RI Kiani, Kourosh/T-7468-2019; Rastgoo, Razieh/AFO-9957-2022; Escalera,
   Sergio/L-2998-2015
OI Kiani, Kourosh/0000-0001-6582-8691; Rastgoo, Razieh/0000-0001-7963-9461;
   Escalera, Sergio/0000-0003-0617-8873
CR Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bilge Y., 2019, BMVC
   Bishay M, 2019, Arxiv, DOI arXiv:1907.09021
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chan WL, 2020, Arxiv, DOI arXiv:2002.08926
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dosovitskiy Alexey, 2021, ICLR
   Escalera S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2522848.2532595
   Gu Jiatao, 2018, ICLR
   Gupta P, 2021, Arxiv, DOI arXiv:2101.11530
   Gupta P, 2021, IEEE IMAGE PROC, P439, DOI 10.1109/ICIP42928.2021.9506179
   Hahn M, 2019, Arxiv, DOI arXiv:1901.00484
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang G., 2021, arXiv
   Kalfaoglu M. E., 2020, arXiv
   Khan S.H., 2021, arXiv
   Kiani K, 2021, J AI Data Mining, DOI DOI 10.22044/JADM.2021.9957.2131
   Li CY, 2019, AAAI CONF ARTIF INTE, P8585
   Li D., 2020, TSPNet hierarchical feature learning via temporal semantic pyramid for sign language translation
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Madapana N, 2020, 15 IEEE INT C AUT FA
   Majidi Nezam, 2020, Journal of AI and Data Mining, V8, P451
   Mishra A, 2018, IEEE WINT CONF APPL, P372, DOI 10.1109/WACV.2018.00047
   Nguyen M., 2021, Geometry and Vision, P108
   Rastgoo R, 2023, MULTIMED TOOLS APPL, V82, P1401, DOI 10.1007/s11042-022-13573-w
   Rastgoo R, 2021, IEEE COMPUT SOC CONF, P3446, DOI 10.1109/CVPRW53098.2021.00384
   Rastgoo R, 2022, J AMB INTEL HUM COMP, V13, P591, DOI 10.1007/s12652-021-02920-8
   Rastgoo R, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.113794
   Rastgoo R, 2021, MULTIMED TOOLS APPL, V80, P127, DOI 10.1007/s11042-020-09700-0
   Rastgoo R, 2020, MULTIMED TOOLS APPL, V79, P22965, DOI 10.1007/s11042-020-09048-5
   Rastgoo R, 2020, EXPERT SYST APPL, V150, DOI 10.1016/j.eswa.2020.113336
   Rastgoo R, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20110809
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Ren S, 2015, PAMI, P1137
   Schonfeld E, 2022, CVPR, P8247
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Tsai YHH, 2017, IEEE I CONF COMP VIS, P3591, DOI 10.1109/ICCV.2017.386
   Vaswani A, 2017, ADV NEUR IN, V30
   Wan J, 2016, IEEE COMPUT SOC CONF, P761, DOI 10.1109/CVPRW.2016.100
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wray M, 2019, IEEE I CONF COMP VIS, P450, DOI 10.1109/ICCV.2019.00054
   Wu JT, 2018, LECT NOTES COMPUT SC, V11305, P244, DOI 10.1007/978-3-030-04221-9_22
NR 44
TC 2
Z9 2
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43781
EP 43796
DI 10.1007/s11042-023-15112-7
EA APR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:001066758900002
DA 2024-07-18
ER

PT J
AU Zhang, JZ
   Wang, SX
   Zhang, SM
   Li, JK
   Sun, YY
AF Zhang, Jiaze
   Wang, Shuxian
   Zhang, Shengmao
   Li, Jiakang
   Sun, Yueying
TI Research on target detection and recognition algorithm of <i>Eriocheir
   sinensis</i> carapace
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chinese Mitten Crab; Transfer learning; KPCA; 1D-PCA; 2D-PCA;
   (2D)(2)-PCA
ID FACE REPRESENTATION; 2-DIMENSIONAL PCA
AB Chinese mitten crab is one of China's unique aquaculture species, which has significant economic value to the aquatic product market. In order to recognize different individual Chinese mitten crab, this paper proposes a method of first detection and recognition of carapace combined with YOLOv5 (You Only Look Once v5) and principal component analysis (PCA) and its improved method. First, the image of the Chinese mitten crab is obtained through the camera. Secondly, YOLOv5 and transfer learning method are used to detect the target of the Chinese mitten crab, and then the target is automatic cropped according to the detected target frame of Chinese mitten crab carapace. Finally, four methods of KPCA, one-dimensional PCA (1D-PCA), two-dimensional PCA (2D-PCA), and two-way two-dimensional PCA ((2D)(2)-PCA) were used for matching. The results show that the (2D)(2)-PCA recognition rate can reach 84.42%, which is 18.27%, 9.128% and 8.689% higher than the other three methods respectively. In addition, the matching speed only takes 1.859 s, compared with the other three methods. The method improves by 86.051 s, 2.562 s and 0.784 s, respectively. Therefore, this method has a better experimental effect in the experiment, and the recognition speed is faster. The results of the study can avoid the economic loss of aquatic products and provide a new research method for the recognition of the Chinese mitten crab carapace.
C1 [Zhang, Jiaze; Wang, Shuxian; Zhang, Shengmao; Li, Jiakang; Sun, Yueying] Chinese Acad Fishery Sci, East China Sea Fisheries Res Inst, Key Lab Fisheries Remote Sensing, Minist Agr & Rural Affairs, Shanghai, Peoples R China.
   [Zhang, Jiaze; Li, Jiakang; Sun, Yueying] Shanghai Ocean Univ, Coll Informat, Shanghai, Peoples R China.
   [Wang, Shuxian] Dalian Ocean Univ, Sch Nav & Naval Architecture, Dalian, Peoples R China.
   [Zhang, Shengmao] Laoshan Lab, Qingdao, Peoples R China.
C3 Ministry of Agriculture & Rural Affairs; Chinese Academy of Fishery
   Sciences; East China Sea Fisheries Research Institute, CAFS; Shanghai
   Ocean University; Dalian Ocean University; Laoshan Laboratory
RP Zhang, SM (corresponding author), Chinese Acad Fishery Sci, East China Sea Fisheries Res Inst, Key Lab Fisheries Remote Sensing, Minist Agr & Rural Affairs, Shanghai, Peoples R China.; Zhang, SM (corresponding author), Laoshan Lab, Qingdao, Peoples R China.
EM zhangsm@ecsf.ac.cn
FU National Natural Science Foundation of China [61936014]; Laoshan
   Laboratory [2020TD82]; Chinese Academy of Fishery Sciences; 
   [LSKJ202201804]
FX This work was supported by National Natural Science Foundation of China
   under Grant No. 61936014, Laoshan Laboratory under Grant
   No.LSKJ202201804, Chinese Academy of Fishery Sciences basic scientific
   research fees under Grant No. 2020TD82
CR Cao L, 2021, THESIS YANGZHOU U
   Cao LJ, 2003, NEUROCOMPUTING, V55, P321, DOI 10.1016/S0925-2312(03)00433-8
   Cao S, 2021, COMPUT ELECTRON AGR, V180, DOI 10.1016/j.compag.2020.105905
   [陈卉 Chen Hui], 2021, [食品与生物技术学报, Journal of Food Science and Biotechnology], V40, P11
   Cui YH, 2020, MULTIMED TOOLS APPL, V79, P7669, DOI 10.1007/s11042-019-08355-w
   Deng YF., 2022, COMP BIOCHEM PHYS B, V43, P15
   Dong XQ., 2014, J CENT CHINA NORM U, V48, P656
   [段青玲 Duan Qingling], 2022, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V53, P353
   Duan Yan'e Duan Yan'e, 2015, Transactions of the Chinese Society of Agricultural Engineering, V31, P1
   [冯裕清 Feng Yuqing], 2022, [渔业现代化, Fishery Modernization], V49, P52
   Goutte C, 2005, LECT NOTES COMPUT SC, V3408, P345
   Hu ZG., 2013, RURAL NEW TECHNOL, V06, P21
   Huff DT, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/abcd17
   Idaszkin YL, 2013, J ZOOL, V290, P117, DOI 10.1111/jzo.12019
   [姜晓东 Jiang Xiaodong], 2020, [淡水渔业, Freshwater Fisheries], V50, P38
   Johnston D, 2002, AQUAC RES, V33, P785, DOI 10.1046/j.1365-2109.2002.00722.x
   Lalramchhani C, 2020, AQUAC RES, V51, P4165, DOI 10.1111/are.14758
   Li CY., 2022, GEOSPATIAL INF, V20, P89
   Li Honghan, 2019, arXiv
   [李鑫星 Li Xinxing], 2019, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V50, P376
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   [刘洋 Liu Yang], 2022, [渔业现代化, Fishery Modernization], V49, P89
   Luo RZ., 2009, COMPUTER APPL SOFTWA, V26, P223
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Pan X., 1989, MOD AGR, V1989, P32
   [孙龙清 Sun Longqing], 2019, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V50, P260
   [孙永文 Sun Yongwen], 2022, [海洋渔业, Marine Fisheries], V44, P103
   [邰伟鹏 Tai Weipeng], 2021, [中国海洋大学学报. 自然科学版, Periodical of Ocean University of China], V51, P138
   Tang WM., 2022, JIANGSU RURAL EC, V05, P68
   Wang CJ., 2019, OPT LASER TECHNOL, V15, P195
   Wang Hao, 2013, Journal of Southeast University (Natural Science Edition), V43, P247, DOI 10.3969/j.issn.1001-0505.2013.02.004
   Wang JA., 2017, J HUNAN U ARTS SCI S, V29, P35
   Wang SX, 2022, FISH RES, V248, DOI 10.1016/j.fishres.2022.106226
   [王书献 Wang Shuxian], 2021, [大连海洋大学学报, Journal of Dalian Ocean University], V36, P842
   Wang Y.D., 2022, Science and Technology Innovation, V22, P72
   [薛联青 Xue Lianqing], 2022, [水资源保护, Water Resources Protection], V38, P13
   Yang D., 2019, Fisheries Inf Strategy, V31, P112, DOI DOI 10.13233/J.CNKI.FISHIS.2019.02.006
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Ye G., 2022, PHYS REV LETT, V18, P100
   Yin L., 2022, BRIT J NUTR, V49, P193
   Yu HC, 2006, INT C PATT RECOG, P181
   Zhang B.L., 2014, Sci. Fish. Farming, V2, P77
   Zhang DQ, 2005, NEUROCOMPUTING, V69, P224, DOI 10.1016/j.neucom.2005.06.004
   Zhang J., 2022, FRONT MAR SCI, V9, P1400
   Zhang JZ., 2022, S CHINA FISH SCI, V18, P1
   [张胜茂 Zhang Shengmao], 2017, [大连海洋大学学报, Journal of Dalian Ocean University], V32, P493
   Zhao LH, 2007, INT C WAVEL ANAL PAT, P1213
   Zhao YF., 2018, FRONT PHYSIOL, V2018, P148
   Zheng CC, 2021, N AM J FISH MANAGE, V41, P891, DOI 10.1002/nafm.10396
   Zhu PY, 2019, J FOOD PROCESS ENG, V42, DOI 10.1111/jfpe.13095
NR 50
TC 2
Z9 2
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42527
EP 42543
DI 10.1007/s11042-023-15228-w
EA APR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000970495100008
DA 2024-07-18
ER

PT J
AU Shad, R
   Seyyed-Al-hosseini, ST
   Mehrani, YM
   Ghaemi, M
AF Shad, Rouzbeh
   Seyyed-Al-hosseini, Seyyed Tohid
   Mehrani, Yaser Maghsoodi
   Ghaemi, Marjan
TI Ensemble of Support Vector Machines for spectral-spatial classification
   of hyperspectral and multispectral images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Support vector machine; Spectral and spatial information; Direct
   summation of kernels; Weighted summation of kernels; Ensemble
   classifiers; Satellite images
ID MULTICLASS CLASSIFICATION
AB Previous studies on different satellite images have not yet introduced a single attribute with the highest accuracy for different applications. In this paper, a novel classification system with the highest strength against possible noises is offered using Support Vector Machine (SVM) and its performance is evaluated on the selected satellite images. So, an optimal high-strength classifier with the sufficient level of accuracy is proposed executing Composite Kernels and Ensemble of Classifiers. Results obtained from applying this method on IKONOS (91.65%) and AVIRIS (97.71%) satellite images (in Tehran and Indian Pine study areas) showed that the proposed method accuracy is higher than the Direct Summation of Kernels, Weighted Summation of Kernels, Cross Information Kernels and Extracted Features techniques. The main reason for this significant difference is the wide range and variety of input features.
C1 [Shad, Rouzbeh; Seyyed-Al-hosseini, Seyyed Tohid; Ghaemi, Marjan] Ferdowsi Univ Mashhad, Engn Fac, Civil Engn Dept, Mashhad, Iran.
   [Mehrani, Yaser Maghsoodi] KN Toosi Univ Technol, Geodesy & Geomat Fac, Remote Sensing Dept, Tehran, Iran.
C3 Ferdowsi University Mashhad; K. N. Toosi University of Technology
RP Shad, R (corresponding author), Ferdowsi Univ Mashhad, Engn Fac, Civil Engn Dept, Mashhad, Iran.
EM r.shad@um.ac.ir; Tohid_200970@yahoo.com; Ymaghsoudi@kntu.ac.ir;
   mghaemi270@gmail.com
RI Shad, Rouzbeh/AAA-4026-2020
OI Shad, Rouzbeh/0000-0003-2078-8571; Seyyed-Al-hosseini, Seyyed
   Tohid/0000-0002-6178-3876
CR Alpaydin E., 2010, Introduction to Machine Learning
   Ben Salem R, 2014, 2014 FIRST INTERNATIONAL IMAGE PROCESSING, APPLICATIONS AND SYSTEMS CONFERENCE (IPAS)
   Camps-Valls G, 2008, IEEE T GEOSCI REMOTE, V46
   Camps-Valls G., 2006, GEOSCI REMOTE SENS L, P3
   Canty M, 2014, IMAGE ANAL CLASSIFIC, P275
   Chen H, 2019, REMOTE SENS LETT, V10, P411, DOI 10.1080/2150704X.2018.1563838
   Chen Y., 2021, REMOTE SENS-BASEL, V13
   Chen Y, 2011, IEEE T GEOSCI REMOTE, V49, P3973, DOI 10.1109/TGRS.2011.2129595
   Dalla Mura M, 2011, IEEE GEOSCI REMOTE S, V8, P542, DOI 10.1109/LGRS.2010.2091253
   Dalla Mura M, 2010, INT J REMOTE SENS, V31, P5975, DOI 10.1080/01431161.2010.512425
   Ergul U, 2019, NEUROCOMPUTING, V334, P100, DOI 10.1016/j.neucom.2019.01.010
   Fan GF, 2020, INT J ELEC POWER
   Fauvel M, 2008, IEEE T GEOSCI REMOTE, V46, P3804, DOI 10.1109/TGRS.2008.922034
   Geijn Van de RA, 2011, NOTES CHOLESKY FACTO
   Gonzalesalonso F, 2010, INT J REMOTE SENS, V12
   Guillamet D., 2002, 16 INT C PATT REC
   Guo YH, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1346-z
   Hasan Hayder, 2019, IOP Conference Series: Earth and Environmental Science, V357, DOI 10.1088/1755-1315/357/1/012035
   Higham NJ., 2003, SOLVING NONLINEAR EQ
   Huang X, 2013, IEEE T GEOSCI REMOTE, V51, P257, DOI 10.1109/TGRS.2012.2202912
   Jain DK, 2018, J COMPUT SCI-NETH, V25, P252, DOI 10.1016/j.jocs.2017.07.016
   Ji R, 2014, IEEE T GEOSCI REMOTE, V52
   Jia XP, 2013, P IEEE, V101, P676, DOI 10.1109/JPROC.2012.2229082
   Karakatic S, 2016, INFORM FUSION, V31, P26, DOI 10.1016/j.inffus.2015.12.006
   Kavitha K, 2015, INT J INNOV RES SCI, V4
   Kuncheva LI, 2014, COMBINING PATTERN CLASSIFIERS: METHODS AND ALGORITHMS, 2ND EDITION, P1
   Li J, 2013, IEEE T GEOSCI REMOTE, V51
   Lv WJ, 2020, J SENSORS, V2020, DOI 10.1155/2020/4817234
   Majdar RS, 2017, INT J REMOTE SENS, V38, P4265, DOI 10.1080/01431161.2017.1317941
   Mura MD, 2010, T GEOSCI REMOTE SENS
   Okwuashi O, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107298
   Oza NC, 2008, INFORM FUSION, V9, P4, DOI 10.1016/j.inffus.2007.07.002
   Sesmero MP, 2015, INFORM FUSION, V24, P122, DOI 10.1016/j.inffus.2014.09.002
   Shang WT, 2019, APSIPA TRANS SIGNAL, V8, DOI 10.1017/ATSIP.2019.15
   Taylor JS., 2000, SUPPORT VECTOR MACHI
   Wang Y, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030441
   Waske B, 2007, IEEE T GEOSCI REMOTE, V45, P3858, DOI 10.1109/TGRS.2007.898446
   Wu TF, 2004, J MACH LEARN RES, V5, P975
   Zhu XD, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11101208
NR 39
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42119
EP 42146
DI 10.1007/s11042-023-14972-3
EA APR 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000963639900004
DA 2024-07-18
ER

PT J
AU Singh, H
   Rana, PS
   Singh, U
AF Singh, Harpreet
   Rana, Prashant Singh
   Singh, Urvinder
TI Evolutionary based drug synergy prediction using adaptive Levy based
   neural network structure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Drug synergy score; Neural network; Adaptive Levy
ID CANCER; COMBINATION; ALGORITHMS; ENSEMBLE; DESIGN
AB As cancer cases are looming large worldwide, the applications of data science and machine learning in these fields possess a greater scope especially when there is the availability of data containing the drug synergy score of different combinations. Predictive analytics holds the ability to generate a more efficient and accurate drug synergy score, that describes the synergies between interactions of two drugs. Various machine learning techniques have been designed so far for the prediction of drug synergy scores. However, parameter tuning is the primary issue for these techniques. To overcome this issue, an efficient and robust Evolutionary based Neural Network Structure using Adaptive Levy technique has been proposed. The existing machine learning techniques and this evolutionary-based technique are tested on the drug dataset to predict synergy score. As supported by comparative analysis, the findings of the proposed research outperform all the known techniques in terms of parameters like accuracy, coefficient of correlation, and RMSE.
C1 [Singh, Harpreet; Rana, Prashant Singh] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
   [Singh, Urvinder] Thapar Inst Engn & Technol, Elect & Commun Engn Dept, Patiala 147004, Punjab, India.
C3 Thapar Institute of Engineering & Technology; Thapar Institute of
   Engineering & Technology
RP Singh, H (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
EM akalharpreet@gmail.com; prashant.singh@thapar.edu; urvinders@gmail.com
FU NVIDIA Corporation
FX Our research gratefully acknowledge the support of NVIDIA Corporation
   with the donation of the Quadro P6000 GPU used for this research.
CR Belarbi K, 2000, IEEE T FUZZY SYST, V8, P398, DOI 10.1109/91.868946
   Bulusu KC, 2016, DRUG DISCOV TODAY, V21, P225, DOI 10.1016/j.drudis.2015.09.003
   Caponetto R, 2000, IEEE T FUZZY SYST, V8, P753, DOI 10.1109/91.890333
   Cassel JB, 2016, J PAIN SYMPTOM MANAG, V52, P437, DOI 10.1016/j.jpainsymman.2016.02.014
   Challenge D, 2015, CHALLENGE
   Chen HR, 2019, IEEE T NEUR NET LEAR, V30, P588, DOI 10.1109/TNNLS.2018.2844866
   Chen RL, 2018, MOLECULES, V23, DOI 10.3390/molecules23092208
   Cheng FX, 2014, J AM MED INFORM ASSN, V21, pE278, DOI 10.1136/amiajnl-2013-002512
   Cokol M, 2011, MOL SYST BIOL, V7, DOI 10.1038/msb.2011.71
   Ding SF, 2013, ARTIF INTELL REV, V39, P251, DOI 10.1007/s10462-011-9270-6
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Fu J, 2016, SYNERGY, V3, P15, DOI DOI 10.1016/J.SYNRES.2016.06.001
   Gao SC, 2019, IEEE T NEUR NET LEAR, V30, P601, DOI 10.1109/TNNLS.2018.2846646
   Geary N, 2013, AM J PHYSIOL-ENDOC M, V304, pE237, DOI 10.1152/ajpendo.00308.2012
   Gomathi S, 2022, WORLD J ENG, V19, P21, DOI 10.1108/WJE-09-2020-0450
   Goswami CP, 2015, CPT-PHARMACOMET SYST, V4, P80, DOI 10.1002/psp4.9
   Icke I, 2013, 2013 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P1763
   Jansen G, 2009, MOL SYST BIOL, V5, DOI 10.1038/msb.2009.95
   Jia J, 2009, NAT REV DRUG DISCOV, V8, P111, DOI 10.1038/nrd2683
   Jia XL, 2017, COMPUT BIOL CHEM, V67, P234, DOI 10.1016/j.compbiolchem.2017.01.010
   Juidette H, 2000, ELECTRON LETT, V36, P374, DOI 10.1049/el:20000314
   Larsson M, 2017, CANCER TREAT REV, V55, P128, DOI 10.1016/j.ctrv.2017.03.004
   Lazaridis G, 2008, CRIT REV ONCOL HEMAT, V66, P31, DOI 10.1016/j.critrevonc.2007.07.002
   Lee CY, 2001, IEEE C EVOL COMPUTAT, P568, DOI 10.1109/CEC.2001.934442
   Li H, 2013, EXPERT SYST, V30, P385, DOI 10.1111/j.1468-0394.2012.00642.x
   Li M., 1990, Proceedings. 5th IEEE International Symposium on Intelligent Control 1990 (Cat. No.90TH0333-5), P524, DOI 10.1109/ISIC.1990.128507
   Li MW, 2021, NONLINEAR DYNAM, V103, P1167, DOI 10.1007/s11071-020-06111-6
   Li S, 2011, BMC SYST BIOL, V5, DOI 10.1186/1752-0509-5-S1-S10
   Man KF, 1996, IEEE T IND ELECTRON, V43, P519, DOI 10.1109/41.538609
   Margolin AA, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S1-S7
   Martinez-Outschoorn U, 2014, SEMIN ONCOL, V41, P195, DOI 10.1053/j.seminoncol.2014.03.002
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Pang KF, 2014, BIOINFORMATICS, V30, P1456, DOI 10.1093/bioinformatics/btu046
   Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a
   Preuer K, 2018, BIOINFORMATICS, V34, P1538, DOI 10.1093/bioinformatics/btx806
   Puddicombe SM, 2000, FASEB J, V14, P1362, DOI 10.1096/fj.14.10.1362
   Roemer T, 2013, NAT CHEM BIOL, V9, P222, DOI [10.1038/NCHEMBIO.1205, 10.1038/nchembio.1205]
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Salgotra R, 2017, EXPERT SYST APPL, V79, P112, DOI 10.1016/j.eswa.2017.02.035
   Setnes M, 2000, IEEE T FUZZY SYST, V8, P509, DOI 10.1109/91.873575
   Singh H, 2019, IET SYST BIOL, V13, P24, DOI 10.1049/iet-syb.2018.5023
   Singh H, 2018, MOD PHYS LETT B, V32, DOI 10.1142/S0217984918501324
   Vikhar Pradnya A., 2016, 2016 International Conference on Global Trends in Signal Processing, Information Computing and Communication (ICGTSPICC). Proceedings, P261, DOI 10.1109/ICGTSPICC.2016.7955308
   Yang SX, 2004, IEEE T SYST MAN CY B, V34, P718, DOI 10.1109/TSMCB.2003.811769
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Yi N, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0093960
   Yin ZJ, 2018, FRONT PHARMACOL, V9, DOI 10.3389/fphar.2018.00535
   Zhang LX, 2007, P NATL ACAD SCI USA, V104, P4606, DOI 10.1073/pnas.0609370104
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
NR 49
TC 0
Z9 0
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40105
EP 40127
DI 10.1007/s11042-023-14536-5
EA APR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000983404900012
DA 2024-07-18
ER

PT J
AU Keshri, D
   Sriharsha, KV
   Alphonse, PJA
AF Keshri, Divakar
   Sriharsha, K. V.
   Alphonse, P. J. A.
TI Depth perception in single camera system using focus blur and aperture
   number
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aperture number fstop; Auto focusing mode; Defocus; Exposure time; Film
   speed; Focal length
AB This article discusses a depth prediction model that takes advantage of rich interpretations. Profundity assessment is a basic interest for scene understanding and exact 3D reproduction. Latest methodologies with profound learning exploit mathematical designs of standard sharp pictures to foresee profundity maps. In any case, cameras can likewise deliver pictures with defocus obscure contingent upon the profundity of the articles and camera settings. Subsequently, these highlights might address a significant clue for figuring out how to foresee profundity. In this article, we postulate a full framework for single-picture profundity expectation by estimating the level of obscure w.r.t real profundity by bringing the picture in to concentrate just on pre-characterized focal point numbers. As a result, these characteristics may provide a crucial clue for studying to predict depth. These lens numbers indicate the distance at which the lens is currently focused. We also intend to know the influence of lens aperture numbers on the depth estimated. For this stated goal,We introduce a new data set that has 477 images taken in real-time using a DSLR (Digital Single-Lens Reflex). For indoor pictures, a lens is coupled with ground truth depth data provided with a laser distance meter.On this new platform, the strategy has been a framework that supports new data set and is proved that the predicted depth estimates correlate with ground truth by 98.7 percent with an 8.647 Std Error estimate. When compared to recent research on stereo vision and other non-triangulation techniques proposed so far, the depth estimations derived from the proposed model approximates the ground truth with RMSE of 0.05 and display around 98.7 percent correlation wrt ground truth data. Depth estimation strategy using a Single RGB cameras are proved efficient in computing depth estimates from blur with 99 percent accuracy, which is not in an earlier case. Our proposed model evidently works well with both sharp and blur images in computing depth estimates up to 3.3 meters range irrespective of whether an image is in focus or out of focus.
C1 [Keshri, Divakar; Alphonse, P. J. A.] Natl Inst Technol, Dept Comp Applicat, Tiruchirappalli 620015, Tamilnadu, India.
   [Sriharsha, K. V.] Centurion Univ Technol & Management, Dept Comp Sci & Engn, Mandal 535003, Andhra Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli; Centurion University of Technology &
   Management
RP Keshri, D (corresponding author), Natl Inst Technol, Dept Comp Applicat, Tiruchirappalli 620015, Tamilnadu, India.
EM keshri9@gmail.com; alphonse@nitt.edu
OI Keshri, Divakar/0000-0002-8268-3233
CR Alphonse PJA, 2021, SN APPL SCI, V3, DOI 10.1007/s42452-021-04212-4
   [Anonymous], 2014, 2014 IEEE International Conference on Computational Photography (ICCP)
   Chen Shan-shan, 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P403, DOI 10.1109/ICCSN.2011.6014298
   Chen YJ, 2016, OPTIK, V127, P763, DOI 10.1016/j.ijleo.2015.10.171
   Hamzah RA, 2016, J SENSORS, V2016, DOI 10.1155/2016/8742920
   Kytö M, 2011, PROC SPIE, V7864, DOI 10.1117/12.872015
   Monteiro NB, 2018, COMPUT VIS IMAGE UND, V168, P104, DOI 10.1016/j.cviu.2018.01.010
   Palmieri L, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030500
   Pertuz S, 2018, ISPRS J PHOTOGRAMM, V144, P38, DOI 10.1016/j.isprsjprs.2018.06.020
   Sánchez-Ferreira C, 2016, J BRAZ SOC MECH SCI, V38, P2039, DOI 10.1007/s40430-016-0596-5
   Trouvé P, 2013, APPL OPTICS, V52, P7152, DOI 10.1364/AO.52.007152
   Wahab M. N. A., 2011, 2011 IEEE Conference on Sustainable Utilization and Development in Engineering and Technology, P36, DOI 10.1109/STUDENT.2011.6089321
   Zhuo SJ, 2011, PATTERN RECOGN, V44, P1852, DOI 10.1016/j.patcog.2011.03.009
NR 13
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 41405
EP 41431
DI 10.1007/s11042-023-14528-5
EA MAR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000961632300007
DA 2024-07-18
ER

PT J
AU Baig, MA
   Moinuddin, AA
   Khan, E
   Ghanbari, M
AF Baig, Md Amir
   Moinuddin, Athar A.
   Khan, E.
   Ghanbari, M.
TI A versatile blind JPEG image quality assessment method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockiness; Blocking artifacts; JPEG; Image quality assessment;
   Distortion specific
ID STATISTICS; STRENGTH; ROBUST
AB It is well known that the images suffer from blocking artifacts when compressed by JPEG at low quality factors. Since JPEG uses a standard block size of 8x8 pixels, then the locations of blocking artifacts are known and occur at the boundaries of multiples of 8th pixel positions in horizontal and vertical directions. There exist a number of state-of-the-art algorithms capable of estimating the blockiness in the image for such situations. However, when an image is arbitrarily cropped or resized, the locations of block boundaries and block size are unknown and the existing block-based algorithms either fail or are not robust. For such situations, a simple no-reference method in pixel-domain is proposed in this paper. It is based on the observation that the ratio of inter-block pixel difference to the average of the two neighbouring intra-block pixel differences is likely to be higher for images compressed at lower quality factor. Therefore, the average of this ratio computed across the image is an indicator of strength of blockiness and is used as a quality metric. Unlike existing algorithms, the proposed method can be applied to images with known as well as unknown block boundaries and is robust to block misalignment making it capable of measuring the blockiness even in arbitrarily cropped and resized images. The Spearman's-rank-order-correlation-coefficient between the quality score and subjective rating of images is computed for seven standard image databases. It is observed that the proposed method gives consistent performance with higher correlation values than most of the competitive state-of-the-art blockiness measuring algorithms. The computational complexity analysis shows that despite the high accuracy, the proposed method has lower complexity.
C1 [Baig, Md Amir] Aligarh Muslim Univ, Univ Womens Polytech, Z H Coll Engn & Technol, Aligarh, India.
   [Moinuddin, Athar A.; Khan, E.] Aligarh Muslim Univ, Z H Coll Engn & Technol, Dept Elect Engn, Aligarh, India.
   [Ghanbari, M.] Univ Essex, Sch Comp Sci & Elect Engn, Colchester, England.
C3 Aligarh Muslim University; Zakir Husain College Of Engineering &
   Technology; Zakir Husain College Of Engineering & Technology; Aligarh
   Muslim University; University of Essex
RP Baig, MA (corresponding author), Aligarh Muslim Univ, Univ Womens Polytech, Z H Coll Engn & Technol, Aligarh, India.
EM amir.jvwu@gmail.com; atharamoin@gmail.com; ekhan67@gmail.com;
   ghan@essex.ac.uk
OI BAIG, MD AMIR/0000-0002-4607-3286
FU MeitY, Government of India [MEITY-PHD-562]
FX This publication is an outcome of the R&D project carried out under the
   Visvesvaraya PhD scheme (Unique Awardee Number is MEITY-PHD-562) of
   MeitY, Government of India. The MATLAB P-files of the proposed method
   are publicly available at
   https://github.com/MdAmirBaig/IQA-of-JPEG-compressed-image.
CR Babu RV, 2007, SIGNAL PROCESS, V87, P1493, DOI 10.1016/j.sigpro.2006.12.014
   Chen CH, 2010, LECT NOTES COMPUT SC, V6297, P112, DOI 10.1007/978-3-642-15702-8_11
   Corchs S, 2014, DIGIT SIGNAL PROCESS, V30, P86, DOI 10.1016/j.dsp.2014.04.003
   Fang RG, 2017, IEEE T CIRC SYST VID, V27, P1381, DOI 10.1109/TCSVT.2016.2539658
   Golestaneh S. Alireza, 2014, IEEE Signal Processing Letters, V21, P155, DOI 10.1109/LSP.2013.2296038
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gunawan IP, 2008, IEEE T BROADCAST, V54, P669, DOI 10.1109/TBC.2008.2000734
   Larson E C, 2009, Categorical Image Quality (CSIQ) database [EB/OL]
   Le Callet P., 2005, Subjective quality assessment irccyn/ivc database
   Lee S, 2012, SIGNAL PROCESS-IMAGE, V27, P31, DOI 10.1016/j.image.2011.08.002
   Li LD, 2015, J VIS COMMUN IMAGE R, V30, P153, DOI 10.1016/j.jvcir.2015.04.001
   Li LD, 2014, IEEE SIGNAL PROC LET, V21, P122, DOI 10.1109/LSP.2013.2294333
   Lim CL, 2016, J FRANKLIN I, V353, P4715, DOI 10.1016/j.jfranklin.2016.08.012
   Liu H, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/263540
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Meesters L, 2002, SIGNAL PROCESS, V82, P369, DOI 10.1016/S0165-1684(01)00177-3
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Nafchi HZ, 2016, IEEE SIGNAL PROC LET, V23, P1577, DOI 10.1109/LSP.2016.2608865
   Nakhaei AA, 2018, IET IMAGE PROCESS, V12, DOI 10.1049/iet-ipr.2017.0916
   Pan F, 2004, 2004 IEEE INT S CIRC, V3, pIII
   Ponomarenko N, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P407
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Saha A, 2015, IEEE T IMAGE PROCESS, V24, P1879, DOI 10.1109/TIP.2015.2411436
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Tan KT, 2000, IEEE SIGNAL PROC LET, V7, P213, DOI 10.1109/97.855443
   Tang CY, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0165664
   Venkatanath N, 2015, NATL CONF COMMUN
   Wang Z, 2002, IEEE IMAGE PROC, P477
   Wang Z, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P981, DOI 10.1109/ICIP.2000.899622
   Wang Z., 2006, SYNTHESIS LECT IMAGE, V1, P1, DOI DOI 10.1007/978-3-031-02238-8
   Wang Z., 2016, Electron. Imag., V2016, P1
   Wu HR, 1997, IEEE SIGNAL PROC LET, V4, P317, DOI 10.1109/97.641398
   Wu JJ, 2019, J VIS COMMUN IMAGE R, V58, P353, DOI 10.1016/j.jvcir.2018.12.005
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Yang C, 2021, IEEE T MULTIMEDIA, V23, P1557, DOI 10.1109/TMM.2020.3001537
   Zaric A, 2012, AUTOMATIKA, V53, P344, DOI 10.7305/automatika.53-4.241
   Zhan YB, 2017, IEEE SIGNAL PROC LET, V24, P760, DOI 10.1109/LSP.2017.2688371
NR 41
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36395
EP 36412
DI 10.1007/s11042-023-14983-0
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN8D9
UT WOS:000983783100012
DA 2024-07-18
ER

PT J
AU Bastanfard, A
   Abbasian, A
AF Bastanfard, Azam
   Abbasian, Alireza
TI Speech emotion recognition in Persian based on stacked autoencoder by
   comparing local and global features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech emotion recognition; Stacked autoencoder; Persian language; Deep
   learning
ID NEURAL-NETWORK; CLASSIFICATION; DATABASES; NN
AB Among the barriers to establishing effective human-machine interactions is the machines' inability to properly distinguish emotions from the human voice. The Speech Emotion Recognition (SER) systems have emerged to tackle this limitation. The accuracy of these systems depends on different factors such as the quantity and the types of emotions included in the database, feature extraction process including local and global features, feature selection method, and the type of classifier. This study presents a methodology for speech emotion recognition using an autoencoder neural network. It is shown that using a digit-level stacked autoencoder can be suitable for digit classification. The speech emotion recognition is done using the Persian emotional speech database (Persian ESD), which includes six emotional states: Happiness, Sadness, Fear, Disgust, Anger, and Neutral. Moreover, the popular, widely-used Berlin Emotional database (EMO-DB) is used to evaluate the effectiveness of the proposed approach. The experimental results show that the proposed method has significantly improved recognition accuracy.
C1 [Bastanfard, Azam] Islamic Azad Univ, Dept Comp Engn, Karaj Branch, Karaj, Iran.
   [Abbasian, Alireza] Iran Broadcasting Univ, Fac Media Engn, Tehran, Iran.
C3 Islamic Azad University
RP Bastanfard, A (corresponding author), Islamic Azad Univ, Dept Comp Engn, Karaj Branch, Karaj, Iran.
EM bastanfard@kiau.ac.ir; a7abbasian@gmail.com
RI Bastanfard, Azam/AAX-8571-2020
OI Bastanfard, Azam/0000-0002-7935-819X
CR Akçay MB, 2020, SPEECH COMMUN, V116, P56, DOI 10.1016/j.specom.2019.12.001
   Albornoz EM, 2011, COMPUT SPEECH LANG, V25, P556, DOI 10.1016/j.csl.2010.10.001
   [Anonymous], 2006, P INT S CHIN SPOK LA
   [Anonymous], 2015, 2015 7 C INFORM KNOW, DOI DOI 10.1109/IKT.2015.7288756
   Badshah AM, 2019, MULTIMED TOOLS APPL, V78, P5571, DOI 10.1007/s11042-017-5292-7
   Bashirpour M, 2018, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-018-0133-9
   Bastanfard A, 2009, LECT NOTES COMPUT SC, V5879, P1080, DOI 10.1007/978-3-642-10467-1_104
   Bitouk D, 2010, SPEECH COMMUN, V52, P613, DOI 10.1016/j.specom.2010.02.010
   Borchert M, 2005, Proceedings of the 2005 IEEE International Conference on Natural Language Processing and Knowledge Engineering (IEEE NLP-KE'05), P147
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Cibau NeriE., 2013, ANALES 15 REUNION PR, V16, P934
   Daneshfar F, 2020, MULTIMED TOOLS APPL, V79, P1261, DOI 10.1007/s11042-019-08222-8
   Dangol R, 2020, MULTIMED TOOLS APPL, V79, P32917, DOI 10.1007/s11042-020-09693-w
   Deng J, 2017, IEEE SIGNAL PROC LET, V24, P500, DOI 10.1109/LSP.2017.2672753
   Deng J, 2013, INT CONF AFFECT, P511, DOI 10.1109/ACII.2013.90
   Dissanayake V, 2020, INTERSPEECH, P526, DOI 10.21437/Interspeech.2020-1356
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Esmaileyan Z, 2014, INT J ENG-IRAN, V27, P79, DOI 10.5829/idosi.ije.2014.27.01a.11
   Javidi MM, 2013, J MATH COMPUT SCI-JM, V6, P191
   Keshtiari N., 2016, International Journal of Society, Culture & Language, V4, P71
   Keshtiari N, 2015, BEHAV RES METHODS, V47, P275, DOI 10.3758/s13428-014-0467-x
   Langari S., 2020, Inf. Med. Unlocked, V20, DOI DOI 10.1016/J.IMU.2020.100424
   Lanjewar RB, 2015, PROCEDIA COMPUT SCI, V49, P50, DOI 10.1016/j.procs.2015.04.226
   Latif S, 2022, IEEE T AFFECT COMPUT, V13, P992, DOI 10.1109/TAFFC.2020.2983669
   Lee J, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1537
   Li LF, 2013, INT CONF AFFECT, P312, DOI 10.1109/ACII.2013.58
   Low LSA, 2011, IEEE T BIO-MED ENG, V58, P574, DOI 10.1109/TBME.2010.2091640
   Luengo I., 2005, INTERSPEECH 2005, P493
   Lugger M, 2007, INT CONF ACOUST SPEE, P17
   Mahdavi R, 2020, IEEE INT COMPUT C, P1
   Mansoorizadeh M, 2010, MULTIMED TOOLS APPL, V49, P277, DOI 10.1007/s11042-009-0344-2
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552
   Mustaqeem, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114177
   Nezami OM, 2019, LANG RESOUR EVAL, V53, P1, DOI 10.1007/s10579-018-9427-x
   Peipei Shen, 2011, 2011 International Conference on Electronic & Mechanical Engineering and Information Technology (EMEIT 2011), P621, DOI 10.1109/EMEIT.2011.6023178
   Pohjalainen J, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P670, DOI 10.1145/2964284.2967306
   Rao KS, 2013, INT J SPEECH TECHNOL, V16, P143, DOI 10.1007/s10772-012-9172-2
   RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512
   Savargiv M., 2014, Journal of Computer & Robotics, V7, P19
   Savargiv M, 2016, 2016 ARTIFICIAL INTELLIGENCE AND ROBOTICS (IRANOPEN), P72, DOI 10.1109/RIOS.2016.7529493
   Schuller B, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P865
   Schuller B, 2005, P INT 2005 P EUR C S
   Sedaaghi M, 2008, DOCUMENTATION SAHAND
   Shirani Amirreza, 2016, International Journal of Image, Graphics and Signal Processing, V8, P40, DOI 10.5815/ijigsp.2016.04.05
   Swain M, 2018, INT J SPEECH TECHNOL, V21, P93, DOI 10.1007/s10772-018-9491-z
   Vasuki P., 2015, Res J Appl Sci Eng Technol, V9, P1105, DOI DOI 10.19026/RJASET.9.2604
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang KX, 2015, IEEE T AFFECT COMPUT, V6, P69, DOI 10.1109/TAFFC.2015.2392101
   Wani TM, 2021, IEEE ACCESS, V9, P47795, DOI 10.1109/ACCESS.2021.3068045
   Wu SQ, 2011, SPEECH COMMUN, V53, P768, DOI 10.1016/j.specom.2010.08.013
   Yadav SP, 2022, ARCH COMPUT METHOD E, V29, P1753, DOI 10.1007/s11831-021-09647-x
   Yang B, 2010, SIGNAL PROCESS, V90, P1415, DOI 10.1016/j.sigpro.2009.09.009
   Yang Yali, 2022, Machine Learning and Intelligent Communications: 6th EAI International Conference, MLICOM 2021,Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (438), P315, DOI 10.1007/978-3-031-04409-0_29
   Yazdani A, 2021, 2021 IEEE INT C COMP, P374
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
NR 57
TC 2
Z9 2
U1 8
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36413
EP 36430
DI 10.1007/s11042-023-15132-3
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN8D9
UT WOS:000983783100003
DA 2024-07-18
ER

PT J
AU Ren, HW
   Yang, XY
AF Ren, Huwei
   Yang, Xiaoyuan
TI WeightFace: weight adaptive scaling loss for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Adaptive scaling; Loss function; Deep learning
ID MARGIN LOSS
AB The discriminability between distinct classes in the embedding space is improved by margin-based loss functions like SphereFace, CosFace and Arcface. More recently, face quality is introduced to face recognition to adaptively adjust the margin. However, these methods ignore the class imbalance problem, which affects the distribution of each class in the real embedding space and misleads the classification results of minority class. In this paper, a novel loss (WeightFace) is proposed to learn the scale parameter adaptively guided by class weight to address the class imbalance problem. We have proved that the minority class requires a larger scale parameter, since the minority class get a relatively smaller gradient so that the minority class has an intra-class variation comparable to the majority class. The weight magnitude is used to connect classes and scale parameters. This allows different classes distributing properly in real space and the test accuracy is boosted. Extensive experiments on popular benchmarks demonstrate the superiority of our WeightFace over state-of-the-arts.
C1 [Ren, Huwei; Yang, Xiaoyuan] Beihang Univ, Sch Math Sci, Beijing 102206, Peoples R China.
C3 Beihang University
RP Yang, XY (corresponding author), Beihang Univ, Sch Math Sci, Beijing 102206, Peoples R China.
EM 13031016060@163.com; xiaoyuanyang@vip.163.com
FU National Natural Science Foundation of China [61671002]
FX The experiments in this paper are conducted on the High Performance
   Computing Platform of Beihang University and the Supercomputing Platform
   of School of Mathematical Sciences. This work is supported by the
   National Natural Science Foundation of China under Grant 61671002.
CR Boutros F, 2022, IEEE COMPUT SOC CONF, P1577, DOI 10.1109/CVPRW56347.2022.00164
   Boutros F, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108473
   Chen S, 2018, LECT NOTES COMPUT SC, V10996, P428, DOI 10.1007/978-3-319-97909-0_46
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang C, 2020, IEEE T PATTERN ANAL, V42, P2781, DOI 10.1109/TPAMI.2019.2914680
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Huang YG, 2020, PROC CVPR IEEE, P5900, DOI 10.1109/CVPR42600.2020.00594
   Khalil U, 2022, IEEE ACCESS, V10, P76805, DOI [10.1109/ACCESS.2022.3189998, 10.30495/admt.2022.1937484.1302]
   Kim M, 2022, 2002 IEEE CVF C COMP, V738, P729
   Krawczyk B, 2014, APPL SOFT COMPUT, V14, P554, DOI 10.1016/j.asoc.2013.08.014
   Li S, 2021, PROC CVPR IEEE, P15624, DOI 10.1109/CVPR46437.2021.01537
   Li Y, 2019, MULTIMED TOOLS APPL, P1
   Ling HF, 2020, MULTIMED TOOLS APPL, V79, P5595, DOI 10.1007/s11042-019-08422-2
   Liu BY, 2019, IEEE I CONF COMP VIS, P10051, DOI 10.1109/ICCV.2019.01015
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Liu WY, 2016, PR MACH LEARN RES, V48
   Mao HZ, 2017, IEEE COMPUT SOC CONF, P1927, DOI 10.1109/CVPRW.2017.241
   Maze B, 2018, INT CONF BIOMETR, P158, DOI 10.1109/ICB2018.2018.00033
   Meng Q, 2021, PROC CVPR IEEE, P14220, DOI 10.1109/CVPR46437.2021.01400
   Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250
   Paszke Adam, 2017, NIPS W
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sengupta S, 2016, IEEE WINT CONF APPL
   Singh R, 2017, MULTIMED TOOLS APPL, V76, P19005, DOI 10.1007/s11042-016-4342-x
   Sun Y, 2014, 28 C NEURAL INFORM P
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tang YC, 2009, IEEE T SYST MAN CY B, V39, P281, DOI 10.1109/TSMCB.2008.2002909
   Wang F, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1041, DOI 10.1145/3123266.3123359
   Wang F, 2018, IEEE SIGNAL PROC LET, V25, P926, DOI 10.1109/LSP.2018.2822810
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang X, 2020, 34 AAAI C ART INT, V248, P241
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Whitelam C, 2017, IEEE COMPUT SOC CONF, P592, DOI 10.1109/CVPRW.2017.87
   Wu Y, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P408, DOI 10.1145/3126636.3126693
   Yi Dong, 2014, ARXIV14117923
   Yin X., 2018, ARXIV
   Zhang X, 2019, PROC CVPR IEEE, P10815, DOI 10.1109/CVPR.2019.01108
   Zhang X, 2017, IEEE I CONF COMP VIS, P5419, DOI 10.1109/ICCV.2017.578
   Zheng T., 2018, Tech. Rep., V5
   Zheng T., 2017, ARXIV
   Zhong YY, 2021, IEEE T IMAGE PROCESS, V30, P2587, DOI 10.1109/TIP.2020.3048632
NR 47
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36633
EP 36646
DI 10.1007/s11042-023-15085-7
EA MAR 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000960423600003
DA 2024-07-18
ER

PT J
AU Alamgir, FM
   Alam, MS
AF Alamgir, Fakir Mashuque
   Alam, Md. Shafiul
TI Hybrid multi-modal emotion recognition framework based on
   InceptionV3DenseNet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-modal emotion recognition; Audio features; Video features; Textual
   features; Feature extraction; Feature fusion; Classification; Deep
   learning
AB Emotion recognition is one of the most complex research areas as individuals express emotional cues based on several modalities such as audio, facial expressions, and language. The recognition of emotion from one of the modalities is not always feasible as the single modalities are disturbed by several factors. The existing models cannot attain the maximum accuracy in exactly identifying the expressions of individuals. In this paper, a novel hybrid multi-modal emotion recognition framework InceptionV3DenseNet is proposed for improving the recognition accuracy. Initially contextual features are extracted from different modalities such as video, audio and text. From the video modality, the features such as shot length, lighting key, motion and color are extracted. Zero-crossing rate, Mel frequency cepstral coefficient (MFCC), energy and pitch are extracted from the audio modality and the unigram, bigram and TF-IDF are extracted from the textual modality. In feature extraction, high level features are extracted with better generalization capability. The extracted features are fused using the multi-set integrated canonical correlation analysis (MICCA) and are provided as the input to the proposed hybrid network model. It detects the correlation between multimodal features to provide better performance with single learning phase. Then the proposed hybrid deep learning model is utilized to classify emotional states by considering the accuracy and reliability. The work simulations are conducted in the MATLAB platform and evaluated using the MELD and RAVDESS datasets. The outcomes proved that the proposed model is more efficient and accurate than the compared models and attained an overall accuracy rate of 74.87% in MELD and 95.25% in RAVDESS.
C1 [Alamgir, Fakir Mashuque; Alam, Md. Shafiul] Univ Dhaka, Dept Elect & Elect Engn, Dhaka, Bangladesh.
C3 University of Dhaka
RP Alamgir, FM (corresponding author), Univ Dhaka, Dept Elect & Elect Engn, Dhaka, Bangladesh.
EM fma@ewubd.edu
CR Abdullah SMSA., 2021, Journal of Applied Science and Technology Trends, V2, P52
   [Anonymous], 2015, 2015 7 C INFORM KNOW, DOI DOI 10.1109/IKT.2015.7288756
   Bastanfard A, 2019, 2019 IEEE 5TH CONFERENCE ON KNOWLEDGE BASED ENGINEERING AND INNOVATION (KBEI 2019), P592, DOI 10.1109/KBEI.2019.8735005
   Bastanfard A, 2009, LECT NOTES COMPUT SC, V5879, P1080, DOI 10.1007/978-3-642-10467-1_104
   Cevher D, 2019, Arxiv, DOI arXiv:1909.02764
   Chang X, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165452
   Cimtay Y, 2020, IEEE ACCESS, V8, P168865, DOI 10.1109/ACCESS.2020.3023871
   Correa NM, 2010, NEUROIMAGE, V50, P1438, DOI 10.1016/j.neuroimage.2010.01.062
   Dai WL, 2020, Arxiv, DOI arXiv:2009.09629
   Granger E., 2021, arXiv
   Guo JJ, 2019, IEEE ENG MED BIO, P3071, DOI [10.1109/EMBC.2019.8856563, 10.1109/embc.2019.8856563]
   Hashim FA, 2022, MATH COMPUT SIMULAT, V192, P84, DOI 10.1016/j.matcom.2021.08.013
   He ZP, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10100687
   Huan RH, 2021, MULTIMED TOOLS APPL, V80, P8213, DOI 10.1007/s11042-020-10030-4
   Huang HP, 2020, IEEE ACCESS, V8, P3265, DOI 10.1109/ACCESS.2019.2962085
   Li JL, 2019, INTERSPEECH, P211, DOI 10.21437/Interspeech.2019-2044
   Li Y, 2019, ADV ROBOTICS, V33, P1030, DOI 10.1080/01691864.2019.1667872
   Liu D, 2021, J GRID COMPUT, V19, DOI 10.1007/s10723-021-09564-0
   Liu W, 2019, Arxiv, DOI arXiv:1908.05349
   Mahdavi R, 2020, IEEE INT COMPUT C, P1
   Mittal T, 2020, AAAI CONF ARTIF INTE, V34, P1359
   Nemati S, 2019, IEEE ACCESS, V7, P172948, DOI 10.1109/ACCESS.2019.2955637
   Ho NH, 2020, IEEE ACCESS, V8, P61672, DOI 10.1109/ACCESS.2020.2984368
   Panda Debadrita, 2020, Proceedings of the Global AI Congress 2019. Advances in Intelligent Systems and Computing (AISC 1112), P399, DOI 10.1007/978-981-15-2188-1_32
   Radoi A, 2021, IEEE ACCESS, V9, P135559, DOI 10.1109/ACCESS.2021.3116530
   Rahdari F, 2019, IJST-T ELECTR ENG, V43, P171, DOI 10.1007/s40998-018-0142-9
   Savargiv M, 2016, 2016 ARTIFICIAL INTELLIGENCE AND ROBOTICS (IRANOPEN), P72, DOI 10.1109/RIOS.2016.7529493
   Savargiv M, 2013, 2013 INTERNATIONAL CONFERENCE ON FUZZY THEORY AND ITS APPLICATIONS (IFUZZY 2013), P380, DOI 10.1109/iFuzzy.2013.6825469
   Shahin I, 2022, EXPERT SYST APPL, V188, DOI 10.1016/j.eswa.2021.116080
   Siddiqui MFH, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4030046
   Singh P, 2021, KNOWL-BASED SYST, V229, DOI 10.1016/j.knosys.2021.107316
   Siriwardhana S, 2020, IEEE ACCESS, V8, P176274, DOI 10.1109/ACCESS.2020.3026823
   Veni S., 2021, IOP C SERIES MAT SCI, V1084
   Xie BJ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144913
   Xu HY, 2020, Arxiv, DOI arXiv:1909.05645
   Xu N., 2019, AAAI, P371
   Yalamanchili B, 2021, MACHINE LEARNING TEC, P319
   Yin GH, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3490686
   Yu C, 2019, LECT NOTES ARTIF INT, V11876, P633, DOI 10.1007/978-3-030-35888-4_59
   Yuan YH, 2011, PATTERN RECOGN, V44, P1031, DOI 10.1016/j.patcog.2010.11.004
   Zhang G, 2020, IEEE ACCESS, V8, P55688, DOI 10.1109/ACCESS.2020.2981760
   Zhang HL, 2020, IEEE ACCESS, V8, P164130, DOI 10.1109/ACCESS.2020.3021994
   Zhao Y, 2021, COMPUT MATH METHOD M, V2021
NR 43
TC 1
Z9 1
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40375
EP 40402
DI 10.1007/s11042-023-15066-w
EA MAR 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000983485500005
DA 2024-07-18
ER

PT J
AU Jitendra, MSNV
   Radhika, Y
AF Jitendra, Mukkamala S. N. V.
   Radhika, Y.
TI An ensemble model of CNN with Bi-LSTM for automatic singer
   identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bidirectional long short-term memory; CNN; Gender identification;
   LSTM-RNN; Music information retrieval; Singer identification;
   Spectrogram
ID CLASSIFICATION
AB In the present-day scenario, gender detection has become significant in content-based multimedia systems. An automated mechanism for gender identification is mainly in demand to process the massive data. Singer identification is a popular topic in music information recommender systems that includes identifying the singer from the song based on the singer's voice and other background key features like timbre and pitch. Many models like GMM, SVM, and MLP are broadly used for classification and singer identification. Moreover, most current models have limitations where vocals and instrumental music are separated manually, and only vocals are used to build and train the model. To deal with unstructured data like music, the deep learning techniques are very suitable and have exhibited exemplary performance in similar studies. In acoustic modeling, the Deep Neural Networks (DNN) models like convolutional neural networks (CNN) have played a promising role in classifying unstructured and poorly labeled data. In the current study, an ensemble model, a combination of a CNN model with bi-directional LSTM, is considered for singer identification from the spectrogram images generated from the audio clip. CNN models are proven to better handle variable-length input data by identifying the features. Bi-LSTM will yield better accuracy by remembering the essential features over time and addressing temporal contextual information. The experimentation is performed on the Indian songs and MIR-1 k data set, and it is observed that the proposed model has outperformed with a prediction accuracy of 97.4%. The performance of the proposed model is being compared against the existing models in the current study.
C1 [Jitendra, Mukkamala S. N. V.; Radhika, Y.] GITAM, GITAM Sch Technol, Dept Comp Sci & Engn, Visakhapatnam 530045, AP, India.
C3 Gandhi Institute of Technology & Management (GITAM)
RP Jitendra, MSNV (corresponding author), GITAM, GITAM Sch Technol, Dept Comp Sci & Engn, Visakhapatnam 530045, AP, India.
EM jitendra.mukkamala@gmail.com; ryalavar@gitam.edu
RI mukkamala, jitendra/ABI-5011-2020
OI mukkamala, jitendra/0000-0003-0007-8089
CR Alkhawaldeh RS, 2019, SCI PROGRAMMING-NETH, V2019, DOI 10.1155/2019/7213717
   Badshah AM, 2017, 2017 INTERNATIONAL CONFERENCE ON PLATFORM TECHNOLOGY AND SERVICE (PLATCON), P125
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bhatia R, 2018, INT CONF RELI INFO, P261, DOI 10.1109/ICRITO.2018.8748783
   Bjorkner E, 2006, THESIS KTH
   Costa YMG, 2017, APPL SOFT COMPUT, V52, P28, DOI 10.1016/j.asoc.2016.12.024
   Deshmukh SH., 2014, INT J COMPUTER APPL, V91, P1, DOI DOI 10.5120/15866-4804
   Dhar D, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351180
   Dharini D., 2014, 2014 International Conference on Communications and Signal Processing (ICCSP), P1927, DOI 10.1109/ICCSP.2014.6950180
   Fujihara H, 2010, IEEE T AUDIO SPEECH, V18, P638, DOI 10.1109/TASL.2010.2041386
   Goto M., 2002, P 3 INT C MUS INF RE, V2, P287
   Jitendra M, 2021, RECENT TRENDS INTENS, P80, DOI [10.3233/APC210182, DOI 10.3233/APC210182]
   Kooshan Seyed, 2019, 2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA), P246, DOI 10.1109/PRIA.2019.8786009
   Lagrange M, 2012, 13 INT SOC MUS INF R
   Leglaive S, 2015, INT CONF ACOUST SPEE, P121, DOI 10.1109/ICASSP.2015.7177944
   Lehner Bernhard, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7480, DOI 10.1109/ICASSP.2014.6855054
   Lehner B, 2015, EUR SIGNAL PR CONF, P21, DOI 10.1109/EUSIPCO.2015.7362337
   Li L, 2017, MUSIC TRANSCRIPTION
   Loni DY, 2019, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-019-0153-0
   Metilda Florence S., 2017, J CHEM PHARM SCI, V10, P462
   Mukkamala SNVJ, 2021, INT J ADV COMPUT SC, V12, DOI [10.14569/IJACSA.2021.0120218, DOI 10.14569/IJACSA.2021.0120218]
   Murthy YVS, 2018, INT CONF CONTEMP, P41
   Murthy YVS, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3177849
   Murthy YVS, 2018, EXPERT SYST APPL, V106, P77, DOI 10.1016/j.eswa.2018.04.005
   MURTHY YS, 2021, INT J SPEECH TECHNOL, P1
   Nameirakpam J, 2019, 2019 2 INT C INN EL, P238
   Passricha V, 2020, J INTELL SYST, V29, P1261, DOI 10.1515/jisys-2018-0372
   Patil HA, 2012, INT CONF ASIAN LANG, P145, DOI 10.1109/IALP.2012.33
   Ratanpara T, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0062-9
   Robinson T., 1996, Speech andSpeaker Recognition: Advanced Topics, P233, DOI 10.1007/978-1-4613-1367-0_10
   Sak H, 2014, INTERSPEECH, P338
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Sharma B, 2019, INTERSPEECH, P2020, DOI 10.21437/Interspeech.2019-1925
   Shen JL, 2009, ACM T INFORM SYST, V27, DOI 10.1145/1508850.1508856
   Sridhar R, 2008, INT C COMP ELEC ENG, P407, DOI 10.1109/ICCEE.2008.118
   Srinivasu PN, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.654
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Tasleem A, 2016, INT C ADV COMPUTING, P81
   Wai SL, 2010, THESIS MERAL PORTAL
   Weninger F, 2011, P 12 INT SOC MUS INF
   Zhang T, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P33
NR 41
TC 0
Z9 0
U1 7
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38853
EP 38874
DI 10.1007/s11042-023-14802-6
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000983485500009
DA 2024-07-18
ER

PT J
AU Mohamadi, S
   Aghazarian, V
   Hedayati, A
AF Mohamadi, Samad
   Aghazarian, Vahe
   Hedayati, Alireza
TI An effective profile expansion technique based on movie genres and user
   demographic information to improve movie recommendation systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommendation systems; Movie; Data sparsity; Demographic information;
   Genre
ID RELIABILITY; MODEL; RATINGS
AB Movie recommendation systems are efficient tools to help users find their relevant movies by investigating the previous interests of users. These systems are established on considering the ratings of users provided for movies in the past and using them to predict their interests in the future. However, users mainly provide insufficient ratings leading to make a problem called data sparsity. This problem makes reducing the effectiveness of movie recommendation systems. On the other hand, other available data such as genres of movies and demographic information of users play a vital role in assisting recommenders in order to better produce recommendations. This paper proposes a movie recommendation method utilizing the movies' genres and users' demographic information. In particular, we propose an effective model to evaluate the user's rating profile and determine the minimum number of ratings required to produce an accurate prediction. Then, appropriate virtual ratings are incorporated into the profiles with insufficient ratings to expand them. These virtual ratings are calculated using similarity values between users obtained by genres of movies and demographic information of users. Furthermore, an effective measure is introduced to determine how much an item is reliable. This measure guarantees the virtual ratings' reliability. Finally, unknown ratings for target user are predicted based on the expanded rating profiles. Experiments performed on two well-known movie recommendation datasets demonstrate that the proposed approach is more efficient than other compared recommenders.
C1 [Mohamadi, Samad; Aghazarian, Vahe; Hedayati, Alireza] Islamic Azad Univ, Dept Comp Engn, Cent Tehran Branch, Tehran, Iran.
C3 Islamic Azad University
RP Aghazarian, V (corresponding author), Islamic Azad Univ, Dept Comp Engn, Cent Tehran Branch, Tehran, Iran.
EM s.mohamadi@iauctb.ac.ir; v_aghazarian@iauctb.ac.ir;
   hedayati@iauctb.ac.ir
CR Ahmadian S, 2022, EXPERT SYST APPL, V187, DOI 10.1016/j.eswa.2021.115849
   Ahmadian S, 2019, J INF SCI, V45, P607, DOI 10.1177/0165551518808191
   Ahmadian S, 2019, MULTIMED TOOLS APPL, V78, P17763, DOI 10.1007/s11042-018-7079-x
   Ahmadian S, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P1139, DOI 10.1109/ASONAM.2018.8508723
   Ahmadian S, 2018, APPL INTELL, V48, P4448, DOI 10.1007/s10489-018-1219-x
   Ahmadian S, 2014, 2014 6TH CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT), P98, DOI 10.1109/IKT.2014.7030341
   Alonso S, 2019, IEEE ACCESS, V7, P41782, DOI 10.1109/ACCESS.2019.2905862
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Breitfuss A, 2021, FUTURE GENER COMP SY, V125, P715, DOI 10.1016/j.future.2021.06.001
   Cauteruccio F, 2020, KNOWL-BASED SYST, V187, DOI 10.1016/j.knosys.2019.06.028
   Chen B, 2021, NEUROCOMPUTING, V421, P105
   Chen XS, 2021, IEEE T MULTIMEDIA, V23, P484, DOI 10.1109/TMM.2020.2978618
   Chen YL, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102531
   Darban ZZ, 2022, EXPERT SYST APPL, V200, DOI 10.1016/j.eswa.2022.116850
   Formoso V, 2013, INFORM PROCESS MANAG, V49, P659, DOI 10.1016/j.ipm.2012.07.005
   Gan MX, 2021, EXPERT SYST APPL, V173, DOI 10.1016/j.eswa.2021.114695
   Huang LL, 2021, FRONT COMPUT SCI-CHI, V15, DOI 10.1007/s11704-020-9511-4
   Huang L, 2019, MULTIMED TOOLS APPL, V78, P8711, DOI 10.1007/s11042-018-6232-x
   Huang XW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P548, DOI 10.1145/3343031.3350893
   Indira K, 2019, MOBILE NETW APPL, V24, P1872, DOI 10.1007/s11036-019-01387-4
   Katarya R, 2017, EGYPT INFORM J, V18, P105, DOI 10.1016/j.eij.2016.10.002
   Khan ZY, 2021, ENG APPL ARTIF INTEL, V97, DOI 10.1016/j.engappai.2020.104066
   Li HZ, 2021, FRONT COMPUT SCI-CHI, V15, DOI 10.1007/s11704-020-0028-7
   Matoussek J, 2001, PROBABILISTIC METHOD
   Moradi P, 2016, INT CONF ADV ICT, P162, DOI 10.1109/ICTER.2016.7829914
   Moradi P, 2015, EXPERT SYST APPL, V42, P7386, DOI 10.1016/j.eswa.2015.05.027
   Moradi P, 2015, PHYSICA A, V436, P462, DOI 10.1016/j.physa.2015.05.008
   Natarajan S, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113248
   Neil D., 2009, P 26 ANN INT C MACH, P601
   Ortega F, 2021, INFORM SCIENCES, V553, P110, DOI 10.1016/j.ins.2020.12.001
   Polatidis N, 2016, EXPERT SYST APPL, V48, P100, DOI 10.1016/j.eswa.2015.11.023
   Qu T, 2021, NEUROCOMPUTING, V443, P262, DOI 10.1016/j.neucom.2021.02.037
   Rahmani H. A., 2019, AS INF RETR S, P66
   Rezaeimehr F, 2018, FUTURE GENER COMP SY, V78, P419, DOI 10.1016/j.future.2017.04.003
   Roy A, 2021, J INTELL INF SYST, V56, P485, DOI 10.1007/s10844-021-00637-w
   Salakhutdinov Ruslan, 2008, ADV NEURAL INFORM PR, P1257, DOI DOI 10.5555/2981562.2981720
   Sang L, 2021, IEEE T MULTIMEDIA, V23, P2019, DOI 10.1109/TMM.2020.3007330
   Tahmasebi F, 2021, MULTIMED TOOLS APPL, V80, P2339, DOI 10.1007/s11042-020-09768-8
   Tahmasebi H, 2021, NEURAL COMPUT APPL, V33, P1607, DOI 10.1007/s00521-020-05085-1
   Thakker U, 2021, MULTIMED TOOLS APPL, V80, P28647, DOI 10.1007/s11042-021-10965-2
   Walek B, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113452
   Wang DW, 2020, EXPERT SYST APPL, V160, DOI 10.1016/j.eswa.2020.113651
   Wei GS, 2021, IEEE T COMPUT SOC SY, V8, P589, DOI 10.1109/TCSS.2021.3055823
   Widiyaningtyas T, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00425-x
   Xia HS, 2021, ELECTRON MARK, V31, P295, DOI 10.1007/s12525-020-00435-2
   Xie H, 2015, ACM T KNOWL DISCOV D, V9, DOI 10.1145/2700386
   Yanbin Jiang, 2020, Neural Information Processing. 27th International Conference, ICONIP 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12533), P333, DOI 10.1007/978-3-030-63833-7_28
   Yuan XF, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102384
   Zayani CA, 2020, ONLINE INFORM REV, V44, P433, DOI 10.1108/OIR-02-2017-0068
NR 49
TC 1
Z9 1
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38275
EP 38296
DI 10.1007/s11042-023-15141-2
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000956327700001
DA 2024-07-18
ER

PT J
AU Jiji, GW
   Rajesh, A
   Kanagaraj, A
AF Jiji, G. Wiselin
   Rajesh, A.
   Kanagaraj, Ajitha
TI Analysis of schizophrenia using support vector machine classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SPM; SVM; SURF; Feature reduction; Classification
ID WHITE-MATTER; PATTERN-CLASSIFICATION; BRAIN; METAANALYSIS; GRAY; FMRI;
   DIAGNOSIS; VOLUME
AB Schizophrenia affects the substances of the brain, which decreases the volume of the brain and leads to mental disorder. This work deals with the study of using computer aided technique on early diagnose of schizophrenia. Statistical parametric mapping (SPM) is used to separate Gray matter, White matter, and Cerebrospinal fluid from Brain and computed the volume of the brain. We also executed 2D SURF and FAST features and identified the apt feature vector for diagnosing Schizophrenia accurately. Principal Component Analysis is used to find out the most promising feature vectors and SVM Classifier is used to diagnose whether the user was affected by Schizophrenia or not. During the analysis, it was found that FAST feature overperforms the SURF feature in early diagnose of Schizophrenia and results were compared with earlier work.
C1 [Jiji, G. Wiselin; Kanagaraj, Ajitha] Dr Sivanthi Aditanar Coll Engn, Dept Comp Sci & Engn, Thoothukudi, India.
   [Rajesh, A.] Indian Space Res Org, Vikram Sarabhai Space Ctr, Thiruvananthapuram 695022, Kerala, India.
C3 Department of Space (DoS), Government of India; Indian Space Research
   Organisation (ISRO); Vikram Sarabhai Space Center (VSSC)
RP Jiji, GW (corresponding author), Dr Sivanthi Aditanar Coll Engn, Dept Comp Sci & Engn, Thoothukudi, India.
EM jijivevin@yahoo.co.in; ajithakanagaraj6@gmail.com
CR Ashburner J, 1997, NEUROIMAGE, V6, P209, DOI 10.1006/nimg.1997.0290
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Chen L, 2020, PHYS ENG SCI MED, V43, P1151, DOI 10.1007/s13246-020-00920-0
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Dauvermann MR, 2013, NEUROIMAGE, V73, P16, DOI 10.1016/j.neuroimage.2013.01.063
   Du W, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00145
   Ford J, 2002, P ANN INT IEEE EMBS, P48, DOI 10.1109/IEMBS.2002.1134381
   Gogtay N, 2003, AM J PSYCHIAT, V160, P569, DOI 10.1176/appi.ajp.160.3.569
   Hiesh MH, 2013, IEEE ENG MED BIO, P6047, DOI 10.1109/EMBC.2013.6610931
   Honea R, 2005, AM J PSYCHIAT, V162, P2233, DOI 10.1176/appi.ajp.162.12.2233
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Jahmunah V, 2019, ARTIF INTELL MED, V100, DOI 10.1016/j.artmed.2019.07.006
   Jiji G. Wiselin, 2015, International Journal of Computers and Applications, V37, P168, DOI 10.1080/1206212X.2016.1188552
   Latha, 2017, 2017 4 INT C SIGNAL, P1
   Lawrie SM, 1998, BRIT J PSYCHIAT, V172, P110, DOI 10.1192/bjp.172.2.110
   Lu XB, 2016, MEDICINE, V95, DOI 10.1097/MD.0000000000003973
   Manohar L, 2018, J MED BIOL ENG, V38, P917, DOI 10.1007/s40846-017-0355-9
   Meisenzahl EM, 2008, SCHIZOPHR RES, V104, P44, DOI 10.1016/j.schres.2008.06.023
   Olabi B, 2011, BIOL PSYCHIAT, V70, P88, DOI 10.1016/j.biopsych.2011.01.032
   Paillère-Martinot ML, 2001, SCHIZOPHR RES, V50, P19, DOI 10.1016/S0920-9964(00)00137-7
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Savio A, 2015, NEUROCOMPUTING, V164, P154, DOI 10.1016/j.neucom.2015.01.079
   Schneider-Axmann T, 2006, J PSYCHIATR RES, V40, P646, DOI 10.1016/j.jpsychires.2005.04.009
   Shahamat H., 2015, J AI DATA MIN, V3, P30, DOI DOI 10.5829/ID0SI.JAIDM.2015.03.01.04
   Shenton ME, 2001, SCHIZOPHR RES, V49, P1, DOI 10.1016/S0920-9964(01)00163-3
   Singh Pawan Kumar, 2015, International Journal of Intelligent Systems Technologies and Applications, V14, P27
   Sui J, 2014, IEEE ENG MED BIO, P3889, DOI 10.1109/EMBC.2014.6944473
   Suzuki M, 2002, SCHIZOPHR RES, V55, P41, DOI 10.1016/S0920-9964(01)00224-9
   Tomazic T, 2019, PHILOS ETHICS HUM ME, V14, DOI 10.1186/s13010-019-0076-5
   Wright IC, 2000, AM J PSYCHIAT, V157, P16, DOI 10.1176/ajp.157.1.16
   Yoon U, 2007, NEUROIMAGE, V34, P1405, DOI 10.1016/j.neuroimage.2006.11.021
   Zarogianni E, 2013, NEUROIMAGE-CLIN, V3, P279, DOI 10.1016/j.nicl.2013.09.003
NR 32
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32505
EP 32517
DI 10.1007/s11042-023-14513-y
EA MAR 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000954480900008
DA 2024-07-18
ER

PT J
AU Zhao, Q
   Chang, Z
   Wang, ZW
AF Zhao, Qiang
   Chang, Zheng
   Wang, Ziwen
TI Research on the factors affecting accuracy of abstract painting
   orientation detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Orientation detection; Abstract paintings; Recognition accuracy; Image
   feature; Deep neural network
AB An abstract painting's hanging orientation directly affects how audiences judge its artistic value. Choosing the optimal hanging orientation can preserve the artist's primary intention, preserving the original aesthetic value to a greater extent. Aesthetic value is frequently influenced by human subjective consciousness. Previous approaches improved direction recognition accuracy only by improving the feature extraction method and deep learning network. For this paper, the key factors that can influence recognition accuracy (such as painting content, image features and learning models) were investigated in conjunction with painting skills to find an experimental setting method that can enhance recognition accuracy. Experiment results show that the content of the painting has the greatest impact on classification accuracy. Furthermore, the average accuracy can be increased to more than 90% by reducing the number of painting categories in a dataset and the number of directions to be classified. While the outcome is superior to the state of the art, it is one-sided to rely solely on the information in the abstract painting. A combination of eye tracker data and questionnaires will be used in the future to examine the effect of audience subjective feelings on orientation classification.
C1 [Zhao, Qiang] Univ Elect Sci & Technol China, Inst Elect & Informat Engn, Dongguan, Peoples R China.
   [Zhao, Qiang; Wang, Ziwen] Shanxi Univ, Sch Automation & Software Engn, Taiyuan, Peoples R China.
   [Chang, Zheng] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu, Peoples R China.
   [Chang, Zheng] Univ Jyvaskyla, Fac Informat Technol, POB 35, Jyvaskyla 40014, Finland.
C3 University of Electronic Science & Technology of China; Shanxi
   University; University of Electronic Science & Technology of China;
   University of Jyvaskyla
RP Zhao, Q (corresponding author), Univ Elect Sci & Technol China, Inst Elect & Informat Engn, Dongguan, Peoples R China.; Zhao, Q (corresponding author), Shanxi Univ, Sch Automation & Software Engn, Taiyuan, Peoples R China.
EM hmoe@vip.qq.com
RI Chang, Zheng/G-2873-2018
OI Chang, Zheng/0000-0003-3766-820X; Zhao, Qiang/0000-0002-9506-4140
FU National Natural Science Foundation of China [62102238]; Natural Science
   Foundation of Shanxi Province [20210302124555]
FX This work was supported in part by the project of the National Natural
   Science Foundation of China in 2022 under Grant 62102238, and in part by
   the project of the Natural Science Foundation of Shanxi Province in 2021
   under Grant 20210302124555.
CR Bai RW, 2019, IEEE GLOB COMM CONF, DOI 10.1109/globecom38437.2019.9013244
   Bai RY, 2021, KNOWL-BASED SYST, V227, DOI 10.1016/j.knosys.2021.107240
   Ciocca G, 2015, MULTIMED TOOLS APPL, V74, P3013, DOI 10.1007/s11042-013-1766-4
   Datar M, 2006, AUTOMATIC IMAGE ORIE
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hawley-Dolan A, 2011, PSYCHOL SCI, V22, P435, DOI 10.1177/0956797611400915
   Hongjian Zhan, 2020, Pattern Recognition and Artificial Intelligence. International Conference, ICPRAI 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12068), P538, DOI 10.1007/978-3-030-59830-3_46
   Johnson MG, 2010, PSYCHOL AESTHET CREA, V4, P161, DOI 10.1037/a0018155
   Joshi U, 2017, 2017 14TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2017), P103, DOI 10.1109/CRV.2017.59
   Khan AI, 2022, ENG APPL ARTIF INTEL, V114, DOI 10.1016/j.engappai.2022.104996
   Lelièvre P, 2021, J VISION, V21, DOI 10.1167/jov.21.5.9
   Li QJ, 2010, IEEE IMAGE PROC, P2665, DOI 10.1109/ICIP.2010.5651837
   Liu J, 2017, MULTIMED TOOLS APPL, V76, P1017, DOI 10.1007/s11042-015-3104-5
   Luo JB, 2003, SPATIAL VISION, V16, P429, DOI 10.1163/156856803322552757
   Mather G, 2012, I-PERCEPTION, V3, P18, DOI 10.1068/i0447aap
   Mokrzycki W, 2012, LECT NOTES COMPUT SC, V7594, P533, DOI 10.1007/978-3-642-33564-8_64
   Morra L, 2019, 2019 IEEE 23RD INTERNATIONAL SYMPOSIUM ON CONSUMER TECHNOLOGIES (ISCT), P118, DOI [10.1109/isce.2019.8901005, 10.1109/ISCE.2019.8901005]
   Santos I, 2021, NEURAL COMPUT APPL, V33, P121, DOI 10.1007/s00521-020-05565-4
   Sarker I, 2020, J BIG DATA-GER, V7
   Specker E, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0232083
   Stankovic RS, 2003, COMPUT ELECTR ENG, V29, P25, DOI 10.1016/S0045-7906(01)00011-8
   Tolstaya E, 2007, CONTENT BASED IMAGE
   Vailaya A, 2002, IEEE T IMAGE PROCESS, V11, P746, DOI [10.1109/TIP.2002.801590, 10.1109/TIP2002.801590]
   Wasilly K, 1926, POINT LINE PLANE
   Wu G., 2019, Comput. Eng. Softw, V40, P167
   Ye J, 2022, ELECTRONICS, V11
   Zhang L, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P95, DOI 10.1109/ACV.2002.1182164
   Zhang W., 2017, INT J SOCIAL BEHAV E, V11, P231, DOI [10.5281/zenodo.1128985, DOI 10.5281/ZENODO.1128985]
   Zhao Q, 2022, IEEE INTERNET THINGS, V9, P3704, DOI 10.1109/JIOT.2021.3098735
   Zhao Q, 2021, MULTIMED TOOLS APPL, V80, P27279, DOI 10.1007/s11042-021-10996-9
NR 30
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36231
EP 36254
DI 10.1007/s11042-023-15034-4
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000953336200008
DA 2024-07-18
ER

PT J
AU Karanwal, S
   Diwakar, M
AF Karanwal, Shekhar
   Diwakar, Manoj
TI Triangle and orthogonal local binary pattern for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local binary pattern (LBP); Triangle LBP (TLBP); Orthogonal LBP (OLBP);
   TAO-LBP; Face recognition; Local features
ID TEXTURE CLASSIFICATION
AB LBP is known as one of the best performing local descriptor in texture representation. But there are various shortcomings observed in LBP and these are finite spatial patch and large feature size. These shortcomings also persist in numerous LBP variants. To remedy these shortcomings, the proposed work presents 2 LBP variants so-called Triangle LBP (TLBP) and Orthogonal LBP (OLBP), in pose and expression variations. TLBP features are extracted in horizontal and vertical directions by using 3 x 5 and 5 x 3 image patches, by rotating the triangle in 0(0) and 180(0) directions of both patch. OLBP features are extracted from orthogonal positions of the respective patch. The feature size derived from TLBP and OLBP descriptors are fused to manufacture the robust face descriptor called as Triangle And Orthogonal LBP (TAO-LBP). The compressed set of feature is accomplished by PCA. The finite spatial patch problem is eliminated by using two different patches, from which lower and higher scale features are extracted in the form of histograms, by using novel methodologies as introduced in TLBP and OLBP. The large feature size problem is scrutinized by the deployment of PCA and FLDA, which also selects the relevant and essential information for classification. The classification is procured by SVMs and NN. Experiments confirms the potential of TAO-LBP against LBP-like and non LBP-like based methods on ORL, GT, JAFFE, EYB and Faces94 datasets.
C1 [Karanwal, Shekhar; Diwakar, Manoj] Graph Era Deemed Univ, CSE Dept, Dehra Dun 248002, Uttarakhand, India.
C3 Graphic Era University
RP Karanwal, S (corresponding author), Graph Era Deemed Univ, CSE Dept, Dehra Dun 248002, Uttarakhand, India.
EM shekhar.karanwal@gmail.com; manoj.diwakar@gmail.com
RI Karanwal, Dr. Shekhar/AGF-1442-2022; Diwakar, Manoj/AAS-2520-2021
OI Karanwal, Dr. Shekhar/0000-0003-2932-4132; 
CR Ahonen T., 2008, 19th Intl. Conf. on Pattern Recognition, P1, DOI DOI 10.1109/ICPR.2008.4761847
   Baohua Yuan, 2012, 2012 International Symposium on Biometrics and Security Technologies (ISBAST 2012), P51, DOI 10.1109/ISBAST.2012.14
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Chen WS, 2015, INT J WAVELETS MULTI, V13, DOI 10.1142/S0219691315500496
   Chen XB, 2015, MACH VISION APPL, V26, P857, DOI 10.1007/s00138-015-0709-7
   Chu YH, 2020, NEUROCOMPUTING, V387, P13, DOI 10.1016/j.neucom.2019.09.013
   Duong H, 2016, ARXIV
   Fasel B, 2002, INT C PATT RECOG, P40, DOI 10.1109/ICPR.2002.1048231
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   He B, 2014, COGN COMPUT, V6, P264, DOI 10.1007/s12559-013-9224-1
   He ZX, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107664
   Hong XP, 2014, IEEE T IMAGE PROCESS, V23, P2557, DOI 10.1109/TIP.2014.2316640
   Hongliang Jin, 2004, Proceedings. Third International Conference on Image and Graphics, P306
   Huu-Tuan Nguyen, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P85, DOI 10.1007/978-3-642-37410-4_8
   Kaplan K, 2020, MED HYPOTHESES, V139, DOI 10.1016/j.mehy.2020.109696
   Karanwal S, 2021, INT ARAB C INFORM TE
   Karanwal S, 2022, MULTIMED TOOLS APPL, V81, P29405, DOI 10.1007/s11042-022-13006-8
   Karanwal S, 2021, DIGIT SIGNAL PROCESS, V110, DOI 10.1016/j.dsp.2020.102948
   Karanwal S, 2021, MULTIMED TOOLS APPL, V80, P12195, DOI 10.1007/s11042-020-09833-2
   Karanwal S, 2021, PATTERN ANAL APPL, V24, P741, DOI 10.1007/s10044-020-00948-8
   Karanwal S, 2021, OPTIK, V226, DOI 10.1016/j.ijleo.2020.166007
   Kekre HB, 2010, P INT C WORKSHOP EME, P241
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Lai J, 2013, IEEE IMAGE PROC, P3695, DOI 10.1109/ICIP.2013.6738762
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Lin GF, 2017, PATTERN RECOGN, V68, P14, DOI 10.1016/j.patcog.2017.03.014
   Liu H, 2015, AAAI CONF ARTIF INTE, P196
   Lu JL, 2021, PATTERN RECOGN, V113, DOI 10.1016/j.patcog.2020.107758
   Mandal B., 2014, AS C COMP VIS, P585
   Mehta S., 2020, LGU RES J COMPUT SCI, V4, P1
   Khanbebin SN, 2021, NEURAL COMPUT APPL, V33, P7691, DOI 10.1007/s00521-020-05512-3
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Perikos I, 2014, IFIP INT C ART INT A, P236
   Song TC, 2021, IEEE T CIRC SYST VID, V31, P189, DOI 10.1109/TCSVT.2020.2972155
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tao DC, 2008, IEEE T CIRC SYST VID, V18, P1397, DOI 10.1109/TCSVT.2008.2002825
   Tran CK, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.2.023011
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wan M., 2021, COMPUTER, V2021, P1
   Wang HB, 2016, SOFT COMPUT, V20, P3969, DOI 10.1007/s00500-015-1985-x
   Wang SF, 2010, LECT NOTES COMPUT SC, V6064, P104, DOI 10.1007/978-3-642-13318-3_14
   Wang YC, 2016, INT CONF ACOUST SPEE, P1273, DOI 10.1109/ICASSP.2016.7471881
   Wu F, 2018, KNOWLEDGE BASED SYST
   Wu F, 2020, IEEE T CYBERNETICS, V50, P1009, DOI 10.1109/TCYB.2018.2876591
   Wu F, 2016, PATTERN RECOGN, V60, P630, DOI 10.1016/j.patcog.2016.06.010
   Xiaogang Gong, 2011, Journal of Computers, V6, P2427, DOI 10.4304/jcp.6.11.2427-2433
   Xu Y, 2017, IEEE ACCESS, V5, P8502, DOI 10.1109/ACCESS.2017.2695239
   Xuan SB, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/641510
   Yang CL, 2013, PATTERN RECOGN, V46, P948, DOI 10.1016/j.patcog.2012.07.011
   Zhang ZX, 2022, SIGNAL IMAGE VIDEO P, V16, P1091, DOI 10.1007/s11760-021-02058-2
   Zhu C, 2013, PATTERN RECOGN, V46, P1949, DOI 10.1016/j.patcog.2013.01.003
NR 54
TC 2
Z9 2
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36179
EP 36205
DI 10.1007/s11042-023-15072-y
EA MAR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000950429600001
DA 2024-07-18
ER

PT J
AU Priya, RV
   Nag, PK
AF Priya, R. Vishnu
   Nag, Prashant Kumar
TI Text-based emotion recognition using contextual phrase embedding model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; Emotional cause; Skip phrase; FrameNet; Semantic
   role labelling; BERT
ID CONVOLUTIONAL NEURAL-NETWORK; DOCUMENT REPRESENTATION; SELECTION
AB In this paper, the proposed approach categories the sentences in the dataset into the various topical documents using the TE-LSTM+SC model. As well as, the model generates semantic words related to topics that are fed into the word embedding like Skip-Gram and FrameNet to build the domain-specific lexicon. The topically related sentences in each document are contextually grouped using Skip-Phrase. Each sentence in contextual group is given to Semantic Role Labelling (SRL). SRL indentify the essential predicate-argument structures with the semantic labels like verb (V) tag or ARGM-NEG or ARGM-PRP or ARGM-CAU or structures with the semantic labels like verb (V) tag or ARGM-NEG or ARGM-PRP or ARGM-CAU or ARGM-MNR or ARGM-MOD. The selected predicate-argument structures are aggregated into a linear layer to form a semantic embedding. Simultaneously, the predicate-argument embedding is segmented to sub words by BERT. The sub-words are transformed to word level through a convolutional layer to acquire the contextual word representation. Finally, semantic embedding and word representation are integrated to efficiently find the emotion of the given sentence. The experimental result proved that the proposed approach outperforms all the state-of-art approaches.
C1 [Priya, R. Vishnu] Natl Inst Technol, Dept Comp Applicat, Trichy, Tamil Nadu, India.
   [Nag, Prashant Kumar] Maulana Azad Natl Inst Technol MANIT, Dept Math Bioinformat & Comp Applicat, Link Rd 3, Bhopal 462003, Madhya Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli; National Institute of Technology (NIT
   System); Maulana Azad National Institute of Technology Bhopal
RP Priya, RV (corresponding author), Natl Inst Technol, Dept Comp Applicat, Trichy, Tamil Nadu, India.
EM vishnupriya@nitt.edu; pn.193120001@manit.ac.in
RI Nag, Prashant Kumar/HPE-9262-2023
OI Nag, Prashant Kumar/0000-0002-1601-1455
CR Alm CO, 2005, P C HUM LANG TECHN E, P579, DOI DOI 10.3115/1220575.1220648
   Alshaabi T, 2022, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.783778
   [Anonymous], 2015, Transactions of the Association for Computational Linguistics
   Araque O, 2022, IEEE T AFFECT COMPUT, V13, P496, DOI 10.1109/TAFFC.2019.2934444
   Baker C.F., 1998, P 36 ANN M ASS COMP, P86, DOI [DOI 10.3115/980845.980860, DOI 10.3115/980451.980860]
   Batbaatar E, 2019, IEEE ACCESS, V7, P111866, DOI 10.1109/ACCESS.2019.2934529
   Bostan LAM, 2018, ANAL ANNOTATED CORPO, V16
   Cai D, 2011, IEEE T KNOWL DATA EN, V23, P902, DOI 10.1109/TKDE.2010.165
   Cai Y, 2020, KNOWL-BASED SYST, V203, DOI 10.1016/j.knosys.2020.105856
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen ZX, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P229, DOI 10.1145/3240508.3240568
   Crowdflower, 2016, SENT AN TEXT DAT CRO
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ding M, 2020, COGLTX APPL BERT LON, V13
   Ding Z, 2019, ARXIV
   Dowdy S, 2004, STAT RES, V441
   Er MJ, 2016, INFORM SCIENCES, V373, P388, DOI 10.1016/j.ins.2016.08.084
   Gómez-Adorno H, 2018, COMPUTING, V100, P741, DOI 10.1007/s00607-018-0587-8
   Guan C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3361
   Gui L., 2017, ARXIV
   Hashimoto Kazuma., 2013, EMNLP, P1372
   He LH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P473, DOI 10.18653/v1/P17-1044
   Huang CK, 2019, PROCEEDINGS OF THE 2019 ACM MOBIHOCWORKSHOP ON PERVASIVE SYSTEMS IN THE IOT ERA (PERSIST-IOT '19), P49, DOI 10.1145/3331052.3332478
   Ishiwatari T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7360
   Jo Y, 2017, ARXIV
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Keikha M, 2009, KNOWL-BASED SYST, V22, P67, DOI 10.1016/j.knosys.2008.06.002
   Kim Y., 2014, P 2014 C EMP METH NA, P1746, DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/D14-1181]
   Lai SW, 2016, IEEE INTELL SYST, V31, P5, DOI 10.1109/MIS.2016.45
   Le Q., 2014, ARXIV
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee Ji Young, 2017, P 11 INT WORKSHOP SE, P978, DOI [10.18653/v1/S17-2171, DOI 10.18653/V1/S17-2171]
   Lee SYM, 2010, TEXT DRIVEN RULE BAS, V9
   Li B, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4144
   Li CC, 2020, IEEE T MULTIMEDIA, V22, P1634, DOI 10.1109/TMM.2019.2946477
   Li J., 2020, P 28 INT C COMPUTATI, P4190, DOI DOI 10.18653/V1/2020.C0LING-MAIN.370
   Li JW, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1106, DOI 10.3115/v1/p15-1107
   Li XJ, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4752
   Liu JL, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1729, DOI 10.1145/2723372.2751523
   Liu K., 2014, P COLING 2014 25 INT, P2335
   Minaee, 2021, ARXIV
   Mohammad S, 2012, EMOTIONAL TWEETS, V10
   Mundra S, 2017, LECT NOTES ARTIF INT, V10235, P337, DOI 10.1007/978-3-319-57529-2_27
   Nag Prashant Kumar, 2021, AIR2021: Advances in Robotics - 5th International Conference of The Robotics Society, DOI 10.1145/3478586.3478629
   Nguyen T.H., 2015, P 1 WORKSH VECT SPAC, P39, DOI 10.3115/v1/W15-1506
   Nonis F, 2021, PROGRESSES ARTIFICIA, P281, DOI [10.1007/978-981-15-5093-526, DOI 10.1007/978-981-15-5093-5_26]
   Oyedotun OK, 2017, IEEE INT CONF COMP V, P3161, DOI 10.1109/ICCVW.2017.374
   Palangi H, 2016, IEEE-ACM T AUDIO SPE, V24, P694, DOI 10.1109/TASLP.2016.2520371
   Palmer M, 2005, COMPUT LINGUIST, V31, P71, DOI 10.1162/0891201053630264
   Plaza -del -Arco FM, 2022, ARXIV
   Posadas-Durán JP, 2017, SOFT COMPUT, V21, P627, DOI 10.1007/s00500-016-2446-x
   Priya RV, 2019, MULTIMED TOOLS APPL, V78, P17847, DOI 10.1007/s11042-018-6954-9
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Riaz M., 2014, P 15 ANN M SPEC INT, P161
   Roth M, 2016, ARXIV
   Ruppenhofer Josef, 2006, FrameNet II: Extended theory and practice
   Santos WR, 2015, J STRENGTH COND RES, V29, P3466, DOI 10.1519/JSC.0000000000001001
   SCHERER KR, 1994, J PERS SOC PSYCHOL, V66, P310, DOI 10.1037/0022-3514.66.2.310
   Shang JB, 2018, IEEE T KNOWL DATA EN, V30, P1825, DOI 10.1109/TKDE.2018.2812203
   Singh N, 2019, PERVASIVE MOB COMPUT, V58, DOI 10.1016/j.pmcj.2019.04.009
   Socher Richard, 2012, P 2012 JOINT C EMPIR, DOI [10.5555/2390948.2391084, DOI 10.1162/153244303322533223]
   Sun M, 2019, LECT NOTES COMPUTER, V11856, DOI [10.1007/978-3-030-32381-3, DOI 10.1007/978-3-030-32381-3]
   Sun YA, 2020, IEEE T EVOLUT COMPUT, V24, P394, DOI 10.1109/TEVC.2019.2916183
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Tang H, 2020, NEUROCOMPUTING, V409, P329, DOI 10.1016/j.neucom.2020.03.105
   Turian J, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P384
   Violante MG, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112218
   Wei C, 2017, KNOWL-BASED SYST, V121, P41, DOI 10.1016/j.knosys.2017.01.012
   Winata G.I., 2019, P 13 INT WORKSHOP SE, P142
   Wong DF, 2016, KNOWL-BASED SYST, V108, P15, DOI 10.1016/j.knosys.2016.05.003
   Wu YL, 2020, INFORM SCIENCES, V517, P100, DOI 10.1016/j.ins.2019.12.031
   Xia R., 2019, ARXIV
   Xiao J., 2019, P 13 INT WORKSHOP SE, P220
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yu XY, 2019, IEEE ACCESS, V7, P9071, DOI 10.1109/ACCESS.2018.2890390
   Zhang CQ, 2019, IEEE ACCESS, V7, P181758, DOI 10.1109/ACCESS.2019.2959831
   Zhang WY, 2019, KNOWL-BASED SYST, V174, P194, DOI 10.1016/j.knosys.2019.03.007
   Zhao R, 2018, IEEE T FUZZY SYST, V26, P794, DOI 10.1109/TFUZZ.2017.2690222
NR 80
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35329
EP 35355
DI 10.1007/s11042-023-14524-9
EA MAR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000950119900001
DA 2024-07-18
ER

PT J
AU Cecchinato, N
   Toma, A
   Drioli, C
   Ferrin, G
   Foresti, GL
AF Cecchinato, Niccolo
   Toma, Andrea
   Drioli, Carlo
   Ferrin, Giovanni
   Foresti, Gian Luca
TI Performance evaluation of a Wi-Fi-based multi-node network for
   distributed audio-visual sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia data transmission; Wireless sensor networks; Sensor data
   streaming architecture; Multimedia sensor networks; Wireless networks;
   Distributed node streaming
AB The experimental research described in this manuscript proposes a complete network system for distributed multimedia acquisition by mobile remote nodes, streaming to a central unit, and centralized real-time processing of the collected signals. Particular attention is placed on the hardware structure of the system and on the research of the best network performances for an efficient and secure streaming. Specifically, these acoustic and video sensors, microphone arrays and video cameras respectively, can be employed in any robotic vehicles and systems, both mobile and fixed. The main objective is to intercept unidentified sources, like any kind of vehicles or robotic vehicles, drones, or people whose identity is not a-priory known whose instantaneous location and trajectory are also unknown. The proposed multimedia network infrastructure is analysed and studied in terms of efficiency and robustness, and experiments are conducted on the field to validate it. The hardware and software components of the system were developed using suitable technologies and multimedia transmission protocols to meet the requirements and constraints of computation performance, energy efficiency, and data transmission security.
C1 [Cecchinato, Niccolo; Toma, Andrea; Drioli, Carlo; Ferrin, Giovanni; Foresti, Gian Luca] Univ Udine, Dept Math Comp Sci & Phys, Udine, Italy.
C3 University of Udine
RP Cecchinato, N (corresponding author), Univ Udine, Dept Math Comp Sci & Phys, Udine, Italy.
EM cecchinato.niccolo@spes.uniud.it; andrea.toma@uniud.it;
   carlo.drioli@uniud.it; giovanni.ferrin@uniud.it;
   gianluca.foresti@uniud.it
OI Cecchinato, Niccolo/0000-0001-9701-8650
FU ONRG - U.S. Department of Defense [N62909-20-1-2075]
FX AcknowledgementsThis research was partially supported by ONRG - U.S.
   Department of Defense research project N62909-20-1-2075 "Target
   Re-Association for Autonomous Agents" (TRAAA).
CR Abdullah Miran Taha Abdullah, 2017, NETW PROTOC ALGORITH, V9, P85
   Barello P, 2021, MULTIMED TOOLS APPL, V80, P13389, DOI 10.1007/s11042-020-10307-8
   Garcia L., 2018, Network Protocols and Algorithms, V10, P23, DOI DOI 10.5296/NPA.V10I1.12798
   Hayat S, 2015, 2015 IEEE 26TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), P1991, DOI 10.1109/PIMRC.2015.7343625
   Kaewkiriya T, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEMS, COMPUTING AND IT APPLICATIONS (CSCITA), P235, DOI 10.1109/CSCITA.2017.8066560
   Kim D Y, 2020, MULTIMED TOOLS APPL, P1
   Leong WL, 2021, J INTELL ROBOT SYST, V102, DOI 10.1007/s10846-021-01398-y
   Martinel N, 2017, IEEE T CYBERNETICS, V47, P3530, DOI 10.1109/TCYB.2016.2568264
   Newell D, 2017, 2017 31ST IEEE INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (IEEE WAINA 2017), P710, DOI 10.1109/WAINA.2017.113
   Piciarelli C, 2011, IEEE INTELL SYST, V26, P32, DOI 10.1109/MIS.2010.38
   Salvati D, 2020, IEEE T IND ELECTRON, V67, P8618, DOI 10.1109/TIE.2019.2949529
   Salvati D, 2014, IEEE SIGNAL PROC LET, V21, P581, DOI 10.1109/LSP.2014.2311164
   Toma A, 2021, 1 190 S ML BD HYBRID
   Toma A, 2021, PROC INT C MIL COMMU, P1, DOI [10.1109/ICMCIS52405.2021.9486424, DOI 10.1109/ICMCIS52405.2021.9486424]
   Toma A, 2021, INTERSPEECH, P2147, DOI 10.21437/Interspeech.2021-886
   TP-Link Technologies Co. Ltd, EAP DAT
   Waharte S, 2006, MULTIMED TOOLS APPL, V29, P285, DOI 10.1007/s11042-006-0012-8
   Yanmaz E, 2018, AD HOC NETW, V68, P1, DOI 10.1016/j.adhoc.2017.09.001
   zylia, ZYLIA ZM 1 MICROPHON
NR 19
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29753
EP 29768
DI 10.1007/s11042-023-14677-7
EA MAR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000950119600009
OA hybrid
DA 2024-07-18
ER

PT J
AU Zergat, KY
   Selouani, SA
   Amrouche, A
   Kahil, Y
   Merazi-Meksen, T
AF Zergat, Kawthar Yasmine
   Selouani, Sid Ahmed
   Amrouche, Abderrahmane
   Kahil, Yazid
   Merazi-Meksen, Thouraya
TI The voice as a material clue: a new forensic Algerian Corpus
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech corpus; Accents recognition; Algerian dialect; Forensic voice
   comparison
ID RECOGNITION
AB Dialects have received bigger interest in recent years as they are increasingly used on the web and social media. Because Algerian Arabic dialects suffer from a lack of appropriate speech corpora for speech recognition, a rich dialect corpus is needed to approach Algerian Accent recognition. The latter remains a key feature in the field of Forensic Voice Comparison (FVC) systems. This paper presents a new large-scale forensic Algerian speech corpus called Sawt El-Djazair. An important criterion in dealing with forensic corpora is the presence of session variability. For this purpose, we collected celebrity recordings in various regions of Algeria, from different social networks, in various scenarios, and at different times. In addition, we also recorded 87 participants using cellular calls and voice over IP (VoIP) applications including Viber, WhatsApp, and Google Meet. The corpus of approximately 50 hours covers various speech topics and is spoken in twelve Algerian sub-dialects. The design guidelines of the proposed corpus are described along with the grouping of dialects across different geographical locations. Sawt El-Djazair is available to the research community upon request.
C1 [Zergat, Kawthar Yasmine; Amrouche, Abderrahmane; Kahil, Yazid; Merazi-Meksen, Thouraya] Univ Sci & Technol Houari Boumediene USTHB, Speech Com & Signal Proc Lab, POB 32, Algiers 16111, Algeria.
   [Selouani, Sid Ahmed] Univ Moncton, Informat Management Dept, Campus Shippagan, Shippegan, NB E8S 1P6, Canada.
C3 University Science & Technology Houari Boumediene; University of Moncton
RP Zergat, KY (corresponding author), Univ Sci & Technol Houari Boumediene USTHB, Speech Com & Signal Proc Lab, POB 32, Algiers 16111, Algeria.
EM kzergat@usthb.dz
CR Abainia K, 2020, LANG RESOUR EVAL, V54, P419, DOI 10.1007/s10579-019-09454-8
   Abdel-Hamid L, 2020, SPEECH COMMUN, V122, P19, DOI 10.1016/j.specom.2020.04.005
   Ait Habbouche K., 2013, LANGUAGE MAINTENANCE
   Alsulaiman M. M., 2013, Int. J. Inf., V16, P4231
   Amazouz D, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P1468
   Benali A, 2018, P 2 C LANGUAGE PROCE
   Biadsy F., 2009, P EACL 2009 WORKSH C, P53
   Bougrine S., 2016, 2 WORKSH AR CORP PRO, P2
   Bougrine S., 2017, P 3 ARABIC NATURAL L, P138
   Bu H, 2017, 2017 20TH CONFERENCE OF THE ORIENTAL CHAPTER OF THE INTERNATIONAL COORDINATING COMMITTEE ON SPEECH DATABASES AND SPEECH I/O SYSTEMS AND ASSESSMENT (O-COCOSDA), P58, DOI 10.1109/ICSDA.2017.8384449
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   CAMPBELL JP, 1995, INT CONF ACOUST SPEE, P341, DOI 10.1109/ICASSP.1995.479543
   Cooke M, 2006, J ACOUST SOC AM, V120, P2421, DOI 10.1121/1.2229005
   Correia J, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6973, DOI 10.1109/ICASSP39728.2021.9414230
   Dahmani H, 2019, COMM COM INF SC, V1108, P18, DOI 10.1007/978-3-030-32959-4_2
   Djellab M, 2017, LANG RESOUR EVAL, V51, P613, DOI 10.1007/s10579-016-9347-6
   Fan WQ, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P641, DOI 10.1109/ICASSP39728.2021.9414542
   Garofolo John S, 1993, Tech.Rep. NISTIR 4930
   Godfrey J. J., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P517, DOI 10.1109/ICASSP.1992.225858
   Guella N., 2011, SYNERGIES MONDE ARAB, V8, P81
   Haizhou L, 2006, 5 INT S
   Halpern BM, 2022, SPEECH COMMUN, V141, P14, DOI 10.1016/j.specom.2022.04.006
   Medjdoub MB, 2014, THESIS U TLEMCEN TLE
   Melin H, 1999, DATABASES SPEAKER RE
   Mohamed MM, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108361
   Morrison GS., 2019, ROUTLEDGE HDB PHONET, P599, DOI [10.4324/9780429056253-22, DOI 10.4324/9780429056253-22]
   Nadungodage T, 2013, ICON 2013 10 INT C N
   Ng SI, 2020, CUCHILD LARGE SCALE, V10, P2020
   Nour-Eddine L, 2015, J INF PROCESS SYST, V11, P22, DOI 10.3745/JIPS.02.0015
   Parada-Cabaleiro E, 2020, LANG RESOUR EVAL, V54, P341, DOI 10.1007/s10579-019-09450-y
   Pérez-Espinosa H, 2020, COMPUT SPEECH LANG, V59, P55, DOI 10.1016/j.csl.2019.06.006
   Saadane H., 2015, P 2 WORKSHOP ARABIC, P69
   Sadjadi SO., 2020, 2019 NIST AUDIO VISU, DOI [10.21437/Odyssey.2020-37, DOI 10.21437/ODYSSEY.2020-37]
   Taleb Ibrahimi K, 1997, ALGERIENS LEUR LANGU
   Urooj S, 2021, INTERSPEECH, P396, DOI 10.21437/Interspeech.2021-910
   Zergat KY, 2021, 4 C COMPUTING SYSTEM
   Zhang BB, 2022, INT CONF ACOUST SPEE, P6182, DOI 10.1109/ICASSP43922.2022.9746682
NR 37
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29095
EP 29113
DI 10.1007/s11042-023-14412-2
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000950119600006
PM 37362717
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Devi, TG
   Patil, N
   Rai, S
   Sarah, CP
AF Devi, Tulasi Gayatri
   Patil, Nagamma
   Rai, Sharada
   Sarah, Cheryl Philipose
TI Segmentation and classification of white blood cancer cells from bone
   marrow microscopic images using duplet-convolutional neural network
   design
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acute Lymphoblastic Leukemia; Adamoptimizer; Binary Classification Blood
   Cancer; CatBoost Algorithm; Convolutional Neural Network; Extreme
   Gradient Boost Algorithm; Multiple Myeloma
AB Cancer is a disease linked to the untamed and rapid division of cells in the body. Cancer detection through conventional methods like complete blood count is a tedious and time-consuming task prone to human errors. The introduction of image processing techniques and computer-aided diagnostics is beneficial to this field as the results obtained by utilizing these methods are quick and accurate. The proposed method in this paper uses a design Convolutional Leaky RELU with CatBoost and XGBoost (CLR-CXG) to segment the images and extract the important features that help in classification. The binary classification algorithm and gradient boosting algorithm CatBoost (Categorical Boost) and XGBoost (Extreme Gradient Boost) are implemented individually. Moreover, Convolutional Leaky RELU with CatBoost (CLRC) is designed to decrease bias and provide high accuracy, while Convolutional Leaky RELU with XGBoost (CLRXG) is designed for classification or regression prediction problems which will increase the speed of executing the algorithm and improve its performance. Thus the CLR-CXG classifies the test images into Acute Lymphoblastic Leukemia (ALL) or Multiple Myeloma (MM). Finally, the CLRC algorithm achieved 100% accuracy in classifying cancer cells, and the recorded run time is 10s. Moreover, the CLRXG algorithm has gained an accuracy of 97.12% for classifying cancer cells and 12 s for executing the process.
C1 [Devi, Tulasi Gayatri; Patil, Nagamma] Natl Inst Technol Karnataka, Dept Informat Technol, Mangalore, Karnataka, India.
   [Rai, Sharada; Sarah, Cheryl Philipose] Kasturba Med Coll & Hosp, Dept Pathol, Mangalore, Karnataka, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka; Manipal Academy of Higher Education (MAHE);
   Kasturba Medical College, Mangalore
RP Devi, TG (corresponding author), Natl Inst Technol Karnataka, Dept Informat Technol, Mangalore, Karnataka, India.
EM 177it003tulasi@nitk.edu.in; nagammapatil@nitk.edu.in;
   sharada.rai@manipal.edu; cheryl.philipose@manipal.edu
OI Gayatri, Tulasi/0000-0002-9898-5412
CR Abbasi M, 2019, J SUPERCOMPUT, V75, P6574, DOI 10.1007/s11227-019-02861-2
   Abbasi M, 2021, IEEE T INTELL TRANSP, V22, P5283, DOI 10.1109/TITS.2020.3038250
   Abbasi M, 2019, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.185
   Achanta SDM, 2021, INT J SPEECH TECHNOL, DOI 10.1007/s10772-021-09893-1
   Achanta SDM, 2019, INT J INTELL UNMANNE, V8, P43, DOI 10.1108/IJIUS-01-2019-0005
   Achanta SDM, 2019, SOFT COMPUT, V23, P8359, DOI 10.1007/s00500-019-04108-x
   Agrawal R, 2019, 2019 INT C VIS EM TR, P1, DOI [10.1109/ViTECoN.2019.8899602, DOI 10.1109/VITECON.2019.8899602]
   [Anonymous], 2021, What is Cancer?
   Bayat M., 2016, J ASIAN SCI RES, V6, P24, DOI [10.18488/journal.2/2016.6.2/2.2.24.33, DOI 10.18488/JOURNAL.2/2016.6.2/2.2.24.33]
   Brownlee J., 2021, Extreme Gradient Boosting (XGBoost) Ensemble in Python
   Bushaev V., 2018, Adam-latest trends in deep learning optimization
   Clinic M, 2021, MULTIPLE MYELOMA SYM
   Fei XH, 2020, CHIN CONT DECIS CONF, P4396, DOI [10.1109/ccdc49329.2020.9164224, 10.1109/CCDC49329.2020.9164224]
   Grover P., 2018, 5 Regression Loss Functions All Machine Learners Should Know
   Honomichl N, 2021, CANC IMAGING ARCH
   Macawile MJ, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON CONTROL AND ROBOTICS ENGINEERING (ICCRE), P259, DOI 10.1109/ICCRE.2018.8376476
   Kumar D, 2020, IEEE ACCESS, V8, P142521, DOI 10.1109/ACCESS.2020.3012292
   Kutlu H, 2020, MED HYPOTHESES, V135, DOI 10.1016/j.mehy.2019.109472
   Markman M, 2021, BLOOD CANC TYPES TRE
   MATLAB, 2021, MAX POOL LAYER MATL
   Medium, 2018, DATA SCI, V15
   Mohammed ZF, 2021, MULTIMED TOOLS APPL, V80, P6355, DOI 10.1007/s11042-020-10066-6
   Mujtaba H, 2020, INTRO RECTIFIED LINE
   Murthy ASD, 2020, MATER TODAY-PROC, V33, P4323, DOI 10.1016/j.matpr.2020.07.447
   Murthy ASD, 2022, SOFT COMPUT, V26, P12933, DOI 10.1007/s00500-021-06125-1
   Onciu M, 2009, HEMATOL ONCOL CLIN N, V23, P655, DOI 10.1016/j.hoc.2009.04.009
   Poornima N., 2016, INT J ADV RES COMPUT, V5, P587
   Ray S, 2017, CATBOOST CATEGORICAL
   Sampath Dakshina Murthy A., 2020, INT J PHARMACEUT, V12, P3373, DOI [10.31838/ijpr/2020.12.04.460, DOI 10.31838/IJPR/2020.12.04.460]
   Sharma N., 2020, Materials Today: Proceedings, DOI [10.1016/J.MATPR.2020.10.623, DOI 10.1016/J.MATPR.2020.10.623]
   Sipes R, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (ICCIA), P157, DOI 10.1109/ICCIA.2018.00036
   Togaçar M, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106810
   Wang Q, 2021, OPT LASER TECHNOL, V139, DOI 10.1016/j.optlastec.2021.106931
NR 33
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35277
EP 35299
DI 10.1007/s11042-023-14899-9
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000948950300009
DA 2024-07-18
ER

PT J
AU Su, TT
   Liu, DM
AF Su, Tongtong
   Liu, Daming
TI Transmission line defect detection based on feature enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Transmission line defect; Contextual information; Effective receptive
   field; Feature fusion; Default boxes
AB Defects in power transmission lines affect the safety operation of devices and the reliability of power supply. Automatic visual detection of defects for power transmission lines is an ongoing trend in the smart grid development. The traditional target detector has poor applicability and low accuracy for small-sized defects taken by UAVs. To address this problem, we proposed a multi-scale model based on reinforcement context (CE-SSD, Context Enhancement-SSD). Concatenating multi-scale features from different layers as context are applied in proposed method. The CEC (context enhancement component) constitute with dilated convolution and residual blocks to enhance contextual information. In addition, so as to heighten the focus on small targets and decrease the parameter size of the network, the default box was changed. Seven common transmission line defects (TLDD) including 14,400 images were used in the experiment. The results show that CE-SSD has rather higher detection accuracy than others. The accuracy ratio of CE-SSD is 66.65% on TLDD, where the accuracy ratio of small targets is 7.6% higher than that of SSD network, and 86.4% and 98.0% in bird nest detection and misplacement detection, respectively. CE-SSD also has extraordinary performance in Pascal VOC, with a detection accuracy of 80.92%.
C1 [Su, Tongtong; Liu, Daming] Shanghai Univ Elect Power, Coll Comp Technol & Sci, Shanghai 200090, Peoples R China.
C3 Shanghai University of Electric Power
RP Su, TT (corresponding author), Shanghai Univ Elect Power, Coll Comp Technol & Sci, Shanghai 200090, Peoples R China.
EM sudoubletong@163.com; ldm@shiep.edu.cn
CR Shah NA, 2021, Arxiv, DOI arXiv:2103.09289
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Changqian Yu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12413, DOI 10.1109/CVPR42600.2020.01243
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Everingham M., 2005, P MACHINE LEARNING C, P117
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jiang H, 2019, IEEE ACCESS, V7, P61797, DOI 10.1109/ACCESS.2019.2915985
   Ju Minjeong, 2019, 2019 34 INT TECHNICA
   Li H, 2022, IEEE ACCESS, V10, P45620, DOI 10.1109/ACCESS.2022.3170696
   Li J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186147
   Liang HG, 2020, IEEE ACCESS, V8, P38448, DOI 10.1109/ACCESS.2020.2974798
   Lim JS, 2021, 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN INFORMATION AND COMMUNICATION (IEEE ICAIIC 2021), P181, DOI 10.1109/ICAIIC51459.2021.9415217
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu ZY, 2022, INT J ELEC POWER, V142, DOI 10.1016/j.ijepes.2022.108277
   Lu Y, 2019, LECT NOTES COMPUT SC, V11554, P97, DOI 10.1007/978-3-030-22796-8_11
   Miao XR, 2019, IEEE ACCESS, V7, P9945, DOI 10.1109/ACCESS.2019.2891123
   Nie X, 2019, IEEE INT C INTELL TR, P47, DOI 10.1109/ITSC.2019.8917475
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Zhao LQ, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030537
   Zou Z., 2019, arXiv
NR 28
TC 1
Z9 1
U1 5
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 13
PY 2023
DI 10.1007/s11042-023-15063-z
EA MAR 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9W3AE
UT WOS:000948950300001
DA 2024-07-18
ER

PT J
AU Balshetwar, SV
   Abilash, RS
   Jermisha, DR
AF Balshetwar, Sarita, V
   Abilash, R. S.
   Jermisha, Dani R.
TI Fake news detection in social media based on sentiment analysis using
   classifier techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis (NLP); Fake news; Social media; Missing data;
   Multiple imputation; Naive Bayes classifier; Deep neural network (DNN)
AB Fake news on social media, has spread for personal or societal gain. Detecting fake news is a multi-step procedure that entails analysing the content of the news to assess its trustworthiness. The article has proposed a new solution for fake news detection which incorporates sentiment as an important feature to improve the accuracy with two different data sets of ISOT and LIAR. The key feature words with content's propensity scores of the opinions are developed based on sentiment analysis using a lexicon-based scoring algorithm. Further, the study proposed a multiple imputation strategy which integrated Multiple Imputation Chain Equation (MICE) to handle multivariate missing variables in social media or news data from the collected dataset. Consequently, to extract the effective features from the text, Term Frequency and Inverse Document Frequency (TF-IDF) are introduced to determine the long-term features with the weighted matrix. The correlation of missing data variables and useful data features are classified based on Naive Bayes, passive-aggressive and Deep Neural Network (DNN) classifiers. The findings of this research described that the overall calculation of the proposed method was obtained with an accuracy of 99.8% for the detection of fake news with the evaluation of various statements such as barely true, half true, true, mostly true and false from the dataset. Finally, the performance of the proposed method is compared with the existing methods in which the proposed method results in better efficiency.
C1 [Balshetwar, Sarita, V] AGTIs Dr Daulatrao Aher Coll Engn, Karad, Satara, Maharashtra, India.
   [Abilash, R. S.] Bethlahem Inst Engn, Ulaganvillai, Tamil Nadu, India.
   [Jermisha, Dani R.] Arunachala Coll Engn Women, Manavilai, Tamil Nadu, India.
RP Balshetwar, SV (corresponding author), AGTIs Dr Daulatrao Aher Coll Engn, Karad, Satara, Maharashtra, India.
EM balshetwar.satara@gmail.com; abilash.res2k21@yahoo.com;
   danijermisha01@yahoo.com
OI Balshetwar, Dr. Sarita/0000-0001-6788-1365
CR Ahmad I, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/8812019
   Akinyemi B., 2020, INT J INF TECHNOL CO, V12, P34, DOI [10.5815/ijitcs.2020.01.05, DOI 10.5815/IJITCS.2020.01.05]
   Alonso MA, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10111348
   Amer AYA., 2020, INT J COMPUT SCI INF, DOI [10.5281/zenodo.4427205, DOI 10.5281/ZENODO.4427205]
   Aslam N, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/5557784
   Choudhary A, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114171
   Dang NC, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030483
   Duan X, 2020, CLEF WORKING NOTES
   Enders CK., 2018, The Wiley handbook of psychometric testing: A multidisciplinary reference on survey, scale and test development, P139, DOI [DOI 10.1002/9781118489772.CH6, 10.1002/9781118489772.ch6]
   Harb JGD, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102372
   Harel O, 2018, AM J EPIDEMIOL, V187, P576, DOI 10.1093/aje/kwx349
   Javed Awan M., 2020, INT J EMERG TECHNOL, V11, P197
   Jiang T, 2021, IEEE ACCESS, V9, P22626, DOI 10.1109/ACCESS.2021.3056079
   Kaliyar RK, 2021, NEURAL COMPUT APPL, V33, P8597, DOI 10.1007/s00521-020-05611-1
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Kumar S, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3767
   Lang KM, 2018, PREV SCI, V19, P284, DOI 10.1007/s11121-016-0644-5
   Maniruzzaman M, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0940-7
   Nasir J.A., 2021, International Journal of Information Management Data Insights, V1, P100007, DOI [10.1016/j.jjimei.2020.100007, DOI 10.1016/J.JJIMEI.2020.100007]
   Nithya SH, 2022, J INF KNOWL MANAG, V21, DOI 10.1142/S0219649222500368
   Richardson HA., 2020, OXFORD RES ENCY BUSI, DOI [10.1093/acrefore/9780190224851.013.226, DOI 10.1093/ACREFORE/9780190224851.013.226]
   Sahoo SR, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106983
   Shu K, 2020, BIG DATA, V8, P171, DOI 10.1089/big.2020.0062
   Sperrin M, 2020, J CLIN EPIDEMIOL, V125, P183, DOI 10.1016/j.jclinepi.2020.03.028
   Xu K, 2020, TSINGHUA SCI TECHNOL, V25, P20, DOI 10.26599/TST.2018.9010139
   Yuan C., 2020, P 28 INT C COMP LING, P5444
   Zhou X., 2020, DIGITAL THREATS RES, V1, P1
NR 27
TC 7
Z9 7
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35781
EP 35811
DI 10.1007/s11042-023-14883-3
EA MAR 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000947594500007
PM 37362674
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Awasthi, D
   Srivastava, VK
AF Awasthi, Divyanshu
   Srivastava, Vinay Kumar
TI Performance enhancement of SVD based dual image watermarking in wavelet
   domain using PSO and JAYA optimization and their comparison under hybrid
   attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE JAYA optimization; Hybrid attacks; Combined SVD; Dual image; Particle
   swarm optimization; Lifting wavelet transform
ID SCHEME; DWT; TRANSFORM
AB In this paper, a dual image watermarking technique is proposed to secure the data, which utilizes the property of lifting wavelet transformation (LWT), singular value decomposition (SVD), Swarm optimization (PSO), and JAYA optimization. Dual image watermarking brings some potential concerns and obstacles. The first difficulty is to find a balance among imperceptibility, resilience, and capacity, as increasing one component negatively impacts the others, and a successful digital watermarking system should have all three qualities simultaneously. The next factor is payload size, which refers to the amount of data carried. Larger the payload lesser is its imperceptibility. A good watermarking scheme must have a tradeoff among all these qualities. In the embedding procedure, firstly, a second-level LWT is applied to split the host image into four sub-bands (LL, HL, LH, HH) then the SVD is applied to the low-low sub-band. These singular values are combined with the singular values of the dual watermark image, which are obtained by combing the SVDs of both the watermark images and then they are attached to the dominant component of the SVD of the host image. Combining the SVs of both the watermark images provides less effect of attacks on the first watermark image. The scaling factor is calculated with the help of optimization techniques to combine the singular values of the watermark logo with the singular values of the input host image. The peak signal-to-noise ratio plays a vital role in digital image watermarking. The peak signal-to-noise ratio between the input and watermarked images is calculated, and the result shows that the proposed method is imperceptible. The normalized correlation coefficient is calculated to show the robustness of the scheme against various attacks. This proposed work also mentions the comparison between PSO and JAYA optimization. The proposed scheme is examined under various regular and hybrid attacks, and the quality of this technique is examined by comparing it with other reported techniques.
C1 [Awasthi, Divyanshu; Srivastava, Vinay Kumar] Motilal Nehru Natl Inst Technol, Elect & Commun Engn Dept, Prayagraj 211004, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Awasthi, D (corresponding author), Motilal Nehru Natl Inst Technol, Elect & Commun Engn Dept, Prayagraj 211004, Uttar Pradesh, India.
EM divyanshuawasthi83@gmail.com; vinay@mnnit.ac.in
RI Srivastava, Vinay Kumar/AAL-2501-2021; awasthi, divyanshu/ABX-1965-2022
OI Srivastava, Vinay Kumar/0000-0002-7993-0993; awasthi,
   divyanshu/0000-0002-1764-772X
CR Abdallah HA, 2014, INFORM PROCESS MANAG, V50, P909, DOI 10.1016/j.ipm.2014.07.001
   Awasthi D, 2022, MULTIMED TOOLS APPL, V81, P25075, DOI 10.1007/s11042-022-12456-4
   Bao P, 2005, IEEE T CIRC SYST VID, V15, P96, DOI 10.1109/TCSVT.2004.836745
   Bhatnagar G, 2008, 2008 FIRST INTERNATIONAL CONFERENCE ON THE APPLICATIONS OF DIGITAL INFORMATION AND WEB TECHNOLOGIES, VOLS 1 AND 2, P526, DOI 10.1109/ICADIWT.2008.4664404
   Dowling J, 2008, LECT NOTES COMPUT SC, V5041, P454
   Furqan A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P638, DOI 10.1109/CICT.2015.74
   Gaur S, 2017, INT J ADV COMPUT SC, V8, P211
   Hurrah NN, 2019, FUTURE GENER COMP SY, V94, P654, DOI 10.1016/j.future.2018.12.036
   Jane O, 2014, J APPL RES TECHNOL, V12, P750, DOI 10.1016/S1665-6423(14)70091-4
   Kale Mehmet Cemil, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2619, DOI 10.1109/ICASSP.2014.6854074
   Khare P, 2018, 2018 5TH IEEE UTTAR PRADESH SECTION INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS AND COMPUTER ENGINEERING (UPCON), P88
   Khare P, 2021, J INTELL SYST, V30, P297, DOI 10.1515/jisys-2019-0046
   Khare P, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P88, DOI 10.1109/SPIN.2018.8474125
   Kuppusamy K, 2012, PROCEDIA ENGINEER, V38, P493, DOI 10.1016/j.proeng.2012.06.061
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Liu JX, 2019, IEEE ACCESS, V7, P80849, DOI 10.1109/ACCESS.2019.2915596
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Mehta S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI 2013), P287, DOI 10.1109/ICHI.2013.41
   Nandi S, 2016, ADV INTELL SYST, V394, P69, DOI 10.1007/978-81-322-2656-7_7
   Rao VSV., 2012, IEEE STUD C EL EL CO, P1, DOI DOI 10.1109/SCEECS.2012.6184795
   Rykaczewski R, 2007, IEEE T MULTIMEDIA, V9, P421, DOI 10.1109/TMM.2006.886297
   Surekha P, 2012, APPL ARTIF INTELL, V26, P615, DOI 10.1080/08839514.2012.687670
   Thakkar F, 2017, TURK J ELECTR ENG CO, V25, P3273, DOI 10.3906/elk-1603-17
   Tsai HH, 2012, APPL SOFT COMPUT, V12, P2442, DOI 10.1016/j.asoc.2012.02.021
   Wang ZQ, 2007, LECT NOTES COMPUT SC, V4688, P307
   Yun SH, 2019, J SIGNAL PROCESS SYS, V91, P551, DOI 10.1007/s11265-018-1353-z
   Zear A, 2018, J INTELL SYST, V27, P5, DOI 10.1515/jisys-2016-0036
   Zhang LN, 2019, MULTIMED TOOLS APPL, V78, P28003, DOI 10.1007/s11042-019-07902-9
   Zhang XP, 2005, IEEE T MULTIMEDIA, V7, P593, DOI 10.1109/TMM.2005.843357
NR 29
TC 6
Z9 6
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35685
EP 35717
DI 10.1007/s11042-023-14723-4
EA MAR 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000946890000011
DA 2024-07-18
ER

PT J
AU Khedgaonkar, RS
   Singh, KR
AF Khedgaonkar, Roshni S. S.
   Singh, Kavita R. R.
TI Designing face resemblance technique using near set theory under varying
   facial features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Plastic surgery; Near set theory; Deep learning; Face
   resemblance; Facial features
ID DISCRIMINATIVE COMMON VECTORS; RECOGNITION; REPRESENTATION; HISTOGRAM
AB Near sets (also called Descriptively Near Sets) classify nonempty sets of objects based on object feature values. The Near Set Theory provides a framework for measuring the similarity of objects based on features that describe them in much the same way humans perceive the similarity of objects. This paper presents a novel approach for face recognition using Near Set Theory that takes into account variations in facial features due to varying facial expressions, and facial plastic surgery. In the proposed work, we demonstrate two-fold usage of Near set theory; firstly, Near Set Theory as a feature selector to select the plastic surgery facial features with the help of tolerance classes, and secondly, Near Set Theory as a recognizer that uses selected prominent intrinsic facial features which are automatically extracted through the deep learning model. Extensive experimentation was performed on various facial datasets such as YALE, PSD, and ASPS. Experimentation demonstrates 93% of accuracy on the YALE face dataset, 98% of accuracy on the PSD dataset, and 98% of accuracy on the ASPS dataset. A detailed comparative analysis of the proposed work of facial resemblance with other state-of-the-art algorithms is presented in this paper. The experimentation results effectively classify face resemblance using Near Set Theory, which has outperformed several state-of-the-art classification approaches.
C1 [Khedgaonkar, Roshni S. S.; Singh, Kavita R. R.] Yeshwantrao Chavan Coll Engn, Comp Technol, Nagpur, India.
C3 Yeshwantrao Chavan College of Engineering
RP Khedgaonkar, RS (corresponding author), Yeshwantrao Chavan Coll Engn, Comp Technol, Nagpur, India.
EM roshni.k86@gmail.com; singhkavita@yahoo.co.in
RI Singh, Kavita R/B-6439-2019
CR Alfalou A, 2010, FACE RECOGNITION, P353
   Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Bakshi A, 2022, MULTIMED TOOLS APPL, V81, P35047, DOI 10.1007/s11042-020-10045-x
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Cevikalp H, 2005, IEEE T PATTERN ANAL, V27, P4, DOI 10.1109/TPAMI.2005.9
   Ebadi M, 2020, SIGNAL IMAGE VIDEO P, V14, P1071, DOI 10.1007/s11760-020-01642-2
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hu CH, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107724
   Jayant Deepanshu, 2021, 2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS), P1230, DOI 10.1109/ICICCS51141.2021.9432300
   Khadatkar A., 2016, WORLD C FUTURISTIC T, P1, DOI 10.1109/STARTUP.2016.7583985
   Khedgaonkar R, 2021, Demystifying big data, machine learning, and deep learning for healthcare analytics, P215
   Khedgaonkar R, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P364, DOI 10.1109/ICSCCC.2018.8703270
   Kim KI, 2002, IEEE SIGNAL PROC LET, V9, P40, DOI 10.1109/97.991133
   Kortylewski Adam, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8937, DOI 10.1109/CVPR42600.2020.00896
   Krithika LB, 2021, J AMB INTEL HUM COMP, V12, P2131, DOI 10.1007/s12652-020-02311-5
   Leonard I, 2012, APPL OPTICS, V51, P2638, DOI 10.1364/AO.51.002638
   Li SZ, 2007, IEEE T PATTERN ANAL, V29, P627, DOI 10.1109/TPAMI.2007.1014
   Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Orlowska E., 1982, 469 POL AC SCI I COM
   Ouerhani Y, 2013, OPT COMMUN, V289, P33, DOI 10.1016/j.optcom.2012.09.074
   Pal SK, 2010, CH CRC MATH COMP IMA, P1
   Pawlak Z., 1981, POLISH ACAD SCI, P429
   Pawlak Z, 2007, INFORM SCIENCES, V177, P3, DOI 10.1016/j.ins.2006.06.003
   Peters JF, 2008, LECT NOTES COMPUT SC, V4944, P57
   Peters JF, 2007, FUND INFORM, V75, P407
   Peters JF, 2013, MATH COMPUT SCI, V7, P87, DOI 10.1007/s11786-013-0143-z
   Peters JF, 2009, STUD COMPUT INTELL, V202, P3
   Petersen J., 2007, Production and Consumption of Electricity in Oberlin College' s Lewis Center for Environmental Studies: Realizing the Goal of a Net Zero Building', P1
   plasticsurgery, AM SOC PLAST SURG FA
   Rettkowski J, 2017, J PARALLEL DISTR COM, V109, P50, DOI 10.1016/j.jpdc.2017.05.005
   Salim NR, 2022, MULTIMED TOOLS APPL, V81, P4143, DOI 10.1007/s11042-021-11728-9
   Shankar BU, 2007, LECT NOTES COMPUT SC, V4400, P295
   Singh KR, 2013, OPEN COMPUT SCI, V3, P129, DOI 10.2478/s13537-013-0108-y
   Singh Richa, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P72, DOI 10.1109/CVPR.2009.5204287
   Singh R, PLASTIC SURG FACE DA
   Srivastava S, 2022, MULTIMED TOOLS APPL, V81, P8471, DOI 10.1007/s11042-021-11721-2
   Sun J, 2018, J SENSORS, V2018, DOI 10.1155/2018/8580959
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   vision, YALE FACE DATABASE
   Wang W, 2022, ACM T GRAPHIC, V1
   Wen Y, 2012, EXPERT SYST APPL, V39, P4628, DOI 10.1016/j.eswa.2011.09.119
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhao CH, 2015, OPTIK, V126, P1761, DOI 10.1016/j.ijleo.2015.04.068
   Zhi H, 2019, J VIS COMMUN IMAGE R, V58, P495, DOI 10.1016/j.jvcir.2018.12.012
   Zhou TF, 2021, PROC CVPR IEEE, P5774, DOI 10.1109/CVPR46437.2021.00572
NR 50
TC 1
Z9 1
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 33161
EP 33182
DI 10.1007/s11042-023-14927-8
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943970200006
PM 37362639
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Tang, ZJ
   Li, JD
   Wang, ZH
   Huang, JK
   Li, Y
   Wang, C
AF Tang, Zhijie
   Li, Jianda
   Wang, Zhanhua
   Huang, Jingke
   Li, Yang
   Wang, Chi
TI Research on underwater target measurement technology based on sonar
   image and artificial landmark
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Angle measurement; Artificial landmark; Size measurement; Sonar image
AB Sonar imaging is one of the important means of underwater target detection. It can measure underwater targets and draw underwater topographic map. However, the existing methods can not rely on sonar images alone to measure underwater targets. In this paper, an underwater measurement technology based on sonar image is proposed. We combine the third-party reference object, artificial landmark to make up for the defects of sonar image measurement. The proposed method includes angle measurement method and three-dimensional mapping algorithm for size measurement. In the experiment, we combine image processing technology to restore the image contour information to obtain the key points in the sonar image. The experimental results show that the accuracy of this method can reach millimeter level, and the error range is within 5%. This technology realizes the shape correction and precise length measurement of underwater targets.
C1 [Tang, Zhijie; Li, Jianda; Wang, Zhanhua; Huang, Jingke; Li, Yang; Wang, Chi] Shanghai Univ, Sch Mechatron Engn & Automat, 99 Shangda Rd, Shanghai, Peoples R China.
C3 Shanghai University
RP Tang, ZJ (corresponding author), Shanghai Univ, Sch Mechatron Engn & Automat, 99 Shangda Rd, Shanghai, Peoples R China.
EM tangzhijie@shu.edu.cn
RI CHEN, AN/KFT-3370-2024; Li, YU/JQV-2716-2023; li, Shang/KHU-3233-2024;
   wang, zhenyu/H-4365-2011; Wang, Yue/JRY-8962-2023
OI Wang, Yue/0000-0001-8673-6358
FU National Natural Science Foundation of China [51005142]; Innovation
   Program of Shanghai Municipal Education Commission [14YZ010]; Natural
   Science Foundation of Shanghai [14ZR1414900, 19ZR1419300]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship and publication of this article. This work was
   supported by the National Natural Science Foundation of China (No.
   51005142), the Innovation Program of Shanghai Municipal Education
   Commission (No.14YZ010), and the Natural Science Foundation of Shanghai
   (No. 14ZR1414900 No.19ZR1419300).
CR Baumgartner LJ, 2006, ASSESSMENT DUAL FREQ, V84, P1
   Chanussot J, 2002, OCEANS 2002 MTS/IEEE CONFERENCE & EXHIBITION, VOLS 1-4, CONFERENCE PROCEEDINGS, P2294
   Chen DS, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON TRANSPORTATION INFORMATION AND SAFETY (ICTIS), P1177, DOI 10.1109/ICTIS.2017.8047920
   Chen WL, 2019, IEEE ACCESS, V7, P37575, DOI 10.1109/ACCESS.2019.2905769
   Cho H, 2015, OCEAN ENG, V104, P568, DOI 10.1016/j.oceaneng.2015.05.037
   Coiras E, 2007, IEEE T IMAGE PROCESS, V16, P382, DOI 10.1109/TIP.2006.888337
   Ferreira F, 2015, ANNU REV CONTROL, V40, P212, DOI 10.1016/j.arcontrol.2015.09.014
   Galceran E., 2012, IFAC Proceedings, V45, P306, DOI DOI 10.3182/20120410-3-PT-4028.00051
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   Hover FS, 2012, INT J ROBOT RES, V31, P1445, DOI 10.1177/0278364912461059
   Jian Z, 2017, 2017 INT C COMPUTER
   Kawasaki H, 2017, IEEE WINT CONF APPL, P302, DOI 10.1109/WACV.2017.40
   Kumar M, 2020, ARCH COMPUT METHOD E
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Li J., 2018, IOP CONF SER-MAT SCI, V439
   Liu Tao, 2014, Applied Mechanics and Materials, V532, P165, DOI 10.4028/www.scientific.net/AMM.532.165
   Longxing W, 1864, LECT NOTES ELECT ENG, V861, P2022
   Negahdaripour S., 2011, OCEANS'11 MTS/IEEE KONA, P1
   Preciado-Grijalva A., 2022, SELF SUPERVISED LEAR, DOI [10.1109/CVPRW56347.2022.00156, DOI 10.1109/CVPRW56347.2022.00156]
   Sheng Mingwei, 2018, Journal of Huazhong University of Science and Technology (Natural Science Edition), V46, P93, DOI 10.13245/j.hust.180818
   Shim H, 2010, OCEAN ENG, V37, P1036, DOI 10.1016/j.oceaneng.2010.03.017
   Tang YH, 2021, CHIN CONTR CONF, P8416, DOI 10.23919/CCC52363.2021.9550003
   York D, 1966, CAN JOUR PHYS, V44
   Yu S, 2022, MATH PROBL ENG
   Zhang CX, 2015, PROCEEDINGS OF 2015 IEEE 12TH INTERNATIONAL CONFERENCE ON ELECTRONIC MEASUREMENT & INSTRUMENTS (ICEMI), VOL. 3, P1172, DOI 10.1109/ICEMI.2015.7494462
   Zhao J, 2018, OCEAN OPTICS INFORM
NR 26
TC 0
Z9 0
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29713
EP 29732
DI 10.1007/s11042-023-14822-2
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000943970200007
DA 2024-07-18
ER

PT J
AU Tsuru, T
   Hasegawa, M
   Shoji, Y
   Nguyen, K
   Sekiya, H
AF Tsuru, Taichi
   Hasegawa, Mikio
   Shoji, Yozo
   Nguyen, Kien
   Sekiya, Hiroo
TI An implementation and evaluation of MPTCP-based IoT router
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MPTCP; IoT; evaluation
AB The evolving Internet of Things (IoT) promisingly improves the quality of life and transforms many industries. However, the IoT application challenges the wireless networks since the resource-constrained IoT devices typically need to send data to the cloud or edge server. Therefore, it is necessary to introduce an intermediate device between IoT devices and the servers, for example, to reduce the cost of direct communication between them. In another case, the device may move and collect the data from IoT devices before transmitting it to the server. The intermediate device should be designed to have resilient Internet connections and sufficient bandwidth in such a context. This work implements and evaluates a Multipath TCP (MPTCP) IoT router, which uses multiple radios to connect a server to address the demanding design. The router leverages MPTCP, an extension of TCP for simultaneous transmission over several paths on top of Wi-Fi interfaces. MPTCP has also supported several working modes for throughput and (or) resilience enhancements. First, we implement the MPTCP kernels, which can run on the popular IoT devices Raspberry Pi 3B+ and 4. Second, we extensively evaluate the performance of IoT routers in a static and mobility scenario. The static scenario's evaluation results show that the MPTCP-based router can achieve seamless handover and bandwidth aggregation. In the mobility scenario, the MPTCP router with one backup path performs better than the single-path TCP. Besides, the MPTCP routers are more energy-efficient than TCP on the same hardware.
C1 [Tsuru, Taichi; Nguyen, Kien; Sekiya, Hiroo] Chiba Univ, Grad Sch Engn, Chiba, Japan.
   [Hasegawa, Mikio] Tokyo Univ Sci, Dept Elect Engn, Tokyo, Japan.
   [Shoji, Yozo] Natl Inst Informat & Commun Technol, Social ICT Syst Lab, Tokyo, Japan.
   [Nguyen, Kien] Chiba Univ, Inst Adv Acad Res, Chiba, Japan.
C3 Chiba University; Tokyo University of Science; National Institute of
   Information & Communications Technology (NICT) - Japan; Chiba University
RP Nguyen, K (corresponding author), Chiba Univ, Grad Sch Engn, Chiba, Japan.; Nguyen, K (corresponding author), Chiba Univ, Inst Adv Acad Res, Chiba, Japan.
EM mrt726625@icloud.com; hasegawa@ee.kagu.tus.ac.jp; shoji@nict.go.jp;
   nguyen@chiba-u.jp; sekiya@faculty.chiba-u.jp
RI Sekiya, Hiroo/I-5987-2019; Hasegawa, Mikio/AAV-1430-2021
OI Sekiya, Hiroo/0000-0003-3557-1463; Hasegawa, Mikio/0000-0001-5638-8022;
   Nguyen, Kien/0000-0003-0400-3084
FU Japan Society for the Promotion of Science (JSPS) [20H0417]; Japan
   Science and Technology Agency (JST) [JPMJFS2107]; Grants-in-Aid for
   Scientific Research [20H04174] Funding Source: KAKEN
FX This work was supported in part by the Japan Society for the Promotion
   of Science (JSPS) under Grant 20H0417 and in part by the Japan Science
   and Technology Agency (JST) through the establishment of university
   fellowships towards the creation of science technology innovation, Grant
   Number JPMJFS2107
CR Aloi G, 2017, J NETW COMPUT APPL, V81, P74, DOI 10.1016/j.jnca.2016.10.013
   [Anonymous], 2021, COOWOO POW MET
   [Anonymous], 2012, 9 USENIX S NETW SYST
   [Anonymous], 2021, RASPBERRY PI LINUX K
   [Anonymous], 2021, MPTCP KERNEL ANDROID
   [Anonymous], 2021, IPROUTE MPTCP
   [Anonymous], 2013, 2013 IEEE International Conference on Green Computing and Communications and IEEE Internet of Things and IEEE Cyber, Physical and Social Computing, DOI [DOI 10.1109/GREENCOM-ITHINGS-CPSCOM.2013.130, 10.1109/GreenCom-iThings-CPSCom.2013.130]
   [Anonymous], 2013, Technical Report
   [Anonymous], 2021, MPTCP LINUX KERNEL
   Apple Inc, 2020, IMPR NETW REL US MUL
   Bimschas Daniel., 2010, Proceedings of the 5th International Workshop on Middleware Tools, Services and Run-Time Supportfor Sensor Networks, P8
   Chen H, 2011, PROCEEDINGS OF 2011 INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY AND APPLICATION, ICCTA2011, P610, DOI 10.1049/cp.2011.0740
   Chen XJ, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTER AND COMPUTATIONAL SCIENCES (ICCCS), P257, DOI 10.1109/ICCACS.2015.7361361
   Cirillo F, 2020, IEEE INTERNET THINGS, V7, P5267, DOI 10.1109/JIOT.2020.2978770
   Datta SK, 2014, 2014 IEEE WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P514, DOI 10.1109/WF-IoT.2014.6803221
   FreeBSD, 2018, MULTIPATH TCP FREEBS
   Garcia L., 2018, Network Protocols and Algorithms, V10, P23, DOI DOI 10.5296/NPA.V10I1.12798
   Iperf3, 2021, US
   Kang B, 2017, IEEE T MULTI-SCALE C, V3, P206, DOI 10.1109/TMSCS.2017.2705683
   Kaspa D, 2011, THESIS U OSLO
   Khalili R, 2013, IEEE ACM T NETWORK, V21, P1651, DOI 10.1109/TNET.2013.2274462
   Kibria MG, 2018, IEEE WIREL COMMUN, V25, P120, DOI 10.1109/MWC.2018.1700277
   Nguyen K, 2019, IEICE T COMMUN, VE102B, P1904, DOI 10.1587/transcom.2018EBP3208
   Nguyen K, 2019, WIREL COMMUN MOB COM, DOI 10.1155/2019/4089365
   Nguyen K, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030476
   Nguyen K, 2017, COMPUT ELECTR ENG, V57, P104, DOI 10.1016/j.compeleceng.2016.09.014
   Mondal A, 2018, NATL CONF COMMUN
   Ndiaye M, 2020, IEEE ACCESS, V8, P186821, DOI 10.1109/ACCESS.2020.3030090
   Peng Q, 2015, IEEE ACM T NETWORK
   Saxena N, 2017, IEEE COMMUN MAG, V55, P97, DOI 10.1109/MCOM.2017.1600437CM
   Wischik D., 2011, USENIX NSDI, P99
   Zhu Q., 2010, IEEEIFIP 8 INT C EMB, P347, DOI [10.1109/EUC.2010.58, DOI 10.1109/EUC.2010.58]
   Zielonka A, 2021, IEEE T IND INFORM, V17, P4308, DOI 10.1109/TII.2020.3009094
NR 33
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28389
EP 28404
DI 10.1007/s11042-023-14781-8
EA MAR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000943163700006
PM 37362665
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Nie, L
   Lin, JF
   Kang, WX
   Shi, YK
   Lin, L
AF Nie, Lin
   Lin, Junfan
   Kang, Wenxiong
   Shi, Yukai
   Lin, Liang
TI Learning image blind denoisers without explicit noise modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Blind; Noise modeling
ID NETWORK
AB Image blind denoising aims at removing the unknown noise from given images to improve the image's visual quality. Current blind denoisers can be categorized into two classes, i.e., traditional and deep learning-based methods. Generally, deep learning-based methods are likely to outperform the traditional methods when the model of image noise is within the training noise distribution. However, when the image noise is unseen during the optimization process, traditional methods usually achieve better denoising performance. To address the generalization problem of deep learning-based denoiser, our paper proposed a general yet concise image blind denoising framework that can be applied to existing deep learning-based denoisers. Specifically, given noisy images, our method first extracts high-frequency signals from the images and synthesizes noise from the extracted signals using several noise generation techniques. In contrast to the existing conventional approaches that explicitly model the noise, our proposed framework advances in generating noise directly from the noisy images without explicitly noise modeling. By applying the generated noise to clean images to construct noisy-clean paired images, the deep learning-based denoisers can be optimized using the constructed data with the similar noise of the given noisy images. After optimization, the denoisers are capable of removing noise from the given noisy images. Extensive experiments and comprehensive ablations on both synthetic noisy image and real-world image denoising tasks demonstrate the superiority of our proposed framework over all the compared approaches.
C1 [Nie, Lin; Kang, Wenxiong] South China Univ Technol, Sch Automat Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China.
   [Lin, Junfan; Lin, Liang] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
   [Shi, Yukai] Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Guangdong, Peoples R China.
C3 South China University of Technology; Sun Yat Sen University; Guangdong
   University of Technology
RP Lin, JF (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
EM linjf8@mail2.sysu.edu.cn; ykshi@gdut.edu.cn
RI Lin, Junfan/GQI-3882-2022; qin, cheng/KHC-3344-2024
FU National Natural Science Foundation of China (NSFC); Science and
   Technology Project of Guangdong Province [2021A1515011341,
   2022A1515011835]; China Postdoctoral Science Foundation [2021M703687];
   Guangzhou Science and Technology Plan Project [202002030386, 102020369]
FX This work is supported in part by National Natural Science Foundation of
   China (NSFC) (no. 62002069), the Science and Technology Project of
   Guangdong Province (no. 2021A1515011341, 2022A1515011835), China
   Postdoctoral Science Foundation funded project (Grant no. 2021M703687)
   and the Guangzhou Science and Technology Plan Project (no. 202002030386,
   102020369).
CR ABSoft N, 2022, NEAT IM
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Anayaa J, 2014, J VIS COMMUN IMAGE R
   Bai Y, 2021, IEEE ICC, DOI 10.1109/ICC42927.2021.9500657
   Cao QX, 2017, PROC CVPR IEEE, P1656, DOI 10.1109/CVPR.2017.180
   Chen JW, 2018, PROC CVPR IEEE, P3155, DOI 10.1109/CVPR.2018.00333
   Chen TS, 2022, IEEE T PATTERN ANAL, V44, P1371, DOI 10.1109/TPAMI.2020.3025814
   Dabov K, 2007, IEEE IMAGE PROC, P313, DOI 10.1109/icip.2007.4378954
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   European Machine Vision Association, 2010, 1288 EMVA, V1288
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Granados M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508410
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kingma D. P., 2014, arXiv
   Lebrun M, 2013, SIAM J IMAGING SCI, V6, P1665, DOI 10.1137/120874989
   Lebrun M, 2015, IMAGE PROCESS ON LIN, V5, P1, DOI 10.5201/ipol.2015.125
   Lebrun M, 2015, IEEE T IMAGE PROCESS, V24, P3149, DOI 10.1109/TIP.2015.2439041
   Lefkimmiatis S, 2017, PROC CVPR IEEE, P5882, DOI 10.1109/CVPR.2017.623
   Li H, 2022, IEEE T MULTIMEDIA
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lin Y., 2022, ARXIV
   Liu C, 2008, IEEE T PATTERN ANAL, V30, P299, DOI 10.1109/TPAMI.20071176
   Liu XH, 2013, IEEE T IMAGE PROCESS, V22, P5226, DOI 10.1109/TIP.2013.2283400
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P1004, DOI 10.1109/TIP.2016.2631888
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Meng DY, 2013, IEEE I CONF COMP VIS, P1337, DOI 10.1109/ICCV.2013.169
   Nam S, 2016, PROC CVPR IEEE, P1683, DOI 10.1109/CVPR.2016.186
   Plötz T, 2017, PROC CVPR IEEE, P2750, DOI 10.1109/CVPR.2017.294
   Portilla J, 2004, IEEE IMAGE PROC, P1217
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Portilla J., 2004, BENELUX SIGNAL PROCE
   Rabie T, 2005, IEEE T IMAGE PROCESS, V14, P1755, DOI 10.1109/TIP.2005.857276
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Santoro A., 2016, INT C MACH LEARN, P1842, DOI DOI 10.5555/3045390.3045585
   Shi Y, 2016, 2016 IEEE INT C MULT, P1
   Shi YK, 2021, ACM T INTEL SYST TEC, V12, DOI 10.1145/3448733
   Shi YK, 2020, IEEE SIGNAL PROC LET, V27, P481, DOI 10.1109/LSP.2020.2978410
   Shi YK, 2020, IEEE T PATTERN ANAL, V42, P2809, DOI 10.1109/TPAMI.2019.2915301
   Shi YK, 2019, IEEE ACCESS, V7, P39660, DOI 10.1109/ACCESS.2019.2906936
   Shi Y, 2017, IEEE T MULTIMEDIA, V19, P2804, DOI 10.1109/TMM.2017.2711263
   Shocher A, 2018, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2018.00329
   Tan JP, 2021, IEEE T MULTIMEDIA, V23, P2943, DOI 10.1109/TMM.2020.3019683
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wu XJ, 2014, INT CONF MEAS, P55, DOI 10.1109/ICMTMA.2014.20
   Xu J, 2018, ARXIV
   Xu J, 2018, IEEE T IMAGE PROCESS, V27, P2996, DOI 10.1109/TIP.2018.2811546
   Xu J, 2017, IEEE I CONF COMP VIS, P1105, DOI 10.1109/ICCV.2017.125
   Xu J, 2015, IEEE I CONF COMP VIS, P244, DOI 10.1109/ICCV.2015.36
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhu FY, 2016, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2016.52
   Zhu L, 2017, PROC CVPR IEEE, P493, DOI 10.1109/CVPR.2017.60
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 60
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27839
EP 27859
DI 10.1007/s11042-023-14590-z
EA FEB 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000937854600001
DA 2024-07-18
ER

PT J
AU Shrestha, H
   Jaganathan, SCB
   Dhasarathan, C
   Suriyan, K
AF Shrestha, Hewan
   Jaganathan, Subash Chandra Bose
   Dhasarathan, Chandramohan
   Suriyan, Kannadhasan
TI Detection and classification of dermatoscopic images using segmentation
   and transfer learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Melanoma detection; U-net segmentation; Transfer learning; Biomedical
   image classification
ID MELANOMA; NETWORKS
AB With the increase in the number of cases every year, skin cancer stays as one of the most common cancers worldwide. Although dermatologists have been aided with modern research study in detection of cancer, proper treatment of cancer has been a quite challenging task due to the visual appearance of cells. In this experiment, we have studied segmentation and classification algorithms for early detection of cancerous cells, as early detection may increase survival rate of the affected person. HAM10000 dataset has been utilized in this study which has 10,015 different images into seven different classes. Three different types of segmentation algorithms have been studied in this experiment, U-Net, ResUNet and DeeplabV3+. Among all these, DeeplabV3+ appears to outperform the rest of the algorithms giving an overall accuracy of 96.21%, precision and recall of 93.26% and 93% respectively. Few pre-trained models namely ResNet50, ResNet152, SqueezeNet1.1 and DenseNet121 have been utilized for classification of skin cancer. As per the results obtained from the experiment, ResNet152 outperforms the rest of the three pre-trained models with an overall training and validation accuracy of 81.75% and 78.51% respectively.
C1 [Shrestha, Hewan] Saarland Univ, Dept Comp Sci, Saarbrucken, Germany.
   [Jaganathan, Subash Chandra Bose] VIT Bhopal Univ, Sch Comp Sci & Engn, Bhopal Indore Highway, Sehore 466114, Madhya Pradesh, India.
   [Dhasarathan, Chandramohan] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
   [Suriyan, Kannadhasan] Study World Coll Engn, Dept Elect & Commun Engn, Coimbatore, Tamilnadu, India.
C3 Saarland University; VIT Bhopal University; Thapar Institute of
   Engineering & Technology
RP Jaganathan, SCB (corresponding author), VIT Bhopal Univ, Sch Comp Sci & Engn, Bhopal Indore Highway, Sehore 466114, Madhya Pradesh, India.
EM shresthahewan12@gmail.com; jsubashme@gmail.com;
   pdchandramohan@gmail.com; kannadhasan.ece@gmail.com
RI DHASARATHAN, CHANDRAMOHAN/E-3555-2015; Suriyan, Dr.
   Kannadhasan/AAI-7925-2020; Shrestha, Hewan/AAH-5559-2021
OI DHASARATHAN, CHANDRAMOHAN/0000-0002-5279-950X; Suriyan, Dr.
   Kannadhasan/0000-0001-6443-9993; Shrestha, Hewan/0000-0003-3901-2212;
   Jaganathan, Dr. Subash Chandra Bose/0000-0003-2497-1621
CR Abbas Q, 2019, MULTIMED TOOLS APPL, V78, P23559, DOI 10.1007/s11042-019-7652-y
   Abbasi AA, 2020, COGN NEURODYNAMICS, V14, P523, DOI 10.1007/s11571-020-09587-5
   Albert BA, 2020, IEEE ACCESS, V8, P31254, DOI 10.1109/ACCESS.2020.2973188
   Arora R, 2021, BIOMED SIGNAL PROCES, V65, DOI 10.1016/j.bspc.2020.102358
   Barata C, 2014, IEEE SYST J, V8, P965, DOI 10.1109/JSYST.2013.2271540
   Bose SC, 2020, ADV INTELL SYST COMP, V1108, P26, DOI 10.1007/978-3-030-37218-7_4
   Chaturvedi SS, 2020, MULTIMED TOOLS APPL, V79, P28477, DOI 10.1007/s11042-020-09388-2
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chou HY, 2021, COMPUT MED IMAG GRAP, V87, DOI 10.1016/j.compmedimag.2020.101833
   Diakogiannis FI, 2020, ISPRS J PHOTOGRAMM, V162, P94, DOI 10.1016/j.isprsjprs.2020.01.013
   Dobbs TD, 2021, J PLAST RECONSTR AES, V74, P615, DOI 10.1016/j.bjps.2020.09.005
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Ichim L, 2020, IEEE ACCESS, V8, P179189, DOI 10.1109/ACCESS.2020.3028248
   Jin QG, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106881
   Kassani SH, 2019, TISSUE CELL, V58, P76, DOI 10.1016/j.tice.2019.04.009
   Kim D, 2021, IEEE ACCESS, V9, P42610, DOI 10.1109/ACCESS.2021.3065701
   Madooei A, 2019, IEEE J BIOMED HEALTH, V23, P779, DOI 10.1109/JBHI.2018.2835405
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Putra TA, 2020, IEEE ACCESS, V8, P40536, DOI 10.1109/ACCESS.2020.2976045
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sáaez A, 2019, IEEE J BIOMED HEALTH, V23, P560, DOI 10.1109/JBHI.2018.2823499
   Shell J, 2015, INFORM SCIENCES, V293, P59, DOI 10.1016/j.ins.2014.09.004
   Shrestha H, 2022, ADV INTELL SYST COMP, V1411, DOI 10.1007/978-981-16-6887
   Shrestha H, 2020, INT J SPEECH TECHNOL, V23, P757, DOI 10.1007/s10772-020-09730-x
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Simon M, 2020, MED IMAGE ANAL, DOI 10.1016/j.media.2020.101915
   Subash Chandra Bose J., 2012, EUR J SCI RES, V86, P103
   Thurnhofer-Hemsi K, 2021, IEEE ACCESS, V9, P112193, DOI 10.1109/ACCESS.2021.3103410
   Thurnhofer-Hemsi K, 2021, NEURAL PROCESS LETT, V53, P3073, DOI 10.1007/s11063-020-10364-y
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Yu Z, 2019, IEEE T BIO-MED ENG, V66, P1006, DOI 10.1109/TBME.2018.2866166
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 34
TC 3
Z9 3
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23817
EP 23831
DI 10.1007/s11042-023-14752-z
EA FEB 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000936195100010
DA 2024-07-18
ER

PT J
AU Abedzadeh, M
   Rostami, MJ
   Shariatzadeh, M
AF Abedzadeh, Mohammad
   Rostami, Mohamad Javad
   Shariatzadeh, Mahdi
TI Image encryption using a standard map and a teaching-learning based
   optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image digest; Image encryption; Logistic map; SHA-512; Standard map;
   TLBO
ID HYBRID GENETIC ALGORITHM; DNA ENCRYPTION; CHAOS THEORY; COLOR; SYSTEM;
   KEY
AB Image encryption is a topic that has been the subject of numerous articles and dissertations in recent years. A proper encryption algorithm has high speed and can withstand statistical and differential attacks. The image digest gives a different output for each image, and only by changing one bit in the image, the output changes completely. Therefore, the image digest can be used as a suitable option for the initial values of the chaotic map. In this paper, the images are encrypted using the Teaching-Learning Based Optimization (TLBO) algorithm. First, the image digest is calculated by SHA-512 and used to generate numbers between zero and one. The image is then divided into 16 equal parts. In the next step, the image pixels are shuffled using the special mode of the standard map developed in this article. Then each of the parts becomes a teacher once. The best value, one that improves the entropy, is selected among the generated values. The other parts follow this value, and the initial value of the chaotic function is obtained for all 16 parts. Then the encryption of each part is done by the logistic map. This algorithm has relatively good execution time and has demonstrated good results against statistical and differential attacks. Among the most important results obtained for the proposed method, reaching the value of 35.5 for UACI, reaching the value of 99.6 for NPCR, and reaching the value of 7.971 for the information entropy can be mentioned.
C1 [Abedzadeh, Mohammad; Rostami, Mohamad Javad; Shariatzadeh, Mahdi] Shahid Bahonar Univ Kerman, Dept Comp Engn, Kerman, Iran.
C3 Shahid Bahonar University of Kerman (SBUK)
RP Rostami, MJ (corresponding author), Shahid Bahonar Univ Kerman, Dept Comp Engn, Kerman, Iran.
EM rostami@uk.ac.ir
CR Abbasi AA, 2020, OPTIK, V219, DOI 10.1016/j.ijleo.2020.164949
   Abd EL-Latif AA, 2020, PHYSICA A, V547, DOI 10.1016/j.physa.2019.123869
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Akhshani A, 2014, COMMUN NONLINEAR SCI, V19, P101, DOI 10.1016/j.cnsns.2013.06.017
   Ali TS, 2020, MULTIMED TOOLS APPL, V79, P19853, DOI 10.1007/s11042-020-08850-5
   Azimi Z, 2020, MULTIMED TOOLS APPL, V79, P1727, DOI 10.1007/s11042-019-08375-6
   Budda N, 2021, MATER TODAY-PROC
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Dong H, 2020, IEEE ACCESS, V8, P163524, DOI 10.1109/ACCESS.2020.3022398
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Faragallah OS, 2020, MULTIMED TOOLS APPL, V79, P2495, DOI 10.1007/s11042-019-08190-z
   Ferdush Jannatul, 2021, International Journal of Computers and Applications, V43, P960, DOI 10.1080/1206212X.2019.1662170
   Ghazvini M, 2020, MULTIMED TOOLS APPL, V79, P26927, DOI 10.1007/s11042-020-09058-3
   Guesmi R, 2021, MULTIMED TOOLS APPL, V80, P1925, DOI 10.1007/s11042-020-09672-1
   Hansen L, 2011, EUR J INT RELAT, V17, P51, DOI 10.1177/1354066110388593
   Hasheminejad A, 2019, OPTIK, V184, P205, DOI 10.1016/j.ijleo.2019.03.065
   Kang XJ, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115670
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Kaur M, 2018, IMAGING SCI J, V66, P453, DOI 10.1080/13682199.2018.1505327
   Kaur M, 2018, ARAB J SCI ENG, V43, P8127, DOI 10.1007/s13369-018-3355-3
   Kaur M, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418501328
   Khalfallah AC, 2020, INF SECUR J, V29, P297, DOI 10.1080/19393555.2020.1767831
   Kumar V, 2021, MULTIMED TOOLS APPL, V80, P3749, DOI 10.1007/s11042-020-09854-x
   Liu Q, 2020, IEEE ACCESS, V8, P83596, DOI 10.1109/ACCESS.2020.2991420
   Malik MGA, 2020, IEEE ACCESS, V8, P88093, DOI 10.1109/ACCESS.2020.2990170
   Mather JN., 1984, ERGOD THEORY DYN SYS, V4, P301, DOI [10.1017/S0143385700002455, DOI 10.1017/S0143385700002455]
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Noshadian S, 2020, MULTIMED TOOLS APPL, V79, P25635, DOI 10.1007/s11042-020-09233-6
   Noshadian S, 2018, MULTIMED TOOLS APPL, V77, P25569, DOI 10.1007/s11042-018-5807-x
   Palacios-Luengas L, 2019, ARAB J SCI ENG, V44, P3817, DOI 10.1007/s13369-018-3688-y
   Perre RM, 2020, CHAOS SOLITON FRACT, V131, DOI 10.1016/j.chaos.2019.109520
   Rao RV, 2011, COMPUT AIDED DESIGN, V43, P303, DOI 10.1016/j.cad.2010.12.015
   Rehman AU, 2020, IEEE ACCESS, V8, P172275, DOI 10.1109/ACCESS.2020.3024994
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   Rostami MJ, 2017, COMPUT ELECTR ENG, V62, P384, DOI 10.1016/j.compeleceng.2017.04.004
   Shariatzadeh M, 2021, OPTIK, V246, DOI 10.1016/j.ijleo.2021.167779
   Srivastava SCL, 2015, CHAOS SOLITON FRACT, V74, P67, DOI 10.1016/j.chaos.2014.12.011
   Talarposhti KM, 2016, OPT LASER ENG, V81, P21, DOI 10.1016/j.optlaseng.2016.01.006
   Wang MX, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110028
   Wang XY, 2020, OPT LASER ENG, V125, DOI 10.1016/j.optlaseng.2019.105851
   Wang YJ, 2020, MULTIMED TOOLS APPL, V79, P18317, DOI 10.1007/s11042-020-08742-8
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Yadollahi M, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102505
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhou SH, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22101091
NR 48
TC 0
Z9 0
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29199
EP 29225
DI 10.1007/s11042-023-14379-0
EA FEB 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000936501100006
DA 2024-07-18
ER

PT J
AU Omranpour, H
   Tirdad, V
   Misaghi, A
AF Omranpour, Hesam
   Tirdad, Vajihe
   Misaghi, Aref
TI Representation of fingerprint recognition system based on geometric and
   statistical features of distance and angle of minutiae points
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature extraction; Geometric feature; Statistical features; LDA; KNN;
   Pattern recognition; Deep learning
ID VERIFICATION
AB This paper presents an approach for identifying fingerprints through the extraction of geometric and statistical features of characteristic Minutiae. The proposed approach is in accordance with statistical features to extract important points from the skeleton of a fingerprint's image. Through the addition of geometric features as a kind of preprocessing to this approach, the images are divided into distinct regions. In this approach, statistical parameters like min, max, mean and standard deviation are applied in order to compute the general abstract of the features. Another achievement in this article is the presentation of a similarity measure in identification tools which is only used for methods based on matching patterns. The Optimized version of the proposed method achieved near zero EER percentage in some of the datasets.
C1 [Omranpour, Hesam; Tirdad, Vajihe; Misaghi, Aref] Babol Noshirvani Univ Technol, Elect & Comp Engn Dept, Babol, Iran.
C3 Babol Noshirvani University of Technology
RP Omranpour, H (corresponding author), Babol Noshirvani Univ Technol, Elect & Comp Engn Dept, Babol, Iran.
EM h.omranpour@nit.ac.ir
CR Babatunde Iwasokun Gabriel, 2013, 2013 Science and Information Conference (SAI), P434
   Benhammadi F, 2007, PATTERN RECOGN, V40, P189, DOI 10.1016/j.patcog.2006.06.031
   Cappelli R, 2010, IEEE T PATTERN ANAL, V32, P2128, DOI 10.1109/TPAMI.2010.52
   Dadgostar, 2008, 5 IRANIAN C VISION M, P4
   Feng JJ, 2008, PATTERN RECOGN, V41, P342, DOI 10.1016/j.patcog.2007.04.016
   Ghaddab MH, 2017, I C COMP SYST APPLIC, P751, DOI 10.1109/AICCSA.2017.33
   He YL, 2006, IEEE T PATTERN ANAL, V28, P850, DOI 10.1109/TPAMI.2006.119
   Hendre M, 2022, MULTIMED TOOLS APPL, V81, P17483, DOI 10.1007/s11042-021-11686-2
   Islam M. M., 2020, Social Netw. Comput. Sci., V1, P1, DOI [10.1007/s42979-020-00223-x, DOI 10.1007/S42979-020-00223-X]
   Ji LP, 2007, IEEE T SYST MAN CY B, V37, P1407, DOI 10.1109/TSMCB.2007.903369
   Kumar R, 2016, J INF PROCESS SYST, V12, P83, DOI 10.3745/JIPS.02.0020
   Lang Dane, 2022, Pattern Recognition and Artificial Intelligence: Third International Conference, ICPRAI 2022, Paris, France, June 1-3, 2022, Proceedings, Part II. Lecture Notes in Computer Science (13364), P15, DOI 10.1007/978-3-031-09282-4_2
   Li Qiongxiu, 2017, IEIE Transactions on Smart Processing & Computing, V6, P387, DOI 10.5573/IEIESPC.2017.6.6.387
   Li Tian, 2007, 2007 Third International IEEE Conference on Signal-Image Technologies and Internet-Based System (SITIS), P593, DOI 10.1109/SITIS.2007.75
   Liu YH, 2020, APPL INTELL, V50, P397, DOI 10.1007/s10489-019-01530-4
   Maio D, 2004, LECT NOTES COMPUT SC, V3072, P1
   Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144
   Maio D, 2002, IEEE T PATTERN ANAL, V24, P402, DOI 10.1109/34.990140
   Maltoni D., 2009, Handbook of fingerprint recognition, V2
   Nassiri, 2011, 3 NATL C COMPUTER EN
   Peralta D, 2015, INFORM SCIENCES, V315, P67, DOI 10.1016/j.ins.2015.04.013
   Pourghasem, 2005, 3 IRANIAN C VISION M
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Pradeep N. R., 2021, International Journal of Information Technology, V13, P1581, DOI 10.1007/s41870-021-00700-3
   Ross A, 2003, PATTERN RECOGN, V36, P1661, DOI 10.1016/S0031-3203(02)00349-7
   Watson C.I., 2007, USERS GUIDE NIST BIO
   Xiang C, 2006, IEEE T IMAGE PROCESS, V15, P2097, DOI 10.1109/TIP.2006.875225
   Yager N, 2004, PATTERN ANAL APPL, V7, P94, DOI 10.1007/s10044-003-0201-2
NR 28
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27727
EP 27750
DI 10.1007/s11042-023-14506-x
EA FEB 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000934850300001
DA 2024-07-18
ER

PT J
AU Deshmukh, PV
   Kapse, AS
   Thakare, VM
   Kapse, AS
AF Deshmukh, Priyanka V.
   Kapse, Avinash S.
   Thakare, V. M.
   Kapse, Arvind S.
TI High capacity reversible data hiding in encrypted images using multi-MSB
   data hiding mechanism with elliptic curve cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Image encryption; Elliptic curve cryptography;
   Multi MSB prediction; Image security; Hiding capacity; Location map
ID PREDICTION
AB Data-hiding technology plays an important role in fields of the image such as copyright identification and annotation. Predicators may be exploited in RDH in the encrypted image (RDHEI); this has become a research interest in recent years because of the development of cloud computing and a need for content owner privacy. The existing algorithms cannot implement large embedding capacity and good reconstructed image quality simultaneously. Consequently, for secure data image transfer, the article suggested the High-Capacity Reversible Data Hiding in Encrypted Images (RDH-EI) approach. The original image was pre-processed by the content owner to free up hiding space in the RRBE scheme, following which the image will be encrypted and transferred to the data hider. Asymmetric encryption is considered to be more secure than symmetric encryption as it uses two keys for the process. Initially, to offer authenticity and integrity, Elliptic Curve Cryptography (ECC) is proposed to encrypt, decrypt, and authenticate the cipher image. This requires much shorter key lengths and was highly efficient in the decryption process. Further, the encrypted images are directed to the data hiding process. A considerable amount of data is employed to embed in the image encryption domain to ensure that the embedded data can be extracted error-free. Subsequently, to have high embedding capacity, the research proposed Multi-MSB (Most Significant Bit) data embedding scheme in which secret bits can be directly extracted from the encrypted domain from the pixels without any error. In addition, to retain image quality by employing both reference and context pixels, a near-lossless solution based on the Huffman Coding technique is proposed. With the use of decryption and a data concealing key, the receiver can restore the original image and extract hidden data afterwards. The keys are made in such a way that the decryption key cannot be easily deduced from the public encryption key. The experiment was carried out in MATLAB software using a built-in function. The findings reveal that the suggested method outperforms conventional RDH strategies in terms of PSNR and embedding with 3.6 bpp respectively. In addition, the algorithm can resist steganalysis attacks, and demonstrated the effectiveness of the proposed algorithm.
C1 [Deshmukh, Priyanka V.] Shri Sant Gajanan Maharaj Coll Engn, Shegaon 444203, Maharashtra, India.
   [Kapse, Avinash S.] Anuradha Coll Engn, Dept IT, Chikhali 443201, Maharashtra, India.
   [Thakare, V. M.] Sant Gadge Baba Amravati Univ, Dept CSE, Amravati 444602, Maharashtra, India.
   [Kapse, Arvind S.] New Horizon Coll Engn, Bengaluru 560103, Karnataka, India.
C3 Sant Gadge Baba Amravati University
RP Deshmukh, PV (corresponding author), Shri Sant Gajanan Maharaj Coll Engn, Shegaon 444203, Maharashtra, India.
EM priyanka8deshmukh@gmail.com
RI Deshmukh, Dr Priyanka/JSL-5751-2023; Deshmukh, Priyanka/JCO-3777-2023;
   Kapse, Arvind/ABG-4541-2020
OI Kapse, Arvind/0000-0002-2592-5603; Kapse, Dr.
   Avinash/0000-0003-4637-6006
CR Ahmed S, 2022, ADV INTELL SYST COMP, V1411, P255, DOI 10.1007/978-981-16-6887-6_21
   Aziz F, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231602
   Fatima E, 2019, LECT NOTES COMPUT SC, V11952, P290, DOI 10.1007/978-3-030-36945-3_16
   Fu YJ, 2019, INFORM SCIENCES, V494, P21, DOI 10.1016/j.ins.2019.04.043
   Hassan FS, 2020, MULTIMED TOOLS APPL, V79, P30087, DOI 10.1007/s11042-020-09513-1
   Hu RW, 2021, IEEE SIGNAL PROC LET, V28, P464, DOI 10.1109/LSP.2021.3059202
   Huang B, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9172166
   Kumar R, 2020, INFORM SCIENCES, V536, P101, DOI 10.1016/j.ins.2020.05.047
   Kumar R, 2020, INFORM SCIENCES, V512, P96, DOI 10.1016/j.ins.2019.09.062
   Liu Y, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10060664
   Lyu WL, 2022, SIGNAL PROCESS, V201, DOI 10.1016/j.sigpro.2022.108686
   Malik A, 2020, IEEE ACCESS, V8, P148997, DOI 10.1109/ACCESS.2020.3015882
   Maniriho P, 2019, J KING SAUD UNIV-COM, V31, P335, DOI 10.1016/j.jksuci.2018.01.011
   Nguyen TS, 2022, J INTERNET TECHNOL, V23, P255, DOI 10.53106/160792642022032302006
   Qiu YQ, 2022, IEEE T CIRC SYST VID, V32, P5874, DOI 10.1109/TCSVT.2022.3163905
   Qiu YQ, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107288
   Sahu A., 2019, INT J INTELL ENG SYS, V12, P63, DOI DOI 10.22266/IJIES2019.1031.07
   Sahu AK, 2022, J KING SAUD UNIV-COM, V34, P1395, DOI 10.1016/j.jksuci.2019.07.004
   Tang ZJ, 2019, J REAL-TIME IMAGE PR, V16, P709, DOI 10.1007/s11554-018-0838-0
   Wang JX, 2020, IEEE T CIRC SYST VID, V30, P2313, DOI 10.1109/TCSVT.2019.2915584
   Wang JX, 2019, SIGNAL PROCESS, V159, P193, DOI 10.1016/j.sigpro.2019.02.013
   Wang XY, 2021, IEEE SIGNAL PROC LET, V28, P1125, DOI 10.1109/LSP.2021.3080181
   Wang X, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/9606116
   Weng SW, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2020.102932
   Wu XT, 2020, MULTIMED TOOLS APPL, V79, P23425, DOI 10.1007/s11042-020-09098-9
   Xiong XG, 2022, SIGNAL PROCESS, V194, DOI 10.1016/j.sigpro.2022.108458
   Xu DW, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/7480147
   Xu SY, 2021, IEEE ACCESS, V9, P55191, DOI 10.1109/ACCESS.2021.3071819
   Yamaç M, 2021, IEEE T INF FOREN SEC, V16, P1014, DOI 10.1109/TIFS.2020.3026467
   Yu CQ, 2022, INFORM SCIENCES, V584, P89, DOI 10.1016/j.ins.2021.10.050
NR 30
TC 1
Z9 1
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28087
EP 28115
DI 10.1007/s11042-023-14683-9
EA FEB 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000939670800002
DA 2024-07-18
ER

PT J
AU Jin, T
   Wang, Z
AF Jin, Tao
   Wang, Zhen
TI Multi-scale-ResUNet: an improve u-net with multi-scale attention and
   hybrid dilation for medical image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image segmentation; Convolution neural network; U-Net; Channel
   attention mechanism; Deep learning; Residual structures
ID NETWORK; LIVER; MODEL
AB The liver is one of the largest and most important organs in the human body. It maintains important life activities and is also one of the organs with high incidence of malignant tumors. Liver cancer is a major threat to human health. Liver segmentation is a prerequisite for disease treatment and treatment planning. In fact, liver CT segmentation is an important and meaningful challenge in medical image segmentation. The traditional method is based on the experience of doctors. This process is very error prone and time-consuming. Therefore, we introduce a novel network, called Multi-scale-ResUNet, to solve the problem of image feature loss and extract useful information from images. Firstly, we introduce a multi-scale squeeze and excitation module into U-Net network. The module can suppress irrelevant regions, extract image features from multiple angles, and highlight segmentation tasks. Then, adding residual structure to standard convolution layer can effectively avoid gradient explosion and increase network depth. Secondly, hybrid dilated attention conventional layer is used to replace the bottom of the "U" shape network to obtain context information and avoid the loss of spatial information. Finally, we do experiments on LiTS17 and SLiver07 datasets. Experiments show that our method has superior performance and the highest segmentation accuracy compared with other methods.
C1 [Jin, Tao] Harbin Engn Univ, Coll Comp Sci & Technol, Nantong St, Harbin 150028, Heilongjiang, Peoples R China.
   [Jin, Tao; Wang, Zhen] Qiqihar Univ, Coll Comp & Control Engn, Cultural St, Qiqihar 161000, Heilongjiang, Peoples R China.
C3 Harbin Engineering University; Qiqihar University
RP Jin, T (corresponding author), Harbin Engn Univ, Coll Comp Sci & Technol, Nantong St, Harbin 150028, Heilongjiang, Peoples R China.; Jin, T (corresponding author), Qiqihar Univ, Coll Comp & Control Engn, Cultural St, Qiqihar 161000, Heilongjiang, Peoples R China.
EM 24026027@qq.com; zhenwangwzzw@163.com
RI Liu, Yining/KHC-6217-2024
OI Liu, Yining/0000-0002-2218-2349; jin, tao/0000-0002-6124-1997
FU Fundamental Research Funds in Heilongjiang Provincial Universities
   [135309356]
FX The Fundamental Research Funds in Heilongjiang Provincial Universities
   (Grant No.135309356).
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bhatkalkar BJ, 2020, IEEE ACCESS, V8, P29299, DOI 10.1109/ACCESS.2020.2972318
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chartrand G, 2014, I S BIOMED IMAGING, P641, DOI 10.1109/ISBI.2014.6867952
   Chen JT, 2021, IEEE ACM T COMPUT BI, V18, P103, DOI 10.1109/TCBB.2020.2991173
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen TT, 2022, IEEE J BIOMED HEALTH, V26, P1411, DOI 10.1109/JBHI.2021.3100367
   Christ Patrick Ferdinand, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P415, DOI 10.1007/978-3-319-46723-8_48
   Conze PH, 2015, SEMIAUTOMATIC LIVER
   Fan TL, 2020, IEEE ACCESS, V8, P179656, DOI 10.1109/ACCESS.2020.3025372
   Gao HH, 2024, IEEE T NEUR NET LEAR, V35, P4826, DOI 10.1109/TNNLS.2022.3155486
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Khadidos A., 2017, IEEE T IMAGE PROCESS, VPP, P1
   Li CY, 2013, IEEE T BIO-MED ENG, V60, P2967, DOI 10.1109/TBME.2013.2267212
   Li X., 2017, arXiv
   Li X, 2021, NEUROCOMPUTING, V461, P228, DOI 10.1016/j.neucom.2021.07.018
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   LU XQ, 2021, IEEE T IND INFORM, V17, P1483, DOI DOI 10.1109/TII.2020.2985905
   Mharib AM, 2012, ARTIF INTELL REV, V37, P83, DOI 10.1007/s10462-011-9220-3
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Priyadarsini S, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P234, DOI 10.1109/ICACCCT.2012.6320777
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy AG, 2019, NEUROIMAGE, V186, P713, DOI 10.1016/j.neuroimage.2018.11.042
   Rundo L, 2019, NEUROCOMPUTING, V365, P31, DOI 10.1016/j.neucom.2019.07.006
   Saito A, 2016, MED IMAGE ANAL, V28, P46, DOI 10.1016/j.media.2015.11.003
   Schlemper J, 2018, ARXIV
   Shen DG, 2003, IEEE T MED IMAGING, V22, P539, DOI 10.1109/TMI.2003.809057
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sinha A, 2021, IEEE J BIOMED HEALTH, V25, P121, DOI 10.1109/JBHI.2020.2986926
   Sun W, 2018, IEEE GEOSCI REMOTE S, P1
   Vaswani A, 2017, ADV NEUR IN, V30
   Vicente S, 2008, PROC CVPR IEEE, P767
   Vorontsov E, 2014, LECT NOTES COMPUT SC, V8676, P74, DOI 10.1007/978-3-319-13692-9_7
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wong D, 2008, SEMIAUTOMATED METHOD
   Xiao JS, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3419842
   Yu F., 2015, ARXIV
   Zhang BH, 2022, COMPUT METH PROG BIO, V222, DOI 10.1016/j.cmpb.2022.106946
   Zhang JX, 2020, IEEE ACCESS, V8, P58533, DOI 10.1109/ACCESS.2020.2983075
   Zhang XH, 2017, INT CONF DIGIT SIG
   Zhou YJ, 2021, IEEE ACM T COMPUT BI, V18, P940, DOI 10.1109/TCBB.2019.2939522
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zhu YS, 2019, IEEE T IMAGE PROCESS, V28, P113, DOI 10.1109/TIP.2018.2865280
NR 49
TC 0
Z9 0
U1 5
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28473
EP 28492
DI 10.1007/s11042-023-14404-2
EA FEB 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000931739200003
DA 2024-07-18
ER

PT J
AU Kaur, A
   Kumar, M
   Jindal, MK
AF Kaur, Amanpreet
   Kumar, Munish
   Jindal, M. K.
TI Cattle identification system: a comparative analysis of SIFT, SURF and
   ORB feature descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SIFT; SURF; ORB; Decision tree; K-NN; Random Forest
AB Image processing is a key research area in computer vision that recognizes images and assigns labels to the extracted features. This new paradigm has recently received significant attention in biometric features that aid in the identification of breed and individual cattle based on extracted muzzle point features. The primary goal of this article is to present a comparison of various feature descriptors and classifiers for cattle identification using muzzle points. This paper also involves identification based on various features extracted from an image. There are a few feature extraction techniques available, such as Holistic features extraction, ORB, SIFT, SURF, Shi-Tomasi, Harris corner detection, and so on. The authors of this article considered three feature descriptor algorithms, SIFT (Scale Invariant Feature Transform), SURF (Speeded up Robust Feature), and ORB (Oriented Fast and Rotated BRIEF), to carry out experimental work on cattle images for breed identification system. A differentiation among three descriptors is presented in this article by determining them individually and in a combination of these methodologies. Classifiers such as Decision Tree, k-NN, and Random Forest are used to categorize images based on extracted features. The experiments are carried out on a dataset of four breeds: Holstein Friesian (470 images), Jersey (200 images), Rathi (100 images), and Sahiwal (100 images) (160 images). In the partitioning strategy, 80% of the data is considered as training dataset, and the remaining 20% is considered a testing set. The accuracy of 97.23% is achieved by hybrid feature techniques composed of SIFT, SURF, and ORB for the cattle identification system. This paper describes the feature extraction and classifiers used in the cattle identification system, data collection, methodology, and design of the proposed system, evaluates results, and represents the system's relevance and future prospects.
C1 [Kaur, Amanpreet] Guru Nanak Coll, Dept Comp Sci & Applicat, Sri Muktsar Sahib, Punjab, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
   [Jindal, M. K.] Panjab Univ Reg Ctr, Dept Comp Sci & Applicat, Chandigarh, Punjab, India.
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM amanpreetkkour07@gmail.com; munishcse@gmail.com;
   manishphd@rediffmail.com
RI Kumar, Munish/P-7756-2018
OI Kumar, Munish/0000-0003-0115-1620
CR Abdelmajed A. K. A., 2016, COMP STUDY LOCALITY
   Awad AI, 2013, FED CONF COMPUT SCI, P529
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bello RW, 2020, GAZI U J SCI, V33, P831, DOI 10.35378/gujs.605631
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cong S, 2020, IOP CONF SER-MAT SCI, V853, DOI 10.1088/1757-899X/853/1/012051
   El Hadad HM, 2015, PROCEDIA COMPUT SCI, V65, P864, DOI 10.1016/j.procs.2015.09.044
   Hassanien, 2015, INT J IMAGE MINING, V1, P342, DOI [10.1504/IJIM.2015.073902, DOI 10.1504/IJIM.2015.073902]
   Hu HQ, 2020, BIOSYST ENG, V192, P245, DOI 10.1016/j.biosystemseng.2020.02.001
   Kaur A, 2022, ECOL INFORM, V68, DOI 10.1016/j.ecoinf.2021.101549
   Kaur A, 2022, SOFT COMPUT, V26, P4771, DOI 10.1007/s00500-022-06935-x
   Kusakunniran W, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420560078
   Kusakunniran W, 2018, IEEE INT CONF INDUST, P1484, DOI 10.1109/ICIT.2018.8352400
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Noviyanto A, 2013, COMPUT ELECTRON AGR, V99, P77, DOI 10.1016/j.compag.2013.09.002
   Petersen, 1922, J DAIRY SCI, V5, P249, DOI DOI 10.3168/JDS.S0022-0302(22)94150-5
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Shojaeipour A, 2021, AGRONOMY-BASEL, V11, DOI 10.3390/agronomy11112365
   Tharwat A, 2014, COMM COM INF SC, V488, P236
   Tharwat A, 2014, ADV INTELL SYST, V303, P217, DOI 10.1007/978-3-319-08156-4_22
NR 20
TC 2
Z9 2
U1 5
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27391
EP 27413
DI 10.1007/s11042-023-14478-y
EA FEB 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000929853100001
DA 2024-07-18
ER

PT J
AU Li, SL
   Yao, R
   Zhou, Y
   Zhu, HC
   Liu, B
   Zhao, JQ
   Shao, ZW
AF Li, Shenglan
   Yao, Rui
   Zhou, Yong
   Zhu, Hancheng
   Liu, Bing
   Zhao, Jiaqi
   Shao, Zhiwen
TI Unsupervised RGB-T object tracking with attentional multi-modal feature
   fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised learning; RGB-T object tracking; Attention mechanism
AB RGB-T tracking means that given the object position in the first frame, the tracker is trained to predict the position of the object in consecutive frames by taking full advantage of the complementary information of RGB and thermal infrared images. As the amount of data increases, unsupervised training has great potential for development in RGB-T tracking task. As we all know, features extracted from different convolutional layers can provide different levels information in the image. In this paper, we propose a framework for visual tracking based on the attention mechanism fusion of multi-modal and multi-level features. This fusion method can give full play to the advantages of multi-level and multi-modal information. Specificly, we use a feature fusion module to fuse these features from different levels and different modalities at the same time. We use cycle consistency based on a correlation filter to implement unsupervised training of the model to reduce the cost of annotated data. The proposed tracker is evaluated on two popular benchmark datasets, GTOT and RGB-T234. Experimental results show that our tracker performs favorably against other state-of-the-art unsupervised trackers with a real-time tracking speed.
C1 [Li, Shenglan; Yao, Rui; Zhou, Yong; Zhu, Hancheng; Liu, Bing; Zhao, Jiaqi; Shao, Zhiwen] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou, Peoples R China.
   [Li, Shenglan; Yao, Rui; Zhou, Yong; Zhu, Hancheng; Liu, Bing; Zhao, Jiaqi; Shao, Zhiwen] Minist Educ Peoples Republ China, Engn Res Ctr Mine Digitizat, Xuzhou, Peoples R China.
C3 China University of Mining & Technology
RP Yao, R (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou, Peoples R China.; Yao, R (corresponding author), Minist Educ Peoples Republ China, Engn Res Ctr Mine Digitizat, Xuzhou, Peoples R China.
EM ruiyao@cumt.edu.cn
RI chen, huan/KEC-2019-2024; Shao, Zhiwen/N-8985-2018; Yin,
   Jing/KDO-6274-2024; Li, Kunpeng/KFS-6306-2024; Wang,
   zhenhua/KFA-8731-2024; TIAN, YI/KHU-9704-2024; Wang, Zejun/KBB-8454-2024
OI Yao, Rui/0000-0003-2734-915X
FU National Natural Science Foundation of China [62172417, 62101555,
   62106268]; Natural Science Foundation of Jiangsu Province [BK20201346];
   Xuzhou Key Research and Development Program [KC22287]
FX AcknowledgementsThis work was supported in part by the National Natural
   Science Foundation of China under Grant 62172417, 62101555, 62106268, in
   part by the Natural Science Foundation of Jiangsu Province under Grant
   BK20201346, in part by Xuzhou Key Research and Development Program under
   Grant KC22287.
CR Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Chen H, 2019, PATTERN RECOGN, V86, P376, DOI 10.1016/j.patcog.2018.08.007
   Chen YB, 2018, LECT NOTES COMPUT SC, V11205, P275, DOI 10.1007/978-3-030-01246-5_17
   Dai Y, ARXIV
   Fu ZH, 2021, PROC CVPR IEEE, P13769, DOI 10.1109/CVPR46437.2021.01356
   Gao J., ARXIV
   Gao Y, 2019, IEEE INT CONF COMP V, P91, DOI 10.1109/ICCVW.2019.00017
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Kristan M, ARXIV
   Li C., ARXIV
   Li C, CROSS MODAL RANKING
   Li CL, 2019, IEEE INT CONF COMP V, P2262, DOI 10.1109/ICCVW.2019.00279
   Li CL, 2019, IEEE T CIRC SYST VID, V29, P2913, DOI 10.1109/TCSVT.2018.2874312
   Li CL, 2016, IEEE T IMAGE PROCESS, V25, P5743, DOI 10.1109/TIP.2016.2614135
   Lu X, ARXIV
   Mnih V, 2014, ADV NEUR IN, V27
   Oh S.-j., ARXIV
   Shen Q, 2022, ARXIV
   Sio CH, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1948, DOI 10.1145/3394171.3413611
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang N., ARXIV
   Wang N, 2013, P ADV NEURAL INFORM
   Wang X, ARXIV
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu Q, 2022, IEEE T IND ELECTRON, V69, P2022, DOI 10.1109/TIE.2021.3057030
   Yang R., 2019, 2019 IEEE INT C IMAG, P3975, DOI DOI 10.1109/ICIP.2019.8803528
   Yuan D, 2021, IEEE T IMAGE PROCESS, V30, P976, DOI 10.1109/TIP.2020.3037518
   Yuan WH, 2020, IEEE INT C INT ROBOT, P10351, DOI 10.1109/IROS45743.2020.9341621
   Zhang PY, 2021, INT J COMPUT VISION, V129, P2714, DOI 10.1007/s11263-021-01495-3
   Zheng JL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13526, DOI 10.1109/ICCV48922.2021.01329
   Zhou T., ARXIV
   Zhou TF, 2022, IEEE T IMAGE PROCESS, V31, P799, DOI 10.1109/TIP.2021.3132834
   Zhou TF, 2020, IEEE T IMAGE PROCESS, V29, P8326, DOI 10.1109/TIP.2020.3013162
NR 33
TC 0
Z9 0
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23595
EP 23613
DI 10.1007/s11042-023-14362-9
EA FEB 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000924482400002
DA 2024-07-18
ER

PT J
AU Waheed, SR
   Rahim, MSM
   Suaib, NM
   Salim, AA
AF Waheed, Safa Riyadh
   Rahim, Mohd Shafry Mohd
   Suaib, Norhaida Mohd
   Salim, A. A.
TI CNN deep learning-based image to vector depiction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Classification; Image description; CNN; Image vector
ID MODELS
AB In the computational science and engineering domains, the depiction of picture information remains an intricate problem. Such a description needs an accurate recognition of various objects and individuals together with their attributes, correlations, and panorama information. Based on this fact, we depict the image contents in the natural language or image description generation methods using the convolutional neural networks (CNNs)-assisted deep learning (CNN-DL) approach, wherein the images are transformed to vectors. The DL and study attributes via the machine-learned data were used to construct the complete pictures from the real world. Two sections were considered based on image classification for CNN's improvement method to develop a classification model and the good results of the classification via a novel method for describing an image to the vector of each object in the image. The learning and relationship activity included all the essential categorizing and classifying entities. In addition, the developed system was extended to handle the open detection and hazards classification. The performance evaluation (using the CIFAR dataset) of the newly developed system revealed its better strength and flexibility in managing the test images from a new-fangled and isolated field than the reported techniques.
C1 [Waheed, Safa Riyadh; Rahim, Mohd Shafry Mohd; Suaib, Norhaida Mohd] Univ Teknol Malaysia, Fac Engn, Sch Comp, Johor Baharu 81310, Malaysia.
   [Waheed, Safa Riyadh] Imam Jaafar Al sadiq Univ, Fac informat Technol, Comp Tech Engn Dept, Najaf, Iraq.
   [Salim, A. A.] Univ Teknol Malaysia, Fac Sci, Laser Ctr, Johor Baharu, Johor, Malaysia.
   [Salim, A. A.] Univ Teknol Malaysia, Fac Sci, Phys Dept, Johor Baharu, Johor, Malaysia.
C3 Universiti Teknologi Malaysia; Imam Jaa'far al-Sadiq University;
   Universiti Teknologi Malaysia; Universiti Teknologi Malaysia
RP Salim, AA (corresponding author), Univ Teknol Malaysia, Fac Sci, Laser Ctr, Johor Baharu, Johor, Malaysia.; Salim, AA (corresponding author), Univ Teknol Malaysia, Fac Sci, Phys Dept, Johor Baharu, Johor, Malaysia.
EM safa_albdeary@hotmail.com; haida@utm.my; asali@utm.my
RI Waheed, Safa/ABN-5296-2022; Salim, Ali Aqeel/W-4116-2019; Bin Mohd
   Rahim, Mohd Shafry/B-7552-2016; MOHD SUAIB, NORHAIDA/AAX-9730-2020
OI Waheed, Safa/0000-0003-2392-2545; Salim, Ali Aqeel/0000-0002-2801-9673;
   MOHD SUAIB, NORHAIDA/0000-0003-4182-309X
FU Universiti Teknologi Malaysia (UTM); Ministry of Higher Education
   Malaysia (MOHE); RMC [FRGS Q.J130000.2509.21H11]; UTM RA ICONIC GRANT
   [Q.J130000.4354.09G60, FRGS-04E86, UTMFR 21H78]; Research Management
   Centre-Universiti Teknologi Malaysia (RMC-UTM)
FX Authors are extremely thankful to Universiti Teknologi Malaysia (UTM),
   Ministry of Higher Education Malaysia (MOHE), and RMC for research grant
   FRGS Q.J130000.2509.21H11, and UTM RA ICONIC GRANT Q.J130000.4354.09G60,
   FRGS-04E86 and UTMFR 21H78. Authors are also grateful to Research
   Management Centre-Universiti Teknologi Malaysia (RMC-UTM) for supporting
   under Postdoctoral fellowship scheme.
CR Adnan MM, 2021, IEEE ACCESS, V9, P50253, DOI 10.1109/ACCESS.2021.3068897
   Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Ayadi W, 2021, NEURAL PROCESS LETT, V53, P671, DOI 10.1007/s11063-020-10398-2
   Banerjee S., 2005, P WORKSHOP INTRINSIC, P65
   Benyahia S, 2022, TISSUE CELL, V74, DOI 10.1016/j.tice.2021.101701
   Bianchini M, 2014, IEEE T NEUR NET LEAR, V25, P1553, DOI 10.1109/TNNLS.2013.2293637
   Bullins B, 2019, ALGORITHMIC LEARNING, P235
   Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856
   Chen YT, 2021, MULTIMED TOOLS APPL, V80, P4237, DOI 10.1007/s11042-020-09887-2
   Choi Y, 2011, P 15 C COMPUTATIONAL, P220
   Chun PJ, 2022, COMPUT-AIDED CIV INF, V37, P1387, DOI 10.1111/mice.12793
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   El-Komy A., 2022, INFORM SCI LETT, V11, P9
   Esteva A, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-020-00376-2
   Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He X, 2018, DEEP LEARNING NATURA, P289, DOI DOI 10.1007/978-981-10-5209-5_10
   He XD, 2017, IEEE SIGNAL PROC MAG, V34, P109, DOI 10.1109/MSP.2017.2741510
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Jena B, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104803
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Kadhim KA, 2021, MAT TODAY P WITHDRAW
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Li S, 2017, PROC CVPR IEEE, P5187, DOI 10.1109/CVPR.2017.551
   Lin K, 2017, ADV NEUR IN, V30
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu CX, 2017, AAAI CONF ARTIF INTE, P4176
   Liu Y, 2017, 2017 10 INT C IM SIG, P1, DOI DOI 10.1109/CISP-BMEI.2017.8302240
   Mao J, 2014, ARXIV
   McCulloch WS, 2016, EMBODIMENTS OF MIND, P19
   Najjar FH, 2021, J PHYS C SERIES, V1892
   O'Connor P, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00178
   Ordonez V., 2011, ADV NEURAL INFORM PR, P1143
   Piasco N, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01363-6
   Qin JH, 2020, ECOL INFORM, V58, DOI 10.1016/j.ecoinf.2020.101093
   Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.5555/1866696.1866717
   Shao HD, 2021, INFORM FUSION, V74, P65, DOI 10.1016/j.inffus.2021.03.008
   Sharma H, 2022, MULTIMED TOOLS APPL, V81, P34775, DOI 10.1007/s11042-021-11276-2
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sreela SR, 2019, INFORMATION, V10, DOI 10.3390/info10110354
   Sun YN, 2020, IEEE T CYBERNETICS, V50, P3840, DOI 10.1109/TCYB.2020.2983860
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Waheed Safa Riyadh, 2021, Journal of Physics: Conference Series, V1892, DOI 10.1088/1742-6596/1892/1/012001
   Waheed SR, 2016, MICROSC RES TECHNIQ, V79, P431, DOI 10.1002/jemt.22646
   Wang H., 2016, ARXIV
   Wu FX, 2019, NEUROCOMPUTING, V324, P1, DOI 10.1016/j.neucom.2018.05.047
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu SY, 2021, ARCH COMPUT METHOD E, V28, P3383, DOI 10.1007/s11831-020-09504-3
   Yang ZL, 2016, ADV NEUR IN, V29
   Yao KS, 2014, IEEE W SP LANG TECH, P189, DOI 10.1109/SLT.2014.7078572
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Yu L, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI 10.14722/ndss.2017.23241
NR 59
TC 19
Z9 19
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20283
EP 20302
DI 10.1007/s11042-023-14434-w
EA JAN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000923421800002
DA 2024-07-18
ER

PT J
AU Li, SY
   Chen, J
   Peng, WM
   Shi, XY
   Bu, WH
AF Li, Shiyang
   Chen, Jing
   Peng, Weimin
   Shi, Xiaoying
   Bu, Wanghui
TI A vehicle detection method based on disparity segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Multi-scale; Disparity segmentation; Stereovision
AB The detection of small objects has always been one of the key challenges in vehicle detection. In this work, a standard for dividing the object more accurately than traditional methods is presented. Based on the division standard of disparity segmentation, we propose a novel multi-scale detection network aiming to reduce the transmission of redundant information between each scale. We divide the objects by depth, which is the distance from the object to the viewpoint. Then, a multi-branch architecture providing specialized detection for objects of each scale separately is constructed. Through ablation experiments, our method achieves an increase of 1.63 to 2.01 mAP compared with the baseline method. On the KITTI dataset, our method combined with state-of-arts achieves an increase of 3.54 mAP for small objects and 0.79 mAP for medium objects.
C1 [Li, Shiyang; Chen, Jing; Peng, Weimin; Shi, Xiaoying] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
   [Bu, Wanghui] Tongji Univ, Sch Mech Engn, Shanghai 201804, Peoples R China.
C3 Hangzhou Dianzi University; Tongji University
RP Chen, J (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
EM missouter@hdu.edu.cn; cj@hdu.edu.cn; penwm@hdu.edu.cn;
   shixiaoyin@hdu.edu.cn; buwanghui@tongji.edu.cn
RI Chen, Jing/ACN-9965-2022
OI Chen, Jing/0000-0003-3127-8462
CR Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Chen J, 2018, IEEE T INTELL TRANSP
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Choi HM, 2019, IEEE INT CONF COMP V, P2357, DOI 10.1109/ICCVW.2019.00289
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Dai JF, 2016, ADV NEUR IN, V29
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Fan SQ, 2021, IEEE T VEH TECHNOL, V70, P121, DOI 10.1109/TVT.2021.3049805
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guo LY, 2021, MULTIMED TOOLS APPL, V80, P28583, DOI 10.1007/s11042-021-11102-9
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hong S., 2016, ARXIV
   Hu XW, 2019, IEEE T INTELL TRANSP, V20, P1010, DOI 10.1109/TITS.2018.2838132
   Kaiwen Duan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P399, DOI 10.1007/978-3-030-58580-8_24
   Li S, 2021, IEEE CONF COMPUT, DOI 10.1109/INFOCOMWKSHPS51825.2021.9484562
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu X, 2020, LECT NOTES COMPUTER, V2348
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren J., 2017, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2017.87
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Singh B, 2018, 32 C NEURAL INFORM P
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wu Jiapeng, 2020, ARXIV
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
   Zhao Q., 2019, ASS ADV ARTIFICIAL I
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhu R, 2019, PROC CVPR IEEE, P2263, DOI 10.1109/CVPR.2019.00237
NR 38
TC 32
Z9 32
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19643
EP 19655
DI 10.1007/s11042-023-14360-x
EA JAN 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000920621000006
DA 2024-07-18
ER

PT J
AU Kumari, P
   Seeja, KR
AF Kumari, Punam
   Seeja, K. R.
TI One shot learning approach for cross spectrum periocular verification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross spectrum; Periocular biometrics; Siamese neural network; One shot
   learning; Triplet loss
ID IRIS RECOGNITION; CNN
AB The use of face mask during the COVID-19 pandemic has increased the popularity of the periocular biometrics in surveillance applications. Despite of the rapid advancements in this area, matching images over cross spectrum is still a challenging problem. Reason may be two-fold 1) variations in image illumination 2) small size of available data sets and/or class imbalance problem. This paper proposes Siamese architecture based convolutional neural networks which works on the concept of one-shot classification. In one shot classification, network requires a single training example from each class to train the complete model which may lead to reduce the need of large dataset as well as doesn't matter whether the dataset is imbalance. The proposed architectures comprise of identical subnetworks with shared weights whose performance is assessed on three publicly available databases namely IMP, UTIRIS and PolyU with four different loss functions namely Binary cross entropy loss, Hinge loss, contrastive loss and Triplet loss. In order to mitigate the inherent illumination variations of cross spectrum images CLAHE was used to preprocess images. Extensive experiments show that the proposed Siamese CNN model with triplet loss function outperforms the states of the art periocular verification methods for cross, mono and multi spectral periocular image matching.
C1 [Kumari, Punam; Seeja, K. R.] Indira Gandhi Delhi Tech Univ Women, Dept Comp Sci & Engn, Delhi, India.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW)
RP Seeja, KR (corresponding author), Indira Gandhi Delhi Tech Univ Women, Dept Comp Sci & Engn, Delhi, India.
EM punam_taurus@hotmail.com; seeja@igdtuw.ac.in
CR Abate A, 2022, LECT NOTES COMPUT SC, V13231, P368, DOI 10.1007/978-3-031-06427-2_31
   Aguilera CA, 2016, IEEE COMPUT SOC CONF, P267, DOI 10.1109/CVPRW.2016.40
   Alzu'bi A, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10212666
   Behera SS, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P681, DOI 10.1109/BTAS.2017.8272757
   Boddeti V.N., 2011, BIOMETRICS IJCB 2011, P1, DOI 10.1109/ijcb.2011.6117500
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Cao ZC, 2016, PATTERN RECOGN LETT, V82, P170, DOI 10.1016/j.patrec.2015.10.018
   Cao ZCX, 2014, IEEE IMAGE PROC, P4967, DOI 10.1109/ICIP.2014.7026006
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Chung D, 2017, IEEE I CONF COMP VIS, P1992, DOI 10.1109/ICCV.2017.218
   Fuentes A, 2021, IEEE COMPUT SOC CONF, P2134, DOI 10.1109/CVPRW53098.2021.00242
   Gautam G, 2021, APPL INTELL, V51, P1, DOI 10.1007/s10489-019-01562-w
   Ghosh S, 2019, PROC CVPR IEEE, P4879, DOI 10.1109/CVPR.2019.00502
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Hosseini MS, 2010, IEEE T INSTRUM MEAS, V59, P792, DOI 10.1109/TIM.2009.2037996
   Kumari P, 2020, PROCEDIA COMPUT SCI, V167, P344, DOI 10.1016/j.procs.2020.03.234
   Kumari P, 2020, ADV INTELL SYST COMP, V1034, P143, DOI 10.1007/978-981-15-1084-7_15
   Lezama J, 2017, PROC CVPR IEEE, P6807, DOI 10.1109/CVPR.2017.720
   Lin HY, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1676, DOI 10.1145/3343031.3350900
   Liu XM, 2016, AER ADV ENG RES, V116, P1, DOI 10.1145/2875194.2875248
   Mahalingam G, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-36
   Melekhov I, 2016, INT C PATT RECOG, P378, DOI 10.1109/ICPR.2016.7899663
   Nalla PR, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2616281
   Nicolò F, 2012, IEEE T INF FOREN SEC, V7, P1717, DOI 10.1109/TIFS.2012.2213813
   Park M, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ULTRA-WIDEBAND (ICUWB 2009), P1, DOI 10.1109/ICUWB.2009.5288737
   Proença H, 2018, IEEE T INF FOREN SEC, V13, P888, DOI 10.1109/TIFS.2017.2771230
   Raja K.B., 2017, International Conference on Information Fusion (Fusion), P1
   Raja KB, 2016, IEEE CONF IMAGING SY, P227, DOI 10.1109/IST.2016.7738228
   Ramaiah NP, 2016, INT CONF BIOMETR THE
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sharma A, 2014, IEEE IMAGE PROC, P5007, DOI 10.1109/ICIP.2014.7026014
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Uzhinskiy AV, 2021, COMPUT OPT, V45, P608, DOI 10.18287/2412-6179-CO-856
   Vyas R, 2019, MULTIMED TOOLS APPL, V78, P5681, DOI 10.1007/s11042-018-5689-y
   Wan W, 2019, NEURAL COMPUT APPL, V31, P9175, DOI 10.1007/s00521-019-04242-5
   Wang K, 2019, PATTERN RECOGN, V86, P85, DOI 10.1016/j.patcog.2018.08.010
   Wu L, 2019, IEEE T MULTIMEDIA, V21, P1412, DOI 10.1109/TMM.2018.2877886
   Yang K, 2020, NEURAL COMPUT APPL, V32, P14335, DOI 10.1007/s00521-019-04238-1
   Zanlorensi LA, 2020, IET BIOMETRICS, V9, P68, DOI 10.1049/iet-bmt.2019.0116
   Zhao ZJ, 2017, IEEE T INF FOREN SEC, V12, P1017, DOI 10.1109/TIFS.2016.2636093
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 42
TC 3
Z9 3
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20589
EP 20604
DI 10.1007/s11042-023-14386-1
EA JAN 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000926801100007
PM 36685013
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Ouni, A
   Chateau, T
   Royer, E
   Chevaldonne, M
   Dhome, M
AF Ouni, Achref
   Chateau, Thierry
   Royer, Eric
   Chevaldonne, Marc
   Dhome, Michel
TI An efficient ir approach based semantic segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; Deep learning; Semantic segmentation; Image retrieval
ID IMAGE RETRIEVAL
AB Content Based Image Retrieval (CBIR) is the task of finding similar images from a query one. The state of the art mentions two main methods to solve the retrieval problem: (1) Methods dependent on visual description, for example, bag of visual words model (BoVW), Vector of Locally Aggregated Descriptors (VLAD) (2) Methods dependent on deep learning approaches in particular convolutional neural networks (CNN). In this article, we attempt to improve the CBIR algorithms with the proposition of two image signatures based on deep learning. In the first, we build a fast binary signature by utilizing a CNN based semantic segmentation. In the second, we combine the visual information with the semantic information to get a discriminative image signature denoted semantic bag of visual phrase. We study the performance of the proposed approach on six different public datasets: Wang, Corel 10k, GHIM-10K, MSRC-V1,MSRC-V2, Linnaeus. We significantly improve the mean of average precision scores (MAP) between 10% and 25% on almost all the datasets compared to state-of-the-art methods. Several experiments achieved on public datasets show that our proposal leads to increase the CBIR accuracy.
C1 [Ouni, Achref; Chateau, Thierry; Royer, Eric; Chevaldonne, Marc; Dhome, Michel] Univ Clermont Auvergne, Inst Pascal, CNRS, SIGMA Clermont, F-63000 Clermont Ferrand, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite Clermont
   Auvergne (UCA)
RP Ouni, A (corresponding author), Univ Clermont Auvergne, Inst Pascal, CNRS, SIGMA Clermont, F-63000 Clermont Ferrand, France.
EM Achref.ELOUNI@uca.fr
OI Ouni, Achref/0000-0002-1197-253X
CR Admile N.S., 2016, INT C COMMUNICATION, P1
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Balaiah T, 2019, INT CONF ADV COMPU, P428, DOI 10.1109/ICoAC48765.2019.246880
   Bawa M, 2005, Proceedings of the 14th International Conference on World Wide Web-WWW'05, P651, DOI [DOI 10.1145/1060745.1060840, 10.1145/1060745.1060840]
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bhandi Vijayakumar, 2019, 2019 1st International Conference on Advanced Technologies in Intelligent Control, Environment, Computing & Communication Engineering (ICATIECE), P35, DOI 10.1109/ICATIECE45860.2019.9063814
   Bhunia AK, 2020, PATTERN ANAL APPL, V23, P703, DOI 10.1007/s10044-019-00827-x
   Caesar H, 2018, PROC CVPR IEEE, P1209, DOI 10.1109/CVPR.2018.00132
   Chaladze G., 2017, Linnaeus 5 dataset for machine learning
   Chatzichristofis SA, 2014, MULTIMED TOOLS APPL, V70, P1767, DOI 10.1007/s11042-012-1192-z
   Chen T, 2014, IEEE T MULTIMEDIA, V16, P612, DOI 10.1109/TMM.2014.2301978
   Chu K, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/1461459
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060
   Duda J, 2019, ARXIV
   ElAlami ME, 2014, APPL SOFT COMPUT, V14, P407, DOI 10.1016/j.asoc.2013.10.003
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Fu RG, 2016, 2016 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P638, DOI 10.1109/CompComm.2016.7924779
   Ginn D, 2018, CONFERENCE PROCEEDINGS OF 2018 4TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P88, DOI 10.1109/ICCAR.2018.8384650
   Iakovidou C, 2019, IEEE T IMAGE PROCESS, V28, P3115, DOI 10.1109/TIP.2019.2894281
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jin S, 2020, AAAI CONF ARTIF INTE, V34, P11157
   Khwildi R, 2021, MULTIMED TOOLS APPL, V80, P15413, DOI 10.1007/s11042-020-10416-4
   Krishna K, 1999, IEEE T SYST MAN CY B, V29, P433, DOI 10.1109/3477.764879
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lambert J, 2020, PROC CVPR IEEE, P2876, DOI 10.1109/CVPR42600.2020.00295
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mishchuk A., 2017, P ADV NEURAL INFORM, P4826
   Neuhold G, 2017, IEEE I CONF COMP VIS, P5000, DOI 10.1109/ICCV.2017.534
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Ouni A, 2022, LECT NOTES ARTIF INT, V13501, P437, DOI 10.1007/978-3-031-16014-1_35
   Ouni A, 2018, MULTIMED TOOLS APPL, V77, P26173, DOI 10.1007/s11042-018-5841-8
   Paulin M, 2015, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2015.19
   Pedrosa Glauco V., 2013, 2013 XXVI Conference on Graphics, Patterns and Images (SIBGRAPI 2013), P304, DOI 10.1109/SIBGRAPI.2013.49
   Peng X, 2016, LECT NOTES COMPUT SC, V9905, P38, DOI 10.1007/978-3-319-46448-0_3
   Perronnin F, 2007, PROC CVPR IEEE, P2272
   Pradhan J., 2018, INT C MATH COMPUTING, V834, P84
   Putzu L, 2020, MULTIMED TOOLS APPL, V79, P26995, DOI 10.1007/s11042-020-09292-9
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Ren Y, 2013, VISUAL OBJECT RETRIE
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Shen YM, 2020, PROC CVPR IEEE, P2815, DOI 10.1109/CVPR42600.2020.00289
   Song JK, 2018, AAAI CONF ARTIF INTE, P394
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tian YR, 2017, PROC CVPR IEEE, P6128, DOI 10.1109/CVPR.2017.649
   Wang GA, 2018, LECT NOTES COMPUT SC, V11219, P491, DOI 10.1007/978-3-030-01267-0_29
   Wang JH, 2020, IEEE T CYBERNETICS, V50, P2971, DOI 10.1109/TCYB.2019.2891265
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wu P., 2013, P 21 ACM INT C MULT, P153, DOI DOI 10.1145/2502081.2502112
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Yang JX, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107116
   Yang ZL, 2018, IFAC PAPERSONLINE, V51, P280, DOI 10.1016/j.ifacol.2018.08.175
   Yuan X, 2018, LECT NOTES COMPUT SC, V11208, P141, DOI 10.1007/978-3-030-01225-0_9
   Zeng S, 2016, NEUROCOMPUTING, V171, P673, DOI 10.1016/j.neucom.2015.07.008
   Zhou Bolei, 2017, PROC CVPR IEEE, P633, DOI DOI 10.1109/CVPR.2017.544
NR 64
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10145
EP 10163
DI 10.1007/s11042-022-14297-7
EA DEC 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000904951900001
DA 2024-07-18
ER

PT J
AU Gurubelli, Y
   Ramanathan, M
   Ponnusamy, P
AF Gurubelli, Yogeswararao
   Ramanathan, Malmathanraj
   Ponnusamy, Palanisamy
TI Colour texture descriptor for CBIR of diseased tomato leaf images using
   modified local zigzag pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Local zigzag pattern; CBIR; Features; SIFT; HSV colour histogram; Edge
   detection
ID BINARY PATTERNS; RETRIEVAL; CLASSIFICATION
AB A novel colour texture extraction method called modified local zigzag pattern (MLZP) is suggested to efficaciously retrieve the content from diseased tomato leaf images. The presented descriptor is simple, yet a vigorous rotational invariant method which uses zigzag sampling for texture classification. This research work implements a method to retrieve images of leaves using colour, shape and texture feature descriptors. Initially, the directional edge information of a texture image is calculated in eight different directions using the Kirsch compass mask. Local Zigzag Pattern (LZP) and MLZP are later calculated using information relevant to edges. In general, the spatial Zigzag structure can be calculated by this pattern, based on values obtained for center pixel and the ones adjoining to it. Also, the system is robust to the illumination variations. HSV Colour Histogram is applied for extracting colour feature, while Scale Invariant Feature Transform (SIFT) is utilised to extract shape feature by matching Key points. Finally, the distance measure such as Euclidean, Cosine and Chi-square are used to find the distance between the features of the query image and the feature vector of the different diseased leaf images. All the samples with less distance value are retrieved for the query image. The retrieval efficiency of proposed CBIR system combined with MLZP feature extraction and Chi-square distance measure are achieving as 90%, 92%, 94%, 91% and 88% for bacterial spot, late blight, mosaic virus, septoria leaf spot and yellow leaf curl virus respectively.
C1 [Gurubelli, Yogeswararao] Aditya Inst Technol & Management, Tekkali, India.
   [Ramanathan, Malmathanraj; Ponnusamy, Palanisamy] Natl Inst Technol Tiruchirappalli, Trichy, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Gurubelli, Y (corresponding author), Aditya Inst Technol & Management, Tekkali, India.
EM yogi.gurubelli@gmail.com
RI Yogeswararao, Gurubelli/ADN-0953-2022
OI G, Yogeswararao/0000-0002-4494-5749
CR Afifi AJ, 2012, 2012 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING TECHNIQUES AND APPLICATIONS (DICTA)
   [Anonymous], 2008, INT J COMPUT SCI SEC
   Belloulata K, 2014, 2014 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (CHINASIP), P470, DOI 10.1109/ChinaSIP.2014.6889287
   Bhagat A. P., 2012, Proceedings of the 2012 2nd National Conference on Computational Intelligence and Signal Processing (CISP 2012), P109, DOI 10.1109/NCCISP.2012.6189688
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Choudhary R, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2404, DOI 10.1109/ICACCI.2014.6968394
   Dong WF, 2014, INT CONF INSTR MEAS, P240, DOI 10.1109/IMCCC.2014.57
   Dubey SR, 2019, MULTIMED TOOLS APPL, V78, P16411, DOI 10.1007/s11042-018-7028-8
   Dubey SR, 2016, SIGNAL IMAGE VIDEO P, V10, P819, DOI 10.1007/s11760-015-0821-1
   Dubey SR, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493446
   Ganar Apurva N., 2014, 2014 International Conference on Electronic Systems, Signal Processing and Computing Technologies (ICESC), P251, DOI 10.1109/ICESC.2014.48
   Guo ZH, 2012, NEURAL COMPUT APPL, V21, P1893, DOI 10.1007/s00521-011-0586-6
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Kang JY, 2012, CHIN CONT DECIS CONF, P1326, DOI 10.1109/CCDC.2012.6244213
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Patil J.K., 2017, Engineering in agriculture, environment and food, V10, P69
   Rasli R. M., 2012, Proceedings of the 2012 3rd International Conference on Intelligent Systems, Modelling and Simulation (ISMS 2012), P283, DOI 10.1109/ISMS.2012.111
   Redi M., 2011, 2011 9th International Workshop on Content-Based Multimedia Indexing (CBMI), P199, DOI 10.1109/CBMI.2011.5972545
   Selvarajah S., 2011, 2011 IEEE 6th International Conference on Industrial and Information Systems (ICIIS 2011), P164, DOI 10.1109/ICIINFS.2011.6038060
   Singh C, 2018, PATTERN RECOGN, V76, P50, DOI 10.1016/j.patcog.2017.10.021
   Singh N, 2012, PROC TECH, V4, P245, DOI 10.1016/j.protcy.2012.05.037
   Varish N, 2015, INT C SIGN PROC COMM, P1, DOI DOI 10.1109/ICSCN.2015.7219922
   Vatamanu OA, 2015, STUD HEALTH TECHNOL, V210, P75, DOI 10.3233/978-1-61499-512-8-75
   Yasmin M, 2014, J APPL RES TECHNOL, V12, P877, DOI 10.1016/S1665-6423(14)70594-2
NR 28
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 DEC 13
PY 2022
DI 10.1007/s11042-022-14292-y
EA DEC 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7A7NK
UT WOS:000898637800001
DA 2024-07-18
ER

PT J
AU Tu, CT
   Hsieh, SH
   Chen, KL
   Lien, JJJ
AF Tu, Ching-Ting
   Hsieh, Sung-Hsien
   Chen, Kuan-Lin
   Lien, Jenn-Jier James
TI Personalized smile synthesis using attention-guided global parametric
   model and local non-parametric model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face expression transfer; Face hallucination; Style transfer
AB This study proposes a new learning-based smile synthesis system, in which a given neutral facial image is automatically transferred as a smile result in a certain style. Although the example-based face synthesis framework has made great progress recently, the construction of robust transformation, the preservation of personal characteristics and the production of high-quality images, etc. remain unresolved problems. These questions are addressed in the proposed framework using a new expression attention-guided global parametric model and local non-parametric model. Our key innovations include (a) a flexible framework design that produces expression attention regions with only expression category labels as supervision, (b) a novel smile style analysis framework that explores different smile styles from training samples that are then used to guide more robust face modeling, and (c) a two-step expression transformation approach is proposed that integrates global parametric models for robust prediction of expression geometry and local non-parametric models for high-quality image generation. Experimental results show that in the case of a limited training data scenario, the facial images obtained using the proposed framework are more vivid than those generated using existing synthesis methods. In addition, the proposed method can be extended directly to the image-to-image transformation task to produce high-quality hallucinations of faces, which is very importance in digital entertainment.
C1 [Tu, Ching-Ting; Hsieh, Sung-Hsien; Chen, Kuan-Lin; Lien, Jenn-Jier James] Natl Chung Hsing Univ, Dept Appl Math, Taichung 402, Taiwan.
C3 National Chung Hsing University
RP Tu, CT (corresponding author), Natl Chung Hsing Univ, Dept Appl Math, Taichung 402, Taiwan.
EM cttu@nchu.edu.tw; parvaty316@hotmail.com; a0987527899@gmail.com;
   jjlien@csie.ncku.edu.tw
OI Tu, Ching-Ting/0000-0003-2410-726X; Chen, KuanLin/0009-0008-1372-7256
FU Ministry of Science and Technology of Taiwan;  [MOST 109-2221-E-005 -056
   -MY2]
FX AcknowledgementsThis work was supported by the Ministry of Science and
   Technology of Taiwan under Grant numbers MOST 109-2221-E-005 -056 -MY2.
   We thank anonymous reviewers for the insightful comments that improved
   this paper. We acknowledge all the authors for distributing the source
   code into the public domain and allowing us to use it as a basis for
   modifying it as comparison methods in this study.
CR Bouaziz S, 2014, 202143 EPFL
   Bozorgtabar B, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107111
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Deng ZG, 2006, IEEE T VIS COMPUT GR, V12, P1523, DOI 10.1109/TVCG.2006.90
   Tran DL, 2017, IEEE I CONF COMP VIS, P3209, DOI 10.1109/ICCV.2017.346
   Etoundi CML, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14030493
   Fan GF, 2022, INT J ELEC POWER, V139, DOI 10.1016/j.ijepes.2022.108073
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Ghahramani Z., 1997, The EM algorithm for mixtures of factor analyzers
   Gong B., 2009, Proceedings of the 17th ACM International Conference on Multimedia, P569
   Huang D, 2010, LECT NOTES COMPUT SC, V6312, P364, DOI 10.1007/978-3-642-15552-9_27
   Huang L, 2006, SOFT COMPUT, V10, P1193, DOI 10.1007/s00500-005-0041-7
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Khan N, 2020, INT J COMPUT VISION, V128, P1433, DOI 10.1007/s11263-019-01256-3
   Li K, 2014, IEEE T MULTIMEDIA, V16, P299, DOI 10.1109/TMM.2013.2293064
   Liu WS, 2021, AAAI CONF ARTIF INTE, V35, P2180
   Lu ZH, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1083, DOI 10.1145/3240508.3240647
   Mohammed U, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531363
   Noh JY, 2006, ACM SIGGRAPH COURSES
   Peng Y, 2019, IET IMAGE PROCESS, V13, P2706, DOI 10.1049/iet-ipr.2018.6576
   Pumarola A, 2020, INT J COMPUT VISION, V128, P698, DOI 10.1007/s11263-019-01210-3
   Sahoo KK, 2021, IEEE ACCESS, V9, P166518, DOI 10.1109/ACCESS.2021.3135658
   Song YB, 2014, LECT NOTES COMPUT SC, V8694, P800, DOI 10.1007/978-3-319-10599-4_51
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Tang H, 2021, IEEE T NEURAL NETWOR
   Tie Y, 2013, IEEE T CIRC SYST VID, V23, P142, DOI 10.1109/TCSVT.2012.2203210
   Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055
   Wang S., 2008, IEEE C COMPUT VISION, V2008, P1
   Xia JZ, 2012, IEEE T CIRC SYST VID, V22, P77, DOI 10.1109/TCSVT.2011.2158337
   Xu WH, 2021, IEEE T IMAGE PROCESS, V30, P3450, DOI 10.1109/TIP.2021.3061933
   Yunjey Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8185, DOI 10.1109/CVPR42600.2020.00821
   Zhang FF, 2020, IEEE T IMAGE PROCESS, V29, P6574, DOI 10.1109/TIP.2020.2991549
   Zhang FF, 2020, IEEE T IMAGE PROCESS, V29, P4445, DOI 10.1109/TIP.2020.2972114
   Zhang QS, 2006, IEEE T VIS COMPUT GR, V12, P48, DOI 10.1109/TVCG.2006.9
   Zhang YM, 2008, IEEE T CIRC SYST VID, V18, P1383, DOI 10.1109/TCSVT.2008.928887
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 37
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21585
EP 21609
DI 10.1007/s11042-022-14260-6
EA DEC 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000893350700001
DA 2024-07-18
ER

PT J
AU Singha, A
   Bhowmik, MK
AF Singha, Anu
   Bhowmik, Mrinal Kanti
TI AlexSegNet: an accurate nuclei segmentation deep learning model in
   microscopic images for diagnosis of cancer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Nuclei; Segmentation; Fluorescent;
   Histopathology; cancer
AB The nuclei segmentation of microscopic images is a key pre-requisite for cancerous pathological image analysis. However, an accurate nuclei cell segmentation is a long running major challenge due to the enormous color variability of staining, nuclei shapes, sizes, and clustering of overlapping cells. To address this challenges, we proposed a deep learning model, namely, AlexSegNet which is based upon AlexNet model Encoder-Decoder framework. In Encoder part, it stitches feature maps in the channel dimension to achieve feature fusion and uses a skip structure in Decoder part to combine low- and high-level features to ensure the segmentation effect of the nucleus. At final stage, we have also introduced a stacked network where feature maps are stacks on top of each other. We have used a publically available 2018 Data Science Bowl and Triple Negative Breast Cancer (TNBC) datasets of microscopic nuclei images for this study which comprises of several sample types such as small and large fluorescent, pink, purple, and grayscale tissue samples. Experimental results show that our proposed AlexSegNet achieved a segmentation maximum performance of 91.66% for Data Science Bowl dataset and 66.88% for TNBC dataset. The results are competitive compared to the results of other state-of-the-art models. This model is expected to be useful clinically for technician experts to succeed the analysis of cancer diagnosis into the survival chances of patients.
C1 [Singha, Anu] SRM Inst Sci & Technol, Dept Comp Sci & Engn, Delhi NCR Campus, Ghaziabad 201204, Uttar Pradesh, India.
   [Bhowmik, Mrinal Kanti] Tripura Univ, Dept Comp Sci & Engn, Suryamaninagar 799022, Agartala, India.
C3 SRM Institute of Science & Technology Delhi NCR (Ghaziabad); Tripura
   University
RP Singha, A (corresponding author), SRM Inst Sci & Technol, Dept Comp Sci & Engn, Delhi NCR Campus, Ghaziabad 201204, Uttar Pradesh, India.
EM anusingh5012@gmail.com; mrinalkantibhowmik@tripurauniv.ac.in
RI Bhowmik, Mrinal Kanti/AAY-8356-2020
OI Bhowmik, Mrinal Kanti/0000-0003-3451-191X; Singha,
   Anu/0000-0002-5149-0594
CR Abhishek S, 2022, ARXIV
   Ambati LS, 2021, P 27 ANN AMERICAS C
   [Anonymous], 2021, About us
   Badrinarayanan V., 2015, SEGNET DEEP CONVOLUT
   Bakkouri I, 2022, MULTIMED TOOLS APPL, V81, P10743, DOI 10.1007/s11042-022-12242-2
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Basavanhally Ajay, 2011, J Pathol Inform, V2, pS1, DOI 10.4103/2153-3539.92027
   Caicedo JC, 2019, NAT METHODS, V16, P1247, DOI 10.1038/s41592-019-0612-7
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Cui YX, 2019, MED BIOL ENG COMPUT, V57, P2027, DOI 10.1007/s11517-019-02008-8
   Debesh J, 2020, P IEEE 33 INT S COMP
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dubost Florian, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P214, DOI 10.1007/978-3-319-66179-7_25
   El-Gayar OmarF., 2020, BIG DATAS POTENTIAL, P104, DOI DOI 10.4018/978-1-5225-9687-5.CH005
   Graham S, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101563
   Hassan L, 2021, INT J INTERACT MULTI, V6, P35, DOI 10.9781/ijimai.2020.10.004
   He K., 2015, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2015.7299173, DOI 10.1109/CVPR.2015.7299173]
   Hipp Jason D, 2011, J Pathol Inform, V2, P26, DOI 10.4103/2153-3539.82051
   Irshad Humayun, 2014, IEEE Rev Biomed Eng, V7, P97, DOI 10.1109/RBME.2013.2295804
   Kang QB, 2019, LECT NOTES COMPUT SC, V11764, P703, DOI 10.1007/978-3-030-32239-7_78
   Kong Y, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.573866
   Lagree A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-87496-1
   Lal S, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104075
   Li K, 2020, AAAI CONF ARTIF INTE, V34, P775
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Lin AL, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3178991
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu Lu, 2018, Wuhan University Journal of Natural Sciences, V23, P178, DOI 10.1007/s11859-018-1308-z
   Mehta S, 2019, ARXIV
   Mehta S, 2018, arXiv
   Naylor P, 2019, IEEE T MED IMAGING, V38, P448, DOI 10.1109/TMI.2018.2865709
   Naylor P, 2017, I S BIOMED IMAGING, P933, DOI 10.1109/ISBI.2017.7950669
   Nikhil KT, 2022, ARXIV
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Paszke A., 2016, ARXIV160602147
   Poplavskiy D, 2018, DATA SCI BOWL DISCUS
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Qing X, 2022, ARXIV
   Vu QD, 2019, FRONT BIOENG BIOTECH, V7, DOI 10.3389/fbioe.2019.00053
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shah S, 2020, LATEST STAT BREAST C
   Su H, 2015, LECT NOTES COMPUT SC, V9351, P383, DOI 10.1007/978-3-319-24574-4_46
   Tomar NK, 2022, COMP MED SY, P317, DOI 10.1109/CBMS55023.2022.00063
   Xing Fuyong, 2016, IEEE Rev Biomed Eng, V9, P234, DOI 10.1109/RBME.2016.2515127
   Xu J, 2016, IEEE T MED IMAGING, V35, P119, DOI 10.1109/TMI.2015.2458702
   Yu F., 2015, ARXIV
   Zhao H., 2018, ARXIV
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou YN, 2019, LECT NOTES COMPUT SC, V11492, P682, DOI 10.1007/978-3-030-20351-1_53
NR 50
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20431
EP 20452
DI 10.1007/s11042-022-14098-y
EA DEC 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000893056800003
DA 2024-07-18
ER

PT J
AU Singh, AK
   Nayyar, A
   Garg, A
AF Singh, Anuj Kumar
   Nayyar, Anand
   Garg, Ankit
TI A secure elliptic curve based anonymous authentication and key
   establishment mechanism for IoT and cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IoT; Authentication; Key establishment; Anonymous; Elliptic curve
   cryptography; BAN logic
ID AGREEMENT SCHEME; MUTUAL AUTHENTICATION; PROTOCOL; PASSWORD;
   REQUIREMENTS; CHALLENGES; DEVICES; DESIGN
AB With the increased number of smart devices in IoT and cloud, communication messages are exchanged extensively throughout the network. This requires secure data transfer between the user and the IoT node, and it entails appropriate mutual authentication and a key establishment mechanism. In this paper, a secure authentication and key agreement mechanism for cloud-based IoT based on elliptic curve cryptography, which provides complete anonymity, has been developed and proposed. The proposed mechanism satisfies multiple security attributes, including confidentiality, the anonymity of the user, anonymity of the IoT node, mutual authentication, secret key establishment, integrity, key privacy, non-repudiation, forward secrecy, and availability. Moreover, security analysis has revealed that the proposed mechanism is safe from replay, user impersonation, gateway impersonation, denial of service, man-in-the-middle, lost/stolen device, desynchronization, known-key, parallel session, gateway bypassing, and online password guessing attacks. Formal security analysis of the proposed protocol using BAN logic and ROR model has been carried out to ensure the security of the authentication process and the secrecy of the established key respectively. Comparative analysis of the security functionalities has established that the proposed mechanism provides the highest security in comparison to the other related schemes. The proposed mechanism has also removed the requirement of using a secure communication channel for the registration of an IoT node with the gateway. Though, the proposed mechanism consumes more computational and communication overhead, but in view of trade-off between security functions and performance, the proposed protocol outperforms the other existing IoT authentication protocols.
C1 [Singh, Anuj Kumar; Garg, Ankit] Univ Engn & Technol UETR, Sch Comp, Roorkee 247667, Uttar Pradesh, India.
   [Nayyar, Anand] Duy Tan Univ, Grad Sch, Da Nang 550000, Vietnam.
   [Nayyar, Anand] Duy Tan Univ, Fac Informat Technol, Da Nang 550000, Vietnam.
C3 Duy Tan University; Duy Tan University
RP Nayyar, A (corresponding author), Duy Tan Univ, Grad Sch, Da Nang 550000, Vietnam.; Nayyar, A (corresponding author), Duy Tan Univ, Fac Informat Technol, Da Nang 550000, Vietnam.
EM anujbtechcs@gmail.com; anandnayyar@duytan.edu.vn; ankitgitm@gmail.com
RI Singh, Dr. Anuj Kr./HGB-0160-2022; Garg, Ankit/ABD-9886-2020; Nayyar,
   Anand/F-3732-2015
OI Nayyar, Anand/0000-0002-9821-6146; Garg, Dr. Ankit/0000-0002-6466-2738
CR Abdalla M, 2005, LECT NOTES COMPUT SC, V3386, P65
   Agilandeeswari L, 2022, MULTIMED TOOLS APPL, V81, P27683, DOI 10.1007/s11042-022-12946-5
   AL-Turjman F, 2021, IEEE T IND INFORM, V17, P2919, DOI 10.1109/TII.2020.2990741
   Amin  R., 2016, FUTURE GENER COMP SY, V78, P1005
   Amin R, 2018, FUTURE GENER COMP SY, V78, P1005, DOI 10.1016/j.future.2016.12.028
   Azrour M, 2021, NEW EFFICIENT SECURE
   Banerjee S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041215
   Boneh D., 1998, Algorithmic Number Theory. Third International Symposium, ANTS-III. Proceedings, P48, DOI 10.1007/BFb0054851
   BURROWS M, 1989, P ROY SOC LOND A MAT, V426, P233, DOI 10.1098/rspa.1989.0125
   Caruccio L, 2020, IEEE ACCESS, V8, P205034, DOI 10.1109/ACCESS.2020.3036916
   Challa S, 2017, IEEE ACCESS, V5, P3028, DOI 10.1109/ACCESS.2017.2676119
   Chang CC, 2016, IEEE T WIREL COMMUN, V15, P357, DOI 10.1109/TWC.2015.2473165
   Chen CM, 2022, ENHANCED AUTHENTICAT
   Chen K., 2018, J. Hardware Syst. Secur., V2, P97, DOI [10.1007/s41635-017-0029-7, DOI 10.1007/S41635-017-0029-7]
   Chen YC, 2011, WIREL COMMUN MOB COM, V11, P1366, DOI 10.1002/wcm.933
   Das Ayan Kumar, 2020, Computational Intelligence in Pattern Recognition. Proceedings of CIPR 2019. Advances in Intelligent Systems and Computing (AISC 999), P267, DOI 10.1007/978-981-13-9042-5_23
   Das AK, 2015, J KING SAUD UNIV-COM, V27, P193, DOI 10.1016/j.jksuci.2014.03.020
   Das AK, 2020, COMPUT SECUR, V97, DOI 10.1016/j.cose.2020.101938
   Dexin Yang, 2010, 2010 International Conference on Computer Design and Applications (ICCDA 2010), P554, DOI 10.1109/ICCDA.2010.5541128
   Dhillon PK, 2017, J INF SECUR APPL, V34, P255, DOI 10.1016/j.jisa.2017.01.003
   Fakroon M, 2020, INTERNET THINGS-NETH, V9, DOI 10.1016/j.iot.2020.100158
   Fouda MM, 2011, IEEE T SMART GRID, V2, P675, DOI 10.1109/TSG.2011.2160661
   Ghani A, 2019, INT J COMMUN SYST, V32, DOI 10.1002/dac.4139
   Haixian Chen, 2019, 2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS). Proceedings, P1682, DOI 10.1109/HPCC/SmartCity/DSS.2019.00230
   Hussain K, 2021, J KING SAUD UNIV-COM, V33, P417, DOI 10.1016/j.jksuci.2019.01.015
   Iqbal W, 2020, IEEE INTERNET THINGS, V7, P10250, DOI 10.1109/JIOT.2020.2997651
   Islam SKH, 2017, J KING SAUD UNIV-COM, V29, P311, DOI 10.1016/j.jksuci.2015.08.002
   Kalra S, 2015, PERVASIVE MOB COMPUT, V24, P210, DOI 10.1016/j.pmcj.2015.08.001
   Khan MK, 2014, COMPUTING, V96, P793, DOI 10.1007/s00607-013-0308-2
   Koblitz N, 2000, DESIGN CODE CRYPTOGR, V19, P173, DOI 10.1023/A:1008354106356
   Kumari S, 2018, J SUPERCOMPUT, V74, P6428, DOI 10.1007/s11227-017-2048-0
   Kumari S, 2017, MULTIMED TOOLS APPL, V76, P13581, DOI 10.1007/s11042-016-3771-x
   Kumari S, 2016, FUTURE GENER COMP SY, V63, P56, DOI 10.1016/j.future.2016.04.016
   LAMPORT L, 1981, COMMUN ACM, V24, P770, DOI 10.1145/358790.358797
   Lauter KE, 2009, LECT NOTES COMPUT SC, V5381, P309, DOI 10.1007/978-3-642-04159-4_20
   Li L., 2012, P 2012 INT C MEAS IN, V1, P374
   Li XX, 2010, IEEE T IND ELECTRON, V57, P793, DOI 10.1109/TIE.2009.2028351
   Li X, 2012, J NETW COMPUT APPL, V35, P763, DOI 10.1016/j.jnca.2011.11.009
   Lu YR, 2017, MULTIMED TOOLS APPL, V76, P1801, DOI 10.1007/s11042-015-3166-4
   Luo H, 2021, PROVABLY SECURE ECC
   Maitra T, 2016, SECUR COMMUN NETW, V9, P4615, DOI 10.1002/sec.1653
   Malik MY, 2010, INT CONF ADV COMMUN, P1464
   Martínez-Peláez R, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092098
   Mishra D, 2014, EXPERT SYST APPL, V41, P8129, DOI 10.1016/j.eswa.2014.07.004
   Mo JQ, 2019, WIREL COMMUN MOB COM, DOI 10.1155/2019/4520685
   Ouafi K, 2008, LECT NOTES COMPUT SC, V5037, P479, DOI 10.1007/978-3-540-68914-0_29
   Pal S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20205897
   Pandey PC, 2021, J BIOMED MATER RES B, V109, P33, DOI [10.1002/jbm.b.34678, 10.1007/s40860-020-00098-y]
   Park DS, 2018, J SUPERCOMPUT, V74, P6401, DOI 10.1007/s11227-018-2652-7
   Park K, 2017, IEEE ACCESS, V5, P25110, DOI 10.1109/ACCESS.2017.2773535
   Porambage P, 2014, IEEE WCNC, P2728, DOI 10.1109/WCNC.2014.6952860
   Ray S., 2011, 2011 International Conference on Recent Trends in Information Systems (ReTIS), P297, DOI 10.1109/ReTIS.2011.6146885
   Ray S, 2016, WIRELESS PERS COMMUN, V90, P1331, DOI 10.1007/s11277-016-3393-7
   Sadhukhan D, 2021, J SUPERCOMPUT, V77, P1114, DOI 10.1007/s11227-020-03318-7
   Sharma G, 2018, J INF SECUR APPL, V42, P95, DOI 10.1016/j.jisa.2018.08.003
   Shparlinski I., 2011, Encyclopedia of Cryptography and Security, P240
   Shuai MX, 2019, COMPUT SECUR, V86, P132, DOI 10.1016/j.cose.2019.06.002
   Singh AK, 2019, INT J COMPUT NETW CO, V11
   Singh AK, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10228291
   Singh AK, 2019, CYBERN INF TECHNOL, V19, P133, DOI 10.2478/cait-2019-0008
   Sood SK, 2011, J NETW COMPUT APPL, V34, P609, DOI 10.1016/j.jnca.2010.11.011
   Souri Alireza, 2019, Journal of Service Science Research, V11, P47, DOI 10.1007/s12927-019-0003-8
   Sowjanya K, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2021.102761
   Subramanian EK, 2020, CLUSTER COMPUT, V23, P3057, DOI 10.1007/s10586-020-03069-3
   Tabassum A, 2020, Secure Anti-Void Energy-Efficient Routing (SAVEER) Protocol for WSN-Based IoT Network
   Taher BH, 2021, J SENSORS, V2021, DOI 10.1155/2021/8871204
   Thakare A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11031260
   Tsai JL, 2010, INT J COMMUN SYST, V23, P1449, DOI 10.1002/dac.1118
   Wang CY, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/3048697
   Wang D, 2020, COMPUT SECUR, V88, DOI 10.1016/j.cose.2019.101619
   Wang D, 2018, IEEE T DEPEND SECURE, V15, P708, DOI 10.1109/TDSC.2016.2605087
   Wang D, 2017, IEEE T INF FOREN SEC, V12, P2776, DOI 10.1109/TIFS.2017.2721359
   Wang FF, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/3805058
   Wazid M, 2018, IEEE INTERNET THINGS, V5, P269, DOI 10.1109/JIOT.2017.2780232
   Wu HL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195604
   Wu SH, 2012, SECUR COMMUN NETW, V5, P236, DOI 10.1002/sec.315
   Xie Q, 2014, WIRELESS PERS COMMUN, V74, P601, DOI 10.1007/s11277-013-1309-3
   Xue KP, 2013, J NETW COMPUT APPL, V36, P316, DOI 10.1016/j.jnca.2012.05.010
   Yu S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19163598
   Zhou L, 2019, FUTURE GENER COMP SY, V91, P244, DOI 10.1016/j.future.2018.08.038
NR 80
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22525
EP 22576
DI 10.1007/s11042-022-14140-z
EA NOV 2022
PG 52
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000886859100008
DA 2024-07-18
ER

PT J
AU Heydari, Z
   Mahabadi, A
AF Heydari, Zahra
   Mahabadi, Aminollah
TI Scalable real-time sound source localization method based on TDOA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acoustic; Sound source localization (SSL); Time difference of arrival
   (TDOA); Successive unconstrained minimization (SUM); Distributed
   real-time embedded system (DRES)
ID ROBOTICS; TRACKING; SPEECH
AB Sound source localization remains a critical task for increasing sufficiently the location accuracy and typically decreasing the computational complexity of a real-time passive or active target tracking by multiple-microphone in topology-based concurrent sensor arrays for far- or near-filed domains. This paper properly presents a passive real-time localization method scientifically based on the time difference of arrival signal in reliably estimating the arrival angles for meaningfully improving the location accuracy and typically decreasing the prediction time of a stationary source in a three-dimensional (3D) model for an outdoor environment in free-field conditions. The proposed scalable distributed method significantly increases the localization accuracy by integrating local direction-finding information of two concurrent parallel microphone arrays and naturally deriving a specific piece of global location-finding information to sufficiently reduce the predictions' run-time. The designing approach accurately represents a two-step process to properly implement a suitable decomposition method and gently apply an interpolation technique in the near-filed ideal domain. The primary goal of our innovative design realistically is to seemingly indicate the key role of hardware architecture and popularly use suitable techniques in complexity reduction and accuracy improvement of the intelligent model for future scalable localization systems to progressively increase outstanding performance. The empirical experiments using different real and simulated datasets show the modern TDOA-SSL method ordinarily has a low-time 360 msec in 3D accurately estimating the prime location with an average error of 12.07 cm in the near-field and 296 cm in the far-field. In key addition, the proposed method invariably is robust to ambient noise and sound reflection in the near- and far-field. However, the average accuracy of the proposed system efficiently is 99.43% with an error factor of 0.19% for the near-field and 99.70% with an error factor of 0.016% for the far-field for the used range of 100 m and 1 km, respectively. Performance evaluation of the proposed method sufficiently shows the real-time prediction and the reasonable accuracy of the specific prediction positively enhances by carefully applying the geometric architectural specification.
C1 [Heydari, Zahra; Mahabadi, Aminollah] Shahed Univ, Comp Engn Dept, Tehran, Iran.
   [Heydari, Zahra; Mahabadi, Aminollah] Shahed Univ, Acoust Res Ctr, Tehran, Iran.
   [Mahabadi, Aminollah] Inst Res Fundamental Sci IPM, Sch Comp Sci, Tehran, Iran.
C3 Shahed University; Shahed University
RP Mahabadi, A (corresponding author), Shahed Univ, Comp Engn Dept, Tehran, Iran.; Mahabadi, A (corresponding author), Shahed Univ, Acoust Res Ctr, Tehran, Iran.; Mahabadi, A (corresponding author), Inst Res Fundamental Sci IPM, Sch Comp Sci, Tehran, Iran.
EM mahabadi@shahed.ac.ir
CR Abiri A, 2020, IEEE SENS J, V20, P7253, DOI 10.1109/JSEN.2020.2978814
   Awarkeh N, 2019, THESIS U PARIS SACLA
   Bai Y, 2020, COMPUT NETW, V181, DOI 10.1016/j.comnet.2020.107447
   CHAN YT, 1994, IEEE T SIGNAL PROCES, V42, P1905, DOI 10.1109/78.301830
   Chen J, 2020, PARTICUL SCI TECHNOL, V38, P247, DOI 10.1080/02726351.2018.1504152
   Cui XX, 2018, IEEE SENS J, V18, P3360, DOI 10.1109/JSEN.2018.2803150
   Dang XD, 2022, IEEE-ACM T AUDIO SPE, V30, P1108, DOI 10.1109/TASLP.2022.3153251
   DiBiase J. H., 2000, Ph.D. thesis
   Dogancay K, 2005, P SIMTECT 2005
   Fabregat G, 2020, IEEE T CIRCUITS-II, V67, P3547, DOI 10.1109/TCSII.2020.2986296
   Fenwick AJ, 1999, IEE P-RADAR SON NAV, V146, P208, DOI 10.1049/ip-rsn:19990538
   Foy W. H., 1976, IEEE Transactions on Aerospace and Electronic Systems, VAES-12, P187, DOI 10.1109/TAES.1976.308294
   Grondin F, 2019, ROBOT AUTON SYST, V113, P63, DOI 10.1016/j.robot.2019.01.002
   Heydari Z., 2021, J ACOUSTICAL ENG SOC, V8, P13
   Heydari Z, 2020, 6 INT ACOUSTIC C IRA
   Heydari Z., 2021, J COMPUTER SCI INFOR, V19, P1
   Invernizzi D, 2021, IEEE T CONTR SYST T, V29, P1147, DOI 10.1109/TCST.2020.2992389
   Jin BN, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030778
   Kraljevic L, 2020, IEEE ACCESS, V8, P87749, DOI 10.1109/ACCESS.2020.2993076
   Liang Z, 2022, 2TH INT C MECH ENG I, P1
   Liaquat MU, 2021, ENERGIES, V14, DOI 10.3390/en14133910
   Luo HJ, 2022, IEEE SENS J, V22, P8360, DOI 10.1109/JSEN.2022.3162600
   Mahabadi A, 2021, MULTIMED TOOLS APPL, V80, P1433, DOI 10.1007/s11042-020-09787-5
   Mirbeygi M, 2021, SPEECH COMMUN, V126, P22, DOI 10.1016/j.specom.2020.12.003
   Pierce A. D., 1989, Acoustics: An Introduction to Its Physical Principles and Applications"
   Polvara R, 2021, IEEE ROBOT AUTOM LET, V6, P6577, DOI 10.1109/LRA.2021.3094557
   Popper A.N., 2005, SOUND SOURCE LOCALIZ
   Rascon C, 2017, ROBOT AUTON SYST, V96, P184, DOI 10.1016/j.robot.2017.07.011
   Rumsey F., 2014, Sound and Recording: Applications and Theory, V7th
   Seidel A, 2021, TELEMAT INFORM, V64, DOI 10.1016/j.tele.2021.101686
   Shi ZG, 2020, IEEE T VEH TECHNOL, V69, P2731, DOI 10.1109/TVT.2020.2964110
   SMITH JO, 1987, IEEE T ACOUST SPEECH, V35, P1661, DOI 10.1109/TASSP.1987.1165089
   So HC, 2008, IEEE T SIGNAL PROCES, V56, P2614, DOI 10.1109/TSP.2007.914342
   Su D, 2021, IEEE T ROBOT, V37, P1451, DOI 10.1109/TRO.2021.3069140
   Sudo Y, 2021, IEEE/SICE I S SYS IN, P382, DOI 10.1109/IEEECONF49454.2021.9382730
   Sun YM, 2019, IEEE T SIGNAL PROCES, V67, P320, DOI 10.1109/TSP.2018.2879622
   Wu P, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112554
   Yang SM, 2020, IEEE T NEUR NET LEAR, V31, P148, DOI 10.1109/TNNLS.2019.2899936
   Yasin I, 2020, IEEE ACCESS, V8, P56711, DOI 10.1109/ACCESS.2020.2981885
   Yassin A, 2017, IEEE COMMUN SURV TUT, V19, P1327, DOI 10.1109/COMST.2016.2632427
   Yin JH, 2016, IEEE SIGNAL PROC LET, V23, P144, DOI 10.1109/LSP.2015.2505138
   Zou YB, 2020, INT CONF ACOUST SPEE, P4881, DOI [10.1109/icassp40776.2020.9053746, 10.1109/ICASSP40776.2020.9053746]
NR 42
TC 0
Z9 0
U1 6
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23333
EP 23372
DI 10.1007/s11042-022-14256-2
EA NOV 2022
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000885231500003
DA 2024-07-18
ER

PT J
AU Song, WR
   Wang, XY
   Chen, CH
   Liu, F
AF Song, Wanru
   Wang, Xinyi
   Chen, Changhong
   Liu, Feng
TI Visible-thermal person re-identification via multiple center-based
   constraints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visible-thermal person re-identification; Center-constrained; Grayscale
   transformation; Loss function
AB Person re-identification is an important part of the intelligent video analysis and processing system. A new type of surveillance camera can switch to the thermal infrared mode for 24-hour video surveillance. It is necessary to research the visible-thermal cross-modality person re-identification. However, there is a large modal discrepancy in the visible-thermal task. Therefore, the research focus on how to build a bridge to narrow the cross-modality gap and fully exploit the shared information. In this paper, we first employ grayscale transformation of the visible image to generate an intermediate modality, thereby reducing the distance between the original two domains. On this basis, a novel three-branch multiple center-constrained network (TMCC-Net) is built for the visible-thermal task. More specifically, TMCC-Net is a three-branch network that mines the shared information of pedestrians in three modalities through special feature learning and shared feature embedding. In order to obtain better performance, our work introduces two heterogeneous center-constrained losses to constrain the feature embedding. On the one hand, the proposed losses limit the distribution of features at the modality edge; on the other hand, they can strengthen the role of grayscale modality in the cross-modality task. Finally, an end-to-end model for visible-thermal person re-identification is built, which is effective for shared information mining. Extensive experiments are conducted on the two cross-modality datasets, including the SYSU-MM01 and RegDB datasets. The experimental results demonstrate the effectiveness and superiority of the proposed method compared to the state-of-the-art approaches.
C1 [Song, Wanru; Wang, Xinyi; Chen, Changhong; Liu, Feng] Nanjing Univ Posts & Telecommunicat, Nanjing 210013, Jiangsu, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Song, WR (corresponding author), Nanjing Univ Posts & Telecommunicat, Nanjing 210013, Jiangsu, Peoples R China.
EM songwanruu@163.com; xawangxy@njupt.edu.cn; chenchh@njupt.edu.cn;
   liuf@njupt.edu.cn
RI chen, changhong/V-1382-2018
OI Song, Wanru/0000-0002-7067-6108
FU National Natural Science Foundation of China [62177029, 61807020];
   Startup Foundation for Introducing Talent of Nanjing University of Posts
   and Communications [NY221041, NY222034]; General Project of The Natural
   Science Foundation of Jiangsu Higher Education Institution of China
   [22KJB520025]
FX This work was supported in part by National Natural Science Foundation
   of China under Grant 62177029 and 61807020, and in part by the Startup
   Foundation for Introducing Talent of Nanjing University of Posts and
   Communications under Grant NY221041 and NY222034, and in part by General
   Project of The Natural Science Foundation of Jiangsu Higher Education
   Institution of China 22KJB520025.
CR [Anonymous], 2014, ADV COMPUT VIS PATT, DOI DOI 10.1007/978-1-4471-6296-4
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Cheng YZ, 2021, IEEE IMAGE PROC, P1149, DOI 10.1109/ICIP42928.2021.9506219
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Dai J, 2019, IEEE T IMAGE PROCESS, V28, P1366, DOI 10.1109/TIP.2018.2878505
   Dai PY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P677
   Hao Y, 2019, AAAI CONF ARTIF INTE, P8385
   Kaur A, 2022, IEEEACM T COMPUTATIO, V1, P1
   Kumar K, 2017, 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT - 2017), P100, DOI 10.1145/3154979.3154998
   Kumar K, 2019, J VIS COMMUN IMAGE R, V58, P345, DOI 10.1016/j.jvcir.2018.12.009
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Leng QM, 2020, IEEE T CIRC SYST VID, V30, P1092, DOI 10.1109/TCSVT.2019.2898940
   Li DG, 2020, AAAI CONF ARTIF INTE, V34, P4610
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu HJ, 2021, IEEE SIGNAL PROC LET, V28, P653, DOI 10.1109/LSP.2021.3065903
   Liu HJ, 2020, NEUROCOMPUTING, V398, P11, DOI 10.1016/j.neucom.2020.01.089
   Liu HF, 2020, I S BIOMED IMAGING, DOI 10.1109/isbiworkshops50223.2020.9153365
   Liu JC, 2022, APPL INTELL, V52, P2423, DOI 10.1007/s10489-021-02548-3
   Liu J, 2019, APPL INTELL, V49, P3436, DOI 10.1007/s10489-019-01459-8
   Negi A., 2022, Cyber-Physical Systems, P1
   Nguyen DT, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030605
   Qi MB, 2021, MULTIMED TOOLS APPL, V80, P17645, DOI 10.1007/s11042-020-10431-5
   Seokeon Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10254, DOI 10.1109/CVPR42600.2020.01027
   Ubhi JS, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103483
   Wang GA, 2020, AAAI CONF ARTIF INTE, V34, P12144
   Wang GA, 2019, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2019.00372
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wang ZX, 2019, PROC CVPR IEEE, P618, DOI 10.1109/CVPR.2019.00071
   Wei ZY, 2022, IEEE T NEUR NET LEAR, V33, P4676, DOI 10.1109/TNNLS.2021.3059713
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu AC, 2017, IEEE I CONF COMP VIS, P5390, DOI 10.1109/ICCV.2017.575
   Yan Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13376, DOI 10.1109/CVPR42600.2020.01339
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Yao HT, 2019, IEEE T IMAGE PROCESS, V28, P2860, DOI 10.1109/TIP.2019.2891888
   Ye HR, 2021, IEEE T IMAGE PROCESS, V30, P1583, DOI 10.1109/TIP.2020.3045261
   Ye M, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1092
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Ye M, 2021, IEEE T INF FOREN SEC, V16, P728, DOI 10.1109/TIFS.2020.3001665
   Ye M, 2020, IEEE T INF FOREN SEC, V15, P407, DOI 10.1109/TIFS.2019.2921454
   Ye M, 2018, AAAI CONF ARTIF INTE, P7501
   You JJ, 2016, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2016.150
   Zhu YX, 2020, NEUROCOMPUTING, V386, P97, DOI 10.1016/j.neucom.2019.12.100
   Zhao JQ, 2023, IEEE T MULTIMEDIA, V25, P3668, DOI 10.1109/TMM.2022.3163847
   Zheng Liang, 2016, ARXIV
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zhong X, 2022, IEEE T CIRC SYST VID, V32, P1418, DOI 10.1109/TCSVT.2021.3072171
NR 46
TC 1
Z9 1
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18459
EP 18481
DI 10.1007/s11042-022-14113-2
EA NOV 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000882819700002
DA 2024-07-18
ER

PT J
AU Wang, J
   Xia, B
AF Wang, Juan
   Xia, Bin
TI CDRNet: accurate cup-to-disc ratio measurement with tight bounding box
   supervision in fundus photography using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cup-to-disc ratio (CDR); Bounding box tightness prior; Class-specific
   bounding-box regression; Weakly supervised image segmentation; Fundus
   photography
ID OPTIC DISC; SEGMENTATION; CLASSIFICATION; PREVALENCE; DIAGNOSIS;
   GLAUCOMA
AB The cup-to-disc ratio (CDR) is one of the most significant indicator for glaucoma diagnosis. Different from the use of costly fully supervised learning formulation with pixel-wise annotations in the literature, this study investigates the feasibility of accurate CDR measurement in fundus images using only tight bounding box supervision. For this purpose, we develop a two-task network named as CDRNet for accurate CDR measurement, one for weakly supervised image segmentation, and the other for bounding-box regression. The weakly supervised image segmentation task is implemented based on generalized multiple instance learning formulation and smooth maximum approximation, and the bounding-box regression task outputs class-specific bounding box prediction in a single scale at the original image resolution. To get accurate bounding box prediction, a class-specific bounding-box normalizer and an expected intersection-over-union are proposed. In the experiments, the proposed approach was evaluated by a testing set with 1200 images using CDR error and F-1 score for CDR measurement and dice coefficient for image segmentation. A grader study was conducted to compare the performance of the proposed approach with those of individual graders. The experimental results show that the proposed approach achieves CDR error of 0.0458 and F-1 score of 0.917 in CDR measurement and dice coefficients of 0.882 and 0.950 in optic cup and disc segmentation, respectively. These results indicate that the proposed approach outperforms the state-of-the-art performance obtained from the fully supervised image segmentation (FSIS) approach using pixel-wise annotation for CDR measurement. Its performance is also better than those of individual graders. In addition, the proposed approach gets performance close to the state-of-the-art obtained from FSIS and the performance of individual graders for optic cup and disc segmentation. The codes are available at https://github.com/wangjuan313/CDRNet.
C1 [Wang, Juan] Delta Micro Technol Inc, 23421 S Pointe Dr, Laguna Hills, CA 92653 USA.
   [Xia, Bin] Shenzhen SiBright Co Ltd, Tinwe Ind Pk,6 Liufang Rd, Shenzhen 518052, Guangdong, Peoples R China.
RP Wang, J (corresponding author), Delta Micro Technol Inc, 23421 S Pointe Dr, Laguna Hills, CA 92653 USA.
EM wangjuan313@gmail.com; b.xia@sibionics.com
RI Wang, Juan/O-5400-2019
CR Alawad M, 2022, CLIN OPHTHALMOL, V16, P747, DOI 10.2147/OPTH.S348479
   Almazroa A, 2015, J OPHTHALMOL, V2015, DOI 10.1155/2015/180972
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P1597, DOI 10.1109/TMI.2018.2791488
   Gupta P, 2016, INVEST OPHTH VIS SCI, V57, P2905, DOI 10.1167/iovs.15-18469
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hsu CC, 2019, ADV NEUR IN, V32
   Jiang YM, 2020, IEEE T BIO-MED ENG, V67, P335, DOI 10.1109/TBME.2019.2913211
   Kervadec H, 2020, PR MACH LEARN RES, V121, P365
   Kingma D. P., 2014, arXiv
   Lange M, 2014, APPL LP NORMS THEIR
   Pachade S, 2021, MED IMAGE ANAL, V74, DOI 10.1016/j.media.2021.102253
   Puttagunta M, 2021, MULTIMED TOOLS APPL, V80, P24365, DOI 10.1007/s11042-021-10707-4
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sevastopolsky A., 2017, Pattern Recognition and Image Analysis, V27, P618, DOI 10.1134/S1054661817030269
   Thakur N, 2018, BIOMED SIGNAL PROCES, V42, P162, DOI 10.1016/j.bspc.2018.01.014
   Tham Yih-Chung, 2014, Ophthalmology, V121, P2081, DOI 10.1016/j.ophtha.2014.05.013
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang J., 2022, ARXIV
   Wang J, 2021, LECT NOTES COMPUT SC, V12902, P526, DOI 10.1007/978-3-030-87196-3_49
   Wang J, 2020, IEEE J BIOMED HEALTH, V24, P3397, DOI 10.1109/JBHI.2020.3012547
   Wang J, 2019, IEEE IMAGE PROC, P804, DOI [10.1109/ICIP.2019.8802984, 10.1109/icip.2019.8802984]
   Wang J, 2019, IEEE ACCESS, V7, P102589, DOI 10.1109/ACCESS.2019.2930941
   Wang J, 2018, PATTERN RECOGN, V78, P12, DOI 10.1016/j.patcog.2018.01.009
   Wang J, 2017, IEEE T MED IMAGING, V36, P1172, DOI 10.1109/TMI.2017.2655486
   Wang J, 2017, COMPUT BIOL MED, V84, P137, DOI 10.1016/j.compbiomed.2017.03.024
   Yu F., 2015, ARXIV
   Yu H, 2021, NEUROCOMPUTING, V444, P92, DOI 10.1016/j.neucom.2020.04.157
NR 28
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16455
EP 16477
DI 10.1007/s11042-022-14183-2
EA NOV 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000882352400003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Akin, AT
   Cömert, Ç
AF Akin, Alper Tunga
   Comert, Cetin
TI The development of an augmented reality audio application for visually
   impaired persons
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Object detection; Navigation; Monocular depth
   extraction
ID NAVIGATION
AB In this study, an augmented reality audio application that works with smartphones has been developed to assist the lives of visually impaired persons. The application provides object detection, obstacle notification, and navigation through online base maps with audio feedback. Several important issues were to be tackled in such an undertaking. Deep learning techniques have been employed for the issues of monocular depth extraction and object detection. A web services solution has been adopted concerning real-time feedback, which is critical for the impaired. A deep learning monocular depth extraction model, which has been preferred with respect to a literature review, has been validated with relevant metrics. For object detection, a well-proven and widely used deep learning model has been chosen. All the involved software components and the developed application are open source.
C1 [Akin, Alper Tunga; Comert, Cetin] Karadeniz Tech Univ, Dept Geomat Engn, TR-61080 Trabzon, Turkey.
C3 Karadeniz Technical University
RP Akin, AT (corresponding author), Karadeniz Tech Univ, Dept Geomat Engn, TR-61080 Trabzon, Turkey.
EM alpertunga@ktu.edu.tr; ccomert@ktu.edu.tr
RI AKIN, Alper Tunga/AAK-3211-2021
OI AKIN, Alper Tunga/0000-0002-4535-9143
FU KTU Scientific Research Projects (KTU BAP) [FBA-2021-9488]
FX This work was supported by KTU Scientific Research Projects (KTU BAP)
   [FBA-2021-9488].
CR Akin Alper Tunga, 2021, 2021 5th International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT), P43, DOI 10.1109/ISMSIT52890.2021.9604645
   Aktas A, 2020, J FAC ENG ARCHIT GAZ, V35, P1685, DOI 10.17341/gazimmfd.652101
   [Anonymous], 2022, CLOUD TEXT TO SPEECH
   [Anonymous], 2022, UNITY MANUAL
   [Anonymous], 2022, TAPTAPSEE ASSISTIVE
   [Anonymous], 2020, BTS PYTORCH
   [Anonymous], 2022, GSMARENA
   [Anonymous], 2022, YOLOV5 ULTRALYTICS
   [Anonymous], 2022, IMPACT VISION IMPAIR
   [Anonymous], 2022, PROTECT YOURSELF OTH
   [Anonymous], 2013, STEPPING SCI ESTIMAT
   [Anonymous], 2022, MAPBOX WEB SERVICES
   Baecker RM., 2000, READINGS HUMAN COMPU, P2014
   Bauer Z, 2020, PATTERN RECOGN LETT, V137, P27, DOI 10.1016/j.patrec.2019.03.008
   Bimber O., 2005, Spatial Augmented Reality: Merging Real and Virtual Worlds, DOI [DOI 10.1201/B10624, 10.1201/B10624]
   Bradski G, 2000, DR DOBBS J, V25, P120
   CloudSight AI, 2022, IM REC API
   Eigen D, 2014, ADV NEUR IN, V27
   Elmannai W, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030565
   Furht B., 2008, Encyclopedia of Multimedia, P651, DOI 10.1007/978-0-387-78414-4_159
   Gallo P, 2013, ARXIV
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   github, 2021, DEPTH REC APP
   Grinberg Miguel, 2018, Flask web development: developing web applications with python
   Haklay M, 2008, IEEE PERVAS COMPUT, V7, P12, DOI 10.1109/MPRV.2008.80
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Kandalan RN, 2020, IEEE T HUM-MACH SYST, V50, P492, DOI 10.1109/THMS.2020.3016051
   Khan F, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082272
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Lee J, 2019, PR MACH LEARN RES, V97
   Lin BS, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061371
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lo Valvo A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093061
   Ming Y, 2021, NEUROCOMPUTING, V438, P14, DOI 10.1016/j.neucom.2020.12.089
   Nowacki Pawel, 2020, Engineering in Dependability of Computer Systems and Networks. Proceedings of the Fourteenth International Conference on Dependability of Computer Systems DepCoS-RELCOMEX. Advances in Intelligent Systems and Computing (AISC 987), P358, DOI 10.1007/978-3-030-19501-4_36
   Paszke A, 2019, ADV NEUR IN, V32
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Senanayake I.P., 2018, ANN SESSIONS IESL, P447
   Skopeliti A, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8050215
   Sun MH, 2019, IEEE ACCESS, V7, P66731, DOI 10.1109/ACCESS.2019.2915552
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tapu R, 2020, PATTERN RECOGN LETT, V137, P37, DOI 10.1016/j.patrec.2018.10.031
   WeWALK, 2022, US
   World Health Organization, 2019, WORLD REP VIS
   Zaba J.N., 2011, Journal of Behavioral Optometry, V22
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
NR 50
TC 0
Z9 0
U1 5
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17493
EP 17512
DI 10.1007/s11042-022-14134-x
EA NOV 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000880546200004
DA 2024-07-18
ER

PT J
AU Biswas, N
   Banerjee, D
   Bhattacharya, S
AF Biswas, Nilotpal
   Banerjee, Debangshu
   Bhattacharya, Samit
TI Realistic walking experience for system-automated virtual reality tour
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; Realistic walking experience; Locomotion; Walking speed
   model; Virtual tour
ID ENVIRONMENTS; SPEED
AB Walking through a virtual environment is significant in many virtual reality applications. To provide a realistic walking experience, researchers have developed many virtual locomotion techniques where users provide constant input for walking. Usually, the user's continuous input is mapped with the visual stimulus to make the user experience walking in the virtual environment. However, system-automated virtual tours allow the users to navigate in the virtual environment without any continuous input for travelling, leaving no room for mapping user input with walking. Due to its low interaction fidelity, it is less preferred to implement realistic walking for a system-automated tour. In order to improve the walking realism (visually), in this work, we have proposed an instantaneous walking speed prediction model for a system-automated tour. We built and validated the model by collecting walking data from 40 users. The model was then evaluated with the help of an empirical study (N = 34). We found that using the speed predicted by the model as the visual optic flow can enhance the realistic walking experience than using a constant average walking speed. This work may motivate the developers and researchers to incorporate realistic walking experiences on a system-automated virtual tour.
C1 [Biswas, Nilotpal; Banerjee, Debangshu; Bhattacharya, Samit] Indian Inst Technol Guwahati, Dept Comp Sci & Engn, Gauhati 100190, Assam, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Biswas, N (corresponding author), Indian Inst Technol Guwahati, Dept Comp Sci & Engn, Gauhati 100190, Assam, India.
EM nilot176101101@iitg.ac.in; debangshu@google.com; samit@iitg.ac.in
RI Biswas, Nilotpal/JAC-5528-2023
OI Biswas, Nilotpal/0000-0002-8819-0093
FU Department of Science and Technology (DST)
FX We sincerely wish to thank the Department of Science and Technology
   (DST), Govt. of India, for supporting this work. Also, we would like to
   thank all the participants who volunteered for the empirical studies.
CR Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   [Anonymous], 1981, Human Walking
   Bennett JA, 2019, J MICROBIOL BIOL EDU, V20, DOI 10.1128/jmbe.v20i2.1658
   Biswas N, 2021, INT SYM MIX AUGMENT, P209, DOI 10.1109/ISMAR-Adjunct54149.2021.00050
   Boian RF, 2005, INT C REHAB ROBOT, P550
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Bowman DA, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2330667.2330687
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Brogan DC, 1998, IEEE COMPUT GRAPH, V18, P58, DOI 10.1109/38.708561
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Cho Y. H., 2002, Journal of Travel & Tourism Marketing, V12, P1, DOI 10.1300/J073v12n04_01
   Cirio G., 2009, Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology, P155, DOI [DOI 10.1145/1643928.1643965, 10.1145/1643928.1643965]
   DEAN GA, 1965, ERGONOMICS, V8, P31, DOI 10.1080/00140136508930772
   Debailleux L, 2018, LECT NOTES COMPUT SC, V10605, P289, DOI 10.1007/978-3-319-75826-8_24
   Durgin FH, 2005, J EXP PSYCHOL HUMAN, V31, P339, DOI 10.1037/0096-1523.31.2.339
   Fasel B, 2017, MED BIOL ENG COMPUT, V55, P1773, DOI 10.1007/s11517-017-1621-2
   Freitag S, 2016, IEEE T VIS COMPUT GR, V22, P1462, DOI 10.1109/TVCG.2016.2518298
   Fujita Kinya., 2004, Proc. IEEE Virtual Reality Workshop, P29
   Goedicke D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173739
   Hoppe M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300776
   Jerald Jason, 2015, The VR Book: Human-Centered Design for Virtual Reality, DOI [DOI 10.1145/2792790, 10.1145/2792790]
   Kennedy RS, 2000, PRESENCE-TELEOP VIRT, V9, P463, DOI 10.1162/105474600566952
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Lee J, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P427, DOI 10.1145/3343055.3361926
   Liu SH, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P817, DOI [10.1109/vr.2019.8798158, 10.1109/VR.2019.8798158]
   MacQuarrie A, 2017, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VR.2017.7892230
   Matsumoto K, 2021, INT SYM MIX AUGMENT, P498, DOI 10.1109/ISMAR52148.2021.00067
   Mine M.R., 1995, Virtual Environment Interaction Techniques
   Moghadam K, 2020, IEEE T VIS COMPUT GR, V26, P2273, DOI 10.1109/TVCG.2018.2884468
   Nilsson NC, 2014, IEEE T VIS COMPUT GR, V20, P569, DOI 10.1109/TVCG.2014.21
   Park JG, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P113
   Peng YH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376847
   Razzaque S., 2005, REDIRECTED WALKING
   Rose T, 2018, APPL ERGON, V69, P153, DOI 10.1016/j.apergo.2018.01.009
   Sarupuri B, 2020, TESTBED EVALUATION M
   Sarupuri B, 2017, IEEE SYMP 3D USER, P227, DOI 10.1109/3DUI.2017.7893354
   Schmidt H., 2004, Proceedings of EuroHaptics, P60
   Seethapathi N, 2015, BIOL LETTERS, V11, DOI 10.1098/rsbl.2015.0486
   Sloot LH, 2014, GAIT POSTURE, V39, P939, DOI 10.1016/j.gaitpost.2013.12.005
   Sra M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300905
   Terziman L., 2010, P 17 ACM S VIRT REAL, P27, DOI DOI 10.1145/1889863.1889867
   van Gisbergen Marnix, 2019, Augmented Reality and Virtual Reality, P45
   Visell Y., 2013, HUMAN WALKING VIRTUA
   Wendt JD, 2010, P IEEE VIRT REAL ANN, P51
   Yan L., 2004, P 4 INT IEEE C POL A, P1
   Yang J, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1093, DOI 10.1145/3332165.3347875
   Zielasko D, 2021, COMPUTERS, V10, DOI 10.3390/computers10060073
   Ziemer R E, 1984, SIGNALS SYSTEMS CONT
   Zihajehzadeh S, 2017, IEEE ENG MED BIO, P2345, DOI 10.1109/EMBC.2017.8037326
   Zihajehzadeh S, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0165211
   Zihajehzadeh S, 2016, IEEE ENG MED BIO, P243, DOI 10.1109/EMBC.2016.7590685
NR 51
TC 0
Z9 0
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17453
EP 17470
DI 10.1007/s11042-022-14035-z
EA OCT 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000876660800003
DA 2024-07-18
ER

PT J
AU Joseph, DS
   Pawar, PM
   Pramanik, R
AF Joseph, Diana Susan
   Pawar, Pranav M.
   Pramanik, Rahul
TI Intelligent plant disease diagnosis using convolutional neural network:
   a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Deep learning; Convolutional neural networks; Plant disease
   classification and identification; Leaf images
ID IMAGE-PROCESSING TECHNIQUES; DATA AUGMENTATION; DEEP; IDENTIFICATION;
   CLASSIFICATION; RECOGNITION; CNN; SEGMENTATION; SYSTEM
AB In recent times use of different technologies for intelligent crop production is growing. To increase the production of crops, diagnosing a plant disease is very important. Plant diseases can be identified using various techniques like image processing, machine learning, deep learning, etc. Among these techniques deep learning, especially deep learning using convolutional neural networks (CNN) has proved to be more efficient in recent years compared to other methods. This manuscript focuses mainly on the diseases affecting on eleven (11) different plants and how the diseases can be identified from plant leaf images using CNN based deep learning models. This review can help the researchers to get a brief overview of how state-of-the-art CNN models can be used for disease diagnosis in plants, and an overview of the state-of-the-art studies that have used visualization techniques to identify the disease spots for better diagnosis. The review also summarises the studies that have used hyperspectral images for plant disease diagnosis and various data sources used by different studies. The challenges that currently exist while developing a plant disease diagnostic system and the shortcomings and open areas for research have also been discussed in this manuscript.
C1 [Joseph, Diana Susan; Pawar, Pranav M.; Pramanik, Rahul] Birla Inst Technol & Sci Pilani, Dubai Campus, Dubai, U Arab Emirates.
RP Pawar, PM (corresponding author), Birla Inst Technol & Sci Pilani, Dubai Campus, Dubai, U Arab Emirates.
EM pranav@dubai.bits-pilani.ac.in
RI ; Pawar, Pranav M/G-8657-2019
OI , Diana Susan Joseph/0009-0007-1455-840X; Pawar, Pranav
   M/0000-0001-8193-7388
CR Adegun A, 2021, ARTIF INTELL REV, V54, P811, DOI 10.1007/s10462-020-09865-y
   Amara J., 2017, DATENBANKSYSTEME BUS
   Arivazhagan S., 2018, INT J PURE APPL MATH, V120, P11067
   Barbedo JGA, 2019, BIOSYST ENG, V180, P96, DOI 10.1016/j.biosystemseng.2019.02.002
   Barbedo JGA, 2016, BIOSYST ENG, V144, P52, DOI 10.1016/j.biosystemseng.2016.01.017
   Arsenovic M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11070939
   Barbedo J. G. A., 2018, IEEE Latin America Transactions, V16, P1749
   Barbedo JGA, 2018, BIOSYST ENG, V172, P84, DOI 10.1016/j.biosystemseng.2018.05.013
   Bari BS, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.432
   Bi CK, 2022, MOBILE NETW APPL, V27, P172, DOI 10.1007/s11036-020-01640-1
   Brahimi M, 2019, SIG P ALGO ARCH ARR, P111, DOI [10.23919/SPA.2019.8936759, 10.23919/spa.2019.8936759]
   Brahimi M, 2018, HUM-COMPUT INT-SPRIN, P93, DOI 10.1007/978-3-319-90403-0_6
   Brahimi M, 2017, APPL ARTIF INTELL, V31, P299, DOI 10.1080/08839514.2017.1315516
   Dung CV, 2019, AUTOMAT CONSTR, V99, P52, DOI 10.1016/j.autcon.2018.11.028
   Chen JW, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10040372
   Cristin R, 2020, ARTIF INTELL REV, V53, P4993, DOI 10.1007/s10462-020-09813-w
   Cruz AC, 2017, 2017 ASABE ANN INT M, P1, DOI DOI 10.13031/AIM.201700241
   DeChant C, 2017, PHYTOPATHOLOGY, V107, P1426, DOI 10.1094/PHYTO-11-16-0417-R
   Deepalakshmi P, 2021, INT J INF SYST MODEL, V12, P1, DOI 10.4018/IJISMD.2021010101
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhingra G, 2018, MULTIMED TOOLS APPL, V77, P19951, DOI 10.1007/s11042-017-5445-8
   Fenu G, 2021, AGRONOMY-BASEL, V11, DOI 10.3390/agronomy11112107
   Fuentes A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092022
   Ghosal S, 2018, P NATL ACAD SCI USA, V115, P4613, DOI 10.1073/pnas.1716999115
   Gobalakrishnan N., 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P0465, DOI 10.1109/ICCSP48568.2020.9182046
   Golhani Kamlesh, 2018, Information Processing in Agriculture, V5, P354, DOI 10.1016/j.inpa.2018.05.002
   Goluguri NVRR, 2021, ARTIF INTELL REV, V54, P359, DOI 10.1007/s10462-020-09849-y
   Ha JG, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042621
   Hamidisepehr A, 2020, T ASABE, V63, P1969, DOI 10.13031/trans.13791
   Han H, 2018, IEEE T PATTERN ANAL, V40, P2597, DOI 10.1109/TPAMI.2017.2738004
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hiroaki T., 2018, 2018 IEEE 8th International Conference on Consumer Electronics - Berlin (ICCE-Berlin), P1, DOI [DOI 10.1109/OECC.2018.8730055, DOI 10.1109/AIPR.2018.8707385]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Hughes D., 2015, ABS151108060 CORR
   Nguyen HT, 2019, PATTERN RECOGN LETT, V121, P104, DOI 10.1016/j.patrec.2018.07.022
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Izay A., 2017, CIRC COMPUT SCI, V2, P1, DOI DOI 10.22632/CCS-2017-252-66
   Jiang F, 2020, COMPUT ELECTRON AGR, V179, DOI [10.1016/j.compeg.2020.105824, 10.1016/j.compag.2020.105824]
   Jiang P, 2019, IEEE ACCESS, V7, P59069, DOI 10.1109/ACCESS.2019.2914929
   Johannes A, 2017, COMPUT ELECTRON AGR, V138, P200, DOI 10.1016/j.compag.2017.04.013
   Joshi BM, 2020, J INFORM OPTIM SCI, V41, P475, DOI 10.1080/02522667.2020.1734295
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Karlekar A, 2020, COMPUT ELECTRON AGR, V172, DOI 10.1016/j.compag.2020.105342
   Kaur S, 2019, ARCH COMPUT METHOD E, V26, P507, DOI 10.1007/s11831-018-9255-6
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Khan MA, 2020, MULTIMED TOOLS APPL, V79, P18627, DOI 10.1007/s11042-020-08726-8
   Khan MA, 2018, COMPUT ELECTRON AGR, V155, P220, DOI 10.1016/j.compag.2018.10.013
   Khatoon S., 2021, Comput. Mater. Contin, V67, P595, DOI [10.32604/cmc.2021.014580, DOI 10.32604/CMC.2021.014580]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36
   Lauguico Sandy, 2020, 2020 IEEE Region 10 Conference (TENCON), P767, DOI 10.1109/TENCON50793.2020.9293866
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee S, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI [10.14722/ndss.2017.23457, 10.1016/j.patcog.2017.05.015]
   Lee SH, 2015, IEEE IMAGE PROC, P452, DOI 10.1109/ICIP.2015.7350839
   Li H, 2013, IEEE INT CON MULTI
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Lin TL, 2020, J INTERNET TECHNOL, V21, P605, DOI 10.3966/160792642020032102027
   Liu B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010011
   Liu J, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.00898
   Loey M., 2020, INT J SERV SCI MANAG, V11, P41
   Lowe A, 2017, PLANT METHODS, V13, DOI 10.1186/s13007-017-0233-z
   Lu J, 2017, COMPUT ELECTRON AGR, V142, P369, DOI 10.1016/j.compag.2017.09.012
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Ma JC, 2018, COMPUT ELECTRON AGR, V154, P18, DOI 10.1016/j.compag.2018.08.048
   Mary NAB, 2020, MULTIMED TOOLS APPL, V79, P30601, DOI 10.1007/s11042-020-09521-1
   Mia MR., 2020, IRAN J COMPUTER SCI, V3, P185, DOI DOI 10.1007/S42044-020-00057-Z
   Mishra S, 2020, PROCEDIA COMPUT SCI, V167, P2003, DOI 10.1016/j.procs.2020.03.236
   Mohan KJ., 2016, INT J COMPUT APPL, V144, P34, DOI DOI 10.5120/IJCA2016910505
   Mohanty S. P., 2016, Frontiers in Plant Science, V7, P1419
   Nagaraju M, 2020, INT J SYST ASSUR ENG, V11, P547, DOI 10.1007/s13198-020-00972-1
   Nagasubramanian K, 2018, ARXIV
   Nagasubramanian K, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0479-8
   Nandhini S, 2021, MULTIMED TOOLS APPL, V80, P18583, DOI 10.1007/s11042-021-10599-4
   Nguyen C, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030742
   Nguyen G, 2019, ARTIF INTELL REV, V52, P77, DOI 10.1007/s10462-018-09679-z
   Nie X, 2019, IEEE ACCESS, V7, P170003, DOI 10.1109/ACCESS.2019.2954845
   Parraga-Alava J, 2019, DATA BRIEF, V25, DOI 10.1016/j.dib.2019.104414
   Picon A, 2019, COMPUT ELECTRON AGR, V161, P280, DOI 10.1016/j.compag.2018.04.002
   Polder G, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.00209
   Prajwala TM, 2018, INT CONF CONTEMP, P314
   Priyadharshini RA, 2019, NEURAL COMPUT APPL, V31, P8887, DOI 10.1007/s00521-019-04228-3
   Qiu RC, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11222658
   Ramcharan A, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.01852
   Saleem MH, 2020, PLANTS-BASEL, V9, DOI 10.3390/plants9111451
   Saleem MH, 2020, PLANTS-BASEL, V9, DOI 10.3390/plants9101319
   Saleem MH, 2019, PLANTS-BASEL, V8, DOI 10.3390/plants8110468
   Sambasivam G, 2021, EGYPT INFORM J, V22, P27, DOI 10.1016/j.eij.2020.02.007
   Sermanet P, 2014, ARXIV
   Sethy PK, 2020, PROCEDIA COMPUT SCI, V167, P516, DOI 10.1016/j.procs.2020.03.308
   Shuaibu M, 2018, COMPUT ELECTRON AGR, V148, P45, DOI 10.1016/j.compag.2017.09.038
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh RK, 2022, MULTIMED TOOLS APPL, V81, P6051, DOI 10.1007/s11042-021-11763-6
   Singh UP, 2019, IEEE ACCESS, V7, P43721, DOI 10.1109/ACCESS.2019.2907383
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Sood S, 2021, MULTIMED TOOLS APPL, V80, P27973, DOI 10.1007/s11042-021-11036-2
   Sun J, 2020, IEEE ACCESS, V8, P33679, DOI 10.1109/ACCESS.2020.2973658
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Pham TN, 2020, IEEE ACCESS, V8, P189960, DOI 10.1109/ACCESS.2020.3031914
   Thomas S, 2018, J PLANT DIS PROTECT, V125, P5, DOI 10.1007/s41348-017-0124-6
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   Vardhana M, 2018, COGN SYST RES, V50, P10, DOI 10.1016/j.cogsys.2018.03.005
   Vishnoi VK, 2022, MULTIMED TOOLS APPL, V81, P367, DOI 10.1007/s11042-021-11375-0
   Wang GQ, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/2373818
   Wu H., 2019, Plant Phenome Journal, Volume, V2, P1, DOI DOI 10.2135/TPPJ2019.03.0006
   Wu QF, 2020, IEEE ACCESS, V8, P98716, DOI 10.1109/ACCESS.2020.2997001
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120
   Xing SL, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143195
   Xu Z, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/7307252
   Yan Q, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123535
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeng QM, 2020, IEEE ACCESS, V8, P172882, DOI 10.1109/ACCESS.2020.3025196
   Zhang Kaipeng., 2016, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops CVPR Workshops, P34
   Zhang KK, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/6710865
   Zhang N, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12193188
   Zhang SW, 2019, COMPUT ELECTRON AGR, V162, P422, DOI 10.1016/j.compag.2019.03.012
   Zhang SW, 2016, NEUROCOMPUTING, V205, P341, DOI 10.1016/j.neucom.2016.04.034
   Zhang XH, 2018, IEEE ACCESS, V6, P30370, DOI 10.1109/ACCESS.2018.2844405
   Zhang X, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11131554
   Zhou H, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON VIDEO AND IMAGE PROCESSING (ICVIP 2017), P56, DOI 10.1145/3177404.3177433
NR 120
TC 14
Z9 15
U1 12
U2 66
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21415
EP 21481
DI 10.1007/s11042-022-14004-6
EA OCT 2022
PG 67
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000876660900001
DA 2024-07-18
ER

PT J
AU Lavanya, S
   Saravanakumar, NM
AF Lavanya, S.
   Saravanakumar, N. M.
TI Secured two factor authentication, graph based replication and
   encryption strategy in cloud computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph-based encryption; Replication; Encryption; Packing coloring; Jump
   graph; Web graph; Stream cipher; Key stream
ID ACCESS-CONTROL
AB In recent times, many innovative techniques are enabled in the real-time business environment and becoming more popular day by day in the cloud platform. The IT platform is expecting a whole new level of development by implementing new innovative technologies to a greater extent without employing additional infrastructure. Security is a critical concern in a shared environment in the current era, and it remains unresolved in the cloud. Data replication is also challenging to sustain performance, including data availability, reliability, scalability, bandwidth, access latency, and storage capacity constraints. Hence, data must be replicated to different nodes to achieve greater performance in the shared environment. Once the data is placed on to the backend storage, no proper encryption method is implemented when data is in motion and rest. This research proposes a new method to secure a one-time password in a two-factor authentication mechanism. The research employs, proves, and ensures strong security. The second method proposed in this research is to place the optimal number of replicas on different nodes to offer high availability. The replication using the packing coloring process is performed over multiple servers and optimizes the replica, which leads a path to space efficiency. The final method is a graph-based data encryption strategy that performs encryption on data in backend Redundant Array of Independent Disk (RAID) storage using crypto keys generated by the packing coloring process. The dynamic keystream considered in the proposed research offers better security. This research offers a novel architecture that proves strong security, improved authentication, and optimal replica placement with minimal cost.
C1 [Lavanya, S.] Sri Krishna Coll Engn & Technol, Dept Informat Technol, Kuniyamuthur, India.
   [Saravanakumar, N. M.] M Kumarasamy Coll Engn, Dept Comp Sci Engn, Karur, India.
C3 Sri Krishna College of Engineering & Technology; M.Kumarasamy College of
   Engineering
RP Lavanya, S (corresponding author), Sri Krishna Coll Engn & Technol, Dept Informat Technol, Kuniyamuthur, India.
EM lavanyamecsbit@gmail.com
CR Banerjee A, 2017, IEEE ACCESS, V5, P17678, DOI 10.1109/ACCESS.2017.2744670
   Chang XZ, 2015, INT CONF MEAS, P693, DOI 10.1109/ICMTMA.2015.172
   Chen TH, 2021, MULTIMED TOOLS APPL, V80, P1901, DOI 10.1007/s11042-020-09484-3
   Cheng HB, 2018, IEEE ACCESS, V6, P37869, DOI 10.1109/ACCESS.2018.2851599
   Chidambaram N, 2019, MULTIMED TOOLS APPL, V78, P33837, DOI 10.1007/s11042-019-08166-z
   Guo C, 2019, IEEE INTERNET THINGS, V6, P9868, DOI 10.1109/JIOT.2019.2932775
   Jung KD, 2017, MULTIMED TOOLS APPL, V76, P19983, DOI 10.1007/s11042-016-4016-8
   Li JQ, 2019, IEEE T IND INFORM, V15, P6500, DOI 10.1109/TII.2019.2931156
   Liu C, 2017, IEEE T SUST COMPUT, V2, P371, DOI 10.1109/TSUSC.2017.2704163
   Liu PT, 2020, IEEE ACCESS, V8, P16750, DOI 10.1109/ACCESS.2020.2967457
   Mishra AK, 2018, IEEE POW INDIA INT C
   Singh JP, 2015, 2015 INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES AND MANAGEMENT FOR COMPUTING, COMMUNICATION, CONTROLS, ENERGY AND MATERIALS (ICSTM), P216, DOI 10.1109/ICSTM.2015.7225417
   Su YP, 2019, IEEE ACCESS, V7, P141352, DOI 10.1109/ACCESS.2019.2943971
   Tseng YM, 2018, IEEE T CLOUD COMPUT, V6, P1041, DOI 10.1109/TCC.2016.2541138
   Wei JH, 2018, IEEE T CLOUD COMPUT, V6, P1136, DOI 10.1109/TCC.2016.2545668
   Xiong H, 2017, IEEE T DEPEND SECURE, V14, P461, DOI 10.1109/TDSC.2017.2710119
   Xu DL, 2017, IEEE ACCESS, V5, P20652, DOI 10.1109/ACCESS.2017.2754515
   Zeng P, 2018, IEEE ACCESS, V6, P70017, DOI 10.1109/ACCESS.2018.2879479
   Zhang R, 2018, IEEE T SERV COMPUT, V11, P978, DOI 10.1109/TSC.2017.2762296
NR 19
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16105
EP 16125
DI 10.1007/s11042-022-13838-4
EA OCT 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000869194800005
DA 2024-07-18
ER

PT J
AU Zhou, XZ
   Guo, YB
   Jia, LS
   Jin, Y
   Li, HL
   Xue, CQ
AF Zhou, Xiaozhou
   Guo, Yibing
   Jia, Lesong
   Jin, Yu
   Li, Helu
   Xue, Chengqi
TI A study of button size for virtual hand interaction in virtual
   environments based on clicking performance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-computer interaction; Virtual hand interaction; Ergonomics;
   Clicking; Fitts' law
ID HUMAN MOTOR SYSTEM; FITTS LAW; INFORMATION CAPACITY; GESTURE
   RECOGNITION; TOUCHABLE AREA; DESIGN; AMPLITUDE; SELECTION
AB In virtual environments (VEs), virtual hand interaction is one of the most common and natural interaction methods. To improve the usability of hand interaction, it is necessary to determine the design requirements of buttons for virtual hand clicks. In this paper, a virtual hand clicking experiment in virtual reality (VR) was conducted to test the click performance under different width and spacing conditions of controls. The experiment set three independent variables, including five width levels (1.6 degrees, 2.0 degrees, 2.4 degrees, 2.8 degrees, 3.2 degrees), six spacing levels (0.2 degrees, 0.6 degrees, 1.0 degrees, 1.4 degrees, 1.8 degrees, 2.2 degrees), and four clicking directions of the consecutive clicking buttons. According to the experimental results, under a clicking distance of 45 cm, the spacing of adjacent buttons should be more than 1.4 degrees, and the width of buttons should be more than 2.4 degrees. Based on the experimental results, the information throughput (TP) of the virtual hand clicking in VEs is between the TP of the mouse and the handheld touch screen. The button design suggestions obtained in this paper are of guiding significance to the interface design for virtual hand clicking interactions in virtual environments.
C1 [Zhou, Xiaozhou; Guo, Yibing; Jia, Lesong; Li, Helu; Xue, Chengqi] Southeast Univ, Sch Mech Engn, Nanjing, Peoples R China.
   [Jin, Yu] Zhejiang Inst Commun Co Ltd, Hangzhou, Peoples R China.
C3 Southeast University - China
RP Zhou, XZ (corresponding author), Southeast Univ, Sch Mech Engn, Nanjing, Peoples R China.
EM zxz@seu.edu.cn
OI ZHOU, XIAOZHOU/0000-0003-0370-2369
FU National Natural Science Foundation of China [71901061, 71871056];
   Department of Industrial Design at Southeast University
FX This work is supported in part by the National Natural Science
   Foundation of China (No. 71901061 and 71871056). The authors would like
   to thank the graduate students from the Department of Industrial Design
   at Southeast University for the selfless support in the experimental
   process.
CR Aloraini SM, 2019, HUM MOVEMENT SCI, V64, P366, DOI 10.1016/j.humov.2019.02.019
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Argelaguet F, 2009, IEEE COMPUT GRAPH, V29, P34, DOI 10.1109/MCG.2009.117
   Aslandere T, 2015, 2015 IEEE AEROSPACE CONFERENCE
   Borrego A, 2018, GAMES HEALTH J, V7, P151, DOI 10.1089/g4h.2017.0114
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P75, DOI 10.1162/105474601750182333
   CARD SK, 1991, ACM T INFORM SYST, V9, P99, DOI 10.1145/123078.128726
   Cha Y, 2013, INT J IND ERGONOM, V43, P350, DOI 10.1016/j.ergon.2013.05.005
   Giglioli IAC, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00959
   Clark LD, 2020, INT J HUM-COMPUT ST, V139, DOI 10.1016/j.ijhcs.2020.102413
   Cockburn A, 2019, INT J HUM-COMPUT ST, V122, P21, DOI 10.1016/j.ijhcs.2018.08.005
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   FITTS PM, 1992, J EXP PSYCHOL GEN, V121, P262, DOI 10.1037/0096-3445.121.3.262
   Guo L, 2021, IEEE T HUM-MACH SYST, V51, P300, DOI 10.1109/THMS.2021.3086003
   Hansberger JT, 2017, LECT NOTES COMPUT SC, V10280, P505, DOI 10.1007/978-3-319-57987-0_41
   Hirota M, 2018, SA'18: SIGGRAPH ASIA 2018 POSTERS, DOI 10.1145/3283289.3283335
   Hu Xu-hui, 2018, Control Theory & Applications, V35, P1707, DOI 10.7641/CTA.2018.80448
   Im Y, 2015, HUM FACTOR ERGON MAN, V25, P251, DOI 10.1002/hfm.20593
   Jost TA, 2019, J BIOMECH, V97, DOI 10.1016/j.jbiomech.2019.109379
   Jung ES, 2015, INT J IND ERGONOM, V49, P21, DOI 10.1016/j.ergon.2015.05.008
   Jung S, 2021, INT J HUM-COMPUT INT, V37, P1404, DOI 10.1080/10447318.2021.1886484
   Katzakis N, 2021, IEEE T VIS COMPUT GR, V27, P1929, DOI 10.1109/TVCG.2019.2947504
   Kim J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3143420
   Kim T, 2014, INFORM SCIENCES, V257, P264, DOI 10.1016/j.ins.2013.05.034
   Kopper R, 2010, INT J HUM-COMPUT ST, V68, P603, DOI 10.1016/j.ijhcs.2010.05.001
   Liang ZR, 2017, UNIVERSAL ACCESS INF, V16, P381, DOI 10.1007/s10209-016-0464-1
   Lin J, 2019, INT J HUM-COMPUT INT, V35, P1729, DOI 10.1080/10447318.2019.1571783
   Livingston MA, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P56, DOI 10.1109/ISMAR.2003.1240688
   Looker J., 2015, REACHING HOLOGRAMS A
   Lubos P, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P13, DOI 10.1145/2983310.2985753
   Lubos P, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P11, DOI 10.1109/3DUI.2014.6798834
   Machuca MDB, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300437
   MacKenzie CL, 1997, BEHAV BRAIN SCI, V20, P316, DOI 10.1017/S0140525X97361445
   MacKenzie IS, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1633
   Marín-Morales J, 2017, DYNA-BILBAO, V92, P34, DOI 10.6036/7963
   Mine M. R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P19, DOI 10.1145/258734.258747
   Murata A, 2001, HUM MOVEMENT SCI, V20, P791, DOI 10.1016/S0167-9457(01)00058-6
   Murthy LRD, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES COMPANION (IUI'20), P29, DOI 10.1145/3379336.3381506
   Park K, 2020, INT J IND ERGONOM, V76, DOI 10.1016/j.ergon.2020.102939
   Park YS, 2010, INT J IND ERGONOM, V40, P68, DOI 10.1016/j.ergon.2009.08.002
   Poupyrev I., 1997, VRST'97. ACM Symposium on Virtual Reality Software and Technology 1997, P21, DOI 10.1145/261135.261141
   Poupyrev I., 1996, P 9 ANN ACM S USER I, P79, DOI [DOI 10.1145/237091.237102, 10.1145/237091.237102]
   Rizzuto MA, 2019, APPL ERGON, V79, P1, DOI 10.1016/j.apergo.2019.04.001
   Sagayam KM, 2017, VIRTUAL REAL-LONDON, V21, P91, DOI 10.1007/s10055-016-0301-0
   Scott MacKenzie I., 2015, Human-Computer Interaction. Interaction Technologies. 17th International Conference, HCI International 2015. Proceedings: LNCS 9170, P238, DOI 10.1007/978-3-319-20916-6_23
   SHNEIDERMAN B, 1983, COMPUTER, V16, P57, DOI 10.1109/MC.1983.1654471
   Sidenmark L, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319815
   Soukoreff RW, 2004, INT J HUM-COMPUT ST, V61, P751, DOI 10.1016/j.ijhcs.2004.09.001
   Tao D, 2018, INT J IND ERGONOM, V64, P59, DOI 10.1016/j.ergon.2017.12.001
   Teather R. J., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P87, DOI 10.1109/3DUI.2011.5759222
   Wingrave CA, 2005, P HCI INT 2005 LAS V, ppp1
   Yang XC, 2018, IEEE T NEUR SYS REH, V26, P1199, DOI 10.1109/TNSRE.2018.2829913
   Yashas J., 2019, 2019 International Conference on Applied Machine Learning (ICAML). Proceedings, P3, DOI 10.1109/ICAML48257.2019.00009
   Yu DF, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356544
   Yu H, 2021, APPL ERGON, V97, DOI 10.1016/j.apergo.2021.103541
   Zholshiyeva LZ, 2021, HAND GESTURE RECOGNI, P1
   Zhou XH, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65863-8
NR 57
TC 2
Z9 2
U1 10
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15903
EP 15918
DI 10.1007/s11042-022-14038-w
EA OCT 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000874060500002
DA 2024-07-18
ER

PT J
AU Xiong, X
   Li, MR
   Ren, YY
   Yao, XS
   Du, YH
   Huang, QS
   Kong, XY
   He, JF
AF Xiong, Xin
   Li, Minrui
   Ren, Yuyan
   Yao, Xusheng
   Du, Yuhui
   Huang, Qingsong
   Kong, Xiangyang
   He, Jianfeng
TI A new method for mining information of gut microbiome with probabilistic
   topic models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Probabilistic topic model; Latent Dirichlet Allocation; Gut microbiome;
   Type 2 diabetes mellitus
ID METAGENOME
AB Microbiome is closely related to many major human diseases, but it is generally analyzed by the traditional statistical methods such as principal component analysis, principal coordinate analysis, etc. These methods have shortcomings and do not consider the characteristics of the microbiome data itself (i.e., the "probability distribution" of microbiome). A new method based on probabilistic topic model was proposed to mine the information of gut microbiome in this paper, taking gut microbiome of type 2 diabetes patients and healthy subjects as an example. Firstly, different weights were assigned to different microbiome according to the degree of correlation between different microbiome and subjects. Then a probabilistic topic model was employed to obtain the probabilistic distribution of gut microbiome (i.e., per-topic OTU (operational taxonomic units, OTU) distribution and per-patient topic distribution). Experimental results showed that the output topics can be used as the characteristics of gut microbiome, and can describe the differences of gut microbiome over different groups. Furthermore, in order to verify the ability of this method to characterize gut microbiome, clustering and classification operations on the distributions over topics for gut microbiome in each subject were performed, and the experimental results showed that the clustering and classification performance has been improved, and the recognition rate of three groups reached 100%. The proposed method could mine the information hidden in gut microbiome data, and the output topics could describe the characteristics of gut microbiome, which provides a new perspective for the study of gut microbiome.
C1 [Xiong, Xin; Li, Minrui; Ren, Yuyan; Yao, Xusheng; Huang, Qingsong; He, Jianfeng] Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Kunming 650500, Yunnan, Peoples R China.
   [Xiong, Xin; Huang, Qingsong] Kunming Univ Sci & Technol, Comp Technol Applicat Key Lab Yunnan Prov, Kunming 650500, Yunnan, Peoples R China.
   [He, Jianfeng] Kunming Univ Sci & Technol, Yunnan Key Lab Artificial Intelligence, Kunming 650500, Yunnan, Peoples R China.
   [Du, Yuhui; Kong, Xiangyang] Kunming Univ Sci & Technol, Fac Med, Kunming 650500, Yunnan, Peoples R China.
C3 Kunming University of Science & Technology; Kunming University of
   Science & Technology; Kunming University of Science & Technology;
   Kunming University of Science & Technology
RP He, JF (corresponding author), Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Kunming 650500, Yunnan, Peoples R China.; He, JF (corresponding author), Kunming Univ Sci & Technol, Yunnan Key Lab Artificial Intelligence, Kunming 650500, Yunnan, Peoples R China.; Kong, XY (corresponding author), Kunming Univ Sci & Technol, Fac Med, Kunming 650500, Yunnan, Peoples R China.
EM xiongxin840826@163.com; 2389020966@qq.com; 1713397685@qq.com;
   527864290@qq.com; 429819408@qq.com; 1912443688@qq.com;
   1745982615@qq.com; jfenghe@foxmail.com
RI Huang, Qingsong/G-6657-2015; ren, yuyan/T-1883-2019
FU National Natural Science Foundation of China (NSFC) [82060329, 11265007,
   81860318]; Scientific Research Fund Project of Yunnan Education
   Department of China [2020J0052]
FX This study was funded by Grant Nos. 82060329, 11265007, 81860318 from
   National Natural Science Foundation of China (NSFC), No. 2020J0052 from
   Scientific Research Fund Project of Yunnan Education Department of
   China.
CR Abe K, 2019, BMC GENOMICS, V20, DOI 10.1186/s12864-019-5476-9
   Arumugam M, 2011, NATURE, V473, P174, DOI 10.1038/nature09944
   Azpiroz F., 2015, DIABETOLOGIA, V59, P1
   Bisgin H, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-S15-S6
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Brock C, 2013, DIABETES CARE, V36, P3698, DOI 10.2337/dc13-0347
   CHARDY P, 1976, ESTUAR COAST MAR SCI, V4, P179, DOI 10.1016/0302-3524(76)90041-4
   Chen L, 2018, PEERJ, V6, DOI 10.7717/peerj.4600
   Chen X, 2012, IEEE T NANOBIOSCI, V11, P203, DOI 10.1109/TNB.2012.2212204
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Costello EK, 2012, SCIENCE, V336, P1255, DOI 10.1126/science.1224203
   Cotillard A, 2013, NATURE, V500, P585, DOI 10.1038/nature12480
   Ha C, 2019, INT J APPROX REASON, V112, P85, DOI 10.1016/j.ijar.2019.05.010
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   duVerle,DA, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-016-1175-6
   Ebert EC, 2005, DM-DIS MON, V51, P620, DOI 10.1016/j.disamonth.2005.11.002
   Falkowski PG, 2008, SCIENCE, V320, P1034, DOI 10.1126/science.1153213
   Gould Milena, 2009, Curr Gastroenterol Rep, V11, P354, DOI 10.1007/s11894-009-0054-y
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Hao Jie, 2016, CAAI Transactions on Intelligent Systems, V11, P539, DOI 10.11992/tis.201606007
   Hoffman M., 2010, ADV NEURAL INFORM PR, V23, P856
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Holmes I, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030126
   HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075
   Iverson V, 2012, SCIENCE, V335, P587, DOI 10.1126/science.1212665
   Jiang X., 2015, MATH MODEL APPL, V4, P6
   Jordan Michael Irwin, 1999, LEARNING GRAPHICAL M
   Karlsson FH, 2013, NATURE, V498, P99, DOI 10.1038/nature12198
   Laib L, 2019, SIGNAL PROCESS-IMAGE, V76, P283, DOI 10.1016/j.image.2019.05.012
   Lambeth Stacey M, 2015, J Diabetes Obes, V2, P1
   Larsen N, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0009085
   Li XianFeng Li XianFeng, 2015, Zhongguo Weishengtaxixue Zazhi / Chinese Journal of Microecology, V27, P1224
   Okui Tasuku, 2020, IPSJ Transactions on Bioinformatics, V13, P1, DOI 10.2197/ipsjtbio.13.1
   Papadimitriou C. H., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, P159, DOI 10.1145/275487.275505
   Phan Xuan-Hieu, 2008, P 17 INT C WORLD WID, P91
   Qin JJ, 2012, NATURE, V490, P55, DOI 10.1038/nature11450
   Rajpal DK, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0145499
   Rayner CK, 2001, DIABETES CARE, V24, P371, DOI 10.2337/diacare.24.2.371
   Sato J, 2014, DIABETES CARE, V37, P2343, DOI 10.2337/dc13-2817
   Sekirov I, 2009, J PHYSIOL-LONDON, V587, P4159, DOI 10.1113/jphysiol.2009.172742
   Shivashankar S, 2011, BIOINFORMATICS, V27, pI61, DOI 10.1093/bioinformatics/btr249
   Taddy M., 2012, Artificial Intelligence and Statistics, V20, P1184
   Tian DP, 2020, INT J MACH LEARN CYB, V11, P417, DOI 10.1007/s13042-019-00983-w
   Tremaroli V, 2012, NATURE, V489, P242, DOI 10.1038/nature11552
   Turney P. D., 2003, ACM Transactions on Information Systems, V21, P315, DOI 10.1145/944012.944013
   Vatanen T, 2018, NATURE, V562, P589, DOI 10.1038/s41586-018-0620-2
   Virally-Monod M, 1998, DIABETES METAB, V24, P530
   von Mering C, 2007, SCIENCE, V315, P1126, DOI 10.1126/science.1133420
   Wallach H.M., 2006, Proc. 23rd Int. Conf. Mach. Learn, P977984
   Wang Xialin, 2018, Weishengwu Xuebao, V58, P1274, DOI 10.13343/j.cnki.wsxb.20170409
   [王侠林 Wang Xialin], 2017, [中国科学. 生命科学, Scientia Sinica Vitae], V47, P1220
   Woloszynek S., 2017, bioRxiv
   Wu GD, 2011, SCIENCE, V334, P105, DOI 10.1126/science.1208344
   Xing W, 2006, SIXTH IEEE INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID, P178
   Zhang RC, 2015, BMC BIOINFORMATICS, V16, DOI 10.1186/1471-2105-16-S5-S2
   Zhao WZ, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-016-1156-9
NR 59
TC 1
Z9 1
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16081
EP 16104
DI 10.1007/s11042-022-13916-7
EA OCT 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000867602700001
OA hybrid
DA 2024-07-18
ER

PT J
AU Nie, X
   Chai, BS
   Wang, LY
   Liao, QY
   Xu, M
AF Nie, Xuan
   Chai, Bosong
   Wang, Luyao
   Liao, Qiyu
   Xu, Min
TI Learning enhanced features and inferring twice for fine-grained image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fine-grained visual categorization (FGVC); Image classification;
   Convolutional neural networks (CNN)
AB Fine-Grained Visual Categorization (FGVC) aims to distinguish between extremely similar subordinate-level categories within the same basic-level category. Existing research has proven the great importance of the discriminative features in FGVC but ignored the contributions for correct classification from other features, and the extracted features always contain more information about the obvious regions but less about subtle regions. In this paper, firstly, a novel module named forcing module is proposed to force the network to extract more diverse features for FGVC, which generates a suppression mask based on the class activation maps to suppress the most distinguishable regions, so as to force the network to extract other secondary distinguishable features as the final features. The forcing module consists of the original branch and the forcing branch. The original branch focuses on the primary discriminative regions while the forcing branch focuses on secondary discriminative regions. Secondly, in order to solve the problem that information of small-scale distinguishable features is lost seriously after multi-layer down-sampling, according to the class activation maps of the first prediction, the object is cropped and scaled as the second input. To reduce the prediction error, the first and second prediction probabilities are fused as the final prediction result. Experimental results indicate that the proposed method not only outperforms the baseline model by a large margin (3.7%, 5.9%, 3.1% respectively) on CUB-200-2011, Stanford-Cars, and FGVC-Aircraft, but also achieves state-of-the-art performance on FGVC-Aircraft.
C1 [Nie, Xuan; Chai, Bosong; Wang, Luyao] Northwestern Polytech Univ, Xian, Peoples R China.
   [Liao, Qiyu; Xu, Min] Univ Technol Sydney Ultimo, Sydney, NSW, Australia.
C3 Northwestern Polytechnical University; University of Technology Sydney
RP Xu, M (corresponding author), Univ Technol Sydney Ultimo, Sydney, NSW, Australia.
EM xnie@nwpu.edu.cn; chaibosong@mail.nwpu.edu.cn;
   sf_wly_faith@mail.nwpu.edu.cn; min.xu@uts.edu.au
OI Liao, Qiyu/0000-0002-5842-9841
FU 2020 Key research and development Plan of Shaanxi Province
   [2020ZDLSF04-02]; CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions. This work is supported by the 2020 Key research and
   development Plan of Shaanxi Province under project (no: 2020ZDLSF04-02).
CR Azulay A, 2019, J MACH LEARN RES, V20
   Berg T, 2013, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2013.128
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Chai Y, 2013, IEEE I CONF COMP VIS, P321, DOI 10.1109/ICCV.2013.47
   Chang DL, 2020, IEEE T IMAGE PROCESS, V29, P4683, DOI 10.1109/TIP.2020.2973812
   Chen Y, 2019, PROC CVPR IEEE, P5152, DOI 10.1109/CVPR.2019.00530
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding Y, 2019, IEEE I CONF COMP VIS, P6598, DOI 10.1109/ICCV.2019.00670
   Fan GF, 2021, UTIL POLICY, V73, DOI 10.1016/j.jup.2021.101294
   Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41
   Ge WF, 2019, PROC CVPR IEEE, P3029, DOI 10.1109/CVPR.2019.00315
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Hanselmann H, 2020, IEEE WINT CONF APPL, P1236, DOI [10.1109/WACV45572.2020.9093601, 10.1109/wacv45572.2020.9093601]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kayhan Osman Semih, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14262, DOI 10.1109/CVPR42600.2020.01428
   Khosla A., 2012, Novel Dataset for Fine-Grained Image Categorization
   Kong S, 2017, PROC CVPR IEEE, P7025, DOI 10.1109/CVPR.2017.743
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liu Z., 2022, ARXIV
   Ng PC, 2003, NUCLEIC ACIDS RES, V31, P3812, DOI 10.1093/nar/gkg509
   Onyema EM, 2020, INT J INNOV SCI ENG, V7, P91, DOI DOI 10.1109/TENSYMP50017.2020.9230464
   Sun GL, 2020, AAAI CONF ARTIF INTE, V34, P12047
   Sun M, 2018, LECT NOTES COMPUT SC, V11220, P834, DOI 10.1007/978-3-030-01270-0_49
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PR MACH LEARN RES, V97
   Vedaldi A., 2013, Technical report
   Wah C, 2011, CALTECH UCSD BIRDS 2
   Wang Q, 2022, IEEE T NEUR NET LEAR, V33, P1414, DOI 10.1109/TNNLS.2020.3042276
   Wang ZH, 2020, AAAI CONF ARTIF INTE, V34, P12289
   Xie LX, 2013, IEEE I CONF COMP VIS, P1641, DOI 10.1109/ICCV.2013.206
   Xiong ZT, 2021, IEEE T IMAGE PROCESS, V30, P2722, DOI 10.1109/TIP.2021.3053459
   Yang Z, 2018, LECT NOTES COMPUT SC, V11218, P438, DOI 10.1007/978-3-030-01264-9_26
   Yu CJ, 2018, LECT NOTES COMPUT SC, V11220, P595, DOI 10.1007/978-3-030-01270-0_35
   Zhang LB, 2019, IEEE I CONF COMP VIS, P8330, DOI 10.1109/ICCV.2019.00842
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhang R, 2019, PR MACH LEARN RES, V97
   Zheng HL, 2019, PROC CVPR IEEE, P5007, DOI 10.1109/CVPR.2019.00515
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
   Zhuang PQ, 2020, AAAI CONF ARTIF INTE, V34, P13130
NR 41
TC 3
Z9 3
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14799
EP 14813
DI 10.1007/s11042-022-13619-z
EA OCT 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000864966800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Feng, ZA
   Han, XF
AF Feng, Zhi-Ao
   Han, Xian-Feng
TI Guided normal filter for 3D point clouds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D point cloud; Filter; Local linear model; Feature preserving
AB Point clouds have been attracting more and more attention due to the advancement of 3D sensors. However, the raw point clouds acquired suffer inevitably from noise, which challenges their applications in 3D computer vision. In order to address this problem, we propose a novel feature-preserving filtering framework, termed Guided Normal Point Cloud Filter. First, we perform initial normal estimation using improved Principal Component Analysis algorithm. Then, a well-designed point normal filter based on locally linear model is proposed, which uses the estimated normal field as guidance. Finally, according to the adjusted normal field, we treat the point positions update problem as a least-squares issue solved by stochastic gradient decent optimizer. Quantitative and qualitative experimental results on several point cloud models show the effectiveness of our proposed algorithm, which can provide a much better trade-off between filtering performance and computational efficiency.
C1 [Feng, Zhi-Ao; Han, Xian-Feng] Southwest Univ, Coll Comp & Informat Sci, Chongqing, Peoples R China.
C3 Southwest University - China
RP Han, XF (corresponding author), Southwest Univ, Coll Comp & Informat Sci, Chongqing, Peoples R China.
EM fengzhiao@email.swu.edu.cn; xianfenghan@swu.edu.cn
RI Feng, zhiao/KFR-9141-2024; Feng, Zhiao/KFR-8871-2024; Feng,
   Zhiao/IQU-3046-2023
OI Feng, Zhiao/0000-0002-4938-9411; Han, Xianfeng/0000-0002-4869-4537
FU National Natural Science Foundation of China [62002299]; Natural Science
   Foundation of Chongqing of China [cstc2020jcyj-msxmX0126]; Fundamental
   Research Funds for the Central Universities [SWU120005]
FX This research was supported by the National Natural Science Foundation
   of China (No. 62002299), and the Natural Science Foundation of Chongqing
   of China (No. cstc2020jcyj-msxmX0126), and the Fundamental Research
   Funds for the Central Universities (No. SWU120005).
CR Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   Alexa M, 2001, IEEE VISUAL, P21, DOI 10.1109/VISUAL.2001.964489
   Avron H, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1857907.1857911
   Bai B, 2012, TECH AUTOM APPL, P38
   Belhedi A, 2012, LECT NOTES COMPUT SC, V7585, P476, DOI 10.1007/978-3-642-33885-4_48
   Boulch A, 2012, COMPUT GRAPH FORUM, V31, P1765, DOI 10.1111/j.1467-8659.2012.03181.x
   BROWN BM, 1983, J ROY STAT SOC B MET, V45, P25
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Dey T, 2004, OSUCISRC304TR17
   Fleishman S, 2003, ACM T GRAPHIC, V22, P950, DOI 10.1145/882262.882368
   Fujiwara Kent, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11731, DOI 10.1109/CVPR42600.2020.01175
   Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434
   Han XF, 2018, MULTIMED TOOLS APPL, V77, P16887, DOI 10.1007/s11042-017-5258-9
   Han XF, 2017, SIGNAL PROCESS-IMAGE, V57, P103, DOI 10.1016/j.image.2017.05.009
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang H., 2013, ACM Trans. Graph., V32, P1
   Huang HY, 2013, ANAL CHIM ACTA, V779, P96, DOI 10.1016/j.aca.2013.03.071
   Huang H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618522
   Ito K, 2000, IEEE T AUTOMAT CONTR, V45, P910, DOI 10.1109/9.855552
   Jones TR, 2004, IEEE COMPUT GRAPH, V24, P53, DOI 10.1109/MCG.2004.14
   Jones TR, 2003, ACM T GRAPHIC, V22, P943, DOI 10.1145/882262.882367
   Lee KW, 2005, INT C COMP AID DES C, P275
   Levin D., 1998, Mathematics of Computation, V67, P1517, DOI 10.1090/S0025-5718-98-00974-0
   Levin D, 2004, MATH VISUAL, P37
   Liao B, 2013, COMPUT AIDED DESIGN, V45, P861, DOI 10.1016/j.cad.2013.02.003
   Lin YQ, 2020, PROC CVPR IEEE, P4292, DOI 10.1109/CVPR42600.2020.00435
   Lipman Y, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276405
   Liu Z, 2020, COMPUT AIDED DESIGN, V127, DOI 10.1016/j.cad.2020.102857
   Lu DN, 2020, COMPUT AIDED DESIGN, V125, DOI 10.1016/j.cad.2020.102860
   Lu XQ, 2022, IEEE T VIS COMPUT GR, V28, P1835, DOI 10.1109/TVCG.2020.3026785
   Lu XQ, 2018, IEEE T VIS COMPUT GR, V24, P2315, DOI 10.1109/TVCG.2017.2725948
   Miropolsky A, 2004, RECONSTRUCTION 3D GE
   Moorfield B, 2015, LECT NOTES COMPUT SC, V9257, P394, DOI 10.1007/978-3-319-23117-4_34
   Nasab SE, 2014, 2014 7th International Symposium on Telecommunications (IST), P289, DOI 10.1109/ISTEL.2014.7000716
   Öztireli AC, 2009, COMPUT GRAPH FORUM, V28, P493, DOI 10.1111/j.1467-8659.2009.01388.x
   Preiner R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601172
   Qiao Pei-yu, 2012, Chinese Journal of Liquid Crystals and Displays, V27, P708, DOI 10.3788/YJYXS20122705.0708
   Rakotosaona MJ, 2020, COMPUT GRAPH FORUM, V39, P185, DOI 10.1111/cgf.13753
   Rosli NAIM, 2014, AIP CONF PROC, V1605, P149, DOI 10.1063/1.4887580
   Schall O, 2008, COMPUT AIDED DESIGN, V40, P701, DOI 10.1016/j.cad.2008.01.011
   Sharma S, 2013, INT J ELECT COMMUN E
   Shi Z., 2019, ELECTRO OPTIC TECHNO, P57
   SMALL CG, 1990, INT STAT REV, V58, P263, DOI 10.2307/1403809
   Sun XF, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P37, DOI 10.1109/SMI.2008.4547945
   Sun XF, 2007, IEEE T VIS COMPUT GR, V13, P925, DOI 10.1109/TVCG.2007.1065
   Sun YJ, 2015, COMPUT AIDED GEOM D, V35-36, P2, DOI 10.1016/j.cagd.2015.03.011
   TAGLIASACCHI A, 2009, ACM SIGGRAPH 2009 PA, P1, DOI DOI 10.1145/1576246.1531377
   Tatsumi T., 2016, PROC MECH ENG C JPN, V2016, P507, DOI [10.1299/jsmemecj.2016.S1170507, DOI 10.1299/JSMEMECJ.2016.S1170507]
   Tomasi C., 1998, P IEEE INT C COMP VI
   Wand M, 2008, COMPUT GRAPH-UK, V32, P204, DOI 10.1016/j.cag.2008.01.010
   Wang J, 2013, COMPUT GRAPH FORUM, V32, P207, DOI 10.1111/cgf.12187
   Xu WK, 2015, KSII T INTERNET INF, V9, P2585, DOI 10.3837/tiis.2015.07.0014
   Ye M, 2011, IEEE I CONF COMP VIS, P731, DOI 10.1109/ICCV.2011.6126310
   Zhang JZ, 2020, PROC CVPR IEEE, P4533, DOI 10.1109/CVPR42600.2020.00459
   Zhang YQ, 2013, IET IMAGE PROCESS, V7, P270, DOI 10.1049/iet-ipr.2012.0351
NR 55
TC 1
Z9 1
U1 7
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13797
EP 13810
DI 10.1007/s11042-022-13751-w
EA OCT 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000864205500001
DA 2024-07-18
ER

PT J
AU Lanjewar, MG
   Parab, JS
   Shaikh, AY
AF Lanjewar, Madhusudan G.
   Parab, Jivan S.
   Shaikh, Arman Yusuf
TI Development of framework by combining CNN with KNN to detect Alzheimer's
   disease using MRI images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CNN-KNN; VGG16; MobileNetV2; ResNet50; Stratified K-fold
ID CONVOLUTIONAL NEURAL-NETWORK; STRUCTURAL MRI; CLASSIFICATION; DIAGNOSIS;
   PREDICTION; ALGORITHMS; DEMENTIA
AB Alzheimer's disease (AD) is an irremediable, irrecoverable brain illness without proper treatment. Therefore, AD recognition is essential for precluding and dominating its advancement. The conventional method considers the patient history, MRI, and empirical tests to detect AD. This method is effective, but it lacks accuracy. The primary objective is to create an efficient framework for timely AD identification from MRI images. This work combines a Convolutional Neural Network (CNN) with the K-nearest neighbor (KNN) to detect AD from 6400 MRI images. The dataset consists of four types of AD MRI images such as Moderate Demented (MOD), Mild Demented (MID), Very Mild Demented (VMD), and Non-Demented (ND). The dataset was split into training (80%) and validation (20%) sets. The CNN was utilized to extract the informative features automatically from the MRI dataset images, and these extracted features are used to train and validate the KNN model. The CNN-KNN framework is accessed utilising the Receiver Operating Characteristic (ROC) curve, stratified K-fold, Cohen's Matthews Correlation Coefficient (MCC) and Kappa Coefficient (CKC). This method achieved average 99.58% accuracy, 99.63% precision, 99.31% recall, 99.43% F1-score, 99.31% MCC, and 0.9931 CKC. Furthermore, three deep CNNs (DCNNs), ResNet50, VGG16, and MobileNetV2, were employed to detect AD and compare their performance with CNN-KNN. The proposed CNN-KNN method's performance has significantly improved compared to the DCNN and literature.
C1 [Lanjewar, Madhusudan G.; Parab, Jivan S.; Shaikh, Arman Yusuf] Goa Univ, Sch Phys & Appl Sci, Taleigao Plateau, Goa, India.
C3 Goa University
RP Lanjewar, MG (corresponding author), Goa Univ, Sch Phys & Appl Sci, Taleigao Plateau, Goa, India.
EM madhusudan@unigoa.ac.in; jsparab@unigoa.ac.in; shaikharmanx@gmail.com
OI Lanjewar, Madhusudan/0000-0002-9670-3020
CR Al-Shoukry S, 2020, IEEE ACCESS, V8, P77131, DOI 10.1109/ACCESS.2020.2989396
   Alzheimer's Assoc, 2018, ALZHEIMERS DEMENT, V14, P367, DOI 10.1016/j.jalz.2018.02.001
   [Anonymous], UNDERSTANDING DEEP C
   [Anonymous], KNN ALGORITHM FINDIN
   [Anonymous], ALZHEIMERS DATASET 4
   Arafa DA, 2022, MULTIMED TOOLS APPL, V81, P23735, DOI 10.1007/s11042-022-11925-0
   Arco JE, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115549
   Asraf Amanullah, 2020, SN Comput Sci, V1, P363, DOI 10.1007/s42979-020-00383-w
   Ayon SI, 2022, IETE J RES, V68, P2488, DOI 10.1080/03772063.2020.1713916
   Baik R, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719826048
   Pulido MLB, 2020, EXPERT SYST APPL, V150, DOI 10.1016/j.eswa.2020.113213
   Bi XL, 2020, NEUROCOMPUTING, V392, P296, DOI 10.1016/j.neucom.2018.11.111
   Bron EE, 2015, NEUROIMAGE, V111, P562, DOI 10.1016/j.neuroimage.2015.01.048
   Feng JW, 2021, NEUROCOMPUTING, V421, P260
   Gao S., 2022, International Journal of Cognitive Computing in Engineering, V3, P1, DOI DOI 10.1016/J.IJCCE.2021.12.002
   Goenka N, 2022, BIOMED SIGNAL PROCES, V74, DOI 10.1016/j.bspc.2022.103500
   Grandini M., 2020, ARXIV, DOI DOI 10.48550/ARXIV.2008.05756
   Gunawardena KANNP, 2017, I C MECH MACH VIS PR, P173
   Haque M E., 2018, Proceedings of 2018 21st International Conference of Computer and Information Technology (ICCIT'18), P21, DOI [DOI 10.1109/ICCITECHN.2018.8631957, 10.1109/IC4ME2.2018.8465658, DOI 10.1109/IC4ME2.2018.8465658]
   Hasan MK, 2016, 2016 5TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS AND VISION (ICIEV), P574, DOI 10.1109/ICIEV.2016.7760068
   Helaly HA, 2022, COGN COMPUT, V14, P1711, DOI 10.1007/s12559-021-09946-2
   Islam Ayon S., 2019, Int J Inf Eng Electronic Business, V11, P21, DOI DOI 10.5815/IJIEEB.2019.02.03
   Islam J, 2017, LECT NOTES ARTIF INT, V10654, P213, DOI 10.1007/978-3-319-70772-3_20
   Islam M., 2020, DIAGNOSIS COVID 19 X
   Islam MM, 2021, IEEE ACCESS, V9, P30551, DOI 10.1109/ACCESS.2021.3058537
   Islam Md Milon, 2020, SN Comput Sci, V1, P274, DOI 10.1007/s42979-020-00300-1
   Islam MM, 2017, IEEE REG 10 HUMANIT, P226, DOI 10.1109/R10-HTC.2017.8288944
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Jain R, 2019, COGN SYST RES, V57, P147, DOI 10.1016/j.cogsys.2018.12.015
   Jie B, 2018, MED IMAGE ANAL, V47, P81, DOI 10.1016/j.media.2018.03.013
   Khvostikov A, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1809.03972
   Kong ZK, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103565
   Kruthika K. R., 2019, Informatics in Medicine Unlocked, V14, P34, DOI 10.1016/j.imu.2018.12.003
   Lanjewar MG, 2022, MULTIMED TOOLS APPL, V81, P10313, DOI 10.1007/s11042-022-12200-y
   Lanjewar MG, 2022, MULTIMED TOOLS APPL, V81, P16537, DOI 10.1007/s11042-022-12392-3
   Lanjewar MG, 2022, Artificial Intelligence Applications for Health Care
   Lin WM, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00777
   Liu JX, 2021, COMPUT METH PROG BIO, V203, DOI 10.1016/j.cmpb.2021.106032
   Liu L, 2020, SIMUL MODEL PRACT TH, V99, DOI 10.1016/j.simpat.2019.102023
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   MobileNetV2, GOOGLE AI BLOG
   Mueller Susanne G, 2005, Alzheimers Dement, V1, P55, DOI 10.1016/j.jalz.2005.06.003
   Muhammad L J, 2020, SN Comput Sci, V1, P206, DOI 10.1007/s42979-020-00216-w
   Nawaz A, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2101.02876
   Noor Manan Binth Taj, 2020, Brain Inform, V7, P11, DOI 10.1186/s40708-020-00112-2
   Nozadi SH, 2018, INT J BIOMED IMAGING, V2018, DOI 10.1155/2018/1247430
   Odusami M, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11061071
   Pan D, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00259
   Parmar H, 2020, J MED IMAGING, V7, DOI 10.1117/1.JMI.7.5.056001
   Poloni KM, 2021, NEUROCOMPUTING, V419, P126, DOI 10.1016/j.neucom.2020.07.102
   Poloni KM, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116622
   Prince M, 2013, ALZHEIMERS DEMENT, V9, P63, DOI 10.1016/j.jalz.2012.11.007
   Qiu SR, 2020, BRAIN, V143, P1920, DOI 10.1093/brain/awaa137
   Raees P. C. Muhammed, 2021, Journal of Physics: Conference Series, V1921, DOI 10.1088/1742-6596/1921/1/012024
   Rahman Mohammad Marufur, 2021, SN Comput Sci, V2, P384, DOI 10.1007/s42979-021-00774-7
   Rallabandi V. P. Subramanyam, 2020, Informatics in Medicine Unlocked, V18, P295, DOI 10.1016/j.imu.2020.100305
   Saha Prottoy, 2021, Inform Med Unlocked, V22, P100505, DOI 10.1016/j.imu.2020.100505
   Sarraf S, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1607.06583
   Scheltens P, 2016, LANCET, V388, P505, DOI 10.1016/S0140-6736(15)01124-1
   Spasov SE, 2018, IEEE ENG MED BIO, P1271, DOI 10.1109/EMBC.2018.8512468
   Thakur R, 2020, Medium
   Vaithinathan K, 2019, J NEUROSCI METH, V318, P84, DOI 10.1016/j.jneumeth.2019.01.011
   Vemuri P, 2012, ALZHEIMERS RES THER, V4, DOI 10.1186/alzrt100
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang SH, 2018, J MED SYST, V42, DOI [10.1007/s10916-017-0845-x, 10.1007/s10916-018-0932-7]
NR 65
TC 12
Z9 12
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12699
EP 12717
DI 10.1007/s11042-022-13935-4
EA SEP 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000859866600010
DA 2024-07-18
ER

PT J
AU Singh, A
   Kukreja, V
   Kumar, M
AF Singh, Amitoj
   Kukreja, Vinay
   Kumar, Munish
TI An empirical study to design an effective agile knowledge management
   framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Knowledge management; Knowledge sharing; Agile software development;
   Extreme programming; SCRUM
ID ORGANIZATIONAL SIZE; SOFTWARE-DEVELOPMENT; SUCCESS FACTORS; SMES
AB Despite the profusion of research about knowledge management within larger organizations, fewer studies tried to analyze knowledge management in small and medium enterprises. The study contributes to research by providing a more nuanced classification of knowledge management approaches and guides managers about the types of knowledge management approaches that should be adopted based on the size, geographical dispersion, and task nature of the organization. A purposive sample of 34 companies was selected for this study along with a survey that focused on the objective of investigating awareness and implementing strategies of knowledge management. The various phases and processes of knowledge management were accounted for. Organizations were bifurcated on the criteria like the core area of the company, the size of the company, the type of company, etc. Knowledge management implementation was judged through each dimension. Different statistical tests were carried out to test a set hypothesis. Having established that wide variation in overall adoption of knowledge management practices exists across the software engineering organizations, the different characteristics associated with knowledge management adoption were tested: organization size in terms of employee strength, the domain of the software engineering, team distribution, and type of organization. To a surprise, most of the organizational characteristics are not found in the significantly associated with knowledge management adoption except knowledge management adoption level in full and partial agile organizations and the relationship between the organization KM level and the number of software developers in organization for only product development companies is found significant. Opposite to the claims of many researchers, this study does not find any significant difference between knowledge management adoptions between distributed and co-located agile teams.
C1 [Singh, Amitoj] Jagat Guru Nanak Dev Punjab State Open Univ, Patiala, Punjab, India.
   [Kukreja, Vinay] Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, India.
C3 Chitkara University, Punjab
RP Kukreja, V (corresponding author), Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
EM amitoj.pb@gmail.com; onlyvinaykukreja@gmail.com; munishcse@gmail.com
RI Kumar, Munish/P-7756-2018; Kukreja, Vinay/AAT-7893-2021
OI Kumar, Munish/0000-0003-0115-1620; Kukreja, Vinay/0000-0002-9760-0824
CR Amritesh, 2014, KNOWL ENG REV, V29, P496, DOI 10.1017/S0269888914000198
   [Anonymous], 2004, 37 ANN HAW INT C SYS
   APO, 2010, KNOWLEDGE MANAGEMENT
   Beecham S, 2013, 2013 IEEE 8TH INTERNATIONAL CONFERENCE ON GLOBAL SOFTWARE ENGINEERING (ICGSE 2013), P41, DOI 10.1109/ICGSE.2013.14
   Bjornson FO, 2008, INFORM SOFTWARE TECH, V50, P1055, DOI 10.1016/j.infsof.2008.03.006
   Cabral ARY, 2014, J INF KNOWL MANAG, V13, DOI 10.1142/S0219649214500105
   Cabral AY, 2009, LECT NOTES BUS INF P, V24, P627
   Chau T, 2004, LECT NOTES COMPUT SC, V3096, P98
   Chaudhuri SW, 2011, INT P ECON DEV RES, V12, P251
   Cloke G, 2007, AGILE 2007, Proceedings, P240, DOI 10.1109/AGILE.2007.30
   Cockburn A., 2001, EXTREME PROGRAMMING, P223, DOI DOI 10.1108/00012530210448235
   Connelly C. E., 2003, Leadership Organization Development Journal, V24, P294, DOI [DOI 10.1108/01437730310485815/FULL/PDF, 10.1108/01437730310485815, DOI 10.1108/01437730310485815]
   Dikert K, 2016, J SYST SOFTWARE, V119, P87, DOI 10.1016/j.jss.2016.06.013
   Durst S, 2012, J KNOWL MANAG, V16, P879, DOI 10.1108/13673271211276173
   Esper TL, 2010, J ACAD MARKET SCI, V38, P5, DOI 10.1007/s11747-009-0135-3
   Genovese A, 2013, INT J PROD ECON, V144, P20, DOI 10.1016/j.ijpe.2012.12.019
   Grant RM, 1996, ORGAN SCI, V7, P375, DOI 10.1287/orsc.7.4.375
   Hazzan O, 2003, 16TH CONFERENCE ON SOFTWARE ENGINEERING EDUCATION AND TRAINING, PROCEEDINGS, P176, DOI 10.1109/CSEE.2003.1191375
   Hung YH, 2011, DECIS SUPPORT SYST, V51, P270, DOI 10.1016/j.dss.2010.11.021
   Jun Xu, 2007, Journal of Organizational and End User Computing, V19, P57, DOI 10.4018/joeuc.2007100104
   Kaisti M, 2013, EURASIP J EMBED SYST, DOI 10.1186/1687-3963-2013-15
   KOGUT B, 1992, ORGAN SCI, V3, P383, DOI 10.1287/orsc.3.3.383
   KOSKELA J., 2003, Software Configuration Management in Agile Methods
   Kroll J, 2016, PROCEEDINGS OF THE 8TH INTERNATIONAL JOINT CONFERENCE ON KNOWLEDGE DISCOVERY, KNOWLEDGE ENGINEERING AND KNOWLEDGE MANAGEMENT, VOL 3 (KMIS), P156, DOI 10.5220/0006046001560164
   Kruger C, 2013, S AFR J INFORM MANAG, V15, DOI 10.4102/sajim.v15i1.526
   Kukreja V., 2021, INDERSCIENCE, V14, P2021
   Lindsjorn Y, 2016, J SYST SOFTWARE, V122, P274, DOI 10.1016/j.jss.2016.09.028
   Marra M, 2012, EXPERT SYST APPL, V39, P6103, DOI 10.1016/j.eswa.2011.11.035
   Merisalo-Rantanen H, 2005, J DATABASE MANAGE, V16, P41, DOI 10.4018/jdm.2005100103
   Moffett S, 2006, TOTAL QUAL MANAG BUS, V17, P221, DOI 10.1080/14783360500450780
   Zenun MMN, 2007, COMPLEX SYSTEMS CONCURRENT ENGINEERING: COLLABORATION, TECHNOLOGY INNOVATION AND SUSTAINABILITY, P717, DOI 10.1007/978-1-84628-976-7_79
   NONAKA I, 1991, HARVARD BUS REV, V69, P96
   Paasivaara M, 2014, INT CONF GLOBAL SOFT, P16, DOI 10.1109/ICGSE.2014.22
   Paterek P., 2016, PM WORLD J, V5, P1
   Pillania RK, 2008, MANAGE DECIS, V46, P1452, DOI 10.1108/00251740810919986
   Razzak MA, 2015, INT CONF GLOBAL SOFT, P81, DOI 10.1109/ICGSE.2015.22
   Samuel KE, 2011, J STRATEGIC INF SYST, V20, P283, DOI 10.1016/j.jsis.2010.11.001
   Serenko A, 2007, J INTELLECT CAP, V8, P610, DOI 10.1108/14691930710830783
   Sfetsos P, 2006, EMPIR SOFTW ENG, V11, P269, DOI 10.1007/s10664-006-6404-6
   Singh Amitoj, 2015, International Journal of Agile Systems and Management, V8, P23, DOI 10.1504/IJASM.2015.068607
   Singh A., 2012, PROC INT J COMPUT AP, V50, P33
   Singh A, 2014, INNOV SYST SOFTW ENG, V10, P297, DOI 10.1007/s11334-014-0237-z
   Sison R, 2007, 14TH ASIA-PACIFIC SOFTWARE ENGINEERING CONFERENCE, PROCEEDINGS, P462, DOI 10.1109/ASPEC.2007.35
   Srivastava A, 2020, INT J SYST ASSUR ENG, V11, P247, DOI 10.1007/s13198-020-00966-z
   Tsoy M, 2021, INFORM SYST MANAGE, V38, P324, DOI 10.1080/10580530.2020.1818899
   Turk D, 2005, J DATABASE MANAGE, V16, P62, DOI 10.4018/jdm.2005100104
   VANHANEN J, 2007, 40 ANN HAW INT C SYS, pB274, DOI DOI 10.1109/HICSS.2007.218
   Wong KY, 2005, IND MANAGE DATA SYST, V105, P261, DOI 10.1108/02635570510590101
   Zykov SV, 2020, PUBLISH BOOK SERIES
NR 49
TC 5
Z9 5
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12191
EP 12209
DI 10.1007/s11042-022-13871-3
EA SEP 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000855612200023
DA 2024-07-18
ER

PT J
AU Shahsavari, A
   Khatibi, T
   Ranjbari, S
AF Shahsavari, Ali
   Khatibi, Toktam
   Ranjbari, Sima
TI Skin lesion detection using an ensemble of deep models: SLDED
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer-assisted; Medical image; Skin cancer detection; Ensemble
   convolutional neural networks; Skin image segmentation
ID CONVOLUTIONAL NEURAL-NETWORK; LEVEL CLASSIFICATION; IMAGE
   CLASSIFICATION; MELANOMA; CANCER; DERMATOLOGISTS; DIAGNOSIS; DERMOSCOPY;
   SEGMENTATION; RECOGNITION
AB Skin cancer is a major public health concern and the most common type of cancer among the other types. Reliable automated classification systems will provide clinicians with great help to detect malignant skin lesions as quickly as possible. Recently, deep learning-based approaches have efficiently outperformed other conventional machine learning models in medical image classification tasks. In this study, a novel computer-aided approach is designed for Skin Lesion Detection by creating an Ensemble of Deep (SLDED) models. More specifically, we initially performed a modified faster R-CNN using VGGNet feature extractor on ISIC archive database, including 4668 skin lesion images for lesion localization, and we obtained a mean average precision (mAP) of 0.96. Then we fused four different convolutional neural networks (CNNs) into one framework to obtain high classification accuracy. Moreover, a weighted majority voting method is proposed to aggregate the final decision of each individual voter. We evaluate our experimental classification results on 934 and 200 images from ISIC and PH2 test data. We achieved the average accuracy of 97.1% and 96%, Area under receiver operating characteristics curve (AUC) of 98.6% and 98.1%, precision of 87.1% and 90.2%, recall of 86.7% and 85.4% for ISIC and PH2 test data, respectively. As another objective evaluation, we have tested our proposed procedure on official test set of 2016 and 2017 International Symposium on Biomedical Imaging (ISIB) challenges. It outperforms the results of other proposed frameworks that have been published in those challenges. The results demonstrate that our proposed SLDED method is a meaningful approach to classify four different skin lesions with a high accuracy despite the lack of access to expensive computational equipment.
C1 [Shahsavari, Ali; Khatibi, Toktam] Tarbiat Modares Univ, Sch Ind & Syst Engn, Tehran, Iran.
   [Ranjbari, Sima] Wayne State Univ, Dept Comp Sci, Detroit, MI 48201 USA.
C3 Tarbiat Modares University; Wayne State University
RP Khatibi, T (corresponding author), Tarbiat Modares Univ, Sch Ind & Syst Engn, Tehran, Iran.
EM toktamk.khatibi@modares.ac.ir
RI Khatibi, Toktam/HIR-8049-2022
OI Khatibi, Toktam/0000-0001-5824-9798
CR Abbes W, 2017, PROCEDIA COMPUT SCI, V112, P2096, DOI 10.1016/j.procs.2017.08.226
   Agarwal M, SKIN LESION ANAL MEL
   [Anonymous], 2017, SIIM 2017 SCI PROGR
   Argenziano G, 2006, J CLIN ONCOL, V24, P1877, DOI 10.1200/JCO.2005.05.0864
   Argenziano G, 2001, LANCET ONCOL, V2, P443, DOI 10.1016/S1470-2045(00)00422-8
   Attia M, 2017, I S BIOMED IMAGING, P292, DOI 10.1109/ISBI.2017.7950522
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Barata C, 2017, PATTERN RECOGN, V69, P270, DOI 10.1016/j.patcog.2017.04.023
   Baumann LS, 2018, J AM ACAD DERMATOL, V79, P869, DOI 10.1016/j.jaad.2018.05.044
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bi L, 2017, I S BIOMED IMAGING, P561, DOI 10.1109/ISBI.2017.7950583
   Brinker TJ, 2019, EUR J CANCER, V119, P11, DOI 10.1016/j.ejca.2019.05.023
   Brinker TJ, 2019, EUR J CANCER, V111, P148, DOI 10.1016/j.ejca.2019.02.005
   Brinker TJ, 2019, EUR J CANCER, V111, P30, DOI 10.1016/j.ejca.2018.12.016
   Carli P, 2000, J AM ACAD DERMATOL, V43, P459, DOI 10.1067/mjd.2000.106518
   Celebi ME, 2007, COMPUT MED IMAG GRAP, V31, P362, DOI 10.1016/j.compmedimag.2007.01.003
   center, 2019, ESTIMATED NEW CASES
   Chang WY, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0076212
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Collaboration I.S.I, 2020, ISIC ARCHIVE
   CONN AR, 1991, SIAM J NUMER ANAL, V28, P545, DOI 10.1137/0728030
   Dascalu A, 2019, EBIOMEDICINE, V43, P107, DOI 10.1016/j.ebiom.2019.04.055
   Diaz I. G., 2017, ARXIV
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Isasi AG, 2011, COMPUT BIOL MED, V41, P742, DOI 10.1016/j.compbiomed.2011.06.010
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Grichnik J M., 2008, Fitzpatrick's Dermatology in General Medicine, V7th, P1099
   Haenssle H A, 2019, Ann Oncol, V30, p130e, DOI 10.1093/annonc/mdy520
   Hahnloser RHR, 2000, NATURE, V405, P947, DOI 10.1038/35016072
   Harangi B, 2018, J BIOMED INFORM, V86, P25, DOI 10.1016/j.jbi.2018.08.006
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He K, 2017, IEEE INT WORKSH MULT
   Hekler A, 2019, EUR J CANCER, V120, P114, DOI 10.1016/j.ejca.2019.07.019
   Hekler A, 2019, EUR J CANCER, V115, P79, DOI 10.1016/j.ejca.2019.04.021
   Jain S, 2015, PROCEDIA COMPUT SCI, V48, P735, DOI 10.1016/j.procs.2015.04.209
   Jaleel JA, 2013, PROCEEDINGS OF 2013 INTERNATIONAL CONFERENCE ON CIRCUITS, POWER AND COMPUTING TECHNOLOGIES (ICCPCT 2013), P1137, DOI 10.1109/ICCPCT.2013.6528879
   Kallenberg M, 2016, IEEE T MED IMAGING, V35, P1322, DOI 10.1109/TMI.2016.2532122
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Levine AB, 2019, TRENDS CANCER, V5, P157, DOI 10.1016/j.trecan.2019.02.002
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P49, DOI 10.1109/MIC.2020.2971447
   Li YT, 2019, IEEE INTERNET THINGS, V6, P628, DOI 10.1109/JIOT.2018.2851185
   Lopez AR, 2017, 2017 13TH IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (BIOMED), P49, DOI 10.2316/P.2017.852-053
   Majtner T, 2016, INT CONF IMAG PROC, DOI 10.1109/IPTA.2016.7821017
   Mar VJ, 2017, LANCET, V389, P1962, DOI 10.1016/S0140-6736(17)31285-0
   Marchetti MA, 2018, J AM ACAD DERMATOL, V78, P270, DOI 10.1016/j.jaad.2017.08.016
   Maron RC, 2019, EUR J CANCER, V119, P57, DOI 10.1016/j.ejca.2019.06.013
   Matsunaga K., 2017, ARXIV
   Megahed M, 2002, LANCET, V359, P1921, DOI 10.1016/S0140-6736(02)08741-X
   Mendonca T., 2015, Dermoscopy image analysis, DOI 10.1201/b19107-14
   Menegola A., 2017, ARXIV
   Mirzaalian-Dastjerdi H, 2018, BILDVERARBEITUNG MED, P29
   MOSS RH, 1989, COMPUT MED IMAG GRAP, V13, P31, DOI 10.1016/0895-6111(89)90076-1
   Mueller SA, 2019, J INVEST DERMATOL, V139, P1449, DOI 10.1016/j.jid.2019.01.008
   Nida N, 2019, INT J MED INFORM, V124, P37, DOI 10.1016/j.ijmedinf.2019.01.005
   Okur E, 2018, ENG APPL ARTIF INTEL, V73, P50, DOI 10.1016/j.engappai.2018.04.028
   Renzi M, 2019, DERMATOL CLIN, V37, P279, DOI 10.1016/j.det.2019.02.003
   Sanderson M, 2010, NAT LANG ENG, V16, P100, DOI 10.1017/S1351324909005129
   Sarigül M, 2019, NEURAL NETWORKS, V116, P279, DOI 10.1016/j.neunet.2019.04.025
   Schaefer G, 2014, MEMET COMPUT, V6, P233, DOI 10.1007/s12293-014-0144-8
   Soudani A, 2019, EXPERT SYST APPL, V118, P400, DOI 10.1016/j.eswa.2018.10.029
   Sreekantaswamy S, 2019, CLIN DERMATOL, V37, P373, DOI 10.1016/j.clindermatol.2019.06.004
   Stoecker WV, 2005, SKIN RES TECHNOL, V11, P179, DOI 10.1111/j.1600-0846.2005.00117.x
   Stoecker WV, 1992, DIGITAL IMAGING DERM
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vasconcelos CN, 2020, PATTERN RECOGN LETT, V139, P95, DOI 10.1016/j.patrec.2017.11.005
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Zhang HZ, 2018, IEEE INT CON MULTI
NR 70
TC 11
Z9 11
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10575
EP 10594
DI 10.1007/s11042-022-13666-6
EA SEP 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000852464000003
DA 2024-07-18
ER

PT J
AU Hanumantharaju, R
   Shreenath, KN
   Sowmya, BJ
   Srinivasa, KG
AF Hanumantharaju, R.
   Shreenath, K. N.
   Sowmya, B. J.
   Srinivasa, K. G.
TI Fog based smart healthcare: a machine learning paradigms for IoT sector
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Cloud computing; Fog computing; Machine learning;
   Random Forest; Naive Bayes; Smart healthcare
ID ARCHITECTURE; SYSTEM
AB Smart healthcare serves as an innovative way for integrating sensors, Internet of things (IoT) and large scale analytics. A better patient monitoring reduces the costs of medical services to great extent, which opens up new frontiers or strategies for the sustainability of mankind in terms of data services, remote diagnosing/monitoring or the new kinds of treatments. However, Cloud computing is an on-demand service that provides storage, network, power to do intensive computing, intensive sharing of resources, but users should also deal with the privacy-related issues to the data stored in the cloud through data breaches. The current health care systems implemented on the cloud poses threat to the privacy of the data of the patients, since data breaches cost millions to billions of dollars to the health care institutions every year this problem can be taken care with the Fog computing (FC) based health care systems, where the fog technology offers more additional advantages like low latency, resource management, less power consumption, etc. The proposed system demonstrates the use of IoT, computing platforms (cloud/Fog) with Machine Learning (ML) algorithms. Fog layer extracts the attributes and filters the data collected about heart diseases, whereas cloud layer estimates the level of disease detection using the classifier algorithms Random forest and Naive Bayes. In terms of accuracy, precision, recall, and f-measure, the results suggest that Random Forest outperforms Naive Bayes.
C1 [Hanumantharaju, R.; Shreenath, K. N.] Siddaganga Inst Technol, Tumkur, India.
   [Hanumantharaju, R.; Shreenath, K. N.] Visvesvaraya Technol Univ, Belagavi, India.
   [Sowmya, B. J.] Visvesvaraya Technol Univ, MS Ramaiah Inst Technol, Belagavi, India.
   [Srinivasa, K. G.] Int Inst Informat Technol, Naya Raipur, Chhattisgarh, India.
C3 Siddaganga Institute of Technology; Visvesvaraya Technological
   University; Visvesvaraya Technological University; Ramaiah Institute of
   Technology
RP Hanumantharaju, R (corresponding author), Siddaganga Inst Technol, Tumkur, India.; Hanumantharaju, R (corresponding author), Visvesvaraya Technol Univ, Belagavi, India.
EM rajurjs@gmail.com; shreenathk_n@sit.ac.in; sowmyabj@msrit.edu;
   kgsrinivasa@gmail.com
CR Adel A, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00372-z
   Al-Joboury IM, 2017, LECT NOTES COMPUT SC, V10542, P368, DOI 10.1007/978-3-319-68179-5_32
   Catarinucci L, 2015, IEEE INTERNET THINGS, V2, P515, DOI 10.1109/JIOT.2015.2417684
   Cech HL, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON FOG COMPUTING (ICFC 2019), P31, DOI 10.1109/ICFC.2019.00013
   Darshan KR, 2015, 2015 INTERNATIONAL CONFERENCE ON EMERGING RESEARCH IN ELECTRONICS, COMPUTER SCIENCE AND TECHNOLOGY (ICERECT), P132, DOI 10.1109/ERECT.2015.7499001
   Dhar SK, 2014, PROC INT CONF EMERG, P152, DOI 10.1109/EAIT.2014.50
   Dziak D, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7060596
   Ganesan M, 2019, 2019 IEEE International Conference on System, Computation, Automation and Networking (ICSCAN), P1, DOI [10.1109/ICSCAN.2019.8878850, DOI 10.1109/ICSCAN.2019.8878850]
   Hang L, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19102228
   Jagadeeswari V, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0049-x
   de Macedo DDJ, 2019, CONCURRENT ENG-RES A, V27, P189, DOI 10.1177/1063293X19844548
   Kodali RK, 2015, PROCEEDINGS OF THE 2015 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), P411, DOI 10.1109/RAICS.2015.7488451
   Kumar Y., 2019, International Journal Of Scientific and Technology Research, V8, P674
   Latha C. Beulah Christalin, 2019, Informatics in Medicine Unlocked, V16, DOI 10.1016/j.imu.2019.100203
   Machado JD, 2020, INT J GRID UTIL COMP, V11, P486
   Mani N, 2020, PROCEDIA COMPUT SCI, V167, P850, DOI 10.1016/j.procs.2020.03.424
   Muthanna A, 2019, J SENS ACTUAT NETW, V8, DOI 10.3390/jsan8010015
   Rahmani AM, 2018, FUTURE GENER COMP SY, V78, P641, DOI 10.1016/j.future.2017.02.014
   Rotariu C, 2012, FED CONF COMPUT SCI, P193
   Satpathy S, 2020, J SUPERCOMPUT, V76, pS849, DOI 10.1007/s11227-019-03013-2
   Tuli S, 2020, FUTURE GENER COMP SY, V104, P187, DOI 10.1016/j.future.2019.10.043
NR 21
TC 3
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37299
EP 37318
DI 10.1007/s11042-022-13530-7
EA AUG 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000844934900003
DA 2024-07-18
ER

PT J
AU Zhou, B
   Liu, ZA
   Ji, JY
   Wang, XY
AF Zhou, Bin
   Liu, Ze'an
   Ji, Jiayu
   Wang, Xuanyin
TI Objective quality assessment of retargeted images based on RBF neural
   network with structural distortion and content change
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retargeting quality assessment; RBF neural network; Feature
   matching; Visual saliency
ID VISUAL-ATTENTION; COLOR; MODEL
AB Objective quality assessment of retargeted images aims to find the best retargeting method for showing an image on different display terminals. This paper uses a Radial Basis Function (RBF) neural network to assess the quality of retargeted images. First, invariant feature points in the original image and their counterparts in the retargeted image are matched in a spatial order-preserving manner. Feature points centered local patches are extracted from original and retargeted images. Then, multi-scale local structural similarity and multi-scale local HSV color histograms difference of matched local patches are measured. A saliency map is employed as the weights of the local patches for evaluating the structural distortion and content change. Finally, the overall assessment of the retargeted image quality can be obtained by the RBF neural network. Experimental results on a benchmark test show the high consistency between the proposed objective assessment and subjective evaluations, and our method is closer to the practical application due to its simplicity compared with those complex ones.
C1 [Zhou, Bin; Liu, Ze'an; Ji, Jiayu; Wang, Xuanyin] Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Wang, XY (corresponding author), Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
EM xywang@zju.edu.cn
RI wang, xuan/JBJ-6948-2023; wang, xuan/GXF-3679-2022
FU National Natural Science Foundation of China [52075483]
FX This study was funded by National Natural Science Foundation of China
   (Grant No. 52075483).
CR [Anonymous], 1991, ARTIFICIAL NEURAL NE
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Broomhead D. S., 1988, Complex Systems, V2, P321
   Castillo S., 2011, ACM SIGGRAPH S APPLP, P7
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   Dong WM, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618471
   Fang YM, 2014, IEEE J EM SEL TOP C, V4, P95, DOI 10.1109/JETCAS.2014.2298919
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Girod Bernd, 1993, P207
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Harel J., 2006, ADV NEURAL INF PROCE
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hsu CC, 2014, IEEE J-STSP, V8, P377, DOI 10.1109/JSTSP.2014.2311884
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Karni Z, 2009, COMPUT GRAPH FORUM, V28, P1257, DOI 10.1111/j.1467-8659.2009.01503.x
   Kasutani E, 2001, IEEE IMAGE PROC, P674, DOI 10.1109/ICIP.2001.959135
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   Krähenbühl P, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1616452.1618472, 10.1145/1618452.1618472]
   Liang Y, 2017, IEEE T VIS COMPUT GR, V23, P1099, DOI 10.1109/TVCG.2016.2517641
   Liu AM, 2015, SIGNAL PROCESS-IMAGE, V39, P444, DOI 10.1016/j.image.2015.08.001
   Liu C, 2008, LECT NOTES COMPUT SC, V5304, P28, DOI 10.1007/978-3-540-88690-7_3
   Liu YJ, 2011, COMPUT GRAPH FORUM, V30, P583, DOI 10.1111/j.1467-8659.2011.01881.x
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma L, 2012, IEEE J-STSP, V6, P626, DOI 10.1109/JSTSP.2012.2211996
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Novak C. L., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P599, DOI 10.1109/CVPR.1992.223129
   Oliva A, 2003, IEEE IMAGE PROC, P253, DOI 10.1109/icip.2003.1246946
   Pele O, 2009, IEEE I CONF COMP VIS, P460, DOI 10.1109/ICCV.2009.5459199
   Pritch Y, 2009, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2009.5459159
   Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Simakov D., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587842
   Wang J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330512
   Wang Z, 2005, INT CONF ACOUST SPEE, P573
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wolf L, 2007, IEEE I CONF COMP VIS, P1418
   Yan B, 2017, SIGNAL PROCESS-IMAGE, V56, P12, DOI 10.1016/j.image.2017.04.005
NR 41
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7463
EP 7477
DI 10.1007/s11042-022-13662-w
EA AUG 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000843430000001
DA 2024-07-18
ER

PT J
AU Venkatesan, B
   Ragupathy, US
   Natarajan, I
AF Venkatesan, B.
   Ragupathy, U. S.
   Natarajan, Indhu
TI A review on multimodal medical image fusion towards future research
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Image fusion; Imaging modalities; Medical imaging; Spatial domain;
   Transform domain
ID CENTRAL FORCE OPTIMIZATION; SHEARLET TRANSFORM; QUALITY ASSESSMENT;
   ALGORITHM; DIAGNOSIS; NETWORKS; SCHEME
AB Image fusion is a technique used to merge two or more source images into a single image that incorporates more details than the originals and still offering an accurate depiction about the captured information. Resultant fused images are more accurate and provide comprehensive information for both the human and machine vision perception for further processing of the image. Image fusion provides better performance in the areas like pattern recognition, image processing, computer vision, machine learning and artificial intelligence. In the recent years image fusion has moved out of the laboratories and used in the real time applications. This paper provides the insight of various techniques for image fusion like primitive fusion (Simple averaging, Maxima and Minima, etc.), Discrete Wavelet Transform (DWT) based fusion, Principal Component Analysis (PCA) based fusion, Curvelet transform based fusion etc. On-going through various literatures, it is found that image fusion in spatial domain provides high resolution images, although the fusion algorithms are dependent on the nature of image and also depends on the application for which the image is to be fused. Hence, spectral domain fusion and hybrid fusion techniques are introduced and it is proven to be better than the spatial domain fusion. Comparison of all the techniques along with recent approaches are done to find the best approach towards future research to provide new direction to the researchers in medical sector.
C1 [Venkatesan, B.; Ragupathy, U. S.] Kongu Engn Coll, Dept Elect & Instrumentat Engn, Erode, Tamil Nadu, India.
   [Natarajan, Indhu] Sri Shakthi Inst Engn & Technol, Dept Elect & Elect Engn, Coimbatore, Tamil Nadu, India.
C3 Kongu Engineering College
RP Venkatesan, B (corresponding author), Kongu Engn Coll, Dept Elect & Instrumentat Engn, Erode, Tamil Nadu, India.
EM sivavenkat88@gmail.com; ragupathy.us@gmail.com;
   indhunatarajan31@gmail.com
OI B, Venkatesan/0000-0001-5523-972X
CR Akbarpour T, 2019, INT J WAVELETS MULTI, V17, DOI 10.1142/S0219691319500231
   Aktar MN, 2018, COMP M BIO BIO E-IV, V6, P584, DOI 10.1080/21681163.2017.1304244
   Algarni AD, 2020, WIRELESS PERS COMMUN, V111, P1033, DOI 10.1007/s11277-019-06899-6
   Amin-Naji M, 2019, INFORM FUSION, V51, P201, DOI 10.1016/j.inffus.2019.02.003
   Anandhi D, 2018, COMPUT ELECTR ENG, V65, P139, DOI 10.1016/j.compeleceng.2017.04.002
   Anilkumar B., 2020, INT J EMERG TECHNOL, V11, P83
   Arathy Menon NP, 2015, 2015 INT C INN INF E
   Arif M, 2020, SOFT COMPUT, V24, P1815, DOI 10.1007/s00500-019-04011-5
   Auer T, 2019, IN VIVO, V33, P203, DOI 10.21873/invivo.11460
   Aymaz S, 2020, MULTIMED TOOLS APPL, V79, P13311, DOI 10.1007/s11042-020-08670-7
   Aymaz S, 2019, INFORM FUSION, V45, P113, DOI 10.1016/j.inffus.2018.01.015
   Barba J L., 2019, ECCOMAS THEMATIC C C
   Benjamin JR, 2018, INT J COMPUT ASS RAD, V13, P229, DOI 10.1007/s11548-017-1692-4
   Bhatnagar G, 2015, NEUROCOMPUTING, V157, P143, DOI 10.1016/j.neucom.2015.01.025
   Bhatnagar G, 2013, IEEE T MULTIMEDIA, V15, P1014, DOI 10.1109/TMM.2013.2244870
   Bhavana V, 2015, PROCEDIA COMPUT SCI, V70, P625, DOI 10.1016/j.procs.2015.10.057
   Chavan S, 2017, ADV INTEL SYS RES, V137, P627
   Chavan SS, 2017, COMPUT BIOL MED, V81, P64, DOI 10.1016/j.compbiomed.2016.12.006
   Daneshvar S, 2010, INFORM FUSION, V11, P114, DOI 10.1016/j.inffus.2009.05.003
   Ding ZS, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102697
   Dogra A, 2017, PATTERN RECOGN LETT, V94, P189, DOI 10.1016/j.patrec.2017.03.002
   Du CB, 2018, OPTIK, V157, P1003, DOI 10.1016/j.ijleo.2017.11.162
   Du J, 2020, INT J IMAG SYST TECH, V30, P271, DOI 10.1002/ima.22367
   El-Hoseny HM, 2019, MULTIMED TOOLS APPL, V78, P26373, DOI 10.1007/s11042-019-7552-1
   El-Hoseny HM, 2018, INFRARED PHYS TECHN, V94, P223, DOI 10.1016/j.infrared.2018.09.003
   Fu J, 2021, OPTIK, V237, DOI 10.1016/j.ijleo.2021.166726
   Ganasala P, 2016, J DIGIT IMAGING, V29, P73, DOI 10.1007/s10278-015-9806-4
   Gomathi P.S., 2016, Circuits Syst., V7, P1598, DOI [10.4236/cs.2016.78139, DOI 10.4236/CS.2016.78139]
   Gupta D, 2018, BIOCYBERN BIOMED ENG, V38, P262, DOI 10.1016/j.bbe.2017.12.005
   Haghighat MBA, 2011, COMPUT ELECTR ENG, V37, P744, DOI 10.1016/j.compeleceng.2011.07.012
   Hermessi H, 2018, NEURAL COMPUT APPL, V30, P2029, DOI 10.1007/s00521-018-3441-1
   Hou RC, 2019, MED BIOL ENG COMPUT, V57, P887, DOI 10.1007/s11517-018-1935-8
   Huang B, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/8279342
   Huang CX, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00210
   Huang H, 2017, J ELECTR COMPUT ENG, V2017, DOI 10.1155/2017/6807473
   Jagalingam P, 2015, AQUAT PR, V4, P133, DOI 10.1016/j.aqpro.2015.02.019
   Jin X, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16091376
   Jin X, 2018, SIGNAL PROCESS, V153, P379, DOI 10.1016/j.sigpro.2018.08.002
   Kalita DJ, 2022, SOFT COMPUT, V26, P2277, DOI 10.1007/s00500-021-06498-3
   Kaur M, 2020, CLUSTER COMPUT, V23, P1439, DOI 10.1007/s10586-019-02999-x
   Li CX, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10031171
   Li Wei, 2023, Personal and Ubiquitous Computing, P2019, DOI 10.1007/s00779-019-01317-x
   Li Y., 2021, Int J Cogn Comput Eng, V2, P21, DOI DOI 10.1016/J.IJCCE.2020.12.004
   Liu XB, 2017, NEUROCOMPUTING, V235, P131, DOI 10.1016/j.neucom.2017.01.006
   Liu Y, 2017, 2017 20TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1070
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Manchanda M, 2018, J VIS COMMUN IMAGE R, V51, P76, DOI 10.1016/j.jvcir.2017.12.011
   Meng LY, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.04.013
   Miao Y, 2021, IET IMAGE PROCESS
   Naidu VPS, 2010, DEFENCE SCI J, V60, P48, DOI 10.14429/dsj.60.105
   Naveenadevi R, 2017, RES J PHARM BIOL CHE, V8, P310
   Nikolakopoulos K, 2015, EUR J REMOTE SENS, V48, P141, DOI 10.5721/EuJRS20154809
   Ozyurt F, 2019, MEASUREMENT, V147, DOI 10.1016/j.measurement.2019.07.058
   Parvathy VS, 2020, HEALTH CARE MANAG SC, V23, P661, DOI 10.1007/s10729-019-09492-2
   Patil HV, 2018, SADHANA-ACAD P ENG S, V43, DOI 10.1007/s12046-018-0796-z
   Patil U, 2011, 2011 INT C IM INF PR, P1
   Polinati S, 2019, 2019 INT C COMM SIGN
   Prakash C., 2012, Proceedings of the 2012 International Conference on Recent Advances in Computing and Software Systems (RACSS), P54, DOI 10.1109/RACSS.2012.6212697
   Prakash O, 2019, OPTIK, V182, P995, DOI 10.1016/j.ijleo.2018.12.028
   Rajalingam B, 2018, Int. J. ChemTech Res., V11, P160
   Rani K., 2013, International journal of Emerging Technology and advanced Engineering, V3, P288
   Ravi P, 2018, MATER TODAY-PROC, V5, P1936, DOI 10.1016/j.matpr.2017.11.296
   Sandhya S, 2019, L N COMPUT VIS BIOME, V31, P61, DOI 10.1007/978-3-030-04061-1_7
   Shabu SJ., 2013, INT J ENG ADV TECHNO, V3, P457
   Shahdoosti HR, 2018, MULTIMED TOOLS APPL, V77, P22649, DOI 10.1007/s11042-017-5067-1
   Shariaty F, 2022, COMPUT BIOL MED, V140, DOI 10.1016/j.compbiomed.2021.105086
   Singh R., 2015, INT J INNOVATIVE RES, V1, P259
   Singh Rajiv, 2013, ScientificWorldJournal, V2013, P521034, DOI 10.1155/2013/521034
   Singh S., 2014, INT J ENG COMPUTER S, V3, P7350
   Song ZY, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/8407019
   Sui YB, 2019, ONCOL LETT, V18, P43, DOI 10.3892/ol.2019.10286
   Tan L, 2019, COMPUT MATH METHOD M, V2019, DOI 10.1155/2019/3503267
   Tang H, 2018, INFORM SCIENCES, V433, P125, DOI 10.1016/j.ins.2017.12.043
   Tang L, 2017, INT J IMAG SYST TECH, V27, P57, DOI 10.1002/ima.22210
   Tannaz A, 2020, MULTIDIM SYST SIGN P, V31, P269, DOI 10.1007/s11045-019-00662-7
   Udomhunsakul S, 2011, LECT NOTES ENG COMP, P1619
   Verma A, 2022, ARXIV
   Vijayarajan R, 2015, AEU-INT J ELECTRON C, V69, P896, DOI 10.1016/j.aeue.2015.02.007
   Wang LF, 2019, MULTIMED TOOLS APPL, V78, P929, DOI 10.1007/s11042-018-5907-7
   Wang ZY, 2019, MULTIMED TOOLS APPL, V78, P34483, DOI 10.1007/s11042-019-08070-6
   Xia KJ, 2019, CLUSTER COMPUT, V22, P1515, DOI 10.1007/s10586-018-2026-1
   Xu XJ, 2016, BIOMED SIGNAL PROCES, V27, P103, DOI 10.1016/j.bspc.2016.02.008
   Yakhdani MF, 2010, INT ARCH PHOTOGRAMM, V38, P204
   Yang Y, 2016, IEEE SENS J, V16, P3735, DOI 10.1109/JSEN.2016.2533864
   Yin M, 2017, NEUROCOMPUTING, V226, P182, DOI 10.1016/j.neucom.2016.11.051
   Zhou H, 2012, INT J DIGIT CONTENT, V6
   Zhu ZQ, 2018, INFORM SCIENCES, V432, P516, DOI 10.1016/j.ins.2017.09.010
   Zuo YJ, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051127
NR 89
TC 4
Z9 4
U1 6
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7361
EP 7382
DI 10.1007/s11042-022-13691-5
EA AUG 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000842724300002
DA 2024-07-18
ER

PT J
AU Stella, E
   Agosti, I
   Di Blas, N
   Finazzi, M
   Lanzi, PL
   Loiacono, D
AF Stella, Erica
   Agosti, Isabella
   Di Blas, Nicoletta
   Finazzi, Marco
   Lanzi, Pier Luca
   Loiacono, Daniele
TI A virtual reality classroom to teach and explore crystal solid state
   structures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; Education; Virtual classroom; Solid state physics;
   Crystallography
ID OF-THE-ART; MOLECULAR-DYNAMICS; VISUALIZATION; PERFORMANCE;
   ENVIRONMENTS; FILE
AB We present an educational application of virtual reality that we created to help students gain an in-depth understanding of the internal structure of crystals and related key concepts. Teachers can use it to give lectures to small groups (10-15) of students in a shared virtual environment, both remotely (with teacher and students in different locations) and locally (while sharing the same physical space). Lectures can be recorded, stored in an online repository, and shared with students who can either review a recorded lecture in the same virtual environment or can use the application for self-studying by exploring a large collection of available crystal structures. We validated our application with human subjects receiving positive feedback.
C1 [Stella, Erica; Agosti, Isabella; Di Blas, Nicoletta; Finazzi, Marco; Lanzi, Pier Luca; Loiacono, Daniele] Politecn Milan, Milan, Italy.
C3 Polytechnic University of Milan
RP Lanzi, PL (corresponding author), Politecn Milan, Milan, Italy.
EM erica.stella@polimi.it; isabella.agosti@mail.polimi.it;
   nicoletta.diblas@polimi.it; marco.finazzi@polimi.it;
   pierluca.lanzi@polimi.it; daniele.loiacono@polimi.it
RI Loiacono, Daniele/AAB-9829-2019
OI Loiacono, Daniele/0000-0002-5355-0634; Lanzi, Pier
   Luca/0000-0002-1933-7717
FU Politecnico di Milano within the CRUI-CARE Agreement
FX Open access funding provided by Politecnico di Milano within the
   CRUI-CARE Agreement.
CR [Anonymous], 2018, 2018 10 INT C VIRT W, DOI DOI 10.1109/VS-GAMES.2018.8493423
   Baheti A, 2008, SYMPOSIUM ON HAPTICS INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS 2008, PROCEEDINGS, P479
   Ballabio A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-53949-x
   Bekele MK, 2018, ACM J COMPUT CULT HE, V11, DOI 10.1145/3145534
   Bennie SJ, 2019, J CHEM EDUC, V96, P2488, DOI 10.1021/acs.jchemed.9b00181
   Berman H, 2003, NAT STRUCT BIOL, V10, P980, DOI 10.1038/nsb1203-980
   Bernstein HJ, 2016, J APPL CRYSTALLOGR, V49, P277, DOI 10.1107/S1600576715021871
   Borchardt-Ott W., 2011, CRYSTALLOGRAPHY INTR
   CARO V, 2018, 2018 IEEE FRONT ED C, P1, DOI DOI 10.1109/FIE.2018.8659267
   Chittaro L, 2015, IEEE T VIS COMPUT GR, V21, P529, DOI 10.1109/TVCG.2015.2391853
   Clifford RMS, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P181, DOI [10.1109/VR.2019.8797889, 10.1109/vr.2019.8797889]
   Coan HA, 2020, J TEACH LEARN, V14, P71, DOI 10.22329/jtl.v14i1.6234
   Dai RX, 2020, J CHEM EDUC, V97, P3647, DOI 10.1021/acs.jchemed.0c00469
   Daniel F, 2019, CRYSTAL VIEWER LAB N
   Deeks HM, 2020, J CHEM INF MODEL, V60, P5803, DOI 10.1021/acs.jcim.0c01030
   Drouhard M, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2453, DOI 10.1109/BigData.2015.7364040
   Ferey N., 2008, Proceedings of the 2008 ACM Symposium on Virtual Reality Software and Technology, P91, DOI DOI 10.1145/1450579.1450598
   Francoeur E, 2002, ENDEAVOUR, V26, P127, DOI 10.1016/S0160-9327(02)01468-0
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   García-Hernández RJ, 2019, COMPUT PHYS COMMUN, V237, P230, DOI 10.1016/j.cpc.2018.11.013
   García-Hernández RJ, 2017, LECT NOTES COMPUT SC, V10324, P309, DOI 10.1007/978-3-319-60922-5_25
   Greenwald ScottW., 2017, 12th International Conference on Computer Supported Collaborative Learning (CSCL), P1
   Gruber C, 2020, J CHEM EDUC, V97, P2020, DOI 10.1021/acs.jchemed.9b01207
   Hall S., 2006, International Tables for Crystallography, DOI 10.1107/97809553602060000107
   HALL SR, 1991, ACTA CRYSTALLOGR A, V47, P655, DOI 10.1107/S010876739101067X
   Hite R., 2018, REV VIRTUAL REALITY
   Humphrey W, 1996, J MOL GRAPH MODEL, V14, P33, DOI 10.1016/0263-7855(96)00018-5
   Juárez-Jiménez J, 2020, J CHEM INF MODEL, V60, P6344, DOI 10.1021/acs.jcim.0c00221
   Kingsley LJ, 2019, J MOL GRAPH MODEL, V89, P234, DOI 10.1016/j.jmgm.2019.03.010
   Kozlíková B, 2017, COMPUT GRAPH FORUM, V36, P178, DOI 10.1111/cgf.13072
   Le Muzic Mathieu, 2015, Eurographics Workshop Vis Comput Biomed, V2015, P61, DOI 10.2312/vcbm.20151209
   Lee J, 2012, J BIOMED BIOTECHNOL, DOI 10.1155/2012/546521
   LEWIS JR, 1995, INT J HUM-COMPUT INT, V7, P57, DOI 10.1080/10447319509526110
   Likert R., 1932, Arch. Psychol., V22, P44, DOI DOI 10.4135/9781412961288.N454
   Lourdeaux D, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P241, DOI 10.1145/3308532.3329418
   Lugrin J-L., 2016, FRONTIERS ICT, V3, P26, DOI [10.3389/fict.2016.00026, DOI 10.3389/FICT.2016.00026]
   Lv ZH, 2021, IEEE T IND INFORM, V17, P1496, DOI 10.1109/TII.2020.2994747
   Lv ZH, 2020, NEURAL COMPUT APPL, V32, P9593, DOI 10.1007/s00521-019-04472-7
   Lv ZH, 2017, NEUROCOMPUTING, V254, P71, DOI 10.1016/j.neucom.2016.07.078
   Manca D, 2013, ADV ENG SOFTW, V55, P1, DOI 10.1016/j.advengsoft.2012.09.002
   Mansoor B., 2018, 125 ASEE ANN C EXP
   Mantovani F, 2003, EMERG COMMUNICAT, V5, P167
   Müller C, 2018, J INTEGR BIOINFORMAT, V15, DOI 10.1515/jib-2018-0005
   Norrby M, 2015, J CHEM INF MODEL, V55, P2475, DOI 10.1021/acs.jcim.5b00544
   O'Connor M, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aat2731
   OConnor MB, 2019, ARXIV
   OpenRasMol, 2009, US
   Pettersen EF, 2004, J COMPUT CHEM, V25, P1605, DOI 10.1002/jcc.20084
   Pettersen EF, 2021, PROTEIN SCI, V30, P70, DOI 10.1002/pro.3943
   Pietikainen O, 2018, VRCHEM MOL MODELING
   Quishpe-Armas JA, 2015, PROCEDIA COMPUT SCI, V75, P413, DOI 10.1016/j.procs.2015.12.265
   Radianti Jaziar, 2020, Computers & Education, V147, P18, DOI 10.1016/j.compedu.2019.103778
   Ragan ED, 2010, PRESENCE-TELEOP VIRT, V19, P527, DOI 10.1162/pres_a_00016
   Rashid F, 2017, USE VR TECHNOLOGY PA
   REWIND, 2017, US
   Salomoni P, 2017, J MULTIMODAL USER IN, V11, P173, DOI 10.1007/s12193-016-0236-5
   Salvadori A, 2016, INT J QUANTUM CHEM, V116, P1731, DOI 10.1002/qua.25207
   SAYLE RA, 1995, TRENDS BIOCHEM SCI, V20, P374, DOI 10.1016/S0968-0004(00)89080-5
   Schijven MP, 2005, SURG ENDOSC, V19, P1220, DOI 10.1007/s00464-004-2240-1
   Schrodinger LLC, 2015, AXPYMOL MOL GRAPH PL
   Scott E, 2017, IEEE T LEARN TECHNOL, V10, P262, DOI 10.1109/TLT.2016.2609910
   Sharma S, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI), VOL 2, P187, DOI 10.1109/CSCI.2014.116
   Shibata Takashi, 2019, Proceedings of the 20th Congress of the International Ergonomics Association (IEA 2018). Volume X: Auditory and Vocal Ergonomics, Visual Ergonomics, Psychophysiology in Ergonomics, Ergonomics in Advanced Imaging. Advances in Intelligent Systems and Computing (AISC 827), P423, DOI 10.1007/978-3-319-96059-3_48
   Stinson C, 2014, IEEE T VIS COMPUT GR, V20, P606, DOI 10.1109/TVCG.2014.23
   Ström P, 2006, SURG ENDOSC, V20, P1383, DOI 10.1007/s00464-005-0545-3
   Swamy KLN, 2018, IEEE CONF TECHNOL ED, P53, DOI 10.1109/T4E.2018.00018
   Swamy KLN, 2018, IEEE INT CONF ADV LE, P252, DOI 10.1109/ICALT.2018.00065
   Tarng W, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030580
   Taupiac JD, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P190, DOI [10.1109/VR.2019.8797854, 10.1109/vr.2019.8797854]
   Vichitvejpaisal P, 2016, INT JOINT CONF COMP, P422
   Wu JX, 2016, PROCEEDINGS OF THE 2016 SAI COMPUTING CONFERENCE (SAI), P1257, DOI 10.1109/SAI.2016.7556140
   Yan ZH, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155058
   Yun H., 2019, P SOC INF TECHN TEAC, P2112
   Zakharov P. V., 2020, Journal of Physics: Conference Series, V1515, DOI 10.1088/1742-6596/1515/2/022001
   Zhao JY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P155, DOI [10.1109/VR.2019.8797867, 10.1109/vr.2019.8797867]
   Zheng M, 2017, J MOL GRAPH MODEL, V73, P18, DOI 10.1016/j.jmgm.2017.01.019
NR 76
TC 3
Z9 3
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6993
EP 7016
DI 10.1007/s11042-022-13410-0
EA AUG 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000839516900003
PM 35971458
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Melinda, L
   Bhagvati, C
AF Melinda, Laiphangbam
   Bhagvati, Chakravarthy
TI Parameter free approach for segmenting complex manhattan layouts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Document layout analysis; Bounding boxes; Height histogram; Gaussian
   mixture model; Expectation maximization; Nearest neighbor
ID PAGE SEGMENTATION; SYSTEM
AB This paper presents a two-stage parameter-free technique for the physical layout analysis of a document. In the first stage, Gaussian Mixture Model (GMM) with Expectation-Maximization (EM) is applied followed by recursive merging to obtain the best number of components from the height-frequency data. Such components are classified into running text, titles, and graphical elements. Using a Next Nearest Neighbor analysis, running-text and title text are grouped into blocks in the initial layout. At the second stage, the graphical elements are further divided into text boxes, light-colored text on a dark background, line separators, and graphics that give the final layout. Our proposed method achieved an accuracy of 86.30% and 75.14% in recognizing text and non-text elements from our generated dataset, which contains over 700 documents. Results on the ICDAR dataset show accuracy comparable to some of the best and most popular algorithms such as MHS (winner of the ICDAR-RDCL2015 competition) and PRImA's Aletheia. The strength of our algorithm is that it is entirely free of manually tuned parameters.
C1 [Melinda, Laiphangbam; Bhagvati, Chakravarthy] Univ Hyderabad, Sch Comp & Informat Sci, Hyderabad, India.
C3 University of Hyderabad
RP Melinda, L (corresponding author), Univ Hyderabad, Sch Comp & Informat Sci, Hyderabad, India.
EM mel.laiphangbam20@gmail.com; chakcs@uohyd.ernet.in
CR Alginahi Y, 2005, J CIRCUIT SYST COMP, V14, P109, DOI 10.1142/S0218126605002192
   Antonacopoulos A, 2015, PROC INT CONF DOC, P1151, DOI 10.1109/ICDAR.2015.7333941
   Antonacopoulos A., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1370, DOI 10.1109/ICDAR.2009.275
   Baird H. S., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P820, DOI 10.1109/ICPR.1990.118223
   Binmakhashen GM, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3355610
   Oliveria DAB, 2017, IEEE INT CONF COMP V, P1173, DOI 10.1109/ICCVW.2017.142
   Chaudhuri AR, 2003, LANGUAGE ENGINEERING CONFERENCE, PROCEEDINGS, P24, DOI 10.1109/LEC.2002.1182287
   Chen K, 2013, PROC INT CONF DOC, P958, DOI 10.1109/ICDAR.2013.194
   Clausner C, 2011, PROC INT CONF DOC, P48, DOI 10.1109/ICDAR.2011.19
   Dasigi P, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P305, DOI 10.1109/ICVGIP.2008.96
   Esposito F., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P466, DOI 10.1109/ICDAR.1995.599037
   FAN KC, 1994, PATTERN RECOGN LETT, V15, P1201, DOI 10.1016/0167-8655(94)90110-4
   Fei Liu, 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P1176, DOI 10.1109/ICDAR.2001.953970
   Felhi M, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P6, DOI 10.1109/DAS.2014.68
   Ferilli Stefano, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P231, DOI 10.1109/ICDAR.2009.37
   Forczmanski P., 2019, International Conference on Computer Recognition Systems, P141
   Grana C, 2016, MULTIMED TOOLS APPL, V75, P3879, DOI 10.1007/s11042-014-2360-0
   Hadjar K, 2001, PROC INT CONF DOC, P1186, DOI 10.1109/ICDAR.2001.953972
   Ittner D. J., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P336, DOI 10.1109/ICDAR.1993.395720
   Kamola G, 2015, PATTERN ANAL APPL, V18, P651, DOI 10.1007/s10044-014-0412-8
   Kise K, 1998, COMPUT VIS IMAGE UND, V70, P370, DOI 10.1006/cviu.1998.0684
   Kise K., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P788, DOI 10.1109/ICPR.1996.547276
   KRISHNAMOORTHY M, 1993, IEEE T PATTERN ANAL, V15, P737, DOI 10.1109/34.221173
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Li XH, 2020, LECT NOTES COMPUT SC, V12116, P231, DOI 10.1007/978-3-030-57058-3_17
   Liang J, 1996, THIRD IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV '96, PROCEEDINGS, P278
   Liu DR, 2002, 2002 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-4, PROCEEDINGS, P1711, DOI 10.1109/ICMLC.2002.1175327
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Melinda L, 2017, PROC INT CONF DOC, P747, DOI 10.1109/ICDAR.2017.127
   Mitchell PE, 2001, PROC INT CONF DOC, P1181, DOI 10.1109/ICDAR.2001.953971
   Mitchell PE, 2000, INT C PATT RECOG, P458, DOI 10.1109/ICPR.2000.905375
   NAGY G, 1992, COMPUTER, V25, P10, DOI 10.1109/2.144436
   OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677
   Pati PB, 2004, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON INTELLIGENT SENSING AND INFORMATION PROCESSING, P123
   PAVLIDIS T, 1992, CVGIP-GRAPH MODEL IM, V54, P484, DOI 10.1016/1049-9652(92)90068-9
   Qiao YL, 2006, ISSCAA 2006: 1ST INTERNATIONAL SYMPOSIUM ON SYSTEMS AND CONTROL IN AEROSPACE AND ASTRONAUTICS, VOLS 1AND 2, P451
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Shih FY, 1996, IEEE T SYST MAN CY B, V26, P797, DOI 10.1109/3477.537322
   Singh V, 2014, INT CONF COMP COMMUN
   Smith Raymond W., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P241, DOI 10.1109/ICDAR.2009.257
   Smith R, 2007, PROC INT CONF DOC, P629, DOI 10.1109/icdar.2007.4376991
   Sun HM, 2005, PROC INT CONF DOC, P116
   Taylor SL, 1994, INTEGRATION NATURAL, P163
   Tran TA, 2015, P 9 INT C UB INF MAN, P78
   Tran TA, 2016, INT J DOC ANAL RECOG, V19, P191, DOI 10.1007/s10032-016-0265-3
   Le VP, 2015, PROC INT CONF DOC, P1096, DOI 10.1109/ICDAR.2015.7333930
   WAHL FM, 1983, COMPUT VISION GRAPH, V23, P218, DOI 10.1016/0734-189X(83)90114-7
   WONG KY, 1982, IBM J RES DEV, V26, P647, DOI 10.1147/rd.266.0647
NR 51
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6581
EP 6603
DI 10.1007/s11042-022-13400-2
EA AUG 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000837590100008
DA 2024-07-18
ER

PT J
AU Banskota, N
   Alsadoon, A
   Prasad, PWC
   Dawoud, A
   Rashid, TA
   Alsadoon, OH
AF Banskota, Nitesh
   Alsadoon, Abeer
   Prasad, P. W. C.
   Dawoud, Ahmed
   Rashid, Tarik A.
   Alsadoon, Omar Hisham
TI A novel enhanced convolution neural network with extreme learning
   machine: facial emotional recognition in psychology practices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution neural network; Stochastic gradient descent; Log-likelihood
   estimator; Optical flow estimation; Extreme learning machine;
   Cross-entropy loss
ID EXPRESSION RECOGNITION; DEEP
AB Facial emotional recognition is one of the essential tools used by recognition psychology to diagnose patients. Face and facial emotional recognition are areas where machine learning is excelling. Facial Emotion Recognition in an unconstrained environment is an open challenge for digital image processing due to different environments, such as lighting conditions, pose variation, yaw motion, and occlusions. Deep learning approaches have shown significant improvements in image recognition. However, accuracy and time still need improvements. This research aims to improve facial emotion recognition accuracy during the training session and reduce processing time using a modified Convolution Neural Network Enhanced with Extreme Learning Machine (CNNEELM). The proposed system consists of an optical flow estimation technique that detects the motion of change in facial expression and extracts peak images from video frames for image pre-processing. The system entails (CNNEELM) improving the accuracy in image registration during the training session. Furthermore, the system recognizes six facial emotions - happy, sad, disgust, fear, surprise, and neutral with the proposed CNNEELM model. The study shows that the overall facial emotion recognition accuracy is improved by 2% than the state of art solutions with a modified Stochastic Gradient Descent (SGD) technique. With the Extreme Learning Machine (ELM) classifier, the processing time is brought down to 65 ms from 113 ms, which can smoothly classify each frame from a video clip at 20fps. With the pre-trained InceptionV3 model, the proposed CNNEELM model is trained with JAFFE, CK+, and FER2013 expression datasets. The simulation results show significant improvements in accuracy and processing time, making the model suitable for the video analysis process. Besides, the study solves the issue of the large processing time required to process the facial images.
C1 [Banskota, Nitesh; Alsadoon, Abeer; Prasad, P. W. C.; Dawoud, Ahmed] Charles Start Univ CSU, Sch Comp Math & Engn, Bathurst, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.; Dawoud, Ahmed] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.] Kent Inst Australia, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
   [Rashid, Tarik A.] Univ Kurdistan Hewler, Comp Sci & Engn, Erbil, Krg, Iraq.
   [Alsadoon, Omar Hisham] Al Traqia Univ, Dept Islamic Sci, Baghdad, Iraq.
C3 Charles Sturt University; Western Sydney University; University of
   Kurdistan Hewler
RP Alsadoon, A (corresponding author), Charles Start Univ CSU, Sch Comp Math & Engn, Bathurst, NSW, Australia.; Alsadoon, A (corresponding author), Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021; Rashid, Tarik A./P-3473-2019;
   Rashid, Tarik A./HLX-0184-2023
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; Rashid, Tarik
   A./0000-0002-8661-258X; Rashid, Tarik A./0000-0002-8661-258X; withana,
   chandana/0000-0002-3007-687X; Alsadoon, Omar Hisham/0000-0001-7797-6392
CR Ahmed MU, 2018, COGN SYST RES, V52, P212, DOI 10.1016/j.cogsys.2018.06.017
   [Anonymous], 2007, Nonverbal Communication
   Bora K, 2016, TENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2016), DOI 10.1145/3009977.3010068
   Fang BF, 2018, INT J MACH LEARN CYB, V9, P1955, DOI 10.1007/s13042-017-0679-3
   Han XH, 2016, LECT NOTES COMPUT SC, V10008, P3, DOI 10.1007/978-3-319-46976-8_1
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977
   Jain N, 2018, PATTERN RECOGN LETT, V115, P101, DOI 10.1016/j.patrec.2018.04.010
   Kaya H, 2017, IMAGE VISION COMPUT, V65, P66, DOI 10.1016/j.imavis.2017.01.012
   Li HB, 2017, IEEE T MULTIMEDIA, V19, P2816, DOI 10.1109/TMM.2017.2713408
   Li S., 2018, arXiv
   Liu X, 2015, IEEE T NEUR NET LEAR, V26, P7, DOI 10.1109/TNNLS.2014.2335212
   Liu YY, 2018, PATTERN RECOGN, V84, P251, DOI 10.1016/j.patcog.2018.07.016
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Peng M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01745
   Ruiz-Garcia A, 2018, NEURAL COMPUT APPL, V29, P359, DOI 10.1007/s00521-018-3358-8
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sharif M., 2017, J. Eng. Sci. Technol. Rev., V10, P166
   Wang SJ, 2018, NEUROCOMPUTING, V312, P251, DOI 10.1016/j.neucom.2018.05.107
   Wu BF, 2018, IEEE ACCESS, V6, P12451, DOI 10.1109/ACCESS.2018.2805861
   Yao NM, 2017, J COMPUT SCI TECH-CH, V32, P1172, DOI 10.1007/s11390-017-1792-1
   Yuan XH, 2018, PATTERN RECOGN, V77, P160, DOI 10.1016/j.patcog.2017.12.017
   Zhang T, 2016, IEEE T MULTIMEDIA, V18, P2528, DOI 10.1109/TMM.2016.2598092
   Zhao XQ, 2017, BERNOULLI, V23, P3385, DOI 10.3150/16-BEJ850
NR 25
TC 7
Z9 7
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6479
EP 6503
DI 10.1007/s11042-022-13567-8
EA AUG 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000836525000004
DA 2024-07-18
ER

PT J
AU Gupta, D
   Rani, S
   Ahmed, SH
AF Gupta, Divya
   Rani, Shalli
   Ahmed, Syed Hassan
TI ICN-edge caching scheme for handling multimedia big data traffic in
   smart cities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information centric networking; Caching; Edge computing; Content
   delivery; Node centrality
ID INFORMATION-CENTRIC NETWORKING; CONTENT POPULARITY; CHALLENGES;
   INTERNET; THINGS; DELIVERY; STRATEGY; LESS
AB Today, the rapid development, large volume, and global access of multimedia applications have demanded the shifting of network functionality from the central server to the near user. In recent times, Edge Computing (EC) and Information Centric Networking (ICN) have been presented as arising advances for content dissemination near the end user. The EC aims to provide content locally by reducing the burden of the core networks, while ICN allows content routing and forwarding based on content names directly. The inherent in-network caching feature of ICN facilitates caching by intermediate network nodes. The combined use of EC and ICN can efficiently handle content dissemination and ultimately improves user experience. In this regards, an ICN based edge caching scheme has been proposed for handling multimedia big data traffic in IoT based smart cities, while incorporating four caching attributes in its proposed design. Firstly, a layered network architecture has been presented that offers Device-to-Device (D2D) communication and ICN support at the application layer of Base station (BS) for utilizing caching of the requested content at edge of the network. Secondly, a decision on caching of contents at network nodes in layered network architecture has been presented based on various centrality measures, which supports efficient caching. Thirdly, this work offers caching of content near the delivery path in ICN network tiers, while leveraging near path caching for fast content dissemination. Lastly, reproactive caching where proactive caching is followed by reactive caching for controlling the network traffic during peak hours has been integrated in to the design model. The performance of the proposed scheme has been evaluated by conducting simulations in Icarus- an ICN caching simulator against various caching benchmark schemes. The results received from the experiments have shown significant performance improvement of our proposed scheme for different performance metrics including cache hit ratio, content retrieval delay, content path stretch, and internal link load.
C1 [Gupta, Divya; Rani, Shalli] Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
   [Gupta, Divya] Chandigarh Univ, Dept Comp Sci & Engn, Mohali 140413, India.
   [Ahmed, Syed Hassan] Calif State Univ Fullerton, Dept Comp Sci, Fullerton, CA 92831 USA.
C3 Chitkara University, Punjab; Chandigarh University; California State
   University System; California State University Fullerton
RP Rani, S (corresponding author), Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
EM divya1907gupta@gmail.com; shalli.rani@chitkara.edu.in; sh.ahmed@ieee.org
RI Ahmed, Syed/GSN-7305-2022; Rani, Shalli/AGY-9513-2022; Shah, Syed
   Hassan/E-5058-2014
OI Rani, Shalli/0000-0002-8474-9435; Shah, Syed Hassan/0000-0002-1381-5095
CR Ai Y, 2018, DIGIT COMMUN NETW, V4, P77, DOI 10.1016/j.dcan.2017.07.001
   Arshad S, 2019, IEEE INTERNET THINGS, V6, P2128, DOI 10.1109/JIOT.2018.2873343
   Banerjee B, 2018, COMPUT NETW, V140, P78, DOI 10.1016/j.comnet.2018.05.001
   Chai WK, 2013, COMPUT COMMUN, V36, P758, DOI 10.1016/j.comcom.2013.01.007
   Chen MK, 2019, IEEE NETWORK, V33, P89, DOI 10.1109/MNET.2019.1800253
   Cho K, 2012, IEEE CONF COMPUT, P316, DOI 10.1109/INFCOMW.2012.6193512
   Colakovic A, 2018, COMPUT NETW, V144, P17, DOI 10.1016/j.comnet.2018.07.017
   Dastjerdi AV, 2016, COMPUTER, V49, P112, DOI 10.1109/MC.2016.245
   Din IU, 2018, IEEE COMMUN SURV TUT, V20, P1443, DOI 10.1109/COMST.2017.2787609
   Nguyen D, 2015, IEEE CONF COMPUT, P287, DOI 10.1109/INFCOMW.2015.7179399
   Fotiou N, 2017, EDGE ICN IFIP NETWOR, P1
   Garcia G., 2011, Future Network Mobile Summit (FutureNetw), P1
   Hua YN, 2020, FUTURE GENER COMP SY, V111, P82, DOI 10.1016/j.future.2020.04.040
   Huang LM, 2017, IEEE CONF COMPUT, P175, DOI 10.1109/INFCOMW.2017.8116372
   Ioannou A, 2016, IEEE COMMUN SURV TUT, V18, P2847, DOI 10.1109/COMST.2016.2565541
   Kobusinska A, 2018, FUTURE GENER COMP SY, V87, P416, DOI 10.1016/j.future.2018.05.021
   Laoutaris N, 2006, PERFORM EVALUATION, V63, P609, DOI 10.1016/j.peva.2005.05.003
   Li YH, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9101705
   Liu WX, 2018, IEEE ACCESS, V6, P5075, DOI 10.1109/ACCESS.2017.2781716
   Majeed MF, 2017, COMPUT NETW, V125, P103, DOI 10.1016/j.comnet.2017.05.030
   Man DP, 2021, COMPUT COMMUN, V176, P272, DOI 10.1016/j.comcom.2021.06.015
   Plass M.F., 2009, P 5 INT C EMERGING N, P1, DOI [10.1145/1658939.1658941, DOI 10.1145/1658939.1658941]
   Psaras I., 2012, P 2 ED ICN WORKSH IN, P55, DOI DOI 10.1145/2342488.2342501
   Ren J, 2014, IEEE CONF COMPUT, P470, DOI 10.1109/INFCOMW.2014.6849277
   Rossi D, 2012, IEEE CONF COMPUT, P280, DOI 10.1109/INFCOMW.2012.6193506
   Saino Lorenzo., 2014, P 7 INT ICST C SIMUL, P66, DOI DOI 10.4108/ICST.SIMUTOOLS.2014.254630
   Satyanarayanan M, 2017, COMPUTER, V50, P30, DOI 10.1109/MC.2017.9
   Saxena D, 2016, COMPUT SCI REV, V19, P15, DOI 10.1016/j.cosrev.2016.01.001
   Serhane O, 2021, IEEE INTERNET THINGS, V8, P4081, DOI 10.1109/JIOT.2020.3022243
   Suksomboon K, 2013, C LOCAL COMPUT NETW, P236, DOI 10.1109/LCN.2013.6761239
   Tseng L, 2018, IEEE INT CONF CL NET
   Ullah R, 2020, FUTURE GENER COMP SY, V111, P159, DOI 10.1016/j.future.2020.04.033
   Wu HB, 2018, IEEE ACCESS, V6, P32754, DOI 10.1109/ACCESS.2018.2841417
   Zhang Z, 2020, IEEE T VEH TECHNOL, V69, P7955, DOI 10.1109/TVT.2020.2994181
NR 34
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39697
EP 39717
DI 10.1007/s11042-022-13518-3
EA AUG 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000836525000014
DA 2024-07-18
ER

PT J
AU Madaan, H
   Gosain, A
AF Madaan, Heena
   Gosain, Anjana
TI Prioritized dynamic cube selection in data warehouse
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cube priority; Data cubes; Data warehouse; Business decision making;
   View materialization; Dynamic view selection
ID MATERIALIZED VIEW SELECTION; ALGORITHM
AB The main contribution of this paper is to materialize right cubes according to the users' priority at the right time which can significantly reduce delays in information retrieval and achieve faster decision making. Therefore, we propose a PrioDyna algorithm that maintains the two-level cache space to handle the High priority and the long-term user requests dynamically. The first level cache focuses on the short-lived data cubes considering the cube priority as a selection parameter. In contrast, the second level cache targets the long-term trends by capturing frequently used data cubes requested for the longer run. Different experimental results show that our approach significantly outperforms the state-of-the-art methods in terms of overall cost savings by 2-6% in addition to 15-45% fewer cube evictions and better selection of High priority data cubes by 3-8%.
C1 [Madaan, Heena; Gosain, Anjana] Guru Gobind Singh Indraprastha Univ, Delhi 110078, India.
C3 GGS Indraprastha University
RP Madaan, H (corresponding author), Guru Gobind Singh Indraprastha Univ, Delhi 110078, India.
EM heenamadaan100@gmail.com
OI Madaan, Heena/0000-0002-4928-9496
CR Albrecht, 2001, DAWAK, V1874, P47, DOI [10.1007/3-540-44466-1_5, DOI 10.1007/3-540-44466-1_5]
   [Anonymous], 2018, WIDE WORLD IMPORTERS
   [Anonymous], 2008, REPORT
   Antwi Daniel K., 2016, Transactions on Large-Scale Data- and Knowledge-Centered Systems XXVI. Special Issue on Data Warehousing and Knowledge Discovery (DaWaK). LNCS 9670, P61, DOI 10.1007/978-3-662-49784-5_3
   Arigon AM, 2006, ACM T MULTIM COMPUT, V2, P199, DOI 10.1145/1152149.1152152
   Azgomi H, 2019, APPL INTELL, V49, P3965, DOI 10.1007/s10489-019-01481-w
   Azgomi H, 2018, ENG APPL ARTIF INTEL, V71, P125, DOI 10.1016/j.engappai.2018.02.018
   Browning D, 2001, DATA WAREHOUSE DESIG
   Chaudhari Manoj S., 2012, Data Engineering and Management. Second International Conference, ICDEM 2010. Revised Selected Papers, P57, DOI 10.1007/978-3-642-27872-3_9
   Choi CH, 2004, LECT NOTES COMPUT SC, V3129, P147
   Francisco P., 2011, The Netezza Data Appliance Architecture
   Ganapathi A, 2009, PROC INT CONF DATA, P592, DOI 10.1109/ICDE.2009.130
   Ghazanfari M, 2011, SCI IRAN, V18, P1579, DOI 10.1016/j.scient.2011.11.011
   Gosain A, 2018, IET SOFTW, V12, P498, DOI 10.1049/iet-sen.2017.0310
   Gosain A, 2018, ADV INTELL SYST, V518, P403, DOI 10.1007/978-981-10-3373-5_40
   Gosain A, 2016, ADV INTELL SYST, V409, P53, DOI 10.1007/978-981-10-0135-2_5
   Gosain A, 2016, PROCEDIA COMPUT SCI, V79, P2, DOI 10.1016/j.procs.2016.03.002
   Gupta H, 2005, IEEE T KNOWL DATA EN, V17, P24, DOI 10.1109/TKDE.2005.16
   Hamdi I, 2014, 2014 6TH INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), P168, DOI 10.1109/SOCPAR.2014.7008000
   Kalmegh, 2019, THESIS DUKE U DURHAM
   Kotidis Y, 2001, ACM T DATABASE SYST, V26, P388, DOI 10.1145/503099.503100
   Lin WY, 2004, KNOWL INF SYST, V6, P83, DOI 10.1007/s10115-003-0093-x
   Loureiro J, 2006, ICEIS 2006: PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATIONAL SYSTEMS, P46
   Mayata R., 2020, INT S MODELLING IMPL, P203, DOI DOI 10.1007/978-3-030-58861-8_15
   McKendrick J., 2016, With Internet Of Things And Big Data, 92In The Cloud
   Patel JM, 2018, PROC VLDB ENDOW, V11, P663, DOI 10.14778/3184470.3184471
   Savva F, 2020, ARXIV
   Shi JG, 2009, HIS 2009: 2009 NINTH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS, VOL 3, PROCEEDINGS, P301, DOI 10.1109/HIS.2009.275
   Song MN, 2018, LECT NOTES COMPUT SC, V10745, P382, DOI 10.1007/978-3-319-74521-3_41
   Uchiyama Hidetoshi., 1999, P 2 ACM INT WORKSHOP, P36, DOI DOI 10.1145/319757.319786
   Wang L, 2007, ADV INFORM SECUR, V28, P13
   Watson HJ, 2006, INFORM SYST MANAGE, V23, P7, DOI 10.1201/1078.10580530/45769.23.1.20061201/91768.2
   Zhang C, 2001, IEEE T SYST MAN CY C, V31, P282, DOI 10.1109/5326.971656
NR 33
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8113
EP 8135
DI 10.1007/s11042-022-13460-4
EA JUL 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000832565900007
DA 2024-07-18
ER

PT J
AU Chen, XY
   Li, JJ
   Hua, Z
AF Chen, Xinyu
   Li, Jinjiang
   Hua, Zhen
TI Retinex low-light image enhancement network based on attention mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-light enhancement; Retinex theory; Deep learning; Attention
   mechanism
ID ADAPTIVE HISTOGRAM EQUALIZATION; AUTOENCODER
AB Images taken at night, under cloudy conditions, etc., are degraded and of poor quality, which can cause problems such as low brightness, excessive noise, and loss of information. In recent years, deep learning-based methods have led to a significant breakthrough in the challenging task of processing the enhancement of low-light images. We propose a new attention-based network incorporating Retinex theory for the enhancement of low-light images. First, the method in this paper requires pairs of low-/normal-light images for training, and the respective illumination and reflectance maps are decomposed by the first part of the designed network according to the commonality of both. Secondly, an attention mechanism module is inserted in the convolutional layer in the second part of the network, to adaptively adjust the luminance information of the illumination and to preserve the consistency of the image structure. Finally, the new illumination map estimated in the second part is combined with the previous reflectance map to obtain the final enhanced image. The experimental results show that the method achieves better results both quantitatively and qualitatively, with obvious luminance enhancement, less noise, better color reproduction, clearer texture information, and overall superiority compared to existing advanced methods.
C1 [Chen, Xinyu] Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Peoples R China.
   [Li, Jinjiang] Coinnovat Ctr Shandong Coll & Univ Future Intelli, Yantai 264005, Peoples R China.
   [Hua, Zhen] Shandong Technol & Business Univ, Sch Informat & Elect Engn, Yantai 264005, Peoples R China.
C3 Shandong Technology & Business University; Shandong Technology &
   Business University
RP Li, JJ (corresponding author), Coinnovat Ctr Shandong Coll & Univ Future Intelli, Yantai 264005, Peoples R China.
EM 1294584654@qq.com; lijinjiang@gmail.com; huazhen@sdtbu.edu.cn
RI chen, xin/IQW-3432-2023; chen, xinyu/HNR-2708-2023; Hua,
   Zhen/AGN-6068-2022
FU National Natural Science Foundation of China [61772319, 62002200,
   61972235, 12001327]; Shandong Natural Science Foundation of China
   [ZR2020QF012, ZR2021MF068]
FX The authors acknowledge the National Natural Science Foundation of China
   (Grant nos. 61772319, 62002200, 61972235, and 12001327), and Shandong
   Natural Science Foundation of China (Grant no. ZR2020QF012 and
   ZR2021MF068).
CR Al-Nawashi M, 2017, NEURAL COMPUT APPL, V28, pS565, DOI 10.1007/s00521-016-2363-z
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Banerjee S, 2021, ARCH COMPUT METHOD E, V28, P2943, DOI 10.1007/s11831-020-09485-3
   Cai BL, 2017, IEEE I CONF COMP VIS, P4020, DOI 10.1109/ICCV.2017.431
   Du JL, 2020, NEUROCOMPUTING, V392, P209, DOI 10.1016/j.neucom.2018.10.102
   Esposito C, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102468
   Fu G, 2019, IEEE IMAGE PROC, P1925, DOI 10.1109/ICIP.2019.8803197
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Gregor K, 2015, PR MACH LEARN RES, V37, P1462
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Huang OW, 2020, IEEE T MED IMAGING, V39, P2277, DOI 10.1109/TMI.2020.2970867
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lee H, 2020, IEEE SIGNAL PROC LET, V27, P251, DOI 10.1109/LSP.2020.2965824
   Li CY, 2018, PATTERN RECOGN LETT, V104, P15, DOI 10.1016/j.patrec.2018.01.010
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Li JJ, 2021, IEEE T CIRC SYST VID, V31, P4227, DOI 10.1109/TCSVT.2021.3049940
   Li JJ, 2020, COMPUT VIS MEDIA, V6, P169, DOI 10.1007/s41095-020-0172-x
   Li JJ, 2018, IEEE ACCESS, V6, P26831, DOI 10.1109/ACCESS.2018.2833888
   Liu D, 2020, IEEE T IMAGE PROCESS, V29, P3695, DOI 10.1109/TIP.2020.2964518
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Mnih V, 2014, ADV NEUR IN, V27
   Opschoor JAA, 2020, ANAL APPL, V18, P715, DOI 10.1142/S0219530519410136
   Pan YT, 2020, WORLD WIDE WEB, V23, P2259, DOI 10.1007/s11280-020-00793-z
   Pan YT, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8123-3
   Pan YT, 2019, NEUROCOMPUTING, V332, P137, DOI 10.1016/j.neucom.2018.12.025
   Park S, 2018, IEEE ACCESS, V6, P22084, DOI 10.1109/ACCESS.2018.2812809
   Park S, 2017, IEEE T CONSUM ELECTR, V63, P178, DOI 10.1109/TCE.2017.014847
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Popel M, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18073-9
   Rasti B, 2020, INFORM FUSION, V64, P121, DOI 10.1016/j.inffus.2020.07.002
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P4364, DOI 10.1109/TIP.2019.2910412
   REN X, 2018, IEEE T ANTENN PROPAG, P1
   Singh P, 2020, J DIGIT IMAGING, V33, P273, DOI 10.1007/s10278-019-00211-5
   Talaulikar Abhijeet S., 2019, Advanced Computing and Communication Technologies. Proceedings of the 11th ICACCT 2018. Advances in Intelligent Systems and Computing (AISC 702), P109, DOI 10.1007/978-981-13-0680-8_11
   Tang LM, 2019, APPL MATH MODEL, V69, P355, DOI 10.1016/j.apm.2018.12.021
   Tian CW, 2020, NEURAL NETWORKS, V131, P251, DOI 10.1016/j.neunet.2020.07.025
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Wang HX, 2020, PATTERN RECOGN LETT, V130, P64, DOI 10.1016/j.patrec.2018.08.010
   Wang RX, 2019, PROC CVPR IEEE, P6842, DOI 10.1109/CVPR.2019.00701
   Xu J, 2020, IEEE T IMAGE PROCESS, V29, P5022, DOI 10.1109/TIP.2020.2974060
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
   Zhang TL, 2022, COMPUT VIS MEDIA, V8, P495, DOI 10.1007/s41095-021-0246-4
   Zhang Y, 2020, ARXIV
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926
   ZIMMERMAN JB, 1988, IEEE T MED IMAGING, V7, P304, DOI 10.1109/42.14513
NR 50
TC 5
Z9 5
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4235
EP 4255
DI 10.1007/s11042-022-13411-z
EA JUL 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000828935800002
DA 2024-07-18
ER

PT J
AU Ai, XF
   Wang, YG
   Chen, XD
   Li, H
AF Ai, Xiaofei
   Wang, Yigang
   Chen, Xiaodiao
   Li, Hong
TI Omnidirectional stereo video using a hybrid representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Omnidirectional stereo; Stereo video; Stereo panorama; Image based
   rendering; Head mounted display
AB Compared with the traditional video, omnidirectional stereo video (ODSV) provides a larger field of view (FOV) with depth perception but makes the capturing, processing and displaying more complicated. Even though many attempts have been made to address these challenges, they leave one or more of the following problems: complicated camera rig, high latency and visible distortions. This paper presents a practical end-to-end solution based on a novel hybrid representation to solve these problems simultaneously. The proposed solution is directly from capturing to displaying, which removes the processing step, thus reducing the total time consumption and visible stitching distortions. This hybrid representation is piecewise linear about the horizontal viewing direction whose domain of definition is 0 degrees to 360 degrees with an assumption that the background is static, consisting of both static and moving regions. Using this representation, ODSV can be presented by omnidirectional stereo images and normal stereo pair of videos respectively. Moreover, a single panoramic camera strategy can be adopted to capture the omnidirectional stereo images in real environment and a normal binocular camera can be used to capture the stereo pair of videos. To display the ODSV, this paper presents a real-time tracking-based rendering algorithm for head mounted display (HMD). Experiments show that the proposed method is effective and cost-efficient. In contrast to state-of-the-art methods, the proposed method significantly reduces the complexity of camera rig and data amount, preserving a competitive stereo quality without visible distortions.
C1 [Ai, Xiaofei; Chen, Xiaodiao] Hangzhou Dianzi Univ, Sch Comp Sci, Hangzhou, Peoples R China.
   [Wang, Yigang; Li, Hong] Hangzhou Dianzi Univ, Sch Media & Design, Hangzhou, Peoples R China.
C3 Hangzhou Dianzi University; Hangzhou Dianzi University
RP Ai, XF (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci, Hangzhou, Peoples R China.
EM xiaofeiai@hdu.edu.cn; yigang.wang@hdu.edu.cn
OI Ai, Xiaofei/0000-0002-5044-8474
CR Anderson R, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980257
   [Anonymous], 2021, AN 3D
   Appia V, 2014, PROC SPIE, V9011, DOI 10.1117/12.2040907
   Facebook, 2021, INTR OC QUEST 2 NEXT
   Fan CL, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3329119
   FFmpeg Developers, 2021, FFMPEG TOOL VERS BE1
   Flynn J, 2016, PROC CVPR IEEE, P5515, DOI 10.1109/CVPR.2016.595
   Forrest, 2021, SURROUND360 IS NOW O
   Google VR, 2021, EXP VIRT REAL SIMPL
   Huang SK., 2017, ACM SIGGRAPH 2017 PO, V22, P1
   Konrad J, 2013, IEEE T IMAGE PROCESS, V22, P3485, DOI 10.1109/TIP.2013.2270375
   Konrad R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073594
   Koulieris GA, 2019, COMPUT GRAPH FORUM, V38, P493, DOI 10.1111/cgf.13654
   Lee J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925983
   Lessig C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601149
   Limonov A, 2018, IEEE ICCE
   Lu J, 2019, IEEE ACCESS, V7, P23187, DOI 10.1109/ACCESS.2019.2899221
   Mashraki, 2021, SURROUND360
   Matzen K, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073645
   Ochi D, 2015, P IEEE VIRT REAL ANN, P349, DOI 10.1109/VR.2015.7223439
   Peleg S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P395, DOI 10.1109/CVPR.1999.786969
   Pharr M., 2016, Physically Based Rendering: From Theory to Implementation, V3rd ed.
   Pico Fernando., 1988, HIST GEN PUERTO RICO
   Ra KK, 2019, INT CONF 3D VISION, P386, DOI 10.1109/3DV.2019.00050
   Richardt Christian, 2020, Real VR - Immersive Digital Reality: How to Import the Real World into Head-Mounted Immersive Displays. Lecture Notes in Computer Science (LNCS 11900), P3, DOI 10.1007/978-3-030-41816-8_1
   Richardt C, 2013, PROC CVPR IEEE, P1256, DOI 10.1109/CVPR.2013.166
   Richardt Christian, 2020, OMNIDIRECTIONAL STER, P1, DOI [10.1007/978-3-030-03243-2_808-1, DOI 10.1007/978-3-030-03243-2_808-1]
   Richardt Christian, 2019, ACM SIGGRAPH 2019 CO, P1, DOI [10.1145/3305366.3328028, DOI 10.1145/3305366.3328028]
   Rousselle F, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982443
   Schroers C, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3225150
   Sengupta S, 2020, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR42600.2020.00236
   Tang MH, 2019, IEEE T MULTIMEDIA, V21, P957, DOI 10.1109/TMM.2018.2867266
   W3C Immersive web working and community groups, 2021, W3C IMM WEB WORK COM
   Xie JY, 2016, LECT NOTES COMPUT SC, V9908, P842, DOI 10.1007/978-3-319-46493-0_51
   Xu F, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P446, DOI 10.1109/VR.2018.8448283
   Zhang E, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982432
   Zhang JN, 2020, IEEE INT CONF COMPUT, DOI 10.1109/iccp48838.2020.9105244
NR 37
TC 0
Z9 0
U1 5
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3995
EP 4010
DI 10.1007/s11042-022-13432-8
EA JUL 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000828262900001
DA 2024-07-18
ER

PT J
AU Rai, AK
   Om, H
   Chand, S
AF Rai, Arun Kumar
   Om, Hari
   Chand, Satish
TI High capacity reversible data hiding in encrypted images using
   prediction error encoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RDHEI; Prediction error; Gradient edge detection; GED predictor; Huffman
   encoding
AB Reversible data hiding in encrypted images (RDHEI) is a popular way for embedding the information in cover images without knowing their original contents. The RDHEI techniques are quite useful for annotating management data to encrypted images in cloud storage for their effective handling. In this paper, a high capacity RDHEI technique is proposed using prediction error encoding. The proposed RDHEI technique applies gradient edge detection predictor to predict the pixel values of nearby pixels of original image and calculates the prediction error. The host image is then encrypted using stream cipher to encode its contents. Next, the prediction errors are encoded using Huffman encoding to condense their size which helps in embedding the additional amount of secret message bits. Finally, the vacated room is exploited to embed the secret message bits by replacing the MSBs. Experimental results show that the proposed technique maximizes the embedding rate and also ensure security of the contents while comparing with the state-of-the-art techniques. More specifically, the proposed technique provides 1.384 and 4.202 bits per pixel embedding capacity, provide for Baboon and Airplane images, respectively.
C1 [Rai, Arun Kumar; Om, Hari] Indian Inst Technol, Indian Sch Mines, Dhanbad, Bihar, India.
   [Chand, Satish] Jawaharlal Nehru Univ, New Delhi, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad; Jawaharlal Nehru
   University, New Delhi
RP Rai, AK (corresponding author), Indian Inst Technol, Indian Sch Mines, Dhanbad, Bihar, India.; Chand, S (corresponding author), Jawaharlal Nehru Univ, New Delhi, India.
EM arunrai.dei@gmail.com; hariom4india@gmail.com; schand20@gmail.com
CR Avramovic A, 2010, ELMAR PROC, P131
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chandramouli R., 2013, Cryptographic Key Management Issues and Challenges in Cloud Services
   Chen KM, 2019, J VIS COMMUN IMAGE R, V58, P334, DOI 10.1016/j.jvcir.2018.12.023
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Kumar N, 2021, IEEE SIGNAL PROC LET, V28, P1335, DOI 10.1109/LSP.2021.3090673
   Kumar R, 2020, INFORM SCIENCES, V536, P101, DOI 10.1016/j.ins.2020.05.047
   Kumar R, 2016, MULTIMED TOOLS APPL, V75, P241, DOI 10.1007/s11042-014-2289-3
   Li Q, 2018, MULTIMED TOOLS APPL, V77, P30749, DOI 10.1007/s11042-018-6187-y
   Lin J, 2019, J INF HIDING MULTIME, V10, P408
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Malik A, 2018, MULTIMED TOOLS APPL, V77, P15803, DOI 10.1007/s11042-017-5156-1
   Pahl C, 2019, IEEE T CLOUD COMPUT, V7, P677, DOI 10.1109/TCC.2017.2702586
   Puech W, 2008, PROC SPIE, V6819, DOI 10.1117/12.766754
   Puteaux P, 2018, IEEE INT WORKS INFOR
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Puyang Y, 2018, IEEE INT WORKS INFOR
   Rai AK, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13061072
   sipi, USC-SIPI image database
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Wu YQ, 2020, IEEE T MULTIMEDIA, V22, P1929, DOI 10.1109/TMM.2019.2952979
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   Zhang W, 2019, J REAL-TIME IMAGE PR, V16, P697, DOI 10.1007/s11554-018-0811-y
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
NR 25
TC 1
Z9 1
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8345
EP 8358
DI 10.1007/s11042-021-11574-9
EA JUL 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000825912900004
DA 2024-07-18
ER

PT J
AU Huang, SB
   Sha, YP
   Li, RS
AF Huang, Shaobin
   Sha, Yongpeng
   Li, Rongsheng
TI A chinese named entity recognition method for small-scale dataset based
   on lexicon and unlabeled data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Named entity recognition; Lexicon information; Unlabeled data;
   Pre-trained language model
AB Recently, using lexicon information to improve the performance of Chinese named entity recognition has been proven to be effective. Moreover, the lexicon-based method represented by Lattice-LSTM has also become the mainstream. Although Lattice-LSTM can introduce lexicon information into characters to augment named entity recognition performance, it cannot make good use of unlabeled data, which contains abundant semantic information to assist the network to improve effect. And because Lattice-LSTM introduces much lexicon information, there is currently no suitable way to assign weights to each word. In this work, we propose a method that can effectively introduce lexicon information, which is also simple to implement and can be applied to various networks. Based on the lexicon method, this method uses external unlabeled data to count the word frequency and improved mutual information to represent the weight of the word to introduce lexicon information. And attention mechanism is used to dynamically assign weights to each part of lexicon information. In this method, the fusion of character and lexicon information is processed before the input layer, so that the method has a faster training speed and better versatility. Compared with other methods that are based on lexicon information, this method introduces additional prior knowledge, namely unlabeled data, and achieves better results when the scale of dataset is small. And when combined with the pre-trained language model, the performance is better (the F1 scores on Weibo dataset and Resume dataset are 96.73% and 71.53% respectively). Experimental research shows that our method surpasses many other excellent baseline methods in training speed and performance on two small-scale public Chinese named entity recognition datasets.
C1 [Huang, Shaobin; Sha, Yongpeng; Li, Rongsheng] Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Peoples R China.
C3 Harbin Engineering University
RP Li, RS (corresponding author), Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Peoples R China.
EM huangshaobin@hrbeu.edu.cn; shayongpeng@hrbeu.edu.cn;
   dasheng@hrbeu.edu.cn
CR Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Arora R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5862
   Chen YB, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P181
   Chen YB, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P167
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Devlin J., 2018, BERT PRE TRAINING DE
   Dong C, 2016, LECT NOTES COMPUT SC, V10102, P239, DOI 10.1007/978-3-319-50496-4_20
   Gui T, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4982
   Gui T, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1040
   Hammerton J, 2003, P 7 C NAT LANG LEARN, V4, P172, DOI DOI 10.3115/1119176.1119202
   Huang Z, 2015, ARXIV PREPRINTARXIV1
   Jia YG, 2019, 1ST INTERNATIONAL WORKSHOP ON DEEP LEARNING PRACTICE FOR HIGH-DIMENSIONAL SPARSE DATA WITH KDD (DLP-KDD 2019), DOI 10.1145/3326937.3341250
   Jie Z, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P729
   Lample M., 2016, P NAACL HLT, P260, DOI DOI 10.18653/V1/N16-1030
   Li XY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P465, DOI 10.1007/978-981-15-3863-6_51
   Liu A, 2019, ARXIV PREPRINT ARXIV
   Ma Ruotian., 2020, P ASS COMP LING ACL, DOI 10.18653/v1/2020.acl-main.528
   Nie YY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4231
   Peng N, 2016, ARXIV PREPRINT ARXIV
   Pengfei Cao, 2020, Chinese Computational Linguistics. 19th China National Conference, CCL 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12522), P144, DOI 10.1007/978-3-030-63031-7_11
   Riedel S., 2013, P HUM LANG TECHN C N, P74
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Wu Yonghui., 2016, arXiv preprint arXiv:1609.08144, P1, DOI DOI 10.1109/ICASI.2016.7539822
   Yan H., 2019, ARXIV PREPRINT ARXIV, P1
   Yang Yuzhe, 2020, NEURIPS, V33, P19290
   Zhang Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1554
   Zheng CM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P357
   Zhou JT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3461
NR 32
TC 0
Z9 0
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2185
EP 2206
DI 10.1007/s11042-022-13377-y
EA JUN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000814042700001
DA 2024-07-18
ER

PT J
AU Zulqarnain, M
   Ghazali, R
   Aamir, M
   Hassim, YMM
AF Zulqarnain, Muhammad
   Ghazali, Rozaida
   Aamir, Muhammad
   Hassim, Yana Mazwin Mohmad
TI An efficient two-state GRU based on feature attention mechanism for
   sentiment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Recurrent neural network; Gated recurrent unit; Two State GRU; Attention
   mechanism; Sentiment analysis
ID NEURAL-NETWORK
AB Sentiment analysis is one of the most challenging tasks in natural language processing (NLP). The extensively used application of sentiment analysis is sentiment classification of reviews. The purpose of sentiment classification is to determine the sentiment polarity of user opinion, attitude, and emotions expressed in the form of text into positive, negative and neutral polarities. Many advanced deep learning approaches have been proposed to solve sentiment analysis problem. Recurrent neural network (RNN) is one of the popular deep learning architectures which is widely employed in sentiment analysis. In this paper, we proposed a Two State GRU (TS-GRU) based on feature attention mechanism that concentrates on identifying and categorization of the sentiment polarity using sequential modeling and word-feature seizing. The proposed approach integrates pre-feature attention in TS-GRU to associate the complex connection between words by sentence based sequential modeling and capturing the keywords using attention layer for sentiment polarity. Subsequently, a decoder function has been added in the post-feature attention GRU, in order to extract the predicted features during attention mechanism. The proposed approach has been evaluated on three benchmark datasets including IMDB, MR, and SST2. Experimental results conclude that the proposed TS-GRU model obtained higher sentiment analysis accuracy of 90.85%, 80.72%, and 86.51% on IMDB, MR, and SST2 datasets, respectively.
C1 [Zulqarnain, Muhammad; Ghazali, Rozaida; Aamir, Muhammad; Hassim, Yana Mazwin Mohmad] Univ Tun Hussein Onn Malaysia, Fac Comp Sci & Informat Technol, Parit Raja, Kagawa, Malaysia.
   [Zulqarnain, Muhammad] Riphah Int Univ, Riphah Coll Comp, Faisalabad Campus, Faisalabad, Pakistan.
C3 University of Tun Hussein Onn Malaysia
RP Zulqarnain, M (corresponding author), Univ Tun Hussein Onn Malaysia, Fac Comp Sci & Informat Technol, Parit Raja, Kagawa, Malaysia.; Zulqarnain, M (corresponding author), Riphah Int Univ, Riphah Coll Comp, Faisalabad Campus, Faisalabad, Pakistan.
EM zulqarnainmalik321@gmail.com; rozaida@uthm.edu.my
RI Hassim, Yana Mazwin Mohmad/AAD-9329-2019; Zulqarnain, Dr.
   Muhammad/IUQ-2702-2023; Aamir, Muhammad/AAJ-4676-2021; Ghazali,
   Rozaida/D-3985-2013
OI Aamir, Muhammad/0000-0002-4999-7740; Zulqarnain,
   Muhammad/0000-0001-8081-022X
CR Acharjya DP, 2016, INT J ADV COMPUT SC, V7, P511
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   [Anonymous], 2015, COMPUTER SCI
   [Anonymous], 2014, SSST EMNLP
   Balyan R, 2020, INT J ARTIF INTELL E, V30, P337, DOI 10.1007/s40593-020-00201-7
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Camacho-Collados J, 2018, Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, P40
   Cho K., 2014, ARXIV14061078
   Chung Junyoung, 2014, ARXIV14123555
   Do HH, 2019, EXPERT SYST APPL, V118, P272, DOI 10.1016/j.eswa.2018.10.003
   Fu XH, 2018, IEEE ACCESS, V6, P71884, DOI 10.1109/ACCESS.2018.2878425
   Ghazali R, 2014, IEEE IJCNN, P510
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hourri S, 2021, INT J SPEECH TECHNOL, V24, P389, DOI 10.1007/s10772-021-09795-2
   Hunsinger S, 2018, J INFORM SYST APPL R, V11, P25
   Kalyanathaya K. P., 2019, Int. J. Recent Technol. Eng., V7, P199
   Ketkar N., 2017, Deep Learning With Python, P113, DOI DOI 10.1007/978-1-4842-2766-4_8
   Kumar RS, 2022, MULTIMED TOOLS APPL, V81, P11989, DOI 10.1007/s11042-020-10480-w
   Lee OJ, 2020, ARTIF INTELL, V281, DOI 10.1016/j.artint.2020.103235
   Liu B, 2020, J AMB INTEL HUM COMP, V11, P451, DOI 10.1007/s12652-018-1095-6
   Long Yunfei., 2017, P 2017 C EMPIRICAL M, P462
   Ma YH, 2019, IEEE ACCESS, V7, P132542, DOI 10.1109/ACCESS.2019.2940506
   Maas Andrew, 2011, P 49 ANN M ASS COMP
   Pang B, 2005, ARXIV PREPRINT CS050
   Parimala M, 2021, SOFTWARE PRACT EXPER, V51, P550, DOI 10.1002/spe.2851
   Parkhe V, 2016, SOFT COMPUT, V20, P3373, DOI 10.1007/s00500-015-1779-1
   Peng P, 2020, NEUROCOMPUTING, V407, P232, DOI 10.1016/j.neucom.2020.04.075
   Pennington J., 2014, PROC C EMPIRICAL MET
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Rahman S, 2021, P INT C MACH INT DAT, P507
   Sachin S., 2020, SN Comput. Sci, DOI [10.1007/s42979-020-0076-y, DOI 10.1007/S42979-020-0076-Y]
   Say B, 2021, AAAI CONF ARTIF INTE, V35, P5016
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Serrano E, 2019, FUTURE GENER COMP SY, V100, P122, DOI 10.1016/j.future.2019.05.034
   Shiau WL, 2018, INT J INFORM MANAGE, V43, P52, DOI 10.1016/j.ijinfomgt.2018.06.006
   Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Socher Richard, 2012, P 2012 JOINT C EMPIR, DOI [10.5555/2390948.2391084, DOI 10.1162/153244303322533223]
   Song H, 2020, IEEE ACCESS, V8, P151426, DOI 10.1109/ACCESS.2020.3015493
   Usama M, 2019, IEEE ACCESS, V7, P140252, DOI 10.1109/ACCESS.2019.2940051
   Xu GX, 2019, IEEE ACCESS, V7, P51522, DOI 10.1109/ACCESS.2019.2909919
   Yang CHH, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6523, DOI 10.1109/ICASSP39728.2021.9413453
   Yang M, 2019, NEURAL NETWORKS, V118, P247, DOI 10.1016/j.neunet.2019.06.014
   Yongping Xing, 2019, Journal of Physics: Conference Series, V1302, DOI 10.1088/1742-6596/1302/3/032042
   Zhang DJ, 2018, IEEE ACCESS, V6, P73750, DOI 10.1109/ACCESS.2018.2882878
   Zulgarnain M, 2020, INT J ADV COMPUT SC, V11, P594
   Zulqarnain M., 2019, Int. J. Inf. Vis., V3, P377, DOI 10.30630/joiv.3.4.289
   Zulqarnain M., 2020, Int. J. Intell. Syst. Appl. (IJISA), V12, P21
   Zulqarnain M, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.570
   Zulqarnain M, 2021, ARAB J SCI ENG, V46, P8953, DOI 10.1007/s13369-021-05691-8
NR 49
TC 7
Z9 7
U1 7
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 JUN 18
PY 2022
DI 10.1007/s11042-022-13339-4
EA JUN 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2F0JA
UT WOS:000812603300002
DA 2024-07-18
ER

PT J
AU Li, MH
   Bai, M
   Lv, YJ
AF Li, Minhua
   Bai, Meng
   Lv, Yingjun
TI Text segmentation by integrating hybrid strategy and non-text filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text segmentation; Intensity; Stroke width; Integration; Non-text pixel
   filtering
ID BINARIZATION
AB The text embedded in images provides important information for image understanding. Text segmentation is an essential step for text recognition. It is often difficult to segment text from images at low resolution or with complex background. In this paper, a novel text segmentation framework is proposed to solve the problem. The proposed framework adopts a hybrid strategy integrating two different text segmentation methods to produce text candidates. One segmentation method is designed based on the intensity uniformity of text regions, while the other is developed by integrating the features of intensity and stroke width of text. To separate text pixels from the text candidates, a new non-text pixel filtering method is proposed. In the filtering method, an effective classifier is designed based on the number of breaking elements and the k-means clustering algorithm. The performance of the proposed segmentation framework is tested by the pixel-based and recognition-based evaluation methods. Experimental results show that the F-score of the proposed framework on the video caption dataset and born-digital dataset of ICDAR2013 are 95.29% and 89.09% respectively, while the correctly recognized character rate and word rate on the German TV public dataset are 91.00% and 72.33%. The experimental results indicate that the proposed text segmentation framework has excellent performance and high robustness in text segmentation and recognition.
C1 [Li, Minhua; Bai, Meng; Lv, Yingjun] Shandong Univ Sci & Technol, Dept Elect Engn & Informat Technol, 17 Sheng Lizhuang Rd, Jinan 250031, Shandong, Peoples R China.
C3 Shandong University of Science & Technology
RP Bai, M (corresponding author), Shandong Univ Sci & Technol, Dept Elect Engn & Informat Technol, 17 Sheng Lizhuang Rd, Jinan 250031, Shandong, Peoples R China.
EM skd994234@sdust.edu.cn; baimeng06@163.com; sdkdlyj@163.com
FU Natural Science Foundation of Shandong Province [ZR2020MF086]
FX This work is supported by Natural Science Foundation of Shandong
   Province (No. ZR2020MF086). The authors kindly acknowledge Dr. Nick
   Shuley from University of Tasmania, Australia for his constructive
   comments and suggestions. This paper owes much to several anonymous
   reviewers who provided helpful comments and suggestions.
CR Bataineh B, 2011, PATTERN RECOGN LETT, V32, P1805, DOI 10.1016/j.patrec.2011.08.001
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen K, 2015, PROC INT CONF DOC, P291, DOI 10.1109/ICDAR.2015.7333770
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Li MH, 2010, PATTERN RECOGN LETT, V31, P2295, DOI 10.1016/j.patrec.2010.05.031
   Liu JH, 2016, SIGNAL PROCESS, V124, P259, DOI 10.1016/j.sigpro.2015.06.025
   Liu SG, 2012, PATTERN RECOGN, V45, P2769, DOI 10.1016/j.patcog.2011.11.019
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu X, IEEE T PATTERN ANAL
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Mancas-Thillou C, 2007, COMPUT VIS IMAGE UND, V107, P97, DOI 10.1016/j.cviu.2006.11.010
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Moghaddam RF, 2012, PATTERN RECOGN, V45, P2419, DOI 10.1016/j.patcog.2011.12.013
   Mosleh A, 2013, IEEE T IMAGE PROCESS, V22, P4460, DOI 10.1109/TIP.2013.2273672
   Niblack W., 1986, An Introduction to Digital Image Processing
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Phadke HH, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P543, DOI 10.1109/RTEICT.2017.8256656
   Qin SY, 2018, IEEE WINT CONF APPL, P242, DOI 10.1109/WACV.2018.00033
   Rong XJ, 2020, IEEE T IMAGE PROCESS, V29, P591, DOI 10.1109/TIP.2019.2930176
   Sauvola J, 1997, PROC INT CONF DOC, P147, DOI 10.1109/ICDAR.1997.619831
   Tang Y, 2017, IEEE T IMAGE PROCESS, V26, P994, DOI [10.1109/TIP.2016.2639440, 10.1109/TIP.2017.2656474]
   Wang B, 2019, IEEE T CYBERNETICS, V49, P1558, DOI 10.1109/TCYB.2018.2799999
   Wang XB, 2015, PATTERN RECOGN LETT, V60-61, P41, DOI 10.1016/j.patrec.2015.04.005
   Wolf C, 2002, INT C PATT RECOG, P1037, DOI 10.1109/ICPR.2002.1048482
   Yang HJ, 2014, MULTIMED TOOLS APPL, V69, P217, DOI 10.1007/s11042-012-1250-6
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Ye QX, 2004, IEEE IMAGE PROC, P2905
   Yin F, 2009, PATTERN RECOGN, V42, P3146, DOI 10.1016/j.patcog.2008.12.013
   Zhang XN, 2018, NEUROCOMPUTING, V307, P61, DOI 10.1016/j.neucom.2018.03.070
   Zhang Y, 2015, NEUROCOMPUTING, V168, P970, DOI 10.1016/j.neucom.2015.05.028
   Zhu YP, 2017, IET IMAGE PROCESS, V11, P455, DOI 10.1049/iet-ipr.2016.0914
NR 31
TC 1
Z9 1
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 44505
EP 44522
DI 10.1007/s11042-022-13029-1
EA JUN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000811988000001
DA 2024-07-18
ER

PT J
AU Liu, KX
   Li, QW
   Zhou, YQ
AF Liu, Kaixiang
   Li, Qingwu
   Zhou, Yaqin
TI An adaptive converged depth completion network based on efficient RGB
   guidance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth completion; Depth and RGB fusion; Attention mechanism; Dynamic
   convolution
ID SAMPLES
AB The depth completion task aims to recover dense and reliable depth from sparse and accurate depth. Only relying on sparse depth usually cannot achieve good performance. Most methods use RGB images with rich semantic information as a guide and achieve good results. However, The segmentation boundary of the RGB feature does not conform to the real depth distribution in some areas. (For example, there should be no segmentation boundary in an area where the depth changes continuously.) And common fusions (such as concatenated by channels and pixel-by-pixel addition) will promote the propagation of this wrong segmentation boundary features. Therefore two novel modules using dynamic convolution and attention mechanism are proposed in terms of preventing and correcting the propagation of wrong information. The proposed network is divided into two independent branches, then converge the output of the two branches by predicting the corresponding confidence of them. In the guided convolution branch, dynamic convolution is performed to fuse the high-level features of the RGB image and the low-level features of the sparse depth map. In the bidirectional attention branch, the attention mechanism is introduced to construct a bidirectional attention module, which is aimed to correct the wrong segmentation boundaries in the RGB image to achieve more effective feature fusion. Compared with the state-of-the-art methods, the proposed method still maintains excellent performance under different sparse input conditions. And the proposed method has shorter inference time and smaller model size while achieving competitive results.
C1 [Liu, Kaixiang; Li, Qingwu; Zhou, Yaqin] Hohai Univ, Coll Internet Things, Changzhou 213000, Peoples R China.
C3 Hohai University
RP Li, QW (corresponding author), Hohai Univ, Coll Internet Things, Changzhou 213000, Peoples R China.
EM kaixiang2017@outlook.com; li_qingwu@163.com; hhu_zyq@163.com
OI li, qingwu/0000-0003-3224-9831
FU Jiangsu Provincial Key RD Program [BE2018066]; National Natural Science
   Foundation of China [U1830105]
FX This study was funded by the Jiangsu Provincial Key R&D Program
   (No.BE2018066) and the National Natural Science Foundation of China
   (U1830105).
CR Chen J, 2020, ARXIV 200312243
   Cheng XJ, 2018, LECT NOTES COMPUT SC, V11220, P108, DOI 10.1007/978-3-030-01270-0_7
   Cheng XJ, 2020, AAAI CONF ARTIF INTE, V34, P10615
   Eldesokey A, 2020, IEEE T PATTERN ANAL, V42, P2423, DOI 10.1109/TPAMI.2019.2929170
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Gu JQ, 2021, IEEE ROBOT AUTOM LET, V6, P1808, DOI 10.1109/LRA.2021.3060396
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu M, 2021, ARXIV 210300783
   Imran Saif, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12438, DOI 10.1109/CVPR.2019.01273
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jaritz M, 2018, INT CONF 3D VISION, P52, DOI 10.1109/3DV.2018.00017
   Kaiyue Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11303, DOI 10.1109/CVPR42600.2020.01132
   Kingma D. P., 2014, arXiv
   Ku J, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P16, DOI 10.1109/CRV.2018.00013
   Liu LK, 2015, IEEE T IMAGE PROCESS, V24, P1983, DOI 10.1109/TIP.2015.2409551
   Liu LN, 2021, AAAI CONF ARTIF INTE, V35, P2136
   Ma FC, 2019, IEEE INT CONF ROBOT, P3288, DOI [10.1109/ICRA.2019.8793637, 10.1109/icra.2019.8793637]
   Ma FC, 2018, IEEE INT CONF ROBOT, P4796
   Park J, 2020, ARXIV 200710042
   Qiu JX, 2019, PROC CVPR IEEE, P3308, DOI 10.1109/CVPR.2019.00343
   Schuster R, 2020, ARXIV 200809346
   Shivakumar SS, 2019, IEEE INT C INTELL TR, P13, DOI [10.1109/ITSC.2019.8917294, 10.1109/itsc.2019.8917294]
   Tang J, 2019, ARXIV 190801238
   Uhrig J, 2017, INT CONF 3D VISION, P11, DOI 10.1109/3DV.2017.00012
   Van Gansbeke W, 2019, PROCEEDINGS OF MVA 2019 16TH INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), DOI 10.23919/mva.2019.8757939
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiang R, 2020, ARXIV 200309175
   Xu Y, 2019, IEEE I CONF COMP VIS, P2811, DOI 10.1109/ICCV.2019.00290
   Xu ZY, 2020, IEEE IMAGE PROC, P913, DOI [10.1109/ICIP40778.2020.9191138, 10.1109/icip40778.2020.9191138]
   Yinpeng Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11027, DOI 10.1109/CVPR42600.2020.01104
   Zhang Y, 2020, ARXIV 200410694
   Zhang Y, 2019, ARXIV 190306397
   Zhao SS, 2021, IEEE T IMAGE PROCESS, V30, P5264, DOI 10.1109/TIP.2021.3079821
NR 36
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35915
EP 35933
DI 10.1007/s11042-022-13341-w
EA JUN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000810859000002
DA 2024-07-18
ER

PT J
AU Tayal, DK
   Yadav, SK
   Arora, D
AF Tayal, Devendra Kumar
   Yadav, Sumit Kumar
   Arora, Divya
TI Personalized ranking of products using aspect-based sentiment analysis
   and Plithogenic sets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aspect-based sentiment analysis; MCDM; Plithogenic sets; Product ranking
ID INTUITIONISTIC FUZZY; ONLINE REVIEWS; MACHINE
AB The availability of the content on the web has increased enormously in the last decade. Many reviews are written by the users on the e-commerce websites for the products they buy. These reviews are read by customers who are interested in buying those products. Sometimes, these reviews are in thousands which makes it difficult to read them. Customers also want to search reviews based on their preferred aspects to make a buying decision. In this paper, a novel approach for Multi-Criteria Decision Making (MCDM) for multi-aspect based personalized ranking of the products is proposed. It characteristically uses customer preferences as one of the inputs for decision-making. Opinions on various aspects are extracted using Aspect-Based Sentiment Analysis (ABSA) which becomes the second input to the framework which uses Plithogenic sets. This model uniquely incorporating varying customer preferences by mapping them to plithogenic degree of contradictions and modelling linguistic uncertainties in online reviews to create a personalized ranking of products using plithogenic aggregation. It has been shown empirically that our approach outperforms the existing MCDM approaches namely TOPSIS (Technique for Order Preference by Similarity to Ideal Solution) and WSM (Weighted Sum Model) and some of the state-of-the-art methods.
C1 [Tayal, Devendra Kumar; Arora, Divya] Indira Gandhi Delhi Tech Univ Women, Delhi, India.
   [Yadav, Sumit Kumar] Income Tax Dept, Delhi, India.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW)
RP Arora, D (corresponding author), Indira Gandhi Delhi Tech Univ Women, Delhi, India.
EM divya.nasa.jul@gmail.com
CR Abdel-Basset M, 2020, J CLEAN PROD, V247, DOI 10.1016/j.jclepro.2019.119586
   Abdel-Basset M, 2019, ARTIF INTELL MED, V100, DOI 10.1016/j.artmed.2019.101710
   Abdelhack M, 2020, Optimization theory based on neutrosophic and plithogenic sets, P1, DOI [DOI 10.1016/B978-0-12-819670-0.00001-9, 10.1016/B978-0-12-819670-0.00001-9]
   Aghababaei S, 2016, 2016 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2016), P526, DOI [10.1109/WI.2016.131, 10.1109/WI.2016.0089]
   Al-Smadi M, 2018, J COMPUT SCI-NETH, V27, P386, DOI 10.1016/j.jocs.2017.11.006
   Ali F, 2017, TRANSPORT RES C-EMER, V77, P33, DOI 10.1016/j.trc.2017.01.014
   [Anonymous], 2008, Proceedings of ACL-08: HLT
   Atanassov K. T., 1986, Fuzzy Sets and Systems, V20, P87, DOI 10.1016/S0165-0114(86)80034-3
   Bi JW, 2019, INFORM SCIENCES, V504, P293, DOI 10.1016/j.ins.2019.07.025
   Chen L, 2019, INT J HUM-COMPUT ST, V121, P4, DOI 10.1016/j.ijhcs.2017.09.005
   Dhingra K, 2019, INT J MACH LEARN CYB, V10, P2143, DOI 10.1007/s13042-017-0768-3
   Guo CH, 2018, J SYST SCI SYST ENG, V27, P542, DOI 10.1007/s11518-018-5388-2
   Gupta V, 2019, J INTELL FUZZY SYST, V36, P4721, DOI 10.3233/JIFS-179021
   Haider S, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.4956
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hung CL, 2016, KNOWL-BASED SYST, V110, P224, DOI 10.1016/j.knosys.2016.07.030
   Jabreel M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11010216
   Kamel M, 2019, MULTIMED TOOLS APPL, V78, P21917, DOI 10.1007/s11042-019-7505-8
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   Konstan J., 2001, P 10 INT C WORLD WID, P285
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Kumar G, 2020, INT J INF TECH DECIS, V19, P1037, DOI 10.1142/S021962202050025X
   Li LQ, 2018, J SYST SCI SYST ENG, V27, P367, DOI 10.1007/s11518-016-5318-0
   Li Q, 2017, MULTIMED TOOLS APPL, V76, P12315, DOI 10.1007/s11042-016-3643-4
   Li S, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P1151
   Li XL, 2019, INFORM MANAGE-AMSTER, V56, P172, DOI 10.1016/j.im.2018.04.007
   Liang Yunlong, 2020, ARXIV200401951
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Liu Y, 2017, INT J INF TECH DECIS, V16, P1497, DOI 10.1142/S021962201750033X
   Liu Y, 2017, INFORM FUSION, V36, P149, DOI 10.1016/j.inffus.2016.11.012
   Liu Y, 2019, DECIS SUPPORT SYST, V123, DOI 10.1016/j.dss.2019.113079
   Majumder N, 2022, NEURAL COMPUT APPL, V34, P8333, DOI 10.1007/s00521-020-05287-7
   Mukhtar N, 2018, TELEMAT INFORM, V35, P2173, DOI 10.1016/j.tele.2018.08.003
   Nassif AB, 2021, APPL SOFT COMPUT, V98, DOI 10.1016/j.asoc.2020.106836
   Ortigosa A, 2014, COMPUT HUM BEHAV, V31, P527, DOI 10.1016/j.chb.2013.05.024
   Oztas GZ, 2020, INT C INT FUZZ SYST, P742, DOI DOI 10.1007/978-3-030-51156-2_86
   Pazzani M. J., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P325
   Pearson K. VII, 1997, Series A, containing papers of a mathematical or physical character, V187, P253, DOI [10.1098/rsta.1896.0007, DOI 10.1098/RSTA.1896.0007]
   Piryani R, 2017, ADV COMPUTER COMPUTA, P201
   Ray A, 2021, J STRATEG MARK, V29, P430, DOI 10.1080/0965254X.2020.1749875
   Smarandache F., 2014, Introduction to Neutrosophic Statistics
   Smarandache F, 2017, Plithogeny, plithogenic set, logic, probability, and statistics
   Smarandache F, 2018, NEUTROSOPHIC SETS SY, V21, P153
   Stojanovski D, 2018, MULTIMED TOOLS APPL, V77, P32213, DOI 10.1007/s11042-018-6168-1
   Yu J, 2011, P 49 ANN M ASS COMP, P1496, DOI DOI 10.1109/CC.2013.6488828
   Yu Y, 2015, COMPUT HUM BEHAV, V48, P392, DOI 10.1016/j.chb.2015.01.075
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang D, 2020, J OPER RES SOC, V71, P322, DOI 10.1080/01605682.2018.1545519
   Zhang K., 2011, OCEANS 2011 IEEE - Spain, P1, DOI [10.1145/2378104.2378116, 10. 1145/2378104. 2378116, DOI 10.1145/2378104.2378116]
   Zhang Lei., 2010, Proceedings of the 23rd International Conference on Computational Linguistics: Posters, P1462
   Zhao Yanyan., 2010, P HUMAN LANGUAGE TEC, P377
   Zhu XY, 2022, IEEE T CIRC SYST VID, V32, P1273, DOI 10.1109/TCSVT.2021.3078436
   Zhu XY, 2021, IEEE ICC, DOI 10.1109/ICC42927.2021.9500421
   Zuheros C, 2021, INFORM FUSION, V68, P22, DOI 10.1016/j.inffus.2020.10.019
NR 54
TC 5
Z9 5
U1 2
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1261
EP 1287
DI 10.1007/s11042-022-13315-y
EA JUN 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000811421000005
DA 2024-07-18
ER

PT J
AU Garai, A
   Dutta, A
   Biswas, S
AF Garai, Arpan
   Dutta, Arpita
   Biswas, Samit
TI Automatic dewarping of camera-captured comic document images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Comic document; Dewarping; Document image; Warped documents
ID BINARIZATION METHOD; RECTIFICATION; RESTORATION; MANGA
AB People often capture document images using the cameras attached to smart mobile phones. As a result, different types of distorted images gets generated. Warping is one of the major problems found on those distorted document images. Most existing techniques work based on the text lines present in the documents. On the other hand, comic documents contain fewer text lines. So, existing dewarping methods fail to perform with great accuracy in comic document images. Here, we propose a novel dewarping technique for warped comic document images. First, a simple mathematical model is proposed for warping generation in comic documents. Here, we show that warping depends on some factors. We estimate those factors from the boundaries of the panels present in a comic document image. Finally, based on those factors, we dewarp the document image. Unlike, the existing methods, the proposed approach can rectify warping in both horizontal and vertical direction. Nevertheless, the proposed approach can dewarp document images having multiple folds. We also evaluate the proposed approach, and the results are quite encouraging.
C1 [Garai, Arpan] Indian Inst Technol, Dept Comp Sci & Engn, Delhi 110016, India.
   [Dutta, Arpita; Biswas, Samit] Indian Inst Engn Sci & Technol, Dept Comp Sci & Technol, Howrah 711103, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Delhi; Indian Institute of Engineering Science
   Technology Shibpur (IIEST)
RP Garai, A (corresponding author), Indian Inst Technol, Dept Comp Sci & Engn, Delhi 110016, India.
EM agarai.cstaff@iitd.ac.in; arpita_duttass2018@cs.iiests.ac.in;
   samit@cs.iiests.ac.in
RI Garai, Arpan/AFI-9618-2022; Biswas, Samit/T-6889-2019; Dutta,
   Arpita/GLU-5978-2022
OI Garai, Arpan/0000-0002-8233-3591; Biswas, Samit/0000-0001-9379-4484;
   Dutta, Arpita/0000-0002-4220-3418; Dutta, Arpita/0000-0002-2049-2079
CR Augereau O, 2018, J IMAGING, V4, DOI 10.3390/jimaging4070087
   Bera SK, 2021, MULTIMED TOOLS APPL, V80, P7653, DOI 10.1007/s11042-020-09836-z
   Brown MS, 2004, IEEE T PATTERN ANAL, V26, P1295, DOI 10.1109/TPAMI.2004.87
   Cao HG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P228, DOI 10.1109/ICCV.2003.1238346
   Cao Y, 2017, IEEE T MULTIMEDIA, V19, P160, DOI 10.1109/TMM.2016.2609415
   Chu WT, 2015, IEEE T MULTIMEDIA, V17, P201, DOI 10.1109/TMM.2014.2383616
   Das S, 2019, IEEE I CONF COMP VIS, P131, DOI 10.1109/ICCV.2019.00022
   Das S, 2019, MULTIMED TOOLS APPL, V78, P27449, DOI 10.1007/s11042-019-07857-x
   Dubray D, 2019, ARXIV 190208137
   Dutta A, 2019, PROC INT CONF DOC, P38, DOI 10.1109/ICDARW.2019.00012
   Dutta A, 2018, PROC INT CONF EMERG
   Dutta A, 2023, INT REV IMMUNOL, V42, P82, DOI 10.1080/08830185.2021.2022661
   Ezaki H, 2005, PROC INT CONF DOC, P302, DOI 10.1109/ICDAR.2005.87
   Fu B, 2012, INT J IMAGE GRAPH, V12, DOI 10.1142/S0219467812500027
   Garai A, 2021, MULTIMED TOOLS APPL, V80, P36009, DOI 10.1007/s11042-021-10507-w
   Garai A, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107621
   Garai A, 2020, IET IMAGE PROCESS, V14, P74, DOI 10.1049/iet-ipr.2019.0831
   Garai A, 2017, 2017 NINTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION (ICAPR), P94
   Gatos B, 2007, PROC INT CONF DOC, P989
   He Y, 2013, PROC INT CONF DOC, P403, DOI 10.1109/ICDAR.2013.88
   He ZQ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P887, DOI 10.1145/3240508.3240555
   Herranz L, 2012, IEEE T MULTIMEDIA, V14, P1290, DOI 10.1109/TMM.2012.2192917
   Ke Ma, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P4700, DOI 10.1109/CVPR.2018.00494
   Kil T, 2017, PROC INT CONF DOC, P865, DOI 10.1109/ICDAR.2017.146
   Kim BS, 2015, PATTERN RECOGN, V48, P3600, DOI 10.1016/j.patcog.2015.04.026
   Lee SH, 2017, INT J DOC ANAL RECOG, V20, P223, DOI 10.1007/s10032-017-0291-9
   Li LY, 2014, ACM-IEEE J CONF DIG, P299, DOI 10.1109/JCDL.2014.6970183
   Liang J, 2008, IEEE T PATTERN ANAL, V30, P591, DOI 10.1109/TPAMI.2007.70724
   Liu CS, 2015, INT J DOC ANAL RECOG, V18, P111, DOI 10.1007/s10032-014-0233-8
   Liu XY, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107576
   Lu SJ, 2006, INT C PATT RECOG, P971
   Matsumoto Y, 2011, STEM CELLS BIOL REG, P35, DOI 10.1007/978-1-61779-002-7_2
   Meng GF, 2018, LECT NOTES COMPUT SC, V11220, P180, DOI 10.1007/978-3-030-01270-0_11
   Meng GF, 2012, IEEE T PATTERN ANAL, V34, P707, DOI 10.1109/TPAMI.2011.151
   Nguyen NV, 2017, PROC INT CONF DOC, P41, DOI 10.1109/ICDAR.2017.290
   Nguyen NV, 2019, INT J DOC ANAL RECOG, V22, P265, DOI 10.1007/s10032-019-00330-3
   Oh T, 2015, SIGNAL PROCESS-IMAGE, V39, P1, DOI 10.1016/j.image.2015.07.009
   Ohk H, 2011, PROC SPIE, V7866, DOI 10.1117/12.876758
   Pang XF, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1125, DOI 10.1145/2647868.2654990
   Pratikakis Ioannis, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1547, DOI 10.1109/ICDAR.2019.00249
   Qin XR, 2017, PROC INT CONF DOC, P1074, DOI 10.1109/ICDAR.2017.178
   Rigaud C, 2015, PROC INT CONF DOC, P351, DOI 10.1109/ICDAR.2015.7333782
   Rigaud C, 2015, INT J DOC ANAL RECOG, V18, P199, DOI 10.1007/s10032-015-0243-1
   Rigaud C, 2013, PROC INT CONF DOC, P1240, DOI 10.1109/ICDAR.2013.251
   Stamatopoulos N, 2011, IEEE T IMAGE PROCESS, V20, P910, DOI 10.1109/TIP.2010.2080280
   Sun WH, 2013, PROC INT CONF DOC, P275, DOI 10.1109/ICDAR.2013.62
   Sun WH, 2011, PROC INT CONF DOC, P1075, DOI 10.1109/ICDAR.2011.217
   Ulges A, 2005, PROC INT CONF DOC, P1001, DOI 10.1109/ICDAR.2005.90
   Wang FZ, 2017, IEEE T MULTIMEDIA, V19, P418, DOI 10.1109/TMM.2016.2613641
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P858, DOI 10.1109/TMM.2012.2187181
   Wang YT, 2015, PROC INT CONF DOC, P856, DOI 10.1109/ICDAR.2015.7333883
   Yang P, 2017, IET IMAGE PROCESS, V11, P841, DOI 10.1049/iet-ipr.2016.0973
   You S, 2018, IEEE T PATTERN ANAL, V40, P505, DOI 10.1109/TPAMI.2017.2675980
   Zhang L, 2006, INT C PATT RECOG, P642
   Zhao JY, 2018, INT CONF FRONT HAND, P339, DOI 10.1109/ICFHR-2018.2018.00066
NR 55
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1537
EP 1552
DI 10.1007/s11042-022-13234-y
EA JUN 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000809534700003
DA 2024-07-18
ER

PT J
AU Alarab, I
   Prakoonwit, S
AF Alarab, Ismail
   Prakoonwit, Simant
TI Uncertainty estimation based adversarial attack in multi-class
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Uncertainty estimation; Adversarial attack; Deep neural network
AB Model uncertainty has gained popularity in machine learning due to the overconfident predictions derived from standard neural networks which are not trustworthy. Recently, Monte-Carlo based adversarial attack (MC-AA) has been proposed as a simple uncertainty estimation method which is powerful in capturing data points that lie in the overlapping distribution of the decision boundary. MC-AA produces uncertainties by performing back-and-forth perturbations of a given data point towards the decision boundary using the idea of adversarial attacks. Despite its efficacy against other uncertainty estimation methods, this method has been only examined on binary classification problems. Thus, we present and examine MC-AA with multi-class classification tasks. We point out the limitation of this method with multiple classes which we tackle by converting multiclass problem into 'one-versus-all' classification. We compare MC-AA against other recent model uncertainty methods on Cora - a graph structured dataset - and MNIST - an image dataset. Thus, the conducted experiments are performed using a variety of deep learning algorithms to perform the classification. Consequently, we discuss the best results of model uncertainty with Cora data using LEConv model of AUC-score 0.889 and MNIST data using CNN of AUC-score 0.98 against other uncertainty estimation methods.
C1 [Alarab, Ismail; Prakoonwit, Simant] Bournemouth Univ, Bournemouth, Dorset, England.
C3 Bournemouth University
RP Alarab, I (corresponding author), Bournemouth Univ, Bournemouth, Dorset, England.
EM ialarab@bournemouth.ac.uk; sprakoonwit@bournemouth.ac.uk
RI Alarab, Ismail/AAU-1011-2021
OI Alarab, Ismail/0000-0001-8320-6423
CR Abdar M, 2021, INFORM FUSION, V76, P243, DOI 10.1016/j.inffus.2021.05.008
   Alarab I, 2020, P 2020 5 INT C MACHI, P23, DOI DOI 10.1145/3409073.3409080
   Alarab I, 2021, NEURAL PROCESS LETT, V117
   Alarab I., 2020, P 2020 5 INT C MACHI, DOI 10.1145/3409073.3409078
   Alarab I, 2021, NEURAL PROCESS LETT, V53, P1001, DOI 10.1007/s11063-021-10424-x
   Ambati LS., 2019, J MIDWEST ASS INF SY, V2021, P49, DOI DOI 10.17705/3JMWA.000065
   Blundell C, 2015, INT C MACHINE LEARNI
   Chakraborty A., 2018, arXiv
   Cuzzocrea A, 2022, MULTIMED TOOLS APPL, V81, P171, DOI 10.1007/s11042-021-11390-1
   El-Gayar OmarF., 2020, BIG DATAS POTENTIAL, P104, DOI DOI 10.4018/978-1-5225-9687-5.CH005
   Fey Matthias, 2019, ICLR WORKSH REPR LEA
   Gal Y, 2017, PR MACH LEARN RES, V70
   Gal Y, 2016, PR MACH LEARN RES, V48
   Gal Yarin, 2016, Uncertainty in deep learning
   Graves A, 2011, ADV NEURAL INFORM PR
   Handa A, 2019, WIRES DATA MIN KNOWL, V9, DOI 10.1002/widm.1306
   Haq IU, 2022, MULTIMED TOOLS APPL, V81, P33569, DOI 10.1007/s11042-022-13154-x
   Hernández-Lobato JM, 2015, PR MACH LEARN RES, V37, P1861
   Kendall A, 2017, 31 ANN C NEURAL INFO, V30
   Lakshminarayanan B, 2017, ADV NEUR IN, V30
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 1990, ADV NEURAL INFORM PR, P396
   Lee H, 2017, C LEARNING THEORY
   MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI [10.1162/neco.1992.4.3.415, 10.1162/neco.1992.4.3.448]
   Michelmore R, 2018, ARXIV PREPRINT ARXIV
   Mobiny A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84854-x
   Mobiny Aryan, 2019, DROPCONNECT IS EFFEC
   Neal R.M., 1992, Technical report
   Neal Radford M., 1995, PhD thesis,
   Ovadia Y, 2019, ADV NEUR IN, V32
   Paszke A, 2019, ADV NEUR IN, V32
   Pérez-Gil O, 2022, MULTIMED TOOLS APPL, V81, P3553, DOI 10.1007/s11042-021-11437-3
   Sen P, 2008, AI MAG, V29, P93, DOI 10.1609/aimag.v29i3.2157
   Shen S, 2017, ARXIV PREPRINT ARXIV
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tynan D, TESLA DRIVER DIES 1
   van Amersfoort J., 2021, ARXIV PREPRINT ARXIV
   Van Amersfoort Joost, 2020, INT C MACH LEARN, P9690
   Wang C, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108498
   Wang SY, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3264699
   Weber M, 2019, ARXIV PREPRINT ARXIV
   Yang Z, 2016, INT C MACH LEARN, P4048
NR 42
TC 0
Z9 0
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1519
EP 1536
DI 10.1007/s11042-022-13269-1
EA JUN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000805062900001
OA Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Meshram, V
   Patil, K
AF Meshram, Vishal
   Patil, Kailas
TI Border-Square net: a robust multi-grade fruit classification in IoT
   smart agriculture using feature extraction based Deep Maxout network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep Maxout network; Fruit quality classification; Border collie
   optimization (BCO); Least mean square (LMS) algorithm; Agriculture
ID MODEL
AB Internet of Things (IoT) is a distributed system of interconnected tools, such as people, animals, wireless devices, and agents, called nodes. In IoT, clustering is a data collection process that reduces energy consumption by forming IoT nodes into clusters. In the clustering, all nodes are arranged into virtual clusters, while one node acts as the Cluster Head (CH). The correct selection of the cluster head reduces the energy consumption. Now a day, IoT is being distributed in environments, such as the smart agriculture sector or forests. Fruit quality classification is a significant task in the supermarket, factories, as well as other industrial applications. Accordingly, fruit classification mechanism helps cashier of supermarket to find the species and prices of fruits. Various fruit quality classification approaches are developed to find quality of fruit. Accordingly, an efficient fruit quality classification method is modeled by Border Square Optimization-based Deep Maxout network (BSO-based Deep Maxout network) classifier. The proposed Border Square Optimization (BSO) approach is designed by the incorporation of Border Collie Optimization (BCO) with Least Mean Square (LMS) algorithm. It is necessary to select the energy-efficient node as CH, as the process of routing the fruit image to the sink node is done through CH. With the features acquired from fruit image, the multi grade classification of fruit quality is done by the Deep Maxout network model in such a way that training practice of deep learning classifier is accomplished by BSO model. The proposed approach achieved superior performance in terms of throughput, energy, delay, and accuracy with the values of 0.6759, 0.6753 J, 0.3659 s, and 0.9467.
C1 [Meshram, Vishal; Patil, Kailas] Vishwakarma Univ, Dept Sci & Technol, Survey 2,3,4, Pune 411048, Maharashtra, India.
RP Meshram, V (corresponding author), Vishwakarma Univ, Dept Sci & Technol, Survey 2,3,4, Pune 411048, Maharashtra, India.
EM vishal.meshram-020@vupune.ac.in; kailas.patil@vupune.ac.in
RI Patil, Kailas/ABI-6917-2020; Meshram, Vishal Ambadas/HOH-8961-2023
OI Patil, Kailas/0000-0002-1046-9860; Meshram, Vishal
   Ambadas/0000-0001-9950-584X
CR Anandkumar M., 2020, J NETWORKING COMMUNI, V3, P1, DOI DOI 10.46253/JNACS.V3I2.A1
   [Anonymous], TU DG DAT DAT GRAD
   Astuti Winda, 2018, IOP Conference Series: Earth and Environmental Science, V195, DOI 10.1088/1755-1315/195/1/012047
   Bhojwani Y., 2020, P INT C EMERGING TRE, P1
   Biswas Biswajit, 2020, Computational Intelligence in Pattern Recognition. Proceedings of CIPR 2019. Advances in Intelligent Systems and Computing (AISC 999), P105, DOI 10.1007/978-981-13-9042-5_10
   Deepa N, 2020, IEEE ACCESS, V8, P183749, DOI 10.1109/ACCESS.2020.3028595
   Dhumane AV, 2019, WIREL NETW, V25, P399, DOI 10.1007/s11276-017-1566-2
   Dhumane Amol V., 2020, Journal of Networking and Communication Systems, V3, P20
   Dutta T, 2020, IEEE ACCESS, V8, P109177, DOI 10.1109/ACCESS.2020.2999540
   Gadekallu TR, 2021, J REAL-TIME IMAGE PR, V18, P1383, DOI 10.1007/s11554-020-00987-8
   Getahun S, 2017, J FOOD ENG, V203, P58, DOI 10.1016/j.jfoodeng.2017.02.010
   Gómez-Chabla R, 2019, ADV INTELL SYST COMP, V901, P68, DOI 10.1007/978-3-030-10728-4_8
   Gondchawar N., 2016, INT J ADV RES COMPUT, P838, DOI [DOI 10.17148/IJARCCE.2016.56188, 10.17148/IJARCCE.2016.56188]
   Hameed K, 2018, IMAGE VISION COMPUT, V80, P24, DOI 10.1016/j.imavis.2018.09.016
   He RY, 2018, INT J REMOTE SENS, V39, P4059, DOI 10.1080/01431161.2018.1454620
   Hossain MS, 2019, IEEE T IND INFORM, V15, P1027, DOI 10.1109/TII.2018.2875149
   Hu XP, 2020, FRONT ENG MANAG, V7, P309, DOI 10.1007/s42524-020-0107-3
   Kumar R, 2021, COMPUT NETW, V187, DOI 10.1016/j.comnet.2021.107819
   Lee M, 2013, IEEE INT C COMPUT, P833, DOI 10.1109/CSE.2013.126
   Li J, 2010, P 2010 IEEE INT S AP, P3, DOI [DOI 10.1109/ICIECS.2010.5678245, 10.1109/ISAF.2010.5712271, DOI 10.1109/ISAF.2010.5712271, 10.1145/1852786.1852804, DOI 10.1145/1852786.1852804]
   Liu F., 2017, P INT C EC SOCIAL SC
   Machica I. K. D., 2019, INT J COMPUTER SCI M, V8, P153
   Meshram V., 2021, Artif Intell Life Sci, V1, P100010, DOI DOI 10.1016/J.AILSCI.2021.100010
   Meshram V, 2020, IEEE DATAPORT
   Meshram V. A., 2021, Ingenierie des systemes d Inf, V26, P159, DOI [10.18280/isi.260203, DOI 10.18280/ISI.260203]
   Meshram V, 2022, DATA BRIEF, V40, DOI 10.1016/j.dib.2021.107686
   Moummadi K., 2011, MULT COMP SYST ICMCS, P1
   Patil K. A., 2016, 2016 International Conference on Global Trends in Signal Processing, Information Computing and Communication (ICGTSPICC). Proceedings, P543, DOI 10.1109/ICGTSPICC.2016.7955360
   Prathibha SR, 2017, 2017 INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN ELECTRONICS AND COMMUNICATION TECHNOLOGY (ICRAECT), P81, DOI 10.1109/ICRAECT.2017.52
   Maddikunta PKR, 2021, IEEE SENS J, V21, P17608, DOI 10.1109/JSEN.2021.3049471
   Reddy P. K., 2019, J NETWORKING COMMUNI, V2, P23
   Risdin F., 2020, IOSR J. Comput. Eng. (IOSR-JCE), V22, P1
   Rudnik K, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9193971
   Shoaib B, 2014, CHINESE PHYS B, V23, DOI 10.1088/1674-1056/23/3/030502
   Sun WC, 2018, NEUROCOMPUTING, V278, P34, DOI 10.1016/j.neucom.2017.05.103
   Ullah KR, 2019, International Journal of Image, Graphics and Signal Processing, V8, P1, DOI DOI 10.5815/IJIGSP.2019.08.01
   Wang SH, 2020, MULTIMED TOOLS APPL, V79, P15117, DOI 10.1007/s11042-018-6661-6
   Wu S-L., 2020, P 19 IEEE INT C MACH
   Yadav AK, 2017, PEER PEER NETW APPL, V10, P897, DOI 10.1007/s12083-016-0441-8
   Zhang YD, 2019, MULTIMED TOOLS APPL, V78, P3613, DOI 10.1007/s11042-017-5243-3
   Zheng YY, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051058
NR 41
TC 1
Z9 2
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40709
EP 40735
DI 10.1007/s11042-022-12855-7
EA MAY 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000795177900008
DA 2024-07-18
ER

PT J
AU Esmaeili, V
   Feghhi, MM
   Shahdi, SO
AF Esmaeili, Vida
   Feghhi, Mahmood Mohassel
   Shahdi, Seyed Omid
TI A comprehensive survey on facial micro-expression: approaches and
   databases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Apex frame; Micro-expression analysis; Micro-expression databases;
   Micro-expression method categorizations
ID RECOGNITION; DESCRIPTORS; TOP
AB Over the past few years, the importance of the facial micro-expression (FME) has garnered increasing attention from experts because of its potential applications from the judgment court to the psychology research centers. A real challenge for developing an extensive system of the FME analysis is to select a suitable method and a database. In this manuscript, we have conducted a comprehensive and comparative survey to address the aforementioned challenge, and to give clear guidelines to alleviate further researches. To come up with this task, we have justified each method in terms of its pros and cons, which are meant to be beneficial for researchers choosing a method or a database, which suits their context application. Also, we have exhaustively analyzed the whole framework of the FME system by decomposing its pipeline into the pre-processing, the feature extraction, and the classification.
C1 [Esmaeili, Vida; Feghhi, Mahmood Mohassel] Univ Tabriz, Fac Elect & Comp Engn, 29 Bahman Blvd, Tabriz 5166616471, Iran.
   [Shahdi, Seyed Omid] Islamic Azad Univ, Dept Elect Engn, Qazvin Branch, Qazvin, Iran.
C3 University of Tabriz; Islamic Azad University
RP Feghhi, MM (corresponding author), Univ Tabriz, Fac Elect & Comp Engn, 29 Bahman Blvd, Tabriz 5166616471, Iran.
EM v.esmaeili@tabrizu.ac.ir; mohasselfeghhi@tabrizu.ac.ir;
   shahdi@qiau.ac.ir
RI Esmaeili, Vida/AAB-9907-2022; Mohassel Feghhi, Mahmood/D-2414-2010
OI Esmaeili, Vida/0000-0002-1840-8659; Mohassel Feghhi,
   Mahmood/0000-0002-7193-843X
CR Adegun IP, 2016, 2016 PATTERN RECOGNITION ASSOCIATION OF SOUTH AFRICA AND ROBOTICS AND MECHATRONICS INTERNATIONAL CONFERENCE (PRASA-ROBMECH)
   Al-Sumaidaee SAM, 2017, PATTERN RECOGN, V71, P249, DOI 10.1016/j.patcog.2017.06.007
   Ngo ACL, 2017, IEEE T AFFECT COMPUT, V8, P396, DOI 10.1109/TAFFC.2016.2523996
   [Anonymous], 2011, FACE GESTURE 2011
   [Anonymous], 2009, COMPUTER VISION PATT
   [Anonymous], 2009, 2009 WORKSH APPL COM
   Asthana A, 2013, P IEEE C COMPUTER VI
   Ben XY, 2018, PATTERN RECOGN LETT, V107, P50, DOI 10.1016/j.patrec.2017.07.010
   Chang T, 2019, PROCEEDINGS OF CHINESE CHI 2019: SEVENTH INTERNATIONAL SYMPOSIUM OF CHINESE CHI (CHINESE CHI 2019), P44, DOI 10.1145/3332169.3333575
   Choi DY, 2020, IEEE ACCESS, V8, P121549, DOI 10.1109/ACCESS.2020.3006958
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143903
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Das TK, 2020, J BIOMIM BIOMATER BI, V45, P57, DOI 10.4028/www.scientific.net/JBBBE.45.57
   Davison A, 2018, 2018 13 IEEE INT C A
   Davison Adrian K., 2018, IEEE Transactions on Affective Computing, V9, P116, DOI 10.1109/TAFFC.2016.2573832
   Davison AK, 2018, J IMAGING, V4, DOI 10.3390/jimaging4100119
   Davison AK, 2014, EUR C COMP VIS
   Duque CA, 2018, 2018 IEEE WINTER C A
   EKMAN P, 1969, PSYCHIATR, V32, P88, DOI 10.1080/00332747.1969.11023575
   Ekman P., 2002, Microexpression training tool (METT)
   Ekman P., 1978, Facial action coding system
   Esmaeili V., 2020, 2020 INT C MACH VIS
   Esmaeili V, 2020, INT J NONLINEAR ANAL, V11, P483, DOI 10.22075/IJNAA.2020.4707
   Esmaeili V, 2020, MULTIMED TOOLS APPL, V79, P20221, DOI 10.1007/s11042-020-08737-5
   Frank MG, 1997, J PERS SOC PSYCHOL, V72, P1429, DOI 10.1037/0022-3514.72.6.1429
   Gan Y, 2018, 2018 IEEE 3 INT C IM
   Gan YS, 2019, SIGNAL PROCESS-IMAGE, V74, P129, DOI 10.1016/j.image.2019.02.005
   Goh KM, 2020, VISUAL COMPUT, V36, P445, DOI 10.1007/s00371-018-1607-6
   GOSHTASBY A, 1988, IMAGE VISION COMPUT, V6, P255, DOI 10.1016/0262-8856(88)90016-9
   Grobova J, 2017, IEEE INT CONF AUTOMA, P828, DOI 10.1109/FG.2017.105
   Guo CY, 2019, IEEE ACCESS, V7, P174517, DOI 10.1109/ACCESS.2019.2942358
   Guo Y, 2014, 2014 INT JOINT C NEU
   Guo YC, 2015, OPTIK, V126, P4446, DOI 10.1016/j.ijleo.2015.08.167
   Haggard EA, 1966, METHODS RES PSYCHOTH, V5465
   Happy S, 2018, COMPUTATIONAL INTELL, P34168
   Happy S. L., 2017, IEEE Transactions on Affective Computing
   He JC, 2017, PATTERN RECOGN, V66, P44, DOI 10.1016/j.patcog.2016.11.029
   He Yue, 2019, ARXIV PREPRINT ARXIV
   HOUSE C., 2015, IEEE Trans.
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang WL, 2017, PATTERN RECOGN, V68, P126, DOI 10.1016/j.patcog.2017.03.010
   Huang XH, 2019, IEEE T AFFECT COMPUT, V10, P32, DOI 10.1109/TAFFC.2017.2713359
   Huang XH, 2016, NEUROCOMPUTING, V175, P564, DOI 10.1016/j.neucom.2015.10.096
   Husk P, 2017, 22 COMP VIS WINT WOR
   Khor HQ, 2018, IEEE INT CONF AUTOMA, P667, DOI 10.1109/FG.2018.00105
   Kim DH, 2016, P 24 ACM INT C MULTI
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le Ngo AC, 2016, 2016 IEEE INT C ACOU
   Le Ngo AC, 2018, 2018 13 IEEE INT C A
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li J., 2019, 2019 14th IEEE International Conference on Automatic Face Gesture Recognition (FG 2019), P1, DOI [10.1109/FG.2019.8756626.IEEE, DOI 10.1109/FG.2019.8756626.IEEE]
   Li J, 2019, PATTERN ANAL APPL, V22, P1331, DOI 10.1007/s10044-018-0757-5
   Li QY, 2020, J CIRCUIT SYST COMP, V29, DOI 10.1142/S0218126620500061
   Li X., 2016, 2016 IEEE 13 INT C S
   Li X, 2015, ARXIV PREPRINT ARXIV, V2, P7
   Li XB, 2018, IEEE T AFFECT COMPUT, V9, P563, DOI 10.1109/TAFFC.2017.2667642
   Li XB, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553717
   Li Y, 2018, 2018 25 IEEE INT C I
   Lin MB, 2020, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR42600.2020.00160
   Liong S-T, 2016, AS C COMP VIS
   Liong ST, 2019, IEEE INT CONF AUTOMA, P658, DOI 10.1109/fg.2019.8756567
   Liong ST, 2018, J SIGNAL PROCESS SYS, V90, P601, DOI 10.1007/s11265-017-1276-0
   Liong ST, 2018, SIGNAL PROCESS-IMAGE, V62, P82, DOI 10.1016/j.image.2017.11.006
   Liong ST, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P665, DOI 10.1109/ACPR.2015.7486586
   Liu Y. -J., 2018, IEEE Trans. Affect. Comput.
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Liu YC, 2019, IEEE INT CONF AUTOMA, P631, DOI 10.1109/fg.2019.8756583
   Lu H, 2018, SIGNAL PROCESS-IMAGE, V67, P108, DOI 10.1016/j.image.2018.05.014
   Ma HY, 2017, I S INTELL SIG PROC, P281, DOI 10.1109/ISPACS.2017.8266489
   McCabe M, 2009, INFORM TECHNOLOGY LA
   Merghani W, 2018, COMPUTER VISION PATT
   Oh YH, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01128
   Oh YH, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1237, DOI 10.1109/ICDSP.2015.7252078
   Oh YH, 2016, INT CONF ACOUST SPEE, P1851, DOI 10.1109/ICASSP.2016.7471997
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Patel D, 2016, 2016 23 INT C PATT R
   Peng M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01745
   Pfister T, 2011, COMPUTER VISION ICCV
   POLIKOVSKY S., 2009, 3 INT C IM CRIM DET, P1, DOI [10.1049/ic.2009.0244, DOI 10.1049/IC.2009.0244]
   Priya RMS, 2020, COMPUT COMMUN, V160, P139, DOI 10.1016/j.comcom.2020.05.048
   Qu FB, 2018, IEEE T AFFECT COMPUT, V9, P424, DOI 10.1109/TAFFC.2017.2654440
   Reddy G.T., 2020, Int Conf Emerg Trends Inform Technol Eng Ic-ETITE, P1, DOI 10.1109/ic-etite47903.2020.235
   RINN WE, 1984, PSYCHOL BULL, V95, P52, DOI 10.1037/0033-2909.95.1.52
   Ruiz-Hernandez JA, 2013, AUTOMATIC FACE GESTU
   Shahdi Seyed Omid, 2010, 2010 10th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA 2010), P85, DOI 10.1109/ISSPA.2010.5605502
   Shahdi SO, 2012, 2012 4TH INTERNATIONAL CONFERENCE ON INTELLIGENT AND ADVANCED SYSTEMS (ICIAS), VOLS 1-2, P642, DOI 10.1109/ICIAS.2012.6306093
   Song BL, 2019, IEEE ACCESS, V7, P184537, DOI 10.1109/ACCESS.2019.2960629
   Su W, 2018, 2018 IEEE INT C MULT
   Sukno FM, 2007, IEEE T PATTERN ANAL
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Takalkar MA, 2017, 2017 INT C DIGITAL I
   Takalkar M, 2018, MULTIMED TOOLS APPL, V77, P19301, DOI 10.1007/s11042-017-5317-2
   Verma GK., 2017, IN2017 C INF COMM TE, V2017, P1, DOI [10.1109/INFOCOMTECH.2017.8340637, DOI 10.1109/INFOCOMTECH.2017.8340637]
   Wang SJ, 2018, NEUROCOMPUTING, V312, P251, DOI 10.1016/j.neucom.2018.05.107
   Wang SJ, 2017, NEUROCOMPUTING, V230, P382, DOI 10.1016/j.neucom.2016.12.034
   Wang SJ, 2015, LECT NOTES COMPUT SC, V8925, P325, DOI 10.1007/978-3-319-16178-5_23
   Wang YD, 2017, MULTIMED TOOLS APPL, V76, P21665, DOI 10.1007/s11042-016-4079-6
   Wang YD, 2015, LECT NOTES COMPUT SC, V9003, P525, DOI 10.1007/978-3-319-16865-4_34
   Wang YF, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124812
   Warren G, 2009, J NONVERBAL BEHAV, V33, P59, DOI 10.1007/s10919-008-0057-7
   Weber R, 2018, INT JOINT C COMP VIS
   Wu C, 2021, IEEJ T ELECTR ELECTR, V16, P98, DOI 10.1002/tee.23272
   Wu HY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185561
   Wu Q, 2011, INT C AFFECTIVE COMP
   Xia Z., 2018, 2018 8 INT C IM PROC, P1
   Xie L., 2015, J INFORM COMPUTATION, V12, P2117
   Xu F, 2017, IEEE T AFFECT COMPUT, V8, P254, DOI 10.1109/TAFFC.2016.2518162
   Yan WJ, 2013, IEEE INT CONF AUTOMA
   Yan WJ, 2015, LECT NOTES COMPUT SC, V8925, P296, DOI 10.1007/978-3-319-16178-5_20
   Yan WJ, 2014, NEUROCOMPUTING, V136, P82, DOI 10.1016/j.neucom.2014.01.029
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yu M, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16162813
   Yu Y, 2018, J INTELL FUZZY SYST, V35, P4773, DOI 10.3233/JIFS-172307
   Zarezadeh E, 2016, BRAIN-BROAD RES ARTI, V7, P43
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zheng H, 2017, INT J MACH LEARN CYB, V8, P2043, DOI 10.1007/s13042-017-0684-6
   Zheng H, 2016, LECT NOTES COMPUT SC, V9810, P692, DOI 10.1007/978-3-319-42911-3_58
   Zhu, 2012, CHIN C BIOM REC
NR 119
TC 6
Z9 6
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40089
EP 40134
DI 10.1007/s11042-022-13133-2
EA MAY 2022
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000791638100007
DA 2024-07-18
ER

PT J
AU Donuk, K
   Ari, A
   Hanbay, D
AF Donuk, Kenan
   Ari, Ali
   Hanbay, Davut
TI A CNN based real-time eye tracker for web mining applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; CNNs; Eye gaze tracking; Web data mining
ID NEURAL-NETWORK; GAZE; MODEL; LAYER
AB Eye gaze tracking is an increasingly important technology in the field of human-computer interaction. Individuals' preferences, tendencies, and attention can be measured by processing the data obtained from face and eye images. This technology is used in advertising, market research, web page design, education, learning methods, and various neurological-psychiatric studies of medical research. Many different methods have been used in eye gaze tracking tasks. Today, commonly model-shape and appearance-based methods are used. Model-shape based methods require less workload than appearance-based methods. But it is more sensitive to environmental conditions. Appearance-based methods require powerful hardware, but they are less susceptible to environmental conditions. Developments in technology have paved the way for applying appearance-based models in eye gaze tracking. In this paper, a CNN-based real-time eye tracking system was designed to overcome environmental problems in eye gaze tracking. The designed system is used to determine the areas of interest of the user in web pages. The performance of the designed CNN-based system is evaluated during the training and testing phases. In the training phase, the difference between the desired and determined points on the screen is 32 pixels and in testing phase, the difference between the desired and determined points on the screen is 53 pixels. The results of the test trials have shown that the proposed system could be used successfully in eye tracking studies on web pages.
C1 [Donuk, Kenan] Sirnak Univ, Voc Sch Cizre, Comp Prog Programme, TR-73000 Sirnak, Turkey.
   [Ari, Ali; Hanbay, Davut] Inonu Univ, Engn Fac, Comp Engn Dept, 1 Ali Ari 2, TR-44280 Malatya, Turkey.
C3 Sirnak University; Inonu University
RP Ari, A (corresponding author), Inonu Univ, Engn Fac, Comp Engn Dept, 1 Ali Ari 2, TR-44280 Malatya, Turkey.
EM keriandonulc@sirnak.edu.tr; ali.ari@inonu.edu.tr;
   davut.hanbay@inonu.edu.tr
RI Hanbay, Davut/AAG-8511-2019
OI Hanbay, Davut/0000-0003-2271-7865; ari, ali/0000-0002-5071-6790
FU Inonu University Scientific Research Projects Coordination Unit (BAP)
   [FDK-2020-2110]
FX This study was supported by Inonu University Scientific Research
   Projects Coordination Unit (BAP) with the project coded FDK-2020-2110.
CR Akhtar N, 2020, NEURAL COMPUT APPL, V32, P879, DOI 10.1007/s00521-019-04296-5
   Aljaafreh A, 2020, INT J CIRCUITS SYST, V14, DOI 10.46300/9106.2020.14.16
   [Anonymous], SPECIALIZING EYE TRA
   [Anonymous], IBUG FACIAL POINT AN
   [Anonymous], Welcome to Colaboratory
   [Anonymous], TOBII IS WORLD LEADE
   [Anonymous], 2020, dlib C++ Library
   [Anonymous], EYE TRACKING SYSTEM
   Baluja S., 1994, ADV NEURAL INFORM PR, V6
   Barea R, 2002, IEEE T NEUR SYS REH, V10, P209, DOI 10.1109/TNSRE.2002.806829
   Chen HH, 2020, ALGORITHMS, V13, DOI 10.3390/a13050127
   Chen Jixu, 2008, P 2008 19 INT C PATT, P1, DOI DOI 10.1109/ICPR.2008.4761343
   COLLEWIJN H, 1975, VISION RES, V15, P447, DOI 10.1016/0042-6989(75)90098-X
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Damji O, 2019, CAN J EMERG MED, V21, P138, DOI 10.1017/cem.2018.450
   de Araújo FMA, 2020, LECT NOTES ELECTR EN, V621, P239, DOI 10.1007/978-981-15-1465-4_25
   Dogan F., 2019, D MF M HENDISLIK DER, V10, P409, DOI [10.24012/dumf.411130, DOI 10.24012/DUMF.411130]
   Donuk, 2020, 28 IEEE SIGN PROC CO, P2124
   Duchowski A. T., 2017, EYE TRACKING METHODO
   Dutta P, 2020, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT-2020), P175, DOI 10.1109/icict48043.2020.9112469
   Elmas, 2011, YAPAY ZEK UYGULAMALA
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Gurgu E, 2020, INDEP J MANAG PROD, V11, P208, DOI 10.14807/ijmp.v11i1.993
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Home-OpenCV, US
   Hung JC, 2021, J SUPERCOMPUT, V77, P343, DOI 10.1007/s11227-020-03283-1
   Ioffe S., 2015, 32 INT C MACHINE LEA, V1
   Ishikawa T, 2004, P WORLD C INT TRANSP
   Ivakhnenko A.G., 1965, Cybernetic predicting devices
   Janssen RGJ, 2010, THESIS TU DELFT DELF
   Jie HJ, 2020, INT J COMPUT INT SYS, V13, P66, DOI 10.2991/ijcis.d.200120.002
   Kazemi V, 2014, P IEEE COMPUTER SOC, DOI 10.1109/CVPR.2014.241
   Kim M., 2017, CONVOLUTIONAL NEURAL
   KIMME C, 1975, COMMUN ACM, V18, P120, DOI 10.1145/360666.360677
   Kingma D. P., 2014, arXiv
   KRAFKA K, 2016, P IEEE COMP VIS PATT
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LECUN Y, 1989, IEEE COMMUN MAG, V27, P41, DOI 10.1109/35.41400
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 1990, ADV NEURAL INFORM PR, P396
   Lu F, 2014, IEEE T PATTERN ANAL, V36, P2033, DOI 10.1109/TPAMI.2014.2313123
   Majaranta P, 2014, EYE TRACKING EYE BAS, V3965, DOI 10.1007/978-1-4471-6392-3_3
   MARTENS J, 2011, P 28 INT C MACH LEAR, P1033
   Massin L, 2020, OPT EXPRESS, V28, P28635, DOI 10.1364/OE.399823
   Mora K. A. F., 2014, P S EYE TRACK RES AP, P255, DOI [10.1145/2578153.2578190, 10.1145/2578153]
   Morimoto CH, 2002, INT C PATT RECOG, P314, DOI 10.1109/ICPR.2002.1047459
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Niemann J, 2019, COMM COM INF SC, V1060, P289, DOI 10.1007/978-3-030-28005-5_22
   Pfiffelmann J, 2020, J BUS RES, V111, P196, DOI 10.1016/j.jbusres.2019.08.017
   Rayner K, 1998, PSYCHOL BULL, V124, P372, DOI 10.1037/0033-2909.124.3.372
   Reyes F, 2020, INT J ADV TRENDS COM, V9, P3440, DOI [10.30534/ijatcse/2020/0791.12020, DOI 10.30534/IJATCSE/2020/0791.12020]
   ROBINSON DA, 1963, IEEE T BIO-MED ENG, VBM10, P137, DOI 10.1109/TBMEL.1963.4322822
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Salakhutdinov R., 2009, P 12 INT C ART INT S, V8
   Saraee E, 2020, COMPUT VIS IMAGE UND, V195, DOI 10.1016/j.cviu.2020.102949
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Seker A., 2017, Gazi Muhendislik Bilimleri Dergisi, V3, P47
   Sewell W., 2010, CHI 10 EXTENDED ABST, P3739, DOI DOI 10.1145/1753846.1754048
   Shokishalov Z, 2019, PROCEDIA COMPUT SCI, V150, P347, DOI 10.1016/j.procs.2019.02.062
   Slanzi G, 2017, INFORM FUSION, V35, P51, DOI 10.1016/j.inffus.2016.09.003
   Sugano Y, 2014, PROC CVPR IEEE, P1821, DOI 10.1109/CVPR.2014.235
   Sultana F, 2020, ADV INTELLIGENT SYST, V1157, P116
   Sun S, 2020, INT J COMPUT COMMUN, V15, DOI 10.15837/ijccc.2020.1.3712
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Tsantekidis A, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106401
   Uhm KH, 2020, MULTIMED TOOLS APPL, V79, P20603, DOI 10.1007/s11042-020-08679-y
   Velásquez JP, 2013, ENG APPL ARTIF INTEL, V26, P1469, DOI 10.1016/j.engappai.2013.01.003
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Whitmire E, 2016, IEEE INT SYM WRBL CO, P184, DOI 10.1145/2971763.2971771
   Wilkinson L, 2009, AM STAT, V63, P179, DOI 10.1198/tas.2009.0033
   Wong ET, 2019, PERCOM WORKSH 2019, DOI 10.1109/PERCOMW.2019.8730846
   Xu L-Q, 1998, P BMVC, DOI 10.5244/c.12.43
   Ye L, 2014, LECT NOTES COMPUT SC, V8833, P473, DOI 10.1007/978-3-319-12484-1_54
   Yoo DH, 2005, COMPUT VIS IMAGE UND, V98, P25, DOI 10.1016/j.cviu.2004.07.011
   Zhang X., 2015, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, DOI 10.1109/CVPR.2015.7299081
   Zhang X, 2020, VISUAL PLACE RECOGNI, DOI 10.1016/j.patcog.2020.107760
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhang ZQ, 2019, BRIEF FUNCT GENOMICS, V18, P41, DOI 10.1093/bfgp/ely030
   Zhou, 2020, REV ARGENTI CLIN PSI, V29, P523, DOI [10.24205/03276716.2020.272, DOI 10.24205/03276716.2020.272]
NR 82
TC 5
Z9 5
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39103
EP 39120
DI 10.1007/s11042-022-13085-7
EA APR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000794850900003
DA 2024-07-18
ER

PT J
AU García, JMC
   Piorno, JR
   Mata-García, MG
AF Carrera Garcia, Juan Manuel
   Recas Piorno, Joaquin
   Guijarro Mata-Garcia, Maria
TI Expert system design for vacant parking space location using automatic
   learning and artificial vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Machine learning; Neural network; Parking lot
   assistance
AB Finding a free parking space nowadays is a recurring problem in increasingly crowded public parking lots. The present study offers a solution that is based on the analysis of zenith images using artificial vision and is capable of automatically analyzing both the available spaces in the parking lot and their real-time occupancy. In an initial phase, the presented system semi-automatically detects the available parking spaces by filtering, thresholding, and carrying out a process of extracting the contour and approximating to a polygon the parking spaces of an empty parking lot. Once the size and location of the parking spaces have been mapped, the system is capable of detecting not only the presence of a vehicle in a parking space, but also the area of the parking space occupied by it with an accuracy of 98.21% using Region-based Convolutional Neural Networks. This feature allows the system to specify the appropriate parking space for a new vehicle entering the parking lot based on its specific dimensions and the correct location of the cars parked in the spaces adjacent to the free space.
C1 [Carrera Garcia, Juan Manuel; Recas Piorno, Joaquin; Guijarro Mata-Garcia, Maria] UCM Univ Complutense Madrid, Madrid, Spain.
RP Piorno, JR (corresponding author), UCM Univ Complutense Madrid, Madrid, Spain.
EM juanmcar@ucm.es; recas@ucm.es; mguijarro@ucm.es
RI Recas Piorno, Joaquin/I-8705-2014
OI Recas Piorno, Joaquin/0000-0001-9935-7496
FU CRUE-CSIC agreement; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature.
CR Acharya D., 2018, CEUR WORKSHOP PROC, V4, P33
   Al-Absi H. R. H., 2010, 2010 10th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA 2010), P757, DOI 10.1109/ISSPA.2010.5605408
   Almeida P, 2013, IEEE SYS MAN CYBERN, P3603, DOI 10.1109/SMC.2013.614
   Amato G, 2017, EXPERT SYST APPL, V72, P327, DOI 10.1016/j.eswa.2016.10.055
   [Anonymous], 2014, World Journal of Engineering and Technology, DOI [10.4236/wjet.2014.22006, DOI 10.4236/WJET.2014.22006]
   [Anonymous], 2014, 22 INT C CENTR EUR C
   [Anonymous], 2007, VACANT PARKING SPACE
   Blumer K, 2012, LECT NOTES COMPUT SC, V7667, P506, DOI 10.1007/978-3-642-34500-5_60
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Carrera Garcia JM, 2020, P 2020 SUMM SIM C
   Choeychuen K., 2012, 2012 International Joint Conference on Computer Science and Software Engineering (JCSSE 2012), P12, DOI 10.1109/JCSSE.2012.6261917
   Dan N., 2002, U.S. Patent, Patent No. [10/066,215, 10066215]
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   de Almeida PRL, 2015, EXPERT SYST APPL, V42, P4937, DOI 10.1016/j.eswa.2015.02.009
   Delibaltov D, 2013, IEEE INT C INTELL TR, P2387, DOI 10.1109/ITSC.2013.6728584
   Fabián T, 2008, SEVENTH INTERNATIONAL CONFERENCE ON COMPUTER INFORMATION SYSTEMS AND INDUSTRIAL MANAGEMENT APPLICATIONS, PROCEEDINGS, P165, DOI 10.1109/CISIM.2008.53
   Funck S, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P325
   del Postigo CG, 2015, IET INTELL TRANSP SY, V9, P835, DOI 10.1049/iet-its.2014.0090
   Vu HT, 2019, IEEE T CIRC SYST VID, V29, P1194, DOI 10.1109/TCSVT.2018.2826053
   Huang CC, 2015, IEEE ICCE, P314, DOI 10.1109/ICCE-TW.2015.7216918
   Huang CC, 2012, 2012 12TH INTERNATIONAL CONFERENCE ON ITS TELECOMMUNICATIONS (ITST-2012), P278
   Huang CC, 2010, IEEE T CIRC SYST VID, V20, P1770, DOI 10.1109/TCSVT.2010.2087510
   Jermsurawong J, 2012, 10TH INTERNATIONAL CONFERENCE ON FRONTIERS OF INFORMATION TECHNOLOGY (FIT 2012), P84, DOI 10.1109/FIT.2012.24
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li-Chih Chen, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P631, DOI 10.1109/IIHMSP.2010.160
   Liu JZ, 2013, IEEE I C ELECT CIRC, P933, DOI 10.1109/ICECS.2013.6815565
   Mármol E, 2016, MULTIMED TOOLS APPL, V75, P17711, DOI 10.1007/s11042-016-3773-8
   Nieto RM, 2019, IEEE T INTELL TRANSP, V20, P1069, DOI 10.1109/TITS.2018.2838128
   Masmoudi I, 2016, IET COMPUT VIS, V10, P407, DOI 10.1049/iet-cvi.2015.0227
   Masmoudi I, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P526
   Mateus PA, 2015, 2015 20TH SYMPOSIUM ON SIGNAL PROCESSING, IMAGES AND COMPUTER VISION (STSIVA)
   Mutlu A, 2019, TURK J ELECTR ENG CO, V27, P2344, DOI 10.3906/elk-1806-192
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Sastre RJL, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS, PROCEEDINGS, VOLS 1-8, P1675, DOI 10.1109/ISIE.2007.4374856
   Sevillano X, 2014, 2014 17TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION)
   Tschentscher M, 2015, IEEE IJCNN
   Wang XG, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P36, DOI 10.1109/ACV.1998.732855
   Wu Q, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P659
   Xie HH, 2015, PROCEEDINGS 2015 SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND ENGINEERING APPLICATIONS ISDEA 2015, P927, DOI 10.1109/ISDEA.2015.233
   Ying Wang, 2015, Image and Graphics. 8th International Conference, ICIG 2015. Proceedings: LNCS 9217, P516, DOI 10.1007/978-3-319-21978-3_45
NR 40
TC 3
Z9 3
U1 5
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38661
EP 38683
DI 10.1007/s11042-022-12906-z
EA APR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787139100001
PM 35493418
OA hybrid, Green Accepted, Green Published
DA 2024-07-18
ER

PT J
AU Huang, Z
   Li, YN
   Kong, J
AF Huang, Zheng
   Li, Yi-Na
   Kong, Jun
TI Investigating the multimedia pointing techniques in the tabletop-centric
   cross-device interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-device interaction; Human-computer interaction; Pointing
   technique; Tabletop
ID COLLABORATION; INFORMATION; AWARENESS
AB Group collaboration needs the support of a digital interaction system composed of a tabletop-centric shared display and individual operational physical cursors and mobile devices. We examine the usability of a fundamental function of the system, i.e., the pointing techniques. Direct pointing refers to the selection with a cursor placed on the target object, and proximity pointing requires the cursor nearby the target object. The empirical evidence from sixty-two participants shows that the direct pointing technique, although proved as the best choice in single device interaction, is inferior to proximity pointing in cross-device interaction in completion time and operation correctness. We also examine how the display for confirmation on mobile devices fits for pointing technique, discuss how users habituated to single device interaction adapt to cross-device interaction, and suggest guidelines for the design practice.
C1 [Huang, Zheng] Illinois Coll, Dept Math Comp Sci & Phys, Jacksonville, IL USA.
   [Li, Yi-Na] Univ Technol Sydney, Sch Comp Sci, Ultimo, Australia.
   [Kong, Jun] North Dakota State Univ, Dept Comp Sci, Fargo, ND USA.
C3 University of Technology Sydney; North Dakota State University Fargo
RP Li, YN (corresponding author), Univ Technol Sydney, Sch Comp Sci, Ultimo, Australia.
EM zheng.huang@ic.edu; yina.li@student.uts.edu.au; jun.kong@ndsu.edu
FU NSF [1722913]; Australian Government Research Training Program; CAUL;
   Div Of Information & Intelligent Systems; Direct For Computer & Info
   Scie & Enginr [1722913] Funding Source: National Science Foundation
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions. This work is supported by NSF under grant #1722913, an
   Australian Government Research Training Program.
CR [Anonymous], 2003, INTERACTIONS, DOI DOI 10.1145/586081.586086
   [Anonymous], 2010, ACM International Conference on Interactive Tabletops and Surfaces-ITS'10. Saarbr#252;cken, DOI [10.1145/1936652.1936676, DOI 10.1145/1936652.1936676]
   Baldauf M., 2013, P HUM FACT COMP SYST, P3015
   Baldauf M, 2014, INT J HUM-COMPUT INT, V30, P446, DOI 10.1080/10447318.2014.880142
   Ballagas R., 2005, CHI 05 CHI 05 EXTEND, P1200
   Baraldi S, 2008, MULTIMED TOOLS APPL, V38, P385, DOI 10.1007/s11042-007-0195-7
   Baudisch P., 2003, Proceedings of INTERACT, P57
   Boring S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2287
   Buxton William, 1986, P SIGCHI C HUM FACT, P321, DOI [10.1145/22627.22390, DOI 10.1145/22627.22390, 10.1145/22339.22390]
   Carley K.M., 1990, COORDINATING SUCCESS
   Douglas SarahA., 1999, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'99), P215, DOI DOI 10.1145/302979.303042
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Fujinami K, 2012, MULTIMED TOOLS APPL, V57, P269, DOI 10.1007/s11042-011-0759-4
   Greenberg S, 1996, PROC GRAPH INTERF, P28
   Greenberg S., 2011, Interactions, V18, P42, DOI [DOI 10.1145/1897239.1897250, 10.1145/1897239.1897250]
   Grossman Tovi., 2005, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. CHI '05, P281, DOI [10.1145/1054972.1055012, DOI 10.1145/1054972.1055012]
   Grubert J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3966, DOI 10.1145/3025453.3025533
   Gutwin C, 1999, 991 U SASK DEP COMP, P99
   Hardy Robert., 2008, Proceedings of the International Conference on Human-Computer Interaction with Mobile Devices Services, P245, DOI [10.1145/1409240.1409267, DOI 10.1145/1409240.1409267]
   Hopkins D, 1988, PIES IMPLEMENTATION
   Huang Z., 2016, P 9 INT S VISUAL INF, P67, DOI [10.1145/2968220.2968236, DOI 10.1145/2968220.2968236]
   Jin HJ, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P175, DOI 10.1145/2807442.2807485
   KABBASH P, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P417, DOI 10.1145/191666.191808
   Leung WH, 2003, MULTIMED TOOLS APPL, V20, P7, DOI 10.1023/A:1023466231968
   Marco J, 2016, MULTIMED TOOLS APPL, V75, P425, DOI 10.1007/s11042-014-2298-2
   Marquardt Nicolai, 2011, Proceedings of the 24th annual ACM symposium on User interface software and technology-UIST'11, P315, DOI 10.1145/2047196.2047238
   McCallum DC, 2009, UIST 2009: PROCEEDINGS OF THE 22ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P153
   Nancel Mathieu, 2013, P SIGCHI C HUM FACT, P831, DOI [10.1145/2470654.2470773, DOI 10.1145/2470654.2470773, 10.1145/2470654.24707731,2,3, DOI 10.1145/2470654.24707731,2,3]
   Nova N, 2007, MULTIMED TOOLS APPL, V32, P161, DOI 10.1007/s11042-006-0065-8
   Olwal A., 2009, Proc. TEI, P181, DOI [DOI 10.1145/1517664.1517705, 10.1145/1517664.1517705]
   Peng CY, 2009, MOBISYS'09: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P137
   Potter RichardLee., 1988, P SIGCHI C HUMAN FAC, P27
   Rekimoto J., 1999, P SIGCHI C HUMAN FAC, P378
   Roudaki A, 2014, P DMS
   Roudaki A, 2014, J VISUAL LANG COMPUT, V25, P727, DOI 10.1016/j.jvlc.2014.10.002
   Roudaut A., 2008, P WORKING C ADV VISU, P146, DOI DOI 10.1145/1385569.1385594
   Schmidt Dominik., 2012, P DESIGNING INTERACT, P318
   SOHLENKAMP ME, 1999, SUPPORTING GROUP AWA
   THOMPSON MC, 1973, J EXP PSYCHOL, V98, P49, DOI 10.1037/h0034308
   Twerdahl T, 2004, U.S. Patent Application, Patent No. [10/826,533, 10826533]
   Vogel D, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P657
NR 41
TC 0
Z9 0
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10077
EP 10098
DI 10.1007/s11042-022-12975-0
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000784679300005
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, ZL
   Guo, XY
   Xiang, SY
AF Li, Zenglu
   Guo, Xiaoyu
   Xiang, Songyang
TI Robust trimap optimization algorithm based on Superpixel Citation-KNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Matting; Optimize; Trimap; Citation-KNN
ID IMAGE; GENERATION
AB In this paper, we propose a trimap optimization method that can optimize manually created rough trimaps. Most matting algorithms require the user to intervene by using a trimap to generate an alpha mask from the input image. An accurate trimap guarantees a high-quality alpha mask. However, creating a trimap is undoubtedly a very tedious task, and a rough trimap will reduce the accuracy of the matting algorithm. We optimize the manually created trimap based on the local weighted Citation-KNN algorithm, which enables the matting method to obtain results quickly and accurately. The experiments performed show that the method proposed in this paper can better optimize rough trimap created by manual manipulation, thus improving the alpha mask estimation accuracy. We validate our results by replacing our optimized trimap with a manually created trimap while using the same image matting algorithm.
C1 [Li, Zenglu] Sanming Univ, Network Ctr, Informat Construct Off, 25 Jingdong Rd, Sanming 365001, Fujian, Peoples R China.
   [Guo, Xiaoyu] Sanming Univ, Sch Resources & Chem Engn, 25 Jingdong Rd, Sanming 365001, Fujian, Peoples R China.
   [Xiang, Songyang] Fuzhou Univ, Geog & Ecol Environm Res Ctr, 2 Gakyuan Rd, Fuzhou 350000, Fujian, Peoples R China.
C3 Sanming University; Sanming University; Fuzhou University
RP Guo, XY (corresponding author), Sanming Univ, Sch Resources & Chem Engn, 25 Jingdong Rd, Sanming 365001, Fujian, Peoples R China.
EM 20100131@fjsmu.edu.cn; 20161138@fjsmu.edu.cn; 205527048@fzu.edu.cn
CR Acevedo D, 2017, IBEROAMERICAN C PATT, P1
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   AGARWAL PK, 2018, ACM T ALGORITHMS, V14
   Aksoy Y, 2017, PROC CVPR IEEE, P228, DOI 10.1109/CVPR.2017.32
   Al-Kabbany A, 2015, PROC SPIE, V9410, DOI 10.1117/12.2083481
   Alelyani S, 2014, CH CRC DATA MIN KNOW, P29
   Amin B, 2021, IET IMAGE PROCESS, V15, P419, DOI 10.1049/ipr2.12032
   Amin B, 2020, IET IMAGE PROCESS, V14, P1628, DOI 10.1049/iet-ipr.2019.0067
   [Anonymous], 2014, INT J MACHINE INTELL, DOI [10.1504/ijmissp.2014.066425, DOI 10.1504/IJMISSP.2014.066425]
   Cai SF, 2019, IEEE I CONF COMP VIS, P8818, DOI 10.1109/iccv.2019.00891
   Chen QF, 2013, IEEE T PATTERN ANAL, V35, P2175, DOI 10.1109/TPAMI.2013.18
   Cho D, 2017, IEEE T PATTERN ANAL, V39, P1504, DOI 10.1109/TPAMI.2016.2606397
   Cho D, 2016, LECT NOTES COMPUT SC, V9906, P626, DOI 10.1007/978-3-319-46475-6_39
   Chuang YY, 2001, PROC CVPR IEEE, P264
   Dai, 2020, ARXIV201114288
   Ding JR, 2015, OPTIK, V126, P5188, DOI 10.1016/j.ijleo.2015.09.231
   Gastal ESL, 2010, COMPUT GRAPH FORUM, V29, P575, DOI 10.1111/j.1467-8659.2009.01627.x
   Ghosh D, 2015, 2015 IEEE INT C FUZZ, P1
   Guillaumin M, 2010, LECT NOTES COMPUT SC, V6311, P634, DOI 10.1007/978-3-642-15549-9_46
   Gupta V, 2016, 2016 INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (ICONSIP)
   He K., 2011, CVPR, P2049, DOI DOI 10.1109/CVPR.2011.5995495
   He KM, 2010, PROC CVPR IEEE, P2165, DOI 10.1109/CVPR.2010.5539896
   Hou QQ, 2019, IEEE I CONF COMP VIS, P4129, DOI 10.1109/ICCV.2019.00423
   Hsieh CL, 2013, ASIAPAC SIGN INFO PR
   Hu H, 2016, KNOWL-BASED SYST, V102, P51, DOI 10.1016/j.knosys.2016.03.018
   Huttenlocher D. P., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P654, DOI 10.1109/CVPR.1992.223209
   Jiang LX, 2014, INT J MACH LEARN CYB, V5, P193, DOI 10.1007/s13042-013-0152-x
   Kahn JM, 2007, J CRIT CARE, V22, P97, DOI 10.1016/j.jcrc.2006.09.003
   Katsamanis A, 2011, LECT NOTES COMPUT SC, V6974, P145, DOI 10.1007/978-3-642-24600-5_18
   Kyurkchiev N, 2016, J MATH CHEM, V54, P109, DOI 10.1007/s10910-015-0552-0
   Lee P., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2193, DOI 10.1109/CVPR.2011.5995665
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P1699, DOI 10.1109/TPAMI.2008.168
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li C, 2017, COMPUT VIS IMAGE UND, V162, P34, DOI 10.1016/j.cviu.2017.06.011
   Li HX, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13081454
   Li YY, 2020, AAAI CONF ARTIF INTE, V34, P11450
   Lin SC, 2021, PROC CVPR IEEE, P8758, DOI 10.1109/CVPR46437.2021.00865
   Lu H, 2019, IEEE I CONF COMP VIS, P3265, DOI 10.1109/ICCV.2019.00336
   Lutz S., 2018, BMVC
   Melendez J, 2015, IEEE T MED IMAGING, V34, P179, DOI 10.1109/TMI.2014.2350539
   Qiao Y, 2020, P IEEE CVF C COMP VI, P13676
   Quellec Gwenole, 2017, IEEE Rev Biomed Eng, V10, P213, DOI 10.1109/RBME.2017.2651164
   Rhemann C., 2008, P BRIT MACHINE VISIO, P1155
   Rhemann C, 2009, PROC CVPR IEEE, P1826, DOI 10.1109/CVPRW.2009.5206503
   Sengupta S, 2020, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR42600.2020.00236
   Shahrian E, 2013, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2013.88
   Shahrian E, 2012, PROC CVPR IEEE, P718, DOI 10.1109/CVPR.2012.6247741
   Shen X, 2016, LECT NOTES COMPUT SC, V9905, P92, DOI 10.1007/978-3-319-46448-0_6
   Sudharshan PJ, 2019, EXPERT SYST APPL, V117, P103, DOI 10.1016/j.eswa.2018.09.049
   Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721
   Tang H, 2019, IEEE IMAGE PROC, P4255, DOI [10.1109/icip.2019.8803682, 10.1109/ICIP.2019.8803682]
   Tang JW, 2019, PROC CVPR IEEE, P3050, DOI 10.1109/CVPR.2019.00317
   VEZHNEVETS A, 2010, PROC CVPR IEEE, P3249, DOI DOI 10.1109/CVPR.2010.5540060
   Villar P, 2016, IEEE INT FUZZY SYST, P946, DOI 10.1109/FUZZ-IEEE.2016.7737790
   Wang J, 2005, IEEE I CONF COMP VIS, P936
   WANG JQ, 2001, 17 INT C MACH LEARN, P1119
   Wang J, 2007, PROC CVPR IEEE, P281
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei XS, 2014, IEEE DATA MINING, P1037, DOI 10.1109/ICDM.2014.16
   Xu CW, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/ab857d
   Xu N, 2017, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.2017.41
   Yang S, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P67, DOI 10.1145/3269206.3271787
   Yao GL, 2021, INFORM SCIENCES, V580, P720, DOI 10.1016/j.ins.2021.08.058
   Zhang YK, 2019, PROC CVPR IEEE, P7461, DOI 10.1109/CVPR.2019.00765
   Zheng YJ, 2009, IEEE I CONF COMP VIS, P889, DOI 10.1109/ICCV.2009.5459326
   Zhou FF, 2021, IEEE T CIRC SYST VID, V31, P2192, DOI 10.1109/TCSVT.2020.3024213
NR 66
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33483
EP 33511
DI 10.1007/s11042-022-12469-z
EA APR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784913600001
DA 2024-07-18
ER

PT J
AU Sailunaz, K
   Kawash, J
   Alhajj, R
AF Sailunaz, Kashfia
   Kawash, Jalal
   Alhajj, Reda
TI Tweet and user validation with supervised feature ranking and rumor
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media; Twitter; Classification; Rumors; Ranking; Support vector
   machine; Naive bayes; Random forest; Logistic regression; CNN; And LSTM
AB Filtering fake news from social network posts and detecting social network users who are responsible for generating and propagating these rumors have become two major issues with the increased popularity of social networking platforms. As any user can post anything on social media and that post can instantly propagate to all over the world, it is important to recognize if the post is rumor or not. Twitter is one of the most popular social networking platforms used for news broadcasting mostly as tweets and retweets. Hence, validating tweets and users based on their posts and behavior on Twitter has become a social, political and international issue. In this paper, we proposed a method to classify rumor and non-rumor tweets by applying a novel tweet and user feature ranking approach with Decision Tree and Logistic Regression that were applied on both tweet and user features extracted from a benchmark rumor dataset 'PHEME'. The effect of the ranking model was then shown by classifying the dataset with the ranked features and comparing them with the basic classifications with various combination of features. Both supervised classification algorithms (namely, Support Vector Machine, Naive Bayes, Random Forest and Logistic Regression) and deep learning algorithms (namely, Convolutional Neural Network and Long Short-Term Memory) were used for rumor detection. The classification accuracy showed that the feature ranking classification results were comparable to the original classification performances. The ranking models were also used to list the topmost tweets and users with different conditions and the results showed that even if the features were ranked differently by LR and RF, the topmost results for tweets and users for both rumors and non-rumors were the same.
C1 [Sailunaz, Kashfia; Kawash, Jalal; Alhajj, Reda] Univ Calgary, Dept Comp Sci, Calgary, AB, Canada.
   [Alhajj, Reda] Istanbul Medipol Univ, Dept Comp Engn, Istanbul, Turkey.
   [Alhajj, Reda] Univ Southern Denmark, Dept Heath Informat, Odense, Denmark.
C3 University of Calgary; Istanbul Medipol University; University of
   Southern Denmark
RP Alhajj, R (corresponding author), Univ Calgary, Dept Comp Sci, Calgary, AB, Canada.; Alhajj, R (corresponding author), Istanbul Medipol Univ, Dept Comp Engn, Istanbul, Turkey.; Alhajj, R (corresponding author), Univ Southern Denmark, Dept Heath Informat, Odense, Denmark.
EM alhajj@ucalgary.ca
CR Ahsan M., 2019, INT J ADV SCI TECHNO, V128, P45, DOI DOI 10.33832/IJAST.2019.128.05
   ALLPORT GW, 1945, T NEW YORK ACAD SCI, V8, P61, DOI 10.1111/j.2164-0947.1945.tb00216.x
   Arya A, 2018, P PERS PER TECHN WOR
   Ben Veyseh AP, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P113, DOI 10.1145/3341161.3342896
   Castillo C., 2011, P 20 INT C WORLD WID, P675, DOI DOI 10.1145/1963405.1963500
   Cresci S, 2019, ACM T WEB, V13, DOI 10.1145/3313184
   Dayani R, 2015, IEEE I C ADV NETW TE
   Gupta A, 2012, PSOSM 12 P 1 WORKSH
   Hamidian S., 2019, ARXIV191208926
   Hamidian Sardar., 2016, Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, P3, DOI [10. 18653/v1/W16-0403, DOI 10.18653/V1/W16-0403]
   Hassan NY, 2018, PROCEEDINGS OF 2018 13TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), P196, DOI 10.1109/ICCES.2018.8639315
   Hernandez E, 2018, IEEE POTENTIALS, V37, P25, DOI 10.1109/MPOT.2016.2578966
   Kim Y, 2016, ONLINE INFORM REV, V40, P42, DOI 10.1108/OIR-03-2015-0068
   Knapp RH, 1944, PUBLIC OPIN QUART, V8, P22, DOI 10.1086/265665
   Kochkina E, 2018, FIGSHARE
   Kochkina E., 2018, P 27 INT C COMP LING, P3402, DOI [10.48550/arXiv.1806.03713, DOI 10.48550/ARXIV.1806.03713]
   Kostka J, 2008, LECT NOTES COMPUT SC, V5058, P185, DOI 10.1007/978-3-540-69355-0_16
   Li PY, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P6542
   Li PY, 2018, LECT NOTES COMPUT SC, V11233, P145, DOI 10.1007/978-3-030-02922-7_10
   Mondal T, 2019, ICDCN '19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING AND NETWORKING, P381, DOI 10.1145/3288599.3295581
   Oberlo, 10 TWITT STAT EV MAR
   Page L., 1999, PAGERANK CITATION RA, DOI DOI 10.1109/IISWC.2012.6402911
   Park S, 2016, J TRAVEL TOUR MARK, V33, P885, DOI 10.1080/10548408.2015.1071688
   Pathak AR, 2020, PROCEDIA COMPUT SCI, V167, P2286, DOI 10.1016/j.procs.2020.03.281
   Peterson WA, 1951, AM J SOCIOL, V57, P159, DOI 10.1086/220916
   Pitsilis GK, 2016, ARXIV PREPRINT ARXIV
   Rath Bhavtosh, 2017, ACM, P179, DOI [DOI 10.1145/3110025.3110121, 10.1145/3110025.3110121]
   Ravikumar S., 2012, P 9 INT WORKSH INF I, P1
   Ravikumar S, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2345, DOI 10.1145/2505515.2505667
   Ross J, 2016, 2016 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), P18, DOI [10.1109/CTS.2016.0023, 10.1109/CTS.2016.21]
   Sailunaz K, 2019, J COMPUT SCI-NETH, V36, DOI 10.1016/j.jocs.2019.05.009
   Sicilia R, 2018, EXPERT SYST APPL, V110, P33, DOI 10.1016/j.eswa.2018.05.019
   Singh J, 2022, IETE J RES, V68, P4310, DOI 10.1080/03772063.2020.1791745
   Statista, NUMB SOC NETW US WOR
   Takahashi T, 2012, JOINT INT CONF SOFT, P452, DOI 10.1109/SCIS-ISIS.2012.6505254
   Thakur HK, 2018, INT J INF RETR RES, V8, P1, DOI 10.4018/IJIRR.2018070101
   Twitter Inc, Twitter
   Waskale PM, 2019, INT J SCI RES ENG TR, V5
   Weng J., 2010, P 3 ACM INT C WEB SE, P261, DOI [10.1145/1718487.1718520, DOI 10.1145/1718487.1718520]
   Zamani S, 2017, IRAN CONF ELECTR ENG, P1532, DOI 10.1109/IranianCEE.2017.7985287
   Zhang Q, 2015, LECT NOTES ARTIF INT, V9362, P113, DOI 10.1007/978-3-319-25207-0_10
   Zubiaga A., 2016, P COLING 2016 26 INT, P2438
   Zubiaga A, 2016, FIGSHARE
NR 43
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31907
EP 31927
DI 10.1007/s11042-022-12616-6
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781124000016
DA 2024-07-18
ER

PT J
AU Choong, KH
   Basah, SN
   Yazid, H
   Safar, MJA
   Saad, FSA
   Lim, CC
AF Choong, Kar Heng
   Basah, Shafriza Nisha
   Yazid, Haniza
   Safar, Muhammad Juhairi Aziz
   Saad, Fathinul Syahir Ahmad
   Lim, Chee Chin
TI Performance analysis of multi-level thresholding for microaneurysm
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Otsu's thresholding; Multi-level thresholding; Monte Carlo statistical
   analysis; Diabetic retinopathy; Microaneurysm
ID SEGMENTATION
AB Diabetic retinopathy (DR) - one of the diabetes complications - is the leading cause of blindness among the age group of 20-74 years old. Fortunately, 90% of these cases (blindness due to DR) could be prevented by early detection and treatment via manual and regular screening by qualified physicians. The screening of DR is tedious, which can be subjective, time-consuming, and sometimes prone to misclassification. In terms of accuracy and time, many automated screening systems based on image processing have been developed to improve diagnostic performance. However, the accuracy and consistency of the developed systems are largely unaddressed, where a manual screening process is still the most preferred option. The main contribution of this paper is to analyse the accuracy and consistency of microaneurysm (MA) detection via image processing by focusing on Otsu's multi-thresholding as it has been shown to work very well in many applications. The analysis was based on Monte Carlo statistical analysis using synthetic retinal images of retinal images under variation of all stages of DR, retinal, and image parameters - intensity difference between MAs and blood vessels (BVs), MA size, and measurement noise. Then, the conditions - in terms of obtainable retinal and image parameters - that guarantee accurate and consistent MA detection via image processing were extracted. Finally, the validity of the conditions to guarantee accurate and consistent MA detection was verified using real retinal images. The results showed that MA detection via image processing is guaranteed to be accurate and consistent when the intensity difference between MAs and BVs is at least 50% and the sizes of MAs are from 5 to 20 pixels depending on measurement noise values. These conditions are very important as a guideline of MA detection for DR.
C1 [Choong, Kar Heng; Basah, Shafriza Nisha; Safar, Muhammad Juhairi Aziz; Saad, Fathinul Syahir Ahmad] Univ Malaysia Perlis, Fac Elect Engn Technol, Arau 02600, Perlis, Malaysia.
   [Yazid, Haniza; Lim, Chee Chin] Univ Malaysia Perlis, Fac Elect Engn Technol, Perlis 02600, Arau, Malaysia.
C3 Universiti Malaysia Perlis; Universiti Malaysia Perlis
RP Choong, KH (corresponding author), Univ Malaysia Perlis, Fac Elect Engn Technol, Arau 02600, Perlis, Malaysia.
EM kingsleychoong96@gmail.com; shafriza@unimap.edu.my;
   hanizayazid@unimap.edu.my; juhairi@unimap.edu.my;
   fathinul@unimap.edu.my; cclim@unimap.edu.my
RI Lim, Chee Chin/GNO-9181-2022; Ahmad Saad, Fathinul Syahir/R-5360-2019;
   Yazid, Haniza/D-3830-2015
OI Ahmad Saad, Fathinul Syahir/0000-0002-4322-400X; 
FU Fundamental Research Grant Scheme (FRGS)
   [FRGS/1/2019/ICT02/UNIMAP/02/3]; Ministry of Education Malaysia
FX The authors would like to acknowledge the support from the Fundamental
   Research Grant Scheme (FRGS) under the grant number of
   FRGS/1/2019/ICT02/UNIMAP/02/3 from the Ministry of Education Malaysia.
CR Ajaz A, 2017, IEEE ENG MED BIO, P356, DOI 10.1109/EMBC.2017.8036836
   Cervera MMA, 2016, 2016 13TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, COMPUTING SCIENCE AND AUTOMATIC CONTROL (CCE)
   Amin J, 2016, SCIENTIFICA, V2016, DOI 10.1155/2016/6838976
   [Anonymous], 2018, INT J ENG TECHNOL
   Bangare S. L., 2015, International Journal of Applied Engineering Research, V10, P21777, DOI [10.37622/IJAER/10.9.2015.21777-21783, DOI 10.37622/IJAER/10.9.2015.21777-21783]
   Basah S, 2008, 2008 DIGITAL IMAGE C
   Basah SN, 2009, IET COMPUT VIS, V3, P189, DOI 10.1049/iet-cvi.2009.0030
   Basah SN, 2014, IET COMPUT VIS, V8, P658, DOI 10.1049/iet-cvi.2013.0224
   Basah SN, 2009, LECT NOTES COMPUT SC, V5716, P82, DOI 10.1007/978-3-642-04146-4_11
   Cao W, 2018, IEEE T NANOBIOSCI, V17, P191, DOI 10.1109/TNB.2018.2840084
   Carrera EV, 2017, PROCEEDINGS OF THE 2017 IEEE XXIV INTERNATIONAL CONFERENCE ON ELECTRONICS, ELECTRICAL ENGINEERING AND COMPUTING (INTERCON), DOI 10.1109/INTERCON.2017.8079692
   Carrillo C, 2019, IEEE INT AUT MEET, DOI 10.1109/ropec48299.2019.9057034
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Cunha LP, 2018, FRONT ENDOCRINOL, V9, DOI 10.3389/fendo.2018.00251
   Dai L, 2018, IEEE T MED IMAGING, V37, P1149, DOI 10.1109/TMI.2018.2794988
   Decencière E, 2013, IRBM, V34, P196, DOI 10.1016/j.irbm.2013.01.010
   Deng, 2011, 2011 INT C COMP MAN, P1, DOI DOI 10.1109/CAMAN.2011.5778757
   Goh TY, 2018, MEASUREMENT, V114, P298, DOI 10.1016/j.measurement.2017.09.052
   Hazra, 2016, EXUDATES DETECTION R, V5, P615
   Hoseinnezhad R, 2010, J MATH IMAGING VIS, V37, P66, DOI 10.1007/s10851-010-0193-7
   Kumar S, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P359, DOI 10.1109/SPIN.2018.8474264
   Mazlan N, J TELECOMM ELECT COM, V10, P37
   Mazlan N, 2020, J MED BIOL ENG, V40, P292, DOI 10.1007/s40846-020-00509-8
   MOH, 2011, SCREEN DIAB RET
   Priya MS, 2017, MULTILEVEL IMAGE THR, V8, P101
   Qiao LF, 2020, IEEE ACCESS, V8, P104292, DOI 10.1109/ACCESS.2020.2993937
   Qureshi I, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11060749
   Richa R, 2014, IEEE T MED IMAGING, V33, P1304, DOI 10.1109/TMI.2014.2309440
   Shanthi T, 2019, COMPUT ELECTR ENG, V76, P56, DOI 10.1016/j.compeleceng.2019.03.004
   Siddhu MK, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P416, DOI 10.1109/iccisci.2019.8716395
   Sigut J, 2015, OVERAND UNDER SEGMEN, P83
   Sudhan, 2017, OPTIC DISC SEGMENTAT
   Wang SZ, 2016, IEEE T MED IMAGING, V35, P1046, DOI 10.1109/TMI.2015.2506902
NR 33
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 31161
EP 31180
DI 10.1007/s11042-021-11808-w
EA APR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000781336500001
DA 2024-07-18
ER

PT J
AU Regouid, M
   Touahria, M
   Benouis, M
   Mostefai, L
   Lamiche, I
AF Regouid, Meryem
   Touahria, Mohamed
   Benouis, Mohamed
   Mostefai, Lotfi
   Lamiche, Imane
TI Comparative study of 1D-local descriptors for ear biometric system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric system; Ear recognition; 1D-LBP techniques; Handcrafted
   feature
ID LOCAL BINARY PATTERNS; FEATURE-EXTRACTION; RECOGNITION; CLASSIFICATION
AB As an important modality for human identification, Ear based biometric has achieved a relatively mature level of development, as it faces higher challenges surrounded by the real-world applications of biometric technology. One such challenge is extracting a unique template that leads to making a reliable identification task. In the most existing ear biometric approaches, the features were calculated from the 2D and 3D images. In the presented work, we have well investigated the performance of 1D-LBP and its variations (i.e., standard 1D-LBP, shifted-1D-LBP, 1D-Multi-Resolution-LBP, Local Centroid Pattern, Local Ternary Pattern, Local neighbor gradient pattern and 1D-Noise-tolerant local binary pattern) on ear recognition. Typically, the 1D-LBP treats the ear image as a 1D vector where the histograms of the produced image are then used as features to describe a human ear. The experimental results show that the LBP's in 1D is promising in developing a robust handcrafted feature for ear recognition.
C1 [Regouid, Meryem; Touahria, Mohamed] Mohamed El Bachir El Ibrahimi Univ, Comp Sci Dept, Bordj Bou Arreridj 34000, Algeria.
   [Benouis, Mohamed] Univ Msila, Comp Sci Dept, Msila, Algeria.
   [Mostefai, Lotfi] Moulay Tahar Univ Saida, LGE Genie Electrotech Lab, Elect Engn, 138 En Nasr, Saida 20000, Algeria.
   [Lamiche, Imane] Northwestern Polytech Univ, 127 YouYi XiLu, Xian 710072, Shaanxi, Peoples R China.
C3 Universite de M'sila; Northwestern Polytechnical University
RP Regouid, M (corresponding author), Mohamed El Bachir El Ibrahimi Univ, Comp Sci Dept, Bordj Bou Arreridj 34000, Algeria.
EM mregouid@yahoo.com; mohamed.touahria@univ-setif.dz;
   mohamed.benouis@univ-msila.dz; latyfo@gmail.com; stic0303@gmail.com
RI Mostefai, Lotfi/HTS-7318-2023
OI , Lotfi/0000-0002-3066-0443; Benouis, Mohamed/0000-0002-9107-9329
CR Alagarsamy SB, 2020, MULTIMED TOOLS APPL, V79, P10445, DOI 10.1007/s11042-019-7418-6
   Annapurani K, 2015, EXPERT SYST APPL, V42, P649, DOI 10.1016/j.eswa.2014.08.009
   Anwar AS, 2015, PROCEDIA COMPUT SCI, V65, P529, DOI 10.1016/j.procs.2015.09.126
   Arbab-Zavar B, 2008, INT C PATT RECOG, P2735
   Benzaoui A, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.4.043109
   Benzaoui A, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.5.053008
   Bertillon Alphonse., 1890, PHOTOGRAPHIE JUDICIA
   Boodoo-Jahangeer NB, 2013, IEEE INT C BIOINF BI
   Chatlani N, 2010, EUR SIGNAL PR CONF, P95
   Doghmane H, 2019, INT J BIOMETRICS, V11, P50, DOI 10.1504/IJBM.2019.10016808
   Emersic Z, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P715, DOI 10.1109/BTAS.2017.8272761
   Emersic Z, 2017, NEUROCOMPUTING, V255, P26, DOI 10.1016/j.neucom.2016.08.139
   Ertugrul ÖF, 2016, EXPERT SYST APPL, V56, P156, DOI 10.1016/j.eswa.2016.03.018
   Fadaei S, 2017, SIGNAL PROCESS, V137, P274, DOI 10.1016/j.sigpro.2017.02.013
   Ghoualmi L, 2015, ADV INTELL SYST, V370, P37, DOI 10.1007/978-3-319-21206-7_4
   Gonzalez E., 2008, AMI EAR DATABASE
   Hassaballah M, 2020, MULTIMED TOOLS APPL, V79, P31183, DOI 10.1007/s11042-020-09456-7
   Hassaballah M, 2019, EXPERT SYST APPL, V118, P182, DOI 10.1016/j.eswa.2018.10.007
   Houam L, 2010, LECT NOTES COMPUT SC, V6474, P105, DOI 10.1007/978-3-642-17688-3_11
   Hu HW, 2018, NONDESTRUCT TEST EVA, V33, P92, DOI 10.1080/10589759.2017.1299732
   Iannerelli A., 1989, EAR IDENTIFICATION F
   Jahangeer NB, 2009, ARXIV09120955
   Jain AK, 2007, Handbook of biometrics, DOI DOI 10.1007/978-0-387-71041-9
   Jaiswal AK, 2018, J MED BIOL ENG, V38, P222, DOI 10.1007/s40846-017-0286-5
   Karaboga D., 2005, Technical Report-TR06
   Kaya Y, 2018, AUSTRALAS PHYS ENG S, V41, P721, DOI 10.1007/s13246-018-0669-0
   Kaya Y, 2014, APPL MATH COMPUT, V243, P209, DOI 10.1016/j.amc.2014.05.128
   Kylberg G, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-17
   Liu YH, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0166204
   Louis W, 2014, INT CONF DIGIT SIG, P601, DOI 10.1109/ICDSP.2014.6900735
   Lu SY, 2021, NEURAL COMPUT APPL, V33, P10799, DOI 10.1007/s00521-020-05082-4
   Mehraj H, 2020, 2020 INTERNATIONAL CONFERENCE ON EMERGING SMART COMPUTING AND INFORMATICS (ESCI), P357, DOI [10.1109/esci48226.2020.9167641, 10.1109/ESCI48226.2020.9167641]
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pflug A, 2012, IET BIOMETRICS, V1, P114, DOI 10.1049/iet-bmt.2011.0003
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Radhika K., 2020, Nature inspired computing for data science, P57
   Regouid M, 2018, INT S MOD IMPL COMPL, P168, DOI [DOI 10.1007/978-3-030-05481-6_13, 10.1007/ 978-3-030-05481-6_13]
   Regouid M, 2019, MULTIMED TOOLS APPL, V78, P22509, DOI 10.1007/s11042-019-7467-x
   Sairamya NJ, 2018, AUSTRALAS PHYS ENG S, V41, P1029, DOI 10.1007/s13246-018-0697-9
   Sepas-Moghaddam A, 2018, IET BIOMETRICS, V7, P224, DOI 10.1049/iet-bmt.2017.0204
   Tabatabaei SM, 2019, SIGNAL IMAGE VIDEO P, V13, P491, DOI 10.1007/s11760-018-1374-x
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tirunagari S, 2017, INT CONF DIGIT SIG
   Wang SH, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5130
   Watabe D., 2009, INT J INTELLIGENT CO, V3, P9, DOI DOI 10.1080/1931308X.2009.10644168
   Xiao-Bin Huang, 2015, 2015 Asia-Pacific Microwave Conference (APMC). Proceedings, P1, DOI 10.1109/APMC.2015.7413025
   Yan P., 2005, Advanced 3D Ima in for Safet and Securit, VIII, P121
   Youbi Z, 2016, 2016 39TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P685, DOI 10.1109/TSP.2016.7760971
   Yuan L, 2004, EAR RECOGINITION LAB
NR 49
TC 5
Z9 5
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29477
EP 29503
DI 10.1007/s11042-022-12700-x
EA APR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000778057700004
DA 2024-07-18
ER

PT J
AU Li, MX
   Zhou, GX
   Li, ZC
AF Li, Mingxuan
   Zhou, Guoxiong
   Li, Zongchen
TI Fast recognition system forTree images based on dual-task Gabor
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tree image recognition; Image cleaning; Gabor filter; Dual-task CNN
AB Aiming at the difficult problem of complex extraction for tree image in the existing complex background, we took tree species as the research object and proposed a fast recognition system solution for tree image based on Caffe platform and Dual-Task Gabor Convolutional Neural Network. In the research of deep learning algorithms based on Caffe framework, the improved Dual-Task CNN model (DCNN) is applied to train the image extractor and classifier to accomplish the dual tasks of image cleaning and tree classification. In addition, when compared with the traditional classification methods represented by Support Vector Machine (SVM) and Single-Task CNN model, Dual-Task CNN model demonstrates its superiority in classification performance. Then, for further improvement to the recognition accuracy for similar species, Gabor kernel was introduced to extract the features of frequency domain for images in different scales and directions, so as to enhance the texture features of leaf images and improve the recognition effect. The improved model was tested on the data sets of similar species. As demonstrated by the results, the improved deep Gabor Dual-Task convolutional neural network (GCNN) is advantageous in tree recognition and similar tree classification when compared with the order Dual-Task CNN classification method. Finally, the recognition results of trees can be displayed on the application graphical interface as well. Dual-Task Gabor CNN can be applied to mobile programs based on Ubantu, Android, IOS and other systems. The deep learning model used to identify tree species images can be deployed on the server side, and mobile devices can read and search for tree species images through network connections.
C1 [Li, Mingxuan; Zhou, Guoxiong; Li, Zongchen] Cent South Univ Forestry AndTechnol, Coll Comp & Informat Engn, Changsha 410004, Peoples R China.
RP Zhou, GX (corresponding author), Cent South Univ Forestry AndTechnol, Coll Comp & Informat Engn, Changsha 410004, Peoples R China.
EM zhougx01@163.com
OI Zhou, Guoxiong/0000-0002-5142-4845
FU National Natural Science Foundation in China [61703441]
FX This work was supported by the National Natural Science Foundation in
   China (Grant Nos. 61703441).
CR Acnet, 2019, 2019 IEEE INT C IM P
   [Anonymous], 2008, PROC INT C MACHINE L
   Arun Priya C., 2012, Proceedings of the 2012 International Conference on Pattern Recognition, Informatics and Medical Engineering (PRIME), P428, DOI 10.1109/ICPRIME.2012.6208384
   Bhattacharya R, FINE TUNING CAFFE NE
   Byng JW, 2016, BOT J LINN SOC, V181, P1, DOI [10.1111/boj.12385, 10.1111/j.1095-8339.2009.00996.x]
   [常亮 Chang Liang], 2016, [自动化学报, Acta Automatica Sinica], V42, P1300
   Cronquist A., 1981, INTEGRATED SYSTEM CL
   Davidson E. M., 2006, 2006 IEEE Power Engineering Society General Meeting, DOI 10.1109/CNNA.2006.341621
   Dinuls R, 2012, IEEE J-STARS, V5, P594, DOI 10.1109/JSTARS.2012.2196978
   Du JX, 2007, APPL MATH COMPUT, V185, P883, DOI 10.1016/j.amc.2006.07.072
   Guo M, 2018, LECT NOTES COMPUT SC, V11220, P282, DOI 10.1007/978-3-030-01270-0_17
   Han S, 2015, ADV NEUR IN, V28
   Hou T., 2009, HUNAN AGR SCI, V39, P123
   Hu Y, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P386, DOI 10.1109/ICISCE.2016.91
   Ii A., 2003, BOT J LINN SOC, V141, P399, DOI 10.1046/j.1095-8339.2003.t01-1-00158.x
   Kang L, 2015, IEEE IMAGE PROC, P2791, DOI 10.1109/ICIP.2015.7351311
   Korpusik M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6174, DOI 10.1109/ICASSP.2018.8461769
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee SH, 2015, IEEE IMAGE PROC, P452, DOI 10.1109/ICIP.2015.7350839
   Lindenmayer DB, 2000, CONSERV BIOL, V14, P941, DOI 10.1046/j.1523-1739.2000.98533.x
   Liu JD, 2009, LECT NOTES COMPUT SC, V5754, P253
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Liu X.-S., 2017, INORGANIC PHOTOCHEMI, P143, DOI [10.1016/B978-0-444-63591-4.00006-9, DOI 10.1016/B978-0-444-63591-4.00006-9]
   Ning X, 2020, IEEE SIGNAL PROC LET, V27, P1944, DOI 10.1109/LSP.2020.3032277
   Ning X, 2017, IEICE T INF SYST, VE100D, P211, DOI 10.1587/transinf.2016EDL8180
   Panchapagesan S, 2016, INTERSPEECH, P760, DOI 10.21437/Interspeech.2016-1485
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Reyes A.K., 2015, CLEF
   Sarwar SS, 2017, I SYMPOS LOW POWER E
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sindagi VA, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Tyrvainen L., 2005, URBAN FORESTS TREES, P81, DOI DOI 10.1007/3-540-27684-X5
   Victorino J., 2003, P INT C COMPUT INTEL
   Wu Stephen Gang, 2007, 2007 IEEE International Symposium on Signal Processing and Information Technology, P11, DOI 10.1109/ISSPIT.2007.4458016
   Yang XB, 2020, IEEE ACCESS, V8, P151555, DOI 10.1109/ACCESS.2020.3017560
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang Yu Zhang Yu, 2018, Journal of Landscape Research, V10, P159
   Zhou H, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON VIDEO AND IMAGE PROCESSING (ICVIP 2017), P56, DOI 10.1145/3177404.3177433
NR 39
TC 3
Z9 3
U1 4
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28607
EP 28631
DI 10.1007/s11042-022-12963-4
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777375900005
DA 2024-07-18
ER

PT J
AU Jha, R
AF Jha, Rohini
TI A novel hybrid intelligent technique to enhance customer relationship
   management in online food delivery system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Customer relationship management; African buffalo optimization;
   Artificial intelligence; Swiggy database; Customer review
ID SATISFACTION
AB Customer Relationship Management (CRM) has gained more attention due to customer satisfaction based on management decisions. However, customer review maintenance is challenging in the management field because of the structured and unstructured data. This paper proposes a novel Generalized Savitzky-Golay Filter (GS-GF) and Hybrid Self Constructing Neural Fuzzy based African Buffalo Optimization (HSCFN-ABO) techniques for maintaining customer reviews; the customer's reaction may be positive, negative, or neutral. This novel technique provides a solution for classifying customer comments based on the specified problem, including food quality, food delivery, and payment issues. Initially, pre-processing and feature extraction is performed using the novel GS-GF approach. Once the features are extracted from the dataset, they enter the classification layer to value customer reviews using the novel HSCFN-ABO replica. The execution of this research is done using the MATLAB R2018b platform. The proposed HSCFN-ABO classifier method in CRM is tested using the real dataset from swiggy. CRM performance for customer review data using the proposed technique is validated with different case studies. Furthermore, the projected HSCFN-ABO method is compared with various other traditional methods in terms of accuracy, precision, and F measure, proving the significance of the HSCFN-ABO classifier in CRM applications.
C1 [Jha, Rohini] BIT, Dept Management, Mesra Campus, Ranchi 835215, Jharkhand, India.
C3 Birla Institute of Technology Mesra
RP Jha, R (corresponding author), BIT, Dept Management, Mesra Campus, Ranchi 835215, Jharkhand, India.
EM rohinijha@bitmesra.ac.in
CR Akerkar R., 2019, Artificial Intelligence for Business. SpringerBriefs in Business, DOI [10.1007/978-3-319-97436-11, DOI 10.1007/978-3-319-97436-11]
   Al-Fedaghi S, 2019, 2019 IEEE 2ND INTERNATIONAL CONFERENCE ON INFORMATION AND COMPUTER TECHNOLOGIES (ICICT), P235, DOI [10.1109/infoct.2019.8710891, 10.1109/INFOCT.2019.8710891]
   Al-Qudah DA, 2020, IEEE ACCESS, V8, P189930, DOI 10.1109/ACCESS.2020.3032216
   Asif M, 2020, TELEMAT INFORM, V48, DOI 10.1016/j.tele.2020.101345
   Basak S, 2019, N AM J ECON FINANC, V47, P552, DOI 10.1016/j.najef.2018.06.013
   Capuano N, 2021, APPL INTELL, V51, P3339, DOI 10.1007/s10489-020-01984-x
   Choi SB, 2019, MULTIMED TOOLS APPL, V78, P5217, DOI 10.1007/s11042-017-4865-9
   Dalvi PK, 2016, 2016 SYMPOSIUM ON COLOSSAL DATA ANALYSIS AND NETWORKING (CDAN)
   De Caigny A, 2020, INT J FORECASTING, V36, P1563, DOI 10.1016/j.ijforecast.2019.03.029
   De Caigny A, 2018, EUR J OPER RES, V269, P760, DOI 10.1016/j.ejor.2018.02.009
   Deb SK, 2018, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE CONFLUENCE 2018 ON CLOUD COMPUTING, DATA SCIENCE AND ENGINEERING, P758, DOI 10.1109/CONFLUENCE.2018.8442900
   Dewnarain S, 2019, J HOSP MARKET MANAG, V28, P172, DOI 10.1080/19368623.2018.1516588
   Dursun A, 2016, TOUR MANAG PERSPECT, V18, P153, DOI 10.1016/j.tmp.2016.03.001
   Elbagir S, 2019, IEEE ACCESS, V7, P163677, DOI 10.1109/ACCESS.2019.2952127
   Fares A., 2019, LEARNING DATA STREAM, P209, DOI DOI 10.1007/978-3-319-89803-2_9
   Gokulkumari G, 2020, MULTIMED TOOLS APPL, V79, P31691, DOI 10.1007/s11042-020-09526-w
   Guha S., 2018, J SMALL BUSINESS ENT, V30, P193, DOI [10.1080/08276331.2017.1399628, DOI 10.1080/08276331.2017.1399628]
   Gupta H, 2017, MULTIMED TOOLS APPL, V76, P18557, DOI 10.1007/s11042-016-4249-6
   Ibrahim Ali, 2019, Journal of Physics: Conference Series, V1196, DOI 10.1088/1742-6596/1196/1/012026
   Kasemsap K., 2019, Advanced Methodologies and Technologies in Digital Marketing and Entre reneurshi, P44, DOI DOI 10.4018/978-1-5225-7766-9.CH004
   Kumar RS, 2022, MULTIMED TOOLS APPL, V81, P11989, DOI 10.1007/s11042-020-10480-w
   Kumar V, 2018, SPRING TEXT BUS ECON, P135, DOI 10.1007/978-3-662-55381-7_7
   Navimipour NJ, 2016, COMPUT HUM BEHAV, V55, P1052, DOI 10.1016/j.chb.2015.10.036
   Odili JB, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/1510256
   Qaisi LM, 2018, 2018 FIFTH HCT INFORMATION TECHNOLOGY TRENDS (ITT): EMERGING TECHNOLOGIES FOR ARTIFICIAL INTELLIGENCE, P348, DOI 10.1109/CTIT.2018.8649494
   Saha T.R., 2018, INT J RECENT TRENDS, V2, P19
   Sánchez-Franco MJ, 2019, J BUS RES, V101, P499, DOI 10.1016/j.jbusres.2018.12.051
   Santouridis I, 2017, TOTAL QUAL MANAG BUS, V28, P1122, DOI 10.1080/14783363.2017.1303889
   Singh P, 2019, ADV INTELL SYST COMP, V924, P55, DOI 10.1007/978-981-13-6861-5_5
   Sung CS, 2021, MULTIMED TOOLS APPL, V80, P34297, DOI 10.1007/s11042-021-10809-z
   Vafeiadis T, 2015, SIMUL MODEL PRACT TH, V55, P1, DOI 10.1016/j.simpat.2015.03.003
   Xiaokai Zhang, 2018, 2018 10th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC). Proceedings, P20, DOI 10.1109/IHMSC.2018.00013
   Yu JB, 2016, J INTELL MANUF, V27, P905, DOI 10.1007/s10845-014-0923-6
   Zare A, 2020, AI SOC, V35, P469, DOI 10.1007/s00146-019-00893-z
   Zerbino P, 2018, INFORM PROCESS MANAG, V54, P818, DOI 10.1016/j.ipm.2017.10.005
NR 35
TC 3
Z9 3
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28583
EP 28606
DI 10.1007/s11042-022-12877-1
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000775769200002
DA 2024-07-18
ER

PT J
AU Chen, MY
   Chang, JR
   Chen, LS
   Chuang, YJ
AF Chen, Mu-Yen
   Chang, Jing-Rong
   Chen, Long-Sheng
   Chuang, Ying-Jung
TI Identifying the key success factors of movie projects in crowdfunding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Key success factors; Movie crowdfunding; Feature selection; Text mining;
   Data mining
ID SELECTION; CAMPAIGNS
AB Low success rates have been one of the critical issues in crowdfunding. Previous studies already indicated that the project description will affects the success of the crowdfunding project. However, there is no research to explore which factors should be included in the project description for directly affecting the success of the project. The participants' text comments have been confirmed that they might change supporters' decisions. In most of crowdfunding related studies, they often used questionnaires survey which may have sampling bias and require a lot of manpower and time. In addition, they merely focus on music and sports fields but have not yet discussed the movie projects. Consequently, this study attempts to present a scheme to identify the key success factors, especially for project description and user comments, using text mining and data mining approaches. In our presented scheme, feature selection methods, including Decision Trees (DT), Least Absolute Shrinkage and Selection Operator (LASSO), and Back Propagation Network (BPN) pruning method are employed to select important factors from real projects in Kickstarter and Indiegogo. Then, a support vector machine (SVM) is performed to evaluate the performances of selected candidate factor subsets. Finally, we can determine the key success factors for movie crowdfunding projects. Experimental results can give the fundraisers useful suggestions for increasing the success rate of movie crowdfunding projects.
C1 [Chen, Mu-Yen] Natl Cheng Kung Univ, Dept Engn Sci, Tainan 701401, Taiwan.
   [Chang, Jing-Rong; Chen, Long-Sheng; Chuang, Ying-Jung] Chaoyang Univ Technol, Dept Informat Management, 168 Jifeng E Rd, Taichung 41349, Taiwan.
C3 National Cheng Kung University; Chaoyang University of Technology
RP Chen, LS (corresponding author), Chaoyang Univ Technol, Dept Informat Management, 168 Jifeng E Rd, Taichung 41349, Taiwan.
EM mychen119@gs.ncku.edu.tw; chrischang@cyut.edu.tw; lschen@cyut.edu.tw;
   june851119@gmail.com
RI Chen, Long-Sheng/GSD-6470-2022; Chen, Mu-Yen/AAO-6568-2021
OI Chen, Long-Sheng/0000-0002-2967-9956; 
FU Ministry of Science and Technology, Taiwan [MOST 110-2410-H-324 -003]
FX This work was supported in part by Ministry of Science and Technology,
   Taiwan (Grant No. MOST 110-2410-H-324 -003).
CR Agrawal A, 2015, J ECON MANAGE STRAT, V24, P253, DOI 10.1111/jems.12093
   Ahlers GKC, 2015, ENTREP THEORY PRACT, V39, P955, DOI 10.1111/etap.12157
   Alamsyah A., 2018, IOP C SERIES J PHYS, V971
   Aleksina A, 2019, DRUG DISCOV TODAY, V24, P1413, DOI 10.1016/j.drudis.2019.05.012
   Arena M, 2018, TECHNOL FORECAST SOC, V127, P154, DOI 10.1016/j.techfore.2017.05.035
   Bagheri A, 2019, TECHNOL FORECAST SOC, V146, P218, DOI 10.1016/j.techfore.2019.05.002
   Balfour R.E., 2015, P 2015 LONG ISLAND S, P1
   Belleflamme P. -., 2014, Letoltes datuma: 2021.10.13
   Belleflamme P, 2014, J BUS VENTURING, V29, P585, DOI 10.1016/j.jbusvent.2013.07.003
   Berliner LS, 2017, SOC SCI MED, V187, P233, DOI 10.1016/j.socscimed.2017.02.008
   Bhave A, 2015, 2015 INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING (ICPC)
   Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5
   Bouncken R.B., 2015, International Business Economics Research Journal, V14, P407, DOI [10.19030/iber.v14i3.9206, DOI 10.19030/IBER.V14I3.9206]
   Bretschneider U, 2017, J STRATEGIC INF SYST, V26, P246, DOI 10.1016/j.jsis.2017.02.002
   Butticè V, 2019, TECHNOL FORECAST SOC, V141, P85, DOI 10.1016/j.techfore.2018.07.047
   Cecotti H., 2009, ESANN
   Chan HF, 2021, J BUS RES, V125, P443, DOI 10.1016/j.jbusres.2019.07.037
   Chandler JA, 2022, BUS HORIZONS, V65, P79, DOI 10.1016/j.bushor.2021.10.002
   Chang JR, 2020, SOFT COMPUT, V24, P7907, DOI 10.1007/s00500-019-04019-x
   Chang JR, 2019, IEEE ACCESS, V7, P146588, DOI 10.1109/ACCESS.2019.2946168
   CHANG JR, J AMBIENT INTELL HUM
   Chen LS, 2011, J INFORMETR, V5, P313, DOI 10.1016/j.joi.2011.01.003
   Chen WK, 2021, APPL SOFT COMPUT, V111, DOI 10.1016/j.asoc.2021.107704
   Chen WK, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13010268
   Chitsazan H, 2019, PROCEEDINGS OF 2019 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND KNOWLEDGE ECONOMY (ICCIKE' 2019), P20, DOI [10.1109/iccike47802.2019.9004279, 10.1109/ICCIKE47802.2019.9004279]
   Cholakova M, 2015, ENTREP THEORY PRACT, V39, P145, DOI 10.1111/etap.12139
   Chouat O., 2018, INCITEST, V407, P1
   Çizmeci B, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P173, DOI 10.1109/UBMK.2018.8566661
   Cumming D, 2023, J BUS ETHICS, V182, P1103, DOI 10.1007/s10551-021-04942-w
   Davidson R, 2015, NEW MEDIA SOC, V17, P289, DOI 10.1177/1461444814558916
   Devi SG., 2018, Proc. 2018 Int. Conf. Curr. Trends Towar. Converging Technol, DOI [10.1109/ICCTCT.2018.8550928, DOI 10.1109/ICCTCT.2018.8550928]
   Dhir R, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P385, DOI 10.1109/ICSCCC.2018.8703320
   Du L, 2017, 2925962 ROTM SCH MAN, DOI 10.2139/ssrn.2925962
   Forbes H, 2017, PROC CIRP, V60, P398, DOI 10.1016/j.procir.2017.02.021
   Geiger M, 2022, COMPUT HUM BEHAV, V128, DOI 10.1016/j.chb.2021.107061
   Gopinath S, 2013, MANAGE SCI, V59, P2635, DOI 10.1287/mnsc.2013.1732
   Guo YM, 2019, IEEE ACCESS, V7, P103863, DOI 10.1109/ACCESS.2019.2931035
   Hardiyanti Nurul, 2018, 2018 2nd East Indonesia Conference on Computer and Information Technology (EIConCIT). Proceedings, P304, DOI 10.1109/EIConCIT.2018.8878627
   Hassan Doaa, 2018, 2018 IEEE 27th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE), P171, DOI 10.1109/WETICE.2018.00039
   Hearst Marti., 2003, WHAT IS TEXT MINING
   Hsieh HC, 2021, J INT FINANC MARK I, V75, DOI 10.1016/j.intfin.2021.101418
   Jayasekara PK, 2018, IEEE 5TH INTERNATIONAL SYMPOSIUM ON EMERGING TRENDS AND TECHNOLOGIES IN LIBRARIES AND INFORMATION SERVICES (ETTLIS 2018), P128, DOI 10.1109/ETTLIS.2018.8485261
   Jie Zhao, 2020, 2020 12th International Conference on Measuring Technology and Mechatronics Automation (ICMTMA). Proceedings, P361, DOI 10.1109/ICMTMA50254.2020.00086
   Karami A, 2020, IEEE ACCESS, V8, P67698, DOI 10.1109/ACCESS.2020.2983656
   Kraus S, 2016, J INNOV KNOWL, V1, P13, DOI 10.1016/j.jik.2016.01.010
   Kumar SS, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER AND APPLICATIONS (ICCA), P227, DOI 10.1109/COMAPP.2017.8079769
   Kwon S, 2015, COMPUT STAT DATA AN, V92, P53, DOI 10.1016/j.csda.2015.07.001
   Kwon TH, 2020, SUSTAINABILITY FASHI, V1, DOI 10.31274/susfashion.11459
   Liao SH, 2012, EXPERT SYST APPL, V39, P11303, DOI 10.1016/j.eswa.2012.02.063
   Liu H., 2012, FEATURE SELECTION KN, V454, P214
   Liu H., 2007, COMPUTATIONAL METHOD, V1, P440
   Mariani Angela, 2017, Wine Economics and Policy, V6, P60, DOI 10.1016/j.wep.2017.02.001
   Mestyán M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071226
   Meyskens M, 2015, ENTREP RES J, V5, P155, DOI 10.1515/erj-2015-0007
   Miglo A, 2020, J RISK FINANC MANAG, V13, DOI 10.3390/jrfm13030039
   Mitra T., 2014, P 17 ACM C COMP SUPP, P49, DOI [DOI 10.1145/2531602.2531656, 10.1145/2531602.2531656]
   Mollick E, 2014, J BUS VENTURING, V29, P1, DOI 10.1016/j.jbusvent.2013.06.005
   Mondal, 2018, J BUSINESS ED LEADER, V7, P1
   Namazkhan M, 2020, RENEW SUST ENERG REV, V119, DOI 10.1016/j.rser.2019.109542
   Novielli N, 2020, IEEE SOFTWARE, V37, P86, DOI 10.1109/MS.2020.2968557
   Petitjean M, 2018, FINANC RES LETT, V26, P9, DOI 10.1016/j.frl.2017.11.005
   Petruzzelli AM, 2019, TECHNOL FORECAST SOC, V141, P138, DOI 10.1016/j.techfore.2018.10.002
   Qu Y, 2019, J PHYS CONF SER, V1168, DOI 10.1088/1742-6596/1168/5/052012
   Quader N, 2017, 2017 20TH INTERNATIONAL CONFERENCE OF COMPUTER AND INFORMATION TECHNOLOGY (ICCIT)
   Rosely NFLM, 2019, J PHYS CONF SER, V1192, DOI 10.1088/1742-6596/1192/1/012068
   Schuckert M, 2015, INT J HOSP MANAG, V48, P143, DOI 10.1016/j.ijhm.2014.12.007
   Sermpinis G, 2018, J EMPIR FINANC, V48, P19, DOI 10.1016/j.jempfin.2018.05.001
   Shruti, 2014, IEEE INT CON MULTI
   Simonoff J., 2000, Chance, V13, P15, DOI [DOI 10.1080/09332480.2000.10542216, 10.1080/09332480.2000.10542216]
   Sinha, 2017 INT C EN COMM D, P494, DOI 10.1109/ICECDS.2017.8390215
   Sung SF, 2020, IEEE J BIOMED HEALTH, V24, P2922, DOI 10.1109/JBHI.2020.2976931
   Taylor DG, 2014, INT J RETAIL DISTRIB, V42, P759, DOI 10.1108/IJRDM-11-2012-0108
   Teng X, 2018, MATER SCI ENG, V392
   Huynh-Cam TT, 2021, ALGORITHMS, V14, DOI 10.3390/a14110318
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Trindade G, 2017, IBER CONF INF SYST
   Verma G, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P102, DOI [10.1109/AICAI.2019.8701239, 10.1109/aicai.2019.8701239]
   Wang ZY, 2020, INFORM FUSION, V60, P25, DOI 10.1016/j.inffus.2020.02.002
   Wehnert P, 2019, TECHNOL FORECAST SOC, V141, P128, DOI 10.1016/j.techfore.2018.06.036
   Wu WQ, 2022, J BUS RES, V140, P491, DOI 10.1016/j.jbusres.2021.11.018
   Yang FJ, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI 2019), P349, DOI 10.1109/CSCI49370.2019.00068
   Yasen M, 2019, 2019 IEEE JORDAN INTERNATIONAL JOINT CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATION TECHNOLOGY (JEEIT), P860, DOI 10.1109/JEEIT.2019.8717422
   Youyi Kim, 2020, 2020 6th Conference on Data Science and Machine Learning Applications (CDMA), P123, DOI 10.1109/CDMA47397.2020.00027
   Yuan H, 2016, DECIS SUPPORT SYST, V91, P67, DOI 10.1016/j.dss.2016.08.001
   Zaw T, 2019, 2019 INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION TECHNOLOGIES (ICAIT), P84, DOI [10.1109/aitc.2019.8921396, 10.1109/AITC.2019.8921396]
   Zhang HS, 2019, TECHNOVATION, V84-85, P11, DOI 10.1016/j.technovation.2018.05.001
   Zhang T, 2020, IEEE T IND INFORM, V16, P2115, DOI 10.1109/TII.2019.2936825
   Zhao L, 2022, BUS HORIZONS, V65, P89, DOI 10.1016/j.bushor.2021.09.007
   Zvilichovsky D, 2018, J INTERACT MARK, V41, P81, DOI 10.1016/j.intmar.2017.10.002
NR 89
TC 5
Z9 5
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27711
EP 27736
DI 10.1007/s11042-022-12959-0
EA MAR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000780464800005
DA 2024-07-18
ER

PT J
AU Huang, YB
   Chen, TF
   Zhang, QY
   Zhang, Y
   Yan, SH
AF Huang, Yi-bo
   Chen, Teng-fei
   Zhang, Qiu-yu
   Zhang, Yuan
   Yan, Shao-hui
TI Encrypted speech perceptual hashing authentication algorithm based on
   improved 2D-Henon encryption and harmonic product spectrum
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encrypted speech authentication; Perceptual hashing; Improved 2D-Henon;
   HPS; Matching accuracy; Security
ID RETRIEVAL ALGORITHM; SECURITY; SCHEME
AB The existing speech authentication algorithms use plaintext speech for hashing structure, and save the generated hashing sequence in the cloud, which is easy to cause hashing sequence leakage. At the same time, the robustness and matching accuracy of speech signal under complex noise are low, which will cause serious deviations in authentication. In order to solve the above problems, this paper proposes an encrypted speech perceptual hashing authentication algorithm based on improved two-dimensional Henon chaotic map (2D-Henon) encryption and harmonic product spectrum (HPS). Firstly, the algorithm sets the key for the improved 2D-Henon and transforms the original speech to encrypted speech. And then, feature extraction is performed on the encrypted speech signal to obtain the HPS feature matrix, and perform mapping and dimensionality reduction on the HPS matrix. Finally, the threshold is selected for binarization, and the perceptual hashing sequence is constructed. Experimental results show that the algorithm adopts encrypted speech perceptual hashing sequence, which improves the security of hashing sequence storage. The encrypted speech signal can reduce the amplitude of signal change, which has strong discrimination and robustness, and also has better matching accuracy against complex noise.
C1 [Huang, Yi-bo; Chen, Teng-fei; Zhang, Yuan; Yan, Shao-hui] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
   [Zhang, Qiu-yu] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
C3 Northwest Normal University - China; Lanzhou University of Technology
RP Huang, YB (corresponding author), Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
EM huang_yibo@nwnu.edu.cn; ctf122508@163.com; zhangqylz@163.com;
   zy13037100557@163.com; ysh022402@nwnu.edu.cn
RI zhang, qiu/GXG-5600-2022
OI /0000-0003-1667-3114
FU National Natural Science Foundation of China [61862041]; Science and
   Technology Program of Gansu Province of China [21JR7RA120]
FX This work is supported by the National Natural Science Foundation of
   China (No.61862041), Science and Technology Program of Gansu Province of
   China (No.21JR7RA120).
CR Chen N, 2013, ELECTRON LETT, V49, P7, DOI 10.1049/el.2012.3812
   Chen N, 2010, ETRI J, V32, P345, DOI 10.4218/etrij.10.0209.0309
   Ge SM, 2019, IEEE T IMAGE PROCESS, V28, P2051, DOI 10.1109/TIP.2018.2883743
   Gupta BB, 2018, MULTIMED TOOLS APPL, V77, P9203, DOI 10.1007/s11042-017-5301-x
   Hammad M, 2019, COMPUT SECUR, V81, P107, DOI 10.1016/j.cose.2018.11.003
   He SF, 2017, COMPUT SCI INF SYST, V14, P703, DOI 10.2298/CSIS170112024H
   HENON M, 1976, COMMUN MATH PHYS, V50, P69, DOI 10.1007/BF01608556
   Huang Y., 2019, 2019 IEEE INT C SIGN
   Huang Y B, MULTIMED TOOLS APPL, P1
   Huang YB, 2020, IEEE ACCESS, V8, P34140, DOI 10.1109/ACCESS.2020.2974029
   Jin HG., 2019, CLUSTER COMPUT, V19, P323
   Kang Q, 2016, NEUROCOMPUTING, V181, P132, DOI 10.1016/j.neucom.2015.06.098
   Kumar N, 2020, MULTIMED TOOLS APPL, V79, P2363, DOI 10.1007/s11042-019-08228-2
   Kumar P, 2019, IEEE T FUZZY SYST, V27, P956, DOI 10.1109/TFUZZ.2018.2870590
   Leonov GA, 2018, UKR MATH J+, V70, P42, DOI 10.1007/s11253-018-1487-y
   [李金凤 Li Jinfeng], 2015, [北京邮电大学学报, Journal of Beijing University of Posts Telecommunications], V38, P89
   Li JF, 2015, CHINESE J ELECTRON, V24, P579, DOI 10.1049/cje.2015.07.024
   Mendelson A, 2019, COMPUTER, V52, P65, DOI 10.1109/MC.2019.2943137
   Peng LN, 2020, IEEE T VEH TECHNOL, V69, P1091, DOI 10.1109/TVT.2019.2950670
   Prasasti AL., 2019, J PHYS C SER, V1367
   Prathosh AP, 2013, IEEE T AUDIO SPEECH, V21, P2471, DOI 10.1109/TASL.2013.2273717
   Qian Q, 2018, TELECOMMUN SYST, V67, P635, DOI 10.1007/s11235-017-0360-x
   Qinghua L, 2019, J PHYS CHEM B
   Qiuyu Z., 2018, INT J INF COMMUN TEC, V12, P50
   Sathiyamurthi P, 2019, J TEST EVAL, V47, P3028, DOI 10.1520/JTE20170283
   Shi C, 2021, INT J PAVEMENT ENG, V22, P1744, DOI 10.1080/10298436.2020.1721498
   Shukla MK, 2018, ASIAN J CONTROL, V20, P707, DOI 10.1002/asjc.1593
   Siniscalchi SM, 2014, NEUROCOMPUTING, V140, P326, DOI 10.1016/j.neucom.2014.03.005
   Sumarno, 2018, INT J ELECT ENG INF, V10
   ULLAH S, 2019, SENSORS-BASEL, V19
   Wang YB, 2020, MINER DEPOSITA, V55, P1385, DOI 10.1007/s00126-019-00942-z
   Wang ZZ, 2016, NEUROCOMPUTING, V173, P1203, DOI 10.1016/j.neucom.2015.08.078
   Yongbing Z, 2019, RADIO ENG
   Zhang QY, 2020, MULTIMED TOOLS APPL, V79, P29775, DOI 10.1007/s11042-020-09446-9
   Zhang QY, 2019, MULTIMED TOOLS APPL, V78, P17825, DOI 10.1007/s11042-019-7180-9
   Zhang QY, 2018, MULTIMED TOOLS APPL, V77, P21653, DOI 10.1007/s11042-018-5613-5
   Zhang QY, 2018, MULTIMED TOOLS APPL, V77, P1555, DOI 10.1007/s11042-017-4381-y
   Zhang Qiuyu, 2017, Journal of Huazhong University of Science and Technology (Natural Science Edition), V45, P33, DOI 10.13245/j.hust.170907
   Zhang QY., 2019, INT J NETW SECUR, V21, P259
   Zhao SP, 2019, INFORM SCIENCES, V489, P167, DOI 10.1016/j.ins.2019.03.027
   Zhou L, 2019, IEEE MULTIMEDIA, V26, P8, DOI 10.1109/MMUL.2018.2875256
NR 41
TC 2
Z9 2
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25829
EP 25852
DI 10.1007/s11042-022-12746-x
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000772731900004
DA 2024-07-18
ER

PT J
AU Antunes, N
   Ferreira, JC
   Cardoso, E
AF Antunes, Nuno
   Ferreira, Joao Carlos
   Cardoso, Elsa
TI Generating personalized business card designs from imagess
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Artificial intelligence; Marketing; Design generation;
   Natural language processing
ID TEXT EXTRACTION; SCENE-TEXT; RECOGNITION
AB Rising competition in the retail and hospitality sectors, especially in densely populated and touristic destinations is a growing concern for many business owners, who wish to deliver their brand communication strategy to the target audience. Many of these businesses rely on word-of-mouth marketing, delivering business cards to customers. Furthermore, the lack of a dedicated marketing team and budget for brand image consolidation and design creation often limits the brand expansion capability. The purpose of this study is to propose a novel system prototype that can suggest personalized designs for business cards, based on an existing business card picture. Using perspective transformation, text extraction and colour reduction techniques, we were able to obtain features from the original business card image and generate an alternative design, personalized for the end user. We have successfully been able to generate customized business cards for different business types, with textual information and a custom colour palette matching the original submitted image. All of the system modules were demonstrated to have positive results for the test cases and the proposal answered the main research question. Further research and development is required to adapt the current system to other marketing printouts, such as flyers or posters.
C1 [Antunes, Nuno; Ferreira, Joao Carlos; Cardoso, Elsa] Inst Univ Lisboa ISCTE IUL, ISTAR, P-1649026 Lisbon, Portugal.
   [Antunes, Nuno; Ferreira, Joao Carlos] INOV Inst Engn Sistemas & Comp Inovacao, Rua Alves Redol 9, P-1000029 Lisbon, Portugal.
C3 Instituto Universitario de Lisboa; INOV INESC Inovacao
RP Antunes, N (corresponding author), Inst Univ Lisboa ISCTE IUL, ISTAR, P-1649026 Lisbon, Portugal.; Antunes, N (corresponding author), INOV Inst Engn Sistemas & Comp Inovacao, Rua Alves Redol 9, P-1000029 Lisbon, Portugal.
EM nuno_francisco@iscte.ptnuno; joao.carlos.ferreira@iscte.pt;
   elsa.cardoso@iscte.pt
RI ferreira, joao/JJE-8433-2023; Ferreira, João Carlos Amaro/B-5351-2009;
   Ferreira, Joao/HNP-5121-2023; Cardoso, Elsa/AEY-7142-2022
OI Ferreira, João Carlos Amaro/0000-0002-6662-0806; Cardoso,
   Elsa/0000-0002-5555-4567; Antunes, Nuno Francisco/0000-0003-1044-5014
FU EEA Grants Blue Growth Programme [PT-INNOVATION-0045 - Fish2Fork]
FX This work was supported by EEA Grants Blue Growth Programme (Call #5).
   Project PT-INNOVATION-0045 - Fish2Fork.
CR Baek J, 2019, IEEE I CONF COMP VIS, P4714, DOI 10.1109/ICCV.2019.00481
   Baek Y, 2019, PROC CVPR IEEE, P9357, DOI 10.1109/CVPR.2019.00959
   Bora D.J., 2015, International Journal of Emerging Technology and Advanced Engineering, V5, P192
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cho H, 2016, PROC CVPR IEEE, P3566, DOI 10.1109/CVPR.2016.388
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Grover S, 2009, P INDICON 2009 IEEE, DOI 10.1109/INDCON.2009.5409409
   Harris C., 1988, ALVEY VISION C, P147151
   Huang WL, 2013, IEEE I CONF COMP VIS, P1241, DOI 10.1109/ICCV.2013.157
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jahanian Ali, 2013, P 2013 INT C INTELLI, P95
   Jamal A., 2001, MARKETING INTELLIGEN, V19, P482, DOI DOI 10.1108/02634500110408286
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Karras T., 2018, INT CONFLEARN REPRES
   KOBAYASHI S, 1981, COLOR RES APPL, V6, P93, DOI 10.1002/col.5080060210
   Koo HI, 2013, IEEE T IMAGE PROCESS, V22, P2296, DOI 10.1109/TIP.2013.2249082
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Lee J, 2014, INT J APPL GEOSPAT R, V5, P1, DOI 10.4018/ijagr.2014010101
   Liang Y, 2018, BIOSCI BIOTECH BIOCH, V82, P2130, DOI [10.1080/09168451.2018.1514247, 10.1109/ISGT-Asia.2018.8467956]
   Lucas S. M., 2005, International Journal on Document Analysis and Recognition, V7, P105, DOI 10.1007/s10032-004-0134-3
   Michelsanti D, 2017, INTERSPEECH, P2008, DOI 10.21437/Interspeech.2017-1620
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Nogueira TDC, 2020, MULTIMED TOOLS APPL, V79, P30615, DOI 10.1007/s11042-020-09539-5
   Radford A., 2015, ARXIV
   Sahare P, 2017, IETE TECH REV, V34, P144, DOI 10.1080/02564602.2016.1160805
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Tian SX, 2015, IEEE I CONF COMP VIS, P4651, DOI 10.1109/ICCV.2015.528
   Wang C., 2018, IEEE INT C INF COMMU, V44, P2113, DOI [10.16383/j.aas.2018.c170572, DOI 10.16383/J.AAS.2018.C170572]
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Yan JQ, 2014, NEUROCOMPUTING, V134, P3, DOI 10.1016/j.neucom.2012.12.070
   Yang G, 2018, IEEE T MED IMAGING, V37, P1310, DOI 10.1109/TMI.2017.2785879
   Zhang HG, 2013, NEUROCOMPUTING, V122, P310, DOI 10.1016/j.neucom.2013.05.037
   Zhang SY, 2016, INT CONF ACOUST SPEE, P2633, DOI 10.1109/ICASSP.2016.7472154
   Zhang YH, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071123
NR 36
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25051
EP 25073
DI 10.1007/s11042-022-12416-y
EA MAR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000771882300009
PM 35342325
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Nizami, IF
   Rehman, MU
   Waqar, A
   Majid, M
AF Nizami, Imran Fareed
   Rehman, Mobeen Ur
   Waqar, Asad
   Majid, Muhammad
TI Impact of visual saliency on multi-distorted blind image quality
   assessment using deep neural architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE No-reference image quality assessment; Multi-distorted images;
   Convolutional neural network; Visual saliency
ID GRADIENT MAGNITUDE; SIMILARITY; STATISTICS; INDEX
AB No-referenceimage quality assessment (NR-IQA) techniques try to assess the quality of images without anyinformation regarding the pristine version of the image. NR-IQA becomes more challenging for images affected by multiple distortions and images taken in real-world scenarios. Most convolutional neural network (CNN) based NR-IQA techniques do not use visual saliency (VS) and the ones that do require a reference image for computation of VS map. This paper proposes a completely blind end-to-end NR-IQA methodology based on VS and convolutional neural network (CNN). It utilizes VS models to identify the significant region of the image that can be used for quality assessment. The VS methodology used in the proposed approach does not require a reference image for the extraction of VS map. The regions proposed by the VS model are then utilized by a CNN to predict the quality score. The proposed methodology is tested on three publicly available multi-distorted image quality assessment databases i.e., live multiply distorted image quality (MDIQ) database, multiply distorted image database (MDID), and the live in the wild challenge (CLIVE) database. The proposed methodology is also tested over three VS models extract VS maps without the reference image. The experimental results show that using VS models improve the performance of CNN for predicting the image quality score.
C1 [Nizami, Imran Fareed] Jeonbuk Natl Univ, Dept Elect & Informat Engn, Jeonju 54896, South Korea.
   [Waqar, Asad] Bahria Univ, Dept Elect Engn, Islamabad, Pakistan.
   [Rehman, Mobeen Ur; Majid, Muhammad] Univ Engn & Technol, Dept Comp Engn, Taxila, Pakistan.
   [Nizami, Imran Fareed; Rehman, Mobeen Ur] Air Univ, Inst Av & Aeronaut IAA, Islamabad 44000, Pakistan.
C3 Jeonbuk National University; University of Engineering & Technology
   Taxila; Air University Islamabad
RP Nizami, IF (corresponding author), Jeonbuk Natl Univ, Dept Elect & Informat Engn, Jeonju 54896, South Korea.; Nizami, IF (corresponding author), Air Univ, Inst Av & Aeronaut IAA, Islamabad 44000, Pakistan.
EM imnizami.buic@bahria.edu.pk; m.majid@uettaxila.edu.pk
RI Rehman, Mobeen Ur/AAR-2944-2021; Waqar, Asad/AEM-8407-2022; Majid,
   Muhammad/Z-5667-2019
OI Rehman, Mobeen Ur/0000-0003-0914-7132; Majid,
   Muhammad/0000-0003-3662-2525
CR [Anonymous], ARXIV160507678
   Bianco S, 2018, SIGNAL IMAGE VIDEO P, V12, P355, DOI 10.1007/s11760-017-1166-8
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Freitas PG, 2018, IEEE T MULTIMEDIA, V20, P3353, DOI 10.1109/TMM.2018.2839529
   Gao F, 2017, NEUROCOMPUTING, V257, P104, DOI 10.1016/j.neucom.2017.01.054
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   Golestaneh S, 2016, IEEE T IMAGE PROCESS, V25, P5293, DOI 10.1109/TIP.2016.2601821
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Guan JW, 2017, IEEE T MULTIMEDIA, V19, P2505, DOI 10.1109/TMM.2017.2703148
   Guan JW, 2015, J VIS COMMUN IMAGE R, V29, P1, DOI 10.1016/j.jvcir.2015.01.007
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou WL, 2015, IEEE T NEUR NET LEAR, V26, P1275, DOI 10.1109/TNNLS.2014.2336852
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jayaraman D, 2012, CONF REC ASILOMAR C, P1693, DOI 10.1109/ACSSC.2012.6489321
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Kim J, 2017, IEEE SIGNAL PROC MAG, V34, P130, DOI 10.1109/MSP.2017.2736018
   Kim J, 2017, IEEE J-STSP, V11, P206, DOI 10.1109/JSTSP.2016.2639328
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li LD, 2016, IEEE T CYBERNETICS, V46, P39, DOI 10.1109/TCYB.2015.2392129
   Li SY, 2021, INT J COMPUT VISION, V129, P1301, DOI 10.1007/s11263-020-01416-w
   Li SN, 2011, IEEE T MULTIMEDIA, V13, P935, DOI 10.1109/TMM.2011.2152382
   Lin KY, 2018, PROC CVPR IEEE, P732, DOI 10.1109/CVPR.2018.00083
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Liu HT, 2010, IEEE T CIRC SYST VID, V20, P529, DOI 10.1109/TCSVT.2009.2035848
   Liu LX, 2016, SIGNAL PROCESS-IMAGE, V40, P1, DOI 10.1016/j.image.2015.10.005
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Liu TJ, 2018, IEEE T IMAGE PROCESS, V27, P1138, DOI 10.1109/TIP.2017.2771422
   Lu YX, 2023, CONCURR COMP-PRACT E, V35, DOI 10.1002/cpe.6177
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P3951, DOI 10.1109/TIP.2017.2708503
   Ma L, 2011, IEEE T MULTIMEDIA, V13, P824, DOI 10.1109/TMM.2011.2109701
   Ma XY, 2020, MULTIMED TOOLS APPL, V79, P35209, DOI 10.1007/s11042-019-7571-y
   Min XK, 2018, IEEE T MULTIMEDIA, V20, P2049, DOI 10.1109/TMM.2017.2788206
   Min XK, 2018, IEEE T BROADCAST, V64, P508, DOI 10.1109/TBC.2018.2816783
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Oszust M, 2017, IEEE SIGNAL PROC LET, V24, P1656, DOI 10.1109/LSP.2017.2754539
   Pan F, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 3, PROCEEDINGS, P925
   Rehman A, 2012, IEEE T IMAGE PROCESS, V21, P3378, DOI 10.1109/TIP.2012.2197011
   Reisenhofer R, 2018, SIGNAL PROCESS-IMAGE, V61, P33, DOI 10.1016/j.image.2017.11.001
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sun W, 2017, PATTERN RECOGN, V61, P153, DOI 10.1016/j.patcog.2016.07.033
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wu QB, 2018, IEEE T CIRC SYST VID, V28, P2078, DOI 10.1109/TCSVT.2017.2710419
   Wu QB, 2016, IEEE T CIRC SYST VID, V26, P425, DOI 10.1109/TCSVT.2015.2412773
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang P, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3339474
   Yang XH, 2020, NEUROCOMPUTING, V401, P209, DOI 10.1016/j.neucom.2020.03.072
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhang WX, 2020, IEEE T CIRC SYST VID, V30, P36, DOI 10.1109/TCSVT.2018.2886771
NR 61
TC 6
Z9 6
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25283
EP 25300
DI 10.1007/s11042-022-12060-6
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000771882300003
DA 2024-07-18
ER

PT J
AU Tripathi, RK
   Jalal, AS
AF Tripathi, Rajesh Kumar
   Jalal, Anand Singh
TI A robust approach based on local feature extraction for age invariant
   face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Age invariant; Face recognition; Local directional gradient relation
   pattern; Local difference pattern
ID SIMULATION; SCALE
AB Age variation is a major problem in the area of face recognition under uncontrolled environment such as pose, illumination, expression. Most of the works of this area are based on discriminative methods. The most of the discriminative methods used encoding based descriptors. The encoding based descriptors skip pixels of a few radii width which holds important discriminative information for face recognition under age variation. This paper involves all the pixels of local regions and introduces local descriptors-local difference pattern and local directional gradient relation pattern for extracting texture features for face recognition under age variation. The proposed descriptors are used for robust feature extraction from face images and its parts-periocular region i.e. left and right eye, nose and mouth region. The proposed local difference pattern finds the texture feature difference relation on a local region while local directional gradient relation pattern extracts the feature through finding relation of directional gradient of the local region. Histogram is computed for extracted features using descriptors. Chi-square metric computes the the similarity between probe and gallery images. Experiments have been done on two standard challenging datasets to measure the performance. The proposed approach performed well and presented the better and comparable results i.e. 90.75% recognition accuracy on FGNET and 96.95% recognition accuracy on MORPH.
C1 [Tripathi, Rajesh Kumar; Jalal, Anand Singh] GLA Univ, Dept CEA, IET, Mathura, Uttar Pradesh, India.
C3 GLA University
RP Tripathi, RK (corresponding author), GLA Univ, Dept CEA, IET, Mathura, Uttar Pradesh, India.
EM rajesh.tripathi@gla.ac.in; asjalal@gla.ac.in
RI Tripathi, Rajesh/AAE-6995-2020
OI Jalal, Anand/0000-0002-7469-6608; Tripathi, Rajesh/0000-0003-3167-9338
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Alvi FB, 2017, EXPERT SYST APPL, V72, P383, DOI 10.1016/j.eswa.2016.10.042
   [Anonymous], 2018, INT J ELECT COMPUT E
   Bouchaffra D, 2015, IEEE T NEUR NET LEAR, V26, P1375, DOI 10.1109/TNNLS.2014.2341634
   Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374
   Chen BC, 2014, LECT NOTES COMPUT SC, V8694, P768, DOI 10.1007/978-3-319-10599-4_49
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dihong G, 2013, HIDDEN FACTOR ANAL A
   Dubey SR, 2019, MULTIMED TOOLS APPL, V78, P28063, DOI 10.1007/s11042-019-07908-3
   Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P488, DOI 10.1007/978-3-319-10605-2_32
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Gong DH, 2015, PROC CVPR IEEE, P5289, DOI 10.1109/CVPR.2015.7299166
   Klare B., 2011, 2011 International Joint Conference on Biometrics (IJCB), P1
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Li ZF, 2016, IEEE T IMAGE PROCESS, V25, P2146, DOI 10.1109/TIP.2016.2535284
   Li ZF, 2011, IEEE T INF FOREN SEC, V6, P1028, DOI 10.1109/TIFS.2011.2156787
   Ling HB, 2010, IEEE T INF FOREN SEC, V5, P82, DOI 10.1109/TIFS.2009.2038751
   Liu LQ, 2016, IEEE T MULTIMEDIA, V18, P64, DOI 10.1109/TMM.2015.2500730
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Moustafa AA, 2020, SIGNAL IMAGE VIDEO P, V14, P1027, DOI 10.1007/s11760-020-01635-1
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Otto C, 2012, LECT NOTES COMPUT SC, V7584, P189, DOI 10.1007/978-3-642-33868-7_19
   Park U, 2010, IEEE T PATTERN ANAL, V32, P947, DOI 10.1109/TPAMI.2010.14
   Patterson E., 2006, Proc. 6th International Conference on Visualization, Imaging, and Image Processing, V171, pC176
   Ramanathan N., 2006, IEEE COMP SOC C COMP, P387, DOI [DOI 10.1109/CVPR.2006.187, 10.1109/CVPR.2006.187]
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Tanaka, 2020, FACE PARTS DETECTION
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang JY, 2006, INT C PATT RECOG, P913
   WEN YD, 2016, PROC CVPR IEEE, P4893, DOI DOI 10.1109/CVPR.2016.529
   Wu C, 2017, CHIN INT AUT C, P623
   Xu CF, 2017, NEUROCOMPUTING, V222, P62, DOI 10.1016/j.neucom.2016.10.010
   Zheng TY, 2017, IEEE COMPUT SOC CONF, P503, DOI 10.1109/CVPRW.2017.77
NR 33
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21223
EP 21240
DI 10.1007/s11042-022-12783-6
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000770061500009
DA 2024-07-18
ER

PT J
AU Mahmoodi, J
   Nezamabadi-pour, H
   Abbasi-Moghadam, D
AF Mahmoodi, Javad
   Nezamabadi-pour, Hossein
   Abbasi-Moghadam, Dariush
TI Violence detection in videos using interest frame extraction and 3D
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Violence detection; Deep learning; 3D convolutional neural network;
   Interest frame extraction
ID RECOGNITION
AB With the rapid development of detecting violent behaviors in surveillance cameras, requests on systems that automatically recognize violent events are expanded. Nowadays, violence detection has become an active research field in image processing and machine learning. The relevant works in such a field are classified into hand-crafted and deep learning methods. Despite the effectiveness of hand-crafted ones, their computational cost may be suppressive for practical applications. Additionally, deep learning techniques usually exploit 3D Convolutional Networks (3D ConvNets) to do this task. To improve the accuracy of these networks, meaningful regions and temporal changes in videos should be considered. Consequently, the performance of a 3D ConvNet can be reinforced by selecting significant temporal information and noticing to special regions in two spatial dimensions. In this work, we propose a novel 3D ConvNet along with a technique for extracting interest frames. The Structural Similarity Index Measure (SSIM) is exploited to extract interest frames as significant temporal information. Indeed, the SSIM uses the statistical features of two consecutive frames for this reason. In this way, sixteen video frames with the smallest SSIM are considered as dominant motion frames, which are then sent to a 3D CNN for classification. Moreover, a spatial attention module is exploited to make attention on the specific regions. Furthermore, three benchmark datasets are employed to evaluate the performance of the proposed method. The results show that in terms of accuracy, our scheme outperforms existing approaches.
C1 [Mahmoodi, Javad; Nezamabadi-pour, Hossein; Abbasi-Moghadam, Dariush] Shahid Bahonar Univ Kerman, Dept Elect Engn, Kerman, Iran.
C3 Shahid Bahonar University of Kerman (SBUK)
RP Mahmoodi, J (corresponding author), Shahid Bahonar Univ Kerman, Dept Elect Engn, Kerman, Iran.
EM Javad.Mahmoodi@eng.uk.ac.ir; nezam@uk.ac.ir; abbasimoghadam@uk.ac.ir
RI Mahmoodi, Javad/GSN-0804-2022; Mahmoodi, Javad/Y-8118-2019;
   Abbasi-Moghadam, Dariush/HTO-3838-2023; Nezamabadi-pour,
   Hossein/I-9578-2014
OI Mahmoodi, Javad/0000-0003-3758-0451; Mahmoodi,
   Javad/0000-0003-3758-0451; Abbasi-Moghadam, Dariush/0000-0003-2228-0595;
   
CR Bellamine, 2016, LECT NOTES ELECT ENG
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Ben Mabrouk A, 2017, PATTERN RECOGN LETT, V92, P62, DOI 10.1016/j.patrec.2017.04.015
   Nievas EB, 2011, LECT NOTES COMPUT SC, V6855, P332, DOI 10.1007/978-3-642-23678-5_39
   Bilen H, 2018, IEEE T PATTERN ANAL, V40, P2799, DOI 10.1109/TPAMI.2017.2769085
   Chen M-y, 2009, Mosift: Recognizing human actions in surveillance videos, CMU-CS-09-161
   De Souza FD, 2010, 2010 23 SIBGRAPI C G
   Deepak K, 2020, ICT EXPRESS, V6, P155, DOI 10.1016/j.icte.2020.04.014
   Demarty CH, 2015, MULTIMED TOOLS APPL, V74, P7379, DOI 10.1007/s11042-014-1984-4
   Dong ZH, 2016, COMM COM INF SC, V662, P517, DOI 10.1007/978-981-10-3002-4_43
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Febin IP, 2020, PATTERN ANAL APPL, V23, P611, DOI 10.1007/s10044-019-00821-3
   Giannakopoulos T, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P90, DOI 10.1109/MMSP.2007.4412825
   Giannakopoulos T, 2006, LECT NOTES COMPUT SC, V3955, P502
   Gu C, 2020, IEEE ACCESS
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Jain, 2020, 2020 3 INT C SMART S
   Keçeli AS, 2017, ELECTRON LETT, V53, P1047, DOI 10.1049/el.2017.0970
   Kooij JFP, 2016, COMPUT VIS IMAGE UND, V144, P106, DOI 10.1016/j.cviu.2015.06.009
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Liang QM, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.4.043009
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Meng ZH, 2017, LECT NOTES COMPUT SC, V10528, P437, DOI 10.1007/978-3-319-68345-4_39
   Perperis T, 2011, EXPERT SYST APPL, V38, P14102, DOI 10.1016/j.eswa.2011.04.219
   Qian Dai, 2015, 2015 IEEE Power & Energy Society General Meeting, P1, DOI 10.1109/PESGM.2015.7286470
   Ramzan M, 2019, IEEE ACCESS, V7, P107560, DOI 10.1109/ACCESS.2019.2932114
   Rendón-Segador FJ, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10131601
   Serrano I, 2018, IEEE T IMAGE PROCESS, V27, P4787, DOI 10.1109/TIP.2018.2845742
   Shi XJ, 2015, ADV NEUR IN, V28
   Song W, 2019, IEEE ACCESS, V7, P39172, DOI 10.1109/ACCESS.2019.2906275
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sudhakaranu S, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xia Q, 2018, LECT NOTES COMPUT SC, V10996, P157, DOI 10.1007/978-3-319-97909-0_17
   Xu L, 2014, INT CONF ACOUST SPEE
   Zhang T, 2016, MULTIMED TOOLS APPL, V75, P7327, DOI 10.1007/s11042-015-2648-8
NR 36
TC 9
Z9 9
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20945
EP 20961
DI 10.1007/s11042-022-12532-9
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767922000006
DA 2024-07-18
ER

PT J
AU Suchithra, MS
   Pai, ML
AF Suchithra, M. S.
   Pai, Maya L.
TI Evaluating the performance of bagging-based k-nearest neighbor ensemble
   with the voting rule selection method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Label ranking; Ensembles; K-nearest neighbor label ranker; Rank
   aggregation; VRS
ID LABEL RANKING; OPTIMIZATION ALGORITHM
AB Label ranking based prediction problems help to find a mapping between instances and ranked labels. To improve the prediction performance of label ranking models, the main suggestion is to use ensembles. The main feature of ensemble models is the ability to retrieve the outcomes of various multiple simple models and join them into a combined outcome. To ensure the property of ensemble learning, the nearest neighbor estimation is applied with a bagging approach that samples the instances of training data. The reason to select the label ranking ensemble approach is shown in this study using detailed analysis of suitable existing algorithms. The results show that the defined parameters used in the k-nearest label ranker help to obtain a better prediction performance than the existing label ranking ensembles with an accuracy of 85% to 99% on 21 label ranking datasets. But there is a possibility to improve any ensemble algorithm by using the voting rule selection procedure. This study, integrating the Voting Rule Selector (VRS) algorithm and the seven commonly used voting rules with the k-nearest neighbor label ranker, found that VRS and Copeland work more efficiently than the Borda aggregation in dataset level learning. The results indicate that the k-nearest neighbor label ranker with the VRS and Copeland aggregation method is ranked first in most of the datasets. In the dataset level, the VRS method obtained an average improvement of 48.02% in comparison to the simple model k-nearest neighbor approach and is almost equal to the Copeland with 47.84%.
C1 [Suchithra, M. S.; Pai, Maya L.] Amrita Vishwa Vidyapeetham, Amrita Sch Arts & Sci, Dept Comp Sci & IT, Kochi, Kerala, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Kochi
RP Suchithra, MS (corresponding author), Amrita Vishwa Vidyapeetham, Amrita Sch Arts & Sci, Dept Comp Sci & IT, Kochi, Kerala, India.
EM suchithrams194@gmail.com; mayalpai@gmail.com
OI M S, SUCHITHRA/0000-0002-0194-1705
CR Aiguzhinov A, 2010, LECT NOTES ARTIF INT, V6332, P16, DOI 10.1007/978-3-642-16184-1_2
   Aledo JA, 2017, INFORM FUSION, V35, P38, DOI 10.1016/j.inffus.2016.09.002
   Alfaro J.C, 2019, SCIKIT LR
   Alfaro JC, 2020, LECT NOTES ARTIF INT, V12344, P410, DOI 10.1007/978-3-030-61705-9_34
   Alfaro JC, 2021, INT J INTELL SYST, V36, P890, DOI 10.1002/int.22325
   [Anonymous], 2010, ICML
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.37
   Brafman RL, 2009, AI MAG, V30, P58, DOI 10.1609/aimag.v30i1.2114
   Brazdil PB, 2003, MACH LEARN, V50, P251, DOI 10.1023/A:1021713901879
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chen WY, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON PUBLIC ECONOMICS AND MANAGEMENT ICPEM 2009, VOL 6, P21
   Chen ZM, 2021, IEEE T MULTIMEDIA, V23, P1827, DOI 10.1109/TMM.2020.3003779
   Cheng WW, 2009, LECT NOTES COMPUT SC, V5551, P707, DOI 10.1007/978-3-642-01507-6_80
   Cheng Weiwei., 2008, Eccbr workshops, P143
   Cunha T, 2018, 33RD ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, P1393, DOI 10.1145/3167132.3167418
   de Sá CR, 2017, EXPERT SYST, V34, DOI 10.1111/exsy.12166
   de Sá CR, 2011, LECT NOTES ARTIF INT, V6635, P432, DOI 10.1007/978-3-642-20847-8_36
   Dehghani M., 2020, Int. J. Intell. Eng. Syst, V13, P286, DOI [10.22266/ijies2020.1031.26, DOI 10.22266/IJIES2020.1031.26]
   Dehghani M., 2020, Int. J. Intell. Eng. Syst, V13, DOI DOI 10.22266/IJIES2020.1231.32
   Dehghani M., 2019, International Journal of Innovative Technology and Exploring Engineering, V9, P5306, DOI [10.35940/ijitee.A4215.119119, DOI 10.35940/IJITEE.A4215.119119]
   Dehghani M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186173
   Dekel O, 2004, ADV NEUR IN, V16, P497
   Dery L., 2020, ARXIV PREPRINT ARXIV
   Dery L, 2020, IEEE ACCESS, V8, P176023, DOI 10.1109/ACCESS.2020.3026758
   Dhiman G, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106560
   Dhiman G, 2021, J AMB INTEL HUM COMP, V12, P8457, DOI 10.1007/s12652-020-02580-0
   Dhiman G, 2021, ENG COMPUT-GERMANY, V37, P323, DOI 10.1007/s00366-019-00826-w
   Dhiman G, 2019, ENG APPL ARTIF INTEL, V82, P148, DOI 10.1016/j.engappai.2019.03.021
   Dhiman G, 2019, KNOWL-BASED SYST, V165, P169, DOI 10.1016/j.knosys.2018.11.024
   Dhiman G, 2018, KNOWL-BASED SYST, V159, P20, DOI 10.1016/j.knosys.2018.06.001
   Dhiman G, 2017, ADV ENG SOFTW, V114, P48, DOI 10.1016/j.advengsoft.2017.05.014
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Elgharabawy A, 2019, ARXIV PREPRINT ARXIV
   Freund Y, 2004, J MACH LEARN RES, V4, P933, DOI 10.1162/1532443041827916
   Fürnkranz J, 2010, PREFERENCE LEARNING, P65, DOI 10.1007/978-3-642-14125-6_4
   Fürnkranz J, 2003, LECT NOTES ARTIF INT, V2837, P145
   Grbovic M., 2012, Preference Learning: Problems and Applications in AI, P33
   Gurrieri M., 2012, Advances on Computational Intelligence, P613
   Har-Peled S., 2003, ADV NEURAL INFORM PR, P809
   Hestilow TJ, 2009, EURASIP J BIOINFORM, DOI 10.1155/2009/195712
   Hüllermeier E, 2008, ARTIF INTELL, V172, P1897, DOI 10.1016/j.artint.2008.08.002
   Jain H, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P935, DOI 10.1145/2939672.2939756
   Kaur S, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103541
   Kendall M. G., 1948, Rank correlation methods.
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kouchaki S, 2020, FRONT MICROBIOL, V11, DOI 10.3389/fmicb.2020.00667
   Krawczyk B, 2017, INFORM FUSION, V37, P132, DOI 10.1016/j.inffus.2017.02.004
   Lin SL, 2010, WILEY INTERDISCIP RE, V2, P555, DOI 10.1002/wics.111
   Naamani-Dery L, 2015, GROUP DECIS NEGOT, V24, P1015, DOI 10.1007/s10726-015-9427-9
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Prabhu Y, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P456, DOI 10.1145/3336191.3371768
   Ribeiro Geraldina, 2012, Artificial Neural Networks and Machine Learning - ICANN 2012. 22nd International Conference on Artificial Neural Networks, P25, DOI 10.1007/978-3-642-33266-1_4
   Rui Zeng, 2012, Journal of Software, V7, P904, DOI 10.4304/jsw.7.4.904-912
   Sagi O, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1249
   Savargiv M, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01882-7
   Tax DMJ, 2000, PATTERN RECOGN, V33, P1475, DOI 10.1016/S0031-3203(99)00138-7
   Vembu S, 2010, PREFERENCE LEARNING, P45, DOI 10.1007/978-3-642-14125-6_3
   Werbin-Ofir H, 2019, EXPERT SYST APPL, V136, P50, DOI 10.1016/j.eswa.2019.06.022
   Wu HY, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2779-4
   Yu PLH, 2010, PREFERENCE LEARNING, P83, DOI 10.1007/978-3-642-14125-6_5
   Zhou YM, 2018, EXPERT SYST APPL, V112, P99, DOI 10.1016/j.eswa.2018.06.036
   Zhou YM, 2014, J COMPUT, V9, P557, DOI 10.4304/jcp.9.3.557-565
NR 64
TC 4
Z9 4
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20741
EP 20762
DI 10.1007/s11042-022-12716-3
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767922000012
DA 2024-07-18
ER

PT J
AU Jan, AM
   Parah, SA
   Malik, BA
AF Jan, Aiman
   Parah, Shabir A.
   Malik, Bilal A.
TI IEFHAC: Image encryption framework based on hessenberg transform and
   chaotic theory for smart health
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart cities; Medical diagnosis; Security; Computational complexity;
   Image encryption
ID ALGORITHM; EFFICIENT; MAP; CITIES; DESIGN; SECURE; BIT
AB Smart cities aim to improve the quality of life by utilizing technological advancements. One of the main areas of innovation includes the design, implementation, and management of data-intensive medical systems also known as big-data Smart Healthcare systems. Smart health systems need to be supported by highly efficient and resilient security frameworks. One of the important aspects that smart health systems need to provide, is timely access to high-resolution medical images, that form about 80% of the medical data. These images contain sensitive information about the patient and as such need to be secured completely. To prevent unauthorized access to medical images, the process of image encryption has become an imperative task for researchers all over the world. Chaos-based encryption has paved the way for the protection of sensitive data from being altered, modified, or hacked. In this paper, we present an Image Encryption Framework based on Hessenberg transform and Chaotic encryption (IEFHAC), for improving security and reducing computational time while encrypting patient data. IEFHAC uses two 1D-chaotic maps: Logistic map and Sine map for the confusion of data, while diffusion has been achieved by applying the Hessenberg household transform. The Sin and Logistic maps are used to regeneratively affect each other's output, as such dynamically changing the key parameters. The experimental analysis demonstrates that IEFHAC shows better results like NPCR ranging from 99.66 to 100%, UACI of 37.39%, lesser computational time of 0.36 s, and is more robust to statistical attacks.
C1 [Jan, Aiman; Parah, Shabir A.] Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar, India.
   [Malik, Bilal A.] Univ Kashmir Zakoora, Inst Technol, Dept Elect & Commun Engn, Srinagar, India.
C3 University of Kashmir; University of Kashmir
RP Parah, SA (corresponding author), Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar, India.
EM shabireltr@gmail.com
RI Jan, Aiman/ABD-2918-2021
OI Parah, Shabir/0000-0001-5983-0912
CR Al-Turjman F, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.3723
   [Anonymous], 2020, 2020 BREACH BAROMETE
   Anwar S, 2019, MULTIMED TOOLS APPL, V78, P27569, DOI 10.1007/s11042-019-07852-2
   Ayoup AM, 2016, MULTIMED TOOLS APPL, V75, P17171, DOI 10.1007/s11042-015-2985-7
   Bibri SE, 2017, SUSTAIN CITIES SOC, V31, P183, DOI 10.1016/j.scs.2017.02.016
   Cao SJ, 2020, SUSTAIN CITIES SOC, V59, DOI 10.1016/j.scs.2020.102190
   Chan EYS, 2020, LINEAR ALGEBRA APPL, V601, P72, DOI 10.1016/j.laa.2020.03.037
   Chen JX, 2015, COMMUN NONLINEAR SCI, V23, P294, DOI 10.1016/j.cnsns.2014.11.021
   Cicek I, 2017, IEEE T CIRCUITS-II, V64, P329, DOI 10.1109/TCSII.2016.2568181
   Data Breaches, 2020, DIM KOUIMTS REP DAT
   Data Breaches, 2020, OR SANG REP DAT LOSS
   Dogan, 2017, J DIGITAL FORENSICS, V12, DOI [10.15394/jdfsl.2017.1456, DOI 10.15394/JDFSL.2017.1456]
   Ghebleh M, 2018, MULTIMED TOOLS APPL, V77, P7305, DOI 10.1007/s11042-017-4634-9
   Hamza R, 2020, INFORM SCIENCES, V527, P493, DOI 10.1016/j.ins.2019.01.070
   He JH, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00500-y
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Hussain I, 2018, EUR PHYS J PLUS, V133, DOI 10.1140/epjp/i2018-11987-x
   Jiao SM, 2017, OPT COMMUN, V387, P235, DOI 10.1016/j.optcom.2016.11.066
   Jin JX, 2020, IEEE ACCESS, V8, P56730, DOI 10.1109/ACCESS.2020.2981670
   Kaushik N., 2016, INT J INNOV RES COMP, V4, P10420, DOI [10.15680/IJIRCCE.2016.0406028, DOI 10.15680/IJIRCCE.2016.0405028]
   Ke G, 2019, MEASUREMENT, V135, P385, DOI 10.1016/j.measurement.2018.11.074
   Khan FA, 2020, SUSTAIN CITIES SOC, V55, DOI 10.1016/j.scs.2020.102018
   Kumar RR, 2016, INF SECUR J, V25, P235, DOI 10.1080/19393555.2016.1248582
   Kumari M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0148-5
   Laufs J, 2020, SUSTAIN CITIES SOC, V55, DOI 10.1016/j.scs.2020.102023
   Li CQ, 2019, IEEE T CIRCUITS-I, V66, P2322, DOI 10.1109/TCSI.2018.2888688
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lin ZH, 2019, MULTIMED TOOLS APPL, V78, P20511, DOI 10.1007/s11042-018-6824-5
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Luo YQ, 2019, MULTIMED TOOLS APPL, V78, P22023, DOI 10.1007/s11042-019-7453-3
   Lyche, 2020, SPRINGER CHAM NUMERI, V22, P317, DOI [10.1007/978-3-030-36468-7_14, DOI 10.1007/978-3-030-36468-7_14]
   Merchant F, 2018, IEEE T PARALL DISTR, V29, P1707, DOI 10.1109/TPDS.2018.2803820
   Njitacke ZT, 2021, NEURAL COMPUT APPL, V33, P6733, DOI 10.1007/s00521-020-05451-z
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Parah SA, 2018, NONLINEAR DYNAM, V93, P1933, DOI 10.1007/s11071-018-4299-6
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Patro KAK, 2020, MULTIMED TOOLS APPL, V79, P12959, DOI 10.1007/s11042-019-08470-8
   Ping P, 2019, IEEE T
   Prasad Shiv, 2019, Emerging Technologies in Data Mining and Information Security. Proceedings of IEMIS 2018. Advances in Intelligent Systems and Computing (AISC 814), P203, DOI 10.1007/978-981-13-1501-5_17
   Saidi M, 2017, MULTIMED TOOLS APPL, V76, P13493, DOI 10.1007/s11042-016-3722-6
   Sankpal PR, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P102, DOI 10.1109/ICSIP.2014.80
   Silva BN, 2018, SUSTAIN CITIES SOC, V38, P697, DOI 10.1016/j.scs.2018.01.053
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P8781, DOI 10.1007/s11042-016-3522-z
   Tsafack N, 2020, IEEE ACCESS, V8, P137731, DOI 10.1109/ACCESS.2020.3010794
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Wu WB, 2020, ANN NUCL ENERGY, V143, DOI 10.1016/j.anucene.2020.107463
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yang JX, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102822
   Ye GD, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9191-x
   Zhou LC, 2020, IEEE SIGNAL PROC LET, V27, P166, DOI 10.1109/LSP.2019.2963180
   Zou N, 2020, LIBR HI TECH, V38, P769, DOI 10.1108/LHT-09-2019-0177
NR 52
TC 7
Z9 7
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18829
EP 18853
DI 10.1007/s11042-022-12653-1
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766430800008
PM 35282407
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Wu, H
   Wu, SL
   Wu, YH
   Pan, S
AF Wu, Hui
   Wu, Shilong
   Wu, Yihu
   Pan, Sha
TI AttCluster-MDGCNs: multiscale dynamic graph convolution networks with an
   attention cluster for skeletal-based action
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skeleton action recognized; Successive motion frames; Physical and
   multiscale structure information; Contextual semantic information; Graph
   structure
ID ACTION RECOGNITION
AB Traditional graph convolution networks have been widely applied to recognize skeleton action tasks and have achieved great success. However, it is challenging to build interactions between different bone joints and successive motion frames by encoding skeletal topology information of the graph structure. Thus, to strengthen the internal correlations and interaction between bone joints and successive motion frames, we presented multiscale dynamic graph convolution networks with attention clusters (AttCluster-MDGCNs) for skeleton action recognition. Our aim is to explore the relationships between bone joints and successive motion frames and to conduct local and global context encoding to learn skeleton topology automatically. Meanwhile, the recognition frameworks contain backbone networks of cluster graph convolution (Cluster-GCM), graph pruning and joint guidance (multibranch attention joint guidance, MAJG). These modules are trained jointly and enhance each other. The cluster-GCM is mainly used to capture important physical and multiscale structure information and to build interaction relationships for different bone joints. In addition, the contextual semantic information from the remaining bone joints and successive motion frames are aggregated in a multibranch attention joint-guided manner. Notably, dynamic graph topologies are built for different pruning graphs (attention pruning) and cluster graph convolutional layers of various depths. Finally, we conduct abundant experiments for skeleton action recognition with NTU-RGB + D60 and NTU-RGB + D120 baseline datasets. The experiments showed that our proposed AttCluster-MDGCNs achieve better performances on both recognition tasks compared with other methods.
C1 [Wu, Hui; Wu, Yihu; Pan, Sha] Hunan Inst Traff Engn, Sch Mech & Elect Engn, Hengyang, Hunan, Peoples R China.
   [Wu, Shilong] Chinese Acad Sci, Inst Phys, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Physics, CAS
RP Wu, SL (corresponding author), Chinese Acad Sci, Inst Phys, Beijing, Peoples R China.
EM wuhui10652@foxmail.com; swu5@iphy.ac.cn
RI Wu, Shi-Long/GQH-8378-2022
FU Hengyang Science and Technology Plan Project [2019yj011168]; Special
   Project of Educational Examination Research of 2018 in the 13th
   Five-Year Plan of Hunan Province Educational Science [XJK018JKB014]
FX The research was supported by the funds:(1) Hengyang Science and
   Technology Plan Project(2019yj011168), (2) The Special Project of
   Educational Examination Research of 2018 in the 13th Five-Year Plan of
   Hunan Province Educational Science (XJK018JKB014).
CR Banerjee A, 2021, IEEE T CIRC SYST VID, V31, P2206, DOI 10.1109/TCSVT.2020.3019293
   Bui NN, 2015, PROC SPIE, V9631, DOI 10.1117/12.2197316
   Cheng K, 2020, PROC CVPR IEEE, P180, DOI 10.1109/CVPR42600.2020.00026
   De Boissiere AM, 2020, IEEE ACCESS, V8, P168297, DOI 10.1109/ACCESS.2020.3023599
   Deng JF, 2021, COMPUT SPEECH LANG, V68, DOI 10.1016/j.csl.2020.101182
   Ding CY, 2021, APPL INTELL, V51, P560, DOI 10.1007/s10489-020-01803-3
   Ding Z, 2017, 2017 IEEE INT C MULT
   Gao X, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P601, DOI 10.1145/3343031.3351170
   Isensee F, 2021, NAT METHODS, V18, P203, DOI 10.1038/s41592-020-01008-z
   Lecrosnier L, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18010091
   Li B, 2018, MULTIMED TOOLS APPL, V77, P22901, DOI 10.1007/s11042-018-5642-0
   Li JW, 2021, INFORM SCIENCES, V549, P328, DOI 10.1016/j.ins.2020.10.045
   Li M, 2021, IEEE T PATTERN ANAL
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Li X, 2017, ADV MATH PHYS, V2017, DOI [10.1155/2017/1743789, 10.1007/s11042-016-4311-4]
   Liu Junjie, 2019, CVPR WORKSH
   Liu R., INT JOINT C NEURAL N
   Makarov I, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.357
   Nie WZ, 2019, IEEE ACCESS, V7, P132161, DOI 10.1109/ACCESS.2019.2940281
   Ren B, 2020, ARXIV PREPRINT ARXIV
   Ren J, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P199, DOI 10.1109/ICIVC.2018.8492894
   Shi L, 2020, IEEE T IMAGE PROCESS, V29, P9532, DOI 10.1109/TIP.2020.3028207
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Suzuki S, 2019, IEEE IND ELEC, P5382, DOI 10.1109/IECON.2019.8927828
   Wen YH, 2019, AAAI CONF ARTIF INTE, P8989
   Wu C, 2019, IEEE INT CONF COMP V, P1740, DOI 10.1109/ICCVW.2019.00216
   Xie J, 2021, NEUROCOMPUTING, V440, P230, DOI 10.1016/j.neucom.2021.02.001
   Xingchen Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P468, DOI 10.1109/CVPRW50498.2020.00060
   Xu D, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING (ICALIP), P568, DOI 10.1109/ICALIP.2016.7846646
   Xu M, 2017, IEEE INT CON MULTI, P517, DOI 10.1109/ICME.2017.8019351
   Xu WY, 2021, APPL SOFT COMPUT, V104, DOI 10.1016/j.asoc.2021.107236
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Zhu AC, 2020, NEUROCOMPUTING, V414, P90, DOI 10.1016/j.neucom.2020.07.068
NR 34
TC 0
Z9 0
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18855
EP 18874
DI 10.1007/s11042-022-11942-z
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766438300015
DA 2024-07-18
ER

PT J
AU Yang, N
   Wang, ZL
   Zhao, HY
   Shi, X
   Qiu, S
AF Yang, Ning
   Wang, Zhelong
   Zhao, Hongyu
   Shi, Xin
   Qiu, Sen
TI A two-step shapelets based framework for interactional activities
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Two-person interaction; Wearable sensors; Shapelets; Time series;
   Weighted fusion
ID TIME-SERIES; CLASSIFICATION; SENSORS; FUSION
AB Human-human interactions recognition has high potential to have a big impact on enabling robots being able to interact with people. Recently, body sensor networks (BSNs) have been widely applied in many fields. In this paper, we investigate the problem of recognizing human interactional activities based on BSNs. Considering that individual actions may contribute differently to the final recognition of interactions, a novel two-step framework that recognizes interactional activities by fusing labels of individual actions is presented. Specifically, shapelets based method is adopted for recognizing individual actions in the first step, and recognition of interactions is realized by weighted fusion of recognized individual actions in the second step. The framework is tested on our newly collected dataset. We mainly compare the performance of the proposed framework with traditional recognition algorithms based framework. Furthermore, feature level fusion is also conducted to verify the effectiveness of the proposed framework. Experimental results show that the proposed framework has achieved promising results with an overall recognition accuracy of 99.44%.
C1 [Yang, Ning; Wang, Zhelong; Zhao, Hongyu; Shi, Xin; Qiu, Sen] Dalian Univ Technol, Sch Control Sci & Engn, Dalian 116024, Peoples R China.
C3 Dalian University of Technology
RP Yang, N (corresponding author), Dalian Univ Technol, Sch Control Sci & Engn, Dalian 116024, Peoples R China.
EM yangn_Y@mail.dlut.edu.cn
FU National Natural Science Foundation of China [61873044, 61903062,
   61803072]; Natural Science Foundation of Liaoning Province
   [2019-MS-056]; Dalian Science and Technology Innovation fund
   [2018J12SN077, 2019J13SN99, 2020JJ27SN067]; Fundamental Research Funds
   for the Central Universities [DUT21YG125]
FX This work was supported in part by National Natural Science Foundation
   of China under Grant 61873044, Grant 61903062, and Grant 61803072, in
   part by Natural Science Foundation of Liaoning Province under Grant No.
   2019-MS-056, in part by Dalian Science and Technology Innovation fund
   2018J12SN077, 2019J13SN99 and 2020JJ27SN067, and in part by Fundamental
   Research Funds for the Central Universities under Grant DUT21YG125.
CR Afrasiabi M, 2020, MULTIMED TOOLS APPL, V79, P20019, DOI 10.1007/s11042-020-08845-2
   Al noman a, 2019, 2019 10 INT C COMP C, P1, DOI [10.1109/ICCCNT45670.2019.8944512, DOI 10.1109/ICCCNT45670.2019.8944512]
   Alazrai R, 2015, PATTERN RECOGN, V48, P2346, DOI 10.1016/j.patcog.2015.03.002
   Attal F, 2015, SENSORS-BASEL, V15, P31314, DOI 10.3390/s151229858
   Avci A, 2011, INT C ARCH COMP SYST, P167
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4405, DOI 10.1007/s11042-015-3177-1
   Chen YF, 2017, IEEE ACCESS, V5, P3095, DOI 10.1109/ACCESS.2017.2676168
   Chernbumroong S, 2015, IEEE J BIOMED HEALTH, V19, P282, DOI 10.1109/JBHI.2014.2313473
   Coppola C, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P5055, DOI 10.1109/IROS.2016.7759742
   Damaeviius R., 2016, COMPUT MATH METHOD M, P1
   Fullerton E, 2017, IEEE SENS J, V17, P5290, DOI 10.1109/JSEN.2017.2722105
   Gravina R, 2017, INFORM FUSION, V35, P68, DOI 10.1016/j.inffus.2016.09.005
   Guo M, 2018, MULTIMED TOOLS APPL, V77, P21201, DOI 10.1007/s11042-017-5573-1
   Hills J, 2014, DATA MIN KNOWL DISC, V28, P851, DOI 10.1007/s10618-013-0322-1
   Hsu YL, 2018, IEEE ACCESS, V6, P31715, DOI 10.1109/ACCESS.2018.2839766
   Jain A, 2018, IEEE SENS J, V18, P1169, DOI 10.1109/JSEN.2017.2782492
   Ji XF, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7060567
   Keçeli AS, 2018, IET COMPUT VIS, V12, P331, DOI 10.1049/iet-cvi.2017.0204
   Kong Y, 2016, IEEE T IMAGE PROCESS, V25, P167, DOI 10.1109/TIP.2015.2498410
   Kong Y, 2014, IEEE T PATTERN ANAL, V36, P1775, DOI 10.1109/TPAMI.2014.2303090
   Kurban OC, 2019, IEEE SENS J, V19, P7543, DOI 10.1109/JSEN.2019.2915524
   Li M, 2019, MULTIMED TOOLS APPL, V78, P5731, DOI 10.1007/s11042-018-5738-6
   Li M, 2016, IEEE T MULTIMEDIA, V18, P2293, DOI 10.1109/TMM.2016.2614228
   Liu L, 2016, INFORM SCIENCES, V340, P41, DOI 10.1016/j.ins.2016.01.020
   Liu L, 2015, KNOWL-BASED SYST, V90, P138, DOI 10.1016/j.knosys.2015.09.024
   Liu P, 2016, IEEE T ROBOT, V32, P988, DOI 10.1109/TRO.2016.2588880
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Manzi A, 2018, IET COMPUT VIS, V12, P27, DOI 10.1049/iet-cvi.2017.0118
   Mohanty M, 2018, BIOMED SIGNAL PROCES, V44, P200, DOI 10.1016/j.bspc.2018.04.005
   Peng LY, 2017, IEEE T BIO-MED ENG, V64, P1369, DOI 10.1109/TBME.2016.2604856
   Portugal D, 2015, 2015 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P811, DOI 10.1109/SII.2015.7405084
   Qiu S., 2018, IEEE SENS J, P1
   Rashidi P, 2013, IEEE J BIOMED HEALTH, V17, P579, DOI 10.1109/JBHI.2012.2234129
   Wang H., 2018, Data Science Journal, V17, P1, DOI [10.5334/dsj-2018-006, DOI 10.5334/DSJ-2018-006]
   Wang ZL, 2016, IEEE SENS J, V16, P3198, DOI 10.1109/JSEN.2016.2519679
   Wei Y, 2015, 2015 INTERNATIONAL CONFERENCE ON IDENTIFICATION, INFORMATION, AND KNOWLEDGE IN THE INTERNET OF THINGS (IIKI), P7, DOI 10.1109/IIKI.2015.9
   Wu HM, 2018, IEEE T HUM-MACH SYST, V48, P304, DOI 10.1109/THMS.2017.2776211
   Yang Y, 2016, PROC INT C TOOLS ART, P423, DOI [10.1109/ICTAI.2016.68, 10.1109/ICTAI.2016.0071]
   Yatbaz HY, 2019, IEEE SENS J, V19, P7575, DOI 10.1109/JSEN.2019.2915026
   Ye LX, 2011, DATA MIN KNOWL DISC, V22, P149, DOI 10.1007/s10618-010-0179-5
   Ye LX, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P947
   Yuan JD, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414500141
   Zalewski W, 2016, KNOWL-BASED SYST, V112, P80, DOI 10.1016/j.knosys.2016.08.028
   Zhang S., 2017, INT CONF ACOUST SPEE, P1
   Zhao HY, 2019, INFORM FUSION, V52, P157, DOI 10.1016/j.inffus.2019.03.002
   Zlatintsi A, 2017, COMP ACM IEEE INT C
NR 46
TC 1
Z9 1
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 17595
EP 17614
DI 10.1007/s11042-022-11987-0
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000765701900011
DA 2024-07-18
ER

PT J
AU Li, MX
   Zhou, GX
   Lu, C
AF Li, Mingxuan
   Zhou, Guoxiong
   Lu, Chao
TI Peach surface defect identification of complex background based on IDCNN
   and GWOABC-KM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Peach defect recognition; Idcnn model; Gwoabc algorithm; Background
   segmentation
ID AUTOMATIC DETECTION; IMAGE; TRANSFORM; FRUITS; INSPECTION; ALGORITHM;
   QUALITY
AB This paper presents a peach surface defect recognition method based on GWOABC-KM (Gray Wolf algorithm and K-means optimized by improved bee swarm algorithm). Firstly, aiming at the problem of poor sharpness and noise in peach images taken in natural environment, the peach images collected by IDCNN (DCNN model combined with Inception structure) are denoised. Then, aiming at the problem that the complex background interferes greatly and affects the accurate segmentation of defective areas, the denoising is carried out by using threshold and edge detection fusion algorithm. The background information of the processed image is removed to get the complete peach image. Finally, the GWOABC algorithm is used to determine the type of peach defect. The method was validated on the peach dataset collected, and the detection rate was 93.7% and 97.4% respectively. Compared with the traditional fruit surface defect detection, this algorithm can better complete the surface defect recognition.
C1 [Li, Mingxuan; Zhou, Guoxiong; Lu, Chao] Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha, Hunan, Peoples R China.
C3 Central South University of Forestry & Technology
RP Zhou, GX (corresponding author), Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha, Hunan, Peoples R China.
EM 173523919@qq.com; zhougx01@163.com; 1244414754@qq.com
RI 陆, 超/AFD-5669-2022; liu, jianyang/JXL-6273-2024
OI Zhou, Guoxiong/0000-0002-5142-4845
CR Ahn B., 2017, BLOCK MATCHING CONVO
   Akay B, 2013, J GLOBAL OPTIM, V57, P415, DOI 10.1007/s10898-012-9993-1
   [Anonymous], CoRR abs/1511.07122
   Boutsidis C, 2015, IEEE T INFORM THEORY, V61, P1045, DOI 10.1109/TIT.2014.2375327
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chen N, 2014, APPL MATH SER B, V29, P1, DOI 10.1007/s11766-014-3091-8
   Chen YR, 2002, COMPUT ELECTRON AGR, V36, P173, DOI 10.1016/S0168-1699(02)00100-X
   Cruz C, 2018, IEEE SIGNAL PROC LET, V25, P1216, DOI 10.1109/LSP.2018.2850222
   Cubero S, 2011, FOOD BIOPROCESS TECH, V4, P487, DOI 10.1007/s11947-010-0411-8
   Cui XL, 2014, J SUPERCOMPUT, V70, P1249, DOI 10.1007/s11227-014-1225-7
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Feng Bin Feng Bin, 2002, Journal of China Agricultural University, V7, P73
   Fu Feng Fu Feng, 2004, Transactions of the Chinese Society of Agricultural Engineering, V20, P117
   Jain V., 2009, ADV NEURAL INFORM PR, P769, DOI DOI 10.5555/2981780.2981876
   Karaboga D, 2011, APPL SOFT COMPUT, V11, P652, DOI 10.1016/j.asoc.2009.12.025
   Kishor A., 2016, P 5 INT C SOFT COMP, V436, P1037, DOI DOI 10.1007/978-981-10-0448-3_87
   Li, 2018, J CHANGSHU I TECHNOL, V32, P78
   Li J., 2014, J AGR MACHINERY, V45, P288, DOI DOI 10.6041/J.ISSN.1000-1298.2014.08.046
   Li JB, 2013, POSTHARVEST BIOL TEC, V82, P59, DOI 10.1016/j.postharvbio.2013.02.016
   Li JiangBo Li JiangBo, 2011, Nongye Jixie Xuebao = Transactions of the Chinese Society for Agricultural Machinery, V42, P159
   Li L., 2016, J HARBIN U SCI TECHN, V21, P31
   Lin Q, 2015, INT C MOD ID CONTR, P1
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   López-García F, 2010, COMPUT ELECTRON AGR, V71, P189, DOI 10.1016/j.compag.2010.02.001
   Ma L, 2015, INT J GRID DISTRIB, V8, P189, DOI 10.14257/ijgdc.2015.8.1.18
   Pathare PB, 2012, FOOD BIOPROCESS TECH, V5, P2031, DOI [10.1007/s11947-012-0867-9, 10.1007/s11947-012-0883-9]
   Pertot I, 2012, COMPUT ELECTRON AGR, V84, P144, DOI 10.1016/j.compag.2012.02.014
   Remez T, 2018, IEEE T IMAGE PROCESS, V27, P5707, DOI 10.1109/TIP.2018.2859044
   Sarkar JP, 2016, APPL SOFT COMPUT, V46, P527, DOI 10.1016/j.asoc.2016.01.040
   Shahrivari S, 2016, INFORM SYST, V60, P1, DOI 10.1016/j.is.2016.02.007
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   [汤成 Tang Cheng], 2019, [中国图象图形学报, Journal of Image and Graphics], V24, P346
   Tao Y, 1999, T ASAE, V42, P241, DOI 10.13031/2013.13201
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   TSAPANOS N, 2016, AUTOMATICA
   [徐少平 Xu Shaoping], 2017, [中国图象图形学报, Journal of Image and Graphics], V22, P422
   Yan XH, 2012, NEUROCOMPUTING, V97, P241, DOI 10.1016/j.neucom.2012.04.025
   Zhang BH, 2014, SPECTROSC SPECT ANAL, V34, P2743, DOI 10.3964/j.issn.1000-0593(2014)10-2743-09
   Zhang BH, 2015, FOOD ANAL METHOD, V8, P2075, DOI 10.1007/s12161-015-0097-7
   Zhang BH, 2015, COMPUT ELECTRON AGR, V114, P14, DOI 10.1016/j.compag.2015.03.015
   Zhang CM, 2017, IEEE T IMAGE PROCESS, V26, P1355, DOI 10.1109/TIP.2016.2621670
   Zhang HaiLiang Zhang HaiLiang, 2013, Nongye Jixie Xuebao = Transactions of the Chinese Society for Agricultural Machinery, V44, P177
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zou XB, 2010, COMPUT ELECTRON AGR, V70, P129, DOI 10.1016/j.compag.2009.09.014
NR 45
TC 1
Z9 1
U1 6
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16309
EP 16334
DI 10.1007/s11042-022-12563-2
EA MAR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256600018
DA 2024-07-18
ER

PT J
AU Fahad, MS
   Singh, S
   Abhinav
   Ranjan, A
   Deepak, A
AF Fahad, Md Shah
   Singh, Shreya
   Abhinav
   Ranjan, Ashish
   Deepak, Akshay
TI Emotion recognition from spontaneous speech using emotional vowel-like
   regions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotional vowel; Single frequency cepstral coefficients (SFCC);
   Fundamental-frequency; Speech emotion recognition (SER); Long-utterance;
   Vowel-like-regions(VLRs)
ID SPEAKER VERIFICATION; EPOCH EXTRACTION; FREQUENCY
AB Spontaneous speech varies in terms of characteristics such as emotion, volume, and pitch. Emotion, itself, is not uniformly distributed across an utterance. The extraction of relevant portions from an utterance that contain meaningful information in terms of emotion is always challenging. The vowel like regions (VLRs) are known to contain emotion-specific information. However, for spontaneous speech, all the VLRs in an utterance do not contain emotion. This paper proposes a method for extracting the emotional VLRs from a set of vowels in an utterance based on the fundamental frequency of a VLR. Further, the recently proposed epoch synchronous single frequency cepstral coefficients (SFCCs) features are combined with the epoch-based features producing 1.33% better result than state-of-the-art technique. In general, the accuracy value reduces for long utterances because all the VLRs in a long utterance are not consistent with the ground truth label. However, the proposed approach produced an improvement in accuracy by 8.22% for the long utterances when emotional VLRs were used in place of all VLRs.
C1 [Fahad, Md Shah; Singh, Shreya; Abhinav; Ranjan, Ashish; Deepak, Akshay] Natl Inst Technol, Dept Comp Sci & Engn, Patna, Bihar, India.
   [Fahad, Md Shah] Vellore Inst Technol, Bhopal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna; VIT Bhopal University
RP Fahad, MS (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Patna, Bihar, India.; Fahad, MS (corresponding author), Vellore Inst Technol, Bhopal, India.
EM shah.cse16@nitp.ac.in; shreya1506017@nitp.ac.in;
   mastersabhinav@gmail.com; ashish.cse16@nitp.ac.in; akshayd@nitp.ac.in
RI Ranjan, Ashish/KIC-1205-2024
OI Ranjan, Ashish/0000-0002-0091-1088
CR Aneeja G, 2015, IEEE-ACM T AUDIO SPE, V23, P705, DOI 10.1109/TASLP.2015.2404035
   [Anonymous], FUNDAMENTALS SPEECH
   [Anonymous], IEEE T AFFECT COMPUT
   [Anonymous], 2009, Automatic Classification of Emotion-Related User States in Spontaneous Children's Speech
   Badshah AM, 2019, MULTIMED TOOLS APPL, V78, P5571, DOI 10.1007/s11042-017-5292-7
   Badshah AM, 2017, 2017 INTERNATIONAL CONFERENCE ON PLATFORM TECHNOLOGY AND SERVICE (PLATCON), P125
   Burkhardt F., 2005, 9 EUROPEAN C SPEECH
   Busso C., 2009, FUNDAMENTAL FREQUENC, P309
   Busso C, 2009, IEEE T AUDIO SPEECH, V17, P582, DOI 10.1109/TASL.2008.2009578
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Chen MY, 2018, IEEE SIGNAL PROC LET, V25, P1440, DOI 10.1109/LSP.2018.2860246
   Fahad MS, 2021, CIRC SYST SIGNAL PR, V40, P466, DOI 10.1007/s00034-020-01486-8
   Franke J, 2016, ITG S SPEECH COMMUNI
   Gosztolya G, 2008, LECT NOTES ARTIF INT, V5097, P782, DOI 10.1007/978-3-540-69731-2_75
   Gupta S, 2020, MULTIMED TOOLS APPL, V79, P23347, DOI 10.1007/s11042-020-09068-1
   Haq S., 2011, MACHINE AUDITION PRI, P398, DOI DOI 10.4018/978-1-61520-919-4.CH017
   Kadiri SR, 2017, SPEECH COMMUN, V86, P52, DOI 10.1016/j.specom.2016.11.005
   Koolagudi SG, 2009, COMM COM INF SC, V40, P485, DOI 10.1007/978-3-642-03547-0_46
   Lee J, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1537
   Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552
   Murty KSR, 2008, IEEE T AUDIO SPEECH, V16, P1602, DOI 10.1109/TASL.2008.2004526
   Pradhan G, 2013, IEEE T AUDIO SPEECH, V21, P854, DOI 10.1109/TASL.2013.2238529
   Prasanna SRM, 2011, IEEE T AUDIO SPEECH, V19, P2552, DOI 10.1109/TASL.2011.2155061
   Prasanna SRM, 2004, 2004 IEEE INT C ACOU, V1, pI
   Rao KS, 2013, INT J SPEECH TECHNOL, V16, P143, DOI 10.1007/s10772-012-9172-2
   Ringeval F, 2013, IEEE INT CONF AUTOMA
   Satt A, 2017, INTERSPEECH, P1089, DOI 10.21437/Interspeech.2017-200
   Sreenivasa Rao K., 2013, ROBUST EMOTION RECOG
   Tian LM, 2015, INT CONF AFFECT, P698, DOI 10.1109/ACII.2015.7344645
   Wang JC, 2017, MULTIMED TOOLS APPL, V76, P4055, DOI 10.1007/s11042-016-3335-0
   Yegnanarayana B, 2011, INT CONF ACOUST SPEE, P5392
   Zeng YN, 2019, MULTIMED TOOLS APPL, V78, P3705, DOI 10.1007/s11042-017-5539-3
NR 32
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14025
EP 14043
DI 10.1007/s11042-022-12453-7
EA FEB 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761886300013
DA 2024-07-18
ER

PT J
AU Gupta, S
   Thakur, S
   Gupta, A
AF Gupta, Shubhi
   Thakur, Sanjeev
   Gupta, Ashutosh
TI Optimized hybrid machine learning approach for smartphone based diabetic
   retinopathy detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smartphone; Machine learning; Optimization; Diabetic retinopathy;
   Segmentation; And DIY smartphone enabled camera
ID CLASSIFICATION; PHOTOGRAPHY; CAMERA
AB Diabetic Retinopathy (DR) is defined as the Diabetes Mellitus difficulty that harms the blood vessels in the retina. It is also known as a silent disease and cause mild vision issues or no symptoms. In order to enhance the chances of effective treatment, yearly eye tests are vital for premature discovery. Hence, it uses fundus cameras for capturing retinal images, but due to its size and cost, it is a troublesome for extensive screening. Therefore, the smartphones are utilized for scheming low-power, small-sized, and reasonable retinal imaging schemes to activate automated DR detection and DR screening. In this article, the new DIY (do it yourself) smartphone enabled camera is used for smartphone based DR detection. Initially, the preprocessing like green channel transformation and CLAHE (Contrast Limited Adaptive Histogram Equalization) are performed. Further, the segmentation process starts with optic disc segmentation by WT (watershed transform) and abnormality segmentation (Exudates, microaneurysms, haemorrhages, and IRMA) by Triplet half band filter bank (THFB). Then the different features are extracted by Haralick and ADTCWT (Anisotropic Dual Tree Complex Wavelet Transform) methods. Using life choice-based optimizer (LCBO) algorithm, the optimal features are chosen from the mined features. Then the selected features are applied to the optimized hybrid ML (machine learning) classifier with the combination of NN and DCNN (Deep Convolutional Neural Network) in which the SSD (Social Ski-Driver) is utilized for the best weight values of hybrid classifier to categorize the severity level as mild DR, severe DR, normal, moderate DR, and Proliferative DR. The proposed work is simulated in python environment and to test the efficiency of the proposed scheme the datasets like APTOS-2019-Blindness-Detection, and EyePacs are used. The model has been evaluated using different performance metrics. The simulation results verified that the suggested scheme is provides well accuracy for each dataset than other current approaches.
C1 [Gupta, Shubhi] Amity Univ, Dept Comp Sci, Noida, Uttar Pradesh, India.
   [Thakur, Sanjeev] Amity Univ, Noida, Uttar Pradesh, India.
   [Gupta, Ashutosh] UP Rajarshi Tandon Open Univ, Prayagraj, Uttar Pradesh, India.
C3 Amity University Noida; Amity University Noida
RP Gupta, S (corresponding author), Amity Univ, Dept Comp Sci, Noida, Uttar Pradesh, India.
EM sr23.shubhi@gmail.com
RI gupta, shubhi/GLV-5638-2022
OI gupta, shubhi/0000-0002-3618-3457
CR Amin J, 2018, MICROSC RES TECHNIQ, V81, P990, DOI 10.1002/jemt.23063
   Aujih A. B., 2018, 2018 INT C INTELLIGE, P1, DOI DOI 10.1109/ICIAS.2018.8540642
   Bajwa M. N., 2019, ANN C MED IM UND AN, V1065, P242
   Bellemo V, 2019, CURR DIABETES REP, V19, DOI 10.1007/s11892-019-1189-3
   Bhavana S, 2019, MEDIOS SMARTPHONE BA
   Bilong Y, 2019, OSLI RETINA, V50, pS18, DOI 10.3928/23258160-20190108-05
   Bodapati JD, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060914
   Dekhil O, 2019, IEEE CONF IMAGING SY, DOI 10.1109/ist48021.2019.9010333
   Gayathri S, 2020, IEEE ACCESS, V8, P57497, DOI 10.1109/ACCESS.2020.2979753
   Hacisoftaoglu RE, 2020, PATTERN RECOGN LETT, V135, P409, DOI 10.1016/j.patrec.2020.04.009
   Hossein K. M., 2019, 2019 IEEE CAN C EL C, P1, DOI DOI 10.1109/CCECE.2019.8861857
   Islam MR, 2020, IEEE REGION 10 SYMP, P888
   Jadhav AS, 2021, EVOL INTELL, V14, P1431, DOI 10.1007/s12065-020-00400-0
   Karakaya M, 2020, BMC BIOINFORMATICS, V21, DOI 10.1186/s12859-020-03587-2
   Khatri A, 2020, SOFT COMPUT, V24, P9121, DOI 10.1007/s00500-019-04443-z
   Kim TN, 2021, EYE, V35, P334, DOI 10.1038/s41433-020-0849-5
   Kumar S, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105815
   Majumder S, 2020, PROC SPIE, V11401, DOI 10.1117/12.2557554
   Prathiba V, 2020, INDIAN J OPHTHALMOL, V68, pS42, DOI 10.4103/ijo.IJO_1937_19
   Queiroz MS, 2020, ACTA DIABETOL, V57, P1493, DOI 10.1007/s00592-020-01585-7
   Rajalakshmi R, 2018, EYE, V32, P1138, DOI 10.1038/s41433-018-0064-9
   Raju B, 2016, INDIAN J OPHTHALMOL, V64, P663, DOI 10.4103/0301-4738.194325
   Randive SN, 2018, EVOL INTELL, V11, P117, DOI 10.1007/s12065-018-0158-0
   Shanthi T, 2019, COMPUT ELECTR ENG, V76, P56, DOI 10.1016/j.compeleceng.2019.03.004
   Sheikh Sarah, 2021, Intelligent Systems and Applications. Proceedings of the 2020 Intelligent Systems Conference (IntelliSys). Advances in Intelligent Systems and Computing (AISC 1252), P469, DOI 10.1007/978-3-030-55190-2_35
   Singh RP, 2019, J DIABETES COMPLICAT, V33, DOI 10.1016/j.jdiacomp.2019.107417
   Taufiqurrahman Shidqie, 2020, 2020 IEEE Region 10 Conference (TENCON), P235, DOI 10.1109/TENCON50793.2020.9293739
   Tharwat A, 2020, NEURAL COMPUT APPL, V32, P6925, DOI 10.1007/s00521-019-04159-z
   Thota NB, 2020, MIDWEST SYMP CIRCUIT, P1003, DOI [10.1109/MWSCAS48704.2020.9184473, 10.1109/mwscas48704.2020.9184473]
   Usman N., 2020, DIABETIC RETINOPATHY, P26
   Wang FP, 2020, OPHTHALMOL RETINA, V4, P415, DOI 10.1016/j.oret.2019.10.018
   Wang XL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P465, DOI 10.1109/IRI.2018.00074
   Wintergerst MWM, 2020, OPHTHALMOLOGY, V127, P1529, DOI 10.1016/j.ophtha.2020.05.025
   Wu Z, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101936
   Zhou Y, 2019, LECT NOTES COMPUT SC, V11764, P505, DOI 10.1007/978-3-030-32239-7_56
NR 35
TC 12
Z9 13
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14475
EP 14501
DI 10.1007/s11042-022-12103-y
EA FEB 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300028
PM 35233182
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Li, HJ
   Wang, XY
AF Li, Hengjian
   Wang, Xiyu
TI One factor cancellable fingerprint scheme based on novel minimum hash
   signature and secure extended feature vector
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric protection; Novel minimum hash signature; Secure extended
   feature vector; Pseudo identifier
ID CANCELABLE BIOMETRICS; GENERATION; TEMPLATES
AB To solve the problems of privacy preserving and biometric template protection, the one-factor fingerprint biometric authentication scheme based on Novel Minimum Hash Signature (NMHS) and Secure Extended Feature Vector (SEFV) is proposed to generate Pseudo Identifiers. The NMHS algorithm is designed to generate hash codes using the symbols '1' and '0' of the binary fingerprint template and the XOR operation in the hashing process is used to improve the stable of the performance. Then, XOR operation is carried out between the hash codes and the random binary string to get the encryption string to form the fuzzy vault. Furtherly, to improves the security of fingerprint template, the SEFV hash is used to get the Pseudo Identifier. During authentication stage, the Pseudo Identifier is generated with genuine queries using the auxiliary data providing by the system and then is employed to classify using the hamming distance. To improve the performance during the authentication stage, the matching score of '1' and '0' are fused by a novel fusion rule. Experimental results demonstrate that the proposed scheme is also shown satisfy irreversibility, unlinkability and revocability template protection criteria while preserving the favorable authentication performance on benchmark FVC2002 and FVC2004 fingerprint databases. The security and privacy attacks such as the Brute-force attack, False accept attack and Birthday attack are also analyzed in theory in the experiments.
C1 [Li, Hengjian; Wang, Xiyu] Jinan Univ, Sch Informat Sci & Engn, Jinan 250022, Peoples R China.
C3 University of Jinan
RP Li, HJ (corresponding author), Jinan Univ, Sch Informat Sci & Engn, Jinan 250022, Peoples R China.
EM hengjianli@gmail.com
RI wang, xiyu/GYA-4086-2022; He, FC/KGL-6713-2024
CR Abe N, 2015, P IEEE 7 INT C BIOM, P1, DOI DOI 10.1109/BTAS.2015.7358770
   Al-Badarneh A, 2017, INT CONF INFORM COMM, P165, DOI 10.1109/IACS.2017.7921965
   [Anonymous], 2012, Second Generation Biometrics: the Ethical, Legal and Social Context
   Bringer J, 2017, IMAGE VISION COMPUT, V58, P239, DOI 10.1016/j.imavis.2016.08.002
   Broder A. Z., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P327, DOI 10.1145/276698.276781
   Broder Andrei, 2003, Internet Math, V1, DOI DOI 10.1080/15427951.2004.10129096
   Broder AZ, 1998, COMPRESSION AND COMPLEXITY OF SEQUENCES 1997 - PROCEEDINGS, P21, DOI 10.1109/SEQUEN.1997.666900
   Cappelli R, 2010, IEEE T PATTERN ANAL, V32, P2128, DOI 10.1109/TPAMI.2010.52
   Cen W, 2015, INT CONF COMP SCI ED, P61, DOI 10.1109/ICCSE.2015.7250218
   Chen X, 2015, INT WORKS HIGH MOBIL, P36, DOI 10.1109/HMWC.2015.7353351
   Farooq F, 2007, PROC CVPR IEEE, P2946
   Ferrara M, 2012, IEEE T INF FOREN SEC, V7, P1727, DOI 10.1109/TIFS.2012.2215326
   Ferreira M, 2016, INT J ADV MANUF TECH, V85, P57, DOI 10.1007/s00170-014-6026-x
   Gomez-Barrero M, 2018, IEEE T INF FOREN SEC, V13, P1406, DOI 10.1109/TIFS.2017.2788000
   Jain AK, 2003, IEEE T PATTERN ANAL, V25, P1494, DOI 10.1109/TPAMI.2003.1240122
   Jain AK, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/579416
   Jin Z, 2018, IEEE T INF FOREN SEC, V13, P393, DOI 10.1109/TIFS.2017.2753172
   Jin Z, 2016, IEEE T SYST MAN CY-S, V46, P1415, DOI 10.1109/TSMC.2015.2499725
   Juels A, 2006, DESIGN CODE CRYPTOGR, V38, P237, DOI 10.1007/s10623-005-6343-z
   Kim J, 2018, INT C PATT RECOG, P3108, DOI 10.1109/ICPR.2018.8545565
   Kwon M, 2019, EUR CONF NETW COMMUN, P453, DOI [10.1109/EuCNC.2019.8801958, 10.1109/eucnc.2019.8801958]
   Lai YL, 2017, PATTERN RECOGN, V64, P105, DOI 10.1016/j.patcog.2016.10.035
   Lee MJ, 2018, IEEE INT WORKS INFOR
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Li HJ, 2020, MULTIMED TOOLS APPL, V79, P11947, DOI 10.1007/s11042-019-08446-8
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Maio D, 2004, LECT NOTES COMPUT SC, V3072, P1
   Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144
   MCKINNEY EH, 1966, AM MATH MON, V73, P385, DOI 10.2307/2315408
   Nagar A, 2010, PATTERN RECOGN LETT, V31, P733, DOI 10.1016/j.patrec.2009.07.003
   Nandakumar K, 2015, IEEE SIGNAL PROC MAG, V32, P88, DOI 10.1109/MSP.2015.2427849
   Olszewska JI, 2019, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE (ICAART), VOL 2, P850, DOI 10.5220/0007585208500856
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151
   Qiu J, 2019, COMPUT SECUR, V82, P1, DOI 10.1016/j.cose.2018.12.003
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Rathgeb C, 2013, INT CONF BIOMETR
   Rathgeb C, 2015, 3 INT WORKSHOP BIOME, P1
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
   Sadhya D, 2019, IEEE T INF FOREN SEC, V14, P2972, DOI 10.1109/TIFS.2019.2907014
   Sutcu Y, 2008, IEEE INT SYMP INFO, P2297, DOI 10.1109/ISIT.2008.4595400
   Sutcu Y, 2007, PROC SPIE, V6539, DOI 10.1117/12.721058
   Sutcu Yagiz., 2007, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P1
   Tams B, 2015, IEEE T INF FOREN SEC, V10, P985, DOI 10.1109/TIFS.2015.2392559
   Wang S, 2016, PATTERN RECOGN, V54, P14, DOI 10.1016/j.patcog.2016.01.001
   Wang XY, 2019, IEEE ACCESS, V7, P131338, DOI 10.1109/ACCESS.2019.2938019
   Yang B, 2009, PROC IEEE 3 INTCONF, P1
   Yang WC, 2018, PATTERN RECOGN, V78, P242, DOI 10.1016/j.patcog.2018.01.026
NR 49
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 13087
EP 13113
DI 10.1007/s11042-022-12424-y
EA FEB 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000760059700003
DA 2024-07-18
ER

PT J
AU Khoddami, AA
   Moallem, P
   Kazemi, M
AF Khoddami, Ali Asghar
   Moallem, Payman
   Kazemi, Mohammad
TI Large scaling factor depth map super-resolution using progressive
   joint-multilateral filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth map super-resolution; Scaling factor; Bilateral filter;
   Directional kernel
ID STEREOSCOPIC IMAGE; QUALITY ASSESSMENT
AB Depth images captured by conventional RGB-D sensors such as ToF cameras have limited resolution. Despite recent advances in depth camera technology, there is still a significant difference between the resolution of depth and color images. Therefore, depth map Super-Resolution (SR) techniques have received attention. Specifically, achieving an algorithm performing well at large scaling factors is of great importance and also challenging. In most existing methods, the up-sampling of low resolution depth images to the desired size is performed by an interpolation operation during the beginning stage and quality improvement filters are applied then. Due to the different nature of depth images and their sparsity, magnifying the images in a single step brings heavy artifacts specially at large up-sampling factors (e.g., 16). To tackle this problem, we propose a progressive multi-step depth map SR method where interpolation and modified enhancement processes are applied iteratively. This extremely improves the quality of the output depth image. Moreover, considering the importance of edges and discontinuities in depth images, instead of using conventional symmetric kernel, an edge directed kernel is applied which effectively avoids blurring. In addition, texture copying and depth bleeding artifacts are reduced employing a depth range filter. Quantitative and qualitative results of comprehensive experiments on Middlebury and real-world datasets demonstrate the effectiveness of our approach over prior depth SR works, especially for large scaling factors of 16, 32 and even 64.
C1 [Khoddami, Ali Asghar; Moallem, Payman; Kazemi, Mohammad] Univ Isfahan, Fac Engn, Dept Elect Engn, Esfahan, Iran.
C3 University of Isfahan
RP Moallem, P (corresponding author), Univ Isfahan, Fac Engn, Dept Elect Engn, Esfahan, Iran.
EM p_moallem@eng.ui.ac.ir
RI Kazemi, Mohammad/G-7733-2017
OI Khoddami, Ali Asghar/0000-0002-5178-0938
CR Camplani M, 2017, IET COMPUT VIS, V11, P265, DOI 10.1049/iet-cvi.2016.0178
   Chowdhary C.L., 2019, RECENT PAT COMPUT SC, V12, P18, DOI [10.2174/2213275911666180821092033, DOI 10.2174/2213275911666180821092033]
   Chowdhary CL, 2015, 2015 INTERNATIONAL CONFERENCE ON EMERGING TRENDS IN NETWORKS AND COMPUTER COMMUNICATIONS (ETNCC), P162, DOI 10.1109/ETNCC.2015.7184827
   Cui Y, 2010, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2010.5540082
   da Silva SPP, 2020, IEEE SENS J, V20, P12040, DOI 10.1109/JSEN.2020.2964735
   Diebel J., 2005, P 18 INT C NEUR INF, V18, P291
   Ferstl D, 2015, IEEE I CONF COMP VIS, P513, DOI 10.1109/ICCV.2015.66
   Ferstl D, 2013, IEEE I CONF COMP VIS, P993, DOI 10.1109/ICCV.2013.127
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hornácek M, 2013, PROC CVPR IEEE, P1123, DOI 10.1109/CVPR.2013.149
   Horng YR, 2010, IEEE INT SYMP CIRC S, P2650, DOI 10.1109/ISCAS.2010.5537052
   Hui TW, 2016, LECT NOTES COMPUT SC, V9907, P353, DOI 10.1007/978-3-319-46487-9_22
   Kaashki NN, 2018, J VIS COMMUN IMAGE R, V52, P66, DOI 10.1016/j.jvcir.2018.02.003
   Kim Y, 2016, IEEE T IMAGE PROCESS, V25, P5227, DOI 10.1109/TIP.2016.2601262
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276497, 10.1145/1239451.1239547]
   Landau MJ, 2016, IEEE T CYBERNETICS, V46, P3018, DOI 10.1109/TCYB.2015.2494877
   Li YM, 2018, COMPUT ELECTR ENG, V70, P509, DOI 10.1016/j.compeleceng.2017.08.011
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P120, DOI 10.1109/TIP.2014.2371234
   Liao YW, 2019, MULTIMED TOOLS APPL, V78, P10181, DOI 10.1007/s11042-018-6547-7
   Liu XG, 2017, IEEE SYST J, V11, P2829, DOI 10.1109/JSYST.2015.2478119
   Lo KH, 2018, IEEE T CYBERNETICS, V48, P371, DOI 10.1109/TCYB.2016.2637661
   Lu HM, 2017, IEEE ACCESS, V5, P7115, DOI 10.1109/ACCESS.2017.2690455
   Mac Aodha O, 2012, LECT NOTES COMPUT SC, V7574, P71, DOI 10.1007/978-3-642-33712-3_6
   Marin G, 2019, DATA BRIEF, V27, DOI 10.1016/j.dib.2019.104619
   Paris S, 2008, FOUND TRENDS COMPUT, V4, P1, DOI 10.1561/0600000020
   Park J, 2011, IEEE I CONF COMP VIS, P1623, DOI 10.1109/ICCV.2011.6126423
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Riegler G, 2016, LECT NOTES COMPUT SC, V9907, P268, DOI 10.1007/978-3-319-46487-9_17
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Sun CC, 2017, IEEE SENS J, V17, P5728, DOI 10.1109/JSEN.2017.2723599
   Tech G, 2016, IEEE T CIRC SYST VID, V26, P35, DOI 10.1109/TCSVT.2015.2477935
   Voo KHB, 2018, MULTIMED TOOLS APPL, V77, P2313, DOI 10.1007/s11042-017-4361-2
   Wang YC, 2018, IEEE T IMAGE PROCESS, V27, P3571, DOI 10.1109/TIP.2018.2820809
   Xie J, 2016, IEEE T IMAGE PROCESS, V25, P428, DOI 10.1109/TIP.2015.2501749
   Xie J, 2015, IEEE T MULTIMEDIA, V17, P1525, DOI 10.1109/TMM.2015.2457678
   Zhai GT, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-2757-1
   Zhang YF, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.3.033019
NR 38
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11461
EP 11478
DI 10.1007/s11042-022-12253-z
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757777400007
DA 2024-07-18
ER

PT J
AU Kayikçi, S
AF Kayikci, Safak
TI SenDemonNet: sentiment analysis for demonetization tweets using
   heuristic deep neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; SenDemonNet; Demonetization policy; Twitter data;
   Forest-whale optimization algorithm; Weighted feature selection;
   Heuristic deep neural network
ID MODEL; CLASSIFICATION; CNN
AB Sentiment analysis is one of the efficient models for extracting opinion mining with identification and classification from unstructured text data such as product reviews or microblogs. It is used to gain feedback from political campaigns, brand reviews, marketing analysis, and customers. The sentiment analysis on Twitter data is a recent research field in the natural processing. The dataset is gathered from the "Twitter" package in R along with Twitter API. The main intent of this paper is to understand the public opinion on the recently implemented demonetization policy using the proposed SenDemonNet. Initially, the tweet preprocessing was done, which is intended for cleaning the text data. Then, the feature extraction is performed by Bag of n-grams, TF-IDF, and the word2vec algorithm. The main objective of this work is a weighted feature selection that is developed by the hybrid Forest-Whale Optimization Algorithm (F-WOA) to get the best classification outcome. With these features, the Heuristic Deep Neural Network (HDNN) is adopted for classification, where the proposed FOA and WOA tune the parameter of DNN for reaching the maximum accuracy rate. From the statistical analysis, the performance of the designed F-WOA-DNN is 1.8%, 1.9%, 1.86%, and 2% enhanced than PSO-DNN, GWO-DNN, WOA-DNN, FOA-DNN, SVM, CNN, LSTM, and DNN respectively. Extensive experimental results show that SenDemonNet outperforms its competitors, producing an impressive increase in the classification accuracy on the benchmark dataset.
C1 [Kayikci, Safak] Abant Izzet Baysal Univ, Dept Comp Engn, BAIBU Golkoy Yerleskesi, TR-14030 Merkez Bolu, Turkey.
C3 Abant Izzet Baysal University
RP Kayikçi, S (corresponding author), Abant Izzet Baysal Univ, Dept Comp Engn, BAIBU Golkoy Yerleskesi, TR-14030 Merkez Bolu, Turkey.
EM safak.kayikci@ibu.edu.tr
RI Kayikci, Safak/H-1359-2018
OI Kayikci, Safak/0000-0002-3325-4731
CR [Anonymous], 2016, International Journal of Computer Applications, DOI [DOI 10.5120/IJCA2016908625, 10.5120/ijca2016908625]
   [Anonymous], 2018, Int. J. Synth. Emot. (IJSE), DOI DOI 10.4018/IJSE.2018010103
   [Anonymous], 2013, INT J ADV RES COMPUT
   ARUN K, 2017, INT J COMPUTER ENG R, V4, P252
   Avinash M, 2018, ADV INTELLIGENT SYST, P475
   Aziz AA, 2020, IEEE ACCESS, V8, P17722, DOI 10.1109/ACCESS.2019.2958702
   Das S, 2020, SADHANA-ACAD P ENG S, V45, DOI 10.1007/s12046-020-01372-8
   Datta S, 2021, SADHANA-ACAD P ENG S, V46, DOI 10.1007/s12046-021-01608-1
   Dhanya NM, 2018, L N COMPUT VIS BIOME, V28, P227, DOI 10.1007/978-3-319-71767-8_19
   Dubey AD, 2020, JMIR PUBLIC HLTH SUR, V6, P189, DOI 10.2196/19833
   El-Affendi MA, 2021, IEEE ACCESS, V9, P7508, DOI 10.1109/ACCESS.2021.3049626
   Fauzi M. A., 2019, Int. J. Electr. Comput. Eng., V9, P525, DOI DOI 10.11591/IJECE.V9I1.PP525-530
   Feng Y, 2021, IEEE ACCESS, V9, P19854, DOI 10.1109/ACCESS.2021.3054521
   Ghaemi M, 2014, EXPERT SYST APPL, V41, P6676, DOI 10.1016/j.eswa.2014.05.009
   Gupta D, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165491
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Phan HT, 2020, IEEE ACCESS, V8, P14630, DOI 10.1109/ACCESS.2019.2963702
   Kanimozhi P, 2018, 2 INT C EL COMM AER
   Kim H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112347
   Lee H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030785
   Li Z, 2020, IEEE ACCESS, V8, P75073, DOI 10.1109/ACCESS.2020.2986582
   Liu HY, 2020, IEEE T COMPUT SOC SY, V7, P1358, DOI 10.1109/TCSS.2020.3033302
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Nafis NSM, 2021, IEEE ACCESS, V9, P52177, DOI 10.1109/ACCESS.2021.3069001
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9060690
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9070751
   Park SW, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040688
   Rani S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196474
   Roccetti, 2017, JMIR PUBLIC HLTH SUR, V3
   Sadr H, 2020, IEEE ACCESS, V8, P86984, DOI 10.1109/ACCESS.2020.2992063
   Salam, 2020, INT J COMPUT APPL, V176, P22
   Salur MU, 2020, IEEE ACCESS, V8, P58080, DOI 10.1109/ACCESS.2020.2982538
   Schouten K, 2016, IEEE T KNOWL DATA EN, V28, P813, DOI 10.1109/TKDE.2015.2485209
   Singh, 2017, P INT C INV COMP INF
   Singh P, 2018, ICT EXPRESS, V4, P124, DOI 10.1016/j.icte.2017.03.001
   Sousa T, 2004, PARALLEL COMPUT, V30, P767, DOI 10.1016/j.parco.2003.12.015
   Tang TC, 2020, IEEE ACCESS, V8, P193248, DOI 10.1109/ACCESS.2020.3030468
   Tripathy A, 2016, EXPERT SYST APPL, V57, P117, DOI 10.1016/j.eswa.2016.03.028
   Wang CB, 2013, IEEE T HUM-MACH SYST, V43, P620, DOI 10.1109/THMS.2013.2285047
   Wang YB, 2021, IEEE ACCESS, V9, P37075, DOI 10.1109/ACCESS.2021.3062654
   Wu JS, 2019, IEEE ACCESS, V7, P183924, DOI 10.1109/ACCESS.2019.2960655
   Xu GX, 2019, IEEE ACCESS, V7, P43749, DOI 10.1109/ACCESS.2019.2907772
   Yang L, 2020, IEEE ACCESS, V8, P23522, DOI 10.1109/ACCESS.2020.2969854
   Zhai GL, 2020, BIG DATA MIN ANAL, V3, P311, DOI 10.26599/BDMA.2020.9020024
   Zhang KJ, 2019, IEEE ACCESS, V7, P171801, DOI 10.1109/ACCESS.2019.2953502
   Zhou J, 2020, IEEE ACCESS, V8, P132970, DOI 10.1109/ACCESS.2020.3010802
   Zhou J, 2019, IEEE ACCESS, V7, P78454, DOI 10.1109/ACCESS.2019.2920075
NR 47
TC 6
Z9 6
U1 4
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11341
EP 11378
DI 10.1007/s11042-022-11929-w
EA FEB 2022
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757200200001
PM 35194380
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Sun, ZL
   Zhang, RG
   Hu, J
   Liu, XJ
AF Sun, Zhiliang
   Zhang, Rongguo
   Hu, Jing
   Liu, Xiaojun
TI Probability re-weighted 3D point cloud registration for missing
   correspondences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Point cloud registration; Gaussian mixture model; Partial overlap;
   Missing correspondence; Potential outlier
AB Rigid 3D point cloud registration is a challenging problem due to noise, outliers, variations in initial positions, and limited amounts of overlap. Existing methods lack a simple mechanism to deal with missing correspondence and usually fail to align point clouds in the presence of massive outliers and missing correspondences. Aiming at the problem of outliers and missing correspondences in the partially overlapping point cloud, a probability re-weighted 3D point cloud registration algorithm based on the Gaussian mixture model (GMM) is proposed in this paper. Firstly, the correspondences between the 3D target and source point clouds are established by the GMM and uniform distribution. We show that the missing correspondences in the target point cloud can be handled by re-weighting the mixing proportion of GMM through a prior probability re-weighting strategy. Secondly, we propose a posteriori probability inference strategy to infer the outliers and their proportion in the source point cloud, where the potential outliers are removed when solving the GMM parameters. Thirdly, the objective function in the form of point-to-plane distance is introduced by calculating the normal direction in the vicinity of the weight-averaged target point, and then the point clouds with large plane structures are registered finely. Finally, the experiments are conducted on Stanford 3D Scanning data and real 3D scene data. The overall RMSE on the former is 0.40 mm with fitness of 0.775, and it is 5.32 mm with fitness of 0.608 on the latter. The evaluation results show that the proposed algorithm can enhance the fitness and reduce the RMSE of the rigid 3D point cloud registration and improve the accuracy of registration.
C1 [Sun, Zhiliang; Zhang, Rongguo; Hu, Jing] Taiyuan Univ Sci & Technol, Sch Comp Sci & Technol, Taiyuan 030024, Peoples R China.
   [Liu, Xiaojun] Hefei Univ Technol, Sch Mech Engn, Hefei 230009, Peoples R China.
C3 Taiyuan University of Science & Technology; Hefei University of
   Technology
RP Zhang, RG (corresponding author), Taiyuan Univ Sci & Technol, Sch Comp Sci & Technol, Taiyuan 030024, Peoples R China.
EM sun_6s@qq.com; rg_zh@163.com
RI wang, qi/ITT-9652-2023
OI Zhang, Rongguo/0000-0001-9021-881X
FU National Natural Science Foundation of China [51875152]; Graduate
   Students Education Innovation Foundation of Shanxi Province [2021Y698];
   Natural Science Foundation of Shanxi Province [201801D121134]
FX This work was supported partially by the National Natural Science
   Foundation of China (No.51875152), the Graduate Students Education
   Innovation Foundation of Shanxi Province (No.2021Y698) and the Natural
   Science Foundation of Shanxi Province (No.201801D121134).
CR Adams A, 2010, COMPUT GRAPH FORUM, V29, P753, DOI 10.1111/j.1467-8659.2009.01645.x
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Campbell D, 2015, IEEE I CONF COMP VIS, P4292, DOI 10.1109/ICCV.2015.488
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Choi S, 2015, PROC CVPR IEEE, P5556, DOI 10.1109/CVPR.2015.7299195
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Eckart B, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P241, DOI 10.1109/3DV.2015.34
   Eckart B, 2018, LECT NOTES COMPUT SC, V11219, P730, DOI 10.1007/978-3-030-01267-0_43
   Evangelidis GD, 2014, LECT NOTES COMPUT SC, V8695, P109, DOI 10.1007/978-3-319-10584-0_8
   Gao W, 2019, PROC CVPR IEEE, P11087, DOI 10.1109/CVPR.2019.01135
   Granger S, 2002, LECT NOTES COMPUT SC, V2353, P418
   Handa A, 2014, IEEE INT CONF ROBOT, P1524, DOI 10.1109/ICRA.2014.6907054
   Hartley R, 2013, INT J COMPUT VISION, V103, P267, DOI 10.1007/s11263-012-0601-0
   Hertz Amir, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12051, DOI 10.1109/CVPR42600.2020.01207
   Hirose O, 2021, IEEE T PATTERN ANAL, V43, P2269, DOI 10.1109/TPAMI.2020.2971687
   Hua BS, 2016, INT CONF 3D VISION, P92, DOI 10.1109/3DV.2016.18
   Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223
   Li YC, 2020, MULTIMED TOOLS APPL, V79, P14793, DOI 10.1007/s11042-019-7524-5
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631
   Pomerleau F, 2012, INT J ROBOT RES, V31, P1705, DOI 10.1177/0278364912458814
   Pomerleau Francois, 2015, Found. Trends Robot., V4, P1
   Pujol-Miró A, 2019, IMAGE VISION COMPUT, V83-84, P51, DOI 10.1016/j.imavis.2019.02.013
   Segal A., 2009, ROBOT SCI SYST, V2
   Stoyanov T, 2012, IEEE INT CONF ROBOT, P5196, DOI 10.1109/ICRA.2012.6224717
   Tsin Y, 2004, LECT NOTES COMPUT SC, V3023, P558
   Wentao Yuan, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P733, DOI 10.1007/978-3-030-58558-7_43
   Whelan T, 2016, INT J ROBOT RES, V35, P1697, DOI 10.1177/0278364916669237
   Zhou J, 2019, IEEE I CONF COMP VIS, P9904, DOI 10.1109/ICCV.2019.01000
   Zhou Q-Y, 2018, ARXIV
   Zhou ZY, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-26288-6
NR 32
TC 3
Z9 4
U1 4
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11107
EP 11126
DI 10.1007/s11042-022-12134-5
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757200200004
DA 2024-07-18
ER

PT J
AU Chen, Q
   Chen, YN
AF Chen, Qiang
   Chen, Yinong
TI Multi-view 3D model retrieval based on enhanced detail features with
   contrastive center loss
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model retrieval; Multi-view deep features; Contrastive center loss;
   Enhanced detail features; Deep cross-modal
ID CONVOLUTIONAL NEURAL-NETWORKS; CLASSIFICATION
AB In recent years, 3D model retrieval has become a hot topic. With the development of deep learning technology, many state-of-the-art deep learning based multi-view 3D model retrieval algorithms have emerged. One of the major challenges in view-based 3D model retrieval is how to achieve rotation invariant. MVCNN (Multi-View Convolutional Neural Networks) achieving higher performance while maintaining rotation invariant. However, the element-wise maximum operation across the views leads to the loss of detailed information. To address this problem, in this paper, we use a deep cross-modal learning method to treat the features of different views as different modal features. First, we select two of the views as the input of the deep multimodal learning method. Then we combine the proposed method with an improved contrastive center loss, so that we can align the features in the same subspace and obtain a higher discriminative fused feature. Experimental results show that the training of the proposed CNN (Convolutional Neural Networks) model is based on the existing MVCNN pre-trained model, which takes only 18 epochs to converge, and it obtains 90.07% in terms of mAP (mean average precision) using only the MVCNN as the backbone, which is comparable to the feature fusion algorithm PVRNet (Point-View Relation Neural Network) and much higher than the mAP of MVCNN (80.2%). The experimental results demonstrated that the proposed method avoids explicitly learning the weights for fusion of different view features, while incorporating more details into the 3D model's final descriptor can improve the retrieval results.
C1 [Chen, Qiang] Southwest Univ, Coll Comp & Informat Sci, Chongqing 400715, Peoples R China.
   [Chen, Yinong] Arizona State Univ, Sch Comp & Augmented Intelligence, Tempe, AZ 85281 USA.
C3 Southwest University - China; Arizona State University; Arizona State
   University-Tempe
RP Chen, YN (corresponding author), Arizona State Univ, Sch Comp & Augmented Intelligence, Tempe, AZ 85281 USA.
EM yinong@asu.edu
OI Chen, Yinong/0000-0002-8780-3994; Chen, Qiang/0000-0002-5285-3190
FU fundamental research funds for the Central Universities [XDJK2019C097];
   Education Reform Project in Southwest University [2019JY046]; National
   Key Research and Development Program of China [2018YFB1004201]
FX This work was partly sponsored by the fundamental research funds for the
   Central Universities (XDJK2019C097), the Education Reform Project in
   Southwest University (2019JY046), and the National Key Research and
   Development Program of China (2018YFB1004201).
CR [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   Bai S, 2017, IEEE T MULTIMEDIA, V19, P1257, DOI 10.1109/TMM.2017.2652071
   Bai S, 2015, PATTERN RECOGN LETT, V65, P15, DOI 10.1016/j.patrec.2015.06.022
   Bai X, 2015, IEEE T PATTERN ANAL, V37, P2361, DOI 10.1109/TPAMI.2015.2424863
   Chang A, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P53
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Chen Q, 2015, MULTIMED TOOLS APPL, V74, P4907, DOI 10.1007/s11042-013-1850-9
   Chen Y., 2021, Journal of Artificial Intelligence and Technology, V1, P1, DOI DOI 10.37965/JAIT.2020.0065
   Chen YN, 2020, SIMUL MODEL PRACT TH, V102, DOI 10.1016/j.simpat.2020.102070
   Feng YF, 2018, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2018.00035
   Fernandes D, 2021, INFORM FUSION, V68, P161, DOI 10.1016/j.inffus.2020.11.002
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   Han ZZ, 2019, IEEE T IMAGE PROCESS, V28, P658, DOI 10.1109/TIP.2018.2868426
   He XW, 2018, PROC CVPR IEEE, P1945, DOI 10.1109/CVPR.2018.00208
   Jiang JW, 2019, AAAI CONF ARTIF INTE, P8513
   Kanezaki A, 2018, PROC CVPR IEEE, P5010, DOI 10.1109/CVPR.2018.00526
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lengauer S, 2020, COMPUT GRAPH-UK, V87, P111, DOI 10.1016/j.cag.2020.02.001
   Li B, 2014, 35 ANN C EUR ASS COM
   Li B, 2015, COMPUT VIS IMAGE UND, V131, P1, DOI 10.1016/j.cviu.2014.10.006
   Li B, 2013, MULTIMED TOOLS APPL, V62, P821, DOI 10.1007/s11042-011-0873-3
   Li ZQ, 2019, AAAI CONF ARTIF INTE, P8682
   Lian ZH, 2013, MACH VISION APPL, V24, P1685, DOI 10.1007/s00138-013-0501-5
   Mademlis A, 2009, PATTERN RECOGN, V42, P2447, DOI 10.1016/j.patcog.2009.04.024
   Makantasis K, 2016, MULTIMED TOOLS APPL, V75, P3593, DOI 10.1007/s11042-014-2191-z
   Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6
   Qi C, 2017, IEEE IMAGE PROC, P2851, DOI 10.1109/ICIP.2017.8296803
   Qi SH, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102053
   Savva M., 2017, P WORKSH 3D OBJ RETR, P39, DOI DOI 10.2312/3DOR.20171050
   Savva M., 2016, Proceedings of the eurographics workshop on 3D object retrieval, P89
   Sfikas K, 2018, COMPUT GRAPH-UK, V71, P208, DOI 10.1016/j.cag.2017.12.001
   Shi BG, 2015, IEEE SIGNAL PROC LET, V22, P2339, DOI 10.1109/LSP.2015.2480802
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Vranic DV, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P963
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   You HX, 2019, AAAI CONF ARTIF INTE, P9119
   Zarpalas D, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/23912
   Zhen LL, 2019, PROC CVPR IEEE, P10386, DOI 10.1109/CVPR.2019.01064
   Zhu ZT, 2016, NEUROCOMPUTING, V204, P41, DOI 10.1016/j.neucom.2015.08.127
NR 43
TC 4
Z9 5
U1 4
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10407
EP 10426
DI 10.1007/s11042-022-12281-9
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000755422300004
DA 2024-07-18
ER

PT J
AU Cao, YC
   Tang, QF
   Lu, XB
AF Cao, Yichao
   Tang, Qingfei
   Lu, Xiaobo
TI STCNet: spatiotemporal cross network for industrial smoke detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smoke detection; Video understanding; Deep learning
ID VIDEO; SEPARATION
AB Industrial smoke emissions present a serious threat to natural ecosystems and human health. Prior works have shown that using computer vision techniques to identify smoke is a low-cost and convenient method. However, translucent smoke detection is a challenging task because of the irregular contours and complex motion state. To overcome these problems, we propose a novel spatiotemporal cross network (STCNet) to recognize industrial smoke emissions. The proposed STCNet involves a spatial pathway to extract appearance features and a temporal pathway to capture smoke motion information. Our STCNet is more targeted and goal oriented for dealing with translucent, nonrigid smoke objects. The spatial path can easily recognize obvious nonsmoking objects such as trees and buildings, and the temporal path can highlight the obscure traces of motion smoke. Our STC-Net achieves the mutual guidance of multilevel spatiotemporal information by bidirectional feature fusion on multilevel feature maps. Extensive experiments on public datasets show that our STCNet achieves clear improvements against the best competitors by 6.2%. We also perform in-depth ablation studies on STCNet to explore the impacts of different feature fusion methods for the entire model. The code will be available at https://github.com/Caoyichao/STCNet.
C1 [Cao, Yichao; Lu, Xiaobo] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
   [Cao, Yichao; Lu, Xiaobo] Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Peoples R China.
   [Tang, Qingfei] Nanjing Enbo Technol Co Ltd, Nanjing, Peoples R China.
C3 Southeast University - China
RP Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.; Lu, XB (corresponding author), Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Peoples R China.
EM caoyichao@seu.edu.cn; xblu@seu.edu.cn
RI 曹, 毅超/HHS-1274-2022
OI Cao, Yichao/0000-0003-2997-4012
FU National Natural Science Foundation of China [61871123]; Key Research
   and Development Program in Jiangsu Province - Priority Academic Program
   Development of Jiangsu Higher Education Institutions
FX This work was supported by the National Natural Science Foundation of
   China (No.61871123), Key Research and Development Program in Jiangsu
   Province (No.BE2016739) and is a project funded by the Priority Academic
   Program Development of Jiangsu Higher Education Institutions. We thank
   the Big Data Center of Southeast University for providing facility
   support for the numerical calculations in this paper.
CR Cao YC, 2022, IEEE T CIRC SYST VID, V32, P1820, DOI 10.1109/TCSVT.2021.3083112
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chorowski J, 2015, ADV NEUR IN, V28
   Dimitropoulos K, 2017, IEEE T CIRC SYST VID, V27, P1143, DOI 10.1109/TCSVT.2016.2527340
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Goldberg Y., 2017, SYNTH LECT HUM LANG, DOI DOI 10.2200/S00762ED1V01Y201703HLT037
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsu Y.-C., 2020, ARXIV200506111
   Hussein N, 2019, PROC CVPR IEEE, P254, DOI 10.1109/CVPR.2019.00034
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lin GH, 2019, FIRE TECHNOL, V55, P1827, DOI 10.1007/s10694-019-00832-w
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Liu YB, 2019, IEEE ACCESS, V7, P60697, DOI 10.1109/ACCESS.2019.2915599
   Long CJ, 2010, LECT NOTES ARTIF INT, V6319, P389, DOI 10.1007/978-3-642-16530-6_46
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Simonyan K, 2014, ADV NEUR IN, V27
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Tian HD, 2018, IEEE T IMAGE PROCESS, V27, P1164, DOI 10.1109/TIP.2017.2771499
   Tian HD, 2015, LECT NOTES COMPUT SC, V9004, P87, DOI 10.1007/978-3-319-16808-1_7
   Tian HD, 2014, INT J COMPUT VISION, V106, P192, DOI 10.1007/s11263-013-0656-6
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu G, 2019, IEEE ACCESS, V7, P29471, DOI 10.1109/ACCESS.2019.2902606
   Yin ZJ, 2017, IEEE ACCESS, V5, P18429, DOI 10.1109/ACCESS.2017.2747399
   Yuan FN, 2020, IEEE T IMAGE PROCESS, V29, P2301, DOI 10.1109/TIP.2019.2946126
   Yuan FN, 2017, IEEE ACCESS, V5, P6833, DOI 10.1109/ACCESS.2017.2697408
   Yuan FN, 2012, PATTERN RECOGN, V45, P4326, DOI 10.1016/j.patcog.2012.06.008
   Zhao YM, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061799
   Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49
   Zolfaghari M, 2018, LECT NOTES COMPUT SC, V11206, P713, DOI 10.1007/978-3-030-01216-8_43
NR 35
TC 10
Z9 10
U1 4
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 10261
EP 10277
DI 10.1007/s11042-021-11766-3
EA FEB 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800014
DA 2024-07-18
ER

PT J
AU Sethy, PK
AF Sethy, Prabira Kumar
TI Identification of wheat tiller based on AlexNet-feature fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wheat tiller identification; Feature fusion; AlexNet; Wheat head
AB Wheat genotype identification is possible with proper recognition of its tiller. It is again challenging to recognize the wheat tiller in complex imaging conditions such as blurred image due to motion and dense appearance due to overlap of heads. The identification of wheat tiller helps to recognize the wheat genotypic and provides knowledge about the variability of growth stages, the orientation of the head, and the presence of awn. This research considered the Global Wheat Head Detection (GWHD) dataset with seven traits of wheat. The multi-feature fusion technique is adapted in AlexNet to enhance the performance of the classifier. The fc6 feature and fc7 feature of AlexNet are concatenated and fed to Linear-SVM to classify the seven traits of wheat and achieved 94.14% of accuracy.
C1 [Sethy, Prabira Kumar] Sambalpur Univ, Dept Elect, Sambalpur 768019, Odisha, India.
C3 Sambalpur University
RP Sethy, PK (corresponding author), Sambalpur Univ, Dept Elect, Sambalpur 768019, Odisha, India.
EM prabirsethy.05@gmail.com
RI Sethy, Prabira kumar/W-5929-2019
OI Sethy, Prabira kumar/0000-0003-3477-6715
CR Behera S.K., 2020, Karbala International Journal of Modern Science, V6, P16, DOI [10.33640/2405- 609X.1675, DOI 10.33640/2405-609X.1675]
   Behera SK, 2021, INFORM PROCESS AGR, V8, P244, DOI 10.1016/j.inpa.2020.05.003
   Bhagat S, 2021, IEEE INT CONF COMP V, P1332, DOI 10.1109/ICCVW54120.2021.00154
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P6712, DOI 10.1109/TGRS.2018.2841823
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   David E, 2020, PLANT PHENOMICS, V2020, DOI 10.34133/2020/3521852
   Du ShiwEi Du ShiwEi, 2018, Journal of Nanjing Agricultural University, V41, P742
   Fourati F, 2020, ARXIV PREPRINT ARXIV
   Gong B, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010191
   Han C., 2013, J AGR MECH RES, V3, P3
   Hasan MM, 2018, PLANT METHODS, V14, DOI 10.1186/s13007-018-0366-8
   Khaki S, 2021, ARXIV PREPRINT ARXIV
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Sethy PK, 2022, MULTIMED TOOLS APPL, V81, P3005, DOI 10.1007/s11042-021-11729-8
   Sethy PK, 2021, ARCH PHYTOPATH PLANT, V54, P1001, DOI 10.1080/03235408.2020.1869386
   Sethy PK, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105527
   Sethy PK, 2020, J AMB INTEL HUM COMP, V11, P5703, DOI 10.1007/s12652-020-01938-8
   Tao L., 2013, J AGR MECH RES, V21, P90
   Zhao F., 2014, Crops, V1, P1, DOI [10.3969/j.issn.1001-7283.2014.01.033, DOI 10.3969/J.ISSN.1001-7283.2014.01.033]
   Zhou PC, 2019, IEEE T GEOSCI REMOTE, V57, P4823, DOI 10.1109/TGRS.2019.2893180
NR 21
TC 4
Z9 4
U1 12
U2 72
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8309
EP 8316
DI 10.1007/s11042-022-12286-4
EA FEB 2022
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749966800007
DA 2024-07-18
ER

PT J
AU Zerdoumi, S
   Hashem, IAT
   Jhanjhi, NZ
AF Zerdoumi, Saber
   Hashem, Ibrahim Abaker Targio
   Jhanjhi, Noor Zaman
TI A new spatial spherical pattern model into interactive cartography
   pattern: multi-dimensional data via geostrategic cluster
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clustered; Geo-visualization; Web mapping applications; Electoral
   constituencies; Pattern
ID SOCIAL NETWORKS; RECOGNITION; LOCATION
AB A growing amount of research conducted in digital, cooperative with advances in Artificial Intelligence, Computer Vision including Machine learning, has managed to the advance of progressive techniques that aim to detect and process affective information contained in multi-modal evidences. This research intends to bring together for theoreticians and practitioners from academic fields, professionals and industries and extends to be visualizing cries such epidemic, votes, social Phenomena in spherical representation interactive model working in the broad range of topics relevant to multi - modal data processing and forensics tools developing. Furthermore, progress has been made in this research besides that in this research conducted progression of mapping claims in present epoch necessitate the capacities of virtual guide of any understandable Geo-Visualization of spatial features that talented to convert the quantities of spatial pattern into cartography. The enlargement of a novel approaches fit for visualization of spatial pattern constituencies Starting exclusive Input Set of object O, set associated with feature F for regenerating Output the set C , interested region I special target C Even so, as indicated by the construction of the prototype as listed earlier in this thread, does it have the incentive for improvements: Representation could be used by Google Earth can Using Project enhancement representation whereby provides a 3D or 4D interaction with life measures with a view to cartography. In addition, the initiative suggests that a tool not accessible for disseminating information to the public can be addressed by the use of online mapping, which fuses with trends visualization for political circles and electors. But as mentioned above the framework is developed and it's also possible in the current example, for improvements: The project's representation 3D or 4D interacting Earth can use measures of life Earth From the map viewpoint. That's what that says. That means that. Which just means. Developers have concerns that. So it. Designers concern about that. This study supports the new, multi - demission and deployed countries in conjunction with another data is processed. Comprehensive, well-interpreted source data for the Data like Malaysia Jabatan Pendaftaran (JPN).
C1 [Zerdoumi, Saber; Jhanjhi, Noor Zaman] Taylors Univ, Sch Comp Sci & Engn, Subang Jaya 47500, Malaysia.
   [Hashem, Ibrahim Abaker Targio] Univ Sharijah, Coll Comp & Informat, Dept Comp Sci, Sharjah 27272, U Arab Emirates.
C3 Taylor's University
RP Zerdoumi, S (corresponding author), Taylors Univ, Sch Comp Sci & Engn, Subang Jaya 47500, Malaysia.
EM Ihashem@sharjah.ac.ae
RI Jhanjhi, Prof Dr Noor Zaman/F-3051-2011
OI Jhanjhi, Prof Dr Noor Zaman/0000-0001-8116-4733; Hashem, Ibrahim Abaker
   Targio/0000-0001-7611-9540
CR Abd Manap M, 2013, ARAB J GEOSCI, V6, P1621, DOI 10.1007/s12517-011-0469-2
   Ahlquist JS, 2018, J COMP ECON, V46, P906, DOI 10.1016/j.jce.2018.01.001
   Aras G, 2008, MANAGE DECIS, V46, P433, DOI 10.1108/00251740810863870
   Atallah RR, 2018, IEEE ACCESS, V6, P28290, DOI 10.1109/ACCESS.2018.2836924
   Baldera MA, 2017, GOOGLE PATENTS
   Ballatore A, 2010, P 2010 ACM S APPL CO
   Bao J, 2015, GEOINFORMATICA, V19, P525, DOI 10.1007/s10707-014-0220-8
   Blower J.D., 2010, P 1 INT C EXHIBITION, DOI DOI 10.1145/1823854.1823893
   Brovelli MA, 2017, INT ARCH PHOTOGRAMM, V42-4, P51, DOI 10.5194/isprs-archives-XLII-4-W2-51-2017
   Calloway T, 2020, IEEE INT CONF COMP, DOI 10.1109/civemsa48639.2020.9132969
   Caramani D, 2018, VOTING RIGHTS ERA GL
   Chen PH, 2017, AUTOMAT CONSTR, V77, P52, DOI 10.1016/j.autcon.2017.01.014
   Clarke TB, 2010, NAT MED, V16, P228, DOI 10.1038/nm.2087
   Dauda AB, 2017, PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON COMPUTING NETWORKING AND INFORMATICS (ICCNI 2017)
   De Santis D, 2018, INVEST RADIOL, V53, P103, DOI 10.1097/RLI.0000000000000416
   Dooley KA, 2017, ANAL METHODS-UK, V9, P28, DOI 10.1039/c6ay01795a
   Ghani MHA, 2017, GEOGRAFIA MALAYS J S, V12
   Goossens J, 2017, ELECT LAW J, V16, P316, DOI 10.1089/elj.2016.0420
   Greene CA, 2017, COMPUT GEOSCI-UK, V104, P151, DOI 10.1016/j.cageo.2016.08.003
   Haruna K, 2019, IEEE ACCESS, V7, P116179, DOI 10.1109/ACCESS.2019.2892778
   Hernandez PA, 2006, ECOGRAPHY, V29, P773, DOI 10.1111/j.0906-7590.2006.04700.x
   Holdener A.T., 2011, HTML5 Geolocation
   Hudson-Smith A, 2009, SOC SCI COMPUT REV, V27, P524, DOI 10.1177/0894439309332299
   Ibrahim Omar A, 2014, International Journal of Computer Networks and Communications Security (CNCS), V2, P113
   Kim JY, 2018, MOB INF SYST, V2018, DOI 10.1155/2018/8436210
   Kim K, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7060216
   Kotsev A, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9030176
   Li WW, 2017, INT J GEOGR INF SCI, V31, P1562, DOI 10.1080/13658816.2017.1306863
   Longley P. A., 2005, Geographic Information Systems and Science
   MacEachren AM, 2004, IEEE COMPUT GRAPH, V24, P13, DOI 10.1109/MCG.2004.1255801
   Matthews MJ, 2017, STAT PROBABIL LETT, V122, P173, DOI 10.1016/j.spl.2016.11.015
   McCarthy J, 2019, GEOFORUM, V102, P242, DOI 10.1016/j.geoforum.2017.03.025
   McMahon G, 2016, 37 HYDR WAT RES S 20
   Milutinovic G, 2018, VISIGRAPP 2018: PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS / INTERNATIONAL CONFERENCE ON INFORMATION VISUALIZATION THEORY AND APPLICATIONS (IVAPP), VOL 3, P233, DOI 10.5220/0006610202360243
   Miralles A, 2017, INFORSID 2017
   Paju M, 2010, WINT SIMUL C PROC, P3411, DOI 10.1109/WSC.2010.5679031
   Palka Gaetan, 2018, International Journal of Cartography, V4, P25, DOI 10.1080/23729333.2018.1434603
   Read JI, 2017, MON NOT R ASTRON SOC, V467, P2019, DOI 10.1093/mnras/stx147
   Rouse L. J., 2009, THE GEOSPATIAL WEB, P153, DOI [10.1007/978-1-84628-827-2_14, DOI 10.1007/978-1-84628-827-2_14]
   Scharl, 2017, D5 2 2 PHEME VISUAL
   Shekhawat P, 2018, GEOGRAPHICAL INFORM
   SVENNERBERG G., 2010, Beginning Google Maps API 3: The Expert's Voice in Web Development
   Trapp M, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL 3: IVAPP, P282, DOI 10.5220/0007384302820288
   Veenendaal B., 2017, ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, VXLII-2/W7, P155, DOI DOI 10.5194/ISPRS-ARCHIVES-XLII-2-W7-155-2017
   Williams CB, 2013, NEW MEDIA SOC, V15, P52, DOI 10.1177/1461444812457332
   Yeung AK, 2017, SPATIAL DATABASE SYS, V87
   Yeung AKW, 2007, GEOJOURNAL LIB, V87, P1, DOI 10.1007/1-4020-5392-4
   Yue XF, GOOGLE PATENTS
   Zerdoumi S, 2018, MULTIMED TOOLS APPL, V77, P10091, DOI 10.1007/s11042-017-5045-7
   Zheng ZC, 2020, APPL GEOGR, V123, DOI 10.1016/j.apgeog.2020.102310
NR 50
TC 2
Z9 2
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22903
EP 22952
DI 10.1007/s11042-021-11339-4
EA JAN 2022
PG 50
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000749055500008
PM 35125925
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Goala, S
   Prakash, D
   Dutta, P
   Talukdar, P
   Verma, KD
   Palai, G
AF Goala, Soumendra
   Prakash, Deo
   Dutta, Palash
   Talukdar, Pranjal
   Verma, K. D.
   Palai, G.
TI A decision support system for surveillance of smart cities via a novel
   aggregation operator on intuitionistic fuzzy sets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intuitionistic fuzzy sets; Cyber physical systems; Crowd behavior
   analysis; Smart cyber security; Surveillance
ID CITY; NUMBERS; RISK
AB In recent times, terror attacks are becoming one of the most important issues of defense section for almost all the countries, especially for smart cities. Sometimes countries have to spend a lot of money and man power to protect and servile the cities, which is a challenging task for the smart cities to rely on technologies rather than man power for surveillance and protection. In this paper, a fuzzy multi criteria decision support system is utilized to prioritize the parts of a smart city which may lie under potential threat of terror attacks. For this purpose, a new aggregation operation on Intuitionistic fuzzy sets has been proposed. In addition, a case study on a smart city has been carried out which showcase the applicability of the proposed methodology.
C1 [Goala, Soumendra; Dutta, Palash; Talukdar, Pranjal] Dibrugarh Univ, Dept Math, Dibrugarh, Assam, India.
   [Prakash, Deo] Shri Mata Vaishno Devi Univ, Fac Engn, Sch Comp Sci & Engn, Katra 182320, J&K, India.
   [Verma, K. D.] Shri Varshney PG Coll, Dept Phys, Aligarh 202001, UP, India.
   [Palai, G.] Gandhi Inst Technol Adv, Dept Elect & Commun Engn, Bhubaneswar, India.
C3 Dibrugarh University; Shri Mata Vaishno Devi University; Gandhi
   Institute For Technological Advancement
RP Prakash, D (corresponding author), Shri Mata Vaishno Devi Univ, Fac Engn, Sch Comp Sci & Engn, Katra 182320, J&K, India.
EM deoprakash.a@gmail.com
RI Prakash, Deo/O-9722-2015; Palai, Gopinath/O-1554-2013; Verma,
   K.D./K-5758-2018; Dutta, Palash/C-3363-2019
OI Verma, K.D./0000-0002-5492-2997; Dutta, Palash/0000-0002-1565-4889
CR Abbate T, 2019, TECHNOL FORECAST SOC, V142, P183, DOI 10.1016/j.techfore.2018.07.031
   Alamaniotis M, 2017, PROC INT C TOOLS ART, P1021, DOI 10.1109/ICTAI.2017.00157
   Awasthi A, 2012, APPL MATH MODEL, V36, P573, DOI 10.1016/j.apm.2011.07.033
   Bellman R. E., 1971, Decision-making in a fuzzy environment, DOI 10.1287/mnsc.17.4.B141
   BEZDEK JC, 1992, IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, P1035, DOI 10.1109/FUZZY.1992.258797
   Bhunia SS, 2014, IEEE CONF WIREL MOB, P187, DOI 10.1109/WiMOB.2014.6962169
   Calvo T, 2002, STUD FUZZ SOFT COMP, V97, P3
   Chen J.H., 2006, P 9 JOINT C INF SCI, P1196
   CHEN SH, 1985, FUZZY SET SYST, V17, P113, DOI 10.1016/0165-0114(85)90050-8
   Costa DG, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010093
   Cui L, 2018, IEEE ACCESS, V6, P46134, DOI 10.1109/ACCESS.2018.2853985
   D'Aniello G, 2016, IEEE INT FUZZY SYST, P1554, DOI 10.1109/FUZZ-IEEE.2016.7737875
   De Maio C, 2017, J PARALLEL DISTR COM, V110, P31, DOI 10.1016/j.jpdc.2017.02.002
   Deveci M, 2020, SUSTAIN CITIES SOC, V53, DOI 10.1016/j.scs.2019.101889
   Dutta P, 2016, CYBERNET SYST, V47, P290, DOI 10.1080/01969722.2016.1182354
   Firmansyah HS, 2019, IEEE ACCESS, V7, P46136, DOI 10.1109/ACCESS.2019.2908622
   Flauzino R, 2015, 2015 IEEE PES INNOVATIVE SMART GRID TECHNOLOGIES LATIN AMERICA (ISGT LATAM), P204, DOI 10.1109/ISGT-LA.2015.7381154
   Hoang GTT, 2019, SMART CITIES-BASEL, V2, P433, DOI 10.3390/smartcities2030027
   GOALA S, 2018, J TIBAH U SCI
   Goala S., 2019, Int J Appl Comput Math, V5, P1, DOI [10.1007/s40819-019-0695-y, DOI 10.1007/S40819-019-0695-Y]
   Grubesic TH, 2006, J QUANT CRIMINOL, V22, P77, DOI 10.1007/s10940-005-9003-6
   Hwang CL, 1981, Multiple attribute decision making: Methods and applications a state-ofthe-art survey, DOI [DOI 10.1007/978-3-642-48318-93, 10.1007/978-3-642-48318-93, DOI 10.1007/978-3-642-48318-9]
   Iqbal K, 2018, INT J ADV COMPUT SC, V9, P94
   Kacprzyk J, 1997, ORDERED WEIGHTED AVE
   Kumar H, 2019, LAND USE POLICY, V82, P375, DOI 10.1016/j.landusepol.2018.12.025
   Lajmi Hela, 2017, 2017 International Conference on Advanced Systems and Electric Technologies (IC_ASET). Proceedings, P460, DOI 10.1109/ASET.2017.7983737
   Lakhno Valeriy, 2019, 2019 IEEE International Conference on Advanced Trends in Information Theory (ATIT), P249, DOI 10.1109/ATIT49449.2019.9030499
   Li ST, 2010, EXPERT SYST APPL, V37, P7108, DOI 10.1016/j.eswa.2010.03.004
   Li XT, 2018, J INTELL FUZZY SYST, V34, P2491, DOI 10.3233/JIFS-172097
   Liu PD, 2012, APPL MATH MODEL, V36, P2498, DOI 10.1016/j.apm.2011.09.006
   Liu PD, 2011, EXPERT SYST APPL, V38, P1053, DOI 10.1016/j.eswa.2010.07.144
   Melo FS, 2016, 2016 8 EUR AM C TEL, P1
   MOHANTA BK, 2019, INT CONF COMPUT, pN1716, DOI DOI 10.1109/icccnt45670.2019.8944797
   Nadeem M. W., 2019, PROC INT C INNOV COM, P1
   Olszewski R, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9102059
   Olszewski R, 2018, 2018 4TH IEEE INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC 2018), P430, DOI 10.1109/CIC.2018.00065
   Opricovic S, 2004, EUR J OPER RES, V156, P445, DOI 10.1016/s0377-2217(03)00020-1
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI [10.1109/ATNAC.2017.8215431, 10.1109/ICPHM.2017.7998297]
   Riyaz R, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON COMPUTATIONAL TECHNIQUES, ELECTRONICS AND MECHANICAL SYSTEMS (CTEMS), P172, DOI 10.1109/CTEMS.2018.8769195
   Saaty T. L., 2004, Journal of Systems Science and Systems Engineering, V13, P1, DOI 10.1007/s11518-006-0151-5
   Shamsuddin N H.M., 2012, International Journal of Innovative Computing, V01, P15
   Sharma S, 2018, RENEW SUST ENERG REV, V82, P3633, DOI 10.1016/j.rser.2017.10.099
   Shrivastav A. K., 2012, INT J COMPUT SCI ENG, V9, P415
   Sinha D., 2018, OBS RES FDN ORF, V241, P4
   Szabó AB, 2017, I S INTELL SYST INFO, P297, DOI 10.1109/SISY.2017.8080571
   Topaloglu M, 2018, SOFT COMPUT, V22, P4879, DOI 10.1007/s00500-018-3232-8
   Torra V, 2003, STUD FUZZ SOFT COMP, V123, P1
   Wang GJ, 1998, FUZZY SET SYST, V98, P331, DOI 10.1016/S0165-0114(96)00368-5
   Xia XT, 2019, PERS UBIQUIT COMPUT, V23, P453, DOI 10.1007/s00779-019-01209-0
   Xu Z.S., 2004, Uncertain Multiple Attribute Decision Making, Methods and Applications
   Xu ZS, 2007, IEEE T FUZZY SYST, V15, P1179, DOI 10.1109/TFUZZ.2006.890678
   Xu ZS, 2006, INT J GEN SYST, V35, P417, DOI 10.1080/03081070600574353
   Xu ZS, 2003, INT J INTELL SYST, V18, P953, DOI 10.1002/int.10127
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhao H, 2010, INT J INTELL SYST, V25, P1, DOI 10.1002/int.20386
   Zimmermann H.-J., 1985, FUZZY SET THEORY ITS
NR 56
TC 6
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22587
EP 22608
DI 10.1007/s11042-021-11522-7
EA JAN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000745425000005
DA 2024-07-18
ER

PT J
AU Gültekin, G
   Bayat, O
AF Gultekin, Gunay
   Bayat, Oguz
TI A Naive Bayes prediction model on location-based recommendation by
   integrating multi-dimensional contextual information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommendation algorithms; Collaborative filtering; Factorization; Big
   data analysis; Location-based social networks; Naive Bayes theorem
AB In recent years, researchers have been trying to create recommender systems. There are many different recommender systems. Point of Interest (POI) is a new type of recommender systems that focus on personalized and context-aware recommendations to improve user experience. Recommender systems use different types of recommendation methods to obtain information on POI. In this research paper, we introduced a Naive Bayes Prediction Model based on Bayesian Theory for POI recommendation. Then, we used the Brightkite dataset to make predictions on POI recommendation and compared it with the other two different recommendation methods. Experimental results confirm that our proposed method outperforms on Location-based POI recommendation.
C1 [Gultekin, Gunay; Bayat, Oguz] Altinbas Univ, Elect & Comp Engn, Istanbul, Turkey.
C3 Altinbas University
RP Gültekin, G (corresponding author), Altinbas Univ, Elect & Comp Engn, Istanbul, Turkey.
EM gunay.gultekin@ogr.altinbas.edu.tr; oguz.bayat@altinbas.edu.tr
OI Gultekin, Gunay/0000-0003-0640-9643
CR Chan KC, 2017, IEEE INT SYM MULTIM, P438, DOI 10.1109/ISM.2017.87
   Cho E., 2011, P 17 ACM SIGKDD INT, P1082, DOI DOI 10.1145/2020408.2020579
   Gao H., 2014, MOBILE SOCIAL NETWOR, P165, DOI DOI 10.1007/978-1-4614-8579-7_8
   Gultekin G., 2014, J COMPUT COMMUN, V2, P54, DOI DOI 10.4236/JCC.2014.28006
   Hu G, 2020, MULTIMED TOOLS APPL, V79, P33365, DOI 10.1007/s11042-018-6776-9
   Hu HX, 2021, IEEE T CYBERNETICS, V51, P5328, DOI 10.1109/TCYB.2020.2995154
   Huang J, 2015, DISTRIB PARALLEL DAT, V33, P253, DOI 10.1007/s10619-014-7148-8
   Li XH, 2014, FRONT ENV SCI ENG, V8, P277, DOI 10.1007/s11783-013-0562-8
   Lian DF, 2014, ACM T INTEL SYST TEC, V5, DOI 10.1145/2490890
   Lin CY, 2014, PERS UBIQUIT COMPUT, V18, P303, DOI 10.1007/s00779-013-0646-2
   Lin PJ, 2015, MULTIMED TOOLS APPL, V74, P8313, DOI 10.1007/s11042-013-1782-4
   Liu, 2013, P 7 ACM C REC SYST, P93, DOI DOI 10.1145/2507157.2507182
   Liu YD, 2017, PROC VLDB ENDOW, V10, P1010, DOI 10.14778/3115404.3115407
   Navlani A., 2018, NAIVE BAYES CLASSIFI
   Papangelis K, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3364997
   Point T., INTRO NAIVE BAYES AL
   Salkind NJ, 2010, Encyclopedia of research design, DOI DOI 10.4135/9781412961288
   Scellato Salvatore., 2011, INT AAAI C WEB SOC M, Vvol. 5, P329, DOI [10.1609/icwsm.v5i1.14094, DOI 10.1609/ICWSM.V5I1.14094]
   Schmidt MN, 2009, LECT NOTES COMPUT SC, V5441, P540, DOI 10.1007/978-3-642-00599-2_68
   Yao LN, 2018, ACM T INTERNET TECHN, V18, DOI 10.1145/3134438
   Yin HZ, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P221
   Yuan Q, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P363
   Zhang H, 2005, INT J PATTERN RECOGN, V19, P183, DOI 10.1142/S0218001405003983
   Zheng VW, 2010, P 19 INT C WORLD WID, P1029
NR 24
TC 0
Z9 1
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6957
EP 6978
DI 10.1007/s11042-021-11676-4
EA JAN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000744767900003
DA 2024-07-18
ER

PT J
AU Jain, V
   Al-Turjman, F
   Chaudhary, G
   Nayar, D
   Gupta, V
   Kumar, A
AF Jain, Vanita
   Al-Turjman, Fadi
   Chaudhary, Gopal
   Nayar, Devang
   Gupta, Varun
   Kumar, Aayush
TI Video captioning: a review of theory, techniques and practices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Video captioning; Natural language processing; CNN; RNN; Encoder-decoder
   framework
ID ATTENTION; LANGUAGE; VISION
AB In today's world, video captioning is extensively used in various applications for specially-abled and, more specifically, visually abled persons. With advancements in technology for object detection and natural processing, there has been an instant surge infusing the above mainstream tasks. One such example of this fusion resulted in the generation of Image captions when an input image is fed to the system, and it gives a short description of what is present in the image. This fusion pertained to images and was further moved to be implemented on the Videos, with some tweaking in the current methods. This paper presents the survey of the state of art techniques of various video captioning methods. There have been many inputs provided by people worldwide in this domain; thus, there was a need to compile, study and analyze all the results and present that in a comprehensive study, which we have done in this paper. The comparison of various video captioning methods on the distinct dataset was evaluated on different parameters, which were most common and mainly used for image and video analysis. This review was done for methods used from the year 2015-2019 (year by year). The most commonly used dataset and evaluation method are also pictorially represented in a bar graph and scatter plot for each year for the respective evaluation parameter. Though a lot of analysis and research has been done on video captioning, our survey shows many problems.
C1 [Jain, Vanita; Chaudhary, Gopal; Nayar, Devang; Gupta, Varun; Kumar, Aayush] Bharati Vidyapeeths Coll Engn, New Delhi, India.
   [Al-Turjman, Fadi] Near East Univ, Nicosia, Cyprus.
C3 Near East University
RP Chaudhary, G (corresponding author), Bharati Vidyapeeths Coll Engn, New Delhi, India.
EM vanita.jain@bharatividyapeeth.edu; fadi.alturjman@neu.edu.tr;
   gopal.bvcoe@bharatividyapeeth.edu; devang.nayar@bvcoend.ac.in;
   varun.gupta-coend@bvp.edu.in; aayush.kumar-coend@bvp.edu.in
RI Al-Turjman, Fadi/L-2998-2019; ., Gopal/F-8322-2017; Gupta,
   Varun/AAW-9860-2020
OI Al-Turjman, Fadi/0000-0001-5418-873X; ., Gopal/0000-0002-3991-3291;
   Gupta, Varun/0000-0002-2633-5920
CR Aafaq N, 2019, PROC CVPR IEEE, P12479, DOI 10.1109/CVPR.2019.01277
   [Anonymous], CVPR
   [Anonymous], 2016, PROC 24 ACM INT C MU, DOI [DOI 10.1145/2964284.2984065, 10.1145/2964284.2984065]
   [Anonymous], 2016, P 24 ACM INT C MULTI, DOI DOI 10.1145/2964284.2984066
   [Anonymous], 2014, ARXIV14124729
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   [Anonymous], 2004, P ANN M ASS COMP LIN
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Banerjee S., 2005, P ACL 2005 WORKSHOP, P65
   Baraldi L, 2017, PROC CVPR IEEE, P3185, DOI 10.1109/CVPR.2017.339
   Barbu A., 2012, UAI
   Brand M., 1997, P NAT C ART INT 9 C, P132
   Buch S, 2017, PROC CVPR IEEE, P6373, DOI 10.1109/CVPR.2017.675
   Chen D., 2011, P 49 ANN M ASS COMP, P190
   Chen SZ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1838, DOI 10.1145/3123266.3123420
   Chen YP, 2018, LECT NOTES COMPUT SC, V11205, P364, DOI 10.1007/978-3-030-01246-5_22
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Chuanqi Tan, 2018, Artificial Neural Networks and Machine Learning - ICANN 2018. 27th International Conference on Artificial Neural Networks. Proceedings: Lecture Notes in Computer Science (LNCS 11141), P270, DOI 10.1007/978-3-030-01424-7_27
   Dong JF, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1082, DOI 10.1145/2964284.2984064
   Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127
   Gao LL, 2020, NEUROCOMPUTING, V395, P222, DOI 10.1016/j.neucom.2018.06.096
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Guo Z, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P357, DOI 10.1145/2964284.2967242
   Hanckmann P, 2012, LECT NOTES COMPUT SC, V7583, P372, DOI 10.1007/978-3-642-33863-2_37
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hori C, 2017, IEEE I CONF COMP VIS, P4203, DOI 10.1109/ICCV.2017.450
   Jin T, 2019, NEUROCOMPUTING, V370, P118, DOI 10.1016/j.neucom.2019.08.042
   Jonghwan Mun, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P6581, DOI 10.1109/CVPR.2019.00675
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Khan M. U. G., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1480, DOI 10.1109/ICCVW.2011.6130425
   Kojima A, 2002, INT J COMPUT VISION, V50, P171, DOI 10.1023/A:1020346032608
   Koller D., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P90, DOI 10.1109/CVPR.1991.139667
   Krishna R, 2017, IEEE I CONF COMP VIS, P706, DOI 10.1109/ICCV.2017.83
   Krishnakumar Neeraja, 2013, 2013 Annual International Conference on Emerging Research Areas and 2013 International Conference on Microelectronics, Communications and Renewable Energy, DOI 10.1109/AICERA-ICMiCR.2013.6575948
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li G, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1191, DOI 10.1145/2733373.2806314
   Li LJ, 2019, IEEE WINT CONF APPL, P339, DOI 10.1109/WACV.2019.00042
   Li LH, 2018, IEEE T MULTIMEDIA, V20, P726, DOI 10.1109/TMM.2017.2751140
   Li XP, 2019, WORLD WIDE WEB, V22, P621, DOI 10.1007/s11280-018-0531-z
   Li XL, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2208
   Li Y, 2018, PROC CVPR IEEE, P7492, DOI 10.1109/CVPR.2018.00782
   Liu AA, 2017, COMPUT VIS IMAGE UND, V163, P113, DOI 10.1016/j.cviu.2017.04.013
   Liu Y, 2017, AAAI CONF ARTIF INTE, P4197
   Long Xiang, 2018, T ASSOC COMPUT LING, V6, P173, DOI DOI 10.1162/TACL_A_00013
   Luong M.-T., 2015, ARXIV PREPRINT ARXIV
   Mikolov Tomas, 2013, EFFICIENT ESTIMATION
   Pan PB, 2016, PROC CVPR IEEE, P1029, DOI 10.1109/CVPR.2016.117
   Pan YW, 2016, PROC CVPR IEEE, P4594, DOI 10.1109/CVPR.2016.497
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pei WJ, 2019, PROC CVPR IEEE, P8339, DOI 10.1109/CVPR.2019.00854
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Quadrana M, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P130, DOI 10.1145/3109859.3109896
   Rohrbach A, 2015, PROC CVPR IEEE, P3202, DOI 10.1109/CVPR.2015.7298940
   Rohrbach A, 2014, LECT NOTES COMPUT SC, V8753, P184, DOI 10.1007/978-3-319-11752-2_15
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shen ZQ, 2017, PROC CVPR IEEE, P5159, DOI 10.1109/CVPR.2017.548
   Shetty R., 2016, P 24 ACM INT C MULTI, P1073
   Sigurdsson GA, 2016, LECT NOTES COMPUT SC, V9905, P510, DOI 10.1007/978-3-319-46448-0_31
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Song JK, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2737
   Thomason J., 2014, COLING, P1218
   Torabi Atousa., 2015, ARXIV150301070
   Tu YB, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1014, DOI 10.1145/3123266.3123354
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wang BR, 2018, PROC CVPR IEEE, P7622, DOI 10.1109/CVPR.2018.00795
   Wang JW, 2018, PROC CVPR IEEE, P7190, DOI 10.1109/CVPR.2018.00751
   Wang JB, 2018, PROC CVPR IEEE, P7512, DOI 10.1109/CVPR.2018.00784
   Wang X, 2018, PROC CVPR IEEE, P4213, DOI 10.1109/CVPR.2018.00443
   Wu AM, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1029
   Wu X, 2018, PROC CVPR IEEE, P6829, DOI 10.1109/CVPR.2018.00714
   Xiong YL, 2018, LECT NOTES COMPUT SC, V11215, P489, DOI 10.1007/978-3-030-01252-6_29
   Xu CS, 2008, IEEE T MULTIMEDIA, V10, P421, DOI 10.1109/TMM.2008.917346
   Xu H., 2015, WORKSH CLOS LOOP VIS
   Xu J, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P537, DOI 10.1145/3123266.3123448
   Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571
   Xu N, 2019, IEEE T CIRC SYST VID, V29, P2482, DOI 10.1109/TCSVT.2018.2867286
   Xu R, 2015, AAAI CONF ARTIF INTE, P2346
   Xu YJ, 2018, IEEE T IMAGE PROCESS, V27, P4933, DOI 10.1109/TIP.2018.2846664
   Xu YC, 2019, NEUROCOMPUTING, V357, P24, DOI 10.1016/j.neucom.2019.05.027
   Yang Y, 2018, IEEE T IMAGE PROCESS, V27, P5600, DOI 10.1109/TIP.2018.2855422
   Yang ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P146, DOI 10.1145/3123266.3123327
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu HN, 2016, PROC CVPR IEEE, P4584, DOI 10.1109/CVPR.2016.496
   Zhang JC, 2019, PROC CVPR IEEE, P8319, DOI 10.1109/CVPR.2019.00852
   Zhang XS, 2017, PROC CVPR IEEE, P6250, DOI 10.1109/CVPR.2017.662
   Zhou LW, 2018, PROC CVPR IEEE, P8739, DOI 10.1109/CVPR.2018.00911
   Zhu LC, 2017, PROC CVPR IEEE, P1339, DOI 10.1109/CVPR.2017.147
NR 93
TC 7
Z9 8
U1 5
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35619
EP 35653
DI 10.1007/s11042-021-11878-w
EA JAN 2022
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000743891900002
DA 2024-07-18
ER

PT J
AU Chang, CW
   Chang, CY
   Lin, YY
AF Chang, Chuan-Wang
   Chang, Chuan-Yu
   Lin, You-Ying
TI A hybrid CNN and LSTM-based deep learning model for abnormal behavior
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep SORT; YOLOv3; Object detection; Object tracking; Abnormal behavior
   detection
ID FALL DETECTION SYSTEM; ANOMALY DETECTION; SURVEILLANCE; RECOGNITION;
   NETWORK
AB Traditional cameras can only record videos passively. If the camera can further automatically recognize human behavior and activity, it can immediately issue an alarm to notify the monitor or guards when abnormal behavior is detected. Hence, the monitor or guard can quickly take relevant actions based on the detected behavior. In this paper, we propose a deep learning model for abnormal behavior detection, which use object detection technology YOLOv3 to detect pedestrians, and then use hybrid Deep-SORT algorithm to track pedestrians to obtain tracking trajectories from the sequence frames. Then, the convolutional neural network (CNN) is used to extract the action characteristics of each tracked trajectory, and the long short-term memory network (LSTM) is used to build anomalous behavior identification model to predict abnormal behavior, such as falling, kicking, punching, etc. The experimental results show that the proposed method has a good recognition rate in different behavior data sets, and it can also meet the needs of real-time monitoring.
C1 [Chang, Chuan-Wang] Natl Chin Yi Univ Technol, Dept Comp Sci & Informat Engn, 57,Sec 2,Zhongshan Rd, Taichung 41170, Taiwan.
   [Chang, Chuan-Yu; Lin, You-Ying] Natl Yunlin Univ Sci & Technol, Dept Comp Sci & Informat Engn, 123 Univ Rd,Sec 3, Touliu 64002, Yunlin, Taiwan.
C3 National Chin-Yi University of Technology; National Yunlin University
   Science & Technology
RP Chang, CY (corresponding author), Natl Yunlin Univ Sci & Technol, Dept Comp Sci & Informat Engn, 123 Univ Rd,Sec 3, Touliu 64002, Yunlin, Taiwan.
EM cwchang@ncut.edu.tw; chuanyu@yuntech.edu.tw; m10617018@yuntech.edu.tw
RI Chang, Chuan-Yu/X-9186-2019
OI Chang, Chuan-Yu/0000-0001-9476-8130
FU Ministry of Science and Technology, Taiwan [MOST 109-2637-E-167-004-]
FX This work was supported by the Ministry of Science and Technology,
   Taiwan, under the grants MOST 109-2637-E-167-004-.
CR Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284
   Alwan Majd., 2006, 2006 2 INT C INFORM, V1, P1003, DOI DOI 10.1109/ICTTA.2006.1684511
   Arifoglu D, 2017, PROCEDIA COMPUT SCI, V110, P86, DOI 10.1016/j.procs.2017.06.121
   Belshaw M, 2011, RESNA ICTA 2011 ADV
   Belshaw M, 2011, IEEE ENG MED BIO, P1773, DOI 10.1109/IEMBS.2011.6090506
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Bera A, 2016, P INT C COMP VIS PAT, P50
   Nievas EB, 2011, LECT NOTES COMPUT SC, V6855, P332, DOI 10.1007/978-3-642-23678-5_39
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bourke AK, 2007, GAIT POSTURE, V26, P194, DOI 10.1016/j.gaitpost.2006.09.012
   Bourke AK, 2008, IEEE ENG MED BIO, P2844, DOI 10.1109/IEMBS.2008.4649795
   Burkard R., 2012, Assignment problems: revised reprint, DOI [10.1137/1.9781611972238, DOI 10.1137/1.9781611972238]
   Chaker R, 2017, PATTERN RECOGN, V61, P266, DOI 10.1016/j.patcog.2016.06.016
   Charfi I, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.041106
   Fan YX, 2017, NEUROCOMPUTING, V260, P43, DOI 10.1016/j.neucom.2017.02.082
   Feng YC, 2017, NEUROCOMPUTING, V219, P548, DOI 10.1016/j.neucom.2016.09.063
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gómez AHF, 2015, LECT NOTES COMPUT SC, V9107, P516, DOI 10.1007/978-3-319-18914-7_54
   Harrou F, 2017, IEEE INSTRU MEAS MAG, V20, P49, DOI 10.1109/MIM.2017.8121952
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu X, 2020, NEUROCOMPUTING, V383, P270, DOI 10.1016/j.neucom.2019.11.087
   Hu Y, 2020, J GRID COMPUT, V18, P227, DOI 10.1007/s10723-020-09506-2
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Kangas M, 2009, GAIT POSTURE, V29, P571, DOI 10.1016/j.gaitpost.2008.12.008
   Kim Y., 2019, Introduction to Kalman Filter and Its Applications. Dans Kalman Filter, DOI 10.5772/intechopen.80600
   Laxhammar R, 2014, IEEE T PATTERN ANAL, V36, P1158, DOI 10.1109/TPAMI.2013.172
   Li Y, 2010, IEEE ENG MED BIO, P2242, DOI 10.1109/IEMBS.2010.5627368
   Li ZM, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419560044
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Nannan L, 2015, INT J PATTERN RECOGN, V29
   Núñez-Marcos A, 2017, WIREL COMMUN MOB COM, DOI 10.1155/2017/9474806
   Olah C., 2015, Understanding LSTM Networks, DOI DOI 10.1007/S13398-014-0173-7.2
   Pan HD, 2018, 2018 11TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2018)
   Popescu M, 2008, IEEE ENG MED BIO, P4628, DOI 10.1109/IEMBS.2008.4650244
   Redmon J., 2018, COMPUTER VISION PATT
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren WY, 2015, VISUAL COMPUT, V31, P245, DOI 10.1007/s00371-013-0915-0
   Rongyong Zhao, 2021, 2021 IEEE 5th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC), P1924, DOI 10.1109/IAEAC50856.2021.9390762
   Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361
   Shu G, 2014, INT J SECUR APPL, V8, P31, DOI 10.14257/ijsia.2014.8.5.04
   Stone EE, 2015, IEEE J BIOMED HEALTH, V19, P290, DOI 10.1109/JBHI.2014.2312180
   Tani MYK, 2015, LECT NOTES COMPUT SC, V8926, P299, DOI 10.1007/978-3-319-16181-5_21
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Van Beeck K, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Nguyen VD, 2014, C IND ELECT APPL, P994, DOI 10.1109/ICIEA.2014.6931308
   Wang XF, 2016, OPTIK, V127, P2386, DOI 10.1016/j.ijleo.2015.08.081
   Welch G., 2006, Tech. rep.
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Zhang J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030946
   Zhao Z, 2019, BIOMED CIRC SYST C, DOI 10.1109/biocas.2019.8918995
   Zhu YJ, 2016, COMM COM INF SC, V664, P154, DOI 10.1007/978-981-10-3476-3_19
NR 57
TC 11
Z9 11
U1 5
U2 109
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 11825
EP 11843
DI 10.1007/s11042-021-11887-9
EA JAN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000743419000002
DA 2024-07-18
ER

PT J
AU Yuan, C
   Wang, HX
   He, PS
   Luo, J
   Li, B
AF Yuan, Chao
   Wang, Hongxia
   He, Peisong
   Luo, Jie
   Li, Bin
TI GAN-based image steganography for enhancing security via adversarial
   attack and pixel-wise deep fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Generative adversarial networks; Adversarial
   attack; Pixel-wise deep fusion
ID STEGANALYSIS; NETWORK
AB In recent years, the development of steganalysis based on convolutional neural networks (CNN) has brought new challenges to the security of image steganography. However, the current steganographic methods are difficult to resist the detection of CNN-based steganalyzers. To solve this problem, we propose an end-to-end image steganographic scheme based on generative adversarial networks (GAN) with adversarial attack and pixel-wise deep fusion. There are mainly four modules in the proposed scheme: the universal adversarial network is utilized in Attack module to fool CNN-based steganalyzers for enhancing security; Encoder module is seen as the generator to implement the pixel-wise deep fusion for imperceptible information embedding with high payload; Decoder module is responsible for the process of recovering embedded information; Critic module is designed for the discriminator to provide objective scores and conduct adversarial training. Besides, multiple loss functions together with Wasserstein GAN strategy are applied to enhance the stability and availability of the proposed scheme. Experiments on different datasets have verified the advantages of adding universal adversarial perturbations for higher security against CNN-based steganalyzers without compromising imperceptibility. Compared with state-of-the-art methods, the proposed scheme has achieved better performance in security.
C1 [Yuan, Chao; Wang, Hongxia; He, Peisong; Luo, Jie] Sichuan Univ, Sch Cyber Sci & Engn, Chengdu 610065, Peoples R China.
   [Li, Bin] Guangdong Key Lab Intelligent Informat Proc, Shenzhen 518060, Peoples R China.
   [Li, Bin] Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.
C3 Sichuan University
RP Wang, HX (corresponding author), Sichuan Univ, Sch Cyber Sci & Engn, Chengdu 610065, Peoples R China.
EM yuanchao@stu.scu.edu.cn; hxwang@scu.edu.cn; gokeyhps@scu.edu.cn;
   luojie1@stu.scu.edu.cn; libin@szu.edu.cn
RI Wang, Hongxia/AAE-2135-2022; He, Peisong/AAE-2082-2022
OI luo, jie/0000-0002-7309-0866
FU National Natural Science Foundation of China [61972269, 61902263]; China
   Postdoctoral Science Foundation [2020 M673276]; Fundamental Research
   Funds for the Central Universities [YJ201881, 2020SCU12066]
FX This work was supported by National Natural Science Foundation of China
   (61972269, 61902263), China Postdoctoral Science Foundation (2020
   M673276), and the Fundamental Research Funds for the Central
   Universities (YJ201881, 2020SCU12066).
CR [Anonymous], LIRMMBASE
   [Anonymous], 2014, Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific, DOI [10.1109/APSIPA.2014, 10.1109/APSIPA.2014.7041565]
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bas P., 2007, Bows-2
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Chen PY, 2017, P 10 ACM WORKSH ART, P15, DOI [10.1145/3128572.3140448, DOI 10.1145/3128572.3140448]
   Egiazarian K., 2006, proceedings of the second international workshop on video processing and quality metrics, P4
   Feng GR, 2020, IEEE T CIRC SYST VID, V30, P376, DOI 10.1109/TCSVT.2019.2891778
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Geetha S, 2021, PATTERN RECOGN LETT, V147, P197, DOI 10.1016/j.patrec.2021.04.026
   Goodfellow I. J., 2015, CoRR abs/1412.6572
   Goodfellow IJ, 2014, ADV NEUR IN, P2672, DOI DOI 10.1145/3422622
   Hayes J, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P43, DOI 10.1109/SPW.2018.00015
   Hayes Jamie, 2017, Advances in neural information processing systems, P1954
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Li L, 2021, MULTIMED TOOLS APPL, V80, P25539, DOI 10.1007/s11042-021-10904-1
   Lin M., 2013, 13124400 ARXIV, P1
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Ponomarenko N., 2007, P 3 INT WORKSH VID P
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Shi HC, 2018, LECT NOTES COMPUT SC, V10735, P534, DOI 10.1007/978-3-319-77380-3_51
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Volkhonskiy D, 2020, PROC SPIE, V11433, DOI 10.1117/12.2559429
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Yang JH, 2020, IEEE T INF FOREN SEC, V15, P839, DOI 10.1109/TIFS.2019.2922229
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Yu C, 2020, AAAI CONF ARTIF INTE, V34, P1120
   Zhang R, 2020, IEEE T INF FOREN SEC, V15, P1138, DOI 10.1109/TIFS.2019.2936913
   Zhang R, 2019, MULTIMED TOOLS APPL, V78, P8559, DOI 10.1007/s11042-018-6951-z
   Zhou XY, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091024
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
   Zi HQ, 2018, ASIAPAC SIGN INFO PR, P526, DOI 10.23919/APSIPA.2018.8659716
NR 42
TC 10
Z9 10
U1 4
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6681
EP 6701
DI 10.1007/s11042-021-11778-z
EA JAN 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000743419000001
DA 2024-07-18
ER

PT J
AU Yazid, H
   Basah, SN
   Rahim, SA
   Safar, MJA
   Basaruddin, KS
AF Yazid, Haniza
   Basah, Shafriza Nisha
   Rahim, Saufiah Abdul
   Safar, Muhammad Juhairi Aziz
   Basaruddin, Khairul Salleh
TI Performance analysis of entropy thresholding for successful image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Kapur entropy thresholding; Li entropy thresholding;
   Segmentation performance; Monte Carlo statistical method
ID TSALLIS ENTROPY; PARTITION; ALGORITHM
AB Image segmentation refers to a procedure of segmenting the foreground (object of interest) from the background. One of the well-known methods is thresholding based segmentation that segments an image according to a threshold value. Most of the proposed methods either proposing a new algorithm or improvising the algorithm to segment the foreground. However, there is no analysis is carried out to determine the successfulness of the methods under different conditions. This main contribution of this paper is to analyse the entropy thresholding namely the method proposed by Kapur and Li for various parameters which include noise measurement, size of the object, and the difference in intensity between the background and object. In this paper, a few conditions were proposed to ensure successful image segmentation. Based on the experimental result, intensity difference needs to be around 35% and the object size is about 73% for all noise levels for Kapur. For Li entropy, the intensity difference needs to be at a minimum of 44% and 80% for object size. It is demonstrated that the proposed conditions accurately foresee the result of image thresholding based on Kapur and Li entropy.
C1 [Yazid, Haniza; Basah, Shafriza Nisha; Rahim, Saufiah Abdul; Safar, Muhammad Juhairi Aziz] Univ Malaysia Perlis, Fac Elect Engn Technol, 02600 Pauh Putra Campus, Perlis, Malaysia.
   [Basaruddin, Khairul Salleh] Univ Malaysia Perlis, Fac Mech Engn Technol, 02600 Pauh Putra Campus, Perlis, Malaysia.
C3 Universiti Malaysia Perlis; Universiti Malaysia Perlis
RP Yazid, H (corresponding author), Univ Malaysia Perlis, Fac Elect Engn Technol, 02600 Pauh Putra Campus, Perlis, Malaysia.
EM hanizayazid@unimap.edu.my
RI Basaruddin, Khairul/I-8478-2019; Yazid, Haniza/D-3830-2015
OI Basaruddin, Khairul/0000-0002-9806-3565; 
CR ABUTALEB AS, 1989, COMPUT VISION GRAPH, V47, P22, DOI 10.1016/0734-189X(89)90051-0
   Agrawal S, 2013, SWARM EVOL COMPUT, V11, P16, DOI 10.1016/j.swevo.2013.02.001
   Al-Ajlan A, 2009, IEEE SYS MAN CYBERN, P1776, DOI 10.1109/ICSMC.2009.5346619
   [Anonymous], 2018, DIGITAL IMAGE PROCES
   Boaretto N, 2017, NDT&E INT, V86, P7, DOI 10.1016/j.ndteint.2016.11.003
   Cai HM, 2014, IEEE T IMAGE PROCESS, V23, P1038, DOI 10.1109/TIP.2014.2298981
   Chen X, 2016, NEUROCOMPUTING, V189, P43, DOI 10.1016/j.neucom.2015.11.040
   Cheng HD, 1998, PATTERN RECOGN, V31, P857, DOI 10.1016/S0031-3203(97)00113-1
   Cheng HD, 1999, SIGNAL PROCESS, V75, P277, DOI 10.1016/S0165-1684(98)00239-4
   de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   Fu Y, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/3279563
   Goh TY, 2018, MEASUREMENT, V114, P298, DOI 10.1016/j.measurement.2017.09.052
   Gong JA, 1998, PATTERN RECOGN, V31, P295, DOI 10.1016/S0031-3203(97)00043-5
   Horng MH, 2010, EXPERT SYST APPL, V37, P4580, DOI 10.1016/j.eswa.2009.12.050
   Kang C, 2020, IEEE ACCESS, V8, P17025, DOI 10.1109/ACCESS.2020.2964335
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   LI CH, 1993, PATTERN RECOGN, V26, P617, DOI 10.1016/0031-3203(93)90115-D
   Li CH, 1998, PATTERN RECOGN LETT, V19, P771, DOI 10.1016/S0167-8655(98)00057-9
   Lin QQ, 2012, SIGNAL PROCESS, V92, P2931, DOI 10.1016/j.sigpro.2012.05.025
   Liu Y, 2007, IEEE INT C GREY SYST
   Manikandan S, 2014, MEASUREMENT, V47, P558, DOI 10.1016/j.measurement.2013.09.031
   Marin D, 2015, COMPUT METH PROG BIO, V118, P173, DOI 10.1016/j.cmpb.2014.11.003
   Mustafa W.A, 2018, J TELECOMMUN ELECT C, V10, P43
   Nie FY, 2017, SIGNAL PROCESS, V134, P23, DOI 10.1016/j.sigpro.2016.11.004
   Oliva D, 2017, EXPERT SYST APPL, V79, P164, DOI 10.1016/j.eswa.2017.02.042
   Ramesh D, 2018, L N COMPUT VIS BIOME, V28, P937, DOI 10.1007/978-3-319-71767-8_80
   Sahoo P, 1997, PATTERN RECOGN, V30, P71, DOI 10.1016/S0031-3203(96)00065-9
   Sahoo PK, 2004, PATTERN RECOGN, V37, P1149, DOI 10.1016/j.patcog.2003.10.008
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Tao WB, 2007, PATTERN RECOGN LETT, V28, P788, DOI 10.1016/j.patrec.2006.11.007
   WESZKA JS, 1978, IEEE T SYST MAN CYB, V8, P622, DOI 10.1109/TSMC.1978.4310038
   WONG AKC, 1989, IEEE T SYST MAN CYB, V19, P866, DOI 10.1109/21.35351
   Xue JH, 2011, IMAGE VISION COMPUT, V29, P631, DOI 10.1016/j.imavis.2011.06.003
   Yazid H, 2012, MEASUREMENT, V45, P1599, DOI 10.1016/j.measurement.2012.02.016
   Yazid H, 2011, NDT&E INT, V44, P563, DOI 10.1016/j.ndteint.2011.06.002
   YEN JC, 1995, IEEE T IMAGE PROCESS, V4, P370, DOI 10.1109/83.366472
   Yin PY, 2007, APPL MATH COMPUT, V184, P503, DOI 10.1016/j.amc.2006.06.057
   Yin PY, 2002, SIGNAL PROCESS, V82, P993, DOI 10.1016/S0165-1684(02)00203-7
   Zaitoun NM, 2015, PROCEDIA COMPUT SCI, V65, P797, DOI 10.1016/j.procs.2015.09.027
   Zhang H, 2008, COMPUT VIS IMAGE UND, V110, P260, DOI 10.1016/j.cviu.2007.08.003
   Zhao MS, 2001, IEEE T FUZZY SYST, V9, P469, DOI 10.1109/91.928743
   Zou YB, 2020, IEEE ACCESS, V8, P171218, DOI 10.1109/ACCESS.2020.3024718
NR 43
TC 9
Z9 10
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6433
EP 6450
DI 10.1007/s11042-021-11813-z
EA JAN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000742318900001
DA 2024-07-18
ER

PT J
AU Roy, D
   Santra, S
   Chanda, B
AF Roy, Debapriya
   Santra, Sanchayan
   Chanda, Bhabatosh
TI LGVTON: a landmark guided approach for model to person virtual try-on
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual try-on; Conditional generative adversarial networks; Human
   landmarks; Fashion landmarks; Thin-plate spline transformation
AB In this paper, we propose a Landmark Guided Virtual Try-On (LGVTON) method for clothes, which aims to solve the problem of clothing trials on e-commerce websites. Given the images of two people: a person and a model, it generates a rendition of the person wearing the clothes of the model. This is useful considering the fact that on most e-commerce websites images of only clothes are not usually available. We follow a three-stage approach to achieve our objective. In the first stage, LGVTON warps the clothes of the model using a Thin-Plate Spline (TPS) based transformation to fit the person. Unlike previous TPS-based methods, we use the landmarks (of human and clothes) to compute the TPS transformation. This enables the warping to work independently of the complex patterns, such as stripes, florals, and textures, present on the clothes. However, this computed warp may not always be very precise. We, therefore, further refine it in the subsequent stages with the help of a mask generator (Stage 2) and an image synthesizer (Stage 3) modules. The mask generator improves the fit of the warped clothes, and the image synthesizer ensures a realistic output. To tackle the problem of lack of paired training data, we resort to a self-supervised training strategy. Here paired data refers to the image pair of model and person wearing the same cloth. We compare LGVTON with four existing methods on two popular fashion datasets namely MPV and DeepFashion using two performance measures, FID (Frechet Inception Distance) and SSIM (Structural Similarity Index). The proposed method in most cases outperforms the state-of-the-art methods.
C1 [Roy, Debapriya; Chanda, Bhabatosh] Indian Stat Inst, Kolkata, India.
   [Santra, Sanchayan] Osaka Univ, Inst Databil Sci, Suita, Osaka, Japan.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata;
   Osaka University
RP Roy, D (corresponding author), Indian Stat Inst, Kolkata, India.
EM chanda@isical.ac.in
CR Belongie S, 2001, ADV NEUR IN, V13, P831
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donato G, 2002, LECT NOTES COMPUT SC, V2352, P21
   Dong H, 2019, IEEE I CONF COMP VIS, P9025, DOI 10.1109/ICCV.2019.00912
   Dong HY, 2019, IEEE I CONF COMP VIS, P1161, DOI 10.1109/ICCV.2019.00125
   Duchon Jean, 1976, LECT NOTES MATH, V571, P85, DOI DOI 10.1007/BFB0086566
   Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Han XT, 2019, IEEE I CONF COMP VIS, P10470, DOI 10.1109/ICCV.2019.01057
   Han XT, 2018, PROC CVPR IEEE, P7543, DOI 10.1109/CVPR.2018.00787
   Han Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7847, DOI 10.1109/CVPR42600.2020.00787
   Hensel M, 2017, ADV NEUR IN, V30
   Hsieh CW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P275, DOI 10.1145/3343031.3351075
   Hsieh CW, 2019, IEEE IMAGE PROC, P4694, DOI [10.1109/icip.2019.8803681, 10.1109/ICIP.2019.8803681]
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Issenhuth Thibaut, 2019, ARXIV PREPRINT ARXIV
   Jandial Surgan, 2020, 2020 IEEE Winter Conference on Applications of Computer Vision (WACV). Proceedings, P2171, DOI 10.1109/WACV45572.2020.9093458
   Jetchev N, 2017, IEEE INT CONF COMP V, P2287, DOI 10.1109/ICCVW.2017.269
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Lee HJ, 2019, IEEE INT CONF COMP V, P3129, DOI 10.1109/ICCVW.2019.00381
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Liu ZW, 2016, LECT NOTES COMPUT SC, V9906, P229, DOI 10.1007/978-3-319-46475-6_15
   Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8
   Minar MR, 2020, P AS C COMP VIS
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Neuberger A, 2020, PROC CVPR IEEE, P5183, DOI 10.1109/CVPR42600.2020.00523
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   PONSMOLL G, 2017, ACM T GRAPHIC, V36, P1, DOI DOI 10.1145/3072959.3073711
   Raj A, 2018, LECT NOTES COMPUT SC, V11216, P679, DOI 10.1007/978-3-030-01258-8_41
   Rocco I, 2017, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2017.12
   Salimans T, 2016, ADV NEUR IN, V29
   Sekine M., 2014, Int. Conf. on 3D Body Scanning Technologies, P406
   Shai T, 2006, IEEE T IMAGE PROCESS
   Shigeki Yui, 2018, IPSJ Transactions on Computer Vision and Applications, V10, DOI 10.1186/s41074-018-0052-9
   Song D, 2020, MULTIMED TOOLS APPL, V79, P33757, DOI 10.1007/s11042-019-08363-w
   Sprengel R, 1997, P IEEE EMBS, V18, P1190, DOI 10.1109/IEMBS.1996.652767
   Sun F, 2019, IEEE IMAGE PROC, P519, DOI [10.1109/ICIP.2019.8803811, 10.1109/icip.2019.8803811]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Wahba G., 1990, SPLINE MODELS OBSERV
   Wang BC, 2018, LECT NOTES COMPUT SC, V11217, P607, DOI 10.1007/978-3-030-01261-8_36
   Wang WG, 2018, PROC CVPR IEEE, P4271, DOI 10.1109/CVPR.2018.00449
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu ZH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P293, DOI 10.1145/3343031.3351083
   Xian WQ, 2018, PROC CVPR IEEE, P8456, DOI 10.1109/CVPR.2018.00882
   Yu RY, 2019, IEEE I CONF COMP VIS, P10510, DOI 10.1109/ICCV.2019.01061
   Zanfir M, 2018, PROC CVPR IEEE, P5391, DOI 10.1109/CVPR.2018.00565
   Zeng W, 2020, NEURAL COMPUT APPL, V32, P17587, DOI 10.1007/s00521-020-04928-1
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng N, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P266, DOI 10.1145/3343031.3350946
NR 53
TC 4
Z9 4
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5051
EP 5087
DI 10.1007/s11042-021-11647-9
EA JAN 2022
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000740429700017
DA 2024-07-18
ER

PT J
AU Hiriyannaiah, S
   Siddesh, GM
   Srinivasa, KG
AF Hiriyannaiah, Srinidhi
   Siddesh, G. M.
   Srinivasa, K. G.
TI DeepLSGR: Neural collaborative filtering for recommendation systems in
   smart community
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommendation systems; Collaborative filtering; Deep learning; LSTM;
   GRU; Web recommenders
ID NETWORK; RATINGS
AB In the field of Data science and online world, Recommendation Systems (RS) play an important role among the various e-commerce applications. Data sparsity often leads to the problem of precise recommendations in RS as there will be either less number of users or ratings. Collaborative filtering (CF) is one of the key techniques that are used for the RS with the pre-requisite of the adequate information of the users and items. Deep Learning (DL) models haved paved the way for analysis and prediction of sequential textual information in various applications. Hence, CF combined with DL approaches are also being explored to solve the problem of data sparsity in RS with various challenges of analysis and prediction of the sequential information. This paper considers the problem of data sparsity with a novel neural CF based DeepLSGR model to provide better recommendations. It is a bi-directional model composed of stacked hidden layers with Long-short term memory (LSTM) and Gated recurrent unit (GRU) and provide recommendations based on the prediction of rating using the textual reviews from the users. It provided an accuracy of 97%, recall of 61% and RMSE of 0.87 for the experiments conducted on the Amazon Fine Food Reviews and OpinRank datasets. The results of the comparison with the existing works evidently demonstrate that the DeepLSGR provides improved recommendations.
C1 [Hiriyannaiah, Srinidhi; Siddesh, G. M.] Visvesvaraya Technol Univ, MS Ramaiah Inst Technol, Bengaluru, Karnataka, India.
   [Srinivasa, K. G.] Natl Inst Tech Teachers Training & Res, Chandigarh, India.
C3 Ramaiah Institute of Technology; Visvesvaraya Technological University;
   National Institute of Technical Teachers Training & Research, Chandigarh
RP Hiriyannaiah, S (corresponding author), Visvesvaraya Technol Univ, MS Ramaiah Inst Technol, Bengaluru, Karnataka, India.
EM srinidhi.hiriyannaiah@gmail.com
RI Hiriyannaiah, Srinidhi/AAD-2826-2021
OI Hiriyannaiah, Srinidhi/0000-0003-2304-5087
CR Abdi M.H., 2018, Matrix factorization techniques for contextaware collaborative filtering recommender systems: a survey
   Alashkar T, 2017, AAAI CONF ARTIF INTE, P941
   An HW, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01521-w
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chen K, 2021, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.1061/(ASCE)EY.1943-7897.0000804
   Diao QM, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P193, DOI 10.1145/2623330.2623758
   Dong X, 2017, AAAI CONF ARTIF INTE, P1309
   Ganesan KA, INFORM RETRIEVAL
   Gavilan D, 2018, TOURISM MANAGE, V66, P53, DOI 10.1016/j.tourman.2017.10.018
   Gong XY, 2019, J PHYS CONF SER, V1176, DOI 10.1088/1742-6596/1176/2/022043
   Hwangbo H, 2018, ELECTRON COMMER R A, V28, P94, DOI 10.1016/j.elerap.2018.01.012
   Jia XW, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P402, DOI 10.1109/ASONAM.2016.7752265
   Jiang LL, 2019, J AMB INTEL HUM COMP, V10, P3023, DOI 10.1007/s12652-018-0928-7
   Kawale J, 2015, P 24 ACM INT C INF K, P811, DOI DOI 10.1145/2806416.2806527
   Khoshgoftaar T.M., 2009, ADV ARTIFICIAL INTEL, DOI [10.1155/2009/421425, DOI 10.1155/2009/421425]
   Kluver D, 2018, LECT NOTES COMPUT SC, V10100, P344, DOI 10.1007/978-3-319-90092-6_10
   Li S., 2017, P 2017 C EMPIRICAL M, P1884, DOI [DOI 10.18653/V1/D17-1201, 10.18653/v1/D17-1201]
   Li Yuezhang., 2016, COLING
   Liu JT, 2018, INFORM SCIENCES, V423, P50, DOI 10.1016/j.ins.2017.09.048
   Liu Y., 2018, NEURAL NETWORK METHO
   Ma C, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P519, DOI 10.1145/3289600.3290977
   Mahata SK, 2019, J INTELL SYST, V28, P447, DOI 10.1515/jisys-2018-0016
   McAuley J., 2013, AMATEURS CONNOISSEUR
   McAuley Julian, 2013, RECSYS
   Mukherjee S, 2017, P 2017 SIAM INT C DA, P480, DOI [10.1137/1.9781611974973.54, DOI 10.1137/1.9781611974973.54]
   Okura S, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1933, DOI 10.1145/3097983.3098108
   김건우, 2018, [Journal of Intelligence and Information Systems, 지능정보연구], V24, P227, DOI 10.13088/jiis.2018.24.1.227
   Parvin H, 2018, 2018 IEEE DATA SCIENCE WORKSHOP (DSW), P135, DOI 10.1109/DSW.2018.8439905
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Seo S, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P297, DOI 10.1145/3109859.3109890
   Shi Y, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2556270
   Tan Y. K., 2016, Proceedings of the 1st workshop on deep learning for recommender systems, P17
   Thakkar P, 2019, SMART INNOV SYST TEC, V107, P173, DOI 10.1007/978-981-13-1747-7_17
   Nguyen VD, 2017, ELECTRON COMMER R A, V26, P101, DOI 10.1016/j.elerap.2017.10.002
   Wu Chao-Yuan, 2016, JOINT TRAINING RATIN
   Wu S, 2016, PROC INT CONF DATA, P1218, DOI 10.1109/ICDE.2016.7498326
   Wu Y, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P199, DOI 10.1145/2684822.2685291
   Xue W, 2017, WORLD WIDE WEB, V20, P23, DOI 10.1007/s11280-016-0398-9
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
   Zhang QC, 2018, INFORM FUSION, V42, P146, DOI 10.1016/j.inffus.2017.10.006
   Zhang QS, 2018, FRONT INFORM TECH EL, V19, P27, DOI 10.1631/FITEE.1700808
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
   Zheng L, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P425, DOI 10.1145/3018661.3018665
NR 44
TC 5
Z9 5
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8709
EP 8728
DI 10.1007/s11042-021-11551-2
EA JAN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000737741900009
DA 2024-07-18
ER

PT J
AU Salim, NR
   Srinath, V
   Jayaraman, U
   Gupta, P
AF Salim, Nilu R.
   Srinath, V
   Jayaraman, Umarani
   Gupta, Phalguni
TI Recognition in the near infrared spectrum for face, gender andfacial
   expressions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Gender classification; Facial expressions; Near
   infra-red spectrum; Illumination invariance; Convolutional neural
   networks; Biometrics
ID AGE
AB Visible face recognition systems are subjected to failure when recognizing the faces in unconstrained scenarios. So, recognizing faces under variable and low illumination conditions are more important since most of the security breaches happen during night time. Near Infrared (NIR) spectrum enables to acquire high quality images, even without any external source of light and hence it is a good method for solving the problem of illumination. Further, the soft biometric trait, gender classification and non verbal communication, facial expression recognition has also been addressed in the NIR spectrum. In this paper, a method has been proposed to recognize the face along with gender classification and facial expression recognitionin NIR spectrum. The proposed method is based on transfer learning and it consists of three core components, i) training with small scale NIR images ii) matching NIR-NIR images (homogeneous) and iii) classification. Training on NIR images produce features using transfer learning which has been pre-trained on large scale VIS face images. Next, matching is performed between NIR-NIR spectrum of both training and testing faces. Then it is classified using three, separate SVM classifiers, one for face recognition, the second one for gender classification and the third one for facial expression recognition. It has been observed that the method gives state-of-the-art accuracy on the publicly available, challenging, benchmark datasets CASIA NIR-VIS 2.0, Oulu-CASIA NIR-VIS, PolyU, CBSR, IIT Kh and HITSZ for face recognition. Further, for gender classification the Oulu-CASIA NIR-VIS, PolyU,and IIT Kh has been analyzed and for facial expression the Oulu-CASIA NIR-VIS dataset has been analyzed.
C1 [Salim, Nilu R.; Jayaraman, Umarani] IIITDM Kancheepuram, Dept CSE, Chennai, Tamil Nadu, India.
   [Srinath, V] SSN Coll Engn, Dept IT, Chennai, Tamil Nadu, India.
   [Gupta, Phalguni] GLA Univ, Mathura, India.
C3 Indian Institute of Information Technology, Design & Manufacturing,
   Kancheepuram; SSN College of Engineering; GLA University
RP Salim, NR (corresponding author), IIITDM Kancheepuram, Dept CSE, Chennai, Tamil Nadu, India.
EM coe17d001@iiitdm.ac.in; srinathv17111@it.ssn.edu.in;
   umarani@iiitdm.ac.in; iitkmailsofpg@gmail.com
RI jayaraman, umarani/GZG-1821-2022
OI jayaraman, umarani/0000-0002-9676-6291; R SALIM,
   NILU/0000-0001-6619-7027
CR Cerna L., 2013, Proceedings of the International Conference on Image Processing, Computer Vision, and Pattern Recognition (IPCV), P1
   Chen X, 2011, IEEE INT C BIOINFORM, P3, DOI 10.1109/BIBM.2011.12
   Dhamecha TI, 2014, INT C PATT RECOG, P1788, DOI 10.1109/ICPR.2014.314
   Duan MX, 2018, NEUROCOMPUTING, V275, P448, DOI 10.1016/j.neucom.2017.08.062
   Fang J, 2019, NEUROCOMPUTING, V334, P114, DOI 10.1016/j.neucom.2018.12.073
   Farokhi S, 2016, COMPUT SCI REV, V21, P1, DOI 10.1016/j.cosrev.2016.05.003
   Fu C, 2021, IEEE T PATTERN ANAL
   Happy SL, 2012, 4TH INTERNATIONAL CONFERENCE ON INTELLIGENT HUMAN COMPUTER INTERACTION (IHCI 2012)
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He R, 2019, IEEE T PATTERN ANAL, V41, P1761, DOI 10.1109/TPAMI.2018.2842770
   Kim J, 2019, INT CONF ACOUST SPEE, P2337, DOI 10.1109/ICASSP.2019.8683261
   Li SZ, 2007, IEEE T PATTERN ANAL, V29, P627, DOI 10.1109/TPAMI.2007.1014
   Li SZ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P455
   Li SZ, 2013, IEEE COMPUT SOC CONF, P348, DOI 10.1109/CVPRW.2013.59
   Liang DD, 2020, VISUAL COMPUT, V36, P499, DOI 10.1007/s00371-019-01636-3
   Maji S, 2013, IEEE T PATTERN ANAL, V35, P66, DOI 10.1109/TPAMI.2012.62
   Mäkinen E, 2008, IEEE T PATTERN ANAL, V30, P541, DOI 10.1109/TPAMI.2007.70800
   Narang N, 2016, INT CONF BIOMETR
   Nordstrom M.M., 2004, The imm face database an annotated dataset of 240 face images
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Singh M, 2017, IEEE IJCNN, P1026, DOI 10.1109/IJCNN.2017.7965965
   Wu X, 2019, AAAI CONF ARTIF INTE, P9005
   Xu Y, 2011, OPT ENG, V50, DOI 10.1117/1.3554740
   Yang HY, 2018, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2018.00231
   Zhang BC, 2010, PATTERN RECOGN LETT, V31, P2337, DOI 10.1016/j.patrec.2010.07.006
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
NR 27
TC 2
Z9 2
U1 5
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 4143
EP 4162
DI 10.1007/s11042-021-11728-9
EA NOV 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000723965800001
DA 2024-07-18
ER

PT J
AU Chowdhury, DP
   Kumari, R
   Bakshi, S
   Sahoo, MN
   Das, A
AF Chowdhury, Debbrota P.
   Kumari, Ritu
   Bakshi, Sambit
   Sahoo, Manmath N.
   Das, Abhijit
TI Lip as biometric and beyond: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lip; Biometric; Health monitoring; Behavior and physiology
ID SPEAKER IDENTIFICATION; PERSONAL IDENTIFICATION; REGION-SEGMENTATION;
   PRINT RECOGNITION; SECURITY SYSTEMS; MOTION FEATURES; MRF FRAMEWORK;
   ROBUST; EXTRACTION; PATTERN
AB Owing to the recent fuel in investigation of lip as a biometrics trait both in physiological and behavioral aspect, and in healthcare application, it is imperative to comprehensively study and document the literature. Hence, in this work we enlist the works related to the lip as a biometirc trait and other applications-based on its behavior and physiology. Consequently, in this survey we first discuss the lip anatomy that permits to identify the physiological and behavioral properties. Followed by the list of challenges to characterize lip behavior and physiology. Next, we proceed to provide an insight of several inspiring ideas proposed in the literature to establish lip behavior and physiology for identity and other applications such as health monitoring and forensic. Whilst, it can be concluded at the end of the survey that their are several open research area and unsolved issues, which we discuss in details at the end of this survey to attract the attention of researchers.
C1 [Chowdhury, Debbrota P.; Kumari, Ritu; Bakshi, Sambit; Sahoo, Manmath N.] Natl Inst Technol, Dept Comp Sci & Engn, Rourkela, India.
   [Das, Abhijit] Inria Sophia Antipolis Mediterranee, Biot, France.
   [Das, Abhijit] Thapar Univ, Patiala, Punjab, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela; Thapar Institute of Engineering & Technology
RP Das, A (corresponding author), Inria Sophia Antipolis Mediterranee, Biot, France.; Das, A (corresponding author), Thapar Univ, Patiala, Punjab, India.
EM sahoom@nitrkl.ac.in; abhijit.das@inria.fr
RI Bakshi, Sambit/JDC-3355-2023; Sahoo, Manmath Narayan N/N-8111-2017
OI Bakshi, Sambit/0000-0002-6107-114X; Paul Chowdhury,
   Debbrota/0000-0002-4622-2157
CR Abel A, 2009, LECT NOTES COMPUT SC, V5707, P65, DOI 10.1007/978-3-642-04391-8_9
   Adamu LH, 2015, HOMO, V66, P561, DOI 10.1016/j.jchb.2015.08.002
   Aleix M, 1998, 24 CVC TECH
   Almajai I, 2016, INT CONF ACOUST SPEE, P2722, DOI 10.1109/ICASSP.2016.7472172
   [Anonymous], 2015, PROC C AUDITORY VIS
   [Anonymous], 2011, INT C HAND BASED BIO, DOI DOI 10.1109/ICHB.2011.6094309
   [Anonymous], 2010, 2 INT WORKSHOP INTEL
   [Anonymous], 2006, 9 INT C CONTR AUT RO, DOI DOI 10.1109/ICARCV.2006.345473
   Aravabhumi Vikas Reddy, 2010, 2010 2nd International Conference on Mechanical and Electrical Technology (ICMET), P125, DOI 10.1109/ICMET.2010.5598333
   Bakhshali MA, 2014, J COMPUT SCI-NETH, V5, P251, DOI 10.1016/j.jocs.2013.07.001
   Bakshi S., 2016, ACM SIGBIOINFORMATIC, V6, P2, DOI 10.1145/2921555.2921557
   Bakshi S, 2011, ANNU IEEE IND CONF
   Bhattacharjee S, 2013, ARXIV13100036
   Bijjargi SC, 2015, NEW ATTEMPT COMPARIS
   Briceno Juan C., 2010, 2010 IEEE 14th International Conference on Intelligent Engineering Systems (INES 2010), P203, DOI 10.1109/INES.2010.5483848
   Çetingül HE, 2006, IEEE T IMAGE PROCESS, V15, P2879, DOI 10.1109/TIP.2006.877528
   Çetingül HE, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P7
   Çetingül HE, 2005, INT CONF ACOUST SPEE, P509
   Chan CH, 2011, MVA, P422
   Chan CH, 2012, IEEE T INF FOREN SEC, V7, P602, DOI 10.1109/TIFS.2011.2175920
   Chan M. T., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P848, DOI 10.1109/ICIP.1999.823017
   Cheng F, 2018, PATTERN RECOGN, V83, P340, DOI 10.1016/j.patcog.2018.06.005
   Chetty Girija., 2004, Proc. Image and Vision Computing, P17
   Cheung YM, 2014, IEEE T IMAGE PROCESS, V23, P3397, DOI 10.1109/TIP.2014.2331137
   Cheung YM, 2012, PATTERN RECOGN, V45, P3336, DOI 10.1016/j.patcog.2012.02.024
   Chin SW, 2012, INTEL SYST REF LIBR, V26, P135
   Chindaro S, 2001, LECT NOTES COMPUT SC, V2091, P84
   Choras M, 2012, PATTERN ANAL APPL, V15, P73, DOI 10.1007/s10044-011-0248-4
   Choras M, 2007, ADV INTEL SOFT COMPU, V45, P838
   Choras M, 2010, PATTERN ANAL APPL, V13, P105, DOI 10.1007/s10044-008-0144-8
   Choras RS, 2011, ADV INTEL SOFT COMPU, V102, P33
   Cooke M, 2006, J ACOUST SOC AM, V120, P2421, DOI 10.1121/1.2229005
   Coward R C, 2007, J Forensic Odontostomatol, V25, P40
   Daehyun Lee, 2017, 2017 IEEE International Conference on Consumer Electronics (ICCE), P434, DOI 10.1109/ICCE.2017.7889386
   Das A, 2019, LECT NOTES COMPUT SC, V11129, P573, DOI 10.1007/978-3-030-11009-3_35
   Das A, 2018, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2018.00008
   Das S, 2019, PATTERN RECOGN LETT, V126, P102, DOI 10.1016/j.patrec.2018.06.026
   de la Cuesta AG, 2008, 2008 INTERNATIONAL MACHINE VISION AND IMAGE PROCESSING CONFERENCE, PROCEEDINGS, P83, DOI 10.1109/IMVIP.2008.13
   Delmas P, 1999, INT CONF ACOUST SPEE, P3069, DOI 10.1109/ICASSP.1999.757489
   Dineshshankar Janardhanam, 2013, J Pharm Bioallied Sci, V5, pS95, DOI 10.4103/0975-7406.113305
   Erzin E, 2004, DSP MOBILE VEHICULAR
   Ezz M, 2020, IEEE ACCESS, V8, P55354, DOI 10.1109/ACCESS.2020.2982359
   Faraj MI, 2007, PATTERN RECOGN LETT, V28, P1368, DOI 10.1016/j.patrec.2007.02.017
   Foong OM, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCOINS), P616, DOI 10.1109/ICCOINS.2016.7783286
   Fox NA, 2005, LECT NOTES COMPUT SC, V3546, P777
   Fu JW, 2017, INT J PLASTICITY, V93, P229, DOI 10.1016/j.ijplas.2016.07.013
   George R, 2016, J FORENSIC LEG MED, V39, P156, DOI 10.1016/j.jflm.2016.01.021
   Ghaleh V. E. C., 2010, 9 INT C CYB INT SYST, P1, DOI DOI 10.1109/UKRICIS.2010.5898135
   Gofman MI, 2016, COMMUN ACM, V59, P58, DOI 10.1145/2818990
   Gómez E, 2002, 36TH ANNUAL 2002 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P39, DOI 10.1109/CCST.2002.1049223
   Guan C, 2019, IEEE IMAGE PROC, P1540, DOI [10.1109/ICIP.2019.8803087, 10.1109/icip.2019.8803087]
   Guan C, 2020, IEEE T FUZZY SYST, V28, P1242, DOI 10.1109/TFUZZ.2019.2957708
   Guan YP, 2006, 8 INT S SYMB NUM ALG, P125, DOI [10.1109/SYNASC.2006.19, DOI 10.1109/SYNASC.2006.19]
   HAMZAH NH, 2020, J SAINS KESIHAT MALA, V18, P31, DOI DOI 10.17576/jskm-2020-1802-04
   Happy SL, 2019, 2019 14 IEEE INT C A, P1
   Ichino M, 2014, I C CONT AUTOMAT ROB, P958, DOI 10.1109/ICARCV.2014.7064435
   Ichino M, 2012, I C CONT AUTOMAT ROB, P176, DOI 10.1109/ICARCV.2012.6485154
   Jianzong Wang, 2017, Biometric Recognition. 12th Chinese Conference, CCBR 2017. Proceedings: LNCS 10568, P593, DOI 10.1007/978-3-319-69923-3_64
   Jiayao Tan, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3191768
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Kapoor N, 2017, SAUDI J BIOL SCI, V24, P1149, DOI 10.1016/j.sjbs.2015.01.014
   Kasinski A., 2008, Image Processing and Communications, V13, P59
   Kim JO, 2004, FUTURE GENER COMP SY, V20, P295, DOI 10.1016/S0167-739X(03)00145-6
   Lai JY, 2016, INFORM SCIENCES, V373, P219, DOI 10.1016/j.ins.2016.09.015
   Lai JY, 2014, INT CONF DIGIT SIG, P607, DOI 10.1109/ICDSP.2014.6900736
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Leung SH, 2004, IEEE T IMAGE PROCESS, V13, P51, DOI 10.1109/TIP.2003.818116
   Li FF, 2012, BMC COMPLEM ALTERN M, V12, DOI 10.1186/1472-6882-12-127
   Li H, 2019, Development, V146
   Li M, 2010, LECT NOTES COMPUT SC, V6352, P384, DOI 10.1007/978-3-642-15819-3_51
   Liao CW, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P581
   Liévin M, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P691, DOI 10.1109/MMCS.1999.779283
   Lievin M, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P168, DOI 10.1109/ICIP.1998.727160
   Liew AWC, 2002, PATTERN RECOGN, V35, P2949, DOI 10.1016/S0031-3203(01)00231-X
   Lili Zheng, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1883, DOI 10.1109/CISP.2010.5647607
   Liu X, 2014, IEEE T INF FOREN SEC, V9, P233, DOI 10.1109/TIFS.2013.2293025
   Liu YF, 2012, INT CONF ACOUST SPEE, P1857, DOI 10.1109/ICASSP.2012.6288264
   Liu YF, 2012, IEEE T IMAGE PROCESS, V21, P3092, DOI 10.1109/TIP.2012.2186310
   Lu L, 2018, IEEE INFOCOM SER, P1466, DOI 10.1109/INFOCOM.2018.8486283
   Lu YY, 2019, MEASUREMENT, V141, P95, DOI 10.1016/j.measurement.2019.03.009
   Lu YY, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0243-9
   Lu ZH, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P472, DOI 10.1109/ICDSP.2016.7868602
   Luettin J, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P58, DOI 10.1109/ICSLP.1996.607024
   Luettin J, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P62, DOI 10.1109/ICSLP.1996.607030
   Ma X, 2017, P 9 INT C MACH LEARN, P305
   Malek M., 2019, 2019 INT C NN CONTRO, P1, DOI [10.1109/1CCAD46983.2019.9037912, DOI 10.1109/1CCAD46983.2019.9037912]
   Mathulaprangsan S, 2015, PROCEEDINGS OF 2015 INTERNATIONAL CONFERENCE ON ORANGE TECHNOLOGIES (ICOT), P22, DOI 10.1109/ICOT.2015.7498485
   Matthews I, 2002, IEEE T PATTERN ANAL, V24, P198, DOI 10.1109/34.982900
   Messer K., 1999, 2 INT C AUD VID BAS, V964, P965
   Mir SA, 2018, INT J SCI RES COMPUT, P152
   Mok LL, 2004, IEEE IMAGE PROC, P561
   Movellan J. R., 1995, Advances in Neural Information Processing Systems 7, P851
   Nagrani A, 2017, INTERSPEECH, P2616, DOI 10.21437/Interspeech.2017-950
   Nguyen QD, 2008, 2008 BIOMETRICS SYMPOSIUM (BSYM), P35, DOI 10.1109/BSYM.2008.4655520
   Nicolaidis C, 2013, J GEN INTERN MED, V28, P761, DOI 10.1007/s11606-012-2262-7
   Niu XS, 2019, IEEE INT CONF AUTOMA, P582, DOI 10.1109/fg.2019.8756554
   Norhikmah M. Kom, 2019, 2019 4th International Conference on Information Technology, Information Systems and Electrical Engineering (ICITISEE), P101, DOI 10.1109/ICITISEE48480.2019.9003820
   Omata M, 2001, LECT NOTES COMPUT SC, V2091, P108
   Pass A, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1165
   Patterson EK, 2002, INT CONF ACOUST SPEE, P2017
   Peer Peter., 2005, CVL FACE DATABASE
   Perez JFG, 2005, INT CONF ACOUST SPEE, P473
   Petajan E. D., 1984, IEEE Global Telecommunications Conference, GLOBECOM '84 Conference Record. `Communications in the Information Age' (Cat. No. 84CH2064-4), P265
   Petridis S, 2017, 14 INT C AUD VIS SPE, P36
   Pietikainen M., 2015, 11 IEEE INT C WORKSH, P1, DOI DOI 10.1109/FG.2015.7163155
   Pocovnicu Adrian, 2009, Informatica Economica, V13, P57
   Porwik P, 2019, EXPERT SYST APPL, V115, P673, DOI 10.1016/j.eswa.2018.08.037
   Porwik P, 2012, LECT NOTES COMPUT SC, V7564, P191, DOI 10.1007/978-3-642-33260-9_16
   Raman Rahul, 2017, ACM SIGBioinformatics Record, V7, DOI 10.1145/3056351.3056353
   Raman Rahul, 2017, Mobile Biometrics, P155, DOI 10.1049/PBSE003E_ch6
   Ramli Dzati Athiar, 2008, Journal of Applied Sciences, V8, P280, DOI 10.3923/jas.2008.280.287
   Ranjan V, 2014, J INDIAN ACAD ORAL M, V26, P50, DOI DOI 10.4103/0972-1363.141856
   Rojas AM, 2012, INT CARN CONF SECU, P218, DOI 10.1109/CCST.2012.6393562
   Ross A, 2003, PATTERN RECOGN, V36, P1661, DOI 10.1016/S0031-3203(02)00349-7
   Roy Anindya, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4504, DOI 10.1109/ICPR.2010.1094
   Saeed U, 2009, P 1 ACM WORKSH MULT, P7, DOI [10.1145/1631081.1631084, DOI 10.1145/1631081.1631084]
   Saeed U, 2010, P 8 INT C FRONT INF, DOI 10.1145/1943628.1943648
   Saeed U, 2010, LECT NOTES COMPUT SC, V6169, P11, DOI 10.1007/978-3-642-14061-7_2
   SALEHGHAFFARI H, 2018, ARXIV180305427
   Sanderson C, 2009, LECT NOTES COMPUT SC, V5558, P199, DOI 10.1007/978-3-642-01793-3_21
   Sandhya S., 2021, Advances in Artificial Intelligence and Data Engineering. Select Proceedings of AIDE 2019. Advances in Intelligent Systems and Computing (AISC 1133), P1023, DOI 10.1007/978-981-15-3514-7_76
   Saxena A., 2004, P INT C SYST CYB INF, P124
   Sayo A, 2011, 8 INT C INF COMM SIG, P1, DOI [10.1109/ICICS.2011.6173131, DOI 10.1109/ICICS.2011.6173131]
   Shabeer HA, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL IV, PROCEEDINGS, P270, DOI 10.1109/ICCIMA.2007.182
   Sharma P, 2011, SMART INNOV SYST TEC, V11, P347
   Shi XX, 2016, IEEE IMAGE PROC, P3942, DOI 10.1109/ICIP.2016.7533099
   Shirgahi H., 2008, WORLD APPL SCI J, V3, P323
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Singh P., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P472, DOI 10.1109/ICB.2012.6199795
   Smacki L., 2011, 2011 Third World Congress on Nature and Biologically Inspired Computing (NaBIC 2011), P594, DOI 10.1109/NaBIC.2011.6089655
   Smacki L, 2016, ADV INTELL SYST, V403, P337, DOI 10.1007/978-3-319-26227-7_32
   Spyridonos P, 2018, IEEE IMAGE PROC, P1912, DOI 10.1109/ICIP.2018.8451680
   Stafylakis Themos, 2017, ARXIV170304105
   Sukno FM, 2007, IEEE T PATTERN ANAL, V29, P1105, DOI 10.1109/TPAMI.2007.1041
   Sun K, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P581, DOI 10.1145/3242587.3242599
   Szeliski R, 2011, TEXTS COMPUT SCI, P1
   Tatulli E, 2017, INT CONF ACOUST SPEE, P2971, DOI 10.1109/ICASSP.2017.7952701
   Thabet Z, 2018, PROCEEDINGS OF 2018 FIRST INTERNATIONAL WORKSHOP ON DEEP AND REPRESENTATION LEARNING (IWDRL), P19, DOI 10.1109/IWDRL.2018.8358210
   Thein T, 2018, CONFERENCE PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON INFORMATION AND COMPUTER TECHNOLOGIES (ICICT), P123, DOI 10.1109/INFOCT.2018.8356854
   Torfi A, 2017, IEEE ACCESS, V5, P22081, DOI 10.1109/ACCESS.2017.2761539
   Travieso CM, 2019, APPL INTELL, V49, P1823, DOI 10.1007/s10489-018-1352-6
   Travieso CM, 2014, IMAGE VISION COMPUT, V32, P1080, DOI 10.1016/j.imavis.2014.10.001
   Travieso CM, 2011, NEUROCOMPUTING, V74, P2407, DOI 10.1016/j.neucom.2011.03.012
   Tresadern P, 2013, IEEE PERVAS COMPUT, V12, P79, DOI 10.1109/MPRV.2012.54
   TSUCHIHASHI Y, 1974, FORENSIC SCI, V3, P233, DOI 10.1016/0300-9432(74)90034-X
   WANG H, 2021, JASA EXPRESS LETT, V1
   Wang SW, 2007, I C WIREL COMM NETW, P763, DOI 10.1109/SITIS.2007.37
   Wang SL, 2007, PATTERN RECOGN, V40, P3481, DOI 10.1016/j.patcog.2007.03.016
   Wang SL, 2012, PATTERN RECOGN, V45, P3328, DOI 10.1016/j.patcog.2012.02.016
   Wang SL, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P101
   Wang SL, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P529
   Wang SL, 2002, INT CONF ACOUST SPEE, P1077
   Wark T, 1998, INT CONF ACOUST SPEE, P3693, DOI 10.1109/ICASSP.1998.679685
   Wark T, 2000, INT CONF ACOUST SPEE, P2389, DOI 10.1109/ICASSP.2000.859322
   Wright C, 2020, EURASIP J INF SECUR, V2020, DOI 10.1186/s13635-020-0102-6
   Wright C, 2020, LECT NOTES COMPUT SC, V11844, P405, DOI 10.1007/978-3-030-33720-9_31
   Wrobel K, 2018, PATTERN RECOGN, V81, P585, DOI 10.1016/j.patcog.2018.04.030
   Wrobel K, 2017, ENG APPL ARTIF INTEL, V64, P112, DOI 10.1016/j.engappai.2017.06.003
   Wrobel K, 2015, LECT NOTES ARTIF INT, V9012, P72, DOI 10.1007/978-3-319-15705-4_8
   Wrobel K, 2013, 2013 INTERNATIONAL CONFERENCE ON BIOMETRICS AND KANSEI ENGINEERING (ICBAKE), P47, DOI 10.1109/ICBAKE.2013.10
   Yazdi MZ, 2019, MULT DIG PUBL I P, V27, P22
   Yuanyao Lu, 2020, Advances in Human Factors and Systems Interaction. Proceedings of the AHFE 2020 Virtual Conference on Human Factors and Systems Interaction. Advances in Intelligent Systems and Computing (AISC 1207), P250, DOI 10.1007/978-3-030-51369-6_34
   Zhang J., IEEE ACCESS, VPP, P1
   Zhang X, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P226, DOI 10.1109/ICIP.2000.899336
   Zhao GY, 2009, IEEE T MULTIMEDIA, V11, P1254, DOI 10.1109/TMM.2009.2030637
   Zhu ZY, 2013, INT CONF MACH LEARN, P973, DOI 10.1109/ICMLC.2013.6890423
NR 166
TC 8
Z9 9
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3831
EP 3865
DI 10.1007/s11042-021-11613-5
EA NOV 2021
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000722157500002
DA 2024-07-18
ER

PT J
AU Vidhya, R
   Brindha, M
AF Vidhya, R.
   Brindha, M.
TI A novel approach for Chaotic image Encryption based on block level
   permutation and bit-wise substitution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; BNT; Diffusion; Key generation; Crown graph
ID COMBINATION; SYSTEM
AB Digital multimedia information is frequently transferred over the Internet due to its widespread usage. A novel Butterfly Network Topology (BNT) based block-level permutation ((BLP)-L-2) and Crown Graph-based Bit-wise Substitution (CGBS) is proposed in this work to securely transfer images over untrusted networks, such as social networks. First, a plain image related initial vector generation is suggested to obtain good plain image sensitivity to withstand chosen/known plain text attacks. Using these initial vectors, Henon map is iterated to produce the random key sequence values to be utilized over the confusion and diffusion processes. Second, BNT based block-level scrambling is proposed by which the plain image is transformed into blocks to attain the block level confused image. Additionally, simple sorting based confusion is applied to obtain the final confused image. Third, crown graph-based bit-wise diffusion is proposed to attain the final encrypted image. General security measures are carried out for the proposed method to validate its security level. It is shown from the simulations that the suggested approach has good randomness, high key sensitivity, good key space, and flat cipher image pixel distribution. Differential cryptanalysis for the proposed system is also conducted to show its efficacy against differential attacks.
C1 [Vidhya, R.] Vellore Inst Technol, Sch Comp Sci & Engn, Dept IOT, Vellore, Tamil Nadu, India.
   [Brindha, M.] Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; National Institute
   of Technology (NIT System); National Institute of Technology
   Tiruchirappalli
RP Brindha, M (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli, Tamil Nadu, India.
EM brindham@nitt.edu
CR Abdulla A. A., 2015, Ph.D. dissertation
   Ali TS, 2020, MULTIMED TOOLS APPL, V79, P19853, DOI 10.1007/s11042-020-08850-5
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Babaei A, 2020, OPTIK, V203, DOI 10.1016/j.ijleo.2019.164000
   Biswas P, 2020, MULTIMED TOOLS APPL, V79, P31715, DOI 10.1007/s11042-020-09497-y
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Dalhoum A, 2012, IEEE MULTIMEDIA
   Diaconu AV, 2016, INFORM SCIENCES, V355, P314, DOI 10.1016/j.ins.2015.10.027
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P8759, DOI 10.1007/s11042-017-4772-0
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Huang LQ, 2019, OPT LASER ENG, V115, P7, DOI 10.1016/j.optlaseng.2018.11.015
   Kahan W., 1996, Lect. Not. Status IEEE 754 (94720-1776), V754, P94720
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Kocarev L., 2001, IEEE CIRC SYST MAG, V1, P6, DOI DOI 10.1109/7384.963463
   Li PY, 2018, IEEE T MULTIMEDIA, V20, P1960, DOI 10.1109/TMM.2017.2786860
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu HJ, 2020, OPTIK, V216, DOI 10.1016/j.ijleo.2020.164925
   Murugan B, 2016, IET COMPUT VIS, V10, P593, DOI 10.1049/iet-cvi.2015.0344
   Parvaz R, 2018, OPT LASER TECHNOL, V101, P30, DOI 10.1016/j.optlastec.2017.10.024
   Ping P, 2018, NEUROCOMPUTING, V283, P53, DOI 10.1016/j.neucom.2017.12.048
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Rukhin Andrew L., 2001, A statistical test suite for random and pseudorandom number generators for cryptographic applications, V22
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wang J, 2021, MULTIMED TOOLS APPL, V80, P16087, DOI 10.1007/s11042-020-10413-7
   Wang T, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106355
   Wang XY, 2016, NONLINEAR DYNAM, V84, P1417, DOI 10.1007/s11071-015-2579-y
   Wang Y, 2015, COMPUT ELECTR ENG, V46, P433, DOI 10.1016/j.compeleceng.2015.03.011
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yavuz E, 2019, OPT LASER TECHNOL, V114, P224, DOI 10.1016/j.optlastec.2019.01.043
   Zahmoul R, 2017, OPT LASER ENG, V96, P39, DOI 10.1016/j.optlaseng.2017.04.009
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P6647, DOI 10.1007/s11042-017-4577-1
NR 38
TC 2
Z9 2
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3735
EP 3772
DI 10.1007/s11042-021-11720-3
EA NOV 2021
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000721460000002
DA 2024-07-18
ER

PT J
AU Halgamuge, MN
   Guruge, D
AF Halgamuge, Malka N.
   Guruge, Dilmi
TI Fair rewarding mechanism in music industry using smart contracts on
   public-permissionless blockchain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Smart contracts; Permissionless; Music industry; Illegal
   music file resources; Music file requesters; Community network;
   Networking cost; Transaction fee; Incentive fee
AB We develop smart contracts on public-permissionless blockchain to protect the music industry from the consequences of illegal downloading of copyright-protected music files. We develop a decentralized music file-sharing platform, where music file owners can upload the music files, and music file requesters can download the music files. We also establish a fair rewarding mechanism for the music industry for the benefit of music file owners, where music files can be traded through smart contracts between the music file owners and file requesters. Further, we implement a penalty scheme to avoid malicious and illegal music file resources to be added to the community network. This approach is ideal for addressing the problem of illegal distribution of copyright-protected music files without the consent of the owners, which has negative consequences in the music industry. This model considers a community of people networked together, where music file owners can upload their music files to a community network server on approval of the majority of the community and the file requesters can request a paid download from the community network. Music file uploading and downloading transactions are voted and signed by the online community members. All parties are rewarded with an incentive fee per valid transaction. Transactions are handled through self-executing smart contracts. This model further analyzes the costs incurred in music file uploading and downloading transactions based on the uploading/downloading cost, the transaction fee and the networking cost. Perceiving the significance of the smart contract in the music industry, we determine that the effect of illegal downloading of copyright-protected music files can be reduced. We also emphasize the challenges associated with the adoption of the smart contract. Since blockchain interoperability is yet an issue, migrating applications in a heterogeneous network or between platforms can be costly and tedious, which should be further explored in the future. Adapting the proposed architecture for private-permissioned blockchain (Hyperledger Fabric and Libra by Facebook, R3 Corda) and could be a natural extension of this work.
C1 [Halgamuge, Malka N.] Univ Melbourne, Dept Elect & Elect Engn, Parkville, Vic 3010, Australia.
   [Guruge, Dilmi] Nikee Business Grp, Melbourne, Vic 3000, Australia.
C3 University of Melbourne
RP Halgamuge, MN (corresponding author), Univ Melbourne, Dept Elect & Elect Engn, Parkville, Vic 3010, Australia.
EM malka.nisha@unimelb.edu.au
RI Halgamuge, Malka N./JED-4373-2023; Halgamuge, Malka N./ABD-7747-2021;
   Halgamuge, Malka N./JZE-1722-2024
OI Halgamuge, Malka N./0000-0001-9994-3778; Halgamuge, Malka
   N./0000-0001-9994-3778; Halgamuge, Malka N./0000-0001-9994-3778
CR Alphand O, 2018, IEEE WCNC
   [Anonymous], 2019, BINANCE WHITEPAPER
   [Anonymous], 2018, INTR HYP
   [Anonymous], 2019, INTRO LIBRA WHITE PA
   Brown, 2019, CORDA DISTRIBUTED LE
   Buterin V., 2014, CISC VIS NETW IND GL, V3, DOI DOI 10.5663/APS.V1I1.10138
   Coelho I. M., 2019, Tech. Rep.
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Ekanayake OAS, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102523
   EOS, 2017, IO technical white paper
   Gu K, 2019, IEEE ACCESS, V7, P43666, DOI 10.1109/ACCESS.2019.2908627
   Halgamuge MN, 2020, 2020 IEEE THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE 2020), P162, DOI 10.1109/AIKE48582.2020.00032
   Han D, 2020, ENERGY, V199, DOI 10.1016/j.energy.2020.117417
   Hoskinson Charles, 2017, Why we are building Cardano
   Khatoon A, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010094
   Lee MJ, 2007, IEEE T CONSUM ELECTR, V53, P454, DOI 10.1109/TCE.2007.381715
   Levi S., 2018, HARVARD LAW SCH FORU
   Lisi A, 2020, 2020 THE 3RD INTERNATIONAL CONFERENCE ON BLOCKCHAIN TECHNOLOGY AND APPLICATIONS, ICBTA 2020, P67, DOI 10.1145/3446983.3446993
   Lisi A, 2021, FUTURE GENER COMP SY, V120, P36, DOI 10.1016/j.future.2021.02.003
   Liu XL, 2019, FUTURE GENER COMP SY, V100, P590, DOI 10.1016/j.future.2019.05.042
   Nakamoto S., 2008, DECENT BUS REV, V21260, DOI https://bitcoin.org/bitcoin.pdf
   Patsonakis C, 2020, IEEE T ENG MANAGE, V67, P1425, DOI 10.1109/TEM.2020.2972638
   Poon J., 2017, PLASMA SCALABLE AUTO, P1
   Shrestha B., 2020, USING BLOCKCHAIN ONL, P289
   Teutsch J., 2019, ARXIV PREPRINT ARXIV
   Ujo Music, 2015, REB MUS IND BLOCKCH
   Wang SP, 2019, IEEE ACCESS, V7, P115122, DOI 10.1109/ACCESS.2019.2935873
   Wood G, 2020, POLKADOT VISION HETE
   Zhang YY, 2019, IEEE INTERNET THINGS, V6, P1594, DOI 10.1109/JIOT.2018.2847705
   Zhang ZH, 2018, LECT NOTES COMPUT SC, V10974, P32, DOI 10.1007/978-3-319-94478-4_3
NR 30
TC 8
Z9 8
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 1523
EP 1544
DI 10.1007/s11042-021-11078-6
EA OCT 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000703870600001
DA 2024-07-18
ER

PT J
AU Dash, AK
   Mohapatra, P
AF Dash, Amiya Kumar
   Mohapatra, Puspanjali
TI A Fine-tuned deep convolutional neural network for chest radiography
   image classification on COVID-19 cases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Radiography images; Convolutional neural network; Transfer learning
AB The outbreak of coronavirus disease 2019 (COVID-19) continues to have a catastrophic impact on the living standard of people worldwide. To fight against COVID-19, many countries are using a combination of containment and mitigation activities. Effective screening of contaminated patients is a critical step in the battle against COVID-19. During the early medical examination, it was observed that patient having abnormalities in chest radiography images shows the symptoms of COVID-19 infection. Motivated by this, in this article, we proposed a unique framework to diagnose the COVID-19 infection. Here, we removed the fully connected layers of an already proven model VGG-16 and placed a new simplified fully connected layer set that is initialized with some random weights on top of this deep convolutional neural network, which has already learned discriminative features, namely, edges, colors, geometric changes,shapes, and objects. To avoid the risk of destroying the rich features, we warm up our FC head by seizing all layers in the body of our network and then unfreeze all the layers in the network body to be fine-tuned.The suggested classification model achieved an accuracy of 97.12% with 99.2% sensitivity and 99.6% specificity for COVID-19 identification. This classification model is superior to the other classification model used to classify COVID-19 infected patients.
C1 [Dash, Amiya Kumar; Mohapatra, Puspanjali] IIIT Bhubaneswar, Bhubaneswar, Odisha, India.
C3 International Institute of Information Technology, Bhubaneswar
RP Dash, AK (corresponding author), IIIT Bhubaneswar, Bhubaneswar, Odisha, India.
EM dash.amiya.k@gmail.com; puspanjali@iiit-bh.ac.in
CR Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Baliarsingh SK, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105773
   Bernheim A, 2020, RADIOLOGY 200463
   Cohen JP, 2020, COVID 19 IMAGE DATA, DOI 10.59275/j.melba.2020-48g7
   Dorj UO, 2018, MULTIMED TOOLS APPL, V77, P9909, DOI 10.1007/s11042-018-5714-1
   Gozes O., ARXIV PREPRINT ARXIV
   Guan W, 2020, NEW ENGL J MED, V382, P1708, DOI 10.1056/NEJMoa2002032
   Hemdan E. E.- D., 2020, . arXiv preprint arXiv:2003.11055
   Huang CL, 2020, LANCET, V395, P497, DOI [10.1016/S0140-6736(20)30183-5, 10.1016/S0140-6736(20)30211-7]
   Hussain S, 2020, ADV ENV ENG GREEN TE, P1, DOI 10.4018/978-1-7998-2197-7.ch001
   Izonin I, 2019, LECT NOTES COMPUT SC, V11506, P467, DOI 10.1007/978-3-030-20521-8_39
   Lorente E, 2020, COVID 19 PNEUMONIA E
   Mooney P, 2020, Chest x-ray images (pneumonia)
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   Ng MY, 2020, RADIOL-CARDIOTHORAC, V2, DOI 10.1148/ryct.2020200034
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Pannu HS, 2020, MULTIMED TOOLS APPL, V79, P21941, DOI 10.1007/s11042-020-08905-7
   Rehman A, 2021, MULTIMED TOOLS APPL, V80, P30321, DOI 10.1007/s11042-020-09592-0
   Roosa K, 2020, INFECT DIS MODEL, V5, P256, DOI 10.1016/j.idm.2020.02.002
   Sethy PK, 2020, INT J MATH ENG MANAG, V5, P643, DOI 10.33889/IJMEMS.2020.5.4.052
   Tkachenko Roman, 2019, Advances in Computer Science for Engineering and Education. Advances in Intelligent Systems and Computing (AISC 754), P112, DOI 10.1007/978-3-319-91008-6_12
   Tkachenko Roman, 2019, Advances in Computer Science for Engineering and Education. Advances in Intelligent Systems and Computing (AISC 754), P578, DOI 10.1007/978-3-319-91008-6_58
   Tkachenko R, 2018, STUD COMPUT INTELL, V730, P537, DOI 10.1007/978-3-319-63754-9_25
   Udugama B, 2020, ACS NANO, V14, P3822, DOI 10.1021/acsnano.0c02624
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Wang S, 2021, EUR RADIOL, V31, P6096, DOI [10.1080/1064119X.2021.1966557, 10.1079/9781789246070.0001, 10.1007/s00330-021-07715-1]
   Wang Wenling, 2020, JAMA, V323, P1843, DOI 10.1001/jama.2020.3786
NR 27
TC 9
Z9 9
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 1055
EP 1075
DI 10.1007/s11042-021-11388-9
EA SEP 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000698048600002
PM 34566470
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Garnaik, S
   Pradhan, G
   Sethi, K
AF Garnaik, Sarmila
   Pradhan, Gayadhar
   Sethi, Kabiraj
TI An approach for reducing pitch induced mismatches to detect keywords in
   children's speech
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vowel; Non-vowel; Non-uniform filtering; Pitch-mismatch; Keyword
   spotting
ID EFFICIENT HARDWARE ARCHITECTURE; VOWEL-LIKE REGIONS; SPEAKER
   VERIFICATION; OFFSET POINTS; ONSET; NORMALIZATION; RECOGNITION;
   INFORMATION
AB Keyword spotting (KWS) is the task of detecting some specific words of interest in a text or speech signal. The intention or context of a conversation posted on different social platforms can be predicted by detecting the keywords. KWS in continuous speech is challenging due to variation in pitch, speaking rate of the speakers and environment-induced mismatches between training and testing speech. This paper proposes an approach for penalizing the pitch effect on the short-term Fourier transform magnitude spectra (STFT-MS) to reduce the pitch effect on the most frequently used Mel-frequency cepstral coefficient (MFCC) feature for the development of KWS system. To achieve this, we have employed moving average filtering of STFT-MS over different frequency windows for vowel and non-vowel frames. The validity of the proposed spectral filtering approach is verified by analyzing the pitch effect on filtered STFT-MS and evaluating keyword spotting performances without and with vocal-tract length normalization and data-augmented training through explicit pitch modification. The MFCC extracted from the filtered spectra is less affected by pitch, which enhances the keyword spotting performance in pitch-mismatch test cases without loss of performance in match test cases.
C1 [Garnaik, Sarmila; Sethi, Kabiraj] Veer Surendra Sai Univ Technol, Burla, Odisha, India.
   [Pradhan, Gayadhar] Natl Inst Technol Patna, Patna, Bihar, India.
C3 Veer Surendra Sai University of Technology; National Institute of
   Technology (NIT System); National Institute of Technology Patna
RP Garnaik, S (corresponding author), Veer Surendra Sai Univ Technol, Burla, Odisha, India.
EM sgarnaik_eee@vssut.ac.in; gdp@nitp.ac.in; ksethi_etc@vssut.ac.in
OI Pradhan, Gayadhar/0000-0001-7385-6684
CR [Anonymous], 2005, P 14 ACM INT C INFOR
   [Anonymous], P 2 WORKSHOP CHILD C, DOI [DOI 10.1145/1640377.1640384, 10.1145/1640377.1640384]
   Batliner A, 2005, P 9 EUR C SPEECH COM, P1
   Cardillo P. S., 2002, International Journal of Speech Technology, V5, P9, DOI 10.1023/A:1013670312989
   Chen GG, 2013, INT CONF ACOUST SPEE, P8560, DOI 10.1109/ICASSP.2013.6639336
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Dubois C, 2008, INT CONF ACOUST SPEE, P4961, DOI 10.1109/ICASSP.2008.4518771
   Garofolo John, 1993, TIMIT ACOUSTIC PHONE
   HERMES DJ, 1990, J ACOUST SOC AM, V87, P866, DOI 10.1121/1.398896
   Kumar A, 2018, ELECTRON LETT, V54, P722, DOI 10.1049/el.2018.0629
   Kumar A, 2017, INTERSPEECH, P429, DOI 10.21437/Interspeech.2017-624
   Kumari K, 2020, SOFT COMPUT, V24, P11059, DOI 10.1007/s00500-019-04550-x
   Lee L, 1998, IEEE T SPEECH AUDI P, V6, P49, DOI 10.1109/89.650310
   Lee S, 1999, J ACOUST SOC AM, V105, P1455, DOI 10.1121/1.426686
   Mittal VK, 2014, J ACOUST SOC AM, V136, P1932, DOI 10.1121/1.4894789
   Motlicek P, 2012, INT CONF ACOUST SPEE, P4413, DOI 10.1109/ICASSP.2012.6288898
   Narayanan S, 2002, IEEE T SPEECH AUDI P, V10, P65, DOI 10.1109/89.985544
   Pattanayak B, 2019, IET SIGNAL PROCESS, V13, P544, DOI 10.1049/iet-spr.2019.0027
   Paul S, 2022, MULTIMED TOOLS APPL, V81, P26989, DOI 10.1007/s11042-020-09631-w
   Potamianos A, 2003, IEEE T SPEECH AUDI P, V11, P603, DOI 10.1109/TSA.2003.818026
   Povey D., 2011, IEEE 2011 WORKSH AUT
   Pradhan G, 2017, INTERSPEECH, P1884, DOI 10.21437/Interspeech.2017-135
   Pradhan G, 2013, IEEE T AUDIO SPEECH, V21, P854, DOI 10.1109/TASL.2013.2238529
   Prasanna S. R. M., 2010, SPEECH PROSODY 2010, P1
   Prasanna SRM, 2011, IEEE T AUDIO SPEECH, V19, P2552, DOI 10.1109/TASL.2011.2155061
   Prasanna SRM, 2009, IEEE T AUDIO SPEECH, V17, P556, DOI 10.1109/TASL.2008.2010884
   Rao KS, 2009, SPEECH COMMUN, V51, P1263, DOI 10.1016/j.specom.2009.06.004
   Rath SP, 2013, INTERSPEECH, P109
   ROBINSON T, 1995, INT CONF ACOUST SPEE, P81, DOI 10.1109/ICASSP.1995.479278
   Sai BT, 2018, INT CO SIG PROC COMM, P242, DOI 10.1109/SPCOM.2018.8724416
   Shahnawazuddin S, 2019, DIGIT SIGNAL PROCESS, V86, P11, DOI 10.1016/j.dsp.2018.12.011
   Shahnawazuddin S, 2018, DIGIT SIGNAL PROCESS, V79, P142, DOI 10.1016/j.dsp.2018.05.003
   Shahnawazuddin S, 2017, INT CONF ACOUST SPEE, P5225, DOI 10.1109/ICASSP.2017.7953153
   Shahnawazuddin S, 2017, IEEE SIGNAL PROC LET, V24, P1128, DOI 10.1109/LSP.2017.2705085
   Sinha R, 2018, COMPUT SPEECH LANG, V48, P103, DOI 10.1016/j.csl.2017.10.007
   Smídl L, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1894
   Srinivas N, 2019, MICROSYST TECHNOL, V25, P1333, DOI 10.1007/s00542-018-4192-8
   Srinivas N, 2018, INTEGRATION, V63, P185, DOI 10.1016/j.vlsi.2018.07.005
   Stevens K. N., 2000, Acoustic phonetics, V30
   Tabibian S, 2018, INFORM SCIENCES, V423, P157, DOI 10.1016/j.ins.2017.09.052
   Thambiratnam Albert JK, 2005, THESIS QUEENSLAND U
   Vuppala AK, 2012, AEU-INT J ELECTRON C, V66, P697, DOI 10.1016/j.aeue.2011.12.013
   Vuppala AK, 2012, IEEE T AUDIO SPEECH, V20, P1894, DOI 10.1109/TASL.2012.2191284
   Wallace RG, 2007, PHONETIC SEARCH APPR, P1
   Wang D, 2008, INT CONF ACOUST SPEE, P4969
   WANG JF, 1991, IEEE T SIGNAL PROCES, V39, P2141, DOI 10.1109/78.134458
   Wegmann S, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P192, DOI 10.1109/ASRU.2013.6707728
   Yadav IC, 2019, IEEE SIGNAL PROC LET, V26, P1822, DOI 10.1109/LSP.2019.2950763
   Yadav IC, 2018, INTERSPEECH, P1601, DOI 10.21437/Interspeech.2018-1828
   Yadav IC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5629, DOI 10.1109/ICASSP.2018.8462133
NR 50
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27057
EP 27071
DI 10.1007/s11042-021-11243-x
EA SEP 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000696465800004
DA 2024-07-18
ER

PT J
AU Wei, WY
   Wang, WR
   Yang, YJ
   Wang, Y
AF Wei, Weiyi
   Wang, Wanru
   Yang, Yijing
   Wang, Yu
TI A novel color image retrieval method based on texture and deep features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image retrieval; Second-order full-directional derivative;
   Quaternion; Moment invariant; Convolutional neural network
AB Enlightened by the currently prevalent great complementarity of traditional features and deep features in image content expression, we propose a novel color image retrieval method based on texture and deep features which represent the image with the combination of HOG histogram, Hu invariable moments and deep features. Firstly, HOG features based on local binary pattern are extracted from the image using the proposed second-order full-directional derivative, which can express more gradient information through simplification the expression method of full-directional derivative. Meanwhile, considering that the combination of information entropy and color can better represent the image content, we propose a novel quaternion expression method for color image and calculate its Hu moment features, which represent color image in a simple way by combination of color and texture information. Secondly, we extract deep features from an improved VGG network structure. Finally, the hybrid features combining HOG histogram, the new Hu moments and deep information are used to represent a color image and to perform retrieve task. In order to prove the effectiveness of our method, three common databases (INRIA Holidays, Oxford 5 K and UKB) are used to prove the proposed algorithm. Experimental results show that the proposed scheme has better performance on the basis of lower feature dimension.
C1 [Wei, Weiyi; Wang, Wanru; Yang, Yijing; Wang, Yu] Northwest Normal Univ, Coll Comp Sci & Engn, Lanzhou 730070, Gansu, Peoples R China.
C3 Northwest Normal University - China
RP Wang, WR (corresponding author), Northwest Normal Univ, Coll Comp Sci & Engn, Lanzhou 730070, Gansu, Peoples R China.
EM 863789543@qq.com
RI wei, weiyi/ABB-2844-2021; yang, yijing/JWO-8234-2024; wei,
   weiyi/JPL-6353-2023; zhen, wang/KBA-3844-2024; Zhao, ZiHao/KHT-4413-2024
OI Wang, Wanru/0000-0002-3259-9922
FU National Natural Science Foundation of China [61,861,040]; Natural
   Science Foundation of Gansu Province [20JR5RA518]
FX This work was supported by National Natural Science Foundation of China
   (Grant 61,861,040), Natural Science Foundation of Gansu Province
   (20JR5RA518).
CR Ahmed KT, 2019, INFORM FUSION, V51, P76, DOI 10.1016/j.inffus.2018.11.004
   Ali A, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P1048, DOI 10.1109/ICCONS.2017.8250625
   Anandh A, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING TECHNOLOGIES AND INTELLIGENT DATA ENGINEERING (ICCTIDE'16)
   [Anonymous], 2018, COMPUT ENGINE DESIGN
   Bagri N., 2015, International Journal of Advanced Science and Technology, V80, P41
   Banerjee I, 2018, J BIOMED INFORM, V84, P123, DOI 10.1016/j.jbi.2018.07.002
   Choobari BM, 2017, 2017 5TH IRANIAN JOINT CONGRESS ON FUZZY AND INTELLIGENT SYSTEMS (CFIS), P178, DOI 10.1109/CFIS.2017.8003679
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   [高攀 Gao Pan], 2018, [中国图象图形学报, Journal of Image and Graphics], V23, P1024
   Gordo A, 2017, INT J COMPUT VISION, V124, P237, DOI 10.1007/s11263-017-1016-8
   Gupta M, 2018, PROCEDIA COMPUT SCI, V125, P143, DOI 10.1016/j.procs.2017.12.020
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P29099, DOI 10.1007/s11042-018-6122-2
   Jiang Ju-lang, 2006, Acta Electronica Sinica, V34, P861
   Li CR, 2017, PATTERN RECOGN, V64, P118, DOI 10.1016/j.patcog.2016.10.030
   [李康 Li Kang], 2018, [电子学报, Acta Electronica Sinica], V46, P2087
   [李姗姗 Li Shanshan], 2017, [中国图象图形学报, Journal of Image and Graphics], V22, P915
   Li Y, 2017, IEEE SIGNAL PROC LET, V24, P609, DOI 10.1109/LSP.2017.2665522
   Liu PZ, 2017, IEEE T IMAGE PROCESS, V26, P5706, DOI 10.1109/TIP.2017.2736343
   Liu ZH, 2017, NEURAL PROCESS LETT, V45, P913, DOI 10.1007/s11063-016-9550-x
   Nister David, 2006, CVPR
   Popa CA, 2018, NEUROCOMPUTING, V309, P117, DOI 10.1016/j.neucom.2018.05.004
   Sathiamoorthy S., 2019, INT J RECENT TECHNOL, V8, P5584, DOI [10.35940/ijrte.c5567.098319, DOI 10.35940/IJRTE.C5567.098319]
   Seddati O, 2017, IEEE INT CONF COMP V, P1246, DOI 10.1109/ICCVW.2017.150
   Shabat AMM, 2018, IET COMPUT VIS, V12, P603, DOI 10.1049/iet-cvi.2017.0340
   Somnugpong S, 2016, INT JOINT CONF COMP, P417
   Sun JD, 2005, J INFRARED MILLIM W, V24, P135
   Trichet R, 2018, IEEE WINT CONF APPL, P1066, DOI 10.1109/WACV.2018.00122
   Varish N, 2020, IEEE ACCESS, V8, P117639, DOI 10.1109/ACCESS.2020.3003911
   Wang Y, 2017, IEEE INT SYM MULTIM, P553, DOI 10.1109/ISM.2017.108
   Yang JF, 2018, IEEE T IMAGE PROCESS, V27, P5288, DOI 10.1109/TIP.2018.2845136
   Yang P, 2018, IEEE ACCESS, V6, P13336, DOI 10.1109/ACCESS.2018.2797072
   [张春艳 Zhang Chunyan], 2018, [计算机应用, Journal of Computer Applications], V38, P539
   Zhang YP, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P379, DOI 10.1109/CISP-BMEI.2016.7852740
   Zhang Y, 2018, IEEE T IMAGE PROCESS, V27, P5113, DOI 10.1109/TIP.2018.2851390
   Zhi TC, 2016, IEEE IMAGE PROC, P2465, DOI 10.1109/ICIP.2016.7532802
   Zou Binyi, 2018, Computer Engineering, V44, P241, DOI 10.3969/j.issn.1000-3428.2018.03.040
NR 37
TC 7
Z9 7
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 659
EP 679
DI 10.1007/s11042-021-11198-z
EA SEP 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000695787100002
DA 2024-07-18
ER

PT J
AU Ahmadi, Z
   Kashani, MH
   Nikravan, M
   Mahdipour, E
AF Ahmadi, Zahra
   Haghi Kashani, Mostafa
   Nikravan, Mohammad
   Mahdipour, Ebrahim
TI Fog-based healthcare systems: A systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Healthcare; Fog computing; eHealth; Systematic review
ID REAL-TIME; BIG DATA; PRIVACY; IOT; ARCHITECTURE; CHALLENGES; SECURITY;
   INTERNET; DEFENSE; MODEL
AB The healthcare system aims to provide a reliable and organized solution to enhance the health of human society. Studying the history of patients can help physicians to consider patients' needs in healthcare system designing and offering service, which leads to an increase in patient satisfaction. Therefore, healthcare is becoming a growing contesting market. With this significant growth in healthcare systems, such challenges as huge data volume, response time, latency, and security vulnerability are raised. Therefore, fog computing, as a well-known distributed architecture, could help to solve such challenges. In fog computing architecture, processing components are placed between the end devices and cloud components, and they execute applications. This architecture is suitable for such applications as healthcare systems that need a real-time response and low latency. In this paper, a systematic review of available approaches in the field of fog-based healthcare systems is proposed; the challenges of its application in healthcare are explored, classified, and discussed. First, the fog computing approaches in healthcare are categorized into three main classes: communication, application, and resource/service. Then, they are discussed and compared based on their tools, evaluation methods, and evaluation metrics. Finally, based on observations, some open issues and challenges are highlighted for further studies in fog-based healthcare.
C1 [Ahmadi, Zahra; Haghi Kashani, Mostafa; Mahdipour, Ebrahim] Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
   [Haghi Kashani, Mostafa; Nikravan, Mohammad] Islamic Azad Univ, Shahr E Qods Branch, Dept Comp Engn, Tehran, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Nikravan, M (corresponding author), Islamic Azad Univ, Shahr E Qods Branch, Dept Comp Engn, Tehran, Iran.
EM m.nikravan@qodsiau.ac.ir
RI Haghi Kashani, Mostafa/AAO-4921-2021
OI Haghi Kashani, Mostafa/0000-0002-9812-1331
CR Abkenar SB, 2021, TELEMAT INFORM, V57, DOI 10.1016/j.tele.2020.101517
   Acampora G, 2013, P IEEE, V101, P2470, DOI 10.1109/JPROC.2013.2262913
   Ahmed A, 2018, MULTIMED TOOLS APPL, V77, P21947, DOI 10.1007/s11042-017-5540-x
   Akrivopoulos O, 2017, P INT COMP SOFTW APP, P288, DOI 10.1109/COMPSAC.2017.178
   Al Hamid HA, 2017, IEEE ACCESS, V5, P22313, DOI 10.1109/ACCESS.2017.2757844
   Al-Janabi S, 2017, EGYPT INFORM J, V18, P113, DOI 10.1016/j.eij.2016.11.001
   Al-khafajiy M, 2018, ICFNDS'18: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON FUTURE NETWORKS AND DISTRIBUTED SYSTEMS, DOI 10.1145/3231053.3231062
   Alesanco A, 2010, IEEE T INF TECHNOL B, V14, P1144, DOI 10.1109/TITB.2010.2047650
   Alimorad N, 2021, IEEE SENS J, V21, P19623, DOI 10.1109/JSEN.2021.3091768
   Asif-Ur-Rahman M, 2019, IEEE INTERNET THINGS, V6, P4049, DOI 10.1109/JIOT.2018.2876088
   Bazzaz Abkenar S, 2020, TWITTER SPAM DETECTI, P1
   Abkenar SB, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6381
   Bonomi Flavio, 2012, P 1 MCC WORKSH MOB C, P13, DOI 10.1145/2342509.2342513
   Brereton P, 2007, J SYST SOFTWARE, V80, P571, DOI 10.1016/j.jss.2006.07.009
   Catarinucci L, 2015, IEEE INTERNET THINGS, V2, P515, DOI 10.1109/JIOT.2015.2417684
   Cerina L., 2017, Research and Technologies for Society and Industry (RTSI), 2017 IEEE 3rd International Forum on, P1, DOI DOI 10.1109/RTSI.2017.8065939
   Chen M., 2017, Big Data and Cognitive Computing, V1, P2, DOI [DOI 10.3390/BDCC1010002, 10.3390/bdcc1010002]
   Chenthara S, 2019, IEEE ACCESS, V7, P74361, DOI 10.1109/ACCESS.2019.2919982
   da Silva CA, 2018, IEEE SYMP COMP COMMU, P1131
   Dar BK, 2019, IEEE ACCESS, V7, P70975, DOI 10.1109/ACCESS.2019.2910862
   Darwish A, 2019, J AMB INTEL HUM COMP, V10, P4151, DOI 10.1007/s12652-017-0659-1
   Dastjerdi AV, 2016, COMPUTER, V49, P112, DOI 10.1109/MC.2016.245
   Devarajan M, 2019, J AMB INTEL HUM COMP, V10, P3747, DOI 10.1007/s12652-019-01291-5
   Elmisery AM, 2016, IEEE ACCESS, V4, P8418, DOI 10.1109/ACCESS.2016.2631546
   Farahani B, 2020, MICROPROCESS MICROSY, V72, DOI 10.1016/j.micpro.2019.102938
   Farahani B, 2018, FUTURE GENER COMP SY, V78, P659, DOI 10.1016/j.future.2017.04.036
   Fathi M, 2022, ARCH COMPUT METHOD E, V29, P1247, DOI 10.1007/s11831-021-09616-4
   Fernando N, 2013, FUTURE GENER COMP SY, V29, P84, DOI 10.1016/j.future.2012.05.023
   Fettweis GP, 2014, IEEE VEH TECHNOL MAG, V9, P64, DOI 10.1109/MVT.2013.2295069
   Garg L, 2020, IEEE ACCESS, V8, P159402, DOI 10.1109/ACCESS.2020.3020513
   Gill SS, 2019, LECT NOTE DATA ENG, V26, P1376, DOI 10.1007/978-3-030-03146-6_161
   Giri D, 2017, IEEE GLOB COMM CONF
   Gupta V, 2018, J STAT MANAG SYST, V21, P529, DOI 10.1080/09720510.2018.1466961
   Haghi Kashani M., 2020, LOAD BALANCING MECH, P1
   Kashani MH, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4340
   He SQ, 2017, CHINA COMMUN, V14, P1, DOI 10.1109/CC.2017.8233646
   Hossain MS, 2016, IEEE ACCESS, V4, P7806, DOI 10.1109/ACCESS.2016.2626316
   Hosseinpour F, 2016, INT CONF CLOUD COMP, P468, DOI [10.1109/CloudCom.2016.0080, 10.1109/CloudCom.2016.77]
   Hu PF, 2017, J NETW COMPUT APPL, V98, P27, DOI 10.1016/j.jnca.2017.09.002
   Iorga Michaela, 2018, NIST Special Publication, DOI [10.6028/NIST.SP.500-325, DOI 10.6028/NIST.SP.500-325]
   Iuon-Chang Lin, 2017, International Journal of Network Security, V19, P653, DOI 10.6633/IJNS.201709.19(5).01
   Jia XY, 2019, WIREL NETW, V25, P4737, DOI 10.1007/s11276-018-1759-3
   Jit B, 2010, IEEE ENG MED BIO, P3860, DOI 10.1109/IEMBS.2010.5627906
   Jula A, 2014, EXPERT SYST APPL, V41, P3809, DOI 10.1016/j.eswa.2013.12.017
   Kale Siddharth, 2020, Proceedings of 6th International Conference on Big Data and Cloud Computing Challenges. ICBCC 2019. Smart Innovation, Systems and Technologies (SIST 164), P3, DOI 10.1007/978-981-32-9889-7_1
   Karimi Y, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6379
   Kashani MH, 2021, J NETW COMPUT APPL, V192, DOI 10.1016/j.jnca.2021.103164
   Kashani MH, 2017, 2017 IEEE 4TH INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P673, DOI 10.1109/KBEI.2017.8324882
   Khalid M, 2016, ADV COMPUTER COMMUNI, P1001
   Kharel J, 2019, IETE TECH REV, V36, P69, DOI 10.1080/02564602.2017.1406828
   Kim H, 2013, IEEE COMMUN MAG, V51, P114, DOI 10.1109/MCOM.2013.6461195
   Kitchenham Barbara, 2004, Joint Technical Report, V2004, P1
   Kraemer FA, 2017, IEEE ACCESS, V5, P9206, DOI 10.1109/ACCESS.2017.2704100
   Kumar S, 2018, PROG POLYM SCI, V80, P1, DOI 10.1016/j.progpolymsci.2018.03.001
   Kumari A, 2018, COMPUT ELECTR ENG, V72, P1, DOI 10.1016/j.compeleceng.2018.08.015
   Li H, 2015, IEEE CLOUD COMPUT, V2, P42, DOI 10.1109/MCC.2015.114
   Maadani M, 2019, TELECOMMUN SYST, V70, P159, DOI 10.1007/s11235-018-0482-9
   Maadani M, 2016, INT J COMMUN SYST, V29, P1720, DOI 10.1002/dac.2904
   Maadani M, 2014, IET COMMUN, V8, P1724, DOI 10.1049/iet-com.2013.0384
   Maadani M, 2014, WIRELESS PERS COMMUN, V75, P2243, DOI 10.1007/s11277-013-1465-5
   Mahmoud MM., 2019, 2019 INT C COMP INF, P1
   Mahmoud MME, 2018, COMPUT ELECTR ENG, V67, P58, DOI 10.1016/j.compeleceng.2018.02.047
   Mahmud R, 2018, ICDCN'18: PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING AND NETWORKING, DOI 10.1145/3154273.3154347
   Mehta N, 2018, INT J MED INFORM, V114, P57, DOI 10.1016/j.ijmedinf.2018.03.013
   Mohammed M., INTERJ PSYCHO REHAB, V24, P2296
   Movassaghi S, 2014, IEEE COMMUN SURV TUT, V16, P1658, DOI 10.1109/SURV.2013.121313.00064
   Mukherjee M, 2018, IEEE COMMUN SURV TUT, V20, P1826, DOI 10.1109/COMST.2018.2814571
   Nabati M, 2022, MOBILE NETW APPL, V27, P576, DOI 10.1007/s11036-021-01821-6
   Nasrallah S, 2022, J MATERN-FETAL NEO M, V35, P5970, DOI 10.1080/14767058.2021.1903426
   Nath SB., 2018, SURVEY FOG COMPUTING
   Natraj A., 2016, INT J ENG RES, V5, P1004
   Ng JHY, 2019, PATIENT EDUC COUNS, V102, P790, DOI 10.1016/j.pec.2018.11.013
   Ni JB, 2018, IEEE COMMUN SURV TUT, V20, P601, DOI 10.1109/COMST.2017.2762345
   Nikravan M, 2020, WIRELESS PERS COMMUN, V111, P463, DOI 10.1007/s11277-019-06869-y
   Nikravan M, 2019, PEER PEER NETW APPL, V12, P209, DOI 10.1007/s12083-018-0659-8
   Nikravan M, 2018, WIRELESS PERS COMMUN, V99, P1035, DOI 10.1007/s11277-017-5165-4
   Parasuraman S., 2018, Computational Intelligence for Multimedia Big Data on the Cloud With Engineering Applications, P253
   Peng MG, 2016, IEEE NETWORK, V30, P46, DOI 10.1109/MNET.2016.7513863
   Petticrew M, 2006, SYSTEMATIC REVIEWS IN THE SOCIAL SCIENCES: A PRACTICAL GUIDE, P1, DOI 10.1002/9780470754887
   Qi J, 2017, PERVASIVE MOB COMPUT, V41, P132, DOI 10.1016/j.pmcj.2017.06.018
   Rahimi M, 2020, J NETW COMPUT APPL, V153, DOI 10.1016/j.jnca.2020.102531
   Rahmani AM, 2018, FUTURE GENER COMP SY, V78, P641, DOI 10.1016/j.future.2017.02.014
   Rahouma K.H., 2020, SOCIAL INTERNET THIN, P13
   Saha R, 2019, IEEE ACCESS, V7, P44536, DOI 10.1109/ACCESS.2019.2908664
   Sajedi SN, 2022, J SUPERCOMPUT, V78, P1030, DOI 10.1007/s11227-021-03890-6
   Sajid A, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0509-2
   Santos MAG, 2020, INFORM FUSION, V53, P222, DOI 10.1016/j.inffus.2019.06.004
   Sarvizadeh R., 2012, INT J COMPUT APPL, V42, P1, DOI DOI 10.5120/5725-7792
   Selvaraj S, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-019-1925-y
   Shad MN, 2022, WIRELESS PERS COMMUN, V126, P2249, DOI 10.1007/s11277-021-09051-5
   Sofla MS, 2022, MULTIMED TOOLS APPL, V81, P1997, DOI 10.1007/s11042-021-11423-9
   Shi YJ, 2015, 2015 2ND INTERNATIONAL SYMPOSIUM ON FUTURE INFORMATION AND COMMUNICATION TECHNOLOGIES FOR UBIQUITOUS HEALTHCARE (UBI-HEALTH TECH)
   Singh RP, 2020, DIABETES METAB SYND, V14, P521, DOI 10.1016/j.dsx.2020.04.041
   Singh S, 2018, INT J PERVASIVE COMP, V14, P197, DOI 10.1108/IJPCC-D-18-00012
   SONGHORABADI M, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.1016/C2019-0-00478-5
   Sood SK, 2019, IEEE INTERNET THINGS, V6, P1920, DOI 10.1109/JIOT.2018.2871630
   Sood SK, 2018, IEEE INTERNET THINGS, V5, P794, DOI 10.1109/JIOT.2017.2768407
   Stavrinides GL, 2019, MULTIMED TOOLS APPL, V78, P24639, DOI 10.1007/s11042-018-7051-9
   Steele R, 2013, PERS UBIQUIT COMPUT, V17, P533, DOI 10.1007/s00779-012-0506-5
   Stojmenovic I, 2016, CONCURR COMP-PRACT E, V28, P2991, DOI 10.1002/cpe.3485
   Talaat FM, 2019, J NETW SYST MANAG, V27, P883, DOI 10.1007/s10922-019-09490-3
   Talal M, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1158-z
   Tao H, 2019, IEEE INTERNET THINGS, V6, P410, DOI 10.1109/JIOT.2018.2854714
   Thurston KH, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERECE ON CONNECTED HEALTH: APPLICATIONS, SYSTEMS AND ENGINEERING TECHNOLOGIES (CHASE), P51, DOI 10.1145/3278576.3278595
   Gia TN, 2015, CIT/IUCC/DASC/PICOM 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - UBIQUITOUS COMPUTING AND COMMUNICATIONS - DEPENDABLE, AUTONOMIC AND SECURE COMPUTING - PERVASIVE INTELLIGENCE AND COMPUTING, P356, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.51
   Tuli S, 2020, FUTURE GENER COMP SY, V104, P187, DOI 10.1016/j.future.2019.10.043
   Ullah A, 2020, PEER PEER NETW APPL, V13, P163, DOI 10.1007/s12083-019-00745-z
   Ullah A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON SMART INTERNET OF THINGS (SMARTIOT 2018), P166, DOI [10.1109/SmartIoT.2018.000-6, 10.1109/SmartIoT.2018.00038]
   Vijayakumar V, 2019, COMPUT HUM BEHAV, V100, P275, DOI 10.1016/j.chb.2018.12.009
   Vilela PH, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON SMART AND SUSTAINABLE TECHNOLOGIES (SPLITECH), P28
   Wadhwa H, 2018, IEEE INT SYMP PARAL, P987, DOI 10.1109/BDCloud.2018.00144
   Wang K, 2020, IEEE T NETW SCI ENG, V7, P263, DOI 10.1109/TNSE.2018.2859307
   Wang T, 2020, IEEE T IND INFORM, V16, P3531, DOI 10.1109/TII.2019.2920277
   Wazid M, 2019, FUTURE GENER COMP SY, V91, P475, DOI 10.1016/j.future.2018.09.017
   Yi S., 2015, P 2015 WORKSH MOB BI, P37, DOI [DOI 10.1145/2757384.2757397, 10.1145/2757384.2757397]
   Yi SH, 2015, 2015 THIRD IEEE WORKSHOP ON HOT TOPICS IN WEB SYSTEMS AND TECHNOLOGIES (HOTWEB), P73, DOI 10.1109/HotWeb.2015.22
   Yousefpour A, 2019, J SYST ARCHITECT, V98, P289, DOI 10.1016/j.sysarc.2019.02.009
   Zhang C, 2019, PEER PEER NETW, VAppl, P1
NR 118
TC 25
Z9 25
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2021
VL 80
IS 30
BP 36361
EP 36400
DI 10.1007/s11042-021-11227-x
EA SEP 2021
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XI4QI
UT WOS:000692489400003
PM 34512110
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Chen, H
   Zuo, YP
AF Chen, Hui
   Zuo, Yipeng
TI 3D-ARNet: An accurate 3D point cloud reconstruction network from a
   single-image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D Reconstruction; Point cloud; Two-stage training; Single view
   reconstruction
AB Generating a more realistic 3D reconstruction point cloud is an ill-posed problem. It is a challenging task to infer 3D shape from a single image. In this paper, a two-stage training network that can reconstruct point cloud from a single image is proposed, namely, 3D-ARNet. The 3D-ARNet uses the designed image encoder with an attention mechanism to extract image features and output a simple point cloud. To improve the accuracy of point cloud reconstruction, the 3D-ARNet network contains a pre-trained point cloud auto-encoder, which a takes simple point cloud as input, and finally obtains an accurately reconstructed point cloud. The proposed approach is analyzed qualitatively and quantitatively on both synthetic and real-world datasets. Improvements are evidently demonstrated from experimental comparison results in reference to existing related state-of-the-art networks.
C1 [Chen, Hui; Zuo, Yipeng] Shanghai Univ Elect Power, Coll Automat Engn, Shanghai 310027, Peoples R China.
C3 Shanghai University of Electric Power
RP Chen, H (corresponding author), Shanghai Univ Elect Power, Coll Automat Engn, Shanghai 310027, Peoples R China.
EM chenhui@shiep.edu.cn
RI Hui, .Chen/AER-3973-2022
OI Hui, .Chen/0000-0002-5386-4078
FU National Natural Science Foundation of China [51705304]; Natural Science
   Foundation of Shanghai [20ZR1421300]
FX This work was conducted during the research year of Shanghai University
   of Electric Power in 2020 and this work is supported by National Natural
   Science Foundation of China (Grant No. 51705304), Natural Science
   Foundation of Shanghai (Grant No. 20ZR1421300).
CR Achlioptas P, 2018, ICML
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   Chang Angel X., 2015, arXiv
   Choi S, 2019, IEEE IMAGE PROC, P2379, DOI [10.1109/ICIP.2019.8803350, 10.1109/icip.2019.8803350]
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Di X, 2017, 3D RECONSTRUCTION SI
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Fuentes-Pacheco J, 2015, ARTIF INTELL REV, V43, P55, DOI 10.1007/s10462-012-9365-8
   Gadelha M, 2017, INT CONF 3D VISION, P402, DOI 10.1109/3DV.2017.00053
   Girdhar R, 2016, LECT NOTES COMPUT SC, V9910, P484, DOI 10.1007/978-3-319-46466-4_29
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Haming K., 2010, KYBERNETIKA, V5
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurenkov A, 2018, IEEE WINT CONF APPL, P858, DOI 10.1109/WACV.2018.00099
   Lu Q, 2019, IEEE ACCESS, V7, P137420, DOI 10.1109/ACCESS.2019.2943235
   Mandikal P, 2018, 3D LMNET LATENT EMBE
   Navaneet KL, 2019, AAAI CONF ARTIF INTE, P8819
   Ramasinghe S, 2019, ABS191201800 ARXIV
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun R, 2019, IEEE ACCESS, V7, P82206, DOI 10.1109/ACCESS.2019.2923842
   Sun XY, 2018, PROC CVPR IEEE, P2974, DOI 10.1109/CVPR.2018.00314
   Tulsiani S, 2017, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.2017.30
   Wei Y, 2019, PROC CVPR IEEE, P9643, DOI 10.1109/CVPR.2019.00988
   Yan XC, 2016, ADV NEUR IN, V29
   Zhang SY, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4602
NR 29
TC 7
Z9 8
U1 10
U2 70
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12127
EP 12140
DI 10.1007/s11042-021-11433-7
EA SEP 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000692452100002
DA 2024-07-18
ER

PT J
AU Jawad, LM
AF Jawad, Lahieb Mohammed
TI A new scan pattern method for color image encryption based on 3D-Lorenzo
   chaotic map method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shuffling; Pattern scan; Chaotic map; Color image; Stream cipher
ID PERMUTATION
AB Securing the exchange of digital images in the form of huge multimedia data over the internet with limited bandwidth emerges as a significant and sensitive issue. In this paper, a new scan pattern method for protecting color image data based on the 3D-Lorenzo chaotic map method is proposed. The scan pattern method is used for generating three different masks one for each channel of colored image. These masks considered the position of the shuffling pixels which is used as input parameters to the 3D-Lorenzo chaotic map for ciphering the image in a new technique. The experimental results demonstrate that the developed method has the benefit of quick and secure protection of brute force attacks. Hence, the performance analysis of color image encryption reveals a correlation coefficient of almost (CC< 0.00036) and entropy greater than (7.9984). It can be seen that this method yields better security performance in comparison to the results obtained from other methods with a fast process.
C1 [Jawad, Lahieb Mohammed] AL Nahrain Univ, Dept Comp Networks Engn, Coll Informat Engn, Baghdad, Iraq.
C3 Al-Nahrain University
RP Jawad, LM (corresponding author), AL Nahrain Univ, Dept Comp Networks Engn, Coll Informat Engn, Baghdad, Iraq.
EM lahieb.moh@coie-nahrain.edu.iq
RI JAWAD, LAHIEB M./AAF-7186-2020
OI JAWAD, LAHIEB M./0000-0002-9729-2411
CR Al-Hazaimeh OM, 2019, NEURAL COMPUT APPL, V31, P2395, DOI 10.1007/s00521-017-3195-1
   Al-Maadeed TA, 2021, MULTIMED TOOLS APPL, V80, P24801, DOI 10.1007/s11042-021-10695-5
   Anees A, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0059-2
   [Anonymous], 2010, INT J COMPUTER SCI E
   [Anonymous], 2013, INT J SOFTW HARDW RE
   Atani, 2013, INT J SIGNAL PROCESS, V6, P275, DOI 10.14257/ijsip.2013.6.5.25
   Devade SP, 2018, ADV INTELL SYST, V696, P671, DOI 10.1007/978-981-10-7386-1_56
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Gupta R., 2015, INT J ENG SCI INNOV, V3, P81
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Ibrahem M, 2018, J INFORM COMM TECH, V1, P33
   Kaur M, 2018, ELECTRON LETT, V54, P562, DOI 10.1049/el.2017.4426
   Kumar V, 2021, MULTIMED TOOLS APPL, V80, P3749, DOI 10.1007/s11042-020-09854-x
   Li SS, 2013, MULTIMED TOOLS APPL, V66, P573, DOI 10.1007/s11042-012-1281-z
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Lin CY, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22050589
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Masood F, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030274
   Nandish M., 2015, EUROPEAN J ADV ENG T, V2, P23
   Pareek NK, 2011, COMM COM INF SC, V131, P413
   Rakheja P, 2020, OPT QUANT ELECTRON, V52, DOI 10.1007/s11082-020-2219-8
   Raza SF, 2019, NONLINEAR DYNAM, V95, P859, DOI 10.1007/s11071-018-4600-8
   Saini I., 2017, Int. J. Soc. Comput. Cyber Phys. Syst., V2, P59
   Scarmana G, 2015, INT GEOSCI REMOTE SE, P4514, DOI 10.1109/IGARSS.2015.7326831
   Shahna K, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106162
   Sharma M., 2012, INT J ENG RES TECHNO, V1, P2278
   Singar CP, 2017, 2017 INTERNATIONAL CONFERENCE ON RECENT INNOVATIONS IN SIGNAL PROCESSING AND EMBEDDED SYSTEMS (RISE), P257, DOI 10.1109/RISE.2017.8378163
   Sivakumar T, 2016, J INF SCI ENG, V32, P133
   Sivakumar T, 2015, KSII T INTERNET INF, V9, P2317, DOI 10.3837/tiis.2015.06.020
   Sivakumar T., 2014, IAENG International Journal of Computer Science, V41, P91
   Sivakumar T., 2010, INT J LATEST TRENDS, V10, P5
   Somaraj S, 2017, P 1 INT C COMP INT I P 1 INT C COMP INT I
   Tang ZJ, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/8694678
   Vidhya R, 2020, APPL INTELL, V50, P3101, DOI 10.1007/s10489-020-01697-1
   Wang XY, 2018, MULTIMED TOOLS APPL, V77, P6243, DOI 10.1007/s11042-017-4534-z
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Younes MAB, 2008, INT J COMPUT SCI NET, V8, P191
NR 37
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 24
BP 33297
EP 33312
DI 10.1007/s11042-021-11295-z
EA AUG 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WJ3HO
UT WOS:000685605200001
DA 2024-07-18
ER

PT J
AU Zabala, U
   Rodriguez, I
   Martínez-Otzeta, JM
   Lazkano, E
AF Zabala, Unai
   Rodriguez, Igor
   Maria Martinez-Otzeta, Jose
   Lazkano, Elena
TI Modeling and evaluating beat gestures for social robots
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social robots; Motion capturing and imitation; Generative adversarial
   networks; Talking movements; Frechet gesture distance
ID INVERSE KINEMATICS
AB Natural gestures are a desirable feature for a humanoid robot, as they are presumed to elicit a more comfortable interaction in people. With this aim in mind, we present in this paper a system to develop a natural talking gesture generation behavior. A Generative Adversarial Network (GAN) produces novel beat gestures from the data captured from recordings of human talking. The data is obtained without the need for any kind of wearable, as a motion capture system properly estimates the position of the limbs/joints involved in human expressive talking behavior. After testing in a Pepper robot, it is shown that the system is able to generate natural gestures during large talking periods without becoming repetitive. This approach is computationally more demanding than previous work, therefore a comparison is made in order to evaluate the improvements. This comparison is made by calculating some common measures about the end effectors' trajectories (jerk and path lengths) and complemented by the Frechet Gesture Distance (FGD) that aims to measure the fidelity of the generated gestures with respect to the provided ones. Results show that the described system is able to learn natural gestures just by observation and improves the one developed with a simpler motion capture system. The quantitative results are sustained by questionnaire based human evaluation .
C1 [Zabala, Unai; Rodriguez, Igor; Maria Martinez-Otzeta, Jose; Lazkano, Elena] Univ Basque Country, Comp Sci & Artificial Intelligence, Fac Informat, Manuel Lardizabal 1, Donostia San Sebastian 20018, Spain.
C3 University of Basque Country
RP Zabala, U (corresponding author), Univ Basque Country, Comp Sci & Artificial Intelligence, Fac Informat, Manuel Lardizabal 1, Donostia San Sebastian 20018, Spain.
EM unai.zabalac@ehu.eus
RI Zabala, Unai/GMX-2152-2022; Martinez-Otzeta, Jose Maria/K-6464-2014
OI Martinez-Otzeta, Jose Maria/0000-0001-5015-1315; Zabala,
   Unai/0000-0002-8196-2388
FU Basque Government [IT900-16, Elkartek 2018/00114]; Spanish Ministry of
   Economy and Competitiveness (MINECO/FEDER,EU) [RTI 2018-093337-B-100]
FX This work has been partially supported by the Basque Government
   (IT900-16 and Elkartek 2018/00114), the Spanish Ministry of Economy and
   Competitiveness (RTI 2018-093337-B-100, MINECO/FEDER,EU).
CR Alibeigi M, 2017, J INTELL ROBOT SYST, V85, P27, DOI 10.1007/s10846-016-0384-6
   [Anonymous], 2011, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2011.5995316, 10.1109/CVPR.2011.5995316]
   Breazeal C., 2004, Designing sociable robots
   Bremner P, 2009, RO-MAN 2009: THE 18TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1 AND 2, P1029, DOI 10.1109/ROMAN.2009.5326136
   Calinon S., 2004, INT C INT ROB SYST, P2769
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Fadli H., 2015, INT C ADV MECH INT M
   Fernández-Baena A, 2014, SPEECH COMMUN, V57, P331, DOI 10.1016/j.specom.2013.06.005
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Heusel M., 2017, Advances in Neural Information Processing Systems, P6627, DOI [DOI 10.48550/ARXIV.1706.08500, 10.48550/arXiv.1706.08500]
   Kingma D. P., 2013, ARXIV13126114
   Kofinas N, 2015, J INTELL ROBOT SYST, V77, P251, DOI 10.1007/s10846-013-0015-4
   Kucherenko T, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P97, DOI 10.1145/3308532.3329472
   Kwon J., 2006, INT C INT ROB SYST I
   Manfrè A, 2016, BIOL INSPIR COGN ARC, V15, P1, DOI 10.1016/j.bica.2015.09.009
   Marmpena M, 2020, ACMIEEE INT CONF HUM, P357, DOI 10.1145/3371382.3378360
   Marmpena M, 2019, INT CONF AFFECT, DOI [10.1109/ACII.2019.8925459, 10.1109/acii.2019.8925459]
   McNeill D., 1992, Hand and Mind: What Gestures Reveal about Thought
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Ng-Thow-Hing Victor, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P4617, DOI 10.1109/IROS.2010.5654322
   Nishimura Y, 2020, ACMIEEE INT CONF HUM, P375, DOI 10.1145/3371382.3378386
   Pérez-Mayos L, 2020, J INTELL ROBOT SYST, V99, P277, DOI 10.1007/s10846-019-01100-3
   Poubel LP, 2013, THESIS WARSAW U TECH
   Rodriguez I, 2019, TALKING SENTIMENT AD
   Rodriguez I, 2019, ROBOT AUTON SYST, V114, P57, DOI 10.1016/j.robot.2018.11.024
   Rodriguez I, 2016, IEEE INT CONF ROBOT, P2902, DOI 10.1109/ICRA.2016.7487454
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sakai K, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00049
   Schubert T, 2016, IEEE INT CONF ROBOT, P5548, DOI 10.1109/ICRA.2016.7487771
   Tanwani AK, 2018, THESIS EPFL
   Tits M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199744
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wolfert P, 2019, ICDL EPIROB WORKSH N
   Zabala U, 2020, WORKSH PHYS AG, P137
   Zabala U, 2020, AUTONO ROBOT, P1
   Zabala U, 2019, LECT NOTES ARTIF INT, V11876, P666, DOI 10.1007/978-3-030-35888-4_62
   Zhang Z, 2019, INT J ROBOTICS CONTR, V2, P49, DOI DOI 10.5430/IJRC.V2N1P49
   Zhang ZH, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8071203
NR 39
TC 7
Z9 7
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3421
EP 3438
DI 10.1007/s11042-021-11289-x
EA AUG 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000680824700003
OA hybrid
DA 2024-07-18
ER

PT J
AU Ibrahim, DR
   Teh, JS
   Abdullah, R
AF Ibrahim, Dyala R.
   Teh, Je Sen
   Abdullah, Rosni
TI An overview of visual cryptography techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Confidentiality; Encryption; Information security; Pixel expansion;
   Secret sharing; Visual cryptography
ID SECRET SHARING SCHEME; IMAGE; SIZE
AB Visual cryptography is an encryption technique that decomposes secret images into multiple shares. These shares are digitally or physically overlapped to recover the original image, negating the need for complex mathematical operations or additional hardware. There have been many variations of visual cryptography proposed over the years, each addressing different problems or to fulfill different security requirements. Existing review papers on the area only cover certain types of visual cryptography or lack comparisons between the various schemes. To address this gap, this paper provides broad overview of the area to aid new researchers in identifying research problems or to select suitable visual cryptography methods for their desired applications. For more veteran researchers in the area, our paper provides the most up-to-date coverage of the state-of-the-art. We first provide an introduction to the various categories of visual cryptography techniques, including a discussion on recently proposed schemes. These schemes are then compared in terms of their features, performance metrics, advantages and disadvantages. Compared to prior work, we extend the number of comparison metrics to include signal-to-noise ratio and the type of shares. Over 40 visual cryptography schemes that have been proposed in the past two decades were analyzed and compared. Our findings indicate that existing problems such as pixel expansion, poor quality of recovered image quality, computational and memory complexities still exist, and a optimizing the trade-off between these requirements still requires further investigation. We conclude the paper with a discussion of these open problems and future research directions.
C1 [Ibrahim, Dyala R.; Abdullah, Rosni] Univ Sains Malaysia, Natl Adv IPv6 Ctr, George Town, Malaysia.
   [Teh, Je Sen] Univ Sains Malaysia, Sch Comp Sci, George Town, Malaysia.
C3 Universiti Sains Malaysia; Universiti Sains Malaysia
RP Teh, JS (corresponding author), Univ Sains Malaysia, Sch Comp Sci, George Town, Malaysia.
EM jesen_teh@usm.my
RI Teh, Je Sen/B-7368-2018
OI Teh, Je Sen/0000-0001-5571-4148; Ibrahim, Dyala/0000-0002-5216-5769
FU Ministry of Education (MOE) Malaysia under the Fundamental Research
   Grant Scheme (FRGS) [FRGS/1/2019/ICT05/USM/02/1]
FX This work is supported in part by the Ministry of Education (MOE)
   Malaysia under the Fundamental Research Grant Scheme (FRGS), project
   number FRGS/1/2019/ICT05/USM/02/1.
CR Abraham AS, 2017, 2017 INTERNATIONAL CONFERENCE ON NETWORKS & ADVANCES IN COMPUTATIONAL TECHNOLOGIES (NETACT), P387, DOI 10.1109/NETACT.2017.8076801
   Al-Khalid R. I., 2017, Journal of Software Engineering and Applications, V10, P1, DOI [10.4236/JSEA.2017.101001, DOI 10.4236/JSEA.2017.101001]
   Anbarasi L.J., 2011, 2011 3 INT C EL COMP, V2, P393
   [Anonymous], 2011, 2011 INT C REC TREND
   Arumugam S, 2014, DESIGN CODE CRYPTOGR, V71, P153, DOI 10.1007/s10623-012-9722-2
   Askari Nazanin, 2014, Canadian Journal of Electrical and Computer Engineering, V37, P168, DOI 10.1109/CJECE.2014.2333419
   Askari N, 2013, CAN CON EL COMP EN, P286
   Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Bhatnagar Rajat, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P78, DOI 10.1109/ICECA.2018.8474649
   Blesswin AJ, 2013, INT CONF ADV COMPU, P560, DOI 10.1109/ICoAC.2013.6922012
   Blesswin AJ, 2020, MULTIMED TOOLS APPL, V79, P17057, DOI 10.1007/s11042-019-7535-2
   Borchert, 2007, WSI200704 I COMP SCI
   Chanu OB, 2019, INT J MULTIMED INF R, V8, P195, DOI 10.1007/s13735-018-0161-3
   Chao HC, 2017, SIGNAL PROCESS-IMAGE, V57, P60, DOI 10.1016/j.image.2017.05.005
   Chao HC, 2017, DIGIT SIGNAL PROCESS, V68, P69, DOI 10.1016/j.dsp.2017.05.009
   Chaturvedi A., 2015, INT J COMPUTER TREND, V30, P26, DOI [10.14445/22312803/ijctt-v30p105, DOI 10.14445/22312803/IJCTT-V30P105]
   Chavan Pallavi Vijay, 2015, International Journal of Information Privacy, Security and Integrity, V2, P159
   Chavan PV, 2012, NIRMA UNIV INT CONF
   Chavan PV, 2014, 2014 IEEE STUDENTS' CONFERENCE ON ELECTRICAL, ELECTRONICS AND COMPUTER SCIENCE (SCEECS)
   Chen J, 2009, IMAGING SCI J, V57, P101, DOI 10.1179/174313108X384656
   Chen Q, 2010, 2010 3 INT C COMP SC
   Chiu PL, 2020, IEEE ACCESS, V8, P111330, DOI 10.1109/ACCESS.2020.3000308
   Dahat AV, 2016, PROCEDIA COMPUT SCI, V78, P563, DOI 10.1016/j.procs.2016.02.103
   Das S, 2018, ACCIDENT ANAL PREV, V111, P43, DOI 10.1016/j.aap.2017.11.016
   De Bonis A, 2004, THEOR COMPUT SCI, V314, P351, DOI 10.1016/j.tcs.2003.12.018
   De Prisco R, 2014, IEEE T INF FOREN SEC, V9, P653, DOI 10.1109/TIFS.2014.2305574
   De Prisco R, 2013, THEOR COMPUT SCI, V510, P62, DOI 10.1016/j.tcs.2013.09.005
   Deepa AK, 2014, INT CONF SIGN PROCES, P653, DOI 10.1109/ICOSP.2014.7015084
   Dhiman K, 2018, COMPUT ELECTR ENG, V70, P647, DOI 10.1016/j.compeleceng.2017.09.017
   Fang WP, 2008, PATTERN RECOGN, V41, P1410, DOI 10.1016/j.patcog.2007.09.004
   Fathimal M, 2019, INT ARAB J INF TECHN, V16, P66
   Feng JB, 2008, PATTERN RECOGN, V41, P3572, DOI 10.1016/j.patcog.2008.05.031
   Fu Z, 2009, 2009 INT S INF ENG E
   Geetha P, 2019, MULTIMED TOOLS APPL, V78, P18503, DOI 10.1007/s11042-019-7163-x
   Guo YS, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041321
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   Hodeish ME, 2018, MULTIMED TOOLS APPL, V77, P24937, DOI 10.1007/s11042-018-5724-z
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Hou YC., 2001, J TECHNOL, V2, P151, DOI [10.1049/iet-ifs:20080066, DOI 10.1049/IET-IFS:20080066]
   Hou YC, 2013, INFORM SCIENCES, V233, P290, DOI 10.1016/j.ins.2013.01.006
   Hou YC, 2011, IEEE T CIRC SYST VID, V21, P1760, DOI 10.1109/TCSVT.2011.2106291
   Hsu HC, 2007, IMAGING SCI J, V55, P175, DOI 10.1179/174313107X176289
   Hsu SF, 2012, INT CONF GENET EVOL, P464, DOI 10.1109/ICGEC.2012.150
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   Jana B, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON ISSUES AND CHALLENGES IN INTELLIGENT COMPUTING TECHNIQUES (ICICT), P706, DOI 10.1109/ICICICT.2014.6781367
   Jena D, 2009, INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL : ICACC 2009 - PROCEEDINGS, P207, DOI 10.1109/ICACC.2009.109
   Jin D, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1993625
   Joshi AM, 2016, 2016 CONFERENCE ON EMERGING DEVICES AND SMART SYSTEMS (ICEDSS), P56
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Kamath M, 2012, 2012 INT C COMM INF
   Kanakkath P, 2019, MULTIMED TOOLS APPL, V78, P1315, DOI 10.1007/s11042-018-6158-3
   Kang I, 2011, IEEE T IMAGE PROCESS, V20, P132, DOI 10.1109/TIP.2010.2056376
   Kukreja S, 2021, VISUAL COMPUT, V37, P1481, DOI 10.1007/s00371-020-01883-9
   Kumar H, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON ISSUES AND CHALLENGES IN INTELLIGENT COMPUTING TECHNIQUES (ICICT), P857, DOI 10.1109/ICICICT.2014.6781393
   KUMAR M, 2018, T EMERG TELECOMMUN T, V30
   Kumar S, 2013, CRYPTOLOGIA, V37, P154, DOI 10.1080/01611194.2012.739585
   Lee KH, 2013, IEEE T IMAGE PROCESS, V22, P3830, DOI 10.1109/TIP.2013.2262290
   Lee KH, 2012, IEEE T INF FOREN SEC, V7, P219, DOI 10.1109/TIFS.2011.2167611
   Li P, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102911
   Li P, 2020, IEEE ACCESS, V8, P32840, DOI 10.1109/ACCESS.2020.2973659
   Lin HC, 2013, J VIS COMMUN IMAGE R, V24, P318, DOI 10.1016/j.jvcir.2013.01.003
   Lin SJ, 2010, J VIS COMMUN IMAGE R, V21, P900, DOI 10.1016/j.jvcir.2010.08.006
   Liu GY, 2013, INFORM SCIENCES, V235, P259, DOI 10.1016/j.ins.2013.01.003
   Lu JF, 2017, MOB INF SYST, V2017, DOI 10.1155/2017/4356038
   Malar S, 2011, INT J ADV COMPUT SC, V2, DOI 10.14569/ijacsa.2011.021112
   Mary GG, 2018, INTELLIGENT SYSTEMS, P147
   Mousavi SM, 2014, J DIGIT IMAGING, V27, P714, DOI 10.1007/s10278-014-9700-5
   Myodo E, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2114
   Naor M., 1997, Security Protocols. International Workshop Proceedings, P197
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Palevicius P, 2015, OPT COMMUN, V335, P161, DOI 10.1016/j.optcom.2014.09.041
   Pandey A, 2016, INT CONF RELI INFO, P375, DOI 10.1109/ICRITO.2016.7784984
   Pang LJ, 2016, SECUR COMMUN NETW, V9, P966, DOI 10.1002/sec.1392
   Parakh A., 2009, CRYPTOLOGIA, V26, P68, DOI [10.1080/0161-110291890768, DOI 10.1080/0161-110291890768]
   Petrauskiene V, 2014, OPT LASER TECHNOL, V57, P129, DOI 10.1016/j.optlastec.2013.10.015
   Praun E, 2001, COMP GRAPH, P581, DOI 10.1145/383259.383328
   Premkumar S, 2012, 2012 INT C COMP EL E
   Punithavathi P, 2017, INF SECUR J, V26, P305, DOI 10.1080/19393555.2017.1386249
   Punithavathi P., 2016, ADV INTELLIGENT SYST, P511
   Ramya J, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICCICCT), P223, DOI 10.1109/ICCICCT.2014.6992960
   Roy S, 2014, 2014 IEEE STUDENTS' CONFERENCE ON ELECTRICAL, ELECTRONICS AND COMPUTER SCIENCE (SCEECS)
   Salama MA, 2018, AIN SHAMS ENG J, V9, P3001, DOI 10.1016/j.asej.2018.03.002
   Saturwar JH, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE SYSTEMS AND CONTROL (ICISC 2017), P572
   Shaik A., 2017, Journal of Artificial Intelligence, V10, P1, DOI DOI 10.3923/JAI.2017.1.21
   Shankar K, 2016, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL (ISCO'16)
   Shankar K, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616501383
   Shankar K, 2015, PROCEDIA COMPUT SCI, V70, P462, DOI 10.1016/j.procs.2015.10.080
   Shankar K, 2008, J AMB INTEL HUM COMP, DOI 10.1007/s12652-018-1160-1
   Sharma H, 2011, 2011 2 INT C COMP CO
   Shivani S, 2018, PATTERN ANAL APPL, V21, P139, DOI 10.1007/s10044-016-0571-x
   Shyu SJ, 2007, PATTERN RECOGN, V40, P3633, DOI 10.1016/j.patcog.2007.03.012
   Shyu SJ, 2015, IEEE T CIRC SYST VID, V25, P1557, DOI 10.1109/TCSVT.2015.2389372
   Singh P, 2018, SIGNAL PROCESS, V142, P301, DOI 10.1016/j.sigpro.2017.06.015
   Sridhar S, 2021, 2 ONE IMAGE SECRET S, V74
   Thomas Sandhya Anne, 2018, 2018 2nd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P1091, DOI 10.1109/ICOEI.2018.8553863
   Thomas SA, 2017, 2017 INTERNATIONAL CONFERENCE ON CURRENT TRENDS IN COMPUTER, ELECTRICAL, ELECTRONICS AND COMMUNICATION (CTCEEC), P1164, DOI 10.1109/CTCEEC.2017.8455136
   Tuyls P, 2004, LECT NOTES COMPUT SC, V2802, P271
   Melgar MEV, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102592
   Wan S, 2018, J REAL-TIME IMAGE PR, V14, P25, DOI 10.1007/s11554-017-0678-3
   Wang L, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13010065
   Wang RZ, 2011, IEEE SIGNAL PROC LET, V18, P627, DOI 10.1109/LSP.2011.2166543
   Wang RZ, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3557792
   Weir J, 2010, LECT NOTES COMPUT SC, V6010, P70, DOI 10.1007/978-3-642-14298-7_5
   Wu HC, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 3, PROCEEDINGS, P173, DOI 10.1109/ISDA.2008.130
   Wu XT, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102793
   Wu XT, 2019, J VIS COMMUN IMAGE R, V59, P550, DOI 10.1016/j.jvcir.2019.02.008
   Wu Z, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010069
   Yan XH, 2020, MULTIMED TOOLS APPL, V79, P21345, DOI 10.1007/s11042-020-08970-y
   Yan XH, 2015, SIGNAL PROCESS, V109, P317, DOI 10.1016/j.sigpro.2014.12.002
   Yang CN, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102660
   Yang CN, 2017, J VIS COMMUN IMAGE R, V48, P182, DOI 10.1016/j.jvcir.2017.06.012
   Yang CN, 2014, INFORM SCIENCES, V278, P141, DOI 10.1016/j.ins.2014.03.033
   Yang CN, 2013, PERS UBIQUIT COMPUT, V17, P843, DOI 10.1007/s00779-012-0535-0
   Yang CN, 2012, IEEE T CIRC SYST VID, V22, P799, DOI 10.1109/TCSVT.2011.2180952
   Yang CN, 2006, PATTERN RECOGN, V39, P1300, DOI 10.1016/j.patcog.2006.01.013
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Yang N, 2018, OPT EXPRESS, V26, P31995, DOI 10.1364/OE.26.031995
   Zhang X, 2018, INT J PERFORMABILITY, DOI 10.23940/ijpe.18.02.p14.334340
   Zhao TY, 2020, MULTIMED TOOLS APPL, V79, P12165, DOI 10.1007/s11042-020-08632-z
NR 120
TC 16
Z9 17
U1 4
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31927
EP 31952
DI 10.1007/s11042-021-11229-9
EA JUL 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000675334700005
DA 2024-07-18
ER

PT J
AU Wang, B
   Wang, Y
   Hou, JY
   Sui, X
   Zhu, MN
AF Wang, Bo
   Wang, Yue
   Hou, Jiayao
   Sui, Xue
   Zhu, Meineng
TI Discriminative feature projection for camera model identification of
   recompressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensic; Camera model identification; Image recompression;
   Feature projection
ID SENSOR PATTERN NOISE; RETRIEVAL APPROACH; FUSION; ORIGIN
AB Camera model identification, which aims to identify the source camera model of the query images, has been well studied in the laboratory environment. Most existing methods regard it as a classification problem and rely on well-designed features that characterize the differences between various camera models. In these methods, however, the accuracy of identification results would suffer from the process of image recompression. The information loss reduces the discriminative ability of the designed identification features and results in a serious accuracy loss. To remedy this shortcoming, we investigate the handicap for accurate source identification when the query image is recompressed and creatively propose a new method Discriminative Feature Projection (DFP) to solve this problem. The proposed method learns a discriminative feature projection that projects the designed identification features into a new feature representation invariant to recompression by minimizing the divergence between recompressed and uncompressed images. We also incorporate two constraints that the discrepancy of different images sources should be large and the latent geometric relations of images neighbors should be preserved into our method to reinforce the discriminative ability. Moreover, we conduct extensive experiments over the public Dresden Image Database. Compared with several state-of-the-art methods on camera model identification, the experiment results verify that DFP can achieve significant accuracy promotion when identifying the recompressed images.
C1 [Wang, Bo; Wang, Yue; Hou, Jiayao] Dalian Univ Technol, Sch Informat & Commun Engn, Dalian, Peoples R China.
   [Sui, Xue] Liaoning Normal Univ, Dalian 116029, Liaoning, Peoples R China.
   [Zhu, Meineng] Beijing Inst Elect Technol & Applicat, Beijing 100091, Peoples R China.
C3 Dalian University of Technology; Liaoning Normal University
RP Wang, Y (corresponding author), Dalian Univ Technol, Sch Informat & Commun Engn, Dalian, Peoples R China.
EM 31909072@mail.dlut.edu.cn
FU National Natural Science Foundation of China [U1936117, 62076052,
   61772111]; Fundamental Research Funds for the Central Universities
   [DUT21GF303, DUT20RC(3)088]
FX This work is supported by the National Natural Science Foundation of
   China (No. U1936117, No. 62076052, No. 61772111), and the Fundamental
   Research Funds for the Central Universities (DUT21GF303, DUT20RC(3)088).
CR [Anonymous], 2013, IEEE ACCESS, DOI DOI 10.1109/ACCESS.2013.2260814
   [Anonymous], 2010, J DIGITAL FORENSIC P
   [Anonymous], P MED WAT SEC FOR
   [Anonymous], P IEEE INT C IM GRAP
   Bayram S, 2005, IEEE IMAGE PROC, P2793
   Bayram S, 2015, IEEE T INF FOREN SEC, V10, P597, DOI 10.1109/TIFS.2014.2385634
   Bayram S, 2012, IEEE T INF FOREN SEC, V7, P1404, DOI 10.1109/TIFS.2012.2192272
   Bo Wang, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P702, DOI 10.1109/IIH-MSP.2009.244
   Calmon FD, 2018, IEEE J-STSP, V12, P1106, DOI 10.1109/JSTSP.2018.2865887
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Cheng CQ, 2015, INT ARCH PHOTOGRAMM, V47, P1, DOI 10.5194/isprsarchives-XL-7-W4-1-2015
   Chierchia Giovanni., 2010, Proceedings of the 2nd ACM workshop on Multimedia in forensics, security, and intelligence, MiFor '10, P117, DOI DOI 10.1145/1877972.1878002
   Choi KS, 2006, TENCON IEEE REGION, P656
   Gao S, 2011, P INT WORKSH DIG WAT, P268
   Gloe Thomas, 2012, Transactions on Data Hiding and Multimedia Security VIII. Pattern Recognition for IT Security, P42, DOI 10.1007/978-3-642-31971-6_3
   Goljan M, 2013, PROC SPIE, V8665, DOI 10.1117/12.2003234
   Gretton A, 2006, Adv Neural Inf Process Syst, V19
   Ho JS, 2010, IEEE INT CON MULTI, P1475, DOI 10.1109/ICME.2010.5582951
   Hou JU, 2017, IEEE T CIRC SYST VID, V27, P1826, DOI 10.1109/TCSVT.2016.2539828
   Hu YJ, 2015, MULTIMED TOOLS APPL, V74, P7405, DOI 10.1007/s11042-014-1985-3
   Hu YJ, 2010, IEEE INT CON MULTI, P1481, DOI 10.1109/ICME.2010.5582952
   Kang XG, 2012, IEEE T INF FOREN SEC, V7, P393, DOI 10.1109/TIFS.2011.2168214
   Kharrazi M, 2004, IEEE IMAGE PROC, P709
   Khosravi MR., 2019, EURASIP J WIREL COMM, V2019, P1, DOI [10.1186/s13638-018-1318-8, DOI 10.1186/S13638-018-1318-8]
   Kirchner M, 2015, HDB DIGITAL FORENSIC, P3299
   Lawgaly A, 2017, IEEE T INF FOREN SEC, V12, P392, DOI 10.1109/TIFS.2016.2620280
   Lawgaly A, 2014, IEEE IMAGE PROC, P5357, DOI 10.1109/ICIP.2014.7026084
   Li CT, 2012, IEEE T CIRC SYST VID, V22, P260, DOI 10.1109/TCSVT.2011.2160750
   Li CT, 2010, IEEE T INF FOREN SEC, V5, P280, DOI 10.1109/TIFS.2010.2046268
   Li RZ, 2018, PATTERN RECOGN, V74, P556, DOI 10.1016/j.patcog.2017.09.027
   Li XF, 2013, IEEE IMAGE PROC, P4432, DOI 10.1109/ICIP.2013.6738913
   Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461
   Lin XF, 2016, IEEE SIGNAL PROC LET, V23, P381, DOI 10.1109/LSP.2016.2521349
   Long MS, 2014, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2014.183
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Lukás J, 2005, PROC SPIE, V5685, P249, DOI 10.1117/12.587105
   LUO L, 2017, ARXIV170404235
   Marra F, 2017, MULTIMED TOOLS APPL, V76, P4765, DOI 10.1007/s11042-016-3663-0
   Marra F, 2015, LECT NOTES COMPUT SC, V9281, P11, DOI 10.1007/978-3-319-23222-5_2
   Mo Fridrich JJ, 2007, P SPIE
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Piva A., 2013, ISRN SIGNAL PROCESS, V2013, DOI [10.1155/2013/496701, DOI 10.1155/2013/496701]
   Roy A, 2017, IEEE COMPUT SOC CONF, P1848, DOI 10.1109/CVPRW.2017.231
   Tang ZJ, 2019, IEEE T KNOWL DATA EN, V31, P549, DOI 10.1109/TKDE.2018.2837745
   Tang ZJ, 2016, IEEE T INF FOREN SEC, V11, P200, DOI 10.1109/TIFS.2015.2485163
   Tomioka Y, 2013, IEEE T INF FOREN SEC, V8, P1986, DOI 10.1109/TIFS.2013.2284761
   Tuama A, 2016, EUR SIGNAL PR CONF, P1183, DOI 10.1109/EUSIPCO.2016.7760435
   Unar S, 2019, KNOWL-BASED SYST, V179, P8, DOI 10.1016/j.knosys.2019.05.001
   Unar S, 2019, IET IMAGE PROCESS, V13, P1191, DOI 10.1049/iet-ipr.2019.0098
   Unar S, 2019, IET IMAGE PROCESS, V13, P515, DOI 10.1049/iet-ipr.2018.5277
   Unar S, 2018, INFORM FUSION, V44, P176, DOI 10.1016/j.inffus.2018.03.006
   Valsesia D, 2015, IEEE T INF FOREN SEC, V10, P1472, DOI 10.1109/TIFS.2015.2415461
   Wang B, 2019, MATH BIOSCI ENG, V16, P5041, DOI 10.3934/mbe.2019254
   Wang XY, 2012, COMPUT STAND INTER, V34, P31, DOI 10.1016/j.csi.2011.05.001
   Wang XY, 2009, FRACTALS, V17, P441, DOI 10.1142/S0218348X09004557
   Wang XY, 2014, PATTERN RECOGN, V47, P3293, DOI 10.1016/j.patcog.2014.04.020
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Wu GD, 2012, IEEE IMAGE PROC, P237, DOI 10.1109/ICIP.2012.6466839
   Xu BC, 2016, NEUROCOMPUTING, V207, P131, DOI 10.1016/j.neucom.2016.05.012
   Xu G, 2012, P IEEE INT C MULT EX
   Yongjian Hu, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P325, DOI 10.1109/IIH-MSP.2012.85
NR 61
TC 1
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29719
EP 29743
DI 10.1007/s11042-021-11201-7
EA JUL 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000671519600001
DA 2024-07-18
ER

PT J
AU Bernacki, J
AF Bernacki, Jaroslaw
TI Robustness of digital camera identification with convolutional neural
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital forensics; Privacy; Hardwaremetry; Camera recognition; Camera
   fingerprint; Convolutional neural networks; Robustness
ID MODEL; RECOGNITION; IRIS
AB This paper considers the area of digital forensics (DF). One of the problem in DF is the issue of identification of digital cameras based on images. This aspect has been attractive in recent years due to popularity of social media platforms like Facebook, Twitter etc., where lots of photographs are shared. Although many algorithms and methods for digital camera identification have been proposed, there is lack of research about their robustness. Therefore, in this paper the robustness of digital camera identification with the use of convolutional neural network is discussed. It is assumed that images may be of poor quality, for example, degraded by Poisson noise, Gaussian blur, random noise or removing pixels' least significant bit. Experimental evaluation conducted on two large image datasets (including Dresden Image Database) confirms usefulness of proposed method, where noised images are recognized with almost the same high accuracy as normal images.
C1 [Bernacki, Jaroslaw] Czestochowa Tech Univ, Al Armii Krajowej 36, PL-42200 Czestochowa, Poland.
C3 Technical University Czestochowa
RP Bernacki, J (corresponding author), Czestochowa Tech Univ, Al Armii Krajowej 36, PL-42200 Czestochowa, Poland.
EM jaroslaw.bernacki@pcz.pl
OI Bernacki, Jaroslaw/0000-0002-4488-3488
CR Agarwal A, 2019, INFORM FUSION, V45, P333, DOI 10.1016/j.inffus.2017.11.004
   Al Shaya O, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113801
   [Anonymous], 2016, IEEE INT WORKS INFOR
   [Anonymous], 2017, Electron. Imaging
   [Anonymous], 2016, Digital Forensics and Watermarking, DOI DOI 10.1007/978-3-319-53465-7-9
   [Anonymous], 2020, DOCUMENTATION M
   Bernacki J, 2021, MULTIMED TOOLS APPL, V80, P921, DOI 10.1007/s11042-020-09133-9
   Bondi L, 2017, IEEE SIGNAL PROC LET, V24, P259, DOI 10.1109/LSP.2016.2641006
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Chen YS, 2017, IEEE IMAGE PROC, P4337, DOI 10.1109/ICIP.2017.8297101
   De Marsico M, 2015, PATTERN RECOGN LETT, V57, P17, DOI 10.1016/j.patrec.2015.02.009
   Debiasi L., 2016, 4 INT C BIOM FOR IWB, P1, DOI DOI 10.1109/IWBF.2016.7449674
   Delp, 2010, SPIE P, V7541
   Delp EJ, 2010, SPIE P, V7541
   Flusser J, 2016, IEEE T IMAGE PROCESS, V25, P790, DOI 10.1109/TIP.2015.2512108
   Freire-Obregon D, 2017, ARXIV171001257
   Freire-Obregón D, 2019, PATTERN RECOGN LETT, V126, P86, DOI 10.1016/j.patrec.2018.01.005
   Galdi C, 2016, PATTERN RECOGN LETT, V82, P144, DOI 10.1016/j.patrec.2015.09.009
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   Goljan M., 2016, Electronic Imaging, V2016, P1, DOI [10.2352/ISSN.2470-1173.2016.8.MWSF-086, DOI 10.2352/ISSN.2470-1173.2016.8.MWSF-086]
   Goljan M, 2011, IEEE T INF FOREN SEC, V6, P227, DOI 10.1109/TIFS.2010.2099220
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Hosseini MDM, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P69, DOI 10.1145/3335203.3335717
   Kang XG, 2012, IEEE T INF FOREN SEC, V7, P393, DOI 10.1109/TIFS.2011.2168214
   Kirchner M, 2009, MEDIA FORENSICS SECU
   Li CD, 2009, IEEE I C EMBED SOFTW, P19, DOI 10.1109/ICESS.2009.51
   Li RZ, 2018, PATTERN RECOGN, V74, P556, DOI 10.1016/j.patcog.2017.09.027
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Marra F, 2018, SIGNAL PROCESS-IMAGE, V65, P240, DOI 10.1016/j.image.2018.04.007
   Marra F, 2018, PATTERN RECOGN LETT, V113, P46, DOI 10.1016/j.patrec.2017.04.010
   Marra F, 2015, LECT NOTES COMPUT SC, V9281, P11, DOI 10.1007/978-3-319-23222-5_2
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Rafi Rafi A. M. A. M., CVPR WORKSHOPS, P19
   Syga, 2017, P 14 INT JOINT C E B, V4, P343
   Taspinar S, 2016, IEEE IMAGE PROC, P156, DOI 10.1109/ICIP.2016.7532338
   Thai TH, 2016, DIGIT SIGNAL PROCESS, V48, P285, DOI 10.1016/j.dsp.2015.10.002
   Tuama A, 2016, IEEE INT WORKS INFOR
   Tuama A, 2016, EUR SIGNAL PR CONF, P1183, DOI 10.1109/EUSIPCO.2016.7760435
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Wu X, 2016, CORRABS161007728
   Yang PP, 2019, PATTERN RECOGN LETT, V119, P195, DOI 10.1016/j.patrec.2017.10.016
   Yao HW, 2018, IEEE ACCESS, V6, P24973, DOI 10.1109/ACCESS.2018.2832066
NR 43
TC 6
Z9 6
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29657
EP 29673
DI 10.1007/s11042-021-11129-y
EA JUL 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000670222600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Kim, JH
   Lee, J
AF Kim, Jong-Hyun
   Lee, Jung
TI Draft layout generation of building drawings on real urban scenes with
   boundary particle method and priority solver
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Element packaging; Building drawings; Real urban scene; Optimized
   layout; Architectural design
ID POLYGON CONTAINMENT; IRREGULAR OBJECTS; PACKING PROBLEMS; ALLOCATION;
   SEARCH; PLANE
AB We propose a method for efficiently and automatically arranging building drawings using a 3D National Geographic Information System (NGIS) within a real-world urban scene. In the architectural design office, in general, the designer manually adjusts the position of each building drawings in order to place buildings within a specific area, so the larger the area to be placed, the higher the processing cost and the longer the working time. On the other hand, we classify the user-specified area based on building regulations, apply the boundary particle method used in fluid simulation, and place building drawings near the boundary according to the area type. Then, we propose a priority map and a priority solver to automatically place buildings as many as possible inside the area, and create several building drawing layouts so that users can select from them. We have reduced the time required for designing urban and apartment complexes by improving the cost of manual labor by automating the optimized layout of building drawings while satisfying the given building regulations.
C1 [Kim, Jong-Hyun] Kangnam Univ, Sch Software Applicat, Yongin, Gyeonggi Do, South Korea.
   [Lee, Jung] Hallym Univ, Chunchon, Gangwon, South Korea.
C3 Kangnam University; Hallym University
RP Lee, J (corresponding author), Hallym Univ, Chunchon, Gangwon, South Korea.
EM jonghyunkim@kangnam.ac.kr; airjung@hallym.ac.kr
OI Lee, Jung/0000-0003-0458-1474
FU National Research Foundation of Korea(NRF) - Ministry of Science, ICT &
   Future Planning [2017R1C1B5074984]; Hallym University [202002690001]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Science, ICT & Future Planning (No.2017R1C1B5074984). This research was
   supported by a Hallym University Research Fund (202002690001).
CR Adamowicz M., 1976, Computer Aided Design, V8, P27, DOI 10.1016/0010-4485(76)90006-3
   ALBANO A, 1980, IEEE T SYST MAN CYB, V10, P242, DOI 10.1109/TSMC.1980.4308483
   Alvarez-Valdes R, 2013, INT J PROD ECON, V145, P463, DOI 10.1016/j.ijpe.2013.04.007
   Amaro B, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/1670709
   AVNAIM F, 1987, LECT NOTES COMPUT SC, V294, P322
   Avnaim Francis., 1987, P 3 ACM S COMPUTATIO, P242
   BAKER BS, 1986, J ALGORITHM, V7, P532, DOI 10.1016/0196-6774(86)90017-9
   Battiato S, 2007, COMPUT GRAPH FORUM, V26, P794, DOI 10.1111/j.1467-8659.2007.01021.x
   Battiato S, 2013, J ELECTR COMPUT ENG, V2013, DOI 10.1155/2013/908905
   Bennell J, 2010, ANN OPER RES, V179, P343, DOI 10.1007/s10479-008-0456-5
   Bennell JA, 2009, J OPER RES SOC, V60, pS93, DOI 10.1057/jors.2008.169
   Bennell JA, 2008, EUR J OPER RES, V184, P397, DOI 10.1016/j.ejor.2006.11.038
   Bennell JA, 2008, COMPUT OPER RES, V35, P267, DOI 10.1016/j.cor.2006.02.026
   Bouganis A, 2007, IEEE T AUTOM SCI ENG, V4, P382, DOI 10.1109/TASE.2006.887158
   Chernov N, 2010, COMP GEOM-THEOR APPL, V43, P535, DOI 10.1016/j.comgeo.2009.12.003
   Domovic D, 2014, 2014 37TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1094, DOI 10.1109/MIPRO.2014.6859732
   DOWSLAND KA, 1995, EUR J OPER RES, V84, P506, DOI 10.1016/0377-2217(95)00019-M
   Egeblad J, 2007, EUR J OPER RES, V183, P1249, DOI 10.1016/j.ejor.2005.11.063
   Fischetti M, 2009, J HEURISTICS, V15, P201, DOI 10.1007/s10732-008-9088-9
   FOWLER RJ, 1981, INFORM PROCESS LETT, V12, P133, DOI 10.1016/0020-0190(81)90111-3
   Gomes AM, 2006, EUR J OPER RES, V171, P811, DOI 10.1016/j.ejor.2004.09.008
   Gomes AM, 2002, EUR J OPER RES, V141, P359, DOI 10.1016/S0377-2217(02)00130-3
   Grinde RB, 1996, EUR J OPER RES, V92, P368, DOI 10.1016/0377-2217(94)00279-7
   Grinde RB, 1997, COMPUT OPER RES, V24, P231, DOI 10.1016/S0305-0548(96)00050-0
   Guo BS, 2018, IEEE ACCESS, V6, P62675, DOI 10.1109/ACCESS.2018.2876546
   Hausner A, 2001, COMP GRAPH, P573, DOI 10.1145/383259.383327
   Jakobs S, 1996, EUR J OPER RES, V88, P165, DOI 10.1016/0377-2217(94)00166-9
   Jiang W, 2016, INT J PEDIATR ENDOCR, DOI 10.1186/s13633-015-0019-x
   Jones DR, 2014, J GLOBAL OPTIM, V59, P367, DOI 10.1007/s10898-013-0129-z
   Kallrath J, 2009, J GLOBAL OPTIM, V43, P299, DOI 10.1007/s10898-007-9274-6
   Liu Y, 2010, COMPUT GRAPH FORUM, V29, P2387, DOI 10.1111/j.1467-8659.2010.01752.x
   MARQUES VMM, 1991, IECON 91, VOLS 1-3, P1911
   MARTIN RR, 1988, COMPUT AIDED DESIGN, V20, P506, DOI 10.1016/0010-4485(88)90040-1
   Milenkovic V, 1997, ALGORITHMICA, V19, P183, DOI 10.1007/PL00014416
   Milenkovic VJ, 1999, COMP GEOM-THEOR APPL, V13, P3, DOI 10.1016/S0925-7721(99)00006-1
   Milenkovic VJ, 1998, COMP GEOM-THEOR APPL, V10, P305, DOI 10.1016/S0925-7721(98)00012-1
   Nielsen B.K., 2007, Proceedings of the thirteenth Australasian symposium on Theory of computing, V65, P123
   Oliveira J, 1993, LECT NOTES ECON MATH, P255
   Peralta Jeinny, 2018, Pesqui. Oper., V38, P195, DOI 10.1590/0101-7438.2018.038.02.0195
   Puglisi G., 2013, Image and video-based artistic stylisation, P189
   Rocha P, 2015, IFAC PAPERSONLINE, V48, P501, DOI 10.1016/j.ifacol.2015.06.131
   SEGENREICH SA, 1986, COMPUT GRAPH, V10, P229, DOI 10.1016/0097-8493(86)90007-5
   Stoyan Y., 2004, Q J BELGIAN FRENCH I, V2, P69
   Stoyan Y, 2016, J OPER RES SOC, V67, P786, DOI 10.1057/jors.2015.94
   Tang Deyou, 2016, Journal of Computer Applications, V36, P2540, DOI 10.11772/j.issn.1001-9081.2016.09.2540
   Toledo FMB, 2013, INT J PROD ECON, V145, P478, DOI 10.1016/j.ijpe.2013.04.009
   Wenlan Guo, 2011, 2011 International Conference on Computer Science and Service System (CSSS), P2622
   Wong WK, 2009, EXPERT SYST APPL, V36, P3489, DOI 10.1016/j.eswa.2008.02.068
   Xu JJ, 2017, CHIN CONTR CONF, P2858, DOI 10.23919/ChiCC.2017.8027799
   Zheng W, 2012, APPL MECH MATER, V130-134, P2090, DOI 10.4028/www.scientific.net/AMM.130-134.2090
NR 50
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29539
EP 29560
DI 10.1007/s11042-021-10659-9
EA JUL 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000669188400001
DA 2024-07-18
ER

PT J
AU Gao, BK
   Ma, K
   Bi, HB
   Wang, L
   Wu, CL
AF Gao, Bingkun
   Ma, Ke
   Bi, Hongbo
   Wang, Ling
   Wu, Chenlei
TI Learning high resolution reservation for human pose estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human pose estimation; High resolution information; Depth pyramid
   residual module; Multi-scale fusion
AB The human pose estimation in images and videos is a challenging task in many applications. Most of the network structures used to estimate the pose only use the convolution feature of the last layer, which will cause the loss of information. In this paper, we propose a multi-scales fusion framework based on the hourglass network for the human pose estimation, which can effectively obtain sufficient information of different resolutions. In the process of extracting different resolution features, the network constantly complements the high resolution features. Additionally, we design the depth pyramid residual module to fuse different various scales features. The whole network is stacked by sub-networks. For applying in limited storage space better, we only use 2-stage stacked network. We test the network on standard benchmarks MPII dataset, our method achieves 88.9% PCKh score and improves the PCK score by 0.7%, compared with the original network. Our approach gains state-of-the-art results.
C1 [Gao, Bingkun; Ma, Ke; Bi, Hongbo; Wang, Ling; Wu, Chenlei] Northeast Petr Univ, Sch Elect & Informat Engn, Daqing, Peoples R China.
C3 Northeast Petroleum University
RP Bi, HB (corresponding author), Northeast Petr Univ, Sch Elect & Informat Engn, Daqing, Peoples R China.
EM bkgao@126.com; make098@126.com; bhbdq@126.com; 1024573821@qq.com;
   wcl_master@126.com
OI Bi, Hongbo/0000-0003-2442-330X
FU NEPU Natural Science Foundation [2017P Y ZL -05, JY CX CX06 2018, JY CX
   JG06 2018]
FX This study was funded by the NEPU Natural Science Foundation under Grant
   No. 2017P Y ZL -05, JY CX CX06 2018 and JY CX JG06 2018.
CR Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   [Anonymous], 2020, ARXIV PREPRINT ARXIV
   Bastanfard A, 2016, 1 INT C NEW RES ACHI
   Bastanfard A, 2016, IMPROVED CONFIDENCE
   Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303
   Cai XY, 2016, IEEE T MULTIMEDIA, V18, P141, DOI 10.1109/TMM.2015.2505089
   Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Cheng BW, 2020, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR42600.2020.00543
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Gao S, 2020, P IEEE CVF C COMP VI, P11744
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hernández-Vela A, 2016, INT J COMPUT VISION, V118, P49, DOI 10.1007/s11263-015-0869-y
   Hidalgo G, 2019, IEEE I CONF COMP VIS, P6981, DOI 10.1109/ICCV.2019.00708
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Ke LP, 2018, LECT NOTES COMPUT SC, V11206, P731, DOI 10.1007/978-3-030-01216-8_44
   Li C, 2019, IEEE T IMAGE PROCESS, V28, P4646, DOI 10.1109/TIP.2019.2912357
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395
   Pishchulin L, 2013, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2013.82
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Sun X, 2018, LECT NOTES COMPUT SC, V11210, P536, DOI 10.1007/978-3-030-01231-1_33
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tang ZQ, 2018, LECT NOTES COMPUT SC, V11207, P348, DOI 10.1007/978-3-030-01219-9_21
   Tian TP, 2010, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2010.5540227
   Tompson Jonathan, 2014, ARXIV14062984, DOI DOI 10.5555/2968826.2969027
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Xie CY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1639
   Yang W, 2017, IEEE I CONF COMP VIS, P1290, DOI 10.1109/ICCV.2017.144
   Yang Y., 2011, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, page, V1385-1392, P2011, DOI DOI 10.1109/CVPR.2011.5995741
   Zhang JT, 2018, IEEE T IMAGE PROCESS, V27, P4709, DOI 10.1109/TIP.2018.2836323
   Zhao R, 2019, PROC CVPR IEEE, P7725, DOI 10.1109/CVPR.2019.00792
NR 39
TC 1
Z9 1
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29251
EP 29265
DI 10.1007/s11042-021-10731-4
EA JUN 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000664818500001
DA 2024-07-18
ER

PT J
AU Ren, DK
   Wen, XM
   Chen, JZ
   Han, Y
   Zhang, SQ
AF Ren, Dakai
   Wen, Xiangmin
   Chen, Jiazhong
   Han, Yu
   Zhang, Shiqi
TI Multi-view facial action unit detection via DenseNets and CapsNets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial action unit; Facial expression recognition; Emotion recognition;
   CapsNets; DenseNets; Deep learning; Convolutional neural networks
ID EXPRESSION RECOGNITION
AB Though the standard convolutional neural networks (CNNs) have been proposed to increase the robustness of facial action unit (AU) detection regarding pose variations, it is hard to enhance detection performance because the standard CNNs are not robust enough to affine transformation. To address this issue, two novel architectures termed as AUCaps and AUCaps++ are proposed for multi-view and multi-label facial AU detection in this work. In these two architectures, one or more dense blocks and one capsule networks (CapsNets) are stacked. Specifically, The dense blocks prefixed before CapsNets are used to learn more discriminative high-level AU features, and the CapsNets is exploited to learn more view-invariant AU features. Moreover, the capsule types and digit capsule dimension are optimized to avoid the computation and storage burden caused by the dynamic routing in standard CapsNets. Because the AUCaps and AUCaps++ are trained by jointly optimizing multi-label loss of AU and reconstruction loss of viewpoint image, the proposed method could achieve high F1 score and learn human face roughly in the reconstruction images over different AUs. Numerical results of within-dataset and cross-dataset show that the average F1 scores of the proposed method outperform the competitors using hand-crafted features or deep learning features by a big margin on two public datasets.
C1 [Ren, Dakai; Wen, Xiangmin] Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing 100876, Peoples R China.
   [Chen, Jiazhong; Han, Yu; Zhang, Shiqi] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Huazhong University of
   Science & Technology
RP Chen, JZ (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM rendakai@bupt.edu.cn; jzchen@hust.edu.cn
FU Beijing Nova Program [Z201100006820123]; Beijing Municipal Science and
   Technology Commission; Natural Science Foundation of China [U1536203,
   61972169]; National key research and development program of China
   [2016QY01W0200]; Major Scientific and Technological Project of Hubei
   Province [2018AAA068, 2019AAA051]
FX This work was supported in part by the Beijing Nova Program
   (Z201100006820123) from Beijing Municipal Science and Technology
   Commission, in part by the Natural Science Foundation of China under
   Grant U1536203 and 61972169, in part by the National key research and
   development program of China (2016QY01W0200), in part by the Major
   Scientific and Technological Project of Hubei Province (2018AAA068 and
   2019AAA051).
CR Afshar P, 2018, IEEE IMAGE PROC, P3129, DOI 10.1109/ICIP.2018.8451379
   Almaev TR, 2013, INT CONF AFFECT, P356, DOI 10.1109/ACII.2013.65
   [Anonymous], 2018, CapsuleGAN: Generative Adversarial Capsule Network
   [Anonymous], 2017, Capsule Network Performance on Complex Data
   Baltrusaitis T, 2015, IEEE INT CONF AUTOMA
   Batista JC, 2017, IEEE INT CONF AUTOMA, P866, DOI 10.1109/FG.2017.111
   Benitez-Quiroz CF, 2016, PROC CVPR IEEE, P5562, DOI 10.1109/CVPR.2016.600
   Chu WS, 2017, IEEE INT CONF AUTOMA, P25, DOI 10.1109/FG.2017.13
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Ekman Paul, 1997, What the Face Reveals: Basic and Applied Studies of Spontaneous Expression using the Facial Action Coding System (FACS)
   Eleftheriadis S, 2015, IEEE I CONF COMP VIS, P3792, DOI 10.1109/ICCV.2015.432
   Ertugrul I, 2018, C COMP VIS PATT REC, P2130
   Gudi A., 2015, 2015 11 IEEE INT C W, V6, P1
   He J, 2017, IEEE INT CONF AUTOMA, P848, DOI 10.1109/FG.2017.108
   Hinton G.E., 2018, INT C LEARN REPR
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Kingma D. P., 2014, arXiv
   Koelstra S, 2010, IEEE T PATTERN ANAL, V32, P1940, DOI 10.1109/TPAMI.2010.50
   Lakshminarayana N, 2020, IEEE INT CONF AUTOMA, P465, DOI 10.1109/FG47880.2020.00128
   Li XR, 2017, IEEE INT CONF AUTOMA, P860, DOI 10.1109/FG.2017.110
   Li YQ, 2013, IEEE T AFFECT COMPUT, V4, P127, DOI 10.1109/T-AFFC.2013.5
   Liang LQ, 2021, IEEE T INF FOREN SEC, V16, P482, DOI 10.1109/TIFS.2020.3007327
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Mehrabian A., 1974, APPROACH ENV PSYCHOL, P222, DOI DOI 10.1016/J.ELERAP.2013.07.001
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Peng GZ, 2018, PROC CVPR IEEE, P2188, DOI 10.1109/CVPR.2018.00233
   Phaye SSR, 2018, ARXIV180504001
   Ruiz A, 2015, IEEE I CONF COMP VIS, P3703, DOI 10.1109/ICCV.2015.422
   Sabour S, 2017, ADV NEUR IN, V30
   Sánchez-Lozano E, 2016, LECT NOTES COMPUT SC, V9912, P645, DOI 10.1007/978-3-319-46484-8_39
   Senechal T, 2012, IEEE T SYST MAN CY B, V42, P993, DOI 10.1109/TSMCB.2012.2193567
   Shao ZW, 2018, LECT NOTES COMPUT SC, V11217, P725, DOI 10.1007/978-3-030-01261-8_43
   Tang CG, 2017, IEEE INT CONF AUTOMA, P878, DOI 10.1109/FG.2017.113
   Tosér Z, 2016, LECT NOTES COMPUT SC, V9915, P359, DOI 10.1007/978-3-319-49409-8_29
   Valstar MF, 2017, IEEE INT CONF AUTOMA, P839, DOI 10.1109/FG.2017.107
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P966, DOI 10.1109/TSMCB.2012.2200675
   Wang K, 2020, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR42600.2020.00693
   Wang YQ, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1165, DOI 10.1145/3178876.3186015
   Wang ZH, 2013, IEEE I CONF COMP VIS, P3304, DOI 10.1109/ICCV.2013.410
   Wu S, 2017, IEEE I CONF COMP VIS, P3971, DOI 10.1109/ICCV.2017.426
   Yang H, 2021, IEEE T MULTIMEDIA, V23, P572, DOI 10.1109/TMM.2020.2985536
   Yüce A, 2015, IEEE INT CONF AUTOMA
   Zhang FF, 2018, PROC CVPR IEEE, P3359, DOI 10.1109/CVPR.2018.00354
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
   Zhang Y, 2019, IEEE I CONF COMP VIS, P733, DOI 10.1109/ICCV.2019.00082
   Zhang Y, 2019, PROC CVPR IEEE, P3452, DOI 10.1109/CVPR.2019.00357
   Zhang Y, 2018, PROC CVPR IEEE, P7034, DOI 10.1109/CVPR.2018.00735
   Zhang Z, 2016, PROC CVPR IEEE, P3438, DOI 10.1109/CVPR.2016.374
   Zhao KL, 2016, PROC CVPR IEEE, P3391, DOI 10.1109/CVPR.2016.369
   Zhao KL, 2015, PROC CVPR IEEE, P2207, DOI 10.1109/CVPR.2015.7298833
NR 51
TC 0
Z9 0
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19377
EP 19394
DI 10.1007/s11042-021-11147-w
EA JUN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000663271700004
DA 2024-07-18
ER

PT J
AU Gupta, H
   Verma, OP
AF Gupta, Himanshu
   Verma, Om Prakash
TI Monitoring and surveillance of urban road traffic using low altitude
   drone images: a deep learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aerial image; CNN; Deep learning; Object detection; Traffic
   surveillance; UAV
ID OBJECT DETECTION; VISION
AB In the contemporary era, the global explosion of traffic has created many eye-catching concerns for policymakers. This not only enhances pollution but also leads to several road accident fatalities which may be greatly reduced by proper monitoring and surveillance. Further, with the advent of UAV technology and due to the incompatibility of traditional techniques, surveillance has become one of UAVs prominent application domains. However, it requires algorithmic analysis of aerial images which becomes extremely challenging due to multi-scale rotating objects with large aspect ratios, extremely imbalanced categories, cluttered background, and birds-eye view. Therefore, this article presents the novel aerial image traffic monitoring and surveillance algorithms based on the most advanced and popular DL object detection models (Faster-RCNN, SSD, YOLOv3, and YOLOv4) using the AU-AIR dataset. This dataset is exceedingly imbalanced and to resolve this issue, another 500 images have been grabbed by web-mining techniques. The novel contribution of this work is two-fold. First, this article scientifically distinguishes the inappropriateness of ground-view images for aerial object detection. Second, a regress comparison of these algorithms has been made to investigate their effectiveness. Extensive experimental analysis endorses the efficiency of YOLOv4 as it outperforms the other developed models by a minimum mAP margin of 88%. Also, more than 6 times high detection speed and greater adaptability with stronger detection robustness ensure its real-time practical implementation.
C1 [Gupta, Himanshu; Verma, Om Prakash] Dr BR Ambedkar Natl Inst Technol, Dept Instrumentat & Control Engn, Jalandhar, Punjab, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar
RP Verma, OP (corresponding author), Dr BR Ambedkar Natl Inst Technol, Dept Instrumentat & Control Engn, Jalandhar, Punjab, India.
EM guptah.nitj@gmail.com; vermaop@nitj.ac.in
RI Gupta, Himanshu/AAW-2278-2021; Verma, Om/AAD-1007-2019
OI Gupta, Himanshu/0000-0003-4799-5693; Verma, Om/0000-0002-7421-295X
FU Ministry of Human Resource Development, New Delhi, India; ISRO, India
FX The first author would like to thank the Ministry of Human Resource
   Development, New Delhi, India for providing the Research Fellowship for
   carrying out this work. The authors would also like to thank ISRO, India
   for providing the support time to time to carry out this area of
   research.
CR Al-Turjman F, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.3677
   Barmpounakis E.N., 2016, INT J TRANSP SCI TEC, V5, P111, DOI [DOI 10.1016/J.IJTST.2017.02.001, 10.1016/j.ijtst.2017.02.001]
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Benjdira B., 2019, CAR DETECTION USING
   Bonali FL, 2019, J STRUCT GEOL, V121, P46, DOI 10.1016/j.jsg.2019.02.004
   Bozcan I, 2020, IEEE INT CONF ROBOT, P8504, DOI [10.1109/ICRA40945.2020.9196845, 10.1109/icra40945.2020.9196845]
   Rangel JC, 2018, APPL SOFT COMPUT, V65, P603, DOI 10.1016/j.asoc.2018.02.005
   Chang FR, 2020, CHIN J TRAUMATOL, V23, P216, DOI 10.1016/j.cjtee.2020.06.001
   Choi Y, 2018, IEEE T INTELL TRANSP, V19, P934, DOI 10.1109/TITS.2018.2791533
   Chriki A, 2021, MULTIMED TOOLS APPL, V80, P2599, DOI 10.1007/s11042-020-09774-w
   Christiansen MP, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122703
   Dai JF, 2016, ADV NEUR IN, V29
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Gomaa A, 2020, MULTIMED TOOLS APPL, V79, P26023, DOI 10.1007/s11042-020-09242-5
   Gomez M., 2020, ISPRS J PHOTOGRAMM, V169, P110, DOI [10.1016/j.isprsjprs.2020.08.025, DOI 10.1016/J.ISPRSJPRS.2020.08.025]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hendry, 2019, IMAGE VISION COMPUT, V87, P47, DOI 10.1016/j.imavis.2019.04.007
   Hildmann H, 2019, DRONES-BASEL, V3, DOI 10.3390/drones3030059
   Karthik R, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105933
   Khan NA., 2020, Emerging use of UAV's: secure communication protocol issues and challenges, P37
   Khan NA, 2020, COMPUT COMMUN, V157, P434, DOI 10.1016/j.comcom.2020.04.049
   Kumar S, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10010014
   Li YD, 2020, CHINESE J AERONAUT, V33, P1747, DOI 10.1016/j.cja.2020.02.024
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mittal P, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104046
   Nie X, 2019, IEEE INT C INTELL TR, P47, DOI 10.1109/ITSC.2019.8917475
   Novak B, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P165, DOI [10.1109/zinc50678.2020.9161446, 10.1109/ZINC50678.2020.9161446]
   Park MW, 2017, MULTIMED TOOLS APPL, V76, P25343, DOI 10.1007/s11042-017-4521-4
   Pi YL, 2020, ADV ENG INFORM, V43, DOI 10.1016/j.aei.2019.101009
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rohan A, 2019, IEEE ACCESS, V7, P69575, DOI 10.1109/ACCESS.2019.2919332
   Sadykova D, 2020, IEEE T POWER DELIVER, V35, P1599, DOI 10.1109/TPWRD.2019.2944741
   Saleh M, 2020, INT CONF ADV COMMUN, P596, DOI [10.23919/icact48636.2020.9061508, 10.23919/ICACT48636.2020.9061508]
   Shastry AC, 2005, IEEE T INTELL TRANSP, V6, P391, DOI 10.1109/TITS.2005.858621
   Smitha JA, 2020, MULTIMED TOOLS APPL, V79, P18591, DOI 10.1007/s11042-020-08757-1
   Tian YN, 2019, COMPUT ELECTRON AGR, V157, P417, DOI 10.1016/j.compag.2019.01.012
   Tzutalin, 2015, LabelImg, Git Code
   Wang ZZ, 2020, MULTIMED TOOLS APPL, V79, P22083, DOI 10.1007/s11042-020-08807-8
   Wu DH, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105742
   Wu YW, 2017, IEEE ACCESS, V5, P23969, DOI 10.1109/ACCESS.2017.2764419
   Xu YZ, 2017, J ADV TRANSPORT, DOI 10.1155/2017/2823617
   Zhang J, 2020, NEUROCOMPUTING, V398, P555, DOI 10.1016/j.neucom.2019.03.102
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhu P., 2018, ECCVW, P1
NR 50
TC 33
Z9 33
U1 3
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19683
EP 19703
DI 10.1007/s11042-021-11146-x
EA JUN 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000661795700001
DA 2024-07-18
ER

PT J
AU Williamson, S
   Vijayakumar, K
   Kadam, VJ
AF Williamson, Sheldon
   Vijayakumar, K.
   Kadam, Vinod J.
TI Predicting breast cancer biopsy outcomes from BI-RADS findings using
   random forests with chi-square and MI features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Biopsy; BI-RADS; Random forests; Chi-square test; Mutual
   information
ID NEURAL-NETWORK; REASONING CLASSIFIER; SYSTEM
AB To look for early breast cancer signs and indications, mammography screening is one of the best approaches available. Screening mammograms are the most commonly recognized procedure and remain the gold standard for early breast cancer screening. But many times, a relatively low positive predictive rate of breast biopsy demonstrated by this diagnostic technique leads to unneeded biopsies for abnormal findings that are ultimately proven benign in many cases. Random Forest (RF)-which evolves from Decision Trees (DTs)-is one of the most practical and powerful ensemble learning concepts (or meta estimators). Breast Imaging Reporting and Data System (BI-RADS) is developed as a standardized system or tool for reporting breast mammograms. This technique is used to locate unusual findings into groups. In this study, the RF classifier with Chi-Square (chi(2)) and Mutual Information (MI) procedures of relevant Feature Selection (FS) has been applied successfully, in an attempt to predict cancer biopsy outcomes from BI-RAD findings and the patient's age. For validation purposes, the UCI Mammographic Mass dataset has been used and assessed using accuracy, AUC, and several other performance criteria through a 10-fold CV approach. The prediction findings from the proposed method were very encouraging (84.70% accuracy and AUC 0.9023). Similarly, the proposed system gave better results in terms of MCC and F1-score. The results were directly compared with the RF classifiers and other state-of-the-art classification methods. This comparative analysis indicates that the proposed model is superior in terms of various efficiency indicators to the RF classifier and all standard models used in the study. These findings also confirm that the chi(2) and MI FS approaches correctly as well as efficiently obtained the relevant and discriminating feature subset. The result also points out that the suggested approach is a comparable approach to different classification models present in the relevant literature. It is an advantageous, practical, and sound method to predict cancer biopsy outcomes.
C1 [Williamson, Sheldon] OntarioTech Univ, Fac Engn & Appl Sci, Oshawa, ON, Canada.
   [Vijayakumar, K.] St Josephs Inst Technol, Dept Comp Sci & Engn, OMR, Chennai, Tamil Nadu, India.
   [Kadam, Vinod J.] Dr Babasaheb Ambedkar Technol Univ, Dept Informat Technol, Lonere, Maharashtra, India.
C3 Dr. Babasaheb Ambedkar Technological University
RP Williamson, S (corresponding author), OntarioTech Univ, Fac Engn & Appl Sci, Oshawa, ON, Canada.
EM sheldon.williamson@ieee.org; mkvijay@msn.com; vjkadam@dbatu.ac.in
RI K, VIJAYAKUMAR/I-6554-2019; Kadam, VJ/ABS-6090-2022
OI K, VIJAYAKUMAR/0000-0002-5379-5703; Kadam, VJ/0000-0003-4798-7984
CR A. C. of Radiology (ACR), 2003, BREAST IMAGING REPOR
   Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545
   BAKER JA, 1995, RADIOLOGY, V196, P817, DOI 10.1148/radiology.196.3.7644649
   Bakirarar, 2019, TURKIYE KLIN J BIOST, V11
   Bethapudi P., 2015, INT J COMPUTER APPL, V975, P8887
   Bhat VH, 2011, COMM COM INF SC, V192, P522
   Bilska AO, 2001, PROC SPIE, V4322, P1862, DOI 10.1117/12.431077
   Bilska-Wolak AO, 2002, MED PHYS, V29, P2090, DOI 10.1118/1.1501140
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   D'Orsi C., 2018, Breast imaging reporting and data system (bi-rads)
   Dua, 2019, UCI MACHINE LEARNING
   Elsayad Alaa M., 2010, Journal of Computer Sciences, V6, P576, DOI 10.3844/jcssp.2010.576.584
   Elter M, 2007, MED PHYS, V34, P4164, DOI 10.1118/1.2786864
   Eltieb MA., 2018, THEIS SUDAN U SCI TE
   Fischer EA, 2004, P ANN INT IEEE EMBS, V26, P3031
   Floyd CE, 2000, AM J ROENTGENOL, V175, P1347, DOI 10.2214/ajr.175.5.1751347
   Gastounioti A, 2019, RADIOLOGY, V291, P319, DOI 10.1148/radiol.2019181740
   Halawani S, 2012, STUDY DIGITAL MAMMOG
   Hassim YMM, 2015, INT WORKSH NEUR NETW, P213
   Heine JJ, 1997, IEEE T MED IMAGING, V16, P503, DOI 10.1109/42.640740
   Huang ML, 2012, J MED SYST, V36, P407, DOI 10.1007/s10916-010-9485-0
   Ibrikci Turgay, 2016, International Conference on Information Science and Applications (ICISA) 2016. LNEE 376, P933, DOI 10.1007/978-981-10-0557-2_89
   Karssemeijer N., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P1357, DOI 10.1142/S0218001493000662
   Kaushik D, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION PROCESSING, DATA MINING, AND WIRELESS COMMUNICATIONS (DIPDMWC), P40, DOI 10.1109/DIPDMWC.2016.7529361
   Kaya, 2013, GLOBAL J TECHNOLOGY, V4
   Kharya S., 2014, IJARCCE, V3, P5423
   Kozachenko L. F., 1987, Problems of Information Transmission, V23, P95
   Kraskov A, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.066138
   Kumar G., 2014, International Journal of Advanced Research in Computer Science and Software Engineering, V2, P272
   Lairenjam B., 2010, 2010 International Conference on Educational and Network Technology (ICENT 2010), P276, DOI 10.1109/ICENT.2010.5532173
   Lairenjam B, 2010, INT J OPEN PROBLEMS, V3
   Lairenjam B, 2009, LECT NOTES COMPUT SC, V5788, P465, DOI 10.1007/978-3-642-04394-9_57
   Liberman L, 2002, RADIOL CLIN N AM, V40, P409, DOI 10.1016/S0033-8389(01)00017-3
   Liberman N., 2017, Decision Trees and Random Forests
   Ludwig S, 2010, IHI 10 P 1 ACM INT H, P694
   Luo ST, 2012, J MED SYST, V36, P569, DOI 10.1007/s10916-010-9518-8
   Malmartel A, 2019, EUR J OBSTET GYN R B, V237, P1, DOI 10.1016/j.ejogrb.2019.04.003
   Markey MK, 2002, COMPUT BIOL MED, V32, P99, DOI 10.1016/S0010-4825(01)00035-X
   Mokhtar SA, 2013, ARXIV PREPRINT ARXIV
   Music L., 2019, INT C MEDICAL BIOLOG, P775
   Nilashi M, 2017, TELEMAT INFORM, V34, P133, DOI 10.1016/j.tele.2017.01.007
   Nithya R, 2015, INT J SIGNAL IMAGING, V8, P39, DOI 10.1504/IJSISE.2015.067068
   Novakovic J., 2011, 2011 6th IEEE International Symposium on Applied Computational Intelligence and Informatics (SACI), P571, DOI 10.1109/SACI.2011.5873068
   Nugroho Kuntoro Adi, 2013, 2013 International Conference on Information Technology and Electrical Engineering (ICITEE), P57, DOI 10.1109/ICITEED.2013.6676211
   Priebe C, 1994, NONPARAMETRIC SPATIO
   Rakowski W, 1998, AM J PREV MED, V15, P187, DOI 10.1016/S0749-3797(98)00048-8
   Rathi V, 2014, IEEE INT ADV COMPUT, P1307, DOI 10.1109/IAdCC.2014.6779516
   Ross BC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0087357
   Saritas I, 2012, J MED SYST, V36, P2901, DOI 10.1007/s10916-011-9768-0
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Sondakh, 2017, COGITO SMART J, V3, P10, DOI [10.31154/cogito.v3i1.40.10-19, DOI 10.31154/COGITO.V3I1.40.10-19]
   The Python Standard Library, PYTHON 392 DOCUMENTA
   Nguyen TT, 2017, STAT PAP, V58, P211, DOI 10.1007/s00362-015-0694-y
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520
   Yan YT, 2017, INT J MACH LEARN CYB, V8, P1513, DOI 10.1007/s13042-016-0524-0
   Zahriah S, 2017, P 8 INT C AGR BIOL E
NR 58
TC 14
Z9 14
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 36869
EP 36889
DI 10.1007/s11042-021-11114-5
EA JUN 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000658077800006
DA 2024-07-18
ER

PT J
AU Zhang, BX
   Liu, ML
   Zhou, B
   Liu, XY
AF Zhang, Beixian
   Liu, Meiling
   Zhou, Bo
   Liu, Xingyi
TI Graph learning in low dimensional space for graph convolutional networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE GCNs; Graph learning; Dimension reduction
AB Graph Convolutional Networks (GCNs) recently have been adopted in several feature representation studies for different classification tasks. While many of these methods are used to work with irregular structure data, they are rarely used to learn regular structure data. It is crucial to construct an excellent graph representation to traditional classification tasks for obtaining the sufficient data representation, including attribute representation and relative representation. In this context, we propose a novel method to construct a reasonable graph representation by capturing the relations in low dimensional space among the data. In order to get the well-represented, we introduce the low-rank constraint and L2-norm regularization to the graph learning framework simultaneously. Experiments demonstrate that the proposed method to learn graph representation is helpful for classification task, and leads to improved performance when compared to state-of-the-art graph learning methods on twelve data sets.
C1 [Zhang, Beixian; Liu, Meiling; Zhou, Bo] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Guangxi, Peoples R China.
   [Liu, Meiling] GuangXi Univ Nationalities, Coll Artificial Intelligence, Nanning 530006, Guangxi, Peoples R China.
   [Liu, Xingyi] Guangxi Vocat & Tech Inst Ind, Sch Elect & Informat, Nanning, Guangxi, Peoples R China.
C3 Guangxi Normal University; Guangxi Minzu University
RP Liu, ML (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Guangxi, Peoples R China.; Liu, XY (corresponding author), Guangxi Vocat & Tech Inst Ind, Sch Elect & Informat, Nanning, Guangxi, Peoples R China.
EM bolleay@163.com; lml97@126.com; zhoubo1114@163.com; qzk@163.com
RI Yang, Shu/JUU-4592-2023; Zhang, Shiwei/JIY-4344-2023; wang,
   jiajun/JRW-6032-2023
FU Innovation Project of Guangxi Graduate Education; Research Fund of
   Guangxi Key Lab of Multi-source Information Mining Security
   [MIMS19-M-02]; Key Laboratory of Software Engineering in Guangxi
   University for Nationalities [2019-18XJSY-03]; National Natural Science
   Foundation of China [62062011]; Guangxi Natural Science Foundation
   [2017GXNSFAA198008]; Guangxi Key Laboratory of Hybrid Computation and IC
   Design Analysis [GXIC20-06]; Basic Competence Promotion Project for
   Young and Middle-aged Teachers in Guangxi Education Department
   [2017KY0176]
FX This work is supported by Innovation Project of Guangxi Graduate
   Education, Basic Competence Promotion Project for Young and Middle-aged
   Teachers in Guangxi Education Department (No. 2017KY0176), Research Fund
   of Guangxi Key Lab of Multi-source Information Mining & Security (No.
   MIMS19-M-02), Key Laboratory of Software Engineering in Guangxi
   University for Nationalities (No.2019-18XJSY-03), National Natural
   Science Foundation of China under Grant No. 62062011, Guangxi Natural
   Science Foundation under Grant No. 2017GXNSFAA198008 and Open Fund Grant
   No. GXIC20-06 of Guangxi Key Laboratory of Hybrid Computation and IC
   Design Analysis.
CR Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bruna J., 2014, ABS13126203 CORR, P1, DOI [10.48550/arXiv.1312.6203, DOI 10.48550/ARXIV.1312.6203]
   Burges CJC, 2010, FOUND TRENDS MACH LE, V2, P275, DOI 10.1561/2200000002
   Chung F. R. K., 1997, Spectral graph theory
   Defferrard M, 2016, ADV NEUR IN, V29
   Duvenaudt D, 2015, ADV NEUR IN, V28
   FAN K, 1949, P NATL ACAD SCI USA, V35, P652, DOI 10.1073/pnas.35.11.652
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hu RY, 2020, WORLD WIDE WEB, V23, P1945, DOI 10.1007/s11280-019-00766-x
   Jiang B, 2019, PROC CVPR IEEE, P11305, DOI 10.1109/CVPR.2019.01157
   Kingma D. P., 2014, arXiv
   Kipf TN, 2017, INT C LEARN REPR
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491, DOI 10.1109/TKDE.2005.66
   Luo, 2019, 2019 IEEE CVF C COMP
   Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576
   Nie FP, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-016-9021-9
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1969
   Nie FP, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P977, DOI 10.1145/2623330.2623726
   Sermanet P, 2012, INT C PATT RECOG, P3288
   Shen HT, 2021, IEEE T NEUR NET LEAR, V32, P3122, DOI 10.1109/TNNLS.2020.3009632
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Vavasis, 1997, J ACM
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Zhang, 2020, ROBUSTGCNS ROBUST NO
   Zhu XF, 2020, WORLD WIDE WEB, V23, P1969, DOI 10.1007/s11280-019-00731-8
   Zhu XY, 2022, INT J PAVEMENT ENG, V23, P784, DOI 10.1080/10298436.2020.1774587
NR 30
TC 2
Z9 2
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34263
EP 34279
DI 10.1007/s11042-021-11033-5
EA MAY 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000655825400005
DA 2024-07-18
ER

PT J
AU Kalyani, R
   Sathya, PD
   Sakthivel, VP
AF Kalyani, R.
   Sathya, P. D.
   Sakthivel, V. P.
TI Multilevel thresholding for image segmentation with exchange market
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tsallis; Renyi; Multilevel thresholding; Exchange market algorithm;
   Image segmentation; Particle swarm optimisation
ID CUCKOO SEARCH ALGORITHM; MINIMUM CROSS-ENTROPY; EMISSION DISPATCH; 2D
   HISTOGRAM; ENERGY
AB Image segmentation is the prime factor to elicit the detailed investigation of an image. The desired information from an image can be easily obtained through the intuitive technique called thresholding. In this technique, detailed analysis of different classes of an image is realised through Multilevel Thresholding (MLT). Accurate and ideal threshold values achieved by non-parametric objective functions such as Tsallis and Renyi are briefed in this paper. The non-additive property of Tsallis and entropic threshold selection property of Renyi drive to search the global threshold value precisely. Higher the segmentation level more is the computational time for exploration of optimal threshold with Tsallis and Renyi. This challenge is countered by MLT based Tsallis and Renyi, aided with Exchange Market Algorithm (EMA). Several research on nature- inspired algorithms such as Bacterial Foraging (BF), Particle Swarm Optimisation (PSO) and Genetic Algorithm (GA) are carried out. For the first time, this paper proposes a powerful metaheuristic EMA technique for image segmentation, which implements the strategies of shareholders in stable and unstable mode to earn profit. The cognizance of the shareholders is extracted to attain the desired goal to reach the global threshold avoiding premature convergence. Empirical outcome of the results indicate that outstanding tuning search is achieved by EMA compared to extensive search techniques such as PSO, BF and GA. Exploration and exploitation assessment by metrics such as stability, computational efficiency, Peak Signal to Noise Ratio (PSNR), uniformity measure and Wilcoxon rank sum test affirm the Tsallis and Renyi based EMA surpass the existing techniques to analyse the real-world images.
C1 [Kalyani, R.] Annamalai Univ, Dept Elect & Commun Engn, Chidambaram 608002, Tamil Nadu, India.
   [Sathya, P. D.] Annamalai Univ, Dept Elect & Commun Engn, Fac Engn & Technol, Chidambaram 608002, Tamil Nadu, India.
   [Sakthivel, V. P.] Govt Coll Engn, Dept Elect & Elect Engn, Dharmapuri 636704, Tamil Nadu, India.
C3 Annamalai University; Annamalai University
RP Kalyani, R (corresponding author), Annamalai Univ, Dept Elect & Commun Engn, Chidambaram 608002, Tamil Nadu, India.
EM harebalu@gmail.com; pd.sathya@yahoo.in; vp.sakthivel@yahoo.com
RI P D, SATHYA/AAZ-8434-2021; Sakthivel, V P/AAE-5661-2022
OI Sakthivel, V P/0000-0002-2720-0200; P D, SATHYA/0000-0003-2404-2566
CR Abd Elaziz M, 2019, EXPERT SYST APPL, V125, P112, DOI 10.1016/j.eswa.2019.01.047
   Ben Ishak A, 2017, APPL SOFT COMPUT, V52, P306, DOI 10.1016/j.asoc.2016.10.034
   Bhandari AK, 2016, EXPERT SYST APPL, V63, P112, DOI 10.1016/j.eswa.2016.06.044
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P8707, DOI 10.1016/j.eswa.2015.07.025
   Bhandari AK, 2014, EXPERT SYST APPL, V41, P3538, DOI 10.1016/j.eswa.2013.10.059
   Borjigin S, 2019, PATTERN RECOGN, V92, P107, DOI 10.1016/j.patcog.2019.03.011
   de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5
   Gao H, 2018, COMPUT ELECTR ENG, V70, P931, DOI 10.1016/j.compeleceng.2017.12.037
   Gao H, 2010, IEEE T INSTRUM MEAS, V59, P934, DOI 10.1109/TIM.2009.2030931
   Ghorbani N, 2018, INT J MANAG SCI ENG, V13, P175, DOI 10.1080/17509653.2017.1365262
   Ghorbani N, 2017, PROCEDIA COMPUT SCI, V120, P633, DOI 10.1016/j.procs.2017.11.289
   Ghorbani N, 2016, INT J ELEC POWER, V82, P58, DOI 10.1016/j.ijepes.2016.03.004
   Ghorbani N, 2016, INT J ELEC POWER, V75, P19, DOI 10.1016/j.ijepes.2015.08.013
   Ghorbani N, 2014, APPL SOFT COMPUT, V19, P177, DOI 10.1016/j.asoc.2014.02.006
   Gill HS, 2019, EGYPT INFORM J, V20, P11, DOI 10.1016/j.eij.2018.03.006
   Han J, 2017, APPL MATH MODEL, V44, P588, DOI 10.1016/j.apm.2017.02.015
   He LF, 2017, NEUROCOMPUTING, V240, P152, DOI 10.1016/j.neucom.2017.02.040
   Jiang YZ, 2016, INFORM SCIENCES, V369, P171, DOI 10.1016/j.ins.2016.06.020
   Kurban T, 2014, APPL SOFT COMPUT, V23, P128, DOI 10.1016/j.asoc.2014.05.037
   Lei B, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106588
   Li JF, 2019, OPTIK, V183, P30, DOI 10.1016/j.ijleo.2019.02.004
   Li JF, 2018, SIGNAL PROCESS, V147, P80, DOI 10.1016/j.sigpro.2018.01.022
   Li YY, 2017, APPL SOFT COMPUT, V56, P345, DOI 10.1016/j.asoc.2017.03.018
   Mittal H, 2018, ENG APPL ARTIF INTEL, V71, P226, DOI 10.1016/j.engappai.2018.03.001
   Mlakar U, 2016, EXPERT SYST APPL, V65, P221, DOI 10.1016/j.eswa.2016.08.046
   Nair, 2018, J KING SAND U COMPUT, DOI [10.1016/j.jksuci.2018.04.007, DOI 10.1016/J.JKSUCI.2018.04.007]
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Pare S, 2018, COMPUT ELECTR ENG, V70, P476, DOI 10.1016/j.compeleceng.2017.08.008
   Pare S, 2017, APPL SOFT COMPUT, V61, P570, DOI 10.1016/j.asoc.2017.08.039
   Pare S, 2017, EXPERT SYST APPL, V87, P335, DOI 10.1016/j.eswa.2017.06.021
   Rajan A, 2016, INT J ELEC POWER, V82, P545, DOI 10.1016/j.ijepes.2016.04.022
   Sakthivel, 2013, HELV CHIM ACTA, P53, DOI [10.1007/978-81-322-1035-1_6., DOI 10.1007/978-81-322-1035-1_6]
   Sarkar S, 2016, EXPERT SYST APPL, V50, P120, DOI 10.1016/j.eswa.2015.11.016
   Sarkar S, 2015, PATTERN RECOGN LETT, V54, P27, DOI 10.1016/j.patrec.2014.11.009
   Sathya PD, 2011, ENG APPL ARTIF INTEL, V24, P595, DOI 10.1016/j.engappai.2010.12.001
   Sohrabi F, 2018, ENERG BUILDINGS, V169, P245, DOI 10.1016/j.enbuild.2018.03.077
   Srikanth R, 2021, AIN SHAMS ENG J, V12, P1, DOI 10.1016/j.asej.2020.09.003
   Sun GY, 2016, APPL SOFT COMPUT, V46, P703, DOI 10.1016/j.asoc.2016.01.054
   Suresh S, 2016, EXPERT SYST APPL, V58, P184, DOI 10.1016/j.eswa.2016.03.032
   Wang ST, 2005, PATTERN RECOGN LETT, V26, P2309, DOI 10.1016/j.patrec.2005.03.027
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Wunnava A, 2022, J KING SAUD UNIV-COM, V34, P3011, DOI 10.1016/j.jksuci.2020.05.001
NR 43
TC 7
Z9 7
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27553
EP 27591
DI 10.1007/s11042-021-10909-w
EA MAY 2021
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000652939000001
DA 2024-07-18
ER

PT J
AU Luo, DL
   Du, SL
   Ikenaga, T
AF Luo, Dingli
   Du, Songlin
   Ikenaga, Takeshi
TI Multi-task neural network with physical constraint for real-time
   multi-person 3D pose estimation from monocular camera
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D human pose estimation; Convolutional neural network; Multi-task
   learning; Real-time processing
AB 3D human pose estimation has many important applications in human-computer interaction and human action recognition. Simultaneously achieving real-time speed, varying human number, and high accuracy from a single RGB image is a challenging problem. To this end, this paper proposes a multi-task and multi-level neural network structure with physical constraint. The unique network structure estimates 3D human poses from single RGB image in an end-to-end way and achieves both high accuracy and high speed. Experimental results shows that the proposed system achieves 21 fps on RTX 2080 GPU with only 33 mm accuracy loss compared with conventional works. The mechanism of the network is also analyzed through network visualization. This work shows the possibility of estimating 3D human pose from a single RGB monocular camera with real-time speed.
C1 [Luo, Dingli; Ikenaga, Takeshi] Waseda Univ, Grad Sch Informat Prod & Syst, Kitakyushu, Fukuoka 8080135, Japan.
   [Du, Songlin] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
   [Du, Songlin] Southeast Univ, Shenzhen Inst, Shenzhen 518063, Peoples R China.
   [Du, Songlin] Hubei Key Lab Adv Control & Intelligent Automat C, Wuhan 430074, Peoples R China.
   [Du, Songlin] Minist Educ, Engn Res Ctr Intelligent Geodetect Technol, Wuhan 430074, Peoples R China.
C3 Waseda University; Southeast University - China; Southeast University -
   China
RP Du, SL (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.; Du, SL (corresponding author), Southeast Univ, Shenzhen Inst, Shenzhen 518063, Peoples R China.; Du, SL (corresponding author), Hubei Key Lab Adv Control & Intelligent Automat C, Wuhan 430074, Peoples R China.; Du, SL (corresponding author), Minist Educ, Engn Res Ctr Intelligent Geodetect Technol, Wuhan 430074, Peoples R China.
EM sdu@seu.edu.cn
FU Waseda University Grant for Special Research Projects [2020C-657,
   2020R-040]; National Natural Science Foundation of China [62001110];
   Natural Science Foundation of Jiangsu Province [BK20200353]; Guangdong
   Basic and Applied Basic Research Foundation [2020A1515110145]; Shenzhen
   Science and Technology Program [RCBS20200714114858072]; 111 Project
   [B17040]; Fundamental Research Funds for the Central Universities
   [2242021R10115]; Grants-in-Aid for Scientific Research [21K11816]
   Funding Source: KAKEN
FX This work was jointly supported by the Waseda University Grant for
   Special Research Projects under grants 2020C-657 and 2020R-040, the
   National Natural Science Foundation of China under grant 62001110, the
   Natural Science Foundation of Jiangsu Province under grant BK20200353,
   the Guangdong Basic and Applied Basic Research Foundation under grant
   2020A1515110145, the Shenzhen Science and Technology Program under grant
   RCBS20200714114858072, the 111 Project under grant B17040, and the
   Fundamental Research Funds for the Central Universities under grant
   2242021R10115.
CR Blumenthal-Barby DC, 2014, COMPUT GRAPH-UK, V39, P89, DOI 10.1016/j.cag.2013.12.001
   Cao SS, 2016, AAAI CONF ARTIF INTE, P1145
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chen CH, 2019, PROC CVPR IEEE, P5707, DOI 10.1109/CVPR.2019.00586
   Chen X., 2014, Advances in neural information processing systems, P1736, DOI DOI 10.1109/CVPR.2018.00742
   Cheng BW, 2020, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR42600.2020.00543
   Cheng Y, 2019, IEEE I CONF COMP VIS, P723, DOI 10.1109/ICCV.2019.00081
   Dai-xian Z., 2010, 2010 2nd International Workshop on Intelligent Systems and Applications, P1
   Drennan M, 2010, IMPLEMENTATION CAMER
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kocabas M, 2019, PROC CVPR IEEE, P1077, DOI 10.1109/CVPR.2019.00117
   Li Z, 2019, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2019.00228
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   LUO D, 2019, INT C MACH VIS APPL
   Luo DL, 2019, ASIAPAC SIGN INFO PR, P1427, DOI [10.1109/apsipaasc47483.2019.9023084, 10.1109/APSIPAASC47483.2019.9023084]
   Martinez Julieta, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2659, DOI 10.1109/ICCV.2017.288
   Mehta D, 2018, INT CONF 3D VISION, P120, DOI 10.1109/3DV.2018.00024
   Nie XC, 2018, LECT NOTES COMPUT SC, V11209, P705, DOI 10.1007/978-3-030-01228-1_42
   Omran M, 2018, INT CONF 3D VISION, P484, DOI 10.1109/3DV.2018.00062
   Pavllo D, 2019, PROC CVPR IEEE, P7745, DOI 10.1109/CVPR.2019.00794
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Rogez G, 2017, PROC CVPR IEEE, P1216, DOI 10.1109/CVPR.2017.134
   Sharifi A, 2014, 2014 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P135, DOI 10.1109/ICCKE.2014.6993366
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Vatahska T, 2007, IEEE-RAS INT C HUMAN, P330, DOI 10.1109/ICHR.2007.4813889
   Waleed A, 2017, GITHUB REPOSITORY
   Xiu Y., 2018, BMVC
   Xu JW, 2020, PROC CVPR IEEE, P896, DOI 10.1109/CVPR42600.2020.00098
   Zhang Z, 2020, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR42600.2020.00227
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhou XW, 2016, PROC CVPR IEEE, P4966, DOI 10.1109/CVPR.2016.537
NR 33
TC 5
Z9 5
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27223
EP 27244
DI 10.1007/s11042-021-10982-1
EA MAY 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000650816400004
DA 2024-07-18
ER

PT J
AU Salamaa, WM
   Aly, MH
AF Salamaa, Wessam M.
   Aly, Moustafa H.
TI Deep learning design for benign and malignant classification of skin
   lesions: a new approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin Cancer; Deep learning; Support vector machine; ResNet50; Transfer
   learning
ID NEURAL-NETWORKS; IMPLEMENTATION; SEGMENTATION; EFFICIENT; MELANOMA
AB ResNet50 and VGG-16 models are introduced in this paper with different strategies, with and without preprocessing and with and without Support Vector Machine (SVM). Moreover, both transfer learning and data augmentation are used to solve the problem of lack of tagged data. The fully connected (FC) layer is replaced by the SVM classifier leading to better accuracy. In addition, in our work, we utilize the median filter, contrast enhancement and edge detection, which based on four main steps: noise removal, gradient smoothed image calculations, non-highest suppression and hysteresis thresholding. Also, the k-fold cross validation is performed to authenticate our model's performance. Three data sets: ISIC 2017 MNIST-HAM10000 and ISBI 2016 are utilized in our proposed work. It is observed that the proposed technique of employing ResNet50 hybridized with SVM achieves the best performance, specifically with the ISIC2017 dataset, producing 99.19% accuracy, 99.32% area under the curve (AUC), 98.98% sensitivity, 98.78% precision, 98.88% F1 score and 2.6988 s computational time.
C1 [Salamaa, Wessam M.] Pharos Univ, Fac Engn, Dept Basic Sci, Alexandria, Egypt.
   [Aly, Moustafa H.] Arab Acad Sci Technol & Maritime Transport, Coll Engn & Technol, Dept Elect & Commun Engn, Alexandria, Egypt.
C3 Egyptian Knowledge Bank (EKB); Pharos University in Alexandria; Egyptian
   Knowledge Bank (EKB); Arab Academy for Science, Technology & Maritime
   Transport
RP Aly, MH (corresponding author), Arab Acad Sci Technol & Maritime Transport, Coll Engn & Technol, Dept Elect & Commun Engn, Alexandria, Egypt.
EM wessam.salama@pua.edu.eg; mosaly@aast.edu
RI Aly, Moustafa H./I-9205-2018
OI Aly, Moustafa H./0000-0003-1966-3755
CR Abbas Q, 2016, COMPUTERS, V5, DOI 10.3390/computers5030013
   Albahar MA, 2019, IEEE ACCESS, V7, P38306, DOI 10.1109/ACCESS.2019.2906241
   [Anonymous], 2018, Revista Brasileira de Cancerologia, V64, P119, DOI DOI 10.32635/2176-9745.RBC.2018V64N1.115
   [Anonymous], 2017, arXiv preprint arXiv:1703.03108
   Pham BT, 2019, B ENG GEOL ENVIRON, V78, P2865, DOI 10.1007/s10064-018-1281-y
   Brinker TJ, 2018, J MED INTERNET RES, V20, DOI 10.2196/11936
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cervantes J, 2020, NEUROCOMPUTING, V408, P189, DOI 10.1016/j.neucom.2019.10.118
   Dalila F, 2017, OPTIK, V140, P749, DOI 10.1016/j.ijleo.2017.04.084
   Demyanov S, 2016, I S BIOMED IMAGING, P364, DOI 10.1109/ISBI.2016.7493284
   Eltrass AS, 2020, IET IMAGE PROCESS, V14, P495, DOI 10.1049/iet-ipr.2018.5953
   Feng XJ, 2019, SIGNAL IMAGE VIDEO P, V13, P959, DOI 10.1007/s11760-019-01433-4
   Firoz R., 2016, Journal of Data Analysis and Information Processing, V4, P1, DOI DOI 10.4236/JDAIP.2016.41001
   Hopkins ZH, 2019, AM J HEALTH PROMOT, V33, P611, DOI 10.1177/0890117118811754
   HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188
   ISIS, ARCH EL RES
   K. Inc, 2019, SKIN CANC MNIST HAM1
   Kasmi R, 2016, IET IMAGE PROCESS, V10, P448, DOI 10.1049/iet-ipr.2015.0385
   Kebede TM., 2018, ARXIV180707001EESSIV
   Khan MA, 2018, BMC CANCER, V18, DOI 10.1186/s12885-018-4465-8
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P293, DOI 10.1016/j.patrec.2019.11.034
   Mahbod A, 2019, INT CONF ACOUST SPEE, P1229, DOI [10.1109/ICASSP.2019.8683352, 10.1109/icassp.2019.8683352]
   Majtner T, 2016, INT CONF IMAG PROC, DOI 10.1109/IPTA.2016.7821017
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Rembielak A, 2019, CLIN ONCOL-UK, V31, P735, DOI 10.1016/j.clon.2019.08.013
   Salama MS, 2018, IEEE INT SYM MED MEA, P526
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Serte S, 2019, COMPUT BIOL MED, V113, DOI 10.1016/j.compbiomed.2019.103423
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Sofaer HR, 2019, METHODS ECOL EVOL, V10, P565, DOI 10.1111/2041-210X.13140
   Srinivasan K, 2019, J INTERNET TECHNOL, V20, P1213, DOI 10.3966/160792642019072004020
   Tschandl P, 2019, LANCET ONCOL, V20, P938, DOI 10.1016/S1470-2045(19)30333-X
   Vasconcelos CN, 2020, PATTERN RECOGN LETT, V139, P95, DOI 10.1016/j.patrec.2017.11.005
   Yilmaz E., 2020, LECT NOTES COMPUTER, V12033
   Yoshida T, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P3439, DOI 10.1109/BigData.2016.7841005
   Yu DJ, 2014, LECT NOTES ARTIF INT, V8818, P364, DOI 10.1007/978-3-319-11740-9_34
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Yüksel ME, 2009, IEEE T FUZZY SYST, V17, P976, DOI 10.1109/TFUZZ.2009.2018300
   Zhang JB, 2020, IEEE T KNOWL DATA EN, V32, P468, DOI [10.1109/TMI.2019.2893944, 10.1109/TKDE.2019.2891537]
NR 40
TC 6
Z9 6
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26795
EP 26811
DI 10.1007/s11042-021-11000-0
EA MAY 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000648376500002
DA 2024-07-18
ER

PT J
AU Ren, ZL
   Zhang, QS
   Gao, XY
   Hao, PY
   Cheng, J
AF Ren, Ziliang
   Zhang, Qieshi
   Gao, Xiangyang
   Hao, Pengyi
   Cheng, Jun
TI Multi-modality learning for human action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-modality; Human action recognition; Rank pooling; Convolutional
   networks (ConvNets)
ID RGB-D; FEATURES
AB The multi-modality based human action recognition is an increasing topic. Multi-modality can provide more abundant and complementary information than single modality. However, it is difficult for multi-modality learning to capture the spatial-temporal information from the entire RGB and depth sequence effectively. In this paper, to obtain better representation of spatial-temporal information, we propose a bidirectional rank pooling method to construct the RGB Visual Dynamic Images (VDIs) and Depth Dynamic Images (DDIs). Furthermore, we design an effective segmentation convolutional networks (ConvNets) architecture based on multi-modality hierarchical fusion strategy for human action recognition. The proposed method has been verified and achieved the state-of-the-art results on the widely used NTU RGB+D, SYSU 3D HOI and UWA3D II datasets.
C1 [Ren, Ziliang; Zhang, Qieshi; Gao, Xiangyang; Cheng, Jun] Chinese Acad Sci, Shenzhen Inst Adv Technol, CAS Key Lab Human Machine Intelligence Synergy Sy, Shenzhen, Peoples R China.
   [Ren, Ziliang; Zhang, Qieshi; Gao, Xiangyang; Cheng, Jun] Chinese Univ Hong Kong, Hong Kong, Peoples R China.
   [Hao, Pengyi] Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; Chinese University of Hong Kong; Zhejiang University of Technology
RP Cheng, J (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, CAS Key Lab Human Machine Intelligence Synergy Sy, Shenzhen, Peoples R China.; Cheng, J (corresponding author), Chinese Univ Hong Kong, Hong Kong, Peoples R China.
EM jun.cheng@siat.ac.cn
RI gao, xiangyang/JLL-7276-2023
OI Ren, Ziliang/0000-0001-7940-294X
CR Asadi-Aghbolaghi M, 2018, MULTIMED TOOLS APPL, V77, P14115, DOI 10.1007/s11042-017-5017-y
   Aydin R, 2014, IN C IND ENG ENG MAN, P1, DOI 10.1109/IEEM.2014.7058588
   Baradel Fabien., 2018, Proc. Brit. Mach. Vis. Conf, P1
   Bilen H, 2016, PROC CVPR IEEE, P3034, DOI 10.1109/CVPR.2016.331
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fernando B, 2017, IEEE T PATTERN ANAL, V39, P773, DOI 10.1109/TPAMI.2016.2558148
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu JF, 2017, IEEE T PATTERN ANAL, V39, P2186, DOI 10.1109/TPAMI.2016.2640292
   Ijjina EP, 2017, PATTERN RECOGN, V72, P504, DOI 10.1016/j.patcog.2017.07.013
   Ji XP, 2018, SIGNAL PROCESS, V143, P56, DOI 10.1016/j.sigpro.2017.08.016
   Ji XP, 2017, KNOWL-BASED SYST, V122, P64, DOI 10.1016/j.knosys.2017.01.035
   Jiang YG, 2015, IEEE T IMAGE PROCESS, V24, P3781, DOI 10.1109/TIP.2015.2456412
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Khaire P, 2018, PATTERN RECOGN LETT, V115, P107, DOI 10.1016/j.patrec.2018.04.035
   Kong Y, 2015, PROC CVPR IEEE, P1054, DOI 10.1109/CVPR.2015.7298708
   Li C., 2018, P 27 INT JOINT C ART, Vabs/1804.06055
   Liu J, 2017, PROC CVPR IEEE, P3671, DOI 10.1109/CVPR.2017.391
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu Z, 2016, IMAGE VISION COMPUT, V55, P93, DOI 10.1016/j.imavis.2016.04.004
   Moghaddam Z, 2014, IEEE T AUTOM SCI ENG, V11, P394, DOI 10.1109/TASE.2013.2262940
   Rahmani H, 2016, PROC CVPR IEEE, P1506, DOI 10.1109/CVPR.2016.167
   Rahmani H, 2016, IEEE T PATTERN ANAL, V38, P2430, DOI 10.1109/TPAMI.2016.2533389
   Sempena Samsu., 2011, P INT C EL ENG INF, P1, DOI DOI 10.1109/ICEEI.2011.6021605
   Shahroudy A, 2018, IEEE T PATTERN ANAL, V40, P1045, DOI 10.1109/TPAMI.2017.2691321
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Simonyan K, 2014, ADV NEUR IN, V27
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang PC, 2018, AAAI CONF ARTIF INTE, P7404
   Wang PC, 2018, IEEE T MULTIMEDIA, V20, P1051, DOI 10.1109/TMM.2018.2818329
   Wang PC, 2017, PROC CVPR IEEE, P416, DOI 10.1109/CVPR.2017.52
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Xiao Y, 2019, INFORM SCIENCES, V480, P287, DOI 10.1016/j.ins.2018.12.050
   Zhang J, 2016, PATTERN RECOGN, V60, P86, DOI 10.1016/j.patcog.2016.05.019
   Zhang KT, 2018, MULTIMED TOOLS APPL, V77, P16053, DOI 10.1007/s11042-017-5179-7
NR 41
TC 31
Z9 33
U1 1
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16185
EP 16203
DI 10.1007/s11042-019-08576-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000652283400006
DA 2024-07-18
ER

PT J
AU Baareh, AK
   Elsayad, A
   Al-Dhaifallah, M
AF Baareh, Abdel Karim
   Elsayad, Alaa
   Al-Dhaifallah, Mujahed
TI Recognition of splice-junction genetic sequences using random forest and
   Bayesian optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Splice junction recognition; Random forest; Bayesian optimization;
   feature selection; support vector machine; K-nearest neighbor; Decision
   tree
ID IDENTIFICATION; MACHINE; RNA
AB Recently, Bayesian Optimization (BO) provides an efficient technique for selecting the hyperparameters of machine learning models. The BO strategy maintains a surrogate model and an acquisition function to efficiently optimize the computation-intensive functions with a few iterations. In this paper, we demonstrate the utility of the BO to fine-tune the hyperparameters of a Random Forest (RF) model for a problem related to the recognition of splice-junction genetic sequences. Locating these splice-junctions prompts further understanding of the DNA splicing process. Specifically, the BO algorithm optimizes four RF hyperparameters: number of trees, number of splitting features, splitting criterion, and leaf size. The optimized RF model automatically selects the most predictive features of the training data. The dataset is obtained from the UCI machine learning repository where half of the records represent two different types of splice-junctions and the other half does not represent any splice-junction. Experimental results proved the advantage of the BO-RF with 99.96% and 97.34% training and test classification accuracies respectively. The results also demonstrated the ability of the RF model to select the most important features, ensuring the best possible results using Support Vector Machine (SVM), K-Nearest Neighbor (KNN), and decision tree (DT) models. Some practical procedures in model development and evaluation such as out-of-bag error and cross-validation approaches are also referred to.
C1 [Baareh, Abdel Karim] Al Balqa Appl Univ, Ajloun Coll, Comp Sci Dept, Ajloun, Jordan.
   [Elsayad, Alaa] Prince Sattam Bin Abdulaziz Univ, Coll Engn, Wadi Eldawasir, Saudi Arabia.
   [Elsayad, Alaa] Elect Res Inst, Comp & Syst Dept, Giza 12622, Egypt.
   [Al-Dhaifallah, Mujahed] King Fahd Univ Petr & Minerals, Dept Syst Engn, Dhahran 31261, Saudi Arabia.
C3 Al-Balqa Applied University; Prince Sattam Bin Abdulaziz University;
   Egyptian Knowledge Bank (EKB); Electronics Research Institute (ERI);
   King Fahd University of Petroleum & Minerals
RP Elsayad, A (corresponding author), Prince Sattam Bin Abdulaziz Univ, Coll Engn, Wadi Eldawasir, Saudi Arabia.; Elsayad, A (corresponding author), Elect Res Inst, Comp & Syst Dept, Giza 12622, Egypt.
EM a.elsayyad@psau.edu.sa
RI Elsayad, Alaa/ABI-1217-2020; Aldhaifallah, Mujahed/D-9526-2015
OI Aldhaifallah, Mujahed/0000-0002-8441-2146; Elsayad,
   Alaa/0000-0001-8053-9759
CR [Anonymous], 2016, ARXIV161204858
   Boulesteix AL, 2012, WIRES DATA MIN KNOWL, V2, P493, DOI 10.1002/widm.1072
   Breiman L., 2001, Mach. Learn., V45, P5
   Brochu E, 2010, ARXIV10122599
   Cervantes J, 2011, P INT C BIOINF COMP, P1
   Cooper TA, 2009, CELL, V136, P777, DOI 10.1016/j.cell.2009.02.011
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cox DD, 1997, SIAM PROC S, P315
   Damasevicius R, 2008, CISIS 2008: THE SECOND INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT AND SOFTWARE INTENSIVE SYSTEMS, PROCEEDINGS, P687, DOI 10.1109/CISIS.2008.41
   Elyan E, 2017, INFORM SCIENCES, V384, P220, DOI 10.1016/j.ins.2016.08.007
   Faris H, 2016, LECT NOTES ARTIF INT, V9875, P498, DOI 10.1007/978-3-319-45243-2_46
   He X, 2006, TREE BASED METHODS T, P551
   Htike ZZ, 2013, PROCEDIA COMPUT SCI, V23, P36, DOI 10.1016/j.procs.2013.10.006
   Jiang F, 2017, STROKE VASC NEUROL, V2, P230, DOI 10.1136/svn-2017-000101
   Jones DR, 1998, J GLOBAL OPTIM, V13, P455, DOI 10.1023/A:1008306431147
   Kaur P, 2019, MULTIMED TOOLS APPL, V78, P19905, DOI 10.1007/s11042-019-7327-8
   Kushner H.J., 1964, J. Basic Eng., V86, P97, DOI [DOI 10.1115/1.3653121, 10.1115/1.3653121]
   Levesque J-C, 2018, BAYESIAN HYPERPARAME
   Lorena A C, 2002, WOB, P32
   Luts J, 2010, ANAL CHIM ACTA, V665, P129, DOI 10.1016/j.aca.2010.03.030
   MathWorks, 2018, MATLAB ONL DOC
   Meher PK, 2016, ALGORITHM MOL BIOL, V11, DOI 10.1186/s13015-016-0078-4
   Meher PK, 2016, BIODATA MIN, V9, DOI 10.1186/s13040-016-0086-4
   Minasny B, 2005, GEODERMA, V128, P192, DOI 10.1016/j.geoderma.2005.04.003
   Pashaei E, 2017, HEALTH TECHNOL-GER, V7, P141, DOI 10.1007/s12553-016-0157-z
   Probst P., 2019, THESIS IMU
   Rácz A, 2018, SAR QSAR ENVIRON RES, V29, P661, DOI 10.1080/1062936X.2018.1505778
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Snoek J., 2012, 26 ANN C NEUR INF PR, P2951
   Stranger Barbara E., 2006, Human Genomics, V2, P383
   Zeng Y, 2019, BIOL DIRECT, V14, DOI 10.1186/s13062-019-0236-y
   Zhang SC, 2020, NEUROCOMPUTING, V391, P234, DOI 10.1016/j.neucom.2018.11.101
   Zhang Y, 2018, BMC GENOMICS, V19, DOI 10.1186/s12864-018-5350-1
   Ziegler A, 2014, WIRES DATA MIN KNOWL, V4, P55, DOI 10.1002/widm.1114
NR 34
TC 5
Z9 5
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30505
EP 30522
DI 10.1007/s11042-021-10944-7
EA APR 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000656312000001
DA 2024-07-18
ER

PT J
AU Amirkhani, D
   Bastanfard, A
AF Amirkhani, Dariush
   Bastanfard, Azam
TI An objective method to evaluate exemplar-based inpainted images quality
   using Jaccard index
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image inpainting; Objective evaluation; Saliency map; Image quality
   evaluation; Jaccard index
ID SALIENCY DETECTION; COMPLETION; FRAMEWORK; REMOVAL; TENSOR; MODEL
AB Objective evaluation of images is one of the most essential and practical aspects of image inpainting. The existing objective evaluation methods of image inpainting are functional only on an individual basis and do not provide an accurate and useful objective evaluation of inpainted images. Currently, there is no objective measure for evaluating inpainted images. In this study, an objective evaluation method was developed for image inpainting. In the proposed method, first, 100 images were inpainted using an exemplar-based algorithm. Then, the saliency map and its complementary region in the original image were obtained and a new objective measure was proposed for the evaluation of inpainted images based on the saliency map features. To make the assessment more realistic and comparable to human judgments, two terms, namely penalty and compensation, were taken into account. To assess the performance of our proposed objective measure, the inpainted images were also evaluated using a subjective test. The experiments demonstrates that the proposed objective measure correlated with the qualitative opinion in a human observer study. Finally, the objective measure was compared against three other measures, and the results showed that our proposed objective measure performed better than the other evaluation measures.
C1 [Amirkhani, Dariush] Iran Broadcast Univ, Dept Engn & Media, Tehran, Iran.
   [Bastanfard, Azam] Islamic Azad Univ Karaj, Dept Mechatron Engn, Karaj, Iran.
C3 Islamic Azad University
RP Amirkhani, D (corresponding author), Iran Broadcast Univ, Dept Engn & Media, Tehran, Iran.
EM Dariushamirkhani@iribu.ac.ir; Bastanfard@kiau.ac.ir
RI Amirkhani, Dariush/IYT-2131-2023; Bastanfard, Azam/AAX-8571-2020
OI Bastanfard, Azam/0000-0002-7935-819X; Amirkhani,
   Dariush/0000-0001-5653-9644
CR Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   [Anonymous], IMAGE OBJECT SEGMENT
   Arias P, 2012, MULTISCALE MODEL SIM, V10, P473, DOI 10.1137/110848281
   Atapour-Abarghouei A, 2018, LECT NOTES COMPUT SC, V10882, P306, DOI 10.1007/978-3-319-93000-8_35
   Barbu T, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/1701052
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Brkic A. L., LET NOTES ELECT ENG, V559, P229
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Cao F, 2011, SIAM J IMAGING SCI, V4, P1143, DOI 10.1137/110823572
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Demanet L., 2003, Appl. Comput. Math., V1100, P217
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan Q, 2018, MULTIMED TOOLS APPL, V77, P10807, DOI 10.1007/s11042-017-5077-z
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   ITU, 2002, METHODOLOGY SUBJECTI, V211, P1
   Jia JY, 2004, IEEE T PATTERN ANAL, V26, P771, DOI 10.1109/TPAMI.2004.10
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Komodakis N, 2007, IEEE T IMAGE PROCESS, V16, P2649, DOI 10.1109/TIP.2007.906269
   Kumar BVR, 2019, COMPUT APPL MATH, V38, DOI 10.1007/s40314-019-0768-x
   Kumar Hitesh, 2018, Intelligent Computing and Information and Communication. Proceedings of 2nd International Conference, ICICC 2017. Advances in Intelligent Systems and Computing (AISC 673), P705, DOI 10.1007/978-981-10-7245-1_69
   Levin A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P305
   Li SN, 2011, IEEE T MULTIMEDIA, V13, P935, DOI 10.1109/TMM.2011.2152382
   Li SN, 2011, STUD COMPUT INTELL, V346, P497
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Lorenz, 2018, MATH IMAGE PROCESSIN, P171
   Ma L, 2012, IEEE J-STSP, V6, P626, DOI 10.1109/JSTSP.2012.2211996
   Mahalingam, 2010, DIGITAL INPAINTING A
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Masnou S, 2002, IEEE T IMAGE PROCESS, V11, P68, DOI 10.1109/83.982815
   Newson Alasdair., 2013, Proceedings of the 10th European Conference on Visual Media Production, page, P7
   Qureshi MA, 2017, J VIS COMMUN IMAGE R, V49, P177, DOI 10.1016/j.jvcir.2017.09.006
   Ribeiro F, 2011, INT CONF ACOUST SPEE, P2416
   Roth S, 2005, PROC CVPR IEEE, P860
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Shi R, 2015, IEEE T IMAGE PROCESS, V24, P5033, DOI 10.1109/TIP.2015.2473099
   Singhal, 2009, P SPIE IS T ELECT, V7257
   Trampert P, 2018, ULTRAMICROSCOPY, V191, P1, DOI 10.1016/j.ultramic.2018.04.001
   Tschumperlé D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87
   Underwood G, 2006, EUR J COGN PSYCHOL, V18, P321, DOI 10.1080/09541440500236661
   VANDIJK AM, 1995, P SOC PHOTO-OPT INS, V2451, P90, DOI 10.1117/12.201231
   Viacheslav V, 2014, INT CONF SIGN PROCES, P643, DOI 10.1109/ICOSP.2014.7015082
   Voronin V., 2015, INPAINTED IMAGE QUAL
   Walther D, 2006, THESIS CALIF I TECHN
   Wei W, 2019, PATTERN RECOGN, V92, P64, DOI 10.1016/j.patcog.2019.03.009
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
   Xiang S, 2019, SIGNAL PROCESS-IMAGE, V71, P56, DOI 10.1016/j.image.2018.07.005
   XIAO M, 2018, PLOS ONE, V13
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
   Yang XH, 2019, SIGNAL PROCESS-IMAGE, V73, P84, DOI 10.1016/j.image.2018.02.006
   Yao F., 2018, CLUSTER COMPUT, V22, P1
   Zhang DY, 2018, MULTIMED TOOLS APPL, V77, P11823, DOI 10.1007/s11042-017-4829-0
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
   Zhang N, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0471-2
NR 58
TC 28
Z9 28
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26199
EP 26212
DI 10.1007/s11042-021-10883-3
EA APR 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000645531100002
DA 2024-07-18
ER

PT J
AU Baziyad, M
   Shahin, I
   Rabie, T
   Nassif, AB
AF Baziyad, Mohammed
   Shahin, Ismail
   Rabie, Tamer
   Nassif, Ali Bou
TI Maximizing embedding capacity for speech steganography: a
   segment-growing approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stegangography; Speech; Speech stegnaography; DCT; Region-growing
ID EMOTION CUES; WAVELET
AB It has been proven that the higher the correlation level between samples in the time-domain of a digital signal, the stronger the energy com paction property in the Discrete Cosine Transform (DCT) domain. This paper aims to investigate the limits of the DCT energy compaction property in speech signals by segmenting the cover speech signal into correlated segments and hide in each segment. The Hiding process is performed using a hiding strategy in spired by the Amplitude Modulation (AM) technique. Due to segmentation, the homogeneity is expected to increase which causes the energy of the signal to be strongly compacted in a few critical DCT coefficients, and therefore, a substantial amount of insignificant DCT coefficients can be replaced with the secret data without sacrificing the quality of the signal. Experimental results have proven the effectiveness of the proposed scheme which outperforms other speech steganography techniques recently published in the literature.
C1 [Baziyad, Mohammed] Univ Sharjah, Res Inst Sci & Engn, Sharjah, U Arab Emirates.
   [Shahin, Ismail] Univ Sharjah, Dept Elect Engn, Sharjah, U Arab Emirates.
   [Rabie, Tamer; Nassif, Ali Bou] Univ Sharjah, Dept Comp Engn, Sharjah, U Arab Emirates.
C3 University of Sharjah; University of Sharjah; University of Sharjah
RP Baziyad, M (corresponding author), Univ Sharjah, Res Inst Sci & Engn, Sharjah, U Arab Emirates.
EM mbaziyad@sharjah.ac.ae; ismail@sharjah.ac.ae; trabie@sharjah.ac.ae;
   anassif@sharjah.ac.ae
OI Baziyad, Mohammed/0000-0003-0272-2659; Shahin,
   Ismail/0000-0001-7856-9342
CR Abdulla A. A., 2015, Ph.D. dissertation
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abdulla AA, 2014, PROC SPIE, V9120, DOI 10.1117/12.2050518
   Ahmed Mohamed A., 2010, Journal of Applied Sciences, V10, P59, DOI 10.3923/jas.2010.59.64
   AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   [Anonymous], 2009, J THEORETICAL APPL I
   [Anonymous], 2013, IJCSA
   Ballesteros DM, 2012, EXPERT SYST APPL, V39, P9141, DOI 10.1016/j.eswa.2012.02.066
   Baziyad Mohammed, 2020, Trends and Innovations in Information Systems and Technologies. Advances in Intelligent Systems and Computing (AISC 1160), P251, DOI 10.1007/978-3-030-45691-7_24
   Baziyad M, 2018, IEEE INT CONF INNOV, P1, DOI 10.1109/INNOVATIONS.2018.8606008
   Boroumand M, 2018, Electron. Imag., V30, DOI 10.2352/
   Erfani Y, 2009, DIGIT SIGNAL PROCESS, V19, P809, DOI 10.1016/j.dsp.2009.04.003
   Jin Liu, 2012, IEEE International Conference on Communications (ICC 2012), P1133, DOI 10.1109/ICC.2012.6363997
   Kanhe A, 2018, CIRC SYST SIGNAL PR, V37, P5049, DOI 10.1007/s00034-018-0805-9
   Kanhe A, 2016, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INFORMATICS AND ANALYTICS (ICIA' 16), DOI 10.1145/2980258.2980360
   Karampidis K, 2018, J INF SECUR APPL, V40, P217, DOI 10.1016/j.jisa.2018.04.005
   Kathum Ahlam Majead, 2016, INT INFORM I TOKYO I, V19, P4633
   Katz J., 2014, INTRO MODERN CRYPTOG
   KITAWAKI N, 1984, IEEE COMMUN MAG, V22, P26, DOI 10.1109/MCOM.1984.1091825
   Kurapati, 2013, US Patent, Patent No. [8,582,567, 8582567]
   METCALFE RM, 1976, COMMUN ACM, V19, P395, DOI 10.1145/360248.360253
   Nassif AB, 2019, IEEE ACCESS, V7, P19143, DOI 10.1109/ACCESS.2019.2896880
   Rabie, 2015, INT J COMPUTER APPL, V116
   Rabie T, 2019, INT C COMM SIG PROC, P1
   Rabie T, 2020, MULTIMED TOOLS APPL, P1
   Rabie T, 2019, IEEE ACCESS, V7, P21948, DOI 10.1109/ACCESS.2019.2898838
   Rabie T, 2018, MULTIMED TOOLS APPL, V77, P23673, DOI 10.1007/s11042-018-5713-2
   Rabie T, 2018, MULTIMED TOOLS APPL, V77, P8295, DOI 10.1007/s11042-017-4727-5
   Rabie T, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.6.063001
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P8627, DOI 10.1007/s11042-016-3501-4
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P6473, DOI 10.1007/s11042-016-3301-x
   Rabie T, 2016, MULTIMED TOOLS APPL, V75, P5939, DOI 10.1007/s11042-015-2557-x
   Rekik S, 2012, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2012-20
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Shahin I, 2020, NEURAL COMPUT APPL, V32, P2575, DOI 10.1007/s00521-018-3760-2
   Shahin I, 2019, IEEE ACCESS, V7, P26777, DOI 10.1109/ACCESS.2019.2901352
   Shahin I, 2016, J INTELL SYST, V25, P3, DOI 10.1515/jisys-2014-0118
   Shahin IMA, 2013, INT J SPEECH TECHNOL, V16, P341, DOI 10.1007/s10772-013-9188-2
   Shih Frank Y, 2017, Digital watermarking and steganography: fundamentals and techniques
   Shirali-Shahreza S, 2008, INT CONF ACOUST SPEE, P1729, DOI 10.1109/ICASSP.2008.4517963
   Smith S.W., 2003, Digital Signal Processing
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Theodoridis, 2014, ACAD PRESS LIB SIGNA
   Xu TY, 2009, IEEE ICC, P1426
   Xu TT, 2009, 2009 4TH INTERNATIONAL CONFERENCE ON SYSTEMS AND NETWORKS COMMUNICATIONS (ICSNC 2009), P201, DOI 10.1109/ICSNC.2009.71
   Zhang Y, 2002, ELECTRON COMMUN ENG, V14, P273, DOI 10.1049/ecej:20020603
NR 46
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24469
EP 24490
DI 10.1007/s11042-020-10228-6
EA APR 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000637475800002
DA 2024-07-18
ER

PT J
AU Gupta, N
   Jain, A
   Vaisla, KS
   Kumar, A
   Kumar, R
AF Gupta, Namit
   Jain, Arpit
   Vaisla, Kunwar Singh
   Kumar, Adesh
   Kumar, Rajeev
TI Performance analysis of DSDV and OLSR wireless sensor network routing
   protocols using FPGA hardware and machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless sensor network (WSN); Packet delivery ratio (PDR); Destination
   sequenced distance vector (DSDV) routing; Optical link state routing
   (OLSR); Field programmable gate Array (FPGA); Machine learning model
AB Wireless Sensor Network (WSN) is a self-organized network, contains sensor nodes deployed in particular regions to gather the environmental parameters and communicate the information to the base station directly through intermediate nodes. In recent times, WSN has gained attention from wireless device manufacturers, researchers, and users for remotely accessing and monitoring the information in diverse environments. The scalability and routing are the major concerns of the network. Apart from that, the performance of WSN depends on network simulation parameters such as delay, throughput, packet delivery ratio (PDR), and control overhead. The research paper focused on the DSDV and OLSR routing protocol realization on the new hardware platform. The hardware chip of these protocols is designed in Xilinx ISE 14.7 software using VHDL, targeted on Virtex-5 FPGA. The node communication is verified on Modelsim 10.0 simulation software. The FPGA hardware and timing parameters are analyzed for different node clusters (N = 10, 20 horizontal ellipsis 150) configuration. The OLSR routing protocol network performance parameters are used to build the machine learning prediction model using cluster tree regression, random forest regression, multiple regression, and K-means clustering. The K-means clustering predicted 99.12% and 98.50% accuracy in terms of the packet delivery ratio and throughput respectively.
C1 [Gupta, Namit] Uttarakhand Tech Univ, Dept Comp Sci & Engn, Dehra Dun, Uttarakhand, India.
   [Jain, Arpit; Kumar, Rajeev] Teerthanker Mahaveer Univ, Fac Engn & CS, Moradabad, India.
   [Vaisla, Kunwar Singh] BT Kumaon Inst Technol Dwarahat, Dept Comp Sci, Dwarahat, India.
   [Kumar, Adesh] Univ Petr & Energy Studies, Dept Elect & Elect Engn, Dehra Dun, Uttarakhand, India.
C3 Uttarakhand Technical University; Teerthanker Mahaveer University; Bipin
   Tripathi Kumaon Institute of Technology; University of Petroleum &
   Energy Studies (UPES)
RP Jain, A (corresponding author), Teerthanker Mahaveer Univ, Fac Engn & CS, Moradabad, India.
EM arpit.record@gmail.com
RI Gupta, Namit/ADL-3474-2022; Jain, Dr Arpit/HGB-0919-2022; Gupta, Dr.
   Namit/AFH-4574-2022; Vaisla, Kunwar Singh/ABB-4004-2020; Kumar,
   Rajeev/AAJ-4134-2021; Kumar, Rajeev/N-8237-2016; Jain, Dr.
   Arpit/AAW-4147-2021; KUMAR, ADESH/AAP-1581-2020
OI Gupta, Namit/0000-0001-6764-8467; Jain, Dr Arpit/0000-0003-2325-5893;
   Gupta, Dr. Namit/0000-0001-8303-6065; Vaisla, Kunwar
   Singh/0000-0001-5296-6112; Kumar, Rajeev/0000-0002-4141-1282; Kumar,
   Rajeev/0000-0002-4141-1282; Jain, Dr. Arpit/0000-0003-2325-5893; KUMAR,
   ADESH/0000-0002-0209-9206
CR Abba S, 2016, INT J DISTRIB SENS N, DOI 10.1155/2016/4246596
   Angurala M, 2020, IEEE ACCESS, V8, P10606, DOI 10.1109/ACCESS.2020.2965329
   Chavan AA, 2016, PROCEDIA COMPUT SCI, V79, P835, DOI 10.1016/j.procs.2016.03.108
   de la Piedra A, 2012, SENSORS-BASEL, V12, P12235, DOI 10.3390/s120912235
   Hamerly G., 2015, PARTITIONAL CLUSTERI, P41, DOI [10.1007/978-3-319-09259-1_2, DOI 10.1007/978-3-319-09259-1_2]
   Joshi P, 2020, LECT NOTES ELECTR EN, V587, P161, DOI 10.1007/978-981-32-9775-3_16
   Jubair M.A., 2018, INT J ADV SCI ENGINF, V8, P1277
   Kashyap VK, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P687, DOI 10.1109/CCAA.2017.8229889
   Kaur A., 2014, P REC ADV ENG COMP S, P1, DOI 10.1109/ICRAIE.2014.6909326
   Keerthiga, 2019, 2019 IEEE INT C SYST, P1, DOI [10.1109/ICSCAN.2019.8878767, DOI 10.1109/ICSCAN.2019.8878767]
   Kumar A, 2018, WIRELESS PERS COMMUN, V102, P2211, DOI 10.1007/s11277-018-5376-3
   Kumar DP, 2019, INFORM FUSION, V49, P1, DOI 10.1016/j.inffus.2018.09.013
   Kumar H., 2011, 2011 Proceedings of International Conference on Emerging Trends in Networks and Computer Communications (ETNCC 2011), P192, DOI 10.1109/ETNCC.2011.5958514
   Kumar P, 2017, IOP CONF SER-MAT SCI, V225, DOI 10.1088/1757-899X/225/1/012231
   Liao J, 2013, EURASIP J EMBED SYST, DOI 10.1186/1687-963-2013-5
   Mohapatra S, 2012, PROCEDIA ENGINEER, V30, P69, DOI 10.1016/j.proeng.2012.01.835
   Morshed MM, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P1069, DOI 10.1109/ICIEV.2012.6317478
   Mostafa S. A., 2020, P INT C APPL HUM FAC, P117
   Mouiz A., 2019, J COMMUNICATIONS, V14, DOI [10.12720/jcm.14.11.1067-1074, DOI 10.12720/JCM.14.11.1067-1074]
   Mouiz A, 2019, PROCEEDINGS OF THE 2019 5TH INTERNATIONAL CONFERENCE ON COMPUTER AND TECHNOLOGY APPLICATIONS (ICCTA 2019), P134, DOI 10.1145/3323933.3324065
   Muruganantham N, 2020, WIRELESS PERS COMMUN, V111, P2703, DOI 10.1007/s11277-019-07011-8
   Purkar SV, 2018, J COMPUT NETW COMMUN, V2018, DOI 10.1155/2018/2078627
   Salem O., 2013, HDB MED HEALTHCARE T, P207, DOI DOI 10.1007/978-1-4614-8495-08
   Shabbir N., 2017, Wirel Sensor Netw-Insights Innov, P36
   Spaho E., 2013, LNEE, V253, P37, DOI DOI 10.1007/978-94-007-6996-0_5
   Varshovi H, 2019, MULTIMED TOOLS APPL, V78, P17413, DOI 10.1007/s11042-018-7104-0
   Waharte S, 2006, MULTIMED TOOLS APPL, V29, P285, DOI 10.1007/s11042-006-0012-8
   Yadav S, 2016, WIREL NETW, V22, P335, DOI 10.1007/s11276-015-1025-x
   Yang T, 2009, 2009 INTERNATIONAL CONFERENCE ON NETWORK-BASED INFORMATION SYSTEMS, P335, DOI 10.1109/NBiS.2009.35
   Yick J, 2008, COMPUT NETW, V52, P2292, DOI 10.1016/j.comnet.2008.04.002
NR 30
TC 20
Z9 20
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 22301
EP 22319
DI 10.1007/s11042-021-10820-4
EA MAR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000633324300003
DA 2024-07-18
ER

PT J
AU Ripamonti, LA
   Distefano, F
   Trubian, M
   Maggiorini, D
   Gadia, D
AF Ripamonti, Laura Anna
   Distefano, Federico
   Trubian, Marco
   Maggiorini, Dario
   Gadia, Davide
TI DRAGON: diversity regulated adaptive generator online
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Genetic algorithms (GAs); Procedural content generation (PCG);
   Personalized user-experience; Video games design
ID GAMES
AB Approaches based on Procedural Content Generation (PCG) are more and more diffused among video game developers. They offer many advantages, among which two of the most notables are the opportunity to lighten the burden of level designers and the possibility to produce personalized experiences for the players. In the present work we focus especially on the second aspect, while the first one is addressed as a side effect. In particular, we present DRAGON (Diversity Regulated Adaptive Generator Online), an algorithm for procedurally generating "monster" archetypes for multiplayer games basing also on the players' preferences. The generation process exploits the genetic algorithm paradigm, opportunely adapted, and modified in order to guarantee enough flexibility to the game or level designers. Ideally, the archetypes produced by DRAGON can be employed for any game genre and setting. DRAGON has been implemented as a plugin for one of the state-of-the-art game engines and tested with game developers. Moreover, a simulation has been conducted for the end-users.
C1 [Ripamonti, Laura Anna; Distefano, Federico; Trubian, Marco; Maggiorini, Dario; Gadia, Davide] Univ Milan, Dept Comp Sci, Milan, Italy.
C3 University of Milan
RP Ripamonti, LA (corresponding author), Univ Milan, Dept Comp Sci, Milan, Italy.
EM ripamonti@di.unimi.it
RI Gadia, Davide/P-6309-2016; Ripamonti, Laura Anna/GQH-8599-2022
OI Gadia, Davide/0000-0003-4491-9150; /0000-0001-8167-7870; TRUBIAN,
   MARCO/0000-0002-3523-817X; Maggiorini, Dario/0000-0002-7460-2966
CR Alhejali AM, 2010, 2010 UK WORKSH COMP, P1, DOI [10.1109/UKCI.2010.5625586, DOI 10.1109/UKCI.2010.5625586]
   Andrade G, 2005, 2005 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON INTELLIGENT AGENT TECHNOLOGY, PROCEEDINGS, P194
   Andrade G., 2005, Proceedings of the fourth international joint conference on Autonomous agents and multiagent systems, P1111, DOI DOI 10.1145/1082473.1082648
   Arneson D, 1974, DUNGEONS DRAGONS, V19
   Barros GAB, 2011, 2011 BRAZILIAN S GAM, P63, DOI 10.1109/SBGAMES.2011.14
   Bartle R., 2003, Designing Virtual Worlds
   BECK LA, 1992, J LEISURE RES, V24, P93, DOI 10.1080/00222216.1992.11969876
   Benbassat A, 2011, GENETIC EVOLUTIONARY, P739, DOI 10.1145/2001858.2002080
   Chen GN, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360702
   Claxton Guy., 1999, HARE BRAIN TORTOISE, V1st
   Compton K., 2006, Proceedings of the Second AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, P109
   de Carvalho Leonardo Filipe Batista Silva, 2010, 2010 IEEE International Conference on Intelligent Computing and Intelligent Systems (ICIS 2010), P526, DOI 10.1109/ICICISYS.2010.5658282
   Dormans Joris., 2011, Proceedings of the 2nd International Workshop on Procedural Content Generation in Games, P2
   Dragons, 2003, MONST MAN COR RUL 3
   Ebert David S, 2003, Texturing Modeling: A Procedural Approach
   Esparcia-Alcazar AI, 2012, FITNESS APPROXIMATIO, P1
   Frade M, 2012, SOFT COMPUT, V16, P1893, DOI 10.1007/s00500-012-0863-z
   Frade M, 2010, LECT NOTES COMPUT SC, V6024, P90, DOI 10.1007/978-3-642-12239-2_10
   Fullerton Tracy., 2014, GAME DESIGN WORKSHOP, DOI 10.1201/b16671
   Guarneri A, 2013, 12 EUROPEAN C ARTIFI, P585, DOI 10.7551/978-0-262-31709-2-ch084
   Halim Z., 2011, EVOLUTIONARY ALGORIT, P383
   Hastings Erin J., 2009, 2009 IEEE Symposium on Computational Intelligence and Games (CIG), P241, DOI 10.1109/CIG.2009.5286468
   Hastings EJ, 2009, IEEE T COMP INTEL AI, V1, P245, DOI 10.1109/TCIAIG.2009.2038365
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Huizinga J, 1949, BEACON PAPERBACKS RE, V15, P1970
   Hunicke R, 2004, P 2004 AAAI WORKSH C
   Inführ J, 2012, LECT NOTES COMPUT SC, V6927, P248
   Isaac A.R., 1992, SPORT PSYCHOL, V6, P192, DOI DOI 10.1123/TSP.6.2.192
   Johnson S., 2005, MIND WIDE OPEN YOUR
   Klein GA, 1999, SOURCE POWER PEOPLE
   Koster Raph, 2013, Theory of fun for game design
   Lee S, 2006, LECT NOTES ARTIF INT, V4099, P955
   Maggiorini D, 2015, P 11 BIANN C IT SIGC, DOI [10.1145/2808435.2808451, DOI 10.1145/2808435.2808451]
   Marks Joe., 2007, AIIDE, P25, DOI [10.1609/AIIDE.V3I1.18777, DOI 10.1609/AIIDE.V3I1.18777]
   Mazza C, 2017, P 12 BIANN C IT SIGC, P1, DOI [10.1145/3125571.3125592, DOI 10.1145/3125571.3125592]
   Mora AM, 2010, LECT NOTES COMPUT SC, V6024, P171, DOI 10.1007/978-3-642-12239-2_18
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/h0043158
   Missura O, 2009, LECT NOTES ARTIF INT, V5808, P197, DOI 10.1007/978-3-642-04747-3_17
   Mitchell M., 1998, INTRO GENETIC ALGORI
   Mora AM, 2010, P 2010 IEEE C COMP I, P241, DOI [10.1109/ITW.2010.5593347, DOI 10.1109/ITW.2010.5593347]
   Mora AM, 2012, J COMPUT SCI TECH-CH, V27, P1007, DOI 10.1007/s11390-012-1281-5
   Mourato F, 2011, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY (ACE 2011)
   Müller P, 2006, ACM T GRAPHIC, V25, P614, DOI 10.1145/1141911.1141931
   Norton D, 2017, GAMES HUMAN INTERACT
   Onieva E, 2012, INT J INTELL SYST, V27, P217, DOI 10.1002/int.21512
   Parish YIH, 2001, COMP GRAPH, P301, DOI 10.1145/383259.383292
   Prusinkiewicz P., 2004, The Algorithmic Beauty of Plants
   Ripamonti LA, 2017, MULTIMED TOOLS APPL, V76, P5001, DOI 10.1007/s11042-016-3636-3
   Schell J., 2014, The Art of Game Design: A book of lenses
   Schwarz M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766956
   Smith G., Proceedings of the International Conference on the Foundations of Digital Games, ser. FDG '12. New York, NY, USA: ACM, P188
   Smith G., 2011, P 2 INT WORKSH PROC, DOI [10.1145/2000919.2000926, DOI 10.1145/2000919.2000926]
   Smith G, 2011, IEEE T COMP INTEL AI, V3, P201, DOI 10.1109/TCIAIG.2011.2159716
   Smith G, 2011, IEEE T COMP INTEL AI, V3, P1, DOI 10.1109/TCIAIG.2010.2095855
   Smith Gillian., 2009, P 4 INT C FDN DIGITA, P175
   Sorenson N, 2010, LECT NOTES COMPUT SC, V6024, P131, DOI 10.1007/978-3-642-12239-2_14
   Spronck P, 2006, MACH LEARN, V63, P217, DOI 10.1007/s10994-006-6205-6
   Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811
   Togelius J, 2015, FDN DIGITAL GAMES
   Togelius J, 2011, P 2 INT WORKSH PROC, DOI 10.1145/2000919.2000922
   Togelius J, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND GAMES, P252, DOI 10.1109/CIG.2007.368106
   Togelius J, 2008, 2008 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND GAMES, P111, DOI 10.1109/CIG.2008.5035629
   Toy M, 1980, ROGUE PC GAME
   Wong SK, 2012, J INF SCI ENG, V28, P145
   Yang H., 2010, 2010 International Conference on Biomedical Engineering and Computer Science, P1
   Yannakakis GN, 2011, IEEE T AFFECT COMPUT, V2, P147, DOI 10.1109/T-AFFC.2011.6
   Yannakakis GN, 2009, IEEE T COMP INTEL AI, V1, P121, DOI 10.1109/TCIAIG.2009.2024533
NR 67
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34933
EP 34969
DI 10.1007/s11042-021-10620-w
EA MAR 2021
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000631790800003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Saini, M
   Susan, S
AF Saini, Manisha
   Susan, Seba
TI Bag-of-Visual-Words codebook generation using deep features for
   effective classification of imbalanced multi-class image datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ResNet-50; Bag-of-Visual-Words; Imbalanced dataset; Image
   classification; Chi(2) SVM; Multi-class datasets
ID CONVOLUTIONAL NEURAL-NETWORKS; INVARIANT FEATURE TRANSFORM; TRENDS;
   SMOTE
AB Classification of imbalanced multi-class image datasets is a challenging problem in computer vision. Most of the real-world datasets are imbalanced in nature because of the uneven distribution of the samples in each class. The problem with an imbalanced dataset is that the minority class having a smaller number of instance samples is left undetected. Most of the traditional machine learning algorithms can detect the majority class efficiently but lag behind in the efficient detection of the minority class, which ultimately degrades the overall performance of the classification model. In this paper, we have proposed a novel combination of visual codebook generation using deep features with the non-linear Chi(2) SVM classifier to tackle the imbalance problem that arises while dealing with multi-class image datasets. The low-level deep features are first extracted by transfer learning using the ResNet-50 pre-trained network, and clustered using k-means. The center of each cluster is a visual word in the codebook. Each image is then translated into a set of features called the Bag-of-Visual-Words (BOVW) derived from the histogram of visual words in the vocabulary. The non-linear Chi(2) SVM classifier is found most optimal for classifying the ensuing features, as proved by a detailed empirical analysis. Hence with the right combination of learning tools, we are able to tackle classification of multi-class imbalanced image datasets in an effective manner. This is proved from the higher scores of accuracy, F1-score and AUC metrics in our experiments on two challenging multi-class datasets: Graz-02 and TF-Flowers, as compared to the state-of-the-art methods.
C1 [Saini, Manisha; Susan, Seba] Delhi Technol Univ, New Delhi, India.
C3 Delhi Technological University
RP Saini, M (corresponding author), Delhi Technol Univ, New Delhi, India.
EM manisha.saini44@gmail.com
RI Susan, Dr. Seba/KHY-0356-2024; Susan, Seba/V-4527-2019
OI Susan, Seba/0000-0002-6709-6591; Saini, Manisha/0000-0003-4807-6787
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2013, Advances in Neural Information Processing Systems (NIPS)
   [Anonymous], 2016, PROCEEDINGS OF 2016 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), DOI 10.1109/ SSCI.2016.7850111
   Bellet A., 2015, SYNTH LECT ARTIF INT, V9, P1, DOI DOI 10.2200/S00626ED1V01Y201501AIM030
   Bellet A., 2013, SURVEY METRIC LEARNI
   Bosch A, 2007, PERSP MED V, V17, P1
   Brendel W, 2019, ARXIV190400760
   Buda M, 2018, NEURAL NETWORKS, V106, P249, DOI 10.1016/j.neunet.2018.07.011
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Cheng G, 2017, IEEE GEOSCI REMOTE S, V14, P1735, DOI 10.1109/LGRS.2017.2731997
   Convolutional Neural Networks (CNNs / ConvNets), 2019, STANF CS CLASS NOT S
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deselaers T, 2008, INT C PATT RECOG, P2100
   Dittman David J., 2014, 27 INT FLAIRS C
   Eitrich T, 2006, J COMPUT APPL MATH, V196, P425, DOI 10.1016/j.cam.2005.09.009
   Estabrooks A, 2004, COMPUT INTELL-US, V20, P18, DOI 10.1111/j.0824-7935.2004.t01-1-00228.x
   Feng J., 2017, COMPUT INTEL NEUROSC, V2017, P14
   Georgescu MI, 2019, IEEE ACCESS, V7, P64827, DOI 10.1109/ACCESS.2019.2917266
   Geron A., 2019, Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems, V2
   HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Kotsiantis S., 2003, ANN MATH COMPUTING T, V1, P46
   Kumar MD, 2017, 2017 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P689
   Lessmann S, 2004, IC-AI '04 & MLMTA'04 , VOL 1 AND 2, PROCEEDINGS, P214
   López V, 2013, INFORM SCIENCES, V250, P113, DOI 10.1016/j.ins.2013.07.007
   Mahmood A, 2017, IEEE IMAGE PROC, P1597, DOI 10.1109/ICIP.2017.8296551
   Opelt A, 2004, LECT NOTES COMPUT SC, V3022, P71
   Oskouei Rozita Jamili, 2017, International Journal of Advanced Intelligence Paradigms, V9, P58
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Provost F., 2000, P AAAI 2000 WORKSH I, V68, P1, DOI DOI 10.1109/SOCPAR.2011
   Rahimi Ali, 2007, ADV NEURAL INFORM PR
   Sáez JA, 2016, PATTERN RECOGN, V57, P164, DOI 10.1016/j.patcog.2016.03.012
   Saini Manisha, 2019, Pattern Recognition and Image Analysis. 9th Iberian Conference, IbPRIA 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11867), P409, DOI 10.1007/978-3-030-31332-6_36
   Saini M, 2018, INT C REC TRENDS IM, P561
   Saini M, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106759
   Sculley D., 2010, P INT C WORLD WID WE, V19, P1177, DOI [DOI 10.1145/1772690.1772862, 10.1145/1772690.1772862]
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suh HK, 2018, BIOSYST ENG, V166, P210, DOI 10.1016/j.biosystemseng.2017.11.015
   Susan S, INT C INN COMP COMM, P825
   Susan S, 2019, APPL SOFT COMPUT, V78, P141, DOI 10.1016/j.asoc.2019.02.028
   Susan S, 2015, IET IMAGE PROCESS, V9, P951, DOI 10.1049/iet-ipr.2014.0670
   Susan Seba, 2018, INT C INTELLIGENT SY, P760
   Syarif I., 2012, NETWORKED DIGITAL TE, P135, DOI [DOI 10.1007/978-3-642-30507-813, DOI 10.1007/978-3-642-30507-8_13]
   Tahir MA, 2012, PATTERN RECOGN, V45, P3738, DOI 10.1016/j.patcog.2012.03.014
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tang Y., 2013, DEEP LEARNING USING
   Tax D. M. J., 2000, Learning from Imbalanced Data Sets. Papers from the AAAI Workshop (Technical Report WS-00-05), P25
   The TensorFlow Team, 2019, TENSORFLOW DAT FLOW
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang XD, 2019, IEEE ACCESS, V7, P42639, DOI 10.1109/ACCESS.2019.2907043
   Xia XL, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P783, DOI 10.1109/ICIVC.2017.7984661
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Yang Y, 2020, ARXIV200108878
   Zheng JB, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON BIG KNOWLEDGE (IEEE ICBK 2017), P320, DOI 10.1109/ICBK.2017.58
NR 58
TC 11
Z9 11
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 20821
EP 20847
DI 10.1007/s11042-021-10612-w
EA MAR 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000627245300001
DA 2024-07-18
ER

PT J
AU Kaliyar, RK
   Goswami, A
   Narang, P
AF Kaliyar, Rohit Kumar
   Goswami, Anurag
   Narang, Pratik
TI FakeBERT: Fake news detection in social media with a BERT-based deep
   learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fake news; Neural network; Social media; Deep learning; BERT
ID CONVOLUTIONAL NEURAL-NETWORK; REPRESENTATIONS
AB In the modern era of computing, the news ecosystem has transformed from old traditional print media to social media outlets. Social media platforms allow us to consume news much faster, with less restricted editing results in the spread of fake news at an incredible pace and scale. In recent researches, many useful methods for fake news detection employ sequential neural networks to encode news content and social context-level information where the text sequence was analyzed in a unidirectional way. Therefore, a bidirectional training approach is a priority for modelling the relevant information of fake news that is capable of improving the classification performance with the ability to capture semantic and long-distance dependencies in sentences. In this paper, we propose a BERT-based (Bidirectional Encoder Representations from Transformers) deep learning approach (FakeBERT) by combining different parallel blocks of the single-layer deep Convolutional Neural Network (CNN) having different kernel sizes and filters with the BERT. Such a combination is useful to handle ambiguity, which is the greatest challenge to natural language understanding. Classification results demonstrate that our proposed model (FakeBERT) outperforms the existing models with an accuracy of 98.90%.
C1 [Kaliyar, Rohit Kumar; Goswami, Anurag] Bennett Univ, Dept Comp Sci Engn, Greater Noida, India.
   [Narang, Pratik] BITS Pilani, Dept CSIS, Pilani, Rajasthan, India.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani)
RP Narang, P (corresponding author), BITS Pilani, Dept CSIS, Pilani, Rajasthan, India.
EM rk5370@bennett.edu.in; pratik.narang@pilani.bits-pilani.ac.in
RI kaliyar, rohit/AAD-8666-2022
OI kaliyar, rohit/0000-0001-7233-872X
CR Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   [Anonymous], 2017, Convergence Analysis of Two-layer Neural Networks with ReLU Activation
   Asparouhov T., 2010, WEIGHTED LEAST SQUAR, V5, P1, DOI DOI 10.1016/0165-1765(94)90069-8
   Aswani R, 2018, INFORM SYST FRONT, V20, P515, DOI 10.1007/s10796-017-9805-8
   Bondielli A, 2019, INFORM SCIENCES, V497, P38, DOI 10.1016/j.ins.2019.05.035
   Brien N, 2018, LANGUAGE FAKE NEWS O
   Castillo C., 2011, P 20 INT C WORLD WID, P675, DOI DOI 10.1145/1963405.1963500
   Cerisara C, 2018, COMPUT SPEECH LANG, V47, P175, DOI 10.1016/j.csl.2017.07.009
   Chen WL, 2018, PATTERN RECOGN LETT, V105, P226, DOI 10.1016/j.patrec.2017.10.014
   Crestani F, 2020, SAARBRUCKEN GERMANY, V181
   De Sarkar Sohan, 2018, P 27 INT C COMP LIGN, P3371
   Del Vicario M, 2016, P NATL ACAD SCI USA, V113, P554, DOI 10.1073/pnas.1517441113
   Devlin Jacob, 2019, C N AM CHAPTER ASS C
   Fazil M, 2018, IEEE T INF FOREN SEC, V13, P2707, DOI 10.1109/TIFS.2018.2825958
   Ghanem Bilal, 2018, Proceedings of the First Workshop on Fact Extraction and VERification (FEVER), P66
   Ghosh Souvick, 2018, Proceedings of the Association for Information Science and Technology, V55, DOI 10.1002/pra2.2018.14505501125
   Gorrell G., 2019, P 13 INT WORKSH SEM, P845, DOI [DOI 10.18653/V1/S19-2147, 10.18653/v1/S19-2147]
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Gupta M., 2012, P 2012 SIAM INT C DA, DOI [10.1137/1.9781611972825.14, DOI 10.1137/1.9781611972825.14]
   Jwa H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194062
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Karimi Hamid, 2018, P 27 INT C COMP LING, P1546
   Kumar S, 2018, ARXIV ARXIV 1804
   Liu Y, 2018, AAAI CONF ARTIF INTE, P354
   MALIK S, 1991, IEEE T COMPUT AID D, V10, P74, DOI 10.1109/43.62793
   Monteiro RA, 2018, LECT NOTES ARTIF INT, V11122, P324, DOI 10.1007/978-3-319-99722-3_33
   Munandar D, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P104, DOI 10.1109/IC3INA.2018.8629522
   Nagi J., 2011, Max-Pooling Convolutional Neural Networks for Vision-based Hand Gesture Recognition
   Perez-Rosas Perez-Rosas V. V., P 27 INT C COMP LING, P3391
   Qi Y., 2018, HLT NAACL, P529, DOI 10.18653/v1/N18-2084
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Rashkin Hannah, 2017, P C EMP METH NAT LAN, P2931
   Roy A, 2018, ARXIV ARXIV 1811
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Seide F., 2011, FEATURE ENG CONTEXT
   Shin J, 2018, COMPUT HUM BEHAV, V83, P278, DOI 10.1016/j.chb.2018.02.008
   Shu K, 2020, BIG DATA, V8, P171, DOI 10.1089/big.2020.0062
   Shu K, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P395, DOI 10.1145/3292500.3330935
   Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994
   Sibi P., 2013, Journal of Theoretical and Applied Information Technology, V47, P1264
   Singh D, 2017, IMAGING SCI J, V65, P108, DOI 10.1080/13682199.2017.1289629
   Tacchini Eugenio, 2017, ARXIV170407506, P1, DOI [10.48550/arXiv.1704.07506, DOI 10.1257/JEP.31.2.211]
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593
   Vasudevan Vijay, 2019, U.S. patent, Patent No. [10,521,729, 10521729]
   Vosoughi S, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3070644
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Weiss AP, 2020, INT J EDUC INTEGR, V16, DOI 10.1007/s40979-019-0049-x
   Yang F., 2012, P ACM SIGKDD WORKSHO, P1
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhang X, 2015, ADV NEUR IN, V28
   Zhong BT, 2019, ADV ENG INFORM, V40, P46, DOI 10.1016/j.aei.2019.02.009
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
   Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603
NR 54
TC 207
Z9 216
U1 30
U2 166
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11765
EP 11788
DI 10.1007/s11042-020-10183-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RQ2GA
UT WOS:000642237200002
PM 33432264
OA Green Published, Bronze
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Shi, L
   Nazir, S
   Chen, LQ
   Zhu, R
AF Shi, Lin
   Nazir, Shah
   Chen, Liquan
   Zhu, Rui
TI Secure convergence of artificial intelligence and internet of things for
   cryptographic cipher- a decision support system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secure communication; AI; IoT; Decision support system
ID HEALTH-CARE; MODEL
AB The communication industry is rapidly growing with the passage of time and the number of communication devices is increasing. This increase of communication devices put the devices and their communication into a high risk and security challenges. Intruders tries for capturing important information from such communication devices and are using for their own benefits. To build an effective and accurate decision support system (DSS) for the convergence of Artificial Intelligence (AI) and Internet of Things (IoT) can secure the systems for secure and smooth point-to-point communication. Multi-criteria decision support systems play an important role in decision making for a particular situation based on several security criteria. Decision making based on multi-criteria is one of the exciting issues faced by practitioners and researchers for the convergence of AI and IoT. Numerous DSS are available for making decisions which have the possibility to adopt activities of the decision making. The planned study presented a DSS for the secure convergence of AI and IoT for devices. The experimental work of the proposed study was carried out in the SuperDecisions tool for plotting the hierarchy of security situations based on goal, security criteria, and alternatives.
C1 [Shi, Lin] Nanjing Univ Aeronaut & Astronaut, Coll Econ & Management, Nanjing 211106, Jiangsu, Peoples R China.
   [Nazir, Shah] Univ Swabi, Dept Comp Sci, Ambar, Pakistan.
   [Chen, Liquan; Zhu, Rui] Southeast Univ, Sch Cyber Sci & Engn, Nanjing 210096, Jiangsu, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Southeast University -
   China
RP Shi, L (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Econ & Management, Nanjing 211106, Jiangsu, Peoples R China.; Nazir, S (corresponding author), Univ Swabi, Dept Comp Sci, Ambar, Pakistan.
EM shiling717@nuaa.edu.cn; snshahnzr@gmail.com
RI Nazir, Shah/D-2020-2015
OI Nazir, Shah/0000-0003-0126-9944
CR Alizadeh Mojtaba, 2013, Journal of Next Generation Information Technology, V4, P65, DOI 10.4156/jnit.vol4.issue1.9
   Amanullah MA, 2020, COMPUT COMMUN, V151, P495, DOI 10.1016/j.comcom.2020.01.016
   Amin R, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071962
   Awotunde J. B., 2017, Nigerian J. Technol. Develop., V13, P74
   Cheah M, 2017, VEH COMMUN, V9, P8, DOI 10.1016/j.vehcom.2017.02.008
   Cherdantseva Y, 2016, COMPUT SECUR, V63, P45, DOI 10.1016/j.cose.2016.09.007
   Deshpande K, 2018, ARXIV PREPRINT ARXIV
   Dhanda SS, 2020, WIRELESS PERS COMMUN, V112, P1947, DOI 10.1007/s11277-020-07134-3
   Dimitrioglou N, 2017, CONF BUS INFORM, V1, P454, DOI 10.1109/CBI.2017.34
   Drake Julia I, 2017, J Mark Access Health Policy, V5, P1360545, DOI 10.1080/20016689.2017.1360545
   Eisenbarth T, 2007, IEEE DES TEST COMPUT, V24, P522, DOI 10.1109/MDT.2007.178
   Fernandes JACS, CHOOSING FUTURE LIGH
   Figueroa-Hernandez, 2019, COMP LIGHTWEIGHT CIP
   Frazao TDC, 2018, BMC MED INFORM DECIS, V18, DOI 10.1186/s12911-018-0663-1
   Girija PMM, 2019, TEST ENG MANAG, V81, P14
   Goyal TK, 2022, IETE J RES, V68, P1722, DOI 10.1080/03772063.2019.1670103
   Gu ZW, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/8830903
   Halabi T, 2017, J INF SECUR APPL, V33, P55, DOI 10.1016/j.jisa.2017.01.007
   Jouini M, 2015, PROCEDIA COMPUT SCI, V52, P507, DOI 10.1016/j.procs.2015.05.024
   Kashem MA, 2018, SPECTRUM, V9
   Kerckhof S, 2012, LECT NOTES COMPUT SC, V7428, P390, DOI 10.1007/978-3-642-33027-8_23
   Khan S, 2018, INT J ADV COMPUT SC, V9, P570
   Li ML, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/8852124
   Mao WX, 2017, COMPUT SECUR, V68, P47, DOI 10.1016/j.cose.2017.02.009
   Marwan M, 2018, PROCEDIA COMPUT SCI, V127, P388, DOI 10.1016/j.procs.2018.01.136
   Mohanta BK, 2020, INTERNET THINGS-NETH, V11, DOI 10.1016/j.iot.2020.100227
   Mohd NAB, 2019, PROCEDIA COMPUT SCI, V161, P1199, DOI 10.1016/j.procs.2019.11.233
   Nabeeh NA, 2019, IEEE ACCESS, V7, P59559, DOI 10.1109/ACCESS.2019.2908919
   Nazir, 2020, SECUR COMMUN NETW
   Nazir S, 2015, INT ARAB J INF TECHN, V15, P1
   Nazir S, 2019, WIREL COMMUN MOB COM, V2019, DOI 10.1155/2019/5931315
   Nazir S, 2013, INT CONF FRONT INFO, P183, DOI 10.1109/FIT.2013.41
   Patil P, 2016, PROCEDIA COMPUT SCI, V78, P617, DOI 10.1016/j.procs.2016.02.108
   Pei C, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1121-6
   Rajesh S, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11020293
   Rani SS, 2020, MULTIMED TOOLS APPL, V79, P35405, DOI 10.1007/s11042-019-07760-5
   Rehman H. U., 2019, FUTURE INFORM COMMUN, V2, P964
   Saranya T., 2020, Procedia Computer Science, V171, P1251, DOI 10.1016/j.procs.2020.04.133
   Shatharama R., 2017, INT J MECH MATER ENG, V12, P45
   Song HH, 2020, PROCEDIA COMPUT SCI, V166, P84, DOI 10.1016/j.procs.2020.02.023
   Subsorn P, 2012, PROCEDIA ENGINEER, V32, P260, DOI 10.1016/j.proeng.2012.01.1266
   Wang LJ, 2020, IEEE ACCESS, V8, P152316, DOI 10.1109/ACCESS.2020.3017221
   Wang XM, 2019, J PARALLEL DISTR COM, V130, P12, DOI 10.1016/j.jpdc.2019.03.003
   Wijayarathna C, 2019, INFORM SOFTWARE TECH, V115, P5, DOI 10.1016/j.infsof.2019.07.007
   Wu X, 2019, ECOL INDIC, V102, P469, DOI 10.1016/j.ecolind.2019.02.057
   Yuan JH, 2019, SCI TOTAL ENVIRON, V696, DOI 10.1016/j.scitotenv.2019.133817
   Zhang J, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/8827364
   Zhang ZY, 2018, J COMPUT SCI-NETH, V26, P468, DOI 10.1016/j.jocs.2017.05.018
NR 48
TC 6
Z9 6
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 31451
EP 31463
DI 10.1007/s11042-020-10489-1
EA FEB 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000617861200003
DA 2024-07-18
ER

PT J
AU Zhou, JC
   Zhang, DH
   Zhang, WS
AF Zhou, Jingchun
   Zhang, Dehuan
   Zhang, Weishi
TI A multifeature fusion method for the color distortion and low contrast
   of underwater images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater images; Image enhancement; Guided filter; Multifeature fusion
ID ADAPTIVE HISTOGRAM EQUALIZATION; ENHANCEMENT
AB Light is scattered and absorbed when it is transmitted through seawater. Underwater images captured in water suffer from color attenuation, low contrast, and blurred details. To address these effects, we propose a multifeature fusion method (MFFM) to improve the color distortion and low contrast of underwater images. White balance technology is used to address the color cast of underwater images and obtain a color correction image. On this basis, the color correction image is enhanced by a guided filter to obtain a contrast-enhanced image. Four feature weights of the input images are calculated separately, and two normalized weight maps are constructed by normalization. To avoid a halo, the two normalized weight maps are multiscale fused. To improve the edge detail, the fused image is enhanced by a color adjustment technique to obtain the final enhanced image. Real underwater images are used for simulation and application testing. Compared with the current state-of-the-art methods, our method can balance the color and contrast and improve the visibility of underwater images. Extensive qualitative and quantitative experiments verify the superiority of the MFFM.
C1 [Zhou, Jingchun; Zhang, Dehuan; Zhang, Weishi] Dalian Maritime Univ, Dalian, Peoples R China.
C3 Dalian Maritime University
RP Zhang, WS (corresponding author), Dalian Maritime Univ, Dalian, Peoples R China.
EM 630790387@qq.com; teesiv@dlmu.edu.cn
RI Zhou, Jingchun/AAF-6817-2019
OI Zhou, Jingchun/0000-0002-4111-6240
FU National Natural Science Foundation of China [61702074]; Liaoning
   Provincial Natural Science Foundation of China [20170520196];
   Fundamental Research Funds for the Central Universities [3132019205,
   3132019354]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61702074), the Liaoning Provincial Natural Science Foundation
   of China(No. 20170520196), and the Fundamental Research Funds for the
   Central Universities (Nos.3132019205 and 3132019354).
CR Ancuti C., 2012, PROC CVPR IEEE, P81, DOI DOI 10.1109/CVPR.2012.6247661
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Ancuti CO, 2017, IEEE COMPUT SOC CONF, P997, DOI 10.1109/CVPRW.2017.136
   Anwar S, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115978
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Carlevaris-Bianco N, 2010, OCEANS-IEEE
   Chang HH, 2019, IEEE J OCEANIC ENG, V44, P1130, DOI 10.1109/JOE.2018.2865045
   Cheng NN, 2019, IEEE ACCESS, V7, DOI 10.1109/ACCESS.2019.2929562
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   Finlayson GD, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P37
   Gao SB, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2919947
   Gijsenij A, 2012, IEEE T PATTERN ANAL, V34, P918, DOI 10.1109/TPAMI.2011.197
   Guo YC, 2020, IEEE J OCEANIC ENG, V45, P862, DOI 10.1109/JOE.2019.2911447
   Han M, 2020, IEEE T SYST MAN CY-S, V50, P1820, DOI 10.1109/TSMC.2017.2788902
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hou GJ, 2019, NEUROCOMPUTING, V369, P106, DOI 10.1016/j.neucom.2019.08.041
   HUANG D, 2018, LECT NOTES COMPUT SC, V2018, P453
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   HUMMEL R, 1977, COMPUT VISION GRAPH, V6, P184, DOI 10.1016/S0146-664X(77)80011-7
   Kim SE, 2016, SIGNAL PROCESS, V127, P1, DOI 10.1016/j.sigpro.2016.02.016
   Kim TK, 1998, IEEE T CONSUM ELECTR, V44, P82, DOI 10.1109/30.663733
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li CY, 2018, IEEE SIGNAL PROC LET, V25, P323, DOI 10.1109/LSP.2018.2792050
   Li CY, 2017, PATTERN RECOGN LETT, V94, P62, DOI 10.1016/j.patrec.2017.05.023
   Li J, 2018, IEEE ROBOT AUTOM LET, V3, P387, DOI 10.1109/LRA.2017.2730363
   Ma D, 2022, INFORM TECHNOL DEV, V28, P297, DOI 10.1080/02681102.2020.1801566
   Mahmood A, 2019, IEEE J OCEANIC ENG, V44, P121, DOI 10.1109/JOE.2017.2786878
   Pan PW, 2018, J MAR SCI TECH-TAIW, V26, P531, DOI 10.6119/JMST.201808_26(4).0006
   Peng YT, 2018, IEEE T IMAGE PROCESS, V27, P2856, DOI 10.1109/TIP.2018.2813092
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Priyadharsini R, 2018, MULTIDIM SYST SIGN P, V29, P1845, DOI 10.1007/s11045-017-0533-5
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P4364, DOI 10.1109/TIP.2019.2910412
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Song W, 2018, LECT NOTES COMPUT SC, V11164, P678, DOI 10.1007/978-3-030-00776-8_62
   Sun ZG, 2020, IEEE T IMAGE PROCESS, V29, P500, DOI 10.1109/TIP.2019.2928631
   Tang JR, 2017, APPL SOFT COMPUT, V55, P31, DOI 10.1016/j.asoc.2017.01.053
   Tang JS, 2009, IEEE J-STSP, V3, P74, DOI 10.1109/JSTSP.2008.2011108
   Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808
   Wang XW, 2017, SIGNAL PROCESS-IMAGE, V58, P187, DOI 10.1016/j.image.2017.07.009
   Weng CC, 2005, IEEE INT SYMP CIRC S, P3801
   YANG M, 2019, IEEE ACCESS, V7
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Zhang S, 2017, NEUROCOMPUTING, V245, P1, DOI 10.1016/j.neucom.2017.03.029
   Zhou J, 2020, MULTIMED TOOLS APPL, V79, P26305, DOI 10.1007/s11042-020-08919-1
   Zhou Z, 2019, IEEE ACCESS, V7, P108818, DOI 10.1109/ACCESS.2019.2933228
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 56
TC 15
Z9 15
U1 1
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17515
EP 17541
DI 10.1007/s11042-020-10273-1
EA FEB 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000616158900005
DA 2024-07-18
ER

PT J
AU Ghate, V
   Hemalatha, SC
AF Ghate, Vasundhara
   Hemalatha, Sweetlin C.
TI Hybrid deep learning approaches for smartphone sensor-based human
   activity recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HAR; ADL; Inertial sensors; LSTM; GRU; CNN; DeepCNN-RF
ID RECURRENT NEURAL-NETWORKS
AB Human Activity Recognition (HAR) has become one of the most important research fields to achieve real-time monitoring of human activities for timely decision making in various applications like fall detection, elderly care etc. Now-a-days, most people use smartphones which come with various embedded inertial sensors like accelerometer and gyroscope to monitor acceleration and angular velocity. These smartphone-based sensors have proven to be cost-effective solution in identification of activities belonging to ADL (Activities of Daily Living). Various Machine Learning, Deep learning and hybrid models have been proposed and implemented for HAR. This paper also proposes various hybrid deep learning approaches which combine Deep Neural Networks with other models like LSTM (Long Short Term Memory) Model and GRU (Gated Recurrent Unit) for effective classification of engineered features from CNN (Convolutional Neural Network) Model. A novel architecture that integrates CNN with Random Forest Classifier (DeepCNN-RF) is proposed to add randomness to the model. The proposed models have been tested on publicly available HAR Datasets like UCI HAR and WISDM Activity Recognition Datasets. Experimental results show that the hybrid models outperform the state-of-the-art data mining, machine learning techniques in UCI HAR and WISDM with an overall maximum accuracy of 97.77% and 98.2% respectively.
C1 [Ghate, Vasundhara; Hemalatha, Sweetlin C.] Vellore Inst Technol, Sch Comp Sci & Engn SCOPE, Chennai, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai
RP Hemalatha, SC (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn SCOPE, Chennai, Tamil Nadu, India.
EM vasundharavijay.ghate2016@vitstudent.ac.in; sweetlinh@gmail.com
RI Ghate, Vasundhara/AAI-2363-2021; Ghate, Vasundhara Vijay/G-3759-2017
OI Ghate, Vasundhara/0000-0001-7883-9920; 
CR Abbaspour S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195707
   Anguita D., 2012, INT WORKSH AMB ASS L, P216
   Bayat A, 2014, PROCEDIA COMPUT SCI, V34, P450, DOI 10.1016/j.procs.2014.07.009
   Bux A, 2017, ADV INTELL SYST COMP, V513, P341, DOI 10.1007/978-3-319-46562-3_23
   Feng ZT, 2015, IEEE ENG MED BIO, P5074, DOI 10.1109/EMBC.2015.7319532
   Ha S, 2015, IEEE SYS MAN CYBERN, P3017, DOI 10.1109/SMC.2015.525
   Ignatov A, 2018, APPL SOFT COMPUT, V62, P915, DOI 10.1016/j.asoc.2017.09.027
   Ijjina EP, 2016, APPL SOFT COMPUT, V46, P936, DOI 10.1016/j.asoc.2015.08.025
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jiang WC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1307, DOI 10.1145/2733373.2806333
   Ke SR, 2013, COMPUTERS, V2, P88, DOI 10.3390/computers2020088
   Krishnan NC, 2014, PERVASIVE MOB COMPUT, V10, P138, DOI 10.1016/j.pmcj.2012.07.003
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Mandong A., 2018, Proceedings of the International Conference on Engineering Technologies, P26
   Mekruksavanich S, 2018, 2018 1ST INTERNATIONAL ECTI NORTHERN SECTION CONFERENCE ON ELECTRICAL, ELECTRONICS, COMPUTER AND TELECOMMUNICATIONS ENGINEERING (ECTI-NCON, P160, DOI 10.1109/ECTI-NCON.2018.8378302
   Murad A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112556
   Okai J, 2019, IEEE ENG MED BIO, P2486, DOI [10.1109/EMBC.2019.8857288, 10.1109/embc.2019.8857288]
   Ordóñez FJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010115
   Ortiz LJ., 2011, USER MODELING ADAPTI
   Qingzhong Liu, 2018, International Journal of Machine Learning and Computing, V8, P121, DOI 10.18178/ijmlc.2018.8.2.674
   Ronao CA, 2016, EXPERT SYST APPL, V59, P235, DOI 10.1016/j.eswa.2016.04.032
   Sai NL, 2019, INT J INNOVATIVE TEC, V8, P2817
   Sani S., 2017, CASE BASED REASONING
   Schwartz WR., 2018, ARXIV PREPRINT ARXIV
   Sikder N, 2019, INT CONF ADV ELECTR, P560, DOI [10.1109/ICAEE48663.2019.8975649, 10.1109/icaee48663.2019.8975649]
   Walse KH, 2016, SMART INNOV SYST TEC, V50, P429, DOI 10.1007/978-3-319-30933-0_43
   Wang AG, 2016, IEEE SENS J, V16, P4566, DOI 10.1109/JSEN.2016.2545708
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Zeng M, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON MOBILE COMPUTING, APPLICATIONS AND SERVICES (MOBICASE), P197, DOI 10.4108/icst.mobicase.2014.257786
NR 29
TC 22
Z9 22
U1 2
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35585
EP 35604
DI 10.1007/s11042-020-10478-4
EA FEB 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000615564900002
DA 2024-07-18
ER

PT J
AU Hui, YY
   Liu, H
   Fang, PF
AF Hui, Yuanyuan
   Liu, Han
   Fang, Pengfei
TI A DNA image encryption based on a new hyperchaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperchaotic system; Image encryption; Security analysis
AB In this paper, a new four-dimensional hyperchaotic system that has better unpredictability, more complex dynamic behavior, and a larger key space is proposed. The initial chaos value is calculated by using the Secure Hash Algorithm-512 (SHA-512) function, and the hyperchaotic sequence is then used as the key stream to encrypt the original image through pixel scrambling and pixel diffusion. The experimental results show that the image encryption algorithm has a strong ability to resist exhaustive attacks, statistical attacks and plaintext attacks.
C1 [Hui, Yuanyuan; Liu, Han; Fang, Pengfei] Xian Univ Technol, Sch Automat & Engn, Xian, Peoples R China.
C3 Xi'an University of Technology
RP Liu, H (corresponding author), Xian Univ Technol, Sch Automat & Engn, Xian, Peoples R China.
EM liuhan@xaut.edu.cn
RI Liu, Han/A-8156-2008; Liu, Han/HMD-9231-2023
OI Liu, Han/0000-0002-6618-1380; Liu, Han/0000-0002-5269-8477
CR Anandkumar R, 2018, 2018 2 INT C I SMAC, P6883
   Arpaci B, 2020, J ELECTR ENG TECHNOL, V15, P1413, DOI 10.1007/s42835-020-00393-x
   Banu SA, 2020, MULTIMED TOOLS APPL, V79, P28807, DOI 10.1007/s11042-020-09501-5
   Benkouider K, 2019, INT C CONTROL DECISI, P1717, DOI [10.1109/codit.2019.8820431, 10.1109/CoDIT.2019.8820431]
   Bibi N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194343
   Chen CF, 2020, CHINA COMMUN, V17, P12, DOI 10.23919/JCC.2020.05.002
   Chen H., 2019, 2019 4 INT C MECH CO
   Chen HH, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON MECHANICAL, CONTROL AND COMPUTER ENGINEERING (ICMCCE 2019), P493, DOI 10.1109/ICMCCE48743.2019.00116
   Choi U.S., 2019, 2019 10 IFIP INT C N, P1
   Das S, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P876, DOI [10.1109/aicai.2019.8701249, 10.1109/AICAI.2019.8701249]
   Ding LN, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030310
   Durdi VB, 2017, ADV INTELL SYST, V469, P469, DOI 10.1007/978-981-10-1678-3_45
   Hong-Li Xu, 2019, 2019 3rd International Conference on Electronic Information Technology and Computer Engineering (EITCE). Proceedings, P784, DOI 10.1109/EITCE47263.2019.9095007
   Hua ZY, 2019, IEEE ACCESS, V7, P8660, DOI 10.1109/ACCESS.2018.2890116
   Hussien Hany H., 2019, 2019 14th International Conference on Computer Engineering and Systems (ICCES). Proceedings, P169, DOI 10.1109/ICCES48960.2019.9068136
   Jarin I, 2018, 2018 4TH IEEE INTERNATIONAL WIE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (IEEE WIECON-ECE 2018), P99, DOI 10.1109/WIECON-ECE.2018.8783074
   Jeong HS, 2018, INT CONF UBIQ FUTUR, P795, DOI 10.1109/ICUFN.2018.8437025
   Khan A T., 2018, ADV INT SYST 921 INT, P382
   Lakshmi C, 2021, MULTIMED TOOLS APPL, V80, P8581, DOI 10.1007/s11042-020-09978-0
   Li CQ, 2016, SIGNAL PROCESS, V118, P203, DOI 10.1016/j.sigpro.2015.07.008
   Li XH, 2018, CHINA COMMUN, V15, P138, DOI 10.1109/CC.2018.8300278
   Liu, 2020, MATH PROBL ENG, V2020, P1
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Mehdi S. A., 2019, P INT ENG C IEC JUN, P188, DOI 10.1109/IEC47844.2019.8950560
   Muhammad N, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176979
   Muhammad N, 2015, IET IMAGE PROCESS, V9, P795, DOI 10.1049/iet-ipr.2014.0395
   Nestor T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010083
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Noshadian S, 2018, MULTIMED TOOLS APPL, V77, P25569, DOI 10.1007/s11042-018-5807-x
   Pak C, 2019, MULTIMED TOOLS APPL, V78, P12027, DOI 10.1007/s11042-018-6739-1
   Patro KAK, 2020, IETE TECH REV, V37, P223, DOI 10.1080/02564602.2019.1595751
   Peng YX, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21010027
   Peng YX, 2018, EUR PHYS J PLUS, V133, DOI 10.1140/epjp/i2018-12091-1
   Ran QW, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1958-y
   Shankar K, 2017, CHINA COMMUN, V14, P118, DOI 10.1109/CC.2017.7868160
   Sun SL, 2019, IEEE ACCESS, V7, P28539, DOI 10.1109/ACCESS.2019.2901870
   Teng L, 2018, MULTIMED TOOLS APPL, V77, P6883, DOI 10.1007/s11042-017-4605-1
   Tsafack N, 2020, IEEE ACCESS, V8, P137731, DOI 10.1109/ACCESS.2020.3010794
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Wang, 2014, SCI TECHNOL INNOV, P169
   Wang SC, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2019.105995
   Xiang HY, 2020, MULTIMED TOOLS APPL, V79, P30329, DOI 10.1007/s11042-020-09595-x
   Xie Shaobin, 2011, 2011 International Conference on Electrical and Control Engineering, P4874, DOI 10.1109/ICECENG.2011.6056831
   Yang QG, 2017, NONLINEAR DYNAM, V88, P189, DOI 10.1007/s11071-016-3238-7
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhong YR, 2018, INT C WAVEL ANAL PAT, P72, DOI 10.1109/ICWAPR.2018.8521240
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 47
TC 34
Z9 34
U1 1
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21983
EP 22007
DI 10.1007/s11042-021-10526-7
EA FEB 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000615564900004
DA 2024-07-18
ER

PT J
AU Ahmed, N
   Asif, HMS
   Khalid, H
AF Ahmed, Nisar
   Asif, Hafiz Muhammad Shahzad
   Khalid, Hassan
TI PIQI: perceptual image quality index based on ensemble of Gaussian
   process regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Perceptual quality assessment; Image quality; Gaussian process
   regression; Ensemble learning
ID STATISTICS; MODEL; SIMILARITY; MAGNITUDE
AB Digital images contain a lot of redundancies, therefore, compression techniques are applied to reduce the image size without loss of reasonable image quality. Same become more prominent in the case of videos which contains image sequences and higher compression ratios are achieved in low throughput networks. Assessment of quality of images in such scenarios has become of particular interest. Subjective evaluation in most of the scenarios is infeasible so objective evaluation is preferred. Among the three objective quality measures, full-reference and reduced-reference methods require an original image in some form to calculate the image quality which is unfeasible in scenarios such as broadcasting, acquisition or enhancement. Therefore, a no-reference Perceptual Image Quality Index (PIQI) is proposed in this paper to assess the quality of digital images which calculates luminance and gradient statistics along with mean subtracted contrast normalized products in multiple scales and color spaces. These extracted features are provided to a stacked ensemble of Gaussian Process Regression (GPR) to perform the perceptual quality evaluation. The performance of the PIQI is checked on six benchmark databases and compared with twelve state-of-the-art methods and competitive results are achieved. The comparison is made based on RMSE, Pearson and Spearman's correlation coefficients between ground truth and predicted quality scores. The scores of 0.0552, 0.9802 and 0.9776 are achieved respectively for these metrics on CSIQ database. Two cross-dataset evaluation experiments are performed to check the generalization of PIQI.
C1 [Ahmed, Nisar] Univ Engn & Technol, Dept Comp Engn, Lahore 54890, Pakistan.
   [Asif, Hafiz Muhammad Shahzad] Univ Engn & Technol, Dept Comp Sci, Lahore 54890, Pakistan.
   [Khalid, Hassan] Space & Upper Atmosphere Res Commiss, Karachi 8402, Sindh, Pakistan.
C3 University of Engineering & Technology Lahore; University of Engineering
   & Technology Lahore
RP Ahmed, N (corresponding author), Univ Engn & Technol, Dept Comp Engn, Lahore 54890, Pakistan.
EM nisarahmedrana@yahoo.com
RI Ahmed, Nisar/AAX-5519-2020; Ahmad, Nisar/IAQ-3092-2023
OI Ahmed, Nisar/0000-0002-6397-4860; Khalid, Hassan/0000-0002-5861-4377
CR Ahmed N., COMMUNICATIONS COMPU, V1198, DOI [10.1007/978-981-15-5232-8_51, DOI 10.1007/978-981-15-5232-8_51]
   Ahmed N, 2019, 2019 13TH INTERNATIONAL CONFERENCE ON MATHEMATICS, ACTUARIAL SCIENCE, COMPUTER SCIENCE AND STATISTICS (MACS-13), DOI 10.1109/macs48846.2019.9024822
   Bianco S, 2018, SIGNAL IMAGE VIDEO P, V12, P355, DOI 10.1007/s11760-017-1166-8
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Cai H, 2019, SIGNAL PROCESS-IMAGE, V71, P88, DOI 10.1016/j.image.2018.11.003
   Chang HW, 2013, IEEE T IMAGE PROCESS, V22, P4007, DOI 10.1109/TIP.2013.2266579
   Charrier C, 2012, SIGNAL PROCESS-IMAGE, V27, P209, DOI 10.1016/j.image.2012.01.002
   Chen MJ, 2011, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2011-3
   Dixit MM, 2020, MULTIMED TOOLS APPL, V79, P163, DOI 10.1007/s11042-019-07987-2
   Fu B, 2019, MULTIMED TOOLS APPL, V78, P30707, DOI 10.1007/s11042-018-6521-4
   Ghadiyaram D., 2017, IEEE T CIRC SYST VID, VPP, P1
   Heydari M, 2019, SIGNAL PROCESS-IMAGE, V74, P280, DOI 10.1016/j.image.2018.12.016
   Lasmar NE, 2009, IEEE IMAGE PROC, P2281, DOI 10.1109/ICIP.2009.5414404
   Li QH, 2019, NEUROCOMPUTING, V331, P189, DOI 10.1016/j.neucom.2018.11.015
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Liu LX, 2016, SIGNAL PROCESS-IMAGE, V40, P1, DOI 10.1016/j.image.2015.10.005
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P3951, DOI 10.1109/TIP.2017.2708503
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Nadeem M, 2019, MULTIMED TOOLS APPL, V78, P18531, DOI 10.1007/s11042-019-7221-4
   Nizami IF, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0392-5
   Ou FZ, 2019, IEEE IMAGE PROC, P1004, DOI [10.1109/icip.2019.8803047, 10.1109/ICIP.2019.8803047]
   Ponomarenko N., 2013, VIS INF PROC EUVIP 2
   Reisenhofer R, 2018, SIGNAL PROCESS-IMAGE, V61, P33, DOI 10.1016/j.image.2017.11.001
   RUDERMAN DL, 1994, PHYS REV LETT, V73, P814, DOI 10.1103/PhysRevLett.73.814
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Saad MA, 2010, IEEE SIGNAL PROC LET, V17, P583, DOI 10.1109/LSP.2010.2045550
   Sadiq A, 2020, OPTIK, V205, DOI 10.1016/j.ijleo.2020.164189
   SHARIFI K, 1995, IEEE T CIRC SYST VID, V5, P52, DOI 10.1109/76.350779
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Shen J, 2011, IEEE T IMAGE PROCESS, V20, P2089, DOI 10.1109/TIP.2011.2108661
   Shen L., 2020, MULTIMED TOOLS APPL, V2020, P1
   Tang HX, 2011, PROC CVPR IEEE, P305, DOI 10.1109/CVPR.2011.5995446
   Varga D, 2020, SIGNAL IMAGE VIDEO P, V14, P1265, DOI 10.1007/s11760-020-01664-w
   Wan ZL, 2020, IEEE T MULTIMEDIA, V22, P2024, DOI 10.1109/TMM.2019.2950533
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2010, IET RENEW POWER GEN, V4, P232, DOI 10.1049/iet-rpg.2009.0088
   Wang Z., 2006, Modern Image Quality Assessment, DOI 10.2200/S00010ED1V01Y200508IVM003
   Xu, 2015 VIS COMM IM PRO, P1, DOI [10.1109/VCIP.2015.7457832, DOI 10.1109/VCIP.2015.7457832]
   Xu JT, 2016, IEEE T IMAGE PROCESS, V25, P4444, DOI 10.1109/TIP.2016.2585880
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
   Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X
   Zhuang PX, 2020, MULTIMED TOOLS APPL, V79, P17257, DOI 10.1007/s11042-019-08404-4
NR 52
TC 13
Z9 13
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15677
EP 15700
DI 10.1007/s11042-020-10286-w
EA FEB 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000615174300010
DA 2024-07-18
ER

PT J
AU Li, YF
   Zhang, B
   Sun, J
   Chen, HJ
   Zhu, XD
   Zhu, JL
AF Li, Yanfeng
   Zhang, Bin
   Sun, Jia
   Chen, Houjin
   Zhu, Xiaodi
   Zhu, Jinlei
TI Person re-identification based on activation guided identity and
   attribute classification model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Attribute; Branch-guided classification; Mutex
   local activation
AB Attribute features can be exploited as high-level semantic features to help the model better express person characteristics and improve person re-identification (re-ID) performance. In this paper, a novel activation guided identity and attribute classification (AGIAC) model is proposed for person re-ID. AGIAC model includes the backbone, the mutex local activation (MLA) module and the branch-guided identity-attribute classification (BIAC) module. To fuse the global and local features, the backbone is designed as four branches. Based on the fact the different attributes are related to different regions, the BIAC module is designed, which employs the relevant branch to classify each attribute. To provide more specific information for each attribute in the BIAC model and increase the feature diversity of the four branches, the MLA module is constructed, which generates mutex activation area for each branch. The overall loss function of the AGIAC model is designed as the combination of identity classification loss, attribute classification loss and activation loss. The proposed model is evaluated on three popular person re-ID datasets, Market-1501, DukeMTMC-reID, and MSMT17. Experimental results show that the AGIAC model outperforms the state-of-the-art attribute-combined re-ID methods.
C1 [Li, Yanfeng; Zhang, Bin; Sun, Jia; Chen, Houjin; Zhu, Xiaodi; Zhu, Jinlei] Beijing Jiaotong Univ, Sch Elect & Informat Engn, Beijing 100044, Peoples R China.
   [Zhu, Jinlei] Synth Elect Technol Co Ltd, Jinan, Peoples R China.
C3 Beijing Jiaotong University
RP Li, YF (corresponding author), Beijing Jiaotong Univ, Sch Elect & Informat Engn, Beijing 100044, Peoples R China.
EM yf.li@bjtu.edu.cn
RI Zhu, Jinlei/AAL-1886-2020
OI Zhu, Xiaodi/0000-0002-1322-7269
FU National Nature Science Foundation of China [61872030]; Major Science
   and Technology Innovation Project of Shandong Province [2019TSLH0206]
FX The work was supported in part by the National Nature Science Foundation
   of China [grant number 61872030] and Major Science and Technology
   Innovation Project of Shandong Province [grant number 2019TSLH0206].
CR Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chikontwe P, 2018, IEEE ACCESS, V6, P60801, DOI 10.1109/ACCESS.2018.2875783
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715
   Han K, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P2040, DOI 10.1145/3240508.3240550
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang HW, 2020, TOP CATAL, V63, P664, DOI 10.1007/s11244-020-01235-w
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Li SZ, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107016
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Ling HF, 2019, NEUROCOMPUTING, V347, P109, DOI 10.1016/j.neucom.2019.01.027
   Liu LY, 2019, IEEE INT SYMP PARAL, P1436, DOI 10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00206
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Luo JH, 2019, IEEE IMAGE PROC, P165, DOI [10.1109/ICIP.2019.8802961, 10.1109/icip.2019.8802961]
   Luo YW, 2018, LECT NOTES COMPUT SC, V11213, P424, DOI 10.1007/978-3-030-01240-3_26
   Ou XY, 2019, MULTIMED TOOLS APPL, V78, P28257, DOI 10.1007/s11042-019-07921-6
   Quan HL, 2020, MULTIMED TOOLS APPL, V79, P7259, DOI 10.1007/s11042-019-08184-x
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Su C, 2018, IEEE T PATTERN ANAL, V40, P1167, DOI 10.1109/TPAMI.2017.2679002
   Su C, 2018, PATTERN RECOGN, V75, P77, DOI 10.1016/j.patcog.2017.07.005
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Watson G, 2020, MULTIMED TOOLS APPL, V79, P6463, DOI 10.1007/s11042-019-08499-9
   Wei LH, 2019, IEEE T MULTIMEDIA, V21, P986, DOI 10.1109/TMM.2018.2870522
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Xiang J, 2018, INT C PATT RECOG, P3477, DOI 10.1109/ICPR.2018.8546082
   Yang WJ, 2019, PROC CVPR IEEE, P1389, DOI 10.1109/CVPR.2019.00148
   Yin JY, 2020, APPL INTELL, V50, P3607, DOI 10.1007/s10489-020-01752-x
   Zhao DD, 2020, SIGNAL PROCESS, V166, DOI 10.1016/j.sigpro.2019.107277
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 34
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 14961
EP 14977
DI 10.1007/s11042-021-10545-4
EA JAN 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000613057400009
DA 2024-07-18
ER

PT J
AU Liu, B
   Nie, LM
AF Liu, Bai
   Nie, Liming
TI Gradient based invasive weed optimization algorithm for the training of
   deep neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stacked sparse auto-encoder; Limited memory BFGS; Meta-heuristic
   algorithm; Global exploration
AB Stacked Sparse Auto-Encoder (SSAE) is well known hierarchical deep neural networks for simulating the deep architecture of mammal brain. SSAE can be trained in a greedy layer-wise manner by using methods based on gradient such as Limited memory BFGS (LBFGS). However, methods based on gradient have many disadvantages. The main disadvantage is that they are sensitive to the initial value. In this paper, a meta-heuristic algorithm based on gradient, referred to GCIWOSS, is used to optimize the weights and biases of SSAE. Chaos strategy is firstly used to initial the population of IWO and then a new selection strategy is adopted with the purpose of improving the diversity of population and increasing the global exploration ability. The improved IWO is preparing for the following exploitation based on gradient to avoid falling into local optimal values. In the experiments, the proposed algorithm is proven to be effective in extracting features from different image datasets, compared with the LBFGS and several other feature learning models.
C1 [Liu, Bai] Hubei Univ Technol, Sch Comp Sci, Wuhan 430068, Hubei, Peoples R China.
   [Nie, Liming] Zhejiang Sci Tech Univ, Hangzhou 310018, Zhejiang, Peoples R China.
C3 Hubei University of Technology; Zhejiang Sci-Tech University
RP Liu, B (corresponding author), Hubei Univ Technol, Sch Comp Sci, Wuhan 430068, Hubei, Peoples R China.
EM liubai@hbut.edu.cn
RI Nie, Liming/AAI-4354-2020
FU National Natural Science Foundation of China [62002105, 61672010,
   61701173, 61702168]; Provincial education project [B2018310];
   Ph.D.Programs Foundation [BSQD2019024]
FX This work was supported by the National Natural Science Foundation of
   China (62002105,61672010, 61701173 and 61702168), Ph.D.Programs
   Foundation(BSQD2019024), Provincial education project(B2018310).
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Alghamdi A, 2024, MULTIMED TOOLS APPL, V83, P14913, DOI 10.1007/s11042-020-08769-x
   Alghamdi AS, 2020, APPL ACOUST, V164, DOI 10.1016/j.apacoust.2020.107279
   [Anonymous], 2007, Advances in Neural Information Processing Systems
   [Anonymous], 2006, Advances in Neural Information Processing Systems 19
   [Anonymous], 2014, P COMPANION PUBLICAT, DOI DOI 10.1145/2598394.2602287
   [Anonymous], 2012, Deep Learning using Genetic Algorithms
   Bai XF, 2013, IEICE T INF SYST, VE96D, P387, DOI 10.1587/transinf.E96.D.387
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Chen H, 2019, NEUROCOMPUTING, V332, P56, DOI 10.1016/j.neucom.2018.11.077
   Chen K, 2011, IEEE T NEURAL NETWOR, V22, P1744, DOI 10.1109/TNN.2011.2167240
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Deng L, 2013, INT CONF ACOUST SPEE, P8599, DOI 10.1109/ICASSP.2013.6639344
   Eiben AE, 2015, NATURE, V521, P476, DOI 10.1038/nature14544
   Engelbrecht A., 2007, Computational Intelligence: An Introduction, Vsecond
   Floreano D, 2008, EVOL INTELL, V1, P47, DOI 10.1007/s12065-007-0002-4
   Getoor, 2011, P 28 INT C MACH LEAR, P833
   Gleick J., 1988, American Journal of Physics, V56, P1053, DOI [DOI 10.1119/1.15345, 10.1063/1.2811320]
   Gong MG, 2015, IEEE T NEUR NET LEAR, V26, P3263, DOI 10.1109/TNNLS.2015.2469673
   Hayat M, 2015, IEEE T PATTERN ANAL, V37, P713, DOI 10.1109/TPAMI.2014.2353635
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hou WL, 2015, IEEE T NEUR NET LEAR, V26, P1275, DOI 10.1109/TNNLS.2014.2336852
   Huang F. J., 2006, 2006 IEEE COMP SOC C, V1, P284, DOI DOI 10.1109/CVPR.2006.164
   Ji NN, 2014, PATTERN RECOGN, V47, P3179, DOI 10.1016/j.patcog.2014.03.025
   Jing HY, 2014, NEUROCOMPUTING, V129, P114, DOI 10.1016/j.neucom.2013.02.048
   Kelly K, 2014, TRAINING STACKED DEN
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Kim H, 2013, IEEE SENS J, V13, P2084, DOI 10.1109/JSEN.2013.2248142
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee H., 2007, NIPS
   Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434
   Li HR, 2020, SOFT COMPUT, V24, P6851, DOI 10.1007/s00500-019-04324-5
   Li MS, 2013, FLUID PHASE EQUILIBR, V356, P11, DOI 10.1016/j.fluid.2013.07.017
   Mehrabian AR, 2006, ECOL INFORM, V1, P355, DOI 10.1016/j.ecoinf.2006.07.003
   Ngiam Jiquan, 2011, P 28 INT C MACH LEAR, P265
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Sarikaya R, 2014, IEEE-ACM T AUDIO SPE, V22, P778, DOI 10.1109/TASLP.2014.2303296
   Sivagaminathan RK, 2007, EXPERT SYST APPL, V33, P49, DOI 10.1016/j.eswa.2006.04.010
   Storn R., 1995, INT COMPUT SCI I, DOI [10.1023/a, DOI 10.1023/A:1008202821328]
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang L, 2005, APPL MATH COMPUT, V170, P1329, DOI 10.1016/j.amc.2005.01.024
   Yan XH, 2018, INT J COOP INF SYST, V27, DOI 10.1142/S0218843017410015
   Yao X, 1999, P IEEE, V87, P1423, DOI 10.1109/5.784219
   Yong JS, 2019, APPL MATH SER B, V34, P480, DOI 10.1007/s11766-019-3714-1
   Yu D, 2012, IEEE T AUDIO SPEECH, V20, P4, DOI 10.1109/TASL.2011.2173371
   Yuan Y, 2015, IEEE T NEUR NET LEAR, V26, P2222, DOI 10.1109/TNNLS.2014.2359471
   Zhong S, 2011, P 19 ACM INT C MULT, V2011, P883
NR 49
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22795
EP 22819
DI 10.1007/s11042-020-10495-3
EA JAN 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000610019400017
DA 2024-07-18
ER

PT J
AU Silva, PM
   Florindo, JB
AF Silva, Pedro M.
   Florindo, Joao B.
TI Fractal measures of image local features: an application to texture
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fractal geometry; Multifractals; Texture classification; Box counting;
   Local binary patterns
AB Here we propose a new method for the classification of texture images combining fractal measures (fractal dimension, multifractal spectrum and lacunarity) with local binary patterns. More specifically we compute the box counting dimension of the local binary codes thresholded at different levels to compose the feature vector. The proposal is assessed in the classification of three benchmark databases: KTHTIPS-2b, UMD and UIUC as well as in a real-world problem, namely the identification of Brazilian plant species (database 1200Tex) using scanned images of their leaves. The proposed method demonstrated to be competitive with other state-of-the-art solutions reported in the literature. Such results confirmed the potential of combining a powerful local coding description with the multiscale information captured by the fractal dimension for texture classification.
C1 [Silva, Pedro M.] Fed Inst Educ Sci & Technol Espirito Santo, Rodovia Governador Jose Sete 184, BR-29150410 Cariacica, ES, Brazil.
   [Florindo, Joao B.] Univ Estadual Campinas, Inst Math Stat & Sci Comp, Rua Sergio Buarque de Holanda 651, BR-13083859 Campinas, SP, Brazil.
C3 Instituto Federal do Espirito Santo (IFES); Universidade Estadual de
   Campinas
RP Florindo, JB (corresponding author), Univ Estadual Campinas, Inst Math Stat & Sci Comp, Rua Sergio Buarque de Holanda 651, BR-13083859 Campinas, SP, Brazil.
EM icmpedro@gmail.com; jbflorindo@ime.unicamp.br
RI Florindo, Joao/S-5823-2019
OI Florindo, Joao/0000-0002-0071-0227
FU S ~ao Paulo Research Foundation (FAPESP) [2016/16060-0]; National
   Council for Scientific and Technological Development, Brazil (CNPq)
   [301480/2016-8, 423292/2018-8]; Fundacao de Amparo a Pesquisa do Estado
   de Sao Paulo (FAPESP) [16/16060-0] Funding Source: FAPESP
FX J. B. F. gratefully acknowledges the financial support of S ~ao Paulo
   Research Foundation (FAPESP) (Grant #2016/16060-0) and from National
   Council for Scientific and Technological Development, Brazil (CNPq)
   (Grants #301480/2016-8 and #423292/2018-8).
CR Ahonen T, 2009, LECT NOTES COMPUT SC, V5575, P61, DOI 10.1007/978-3-642-02230-2_7
   [Anonymous], 1999, FRACTAL GEOMETRY NAT
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Casanova D, 2009, INT J IMAG SYST TECH, V19, P236, DOI 10.1002/ima.20201
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Cimpoi M, 2016, INT J COMPUT VISION, V118, P65, DOI 10.1007/s11263-015-0872-3
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dhal KG, 2020, MULTIMED TOOLS APPL, V79, P12227, DOI 10.1007/s11042-019-08417-z
   Falconer K., 2004, FRACTAL GEOMETRY MAT
   Florindo JB, 2018, INFORM SCIENCES, V459, P36, DOI 10.1016/j.ins.2018.05.037
   Florindo JB, 2017, INFORM SCIENCES, V415, P142, DOI 10.1016/j.ins.2017.06.022
   Gao TJ, 2020, J ALLOY COMPD, V845, DOI 10.1016/j.jallcom.2020.155911
   Gonçalves WN, 2016, INFORM SCIENCES, V364, P51, DOI 10.1016/j.ins.2016.04.052
   Grochalski K, 2020, MATERIALS, V13, DOI 10.3390/ma13102337
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kannala J, 2012, INT C PATT RECOG, P1363
   Kenkel NC, 2013, COMMUNITY ECOL, V14, P144, DOI 10.1556/ComEc.14.2013.2.4
   Krishnamoorthi N, 2019, MULTIMED TOOLS APPL, V78, P34247, DOI 10.1007/s11042-019-08249-x
   Krzanowski Wojtek J, 2000, PRINCIPLES MULTIVARI
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Liu J, 2019, MULTIMED TOOLS APPL, V78, P18735, DOI 10.1007/s11042-018-7095-x
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Matas, 2004, SIGNIFICANCE REAL WO
   McCulloch W.S., 1943, B MATH BIOPHYS, V5, P115, DOI 10.1007/BF02478259
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliveira MWD, 2014, PHYSICA A, V416, P41, DOI 10.1016/j.physa.2014.07.074
   Pentland, IJCAI 83, V2
   Posadas AND, 2001, SOIL SCI SOC AM J, V65, P1361, DOI 10.2136/sssaj2001.6551361x
   Quan YH, 2014, PROC CVPR IEEE, P160, DOI 10.1109/CVPR.2014.28
   Russ J., 1994, FRACTAL SURFACES, DOI [10.1007/978-1-4899-2578-7, DOI 10.1007/978-1-4899-2578-7]
   Taraschi G, 2020, PHYSICA A, V545, DOI 10.1016/j.physa.2019.123651
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Verma G, 2018, COMPUT BIOL MED, V93, P1, DOI 10.1016/j.compbiomed.2017.12.004
   Xu Y, 2010, PROC CVPR IEEE, P161, DOI 10.1109/CVPR.2010.5540217
   Xu Y, 2009, INT J COMPUT VISION, V83, P85, DOI 10.1007/s11263-009-0220-6
   Yang QW, 2016, MULTIMED TOOLS APPL, V75, P10201, DOI 10.1007/s11042-015-3079-2
   Zaghloul R., 2019, MULTIMED TOOLS APPL
   Zaghloul R, 2020, MULTIMED TOOLS APPL, V79, P5807, DOI 10.1007/s11042-019-08420-4
   Zhang JH, 2019, J MECH SCI TECHNOL, V33, P475, DOI 10.1007/s12206-018-1247-9
   Zhang P., 1990, SOUTHEASTCON '90. Proceedings (Cat. No.90CH2883-7), P934, DOI 10.1109/SECON.1990.117957
   Zheng Q, 2018, FRACTALS, V26, DOI 10.1142/S0218348X18500354
NR 45
TC 8
Z9 8
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14213
EP 14229
DI 10.1007/s11042-020-10369-8
EA JAN 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000610019400006
DA 2024-07-18
ER

PT J
AU Srivastava, AM
   Jain, A
   Rotte, P
   Prakash, S
   Jayaraman, U
AF Srivastava, Akhilesh Mohan
   Jain, Arushi
   Rotte, Priyanka
   Prakash, Surya
   Jayaraman, Umarani
TI A technique to match highly similar 3D objects with an application to
   biomedical security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Face recognition; Object recognition; Deep learning;
   Biomedical applications; Healthcare applications
ID RECOGNITION
AB Biometric technologies such as the face, fingerprint, and iris recognition have important utility in biomedical and healthcare applications. The use of biometrics in these applications ensures that critical medical information and access to secure premises and medical instruments is given only to authorized persons. In the past, the 2D face has been reliably used as biometrics in biomedical and healthcare applications. Though it provides remarkable performance in normal scenarios, the performance deteriorates in the presence of poor illumination, pose variations, and occlusions. These challenges are overcome by 3D face biometrics, where 3D face data (which provides complete geometric information of the face) is used in place of 2D face images. In this work, we develop a generic technique for matching of highly similar 3D objects and demonstrate its use in 3D face biometrics. The proposed technique combines the object classification utility from PointNet with One-Shot Learning from Siamese Network that converts the multi-class classification problem to a binary classification problem. We also propose a novel data augmentation technique that uses sub-sampling from the existing 3D data to increase the size and variability of the data, which is otherwise limited. Experimental results show that the proposed technique is considerably fast and accurate in the matching of highly similar 3D objects such as 3D human faces. It is also found to be highly efficient in terms of time and space and hence can be employed in designing real-time security solutions for biomedical, healthcare, and several applications in other fields.
C1 [Srivastava, Akhilesh Mohan; Jain, Arushi; Rotte, Priyanka; Prakash, Surya] Indian Inst Technol Indore, Discipline Comp Sci & Engn, Indore, Madhya Pradesh, India.
   [Jayaraman, Umarani] Indian Inst Informat Technol Design & Mfg, Dept Comp Sci & Engn, Kancheepuram, Tamil Nadu, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Indore; Indian Institute of Information Technology,
   Design & Manufacturing, Kancheepuram
RP Prakash, S (corresponding author), Indian Inst Technol Indore, Discipline Comp Sci & Engn, Indore, Madhya Pradesh, India.
EM surya@iiti.ac.in
RI Prakash, Surya/S-6308-2019; jayaraman, umarani/GZG-1821-2022
OI Prakash, Surya/0000-0001-8039-1280; jayaraman,
   umarani/0000-0002-9676-6291; Jain, Arushi/0000-0001-7556-5389;
   Srivastava, Akhilesh Mohan/0000-0002-6812-446X
FU Visvesvaraya Young Faculty Research Fellowship from the Ministry of
   Electronics and Information Technology, Government of India
FX This research is supported by the Visvesvaraya Young Faculty Research
   Fellowship grant received by Surya Prakash from the Ministry of
   Electronics and Information Technology, Government of India, under the
   "Visvesvaraya Ph.D. Scheme for Electronics and IT."
CR Asif U, 2018, IEEE T PATTERN ANAL, V40, P2051, DOI 10.1109/TPAMI.2017.2747134
   Aubry M, 2011, IEEE I CONF COMP VIS, P1411, DOI 10.1109/ICCV.2011.6126396
   Braeger S, 2018, IEEE IMAGE PROC, P3648, DOI 10.1109/ICIP.2018.8451487
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838
   Caglayan A, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P125, DOI 10.23919/MVA.2017.7986817
   Chang K., 2003, MULTIMODAL USER AUTH, P25
   Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007
   Collaud, 2016, BIOMETRICS BIOMEDICA, P143
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Elaraby AF, 2018, 2018 IEEE 9TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P247, DOI 10.1109/IEMCON.2018.8615020
   Flynn PJ, 2003, LECT NOTES COMPUT SC, V2688, P44
   Funkhouser T., 2006, P 4 EUROGRAPHICS S G, P131
   Ganapathi II, 2018, IET BIOMETRICS, V7, P519, DOI 10.1049/iet-bmt.2018.5064
   Gilani SZ, 2018, PROC CVPR IEEE, P1896, DOI 10.1109/CVPR.2018.00203
   Gomez-Donoso F, 2017, IEEE IJCNN, P412, DOI 10.1109/IJCNN.2017.7965883
   GORDON GG, 1991, P SOC PHOTO-OPT INS, V1570, P234, DOI 10.1117/12.48428
   Graham B., 2013, ARXIV13080371
   Guo K, 2015, ACM T GRAPHIC, V35, DOI 10.1145/2835487
   Hayale W, 2019, IEEE INT CONF AUTOMA, P185, DOI 10.1109/fg.2019.8756571
   He MY, 2017, IEEE IMAGE PROC, P3904, DOI 10.1109/ICIP.2017.8297014
   Hu HY, 2017, TENCON IEEE REGION, P133, DOI 10.1109/TENCON.2017.8227850
   Ioannidou A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3042064
   Joshi Jetendra, 2018, 2018 Global Wireless Summit (GWS), P1, DOI 10.1109/GWS.2018.8686652
   Kangming Xu, 2019, 2019 IEEE 19th International Conference on Communication Technology (ICCT), P1665, DOI 10.1109/ICCT46805.2019.8947113
   Kim D, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P133, DOI 10.1109/BTAS.2017.8272691
   Lei YJ, 2016, PATTERN RECOGN, V52, P218, DOI 10.1016/j.patcog.2015.09.035
   Li HB, 2015, INT J COMPUT VISION, V113, P128, DOI 10.1007/s11263-014-0785-6
   Luo J, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P1576, DOI [10.1109/ICMA.2019.8816269, 10.1109/icma.2019.8816269]
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Neves J, 2019, IEEE T INF FOREN SEC, V14, P151, DOI 10.1109/TIFS.2018.2846617
   Osada R, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P154, DOI 10.1109/SMA.2001.923386
   Patil H, 2015, ARTIF INTELL REV, V44, P393, DOI 10.1007/s10462-015-9431-0
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Salem D, 2017, PROC LATIN AM ROBOT, P1
   Savran A., 2008, BIOID, P47, DOI [DOI 10.1007/978-3-540-89991-4_6, DOI 10.1007/978-3-540-89991-4_]
   Sheng Li, 2019, 2019 International Conference on Communications, Information System and Computer Engineering (CISCE). Proceedings, P403, DOI 10.1109/CISCE.2019.00095
   Taertulakarn S, 2016, BIOMED ENG INT CONF
   Tanaka HT, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P372, DOI 10.1109/AFGR.1998.670977
   Terada Takuma, 2018, 2018 14th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD), P390, DOI 10.1109/FSKD.2018.8687254
   Wu H, 2017, AEBMR ADV ECON, V21, P1
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Yun WH, 2017, INT CONF UBIQ ROBOT, P198
   Zhang YC, 2019, IEEE INT CON MULTI, P1606, DOI 10.1109/ICME.2019.00277
   Zhang YH, 2018, IET IMAGE PROCESS, V12, P819, DOI 10.1049/iet-ipr.2017.1085
NR 46
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13159
EP 13178
DI 10.1007/s11042-020-10161-8
EA JAN 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000608968500006
DA 2024-07-18
ER

PT J
AU Muñoz-Ramírez, DO
   García-Salgado, BP
   Ponomaryov, V
   Reyes-Reyes, R
   Sadovnychiy, S
   Cruz-Ramos, C
AF Munoz-Ramirez, David-Octavio
   Garcia-Salgado, Beatriz-Paulina
   Ponomaryov, Volodymyr
   Reyes-Reyes, Rogelio
   Sadovnychiy, Sergiy
   Cruz-Ramos, Clara
TI A color image watermarking framework for copyright protection of stereo
   images based on binocular just noticeable difference and LU
   decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereo image; 24 bits color watermark; BJND; Copyright protection; Blind
   extraction; LU decomposition
ID SCHEME; DWT; ALGORITHM; ROBUST; SVD
AB The copyright protection of three-dimensional (3D) content is a matter of interest in artistic and creative works due to the rights of the holder for the distribution of the material. However, although stereo images are widely used for the generation of 3D content, there is a little amount of research focused on copyright protection for this type of image. In this study, a novel invisible and blind color image watermarking framework for protecting the copyright of the stereo images based on Binocular Just Noticeable Difference (BJND) and lower-and-upper (LU) decomposition is proposed. In this framework, a color watermark is encoded to reduce the information. Then, the BJND model is calculated in the R channel of a stereo image, and finally, LU decomposition is applied into the G and B channels to embed and extract a color watermark. The BJND model has demonstrated a remarkable sensitivity comparable with the Human Visual System (HVS) in luminance changes such as the ones presented in stereo images, guaranteeing a good protection performance and a high imperceptibility. The proposed framework was compared with other state-of-the-art techniques, and it has demonstrated better performance and high resistance to attacks of JPEG compression or impulsive and Gaussian noise. Additionally, this novel framework does not affect the generation of the disparity map or the 3D content when the watermarked stereo images are used for their creation.
C1 [Munoz-Ramirez, David-Octavio; Garcia-Salgado, Beatriz-Paulina; Ponomaryov, Volodymyr; Reyes-Reyes, Rogelio; Cruz-Ramos, Clara] Inst Politecn Nacl, Escuela Super Ingn Mecan & Elect, Unidad Culhuacan, Av Santa Ana 1000, Cdmx, Mexico.
   [Sadovnychiy, Sergiy] Inst Mexicano Petr, Mexico City, Cdmx, Mexico.
C3 Instituto Mexicano del Petroleo
RP Ponomaryov, V (corresponding author), Inst Politecn Nacl, Escuela Super Ingn Mecan & Elect, Unidad Culhuacan, Av Santa Ana 1000, Cdmx, Mexico.
EM vponomar@ipn.mx
RI Reyes-Reyes, Rogelio/AAC-7553-2019; PONOMARYOV, VOLODYMYR/AAF-2858-2021;
   Ponomaryov, Volodymyr/AAK-1537-2021; Cruz-Ramos, Clara/AAN-2761-2020;
   Sadovnychiy, Sergiy/AAD-9754-2020; García Salgado, Beatriz
   Paulina/R-7254-2019
OI Reyes-Reyes, Rogelio/0000-0001-5506-6611; Ponomaryov,
   Volodymyr/0000-0003-4477-4676; Cruz-Ramos, Clara/0000-0001-6050-5885;
   Sadovnychiy, Sergiy/0000-0001-5219-1150; García Salgado, Beatriz
   Paulina/0000-0003-2535-6401
FU Instituto Politecnico Nacional (IPN); Consejo Nacional de Ciencia y
   Tecnologia (CONACyT)
FX The authors would like to thank Instituto Politecnico Nacional (IPN) and
   Consejo Nacional de Ciencia y Tecnologia (CONACyT) for their support.
CR Abdelwahab KM, 2020, MULTIMED TOOLS APPL, V79, P5617, DOI 10.1007/s11042-019-08023-z
   Aja-Fernández S, 2006, 2006 28TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOLS 1-15, P4053
   Bitaghsir SA, 2014, INT ISC CONF INFO SE, P33, DOI 10.1109/ISCISC.2014.6994018
   Cao ZL, 2019, MULTIMED TOOLS APPL, V78, P26089, DOI 10.1007/s11042-019-07809-5
   Chierichetti F, 2010, PROC APPL MATH, V135, P293
   Esfahani R, 2019, MULTIMED TOOLS APPL, V78, P16159, DOI 10.1007/s11042-018-6892-6
   Garg P, 2020, MULTIMED TOOLS APPL, V79, P25921, DOI 10.1007/s11042-020-09262-1
   Gladis AN, 2016, INT J RES ENG APPL S, V6, P1
   Gonzalez-Huitron V, 2018, SIGNAL IMAGE VIDEO P, V12, P231, DOI 10.1007/s11760-017-1150-3
   Hirschmüller H, 2009, IEEE T PATTERN ANAL, V31, P1582, DOI 10.1109/TPAMI.2008.221
   International Telecommunication Union, 2002, BT50011 ITUR, P2
   Karajeh H, 2019, MULTIMED TOOLS APPL, V78, P18395, DOI 10.1007/s11042-019-7214-3
   LEGGE GE, 1980, J OPT SOC AM, V70, P1458, DOI 10.1364/JOSA.70.001458
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu DC, 2020, MULTIMED TOOLS APPL, V79, P7491, DOI 10.1007/s11042-019-08423-1
   Luo AW, 2020, MULTIMED TOOLS APPL, V79, P243, DOI 10.1007/s11042-019-08074-2
   Mohanarathinam A, 2020, J AMB INTEL HUM COMP, V11, P3221, DOI 10.1007/s12652-019-01500-1
   Muñoz-Ramirez DO, 2020, PROC SPIE, V11401, DOI 10.1117/12.2556289
   Muñoz-Ramirez DO, 2019, TURK J ELECTR ENG CO, V27, P1571, DOI 10.3906/elk-1810-138
   Nagarajan D, 2017, INT J ADV RES COMPUT, V8, P675, DOI [10.26483/ijarcs.v8i7.4370, DOI 10.26483/IJARCS.V8I7.4370]
   Netravali AN, 1995, DIGITAL PICTURES APP, DOI [10.1007/978-1-4899-6950-7_4, DOI 10.1007/978-1-4899-6950-7_4]
   Northam L, 2013, COMPUT GRAPH-UK, V37, P389, DOI 10.1016/j.cag.2012.11.005
   Ou ZH, 2016, MULTIMED TOOLS APPL, V75, P3259, DOI 10.1007/s11042-014-2433-0
   Ponomarenko N, 2013, LECT NOTES COMPUT SC, V8192, P402, DOI 10.1007/978-3-319-02895-8_36
   Noriega-Galeana LR, 2017, 2017 14TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, COMPUTING SCIENCE AND AUTOMATIC CONTROL (CCE)
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Shrikalaa M, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P686
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Su QT, 2018, MULTIDIM SYST SIGN P, V29, P1055, DOI 10.1007/s11045-017-0487-7
   Tian C, 2020, MULTIMED TOOLS APPL, V79, P7515, DOI 10.1007/s11042-019-08530-z
   TURING AM, 1948, Q J MECH APPL MATH, V1, P287, DOI 10.1093/qjmam/1.1.287
   Tyagi S, 2016, 2016 INTERNATIONAL CONFERENCE ON EMERGING TRENDS IN ELECTRICAL ELECTRONICS & SUSTAINABLE ENERGY SYSTEMS (ICETEESES), P379, DOI 10.1109/ICETEESES.2016.7581413
   Wang DY, 2016, J INF PROCESS SYST, V12, P765, DOI 10.3745/JIPS.03.0055
   Wang WY, 2016, MULTIMED TOOLS APPL, V75, P4285, DOI 10.1007/s11042-015-2475-y
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu J, 2019, PROC SPIE, V11179, DOI 10.1117/12.2539748
   Wu JY, 2020, MULTIMED TOOLS APPL, V79, P22727, DOI 10.1007/s11042-020-08987-3
   Yang WC, 2015, MULTIMED TOOLS APPL, V74, P7181, DOI 10.1007/s11042-014-1958-6
   Yaqing Niu, 2011, 2011 3rd European Workshop on Visual Information Processing, P211, DOI 10.1109/EuVIP.2011.6045546
   Yu M, 2012, PROCEDIA ENGINEER, V29, P2399, DOI 10.1016/j.proeng.2012.01.322
   Zhao Y, 2011, IEEE SIGNAL PROC LET, V18, P19, DOI 10.1109/LSP.2010.2090041
   Zhou NR, 2019, MULTIMED TOOLS APPL, V78, P2507, DOI 10.1007/s11042-018-6322-9
   Zhou NR, 2018, MULTIMED TOOLS APPL, V77, P30251, DOI 10.1007/s11042-018-6128-9
NR 44
TC 2
Z9 2
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13707
EP 13734
DI 10.1007/s11042-020-10445-z
EA JAN 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000608106900003
DA 2024-07-18
ER

PT J
AU Qureshi, I
   Ma, J
   Abbas, Q
AF Qureshi, Imran
   Ma, Jun
   Abbas, Qaisar
TI Diabetic retinopathy detection and stage classification in eye fundus
   images using active deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic retinopathy; Severity-level; Active deep learning;
   Convolutional neural network; Diabetic retinopathy; Expected gradient
   length; Image processing
ID COMPUTER-AIDED DIAGNOSIS; AUTOMATED IDENTIFICATION; NEURAL-NETWORK;
   VALIDATION; CHALLENGES; ALGORITHM; DISEASES; SYSTEMS
AB Retinal fundus image analysis (RFIA) for diabetic retinopathy (DR) screening can be used to reduce the risk of blindness among diabetic patients. The RFIA screening programs help the ophthalmologists to cope with this paramount visual impairment problem. In this article, an automatic recognition of the DR stage is proposed based on a new multi-layer architecture of active deep learning (ADL). To develop the ADL system, we used the convolutional neural networks (CNN) model to automatically extract features compare to handcrafted-based features. However, the training of CNN procedure requires an immense size of labeled data that makes it almost difficult in the classification phase. As a result, a label-efficient CNN architecture is presented known as ADL-CNN by using one of the active learning methods known as an expected gradient length (EGL). This ADL-CNN model can be seen as a two-stage process. At first, the proposed ADL-CNN system selects both the most informative patches and images by using some ground truth labels of training samples to learn the simple to complex retinal features. Next, it provides useful masks for prognostication to assist clinical specialists for the important eye sample annotation and segment regions-of-interest within the retinograph image to grade five severity-levels of diabetic retinopathy. To test and evaluate the performance of ADL-CNN model, the EyePACS benchmark is utilized and compared with state-of-the-art methods. The statistical metrics are used such as sensitivity (SE), specificity (SP), F-measure and classification accuracy (ACC) to measure the effectiveness of ADL-CNN system. On 54,000 retinograph images, the ADL-CNN model achieved an average SE of 92.20%, SP of 95.10%, F-measure of 93% and ACC of 98%. Hence, the new ADL-CNN architecture is outperformed for detecting DR-related lesions and recognizing the five levels of severity of DR on a wide range of fundus images.
C1 [Qureshi, Imran; Ma, Jun] Shandong Univ, Intelligent Media Res Ctr iLEARN, Sch Comp Sci & Technol, Binhailu 72, Qingdao 266237, Peoples R China.
   [Abbas, Qaisar] Imam Mohammad Ibn Saud Islamic Univ IMSIU, Dept Comp & Informat Sci, Riyadh 11432, Saudi Arabia.
C3 Shandong University; Imam Mohammad Ibn Saud Islamic University (IMSIU)
RP Ma, J (corresponding author), Shandong Univ, Intelligent Media Res Ctr iLEARN, Sch Comp Sci & Technol, Binhailu 72, Qingdao 266237, Peoples R China.
EM imarwat11@gmail.com; majun@sdu.edu.cn; qaabbas@imamu.edu.sa
RI Muhammad Abas, Qaisar Abbas/ABI-6501-2020; Muhammad Abas, Qaisar
   Abbas/GPX-7906-2022
OI Muhammad Abas, Qaisar Abbas/0000-0002-0361-1363; Muhammad Abas, Qaisar
   Abbas/0000-0002-0361-1363; qureshi, imran/0000-0002-8542-7112
FU National Natural Science Foundation of China (NNSFC) [61672322,
   61672324]; intelligent and media research center (iLEARN), School of
   Computer Science and Technology, Shandong University, Qingdao, China
FX We would like to thank all the anonymous reviewers for their valuable
   comments. This work is supported by the National Natural Science
   Foundation of China (NNSFC) under the grant no: (61672322, 61672324) and
   is a part of a Ph.D. research project conducted in the intelligent and
   media research center (iLEARN), School of Computer Science and
   Technology, Shandong University, Qingdao, China.
CR Abbas Q, 2018, MULTIMED TOOLS APPL, V77, P20415, DOI 10.1007/s11042-017-5438-7
   Abbas Q, 2017, MED BIOL ENG COMPUT, V55, P1959, DOI 10.1007/s11517-017-1638-6
   Abràmoff MD, 2016, INVEST OPHTH VIS SCI, V57, P5200, DOI 10.1167/iovs.16-19964
   Acharya UR, 2009, P I MECH ENG H, V223, P545, DOI 10.1243/09544119JEIM486
   Adarsh P, 2013, 2013 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P206, DOI 10.1109/iccsp.2013.6577044
   Akilesh B., 2017, APPL COGNITIVE COMPU, P47, DOI [10.1007/978-981-10-6418-0_6, DOI 10.1007/978-981-10-6418-0_6]
   [Anonymous], 2016, Report of standford education
   [Anonymous], 2016, NEUROCOMPUTING, DOI [DOI 10.1016/J.NEUC0M.2015.09.116, DOI 10.1016/J.NEUCOM.2015.09.116, 10. 1016/j.neucom.2015.09.116]
   [Anonymous], 2016, Int J Eng Res Technol
   [Anonymous], 2015, Int J Adv Networking Appl
   Arunkumar R, 2017, NEURAL COMPUT APPL, V28, P329, DOI 10.1007/s00521-015-2059-9
   Bello-Cerezo R, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040738
   Bhaskaranand M., 2016, J DIABETES SCI TECHN, V10, P254, DOI [DOI 10.1177/1932296816628546, 10.1177/1932296816628546]
   Choi JY, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187336
   Christine N, 2015, YOUR DIABETIC PATIEN
   Chudzik P, 2018, COMPUT METH PROG BIO, V158, P185, DOI 10.1016/j.cmpb.2018.02.016
   Colas E, 2016, ACTA OPHTHALMOL, V94, DOI 10.1111/j.1755-3768.2016.0635
   Costa P, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P165, DOI 10.23919/MVA.2017.7986827
   Dai L, 2018, IEEE T MED IMAGING, V37, P1149, DOI 10.1109/TMI.2018.2794988
   Decencière E, 2013, IRBM, V34, P196, DOI 10.1016/j.irbm.2013.01.010
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Freytag A, 2014, LECT NOTES COMPUT SC, V8692, P562, DOI 10.1007/978-3-319-10593-2_37
   Galveia JN, 2018, L N COMPUT VIS BIOME, V26, P263, DOI 10.1007/978-3-319-65981-7_10
   García G, 2017, LECT NOTES COMPUT SC, V10614, P635, DOI 10.1007/978-3-319-68612-7_72
   Gardner GG, 1996, BRIT J OPHTHALMOL, V80, P940, DOI 10.1136/bjo.80.11.940
   Gargeya R, 2017, OPHTHALMOLOGY, V124, P962, DOI 10.1016/j.ophtha.2017.02.008
   Gondal WM, 2017, IEEE IMAGE PROC, P2069, DOI 10.1109/ICIP.2017.8296646
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Guo S, 2019, NEUROCOMPUTING, V349, P52, DOI 10.1016/j.neucom.2019.04.019
   Haloi M., 2015, ARXIV150504424
   Haneda Shion, 2010, Nihon Rinsho, V68 Suppl 9, P228
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Ishtiaq U, 2020, MULTIMED TOOLS APPL, V79, P15209, DOI 10.1007/s11042-018-7044-8
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kermany Daniel, 2018, Mendeley Data, V3
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li BX, 2013, CURR DIABETES REP, V13, P453, DOI 10.1007/s11892-013-0393-9
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Li K, 2019, FRONT COMPUT SCI-CHI, V13, P1116, DOI 10.1007/s11704-018-6442-4
   Li T, 2019, INFORM SCIENCES, V501, P511, DOI 10.1016/j.ins.2019.06.011
   Li ZX, 2018, DIABETES CARE, V41, P2509, DOI 10.2337/dc18-0147
   Lin JW, 2020, MULTIMED TOOLS APPL, V79, P16173, DOI 10.1007/s11042-019-07751-6
   Liu L, 2019, INT J COMPUT VISION, V127, P74, DOI 10.1007/s11263-018-1125-z
   Mansour RF, 2018, BIOMED ENG LETT, V8, P41, DOI 10.1007/s13534-017-0047-y
   Mookiah MRK, 2013, COMPUT BIOL MED, V43, P2136, DOI 10.1016/j.compbiomed.2013.10.007
   Nanni L, 2021, APPL COMPUT INFORM, V17, P19, DOI 10.1016/j.aci.2018.06.002
   Napoletano P, 2017, LECT NOTES COMPUT SC, V10213, P259, DOI 10.1007/978-3-319-56010-6_22
   Nayak J, 2008, J MED SYST, V32, P107, DOI 10.1007/s10916-007-9113-9
   Orlando JI, 2018, COMPUT METH PROG BIO, V153, P115, DOI 10.1016/j.cmpb.2017.10.017
   Otálora S, 2017, LECT NOTES COMPUT SC, V10552, P146, DOI 10.1007/978-3-319-67534-3_16
   Pan YT, 2020, WORLD WIDE WEB, V23, P2259, DOI 10.1007/s11280-020-00793-z
   Pang H, 2018, WIRELESS PERS COMMUN, V103, P611, DOI 10.1007/s11277-018-5465-3
   Perdomo O., 2016, Lecture Notes in Computer Science, V1, P137, DOI [10.17077/omia.1057, DOI 10.17077/OMIA.1057]
   Pratt H, 2016, PROCEDIA COMPUT SCI, V90, P200, DOI 10.1016/j.procs.2016.07.014
   Prentasic P, 2015, INT SYMP IMAGE SIG, P188, DOI 10.1109/ISPA.2015.7306056
   Quellec G, 2017, MED IMAGE ANAL, V39, P178, DOI 10.1016/j.media.2017.04.012
   Qureshi Imran, 2020, International Journal of Intelligent Systems Technologies and Applications, V19, P1
   Qureshi I, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11060749
   Qureshi I, 2019, ALGORITHMS, V12, DOI 10.3390/a12010014
   Qureshi I, 2016, CURR MED IMAGING, V12, P234, DOI 10.2174/1573405611666150929234644
   Rahim Sarni Suhaila, 2016, Brain Inform, V3, P249, DOI 10.1007/s40708-016-0045-3
   Raju M, 2017, STUD HEALTH TECHNOL, V245, P559, DOI 10.3233/978-1-61499-830-3-559
   Sadek I, 2018, ARXIV170702022
   Saha SK, 2018, J DIGIT IMAGING, V31, P869, DOI 10.1007/s10278-018-0084-9
   Sánchez CI, 2010, LECT NOTES COMPUT SC, V6363, P603
   Sankar M., 2016, INT J ADV ENG TECHNO
   Settles B., 2012, Active Learning, V6, P1, DOI DOI 10.1007/978-3-031-01560-1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan JH, 2017, INFORM SCIENCES, V420, P66, DOI 10.1016/j.ins.2017.08.050
   Ting DSW, 2017, JAMA-J AM MED ASSOC, V318, P2211, DOI 10.1001/jama.2017.18152
   Ting DSW, 2016, CLIN EXP OPHTHALMOL, V44, P260, DOI 10.1111/ceo.12696
   U RA, 2008, J MED SYST, V32, P481, DOI 10.1007/s10916-008-9154-8
   Wang Z., 2017, Diabetic Retinopathy Detection via Deep Convolutional Networks for Discriminative Localization and Visual Explanation
   Washington RE, 2014, DIABETES RES CLIN PR, V103, P504, DOI 10.1016/j.diabres.2013.12.014
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Xu KL, 2017, MOLECULES, V22, DOI 10.3390/molecules22122054
   Yang M, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCED EDUCATION, PSYCHOLOGY AND SPORTS SCIENCE (AEPSS 2017), P533
   Yu Fisher, 2015, ARXIV150603365
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
   Zhang W, 2019, KNOWL-BASED SYST, V175, P12, DOI 10.1016/j.knosys.2019.03.016
   Zhe Wang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P267, DOI 10.1007/978-3-319-66179-7_31
   Zhou L, 2018, IET IMAGE PROCESS, V12, P563, DOI 10.1049/iet-ipr.2017.0636
   Zhou SS, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0107122
NR 87
TC 64
Z9 66
U1 2
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11691
EP 11721
DI 10.1007/s11042-020-10238-4
EA JAN 2021
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000605548700001
DA 2024-07-18
ER

PT J
AU Wang, XY
   Liu, L
AF Wang, Xingyuan
   Liu, Lin
TI Application of chaotic Josephus scrambling and RNA computing in image
   encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic Josephus scrambling; RNA computing; Hyper-chaotic Lorenz system;
   Image encryption
ID SEMI-TENSOR PRODUCT; ALGORITHM; DNA; IMPULSE; SYSTEM; MAP
AB This article describes the application of chaotic Josephus scrambling and RNA computing in image encryption. The algorithm uses the classical 'scrambling-diffusion' process, and the pseudo-random sequences used in each stage are generated by the hyper-chaotic Lorenz system. Firstly, during the scrambling phase, the randomness of the traditional Josephus traversal sequence is improved by using chaotic mapping, which makes the image scrambling effect better. Then during the diffusion phase, the gray value of the pixel is modified by using RNA modular operation and random substitution of RNA codons. The research results prove the feasibility of the encryption system.
C1 [Wang, Xingyuan; Liu, Lin] Dalian Maritime Univ, Fac Informat Sci & Technol, Dalian 116026, Peoples R China.
C3 Dalian Maritime University
RP Wang, XY (corresponding author), Dalian Maritime Univ, Fac Informat Sci & Technol, Dalian 116026, Peoples R China.
EM xywang@dlmu.edu.cn; 2298472397@qq.com
RI Wang, Xing-yuan/I-6353-2015
OI Liu, Lin/0000-0003-3264-4524
FU National Natural Science Foundation of China [61672124]; Password Theory
   Project of the 13th Five-Year Plan National Cryptography Development
   Fund [MMJJ20170203]; Liaoning Province Science and Technology Innovation
   Leading Talents Program Project [XLYC1802013]; Key R&D Projects of
   Liaoning Province [2019020105-JH2/103]; Jinan City '20 universities'
   Funding Projects Introducing Innovation Team Program [2019GXRC031]
FX This research is supported by the National Natural Science Foundation of
   China (No: 61672124), the Password Theory Project of the 13th Five-Year
   Plan National Cryptography Development Fund (No: MMJJ20170203), Liaoning
   Province Science and Technology Innovation Leading Talents Program
   Project (No: XLYC1802013), Key R&D Projects of Liaoning Province (No:
   2019020105-JH2/103), Jinan City '20 universities' Funding Projects
   Introducing Innovation Team Program (No: 2019GXRC031).
CR [Anonymous], 2018, INT C INN BIOINSP CO
   Batool SI, 2019, MULTIMED TOOLS APPL, V78, P27611, DOI 10.1007/s11042-019-07881-x
   Binxuan Xu, 2017, Cyberspace Safety and Security. 9th International Symposium, CSS 2017. Proceedings: LNCS 10581, P307, DOI 10.1007/978-3-319-69471-9_23
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Devi RS, 2020, MULTIMED TOOLS APPL, V79, P12093, DOI 10.1007/s11042-019-08562-5
   Devi RS, 2019, INT J THEOR PHYS, V58, P1937, DOI 10.1007/s10773-019-04088-6
   Elamrawy F., 2018, INT J SIGNAL PROCESS, V3, P27
   Fu X, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2827059
   Gayathri J, 2018, MULTIMED TOOLS APPL, V77, P24751, DOI 10.1007/s11042-018-5675-4
   Guan MM, 2019, IET IMAGE PROCESS, V13, P1535, DOI 10.1049/iet-ipr.2019.0051
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Hua ZY, 2019, IEEE ACCESS, V7, P8660, DOI 10.1109/ACCESS.2018.2890116
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   JarJar A, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1305-7
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Li P, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0402-7
   Liu HJ, 2019, MULTIMED TOOLS APPL, V78, P15997, DOI 10.1007/s11042-018-6996-z
   Liu HJ, 2019, APPL MATH COMPUT, V360, P83, DOI 10.1016/j.amc.2019.04.078
   Liu P, 2019, MULTIMED TOOLS APPL, V78, P14823, DOI 10.1007/s11042-018-6758-y
   Mahmud M, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105818
   Nematzadeh H, 2020, OPTIK, V202, DOI 10.1016/j.ijleo.2019.163505
   Pak C, 2019, MULTIMED TOOLS APPL, V78, P12027, DOI 10.1007/s11042-018-6739-1
   Ran QW, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1958-y
   Sun S, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2017.2766087
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2018, IEEE ACCESS, V6, P23733, DOI 10.1109/ACCESS.2018.2805847
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wei D, 2017, MATH METHOD APPL SCI, V40, P4259, DOI 10.1002/mma.4302
   Wu XJ, 2017, NONLINEAR DYNAM, V90, P855, DOI 10.1007/s11071-017-3698-4
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yadollahi M, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102505
   Zhang X, 2018, NANO-MICRO LETT, V10, DOI 10.1007/s40820-017-0164-2
   Zhuang Z., 2018, J. Comput. Commun, V6, P31, DOI [10.4236/jcc.2018.66003, DOI 10.4236/JCC.2018.66003]
NR 35
TC 14
Z9 14
U1 6
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23337
EP 23358
DI 10.1007/s11042-020-10209-9
EA JAN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000605548700018
DA 2024-07-18
ER

PT J
AU Ashwini, K
   Amutha, R
AF Ashwini, K.
   Amutha, R.
TI Compressive sensing based recognition of human upper limb motions with
   kinect skeletal data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kinect sensor; Skeletal data; Compressive sensing; Action recognition;
   Neural network
ID RGB-D; SCHEME; SYSTEM; REPRESENTATION; ENCRYPTION; MOVEMENTS; SEQUENCES;
   FRAMEWORK; VALIDITY; SIGNALS
AB Limb motion recognition and assessment tasks have become one of the most substantial techniques in clinical environment to evaluate the motor capabilities of neurological patients. However, most of the recognition task are often time consuming and computationally expensive as well. In this paper, we propose a compressive sensing based upper limb motion recognition method using kinect skeletal data. Participants with no form of disabilities were selected for this study. Participants were requested to perform three limb actions and their upper limb motions are captured using kinect sensor. The skeletal data from the kinect sensor chosen for the recognition task is initially converted into RGB image. To alleviate the storage and computational issues, images from skeletal data are further compressed using compressive sensing paradigm. The compressed images are then fed onto a feed forward convolutional neural network for learning and recognizing actions. The recognition task is thus performed directly in the compressed domain avoiding the need for the usage of expensive decompression algorithms. Our proposed method is tested on the acquired data as well as two public benchmark datasets namely MSR Action 3D dataset and KARD dataset. An average recognition accuracy of 96.82%, 94.88% and 97.22% is obtained with our proposed method when tested on acquired dataset, MSR Action 3D dataset and KARD dataset respectively. The proposed method is also compared with several state of the art methods available in literature. Though there is not much increase in the average recognition accuracy of the proposed method on KARD dataset, an increase in average recognition accuracy of around 0.03% to 7.38% is achieved with the proposed method on MSR Action 3D dataset compared to many state of the art methods available in literature.
C1 [Ashwini, K.; Amutha, R.] Sri Sivasubramaniya Nadar Coll Engn, Dept Elect & Commun, Chennai, Tamil Nadu, India.
C3 SSN College of Engineering
RP Ashwini, K (corresponding author), Sri Sivasubramaniya Nadar Coll Engn, Dept Elect & Commun, Chennai, Tamil Nadu, India.
EM ashwini88.k@gmail.com
RI Amutha, R./AAB-9399-2020
OI Ashwini, K/0000-0003-1974-2162
CR Akkaladevi SC, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS, VISION AND INFORMATION SECURITY (CGVIS), P94, DOI 10.1109/CGVIS.2015.7449900
   Asaeda M, 2018, GAIT POSTURE, V62, P458, DOI 10.1016/j.gaitpost.2018.04.010
   Ashwini K, 2018, MULTIMED TOOLS APPL, V77, P31581, DOI 10.1007/s11042-018-6112-4
   Ashwini K, 2018, MULTIMED TOOLS APPL, V77, P25889, DOI 10.1007/s11042-018-5824-9
   Atrsaei A, 2016, J BIOMECH ENG-T ASME, V138, DOI 10.1115/1.4034170
   Biswas D, 2015, HUM MOVEMENT SCI, V40, P59, DOI 10.1016/j.humov.2014.11.013
   Bobin J, 2008, IEEE J-STSP, V2, P718, DOI 10.1109/JSTSP.2008.2005337
   Candes E, 2009, P INT C MATHEMATICIA, V22-30, P1433
   Chen C, 2016, J REAL-TIME IMAGE PR, V12, P155, DOI 10.1007/s11554-013-0370-1
   Cippitelli E, 2016, EVALUATION SKELETON, V14
   Da Poian G, 2016, IEEE T BIO-MED ENG, V63, P1269, DOI 10.1109/TBME.2015.2493726
   Dhiman C, 2019, IEEE SENS J, V19, P5195, DOI 10.1109/JSEN.2019.2903645
   Diliang Chen, 2018, Smart Health, V7-8, P60, DOI 10.1016/j.smhl.2018.05.003
   Ding WW, 2018, PATTERN RECOGN, V77, P75, DOI 10.1016/j.patcog.2017.12.004
   Elmadany NE, 2018, IEEE T IMAGE PROCESS, V27, P5275, DOI 10.1109/TIP.2018.2855438
   Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772
   Gaglio S, 2015, IEEE T HUM-MACH SYST, V45, P586, DOI 10.1109/THMS.2014.2377111
   Gharaee Z, 2020, COGN SYST RES, V63, P11, DOI 10.1016/j.cogsys.2020.05.002
   Guerra J, 2017, INT C REHAB ROBOT, P547, DOI 10.1109/ICORR.2017.8009305
   Huang M, 2018, NEUROCOMPUTING, V291, P84, DOI 10.1016/j.neucom.2018.02.056
   Pham HH, 2018, COMPUT VIS IMAGE UND, V170, P51, DOI 10.1016/j.cviu.2018.03.003
   Ijjina EP, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P159, DOI 10.1109/ICMLA.2014.30
   Jansi R, 2018, MULTIMED TOOLS APPL, V77, P31261, DOI 10.1007/s11042-018-6117-z
   Ji XP, 2018, SIGNAL PROCESS, V143, P56, DOI 10.1016/j.sigpro.2017.08.016
   Khaire P, 2018, PATTERN RECOGN LETT, V115, P107, DOI 10.1016/j.patrec.2018.04.035
   Kumar EK, 2021, J KING SAUD UNIV-COM, V33, P852, DOI 10.1016/j.jksuci.2018.06.008
   Kumar P, 2017, NEUROCOMPUTING, V259, P21, DOI 10.1016/j.neucom.2016.08.132
   Kumar P, 2017, PATTERN RECOGN LETT, V86, P1, DOI 10.1016/j.patrec.2016.12.004
   Lee SI, 2018, IEEE J TRANSL ENG HE, V6, DOI 10.1109/JTEHM.2018.2829208
   Li G, 2020, SIGNAL PROCESS-IMAGE, V84, DOI 10.1016/j.image.2020.115814
   Li QM, 2018, SIGNAL PROCESS-IMAGE, V68, P265, DOI 10.1016/j.image.2018.06.013
   Liu JJ, 2020, NEUROCOMPUTING, V385, P22, DOI 10.1016/j.neucom.2019.11.048
   Mazomenos EB, 2016, IEEE J BIOMED HEALTH, V20, P1088, DOI 10.1109/JBHI.2015.2431472
   Papadopoulos K, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19163503
   Phamila AVY, 2015, ELECTRON LETT, V51, DOI 10.1049/el.2015.0411
   Phamila YAV, 2013, INFORM PROCESS LETT, V113, P672, DOI 10.1016/j.ipl.2013.06.008
   Ponuma R, 2019, MULTIMED TOOLS APPL, V78, P11857, DOI 10.1007/s11042-018-6745-3
   Prajapati SK, 2011, NEUROREHAB NEURAL RE, V25, P6, DOI 10.1177/1545968310374189
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Scano A, 2018, MED ENG PHYS, V56, P54, DOI 10.1016/j.medengphy.2018.04.005
   Scano A, 2017, APPL BIONICS BIOMECH, V2017, DOI 10.1155/2017/8567084
   Scherer M, 2016, PROCEDIA ENGINEER, V147, P466, DOI 10.1016/j.proeng.2016.06.342
   Simonyan K, 2014, ADV NEUR IN, V27
   Singh A, 2016, COMPUT BIOL MED, V73, P24, DOI 10.1016/j.compbiomed.2016.03.021
   Sun BL, 2017, GAIT POSTURE, V58, P428, DOI 10.1016/j.gaitpost.2017.09.001
   Tannous H, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16111914
   Theodorakopoulos I, 2014, J VIS COMMUN IMAGE R, V25, P12, DOI 10.1016/j.jvcir.2013.03.008
   Uswatte G, 2006, ARCH PHYS MED REHAB, V87, P1340, DOI 10.1016/j.apmr.2006.06.006
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Vieira AW, 2014, PATTERN RECOGN LETT, V36, P221, DOI 10.1016/j.patrec.2013.07.011
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Yang ZS, 2018, INT J APPL ELECTROM, V57, P439, DOI 10.3233/JAE-170116
   Zeng K, 2016, NEUROCOMPUTING, V171, P497, DOI 10.1016/j.neucom.2015.06.076
   Zhang Y., 2018, Human activity recognition based on time series analysis using U -Net
   Zhou Bolei, 2018, REVISITING IMPORTANC
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
NR 56
TC 10
Z9 10
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10839
EP 10857
DI 10.1007/s11042-020-10327-4
EA JAN 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000604479100001
DA 2024-07-18
ER

PT J
AU Mishra, P
   Kumar, S
   Chaube, MK
AF Mishra, Prerna
   Kumar, Santosh
   Chaube, Mithilesh Kumar
TI ChartFuse: a novel fusion method for chart classification using
   heterogeneous microstructures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chart interpretation; Chart recognition; Microstructural features;
   Heterogeneous local penta pattern; Heterogeneous index
ID FACIAL IMAGE RECOGNITION; LOCAL BINARY PATTERNS; FEATURE DESCRIPTOR;
   COLOR HISTOGRAM; RETRIEVAL
AB Chart images exhibit significant structural variabilities, which is called as micro-structural variabilities, which makes each image type different from others even though chart image belongs to the same class or categories. The lack of affiliation between the heterogeneous features and the structure of the chart images, make it challenging to learn these micro-variabilities features by any learning model for automatic chart recognition and interpretation. However, extracting low-level heterogeneous features from chart images remains challenging. This paper presents a novel chart image classification method by using local feature descriptor. We proposed a new heterogeneous feature extractor, namely the heterogeneity index (HI) fused with local penta pattern. Here, the microstructural features are defined on the similarity of the chroma effects, and HI is computed depending upon the basic colors and its intensity in the microstructures with similar chroma effects. HI integrates colors, textures, structural layout, and illumination details with the local features altogether for the image classification. The proposed method is tested on chart image datasets, namely FigureQA and our handcrafted chart dataset. Experimental results depict that our method classify images with an accuracy rate of 95%-97% which is an increase of 5%-10% as compared with the customary methods.
C1 [Mishra, Prerna; Kumar, Santosh] DSPM IIITNR, Dept Comp Sci & Engn, Raipur, Madhya Pradesh, India.
   [Chaube, Mithilesh Kumar] DSPM IIITNR, Dept Math, Raipur, Madhya Pradesh, India.
RP Mishra, P (corresponding author), DSPM IIITNR, Dept Comp Sci & Engn, Raipur, Madhya Pradesh, India.
EM prerna@iiitnr.edu.in; santosh@iiitnr.edu.in; mithilesh@iiitnr.edu.in
RI Chaube, Mithilesh/AAV-7844-2020; mishra, prerna/GPW-6915-2022
OI Chaube, Mithilesh/0000-0001-7086-1277; Kumar, Dr.
   Santosh/0000-0003-2264-9014; mishra, prerna/0000-0003-2895-6146
CR Agarwal M, 2019, PATTERN ANAL APPL, V22, P1585, DOI 10.1007/s10044-019-00787-2
   Al-Ariny Z, 2020, PROCEEDINGS OF 2020 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN COMMUNICATION AND COMPUTER ENGINEERING (ITCE), P232, DOI [10.1109/ITCE48509.2020.9047800, 10.1109/itce48509.2020.9047800]
   Amara JH, 2017, COMPUT SCI RES NOTES, V2701, P83
   [Anonymous], 2015, ARXIV150207041
   [Anonymous], 2011, P 24 ANN ACM S US IN
   [Anonymous], 2016, INT J SIGNAL PROCESS
   Ashish B, 2013, INT J ENG SCI TECHNO, V5, P27
   Atkinson A., 2017, Figureqa: An annotated figure dataset for visual reasoning
   Bala A, 2016, ENG SCI TECHNOL, V19, P101, DOI 10.1016/j.jestch.2015.06.008
   Chakraborty S, 2019, MULTIMED TOOLS APPL, V78, P25143, DOI 10.1007/s11042-019-7707-0
   Chakraborty S, 2017, COMPUT ELECTR ENG, V62, P92, DOI 10.1016/j.compeleceng.2017.06.013
   Chen M, 2016, IEEE T VIS COMPUT GR, V22, P2619, DOI 10.1109/TVCG.2015.2513410
   Choi JO, 2019, COMPUT GRAPH FORUM, V38, P249, DOI 10.1111/cgf.13686
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dandashy T, 2019, INT J ENG MANAG RES, DOI 10.31033/ijemr.9.4.17
   DAVILA K, 2020, IEEE T PATT ANAL MAC
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   El Khadiri I, 2018, COMPUT VIS IMAGE UND, V169, P14, DOI 10.1016/j.cviu.2018.01.004
   Fadaei S, 2017, SIGNAL PROCESS, V137, P274, DOI 10.1016/j.sigpro.2017.02.013
   Fu XF, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 4, PROCEEDINGS, P115, DOI 10.1109/ICNC.2008.94
   Ganesh P, 2019, IFAC PAPERSONLINE, V52, P70, DOI 10.1016/j.ifacol.2019.12.499
   Hao QH, 2018, LECT NOTES COMPUT SC, V11164, P290, DOI 10.1007/978-3-030-00776-8_27
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Höschl C, 2016, PATTERN RECOGN LETT, V69, P72, DOI 10.1016/j.patrec.2015.10.012
   Jung Daekyoung, 2017, P 2017 CHI C HUM FAC
   Karthikeyani V., 2012, INT J COMPUTER APPL, V39, P1, DOI DOI 10.5120/4789-6997
   Kou QQ, 2018, IEEE ACCESS, V6, P30691, DOI 10.1109/ACCESS.2018.2842078
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar K, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P3922
   Kumar TGS, 2018, SIGNAL IMAGE VIDEO P, V12, P591, DOI 10.1007/s11760-017-1197-1
   Lan RS, 2018, MULTIMED TOOLS APPL, V77, P10853, DOI 10.1007/s11042-017-5341-2
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Liu PZ, 2017, INFORM SCIENCES, V390, P95, DOI 10.1016/j.ins.2017.01.025
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Prasad VSN, 2007, INT WORK CONTENT MUL, P85
   Shakoor MH, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417500197
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh C, 2018, PATTERN RECOGN, V76, P50, DOI 10.1016/j.patcog.2017.10.021
   Suhasini Pallikonda Sarah, 2017, Journal of the Institution of Engineers (India): Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V98, P129, DOI 10.1007/s40031-016-0223-y
   Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Tang BB, 2016, SIGNAL PROCESS, V124, P156, DOI 10.1016/j.sigpro.2015.09.027
   Tao G, 2013, OPTIK, V124, P7022, DOI 10.1016/j.ijleo.2013.05.159
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Vipparthi SK, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0006-x
   Youssef N, 2018, INT C ADV INT SYST I, P634
   Zhang BC, 2010, PATTERN RECOGN LETT, V31, P2337, DOI 10.1016/j.patrec.2010.07.006
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhou JX, 2018, INT J MACH LEARN CYB, V9, P677, DOI 10.1007/s13042-016-0597-9
   Zhou W., 2017, Recent Advance in Content-based Image Retrieval: A Literature Survey
   Zhou YP., 2001, 4th IAPR International Workshop on Graphics Recognition, GREC, P482
NR 57
TC 7
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10417
EP 10439
DI 10.1007/s11042-020-10186-z
EA NOV 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000591815700001
DA 2024-07-18
ER

PT J
AU He, J
AF He, Jie
TI Design and implementation of an improved wavelet model for processing
   sound production images in vocal music
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Improved wavelet model; Sound production images; Vocal music; Image
   segmentation
AB This paper aims to acquire the crack information from the sound production images in vocal music in an accurate and comprehensive manner. Firstly, the image processing technology based on partial differential equations was introduced, and the principle of wavelet model was expounded. Considering the defects of the wavelet model, an improved wavelet model was constructed based on image enhancement function. The improved model was applied to process the sound production images in vocal music, which contain single crack or multiple cracks, respectively, producing high-quality binary images on the cracks of sound production in vocal music. The binary images were quantified to obtain the characteristic parameters of the sound source in vocal music, laying the basis for further research into sound production in vocal music. To verify its effectiveness, the improved wavelet model was compared with the traditional wavelet model through simulation experiment. The results show that the improved wavelet model achieved better image segmentation effect and quantified the microstructure of the sound source more accurately than the traditional wavelet model. Finally, the authors proved that the proposed model can be used to compute the coefficients of sound production with cracks and the damage variables of microstructure.
C1 [He, Jie] Taiyuan Normal Univ, Mus Dept, Jinzhong 030619, Peoples R China.
C3 Taiyuan Normal University
RP He, J (corresponding author), Taiyuan Normal Univ, Mus Dept, Jinzhong 030619, Peoples R China.
EM 18103511507@163.com
CR Bhadra J, 2020, MULTIMED TOOLS APPL, V79, P25215, DOI 10.1007/s11042-020-09162-4
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1522, DOI 10.1109/83.862630
   DAUBECHIES I, 1993, SIAM J MATH ANAL, V24, P499, DOI 10.1137/0524031
   Huang YL, 2018, TRAIT SIGNAL, V35, P137, DOI 10.3166/TS.35.137-151
   Kaur R, 2013, INT J SCI EMERGING T, V10, P12
   Kuraparthi S, 2019, TRAIT SIGNAL, V36, P565, DOI 10.18280/ts.360612
   Leung K. H., 2001, ISCAS 2001. The 2001 IEEE International Symposium on Circuits and Systems (Cat. No.01CH37196), P235, DOI 10.1109/ISCAS.2001.922028
   Luisier F, 2007, IEEE T IMAGE PROCESS, V16, P593, DOI 10.1109/TIP.2007.891064
   MALLAT S, 1991, IEEE T INFORM THEORY, V37, P1019, DOI 10.1109/18.86995
   Mallat S., 2002, WAVELET TOUR SIGNAL, V3rd
   Panigrahi SK, 2018, TRAIT SIGNAL, V35, P121, DOI 10.3166/TS.35.121-136
   Rommes, 1966, FLUID FLOW FRACTURES, P7
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   Tolos M, 2005, CONSUM COMM NETWORK, P71
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   XU YS, 1994, IEEE T IMAGE PROCESS, V3, P747, DOI 10.1109/83.336245
   Zhang Chao, 2012, Computer Engineering, V38, P131, DOI 10.3969/j.issn.1000-3428.2012.10.040
NR 17
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21925
EP 21939
DI 10.1007/s11042-020-10168-1
EA NOV 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000590967300003
DA 2024-07-18
ER

PT J
AU Zhang, B
   Oh, K
AF Zhang, Bo
   Oh, Kyoungsu
TI Indirect illumination with efficient monte carlo integration and
   denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time rendering; Indirect illumination; Indirect visibility; Ray
   marching; 3D mipmap; Interactive denoising
ID PERFORMANCE
AB Herein, an interactive, one-bounce, and indirect illumination algorithm that considers indirect visibility even in a fully dynamic scene is introduced. First, a small number of rays are randomly emitted on the hemisphere of the current pixel to obtain the first intersection point in a scene. If this point is directly illuminated by the light source, its illuminated color is collected by sampling the reflective shadow maps for gathering the indirect illumination. Second, to approximate indirect visibility, a three-dimensional ray marching algorithm (MRM) is used; the algorithm is based on a mipmap hierarchy structure generated by voxelizing the scene to accelerate the ray-voxel intersection. Third, images of indirect illumination are denoised by iterating an improved edge-avoiding filtering via a local means replacement method (LMR). Finally, variance-clip temporal filtering on the merged global illumination image is applied to further eliminate jitter. The implementation demonstrates that the algorithm used in this study can efficiently generate high-quality global illumination images.
C1 [Zhang, Bo; Oh, Kyoungsu] Soongsil Univ, Dept Media, Seoul, South Korea.
C3 Soongsil University
RP Zhang, B (corresponding author), Soongsil Univ, Dept Media, Seoul, South Korea.
EM zhangbo0037@soongsil.ac.kr; oks@soongsil.ac.kr
OI ZHANG, BO/0000-0001-7139-085X
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2018R1D1A1B07050099]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (2018R1D1A1B07050099).
CR [Anonymous], 1978, P 5 ANN C COMPUTER G, P270
   Bako S, 2017, ACM T GRAPHIC, V36, DOI [10.1145/3072959.3073703, 10.1145/3072959.3073708]
   Christensen PH, 2014, FOUND TRENDS COMPUT, V10, pI, DOI 10.1561/0600000073
   Claypool KT, 2007, MULTIMEDIA SYST, V13, P3, DOI 10.1007/s00530-007-0081-1
   Crassin C., 2009, P 2009 S INT 3D GRAP, P15, DOI [10.1145/1507149.1507152, DOI 10.1145/1507149.1507152]
   Crassin C, 2011, COMPUT GRAPH FORUM, V30, P1921, DOI 10.1111/j.1467-8659.2011.02063.x
   Dachsbacher C., 2005, Proc. Symp. Interactive Graph. and Games, P203, DOI DOI 10.1145/1053427.1053460
   Dachsbacher C., 2006, Proc. Symp. Interactive 3D Graph. and Games, Redwood City, P93, DOI DOI 10.1145/1111411.1111428
   Dammertz H, 2010, C HIGH PERFORMANCE G
   Dong Z, 2009, P VISION MODELING VI
   Eilertsen G, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818092
   Fattal R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477933
   FUJIMOTO A, 1986, IEEE COMPUT GRAPH, V6, P16, DOI 10.1109/MCG.1986.276715
   Ganestam P, 2016, COMPUT GRAPH FORUM, V35, P285, DOI 10.1111/cgf.12831
   Huang J, 1998, IEEE S VOLUME VISUAL
   Jamriska O, 2010, P CESCG 2010 14TH CE
   Jensen H. W., 1996, Rendering Techniques '96. Proceedings of the Eurographics Workshop. Eurographics, P21
   Kajiya J.T., 1986, P 13 ANN C COMP GRAP, P143, DOI 10.1145/15922.15902
   Kaplanyan A., 2010, Proceedings of the 2010 ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games, I3D'10, P99, DOI [10.1145/1730804.1730821, 10.1145/1730804.1730821.24, DOI 10.1145/1730804.1730821.24]
   Karis B, 2014, ADV REALTIME RENDERI
   Kay T. L., 1986, Computer Graphics, V20, P269, DOI 10.1145/15886.15916
   Keller A., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P49, DOI 10.1145/258734.258769
   Laine S., 2007, P EUR S REND, P277, DOI DOI 10.2312/EGWR/EGSR07/277-286
   Lensing P., 2013, I3D 13 P ACM SIGGRAP, P95
   MARA M, 2017, EFFICIENT DENOISING
   Nichols G., 2009, P 2009 S INTERACTIVE, P83, DOI DOI 10.1145/1507149.1507162
   Nichols G, 2009, COMPUT GRAPH FORUM, V28, P1141, DOI 10.1111/j.1467-8659.2009.01491.x
   Oh K., 2006, Proceedings of the ACM symposium on Virtual reality software and technology, P75
   Perlin K., 1989, Computer Graphics, V23, P253, DOI 10.1145/74334.74359
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   PRUTKIN R., 2012, Eurographics 2012-Short Papers, P9
   Ritschel T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409082
   Ritschel T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618478
   Ritschel T, 2012, COMPUT GRAPH FORUM, V31, P160, DOI 10.1111/j.1467-8659.2012.02093.x
   Ritschel T, 2011, COMPUT GRAPH FORUM, V30, P2258, DOI 10.1111/j.1467-8659.2011.01998.x
   Salvi M, 2016, GDC16 SAN FRANCISCO
   Schied C, 2017, SPATIOTEMPORAL VARIA
   Schwarz M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866201
   Sugihara M, 2014, LAYERED REFLECTIVE S
   Thiedemann Sinje., 2011, Symposium on Interactive 3D Graphics and Games, I3D '11, P103
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tomczak LJ, 2012, TECHNICAL REPORT
   Vinkler M, 2016, COMPUT GRAPH FORUM, V35, P68, DOI 10.1111/cgf.12776
   Yang JC, 2010, COMPUT GRAPH FORUM, V29, P1297, DOI 10.1111/j.1467-8659.2010.01725.x
NR 44
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10167
EP 10185
DI 10.1007/s11042-020-09884-5
EA NOV 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000590232700005
DA 2024-07-18
ER

PT J
AU Wang, Y
   Huang, YB
   Zhang, R
   Zhang, QY
AF Wang, Yong
   Huang, Yi-bo
   Zhang, Ran
   Zhang, Qiu-yu
TI Multi-format speech BioHashing based on energy to zero ratio and
   improved LP-MMSE parameter fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech content authentication; BioHashing; LP-MMSE; Henon map; MCD;
   Comparative difference method
ID HARMONIC FOURIER MOMENTS; AUTHENTICATION; BIOMETRICS; AUDIO;
   SPECTROGRAM; SECURITY; PROTOCOL; SCHEME
AB In order to solve the problems of poor security and small application scope of speech content authentication, and to improve the robustness, discrimination and real-time performance of speech authentication, a multi-format speech BioHashing algorithm based on energy to zero ratio and improved linear prediction minimum mean square error (LP-MMSE) parameter fusion is proposed. Firstly, the algorithm extracts the short-term logarithmic energy, zero-crossing rate and the covariance method's LP-MMSE of speech signal to be processed. Then, the time-frequency parameters are fused, and the fused feature vector and the orthogonal normalized random matrix of the key control are generated into BioHashing sequences through the inner product form. Finally, the BioHashing is encrypted by equal-length scrambling using henon chaotic map. The experimental results show that the proposed algorithm not only has the characteristics of good discrimination, strong robustness, good security, high real-time performance and wide application range, but also realizes the detection and localization of small-scale tampering of speech through minimum code distance (MCD) algorithm. At the same time, the algorithm also validates the unidirectionality of BioHashing with trapdoor by comparative difference method.
C1 [Wang, Yong; Huang, Yi-bo; Zhang, Ran] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
   [Zhang, Qiu-yu] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
C3 Northwest Normal University - China; Lanzhou University of Technology
RP Huang, YB (corresponding author), Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
EM 15737315638@163.com; huang_yibo@foxmail.com; 15732029548@163.com;
   zhangqylz@163.com
RI Yong, Wang/AAW-8984-2020; zhang, qiu/GXG-5600-2022
OI Yong, Wang/0000-0002-8326-2924; /0000-0003-1667-3114
FU National Natural Science Foundation of China [61862041]; Youth Science
   and Technology Fund of Gansu Province of China [1606RJYA274]
FX This work is supported by the National Natural Science Foundation of
   China(No.61862041), Youth Science and Technology Fund of Gansu Province
   of China(No.1606RJYA274).
CR Aghili SF, 2019, FUTURE GENER COMP SY, V96, P410, DOI 10.1016/j.future.2019.02.020
   Alpar O, 2018, APPL INTELL, V48, P1189, DOI 10.1007/s10489-017-1009-x
   Amin R, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0258-7
   [Anonymous], 2015, J INF HIDING MULTIME
   Atighehchi K, 2019, FUTURE GENER COMP SY, V101, P819, DOI 10.1016/j.future.2019.07.022
   Awais A, 2018, 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD), P271, DOI 10.1109/ICAIBD.2018.8396208
   Chen N, 2010, IET COMMUN, V4, P1722, DOI 10.1049/iet-com.2009.0749
   Chen N, 2013, DIGIT SIGNAL PROCESS, V23, P1216, DOI 10.1016/j.dsp.2013.01.012
   Chen YZ, 2019, SIGNAL PROCESS, V154, P314, DOI 10.1016/j.sigpro.2018.09.013
   Huang Y-B, 2018, IJ NETW SECUR, V20, P206
   Huang Y-B, 2017, J SOFTW ENG, V11, P22, DOI [10.3923/jse.2017.22.31, DOI 10.3923/JSE.2017.22.31]
   Jiang Q, 2018, J AMB INTEL HUM COMP, V9, P1061, DOI 10.1007/s12652-017-0516-2
   Jin Z, 2018, IEEE T INF FOREN SEC, V13, P393, DOI 10.1109/TIFS.2017.2753172
   Kim HG, 2016, CLUSTER COMPUT, V19, P315, DOI 10.1007/s10586-015-0523-z
   Kumar D, 2019, J INF SECUR APPL, V47, P8, DOI 10.1016/j.jisa.2019.03.008
   Kumari S, 2017, FUTURE GENER COMP SY, V68, P320, DOI 10.1016/j.future.2016.10.004
   Li JF, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P363, DOI 10.1109/CIS.2015.94
   Li JF, 2015, CHINESE J ELECTRON, V24, P579, DOI 10.1049/cje.2015.07.024
   LIU J, 2019, APPL SCI BASEL, V9
   Lotia P, 2013, IJRCCT, V2, P579
   Lumini A, 2007, PATTERN RECOGN, V40, P1057, DOI 10.1016/j.patcog.2006.05.030
   Qian Q, 2018, TELECOMMUN SYST, V67, P635, DOI 10.1007/s11235-017-0360-x
   Qiuyu Zhang, 2017, 2017 13th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD), P1295, DOI 10.1109/FSKD.2017.8392951
   Sheela SJ, 2018, MULTIMED TOOLS APPL, V77, P25223, DOI 10.1007/s11042-018-5782-2
   Siddavatam I, 2019, STUD COMPUT INTELL, V771, P293, DOI 10.1007/978-981-10-8797-4_31
   Srinivas J, 2019, INF TECHNOL CONTROL, V48, P129, DOI 10.5755/j01.itc.48.1.17270
   Teoh ABJ, 2008, PATTERN RECOGN, V41, P2034, DOI 10.1016/j.patcog.2007.12.002
   Verma G, 2019, OPT LASER ENG, V123, P28, DOI 10.1016/j.optlaseng.2019.06.028
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang CP, 2018, INFORM SCIENCES, V450, P141, DOI 10.1016/j.ins.2018.03.040
   Wodecki J, 2019, MECH SYST SIGNAL PR, V130, P585, DOI 10.1016/j.ymssp.2019.05.020
   Xia ZQ, 2019, SIGNAL PROCESS, V157, P108, DOI 10.1016/j.sigpro.2018.11.011
   Yenigalla P, 2018, INTERSPEECH, P3688, DOI 10.21437/Interspeech.2018-1811
   Zhang Q, 2018, INT J INF COMMUN TEC, V12, P31, DOI DOI 10.1504/IJICT.2018.089021
   Zhang Q.Y., 2018, J INF HIDING MULTIME, V9, P1452
   Zhang QY, 2018, MULTIMED TOOLS APPL, V77, P21653, DOI 10.1007/s11042-018-5613-5
   Zhang QY, 2018, MULTIMED TOOLS APPL, V77, P1555, DOI 10.1007/s11042-017-4381-y
   Zhang Qiuyu, 2018, Journal of Huazhong University of Science and Technology (Natural Science Edition), V46, P58, DOI 10.13245/j.hust.180311
   Zhang Qiuyu, 2017, Journal of Huazhong University of Science and Technology (Natural Science Edition), V45, P33, DOI 10.13245/j.hust.170907
   Zhang Qiuyu, 2016, Journal of Huazhong University of Science and Technology (Natural Science Edition), V44, P127, DOI 10.13245/j.hust.161222
   [张秋余 Zhang Qiuyu], 2016, [北京邮电大学学报, Journal of Beijing University of Posts Telecommunications], V39, P77
   Zhang XM, 2018, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: IOT AND SMART CITY (ICIT 2018), P110, DOI 10.1145/3301551.3301600
NR 43
TC 4
Z9 5
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10013
EP 10036
DI 10.1007/s11042-020-09701-z
EA NOV 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000589565300003
DA 2024-07-18
ER

PT J
AU Kim, J
   Lee, J
   Chung, M
   Shin, YG
AF Kim, Jiwan
   Lee, Jeongjin
   Chung, Minyoung
   Shin, Yeong-Gil
TI Multiple weld seam extraction from RGB-depth images for automatic
   robotic welding via point cloud registration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Seam extraction; 3D reconstruction; Point cloud registration; Multiple
   weld seam extraction
ID IDENTIFICATION; VISION; TRACKING; SENSOR
AB Robotic welding technology is constantly growing with the development of vision technologies. To establish a fully automatic robotic welding system, an automated weld seam extraction process with accurate perception of the target workpiece (i.e., object) is one of the most challenging tasks. Although many methods pertaining to automatic weld seam extraction have been proposed, most of the previous studies are difficult to employ in practical systems because the algorithms are unable to simultaneously handle multiple and occluded seams from arbitrary view directions. In this study, we propose a novel method to extract weld seams based on point cloud registration from various view directions that can handle randomly occluded seams in a workpiece with multiple seam parts. We focus on the shape of the weld seams as a line or curve, which are dominant structures in the field. Initially, we extract all detectable weld seams for each image with a single view direction obtained using an RGB-depth vision sensor. Subsequently, three-dimensional points of weld seams obtained from each view direction are filtered based on the edge cues from RGB images. Finally, the extracted weld seams obtained from the various view directions are merged by employing a point cloud registration technique. The experimental results demonstrate that the proposed method outperforms a state-of-the-art method in terms of detection accuracy. Our proposed algorithm can be employed for dynamic workpiece scenes, which indicates that multiple weld seams can be successfully extracted from arbitrary view directions containing scene occlusions.
C1 [Kim, Jiwan; Chung, Minyoung; Shin, Yeong-Gil] Seoul Natl Univ, Dept Comp Sci & Engn, 1 Gwanak Ro, Seoul 08826, South Korea.
   [Lee, Jeongjin] Soongsil Univ, Sch Comp Sci & Engn, 369 Sangdo Ro, Seoul 06978, South Korea.
C3 Seoul National University (SNU); Soongsil University
RP Chung, M (corresponding author), Seoul Natl Univ, Dept Comp Sci & Engn, 1 Gwanak Ro, Seoul 08826, South Korea.
EM jwkim@cglab.snu.ac.kr; leejeongjin@ssu.ac.kr; chungmy@snu.ac.kr;
   yshin@snu.ac.kr
RI Chung, Minyoung/U-4310-2019
OI Chung, Minyoung/0000-0001-7503-3307
FU Osstem Implant Inc. [0536-20190132]
FX This work was supported by Osstem Implant Inc. (No. 0536-20190132,
   AI-based Panoramic, and CT Image Detection).
CR Ahmed SM, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2610, DOI 10.1109/IROS.2016.7759406
   Akinlar C, 2011, PATTERN RECOGN LETT, V32, P1633, DOI 10.1016/j.patrec.2011.06.001
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Desolneux A, 2001, J MATH IMAGING VIS, V14, P271, DOI 10.1023/A:1011290230196
   Desolneux A, 2000, INT J COMPUT VISION, V40, P7, DOI 10.1023/A:1026593302236
   Dinham M, 2014, ROBOT CIM-INT MANUF, V30, P229, DOI 10.1016/j.rcim.2013.10.008
   Dinham M, 2013, ROBOT CIM-INT MANUF, V29, P288, DOI 10.1016/j.rcim.2013.01.004
   Fang ZJ, 2011, IEEE-ASME T MECH, V16, P540, DOI 10.1109/TMECH.2010.2045766
   Fernandes LAF, 2008, PATTERN RECOGN, V41, P299, DOI 10.1016/j.patcog.2007.04.003
   GORDON WJ, 1974, COMPUT AIDED GEOM D, P95, DOI DOI 10.1016/B978-0-12-079050-0.50011-4
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Lee SK, 2002, J MANUF SYST, V21, P302, DOI 10.1016/S0278-6125(02)80169-8
   Li J, 2008, PATTERN RECOGN, V41, P3244, DOI 10.1016/j.patcog.2008.03.018
   Li J, 2019, INT J HUM ROBOT, V16, DOI 10.1142/S0219843619410020
   Li J, 2016, CHIN CONTR CONF, P6217, DOI 10.1109/ChiCC.2016.7554333
   Liu FQ, 2018, INT J ADV MANUF TECH, V99, P2059, DOI 10.1007/s00170-018-2574-9
   Liu JC, 2017, IEEE T AUTOM SCI ENG, V14, P1096, DOI 10.1109/TASE.2015.2498929
   Liu Y, 2019, ROBOT CIM-INT MANUF, V57, P404, DOI 10.1016/j.rcim.2018.12.018
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu XH, 2015, IEEE IMAGE PROC, P507, DOI 10.1109/ICIP.2015.7350850
   Maiolino P, 2017, ROBOT CIM-INT MANUF, V48, P188, DOI 10.1016/j.rcim.2017.04.004
   Muhammad J, 2018, INT J ADV MANUF TECH, V94, P13, DOI 10.1007/s00170-016-9481-8
   Nunes Joao Ferreira, 2019, VipIMAGE 2019. Proceedings of the VII ECCOMAS Thematic Conference on Computational Vision and Medical Image Processing. Lecture Notes in Computational Vision and Biomechanics (LNCVB 34), P366, DOI 10.1007/978-3-030-32040-9_38
   Rodríguez-Martín M, 2017, IEEE SENS J, V17, P4217, DOI 10.1109/JSEN.2017.2700954
   Rout A, 2019, ROBOT CIM-INT MANUF, V56, P12, DOI 10.1016/j.rcim.2018.08.003
   Rusu RB, 2010, KUNSTL INTELL, V24, P345, DOI 10.1007/s13218-010-0059-6
   Segal A., 2009, P ROB SCI SYST 5 JUN, P435
   Shah HNM, 2018, ROBOT CIM-INT MANUF, V51, P181, DOI 10.1016/j.rcim.2017.12.007
   Silvers GA, 2014, ADV MATER RES-SWITZ, V875-877, P1967, DOI 10.4028/www.scientific.net/AMR.875-877.1967
   Sun Y., 2020, IET IMAGE PROCESSING
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Wang NF, 2020, ROBOT CIM-INT MANUF, V61, DOI 10.1016/j.rcim.2019.101821
   Wu JP, 2019, PROC INT SYMP POWER, P203, DOI [10.1109/ispsd.2019.8757619, 10.1109/ISPSD.2019.8757619]
   Yang L, 2020, ROBOT CIM-INT MANUF, V64, DOI 10.1016/j.rcim.2019.101929
   Yang L, 2019, IEEE SENS J, V19, P763, DOI 10.1109/JSEN.2018.2877976
   Zhang S, 2018, OPT LASER ENG, V106, P119, DOI 10.1016/j.optlaseng.2018.02.017
NR 36
TC 17
Z9 18
U1 9
U2 75
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9703
EP 9719
DI 10.1007/s11042-020-10138-7
EA NOV 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000589699900001
DA 2024-07-18
ER

PT J
AU Song, ZY
   Zhao, XQ
   Jiang, HM
AF Song, Zhaoyang
   Zhao, Xiaoqiang
   Jiang, Hongmei
TI Gradual deep residual network for <i>super</i>-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image super-resolution; Gradual deep residual network; Residual
   block connected by residual; Sub-pixel convolutional layer
ID IMAGE QUALITY ASSESSMENT
AB Deep neural networks with single upsampling have achieved the improvement of performance for single image super-resolution. However, these networks lose a lot of details of low-resolution image in the reconstruction process. In this paper, we propose a gradual deep residual network for super-resolution (GDSR), which consists of multiple reconstruction network with 2 scale factor (2X reconstruction network). In 2X reconstruction network, a residual block connected by residual (RBR) is proposed to form a deep residual network, which is used to extract the depth features of low-resolution images; then the extracted features are upsampled into the features of high-resolution image by sub-pixel convolutional layer. GDSR gradually reconstructs high-quality high-resoluiton images from low-resolution images by multiple 2X reconstruction networks. Extensive experiments on benchmark datasets demonstrate that the proposed GDSR outperforms the state-of-the-art methods in terms of quantitative evaluation, visual evaluation, and execution time evaluation.
C1 [Song, Zhaoyang; Zhao, Xiaoqiang; Jiang, Hongmei] Lanzhou Univ Technol, Coll Elect Engn & Informat Engn, Lanzhou 730050, Peoples R China.
   [Zhao, Xiaoqiang; Jiang, Hongmei] Key Lab Gansu Adv Control Ind Proc, Lanzhou 730050, Peoples R China.
   [Zhao, Xiaoqiang; Jiang, Hongmei] Lanzhou Univ Technol, Natl Expt Teaching Ctr Elect & Control Engn, Lanzhou 730050, Peoples R China.
C3 Lanzhou University of Technology; Lanzhou University of Technology
RP Zhao, XQ (corresponding author), Lanzhou Univ Technol, Coll Elect Engn & Informat Engn, Lanzhou 730050, Peoples R China.; Zhao, XQ (corresponding author), Key Lab Gansu Adv Control Ind Proc, Lanzhou 730050, Peoples R China.; Zhao, XQ (corresponding author), Lanzhou Univ Technol, Natl Expt Teaching Ctr Elect & Control Engn, Lanzhou 730050, Peoples R China.
EM xqzhao@lut.cn
FU National Natural Science Foundation of China [61763029, 61873116];
   Industrial support and guidance project of colleges and universities of
   Gansu Province [2019C-05]; open fund project of Key Laboratory of Gansu
   Advanced Control for Industrial Processes [2019KFJJ01]
FX This work is supported by the National Natural Science Foundation of
   China (61763029, 61873116), the Industrial support and guidance project
   of colleges and universities of Gansu Province (2019C-05), the open fund
   project of Key Laboratory of Gansu Advanced Control for Industrial
   Processes (2019KFJJ01) and the open fund project of Key Laboratory of
   Gansu Advanced Control for Industrial Processes (2019KFJJ01).
CR Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen L., 2007, COMPUTER ENG DESIGN, V28, P15
   Chen YB, 2020, J CONTEMP CHINA, V29, P1, DOI [10.1080/10670564.2019.1621526, 10.1080/01932691.2020.1791172, 10.1007/s12652-020-02066-z]
   Chen Y, 2021, VIROL SIN, V36, P365, DOI 10.1007/s12250-020-00250-1
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Ding L, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8891778
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   FRITSCH FN, 1980, SIAM J NUMER ANAL, V17, P238, DOI 10.1137/0717021
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   HUANG JB, 2015, PROC CVPR IEEE, P5197, DOI DOI 10.1109/CVPR.2015.7299156
   Jiang N, 2015, QUANTUM INF PROCESS, V14, P1559, DOI 10.1007/s11128-014-0841-8
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Lai W-S, 2017, PROC CVPR IEEE, P624, DOI DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lu X, 2020, COMPUTER VISION PATT
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Patanavijit V, 2006, 2006 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P1717
   Peled S, 2001, MAGN RESON MED, V45, P29, DOI 10.1002/1522-2594(200101)45:1<29::AID-MRM1005>3.0.CO;2-Z
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   STARK H, 1989, J OPT SOC AM A, V6, P1715, DOI 10.1364/JOSAA.6.001715
   [苏衡 Su Heng], 2013, [自动化学报, Acta Automatica Sinica], V39, P1202
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang XM, 2017, MULTIMED TOOLS APPL, V76, P24871, DOI 10.1007/s11042-017-4639-4
   Yu F, 2019, NEUROCOMPUTING, V350, P108, DOI 10.1016/j.neucom.2019.03.053
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhang LP, 2010, SIGNAL PROCESS, V90, P848, DOI 10.1016/j.sigpro.2009.09.002
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhao Y, 2018, IEEE ACCESS, V6, P39363, DOI 10.1109/ACCESS.2018.2855127
NR 43
TC 10
Z9 14
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 9765
EP 9778
DI 10.1007/s11042-020-10152-9
EA NOV 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000589699900005
DA 2024-07-18
ER

PT J
AU Sravani, M
   Maheswararao, A
   Murthy, MK
AF Sravani, Meesala
   Maheswararao, Aggala
   Murthy, Meesala Krishna
TI Robust detection of video text using an efficient hybrid method via key
   frame extraction and text localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text detection; Maximally stable extremal region; Preprocessing; Text
   region detection; Segmentation; Recognition
ID SCENE; RECOGNITION; IMAGES
AB Video text detection is a challenging problem, since the background of the video image is generally complex and its subtitles often have colour bleeding problems, blurred boundaries and low contrast due to video loss compression and low resolution. Text detection is an important method for many image processing tasks that are focused on text. In this paper, we put forward a robust detection method for extracting video text using hybrid method of MSER via morphological filtering for solving these problems. This can also solve the problems of bleeding in colour and floured boundaries. In this we added 2-D DWT (discrete wavelet transforms) is developed to remove background noise and improve sound and text contrast. SO that components are extracted with MSER from origin and processed images. In this work, the proposed method develops an efficient method of extracting and recognizing text, using the principle of morphological operations using MATLAB. Current text extraction methods-edge dependent and connected components when implemented separately yield better results. But using these approaches sometimes cannot get better results as well as its time taken. Therefore it is suggested that combine both methods, the outcome shows that the approach suggested produces better results than the other two approaches.
C1 [Sravani, Meesala] Satya Inst Technol & Management, Dept Comp Sci & Engn, Vizianagaram 535003, Andhra Pradesh, India.
   [Maheswararao, Aggala] Vignan Inst Engn Women, Dept Comp Sci & Engn, Visakhapatnam 530049, Andhra Pradesh, India.
   [Murthy, Meesala Krishna] Utkal Univ, Dept Biotechnol & Bioinformat, AMIT, Khurja 752050, Odisha, India.
C3 Utkal University
RP Murthy, MK (corresponding author), Utkal Univ, Dept Biotechnol & Bioinformat, AMIT, Khurja 752050, Odisha, India.
EM smeesala502@gmail.com; aggalamaheswararao@gmail.com;
   krishnameesala6@gmail.com
RI Murthy, Krishna/AAS-6100-2021
OI Murthy, Krishna/0000-0002-3634-0053; Sravani,
   Meesala/0000-0001-6883-5248; MAHESWARARAO, AGGALA/0000-0002-8651-4429
CR Abualigah L.M.Q., 2019, STUDIES COMPUTATIONA, V816, DOI [10.1007/978-3-030-10674-4, DOI 10.1007/978-3-030-10674-4]
   Abualigah LM, 2018, J COMPUT SCI-NETH, V25, P456, DOI 10.1016/j.jocs.2017.07.018
   [Anonymous], 2013, P 12 INT C DOC AN RE
   Chen DT, 2004, PATTERN RECOGN, V37, P595, DOI 10.1016/j.patcog.2003.06.001
   Chen H., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2609, DOI 10.1109/ICIP.2011.6116200
   Chen XR, 2004, PROC CVPR IEEE, P366
   Chung- Wei Liang and Po-Yueh Chen, 2004, INT J APPL SCI ENG, V2, P105
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Gonzalez A., 2013, IMAGE VISION COMPUT, V31, P255
   HUO YK, 2010, INT C IM AN SIGN PRO, V2010, P371, DOI DOI 10.1109/IASP.2010.5476095
   Jing Zhang, 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P308, DOI 10.1007/978-3-642-19309-5_24
   Kim HK, 1996, J VIS COMMUN IMAGE R, V7, P336, DOI 10.1006/jvci.1996.0029
   Koo HI, 2013, IEEE T IMAGE PROCESS, V22, P2296, DOI 10.1109/TIP.2013.2249082
   Liu WF, 2015, SIGNAL PROCESS, V110, P101, DOI 10.1016/j.sigpro.2014.08.002
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mosleh A, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.63
   Neumann L, 2013, PROC INT CONF DOC, P523, DOI 10.1109/ICDAR.2013.110
   Pan YF, 2011, IEEE T IMAGE PROCESS, V20, P800, DOI 10.1109/TIP.2010.2070803
   Shekar B., 2011, INT J ARTIFICIAL INT, V1, P77
   Shi CZ, 2013, PROC CVPR IEEE, P2961, DOI 10.1109/CVPR.2013.381
   Shi CZ, 2013, PATTERN RECOGN LETT, V34, P107, DOI 10.1016/j.patrec.2012.09.019
   Shivakumara P, 2013, PROC INT CONF DOC, P594, DOI 10.1109/ICDAR.2013.123
   Shivakumara P, 2011, IEEE T PATTERN ANAL, V33, P412, DOI 10.1109/TPAMI.2010.166
   Singh M, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1250, DOI 10.1109/ICACCI.2015.7275784
   Wei YC, 2012, EXPERT SYST APPL, V39, P10832, DOI 10.1016/j.eswa.2012.03.010
   Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578
   Ye Q., 2014, IEEE Transactions on Pattern Analysis and Machine Intelligence, V37, P1
   Ye QX, 2014, IEEE IMAGE PROC, P1678, DOI 10.1109/ICIP.2014.7025336
   Yi CC, 2011, IEEE T IMAGE PROCESS, V20, P2594, DOI 10.1109/TIP.2011.2126586
   Yin X, 2013, P 36 INT ACMSIGIR C
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Yin XW, 2012, INT C PATT RECOG, P725
NR 32
TC 5
Z9 5
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9671
EP 9686
DI 10.1007/s11042-020-10113-2
EA NOV 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000589699900002
DA 2024-07-18
ER

PT J
AU Yu, YT
   Lu, ZY
   Li, Y
   Liu, DL
AF Yu, Yitong
   Lu, Ziyu
   Li, Yang
   Liu, Delong
TI ASTS: attention based spatio-temporal sequential framework for movie
   trailer genre classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Movie genre classification; Self-attention; Spatio-temporal model;
   Sequential modeling
AB Automatic movie trailer genre classification is a challenging task because trailers have more diverse content and high-level sequential semantic concepts within the movie storyline, which can help for multimedia search and personalized movie recommendation. Traditional methods generally extract the low-level features or consider the local sequential dependencies among trailer frames, ignoring the global high-level sequential semantic concepts. In this manuscript, we propose a novel and effective Attention based Spatio-temporal Sequential Framework (ASTS) for movie trailer genre classification. The proposed framework mainly consists of two modules, respectively the spatio-temporal descriptive module and the attention-based sequential module. The spatio-temporal descriptive module adopts some advanced convolution neural networks to extract the spatio-temporal features of key trailer frames, which can capture the local spatio-temporal semantic features. The attention-based sequential module is designed to process the extracted spatio-temporal feature representation sequence for capturing the global high-level sequential semantic concepts within the movie storyline. We crawl 14,415 labeled movie trailers from YouTube and integrate them into the public dataset MovieLens. Experiment results show that our proposed framework is superior to state-of-the-art methods.
C1 [Yu, Yitong; Li, Yang] Cent Univ Finance & Econ, Sch Informat, Beijing, Peoples R China.
   [Lu, Ziyu] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
   [Liu, Delong] China Inst Water Resources & Hydropower Res, Beijing, Peoples R China.
C3 Central University of Finance & Economics; Chinese Academy of Sciences;
   Shenzhen Institute of Advanced Technology, CAS; China Institute of Water
   Resources & Hydropower Research
RP Lu, ZY (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
EM limerenceyu@gmail.com; zy.lv@siat.ac.cn; liyang@cufe.edu.cn;
   jkliudl@iwhr.com
CR Abualigah L. M. Q., 2019, Feature selection and enhanced krill herd algorithm for text document clustering, DOI [DOI 10.1007/978-3-030-10674-4, 10.1007/978-3-030-10674-4]
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chu W. -T., 2017, MUSA2 2017 PROC WORK, P39, DOI DOI 10.1145/3132515.3132516
   Chung Junyoung, 2014, ARXIV14123555
   Deldjoo Y, 2016, J DATA SEMANT, V5, P99, DOI 10.1007/s13740-016-0060-9
   Deldjoo Y, 2015, LECT NOTES BUS INF P, V239, P45, DOI 10.1007/978-3-319-27729-5_4
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang HY, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P465
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kingma D. P., 2014, arXiv
   Kundalia K., 2020, AUGMENT HUM RES, V5, P11, DOI [DOI 10.1007/S41133-019-0029-Y, 10.1007/s41133-019-0029-y]
   Li Q, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P159, DOI 10.1145/2911996.2912001
   Rasheed Z, 2005, IEEE T CIRC SYST VID, V15, P52, DOI 10.1109/TCSVT.2004.839993
   Rasheed Z, 2002, INT C PATT RECOG, P1086, DOI 10.1109/ICPR.2002.1048494
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Simoes GS, 2016, IEEE IJCNN, P259, DOI 10.1109/IJCNN.2016.7727207
   Simonyan K, 2014, ADV NEUR IN, V27
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wehrmann J, 2017, INTELLIGENT SYSTEMS
   Wehrmann J, 2017, APPL SOFT COMPUT, V61, P973, DOI 10.1016/j.asoc.2017.08.029
   Zha Shengxin., 2015, BMVC
   Zhou H, 2010, INT C MULT
NR 27
TC 9
Z9 9
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 9749
EP 9764
DI 10.1007/s11042-020-10125-y
EA NOV 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000589699900003
DA 2024-07-18
ER

PT J
AU Palestra, G
   Pino, O
AF Palestra, Giuseppe
   Pino, Olimpia
TI Detecting emotions during a memory training assisted by a social robot
   for individuals with Mild Cognitive Impairment (MCI)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Social robot; Memory training; Mild
   Cognitive Impairment
ID TELEPRESENCE; DEMENTIA
AB The attention towards robot-assisted therapies (RAT) had grown steadily in recent years particularly for patients with dementia. However, rehabilitation practice using humanoid robots for individuals with Mild Cognitive Impairment (MCI) is still a novel method for which the adherence mechanisms, indications and outcomes remain unclear. An effective computing represents a wide range of technological opportunities towards the employment of emotions to improve human-computer interaction. Therefore, the present study addresses the effectiveness of a system in automatically decode facial expression from video-recorded sessions of a robot-assisted memory training lasted two months involving twenty-one participants. We explored the robot's potential to engage participants in the intervention and its effects on their emotional state. Our analysis revealed that the system is able to recognize facial expressions from robot-assisted group therapy sessions handling partially occluded faces. Results indicated reliable facial expressiveness recognition for the proposed software adding new evidence base to factors involved in Human-Robot Interaction (HRI). The use of a humanoid robot as a mediating tool appeared to promote the engagement of participants in the training program. Our findings showed positive emotional responses for females. Tasks affects differentially affective involvement. Further studies should investigate the training components and robot responsiveness.
C1 [Palestra, Giuseppe] HERO Srl, Res Dept, Bari, Italy.
   [Pino, Olimpia] Univ Parma, Dept Med & Surg, Parma, Italy.
C3 University of Parma
RP Pino, O (corresponding author), Univ Parma, Dept Med & Surg, Parma, Italy.
EM giuseppepalestra@gmail.com; olimpia.pino@unipr.it
RI Pino, Olimpia/AFY-8034-2022; Palestra, Giuseppe/HLW-6307-2023
OI Pino, Olimpia/0000-0003-3035-8401; PALESTRA,
   GIUSEPPE/0000-0002-0159-2672
FU Universita degli Studi di Parma within the CRUI-CARE Agreement
FX Open access funding provided by Universita degli Studi di Parma within
   the CRUI-CARE Agreement.
CR ALBERT MS, 1991, ARCH NEUROL-CHICAGO, V48, P791, DOI 10.1001/archneur.1991.00530200027013
   [Anonymous], 2007, PALESTRA MENTE STIMO
   [Anonymous], 2006, DARWIN FACIAL EXPRES
   Back I., 2013, Annals of Long-Term Care: Clinical Care and Aging, V21, P38
   Bailey PE, 2020, J GERONTOL B-PSYCHOL, V75, P802, DOI 10.1093/geronb/gby084
   Beadle JN, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00331
   Beck A, 2013, INT J SOC ROBOT, V5, P325, DOI 10.1007/s12369-013-0193-z
   Boissy P, 2007, J TELEMED TELECARE, V13, P79, DOI 10.1258/135763307780096195
   Carolis Berardina, 2015, Foundations of Intelligent Systems. 22nd International Symposium, ISMIS 2015. Proceedings: LNCS 9384, P273, DOI 10.1007/978-3-319-25252-0_30
   Corcella L, 2019, MULTIMED TOOLS APPL, V78, P21557, DOI 10.1007/s11042-019-7449-z
   Dahl TS, 2014, ROBOTICS, V3, P1, DOI 10.3390/robotics3010001
   Damasio Antonio R, 1995, Descartes' Error-Emotion, Reason and the Human Brain
   Dautenhahn K., 2002, COGN SYST RES, V3, P397, DOI [10.1016/S1389-0417(02)00050-5, DOI 10.1016/S1389-0417(02)00050-5]
   De Carolis B, 2019, P WORKSH SOC TECHN I, P42
   De Carolis B, 2019, LECT NOTES ARTIF INT, V11606, P687, DOI 10.1007/978-3-030-22999-3_59
   De Carolis B, 2017, MULTIMED TOOLS APPL, V76, P5073, DOI 10.1007/s11042-016-3797-0
   DeCarolis BN, 2015, ESSEM AAMAS, P19
   Elferink MWO, 2015, TRANSL NEUROSCI, V6, P139, DOI 10.1515/tnsci-2015-0013
   Farina E, 2017, FRONT AGING NEUROSCI, V9, DOI 10.3389/fnagi.2017.00371
   Fincannon T., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P1089
   Gauthier S, 2006, LANCET, V367, P1262, DOI 10.1016/S0140-6736(06)68542-5
   Gazzola V, 2007, NEUROIMAGE, V35, P1674, DOI 10.1016/j.neuroimage.2007.02.003
   Gross HM, 2011, IEEE SYS MAN CYBERN, P2481, DOI 10.1109/ICSMC.2011.6084050
   Gross HM, 2012, IEEE SYS MAN CYBERN, P637, DOI 10.1109/ICSMC.2012.6377798
   Karas GB, 2004, NEUROIMAGE, V23, P708, DOI 10.1016/j.neuroimage.2004.07.006
   Kasper S, 2020, WORLD J BIOL PSYCHIA, V21, P579, DOI 10.1080/15622975.2019.1696473
   Knapp M.L., 2013, Cengage Learning
   Kory Jacqueline, 2014, 2014 IEEE RO-MAN. 23rd IEEE International Symposium on Robot and Human Interactive Communication, P643, DOI 10.1109/ROMAN.2014.6926325
   Law M, 2019, BMJ OPEN, V9, DOI 10.1136/bmjopen-2019-031937
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Martín F, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/54765
   Martin Francisco., 2013, Journal of Physical Agents, V7, P48
   McCade D, 2011, DEMENT GERIATR COGN, V32, P257, DOI 10.1159/000335009
   Moyle W, 2014, BMC GERIATR, V14, DOI 10.1186/1471-2318-14-7
   Nourbakhsh IR, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P3636
   Palestra G., 2017, WAIAH AI IA, P17
   Palestra G, 2015, LECT NOTES COMPUT SC, V9280, P518, DOI 10.1007/978-3-319-23234-8_48
   Perugia G, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00690
   Petersen RC, 2014, J INTERN MED, V275, P214, DOI 10.1111/joim.12190
   Petersen RC, 2018, NEUROLOGY, V90, P126, DOI 10.1212/WNL.0000000000004826
   Picard R. W., 1999, Human-Computer Interaction: Ergonomics and User Interfaces. Proceedings of HCI International '99 (8th International Conference on Human-Computer Interaction), P829
   Pino O., 2015, OPEN REHABIL J, V8, P25, DOI [10.2174/1874943720150601E001, DOI 10.2174/1874943720150601E001]
   Pino O, 2020, INT J SOC ROBOT, V12, P21, DOI 10.1007/s12369-019-00533-y
   Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340
   Reyes ME, 2019, INT J ADV ROBOT SYST, V16, DOI 10.1177/1729881418817972
   Rouaix N, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00950
   Sabanovic Selma, 2013, IEEE Int Conf Rehabil Robot, V2013, P6650427, DOI 10.1109/ICORR.2013.6650427
   Spoletini I, 2008, AM J GERIAT PSYCHIAT, V16, P389, DOI 10.1097/JGP.0b013e318165dbce
   Soler MV, 2015, FRONT AGING NEUROSCI, V7, DOI 10.3389/fnagi.2015.00133
   Vital JPM., 2013, 2013 IEEE 2 INT C SE, P1
NR 50
TC 15
Z9 15
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35829
EP 35844
DI 10.1007/s11042-020-10092-4
EA NOV 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000587107900001
OA hybrid
DA 2024-07-18
ER

PT J
AU Setitra, I
   Aouaa, N
   Meziane, A
   Benrabia, A
   Kaced, H
   Belabassi, H
   Ziane, SA
   Zenati, NH
   Djekkoune, O
AF Setitra, Insaf
   Aouaa, Noureddine
   Meziane, Abdelkrim
   Benrabia, Afef
   Kaced, Houria
   Belabassi, Hanene
   Ziane, Sara Ait
   Zenati, Nadia Henda
   Djekkoune, Oualid
TI RGB-topography and X-rays image registration for idiopathic scoliosis
   children patient follow-up
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE X-rays; Image registration; Monomodal registration; Multimodal
   registration; Idiopathic scoliosis
AB Children diagnosed with a scoliosis pathology are exposed during their follow up to ionic radiations in each X-rays diagnosis. This exposure can have negative effects on the patient's health and cause diseases in the adult age. In order to reduce X-rays scanning, recent systems provide diagnosis of scoliosis patients using solely RGB images. The output of such systems is a set of augmented images and scoliosis related angles. However, these angles, confuse the physicians due to their large number. Moreover, the lack of X-rays scans makes it impossible for the physician to compare RGB and X-rays images, and decide whether to reduce X-rays exposure or not. In this work, we exploit both RGB images of scoliosis captured during clinical diagnosis, and X-rays hard copies provided by patients in order to register both images and give a rich comparison of diagnoses. The work consists in, first, establishing the monomodal (RGB topography of the back) and multimodal (RGB and Xrays) image database, then registering images based on patient landmarks, and finally blending registered images for a visual analysis and follow up by the physician. Proposed registration is based on a rigid transformation that preserves the topology of the patient's back. Parameters of the rigid transformation are estimated using a proposed angle minimization of Cervical vertebra 7, and Posterior Superior Iliac Spine landmarks of a source and target diagnoses. Experiments conducted on the constructed database show a better monomodal and multimodal registration using our proposed method compared to registration using an Equation System Solving based registration.
C1 [Setitra, Insaf; Benrabia, Afef] Univ Sci & Technol Houari Bouemadiene USTHB, Algiers, Algeria.
   [Aouaa, Noureddine; Meziane, Abdelkrim] CERIST, Res Ctr Sci & Tech Informat, Algiers, Algeria.
   [Kaced, Houria; Belabassi, Hanene; Ziane, Sara Ait] Saad Dahleb Univ, Specialized Hosp Bounaama Djilali, Phys Med & Rehabil Serv, Fac Med, Blida, Algeria.
   [Zenati, Nadia Henda; Djekkoune, Oualid] Ctr Dev Adv Technol, Algiers, Algeria.
C3 Centre de Recherche sur l'Information Scientifique et Technique
   (CERIST); Universite Saad Dahlab de Blida
RP Setitra, I (corresponding author), Univ Sci & Technol Houari Bouemadiene USTHB, Algiers, Algeria.
EM isetitra@usthb.dz
RI Meziane, Abdelkrim/AGX-0415-2022
CR A Safari, 2019, J Biomed Phys Eng, V9, P317, DOI 10.31661/jbpe.v9i3Jun.730
   [Anonymous], 2012, ATLAS CLIN GROSS ANA
   Bolzinger M, 2017, THESIS
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   Cobetto N, 2013, THESIS
   De Korvin G., 2014, Annals of Physical and Rehabilitation Medicine, V57, P629, DOI 10.1016/j.rehab.2014.09.002
   García E, 2019, MED IMAGE ANAL, V54, P76, DOI 10.1016/j.media.2019.02.013
   Gesbert JC, 2013, THESIS
   Grewal M., 2020, MEDICAL IMAGING 2020, V11313
   Haskins G, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01060-x
   Iglesias JE, 2018, MED IMAGE ANAL, V50, P127, DOI 10.1016/j.media.2018.09.002
   Janicki JA, 2007, PAED CHILD HEALT-CAN, V12, P771, DOI 10.1093/pch/12.9.771
   Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8
   Medical A, 2008, TECH REP
   Mutneja V, 2015, J ELECT ELECT SYST
   Nag Sayan, 2017, ARXIV171207540
   Palen A, 2016, THESIS
   Pino-Almero L, 2016, J BIOMED OPT, V21, DOI 10.1117/1.JBO.21.11.116001
   Polfliet M, 2018, MED IMAGE ANAL, V46, P15, DOI 10.1016/j.media.2018.02.003
   Porto F, 2010, GAIT POSTURE, V32, P422, DOI 10.1016/j.gaitpost.2010.06.017
   Ronckers CM, 2010, RADIAT RES, V174, P83, DOI 10.1667/RR2022.1
   Szeliski R, 2011, COMPUTER VISION ALGO, V5
   Wang L, 2015, PROGR BIOMEDICAL OPT, V9413
   Wu H, 2017, DESTECH TRANS ECON, P127
   Yi J, 2020, ARXIV200103187
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 27
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9027
EP 9054
DI 10.1007/s11042-020-10146-7
EA NOV 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587279700003
DA 2024-07-18
ER

PT J
AU Mallela, NC
   Volety, R
   Perumal, RS
   Nadesh, RK
AF Mallela, Nikhil Chakravarthy
   Volety, Rohit
   Perumal, R. Srinivasa
   Nadesh, R. K.
TI Detection of the triple riding and speed violation on two-wheelers using
   deep learning algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Triple riding; Object detection; YOLO; Speed violation; Deep learning
AB To curb the accident rate and traffic levels, strict implementation of the rules and continuous monitoring of the traffic is mandatory. Traffic Rule Violation Monitoring System ensures that the rules are followed strictly and it reduces the human effort. The main objective of this work is to identify the Triple Riding. To detect the triple riders, the deep learning framework darknet is used, which in turn uses a type of convolutional neural networks i.e. Deconvolutional neural network-based YOLO (You Only Look Once) algorithm for detection of the number of persons riding a bike, the system classifies the vehicle as to the rule-breach vehicle or not. The junctions acting as the data collections center, collects the data. The image of the vehicle classified as the rule-breach is stored along with the data such as vehicle manufacturing ID and vehicle speed transferred at the particular frame. The transfer of the data is facilitated using the GSM module and the NodeMCU deployed on the vehicle. The vehicle number will be verified with the transport office. To survive the lack of internet connectivity or low internet connectivity, the system is being equipped with the GSM module; else, the data related to the vehicle can be pulled by the development boards deployed at the junctions, acting them as the central part of the public internetwork deployed. This public internetwork acting the medium to pull the data from the vehicle to the central system. This is carried out using the concept of dynamic network configuration in NodeMCU. The use of Node MCU and the public network system makes the system much more viable, available and reliable. Thereby making the riders follow the rules properly and reducing irresponsible driving.
C1 [Mallela, Nikhil Chakravarthy; Perumal, R. Srinivasa; Nadesh, R. K.] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
   [Volety, Rohit] Vellore Inst Technol, Sch Elect Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Vellore
RP Mallela, NC (corresponding author), Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
EM nikhilchakravarthy.mallela@gmail.com; r.srinivasaperumal@vit.ac.in
OI R, Dr. Srinivasa Perumal/0000-0001-7143-7371; Volety,
   Rohit/0000-0002-5547-9376; Mallela, Nikhil
   Chakravarthy/0000-0001-6967-0561
CR Dahiya K, 2016, IEEE IJCNN, P3046, DOI 10.1109/IJCNN.2016.7727586
   Desai M., 2016, Int. J. Eng. Trends Technol, V35, P185, DOI [10.14445/22315381/IJETT-V35P241, DOI 10.14445/22315381/IJETT-V35P241]
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gokhale M., 2018, 2018 4 INT C COMPUTI, P1
   Hu YP, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P568, DOI 10.1109/ROBIO.2013.6739520
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Placzek B, 2010, LECT NOTES COMPUT SC, V6375, P211, DOI 10.1007/978-3-642-15907-7_26
   Rahman Md Atiqur, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P234, DOI 10.1007/978-3-319-50835-1_22
   Raj KCD, 2018, PROC INT WORKSH ADV
   Redmon, 2016, DARKNET OPEN SOURCE
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Satya, 2018, DEEP LEARNING BASED
   Silva SM, 2018, LECT NOTES COMPUT SC, V11216, P593, DOI 10.1007/978-3-030-01258-8_36
   Vishnu C, 2017, IEEE IJCNN, P3036, DOI 10.1109/IJCNN.2017.7966233
   Wang H, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124109
   Xu Z, 2018, INT CONF SYST INFORM, P407, DOI 10.1109/ICSAI.2018.8599403
NR 17
TC 10
Z9 10
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8175
EP 8187
DI 10.1007/s11042-020-10126-x
EA OCT 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000583128600003
DA 2024-07-18
ER

PT J
AU Hammami, A
   Ben Hamida, A
   Ben Amar, C
AF Hammami, Amal
   Ben Hamida, Amal
   Ben Amar, Chokri
TI Blind semi-fragile watermarking scheme for video authentication in video
   surveillance context
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind semi-fragile watermarking; Video authentication; Video
   surveillance; Singular value decomposition; Discrete wavelet transform;
   Quick response code
ID TRANSFORM
AB With the development of advanced multimedia editing tools, numerous unauthorized manipulations are easily doable to surveillance systems video files. Thus, video tamper detection is revealed as a big challenge for multimedia security field researchers. Indeed, we propose herein a singular value decomposition (SVD) and discrete wavelet transform (DWT) based semi fragile watermarking scheme for video content authentication. A content-based authentication signature is firstly generated by extracting reliable features from regions of interest. QR code generation technique as well as Arnold transform are used to boost the security aspect of the watermark. This latter is efficiently hidden in the wavelet middle frequency sub bands through an additive embedding algorithm and then extracted via a blind detection method. Simulation results demonstrate that the proposed scheme jointly achieves a good perceptual quality and a high watermark capacity. In addition, it is capable of distinguishing intentional attacks from incidental modifications. Indeed, the proposed watermarking scheme is very fragile to malicious tampering while allowing non-malicious processing.
C1 [Hammami, Amal; Ben Hamida, Amal; Ben Amar, Chokri] Univ Sfax, Natl Engn Sch Sfax, REs Grp Intelligent Machines, Sfax 3038, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Hammami, A (corresponding author), Univ Sfax, Natl Engn Sch Sfax, REs Grp Intelligent Machines, Sfax 3038, Tunisia.
EM amal.hammami@enis.tn; amal.benhamida@enis.tn; chokri.benamar@ieee.org
RI Chokri, BEN AMAR/K-5237-2012; BEN HAMIDA, Amal/B-5397-2019
OI BEN HAMIDA, Amal/0000-0002-3164-5456
FU Ministry of Higher Education and Scientific Research of Tunisia
   [LR11ES48]
FX The research leading to these results received funding from the Ministry
   of Higher Education and Scientific Research of Tunisia under the grant
   agreement number LR11ES48.
CR Abood O.G., 2018, Information Securityand Computer Fraud, V8, P495
   Agarwal P, 2014, 2014 5TH INTERNATIONAL CONFERENCE CONFLUENCE THE NEXT GENERATION INFORMATION TECHNOLOGY SUMMIT (CONFLUENCE), P657, DOI 10.1109/CONFLUENCE.2014.6949276
   Alenizi F, 2015, IEEE I C ELECT CIRC, P41, DOI 10.1109/ICECS.2015.7440244
   [Anonymous], 2011, INT J COMPUT SCI ENG
   Araghi TK, 2018, EXPERT SYST APPL, V112, P208, DOI 10.1016/j.eswa.2018.06.024
   Asikuzzaman M, 2018, IEEE T CIRC SYST VID, V28, P2131, DOI 10.1109/TCSVT.2017.2712162
   Bartolini F, 2001, P IEEE, V89, P1403, DOI 10.1109/5.959338
   Ben Hamida A, 2013, INT C MULT EXP WORKS, P1
   Ben Hamida A, 2016, MULTIMED TOOLS APPL, V75, P17187, DOI 10.1007/s11042-015-2987-5
   Ben Hamida A, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P384, DOI 10.1109/SAI.2014.6918215
   Bhardwaj A, 2018, MULTIMED TOOLS APPL, V77, P19659, DOI 10.1007/s11042-017-5340-3
   Boreiry M, 2017, 2017 ARTIFICIAL INTELLIGENCE AND ROBOTICS (IRANOPEN), P73, DOI 10.1109/RIOS.2017.7956446
   Chang YC, 2016, 2016 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C), P287, DOI 10.1109/IS3C.2016.82
   Chauhan S., 2016, 2016 IEEE International Conference on Plasma Science (ICOPS), DOI 10.1109/PLASMA.2016.7534009
   Deljavan Amiri D, 2019, MULTIMEDIA SYSTEMS, V25, P1
   Farfoura M, 2016, MULTIMED TOOLS APPL, V75, P7465, DOI 10.1007/s11042-015-2672-8
   Hammami A., 2020, INT C CENTRAL EUROPE, P96, DOI 10.24132/JWSCG.2020.28.12
   Hammami A, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4, P597, DOI 10.5220/0007685305970604
   Hamza R, 2017, J INF SECUR APPL, V35, P119, DOI 10.1016/j.jisa.2017.06.005
   Hasnaoui M, 2012, EUR SIGNAL PR CONF, P1782
   Himeur Y, 2018, MULTIMED TOOLS APPL, V77, P8603, DOI 10.1007/s11042-017-4754-2
   Jenkins N., 2015, '245 million video surveillance cameras installed globally in 2014'
   JINDAL H, 2016, P INT C REC COGN WIR, P1
   Jindal H, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500133
   JOSHI A, 2017, PROC CVPR IEEE, P455
   Joshi AM, 2016, MULTIMED TOOLS APPL, V75, P3121, DOI 10.1007/s11042-014-2426-z
   Jumana W, 2015, INT J MULTIMEDIA UBI, V1, P399
   Kalker T, 1999, VIDEO WATERMARKING S, P103
   Kaur G, 2019, MULTIMED TOOLS APPL, V78, P21245, DOI 10.1007/s11042-019-7456-0
   Kaur Sandeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P23, DOI 10.5815/ijigsp.2017.07.03
   Khosravi M. R., 2019, P 25 INT C PAR DISTR, P87
   Khosravi MR, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1572-4
   Khosravi MR, 2020, IEEE INTERNET THINGS, V7, P2603, DOI 10.1109/JIOT.2019.2952284
   Khosravi MR, 2018, NEURAL COMPUT APPL, V30, P2017, DOI 10.1007/s00521-018-3489-y
   Kim C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040644
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Kirovski D, 2002, ACM INT C MULT, P372
   Kumar S, 2018, J INF SECUR APPL, V43, P123, DOI 10.1016/j.jisa.2018.10.011
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Li JF, 2018, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY (ICVR 2018), P95, DOI 10.1145/3198910.3234660
   Li L, 2018, LECT NOTES COMPUT SC, V11066, P160, DOI 10.1007/978-3-030-00015-8_14
   Li Liu, 2010, 2010 International Conference on E-Business and E-Government (ICEE 2010), P1634, DOI 10.1109/ICEE.2010.414
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Mander Kuldeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P17, DOI 10.5815/ijigsp.2017.08.03
   Mishra A., 2018, 2018 INT JOINT C NEU, P1, DOI [10.1109/IJCNN.2018.8489305, DOI 10.1109/IJCNN.2018.8489305]
   Mittal Archie, 2017, International Journal of Image, Graphics and Signal Processing, V9, P28, DOI 10.5815/ijigsp.2017.05.04
   Nouioua I, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/6712065
   Panyavaraporn J, 2017, PROC SPIE, V10420, DOI 10.1117/12.2281682
   Preda RO, 2011, UNIV POLIT BUCHAR S, V73, P93
   Priya P., 2014, Int J Res EngTechnol, V4, P630
   Sadek RA, 2012, INT J ADV COMPUT SC, V3, P26
   Sadi KA, 2017, INT J ELECTRON, V104, P673, DOI 10.1080/00207217.2016.1242163
   Saikrishna N, 2016, PROCEDIA COMPUT SCI, V93, P808, DOI 10.1016/j.procs.2016.07.299
   Sathya SP, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P45, DOI 10.1109/ICICCT.2017.7975156
   Sathya SPA, 2018, WIRELESS PERS COMMUN, V102, P2011, DOI 10.1007/s11277-018-5252-1
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Shukla D, 2018, J INTELL SYST, V27, P47, DOI 10.1515/jisys-2017-0039
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sujatha C. N., 2019, Information and Communication Technology for Intelligent Systems. Proceedings of ICTIS 2018. Smart Innovation, Systems and Technologies (SIST 106), P621, DOI 10.1007/978-981-13-1742-2_62
   Swaraja K, 2019, INT C INT COMP COMM, P379
   Tyagi S, 2016, 2016 INTERNATIONAL CONFERENCE ON EMERGING TRENDS IN ELECTRICAL ELECTRONICS & SUSTAINABLE ENERGY SYSTEMS (ICETEESES), P379, DOI 10.1109/ICETEESES.2016.7581413
   Yassin NI, 2014, ALEX ENG J, V53, P833, DOI 10.1016/j.aej.2014.07.008
   Yu XY, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101891
   Zebbiche K, 2006, AHS 2006: FIRST NASA/ESA CONFERENCE ON ADAPTIVE HARDWARE AND SYSTEMS, PROCEEDINGS, P451
   Zhang Diming, 2010, 2010 International Conference on Computer Application and System Modeling (ICCASM 2010), P267, DOI 10.1109/ICCASM.2010.5622796
NR 68
TC 15
Z9 15
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7479
EP 7513
DI 10.1007/s11042-020-09982-4
EA OCT 2020
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000584858400006
DA 2024-07-18
ER

PT J
AU Damiano, R
   Lombardo, V
   Monticone, G
   Pizzo, A
AF Damiano, Rossana
   Lombardo, Vincenzo
   Monticone, Giulia
   Pizzo, Antonio
TI Studying and designing emotions in live interactions with the audience
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive performance; Audience emotions; Audience engagement
AB In the last decade, a number of projects have investigated the use of digital technologies to increase the engagement of the audience in live interactive performance. In this paper, we explore the relation between interactive performance and emotional participation of the audience through an experiment in the wild where perftormance is mediated by a computational system, DoPPioGioco. DoPPioGioco detects the emotional response of the audience, conveyed through face expression, allowing the performer to encourage or oppose it as the performance progresses. Based on the data collected during the experiment, we discuss the limitations and strengths of this approach for audience engagement, in the attempt to identify the factors which must be accounted for when affective technologies are employed to mediate between audience and performer in live interaction.
C1 [Damiano, Rossana; Lombardo, Vincenzo; Monticone, Giulia] Univ Torino, Dipartimento Informat, C So Svizzera 185, I-10149 Turin, Italy.
   [Damiano, Rossana; Lombardo, Vincenzo] Univ Torino, CIRMA, C So Svizzera 185, I-10149 Turin, Italy.
   [Pizzo, Antonio] Univ Torino, Dipartimento Studi Umanistici, Via S Ottavio 20, I-10124 Turin, Italy.
   [Pizzo, Antonio] Univ Torino, CIRMA, Via S Ottavio 20, I-10124 Turin, Italy.
C3 University of Turin; University of Turin; University of Turin;
   University of Turin
RP Damiano, R (corresponding author), Univ Torino, Dipartimento Informat, C So Svizzera 185, I-10149 Turin, Italy.; Damiano, R (corresponding author), Univ Torino, CIRMA, C So Svizzera 185, I-10149 Turin, Italy.
EM rossana.damiano@unito.it; vincenzo.lombardo@unito.it;
   giulia.monticone276@edu.unito.it; antonio.pizzo@unito.it
RI Lombardo, Vincenzo/ABE-2078-2021; Pizzo, Antonio/HHN-6598-2022; Damiano,
   Rossana/C-6288-2011
OI Damiano, Rossana/0000-0001-9866-2843
CR Alrutz M., 2011, PLAYING THEORY THEAT
   [Anonymous], 2013, AAMAS INT C AUTONOMO
   [Anonymous], 2007, P INAUGERAL INT C MU
   [Anonymous], 2003, GAM DEV C
   [Anonymous], 2010, INTRO GENEVA MULTIMO, DOI 10.1037/a0025827
   Arriaga O., 2017, Real-time Convolutional Neural Networks for Emotion and Gender Classification', P221
   Aylett RS, 2005, LECT NOTES ARTIF INT, V3661, P305
   Aylett R, 2013, C&C'13: PROCEEDINGS OF THE 9TH ACM CONFERENCE ON CREATIVITY & COGNITION 2013, P337
   Baumer A, 2009, LECT NOTES COMPUT SC, V5915, P140, DOI 10.1007/978-3-642-10643-9_19
   Benford S., 2018, FUNOLOGY, V2, P209, DOI DOI 10.1007/978-3-319-68213-6_13
   Benford Steve, 2012, P SIGCHI C HUM FACT, P2005, DOI [DOI 10.1145/2207676.2208347, 10.1145/2207676.2208347, 10.1145/2207676.2208347event-place:Austin,Texas,USA, DOI 10.1145/2207676.2208347EVENT-PLACE:AUSTIN,TEXAS,USA]
   Borowski Mateusz., 2010, WORLDS WORDS STORYTE
   Cerratto-Pargman T, 2014, PROCEEDINGS OF THE NORDICHI'14: THE 8TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION: FUN, FAST, FOUNDATIONAL, P608, DOI 10.1145/2639189.2641213
   Corness G., 2011, P 8 ACM C CREATIVITY, P127, DOI DOI 10.1145/2069618.2069641
   Damiano Rossana, 2019, AI*IA 2019 - Advances in Artificial Intelligence. XVIIIth International Conference of the Italian Association for Artificial Intelligence. Proceedings. Lecture Notes in Artificial Intelligence (LNAI 11946), P542, DOI 10.1007/978-3-030-35166-3_38
   Damiano R, 2017, LECT NOTES COMPUT SC, V10690, P206, DOI 10.1007/978-3-319-71027-3_17
   Downman S, 2018, DISRUPT-ST DIGIT JOU, P79
   Fischer-Lichte E, 2017, ROUTLEDGE ADV THEATR
   Foreman-Wernet L, 2013, AUDIENCE EXPERIENCE: A CRITICAL ANALYSIS OF AUDIENCES IN THE PERFORMING ARTS, P67
   FUCHS E, 1985, PERFORM ART J, V9, P163, DOI 10.2307/3245520
   Geelhoed E, 2017, MULTIMED TOOLS APPL, V76, P5573, DOI 10.1007/s11042-016-3879-z
   Giardina M, 2017, ADV INTELLIGENT SYST, P249
   He LJ, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281508
   Latulipe C, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1845
   Li B., 2013, STORY GENERATION CRO
   Lindinger C, 2013, DIGIT CREAT, V24, P119, DOI 10.1080/14626268.2013.808966
   Lombardo V, 2015, 2015 9TH INTERNATIONAL CONFERENCE ON INNOVATIVE MOBILE AND INTERNET SERVICES IN UBIQUITOUS COMPUTING IMIS 2015, P117, DOI 10.1109/IMIS.2015.22
   Lombardo V, 2015, SEMANT WEB, V6, P503, DOI 10.3233/SW-140156
   Louchart Sandy., 2015, Interactive Digital Narrative: History, Theory and Practice, P185
   Lumens J, 2019, J AM HEART ASSOC, V8, DOI 10.1161/JAHA.118.010903
   Marranca B, 2010, PAJ, P16
   Philpott JM, 2017, SURGICAL TREATMENT OF ATRIAL FIBRILLATION: A COMPREHENSIVE GUIDE TO PERFORMING THE COX MAZE IV PROCEDURE, P285
   Pitts SE, 2020, ROUTLEDGE RES CREATI
   Pizzo A, 2019, TDR-DRAMA REV-J PERF, V63, P14, DOI 10.1162/dram_a_00872
   Plutchik R., 1980, EMOTION PSYCHOEVOLUT
   Rao NJ, 2019, LECT NOTES COMPUT SC, V11869, P395, DOI 10.1007/978-3-030-33894-7_42
   Riedl MO, 2010, J ARTIF INTELL RES, V39, P217, DOI 10.1613/jair.2989
   Roseman IJ, 2013, EMOT REV, V5, P141, DOI 10.1177/1754073912469591
   Row J, 2019, J NEUROTRAUM, V36, P2435, DOI 10.1089/neu.2018.5755
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   Scherer K. R., 1999, HDB COGNITION EMOTIO, P637, DOI [10.1002/0470013494.ch30, DOI 10.1002/0470013494.CH30]
   Sgouros NM, 2003, MULTIMEDIA SYST, V8, P470, DOI 10.1007/s00530-002-0072-1
   Silvia PJ, 2009, PSYCHOL AESTHET CREA, V3, P48, DOI 10.1037/a0014632
   Swartjes I, 2009, L N INST COMP SCI SO, V9, P234
   Tanenbaum J, 2013, P DIGRA
   Tschacher W, 2012, PSYCHOL AESTHET CREA, V6, P96, DOI 10.1037/a0023845
   Vicentini C, 2012, THEORY ACTING ANTIQU
   Wang C, 2014, INT CONF UNMAN AIRCR, P902, DOI 10.1109/ICUAS.2014.6842339
   Weallans Allan, 2012, Interactive Storytelling. Proceedings of the 5th International Conference, ICIDS 2012, P132, DOI 10.1007/978-3-642-34851-8_13
   Yan S, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P306, DOI 10.1145/2856767.2856768
NR 50
TC 3
Z9 4
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 6711
EP 6736
DI 10.1007/s11042-020-10007-3
EA OCT 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000580398000002
DA 2024-07-18
ER

PT J
AU Tehrani, AA
   Nickfarjam, AM
   Ebrahimpour-komleh, H
   Aghadoost, D
AF Tehrani, Amirali Amini
   Nickfarjam, Ali Mohammad
   Ebrahimpour-komleh, Hossein
   Aghadoost, Dawood
TI Multi-input 2-dimensional deep belief network: diabetic retinopathy
   grading as case study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic retinopathy; Mixed-restricted Boltzmann machine; Retinal image;
   Deep networks; Multi-input 2-dimensional deep belief network
AB The most important action in treating diabetic retinopathy is early diagnosis and its progression degree. This paper presents a two-dimensional Deep Belief Network based on Mixed-restricted Boltzmann Machine capable of receiving multiple two-dimensional inputs. Using multiple inputs provides more appropriate prior information for learning. In this proposed method, the image is transferred to the HSV color space and then the 3D color image is converted to a 2D matrix using a weighted mean. This weighted mean is calculated based on the entropy criterion. The resulting two-dimensional matrix is not in pixel and is merely a raw description of the image. The local, regional and global descriptions are extracted from this matrix and provided for the network. The proposed deep network automatically extracts the appropriate features to determine the progression degree of diabetic retinopathy by the network. Window by window image processing can overcome one of the basic problems of image classification, i.e. the small number of labeled data. Experiments showed that the proposed method is superior when compared to other methods.
C1 [Tehrani, Amirali Amini; Nickfarjam, Ali Mohammad; Ebrahimpour-komleh, Hossein] Univ Kashan, Dept Comp Engn, Fac Elect & Comp Engn, Kashan, Iran.
   [Aghadoost, Dawood] Kashan Univ Med Sci, Sch Med, Kashan, Iran.
C3 University Kashan
RP Ebrahimpour-komleh, H (corresponding author), Univ Kashan, Dept Comp Engn, Fac Elect & Comp Engn, Kashan, Iran.
EM amir.tehrani@grad.kashanu.ac.ir; amnickfarjam@grad.kashanu.ac.ir;
   ebrahimpour@kashanu.ac.ir; aghadoost_d@kaums.ac.ir
RI Ebrahimpour-komleh, Hossein/ABG-2658-2020; Aghadoost, Dawood/W-2400-2017
OI Ebrahimpour-komleh, Hossein/0000-0002-9935-7821; 
CR Abramoff M, 2008, DIABETES CARE
   Abramoff M, 2010, OPHTHALMOL
   Agurto C, 2011, INVESTIG OPHTHALMOL
   Agurto C, 2011, INVESTIGATIVE OPHTHA
   [Anonymous], 2019, NEUROCOMPUTING
   [Anonymous], 2011, ESANN
   [Anonymous], 2006, NEURAL COMPUT
   [Anonymous], 2018, ARXIV181210595
   Antal B, 2014, KNOWLEDGE BASED SYST
   Asiri N, 2019, ARTIFICIAL INTELLIGE
   Bautista Pinky A, 2010, J Pathol Inform, V1, P25, DOI 10.4103/2153-3539.73320
   Bengio Y, 2013, INT C STAT LNAG SPEE
   Chebbout S, 2012, INT IEEE C SIGN IM T
   Erickson BJ, 2017, RADIOGRAPHICS
   Gelman R, 2019, ARXIV190204151
   Grewal PS, 2018, CAN J OPHTHALMOL
   Gudla S, 2018, DRUG DELIVERY RETINA
   He X., 2004, IEEE COMP SOC C COMP
   Ishida T, 2015, INT IEEE C DIG IM CO
   Liu WF, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/2658707
   Mori T., 2002, P COL 2002 19 INT C
   NCSS Statistical Software Chapter, 2004, ON ROC CURV CUT AN
   Nickfarjam A. M., 2019, MULTIMEDIA TOOLS APP
   Nickfarjam AM, 2015, INT IEEE C TECHN COM
   Suzuki K., 2017, RADIOL PHYS TECHNOL
   Wang WL, 2018, INT J MOL SCI, V19, DOI [10.3390/ijms19030721, 10.3390/ijms19010135]
   Wang Z, 2017, INT C MED IM COMP AS
   Yu D., 2011, IEEE SIGNAL PROCESSI
   Zhao Z, 2019, ARXIV190506312
   Zhou K, 2018, INT C IEEE ENG MED B
NR 30
TC 6
Z9 7
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6171
EP 6186
DI 10.1007/s11042-020-10025-1
EA OCT 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577066700001
DA 2024-07-18
ER

PT J
AU Yu, XC
   Chen, HC
   Liang, MM
   Xu, Q
   He, LF
AF Yu, Xiangchun
   Chen, Hechang
   Liang, Miaomiao
   Xu, Qing
   He, Lifang
TI A transfer learning-based novel fusion convolutional neural network for
   breast cancer histology classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer histology classification; Convolutional neural network;
   Transfer learning; Pre-trained CNN model; VGG19
AB To train a convolutional neural network (CNN) from scratch is not suitable for medical image tasks with insufficient data. Benefiting from the transfer learning, the pre-trained CNN model can provide a reliable initial solution for model optimization of medical image classification. A key concern in breast cancer histology classification is that the model should cover the multi-scale features including nuclei-scale, nuclei organization, and structure-scale features. Inspired by these conjectures, we proposed a novel fusion convolutional neural network (FCNN) based on pre-trained VGG19. The FCNN fuses the shallow, intermediate abstract, and abstract layers to approximately cover the multi-scale features. In order to improve the sensitivity of carcinoma classes, the prediction priority is introduced to enable the lesions can be detected as early as possible. Experimental results show that the proposed FCNN can approximately cover the nuclei-scale, nuclei organization, and structure-scale features. Accuracies of 85%, 75%, and 80.56% are achieved in Initial, Extended, and Overall test set, respectively. The source code for this research is available at https://github.com/yxchspring/breasthistolgoy.
C1 [Yu, Xiangchun; Liang, Miaomiao; Xu, Qing] Jiangxi Univ Sci & Technol, Sch Informat Engn, Ganzhou 341000, Peoples R China.
   [Chen, Hechang] Jilin Univ, Sch Artificial Intelligence, Changchun 130012, Peoples R China.
   [He, Lifang] Lehigh Univ, Dept Comp Sci & Engn, Bethlehem, PA 18015 USA.
C3 Jiangxi University of Science & Technology; Jilin University; Lehigh
   University
RP Liang, MM; Xu, Q (corresponding author), Jiangxi Univ Sci & Technol, Sch Informat Engn, Ganzhou 341000, Peoples R China.
EM liangmiaom@jxust.edu.cn; xuqing@jxust.edu.cn
RI Liang, Miaomiao/AAN-5085-2021; He, Lifang/D-8175-2016; Yu,
   Xiangchun/AAX-3376-2020; Chen, Hechang/Y-7950-2018; xu,
   qing/JOZ-6057-2023
OI He, Lifang/0000-0001-7810-9071; Yu, Xiangchun/0000-0001-6206-450X; Chen,
   Hechang/0000-0001-7835-9556; 
FU Doctoral Scientific Research Foundation of Jiangxi University of Science
   and Technology [jxxjbs19029, jxxjbs19006, jxxjbs19012]; National Natural
   Science Foundation of China [61901198, 61902145]
FX This research was funded by 1) Doctoral Scientific Research Foundation
   of Jiangxi University of Science and Technology, grant number
   jxxjbs19029, jxxjbs19006, jxxjbs19012. 2) National Natural Science
   Foundation of China, grant number 61901198, 61902145.
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   Albarqouni S, 2016, IEEE T MED IMAGING, V35, P1313, DOI 10.1109/TMI.2016.2528120
   Araújo T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177544
   Beam AL, 2018, JAMA-J AM MED ASSOC, V319, P1317, DOI 10.1001/jama.2017.18391
   Berg E, 2015, CAN MED ASSOC J, V75
   Bioimaging Challenge, 2015, BREAST HISTOLOGY DAT
   Che D, 2019, J JIANGXI U SCI TECH, V40, P80
   Ciresan DC, 2013, LECT NOTES COMPUT SC, V8150, P411, DOI 10.1007/978-3-642-40763-5_51
   DeSantis CE, 2017, CA-CANCER J CLIN, V67, P439, DOI 10.3322/caac.21412
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   Golatkar A, 2018, LECT NOTES COMPUT SC, V10882, P837, DOI 10.1007/978-3-319-93000-8_95
   Gudmundsson E, 2019, PROC SPIE, V10950, DOI 10.1117/12.2512974
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang JB, 2010, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2010.5539919
   Jaworek-Korjakowska J, 2019, IEEE COMPUT SOC CONF, P2748, DOI 10.1109/CVPRW.2019.00333
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li B, 2019, PATTERN RECOGN IMAGE, V29, P258, DOI 10.1134/S1054661819020044
   McGuire S, 2014, ADV NUTR, V2016, P418
   Nawaz W, 2018, LECT NOTES COMPUT SC, V10882, P869, DOI 10.1007/978-3-319-93000-8_99
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Rajaraman S, 2018, PEERJ, V6, DOI 10.7717/peerj.4568
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Shima Y, 2018, C IND ELECT APPL, P2360, DOI 10.1109/ICIEA.2018.8398104
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sohretoglu D, 2019, SIGNAL TRANSDUCT TAR, V4, DOI 10.1038/s41392-019-0056-7
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Upadhyay PK, 2019, INT J PERFORMABILITY, V15, P1083
   Wen L, 2019, INT C COMP SUPP COOP, P205, DOI [10.1109/cscwd.2019.8791884, 10.1109/CSCWD.2019.8791884]
   Yang G, 2018, J JIANGXI U SCI TECH, V39, P76
   Yang J, 2019, EXPERT SYST APPL, V116, P255, DOI 10.1016/j.eswa.2018.08.038
   Yang X, 2016, IASTED BIOMEDICAL EN
   Yu X, 2018, INTERN J CLIMATOL, V2018, P1, DOI DOI 10.1155/2018/9751783
   Yu XC, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-67476-7
   Yu XC, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/9428612
   Yu XC, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.2.023006
   Zhang Y, 2020, IEEE T IMAGE PROCESS, V29, P509, DOI 10.1109/TIP.2019.2929433
NR 39
TC 4
Z9 4
U1 3
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 11949
EP 11963
DI 10.1007/s11042-020-09977-1
EA OCT 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000576709300001
DA 2024-07-18
ER

PT J
AU Sulaiman, A
   Omar, K
   Nasrudin, MF
AF Sulaiman, Alaa
   Omar, Khairuddin
   Nasrudin, Mohammad F.
TI Two streams deep neural network for handwriting word recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Handwritten word recognition; Deep model; Convolutional layer; ConvLSTM
ID PATTERN-RECOGNITION; IMAGE; IDENTIFICATION; NORMALIZATION; SEQUENCE
AB Handwritten word recognition is one of the hot topics in automatic handwritten text recognition that received a lot of attention in recent years. Unlike character recognition, word recognition deals with considerable variations in word shape and written style. This paper proposes a novel deep model for language-independent handwritten word recognition. The proposed deep structure has two parallel stages for jointly learning character and word-level information. In the character-level stage, a weakly character segmentation method is performed and then applies a series ofLong short-term memory(LSTM) layers for character-level representation. The word-level stage employs a series of convolutional layers for the shape and structure representation of the word. These representations are then concatenated and followed by a series of fully connected layers for jointly learning the words and the character-level information. Since the character segmentation is language independent and error-prone, the proposed deep structure only applies weakly separation scheme and does not rely on any character segmentation algorithm. Thus, it effectively utilizes character level representation without bounding on any language model. In the proposed methodology, we use two new data augmentation strategies based on a psychological assumption to increase the model generalization performance. Experimental results on five public datasets including Arabic, English and German languages demonstrate that the proposed deep model has a superior performance to the state-of-the-art methods.
C1 [Sulaiman, Alaa; Omar, Khairuddin; Nasrudin, Mohammad F.] Univ Kebangsaan Malaysia, Pattern Recognit Res Grp, Ctr Artificial Intelligence Technol, Fac Informat Sci & Technol, Bangi 43600, Selangor, Malaysia.
C3 Universiti Kebangsaan Malaysia
RP Sulaiman, A (corresponding author), Univ Kebangsaan Malaysia, Pattern Recognit Res Grp, Ctr Artificial Intelligence Technol, Fac Informat Sci & Technol, Bangi 43600, Selangor, Malaysia.
EM alaasol@gmail.com
RI Sulaiman, Alaa/IQU-4162-2023; Omar, Khairuddin/C-3534-2017
OI Sulaiman, Alaa/0000-0003-0149-3479; Omar, Khairuddin/0000-0003-1794-019X
FU Ministry of Higher Education in Malaysia [FRGS/1/2016/ICT02/UKM/01/1]
FX This research was funded by the Ministry of Higher Education in Malaysia
   by the grant number FRGS/1/2016/ICT02/UKM/01/1.
CR Ajmire P, 2012, STRUCTURAL FEATURES
   AlKhateeb J, 2008, 5 IEEE INT MULT SYST, P1, DOI 10.1109/SSD.2008.4632863
   AlKhateeb JH, 2011, PATTERN RECOGN LETT, V32, P1081, DOI 10.1016/j.patrec.2011.02.006
   Almazán J, 2014, IEEE T PATTERN ANAL, V36, P2552, DOI 10.1109/TPAMI.2014.2339814
   Amrouch M, 2018, LECT NOTES COMPUT SC, V10884, P265, DOI 10.1007/978-3-319-94211-7_29
   Azad R, 2014, ARXIV14076492
   Babu Nija, 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0299, DOI 10.1109/ICCSP.2019.8697988
   Bernardo LS, 2019, PATTERN RECOGN LETT, V125, P78, DOI 10.1016/j.patrec.2019.04.003
   Bhunia AK, 2019, PATTERN RECOGN, V85, P172, DOI 10.1016/j.patcog.2018.07.034
   Bluche T, 2014, SLSP
   Bluche T, 2017, PROC INT CONF DOC, P646, DOI 10.1109/ICDAR.2017.111
   Bluche T, 2013, INT CONF ACOUST SPEE, P2390, DOI 10.1109/ICASSP.2013.6638083
   Castro D, 2018, INT CONF FRONT HAND, P127, DOI 10.1109/ICFHR-2018.2018.00031
   Chen Z, 2017, PROC INT CONF DOC, P525, DOI 10.1109/ICDAR.2017.92
   Chowdhury A., 2018, P BRIT MACH VIS C 20, P1
   Dutta K, 2018, INT CONF FRONT HAND, P80, DOI 10.1109/ICFHR-2018.2018.00023
   Elleuch M, 2016, ICCS
   Eraqi HM, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P993, DOI [10.1109/ICMLA.2016.63, 10.1109/ICMLA.2016.0179]
   España-Boquera S, 2011, IEEE T PATTERN ANAL, V33, P767, DOI 10.1109/TPAMI.2010.141
   Feng S, 2019, NEUROCOMPUTING, V325, P288, DOI 10.1016/j.neucom.2018.09.087
   Graves A., 2013, GENERATING SEQUENCES
   Grdiet P, 2013, BINARIZATION TECHNIQ
   Hallale SB, 2013, 12 DIRECTIONAL FEATU
   He S, 2019, PATTERN RECOGN, V88, P64, DOI 10.1016/j.patcog.2018.11.003
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hussein ME, 2014, ARXIV14114670
   Ingle RR, ARXIV190409150
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   Jayech K, 2016, INT ARAB J INF TECHN, V13, P1024
   Kacalak W, 2007, ANAL DESIGN INTELLIG
   Kadhm MS, 2015, HANDWRITING WORD REC
   Kessentini Y, 2010, PATTERN RECOGN LETT, V31, P60, DOI 10.1016/j.patrec.2009.08.009
   Kleber F, 2013, PROC INT CONF DOC, P560, DOI 10.1109/ICDAR.2013.117
   Kozielski M, 2012, INT CONF FRONT HAND, P256, DOI 10.1109/ICFHR.2012.236
   Lawgali, 2015, SURVEY ARABIC CHARAC
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Maalej R, 2018, INT ARAB CONF INF TE, P267
   Mamathah HR, 2012, PERFORMANCE ANAL VAR
   Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071
   Mhiri M, 2019, PATTERN RECOGN, V88, P312, DOI 10.1016/j.patcog.2018.11.017
   Mhiri M, 2018, PATTERN RECOGN LETT, V111, P87, DOI 10.1016/j.patrec.2018.04.025
   Oliveira LS, 2002, IEEE T PATTERN ANAL, V24, P1438, DOI 10.1109/TPAMI.2002.1046154
   Panwar S, 2012, 2012 4 INT C INT HUM, P1
   Pechwitz M., 2002, P CIFED, P127
   Ptucha R, 2019, PATTERN RECOGN, V88, P604, DOI 10.1016/j.patcog.2018.12.017
   Rajora S, 2018, 2018 IEEE 9TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P209, DOI 10.1109/IEMCON.2018.8615011
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sharan A, 1993, THESIS
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Shi X., 2015, ADV NEURAL INFORM PR, DOI DOI 10.48550/ARXIV.1506.04214
   Sonkusare M., 2016, Adv vis Comput Int J, V3, P1, DOI DOI 10.5121/AVC.2016.3101
   Sudarsan D, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1818, DOI 10.1109/ICACCI.2018.8554592
   Sueiras J, 2018, NEUROCOMPUTING, V289, P119, DOI 10.1016/j.neucom.2018.02.008
   Sulaiman A, 2019, IEEE ACCESS, V7, P91772, DOI 10.1109/ACCESS.2019.2927286
   Sulaiman WNA, 2019, NASRUDIN DEGRADED HI
   Tavoli R, 2018, IET IMAGE PROCESS, V12, P1606, DOI 10.1049/iet-ipr.2017.0839
   Wang WL, 2015, PROCEDIA COMPUT SCI, V61, P402, DOI 10.1016/j.procs.2015.09.171
   Xue HH, 2006, IEEE T PATTERN ANAL, V28, P458, DOI 10.1109/TPAMI.2006.55
   YAN H, 1993, CVGIP-GRAPH MODEL IM, V55, P538, DOI 10.1006/cgip.1993.1041
NR 61
TC 8
Z9 8
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5473
EP 5494
DI 10.1007/s11042-020-09923-1
EA OCT 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577469600001
DA 2024-07-18
ER

PT J
AU Abbass, MY
   Kwon, KC
   Alam, MS
   Piao, YL
   Lee, KY
   Kim, N
AF Abbass, Mohammed Y.
   Kwon, Ki-Chul
   Alam, Md Shahinur
   Piao, Yan-Ling
   Lee, Kwon-Yeon
   Kim, Nam
TI Image super resolution based on residual dense CNN and guided filters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image resolution; Bicubic interpolation; Guided filter; Sparse coding;
   Multi-scale deep super-resolution
ID SUPERRESOLUTION
AB Convolutional neural networks (CNNs) have recently made impressive results for image super-resolution (SR). Our goal is to introduce a new image SR framework rely on a CNN. In this paper, the input image is decomposed into luminance channel and chromatic channels. A designed network based on a residual dense network is introduced to extract the hierarchical features from luminance part. The bicubic interpolation is simply used to upscale low resolution (LR) chromatic channels. However, this step degrades the chromatic channels. To tackle this issue, the SR reconstructed luminance channel is applied as the reference image in guided filters to promote the interpolated chromatic channels. Guided filters technique has ability to retain sharp edges and fine details from the reference image and carry them to the target images. Extensive experiments on several commonly used image SR testing datasets demonstrate that our framework has the ability to extract features and outperforms existing well-known techniques for image SR by LR image into the high resolution (HR) image efficiently.
C1 [Abbass, Mohammed Y.; Kwon, Ki-Chul; Alam, Md Shahinur; Piao, Yan-Ling; Kim, Nam] Chungbuk Natl Univ, Sch Informat & Commun Engn, Cheongju 28644, South Korea.
   [Abbass, Mohammed Y.] Atom Energy Author, Engn Dept, Nucl Res Ctr, Cairo, Egypt.
   [Lee, Kwon-Yeon] Sunchon Natl Univ, Dept Elect Engn, 255 Jungang Ro, Jeonnam 57922, South Korea.
C3 Chungbuk National University; Egyptian Knowledge Bank (EKB); Egyptian
   Atomic Energy Authority (EAEA); Sunchon National University
RP Kim, N (corresponding author), Chungbuk Natl Univ, Sch Informat & Commun Engn, Cheongju 28644, South Korea.
EM myehiaa@yahoo.com; kwon@osp.chungbuk.ac.kr; shahinur@chungbuk.ac.kr;
   yanling@osp.chungbuk.ac.kr; kwonyeon@sunchon.ac.kr;
   namkim@chungbuk.ac.kr
RI Alam, Md Shahinur/ABH-9140-2020
OI Alam, Md Shahinur/0000-0001-8413-5428
FU Korea Government, under the ITRC (Information Technology Research
   Center) support program [IITP-2020-2015-0-00448]; Grand Information
   Technology Research Center support program [IITP-2020-0-01462]
FX This research was supported by the Korea Government, under the ITRC
   (Information Technology Research Center) support program
   (IITP-2020-2015-0-00448) and Grand Information Technology Research
   Center support program (IITP-2020-0-01462), supervised by the IITP
   (Institute for Information & communications Technology Promotion).
CR Abbass MY, 2019, SIGNAL IMAGE VIDEO P, V13, P703, DOI 10.1007/s11760-018-1399-1
   Abbass MY, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0276-8
   Abualigah L, 2021, CLUSTER COMPUT, V24, P205, DOI 10.1007/s10586-020-03075-5
   Abualigah L, 2020, NEURAL COMPUT APPL, V32, P12381, DOI 10.1007/s00521-020-04839-1
   Abualigah LM, 2018, APPL INTELL, V48, P4047, DOI 10.1007/s10489-018-1190-6
   Abualigah LM, 2018, ENG APPL ARTIF INTEL, V73, P111, DOI 10.1016/j.engappai.2018.05.003
   Abualigah LM, 2018, J COMPUT SCI-NETH, V25, P456, DOI 10.1016/j.jocs.2017.07.018
   Alam MS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020376
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chen YX, 2019, J VIS COMMUN IMAGE R, V60, P229, DOI 10.1016/j.jvcir.2019.02.022
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fairley JL, 2019, INTERN MED J, V49, P5
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Greeshma MS, 2020, MULTIMED TOOLS APPL, V79, P35125, DOI 10.1007/s11042-020-09352-0
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Huang T.S., 1984, ADV COMPUTER VISION, V1, P317
   Huang YF, 2018, IEEE T IMAGE PROCESS, V27, P5904, DOI 10.1109/TIP.2018.2860685
   Hui TW, 2016, LECT NOTES COMPUT SC, V9907, P353, DOI 10.1007/978-3-319-46487-9_22
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li YJ, 2016, LECT NOTES COMPUT SC, V9908, P154, DOI 10.1007/978-3-319-46493-0_10
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Martin D., 2001, P IEEE C COMP VIS JU, V2, P416
   Nasrollahi H, 2020, SIGNAL IMAGE VIDEO P, V14, P407, DOI 10.1007/s11760-019-01569-3
   Ren HY, 2017, IEEE COMPUT SOC CONF, P1050, DOI 10.1109/CVPRW.2017.142
   Shi WZ, 2013, LECT NOTES COMPUT SC, V8151, P9, DOI 10.1007/978-3-642-40760-4_2
   Singh A., 2014, ACCV
   Singh A, 2020, MULTIMED TOOLS APPL, V79, P1641, DOI 10.1007/s11042-019-08254-0
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Veit A, 2016, ADV NEUR IN, V29
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Yang J, 2008, 2008 IEEE C COMP VIS, P1, DOI 10.1109/CVPR.2008.4587647
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang QL, 2019, J VIS COMMUN IMAGE R, V58, P277, DOI 10.1016/j.jvcir.2018.11.040
   Zhao F, 2019, MULTIMED TOOLS APPL, V78, P28453, DOI 10.1007/s11042-017-5493-0
NR 45
TC 10
Z9 11
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5403
EP 5421
DI 10.1007/s11042-020-09824-3
EA OCT 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000575795600002
DA 2024-07-18
ER

PT J
AU Agrawal, P
   Chaudhary, D
   Madaan, V
   Zabrovskiy, A
   Prodan, R
   Kimovski, D
   Timmerer, C
AF Agrawal, Prateek
   Chaudhary, Deepak
   Madaan, Vishu
   Zabrovskiy, Anatoliy
   Prodan, Radu
   Kimovski, Dragi
   Timmerer, Christian
TI Automated bank cheque verification using image processing and deep
   learning methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cheque truncation system; Image segmentation; Bank cheque clearance;
   Image feature extraction; Convolution neural network; Support vector
   machine; Scale invariant feature transform
ID RECOGNITION; SEGMENTATION
AB Automated bank cheque verification using image processing is an attempt to complement the present cheque truncation system, as well as to provide an alternate methodology for the processing of bank cheques with minimal human intervention. When it comes to the clearance of the bank cheques and monetary transactions, this should not only be reliable and robust but also save time which is one of the major factor for the countries having large population. In order to perform the task of cheque verification, we developed a tool which acquires the cheque leaflet key components, essential for the task of cheque clearance using image processing and deep learning methods. These components include the bank branch code, cheque number, legal as well as courtesy amount, account number, and signature patterns. our innovation aims at benefiting the banking system by re-innovating the other competent cheque-based monetary transaction system which requires automated system intervention. For this research, we used institute of development and research in banking technology (IDRBT) cheque dataset and deep learning based convolutional neural networks (CNN) which gave us an accuracy of 99.14% for handwritten numeric character recognition. It resulted in improved accuracy and precise assessment of the handwritten components of bank cheque. For machine printed script, we used MATLAB in-built OCR method and the accuracy achieved is satisfactory (97.7%) also for verification of Signature we have used Scale Invariant Feature Transform (SIFT) for extraction of features and Support Vector Machine (SVM) as classifier, the accuracy achieved for signature verification is 98.10%.
C1 [Agrawal, Prateek; Zabrovskiy, Anatoliy; Prodan, Radu; Kimovski, Dragi; Timmerer, Christian] Univ Klagenfurt, Klagenfurt, Austria.
   [Agrawal, Prateek; Chaudhary, Deepak; Madaan, Vishu] Lovely Profess Univ, Phagwara, India.
   [Zabrovskiy, Anatoliy] Petrozavodsk State Univ, Petrozavodsk, Russia.
   [Timmerer, Christian] Bitmovin Inc, San Francisco, CA USA.
C3 University of Klagenfurt; Lovely Professional University; Petrozavodsk
   State University
RP Madaan, V (corresponding author), Lovely Profess Univ, Phagwara, India.
EM prateek061186@gmail.com; deepak3.14159@gmail.com;
   vishumadaan123@gmail.com; anatoliy.zabrovskiy@aau.at;
   radu.prodan@aau.at; dragi.kimovski@aau.at; christian.timmerer@aau.at
RI Agrawal, Prateek/AAE-1912-2021; Prodan, Radu/S-4253-2017; Kimovski,
   Dragi/A-2332-2015
OI Agrawal, Prateek/0000-0001-6861-0698; Kimovski,
   Dragi/0000-0001-5933-3246; Madaan, Vishu/0000-0002-9127-4490
FU European Union Horizon 2020 Research and Innovation Programme under the
   ARTICONF Project [644179]
FX This work has been partly supported by the European Union Horizon 2020
   Research and Innovation Programme under the ARTICONF Project with grant
   agreement number 644179.
CR Agrawal P., 2012, 2012 International Conference on Computing Sciences (ICCS), P127, DOI 10.1109/ICCS.2012.14
   Ahlawat S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123344
   [Anonymous], 2018, CHEQUE MARKET 2018
   [Anonymous], 2017, CHEQUE MARKET 2018
   [Anonymous], 2019, MALAYSIA BANK TEMPLA
   [Anonymous], 2017, FARSI DATATSET
   [Anonymous], 2016, INDIAN J SCI TECHNOL
   [Anonymous], 2014, INT C INF COMM EMB S
   [Anonymous], 2019, CHRYSANTH CHEQUE WRI
   [Anonymous], 2015, 8 INT C ADV PATT REC
   [Anonymous], 2010, CTS 2010 CHEQUE LEAF
   [Anonymous], 2018, CTS2010
   Aronoff JS, 2011, DIGITAL FABRICATION 2011/ NIP27- 27TH INTERNATIONAL CONFERENCE ON DIGITAL PRINTING TECHNOLOGIES: TECHNICAL PROGRAMS AND PROCEEDINGS, 2011, P690
   Beresneva A, 2018, PROCEEDINGS OF THE 2018 IEEE CONFERENCE OF RUSSIAN YOUNG RESEARCHERS IN ELECTRICAL AND ELECTRONIC ENGINEERING (EICONRUS), P1477, DOI 10.1109/EIConRus.2018.8317376
   Bhadwal Neha, 2019, 2019 International Conference on Automation, Computational and Technology Management (ICACTM). Proceedings, P183, DOI 10.1109/ICACTM.2019.8776749
   Boudamous F., 2017, IEEE C RUSS YOUNG RE, P1
   Brisinello M, 2018, IEEE 8 INT C CONS EL, P1, DOI [10.1109/ICCE-Berlin.2018.8576202, DOI 10.1109/ICCE-BERLIN.2018.8576202]
   Brisinello M, 2017, ELMAR PROC, P167, DOI 10.23919/ELMAR.2017.8124460
   Camastra F, 2006, INT C PATT REC ICPR, P1
   Chaudhary D, 2019, COMM COM INF SC, V1075, P148, DOI 10.1007/978-981-15-0108-1_15
   Chauhan S, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON COMPUTING SCIENCES (ICCS), P137, DOI 10.1109/ICCS.2018.00031
   Chen C, 2017, PROC INT CONF DOC, P547, DOI 10.1109/ICDAR.2017.95
   Cohen G, 2017, IEEE IJCNN, P2921, DOI 10.1109/IJCNN.2017.7966217
   Dansena P, 2017, LECT NOTES COMPUT SC, V10597, P655, DOI 10.1007/978-3-319-69900-4_83
   Dhande Pritam, 2017, 2017 International Conference on Trends in Electronics and Informatics (ICEI). Proceedings, P199, DOI 10.1109/ICOEI.2017.8300915
   Dhande P. S., 2017, INT C COMP COMM CONT, P1, DOI 10.1109/ICCUBEA.2017.8463842
   Dhanya K, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P1256, DOI 10.1109/ICICCT.2018.8473098
   DICKINSON WE, 1960, IBM J RES DEV, V4, P335, DOI 10.1147/rd.43.0335
   Feng Wanli, 2010, 2010 3rd International Conference on Advanced Computer Theory and Engineering (ICACTE 2010), P53, DOI 10.1109/ICACTE.2010.5579639
   Ferrer MA, 2018, IEEE T CYBERNETICS, V48, P2896, DOI 10.1109/TCYB.2017.2751740
   Gluhovic M, 2017, CONT PERFORM INTERAC, P1, DOI 10.1057/978-1-137-49608-9_1
   Gonge SS, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P769, DOI 10.1109/IC3I.2016.7918064
   Gonge SS, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON ISSUES AND CHALLENGES IN INTELLIGENT COMPUTING TECHNIQUES (ICICT), P776, DOI 10.1109/ICICICT.2014.6781379
   Goto H, 2002, INT C PATT RECOG, P180, DOI 10.1109/ICPR.2002.1047824
   Hafemann LG, 2020, IEEE T INF FOREN SEC, V15, P1735, DOI 10.1109/TIFS.2019.2949425
   Hafemann LG, 2019, IEEE T INF FOREN SEC, V14, P2153, DOI 10.1109/TIFS.2019.2894031
   Handhayani T, 2017, PROCEEDINGS OF THE 2017 INTELLIGENT SYSTEMS CONFERENCE (INTELLISYS), P1103, DOI 10.1109/IntelliSys.2017.8324267
   Hou JH, 2017, I S INTELL SIG PROC, P155, DOI 10.1109/ISPACS.2017.8266464
   Ignat A, 2016, INT SYMP SYMB NUMERI, P303, DOI 10.1109/SYNASC.2016.48
   Jain UA, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON ISSUES AND CHALLENGES IN INTELLIGENT COMPUTING TECHNIQUES (ICICT), P760, DOI 10.1109/ICICICT.2014.6781376
   Jayadevan R., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P166, DOI 10.1109/ICFHR.2010.33
   Ji XQ, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P433, DOI 10.1109/CISP.2015.7407919
   Jia H, 2010, INT C WEB INT INT AG, P253
   Joshi OS, 2017, INT C COMP COMM CONT, P1
   Kajale R, 2017, 2017 INT C ADV COMP, P1
   Kanan C, 2012, PLOS ONE, V7, P133, DOI 10.1371/journal.pone.0029740
   Karanjkar SL, 2016, 2016 IEEE INTERNATIONAL WIE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (IEEE WIECON-ECE 2016), P44, DOI 10.1109/WIECON-ECE.2016.8009084
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Li YB, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P311, DOI 10.1109/ICIVC.2018.8492818
   LIU CN, 1966, IEEE TRANS ELECTRON, VEC15, P916, DOI 10.1109/PGEC.1966.264474
   Lu HJ, 2018, CANCER BIOMARK, V21, P711, DOI 10.3233/CBM-170809
   Madaan V, 2020, IEEE ACCESS, V8, P65060, DOI 10.1109/ACCESS.2020.2985717
   Miah Mohammad Badrul Alam, 2015, INT J COMPUT APPL, V118, P21
   Mityakov AV, 2017, PROCEEDINGS OF 2017 XX IEEE INTERNATIONAL CONFERENCE ON SOFT COMPUTING AND MEASUREMENTS (SCM), P389, DOI 10.1109/SCM.2017.7970594
   Mondal P, 2017, 2017 THIRD INTERNATIONAL CONFERENCE ON SCIENCE TECHNOLOGY ENGINEERING & MANAGEMENT (ICONSTEM), P409, DOI 10.1109/ICONSTEM.2017.8261355
   Morocho D, 2017, PROC INT CONF DOC, P5, DOI 10.1109/ICDAR.2017.373
   NAGY G, 1966, IEEE T INFORM THEORY, V12, P215, DOI 10.1109/TIT.1966.1053864
   Nainani A, 2009, INT EL DEVICES MEET, P801
   Nasser AT, 2017, I C ENG TECHNOL
   Pal U, 2006, INT C PATT RECOG, P873
   Pérez-Basante A, 2019, IEEE T POWER ELECTR, V34, P943, DOI 10.1109/TPEL.2018.2819724
   Peymani K, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND IMAGE ANALYSIS (IPRIA), P243, DOI 10.1109/PRIA.2017.7983055
   Pornpanomchai C, 2015, 2015 INTERNATIONAL COMPUTER SCIENCE AND ENGINEERING CONFERENCE (ICSEC), P1
   Ramanathan TT, 2017, PROCEDIA COMPUT SCI, V115, P307, DOI 10.1016/j.procs.2017.09.139
   Saenthon A, 2014, SIGN INF PROC ASS AN, P1
   Sahbi H, 2013, IEEE T IMAGE PROCESS, V22, P1018, DOI 10.1109/TIP.2012.2226046
   Shen L, 2012, SIGN INF PROC ASS AN, P1
   Shenoy SS, 2016, INT SYMP PARA DISTR, P80, DOI 10.1109/ISPDC.2016.19
   Shirai K., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P190, DOI 10.1109/DAS.2012.75
   Shirazi AA, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND IMAGE ANALYSIS (IPRIA), P258, DOI 10.1109/PRIA.2017.7983058
   Shitole S, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INVENTIVE SYSTEMS AND CONTROL (ICISC 2018), P100, DOI 10.1109/ICISC.2018.8398991
   Singh HL, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P628, DOI 10.1145/2254556.2254671
   Singh H, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P190, DOI 10.1109/ICCONS.2018.8663011
   Singh Santosh Kumar, 2015, 2015 International Conference on Energy Economics and Environment (ICEEE), P1, DOI 10.1109/EnergyEconomics.2015.7235065
   Stewart S, 2018, INT CONF FRONT HAND, P465, DOI 10.1109/ICFHR-2018.2018.00087
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wang HF, 2010, CHIN CONTR CONF, P2712
   WANG PP, 1973, PATTERN RECOGN, V5, P303, DOI 10.1016/0031-3203(73)90023-X
   Wankhede PA, 2017, 2017 INTERNATIONAL CONFERENCE OF ELECTRONICS, COMMUNICATION AND AEROSPACE TECHNOLOGY (ICECA), VOL 2, P155, DOI 10.1109/ICECA.2017.8212785
   Wiraatmaja C, 2017, 2017 INTERNATIONAL CONFERENCE ON SOFT COMPUTING, INTELLIGENT SYSTEM AND INFORMATION TECHNOLOGY (ICSIIT), P72, DOI 10.1109/ICSIIT.2017.32
   Yao CH, 2009, INT TEST CONF P, P613
   Zhang H, 2018, INT C INT TRANSP BIG, P665
   Zhou Y., 2017, P IEEE INT C CYB EN, P1772
   Zhu Y, 2001, IEEE T PATTERN ANAL, V23, P1192, DOI 10.1109/34.954608
   Zramdini A, 1998, IEEE T PATTERN ANAL, V20, P877, DOI 10.1109/34.709616
NR 86
TC 16
Z9 17
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5319
EP 5350
DI 10.1007/s11042-020-09818-1
EA OCT 2020
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000575795600008
DA 2024-07-18
ER

PT J
AU Haider, MI
   Ali, A
   Shah, D
   Shah, T
AF Haider, Muhammad Imran
   Ali, Asif
   Shah, Dawood
   Shah, Tariq
TI Block cipher's nonlinear component design by elliptic curves: an image
   encryption application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Elliptic curves; Substitution box; Pseudo-random numbers; Image
   encryption
ID WAVELET TRANSFORM; CHAOTIC MAP; SCHEME; CRYPTOGRAPHY; PERMUTATION
AB Due to less computational effort with strong security, Elliptic curve based cryptographic architectures are more reliable as compared to the existing cryptographic methods. In this manuscript, we have introduced an efficient cryptosystem based on elliptic curves for digital image encryption. The designed scheme is consisting of three steps. Initially, the system uses the special type of the isomorphic elliptic curves over a prime field and scrambles the pixel position of the plain image. Consequently, it disperses the intra-correlation among the pixels of the original image, and capable the scheme to be secure against statistical attacks. In the next step, the scheme generates multiple S-boxes with good cryptographic features by using isomorphic elliptic curves. The generated S-boxes are then used to substitute the scrambled data that produce optimum confusion in the ciphered data. Eventually, the encryption procedure generates pseudo-random numbers (PRNs) through the arithmetic operation of the elliptic curves instead of elliptic curve group law; the operation used in the scheme creates high randomness as a result our proposed scheme shows high security against classical attacks. The simulation results and performance analysis divulge that the proposed scheme has excellent encryption performance with less computational effort, which indicates that the scheme has effective potential in real-time image encryption application.
C1 [Haider, Muhammad Imran; Ali, Asif; Shah, Dawood; Shah, Tariq] Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.
C3 Quaid I Azam University
RP Haider, MI (corresponding author), Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.
EM mimran@math.qau.edu.pk
CR Abd El-Latif AA, 2020, IEEE T NETW SERV MAN, V17, P118, DOI 10.1109/TNSM.2020.2969863
   Abd El-Latif AA, 2019, OPT LASER TECHNOL, V116, P92, DOI 10.1016/j.optlastec.2019.03.005
   Adams C., 1990, Journal of Cryptology, V3, P27, DOI 10.1007/BF00203967
   Ahmad M, 2015, PROCEDIA COMPUT SCI, V57, P572, DOI 10.1016/j.procs.2015.07.394
   [Anonymous], 2008, ELLIPTIC CURVES NUMB, DOI DOI 10.1201/9781420071474
   [Anonymous], 2012, MATH PUBLIC KEY CRYP
   Azam NA, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/3421725
   Belazi A, 2017, OPTIK, V130, P1438, DOI 10.1016/j.ijleo.2016.11.152
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Belazi A, 2015, INT WIREL COMMUN, P606, DOI 10.1109/IWCMC.2015.7289152
   Bhatnagar G, 2013, INFORM SCIENCES, V223, P297, DOI 10.1016/j.ins.2012.09.053
   Chen RJ, 2010, SIGNAL PROCESS-IMAGE, V25, P413, DOI 10.1016/j.image.2010.03.002
   Chen TH, 2012, INFORM SCIENCES, V189, P255, DOI 10.1016/j.ins.2011.11.026
   Chen TH, 2010, INFORM SCIENCES, V180, P1690, DOI 10.1016/j.ins.2009.12.021
   El-Latif AAA, 2013, HYBRID CHAOTIC SYSTE
   Gao TG, 2008, CHAOS SOLITON FRACT, V38, P213, DOI 10.1016/j.chaos.2006.11.009
   Ghadirli HM, 2019, SIGNAL PROCESSING
   Gura N, 2004, LECT NOTES COMPUT SC, V3156, P119
   Hayat U, 2019, SIGNAL PROCESS, V155, P391, DOI 10.1016/j.sigpro.2018.10.011
   Jakimoski G, 2001, IEEE T CIRCUITS-I, V48, P163, DOI 10.1109/81.904880
   Kang XJ, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115670
   Khan M, 2018, NEURAL COMPUT APPL, V29, P993, DOI 10.1007/s00521-016-2511-5
   Khan M, 2016, NEURAL COMPUT APPL, V27, P677, DOI 10.1007/s00521-015-1887-y
   Kim J, 2009, CRYPTOLOGIA, V33, P246, DOI 10.1080/01611190802653228
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   Lee LP, 2004, COMPUT MATH APPL, V47, P217, DOI [10.1016/S0898-1221(04)90018-1, 10.1016/S0898-1221(04)00006-9]
   Li L., 2019, 2019 IEEE 90th Vehicular Technology Conference (VTC2019-Fall), P1
   Li X, 2016, OPTIK, V127, P2558, DOI 10.1016/j.ijleo.2015.11.221
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Liu GJ, 2015, NONLINEAR DYNAM, V82, P1867, DOI 10.1007/s11071-015-2283-y
   Liu H, 2014, OPT LASER TECHNOL, V56, P15, DOI 10.1016/j.optlastec.2013.07.009
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Mehra I, 2014, OPT EXPRESS, V22, P5474, DOI 10.1364/OE.22.005474
   MEIER W, 1990, LECT NOTES COMPUT SC, V434, P549
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Mohamed FK, 2014, OPT LASER TECHNOL, V64, P145, DOI 10.1016/j.optlastec.2014.05.012
   Mohamed NA, 2015, INT CONF SOFT COMPUT, P230, DOI 10.1109/SOCPAR.2015.7492812
   Nestor T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010083
   Patro K.A.K., 2017, Smart and Innovative Trends in Next Generation Computing Technologies, V828, P396, DOI [10.1007/978-981-10-8660-130, DOI 10.1007/978-981-10-8660-130]
   Peng JL, 2017, INT CONF UBIQ FUTUR, P989
   Peng Z-P, 2014, NOVEL 4 DIMENTIONAL, P40506
   Reyad O., 2015, Appl. Math. Inf. Sci., V9, P31, DOI 10.12785/amis/090105
   Sesha Pallavi Indrakanti P.S. A., 2011, INT J COMPUT APPL, V28, P45
   Shankar K, 2016, ADV INTELL SYST, V394, P705, DOI 10.1007/978-81-322-2656-7_64
   Toughi S, 2017, SIGNAL PROCESS, V141, P217, DOI 10.1016/j.sigpro.2017.06.010
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Wang XY, 2016, BIOSYSTEMS, V144, P18, DOI 10.1016/j.biosystems.2016.03.011
   Wang XY, 2016, OPT LASER ENG, V82, P79, DOI 10.1016/j.optlaseng.2015.12.006
   Wang Y, 2012, PHYS LETT A, V376, P827, DOI 10.1016/j.physleta.2012.01.009
   Weister AF, 1986, DVANCES CRYPTOLOGY C
   Ye GD, 2017, NEUROCOMPUTING, V251, P45, DOI 10.1016/j.neucom.2017.04.016
   Zhang M, 2014, J SYST SOFTWARE, V98, P140, DOI 10.1016/j.jss.2014.08.066
   Zhou YC, 2013, IEEE T CYBERNETICS, V43, P515, DOI 10.1109/TSMCB.2012.2210706
NR 54
TC 28
Z9 28
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4693
EP 4718
DI 10.1007/s11042-020-09892-5
EA OCT 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000574376900005
DA 2024-07-18
ER

PT J
AU Wang, CM
   Ran, LQ
   He, C
AF Wang, Chunmeng
   Ran, Lingqiang
   He, Chen
TI Fast image super-resolution with the simplified residual network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super resolution; Convolutional neural networks; Simplified residual
   network
AB Recently, the image super-resolution (SR) methods based on residual learning have obtained remarkable quality performance. However, the current residual-learning methods have low computational performance and slow convergence rate. In this paper, we propose a high-efficiency two-level residual network to make the network learn more useful high-frequency information. Only 5 convolution layers in the LR space are used in our residual network, and no parameters are introduced in the other layers. Compared with the long training time up to several hours or days of previous deep residual networks, our simplified network can make the training time reduce to half an hour. Besides, our simplified network achieves satisfactory quality performance. The evaluation on the public datasets shows that our method can process SR of ultra-high definition (UHD) videos in real-time (more than 24 frames per second) on a generic graphical processing unit (GPU).
C1 [Wang, Chunmeng] Jinling Inst Technol, Sch Comp Engn, Nanjing 211169, Jiangsu, Peoples R China.
   [Ran, Lingqiang] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Shandong, Peoples R China.
   [He, Chen] Weifang Univ, Media & Commun Coll, Weifang 261061, Shandong, Peoples R China.
C3 Jinling Institute of Technology; Shandong University of Finance &
   Economics; Weifang University
RP Wang, CM (corresponding author), Jinling Inst Technol, Sch Comp Engn, Nanjing 211169, Jiangsu, Peoples R China.
EM wchm87@jit.edu.cn
RI liang, shuang/JOK-5869-2023; Ran, Ling-Qiang/F-9796-2010; Chen,
   Xupeng/KFA-5959-2024; He, Chen/JLM-5059-2023
FU Project of High-level Talents Research Foundation of Jinling Institute
   of Technology [jit-b-201802]; General Program of Natural Science
   Foundation of the Jiangsu Higher Education Institutions of China
   [19KJB520007]; Shandong Provincial Natural Science Foundation
   [ZR2019PF023]; Project of Shandong Province Higher Educational Science
   and Technology Program [J17KB184]; Science and Technology Development
   Plan Project of Weifang City [2019GX005]
FX We would like to thank Prof. Kim Munchurl in Korea Advanced Institute of
   Science and Technology (KAIST) for the initial inspiration of this work.
   This work is supported by the Project of High-level Talents Research
   Foundation of Jinling Institute of Technology (No. jit-b-201802), the
   General Program of Natural Science Foundation of the Jiangsu Higher
   Education Institutions of China (No. 19KJB520007), the Shandong
   Provincial Natural Science Foundation (Grant No. ZR2019PF023), the
   Project of Shandong Province Higher Educational Science and Technology
   Program under grant (No. J17KB184) and the Science and Technology
   Development Plan Project of Weifang City (No. 2019GX005).
CR Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852
   Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P3194, DOI 10.1109/TIP.2012.2190080
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   LU X, 2019, IEEE C COMP VIS PATT
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   PABLO A, 2011, IEEE T PATTERN ANAL, V33, P898, DOI DOI 10.1109/TPAMI.2010.161
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Tong CS, 2007, MULTIDIM SYST SIGN P, V18, P153, DOI 10.1007/s11045-007-0023-2
   Wang ZY, 2015, IEEE T IMAGE PROCESS, V24, P4359, DOI 10.1109/TIP.2015.2462113
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhang Y, 2018, IEEE ICC
   Zhou QY, 2010, 2010 INTERNATIONAL CONFERENCE ON INFORMATION, ELECTRONIC AND COMPUTER SCIENCE, VOLS 1-3, P1186
NR 27
TC 1
Z9 1
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4327
EP 4339
DI 10.1007/s11042-020-09954-8
EA SEP 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000573567500001
DA 2024-07-18
ER

PT J
AU Das, S
   Roy, ND
   Biswas, A
   Saha, SK
AF Das, Sayan
   Roy, Nilanjana Dutta
   Biswas, Arindam
   Saha, Sanjoy Kumar
TI A novel methodology for vessel extraction from retinal fundus image and
   detection of neovascularization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinal fundus images; Blood vessel segmentation; NVD and NVE detection
ID BLOOD-VESSELS; DIABETIC-RETINOPATHY; MATCHED-FILTER; SEGMENTATION;
   DIAGNOSIS; GLAUCOMA
AB Vessel extraction from the retinal fundus images plays a significant role in ophthalmologic disease diagnosis. Proliferative Diabetic Retinopathy (PDR) is the ultimate stage of Diabetic Retinopathy where proliferation of new and fragile blood vessels grow in human retina. These new blood vessels often show a tendency to rupture which further leads to severe damage of human eye. Neovascularization at the disk (NVD) and elsewhere (NVE) are the two general categories of PDR. So, disease diagnosis at the early stage by detecting the newly generated thin vessels demands utmost importance. Literature witness that most of the existing works emphasised on detecting only NVD. The goal of this work is to detect NVD along with NVE, as both the stages are equally devastating. The disease detection requires the extraction of vessels for subsequent analysis. A novel vessel extraction methodology has been proposed here which is capable of extracting the thick and thin vessels for further analysis. The experimental results have been tested and verified with two publicly available datasets of retinal fundus images, DRIVE and STARE. Finally, experiment for NVD and NVE detection has been carried out with DIARET-DB1 data-set. Comparison of performance with some other state-of-the-works shows superiority of the proposed methodology.
C1 [Das, Sayan; Saha, Sanjoy Kumar] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, West Bengal, India.
   [Roy, Nilanjana Dutta] Inst Engn & Management, Dept Comp Sci & Engn, Kolkata, West Bengal, India.
   [Biswas, Arindam] Indian Inst Engn Sci & Technol, Dept Informat Technol, Sibpur, Howrah, India.
C3 Jadavpur University; Institute of Engineering & Management (IEM),
   Kolkata; Indian Institute of Engineering Science Technology Shibpur
   (IIEST)
RP Das, S (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, West Bengal, India.
EM sayandas896@gmail.com
RI Dutta Roy, Nilanjana/AAC-7347-2022
OI Das, Sayan/0000-0003-0505-8589
CR Agurto C, 2012, IEEE ENG MED BIO, P4946, DOI 10.1109/EMBC.2012.6347102
   Akram MU, 2012, LECT NOTES COMPUT SC, V7325, P372, DOI 10.1007/978-3-642-31298-4_44
   Al-Diri B, 2009, IEEE T MED IMAGING, V28, P1488, DOI 10.1109/TMI.2009.2017941
   Azzopardi G, 2015, MED IMAGE ANAL, V19, P46, DOI 10.1016/j.media.2014.08.002
   Cinsdikici MG, 2009, COMPUT METH PROG BIO, V96, P85, DOI 10.1016/j.cmpb.2009.04.005
   Dash Jyotiprava, 2017, Future Computing and Informatics Journal, V2, P103, DOI 10.1016/j.fcij.2017.10.001
   DAXER A, 1993, CURR EYE RES, V12, P1103, DOI 10.3109/02713689309033508
   Dong Y, 2019, 2019 12 INT C IMAGE, P1
   Firdausy K, 2019, 2019 11 INT C INF TE, P1
   Franklin SW, 2014, BIOCYBERN BIOMED ENG, V34, P117, DOI 10.1016/j.bbe.2014.01.004
   Fraz MM, 2012, COMPUT METH PROG BIO, V108, P600, DOI 10.1016/j.cmpb.2011.08.009
   Frucci M, 2016, PATTERN RECOGN LETT, V82, P162, DOI 10.1016/j.patrec.2015.07.002
   Garhöfer G, 2004, J GLAUCOMA, V13, P340, DOI 10.1097/00061198-200408000-00013
   Guo CL, 2020, INT CONF ACOUST SPEE, P1374, DOI [10.1109/ICASSP40776.2020.9054290, 10.1109/icassp40776.2020.9054290]
   Hassan SSA, 2012, J DIGIT IMAGING, V25, P437, DOI 10.1007/s10278-011-9418-6
   Holzinger A, 2019, WIRES DATA MIN KNOWL, V9, DOI 10.1002/widm.1312
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Huang H, 2019, IEEE ENG MED BIO, P4712, DOI [10.1109/EMBC.2019.8856403, 10.1109/embc.2019.8856403]
   Imani E, 2015, COMPUT METH PROG BIO, V118, P263, DOI 10.1016/j.cmpb.2015.01.004
   Jiang XY, 2003, IEEE T PATTERN ANAL, V25, P131, DOI 10.1109/TPAMI.2003.1159954
   Joussen AM, 2004, FASEB J, V18, P1450, DOI 10.1096/fj.03-1476fje
   Kauppi T, 2007, DIARETDB1 STANDARD D
   Kowluru RA, 2001, DIABETES, V50, P1938, DOI 10.2337/diabetes.50.8.1938
   Kromm C, 2020, I S BIOMED IMAGING, P1223, DOI [10.1109/ISBI45749.2020.9098538, 10.1109/isbi45749.2020.9098538]
   Lam BSY, 2008, IEEE T MED IMAGING, V27, P237, DOI 10.1109/TMI.2007.909827
   Lee J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0075699
   Li Q, 2012, EXPERT SYST APPL, V39, P7600, DOI 10.1016/j.eswa.2011.12.046
   Marin D., 2010, IEEE T MED IMAGING, P1
   Martinez-Perez ME, 2007, MED IMAGE ANAL, V11, P47, DOI 10.1016/j.media.2006.11.004
   Mendonça AM, 2006, IEEE T MED IMAGING, V25, P1200, DOI 10.1109/TMI.2006.879955
   Miri MS, 2011, IEEE T BIO-MED ENG, V58, P1183, DOI 10.1109/TBME.2010.2097599
   Mitchell P, 2005, OPHTHALMOLOGY, V112, P245, DOI 10.1016/j.ophtha.2004.08.015
   Mudigonda S, 2015, E HLTH BIOENG C EHB, P1
   Nagel E, 2001, EUR J OPHTHALMOL, V11, P338, DOI 10.1177/112067210101100404
   Narasimhan K, 2012, PROCEDIA ENGINEER, V38, P980, DOI 10.1016/j.proeng.2012.06.124
   Niemeijer M, 2004, PROC SPIE, V5370, P648, DOI 10.1117/12.535349
   Ohno Takayuki, 2007, J Interv Cardiol, V20, P122, DOI 10.1111/j.1540-8183.2007.00252.x
   Oloumi F, 2015, COMPUT BIOL MED, V66, P316, DOI 10.1016/j.compbiomed.2015.09.009
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Prasad MNV, 2020, CLIMATE CHANGE AND SOIL INTERACTIONS, P1, DOI 10.1016/C2018-0-03008-X
   Rafsanjany Kushol, 2017, CONTRAST ENHANCEMENT, P533
   Rahim SS, 2019, LECT NOTES COMPUT SC, V11713, P114, DOI 10.1007/978-3-030-29726-8_8
   Rahim SS, 2015, LECT NOTES ARTIF INT, V9250, P379, DOI 10.1007/978-3-319-23344-4_37
   Ricci E, 2007, IEEE T MED IMAGING, V26, P1357, DOI 10.1109/TMI.2007.898551
   Rodrigues J, 2016, SIBGRAPI, P17, DOI [10.1109/SIBGRAPI.2016.11, 10.1109/SIBGRAPI.2016.012]
   Roychowdhury S, 2016, IEEE ENG MED BIO, P1300, DOI 10.1109/EMBC.2016.7590945
   Saranya K., 2012, 2012 International Conference on Communications and Signal Processing (ICCSP), P57, DOI 10.1109/ICCSP.2012.6208394
   Soares JVB, 2006, IEEE T MED IMAGING, V25, P1214, DOI 10.1109/TMI.2006.879967
   Sohini R. C., 2015, BIOMEDICAL HLTH INFO, DOI [DOI 10.1109/JBHI.2014.2335617, 10.1109/JBHI.2014.2335617]
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Triwijoyo BK, 2017, J PHYS CONF SER, V801, DOI 10.1088/1742-6596/801/1/012039
   VALSANIA P, 1993, ARCH OPHTHALMOL-CHIC, V111, P202, DOI 10.1001/archopht.1993.01090020056023
   Wahid FF, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P666, DOI [10.1109/aicai.2019.8701376, 10.1109/AICAI.2019.8701376]
   Wankhede PR, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INSTRUMENTATION AND CONTROL (ICIC), P1429, DOI 10.1109/IIC.2015.7150973
   Wu YC, 2018, LECT NOTES COMPUT SC, V11071, P119, DOI 10.1007/978-3-030-00934-2_14
   Yu S, 2018, IEEE J BIOMED HEALTH, V22, P886, DOI 10.1109/JBHI.2017.2710201
   Zana F, 2001, IEEE T IMAGE PROCESS, V10, P1010, DOI 10.1109/83.931095
   Zhang B, 2010, COMPUT BIOL MED, V40, P438, DOI 10.1016/j.compbiomed.2010.02.008
NR 58
TC 0
Z9 0
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4093
EP 4110
DI 10.1007/s11042-020-09889-0
EA SEP 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572865900001
DA 2024-07-18
ER

PT J
AU Su, AT
   He, XL
   Zhao, XF
AF Su, Ante
   He, Xiaolei
   Zhao, Xianfeng
TI JPEG steganalysis based on ResNeXt with Gauss partial derivative filters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; JPEG; CNNs; Gauss partial derivative
AB The latest research indicates that the image steganalysis has been greatly promoted by convolutional neural networks (CNNs). This study further addresses the problem of JPEG steganalysis through proposing a novel CNN architecture in which Gauss partial derivative (GPD) filters and two constructed blocks based on ResNeXt are integrated. In the proposed network, multi-order GPD filters are designed as the pre-processing layer to generate residual images, which can effectively capture sufficient embedding disturbance in texture and edge regions. Furthermore, referring to ResNeXt, two multi-branch blocks are constructed and aggregated to fully exploit the residual images to generate image features for classification. Numerous experiments have been conducted against J-UNIWARD on the public dataset to demonstrate the effectiveness and remarkable performance of the proposed network. Experimental results prove that the proposed network makes better performance than state-of-the-art CNN-based method J-Xu-Net and SCA-GFR. Source code is available via GitHub https://github.com/Ante-Su/RXGNet.
C1 [Su, Ante; He, Xiaolei; Zhao, Xianfeng] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [Su, Ante; He, Xiaolei; Zhao, Xianfeng] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100093, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP He, XL (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.; He, XL (corresponding author), Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100093, Peoples R China.
EM suante@iie.ac.cn; hexiaolei@iie.ac.cn; zhaoxianfeng@iie.ac.cn
RI Zhao, Xianfeng/AAE-7278-2021; He, Xiaolei/GQO-8250-2022
OI Zhao, Xianfeng/0000-0002-5617-8399; He, Xiaolei/0000-0003-1739-5355; He,
   Xiaolei/0000-0002-5770-7192
FU NSFC [61972390, U1736214, 61872356, 61902391, 61802393]; National Key
   Technology RD Program [2019QY0701]
FX This work was supported by NSFC under 61972390, U1736214, 61872356,
   61902391 and 61802393, and National Key Technology R&D Program under
   2019QY0701
CR Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bas P, 2007, BOWS 2 BREAK OUR WAT
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Chen M, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P75, DOI 10.1145/3082031.3083248
   Cox IJ., 2007, DIGITAL WATERMARKING
   Denemark T, 2016, IEEE T INF FOREN SEC, V11, P1747, DOI 10.1109/TIFS.2016.2555281
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Luo Y, 2015, ISPRS INTERNATIONAL WORKSHOP ON SPATIOTEMPORAL COMPUTING, P19, DOI 10.5194/isprsannals-II-4-W2-19-2015
   Qian YL, 2016, IEEE IMAGE PROC, P2752, DOI 10.1109/ICIP.2016.7532860
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu G., 2016, P 4 ACM WORKSH INF H, P103, DOI DOI 10.1145/2909827.2930798
   Xu GS, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P67, DOI 10.1145/3082031.3083236
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Yedroudj M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2092, DOI 10.1109/ICASSP.2018.8461438
   Zeng JS, 2018, IEEE T INF FOREN SEC, V13, P1200, DOI 10.1109/TIFS.2017.2779446
   Zhang Y, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013011
NR 26
TC 8
Z9 8
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3349
EP 3366
DI 10.1007/s11042-020-09350-2
EA SEP 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000571689900002
DA 2024-07-18
ER

PT J
AU Kobayashi, K
   Komuro, T
   Kagawa, K
   Kawahito, S
AF Kobayashi, Kazuki
   Komuro, Takashi
   Kagawa, Keiichiro
   Kawahito, Shoji
TI Transmission of correct gaze direction in video conferencing using
   screen-embedded cameras
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gaze preservation; Teleconferencing; Camera selection
AB In this paper, we propose a new video conferencing system that presents correct gaze directions of a remote user by switching among images obtained from multiple cameras embedded in a screen according to a local user's position. Our proposed method reproduces a situation like that in which the remote user is in the same space as the local user. The position of the remote user to be displayed on the screen is determined so that the positional relationship between the users is reproduced. The system selects one of the embedded cameras whose viewing direction towards the remote user is the closest to the local user's viewing direction to the remote user's image on the screen. As a result of quantitative evaluation, we confirmed that, in comparison with the case using a single camera, the accuracy of gaze estimation was improved by switching among the cameras according to the position of the local user.
C1 [Kobayashi, Kazuki; Komuro, Takashi; Kagawa, Keiichiro; Kawahito, Shoji] Shizuoka Univ, Naka Ku, Johoku 3-5-1, Hamamatsu, Shizuoka, Japan.
C3 Shizuoka University
RP Komuro, T (corresponding author), Shizuoka Univ, Naka Ku, Johoku 3-5-1, Hamamatsu, Shizuoka, Japan.
EM komuro@mail.saitama-u.ac.jp
FU Center of Innovation Program from Japan Science and Technology Agency
FX This research is partially supported by the Center of Innovation Program
   from Japan Science and Technology Agency.
CR Harrison C, 2008, IEEE INT SYM MULTIM, P236, DOI 10.1109/ISM.2008.12
   Hecht H, 2014, PSIHOLOGIJA, V47, P287, DOI 10.2298/PSI1403287H
   HIGUCHI K, 2015, P 33 ANN ACM C HUM F, P2383
   Jones A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531370
   Jouppi NP, 2004, P 12 ANN ACM INT C M, P860, DOI DOI 10.1145/1027527.1027725
   Kim K, 2012, P SIGCHI C HUM FACT, P2531, DOI DOI 10.1145/2207676.2208640
   Kuster C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366193
   Lincoln P, 2011, VIRTUAL REAL-LONDON, V15, P225, DOI 10.1007/s10055-010-0175-5
   Lincoln Peter, 2009, IMMERSIVE TELECOMMUN
   Maimone A, 2011, INT SYM MIX AUGMENT
   Misawa K, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P394, DOI 10.1145/2254556.2254632
   Nguyen D., 2005, Proceedings of the sigchi conference on human factors in computing systems, P799
   Otsuka K, 2016, P IEEE VIRT REAL ANN, P19, DOI 10.1109/VR.2016.7504684
   Pan Y, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2173, DOI 10.1145/2556288.2557320
   Pejsa T, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1716, DOI 10.1145/2818048.2819965
   Sirkin D, 2011, LECT NOTES COMPUT SC, V6946, P162, DOI 10.1007/978-3-642-23774-4_16
   Vertegaal R., 2003, ACM CHI, P521, DOI 10.1145/642611.642702
   Yang RG, 2004, IEEE T PATTERN ANAL, V26, P956, DOI 10.1109/TPAMI.2004.27
   Zhang C, 2013, IEEE MULTIMEDIA, V20, P17, DOI 10.1109/MMUL.2013.12
   Zhu JJ, 2011, 3D RES, V2, DOI 10.1007/3DRes.03(2011)5
NR 20
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31509
EP 31526
DI 10.1007/s11042-020-09758-w
EA SEP 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000571253200004
DA 2024-07-18
ER

PT J
AU Zhang, ZC
   Xi, XX
   Luo, XQ
   Jiang, YT
   Dong, J
   Wu, XJ
AF Zhang, Zhancheng
   Xi, Xinxing
   Luo, Xiaoqing
   Jiang, Yuting
   Dong, Jing
   Wu, Xiaojun
TI Multimodal image fusion based on global-regional-local rule in NSST
   domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Global; Regional; Local; Correlation; Contextual hidden Markov model;
   Image fusion
ID WAVELET; TRANSFORM; NETWORK; MODEL
AB An accurate representation of the source image is vital in image fusion processing. However, among most of the traditional multi-scale decomposition based image fusion methods, they fail to accurately interpret the source images, only capturing local information without considering the regional and global information. To overcome this drawback, a novel image fusion method based on the global-regional-local rule is proposed in the nonsubsampled shearlet transform (NSST) domain. First, the source paired images are decomposed into the low-pass subbands and high-pass subbands with the NSST transformation. Second, for comprehensively representing the statistical correlation of source image, three-level statistical models, that is, global contextual hidden Markov model (G-CHMM), regional contextual hidden Markov model (R-CHMM), and local contextual hidden Markov model (L-CHMM) are established for the high-pass subbands. In the R-CHMM, a novel feature vector is extracted for getting the region map of source image by the fuzzy cluster method (FCM). Third, to get accurate active measures of the source image, a global-regional-local fusion rule based on the statistical characteristics extracted from global-regional-local CHMM is designed, which is used to fuse the high-pass subbands. The low-pass subbands are fused with the choose-max rule based on the local gradient measure. Finally, the fused image is obtained by the inverse NSST. Experimental results on serials of infrared and visible images, medical images and multi-focus images demonstrate the advantage of the proposed method in terms of detail preserving.
C1 [Zhang, Zhancheng] Suzhou Univ Sci & Technol, Coll Elect & Informat Engn, Suzhou 215009, Peoples R China.
   [Xi, Xinxing; Luo, Xiaoqing; Jiang, Yuting; Wu, Xiaojun] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Jiangsu, Peoples R China.
   [Xi, Xinxing; Luo, Xiaoqing; Jiang, Yuting; Wu, Xiaojun] Jiangsu Prov Engn Lab Pattern Recognit & Computat, Wuxi 214122, Jiangsu, Peoples R China.
   [Dong, Jing] Nanjing Tech Univ, Coll Elect Engn & Control Sci, Nanjing 211816, Peoples R China.
C3 Suzhou University of Science & Technology; Jiangnan University; Nanjing
   Tech University
RP Luo, XQ (corresponding author), Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Jiangsu, Peoples R China.; Luo, XQ (corresponding author), Jiangsu Prov Engn Lab Pattern Recognit & Computat, Wuxi 214122, Jiangsu, Peoples R China.
EM xqluo@jiangnan.edu.cn
FU National Natural Science Foundation of China [61772237, 61906087];
   Provincial Research [BK20180692]; Fundamental Research Funds for the
   Central Universities [JUSRP51618B]; Six Talent Climax Foundation of
   Jiangsu [XYDXX-030]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61772237, 61906087, in part by
   Provincial Research under Grant BK20180692, and in part by the
   Fundamental Research Funds for the Central Universities under Grant
   JUSRP51618B, and the Six Talent Climax Foundation of Jiangsu under Grant
   XYDXX-030. Z. Zhang is with the College of Electronic and Information
   Engineering, Suzhou University of Science and Technology, Suzhou 215009,
   China. X. Luo, Y. Jiang, X. Xi and X. Wu are with the School of Internet
   of Artificial Intelligence and Computer Science, Jiangnan University,
   Wuxi 214122, China and Jiangsu Provincial Engineering Laboratory for
   Pattern Recognition and Computational Intelligence. J. D is with the
   College of Electrical Engineering and Control Science, Nanjing Tech
   University, Nanjing, Jiangsu, China. (Correspondence e-mail: xqluo@
   jiangnan.edu.cn).
CR Bhatnagar G, 2013, IEEE T MULTIMEDIA, V15, P1014, DOI 10.1109/TMM.2013.2244870
   Chai PF, 2017, IEEE ACCESS, V5, P6724, DOI 10.1109/ACCESS.2017.2685178
   Crouse M.S., 1997, P 31 AS C, V1, P95
   Das S, 2013, IEEE T BIO-MED ENG, V60, P3347, DOI 10.1109/TBME.2013.2282461
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Fan GL, 2001, IEEE SIGNAL PROC LET, V8, P125, DOI 10.1109/97.917691
   Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312
   Haribabu M., 2012, 2012 International Conference on Advances in Mobile Network, Communication and its Applications (MNCAPPS), P127, DOI 10.1109/MNCApps.2012.33
   Huang FR, 2021, IEEE T CYBERNETICS, V51, P1506, DOI 10.1109/TCYB.2019.2896100
   Huang FR, 2019, IEEE T IMAGE PROCESS, V28, P2008, DOI 10.1109/TIP.2018.2882225
   Kwitt R, 2011, IEEE T IMAGE PROCESS, V20, P2063, DOI 10.1109/TIP.2011.2108663
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Liang JL, 2012, IEEE T IMAGE PROCESS, V21, P2898, DOI 10.1109/TIP.2012.2183140
   Liu YP, 2014, SIGNAL PROCESS, V97, P9, DOI 10.1016/j.sigpro.2013.10.010
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Luo XQ, 2014, INT C PATT RECOG, P1049, DOI 10.1109/ICPR.2014.190
   Luo XQ, 2017, IEEE SENS J, V17, P1760, DOI 10.1109/JSEN.2016.2646741
   Pohl C, 1998, INT J REMOTE SENS, V19, P823, DOI 10.1080/014311698215748
   Pu T, 2000, OPT ENG, V39, P2075, DOI 10.1117/1.1303728
   Sahu A, 2015, 2014 INTERNATIONAL CONFERENCE ON MEDICAL IMAGING, M-HEALTH & EMERGING COMMUNICATION SYSTEMS (MEDCOM), P448
   Srivastava R, 2016, IET COMPUT VIS, V10, P513, DOI 10.1049/iet-cvi.2015.0251
   Wang L, 2014, INFORM FUSION, V19, P29, DOI 10.1016/j.inffus.2013.04.005
   Yang X, 2019, IEEE T MULTIMEDIA, V21, P328, DOI 10.1109/TMM.2018.2863602
   Yang Y, 2019, IEEE T COMPUT IMAG, V5, P262, DOI 10.1109/TCI.2018.2889959
   Yang Yong., 2012, Computing and Informatics, V26, P17
   Yuan Cao, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P17, DOI 10.1109/ICIG.2011.37
   Zhang HY, 2014, INT C PATT RECOG, P1067, DOI 10.1109/ICPR.2014.193
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
NR 30
TC 14
Z9 16
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2847
EP 2873
DI 10.1007/s11042-020-09647-2
EA SEP 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000570032900002
DA 2024-07-18
ER

PT J
AU Li, FY
   Zhu, HJ
   Yu, J
   Qin, C
AF Li, Fengyong
   Zhu, Hengjie
   Yu, Jiang
   Qin, Chuan
TI Double linear regression prediction based reversible data hiding in
   encrypted images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Image encryption; Double linear regression
   prediction
ID SCHEME; INTERPOLATION
AB Existing prediction-based works on reversible data hiding in encrypted images usually embed the secret messages by referring to the difference between current pixel and its predicted value. An accurate prediction model may promote an improvement of embedding capacity. Existing schemes, however, may not work well due to involving a bad prediction model so that their embedding capacity cannot be improved further. To address the problem, this paper proposes a new reversible data hiding scheme in encrypted images by designing double linear regression prediction model. Proposed model can significantly improve the prediction accuracy of current pixel based on neighboring pixels, more auxiliary rooms are thus vacated to embed secret data. Furthermore, a prediction error map is constructed to mark the error positions caused by inaccurate prediction, which can be further compressed lossless to lower the capacity of auxiliary data. Reversible recovery for original image can be finally achieved successfully. Experimental results demonstrate that the proposed scheme significantly improves prediction accuracy and data embedding capacity by combining double linear regression prediction model and prediction error map, and then can achieve separable and lossless recovery for the original image. Compared with existing works, the proposed scheme can implement a higher visual quality of decrypted images, while maintaining a larger embedding capacity.
C1 [Li, Fengyong; Zhu, Hengjie] Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 200090, Peoples R China.
   [Yu, Jiang] Shanghai Business Sch, Sch Informat & Comp, Shanghai, Peoples R China.
   [Qin, Chuan] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai, Peoples R China.
C3 Shanghai University of Electric Power; Shanghai Business School;
   University of Shanghai for Science & Technology
RP Li, FY (corresponding author), Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 200090, Peoples R China.
EM fyli@shiep.edu.cn
RI qin, chuan/ABG-4508-2020; Qin, Chuan/C-1106-2017
OI Qin, Chuan/0000-0002-0370-4623
FU Natural Science Foundation of Shanghai [20ZR1421600, 18ZR1427500]
FX This work is supported by the Natural Science Foundation of Shanghai
   (20ZR1421600, 18ZR1427500).
CR Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chen KM, 2019, MULTIMED TOOLS APPL, V78, P31441, DOI 10.1007/s11042-019-07946-x
   Huang DL, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115632
   Kaur Sandeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P23, DOI 10.5815/ijigsp.2017.07.03
   Khosravi MR, 2018, NEURAL COMPUT APPL, V30, P2017, DOI 10.1007/s00521-018-3489-y
   Khosravi MR, 2018, INT J AGRIC ENVIRON, V9, P53, DOI 10.4018/IJAEIS.2018040104
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Li FY, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2020.107454
   Li Q, 2018, MULTIMED TOOLS APPL, V77, P30749, DOI 10.1007/s11042-018-6187-y
   Liu Jin, 2019, ACTA BOTANICA BOREALI-OCCIDENTALIA SINICA, V39, P1, DOI 10.7606/j.issn.1000-4025.2019.01.0001
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Mander Kuldeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P17, DOI 10.5815/ijigsp.2017.08.03
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qin C, 2018, IEEE MULTIMEDIA, V25, P36, DOI 10.1109/MMUL.2018.112142509
   Qin C, 2018, SIGNAL PROCESS, V153, P109, DOI 10.1016/j.sigpro.2018.07.008
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tang ZJ, 2019, MULTIMED TOOLS APPL, V78, P9691, DOI 10.1007/s11042-018-6567-3
   Nguyen TS, 2016, SIGNAL PROCESS-IMAGE, V44, P84, DOI 10.1016/j.image.2016.03.010
   Wu HB, 2019, MULTIMED TOOLS APPL, V78, P25349, DOI 10.1007/s11042-019-07769-w
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xiao D, 2017, J VIS COMMUN IMAGE R, V45, P1, DOI 10.1016/j.jvcir.2017.02.001
   Xu DW, 2016, SIGNAL PROCESS, V123, P9, DOI 10.1016/j.sigpro.2015.12.012
   Yi S, 2017, SIGNAL PROCESS, V133, P40, DOI 10.1016/j.sigpro.2016.10.017
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang X, 2012, INT WORKSH DIG WAT, P358
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zheng SL, 2016, MULTIMED TOOLS APPL, V75, P13765, DOI 10.1007/s11042-015-2920-y
NR 29
TC 11
Z9 11
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2141
EP 2159
DI 10.1007/s11042-020-09805-6
EA SEP 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568478700004
DA 2024-07-18
ER

PT J
AU Daoui, A
   Sayyouri, M
   Qjidaa, H
AF Daoui, Achraf
   Sayyouri, Mhamed
   Qjidaa, Hassan
TI Efficient computation of high-order Meixner moments for large-size
   signals and images analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete orthogonal Meixner moments; Discrete orthogonal Meixner
   polynomials; Signal and image reconstruction; Orthogonalization methods;
   Numerical stability; High-order polynomials
ID INVARIANT MOMENTS; CHARLIER MOMENTS; STABLE COMPUTATION; TCHEBICHEF
   MOMENTS; KRAWTCHOUK; CLASSIFICATION; COMPRESSION; ALGORITHM; SET
AB In this paper, we present an in-depth study on the computational aspects of high-order discrete orthogonal Meixner polynomials (MPs) and Meixner moments (MMs). This study highlights two major problems related to the computation of MPs. The first problem is the overflow and the underflow of MPs values ("Nan" and "infinity"). To overcome this problem, we propose two new recursive Algorithms for MPs computation with respect to the polynomial ordernand with respect to the variablex. These Algorithms are independent of all functions that are the origin the numerical overflow and underflow problem. The second problem is the propagation of rounding errors that lead to the loss of the orthogonality property of high-order MPs. To fix this problem, we implement MPs based on the following orthogonalization methods: modified Gram-Schmidt process (MGS), Householder method, and Givens rotation method. The proposed Algorithms for the stable computation of MPs are efficiently applied for the reconstruction and localization of the region of interest (ROI) of large-sized 1D signals and 2D/3D images. We also propose a new fast method for the reconstruction of large-size 1D signal. This method involves the conversion of 1D signal into 2D matrix, then the reconstruction is performed in the 2D domain, and a 2D to 1D conversion is performed to recover the reconstructed 1D signal. The results of the performed simulations and comparisons clearly justify the efficiency of the proposed Algorithms for the stable analysis of large-size signals and 2D/3D images.
C1 [Daoui, Achraf; Sayyouri, Mhamed] Sidi Mohamed Ben Abdellah Fez Univ, Natl Sch Appl Sci, Lab Engn Syst & Applicat, Fes, Morocco.
   [Qjidaa, Hassan] Fac Sci, Lab Elect Signals & Syst Informat, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Daoui, A (corresponding author), Sidi Mohamed Ben Abdellah Fez Univ, Natl Sch Appl Sci, Lab Engn Syst & Applicat, Fes, Morocco.
EM achraf.daoui@usmba.ac.ma; mhamed.sayyouri@usmba.ac.ma; qjidah@yahoo.fr
RI DAOUI, Achraf/AAE-7012-2022; Sayyouri, Mhamed/AAB-5496-2020
OI DAOUI, Achraf/0000-0002-2326-9550; Sayyouri, Mhamed/0000-0002-1615-419X;
   Hassan, qjidaa/0000-0003-4505-5243
CR Asli BHS, 2014, INFORM SCIENCES, V288, P73, DOI 10.1016/j.ins.2014.07.046
   Benouini R, 2019, PATTERN RECOGN, V91, P100, DOI 10.1016/j.patcog.2019.02.014
   Benouini R, 2019, PATTERN RECOGN LETT, V123, P39, DOI 10.1016/j.patrec.2019.03.001
   Camacho-Bello C, 2018, PATTERN RECOGN LETT, V112, P332, DOI 10.1016/j.patrec.2018.08.020
   Daoui A., 2020, Embedded Systems and Artificial Intelligence. Proceedings of ESAI 2019. Advances in Intelligent Systems and Computing (AISC 1076), P369, DOI 10.1007/978-981-15-0947-6_35
   Daoui A, 2020, CIRC SYST SIGNAL PR, V39, P4552, DOI 10.1007/s00034-020-01384-z
   Daoui A, 2020, INFORM SCIENCES, V521, P251, DOI 10.1016/j.ins.2020.02.019
   Deng AW, 2016, PATTERN RECOGN, V56, P16, DOI 10.1016/j.patcog.2016.02.014
   Ernawan F, 2017, OPTIK, V148, P106, DOI 10.1016/j.ijleo.2017.08.007
   Fang R, 2008, LECT NOTES COMPUT SC, V5358, P381, DOI 10.1007/978-3-540-89639-5_37
   Ford W., 2014, Numerical Linear Algebra with Applications: Using MATLAB
   Hmimid A, 2018, MULTIMED TOOLS APPL, V77, P23607, DOI 10.1007/s11042-018-5623-3
   Hmimid A, 2015, PATTERN RECOGN, V48, P509, DOI 10.1016/j.patcog.2014.08.020
   Hmimid A, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.013026
   Hosny KM, 2018, IET IMAGE PROCESS, V12, P2178, DOI 10.1049/iet-ipr.2018.5661
   Hosny KM, 2018, BIOCYBERN BIOMED ENG, V38, P385, DOI 10.1016/j.bbe.2018.02.006
   Jahid T, 2019, J MATH IMAGING VIS, V61, P534, DOI 10.1007/s10851-018-0860-7
   Jahid T, 2018, MULTIMED TOOLS APPL, V77, P19811, DOI 10.1007/s11042-017-5371-9
   Karakasis EG, 2013, PATTERN RECOGN, V46, P1998, DOI 10.1016/j.patcog.2013.01.008
   Karmouni H, 2019, MULTIMED TOOLS APPL, V78, P31245, DOI 10.1007/s11042-019-07961-y
   Karmouni H, 2018, CIRC SYST SIGNAL PR, V37, P4015, DOI 10.1007/s00034-018-0755-2
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu XL, 2017, IEEE T SIGNAL PROCES, V65, P1894, DOI 10.1109/TSP.2017.2652383
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Peng C, 2019, FRONT OPTOELECTRON, V12, P413, DOI 10.1007/s12200-019-0862-0
   Radiopaedia.org, WIK BAS COLL RAD RES
   Rahman SMM, 2016, PATTERN RECOGN, V54, P83, DOI 10.1016/j.patcog.2016.01.003
   Sayyouri M, 2016, MULTIMED TOOLS APPL, V75, P547, DOI 10.1007/s11042-014-2307-5
   Sayyouri M, 2015, CIRC SYST SIGNAL PR, V34, P875, DOI 10.1007/s00034-014-9881-7
   Sayyouri M, 2014, LECT NOTES COMPUT SC, V8509, P441, DOI 10.1007/978-3-319-07998-1_51
   Sayyouri M, 2013, J OPT SOC AM A, V30, P2381, DOI 10.1364/JOSAA.30.002381
   Singh C, 2012, DIGIT SIGNAL PROCESS, V22, P1031, DOI 10.1016/j.dsp.2012.06.009
   Stewart G. W., 1998, MATRIX ALGORITHMS, V1
   Trefethen L.N., 1997, NUMERICAL LINEAR ALG
   Xia T, 2007, J OPT SOC AM A, V24, P50, DOI 10.1364/JOSAA.24.000050
   Xiao B, 2016, NEUROCOMPUTING, V214, P587, DOI 10.1016/j.neucom.2016.06.050
   Yamni M, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107509
   Yamni M, 2019, PROCEDIA COMPUT SCI, V148, P418, DOI 10.1016/j.procs.2019.01.054
   Yap PT, 2007, IEEE T PATTERN ANAL, V29, P2057, DOI 10.1109/TPAMI.2007.70709
   Zhang GJ, 2010, PATTERN RECOGN LETT, V31, P548, DOI 10.1016/j.patrec.2009.12.007
   Zhu H, 2010, IET IMAGE PROCESS, V4, P335, DOI 10.1049/iet-ipr.2009.0195
   Zhu HQ, 2007, PATTERN RECOGN LETT, V28, P1688, DOI 10.1016/j.patrec.2007.04.013
   Zhu HQ, 2007, SIGNAL PROCESS, V87, P687, DOI 10.1016/j.sigpro.2006.07.007
NR 45
TC 15
Z9 15
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 1641
EP 1670
DI 10.1007/s11042-020-09739-z
EA SEP 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568765600004
DA 2024-07-18
ER

PT J
AU Mouhou, AA
   Saaidi, A
   Ben Yakhlef, M
   Abbad, K
AF Mouhou, A. Ait
   Saaidi, A.
   Ben Yakhlef, M.
   Abbad, K.
TI Wrinkle synthesis for cloth mesh with hermite radial basis functions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloth simulation; Wrinkle augmentation; Mesh deformation; Implicit
   modeling
AB Designing virtual clothing has received much attention recently due to the increasing need for synthesizing realistically dressed digital humans for various applications. Wrinkles are an important appearance feature of the garment in virtual environments. Generating such wrinkles currently requires a computationally expensive simulation or specialized design skills. We present a new geometric method for adding believable wrinkles to existing virtual clothing. The key novelty of our work is to use Hermite Radial Based Functions (HRBF) to reconstruct an approximation of the clothing mesh. Our method takes advantage of angles between gradients of adjacent HRBF scalar fields to trace spatially and temporally coherent wrinkle curves on a cloth mesh. We generate plausible wrinkle geometry using implicit deformers following the wrinkle curves. Our method can be used as a post-processing step on any garment simulation system. The results obtained demonstrate that our approach produces believable wrinkles and it is very satisfactory in terms of performance. The method is fully automatic and provides a large set of parameters that can be modified by the user in order to control the appearance of the resulting wrinkles in real-time and thus obtain the desired result.
C1 [Mouhou, A. Ait; Saaidi, A.; Ben Yakhlef, M.] Sidi Mohamed Ben Abdellah Univ, FP Taza, Tinghir, Morocco.
   [Abbad, K.] Sidi Mohamed Ben Abdellah Univ, FST, Tinghir, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Mouhou, AA (corresponding author), Sidi Mohamed Ben Abdellah Univ, FP Taza, Tinghir, Morocco.
EM abderrazzak.aitmouhou@usmba.ac.ma; abderrahim.saaidi@usmba.ac.ma;
   majid.benyakhlef@usmba.ac.ma; khalid.abbad@usmba.ac.ma
OI khalid, abbad/0000-0002-4929-1967; BEN YAKHLEF,
   Majid/0000-0002-6696-9426; abderrazzak, ait mouhou/0000-0002-6903-0860
CR Ait Mouhou Abderrazzak, 2019, Lecture Notes in Real-Time Intelligent Systems. Advances in Intelligent Systems and Computing (AISC 756), P497, DOI 10.1007/978-3-319-91337-7_44
   [Anonymous], 2010, J THERM ANAL CALORIM, DOI DOI 10.5220/0002996201420151
   Baran I, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239523, 10.1145/1276377.1276467]
   Bender J, 2014, COMPUT GRAPH FORUM, V33, P228, DOI 10.1111/cgf.12346
   BLOOMENTHAL J, 1991, COMP GRAPH, V25, P251, DOI 10.1145/127719.122757
   Cutler Lawrence D., 2005, P 2005 ACM SIGGRAPH, P117
   English E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360665
   Gillette Russell, 2015, P 14 ACM SIGGRAPH EU, P17
   Gourmel O, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451238
   Gundogdu E, 2019, IEEE I CONF COMP VIS, P8738, DOI 10.1109/ICCV.2019.00883
   Hahn Fabian, 2014, ACM Transactions on Graphics, V33, DOI 10.1145/2601097.2601160
   Han XT, 2018, PROC CVPR IEEE, P7543, DOI 10.1109/CVPR.2018.00787
   Jin N, 2017, ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2017), DOI 10.1145/3099564.3099568
   Kavan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409627
   Li J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201308
   Li JT, 2011, COMPUT IND, V62, P693, DOI 10.1016/j.compind.2011.04.002
   Li MC, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201310
   Liu SJ, 2016, COMPUT AIDED DESIGN, V78, P147, DOI 10.1016/j.cad.2016.05.001
   Liu TT, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508406
   Macêdo I, 2011, COMPUT GRAPH FORUM, V30, P27, DOI 10.1111/j.1467-8659.2010.01785.x
   McCormack J, 1998, COMPUT GRAPH FORUM, V17, P113, DOI 10.1111/1467-8659.00232
   Muller Matthias, 2010, Proceedings of the 2010 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P85, DOI [10.5555/1921427.19214412, DOI 10.5555/1921427.19214412]
   Oh Y. J., 2018, P COMP GRAPH INT 201, P139, DOI DOI 10.1145/3208159.3208162
   Rémillard O, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462018
   RICCI A, 1973, COMPUT J, V16, P157, DOI 10.1093/comjnl/16.2.157
   Rohmer D, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866183
   Santesteban Igor, 2019, Computer Graphics Forum, V38, P355, DOI 10.1111/cgf.13643
   Shell M., 2012, Carnegie mellon university motion capture database
   Vaillant R, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461960
   Wang Tuanfeng Y., 2018, ACM Transactions on Graphics, V37, DOI 10.1145/3272127.3275074
   Wang TY, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356512
   White KB, 2007, RT07: IEEE/EG Symposium on Interactive Ray Tracing 2007, P129, DOI 10.1109/RT.2007.4342600
   Xu WW, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601136
NR 33
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1583
EP 1610
DI 10.1007/s11042-020-09743-3
EA SEP 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000567642600006
DA 2024-07-18
ER

PT J
AU Cornia, M
   Baraldi, L
   Tavakoli, HR
   Cucchiara, R
AF Cornia, Marcella
   Baraldi, Lorenzo
   Tavakoli, Hamed R.
   Cucchiara, Rita
TI A unified cycle-consistent neural model for text and image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text-image cross retrieval; Cycle-consistency; Visual-semantic models
AB Text-image retrieval has been recently becoming a hot-spot research field, thanks to the development of deeply-learnable architectures which can retrieve visual items given textual queries and vice-versa. The key idea of many state-of-the-art approaches has been that of learning a joint multi-modal embedding space in which text and images could be projected and compared. Here we take a different approach and reformulate the problem of text-image retrieval as that of learning a translation between the textual and visual domain. Our proposal leverages an end-to-end trainable architecture that can translate text into image features and vice versa and regularizes this mapping with a cycle-consistency criterion. Experimental evaluations for text-to-image and image-to-text retrieval, conducted on small, medium and large-scale datasets show consistent improvements over the baselines, thus confirming the appropriateness of using a cycle-consistent constrain for the text-image matching task.
C1 [Cornia, Marcella; Baraldi, Lorenzo; Cucchiara, Rita] Univ Modena & Reggio Emilia, Dept Engn Enzo Ferrari, Modena, Italy.
   [Tavakoli, Hamed R.] Nokia Technol, Espoo, Finland.
C3 Universita di Modena e Reggio Emilia; Nokia Corporation; Nokia Finland
RP Cornia, M (corresponding author), Univ Modena & Reggio Emilia, Dept Engn Enzo Ferrari, Modena, Italy.
EM marcella.cornia@unimore.it; lorenzo.baraldi@unimore.it;
   hamed.rezazadegan_tavakoli@nokia.com; rita.cucchiara@unimore.it
RI Cucchiara, Rita/L-3006-2015; Tavakoli, Hamed R./O-9942-2016; Cornia,
   Marcella/Y-9903-2019
OI Tavakoli, Hamed R./0000-0002-9466-9148; Cornia,
   Marcella/0000-0001-9640-9385; Baraldi, Lorenzo/0000-0001-5125-4957
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Banerjee S., 2005, P WORKSHOP INTRINSIC, P65
   Baraldi L, 2018, INT C PATT RECOG, P1097, DOI 10.1109/ICPR.2018.8545064
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Cornia M, 2018, EUR C COMP VIS WORKS
   Cornia M, 2020, PATTERN RECOGN LETT, V129, P166, DOI 10.1016/j.patrec.2019.11.018
   Cornia M, 2017, IEEE INT CONF MULTI
   Cornia M, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3177745
   Cornia Marcella, 2020, IEEE C COMP VIS PATT
   Dong JF, 2018, IEEE T MULTIMEDIA, V20, P3377, DOI 10.1109/TMM.2018.2832602
   Dong Jianfeng., 2016, CoRR
   Eisenschtat A, 2017, PROC CVPR IEEE, P1855, DOI 10.1109/CVPR.2017.201
   Engilberge M., 2018, P CVPR
   Faghri F, 2018, P BRIT MACH VIS C, P1
   Gu JX, 2018, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR.2018.00750
   He Di, 2016, P ADV NEUR INF PROC, DOI DOI 10.5555/3157096.3157188
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Huang Y, 2018, PROC CVPR IEEE, P6163, DOI 10.1109/CVPR.2018.00645
   Huang Y, 2017, PROC CVPR IEEE, P7254, DOI 10.1109/CVPR.2017.767
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kingma D. P., 2014, arXiv
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Klein E, 2015, PROC CVPR IEEE, P4437, DOI 10.1109/CVPR.2015.7299073
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu RY, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3300939
   Luo P, 2017, IEEE I CONF COMP VIS, P2737, DOI 10.1109/ICCV.2017.296
   Malinowski M, 2015, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2015.9
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Peng L, 2019, MULTIMED TOOLS APPL, V78, P3843, DOI 10.1007/s11042-018-6389-3
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Pini S, 2019, MULTIMED TOOLS APPL, V78, P14007, DOI 10.1007/s11042-018-7040-z
   Qiao Tingting, 2019, IEEE C COMP VIS PATT
   Reed S, 2016, PR MACH LEARN RES, V48
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shah Meet, 2019, CVPR
   Shao J, 2019, MULTIMED TOOLS APPL, V78, P16615, DOI 10.1007/s11042-018-7068-0
   Shetty R, 2018, IEEE MULTIMEDIA, V25, P34, DOI 10.1109/MMUL.2018.112135923
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sundaram N, 2010, LECT NOTES COMPUT SC, V6311, P438, DOI 10.1007/978-3-642-15549-9_32
   Tang D, 2018, C N AM ASS COMP LING
   Tavakoli A, 2018, IEEE CONF NANOTECH
   Toor AS, 2019, MULTIMED TOOLS APPL, V78, P2921, DOI 10.1007/s11042-018-6097-z
   Tu ZP, 2017, AAAI CONF ARTIF INTE, P3097
   Wang BR, 2018, PROC CVPR IEEE, P7622, DOI 10.1109/CVPR.2018.00795
   Wang LW, 2019, IEEE T PATTERN ANAL, V41, P394, DOI 10.1109/TPAMI.2018.2797921
   Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246
   Wu CY, 2017, IEEE I CONF COMP VIS, P2859, DOI 10.1109/ICCV.2017.309
   Xie L, 2016, MULTIMED TOOLS APPL, V75, P9185, DOI 10.1007/s11042-016-3432-0
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Zhang H., 2017, IEEE INT C COMP VIS
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 63
TC 7
Z9 8
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25697
EP 25721
DI 10.1007/s11042-020-09251-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000565043500021
DA 2024-07-18
ER

PT J
AU Li, YP
   Li, C
AF Li, Yuepeng
   Li, Chun
TI A mixed model with multi-fidelity terms and nonlocal low rank
   regularization for natural image noise removal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mixed denoising model; Inverse problem; Alternative minimization; Image
   processing
ID ALTERNATING DIRECTION METHOD; GAUSSIAN-IMPULSE NOISE; RESTORATION;
   SPARSE; ALGORITHM; MATRIX; OPTIMIZATION; MINIMIZATION
AB Reconstructing an original image from its corrupted observation is an important and fundamental problem in many image processing applications. Generally, theL(1)-norm orL(2)-norm combined with a regularization term (the total variation (TV), total generalized variation (TGV) or nuclear norm) is used to fit the impulse noise and Gaussian noise, respectively. However, these methods can only be used to remove a single type of noise from images, and traditional regularization terms often have difficulties in capturing some important prior knowledge of images, such as nonlocal self-similarity, low rank and sparsity. To overcome the above issues, we propose a mixed noise removal model withL(1)-L(2)fidelity terms and a popular nonlocal low-rank regularization term, which has been shown to have more effective image denoising performance than traditional regularization methods. To solve this model, the split Bregman iteration method (SBIM) is adopted to decompose the difficult minimization optimization problem into four simple subproblems. Extensive experiments on natural images demonstrate that the effectiveness of the proposed method is better than that of other state-of-the-art methods.
C1 [Li, Yuepeng; Li, Chun] Chinese Acad Sci, Comp Network Informat Ctr, Beijing 100190, Peoples R China.
   [Li, Yuepeng; Li, Chun] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Computer Network Information Center, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Li, YP (corresponding author), Chinese Acad Sci, Comp Network Informat Ctr, Beijing 100190, Peoples R China.; Li, YP (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
EM liyuepeng@cnic.cn
RI li, yue/HZL-3265-2023; Wang, zhenhua/KFA-8731-2024; Chen,
   Haili/KHE-2315-2024
CR Abiko R, 2019, INT CONF ACOUST SPEE, P1717, DOI [10.1109/icassp.2019.8683878, 10.1109/ICASSP.2019.8683878]
   Ahn B., 2017, ARXIV170400524
   Alkinani Monagi H, 2017, EURASIP J Image Video Process, V2017, P58, DOI 10.1186/s13640-017-0203-4
   [Anonymous], 2011, COMPUTER VISION PATT
   Bovik Alan C, 2010, Handbook of image and video processing
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Burger HC, 2012, ARXIV12111544 1
   Cai JF, 2008, INVERSE PROBL IMAG, V2, P187
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Cai XH, 2013, SIAM J IMAGING SCI, V6, P368, DOI 10.1137/120867068
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Chatterjee P, 2009, IEEE T IMAGE PROCESS, V18, P1438, DOI 10.1109/TIP.2009.2018575
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Deng LJ, 2019, INFORM FUSION, V52, P76, DOI 10.1016/j.inffus.2018.11.014
   Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P3618, DOI 10.1109/TIP.2014.2329449
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Duval V, 2010, PARAMETER CHOICE NON
   Eckart C, 1936, PSYCHOMETRIKA, V1, P211, DOI 10.1007/BF02288367
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Ferstl D, 2013, IEEE I CONF COMP VIS, P993, DOI 10.1109/ICCV.2013.127
   Froment J, 2014, IMAGE PROCESS ON LIN, V4, P300, DOI 10.5201/ipol.2014.120
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   He BS, 2012, SIAM J OPTIMIZ, V22, P313, DOI 10.1137/110822347
   He BS, 2000, J OPTIMIZ THEORY APP, V106, P337, DOI 10.1023/A:1004603514434
   HEBERT T, 1989, IEEE T MED IMAGING, V8, P194, DOI 10.1109/42.24868
   Huang T, 2017, IEEE T IMAGE PROCESS, V26, P3171, DOI 10.1109/TIP.2017.2676466
   Ji H, 2011, SIAM J IMAGING SCI, V4, P1122, DOI 10.1137/100817206
   Jia TT, 2016, J VIS COMMUN IMAGE R, V38, P461, DOI 10.1016/j.jvcir.2016.03.022
   Jiang JL, 2015, NEUROCOMPUTING, V151, P817, DOI 10.1016/j.neucom.2014.10.017
   Jiang JL, 2014, IEEE T IMAGE PROCESS, V23, P2651, DOI 10.1109/TIP.2014.2317985
   Jung M, 2017, J SCI COMPUT, V70, P1229, DOI 10.1007/s10915-016-0280-z
   Jung M, 2015, SIAM J IMAGING SCI, V8, P721, DOI 10.1137/140967416
   Jung M, 2015, J SCI COMPUT, V62, P336, DOI 10.1007/s10915-014-9860-y
   Knoll F, 2011, MAGN RESON MED, V65, P480, DOI 10.1002/mrm.22595
   Lan XY, 2006, LECT NOTES COMPUT SC, V3952, P269
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Mahmoudi M, 2005, IEEE SIGNAL PROC LET, V12, P839, DOI 10.1109/LSP.2005.859509
   Mairal J, 2010, IEEE INT C COMP VIS
   Milovic C, 2018, MAGN RESON MED, V80, P814, DOI 10.1002/mrm.27073
   Mohan J, 2014, BIOMED SIGNAL PROCES, V9, P56, DOI 10.1016/j.bspc.2013.10.007
   Osher S., 2018, ARXIV180606317
   Qin ZW, 2015, OPTIM METHOD SOFTW, V30, P594, DOI 10.1080/10556788.2014.955100
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Srebro Nathan., 2003, Proceedings of the 20th International Conference on Machine Learning (ICML-03), P720
   Tikhonov A.N., 1963, SOV MATH DOKL, V5, P1035, DOI DOI 10.1111/J.1365-246X.2012.05699.X
   Wang F, 2019, IEEE T IMAGE PROCESS
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Xiao Y, 2011, PATTERN RECOGN, V44, P1708, DOI 10.1016/j.patcog.2011.02.002
   Xie Y, 2016, IEEE T IMAGE PROCESS, V25, P4842, DOI 10.1109/TIP.2016.2599290
   Xiong B, 2012, IEEE T IMAGE PROCESS, V21, P1663, DOI 10.1109/TIP.2011.2172804
   Yan M, 2013, SIAM J IMAGING SCI, V6, P1227, DOI 10.1137/12087178X
   Yang JF, 2009, SIAM J SCI COMPUT, V31, P2842, DOI 10.1137/080732894
   Yang Y., 2017, ADMM-Net: A deep learning approach for compressive sensing MRI
   Zhang DB, 2012, PROC CVPR IEEE, P2192, DOI 10.1109/CVPR.2012.6247927
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang Y., 2010, ALTERNATING DIRECTIO
   Zhou T, 2018, IEEE T CYBERNETICS, V48, P2643, DOI 10.1109/TCYB.2017.2747998
   Zhou T, 2019, IEEE T BIO-MED ENG, V66, P165, DOI 10.1109/TBME.2018.2824725
   Zhou T, 2017, NEUROCOMPUTING, V226, P221, DOI 10.1016/j.neucom.2016.11.055
   Zhou W, 2017, DESTECH T COMPUTER S
NR 65
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 33043
EP 33069
DI 10.1007/s11042-020-09565-3
EA AUG 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000564527000007
DA 2024-07-18
ER

PT J
AU Li, SQ
   Wang, HP
   Wang, SZ
   Zhang, S
AF Li, Shiqi
   Wang, Haipeng
   Wang, Shuze
   Zhang, Shuai
TI Life detection and non-contact respiratory rate measurement in cluttered
   environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Life detection; Respiratory rate measurement; Spatial filtering; Gray
   level compensation; Temporal filtering
ID MOTION
AB A method is proposed in this paper for life detection and non-contact respiratory rate measurement in cluttered environments. Only an RGB video of the detection area is required. In the method, spatial filtering is firstly applied to each frame of the video for image denoising. Gray level compensation follows to compensate for the change of gray level caused by the environment light. Thirdly, the gray levels of each pixel over time are filtered separately by a low-pass filter. At last, the human is located and the respiratory rate is measured. Tests on a self-made dataset show that an accuracy of 76.7% is achieved by the proposed method, which is better than that of the Convolutional Neural Networks (30%) and the histogram of oriented gradients (3.3%).
C1 [Li, Shiqi; Wang, Haipeng; Wang, Shuze; Zhang, Shuai] Huazhong Univ Sci & Technol, Sch Mech Engn Sci, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Wang, HP (corresponding author), Huazhong Univ Sci & Technol, Sch Mech Engn Sci, Wuhan 430074, Peoples R China.
EM sqli@hust.edu.cn; wanghai463100@126.com; sinankindle@163.com;
   zhangshuaihenan@163.com
RI wang, haipeng/HGB-4694-2022; wang, haipeng/JBJ-2111-2023
OI wang, haipeng/0000-0002-7400-8158; wang, haipeng/0000-0002-7400-8158;
   zhang, shuai/0000-0002-4457-9240
FU Manned Aerospace Research Project of China [060601]
FX This work was supported in part by the Manned Aerospace Research Project
   of China [grant number 060601].
CR [Anonymous], 2014, P COMP VIS ECCV 2014
   Aoki H, 2012, 2012 PROCEEDINGS OF SICE ANNUAL CONFERENCE (SICE), P614
   Awad F., 2014, INT J INTELL SCI, V04, P39, DOI [10.4236/ijis.2014.42006, DOI 10.4236/IJIS.2014.42006]
   Bai ZX, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P2218, DOI [10.1109/ICMA.2019.8816624, 10.1109/icma.2019.8816624]
   Burba N., 2012, Proc. 2012 IEEE Virtual Reality, V12, P1, DOI DOI 10.1109/VR.2012.6180952
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donelli M, 2011, PROG ELECTROMA RES M, V19, P173, DOI 10.2528/PIERM11061206
   Doulamis N, 2017, 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017), P311, DOI 10.1145/3056540.3076201
   Nguyen DT, 2016, PATTERN RECOGN, V51, P148, DOI 10.1016/j.patcog.2015.08.027
   Fang ZC, 2016, 2016 19TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1427
   Fusang Zhang, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3191785
   García-Martín A, 2015, IET COMPUT VIS, V9, P779, DOI 10.1049/iet-cvi.2014.0148
   Garnaut R, 2015, CHIN UPDATE BK SER, P1
   Huang Jonathan., 2017, Supercharge your Computer Vision models with the TensorFlow Object Detection API
   Jiang YS, 2015, PROC CVPR IEEE, P240, DOI 10.1109/CVPR.2015.7298620
   Kim Y, 2016, IEEE GEOSCI REMOTE S, V13, P8, DOI 10.1109/LGRS.2015.2491329
   Kumdee O, 2015, IEEE INT SYMP SIGNAL, P484, DOI 10.1109/ISSPIT.2015.7394384
   Lee TS, 2015, PHYS MED BIOL, V60, P1399, DOI 10.1088/0031-9155/60/4/1399
   Levin E, 2016, INT ARCH PHOTOGRAMM, V41, P99, DOI 10.5194/isprsarchives-XLI-B8-99-2016
   Rohrbach A, 2015, PROC CVPR IEEE, P3202, DOI 10.1109/CVPR.2015.7298940
   Sommer L.W., 2016, 2016 IEEE WINTER C A, P1
   Sulistijono IA, 2016, 2016 INTERNATIONAL ELECTRONICS SYMPOSIUM (IES), P93, DOI 10.1109/ELECSYM.2016.7860982
   Tran QV, 2017, P JOINT 17 WORLD C I, P1, DOI [10.1109/IFSA-SCIS.2017.8023320, DOI 10.1109/IFSA-SCIS.2017.8023320]
   Villarroel M, 2014, HEALTHC TECHNOL LETT, V1, P87, DOI 10.1049/htl.2014.0077
   Wu CS, 2015, IEEE J SEL AREA COMM, V33, P2329, DOI 10.1109/JSAC.2015.2430294
   Zhao MM, 2018, PROC CVPR IEEE, P7356, DOI 10.1109/CVPR.2018.00768
   Zhou F, 2014, LECT NOTES COMPUT SC, V8694, P62, DOI 10.1007/978-3-319-10599-4_5
NR 29
TC 7
Z9 7
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32065
EP 32077
DI 10.1007/s11042-020-09510-4
EA AUG 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562697400007
DA 2024-07-18
ER

PT J
AU Satouri, B
   Satori, K
   El Abderrahmani, A
AF Satouri, B.
   Satori, K.
   El Abderrahmani, A.
TI Genetic algorithms and bundle adjustment for the enhancement of 3D
   reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D reconstruction; Bundle adjustment; Self-calibration; Interests
   points; Matching; 3D mesh
ID SELF-CALIBRATION; IMAGE; SEQUENCES; POSE
AB In this paper, we present a new technique of tridimensional reconstruction from a sequence of uncalibrated stereo images taken with cameras having varying parameters. At first, our system allows to recover initial coordinates of a set of 3D points. In this context, we have used our method of self-calibration based on the use of unknown 3D scene with its image projections and genetic algorithms to estimate all intrinsic parameters. After that extrinsic parameters are estimated based on classical pose estimation algorithms. Matching points and estimated value of intrinsic and extrinsic parameters are used to estimate initial 3D model that helps us in the initialization step. In order to have a reliable and relevant 3D reconstruction the proposed method is based on good and new exploitation of bundle adjustment (without camera poses initialization) technique based on Levenberg-Marquardt optimization with the aim to estimate our optimal 3D model that has special features compared to the classical case because it masks the pose parameters estimation in the optimization process. Finally, 3D mesh of the 3D scene is constructed with Delaunay algorithm and the 2D image is projected on the 3D model to generate the texture mapping. Experiments is conducted on real data to achieve demonstrate the validity and the performance of the proposed approach in terms of convergence, simplicity, stability and reconstruction quality.
C1 [Satouri, B.; Satori, K.] Fac Sci Dhar Mahraz, Dept Math & Informat, LIIAN, POB 1796, Atlas Fes, Morocco.
   [El Abderrahmani, A.] Larache Poly Disciplinary Sch, Dept Math & Informat, LIIAN, Larache, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Abdelmalek Essaadi
   University of Tetouan
RP Satouri, B (corresponding author), Fac Sci Dhar Mahraz, Dept Math & Informat, LIIAN, POB 1796, Atlas Fes, Morocco.
EM boutainasatori@gmail.com; khalidsatori@gmail.fr; elabderrahmani@yahoo.fr
RI satori, khalid/GSE-3077-2022
OI SATORI, khalid/0000-0001-6055-4169
CR Al-Saeed Tarek A., 2006, GVIP SPECIAL ISSUE M
   Ameller M.-A., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P356
   [Anonymous], 1988, ALVEY VISION C
   Armstrong M., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P3
   Baataoui A., 2012, INT J COMPUT APPL, P29
   Beardsley P., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P683
   Blumenthal-Barby DC, 2014, COMPUT GRAPH-UK, V39, P89, DOI 10.1016/j.cag.2013.12.001
   Brooks M. J., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P415
   Brooks M. J., 1997, J OPTICAL SOC AM, V14
   Cao XC, 2006, COMPUT VIS IMAGE UND, V102, P227, DOI 10.1016/j.cviu.2006.01.004
   CAZALS F, 2004, RR5393 INRIA
   Cefalu A, 2016, ISPRS ANN PHOTO REM, V3, P3, DOI 10.5194/isprsannals-III-3-3-2016
   Chambon S., 2004, TRAITEMENT SIGNAL 20, V21
   Chambon S, 2011, PATTERN RECOGN, V44, P2063, DOI 10.1016/j.patcog.2011.02.001
   Cornou S, 2002, BUNDLE ADJUSTMENT FA
   David P, 2004, INT J COMPUT VISION, V59, P259, DOI 10.1023/B:VISI.0000025800.10423.1f
   DEMENTHON DF, 1992, LECT NOTES COMPUT SC, V588, P335, DOI 10.1007/BF01450852
   El abderrahmani A., 2010, ICGST GVIP, V10
   El Akkad N, 2016, 3D RES, V7, DOI 10.1007/s13319-016-0082-y
   El Akkad N, 2012, INT CONF MULTIMED, P161, DOI 10.1109/ICMCS.2012.6320196
   El Hazzat Soulaiman, 2014, Journal of Emerging Technologies in Web Intelligence, V6, P59, DOI 10.4304/jetwi.6.1.59-63
   El hazzat S., 2018, MULTIMEDIA TOOLS APP
   El hazzat S., 2018, VISUAL COMPUTER
   Elabderrahmani A., 2011, IJCST, V2
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fitzgibbon A. W., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P311, DOI 10.1007/BFb0055675
   Gao YY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P537
   Gouet V, 2002, OPTIMAL USE COLOR PO
   Gurdjos P, 2003, PROC CVPR IEEE, P491
   Hanet M., 2001, P 8 INT C COMP VIS V
   Hartley RI, 1993, P 2 EUR US WORKSH AP, P237
   Hartley R, 2013, INT J COMPUT VISION, V103, P267, DOI 10.1007/s11263-012-0601-0
   Hemayed EE, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P351, DOI 10.1109/AVSS.2003.1217942
   Holland JH., 1975, Ann Arbor
   Hu ZZ, 2019, MULTIMED TOOLS APPL, V78, P25731, DOI 10.1007/s11042-019-7666-5
   Indelman V., 2012, P BRIT MACH VIS C BM, P3
   Indelman V., 2012, POS LOC NAV S PLANS
   Jiang ZT, 2011, COMM COM INF SC, V86, P452
   Jiang ZT, 2012, J COMPUT, V7, P774, DOI 10.4304/jcp.7.3.774-778
   Le V, 2010, IEEE IMAGE PROC, P4265, DOI 10.1109/ICIP.2010.5651875
   Li Liangfu, 2004, JCS T, V4
   Liu PJ, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P262, DOI 10.1109/CGI.2003.1214479
   Lourakis MIA, 2005, COMPUT VIS IMAGE UND, V99, P259, DOI 10.1016/j.cviu.2005.02.001
   Manolis I.A., 2000, 3911 INRIA
   Meng Xiaoqiao, 2000, NEW EASY CAMERA CALI
   Merras M, 2018, SOFT COMPUT, V22, P6271, DOI 10.1007/s00500-017-2966-z
   Pollefeys M, 1999, INT J COMPUT VISION, V32, P7, DOI 10.1023/A:1008109111715
   Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a
   Ram P., 2016, INT C SIGN PROC COMM
   Rodríguez AL, 2011, PROC CVPR IEEE
   Saaidi A., 2008, WSEAS Transactions on Computers Research, V3, P295
   Saaidi A., 2009, ICGST GVIP, P41
   Satouri B., 2016, INT J ADV COMPUTER S, V7
   Steffen Richard, 2010, TRENDS TOPICS COMPUT, P282
   Sturm P, 2002, IMAGE VISION COMPUT, V20, P415, DOI 10.1016/S0262-8856(02)00012-4
   Sturm P, 2000, IEEE T PATTERN ANAL, V22, P1199, DOI 10.1109/34.879804
   Sun J, 2009, WORLD ACAD SCI ENG T, V60
   Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552
   Triggs, 2000, INT WORKSH VIS ALG
   Triggs B., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P89, DOI 10.1007/BFb0055661
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Triggs B., 2000, INT WORKSH VIS ALG
   Wang GH, 2009, IEEE T CIRC SYST VID, V19, P1793, DOI 10.1109/TCSVT.2009.2031380
   Wiles C., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P238
   Yanliang Shang, 2012, Information Technology Journal, V11, P376, DOI 10.3923/itj.2012.376.379
   Yue Zhao, 2012, Information Technology Journal, V11, P926, DOI 10.3923/itj.2012.926.930
   Zhang W., 2005, GVIP 05 C
   Zhao Y., 2012, Information Technology Journal, V11, P276, DOI 10.3923/itj.2012.276.282
NR 68
TC 1
Z9 1
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29265
EP 29288
DI 10.1007/s11042-020-09097-w
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559640400005
DA 2024-07-18
ER

PT J
AU Bhalarao, R
   Raval, M
AF Bhalarao, Raghavendra
   Raval, Mitesh
TI Automated tabla syllable transcription using image processing techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic transcription; Tabla; Image processing; SURF features; SSIM
AB In this paper, we have proposed an automated tabla syllable transcription method using image processing technique. As for a beginner tabla learner, the learning is faster by visualizing things rather than just listening. Therefore, we have adopted this technique for our study. We have used a human perception based approach for learning tabla and implemented the same. We have created three regions of interest for each drum,dayanandbayan. The placement of the fingers' image feature over this region is tracked to determine the exact region where it strikes and produces a particular syllable. Each frame is initially labeled to a syllable. Finally, we have used supervised classification to prune the labeling for each stroke based on its image for a particular syllable by comparing incoming frames to the reference image using the structural similarity index. Based on this the syllables are classified and automatic transcription is done. Using the proposed method, we are proficiently able to transcript 97.14% of the tabla syllables with F1 score of 0.98.
C1 [Bhalarao, Raghavendra; Raval, Mitesh] Inst Infrastruct Technol Res & Management IITRAM, Dept Elect Engn, Ahmadabad, India.
C3 Institute of Infrastructure, Technology, Research & Management
RP Bhalarao, R (corresponding author), Inst Infrastruct Technol Res & Management IITRAM, Dept Elect Engn, Ahmadabad, India.
EM raghavendra.bhalarao@iitram.ac.in
RI Bhalerao, Raghavendra Hemant/AGK-9064-2022
OI Bhalerao, Raghavendra Hemant/0000-0003-0645-2959
CR Akbari M, 2015, IEEE T MULTIMEDIA, V17, P2113, DOI 10.1109/TMM.2015.2473702
   [Anonymous], 2014, FOUND TRENDS INF RET, V8, P128, DOI 10.1561/1500000042
   [Anonymous], 2018, MULTIMED TOOLS APPL, DOI DOI 10.1007/S11042-018-5803-1
   Bello JP, 2005, IEEE T SPEECH AUDI P, V13, P1035, DOI 10.1109/TSA.2005.851998
   Bello JP, 2003, THESIS
   Benetos E, 2019, IEEE SIGNAL PROC MAG, V36, P20, DOI 10.1109/MSP.2018.2869928
   Benetos E, 2013, J INTELL INF SYST, V41, P407, DOI 10.1007/s10844-013-0258-3
   Beronja S, 2008, ART INDIAN TABLA
   Chordia P, 2005, P ISMIR 2003 4 INT C, P385
   Downie JS, 2003, ANNU REV INFORM SCI, V37, P295, DOI 10.1002/aris.1440370108
   Dressler K., 2012, Music Information Retrieval Evaluation eXchange
   Fan D, ARXIV180306091 CORR
   Frisson C, 2009, MULTIMODAL GUITAR PE
   Fu ZY, 2011, IEEE T MULTIMEDIA, V13, P303, DOI 10.1109/TMM.2010.2098858
   Gillet O, 2005, INT CONF ACOUST SPEE, P205
   Gillet O, 2003, P ISMIR 2003 4 INT C
   Gupta S, 2015, P ISMIR 2015 16 INT
   MAHER RC, 1990, J AUDIO ENG SOC, V38, P956
   Moorer JA, 1977, COMPUT MUSIC J, V3, P32
   Paleari M, 2008, IEEE IMAGE PROC, P93, DOI 10.1109/ICIP.2008.4711699
   Peeling PH, 2011, IEEE J-STSP, V5, P1133, DOI 10.1109/JSTSP.2011.2158804
   Piszczalski M, 1977, COMPUT MUSIC J, V4, P24
   Quenneville D, 2018, THESIS
   Raman C.V., 1934, Proc. Indian Acad. Sci, Vla, P179
   Sarkar R, 2018, ADV INTELL SYST COMP, V666, P139, DOI 10.1007/978-981-10-8180-4_9
   Scaringella N, 2006, IEEE SIGNAL PROC MAG, V23, P133, DOI 10.1109/MSP.2006.1598089
   Suteparuk P, 2014, TECH REP
   Tavares T.F., 2013, J BRAZ COMPUT SOC, V19, P589, DOI DOI 10.1007/S13173-013-0118-6
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang B, 2007, P 15 ACM INT C MULT, P521
NR 31
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28885
EP 28899
DI 10.1007/s11042-020-09417-0
EA AUG 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000557124000001
DA 2024-07-18
ER

PT J
AU Chen, F
   Ren, Y
   Peng, ZJ
   Jiang, GY
   Cui, X
AF Chen, Fen
   Ren, Yan
   Peng, Zongju
   Jiang, Gangyi
   Cui, Xin
TI A fast CU size decision algorithm for VVC intra prediction based on
   support vector machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Versatile video coding; Fast algorithm; Support vector machine; CU
   splitting
ID CODING UNIT DECISION; DEPTH DECISION
AB The latest generation of coding standard, Versatile Video Coding (VVC), has achieved more bitrate reduction compared with high efficiency video coding. However, the introduction of quadtree with nested Multi-Type Tree (MTT) coding structure greatly increases the computational complexity. To reduce the complexity of VVC, a Support Vector Machine (SVM) based Coding Unit (CU) size decision algorithm is presented. Firstly, effective features, derived from entropy, texture contrast, and Haar wavelet efficient of current CU, are select to distinguish the splitting directions. Then, the six SVM classifying models are on-line trained at different CU sizes. Finally, the models are utilized to prediction the direction of CU splitting in the quadtree with nested MTT coding structure. Experimental results show that the proposed algorithm can significantly save the encoding time by 51.01% with slight increase of Bjontegaard delta bit rate.
C1 [Chen, Fen; Peng, Zongju] Chongqing Univ Technol, Sch Elect & Elect Engn, Chongqing 400054, Peoples R China.
   [Ren, Yan; Peng, Zongju; Jiang, Gangyi; Cui, Xin] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
C3 Chongqing University of Technology; Ningbo University
RP Peng, ZJ (corresponding author), Chongqing Univ Technol, Sch Elect & Elect Engn, Chongqing 400054, Peoples R China.; Peng, ZJ (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
EM pengzongju@126.com
RI Chen, Fen/ABG-7013-2021; jiang, gang/KII-8233-2024
FU National Natural Science Foundation of China [61771269, 61620106012,
   61871247]; Natural Science Foundation of Zhejiang Province
   [LY20F010005]; Natural Science Foundation of Ningbo [2018A610052,
   2019A610107]; K. C. Wong Magna Fund in Ningbo University
FX This work was supported by the National Natural Science Foundation of
   China under Grant Nos. 61771269, 61620106012, and 61871247, the Natural
   Science Foundation of Zhejiang Province under No. LY20F010005, the
   Natural Science Foundation of Ningbo under Nos. 2018A610052 and
   2019A610107, and the K. C. Wong Magna Fund in Ningbo University.
CR [Anonymous], 2001, ITU-T SG16/Q6
   [Anonymous], 2017, IEEE T CIRC SYST VID
   [Anonymous], 2016, JVETC0024
   Boyce J., 2018, JVET-J1010: JVET common test conditions and software reference configurations
   Bross B, 2018, JVETJ1001V2
   Chen J., 2015, JEVTA1001
   Chen J, 2015, COM16C806E ITUT SG16
   CHEN Y, 2006, COMBINING SVMS VARIO, P316
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Feng ZQ, 2018, IEEE ACCESS, V6, P45262, DOI 10.1109/ACCESS.2018.2864881
   Fu T, 2019, IEEE INT CON MULTI, P55, DOI 10.1109/ICME.2019.00018
   Grellert M, 2019, IEEE T CIRC SYST VID, V29, P1741, DOI 10.1109/TCSVT.2018.2849941
   Hsu C.-W., 2003, Department of Computer Science and Information Engineering
   Huang C, 2018, IEEE ACCESS, V6, P46643, DOI 10.1109/ACCESS.2018.2866081
   Kim K, 2019, IEEE T CIRC SYST VID, V29, P1462, DOI 10.1109/TCSVT.2018.2839113
   Lee D, 2017, SIGNAL PROCESS-IMAGE, V55, P121, DOI 10.1016/j.image.2017.03.019
   Lin TL, 2020, J REAL-TIME IMAGE PR, V17, P493, DOI 10.1007/s11554-018-0794-8
   Ruiz D, 2017, MULTIMED TOOLS APPL, V76, P861, DOI 10.1007/s11042-015-3014-6
   Ryu S, 2018, IEEE T IMAGE PROCESS, V27, P5525, DOI 10.1109/TIP.2018.2857404
   Shen XL, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-4
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun XB, 2017, IET IMAGE PROCESS, V11, P717, DOI 10.1049/iet-ipr.2016.1082
   Wang Z, 2018, IEEE T IMAGE PROCESS, V27, P1475, DOI 10.1109/TIP.2017.2778564
   Wieckowski A., 2018, JVETJ0095
   Wieckowski A., 2018, JVETI0034
   Xu M, 2018, IEEE T IMAGE PROCESS, V27, P5044, DOI 10.1109/TIP.2018.2847035
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
   Zhang MM, 2019, MULTIMED TOOLS APPL, V78, P1035, DOI 10.1007/s11042-018-6105-3
   Zhang Y, 2015, IEEE T IMAGE PROCESS, V24, P2225, DOI 10.1109/TIP.2015.2417498
   Zhu LW, 2018, IEEE T BROADCAST, V64, P681, DOI 10.1109/TBC.2017.2762470
NR 30
TC 32
Z9 32
U1 3
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27923
EP 27939
DI 10.1007/s11042-020-09401-8
EA JUL 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000559382300006
DA 2024-07-18
ER

PT J
AU Kanrar, S
   Dawar, K
   Pundir, A
AF Kanrar, Soumen
   Dawar, Kanika
   Pundir, Abhishek
TI Pedestrian localisation in the typical indoor environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Localisation; WiFi; RSS; Wireless LAN; Wireless access point; Data
   science
ID POSITIONING SYSTEMS; ACCESS POINT; PERFORMANCE; SELECTION; TRACKING
AB The world is adopting complete wireless infrastructure to cover small size buildings as well as large geographical regions. Indoor Positioning System (IPS) is used to locate stationary as well as non-stationary objects in the wireless domain. The indoor localisation of a pedestrian remains an open problem in the noisy environment. Researchers are trying to develop low-complexity approach without depending on building infrastructure to achieve accurate and reliable results for pedestrian localisation in noisy environment. We are proposed the problem associated with improving localisation scalability and accuracy by considering the noisy environment. Our propose methodology exhibits robustness and portability with respect to the number of experiments in noisy environment with the help of captured signal strength. The propose methodology is easily applied in various indoor environments (i.e. different building designs) to locate the stationary and non-stationary object. The collected multimodal data of non-stationary targets in the noisy environment is required to enhance further. The collected multimodal data is used to explore specific movement of the pedestrian in the noisy environment. We consider numerical methods to make the shape of hot-spot contour for a specific target. Principal Component Analysis (PCA) based data science is used to obtain the predominant components in the collected information and make a compact contour in the noisy environment. The generated model depicts a highly sensitive region in the noisy environment due to the presence of thick walls inside the building and multipath fading. Our novel methodology exhibits efficient localisation of the non-stationary target or precisely identifies the moving object, on the floor of a multi- storey building. Our novel approach enhances the technique to improve surveillance and security for the noisy indoor environment.
C1 [Kanrar, Soumen] DIT Univ, Dept Comp Sci & Engn, Dehra Dun 248009, Uttarakhand, India.
   [Kanrar, Soumen] Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, India.
   [Dawar, Kanika] Airtel Ctr, Phase 4,Sect 18, Gurugram 122008, India.
   [Pundir, Abhishek] GeekyAnts, Bengaluru 560076, Karnataka, India.
C3 DIT University; Vidyasagar University
RP Kanrar, S (corresponding author), DIT Univ, Dept Comp Sci & Engn, Dehra Dun 248009, Uttarakhand, India.; Kanrar, S (corresponding author), Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, India.
EM dr.soumen.kanrar@gmail.com
RI Kanrar, Soumen/N-3113-2019
OI Kanrar, Soumen/0000-0002-0331-4932
CR [Anonymous], 2012, International Conference on Indoor Positioning and Indoor Navigation (IPIN), DOI DOI 10.1109/IPIN.2012.6418880
   [Anonymous], 2003, PORPHYRIN HDB
   [Anonymous], 2006, PROC WORKSHOP POSITI
   Boyd RW, 2011, US patent No, Patent No. [US7899006B2, 7899006B2]
   Brooks T.T., 2005, 1 INT C SENS TECHN, P54
   Catovic A, 2004, IEEE COMMUN LETT, V8, P626, DOI 10.1109/LCOMM.2004.835319
   Correia N., 2005, Proceedings of the 2005 ACM SIGCHI International Conference on Advances in Computer Entertainment Technology ACE '05, P102, DOI DOI 10.1145/1178477.1178491
   Dardari D, 2015, IEEE T VEH TECHNOL, V64, P1263, DOI 10.1109/TVT.2015.2403868
   Dong K, 2017, WIREL COMMUN MOB COM, DOI 10.1155/2017/1268515
   Dou F, 2018, IEEE INT CONF MOB, P166, DOI 10.1109/MASS.2018.00037
   Ekahau Inc, 2005, EK POS ENG 3 1
   FOY WH, 1976, IEEE T AERO ELEC SYS, V12, P187, DOI 10.1109/TAES.1976.308294
   Gezici S, 2005, IEEE SIGNAL PROC MAG, V22, P70, DOI 10.1109/MSP.2005.1458289
   Gezici S, 2008, IEEE ICC, P4203, DOI 10.1109/ICC.2008.789
   Gu YY, 2009, IEEE COMMUN SURV TUT, V11, P13, DOI 10.1109/SURV.2009.090103
   Guerra A, 2018, IEEE T WIREL COMMUN, V17, P5241, DOI 10.1109/TWC.2018.2840136
   Gupta GS, 2005, IEEE T INSTRUM MEAS, V54, P200, DOI 10.1109/TIM.2004.840223
   Guvenc I, 2008, IEEE WCNC, P284, DOI 10.1109/WCNC.2008.55
   He SN, 2016, IEEE COMMUN SURV TUT, V18, P466, DOI 10.1109/COMST.2015.2464084
   Hilsenbeck S, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P147, DOI 10.1145/2632048.2636079
   Huang HL, 2019, J NETW COMPUT APPL, V144, P49, DOI 10.1016/j.jnca.2019.07.002
   Ibach P, 2005, P IADIS INT C COMM, P1, DOI DOI 10.13140/RG.2.1.1133.8001
   Kanrar S., 2014, ADV COMPUTING NETWOR, V2, P461, DOI [10.1007/978-3-319-07350-7_51, DOI 10.1007/978-3-319-07350-7_51]
   Kanrar S, 2012, IEEE P NAT C COMP CO, P1, DOI [10.1109/NCCCS.2012.6412991, DOI 10.1109/NCCCS.2012.6412991]
   Kanrar S, 2016, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INFORMATICS AND ANALYTICS (ICIA' 16), DOI 10.1145/2980258.2980296
   Kanrar S, 2017, MULTIMED TOOLS APPL, V76, P13315, DOI 10.1007/s11042-016-3752-0
   Kanrar S, 2015, ADV INTELL SYST, V339, P21, DOI 10.1007/978-81-322-2250-7_3
   Khoury HM, 2009, AUTOMAT CONSTR, V18, P444, DOI 10.1016/j.autcon.2008.10.011
   Kim H, 2017, IEEE T MOBILE COMPUT, V16, P2366, DOI 10.1109/TMC.2016.2618790
   King Thomas., 2006, Proceedings of the 1st international workshop on Wireless network testbeds, experimental evaluation characterization, P34
   Koo J, 2011, IEEE COMMUN LETT, V15, P187, DOI 10.1109/LCOMM.2011.121410.101379
   Leick A, 2015, GPS SATELLITE SURVEYING, 4TH EDITION, P1, DOI 10.1002/9781119018612
   Li D, 2002, IEEE SIGNAL PROC MAG, V19, P17, DOI 10.1109/79.985674
   Li D, 2017, P IEEE CVPR, P388, DOI [10.1109/CVPR.2017.49, DOI 10.1109/CVPR.2017.49]
   Liao SH, 2012, EXPERT SYST APPL, V39, P11303, DOI 10.1016/j.eswa.2012.02.063
   Lin K, 2013, J NETW COMPUT APPL, V36, P1316, DOI 10.1016/j.jnca.2012.01.001
   Liu H, 2007, IEEE T SYST MAN CY C, V37, P1067, DOI 10.1109/TSMCC.2007.905750
   Liu W, 2012, LECT NOTES COMPUT SC, V7131, P750
   Luo W, 2018, J WIREL COMMUN NETW, V170, P1, DOI [10.1186/s13638-018-1183-5, DOI 10.1186/S13638-018-1183-5]
   Meng Z, 2020, ASS ADV ARTIFICIAL I, P1
   Parker R, 2007, IEEE T VEH TECHNOL, V56, P3371, DOI 10.1109/TVT.2007.907687
   Qian Jiuchao., 2013, IEEE International Conference on Indoor Positioning and Indoor Navigation IPIN, P1
   Ramnath S., P 2017 INT C IOT APP, P1, DOI [10.1109/ICIOTA.2017.8073629, DOI 10.1109/ICIOTA.2017.8073629]
   Randell Cliff., 2001, UBICOMP 2001 UBIQUIT, P42, DOI 10.1007/3-540-45427-6_5.
   Rodriguez LJ, 2016, US, Patent No. [20160330591 A1, 20160330591A1]
   Saha S, 2003, IEEE WCNC, P1987
   Shi GW, 2016, LECT NOTES ELECTR EN, V348, P1269, DOI 10.1007/978-81-322-2580-5_115
   So HC, 2008, IEEE T SIGNAL PROCES, V56, P2614, DOI 10.1109/TSP.2007.914342
   Suining He, 2015, 2015 IEEE Conference on Computer Communications (INFOCOM). Proceedings, P2506, DOI 10.1109/INFOCOM.2015.7218640
   Sun W, 2018, IEEE T VEH TECHNOL, V67, P10896, DOI 10.1109/TVT.2018.2870160
   Sung K, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061722
   Tian ZS, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-65
   Velastin SA, 2004, J NETW COMPUT APPL, V27, P221, DOI 10.1016/j.jnca.2003.11.001
   Wang S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC), P1, DOI 10.1109/INTMAG.2015.7156812
   WANT R, 1992, IEEE T CONSUM ELECTR, V38, P10, DOI 10.1109/30.125076
   WANT R, 1992, ACM T INFORM SYST, V10, P91, DOI 10.1145/128756.128759
   Woodman O, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P114, DOI 10.1145/1409635.1409651
   Yiu SM, 2017, SIGNAL PROCESS, V131, P235, DOI 10.1016/j.sigpro.2016.07.005
   Yu J, 2012, I NAVIG SAT DIV INT, P960
   Zhang W, 2016, NEUROCOMPUTING, V194, P279, DOI 10.1016/j.neucom.2016.02.055
   Zheng H, 2018, IEEE ANTENN WIREL PR, V17, P1359, DOI 10.1109/LAWP.2018.2846748
NR 61
TC 3
Z9 4
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27833
EP 27866
DI 10.1007/s11042-020-09291-w
EA JUL 2020
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000559382300007
DA 2024-07-18
ER

PT J
AU George, M
   Jose, BR
   Mathew, J
AF George, Michael
   Jose, Babita Roslind
   Mathew, Jimson
TI Abnormal activity detection using shear transformed spatio-temporal
   regions at the surveillance network edge
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Events; Actions and activity recognition; Internet of things; Video
   surveillance architectures; Image/video surveillance and analytics
ID ANOMALY DETECTION; EVENT DETECTION; SYSTEMS; RECOGNITION; BEHAVIOR
AB This paper presents a method of detecting abnormal activity in crowd videos while considering the direction of the dominant crowd motion. One main goal of our approach is to be able to run at the edge of the surveillance network close to the surveillance cameras so as to reduce network congestion and decision latency. To capture motion features while considering the direction of dominant crowd direction we propose a generalised shear transform based spatio-temporal region. To detect abnormal activity, an autoencoder based method is adopted considering the requirement for running the method at the network edge. During training, the autoencoder learns motion features for each spatio-temporal region from video frames containing normal activity. While testing, those motion features from each spatio-temporal region that cannot be reconstructed satisfactorily by the autoencoder indicate abnormal activity. This approach allows coarse localisation as well as detection of abnormal activity. The approach demonstrated O(n) behaviour with ability to work at higher frame rates by trading off accuracy. The approach has been verified against recent works on standard abnormal activity datasets: UCSD dataset and Subway dataset.
C1 [George, Michael; Jose, Babita Roslind] Cochin Univ Sci & Technol, Sch Engn, Kochi 682022, Kerala, India.
   [Mathew, Jimson] Indian Inst Technol Patna, Dept Comp Sci & Engn, Patna 801103, Bihar, India.
C3 Cochin University Science & Technology; Indian Institute of Technology
   System (IIT System); Indian Institute of Technology (IIT) - Patna
RP George, M (corresponding author), Cochin Univ Sci & Technol, Sch Engn, Kochi 682022, Kerala, India.
EM michaelgeorge2010@gmail.com; babitajose@cusat.ac.in; jimson@iitp.ac.in
OI George, Michael/0000-0001-7917-8634
FU Technical Education Quality Improvement Programme (TEQIP) Research Seed
   Money Project [TEQIP/PTRA/2017]; APJ Abdul Kalam Technological
   University - Center for Engineering Research & Development
   (APJAKTU-CERD) Research Seed Money Project [KTU/RESEARCH 2/4068/2019]
FX This work was supported by Technical Education Quality Improvement
   Programme (TEQIP) Research Seed Money Project (No. TEQIP/PTRA/2017); APJ
   Abdul Kalam Technological University - Center for Engineering Research &
   Development (APJAKTU-CERD) Research Seed Money Project (No. KTU/RESEARCH
   2/4068/2019).
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Afiq AA, 2019, J VIS COMMUN IMAGE R, V58, P285, DOI 10.1016/j.jvcir.2018.11.035
   [Anonymous], 2018, Cisco Visual Networking Index: Forecast and Trends, 2017-2022
   [Anonymous], 2017, INT J MACH LEARN CYB
   [Anonymous], 2020, Cisco annual Internet report (2018-2023) white paper
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Biswas S, 2017, NEUROCOMPUTING, V242, P63, DOI 10.1016/j.neucom.2017.02.058
   Bouguet J-Y, 1999, Pyramidal implementation of the Lucas Kanade feature tracker
   Bouindour S, 2019, 2019 IEEE SECOND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE), P172, DOI 10.1109/AIKE.2019.00039
   Chalapathy Raghavendra, 2019, ARXIV190103407
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Chen N, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SMART CLOUD (SMARTCLOUD), P109, DOI 10.1109/SmartCloud.2017.24
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Cicirelli F, 2018, IEEE INTERNET THINGS, V5, P2557, DOI 10.1109/JIOT.2017.2775739
   Colque RM, 2018, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2018), VOL 5: VISAPP, P293, DOI 10.5220/0006615202930300
   Fan Y., 2018, arXiv:1805.11223
   George M, 2019, IET COMPUT VIS, V13, P23, DOI 10.1049/iet-cvi.2018.5240
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   He YB, 2019, J PHYS CONF SER, V1215, DOI 10.1088/1742-6596/1215/1/012042
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu X, 2019, IEEE T INF FOREN SEC, V14, P1007, DOI 10.1109/TIFS.2018.2868617
   Colque RVHM, 2017, IEEE T CIRC SYST VID, V27, P673, DOI 10.1109/TCSVT.2016.2637778
   Colque RVHM, 2015, SIBGRAPI, P126, DOI 10.1109/SIBGRAPI.2015.21
   Khan MUK, 2019, IEEE T INF FOREN SEC, V14, P541, DOI 10.1109/TIFS.2018.2856189
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Lea C, 2017, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2017.113
   Lei Z, 2019, PROCEEDINGS OF 2019 INTERNATIONAL CONFERENCE ON IMAGE, VIDEO AND SIGNAL PROCESSING (IVSP 2019), P1, DOI 10.1145/3317640.3317644
   Leyva R, 2017, IEEE T IMAGE PROCESS, V26, P3463, DOI 10.1109/TIP.2017.2695105
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Liu P, 2017, NEUROCOMPUTING, V269, P3, DOI 10.1016/j.neucom.2016.09.138
   Lloyd K, 2017, MACH VISION APPL, V28, P361, DOI 10.1007/s00138-017-0830-x
   Lu CY, 2018, IEEE T PATTERN ANAL, V40, P527, DOI 10.1109/TPAMI.2017.2689021
   MAHADEVAN V, 2010, PROC CVPR IEEE, P1975, DOI DOI 10.1109/CVPR.2010.5539872
   Miraftabzadeh SA, 2018, IEEE INTERNET THINGS, V5, P2936, DOI 10.1109/JIOT.2017.2761801
   Nikouei SY, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING (IEEE EDGE), P125, DOI 10.1109/EDGE.2018.00025
   Nikouei Seyed Yahya, 2018, ARXIV180500331
   Quigley PA, 2019, CLIN GERIATR MED, V35, P253, DOI 10.1016/j.cger.2019.01.005
   Ravanbakhsh M, 2018, IEEE WINT CONF APPL, P1689, DOI 10.1109/WACV.2018.00188
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Shi WS, 2016, IEEE INTERNET THINGS, V3, P637, DOI 10.1109/JIOT.2016.2579198
   Shi XS, 2015, 2015 IEEE ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P802, DOI 10.1109/IAEAC.2015.7428667
   Sun JY, 2018, IEEE ACCESS, V6, P33353, DOI 10.1109/ACCESS.2018.2848210
   Sutskever I, 2014, ADV NEUR IN, V27
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tsakanikas V, 2018, COMPUT ELECTR ENG, V70, P736, DOI 10.1016/j.compeleceng.2017.11.011
   Usman M, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3323334
   Wang J, 2016, COMPUT VIS IMAGE UND, V144, P177, DOI 10.1016/j.cviu.2015.08.010
   Wang J, 2017, IEEE WINT CONF APPL, P168, DOI 10.1109/WACV.2017.26
   Wang L, 2018, IEEE IMAGE PROC, P2276, DOI 10.1109/ICIP.2018.8451070
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   Xu RK, 2018, INT J ADV ROBOT SYST, V15, DOI 10.1177/1729881417750759
   Yang B, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/2087574
   Yuan Y, 2017, IEEE T CYBERNETICS, V47, P3597, DOI 10.1109/TCYB.2016.2572609
   Yuan Y, 2018, PATTERN RECOGN, V73, P99, DOI 10.1016/j.patcog.2017.08.001
   Zhang T, 2015, MOBICOM '15: PROCEEDINGS OF THE 21ST ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P426, DOI 10.1145/2789168.2790123
   Zhou FQ, 2020, NEURAL PROCESS LETT, V52, P961, DOI 10.1007/s11063-019-10113-w
   Zitouni MS, 2019, ENG APPL ARTIF INTEL, V82, P294, DOI 10.1016/j.engappai.2019.04.012
NR 57
TC 8
Z9 8
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27511
EP 27532
DI 10.1007/s11042-020-09277-8
EA JUL 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000552512900001
DA 2024-07-18
ER

PT J
AU Bhunia, AK
   Roy, PP
   Sain, A
   Pal, U
AF Bhunia, Ayan Kumar
   Roy, Partha Pratim
   Sain, Aneeshan
   Pal, Umapada
TI Zone-based keyword spotting in Bangla and Devanagari documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Word spotting; Handwritten text recognition; Knowledge extraction;
   Hidden Markov model
ID WORD RECOGNITION; ALGORITHM
AB In this paper, we present a word spotting system in text lines for offline Indic scripts such as Bangla (Bengali) and Devanagari. Recently, it was shown that the zone-wise recognition method improves word recognition performance than the conventional full word recognition system in Indic scripts, like Bangla, Devanagari, Gurumukhi (Roy et al. in Pattern Recogn 60: 1057-1075,26; Bhunia et al. in Pattern Recogn 79: 12-31,6). Inspired from this idea we consider the zone segmentation approach and use middle zone information to improve the traditional word spotting performance. To avoid the problem of zone segmentation using heuristic approach, we propose here a new HMM based approach to segment the upper and lower zone components from the text line images. The candidate keywords are searched from a line without segmenting characters or words. Also, we propose a feature combining foreground and background information of text line images for keyword-spotting by character filler models. A significant improvement in performance is noted by using both foreground and background information instead of the individual one. Pyramid Histogram of Oriented Gradient (PHOG) feature has been used in our word spotting framework. From the experiment, it has been noted that the proposed zone-segmentation based system outperforms traditional approaches of word spotting.
C1 [Bhunia, Ayan Kumar] Inst Engn & Management, Dept ECE, Kolkata, India.
   [Roy, Partha Pratim] Indian Inst Technol Roorkee, Dept CSE, Roorkee, Uttarakhand, India.
   [Sain, Aneeshan] Inst Engn & Management, Dept EE, Kolkata, India.
   [Pal, Umapada] Indian Stat Inst, CVPR Unit, Kolkata, India.
C3 Institute of Engineering & Management (IEM), Kolkata; Indian Institute
   of Technology System (IIT System); Indian Institute of Technology (IIT)
   - Roorkee; Institute of Engineering & Management (IEM), Kolkata; Indian
   Statistical Institute; Indian Statistical Institute Kolkata
RP Bhunia, AK (corresponding author), Inst Engn & Management, Dept ECE, Kolkata, India.
EM ayanbhunia007@gmail.com
RI Pal, Umapada/AAC-4930-2022; Roy, Partha Pratim/AAW-2994-2020; Sain,
   Aneeshan/JFJ-7046-2023
OI Roy, Partha Pratim/0000-0002-5735-5254; Sain,
   Aneeshan/0000-0001-7789-3060
CR Ahmed R., 2016, P IEEE 83 VEH TECHN, P1
   Almazán J, 2014, IEEE T PATTERN ANAL, V36, P2552, DOI 10.1109/TPAMI.2014.2339814
   Antonacopoulos A, 2007, INT J DOC ANAL RECOG, V9, P75, DOI 10.1007/s10032-007-0045-1
   Bai Y, 2009, IEEE IMAGE PROC, P3305, DOI 10.1109/ICIP.2009.5413938
   Bhunia AK, 2019, IEEE C COMP VIS PATT
   Bhunia AK, 2018, PATTERN RECOGN, V79, P12, DOI 10.1016/j.patcog.2018.01.034
   Bhunia AK, 2015, PROC INT CONF DOC, P636, DOI 10.1109/ICDAR.2015.7333839
   Chaudhuri BB, 1998, PATTERN RECOGN, V31, P531, DOI 10.1016/S0031-3203(97)00078-2
   Das A, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P426, DOI 10.1109/ACPR.2015.7486539
   Dutta K, 2018, INT CONF FRONT HAND, P32, DOI 10.1109/ICFHR-2018.2018.00015
   Fischer A, 2012, PATTERN RECOGN LETT, V33, P934, DOI 10.1016/j.patrec.2011.09.009
   Frinken V, 2012, IEEE T PATTERN ANAL, V34, P211, DOI 10.1109/TPAMI.2011.113
   Jayadevan R, 2012, INT J DOC ANAL RECOG, V15, P267, DOI 10.1007/s10032-011-0170-8
   Kavallieratou E, 2001, PATTERN RECOGN, V34, P2515, DOI 10.1016/S0031-3203(00)00153-9
   Leydier Y, 2009, PATTERN RECOGN, V42, P2089, DOI 10.1016/j.patcog.2009.01.026
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nagy G, 2006, SECOND INTERNATIONAL CONFERENCE ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P2, DOI 10.1109/DIAL.2006.25
   Niyogi D, 1997, HDB CHARACTER RECOGN, P485
   Roy PP, 2012, INT J DOC ANAL RECOG, V15, P227, DOI 10.1007/s10032-011-0167-3
   Rath TM, 2007, INT J DOC ANAL RECOG, V9, P139, DOI 10.1007/s10032-006-0027-8
   Rodríguez-Serrano JA, 2009, PATTERN RECOGN, V42, P2106, DOI 10.1016/j.patcog.2009.02.005
   Rothacker L, 2017, PROC INT CONF DOC, P1174, DOI 10.1109/ICDAR.2017.194
   Rothfeder J.L., 2003, P C COMPUTER VISION, P30
   Roy P.P., 2008, Proceedings of the International Conference in Frontiers in Handwritten Recognition (ICFHR-08), August 19-21, 2008, Canada, P241
   Roy PP, 2016, PATTERN RECOGN, V60, P1057, DOI 10.1016/j.patcog.2016.04.012
   Roy PP, 2015, IMAGE VISION COMPUT, V44, P15, DOI 10.1016/j.imavis.2015.09.006
   Roy PP, 2018, MULTIMED TOOLS APPL, P1
   Rusiñol M, 2011, PROC INT CONF DOC, P63, DOI 10.1109/ICDAR.2011.22
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Srihari S, 2005, P SOC PHOTO-OPT INS, V5676, P66, DOI 10.1117/12.585883
   Srihari SN, 1997, PROC INT CONF DOC, P892, DOI 10.1109/ICDAR.1997.620640
   Sudholt S, 2017, PROC INT CONF DOC, P493, DOI 10.1109/ICDAR.2017.87
   Sudholt S, 2016, INT CONF FRONT HAND, P277, DOI [10.1109/ICFHR.2016.0060, 10.1109/ICFHR.2016.55]
   Tarafdar Arundhati, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1989, DOI 10.1109/ICPR.2010.490
   Wijitha Senadeera Wijitha Senadeera, 2006, International Journal of Food Engineering, V2, P7
   Wshah S, 2014, PATTERN RECOGN, V47, P1039, DOI 10.1016/j.patcog.2013.09.019
   Zhang X, 2014, INT CONF FRONT HAND, P381, DOI 10.1109/ICFHR.2014.70
NR 37
TC 5
Z9 5
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27365
EP 27389
DI 10.1007/s11042-019-08442-y
EA JUL 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000552190000005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ozcan, T
   Basturk, A
AF Ozcan, Tayyip
   Basturk, Alper
TI Static facial expression recognition using convolutional neural networks
   based on transfer learning and hyperparameter optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ERUFER dataset; Static facial expression recognition; Emotion analysis;
   Deep learning; Image processing; Hyperparameter optimization
ID CLASSIFIERS; ALGORITHM; FUSION
AB Expression recognition (ER), which has been frequently used in human-computer interaction, uses visual data such as video and static images or sensor-based data for recognizing. Facial expression recognition (FER) is a visual data based ER. Since videos have sequential images, it can be easier to recognize emotion in video signals rather than static images which consist of a single plain image. Therefore, FER on static images is a relatively tough task. Recently, deep learning methods have introduced increased success in classification problems. Accordingly, these methods are also used for FER in the literature. Data preparation and hyperparameter optimization can be utilized to increase the success of deep learning methods. With the preparation of data, the features become more pronounced. Increasing the number of training samples directly also generally affects the success rate. Tuning the hyperparameters of deep learning is another factor that increases the performance of the models. In this study, a classification method including data preparation, hyperparameter optimization, and a transfer learning aided convolutional neural network is proposed. Through the study, a new dataset, named ERUFER, was created by using static images. The newly introduced dataset ERUFER and a popular public dataset JAFFE were classified by the proposed method. To the extent of our knowledge, the best result in the literature is achieved by the proposed method for the JAFFE dataset using a 10-fold cross-validation test technique. On the other hand, a success rate with 92.56 % is achieved for the ERUFER dataset.
C1 [Ozcan, Tayyip; Basturk, Alper] Erciyes Univ, Dept Comp Engn, TR-38039 Kayseri, Turkey.
C3 Erciyes University
RP Ozcan, T (corresponding author), Erciyes Univ, Dept Comp Engn, TR-38039 Kayseri, Turkey.
EM tozcan@erciyes.edu.tr; ab@erciyes.edu.tr
RI Basturk, Alper/A-8953-2012; Özcan, Tayyip/JCO-5020-2023; Ozcan,
   Tayyip/ABG-4306-2020
OI Basturk, Alper/0000-0001-5810-0643; Özcan, Tayyip/0000-0001-7414-7425;
   Ozcan, Tayyip/0000-0002-3111-5260
CR Abramowitz Joel, 2007, P1
   Aghamaleki JA, 2019, MULTIMED TOOLS APPL, V78, P22861, DOI 10.1007/s11042-019-7530-7
   Alghamdi A, 2024, MULTIMED TOOLS APPL, V83, P14913, DOI 10.1007/s11042-020-08769-x
   Alghamdi AS, 2020, APPL ACOUST, V164, DOI 10.1016/j.apacoust.2020.107279
   [Anonymous], 2015, 2015 International Joint Conference on Neural Networks (IJCNN)
   [Anonymous], 2014, PROCEDIA IEEE COMPUT, DOI DOI 10.1109/CVPR.2014.233
   [Anonymous], ARXIV171003144
   [Anonymous], CONV NEUR NETW
   [Anonymous], 2010, Tech. Rep
   [Anonymous], 2016, ARXIV160906591
   [Anonymous], 2018, OMER HALISDEMIR U MU
   [Anonymous], ARXIV151002969
   Araújo T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177544
   Badem H, 2018, APPL SOFT COMPUT, V70, P826, DOI 10.1016/j.asoc.2018.06.010
   Badem H, 2017, NEUROCOMPUTING, V266, P506, DOI 10.1016/j.neucom.2017.05.061
   Basturk A, 2018, 2018 26 SIGN PROC CO, P1, DOI [10.1109/SIU.2018.8404577, DOI 10.1109/SIU.2018.8404577]
   Caliskan A, 2018, ENG APPL ARTIF INTEL, V67, P14, DOI 10.1016/j.engappai.2017.09.002
   Caliskan Abdullah., 2017, IU-J. Electr. Electron. Eng., V17, P3311
   Chang TY, 2019, APPL INTELL, V49, P4319, DOI 10.1007/s10489-019-01491-8
   Devries T, 2014, 2014 CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P98, DOI 10.1109/CRV.2014.21
   Dhall A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Dong YQ, 2018, ENERGIES, V11, DOI 10.3390/en11041009
   Gogic I, 2020, VISUAL COMPUT, V36, P97, DOI 10.1007/s00371-018-1585-8
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Guo YN, 2016, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2016.7574736
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hong WC, 2019, APPL MATH MODEL, V72, P425, DOI 10.1016/j.apm.2019.03.031
   Hong WC, 2011, ENERGIES, V4, P960, DOI 10.3390/en4060960
   Jiang MY, 2018, NEURAL COMPUT APPL, V29, P61, DOI 10.1007/s00521-016-2401-x
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kim BK, 2016, IEEE COMPUT SOC CONF, P1499, DOI 10.1109/CVPRW.2016.187
   Kim BK, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P427, DOI 10.1145/2818346.2830590
   Kim TH, 2018, ELECTRON LETT, V54, P1326, DOI 10.1049/el.2018.6932
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kundra H., 2015, RES J INF TECHNOL, V7, P58, DOI DOI 10.3923/RJIT.2015.58.69
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Li DY, 2019, APPL INTELL, V49, P3188, DOI 10.1007/s10489-019-01435-2
   Li Shan, 2018, arXiv:1804.08348
   Lundqvist D., 1998, The Karolinska Directed Emotional Faces-KDEF
   Luo Y, 2019, OPTOELECTRON LETT, V15, P224, DOI 10.1007/s11801-019-8136-z
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Mathworks, DOCUMENTATION
   MATSUMOTO D, 1992, MOTIV EMOTION, V16, P363, DOI 10.1007/BF00992972
   Meng ZB, 2017, IEEE INT CONF AUTOMA, P558, DOI 10.1109/FG.2017.140
   Moeini A, 2017, J VIS COMMUN IMAGE R, V45, P20, DOI 10.1016/j.jvcir.2017.02.007
   Ng A, 2018, Machine Learning Yearning
   Ondrúska P, 2016, AAAI CONF ARTIF INTE, P3361
   Ozcan T, 2020, CLUSTER COMPUT, P1
   Ozcan T., 2019, BALK J ELECT COMPUT, V7, P195
   Özcan T, 2019, SIG PROCESS COMMUN, DOI 10.1109/siu.2019.8806408
   Ozcan T, 2019, NEURAL COMPUT APPL, V31, P8955, DOI 10.1007/s00521-019-04427-y
   Poursaberi A, 2012, EURASIP J IMAGE VIDE, P1, DOI 10.1186/1687-5281-2012-17
   Pramerdorfer C, 2016, ARXIV
   Saeed F, 2020, MULTIMED TOOLS APPL, V79, P9083, DOI 10.1007/s11042-019-07785-w
   Schmidt EM, 2011, 2011 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS (WASPAA), P65, DOI 10.1109/ASPAA.2011.6082328
   Sekaran K, 2020, MULTIMED TOOLS APPL, V79, P10233, DOI 10.1007/s11042-019-7419-5
   Sun WY, 2019, NEUROCOMPUTING, V337, P203, DOI 10.1016/j.neucom.2019.01.068
   Tang Y., 2013, DEEP LEARNING USING
   Ngo TA, 2013, IEEE IMAGE PROC, P695, DOI 10.1109/ICIP.2013.6738143
   Venkata S. Avula, 2017, 2017 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2017.8008023
   Wang N., 2013, Journal of University Teaching Learning Practice, V9, P1
   Wang N, 2014, MULTIMED TOOLS APPL, V72, P2339, DOI 10.1007/s11042-013-1551-4
   Wang N, 2013, 2013 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES (ISBAST), P217, DOI 10.1109/ISBAST.2013.38
   Yu ZD, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P435
   Yuksel ME, 2018, J INTELL FUZZY SYST, V34, P2273, DOI 10.3233/JIFS-171307
   Zavaschi THH, 2013, EXPERT SYST APPL, V40, P646, DOI 10.1016/j.eswa.2012.07.074
   Zhang Z, 2015, ARXIV150903936
   Zhang ZC, 2020, IEEE ACCESS, V8, P14642, DOI 10.1109/ACCESS.2020.2966712
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
NR 70
TC 12
Z9 12
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26587
EP 26604
DI 10.1007/s11042-020-09268-9
EA JUL 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000549703700002
DA 2024-07-18
ER

PT J
AU Lu, X
   Yu, C
   Martin, GR
AF Lu, Xin
   Yu, Chang
   Martin, Graham R.
TI Fast intra- and inter-coding algorithms for the spatially scalable
   extension of H.265/HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scalable HEVC (SHVC); Scalable video coding (SVC); Fast intra-coding;
   Fast inter-coding; Rate-distortion (RD)
ID CU SIZE DECISION; FAST MODE; PREDICTION; QUALITY; SCHEME
AB High Efficiency Video Coding (HEVC) is the latest international video coding standard. As an extension of HEVC, scalable HEVC (SHVC) achieves high compression efficiency at the cost of dramatically increased computational complexity. In this paper, a fast Coding Unit (CU) size decision algorithm is suggested for spatial SHVC intra-coding to early terminate the CU size decision process by jointly utilising the inter-layer and spatiotemporal correlations. Furthermore, in order to realise a fast Prediction Unit (PU) intra-mode decision, the mode dependency between the Base Layer (BL) and the Enhancement Layer (EL) is effectively used to remove unlikely coding modes. A fast PU inter-mode decision method is also developed for spatial SHVC inter-coding, in which the degree of motion activity and the PU mode dependency are exploited. Simulation results show that the proposed fast intra-coding algorithm produces a saving in encoding time of up to 72% and the proposed fast inter-coding scheme reduces the encoding time by up to 50% compared with the original SHVC encoder, and the loss in Rate-Distortion (RD) performance is negligible.
C1 [Lu, Xin] Harbin Inst Technol, Harbin, Peoples R China.
   [Yu, Chang] HiSilicon Technol Co Ltd, Beijing, Peoples R China.
   [Martin, Graham R.] Univ Warwick, Coventry, W Midlands, England.
C3 Harbin Institute of Technology; University of Warwick
RP Lu, X (corresponding author), Harbin Inst Technol, Harbin, Peoples R China.
EM xin@hit.edu.cn
OI Lu, Xin/0000-0001-6470-8022
FU National Natural Science Foundation of China (NSFC) [61401123];
   Fundamental Research Funds for the Central Universities
   [HIT.NSRIF.201617]; Harbin Science and Technology Bureau [2014RFQXJ166]
FX This work has been supported by the National Natural Science Foundation
   of China (NSFC) under project No. 61401123, the Fundamental Research
   Funds for the Central Universities under project No. HIT.NSRIF.201617,
   and the Harbin Science and Technology Bureau under project No.
   2014RFQXJ166.
CR [Anonymous], 2018, BIOGEOSCIENCES DISCU
   Bailleul R, 2014, I SYMP CONSUM ELECTR, P195
   Bjfntegaard G, 2001, 13 VCEG M AUST US
   Chang Y, 2016, INT J COMPUT CONSUM, V5, P50
   Francois E, 2013, 13 JCT VC M INCH S K
   Ge QY, 2014, PROCEEDINGS OF 2014 IEEE WORKSHOP ON ADVANCED RESEARCH AND TECHNOLOGY IN INDUSTRY APPLICATIONS (WARTIA), P1366, DOI 10.1109/WARTIA.2014.6976537
   Heindel A, 2017, IEEE T CIRC SYST VID, V27, P1749, DOI 10.1109/TCSVT.2016.2556338
   HoangVan X, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P15, DOI 10.1109/PCS.2015.7170038
   JCT-VC of ITU-T VCEG and ISO/IEC MPEG, 2013, ITU T REC H 265 ISO
   Katayama Takafumi, 2016, 2016 IEEE International Conference on Consumer Electronics (ICCE), P419, DOI 10.1109/ICCE.2016.7430673
   Katayama T, 2017, IEICE T FUND ELECTR, VE100A, P2936, DOI 10.1587/transfun.E100.A.2936
   Katayama T, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P3079, DOI 10.1109/TENCON.2016.7848614
   Lasserre S, 2014, IEEE T CIRC SYST VID, V24, P1375, DOI 10.1109/TCSVT.2014.2305513
   Li XN, 2017, MULTIMED TOOLS APPL, V76, P8011, DOI 10.1007/s11042-016-3460-9
   Lu XQ, 2017, IEEE T CYBERNETICS, V47, P884, DOI 10.1109/TCYB.2016.2531179
   Lu X, 2018, ELECTRON LETT, V54, P1274, DOI 10.1049/el.2018.5451
   Lu X, 2013, IEEE T CIRC SYST VID, V23, P846, DOI 10.1109/TCSVT.2012.2226525
   Min B, 2015, IEEE T CIRC SYST VID, V25, P892, DOI 10.1109/TCSVT.2014.2363739
   Piao Y, 2010, 3 JCT VC M GUANGZH C
   Seregin V., 2014, JCTVCQ1009
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tohidypour H, 2013, 12 JCT VC M GEN SWIT
   Tohidypour HR, 2017, IEEE T CIRC SYST VID, V27, P2204, DOI 10.1109/TCSVT.2016.2576738
   Tohidypour HR, 2016, IEEE T BROADCAST, V62, P664, DOI 10.1109/TBC.2016.2576600
   Tohidypour HR, 2016, IEEE T MULTIMEDIA, V18, P182, DOI 10.1109/TMM.2015.2510332
   Wali I, 2019, SIGNAL IMAGE VIDEO P, V13, P145, DOI 10.1007/s11760-018-1339-0
   Wang CC, 2016, RECENT ADVANCES IN IMAGE AND VIDEO CODING, P247, DOI 10.5772/64847
   Wang DY, 2019, IEEE T IMAGE PROCESS, V28, P2063, DOI 10.1109/TIP.2017.2740161
   Wang DY, 2014, LECT NOTES COMPUT SC, V8588, P693, DOI 10.1007/978-3-319-09333-8_75
   Wei-Ju Chiang, 2017, 2017 IEEE International Conference on Multimedia and Expo: Workshops (ICMEW), P381, DOI 10.1109/ICMEW.2017.8026217
   HongVan X, 2016, INT CONF ACOUST SPEE, P1145
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P1714, DOI 10.1109/TCSVT.2016.2556518
   Zhu GJ, 2016, 2016 IEEE 12TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA), P50, DOI 10.1109/CSPA.2016.7515802
   Zuo XG, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P394, DOI 10.1109/VCIP.2014.7051589
NR 35
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26447
EP 26465
DI 10.1007/s11042-020-09085-0
EA JUL 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000549313700002
DA 2024-07-18
ER

PT J
AU Zhou, J
   Wang, TJ
AF Zhou, Jing
   Wang, Tianjiang
TI FER based on the improved convex nonnegative matrix factorization
   feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Feature extraction; Improved convex
   non-negative matrix factorization; Novel objective function; Improved
   iterative step sizes
ID FACIAL EXPRESSION RECOGNITION
AB Facial expression recognition is an important research issue in the pattern recognition field. In this paper, we intend to present an accurate facial expression recognition (FER) system, which employs an improved convex non-negative matrix factorization (ICNMF) method based on a novel objective function and smaller iterative step sizes for feature extraction. Since negative values appearing in the facial expression feature will weaken the features and reduce the recognition rate, the nonnegative matrix factorization (NMF) methods are adopted to guarantee the non-negativity of the extracted feature value to improve the recognition rate. To enhance the performance of NMF method for FER, the ICNMF approach based on a novel convergent objective function and smaller iterative step sizes is proposed, and the FER rate can be improved effectively. In the FER system, the face region is detected firstly, and is enhanced by histogram specification, secondly the ICNMF approach is adopted to extract features and then the feature coefficient matrix is achieved. Finally, the SVM classifier is applied to recognize the extracted features. To validate the effectiveness of FER system, four public available datasets of MultiPIE, CK+, FER2013 and SFEW are tested and then high recognition rates can be achieved based on ICNMF method. In addition, the proposed ICNMF approach is compared with the methods of multi-layer NMF, sparse non-negative matrix factorization (SNMF), the traditional convex non-negative matrix factorization (CNMF), deep belief networks (DBN) and stacked auto-encoder (SAE), and results of experiments show that the proposed ICNMF approach is significantly effective contrasting to the other five expression extraction methods.
C1 [Zhou, Jing] Jianghan Univ, Sch Math & Comp Sci, Wuhan 430056, Hubei, Peoples R China.
   [Wang, Tianjiang] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
C3 Jianghan University; Huazhong University of Science & Technology
RP Zhou, J (corresponding author), Jianghan Univ, Sch Math & Comp Sci, Wuhan 430056, Hubei, Peoples R China.
EM zhj131@jhun.edu.cn
FU 13th five year plan for education science of Wuhan in 2017 [2017A073]
FX This paper is sponsored by key research funding of the 13th five year
   plan for education science of Wuhan in 2017(2017A073).
CR Ahsan T, 2013, IETE TECH REV, V30, P47, DOI 10.4103/0256-4602.107339
   [Anonymous], 2018, INT J COMPUTATIONAL, DOI DOI 10.1504/IJCVR.2018.091980
   Arlot S, 2010, STAT SURV, V4, P40, DOI 10.1214/09-SS054
   Bejaoui H, 2019, MULTIMED TOOLS APPL, V78, P22773, DOI 10.1007/s11042-019-7632-2
   Bhowmik MK, 2019, EXPERT SYST APPL, V116, P96, DOI 10.1016/j.eswa.2018.08.047
   Binte Ali Humayra, 2015, International Journal of Machine Learning and Computing, V5, P142, DOI 10.7763/IJMLC.2015.V5.498
   Ding Chris H.Q., 2008, IEEE transactions on pattern analysis and machine intelligence, V32, P45, DOI DOI 10.1109/TPAMI.2008.277
   Gong J, 2018, PHYS MEDICA, V46, P124, DOI 10.1016/j.ejmp.2018.01.019
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Issas S, 2019, J INF ASSUR SECUR, V14, P20
   Jun Zhou, 2016, Pattern Recognition and Image Analysis, V26, P119, DOI 10.1134/S1054661815040070
   Khan RA, 2019, FRONT COMPUT SCI-CHI, V13, P183, DOI 10.1007/s11704-017-6114-9
   Kumar S., 2015, P NATL C CLOUD COMPU, P4
   Lai SZ, 2014, THESIS, P17
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2015, ADV NEURAL INF PROCE, V13, P556
   Fernandez PDM, 2019, IEEE COMPUT SOC CONF, P837, DOI 10.1109/CVPRW.2019.00112
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Nigam S., 2019, Security in Smart Cities: Models, Applications, and Challenges, P297
   Patil B., 2016, P 5 INT C SOFT COMP, P965, DOI DOI 10.1007/978-981-10-0448-3-81
   Rezaei M, 2019, J AI DATA MINING, V7, P17
   Sajjad M, 2019, INFORM SCIENCES, V479, P416, DOI 10.1016/j.ins.2018.07.027
   Siddiqi MH, 2015, IEEE T IMAGE PROCESS, V24, P1386, DOI 10.1109/TIP.2015.2405346
   Song HA, 2015, NEUROCOMPUTING, V165, P63, DOI 10.1016/j.neucom.2014.08.095
   Uddin MZ, 2017, IEEE ACCESS, V5, P4525, DOI 10.1109/ACCESS.2017.2676238
   Wang Y., 2015, THESIS, P5
   Xue ML, 2018, LECT NOTES COMPUT SC, V10996, P367, DOI 10.1007/978-3-319-97909-0_40
   Yadan Lv, 2014, 2014 International Conference on Smart Computing (SMARTCOMP), P303, DOI 10.1109/SMARTCOMP.2014.7043872
   Yang HY, 2018, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2018.00231
   YANG Y, 2016, REV TEC FAC ING UNIV, V39, P384
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zhang ZP, 2018, INT J COMPUT VISION, V126, P550, DOI 10.1007/s11263-017-1055-1
   Zhou H, 2018, INT SOC OPTICS PHOTO, V10609, P1060908
NR 33
TC 4
Z9 4
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26305
EP 26325
DI 10.1007/s11042-020-08919-1
EA JUL 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000548495600001
DA 2024-07-18
ER

PT J
AU Mahmoud, MAB
   Guo, P
   Wang, K
AF Mahmoud, Mohammed A. B.
   Guo, Ping
   Wang, Ke
TI Pseudoinverse learning autoencoder with DCGAN for plant diseases
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Plant diseases; DCGAN; Pseudoinverse learning
ID DEEP; NETWORKS; SYSTEM
AB Pest infestation of crops and plants impacts agricultural development. Generally, farmers or specialist observe the plants with the naked eye to recognise and diagnose ailments. However, this technique can be time-consuming, costly and inexact. In contrast, auto-detection using image processing methods gives fast and precise results. This paper introduces a new plant disease identification model predicated on leaf image classification that employs a deep convolutional generative adversarial network (DCGAN) along with a classifier identified by multilayer perceptron (MLP) neural networks trained with a pseudoinverse learning autoencoder (PILAE) algorithm. The DCGAN performes two tasks: (1) synthesis of the minor class images to overcome the issue of imbalance in the dataset and (2) extracting deep features of all images within the dataset. The PILAE training procedure is not required to identify the learning control variables or indicate the number of hidden layers. Consequently, the PILAE classifier can fulfil exceptional execution with regard to training efficiency and reliability. Empirical results from PlantVillage dataset possess demonstrated how the presented method yields positive results with other models and reasonably minimal complexly.
C1 [Mahmoud, Mohammed A. B.] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing, Peoples R China.
   [Guo, Ping] Beijing Normal Univ, Sch Syst Sci, Beijing, Peoples R China.
   [Wang, Ke] Univ Michigan, Dept Elect & Comp Engn, Dearborn, MI 48128 USA.
C3 Beijing Institute of Technology; Beijing Normal University; University
   of Michigan System; University of Michigan
RP Mahmoud, MAB (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing, Peoples R China.
EM mahmoud.mohammed@bit.edu.cn
RI GUO, Ping/AAG-2160-2019; Mahmoud, Mohammed/P-3487-2018
OI GUO, Ping/0000-0002-7122-1084; Mahmoud, Mohammed/0000-0001-5543-6360
FU National Natural Science Foundation of China (NSFC) [61375045]; NSFC
   [U1531242]; Chinese Academy of Sciences (CAS) [U1531242]
FX This work is fully supported by the grants from the National Natural
   Science Foundation of China (NSFC) (61375045), and the Joint Research
   Fund in Astronomy (U1531242) under cooperative agreement between the
   NSFC and Chinese Academy of Sciences (CAS).
CR Akhtar A, 2013, INT CONF FRONT INFO, P60, DOI 10.1109/FIT.2013.19
   Al-Hiary H., 2011, International Journal of Computer Applications, V17, P31, DOI [10.5120/2183-2754, DOI 10.5120/2183-2754]
   Ale L, 2019, IEEE GLOBE WORK, DOI 10.1109/gcwkshps45667.2019.9024439
   [Anonymous], DEEP CONVOLUTIONAL G
   [Anonymous], 2012, INT C SYST INFORMAT
   Arsenovic M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11070939
   Athanikar G., 2016, International Journal of Computer Science and Mobile Computing, V5, P76
   Athiwaratkun B., 2015, ARXIV150702313
   Barré P, 2017, ECOL INFORM, V40, P50, DOI 10.1016/j.ecoinf.2017.05.005
   Barua S., 2019, ARXIV190500643
   Blancard D., 2012, Tomato Diseases: Identification, Biology and Control: A Colour Handbook, VSecond, P35, DOI DOI 10.1201/B15145
   Brahimi M, 2018, HUM-COMPUT INT-SPRIN, P93, DOI 10.1007/978-3-319-90403-0_6
   Brahimi M, 2017, APPL ARTIF INTELL, V31, P299, DOI 10.1080/08839514.2017.1315516
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   CHOUDHURY SD, 2018, BIOSYST ENG, V170, P72, DOI DOI 10.1016/j.biosystemseng.2018.04.001
   Dandawate Y, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P794, DOI 10.1109/ICACCI.2015.7275707
   DeChant C, 2017, PHYTOPATHOLOGY, V107, P1426, DOI 10.1094/PHYTO-11-16-0417-R
   Dyrmann M, 2016, BIOSYST ENG, V151, P72, DOI 10.1016/j.biosystemseng.2016.08.024
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Fujita E, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P989, DOI [10.1109/ICMLA.2016.56, 10.1109/ICMLA.2016.0178]
   Giuffrida MV, 2017, IEEE INT CONF COMP V, P2064, DOI 10.1109/ICCVW.2017.242
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo P, 2004, NEUROCOMPUTING, V56, P101, DOI 10.1016/S0925-2312(03)00385-0
   Guo P, 2003, IEEE T SYST MAN CY B, V33, P35, DOI 10.1109/TSMCB.2003.808176
   Guo P., 2018, ARXIV181101545
   Hanssen IM, 2012, ADV VIRUS RES, V84, P31, DOI 10.1016/B978-0-12-394314-9.00002-6
   Hughes D., 2015, ABS151108060 CORR
   Hwang U., 2017, ARXIV PREPRINT ARXIV
   Japkowicz N., 2004, P IRIS MACH LEARN WO
   Kawasaki Y, 2015, LECT NOTES COMPUT SC, V9475, P638, DOI 10.1007/978-3-319-27863-6_59
   Kheirkhah FM, 2019, IET COMPUT VIS, V13, P369, DOI 10.1049/iet-cvi.2018.5028
   Kornblith S, 2019, PROC CVPR IEEE, P2656, DOI 10.1109/CVPR.2019.00277
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar N., 2012, 12 EUR C COMP VIS EC
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Mahmoud MAB, 2019, IEEE ACCESS, V7, P74602, DOI 10.1109/ACCESS.2019.2919125
   Mao WT, 2019, IEEE ACCESS, V7, P9515, DOI 10.1109/ACCESS.2018.2890693
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Mokhtar U, 2015, INTELLIGENT SYSTEMS, P641
   Nachtigall LG, 2016, PROC INT C TOOLS ART, P472, DOI [10.1109/ICTAI.2016.75, 10.1109/ICTAI.2016.0078]
   Nazki H, 2020, COMPUT ELECTRON AGR, V168, DOI 10.1016/j.compag.2019.105117
   Ping G, 2017, ARXIV171110339
   Radford A., 2015, ARXIV
   Ren JSJ, 2012, IEEE INT C INTELL TR, P172, DOI 10.1109/ITSC.2012.6338621
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sa I, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081222
   Samanta D, 2012, INT J COMPUTER TREND, V1, P3
   Shah MP, 2017, IEEE IMAGE PROC, P860, DOI 10.1109/ICIP.2017.8296403
   Shi R, 2020, ARXIV200307603
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Soderkvist Oskar., 2001, COMPUTER VISION CLAS, P74
   Suh S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040746
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tian Y, 2019, DETECTION APPLE LESI, V2019
   Too EC, 2019, J INTELLIGENT FUZZY, P1
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang B, 2019, IEEE ACCESS, V7, P151754, DOI 10.1109/ACCESS.2019.2947510
   Wang D, 2018, 2018 6TH INTERNATIONAL SYMPOSIUM ON DIGITAL FORENSIC AND SECURITY (ISDFS), P1
   Wang J, 2018, LECT NOTES COMPUT SC, V10878, P99, DOI 10.1007/978-3-319-92537-0_12
   Wang K, 2017, IEEE SYS MAN CYBERN, P948, DOI 10.1109/SMC.2017.8122732
   Wang X, 2020, IEEE ACCESS, V8, P39175, DOI 10.1109/ACCESS.2020.2976117
   Wang ZS, 2020, IEEE ACCESS, V8, P71353, DOI 10.1109/ACCESS.2020.2986267
   Yang CZ, 2019, IEEE ACCESS, V7, P178108, DOI 10.1109/ACCESS.2019.2958416
   You H, 2019, IEEE T GEOSCIENCE RE
   Yu DF, 2019, INT SYM MIX AUGMENT, P103, DOI 10.1109/ISMAR.2019.00-20
   Zhang J, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020271
   Zhang ZH, 2016, INT SYM COMPUT INTEL, P103, DOI [10.1109/ISCID.2016.2033, 10.1109/ISCID.2016.138]
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhu Y, 2018, DATA AUGMENTATION US, P324
NR 74
TC 15
Z9 15
U1 1
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26245
EP 26263
DI 10.1007/s11042-020-09239-0
EA JUL 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000548128400008
DA 2024-07-18
ER

PT J
AU Xu, DZ
   Wu, LF
   He, YH
   Zhao, Q
   Jian, M
   Yan, JC
   Zhao, L
AF Xu, Dezhong
   Wu, Lifang
   He, Yonghao
   Zhao, Qing
   Jian, Meng
   Yan, Junchi
   Zhao, Liang
TI OS-LFFD: a light and fast face detector with Ommateum structure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Edge devices; Face detector; Effective receptive field; Ommateum block
AB Face detection has been deployed on edge devices as the basis for face applications, but the devices cannot store large-scale models and have low computing power. The existing anchor-based face detection schemes cannot cover face images over a continuous size range, and their performance is not satisfactory. Obviously, good performances are accompanied by increased storage and lower speed. We find that the feature points in different layers correspond to a specific size range of RFs (receptive fields). According to the survey, the predictable range of RFs with the same size is the face on a continuous scale. Therefore, we argue that RFs are inherent anchors. A Light and Fast Face Detector with an Ommateum Structure (OS-LFFD) is proposed in this paper. By analyzing the correlation between the effective receptive field (ERF) and face sizes, a 4-branch network is designed to cover the objective range of face sizes. Each branch involves an ommateum block with a similar structure and shared parameters. It reduces the number of model parameters (8 M), which makes it much smaller than most face detectors. Experiments on the popular benchmarks WIDER FACE and FDDB using multiple hardware platforms demonstrate that the proposed scheme can considerably balance the accuracy and running speed.
C1 [Xu, Dezhong; Wu, Lifang; He, Yonghao; Zhao, Qing; Jian, Meng; Zhao, Liang] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
   [He, Yonghao] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
   [Yan, Junchi] Shanghai Jiao Tong Univ, Artificial Intelligence Inst, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
C3 Beijing University of Technology; Chinese Academy of Sciences; Institute
   of Automation, CAS; Shanghai Jiao Tong University
RP Zhao, Q (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
EM zhaoqing1025@emails.bjut.edu.cn
RI Yan, Jun/IXD-7801-2023
FU National Natural Science Foundation of China [61976010, 61702022,
   61802011]; Beijing Municipal Education Committee Science Foundation
   [KM201910005024]; China Postdoctoral Science Foundation [2018M640033];
   Beijing Excellent Young Talent Cultivation Project [2017000020124G075];
   Beijing University of Technology "Ri xin" Cultivation Project
FX This work was supported in part by the National Natural Science
   Foundation of China (61976010,61702022,61802011), Beijing Municipal
   Education Committee Science Foundation KM201910005024, China
   Postdoctoral Science Foundation Funded Project (2018M640033), Beijing
   Excellent Young Talent Cultivation Project (2017000020124G075), and
   Beijing University of Technology "Ri xin" Cultivation Project.
CR [Anonymous], 2018, ABS180406655 CORR
   [Anonymous], 2016, arXiv
   Brubaker SC, 2008, INT J COMPUT VISION, V77, P65, DOI 10.1007/s11263-007-0060-1
   Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3
   Chi C., 2018, ABS180902693 CORR
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Howard A. G., 2013, Some improvements on deep convolutional neural network based image classification
   Hu PY, 2017, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2017.166
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jain V., 2010, Fddb: A benchmark for face detection in unconstrained settings
   Jiang HZ, 2017, IEEE INT CONF AUTOMA, P650, DOI [10.1109/FG.2017.82, 10.1109/MWSYM.2017.8058653]
   Jin X, 2017, COMPUT VIS IMAGE UND, V162, P1, DOI 10.1016/j.cviu.2017.08.008
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li JF, 2019, PROC CVPR IEEE, P10855, DOI 10.1109/CVPR.2019.01112
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luo WJ, 2016, ADV NEUR IN, V29
   Molchanov P, 2017, INT C LEARN REPR ICC
   Najibi M, 2017, IEEE I CONF COMP VIS, P4885, DOI 10.1109/ICCV.2017.522
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pham MT, 2007, IEEE I CONF COMP VIS, P1634
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tang X, 2018, LECT NOTES COMPUT SC, V11213, P812, DOI 10.1007/978-3-030-01240-3_49
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang H., 2017, CoRR
   Yang H, 2014, C IND ELECT APPL, P1, DOI 10.1109/ICIEA.2014.6931121
   YANG S, 2016, PROC CVPR IEEE, P5525, DOI DOI 10.1109/CVPR.2016.596
   Zhang S, 2019, ARXIV190106651
   Zhang SF, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P1, DOI 10.1109/BTAS.2017.8272675
   Zhang SF, 2017, IEEE I CONF COMP VIS, P192, DOI 10.1109/ICCV.2017.30
   Zhang Y, 2019, ARXIV190102350
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhu CC, 2018, PROC CVPR IEEE, P5127, DOI 10.1109/CVPR.2018.00538
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
NR 43
TC 5
Z9 5
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34153
EP 34172
DI 10.1007/s11042-020-09143-7
EA JUL 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000548128400005
DA 2024-07-18
ER

PT J
AU Wadhwa, A
   Bhardwaj, A
AF Wadhwa, Anjali
   Bhardwaj, Anuj
TI Enhancement of MRI images of brain tumor using Gr<i>u</i>nwald Letnikov
   fractional differential mask
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MRI; Grunwald Letnikov fractional derivative; Brain tumor; Gray level
   co-occurrence matrix; Mean opinion score
ID TEXTURAL FEATURES
AB The present paper focuses on the enhancement of magnetic resonance imaging (MRI) images of the brain tumor using the Grunwald Letnikov (G-L) fractional differential mask. The method aims to enhance the edges and texture while preserving the smooth regions of an image. This will help the doctors to take a right decision for treatment by correctly identifying the location of the tumor present in an image. The method uses the G-L definition of the fractional derivative to form masks of size 3 x 3 and 5 x 5 in which the correlation of the neighboring pixels is preserved. A gradient is used to find the threshold so that the input image can be partitioned into edge, texture and smooth region. The order of the fractional derivative is chosen individually for each pixel of these three regions and the framed mask is applied on the input image to get the enhanced image. To show the effectiveness of the proposed method, results are presented in terms of visual appearance, subjective assessment and quantitative metrics. PSNR, AMBE, entropy, and GLCM are used as evaluation parameters for quantitative analysis. The comparison with other existing methods such as fixed order fractional differential, adaptive fractional differential, and modified G-L differential operator shows the improvement in results obtained by the proposed method.
C1 [Wadhwa, Anjali; Bhardwaj, Anuj] Jaypee Inst Informat Technol, Noida 201309, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Bhardwaj, A (corresponding author), Jaypee Inst Informat Technol, Noida 201309, India.
EM anujbhardwaj8@gmail.com
RI Bhardwaj, Anuj/KIE-2095-2024
OI Bhardwaj, Anuj/0000-0003-0866-2618
CR Chandra SK, 2018, TENCON IEEE REGION, P2408, DOI 10.1109/TENCON.2018.8650163
   Dhal Krishna Gopal, 2018, International Journal of Medical Engineering and Informatics, V10, P164
   Gao CB, 2012, MATH PROBL ENG, V2012, DOI 10.1155/2012/325785
   Ghatwary N, 2016, LIVER CT ENHANCEMENT
   Gonzalez R. C., 2006, PEARSON ED INDIA, V3rd
   Guan JL, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S021800141857001X
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hemalatha S, 2018, AIN SHAMS ENG J, V9, P1689, DOI 10.1016/j.asej.2016.12.003
   Hincapie G.A. Moreno, 2019, BANKNOTES CLASSIFICA, V11137, P451, DOI [10.1117/12.2529752,9, DOI 10.1117/12.2529752,9]
   Hu FY, 2015, NEUROCOMPUTING, V158, P295, DOI 10.1016/j.neucom.2014.10.013
   Huang PW, 2006, J VIS COMMUN IMAGE R, V17, P947, DOI 10.1016/j.jvcir.2005.08.005
   Jalab H.A., 2013, MATH PROBL ENG, V2013, P1
   Jensen J.R., 2015, INTRO DIGITAL IMAGE
   Kansal S, 2018, MULTIMED TOOLS APPL, V77, P26919, DOI 10.1007/s11042-018-5894-8
   Kashyap KL, 2018, MULTIMED TOOLS APPL, V77, P9249, DOI 10.1007/s11042-017-4751-5
   Kimori Y, 2013, J SYNCHROTRON RADIAT, V20, P848, DOI 10.1107/S0909049513020761
   Li B, 2015, COMPUT ELECTR ENG, V45, P324, DOI 10.1016/j.compeleceng.2015.02.013
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   LOVE ER, 1971, J LOND MATH SOC, V3, P241, DOI 10.1112/jlms/s2-3.2.241
   Matlob MA, 2017, CRIT REV BIOMED ENG
   McBride A. C., 1986, FRACTIONAL CALCULUS
   Mun J, 2019, J VIS COMMUN IMAGE R, V58, P688, DOI 10.1016/j.jvcir.2018.12.037
   Pu YF, 2010, IEEE T IMAGE PROCESS, V19, P491, DOI 10.1109/TIP.2009.2035980
   Pu YF, 2008, SCI CHINA SER F, V51, P1319, DOI 10.1007/s11432-008-0098-x
   Saadia A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P166, DOI 10.1109/SIPROCESS.2016.7888245
   Sridevi G, 2019, LECT NOTE DATA ENG, V28, P197, DOI 10.1007/978-981-13-6459-4_20
   Subramani B, 2018, INT J IMAG SYST TECH, V28, P217, DOI 10.1002/ima.22272
   Taleb-Ahmedx, 2018, NEURAL ADAPTIVE FRAC, P1
   Tang JR, 2017, APPL SOFT COMPUT, V55, P31, DOI 10.1016/j.asoc.2017.01.053
   Wadhwa A, 2019, MAGN RESON IMAGING, V61, P247, DOI 10.1016/j.mri.2019.05.043
   Xu MJ, 2015, BIO-MED MATER ENG, V26, pS1325, DOI 10.3233/BME-151430
   Yu Q, 2015, PLOS ONE, V10
   Yu RR, 2008, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON TEST AUTOMATION & INSTRUMENTATION, VOLS 1-2, P375
   Zhang Y., 2010, J COMPUT INF SYST, V6, P3191
NR 36
TC 10
Z9 11
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25379
EP 25402
DI 10.1007/s11042-020-09177-x
EA JUL 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000544844100002
DA 2024-07-18
ER

PT J
AU Bhadra, J
   Murthy, MV
   Banga, MK
AF Bhadra, Jayati
   Murthy, M. Vinayaka
   Banga, M. K.
TI A novel piracy protection scheme for videos using force-induced pixels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stego-image; watermark; bit-tolerance; frame-tolerance; centrifugal
   force; modified LSB
AB In this paper, a novel reversible keyless invisible authentication method is proposed for video piracy protection which uses randomized pixel at Red color channel for hiding information with locations of such modified pixels being stored in an immediate next frame. Each pair of these frames is identified with an embedded random number and an alphabet "A" or "B" based on hidden information frame and location information frame respectively. Such randomization at two different levels is not considered in any of the existing methods. Videos with this proposed embedding of copyright information ensure minimum distortions and maximum resistance to the removal of authentication information thereby providing an effective control of the rampant piracy menace. Keyless invisible embedding process increases the security and reduces the cost. Modified Least Significant Bit (LSB) based mechanism is used for achieving cost effectiveness and simplicity. The extracted information will be compared to assure the authenticity of videos. The average Euclidean distance between original and authenticated frames' histogram is 2.5902e-10 that implies high similarity and thereby increasing its ability to withstand visual attacks. The proposed method results in PSNR greater than 50 dB with MSE less than 0.001 leading to high resultant image quality after embedding. High level of robustness is achieved due to the inherent mechanism of storing authentication information across all pairs of frame as well as complete randomization of the authentication storing pixels. In case of eavesdropping, using Bit-tolerance and Frame-tolerance we can confirm whether the corrupted video is acceptable or not.
C1 [Bhadra, Jayati] REVA Univ, Sch Comp Sci & Applicat, Rukmini Knowledge Pk, Bengaluru 560064, Karnataka, India.
   [Murthy, M. Vinayaka] REVA Univ, Sch Comp Sci Applicat, Rukmini Knowledge Pk, Bengaluru 560064, Karnataka, India.
   [Banga, M. K.] Dayananda Sagar Univ, Dept Comp Sci Engn, Hosur Main Rd, Bangalore 560068, Karnataka, India.
C3 REVA University; REVA University
RP Bhadra, J (corresponding author), REVA Univ, Sch Comp Sci & Applicat, Rukmini Knowledge Pk, Bengaluru 560064, Karnataka, India.
EM jayatibhadra@sjc.ac.in; dr.m.vinayakamurthy@gmail.com
RI Murthy, M Vinayaka/AAZ-3903-2021; Bhadra, Jayati/ABE-4563-2021
OI Bhadra, Jayati/0000-0002-0509-3272
CR Cao Y., 2015, P 3 ACM WORKSH INF H, P25, DOI DOI 10.1145/2756601.2756609
   CIPRA BA, 1987, AM MATH MON, V94, P937, DOI 10.2307/2322600
   Das SK, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P395, DOI 10.1109/ICRCICN.2015.7434271
   Deshmukh P.U., 2014, IEEE INT C INF COMM, P27
   Feng BW, 2015, IEEE T INF FOREN SEC, V10, P243, DOI 10.1109/TIFS.2014.2368364
   Hao Bin, 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P406, DOI 10.1109/ICCSN.2011.6013622
   JAIN YK, 2010, INT J COMPUTER SCI S, V0004, P00040
   Kasapbasi MC, 2018, SADHANA-ACAD P ENG S, V43, DOI 10.1007/s12046-018-0848-4
   KEKRE HB, 2008, INT J ELEC COMPUT SY, V0002, P00246
   Kelash HM, 2013, 2013 INTERNATIONAL CONFERENCE ON ICT CONVERGENCE (ICTC 2013): FUTURE CREATIVE CONVERGENCE TECHNOLOGIES FOR NEW ICT ECOSYSTEMS, P353, DOI 10.1109/ICTC.2013.6675372
   Paul G., 2012, INT C INF SYST SEC, P134, DOI 10.1007/978-3-642-35130-3_10
   Paul G, 2010, ARXIV10125573
   Paul G, 2017, MULTIMED TOOLS APPL, V76, P7445, DOI 10.1007/s11042-016-3319-0
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Provos N., 2001, 10 USENIX SEC S, P325
   Ramalingam M., 2011, WORLD ACAD SCI ENG T, V74, P502
   Swain G, 2012, INT J SECUR APPL, V6, P1
   Wayner Peter., 2002, DISAPPEARING CRYPTOG
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 23
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 25215
EP 25236
DI 10.1007/s11042-020-09162-4
EA JUL 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000544843700002
DA 2024-07-18
ER

PT J
AU Li, SG
   Lu, HY
   Kong, JL
   Yu, ZX
   Wang, R
AF Li, Shugang
   Lu, Hanyu
   Kong, Jiali
   Yu, Zhaoxu
   Wang, Ru
TI Lean improvement of the stage shows in theme park based on consumer
   preferences correlation deep mining
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Consumer preferences; Correlation deep mining; Kano-IPA model; Product
   improvement; Theme park
ID IMPUTATION
AB Online comments provide a new and convenient way to understand consumer preference, but these comments for stage shows in theme park are usually incomplete, which can seriously affect the accuracy of existing mining models. In order to overcome the dilemma of missing information, we propose the consumer preferences correlation deep mining model, which precisely mines user preferences from two aspects: comment semantic deep mining and attribute emotion correlation mining. Furthermore, the Kano-IPA model is proposed to comprehensively excavate the user satisfaction and the importance of product attributes to give a lean improvement strategy for stage shows. Specifically, firstly, correlation deep mining model is constructed to deeply mine the missing attribute emotional polarity based on the emotional correlation sequence, emotional vector and Senti2vec + Gated Recurrent Unit model. Secondly, correlation width mining model is developed to excavate the user preferences for the stage shows attribute. In the correlation width mining model, the partial regression equation is used to describe the influence of the user emotional polarity on the user satisfaction level. Based on the emotion correlated attribute sequences, the correlation Kano mapping rules are proposed, and then the priority of user preferences for product attributes is given. Thirdly, the Kano-IPA model is designed for the lean improvement of products to achieve higher benefits at a lower cost. Finally, the experimental results on Shanghai Disneyland confirm the effectiveness and application value of the proposed model. Consequently, this study provides an accurate decision support model driven by big data for product improvement.
C1 [Li, Shugang; Lu, Hanyu; Kong, Jiali; Wang, Ru] Shanghai Univ, Sch Management, Shanghai 200444, Peoples R China.
   [Kong, Jiali] Ind & Commercial Bank China, Shanghai Branch, Shanghai 200131, Peoples R China.
   [Yu, Zhaoxu] East China Univ Sci & Technol, Dept Automat, Shanghai 200237, Peoples R China.
C3 Shanghai University; Industrial & Commercial Bank of China (ICBC); East
   China University of Science & Technology
RP Kong, JL (corresponding author), Shanghai Univ, Sch Management, Shanghai 200444, Peoples R China.; Kong, JL (corresponding author), Ind & Commercial Bank China, Shanghai Branch, Shanghai 200131, Peoples R China.
EM westside_li@163.com; luhanyuwill@126.com; K_jiali@yeah.net;
   yyzx@ecust.edu.cn; Ruwang311@163.com
RI Wang, Ru/IXW-6013-2023
OI Yu, Zhaoxu/0000-0002-2375-0213
FU Chinese National Natural Science Foundation [71871135]
FX This work was supported by the Chinese National Natural Science
   Foundation (No. 71871135).
CR Bai S, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P270, DOI 10.1109/ICISCE.2017.65
   Batavio AB, 2017, IOP CONF SER-MAT SCI, V277, DOI 10.1088/1757-899X/277/1/012003
   Calegari LP, 2018, FOOD RES INT, V109, P1, DOI 10.1016/j.foodres.2018.03.080
   Chong AYL, 2017, INT J PROD RES, V55, P5142, DOI 10.1080/00207543.2015.1066519
   De Pelsmaeker S, 2017, FOOD QUAL PREFER, V62, P323, DOI 10.1016/j.foodqual.2017.02.018
   García-Laencina PJ, 2009, NEUROCOMPUTING, V72, P1483, DOI 10.1016/j.neucom.2008.11.026
   Hron K, 2010, COMPUT STAT DATA AN, V54, P3095, DOI 10.1016/j.csda.2009.11.023
   Hsieh P.L., 2015, Review of Integrative Business and Economics Research, V4, P142
   Kalchschmidt M, 2003, INT J PROD ECON, V81-2, P397, DOI 10.1016/S0925-5273(02)00284-0
   Kano N., 1984, J JAPANESE SOC QUALI, V14, P147, DOI DOI 10.20684/QUALITY.14.2_147
   Kerzner H, 2017, IND SPECIFIC DISNEY
   Kuang CJ, 2018, INTEGRATED FUZZY MIC, P1
   Kumar K, 2016, ADV INTELL SYST, V433, P1, DOI 10.1007/978-81-322-2755-7_1
   Kuroda M, 2006, ACCELERATING CONVERG
   Li J., 2011, INT C COMP INF SCI, P442
   Liao SH, 2016, INFORM PROCESS MANAG, V52, P1142, DOI 10.1016/j.ipm.2016.05.003
   LITTLE RJA, 1992, J AM STAT ASSOC, V87, P1227, DOI 10.2307/2290664
   Mikulic J, 2012, EXPERT SYST APPL, V39, P5144, DOI 10.1016/j.eswa.2011.11.026
   Miranda S, 2018, J BUS RES, V89, P371, DOI 10.1016/j.jbusres.2017.12.040
   Pradhan N, 2018, IEEE INT CONF BIG DA, P3717, DOI 10.1109/BigData.2018.8622155
   Wang Y, 2009, J COMPUT APPL MATH, V229, P168, DOI 10.1016/j.cam.2008.10.020
   Zeithaml VA, 1996, J MARKETING, V60, P31, DOI 10.2307/1251929
   Zhang YS, 2017, TOURISM MANAGE, V59, P564, DOI 10.1016/j.tourman.2016.08.019
NR 23
TC 1
Z9 1
U1 2
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24487
EP 24506
DI 10.1007/s11042-020-09112-0
EA JUN 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000542143000004
DA 2024-07-18
ER

PT J
AU Xu, XP
   Matkowski, WM
   Kong, AWK
AF Xu, Xingpeng
   Matkowski, Wojciech Michal
   Kong, Adams Wai Kin
TI A portrait photo-to-tattoo transform based on digital tattooing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Computer graphics; Computational geometry
ID IMAGE; MODEL
AB Tattooing portraits of loved ones is a popular form of love expression and tribute. Tattooing portraits is complicated and challenging because of detailed facial expressions and unique characters of each person. Currently, it is hard for clients to give clear instructions on tattoo designs to tattooists, because there is no effective way to see a portrait tattoo before putting it on the body. In this paper, an algorithm which transforms a given portrait photo to a portrait tattoo is proposed. It takes a portrait photo, a reference portrait tattoo image, a skin image and a set of parameters as inputs. The portrait photo is the person's face whom the client wants to put on his/her skin. The reference portrait tattoo image is used to control the color and style of the synthetic portrait tattoo. The skin image is taken from the skin region where the client wants to tattoo. By adjusting the parameters, portrait tattoos with different characteristics can be generated. The proposed algorithm uses a series of tailor-made image processing methods and a digital tattoo needle model to perform digital tattooing on the skin image. Comparing with the state-of-the-art style transfer methods, the proposed algorithm produces more realistic portrait tattoos.
C1 [Xu, Xingpeng; Matkowski, Wojciech Michal; Kong, Adams Wai Kin] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
C3 Nanyang Technological University
RP Xu, XP (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
EM xpxu@ntu.edu.sg; wojciech.matkowski@ntu.edu.sg; adamskong@ntu.edu.sg
RI Matkowski, Wojciech/AAX-5437-2020
OI Xu, Xingpeng/0000-0002-0791-0221
FU Ministry of Education, Singapore [RG30/17 (S)]
FX This work is partially supported by the Ministry of Education, Singapore
   through Academic Research Fund Tier 1, RG30/17 (S).
CR [Anonymous], 2018, US LUN COM TATT IM I
   [Anonymous], 2018, MAK TATT
   Baxter W., 2004, THESIS
   Burger Wilhelm., 2010, Principles of digital image processing core algorithms, P110
   Calmon J, 2015, SIBGRAPI, P265, DOI 10.1109/SIBGRAPI.2015.30
   Chen TC, 2017, AGEING SOC, V37, P1798, DOI 10.1017/S0144686X16000623
   Chen ZL, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818066
   Deussen O, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130819
   Edmonds L, 2016, TATTOOIST DAVE STEWA
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Goodfello I, 2014, ADV NEURAL INFORM PR
   HADDAD RA, 1991, IEEE T SIGNAL PROCES, V39, P723, DOI 10.1109/78.80892
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hsu RL, 2003, IEEE T PATTERN ANAL, V25, P1388, DOI 10.1109/TPAMI.2003.1240113
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Huang Y, 2015, IEEE INT WIE C EL CO
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim D, 2008, COMPUT GRAPH FORUM, V27, P1209, DOI 10.1111/j.1467-8659.2008.01259.x
   Larry L, 2016, TATTOO TAKEOVER 3 10
   Laumann AE, 2006, J AM ACAD DERMATOL, V55, P413, DOI 10.1016/j.jaad.2006.03.026
   Lee JE, 2012, IEEE MULTIMEDIA, V19, P40, DOI 10.1109/MMUL.2011.59
   Lee JE, 2008, 2008 BIOMETRICS SYMPOSIUM (BSYM), P1, DOI [10.1109/PLASMA.2008.4591032, 10.1109/BSYM.2008.4655515]
   Lu JW, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461998
   Maurer CR, 2003, IEEE T PATTERN ANAL, V25, P265, DOI 10.1109/TPAMI.2003.1177156
   Mauricio G, 2015, INT C DES US EXP US
   Newson A, 2017, COMPUT GRAPH FORUM, V36, P684, DOI 10.1111/cgf.13159
   Nirkin Y, 2018, IEEE INT CONF AUTOMA, P98, DOI 10.1109/FG.2018.00024
   Parker RJ, 1997, ALGORITHMS IMAGE PRO, P23
   Patel VM, 2016, IEEE C COMP VIS PATT
   Proud A, 2015, WERE NOT GOING REACH
   Radford A., 2016, INT C LEARN REPR
   Selim A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925968
   Shahrian E, 2013, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2013.88
   Smith A, 2015, 7 MOST FREQUENTLY AS
   Statista Research Department, 2016, SHAR AM ON MOR TATT
   Stuyck T, 2017, COMPUT GRAPH FORUM, V36, P69, DOI 10.1111/cgf.12995
   Sullivan R, 2017, TATTOO LASER REMOVAL
   Taigman Y., 2016, INT C LEARN REPR
   Venkatanath N, 2015, NATL CONF COMMUN
   Winnemoeller H, 2012, COMPUT GRAPH-UK, V36, P740, DOI 10.1016/j.cag.2012.03.004
   Xia Y, 2013, COMPUT GRAPH FORUM, V32, P11, DOI 10.1111/cgf.12207
   Zhang Y, 2017, IEEE T IMAGE PROCESS, V26, P464, DOI 10.1109/TIP.2016.2628581
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 44
TC 4
Z9 5
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24367
EP 24392
DI 10.1007/s11042-020-09101-3
EA JUN 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000541402000004
DA 2024-07-18
ER

PT J
AU Khurana, A
   Verma, OP
AF Khurana, Anshu
   Verma, Om Prakash
TI Novel approach with nature-inspired and ensemble techniques for optimal
   text classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text classification; Feature selection; Nature-based optimization;
   Machine learning classifier; Ensemble classifier; Biogeography based
   optimization
ID PARTICLE SWARM OPTIMIZATION; GLOBAL FEATURE-SELECTION; DIFFERENTIAL
   EVOLUTION; SENTIMENT ANALYSIS; GENETIC ALGORITHM; CLASSIFIERS; COLONY;
   TREE
AB Text classification reduces the time complexity and space complexity by dividing the complete task into the different classes. The main problem with text classification is a vast number of features extracted from the textual data. Pre-processed dataset have many features, some of which are not desirable and act only like noise. In this paper, a novel approach for optimal text classification based on nature-inspired algorithm and ensemble classifier is proposed. In the proposed model, feature selection was performed with Biogeography Based Optimization (BBO) algorithm along with ensemble classifiers (Bagging). The use of ensemble classifiers for classification delivers better performance for optimal text classification as compared to an individual classifier, and hence, improving the accuracy. Ensemble classifiers combines the weakness of individual classifiers. The individual classifiers are unable to improve the classification results when compared to ensemble classifier. The selected features, after feature selection using BBO algorithm, are classified into various classes using six machine learning classifier. The experimental results are computed on ten text classification datasets taken from UCI repository and one real-time dataset of an airlines. The four different measures namely; Accuracy, Precision, Recall and F- measure are used to validate performance of our model with ten-fold cross-validation. For feature selection process, a comparison is performed among state-of-the-art algorithms available in the literature. Results shows that BBO for feature selection outperforms the other similar nature-based optimization techniques. Our proposed approach of BBO with ensemble classifier is also compared with techniques proposed by other researchers and we analyzed the results quantitatively and qualitatively.
C1 [Khurana, Anshu] Delhi Technol Univ, Dept Comp Sci & Engn, New Delhi, India.
   [Verma, Om Prakash] Delhi Technol Univ, Dept Elect & Commun, New Delhi, India.
C3 Delhi Technological University; Delhi Technological University
RP Khurana, A (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, New Delhi, India.
EM anshuchugh@gmail.com
RI Verma, Om/AAD-1007-2019
OI Verma, Om/0000-0002-7421-295X
CR Akinyelu AA, 2014, J APPL MATH, DOI 10.1155/2014/425731
   [Anonymous], CLUST COMPUT
   Balasubramanian V., 2014, Newnes
   Bhattacharya A, 2010, EXPERT SYST APPL, V37, P3605, DOI 10.1016/j.eswa.2009.10.031
   Boynukalin Z., 2012, Emotion analysis of Turkish texts by using machine learning methods
   Catal C, 2017, IET SOFTW, V11, P89, DOI 10.1049/iet-sen.2016.0137
   da Silva NFF, 2014, DECIS SUPPORT SYST, V66, P170, DOI 10.1016/j.dss.2014.07.003
   Dadaneh BZ, 2016, EXPERT SYST APPL, V53, P27, DOI 10.1016/j.eswa.2016.01.021
   Das AK, 2018, APPL SOFT COMPUT, V65, P400, DOI 10.1016/j.asoc.2018.01.040
   DEMIDOVA L, 2016, ARXIV160308296
   Diab DM, 2017, APPL SOFT COMPUT, V54, P183, DOI 10.1016/j.asoc.2016.12.043
   El Hindi K, 2014, J KING SAUD UNIV-COM, V26, P237, DOI 10.1016/j.jksuci.2014.03.008
   El Hindi K, 2014, AI COMMUN, V27, P133, DOI 10.3233/AIC-130588
   Emary E, 2016, NEUROCOMPUTING, V172, P371, DOI 10.1016/j.neucom.2015.06.083
   Eroglu DY, 2017, INFORM SCIENCES, V405, P18, DOI 10.1016/j.ins.2017.04.009
   Esseghir MA, 2010, LECT NOTES COMPUT SC, V6283, P226, DOI 10.1007/978-3-642-15381-5_28
   Fersini E, 2014, DECIS SUPPORT SYST, V68, P26, DOI 10.1016/j.dss.2014.10.004
   Fister I, 2013, ELEKTROTEH VESTN, V80, P1
   Fong S, 2016, IEEE T SERV COMPUT, V9, P33, DOI 10.1109/TSC.2015.2439695
   Ghareb AS, 2016, EXPERT SYST APPL, V49, P31, DOI 10.1016/j.eswa.2015.12.004
   Gong WY, 2011, SOFT COMPUT, V15, P645, DOI 10.1007/s00500-010-0591-1
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hafez AI, 2016, PROCEEDINGS OF THE 2016 INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA)
   Hafez AI, 2015, INT CONF SOFT COMPUT, P19, DOI 10.1109/SOCPAR.2015.7492775
   Janardan SM, 2017, PROCEDIA COMPUT SCI, V122, P804, DOI 10.1016/j.procs.2017.11.440
   Jiang LX, 2016, ENG APPL ARTIF INTEL, V52, P26, DOI 10.1016/j.engappai.2016.02.002
   Jiang LX, 2012, KNOWL-BASED SYST, V26, P239, DOI 10.1016/j.knosys.2011.08.010
   Jiang MY, 2018, NEURAL COMPUT APPL, V29, P61, DOI 10.1007/s00521-016-2401-x
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Li XS, 2017, IEEE T AFFECT COMPUT, V8, P428, DOI 10.1109/TAFFC.2017.2716930
   LIANG HS, 2007, J HEBEI U NATURAL SC, P24
   Lin KC, 2016, J SUPERCOMPUT, V72, P3210, DOI 10.1007/s11227-016-1631-0
   Lin SW, 2008, EXPERT SYST APPL, V35, P1817, DOI 10.1016/j.eswa.2007.08.088
   Liu Y, 2017, EXPERT SYST APPL, V80, P323, DOI 10.1016/j.eswa.2017.03.042
   McCallum A., 1998, AAAI 98 WORKSH LEARN, V752, P41, DOI DOI 10.1109/TSMC.1985.6313426
   Melo A, 2019, ARTIF INTELL REV, V51, P33, DOI 10.1007/s10462-017-9556-4
   Mironczuk MM, 2018, EXPERT SYST APPL, V106, P36, DOI 10.1016/j.eswa.2018.03.058
   Moradi P, 2016, APPL SOFT COMPUT, V43, P117, DOI 10.1016/j.asoc.2016.01.044
   Nag K, 2016, IEEE T CYBERNETICS, V46, P499, DOI 10.1109/TCYB.2015.2404806
   Onan A, 2016, EXPERT SYST APPL, V57, P232, DOI 10.1016/j.eswa.2016.03.045
   Pai PF, 2014, NEURAL COMPUT APPL, V25, P2011, DOI 10.1007/s00521-014-1689-7
   PANCHAL V, 2010, INT J COMPUTER APPL, V1, P975
   PANCHAL V, 2009, ARXIV09121009
   Pinheiro RHW, 2012, EXPERT SYST APPL, V39, P12851, DOI 10.1016/j.eswa.2012.05.008
   Prabowo R, 2009, J INFORMETR, V3, P143, DOI 10.1016/j.joi.2009.01.003
   Rennie J.D., 2003, Proceedings of the 20th International Conference on Machine Learning, P616
   Russell S., 1995, Acm Sigart Bulletin, V6, P24, DOI DOI 10.1145/201977.201989
   Sabbah T, 2017, APPL SOFT COMPUT, V58, P193, DOI 10.1016/j.asoc.2017.04.069
   Sayed GI, 2019, NEURAL COMPUT APPL, V31, P171, DOI 10.1007/s00521-017-2988-6
   Sayed GI, 2017, ADV INTELL SYST, V536, P306, DOI 10.1007/978-3-319-48490-7_36
   Sayed SAF, 2016, PATTERN RECOGN LETT, V77, P21, DOI 10.1016/j.patrec.2016.03.014
   Sboev A, 2016, PROCEDIA COMPUT SCI, V101, P135, DOI 10.1016/j.procs.2016.11.017
   Schiezaro M, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-47
   Silla CN, 2011, DATA MIN KNOWL DISC, V22, P31, DOI 10.1007/s10618-010-0175-9
   Simon D, 2011, EVOL COMPUT, V19, P167, DOI 10.1162/EVCO_a_00018
   Simon D, 2008, IEEE T EVOLUT COMPUT, V12, P702, DOI 10.1109/TEVC.2008.919004
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Su CT, 2011, INFORM SCIENCES, V181, P972, DOI 10.1016/j.ins.2010.11.008
   Tang B, 2016, IEEE T KNOWL DATA EN, V28, P2508, DOI 10.1109/TKDE.2016.2563436
   Uysal AK, 2016, EXPERT SYST APPL, V43, P82, DOI 10.1016/j.eswa.2015.08.050
   Uysal AK, 2014, EXPERT SYST APPL, V41, P5938, DOI 10.1016/j.eswa.2014.03.041
   Wang G, 2014, DECIS SUPPORT SYST, V57, P77, DOI 10.1016/j.dss.2013.08.002
   Wang H, 2017, SOFT COMPUT, V21, P5091, DOI 10.1007/s00500-016-2104-3
   Xia R, 2011, INFORM SCIENCES, V181, P1138, DOI 10.1016/j.ins.2010.11.023
   Yang BG, 2011, DATA KNOWL ENG, V70, P775, DOI 10.1016/j.datak.2011.05.002
   YING L, 2007, COMPUTER KNOWLEDGE T, V11
   Zawbaa HM, 2016, IEEE C EVOL COMPUTAT, P4612, DOI 10.1109/CEC.2016.7744378
   Zhang Y, 2017, IEEE ACM T COMPUT BI, V14, P64, DOI 10.1109/TCBB.2015.2476796
   Zorarpaci E, 2016, EXPERT SYST APPL, V62, P91, DOI 10.1016/j.eswa.2016.06.004
NR 69
TC 7
Z9 7
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 23821
EP 23848
DI 10.1007/s11042-020-09013-2
EA JUN 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000539939200002
DA 2024-07-18
ER

PT J
AU Jiao, ZQ
   Wang, H
   Cai, M
   Cao, Y
   Zou, L
   Wang, SH
AF Jiao, Zhuqing
   Wang, Huan
   Cai, Min
   Cao, Yin
   Zou, Ling
   Wang, Shuihua
TI Rich club characteristics of dynamic brain functional networks in
   resting state
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Functional magnetic resonance imaging (fMRI); Time series; Brain
   functional networks; Rich club
ID ALZHEIMERS-DISEASE; CONNECTIVITY ANALYSIS; REVEALS; ATROPHY
AB Conventional brain functional networks are constructed by extracting the entire time series from functional Magnetic Resonance Imaging (fMRI). Yet such a method is easy to ignore the dynamic interaction patterns of brain regions that essentially change across time. In this study, we analyze the functional connectivity characteristics of Rich Club in resting-state brain functional networks, and study the dynamic functional differences of core brain regions at different time periods. First, the time series is extracted from resting-state fMRI to construct a dynamic brain functional network. Then, Rich Clubs of different time periods are determined by the Rich Club coefficients. In particular, the efficiency of each Rich Club is calculated to examine the influences of the Rich Connections, Feeder Connections and Local Connections. Finally, the node degree, clustering coefficient and efficiency for Rich Club nodes are calculated to quantify the dynamic processes of Rich Clubs, and the functional connectivity of Rich Clubs are compared with those of the functional networks constructed by the entire fMRI time series. Experimental results demonstrate that the distribution of Rich Clubs in the dynamic brain functional network is consistent with that from the entire fMRI time series, while the composition and functional connectivity of Rich Club dynamically change across time. Moreover, Rich connection and Local connection in the brain functional networks show a significant correlation with the efficiency of Rich Club, and the local and the global efficiency of Rich Clubs are greater than that of the global network. These results further illustrate the viewpoint that Rich Clubs have significant influence on the functional characteristics of global brain functional networks.
C1 [Jiao, Zhuqing; Wang, Huan; Cai, Min; Zou, Ling] Changzhou Univ, Sch Informat Sci & Engn, Changzhou 213164, Peoples R China.
   [Cao, Yin] Nanjing Med Univ, Changzhou Peoples Hosp 2, Dept Neurol, Changzhou 213003, Peoples R China.
   [Wang, Shuihua] Univ Leicester, Dept Informat, Univ Rd, Leicester LE1 7RH, Leics, England.
C3 Changzhou University; Nanjing Medical University; University of
   Leicester
RP Zou, L (corresponding author), Changzhou Univ, Sch Informat Sci & Engn, Changzhou 213164, Peoples R China.; Wang, SH (corresponding author), Univ Leicester, Dept Informat, Univ Rd, Leicester LE1 7RH, Leics, England.
EM zouling@cczu.edu.cn; shuihuawang@ieee.org
RI Jiao, Zhuqing/JDD-4102-2023; Wang, Shuihua/G-7326-2016
CR Breakspear M, 2017, NAT NEUROSCI, V20, P340, DOI 10.1038/nn.4497
   Calhoun VD, 2014, NEURON, V84, P262, DOI 10.1016/j.neuron.2014.10.015
   Chen XB, 2016, HUM BRAIN MAPP, V37, P3282, DOI 10.1002/hbm.23240
   Chen XY, 2017, INT J CHEM REACT ENG, V15, DOI 10.1515/ijcre-2016-0039
   Colizza V, 2006, NAT PHYS, V2, P110, DOI 10.1038/nphys209
   Collin G., 2013, Society for Neuroscience Abstract Viewer and Itinerary Planner, V43, DOI 10.1093/schbul/sbt162
   Daianu M, 2015, HUM BRAIN MAPP, V36, P3087, DOI 10.1002/hbm.22830
   Damaraju E, 2014, NEUROIMAGE-CLIN, V5, P298, DOI 10.1016/j.nicl.2014.07.003
   Echávarri C, 2011, BRAIN STRUCT FUNCT, V215, P265, DOI 10.1007/s00429-010-0283-8
   Geng Y, 2016, ESANN 2017 P, P589
   Geng YY, 2017, LECT NOTES COMPUT SC, V10614, P539, DOI 10.1007/978-3-319-68612-7_61
   Griffa A, 2013, NEUROIMAGE, V80, P515, DOI 10.1016/j.neuroimage.2013.04.056
   Harrington DL, 2015, BRAIN, V138, P2332, DOI 10.1093/brain/awv145
   Jiao ZQ, 2014, J SUPERCOMPUT, V67, P806, DOI 10.1007/s11227-013-1010-z
   Jiao ZQ, 2018, MULTIMED TOOLS APPL, V77, P22689, DOI 10.1007/s11042-017-5163-2
   Jiao ZQ, 2017, INT J SENS NETW, V24, P90, DOI 10.1504/IJSNET.2017.10005733
   Jiao ZQ, 2017, J MED IMAG HEALTH IN, V7, P407, DOI 10.1166/jmihi.2017.2029
   Jiao ZQ, 2017, FRONT BIOSCI-LANDMRK, V22, P1634, DOI 10.2741/4562
   Jiao ZQ, 2017, CNS NEUROL DISORD-DR, V16, P44, DOI 10.2174/1871527314666161124120040
   Jiao ZQ, 2016, INT J SENS NETW, V21, P197, DOI 10.1504/IJSNET.2016.078374
   Latora V, 2001, PHYS REV LETT, V87, DOI 10.1103/PhysRevLett.87.198701
   Li HJ, 2016, J SYST SCI COMPLEX, V29, P1071, DOI 10.1007/s11424-015-4145-6
   Ma A, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0119678
   Markett S, 2017, CEREB CORTEX, V27, P2166, DOI 10.1093/cercor/bhw059
   Marusak HA, 2017, HUM BRAIN MAPP, V38, P97, DOI 10.1002/hbm.23346
   McColgan P, 2015, BRAIN, V138, DOI 10.1093/brain/awv259
   Nguyen TT, 2017, NEUROPSYCHOLOGY, V31, P73, DOI 10.1037/neu0000317
   Pasquale F. D., 2016, CEREB CORTEX, V26, P878
   Poulin SP, 2011, PSYCHIAT RES-NEUROIM, V194, P7, DOI 10.1016/j.pscychresns.2011.06.014
   Power JD, 2013, NEURON, V79, P798, DOI 10.1016/j.neuron.2013.07.035
   Ray S, 2014, HUM BRAIN MAPP, V35, P6032, DOI 10.1002/hbm.22603
   Rubinov M, 2010, NEUROIMAGE, V52, P1059, DOI 10.1016/j.neuroimage.2009.10.003
   Sheline YI, 2013, BIOL PSYCHIAT, V74, P340, DOI 10.1016/j.biopsych.2012.11.028
   Sporns O, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0001049
   Tobia MJ, 2017, HUM BRAIN MAPP, V38, P6185, DOI 10.1002/hbm.23821
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   van den Heuvel MP, 2011, J NEUROSCI, V31, P15775, DOI 10.1523/JNEUROSCI.3539-11.2011
   Wang JH, 2010, FRONT SYST NEUROSCI, V4, DOI 10.3389/fnsys.2010.00016
   Wang SH, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0932-7
   Wang SH, 2018, MULTIMED TOOLS APPL, V77, P3701, DOI 10.1007/s11042-016-3401-7
   Wang SH, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18050194
   [王鑫 Wang Xin], 2017, [中国图象图形学报, Journal of Image and Graphics], V22, P978
   Wee CY, 2016, BRAIN IMAGING BEHAV, V10, P342, DOI 10.1007/s11682-015-9408-2
   Yao Z., 2012, J U SHANGHAI SCI TEC, V34, P18
   Zhang GH, 2017, LECT NOTES COMPUT SC, V10585, P1, DOI 10.1007/978-3-319-68935-7_1
   Zhang YD, 2016, INT J BIOMEDICAL IMA, V3, P1, DOI 10.1155/2016/9416435
   Zhang Y, 2017, MINERALS-BASEL, V7, DOI 10.3390/min7060102
   Zhang YD, 2016, IEEE ACCESS, V4, P5937, DOI 10.1109/ACCESS.2016.2611530
   Zhang YD, 2017, J AM COLL CARDIOL, V70, pC167, DOI 10.1016/j.jacc.2017.07.613
   Zhang YD, 2016, J ALZHEIMERS DIS, V50, P1163, DOI 10.3233/JAD-150988
   Zhang YD, 2015, PEERJ, V3, DOI 10.7717/peerj.1251
   Zhang YD, 2015, BIOMED SIGNAL PROCES, V21, P58, DOI 10.1016/j.bspc.2015.05.014
   Zhang YD, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00066
   Zhou S, 2004, IEEE COMMUN LETT, V8, P180, DOI 10.1109/LCOMM.2004.823426
   Zhou XX, 2016, IEEJ T ELECTR ELECTR, V11, P364, DOI 10.1002/tee.22226
NR 55
TC 3
Z9 3
U1 4
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15075
EP 15093
DI 10.1007/s11042-018-6424-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900043
DA 2024-07-18
ER

PT J
AU Lin, JY
   Song, XM
   Gan, T
   Yao, YY
   Liu, WF
   Nie, LQ
AF Lin, Junyu
   Song, Xuemeng
   Gan, Tian
   Yao, Yiyang
   Liu, Weifeng
   Nie, Liqiang
TI PaintNet: A shape-constrained generative framework for generating
   clothing from fashion model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image-to-image translation; Domain transfer; Generative adversarial
   networks
AB Recent years have witnessed the proliferation of online fashion blogs and communities, where a large amount of fashion model images with chic clothes in various scenarios are publicly available. To facilitate users to find the corresponding clothes, we focus on studying how to generate pure wellshaped clothing items with the best view from the complex model images. Towards this end, inspired by painting, where the initial sketches and following coloring are both essential, we propose a two-stage shape-constrained clothing generative framework, dubbed as PaintNet. PaintNet comprises two coherent components: shape predictor and texture renderer. The shape predictor is devised to predict the intermediate shape map for the to-be-generated clothing item based on the latent representation learning, while the texture renderer is introduced to generate the final clothing image with the guidance of the predicted shape map. Extensive qualitative and quantitative experiments conducted on the public Lookbook dataset verify the effectiveness of PaintNet in clothing generation from fashion model images. Moreover, we also explore the potential of PaintNet in the task of cross-domain clothing retrieval, and the experiment results show that PaintNet can achieve, on average, 5.34% performance improvement over the traditional non-generative retrieval methods.
C1 [Lin, Junyu; Song, Xuemeng; Gan, Tian; Nie, Liqiang] Shandong Univ, Dept Comp Sci & Technol, Qingdao, Peoples R China.
   [Yao, Yiyang] State Grid Zhejiang Elect Power Co, Hangzhou, Peoples R China.
   [Liu, Weifeng] China Univ Petr, Dept Comp Sci & Technol, Beijing, Peoples R China.
C3 Shandong University; State Grid Corporation of China; China University
   of Petroleum
RP Song, XM (corresponding author), Shandong Univ, Dept Comp Sci & Technol, Qingdao, Peoples R China.
EM sxmustc@gmail.com
RI liu, weifeng/B-7909-2008
FU National Natural Science Foundation of China [61772310, 61702300,
   61702302, 61802231, U1836216]; Project of Thousand Youth Talents 2016;
   Shandong Provincial Natural Science and Foundation [ZR2019JQ23,
   ZR2019QF001]; Young Scholars Program of Shandong University
FX This work is supported by the National Natural Science Foundation of
   China, No.: 61772310, No.:61702300, No.:61702302, No.: 61802231, and No.
   U1836216; the Project of Thousand Youth Talents 2016; the Shandong
   Provincial Natural Science and Foundation, No.: ZR2019JQ23,
   No.:ZR2019QF001; the Young Scholars Program of Shandong University.
CR Abadi Martin, 2016, TENSORFLOW LARGE SCA, V16, P265
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Chen HJ, 2019, PROC CVPR IEEE, P10034, DOI 10.1109/CVPR.2019.01028
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   EMAMI H, 2019, ARXIV190806616
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Ge WF, 2018, LECT NOTES COMPUT SC, V11210, P272, DOI 10.1007/978-3-030-01231-1_17
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hidayati SC, 2018, IEEE T CYBERNETICS, V48, P1647, DOI 10.1109/TCYB.2017.2712634
   Hidayati SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P197, DOI 10.1145/2647868.2656405
   HOFFER E, 2015, INT C LEARN REPR ICL
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Hsieh CW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P275, DOI 10.1145/3343031.3351075
   Huang JS, 2015, IEEE I CONF COMP VIS, P1062, DOI 10.1109/ICCV.2015.127
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jaderberg Max, 2015, ADV NEURAL INFORM PR, P8
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kiapour MH, 2015, IEEE I CONF COMP VIS, P3343, DOI 10.1109/ICCV.2015.382
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Lo L, 2019, IEEE IMAGE PROC, P3222, DOI [10.1109/icip.2019.8803461, 10.1109/ICIP.2019.8803461]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marques O., 2006, Proc. 44th ACM Southeast Regional Conf, P638, DOI DOI 10.1145/1185448.1185588
   Noh H, 2017, IEEE I CONF COMP VIS, P3476, DOI 10.1109/ICCV.2017.374
   Ono Y, 2018, ADV NEUR IN, V31
   Radford A., 2015, ARXIV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salimans T, 2016, ADV NEUR IN, V29
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sonderby C. K., 2017, ICLR
   Song Y, 2017, IEEE INT CONF COMP V, P2243, DOI 10.1109/ICCVW.2017.262
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tian YR, 2017, PROC CVPR IEEE, P6128, DOI 10.1109/CVPR.2017.649
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Wang X, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P7, DOI 10.1145/2911996.2912002
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu BC, 2019, IEEE INT CONF ROBOT, P4376, DOI [10.1109/ICRA.2019.8793495, 10.1109/icra.2019.8793495]
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu YJ, 2018, IEEE T IMAGE PROCESS, V27, P4933, DOI 10.1109/TIP.2018.2846664
   Yoo D, 2016, LECT NOTES COMPUT SC, V9912, P517, DOI 10.1007/978-3-319-46484-8_31
   Yuan YH, 2017, IEEE I CONF COMP VIS, P814, DOI 10.1109/ICCV.2017.94
   Zhang H., 2019, INT C MACHINE LEARNI, P12744, DOI DOI 10.48550/ARXIV.1805.08318
   Zhao J, 2016, 2016 IEEE MTT-S INTERNATIONAL WIRELESS SYMPOSIUM (IWS), DOI 10.1109/ICSSSM.2016.7538614
   ZHAO S, 2020, NAT C ART INT
   Zhao S., 2019, P ADV NEUR INF PROC, P7285
   Zhao SC, 2018, IEEE T CIRC SYST VID, V28, P1839, DOI 10.1109/TCSVT.2017.2682196
   Zhao SC, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1319, DOI 10.1145/3240508.3240591
   Zhao SC, 2019, AAAI CONF ARTIF INTE, P2620
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 56
TC 7
Z9 8
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17183
EP 17203
DI 10.1007/s11042-020-09009-y
EA MAY 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000536743500001
DA 2024-07-18
ER

PT J
AU Zarrabi, H
   Emami, A
   Khadivi, P
   Karimi, N
   Samavi, S
AF Zarrabi, Hamidreza
   Emami, Ali
   Khadivi, Pejman
   Karimi, Nader
   Samavi, Shadrokh
TI BlessMark: a blind diagnostically-lossless watermarking framework for
   medical applications based on deep neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ROI-based watermarking; Blind watermarking; CNN; Fully connected neural
   network; Deep neural network
ID HIGH-CAPACITY; ROBUST; SCHEME; AUTHENTICATION; MACHINE; IMAGES; DWT
AB Nowadays, with the development of public network usage, medical information is transmitted throughout the hospitals. A watermarking system can help for the confidentiality of medical information distributed over the internet. In medical images, regions-of-interest (ROI) contain diagnostic information. The watermark should be embedded only into non-regions-of-interest (NROI) regions to keep diagnostically important details without distortion. Recently, ROI based watermarking has attracted the attention of the medical research community. The ROI map can be used as an embedding key for improving confidentiality protection purposes. However, in most existing works, the ROI map that is used for the embedding process must be sent as side-information along with the watermarked image. This side information is a disadvantage and makes the extraction process non-blind. Also, most existing algorithms do not recover NROI of the original cover image after the extraction of the watermark. In this paper, we propose a framework for blind diagnostically-lossless watermarking, which iteratively embeds only into NROI. The significance of the proposed framework is in satisfying the confidentiality of the patient information through a blind watermarking system, while it preserves diagnostic/medical information of the image throughout the watermarking process. A deep neural network is used to recognize the ROI map in the embedding, extraction, and recovery processes. In the extraction process, the same ROI map of the embedding process is recognized without requiring any additional information. Hence, the watermark is blindly extracted from the NROI. Furthermore, a three-layer fully connected neural network is used for the detection of distorted NROI blocks in the recovery process to recover the distorted NROI blocks to their original form. The proposed framework is compared with one lossless watermarking algorithm. Experimental results demonstrate the superiority of the proposed framework in terms of side information.
C1 [Zarrabi, Hamidreza; Emami, Ali; Karimi, Nader; Samavi, Shadrokh] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
   [Khadivi, Pejman] Seattle Univ, Dept Comp Sci, Seattle, WA 98122 USA.
   [Samavi, Shadrokh] Univ Michigan, Dept Computat Med & Bioinformat, Ann Arbor, MI 48109 USA.
C3 Isfahan University of Technology; Seattle University; University of
   Michigan System; University of Michigan
RP Khadivi, P (corresponding author), Seattle Univ, Dept Comp Sci, Seattle, WA 98122 USA.
EM khadivip@seattleu.edu
RI Karimi, Nader/HWP-4206-2023
OI Karimi, Nader/0000-0001-8904-1607
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   Abdelhakim AM, 2018, EXPERT SYST APPL, V100, P197, DOI 10.1016/j.eswa.2018.02.002
   [Anonymous], MULTIMED TOOLS APPL
   Ansari IA, 2017, MULTIMED TOOLS APPL, V76, P18001, DOI 10.1007/s11042-016-3680-z
   Bamal R, 2018, MULTIMED TOOLS APPL, V77, P12493, DOI 10.1007/s11042-017-4898-0
   Benrhouma O, 2016, MULTIMED TOOLS APPL, V75, P8695, DOI 10.1007/s11042-015-2786-z
   CHAITANYA K, 2018, J THEORETICAL APPL I, V96
   Chao HM, 2002, IEEE T INF TECHNOL B, V6, P46, DOI 10.1109/4233.992161
   Chauhan DS, 2019, MULTIMED TOOLS APPL, V78, P3911, DOI 10.1007/s11042-017-4886-4
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Eswaraiah R, 2015, IET IMAGE PROCESS, V9, P615, DOI 10.1049/iet-ipr.2014.0986
   Etemad E, 2018, MULTIMED TOOLS APPL, V77, P2033, DOI 10.1007/s11042-016-4278-1
   Heidari M, 2017, MULTIMED TOOLS APPL, V76, P23459, DOI 10.1007/s11042-016-4150-3
   Hou DD, 2019, IEEE T CIRC SYST VID, V29, P363, DOI 10.1109/TCSVT.2018.2803303
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jaiswal SP, 2013, IEEE IMAGE PROC, P4540, DOI 10.1109/ICIP.2013.6738935
   Jane O, 2014, J APPL RES TECHNOL, V12, P750, DOI 10.1016/S1665-6423(14)70091-4
   Kandi H, 2017, COMPUT SECUR, V65, P247, DOI 10.1016/j.cose.2016.11.016
   Kelkar V, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/3538979
   KIM WH, 2018, ARXIV180506199
   Liu XY, 2019, IEEE ACCESS, V7, P76580, DOI 10.1109/ACCESS.2019.2921894
   Mehta R, 2017, INT J MACH LEARN CYB, V8, P379, DOI 10.1007/s13042-015-0331-z
   Naik K, 2018, MULTIMED TOOLS APPL, V77, P13721, DOI 10.1007/s11042-017-4986-1
   Nasr-Esfahani E, 2018, BIOMED SIGNAL PROCES, V40, P240, DOI 10.1016/j.bspc.2017.09.012
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   SADREAZAMI H, 2018, IEEE T CIRCUITS SY 2
   Savakar D. G., 2017, Pattern Recognition and Image Analysis, V27, P511, DOI 10.1134/S1054661817030257
   Shih FY, 2018, MULTIMED TOOLS APPL, V77, P1623, DOI 10.1007/s11042-017-4367-9
   Singh RP, 2016, NEUROCOMPUTING, V174, P238, DOI 10.1016/j.neucom.2015.03.115
   Thanki R, 2019, MULTIMED TOOLS APPL, V78, P13905, DOI 10.1007/s11042-018-6746-2
   TIAN J, 2002, P WORKSH MULT SEC
   Turuk MP, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0608-0
   Yang Y, 2018, MULTIMED TOOLS APPL, V77, P18043, DOI 10.1007/s11042-017-4444-0
   ZARRABI H, 2018, ANN INT C IEEE ENG M
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159171
NR 38
TC 5
Z9 6
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22473
EP 22495
DI 10.1007/s11042-020-08698-9
EA MAY 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000534982100001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chakroun, R
   Frikha, M
AF Chakroun, Rania
   Frikha, Mondher
TI Efficient text-independent speaker recognition with short utterances in
   both clean and uncontrolled environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker recognition; Speaker identification; I-vector; PLDA; Short
   utterances; Noise
ID IDENTIFICATION; ROBUSTNESS; MACHINES; FEATURES; MFCC; PLDA; GMM
AB Automatic speaker recognition has emerged as an important technology for voice-based biometric systems. However, text-independent speaker recognition against short utterances remains a challenging task despite of recent advances in the domain of speaker recognition. The presence of background noise presents another critical issue in this field. In this paper, we propose effective features for speaker identification with short utterances, which perform well in both clean and noisy conditions. Speaker identification performance for utterances having very short training and testing durations are presented which provide a clearer description of the proposed system performance. Te proposed features have shown strong robustness in these challenging situations and they consistently perform better than the well known MFCC and GFCC features. The efficiency of the proposed approach was thoroughly tested by comparisons with the most recently successful SVM and i-vector PLDA baseline speaker recognition systems.
C1 [Chakroun, Rania; Frikha, Mondher] Adv Technol Image & Signal Proc ATISP Res Unit, Sfax, Tunisia.
   [Chakroun, Rania] Univ Sfax, Natl Sch Engn sfax, Sfax, Tunisia.
   [Frikha, Mondher] Univ Sfax, Natl Sch Elect & Telecommun Sfax, Sfax, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Sfax
RP Chakroun, R (corresponding author), Adv Technol Image & Signal Proc ATISP Res Unit, Sfax, Tunisia.; Chakroun, R (corresponding author), Univ Sfax, Natl Sch Engn sfax, Sfax, Tunisia.
EM chakrounrania@yahoo.fr; mondher@yahoo.fr
RI FRIKHA, Mondher/IAN-7365-2023
OI FRIKHA, Mondher/0000-0003-2584-5141
CR [Anonymous], 2012, NIST YEAR 2012 SPEAK
   [Anonymous], SPEAK REC EV PLAN
   Campbell WM, 2006, IEEE SIGNAL PROC LET, V13, P308, DOI 10.1109/LSP.2006.870086
   Campbell WM, 2002, INT CONF ACOUST SPEE, P161
   Chakroun R, 2018, IET SIGNAL PROCESS, V12, P873, DOI 10.1049/iet-spr.2016.0572
   Chang J, 2017, INT CONF ACOUST SPEE, P5415, DOI 10.1109/ICASSP.2017.7953191
   Chow D., 2004, 8 INT C SPOK LANG PR
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Disken G, 2017, IETE TECH REV, V34, P321, DOI 10.1080/02564602.2016.1185976
   Dua M, 2019, J AMB INTEL HUM COMP, V10, P2301, DOI 10.1007/s12652-018-0828-x
   Fatima N., 2012, 2012 International Conference on Systems and Informatics (ICSAI 2012), P1746, DOI 10.1109/ICSAI.2012.6223381
   Fedila M, 2017, MULTIMED TOOLS APPL, P1
   Feng L., 2005, A new database for speaker recognition
   Garofolo J. S., 1993, Timit acoustic phonetic continuous speech corpus
   Hansen JHL, 2015, IEEE SIGNAL PROC MAG, V32, P74, DOI 10.1109/MSP.2015.2462851
   Hurmalainen A, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P244
   Islam MA, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0158520
   Jayanna HS, 2009, IET SIGNAL PROCESS, V3, P189, DOI 10.1049/iet-spr.2008.0211
   Kanagasundaram Ahilan, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1665, DOI 10.1109/ICASSP.2014.6853881
   KANAGASUNDARAM A, 2012, SPEAK LANG REC WORKS
   Kanagasundaram A, 2017, INT J SPEECH TECHNOL, V20, P247, DOI 10.1007/s10772-017-9402-8
   Kanagasundaram A, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P2352
   Khosravani A, 2018, COMPUT SPEECH LANG, V52, P105, DOI 10.1016/j.csl.2017.12.009
   Kinnunen T, 2006, IEEE T AUDIO SPEECH, V14, P277, DOI 10.1109/TSA.2005.853206
   Kozlov A, 2013, INT C SPEECH COMP, P278
   Krishnamoorthy P, 2011, EXPERT SYST APPL, V38, P13487, DOI 10.1016/j.eswa.2011.04.069
   Li Q, 2011, IEEE T AUDIO SPEECH, V19, P1791, DOI 10.1109/TASL.2010.2101594
   Li ZY, 2015, MULTIMED TOOLS APPL, V74, P937, DOI 10.1007/s11042-013-1705-4
   Li ZQ, 2016, MULTIMED TOOLS APPL, V75, P7391, DOI 10.1007/s11042-015-2660-z
   Liu JC, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4255
   Liu XY, 2017, INT CONF ACOUST SPEE, P5230, DOI 10.1109/ICASSP.2017.7953154
   Liu ZL, 2018, IEEE T IND INFORM, V14, P3244, DOI 10.1109/TII.2018.2799928
   Manikandan J, 2011, IET SIGNAL PROCESS, V5, P506, DOI 10.1049/iet-spr.2010.0311
   Matza A, 2014, IET SIGNAL PROCESS, V8, P860, DOI 10.1049/iet-spr.2013.0270
   McLaren M, 2010, P OD, P17
   Motlicek P, 2015, INT CONF ACOUST SPEE, P4445, DOI 10.1109/ICASSP.2015.7178811
   Nautsch A., 2016, P OD, P358
   Park SJ, 2017, INTERSPEECH, P1522, DOI 10.21437/Interspeech.2017-157
   Qi J, 2013, INTERSPEECH
   Rahman MH, 2018, COMPUT SPEECH LANG, V47, P240, DOI 10.1016/j.csl.2017.08.001
   Ranjan S, 2017, INTERSPEECH, P3717, DOI 10.21437/Interspeech.2017-1199
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Saeidi R, 2015, 16 ANN C INT SPEECH, V2015, P2015
   Shahamiri SR, 2014, ADV ENG INFORM, V28, P102, DOI 10.1016/j.aei.2014.01.001
   Shao Y, 2008, INT CONF ACOUST SPEE, P1589
   Sholokhov A, 2018, COMPUT SPEECH LANG, V47, P132, DOI 10.1016/j.csl.2017.07.005
   Togneri R, 2011, IEEE CIRC SYST MAG, V11, P23, DOI 10.1109/MCAS.2011.941079
   Turner C, 2015, PROCEDIA COMPUT SCI, V61, P416, DOI 10.1016/j.procs.2015.09.177
   Venkatesan R., 2017, CIRC SYST SIGNAL PR, V37, P1
   Wei YG, 2019, IEEE ACCESS, V7, P166157, DOI 10.1109/ACCESS.2019.2947179
   Young S., 2002, Hidden Markov model toolkit (htk) version 3.4 user's guide
   Zhao XJ, 2014, IEEE-ACM T AUDIO SPE, V22, P836, DOI 10.1109/TASLP.2014.2308398
   Zhao XJ, 2013, INT CONF ACOUST SPEE, P7204, DOI 10.1109/ICASSP.2013.6639061
   Zhao XJ, 2012, IEEE T AUDIO SPEECH, V20, P1608, DOI 10.1109/TASL.2012.2186803
   ZUE V, 1990, SPEECH COMMUN, V9, P351, DOI 10.1016/0167-6393(90)90010-7
NR 55
TC 6
Z9 6
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21279
EP 21298
DI 10.1007/s11042-020-08824-7
EA MAY 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000530173800001
DA 2024-07-18
ER

PT J
AU Dai, CQ
   Peng, C
   Chen, M
AF Dai, Chengqiu
   Peng, Cheng
   Chen, Min
TI Selective transfer cycle GAN for unsupervised person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised person re-identification; Selective transfer; Domain
   adaptation; Part based feature
ID NETWORK
AB Recently, many researchers pay more attention to unsupervised person re-identification (UPRID) due to its scalability and flexibility without any labeled data. The popular methods for UPRID are divided into clustering based and transfer learning based approaches. However, both of them either lack pre-knowledge or some useless knowledge transfered, which always achieves poor matching performance. Specifically, transfer learning based methods can utilize existing labeled data to boost the training of unlabeled data in target domain. Nevertheless, they generally offer weaker re-identification performance because there are a lot of negative images in source domain bringing negative effect on accuracy for the target domain, which is very challenging to address this negative source data removing problem. In this paper, we propose a Selective Transfer Cycle Generative Adversarial Network (STCGAN) by selecting "valuable" source domain knowledge to boost the training efficiency in unlabeled target domain. Our STCGAN approach is developed from a Cycle GAN attached a selector for source data, a part based feature extractor for target data and reconstructed source images following target distribution. Such that it can simultaneously learn "valuable" source images through the selector and exploit transferable discriminative information from these selected source images into target domain. Then, we introduce a joint optimization method and conduct extensively experiments on two widely used person re-identification datasets. The results show the superiority of the proposed STCGAN model over a range of the-state-of-the-arts.
C1 [Dai, Chengqiu; Chen, Min] Hunan Inst Technol, Sch Comp & Informat Sci, 18 Henghua Rd, Hengyang 421002, Peoples R China.
   [Peng, Cheng] Hunan Univ Technol, Sch Comp Sci & Technol, Taishanxi Rd, Zhuzhou 412007, Peoples R China.
C3 Hunan Institute of Technology; Hunan University of Technology
RP Dai, CQ (corresponding author), Hunan Inst Technol, Sch Comp & Informat Sci, 18 Henghua Rd, Hengyang 421002, Peoples R China.
EM daicqhnit@163.com
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2019, P IEEE CVF C COMP VI
   [Anonymous], 2008, 2008 IEEE COMP SOC C
   [Anonymous], 2018, P EUR C COMP VIS ECC
   [Anonymous], 2006, PROC IEEE COMPUT SOC
   Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chen WH, 2017, AAAI CONF ARTIF INTE, P3988
   Chen YC, 2018, IEEE T PATTERN ANAL, V40, P392, DOI 10.1109/TPAMI.2017.2666805
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Jiao SS, 2019, IEEE ACCESS, V7, P90497, DOI 10.1109/ACCESS.2019.2927170
   Khan FM, 2019, IEEE WINT CONF APPL, P2019, DOI 10.1109/WACV.2019.00219
   Kodirov E., 2015, BMVC, DOI DOI 10.5244/C.29.44
   Kodirov E, 2016, LECT NOTES COMPUT SC, V9905, P178, DOI 10.1007/978-3-319-46448-0_11
   Li M, 2019, IEEE T PATTERN ANAL
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2194
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055
   Lu KK, 2018, INT C PATT RECOG, P489, DOI 10.1109/ICPR.2018.8545190
   Lv JM, 2018, PROC CVPR IEEE, P7948, DOI 10.1109/CVPR.2018.00829
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Subramaniam A, 2016, ADV NEUR IN, V29
   Wang H., 2014, ADV MECH ENG, V2014, P587497, DOI [10.1155/2014/587497, DOI 10.1155/2014/587497]
   Wang HX, 2016, LECT NOTES COMPUT SC, V9908, P405, DOI 10.1007/978-3-319-46493-0_25
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wang TQ, 2016, IEEE T PATTERN ANAL, V38, P2501, DOI 10.1109/TPAMI.2016.2522418
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Yu BZ, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.3.033033
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Yu J, 2014, INFORM SCIENCES, V281, P674, DOI 10.1016/j.ins.2014.01.025
   Yu ZX, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4220
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhao R, 2017, IEEE T PATTERN ANAL, V39, P356, DOI 10.1109/TPAMI.2016.2544310
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu X, 2019, Pattern Recognition
NR 48
TC 8
Z9 8
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12597
EP 12613
DI 10.1007/s11042-019-08604-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400059
DA 2024-07-18
ER

PT J
AU Zhang, LY
   Chen, DY
AF Zhang, Lingyu
   Chen, Deyuan
TI The large capacity embedding algorithm for H.264/AVC intra-prediction
   mode video steganography based on linear block code over Z4
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intra-prediction; Video steganography; Linear block code over Z(4); High
   embedding rate; Lee distance
AB The H.264/AVC intra prediction video steganography based on (n,k) linear block code over ring Z(4) is proposed by this paper. On the basis of (n,k) linear block code over Z(4), the property of addition of abelian groups and multiplicative commutative semigroup are utilized to generate the steganography code. Lee distance of linear codes over ring Z(4) is researched, and it makes the equation has unique solution. Furthermore, the optimal performance of the proposed code is proved. The code performance with high embedding rate whose upper bound of embedding rate is reached to 1.33bpp, and the code is applied to video steganography based on intra-prediction mode (IPM-based video steganography). It obtains better performances of security and anti-attack. The average distortion is decreased to 50% and the detection accuracy is decreased to 3-5% with identical embedding rate. Experimental results show that the performance of the proposed scheme is superior to those of the former IPM-based schemes.
C1 [Zhang, Lingyu] Liaoning Shihua Univ, Fac Sch Comp & Commun Engn, Fushun 113001, Liaoning, Peoples R China.
   [Chen, Deyuan] Univ Chinese Acad Sci, Fac Sch Elect Elect & Commun Engn, Beijing 100093, Peoples R China.
C3 Liaoning Petrochemical University; Chinese Academy of Sciences;
   University of Chinese Academy of Sciences, CAS
RP Zhang, LY (corresponding author), Liaoning Shihua Univ, Fac Sch Comp & Commun Engn, Fushun 113001, Liaoning, Peoples R China.
EM 6628019@qq.com
RI Zhang, Lingyu/AAE-4891-2022; Chen, Deyuan/HGA-6403-2022
OI Zhang, Lingyu/0000-0002-5035-6369; 
CR Abdallah EE, 2007, LECT NOTES COMPUT SC, V4633, P772
   Abdallah EE, 2010, SIGNAL IMAGE VIDEO P, V4, P233, DOI 10.1007/s11760-009-0114-7
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Bouchama S, 2012, LECT NOTES ENG COMP, P655
   Nguyen DC, 2019, MULTIMED TOOLS APPL, V78, P16033, DOI 10.1007/s11042-018-6976-3
   Filler T., 2010, P SPIE INT SOC OPT E, P175
   Fu ZY, 2007, INFORM THEORY
   Golea Nour El-Houda, 2019, International Journal of High Performance Computing and Networking, V13, P199
   Golomb S. W., 1968, Error correcting codes, P175
   Heo J, 2010, IEEE T CIRC SYST VID, V20, P213, DOI 10.1109/TCSVT.2009.2031392
   Hongyong Ji, 2019, International Journal of High Performance Computing and Networking, V14, P1
   Hu Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1231
   Hui X, 2004, MODERN TELECOMMUNICA
   Joohyeok Kim, 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P655, DOI 10.1109/DICTA.2011.116
   Kapotas SK, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P373, DOI 10.1109/MMSP.2007.4412894
   Ker AD, 2007, IEEE SIGNAL PROC LET, V14, P525, DOI 10.1109/LSP.2006.891319
   Kim Y, 2007, LECT NOTES COMPUT SC, V4437, P314
   LEE CY, 1958, IRE T INFORM THEOR, V4, P77, DOI 10.1109/TIT.1958.1057446
   Li SB, 2014, ANN TELECOMMUN, V69, P461, DOI 10.1007/s12243-013-0381-8
   Ma S, 2018, MULTIMED TOOLS APPL, V77, P17889, DOI 10.1007/s11042-017-4955-8
   Petty T., 2016, Handbook of Research on Professional Development for Quality Teaching and Learning
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu DW, 2012, J REAL-TIME IMAGE PR, V7, P205, DOI 10.1007/s11554-010-0175-4
   Yang GB, 2011, AEU-INT J ELECTRON C, V65, P331, DOI 10.1016/j.aeue.2010.03.011
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang H, 2017, IEEE T INF FOREN SEC, V12, P465, DOI 10.1109/TIFS.2016.2623587
   Zhang H, 2016, MULTIMED TOOLS APPL, V75, P13503, DOI 10.1007/s11042-015-2743-x
   Zhang L., 2016, PROC 15 INTWORKSHOP, P518
   Zhang LY, 2015, IEEE I C EMBED SOFTW, P1274, DOI 10.1109/HPCC-CSS-ICESS.2015.62
   Zhang YN, 2017, TSINGHUA SCI TECHNOL, V22, P198
   Zhao X, 2018, THEORY TECHNOLOGY ST, P51
   ZHAO Y, 2015, PROC INT WORKSHOP DI, P119
NR 33
TC 3
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12659
EP 12677
DI 10.1007/s11042-019-08528-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400062
DA 2024-07-18
ER

PT J
AU Liu, DSM
   Cheng, CI
   Liu, ML
AF Liu, Damon Shing-Min
   Cheng, Ching-, I
   Liu, Mei-Lin
TI Animating characters in Chinese painting using two-dimensional
   skeleton-based deformation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skeleton-based animation; 2D character animation; Character deformation;
   Chinese painting; Sample point allocation; Sample point distribution
AB Chinese painting is always a kind of resource to explore ancient Chinese dynasties and the ideology of painters. Nowadays, more and more Chinese-antique museums have created corresponding animations from Chinese painting for representing daily life of ancient Chinese and providing immersive experience to attract visitors. However, it is not easy to produce animation sequences directly from Chinese paintings. It is laborious and time-consuming to build every motion of animated characters in Chinese painting. Since the irregular borders of characters in Chinese painting are torn and the connectivity of stroke line will be lost while implementing deformation. This research therefore presents a procedure of generating Chinese painting animation sequences to overcome these problems. It focuses on two technical issues: sample point processing and animation generation. Sample point distribution and allocation are the major tasks in sample pint processing. A point distribution method is proposed to preserve connectivity of stroke line of object and a weight scheme is implemented to decide control bone of individual sample points. For the stage of animation, the skeleton-based deformation is firstly used to generate key frames through user-provided skeleton. Then an interpolation method is exploited to create smooth animations. The proposed scheme could also be applied to multiple-character and multiple-skeleton animations.
C1 [Liu, Damon Shing-Min; Liu, Mei-Lin] Natl Chung Cheng Univ, 168 Univ Rd, Chiayi 621, Taiwan.
   [Cheng, Ching-, I] Southern Taiwan Univ Sci & Technol, 1 Nan Tai St, Tainan 710, Taiwan.
C3 National Chung Cheng University; Southern Taiwan University of Science &
   Technology
RP Cheng, CI (corresponding author), Southern Taiwan Univ Sci & Technol, 1 Nan Tai St, Tainan 710, Taiwan.
EM damon@cs.ccu.edu.tw; chingi720@gmail.com; gtsitm@gmail.com
FU Ministry of Science and Technology of Taiwan
   [MOST104-2221-E-194-042-MY2]
FX This work of Professor Damon Shing-Min Liu was supported in part by the
   Ministry of Science and Technology of Taiwan under grant number
   MOST104-2221-E-194-042-MY2, while Dr. Ching-I Cheng and Ms. Mei-Lin Liu
   has no conflict of interest.
CR [Anonymous], 2011, ACM Transactions on Graphics, DOI DOI 10.1145/2010324.1964973
   Bai X, 2007, IEEE T PATTERN ANAL, V29, P449, DOI 10.1109/TPAMI.2007.59
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Delaunay B., 1934, IZV AKAD NAUK SSSR O, V7, P1
   Delmas P, 2015, GEOMETRIC OPERATIONS
   Dong LX, 2014, MULTIMED TOOLS APPL, V69, P605, DOI 10.1007/s11042-012-1126-9
   James DL, 2005, ACM T GRAPHIC, V24, P399, DOI 10.1145/1073204.1073206
   Junjun Pan, 2011, Transactions on Edutainment VI, P164, DOI 10.1007/978-3-642-22639-7_17
   Lai YC, 2017, IEEE T VIS COMPUT GR, V23, P2535, DOI 10.1109/TVCG.2016.2622269
   Lee TY, 2008, IEEE T VIS COMPUT GR, V14, P382, DOI 10.1109/TVCG.2007.70432
   Manli Yuan, 2007, Proceedings Graphics Interface 2007, P57, DOI 10.1145/1268517.1268529
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Schaefer S, 2006, ACM T GRAPHIC, V25, P533, DOI 10.1145/1141911.1141920
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   Serra J., 1983, IMAGE ANAL MATH MORP
   Shen W, 2011, PATTERN RECOGN, V44, P196, DOI 10.1016/j.patcog.2010.08.021
   Tang F, 2018, IEEE T VIS COMPUT GR, V24, P3019, DOI 10.1109/TVCG.2017.2774292
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Wang X, 2013, VISUAL COMPUT, V29, P545, DOI 10.1007/s00371-013-0817-1
   Wolberg G., 1989, Visual Computer, V5, P95, DOI 10.1007/BF01901485
   Wolberg G., 1990, Digital image warping
   Xin Feng, 2010, Proceedings of the Third International Joint Conference on Computational Sciences and Optimization (CSO 2010), P447, DOI 10.1109/CSO.2010.32
   Xu SH, 2006, ACM T GRAPHIC, V25, P239, DOI 10.1145/1138450.1138454
   Yan HB, 2008, IEEE T VIS COMPUT GR, V14, P693, DOI 10.1109/TVCG.2008.28
   Yang L, 2015, LECT NOTES COMPUTER, V8971
   ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023
NR 26
TC 1
Z9 1
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 20343
EP 20371
DI 10.1007/s11042-020-08842-5
EA APR 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000558430400006
DA 2024-07-18
ER

PT J
AU Chen, JY
   Yang, GB
   Zhao, HH
   Ramasamy, M
AF Chen, Jiyou
   Yang, Gaobo
   Zhao, Huihuang
   Ramasamy, Manimaran
TI Audio style transfer using shallow convolutional networks and random
   filters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio style transfer; Continuous wavelet transfer; Deep neural network;
   Spectrogram
AB Recently, with the advent of Convolutional Neural Network (CNN) era, Neural style transfer on images has become a very active research topic and the style of an image can be transferred to another image through a CNN so that the image retains both its own content and another style of image. In this work, we propose an algorithm for audio style transfer that uses the force of CNN to generate a new audio from a style audio. We use Continuous Wavelet Transfer(CWT) to convert the audio into a spectrogram and then use the spectrogram as the representation of the audio image through image style transfer method to obtain a new image, and finally, generate an audio using iterative phase reconstruction with Griffin-Lim. We succeed in transferring audio such as light music but had difficulty in transferring audio that has lyrics and high-level metrics such as emotion or tone. We propose several measures to improve the quality of audio and a lot of experimental results shows that our method is better than other methods in terms of sound quality.
C1 [Chen, Jiyou; Yang, Gaobo] Hunan Univ, Coll Informat Sci & Engn, Changsha 410082, Peoples R China.
   [Chen, Jiyou; Zhao, Huihuang; Ramasamy, Manimaran] Hengyang Normal Univ, Hunan Prov Key Lab Intelligent Informat Proc & Ap, Hengyang 421002, Peoples R China.
C3 Hunan University; Hengyang Normal University
RP Zhao, HH (corresponding author), Hengyang Normal Univ, Hunan Prov Key Lab Intelligent Informat Proc & Ap, Hengyang 421002, Peoples R China.
EM happyday.huihuang@gmail.com
FU National Natural Science Foundation of China [61503128, 61772179];
   Science and Technology Plan Project of Hunan Province [2016TP1020];
   Scientific Research Fund of Hunan Provincial Education Department
   [16C0226, 17C0223, 18A333]; Scientific Research Fund of Hunan Provincial
   Key Laboratory of Intelligent Information Processing and Application
   [IIPA19K05]
FX This work was supported by National Natural Science Foundation of China
   (61503128, 61772179), Science and Technology Plan Project of Hunan
   Province (2016TP1020), Scientific Research Fund of Hunan Provincial
   Education Department (16C0226, 17C0223, and 18A333), Scientific Research
   Fund of Hunan Provincial Key Laboratory of Intelligent Information
   Processing and Application (IIPA19K05). We would like to thank NVIDIA
   for the GPU donation.
CR [Anonymous], 2016, ARXIV160600021
   [Anonymous], 2016, Audio texture synthesis and style transfer
   Aytar Y., 2016, Advances in neural information processing systems (NeurIPS), V29, P892
   BARRY S, 2018, STYLE TRANSFER UNPUB
   Brunner Gino, 2018, ARXIV180907600, P747
   Ephrat A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201357
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Giurgiutiu V., 2003, Proceedings of 4th International Workshop on Structural Health Monitoring, P1267
   GRIFFIN DW, 1984, IEEE T ACOUST SPEECH, V32, P236, DOI 10.1109/TASSP.1984.1164317
   Grinstein E, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P586, DOI 10.1109/ICASSP.2018.8461711
   He Kun, 2016, NeurIPS, P631
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lu HM, 2018, MULTIMED TOOLS APPL, V77, P21847, DOI 10.1007/s11042-017-4585-1
   Lu HM, 2019, IEEE WIREL COMMUN, V26, P90, DOI 10.1109/MWC.2019.1800325
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   MITAL PK, 2017, ARXIV171111160
   NASH J, 1951, ANN MATH, V54, P286, DOI 10.2307/1969529
   Shih YC, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508419
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   VERMA P, 2018, ARXIV180101589
   Wyse L., 2017, P 1 INT C DEEP LEARN, P37
   Xu X, 2019, SIGNAL PROCESS, V164, P354, DOI 10.1016/j.sigpro.2019.05.022
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Xu X, 2016, NEUROCOMPUTING, V213, P191, DOI 10.1016/j.neucom.2015.11.133
   Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236
NR 27
TC 6
Z9 6
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15043
EP 15057
DI 10.1007/s11042-020-08798-6
EA APR 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000524392000002
DA 2024-07-18
ER

PT J
AU Nair, LR
   Subramaniam, K
   Venkatesan, GKDP
AF Nair, Lakshmi R.
   Subramaniam, Kamalraj
   Venkatesan, G. K. D. Prasanna
TI An effective image retrieval system using machine learning and fuzzy c-
   means clustering approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image retrieval; feature extraction; deep learning; correlation
   analysis; support vector machine
AB Recently, Content-based medical image retrieval (CBMIR) systems enable fast diagnosis via the assessment of the visual information in medical application. Most of the state-of-the-art CBMIR systems facing few issues: computationally expensive due to the usage of high dimensional feature vectors and complex classifier/clustering approaches. The reasons behind this are, inability to properly handle the "semantic gap" and the high intra-class versus inter-class variability problem of the medical image database (like radiographic image database). This yields a crucial demand for developing computationally efficient and highly effective retrieval system. For this purpose, the present study proposed an efficient retrieval system which has a four-fold: First, pre-processing and Feature extraction of input image using canonical correlation analysis (CCA). By this approach extracted the feature in both pixel and feature domains and examined more rigorously. Second, applied Fuzzy C means clustering of pixel intensity values as features based on the singular value decomposition. Through this can grouping, the image based on the pixel intensity value. Third, deep convolutional neural network with SVM classifier which makes implementable and requires only a compact feature vector representation of the stored database image with their class levels during retrieval. Finally evaluated the performance based on the measure of Mean Average Precision, Correct rate (CR), Error rate (ER), Accuracy. The classification results and learned features are used for the purpose of retrieving the medical images in a database. The proposed retrieval system performs better than the traditional approach in terms of measuring average value of precision, recall, f-measure and accuracy 95.9%, 94.96%, 95.37% and 95.798% respectively. The suggested approach is best suited towards retrieving the medical images for various part of the body.
C1 [Nair, Lakshmi R.] Karpagam Acad Higher Educ, Dept Elect & Commun Engn, Coimbatore, Tamil Nadu, India.
   [Subramaniam, Kamalraj] Karpagam Acad Higher Educ, Dept Elect & Commun Engn, Coimbatore, Tamil Nadu, India.
   [Venkatesan, G. K. D. Prasanna] Karpagam Acad Higher Educ, Coimbatore, Tamil Nadu, India.
C3 Karpagam Academy of Higher Education (KAHE); Karpagam Academy of Higher
   Education (KAHE); Karpagam Academy of Higher Education (KAHE)
RP Nair, LR (corresponding author), Karpagam Acad Higher Educ, Dept Elect & Commun Engn, Coimbatore, Tamil Nadu, India.
EM lakshmi688@gmail.com; kamalrajece@gmail.com; prasphd@gmail.com
RI Subramaniam, Kamalraj/B-4069-2019; d, p/GWC-4283-2022; VENKATESAN,
   PRASANNA/V-5828-2018
OI Dhayanithi, Dr. Prasanna Venkatesh/0000-0001-6339-2142; VENKATESAN,
   PRASANNA/0000-0002-0638-1938
CR [Anonymous], J ADV RES DYNAMICAL
   [Anonymous], PAK J BIOTECHNOL
   [Anonymous], 2013, OVERFEAT INTEGRATED
   [Anonymous], EFFICIENT ANAL SATEL
   [Anonymous], 2010 INT C COMP MECH
   Cheng ZY, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1069, DOI 10.1145/2911451.2914765
   Cui CR, 2017, J VIS COMMUN IMAGE R, V48, P367, DOI 10.1016/j.jvcir.2017.03.011
   Divya BS, 2020, IETE J RES, V66, P30, DOI 10.1080/03772063.2018.1474810
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hwang KH, 2012, HEALTHC INFORM RES, V18, P3, DOI 10.4258/hir.2012.18.1.3
   Jensen R, 2009, IEEE T FUZZY SYST, V17, P824, DOI 10.1109/TFUZZ.2008.924209
   Kannan SR, 2010, COMPUT BIOL MED, V40, P572, DOI 10.1016/j.compbiomed.2010.04.001
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Khatami A, 2018, APPL SOFT COMPUT, V63, P197, DOI 10.1016/j.asoc.2017.11.024
   Khatami A, 2017, EXPERT SYST APPL, V86, P190, DOI 10.1016/j.eswa.2017.05.073
   Khatami A, 2016, LECT NOTES COMPUT SC, V9949, P467, DOI 10.1007/978-3-319-46675-0_51
   Kumar A, 2013, J DIGIT IMAGING, V26, P1025, DOI 10.1007/s10278-013-9619-2
   Kundu MK, 2017, COMPUT METH PROG BIO, V139, P209, DOI 10.1016/j.cmpb.2016.10.023
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li ZY, 2018, MED IMAGE ANAL, V43, P66, DOI 10.1016/j.media.2017.09.007
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Lotfabadi MS, 2013, PROCEEDINGS OF THE 2013 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE FOR MULTIMEDIA, SIGNAL AND VISION PROCESSING (CIMSIVP), P42, DOI 10.1109/CIMSIVP.2013.6583846
   Müller H, 2004, PRO BIOMED OPT IMAG, V5, P99
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Nie XS, 2013, SCI CHINA INFORM SCI, V56, DOI 10.1007/s11432-012-4760-y
   Paulraj MP, 2014, 2014 IEEE CONFERENCE ON BIOMEDICAL ENGINEERING AND SCIENCES (IECBES), P991, DOI 10.1109/IECBES.2014.7047661
   Qayyum A, 2017, NEUROCOMPUTING, V266, P8, DOI 10.1016/j.neucom.2017.05.025
   Quellec G, 2010, MED IMAGE ANAL, V14, P227, DOI 10.1016/j.media.2009.11.004
   Rahman MM, 2011, IEEE T INF TECHNOL B, V15, P640, DOI 10.1109/TITB.2011.2151258
   Rasiwasia N, 2014, JMLR WORKSH CONF PRO, V33, P823
   Scott G, 2007, IEEE T INF TECHNOL B, V11, P320, DOI 10.1109/TITB.2006.880551
   Subrahmanyam M, 2012, SIGNAL PROCESS, V92, P1467, DOI 10.1016/j.sigpro.2011.12.005
   Subramaniam KHRN, 2018, J AMBIENT INTELL HUM, V02, P1
   Velmurugan K., 2011, Int. J. Comput. Appl, V24, P6, DOI 10.5120/2968-3968
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wu GX, 2016, NEUROCOMPUTING, V175, P310, DOI 10.1016/j.neucom.2015.10.064
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhao SY, 2009, IEEE T FUZZY SYST, V17, P451, DOI 10.1109/TFUZZ.2009.2013204
   Zhou SS, 2013, NEUROCOMPUTING, V120, P536, DOI 10.1016/j.neucom.2013.04.017
NR 40
TC 7
Z9 7
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10123
EP 10140
DI 10.1007/s11042-019-08090-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600021
DA 2024-07-18
ER

PT J
AU Wang, C
   Feng, G
   Cai, CT
   Han, X
   Cao, HY
AF Wang, Chi
   Feng, Gui
   Cai, Chunting
   Han, Xue
   Cao, Haiyan
TI Multi-strategy depth intra mode decision algorithm in 3D-HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D-HEVC; MVD; Depth maps; Computational complexity; Intra mode
ID VIDEO
AB The new generation of 3D video coding standard, denoted as 3D High Efficiency Video Coding (3D-HEVC), uses Multi-view Video Plus Depth (MVD) format to represent stereo videos. Due to the reason that the fringe information of depth maps has great influence on the video quality of synthesized views, Depth Modeling Modes (DMMs) are introduced to maintain the quality of depth maps, while causing computational complexity increase tremendously. Therefore, a multi-strategy depth intra mode decision algorithm is proposed in this paper. It incorporates early rough mode decision (RMD) termination strategy, candidate mode reduction strategy and fast DMM decision strategy. The experimental results indicate that the proposed algorithm can obtain an average encoding time reduction of 34.38% for depth map coding, with just 0.43% BDBR increase.
C1 [Wang, Chi; Feng, Gui; Cai, Chunting; Han, Xue; Cao, Haiyan] Huaqiao Univ, Coll Informat Sci & Engn, Xiamen 361021, Peoples R China.
C3 Huaqiao University
RP Feng, G (corresponding author), Huaqiao Univ, Coll Informat Sci & Engn, Xiamen 361021, Peoples R China.
EM 929854291@qq.com; fengg@hqu.edu.cn; 931564639@qq.com; 1766502281@qq.com;
   1156957638@qq.com
CR [Anonymous], 2001, VCEGM33
   [Anonymous], 2015, 2015 IEEE 13 BRAZ PO, DOI DOI 10.1109/COBEP.2015.7420203
   [Anonymous], 2014, Doc. JCT3V-G1100
   Chen J, 2017, J VIS COMMUN IMAGE R, V48, P329, DOI 10.1016/j.jvcir.2017.05.006
   Correa G, 2015, IEEE T CIRC SYST VID, V25, P660, DOI 10.1109/TCSVT.2014.2363753
   Ding HC, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEMS (ICCS), P1, DOI 10.1109/ICCS.2014.7024754
   Fan J, 2016, INT C ART INT IND EN
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Fu CH, 2017, IEEE IMAGE PROC, P4018, DOI 10.1109/ICIP.2017.8297037
   G. Tech, 2013, JCT3VC1005 JCTVC
   Gu ZY, 2013, IEEE INT CONF MULTI
   Guo LL, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P328, DOI 10.1109/SIPROCESS.2016.7888278
   Kauff P, 2007, SIGNAL PROCESS-IMAGE, V22, P217, DOI 10.1016/j.image.2006.11.013
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Duch M, 2018, MULTIMED TOOLS APPL, V77, P19869, DOI 10.1007/s11042-017-5409-z
   Merkle P, 2013, IEEE INT CON MULTI
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Park CS, 2015, IEEE T IMAGE PROCESS, V24, P155, DOI 10.1109/TIP.2014.2375653
   Sánchez-Marín G, 2019, INT J HUM RESOUR MAN, V30, P1084, DOI 10.1080/09585192.2017.1289547
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sze V, 2014, Integr. Circ. Syst. Algor. Archit, V39, P40
   Zhang HB, 2018, IEEE T CIRC SYST VID, V28, P513, DOI 10.1109/TCSVT.2016.2612693
   Zhang HB, 2015, ASIAPAC SIGN INFO PR, P374, DOI 10.1109/APSIPA.2015.7415297
   Zhang QW, 2014, ELECTRON LETT, V50, P994, DOI 10.1049/el.2014.0065
   Zhang QW, 2011, J ELECT INF TECHNOL, V33, P2541, DOI [10.3724/SP.J.1146.2011.00218, DOI 10.3724/SP.J.1146.2011.00218]
NR 26
TC 2
Z9 2
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8841
EP 8861
DI 10.1007/s11042-019-7715-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600025
DA 2024-07-18
ER

PT J
AU Zhang, H
   Wei, ZQ
AF Zhang, Han
   Wei, Ziqin
TI Risk management of commodity trade business based on deep learning and
   parallel processing of visual multimedia big data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Risk management; Commodity trade business; Deep learning; Parallel
   processing; Visual multimedia big data
ID ANALYTICS
AB In order to solve the problems of low execution efficiency, big data error in risk analysis and high resource consumption in risk management of commodity trade business, this paper designs a feasible and credible risk management scheme of commodity trade business based on in-depth learning and parallel big data processing, combined with visual multimedia scheme. Based on the in-depth study of commodity trade data model, this paper extracts the features of visualized multimedia data of commodity trade business, which ensures that the extracted features adapt to dynamic and changeable diversified business. Then, this paper designs a commodity trade business management platform, which can provide dynamic migration support for the visualized multimedia data of commodity trade business. Therefore, this paper puts forward a management mechanism that can deal with the risks of commodity trade business. Finally, the simulation experiments prove the rationality and advantages of the proposed algorithm in terms of the accuracy of risk analysis, the efficiency of visual multimedia data processing and the effectiveness of commodity trade business management.
C1 [Zhang, Han; Wei, Ziqin] Anyang Inst Technol, Coll Comp Sci & Informat Engn, Anyang, Henan, Peoples R China.
C3 Anyang Institute of Technology
RP Zhang, H (corresponding author), Anyang Inst Technol, Coll Comp Sci & Informat Engn, Anyang, Henan, Peoples R China.
EM 370616261@qq.com
CR Ascherio A, 2016, LANCET NEUROL, V15, P1255, DOI 10.1016/S1474-4422(16)30230-7
   Benson D, 2016, ENVIRON SCI POLICY, V55, P326, DOI 10.1016/j.envsci.2015.05.013
   Broll U, 2017, IMA J MANAG MATH, V28, P245, DOI 10.1093/imaman/dpv019
   Chen X, 2018, IEEE T LEARN TECHNOL, V11, P81, DOI 10.1109/TLT.2017.2757481
   Chen YZ, 2018, IEEE T VIS COMPUT GR, V24, P45, DOI 10.1109/TVCG.2017.2745083
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Choi HG, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-20374-5
   Crouser RJ, 2017, IEEE INTERNET COMPUT, V21, P72, DOI 10.1109/MIC.2017.2911428
   Giannakis Mihalis, 2016, International Journal of Production Economics, V171, P455, DOI 10.1016/j.ijpe.2015.06.032
   Kallenberg M, 2016, IEEE T MED IMAGING, V35, P1322, DOI 10.1109/TMI.2016.2532122
   Kharrazi A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171184
   Kharrazi A, 2015, J IND ECOL, V19, P805, DOI 10.1111/jiec.12328
   Kocoloski B, 2016, IEEE T PARALL DISTR, V27, P468, DOI 10.1109/TPDS.2015.2397452
   Lee I, 2016, IEEE T BROADCAST, V62, P35, DOI 10.1109/TBC.2015.2492469
   Li Q, 2017, IEEE SYST J, V11, P1526, DOI 10.1109/JSYST.2016.2540648
   Liu W, 2016, IEEE MULTIMEDIA, V23, P75, DOI 10.1109/MMUL.2016.39
   Qiu JF, 2016, EURASIP J ADV SIG PR, DOI 10.1186/s13634-016-0355-x
   Rezník T, 2017, ISPRS INT J GEO-INF, V6, DOI 10.3390/ijgi6080238
   Tauer J, 2014, AGR EC, V60, P174
   Uddin J, 2016, MULTIMED TOOLS APPL, V75, P15365, DOI 10.1007/s11042-014-2013-3
   Wang B, 2018, IEEE T BIG DATA, V4, P396, DOI 10.1109/TBDATA.2016.2599933
   Wang CL, 2018, COMPUT SCI ENG, V20, P93, DOI 10.1109/MCSE.2018.011111131
   Worring M, 2016, IEEE T MULTIMEDIA, V18, P2217, DOI 10.1109/TMM.2016.2614380
   Zhang T, 2018, IEEE T WIREL COMMUN, V17, P7879, DOI 10.1109/TWC.2018.2872551
   Zou Y, 2017, SAFETY SCI, V97, P88, DOI 10.1016/j.ssci.2015.12.027
NR 25
TC 3
Z9 3
U1 4
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9331
EP 9349
DI 10.1007/s11042-019-7508-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600055
DA 2024-07-18
ER

PT J
AU Al-kateeb, ZN
   Mohammed, SJ
AF Al-kateeb, Zeena N.
   Mohammed, Saja J.
TI A novel approach for audio file encryption using hand geometry
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption audio file encryption; Biometrics; Hand geometry; Discrete
   wavelet transforms; Decryption
ID NETWORK
AB This paper suggests a new proposed algorithm for encryption/ decryption audio files based on discrete wavelet transform (DWT) and biometric features to provide a high level of confidentiality and reliability. The proposed algorithm used number of hand geometry measurements properties as keys to encode and decode the audio file, combine with using the discrete wavelet transform (DWT) in order to increase the efficiency of the encryption process. Subjective and objective measures are applied to the resulted signal. They cleared that the retrieved audio signal has very acceptable loosing of its data with certain keeping the main decrypted message in a good understanding on the receiver side. This achieves the major target of encryption processing.
C1 [Al-kateeb, Zeena N.; Mohammed, Saja J.] Univ Mosul, Coll Comp Sci & Math, Dept Comp Sci, Mosul, Iraq.
C3 University of Mosul
RP Al-kateeb, ZN (corresponding author), Univ Mosul, Coll Comp Sci & Math, Dept Comp Sci, Mosul, Iraq.
EM zeenaalkateeb@yahoo.com
RI Al-kateeb, Zeena N./AAM-2750-2020; Mohammed, Saja J./ADO-5964-2022
OI Mohammed, Saja J./0000-0002-3857-8057; Al-kateeb,
   Zeena/0000-0002-6440-3824
CR Akgul A, 2015, ONLINE J SCI TECHNOL, V5
   AL-Azzawi S., 2019, Telecommunication Computing Electronics and Control, V17.4, P1931
   Al-Azzawi SF, 2018, ALEX ENG J, V57, P3493, DOI 10.1016/j.aej.2017.11.017
   Al-Azzawi SF, 2012, APPL MATH COMPUT, V219, P1144, DOI 10.1016/j.amc.2012.07.022
   Al-Kateeb ZN, 2019, TIKRIT J PURE SCI, V24, P111
   Al-Obeidi AS., 2019, INDONESIAN J ELECT E, V16, P692, DOI DOI 10.11591/IJEECS.V16.I2.PP692-700
   Albahrani Ekhlas Abbas, 2017, 2017 Annual Conference on New Trends in Information & Communications Technology Applications (NTICT), P22, DOI 10.1109/NTICT.2017.7976129
   [Anonymous], 2012, INT J COMPUT APPL
   Arul P, 2009, J THEOR APPL INF TEC
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Cahyono JSubiono, 2016, C P 6 ANN BAS SCI IN
   Chadha A, 2015, INT J COMPUTER APPL, V116, P975
   Djebbar F, 2012, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2012-25
   Gad R, 2015, INT J ADV COMPUT SC, V6, P128
   Gadanayak B., 2011, INT J COMPUTER SCI I, V2, P1584
   Gadanayak B., 2011, INT J COMPUT APPL, V26, P28
   Gandhi R A, 2015, INT J COMPUT APPL, V116
   Hemalatha S, 2015, INT J APPL ENG RES, V10, P36639
   Kahn D., 1980, IEEE Communications Magazine, V18, P19, DOI 10.1109/MCOM.1980.1090200
   Kisasondi T, 2007, J INF ORGAN SCI, V31, P91
   Kordov K, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8050530
   Osaghae E. O., 2018, Journal of Applied Sciences & Environmental Management, V22, P1193, DOI 10.4314/jasem.v22i8.8
   Prabu AV, 2012, INT J COMPUTER APPL, V40, P8975
   Radha N, 2011, INDIAN J COMPUTER SC, V2, P917
   Rungta PD, 2015, EPL-EUROPHYS LETT, V112, DOI 10.1209/0295-5075/112/60004
   Sharma P., 2013, THESIS
   Sheela SJ, 2017, HINDAWI J COMPUTER N, V2017, P12
   Sheetal S., 2013, INT J ADV RES COMPUT, V3, P79
   Singh K, 2015, C C EM FUT TRENDS EN, V1, DOI [10.2139/ssrn.2777942, DOI 10.2139/SSRN.2777942]
   Streijl RC, 2016, MULTIMED SYST
   Tamimi AA, 2014, P WWORLD C ENG COMP
NR 31
TC 21
Z9 24
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19615
EP 19628
DI 10.1007/s11042-020-08869-8
EA MAR 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000521930200003
DA 2024-07-18
ER

PT J
AU Lee, MC
   Chiang, SY
   Yeh, SC
   Wen, TF
AF Lee, Ming-Che
   Chiang, Shu-Yin
   Yeh, Sheng-Cheng
   Wen, Ting-Feng
TI Study on emotion recognition and companion Chatbot using deep neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chatbot; Emotion recognition; Convolutional neural network; Recurrent
   neural network; Seq2SeqIntroduction
AB With the development of technology, the importance of the research on speech emotion recognition and semantic analysis has increased. The research is primarily applied in companion robot, technology products and medical purpose. In this research, a communication system with speech emotion recognition is proposed. The system pre-process speech with sound data enhancing method in speech emotion recognition and transform the sound into spectrogram by MFCC (Mel Frequency Cepstral Coefficient). Then, GoogLeNet of CNN (Convolutional Neural Network) is applied to recognize the five emotions, which are peace, happy, sad, angry and fear, and the top accuracy of recognition is 79.81%. When applying semantic analysis, the training texts are divided into two categories, positive and negative, and the chatting conversations are conducted in the framework Seq2Seq of RNN (Recurrent Neural Network). The systematic framework of this research has two parts, the client and the server. The former one is developed on Android system to be used in Application, and the latter one is established by Ubuntu Linux system and combined with the web server. With the bi-terminal framework system, the users can record voice in APP one his/her cellphone and upload the voice file to the server. Then, the voice undergoes speech emotion recognition by CNN and semantic analysis by RNN to function as a chatting machine that can respond positively or negatively based on the detected emotion and show the results on APP of the user's cell phone. The main contributions of this research are: 1) This study introduces the Chinese word vector to the robot dialogue system, effectively improving dialogue tolerance and semantic interpretation, 2) The traditional method of emotion identification must first tokenize the Chinese words, analyze the clauses and part of speech, and capture the emotional keywords before being interpreted by the expert system. Different from the traditional method, this study classifies the input directly through the convolutional neural network after the input sentence is converted into a spectrogram by MFCC, and 3) in addition to implementing the companion robot, the user's emotional index can be collected for analysis by the back-end care organization. In addition, compared with other commercial humanoid companion robots, this study is presented in an App, which is easier to use and economical.
C1 [Lee, Ming-Che; Yeh, Sheng-Cheng; Wen, Ting-Feng] Ming Chuan Univ, Dept Comp & Commun Engn, Taoyuan 333, Taiwan.
   [Chiang, Shu-Yin] Ming Chuan Univ, Dept Informat & Telecommun Engn, Taoyuan 333, Taiwan.
C3 Ming Chuan University; Ming Chuan University
RP Lee, MC (corresponding author), Ming Chuan Univ, Dept Comp & Commun Engn, Taoyuan 333, Taiwan.
EM leemc@mail.mcu.cdu.tw
CR *AM, SET UP YOUR AM ECH
   Badshah AM, 2017, 2017 INTERNATIONAL CONFERENCE ON PLATFORM TECHNOLOGY AND SERVICE (PLATCON), P125
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Chandrasekar P, 2014, 2014 INTERNATIONAL CONFERENCE ON CIRCUITS, SYSTEMS, COMMUNICATION AND INFORMATION TECHNOLOGY APPLICATIONS (CSCITA), P341, DOI 10.1109/CSCITA.2014.6839284
   Cho K., 2014, ARXIV14061078
   Deng L., 2014, FOND T SIGN PROC, V7, P197, DOI [10.1561/2000000039, DOI 10.1561/2000000039, 10.1561/]
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Heideman M. T., 1984, IEEE ASSP Magazine, V1, P14, DOI 10.1109/MASSP.1984.1162257
   Hinton GE, 1986, P 8 ANN C C SCI SOC, V1, P12
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   KOMBRINK S, 2011, RECURRENT NEURAL NET
   LAU C, 2014, STREET
   Le Quoc V., 2014, P INT C MACH LEARN I
   LeCun Yann, Lenet-5, convolutional neural networks
   Livi S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193508
   LYNLEY M, 2016, GOOGLE UNVEILS GOOGL
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Mnih A., 2012, Proceedings of the 29th International Conference on Machine Learning, P419
   Mnih A., 2007, P 24 INT C MACH LEAR, P641, DOI [DOI 10.1145/1273496.1273577, 10.1145/1273496.1273577]
   Mnih Andriy, 2009, Advances in Neural Information Processing Systems, P1081
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Ren F., 2016, CHAPTER 1 Organic Electronic Memory Devices, P1, DOI DOI 10.1039/9781782622505-00001
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sejdic E, 2009, DIGIT SIGNAL PROCESS, V19, P153, DOI 10.1016/j.dsp.2007.12.004
   Sutskever I, 2014, ADV NEUR IN, V27
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wu CH, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/ATSIP.2014.11
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
   2017, PRE TRAINED WORD VEC
   2018, CLOUD SPEECH TEXT
   2016, JIEBA
   2017, ANDROIDAUDIORECORDER
NR 35
TC 27
Z9 28
U1 4
U2 59
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19629
EP 19657
DI 10.1007/s11042-020-08841-6
EA MAR 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000521930200006
DA 2024-07-18
ER

PT J
AU Ghose, S
   Das, A
   Bhunia, AK
   Roy, PP
AF Ghose, Shuvozit
   Das, Abhirup
   Bhunia, Ayan Kumar
   Roy, Partha Pratim
TI Fractional Local Neighborhood Intensity Pattern for Image Retrieval
   using Genetic Algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local neighborhood intensity pattern; Local binary pattern; Feature
   extraction; Texture feature
ID BINARY PATTERNS; FEATURE DESCRIPTOR; TEXTURE; WAVELET; EXTREMA; FACE;
   MRI
AB In this paper, a new texture descriptor named "Fractional Local Neighborhood Intensity Pattern" (FLNIP) has been proposed for content-based image retrieval (CBIR). It is an extension of an earlier work involving adjacent neighbors (local neighborhood intensity pattern). However, instead of considering two separate patterns for representing sign and magnitude information, one single pattern is generated. FLNIP calculates the relative intensity difference between a particular pixel and the center pixel of a 3 x 3 window by considering the relationship with adjacent neighbors. In this work, the fractional change in the local neighborhood involving the adjacent neighbors has been calculated first with respect to one of the eight neighbors of the center pixel of a 3 x 3 window. Next, the fractional change has been calculated with respect to the center itself. The two values of fractional change are next compared to generate a binary bit pattern. The descriptor is applied on four images- one being the raw image and the other three being filtered gaussian images obtained by applying gaussian filters of different standard deviations on the raw image to signify the importance of exploring texture information at different resolutions in an image. The four sets of distances obtained between the query and the target image are then combined with a genetic algorithm based approach to improve the retrieval performance by minimizing the distance between similar class images. The performance of the method has been tested for image retrieval on four databases and the proposed method has shown a significant improvement over many other existing methods.
C1 [Ghose, Shuvozit; Das, Abhirup] Inst Engn & Management, Dept CSE, Kolkata, India.
   [Bhunia, Ayan Kumar] Inst Engn & Management, Dept ECE, Kolkata, India.
   [Roy, Partha Pratim] Indian Inst Technol Roorkee, Dept CSE, Roorkee, Uttar Pradesh, India.
C3 Institute of Engineering & Management (IEM), Kolkata; Institute of
   Engineering & Management (IEM), Kolkata; Indian Institute of Technology
   System (IIT System); Indian Institute of Technology (IIT) - Roorkee
RP Roy, PP (corresponding author), Indian Inst Technol Roorkee, Dept CSE, Roorkee, Uttar Pradesh, India.
EM shuvozit.ghose@gmail.com; abhirupdas.iem@gmail.com;
   ayanbhunia007@gmail.com; proy.fcs@iitr.ac.in
RI Roy, Partha Pratim/GPF-4253-2022; Roy, Partha Pratim/AAV-9061-2020; Roy,
   Partha Pratim/AAW-2994-2020
OI Roy, Partha Pratim/0000-0002-5735-5254
CR Abdelmounaime Safia, 2013, ISRN Machine Vision, DOI 10.1155/2013/876386
   [Anonymous], 2017, ARXIV170902463
   [Anonymous], 2014, P ACM INT C MULT MM
   [Anonymous], 2008, REAL LIF IM WORKSH E
   AT&T LABORATORIES CAMBRIDGE, 2002, DAT FAC
   Chen J, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.122
   Daye ZJ, 2009, COMPUT STAT DATA AN, V53, P1284, DOI 10.1016/j.csda.2008.11.007
   Dubey SR, 2016, IEEE J BIOMED HEALTH, V20, P1139, DOI 10.1109/JBHI.2015.2437396
   Fang YC, 2009, 2009 THIRD INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL 2, PROCEEDINGS, P332, DOI 10.1109/IITA.2009.206
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Hamouchene I, 2014, AASRI PROC, V9, P2, DOI 10.1016/j.aasri.2014.09.002
   He YG, 2013, PATTERN ANAL APPL, V16, P595, DOI 10.1007/s10044-011-0264-4
   Hill PR, 2000, P 2000 INT C IM PROC, V3, P0
   Jacob IJ, 2014, PATTERN RECOGN LETT, V42, P72, DOI 10.1016/j.patrec.2014.01.017
   Kokare M, 2007, PATTERN RECOGN LETT, V28, P1240, DOI 10.1016/j.patrec.2007.02.006
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liao S, 2007, LECT NOTES COMPUT SC, V4844, P672
   Lin J, 2000, J SOUND VIB, V234, P135, DOI 10.1006/jsvi.2000.2864
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Lu X, 2018, IEEE T IMAGE PROCESS
   Marcus DS, 2007, J COGNITIVE NEUROSCI, V19, P1498, DOI 10.1162/jocn.2007.19.9.1498
   Moghaddam HA, 2005, PATTERN RECOGN, V38, P2506, DOI 10.1016/j.patcog.2005.05.010
   Moore S, 2011, COMPUT VIS IMAGE UND, V115, P541, DOI 10.1016/j.cviu.2010.12.001
   Müller H, 2004, COMPUT MED IMAG GRAP, V28, P295, DOI 10.1016/j.compmedimag.2004.04.005
   Murala S, 2015, NEUROCOMPUTING, V149, P1502, DOI 10.1016/j.neucom.2014.08.042
   Murala S, 2014, IEEE J BIOMED HEALTH, V18, P929, DOI 10.1109/JBHI.2013.2288522
   Murala S, 2014, SIGNAL PROCESS-IMAGE, V29, P400, DOI 10.1016/j.image.2013.12.002
   Murala S, 2012, INT J MULTIMED INF R, V1, P191, DOI 10.1007/s13735-012-0008-2
   Murala S, 2013, IEEE COMPUT SOC CONF, P444, DOI 10.1109/CVPRW.2013.73
   Murala S, 2012, J MED SYST, V36, P2865, DOI 10.1007/s10916-011-9764-4
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Murala S, 2009, 2009 IEEE INTERNATIONAL ADVANCE COMPUTING CONFERENCE, VOLS 1-3, P1411, DOI 10.1109/IADCC.2009.4809223
   Nanni L, 2010, ARTIF INTELL MED, V49, P117, DOI 10.1016/j.artmed.2010.02.006
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Ning JF, 2009, INT J PATTERN RECOGN, V23, P1245, DOI 10.1142/S0218001409007624
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Papushoy A, 2015, DIGIT SIGNAL PROCESS, V36, P156, DOI 10.1016/j.dsp.2014.09.005
   Raghuwanshi G, 2016, DIGIT SIGNAL PROCESS, V48, P50, DOI 10.1016/j.dsp.2015.09.003
   Reddy PVB, 2014, AEU-INT J ELECTRON C, V68, P637, DOI 10.1016/j.aeue.2014.01.012
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   Subrahmanyam M, 2012, SIGNAL PROCESS, V92, P1467, DOI 10.1016/j.sigpro.2011.12.005
   Takala V, 2005, LECT NOTES COMPUT SC, V3540, P882
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Verma M, 2016, DIGIT SIGNAL PROCESS, V51, P62, DOI 10.1016/j.dsp.2016.02.002
   Verma M, 2015, J VIS COMMUN IMAGE R, V32, P224, DOI 10.1016/j.jvcir.2015.08.015
   Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397
   Xu Y, 2015, NEUROCOMPUTING, V168, P566, DOI 10.1016/j.neucom.2015.05.070
   Yao CH, 2003, PATTERN RECOGN, V36, P913, DOI 10.1016/S0031-3203(02)00124-3
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang Dengsheng., 2000, IMAGE, V3656 LNCS, P13
   Zhang J, 2008, HPCC 2008: 10TH IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P782, DOI 10.1109/HPCC.2008.55
   Zhao Y, 2013, NEUROCOMPUTING, V106, P68, DOI 10.1016/j.neucom.2012.10.017
NR 55
TC 10
Z9 10
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18527
EP 18552
DI 10.1007/s11042-020-08752-6
EA MAR 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000518306100001
DA 2024-07-18
ER

PT J
AU Wang, XR
   Nie, XS
   Liu, XB
   Wang, BZ
   Yin, YL
AF Wang, Xingrun
   Nie, Xiushan
   Liu, Xingbo
   Wang, Binze
   Yin, Yilong
TI Modality correlation-based video summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Modality correlation; Modality-specific
   information; Attention mechanism
AB Video summarization is an important technique to help us browse, store, and retrieve a rapidly increasing amount of video data, which extracts frames or shots from the original video. Text information covers important content of a video, and thus a summarization can be generated by exploring the correlation between the frame and text. In this study, we propose a video summarization method based on the modality correlation. With this method, we first learn the correlation between the text and frame in the respective space, and then fuse two correlations to obtain the importance score of each shot. Finally, video shots that have a high importance score are chosen as the video summarization. Compared to previous methods that seldom apply text to generate the video summarization, or only use the latent common information between text and frame, the proposed method fully utilizes not only the latent common but also modality-specific information for a video summarization. Experiments were conducted on the TVSum50 dataset, and the results verify the effectiveness of our proposed approach.
C1 [Wang, Xingrun; Liu, Xingbo] Shandong Univ, Sch Comp Sci & Technol, Jinan 250101, Shandong, Peoples R China.
   [Nie, Xiushan] Shandong Jianzhu Univ, Sch Comp Sci & Technol, Jinan 250101, Shandong, Peoples R China.
   [Wang, Binze] Changan Univ, Coll Geol Engn & Geomat, Xian 710054, Peoples R China.
   [Yin, Yilong] Shandong Univ, Sch Software Engn, Jinan 250101, Shandong, Peoples R China.
C3 Shandong University; Shandong Jianzhu University; Chang'an University;
   Shandong University
RP Nie, XS (corresponding author), Shandong Jianzhu Univ, Sch Comp Sci & Technol, Jinan 250101, Shandong, Peoples R China.
EM niexiushan@163.com
RI Nie, Xiushan/AAZ-6410-2020
FU National Natural Science Foundation of China [61671274, 61876098,
   61573219]; Postdoctoral Science Foundation [2016M592190]; Fostering
   Project of Dominant Discipline and Talent Team of Shandong Province
   Higher Education Institutions
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61671274, 61876098 and 61573219, in part
   by the Postdoctoral Science Foundation under Grant 2016M592190, in part
   by the Fostering Project of Dominant Discipline and Talent Team of
   Shandong Province Higher Education Institutions.
CR Aner A, 2002, LECT NOTES COMPUT SC, V2353, P388
   [Anonymous], P IEEE COMP SOC C CO
   [Anonymous], 2002, P 10 ACM INT C MULT
   [Anonymous], 2009, P SIGMM WORKSH SOC M
   Chakraborty S, 2015, IEEE WINT CONF APPL, P702, DOI 10.1109/WACV.2015.99
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Gong BQ, 2014, ADV NEUR IN, V27
   Guan GL, 2013, IEEE T CIRC SYST VID, V23, P729, DOI 10.1109/TCSVT.2012.2214871
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   HADI Y, 2006, P ACM S APPL COMP, P1400
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han YD, 2020, IEEE T CYBERNETICS, V50, P1697, DOI 10.1109/TCYB.2018.2881539
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu TL, 2017, 2017 IEEE THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2017), P117, DOI 10.1109/BigMM.2017.19
   Khosla A, 2013, PROC CVPR IEEE, P2698, DOI 10.1109/CVPR.2013.348
   Kuanar SK, 2013, J VIS COMMUN IMAGE R, V24, P1212, DOI 10.1016/j.jvcir.2013.08.003
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Li JJ, 2019, IEEE T NEUR NET LEAR, V30, P1381, DOI 10.1109/TNNLS.2018.2868854
   Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174
   Li JJ, 2017, IEEE T CYBERNETICS, V47, P3516, DOI 10.1109/TCYB.2016.2565898
   Li XL, 2017, IEEE T IMAGE PROCESS, V26, P3652, DOI 10.1109/TIP.2017.2695887
   Lin DH, 2014, PROC CVPR IEEE, P2657, DOI 10.1109/CVPR.2014.340
   Liu D, 2010, IEEE T PATTERN ANAL, V32, P2178, DOI 10.1109/TPAMI.2010.31
   Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350
   Nam J, 2002, MULTIMED TOOLS APPL, V16, P55, DOI 10.1023/A:1013241718521
   NEWEY WK, 1988, J ECONOMETRICS, V38, P301, DOI 10.1016/0304-4076(88)90048-6
   Ngo CW, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P104, DOI 10.1109/ICCV.2003.1238320
   Peng YX, 2018, IEEE T IMAGE PROCESS, V27, P5585, DOI 10.1109/TIP.2018.2852503
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Rush Alexander M., 2015, P 2015 C EMPIRICAL M, P379, DOI [10.48550/arXiv.1509.00685, DOI 10.18653/V1/D15-1044]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song JK, 2013, IEEE T MULTIMEDIA, V15, P1997, DOI 10.1109/TMM.2013.2271746
   SONG YL, 2015, PROC CVPR IEEE, P5179, DOI [DOI 10.1109/CVPR.2015.7299154, 10.1109/CVPR.2015.7299154]
   Sun K, 2017, IEEE INT CON MULTI, P643, DOI 10.1109/ICME.2017.8019411
   Tang J, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2564638
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Zhang HJ, 1997, PATTERN RECOGN, V30, P643, DOI 10.1016/S0031-3203(96)00109-4
   Zhang K, 2016, LECT NOTES COMPUT SC, V9911, P766, DOI 10.1007/978-3-319-46478-7_47
   Zhang S, 2016, IEEE T IMAGE PROCESS, V25, P5469, DOI 10.1109/TIP.2016.2601493
   Zhang Z, 2019, IEEE T PATTERN ANAL, V41, P1774, DOI 10.1109/TPAMI.2018.2847335
   Zhang Z, 2018, IEEE T NEUR NET LEAR, V29, P4645, DOI 10.1109/TNNLS.2017.2772264
   Zhang Z, 2018, IEEE T NEUR NET LEAR, V29, P3111, DOI 10.1109/TNNLS.2017.2712801
   Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 45
TC 6
Z9 7
U1 6
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33875
EP 33890
DI 10.1007/s11042-020-08690-3
EA MAR 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000518068900002
DA 2024-07-18
ER

PT J
AU Mesfin, G
   Hussain, N
   Kani-Zabihi, E
   Covaci, A
   Saleme, EB
   Ghinea, G
AF Mesfin, Gebremariam
   Hussain, Nadia
   Kani-Zabihi, Elahe
   Covaci, Alexandra
   Saleme, Estevao B.
   Ghinea, Gheorghita
TI QoE of cross-modally mapped Mulsemedia: an assessment using eye gaze and
   heart rate
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mulsemedia; Crossmodal correspondence; Quality of experience; Gaze
   tracking; Heart rate
ID EXPERIENCE; COLOR; ODORS; CORRESPONDENCES; ASSOCIATIONS; QUALITY; SOUND
AB A great deal of research effort has been put in exploring crossmodal correspondences in the field of cognitive science which refer to the systematic associations frequently made between different sensory modalities (e.g. high pitch is matched with angular shapes). However, the possibilities cross-modality opens in the digital world have been relatively unexplored. Therefore, we consider that studying the plasticity and the effects of crossmodal correspondences in a mulsemedia setup can bring novel insights about improving the human-computer dialogue and experience. Mulsemedia refers to the combination of three or more senses to create immersive experiences. In our experiments, users were shown six video clips associated with certain visual features based on color, brightness, and shape. We examined if the pairing with crossmodal matching sound and the corresponding auto-generated haptic effect, and smell would lead to an enhanced user QoE. For this, we used an eye-tracking device as well as a heart rate monitor wristband to capture users' eye gaze and heart rate whilst they were experiencing mulsemedia. After each video clip, we asked the users to complete an on-screen questionnaire with a set of questions related to smell, sound and haptic effects targeting their enjoyment and perception of the experiment. Accordingly, the eye gaze and heart rate results showed significant influence of the cross-modally mapped multisensorial effects on the users' QoE. Our results highlight that when the olfactory content is crossmodally congruent with the visual content, the visual attention of the users seems shifted towards the correspondent visual feature. Crosmodally matched media is also shown to result in an enhanced QoE compared to a video only condition.
C1 [Mesfin, Gebremariam; Hussain, Nadia; Ghinea, Gheorghita] Brunel Univ London, London, England.
   [Kani-Zabihi, Elahe] Univ West London, London, England.
   [Covaci, Alexandra] Univ Kent, Canterbury CT2 7NZ, Kent, England.
   [Saleme, Estevao B.] Univ Fed Espirito Santo, BR-29075910 Vitoria, ES, Brazil.
C3 Brunel University; University of West London; University of Kent;
   Universidade Federal do Espirito Santo
RP Ghinea, G (corresponding author), Brunel Univ London, London, England.
EM gebremariam.assres@brunel.ac.uk; nadia.hussain@brunel.ac.uk;
   Elahe.Kani@uwl.ac.uk; a.covaci@kent.ac.uk; estevaobissoli@gmail.com;
   george.ghinea@brunel.ac.uk
RI Saleme, Estêvão Bissoli/U-4446-2019; Hussain, Nadia/GXH-7350-2022;
   Saleme, Estevao B./AAZ-7161-2020; Assres, Gebremariam
   Mesfin/AFM-0811-2022; Ghinea, Gheorghita/AAG-6770-2020
OI Saleme, Estêvão Bissoli/0000-0003-1856-3824; Saleme, Estevao
   B./0000-0003-1856-3824; Assres, Gebremariam Mesfin/0000-0002-6760-690X;
   Ghinea, Gheorghita/0000-0003-2578-5580; Covaci,
   Alexandra/0000-0002-3205-2273; Kani-Zabihi, Elahe/0000-0002-5679-8512
CR Ademoye OA, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2957753
   Ademoye OA, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2487268.2487270
   [Anonymous], GAM VIRT WORLDS SER
   [Anonymous], INFORM SCI REFERENCE
   [Anonymous], P INT C MAN EM DIG E
   [Anonymous], P 19 INT AC MINDTR C
   [Anonymous], 2007, Cross-Modal Influences on Gustatory Perception
   [Anonymous], SIMPLE STAT LIB INFO
   [Anonymous], ACM T MULTIM COMPU S
   [Anonymous], ACM T MULTIM COMPUT
   [Anonymous], P 2019 CHI C HUM FAC
   [Anonymous], P 13 INT C ADV COMP
   [Anonymous], P 25 SPRING C COMP G
   [Anonymous], CONS EL ICCE 2017 IE
   [Anonymous], 4 INT WORKSH QUAL MU
   [Anonymous], 2005, P 3 INT C COMPUTER G, DOI DOI 10.1145/1101389.1101462
   [Anonymous], P HAID 2006 1 INT WO
   [Anonymous], PEERJ
   [Anonymous], IEEE MULTIMEDIA
   Brunnstrom K., 2013, Qualinet White Paper on Definitions of Quality of Experience
   Choi Bumsuk, 2011, 2011 INT C INFORM SC, DOI [10.1109/icisa.2011.5772390, DOI 10.1109/ICISA.2011.5772390]
   Covaci A, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3233774
   Crisinel AS, 2009, NEUROSCI LETT, V464, P39, DOI 10.1016/j.neulet.2009.08.016
   Danieau F, 2013, IEEE T HAPTICS, V6, P193, DOI [10.1109/TOH.2012.70, 10.1109/ToH.2012.70]
   de Valk JM, 2017, PSYCHON B REV, V24, P1171, DOI 10.3758/s13423-016-1179-2
   Demattè ML, 2006, CHEM SENSES, V31, P531, DOI 10.1093/chemse/bjj057
   Deroy O, 2013, PSYCHON B REV, V20, P643, DOI 10.3758/s13423-013-0387-2
   Egan D, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON QUALITY OF MULTIMEDIA EXPERIENCE (QOMEX)
   Eid M, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON VIRTUAL ENVIRONMENTS, HUMAN-COMPUTER INTERFACES AND MEASUREMENT SYSTEMS, P5, DOI 10.1109/VECIMS.2008.4592743
   Ghinea G, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2617994
   Gilbert AN, 1996, AM J PSYCHOL, V109, P335, DOI 10.2307/1423010
   Hagtvedt H, 2016, J MARKETING RES, V53, P551, DOI 10.1509/jmr.14.0414
   Hanson-Vaux G, 2013, CHEM SENSES, V38, P161, DOI 10.1093/chemse/bjs087
   Hulusic Vedad., 2009, SCCG, P151
   Jacquot M, 2016, CHEMOSENS PERCEPT, V9, P79, DOI 10.1007/s12078-016-9209-z
   Jalal L, 2018, IEEE T BROADCAST, V64, P552, DOI 10.1109/TBC.2018.2823914
   Jezler Olivia., 2016, Extended Abstracts of the ACM Conference on Human Factors in Computing Systems, P1677, DOI [10.1145/2851581.2892471, DOI 10.1145/2851581.2892471]
   Keighrey C, 2017, INT WORK QUAL MULTIM
   Kemp SE, 1997, AM J PSYCHOL, V110, P35, DOI 10.2307/1423699
   Kim SK, 2014, ETRI J, V36, P224, DOI 10.4218/etrij.14.2113.0065
   Kim SK, 2013, SIGNAL PROCESS-IMAGE, V28, P162, DOI 10.1016/j.image.2012.10.011
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Koizumi N., 2011, P 8 INT C ADV COMPUT, P1, DOI DOI 10.1145/2071423.2071449
   MARKS LE, 1987, J EXP PSYCHOL HUMAN, V13, P384, DOI 10.1037/0096-1523.13.3.384
   MARKS LE, 1974, AM J PSYCHOL, V87, P173, DOI 10.2307/1422011
   Mastoropoulou Georgia, 2007, THESIS
   Möller S, 2014, T-LAB SER TELECOMMUN, P73, DOI 10.1007/978-3-319-02681-7_5
   Monks James N., 2017, 2017 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2017.8087770
   Munster G., 2015, gene, V612, P303
   Murray N, 2017, IEEE T SYST MAN CY-S, V47, P2503, DOI 10.1109/TSMC.2016.2531654
   Murray N, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON QUALITY OF MULTIMEDIA EXPERIENCE (QOMEX)
   Murray N, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3108243
   Ramic-Brkic Belma, 2013, P 29 SPRING C COMP G, P91, DOI DOI 10.1145/2508244.2508256
   Ranasinghe N., 2014, Proceedings of the 8th International Conference on Tangible, Embedded and Embodied Interaction, P133, DOI [DOI 10.1145/2540930, DOI 10.1145/2540930.2540939, 10.1145/2540930.2540939]
   Ranasinghe N, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1139, DOI 10.1145/3123266.3123440
   Rehman S., 2014, P 51 ANN DES AUT C D, P1, DOI DOI 10.7873/DATE.2014.119
   Rousi RA, 2017, PROCEEDINGS OF THE 21ST INTERNATIONAL ACADEMIC MINDTREK CONFERENCE (ACADEMIC MINDTREK), P147, DOI 10.1145/3131085.3131113
   Sakai N, 2005, CHEM SENSES, V30, pI244, DOI 10.1093/chemse/bjh205
   Saleme E. B., 2015, P 21 BRAZ S 15 MULT, P145
   Seo HS, 2010, NEUROSCI LETT, V478, P175, DOI 10.1016/j.neulet.2010.05.011
   Shin SH, 2016, INT CONF UBIQ FUTUR, P730, DOI 10.1109/ICUFN.2016.7537133
   Simner J., 2009, 3 INT C SYN ART GRAN
   SIMPSON R H, 1956, J Genet Psychol, V89, P95
   Spector F, 2012, SEEING PERCEIVING, V25, P655, DOI 10.1163/187847612X648800
   Spence C., 2010, The World of Fine Wine, V28, P122
   Spence C, 2011, ATTEN PERCEPT PSYCHO, V73, P971, DOI 10.3758/s13414-010-0073-7
   Streeter NL, 2011, CHEMOSENS PERCEPT, V4, P1, DOI 10.1007/s12078-010-9082-0
   Striner Alina, 2018, ARXIV180400229
   Sulema Y, 2016, INT CONF SYST SIGNAL, P19
   Sun XW, 2018, PEERJ, V6, DOI 10.7717/peerj.4443
   Tag B, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC '17 ADJUNCT), P289, DOI 10.1145/3123024.3123190
   Tanaka A, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2150, DOI 10.1145/2858036.2858304
   Tsiros A, 2017, ELECT VISUALISATION, P175
   Valenti G, 2013, IEEE ICCE, P195, DOI 10.1109/ICCE.2013.6486856
   Waltl Markus, 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P124, DOI 10.1109/QOMEX.2010.5517704
   Waltl M, 2013, SIGNAL PROCESS-IMAGE, V28, P136, DOI 10.1016/j.image.2012.10.009
   Yau JM, 2009, CURR BIOL, V19, P561, DOI 10.1016/j.cub.2009.02.013
   Yuan ZH, 2015, IEEE T MULTIMEDIA, V17, P957, DOI 10.1109/TMM.2015.2431915
   Yuan ZH, 2015, IEEE T MULTIMEDIA, V17, P104, DOI 10.1109/TMM.2014.2371240
   Yuan ZH, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2661329
   Zou LH, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P315, DOI 10.1145/3083187.3084014
NR 81
TC 6
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7987
EP 8009
DI 10.1007/s11042-019-08473-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100051
OA Green Published, Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Kumar, U
   Gambhir, S
AF Kumar, Umesh
   Gambhir, Sapna
TI KDFBA: key distribution through fingerprint based authentication using
   Mobile agent
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless network; Key exchange; Black hole attack; Authentication; KDC;
   Mobile agent; Wireless security
ID SECURE; SCHEME; MANAGEMENT
AB As mobile networks and use of mobile devices are increasing at a rapid rate, need of securing both the device information and the network increasing evermore. Authentication of the user is another important challenge as this need to be done remotely. Bio-cryptography is one of the robust solution, which uses existing cryptography techniques with user biometric information for encryption and authentication. Encryption process also involves key generation and distribution. Key Distribution Center (KDC) is the most common mode of key generation and key distribution. KDC is always been the most profitable and worthy target for the adversaries. When KDC is compromised the strongest security protocols, encryption protocols, firewalls etc. will be of no use and will backfire. This paper explains some of the currently existing approaches of key exchange and problems in existing approaches are identified. A new biometric based key exchange protocol (KDFBA) is proposed which makes use of the mobile agent for key exchange and biometric information for authentication. Proposed protocol is simulated on NS2 platform and is also compared with the existing approaches. Protocol is tested against some parameters like traffic generated, timing analysis and prevention against attacks like black hole attack. The simulation results prove that the proposed key exchange protocol reduces the traffic on the network considerably and also prevents attacks like black hole.
C1 [Kumar, Umesh; Gambhir, Sapna] JC Bose Univ Sci & Technol YMCA, Dept Comp Engn, Faridabad, Haryana, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Kumar, U (corresponding author), JC Bose Univ Sci & Technol YMCA, Dept Comp Engn, Faridabad, Haryana, India.
EM umesh554@gmail.com
RI Kumar, Umesh/H-4475-2018
OI Kumar, Umesh/0000-0002-4805-8047
CR Abosamra A, 2011, EGYPT INFORM J, V12, P29, DOI 10.1016/j.eij.2011.02.003
   Al-Riyami SS, 2003, LECT NOTES COMPUT SC, V2894, P452
   [Anonymous], P 2 ACM INT C WIR SE
   Anzani M, 2018, WIREL NETW, V24, P2867, DOI 10.1007/s11276-017-1509-y
   Blundo C., 1996, Advances in Cryptology - CRYPTO'96. 16th Annual International Cryptology Conference. Proceedings, P387
   Blundo C, 1998, INFORM COMPUT, V146, P1, DOI 10.1006/inco.1998.2717
   Chatterjee K, 2012, LECT NOTES COMPUT SC, V7332, P351, DOI 10.1007/978-3-642-31020-1_41
   CHATTERJEE U, 2018, IEEE T DEPEND SECURE, P1
   Cimato S, 2006, J COMPUT SECUR, V14, P45, DOI 10.3233/JCS-2006-14102
   Daghighi B, 2018, WIREL NETW, V24, P3009, DOI 10.1007/s11276-017-1511-4
   Dargahi T, 2015, SECUR COMMUN NETW, V8, P1561, DOI 10.1002/sec.1104
   Dong JK, 2018, IEEE CONF COMM NETW
   Du XJ, 2009, IEEE T WIREL COMMUN, V8, P1223, DOI 10.1109/TWC.2009.060598
   Eom Sungwook, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1411, DOI 10.1007/s12652-018-0698-2
   Huh JH, 2019, J SUPERCOMPUT, V75, P3123, DOI 10.1007/s11227-018-2496-1
   Juang WS, 2009, COMPUT ELECTR ENG, V35, P33, DOI 10.1016/j.compeleceng.2008.03.002
   Kumar U, 2018, INT J FUTUR GENER CO, V11, P33, DOI 10.14257/ijfgcn.2018.11.3.04
   LIN XJ, 2013, IACR CRYPTOLOGY EPRI, P698
   Lin YH, 2010, IEEE T MOBILE COMPUT, V9, P1666, DOI 10.1109/TMC.2010.150
   LIU Y, 2015, 2015 IEEE 12 INT C N
   Liu ZH, 2009, IEEE T WIREL COMMUN, V8, P1366, DOI 10.1109/TWC.2009.080049
   MALL D, 2017, 2017 INT C NETW SYST
   Memon I, 2015, WIRELESS PERS COMMUN, V85, P1167, DOI 10.1007/s11277-015-2833-0
   Memon I, 2015, WIRELESS PERS COMMUN, V84, P1487, DOI 10.1007/s11277-015-2699-1
   MITCHELL CJ, 1988, DISCRETE APPL MATH, V21, P215, DOI 10.1016/0166-218X(88)90068-6
   Nan Li, 2010, 2010 2nd International Conference on Computer Engineering and Technology (ICCET), P634, DOI 10.1109/ICCET.2010.5485276
   Nehra N, 2008, IEEE INT CONF NETWOR, P120
   QIN D, 2018, SMART INNOVATION SYS, V82
   Ruj S, 2013, IEEE T COMPUT, V62, P2224, DOI 10.1109/TC.2012.138
   Seo SH, 2015, IEEE T INF FOREN SEC, V10, P371, DOI 10.1109/TIFS.2014.2375555
   SILVA L, 1999, 1 INT S AG SYST APPL, P210
   Stallings W., 2005, CRYPTOGRAPHY NETWORK, V4th
   WILLIAMS HC, 1980, IEEE T INFORM THEORY, V26, P726, DOI 10.1109/TIT.1980.1056264
   Zhang W, 2018, IEEE TRUST BIG, P699, DOI 10.1109/TrustCom/BigDataSE.2018.00102
   Zhang X, 2011, EURASIP J WIREL COMM, DOI 10.1155/2011/765143
NR 35
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13891
EP 13918
DI 10.1007/s11042-020-08614-1
EA FEB 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515805100001
DA 2024-07-18
ER

PT J
AU Sreeja, SR
   Himanshu
   Samanta, D
AF Sreeja, S. R.
   Himanshu
   Samanta, Debasis
TI Distance-based weighted sparse representation to classify motor imagery
   EEG signals for BCI applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electroencephalography (EEG); Brain computer interface (BCI); Motor
   imagery (MI); Sparsity-based classification; Weighted sparse
   representation
ID BRAIN-COMPUTER-INTERFACE; SPATIAL-PATTERNS; NEURAL-NETWORKS;
   CLASSIFICATION; DECOMPOSITION; ROBUST
AB Motor imagery (MI) based brain-computer interface systems (BCIs) are highly in need for a large number of real-time applications such as hands and touch-free text entry system, movement of a wheelchair, movement of a cursor, prosthetic arm movement, virtual reality systems, etc. In recent years, sparse representation-based classification (SRC) is a growing technique and has been a successful technique on classifying MI-based Electroencephalography (EEG) signals. To further boost the proficiency of SRC technique, in this paper, a weighted SRC (WSRC) has been proposed for classifying MI signals. In WSRC approach, a weighted dictionary has been constructed according to the dissimilarity information between a test data and training samples. Then for the given test data, the sparse coefficients are computed over the weighted dictionary using l(0)-minimization problem. The sparse solution obtained using WSRC gives discriminative information and as a consequence, WSRC proves to be superior for MI-based EEG classification. The experimental results substantiate that WSRC is more efficient and accurate than SRC.
C1 [Sreeja, S. R.; Samanta, Debasis] Indian Inst Technol Kharagpur, Dept Comp Sci & Engn, Kharagpur 721302, W Bengal, India.
   [Himanshu] Indian Inst Technol Kharagpur, Dept Math, Kharagpur 21302, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Kharagpur
RP Samanta, D (corresponding author), Indian Inst Technol Kharagpur, Dept Comp Sci & Engn, Kharagpur 721302, W Bengal, India.
EM sreejasr@iitkgp.ac.in; hs80941@iitkgp.ac.in; dsamanta@iitkgp.ac.in
RI SR, Sreeja/AAV-2512-2020
OI SR, Sreeja/0000-0002-9853-5964; Samanta, Debasis/0000-0002-6104-3771
CR Ameri R, 2016, NEUROCOMPUTING, V218, P382, DOI 10.1016/j.neucom.2016.08.082
   An X, 2014, LECT N BIOINFORMAT, V8590, P203, DOI 10.1007/978-3-319-09330-7_25
   [Anonymous], 2012, BRAIN COMPUTER INTER
   Arvaneh M, 2011, IEEE T BIO-MED ENG, V58, P1865, DOI 10.1109/TBME.2011.2131142
   Baali Hamza, 2015, IEEE J Transl Eng Health Med, V3, P2100108, DOI 10.1109/JTEHM.2015.2485261
   Bekhti Y, 2018, INVERSE PROBL, V34, DOI 10.1088/1361-6420/aac9b3
   Bell CJ, 2008, J NEURAL ENG, V5, P214, DOI 10.1088/1741-2560/5/2/012
   Blankertz B, 2008, IEEE SIGNAL PROC MAG, V25, P41, DOI 10.1109/MSP.2008.4408441
   Blankertz B, 2006, IEEE T NEUR SYS REH, V14, P153, DOI 10.1109/TNSRE.2006.875642
   Cai TT, 2011, IEEE T INFORM THEORY, V57, P4680, DOI 10.1109/TIT.2011.2146090
   Dokmanic I, 2015, IEEE SIGNAL PROC MAG, V32, P12, DOI 10.1109/MSP.2015.2398954
   Fan ZZ, 2015, NEUROCOMPUTING, V151, P304, DOI 10.1016/j.neucom.2014.09.035
   Fang LY, 2017, IEEE T INSTRUM MEAS, V66, P1646, DOI 10.1109/TIM.2017.2664480
   Fang LY, 2017, IEEE T MED IMAGING, V36, P407, DOI 10.1109/TMI.2016.2611503
   Gan L, 2017, IEEE GEOSCI REMOTE S, V14, P1968, DOI 10.1109/LGRS.2017.2743742
   Grosse-Wentrup M, 2008, IEEE T BIO-MED ENG, V55, P1991, DOI 10.1109/TBME.2008.921154
   He B, 2015, P IEEE, V103, P907, DOI [10.1109/jproc.2015.2407272, 10.1109/JPROC.2015.2407272]
   He LH, 2016, IEEE T SYST MAN CY-S, V46, P843, DOI 10.1109/TSMC.2015.2450680
   Huang DD, 2012, IEEE T NEUR SYS REH, V20, P379, DOI 10.1109/TNSRE.2012.2190299
   Jiao Y, 2018, IEEE J BIOMEDICAL HL
   Kevric J, 2017, BIOMED SIGNAL PROCES, V31, P398, DOI 10.1016/j.bspc.2016.09.007
   Kumar Shiu, 2016, 2016 3rd Asia-Pacific World Congress on Computer Science and Engineering (APWC on CSE), P34, DOI 10.1109/APWC-on-CSE.2016.017
   Kumar S, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1964-6
   Li JH, 2015, NEUROCOMPUTING, V165, P23, DOI 10.1016/j.neucom.2014.08.092
   Li JH, 2014, LECT NOTES COMPUT SC, V8834, P503, DOI 10.1007/978-3-319-12637-1_63
   Lu CY, 2013, J VIS COMMUN IMAGE R, V24, P111, DOI 10.1016/j.jvcir.2012.05.003
   Lu N, 2017, IEEE T NEUR SYS REH, V25, P566, DOI 10.1109/TNSRE.2016.2601240
   Lu N, 2015, J NEUROSCI METH, V249, P41, DOI 10.1016/j.jneumeth.2015.03.031
   McFarland DJ, 2008, COMPUTER, V41, P52, DOI 10.1109/MC.2008.409
   McFarland DJ, 2008, J NEURAL ENG, V5, P101, DOI 10.1088/1741-2560/5/2/001
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Ojeda A, 2018, NEUROIMAGE, V174, P449, DOI 10.1016/j.neuroimage.2018.03.048
   Ouzir N, 2018, IEEE T IMAGE PROCESS, V27, P64, DOI 10.1109/TIP.2017.2753406
   Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145
   Park SA, 2013, MED BIOL ENG COMPUT, V51, P571, DOI 10.1007/s11517-012-1026-1
   Qiu ZY, 2016, NEUROCOMPUTING, V207, P519, DOI 10.1016/j.neucom.2016.05.035
   Roy DE, 2017, COMPUTER VISION PRIN
   Royer AS, 2010, IEEE T NEUR SYS REH, V18, P581, DOI 10.1109/TNSRE.2010.2077654
   Schirrmeister RT, 2017, HUM BRAIN MAPP, V38, P5391, DOI 10.1002/hbm.23730
   Sharma P, 2017, IEEE-ACM T AUDIO SPE, V25, P2162, DOI 10.1109/TASLP.2017.2748240
   Shin Y, 2015, COMPUT BIOL MED, V66, P29, DOI 10.1016/j.compbiomed.2015.08.017
   Shin Y, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/5/056002
   Siuly, 2014, COMPUT METH PROG BIO, V113, P767, DOI [10.1016/j.cmpb.2013.17.070, 10.1016/j.cmpb.2013.12.020]
   Sreeja SR, 2019, NEUROCOMPUTING, V368, P133, DOI 10.1016/j.neucom.2019.08.037
   Sreeja SR, 2018, IEEE J BIOMED HEALTH, V22, P1362, DOI 10.1109/JBHI.2017.2771783
   Sreeja SR, 2017, LECT NOTES COMPUT SC, V10688, P47, DOI 10.1007/978-3-319-72038-8_5
   Sreeja SR, 2017, 2017 INTERNATIONAL CONFERENCE ON NEW TRENDS IN COMPUTING SCIENCES (ICTCS), P61, DOI 10.1109/ICTCS.2017.15
   Sturm I, 2016, J NEUROSCI METH, V274, P141, DOI 10.1016/j.jneumeth.2016.10.008
   Tabar YR, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2560/14/1/016003
   Tang ZC, 2017, OPTIK, V130, P11, DOI 10.1016/j.ijleo.2016.10.117
   Wan MH, 2017, MULTIMED TOOLS APPL, V76, P355, DOI 10.1007/s11042-015-3057-8
   Wan MH, 2014, INFORM SCIENCES, V274, P55, DOI 10.1016/j.ins.2014.02.145
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Zhang BC, 2015, PROC CVPR IEEE, P4557, DOI 10.1109/CVPR.2015.7299086
   Zhang ST, 2012, MED IMAGE ANAL, V16, P265, DOI 10.1016/j.media.2011.08.004
   Zhang Y., 2019, IEEE T MULTIMEDIA
   Zhang Y, 2019, IEEE T CYBERNETICS, V49, P3322, DOI 10.1109/TCYB.2018.2841847
   Zhang Y, 2017, NEUROCOMPUTING, V225, P103, DOI 10.1016/j.neucom.2016.11.008
   Zhang Y, 2016, IEEE T NEUR NET LEAR, V27, P2256, DOI 10.1109/TNNLS.2015.2476656
   Zhang Y, 2015, J NEUROSCI METH, V255, P85, DOI 10.1016/j.jneumeth.2015.08.004
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
   Zheng QQ, 2018, NEUROCOMPUTING, V275, P869, DOI 10.1016/j.neucom.2017.09.030
NR 63
TC 23
Z9 24
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13775
EP 13793
DI 10.1007/s11042-019-08602-0
EA FEB 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515805300003
DA 2024-07-18
ER

PT J
AU Ganesh, RK
   Kanthavel, R
   Dhaya, R
AF Ganesh, R. Karthik
   Kanthavel, R.
   Dhaya, R.
TI RETRACTED: Development of video compression using EWNS linear
   transformation and un-repetition simulated contrary based resurgence
   procedure (Retracted article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Video compression; Acclimatize frame formation; East west north south
   linear transformation; Compression ratio
ID SIGNAL RECOVERY
AB In the recent years, video transmission area endures several failures owing to the limited amount of a cutting edge technique to store large sized videos. For this reason, video compression method is used. For compression of videos, frame formation can be done by splitting the video frames by A_Frames, B_Frames and C_Frames. These frames will stay unchanged entire process; it will also utilize the memory for computational purpose. The proposed work consists of 2 phases. In the first phase, Acclimatize Frame Formation (AFF) is used to expand the characteristic of video coding and EWNS linear transformation (ELT) is initiated for substituting B_Frames with neither A_Frame nor C_Frame. In the second phase, un-repetition simulated contrary based resurgence procedure (URSCRP) is proposed for restoration of videos that demonstrates tiny convolution and time necessity together with conservation of restoration feature. Simulation results shows that URSCRP provides better accuracy and optimization compared to other related procedures. URSCRP provides PSNR of 30 dB, accuracy of 98% and minimized amount of elapsed time compared to related procedures.
C1 [Ganesh, R. Karthik] SCAD Coll Engn & Technol, Dept Comp Sci & Engn, Tuunelveli, India.
   [Kanthavel, R.] VV Coll Engn, Tirunelveli, India.
   [Dhaya, R.] Rajalakshmi Engn Coll, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 Rajalakshmi Engineering College
RP Ganesh, RK (corresponding author), SCAD Coll Engn & Technol, Dept Comp Sci & Engn, Tuunelveli, India.
EM karthiganesh2k4@gmail.com; kanthavel2005@gmail.com;
   dhayavel2005@gmail.com
CR Aghamaleki JA, 2016, SIGNAL PROCESS-IMAGE, V47, P289, DOI 10.1016/j.image.2016.07.001
   Ahmadi A, 2011, SMART INNOV SYST TEC, V11, P143
   [Anonymous], 2008, BMVA S 3D VID AN DIS
   Cai TT, 2011, IEEE T INFORM THEORY, V57, P4680, DOI 10.1109/TIT.2011.2146090
   Candès EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014
   Donoho DL, 2012, IEEE T INFORM THEORY, V58, P1094, DOI 10.1109/TIT.2011.2173241
   Fazel M, 2008, CONF REC ASILOMAR C, P1043, DOI 10.1109/ACSSC.2008.5074571
   Kumar V, 2013, LECT NOTES ELECT ENG, P149, DOI DOI 10.1007/978-81-322-1000-9_14
   Liu J., 2013, MULTIMEDIA UBIQUITOU, V240, P13, DOI DOI 10.1007/978-94-007-6738-6_2
   Masiero R, 2009, GLOB TELECOMM CONF, P1271
   Mukherjee R, 2016, SIGNAL PROCESS-IMAGE, V47, P426, DOI 10.1016/j.image.2016.08.001
   Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002
   Patel V.M., 2013, Sparse Representations and Compressive Sensing for Imaging and Vision
   Paul M, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-11
   Rajalakshmi K., 2016, INT J COMPUTER APPL, V141, P32
   Worasucheep C, 2015, INT J MACHINE LEARNI, V5
   Xu D., 2016, SIGNAL PROCESS-IMAGE, V47, P289
   Yang J, 2013, IEEE T ANTENN PROPAG, V61, P5485, DOI 10.1109/TAP.2013.2279093
   Zatt B, 2010, IEEE IMAGE PROC, P3053, DOI 10.1109/ICIP.2010.5651700
   Zhi-xue L, 2012, P 1 INT WORKSH COMPR
NR 20
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3519
EP 3541
DI 10.1007/s11042-018-6008-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700022
DA 2024-07-18
ER

PT J
AU Kuang, HP
   Xun, L
AF Kuang, Haipeng
   Xun, Liang
TI Object tracking with collaborative extreme learning machines
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Collaborative model; Extreme learning machine;
   Kullback-Laibler distance
ID ROBUST VISUAL TRACKING
AB We propose a novel collaborative discriminative model based on extreme learning machine (ELM) for object tracking in this paper. In order to represent the object more precisely, we first propose a new collaborative discriminative representation model, which includes both a global discriminative sub-model and a local discriminative sub-model. Different from traditional local representation models, in particular, our local sub-model integrates several classifiers which have structural relations to improve the expression. The global discriminative model represents the appearance comprehensively while the local discriminative sub-model can effectively address occlusions and assist the update. Second, to have better combination of these sub-models, we propose a novel collaboration strategy based on the Kullback-Leibler (KL) distance. The novel strategy can determine the weights of the sub-models adaptively by measuring their KL distances reciprocally. Third, we introduce ELM into tracking and adopt it to build both the global and the local discriminative sub-models simultaneously. Since ELM has a good generalization performance and is robust to the imbalance of the training samples, it is suitable to be used for tracking. Experimental results demonstrate that our method can achieve comparable performance to many state-of-the-art tracking approaches.
C1 [Kuang, Haipeng] Chinese Acad Sci, Changchun Inst Opt Fine Mech & Phys, Key Lab Airborne Opt Imaging & Measurement, Changchun 130033, Peoples R China.
   [Xun, Liang] Beijing Topmoo Technol Co Ltd, Res & Dev Plaza,Tsinghua Sci Pk, Beijing 100084, Peoples R China.
C3 Chinese Academy of Sciences; Changchun Institute of Optics, Fine
   Mechanics & Physics, CAS
RP Kuang, HP (corresponding author), Chinese Acad Sci, Changchun Inst Opt Fine Mech & Phys, Key Lab Airborne Opt Imaging & Measurement, Changchun 130033, Peoples R China.
EM kuanghp@163.com; xunliang@gmail.com
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bai Q, ICCV2013
   Baojie Fan YT, 2017, J ELECTRON IMAGING, V26, P26, DOI [10.1117/1.JEI.26.1.013007, DOI 10.1117/1.JEI.26.1.013007]
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chen D, 2013, ICCV2013
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Grabner H., 2006, BMVC, P47
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huchuan Lu, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P539, DOI 10.1109/FG.2011.5771455
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kwon J, 2011, IEEE I CONF COMP VIS, P1195, DOI 10.1109/ICCV.2011.6126369
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li HX, 2011, PROC CVPR IEEE, P1305, DOI 10.1109/CVPR.2011.5995483
   Li Xiaolin., 2000, IEEE Trans- actions on Pattern Analysis and Machine Intelligence
   Liu BY, 2013, IEEE T PATTERN ANAL, V35, P2968, DOI 10.1109/TPAMI.2012.215
   Liu R, 2009, IEEE I CONF COMP VIS, P1459, DOI 10.1109/ICCV.2009.5459285
   Luka C, TECHNICAL REPORT 10
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Peng XJ, 2016, LECT NOTES COMPUT SC, V9908, P744, DOI 10.1007/978-3-319-46493-0_45
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Saffari Amir, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1393, DOI 10.1109/ICCVW.2009.5457447
   Santner J, 2010, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2010.5540145
   Sun L, 2011, IEEE T CIRC SYST VID, V21, P408, DOI 10.1109/TCSVT.2010.2087815
   Tang F, 2007, IEEE I CONF COMP VIS, P992
   Wang Y, 2018, MULTIMED TOOLS APPL, V77, P31447, DOI 10.1007/s11042-018-6198-8
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Yang H, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023008
   Yang J, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.5.053006
   Yao R, 2013, PROC CVPR IEEE, P2363, DOI 10.1109/CVPR.2013.306
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yu Q, 2008, COMPUT VIS ECCV, V2008, P678
   Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148
   Zhang GY, 2017, IEEE SIGNAL PROC LET, V24, P1666, DOI 10.1109/LSP.2017.2731952
   Zhang L, 2013, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2013.240
   Zhang SL, 2020, IEEE T CYBERNETICS, V50, P270, DOI 10.1109/TCYB.2018.2868782
   Zhang SL, 2018, PATTERN RECOGN, V84, P112, DOI 10.1016/j.patcog.2018.07.012
   Zhang SL, 2015, IEEE T IMAGE PROCESS, V24, P5723, DOI 10.1109/TIP.2015.2484068
   Zhang SL, 2015, PATTERN RECOGN, V48, P2474, DOI 10.1016/j.patcog.2015.02.008
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhao JW, 2018, MULTIMED TOOLS APPL, V77, P30969, DOI 10.1007/s11042-018-6132-0
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 54
TC 0
Z9 0
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4965
EP 4988
DI 10.1007/s11042-018-7135-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500040
DA 2024-07-18
ER

PT J
AU Lakshmi, MV
   Sudha, S
AF Lakshmi, M. Vanitha
   Sudha, S.
TI RETRACTED: Noise diminution and formant extraction on vowels for hearing
   aid users (Retracted article. See vol. 82, pg. 14333, 2023)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Hearing aid; Modified spectral subtraction; Perceptual evaluation of
   speech quality (PESQ); Speech enhancement; Signal to noise ratio (SNR);
   Vowels and formant extraction
ID SPEECH ENHANCEMENT; MODEL
AB People suffering from hearing loss have great difficulty to hear even with the help of hearing aids due to background noises. The problem of reducing noise in hearing aids still remains as a toughest problem to solve. A speech upgrade method to be specific, a modified spectral subtraction is proposed to decrease the different foundation noises and its execution is tried with target quality estimation parameter like signal to noise ratio (SNR) and perceptual evaluation of speech quality (PESQ), and furthermore Vowels are thought to be voiced sounds with more vitality for discourse creation. And hence from the enhanced speech signal the formant frequency of the voiced vowels is extracted based on autocorrelation method and in future work thereby increase the intelligibility of the vowels by enhancing the formants for the hearing aid listeners.
C1 [Lakshmi, M. Vanitha] SA Engn Coll, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
   [Sudha, S.] SRM Easwari Engn Coll, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
C3 S.A. Engineering College; Easwari Engineering College
RP Lakshmi, MV (corresponding author), SA Engn Coll, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
EM vanilakshu@gmail.com
RI Sudha, S/AAI-9005-2021; M, vanithalakshmi/GXZ-8567-2022
OI M, vanithalakshmi/0000-0002-1157-9172
CR Acoustical Solutions Inc, INTR NOIS CONTR AC E
   Anitha Sheela K, ICRACVES 2014
   Berouti M., 1979, ICASSP 79. 1979 IEEE International Conference on Acoustics, Speech and Signal Processing, P208
   Cohen I, 2003, IEEE T SPEECH AUDI P, V11, P466, DOI 10.1109/TSA.2003.811544
   Cohen I, 2005, IEEE T SPEECH AUDI P, V13, P870, DOI 10.1109/TSA.2005.851940
   Cohen I, 2001, SIGNAL PROCESS, V81, P2403, DOI 10.1016/S0165-1684(01)00128-1
   Dhivya E, 2016, ADV INTELLIGENCE COM, V397CTU, P47
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   FRY DB, 1962, LANG SPEECH, V5, P171, DOI 10.1177/002383096200500401
   Helmholtz H.L., 2009, On the Sensations of Tone as a Physiological Basis for the Theory of Music
   Hu Y, 2003, IEEE T SPEECH AUDI P, V11, P457, DOI 10.1109/TSA.2003.815936
   Kamrul Hasan MD, 2004, IEEE SIGNAL PROCESSI, V4
   Kewley-Port D, 2007, J ACOUST SOC AM, V122, P2365, DOI 10.1121/1.2773986
   Kuppusamy PG, 2012, EUROPEAN J SCI RES
   Parikh G, 2005, J ACOUST SOC AM, V118, P3874, DOI 10.1121/1.2118407
   Parlak K, 2012, APPL SPEECH ENHANCEM
   Rao A, 2014, IEEE T BIO-MED ENG, V61, P2081, DOI 10.1109/TBME.2014.2313618
   Scalart P, 1996, INT CONF ACOUST SPEE, P629, DOI 10.1109/ICASSP.1996.543199
   Upadhyay N, 2013, INT C DES MAN ICONDM, DOI [10.1016/j.proeng2013.09.103, DOI 10.1016/J.PROENG2013.09.103]
   ZAHORIAN SA, 1993, J ACOUST SOC AM, V94, P1966, DOI 10.1121/1.407520
NR 20
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3729
EP 3741
DI 10.1007/s11042-018-6914-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700034
DA 2024-07-18
ER

PT J
AU Praveena, D
   Rangarajan, P
AF Praveena, D.
   Rangarajan, P.
TI A machine learning application for reducing the security risks in hybrid
   cloud networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Hybrid cloud networks; Security; Deduplication; Access
   control; Secured storage
ID MANAGEMENT; TRUST
AB Cloud computing facilitates the enormous support of the public, business and emerging applications such as healthcare and nature disasters. Based on their services and characteristics, it can be classified as private cloud and public cloud. In this scenario, we need these two kinds of cloud services for an organization to provide the better service to the society. For that purpose, introduced a new cloud service called hybrid cloud service which is the combination of both private and public cloud. Security to the cloud environment is a challenging issue today especially for the hybrid cloud due to the combination of both. Many security mechanisms available in the literature but these are not achieved the sufficient level of security. For this purpose, we propose a new machine learning application for providing security to the hybrid cloud networks while storing the data and retrieving or accessing the data from the cloud. This proposed algorithm combines an existing Enhanced C4.5, newly proposed deduplication processing algorithm and the newly proposed dynamic access control mechanism. Moreover, we introduce a new deduplication processing algorithm for secure storage and retrieval without duplication or redundancy. In addition, a newly proposed dynamic access control mechanism called Dynamic Spatial Role Based Access Control Algorithm is also used in the proposed security framework. The proposed security framework has been implemented and also evaluated that the security level of the hybrid cloud while storing, retrieving and accessing the data from the cloud database.
C1 [Praveena, D.] RMD Engn Coll, Dept Informat Technol, Chennai 601206, Tamil Nadu, India.
   [Rangarajan, P.] RMD Engn Coll, Dept Comp Sci & Engn, Chennai 601206, Tamil Nadu, India.
RP Praveena, D (corresponding author), RMD Engn Coll, Dept Informat Technol, Chennai 601206, Tamil Nadu, India.
EM praveena.it@rmd.ac.in; rangarajan69@gmail.com
RI PARTHASARATHY, RANGARAJAN/Y-8386-2018; D, Praveena/AAN-7542-2020
OI PARTHASARATHY, RANGARAJAN/0000-0002-9937-4509; D,
   Praveena/0000-0001-6252-2312
CR Alabdulatif A, 2017, J COMPUT SYST SCI, V90, P28, DOI 10.1016/j.jcss.2017.03.001
   [Anonymous], 2016, AUST J BASIC APPL SC
   Gordon A, 2016, IEEE CLOUD COMPUT, V3, P82, DOI 10.1109/MCC.2016.21
   Helmi AM, 2018, COMPUT ELECTR ENG, V67, P145, DOI 10.1016/j.compeleceng.2018.03.027
   Hudic A, 2017, COMPUT SECUR, V70, P723, DOI 10.1016/j.cose.2017.03.009
   Khan KM, 2010, IT PROF, V12, P20, DOI 10.1109/MITP.2010.128
   Laatikainen G, 2016, J SYST SOFTWARE, V122, P180, DOI 10.1016/j.jss.2016.09.008
   Li XY, 2015, IEEE T INF FOREN SEC, V10, P1402, DOI 10.1109/TIFS.2015.2413386
   Linthicum DS, 2016, IEEE CLOUD COMPUT, V3, P88, DOI 10.1109/MCC.2016.22
   Muthurajkumar S, 2015, PROCEDIA COMPUT SCI, V46, P589, DOI 10.1016/j.procs.2015.02.098
   Muthurajkumar S., 2015, P 7 INT C ADV COMP C, P1
   MUTHURAJKUMAR S, 2015, AUST J BASIC APPL SC, V9, P38
   Nagashree N, 2018, COMPUT IND, V97, P24, DOI 10.1016/j.compind.2018.01.018
   Qiu MK, 2018, FUTURE GENER COMP SY, V80, P421, DOI 10.1016/j.future.2016.01.006
   Rajeswari L. Prema, 2008, International Journal of Communications, Networks and System Sciences, V1, P314, DOI 10.4236/ijcns.2008.14039
   Saber T, 2018, FUTURE GENER COMP SY, V79, P751, DOI 10.1016/j.future.2017.06.015
   Tysowski PK, 2013, IEEE T CLOUD COMPUT, V1, P172, DOI 10.1109/TCC.2013.11
   Velapure Sunita S, 2014, IEEE T PARALL DISTR, V26, P1206, DOI DOI 10.1109/TPDS.2014.2318320
   Yuan HR, 2018, INFORM SCIENCES, V456, P159, DOI 10.1016/j.ins.2018.05.024
   Zhou L, 2013, IEEE T INF FOREN SEC, V8, P1947, DOI 10.1109/TIFS.2013.2286456
   Zhou YK, 2018, FUTURE GENER COMP SY, V84, P177, DOI 10.1016/j.future.2017.10.014
NR 21
TC 11
Z9 11
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5161
EP 5173
DI 10.1007/s11042-018-6339-0
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500053
DA 2024-07-18
ER

PT J
AU Zhan, YT
   Zhang, GY
AF Zhan, Yantong
   Zhang, Guoying
TI Ore particle size classification model based on bi-dimensional empirical
   mode decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bi-dimensional empirical mode decomposition; Ore image; Instantaneous
   frequency; Multivariate multiscale entropy; Particle size detection
ID IMAGE-ANALYSIS; FUSION
AB The frequency domain information of ore multi-scale image is difficult to distinguish boundary and texture details of ore objects, and hard to apply to particle size detection. Particle size classification model based on Bi-dimensional empirical mode decomposition (BEMD) is proposed, which is applied to particle detection of multi-size scenarios. Different size fraction ore images' local frequencies are extracted by BEMD reflecting the edge and texture features. The instantaneous frequencies of each high-frequency images are statistic with image multivariate multiscale entropy, and the entropy ranges can be mapped into the particle size distribution. Three different size fraction images are used to verify the accuracy of the proposed method. The experimental results show that the validity and accuracy of our proposed model is better than other methods in multi-scenario ore particle size detection.
C1 [Zhan, Yantong; Zhang, Guoying] China Univ Min & Technol, Sch Mech Elect & Informat Engn, Beijing 100083, Peoples R China.
C3 China University of Mining & Technology
RP Zhan, YT (corresponding author), China Univ Min & Technol, Sch Mech Elect & Informat Engn, Beijing 100083, Peoples R China.
EM yinpuliusha@163.com
RI Zhang, Guoying/G-8945-2016
OI Zhang, Guoying/0000-0001-9568-3702
CR Abhik M, 2017, INT J MIN SCI TECHNO, V27, P435, DOI 10.1016/j.ijmst.2017.03.015
   Acharya UR, 2018, COMPUT BIOL MED, V94, P11, DOI 10.1016/j.compbiomed.2017.12.024
   Artyom M, 2015, INT SOC OPT PHOTO
   Bhattacharya A, 2018, SOFT COMPUT, V22, P889, DOI 10.1007/s00500-016-2395-4
   Chen Z, 2014, INFRARED PHYS TECHN, V66, P114, DOI 10.1016/j.infrared.2014.05.013
   Facco P, 2017, CHEM ENG SCI, V164, P246, DOI 10.1016/j.ces.2017.01.053
   Guaragnella C., 2010, Proceedings of the 2010 IEEE International Conference on Computational Intelligence for Measurement Systems and Applications (CIMSA 2010), P30, DOI 10.1109/CIMSA.2010.5611761
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Huang NE, 2009, ADV DATA SCI ADAPT, V1, P177, DOI 10.1142/S1793536909000096
   Huang YP, 2017, ENERGIES, V10, DOI 10.3390/en10101655
   Lindeberg T, 1996, CERN REPORT, V96, P27
   Linderhed A, 2009, ADV DATA SCI ADAPT, V1, P265, DOI 10.1142/S1793536909000138
   Meng YC, 2018, MICRON, V106, P34, DOI 10.1016/j.micron.2017.12.002
   Mondal A, 2018, COMPUT METH PROG BIO, V159, P199, DOI 10.1016/j.cmpb.2018.03.016
   Nunes JC, 2003, IMAGE VISION COMPUT, V21, P1019, DOI 10.1016/S0262-8856(03)00094-5
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Qin XQ, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.1.013017
   Qin Y, 2018, COMPUT ELECTR ENG, V68, P215, DOI 10.1016/j.compeleceng.2018.03.033
   Sudarsan B, 2018, COMPUT ELECTRON AGR, V148, P217, DOI 10.1016/j.compag.2018.03.019
   Wang J, 2015, PHYSICA A, V421, P583, DOI 10.1016/j.physa.2014.12.001
   Yang YH, 2017, ACTA OCEANOL SIN, V36, P86, DOI 10.1007/s13131-017-1086-z
   Zhan YT, 2017, IEEE TRUST BIG, P973, DOI 10.1109/Trustcom/BigDataSE/ICESS.2017.339
   Zhang S, 2017, HYDROMETALLURGY, V171, P99, DOI 10.1016/j.hydromet.2017.05.001
   Zhang ZL, 2016, INT J MINER PROCESS, V155, P136, DOI 10.1016/j.minpro.2016.08.016
   Zheng JX, 2017, COMPUT GEOTECH, V88, P46, DOI 10.1016/j.compgeo.2017.02.021
NR 25
TC 1
Z9 1
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4847
EP 4866
DI 10.1007/s11042-018-6749-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500034
DA 2024-07-18
ER

PT J
AU Srivastava, G
   Srivastava, R
AF Srivastava, Gargi
   Srivastava, Rajeev
TI An efficient modification of generalized gradient vector flow using
   directional contrast for salient object detection and intelligent scene
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object detection; Minimum directional contrast; Generalized
   gradient vector flow
ID EXTERNAL FORCE; SNAKES; MODEL
AB In the field of computer vision, scene analysis is a very important area of study. To analyze the scene present in an image, in this paper, the attempt is to enhance salient object information with background information. For this, the Generalized Gradient Vector Flow model is modified by adding contrast information. The contrast information of an image is obtained by computing the Minimum Directional Contrast of the image. Using Minimum Directional Contrast as a determinant of the salient object arises from the fact that the salient objects have higher Minimum Directional Contrast than the non-salient objects. The Minimum Directional Contrast information is added to the data term of Generalized Gradient Vector Flow so that for producing contours, not only edge information is utilized, but saliency information is also used. The result gives us the salient object and added relevant background information. The algorithm is tested on three public datasets. The evaluation is done based on precision, recall, accuracy, and F1-score after comparing with six state-of-the-art methods.
C1 [Srivastava, Gargi] Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
   [Srivastava, Rajeev] Indian Inst Technol BHU, Varanasi 221005, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi); Indian Institute of
   Technology System (IIT System); Indian Institute of Technology BHU
   Varanasi (IIT BHU Varanasi)
RP Srivastava, G (corresponding author), Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
EM gargis.rs.cse16@iitbhu.ac.in
RI Srivastava, Rajeev/C-7906-2016; Srivastava, Gargi/AAC-4052-2019
OI Srivastava, Rajeev/0000-0002-0165-1556; Srivastava,
   Gargi/0000-0001-6770-561X
CR Borji A, 2015, IEEE T IMAGE PROCESS, V24, P742, DOI 10.1109/TIP.2014.2383320
   Chen X, 2019, MULTIMED TOOLS APPL, V78, P11173, DOI 10.1007/s11042-018-6690-1
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Huang K, 2018, IEEE IMAGE PROC, P2341, DOI 10.1109/ICIP.2018.8451046
   Huang L, 2016, PROCEEDINGS OF 2016 12TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P218, DOI [10.1109/CIS.2016.0058, 10.1109/CIS.2016.57]
   HUANG P, 2018, 2018 IEEE 23 INT C D, P1, DOI DOI 10.1109/ICDSP.2018.8631584
   Huang XM, 2017, IEEE T IMAGE PROCESS, V26, P4243, DOI 10.1109/TIP.2017.2710636
   Hyunjun Eun, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457798
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Ning JF, 2007, PATTERN RECOGN LETT, V28, P58, DOI 10.1016/j.patrec.2006.06.014
   Nouri F, 2015, 2015 SIGNAL PROCESSING AND INTELLIGENT SYSTEMS CONFERENCE (SPIS), P159, DOI 10.1109/SPIS.2015.7422332
   Qin LM, 2013, IEEE T CIRC SYST VID, V23, P883, DOI 10.1109/TCSVT.2013.2242554
   Seo Y, 2014, IEEE IMAGE PROC, P1145, DOI 10.1109/ICIP.2014.7025228
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Srivastava G., 2018, MATH COMPUTING, P74
   Sun XL, 2017, IEEE IMAGE PROC, P1532, DOI 10.1109/ICIP.2017.8296538
   Tan Xiuli, 2017, 2017 13th IEEE International Conference on Electronic Measurement & Instruments (ICEMI), P407, DOI 10.1109/ICEMI.2017.8265835
   Tang C, 2017, IEEE SIGNAL PROC LET, V24, P490, DOI 10.1109/LSP.2016.2620162
   Wang BG, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/152693
   Wang H, 2016, EVID-BASED COMPL ALT, V2016, DOI 10.1155/2016/8949835
   Wang X, 2018, INT GEOSCI REMOTE SE, P3631, DOI 10.1109/IGARSS.2018.8518425
   Wang XH, 2017, IEEE SIGNAL PROC LET, V24, P510, DOI 10.1109/LSP.2016.2611485
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Wu YW, 2013, COMPUT VIS IMAGE UND, V117, P1421, DOI 10.1016/j.cviu.2013.05.003
   Xu CY, 1998, SIGNAL PROCESS, V71, P131, DOI 10.1016/S0165-1684(98)00140-6
   Xu CY, 1997, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.1997.609299
   Yan HQ, 2016, INT GEOSCI REMOTE SE, P1560, DOI 10.1109/IGARSS.2016.7729398
   Yan XY, 2016, IEEE IMAGE PROC, P2762, DOI 10.1109/ICIP.2016.7532862
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang KF, 2016, IEEE T IMAGE PROCESS, V25, P3475, DOI 10.1109/TIP.2016.2572600
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Yu JG, 2016, IEEE T MULTIMEDIA, V18, P273, DOI 10.1109/TMM.2015.2505908
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
   Zhang JX, 2014, IEEE IMAGE PROC, P1175, DOI 10.1109/ICIP.2014.7025234
   Zhang Q, 2017, IEEE IMAGE PROC, P895, DOI 10.1109/ICIP.2017.8296410
   Zhang XT, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P120, DOI 10.1109/CIS.2017.00034
   Zhang YB, 2018, CHIN CONTR CONF, P9374, DOI 10.23919/ChiCC.2018.8484108
   Zhang YB, 2016, CHIN CONTR CONF, P4194, DOI 10.1109/ChiCC.2016.7554008
   Zhu CB, 2017, 2017 IEEE THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2017), P33, DOI 10.1109/BigMM.2017.22
NR 46
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13599
EP 13619
DI 10.1007/s11042-020-08609-y
EA JAN 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515798800005
DA 2024-07-18
ER

PT J
AU Wang, ZX
   Ho, SB
   Cambria, E
AF Wang, Zhaoxia
   Ho, Seng-Beng
   Cambria, Erik
TI A review of emotion sensing: categorization models and algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Affective computing; Emotion definition; Emotion categorization model;
   Sentiment analysis
ID FRAMEWORK; WORDS
AB Sentiment analysis consists in the identification of the sentiment polarity associated with a target object, such as a book, a movie or a phone. Sentiments reflect feelings and attitudes, while emotions provide a finer characterization of the sentiments involved. With the huge number of comments generated daily on the Internet, besides sentiment analysis, emotion identification has drawn keen interest from different researchers, businessmen and politicians for polling public opinions and attitudes. This paper reviews and discusses existing emotion categorization models for emotion analysis and proposes methods that enhance existing emotion research. We carried out emotion analysis by inviting experts from different research areas to produce comprehensive results. Moreover, a computational emotion sensing model is proposed, and future improvements are discussed in this paper.
C1 [Wang, Zhaoxia] Singapore Management Univ, Sch Informat Syst, 80 Stamford Rd, Singapore 178902, Singapore.
   [Ho, Seng-Beng] ASTAR, Inst High Performance Comp, 1 Fusionopolis Way, Singapore 138632, Singapore.
   [Cambria, Erik] Nanyang Technol Univ, Sch Comp Sci & Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
C3 Singapore Management University; Agency for Science Technology &
   Research (A*STAR); A*STAR - Institute of High Performance Computing
   (IHPC); Nanyang Technological University
RP Cambria, E (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
EM zxwang@smu.edu.sg; hosb@ihpc.a-star.edu.sg; cambria@ntu.edu.sg
RI Cambria, Erik/C-2103-2013; Li, Yang/HPC-4054-2023
OI Cambria, Erik/0000-0002-3030-1280; WANG, Zhaoxia/0000-0001-7674-5488
CR [Anonymous], 2001, EMOTIONS SOCIAL PSYC
   Ashkanasy NM, 2008, NEW HORIZ MANAG, P1
   Balahur A, 2013, DATA KNOWL ENG, V88, P113, DOI 10.1016/j.datak.2013.08.002
   Cambria Erik, 2012, Cognitive Behavioural Systems (COST 2012). International Training School. Revised Selected Papers, P144, DOI 10.1007/978-3-642-34584-5_11
   Cambria E, 2018, AAAI CONF ARTIF INTE, P1795
   Cambria E, 2017, IEEE INTELL SYST, V32, P74, DOI 10.1109/MIS.2017.4531228
   Cambria E, 2015, LECT NOTES COMPUT SC, V9042, P3, DOI 10.1007/978-3-319-18117-2_1
   Cambria E, 2012, EXPERT SYST APPL, V39, P10533, DOI 10.1016/j.eswa.2012.02.120
   Cambria E, 2010, LECT NOTES COMPUT SC, V5967, P148
   Chafale D, 2014, INT J COMPUT SCI ENG, V2
   Chikersal P, 2015, LECT NOTES COMPUT SC, V9042, P49, DOI 10.1007/978-3-319-18117-2_4
   Ding Z, 2019, P AAAI
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Ghazi D, 2014, COMPUT SPEECH LANG, V28, P76, DOI 10.1016/j.csl.2013.04.009
   Gui L., 2016, P 2016 C EMP METH NA, P1639, DOI DOI 10.18653/V1/D16-1170
   Howard N, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-9
   Huangfu LW, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS: BIG DATA, EMERGENT THREATS, AND DECISION-MAKING IN SECURITY INFORMATICS, P116, DOI 10.1109/ISI.2013.6578799
   Latinjak AT, 2012, REV IBEROAM PSICOL E, V7, P71
   Lerner JS, 2015, ANNU REV PSYCHOL, V66, P799, DOI 10.1146/annurev-psych-010213-115043
   Li HF, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-5, P2222, DOI 10.1109/ROBIO.2007.4522515
   Ma YK, 2018, AAAI CONF ARTIF INTE, P5876
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Neviarouskaya A, 2007, LECT NOTES COMPUT SC, V4738, P218
   ORTONY A, 1990, PSYCHOL REV, V97, P315, DOI 10.1037/0033-295X.97.3.315
   Ortony A., 1988, COGNITIVE STRUCTURE
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344
   Poria S, 2016, IEEE DATA MINING, P439, DOI [10.1109/ICDM.2016.178, 10.1109/ICDM.2016.0055]
   Poria S, 2014, KNOWL-BASED SYST, V69, P45, DOI 10.1016/j.knosys.2014.05.005
   Reeck C, 2016, TRENDS COGN SCI, V20, P47, DOI 10.1016/j.tics.2015.09.003
   Robinson D.L., 2008, Neth. J. Psychol., V64, P152, DOI DOI 10.1007/BF03076418
   Schulz A., 2013, Proceedings of the 10th International ISCRAM Conference, P846
   SHAVER P, 1987, J PERS SOC PSYCHOL, V52, P1061, DOI 10.1037//0022-3514.52.6.1061
   Shivhare SN, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P52, DOI 10.1109/CCAA.2015.7148343
   Soares AP, 2012, BEHAV RES METHODS, V44, P256, DOI 10.3758/s13428-011-0131-7
   Steunebrink BR, 2009, P 4 WORK EM COMP
   Suttles Jared, 2013, Computational Linguistics and Intelligent Text Processing. 14th International Conference, CICLing 2013. Proceedings, P121, DOI 10.1007/978-3-642-37256-8_11
   Wang Z, 2015, Patent No. [10201601413Q, 1020601413]
   Wang ZX, 2016, INT CONF DAT MIN WOR, P978, DOI [10.1109/ICDMW.2016.37, 10.1109/ICDMW.2016.0142]
   Wang ZX, 2016, PROCEEDINGS OF 2016 FUTURE TECHNOLOGIES CONFERENCE (FTC), P1361, DOI 10.1109/FTC.2016.7821783
   Wang ZX, 2014, INT CONF CLOUD COMP, P917, DOI 10.1109/CloudCom.2014.69
   Wang ZX, 2014, INT CONF CLOUD COMP, P899, DOI 10.1109/CloudCom.2014.40
   Wang Z, 2014, BMC GENOMICS, V15, DOI 10.1186/1471-2164-15-529
   Xia R, 2019, P INT JOINT C ART IN
   Xia R, 2019, P ASS COMP LING ACL
   Yu Y, 2015, COMPUT HUM BEHAV, V48, P392, DOI 10.1016/j.chb.2015.01.075
NR 45
TC 69
Z9 72
U1 8
U2 65
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35553
EP 35582
DI 10.1007/s11042-019-08328-z
EA JAN 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000574070600001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Chouhan, SS
   Kaul, A
   Singh, UP
AF Chouhan, Siddharth Singh
   Kaul, Ajay
   Singh, Uday Pratap
TI Image segmentation using fuzzy competitive learning based counter
   propagation network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bacterial foraging algorithm; Counter propagation network; Fuzzy
   competitive learning; Image segmentation; Soft computing
ID GENETIC ALGORITHM; NEURAL-NETWORKS; FEATURE-SPACE; MEAN SHIFT;
   OPTIMIZATION; INFORMATION; SYSTEM
AB Image segmentation is the method of partitioning an image into some homogenous regions that are more meaningful for its better understanding and examination. Soft computing methods having the capabilities of achieving artificial intelligence are predominately used to perform the task of segmentation. Due to the variability and the uncertainty present in natural scenes, segmentation is a complicated task to perform with the help of conventional image segmentation techniques. Therefore, in this article a hybrid Fuzzy Competitive Learning based Counter Propagation Network (FCPN) is proposed for the segmentation of natural scene images. This method compromises of the uncertainty handling capabilities of the fuzzy system and proficiency of parallel learning ability of neural network. To identify the number of clusters automatically in less computational time, the instar layer of Counter propagation network (CPN) has been trained by using Fuzzy competitive learning (FCL). The outstar layer of counter propagation network is trained by using Grossberg learning for obtaining the desired output. Region growing method having the tendency to correctly identify edges with simplicity is used for initial seed point selection. Then, the most similar regions in the image are clustered and the number of clusters is estimated automatically. Finally, by identifying the cluster centers the images are segmented. Bacterial foraging algorithm is used to initialize the initial weights to the network, which helps the proposed method in achieving low convergence ratio with higher accuracy. Results validated the higher performance of proposed FCPN method when compared with other states-of-the-art methods. For future work, some other adaptive methods like the fuzzy model-based network can be used to identify multiple object regions and classifying them among separate clusters.
C1 [Chouhan, Siddharth Singh; Kaul, Ajay] Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra 182320, India.
   [Singh, Uday Pratap] Shri Mata Vaishno Devi Univ, Sch Math, Katra 182320, India.
C3 Shri Mata Vaishno Devi University; Shri Mata Vaishno Devi University
RP Chouhan, SS (corresponding author), Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra 182320, India.
EM siddharth.lnct@gmail.com
RI Chouhan, Siddharth Singh/X-5909-2019; Singh, Uday Pratap/AAW-9594-2020
OI Chouhan, Siddharth Singh/0000-0003-3787-1857; Singh, Uday
   Pratap/0000-0003-2077-0793
CR Abdel-Khalek S, 2017, OPTIK, V131, P414, DOI 10.1016/j.ijleo.2016.11.039
   Aghajari E, 2017, APPL SOFT COMPUT, V54, P347, DOI 10.1016/j.asoc.2017.01.003
   [Anonymous], COMMUNICATIONS COMPU
   [Anonymous], SPIE MED IMAGING
   [Anonymous], AUTOMATED BRAIN TISS
   [Anonymous], ADV INTELLIGENT SYST
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Arumugadevi S, 2016, INT J AUTOM COMPUT, V13, P491, DOI 10.1007/s11633-016-0975-5
   Arumugadevi S., 2015, INDIAN J SCI TECHNOL, V8, P670
   Bdiri T, 2013, NEURAL COMPUT APPL, V23, P1443, DOI 10.1007/s00521-012-1094-z
   Bhattacharyya S, 2011, APPL SOFT COMPUT, V11, P946, DOI 10.1016/j.asoc.2010.01.015
   Borges VR, 2015, SOFT COMPUT, V19, P339, DOI 10.1007/s00500-014-1256-2
   Chouhan SS, 2019, ARCH COMPUT METHOD E, V26, P533, DOI 10.1007/s11831-018-9257-4
   Choy SK, 2017, PATTERN RECOGN, V68, P141, DOI 10.1016/j.patcog.2017.03.009
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   De S, 2012, APPL SOFT COMPUT, V12, P3228, DOI 10.1016/j.asoc.2012.05.011
   Fan WT, 2012, IEEE T NEUR NET LEAR, V23, P762, DOI 10.1109/TNNLS.2012.2190298
   Gharieb RR, 2017, SIGNAL IMAGE VIDEO P, V11, P541, DOI 10.1007/s11760-016-0992-4
   Helmy AK, 2016, APPL SOFT COMPUT, V40, P405, DOI 10.1016/j.asoc.2015.11.042
   Huang YZ, 2006, J COMPUT ELECTRON, V5, P275, DOI 10.1007/s10825-006-0145-z
   Jiang XL, 2016, NEUROCOMPUTING, V207, P22, DOI 10.1016/j.neucom.2016.03.046
   Kang ZH, 2016, CARBON NANOSTRUCT, P257, DOI 10.1007/978-3-319-28782-9_8
   Khan A, 2015, APPL SOFT COMPUT, V32, P300, DOI 10.1016/j.asoc.2015.03.029
   Konar D, 2016, APPL SOFT COMPUT, V46, P731, DOI 10.1016/j.asoc.2015.12.040
   Li LG, 2016, IEEE ACCESS, V4, P6438, DOI 10.1109/ACCESS.2016.2613940
   Li YL, 2010, SOFT COMPUT, V14, P123, DOI 10.1007/s00500-009-0442-0
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Long YJ, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P419, DOI 10.1109/MMSP.2006.285343
   Makrogiannis S, 2005, IEEE T SYST MAN CY B, V35, P44, DOI 10.1109/TSMCB.2004.837756
   Maszczyk T, 2008, LECT NOTES ARTIF INT, V5097, P643, DOI 10.1007/978-3-540-69731-2_62
   Mondal A, 2016, APPL SOFT COMPUT, V47, P191, DOI 10.1016/j.asoc.2016.05.026
   Nandagopalan S., 2008, INT J COMPUT ELECT A, V2, P3436
   Passino KM, 2002, IEEE CONTR SYST MAG, V22, P52, DOI 10.1109/MCS.2002.1004010
   Sakhre V, 2017, INT J FUZZY SYST, V19, P452, DOI 10.1007/s40815-016-0145-5
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Singh UP, 2019, SOFT COMPUT, V23, P4955, DOI 10.1007/s00500-018-3160-7
   Singh UP, 2018, SOFT COMPUT, V22, P2667, DOI 10.1007/s00500-017-2522-x
   Singh UP, 2016, INT J COMPUT INTELL, V15, DOI 10.1142/S1469026816500164
   Tao WB, 2007, IEEE T SYST MAN CY B, V37, P1382, DOI 10.1109/TSMCB.2007.902249
   Wang L, 2015, NEUROIMAGE, V108, P160, DOI 10.1016/j.neuroimage.2014.12.042
   Wang ZB, 2010, IMAGE VISION COMPUT, V28, P5, DOI 10.1016/j.imavis.2009.06.007
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yin SB, 2017, PATTERN RECOGN, V68, P245, DOI 10.1016/j.patcog.2017.03.012
   Zhao JJ, 2016, FRONT COMPUT SCI-CHI, V10, P189, DOI 10.1007/s11704-015-4543-x
NR 46
TC 8
Z9 8
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35263
EP 35287
DI 10.1007/s11042-019-08094-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800046
DA 2024-07-18
ER

PT J
AU Lou, JW
   Cai, XX
   Wang, YM
   Yu, H
   Canavan, S
AF Lou, Jianwen
   Cai, Xiaoxu
   Wang, Yiming
   Yu, Hui
   Canavan, Shaun
TI Multi-subspace supervised descent method for robust face alignment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unconstrained face alignment; SDM; Subspace learning; Cascaded
   regression
AB Supervised Descent Method (SDM) is one of the leading cascaded regression approaches for face alignment with state-of-the-art performance and a solid theoretical basis. However, SDM is prone to local optima and likely averages conflicting descent directions. This makes SDM ineffective in covering a complex facial shape space due to large head poses and rich non-rigid face deformations. In this paper, a novel two-step framework called multi-subspace SDM (MS-SDM) is proposed to equip SDM with a stronger capability for dealing with unconstrained faces. The optimization space is first partitioned with regard to shape variations using k-means. The generated subspaces show semantic significance which highly correlates with head poses. Faces among a certain subspace also show compatible shape-appearance relationships. Then, Naive Bayes is applied to conduct robust subspace prediction by concerning about the relative proximity of each subspace to the sample. This guarantees that each sample can be allocated to the most appropriate subspace-specific regressor. The proposed method is validated on benchmark face datasets with a mobile facial tracking implementation.
C1 [Lou, Jianwen; Cai, Xiaoxu; Wang, Yiming; Yu, Hui] Univ Portsmouth, Sch Creat Technol, Portsmouth PO1 2DJ, Hants, England.
   [Canavan, Shaun] Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA.
C3 University of Portsmouth; State University System of Florida; University
   of South Florida
RP Yu, H (corresponding author), Univ Portsmouth, Sch Creat Technol, Portsmouth PO1 2DJ, Hants, England.
EM hui.yu@port.ac.uk
RI Yu, Hui/G-1115-2018; Wang, Yiming/KTI-0022-2024
OI Yu, Hui/0000-0002-7655-9228; Wang, Yiming/0000-0002-4390-5796
FU EPSRC [EP/N025849/1]; UoP RIDF2017 fund; Emteq; State Key Laboratory for
   Management and Control of Complex Systems, Institute of Automation,
   Chinese Academy of Sciences [Y6S9011F51]; EPSRC [EP/N025849/1] Funding
   Source: UKRI
FX This work was supported by the EPSRC through project 4D Facial Sensing
   and Modelling (EP/N025849/1), UoP RIDF2017 fund, the Emteq
   (https://emteq.net/) and was in part supported by the Open Fund of the
   State Key Laboratory for Management and Control of Complex Systems,
   Institute of Automation, Chinese Academy of Sciences (Y6S9011F51).
CR Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23
   Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Chrysos GG, 2018, INT J COMPUT VISION, V126, P198, DOI 10.1007/s11263-017-0999-5
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cristinacce D., 2006, BRIT MACH VIS C, V1, P3
   Guo SR, 2017, MULTIMED TOOLS APPL, V76, P8677, DOI 10.1007/s11042-016-3470-7
   Jian M, 2015, IEEE T CIRC SYST VID, V25, P1761, DOI 10.1109/TCSVT.2015.2400772
   Jourabloo A, 2016, PROC CVPR IEEE, P4188, DOI 10.1109/CVPR.2016.454
   Jourabloo A, 2015, IEEE I CONF COMP VIS, P3694, DOI 10.1109/ICCV.2015.421
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Liu QS, 2016, IEEE T IMAGE PROCESS, V25, P700, DOI 10.1109/TIP.2015.2502485
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Messer K., 1999, 2 INT C AUD VID BAS, V964, P965
   Saeed A, 2018, MULTIMED TOOLS APPL, V77, P2261, DOI 10.1007/s11042-016-4261-x
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Semwal VB, 2017, NEURAL COMPUT APPL, V28, P565, DOI 10.1007/s00521-015-2089-3
   Shao XH, 2017, IEEE COMPUT SOC CONF, P2069, DOI 10.1109/CVPRW.2017.258
   Tao DP, 2018, IEEE T CIRC SYST VID, V28, P2657, DOI 10.1109/TCSVT.2017.2726580
   Tao DP, 2018, IEEE T IMAGE PROCESS, V27, P325, DOI 10.1109/TIP.2017.2762588
   Wang NN, 2018, NEUROCOMPUTING, V275, P50, DOI 10.1016/j.neucom.2017.05.013
   Wang YM, 2017, IEEE IMAGE PROC, P2831, DOI 10.1109/ICIP.2017.8296799
   Weng CH, 2017, LECT NOTES COMPUT SC, V10118, P117, DOI 10.1007/978-3-319-54526-4_9
   Xia YF, 2018, 2018 16TH IEEE INT CONF ON DEPENDABLE, AUTONOM AND SECURE COMP, 16TH IEEE INT CONF ON PERVAS INTELLIGENCE AND COMP, 4TH IEEE INT CONF ON BIG DATA INTELLIGENCE AND COMP, 3RD IEEE CYBER SCI AND TECHNOL CONGRESS (DASC/PICOM/DATACOM/CYBERSCITECH), P862, DOI 10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.00-17
   Xiao ST, 2017, IEEE COMPUT SOC CONF, P2060, DOI 10.1109/CVPRW.2017.257
   Xiong X., 2014, ARXIV14050601
   Xiong XH, 2015, PROC CVPR IEEE, P2664, DOI 10.1109/CVPR.2015.7298882
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yang J, 2017, IEEE COMPUT SOC CONF, P2025, DOI 10.1109/CVPRW.2017.253
   YimingWang Hui Yu, 2016, ASIAN C COMPUT VIS, P375
   Yu H, 2014, IEEE T HUM-MACH SYST, V44, P386, DOI 10.1109/THMS.2014.2313912
   Yu X, 2016, IJCAI, P2711
   Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1
   Zhang YZ, 2016, ACM SIGPLAN NOTICES, V51, P281, DOI [10.1145/2908080.2908086, 10.1145/2980983.2908086]
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zhao Y., 2018, MATH PROBL ENG, P1
   Zhao Y, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2019), P1, DOI [10.1109/aicas.2019.8771573, 10.1109/AICAS.2019.8771573]
   Zhu SZ, 2016, PROC CVPR IEEE, P3409, DOI 10.1109/CVPR.2016.371
   Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
   Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23
NR 40
TC 6
Z9 7
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35455
EP 35469
DI 10.1007/s11042-019-08129-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800054
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Qumsieh, R
   Farajallah, M
   Hamamreh, R
AF Qumsieh, Rawan
   Farajallah, Mousa
   Hamamreh, Rushdi
TI Joint block and stream cipher based on a modified skew tent map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stream cipher; Block cipher; Finite State Tent Map; Cryptosystem
ID 2-DIMENSIONAL CHAOTIC MAP; IMAGE; ALGORITHM; CRYPTOGRAPHY
AB Image encryption is very different from that of texts due to the bulk data capacity and the high redundancy of images. Thus, traditional methods are difficult to use for image encryption as their pseudo-random sequences have small space. Chaotic cryptography use chaos theory in specific systems working such as computing algorithms to accomplish dissimilar cryptographic tasks in a cryptosystem with a fast throughput. For higher security, encryption is the approach to guard information and prevent its leakage. In this paper, a hybrid encryption scheme that combines both stream and block ciphering algorithms is proposed in order to achieve the required level of security with the minimum encryption time. This scheme is based on an improved mathematical model to cover the defects in the previous discredited model proposed by Masuda. The proposed chaos-based cryptosystem uses the improved Skew Tent Map (STM) RQ-FSTM as a substitution layer. This map is based on a lookup table to overcome various problems, such as the fixed point, the key space restrictions, and the limitation of mapping between plain text and cipher text. It uses the same map as a generator to change the byte position to achieve the required confusion and diffusion effects. This modification improves the security level of the original STM. The robustness of the proposed cryptosystem is proven by the performance and the security analysis, as well as the high encryption speed. Depending on the results of the security analysis the proposed system has a better dynamic key space than previous ones using STM, a double encryption quality and a better security analysis than others in the literature with speed convenience to real-time applications.
C1 [Qumsieh, Rawan] Palestine Polytech Univ, Hebron, Palestine.
   [Farajallah, Mousa] Palestine Polytech Univ, Comp Engn & Secur Dept, Hebron, Palestine.
   [Hamamreh, Rushdi] Al Quds Univ, Dept Comp Engn, East Jerusalem, Palestine.
C3 Palestine Polytechnic University; Palestine Polytechnic University;
   Al-Quds University
RP Farajallah, M (corresponding author), Palestine Polytech Univ, Comp Engn & Secur Dept, Hebron, Palestine.
EM rawan.iq@gmail.com; mousa_math@ppu.edu; rushdi@staff.alquds.edu
RI Farajallah, Mousa/N-8399-2017
CR Ahmad M., 2009, Int. J. Comput. Sci. Eng., V2, P46
   Ahmed HAM, 2007, INZ MINER, P1
   Akhshani A, 2012, COMMUN NONLINEAR SCI, V17, P4653, DOI 10.1016/j.cnsns.2012.05.033
   [Anonymous], 2015, THESIS
   [Anonymous], 2001, STAT TEST SUITE RAND
   Baptista MS, 1998, PHYS LETT A, V240, P50, DOI 10.1016/S0375-9601(98)00086-3
   Belkhouche F, 2003, IEEE REGION 5 2003 ANNUAL TECHNICAL CONFERENCE, CONFERENCE RECORD, P39, DOI 10.1109/REG5.2003.1199708
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   BROWN WS, 1971, J ACM, V18, P478, DOI 10.1145/321662.321664
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Cohen J., 2013, APPL MULTIPLE REGRES
   Desmedt YG, 2003, ADV CRYPTOLOGY CRYPT, V839
   Ehrsam W. F., 1978, U.S. Patent, Patent No. 4074066
   El Assad S., 2014, uS Patent, Patent No. [8,781,116, 8781116]
   Farajallah M., 2013, 2013 IEEE International Conference on Green Computing and Communications (GreenCom) and IEEE Internet of Things (iThings) and IEEE Cyber, Physical and Social Computing (CPSCom), P282, DOI 10.1109/GreenCom-iThings-CPSCom.2013.65
   Farajallah M, 2016, 10 INT C EM SEC INF
   Farajallah M, 2018, MULTIMED TOOLS APPL, V77, P28225, DOI 10.1007/s11042-018-6015-4
   Fridrich J, 1997, IEEE SYS MAN CYBERN, P1105, DOI 10.1109/ICSMC.1997.638097
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fridrich J., 1997, SECURE IMAGE CIPHERI
   Gotz M, 1997, IEEE T CIRCUITS-I, V44, P963, DOI 10.1109/81.633885
   Habutsu T., 1990, Transactions of the Institute of Electronics, Information and Communication Engineers E, VE73, P1041
   Habutsu T., 1991, ADV CRYPTOLOGY EUROC, V91, P127
   Hamza R, 2016, INF SECUR J, V25, P162, DOI 10.1080/19393555.2016.1212954
   Hraoui S, 2013, 2013 ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS (AICCSA)
   Jakimoski G, 2001, PHYS LETT A, V291, P381, DOI 10.1016/S0375-9601(01)00771-X
   Jessa M., 2000, 2000 IEEE International Symposium on Circuits and Systems. Emerging Technologies for the 21st Century. Proceedings (IEEE Cat No.00CH36353), P711, DOI 10.1109/ISCAS.2000.857194
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P2943, DOI 10.1016/j.cnsns.2011.11.030
   Kocarev L., 1998, ISCAS '98. Proceedings of the 1998 IEEE International Symposium on Circuits and Systems (Cat. No.98CH36187), P514, DOI 10.1109/ISCAS.1998.698968
   Lewis-Beck M, 1995, DATA ANAL INTRO, P103
   Li Chunhu, 2019, INT J NETW SECUR, V21, P22
   Li S., 2003, THESIS XIAN JIAOTONG
   Li S., 2001, IMA International Conference on Cryptography and Coding, V2260, P205, DOI [10.1007/3-540-45325-319, DOI 10.1007/3-540-45325-319]
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Maleki F, 2008, ARES 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON AVAILABILITY, SECURITY AND RELIABILITY, P1266, DOI 10.1109/ARES.2008.121
   Masuda N, 2002, IEEE T CIRCUITS-I, V49, P28, DOI 10.1109/81.974872
   Masuda N, 2006, IEEE T CIRCUITS-I, V53, P1341, DOI 10.1109/TCSI.2006.874182
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Muhammad K, 2018, IEEE T IND INFORM, V14, P3679, DOI 10.1109/TII.2018.2791944
   Munir R., 2012, 2012 7th International Conference on Telecommunications, Systems, Services, and Applications (TSSA 2012), P142, DOI 10.1109/TSSA.2012.6366039
   Murillo-Escobar M., 2014, P INT C COMM SIGN PR, VVolume 4953
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Pareek N. K., 2005, Communications in Nonlinear Science and Numerical Simulation, V10, P715, DOI 10.1016/j.cnsns.2004.03.006
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Pareek NK, 2003, PHYS LETT A, V309, P75, DOI 10.1016/S0375-9601(03)00122-1
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Protopopescu V. A., 1995, US Patent, Patent No. 5479513
   Rafik H, 2019, INFORM SCI
   ROSSLER OE, 1976, PHYS LETT A, V57, P397, DOI 10.1016/0375-9601(76)90101-8
   Ruelle D., 2006, NOTICES AMS, V53, P764
   Sang T, 1998, ELECTRON LETT, V34, P873, DOI 10.1049/el:19980680
   Schneier B., 1993, INT WORKSH FAST SOFT, P191, DOI DOI 10.1007/3-540-58108-1_24
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   SHARKOVSKII AN, 1995, INT J BIFURCAT CHAOS, V5, P1263, DOI 10.1142/S0218127495000934
   Sharma M, 2010, IMAGE ENCRYPTION TEC
   Shujuna L, 2001, INT C CRYPTOLOGY IND, V16, P20
   Soto J., 1999, P 22 NAT INF SYST SE, V10, P12
   Srividya G., 2011, 2011 International Conference on Communications and Signal Processing (ICCSP), P266, DOI 10.1109/ICCSP.2011.5739316
   Volos C. K., 2015, J APPL MATH BIOINFOR, V5, P15
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wheeler DD., 1989, CRYPTOLOGIA, V13, P243, DOI DOI 10.1080/0161-118991863934
   William S., 1999, CRYPTOGRAPHY NETWORK, P23
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xu QY, 2019, OPT LASER ENG, V121, P203, DOI 10.1016/j.optlaseng.2019.04.011
   Yano K, 2002, IEICE T FUND ELECTR, VE85A, P2025
   ZAIKIN AN, 1970, NATURE, V225, P535, DOI 10.1038/225535b0
   Zhang H, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS, INTELLIGENT SYSTEMS AND SIGNAL PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P778
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P2066, DOI 10.1016/j.cnsns.2012.12.012
NR 72
TC 7
Z9 7
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33527
EP 33547
DI 10.1007/s11042-019-08112-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600044
DA 2024-07-18
ER

PT J
AU Ashiba, HI
AF Ashiba, H., I
TI Cepstrum adaptive plateau histogram for dark IR night vision images
   enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Night vision; Image negative method; Log transformation method; The APH;
   The CHFE
ID FUSION
AB This paper presents a novel enhancement algorithm for infrared (IR) images. This suggested algorithm mixes the benefits of the adaptive plateau histogram equalization (APH) and the cepstrum of homomorphic filtering enhancement (CHFE). The main idea of this approach depends on applying the APH on the IR image. Then, the resultant image is applied on the frequency domain by using the CHFE. This CHFE model is depending on the image has produced high energy that received from object. The energy received is determined by illumination radiation source and the features of reflectance of the object itself. Applying this model on the APH gives more details in the IR image and the IR night vision images show like as in the morning. The performance quality metrics for the suggested approach are entropy, average gradient, contrast, and Sobel edge magnitude. Simulation results reveal the success of the proposed approach in enhancing the quality of IR images.
C1 [Ashiba, H., I] Bilbis Higher Inst Engn, Dept Elect & Elect Commun, Bilbis, Sharqia, Egypt.
RP Ashiba, HI (corresponding author), Bilbis Higher Inst Engn, Dept Elect & Elect Commun, Bilbis, Sharqia, Egypt.
EM eng_h_2006@yahoo.com
RI ashiba, huda/GQI-4310-2022
OI ashiba, huda/0000-0002-4926-8919
CR Ashiba HI, 2019, MULTIMED TOOLS APPL, V78, P11277, DOI 10.1007/s11042-018-6545-9
   Ashiba H. I., 2008, Progress In Electromagnetics Research C, V1, P123, DOI 10.2528/PIERC08012301
   Chang YC, 2010, IEEE T CONSUM ELECTR, V56, P737, DOI 10.1109/TCE.2010.5505995
   Furnari A, 2017, J VIS COMMUN IMAGE R, V46, P165, DOI 10.1016/j.jvcir.2017.03.019
   Gade R, 2014, MACH VISION APPL, V25, P245, DOI 10.1007/s00138-013-0570-5
   Gonzalez Rafael C., 2008, WOODS DIGITAL IMAGE
   Gonzalez RC, 2008, WOODS DIGITAL IMAGE
   Hinojosa S, 2018, NEUROCOMPUTING, V321, P201, DOI 10.1016/j.neucom.2018.09.034
   Huang ZH, 2016, INFRARED PHYS TECHN, V79, P205, DOI 10.1016/j.infrared.2016.11.001
   Lai R, 2010, OPT COMMUN, V283, P4283, DOI 10.1016/j.optcom.2010.06.072
   Lin CL, 2011, INFRARED PHYS TECHN, V54, P84, DOI 10.1016/j.infrared.2011.01.001
   Qadar MA, 2015, OPTIK, V126, P5890, DOI 10.1016/j.ijleo.2015.08.278
   Torabi A, 2012, COMPUT VIS IMAGE UND, V116, P210, DOI 10.1016/j.cviu.2011.10.006
   Vickers VE, 1996, OPT ENG, V35, P1921, DOI 10.1117/1.601006
   Wan MJ, 2018, INFRARED PHYS TECHN, V91, P164, DOI 10.1016/j.infrared.2018.04.003
   Wang BJ, 2006, INFRARED PHYS TECHN, V48, P77, DOI 10.1016/j.infrared.2005.04.008
   Wang J, 2014, INFRARED PHYS TECHN, V67, P477, DOI 10.1016/j.infrared.2014.09.019
   Wang Y, 2017, INFRARED PHYS TECHN, V86, P59, DOI 10.1016/j.infrared.2017.08.005
   Wu Z, THERMAL INFRARED VID
   Zhang QY, 2018, J PETROL SCI ENG, V160, P433, DOI 10.1016/j.petrol.2017.10.048
NR 20
TC 10
Z9 10
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2543
EP 2554
DI 10.1007/s11042-019-08154-3
EA NOV 2019
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000502127000003
DA 2024-07-18
ER

PT J
AU Al-Qarni, BH
   Almogren, A
   Hassan, MM
AF Al-Qarni, Bandar H.
   Almogren, Ahmad
   Hassan, Mohammad Mehedi
TI An efficient networking protocol for internet of things to handle
   multimedia big data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Communication protocol; Internet of things; Multimedia big data; Mobile
   adhoc network; Energy preservation; Clustering; Congestion control;
   Links utilization
ID SENSOR NETWORKS
AB In recent years, the emergence of multimedia big data (MBD) due to the excessive use of mobile Internet of Things (ioT) is imposing various challenges to develop efficient communication with the digital world. In this aspect, Mobile Adhoc Network based IoT (MANET-IoT) system is becoming popular due to its greater mobility support and cost-effective nature. A mobile ad hoc network (MANET) consists of randomly placed, battery-powered, moving nodes without an infrastructure that can administer and control traffic in the IoT network. In the MANET-IoT network, the major problems include energy consumption and congestion control to handle MBD data. In this paper, we present two proposals for solving these problems. In the first proposal, a new clustering approach that depends on a well-known protocol called the Low Energy Adaptive Clustering Hierarchy (LEACH) been used in a wireless sensor network (WSN) with modification to adapt to the MANET-IoT's mobility. Our proposal for applying LEACH to a MANET-IoT consists of rounds, each containing three ordered phases as follows: (1) the announcement phase, in which all nodes announce their remaining energy and the node with the original message also announces itself; (2) the setup phase, in which all cluster heads are selected based on the probability factor with a cycling method; and (3) the steady state phase, in which message delivery to all nodes occurs using several types of links. The second proposal is to provide congestion control for all mobile nodes by link utilization that can support different data rates depending on the link status. Simulation results comparing our modified LEACH protocol to state-of-the-art protocols with utilized links show a great enhancement in energy consumption, received data, throughput, and delay.
C1 [Al-Qarni, Bandar H.; Almogren, Ahmad; Hassan, Mohammad Mehedi] King Saud Univ, Coll Comp & Informat Sci, Riyadh 11543, Saudi Arabia.
C3 King Saud University
RP Hassan, MM (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Riyadh 11543, Saudi Arabia.
EM alqarni.bander@gmail.com; ahalmogren@ksu.edu.sa; mmhassan@ksu.edu.sa
RI Hassan, Mohammad/KDM-9524-2024; Hassan, Mohammad Mehedi/D-4946-2016;
   Almogren, Ahmad S/F-1365-2014; Hassan, Mohammad/GZA-7507-2022
OI Almogren, Ahmad S/0000-0002-8253-9709; Hassan,
   Mohammad/0000-0002-1712-0004
FU Deanship of Scientific Research at King Saud University [RGP- 1437-35]
FX The authors extend their appreciation to the Deanship of Scientific
   Research at King Saud University for funding this work through research
   group no (RGP- 1437-35).
CR Afsar MM, 2014, J NETW COMPUT APPL, V46, P198, DOI 10.1016/j.jnca.2014.09.005
   Agarwal R., 2009, International Journal on Computer Science and Engineering, V1, P98
   Alameri IA, 2018, ENG TECHNOL APPL SCI, V8, P2604
   [Anonymous], AD HOC NETWORKS
   [Anonymous], 2018, MULTIMEDIA ENABLED S
   [Anonymous], 2012, OVERVIEW INTERNET TH
   Arshad S, 2019, IEEE INTERNET THINGS, V6, P2128, DOI 10.1109/JIOT.2018.2873343
   Arvind S, 2013, GLOBAL J COMP SCI TE, V13
   Balakrishna R, 2013, NAT C FRONT ADV INF
   Bellavista P, 2013, IEEE SENS J, V13, P3558, DOI 10.1109/JSEN.2013.2272099
   Fan S, 2014, APPL MECH MAT, V989-994, P4373
   Hnini Abdelhalim, 2015, Journal of Theoretical and Applied Information Technology, V80, P500
   Javed F, 2018, IEEE COMMUN SURV TUT, V20, P2062, DOI 10.1109/COMST.2018.2817685
   Kazerooni AA, 2015, ADV SCI TECHNOL-RES, V9, P7, DOI 10.12913/22998624/1918
   LI G, 2013, J COMPUTATIONAL INFO, V9, P8541
   Lin-Feng L, 2014, APPL MECH MAT, V743, P748
   MANJUL M, 2013, COMMUNICATIONS NETWO, V5, P649
   Sharma P, 2014, INT J ADV RES COMPUT, V5, P237
   Wang NC, 2013, TELECOMMUN SYST, V52, P97, DOI 10.1007/s11235-011-9463-y
   Yiming Miao, 2015, Applied Mechanics and Materials, V738-739, P19, DOI 10.4028/www.scientific.net/AMM.738-739.19
NR 20
TC 13
Z9 13
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30039
EP 30056
DI 10.1007/s11042-018-6883-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200023
DA 2024-07-18
ER

PT J
AU Fu, B
   Zhao, XY
   Li, Y
   Wang, XH
   Ren, YG
AF Fu, Bo
   Zhao, Xiaoyang
   Li, Yi
   Wang, Xianghai
   Ren, Yonggong
TI A convolutional neural networks denoising approach for salt and pepper
   noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Salt and pepper noise; Convolutional neural networks;
   Non-local switching filter
ID SWITCHING MEDIAN FILTER
AB The salt and pepper noise, especially the one with extremely high percentage of impulses, brings a significant challenge to image denoising. In this paper, we propose a non-local switching filter convolutional neural network denoising algorithm, named NLSF-CNN, for salt and pepper noise. As its name suggested, our NLSF-CNN consists of two steps, i.e., a NLSF processing step and a CNN training step. First, we develop a NLSF pre-processing step for noisy images using non-local information. Then, the pre-processed images are divided into patches and used for CNN training, leading to a CNN denoising model for future noisy images. We conduct a number of experiments to evaluate the effectiveness of NLSF-CNN. Experimental results show that NLSF-CNN outperforms the state-of-the-art denoising algorithms with a few training images.
C1 [Fu, Bo; Zhao, Xiaoyang; Li, Yi; Wang, Xianghai; Ren, Yonggong] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian, Peoples R China.
C3 Liaoning Normal University
RP Fu, B (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian, Peoples R China.
EM fubo@lnnu.edu.cn; ryg@lnnu.edu.cn
RI Wang, Xianghai/GRR-4512-2022
OI Wang, Xianghai/0000-0002-7600-9939; Fu, Bo/0000-0001-7030-821X
FU National Natural Science Foundation of China (NSFC) [61702246]; Liaoning
   Province of China General Project of Scientific Research [L2015285];
   Liaoning Province of China Doctoral Research Start-Up Fund [201601243]
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) No. 61702246, Liaoning Province of China General Project of
   Scientific Research No. L2015285, Liaoning Province of China Doctoral
   Research Start-Up Fund No. 201601243.
CR Aiswarya K, 2010, ICCMS 2010, V4, DOI [10.1109/ICCMS.2010.310, DOI 10.1109/ICCMS.2010.310]
   Astola J., 1997, Fundamentals of nonlinear digital filtering, DOI DOI 10.1201/9781003067832
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Burger HC, 2012, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2012.6247952
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Delon J, 2016, IMAGE PROCESS ON LIN, V6, P130, DOI 10.5201/ipol.2016.161
   Dong C., 2016, IEEE C COMP VIS PATT
   Eng HL, 2001, IEEE T IMAGE PROCESS, V10, P242, DOI 10.1109/83.902289
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Fu B, 2015, NEUROCOMPUTING, V169, P119, DOI 10.1016/j.neucom.2014.11.094
   Ghifary M, 2016, EUR C COMPUT VISION
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jafar IF, 2013, IEEE T IMAGE PROCESS, V22, P1223, DOI 10.1109/TIP.2012.2228496
   Jain V., 2009, ADV NEURAL INFORM PR, P769, DOI DOI 10.5555/2981780.2981876
   Kim J, 2016, IEEE CONF COMPUT
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Marco Bevilacqua CG, 2012, BMVC, V2, P5
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   Toh KKV, 2008, IEEE T CONSUM ELECTR, V54, P1956, DOI 10.1109/TCE.2008.4711258
   Varghese J, 2015, ARAB J SCI ENG, V40, P3233, DOI 10.1007/s13369-015-1799-2
   Wang W, 2011, IEEE SIGNAL PROC LET, V18, P551, DOI 10.1109/LSP.2011.2162583
   Wang  Y., 2018, IEEE T NEURAL NETW L
   Wang Y., 2016, P 25 INT JOINT C ART, P2153
   Wang Y., 2015, ACM SIGIR
   Wang Y, 2018, NEURAL NETWORKS, V103, P1, DOI 10.1016/j.neunet.2018.03.006
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang Y, 2017, IEEE T NEUR NET LEAR, V28, P57, DOI 10.1109/TNNLS.2015.2498149
   Wang Y, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P79, DOI 10.1145/2733373.2806233
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Wu L, 2018, ARXIV180411013
   Wu L, 2019, IEEE T MULTIMEDIA, V21, P1412, DOI 10.1109/TMM.2018.2877886
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Wu L, 2017, IMAGE VISION COMPUT, V57, P58, DOI 10.1016/j.imavis.2016.11.008
   Xie J, 2012, ADV NEURAL INF PROCE, V1, P314
   Yang M, 2010, NANOSCI NANOTECH LET, V2, P7, DOI 10.1166/nnl.2010.1055
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang SQ, 2002, IEEE SIGNAL PROC LET, V9, P360, DOI 10.1109/LSP.2002.805310
   Zhou YY, 2012, IET IMAGE PROCESS, V6, P976, DOI 10.1049/iet-ipr.2011.0312
NR 40
TC 27
Z9 28
U1 5
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30707
EP 30721
DI 10.1007/s11042-018-6521-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200059
DA 2024-07-18
ER

PT J
AU Li, GH
   Sun, P
   Yuan, L
   Wang, ML
   Cheng, HJ
AF Li, GuoHui
   Sun, Ping
   Yuan, Ling
   Wang, MingLi
   Cheng, HongJu
TI Research on why-not questions of top-K query in orthogonal region
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Orthogonal range query; Top-K query; Why-not questions
ID ANSWERS
AB Orthogonal region query has always been an important topic in the field of database query, geographic information system, computer graphics, data mining and multimedia information retrieval. In recent years, the "Why-Not" questions has gradually become a hot topic in the SQL query, Skyline query, and spatial keyword Top-K query. However, no one has answered the "Why-Not" questions of the orthogonal region Top-K query. Based on the in-depth study of the orthogonal region Top-K query algorithm, this paper first proposes to answer the "Why-Not" questions in the orthogonal region Top-K query. We adjust the initial query so that the result set of the new query contains the "Why-Not" elements with the least cost. Abundant experiments have been conducted to analyze the proposed algorithm on the factors of initial k value, initial rank, and data size. The experimental results demonstrate the accuracy and efficiency of the proposed algorithm.
C1 [Li, GuoHui; Yuan, Ling] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430072, Hubei, Peoples R China.
   [Sun, Ping; Wang, MingLi] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Comp Software & Theory, Wuhan, Hubei, Peoples R China.
   [Sun, Ping] FiberHome Technol Grp, Wuhan, Hubei, Peoples R China.
   [Cheng, HongJu] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou 350108, Fujian, Peoples R China.
   [Cheng, HongJu] Minist Educ, Key Lab Spatial Data Min & Informat Sharing, Fuzhou, Fujian, Peoples R China.
C3 Huazhong University of Science & Technology; Huazhong University of
   Science & Technology; Wuhan Research Institute of Post &
   Telecommunications; Fuzhou University
RP Yuan, L (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430072, Hubei, Peoples R China.
EM cherryyuanling@hust.edu.cn
OI Sun, Ping/0000-0003-2594-9805
FU National Natural Science Fund of China [61572215]
FX This work was supported by National Natural Science Fund of China under
   grants 61572215.
CR Afshani P, 2011, PROCEEDINGS OF THE TWENTY-SECOND ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P390
   Bhowmick S.S., 2013, ACM Multimedia Conference, MM'13, Barcelona, Spain, October 21-25, 2013, P917
   Bhowmick SS, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P83, DOI 10.1145/2567948.2577028
   Brodal GS, 2009, LECT NOTES COMPUT SC, V5878, P173, DOI 10.1007/978-3-642-10631-6_19
   Buneman Peter., 2007, SIGMOD 2007 P ACM SI, P1171
   Chapman A, 2009, ACM SIGMOD/PODS 2009 CONFERENCE, P523
   Cheng L, 2015, LECT NOTES COMPUT SC, V9049, P279, DOI 10.1007/978-3-319-18120-2_17
   de Berg M, 2000, COMPUTATIONAL GEOMET, P95
   Gao YJ, 2015, PROC VLDB ENDOW, V8, P738, DOI 10.14778/2752939.2752943
   He Z, 2012, PROC INT CONF DATA, P750, DOI 10.1109/ICDE.2012.8
   Herschel M, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2213, DOI 10.1145/2505515.2505725
   Herschel M, 2015, ACM J DATA INF QUAL, V5, DOI 10.1145/2665070
   Herschel M, 2010, PROC VLDB ENDOW, V3, P185, DOI 10.14778/1920841.1920869
   Huang JS, 2008, PROC VLDB ENDOW, V1, P736, DOI 10.14778/1453856.1453936
   Ilyas IF, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1391729.1391730
   Jagadish H. V., 2007, SIGMOD, P13, DOI [DOI 10.1145/1247480.1247483, 10.1145/1247480.1247483]
   Sheng Cheng., 2012, P 31 ACM SIGMOD SIGA, P121
   Tran Q. T., 2010, P ACM SIGMOD INT C M, P15, DOI DOI 10.1145/1807167.1807172
NR 18
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30197
EP 30219
DI 10.1007/s11042-018-6920-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200032
DA 2024-07-18
ER

PT J
AU Long, J
   Zhu, L
   Zhang, CY
   Yang, Z
   Lin, YW
   Chen, RP
AF Long, Jun
   Zhu, Lei
   Zhang, Chengyuan
   Yang, Zhan
   Lin, Yunwu
   Chen, Ruipeng
TI Efficient interactive search for geo-tagged multimedia data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Geo-tagged multimedia data; Interactive query; Top-k spatial search
ID IMAGE RETRIEVAL; KEYWORD SEARCH; NETWORKS
AB Due to the advances in mobile computing and multimedia techniques, there are vast amount of multimedia data with geographical information collected in multifarious applications. In this paper, we propose a novel type of image search namedinteractive geo-tagged image search which aims to find out a set of images based on geographical proximity and similarity of visual content, as well as the preference of users. Existing approaches for spatial keyword query and geo-image query cannot address this problem effectively since they do not consider these three type of information together for query. In order to solve this challenge efficiently, we propose the definition of interactive top-k geo-tagged image query and then present a framework including candidate search stage , interaction stage and termination stage. To enhance the searching efficiency in a large-scale database, we propose the candidate search algorithm named GI-SUPER Search based on a new notion called superior relationship and GIR-Tree, a novel index structure. Furthermore, two candidate selection methods are proposed for learning the preferences of the user during the interaction. At last, the termination procedure and estimation procedure are introduced in brief. Experimental evaluation on real multimedia dataset demonstrates that our solution has a really high performance.
C1 [Long, Jun; Zhu, Lei; Zhang, Chengyuan; Yang, Zhan; Lin, Yunwu; Chen, Ruipeng] Cent South Univ, Sch Informat Sci & Engn, Changsha, Hunan, Peoples R China.
   [Long, Jun; Zhu, Lei; Zhang, Chengyuan; Yang, Zhan; Lin, Yunwu; Chen, Ruipeng] Cent South Univ, Big Data & Knowledge Engn Inst, Changsha, Hunan, Peoples R China.
C3 Central South University; Central South University
RP Zhang, CY (corresponding author), Cent South Univ, Sch Informat Sci & Engn, Changsha, Hunan, Peoples R China.; Zhang, CY (corresponding author), Cent South Univ, Big Data & Knowledge Engn Inst, Changsha, Hunan, Peoples R China.
EM jlong@csu.edu.cn; leizhu@csu.edu.cn; cyzhang@csu.edu.cn;
   zyang22@csu.edu.cn; lywcsu@csu.edu.cn; rpchen@csu.edu.cn
RI Yang, Zhan/GQG-9995-2022; Zhu, Lei/GQQ-1130-2022
OI Zhu, Lei/0000-0002-5348-7532
FU National Natural Science Foundation of China [61702560, 61472450]; Key
   Research Program of Hunan Province [2016JC2018]; project of Science and
   Technology Plan of Hunan Province [2018JJ3691]; Research and Innovation
   Project of Central South University Graduate Students [2018zzts177]
FX This work was supported in part by the National Natural Science
   Foundation of China (61702560, 61472450), the Key Research Program of
   Hunan Province(2016JC2018), project (2018JJ3691) of Science and
   Technology Plan of Hunan Province, and the Research and Innovation
   Project of Central South University Graduate Students (2018zzts177).
CR Andersen R, 2009, LECT NOTES COMPUT SC, V5427, P25, DOI 10.1007/978-3-540-95995-3_3
   [Anonymous], MULTIMEDIA IEEE
   [Anonymous], P ACM MULT 2012 WORK
   [Anonymous], 2014, Metallogenic regularity and prospecting direction of Mo-Pb-Zn polymetallic mineralization in Dongwuqi area, Inner Mongolia
   [Anonymous], 1990, SIGMOD, DOI DOI 10.1145/93597.98741
   [Anonymous], 2013, P 16 INT C EXT DAT T
   [Anonymous], 2012, P 20 ACM INT C MULT
   Börzsönyi S, 2001, PROC INT CONF DATA, P421, DOI 10.1109/ICDE.2001.914855
   Cao XL, 2011, IEEE INT CONF TRUST, P373, DOI 10.1109/TrustCom.2011.48
   Chen J, 2016, PATTERN RECOGN LETT, V83, P379, DOI 10.1016/j.patrec.2016.01.017
   Chum O, 2008, P BRIT MACH VIS C 20, P1
   Cong G., 2009, PROC VLDB ENDOW, V2, P337, DOI DOI 10.14778/1687627.1687666
   De Felipe I, 2008, PROC INT CONF DATA, P656, DOI 10.1109/ICDE.2008.4497474
   Deng K, 2015, IEEE T KNOWL DATA EN, V27, P61, DOI 10.1109/TKDE.2014.2324897
   Douze M, 2011, PROC CVPR IEEE, P745, DOI 10.1109/CVPR.2011.5995595
   GALLO G, 1989, SIAM J COMPUT, V18, P30, DOI 10.1137/0218003
   Goldberg A.V., 1984, Technical Report
   Gosselin PH, 2008, IEEE T IMAGE PROCESS, V17, P1200, DOI 10.1109/TIP.2008.924286
   Guo T, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P405, DOI 10.1145/2723372.2723723
   Guttman A., 1984, SIGMOD Record, V14, P47, DOI 10.1145/971697.602266
   Huang M, 2018, IEEE T SYST MAN CYBE
   Huang YC, 2010, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2010.5540012
   Ilyas IF, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1391729.1391730
   Jia D, 2011, PROC CVPR IEEE, P785, DOI 10.1109/CVPR.2011.5995516
   Jin HY, 2015, J TRANSL MED, V13, DOI 10.1186/s12967-015-0616-8
   Kim G, 2014, PROC CVPR IEEE, P4225, DOI 10.1109/CVPR.2014.538
   Kitanovski I, 2017, MULTIMED TOOLS APPL, V76, P2955, DOI 10.1007/s11042-016-3261-1
   Li YS, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090709
   Li YL, 2017, MULTIMED TOOLS APPL, V76, P16749, DOI 10.1007/s11042-016-3950-9
   Liu X, 2018, IEEE T INDUS INF
   Long C., 2013, SIGMOD, P689
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Memon MH, 2017, MULTIMED TOOLS APPL, V76, P15377, DOI 10.1007/s11042-016-3834-z
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Rocha-Junior Joao B., 2011, Advances in Spatial and Temporal Databases. Proceedings 12th International Symposium (SSTD 2011), P205, DOI 10.1007/978-3-642-22922-0_13
   Rocha-Junior J.B., 2012, EDBT, P168
   Singh S. K., 2017, SUSTAINABILITY-BASEL, P1
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Thomee B, 2012, INT J MULTIMED INF R, V1, P71, DOI 10.1007/s13735-012-0014-4
   Wang  Y., 2018, IEEE T NEURAL NETW L
   Wang Y, 2018, NEURAL NETWORKS, V103, P1, DOI 10.1016/j.neunet.2018.03.006
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang Y, 2017, IEEE T NEUR NET LEAR, V28, P57, DOI 10.1109/TNNLS.2015.2498149
   Wang Y, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P79, DOI 10.1145/2733373.2806233
   Wang Y, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P999, DOI 10.1145/2766462.2767825
   Wang Y, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P981, DOI 10.1145/2647868.2654999
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Wang Y, 2013, IEEE IMAGE PROC, P805, DOI 10.1109/ICIP.2013.6738166
   Wang Yuan-sheng, 2014, COMPUTER MODELLING N, V16, P13
   Wu L, 2013, PROCEEDINGS OF 2013 INTERNATIONAL CONFERENCE ON PUBLIC ADMINISTRATION (9TH), VOL II, P598
   Wu L, 2019, IEEE T CYBERNETICS, V49, P1791, DOI 10.1109/TCYB.2018.2813971
   Wu L, 2018, COMPUT VIS IMAGE UND, V167, P63, DOI 10.1016/j.cviu.2017.11.009
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Wu L, 2017, IMAGE VISION COMPUT, V57, P58, DOI 10.1016/j.imavis.2016.11.008
   Wu L, 2015, MULTIMED TOOLS APPL, V74, P5635, DOI 10.1007/s11042-014-1873-x
   Yaegashi Keita, 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P360, DOI 10.1007/978-3-642-19309-5_28
   Yang Wang, 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference (PAKDD 2013). Proceedings, P449, DOI 10.1007/978-3-642-37456-2_38
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Zhang CY, 2016, IEEE T KNOWL DATA EN, V28, P1706, DOI 10.1109/TKDE.2016.2530060
   Zhang CY, 2013, PROC INT CONF DATA, P901, DOI 10.1109/ICDE.2013.6544884
   Zhang DX, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P355, DOI 10.1145/2600428.2609562
   Zhang DX, 2009, PROC INT CONF DATA, P688, DOI 10.1109/ICDE.2009.77
   Zhao PP, 2015, LECT NOTES COMPUT SC, V9050, P379, DOI 10.1007/978-3-319-18123-3_23
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1025, DOI 10.1145/2647868.2655035
   Zhu GQ, 2016, ONCOTARGETS THER, V9, P2153, DOI 10.2147/OTT.S97864
   Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389
NR 68
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30677
EP 30706
DI 10.1007/s11042-018-6393-7
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200058
DA 2024-07-18
ER

PT J
AU Said, N
   Ahmad, K
   Riegler, M
   Pogorelov, K
   Hassan, L
   Ahmad, N
   Conci, N
AF Said, Naina
   Ahmad, Kashif
   Riegler, Michael
   Pogorelov, Konstantin
   Hassan, Laiq
   Ahmad, Nasir
   Conci, Nicola
TI Natural disasters detection in social media and satellite imagery: a
   survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information retrieval; Natural disasters; Satellite; Social media; Deep
   learning; CNN
ID COLOR; TWITTER; CLASSIFICATION; EARTHQUAKE; PREDICTION; DESCRIPTOR;
   HISTOGRAM; FEATURES
AB The analysis of natural disaster-related multimedia content got great attention in recent years. Being one of the most important sources of information, social media have been crawled over the years to collect and analyze disaster-related multimedia content. Satellite imagery has also been widely explored for disasters analysis. In this paper, we survey the existing literature on disaster detection and analysis of the retrieved information from social media and satellites. Literature on disaster detection and analysis of related multimedia content on the basis of the nature of the content can be categorized into three groups, namely (i) disaster detection in text; (ii) analysis of disaster-related visual content from social media; and (iii) disaster detection in satellite imagery. We extensively review different approaches proposed in these three domains. Furthermore, we also review benchmarking datasets available for the evaluation of disaster detection frameworks. Moreover, we provide a detailed discussion on the insights obtained from the literature review, and identify future trends and challenges, which will provide an important starting point for the researchers in the field.
C1 [Said, Naina; Hassan, Laiq; Ahmad, Nasir] Univ Engn & Technol, DCSE, Peshawar, Pakistan.
   [Ahmad, Kashif] Hamad Bin Khalifa Univ, Coll Sci & Engn CSE, Informat & Comp Technol ICT Div, Doha, Qatar.
   [Riegler, Michael] Simula Met, Simula, Norway.
   [Pogorelov, Konstantin] Simula Res Lab, Simula, Norway.
   [Conci, Nicola] Univ Trento, DISI, Trento, Italy.
C3 University of Engineering & Technology Peshawar; Qatar Foundation (QF);
   Hamad Bin Khalifa University-Qatar; University of Trento
RP Ahmad, K (corresponding author), Hamad Bin Khalifa Univ, Coll Sci & Engn CSE, Informat & Comp Technol ICT Div, Doha, Qatar.
EM naina_dcse@yahoo.com; kahmad@hbku.edu.qa; michael@simula.no;
   konstantin@simula.no; laiqhasan@gmail.com; n.ahmad@uetpeshawar.edu.pk
RI Ahmad, Kashif/JJE-8424-2023; ahmad, kashif/AAV-8323-2021; Riegler,
   Michael A/E-5443-2015; Conci, Nicola/AAH-4671-2020; Ahmad,
   Nasir/IXW-6930-2023
OI Conci, Nicola/0000-0002-7858-0928; Ahmad, Kashif/0000-0002-0931-9275
CR Ahmad HAH, 2017, PROCEEDINGS OF THE 2017 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P461, DOI 10.1109/ICCKE.2017.8167922
   Ahmad K, 2017, P MEDIAEVAL WORKSH
   Ahmad K, 2019, SIGNAL PROCESS-IMAGE, V74, P110, DOI 10.1016/j.image.2019.02.002
   Ahmad K, 2019, MULTIMED TOOLS APPL, V78, P2837, DOI 10.1007/s11042-018-5982-9
   Ahmad K, 2018, INT ARAB CONF INF TE, P273
   Ahmad S, 2016, 2016 INTERNATIONAL CONFERENCE ON SYSTEMS IN MEDICINE AND BIOLOGY (ICSMB), P53, DOI 10.1109/ICSMB.2016.7915086
   Ahmadi S, 2017, LECT NOTES COMPUT SC, V10328, P13, DOI 10.1007/978-3-319-59250-3_2
   Alam F, 2018, INT J HUM-COMPUT INT, V34, P311, DOI 10.1080/10447318.2018.1427831
   Albuz E, 2001, IEEE T KNOWL DATA EN, V13, P851, DOI 10.1109/69.956109
   Amit SNKB, 2016, INT GEOSCI REMOTE SE, P5189, DOI 10.1109/IGARSS.2016.7730352
   [Anonymous], 2012, P 15 WORLD C EARTHQ
   [Anonymous], 2018, P MEDIAEVAL 2018 WOR
   [Anonymous], 2016, IARIA C COGNITIVE
   [Anonymous], STANFORD NAMED ENTIT
   [Anonymous], P 7 INT C MULT SYST
   [Anonymous], 2017, RETRIEVING SOCIAL FL
   [Anonymous], 2002, INT J APPL EARTH OBS
   [Anonymous], 2016, P INT C DATA MINING
   [Anonymous], P 15 WORLD C EARTHQ
   [Anonymous], 1999, WORLD DEV IND
   [Anonymous], SOMERSET
   [Anonymous], P 24 INT C COMP WWW
   [Anonymous], P ACM C MULT
   [Anonymous], GLOBAL BIOGEOCHEMICA
   [Anonymous], 2014, ISCRAM
   [Anonymous], WORK NOT P MEDIAEVAL
   [Anonymous], AAAI WORKSH WWW PUBL
   [Anonymous], 2001, ORDINAL LOGISTIC REG
   [Anonymous], 2015, P 9 INT AAAI C WEB S
   [Anonymous], 2014, P 8 INT AAAI C WEBL
   [Anonymous], PROGR PHYS GEOGR
   [Anonymous], DATA DRIVEN FLOOD DE
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], P 15 INT WORKSH CONT
   [Anonymous], 2014, Comput. Sci.
   [Anonymous], 2002, P INT C IM PROC
   [Anonymous], 2017, P MEDIAEVAL 2017 WOR
   [Anonymous], 2014, P 31 INT C INT C MAC
   [Anonymous], PLAN APPL PROGR INT
   [Anonymous], 2016, P INT C SEC MAN SAM
   [Anonymous], RES PROGR ACCOMPLISH
   [Anonymous], 2018, ARXIV180711805
   [Anonymous], 2018, P 4 INT C IMAGE PROC
   [Anonymous], NY TIMES
   [Anonymous], 2017, Retinal Vessel Segmentation in Fundoscopic Images with Generative Adversarial Networks
   [Anonymous], 2018, P MEDIAEVAL 2018 WOR
   [Anonymous], 2018, P MEDIAEVAL 2018 WOR
   [Anonymous], BIG CRISIS DATA SOCI
   [Anonymous], ROBOT SEARCH APACHE
   [Anonymous], WORK NOT P MEDIAEVAL
   [Anonymous], ARXIV161106474
   Arvor D, 2013, ISPRS J PHOTOGRAMM, V82, P125, DOI 10.1016/j.isprsjprs.2013.05.003
   Atefeh F, 2015, COMPUT INTELL-US, V31, P132, DOI 10.1111/coin.12017
   Avgerinakis K., 2017, Working Notes Proc. MediaEval Workshop p, P2, DOI DOI 10.1016/J.EURURO.2014.12.014
   Avvenuti M, 2015, INT CONF INFORM COMM, P258, DOI 10.1109/ICT-DM.2015.7402058
   Bai Y, 2009, IEEE IMAGE PROC, P3305, DOI 10.1109/ICIP.2009.5413938
   Bischke B., 2017, P MEDIAEVAL 2017 WOR
   Bischke B., 2018, P MEDIAEVAL 2018 WOR
   BISCHKE B, 2017, P MED 2017 WORKSH, V1984
   Bischke B, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1077, DOI 10.1145/2964284.2984063
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Breitinger F, 2013, DIGIT INVEST, V10, pS50, DOI 10.1016/j.diin.2013.06.006
   Brouwer T, 2017, NAT HAZARD EARTH SYS, V17, P735, DOI 10.5194/nhess-17-735-2017
   Cai D, 2007, IEEE DATA MINING, P427, DOI 10.1109/ICDM.2007.88
   Campbell J. B., 2011, INTRO REMOTE SENSING
   Chatzichristofis Savvas A., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P191, DOI 10.1109/WIAMIS.2008.24
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Chen SC, 2000, P SOC PHOTO-OPT INS, V3972, P262
   Cimpoi M, 2015, PROC CVPR IEEE, P3828, DOI 10.1109/CVPR.2015.7299007
   Cobo A, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P1189, DOI 10.1145/2740908.2741719
   Cresci S, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P1195, DOI 10.1145/2740908.2741722
   Crooks A, 2013, T GIS, V17, P124, DOI 10.1111/j.1467-9671.2012.01359.x
   Dalponte M, 2008, IEEE T GEOSCI REMOTE, V46, P1416, DOI 10.1109/TGRS.2008.916480
   Dao M. S., 2017, DOMAIN BASED LATE FU
   Datta RS, 2009, NUCLEIC ACIDS RES, V37, pW84, DOI 10.1093/nar/gkp373
   De Maesschalck R, 2000, CHEMOMETR INTELL LAB, V50, P1, DOI 10.1016/S0169-7439(99)00047-7
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Earle PS, 2011, ANN GEOPHYS-ITALY, V54, P708, DOI 10.4401/ag-5364
   Eutamene A, 2011, COMM COM INF SC, V240, P137
   Feng Y, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7020039
   Fisher A, 2016, REMOTE SENS ENVIRON, V175, P167, DOI 10.1016/j.rse.2015.12.055
   Gillespie TW, 2007, PROG PHYS GEOG, V31, P459, DOI 10.1177/0309133307083296
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guha-Sapir D., 2015, Em-dat: International Disaster Database
   Gupta S, 2011, US Patent, Patent No. [8,032,529, 8032529]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herrmann RB, 2008, SEISMOL RES LETT, V79, P830, DOI 10.1785/gssrl.79.6.830
   Houston JB, 2015, DISASTERS, V39, P1, DOI 10.1111/disa.12092
   Howarth P, 2004, LECT NOTES COMPUT SC, V3115, P326
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Imran M., 2013, P ISCRAM, P1
   Imran M, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P159, DOI 10.1145/2567948.2577034
   Kansas J, 2016, INT J WILDLAND FIRE, V25, P597, DOI 10.1071/WF15170
   Kaplan AM, 2010, BUS HORIZONS, V53, P59, DOI 10.1016/j.bushor.2009.09.003
   Kasutani E, 2001, IEEE IMAGE PROC, P674, DOI 10.1109/ICIP.2001.959135
   Kerle N, 2002, DISASTERS, V26, P140, DOI 10.1111/1467-7717.00197
   Kirchknopf A., 2018, P MEDIAEVAL 2018 WOR
   Kisilevich S, 2010, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, SECOND EDITION, P855, DOI 10.1007/978-0-387-09823-4_44
   Klainman E, 2013, CORONARY ARTERY DISEASE 2013, P239
   Lagerstrom R, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00054
   Lamb LE, 2018, BMC MICROBIOL, V18, DOI 10.1186/s12866-018-1200-1
   Li ZC, 2011, IEEE T IMAGE PROCESS, V20, P2017, DOI 10.1109/TIP.2010.2099128
   Liu Y, 2016, PROCEDIA COMPUT SCI, V91, P566, DOI 10.1016/j.procs.2016.07.144
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   McMinn AJ, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P409, DOI 10.1145/2505515.2505695
   Middleton SE, 2014, IEEE INTELL SYST, V29, P9, DOI 10.1109/MIS.2013.126
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   MITRA S, 1995, IEEE T NEURAL NETWOR, V6, P51, DOI 10.1109/72.363450
   Moumtzidou A., 2018, P MEDIAEVAL 2018 WOR
   Murthy D, 2013, INFORM COMMUN SOC, V16, P837, DOI 10.1080/1369118X.2012.696123
   Nguyen Dat T., 2017, 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P569, DOI 10.1145/3110025.3110109
   Nogueira K, 2018, IEEE GEOSCI REMOTE S, V15, P1446, DOI 10.1109/LGRS.2018.2845549
   Noh H, 2017, IEEE I CONF COMP VIS, P3476, DOI 10.1109/ICCV.2017.374
   Olteanu A, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'15), P994, DOI 10.1145/2675133.2675242
   Parilla-Ferrer B. E., 2014, P INT C INN ENG TECH, P62
   Paul F, 2009, J GLACIOL, V55, P607, DOI 10.3189/002214309789471003
   Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI [DOI 10.3115/V1/D14-1162, 10.3115/v1/D14-1162]
   Rhee J, 2010, REMOTE SENS ENVIRON, V114, P2875, DOI 10.1016/j.rse.2010.07.005
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Shekhar H, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1719, DOI 10.1109/ICACCI.2015.7275861
   Shi Y., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P1945, DOI 10.1109/CEC.1999.785511
   Simonyan K., 2014, 14091556 ARXIV
   Steedman M, 2003, EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P331
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Takahashi B, 2015, COMPUT HUM BEHAV, V50, P392, DOI 10.1016/j.chb.2015.04.020
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   To H, 2017, 2017 IEEE THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2017), P330, DOI 10.1109/BigMM.2017.82
   Truong B., 2014, Proceedings of the American Society for Information Science and Technology, V51, P1, DOI DOI 10.1002/MEET.2014.14505101162
   Vieweg S, 2014, LECT NOTES COMPUT SC, V8851, P444, DOI 10.1007/978-3-319-13734-6_32
   Voigt S, 2007, IEEE T GEOSCI REMOTE, V45, P1520, DOI 10.1109/TGRS.2007.895830
   Won CS, 2002, ETRI J, V24, P23, DOI 10.4218/etrij.02.0102.0103
   Wu HJ, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP), P29, DOI 10.1109/ICICIP.2018.8606704
   Yager RR, 1999, IEEE T SYST MAN CY B, V29, P141, DOI 10.1109/3477.752789
   Yang YM, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P181, DOI 10.1109/IRI.2011.6009543
   Yin J, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4234
   Youssef AM, 2011, ENVIRON EARTH SCI, V62, P611, DOI 10.1007/s12665-010-0551-1
   Zhang XW, 2013, WORLD WIDE WEB, V16, P497, DOI 10.1007/s11280-012-0181-5
   Zhang Y, 2010, INT J MACH LEARN CYB, V1, P43, DOI 10.1007/s13042-010-0001-0
   Zhou BL, 2014, ADV NEUR IN, V27
NR 141
TC 58
Z9 62
U1 4
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31267
EP 31302
DI 10.1007/s11042-019-07942-1
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000014
DA 2024-07-18
ER

PT J
AU Sawant, M
   Addepalli, S
   Bhurchandi, K
AF Sawant, Manisha
   Addepalli, Shalini
   Bhurchandi, Kishor
TI Age estimation using local direction and moment pattern (LDMP) features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Age estimation; Directional filter; Local Tchebichef moment; Warped
   Gaussian process regression
ID IMAGE-ANALYSIS; FACE-RECOGNITION; CLASSIFICATION; INVARIANT
AB An automatic estimation of age from face images is gaining attention due to its interesting applications such as age-based access control, customer profiling for targeted advertisements and video surveillance. However, age estimation from a face image is challenging due to complex interpersonal biological aging process, incomplete databases and dependency of facial aging on extrinsic and intrinsic factors. The published literature on age estimation utilizes multiple existing feature descriptors and then combines them into a hybrid feature vector. There is still an absence of specially designed aging feature descriptor which encodes facial aging cues. To address this issue we propose aging feature descriptor; Local Direction and Moment Pattern (LDMP), which capture directional and textural variations due to aging. We encode the orientation information available in eight unique directions. The texture is embedded into the magnitudes of higher order moments which we extract using local Tchebichef moments. Next, orientation and texture information is combined into a robust feature descriptor. To learn the age estimator, we apply warped Gaussian process regression on the proposed feature vector. Experimental analysis demonstrates the effectiveness of the proposed method on two large databases FG-NET and MORPH-II.
C1 [Sawant, Manisha; Addepalli, Shalini; Bhurchandi, Kishor] Visvesvaraya Natl Inst Technol, Nagpur, Maharashtra, India.
C3 National Institute of Technology (NIT System); Visvesvaraya National
   Institute of Technology, Nagpur
RP Sawant, M (corresponding author), Visvesvaraya Natl Inst Technol, Nagpur, Maharashtra, India.
EM mpparlewar@gmail.com; shaliniaddepalli@gmail.com;
   bhurchandikm@ece.vnit.ac.in
RI BHURCHANDI, KISHOR/AAA-7708-2022; Sawant, Manisha/JRX-5340-2023;
   Sawant-Parlewar, Manisha/AAY-4591-2020
OI BHURCHANDI, KISHOR/0000-0003-0730-363X; Sawant,
   Manisha/0009-0009-9399-1002; Sawant-Parlewar,
   Manisha/0000-0002-3682-4146
CR Ahonen T, 2008, ICPR2009, P1, DOI DOI 10.1109/ICPR.2008.4761847
   [Anonymous], 2007, SEMINUMERICAL ALGORI
   [Anonymous], 2014, EUR C COMP VIS
   [Anonymous], 2006, CKI WILLIAMS GAUSSIA
   [Anonymous], 1970, PICTURE PROCESSING P
   BIGUN J, 1994, IEEE T PATTERN ANAL, V16, P80, DOI 10.1109/34.273714
   Budka M, 2013, IEEE T NEUR NET LEAR, V24, P22, DOI 10.1109/TNNLS.2012.2222925
   Chang KY, 2015, IEEE T IMAGE PROCESS, V24, P785, DOI 10.1109/TIP.2014.2387379
   Chang KY, 2011, PROC CVPR IEEE, P585, DOI 10.1109/CVPR.2011.5995437
   Chihara TS, 2011, Dover Books on Mathematics
   Choi SE, 2011, PATTERN RECOGN, V44, P1262, DOI 10.1016/j.patcog.2010.12.005
   Chu Y., 2018, VISUAL COMPUT, P1
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   Farage M. A., 2008, International Journal of Cosmetic Science, V30, P87, DOI 10.1111/j.1468-2494.2007.00415.x
   Faraji MR, 2015, IET BIOMETRICS, V4, P10, DOI 10.1049/iet-bmt.2014.0033
   Feng SH, 2017, IEEE T MULTIMEDIA, V19, P136, DOI 10.1109/TMM.2016.2608786
   Flusser J., 2009, Moments and Moment Invariants in Pattern Recognition
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51
   Günay A, 2018, MULTIMED TOOLS APPL, V77, P6555, DOI 10.1007/s11042-017-4572-6
   Guo GD, 2011, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2011.5995404
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759
   Haralick R. M, 1987, Readings in Computer Vision, P216, DOI DOI 10.1016/B978-0-08-051581-6.50027-1
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Indrawan M, 2007, I C DIGIT ECOSYST TE, P1
   Jabid T., 2010, Digest of Technical Papers Int. Conf. Consumer Electronics, P329, DOI DOI 10.1109/ICCE.2010.5418801
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   KIRSCH RA, 1971, COMPUT BIOMED RES, V4, P315, DOI 10.1016/0010-4809(71)90034-6
   Kwon YH, 1999, COMPUT VIS IMAGE UND, V74, P1, DOI 10.1006/cviu.1997.0549
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Li Y, 2016, VISUAL COMPUT, V32, P1525, DOI 10.1007/s00371-015-1137-4
   Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554
   Lu JW, 2015, IEEE T IMAGE PROCESS, V24, P5356, DOI 10.1109/TIP.2015.2481327
   MITCHELL T, 1989, ANNU REV COMPUT SCI, V4, P417
   Fernández AM, 2015, DAIMON, P133, DOI 10.6018/daimon/174601
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Mukundan Ramakrishnan, 2014, GCSR, P127
   Ouloul IM, 2018, MULTIMED TOOLS APPL, P1
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Pontes JK, 2016, PATTERN RECOGN, V54, P34, DOI 10.1016/j.patcog.2015.12.003
   Ramanathan N., 2006, 2006 IEEE COMP SOC C, V1, P387
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Rivera AR, 2015, PATTERN RECOGN LETT, V51, P94, DOI 10.1016/j.patrec.2014.08.012
   Shi FG, 1998, IEEE INT INTERC TECH, P73, DOI 10.1109/IITC.1998.704755
   Snelson E, 2004, ADV NEUR IN, V16, P337
   Suo J., 2008, Automatic Face and Gesture Recognition, P1
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Thukral P, 2012, INT CONF ACOUST SPEE, P1529, DOI 10.1109/ICASSP.2012.6288182
   Marcos JV, 2013, J OPT SOC AM A, V30, P1580, DOI 10.1364/JOSAA.30.001580
   Wang JW, 2013, 2013 IEEE 10TH INTERNATIONAL CONFERENCE ON AND 10TH INTERNATIONAL CONFERENCE ON AUTONOMIC AND TRUSTED COMPUTING (UIC/ATC) UBIQUITOUS INTELLIGENCE AND COMPUTING, P17, DOI 10.1109/UIC-ATC.2013.19
   Wang MS, 2007, J OPT SOC AM A, V24, P2550, DOI 10.1364/JOSAA.24.002550
   Wang SZ, 2016, IEEE T CYBERNETICS, V46, P827, DOI 10.1109/TCYB.2015.2416321
   Wee CY, 2010, PATTERN RECOGN, V43, P4055, DOI 10.1016/j.patcog.2010.05.026
   Weng R, 2013, 2013 10 IEEE INT C W, P1
   Wu T, 2012, IEEE T INF FOREN SEC, V7, P1780, DOI 10.1109/TIFS.2012.2213812
   Yap PT, 2004, IEE P-VIS IMAGE SIGN, V151, P128, DOI 10.1049/ip-vis:20040395
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zhang Y, 2010, PROC CVPR IEEE, P2622, DOI 10.1109/CVPR.2010.5539975
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhu K, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P857, DOI 10.1145/2647868.2655020
NR 64
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30419
EP 30441
DI 10.1007/s11042-019-7589-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200044
DA 2024-07-18
ER

PT J
AU Wasim, M
   Asim, MN
   Ghani, MU
   Rehman, ZU
   Rho, S
   Mehmood, I
AF Wasim, Muhammad
   Asim, Muhammad Nabeel
   Ghani, Muhammad Usman
   Rehman, Zahoor Ur
   Rho, Seungmin
   Mehmood, Irfan
TI Lexical paraphrasing and pseudo relevance feedback for biomedical
   document retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pseudo relevance feedback; Biomedical document retrival; Query
   expansion; Query parapharasing; Information retrival
AB Term mismatch is a serious problem effecting the performance of information retrieval systems. The problem is more severe in biomedical domain where lot of term variations, abbreviations and synonyms exist. We present query paraphrasing and various term selection combination techniques to overcome this problem. To perform paraphrasing, we use noun words to generate synonyms from Metathesaurus. The new synthesized paraphrases are ranked using statistical information derived from the corpus and relevant documents are retrieved based on top n selected paraphrases. We compare the results with state-of-the-art pseudo relevance feedback based retrieval techniques. In quest of enhancing the results of pseudo relevance feedback approach, we introduce two term selection combination techniques namely Borda Count and Intersection. Surprisingly, combinational techniques performed worse than single term selection techniques. In pseudo relevance feedback approach best algorithms are IG, Rochio and KLD which are performing 33%, 30% and 20% better than other techniques respectively. However, the performance of paraphrasing technique is 20% better than pseudo relevance feedback approach.
C1 [Wasim, Muhammad; Ghani, Muhammad Usman] Univ Engn & Technol, Dept Comp Sci & Engn, Lahore, Pakistan.
   [Wasim, Muhammad; Asim, Muhammad Nabeel; Ghani, Muhammad Usman] UET, Al Khawarizmi Inst Comp Sci, Lahore, Pakistan.
   [Rehman, Zahoor Ur] Inst Informat Technol, Dept Comp Sci, Attock, Pakistan.
   [Rho, Seungmin] Sungkyul Univ, Dept Media Software, Anyang, South Korea.
   [Mehmood, Irfan] Sejong Univ, Dept Software, Seoul, South Korea.
C3 University of Engineering & Technology Lahore; Sungkyul University;
   Sejong University
RP Mehmood, I (corresponding author), Sejong Univ, Dept Software, Seoul, South Korea.
EM wasim@kics.edu.pk; nabeel.asim@kics.edu.pk; usman.ghani@kics.edu.pk;
   xahoor@ciit-attock.edu.pk; korea.smrho@gmail.com; irfanmehmood@ieee.org
RI Rho, Seungmin/HTP-6683-2023; rehman, zahoor/AAE-2164-2021
OI Wasim, Muhammad/0000-0001-9248-5540; rehman, zahoor/0000-0001-9968-0330
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2016R1D1A1A09919551]
FX This work was supported by the Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education under Grant NRF-2016R1D1A1A09919551.
CR Abdulla AAA, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-016-1092-8
   [Anonymous], 2009, Association for Computational Linguistics
   [Anonymous], 2002, INT C UN KNOWL LANG
   [Anonymous], 2001, Using language models for information retrieval [PhD Dissertation, University of Twente]
   [Anonymous], ARXIV08042057
   Asim M, 2017, WOODH PUB S COMPOS S, P1, DOI 10.1016/B978-0-08-100789-1.00001-0
   Asim MN, 2017, INT J ADV COMPUT SC, V8, P369, DOI 10.14569/IJACSA.2017.081048
   Bannard Colin, 2005, P 43 ANN M ASS COMP, P597, DOI DOI 10.3115/1219840.1219914
   Barzilay R, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P16
   Barzilay R, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P50
   Bouadjenek MR, 2017, DATABASE-OXFORD, DOI 10.1093/database/bax062
   BRILL E, 1992, SPEECH AND NATURAL LANGUAGE, P112
   Callison-Burch C., 2008, P 2008 C EMPIRICAL M, P196
   Carpineto C, 1999, RES ADV TECHNOL DIGI, P851
   Claveau V, 2012, COLING 24 INT C COMP
   Cover Thomas M, 1999, Elements of information theory
   DILLON M, 1983, INFORM PROCESS MANAG, V19, P402, DOI 10.1016/0306-4573(83)90062-6
   Fang WM, 2008, FPGA 2008: SIXTEENTH ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P139
   Gonzalo J, 1998, ARXIVCMPLG9808002
   Harman DK, 1995, NIST SPECIAL PUBLICA, P500
   Jinxi Xu, 2017, ACM SIGIR Forum, V51, P168, DOI 10.1145/3130348.3130364
   Lee CK, 2006, INFORM PROCESS MANAG, V42, P155, DOI 10.1016/j.ipm.2004.08.006
   Lin D., 1998, P 36 ANN M ASS COMP, V2, P768, DOI DOI 10.3115/980432.980696
   Lytinen S, 2000, P AAAI00 WORKSH AI W
   Mihalcea R., 1999, P ASS COMPUTATIONAL, P152
   Miller G.A., 1990, Int. J. Lexicogr, V3, P235, DOI [DOI 10.1093/IJL/3.4.235, 10.1093/ijl/3.4.235]
   Mitra M., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P206, DOI 10.1145/290941.290995
   Ramos J, 2003, P 1 INSTRUCTIONAL C, V242, P29
   Roy Dwaipayan, 2016, arXiv
   Salton G., 1997, Readings in Information Retrieval, P355
   Sanderson M., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P142
   Singh J, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/568197
   VANRIJSBERGEN CJ, 1977, J DOC, V33, P106, DOI 10.1108/eb026637
   Whissell JS, 2011, INFORM RETRIEVAL, V14, P466, DOI 10.1007/s10791-011-9163-y
   Xiong NX, 2010, INFORM SCIENCES, V180, P2249, DOI 10.1016/j.ins.2009.12.001
   Xiong NX, 2009, IEEE J SEL AREA COMM, V27, P495, DOI 10.1109/JSAC.2009.090512
   Xu J., 1996, P 19 ANN INT ACM SIG, DOI 10.1145/243199.243202
   Zhao M, 2016, J INF PROCESS, V24, P721
   Zhou YZ, 2017, TSINGHUA SCI TECHNOL, V22, P714, DOI 10.23919/TST.2017.8195353
NR 39
TC 4
Z9 4
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 29681
EP 29712
DI 10.1007/s11042-018-6060-z
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200004
DA 2024-07-18
ER

PT J
AU Ibrahim, S
   Khamiss, N
AF Ibrahim, Sarmad
   Khamiss, Nasser
TI Proposed of the wireless mobile system and video coding system in the
   heterogeneous network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 4G; 5G; HEVC; FBMC; MCS
AB Today's 4G and 4.5G network is not capable of meeting the needs of a broadband network, 5G is designed to meet the needs. The key features of 5G include high throughput, improved spectrum efficiency, and reduced latency. Higher frequencies may be used by 5G, but the result is high cost. Furthermore, the volumes of video traffic in wireless system networks, there is an urgent need for improving the quality of video delivery. For this reason, this paper is devoted to proposing a wireless mobile system based on the updated LTE-ADV Pro (4.5G-4.9G) technology to arrive 5G capability with low cost. The proposed system uses advanced adaptive modulation and coding and advanced waveform to provide higher spectral efficiency. It also incorporates the proposed method of the adaptive video streaming of multiple video data rates. The results presented that the proposed wireless technique is better than LTE-ADV regarding data transmitted, while the proposed video coding method is better than H.265. The overall result in the proposed system is supported users about is 24% as compared to LTE-ADV with H.265 and about is 100% as compared to LTE with H.265.
C1 [Ibrahim, Sarmad] Mustansiriyah Univ, Coll Engn, Baghdad, Iraq.
   [Khamiss, Nasser] Al Nahrain Univ, Coll Informat Engn, Baghdad, Iraq.
C3 Mustansiriya University; Al-Nahrain University
RP Ibrahim, S (corresponding author), Mustansiriyah Univ, Coll Engn, Baghdad, Iraq.
EM eng_sarmadnet@uomustansiriyah.edu.iq; nassernafea@gnail.com
RI Ibrahim, Sarmad/M-9275-2014
OI Ibrahim, Sarmad/0000-0003-1444-9653
CR [Anonymous], TELKOMNIKA
   [Anonymous], P 13 INT C APPL COMP
   [Anonymous], FUTURE LTE FEMTOCELL
   DAHLMAN SPE, 2011, 4G LTE LTE ADV MOBIL
   Dao NN, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182527
   Hanzaz Z, 2013, INT WIREL COMMUN, P1509, DOI 10.1109/IWCMC.2013.6583780
   Huu Thuc Nguyen, 2017, IEIE Transactions on Smart Processing & Computing, V6, P428, DOI 10.5573/IEIESPC.2017.6.6.428
   Ibrahim SK, 2019, J COMPUT NETW COMMUN, V2019, DOI 10.1155/2019/3671826
   Ibrahim SK, 2018, 2018 THIRD SCIENTIFIC CONFERENCE OF ELECTRICAL ENGINEERING (SCEE), P197, DOI 10.1109/SCEE.2018.8682244
   IBRAHIM SK, 2019, J COMMUN, V14, P715
   Jassal A, 2016, COMMUNICATION QOS RE, P1
   Mohankumar NM., 2013, International Journal of Computer Networks and Wireless Communications, V3, P41
   NARDINI G, 2016, PIMRC 2016, P1
   Nightingale J, 2012, IEEE T CONSUM ELECTR, V58, P404, DOI 10.1109/TCE.2012.6227440
   Ranjana R., 2016, INT J ADV RES COMPUT, V6, P140
   Sihag K., 2016, INT J COMPUT SCI MOB, V5, P171
   Soni Gaurav, 2015, Proceedings of 2015 Global Conference on Communication Technologies (GCCT), P755, DOI 10.1109/GCCT.2015.7342765
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tchao ET, 2018, INT J ADV COMPUT SC, V9, P165
   Trivedi R., 2014, International Journal of Emerging Technology and Advanced Engineering, V4, P334
   Uhrina M, 2014, ADV ELECTR ELECTRON, V12, P368, DOI 10.15598/aeee.v12i4.1216
   VIRRANKOSKI R, 2011, LTE ADV TECHNOLOGY P
   Winken Martin, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3693, DOI 10.1109/ICIP.2011.6116521
   Yonis AZ, 2012, PR ELECTROMAGN RES S, P1467
   ZENG K, 2013, P INT WORKSH VID PRO, P1
   Zhang R, 2014, IEEE T WIREL COMMUN, V13, P6444, DOI 10.1109/TWC.2014.2350496
NR 26
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 34193
EP 34205
DI 10.1007/s11042-019-08230-8
EA OCT 2019
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000491551600002
DA 2024-07-18
ER

PT J
AU Basavaraju, S
   Sur, A
AF Basavaraju, Sathisha
   Sur, Arijit
TI Multiple instance learning based deep CNN for image memorability
   prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Image memorability; Memorability and emotions;
   Memorability and saliency; Multiple instance learning
ID LONG-TERM-MEMORY; AMYGDALA; EMOTION
AB Image memorability is a recent topic in the domain of computer vision, which enables one to measure the degree at which images are memorable to human cognitive system. Initial research on image memorability shown that memorability is an inherent characteristic of an image, and humans are consistent in remembering images. Further, it is also demonstrated that memorability of an image can be determined using machine learning and computer vision techniques. In this paper, a novel deep learning based image memorability prediction model is proposed. The proposed model automatically learns and utilises multiple visual factors such as object semantics, visual emotions, and saliency to predict image memorability scores. In particular, the proposed model employs multiple instance learning framework to utilise emotion cues evoking from single global context and multiple local contexts of an image. An extensive set of experiments are being carried out on large-scale image memorability dataset LaMem. The experimental results show that the proposed model performs better than current state-of-the-art models by reaching a rank correlation of 0.67, which is close to human consistency (rho = 0.68).
C1 [Basavaraju, Sathisha; Sur, Arijit] Indian Inst Technol Guwahati, Dept CSE, Gauhati, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Basavaraju, S (corresponding author), Indian Inst Technol Guwahati, Dept CSE, Gauhati, India.
EM b.sathisha@iitg.ac.in; arijit@iitg.ac.in
RI Sur, Arijit/AAB-4216-2020
CR Anderson AK, 2006, P NATL ACAD SCI USA, V103, P1599, DOI 10.1073/pnas.0506308103
   [Anonymous], ADV NEURAL INFORM PR
   Baveye Y, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P491, DOI 10.1145/2964284.2967269
   Blackwell A.F., 1997, P 1 ESP STUDENT WORK, P15
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   BRADLEY MM, 1992, J EXP PSYCHOL LEARN, V18, P379, DOI 10.1037/0278-7393.18.2.379
   Brady TF, 2008, P NATL ACAD SCI USA, V105, P14325, DOI 10.1073/pnas.0803390105
   CARBONNEAU MA, 2017, PATTERN RECOGN
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Dubey R, 2015, IEEE I CONF COMP VIS, P1089, DOI 10.1109/ICCV.2015.130
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hilbert M., 2012, Significance, V9, P8, DOI DOI 10.1111/J.1740-9713.2012.00584.X
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Hunt R. R., 2006, Distinctiveness and memory., DOI [10.1093/acprof:oso/9780195169669.001.0001, 10.1093/acprof:oso/9780195169669.003.0001, DOI 10.1093/ACPROF:OSO/9780195169669.003.0001]
   Isola P., 2011, PROC CVPR IEEE, V2011, P145, DOI [DOI 10.1109/CVPR.2011.5995721, 10.1109/CVPR.2011.5995721]
   Isola Phillip, 2011, Advances in Neural Information Processing Systems (NIPS), V24, P2429, DOI DOI 10.1167/12.9.1082
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Khosla A., 2012, SIGGRAPH ASIA 2012 T
   Khosla A, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P867, DOI 10.1145/2566486.2567996
   Khosla A, 2015, IEEE I CONF COMP VIS, P2390, DOI 10.1109/ICCV.2015.275
   Konkle T, 2010, J EXP PSYCHOL GEN, V139, P558, DOI 10.1037/a0019165
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li W, 2011, IEEE I CONF COMP VIS, P2049, DOI 10.1109/ICCV.2011.6126478
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu X, 2015, IEEE I CONF COMP VIS, P990, DOI 10.1109/ICCV.2015.119
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   Mancas M, 2013, IEEE IMAGE PROC, P196, DOI 10.1109/ICIP.2013.6738041
   Maqsood I, 2004, NEURAL COMPUT APPL, V13, P112, DOI 10.1007/s00521-004-0413-4
   Maren S, 1999, TRENDS NEUROSCI, V22, P561, DOI 10.1016/S0166-2236(99)01465-4
   MURRAY N, 2012, PROC CVPR IEEE, P2408, DOI DOI 10.1109/CVPR.2012.6247954
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71
   Peng HW, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1147, DOI 10.1145/2733373.2806303
   Perrone MP, 1995, We Learn We Remember an Understanding of Brain Neural Systems, P342, DOI 10.1142/9789812795885_0025
   Phelps EA, 2004, CURR OPIN NEUROBIOL, V14, P198, DOI 10.1016/j.conb.2004.03.015
   Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780
   Ramanathan S, 2010, LECT NOTES COMPUT SC, V6314, P30, DOI 10.1007/978-3-642-15561-1_3
   Rao TR, 2016, IEEE IMAGE PROC, P634, DOI 10.1109/ICIP.2016.7532434
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rock I., 1959, AM J PSYCHOL, V72, P221
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saleh B, 2013, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2013.107
   Shechtman E, 2007, PROC CVPR IEEE, P1744
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song X, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (IEEE ICMA 2014), P1637, DOI 10.1109/ICMA.2014.6885945
   STANDING L, 1973, Q J EXP PSYCHOL, V25, P207, DOI 10.1080/14640747308400340
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   van de Weijer J, 2007, IEEE I CONF COMP VIS, P2197
   VIJAYANARASIMHA.S, 2008, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2008.4587632
   Viola P., 2006, Proceedings of Advances in Neural Information Processing Systems, V18, P1417
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Xu JZ, 2014, INT C MANAGE SCI ENG, P1622, DOI 10.1109/ICMSE.2014.6930427
   Zhou BL, 2014, ADV NEUR IN, V27
NR 58
TC 5
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35511
EP 35535
DI 10.1007/s11042-019-08202-y
EA OCT 2019
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000492236300005
DA 2024-07-18
ER

PT J
AU Bok, K
   Yoon, S
   Yoo, J
AF Bok, Kyoungsoo
   Yoon, Sangwon
   Yoo, Jaesoo
TI Trust evaluation of multimedia documents based on extended provenance
   model in social semantic web
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web documents; Provenance; Social semantic web; Trust evaluation
ID USER REPUTATION
AB Recently, the importance of social semantic web, which is a combination of the semantic web and the social web, has been increasing with active data creation and sharing through the Web. In this paper, we proposes a provenance based trust evaluation scheme of multimedia documents by extending the PROV data model in social semantic web. The proposed scheme extends the PROV data model of W3C to manage the provenance and evaluate the trust of multimedia documents in a social semantic web environment. The trust of multimedia documents is evaluated by considering the agent trust, source document trust, and reputation score of current document. The evaluated trust is managed as provenance information, and when users request a query, the query results are generated by considering trust. To verify the validity of the proposed scheme, the trust is compared and evaluated using SPARQL queries.
C1 [Bok, Kyoungsoo; Yoon, Sangwon; Yoo, Jaesoo] Chungbuk Natl Univ, Sch Informat & Commun Engn, Chungdae Ro 1, Cheongju 28644, Chungbuk, South Korea.
C3 Chungbuk National University
RP Yoo, J (corresponding author), Chungbuk Natl Univ, Sch Informat & Commun Engn, Chungdae Ro 1, Cheongju 28644, Chungbuk, South Korea.
EM ksbok@chungbuk.ac.kr; nugo8802@naver.com; yjs@chungbuk.ac.kr
OI YOO, JAESOO/0000-0001-9926-9947
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Education [2015R1D1A3A01015962];
   MSIT(Ministry of Science, ICT), Korea, under the ITRC (Information
   Technology Research Center) support program [IITP-2018-2013-1-00881];
   National Research Foundation of Korea (NRF) - Korea government (MSIP)
   [2016R1A2B3007527]; Next-Generation Information Computing Development
   Program through the National Research Foundation of Korea (NRF) -
   Ministry of Science, ICT [NRF-2017M3C4A7069432]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Education(2015R1D1A3A01015962), by the MSIT(Ministry of Science, ICT),
   Korea, under the ITRC (Information Technology Research Center) support
   program (IITP-2018-2013-1-00881) supervised by the IITP(Institute for
   Information & communication Technology Promotion), by the National
   Research Foundation of Korea (NRF) grant funded by the Korea government
   (MSIP) (No. 2016R1A2B3007527), and by Next-Generation Information
   Computing Development Program through the National Research Foundation
   of Korea (NRF) funded by the Ministry of Science, ICT (No.
   NRF-2017M3C4A7069432).
CR [Anonymous], MANAGING USING PROVE
   [Anonymous], P WWW WORKSH MOD TRU
   [Anonymous], 2007, Proceedings of the 16th international conference on world wide web, Banff, Alberta, Canada, DOI DOI 10.1145/1242572.1242684
   Antoniou Grigoris, 2004, A Semantic Web Primer
   Artz D, 2007, J WEB SEMANT, V5, P58, DOI 10.1016/j.websem.2007.03.002
   Batrinca B, 2015, AI SOC, V30, P89, DOI 10.1007/s00146-014-0549-4
   Bok K, 2017, KSII T INTERNET INF, V11, P1570, DOI 10.3837/tiis.2017.03.018
   Cha M, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P1
   Chapman AdrianeP., 2008, P 2008 ACM SIGMOD IN, P993, DOI DOI 10.1145/1376616.1376715
   Constantinides E., 2008, J DIRECT DATA DIGITA, V9, P231, DOI [DOI 10.1057/PALGRAVE.DDDMP.4350098, 10.1057/palgrave.dddmp.4350098]
   Cormode G., 2008, 1 MONDAY, V13, P1, DOI 10.5210/fm.v13i6.2125
   Corsar D, 2016, LECT NOTES COMPUT SC, V9672, P195, DOI 10.1007/978-3-319-40593-3_20
   De Nies T, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P167
   Decker S, 2000, IEEE INTERNET COMPUT, V4, P63, DOI 10.1109/4236.877487
   Ding L., 2005, Proceedings of the IEEE Instrumentation and Measurement Technology Conference (IEEE Cat. No.05CH37627C)
   Gaspar Wander, 2015, International Journal of Metadata, Semantics and Ontologies, V10, P123
   Golbeck J, 2008, CONCURR COMP-PRACT E, V20, P431, DOI 10.1002/cpe.1238
   Golbeck J, 2006, LECT NOTES COMPUT SC, V4145, P101
   Gruber T, 2006, LECT NOTES COMPUT SC, V4273, P994
   Halpin H, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P287, DOI 10.1145/2567948.2577357
   Han YS, 2012, COMPUT INFORM, V31, P447
   Hassanzadeh O, 2012, PROC INT CONF DATA, P1204, DOI 10.1109/ICDE.2012.141
   Jung Im Y., 2011, 2011 IEEE 9th International Symposium on Parallel and Distributed Processing with Applications (ISPA), P294, DOI 10.1109/ISPA.2011.37
   Karvounarakis G., 2010, SIGMOD, P951, DOI DOI 10.1145/1807167.1807269
   Kwon O, 2010, COMPUT HUM BEHAV, V26, P254, DOI 10.1016/j.chb.2009.04.011
   Liu JT, 2014, INT J PHOTOENERGY, V2014, DOI 10.1155/2014/209028
   Ma ZM, 2016, KNOWL ENG REV, V31, P391, DOI 10.1017/S0269888916000217
   Maccioni Antonio, 2013, Current Trends in Web Engineering. ICWE 2013 International Workshops ComposableWeb, QWE, MDWE, DMSSW, EMotions, CSE, SSN, and PhD Symposium. Revised Selected Papers: LNCS 8295, P207, DOI 10.1007/978-3-319-04244-2_19
   Mahmood T, 2013, COMPUT STAND INTER, V35, P6, DOI 10.1016/j.csi.2012.02.004
   Maniymaran B, 2007, GLOB TELECOMM CONF, P248
   Moreau C, 2013, ZOOKEYS, P1, DOI 10.3897/zookeys.294.4796
   Moreau Luc, 2010, Foundations and Trends in Web Science, V2, P99, DOI 10.1561/1800000010
   Murugesan San, 2007, IT Professional, V9, P34, DOI 10.1109/MITP.2007.78
   Phethean C, 2015, LECT NOTES COMPUT SC, V9089, P15, DOI 10.1007/978-3-319-18609-2_2
   Rafferty P, 2011, J DOC, V67, P896, DOI 10.1108/00220411111164745
   Ram S, 2012, J DATA SEMANT, V1, P11, DOI 10.1007/s13740-012-0002-0
   Schäler M, 2011, LECT NOTES COMPUT SC, V7051, P3, DOI 10.1007/978-3-642-24577-0_3
   Shadbolt N, 2006, IEEE INTELL SYST, V21, P96, DOI 10.1109/MIS.2006.62
   Sharma K, 2015, 2015 14TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY (ICIT 2015), P94, DOI 10.1109/ICIT.2015.21
   Shim S, 2009, DECIS SUPPORT SYST, V47, P415, DOI 10.1016/j.dss.2009.04.008
   Spaniol M, 2008, J UNIVERS COMPUT SCI, V14, P1792
   Theoharis Y, 2011, IEEE INTERNET COMPUT, V15, P31, DOI 10.1109/MIC.2010.127
   Wylot M, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P455, DOI 10.1145/2566486.2568014
   Zhang O. Q., 2011, Proceedings of the 2011 IEEE 3rd International Conference on Cloud Computing Technology and Science (CloudCom 2011), P446, DOI 10.1109/CloudCom.2011.66
NR 44
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28681
EP 28702
DI 10.1007/s11042-018-6243-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700019
DA 2024-07-18
ER

PT J
AU Cao, JW
   Cao, M
   Wang, JZ
   Yin, C
   Wang, DP
   Vidal, PP
AF Cao, Jiuwen
   Cao, Min
   Wang, Jianzhong
   Yin, Chun
   Wang, Danping
   Vidal, Pierre-Paul
TI Urban noise recognition with convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Urban noise recognition; Convolutional neural network; Log-Mel-spectrum;
   Dropout; FBank spectrum
ID TRAFFIC-NOISE; SPEECH; SURVEILLANCE
AB Urban noise recognition play a vital role in city management and safety operation, especially in the recent smart city engineering. Exiting studies on urban noise recognition are mostly based on conventional acoustic features, such as Mel-Frequency Cepstral Coefficients (MFCC) and Linear Prediction Cepstral Coefficients (LPCC), and the shallow structure based classifiers, such as support vector machine (SVM). However, the urban acoustic environment is complicated and changeable. Conventional acoustic representation and recognition methods may be insufficient in characterizing urban noises, and generally suffer from a degraded performance. In this paper, we study the recent deep neural network based urban noise recognition. The log-Mel-spectrogram, namely, the FBank feature is first derived for acoustic representation. Then, the FBank spectrum constructed with a set of FBank feature vectors from multiple acoustic signal frames is fed to a convolutional neural network (CNN) for urban noise recognition. Comprehensive studies on the dimension of FBank spectrums and the parameters in CNN, including the size of learnable kernels, the dropout rate, and the activation function, etc., are presented in the paper. An acoustic database collected in real environment covering 11 most common urban noises with more than 56,000 samples is constructed for model verification and performance evaluation. In addition, the traditional LPCC and MFCC acoustic feature combining with two popular machine learning algorithms, extreme learning machine (ELM) and support vector machine (SVM), and the FBank image feature combining with extreme learning machine (ELM), hierarchical extreme learning machine (H-ELM) and multilayer extreme learning machine (ML-ELM), have also been presented for discussions. Experimental results show that the proposed method generally outperforms conventional shallow structure based classifiers.
C1 [Cao, Jiuwen; Cao, Min; Wang, Jianzhong; Wang, Danping; Vidal, Pierre-Paul] Hangzhou Dianzi Univ, Sch Automat, Hangzhou 310018, Zhejiang, Peoples R China.
   [Yin, Chun] Univ Elect Sci & Technol China, Sch Automat Engn, Chengdu 611731, Sichuan, Peoples R China.
   [Wang, Danping] Univ Paris 05, Plateforme Sensorimotr, F-75270 Paris, France.
   [Vidal, Pierre-Paul] Univ Paris 05, COGNAC G COGNit & ACt Grp, F-75270 Paris, France.
C3 Hangzhou Dianzi University; University of Electronic Science &
   Technology of China; Universite Paris Cite; Universite Paris Cite
RP Cao, JW (corresponding author), Hangzhou Dianzi Univ, Sch Automat, Hangzhou 310018, Zhejiang, Peoples R China.
EM jwcao@hdu.edu.cn; wangjz@hdu.edu.cn; yinchun.86416@163.com;
   danping.wang@parisdescartes.fr; pierre-paul.vidal@parisdescartes.fr
RI cao, jiuwen/C-9547-2009; Chen, YangQuan/A-2301-2008
OI Chen, YangQuan/0000-0002-7422-5988
FU National Natural Science Foundation of China [61503104, U1509205];
   Hangzhou Smart City Research Center of Zhejiang/Zhejiang Smart City
   Regional Collaborative Innovation Center [GK150906299001/019]
FX This work was supported by the National Natural Science Foundation of
   China (61503104, U1509205) and Hangzhou Smart City Research Center of
   Zhejiang/Zhejiang Smart City Regional Collaborative Innovation Center
   (GK150906299001/019).
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Agha A, 2017, APPL ACOUST, V117, P236, DOI 10.1016/j.apacoust.2016.05.025
   Ahmad KS, 2015, 2015 EIGHTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION (ICAPR), P105
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   Asensio C, 2017, APPL ACOUST, V117, P191, DOI 10.1016/j.apacoust.2016.11.013
   Azar ER, 2012, AUTOMAT CONSTR, V24, P194, DOI 10.1016/j.autcon.2012.03.003
   Barrigon Morillas JM, 2002, APPL ACOUST, V63, P1061, DOI 10.1016/S0003-682X(02)00030-0
   Calixto A, 2003, CITIES, V20, P23, DOI 10.1016/S0264-2751(02)00093-8
   Cao JW, 2018, MECH SYST SIGNAL PR, V113, P222, DOI 10.1016/j.ymssp.2017.10.016
   Cao JW, 2017, NEUROCOMPUTING, V261, P231, DOI 10.1016/j.neucom.2016.03.113
   Cao JW, 2017, IEEE T CYBERNETICS, V47, P4392, DOI 10.1109/TCYB.2016.2609999
   Cao JW, 2017, MULTIDIM SYST SIGN P, V28, P921, DOI 10.1007/s11045-015-0374-z
   Cao JW, 2016, NEURAL NETWORKS, V81, P91, DOI 10.1016/j.neunet.2016.06.001
   Cao JW, 2016, MULTIMED TOOLS APPL, V75, P2839, DOI 10.1007/s11042-014-2424-1
   Cao M, 2017, CHIN CONTR CONF, P5400, DOI 10.23919/ChiCC.2017.8028211
   Chutani S, 2018, MULTIMED TOOLS APPL, V77, P7447, DOI 10.1007/s11042-017-4656-3
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Deng L., 2014, FOND T SIGN PROC, V7, P197, DOI [10.1561/2000000039, DOI 10.1561/2000000039, 10.1561/]
   Han Y, 2017, IEEE-ACM T AUDIO SPE, V25, P208, DOI 10.1109/TASLP.2016.2632307
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Huang BX, 2015, APPL ACOUST, V99, P125, DOI 10.1016/j.apacoust.2015.06.004
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang Y, 2014, COMP ANAL STUDY GAUS
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li BG, 2002, APPL ACOUST, V63, P1137, DOI 10.1016/S0003-682X(02)00024-5
   de Souza LCL, 2011, COMPUT ENVIRON URBAN, V35, P421, DOI 10.1016/j.compenvurbsys.2011.06.001
   Mydlarz C, 2017, APPL ACOUST, V117, P207, DOI 10.1016/j.apacoust.2016.06.010
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nan SY, 2017, IEEE T NEUR NET LEAR, V28, P94, DOI 10.1109/TNNLS.2015.2504382
   Ntalampiras S, 2014, DIGIT SIGNAL PROCESS, V31, P69, DOI 10.1016/j.dsp.2014.05.003
   Piczak K. J., 2015, IEEE INT WORKS MACH, P1
   Qian YM, 2016, IEEE-ACM T AUDIO SPE, V24, P2263, DOI 10.1109/TASLP.2016.2602884
   Rezazadeh Azar E, 2011, 3 INT 9 CONSTR SPEC
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sainath TN, 2015, NEURAL NETWORKS, V64, P39, DOI 10.1016/j.neunet.2014.08.005
   Sak H, 2014, INTERSPEECH, P338
   Salomons EM, 2012, LANDSCAPE URBAN PLAN, V108, P2, DOI 10.1016/j.landurbplan.2012.06.017
   Fernández LPS, 2015, 2015 SAI INTELLIGENT SYSTEMS CONFERENCE (INTELLISYS), P381, DOI 10.1109/IntelliSys.2015.7361170
   SCHROEDER MR, 1985, IEEE COMMUN MAG, V23, P54, DOI 10.1109/MCOM.1985.1092631
   Sermanet P, 2012, INT C PATT RECOG, P3288
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stoeckle S, 2001, ANZIIS 2001: PROCEEDINGS OF THE SEVENTH AUSTRALIAN AND NEW ZEALAND INTELLIGENT INFORMATION SYSTEMS CONFERENCE, P399
   Torija AJ, 2016, EXPERT SYST APPL, V53, P1, DOI 10.1016/j.eswa.2016.01.011
   Tsai KT, 2009, APPL ACOUST, V70, P964, DOI 10.1016/j.apacoust.2008.11.001
   Yang SW, 2016, PROCEEDINGS OF THE 2016 12TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P924, DOI 10.1109/WCICA.2016.7578544
   Ye JX, 2017, APPL ACOUST, V117, P246, DOI 10.1016/j.apacoust.2016.08.002
   Zannin P.H. T., 2003, ENV IMPACE ASSESSMEN, V23, P245, DOI [DOI 10.1016/S0195-9255(02)00092-6, DOI 10.1016/50195-9255(02100092-6]
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22629, DOI 10.1007/s11042-017-5023-0
   Zhao JQ, 2012, APPL ACOUST, V73, P276, DOI 10.1016/j.apacoust.2011.09.003
NR 50
TC 37
Z9 40
U1 6
U2 56
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29021
EP 29041
DI 10.1007/s11042-018-6295-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700037
DA 2024-07-18
ER

PT J
AU Chaudhry, AM
   Riaz, MM
   Ghafoor, A
AF Chaudhry, Alina Majeed
   Riaz, M. Mohsin
   Ghafoor, Abdul
TI Underwater visibility restoration using dehazing, contrast enhancement
   and filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Haze removal; Image enhancement; Color restoration
ID IMAGE-ENHANCEMENT; CHANNEL
AB A framework for underwater image haze removal and visibility enhancement is proposed. Hybrid median filter in conjunction with shock filter is utilized for initial enhancement of image. For further enhancement and color restoration, content adaptive detail enhancement is applied followed by contrast enhancement in the RGB and HSV color space. The proposed framework effectively dehazes the images, and also minimizes color distortion and artifacts. The quantitative and visual analysis effectiveness demonstrate the effectiveness of our proposed technique.
C1 [Chaudhry, Alina Majeed; Ghafoor, Abdul] Natl Univ Sci & Technol, Rawalpindi, Pakistan.
   [Riaz, M. Mohsin] COMSATS Univ Islamabad, Islamabad, Pakistan.
C3 National University of Sciences & Technology - Pakistan; COMSATS
   University Islamabad (CUI)
RP Ghafoor, A (corresponding author), Natl Univ Sci & Technol, Rawalpindi, Pakistan.
EM alina.phd@students.mcs.edu.pk; mohsin.riaz@comsats.edu.pk;
   abdulghafoor-mcs@nust.edu.pk
RI Imran, Muhammad/AAS-9984-2021
OI Imran, Muhammad/0000-0002-7122-8454; Ghafoor, Abdul/0000-0002-6117-3656
CR Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Ancuti C, 2012, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2012.6247661
   [Anonymous], 2013, IEEE INT C COMP VIS
   Auburt G, 2002, APPL MATH SCI
   Baig N, 2016, IEEE SIGNAL PROC LET, V23, P853, DOI 10.1109/LSP.2016.2559805
   Chaudhry AM, 2018, IEEE GEOSCI REMOTE S, V15, P932, DOI 10.1109/LGRS.2018.2814016
   Chen Y, 2018, IEEE T CIRC SYST VID, V28, P414, DOI 10.1109/TCSVT.2016.2615444
   Chen Y, 2014, IEEE T MED IMAGING, V33, P2271, DOI 10.1109/TMI.2014.2336860
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Davies E R, 2006, MACHINE VISION THEOR
   Drews PLJ, 2016, IEEE COMPUT GRAPH, V36, P24, DOI 10.1109/MCG.2016.26
   Emberton S, 2015, P BRIT MACH VIS C UK
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   He DM, 2004, OPT LASER ENG, V41, P217, DOI 10.1016/S0143-8166(02)00138-0
   He K, 2007, IEEE T PATTERN ANAL, V20, P140
   Kou F, 2015, IEEE SIGNAL PROC LET, V22, P211, DOI 10.1109/LSP.2014.2353774
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Liu J, 2017, IEEE T MED IMAGING, V36, P2499, DOI 10.1109/TMI.2017.2739841
   Lu H, 2017, ARXIV170203600
   Matkovic Kresimir, 2005, COMPUTATIONAL AESTHE
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Ouyang B, 2013, IEEE J OCEANIC ENG, V38, P566, DOI 10.1109/JOE.2012.2229066
   Park D, 2013, IEICE T INF SYST, VE96D, P1793, DOI 10.1587/transinf.E96.D.1793
   Ravisankar P, 2018, MULTIMED TOOLS APPL, V77, P5547, DOI 10.1007/s11042-017-4466-7
   Schechner YY, 2005, IEEE J OCEANIC ENG, V30, P570, DOI 10.1109/JOE.2005.850871
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Shwartz S., 2006, 2006 IEEE COMP SOC C, V2, P1984, DOI DOI 10.1109/CVPR.2006.71
   Snchez Ferreira S, 2015, IEEE C EV COMP, P43
   Treibitz T, 2009, IEEE T PATTERN ANAL, V31, P385, DOI 10.1109/TPAMI.2008.85
   Yang W, 2017, IEEE ACCESS, V5, P24698, DOI 10.1109/ACCESS.2017.2766438
   Zhang S, 2017, NEUROCOMPUTING, V245, P1, DOI 10.1016/j.neucom.2017.03.029
   Zhao XW, 2015, OCEAN ENG, V94, P163, DOI 10.1016/j.oceaneng.2014.11.036
   Zhu XM, 2015, 2015 14TH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), P443, DOI 10.1109/MVA.2015.7153106
NR 33
TC 6
Z9 6
U1 4
U2 89
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 28179
EP 28187
DI 10.1007/s11042-019-07922-5
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000062
DA 2024-07-18
ER

PT J
AU El-Shafai, W
   El-Rabaie, S
   El-Halawany, MM
   Abd El-Samie, FE
AF El-Shafai, W.
   El-Rabaie, S.
   El-Halawany, M. M.
   Abd El-Samie, F. E.
TI Security of 3D-HEVC transmission based on fusion and watermarking
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D-HEVC transmission system; Multimedia watermarking; Wavelet fusion;
   Homomorphic transform; DWT; SVD; DSWT; DCT
ID DIGITAL VIDEO WATERMARKING; ROBUST WATERMARKING; H.264/AVC; FRAMEWORK;
   SCHEME
AB This paper presents two robust hybrid watermarking techniques for efficiently securing the transmission of the Three-Dimensional High Efficiency Video Coding (3D-HEVC). The first watermarking technique is the homomorphic-transform-based Singular Value Decomposition (SVD) in Discrete Wavelet Transform (DWT) domain. The second technique is the three-level Discrete Stationary Wavelet Transform (DSWT) in Discrete Cosine Transform (DCT) domain. The objective of the two proposed hybrid watermarking techniques is to increase the immunity of the watermarked 3D-HEVC to attacks and achieve adequate perceptual quality. Also, we propose a wavelet-based fusion technique to combine multiple depth watermark frames into one fused depth watermark frame. Then, the resultant fused depth watermark is embedded in the 3D-HEVC color frames using the two proposed watermarking techniques to produce the watermarked 3D-HEVC streams. The proposed techniques reduce the required bit rate for transmitting the color-plus-depth 3D-HEVC data. The performances of the two proposed watermarking techniques are compared with those of the state-of-the-art watermarking techniques. The comparisons depend on both subjective visual results and objective results: the Peak Signal-to-Noise Ratios (PSNRs) of the watermarked frames and the Normalized Correlation (NC) of the extracted watermark frames. Extensive simulation experiments on different standard 3D video sequences have been conducted in the presence of attacks. The obtained results confirm that the proposed watermarking techniques achieve not only very good perceptual quality, appreciated PSNR values, and saving of the transmission bit rate, but also high correlation coefficients, and high robustness in the presence of attacks. Furthermore, the proposed techniques improve both the capacity of the embedded information and the robustness without affecting the perceptual quality of the original 3D-HEVC frames. Indeed, the extraction of the fused and multiple primary and secondary depth watermark frames is possible in the presence of different attacks.
C1 [El-Shafai, W.; El-Rabaie, S.; El-Halawany, M. M.; Abd El-Samie, F. E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP El-Shafai, W (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
EM eng.waled.elshafai@gmail.com; elsayed.elrabaie@gmail.com;
   mmohamed.elhalawany@gmail.com; fathi.sayed@yahoo.com
RI Sayed, Fathi/HRA-4752-2023; El-Shafai, Walid/AAG-4796-2021
OI Sayed, Fathi/0000-0001-8749-9518; El-Shafai, Walid/0000-0001-7509-2120;
   EL-Rabaie, El-Sayed/0000-0001-6854-5881
CR Al-Afandy KA., 2016, Adv Sci Technol Eng Syst J, V1, P42, DOI [10.25046/aj010508, DOI 10.25046/AJ010508]
   [Anonymous], 2014, JOINT COLL TEAM 3D V
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], P IEEE INT S BROADB
   Asikuzzaman M, 2016, IEEE T MULTIMEDIA, V18, P1733, DOI 10.1109/TMM.2016.2589208
   Campisi P, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.3009554
   Chen Y, 2014, IEEE MULTIMEDIA, V21, P90, DOI 10.1109/MMUL.2014.31
   De Abreu A, 2015, IEEE J-STSP, V9, P487, DOI 10.1109/JSTSP.2015.2407320
   DUTTA T, 2013, NAT C COMM NCC, P1
   Dutta T, 2016, J VIS COMMUN IMAGE R, V38, P29, DOI 10.1016/j.jvcir.2015.12.007
   El-Shafai W, 2018, INT J COMMUN SYST, V31
   Esen E, 2011, IEEE T CIRC SYST VID, V21, P1130, DOI 10.1109/TCSVT.2011.2134770
   Franco-Contreras J., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2761, DOI 10.1109/ICIP.2011.6116242
   Gaj S, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3009910
   Hartung F, 1998, SIGNAL PROCESS, V66, P283, DOI 10.1016/S0165-1684(98)00011-5
   Khalid Ahmad, 2017, Ph. D. Dissertation.
   Kim HD, 2012, IEEE T BROADCAST, V58, P533, DOI 10.1109/TBC.2012.2206851
   Lin YH, 2012, INT CONF ACOUST SPEE, P1801, DOI 10.1109/ICASSP.2012.6288250
   Lin YH, 2011, IEEE T BROADCAST, V57, P602, DOI 10.1109/TBC.2011.2131470
   Min-Jeong Lee, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P81, DOI 10.1109/IIHMSP.2011.83
   Naeem EA, 2016, COMPUT ELECTR ENG, V54, P450, DOI 10.1016/j.compeleceng.2015.08.018
   Noorkami M, 2008, IEEE T INF FOREN SEC, V3, P441, DOI 10.1109/TIFS.2008.923825
   Noorkami M, 2007, IEEE T INF FOREN SEC, V2, P14, DOI 10.1109/TIFS.2006.890306
   Ogawa K, 2015, I SYMP CONSUM ELECTR, P102, DOI 10.1109/ICCE.2015.7066337
   Purica AI, 2016, IEEE T CIRC SYST VID, V26, P360, DOI 10.1109/TCSVT.2015.2389511
   Qiu G, 2004, INT C PATT RECOG, P865
   Stütz T, 2014, IEEE T MULTIMEDIA, V16, P1337, DOI 10.1109/TMM.2014.2310595
   Su PC, 2011, SIGNAL PROCESS-IMAGE, V26, P413, DOI 10.1016/j.image.2011.07.004
   Swati S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0105613
   Tew Y, 2014, IEEE T CIRC SYST VID, V24, P305, DOI 10.1109/TCSVT.2013.2276710
   Thind DK, 2015, PROCEDIA COMPUT SCI, V46, P1661, DOI 10.1016/j.procs.2015.02.104
   Wang S, 2014, MEASUREMENT, V48, P54, DOI 10.1016/j.measurement.2013.10.028
   Xu DW, 2011, SIGNAL PROCESS-IMAGE, V26, P267, DOI 10.1016/j.image.2011.04.008
   Yaqing Niu, 2011, 2011 3rd European Workshop on Visual Information Processing, P211, DOI 10.1109/EuVIP.2011.6045546
   Zhang J, 2007, IEEE T CIRCUITS-II, V54, P205, DOI 10.1109/TCSII.2006.886247
   Zhang J, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 3, PROCEEDINGS, P46
NR 36
TC 43
Z9 43
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27211
EP 27244
DI 10.1007/s11042-019-7448-0
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000020
DA 2024-07-18
ER

PT J
AU Jeong, Y
   Park, KH
   Park, D
AF Jeong, Yoosoo
   Park, Kil Houm
   Park, Daejin
TI Homogeneity patch search method for voting-based efficient vehicle color
   classification using front-of-vehicle image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color classification; Homogeneity patch; Voting strategy; Multi-class
   Adaboost; HSV histogram
AB Color classification plays a significant role in tracking crime vehicles. Color features can be used to classify vehicle color using a front-of-vehicle image acquired from CCTV. In this paper, we define a new color homogeneity patch and propose search method that focuses on improving the discernment of features by avoiding another color distribution, not a vehicle color, which is included in the vehicle color features. In addition, we could effectively improve this method by using a voting strategy. A region of interest (ROI) that includes a bonnet is detected using predefined information about the given car and the search method is applied to ROI for selecting color homogeneity patches. The proposed approach extracts an HSV histogram for each patch, and adopts the multi-class Adaboost algorithm to classify the color of each patch. We integrate the proposed method with the voting strategy to determine the color of the vehicle. To validate the feasibility of our approach, we compare the results with a sliding window without consideration of homogeneity. Results show that the search method for homogeneity patches can be efficiently applied to recognize vehicle color.
C1 [Jeong, Yoosoo; Park, Kil Houm; Park, Daejin] Kyungpook Natl Univ, Sch Elect Engn, Daegu 41566, South Korea.
C3 Kyungpook National University
RP Park, D (corresponding author), Kyungpook Natl Univ, Sch Elect Engn, Daegu 41566, South Korea.
EM boltanut@knu.ac.kr
OI Park, Daejin/0000-0002-5560-873X
FU BK21 Plus project - Ministry of Education, Korea [21A20131600011]; Basic
   Science Research Program through the National Research Foundation of
   Korea(NRF) - Ministry of Education [2014R1A6A3A04059410]; Electronics
   and Telecommunications Research Institute [MSIP-201612110000]
FX This study was supported by the BK21 Plus project funded by the Ministry
   of Education, Korea (21A20131600011) and by the Basic Science Research
   Program through the National Research Foundation of Korea(NRF) funded by
   the Ministry of Education (2014R1A6A3A04059410). This paper is also the
   result of commissioned research project of Electronics and
   Telecommunications Research Institute (MSIP-201612110000).
CR Baek N, 2007, ICIC
   Brown LM, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P347, DOI 10.1109/AVSS.2013.6636664
   Chen P, 2014, IEEE T INTELL TRANSP, V15, P2340, DOI 10.1109/TITS.2014.2308897
   Dong YM, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P264, DOI 10.1109/CIS.2014.63
   Hsieh JW, 2015, IEEE SENS J, V15, P971, DOI 10.1109/JSEN.2014.2358079
   Huttenlocher, 2012, THEORY COMPUT, V8, P415, DOI [10.4086/toc.2012.v008a019, DOI 10.4086/TOC.2012.V008A019]
   Lin CY, 2014, INT CONF ELECTR COMM, P59, DOI 10.1109/CONIELECOMP.2014.6808568
   Park SM, 2012, INT J COMMUN SYST, V25, P749, DOI 10.1002/dac.1229
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   Sobel I., 1990, ISOTROPIC 3X3 IMAGE
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Wang YC, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-48
NR 12
TC 3
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28633
EP 28648
DI 10.1007/s11042-018-6101-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700016
DA 2024-07-18
ER

PT J
AU Lei, J
   Zhang, BY
   Ling, HF
AF Lei, Jie
   Zhang, BaiYan
   Ling, HeFei
TI Deep learning face representation by fixed erasing in facial landmarks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face verification; Facial landmarks; DCNNs; Data augmentation; Fixed
   erasing
AB Face verification (FV) is a challenging problem, because occlusion, posture, illumination, aging will affect the accuracy of FV. Deep convolutional neural networks (DCNNs) have been widely used in many computer vision tasks. Due to the strong feature learning ability, DCNNs improve the accuracy of FV while they also bring some problems such as overfitting. Erasing has been proven to be an effective method for reducing overfitting, while the erasing position is seldom considered. We analyse the effect of different erasing positions and propose a novel data augmentation method especially for FV, called Fixed Erasing(FE). We randomly erase some face images with random size of rectangles centered on fixed facial landmarks such as the centers of eyes, tip of noses and the corners of mouths. Our method can alleviate the risk of overfitting and make the models learn more robust features. And our method can be easily merged with most DCNN-based FV models through a few lines of code. Extensive experiments demonstrate that FE can improve the performance of most recently proposed FV models on several popular benchmarks.
C1 [Lei, Jie; Zhang, BaiYan; Ling, HeFei] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
   [Lei, Jie] Nanchang Univ, Sch Software, Nanchang 330069, Jiangxi, Peoples R China.
C3 Huazhong University of Science & Technology; Nanchang University
RP Ling, HF (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
EM mymailmylife@163.com; zhangbyxy@hust.edu.cn; lhefei@hust.edu.cn
FU Natural Science Foundation of China [U1536203]; National key research
   and development program of China [2016QY01W0200]; Major Scientific and
   Technological Project of Hubei Province [2018AAA068]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant U1536203, in part by the National key research and
   development program of China(2016QY01W0200), in part by the Major
   Scientific and Technological Project of Hubei Province (2018AAA068).
CR [Anonymous], ARXIV180305846 CORR
   [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.69
   [Anonymous], ARXIV180107698 CORR
   [Anonymous], 2016, COMPUTER VISION PATT
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], ARXIV180105599 CORR
   [Anonymous], P 31 AAAI C ART INT
   [Anonymous], ARXIV171000870 CORR
   [Anonymous], 2017, C COMP VIS PATT REC
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2017, ARXIV170309507 CORR
   [Anonymous], ARXIV180308494 CORR
   [Anonymous], 2014, ARXIV14117923
   [Anonymous], ARXIV150607310 CORR
   [Anonymous], 2016 IEEE C COMP VIS
   [Anonymous], ARXIV170804896 CORR
   [Anonymous], 2013, ARXIV201313013557
   [Anonymous], ARXIV171008092 CORR
   [Anonymous], ARXIV180407573 CORR
   [Anonymous], ACTION2ACTIVITY RECO
   Chen BH, 2017, PROC CVPR IEEE, P4021, DOI 10.1109/CVPR.2017.428
   Deng WH, 2017, PATTERN RECOGN, V66, P63, DOI 10.1016/j.patcog.2016.11.023
   Ding CX, 2018, IEEE T PATTERN ANAL, V40, P1002, DOI 10.1109/TPAMI.2017.2700390
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Huang GS, 2007, 2007 7TH IEEE CONFERENCE ON NANOTECHNOLOGY, VOL 1-3, P7, DOI 10.1109/NANO.2007.4601129
   Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Liu Y., 2016, 2016 3 INT C ARTIFIC, V2016, P2576
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Luo GK, 2018, 2018 IEEE 4TH INTERNATIONAL CONFERENCE ON CONTROL SCIENCE AND SYSTEMS ENGINEERING (ICCSSE 2018), P1, DOI 10.1109/CCSSE.2018.8724758
   Nguyen Hieu V., 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P709, DOI 10.1007/978-3-642-19309-5_55
   Salimans T, 2016, ADV NEUR IN, V29
   Simonyan K., 2014, 14091556 ARXIV
   Sun Y, 2014, ADV NEUR IN, V27
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Wan L, 2013, P 30 INT C MACH LEAR, P1058, DOI DOI 10.5555/3042817.3043055
   Wang F, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1041, DOI 10.1145/3123266.3123359
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Xie LX, 2016, PROC CVPR IEEE, P4753, DOI 10.1109/CVPR.2016.514
   Yu J, 2014, INFORM SCIENCES, V281, P674, DOI 10.1016/j.ins.2014.01.025
   Yu J, 2014, IEEE T CYBERNETICS, V44, P2431, DOI 10.1109/TCYB.2014.2307862
   Yuan CH, 2019, NEUROCOMPUTING, V330, P127, DOI 10.1016/j.neucom.2018.11.010
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang SF, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P1, DOI 10.1109/BTAS.2017.8272675
NR 47
TC 7
Z9 8
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27703
EP 27718
DI 10.1007/s11042-019-07892-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000042
DA 2024-07-18
ER

PT J
AU Park, Y
   Na, MH
   Cho, W
AF Park, Yuha
   Na, Myung Hwan
   Cho, Wanhyun
TI Determination on environmental factors and growth factors affecting
   tomato yield using pattern recognition techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tomato production; Smart farming; Environmental factors; Growth factors;
   Pattern recognition techniques; Graphic analysis method; Dynamic time
   warping; Multidimensional scaling; Data-driven cultivation techniques
ID BIG DATA
AB In the area of smart farming, a big data is being created using information and communication technologies such as the Internet of Things and Cloud computing. Drawing clear and reliable information from analyzing the big data is a challenge task for farmers, researchers, consultants and participants in the agricultural production business. Now, however, there are no many researches as much as the participants need. The paper suggests a statistical application approach for seeking the useful information of the agricultural big data. In the paper the dataset is composed in order to conduct quantitative analysis. From various radars and sensors in researched greenhouses, five environmental factors are measured. In addition to using those environmental factors, a dataset is built through collecting four growth factors, and yield of tomato. Using pattern recognition techniques such as dynamic time warping and multidimensional scaling the paper investigates the relationships among three factors, the environmental factors, the growth factors, and the tomato yield in order to find the most important environmental and growth factors with the aim to increasing tomato production in facility farms. Through analyzing the observed dataset using those pattern recognition techniques, the similarities of temporal sequences among the given patterns of the factors can be measured. Therefore the paper determines the environmental factors and the growth factors that have a strong influence on tomato production currently grown in smart farming greenhouses. Using the analysis results, the paper proposes data-driven cultivation strategies for managing the environmental and growth factors to increase the productivities of tomato.
C1 [Park, Yuha; Cho, Wanhyun] Chonnam Natl Univ, Gwangju, South Korea.
   [Na, Myung Hwan] Chonnam Natl Univ, Dept Stat, Gwangju, South Korea.
C3 Chonnam National University; Chonnam National University
RP Cho, W (corresponding author), Chonnam Natl Univ, Gwangju, South Korea.
EM whcho@chonnam.ac.kr
FU Research Program of Rural Development Administration [PJ01283009]; Korea
   National Research Foundation [2017R1D1A1B03028808]; Korean Government
FX This work was partially supported by the Research Program of Rural
   Development Administration (Project No. PJ01283009), and the Korea
   National Research Foundation (Project No. 2017R1D1A1B03028808) of Korea
   Grant funded by the Korean Government.
CR [Anonymous], 2006, ACM Trans. on Sens. Netw., DOI DOI 10.1145/1138127.1138129
   [Anonymous], TECHNICAL REPORT
   Boyer LR, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01237
   Chaudhuri BB, 1983, ELECTRON LETT, V39, P865
   Cho W, 2018, ADV SCI LETT, V24, P2084, DOI 10.1166/asl.2018.11855
   Coble KH, 2018, APPL ECON PERSPECT P, V40, P79, DOI 10.1093/aepp/ppx056
   Estrada-Ortiz E, 2013, J SOIL SCI PLANT NUT, V13, P612, DOI 10.4067/S0718-95162013005000049
   Fan L, 2017, INTECHOPEN, P177, DOI [10.5772/67233, DOI 10.5772/67233]
   Giorgino T, 2009, J STAT SOFTW, V31, P1, DOI 10.18637/jss.v031.i07
   Jaworska N, 2009, TUTOR QUANT METHODS, V5, P1, DOI 10.20982/tqmp.05.1.p001
   Létourneau G, 2015, AGR WATER MANAGE, V161, P102, DOI 10.1016/j.agwat.2015.07.005
   MYERS CS, 1981, AT&T TECH J, V60, P303, DOI 10.1002/j.1538-7305.1981.tb00243.x
   NaMyungHwan, 2017, [Journal of the Korean Data And Information Science Sociaty, 한국데이터정보과학회지], V28, P1427, DOI 10.7465/jkdi.2017.28.6.1427
   Stubbs Megan, 2016, BIG DATA US AGR, P1
   Sundmaeker H., 2016, DIGITISING IND INTER, P129
   Tuzcu V, 2005, IEEE SYS MAN CYBERN, P182
   Wolfert S, 2017, AGR SYST, V153, P69, DOI 10.1016/j.agsy.2017.01.023
   Wolfert S, 2014, ANN SRII GLOB CONF, P266, DOI 10.1109/SRII.2014.47
   Zhen D, 2013, MECH SYST SIGNAL PR, V34, P191, DOI 10.1016/j.ymssp.2012.07.018
NR 19
TC 2
Z9 2
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28815
EP 28834
DI 10.1007/s11042-019-7212-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700026
DA 2024-07-18
ER

PT J
AU Wang, GD
   Pan, ZK
   Zhang, ZM
AF Wang, Guodong
   Pan, Zhenkuan
   Zhang, Zhimei
TI Deep CNN Denoiser prior for multiplicative noise removal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiplicative noise removal; CNN denoiser prior; Split Bregman method;
   Alternative minimization
ID VARIATIONAL MODEL; SCALE-SPACE; ALGORITHM
AB Multiplicative noise removal is always a hard problem in fundamental image processing task. Many methods are proposed for the multiplicative noise removal by using different denoiser prior in variational framework. Among the image prior, total variation (TV) is first proposed and then many other regularization such as PM, TGV, nonlocal and many other priors are also proposed for enhancing the denoising ability. Although using the priors can get good performance, the models are hard to be resolved with sophisticated priors. A new model based on the deep CNN denoiser prior for removing multiplicative noise is proposed in this paper. The proposed energy function is easy calculated via several sub-optimal questions by split bregman method and alternative minimization is used for the solution. The proposed method does not need to deduce the sophisticated formula and can achieve good performance. From the experiments, we can see that our method achieved good results.
C1 [Wang, Guodong; Pan, Zhenkuan] Qingdao Univ, Coll Comp Sci & Technol, Qingdao, Shandong, Peoples R China.
   [Zhang, Zhimei] Qingdao Univ, Coll Data Sci & Software Engn, Qingdao, Shandong, Peoples R China.
C3 Qingdao University; Qingdao University
RP Wang, GD (corresponding author), Qingdao Univ, Coll Comp Sci & Technol, Qingdao, Shandong, Peoples R China.
EM doctorwgd@gmail.com
FU National Natural Science Foundation of China [61772294]; National
   Scientific and Technological Development and Planning Project during the
   Twelfth Five-year Plan Period [2014BAG03B05]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61772294), The National Scientific and Technological
   Development and Planning Project during the Twelfth Five-year Plan
   Period (No. 2014BAG03B05).
CR Afonso M, 2015, NEUROCOMPUTING, V150, P200, DOI 10.1016/j.neucom.2014.08.073
   [Anonymous], 2017, LEARNING DEEP CNN DE
   Aubert G, 2008, SIAM J APPL MATH, V68, P925, DOI 10.1137/060671814
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Cuiping Wang, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P571, DOI 10.1109/CISP.2010.5647268
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Denis L, 2009, IEEE T IMAGE PROCESS, V18, P1588, DOI 10.1109/TIP.2009.2019302
   Dong J, 2017, SIGNAL PROCESS, V137, P160, DOI 10.1016/j.sigpro.2017.01.032
   Duan JM, 2015, J GLOBAL OPTIM, V62, P853, DOI 10.1007/s10898-015-0290-7
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Hao Y, 2015, AEU-INT J ELECTRON C, V69, P1291, DOI 10.1016/j.aeue.2015.05.009
   Huang YM, 2009, SIAM J IMAGING SCI, V2, P20, DOI 10.1137/080712593
   Jian M, 2017, MULTIMED TOOLS APPL, P1
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Li S, 2016, DIGIT SIGNAL PROCESS, V50, P218, DOI 10.1016/j.dsp.2015.12.012
   Liu M, 2016, J VIS COMMUN IMAGE R, V36, P187, DOI 10.1016/j.jvcir.2016.01.014
   Liu PF, 2015, COMPUT MATH APPL, V70, P2029, DOI 10.1016/j.camwa.2015.08.014
   Lu DY, 2016, J COMPUT APPL MATH, V302, P224, DOI 10.1016/j.cam.2016.02.013
   Lu JG, 2017, MULTIMED TOOLS APPL, V76, P10991, DOI 10.1007/s11042-016-3462-7
   Lu WQ, 2016, MATH METHOD APPL SCI, V39, P4208, DOI 10.1002/mma.3858
   Lv X. G., 2013, MATH PROBL ENG, V2013, P87
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Rudin L, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P103, DOI 10.1007/0-387-21810-6_6
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Setzer S, 2010, J VIS COMMUN IMAGE R, V21, P193, DOI 10.1016/j.jvcir.2009.10.006
   Shama MG, 2016, APPL MATH COMPUT, V276, P109, DOI 10.1016/j.amc.2015.12.005
   Shi JN, 2008, SIAM J IMAGING SCI, V1, P294, DOI 10.1137/070689954
   Ullah A, 2016, J VIS COMMUN IMAGE R, V40, P485, DOI 10.1016/j.jvcir.2016.07.016
   Ullah A, 2016, COMPUT MATH APPL, V71, P2034, DOI 10.1016/j.camwa.2016.03.024
   Wang G, 2013, 2013 IEEE 6 INT C IM, P281
   Wang GD, 2017, MULTIMED TOOLS APPL, V76, P24515, DOI 10.1007/s11042-016-4136-1
NR 32
TC 10
Z9 12
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29007
EP 29019
DI 10.1007/s11042-018-6294-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700036
DA 2024-07-18
ER

PT J
AU Zhu, XB
   Li, ZZ
   Zhang, XY
   Li, P
   Xue, ZY
   Wang, L
AF Zhu, Xiaobin
   Li, Zhuangzi
   Zhang, Xiao-Yu
   Li, Peng
   Xue, Ziyu
   Wang, Lei
TI Deep convolutional representations and kernel extreme learning machines
   for image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Extreme learning machine; Neural network
ID APPROXIMATION; OPTIMIZATION; SCALE
AB Convolutional Neural Networks (CNNs) have been established as a powerful class of models for image classification and related tasks. However, the fully-connected layers in CNN are not robust enough to serve as a classifier to discriminate deep convolutional features, due to the local minima problem of back-propagation. Kernel Extreme Learning Machines (KELMs), known as an outstanding classifier, can not only converge extremely fast but also ensure an outstanding generalization performance. In this paper, we propose a novel image classification framework, in which CNN and KELM are well integrated. In our work, Densely connected network (DenseNet) is employed as the feature extractor, while a radial basis function kernel ELM instead of linear fully connected layer is adopted as a classifier to discriminate categories of extracted features to promote the image classification performance. Experiments conducted on four publicly available datasets demonstrate the promising performance of the proposed framework against the state-of-the-art methods.
C1 [Zhu, Xiaobin; Li, Zhuangzi] Beijing Technol & Business Univ, Sch Comp & Informat Engn, Beijing, Peoples R China.
   [Zhang, Xiao-Yu] Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China.
   [Li, Peng] China Univ Petr, Coll Informat & Control Engn, Beijing, Peoples R China.
   [Xue, Ziyu; Wang, Lei] SART, Acad Broadcasting Sci, Inst Informat Technol, Beijing, Peoples R China.
C3 Beijing Technology & Business University; Chinese Academy of Sciences;
   Institute of Information Engineering, CAS; China University of Petroleum
RP Zhang, XY (corresponding author), Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China.
EM zhangxiaoyu@iie.ac.cn; lipeng@upc.edu.cn
RI Zhang, Xiaoyu/ISV-0984-2023; xiaoyu, zhang/JXY-7226-2024; zhang,
   xiaoyu/HJI-4374-2023; Zhang, xiaoyu/HTM-3222-2023; Wang,
   Lei/A-7836-2018; Zhang, xiaoyu/GXA-3206-2022; Wang, Zixuan/HZJ-2348-2023
OI Wang, Lei/0000-0003-1802-7466; 
FU National Key R&D Program of China [2017YFB1401000]; National Natural
   Science Foundation of China [61501457, 61602517]
FX This work was supported by National Key R&D Program of China
   (2017YFB1401000) and National Natural Science Foundation of China
   (61501457, 61602517).
CR Aguilar E, 2017, LECT NOTES COMPUT SC, V10485, P213, DOI 10.1007/978-3-319-68548-9_20
   An L, 2012, IEEE IMAGE PROC, P2209, DOI 10.1109/ICIP.2012.6467333
   [Anonymous], IEEE T CYBERNETICS
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], COMPUTING SCI ENG
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Cai ZY, 2018, IEEE T IMAGE PROCESS, V27, P2471, DOI 10.1109/TIP.2018.2806839
   Cui Y, 2018, PROC CVPR IEEE, P4109, DOI 10.1109/CVPR.2018.00432
   Cui Y, 2017, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR.2017.325
   Dai P, 2017, AAAI CONF ARTIF INTE, P4567
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhungel Neeraj, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P106, DOI 10.1007/978-3-319-46723-8_13
   Gao SH, 2016, IEEE T CIRC SYST VID, V26, P494, DOI 10.1109/TCSVT.2015.2389413
   Gomez AN, 2017, ADV NEUR IN, V30
   Griffin G., 2007, CALTECH 256 OBJECT C
   Gurpinar F., 2016, P IEEE C COMP VIS PA, P80
   Gürpinar F, 2016, LECT NOTES COMPUT SC, V9915, P372, DOI 10.1007/978-3-319-49409-8_30
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Q, 2014, NEUROCOMPUTING, V128, P88, DOI 10.1016/j.neucom.2012.12.063
   Hou SH, 2017, IEEE I CONF COMP VIS, P502, DOI 10.1109/ICCV.2017.62
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977
   Huang GB, 2015, COGN COMPUT, V7, P263, DOI 10.1007/s12559-015-9333-0
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang ZY, 2017, IEEE T CYBERNETICS, V47, P920, DOI 10.1109/TCYB.2016.2533424
   IGELNIK B, 1995, IEEE T NEURAL NETWOR, V6, P1320, DOI 10.1109/72.471375
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Heravi EJ, 2018, PATTERN RECOGN LETT, V105, P50, DOI 10.1016/j.patrec.2017.12.007
   Kasun LLC, 2013, IEEE INTELL SYST, V28, P31
   Khosla A., 2011, P CVPR WORKSH FIN GR
   Krause J, 2016, LECT NOTES COMPUT SC, V9907, P301, DOI 10.1007/978-3-319-46487-9_19
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larsson Gustav, 2016, ARXIV160507648
   Liu C, 2016, LECT NOTES COMPUT SC, V9677, P37, DOI 10.1007/978-3-319-39601-9_4
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luan S., 2018, IEEE Transactions on Image Processing
   Luo WT, 2019, INT J PAVEMENT ENG, V20, P1170, DOI 10.1080/10298436.2017.1394099
   Martinel N, 2016, COMPUT VIS IMAGE UND, V148, P67, DOI 10.1016/j.cviu.2016.01.012
   Myers A, 2015, IEEE I CONF COMP VIS, P1233, DOI 10.1109/ICCV.2015.146
   Niu XX, 2012, PATTERN RECOGN, V45, P1318, DOI 10.1016/j.patcog.2011.09.021
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   PAO YH, 1994, NEUROCOMPUTING, V6, P163, DOI 10.1016/0925-2312(94)90053-1
   Shen FM, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P595, DOI 10.1145/3077136.3080767
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava RK, 2015, ARXIV150500387
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tang JX, 2016, IEEE T NEUR NET LEAR, V27, P809, DOI 10.1109/TNNLS.2015.2424995
   Targ S., 2016, Resnet in Resnet: Generalizing Residual Architectures
   Uzair M, 2017, IEEE T CYBERNETICS, V47, P651, DOI 10.1109/TCYB.2016.2523538
   Weng Q, 2018, INT J REMOTE SENS, V39, P6281, DOI 10.1080/01431161.2018.1458346
   White H., 1989, IJCNN: International Joint Conference on Neural Networks (Cat. No.89CH2765-6), P451, DOI 10.1109/IJCNN.1989.118281
   Xie ZG, 2014, COMPUT GRAPH FORUM, V33, P85, DOI 10.1111/cgf.12434
   Yan JC, 2018, IEEE T CYBERNETICS, V48, P765, DOI 10.1109/TCYB.2017.2655538
   Yan JC, 2016, IEEE T PATTERN ANAL, V38, P1228, DOI 10.1109/TPAMI.2015.2477832
   Yan JC, 2015, IEEE T IMAGE PROCESS, V24, P994, DOI 10.1109/TIP.2014.2387386
   Yan JC, 2010, IEEE SIGNAL PROC LET, V17, P739, DOI 10.1109/LSP.2010.2053200
   Yanai K, 2015, IEEE INT C MULTIMEDI
   Yosinski J, 2014, ADV NEUR IN, V27
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang CJ, 2016, INFORM SCIENCES, V369, P160, DOI 10.1016/j.ins.2016.06.029
   Zhang XY, 2015, IEEE T NEUR NET LEAR, V26, P3034, DOI 10.1109/TNNLS.2015.2401595
   Zhao B, 2017, IEEE T MULTIMEDIA, V19, P1245, DOI 10.1109/TMM.2017.2648498
   Zheng JN, 2018, IET COMPUT VIS, V12, P298, DOI 10.1049/iet-cvi.2016.0335
   Zhu XB, 2014, PATTERN RECOGN, V47, P1791, DOI 10.1016/j.patcog.2013.11.018
NR 70
TC 13
Z9 13
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29271
EP 29290
DI 10.1007/s11042-018-6781-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700047
DA 2024-07-18
ER

PT J
AU Kumar, A
   Garg, G
AF Kumar, Akshi
   Garg, Geetanjali
TI Sentiment analysis of multimodal twitter data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal text; Twitter; Sentiment; Context-aware; Optical character
   recognition
AB Text-driven sentiment analysis has been widely studied in the past decade, on both random and benchmark textual Twitter datasets. Few pertinent studies have also reported visual analysis of images to predict sentiment, but much of the work has analyzed a single modality data, that is either text or image or GIF video. More recently, as the images, memes and GIFs dominate the social feeds; typographic/infographic visual content has become a non-trivial element of social media. This multimodal text combines both text and image defining a novel visual language which needs to be analyzed as it has the potential to modify, confirm or grade the polarity of the sentiment. We propose a multimodal sentiment analysis model to determine the sentiment polarity and score for any incoming tweet, i.e., textual, image or info-graphic and typographic. Image sentiment scoring is done using SentiBank and SentiStrength scoring for Regions with convolution neural network (R-CNN). Text sentiment scoring is done using a novel context-aware hybrid (lexicon and machine learning) technique. Multimodal sentiment scoring is done by separating text from image using an optical character recognizer and then aggregating the independently processed image and text sentiment scores. High performance accuracy of 91.32% is observed for the random multimodal tweet dataset used to evaluate the proposed model. The research further demonstrates that combining both textual and image features outperforms separate models that rely exclusively on either images or text analysis.
C1 [Kumar, Akshi; Garg, Geetanjali] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
C3 Delhi Technological University
RP Kumar, A (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
EM akshikumar@dce.ac.in; geetanjali.garg@dtu.ac.in
RI Kumar, Akshi/Y-9314-2019; ARSLAN, Okan/AAA-3232-2020
OI Kumar, Akshi/0000-0003-4263-7168; 
CR [Anonymous], 2012, P 20 ACM INT C MULT
   [Anonymous], 2017, INT J ENG SCI
   [Anonymous], 2012, PROC 20 ACM INT C MU
   [Anonymous], 2010, P 18 ACM INT C MULTI
   [Anonymous], AAAI 2015
   [Anonymous], GEN WEISZFELD ALGORI
   [Anonymous], 2018, SUSTAINABLE COMPUTIN
   [Anonymous], 2016, INDIAN J SCI TECHNOL, DOI DOI 10.17485/IJST/2015/V8I1/105286
   [Anonymous], 2013, P 13 INT WORKSH MULT
   [Anonymous], 2012, P 20 ACM INT C MULT
   [Anonymous], 2017, P INT SYST DES APPL
   [Anonymous], 2015, EMOTION DETECTION SE
   [Anonymous], 2003, P 12 INT C WORLD WID, DOI DOI 10.1145/775152.775226
   Bird S., 2004, P ACL INTERACTIVE PO, P214
   Bollen J, 2011, J COMPUT SCI-NETH, V2, P1, DOI 10.1016/j.jocs.2010.12.007
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Borth D., 2013, P 21 ACM INT C MULT, P459
   Cai GY, 2015, LECT NOTES ARTIF INT, V9362, P159, DOI 10.1007/978-3-319-25207-0_14
   Chen ZC, 2014, PHYS REV SPEC TOP-AC, V17, DOI 10.1103/PhysRevSTAB.17.112803
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23
   Elshawy M, 2014, INT DES TEST SYMP, P83, DOI 10.1109/IDT.2014.7038592
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Go A., 2009, Twitter sentiment classification using distant supervision, V150, DOI DOI 10.1016/J.SEDGEO.2006.07.004
   Golder SA, 2011, SCIENCE, V333, P1878, DOI 10.1126/science.1202775
   Hao TY, 2014, J BIOMED INFORM, V52, P112, DOI 10.1016/j.jbi.2014.01.009
   Hare J.S., 2013, Proceedings of the 3rd ACM International Conference on Multimedia Retrieval, ICMR '13, P297
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Kassem II, 2017, FOODBORNE PATHOG DIS, V14, P29, DOI 10.1089/fpd.2016.2161
   Katsurai M, 2016, INT CONF ACOUST SPEE, P2837, DOI 10.1109/ICASSP.2016.7472195
   Kouloumpis E., 2011, TWITTER SENTIMENT AN, P538
   Kumar Akshi, 2012, International Journal of Intelligent Systems and Applications, V4, P1, DOI 10.5815/ijisa.2012.10.01
   Kumar A., 2012, P INT C COMPUTER SCI, P123
   Kumar A, 2019, INT J INF RETR RES, V9, P1, DOI 10.4018/IJIRR.2019010101
   Kumar A, 2019, LECT NOTE NETW SYST, V56, P375, DOI 10.1007/978-981-13-2354-6_40
   Kumar A, 2015, INT CONF CONTEMP, P285, DOI 10.1109/IC3.2015.7346694
   Kumar Akshi, 2012, International Journal of Computer Science Issues (IJCSI), V9, P372
   Kumar A, 2018, P NATL A SCI INDIA A, V88, P95, DOI 10.1007/s40010-017-0369-2
   Li B, 2012, P 20 ACM INT C MULT, P1365
   Lu Xin, 2012, Proc ACM Int Conf Multimed, V2012, P229, DOI 10.1145/2393347.2393384
   Marchesotti L, 2011, IEEE I CONF COMP VIS, P1784, DOI 10.1109/ICCV.2011.6126444
   Neethu M.S., 2013, 2013 Fourth International Conference on Computing, Communications and Networking Technologies (ICCCNT), P1, DOI [DOI 10.1109/ICCCNT.2013.6726818, 10.1109/ICCCNT.2013.6726818]
   Pak A, 2010, P 7 C INT LANG RES E, DOI DOI 10.17148/IJARCCE.2016.51274
   Poria S, 2016, NEUROCOMPUTING, V174, P50, DOI 10.1016/j.neucom.2015.01.095
   PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814
   Saif H., 2013, Evaluation datasets for twitter sentiment analysis: a survey and a new dataset, the sts-gold
   Saif H, 2016, INFORM PROCESS MANAG, V52, P5, DOI 10.1016/j.ipm.2015.01.005
   Sebastiani F., 2007, Evaluation, V17, P1
   Siersdorfer S., 2010, ACM MM, P715
   Soleymani M, 2017, IMAGE VISION COMPUT, V65, P3, DOI 10.1016/j.imavis.2017.08.003
   Thakur A, 2023, INT J COMMUN SYST, V36, DOI 10.1002/dac.4106
   Wang YL, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2378
   Yanulevskaya V, 2008, IEEE IMAGE PROC, P101, DOI 10.1109/ICIP.2008.4711701
   Yanulevskaya V, 2012, P 20 ACM INT C MULT, P349, DOI [10.1145/2393347.2393399, DOI 10.1145/2393347.2393399]
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1025, DOI 10.1145/2647868.2655035
   Zhao W, 2014, INT CONF PERVAS COMP, P1
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
NR 57
TC 63
Z9 70
U1 9
U2 96
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24103
EP 24119
DI 10.1007/s11042-019-7390-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900017
DA 2024-07-18
ER

PT J
AU Córdova-Esparza, DM
   Terven, JR
   Jiménez-Hernández, H
   Herrera-Navarro, A
   Vázquez-Cervantes, A
   García-Huerta, JM
AF Cordova-Esparza, Diana-Margarita
   Terven, Juan R.
   Jimenez-Hernandez, Hugo
   Herrera-Navarro, Ana
   Vazquez-Cervantes, Alberto
   Garcia-Huerta, Juan-M.
TI Low-bandwidth 3D visual telepresence system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Telepresence; Holographic display; 3D reconstruction; RGB-D cameras;
   Background subtraction
AB We present a methodology to develop a low-cost, low-bandwidth visual telepresence system using commodity depth sensors. To obtain a precise representation of the participants, we fuse together multiple views extracted using a deep background subtraction method. We build a proof-of-concept display composed of a video projector and a quadrangular pyramid made of acrylic, to demonstrate the visualization of a remote person without the need for head-mounted displays. Our system represents an attempt to democratize high-fidelity 3D telepresence using off-the-shelf components.
C1 [Cordova-Esparza, Diana-Margarita; Herrera-Navarro, Ana] UAQ, Fac Informat, Av Ciencias S-N,Campus Juriquilla, Queretaro 76230, Mexico.
   [Terven, Juan R.] AiFi Inc, 2364 Walsh Av, Santa Clara, CA 95051 USA.
   [Jimenez-Hernandez, Hugo; Vazquez-Cervantes, Alberto; Garcia-Huerta, Juan-M.] Ctr Ingn & Desarrollo Ind, CIDESI, Av Playa Pie Cuesta 702, Desarrollo San Pablo 76130, Queretaro, Mexico.
RP Córdova-Esparza, DM (corresponding author), UAQ, Fac Informat, Av Ciencias S-N,Campus Juriquilla, Queretaro 76230, Mexico.
EM diana_mce@hotmail.com
RI Terven, Juan Ramon/IAN-0006-2023; Jiménez-Hernández, Hugo/E-8276-2013;
   Jiménez-Hernández, Hugo/GWC-8171-2022; Cordova, Diana/GQZ-7591-2022;
   Vazquez-Cervantes, Alberto/B-1515-2017
OI Jiménez-Hernández, Hugo/0000-0003-0827-6645; Jiménez-Hernández,
   Hugo/0000-0003-0827-6645; Cordova, Diana/0000-0002-5657-7752;
   Vazquez-Cervantes, Alberto/0000-0002-9911-4328
FU CONACYT [291113]
FX This work was supported by CONACYT through postdoctoral support number
   291113. We also want to thank CIDESI for providing the facilities and
   assistance during the development of this project.
CR [Anonymous], 2015, ARXIV151100561
   [Anonymous], 2005, Spatial Augmented Reality: Merging Real and Virtual Worlds
   [Anonymous], 2017, STAT GLOBAL BUSINESS
   [Anonymous], 2012, Computer vision: models, learning, and inference
   [Anonymous], 2017, MULTIMED TOOLS APPL
   Antonio S., 2013, Int. J. of Innovative Research in Computer and Communication Engineering, V1, P2057
   Babaee M, 2018, PATTERN RECOGN, V76, P635, DOI 10.1016/j.patcog.2017.09.040
   Beck S, 2013, IEEE T VIS COMPUT GR, V19, P616, DOI 10.1109/TVCG.2013.33
   Blanche PA, 2010, NATURE, V468, P80, DOI 10.1038/nature09521
   BROWN DC, 1971, PHOTOGRAMM ENG, V37, P855
   Códova-Esparza DM, 2017, SCI COMPUT PROGRAM, V143, P1, DOI 10.1016/j.scico.2016.11.004
   Dalvi AshwiniA., 2015, Proceedings of the 2015 International Conference on Advanced Research in Computer Science Engineering Technology (ICARCSET 2015), page, P18
   Dreshaj E, 2015, THESIS
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Gohane MST, 2014, 3D HOLOGRAPH PROJECT
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   Lee H, 2017, P IEEE VIRT REAL ANN, P349, DOI 10.1109/VR.2017.7892320
   Lee H, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P295, DOI 10.1145/2993369.2996312
   Levenberg K., 1944, Quarterly of Applied Mathematics, V2, P164, DOI [10.1090/QAM/10666, DOI 10.1090/QAM/10666]
   Lu XZ, 2015, IEEE INT SYM MULTIM, P453, DOI 10.1109/ISM.2015.108
   Maimone A., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P137, DOI 10.1109/ISMAR.2011.6092379
   Maimone A, 2013, P IEEE VIRT REAL ANN, P23, DOI 10.1109/VR.2013.6549352
   Maimone Andrew, 2012, P 3DTV C TRUE VIS CA, P1
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   Mekuria R., 2016, P MM 16 P 24 ACM INT, P1222, DOI [10.1145/2964284.2973806, DOI 10.1145/2964284.2973806]
   Noor AK, 2015, ADV ENG SOFTW, V81, P1, DOI 10.1016/j.advengsoft.2014.10.004
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Pejsa T, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1716, DOI 10.1145/2818048.2819965
   Sajid H, 2015, IEEE IMAGE PROC, P4530, DOI 10.1109/ICIP.2015.7351664
   Schwarz S, 2019, IEEE J EM SEL TOP C, V9, P133, DOI 10.1109/JETCAS.2018.2885981
   Sedky M, 2010, IMAGE PROCESSING OBJ
   St-Charles PL, 2015, IEEE WINT CONF APPL, P990, DOI 10.1109/WACV.2015.137
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Terven JR, 2016, SCI COMPUT PROGRAM, V130, P97, DOI 10.1016/j.scico.2016.05.009
   Tiro D, 2015, 2015 4TH MEDITERRANEAN CONFERENCE ON EMBEDDED COMPUTING (MECO), P25, DOI 10.1109/MECO.2015.7181907
   Towles H, 2002, INT WORKSH IMM TEL
   Varadarajan S, 2015, PATTERN RECOGN, V48, P3488, DOI 10.1016/j.patcog.2015.04.016
   Yoo H, 2014, INT MED ARTS P
NR 40
TC 4
Z9 4
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21273
EP 21290
DI 10.1007/s11042-019-7464-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400033
DA 2024-07-18
ER

PT J
AU Huang, JL
   Zhou, WG
   Tian, Q
   Li, HQ
AF Huang, Jianglei
   Zhou, Wengang
   Tian, Qi
   Li, Houqiang
TI Exploiting weak mask representation with convolutional neural networks
   for accurate object tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Deep learning; Mask representation; Data augmentation;
   Bounding box approximation
AB Recent years have witnessed the popularity of Convolutional Neural Networks (CNN) in a variety of computer vision tasks, including video object tracking. Existing object tracking methods with CNN employ either a scalar score or a confidence map as CNN's output, which suffer the infeasibility of estimating the object's accurate scale and rotation angle. Specifically, as with other traditional methods, they assume the targets' scale aspect ratio and rotation angle are fixed. To address the limitation, we propose to take a binary mask as the output of CNN for tracking. To this end, we adapt a semantic segmentation model by online fine-tuning with augmented samples in the initial frame to uncover the target in the following frames. During the generation of training samples, we employ a Crop and Paste method to better utilize context information, add a random value to lightness component to mimic the illumination change, and take a Gaussian filtering approach to mimic the blur. During the tracking, due to the limitation of CNN's receptive field size and spatial resolution, the network may fail to identify the target if the estimated bounding box is considerably incorrect. Therefore we propose a bounding box approximation method by considering temporal consistency. Excluding the initial training cost, our tracker runs at 41 FPS on a single GeForce 1080Ti GPU. Evaluated on benchmarks including OTB-2015, VOT-2016 and TempleColor, it achieves comparable results with non real-time top trackers and state-of-the-art performance among those real-time ones.
C1 [Huang, Jianglei; Zhou, Wengang; Li, Houqiang] Univ Sci & Technol China, EEIS Dept, CAS Key Lab Technol GIPAS, Hefei, Anhui, Peoples R China.
   [Tian, Qi] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX USA.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; University of Texas System; University of Texas at San
   Antonio (UTSA)
RP Zhou, WG; Li, HQ (corresponding author), Univ Sci & Technol China, EEIS Dept, CAS Key Lab Technol GIPAS, Hefei, Anhui, Peoples R China.
EM hjl777@mail.ustc.edu.cn; zhwg@ustc.edu.cn; qi.tian@utsa.edu;
   lihq@ustc.edu.cn
RI Li, Houqiang Li/B-6259-2013
FU NSFC [61822208, 61632019]; Fundamental Research Funds for the Central
   Universities; Young Elite Scientists Sponsorship Program by the CAST
   [2016QNRC001]; Youth Innovation Promotion Association CAS [2018497]
FX This work was supported in part by NSFC under Contract 61822208 and
   Contract 61632019, in part by the Fundamental Research Funds for the
   Central Universities, in part by the Young Elite Scientists Sponsorship
   Program by the CAST under Grant 2016QNRC001, and in part by the Youth
   Innovation Promotion Association CAS under Grant 2018497.
CR Abadi Martin, 2016, TENSORFLOW LARGE SCA, V16, P265
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, CVPR
   [Anonymous], 2017, ICLR
   [Anonymous], 2017, ICCV
   [Anonymous], 2017, ICCV
   [Anonymous], 2017, CVPR
   [Anonymous], 2017, ICCV
   [Anonymous], ICCV
   [Anonymous], 2017, CVPR
   [Anonymous], 2017, CVPR
   [Anonymous], 2014, PROC IEEE C COMPUTER, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]
   [Anonymous], 2016, CVPR
   [Anonymous], 2017, CVPR
   [Anonymous], 2017, CVPR
   [Anonymous], 2017, CVPR
   [Anonymous], 2005, BMVC
   [Anonymous], ARXIV150104587
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chen L.C., 2016, ARXIV160600915
   Chen L.-C., 2017, IEEE C COMP VIS PATT
   Danelljan M, 2016, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2016.159
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Khoreva Anna, 2017, ARXIV170309554
   Kristan M, 2016, LECT NOTES COMPUT SC, V9914, P777, DOI 10.1007/978-3-319-48881-3_54
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li Y, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2222
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Perazzi Federico, 2017, CVPR
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Son J, 2015, IEEE I CONF COMP VIS, P3056, DOI 10.1109/ICCV.2015.350
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xuanhan Wang, 2017, IEEE Signal Processing Letters, V24, P510, DOI 10.1109/LSP.2016.2611485
   Yeo D, 2017, PROC CVPR IEEE, P511, DOI 10.1109/CVPR.2017.62
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang YD, 2018, J COMPUT SCI-NETH, V28, P1, DOI 10.1016/j.jocs.2018.07.003
   Zhang YD, 2018, J COMPUT SCI-NETH, V27, P57, DOI 10.1016/j.jocs.2018.05.005
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
NR 54
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 20961
EP 20985
DI 10.1007/s11042-019-7219-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400019
DA 2024-07-18
ER

PT J
AU Javaran, TA
   Hassanpour, H
   Abolghasemi, V
AF Javaran, Taiebeh Askari
   Hassanpour, Hamid
   Abolghasemi, Vahid
TI Blind motion image deblurring using an effective blur kernel prior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind image deblurring; Image prior; Salient edges; Image
   reconstruction; Kernel estimation
ID RECOVERY
AB Blind image deblurring, i.e., reconstructing a sharp version of a blurred image, is generally an ill-posed problem, as both the blur kernel and the sharp image are unknown. To solve such problem, one must use effective image and blur kernel priors. In this paper, a blind image deblurring method is proposed, which uses an effective image prior based on both the first and second order gradients of the image. This prior causes to properly reconstruct salient edges which provide reliable edge information for kernel estimation in the intermediate latent image. This prior along with a hyper-Laplacian kernel prior can be used to solve the optimization problem in the form of maximum-a posteriori-problem, and hence obtaine the blur kernel with a high accuracy. The efficiency of the proposed method is demonstrated by performing several quantitative and qualitative comparisons with the state-of-the-art methods, on both a benchmark image dataset and real-world motion blurred images.
C1 [Javaran, Taiebeh Askari; Hassanpour, Hamid] Shahrood Univ Technol, Fac Comp Engn & Informat Technol, Image Proc & Data Min IPDM Res Lab, Shahrood, Iran.
   [Javaran, Taiebeh Askari] Higher Educ Complex Bam, Fac Math & Comp, Comp Sci Dept, Bam, Iran.
   [Abolghasemi, Vahid] Shahrood Univ Technol, Fac Elect Engn & Robot, Shahrood, Iran.
C3 Shahrood University of Technology; Shahrood University of Technology
RP Javaran, TA (corresponding author), Shahrood Univ Technol, Fac Comp Engn & Informat Technol, Image Proc & Data Min IPDM Res Lab, Shahrood, Iran.; Javaran, TA (corresponding author), Higher Educ Complex Bam, Fac Math & Comp, Comp Sci Dept, Bam, Iran.
EM t.askari@shahroodut.ac.ir
RI Abolghasemi, Vahid/AAC-8242-2020; Hassanpour, Hamid/AAL-7271-2020
OI Hassanpour, Hamid/0000-0002-5513-9822; Abolghasemi,
   Vahid/0000-0002-2151-5180
CR [Anonymous], 2010, 2 PHASE KERNEL ESTIM
   [Anonymous], 2014, P IPC APEX EXPO C SA
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Cho TS, 2011, PROC CVPR IEEE, P241, DOI 10.1109/CVPR.2011.5995479
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Fortunato HE, 2014, VISUAL COMPUT, V30, P661, DOI 10.1007/s00371-014-0966-x
   GEMAN D, 1995, IEEE T IMAGE PROCESS, V4, P932, DOI 10.1109/83.392335
   GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331
   Javaran TA, 2017, MACH VISION APPL, V28, P431, DOI 10.1007/s00138-017-0824-8
   Javaran TA, 2016, SIGNAL PROCESS-IMAGE, V47, P218, DOI 10.1016/j.image.2016.06.009
   Joshi N, 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587834
   Joshi N, 2009, PROC CVPR IEEE, P1550, DOI 10.1109/CVPRW.2009.5206802
   Krishnan D., 2009, P ADV NEURAL INFORM, V22, P1033
   Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521
   Levin A, 2011, IEEE T PATTERN ANAL, V33, P2354, DOI 10.1109/TPAMI.2011.148
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Levin Anat., 2007, DECONVOLUTION USING
   Liu QH, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.5.053013
   Moghaddam B, 2007, IEEE I CONF COMP VIS, P2073, DOI 10.1109/cvpr.2007.383092
   OSHER S, 1990, SIAM J NUMER ANAL, V27, P919, DOI 10.1137/0727053
   Pan J, 2013, SIGNAL PROCESS-IMAGE, V20, P841
   Pan JS, 2013, SIGNAL PROCESS-IMAGE, V28, P1156, DOI 10.1016/j.image.2013.05.001
   Roth S, 2005, PROC CVPR IEEE, P860
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Shao WZ, 2015, J VIS COMMUN IMAGE R, V33, P42, DOI 10.1016/j.jvcir.2015.08.017
   Sun LX, 2013, PART FIBRE TOXICOL, V10, DOI 10.1186/1743-8977-10-43
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Xiong NX, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010174
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
NR 29
TC 9
Z9 10
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22555
EP 22574
DI 10.1007/s11042-019-7402-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400017
DA 2024-07-18
ER

PT J
AU Li, GF
   Zhu, PJ
   Cao, N
   Wu, M
   Chen, ZY
   Cao, GS
   Li, HJ
   Gong, CJ
AF Li, Guofu
   Zhu, Pengjia
   Cao, Ning
   Wu, Mei
   Chen, Zhiyi
   Cao, Guangsheng
   Li, Hongjun
   Gong, Chenjing
TI Improving the system log analysis with language model and
   semi-supervised classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Log analysis; Language model; Machine learning
AB Mining the vast amount of server-side logging data is an essential step to boost the business intelligence, as well as to facilitate the system maintenance for multimedia or IoT oriented services. Considering the vast volume of the data repository, designers of these logging-data analysis systems need to carefully balance the speed of the processing and the accuracy of the message classification. Conventional keyword-based log data monitoring and classification is sufficiently fast, but does not scale well in complex systems, especially when the target system is contributed by a large group of developers, each may differ in the way to encode the logging messages, and often carrying misleading labels. Conversely, many of the sophisticated approaches may suffer from their considerable time consumption, such that delayed processing jobs may begin to accumulate, and can hardly support the timely decision requirements. Meanwhile, we also suggest that the design of a large scale online log analysis should follow a principle that requires the least prior knowledge, in which unsupervised or semi-supervised solution is preferred. In this paper, we propose a two-stage machine learning based method, in which the system logs are regarded as the output of a quasi-natural language, pre-filtered by a perplexity score threshold, and then undergo a fine-grained classification procedure. Empirical studies on our web-services show that our method has obvious advantage in terms of processing speed and classification accuracy.
C1 [Li, Guofu; Chen, Zhiyi] Univ Shanghai Sci & Technol, Coll Commun & Art Design, Shanghai, Peoples R China.
   [Li, Guofu] Univ Coll Dublin, Comp Sci & Informat, Dublin, Ireland.
   [Zhu, Pengjia] State St Corp, Boston, MA USA.
   [Cao, Ning] Sanming Univ, Coll Informat Engn, Sanming, Peoples R China.
   [Wu, Mei] Wuhan Inst Technol, Sch Comp Sci & Engn, Wuhan, Hubei, Peoples R China.
   [Cao, Guangsheng; Li, Hongjun; Gong, Chenjing] Qingdao Binhai Univ, Coll Informat Engn, Qingdao, Shandong, Peoples R China.
C3 University of Shanghai for Science & Technology; University College
   Dublin; Sanming University; Wuhan Institute of Technology
RP Cao, N (corresponding author), Sanming Univ, Coll Informat Engn, Sanming, Peoples R China.
EM li.guofu.l@gmail.com; zhupengjia@gmail.com; ning.cao2008@hotmail.com;
   wumei0604@hotmail.com; iamedithchen@gmail.com; 52605560@qq.com;
   911845094@qq.com; 821670587@qq.com
RI Cao, Ning/P-6652-2017; Li, guofu/JJC-4546-2023
FU Shanghai University Youth Teacher Training Funding Scheme [ZZslg16054];
   National Social Science Foundation [16BXW031]; Grant of Shandong
   Province Vocational Education Educational Reform Research Project "Study
   on Vocational Colleges" Professional Building Service Regional Upgrade
   Industries" [2017209]
FX This research is supported by Shanghai University Youth Teacher Training
   Funding Scheme (ZZslg16054), National Social Science Foundation
   (16BXW031), Grant of Shandong Province Vocational Education Educational
   Reform Research Project "Study on Vocational Colleges" Professional
   Building Service Regional Upgrade Industries" (2017209).
CR [Anonymous], 2014, P 9 INT C FUTURE INT
   [Anonymous], 2013, P 29 ANN COMP SEC AP, DOI DOI 10.1145/2523649.2523670
   [Anonymous], 1985, CALIFORNIA U SAN DIE
   Añorga J, 2018, MULTIMED TOOLS APPL, V77, P7977, DOI 10.1007/s11042-017-4695-9
   Bhuiyan MZA, 2017, IEEE T DEPEND SECURE, V14, P363, DOI 10.1109/TDSC.2015.2469655
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Charniak E., 1996, Statistical language learning (language, speech, and communication), V1st
   Cheng RZ, 2018, CLIN BIOMECH, V55, P1, DOI 10.1016/j.clinbiomech.2018.03.023
   Datta D, 2017, MULTIMED TOOLS APPL, V76, P22871, DOI 10.1007/s11042-016-4262-9
   Du M, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1285, DOI 10.1145/3133956.3134015
   Elayeb B, 2018, MULTIMED TOOLS APPL, V77, P2423, DOI 10.1007/s11042-017-4398-2
   He P, 2017, SOFT COMPUT, V21, P5413, DOI 10.1007/s00500-016-2130-1
   He P, 2016, SOFT COMPUT, V20, P3537, DOI 10.1007/s00500-015-1710-9
   Kaur J, 2017, CMC-COMPUT MATER CON, V53, P23
   Liu Q, 2017, J COMPUT SCI TECH-CH, V32, P1231, DOI 10.1007/s11390-017-1797-9
   Liu Y, 2018, SOFT COMPUT, V22, P2257, DOI 10.1007/s00500-017-2487-9
   Ponte JM, 1998, P 21 ANN INT ACM SIG, P275, DOI DOI 10.1145/290941.291008
   Rehurek R., 2010, P LREC 2010 WORKSH N, P45, DOI DOI 10.13140/2.1.2393.1847
   Salvetti F., 2006, P HUMAN LANGUAGE TEC, P137
   Shen J, 2018, J NETW COMPUT APPL, V106, P117, DOI 10.1016/j.jnca.2018.01.003
   Silverstein C., 1999, SIGIR Forum, V33, P6, DOI 10.1145/331403.331405
   Sylaiou S, 2017, INT J ARTS TECHNOL, V10, P58, DOI 10.1504/IJART.2017.10004738
   Veale T, 2017, INT C DISTR AMB PERV, P696
   Venkitasubramanian AN, 2017, MULTIMED TOOLS APPL, V76, P22599, DOI 10.1007/s11042-017-4732-8
   Xia ZH, 2017, INFORM SCIENCES, V387, P195, DOI 10.1016/j.ins.2016.12.030
   Xia ZH, 2018, IEEE T CLOUD COMPUT, V6, P276, DOI 10.1109/TCC.2015.2491933
   Xu W, 2009, SOSP'09: PROCEEDINGS OF THE TWENTY-SECOND ACM SIGOPS SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P117
   Yang WY, 2017, J NETW COMPUT APPL, V86, P59, DOI 10.1016/j.jnca.2016.10.002
   Yuan D, 2010, ASPLOS XV: FIFTEENTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P143
NR 29
TC 1
Z9 1
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21521
EP 21535
DI 10.1007/s11042-018-7020-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400044
DA 2024-07-18
ER

PT J
AU Tsai, MJ
   Hsieh, CY
AF Tsai, Min-Jen
   Hsieh, Chin-Yu
TI The visual color QR code algorithm (DWT-QR) based on wavelet transform
   and human vision system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QR codes; Wavelet; HVS; CSF; NVF
ID IMAGE QUALITY ASSESSMENT; VISIBILITY
AB A novel visual Quick Response (QR) code algorithm based on Wavelet transform and Human Visual System (HVS) approach is presented in this study and named DWT-QR. Unlike other QR codes are generally embedded in the spatial domain, the composite coefficients using global and local characteristics of the host image are considered in the discrete wavelet transform (DWT) domain for the visual QR codes. In order to get the best perceptual embedding capability of visual QR codes, the collaboration of the perceptual model of contrast-sensitive function (CSF) with the noise reduction of the visibility thresholds for HVS in DWT domain, achieves the goal of fine tuning of the perceptual weights according to the basis function amplitudes for the best quality of perceptual visibility. In addition, the computation of Noise Visibility Function (NVF) characterizes the local image properties to determine the optimal QR code strength during the QR codes embedding stage. After the detection pattern embedded for the visual QR codes, different distortion attacks have been performed for the proposed method. The experimental results demonstrate that the proposed DWT-QR approach outperforms the known techniques and not only improves the visual quality of the images but also the robustness against various attacks.
C1 [Tsai, Min-Jen; Hsieh, Chin-Yu] Natl Chiao Tung Univ, Inst Informat Management, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Tsai, MJ (corresponding author), Natl Chiao Tung Univ, Inst Informat Management, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
EM mjtsai@cc.nctu.edu.tw
CR Armstrong P., 2018, FORBES
   Beegan AP, 2002, PROCEEDINGS OF THE 2002 IEEE 10TH DIGITAL SIGNAL PROCESSING WORKSHOP & 2ND SIGNAL PROCESSING EDUCATION WORKSHOP, P88, DOI 10.1109/DSPWS.2002.1231082
   Bekkat N, 2004, J ELECTRON IMAGING, V13, P341, DOI 10.1117/1.1666872
   Braudaway GW, 1996, P SOC PHOTO-OPT INS, V2659, P126, DOI 10.1117/12.235469
   Brooks AC, 2008, IEEE T IMAGE PROCESS, V17, P1261, DOI 10.1109/TIP.2008.926161
   Chang JH, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618508
   Chu HK, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508408
   Cox R, 2015, QART CODER
   Duda J, EMBEDDING GRAY SCALE
   Garateguy GJ, 2014, IEEE T IMAGE PROCESS, V23, P2842, DOI 10.1109/TIP.2014.2321501
   Hu YJ, 2001, ELECTRON LETT, V37, P1219, DOI 10.1049/el:20010838
   Huang BB, 2006, IEEE MULTIMEDIA, V13, P60, DOI 10.1109/MMUL.2006.23
   Huang CH, 2004, IEEE T MULTIMEDIA, V6, P16, DOI 10.1109/TMM.2003.819579
   Kyprianidis J. E., 2008, P EG UK THEOR PRACT, P51
   Levicky D, 2004, RADIOENGINEERING, V13, P38
   Lin SS, 2015, IEEE T MULTIMEDIA, V17, P1515, DOI 10.1109/TMM.2015.2437711
   MANNOS JL, 1974, IEEE T INFORM THEORY, V20, P525, DOI 10.1109/TIT.1974.1055250
   Peled U, 2012, VISUALEAD
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Teo PC, 1994, P SOC PHOTO-OPT INS, V2179, P27
   Tong Simon., 2001, Journal of Machine Learning Research, P45
   Tsai M, 2018, DEEP LEARNING PRINTE, DOI [10.1016/j.image.2018.09.006, DOI 10.1016/J.IMAGE.2018.09.006]
   Tsai MJ, 2009, J VIS COMMUN IMAGE R, V20, P323, DOI 10.1016/j.jvcir.2009.03.011
   VILLASENOR JD, 1995, IEEE T IMAGE PROCESS, V4, P1053, DOI 10.1109/83.403412
   Voloshynovskiy Sviatoslav., 1999, Third International Workshop on Information Hiding, P211
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2005, Proceedings of the 12th IEEE International Conference on Image Processing III, P1160
   Watson AB, 1997, IEEE T IMAGE PROCESS, V6, P1164, DOI 10.1109/83.605413
   WATSON AB, 1993, P SOC PHOTO-OPT INS, V1913, P202, DOI 10.1117/12.152694
   Watson AB, 1998, P SOC PHOTO-OPT INS, V3299, P139, DOI 10.1117/12.320105
   Winter M., 2011, Scan Me: Everybody's Guide to the Magical World of QR Codes
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 32
TC 5
Z9 5
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21423
EP 21454
DI 10.1007/s11042-019-7308-y
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400041
DA 2024-07-18
ER

PT J
AU Geetha, P
   Jayanthi, VS
   Jayanthi, AN
AF Geetha, P.
   Jayanthi, V. S.
   Jayanthi, A. N.
TI Multiple share creation based visual cryptographic scheme using
   diffusion method with a combination of chaotic maps for multimedia
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Visual cryptography; Peak signal noise ratio; Mean square
   error; Correlation coefficient; Logistic map; Diffusion; encryption and
   decryption
ID IMAGE ENCRYPTION; ROBUST
AB In the modern years, multimedia security has become a prime agenda for secure transmission over unsecured channels due to the increase in digitalization of media. Cryptography is one of the techniques, which can be used for security of exchanged data. The visual cryptographic scheme generates numerous unreasonable shares of the image with specific information. The secret information hidden in the image can be retrieved by accumulating all the shares. The basic idea behind this cryptographic scheme is the encryption of image which hides the secret into m several image shares. By this process, it turns to be complex for the hackers to retrieve the original data of the image. Furthermore, to increase the confidentiality and privacy of the original image, there is in demand to make use of the efficient encryption algorithm. According to this, a new image encryption and decryption is developed using diffusion method with a combination of chaotic maps. Overall, the proposed visual cryptographic method is divided into three phases namely, i) Separation of color bands, ii) Generation of several shares and iii) Encryption & Decryption. Firstly, the color image is divided into three bands (R, G and B) and then various shares of the image are generated based on the pixel measures. After that, the encryption and decryption are done by using diffusion process associated with chaotic map. Experimental results of various analysis and computer simulation confirm that the new algorithm offers high security and is suitable for practical image encryption.
C1 [Geetha, P.] Hindusthan Coll Engn & Technol, Elect & Commun Engn Dept, Coimbatore, Tamil Nadu, India.
   [Jayanthi, V. S.] Rajagiri Sch Engn & Technol, Elect & Commun Engn Dept, Cochin, Kerala, India.
   [Jayanthi, A. N.] Sri Ramakrishna Inst Technol, Elect & Commun Engn Dept, Coimbatore, Tamil Nadu, India.
C3 Rajagiri School of Engineering & Technology
RP Geetha, P (corresponding author), Hindusthan Coll Engn & Technol, Elect & Commun Engn Dept, Coimbatore, Tamil Nadu, India.
EM pgeethaphd@gmail.com
RI N, J/JOZ-6459-2023; A N, Jayanthi/ADU-3959-2022
OI A N, Jayanthi/0000-0002-6524-4941
CR Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Bal SN, 2018, J KING SAUD U COMPUT
   Barik RC, 2017, ADV INTELL SYST, V556, P449, DOI 10.1007/978-981-10-3874-7_42
   Chang CC, 2000, SEVENTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED SYSTEMS, PROCEEDINGS, P21, DOI 10.1109/ICPADS.2000.857679
   Chavan PV, 2012, INT C ENG
   Chen L, 2006, J OPT COMMUN, V14, P552
   Chen LF, 2009, OPT COMMUN, V282, P3433, DOI 10.1016/j.optcom.2009.05.044
   Dhiman K, 2018, COMPUT ELECTR ENG, V70, P647, DOI 10.1016/j.compeleceng.2017.09.017
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Fang W.-P., 2006, Pattern Recognition and Image Analysis, V16, P632, DOI 10.1134/S1054661806040080
   Geetha P, 2018, COMPUT SECUR, V78, P301, DOI 10.1016/j.cose.2018.07.009
   Hamza R, 2017, J INF SECUR APPL, V35, P119, DOI 10.1016/j.jisa.2017.06.005
   Hou YC, 2014, IEEE T CIRC SYST VID, V24, P733, DOI 10.1109/TCSVT.2013.2280097
   Kalai Selvi R, 2012, INT J COMPUT APPL, V48
   Kamath M, 2012, P INT C COMM INF COM, P19
   Kang Y, 2018, OPT LASER ENG, V111, P58, DOI 10.1016/j.optlaseng.2018.07.014
   Kumar S, 2018, J INF SECUR APPL, V43, P123, DOI 10.1016/j.jisa.2018.10.011
   Li MT, 2002, BMC CANCER, V2, DOI 10.1186/1471-2407-2-16
   Liu S, 2011, J INTEL SIGNAL PROCE, P7
   Liu Z, 2010, J OPTICAL LASERS, V48
   Loukhaoukha K, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/173931
   Lukac R, 2004, IEEE ELECT LETT, V40
   Mandal B, 2013, INT J ELEC POWER, V53, P123, DOI 10.1016/j.ijepes.2013.04.011
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mohanty M, 2014, AVOIDING WEAK PARAME
   Naor Moni., 1995, Visual cryptography, P1
   Nautiyal I., 2014, INT J ADV RES COMPUT, V4, P620
   Padma B., 2010, (IJCSE) Int. J. Comput. Sci. Eng, V2, P1904
   Pandey LN, 2013, J ADV RES COMPUT SCI, V1, P62
   Patidar V, 2011, OPT COMMUN, V284, P4331, DOI 10.1016/j.optcom.2011.05.028
   Popescu C, 2011, INFORMATICA-LITHUAN, V22, P395
   Rijmen V, 1996, EUROCRYPTO 96
   Roy PK, 2014, INT J ELEC POWER, V57, P392, DOI 10.1016/j.ijepes.2013.12.006
   Shao ZH, 2016, SIGNAL PROCESS-IMAGE, V48, P12, DOI 10.1016/j.image.2016.09.001
   Singh KM, 2018, OPTIK, V168, P370, DOI 10.1016/j.ijleo.2018.04.068
   Singh P, 2017, N N THRESHOLD NONEXP
   Soni A., 2012, INT J ADV RES COMPUT, V1, P137
   Srinivas M, 1994, COMPUTER LONG BEACH, V27
   Sujatha K, 2018, MULTIMED TOOLS APPL, V77, P1735, DOI 10.1007/s11042-016-4312-3
   Sundararaj V., 2016, INT J INTELLIGENT EN, V9, P117, DOI DOI 10.22266/ijies2016.0930.12
   Sundararaj V, 2019, WIRELESS PERS COMMUN, V104, P173, DOI 10.1007/s11277-018-6014-9
   Sundararaj V, 2018, COMPUT SECUR, V77, P277, DOI 10.1016/j.cose.2018.04.009
   Tao R, 2010, IEEE T INF FOREN SEC, V5, P734, DOI 10.1109/TIFS.2010.2068289
   Tedmori S, 2014, INFORM SCIENCES, V269, P21, DOI 10.1016/j.ins.2014.02.004
   Vinod Kumar Y, 2012, INT J COMPUT TECHNOL, V3, P298
   Wang S, IEEE T MULTIMEDIA, V18, P219
   Wu X, 2013, P 1 ACM WORKSH INF H
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   You XG, 2014, IEEE T CIRC SYST VID, V24, P1265, DOI 10.1109/TCSVT.2014.2306031
   Youmaran R, 2006, 2006 23RD BIENNIAL SYMPOSIUM ON COMMUNICATIONS, P340, DOI 10.1109/BSC.2006.1644637
   Zhu ZQ, 2015, PATTERN RECOGN, V48, P2592, DOI 10.1016/j.patcog.2015.01.001
NR 52
TC 7
Z9 7
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18503
EP 18530
DI 10.1007/s11042-019-7163-x
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200052
DA 2024-07-18
ER

PT J
AU Gupta, D
   Bag, S
AF Gupta, Deepika
   Bag, Soumen
TI Handwritten multilingual word segmentation using polygonal approximation
   of digital curves for Indian languages
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Character segmentation; Deep learning; Handwritten; Indian languages;
   Multilingual; OCR; Script independent
ID CHARACTER-RECOGNITION; BANGLA; ALGORITHM
AB Multilingual Optical Character Recognition (OCR) is difficult to develop as different languages exhibit different writing and structural characteristics and it is very difficult to generalize their segmentation process. Character segmentation plays an important role in developing OCR for handwritten languages. The exactness of character segmentation is the integral factor of OCR. In this paper, we exploit this limitation and propose a approach based on the polygonal approximation of the word, which works on more than one Indian languages. This work depicts the novel approach for script independent character segmentation of handwritten text utilizing basic structural properties of the languages. Digitally straight line segments (DSS) of the word is obtained by applying Polygonal approximation to the word. The segmentation of character is language independent and works considerably with skew words as well. Experiments are carried out with four popular Indian languages, Hindi, Marathi, Punjabi, and Bangla. The average success rate for character segmentation of four languages is 90.07% which is satisfactory compared with other existing methods. We use shadow and cumulative stretch feature set with random forest, support vector machine (SVM), multi-layer perceptron (MLP), and convolutional neural network (CNN) classifiers for character recognition. On experimentation, it is observed that our proposed method provided good accuracy for character segmentation and recognition.
C1 [Gupta, Deepika; Bag, Soumen] Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad 826004, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Gupta, D (corresponding author), Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad 826004, Bihar, India.
EM deepika.guptaa19@gmail.com; bagsoumen@gmail.com
CR [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2010, INT J COMPUT APPL
   [Anonymous], ARXIV150105472
   [Anonymous], INT C COGN REC
   [Anonymous], 2010, J COMPUT
   Arefin N, 2017, IEEE REG 10 HUMANIT, P678, DOI 10.1109/R10-HTC.2017.8289049
   Arya D, 2011, JOINT WORKSH MULT OC, V9
   Bag Soumen, 2015, Combinatorial Image Analysis. 17th International Workshop, IWCIA 2015. Proceedings, P247, DOI 10.1007/978-3-319-26145-4_18
   Bag S., 2011, Proceedings of the 2011 Third National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG 2011), P21, DOI 10.1109/NCVPRIPG.2011.12
   Bag S, 2018, P INT C REC ADV, P1
   Bag S, 2013, SADHANA-ACAD P ENG S, V38, P133, DOI 10.1007/s12046-013-0121-9
   Bansal V, 2002, PATTERN RECOGN, V35, P875, DOI 10.1016/S0031-3203(01)00081-4
   Basu S, 2007, ICCTA 2007: INTERNATIONAL CONFERENCE ON COMPUTING: THEORY AND APPLICATIONS, PROCEEDINGS, P427
   Bhattad AJ, 2015, IEEE INT ADV COMPUT, P676, DOI 10.1109/IADCC.2015.7154792
   Bhowmick P, 2007, IEEE T PATTERN ANAL, V29, P1590, DOI 10.1109/TPAMI.2007.1082
   Bishnu A., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P402, DOI 10.1109/ICDAR.1999.791809
   Bunke H, 2003, PROC INT CONF DOC, P448
   Casey R.G., 1995, DOC AN REC 1995 P 3, V2, P1028
   Chaudhuri BB, 1997, PROC INT CONF DOC, P1011, DOI 10.1109/ICDAR.1997.620662
   Dershowitz N, 2014, LECT NOTES COMPUT SC, V8001, P584
   Garain U, 2002, IEEE T SYST MAN CY C, V32, P449, DOI 10.1109/TSMCC.2002.807272
   HAVECKER ER, 2004, COMPUT ENG, V5, P225
   Jawahar CV, 2003, PROC INT CONF DOC, P408
   Jayadevan R, 2011, IEEE T SYST MAN CY C, V41, P782, DOI 10.1109/TSMCC.2010.2095841
   Khorsheed MS, 2002, PATTERN ANAL APPL, V5, P31, DOI 10.1007/s100440200004
   Lehal GS, 2009, ADV PATTERN RECOGNIT, P43, DOI 10.1007/978-1-84800-330-9_3
   Lehal GS, 2000, INT C PATT RECOG, P557, DOI 10.1109/ICPR.2000.906135
   Ma H., 2003, ACM T ASIAN LANG INF, V2, P193, DOI [10.1145/979872.979875, DOI 10.1145/979872.979875]
   Mangla P, 2014, IEEE INT C REL INF T, P1
   Mohanty S, 2009, ICAPR 2009: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, PROCEEDINGS, P398, DOI 10.1109/ICAPR.2009.49
   Nawab NB, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P622, DOI 10.1109/ICIEV.2012.6317506
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pal U, 2004, PATTERN RECOGN, V37, P1887, DOI 10.1016/j.patcog.2004.02.003
   Pal U, 2003, PROC INT CONF DOC, P1128
   Palakollu S., 2012, P WORLD C ENG COMPUT, V1, P24
   Patel C., 2010, 2010 International Conference on Signal and Image Processing (ICSIP 2010), P130, DOI 10.1109/ICSIP.2010.5697455
   Pramanik R, 2017, LECT NOTES COMPUT SC, V10597, P116, DOI 10.1007/978-3-319-69900-4_15
   Pramanik R, 2018, J VIS COMMUN IMAGE R, V50, P123, DOI 10.1016/j.jvcir.2017.11.016
   Ramteke Surendra, 2016, 2016 International Conference on Global Trends in Signal Processing, Information Computing and Communication (ICGTSPICC). Proceedings, P404, DOI 10.1109/ICGTSPICC.2016.7955335
   Roy A., 2005, P DIG IM COMP TECHN, P30
   Sarkar R, 2012, INT J DOC ANAL RECOG, V15, P71, DOI 10.1007/s10032-011-0148-6
   Sharma DV, 2006, INT C PATT RECOG, P1022
   Shinde AB, 2014, ANNU IEEE IND CONF
   Srivastav A, 2016, INT J COMPUT APPL, V142
   Wang SH, 2018, NEUROCOMPUTING, V272, P668, DOI 10.1016/j.neucom.2017.08.015
   ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22671, DOI 10.1007/s11042-017-5146-3
NR 47
TC 7
Z9 7
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19361
EP 19386
DI 10.1007/s11042-019-7286-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800020
DA 2024-07-18
ER

PT J
AU Kang, SQ
   Liang, YQ
   Wang, YJ
   Mikulovich, VI
AF Kang, Shouqiang
   Liang, Yaqi
   Wang, Yujing
   Mikulovich, V., I
TI Color image encryption method based on 2D-variational mode decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image; Two-dimensional variational mode decomposition;
   Hyper-chaotic system; Encryption method; Image decomposition
ID CRYPTANALYSIS; OPERATION
AB In order to reduce the correlation between adjacent pixels in a plaintext image, and to solve the small key space problem of image encryption algorithms when a low-dimension chaotic map is used, a new encryption method for color images is proposed based on two-dimensional variational mode decomposition (2D-VMD) combined with eight-dimensional (8D) hyper-chaotic systems. 2D-VMD decomposes R, G and B components of a color image respectively. The 8D hyper-chaotic system is constructed by means of variable coupling. After improving and combining the original sequences obtained by iterating the system, two groups of key sequences associated with the plain-image are obtained. One group is used to scramble each mode image obtained by 2D-VMD; the other is used to replace the pixel values of the scrambled mode images. For different mode images, different key sequences are adopted. The encrypted images whose number is equal to the number of the modes can then be obtained. The experimental results show that, compared with the existing methods, the correlation coefficients between the pixels in the spatial domain of the plain-image can be reduced by 2D-VMD, as it's more difficult to crack. In addition, the encryption method has better statistical and differential characteristics, as well as large enough key space, and better plain-image sensitivity.
C1 [Kang, Shouqiang; Liang, Yaqi; Wang, Yujing] Harbin Univ Sci & Technol, Sch Elect & Elect Engn, 52 Xuefu Rd, Harbin 150080, Heilongjiang, Peoples R China.
   [Mikulovich, V., I] Belarusian State Univ, Radiophys & Elect Dept, Minsk 220030, BELARUS.
C3 Harbin University of Science & Technology; Belarusian State University
RP Wang, YJ (corresponding author), Harbin Univ Sci & Technol, Sch Elect & Elect Engn, 52 Xuefu Rd, Harbin 150080, Heilongjiang, Peoples R China.
EM mirrorwyj@163.com
FU Natural Science Foundation of Heilongjiang Province [QC2014C075];
   University Nursing Program for Young Scholars with Creative Talents in
   Heilongjiang Province [UNPYSCT-2017091]; Program for the Top Young
   Innovative Talents of Harbin University of Science and Technology
   [201511]
FX This research is supported by The Natural Science Foundation of
   Heilongjiang Province (Grant No. QC2014C075), University Nursing Program
   for Young Scholars with Creative Talents in Heilongjiang Province (Grant
   No. UNPYSCT-2017091), and Program for the Top Young Innovative Talents
   of Harbin University of Science and Technology (Grant No. 201511).
CR [Anonymous], 2010, 80022 SP NAT I STAND
   Dragomiretskiy K, 2015, 10 INT C EMMCVPR 201
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   García-Martínez M, 2015, APPL MATH COMPUT, V270, P413, DOI 10.1016/j.amc.2015.08.037
   Gu GS, 2014, OPTIK, V125, P4700, DOI 10.1016/j.ijleo.2014.05.023
   He YT, 2016, J NINGXIA U NAT SCI, V37, P424
   Hsiao HI, 2015, SIGNAL PROCESS, V113, P169, DOI 10.1016/j.sigpro.2015.01.024
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Li CQ, 2013, NONLINEAR DYNAM, V73, P2083, DOI 10.1007/s11071-013-0924-6
   Liu Q, 2015, COMMUN NONLINEAR SCI, V20, P506, DOI 10.1016/j.cnsns.2014.06.005
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Lu J, 2013, J HARBIN U SCI TECHN, V18, P95
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Özkaynak F, 2012, OPT COMMUN, V285, P4946, DOI 10.1016/j.optcom.2012.07.106
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   Sui LS, 2013, OPT LASER ENG, V51, P1297, DOI 10.1016/j.optlaseng.2013.06.005
   Tedmori S, 2014, INFORM SCIENCES, V269, P21, DOI 10.1016/j.ins.2014.02.004
   Wang W, 2016, J SENSORS, V2016, DOI 10.1155/2016/2646205
   Wang XY, 2014, NONLINEAR DYNAM, V78, P2975, DOI 10.1007/s11071-014-1639-z
   Wang XY, 2014, NONLINEAR DYNAM, V75, P567, DOI 10.1007/s11071-013-1086-2
   Ye GD, 2014, NONLINEAR DYNAM, V75, P417, DOI 10.1007/s11071-013-1074-6
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
NR 26
TC 7
Z9 7
U1 3
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17719
EP 17738
DI 10.1007/s11042-018-7129-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200019
DA 2024-07-18
ER

PT J
AU Pellegrin, L
   Escalante, HJ
   Montes-y-Gomez, M
   Gonzalez, FA
AF Pellegrin, Luis
   Escalante, Hugo Jair
   Montes-y-Gomez, Manuel
   Gonzalez, Fabio A.
TI Exploiting label semantic relatedness for unsupervised image annotation
   with large free vocabularies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised image annotation; Label relevance; Semantic-relatedness
   estimation
ID RETRIEVAL; DOCUMENT
AB Automatic Image Annotation (AIA) is the task of assigning keywords to images, with the aim to describe their visual content. Recently, an unsupervised approach has been used to tackle this task. Unsupervised AIA (UAIA) methods use reference collections that consist of the textual documents containing images. The aim of the UAIA methods is to extract words from the reference collection to be assigned to images. In this regard, by using an unsupervised approach it is possible to include large vocabularies because any word could be extracted from the reference collection. However, having a greater diversity of words for labeling entails to deal with a larger number of wrong annotations, due to the increasing difficulty for assigning a correct relevance to the labels. With this problem in mind, this paper presents a general strategy for UAIA methods that reranks assigned labels. The proposed method exploits the semantic-relatedness information among labels in order to assign them an appropriate relevance for describing images. Experimental results in different benchmark datasets show the flexibility of our method to deal with assignments from free-vocabularies, and its effectiveness to improve the initial annotation performance for different UAIA methods. Moreover, we found that (1) when considering the semantic-relatedness information among the assigned labels, the initial ranking provided by a UAIA method is improved in most of the cases; and (2) the robustness of the proposed method to be applied on different UAIA methods, will allow extending capabilities of state-of-the-art UAIA methods.
C1 [Pellegrin, Luis] UABC, Fac Sci, Ensenada, Baja California, Mexico.
   [Escalante, Hugo Jair; Montes-y-Gomez, Manuel] INAOE, Dept Comp Sci, Cholula, Mexico.
   [Gonzalez, Fabio A.] Univ Nacl Colombia, Comp Syst & Ind Engn Dept, Bogota, Colombia.
C3 Universidad Autonoma de Baja California; Instituto Nacional de
   Astrofisica, Optica y Electronica; Universidad Nacional de Colombia
RP Pellegrin, L (corresponding author), UABC, Fac Sci, Ensenada, Baja California, Mexico.
EM luis.pellegrin@uabc.edu.mx; hugojair@inaoep.mx; mmontesg@inaoep.mx;
   fagonzalezo@unal.edu.co
RI Gonzalez, Fabio A/B-9502-2008; Escalante, Hugo Jair/AEP-0896-2022
OI Escalante, Hugo Jair/0000-0003-4603-3513; Luis Pellegrin,
   Luis/0000-0002-4898-1632
FU CONACYT [CB-2014-241306]; CONACyT [214764]
FX This work was supported by CONACYT under project grant CB-2014-241306
   (Clasificacion y recuperacion de imagenes mediante tecnicas de mineria
   de textos). First author was supported by CONACyT under scholarship No.
   214764.
CR Ahmed Z, 2016, DATABASE-OXFORD, DOI 10.1093/database/baw118
   [Anonymous], ARXIV170505102
   [Anonymous], P 18 BRIT MACH VIS C
   [Anonymous], CLEF 2013 EV LAB WOR
   [Anonymous], FLAIRS C
   [Anonymous], P 14 INT C WEB AG IN
   [Anonymous], P 23 INT FLOR ART IN
   [Anonymous], ARXIV14094627
   [Anonymous], CLEF 2013 C VAL SPAI
   [Anonymous], CLEF 2012 EV LABS WO
   [Anonymous], CLEF 2014 EV LAB WOR
   [Anonymous], CLEF 2013 EV LABS WO
   Hernández-Gracidas CA, 2013, MULTIMED TOOLS APPL, V62, P479, DOI 10.1007/s11042-011-0911-1
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Feng Yansong., 2008, P ACL 08 HLT, P272
   Grauman K., 2011, Synthesis Lectures on Artificial Intelligence and Machine Learning, V5, P1, DOI 10. 2200/S00332ED1V01Y201103AIM011
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Hanbury A, 2008, J VISUAL LANG COMPUT, V19, P617, DOI 10.1016/j.jvlc.2008.01.002
   He YF, 2016, NEUROCOMPUTING, V204, P26, DOI 10.1016/j.neucom.2015.11.102
   Hoque E, 2013, INFORM PROCESS MANAG, V49, P1122, DOI 10.1016/j.ipm.2012.12.001
   Hyung Z, 2017, INFORM PROCESS MANAG, V53, P1185, DOI 10.1016/j.ipm.2017.04.006
   Escalante HJ, 2011, COMPUT VIS IMAGE UND, V115, P787, DOI 10.1016/j.cviu.2011.02.002
   Escalante HJ, 2010, COMPUT VIS IMAGE UND, V114, P419, DOI 10.1016/j.cviu.2009.03.008
   Kherfi ML, 2004, ACM COMPUT SURV, V36, P35, DOI 10.1145/1013208.1013210
   Li HJ, 2016, MULTIMED TOOLS APPL, V75, P8939, DOI 10.1007/s11042-014-2336-0
   Li J, 2017, IEEE T IMAGE PROCESS, V26, P3113, DOI 10.1109/TIP.2017.2651379
   Llorente A, 2010, LECT NOTES COMPUT SC, V6242, P307, DOI 10.1007/978-3-642-15751-6_40
   Llorente A, 2009, LECT NOTES COMPUT SC, V5478, P570, DOI 10.1007/978-3-642-00958-7_52
   Makadia A, 2010, INT J COMPUT VISION, V90, P88, DOI 10.1007/s11263-010-0338-6
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Mithun NiluthpolChowdhury., 2016, ACM International Conference on Multimedia (ACM MM), P566
   Murray N, 2014, PROC CVPR IEEE, P2473, DOI 10.1109/CVPR.2014.317
   Ordonez V, 2016, INT J COMPUT VISION, V119, P46, DOI 10.1007/s11263-015-0840-y
   Pandey S, 2016, INFORM PROCESS MANAG, V52, P571, DOI 10.1016/j.ipm.2015.12.005
   Pellegrin Luis, 2018, Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications. 22nd Iberoamerican Congress, CIARP 2017. Proceedings: LNCS 10657, P508, DOI 10.1007/978-3-319-75193-1_61
   Pellegrin L, 2017, MULTIMED TOOLS APPL, V76, P16389, DOI 10.1007/s11042-016-3918-9
   Rahman MM, 2011, INFORM PROCESS MANAG, V47, P676, DOI 10.1016/j.ipm.2010.12.001
   Ramírez-de-la-Rosa G, 2013, LANG RESOUR EVAL, V47, P127, DOI 10.1007/s10579-012-9192-1
   Reshma IA, 2014, 2014 INTERNATIONAL CONFERENCE OF ADVANCED INFORMATICS: CONCEPT, THEORY AND APPLICATION (ICAICTA), P226, DOI 10.1109/ICAICTA.2014.7005945
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Schroff F, 2011, IEEE T PATTERN ANAL, V33, P754, DOI 10.1109/TPAMI.2010.133
   Siva P, 2013, PROC CVPR IEEE, P3238, DOI 10.1109/CVPR.2013.416
   Tian F, 2014, I C VIRTUAL REALITY, P260, DOI 10.1109/ICVRV.2014.39
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Villatoro E, 2012, NAT LANG ENG, V18, P155, DOI 10.1017/S1351324912000010
   Villegas M, 2015, LECT NOTES COMPUT SC, V9283, P444, DOI 10.1007/978-3-319-24027-5_45
   Xu HJ, 2014, INT CONF SEMANT, P177, DOI 10.1109/SKG.2014.12
   Zhang LF, 2015, PATTERN RECOGN, V48, P3102, DOI 10.1016/j.patcog.2014.12.016
   Zhibiao Wu, 1994, 32nd Annual Meeting of the Association for Computational Linguistics. Proceedings of the Conference, P133
NR 51
TC 1
Z9 1
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19641
EP 19662
DI 10.1007/s11042-019-7357-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800033
DA 2024-07-18
ER

PT J
AU Yang, CN
   Wu, SY
   Chou, YS
   Kim, C
AF Yang, Ching-Nung
   Wu, Song-Yu
   Chou, Yung-Shun
   Kim, Cheonshik
TI Enhanced stego-image quality and embedding capacity for the partial
   reversible data hiding scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Partial reversible data hiding; Hamming code; Error
   correcting; Syndrome; LSB
ID ENCRYPTED IMAGES; DIFFERENCE
AB Recently, Jana et al. proposed the partial reversible data hiding (PRDH) based on (7, 4) Hamming code, which deals with three images: the original image (OI), the cover image (CI), and the stego image (SI). The CI is obtained by slightly modifying OI. After that, one can embed secret into CI to generate SI. The so-called partial reversible feature is that we can reconstruct the CI faultlessly, which is almost the same to the OI. However, in Jana et al.'s PRDH, the authors only adjust redundant bits by using (7, 4) Hamming code with even (or odd) parity. This simple approach may modify 3 redundant bits at most in 7 least significant bit (LSBs) to obtain CI from OI, and this degrades the CI quality seriously. In this paper, we construct two schemes: the proposed PRDH (PPRDH) and the modified PRDH (MPRDH). PPRDH enhances the partial reversible property that improves the visual quality of CI. And, MPRDH enhances PPRDH to achieve the high embedding capacity. Theoretical estimations of average mean square errors for these PRDH schemes are given to demonstrate the advantage of our PRDH schemes. In addition, we also point out two inaccurate descriptions in Jana et al.'s PRDH about position of embedded secret to more simplify the procedure of embedding secret.
C1 [Yang, Ching-Nung; Wu, Song-Yu; Chou, Yung-Shun] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Shoufeng, Taiwan.
   [Kim, Cheonshik] Sejong Univ, Dept Comp Engn, Seoul, South Korea.
C3 National Dong Hwa University; Sejong University
RP Kim, C (corresponding author), Sejong Univ, Dept Comp Engn, Seoul, South Korea.
EM cnyang@gms.ndhu.edu.tw; 610621220@gms.ndhu.edu.tw;
   610521215@gms.ndhu.edu.tw; mipsan@paran.com
RI Yang, Ching-Nung/HKV-1639-2023
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) [2015R1D1A1A01059253]; Ministry of Science and Technology
   (MOST) [105-2221-E-259-015-MY2]; NRF [2016K2A9A2A05005255]
FX This work was supported by the Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by
   (2015R1D1A1A01059253), and was supported under the framework of
   international cooperation program managed by NRF (2016K2A9A2A05005255).
   Also, it was supported in part by Ministry of Science and Technology
   (MOST), under 105-2221-E-259-015-MY2.
CR Crandall R., 1998, SOME NOTES STEGANOGR
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Hwang J, 2006, LECT NOTES COMPUT SC, V4283, P348
   Jana B, 2017, MULTIMED TOOLS APPL, V76, P21691, DOI 10.1007/s11042-016-3990-1
   Kim C, 2016, MULTIMED TOOLS APPL, V75, P15651, DOI 10.1007/s11042-014-2355-x
   Kim KS, 2009, PATTERN RECOGN, V42, P3083, DOI 10.1016/j.patcog.2009.04.004
   Kuo WC, 2007, LECT NOTES ARTIF INT, V4682, P1152
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Rashid A, 2018, TECHNOLOGIES, V6, DOI 10.3390/technologies6010007
   Stanley CA, 2017, PAIRS VALUES CHI SQU
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   VARSAKI E, 2006, HOUCSTR200608GR
   Wang WQ, 2017, IET IMAGE PROCESS, V11, P1002, DOI 10.1049/iet-ipr.2017.0151
   WESTFELD A., 2001, P 4 INT WORKSH INF H, V2137, P289, DOI DOI 10.1007/3-540-45496-9_21
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Yang CN, 2017, COMPUT STAND INTER, V50, P209, DOI 10.1016/j.csi.2016.10.005
   Zhang RY, 2012, IEEE T INFORM THEORY, V58, P7272, DOI 10.1109/TIT.2012.2217072
   Zhang WM, 2007, IEEE COMMUN LETT, V11, P680, DOI 10.1109/LCOMM.2007.070438
   Zhang X, 2007, ELECTRON LETT, V43, P482, DOI 10.1049/el:20070248
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
NR 26
TC 8
Z9 8
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18595
EP 18616
DI 10.1007/s11042-019-7220-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200056
DA 2024-07-18
ER

PT J
AU Aote, SS
   Potnurwar, A
AF Aote, Shailendra S.
   Potnurwar, Archana
TI An automatic video annotation framework based on two level keyframe
   extraction mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video processing; image annotation; video annotation
AB Large increase in audio, video and digital data in the internet signifies the importance of video annotation techniques. This paper mainly deals with the development of a hybrid algorithm for automatic Video Annotation (VA). Another aim in developing the algorithm is to improve the performance and precision as well as to reduce the amount of time required to obtain the annotations. The overall process leads to the development of efficient techniques for shot detection followed by two level key frame extractions and saliency based residual approach for feature extraction. For all the stages in VA like shot detection, keyframe extraction and feature extraction, factors relating to improve the performance are addressed here. The combination of color histogram difference (CBD) and Edge change ratio (ECR) is used here; as these two are the most promising techniques in shot detection. The new idea is proposed to fine tune the keyframe extraction, which extracts keyframe in two levels. At first level, the first frame in the shot is considered as a keyframe. But to remove redundancy, it enters into second level and finds the optimal set of keyframes by using fuzzy c-means clustering technique. Colour and texture features are used for feature extraction. Here the Video annotation process is divided into two sections, training and testing. The weight vector is found in training stage. Based on this feature vector, the similarity array is calculated in testing phase which further finds corrected annotations. The proposed method is compared with OMG-SSL and MMT-MGO and results are found better on Trechvid dataset. The significance of using weight vector is also experimentally shown here.
C1 [Aote, Shailendra S.] Shri Ramdeobaba Coll Engn & Management, Dept CSE, Nagpur, Maharashtra, India.
   [Potnurwar, Archana] Priyadarshini Inst Engn & Technol, Dept IT, Nagpur, Maharashtra, India.
C3 Shri Ramdeobaba College of Engineering & Management; Rashtrasant
   Tukadoji Maharaj Nagpur University
RP Aote, SS (corresponding author), Shri Ramdeobaba Coll Engn & Management, Dept CSE, Nagpur, Maharashtra, India.
EM shailendra_aote@rediffmail.com
RI Aote, Shailendra S/ABH-9310-2020; Potnurwar, Archana/AAY-6185-2021
OI Aote, Shailendra/0000-0001-8666-0525
CR Abdollahian G., 2011, 2011 9th International Workshop on Content-Based Multimedia Indexing (CBMI), P121, DOI 10.1109/CBMI.2011.5972532
   Adjeroh D, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/859371
   Angadi S, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P271, DOI 10.1109/ICSIP.2014.49
   [Anonymous], INT C DIG IM COMP TE
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   Boreczky JS, 1996, J ELECTRON IMAGING, V5, P122, DOI 10.1117/12.238675
   Brown G, 2010, TAKING OUR PLACE: ABORIGINAL EDUCATION AND THE STORY OF THE KOORI CENTRE AT THE UNIVERSITY OF SYDNEY, P91
   Chamasemani Fereshteh Falah, 2015, Journal of Applied Sciences, V15, P256, DOI 10.3923/jas.2015.256.263
   Hong-cai F, 2010, INT C E BUS E GOV 7, DOI [10.1109/ICEE.2010.417, DOI 10.1109/ICEE.2010.417]
   Huayong Liu, 2012, 2012 9th International Conference on Fuzzy Systems and Knowledge Discovery, P1238, DOI 10.1109/FSKD.2012.6233777
   HUO Y, 2014, J INFORM COMPUTATION, V11, P391, DOI DOI 10.12733/JICS20102621
   Jialei Bi, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P512, DOI 10.1109/CISP.2011.6099941
   Kavasidis I, 2014, MULTIMED TOOLS APPL, V70, P413, DOI 10.1007/s11042-013-1419-7
   KHURANA K, 2013, INT J ADV RES COMPUT, V3, P540
   Lai JL, 2012, J VIS COMMUN IMAGE R, V23, P114, DOI 10.1016/j.jvcir.2011.08.005
   Lei YQ, 2012, IEEE T CIRC SYST VID, V22, P1332, DOI 10.1109/TCSVT.2012.2201670
   Li A, 2011, IEEE INT C CYB TECHN, P153, DOI [10.1109/CYBER.2011.6011783, DOI 10.1109/CYBER.2011.6011783]
   Li YN, 2010, IEEE T MULTIMEDIA, V12, P814, DOI 10.1109/TMM.2010.2066960
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Moxley E, 2010, IEEE T MULTIMEDIA, V12, P184, DOI 10.1109/TMM.2010.2041101
   Qi G.J., 2007, P 15 ACM INT C MULTI, P17, DOI DOI 10.1145/1291233.1291245
   Qi Guo-Jun, 2006, WORKSH SEM LEARN APP
   Rathod GI, 2013, INT J EMERGING TECHN, V2013, P155
   Sayar A, 2009, 2009 24TH INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, P12, DOI 10.1109/ISCIS.2009.5291929
   Sultan Waqas, 2016, IEEE INT C COMP VIS
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tang JH, 2009, IEEE T SYST MAN CY B, V39, P409, DOI 10.1109/TSMCB.2008.2006045
   Thakar VB, 2013, 2013 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND SIGNAL PROCESSING (ISSP), P145, DOI 10.1109/ISSP.2013.6526891
   Wang M, 2009, IEEE T MULTIMEDIA, V11, P465, DOI 10.1109/TMM.2009.2012919
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Xu CS, 2008, IEEE T MULTIMEDIA, V10, P421, DOI 10.1109/TMM.2008.917346
   Xu SX, 2012, NEUROCOMPUTING, V95, P11, DOI 10.1016/j.neucom.2011.05.041
   Xuan GJ, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND APPLICATIONS (CSA), P627, DOI 10.1109/CSA.2013.151
   Zhang ST, 2012, IEEE T SYST MAN CY B, V42, P838, DOI 10.1109/TSMCB.2011.2179533
NR 35
TC 15
Z9 15
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14465
EP 14484
DI 10.1007/s11042-018-6826-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700016
DA 2024-07-18
ER

PT J
AU Fakhar, B
   Kanan, HR
   Behrad, A
AF Fakhar, Babak
   Kanan, Hamidreza Rashidy
   Behrad, Alireza
TI Event detection in soccer videos using unsupervised learning of
   Spatio-temporal features based on pooled spatial pyramid model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic video analysis; Pooled spatial pyramid feature based sparse
   representation (PSPFSR); Locality-constrained linear coding (LLC);
   Long-short-term memory (LSTM)
ID BAYESIAN NETWORK; K-SVD; SPARSE; DICTIONARY; ANNOTATION; SYSTEM
AB Most existing researches for semantic analysis of soccer videos benefit from special approaches to bridge the semantic gap between low-level features and high-level events using a hierarchical structure. In this paper, we propose a novel data-driven model for automatic recognition of important events in soccer broadcast videos based on the analysis of spatio-temporal local features of video frames. Our presented algorithm explores the local visual content of video frames by focusing on spatial and temporal learned features in a low-dimensional transformed sparse space. The proposed algorithm, without using mid-level futures, dynamically extracts the most informative semantic concepts/features and improves the generality of the system. The dictionary learning process plays an important role in sparse coding and sparse representation-based event classification. In this paper, we present a novel dictionary learning method, which calculates several category-specific dictionaries by training the detected shots of various view categories. In order to evaluate the feasibility and effectiveness of the proposed algorithm, an extensive experimental investigation is conducted for the analysis, detection, and classification of soccer events on a large collection of video data. Experimental results indicate that our approach outperforms the state-of-the-art methods and demonstrate the effectiveness of the proposed approach.
C1 [Fakhar, Babak] Islamic Azad Univ, Qazvin Branch, Fac Comp & Informat Technol Engn, Qazvin, Iran.
   [Kanan, Hamidreza Rashidy] Shahid Rajaee Teacher Training Univ, Dept Comp Engn, Tehran, Iran.
   [Behrad, Alireza] Shahed Univ, Dept Elect Engn, Tehran, Iran.
C3 Islamic Azad University; Shahid Rajaee Teacher Training University
   (SRTTU); Shahed University
RP Kanan, HR (corresponding author), Shahid Rajaee Teacher Training Univ, Dept Comp Engn, Tehran, Iran.
EM h.rashidykanan@sru.ac.ir
RI Behrad, Alireza/F-8795-2018; Rashidy Kanan, Hamidreza/AAI-7928-2020
OI Rashidy Kanan, Hamidreza/0000-0001-8789-8658; Fakhar,
   Babak/0000-0002-4999-1058; Behrad, Alireza/0000-0002-1990-6668
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Akrivas G, 2004, IEEE T SYST MAN CY A, V34, P190, DOI 10.1109/TSMCA.2003.819498
   [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   BENGIO Y, 1994, ADV NEURAL INFORM PR, P75
   Chavan K, 2016, INDIAN J GYNECOL ONC, V14, DOI 10.1007/s40944-016-0061-5
   Cong Y, 2013, PATTERN RECOGN, V46, P1851, DOI 10.1016/j.patcog.2012.11.021
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   D'Orazio T, 2009, COMPUT VIS IMAGE UND, V113, P622, DOI 10.1016/j.cviu.2008.01.010
   D'Orazio T, 2009, IEEE T CIRC SYST VID, V19, P1804, DOI 10.1109/TCSVT.2009.2026817
   Dai WR, 2016, IEEE T IMAGE PROCESS, V25, P4580, DOI 10.1109/TIP.2016.2594490
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   F. J. I. T o p a Perronnin and m intelligence, 2008, UNIVERSAL ADAPTED VO, V30, P1243
   Fani M, 2017, IEEE ACCESS, V5, P27322, DOI 10.1109/ACCESS.2017.2769140
   Guan GL, 2013, IEEE T CIRC SYST VID, V23, P729, DOI 10.1109/TCSVT.2012.2214871
   Guan GL, 2012, IEEE INT CONF MULTI, P570, DOI 10.1109/ICMEW.2012.105
   Hagras, 2017, 2017 IEEE INT C FUZZ, P1
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hosseini MS, 2013, APPL SOFT COMPUT, V13, P846, DOI 10.1016/j.asoc.2012.10.007
   Huang CL, 2006, IEEE T MULTIMEDIA, V8, P749, DOI 10.1109/TMM.2006.876289
   Inoue N, 2012, IEEE T MULTIMEDIA, V14, P1196, DOI 10.1109/TMM.2012.2191395
   Jai-Andaloussi S, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI), P398, DOI 10.1109/CSCI.2015.59
   Jiang HH, 2016, PROC INT C TOOLS ART, P490, DOI [10.1109/ICTAI.2016.0081, 10.1109/ICTAI.2016.78]
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Kolekar MH, 2015, IEEE T BROADCAST, V61, P195, DOI 10.1109/TBC.2015.2424011
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li NN, 2015, NEUROCOMPUTING, V155, P309, DOI 10.1016/j.neucom.2014.12.064
   Liu TX, 2017, LECT NOTES COMPUT SC, V10635, P440, DOI 10.1007/978-3-319-70096-0_46
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu SY, 2014, IEEE T MULTIMEDIA, V16, P1497, DOI 10.1109/TMM.2014.2319778
   Mairal J, 2008, LECT NOTES COMPUT SC, V5304, P43, DOI 10.1007/978-3-540-88690-7_4
   Mei SH, 2015, PATTERN RECOGN, V48, P522, DOI 10.1016/j.patcog.2014.08.002
   Moon S-W, 2017, COMP SCI INF SYST FE, V4, P3
   Nagasaka A, 1992, AUTOMATIC VIDEO INDE
   Ouyang JQ, 2013, IET IMAGE PROCESS, V7, P324, DOI 10.1049/iet-ipr.2012.0495
   Pandya MAZ, 2017, C C 2017 IEEE INT C, P5
   Park JH, 2016, I C INF COMM TECH CO, P1098, DOI 10.1109/ICTC.2016.7763377
   Perin C, 2013, IEEE T VIS COMPUT GR, V19, P2506, DOI 10.1109/TVCG.2013.192
   Qian XM, 2012, MULTIMED TOOLS APPL, V60, P233, DOI 10.1007/s11042-011-0817-y
   Ramirez I., 2010, Classification and clustering via dictionary learning with structured incoherence and shared features."
   Ranzato M., 2006, ADV NEURAL INFORM PR, V19, P1137, DOI DOI 10.7551/MITPRESS/7503.003.0147
   Raventós A, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1065-9
   Roy D, 2016, PATTERN RECOGN, V59, P55, DOI 10.1016/j.patcog.2016.03.011
   Sadlier DA, 2005, IEEE T CIRC SYST VID, V15, P1225, DOI 10.1109/TCSVT.2005.854237
   Sigari MH, 2016, IMAGE VISION COMPUT, V53, P20, DOI 10.1016/j.imavis.2015.07.004
   Sivalingam R, 2011, IEEE I CONF COMP VIS, P1013, DOI 10.1109/ICCV.2011.6126346
   Tavassolipour M, 2014, IEEE T CIRC SYST VID, V24, P291, DOI 10.1109/TCSVT.2013.2243640
   Tjondronegoro DW, 2010, IEEE T SYST MAN CY A, V40, P1009, DOI 10.1109/TSMCA.2010.2046729
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang C., 2016, P 2016 ACM MULT C, P988, DOI 10.1145/2964284.2964299
   Wang C, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3115432
   Wang C, 2016, IEEE IJCNN, P1924, DOI 10.1109/IJCNN.2016.7727435
   Wang C, 2016, MULTIMED TOOLS APPL, V75, P9255, DOI 10.1007/s11042-016-3380-8
   Wang C, 2015, PROC INT C TOOLS ART, P234, DOI 10.1109/ICTAI.2015.45
   Wang XH, 2017, IEEE SIGNAL PROC LET, V24, P510, DOI 10.1109/LSP.2016.2611485
   Wang ZK, 2017, IEEE T CIRC SYST VID, V27, P1104, DOI 10.1109/TCSVT.2016.2515280
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xiang T, 2008, IEEE T PATTERN ANAL, V30, P893, DOI 10.1109/TPAMI.2007.70731
   Xie Wenjuan, 2011, Journal of Electronics (China), V28, P670, DOI 10.1007/s11767-012-0765-3
   Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8
   Yang M, 2010, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2010.5652363
   Zawbaa H. M., 2011, 2011 Third World Congress on Nature and Biologically Inspired Computing (NaBIC 2011), P7, DOI 10.1109/NaBIC.2011.6089409
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
   Zhao W, 2015, Proceedings 3rd IAPR Asian Conference on Pattern Recognition ACPR 2015, P341, DOI 10.1109/ACPR.2015.7486522
   Zhao ZC, 2016, NEUROCOMPUTING, V208, P378, DOI 10.1016/j.neucom.2016.06.002
   Zhou N, 2012, PROC CVPR IEEE, P3490, DOI 10.1109/CVPR.2012.6248091
NR 69
TC 22
Z9 23
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16995
EP 17025
DI 10.1007/s11042-018-7083-1
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500057
DA 2024-07-18
ER

PT J
AU Frikha, T
   Ben Amor, N
   Diguet, JP
   Abid, M
AF Frikha, Tarek
   Ben Amor, Nader
   Diguet, Jean-Philippe
   Abid, Mohamed
TI A novel Xilinx-based architecture for 3D-graphics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Xilinx; Embedded system; Profiling; 3D application
ID OPTIMIZATION
AB Spreading the use of embedded electronic multimedia systems to a large audience has more than one requirement. In fact, it should be operating in extreme conditions: random fluctuation conditions of network transmission, the limited energy resources as well as variable users constraints. All these dynamic parameters were not considered previously in classic codesign methods. In this paper, we propose a novel architecture which combines between adaptation network, application and architectural level. Various assessments were made to validate it raging from the static reconfiguration to the dynamic one, from using monoprocessor systems to multiprocessor ones. We present also a case study on a real system using the proposed Xilinx design for a 3D application.
C1 [Frikha, Tarek; Ben Amor, Nader; Abid, Mohamed] Univ Sfax, CES Lab, Natl Engn Sch Sfax ENIS, BP 1173, Sfax 3038, Tunisia.
   [Diguet, Jean-Philippe] Univ Bretagne Sud, CNRS, LAB STICC, F-56321 Lorient, France.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS); Centre
   National de la Recherche Scientifique (CNRS)
RP Frikha, T (corresponding author), Univ Sfax, CES Lab, Natl Engn Sch Sfax ENIS, BP 1173, Sfax 3038, Tunisia.
EM tarek.frikha@gmail.com; nader.benamor@enis.rnu.tn;
   Jean-philippe.diguet@univ-ubs.fr; mohamed.abid@enis.rnu.tn
RI Diguet, Jean-Philippe/N-1728-2014; FRIKHA, Tarek/AGH-4470-2022
OI FRIKHA, Tarek/0000-0001-8402-8059; Ben Amor, Nader/0000-0002-8437-4346
CR [Anonymous], 2003, P 24 IEEE REAL TIM S
   Astarloa A, 2007, J SYST ARCHITECT, V53, P629, DOI 10.1016/j.sysarc.2007.01.011
   Banerjee S, 2005, DES AUT CON, P335
   BenAmor N, 2007, THESIS
   Bergamaschi RA, 2001, IEEE DES TEST COMPUT, V18, P32, DOI 10.1109/54.953270
   Bobda C, 2005, 2005 IEEE International Conference on Microelectronic Systems Education, Proceedings, P7, DOI 10.1109/MSE.2005.22
   Bormans J, 2003, AMBIENT INTELLIGENCE: IMPACT ON EMBEDDED SYSTEM DESIGN, P183
   Brandt S, 1998, INT WORKSH QUAL SERV, P154, DOI 10.1109/IWQOS.1998.675233
   Demigny D, 2000, 5TH INTERNATIONAL WORKSHOP ON COMPUTER ARCHITECTURES FOR MACHINE PERCEPTION, PROCEEDINGS, P240, DOI 10.1109/CAMP.2000.875983
   Eustache Yvan., 2008, Proceedings of the 6th IEEE/ACM/IFIP international conference on Hardware/Software codesign and system synthesis, P67
   Folliot B., 1998, P 8 ACM SIGOPS EUROP, P175
   Frikha T, 2014, DATA ADAPTATION APPR
   Funkhouser T, 1993, ADAPTIVE DISPLAY ALG
   Guillet C, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036795
   Harley D, 2018, PROCEEDINGS OF THE TWELFTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'18), P386, DOI 10.1145/3173225.3173241
   Hartenstein Reiner, 2010, Proceedings of the VI Southern Programmable Logic Conference (SPL), DOI 10.1109/SPL.2010.5482991
   Javornik A, 2016, J RETAIL CONSUM SERV, V30, P252, DOI 10.1016/j.jretconser.2016.02.004
   Jridi M, 2018, SOC BASED EDGE COMPU
   Kondelová A, 2014, 2014 ELEKTRO, P451, DOI 10.1109/ELEKTRO.2014.6848936
   Kulkarni A, 2018, IEEE T VLSI SYST, V26, P96, DOI 10.1109/TVLSI.2017.2754272
   Le Hung T., 2016, 2016 IEEE International Conference on Consumer Electronics (ICCE), P321, DOI 10.1109/ICCE.2016.7430629
   Li K, 2017, APPL MATH SER B, V32, P294, DOI 10.1007/s11766-017-3466-8
   Linfeng Ye, 2010, Proceedings 2010 International Conference on Field Programmable Logic and Applications (FPL 2010), P285, DOI 10.1109/FPL.2010.65
   Lorch JR, 1998, IEEE PERS COMMUN, V5, P60, DOI 10.1109/98.683740
   Loukil K, 2013, INT J RECONFIGURABLE, V2013, DOI 10.1155/2013/141562
   Min-allah N, 2007, DYNAMIC VOLTAGE SCAL
   Ozawa H, 1998, FUJITSU SCI TECH J, V34, P68
   Pillai P., 2001, Operating Systems Review, V35, P89, DOI 10.1145/502059.502044
   Qu Y, 2007, J SYST ARCHITECT, V53, P861, DOI 10.1016/j.sysarc.2007.02.004
   Schmalstieg D, 1997, TR18629705 VIENN U T
   Ullmann M., 2004, Proceedings. 18th International Parallel and Distributed Processing Symposium
   Wong Stephan, 2013, 2013 2nd Mediterranean Conference on Embedded Computing (MECO 2013), DOI 10.1109/MECO.2013.6601391
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Yan XH, 2017, J COMPUT SCI TECH-CH, V32, P340, DOI 10.1007/s11390-017-1714-2
   Yan XH, 2018, INT J COOP INF SYST, V27, DOI 10.1142/S0218843017410015
   Yilmaz RM, 2016, COMPUT HUM BEHAV, V54, P240, DOI 10.1016/j.chb.2015.07.040
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Yuan WH, 2006, ACM T COMPUT SYST, V24, P292, DOI 10.1145/1151690.1151693
   Zhang DJ, 2016, INTEGR COMPUT-AID E, V23, P31, DOI 10.3233/ICA-150499
NR 39
TC 8
Z9 8
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14947
EP 14970
DI 10.1007/s11042-018-6886-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700036
DA 2024-07-18
ER

PT J
AU Singh, RD
   Mittal, A
   Bhatia, RK
AF Singh, Rahul Dev
   Mittal, Ajay
   Bhatia, Rajesh K.
TI 3D convolutional neural network for object recognition: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; 3D images; Convolutional neural network; Object
   recognition; Supervised learning
ID LEARNING ALGORITHM; CLASSIFICATION; IMAGE; REPRESENTATION; SURVEILLANCE;
   FEATURES
AB Recognition of an object from an image or image sequences is an important task in computer vision. It is an important low-level image processing operation and plays a crucial role in many real-world applications. The challenges involved in object recognition are multi-model, multi-pose, complicated background, and depth variations. Recently developed methods have dealt with these challenges and have reported remarkable results for 3D objects. In this paper, a comprehensive overview of recent advances in 3D object recognition using Convolutional Neural Networks (CNN) has been presented. Along with the latest progress in 3D images, general overview of object recognition of 2D, 2.5D, and 3D images is presented.
C1 [Singh, Rahul Dev] Punjab Engn Coll, Chandigarh, India.
   [Bhatia, Rajesh K.] Punjab Engn Coll, Comp Sci & Engn, Chandigarh, India.
   [Mittal, Ajay] Panjab Univ, UIET, Chandigarh, India.
C3 Punjab Engineering College (Deemed University); Punjab Engineering
   College (Deemed University); Panjab University
RP Singh, RD (corresponding author), Punjab Engn Coll, Chandigarh, India.
EM rahul86.dev@gmail.com
RI Mittal, Ajay/AAE-3475-2019; Bhatia, Dr Rajesh/JUU-9542-2023
CR ACKLEY DH, 1985, COGNITIVE SCI, V9, P147
   Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   Aldoma A, 2012, IEEE ROBOT AUTOM MAG, V19, P80, DOI 10.1109/MRA.2012.2206675
   Andreopoulos A, 2013, COMPUT VIS IMAGE UND, V117, P827, DOI 10.1016/j.cviu.2013.04.005
   Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207
   [Anonymous], ARXIV170505994
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2006, Advances in Neural Information Processing Systems 19
   [Anonymous], P INT C ROB AUT ICAR
   [Anonymous], 2010, P 27 INT C MACHINE L
   [Anonymous], 2017, P IEEE INT C COMP VI
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], ARXIV161105009
   [Anonymous], P TRECVID VID EV WOR
   [Anonymous], 2013, ICLR 2013 INT C LEAR
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.87
   [Anonymous], 8694 ARXIV
   [Anonymous], 2006, Advances in Neural Information Processing Systems
   [Anonymous], MULTISCALE HIERARCHI
   [Anonymous], 2014, EUR WORKSH 3D OBJ RE
   [Anonymous], 2013, P INT C MACHINE LEAR
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], SEMANTIC POSE USING
   [Anonymous], 2017, P CVPR
   [Anonymous], 1989, Backpropagation applied to handwritten zip code recognition
   [Anonymous], 2003, 7 CENTR EUR SEM COMP
   [Anonymous], IEEE T INSTRUM MEAS
   [Anonymous], 2014, SLOA190B
   [Anonymous], 2014, ARXIV14075736
   [Anonymous], 10 INT WORSKH FRONT
   [Anonymous], 2017, ARXIV170309783
   [Anonymous], P WORKSH GEN PURP PR
   [Anonymous], 2013, ARXIV13126184
   [Anonymous], ARXIV160300988V4
   [Anonymous], 2017, COMPUT GRAPHICS
   [Anonymous], 2016, ARXIV160306208
   [Anonymous], 2016, IEEE T PATTERN ANAL
   [Anonymous], 2018, P IEEE C COMP VIS PA
   [Anonymous], 2016, ARXIV160807916
   ARMAN F, 1993, COMPUT SURV, V25, P5, DOI 10.1145/151254.151255
   Ayache S, 2008, LECT NOTES COMPUT SC, V4956, P187
   Bai S, 2016, PROC CVPR IEEE, P5023, DOI 10.1109/CVPR.2016.543
   Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Ben-Shabat Yizhak, 2017, ARXIV171108241
   BESL PJ, 1985, COMPUT SURV, V17, P75, DOI 10.1145/4078.4081
   Bespalov Dmitriy., 2003, ASME DESIGN ENG TECH, P229
   Bo L., 2013, EXPT ROBOTICS VOLUME, P387, DOI DOI 10.1007/978-3-319-00065-7
   Brady J. P., 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P85, DOI 10.1109/ICPR.1988.28178
   BRONSTEIN A, 2010, IMAGING ANAL APPL D, V3, P1
   Bucak SS, 2014, IEEE T PATTERN ANAL, V36, P1354, DOI 10.1109/TPAMI.2013.212
   Byeon YH, 2014, INT J ADV COMPUT SC, V5, P107, DOI 10.14569/ijacsa.2014.051215
   Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Choi C., 2018, IEEE ROBOTICS AUTOMA
   Cicirello V, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P176, DOI 10.1109/SMA.2001.923388
   Ciresan D, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P1918, DOI 10.1109/IJCNN.2011.6033458
   Cordts M, 2015, CVPR WORKSHOP FUTURE, V2, P1
   Deng J, 2014, LECT NOTES COMPUT SC, V8689, P48, DOI 10.1007/978-3-319-10590-1_4
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fathollahi M, 2016, LECT NOTES COMPUT SC, V9915, P40, DOI 10.1007/978-3-319-49409-8_6
   FUKUSHIMA K, 1988, NEURAL NETWORKS, V1, P119, DOI 10.1016/0893-6080(88)90014-7
   Fukushima S., 1982, inCompetition and Cooperation in Neural Nets, P267, DOI 10.1007/978-3-642-46466-9_18
   Furukawa Y, 2013, FOUND TRENDS COMPUT, V9, P1, DOI 10.1561/0600000052
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Getoor, 2011, P 28 INT C MACH LEAR, P833
   Glocker B, 2013, INT SYM MIX AUGMENT, P173, DOI 10.1109/ISMAR.2013.6671777
   Gomez-Donoso F, 2017, IEEE IJCNN, P412, DOI 10.1109/IJCNN.2017.7965883
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Guo YL, 2014, IEEE T PATTERN ANAL, V36, P2270, DOI 10.1109/TPAMI.2014.2316828
   Han F, 2017, COMPUT VIS IMAGE UND, V158, P85, DOI 10.1016/j.cviu.2017.01.011
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hecht-Nielsen R., 1989, IJCNN: International Joint Conference on Neural Networks (Cat. No.89CH2765-6), P593, DOI 10.1109/IJCNN.1989.118638
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 1986, P 8 ANN C C SCI SOC, V1, P12
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Ip CY, 2002, P 7 ACM S SOL MOD AP, P273, DOI 10.1145/566282.566322
   Johns E, 2016, PROC CVPR IEEE, P3813, DOI 10.1109/CVPR.2016.414
   Gómez MJ, 2015, EXPERT SYST APPL, V42, P8156, DOI 10.1016/j.eswa.2015.06.026
   Jourabloo A, 2016, PROC CVPR IEEE, P4188, DOI 10.1109/CVPR.2016.454
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Lee CY, 2016, JMLR WORKSH CONF PRO, V51, P464
   Li JX, 2018, PROC CVPR IEEE, P9397, DOI 10.1109/CVPR.2018.00979
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Lin M., 2013, P 2 INT C LEARNING R
   Liu Z, 2016, IMAGE VISION COMPUT, V55, P93, DOI 10.1016/j.imavis.2016.04.004
   Loncomilla P, 2016, PATTERN RECOGN, V60, P499, DOI 10.1016/j.patcog.2016.05.021
   Makantasis K, 2015, LECT NOTES COMPUT SC, V9474, P717, DOI 10.1007/978-3-319-27857-5_64
   Mamic G, 2002, DIGIT SIGNAL PROCESS, V12, P47, DOI 10.1006/dspr.2001.0412
   MANTAS J, 1986, PATTERN RECOGN, V19, P425, DOI 10.1016/0031-3203(86)90040-3
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   McCormac J., 2016, CORR
   MEAGHER D, 1982, COMPUT VISION GRAPH, V19, P129, DOI 10.1016/0146-664X(82)90104-6
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Mian A. S., 2004, Sensor Review, V24, P206, DOI 10.1108/02602280410525995
   Mian A.S., 2005, INT J OFSHAPE MODELI, V11, P253, DOI DOI 10.1142/S0218654305000797
   Bautista CM, 2016, IEEE REGION 10 SYMP, P277, DOI 10.1109/TENCONSpring.2016.7519418
   Naguri CR, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P1130, DOI 10.1109/ICMLA.2017.00013
   Nalpantidis L, 2008, INT J OPTOMECHATRONI, V2, P435, DOI 10.1080/15599610802438680
   Ngiam J., 2011, P 28 INT C MACHINE L, P1105, DOI 10.5555/3104482.3104621
   Nie D, 2016, LECT NOTES COMPUT SC, V10008, P170, DOI 10.1007/978-3-319-46976-8_18
   Nie WZ, 2017, MULTIMEDIA SYST, V23, P325, DOI 10.1007/s00530-015-0485-2
   Novotni M, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P167, DOI 10.1109/SMA.2001.923387
   Ouyang W., 2014, ARXIV PREPRINT ARXIV
   Poggio T., 2016, ARXIV161100740
   Qi C. R., 2017, Advances in neural information processing systems, P5099
   Qi C. R., 2017, IEEE P COMPUT VIS PA, V1, P4, DOI DOI 10.1109/CVPR.2017.16
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   Quadros A, 2012, IEEE INT CONF ROBOT, P4428, DOI 10.1109/ICRA.2012.6225239
   Rahmati M, 2016, 2016 6TH CONFERENCE ON THERMAL POWER PLANTS (CTPP), P1, DOI 10.1109/CTPP.2016.7482925
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Roth HR, 2014, LECT NOTES COMPUT SC, V8673, P520, DOI 10.1007/978-3-319-10404-1_65
   Salakhutdinov R., 2009, AISTATS
   Salvi J, 2007, IMAGE VISION COMPUT, V25, P578, DOI 10.1016/j.imavis.2006.05.012
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Scholkopf B., 1998, Advances in Kernel Methods: Support Vector Learning
   Schwarz M, 2015, IEEE INT CONF ROBOT, P1329, DOI 10.1109/ICRA.2015.7139363
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shi FM, 2016, ZOOKEYS, P1, DOI 10.3897/zookeys.558.6165
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Siddiqi K, 2008, MACH VISION APPL, V19, P261, DOI 10.1007/s00138-007-0097-8
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simard PY, 2003, PROC INT CONF DOC, P958
   Simonyan K., 2014, Very Deep Convolutional Networks for Large-Scale Image Recognition
   Singh S., 2013, Emerging Trends in Computing and Information Sciences, V4, P545
   Socher R., 2012, ADV NEURAL INFORM PR, P1
   Sochor J, 2017, COMPUT VIS IMAGE UND, V161, P87, DOI 10.1016/j.cviu.2017.05.015
   Soltanpour S, 2017, PATTERN RECOGN, V72, P391, DOI 10.1016/j.patcog.2017.08.003
   Springenberg J. T., 2015, ARXIV PREPRINT ARXIV
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308
   Suetens Paul, 2017, FUNDAMENTALS MED IMA
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Tombari F, 2013, INT J COMPUT VISION, V102, P198, DOI 10.1007/s11263-012-0545-4
   Vidya R, 2014, 2014 WORLD CONGRESS ON COMPUTING AND COMMUNICATION TECHNOLOGIES (WCCCT 2014), P124, DOI 10.1109/WCCCT.2014.69
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Wan L, 2013, P 30 INT C MACH LEAR, P1058, DOI DOI 10.5555/3042817.3043055
   Wang PS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073608
   Wu HB, 2015, NEURAL NETWORKS, V71, P1, DOI 10.1016/j.neunet.2015.07.007
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101
   Xie ZG, 2015, COMPUT GRAPH FORUM, V34, P1, DOI 10.1111/cgf.12740
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yuen K, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P649, DOI 10.1109/ITSC.2016.7795622
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhou S., 2016, CORR
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
NR 155
TC 31
Z9 39
U1 6
U2 74
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 15951
EP 15995
DI 10.1007/s11042-018-6912-6
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500011
DA 2024-07-18
ER

PT J
AU Tong, DY
   Ren, N
   Zhu, CQ
AF Tong, Deyu
   Ren, Na
   Zhu, Changqing
TI Secure and robust watermarking algorithm for remote sensing images based
   on compressive sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Compressive sensing; Security; Robustness; Reconstruction
   accuracy
ID COPYRIGHT PROTECTION; SPARSE DECOMPOSITION; SIGNAL RECOVERY; DIGITAL
   IMAGE; SCHEME; RECONSTRUCTION; SYSTEM
AB The aim of this paper is to improve the reconstruction accuracy and security when adopting Compressive Sensing (CS) in watermarking algorithm. Unlike classical CS-based watermark generation method, lifting wavelet transformation, partial Hadamard matrix, and ternary watermark sequence have been combined together to carry sufficient watermark information to ensure reconstruction accuracy and robustness. In the procedure of watermark embedding and extraction, watermark is embedded and extracted in CS measurement of remote sensing image. Hence the whole algorithm security is guaranteed by CS measurement matrix either in watermark generation or watermark embedding and extraction. Then, the CS-based watermarking algorithm for remote sensing images is proposed and demonstrated. Compared with other CS-based approaches, the improvements on reconstruction accuracy, security and robustness of the proposed algorithm have been verified by experiments.
C1 [Tong, Deyu; Ren, Na; Zhu, Changqing] Nanjing Normal Univ, Key Lab Virtual Geog Environm, Minist Educ, Nanjing 210023, Jiangsu, Peoples R China.
   [Tong, Deyu; Ren, Na; Zhu, Changqing] State Key Lab Cultivat Base Geog Environm Evolut, Nanjing 210023, Jiangsu, Peoples R China.
   [Tong, Deyu; Ren, Na; Zhu, Changqing] Jiangsu Ctr Collaborat Innovat Geog Informat Reso, Nanjing 210023, Jiangsu, Peoples R China.
C3 Nanjing Normal University
RP Ren, N (corresponding author), Nanjing Normal Univ, Key Lab Virtual Geog Environm, Minist Educ, Nanjing 210023, Jiangsu, Peoples R China.; Ren, N (corresponding author), State Key Lab Cultivat Base Geog Environm Evolut, Nanjing 210023, Jiangsu, Peoples R China.; Ren, N (corresponding author), Jiangsu Ctr Collaborat Innovat Geog Informat Reso, Nanjing 210023, Jiangsu, Peoples R China.
EM renna1026@163.com
RI Tong, Deyu/AAD-3813-2020; Tong, Deyu/JXM-3886-2024
CR AL-Mansoori S, 2012, PROC SPIE, V8539, DOI 10.1117/12.979185
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Chang CP, 2006, OPT ENG, V45, DOI 10.1117/1.2202932
   Chen Y, 2010, CONSUM COMM NETWORK, P1
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Du XY, 2015, PROCEEDINGS OF THE ASME 34TH INTERNATIONAL CONFERENCE ON OCEAN, OFFSHORE AND ARCTIC ENGINEERING, 2015, VOL 8
   Ender JHG, 2010, SIGNAL PROCESS, V90, P1402, DOI 10.1016/j.sigpro.2009.11.009
   Fang H, 2013, J COMPUT, V11, P7
   Fang LY, 2012, BIOMED OPT EXPRESS, V3, P927, DOI 10.1364/BOE.3.000927
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Fu JJ, 2016, ACTA ELECT SIN, V3, P8
   Ghaffari A, 2009, INT CONF ACOUST SPEE, P3157, DOI 10.1109/ICASSP.2009.4960294
   Hsu PH, 2016, PHOTOGRAMM REC, V31, P51, DOI 10.1111/phor.12134
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Li LL, 2012, ADV MATER RES-SWITZ, V433-440, P2504, DOI 10.4028/www.scientific.net/AMR.433-440.2504
   Liu CZ, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416580027
   Liu H, 2016, SIGNAL PROCESS-IMAGE, V45, P41, DOI 10.1016/j.image.2016.04.002
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu P, 2013, OPTIK, V124, P2514, DOI 10.1016/j.ijleo.2012.08.017
   Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391
   Melgani F, 2007, J APPL REMOTE SENS, V1, DOI 10.1117/1.2535355
   Mohimani H, 2009, IEEE T SIGNAL PROCES, V57, P289, DOI 10.1109/TSP.2008.2007606
   Rachlin Y, 2008, ANN ALLERTON CONF, P813, DOI 10.1109/ALLERTON.2008.4797641
   [任娜 Ren Na], 2011, [测绘学报, Acta Geodetica et Cartographica Sinica], V40, P623
   Serra-Ruiz J, 2012, PROC SPIE, V8514, DOI 10.1117/12.934248
   Shinoda K, 2015, OPT REV, V22, P469, DOI 10.1007/s10043-015-0082-9
   Somani SM, 2016, PROC SPIE, V9880, DOI 10.1117/12.2223590
   Sui LS, 2017, OPT LASER ENG, V92, P85, DOI 10.1016/j.optlaseng.2017.01.003
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Székely GJ, 2007, ANN STAT, V35, P2769, DOI 10.1214/009053607000000505
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P15191, DOI 10.1007/s11042-016-3744-0
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang RJ, 2012, IEEE ASME INT C ADV, P220, DOI 10.1109/AIM.2012.6266034
   Zhang YS, 2016, IEEE ACCESS, V4, P2507, DOI 10.1109/ACCESS.2016.2569421
   Zhao HM, 2015, INT J SECUR APPL, V9, P259, DOI 10.14257/ijsia.2015.9.12.24
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
   Zhu P, 2013, OPTIK, V124, P4177, DOI 10.1016/j.ijleo.2012.12.049
   Zhu XX, 2013, IEEE T GEOSCI REMOTE, V51, P2827, DOI 10.1109/TGRS.2012.2213604
   Zope-Chaudhari S, 2015, IEEE J-STARS, V8, P5388, DOI 10.1109/JSTARS.2015.2475169
NR 43
TC 11
Z9 15
U1 1
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16053
EP 16076
DI 10.1007/s11042-018-7014-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500015
DA 2024-07-18
ER

PT J
AU Kumar, M
   Srivastava, S
AF Kumar, Manoj
   Srivastava, Sangeet
TI Image authentication by assessing manipulations using illumination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lighting; Image forensics; Decorrelation; Image manipulation
AB With the ever increasing use of digital media, image tampering has become imperative. This spurs the need to identify such tampering for authentication and jurisdiction. The main idea of this paper is an assessment of the possible light source direction from the image. This technique uses the inconsistencies in the light source direction to detect the image forgery. Initially, in the preprocessing step on input image, surface normals are calculated using surface texture profile. RED band is mainly used for obtaining surface texture information and, further, surface normal calculations are done. With estimated illumination profile and normals, the incident angle (i) is computed for various chosen image patches. The (i) angle is the estimated angle from image object to light source direction. The inconsistency in (i) values is used as an evidence of tampering. The proposed technique is tested on different known fake images and is found capable of identifying manipulated objects in an image. This technique works for homogenous illuminated surfaces and has better forgery detection accuracy. Additionally, our technique also diminishes human intervention for forgery detection. The performance of proposed forgery detection technique is examined using CASIA1 image database to give users a feel of the performance.
C1 [Kumar, Manoj] AMITY Univ, Dept Comp Sci, ASET, Noida, India.
   [Srivastava, Sangeet] Northcap Univ, Dept Appl Sci, Gurugram, India.
C3 Amity University Noida; The Northcap University
RP Kumar, M (corresponding author), AMITY Univ, Dept Comp Sci, ASET, Noida, India.
EM wss.manojkumar@gmail.com; sangeet.srivastava@ncuindia.edu
RI Srivastava, Sangeet/AAR-3844-2021; KUMAR, MANOJ/P-7489-2014
OI KUMAR, MANOJ/0000-0001-5113-0639
CR [Anonymous], THESIS
   Austin John D., 1988, INFORM PROCESSING ME, P375
   Carvalho T, 2015, SPIE S MED WAT SEC F
   CHOJNACKI W, 1994, J OPT SOC AM A, V11, P118, DOI 10.1364/JOSAA.11.000118
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   Johnson M.K., 2005, Proceedings of the 7th Workshop on Multimedia and Security, P1
   KEE E, 2013, ACM T GRAPHIC, V32, P1
   KEE E, 2010, IEEE WORKSHOP INFORM, V3
   Kee E, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629646
   Kranthi Kumar M, 2016, Indian Jou Sci Technol, V9, P1
   Kumar M, 2019, AUST J FORENSIC SCI, V51, P243, DOI 10.1080/00450618.2017.1356871
   MINGOLLA E, 1986, BIOL CYBERN, V53, P137, DOI 10.1007/BF00342882
   Moran L, 2012, MAILONLINE
   Nillus P, 2001, P 2001 IEEE COMP SOC
   O'Brien JF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2077341.2077345
   Peng B, 2015, IEEE INT WORKS INFOR
   Peng B, 2017, IEEE T INF FOREN SEC, V12, P479, DOI 10.1109/TIFS.2016.2623589
   Pine J, 2001, INT WORK VERY LOW BI, P197
   Riess C, 2017, MULTIMED TOOLS APPL, V76, P4747, DOI 10.1007/s11042-016-3655-0
   Riess C, 2015, LECT NOTES COMPUT SC, V9281, P3, DOI [10.1007/978-3-319-23222-5_1, 10.1007/978-3-319-23222-5]
   Roy AK, 2011, OPTO-ELECTRON REV, V19, P211, DOI 10.2478/s11772-011-0014-6
   Wang Y, 2002, LECT NOTES COMPUT SC, V2352, P272
   Zhong JL, 2017, MULTIMED TOOLS APPL, V76, P14887, DOI 10.1007/s11042-016-4201-9
NR 23
TC 21
Z9 21
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12451
EP 12463
DI 10.1007/s11042-018-6775-x
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900061
DA 2024-07-18
ER

PT J
AU Li, R
   Pan, ZB
   Wang, Y
AF Li, Rui
   Pan, Zhibin
   Wang, Yang
TI The linear prediction vector quantization for hyperspectral image
   compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral images compression; K-means; Linear prediction; Vector
   quantization (VQ)
ID PRINCIPAL COMPONENT ANALYSIS; LOSSLESS COMPRESSION; MULTISPECTRAL
   IMAGES; TRANSFORM; ALGORITHM
AB In this paper, a hyperspectral image compression method is proposed. It is based on spectral clustering, linear prediction and the vector quantization (VQ). Since the hyperspectral image has stronger spectral correlation than spatial correlation, the spectral clustering and model of linear prediction are introduced to reduce the spectral correlation. In the proposed method, spectral clustering algorithm of K-means is employed, and the centroids of clustered results are used as reference bands, then the reference bands are employed in the model of linear prediction to compute the prediction error, finally the prediction error is encoded by VQ. The experiments results using AVIRIS images are compared to IVQ and AR+SubPCA+JPEG2000 algorithm, the results show that our proposed algorithm outperforms other algorithms.
C1 [Li, Rui; Pan, Zhibin; Wang, Yang] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, 28 Xianning West Rd, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, 28 Xianning West Rd, Xian 710049, Shaanxi, Peoples R China.
EM pofazhelirui@stu.xjtu.edu.cn; zbpan@mail.xjtu.edu.cn; wty2977892@126.com
RI Pan, Zhibin/I-8212-2012
FU Open Research Fund of Key Laboratory of Spectral Imaging Technology,
   Chinese Academy of Sciences [LSIT201606D]; Open Project Program of the
   National Laboratory of Pattern Recognition (NLPR) [201800030]
FX This work is supported in part by the Open Research Fund of Key
   Laboratory of Spectral Imaging Technology, Chinese Academy of Sciences
   (Grant No. LSIT201606D) and the Open Project Program of the National
   Laboratory of Pattern Recognition (NLPR) (Grant No. 201800030).
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Aiazzi B, 1999, IEEE T GEOSCI REMOTE, V37, P2287, DOI 10.1109/36.789625
   Amrani N, 2016, IEEE T GEOSCI REMOTE, V54, P5616, DOI 10.1109/TGRS.2016.2569485
   Baker R. L., 1988, Proceedings of the SPIE - The International Society for Optical Engineering, V974, P255, DOI 10.1117/12.948466
   Beerten J, 2015, IEEE GEOSCI REMOTE S, V12, P1775, DOI 10.1109/LGRS.2015.2425548
   Bita IPA, 2010, SIGNAL PROCESS, V90, P759, DOI 10.1016/j.sigpro.2009.09.011
   Blanes Ian, 2009, 2009 Data Compression Conference. DCC 2009, P233, DOI 10.1109/DCC.2009.7
   Blanes I, 2012, IEEE SIGNAL PROC MAG, V29, P71, DOI 10.1109/MSP.2011.2179416
   Blanes I, 2011, IEEE T GEOSCI REMOTE, V49, P961, DOI 10.1109/TGRS.2010.2071880
   Canta GR, 1997, SIGNAL PROCESS-IMAGE, V11, P147, DOI 10.1016/S0923-5965(96)00043-4
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Ding M, 2016, IEEE T IMAGE PROCESS, V25, P776, DOI 10.1109/TIP.2015.2507445
   Ding M, 2015, IEEE T CYBERNETICS, V45, P2413, DOI 10.1109/TCYB.2014.2373393
   Dragotti PL, 2000, IEEE T GEOSCI REMOTE, V38, P416, DOI 10.1109/36.823937
   Du Q, 2008, INT J HIGH PERFORM C, V22, P438, DOI 10.1177/1094342007088380
   Du Q, 2014, IEEE J-STARS, V7, P2237, DOI 10.1109/JSTARS.2013.2274527
   Effros M, 2004, IEEE T INFORM THEORY, V50, P1605, DOI 10.1109/TIT.2004.831787
   Fu W, 2017, IEEE T GEOSCI REMOTE, V55, P671, DOI 10.1109/TGRS.2016.2613848
   GUPTA S, 1992, IEEE T GEOSCI REMOTE, V30, P491, DOI 10.1109/36.142927
   He C, 2003, IEEE T CIRC SYST VID, V13, P961, DOI 10.1109/TCSVT.2003.816514
   Hou Y, 2008, OPT ENG, V47, DOI 10.1117/1.3006097
   Hsiang ST, 2001, IEEE DATA COMPR CONF, P83, DOI 10.1109/DCC.2001.917139
   Hu YC, 2012, OPTO-ELECTRON REV, V20, P187, DOI 10.2478/s11772-012-0016-z
   Imani M, 2017, IEEE GEOSCI REMOTE S, V14, P1313, DOI 10.1109/LGRS.2017.2710618
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Lagoudakis M. G., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P698
   Lim S, 2001, INT GEOSCI REMOTE SE, P97, DOI 10.1109/IGARSS.2001.976068
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Mielikainen JS, 2002, P SOC PHOTO-OPT INS, V4725, P57
   Pennebaker W. B., 1992, JPEG STILL IMAGE DAT
   Rizzo F, 2005, IEEE SIGNAL PROC LET, V12, P138, DOI 10.1109/LSP.2004.840907
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   Sidharth M., 2017, CHEMOM INTELL LAB SY, V7, P60, DOI [DOI 10.5455/IJLR.20170415115235, DOI 10.1016/0169-7439(87)80084-9, 10.5455/ijlr.20170415115235]
   Tang X, 2003, P SOC PHOTO-OPT INS, P294
   Wen J, 2014, OPT COMMUN, V322, P97, DOI 10.1016/j.optcom.2014.02.016
   Zhang J, 2007, IEEE GEOSCI REMOTE S, V4, P283, DOI 10.1109/LGRS.2007.890546
   Zhao DY, 2016, COMPUT ELECTR ENG, V54, P494, DOI 10.1016/j.compeleceng.2016.03.012
NR 39
TC 10
Z9 10
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11701
EP 11718
DI 10.1007/s11042-018-6724-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900027
DA 2024-07-18
ER

PT J
AU Liu, F
   Yang, S
   Ding, YH
   Xu, F
AF Liu, Fan
   Yang, Sai
   Ding, Yuhua
   Xu, Feng
TI Single sample face recognition via BoF using multistage KNN
   collaborative coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bag-of-feature; Semantic gap; Single sample per person; Sparse coding
ID TRAINING SAMPLE; MODEL
AB In this paper, we propose a multistage KNN collaborative coding based Bag-of-Feature (MKCC-BoF) method to address SSPP problem, which tries to weaken the semantic gap between facial features and facial identification. First, local descriptors are extracted from the single training face images and a visual dictionary is obtained offline by clustering a large set of descriptors with K-means. Then, we design a multistage KNN collaborative coding scheme to project local features into the semantic space, which is much more efficient than the most commonly used non-negative sparse coding algorithm in face recognition. To describe the spatial information as well as reduce the feature dimension, the encoded features are then pooled on spatial pyramid cells by max-pooling, which generates a histogram of visual words to represent a face image. Finally, a SVM classifier based on linear kernel is trained with the concatenated features from pooling results. Experimental results on three public face databases show that the proposed MKCC-BoF is much superior to those specially designed methods for SSPP problem. Moreover, it also has great robustness to expression, illumination, occlusion and, time variation.
C1 [Liu, Fan; Xu, Feng] Hohai Univ, Coll Comp & Informat, Nanjing, Jiangsu, Peoples R China.
   [Liu, Fan] Hohai Univ, Nantong Ocean & Coastal Engn Res Inst, Nantong, Peoples R China.
   [Yang, Sai] Nantong Univ, Sch Elect Engn, Nantong, Peoples R China.
   [Ding, Yuhua] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China.
C3 Hohai University; Hohai University; Nantong University; Nanjing
   University of Science & Technology
RP Liu, F (corresponding author), Hohai Univ, Coll Comp & Informat, Nanjing, Jiangsu, Peoples R China.; Liu, F (corresponding author), Hohai Univ, Nantong Ocean & Coastal Engn Res Inst, Nantong, Peoples R China.; Yang, S (corresponding author), Nantong Univ, Sch Elect Engn, Nantong, Peoples R China.
EM faliu@hhu.edu.cn; yangsai166@126.com; dingyuhua1210@163.com;
   xufeng@hhu.edu.cn
FU National Natural Science Foundation of China [61602150, 61871444];
   Fundamental Research Funds for the Central Universities [2018B16214];
   China Postdoctoral Science Foundation [2016M600355, 2017T100323];
   Jiangsu Planned Projects for Postdoctoral Research Funds [601013B];
   Nantong Science and Technology Project [GY12017014]; University Science
   Research Project of Jiangsu Province [16KJB520037]
FX This work was partially funded by National Natural Science Foundation of
   China under grant No. 61602150 and 61871444, Fundamental Research Funds
   for the Central Universities under grant No. 2018B16214, China
   Postdoctoral Science Foundation funded project under grant No.
   2016M600355, 2017T100323, Jiangsu Planned Projects for Postdoctoral
   Research Funds under grant No. 601013B, Nantong Science and Technology
   Project under grant No. GY12017014 and University Science Research
   Project of Jiangsu Province under grant No. 16KJB520037.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2003, BIOMETRICS LOOK FACI
   [Anonymous], 2016, SEETAFACEENGINE
   [Anonymous], 2012, P 20 ACM INT C MULTI
   Belhumeur P. N., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P45
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Bicego M., 2006, COMP VIS PATT REC WO, P35, DOI DOI 10.1109/CVPRW.2006.149
   CAO ZM, 2010, PROC CVPR IEEE, P2707, DOI DOI 10.1109/CVPR.2010.5539992
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen SC, 2004, PATTERN RECOGN, V37, P1553, DOI 10.1016/j.patcog.2003.12.010
   Cui Z, 2013, PROC CVPR IEEE, P3554, DOI 10.1109/CVPR.2013.456
   Deng WH, 2014, PATTERN RECOGN, V47, P3738, DOI 10.1016/j.patcog.2014.06.020
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Gao QX, 2008, APPL MATH COMPUT, V205, P726, DOI 10.1016/j.amc.2008.05.019
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   He XF, 2004, ADV NEUR IN, V16, P153
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Jolliffe I.T., 1986, PRINCIPAL COMPONENT, P129, DOI 10.1007/978-1-4757-1904-8_8
   Ketcham M, 2016, INT S NAT LANG PROC, P223
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu F, 2015, ACM T INTEL SYST TEC, V7, DOI 10.1145/2733383
   Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   Meng X, 2006, INT C PATT RECOG, P536
   Quan Fang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P260, DOI 10.1109/ICME.2012.164
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P883, DOI 10.1109/TMM.2012.2188782
   Su Y, 2010, PROC CVPR IEEE, P2699, DOI 10.1109/CVPR.2010.5539990
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tzotsos A., 2008, LECT NOTES GEOINFORM, P663, DOI DOI 10.1007/978-3-540-77058-9_36
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Wei XF, 2018, IEEE INT CONF AUTOMA, P31, DOI 10.1109/FG.2018.00015
   Wolf Lior, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P88
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xie SF, 2009, SIGNAL PROCESS, V89, P2333, DOI 10.1016/j.sigpro.2009.02.016
   Yang M, 2013, IEEE I CONF COMP VIS, P689, DOI 10.1109/ICCV.2013.91
   Yu J, 2018, IEEE T IND ELECTRON, V65, P5060, DOI 10.1109/TIE.2017.2739691
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhu M, 2014, FIFTH INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP), P34, DOI 10.1109/ICICIP.2014.7010309
   Zhu PF, 2012, LECT NOTES COMPUT SC, V7572, P822, DOI 10.1007/978-3-642-33718-5_59
   Zisheng Li, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1285, DOI 10.1109/ICPR.2010.320
NR 45
TC 9
Z9 10
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13297
EP 13311
DI 10.1007/s11042-018-7002-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900031
OA hybrid
DA 2024-07-18
ER

PT J
AU Micheloni, E
   Tramarin, M
   Rodà, A
   Chiaravalli, F
AF Micheloni, Edoardo
   Tramarin, Marco
   Roda, Antonio
   Chiaravalli, Federico
TI Playing to play: a piano-based user interface for music education
   video-games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tangible interfaces; Videogame; Piano-based; Music education; Acoustic
   stimuli
ID SPEECH
AB This paper presents and discusses a case-study where a video-game is the means through which the user is induced to learn to use a complex and not-intuitive control interface such as the keyboard of a piano. The interaction paradigm is based on the idea, common to the Tangible Interfaces, to employ everyday objects, or anyway not designed for video games, as control user interface. In this research, the case study is the video game called Musa, in which players are led into an imaginary world where music is magic and every action is carried out through it. Combined with an educational path, this is thought to make players able to learn and, in a successive moment, to abstract this knowledge from the game, just by playing. Musa was evaluated in an experimental setup with 51 kids between 6 and 11years old. Results show that subjects are able to improve their knowledge of the piano keyboard after two sessions of game and no significant differences were found between children with pre-acquired knowledge of the keyboard and the others.
C1 [Micheloni, Edoardo] Univ Padua, Informat Engn, Via Giovanni Gradenigo 6, Padua, Italy.
   [Tramarin, Marco] Univ Padua, Via Giovanni Gradenigo 6, Padua, Italy.
   [Roda, Antonio] Univ Padua, Dept Informat Engn, Via Giovanni Gradenigo 6, Padua, Italy.
   [Chiaravalli, Federico] Musa Srl, Via Plinio 45, Milan, Italy.
C3 University of Padua; University of Padua; University of Padua
RP Micheloni, E (corresponding author), Univ Padua, Informat Engn, Via Giovanni Gradenigo 6, Padua, Italy.
EM micheloni@dei.unipd.it; marco.tramarin@studenti.unipd.it;
   roda@dei.unipd.it; federico.chiaravalli@playmusa.com
FU Musa s.r.l.
FX This research has been supported by Musa s.r.l.
CR Alty JL, 1995, BCS HCI
   Avanzini F, 2015, P 12 INT C SOUND MUS
   Avanzini F, 2016, P INT C SOUND MUS CO
   Bressan F, 2014, INT J ARTS TECHNOL, V7, P294, DOI 10.1504/IJART.2014.066451
   Canazza S, 2015, ACM T MULTIMEDIA COM
   Caroux L, 2015, COMPUT HUM BEHAV, V48, P366, DOI 10.1016/j.chb.2015.01.066
   de Cheveigné A, 2002, J ACOUST SOC AM, V111, P1917, DOI 10.1121/1.1458024
   Deterding S., 2011, P 15 INT ACAD MINDTR, P9, DOI DOI 10.1145/2181037.2181040
   EPHRAIM Y, 1984, IEEE T ACOUST SPEECH, V32, P1109, DOI 10.1109/TASSP.1984.1164453
   Fantozzi C, 2017, INT J DIGIT LIBRARIE, V18, P233, DOI 10.1007/s00799-017-0208-8
   Gaver William W, 1986, Human-computer interaction, V2, P167, DOI [10.1207/s15327051hci0202_3, DOI 10.1207/S15327051HCI0202_3]
   Gerkmann T, 2012, IEEE T AUDIO SPEECH, V20, P1383, DOI 10.1109/TASL.2011.2180896
   Hanna L., 1997, interactions, V4, P9, DOI [DOI 10.1145/264044.264045, 10.1145/264044.264045]
   Ishii H., 2008, P 2 INT C TANG EMB I, P15
   Jacob R. J. K., 2008, P SIGCHI C HUM FACT
   Luc N, 2009, 5 C INT MUS LAM I JE
   Magerkurth C., 2005, Computer in Entertainment (CIE), V3, P4
   Markopoulos P, 2003, INTERACT COMPUT, V15, P227, DOI 10.1016/S0953-5438(03)00009-2
   ORIO N, 2003, P 2003 C NEW INT MUS
   Poole A., 2006, ENCY HUMAN COMPUTER, P211, DOI [DOI 10.4018/978-1-59140-562-7.CH034, 10.4018/978-1-59140-562-7]
   ROUSSOU M, 2004, COMPUT ENTERTAIN, V2, DOI [10.1145/973801.973818, DOI 10.1145/973801.973818]
   Schank RC, 1999, INSTRUCTIONAL-DESIGN THEORIES AND MODELS, VOL II, P161
   Sigtia S, 2016, IEEE-ACM T AUDIO SPE, V24, P927, DOI 10.1109/TASLP.2016.2533858
   Sohn J, 1999, IEEE SIGNAL PROC LET, V6, P1, DOI 10.1109/97.736233
   Wanderley MM, 2002, COMPUT MUSIC J, V26, P62, DOI 10.1162/014892602320582981
   Wigdor D, 2011, BRAVE NUI WORLD: DESIGNING NATURAL USER INTERFACES FOR TOUCH AND GESTURE, P1
   Young GW, 2015, INT S COMP MUS MULT
NR 27
TC 10
Z9 10
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13713
EP 13730
DI 10.1007/s11042-018-6917-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900048
DA 2024-07-18
ER

PT J
AU Teng, JN
   Zhang, D
   Lee, DJ
   Chou, Y
AF Teng, Jianing
   Zhang, Dong
   Lee, Dah-Jye
   Chou, Yao
TI Recognition of Chinese food using convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chinese food; Recognition; Convolutional neural network; Bag-of-features
   model
AB Food recognition is the first step for dietary assessment. Computer vision technology is being viewed as an effective tool for automatic food recognition for monitoring nutrition intake. Of the many food recognition algorithms in the literature, Bag-of-Features model is a proven approach that has shown impressive recognition accuracy. In this paper, we propose a small and efficient convolutional neural network architecture for Chinese food recognition, which is more applicable for resources limited platforms. Our network architecture is designed to model and perform a pipeline of processing similar to the Bag-of-Features approach. The main advantage of the proposed architecture, like other convolutional neural networks, is its ability to unifiedly optimize the entire network through back propagation, which is critical to recognition accuracy. We further compare and correlate our architecture with the traditional Bag-of-Features model in an attempt to investigate the similarities between them and identify factors that influence the recognition accuracy. The proposed architecture with a 5-layer deep convolutional neural network achieves the top-1 accuracy of 97.12% and the top-5 accuracy of 99.86% on a newly created Chinese food image dataset that is composed of 8734 images of 25 food categories. Our experimental result demonstrates the feasibility of applying the proposed compact CNN architecture to a challenging problem and achieve real-time performance.
C1 [Teng, Jianing; Zhang, Dong] Sun Yat Sen Univ, Sch Elect & Informat Technol, Guangzhou, Guangdong, Peoples R China.
   [Teng, Jianing; Zhang, Dong; Lee, Dah-Jye; Chou, Yao] SYSU CMU Shunde Int Joint Res Inst, Shunde, Foshan, Peoples R China.
   [Lee, Dah-Jye; Chou, Yao] Brigham Young Univ, Dept Elect & Comp Engn, Provo, UT 84602 USA.
C3 Sun Yat Sen University; Brigham Young University
RP Zhang, D (corresponding author), Sun Yat Sen Univ, Sch Elect & Informat Technol, Guangzhou, Guangdong, Peoples R China.; Zhang, D (corresponding author), SYSU CMU Shunde Int Joint Res Inst, Shunde, Foshan, Peoples R China.
EM zhangd@mail.sysu.edu.cn
RI Chou, Yao/ABH-5192-2020
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], NY TIMES
   [Anonymous], 2015, P IEEE INT C MULT EX
   [Anonymous], 2014, P 2014 ACM INT JOINT
   [Anonymous], FOOD NUTR DAT DIET S
   [Anonymous], 2016, P 24 ACM INT C MULTI
   [Anonymous], H HN
   [Anonymous], 2016, ARXIV160708194
   [Anonymous], 2012, SIGGRAPH ASIA 2012 T
   Anthimopoulos MM, 2014, IEEE J BIOMED HEALTH, V18, P1261, DOI 10.1109/JBHI.2014.2308928
   Ashkan A, 2017, N Engl J Med, V377
   Bleich S, 2008, ANNU REV PUBL HEALTH, V29, P273, DOI 10.1146/annurev.publhealth.29.020907.090954
   Chen JJ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P32, DOI 10.1145/2964284.2964315
   Chen M, 2009, IEEE IMAGE PROC, P289, DOI 10.1109/ICIP.2009.5413511
   Ciocca G, 2017, IEEE J BIOMED HEALTH, V21, P588, DOI 10.1109/JBHI.2016.2636441
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Farinella GM, 2014, IEEE IMAGE PROC, P5212, DOI 10.1109/ICIP.2014.7026055
   Giovany S, 2017, PROCEDIA COMPUT SCI, V116, P612, DOI 10.1016/j.procs.2017.10.020
   Haslam DW, 2005, LANCET, V366, P1197, DOI 10.1016/S0140-6736(05)67483-1
   Kawano Y, 2015, MULTIMED TOOLS APPL, V74, P5263, DOI 10.1007/s11042-014-2000-8
   Kawano Y, 2013, IEEE COMPUT SOC CONF, P1, DOI 10.1109/CVPRW.2013.5
   Lin M., 2013, P 2 INT C LEARNING R
   Luan SZ, 2018, IEEE T IMAGE PROCESS, V27, P4357, DOI 10.1109/TIP.2018.2835143
   Luppino FS, 2010, ARCH GEN PSYCHIAT, V67, P220, DOI 10.1001/archgenpsychiatry.2010.2
   Martin CK, 2009, IEEE ENG MED BIO, P6869, DOI 10.1109/IEMBS.2009.5333123
   Matsuda Y., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P25, DOI 10.1109/ICME.2012.157
   Shroff G, 2008, TWELFTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P119, DOI 10.1109/ISWC.2008.4911602
   Phat TV, 2017, INT CONF KNOWL SYS, P124, DOI 10.1109/KSE.2017.8119446
   Wang L, 2016, SIGNAL PROCESS-IMAGE, V47, P490, DOI 10.1016/j.image.2016.06.002
   Yang HY, 2016, SPRINGER PROTOC HAND, P3, DOI 10.1007/978-1-4939-3308-2_1
   Yang S, 2010, PROC CVPR IEEE, P2249, DOI 10.1109/CVPR.2010.5539907
   Zhang WS, 2015, IEEE 12TH INT CONF UBIQUITOUS INTELLIGENCE & COMP/IEEE 12TH INT CONF ADV & TRUSTED COMP/IEEE 15TH INT CONF SCALABLE COMP & COMMUN/IEEE INT CONF CLOUD & BIG DATA COMP/IEEE INT CONF INTERNET PEOPLE AND ASSOCIATED SYMPOSIA/WORKSHOPS, P690, DOI 10.1109/UIC-ATC-ScalCom-CBDCom-IoP.2015.139
   Zhao JJ, 2018, IEEE T CIRC SYST VID, V28, P2679, DOI 10.1109/TCSVT.2017.2710120
   Zhu FQ, 2010, IEEE J-STSP, V4, P756, DOI 10.1109/JSTSP.2010.2051471
NR 34
TC 17
Z9 18
U1 3
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11155
EP 11172
DI 10.1007/s11042-018-6695-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900004
DA 2024-07-18
ER

PT J
AU Yi, Y
   Luo, LP
   Zheng, ZX
AF Yi, Yang
   Luo, Liping
   Zheng, Zhenxian
TI Single online visual object tracking with enhanced tracking and
   detection learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single online visual object tracking; Pyramid optical flow; Correlation
   filter; Detection learning
AB Single online visual object tracking has been an active research topic for its wide application on various tasks. In this paper, a new framework and related approaches are proposed to solve this problem consisting of enhanced tracking and detection learning. In the enhanced tracking part, an appearance model based on correlation filter with deep CNN features and a dynamic model using improved pyramid optical flow method are employed. Two models cooperate together to depict object appearance and capture target trajectory, which also contribute to provide training samples for detection learning. In the detection learning part, a cascade classifier and P-N learning scheme are employed to reinitialize tracking when model drift occurs. Data experiments on several challenging benchmarks show that the presented method is comparable to the state-of-the-art.
C1 [Yi, Yang; Luo, Liping; Zheng, Zhenxian] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
   [Yi, Yang] Sun Yat Sen Univ, Xinhua Coll, Sch Informat Sci, Guangzhou, Guangdong, Peoples R China.
   [Yi, Yang] Guangdong Prov Key Lab Big Data Anal & Proc, Guangzhou, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University
RP Yi, Y (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.; Yi, Y (corresponding author), Sun Yat Sen Univ, Xinhua Coll, Sch Informat Sci, Guangzhou, Guangdong, Peoples R China.; Yi, Y (corresponding author), Guangdong Prov Key Lab Big Data Anal & Proc, Guangzhou, Guangdong, Peoples R China.
EM issyy@mail.sysu.edu.cn
RI Yi, Yang/AFP-5892-2022
OI ZHENG, Zhenxian/0000-0002-6546-2324
FU National Natural Science Foundation of China [61672546, 61573385];
   Guangzhou Science and Technology Project [201707010127]
FX The authors would like to thank Fang Li for her insightful comments and
   help in collecting data which have greatly helped us to improve the
   technical contents and experiments of the study. This work was partly
   supported by National Natural Science Foundation of China (No. 61672546
   and No. 61573385), and Guangzhou Science and Technology Project (No.
   201707010127).
CR Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   [Anonymous], 2014, PROC IEEE C COMPUTER, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]
   [Anonymous], 2014, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-10599-4_13
   [Anonymous], 2014, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.230
   [Anonymous], IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2016.2572683
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], 2017, 2017 IEEE INT C SIGN
   Bailer C, 2017, OPTICAL FLOW FIELDS, P4015
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Choi J, 2017, PROC CVPR IEEE, P4828, DOI 10.1109/CVPR.2017.513
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2016.159
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gladh S, 2016, DEEP MOTION FEATURES
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Hua Y, 2014, EUR C COMP VIS
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kristan M, 2016, IEEE T PATTERN ANAL, V38, P2137, DOI 10.1109/TPAMI.2016.2516982
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li H, 2014, DEEPTRACK LEARNING D
   Li T, 2018, INFORM SCI, P444
   Li Y, 2017, PATTERN RECOGN, P75
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Li Z., 2018, IEEE T IND INFORM
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu G., 2017, IEEE COMMUNICATIONS, VPP, P1
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Ning JF, 2016, PROC CVPR IEEE, P4266, DOI 10.1109/CVPR.2016.462
   Pfister T, 2015, IEEE I CONF COMP VIS, P1913, DOI 10.1109/ICCV.2015.222
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Sadeghian A, 2017, IEEE I CONF COMP VIS, P300, DOI 10.1109/ICCV.2017.41
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Supancic JS, 2013, PROC CVPR IEEE, P2379, DOI 10.1109/CVPR.2013.308
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang J, 2017, IEEE WINT CONF APPL, P168, DOI 10.1109/WACV.2017.26
   Wang L, 2015, IEEE T IMAGE PROCESS, V24, P1424, DOI 10.1109/TIP.2015.2403231
   Wang N., 2013, Advances in Neural Information Processing Systems, P809
   Weiyu Zhang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2393, DOI 10.1109/CVPR.2011.5995342
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xing JL, 2013, IEEE I CONF COMP VIS, P665, DOI 10.1109/ICCV.2013.88
   Yi Y, 2013, NOVEL VIDEO SALIENT
   Yi Y, 2016, PATTERN RECOGN, V53, P148, DOI 10.1016/j.patcog.2015.11.022
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang BC, 2017, IEEE T SYST MAN CY-S, V47, P693, DOI 10.1109/TSMC.2016.2629509
   Zhu X, 2016, DEEP FEATURE FLOW VI
   Zhu XZ, 2017, IEEE I CONF COMP VIS, P408, DOI 10.1109/ICCV.2017.52
   Zou W., 2012, ADV NEURAL INFORM PR, V25, P3203, DOI DOI 10.5555/2999325.2999492
NR 62
TC 5
Z9 5
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12333
EP 12351
DI 10.1007/s11042-018-6787-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900056
DA 2024-07-18
ER

PT J
AU Lakshmi, C
   Thenmozhi, K
   Rayappan, JBB
   Amirtharajan, R
AF Lakshmi, C.
   Thenmozhi, K.
   Rayappan, John Bosco Balaguru
   Amirtharajan, Rengarajan
TI Open hiding for truncating hackers - a block truncation and wavelet
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tamper detection; Copyright protection; Integer wavelet transform (IWT);
   Block truncation code (BTC)
ID IMAGE AUTHENTICATION; FRAGILE WATERMARKING; SCHEME
AB Authentication of images with a focus on tamper proofing requires a critical attention. While most of the watermarking schemes look to assist authentication through data concealing in specific section, reversibility of the cover images remains a challenge to be addressed. Post tampering retrieval of the cover associated with the watermarking is the prime objective of this work. The key elements involved in this work are Integer Wavelet Transform (IWT) and Block Truncation Code (BTC). After application of IWT on the chosen cover image, the BTC generated from the HH sub band will be embedded in select regions of the LL sub band of the transformed image. BTC has been employed in this approach and tested for various pixel block sizes namely 2x2, 4x4 and 8x8 in the preferred HH sub band which carry the edge information. While the imperceptibility of recovered cover image was commendable through this reversible scheme, the suggested approach also withstands noticeably against a variety of image processing attacks.
C1 [Lakshmi, C.; Thenmozhi, K.; Rayappan, John Bosco Balaguru; Amirtharajan, Rengarajan] SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Amirtharajan, R (corresponding author), SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
EM lakshmi_c@ece.sastra.edu; thenmozhik@ece.sastra.edu;
   rjbosco@ece.sastra.edu; amir@ece.sastra.edu
RI Ramesh, Lakshmi/AAM-5630-2020; Amirtharajan, Rengarajan/C-6471-2011;
   Rayappan, John Bosco Balaguru/K-6842-2013
OI Ramesh, Lakshmi/0000-0001-5714-4150; Amirtharajan,
   Rengarajan/0000-0003-1574-3045; Rayappan, John Bosco
   Balaguru/0000-0003-4641-9870; Karuppuswamy,
   Thenmozhi/0000-0001-9829-0189
CR Abu-marie W, 2010, INT J SIGNAL IMAGE P, V1
   Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   [Anonymous], 2014, INT C ADV ENG TECHN
   [Anonymous], 4 IEEE GCC C EXH
   Antonio J, 2011, INT J COMPUT, V5
   Chan CS, 2007, PATTERN RECOGN, V40, P681, DOI 10.1016/j.patcog.2006.05.018
   Chang CC, 2018, MULTIMED TOOLS APPL, V77, P9039, DOI 10.1007/s11042-017-4800-0
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen TH, 2018, MULTIMED TOOLS APPL, V77, P12979, DOI 10.1007/s11042-017-4927-z
   Chen YY, 2019, MULTIMEDIA SYST, V25, P551, DOI 10.1007/s00530-017-0560-y
   Chin-Chen Chang, 2014, International Journal of Network Security, V16, P208
   Choi KS, 2013, DIGIT SIGNAL PROCESS, V23, P1171, DOI 10.1016/j.dsp.2013.03.008
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Guo JM, 2009, IEEE INT SYMP CIRC S, P1077, DOI 10.1109/ISCAS.2009.5117946
   Gutub A, SYST SCI, P5
   Gutub A, 2018, J. Comput. Hardw. Eng, V1, P1
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Kim C, 2018, PERS UBIQUIT COMPUT, V22, P11, DOI 10.1007/s00779-017-1061-x
   Li W, 2016, MULTIMED TOOLS APPL, V75, P4771, DOI 10.1007/s11042-015-2502-z
   Lin CC, 2017, MULTIMED TOOLS APPL, V76, P463, DOI 10.1007/s11042-015-3059-6
   Lin CC, 2015, MULTIMED TOOLS APPL, V74, P3823, DOI 10.1007/s11042-013-1801-5
   Mohammad N, 2017, MULTIMED TOOLS APPL, V76, P13301, DOI 10.1007/s11042-016-3757-8
   Huynh NT, 2018, MULTIMED TOOLS APPL, V77, P5767, DOI 10.1007/s11042-017-4487-2
   Nguyen TS, 2016, AEU-INT J ELECTRON C, V70, P1055, DOI 10.1016/j.aeue.2016.05.003
   Parashar P., 2014, International Journal of Signal Processing, Image Processing and Pattern Recognition, V7, P111, DOI DOI 10.14257/IJSIP.2014.7.6.10
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Qin C, 2016, INFORM SCIENCES, V361, P84, DOI 10.1016/j.ins.2016.04.036
   Shaik A., 2017, Journal of Artificial Intelligence, V10, P1, DOI DOI 10.3923/JAI.2017.1.21
   Singh D, 2019, MULTIMED TOOLS APPL, V78, P4197, DOI 10.1007/s11042-017-5454-7
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Zargar AJ, 2016, INT J ELECTRON SECUR, V8, P53, DOI 10.1504/IJESDF.2016.073734
   Zeki A, 2011, RES J INFORM TECHNOL, V3, P123, DOI DOI 10.3923/RJIT.2011.123.131
   Zhang ZW, 2017, EURASIP J ADV SIG PR, DOI 10.1186/s13634-017-0450-7
NR 35
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 9951
EP 9969
DI 10.1007/s11042-018-6549-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400021
DA 2024-07-18
ER

PT J
AU Lv, CZ
   Wu, YS
   Fan, D
   Lu, XS
AF Lv, Changzhi
   Wu, Yingshuai
   Fan, Di
   Lu, Xiushan
TI Fast registration of UAV aerial images based on improved optical-flow
   model combined with feature-point matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image registration; UAV image; Optical-flow model; Feature-point
   matching; Coarse-fine stage
ID METAANALYSIS
AB With a large number of registration algorithms proposed, image registration techniques have achieved rapid development. However, there still exist many deficiencies in aerial images registration where high speed and accuracy are difficult to simultaneously achieve for real-time processing. In order to achieve large-scale and high-precision image registration for unmanned aerial vehicle(UAV) aerial images, a novel and fast sub-pixel image registration algorithm based on improved optical-flow model combined with feature-point matching is proposed in this paper. Firstly, the coarse selection at the feature level is achieved by using the feature-point model, which reduces the number of non-feature points so as to speed up the coarse registration process. Then, the improved pyramid optical-flow model is adopted in the neighborhood of the coarse point, and the sub-pixel fast location is achieved by the bidirectional search strategy. Simulation experiment results show that compared with common image registration based LK optical-flow or feature-point matching, our proposed algorithm will greatly reduce space complexity and time complexity without losing accuracy.
C1 [Lv, Changzhi; Wu, Yingshuai; Fan, Di; Lu, Xiushan] Shandong Univ Sci & Technol, 579 Qianwangang Rd, Qingdao 266590, Shandong, Peoples R China.
C3 Shandong University of Science & Technology
RP Lv, CZ (corresponding author), Shandong Univ Sci & Technol, 579 Qianwangang Rd, Qingdao 266590, Shandong, Peoples R China.
EM 18811354230@163.com
FU National Science Foundation for Young Scientists of China [61703242,
   61503224]; first batch of cooperative education projects of the Ministry
   of education in 2017 [201701065008]; postgraduate science and technology
   innovation project of Shandong University of Science and Technology in
   2018 [SDKDYC180234]
FX National Science Foundation for Young Scientists of China (61703242,
   61503224), The first batch of cooperative education projects of the
   Ministry of education in 2017(201701065008), postgraduate science and
   technology innovation project of Shandong University of Science and
   Technology in 2018 (SDKDYC180234).
CR [Anonymous], ARXIV180301790
   [Anonymous], VIDEO ENG
   [Anonymous], COMPUTER SCI
   [Anonymous], TIP
   [Anonymous], 2006, PROCEDINGS BRIT MACH, DOI DOI 10.5244/C.20.40
   [Anonymous], 2006, IEEE T MAGN, DOI DOI 10.1109/20.312561
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Baker S., 2002, Lucas-kanade 20 years on: A unifying framework: Part 1
   Bigot J, 2009, SIAM J IMAGING SCI, V2, P614, DOI 10.1137/070691231
   BRACEWELL RN, 1993, ELECTRON LETT, V29, P304, DOI 10.1049/el:19930207
   CHEN QS, 1994, IEEE T PATTERN ANAL, V16, P1156
   Ho HT, 2008, P 2008 IEEE C COMPUT, P1
   Lucey S, 2013, IEEE T PATTERN ANAL, V35, P1383, DOI 10.1109/TPAMI.2012.220
   Mazard A, 2004, EUR J COGN PSYCHOL, V16, P673, DOI 10.1080/09541440340000484
   Modinos G, 2013, CORTEX, V49, P1046, DOI 10.1016/j.cortex.2012.01.009
   Onofrey JA, 2015, IEEE T MED IMAGING, V34, P1522, DOI 10.1109/TMI.2015.2404572
   Onofrey JA, 2013, I S BIOMED IMAGING, P580
   Onyango FA, 2017, INT ARCH PHOTOGRAMM, V42-1, P599, DOI 10.5194/isprs-archives-XLII-1-W1-599-2017
   Shattuck DW, 2008, NEUROIMAGE, V39, P1064, DOI 10.1016/j.neuroimage.2007.09.031
   Tang ZH, 2017, J PHYS CONF SER, V787, DOI 10.1088/1742-6596/787/1/012008
   Tsai CH, 2017, ISPRS J PHOTOGRAMM, V128, P130, DOI 10.1016/j.isprsjprs.2017.03.017
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Vishnevskiy V, 2017, IEEE T MED IMAGING, V36, P385, DOI 10.1109/TMI.2016.2610583
   Wang SY, 2017, ELS MIC SOC BOOK SER, P245, DOI 10.1016/B978-0-12-810408-8.00015-8
   Wei ZQ, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9090904
   Yang X, 2017, 2017 PROGRESS IN ELECTROMAGNETICS RESEARCH SYMPOSIUM - SPRING (PIERS), P2554, DOI 10.1109/PIERS.2017.8262182
   Yousef A, 2015, IEEE SIGNAL PROC LET, V22, P1796, DOI 10.1109/LSP.2015.2437881
   Zhang MJ, 2018, ROUTL CONTEMP CHINA, P1, DOI 10.1109/ICNSC.2018.8361272
   Zhuo XY, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9040376
NR 29
TC 6
Z9 7
U1 8
U2 56
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8875
EP 8887
DI 10.1007/s11042-018-6580-6
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800054
DA 2024-07-18
ER

PT J
AU Zou, LM
   Sun, JD
   Gao, M
   Wan, WB
   Gupta, BB
AF Zou, Liming
   Sun, Jiande
   Gao, Min
   Wan, Wenbo
   Gupta, Brij Bhooshan
TI A novel coverless information hiding method based on the average pixel
   value of the sub-images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Coverless information hiding; Sub-images; Average pixel value;
   Multi-level index structure
ID STEGANOGRAPHY; STEGANALYSIS; DOMAIN
AB In traditional information hiding methods, the secret information is embedded into the carriers, which will inevitably leave traces of modification on the carriers. In those methods, the modified images can be easily detected by some steganalysis algorithm and thus the security can not be guaranteed. To address this problem, the concept of coverless information hiding is proposed. However, general coverless information hiding method has a lower information hiding capacity. In this paper, we propose a novel coverless information hiding method based on the average pixel values of sub-images. We generate hash sequences by a hashing algorithm and realize the secret information hiding through mapping relationship. In the first place, we build a dictionary and a hash array. Then we map the dictionary and the hash array through mapping relationship. Furthermore, we build a multi-level index structure for retrieving the stego-images efficiently. The experimental results and analysis show that our method has a good performance in the capacity of information hiding, the security, the robustness to image attacks and the hiding success rate based on different image databases.
C1 [Zou, Liming; Sun, Jiande; Gao, Min; Wan, Wenbo] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Shandong, Peoples R China.
   [Gupta, Brij Bhooshan] Natl Inst Technol, Dept Comp Engn, Thanesar, Haryana, India.
C3 Shandong Normal University
RP Sun, JD; Wan, WB (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Shandong, Peoples R China.
EM jiandesun@hotmail.com; wanwenbo@sdnu.edu.cn
RI Gupta, Brij B/E-9813-2011
OI Gupta, Brij B/0000-0003-4929-4698
FU Natural Science Foundation of China [U1736122]; Natural Science
   Foundation for Distinguished Young Scholars of Shandong Province
   [JQ201718]; Shandong Provincial Key Research and Development Plan
   [2017CXGC1504]
FX This work is supported by the Natural Science Foundation of China
   (U1736122), the Natural Science Foundation for Distinguished Young
   Scholars of Shandong Province (JQ201718) and Shandong Provincial Key
   Research and Development Plan (2017CXGC1504).
CR Cao Y, 2018, CMC-COMPUT MATER CON, V54, P197, DOI 10.3970/cmc.2018.054.197
   Chang CC, 2009, J VIS COMMUN IMAGE R, V20, P57, DOI 10.1016/j.jvcir.2008.08.005
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen WY, 2007, APPL MATH COMPUT, V185, P432, DOI 10.1016/j.amc.2006.07.041
   COX IJ, 2002, J APPL SIGN PROC, V50, P126
   GUO L, 2015, INFO, V10, P2669, DOI DOI 10.1109/TIFS.2015.2473815
   Hirohisa H, 2002, DATA EMBEDDING METHO
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Kawaguchi E, 2005, LECT NOTES ARTIF INT, V3684, P289
   Ker AD, 2004, LECT NOTES COMPUT SC, V3200, P97
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Li XX, 2007, INFORM SCIENCES, V177, P3099, DOI 10.1016/j.ins.2007.02.008
   LI Z, 2009, IEEE, V1, P588, DOI DOI 10.1109/ICCET.2009.40
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Ma Y, 2019, IEEE T CONTR SYST T, V27, P1788, DOI 10.1109/TCST.2018.2819965
   Mckeon R.T., 2007, P IEEE COMP SOC 2007, P178
   Meng RH, 2018, CMC-COMPUT MATER CON, V55, P1, DOI 10.3970/cmc.2018.055.001
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Pevny T, 2013, P SPIE INT SOC OPTIC, V3
   Ren XX, 2018, IEEE ACCESS, V6, P2952, DOI 10.1109/ACCESS.2017.2786271
   Wan WB, 2015, ELECTRON LETT, V51, P758, DOI 10.1049/el.2014.4329
   Wan WB, 2013, IEEE IMAGE PROC, P4522, DOI 10.1109/ICIP.2013.6738931
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Yuan C, 2017, INTERNET J TECHNOL, V18
   Yuan ZQ, 2017, 2017 IEEE/ACIS 15TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT AND APPLICATIONS (SERA), P169, DOI 10.1109/SERA.2017.7965724
   Zhang JH, 2016, LECT NOTES COMPUT SC, V10066, P145, DOI 10.1007/978-3-319-49148-6_13
   Zhang Y, 2018, SIGNAL PROCESSING
   Zheng SL, 2017, LECT NOTES ARTIF INT, V10363, P536, DOI 10.1007/978-3-319-63315-2_47
   Zhili Zhou, 2015, Cloud Computing and Security. First International Conference, ICCCS 2015. Revised Selected Papers: LNCS 9483, P123, DOI 10.1007/978-3-319-27051-7_11
   Zhou QL, 2018, CMC-COMPUT MATER CON, V55, P151, DOI [10.3970/cmc.2018.055.15l, 10.3970/cmc.2018.055.151]
NR 35
TC 60
Z9 65
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 7965
EP 7980
DI 10.1007/s11042-018-6444-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800005
DA 2024-07-18
ER

PT J
AU Gutub, A
   Al-Juaid, N
   Khan, E
AF Gutub, Adnan
   Al-Juaid, Nouf
   Khan, Esam
TI Counting-based secret sharing technique for multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret sharing; Key management; Shares generation; Information security;
   Key distribution technique
ID MONTGOMERY INVERSION; ARCHITECTURE
AB Secret Sharing is required in situations where access to important resources has to be protected by more than one person. We propose new secret-sharing scheme that works based on parallel counting of the ones within the shares to generate the secret output. Our work presented two different modeling variations that are mainly different in the secret-sharing keys generation where both are studied elaborating their pros and cons. Our counting-based secret shares key reconstruction is implemented and simulated considering the security level required by the usage functions. Comparisons showed interesting results that are attractive to be considered. This secret sharing method is of great benefit to all multimedia secret sharing applications such as securing bank sensitive accounts and error tracking, voting systems trust, medical agreements, wills and inheritance authentication management.
C1 [Gutub, Adnan] Umm Al Qura Univ, Comp Engn Dept, Mecca, Saudi Arabia.
   [Al-Juaid, Nouf] Shaqra Univ, Riyadh, Saudi Arabia.
   [Khan, Esam] Umm Al Qura Univ, Custodian Two Holy Mosques Inst Hajj & Umrah Res, Mecca, Saudi Arabia.
C3 Umm Al Qura University; Shaqra University; Umm Al Qura University
RP Gutub, A (corresponding author), Umm Al Qura Univ, Comp Engn Dept, Mecca, Saudi Arabia.
EM aagutub@uqu.edu.sa; naljuaid@su.edu.sa; eakhan@uqu.edu.sa
RI Gutub, Adnan Abdul-Aziz/O-1240-2016; Khan, Esam/AAW-1937-2020; Aljuaid,
   Nouf/O-4678-2017
OI Gutub, Adnan Abdul-Aziz/0000-0003-0923-202X; Aljuaid,
   Nouf/0000-0002-4430-8395
CR Ahmadoh Esraa Mohammad, 2015, Lecture Notes on Information Theory, V3, P42, DOI 10.18178/lnit.3.1.42-47
   ASMUTH C, 1983, IEEE T INFORM THEORY, V29, P208, DOI 10.1109/TIT.1983.1056651
   Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   Blundo C, 1996, THEOR COMPUT SCI, V165, P407, DOI 10.1016/0304-3975(96)00003-5
   Blundo C, 1993, P 1 FRENCH ISR WORKS, P19
   Gutub A, 2003, 9 ANN GULF INT S KHO
   Gutub A. A.-A., 2007, INT ARAB J INF TECHN, V4, P1
   Gutub AAA, 2007, IET COMPUT DIGIT TEC, V1, P389, DOI 10.1049/iet-cdt:20060183
   Gutub AA-A., 2010, INT J SECUR, V4, P46
   Gutub AAA, 2004, INTEGRATION, V37, P103, DOI 10.1016/j.vlsi.2003.12.001
   Gutub AAA, 1999, ICM'99: ELEVENTH INTERNATIONAL CONFERENCE ON MICROELECTRONICS - PROCEEDINGS, P173
   Gutub AAA, 2007, KUWAIT J SCI ENG, V34, P165
   Herzberg A, 1995, LECT NOTES COMPUT SC, V963, P339
   Krawczyk Hugo, 1993, Proceedings of the 13th Annual International Cryptology Conference on Advances in Cryptology, P136
   LAIH CS, 1990, LECT NOTES COMPUT SC, V435, P286
   MCELIECE RJ, 1981, COMMUN ACM, V24, P583, DOI 10.1145/358746.358762
   Ogata W, 2006, SIAM J DISCRETE MATH, V20, P79, DOI 10.1137/S0895480100378689
   Savas E, 2005, IEE P-COMPUT DIG T, V152, P489, DOI 10.1049/ip-cdt:20059032
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Tassa T, 2007, J CRYPTOL, V20, P237, DOI 10.1007/s00145-006-0334-8
   Wang K, 2009, P INT COMP SOFTW APP, P400, DOI 10.1109/COMPSAC.2009.60
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P10521, DOI 10.1007/s11042-017-4554-8
NR 22
TC 116
Z9 118
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5591
EP 5619
DI 10.1007/s11042-017-5293-6
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100029
DA 2024-07-18
ER

PT J
AU Kalpana, M
   Ratnavelu, K
   Balasubramaniam, P
AF Kalpana, M.
   Ratnavelu, K.
   Balasubramaniam, P.
TI An audio encryption based on synchronization of robust BAM FCNNs with
   time delays
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bidirectional associative memory; Chaos; Encryption; Fuzzy cellular
   neural networks; Linear matrix inequality
ID CELLULAR NEURAL-NETWORKS; STABILITY
AB In this work, authors' proposed an audio encryption based on synchronization of hybrid bidirectional associative memory (BAM) and fuzzy cellular neural networks (FCNNs) with time delays. Here, the significant effort is to find the values of the parameters A, B, D, alpha, beta, (A) over tilde, (B) over tilde, (D) over tilde, (alpha) over tilde, (beta) over tilde, L, (L) over tilde, O-d, (O) over tilde (d), O-a, (O) over tilde (a), O-b, (O) over tilde (b), of the given robust BAM FCNNs system to obtain the dynamical signal (chaotic) which are used to encrypt an audio file and satisfy the condition of Linear matrix inequality (LMI) by choosing suitable Lyapunov-Krasovskii functional (LKF). Further, the key sensitivity of order 10(-10) of this proposed method have massive key space to make brute-force attack infeasible. Numerical simulations, results and discussions along with comparison are provided to illustrate the effectiveness and merits of the proposed scheme.
C1 [Kalpana, M.; Ratnavelu, K.] Univ Malaya, Fac Sci, Inst Math Sci, Kuala Lumpur 50603, Malaysia.
   [Balasubramaniam, P.] Deemed Univ, Gandhigram Rural Inst, Dept Math, Gandhigram 624302, Tamil Nadu, India.
C3 Universiti Malaya; Gandhigram Rural Institute
RP Ratnavelu, K (corresponding author), Univ Malaya, Fac Sci, Inst Math Sci, Kuala Lumpur 50603, Malaysia.
EM kuru052001@gmail.com
RI P, Balasubramaniam/O-3041-2013; Ratnavelu, Kurunathan/A-5463-2009;
   Kalpana, M./G-6639-2016
OI Kalpana, M./0000-0003-0605-6657
FU Fundamental Research Grant Scheme (FRGS) MoHE Grant [FP051-2016]
FX This work was supported by the Fundamental Research Grant Scheme (FRGS)
   MoHE Grant No. FP051-2016. Dr. M. Kalpana is working as a Post-Doctoral
   Research Fellow at the University of Malaya.
CR Abdurahman A, 2016, FUZZY SET SYST, V297, P96, DOI 10.1016/j.fss.2015.07.009
   Babu SG, 2013, IEEE SYM COMPUT INTE, P52, DOI 10.1109/CICYBS.2013.6597206
   Balakrishnan, 1994, LINEAR MATRIX INEQUA, V15, DOI DOI 10.1137/1.9781611970777
   Balasubramaniam P, 2011, MATH COMPUT MODEL, V53, P839, DOI 10.1016/j.mcm.2010.10.021
   Bigdeli N, 2012, ENG APPL ARTIF INTEL, V25, P753, DOI 10.1016/j.engappai.2012.01.007
   CARROLL TL, 1991, IEEE T CIRCUITS SYST, V38, P453, DOI 10.1109/31.75404
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Jawahir A., 2015, INT J ADV INTELL INF, V1, P98, DOI [10.26555/ijain.v1i2.24, DOI 10.26555/IJAIN.V1I2.24]
   Kalpana M, 2015, APPL MATH COMPUT, V254, P291, DOI 10.1016/j.amc.2014.12.133
   KOSKO B, 1988, IEEE T SYST MAN CYB, V18, P49, DOI 10.1109/21.87054
   KOSKO B, 1987, APPL OPTICS, V26, P4947, DOI 10.1364/AO.26.004947
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Lian SG, 2009, NEUROCOMPUTING, V72, P1296, DOI 10.1016/j.neucom.2008.11.005
   Lima JB, 2016, MULTIMED TOOLS APPL, V75, P8403, DOI 10.1007/s11042-015-2755-6
   Liu HJ, 2016, OPTIK, V127, P7431, DOI 10.1016/j.ijleo.2016.05.073
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Nadir Jihad, 2016, International Journal of Computer and Information Technology, V5, P465
   Parvaz R, 2018, OPT LASER TECHNOL, V101, P30, DOI 10.1016/j.optlastec.2017.10.024
   Prabu AV., 2012, INT J COMPUTER APPL, V40, P40
   Rakkiyappan R, 2017, NONLINEAR ANAL-HYBRI, V24, P28, DOI 10.1016/j.nahs.2016.10.004
   Ratnavelu K, 2017, SIGNAL PROCESS, V140, P87, DOI 10.1016/j.sigpro.2017.05.002
   Ratnavelu K, 2015, APPL MATH COMPUT, V270, P582, DOI 10.1016/j.amc.2015.07.061
   Sakthivel R, 2015, INFORM SCIENCES, V296, P263, DOI 10.1016/j.ins.2014.10.063
   Wan L, 2017, CHAOS SOLITON FRACT, V101, P68, DOI 10.1016/j.chaos.2017.05.017
   Wang Y, 2018, NEUROCOMPUTING, V275, P1318, DOI 10.1016/j.neucom.2017.09.068
   Wen SP, 2015, IEEE T NEUR NET LEAR, V26, P1493, DOI 10.1109/TNNLS.2014.2387355
   Wong KW, 2010, IEEE T CIRCUITS-II, V57, P146, DOI 10.1109/TCSII.2010.2040315
   Yang RN, 2009, IEEE T SYST MAN CY B, V39, P467, DOI 10.1109/TSMCB.2008.2006860
   Yang T, 1996, IEEE T CIRCUITS-I, V43, P880, DOI 10.1109/81.538999
   Yang YG, 2015, OPTIK, V126, P3221, DOI 10.1016/j.ijleo.2015.07.082
   Yu ZX, 2016, J DIFFER EQUATIONS, V260, P241, DOI 10.1016/j.jde.2015.08.037
   Zhou YC, 2015, IEEE T CYBERNETICS, V45, P2001, DOI 10.1109/TCYB.2014.2363168
NR 36
TC 16
Z9 16
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5969
EP 5988
DI 10.1007/s11042-018-6373-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100046
DA 2024-07-18
ER

PT J
AU Lee, MR
   Lin, DT
AF Lee, Meng-Rong
   Lin, Daw-Tung
TI Vehicle counting based on a stereo vision depth maps for parking
   management
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent parking lot; Vehicle counting; Stereo computer vision; Depth
   maps; Modified sigmoid function
AB Automated parking management systems provide convenience and efficiency, and such systems are increasingly being deployed in modern urban areas. To facilitate the crucial function of vehicle counting in several applications, we developed a novel mechanism for counting vehicles based on stereoscopic computer vision with depth perception. In this study, we first established depth maps of pairs of images captured using stereo cameras through a scene flow-based approach. Next, we designed a modified sigmoid function to change the histogram distribution in the obtained depth maps by using the disparity threshold estimated from a disparity calibration board. Then, we proposed a vehicle counting mechanism using the modified disparity histogram; this mechanism can be used to easily determine the presence of a vehicle. Consequently, we applied the proposed vehicle detection and counting method to a surveillance camera and used it to determine whether vehicles were approaching an entrance; this camera captured a clear photograph of each license plate, which was then used for automatic recognition. The proposed system was evaluated using nine sets of video data recorded in an indoor parking garage and an outdoor parking lot. The experimental results quantified our method's high performance and robustness in vehicle counting. For the indoor parking garage, the precision and recall were 99.56% and 98.29%, respectively. For the outdoor parking lot environment, the vehicle counting precision and recall were 98.85% and 98.85%, respectively. Our method was able to avoid counting errors when distinguishing between closely spaced adjacent vehicles.
C1 [Lee, Meng-Rong; Lin, Daw-Tung] Natl Taipei Univ, Dept Comp Sci & Informat Engn, New Taipei, Taiwan.
C3 National Taipei University
RP Lin, DT (corresponding author), Natl Taipei Univ, Dept Comp Sci & Informat Engn, New Taipei, Taiwan.
EM monemo12@gmail.com; dalton@mail.ntpu.edu.tw
RI Lin, Daw-Tung/B-7043-2009
OI Lin, Daw-Tung/0000-0003-3261-806X
CR [Anonymous], 2000, TECH REP
   [Anonymous], 1981, Proceedings of the 7th International Joint Conference on Artificial Intelligence
   [Anonymous], 2001, PYRAMIDAL IMPLEMENTA
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   [Anonymous], P SPIE
   [Anonymous], INT J COMPUTER APPL
   [Anonymous], BMVC
   Bouguet J.-Y., 2004, CAMERA CALIBRATION T
   Cech J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3129, DOI 10.1109/CVPR.2011.5995442
   Cech J., 2007, IEEE Conference on Computer Vision and Pattern Recognition, P1
   Chintalacheruvu N., 2012, Journal of Transportation Technologies, V2, P305, DOI DOI 10.4236/JTTS.2012.24033
   Choudhury S, 2017, 2017 8TH ANNUAL INDUSTRIAL AUTOMATION AND ELECTROMECHANICAL ENGINEERING CONFERENCE (IEMECON), P106, DOI 10.1109/IEMECON.2017.8079571
   Dong HX, 2018, IEEE SIGNAL PROC LET, V25, P615, DOI 10.1109/LSP.2018.2816905
   Harris C., 1988, Proc. of the 4th Alvey Vision Conference, P189
   Hertz J. A, 2018, INTRO THEORY NEURAL, DOI DOI 10.1201/9780429499661
   Hung CH, 2013, INT J COMPUT VISION, V102, P271, DOI 10.1007/s11263-012-0559-y
   Idris M. Y. I., 2009, Information Technology Journal, V8, P101, DOI 10.3923/itj.2009.101.113
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029
   Rashidi A, 2011, TRANSPORT RES REC, P93, DOI 10.3141/2215-10
   Song JF, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), P16, DOI 10.1109/CISP.2014.7003742
   Tourani A, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND IMAGE ANALYSIS (IPRIA)
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Xia YJ, 2016, SIGNAL PROCESS, V120, P672, DOI 10.1016/j.sigpro.2014.10.035
   Yuan YL, 2013, INT CONF IMAG VIS, P453, DOI 10.1109/IVCNZ.2013.6727057
   Zhan W, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.1017
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zheng JL, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P280, DOI 10.1109/BigMM.2015.56
NR 28
TC 7
Z9 7
U1 12
U2 90
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6827
EP 6846
DI 10.1007/s11042-018-6394-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700019
DA 2024-07-18
ER

PT J
AU Bhushan, K
   Gupta, BB
AF Bhushan, Kriti
   Gupta, Brij B.
TI Network flow analysis for detection and mitigation of Fraudulent
   Resource Consumption (FRC) attacks in multimedia cloud computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fraudulent Resource Consumption (FRC) attacks; Network flow analysis;
   Low rate DDoS attacks; Cloud security; Cloud pricing model; Turing test;
   EDoS attack; Multimedia cloud
ID FRAMEWORK
AB Multimedia computing has evolved as a remarkable technology which provides services to view, create, edit, process, and search multimedia contents. All these multimedia services have high computational, bandwidth, and storage requirements. Therefore, multimedia cloud computing has gained appreciable popularity and acceptance in the past one decade. The convenience of cloud computing comes with financial burden. One of the fundamental features of cloud computing, which helps in reducing the financial worries of the multimedia service providers is the cloud's pay-as-you-go pricing model. However, the cloud's pricing model has also attracted adversaries that have hindered the migration of services and/or data by various organisations to the cloud. Through the cloud's pay-as-you-go pricing model, attackers usually target the financial viability of the cloud customers. Therefore, such attacks are capable to affect the long term availability of multimedia-services hosted on the public cloud. These attacks are known as Fraudulent Resource Consumption (FRC) attack. Therefore, research in the area of FRC attack detection and mitigation is important in motivating the organisations to adopt the public cloud platform. In this paper, we propose a novel approach based on network flow analysis at the victim side to detect and mitigate the FRC attacks against cloud-based services. Experiments were conducted using real world benchmark datasets to evaluate the performance of the proposed approach. Experimental outcomes suggest that our proposed approach is able to detect and mitigate the FRC attacks with satisfactory accuracy and low overhead.
C1 [Bhushan, Kriti; Gupta, Brij B.] Natl Inst Technol Kurukshetra, Dept Comp Engn, Kurukshetra, Haryana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra
RP Gupta, BB (corresponding author), Natl Inst Technol Kurukshetra, Dept Comp Engn, Kurukshetra, Haryana, India.
EM gupta.brij@gmail.com
RI Bhushan, Kriti/AAL-4576-2020; Gupta, Brij B/E-9813-2011
OI Gupta, Brij B/0000-0003-4929-4698
FU SERB, DST, Government of India [SB/FTP/ETA-131/2014]
FX This research work is being supported by Project grant
   (SB/FTP/ETA-131/2014) from SERB, DST, Government of India.
CR Al-Haidari F., 2012, 2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom), P1167, DOI 10.1109/TrustCom.2012.146
   [Anonymous], SP NIST
   Atat R, 2017, IET CYBER PHYS SYST, V2, P49, DOI 10.1049/iet-cps.2017.0010
   Baig ZA, 2016, COMPUT NETW, V97, P31, DOI 10.1016/j.comnet.2016.01.002
   Bhushan K, 2018, MULTIMED TOOLS APPL, V77, P4609, DOI 10.1007/s11042-017-4742-6
   Bhuyan MH, 2015, PATTERN RECOGN LETT, V51, P1, DOI 10.1016/j.patrec.2014.07.019
   Buyya R., 2010, Cloud Computing: Principles and Paradigms
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chen Y, 2006, J PARALLEL DISTR COM, V66, P1137, DOI 10.1016/j.jpdc.2006.04.007
   Feitosa E, 2012, COMPUT NETW, V56, P2805, DOI 10.1016/j.comnet.2012.04.018
   Hoff C., 2008, CLOUD COMPUTING SECU
   Idziorek J., 2012, 2012 IEEE 5th International Conference on Cloud Computing (CLOUD), P99, DOI 10.1109/CLOUD.2012.23
   Idziorek J., 2011, Proceedings of the 2011 IEEE 4th International Conference on Cloud Computing (CLOUD 2011), P33, DOI 10.1109/CLOUD.2011.45
   Idziorek J, 2011, PROCEEDINGS OF THE 3RD ACM WORKSHOP CLOUD COMPUTING SECURITY WORKSHOP (CCSW'11), P61
   Idziorek J, 2013, IT PROF, V15, P22, DOI 10.1109/MITP.2012.43
   Jouini M, 2016, INT J CLOUD APPL COM, V6, P32, DOI 10.4018/IJCAC.2016070103
   Khor S.H., 2009, SPOW ON DEMAND CLOUD
   Koduru A, 2013, CLOUD COMP EM MARK C, P1, DOI [DOI 10.1109/CCEM.2013.6684433, 10.1109/CCEM.2013.6684433]
   Kumar M. N., 2012, 2012 4th International Conference on Computational Intelligence and Communication Networks (CICN 2012), P535, DOI 10.1109/CICN.2012.149
   Kumar PAR, 2013, COMPUT COMMUN, V36, P303, DOI 10.1016/j.comcom.2012.09.010
   LI J, 1937, COMPUTER, V64, P425, DOI DOI 10.1109/TC.2013.208
   Li J, 2018, COMPUT SECUR, V72, P1, DOI 10.1016/j.cose.2017.08.007
   Li J, 2015, IEEE T PARALL DISTR, V26, P1206, DOI 10.1109/TPDS.2014.2318320
   Li J, 2015, KNOWL-BASED SYST, V79, P18, DOI 10.1016/j.knosys.2014.04.010
   Li P, 2017, FUTURE GENER COMP SY, V74, P76, DOI 10.1016/j.future.2017.02.006
   Li P, 2018, CLUSTER COMPUT, V21, P277, DOI 10.1007/s10586-017-0849-9
   Luo HB, 2013, IEEE NETWORK, V27, P60, DOI 10.1109/MNET.2013.6678928
   Maciá-Fernández G, 2010, COMPUT NETW, V54, P2711, DOI 10.1016/j.comnet.2010.05.002
   Maksoudian Y., 1969, Probability and statistics, with applications
   Masood M, 2013, 2013 16TH INTERNATIONAL MULTI TOPIC CONFERENCE (INMIC), P37, DOI 10.1109/INMIC.2013.6731321
   Moore D, 2006, ACM T COMPUT SYST, V24, P115, DOI 10.1145/1132026.1132027
   Ouf S, 2015, INT J CLOUD APPL COM, V5, P53, DOI [10.4018/ijcac.2015040104, 10.4018/IJCAC.2015040104]
   Ratten V, 2015, INT J CLOUD APPL COM, V5, P69, DOI 10.4018/ijcac.2015010106
   Sqalli M. H., 2011, Proceedings of the 2011 IEEE 4th International Conference on Utility and Cloud Computing (UCC 2011), P49, DOI 10.1109/UCC.2011.17
   The CAIDA UCSD, 2007, DDOS ATT DAT
   Wu JS, 2016, IEEE SYST J, V10, P873, DOI 10.1109/JSYST.2016.2550538
   Wu JS, 2016, IEEE SYST J, V10, P888, DOI 10.1109/JSYST.2016.2550530
   Xiang Y, 2011, IEEE T INF FOREN SEC, V6, P426, DOI 10.1109/TIFS.2011.2107320
   Yang TC, 2017, MULTIMED TOOLS APPL, V76, P11715, DOI 10.1007/s11042-016-3506-z
   Yu S, 2012, IEEE T PARALL DISTR, V23, P1073, DOI 10.1109/TPDS.2011.262
   Zhang CW, 2012, COMPUT NETW, V56, P3417, DOI 10.1016/j.comnet.2012.07.003
   Zhu WW, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2011.940269
   Zhu WZ, 2017, MULTIMED TOOLS APPL, V76, P19429, DOI 10.1007/s11042-015-3140-1
NR 46
TC 23
Z9 23
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4267
EP 4298
DI 10.1007/s11042-017-5522-z
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200019
DA 2024-07-18
ER

PT J
AU Liu, CH
AF Liu, Chien-Hung
TI A compatibility testing platform for android multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia app testing; Android compatibility testing; Android testing;
   Software testing
AB Along with the widespread use of smartphones, Android has become one of the major platforms for multimedia applications (apps). However, due to the fast evolution of Android operating system and the fragmentation of Android devices, it becomes important for an Android multimedia app to be tested on different devices to ensure that the app is compatible with and run well on any of the devices so as to provide consistent user experiences. This paper presents a cloud testing platform (CTP) that allows Android multimedia apps to be tested automatically against a scalable number of physical devices in parallel. Particularly, CTP provides five types of testing to ensure the compatibility of apps from different perspectives, including GUI testing, acceptance testing, stress testing, crash testing, and installation/uninstallation testing. Further, to facilitate identifying the bugs of apps, in addition to test results, CTP also provides the video, screenshots, and performance data corresponding to the tests. Moreover, CTP can also generate a GUI state diagram that can be used to analyze app's behavior and is helpful for crash diagnosis and debugging. The case study shows that CTP can be effective in ensuring the compatibility of Android multimedia apps while saving test time and effort.
C1 [Liu, Chien-Hung] Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, 1,Sect 3,Chung Hsiao E Rd, Taipei 106, Taiwan.
C3 National Taipei University of Technology
RP Liu, CH (corresponding author), Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, 1,Sect 3,Chung Hsiao E Rd, Taipei 106, Taiwan.
EM cliu@ntut.edu.tw
FU Ministry of Science and Technology, Taiwan; MOST [105-2221-E-027-086]
FX This work was supported in part by the Ministry of Science and
   Technology, Taiwan, under the grant No. MOST 105-2221-E-027-086.
CR Gamma E., 1994, Design patterns: Elements of reusable object-oriented software
   Jun-fei Huang, 2014, 2014 2nd IEEE International Conference on Mobile Cloud Computing, Services and Engineering (MobileCloud), P85, DOI 10.1109/MobileCloud.2014.13
   Kaasila J, 2012, P 11 INT C MOB UB MU
   Liu C-H, 2017, LECT NOTES ELE UNPUB
   Liu C-H, 2017, P 2017 TAIW AC NETW, P737
   Liu CF, 2015, AIP CONF PROC, V1648, DOI 10.1063/1.4913065
   Ma X, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY AND SECURITY COMPANION (QRS-C 2016), P159, DOI 10.1109/QRS-C.2016.25
   Prathibhan CM, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P1216, DOI 10.1109/ICACCCT.2014.7019292
   Rojas IKV, 2016, P 1 BRAZ SYM SYST TE
   Villanes IK, 2015, IEEE WORLD CONGR SER, P79, DOI 10.1109/SERVICES.2015.20
   Wei LL, 2016, IEEE INT CONF AUTOM, P226, DOI 10.1145/2970276.2970312
   Zhang T, 2015, 9TH IEEE INTERNATIONAL SYMPOSIUM ON SERVICE-ORIENTED SYSTEM ENGINEERING (SOSE 2015), P179, DOI 10.1109/SOSE.2015.35
NR 12
TC 6
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4885
EP 4904
DI 10.1007/s11042-018-6268-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200050
DA 2024-07-18
ER

PT J
AU Baburaj, M
   George, SN
AF Baburaj, M.
   George, Sudhish N.
TI Tensor based approach for inpainting of video containing sparse text
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video inpainting; Low rank recovery; Tensor decomposition; Tensor
   completion
ID OBJECT REMOVAL; DECOMPOSITIONS; COMPLETION; RECOVERY
AB Videos received from certain sources may contain irrelevant contents which might reduce the amount of information conveyed by it. This paper proposes an effective tensor based video inpainting approach to improve the quality of these videos by removing and replacing unwanted contents with relevant information. The proposed method employs reweighted tensor decomposition technique to identify and discard the inappropriate sparse components of the video data. These sparse components are substituted with proper contents by utilising spatio-temporal consistency through reweighted tensor completion. The replacement is carried out in such a way that the resulting video possesses superior temporal consistency and visual credibility. The proposed method is applied to sparse text removal of videos having dynamic content in various extents and is found that our method outperforms its counterparts.
C1 [Baburaj, M.; George, Sudhish N.] Natl Inst Technol Calicut, Dept Elect, Commun Engn, NIT Campus PO, Calicut, Kerala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Calicut
RP Baburaj, M (corresponding author), Natl Inst Technol Calicut, Dept Elect, Commun Engn, NIT Campus PO, Calicut, Kerala, India.
EM baburajmadathil@gmail.com; sudhish@nitc.ac.in
RI George, Sudhish/U-3625-2019; Madathil, Baburaj/T-2001-2019
OI Madathil, Baburaj/0000-0003-3151-9270
CR [Anonymous], 2004 CVPR 2004 CVPR
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], INFORM SCI
   [Anonymous], 2005 ICIP 2005 IEEE
   [Anonymous], ARXIV170107158
   Bornard R., 2002, P ACM INT C MULTIMED, P355
   Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   CARROLL JD, 1970, PSYCHOMETRIKA, V35, P283, DOI 10.1007/BF02310791
   Cichocki A, 2015, IEEE SIGNAL PROC MAG, V32, P145, DOI 10.1109/MSP.2013.2297439
   Comon P, 2014, IEEE SIGNAL PROC MAG, V31, P44, DOI 10.1109/MSP.2014.2298533
   Criminisi Antonio, 2003, 2003 IEEE COMP SOC C, V2, pII, DOI [10.1109/CVPR.2003.1211538, DOI 10.1109/CVPR.2003.1211538]
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696
   De Lathauwer L, 2009, IEEE INT SYMP CIRC S, P2773, DOI 10.1109/ISCAS.2009.5118377
   Demanet L., 2003, Appl. Comput. Math., V1100, P217
   Ding T, 2007, 2007 ICCV 2007 IEEE, P1
   Drori I, 2003, ACM T GRAPHIC, V22, P303, DOI 10.1145/882262.882267
   Ebdelli M, 2015, IEEE T IMAGE PROCESS, V24, P3034, DOI 10.1109/TIP.2015.2437193
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Goldfarb D, 2014, SIAM J MATRIX ANAL A, V35, P225, DOI 10.1137/130905010
   Granados M, 2012, COMPUT GRAPH FORUM, V31, P219, DOI 10.1111/j.1467-8659.2012.03000.x
   GRASEDYCK L., 2013, GAMM-Mitteilungen36, V36, P53, DOI 10.1002/gamm.201310004
   Guo Q, 2016, IEEE T CIRC SYST VID, V26, P868, DOI 10.1109/TCSVT.2015.2416631
   He KM, 2012, LECT NOTES COMPUT SC, V7573, P16, DOI 10.1007/978-3-642-33709-3_2
   He W, 2016, IEEE T GEOSCI REMOTE, V54, P176, DOI 10.1109/TGRS.2015.2452812
   Hu WR, 2017, IEEE T NEUR NET LEAR, V28, P2961, DOI 10.1109/TNNLS.2016.2611525
   Ji H, 2011, SIAM J IMAGING SCI, V4, P1122, DOI 10.1137/100817206
   Jia JY, 2006, IEEE T PATTERN ANAL, V28, P832, DOI 10.1109/TPAMI.2006.108
   Kilmer ME, 2013, SIAM J MATRIX ANAL A, V34, P148, DOI 10.1137/110837711
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Komodakis N, 2007, IEEE T IMAGE PROCESS, V16, P2649, DOI 10.1109/TIP.2007.906269
   Kressner D, 2014, BIT, V54, P447, DOI 10.1007/s10543-013-0455-z
   Krishnamurthy A, 2013, ADV NEURAL INFORM PR, V26, P836
   Ling CH, 2011, IEEE T MULTIMEDIA, V13, P292, DOI 10.1109/TMM.2010.2095000
   Liu YQ, 2013, IEEE T IMAGE PROCESS, V22, P1699, DOI 10.1109/TIP.2012.2218828
   Lu CY, 2016, PROC CVPR IEEE, P5249, DOI 10.1109/CVPR.2016.567
   Martin CD, 2013, SIAM J SCI COMPUT, V35, pA474, DOI 10.1137/110841229
   Newson A, 2014, SIAM J IMAGING SCI, V7, P1993, DOI 10.1137/140954933
   Patwardhan KA, 2007, IEEE T IMAGE PROCESS, V16, P545, DOI 10.1109/TIP.2006.888343
   Peng YG, 2014, IEEE T CYBERNETICS, V44, P2418, DOI 10.1109/TCYB.2014.2307854
   Pritch Y, 2009, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2009.5459159
   Semerci O, 2014, IEEE T IMAGE PROCESS, V23, P1678, DOI 10.1109/TIP.2014.2305840
   Umeda Y., 2012, 2012 International Symposium on Communications and Information Technologies (ISCIT), P6, DOI 10.1109/ISCIT.2012.6380991
   Venkatesh MV, 2009, PATTERN RECOGN LETT, V30, P168, DOI 10.1016/j.patrec.2008.03.011
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu Y., 2013, ARXIV13121254
   Yoo S, 2009, IEEE T CONSUM ELECTR, V55, P1006, DOI 10.1109/TCE.2009.5277948
   Zhang ZM, 2017, IEEE T SIGNAL PROCES, V65, P1511, DOI 10.1109/TSP.2016.2639466
   Zhang ZM, 2014, PROC CVPR IEEE, P3842, DOI 10.1109/CVPR.2014.485
   Zhou XW, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2674559
NR 51
TC 12
Z9 12
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1805
EP 1829
DI 10.1007/s11042-018-6251-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700026
DA 2024-07-18
ER

PT J
AU Huang, HQ
   Zhuo, T
AF Huang, Hanqiao
   Zhuo, Tao
TI Multi-model cooperative task assignment and path planning of multiple
   UCAV formation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Formation; UCAV; Task assignment; Path planning; Multi-model; Particle
   Swarm Optimization (PSO)
ID SYSTEM
AB Multi-model techniques have shown an outstanding effectiveness in the cooperative task assignment and path planning of the unmanned combat aerial vehicle(UCAV) formation. With cooperative decision making and control, the cooperative combat of the UCAV formation are described and the mathematical model of the UCAV formation is built. Then, the task assignment model of the UCAV formation is developed according to flight characteristics of the UCAV formation and constraints in battlefield. The cooperative task assignment problem is solved using the improved particle swarm optimization(IPSO), ant colony algorithm(ACA) and genetic algorithm(GA) respectively. The comparative analysis is conducted in the aspects of the precision and the search speed. The path planning model of the UCAV formation is constructed considering the oil cost, threat cost, crash cost and time cost. The cooperative path planning problem is solved based on the evolution algorithm(EA), in which unique coding scheme of chromosomes is designed, and the crossover operator and mutation operator are redefined. Simulation results demonstrate that the UCAV formation can choose the best algorithm according to the real battlefield environment, which can solve the cooperative task assignment and path planning problems quickly and effectively to meet the demand of the cooperative combat.
C1 [Huang, Hanqiao] Northwestern Polytech Univ, Xian, Shaanxi, Peoples R China.
   [Zhuo, Tao] Natl Univ Singapore, Sensor Enhanced Social Media SeSaMe Ctr, Interact & Digital Media Inst, Singapore, Singapore.
C3 Northwestern Polytechnical University; National University of Singapore
RP Huang, HQ (corresponding author), Northwestern Polytech Univ, Xian, Shaanxi, Peoples R China.; Zhuo, T (corresponding author), Natl Univ Singapore, Sensor Enhanced Social Media SeSaMe Ctr, Interact & Digital Media Inst, Singapore, Singapore.
EM cnxahhq@gmail.com; zhuotao@nus.edu.sg
FU National Natural Science Foundations of China [61601505]; Natural
   Science Foundation of Shaanxi Province [2016JQ6050]; Aviation Science
   Foundations of China [20155196022]; National Research Foundation, Prime
   Ministers Office, Singapore under its International Research Centre in
   Singapore Funding Initiative
FX The work was supported by National Natural Science Foundations of China
   (No.61601505), the Natural Science Foundation of Shaanxi Province
   (No.2016JQ6050), the Aviation Science Foundations of China
   (No.20155196022) and the National Research Foundation, Prime Ministers
   Office, Singapore under its International Research Centre in Singapore
   Funding Initiative.
CR Anitha G, 2012, PROCEDIA ENGINEER, V38, P2250, DOI 10.1016/j.proeng.2012.06.271
   [Anonymous], ENG SCI TECHNOLOGY I
   [Anonymous], P SIGIR
   Cao L, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P2368, DOI 10.1109/ROBIO.2014.7090692
   de Mendonça RM, 2016, NEUROCOMPUTING, V172, P345, DOI 10.1016/j.neucom.2015.05.117
   Edison E, 2011, COMPUT OPER RES, V38, P340, DOI 10.1016/j.cor.2010.06.001
   Evers L, 2014, EUR J OPER RES, V238, P348, DOI 10.1016/j.ejor.2014.03.014
   Evers L, 2014, ANN OPER RES, V222, P293, DOI 10.1007/s10479-012-1261-8
   Francis MS, 2012, J AIRCRAFT, V49, P1652, DOI 10.2514/1.C031425
   Guo JS, 2014, CHINESE J AERONAUT, V27, P1477, DOI 10.1016/j.cja.2014.10.014
   Halman N, 2016, THEOR COMPUT SCI, V645, P41, DOI 10.1016/j.tcs.2016.06.015
   Huang HQ, 2015, INT C CONTR AUTOMAT, P1762, DOI 10.1109/ICCAS.2015.7364635
   Huang H, 2014, J INTELL ROBOT SYST, V74, P999, DOI 10.1007/s10846-013-9870-2
   Ide J, 2014, MATH METHOD OPER RES, V80, P99, DOI 10.1007/s00186-014-0471-z
   Jia Y.-H., 2017, IEEE T SYST MAN CYBE, P1
   Li MD, 2016, ADV ENG SOFTW, V92, P65, DOI 10.1016/j.advengsoft.2015.11.004
   Liu H, 2015, APPL INTELL, V43, P162, DOI 10.1007/s10489-014-0640-z
   Narasimha KV, 2013, SWARM EVOL COMPUT, V13, P63, DOI 10.1016/j.swevo.2013.05.005
   Nie WZ, 2016, IMAGE VISION COMPUT, V55, P109, DOI 10.1016/j.imavis.2016.04.011
   Nie WZ, 2014, NEUROCOMPUTING, V139, P220, DOI 10.1016/j.neucom.2014.02.040
   Noei S, 2016, PROCEDIA COMPUT SCI, V95, P489, DOI 10.1016/j.procs.2016.09.326
   Oh G, 2017, J INTELLIGENT ROBOTI, P1
   Oh G, 2016, IFAC PAPERSONLINE, V49, P314, DOI 10.1016/j.ifacol.2016.09.054
   Sarasola B, 2016, ANN OPER RES, V236, P425, DOI 10.1007/s10479-015-1949-7
   Song BD, 2016, J INTELL ROBOT SYST, V84, P241, DOI 10.1007/s10846-015-0280-5
   Song Q, 2010, 2010 2ND IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND FINANCIAL ENGINEERING (ICIFE), P706, DOI 10.1109/ICIFE.2010.5609456
   Wang MW, 2017, INFORM SCIENCES, V402, P50, DOI 10.1016/j.ins.2017.03.027
   Williams P, 2005, J AIRCRAFT, V42, P1358, DOI 10.2514/1.17811
   Wu Y, 2013, SCI CHINA TECHNOL SC, V56, P1561, DOI 10.1007/s11431-013-5222-5
   Yu X, 2015, PROG AEROSP SCI, V74, P152, DOI 10.1016/j.paerosci.2015.01.001
   Zhang H, 2016, ACM T MULTIMED COMPU, V13
   Zhang P., 2017, NEUROCOMPUTING
   Zhang P, 2016, NEUROCOMPUTING, V204, P87, DOI 10.1016/j.neucom.2015.07.149
   Zhang P, 2016, SIGNAL PROCESS, V124, P246, DOI 10.1016/j.sigpro.2015.07.021
   Zhang P, 2016, NEUROCOMPUTING, V175, P166, DOI 10.1016/j.neucom.2015.10.046
NR 35
TC 26
Z9 31
U1 3
U2 72
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 415
EP 436
DI 10.1007/s11042-017-4956-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500022
DA 2024-07-18
ER

PT J
AU Wang, YS
   Yao, HX
   Yu, W
   Wang, D
   Zhou, SC
   Sun, XS
AF Wang, Yasi
   Yao, Hongxun
   Yu, Wei
   Wang, Dong
   Zhou, Shangchen
   Sun, Xiaoshuai
TI Gradual recovery based occluded digit images recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stacked generalized auto-encoders; Gradual occlusion recovery; Occluded
   digit images recognition; Convolutional neural network
AB Recent research shows that auto-encoder is suitable to model a variation which varies smoothly. In this paper, we attempt to utilize auto-encoder to recognize partially occluded digit images with gradual recovery. We propose a new variation of auto-encoder, namely the generalized auto-encoder, and construct stacked generalized auto-encoders (SGAE) for the problem of occluded digit images recovery and recognition. Rather than recovering the occlusion directly, the degree of occlusion is regarded as a continuous variable, and the recovery task is regarded as a gradual process. We divide the whole task into multiple intermediate recovery procedures, and assign each procedure to one generalized auto-encoder, thus handling the recovery problem gradually. Based on the encouraging recovery results, the occluded digit images can be recognized well. The results demonstrate that gradual recovery outperforms direct recovery of the occluded region. Moreover, the main application in this paper is occluded digit images recognition, though, the proposed framework can be generalized to other problems easily and nicely. Extensive experiments are designed to verify our settings and show the effectiveness, extendibility and generalizability of the method.
C1 [Wang, Yasi; Yao, Hongxun; Yu, Wei; Zhou, Shangchen; Sun, Xiaoshuai] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
   [Wang, Dong] Harbin Inst Technol, State Key Lab Robot & Syst, Harbin, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology; Harbin Institute of Technology
RP Yao, HX (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
EM h.yao@hit.edu.cn
RI Yu, Wei/GPX-1311-2022
CR [Anonymous], 2016, ARXIV161208534
   [Anonymous], 2009, INT C COMP VIS THEOR
   [Anonymous], 2016, INT C MACH LEARN
   [Anonymous], 2016, AAAI C ART INT
   Bansal A., 2017, ARXIV170206506
   Benenson R, 2014, OCCLUSION HANDLING
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Ekman P., 1978, Facial action coding system
   Getoor, 2011, P 28 INT C MACH LEAR, P833
   Ghifary Muhammad, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5437, DOI 10.1109/ICASSP.2014.6854642
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   [胡昭华 Hu Zhao-hua], 2009, [电子与信息学报, Journal of Electronics & Information Technology], V31, P1189
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Kan M, 2014, PROC CVPR IEEE, P1883, DOI 10.1109/CVPR.2014.243
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   King DB, 2015, ACS SYM SER, V1214, P1
   KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209
   Krolupper F, 2007, PATTERN RECOGN LETT, V28, P1002, DOI 10.1016/j.patrec.2006.12.021
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee CY, 2014, INT C ARTIF INTELL S
   Liu LQ, 2016, IEEE T MULTIMEDIA, V18, P64, DOI 10.1109/TMM.2015.2500730
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lopes ANG, 2012, IEEE SYS MAN CYBERN, P733, DOI 10.1109/ICSMC.2012.6377814
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Makhzani A, 2013, ARXIV13125663, P5663
   Na Fan, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3001, DOI 10.1109/ICPR.2010.735
   Saber E, 2005, PATTERN RECOGN, V38, P1560, DOI 10.1016/j.patcog.2005.03.027
   Vincent Pascal, 2008, P 25 INT C MACHINE L, DOI DOI 10.1145/1390156.1390294
   Wang P, 2015, ARXIV151106457 CORR
   Wang SY, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P805, DOI 10.1145/2647868.2654986
   Wang YS, 2016, NEUROCOMPUTING, V184, P232, DOI 10.1016/j.neucom.2015.08.104
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yang H, 2015, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2015.526
   Yonggang Lu, 2017, Multimedia Tools and Applications, V76, P10701, DOI 10.1007/s11042-015-3188-y
NR 40
TC 0
Z9 0
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2571
EP 2586
DI 10.1007/s11042-018-6048-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700057
DA 2024-07-18
ER

PT J
AU Yang, YQ
   Wu, Y
   Chen, N
AF Yang, Yongquan
   Wu, Yang
   Chen, Ning
TI Explorations on visual localization from active to passive
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual localization; Following robot; Loop closure detection; Long-term
   robotic autonomy
ID LOOP CLOSURE DETECTION; LARGE-SCALE; TRACKING; TIME
AB In this paper, we novelly consider visual localization in active and passive two ways, with simple definition that active localization assists device to estimate location of its interest while passive localization aids device to estimate its own location in environment. Expecting to indicate some insights into visual localization, we specifically performed two explorations on active localization and more importantly explored to upgrade them from active to passive localization with extra geometry information available. In order to produce unconstrained and accurate 2D location estimation of interested object, we constructed an active localization system by fusing detection, tracking and recognition. Based on recognition, we proposed a collaborative strategy making mutual enhancement between detection and tracking possible to obtain better performance on 2D location estimation. Meanwhile, to actively estimate semantic location of interested visual region, we employed latest state-of-the-art light weight CNN models specifically designed for efficiency and trained two of them with large place dataset in perspective of scene recognition. What's more, using depth information available from RGB-D camera, we improved the active system for 2D location of interested object to a passive system for relative 3D location of device to the interested object. Firstly estimated was the 3D location of the interested object in the coordinate system of device, then relative location of device to the interested object in world coordinate system was deduced with appropriate assumption. Evaluations both subjectively on a RGB-D sequence obtained in a lab environment and practically on a robotic platform in an office environment indicated that the improved system was suitable for autonomous following robot. As well, the active system for rough semantic location estimation of interested visual region was promoted to a passive system for fine location estimation of device, with available 3D map describing the visited environment. In perspective of place recognition, we first adopted one of the efficient CNN models previously trained for semantic location estimation as a base to generate CNN features for both retrieval of candidate loops in the map and geometrical consistency checking of retrieved loops, then true loops were used to deduce fine location of device itself in environment. Comparison with state-of-the-art results reflected that the promoted system was adequate for long-term robotic autonomy. Achieving favorable performances, the presented four explorations have implied adequacy for elaborating on some insights into visual localization.
C1 [Yang, Yongquan] Nara Inst Sci & Technol, Ikoma, Japan.
   [Wu, Yang] Nara Inst Sci & Technol, NAIST Int Collaborat Lab Robot Vis, Inst Res Initiat, Ikoma, Japan.
   [Chen, Ning] Xian Polytech Univ, Sch Comp Sci, Xian, Shaanxi, Peoples R China.
C3 Nara Institute of Science & Technology; Nara Institute of Science &
   Technology; Xi'an Polytechnic University
RP Yang, YQ (corresponding author), Nara Inst Sci & Technol, Ikoma, Japan.
EM remy_yang@foxmail.com; yangwu@rsc.naist.jp; chennvictor@gmail.com
RI Chen, Ning/GRF-4454-2022; Yang, Yongquan/ABH-8736-2022
OI Chen, Ning/0000-0002-0056-0337; Yang, Yongquan/0000-0002-3965-4816
FU JSPS KAKENHI [15K16024]; Grants-in-Aid for Scientific Research
   [15K16024] Funding Source: KAKEN
FX This work was supported by JSPS KAKENHI Grant Number 15K16024.We
   gratefully acknowledge Intel China Lab and Beijing Qfeel Technology Co.,
   Ltd., China for equipment support.
CR Abadi M, ARXIV, DOI DOI 10.48550/ARXIV.1603.04467
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], 2001, PROC CVPR IEEE
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], Single Shot MultiBox Detector, DOI DOI 10.1007/978-3-319-46448-0_2
   [Anonymous], 2015, P ADV NEUR INF PROC
   [Anonymous], 2015, ICCV WORKSH
   [Anonymous], 2016, LEARNING MULTIDOMAIN
   [Anonymous], 2016, LEARNING TRACK 100 F
   [Anonymous], 2009, P CVPR
   [Anonymous], 2007, CIVR '07
   [Anonymous], 2015, NEUR INF PROC SYST W
   [Anonymous], 2014, P BMVC
   [Anonymous], 2009, CVPR
   [Anonymous], 1981, 7 INT JOINT C ARTIFI
   [Anonymous], 2016, TRAINING REGION BASE
   [Anonymous], 2017, ICCV
   [Anonymous], 2017, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2017.302
   [Anonymous], 2017, ICCV
   [Anonymous], ARXIV170106659
   [Anonymous], 2016, ARXIV160609549
   [Anonymous], 2012, ECCV
   [Anonymous], 2014, P BRIT MACHINE VISIO
   [Anonymous], 2013, 2014 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2014.81
   Aulinas J, 2008, FRONT ARTIF INTEL AP, V184, P363, DOI 10.3233/978-1-58603-925-7-363
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Beaudet P, P IJCPR
   Bolme D.S., 2010, Visual object tracking using adaptive correlation filters
   Bradski G.R., 1998, INTEL TECHNOLOGY J, V2, P12
   C Ma, 2015, HIERARCHICAL CONVOLU
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chatfield K, 2014, BRI MACH VIS C BMVC
   Chen Z., 2015, Comput. Sci., V53, P68
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2017, ECO EFFICIENT CONVOL
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Doersch C, 2013, ADV NEU INF P SYST
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Felzenszwalb P., 2008, A discriminatively trained, multiscale
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   G Nebehay, 2015, CLUSTERING STATIC AD
   Gálvez-López D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gouda W, 2014, ELECTRONICS, P170
   Graziotin D, 2015, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.18
   Hahnel D, 2003, EFFICIENT FASTSLAM A
   Han L, 2017, SIFT USING BINARY FE
   Han L, 2017, INT C MULT EXP
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Harris C., 1988, ALVEY VISION C, P147151
   He K, 2016, COMPUT VIS PATTERN R
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   Henriques J.F., 2014, HIGH SPEED TRACKING
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hou Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P2238, DOI 10.1109/ICInfA.2015.7279659
   Howard A. G., 2017, MOBILENETS EFFICIENT
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jia Y., 2014, P 22 ACM INT C MULT, P675
   Kalal Zdenek, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2756, DOI 10.1109/ICPR.2010.675
   Kalal Z, 2010, 23 IEEE C COMP VIS P
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kejriwal N, 2016, ROBOT AUTON SYST, V77, P55, DOI 10.1016/j.robot.2015.12.003
   Khan S, 2015, IEEE INT CONF ROBOT, P5441, DOI 10.1109/ICRA.2015.7139959
   Klein DA, 2010, IEEE INT C INT ROBOT, P772, DOI 10.1109/IROS.2010.5650583
   Knopp J, 2010, LECT NOTES COMPUT SC, V6311, P748, DOI 10.1007/978-3-642-15549-9_54
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumari D., 2016, Int. J. Eng. Manuf, V6, P40
   Kwon J, 2009, TRACKING NONRIGID OB
   L Wen, 2014, IEEE T IMAGE P
   Labbé M, 2013, IEEE T ROBOT, V29, P734, DOI 10.1109/TRO.2013.2242375
   Latif Y, 2013, INT J ROBOT RES, V32, P1611, DOI 10.1177/0278364913498910
   Lebedev V., 2014, INT C LEARNING REPRE
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Lin T.Y., 2017, P IEEE C COMP VIS PA
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Mair E., 2010, P ECCV
   Nebehay G, 2014, IEEE T PATTERN ANAL, V27, DOI [10. 1109/WACV. 2014. 6836013, DOI 10.1109/WACV.2014.6836013]
   Nister D, 2004, IEEE COMP SOC C COMP, V1
   Nister David, 2006, CVPR
   Ozyesil O, 2017, ACTA NUMERICA, V26
   Pernici F, 2014, IEEE T PATTERN ANAL, V36, P2538, DOI 10.1109/TPAMI.2013.250
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Redmon J, 2017, CVPR, V1, P8
   Redmon J., 2016, YOU ONLY LOOK ONCE U, V1
   Rosten E, 2005, IEEE I CONF COMP VIS, P1508
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sanchez J., 2013, INT J COMPUT VIS
   Sifre L., 2014, THESIS CITESEER
   Simonyan K, 2014, CORR
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Strasdat H., 2012, THESIS IMPERIAL COLL
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taketomi T, 2017, IPSJ Trans. Comput. Vis. Appl, V9, P1, DOI [10.1186/s41074-017-0027-2, DOI 10.1186/S41074-017-0027-2]
   Trevor H., 2009, The Elements of Statistical Learning: Data Mining, Inference, and Prediction
   Uchida Y, 2016, ARXIV160708368
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Ulrich I., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1023, DOI 10.1109/ROBOT.2000.844734
   Vojir T, 2014, ENHANCED FLOCK TRACK
   W Zhong, 2012, ROBUST OBJECT TRACKI
   Wang N., 2013, Advances in Neural Information Processing Systems, P809
   Wei YM, 2013, J ZHEJIANG U-SCI C, V14, P486, DOI 10.1631/jzus.CIDE1302
   Wen W, 2016, ADV NEUR IN, V29
   Williams B, 2011, IEEE T PATTERN ANAL, V33, P1699, DOI 10.1109/TPAMI.2011.41
   Zhang K, 2014, FAST TRACKING VIA DE
   Zhang LM, 2017, MULTIMEDIA SYST, V23, P1, DOI 10.1007/s00530-016-0527-4
   Zhang X, 2015, INTELL CONTROL AUTOM, V22, P2026
   Zhang X., 2017, ARXIV170701083
   Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579
   Zhou B, 2014, ADV NEU INF P SYST
   Zhou B, 2017, IEEE T PAT ANAL MACH, V99
NR 120
TC 5
Z9 5
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2269
EP 2309
DI 10.1007/s11042-018-6347-0
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700044
DA 2024-07-18
ER

PT J
AU Hsiao, CY
   Tsai, MF
   Yang, CY
AF Hsiao, Chun-Yuan
   Tsai, Ming-Feng
   Yang, Ching-Yu
TI Simple and robust watermarking scheme based on square-root-modulus
   technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Integer wavelet transform; Color image watermarking;
   Square-root-modulus
ID COLOR IMAGE WATERMARKING; RECOVERY
AB In this paper, we present a simple and robust watermarking scheme for color images. The scheme is based on the square-root-modulus technique employed in the integer wavelet domain, which allows a large number of data bits to be embedded in a host image. Simulations confirmed that marked images generated by the proposed scheme are tolerant to various attacks such as blurring, brightness, contrast, cropping, edge sharpening, inversion, JPEG/JPEG2000 compressions, noise-additions, and truncation. Additionally, the payload of the proposed method is significantly larger than that of existing watermarking techniques and the resulting perceived quality is not bad. Because the code is quite simple, it is suitable for the proposed method implemented in the mobile equipments or smart devices.
C1 [Hsiao, Chun-Yuan; Tsai, Ming-Feng] Natl Kaoshiung Univ Appl Sci, Dept Comp Sci & Informat Engn, Kaohsiung, Taiwan.
   [Yang, Ching-Yu] Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, Magong, Penghu, Taiwan.
C3 National Penghu University of Science & Technology
RP Yang, CY (corresponding author), Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, Magong, Penghu, Taiwan.
EM cyhsiao@kuas.edu.tw; 1104308106@gm.kuas.edu.tw; chingyu@gms.npu.edu.tw
CR Calderbank AR, 1998, APPL COMPUT HARMON A, V5, P332, DOI 10.1006/acha.1997.0238
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Howard PG, 1998, IEEE T CIRC SYST VID, V8, P838, DOI 10.1109/76.735380
   Lin C.C., 2014, J INF HIDING MULTIME, V5, P124
   Pan JS, 2015, MULTIMED TOOLS APPL, V74, P9191, DOI 10.1007/s11042-014-2076-1
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Phadikar A., 2012, DATA HIDING TECHNIQU
   Qin C, 2018, INFORM SCIENCES, V423, P284, DOI 10.1016/j.ins.2017.09.060
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Qin C, 2016, INFORM SCIENCES, V361, P84, DOI 10.1016/j.ins.2016.04.036
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Qin C, 2013, SIGNAL PROCESS, V93, P933, DOI 10.1016/j.sigpro.2012.11.013
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Wang CP, 2017, SIGNAL PROCESS, V134, P197, DOI 10.1016/j.sigpro.2016.12.010
   Wang XY, 2016, J VIS COMMUN IMAGE R, V38, P678, DOI 10.1016/j.jvcir.2016.04.011
   Wang XY, 2013, J SYST SOFTWARE, V86, P255, DOI 10.1016/j.jss.2012.08.015
   Yang CY, 2017, MULTIMED TOOLS APPL, V76, P1455, DOI 10.1007/s11042-015-3065-8
   Yang CY, 2013, ETRI J, V35, P512, DOI 10.4218/etrij.13.0112.0480
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
   Zielinska E, 2014, COMMUN ACM, V57, P86, DOI 10.1145/2566590.2566610
NR 21
TC 4
Z9 4
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30419
EP 30435
DI 10.1007/s11042-018-6121-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600013
DA 2024-07-18
ER

PT J
AU Hu, Y
AF Hu, Yong
TI Finger spelling recognition using depth information and support vector
   machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Finger spelling recognition; Depth image; Local binary patterns;
   Histograms of oriented gradients; Zernike moments; k-means; Support
   vector machine
ID HAND GESTURE RECOGNITION
AB In Sign Language fingerspelling systems, letters of the alphabet are presented by a diverse form or/and movement of the fingers. In this study, the presented work focus on developing a real-time translation framework of static fingerspelling alphabets. At first an adaptive k-means based cluster method for depth segmentation is proposed, where a flexible cluster number n is used instead of the pre-defined definitive one. Based on the segmentation step, a recognition framework using intensity and depth information is proposed and compared with some distinctive works. Discriminative features extracted from Histogram of Oriented Gradients (HOG), Local Binary Patterns (LBP), and Zernike moments are used due to their simplicity and good performance. The experiments are executed on a public fingerspelling dataset, which consisted of 120,000 images representing 24 alphabet letters over five different users. The results show that the presented framework is efficient, easy implementation, and performs better than the compared approaches.
C1 [Hu, Yong] Jinling Inst Technol, Sch Software Engn, Nanjing, Jiangsu, Peoples R China.
C3 Jinling Institute of Technology
RP Hu, Y (corresponding author), Jinling Inst Technol, Sch Software Engn, Nanjing, Jiangsu, Peoples R China.
EM huyong@jit.edu.cn
FU Top-notch Academic Programs Project of Jiangsu Higher Education
   Institutions (TAPP)
FX This work is supported by Top-notch Academic Programs Project of Jiangsu
   Higher Education Institutions (TAPP).
CR Al-Otaibi N., 2014, LECT NOTES INFORM TH, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Alharthi N., 2017, Scientific Modelling and Research, V2, P9, DOI 10.20448/808.2.1.9.18
   [Anonymous], 2013, 10 IEEE INT C WORKSH
   [Anonymous], 2017, ASL FINGER SPELLING
   Badi Haitham, 2016, Intelligent Industrial Systems, V2, P179, DOI 10.1007/s40903-016-0046-9
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dahmani D, 2014, J VIS COMMUN IMAGE R, V25, P1240, DOI 10.1016/j.jvcir.2013.12.019
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Hruz M., 2012, Pattern Recognition and Image Analysis, V22, P519, DOI 10.1134/S1054661812040062
   Krishnaveni M, 2011, INT J ENG SCI TECHNO, V3, P1014
   Lun R, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415550083
   Norah A, 2017, J RES ENG APPL SCI J, V2, P50, DOI DOI 10.46565/JREAS.2017.V02I02.002
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Otiniano-Rodríguez K, 2015, SIBGRAPI, P72, DOI 10.1109/SIBGRAPI.2015.50
   Otiniano-Rodriguez KC, 2012, 2012 INT C IM PROC C, P1
   Pisharady PK, 2015, COMPUT VIS IMAGE UND, V141, P152, DOI 10.1016/j.cviu.2015.08.004
   Prada F, 2013, 39 LAT AM COMP C CLE, P1
   Prada F, 2012, 25 SIBGRAPI C GRAPH
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   Rioux-Maldague L, 2014, 2014 CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P92, DOI 10.1109/CRV.2014.20
   Uebersax D, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130267
   von Agris Ulrich, 2008, Universal Access in the Information Society, V6, P323, DOI 10.1007/s10209-007-0104-x
   Yang HD, 2015, SENSORS-BASEL, V15, P135, DOI 10.3390/s150100135
   Zhu XL, 2012, INT C PATT RECOG, P2989
NR 25
TC 13
Z9 13
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 29043
EP 29057
DI 10.1007/s11042-018-6102-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500053
DA 2024-07-18
ER

PT J
AU Jia, YH
   Bai, L
   Wang, P
   Guo, JL
   Xie, YX
   Yu, TY
AF Jia, Yuhua
   Bai, Liang
   Wang, Peng
   Guo, Jinlin
   Xie, Yuxiang
   Yu, Tianyuan
TI Irrelevance reduction with locality-sensitive hash learning for
   efficient cross-media retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-media retrieval; Neural networks; Locality-sensitive hashing;
   Multimodal indexing
ID IMAGES
AB Cross-media retrieval is an imperative approach to handle the explosive growth of multimodal data on the web. However, existing approaches to cross-media retrieval are computationally expensive due to high dimensionality. To efficiently retrieve in multimodal data, it is essential to reduce the proportion of irrelevant documents. In this paper, we propose a fast cross-media retrieval approach (FCMR) based on locality-sensitive hashing (LSH) and neural networks. One modality of multimodal information is projected by LSH algorithm to cluster similar objects into the same hash bucket and dissimilar objects into different ones and then another modality is mapped into these hash buckets using hash functions learned through neural networks. Once given a textual or visual query, it can be efficiently mapped to a hash bucket in which objects stored can be near neighbors of this query. Experimental results show that, in the set of the queries' near neighbors obtained by the proposed method, the proportions of relevant documents can be much boosted, and it indicates that the retrieval based on near neighbors can be effectively conducted. Further evaluations on two public datasets demonstrate the efficacy of the proposed retrieval method compared to the baselines.
C1 [Jia, Yuhua; Bai, Liang; Guo, Jinlin; Xie, Yuxiang; Yu, Tianyuan] Natl Univ Def Technol, Sci & Technol Informat Syst Engn Lab, Changsha 410073, Hunan, Peoples R China.
   [Wang, Peng] Tsinghua Univ, Dept Comp Sci & Technol, Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
C3 National University of Defense Technology - China; Tsinghua University
RP Wang, P (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
EM jiayuhua11@outlook.com; xabpz@163.com; pwang@tsinghua.edu.cn;
   gjlin99@gmail.com; yxxie@nudt.edu.cn; yutianyuan92@163.com
RI Wang, Peng/F-2018-2017; ARSLAN, Okan/AAA-3232-2020
FU Natural Science Foundation of China [61571453, 61502264, 61405252];
   Natural Science Foundation of Hunan Province, China [14JJ3010]; National
   University of Defense Technology [ZK16-03-37]
FX This work is supported by the Natural Science Foundation of China under
   Grant No. 61571453, No. 61502264, and No. 61405252, Natural Science
   Foundation of Hunan Province, China under Grant No. 14JJ3010, Research
   Funding of National University of Defense Technology under grant No.
   ZK16-03-37.
CR [Anonymous], COMPUT SCI
   [Anonymous], LINKING IMAGE TEXT 2
   [Anonymous], CAPTIONS VISUAL CONC
   [Anonymous], INSTANCE AWARE IMAGE
   [Anonymous], SCI WORLD J
   [Anonymous], ADV ROBOT
   [Anonymous], 2016, CORR
   [Anonymous], 2013, GROUNDED COMPOSITION
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2016, P 24 ACM INT C MULT
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bian JW, 2015, IEEE T MULTIMEDIA, V17, P216, DOI 10.1109/TMM.2014.2384912
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Ghosh S, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P162, DOI 10.1109/ICACCI.2016.7732041
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He XN, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P549, DOI 10.1145/2911451.2911489
   Jia YQ, 2011, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2011.6126524
   Karpathy A, 2014, ADV NEUR IN, V27
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   Lv Q, 2007, P 33 INT C VER LARG, P950
   Ma L, 2015, IEEE I CONF COMP VIS, P2623, DOI 10.1109/ICCV.2015.301
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Pauleve L, 2010, PATTERN RECOGN LETT, V31, P1348, DOI 10.1016/j.patrec.2010.04.004
   Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wu F., 2013, P ACM INT C MULT, P877
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
   Zhang HW, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P325, DOI 10.1145/2911451.2911502
   Zhuang YT, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P901, DOI 10.1145/2647868.2655059
NR 33
TC 3
Z9 3
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29435
EP 29455
DI 10.1007/s11042-018-5692-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800014
DA 2024-07-18
ER

PT J
AU Kim, TJ
   Huh, JH
   Kim, JM
AF Kim, Tae-Jung
   Huh, Jun-Ho
   Kim, Jin-Mo
TI Bi-directional education contents using VR equipments and augmented
   reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bi-directional education contents; VR; Augmented reality; C#
AB Recently, in the Republic of Korea (ROK), the development of contents related to safe evacuation procedures has become an issue as there have been many man-made disasters. Thus, augmented reality-based bi-directional education contents that can efficiently educate Korean citizens on safe evacuation and crisis-dealing procedures have been proposed in this study. The name of the proposed educational contents is SOS (Safety of Society), and they include use instructions for fire extinguishers or descending devices as well as the method of performing CPR. The remarkable changes in recent technological development diversify the use of augmented reality, whereas the increased use of smartphones is making life more convenient. Such changes pose the necessity of change in educational systems and allow a learning experience outside classrooms. Thus, this paper proposes a two-way education contents design using VR equipment and augmented reality with unity and C# for educational purpose and also proposes a light-weighted system that enables to mount education curriculum.
C1 [Kim, Tae-Jung; Huh, Jun-Ho; Kim, Jin-Mo] Catholic Univ Pusan, Dept Software, Busan, South Korea.
C3 Catholic University Pusan
RP Huh, JH; Kim, JM (corresponding author), Catholic Univ Pusan, Dept Software, Busan, South Korea.
EM 72networks@cup.ac.kr; jmkim11@cup.ac.kr
RI Huh, Jun-Ho/AAC-1518-2022; Huh, Jun-Ho/AAD-2398-2022
OI Huh, Jun-Ho/0000-0001-6735-6456; 
FU 4D Health Care Project Group
FX The 4D Health Care refers to an advance health care technology which is
   used for the operation in a 4D-based mixed reality where human senses,
   cognition and experiences (1D) have been converged with both real and
   virtual information (3D) and the project group runs various curricular
   and extracurricular programs to train every participating student to
   acquire a 4D technology-based health care contents development skills.
   This has been written with the support of the 4D Health Care Project
   Group and the author wishes to express his gratitude to the Ministry of
   Education, National Research Foundation of Korea, as well as the CK
   Project Group. And this paper is the product of a team project performed
   in "Advanced Java Programing" Course at Dept. of Software, Catholic
   University of Pusan for the undergraduates. Also, my gratitude extends
   to Catholic University of Pusan and the Lord who has provided me with
   his wisdom and grace.
CR [Anonymous], 2003, Proceedings of the 2003 conference on Diversity in computing: ACM
   [Anonymous], 2016, J CONVERGENCE
   Barrero D, 2005, 20051151 AIAA
   Bukowski R, 1998, P 2 INT C FIR RES EN
   Forney GP, 2003, IEEE COMPUT GRAPH, V23, P6, DOI 10.1109/MCG.2003.1210858
   Huang HS, 2009, 2009 INTERNATIONAL CONFERENCE ON NEW TRENDS IN INFORMATION AND SERVICE SCIENCE (NISS 2009), VOLS 1 AND 2, P176, DOI 10.1109/NISS.2009.16
   Huh JH, 2017, HUM-CENTRIC COMPUT I, V7, DOI 10.1186/s13673-017-0101-x
   Huh JH, 2016, HUM-CENT COMPUT INFO, V6, DOI 10.1186/s13673-016-0060-7
   Inoue Y, 2008, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON UNIVERSAL COMMUNICATION, P79, DOI 10.1109/ISUC.2008.49
   Jung, 1997, J KIISE, V15, P14
   Kajioka S, 2014, 2014 IEEE 3RD GLOBAL CONFERENCE ON CONSUMER ELECTRONICS (GCCE), P337, DOI 10.1109/GCCE.2014.7031308
   Kim D, 2017, MULTIMEDIA SYST, V23, P435, DOI 10.1007/s00530-016-0503-z
   Kim K, 2006, KOREA ACAD INFORM SO, P65
   Korea Institute of Machinery and Materials, 2010, NEXT GEN COR FIR SAF
   LEE DG, 2017, MUE, V2017, P1
   Lee S.-Y., 2015, J FORENSICS RES, V6, P1, DOI [10.4172/2157-7145.1000297, DOI 10.4172/2157-7145.1000297]
   이준영, 2014, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V17, P1313, DOI 10.9717/kmms.2014.17.11.1313
   Milgram P, 1994, TAXONOMY MIXED REALI
   Park J., 2015, ADV COMPUTER SCI UBI, P541, DOI DOI 10.1007/978-981-10-0281-6_78
   Ren A, 2006, CGVR, P1
   Sung Y, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0051-0
   Yamada T, 2006, DEV FIRE SIMULATOR U
   Zlatanova, 2000, THESIS
   원강식, 2010, [The Journal of the Korea Contents Association, 한국콘텐츠학회 논문지], V10, P205
NR 24
TC 11
Z9 11
U1 5
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 30089
EP 30104
DI 10.1007/s11042-018-6181-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800052
DA 2024-07-18
ER

PT J
AU Thung, KH
   Wee, CY
AF Thung, Kim-Han
   Wee, Chong-Yaw
TI A brief review on multi-task learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Multi-task learning; MTL; Transfer learning; Joint learning; Multi-class
   learning; Learning with auxiliary tasks
ID NEURODEGENERATIVE DISEASE; MULTIPLE TASKS; REGRESSION; CLASSIFICATION;
   SHRINKAGE; SELECTION; SPARSITY
AB Multi-task learning (MTL), which optimizes multiple related learning tasks at the same time, has been widely used in various applications, including natural language processing, speech recognition, computer vision, multimedia data processing, biomedical imaging, socio-biological data analysis, multi-modality data analysis, etc. MTL sometimes is also referred to as joint learning, and is closely related to other machine learning subfields like multi-class learning, transfer learning, and learning with auxiliary tasks, to name a few. In this paper, we provide a brief review on this topic, discuss the motivation behind this machine learning method, compare various MTL algorithms, review MTL methods for incomplete data, and discuss its application in deep learning. We aim to provide the readers with a simple way to understand MTL without too many complicated equations, and to help the readers to apply MTL in their applications.
C1 [Thung, Kim-Han] Univ N Carolina, Dept Radiol, Chapel Hill, NC 27515 USA.
   [Wee, Chong-Yaw] Natl Univ Singapore, Dept Biomed Engn, Singapore, Singapore.
C3 University of North Carolina; University of North Carolina Chapel Hill;
   National University of Singapore
RP Wee, CY (corresponding author), Natl Univ Singapore, Dept Biomed Engn, Singapore, Singapore.
EM khthung@med.unc.edu; cywee2000@gmail.com
RI Thung, KimHan/B-3950-2009
OI Thung, KimHan/0000-0003-1379-2185
CR Agarwal A., 2010, NIPS, P46
   Ahmed B., 2016, Machine Learning for Healthcare Conference, P115
   Ando RK, 2005, J MACH LEARN RES, V6, P1817
   [Anonymous], ARXIV12064632
   [Anonymous], 2017, CoRR, abs/1707.08114
   [Anonymous], 2009, Proceedings of the 26th Annual International Conference on Machine Learning
   [Anonymous], 2012, AI Statistics
   [Anonymous], MULTITASK LEARNING
   [Anonymous], 2011, MALSAR: Multi-Task Learning via Structural Regularization
   Argyriou A, 2008, NIPS, V20
   Argyriou A., 2007, Advances in neural information processing systems, P41
   Argyriou A, 2015, MACHINE LEARNING SOF
   Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8
   Caruana R, 1998, LEARNING TO LEARN, P95, DOI 10.1007/978-1-4615-5529-2_5
   Chaichulee S, 2017, 2017 12 IEEE INT C A, P5110
   Chen JH, 2009, 2009 INTERNATIONAL ASIA SYMPOSIUM ON INTELLIGENT INTERACTION AND AFFECTIVE COMPUTING, P137, DOI 10.1049/cp.2009.1294
   Chen JH, 2012, ACM T KNOWL DISCOV D, V5, DOI 10.1145/2086737.2086742
   Chen Jianhui, 2011, P 17 ACM SIGKDD INT, P42
   Ciliberto C, 2017, MATMTL
   Ciliberto Carlo, 2015, INT C MACH LEARN ICM
   Collobert R, 2008, P 25 ICML, P160, DOI 10.1145/1390156.1390177
   Crichton G, 2017, SOFTWARE, DOI [10.17863/CAM.12584, DOI 10.17863/CAM.12584]
   Elgammal A, 2004, PROC CVPR IEEE, P478
   Evgeniou T, 2005, J MACH LEARN RES, V6, P615
   Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109, DOI DOI 10.1145/1014052.1014067
   Fan JP, 2017, IEEE T IMAGE PROCESS, V26, P1923, DOI 10.1109/TIP.2017.2667405
   Fang YC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1668
   Fazel M., 2002, THESIS STANFORD U ST
   Ghafoorian M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05300-5
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Godwin J, 2018, MULTITASK LEARNING 1
   Gong P., 2012, ADV NEURAL INFORM PR, P1988
   Gong PH, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P761, DOI 10.1145/2623330.2623641
   Gong Pinghua, 2012, KDD, V2012, P895
   Han L., 2016, P AAAI C ART INT
   Han L, 2014, AAAI CONF ARTIF INTE, P1854
   Han L, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P397, DOI 10.1145/2783258.2783393
   Hu RY, 2017, NEUROCOMPUTING, V220, P130, DOI 10.1016/j.neucom.2016.05.081
   Jacob L., 2009, ADV NEURAL INFORM PR, P745
   Jalali A, 2013, IEEE T INFORM THEORY, V59, P7947, DOI 10.1109/TIT.2013.2280272
   Jalali Ali, 2010, ADV NEURAL INFORM PR, P964
   Jebara T., 2004, Proceedings of the 21st International Conference on Machine Learning, page
   Jebara T, 2011, J MACH LEARN RES, V12, P75
   Kim Seyoung, 2010, ICML, P543
   Lee S., 2010, NIPS, P1306
   Li C, 2016, INT C PATT RECOG, P3156, DOI 10.1109/ICPR.2016.7900120
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306
   Liu F, 2014, NEUROIMAGE, V84, P466, DOI 10.1016/j.neuroimage.2013.09.015
   Liu GW, 2014, IEEE IMAGE PROC, P2869, DOI 10.1109/ICIP.2014.7025580
   Liu H., 2009, P 26 ANN INT C MACH, P649, DOI [10.1145/1553374.1553458, DOI 10.1145/1553374.1553458, 10.1145/1553374, DOI 10.1145/1553374]
   Liu J., 2013, SLEP: Sparse Learning with Efficient Projections
   Liu J., 2009, P 25 C UNCERTAINTY A, P339, DOI DOI 10.5555/1795114.1795154
   Liu J., 2010, ADV NEURAL INFORM PR, P1459
   Liu Mingxia, 2017, Med Image Comput Comput Assist Interv, V10435, P3, DOI 10.1007/978-3-319-66179-7_1
   Lozano A. C., 2012, P 29 INT C INT C MAC
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Mandal MK, 2018, MULTITASK LEARNING K
   Maurer A., 2013, INT C MACH LEARN, P343
   McDonald Andrew M, 2014, ADV NEURAL INFORM PR, P3644
   Moeskops P, 2017, ARXIV170403379V1
   Negahban S., 2008, P 21 INT C NEURAL IN
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Ng A., 2018, Multi-task learning
   Obozinski G., 2006, Tech. Rep. 2
   Obozinski G, 2010, STAT COMPUT, V20, P231, DOI 10.1007/s11222-008-9111-x
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pong TK, 2010, SIAM J OPTIMIZ, V20, P3465, DOI 10.1137/090763184
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Rao N. S., 2013, ADV NEURAL INFORM PR, P2202
   Ruder S, 2017, arXiv preprint arXiv:1706.05098
   Samala RK, 2018, PROC SPIE, V10575, DOI 10.1117/12.2293412
   Seltzer ML, 2013, INT CONF ACOUST SPEE, P6965, DOI 10.1109/ICASSP.2013.6639012
   Suo YM, 2014, IEEE IMAGE PROC, P150, DOI 10.1109/ICIP.2014.7025029
   Thung KH, 2014, NEUROIMAGE, V91, P386, DOI 10.1016/j.neuroimage.2014.01.033
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Titsias Michalis K, 2011, Advances in neural information processing systems
   Turlach BA, 2005, TECHNOMETRICS, V47, P349, DOI 10.1198/004017005000000139
   Vasilescu MAO, 2002, INT C PATT RECOG, P511, DOI 10.1109/ICPR.2002.1048350
   Vounou M, 2010, NEUROIMAGE, V53, P1147, DOI 10.1016/j.neuroimage.2010.07.002
   Wachinger C, 2018, NEUROIMAGE, V170, P434, DOI 10.1016/j.neuroimage.2017.02.035
   Wang H., 2012, P ADV NEUR INF PROC, P1277
   Wang HC, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P958, DOI 10.1109/ICCV.2003.1238452
   Wang J, 2015, PR MACH LEARN RES, V37, P1747
   Wang ZX, 2017, MED IMAGE ANAL, V39, P218, DOI 10.1016/j.media.2017.05.003
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wu ZZ, 2015, INT CONF ACOUST SPEE, P4460, DOI 10.1109/ICASSP.2015.7178814
   Xiang S, 2014, NEUROIMAGE, V102, P192, DOI 10.1016/j.neuroimage.2013.08.015
   Xin B, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2847421
   Xue WF, 2018, MED IMAGE ANAL, V43, P54, DOI 10.1016/j.media.2017.09.005
   Yan K, 2017, IEEE T INSTRUM MEAS, V66, P2306, DOI 10.1109/TIM.2017.2707898
   Yuan L, 2012, NEUROIMAGE, V61, P622, DOI 10.1016/j.neuroimage.2012.03.059
   Zhang C, 2014, IEEE WINT CONF APPL, P1036, DOI 10.1109/WACV.2014.6835990
   Zhang DQ, 2012, NEUROIMAGE, V59, P895, DOI 10.1016/j.neuroimage.2011.09.069
   Zhang J., 2006, Advances in neural information processing systems, P1585
   Zhang J, 2008, MACH LEARN, V73, P221, DOI 10.1007/s10994-008-5050-1
   Zhang Jun, 2017, Med Image Comput Comput Assist Interv, V10434, P720, DOI 10.1007/978-3-319-66185-8_81
   Zhang J, 2017, IEEE T IMAGE PROCESS, V26, P4753, DOI 10.1109/TIP.2017.2721106
   Zhang J, 2017, MULTIMED TOOLS APPL, V76, P17511, DOI 10.1007/s11042-016-4231-3
   Zhang S, 2017, IEEE T NEURAL NETWOR
   Zhang W, 2015, DEEP MODEL BASED TRA, DOI [10.1145/2783258.2783304, DOI 10.1145/2783258.2783304]
   Zhang Y.Yeung., 2012, A convex formulation for learning task relationships in multi-task learning
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zheng, 2013, TIME DEPENDENT TRAJE
   Zheng W, 2018, MULTIMED TOOLS APPL, V77, P29739, DOI 10.1007/s11042-017-5272-y
   Zhou Jiayu, 2012, KDD, V2012, P1095
   Zhou Jiayu, 2011, P 17 ACM SIGKDD INT, P814, DOI DOI 10.1145/2020408.2020549
   Zhou Y., 2010, JMLR WORKSHOP C P, P988
   Zhu X, 2017, IEEE T KNOWLEDGE DAT
   Zhu XF, 2017, IEEE T BIG DATA, V3, P405, DOI 10.1109/TBDATA.2017.2735991
   Zhu XF, 2017, IEEE T MULTIMEDIA, V19, P2033, DOI 10.1109/TMM.2017.2703636
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
   Zhu Xiaofeng, 2016, Med Image Comput Comput Assist Interv, V9900, P344, DOI 10.1007/978-3-319-46720-7_40
   Zhu XF, 2016, IEEE T BIO-MED ENG, V63, P607, DOI 10.1109/TBME.2015.2466616
   Zhu Yingying, 2017, Med Image Comput Comput Assist Interv, V10435, P205, DOI 10.1007/978-3-319-66179-7_24
   Zhu Yingying, 2016, Med Image Comput Comput Assist Interv, V9900, P106, DOI 10.1007/978-3-319-46720-7_13
NR 116
TC 126
Z9 139
U1 20
U2 147
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29705
EP 29725
DI 10.1007/s11042-018-6463-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800029
DA 2024-07-18
ER

PT J
AU Wu, JX
   Zhong, SH
   Ma, Z
   Heinen, SJ
   Jiang, JM
AF Wu, Jiaxin
   Zhong, Sheng-hua
   Ma, Zheng
   Heinen, Stephen J.
   Jiang, Jianmin
TI Foveated convolutional neural networks for video summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Convolutional neural networks; Eye movement;
   Foveated image
ID REPRESENTATION; GAZE
AB With the proliferation of video data, video summarization is an ideal tool for users to browse video content rapidly. In this paper, we propose a novel foveated convolutional neural networks for dynamic video summarization. We are the first to integrate gaze information into a deep learning network for video summarization. Foveated images are constructed based on subjects' eye movements to represent the spatial information of the input video. Multi-frame motion vectors are stacked across several adjacent frames to convey the motion clues. To evaluate the proposed method, experiments are conducted on two video summarization benchmark datasets. The experimental results validate the effectiveness of the gaze information for video summarization despite the fact that the eye movements are collected from different subjects from those who generated summaries. Empirical validations also demonstrate that our proposed foveated convolutional neural networks for video summarization can achieve state-of-the-art performances on these benchmark datasets.
C1 [Wu, Jiaxin; Zhong, Sheng-hua; Jiang, Jianmin] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Guangdong, Peoples R China.
   [Ma, Zheng; Heinen, Stephen J.] Smith Kettlewell Eye Res Inst, 2232 Webster St, San Francisco, CA 94115 USA.
C3 Shenzhen University; The Smith-Kettlewell Eye Research Institute
RP Wu, JX (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Guangdong, Peoples R China.
EM jiaxin.wu@email.szu.edu.cn; csshzhong@szu.edu.cn; zma@ski.org;
   heinen@ski.org; jianmin.jiang@szu.edu.cn
RI Ma, Zheng/O-9674-2018; Wu, Jiaxin/GVT-3486-2022
OI Ma, Zheng/0000-0002-9134-1032; 
FU National Natural Science Foundation of China [61502311, 61620106008];
   Natural Science Foundation of Guangdong Province [2016A030310053];
   Special Program for Applied Research on Super Computation of the
   NSFC-Guangdong Joint Fund (the second phase) [U1501501]; Shenzhen
   Emerging Industries of the Strategic Basic Research Project
   [JCYJ20160226191842793]; Shenzhen high-level overseas talents program;
   Tencent "Rhinoceros Birds" - Scientific Research Foundation for Young
   Teachers of Shenzhen University
FX This work was supported by the National Natural Science Foundation of
   China (No. 61502311, No. 61620106008), the Natural Science Foundation of
   Guangdong Province (No. 2016A030310053), the Special Program for Applied
   Research on Super Computation of the NSFC-Guangdong Joint Fund (the
   second phase) under Grant (No.U1501501), the Shenzhen Emerging
   Industries of the Strategic Basic Research Project under Grant (No.
   JCYJ20160226191842793), the Shenzhen high-level overseas talents
   program, and the Tencent "Rhinoceros Birds" - Scientific Research
   Foundation for Young Teachers of Shenzhen University.
CR [Anonymous], 2015, CORR
   [Anonymous], 2002, P 10 ACM INT C MULT
   [Anonymous], P EUR C COMP VIS
   [Anonymous], P EUR C COMP VIS
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Bradley MM, 2015, PSYCHOPHYSIOLOGY, V52, P1186, DOI 10.1111/psyp.12442
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   DANIEL PM, 1961, J PHYSIOL-LONDON, V159, P203, DOI 10.1113/jphysiol.1961.sp006803
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Detenber BH, 1998, J BROADCAST ELECTRON, V42, P113
   Drucker H, 1997, ADV NEUR IN, V9, P155
   Pereira MLGF, 2014, NEUROPSYCH DIS TREAT, V10, P1273, DOI 10.2147/NDT.S55371
   Fu YW, 2010, IEEE T MULTIMEDIA, V12, P717, DOI 10.1109/TMM.2010.2052025
   Guenter B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366183
   Gygli M., 2015, P 2015 IEEE C COMP V
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Holmberg N., 2015, J EYE MOVEMENT RES, V8, P1, DOI 10.16910/jemr.8.2.2
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Kantorov V, 2014, PROC CVPR IEEE, P2593, DOI 10.1109/CVPR.2014.332
   Karessli N, 2017, P 2017 IEEE C COMP V
   Kleiner M, 2007, PERCEPTION, V36, P14
   Li Y, 2013, IEEE I CONF COMP VIS, P3216, DOI 10.1109/ICCV.2013.399
   Li YJ, 2010, 2010 INTERNATIONAL COLLOQUIUM ON COMPUTING, COMMUNICATION, CONTROL, AND MANAGEMENT (CCCM2010), VOL III, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahasseni B, 2017, P 2017 IEEE C COMP V
   Mishra AK, 2012, IEEE T PATTERN ANAL, V34, P639, DOI 10.1109/TPAMI.2011.171
   Nelson AL, 2015, COGNITION EMOTION, V29, P504, DOI 10.1080/02699931.2014.922460
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Papoutsaki Alexandra, 2016, P 25 INT JOINT C ART, P3839, DOI [DOI 10.5555/3061053.3061156, 10.5555/3061053.3061156, DOI 10.1145/2702613.2702627]
   Potapov D, 2014, P EUR C COMP VIS
   ROVAMO J, 1979, EXP BRAIN RES, V37, P495, DOI 10.1007/bf00236819
   Salehin Md Musfequs, 2017, 2017 IEEE International Conference on Multimedia and Expo: Workshops (ICMEW), P692, DOI 10.1109/ICMEW.2017.8026294
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   SONG YL, 2015, PROC CVPR IEEE, P5179, DOI [DOI 10.1109/CVPR.2015.7299154, 10.1109/CVPR.2015.7299154]
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Vul E., 2009, Advances in Neural Information Processing Systems, P1955
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang Z, 2003, P SPIE INT SOC OPTIC, P4472
   Wick DV, 2002, OPT EXPRESS, V10, P60, DOI 10.1364/OE.10.000060
   Wu JX, 2017, MULTIMED TOOLS APPL, V76, P9625, DOI 10.1007/s11042-016-3569-x
   Xie YH, 2007, IJCSES, V1, P159
   Xu J, 2015, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2015.7298836
   Yao Ting, 2016, PROC CVPR IEEE, P982, DOI DOI 10.1109/CVPR.2016.112
   Yun KW, 2013, PROC CVPR IEEE, P739, DOI 10.1109/CVPR.2013.101
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhang BW, 2016, PROC CVPR IEEE, P2718, DOI 10.1109/CVPR.2016.297
   Zhang K, 2016, P 2016 IEEE C COMP V
   Zhang M, 2017, P 2017 IEEE C COMP V
   Zhao S, 2018, IEEE J BIOMED HEALTH, V22, P1571, DOI 10.1109/JBHI.2017.2776246
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 51
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29245
EP 29267
DI 10.1007/s11042-018-5953-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800004
DA 2024-07-18
ER

PT J
AU Zhu, HY
   Liu, QL
   Qi, YK
   Huang, XY
   Jiang, F
   Zhang, SP
AF Zhu, Heyan
   Liu, Qinglin
   Qi, Yuankai
   Huang, Xinyuan
   Jiang, Feng
   Zhang, Shengping
TI Plant identification based on very deep convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Plant identification; CNN; Linear SVM
ID LEAF; RECOGNITION; FEATURES; SYSTEM
AB Plant identification is a critical step in protecting plant diversity. However, many existing identification systems prohibitively rely on hand-crafted features for plant species identification. In this paper, a deep learning method is employed to extract discriminative features from plant images along with a linear SVM for plant identification. To offer a self-learning feature representation for different plant organs, we choose a very deep convolutional neural networks (CNNs), which consists of sixteen convolutional layers followed by three Fully-Connected (FC) layers and a final soft-max layer. Five max-pooling layers are performed over a 2x2 pixel window with stride 2. Extensive experiments on several plant datasets demonstrate the remarkable performance of the very deep neural network compared to the hand-crafted features.
C1 [Zhu, Heyan] Beijing Forestry Univ, Sch Informat, Beijing, Peoples R China.
   [Zhu, Heyan] Yantai Univ, Sch Optoelect Informat, Yantai, Peoples R China.
   [Liu, Qinglin; Zhang, Shengping] Harbin Inst Technol, Sch Comp Sci & Technol, Weihai, Peoples R China.
   [Qi, Yuankai; Jiang, Feng] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
   [Huang, Xinyuan] Commun Univ China, Inst Animat & Digital Art, Beijing, Peoples R China.
C3 Beijing Forestry University; Yantai University; Harbin Institute of
   Technology; Harbin Institute of Technology; Communication University of
   China
RP Zhang, SP (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Weihai, Peoples R China.
EM s.zhang@hit.edu.cn
RI Qi, Yuankai/GYE-2289-2022; Chen, Rainie/ISS-6016-2023; JIANG,
   Feng/HTP-2862-2023; Liu, Qinglin/HMD-1377-2023
OI Liu, Qinglin/0000-0002-2408-3344; Qi, Yuankai/0000-0003-4312-5682
FU key R&D program of Yantai City [2016YT06000609]
FX This work is supported by the key R&D program of Yantai City (No.
   2016YT06000609).
CR [Anonymous], 2012, P 1 ACM INT WORKSH M
   [Anonymous], 2010, Proceedings of the Conference on Image and Video Retrieval
   [Anonymous], 2011, P 16 COMP VIS WINT W
   [Anonymous], CLEF
   [Anonymous], 2015, J COMPUT INFORM SYST
   [Anonymous], P 5 INT MULT C
   [Anonymous], 2015, TREEID IMAGE RECOGNI
   [Anonymous], P COMPUTER VISION PA
   [Anonymous], P INT C COMP VIS IM
   [Anonymous], 2013, P 3 ACM C INT C MULT
   [Anonymous], 2014, P 31 INT C INT C MAC
   [Anonymous], 2010, Int. J. Comput. Appl.
   [Anonymous], 2011, International Journal of Computer Applications, DOI DOI 10.5120/1756-2395
   [Anonymous], 2012, P 2 ACM INT C MULT R
   [Anonymous], INT J COMPUTER SCI N
   [Anonymous], CLEF
   [Anonymous], P C LABS EV FOR
   [Anonymous], 2014, Int. J. Innov. Res. Comput. Commun. Eng
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2013, Int. 1.Bar Sci. Bio Technol., DOI [10.3724/sp.j.1087.2009.01707, DOI 10.1007/978-94-007-5857-5_12]
   [Anonymous], INT J COMPUT SCI BUS
   [Anonymous], LIFECLEF PLANT IDENT
   Barré P, 2017, ECOL INFORM, V40, P50, DOI 10.1016/j.ecoinf.2017.05.005
   Belhumeur PN, 2008, LECT NOTES COMPUT SC, V5305, P116, DOI 10.1007/978-3-540-88693-8_9
   Ben Mabrouk A, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P201
   Bo LF, 2013, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2013.91
   Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963
   Chaki J, 2011, INT J ADV COMPUT SC, V2, P41
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Du JX, 2007, APPL MATH COMPUT, V185, P883, DOI 10.1016/j.amc.2006.07.072
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P3277, DOI 10.1109/TIP.2017.2696747
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P1344, DOI 10.1109/TIP.2017.2652730
   Hsiao JK, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P389, DOI 10.1109/SAI.2014.6918216
   Jiang F, 2015, J MACH LEARN RES, V16, P227
   Jou-Ken Hsiao, 2014, 2014 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P209, DOI 10.1109/ICCE-TW.2014.6904061
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lee H., 2009, P 26 ANN INT C MACH, P609
   Lee SH, 2015, IEEE IMAGE PROC, P452, DOI 10.1109/ICIP.2015.7350839
   Lin ZJ, 2017, IEEE T CYBERNETICS, V47, P4342, DOI 10.1109/TCYB.2016.2608906
   Liu Q, 2017, KNOWL-BASED SYST, V134, P189, DOI 10.1016/j.knosys.2017.07.032
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma LH, 2013, LECT NOTES COMPUT SC, V7995, P106, DOI 10.1007/978-3-642-39479-9_13
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Pradeep Kumar T., 2017, P INT C COMP VIS IM, V2, P531
   Nguyen QK, 2013, PROC INT CONF ADV, P404, DOI 10.1109/ATC.2013.6698145
   Ren XM, 2012, LECT NOTES ARTIF INT, V7390, P237, DOI 10.1007/978-3-642-31576-3_31
   Satti V., 2013, International Journal of Engineering Science and Technology (IJEST), V4, P874
   Seon-Jong Kim, 2011, SICE 2011 - 50th Annual Conference of the Society of Instrument and Control Engineers of Japan, P1147
   Shen ZW, 2016, 2016 13TH CHINA INTERNATIONAL FORUM ON SOLID STATE LIGHTING: INTERNATIONAL FORUM ON WIDE BANDGAP SEMICONDUCTORS CHINA (SSLCHINA: IFWS), P1, DOI 10.1109/IFWS.2016.7803742
   Singh Krishna., 2010, International Journal of Signal Processing Image Processing and Pattern Recognition, V3, P67
   Song Y, 2014, BIOSYST ENG, V118, P203, DOI 10.1016/j.biosystemseng.2013.12.008
   Sun BY, 2004, LECT NOTES COMPUT SC, V3173, P648
   Tsolakidis DG, 2014, LECT NOTES ARTIF INT, V8445, P406, DOI 10.1007/978-3-319-07064-3_33
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang XF, 2008, APPL MATH COMPUT, V205, P916, DOI 10.1016/j.amc.2008.05.108
   Wang Z, 2003, IEE P-VIS IMAGE SIGN, V150, P34, DOI 10.1049/ip-vis:20030160
   Wilf P, 2016, P NATL ACAD SCI USA, V113, P3305, DOI 10.1073/pnas.1524473113
   Xiao XY, 2010, LECT NOTES ARTIF INT, V6216, P149, DOI 10.1007/978-3-642-14932-0_19
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474
   Zhang BC, 2017, IEEE T IMAGE PROCESS, V26, P4648, DOI 10.1109/TIP.2017.2718189
   Zhang CY, 2015, CIT/IUCC/DASC/PICOM 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - UBIQUITOUS COMPUTING AND COMMUNICATIONS - DEPENDABLE, AUTONOMIC AND SECURE COMPUTING - PERVASIVE INTELLIGENCE AND COMPUTING, P2147, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.318
   Zhang SP, 2018, IEEE T INTELL TRANSP, V19, P187, DOI 10.1109/TITS.2017.2766093
   Zhang SP, 2017, IEEE T CIRC SYST VID, V27, P421, DOI 10.1109/TCSVT.2016.2539860
   Zhang SP, 2015, IEEE T CIRC SYST VID, V25, P1749, DOI 10.1109/TCSVT.2015.2406194
   Zhao C, 2015, PATTERN RECOGN, V48, P3203, DOI 10.1016/j.patcog.2015.04.004
   Zhao ZQ, 2015, LECT NOTES COMPUT SC, V9004, P348, DOI 10.1007/978-3-319-16808-1_24
   Zhiyong Wang, 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P650, DOI 10.1109/DICTA.2011.115
   Zhu HY, 2017, MULTIMED TOOLS APPL, V76, P4599, DOI 10.1007/s11042-016-3538-4
NR 72
TC 23
Z9 23
U1 2
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29779
EP 29797
DI 10.1007/s11042-017-5578-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800034
DA 2024-07-18
ER

PT J
AU Avola, D
   Cinque, L
   Foresti, GL
   Marini, MR
   Pannone, D
AF Avola, Danilo
   Cinque, Luigi
   Foresti, Gian Luca
   Marini, Marco Raoul
   Pannone, Daniele
TI VRheab: a fully immersive motor rehabilitation system based on recurrent
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rehabilitation; Virtual reality; Human-computer interaction; Sensors
   data fusion; Deep learning
ID PARKINSONS-DISEASE; PHYSICAL-THERAPY; VIRTUAL-REALITY; DESIGN; STROKE;
   SENSOR
AB In this paper, a fully immersive serious game system that combines two Natural User Interfaces (NUIs) and a Head Mounted Display (HMD) to provide an interactive Virtual Environment (VE) for patient rehabilitation is proposed. Patients' data are acquired in real-time by the NUIs, while by the HMD the VE is shown to them, thus allowing the interaction. A Long Short-Term Memory Recurrent Neural Network (LSTM-RNN), previously trained by healthy subjects (i.e., baseline), processes patients' movements in real-time during the rehabilitation exercises to provide the degree of their performance. By comparing the functionalities of the proposed system with the ongoing state-of-the-art, it is worth noting that the reported fully immersive serious game system provides a concrete contribute to the current literature in terms of completeness and versatility. The results obtained by three rehabilitation exercises, chosen as reference case studies, performed on real patients affected by Parkinson's disease have shown the effectiveness of the presented approach. Finally, the analysis of the feedbacks received by the therapists and patients who have used the system have highlighted remarkable results in terms of motivation, acceptance, and usability.
C1 [Avola, Danilo; Foresti, Gian Luca] Univ Udine, Dept Math Comp Sci & Phys, Via Sci 206, I-33100 Udine, Italy.
   [Cinque, Luigi; Marini, Marco Raoul; Pannone, Daniele] Sapienza Univ, Dept Comp Sci, Via Salaria 113, I-00198 Rome, Italy.
C3 University of Udine; Sapienza University Rome
RP Avola, D (corresponding author), Univ Udine, Dept Math Comp Sci & Phys, Via Sci 206, I-33100 Udine, Italy.
EM danilo.avola@uniud.it; cinque@di.uniroma1.it; gianluca.foresti@uniud.it;
   marini@di.uniroma1.it; pannone@di.uniroma1.it
RI Hidayat, Ima Kusumawati/ABF-6870-2021; Pannone, Daniele/ABD-2058-2021;
   Marini, Marco Raoul/AAR-5812-2021
OI Hidayat, Ima Kusumawati/0000-0002-3387-9213; Marini, Marco
   Raoul/0000-0002-2540-2570; PANNONE, DANIELE/0000-0001-6446-6473
CR Ai BL, 2017, IEEE WINT CONF APPL, P1224, DOI 10.1109/WACV.2017.141
   Alimanova M, 2017, 2017 FIRST IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC), P336, DOI 10.1109/IRC.2017.76
   Angra S, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON BIG DATA ANALYTICS AND COMPUTATIONAL INTELLIGENCE (ICBDAC), P57, DOI 10.1109/ICBDACI.2017.8070809
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], CONTR C ASCC 2015 10
   Asadi-Aghbolaghi M, 2017, IEEE INT CONF AUTOMA, P476, DOI 10.1109/FG.2017.150
   Avola D, 2013, COMPUT METH PROG BIO, V110, P490, DOI 10.1016/j.cmpb.2013.01.009
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Brau E, 2016, INT CONF 3D VISION, P582, DOI 10.1109/3DV.2016.84
   Brooke J, 2013, J USABILITY STUD, V8, P29
   BYEON W, 2015, PROC CVPR IEEE, P3547, DOI DOI 10.1109/CVPR.2015.7298977
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Chung J., 2014, NIPS 2014 WORKSH DEE, Vabs/1412.3555, P1, DOI DOI 10.48550/ARXIV.1412.3555
   Crosbie JH, 2006, CYBERPSYCHOL BEHAV, V9, P137, DOI 10.1089/cpb.2006.9.137
   Desai P.Rajesh., 2014, International Journal of Engineering Trends and Technology, V13, P175, DOI [10.14445/22315381/IJETT-V13P237, DOI 10.14445/22315381/IJETT-V13P237]
   Dorsey ER, 2007, NEUROLOGY, V68, P384, DOI 10.1212/01.wnl.0000247740.47667.03
   Feng XD, 2013, NEURAL REGEN RES, V8, P1423, DOI 10.3969/j.issn.1673-5374.2013.15.010
   García-Martínez S, 2015, 2015 INTERNATIONAL CONFERENCE ON VIRTUAL REHABILITATION PROCEEDINGS (ICVR), P235, DOI 10.1109/ICVR.2015.7358573
   Gargantini A., 2015, Proceedings of the 3rd 2015 Workshop on ICTs for improving Patients Rehabilitation Research Techniques, P81, DOI [10.1145/2838944.2838964, DOI 10.1145/2838944.2838964]
   Gobron SC, 2015, LECT NOTES COMPUT SC, V9254, P199, DOI 10.1007/978-3-319-22888-4_15
   Golomb MR, 2010, ARCH PHYS MED REHAB, V91, P1, DOI 10.1016/j.apmr.2009.08.153
   Guna J, 2014, SENSORS-BASEL, V14, P3702, DOI 10.3390/s140203702
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Hansard M, 2013, SPRINGERBRIEFS COMPU, P95
   Harrington MCR, 2011, IEEE T LEARN TECHNOL, V4, P175, DOI 10.1109/TLT.2010.20
   Hermans M., 2013, Advances in neural information processing systems, V26
   Hirsch MA, 2009, EUR J PHYS REHAB MED, V45, P215
   Holzinger Andreas, 2012, Information Technology in Bio- and Medical Informatics. Proceedings of the Third International Conference, ITBAM 2012, P166, DOI 10.1007/978-3-642-32395-9_13
   Horaud R, 2016, MACH VISION APPL, V27, P1005, DOI 10.1007/s00138-016-0784-4
   Huang ZW, 2017, PROC CVPR IEEE, P1243, DOI 10.1109/CVPR.2017.137
   Ijjina EP, 2017, PATTERN RECOGN, V72, P504, DOI 10.1016/j.patcog.2017.07.013
   Jorissen P, 2005, IEEE T VIS COMPUT GR, V11, P649, DOI 10.1109/TVCG.2005.100
   Kato N, 2016, INT CONF COMP SCI ED, P285, DOI 10.1109/ICCSE.2016.7581595
   Keus SHJ, 2009, MOVEMENT DISORD, V24, P1, DOI 10.1002/mds.22141
   Knight A., 2016, 9 ACM INT C PERV TEC, P1
   Kwakkel G, 2007, PARKINSONISM RELAT D, V13, pS478, DOI 10.1016/S1353-8020(08)70053-1
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li SJ, 2017, INT J COMPUT VISION, V122, P149, DOI 10.1007/s11263-016-0962-x
   Luis MAVS, 2016, 2016 10TH INTERNATIONAL CONFERENCE ON NEXT GENERATION MOBILE APPLICATIONS, SECURITY AND TECHNOLOGIES (NGMAST), P47, DOI 10.1109/NGMAST.2016.13
   Miljkovic D, 2016, LECT NOTES COMPUT SC, V9605, P209, DOI 10.1007/978-3-319-50478-0_10
   Munroe C, 2016, ACMIEEE INT CONF HUM, P565, DOI 10.1109/HRI.2016.7451858
   Nielsen J, 1990, Proceedings ACM CHI'90 Conf, DOI [DOI 10.1145/97243.97281, 10.1145/97243.97281]
   Oak JW, 2014, INT J MULTIMEDIA UBI, V9, P263, DOI DOI 10.14257/IJMUE.2014.9.7.22
   Patterson RE., 2015, HUMAN FACTORS STEREO, P9, DOI DOI 10.1007/978-1-4471-6651-1_2
   Pei W, 2016, INT CONF UBIQ ROBOT, P353, DOI 10.1109/URAI.2016.7734059
   Pellecchia MT, 2004, J NEUROL, V251, P595, DOI 10.1007/s00415-004-0379-2
   Placidi G, 2014, COMPUT METH PROG BIO, V117, P322, DOI 10.1016/j.cmpb.2014.06.020
   Placidi G, 2013, COMPUT BIOL MED, V43, P1927, DOI 10.1016/j.compbiomed.2013.08.026
   Rawat S, 2016, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON SYSTEM MODELING & ADVANCEMENT IN RESEARCH TRENDS (SMART-2016), P115, DOI 10.1109/SYSMART.2016.7894501
   Rego P, 2010, SISTEMAS Y TECNOLOGIAS DE INFORMACION, P349
   Saini S., 2012, 2012 Proceedings of International Conference on Computer & Information Science (ICCIS 2012), P55, DOI 10.1109/ICCISci.2012.6297212
   Sak H, 2014, INTERSPEECH, P338
   Sargano AB, 2017, IEEE IJCNN, P463, DOI 10.1109/IJCNN.2017.7965890
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shiratuddin M. F., 2012, Proceedings of the 2012 International Conference on Computer & Information Science (ICCIS), P1052, DOI 10.1109/ICCISci.2012.6297181
   Singh D, 2017, LECT NOTES COMPUT SC, V10410, P267, DOI 10.1007/978-3-319-66808-6_18
   Sosa GD, 2015, 20 S SIGN PROC IM CO, P1
   Wasenmüller O, 2017, LECT NOTES COMPUT SC, V10117, P34, DOI 10.1007/978-3-319-54427-4_3
   Weiss Patrice L, 2004, J Neuroeng Rehabil, V1, P12, DOI 10.1186/1743-0003-1-12
   Zhang XY, 2017, IEEE T HUM-MACH SYST, V47, P285, DOI 10.1109/THMS.2016.2634921
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 61
TC 31
Z9 32
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 24955
EP 24982
DI 10.1007/s11042-018-5730-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400017
DA 2024-07-18
ER

PT J
AU Chatterjee, I
   Agarwal, M
   Rana, B
   Lakhyani, N
   Kumar, N
AF Chatterjee, Indranath
   Agarwal, Manoj
   Rana, Bharti
   Lakhyani, Navin
   Kumar, Naveen
TI Bi-objective approach for computer-aided diagnosis of schizophrenia
   patients using fMRI data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Functional magnetic resonance imaging (fMRI); Schizophrenia;
   Computer-aided diagnosis (CAD); Feature selection; NSGA-II; Bi-objective
   evolutionary algorithm
ID PRINCIPAL COMPONENT ANALYSIS; FUNCTIONAL CONNECTIVITY; SUBSTANTIA-NIGRA;
   HEALTHY CONTROLS; CLASSIFICATION; VOLUME; PATTERNS; FEATURES
AB Computer-aided diagnosis (CAD) of schizophrenia based on the analysis of brain images, captured using functional Magnetic Resonance Imaging (fMRI) technique, is an active area of research. The main problem lies in the identification of brain regions that contribute to differentiating between a healthy subject and a schizophrenia affected subject. The problem becomes complex due to the high dimensionality of the fMRI data on the one hand and the availability of data for only a small number of subjects on the other hand. In this paper, we propose a three-stage evolutionary based framework for feature selection. It comprises application of general linear model, followed by statistical hypothesis testing, and finally application of Non-dominated Sorting Genetic Algorithm (NSGA-II) to arrive at a small set of about fifty features. Experiments show that the feature set generated by the proposed approach yields accuracy as high as 99.5% in classifying fMRI dataset of healthy and schizophrenia subjects, and can identify the relevant brain regions that are affected in schizophrenia.
C1 [Chatterjee, Indranath; Kumar, Naveen] Univ Delhi, Dept Comp Sci, Delhi 110007, India.
   [Agarwal, Manoj; Rana, Bharti] Univ Delhi, Dept Comp Sci, Hans Raj Coll, Delhi 110007, India.
   [Lakhyani, Navin] Saral Diagnost, Dept MRI, New Delhi 110034, India.
C3 University of Delhi; University of Delhi
RP Chatterjee, I (corresponding author), Univ Delhi, Dept Comp Sci, Delhi 110007, India.
EM indranath.cs.du@gmail.com; agar.manoj@gmail.com;
   bhartirana.it@gmail.com; navinlakhyani@gmail.com; nk.cs.du@gmail.com
RI Agarwal, Manoj/AAU-8614-2021; KUMAR, NAVEEN/N-9993-2018; -,
   BHARTI/IQR-9133-2023; Chatterjee, Indranath/GRO-4311-2022
OI Chatterjee, Indranath/0000-0001-9242-8888
FU Council of Scientific & Industrial Research (CSIR), India
   [09/045(1323)/2014-EMR-I]; University of Delhi [RC/2015/9677]; 
   [U24-RR021992];  [U24 GM104203];  [2007-BDR-6UHZ1]
FX We are thankful to Prof. R. K. Agrawal, School of Computer & Systems
   Sciences, Jawaharlal Nehru University, Delhi, India for his insightful
   comments. Indranath Chatterjee is thankful to the Council of Scientific
   & Industrial Research (CSIR), India for his research fellowship with
   grant number 09/045(1323)/2014-EMR-I. Naveen Kumar is thankful to
   University of Delhi for the research grant RC/2015/9677. Data used here
   for this study were downloaded from the Function BIRN Data Repository
   (http://fbirnbdr.birncommunity.org: 8080/BDR/), i.e., Biomedical
   Informatics Research Network under the following support: for function
   data, U24-RR021992, Function BIRN and U24 GM104203, Bio-Informatics
   Research Network Coordinating Center (BIRN-CC). These data were obtained
   from the Function BIRN Data Repository, Project Accession Number
   2007-BDR-6UHZ1.
CR Åberg M, 2008, BIOSIGNALS 2008: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON BIO-INSPIRED SYSTEMS AND SIGNAL PROCESSING, VOL II, P302
   Agarwal M, 2014, EXPERT SYST APPL, V41, P3736, DOI 10.1016/j.eswa.2013.11.044
   Aliakbaryhosseinabadi S, 2017, BRAIN RES, V1674, P10, DOI 10.1016/j.brainres.2017.08.016
   Arribas JI, 2010, IEEE T BIO-MED ENG, V57, P2850, DOI 10.1109/TBME.2010.2080679
   Bellman R. E., 1961, ADAPTIVE CONTROL PRO
   Bhattacharyya A, 1946, SANKHYA, V7, P401
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Caprihan A, 2008, NEUROIMAGE, V42, P675, DOI 10.1016/j.neuroimage.2008.04.255
   Castro E, 2014, NEUROIMAGE, V87, P1, DOI 10.1016/j.neuroimage.2013.10.065
   Castro E, 2011, NEUROIMAGE, V58, P526, DOI 10.1016/j.neuroimage.2011.06.044
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen J, 2013, AM J MED GENET B, V162B, P191, DOI 10.1002/ajmg.b.32131
   Chyzhyk D, 2015, NEURAL NETWORKS, V68, P23, DOI 10.1016/j.neunet.2015.04.002
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Demirci O, 2008, BRAIN IMAGING BEHAV, V2, P207, DOI 10.1007/s11682-008-9028-1
   Du W, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00145
   Ford J, 2003, LECT NOTES COMPUT SC, V2879, P58
   Ford J, 2002, P ANN INT IEEE EMBS, P48, DOI 10.1109/IEMBS.2002.1134381
   Fortin FA, 2013, GECCO'13: PROCEEDINGS OF THE 2013 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P615
   Frances A., 1994, DIAGNOSTIC STAT MANU
   Friston KJ., 1994, HUMAN BRAIN MAPPING, V2, P189, DOI [10.1002/hbm.460020402, DOI 10.1002/HBM.460020402]
   Garrity AG, 2007, AM J PSYCHIAT, V164, P450, DOI 10.1176/appi.ajp.164.3.450
   Gur Raquel E, 2010, Dialogues Clin Neurosci, V12, P333
   Honea RA, 2008, BIOL PSYCHIAT, V63, P465, DOI 10.1016/j.biopsych.2007.05.027
   IRAGUI VJ, 1993, PSYCHOPHYSIOLOGY, V30, P10, DOI 10.1111/j.1469-8986.1993.tb03200.x
   Juneja A, 2017, MULTIMED TOOLS APPL, P1
   Juneja A, 2014, P 2014 IND C COMP VI, P37
   Juneja A, 2016, BIOMED SIGNAL PROCES, V27, P122, DOI 10.1016/j.bspc.2016.02.009
   Kiehl KA, 2001, SCHIZOPHR RES, V48, P159, DOI 10.1016/S0920-9964(00)00117-1
   Kim DI, 2009, SCHIZOPHRENIA BULL, V35, P67, DOI 10.1093/schbul/sbn133
   Kim J, 2016, NEUROIMAGE, V124, P127, DOI 10.1016/j.neuroimage.2015.05.018
   Kriegeskorte N, 2009, NAT NEUROSCI, V12, P535, DOI 10.1038/nn.2303
   Lancaster JL, 2012, FRONT NEUROINFORM, V6, DOI 10.3389/fninf.2012.00023
   Lancaster JL, 2000, HUM BRAIN MAPP, V10, P120, DOI 10.1002/1097-0193(200007)10:3<120::AID-HBM30>3.0.CO;2-8
   Linden DEJ, 1999, CEREB CORTEX, V9, P815, DOI 10.1093/cercor/9.8.815
   Koolschijn PCMP, 2008, EUR NEUROPSYCHOPHARM, V18, P312, DOI 10.1016/j.euroneuro.2007.12.004
   Ma X, 2016, BRAIN INFORM, P1
   Mitchell TM, 2004, MACH LEARN, V57, P145, DOI 10.1023/B:MACH.0000035475.85309.1b
   Niiniskorpi T, 2009, BIOSIGNALS 2009: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON BIO-INSPIRED SYSTEMS AND SIGNAL PROCESSING, P279
   O'Brien JL, 2017, FRONT AGING NEUROSCI, V9, DOI 10.3389/fnagi.2017.00322
   OGAWA S, 1990, P NATL ACAD SCI USA, V87, P9868, DOI 10.1073/pnas.87.24.9868
   Riaz A, 2017, LECT N BIOINFORMAT, V10511, P70, DOI 10.1007/978-3-319-67159-8_9
   Savio A, 2015, NEUROCOMPUTING, V164, P154, DOI 10.1016/j.neucom.2015.01.079
   Shahamat H., 2015, J AI DATA MIN, V3, P30, DOI DOI 10.5829/ID0SI.JAIDM.2015.03.01.04
   Shi F, 2007, LECT NOTES COMPUT SC, V4792, P136
   Smart O, 2015, ENG APPL ARTIF INTEL, V39, P198, DOI 10.1016/j.engappai.2014.12.008
   Ulker CC, 2013, P 6 BALK C INF ACM, P129
   Ungar L, 2010, PSYCHIAT RES-NEUROIM, V181, P24, DOI 10.1016/j.pscychresns.2009.07.005
   Viviani R, 2005, HUM BRAIN MAPP, V24, P109, DOI 10.1002/hbm.20074
   WELCH BL, 1947, BIOMETRIKA, V34, P28, DOI 10.2307/2332510
   Williams MR, 2014, EUR ARCH PSY CLIN N, V264, P285, DOI 10.1007/s00406-013-0479-z
   Wu L, 2017, PATTERN RECOGN, V65, P238, DOI 10.1016/j.patcog.2016.12.022
   Yoon JH, 2013, BIOL PSYCHIAT, V74, P122, DOI 10.1016/j.biopsych.2012.11.018
   Zang YF, 2004, NEUROIMAGE, V22, P394, DOI 10.1016/j.neuroimage.2003.12.030
NR 54
TC 19
Z9 19
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26991
EP 27015
DI 10.1007/s11042-018-5901-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500034
DA 2024-07-18
ER

PT J
AU Hodeish, ME
   Humbe, VT
AF Hodeish, Mahmoud E.
   Humbe, Vikas T.
TI An Optimized Halftone Visual Cryptography Scheme Using Error Diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Halftone Visual Cryptography (HVC); Objective evaluation metrics; Error
   diffusion; Visual cryptography; Steganography
AB Halftone Visual Cryptography (HVC) is an encryption technique that encodes the secret image into halftone images in order to produce secure meaningful shares. Many methods have been proposed for developing HVC to protect the security of the images. Yet, these methods still have some problems such as poor visual quality of shares, large pixel expansion, interference of secret image on shared images, and interference shared images on retrieved image. To solve such problems, an optimized HVC scheme (OHVCS) using Error Diffusion (ED) is proposed in this paper. The proposed scheme eliminates the explicit requirement of codebook and reduces the random patterns of the shared images, as it encodes only the black pixels of the secret image, taking into account that the pixel expansion is the smallest size to be used. Moreover, it performs the basic concept of Visual Cryptography (VC); therefore, the security of the construction scheme is assured. The experimental results, performance evaluation through statistical analysis, and comparison with some existing schemes in various aspects of HVC show the effectiveness of the proposed scheme.
C1 [Hodeish, Mahmoud E.] Swami Ramanand Teerth Marathwada Univ, Sch Computat Sci, Nanded 431606, MS, India.
   [Humbe, Vikas T.] Swami Ramanand Teerth Marathwada Univ, Sch Technol, Subctr Latur, Nanded 413512, MS, India.
C3 Swami Ramanand Teerth Marathwada University; Swami Ramanand Teerth
   Marathwada University
RP Hodeish, ME (corresponding author), Swami Ramanand Teerth Marathwada Univ, Sch Computat Sci, Nanded 431606, MS, India.
EM mah_hodeish@yahoo.com
RI Humbe, Vikas T/O-2635-2014
CR Alex N. S., 2011, 2011 3rd International Conference on Electronics Computer Technology (ICECT 2011), P393, DOI 10.1109/ICECTECH.2011.5941725
   [Anonymous], INT J SCI TECHNOLEDG
   [Anonymous], 2013, 2013 26 IEEE CAN C E, DOI [DOI 10.1109/CCECE.2013.6567726, 10.1109/CCECE.2013.6567726]
   [Anonymous], INT J INFORM COMPUTA
   [Anonymous], 2014, INT J ELECT COMMUN C
   [Anonymous], IMAGE QUALITY SYSTEM
   Devi E. Sangeetha, 2010, 2010 International Conference on Communication Control and Computing Technologies, P769
   Hodeish ME, 2016, PROCEDIA COMPUT SCI, V93, P760, DOI 10.1016/j.procs.2016.07.288
   Hou YC, 2014, IEEE T CIRC SYST VID, V24, P733, DOI 10.1109/TCSVT.2013.2280097
   Jarvis JF, 1976, Comput Graph Image Process, V5, P13, DOI DOI 10.1016/S0146-664X(76)80003-2
   Lee C, 2006, OPT ENG, V45, DOI 10.1117/1.2160515
   Lee KH, 2012, IEEE T INF FOREN SEC, V7, P219, DOI 10.1109/TIFS.2011.2167611
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu F, 2011, IEEE T INF FOREN SEC, V6, P307, DOI 10.1109/TIFS.2011.2116782
   Mishra SK, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1924, DOI 10.1109/ICACCI.2015.7275899
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Nouri R, 2017, MULTIMED TOOLS APPL, V76, P8745, DOI 10.1007/s11042-016-3507-y
   Satir E, 2014, MULTIMED TOOLS APPL, V70, P2085, DOI 10.1007/s11042-012-1223-9
   Shivani S, 2018, PATTERN ANAL APPL, V21, P139, DOI 10.1007/s10044-016-0571-x
   ULICHNEY RA, 1988, P IEEE, V76, P56, DOI 10.1109/5.3288
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Yan XH, 2015, DIGIT SIGNAL PROCESS, V38, P53, DOI 10.1016/j.dsp.2014.12.002
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 26
TC 7
Z9 7
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 24937
EP 24953
DI 10.1007/s11042-018-5724-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400016
DA 2024-07-18
ER

PT J
AU Kim, H
   Han, S
AF Kim, Hyungki
   Han, Soonhung
TI Interactive 3D building modeling method using panoramic image sequences
   and digital map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D building modeling; Street view; Geo-registration; Shape estimation
ID RECONSTRUCTION; SCENES
AB This paper proposes a method of generating 3D building models with precise geospatial information and a photograph-based fa double dagger ade appearance from panoramic image sequences and digital maps. 3D building modeling research is actively being conducted in areas such as geographic information systems, virtual reality, and augmented reality. However, the generation of realistic 3D models from a ground-level viewpoint is still extremely costly in terms of labor of modeling experts, and collection of data. We have developed a method for 3D building modeling with high-resolution photograph-based appearance information using panoramic images captured at ground level with a mobile mapping system, and geospatial information obtained from a digital map. The proposed method includes 1) pre-processing for tilt correction and base 3D model generation, 2) geo-registration of panoramic images with minimal user input, and 3) building height and shape estimation. This paper presents the proposed method and the quantitative performance measure obtained from a developed test modeling system. In addition, modeling results from an experimental dataset are also presented.
C1 [Kim, Hyungki] ADD, Aero Syst Div 3, Daejeon 34168, South Korea.
   [Han, Soonhung] Korea Adv Inst Sci & Technol, Dept Mech Engn, Grad Program Ocean Syst, Daejeon 34141, South Korea.
C3 Agency of Defense Development (ADD), Republic of Korea; Korea Advanced
   Institute of Science & Technology (KAIST)
RP Kim, H (corresponding author), ADD, Aero Syst Div 3, Daejeon 34168, South Korea.
EM diskhkme@gmail.com; shhan@kaist.ac.kr
RI han, soonhung/AAA-5745-2021; Han, Soonhung/C-2030-2011
OI han, soonhung/0000-0001-5676-8121; Kim, Hyungki/0000-0001-9013-2338
CR [Anonymous], P 23 INT C IM VIS CO
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 2005, Geo-Information for Disaster Management, DOI [DOI 10.1007/3-540-27468-563, DOI 10.1007/3-540-27468-5_63]
   [Anonymous], 2014, Google Earth
   [Anonymous], 2016, P 21 INT C WEB3D TEC
   Baillard C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P559, DOI 10.1109/CVPR.1999.784966
   Barinova O, 2008, LECT NOTES COMPUT SC, V5303, P100, DOI 10.1007/978-3-540-88688-4_8
   Boussias-Alexakis E, 2016, INT ARCH PHOTOGRAMM, V41, P639, DOI 10.5194/isprsarchives-XLI-B1-639-2016
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191
   Guo H, 2016, GEO-SPAT INF SCI, V19, P140, DOI 10.1080/10095020.2016.1182808
   Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232
   KADA M, 2005, P ASPRS 2005 ANN C B, P78
   Kim H.S., 2016, MRS Advances, P1, DOI DOI 10.1155/2016/8641702
   Kim H.Y., 2014, IEEE MTT-S Int. Microw. Symp. (IMS), P1
   Li XW, 2008, LECT NOTES COMPUT SC, V5302, P427
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lv ZH, 2016, IEEE ACCESS, V4, P407, DOI 10.1109/ACCESS.2016.2517076
   Oh SH, 2012, J KOREA MULTIMEDSOC, V15, P1230
   Park JS, 2005, PATTERN RECOGN LETT, V26, P2558, DOI 10.1016/j.patrec.2005.05.009
   Rau JY, 2006, LECT NOTES COMPUT SC, V4319, P1283
   Sato T., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P56, DOI 10.1109/ICCVW.2011.6130222
   Sinha SN, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409112
   Tsai F, 2007, INT J GEOGR INF SCI, V21, P965, DOI 10.1080/13658810601034929
   Ventura J, 2013, VIRTUAL REAL-LONDON, V17, P147, DOI 10.1007/s10055-012-0208-3
   von Gioi RG, 2012, IMAGE PROCESS ON LIN, V2, P35, DOI 10.5201/ipol.2012.gjmr-lsd
   Vworld, 2014, VWORLD
   Wang GH, 2005, PATTERN RECOGN LETT, V26, P207, DOI 10.1016/j.patrec.2004.08.024
   Xiao JX, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618460
   Yoo B, 2013, INT J GEOGR INF SCI, V27, P24, DOI 10.1080/13658816.2012.661055
   Zebedin L, 2008, LECT NOTES COMPUT SC, V5305, P873, DOI 10.1007/978-3-540-88693-8_64
   Zebedin L, 2006, ISPRS J PHOTOGRAMM, V60, P413, DOI 10.1016/j.isprsjprs.2006.06.005
   Zhang CX, 2010, LECT NOTES COMPUT SC, V6314, P708, DOI 10.1007/978-3-642-15561-1_51
   Zheng X, 2011, P 10 INT C VIRT REAL, P225
NR 34
TC 13
Z9 13
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27387
EP 27404
DI 10.1007/s11042-018-5926-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500051
DA 2024-07-18
ER

PT J
AU Hao, T
   Wang, Q
   Wu, D
   Sun, JS
AF Hao, Tong
   Wang, Qian
   Wu, Dan
   Sun, Jin-Sheng
TI Adaptive recommendation for photo pose via deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photo pose recommendation; Deep learning; Feature fusion
ID FEATURE FUSION; MODEL
AB With the development of image acquisition devices and the popularity of smart phones, more and more people would like to upload their photos to diverse social networks. It is hard to guarantee the quality and artistry of these photos because of not everyone is a professional photographer. In order to handle this problem and further help each common user to improve the beauty of photos, we propose an intelligent photo pose recommendation method to recommended professional photo pose according to everyone's posture in viewfinder. Firstly, the CNN model (VGG-16) is utilized to extract the global features for each photo. Secondly, the salient region detection method is leveraged to extract the regions of interest in each photo. To represent the edge distribution in the local regions, we extract the histogram of oriented gradients. Finally, we propose an effective feature fusion method based on CCA to generate the global visual features for each photo. We implement the Euclidean distance to handle the similarity measure between uploaded photos and the professional photos. The most similar professional photo will be utilized to guide user photo composition. In order to evaluate the performance of the proposed method, we collected a set of professional photos form some professional photography websites. The comparison experiments and user study demonstrate the superiority of the proposed approach.
C1 [Hao, Tong; Wang, Qian; Wu, Dan; Sun, Jin-Sheng] Tianjin Normal Univ, Tianjin Key Lab Anim & Plant Resistance, Coll Life Sci, Tianjin 300387, Peoples R China.
   [Sun, Jin-Sheng] Tianjin Aquat Anim Infect Dis Control & Prevent C, Tianjin 300221, Peoples R China.
C3 Tianjin Normal University; Tianjin Center for Disease Control &
   Prevention
RP Hao, T (corresponding author), Tianjin Normal Univ, Tianjin Key Lab Anim & Plant Resistance, Coll Life Sci, Tianjin 300387, Peoples R China.
EM joyht2001@163.com
FU National High-Tech Research and Development Program of China (863
   programs) [2012AA10A401]; Grants of the Major State Basic Research
   Development Program of China (973 programs) [2012CB114405]; National
   Natural Science Foundation of China [31770904, 21106095]; National Key
   Technology R D Program [2011BAD13B07, 2011BAD13B04]; Tianjin Applied
   Basic and Advanced Technology Research Program [15JCYBJC30700]; Project
   of introducing one thousand high level talents in three years
   [5KQM110003]; Tianjin Normal University Academic Innovation Promotion
   Program for Young Teachers [52XC1403]; Tianjin Innovative Talent
   Training Program [ZX110170]
FX This work was funded by National High-Tech Research and Development
   Program of China (863 programs, 2012AA10A401), Grants of the Major State
   Basic Research Development Program of China (973 programs,
   2012CB114405), National Natural Science Foundation of China
   (31770904,21106095), National Key Technology R & D Program
   (2011BAD13B07, 2011BAD13B04), Tianjin Applied Basic and Advanced
   Technology Research Program (15JCYBJC30700), Project of introducing one
   thousand high level talents in three years(5KQM110003), Tianjin Normal
   University Academic Innovation Promotion Program for Young Teachers
   (52XC1403) and Tianjin Innovative Talent Training Program (ZX110170).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bai X, 2015, IEEE GEOSCI REMOTE S, V12, P8, DOI 10.1109/LGRS.2014.2322953
   Chandrasekhar V, ARXIV170104923
   Chen J., 2014, P 16 INT C MULT INT, P508, DOI DOI 10.1145/2663204.2666277
   Cheng ZY, 2016, SIGNAL PROCESS, V124, P13, DOI 10.1016/j.sigpro.2015.10.037
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fei Hongliang., 2008, Proceedings of the 17th ACM conference on Information and knowledge management, P991
   Gao Y, 2016, IEEE T MULTIMEDIA, V18, P2115, DOI 10.1109/TMM.2016.2581483
   Gao Z, 2017, J VIS COMMUN IMAGE R, V48, P442, DOI 10.1016/j.jvcir.2017.03.014
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2014, MULTIMED TOOLS APPL, V68, P641, DOI 10.1007/s11042-012-1071-7
   Gens R, 2013, LEARNING STRUCTURE S, P873
   Gonde AB, 2017, P INT C COMP VIS IM, P495
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Guo J., 2016, P ANN REL MAINT S, P1, DOI DOI 10.1109/RAMS.2016.7448068
   Huang XD, 2016, PROCEEDINGS OF THE 2016 12TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P3056, DOI 10.1109/WCICA.2016.7578372
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Krissinel E, 2004, ACTA CRYSTALLOGR D, V60, P2256, DOI 10.1107/S0907444904026460
   Lai HJ, 2016, IEEE T IMAGE PROCESS, V25, P2469, DOI 10.1109/TIP.2016.2545300
   Li A, 2014, LECT NOTES COMPUT SC, V8695, P265, DOI 10.1007/978-3-319-10584-0_18
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Pong KH, 2014, PATTERN RECOGN, V47, P556, DOI 10.1016/j.patcog.2013.08.023
   Qian XM, 2016, IEEE T IMAGE PROCESS, V25, P195, DOI 10.1109/TIP.2015.2497145
   Vogelstein JT, 2014, SCIENCE, V344, P386, DOI 10.1126/science.1250298
   Wu S, 2016, The Metallogenic Mechanism of Distal Contact Pb-Zn-ag Vines in Shizhuyuan Ore District, Hunan Province, China, V2016, P1
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
   Zhang ST, 2015, IEEE T PATTERN ANAL, V37, P803, DOI 10.1109/TPAMI.2014.2346201
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhou WG, 2016, IEEE T PATTERN ANAL, V38, P159, DOI 10.1109/TPAMI.2015.2430329
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 36
TC 3
Z9 4
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22173
EP 22184
DI 10.1007/s11042-018-5705-2
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500023
DA 2024-07-18
ER

PT J
AU Raghuwanshi, G
   Tyagi, V
AF Raghuwanshi, Ghanshyam
   Tyagi, Vipin
TI Feed-forward content based image retrieval using adaptive tetrolet
   transforms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tetrolet transform; Feed-forward; Edge orientation histogram; Image
   retrieval; CBIR
ID DIRECTIONAL LOCAL EXTREMA; PATTERNS; COLOR; DESCRIPTOR; FEATURES;
   REGIONS
AB This paper proposes a new approach for content based image retrieval based on feed-forward architecture and Tetrolet transforms. The proposed method addresses the problems of accuracy and retrieval time of the retrieval system. The proposed retrieval system works in two phases: feature extraction and retrieval. The feature extraction phase extracts the texture, edge and color features in a sequence. The texture features are extracted using Tetrolet transform. This transform provides better texture analysis by considering the local geometry of the image. Edge orientation histogram is used for retrieving the edge feature while color histogram is used for extracting the color features. Further retrieval phase retrieves the images in the feed-forward manner. At each stage, the number of images for next stage is reduced by filtering out irrelevant images. The Euclidean distance is used to measure the distance between the query and database images at each stage. The experimental results on COREL- 1 K and CIFAR - 10 benchmark databases show that the proposed system performs better in terms of the accuracy and retrieval time in comparison to the state-of-the-art methods.
C1 [Raghuwanshi, Ghanshyam; Tyagi, Vipin] Jaypee Univ Engn & Technol, Guna 473226, MP, India.
RP Tyagi, V (corresponding author), Jaypee Univ Engn & Technol, Guna 473226, MP, India.
EM dr.vipin.tyagi@gmail.com
RI Tyagi, Vipin/I-2451-2013
OI Tyagi, Vipin/0000-0003-4994-3686
CR [Anonymous], 2010, P ACM INT C IMAGE VI
   Chun YD, 2008, IEEE T MULTIMEDIA, V10, P1073, DOI 10.1109/TMM.2008.2001357
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   Dubey SR, 2015, COMPUT ELECTR ENG, V46, P288, DOI 10.1016/j.compeleceng.2015.04.011
   Dubey SR, 2015, P IEEE UP SECT C EL
   ElAlami ME, 2014, APPL SOFT COMPUT, V14, P407, DOI 10.1016/j.asoc.2013.10.003
   ElAlami ME, 2011, KNOWL-BASED SYST, V24, P23, DOI 10.1016/j.knosys.2010.06.001
   Fadaei S, 2017, IET IMAGE PROCESS, V11, P89, DOI 10.1049/iet-ipr.2016.0542
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Hsu WH, 2007, IEEE MULTIMEDIA, V14, P14, DOI 10.1109/MMUL.2007.61
   Huang PW, 2003, PATTERN RECOGN, V36, P665, DOI 10.1016/S0031-3203(02)00083-3
   Jacob IJ, 2014, PATTERN RECOGN LETT, V42, P72, DOI 10.1016/j.patrec.2014.01.017
   Jhanwar N, 2004, IMAGE VISION COMPUT, V22, P1211, DOI 10.1016/j.imavis.2004.03.026
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   Kanimozhi T, 2015, NEUROCOMPUTING, V151, P1099, DOI 10.1016/j.neucom.2014.07.078
   Karakasis EG, 2015, PATTERN RECOGN LETT, V55, P22, DOI 10.1016/j.patrec.2015.01.005
   Krommweh J, 2010, J VIS COMMUN IMAGE R, V21, P364, DOI 10.1016/j.jvcir.2010.02.011
   Kumar A, 2015, IEEE J BIOMED HEALTH, V19, P1734, DOI 10.1109/JBHI.2014.2361318
   Kundu MK, 2015, KNOWL-BASED SYST, V73, P254, DOI 10.1016/j.knosys.2014.10.009
   Lai CC, 2011, IEEE T INSTRUM MEAS, V60, P3318, DOI 10.1109/TIM.2011.2135010
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Long FH, 2003, SIG COM TEC, P1
   Ma YB, 2017, IEEE J BIOMED HEALTH, V21, P1114, DOI 10.1109/JBHI.2016.2611615
   Mehtre BM, 1997, INFORM PROCESS MANAG, V33, P319, DOI 10.1016/S0306-4573(96)00069-6
   Murala S, 2012, INT J MULTIMED INF R, V1, P191, DOI 10.1007/s13735-012-0008-2
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Qiu GP, 2003, IEEE T IMAGE PROCESS, V12, P102, DOI 10.1109/TIP.2002.806228
   Raghuwanshi G, 2017, MULTIMED TOOLS APPL, V76, P13741, DOI 10.1007/s11042-016-3747-x
   Raghuwanshi G, 2016, DIGIT SIGNAL PROCESS, V48, P50, DOI 10.1016/j.dsp.2015.09.003
   Reddy AH, 2015, AEU-INT J ELECTRON C, V69, P290, DOI 10.1016/j.aeue.2014.09.015
   Reddy PVB, 2014, AEU-INT J ELECTRON C, V68, P637, DOI 10.1016/j.aeue.2014.01.012
   Seetharaman K, 2015, ENG APPL ARTIF INTEL, V40, P103, DOI 10.1016/j.engappai.2015.01.008
   Seetharaman K., 2014, MULTIMED TOOLS APPL, V3, P53
   Shrivastava N, 2015, COMPUT ELECTR ENG, V46, P314, DOI 10.1016/j.compeleceng.2014.11.009
   Shrivastava N, 2014, INFORM SCIENCES, V259, P212, DOI 10.1016/j.ins.2013.08.043
   Su JH, 2011, IEEE T KNOWL DATA EN, V23, P360, DOI 10.1109/TKDE.2010.124
   Takala V, 2005, LECT NOTES COMPUT SC, V3540, P882
   Van TT, 2018, EXPERT SYST, V35, DOI 10.1111/exsy.12220
   Wan SH, 2016, CHINESE J ELECTRON, V25, P873, DOI 10.1049/cje.2016.06.010
   Wang XY, 2011, COMPUT STAND INTER, V33, P59, DOI 10.1016/j.csi.2010.03.004
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Yildizer E, 2012, KNOWL-BASED SYST, V31, P55, DOI 10.1016/j.knosys.2012.01.013
   Zhang LL, 2016, IEEE T KNOWL DATA EN, V28, P858, DOI 10.1109/TKDE.2015.2505284
   Zheng YS, 2018, IEEE J BIOMED HEALTH, V22, P1278, DOI 10.1109/JBHI.2017.2723014
   Zujovic J, 2013, IEEE T IMAGE PROCESS, V22, P2545, DOI 10.1109/TIP.2013.2251645
NR 47
TC 7
Z9 7
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23389
EP 23410
DI 10.1007/s11042-018-5628-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900015
DA 2024-07-18
ER

PT J
AU Xiao, D
   Zhao, J
   Wang, MD
   Wang, Y
AF Xiao, Di
   Zhao, Juan
   Wang, Mengdi
   Wang, Yong
TI Controllable high-capacity separable data hiding in encrypted images by
   compressive sensing and data pretreatment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Compressive sensing; Data hiding; Discrete wavelet
   transform; Controllable capacity
ID SECRET DATA; RECONSTRUCTION
AB In this paper, a separable data hiding algorithm in encrypted images with controllable and high-capacity is proposed. Firstly, the original image is decomposed into important coefficients and unimportant coefficients by discrete wavelet transform (DWT). Secondly, DWT is applied again on unimportant coefficients matrixes and then the obtained coefficients matrixes are compressed using compressive sensing (CS) to empty space for data hiding. All the important coefficients are encrypted using the traditional stream cipher by the content owner. Thirdly, the data hider hides the pretreated data information in the free space. Finally, the encrypted image containing additional data is scrambled to improve the security. The receiver can separably extract the hiding data or/and decrypt the image depending on the keys he owns. Compared with the previous work, there are various advantages in the proposed algorithm, such as the separability between image recovery and data extraction, the controllable and high-capacity for data hiding. Experimental results verify the superiority of the proposed algorithm.
C1 [Xiao, Di; Zhao, Juan; Wang, Mengdi] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
   [Wang, Yong] Chongqing Univ Posts & Telecommun, Key Lab Elect Commerce & Logist Chongqing, Chongqing 400065, Peoples R China.
C3 Chongqing University; Chongqing University of Posts & Telecommunications
RP Xiao, D (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
EM xiaodi_cqu@hotmail.com
OI Wang, Yong/0000-0002-5247-043X
FU National Natural Science Foundation of China [61572089, 61472464,
   61633005]; Natural Science Foundation of Chongqing Science and
   Technology Commission [cstc2017jcyjBX0008, cstc2014jcyjA40030,
   cstc2015jcyjA40039]; Graduate Student Research and Innovation Foundation
   of Chongqing [CYB17026]; Fundamental Research Funds for the Central
   Universities [106112017CDJQJ188830, 106112017CDJXY180005]
FX The work was funded by the National Natural Science Foundation of China
   (Grant Nos. 61572089, 61472464, 61633005), the Natural Science
   Foundation of Chongqing Science and Technology Commission (Grant Nos.
   cstc2017jcyjBX0008, cstc2014jcyjA40030, cstc2015jcyjA40039), the Project
   Supported by Graduate Student Research and Innovation Foundation of
   Chongqing (Grant No. CYB17026) and the Fundamental Research Funds for
   the Central Universities (Grant Nos., 106112017CDJQJ188830,
   106112017CDJXY180005).
CR Al-Otaibi NA, 2014, P 3 INT C ADV INF TE, P73
   Alotaibi N, 2015, 12 LEARN TECHN C WEA, P12
   [Anonymous], 2007, DELIVERING ACCESS SA
   [Anonymous], 2014, INT C ADV ENG TECHN
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Chen GF, 2012, MOD ELECT TECHNOL, V35, P98
   Chen RJ, 2015, INT J AD HOC UBIQ CO, V18, P54, DOI 10.1504/IJAHUC.2015.067788
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Do TT, 2012, IEEE T SIGNAL PROCES, V60, P139, DOI 10.1109/TSP.2011.2170977
   Dong J, 2016, INT C SMART HLTH, P217
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Huang H.-C., 2014, J INFORM HIDING MULT, V5, P275
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Li W, 2013, 9 INT C INT INF HID, P9191
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Nazeer Muhammad, 2012, Proceedings of the World Congress on Engineering (WCE 2012), P1156
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Puech W, 2008, ELECT IMAGING 2008
   Rani A, 2016, MULTIMED TOOLS APPL, V75, P1027, DOI 10.1007/s11042-014-2344-0
   Subramanyam AV, 2010, IEEE INT CON MULTI, P1315, DOI 10.1109/ICME.2010.5583571
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P15191, DOI 10.1007/s11042-016-3744-0
   Veena VK, 2012, 2012 INTERNATIONAL CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P105, DOI 10.1109/MVIP.2012.6428771
   Xiao D, 2016, MULTIMED TOOLS APPL, V75, P13779, DOI 10.1007/s11042-015-2922-9
   Xiao D, 2014, ELECTRON LETT, V50, P598, DOI 10.1049/el.2013.3806
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 37
TC 3
Z9 3
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23949
EP 23968
DI 10.1007/s11042-018-5726-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900037
DA 2024-07-18
ER

PT J
AU Yu, Z
   Wang, Q
   Xiong, W
   Zhang, CD
   Hu, HF
AF Yu, Zhuo
   Wang, Qian
   Xiong, Wei
   Zhang, Chengde
   Hu, Huaifei
TI Segmentation of cardiac tagged MR images using a snake model based on
   hybrid gradient vector flow
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE The segmentation of left ventricle; Tagging magnetic resonance image;
   Notch bandstop filtering; GVF snake
ID LEFT-VENTRICLE; AUTOMATIC SEGMENTATION; LEVEL SET
AB In the segmentation of cardiac tagging magnetic resonance (tMR) images, it is difficult to segment the left ventricle automatically by using the traditional segmentation model because of the interference caused by the tags. A new snake model based on hybrid gradient vector flow (HGVF) is proposed by us to improve this segmentation. Due to the different characteristics between endocardium and epicardium of the left ventricle (LV), several gradient vector flows (GVFs) with distinctive boundary information would be fused to segment these two sub regions individually. For segmentation of endocardium, we construct a new HGVF in snake model fused by three independent GVFs. These flows are respectively exported from the original cardiac tMR image, the tags-removed image and the local-filtered image. On the other hand, since the epicardium is with a nearly-circle shape, we construct the other HGVF which is composed of two different GVFs. One of them is derived from the tags-removed image either and the other one is derived from the ideal circle-shape image. Some experiments have been done to validate our new segmentation model. The average overlap of the endocardium segmentation is 89.67% (its mean absolute distance is 1.86 pixels), and the average overlap of the epicardium segmentation is 95.88% (its mean absolute distance is 1.64 pixels). Experimental results show that the proposed method improves the segmentation performance compared to some available methods effectively.
C1 [Yu, Zhuo; Wang, Qian; Zhang, Chengde] Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan 430073, Hubei, Peoples R China.
   [Wang, Qian] Hubei Key Lab Med Informat Anal & Tumor Diag & Tr, Wuhan 430074, Hubei, Peoples R China.
   [Xiong, Wei] South Cent Univ Nationalities, Coll Comp Sci, Wuhan 430074, Hubei, Peoples R China.
   [Xiong, Wei] Deakin Univ, Fac Sci Engn & Bldg Environm, Melbourne, Vic 3125, Australia.
   [Hu, Huaifei] Univ Sheffield, Dept Elect & Elect Engn, Ctr Computat Imaging & Simulat Technol Biomed CIS, Sheffield, S Yorkshire, England.
   [Hu, Huaifei] South Cent Univ Nationalities, Sch Biomed Engn, Wuhan 430074, Hubei, Peoples R China.
C3 Zhongnan University of Economics & Law; South Central Minzu University;
   Deakin University; University of Sheffield; South Central Minzu
   University
RP Wang, Q (corresponding author), Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan 430073, Hubei, Peoples R China.; Wang, Q (corresponding author), Hubei Key Lab Med Informat Anal & Tumor Diag & Tr, Wuhan 430074, Hubei, Peoples R China.
EM yimingfeitian@outlook.com; QianWang@zuel.edu.cn; ccnuxw@sina.com;
   chengdezhang@zuel.edu.cn; huaifeihu@mail.scuec.edu.cn
RI Yu, Zhuo/JKJ-1374-2023
OI Yu, Zhuo/0000-0002-6431-7002
FU National Natural Science Foundation of China [61602519]; Ministry of
   Education of China (MOE) Project of Humanities and Social Sciences
   [16YJC860026]; China Postdoctoral Science Foundation [2013M542021,
   2014M562026]; Natural Science Foundation of Hubei Province, China
   [2013CFC090]; Fundamental Research Funds for the Central Universities;
   Zhongnan University of Economics and Law [2012096]
FX This research was funded by the National Natural Science Foundation of
   China (Grant No. 61602519); Ministry of Education of China (MOE) Project
   of Humanities and Social Sciences (Project No. 16YJC860026); China
   Postdoctoral Science Foundation (Grant No. 2013M542021); China
   Postdoctoral Science Foundation (Grant No.2014M562026); the Natural
   Science Foundation of Hubei Province, China (Grant No. 2013CFC090); the
   Fundamental Research Funds for the Central Universities, Zhongnan
   University of Economics and Law (Grant No. 2012096).
CR Albà X, 2014, MAGN RESON MED, V72, P1775, DOI 10.1002/mrm.25079
   [Anonymous], IEEE COMMUN MAG
   Avendi MR, 2016, MED IMAGE ANAL, V30, P108, DOI 10.1016/j.media.2016.01.005
   Chen M, 2014, MOBILE NETW APPL, V19, P171, DOI 10.1007/s11036-013-0489-0
   Dakua SP, 2010, CARDIOVASC ENG, V10, P163, DOI 10.1007/s10558-010-9102-3
   Dharanibai G., 2014, International Journal of Medical Engineering and Informatics, V6, P115, DOI 10.1504/IJMEI.2014.060247
   Haji-Esmaeili M. M., 2016, IEEE T POWER ELECTR, P1, DOI DOI 10.1109/ICSENS.2016.7808592
   Huang S, 2011, J DIGIT IMAGING, V24, P598, DOI 10.1007/s10278-010-9315-4
   Kasai M, 1990, Nihon Sanka Fujinka Gakkai Zasshi, V42, P711
   [李振立 Li Zhenli], 2011, [中国组织工程研究与临床康复, Journal of Clinical Rehabilitative Tissue Engineering Research], V15, P1521
   Liu Fu-chang, 2009, Journal of Software, V20, P30, DOI 10.3724/SP.J.1001.2009.03360
   LIU L, 2012, J BIOINFORMATICS INT, V1, P56
   Liu L., 2009, INF TECHNOL J, V8, P486
   Liu Y., 2015, MAGNETIC RESONANCE I, V34, P699
   Makram AW, 2014, CAIRO INT BIOM ENG, P67, DOI 10.1109/CIBEC.2014.7020917
   Qin XJ, 2015, NEUROCOMPUTING, V149, P904, DOI 10.1016/j.neucom.2014.07.044
   Ngo TA, 2017, MED IMAGE ANAL, V35, P159, DOI 10.1016/j.media.2016.05.009
   Pham VT, 2016, OPTIK, V127, P991, DOI 10.1016/j.ijleo.2015.10.162
   Pham VT, 2014, MACH VISION APPL, V25, P1967, DOI 10.1007/s00138-014-0626-1
   Varghese T., 2016, Heart
   Wang B, 2015, COMPUT MED IMAG GRAP, V46, P56, DOI 10.1016/j.compmedimag.2015.06.003
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158
   Yuwei W, 2010, J IMAGE GRAPH
   Zhang Ning, 2012, Journal of Computer Applications, V32, P1902, DOI 10.3724/SP.J.1087.2012.01902
   Zhang YJ, 2015, IEEE T VLSI SYST, V23, P1170, DOI 10.1109/TVLSI.2014.2326797
   Zhang Y, 2017, FUTURE GENER COMP SY, V66, P30, DOI 10.1016/j.future.2015.12.001
   Zhang Y, 2015, MOBILE NETW APPL, V20, P348, DOI 10.1007/s11036-014-0537-4
   Zhu Min, 2015, Journal of Sichuan University (Engineering Science Edition), V47, P82, DOI 10.15961/j.jsuese.2015.02.012
   Zhu Y, 2010, IEEE T MED IMAGING, V29, P669, DOI 10.1109/TMI.2009.2031063
NR 30
TC 4
Z9 4
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 21879
EP 21904
DI 10.1007/s11042-017-5013-2
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500005
DA 2024-07-18
ER

PT J
AU Zhang, WF
   Hu, H
   Hu, HY
AF Zhang, Weifeng
   Hu, Hua
   Hu, Haiyang
TI Neural ranking for automatic image annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic image annotation; Learning to rank; Neural networks; Nearest
   neighbor
ID CLASSIFICATION; FEATURES; SCENE
AB Automatic image annotation aims to predict labels for images according to their semantic contents and has become a research focus in computer vision, as it helps people to edit, retrieve and understand large image collections. In the last decades, researchers have proposed many approaches to solve this task and achieved remarkable performance on several standard image datasets. In this paper, we propose a novel learning to rank approach to address image auto-annotation problem. Unlike typical learning to rank algorithms for image auto-annotation which directly rank annotations for image, our approach consists of two phases. In the first phase, neural ranking models are trained to rank image's semantic neighbors. Then nearest-neighbor based models propagate annotations from these semantic neighbors to the image. Thus our approach integrates learning to rank algorithms and nearest-neighbor based models, including TagProp and 2PKNN, and inherits their advantages. Experimental results show that our method achieves better or comparable performance compared with the state-of-the-art methods on four challenging benchmarks including Corel5K, ESP Games, IAPR TC-12 and NUS-WIDE.
C1 [Zhang, Weifeng; Hu, Hua; Hu, Haiyang] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
   [Zhang, Weifeng] Zhejiang Future Technol Inst, Jiaxing, Peoples R China.
   [Zhang, Weifeng] Jiangnan Elect Commun Inst, Sci & Technol Commun Informat Secur Control Lab, Jiaxing, Peoples R China.
C3 Hangzhou Dianzi University
RP Hu, H; Hu, HY (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
EM zwf.zhang@gmail.com; huhua@hdu.edu.cn; haiyanghu@hdu.edu.cn
FU Natural Science Foundation of China [61572162]; Zhejiang Provincial Key
   Science and Technology Project Foundation [2018C01012]
FX This work is supported by the Natural Science Foundation of China ( No.
   61572162) and the Zhejiang Provincial Key Science and Technology Project
   Foundation (No. 2018C01012).
CR [Anonymous], 2007, ICCV
   [Anonymous], NIPS
   [Anonymous], ARXIV13124894
   [Anonymous], 2007, INT C MACH LEARN
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Ballan Lamberto, 2014, P INT C MULT RETR IC, P73
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Burges Chris, 2005, P 22 INT C MACH LEAR, P89, DOI DOI 10.1145/1102351.1102363
   Burges Christopher J. C., 2010, Learning, V11, P81
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Dehghani M, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P65, DOI 10.1145/3077136.3080832
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Desautels T, 2014, J MACH LEARN RES, V15, P3873
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Fernando B, 2017, IEEE T PATTERN ANAL, V39, P773, DOI 10.1109/TPAMI.2016.2558148
   Fernando B, 2016, PROC CVPR IEEE, P1924, DOI 10.1109/CVPR.2016.212
   Fu H, 2012, LECT NOTES COMPUT SC, V7577, P86, DOI 10.1007/978-3-642-33783-3_7
   Gao Z, 2016, NEURAL COMPUT APPL, V27, P2047, DOI 10.1007/s00521-015-2002-0
   Gao Z, 2016, NEUROCOMPUTING, V173, P110, DOI 10.1016/j.neucom.2015.07.105
   Gao Z, 2014, MULTIMED TOOLS APPL, V68, P641, DOI 10.1007/s11042-012-1071-7
   Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Gu Y, 2017, NEURAL PROCESS LETT, V45, P777, DOI 10.1007/s11063-016-9511-4
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jeon J., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P119, DOI DOI 10.1145/860435.860459
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Joachims T., 2006, P 12 ACM SIGKDD INT, P217, DOI [10.1145/1150402.1150429, DOI 10.1145/1150402.1150429]
   Johnson J, 2015, IEEE I CONF COMP VIS, P4624, DOI 10.1109/ICCV.2015.525
   Kang F., 2006, CVPR, V2, P1719
   Kingma D. P., 2014, arXiv
   Klein B, 2015, ARXIV14117399
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lavrenko V, 2004, ADV NEUR IN, V16, P553
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li X, 2007, IEEE TMM, V11, P1310
   Li ZC, 2013, PATTERN RECOGN, V46, P2700, DOI 10.1016/j.patcog.2013.03.016
   Liu J, 2009, PATTERN RECOGN, V42, P218, DOI 10.1016/j.patcog.2008.04.012
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24
   Makadia A, 2010, INT J COMPUT VISION, V90, P88, DOI 10.1007/s11263-010-0338-6
   Montazer GA, 2017, NEURAL PROCESS LETT, V46, P681, DOI 10.1007/s11063-017-9614-6
   Moran S., 2014, P INT C MULTIMEDIA R, P113
   Murthy VN, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P603, DOI 10.1145/2671188.2749391
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Peng X, 2010, ECCV, P581
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Song Y, 2008, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE 2007, VOL 6, PTS A AND B, P515, DOI 10.1145/1390334.1390423
   Tie-Yan Liu, 2009, Foundations and Trends in Information Retrieval, V3, P225, DOI 10.1561/1500000016
   Verma Y, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.25
   Verma Y, 2012, LECT NOTES COMPUT SC, V7574, P836, DOI 10.1007/978-3-642-33712-3_60
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wang L., 2004, P 2 ACM INT WORKSHOP, P100
   Wauthier F., 2013, INT C MACH LEARN, P109
   Weston J, 2011, IJCAI
   Wu F, 2017, NEURAL PROCESS LETT, V45, P649, DOI 10.1007/s11063-016-9545-7
   Yan X., 2009, LINEAR REGRESSION AN
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   Yang C, 2007, CVPR, P2057
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yang Y, 2010, IEEE T IMAGE PROCESS, V19, P2761, DOI 10.1109/TIP.2010.2049235
   Yun H, 2014, ADV NEUR IN, V27
   Zhang ST, 2010, PROC CVPR IEEE, P3312, DOI 10.1109/CVPR.2010.5540036
   Zhu LG, 2019, IRONMAK STEELMAK, V46, P499, DOI 10.1080/03019233.2017.1405153
NR 70
TC 6
Z9 9
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22385
EP 22406
DI 10.1007/s11042-018-5973-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500035
DA 2024-07-18
ER

PT J
AU Zhang, YD
   Sui, YX
   Sun, JD
   Zhao, GH
   Qian, PJ
AF Zhang, Yu-Dong
   Sui, Yuxiu
   Sun, Junding
   Zhao, Guihu
   Qian, Pengjiang
TI Cat Swarm Optimization applied to alcohol use disorder identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alcohol user disorder; Pattern recognition; Cat swarm optimization;
   Two-layer feedforward neural network; Wavelet entropy; Magnetic
   resonance imaging; Cross validation
ID NEURAL-NETWORK; BRAIN DETECTION; ALGORITHM; SEGMENTATION; PREDICTION;
   SYSTEM
AB (Aim) Alcohol use disorder may put health at risk and cause serious health problems. It is of increasing importance to identify alcohol use disorder as early as possible. (Method) This study proposed a computer-vision based technique. The dataset was scanned by magnetic resonance imaging in China participating hospitals. Afterwards, we combined wavelet entropy, two-layer feedforward neural network, and cat swarm optimization (CSO). The CSO mimics the behavior of cat and is composed of two modes: seeking mode and tracing mode. (Results) The results showed that our method achieves a sensitivity of 91.84 +/- 1.66%, a specificity of 92.40 +/- 1.22%, and an accuracy of 92.13 +/- 0.70%. Using grid searching approach, we found the classification performance is the best, when decomposition level is assigned with 2 and the mixture ratio is assigned with a value of 0.8. (Conclusion) The CSO is superior to four bioinspired algorithms: genetic algorithm, immune genetic algorithm, particle swarm optimization, and chaotic self-adaptive particle swarm optimization. In addition, our proposed alcoholism identification system is superior to four state-of-the-art alcoholism detection approaches.
C1 [Zhang, Yu-Dong; Sun, Junding] Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454000, Henan, Peoples R China.
   [Zhang, Yu-Dong] Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.
   [Sui, Yuxiu] Nanjing Med Univ, Dept Psychiat, Nanjing 210029, Jiangsu, Peoples R China.
   [Zhao, Guihu] Cent South Univ, Xiangya Hosp, Natl Clin Res Ctr Geriatr Disorders, Changsha 410083, Hunan, Peoples R China.
   [Qian, Pengjiang] Jiangnan Univ, Sch Digital Media, Wuxi 214122, Peoples R China.
C3 Henan Polytechnic University; University of Leicester; Nanjing Medical
   University; Central South University; Jiangnan University
RP Zhang, YD; Sun, JD (corresponding author), Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454000, Henan, Peoples R China.; Zhang, YD (corresponding author), Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.; Sui, YX (corresponding author), Nanjing Med Univ, Dept Psychiat, Nanjing 210029, Jiangsu, Peoples R China.; Zhao, GH (corresponding author), Cent South Univ, Xiangya Hosp, Natl Clin Res Ctr Geriatr Disorders, Changsha 410083, Hunan, Peoples R China.; Qian, PJ (corresponding author), Jiangnan Univ, Sch Digital Media, Wuxi 214122, Peoples R China.
EM yudongzhang@ieee.org; suiyuxiu@aliyun.com; sunjd@hpu.edu.cn;
   ghzhao@csu.edu.cn; qianpjiang@jiangnan.edu.cn
RI Qian, Pengjiang/AAC-1399-2020; Zhang, Yudong/I-7633-2013
OI Zhang, Yudong/0000-0002-4870-1493; Qian, Pengjiang/0000-0002-5596-3694
FU Natural Science Foundation of China [61602250]; Natural Science
   Foundation of Jiangsu Province [BK20150983]; Project of Science and
   Technology of Henan Province [172102210272]; Program for Science AMP;
   Technology Innovation Talents of Henan Province [174100510009]; Open
   fund for Jiangsu Key Laboratory of Advanced Manufacturing Technology
   [HGAMTL1601, HGAMTL-1703]; Open fund of Key Laboratory of Guangxi High
   Schools Complex System and Computational Intelligence [2016CSCI01]; Open
   Fund of Guangxi Key Laboratory of Manufacturing System AMP; Advanced
   Manufacturing Technology [17-259-05-011 K]; Henan Key Research and
   Development Project [182102310629]; National key research and
   development plan [2017YFB1103202]
FX This paper is financially supported by Natural Science Foundation of
   China (61602250), Natural Science Foundation of Jiangsu Province
   (BK20150983), Project of Science and Technology of Henan Province
   (172102210272), Program for Science & Technology Innovation Talents of
   Henan Province (174100510009), Open fund for Jiangsu Key Laboratory of
   Advanced Manufacturing Technology (HGAMTL1601, HGAMTL-1703), Open fund
   of Key Laboratory of Guangxi High Schools Complex System and
   Computational Intelligence (2016CSCI01), Open Fund of Guangxi Key
   Laboratory of Manufacturing System & Advanced Manufacturing Technology
   (17-259-05-011 K)., Henan Key Research and Development Project
   (182102310629), National key research and development plan
   (2017YFB1103202)
CR Abou El-Ela AA, 2016, PROCEEDINGS OF 2016 EIGHTEENTH INTERNATIONAL MIDDLE EAST POWER SYSTEMS CONFERENCE (MEPCON), P975, DOI 10.1109/MEPCON.2016.7837015
   Alweshah M, 2015, APPL SOFT COMPUT, V35, P513, DOI 10.1016/j.asoc.2015.06.018
   Chen RM, 2017, COMPUT ELECTR ENG, V58, P489, DOI 10.1016/j.compeleceng.2017.01.018
   Chen Y, 2018, MULTIMED TOOLS APPL, V77, P3775, DOI 10.1007/s11042-016-4087-6
   Chen Y, 2018, MULTIMED TOOLS APPL, V77, P3813, DOI 10.1007/s11042-016-4161-0
   Chen Y, 2017, CNS NEUROL DISORD-DR, V16, P5, DOI 10.2174/1871527314666161124115531
   Chu SC, 2006, LECT NOTES ARTIF INT, V4099, P854
   Darvishvand L, 2018, ENG OPTIMIZ, V50, P452, DOI 10.1080/0305215X.2017.1323889
   Fabijanska A, 2017, FED CONF COMPUT SCI, P629, DOI 10.15439/2017F54
   Feng JH, 2017, MULTIMED TOOLS APPL, V76, P17405, DOI 10.1007/s11042-016-3907-z
   Gao ML, 2016, CHINESE J GEOPHYS-CH, V59, P4372
   Gupta L, 2017, J MAGN RESON IMAGING, V46, P1728, DOI 10.1002/jmri.25700
   Huo YK, 2018, IEEE T BIO-MED ENG, V65, P336, DOI 10.1109/TBME.2017.2764752
   Huo YK, 2017, HUM BRAIN MAPP, V38, P599, DOI 10.1002/hbm.23432
   Jenitta A, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0799-z
   Jia WJ, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0814-4
   Kumar Y, 2017, J INF PROCESS SYST, V13, P1000, DOI 10.3745/JIPS.02.0022
   Li G, 2018, APPL THERM ENG, V129, P1518, DOI 10.1016/j.applthermaleng.2017.10.134
   Li MS, 2013, ACTA CHIM SINICA, V71, P1053, DOI 10.6023/A13020193
   Liu SG, 2017, IET COMPUT VIS, V11, P319, DOI 10.1049/iet-cvi.2016.0186
   Liu SG, 2016, SIGNAL PROCESS, V124, P141, DOI 10.1016/j.sigpro.2015.09.033
   Lu SY, 2018, MULTIMED TOOLS APPL, V77, P3715, DOI 10.1007/s11042-016-3559-z
   de Carvalho CAM, 2016, ACTA CIR BRAS, V31, P629, DOI 10.1590/S0102-865020160090000009
   Monnig MA, 2012, ALCOHOLISM, V36, p272A
   Mostafa A, 2017, MULTIMED TOOLS APPL, V76, P24931, DOI 10.1007/s11042-017-4638-5
   Murano T, 2016, INT J NEUROPSYCHOPH, V19, P170
   Nie XH, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/1583847
   Ong HH, 2018, PSYCHOL HEALTH MED, V23, P160, DOI 10.1080/13548506.2017.1338737
   Piersanti S, 2018, IEEE T ELECTROMAGN C, V60, P1014, DOI 10.1109/TEMC.2017.2764623
   Shahrabi J, 2017, J FUNDAM APPL SCI, V9, P154, DOI 10.4314/jfas.v9i1s.685
   Shoaib M, 2018, WATER RESOUR MANAG, V32, P83, DOI 10.1007/s11269-017-1796-1
   Subramaniam S, 2016, INT ARAB J INF TECHN, V13, P118
   Wang SH, 2018, COMPLEXITY, DOI 10.1155/2018/3198184
   Wang SH, 2016, IEEE ACCESS, V4, DOI 10.1109/ACCESS.2016.2620996
   Wang SH, 2018, MULTIMED TOOLS APPL, V77, P3701, DOI 10.1007/s11042-016-3401-7
   Wang SH, 2017, IEEE ACCESS, V5, P16576, DOI 10.1109/ACCESS.2017.2736558
   Wang SH, 2016, SIMUL-T SOC MOD SIM, V92, P637, DOI 10.1177/0037549715623847
   Wang SH, 2016, SIMUL-T SOC MOD SIM, V92, P601, DOI 10.1177/0037549715603481
   Wang SH, 2014, J VIS COMMUN IMAGE R, V25, P263, DOI 10.1016/j.jvcir.2013.11.005
   Wolber N, 2018, J NEUROSCI NURS, V50, P22, DOI 10.1097/JNN.0000000000000335
   Xun YQ, 2016, INT CONF SOFTW ENG, P162, DOI 10.1109/ICSESS.2016.7883039
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22589, DOI 10.1007/s11042-017-4703-0
   Zhang YD, 2017, COMPUT ELECTR ENG, V63, P126, DOI 10.1016/j.compeleceng.2017.04.009
   Zhang YD, 2015, INT J IMAG SYST TECH, V25, P317, DOI 10.1002/ima.22144
   Zhang YD, 2017, J EXP THEOR ARTIF IN, V29, P299, DOI 10.1080/0952813X.2015.1132274
   Zhang YD, 2016, TECHNOL HEALTH CARE, V24, pS641, DOI 10.3233/THC-161191
   Zhou XX, 2016, SIMUL-T SOC MOD SIM, V92, P827, DOI 10.1177/0037549716629227
NR 47
TC 26
Z9 26
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22875
EP 22896
DI 10.1007/s11042-018-6003-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500059
DA 2024-07-18
ER

PT J
AU Liu, X
   Wang, S
   Yan, XH
   Zhang, WZ
AF Liu, Xin
   Wang, Shen
   Yan, Xuehu
   Zhang, Weizhe
TI Random grid-based threshold visual secret sharing with improved visual
   quality and lossless recovery ability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography; Visual secret sharing; Random grids; Progressive
   evaluation; Lossless recovery
ID IMAGE ENCRYPTION; CRYPTOGRAPHY; SCHEME
AB Visual secret sharing (VSS) by random grids (RG) has gained much attention since it avoids the pixel expansion problem as well as requires no basic matrixes design. However, most of the previous RG-based threshold VSS still suffer from low visual quality or worse reconstructed secrets when more shadows are stacked. In this paper, a new RG-based threshold VSS with improved visual quality and lossless recovery ability is proposed. The random bits are utilized to improve the visual quality as well as to decrease the darkness of the reconstructed secret image. And the secret image can be losslessly recovered in the proposed scheme if the computational device is available. Simulation results and analyzes show the effectiveness of the proposed scheme. In addition, this paper gave the preliminary definition and evaluation of progressive secret sharing (PSS) based on mathematical differential and expectations.
C1 [Liu, Xin; Wang, Shen; Zhang, Weizhe] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Heilongjiang, Peoples R China.
   [Liu, Xin] Harbin Univ Sci & Technol, Modern Educ Technol Ctr, Harbin 150080, Heilongjiang, Peoples R China.
   [Yan, Xuehu] Elect Engn Inst, Hefei 230037, Anhui, Peoples R China.
C3 Harbin Institute of Technology; Harbin University of Science &
   Technology
RP Liu, X (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Heilongjiang, Peoples R China.; Liu, X (corresponding author), Harbin Univ Sci & Technol, Modern Educ Technol Ctr, Harbin 150080, Heilongjiang, Peoples R China.
EM liuxin@hrbust.edu.cn; shen.wang@hit.edu.cn
RI Yan, Xuehu/AFK-3139-2022; Yan, Xuehu/AAG-1718-2022
OI Yan, Xuehu/0000-0001-6388-1720; Yan, Xuehu/0000-0001-6388-1720
FU National Natural Science Foundation of China [61471141, 61361166006,
   61301099, 61472108, 61672186, 61501148]; National Key Research and
   Development Program of China [2016YFB0800801]; Key Technology Program of
   Shenzhen, China [JSGG20160427185010977]; Basic Research Project of
   Shenzhen, China [JCYJ2015051351706561]
FX The authors would like to thank the anonymous reviewers for their
   valuable discussions and comments. This work is supported by the
   National Natural Science Foundation of China (Grant Number: 61471141,
   61361166006, 61301099, 61472108, 61672186, 61501148,), the National Key
   Research and Development Program of China (Grant Number:
   2016YFB0800801), Key Technology Program of Shenzhen, China (Grant
   Number: JSGG20160427185010977) and Basic Research Project of Shenzhen,
   China (Grant Number: JCYJ2015051351706561).
CR [Anonymous], IEEE T INF FORENSIC
   [Anonymous], 2017, J REAL-TIME IMAGE PR
   Chao HC, 2017, DIGIT SIGNAL PROCESS, V68, P69, DOI 10.1016/j.dsp.2017.05.009
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Guo T, 2014, SIGNAL PROCESS, V94, P90, DOI 10.1016/j.sigpro.2013.06.003
   Guo T, 2013, J SYST SOFTWARE, V86, P2094, DOI 10.1016/j.jss.2013.03.062
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Hou YC, 2011, IEEE T CIRC SYST VID, V21, P1760, DOI 10.1109/TCSVT.2011.2106291
   Jiang XD, 2016, MULTIMED TOOLS APPL, V75, P11801, DOI 10.1007/s11042-015-2659-5
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Li P, 2016, J REAL TIME IMAGE PR, P1
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   Wang XL, 2016, J ANAL METHODS CHEM, V2016, DOI 10.1155/2016/1435106
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Wu XT, 2014, IEEE T INF FOREN SEC, V9, P1592, DOI 10.1109/TIFS.2014.2346014
   Wu XT, 2014, SIGNAL PROCESS, V97, P64, DOI 10.1016/j.sigpro.2013.10.023
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
   Xuehu Yan, 2018, Journal of Real-Time Image Processing, V14, P61, DOI 10.1007/s11554-015-0540-4
   Yan XH, 2016, MULTIMED TOOLS APPL, V75, P8657, DOI 10.1007/s11042-015-2779-y
   Yan XH, 2015, MULTIMED TOOLS APPL, V74, P9279, DOI 10.1007/s11042-014-2080-5
   Yan XH, 2015, MULTIMED TOOLS APPL, V74, P3231, DOI 10.1007/s11042-013-1784-2
   Yan XH, 2014, SIGNAL PROCESS, V105, P389, DOI 10.1016/j.sigpro.2014.06.011
   Yang CN, 2014, INFORM SCIENCES, V278, P141, DOI 10.1016/j.ins.2014.03.033
NR 29
TC 8
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20673
EP 20696
DI 10.1007/s11042-017-5482-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300017
DA 2024-07-18
ER

PT J
AU Luo, T
   Jiang, GY
   Yu, M
   Xu, HY
   Gao, W
AF Luo, Ting
   Jiang, Gangyi
   Yu, Mei
   Xu, Haiyong
   Gao, Wei
TI Sparse recovery based reversible data hiding method using the human
   visual system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse recovery; JND; Embedding strategy; Prediction error expansion
   (PEE); Reversible data hiding (RDH)
ID WATERMARKING
AB In this paper, a novel sparse recovery based reversible data hiding (RDH) method using the human visual system (HVS) is presented. To improve the low accuracy of existing predictors, a sparse recovery based predictor is proposed. In the processes of sparse recovery, the most relevant neighbors can be adaptively chosen by using sparse representation to predict the current pixel accurately, and thus the concentrated prediction error histogram (PEH) is built to obtain good embedding performance. Moreover, to overcome the conflict between the embedding order of the traditional RDH method and the evaluation of HVS, a new embedding strategy based on just noticeable difference (JND) is designed. In this strategy, pixels are classified into sensitive and in-sensitive clusters according to JND values, and two corresponding PEHs are built. Accordingly, different inner regions of two PEHs are adjusted to meet the required embedding capacity, and the prediction error expansion (PEE) technique is utilized to embed data. Experimental results prove that the proposed method outperforms the state-of-the-art RDH methods, including JND related methods.
C1 [Luo, Ting; Xu, Haiyong; Gao, Wei] Ningbo Univ, Coll Sci & Technol, Ningbo 315212, Zhejiang, Peoples R China.
   [Jiang, Gangyi; Yu, Mei; Xu, Haiyong; Gao, Wei] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
C3 Ningbo University; Ningbo University
RP Jiang, GY (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
EM jianggangyi@126.com
RI jiang, gang/KII-8233-2024
FU Natural Science Foundation of China [61501270, 61311140262]; Natural
   Science Foundation of Ningbo [2017A610127, 2016A610071]; K. C. Wong
   Magna Fund in Ningbo University
FX This work was supported by Natural Science Foundation of China under
   Grant No. 61501270 and 61311140262, Natural Science Foundation of Ningbo
   under Grant No. 2017A610127 and 2016A610071. It was also sponsored by
   the K. C. Wong Magna Fund in Ningbo University.
CR [Anonymous], 2016, J INFORM HIDING MULT
   [Anonymous], J INFO HIDING MULT S
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chambers J, 2015, MULTIMED TOOLS APPL, V74, P4013, DOI 10.1007/s11042-013-1809-x
   Chen XY, 2013, J SYST SOFTWARE, V86, P2620, DOI 10.1016/j.jss.2013.04.086
   Chen YH, 2016, MULTIMED TOOLS APPL, V75, P13679, DOI 10.1007/s11042-015-2825-9
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   DANGNGUYEN DT, 2015, RAISE RAW IMAGES DAT, P219
   Dragoi IC, 2016, EUR SIGNAL PR CONF, P1178, DOI 10.1109/EUSIPCO.2016.7760434
   Fallahpour M, 2008, IEICE ELECTRON EXPR, V5, P870, DOI 10.1587/elex.5.870
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Fu DS, 2014, AEU-INT J ELECTRON C, V68, P933, DOI 10.1016/j.aeue.2014.04.015
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   Hong W, 2017, MULTIMED TOOLS APPL, V76, P5441, DOI 10.1007/s11042-016-4032-8
   Huang HC, 2016, OPTIK, V127, P5950, DOI 10.1016/j.ijleo.2016.04.011
   Jung SW, 2011, IEEE SIGNAL PROC LET, V18, P95, DOI 10.1109/LSP.2010.2095498
   Kim KS, 2009, PATTERN RECOGN, V42, P3083, DOI 10.1016/j.patcog.2009.04.004
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Lin ZX, 2017, SIGNAL PROCESS-IMAGE, V57, P134, DOI 10.1016/j.image.2017.05.012
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Luo T, 2016, DIGIT SIGNAL PROCESS, V48, P116, DOI 10.1016/j.dsp.2015.09.007
   Mao JF, 2016, MULTIMED TOOLS APPL, V75, P5999, DOI 10.1007/s11042-015-2708-0
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, J SYST SOFTWARE, V86, P2700, DOI 10.1016/j.jss.2013.05.077
   Parthasarathy AK, 2007, IEEE T BROADCAST, V53, P468, DOI 10.1109/TBC.2007.894947
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P1983, DOI 10.1007/s11042-013-1733-0
   Padilla-López JR, 2015, EXPERT SYST APPL, V42, P4177, DOI 10.1016/j.eswa.2015.01.041
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Schnev V., 2010, IEEE T CIRCUITS SYST, V5, P187
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai HH, 2011, PATTERN RECOGN, V44, P751, DOI 10.1016/j.patcog.2010.10.004
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang SQ, 2016, IEEE T IMAGE PROCESS, V25, P3838, DOI 10.1109/TIP.2016.2573597
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang XK, 2005, IEEE T CIRC SYST VID, V15, P742, DOI 10.1109/TCSVT.2005.848313
   Yang Y, 2016, MULTIMED TOOLS APPL, V75, P13663, DOI 10.1007/s11042-015-2824-x
   Zhong CM, 2015, PATTERN RECOGN LETT, V59, P48, DOI 10.1016/j.patrec.2015.03.007
   Zhou WJ, 2016, IEEE T MULTIMEDIA, V18, P1077, DOI 10.1109/TMM.2016.2542580
NR 45
TC 8
Z9 9
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19027
EP 19050
DI 10.1007/s11042-017-5356-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500007
DA 2024-07-18
ER

PT J
AU Pashakolaee, PG
   Shahhoseini, HS
   Mollajafari, M
AF Pashakolaee, Parisa Gholizadeh
   Shahhoseini, Hadi Shahriar
   Mollajafari, Morteza
TI Hyper-chaotic Feeded GA (HFGA): a reversible optimization technique for
   robust and sensitive image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Genetic algorithm; Hyper-chaotic system; Security
   evaluation
ID DNA-SEQUENCE OPERATION; ALGORITHM; DIFFUSION; CRYPTANALYSIS;
   IMPROVEMENT; SYSTEM
AB In recent years, due to their straightforward structure and efficiency, the chaos-based cryptographic algorithms have become a good candidate for image encryption. However, they still suffer from many weaknesses, such as insensitivity to the plain image, weak key streams, small key space, non-resistance to some attacks and failure to meet some security criteria. For this purpose in this paper, a novel hybrid image encryption algorithm named Hyper-chaotic Feeded GA (HFGA) is proposed to fill the gaps in two stages; initial encryption by using a hyper-chaotic system, and then outputs reinforcement by employing a customized Genetic Algorithm (GA). By applying an innovative technique, called gene-labelling, the proposed algorithm not only optimizes the preliminary encrypted images in terms of security criteria but also allows the legal receiver to easily and securely decrypt the optimized cipher image. In fact, in the first stage, besides unpredictable random sequences generated by a hyper-chaotic system, a new sensitive diffusion function is proposed which makes the algorithm resistant to differential attacks. In the second stage, the generated cipher images, which are labeled in a special way, will be used as the initial population of a GA which enhances randomness of the cipher images. The results of several experiments and statistical analysis show that the proposed image encryption scheme provides an efficient and secure way for fast image encrypting as well as providing robustness against some well-known statistical attacks.
C1 [Pashakolaee, Parisa Gholizadeh; Shahhoseini, Hadi Shahriar; Mollajafari, Morteza] Iran Univ Sci & Technol, Sch Elect Engn, Tehran, Iran.
C3 Iran University Science & Technology
RP Shahhoseini, HS (corresponding author), Iran Univ Sci & Technol, Sch Elect Engn, Tehran, Iran.
EM p_gholizadeh@elec.iust.ac.ir; shahhoseini@iust.ac.ir;
   mollajafari@elec.iust.ac.ir
RI Shahhoseini, HadiShahriar/S-9857-2018; Mollajafari,
   Morteza/AAH-2050-2020
OI Mollajafari, Morteza/0000-0002-2717-6335; Shahhoseini, Hadi
   Shahriar/0000-0002-6042-0993
CR Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Alvarez G, 2009, COMMUN NONLINEAR SCI, V14, P3743, DOI 10.1016/j.cnsns.2009.02.033
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Alvarez G, 2011, STUD COMPUT INTELL, V354, P257
   [Anonymous], 1996, LECT NOTES STATUS IE
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P9907, DOI 10.1007/s11042-016-3585-x
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JX, 2015, SIGNAL PROCESS, V111, P294, DOI 10.1016/j.sigpro.2015.01.003
   Chen JX, 2015, OPT LASER ENG, V67, P191, DOI 10.1016/j.optlaseng.2014.11.017
   Das S, 2015, ADV INTELL SYST, V327, P729, DOI 10.1007/978-3-319-11933-5_82
   El-Samie F.E. A., 2013, Image encryption: A communication perspective, DOI 10.1201/b1630
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Eslami Z, 2013, OPT COMMUN, V286, P51, DOI 10.1016/j.optcom.2012.07.052
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu ZJ, 2019, IEEE T SERV COMPUT, V12, P813, DOI 10.1109/TSC.2016.2622697
   Furht B., 2004, MULTIMEDIA SECURITY
   Gao HJ, 2006, CHAOS SOLITON FRACT, V29, P393, DOI 10.1016/j.chaos.2005.08.110
   Ghebleh M, 2018, MULTIMED TOOLS APPL, V77, P7305, DOI 10.1007/s11042-017-4634-9
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Guesmi R, 2016, MULTIMED TOOLS APPL, V75, P4753, DOI 10.1007/s11042-015-2501-0
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Li CQ, 2016, SIGNAL PROCESS, V118, P203, DOI 10.1016/j.sigpro.2015.07.008
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Liu Z, 2010, J OPT, V12, P35
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Murugan B, 2016, IET COMPUT VIS, V10, P593, DOI 10.1049/iet-cvi.2015.0344
   Niu YJ, 2010, COMMUN NONLINEAR SCI, V15, P3518, DOI 10.1016/j.cnsns.2009.12.005
   Norouzi B, 2017, MULTIMED TOOLS APPL, V76, P1817, DOI 10.1007/s11042-015-3085-4
   Norouzi B, 2015, MULTIMED TOOLS APPL, V74, P781, DOI 10.1007/s11042-013-1699-y
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Norouzi B, 2014, MULTIMEDIA SYST, V20, P45, DOI 10.1007/s00530-013-0314-4
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Patidar V, 2009, COMMUN NONLINEAR SCI, V14, P3056, DOI 10.1016/j.cnsns.2008.11.005
   Ping P, 2014, SIGNAL PROCESS, V105, P419, DOI 10.1016/j.sigpro.2014.06.020
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Stinson D. R., 2005, CRYPTOGRAPHY THEORY
   Su YG, 2017, OPT LASER ENG, V88, P20, DOI 10.1016/j.optlaseng.2016.07.012
   Teng L, 2018, MULTIMED TOOLS APPL, V77, P6883, DOI 10.1007/s11042-017-4605-1
   Wang K, 2005, PHYS LETT A, V343, P432, DOI 10.1016/j.physleta.2005.05.040
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2016, NONLINEAR DYNAM, V83, P333, DOI 10.1007/s11071-015-2330-8
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang Y, 2007, PHYS LETT A, V363, P277, DOI 10.1016/j.physleta.2006.11.023
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xiang T, 2006, PHYS LETT A, V349, P109, DOI 10.1016/j.physleta.2005.02.083
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yuan CS, 2017, J INTERNET TECHNOL, V18, P435, DOI 10.6138/JIT.2017.18.2.20160624c
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang YQ, 2016, OPT LASER ENG, V82, P95, DOI 10.1016/j.optlaseng.2016.02.002
   Zhang Y, 2012, NONLINEAR DYNAM, V69, P1091, DOI 10.1007/s11071-012-0329-y
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
NR 60
TC 13
Z9 13
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20385
EP 20414
DI 10.1007/s11042-017-5461-8
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300005
DA 2024-07-18
ER

PT J
AU Wang, YY
   Yang, CS
   Zhu, CQ
AF Wang, Yingying
   Yang, Chengsong
   Zhu, Changqing
TI A multiple watermarking algorithm for vector geographic data based on
   coordinate mapping and domain subdivision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple watermarking; Vector geographic data; Mapping; Domain; Block;
   Robustness
AB A lot of watermarking algorithms for vector geographic data are presented in the literature. Due to widely application of digital watermarking, more demands are required, such as multiple watermarking algorithm. However, vector geographic data attracted less research focus on multiple watermarking. Consequently, a multiple watermarking algorithm for vector geographic data is proposed. In particular, the vertices are mapped to the logic domains firstly based on the constructed function. Then every domain is subdivided into blocks according to dichotomy and the number of embedding watermarks. Then, every watermark is embedded in the corresponding block. During the watermark detection, the watermarks are detected without the original vector geographic data. Finally, the experiments are made to test the multiple watermark capacity and robustness against attacks, with an emphasis on cropping attacks. The experimental results show that the proposed algorithm has good robustness against common attacks, such as, data simplification, vertex addition, vertex deletion, feature deletion, and cropping attacks. Moreover, the algorithm provides high multiple watermark capacity.
C1 [Wang, Yingying; Zhu, Changqing] Nanjing Normal Univ, Key Lab Virtual Geog Environm, Minist Educ, Nanjing 210023, Jiangsu, Peoples R China.
   [Yang, Chengsong] PEA Univ Sci & Technol, Inst Field Engn, Nanjing 210007, Jiangsu, Peoples R China.
   [Wang, Yingying; Zhu, Changqing] State Key Lab Cultivat Base Geog Environm Evolut, Nanjing 210023, Jiangsu, Peoples R China.
   [Wang, Yingying; Zhu, Changqing] Jiangsu Ctr Collaborat Innovat Geog Informat Reso, Nanjing 210023, Jiangsu, Peoples R China.
C3 Nanjing Normal University
RP Yang, CS (corresponding author), PEA Univ Sci & Technol, Inst Field Engn, Nanjing 210007, Jiangsu, Peoples R China.
EM ycsdongshang@163.com
OI Yingying, Wang/0000-0002-1530-8708
FU National Natural Science Foundation of China [41401518]; Natural Science
   Foundation of Jiangsu Province [BK20140066]; special scientific research
   of public service industry on state surveying and mapping [201512019];
   Priority Academic Program Development of Jiangsu Higher Education
   Institutions
FX The work was supported by the National Natural Science Foundation of
   China (grant No. 41401518), the Natural Science Foundation of Jiangsu
   Province (grant No. BK20140066), the special scientific research of
   public service industry on state surveying and mapping (grant No.
   201512019), and a project funded by the Priority Academic Program
   Development of Jiangsu Higher Education Institutions.
CR Bhatnagar G, 2015, MULTIMED TOOLS APPL, V74, P8421, DOI 10.1007/s11042-013-1681-8
   Cai LJ, 2012, J CENT SOUTH UNIV, V19, P2866, DOI 10.1007/s11771-012-1353-2
   Cao JH, 2010, P 18 INT C GEOINF, DOI [10.1109/GEOINFORMATICS.2010.5568201, DOI 10.1109/GEOINFORMATICS.2010.5568201]
   Cao LJ, 2013, DIGIT SIGNAL PROCESS, V23, P912, DOI 10.1016/j.dsp.2012.11.007
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Cox I. J., 2002, Digital Watermarking
   Cui H, 2013, THESIS
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Hwan Il K, 2002, P INT C INF TECH COD, P234
   Lee SH, 2014, IEICE T INF SYST, VE97D, P34, DOI 10.1587/transinf.E97.D.34
   Lee SH, 2013, MULTIMED TOOLS APPL, V63, P757, DOI 10.1007/s11042-011-0894-y
   [李强 Li Qiang], 2011, [测绘科学, Science of Surveying and Mapping], V36, P119
   Li YY, 2003, ICCIMA 2003: FIFTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, PROCEEDINGS, P424
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Luo H, 2009, INT J INNOV COMPUT I, V5, P1875
   Ohbuchi R, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P577, DOI 10.1109/ICME.2002.1035847
   Peng ZY, 2015, MULTIMED TOOLS APPL, V74, P11721, DOI 10.1007/s11042-014-2259-9
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Shao CY, 2006, IEICE T INF SYST, VE89D, P1290, DOI 10.1093/ietisy/e89-d.3.1290
   Solachidis V, 2000, INT CONF ACOUST SPEE, P1955, DOI 10.1109/ICASSP.2000.859213
   [孙建国 Sun Jianguo], 2010, [哈尔滨工程大学学报, Journal of Harbin Engineering University], V31, P488
   Voigt M, 2004, P 2004 MULT SEC WORK, P160, DOI DOI 10.1145/1022431.1022459
   Wang NN, 2017, AEU-INT J ELECTRON C, V71, P118, DOI 10.1016/j.aeue.2016.10.010
   Wang YY, 2017, P GEOSP KNOWL INT 4, P429
   Wong PHW, 2003, IEEE T CIRC SYST VID, V13, P813, DOI 10.1109/TCSVT.2003.815948
   Xiong LZ, 2016, MULTIMED TOOLS APPL, V75, P5377, DOI 10.1007/s11042-015-2504-x
   [杨成松 Yang Chengsong], 2011, [测绘学报, Acta Geodetica et Cartographica Sinica], V40, P256
   [杨成松 YANG Chengsong], 2010, [中国图象图形学报, Journal of Image and Graphics], V15, P684
   Zhang LM, 2016, J GEOM, V41, P32, DOI [10.14188/J.2095-6045.2016.05.008, DOI 10.14188/J.2095-6045.2016.05.008]
NR 30
TC 7
Z9 10
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19261
EP 19279
DI 10.1007/s11042-017-5358-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500017
OA hybrid
DA 2024-07-18
ER

PT J
AU Yang, B
   Cao, JM
   Jiang, DP
   Lv, JD
AF Yang, Biao
   Cao, Jin-Meng
   Jiang, Da-Peng
   Lv, Ji-Dong
TI Facial expression recognition based on dual-feature fusion and improved
   random forest classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Dual-feature fusion; Random forest; Deep
   geometric feature; Local appearance feature
ID 3D; HISTORY
AB Facial expression recognition (FER) is an important means for machines to understand the changes in the facial expression of human beings. Expression recognition using single-modal facial images, such as gray scale, may suffer from illumination changes and the lack of detailed expression-related information. In this study, multi-modal facial images, such as facial gray scale, depth, and local binary pattern (LBP), are used to recognize six basic facial expressions, namely, happiness, sadness, anger, disgust, fear, and surprise. Facial depth images are used for robust face detection initially. The deep geometric feature is represented by point displacement and angle variation in facial landmark points with the help of depth information. The local appearance feature, which is obtained by concatenating LBP histograms of expression-prominent patches, is utilized to recognize those expression changes that are difficult to capture by only the geometric changes. Thereafter, an improved random forest classifier based on feature selection is used to recognize different facial expressions. Results of comparative evaluations in benchmarking datasets show that the proposed method outperforms several state-of-the-art FER approaches that are based on hand-crafted features. The capability of the proposed method is comparable to that of the popular convolutional neuralnetwork-based FER approach but with fewer demands for training data and a high-performance hardware platform.
C1 [Yang, Biao; Cao, Jin-Meng; Jiang, Da-Peng; Lv, Ji-Dong] Changzhou Univ, Sch Informat Sci & Engn, Changzhou 213164, Jiangsu, Peoples R China.
C3 Changzhou University
RP Yang, B (corresponding author), Changzhou Univ, Sch Informat Sci & Engn, Changzhou 213164, Jiangsu, Peoples R China.
EM Yb6864171@cczu.edu.cn; 1020053623@qq.com; 527688483@qq.com;
   vveaglevv@163.com
FU National Natural Science Foundation of China [61501060, 61502058];
   Natural Science Foundation of Jiangsu Province [BK20150271, BK20140266];
   Natural Science Foundation of Educational Committee of Jiangsu Province
   [15KJB520002]
FX This work has been supported by the National Natural Science Foundation
   of China under Grant No. 61501060 and No. 61502058, the Natural Science
   Foundation of Jiangsu Province under Grant No. BK20150271 and No.
   BK20140266, Natural Science Foundation of Educational Committee of
   Jiangsu Province under Grant 15KJB520002.
CR Corneanu CA, 2016, IEEE T PATTERN ANAL, V38, P1548, DOI 10.1109/TPAMI.2016.2515606
   Aly S. S., 2016, Proceedings of the NAVC Conference, 16-20 January 2016, Orlando, Florida, USA.  Volume 30, Large Animal, P1
   Aly S, 2015, INT CONF BIOMETR, P90, DOI 10.1109/ICB.2015.7139081
   Baltrusaitis T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P354, DOI 10.1109/ICCVW.2013.54
   Barnouti NH, 2016, INT J ADV COMPUT SC, V7, P371
   Beeler T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778777
   Chao WL, 2015, SIGNAL PROCESS, V117, P1, DOI 10.1016/j.sigpro.2015.04.007
   Chen CR, 2011, IEEE T VLSI SYST, V19, P1937, DOI 10.1109/TVLSI.2010.2069575
   Chen J, 1949, IEEE T AFFECT COMPUT, V99, P1
   Cheng S., 2014, Proceedings of the 5th ACM Multimedia Systems Conference, P148
   Danelakis A, 2016, VISUAL COMPUT, V32, P1001, DOI 10.1007/s00371-016-1243-y
   Demirkus M, 2014, IEEE IMAGE PROC, P3392, DOI 10.1109/ICIP.2014.7025686
   Fan X, 2016, PATTERN RECOGN LETT, V83, P395, DOI 10.1016/j.patrec.2016.07.005
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Jain S., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1642, DOI 10.1109/ICCVW.2011.6130446
   Kobayashi H, 1997, IEEE SYS MAN CYBERN, P3732, DOI 10.1109/ICSMC.1997.633250
   Kung S. H., 2016, T MACH LEARN ARTIF I, V3, P42, DOI DOI 10.14738/TMLAI.36.1661
   Li BYL, 2013, IEEE WORK APP COMP, P186, DOI 10.1109/WACV.2013.6475017
   Li HB, 2015, COMPUT VIS IMAGE UND, V140, P83, DOI 10.1016/j.cviu.2015.07.005
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   MASE K, 1991, IEICE TRANS COMMUN, V74, P3474
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   Moeini A, 2016, J VIS COMMUN IMAGE R, V35, P1, DOI 10.1016/j.jvcir.2015.11.006
   Mohammadi MR, 2014, J VIS COMMUN IMAGE R, V25, P1082, DOI 10.1016/j.jvcir.2014.03.006
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Pu XR, 2015, NEUROCOMPUTING, V168, P1173, DOI 10.1016/j.neucom.2015.05.005
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shao J, 2015, PATTERN RECOGN LETT, V65, P157, DOI 10.1016/j.patrec.2015.07.039
   Siddiqi MH, 2015, IEEE T IMAGE PROCESS, V24, P1386, DOI 10.1109/TIP.2015.2405346
   Siddiqi MH, 2014, IETE TECH REV, V31, P277, DOI 10.1080/02564602.2014.944588
   Valstar M, 2004, IEEE SYS MAN CYBERN, P635
   Yadan Lv, 2014, 2014 International Conference on Smart Computing (SMARTCOMP), P303, DOI 10.1109/SMARTCOMP.2014.7043872
   Yu ZD, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P435
   Zhang W, 2015, PATTERN RECOGN, V48, P3191, DOI 10.1016/j.patcog.2015.04.012
   Zhang Y, 2015, EXPERT SYST APPL, V42, P1446, DOI 10.1016/j.eswa.2014.08.042
   Zhang Z, 2016, 2016 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2016), P407, DOI [10.1109/WI.2016.62, 10.1109/WI.2016.0063]
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhen QK, 2016, IEEE T MULTIMEDIA, V18, P1438, DOI 10.1109/TMM.2016.2557063
   Zhong L, 2015, IEEE T CYBERNETICS, V45, P1499, DOI 10.1109/TCYB.2014.2354351
NR 40
TC 19
Z9 20
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20477
EP 20499
DI 10.1007/s11042-017-5489-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300008
DA 2024-07-18
ER

PT J
AU Yuan, S
   Mao, X
   Chen, LJ
AF Yuan, Sen
   Mao, Xia
   Chen, Lijiang
TI Elastic preserving projections based on L1-norm maximization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Elastic preserving projections; L2-norm; L1-norm; Manifold learning;
   Dimensionality reduction; Outliers
ID PRINCIPAL COMPONENT ANALYSIS; DISCRIMINANT-ANALYSIS; DIMENSIONALITY
   REDUCTION; FACE; EIGENFACES; EIGENMAPS; NORM
AB Elastic preserving projections (EPP) is a classical manifold learning technique for dimensionality reduction, which has demonstrated good performance in pattern recognition. However, EPP is sensitive to the outliers because it makes use of the L2-norm for optimization. In this paper, we propose an effective and robust EPP version based on L1-norm maxmization (EPP-L1), which can learn the optimal projection vectors by maximizing the ratio of the global dispersion to the local dispersion using the L1-norm rather than L2-norm. The proposed method is proved to be feasible and also robust to outliers while overcoming the singular problem of the local scatter matrix for EPP. Experiments on five popular face image databases demonstrate the effectiveness of the proposed method.
C1 [Yuan, Sen; Mao, Xia; Chen, Lijiang] Beihang Univ, Sch Elect & Informat Engn, Beijing 100191, Peoples R China.
C3 Beihang University
RP Chen, LJ (corresponding author), Beihang Univ, Sch Elect & Informat Engn, Beijing 100191, Peoples R China.
EM chenlijiang@buaa.edu.cn
FU National Science Foundation of China [61603013]
FX The authors would like to thank the anonymous reviewers for their
   valuable and constructive criticisms that are very helpful to improve
   the quality of this paper. This work was supported by the National
   Science Foundation of China (Grant no.61603013).
CR [Anonymous], URBAN WATER QUALITY
   [Anonymous], 2016, ARXIV161009462
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Bengio Y, 2004, ADV NEUR IN, V16, P177
   Cai D., 2007, AAAI, P528
   Cai WL, 2017, KNOWL-BASED SYST, V118, P191, DOI 10.1016/j.knosys.2016.11.020
   Guo Y., 2016, International Joint Conference on Artificial Intelligence, P3382
   Harandi M., 2017, IEEE T PATTERN ANAL
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Howland P, 2004, IEEE T PATTERN ANAL, V26, P995, DOI 10.1109/TPAMI.2004.46
   Huang G. B., 2007, Technical Report, DOI 10.1.1. 122.8268
   Huang SC, 2016, NEUROCOMPUTING, V208, P373, DOI 10.1016/j.neucom.2016.02.063
   Jenatton R., 2010, JMLR WORKSH C P 2010, P366
   Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114
   Kwak N, 2014, IEEE T CYBERNETICS, V44, P594, DOI 10.1109/TCYB.2013.2262936
   Li XL, 2010, IEEE T SYST MAN CY B, V40, P1170, DOI 10.1109/TSMCB.2009.2035629
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu G., 2016, Multimedia Tools and Applications, P1
   Lu YF, 2017, MATH MECH SOLIDS, V22, P1997, DOI 10.1177/1081286516653272
   Luo TJ, 2016, NEUROCOMPUTING, V179, P54, DOI 10.1016/j.neucom.2015.11.037
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Nie F., 2011, INT JOINT C ART INT, V22, P1433
   Pang YW, 2010, NEUROCOMPUTING, V73, P968, DOI 10.1016/j.neucom.2009.08.020
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang J, 2016, IEEE T CYBERNETICS, V46, P792, DOI 10.1109/TCYB.2015.2416274
   Wang Q, 2016, IEEE T NEURAL NETWOR
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008
   Yang WK, 2016, NEUROCOMPUTING, V175, P198, DOI 10.1016/j.neucom.2015.10.049
   Yu MY, 2016, IEEE T PATTERN ANAL, V38, P1908, DOI 10.1109/TPAMI.2015.2497686
   Yuan S, 2017, NEUROCOMPUTING
   Yuan S, 2017, IEEE T IMAGE PROCESS
   Yuan S, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.063017
   Zang F, 2012, PATTERN RECOGN, V45, P3866, DOI 10.1016/j.patcog.2012.04.022
   Zhang D, 2014, PATTERN RECOGN, V47, P1433, DOI 10.1016/j.patcog.2013.10.005
   Zheng WM, 2014, IEEE T NEUR NET LEAR, V25, P793, DOI 10.1109/TNNLS.2013.2281428
   Zhong FJ, 2014, IEEE T NEUR NET LEAR, V25, P2065, DOI 10.1109/TNNLS.2014.2303798
   Zhong FJ, 2013, IEEE T IMAGE PROCESS, V22, P3018, DOI 10.1109/TIP.2013.2253476
NR 44
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21671
EP 21691
DI 10.1007/s11042-018-5608-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300059
DA 2024-07-18
ER

PT J
AU Chen, HK
   Li, MW
AF Chen, Hung-Kuang
   Li, Mu-Wei
TI A novel mesh saliency approximation for polygonal mesh segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mesh saliency; Part salience; Mesh segmentation
ID SURFACE DECOMPOSITION; MINIMA RULE; PARTS; GENERATION; SIMILARITY
AB To assist a great variety of applications including object recognition or shape matching, 3D scene analysis, view point selection, mesh simplification, segmentation, and 3D printing etc., the approximation of mesh or part saliency has been intensively studied in recent years. A recent trend on developing such techniques has been turned from utilizing local or global shape descriptors to human visual perceptual rules. Consequently, the concepts and the theories from cognition science were extensively applied. In this paper, we borrowed the theory of part salience by Hoffman and Singh and devised an approach to mesh or part saliency computations. Unlike previous attempts, we proposed a single scalable measure of mesh or part saliency via a linear combination of the three factors of human visual perception, i.e, the degree of part protrusion, the relative size of a part, and the strength of a part's boundaries, in addition to their individual quantizations. To verify the efficacy of our approach, an iterative saliency-optimized polygonal mesh segmentation is devised. To provide an objective quantitative evaluation in addition to traditional visual inspection, a public domain benchmark software developed by Chen et al. was deployed. According to the inspections on the colored segments and the benchmarking scores, our saliency computation indeed improves the segmentation of 3D objects with protrusive parts, outperforming a number of well-known approaches.
C1 [Chen, Hung-Kuang; Li, Mu-Wei] Natl Chin Yi Univ Technol, Elect Engn Dept, Taichung 41170, Taiwan.
C3 National Chin-Yi University of Technology
RP Chen, HK (corresponding author), Natl Chin Yi Univ Technol, Elect Engn Dept, Taichung 41170, Taiwan.
EM hankchentw@gmail.com; zx1122337@gmail.com
RI Chen, Hung-Kuang/R-1255-2019
OI Chen, Hung-Kuang/0000-0002-3994-9745
CR Agathos A, 2010, VISUAL COMPUT, V26, P63, DOI 10.1007/s00371-009-0383-8
   Attene M, 2006, VISUAL COMPUT, V22, P181, DOI 10.1007/s00371-006-0375-x
   Au OKC, 2012, IEEE T VIS COMPUT GR, V18, P1125, DOI 10.1109/TVCG.2011.131
   Benhabiles H, 2010, VISUAL COMPUT, V26, P1451, DOI 10.1007/s00371-010-0494-2
   BRAUNSTEIN ML, 1989, PERCEPTION, V18, P817, DOI 10.1068/p180817
   Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379
   Feixas M, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1462055.1462056
   Funkhouser T, 2004, ACM T GRAPHIC, V23, P652, DOI 10.1145/1015706.1015775
   Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507
   Golovinskiy A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409098
   Gregory A, 1999, VISUAL COMPUT, V15, P453, DOI 10.1007/s003710050192
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Ho TC, 2012, J INF SCI ENG, V28, P705
   Hoffman DD, 1997, COGNITION, V63, P29, DOI 10.1016/S0010-0277(96)00791-3
   HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Katz S, 2005, VISUAL COMPUT, V21, P649, DOI 10.1007/s00371-005-0344-9
   Katz S, 2003, ACM T GRAPHIC, V22, P954, DOI 10.1145/882262.882369
   Kenong Wu, 1996, Proceedings of the 13th International Conference on Pattern Recognition, P14, DOI 10.1109/ICPR.1996.545983
   Kim DH, 2005, PATTERN RECOGN, V38, P673, DOI 10.1016/j.patcog.2004.10.003
   Lai YK, 2008, SPM 2008: PROCEEDINGS OF THE ACM SOLID AND PHYSICAL MODELING SYMPOSIUM, P183
   Lavoué G, 2005, COMPUT AIDED DESIGN, V37, P975, DOI 10.1016/j.cad.2004.09.001
   Lavoue G., 2012, EUROGRAPHICS WORKSHO, P93
   Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244
   Lee Y, 2005, COMPUT AIDED GEOM D, V22, P444, DOI 10.1016/j.cagd.2005.04.002
   Lévy B, 2002, ACM T GRAPHIC, V21, P362, DOI 10.1145/566570.566590
   Limper Max., 2016, Proceedings of the Thirty-Seventh Annual Conference of the European Association for Computer Graphics: Short Papers, P13, DOI DOI 10.2312/EGSH.20161003
   Lin HYS, 2007, IEEE T MULTIMEDIA, V9, P46, DOI 10.1109/TMM.2006.886344
   Lin HYS, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P331
   Liu ZB, 2013, COMPUT GRAPH-UK, V37, P553, DOI 10.1016/j.cag.2013.05.021
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Meng M, 2011, COMPUT GRAPH-UK, V35, P650, DOI 10.1016/j.cag.2011.03.038
   Nouri A, 2015, SIGNAL PROCESS-IMAGE, V38, P151, DOI 10.1016/j.image.2015.08.002
   Page DL, 2003, PROC CVPR IEEE, P27
   Qian Huang, 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P53, DOI 10.1109/ICIP.1995.537578
   RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239
   Shamir A, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P82
   Shamir A, 2008, COMPUT GRAPH FORUM, V27, P1539, DOI 10.1111/j.1467-8659.2007.01103.x
   Shapira L, 2008, VISUAL COMPUT, V24, P249, DOI 10.1007/s00371-007-0197-5
   Shlafman S, 2002, COMPUT GRAPH FORUM, V21, P219, DOI 10.1111/1467-8659.00581
   Song R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2530691
   Sun XP, 2015, LECT NOTES ELECTR EN, V331, P621, DOI 10.1007/978-94-017-9618-7_64
   Theologou P, 2015, COMPUT VIS IMAGE UND, V135, P49, DOI 10.1016/j.cviu.2014.12.008
   Tsuchie S, 2014, PACIFIC GRAPHICS SHO, DOI [10.2312/pgs.20141247, DOI 10.2312/PGS.20141247]
   Valette S., 2005, WORKSHOP SEMANTIC VI, P68
   van Kaick O, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2611811
   Wang X, 2016, IEEE COMPUT GRAPH, V36, P46, DOI 10.1109/MCG.2016.47
   Wu JL, 2013, GRAPH MODELS, V75, P255, DOI 10.1016/j.gmod.2013.05.002
   Wu KN, 1997, IEEE T PATTERN ANAL, V19, P1223, DOI 10.1109/34.632982
   Yan DM, 2012, COMPUT AIDED DESIGN, V44, P1072, DOI 10.1016/j.cad.2012.04.005
   Zhang H., 2005, PROC C VISION MODELI, P429
   Zhang Y, 2002, 2002 INT C IM PROC 2, V3, DOI 10.1109/ICIP.2002.1038958
   Zöckler M, 2000, VISUAL COMPUT, V16, P241, DOI 10.1007/PL00013396
   Zuckerberger E, 2002, COMPUT GRAPH-UK, V26, P733, DOI 10.1016/S0097-8493(02)00128-0
NR 54
TC 6
Z9 12
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 17223
EP 17246
DI 10.1007/s11042-017-5287-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300055
DA 2024-07-18
ER

PT J
AU Lv, JP
   Li, S
   Zhang, XP
AF Lv, Jinpeng
   Li, Sheng
   Zhang, Xinpeng
TI A novel auxiliary data construction scheme for reversible data hiding in
   JPEG images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE JPEG; Reversible data hiding; File size preservation
ID DIFFERENCE EXPANSION; BITSTREAM
AB Constructing the auxiliary data is important in some reversible data hiding (RDH) techniques, where both the auxiliary data and the secret data are embedded into the cover image. The auxiliary data can be extracted and served as side information for the image recovery. In this paper, we propose a novel auxiliary data construction scheme for RDH in JPEG images. In order to preserve the file size, we adopt the RDH framework proposed by Fridrich et al., where the least significant bits (LSBs) of the original AC coefficients (termed as the original LSBs) are compressed directly as the auxiliary data. In order to achieve a higher compression rate, we propose to reconstruct the original LSBs from the corresponding AC coefficients with all the LSBs set to zero, which is performed by analyzing the block artifacts in the spatial domain. The auxiliary data is then constructed by compressing the original LSBs conditioned on the reconstructed LSBs. In conjunction with the auxiliary data construction, we also propose a coefficient selection strategy to further improve the compression rate. The experiments show that the size of our auxiliary data is smaller than that compressed from the original LSBs directly. In addition, the RDH framework with the proposed scheme outperforms the state-of-the-art JPEG RDH techniques with file size preservation.
C1 [Lv, Jinpeng; Li, Sheng; Zhang, Xinpeng] Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
C3 Shanghai University
RP Lv, JP (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
EM ljp@shu.edu.cn; shengli@shu.edu.cn; xzhang@shu.edu.cn
RI li, sheng/AAF-2381-2019
OI li, sheng/0000-0002-7932-9831
FU Natural Science Foundation of China [61525203, U1636206, 61602294,
   61472235]; Shanghai Dawn Scholar Plan [14SG36]; Shanghai Excellent
   Academic Leader Plan [16XD1401200]; Young Oriental Scholar under
   Shanghai Institutions of Higher Education; Shanghai Sailing Program
   [16YF1404100]
FX This work was supported in the Natural Science Foundation of China
   (61525203, U1636206, 61602294 and 61472235), the Shanghai Dawn Scholar
   Plan (14SG36) and the Shanghai Excellent Academic Leader Plan
   (16XD1401200), the Young Oriental Scholar under Shanghai Institutions of
   Higher Education, the Shanghai Sailing Program under Grant 16YF1404100.
CR Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   Fridrich J, 2004, PROC SPIE, V5306, P354, DOI 10.1117/12.525418
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Hu XC, 2015, IEEE T INF FOREN SEC, V10, P653, DOI 10.1109/TIFS.2015.2392556
   Hu YJ, 2013, J SYST SOFTWARE, V86, P2166, DOI 10.1016/j.jss.2013.03.102
   Hu YJ, 2008, IEEE T MULTIMEDIA, V10, P1500, DOI 10.1109/TMM.2008.2007341
   Huang F, 2015, IEEE T CIRCUITS SYST, V99, P1
   Li QM, 2010, LECT NOTES COMPUT SC, V6297, P653, DOI 10.1007/978-3-642-15702-8_60
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Long J, 2016, IETE TECH REV, V33, P607, DOI 10.1080/02564602.2015.1132014
   Mobasseri BG, 2010, IEEE T IMAGE PROCESS, V19, P958, DOI 10.1109/TIP.2009.2035227
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Nikolaidis A, 2016, MULTIMED TOOLS APPL, V75, P1869, DOI 10.1007/s11042-014-2377-4
   Qian Z., 2016, IEEE INFOCOM 2016-The 35th Annual IEEE International Conference on Computer Communications, P1
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Qian ZX, 2012, J SYST SOFTWARE, V85, P309, DOI 10.1016/j.jss.2011.08.015
   Qin C, 2016, SIGNAL PROCESS, V129, P48, DOI 10.1016/j.sigpro.2016.05.032
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   SAYOOD K, 1996, INTRO DATA COMPRESSI, P87
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Zhang XG, 2013, IEEE T MULTIMEDIA, V15, P1446, DOI 10.1109/TMM.2013.2247988
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
NR 26
TC 4
Z9 4
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18029
EP 18041
DI 10.1007/s11042-017-4557-5
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900025
DA 2024-07-18
ER

PT J
AU Sun, GL
   Cheng, ZQ
   Wu, X
   Peng, Q
AF Sun, Guang-Lu
   Cheng, Zhi-Qi
   Wu, Xiao
   Peng, Qiang
TI Personalized clothing recommendation combining user social circle and
   fashion style consistency
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clothing recommendation; Social circle; Fashion; Collaborative filtering
AB With the rapid expansion of social networks and fashion websites, clothing recommendation has attracted more attention of researchers, since various web data bring opportunities for recommender systems to solve the problems of cold start and sparsity. For clothing recommender system, user social circle and fashion style consistency of clothing items are two important factors, which have critical impacts on user decision making. In this paper, two practical problems are considered: how to visually analyze fashion style consistency between clothing items and how to implement personalized clothing recommendation by combining user social circle and fashion style consistency. To address the first problem, a Siamese Convolutional Neural Network (SCNN) with a novel sampling strategy is employed to measure the fashion style consistency of clothing items. It can learn a feature transformation from clothing images to a latent feature space, where the representations of clothing items with similar styles locate closer than those with different styles. For the second problem, three social factors (i.e., personal interest, interpersonal interest similarity and interpersonal influence) and fashion style consistency are fused into a unified personalized recommendation model based on probabilistic matrix factorization (PMF). To comprehensively evaluate our model, extensive experiments have been conducted on two real world datasets collected from a popular social fashion website, which demonstrate the effectiveness of the proposed method for personalized clothing recommendation.
C1 [Sun, Guang-Lu; Cheng, Zhi-Qi; Wu, Xiao; Peng, Qiang] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu, Sichuan, Peoples R China.
C3 Southwest Jiaotong University
RP Wu, X (corresponding author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu, Sichuan, Peoples R China.
EM sunguanglu66@126.com; zhiqicheng@gmail.com; wuxiaohk@home.swjtu.edu.cn;
   qpeng@home.swjtu.edu.cn
RI Cheng, Zhi-Qi/ABD-1657-2020
OI Cheng, Zhi-Qi/0000-0002-1720-2085
FU National Natural Science Foundation of China [61373121, 61772436]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 61373121 and 61772436).
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   [Anonymous], 2012, AS C COMP VIS
   [Anonymous], 2012, P ACM INT C MULT
   [Anonymous], 2014, ARXIV14090575 CORR
   [Anonymous], 2013, P 3 ACM C INT C MULT
   Bossard Lukas, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P321, DOI 10.1007/978-3-642-37447-0_25
   Chen HZ, 2012, LECT NOTES COMPUT SC, V7574, P609, DOI 10.1007/978-3-642-33712-3_44
   Cui P., 2011, AAAI C ART INT
   Cui P, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P185
   Gao HJ, 2015, AAAI CONF ARTIF INTE, P1721
   He RN, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P507, DOI 10.1145/2872427.2883037
   Hu Y, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P129, DOI 10.1145/2733373.2806239
   Huang JS, 2015, IEEE I CONF COMP VIS, P1062, DOI 10.1109/ICCV.2015.127
   Jagadeesh V, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P1925, DOI 10.1145/2623330.2623332
   Jamali M, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P397
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang Meng, 2012, P 21 ACM INT C INFOR, P45
   Jiang SH, 2015, IEEE T MULTIMEDIA, V17, P907, DOI 10.1109/TMM.2015.2417506
   Kiapour MH, 2014, LECT NOTES COMPUT SC, V8689, P472, DOI 10.1007/978-3-319-10590-1_31
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Liang XD, 2016, IEEE T MULTIMEDIA, V18, P1175, DOI 10.1109/TMM.2016.2542983
   Liu S, 2014, IEEE T MULTIMEDIA, V16, P253, DOI 10.1109/TMM.2013.2285526
   Liu S, 2012, PROC CVPR IEEE, P3330, DOI 10.1109/CVPR.2012.6248071
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Ma H, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P203, DOI 10.1145/1571941.1571978
   McAuley J, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P43, DOI 10.1145/2766462.2767755
   Mnih A., 2007, ADV NEURAL INFORM PR, V20
   Nogueira K, 2016, MULTIMED TOOLS APPL, V75, P4083, DOI 10.1007/s11042-015-3087-2
   Qian XM, 2014, IEEE T KNOWL DATA EN, V26, P1763, DOI 10.1109/TKDE.2013.168
   Qian XM, 2013, NEUROCOMPUTING, V111, P144, DOI 10.1016/j.neucom.2012.12.021
   Resnick P., 1994, Transcending Boundaries, CSCW '94. Proceedings of the Conference on Computer Supported Cooperative Work, P175, DOI 10.1145/192844.192905
   Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI 10.1145/371920.372071
   Simo-Serra E, 2015, COMPUTER VISION PATT
   Sun GL, 2016, NEUROCOMPUTING, V213, P115, DOI 10.1016/j.neucom.2015.12.141
   Veit A, 2015, IEEE I CONF COMP VIS, P4642, DOI 10.1109/ICCV.2015.527
   Wang Xianwang., 2011, Proceedings of the 19th ACM International Conference on Multimedia, MM'11, P1353
   Wang Z, 2013, IEEE T MULTIMEDIA, V15, P698, DOI 10.1109/TMM.2012.2237022
   Yamaguchi K, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P773, DOI 10.1145/2647868.2654958
   Yamaguchi K, 2013, IEEE I CONF COMP VIS, P3519, DOI 10.1109/ICCV.2013.437
   Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101
   Yang Xiwang., 2012, P 18 ACM SIGKDD INT, P1267, DOI [10.1145/2339530.2339728, DOI 10.1145/2339530.2339728]
   Zhao B, 2016, IEEE T MULTIMEDIA, V18, P1111, DOI 10.1109/TMM.2016.2537783
NR 42
TC 25
Z9 27
U1 6
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 17731
EP 17754
DI 10.1007/s11042-017-5245-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900010
DA 2024-07-18
ER

PT J
AU Wang, HM
   Zhu, HZ
   Xue, P
   Zhu, XH
AF Wang, Hongmin
   Zhu, Hongzhao
   Xue, Ping
   Zhu, Xiaohui
TI RETRACTED: The resin lens flaw feature extraction and detection system
   based on data transmission security (Retracted article. See vol. 82, pg.
   4779, 2023)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Boundary tracking; Balanced binary search tree; Multi-region; Storage
   encryption; Data transmission
ID IOT; ALGORITHM
AB Data security and privacy have become a problem which people pay more attention to. In the process of feature extraction and detection of lens defects, the security of data transmission becomes more and more important. This paper according to the characteristics of the lens defect extraction method is studied and discussed through a single scan of the two boundary value of graphics and images, without the need to fill the region, does not need the help of chain codes statistical region number and boundary information. According to the established balanced binary search tree, the area and perimeter of each defect were calculated. This method works fast, and it needs only small amount of calculation; it can suppress noise better and accurate. This paper combines the detection of networking and information exchange, in order to ensure the normal lens defects in feature extraction efficiency. And comparing several encryption algorithms in the data transmission process, selecting the best storage and encryption technology to ensure data security and improve the security of the system.
C1 [Wang, Hongmin; Zhu, Hongzhao; Xue, Ping; Zhu, Xiaohui] Harbin Univ Sci & Technol, Harbin 150080, Heilongjiang, Peoples R China.
C3 Harbin University of Science & Technology
RP Wang, HM (corresponding author), Harbin Univ Sci & Technol, Harbin 150080, Heilongjiang, Peoples R China.
EM 13904810908@163.com
OI Zhu, Hongzhao/0000-0002-0973-3660
CR Abdelwahab MM, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, CONTROL, NETWORKING, ELECTRONICS AND EMBEDDED SYSTEMS ENGINEERING (ICCNEEE), P37, DOI 10.1109/ICCNEEE.2015.7381424
   Bovik AC, 2016, ESSENTIAL GUIDE IMAG, V48, pS106
   Chandrasekaran V, 2017, MATH PROGRAM, V161, P1, DOI 10.1007/s10107-016-0998-2
   Chang V, 2018, TECHNOL FORECAST SOC, V130, P57, DOI 10.1016/j.techfore.2017.11.002
   Chang V, 2016, IEEE T SERV COMPUT, V9, P138, DOI [10.1109/ISSNIP.2015.7106910, 10.1109/TSC.2015.2491281]
   Chen Y, 2016, OPTIK, V127, P900, DOI 10.1016/j.ijleo.2015.10.145
   Conti M, 2018, FUTURE GENER COMP SY, V78, P544, DOI 10.1016/j.future.2017.07.060
   Costarelli Danilo, 2015, Proceedings in Applied Mathematics and Mechanics, V15, P655, DOI 10.1002/pamm.201510317
   Farahani B, 2018, FUTURE GENER COMP SY, V78, P659, DOI 10.1016/j.future.2017.04.036
   Ghazisaidi N, 2012, IEEE T BROADCAST, V58, P440, DOI 10.1109/TBC.2012.2191692
   He X, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1447, DOI 10.1145/2588555.2588581
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kmiec M, 2015, OBJECT DETECTION SEC
   Kumar S., 2014, International Journal of Computer Science and Information Technologies, V5, P4492
   Kumara SV, 2017, INT J NET SEC APPL, V9, P29
   Lei Lin, 2008, Journal of National University of Defense Technology, V30, P64
   Liao D, 2017, CLUSTER COMPUT, V20, P1
   Liu LL, 1998, J INFRARED MILLIM W, V17, P386
   Lu Y, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, NETWORKING AND COMMUNICATIONS (ICNC), P418, DOI 10.1109/ICCNC.2015.7069380
   Moustafa Akram A., 2009, Journal of Computer Sciences, V5, P355, DOI 10.3844/jcssp.2009.355.362
   Ora P., 2015, P 2015 INT C COMP CO, P1, DOI DOI 10.1109/IC4.2015.7375655
   Poonia Vaibhav, 2015, 2015 International Conference on Advanced Computing and Communication Systems (ICACCS). Proceedings, P1, DOI 10.1109/ICACCS.2015.7324114
   Poulios K, 2015, COMPUT STRUCT, V153, P75, DOI 10.1016/j.compstruc.2015.02.027
   Qiyong Wang, 2015, Journal of Communications, V10, P192, DOI 10.12720/jcm.10.3.192-198
   Sohal AS, 2018, COMPUT SECUR, V74, P340, DOI 10.1016/j.cose.2017.08.016
   Sumengen B, 2015, SIGN PROC C 2005, P1
   Sun G, 2017, J NETW COMPUT APPL, V89, P3, DOI 10.1016/j.jnca.2016.10.011
   Tardieu F, 2014, CRITICAL REASSESSMEN, V4, P555
   Wang Wenying, 2010, Journal of Computer Aided Design & Computer Graphics, V22, P625, DOI 10.3724/SP.J.1089.2010.10624
   Wu Z., 2014, J. Lightw. Technol., V32, P4565
   Xie J-L, 2014, ELECTRON TECH SOFTW, V9, P119
   Yang Y, 2018, FUTURE GENER COMP SY, V86, P1437, DOI 10.1016/j.future.2018.01.003
   Yang Y, 2018, MULTIMED TOOLS APPL, V77, P9927, DOI 10.1007/s11042-017-4560-x
   Yeh JP, 2012, ADV MAT RES, V588-589, P974
   Zhang B, 2004, J INFRARED MILLIM W, V23, P441
   Zhong L, 2017, INT C AUD LANG IM PR, P131
NR 36
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18483
EP 18501
DI 10.1007/s11042-018-5774-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900045
DA 2024-07-18
ER

PT J
AU Wei, JG
   Ji, Y
   Zhang, JS
   Fang, Q
   Lu, WH
   Honda, K
   Lu, XG
AF Wei, Jianguo
   Ji, Yan
   Zhang, Jingshu
   Fang, Qiang
   Lu, Wenhuan
   Honda, Kiyoshi
   Lu, Xugang
TI Study of articulators' contribution and compensation during speech by
   articulatory speech recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DNN; Articulatory recognition; Articulators' contribution; Crucial
   level; Compensation
AB In this paper, the contributions of dynamic articulatory information were evaluated by using an articulatory speech recognition system. The Electromagnetic Articulographic dataset is relatively small and hard to be recorded compared with popular speech corpora used for modern speech study. We used articulatory data to study the contribution of each observation channel of vocal tracts in speech recognition by DNN framework. We also analyzed the recognition results of each phoneme according to speech production rules. The contribution rate of each articulator can be considered as the crucial level of each phoneme in speech production. Furthermore, the results indicate that the contribution of each observation point is not relevant to a specific method. The tendency of a contribution of each sensor is identical to the rules of Japanese phonology. In this work, we also evaluated the compensation effect between different channels. We discovered that crucial points are hard to be compensated for compared with non-crucial points. The proposed method can help us identify the crucial points of each phoneme during speech. The results of this paper can contribute to the study of speech production and articulatory-based speech recognition.
C1 [Wei, Jianguo; Lu, Wenhuan] Tianjin Univ, Sch Comp Software, Tianjin, Peoples R China.
   [Ji, Yan; Zhang, Jingshu; Honda, Kiyoshi] Tianjin Univ, Sch Comp Sci & Technol, Tianjin, Peoples R China.
   [Fang, Qiang] Chinese Acad Social Sci, Beijing, Peoples R China.
   [Lu, Xugang] NICT, Tokyo, Japan.
C3 Tianjin University; Tianjin University; Chinese Academy of Social
   Sciences; National Institute of Information & Communications Technology
   (NICT) - Japan
RP Lu, WH (corresponding author), Tianjin Univ, Sch Comp Software, Tianjin, Peoples R China.
EM jianguo@tju.edu.cn; tjujiyan@tju.edu.cn; jingshu@tju.edu.cn;
   fangqiang@cass.org.cn; wenhuan@tju.edu.cn; khonda@sannet.ne.jp;
   xugang.lu@nict.go.jp
RI Wei, Jianguo/KBA-3200-2024
OI Wei, Jianguo/0000-0002-8964-9759
FU National Natural Science Foundation of China [61471259, 61233009]; NSFC
   of Tianjin [16JCZDJC35400]
FX This work was supported in part by grants from the National Natural
   Science Foundation of China (General Program No. 61471259, and Key
   Program No. 61233009) and in part by NSFC of Tianjin (No.
   16JCZDJC35400).
CR Akamatsu T., 1997, Japanese phonetics: theory and practice
   [Anonymous], 2011, IEEE 2011 WORKSHOP A
   Chen Qi, 2013, Journal of Information Engineering University, V14, P569, DOI 10.3969/j.issn.1671-0673.2013.05.011
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Dang J, 2001, ACOUST SCI TECHNOL, V22, P6
   Dang J, 2003, P 15 INT C PHON SCI, P731
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Honda K, 2008, PHYSL PROCES SPEECH
   Honda K, 2016, J ACOUST SOC AM, V139, P2192
   Ito Junko., 1995, HDB PHONOLOGICAL THE, P817
   Lu X, 2005, CHINESE J ACOUSTICS, V3, P271
   Lu X, 2004, 18 INT C AC ICA2004, P3499
   Okada H., 1991, Journal of the International Phonetic Association, V21, P94, DOI DOI 10.1017/S002510030000445X
   Riney TJ, 2007, J PHONETICS, V35, P439, DOI 10.1016/j.wocn.2006.01.002
   Tsuchida A, 2001, J EAST ASIAN LINGUIS, V10, P225, DOI 10.1023/A:1011221225072
   Zhang JS, 2015, ASIAPAC SIGN INFO PR, P217, DOI 10.1109/APSIPA.2015.7415507
NR 17
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18849
EP 18864
DI 10.1007/s11042-018-5667-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900064
DA 2024-07-18
ER

PT J
AU Amraee, S
   Vafaei, A
   Jamshidi, K
   Adibi, P
AF Amraee, Somaieh
   Vafaei, Abbas
   Jamshidi, Kamal
   Adibi, Peyman
TI Anomaly detection and localization in crowded scenes using connected
   component analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Crowded scenes; Connected components; multivariate
   Gaussian model; Optical flow
ID HISTOGRAMS; FLOW
AB This paper presents a new method for detecting abnormal events in the surveillance systems. This method does not employ object detection or tracking and thus it does not fail in the crowded scenes. In the first step of proposed method, the appropriate cell size is determined by calculating the prevalent size of the connected components. Then, the redundant information is eliminated and the important regions are extracted from training data. This preprocessing significantly reduces the volume of training data in the learning phase. Next, using the HOG descriptors and a multivariate Gaussian model, the appearance anomalies i.e. the abnormality in terms of physical characteristics is detected. Besides that, a simple algorithm is provided to detect the abnormal motion using the average optical flow of the cells. Experimental results on the UCSD-PED2 datasets show that the proposed method can reliably detect abnormal events in video sequences, outperforming the current state-of-the-art methods.
C1 [Amraee, Somaieh; Vafaei, Abbas; Jamshidi, Kamal; Adibi, Peyman] Univ Isfahan, Fac Comp Engn, Esfahan, Iran.
C3 University of Isfahan
RP Vafaei, A (corresponding author), Univ Isfahan, Fac Comp Engn, Esfahan, Iran.
EM abbas_vafaei@eng.ui.ac.ir
RI Adibi, Peyman/O-2421-2019; Sedeh, Peyman Adibi/AAJ-4582-2020
OI Sedeh, Peyman Adibi/0000-0001-6411-5235; Vafaei,
   Abbas/0000-0001-6535-1272
CR Albusac J, 2009, INT J PATTERN RECOGN, V23, P1223, DOI 10.1142/S0218001409007612
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bertini M, 2012, COMPUT VIS IMAGE UND, V116, P320, DOI 10.1016/j.cviu.2011.09.009
   Biswas S, 2015, MULTIMED TOOLS APPL, V74, P11099, DOI 10.1007/s11042-014-2219-4
   Calderara S, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P141, DOI 10.1109/AVSS.2007.4425300
   Cheng KW, 2015, IEEE T IMAGE PROCESS, V24, P5288, DOI 10.1109/TIP.2015.2479561
   Chengcui Zhang, 2010, Journal of Multimedia, V5, P310, DOI 10.4304/jmm.5.4.310-321
   Cong Y, 2013, IEEE T INF FOREN SEC, V8, P1590, DOI 10.1109/TIFS.2013.2272243
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Diamantopoulos G, 2005, REAL-TIME IMAGING, V11, P233, DOI 10.1016/j.rti.2005.02.002
   Duque D, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING, VOLS 1 AND 2, P362, DOI 10.1109/CIDM.2007.368897
   Fang ZJ, 2016, MULTIMED TOOLS APPL, V75, P14617, DOI 10.1007/s11042-016-3316-3
   Kim J, 2009, PROC CVPR IEEE, P2913
   Li N, 2015, INT J PATTERN RECOGN, V29, P1
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Makantasis K, 2012, LECT NOTES COMPUT SC, V7585, P81, DOI 10.1007/978-3-642-33885-4_9
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Nan Dong, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P80, DOI 10.1109/AVSS.2010.61
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Piciarelli C, 2008, IEEE T CIRC SYST VID, V18, P1544, DOI 10.1109/TCSVT.2008.2005599
   Reddy V., 2011, Computer Vision and Pattern Recognition Workshops (CVPRW), 2011 IEEE Computer Society Conference on, P55
   Roshtkhari MJ, 2013, COMPUT VIS IMAGE UND, V117, P1436, DOI 10.1016/j.cviu.2013.06.007
   Sodemann AA, 2012, IEEE T SYST MAN CY C, V42, P1257, DOI 10.1109/TSMCC.2012.2215319
   Tang SY, 2014, INT J COMPUT VISION, V110, P58, DOI 10.1007/s11263-013-0664-6
   Vallejo D, 2009, EXPERT SYST APPL, V36, P10503, DOI 10.1016/j.eswa.2009.01.034
   Varadarajan Jagannadan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1338, DOI 10.1109/ICCVW.2009.5457456
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Xiang T, 2008, IEEE T PATTERN ANAL, V30, P893, DOI 10.1109/TPAMI.2007.70731
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Xu D, 2014, NEUROCOMPUTING, V143, P144, DOI 10.1016/j.neucom.2014.06.011
   Zaharescu A, 2010, LECT NOTES COMPUT SC, V6311, P563, DOI 10.1007/978-3-642-15549-9_41
   Zhang T, 2016, MULTIMED TOOLS APPL, V75, P7327, DOI 10.1007/s11042-015-2648-8
NR 35
TC 24
Z9 27
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14767
EP 14782
DI 10.1007/s11042-017-5061-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200013
DA 2024-07-18
ER

PT J
AU Choudhury, SK
   Sa, PK
   Padhy, RP
   Sharma, S
   Bakshi, S
AF Choudhury, Suman Kumar
   Sa, Pankaj Kumar
   Padhy, Ram Prasad
   Sharma, Saurav
   Bakshi, Sambit
TI Improved pedestrian detection using motion segmentation and silhouette
   orientation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian detection; Video surveillance; Background subtraction;
   Feature extraction; Classification; Golden ratio
ID MOVING OBJECT DETECTION; BACKGROUND SUBTRACTION; COLOR
AB Pedestrians are the most interesting as well as vulnerable entity from both safety and security perspective in the field of video surveillance. In this article, we present a framework to detect pedestrians across a stationary camera view. Our propositions thrust upon developing a motion segmentation module and a feature extraction module for human localization. In the first stage, a background subtraction method is proposed to collect the initial set of moving objects in the processed frame. A shape descriptor is then presented to encode the pattern of human body in terms of silhouette orientation histogram. Moreover, the principle of Golden ratio is employed to formulate a part-based detector to alleviate the problem with occlusion. Both the above modules are first validated separately, and then as a unified unit, using various statistical measures. The proposed background subtraction module is simulated on twenty video clips taken from three benchmark datasets. The efficacy of our shape descriptor is validated on various image-windows taken from three publicly available datasets. The unified framework including both the modules are tested on two standard surveillance datasets. All the experimental results are uploaded at: https://sites.google.com/
C1 [Choudhury, Suman Kumar; Sa, Pankaj Kumar; Padhy, Ram Prasad; Sharma, Saurav; Bakshi, Sambit] Natl Inst Technol, Dept Comp Sci & Engn, Rourkela 769008, Odisha, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Choudhury, SK (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Rourkela 769008, Odisha, India.
EM sumanchoudhury.nitr@gmail.com; pankajksa@nitrkl.ac.in;
   ramprasad.nitr@gmail.com; srv902@gmail.com; bakshisambit@nitrkl.ac.in
RI K, Pankaj/A-9362-2017; Gandhiraman, Ram P./B-7004-2013; Bakshi,
   Sambit/JDC-3355-2023
OI Bakshi, Sambit/0000-0002-6107-114X; Sa, Pankaj/0000-0002-8362-3873;
   PATURI, RAM PRASAD/0000-0002-1233-6930
FU Science and Engineering Research Board (SERB), Department of Science &
   Technology, Government of India [SB/FTP/ETA-0059/2014]
FX This work is supported by Grant Number SB/FTP/ETA-0059/2014 by Science
   and Engineering Research Board (SERB), Department of Science &
   Technology, Government of India.
CR [Anonymous], INT C COMP VIS SYST
   [Anonymous], 2013, ADV MECH ENG
   [Anonymous], 1999, IEEE COMP SOC C COMP
   [Anonymous], IEEE INT C IM PROC
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2009, P BRIT MACH VIS C
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2012, P IEEE C COMP VIS PA
   [Anonymous], 2010, P BMVC
   [Anonymous], 2014, P IEEE C COMP VIS PA
   [Anonymous], 2012, AS C COMP VIS
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Benenson R, 2015, LECT NOTES COMPUT SC, V8926, P613, DOI 10.1007/978-3-319-16181-5_47
   Brown LM, 2014, INT C PATT RECOG, P2239, DOI 10.1109/ICPR.2014.389
   Cho HG, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P1035, DOI 10.1109/IVS.2012.6232264
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Errami M, 2016, I C COMP GRAPH IM VI, P156, DOI 10.1109/CGiV.2016.38
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Feidie Liang, 2012, Advances in Multimedia Information Processing - PCM 2012. 13th Pacific-Rim Conference on Multimedia. Proceedings, P811, DOI 10.1007/978-3-642-34778-8_76
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Felzenszwalb PedroF., 2008, IEEE C COMPUTER VISI
   Fernandez-Sanchez EJ, 2013, SENSORS-BASEL, V13, P8895, DOI 10.3390/s130708895
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   Hati KK, 2013, IEEE SIGNAL PROC LET, V20, P759, DOI 10.1109/LSP.2013.2263800
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Hong-Son Vu, 2016, 2016 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P1, DOI 10.1109/ICCE-TW.2016.7521014
   Hubert M, 2008, COMPUT STAT DATA AN, V52, P5186, DOI 10.1016/j.csda.2007.11.008
   Jeon H, 2008, PROC INT C TOOLS ART, P241, DOI 10.1109/ICTAI.2008.9
   Ji XF, 2010, IEEE T SYST MAN CY C, V40, P13, DOI 10.1109/TSMCC.2009.2027608
   Li L., 2003, MULTIMEDIA 03 P 11 A, P2, DOI DOI 10.1145/957013.957017
   Li LH, 2016, IEEE T CIRC SYST VID, V26, P278, DOI 10.1109/TCSVT.2014.2380195
   Lin Z, 2008, LECT NOTES COMPUT SC, V5305, P423, DOI 10.1007/978-3-540-88693-8_31
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Maddalena L, 2010, NEURAL COMPUT APPL, V19, P179, DOI 10.1007/s00521-009-0285-8
   Maji S., 2008, IEEE C COMPUTER VISI, P1
   McHugh JM, 2009, IEEE SIGNAL PROC LET, V16, P390, DOI 10.1109/LSP.2009.2016447
   Meng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3401, DOI 10.1109/CVPR.2011.5995698
   Munder S, 2006, IEEE T PATTERN ANAL, V28, P1863, DOI 10.1109/TPAMI.2006.217
   Paul M, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-11
   Piccardi M, 2004, IEEE IMAGE PROC, P3399
   Prioletti A, 2013, IEEE T INTELL TRANSP, V14, P1346, DOI 10.1109/TITS.2013.2262045
   Ren J, 2016, MULTIDIM SYST SIGN P, V27, P1007, DOI 10.1007/s11045-016-0428-x
   Rodríguez P, 2013, IEEE IMAGE PROC, P69, DOI 10.1109/ICIP.2013.6738015
   Schwartz WR, 2009, IEEE I CONF COMP VIS, P24, DOI 10.1109/ICCV.2009.5459205
   Shaikh SH, 2014, SPRINGERBRIEF COMPUT, P15, DOI 10.1007/978-3-319-07386-6_3
   St-Charles PL, 2015, IEEE WINT CONF APPL, P990, DOI 10.1109/WACV.2015.137
   Sulman N, 2008, INT C PATT RECOG, P1850
   Walk S, 2010, PROC CVPR IEEE, P1030, DOI 10.1109/CVPR.2010.5540102
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wang Y., 2014, P IEEE C COMP VIS PA, P387, DOI 10.1109/ICIP40778.2020.9190887
   Wang Y., 2016, Pattern Recognition Letters
   Wojek C, 2008, LECT NOTES COMPUT SC, V5096, P82, DOI 10.1007/978-3-540-69321-5_9
   Wu MJ, 2010, AEU-INT J ELECTRON C, V64, P739, DOI 10.1016/j.aeue.2009.05.004
   Xu JL, 2014, IEEE T INTELL TRANSP, V15, P2121, DOI 10.1109/TITS.2014.2310138
   Yao SH, 2015, NEUROCOMPUTING, V151, P1006, DOI 10.1016/j.neucom.2014.08.080
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 60
TC 8
Z9 9
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13075
EP 13114
DI 10.1007/s11042-017-4933-1
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900002
DA 2024-07-18
ER

PT J
AU Li, JF
   Wang, HX
   Wu, T
   Sun, XM
   Qian, Q
AF Li, Jin-feng
   Wang, Hong-Xia
   Wu, Tao
   Sun, Xing-ming
   Qian, Qing
TI Norm ratio-based audio watermarking scheme in DWT domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio watermarking; Norm ratio; Optimized scaling; Discrete wavelet
   transform
ID SINGULAR-VALUE DECOMPOSITION; DISCRETE WAVELET TRANSFORM; BLIND; DCT;
   SVD
AB In order to reach a balance between robustness, imperceptibility, and data payload, a novel blind audio watermarking scheme is proposed using the norm ratio of approximate coefficients in discrete wavelet domain (DWT). A chaotic sequence generated by Tent map is used to encrypt the watermark image and enhance the security of watermarking system. Firstly the original audio signal is segmented into non-overlapping frames and DWT is applied to each frame. Then, the approximate components are divided into two parts, and the norm ratio is calculated and modulated to embed the watermarks. Finally, the approximate components are scaled by optimizing the quality of the watermarked audio. Experimental results indicate that the proposed watermarking scheme is robust against different common attacks, such as noise addition, resampling, re-quantization, MP3 compression and amplitude scaling. The comparison analysis shows that the proposed scheme has high data payload and provides superior performance compared to the state-of-the-art watermarking schemes.
C1 [Li, Jin-feng; Wang, Hong-Xia; Qian, Qing] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Sichuan, Peoples R China.
   [Wu, Tao] Beijing Univ Posts & Telecommun, Sch Informat Sci & Commun Engn, Beijing 100876, Peoples R China.
   [Sun, Xing-ming] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Southwest Jiaotong University; Beijing University of Posts &
   Telecommunications; Nanjing University of Information Science &
   Technology
RP Li, JF (corresponding author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Sichuan, Peoples R China.
EM jflee85@163.com; hxwang@home.swjtu.edu.cn; wootao@foxmail.com;
   sunnudt@163.com; qianqing_swjtu@163.com
RI Wang, Hongxia/AAE-2135-2022; li, jinfeng/GVS-5425-2022; Wu,
   Tao/V-6689-2019; Sun, Xingming/AAD-1866-2019
OI Wu, Tao/0000-0002-9066-8455; 
FU National Natural Science Foundation of China (NSFC) [U1536110, 61373180]
FX This work is supported in part by the National Natural Science
   Foundation of China (NSFC) under the grant No. U1536110, 61373180.
CR Ali A.-H., 2010, EUR J SCI RES, V39, P6
   Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   Bhat KV, 2010, DIGIT SIGNAL PROCESS, V20, P1547, DOI 10.1016/j.dsp.2010.02.006
   Chen ST, 2013, DIGIT SIGNAL PROCESS, V23, P971, DOI 10.1016/j.dsp.2012.12.013
   Dhar PK, 2015, J INF SECUR APPL, V20, P74, DOI 10.1016/j.jisa.2014.10.007
   Erçelebi E, 2009, DIGIT SIGNAL PROCESS, V19, P265, DOI 10.1016/j.dsp.2008.11.007
   Fan MQ, 2011, DIGIT SIGNAL PROCESS, V21, P110, DOI 10.1016/j.dsp.2010.09.003
   Fan MQ, 2009, COMPUT ELECTR ENG, V35, P506, DOI 10.1016/j.compeleceng.2008.12.004
   Faragallah OS, 2013, AEU-INT J ELECTRON C, V67, P189, DOI 10.1016/j.aeue.2012.07.010
   Gupta G, 2009, LECT NOTES COMPUT SC, V5905, P222, DOI 10.1007/978-3-642-10772-6_17
   Hu HT, 2014, DIGIT SIGNAL PROCESS, V31, P115, DOI 10.1016/j.dsp.2014.04.014
   Jeon Cheol, 2012, P 2012 ACM RES APPL, P333, DOI DOI 10.1145/2401603.2401675
   Khaldi K, 2013, IEEE T AUDIO SPEECH, V21, P675, DOI 10.1109/TASL.2012.2227733
   Lei BY, 2011, SIGNAL PROCESS, V91, P1973, DOI 10.1016/j.sigpro.2011.03.001
   Liu JH, 2012, CIRC SYST SIGNAL PR, V31, P797, DOI 10.1007/s00034-011-9331-8
   Megías D, 2010, SIGNAL PROCESS, V90, P3078, DOI 10.1016/j.sigpro.2010.05.012
   Wang XK, 2013, SIGNAL PROCESS, V93, P913, DOI 10.1016/j.sigpro.2012.11.003
   Wu SQ, 2005, IEEE T BROADCAST, V51, P69, DOI 10.1109/TBC.2004.838265
NR 18
TC 13
Z9 14
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14481
EP 14497
DI 10.1007/s11042-017-5024-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200001
DA 2024-07-18
ER

PT J
AU Li, WJ
   Liang, JZ
AF Li, Wenjing
   Liang, Jiuzhen
TI Adaptive face representation via class-specific and intra-class
   variation dictionaries for recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse representation; Class-specific dictionary; Intra-class variation
   dictionary
ID IMAGE SUPERRESOLUTION; CLASSIFICATION; EIGENFACES; ALGORITHM
AB Face recognition has attracted extensive interests due to its wide applications. However, there are many challenges in the real world scenario. For example, relatively few samples are available for training. Face images collected from surveillance cameras may consist of complex variations (e.g. illumination, expression, occlusion and pose). To address these challenges, in this paper we propose learning class-specific and intra-class variation dictionaries separately. Specifically, we first develop a discriminative class-specific dictionary amplifying the differences between training classes. We impose a constraint on sparse coefficients, which guarantees the sparse representation coefficients having small within-class scatter and large between-class scatter. Moreover, we introduce a new intra-class variation dictionary based on the assumption that similar variations from different classes may share some common features. The intra-class variation dictionary not only captures the inner-relationship of variations, but also addresses the limitation of the manually designed dictionaries that are person-specific. Finally, we apply the combined dictionary to adaptively represent face images. Experiments conducted on the AR, CMU-PIE, FERET and Extended Yale B databases show the effectiveness of the proposed method.
C1 [Li, Wenjing] Chinese Acad Sci, High Field Magnet Lab, Hefei, Anhui, Peoples R China.
   [Li, Wenjing] Univ Sci & Technol China, Hefei, Anhui, Peoples R China.
   [Liang, Jiuzhen] Changzhou Univ, 1 Gehu Rd, Changzhou 213164, Peoples R China.
C3 Chinese Academy of Sciences; Hefei Institutes of Physical Science, CAS;
   Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Changzhou University
RP Liang, JZ (corresponding author), Changzhou Univ, 1 Gehu Rd, Changzhou 213164, Peoples R China.
EM jzliang@cczu.edu.cn
RI Liang, Jiuzhen/HJG-9384-2022
FU National Natural Science Foundation of China [61170121]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61170121).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2009, COMPUTATION
   [Anonymous], NEURAL COMPUT APPL
   [Anonymous], 2016, IEEE T CYBERNETICS
   [Anonymous], 2005, P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.2005.377
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Benavente R, 1998, 24 COMP VIS CTR
   Cai S, 2014, SUPPORT VECTOR GUIDE
   Cai SJ, 2016, PROC CVPR IEEE, P2950, DOI 10.1109/CVPR.2016.322
   Castrodad A, 2012, INT J COMPUT VISION, V100, P1, DOI 10.1007/s11263-012-0534-7
   Chen C, 2014, REMOTE SENS-BASEL, V6, P5795, DOI 10.3390/rs6065795
   Chen C, 2011, CONF REC ASILOMAR C, P1193, DOI 10.1109/ACSSC.2011.6190204
   Deng WH, 2013, PROC CVPR IEEE, P399, DOI 10.1109/CVPR.2013.58
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gordo A, 2015, PROC CVPR IEEE, P2956, DOI 10.1109/CVPR.2015.7298914
   He X. F., 2005, P ADV NEUR INF PROC
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P27, DOI 10.1109/TMM.2016.2601020
   Jin TS, 2015, NEUROCOMPUTING, V154, P245, DOI 10.1016/j.neucom.2014.11.067
   Koh KM, 2007, J MACH LEARN RES, V8, P1519
   Li WJ, 2015, IEEE IMAGE PROC, P2596, DOI 10.1109/ICIP.2015.7351272
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu XB, 2014, IEEE T IMAGE PROCESS, V23, P2159, DOI 10.1109/TIP.2013.2297027
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70
   Lu JW, 2010, IEEE T SYST MAN CY B, V40, P958, DOI 10.1109/TSMCB.2009.2032926
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Sprechmann P, 2010, INT CONF ACOUST SPEE, P2042, DOI 10.1109/ICASSP.2010.5494985
   Tian D.P., 2013, International Journal of Multimedia and Ubiquitous Engineering, V8, P385
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112
   Wang HR, 2012, PATTERN RECOGN, V45, P3902, DOI 10.1016/j.patcog.2012.04.024
   Wang HX, 2014, PROC INT C TOOLS ART, P853, DOI 10.1109/ICTAI.2014.131
   Wang M, 2016, PATTERN RECOGN LETT, V83, P349, DOI 10.1016/j.patrec.2016.05.028
   Wang N, 2013, P ADV NEURAL INFORM
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang M, 2015, EUR C COMP VIS, P448
   Yang M, 2011, INT C COMP VIS, V24
   Zhang JG, 2017, MULTIMED TOOLS APPL, V76, P4227, DOI 10.1007/s11042-016-3496-x
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, P1713, DOI 10.1109/TIP.2016.2531289
   Zhou N, 2012, PROC CVPR IEEE, P3490, DOI 10.1109/CVPR.2012.6248091
   Zhou ZH, 2009, IEEE I CONF COMP VIS, P1050, DOI 10.1109/ICCV.2009.5459383
NR 49
TC 0
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14783
EP 14802
DI 10.1007/s11042-017-5062-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200014
DA 2024-07-18
ER

PT J
AU Wan, L
   Xiao, Y
   Dou, N
   Leung, CS
   Lai, YK
AF Wan, Liang
   Xiao, Yi
   Dou, Ning
   Leung, Chi-Sing
   Lai, Yu-Kun
TI Scribble-based gradient mesh recoloring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gradient mesh; Recoloring by scribble; Control net; Scribble point set
ID LOCAL COLOR TRANSFER
AB Previous gradient mesh recoloring methods usually have dependencies on an additional reference image and the rasterized gradient mesh. To circumvent such dependencies, we propose a user scribble-based recoloring method, in which users are allowed to annotate gradient meshes with a few color scribbles. Our approach builds an auxiliary mesh from gradient meshes, namely control net, by taking both colors and local color gradients at mesh points into account. We then develop an extended chrominance blending method to propagate the user specified colors over the control net. The recolored gradient mesh is finally reconstructed from the recolored control net. Experiments validate the effectiveness of our approach on multiple gradient meshes. Compared with various alternative solutions, our method has no color bleedings nor sampling artifacts, and can achieve fast performance.
C1 [Wan, Liang] Tianjin Univ, Sch Comp Software, Tianjin, Peoples R China.
   [Dou, Ning] Tianjin Univ, Tianjin, Peoples R China.
   [Xiao, Yi] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Hunan, Peoples R China.
   [Leung, Chi-Sing] City Univ Hong Kong, Dept Elect Engn, Kowloon, Hong Kong, Peoples R China.
   [Lai, Yu-Kun] Cardiff Univ, Sch Comp Sci & Informat, Visual Comp, Cardiff, S Glam, Wales.
C3 Tianjin University; Tianjin University; Hunan University; City
   University of Hong Kong; Cardiff University
RP Xiao, Y (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Hunan, Peoples R China.
EM lwan@tju.edu.cn; yixiao_csee@hnu.edu.cn
RI Lai, Yu-Kun/D-2343-2010
FU NSFC from PRC [61572354, 61502158]; GRF from Hong Kong [CityU 11259516];
   Fundamental Research Funds for the Central Universities [531107040842];
   Hunan NSF [2017JJ3042]
FX The authors want to thank the reviewers for their valuable suggestions.
   The work is supported by NSFC from PRC (Project Num.:61572354,
   61502158), GRF from Hong Kong (Project Num.:CityU 11259516), Fundamental
   Research Funds for the Central Universities (Project Num.:
   531107040842), and Hunan NSF (Project Num.:2017JJ3042).
CR Abadpour A, 2007, J VIS COMMUN IMAGE R, V18, P15, DOI 10.1016/j.jvcir.2006.08.001
   An XB, 2010, COMPUT GRAPH FORUM, V29, P263, DOI 10.1111/j.1467-8659.2009.01595.x
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2009, HIGHSIDE
   Drew MS, 2008, IEEE IMAGE PROC, P457, DOI 10.1109/ICIP.2008.4711790
   FERGUSON J, 1964, J ACM, V11, P221, DOI 10.1145/321217.321225
   Horiuchi T, 2005, THIRTEENTH COLOR IMAGING CONFERENCE, FINAL PROGRAM AND PROCEEDINGS, P245
   Ironi R., 2005, RENDERING TECHNIQUES, P201
   Kawulok M, 2011, ADV INTEL SOFT COMPU, V95, P269
   Kawulok M, 2010, IEEE IMAGE PROC, P405, DOI 10.1109/ICIP.2010.5653544
   Lai YK, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531391
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Liu XP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409105
   Luan Q, 2007, P EUR S REND EUR
   Miao Z, 2016, MULTIMED TOOLS APPL, P1
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Sapiro Guillermo., 2005, IEEE INT C IMAGE PRO, P698
   Seo S, 2013, MULTIMED TOOLS APPL, V64, P293, DOI 10.1007/s11042-012-1024-1
   Su Z., 2012, P 20 ACM INT C MULT, P753, DOI [10.1145/2393347.2396304, DOI 10.1145/2393347.2396304]
   Su Z, 2014, IEEE T MULTIMEDIA, V16, P988, DOI 10.1109/TMM.2014.2305914
   Sun J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239462
   Tai YW, 2005, PROC CVPR IEEE, P747
   Wen CL, 2008, COMPUT GRAPH FORUM, V27, P1765, DOI 10.1111/j.1467-8659.2008.01321.x
   Xiao Y, 2015, COMPUT GRAPH FORUM, V34, P123, DOI 10.1111/cgf.12524
   Xiao Y, 2013, IEEE T MULTIMEDIA, V15, P549, DOI 10.1109/TMM.2012.2233725
   Yao C, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3582139
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
   Yi-Chin Huang, 2005, 13th Annual ACM International Conference on Multimedia, P351, DOI 10.1145/1101149.1101223
NR 28
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13753
EP 13771
DI 10.1007/s11042-017-4987-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900031
DA 2024-07-18
ER

PT J
AU Zhou, ZP
   Zhao, XX
   Zhu, SW
AF Zhou, Zhiping
   Zhao, Xiaoxiao
   Zhu, Shuwei
TI K-harmonic means clustering algorithm using feature weighting for color
   image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE K-harmonic means; Color image segmentation; Feature weighting;
   Homogeneity; Feature group
ID LOCAL INFORMATION; SEARCH
AB This paper mainly proposes K-harmonic means (KHM) clustering algorithms using feature weighting for color image segmentation. In view of the contribution of features to clustering, feature weights which can be updated automatically during the clustering procedure are introduced to calculate the distance between each pair of data points, hence the improved versions of KHM and fuzzy KHM are proposed. Furthermore, the Lab color space, local homogeneity and texture are utilized to establish the feature vector to be more applicable for color image segmentation. The feature group weighting strategy is introduced to identify the importance of different types of features. Experimental results demonstrate the proposed feature group weighted KHM-type algorithms can achieve better segmentation performances, and they can effectively distinguish the importance of different features to clustering.
C1 [Zhou, Zhiping; Zhao, Xiaoxiao] Jiangnan Univ, Minist Educ, Engn Res Ctr Internet Things Technol Applicat, Wuxi 214122, Peoples R China.
   [Zhu, Shuwei] Tongji Univ, Coll Elect & Informat Engn, Shanghai 201804, Peoples R China.
C3 Jiangnan University; Tongji University
RP Zhou, ZP (corresponding author), Jiangnan Univ, Minist Educ, Engn Res Ctr Internet Things Technol Applicat, Wuxi 214122, Peoples R China.
EM zzp@jiangnan.edu.cn; 6151905019@vip.jiangnan.edu.cn; zswjiang@163.com
OI Zhao, Xiaoxiao/0000-0003-3578-0089
FU National Natural Science Foundation of China [61373126]; Fundamental
   Research Funds for the Central Universities of China [JUSRP51510]
FX This research is supported by the National Natural Science Foundation of
   China (Grant No. 61373126) and the Fundamental Research Funds for the
   Central Universities of China (Grant No. JUSRP51510).
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Alguwaizani A, 2011, APPL MATH MODEL, V35, P2688, DOI 10.1016/j.apm.2010.11.032
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Carrizosa E, 2015, J GLOBAL OPTIM, V63, P427, DOI 10.1007/s10898-014-0175-1
   Chen XJ, 2012, PATTERN RECOGN, V45, P434, DOI 10.1016/j.patcog.2011.06.004
   Cheng HD, 2000, IEEE T IMAGE PROCESS, V9, P2071, DOI 10.1109/83.887975
   Gan GJ, 2015, PATTERN RECOGN, V48, P3703, DOI 10.1016/j.patcog.2015.05.016
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Huang JZX, 2005, IEEE T PATTERN ANAL, V27, P657, DOI 10.1109/TPAMI.2005.95
   Huang XH, 2014, IEEE T NEUR NET LEAR, V25, P1433, DOI 10.1109/TNNLS.2013.2293795
   Hung CH, 2013, APPL MATH MODEL, V37, P10123, DOI 10.1016/j.apm.2013.05.052
   Jiang H, 2010, EXPERT SYST APPL, V37, P8679, DOI 10.1016/j.eswa.2010.06.061
   Kumar S, 2015, FRONT PLANT SCI, V6, DOI 10.3389/fpls.2015.00078
   Li Q, 2007, IET IMAGE PROCESS, V1, P156, DOI 10.1049/iet-ipr:20050320
   Liu N, 2013, INT J MACH LEARN CYB, V4, P75, DOI 10.1007/s13042-012-0077-9
   Sag T, 2015, APPL SOFT COMPUT, V34, P389, DOI 10.1016/j.asoc.2015.05.016
   Tan KS, 2013, APPL SOFT COMPUT, V13, P2017, DOI 10.1016/j.asoc.2012.11.038
   Wu XH, 2015, APPL MATH MODEL, V39, P3398, DOI 10.1016/j.apm.2014.11.041
   Xing HJ, 2014, INFORM SCIENCES, V267, P1, DOI 10.1016/j.ins.2014.01.033
   Yang FQ, 2009, EXPERT SYST APPL, V36, P9847, DOI 10.1016/j.eswa.2009.02.003
   Yeh WC, 2016, NEUROCOMPUTING, V173, P1720, DOI 10.1016/j.neucom.2015.09.045
   ZHANG B, 2000, GEN K HARMONIC MEANS
   Zhou ZP, 2015, LECT NOTES COMPUT SC, V9243, P140, DOI 10.1007/978-3-319-23862-3_14
NR 24
TC 12
Z9 13
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15139
EP 15160
DI 10.1007/s11042-017-5096-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200032
DA 2024-07-18
ER

PT J
AU Yu, D
   Wu, XJ
AF Yu, Dan
   Wu, Xiao-Jun
TI 2DPCANet: a deep leaning network for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Deep learning; 2DPCA; ELM
ID 2-DIMENSIONAL PCA; REPRESENTATION; TUTORIAL
AB This paper proposes a two-dimensional principal component analysis network (2DPCANet), which is a novel deep learning network for face recognition. In our architecture, 2DPCA is employed to learn the filters of multistage layers, and then we exploit binary hashing and the block-wise histograms to generate the local features. Support vector machine (SVM) and extreme learning machine (ELM) are adopted as the classifier. The experimental results obtained on the facial database YALE, XM2VTS, AR, LFW-a, FERET and Extended Yale B show that the recognition performance of 2DPCANet is superior to other reported methods. Another interesting discovery on ELM classifier is that the advantage of ELM being simple and fast will disappear when it is applied to large databases.
C1 [Yu, Dan; Wu, Xiao-Jun] Jiangnan Univ, Sch Internet Things Engn, 1800 Lihu Ave, Wuxi 214122, Peoples R China.
C3 Jiangnan University
RP Wu, XJ (corresponding author), Jiangnan Univ, Sch Internet Things Engn, 1800 Lihu Ave, Wuxi 214122, Peoples R China.
EM wu_xiaojun@jiangnan.edu.cn
FU National Natural Science Foundation of China [61373055, 61672265];
   Industry Project of Provincial Department of Education of Jiangsu
   Province [JH10-28]; Natural Science Foundation of Jiangsu Province,
   China [BK20151358]
FX The paper is supported by the National Natural Science Foundation of
   China (Grant No. 61373055, 61672265), Industry Project of Provincial
   Department of Education of Jiangsu Province (Grant No. JH10-28), and
   Natural Science Foundation of Jiangsu Province, China (Grant No.
   BK20151358).
CR [Anonymous], 2000, An Introduction to Support Vector Machines and Other Kernel-Based Learning Methods by Nello Christianini and John Shawe-Taylor
   [Anonymous], COMP VIS PATT REC CV
   [Anonymous], 2004, NEUR NETW 2004 P 200
   [Anonymous], 2 INT C AUD VID BAS
   [Anonymous], 2013, Caffe: An open source convolutional architecture for fast feature embedding
   Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Feng ZY, 2015, NEUROCOMPUTING, V157, P11, DOI 10.1016/j.neucom.2015.01.043
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977
   Jia ZH, 2015, COMM COM INF SC, V547, P323, DOI 10.1007/978-3-662-48570-5_32
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ng CJ, 2015, ASIAPAC SIGN INFO PR, P761, DOI 10.1109/APSIPA.2015.7415375
   Phillips P., 1996, FERET FACE RECOGNITI
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Widrow B, 2013, NEURAL NETWORKS, V37, P180, DOI 10.1016/j.neunet.2012.09.020
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Zhang DQ, 2005, NEUROCOMPUTING, V69, P224, DOI 10.1016/j.neucom.2005.06.004
   Zhu PF, 2012, LECT NOTES COMPUT SC, V7572, P822, DOI 10.1007/978-3-642-33718-5_59
NR 24
TC 20
Z9 22
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12919
EP 12934
DI 10.1007/s11042-017-4923-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100056
DA 2024-07-18
ER

PT J
AU Bisio, I
   Fedeli, A
   Lavagetto, F
   Pastorino, M
   Randazzo, A
   Sciarrone, A
   Tavanti, E
AF Bisio, Igor
   Fedeli, Alessandro
   Lavagetto, Fabio
   Pastorino, Matteo
   Randazzo, Andrea
   Sciarrone, Andrea
   Tavanti, Emanuele
TI A numerical study concerning brain stroke detection by microwave imaging
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Microwave imaging; Brain stroke detection; Inverse problems; Imaging
   techniques
ID INEXACT-NEWTON METHOD; DIELECTRIC-PROPERTIES; RADAR; SCATTERING;
   TISSUES; MODEL
AB In this paper, a numerical study devoted to evaluate the application of a microwave imaging method for brain stroke detection is described. First of all, suitable operating conditions for the imaging system are defined by solving the forward electromagnetic scattering problem with respect to simplified configurations and analyzing the interactions between an illuminating electromagnetic wave at microwave frequencies and the biological tissues inside the head. Then, preliminary inversion results are obtained by applying an imaging procedure based on an iterative Gauss-Newton scheme to a realistic model of the human head. The proposed imaging algorithm is able to deal with the nonlinear and ill-posed problem associated to the integral equations describing the inverse scattering problem. The aim of the inversion procedure is related to the determination of the presence of a hemorrhagic brain stroke by retrieving the distributions of the dielectric parameters of the human tissues inside a slice of the head model.
C1 [Bisio, Igor; Fedeli, Alessandro; Lavagetto, Fabio; Pastorino, Matteo; Randazzo, Andrea; Sciarrone, Andrea; Tavanti, Emanuele] Univ Genoa, Dept Elect Elect Telecommun Engn & Naval Architec, Via Opera Pia 11A, I-16145 Genoa, Italy.
C3 University of Genoa
RP Pastorino, M (corresponding author), Univ Genoa, Dept Elect Elect Telecommun Engn & Naval Architec, Via Opera Pia 11A, I-16145 Genoa, Italy.
EM matteo.pastorino@unige.it
RI Randazzo, Andrea/K-1739-2014; Fedeli, Alessandro/AAD-6418-2019; Bisio,
   Igor/L-9799-2015; Fedeli, Alessandro/N-3052-2015
OI Fedeli, Alessandro/0000-0001-6636-1448; Fedeli,
   Alessandro/0000-0001-6636-1448; TAVANTI, EMANUELE/0000-0002-1299-0692
FU Compagnia di San Paolo, Italy
FX The present work is partially supported by Compagnia di San Paolo,
   Italy.
CR Barbeito A, 2017, INT J E-HEALTH MED C, V8, P19, DOI 10.4018/IJEHMC.2017010102
   Bertero M., 1998, Introduction to Inverse Problems in Imaging
   Bozza G, 2007, MATER EVAL, V65, P917
   Bozza G, 2007, IEEE T INSTRUM MEAS, V56, P1181, DOI 10.1109/TIM.2007.900127
   Bozza G, 2007, IEEE GEOSCI REMOTE S, V4, P51, DOI 10.1109/LGRS.2006.885864
   Burfeindt MJ, 2014, IEEE T ANTENN PROPAG, V62, P5126, DOI 10.1109/TAP.2014.2344096
   Byrne D, 2015, IEEE T ANTENN PROPAG, V63, P1725, DOI 10.1109/TAP.2015.2398125
   Caorsi S, 2004, IEEE T INSTRUM MEAS, V53, P987, DOI 10.1109/TIM.2004.831446
   Caorsi S, 2003, IEEE T GEOSCI REMOTE, V41, P2745, DOI 10.1109/TGRS.2003.815676
   Catapano I, 2015, SPR TRANS CIV ENV EN, P239, DOI 10.1007/978-3-319-04813-0_10
   Chew W. C., 1995, Waves and Fields in Inhomogeneous Media, V16
   Donnell KM, 2012, IEEE T INSTRUM MEAS, V61, P2320, DOI 10.1109/TIM.2012.2200822
   Estatico C, 2012, IEEE T ANTENN PROPAG, V60, P3373, DOI 10.1109/TAP.2012.2196925
   Estatico C, 2015, IEEE T ANTENN PROPAG, V63, P4198, DOI 10.1109/TAP.2015.2446995
   Fear EC, 2013, IEEE T MICROW THEORY, V61, P2119, DOI 10.1109/TMTT.2013.2255884
   Gabriel S, 1996, PHYS MED BIOL, V41, P2251, DOI 10.1088/0031-9155/41/11/002
   Guo L, 2015, IEEE T ANTENN PROPAG, V63, P4877, DOI 10.1109/TAP.2015.2473000
   Hacke W, 2008, NEW ENGL J MED, V359, P1317, DOI 10.1056/NEJMoa0804656
   Hossain MD, 2013, IEEE ANTENN WIREL PR, V12, P241, DOI 10.1109/LAWP.2013.2247018
   Ireland D, 2011, PROG ELECTROMA RES M, V21, P163, DOI 10.2528/PIERM11082907
   Ireland D, 2013, IET MICROW ANTENNA P, V7, P909, DOI 10.1049/iet-map.2013.0054
   Kim YJ, 2003, IEEE T ANTENN PROPAG, V51, P3022, DOI 10.1109/TAP.2003.818786
   Kwatkowski TG, 1999, NEW ENGL J MED, V340, P1781
   Larsen L.E., 1986, MED APPL MICROWAVE I
   Lazebnik M, 2007, PHYS MED BIOL, V52, P2637, DOI 10.1088/0031-9155/52/10/001
   Manirabona A, 2017, INT J E-HEALTH MED C, V8, P1, DOI 10.4018/IJEHMC.2017010101
   Miao ZZ, 2017, IEEE T ANTENN PROPAG, V65, P2507, DOI 10.1109/TAP.2017.2679067
   Mohammed BJ, 2015, ELECTRON LETT, V51, P1574, DOI 10.1049/el.2015.1376
   Mohammed BJ, 2014, IEEE T INSTRUM MEAS, V63, P117, DOI 10.1109/TIM.2013.2277562
   Monleone RD, 2012, IEEE T INSTRUM MEAS, V61, P140, DOI 10.1109/TIM.2011.2159144
   Mustafa S, 2013, IEEE ANTENN WIREL PR, V12, P460, DOI 10.1109/LAWP.2013.2255095
   Mustafa S, 2014, IEEE T ANTENN PROPAG, V62, P1354, DOI 10.1109/TAP.2013.2296323
   Nikolova NK, 2011, IEEE MICROW MAG, V12, P78, DOI 10.1109/MMM.2011.942702
   O'Halloran M, 2010, IEEE T BIO-MED ENG, V57, P830, DOI 10.1109/TBME.2009.2016392
   Pastorino M., 2010, Microwave Imaging
   Pastorino M, 2015, WOOD MATER SCI ENG, V10, P75, DOI 10.1080/17480272.2014.898696
   Persson M, 2014, IEEE T BIO-MED ENG, V61, P2806, DOI 10.1109/TBME.2014.2330554
   Porter E, 2016, IEEE T BIO-MED ENG, V63, P530, DOI 10.1109/TBME.2015.2465867
   Ren K, 2016, IEEE T ANTENN PROPAG, V64, P5198, DOI 10.1109/TAP.2016.2617358
   Ricci E, 2015, IEEE ENG MED BIO, P1930, DOI 10.1109/EMBC.2015.7318761
   RICHMOND JH, 1965, IEEE T ANTENN PROPAG, VAP13, P334, DOI 10.1109/TAP.1965.1138427
   Riechers RG, 1998, SENSING THE WORLD: ANALOG SENSORS & SYSTEMS ACROSS THE SPECTRUM, P1, DOI 10.1109/DAYTON.1998.694549
   Scapaticci R., 2012, Progress In Electromagnetics Research B, V40, P305
   Semenov S., 2016, 2016 IEEE Conference on Antenna Measurements Applications (CAMA), P1
   Semenov SY, 2008, INT J ANTENN PROPAG, V2008, DOI 10.1155/2008/254830
   Shea JD, 2012, IEEE T BIO-MED ENG, V59, P936, DOI 10.1109/TBME.2011.2176727
   Zamani A, 2016, IEEE T MICROW THEORY, V64, P653, DOI 10.1109/TMTT.2015.2513398
   Zhang WJ, 2014, IEEE T ANTENN PROPAG, V62, P459, DOI 10.1109/TAP.2013.2287274
   ZUBAL IG, 1994, MED PHYS, V21, P299, DOI 10.1118/1.597290
NR 49
TC 31
Z9 31
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9341
EP 9363
DI 10.1007/s11042-017-4867-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200010
DA 2024-07-18
ER

PT J
AU Chang, CC
   Chen, TS
   Wang, YK
   Liu, YJ
AF Chang, Chin-Chen
   Chen, Tung-Shou
   Wang, Yu-Kai
   Liu, Yanjun
TI A reversible data hiding scheme based on absolute moment block
   truncation coding compression using exclusive OR operator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Absolute moment block truncation coding (AMBTC);
   Joint neighboring coding (JNC); Encrypted image
ID COLOR IMAGES
AB Due to a rapid increase in copyright infringement, protecting secret information during transmission on the Internet is very important. More and more researchers have proposed solutions such as steganography, watermarking and data hiding schemes to solve these problems. Among these methods, the reversible data hiding scheme (RDH) is the most famous method. It not only extracts secret information from the stego carrier, but also recovers the original carrier. Therefore, in this study we propose an effective RDH in absolute mean block truncation coding (AMBTC) compression code, which uses joint neighborhood coding (JNC) to embed secret information and uses an exclusive OR operator to compute differences between the current value and the selected value. Experimental results indicate that our scheme has a satisfactory embedding rate and an appropriate stego file size using JNC and XOR.
C1 [Chang, Chin-Chen; Liu, Yanjun] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
   [Chen, Tung-Shou] Natl Taichung Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taichung 40401, Taiwan.
   [Wang, Yu-Kai] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 62102, Taiwan.
C3 Feng Chia University; National Taichung University of Science &
   Technology; National Chung Cheng University
RP Liu, YJ (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM alan3c@gmail.com; tschen@nutc.edu.tw; hypons_wyk@hotmail.com;
   yjliu104@gmail.com
RI liu, yan/HCI-5542-2022; 刘, 严君/GZL-5764-2022; Chang,
   Ching-Chun/JAN-6210-2023; liu, yan/HGV-1365-2022
CR Ahani S, 2015, IET IMAGE PROCESS, V9, P496, DOI 10.1049/iet-ipr.2014.0351
   Alattar AM, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P377
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Celik MU, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P157
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Chang CC, 2016, MULTIMED TOOLS APPL, V75, P3537, DOI 10.1007/s11042-015-2463-2
   Chang CC, 2011, J VIS COMMUN IMAGE R, V22, P664, DOI 10.1016/j.jvcir.2011.06.005
   Chang I. C., 2013, SIGNAL PROCESS, V7, P297
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Hu YJ, 2008, IEEE T MULTIMEDIA, V10, P1500, DOI 10.1109/TMM.2008.2007341
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Li F, 2016, MULTIMED TOOLS APPL, V75, P16153, DOI 10.1007/s11042-015-2924-7
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin C, 2013, MULTIMED TOOLS APPL, V74, P3823, DOI DOI 10.1007/S11042-013-1801-5
   Ma XX, 2015, J VIS COMMUN IMAGE R, V30, P191, DOI 10.1016/j.jvcir.2015.04.009
   Ma XX, 2015, J VIS COMMUN IMAGE R, V28, P60, DOI 10.1016/j.jvcir.2015.01.009
   Sun W, 2013, SIGNAL IMAGE VIDEO P, V7, P297, DOI 10.1007/s11760-011-0238-4
   Tang MW, 2016, OPTIK, V127, P471, DOI 10.1016/j.ijleo.2015.09.216
   Wang JX, 2009, INFORM SCIENCES, V179, P3332, DOI 10.1016/j.ins.2009.05.021
   Zhao ZF, 2012, INT J DIGIT CONTENT, V6, P205
NR 22
TC 22
Z9 23
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 9039
EP 9053
DI 10.1007/s11042-017-4800-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800056
DA 2024-07-18
ER

PT J
AU Jeong, CW
   Joo, SC
AF Jeong, Chang-Won
   Joo, Su-Chong
TI Skin care management support system based on cloud computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin disease; Skin care management support system; Cloud computing;
   Interaction method; Data synchronization; Psoriasis and melanoma
ID DISEASE; SYNCHRONIZATION; INTERVENTION; CANCER
AB In this paper, we propose a skin care management support system that can provide easy intercommunication between patients and medical staff for optimal management of skin treatment and an aid to diagnosis. This system provides self-management and treatment advice for patients from medical staff. Our research is specially focused on the management of conditions such as psoriasis and melanoma. Although there exist systems have been developed for various medical applications, including some that provide self-monitoring via smartphones, the patient participation rate in using these applications has been low after initial use. This is because obtaining useful information regarding the diagnosis and treatment of disease without the support of medical staff is difficult. We propose a skin care management support system with an enhanced interaction method. It leverages a data synchronization mechanism to enable patients and medical staff to view simultaneously. The system environment is based on cloud computing environment, which provides secure communication by using an Advanced Encryption Standard (AES) between patients and medical staff. Finally, we demonstrate the complete skin care management procedure for skin diseases using a smartphone-based portal service.
C1 [Jeong, Chang-Won] Wonkwang Univ Hosp, Med Convergence Res Ctr, 460 Iksandeaero, Iksan 570749, Jeonbuk, South Korea.
   [Joo, Su-Chong] Wonkwang Univ, Dept Comp Engn, 460 Iksandeaero, Iksan 570749, Jeonbuk, South Korea.
C3 Wonkwang University; Wonkwang University
RP Joo, SC (corresponding author), Wonkwang Univ, Dept Comp Engn, 460 Iksandeaero, Iksan 570749, Jeonbuk, South Korea.
EM mediblue@wku.ac.kr; scjoo@wku.ac.kr
FU Wonkwang University
FX This work was supported by Wonkwang University in 2017.
CR Ahn YS, 2010, J KOREAN MED SCI, V25, pS46, DOI 10.3346/jkms.2010.25.S.S46
   Benmohamed A, 2015, MULTIMED TOOLS APPL, V74, P9297, DOI 10.1007/s11042-014-2082-3
   Hilliard ME, 2014, JMIR MHEALTH UHEALTH, V2, DOI 10.2196/mhealth.3599
   Kim SH, 2015, MULTIMED TOOLS APPL, V74, P8939, DOI 10.1007/s11042-013-1584-8
   Lerman JB, 2016, J INVEST MED, V64, DOI 10.1136/jim-2016-000080.34
   Michel O, 2015, HNO, V63, P875, DOI 10.1007/s00106-015-0064-z
   Naldi L, 2014, BRIT J DERMATOL, V171, P934, DOI 10.1111/bjd.13391
   Parmanto B, 2015, BMC MED INFORM DECIS, V15, DOI 10.1186/s12911-015-0237-4
   Parmanto B, 2013, JMIR MHEALTH UHEALTH, V1, DOI 10.2196/mhealth.2391
   Patapoutian A, 2006, IEEE T SIGNAL PROCES, V54, P1494, DOI 10.1109/TSP.2006.870587
   Powers JG, 2015, J INVEST DERMATOL, V135, P2871, DOI 10.1038/jid.2015.238
   Sanderson R, 2013, D LIB MAGAZINE, V19, P4
   Shah R, 2014, CLIN EXP DERMATOL, V39, P600, DOI 10.1111/ced.12339
   Souza IDD, 2015, INT J COSMETIC SCI, V37, P479, DOI 10.1111/ics.12220
   Volpe G, 2014, AM J HEALTH-SYST PH, V71, P675, DOI 10.2146/ajhp130286
NR 15
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9885
EP 9896
DI 10.1007/s11042-017-5521-0
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200034
DA 2024-07-18
ER

PT J
AU Kounalakis, T
   Triantafyllidis, GA
   Nalpantidis, L
AF Kounalakis, Tsampikos
   Triantafyllidis, Georgios A.
   Nalpantidis, Lazaros
TI Image-based recognition framework for robotic weed control systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image-base system; Weed recognition; Weed detection; Precision
   agriculture; Weed control robotic systems
ID ALGORITHM; FEATURES
AB In this paper, we introduce a novel and efficient image-based weed recognition system for the weed control problem of Broad-leaved Dock (Rumex obtusifolius L.). Our proposed weed recognition system is developed using a framework, that allows the examination of the affects for various image resolutions in detection and recognition accuracy. Moreover, it includes state-of-the-art object/image categorization processes such as feature detection and extraction, codebook learning, feature encoding, image representation and classification. The efficiency of those processes have been improved and optimized by introducing methodologies, techniques and system parameters specially tailored for the goal of weed recognition. Through an exhaustive optimization process, which is presented as our experimental evaluation, we conclude to a weed recognition system that uses an image input resolution of 200 x150, SURF features over dense feature extraction, an optimized Gaussian Mixture Model based codebook combined with Fisher encoding, using a two level image representation. The resulting image representation vectors are classified using a linear classifier. This system is experimentally shown to yield state-of-the-art recognition accuracy of 89.09% in the examined dataset. Our proposed system is also experimentally shown to comply with the specifications of the examined applications since it provides low false-positive results of 4.38%. As a result, the proposed framework can be efficiently used in weed control robots for precision farming applications.
C1 [Kounalakis, Tsampikos; Nalpantidis, Lazaros] Aalborg Univ, Dept Mech & Mfg Engn, Copenhagen, Denmark.
   [Triantafyllidis, Georgios A.] Aalborg Univ, Dept Architecture, Design, Media Technol, Copenhagen, Denmark.
C3 Aalborg University; Aalborg University
RP Kounalakis, T (corresponding author), Aalborg Univ, Dept Mech & Mfg Engn, Copenhagen, Denmark.
EM tkoun@m-tech.aau.dk; gt@create.aau.dk; lanalpa@m-tech.aau.dk
RI Nalpantidis, Lazaros/AAV-9414-2021; Nalpantidis, Lazaros/J-1803-2012;
   Triantafyllidis, Georgios/HTR-3327-2023
OI Nalpantidis, Lazaros/0000-0002-3620-4123; Nalpantidis,
   Lazaros/0000-0002-3620-4123; Triantafyllidis,
   Georgios/0000-0002-0495-777X
FU DockWeeder project [30079, 618123]; Ministry of Economic Affairs (The
   Netherlands); Federal Office for Agriculture (Switzerland); Innovation
   Fund Denmark, the Ministry of Science, Innovation and Higher Education
   (Denmark)
FX This work has been supported by the DockWeeder project (project ID:
   30079), administered through the European Union's Seventh Framework
   Program for research, technological development and demonstration under
   grant agreement no 618123 [ICT-AGRI 2]. The project has received funding
   from the Ministry of Economic Affairs (The Netherlands), from the
   Federal Office for Agriculture (Switzerland), and from Innovation Fund
   Denmark, the Ministry of Science, Innovation and Higher Education
   (Denmark).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], ROB INR
   [Anonymous], IEEE I CONF COMP VIS
   [Anonymous], 2014, P LIFECLEF
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], MECH HOEING ROB
   [Anonymous], CLEF 2014 C
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], 14 INT C INT AUT SYS
   [Anonymous], 2013, ARXIV PREPRINT ARXIV
   [Anonymous], 2014, INT C MACH LEARN ICM
   [Anonymous], DOCKWEEDER ROB EN OR
   [Anonymous], 2012, P ADV NEUR INF PROC
   [Anonymous], 2011, P JMLR WORK, DOI DOI 10.1109/IJCNN.2011.6033302
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Belongie S, 2001, ADV NEUR IN, V13, P831
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fan RE, 2005, J MACH LEARN RES, V6, P1889
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Hamerly G., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P600, DOI 10.1145/584792.584890
   Harris C., 1988, ALVEY VISION C, P147151
   Isik S., 2014, International Journal of Applied Mathematics, Electronics and Computers, V3, P1, DOI [10.18100/ijamec.60004, DOI 10.18100/IJAMEC.60004]
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Kargar Amir H. B., 2013, 2013 First RSI/ISM International Conference on Robotics and Mechatronics (ICRoM 2013). Proceedings, P468, DOI 10.1109/ICRoM.2013.6510152
   Kazmi W, 2015, COMPUT ELECTRON AGR, V118, P290, DOI 10.1016/j.compag.2015.08.023
   Kounalakis T, 2016, IEEE CONF IMAGING SY, P466, DOI 10.1109/IST.2016.7738271
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Lottes P, 2016, IEEE INT CONF ROBOT, P5157, DOI 10.1109/ICRA.2016.7487720
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Michaels A, 2015, IEEE INT C INT ROBOT, P5498, DOI 10.1109/IROS.2015.7354156
   Mikolajczyk Krystian., 2002, An affine invariant interest point detector, P128, DOI DOI 10.1007/3-540-47969-49
   Miksik O, 2012, INT C PATT RECOG, P2681
   Mukherjee D, 2015, MACH VISION APPL, V26, P443, DOI 10.1007/s00138-015-0679-9
   Oerke EC, 2006, J AGR SCI-CAMBRIDGE, V144, P31, DOI 10.1017/S0021859605005708
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pérez-Ortiz M, 2015, APPL SOFT COMPUT, V37, P533, DOI 10.1016/j.asoc.2015.08.027
   Pérez-Ortiz M, 2016, EXPERT SYST APPL, V47, P85, DOI 10.1016/j.eswa.2015.10.043
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Rouse J.W., 1974, P 3 EARTH RESOURCE T, V351, P309
   Salahat E, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1059, DOI 10.1109/ICIT.2017.7915508
   Schwarz M, 2015, IEEE INT CONF ROBOT, P1329, DOI 10.1109/ICRA.2015.7139363
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Silpa-Anan C, 2008, PROC CVPR IEEE, P2308
   Ustyuzhanin A, 2017, WEED TECHNOL, V31, P310, DOI 10.1614/WT-D-16-00068.1
   van Evert FK, 2009, WEED RES, V49, P164, DOI 10.1111/j.1365-3180.2008.00682.x
   Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wong WK, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON ROBOTICS AND MANUFACTURING AUTOMATION (ROMA), P63, DOI 10.1109/ROMA.2014.7295863
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 59
TC 19
Z9 20
U1 0
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9567
EP 9594
DI 10.1007/s11042-017-5337-y
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200020
DA 2024-07-18
ER

PT J
AU Rabie, T
   Kamel, I
   Baziyad, M
AF Rabie, Tamer
   Kamel, Ibrahim
   Baziyad, Mohammed
TI Maximizing embedding capacity <i>and</i> stego quality: curve-fitting in
   the transform domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Curve fitting; High capacity; High perceptual quality; Steganography;
   Transform-domain image hiding; Quad-tree; Discrete cosine transform;
   Discrete wavelet transform
ID IMAGE; STEGANOGRAPHY; WATERMARKING; INFORMATION
AB Achieving high embedding capacities for information hiding systems while maintaining high perceptual stego quality is a critical challenge in steganography. This quandary is attracting researchers to overcome the trade-off barrier between high capacities and enhanced levels of stego image quality. This work introduces a promising transform-domain hiding scheme that aims to achieve ultimate hiding capacity with premium perceptual quality results. The proposed scheme is based on the fact that highly correlated images are represented by significant coefficients that are strongly packed in the transform-domain of the image. This allows for a large space in the insignificant coefficient areas to embed in. To exploit this feature optimally, a curve-fitting approach is introduced and implemented in various adaptive-region transform-domain embedding schemes. Experimental results demonstrate that this curve-fitting methodology is able to enhance adaptive transform-domain embedding schemes where very high embedding capacities can be achieved that are much higher than competing high-capacity hiding schemes. The other noticeable result is that although the embedding capacity has increased compared to earlier work, the perceptual quality level has also improved over previous methods.
C1 [Rabie, Tamer; Kamel, Ibrahim] Univ Sharjah, Dept Elect & Comp Engn, Sharjah, U Arab Emirates.
   [Baziyad, Mohammed] Univ Sharjah, Res Inst Sci & Engn, Sharjah, U Arab Emirates.
C3 University of Sharjah; University of Sharjah
RP Rabie, T (corresponding author), Univ Sharjah, Dept Elect & Comp Engn, Sharjah, U Arab Emirates.
EM trabie@sharjah.ac.ae; kamel@sharjah.ac.ae; mbaziyad@sharjah.ac.ae
FU College of Graduate Studies and Research at the University of Sharjah
FX The authors would like to thank the five anonymous reviewers for their
   valuable suggestions that helped improve the original manuscript. This
   work was supported by the College of Graduate Studies and Research at
   the University of Sharjah.
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   [Anonymous], 1994, T81 ITUT
   Bracamonte J, 2005, LECT NOTES COMPUT SC, V3568, P154
   BRACAMONTE J, 2000, P 6 COST, V276, P88
   Brisbane G, 2005, IEE P-VIS IMAGE SIGN, V152, P787, DOI 10.1049/ip-vis:20045047
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2002, INFORM SCIENCES, V141, P123, DOI 10.1016/S0020-0255(01)00194-3
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Cole E, 2003, HIDING IN PLAIN SIGH
   EBRAHIMPOURKOML.H, 2001, INT C IM PROC, V3, P58
   El Safy R. O., 2009, 2009 International Conference on Networking and Media Convergence (ICNM'09), P111, DOI 10.1109/ICNM.2009.4907200
   Ibaida A, 2013, IEEE T BIO-MED ENG, V60, P3322, DOI 10.1109/TBME.2013.2264539
   Jain A, 2002, PROC OF THE INTERNAT
   Roque JJ, 2009, SECURITY IN INFORMATION SYSTEMS, PROCEEDINGS, P57
   Lee YK, 2000, IEE P-VIS IMAGE SIGN, V147, P288, DOI 10.1049/ip-vis:20000341
   Leng C.K., 2008, JDCTA, V2, P35
   Lin C.-C., 2010, J. Inf. Hiding Multimed. Signal Process, V1, P220
   Lu PZ, 2004, LECT NOTES COMPUT SC, V3200, P116
   Marvel LM, 1999, IEEE T IMAGE PROCESS, V8, P1075, DOI 10.1109/83.777088
   Nozaki K., 1998, ACCV 98 P 3 AS C COM, VI, P112
   Pavildis G, 2003, SIGNAL PROCESS-IMAGE, V18, P497, DOI 10.1016/S0923-5965(03)00038-9
   Qazanfari K, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043009
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Rabie T., 2007, International Journal of Advanced Media and Communication, V1, P298, DOI 10.1504/IJAMC.2007.013952
   Rabie T, 2016, MULTIMED TOOLS APPL, DOI [10.1007/s11,042-016-3942-9, DOI 10.1007/S11,042-016-3942-9]
   Rabie T, 2016, MULTIMED TOOLS APPL, V76, DOI [10.1007/s11,042-016-3501-4, DOI 10.1007/S11,042-016-3501-4]
   RABIE T, 2013, 6 INT C IM SIGN, P858
   Rabie T., 2010, ADV TECHNIQUES MULTI, P21, DOI DOI 10.4018/978-1-61520-903-3.CH002
   Rabie T, 2015, MULTIMED TOOLS APPL, V75, DOI [10.1007/s11,042-015-2557-x, DOI 10.1007/S11,042-015-2557-X]
   Rabie T, 2016, MULTIMED TOOLS APPL, V76, DOI [10.1007/s11,042-016-3301-x, DOI 10.1007/S11,042-016-3301-X]
   Raja KB, 2007, 2006 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATIONS, VOLS 1 AND 2, P223
   Raja K. B., 2005, P 3 INT C INT SENS I, P170
   Rao K.R, 2014, DISCRETE COSINE TRAN
   RODRIGUES J, 2004, 5 INT WORKSH IM AN M
   Solanki K, 2004, IEEE T IMAGE PROCESS, V13, P1627, DOI 10.1109/TIP.2004.837557
   Sumathi C. P., 2014, ARXIV14015561
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Yang B, 2004, PROC SPIE, V5306, P405, DOI 10.1117/12.527216
NR 43
TC 20
Z9 20
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8295
EP 8326
DI 10.1007/s11042-017-4727-5
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800024
DA 2024-07-18
ER

PT J
AU Arain, QA
   Memon, I
   Deng, ZL
   Memon, MH
   Mangi, FA
   Zubedi, A
AF Arain, Qasim Ali
   Memon, Imran
   Deng, Zhongliang
   Memon, Muhammad Hammad
   Mangi, Farman Ali
   Zubedi, Asma
TI Location monitoring approach: multiple mix-zones with location privacy
   protection based on traffic flow over road networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Privacy preservation; Location based services (LBS); Road networks;
   Mix-zones
ID HIGHLY PARALLEL FRAMEWORK; HEVC MOTION ESTIMATION; ARCHITECTURE;
   SECURITY; PROTOCOL; SCHEME
AB Nowadays communication by using mobile vehicle getting popularity and user experience map services like Google maps to reach at the destination. It is also clear that map services user have to reveal important information like GPS coordinates or some other personal information during this process. According to current mix-zones privacy techniques, it is revealed that, these methods are much generalized and cannot be applied to secure map services users. In this paper, we have given a novel MMLPP technique, which is specifically constructed for map services users over road network. According to this, mobile vehicle's users to ask a path among two end points defined on the map, however not to disclose secret location and query statistics. The main concept is to place end points in such a way that, they must be near to each other, alternatively: 1) Actual statistics defined inside these end points (like GPS coordinates) must not be altered i.e. location privacy ensured. 2) The path reverted by the map services change a little, i.e. service usability must be ensured. We can re-iterate in such a way that, firstly, a mobile client extract point of interest, that is close to original end points, and then finally consider two POIs considered as shifted end points which satisfy the condition of Geo-Indistinguishability. We analyzed MMLPP technique for road network application for GTMobiSim on multiple scales of map services and experiments are conducted using real traces. It has been revealed that MMLPP has outperformed all other techniques and shows balance among location privacy and service usability.
C1 [Arain, Qasim Ali; Deng, Zhongliang] Beijing Univ Posts & Telecommun, Beijing, Peoples R China.
   [Memon, Imran] Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Zhejiang, Peoples R China.
   [Memon, Muhammad Hammad; Mangi, Farman Ali] Univ Elect Sci & Technol, Chengdu 611731, Sichuan, Peoples R China.
   [Zubedi, Asma] Beijing Univ Posts & Telecommun, Sch Econ & Management, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Zhejiang University;
   University of Electronic Science & Technology of China; Beijing
   University of Posts & Telecommunications
RP Memon, I (corresponding author), Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Zhejiang, Peoples R China.
EM Imranmemon52@zju.edu.cn
RI MEMON, MUHAMMAD HAMMAD/S-3320-2016; memon, imran/K-1647-2017
OI MEMON, MUHAMMAD HAMMAD/0000-0002-8680-1831; memon,
   imran/0000-0002-8202-6604; Arain, Qasim Ali/0000-0003-2095-7435
FU National High Technology Research and Development Program of China
   [2014AA123103, 2015AA124103]; National Natural Science Foundation of
   China [61401040, 61372110]
FX This research has been funded by The National High Technology Research
   and Development Program of China (NO.2014AA123103, NO. 2015AA124103) and
   National Natural Science Foundation of China (NO.61401040, NO.61372110).
CR Adigun A, 2013, PROCEEDINGS OF THE 2013 38TH ANNUAL IEEE CONFERENCE ON LOCAL COMPUTER NETWORKS WORKSHOPS (LCN WORKSHOPS), P162, DOI 10.1109/LCNW.2013.6758514
   Adu-Gyamfi D, 2013, 6 INT C INF MAN IND
   Akhtar R, 2012, INT C GRAPH IM PROC
   Akhtar R, 2015, WIRELESS PERS COMMUN, V80, P85, DOI 10.1007/s11277-014-1996-4
   Akhtar R, 2013, INT CONF COMPUTAT, P139, DOI 10.1109/ICCPS.2013.6893572
   [Anonymous], TIGER TIGER LIN TIGE
   [Anonymous], 2001, Proceedings of the Second International Conference on Web Information Systems Engineering, Web Information Systems Engineering, 2001. Proceedings of the Second International Conference on, P66
   [Anonymous], 1998, PROTECTING PRIVACY D
   [Anonymous], 2009, Proceedings of International Conference on Very Large Data Bases
   Arain QA, 2017, WIRELESS PERS COMMUN, V95, P505, DOI 10.1007/s11277-016-3906-4
   Arain QA, 2017, WIRELESS PERS COMMUN, V95, P411, DOI 10.1007/s11277-016-3900-x
   Bamba B., 2008, Proceeding of 17th International Conference on World Wide Web, P237, DOI [DOI 10.1145/1367497.1367531, 10.1145/1367497.1367531]
   Bao Jie., 2009, PROC 17 ACM SIGSPATI, P552
   Buttyan L., 2009, IEEE VEH NETW C, P1
   Chen YS, 2013, INT CONF CONNECT VEH, P937, DOI [10.1109/ICCVE.2013.185, 10.1109/ICCVE.2013.6799933]
   Chow C-Y, 2007, P 10 INT C ADV SPAT
   Chow CY, 2011, GEOINFORMATICA, V15, P571, DOI 10.1007/s10707-010-0117-0
   Domenic M. Kamenyi, 2013, 6 INT C INF MAN INN, DOI [10.1109/ICIII.2013.6702947, DOI 10.1109/ICIII.2013.6702947]
   Freudiger J, 2007, ACM WIN ITS
   Freudiger J, 2009, CCS'09: PROCEEDINGS OF THE 16TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P324
   Freudiger Julien., 2010, Proceedings of IEEE INFOCOM 2010, P1
   Gao K, 2016, EURASIP J WIREL COMM, DOI 10.1186/s13638-016-0708-z
   Guo S, 2014, PARALLEL DISTRIBUTED
   Gustav YH, 2013, INT CONF COMPUTAT, P433, DOI 10.1109/ICCPS.2013.6893578
   Haas JJ, 2009, GLOB TELECOMM CONF, P2629
   Hao SY, 2017, NEUROCOMPUTING, V220, P121, DOI 10.1016/j.neucom.2016.05.101
   Huang LP, 2006, LECT NOTES COMPUT SC, V3934, P165
   Huang Q, 2005, IEEE ICC, P3525
   Huang X, 2015, 5 INT C INF SCI TECH, DOI [10.1109/ICIST.2015.7288978, DOI 10.1109/ICIST.2015.7288978]
   Hubaux JP, 2004, IEEE SECUR PRIV, V2, P49, DOI 10.1109/MSP.2004.26
   Kalnis P, 2007, IEEE T KNOWL DATA EN, V19, P1719, DOI 10.1109/TKDE.2007.190662
   Kamenyi D. M., 2013, J COMPUTATIONAL INFO, V9, P9857
   Ku WS, 2007, I C DATA ENGIN WORKS, P215, DOI 10.1109/ICDEW.2007.4400994
   Li XY, 2013, P IEEE INFOCOM IEEE
   Liu FY, 2009, MDM: 2009 10TH INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT, P436, DOI 10.1109/MDM.2009.72
   Liu XX, 2012, IEEE INFOCOM SER, P972, DOI 10.1109/INFCOM.2012.6195848
   Lu RX, 2012, IEEE T VEH TECHNOL, V61, P86, DOI 10.1109/TVT.2011.2162864
   Memon I., 2013, IJCSI INT J COMPUTER, V10, P3
   Memon I, 2017, MULTIMED TOOLS APPL, V76, P24359, DOI 10.1007/s11042-016-4154-z
   Memon I, 2017, WORLD WIDE WEB, V20, P639, DOI 10.1007/s11280-016-0403-3
   Memon I, 2015, WIRELESS PERS COMMUN, V85, P1167, DOI 10.1007/s11277-015-2833-0
   Memon I, 2015, WIRELESS PERS COMMUN, V84, P1487, DOI 10.1007/s11277-015-2699-1
   Memon I, 2015, WIRELESS PERS COMMUN, V82, P1585, DOI 10.1007/s11277-015-2300-y
   Memon I, 2015, WIRELESS PERS COMMUN, V80, P1347, DOI 10.1007/s11277-014-2082-7
   Memon I, 2014, WIRELESS PERS COMMUN, V79, P661, DOI 10.1007/s11277-014-1879-8
   Memon MH, 2017, MULTIMED TOOLS APPL, V76, P15377, DOI 10.1007/s11042-016-3834-z
   Meyerowitz J, 2009, MOBICOM
   Mokbel M. F., 2006, P 32 INT C VER LARG, P763, DOI DOI 10.1145/1620585.1620591
   Mouratidis K, 2010, IEEE T KNOWL DATA EN, V22, P2, DOI 10.1109/TKDE.2009.48
   Narayanan A., 2011, P NETW DISTR SYST SE
   OLUMOFINI F, 2010, 10 INT C PRIV ENH, V6205, P93
   Palanisamy B, 2015, IEEE T MOBILE COMPUT, V14, P495, DOI 10.1109/TMC.2014.2321747
   Palanisamy B, 2011, PROC INT CONF DATA, P494, DOI 10.1109/ICDE.2011.5767898
   Pan X, 2012, IEEE T KNOWL DATA EN, V24, P1506, DOI 10.1109/TKDE.2011.105
   Pan YY, 2013, J NETW COMPUT APPL, V36, P1599, DOI 10.1016/j.jnca.2013.02.003
   Papadopoulos S, 2010, P VLDB ENDOWMENT
   Pingley A, 2011, IEEE INFOCOM SER, P1710, DOI 10.1109/INFCOM.2011.5934968
   Sadhukhan P, 2010, IMSAA, V2010, P15
   Shahabi, 2004, VLDB, V30, P840, DOI DOI 10.1016/B978-012088469-8.50074-7
   Shiode N, 2002, 50 CASA
   Sun G, 2017, FUTURE GENER COMP SY, V74, P375, DOI 10.1016/j.future.2016.08.023
   Sun YP, 2015, PEER PEER NETW APPL, V8, P1108, DOI 10.1007/s12083-014-0269-z
   WANG T., 2009, VLDB
   Wang W, 2016, PROC CVPR IEEE, P2378, DOI 10.1109/CVPR.2016.261
   Wang W, 2016, IEEE MULTIMEDIA, V23, P80, DOI 10.1109/MMUL.2016.69
   Wang W, 2016, IEEE T IMAGE PROCESS, V25, P1465, DOI 10.1109/TIP.2016.2523340
   Wang Y, 2015, J NETW COMPUT APPL, V53, P57, DOI 10.1016/j.jnca.2015.01.004
   Weber M, 2009, GTMOBISIM AMOBILE TR
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Yang KT, 2012, IEEE 8 INT C WIR MOB, DOI [10.1109/WiMOB.2012.6379110, DOI 10.1109/WIMOB.2012.6379110]
   Ying B, 2015, IEEE INT C COMM ICC, P2015, DOI [10.1109/ICC.2015.7249491, DOI 10.1109/ICC.2015.7249491]
   Ying B, 2015, IEEE ICC 2015 COMM S
   Yu R, 2016, IEEE T DEPEND SECURE, V13, P93, DOI 10.1109/TDSC.2015.2399291
   Zuberi RS, 2016, J COMPUT NETW COMMUN, V2016, DOI 10.1155/2016/3821593
NR 78
TC 48
Z9 52
U1 0
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5563
EP 5607
DI 10.1007/s11042-017-4469-4
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800021
DA 2024-07-18
ER

PT J
AU Rabee, AM
   Mohamed, MH
   Mahdy, YB
AF Rabee, Amr Magdy
   Mohamed, Marghny Hassan
   Mahdy, Yousef Bassyouni
TI Blind JPEG steganalysis based on DCT coefficients differences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Steganalysis; JPEG steganography; Blind Steganalysis;
   Support vectormachines
ID IMAGES
AB At recently, the most of the digital images are stored and transferred in their compressed format using discrete cosine transform (DCT)-based compression technique. DCT is one of the most important data compression technique due to the efforts from Joint Photographic Experts Group(JPEG). Blind steganalysis means how to detect the presence of the messages that are hidden using different types of steganography algorithms and has the ability to detect new unknown steganography algorithms. This paper presents blind steganalysis technique that can reliably detect the existence of messages hidden in JPEG files. In order to save the computation and memory cost, it is desirable to have image processing operations implemented directly in the DCT domain. The proposed method is based on extracting features directly from DCT domain through the analysis of differences between DCT coefficients before and after cropping. The extracted features are prepared as input to Support Vector Machine (SVM) to classify the image as stego (image that contain secret message) or clean (image that does not contain secret message). The experiments performed show that the proposed method yields better classification accuracy compared with other related works.
C1 [Rabee, Amr Magdy; Mohamed, Marghny Hassan; Mahdy, Yousef Bassyouni] Assiut Univ, Fac Comp & Informat, Assiut, Egypt.
C3 Egyptian Knowledge Bank (EKB); Assiut University
RP Rabee, AM (corresponding author), Assiut Univ, Fac Comp & Informat, Assiut, Egypt.
EM amrstar25@gmail.com
RI , marghny/AAI-6255-2020
CR [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   Böhme R, 2004, LECT NOTES COMPUT SC, V3193, P125
   Cai KW, 2010, IEEE IMAGE PROC, P1761, DOI 10.1109/ICIP.2010.5651567
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen GM, 2014, MULTIMED TOOLS APPL, V71, P497, DOI 10.1007/s11042-013-1522-9
   Chutani S., 2012, INT J COMPUTERS TECH, V3, P153
   Fridrich J, 2005, MULTIMEDIA SYST, V11, P98, DOI 10.1007/s00530-005-0194-3
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Fridrich J, 2003, LECT NOTES COMPUT SC, V2578, P310
   Fridrich J, 2003, MULTIMEDIA SYST, V9, P288, DOI 10.1007/s00530-003-0100-9
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3
   Hamid N., 2012, International Journal of Computer Science and Security (IJCSS), V6, P168
   Hetzl S, 2005, LECT NOTES COMPUT SC, V3677, P119
   Hsu C.-W., 2003, PRACTICAL GUIDE SUPP
   Jiang JM, 2002, IEEE T SIGNAL PROCES, V50, P1160, DOI 10.1109/78.995072
   Johnson NF, 2000, ART H COMP SCI LIBR, P43
   LATHAM A, JPHIDE SEEK
   Lerch-Hostalot D, 2013, COMPUT SECUR, V32, P192, DOI 10.1016/j.cose.2012.11.005
   Li B, 2009, IEEE T INF FOREN SEC, V4, P369, DOI 10.1109/TIFS.2009.2025841
   Liu QZ, 2010, INFORM SCIENCES, V180, P1643, DOI 10.1016/j.ins.2010.01.001
   Luo WQ, 2011, MULTIMED TOOLS APPL, V52, P407, DOI 10.1007/s11042-009-0440-3
   Meghanathan N., 2010, Int. J. Netw. Secur. Appl, V2, P43, DOI DOI 10.5121/IJNSA.2010.2404
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Pevny T, 2005, LECT NOTES COMPUT SC, V3710, P39
   Qinhua Huang, 2010, 2010 3rd International Symposium on Knowledge Acquisition and Modeling (KAM 2010), P175, DOI 10.1109/KAM.2010.5646209
   Sharma M, 2012, INT J COMPUTER SCI E, V2, P117, DOI [10.5121/ijcseit.2012.2308, DOI 10.5121/IJCSEIT.2012.2308]
   Sharp Toby, 2001, Information Hiding, V2137, P13, DOI 10.1007/3-540-45496-9_2
   Wang K, 2013, J SYST SOFTWARE, V86, P1965, DOI 10.1016/j.jss.2013.03.083
   Wang R, 2015, MULTIMED TOOLS APPL, V74, P5725, DOI 10.1007/s11042-014-1880-y
   Xi L, 2010, INT CONF COMP SCI, P203
   Zeng XT, 2010, PATTERN RECOGN, V43, P1656, DOI 10.1016/j.patcog.2009.09.016
   Zhang J, 2009, J COMPUT, V4, P646
NR 34
TC 4
Z9 4
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7763
EP 7777
DI 10.1007/s11042-017-4676-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700060
DA 2024-07-18
ER

PT J
AU Taheri, YM
   Ahmad, MO
   Swamy, MNS
AF Taheri, Yaser Mohammad
   Ahmad, M. Omair
   Swamy, M. N. S.
TI A joint correlation noise estimation and decoding algorithm for
   distributed video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed video coding; Wyner-Ziv frame; Variational Bayes;
   Correlation noise
ID SIDE-INFORMATION; PIXEL
AB Distributed video coding is relatively a novel video coding paradigm that enables a lower complex video encoding compared to conventional video coding schemes, at the expense of a higher-complexity decoder. Improving the rate-distortion and coding efficiency is a challenging problem in distributed video coding. Using a suitable correlation noise model along with an accurate estimation of its parameter can lead to an improved ratedistortion performance. In a distributed video codec, theWyner-Ziv frames are not available at the decoder. In addition, the correlation noise is not stationary and its statistics vary within each frame and in its corresponding transform coefficient bands. Hence, the estimation of the correlation noise model parameter is not a feasible task. In this paper, a new decoder is proposed to estimate the correlation noise parameter and carry out the decoding process progressively and recursively on an augmented factor graph. In the proposed decoder, a recursive message passing algorithm is used for decoding the bitplanes corresponding to each DCT band in a WZ frame, and simultaneously, for estimating and refining the correlation noise distribution parameter. To approximate the posterior distribution of the correlation noise parameter, and consequently, derive a closed-form expression for the messages on the augmented factor graph, a variational Bayes algorithm is employed. Extensive simulations are carried out to show that using the proposed decoder leads to considerable improvement in the rate-distortion performance of the distributed video codec, particularly on video sequences with fast motions.
C1 [Taheri, Yaser Mohammad; Ahmad, M. Omair; Swamy, M. N. S.] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ H3G 1M8, Canada.
C3 Concordia University - Canada
RP Ahmad, MO (corresponding author), Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ H3G 1M8, Canada.
EM y_moh@ece.concordia.ca; omair@ece.concordia.ca; swamy@ece.concordia.ca
FU Natural Sciences and Engineering Research Council (NSERC) of Canada;
   Regroupement Strategique en Microelectronique du Quebec (ReSMiQ)
FX This work was supported in part by the Natural Sciences and Engineering
   Research Council (NSERC) of Canada and in part by the Regroupement
   Strategique en Microelectronique du Quebec (ReSMiQ).
CR [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], STOCHASTIC APPROXIMA
   [Anonymous], 2003, EXPLORING ARTIFICIAL
   [Anonymous], 2006, HDB OPERATIONS RES M
   [Anonymous], AS C SIGN SYST COMP
   [Anonymous], TUTORIAL BAYESIAN ES
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], RATE ADAPTIVE CODES
   [Anonymous], EURASIP IMAGE VIDEO
   [Anonymous], SPIE VIS COMM IM PRO
   Artigas J., 2007, P PCS, P1
   Ascenso J, 2006, IEEE IMAGE PROC, P605, DOI 10.1109/ICIP.2006.312408
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Bjontegaard G., 2001, P ITU T Q 6 SG16 VCE
   Brites C, 2008, IEEE T CIRC SYST VID, V18, P1177, DOI 10.1109/TCSVT.2008.924107
   Brites C, 2006, IEEE IMAGE PROC, P273, DOI 10.1109/ICIP.2006.313178
   Deligiannis N, 2014, IEEE T SIGNAL PROCES, V62, P892, DOI 10.1109/TSP.2013.2295556
   Esmaili GR, 2009, INT CONF ACOUST SPEE, P801, DOI 10.1109/ICASSP.2009.4959705
   Fan XP, 2009, IEEE IMAGE PROC, P1409, DOI 10.1109/ICIP.2009.5414618
   Fox C, 2011, ARTIF INTELL REV, P1
   Guo M, 2007, IEEE INT SYMP CIRC S, P41, DOI 10.1109/ISCAS.2007.378177
   Huang X, 2012, SIGNAL PROCESS-IMAGE, V27, P16, DOI 10.1016/j.image.2011.06.008
   Huang X, 2009, INT CONF ACOUST SPEE, P921, DOI 10.1109/ICASSP.2009.4959735
   Huynh Van Luong, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2633, DOI 10.1109/ICIP.2011.6116207
   Loeliger HA, 2004, IEEE SIGNAL PROC MAG, V21, P28, DOI 10.1109/MSP.2004.1267047
   Macchiavello B, 2009, IEEE T CIRC SYST VID, V19, P1409, DOI 10.1109/TCSVT.2009.2026820
   Martins R, 2009, IEEE T CIRC SYST VID, V19, P1327, DOI 10.1109/TCSVT.2009.2022783
   Meyer PFA, 2005, PROC SPIE, V5960, P857, DOI 10.1117/12.631572
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Toto-Zarasoa V, 2011, IEEE COMMUN LETT, V15, P232, DOI 10.1109/LCOMM.2011.122810.102182
   Varodayan D, 2008, SIGNAL PROCESS-IMAGE, V23, P369, DOI 10.1016/j.image.2008.04.009
   Wang S, 2012, IEEE T CIRC SYST VID, V22, P649, DOI 10.1109/TCSVT.2011.2171263
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Zia A, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY PROCEEDINGS, VOLS 1-7, P2556, DOI 10.1109/ISIT.2007.4557603
NR 34
TC 9
Z9 9
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7327
EP 7355
DI 10.1007/s11042-017-4635-8
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700042
DA 2024-07-18
ER

PT J
AU Wang, CC
   Kuo, WC
   Huang, YC
   Wuu, LC
AF Wang, Chun-Cheng
   Kuo, Wen-Chung
   Huang, Yu-Chih
   Wuu, Lih-Chyau
TI A high capacity data hiding scheme based on re-adjusted GEMD
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EMD(Exploiting modification direction); GEMD(Generalized exploiting
   modification direction); Embedding capacity; RS detection
AB Steganography is a useful technology to protect secret data traveling through the Internet. Recently, Kuo and Wang proposed a useful data hiding scheme based on GEMD(Generalized Exploiting Modification Direction). They claim that the embedding capacity of their scheme is more than 1 bpp(bits per pixel) and keeps good stego-image quality. In addition, the GEMD scheme can prevent RS detection. However, the embedding capacity of GEMD decreases when pixel numbers in the group becomes large. To alleviate this shortcoming, we will propose a data hiding scheme which can embed extra secret data after the GEMD embedding procedure. The major contribution of the proposed scheme is the embedding capacity always maintains 2 bpp which is independent of the pixel numbers in the group. Finally, according to our experiments, our proposed scheme maintains good image quality and also prevents RS detection.
C1 [Wang, Chun-Cheng] Natl Yunlin Univ Sci & Technol, Grad Sch Engn Sci & Technol, Doctoral Program, Touliu, Yunlin, Taiwan.
   [Kuo, Wen-Chung; Wuu, Lih-Chyau] Natl Yunlin Univ Sci & Technol, Dept Comp Sci & Informat Engn, Touliu, Yunlin, Taiwan.
   [Huang, Yu-Chih] Tainan Univ Technol, Dept Informat Management, Tainan, Taiwan.
C3 National Yunlin University Science & Technology; National Yunlin
   University Science & Technology
RP Kuo, WC (corresponding author), Natl Yunlin Univ Sci & Technol, Dept Comp Sci & Informat Engn, Touliu, Yunlin, Taiwan.
EM simonkuo@yuntech.edu.tw
CR Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Kuo W.C., 2014, J INF HIDING MULTIME, V5, P263
   Kuo WC, 2013, IMAGING SCI J, V61, P484, DOI 10.1179/1743131X12Y.0000000011
   Kuo WC, 2017, J INF HIDING MULTIME, V6, P718
   Kuo WC, 2017, APPL SCI, V5, P1033
   Kuo WC, 2017, AEU-INT J ELECTRON C, V69, P1574
   Kuo WC, 2017, J INF HIDING MULTIME, V6, P1167
   Kuo WC, 2016, OPTIK, V127, P1762, DOI 10.1016/j.ijleo.2015.08.056
   Kuo WC, 2016, INFORM PROCESS LETT, V116, P183, DOI 10.1016/j.ipl.2015.08.003
   Lee CF, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P497
   Kieu TD, 2011, EXPERT SYST APPL, V38, P10648, DOI 10.1016/j.eswa.2011.02.122
   Zhang XD, 2006, IEEE COMMUN LETT, V10, P7, DOI 10.1109/LCOMM.2006.01019
NR 12
TC 8
Z9 8
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 6327
EP 6341
DI 10.1007/s11042-017-4541-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800056
DA 2024-07-18
ER

PT J
AU Sun, GX
   Bin, S
AF Sun, Gengxin
   Bin, Sheng
TI A new opinion leaders detecting algorithm in multi-relationship online
   social networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Opinion leaders; Complex network; Signalling; Node importance; Online
   social network
ID CENTRALITY; USERS
AB Opinion leaders in online social networks are important for various fields such as public opinion propagation, marketing management, administrative science and even politics. There are often many kinds of relationships in an online social network. Detecting and identifying opinion leaders depending on any one kind of relationship is inaccurate. In this paper, node importance analysis in multi-relationship online social networks was proposed by signalling based on Multi-subnet Composited Complex Networks Model, and considering the characteristics of multiple relationships which would interrelate with each other. Through node importance under multiple relationships, the novel opinion leader detecting algorithm in multi-relationship online social networks is proposed and approved to be efficient by experiments described in this paper.
C1 [Sun, Gengxin; Bin, Sheng] Qingdao Univ, Coll Data Sci & Software Engn, Qingdao 266071, Peoples R China.
C3 Qingdao University
RP Sun, GX (corresponding author), Qingdao Univ, Coll Data Sci & Software Engn, Qingdao 266071, Peoples R China.
EM sungengxin@qdu.edu.cn
OI Sun, Gengxin/0000-0001-7029-2852; Bin, Sheng/0000-0002-7540-6801
FU Humanity and Social Science Youth foundation of Ministry of Education of
   China [15YJC860001]; Social Science Foundation of Qingdao, China
   [QDSKL150437]; Statistical Science Research Project of China [2015LZ20];
   China Postdoctoral Science Foundation Funded Project [2015 M580571, 2016
   M590612]
FX This work is supported by the Humanity and Social Science Youth
   foundation of Ministry of Education of China (grant no. 15YJC860001).
   This research is also supported by the Social Science Foundation of
   Qingdao, China (grant no. QDSKL150437), Statistical Science Research
   Project of China (grant no. 2015LZ20) and China Postdoctoral Science
   Foundation Funded Project (grant no. 2015 M580571, grant no. 2016
   M590612).
CR [Anonymous], 1965, PEOPLES CHOICE VOTER
   Belz FM, 2010, CREAT INNOV MANAG, V19, P304, DOI 10.1111/j.1467-8691.2010.00571.x
   Bilgram V, 2008, INT J INNOV MANAG, V12, P419, DOI 10.1142/S1363919608002096
   Callaway DS, 2000, PHYS REV LETT, V85, P5468, DOI 10.1103/PhysRevLett.85.5468
   Ding C., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P353
   FREEMAN LC, 1977, SOCIOMETRY, V40, P35, DOI 10.2307/3033543
   Hino K., 2007, P 16 ACM C C INF KNO, P971, DOI DOI 10.1145/1321440.1321588
   Hippel Ericvon., 1988, Das Summa Summarum des Management: Die 25 wichtigsten Werke fur Strategie, Fuhrung und Veranderung, P111, DOI DOI 10.1007/978-3-8349-9320-5_10
   [胡海波 HU Haibo], 2008, [复杂系统与复杂性科学, Complex Systems and Complexity Science], V5, P1
   Huang B, 2014, PROBL ENG
   Kim H, 2012, COMPUT NETW, V56, P983, DOI 10.1016/j.comnet.2011.10.022
   Kratzer J, 2009, J CONSUM RES, V36, P646, DOI 10.1086/599324
   Mazhari S, 2015, J INF SCI, V41, P284, DOI 10.1177/0165551515569651
   MILGRAM S, 1967, PSYCHOL TODAY, V1, P61
   Miller J. C., 2001, SIGIR Forum, P444
   Okamoto K, 2005, LECT NOTES COMPUT SC, V59, P186
   Opsahl T, 2010, SOC NETWORKS, V32, P245, DOI 10.1016/j.socnet.2010.03.006
   Ravi K, 2015, KNOWL-BASED SYST, V89, P14, DOI 10.1016/j.knosys.2015.06.015
   Song XL, 2015, J INF SCI, V41, P89, DOI 10.1177/0165551514558179
   VONHIPPEL E, 1986, MANAGE SCI, V32, P791, DOI 10.1287/mnsc.32.7.791
   Xia Y, 2011, 2011 IE INT S, P1091
   Yu XA, 2010, LECT NOTES COMPUT SC, V6318, P360, DOI 10.1007/978-3-642-16515-3_45
   Zhongwu Zhai, 2008, 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology - Workshops, P398, DOI 10.1109/WIIAT.2008.37
   Zhou Q., 2013, J DATA INFO SCI, V6, P40
NR 24
TC 57
Z9 61
U1 1
U2 60
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4295
EP 4307
DI 10.1007/s11042-017-4766-y
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500014
DA 2024-07-18
ER

PT J
AU Zhu, MY
   Yao, H
   Wu, XK
   Lu, ZH
   Zhu, XQ
   Huang, QH
AF Zhu, Mengyao
   Yao, Huan
   Wu, Xiukun
   Lu, Zhihua
   Zhu, Xiaoqiang
   Huang, Qinghua
TI Gaussian filter for TDOA based sound source localization in multimedia
   surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Microphone array; sound source location; TDOA; Gaussian filter;
   Surveillance
ID TIME-DELAY ESTIMATION; ACOUSTIC SOURCE; SOURCE LOCATION
AB Although multimedia surveillance systems are becoming increasingly ubiquitous in our living environment, automated multimedia surveillance systems based on video camera lacks the robustness and reliability most of the time in several real applications. To overcome this drawback, audio sensory devices have been taken into account in a considerable amount of research. For example, Sound Source Localization (SSL) may indicate potential security risks and could point the camera in that direction. In this paper, a reliable sound source localization based on Time-Difference-Of-Arrival (TDOA) is explored. The novel aspect of our approach includes a TDOA based Gaussian filter to improve the accuracy and stability of sound source localization. The advantage of our proposed algorithm is its extensive integration with various TDOA-based methods in all kinds of microphone array. The Experimental comparison shows significant improvement over the state of the art TDOA-based algorithm.
C1 [Zhu, Mengyao; Yao, Huan; Wu, Xiukun; Zhu, Xiaoqiang; Huang, Qinghua] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Lu, Zhihua] Ningbo Univ, Coll Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
C3 Shanghai University; Ningbo University
RP Zhu, MY (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM zhumengyao@shu.edu.cn; luzhihua@nbu.edu.cn
FU key support Projects of Shanghai Science and Technology Committee
   [16010500100]; National Natural Science Foundation of China [61402277,
   61571279]; Innovation Program of Shanghai Municipal Education Commission
   [15ZZ044]
FX This work was supported by the key support Projects of Shanghai Science
   and Technology Committee (16010500100), the National Natural Science
   Foundation of China (61402277, 61571279), and Innovation Program of
   Shanghai Municipal Education Commission (15ZZ044).
CR [Anonymous], 1981, THESIS
   [Anonymous], 2002, ADAPTIVE FILTER THEO
   Benesty J, 2008, SPRINGER TOP SIGN PR, V1, P1
   Bian XH, 2005, LECT NOTES COMPUT SC, V3468, P19
   Brandstein M., 2013, Microphone arrays: signal processing techniques and applications
   Brandstein MS, 1997, IEEE T SPEECH AUDI P, V5, P45, DOI 10.1109/89.554268
   BUCKLEY KM, 1988, IEEE T ACOUST SPEECH, V36, P953, DOI 10.1109/29.1617
   CARTER GC, 1973, P IEEE, V61, P1497, DOI 10.1109/PROC.1973.9300
   CARTER GC, 1977, J ACOUST SOC AM, V62, P922, DOI 10.1121/1.381623
   Champagne B, 1996, IEEE T SPEECH AUDI P, V4, P148, DOI 10.1109/89.486067
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Crocco M, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2871183
   de Silva GC, 2008, LECT NOTES COMPUT SC, V4903, P466
   EPHRAIM Y, 1985, IEEE T ACOUST SPEECH, V33, P443, DOI 10.1109/TASSP.1985.1164550
   Garofolo John, 1993, TIMIT ACOUSTIC PHONE
   Guo Y., 2010, P INT C ADJ PAP UB C, P411
   HAHN WR, 1973, IEEE T INFORM THEORY, V19, P608, DOI 10.1109/TIT.1973.1055077
   IANNIELLO JP, 1982, IEEE T ACOUST SPEECH, V30, P998, DOI 10.1109/TASSP.1982.1163992
   Johnson D.H., 1992, Array Signal Processing: Concepts andTechniques
   KNAPP CH, 1976, IEEE T ACOUST SPEECH, V24, P320, DOI 10.1109/TASSP.1976.1162830
   Kotus J, 2013, COMM COM INF SC, V368, P107
   Kotus J, 2014, MULTIMED TOOLS APPL, V68, P5, DOI 10.1007/s11042-012-1183-0
   Lee NT, 2010, INT CONF ACOUST SPEE, P4466, DOI 10.1109/ICASSP.2010.5495611
   Ma ZG, 2017, IEEE T MULTIMEDIA, V19, P1558, DOI 10.1109/TMM.2017.2659221
   Pham Q.C., 2010, INT C IMAGE PROCESS, P47, DOI 10.1109/IPTA.2010.5586783
   SCHMIDT RO, 1972, IEEE T AERO ELEC SYS, VAES8, P821, DOI 10.1109/TAES.1972.309614
   SMITH JO, 1987, IEEE T ACOUST SPEECH, V35, P1661, DOI 10.1109/TASSP.1987.1165089
   Stachurski J, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P93, DOI 10.1109/AVSS.2013.6636622
   Svaizer P, 1997, INT CONF ACOUST SPEE, P231, DOI 10.1109/ICASSP.1997.599611
   Teck Wee Chua, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8326, P44, DOI 10.1007/978-3-319-04117-9_5
   WANG H, 1985, IEEE T ACOUST SPEECH, V33, P823, DOI 10.1109/TASSP.1985.1164667
   WAX M, 1983, IEEE T ACOUST SPEECH, V31, P1210, DOI 10.1109/TASSP.1983.1164183
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Zhu L., 2016, IJCAI, P3959
   Zhu L, 2017, IEEE T CYBERNETICS, V47, P3941, DOI 10.1109/TCYB.2016.2591068
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
   Zieger C, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P314, DOI 10.1109/AVSS.2009.49
NR 41
TC 14
Z9 15
U1 2
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3369
EP 3385
DI 10.1007/s11042-017-5129-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600026
DA 2024-07-18
ER

PT J
AU Memo, A
   Zanuttigh, P
AF Memo, Alvise
   Zanuttigh, Pietro
TI Head-mounted gesture controlled interface for human-computer interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Head mounted display; Gesture recognition; Human-computer interface;
   Augmented reality; Depth data
ID RECOGNITION; FUSION
AB This paper proposes a novel human-computer interaction system exploiting gesture recognition. It is based on the combined usage of an head-mounted display and a multi-modal sensor setup including also a depth camera. The depth information is used both to seamlessly include augmented reality elements into the real world and as input for a novel gesture-based interface. Reliable gesture recognition is obtained through a real-time algorithm exploiting novel feature descriptors arranged in a multi-dimensional structure fed to an SVM classifier. The system has been tested with various augmented reality applications including an innovative human-computer interaction scheme where virtual windows can be arranged into the real world observed by the user.
C1 [Memo, Alvise; Zanuttigh, Pietro] Univ Padua, Dept Informat Engn, Padua, Italy.
C3 University of Padua
RP Zanuttigh, P (corresponding author), Univ Padua, Dept Informat Engn, Padua, Italy.
EM alvise.memo@gmail.com; zanuttigh@dei.unipd.it
RI Zanuttigh, Pietro/AAB-9555-2019
OI Zanuttigh, Pietro/0000-0002-9502-2389
CR Armesto L, 2007, INT J ROBOT RES, V26, P577, DOI 10.1177/0278364907079283
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bai Huidong, 2014, CHI 14 EXTENDED ABST, P1321
   Bambach S, 2015, P IEEE COMP SOC WORK
   Baraldi L, 2014, IEEE COMPUT SOC CONF, P702, DOI 10.1109/CVPRW.2014.107
   Betancourt A, 2014, IEEE COMPUT SOC CONF, P600, DOI 10.1109/CVPRW.2014.92
   BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Colaco Andrea., 2013, P 26 ANN ACM S USER, P227
   Dinh DL, 2014, MULTIMED TOOLS APPL, P1
   Dominio F., 2014, COMPUTER VISION MACH, P215
   Dominio F, 2014, PATTERN RECOGN LETT, V50, P101, DOI 10.1016/j.patrec.2013.10.010
   Dominio Fabio., 2013, Proceedings of the 4th ACM/IEEE international workshop on Analysis and retrieval of tracked events and motion in imagery stream, P9
   Hanheide M, 2006, THESIS
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   Kapuscinski T, 2015, INT J ADV ROBOT SYST, V12, DOI 10.5772/60091
   Kumar Jayant, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P18, DOI 10.1109/CVPRW.2015.7301344
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Liu Y, 2016, SIGNAL PROCESS, V125, P237, DOI 10.1016/j.sigpro.2016.01.019
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Marin G, 2014, IEEE IMAGE PROC, P1565, DOI 10.1109/ICIP.2014.7025313
   Memo A, 2015, P SMART TOOLS APPS C
   Michel D, 2014, LECT NOTES COMPUT SC, V8887, P793, DOI 10.1007/978-3-319-14249-4_76
   Nanni L, 2013, INT J AUTOMATED IDEN, V5, P47
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Premerlani W., 2009, Direction cosine matrix imu: Theory, P13
   Qin SX, 2014, J SIGNAL PROCESS SYS, V74, P47, DOI 10.1007/s11265-013-0778-7
   Ren Z, 2011, PROC FL STATE HORTIC, V124, P1
   Ren Z., 2011, P 19 ACM INT C MULTI, P1093
   Rogez Gregory., 2014, Computer Vision-ECCV 2014 Workshops, P356
   Saric Marin, 2011, LibHand: A Library for Hand Articulation. Version 0.9
   Serra G., 2013, Proceedings of the 3rd ACM international workshop on Interactive multimedia on mobile portable devices, P31, DOI DOI 10.1145/2505483.2505490
   Shaohua Wan, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P36, DOI 10.1109/CVPRW.2015.7301346
   Supancic JS, 2015, IEEE I CONF COMP VIS, P1868, DOI 10.1109/ICCV.2015.217
   Suryanarayan Poonam, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3105, DOI 10.1109/ICPR.2010.760
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Yang JC, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0145800
   Zanuttigh Pietro., 2016, Time-of-flight and structured light depth cameras
   Zhang CY, 2015, COMPUT VIS IMAGE UND, V139, P29, DOI 10.1016/j.cviu.2015.05.010
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhou SL, 2014, SENSORS-BASEL, V14, P15641, DOI 10.3390/s140915641
NR 43
TC 56
Z9 60
U1 1
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 27
EP 53
DI 10.1007/s11042-016-4223-3
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400002
DA 2024-07-18
ER

PT J
AU Yao, XX
   Zhang, YF
   Bao, FX
   Liu, YF
   Zhang, CM
AF Yao, Xunxiang
   Zhang, Yunfeng
   Bao, Fangxun
   Liu, Yifang
   Zhang, Caiming
TI The blending interpolation algorithm based on image features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blending interpolant; Fractal dimension; Local adaptive threshold;
   Parameters selection
ID RATIONAL INTERPOLATION; SUPERRESOLUTION
AB In this paper, we develop a blending interpolation model with help of classical bivariate rational interpolation. The blending model is an organic unity which integrates rational fractal interpolation with bivariate rational interpolation, and it is identified uniquely by the values of scaling factor and shape parameters. Fractal is a powerful tool for the description of the complexity and irregularity of geometric objects, and we introduce the fractal dimension to describe texture. A new local adaptive threshold method which based on local fractal dimension (LFD) is proposed to divide images into texture region and non-texture region. Rational fractal interpolation and rational interpolation are used in texture region and non-texture region respectively. Especially in rational fractal interpolation model, a new method for calculating the scaling factor is proposed, which exploits the relationship between global fractal dimension (GFD) and LFD. Finally, an approach of selecting shape parameters is utilized to further improve the quality of interpolated image. Our extensive experimental results demonstrate that the proposed blending model based image features achieves competitive performance with the state-of-the-art interpolation algorithms.
C1 [Yao, Xunxiang; Zhang, Yunfeng; Zhang, Caiming] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Shandong, Peoples R China.
   [Bao, Fangxun] Shandong Univ, Sch Math, Jinan 250100, Shandong, Peoples R China.
   [Liu, Yifang] Univ Buffalo State Univ New York, Dept Comp Sci & Engn, Albany, NY USA.
C3 Shandong University of Finance & Economics; Shandong University
RP Bao, FX (corresponding author), Shandong Univ, Sch Math, Jinan 250100, Shandong, Peoples R China.
EM fxbao@sdu.edu.cn
RI Zhang, Caiming/AHD-6558-2022
OI Zhang, Caiming/0000-0002-6365-6221
FU National Natural Science Foundation of China [61373080, 61672018];
   Fostering Project of Dominant Discipline and Talent Team of Shandong
   Province Higher Education Institutions; Natural Science Foundation of
   Shandong Province [ZR2015AM007]; National Natural Science Foundation of
   China [61373080, 61672018]; Fostering Project of Dominant Discipline and
   Talent Team of Shandong Province Higher Education Institutions; Natural
   Science Foundation of Shandong Province [ZR2015AM007]
FX This work was supported by National Natural Science Foundation of
   China(No. 61373080,61672018), the Fostering Project of Dominant
   Discipline and Talent Team of Shandong Province Higher Education
   Institutions and Natural Science Foundation of Shandong Province (No.
   ZR2015AM007).
CR [Anonymous], 2007, Computer Vision
   [Anonymous], 2014, ACCV WORKSH IM REST
   [Anonymous], 2015, 2015 IEEE INT C MULT
   Carrato S, 2000, IEEE SIGNAL PROC LET, V7, P132, DOI 10.1109/97.844630
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1382, DOI 10.1109/TIP.2012.2231086
   Duan Q, 2006, COMPUT MATH APPL, V52, P975, DOI 10.1016/j.camwa.2006.04.021
   He SH, 2013, 2013 3RD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT), P1034, DOI 10.1109/ICCSNT.2013.6967280
   Hu M, 2006, J COMPUT APPL MATH, V195, P46, DOI 10.1016/j.cam.2005.07.011
   Jeong S, 2015, IEEE T CONSUM ELECTR, V61, P353, DOI 10.1109/TCE.2015.7298295
   Jha AK, 2015, 2015 4TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION ICIEV 15
   Jian M, 2015, IEEE T CIRC SYST VID, V25, P1761, DOI 10.1109/TCSVT.2015.2400772
   Jian MW, 2013, PATTERN RECOGN, V46, P3091, DOI 10.1016/j.patcog.2013.03.020
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   MANDELBROT BB, 1984, NATURE, V308, P721, DOI 10.1038/308721a0
   MANDELBROT BB, 1985, PHYS SCRIPTA, V32, P257, DOI 10.1088/0031-8949/32/4/001
   Matsumoto S, 2012, OPTIM LETT, V6, P1265, DOI 10.1007/s11590-011-0371-6
   MILLARD JB, 1967, IEEE T INFORM THEORY, V13, P341, DOI 10.1109/TIT.1967.1053982
   Novianto S, 2003, PATTERN RECOGN LETT, V24, P365, DOI 10.1016/S0167-8655(02)00261-1
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Viswanathan P, 2015, RACSAM REV R ACAD A, V109, P483, DOI 10.1007/s13398-014-0197-z
   Viswanathan P, 2014, J MATH ANAL APPL, V419, P804, DOI 10.1016/j.jmaa.2014.05.019
   Xu HT, 2013, IEEE T CIRC SYST VID, V23, P1740, DOI 10.1109/TCSVT.2013.2248305
   Xu Y., 2006, 2006 IEEE COMP SOC C, P1932
   Xu Y, 2011, IEEE I CONF COMP VIS, P1219, DOI 10.1109/ICCV.2011.6126372
   Xu Y, 2010, PROC CVPR IEEE, P161, DOI 10.1109/CVPR.2010.5540217
   Xu Y, 2009, INT J COMPUT VISION, V83, P85, DOI 10.1007/s11263-009-0220-6
   Yunfeng Zhang, 2011, Proceedings of the 2011 Eighth International Symposium on Voronoi Diagrams in Science and Engineering (ISVD 2011), P200, DOI 10.1109/ISVD.2011.34
   Zhai MY, 2011, IEEE T POWER DELIVER, V26, P1864, DOI 10.1109/TPWRD.2011.2129540
   Zhang CM, 2013, IEEE IMAGE PROC, P1046, DOI 10.1109/ICIP.2013.6738216
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
   Zhang YQ, 2015, IEEE T IMAGE PROCESS, V24, P2797, DOI 10.1109/TIP.2015.2431435
   Zhang YF, 2012, J COMPUT ANAL APPL, V14, P1303
NR 33
TC 4
Z9 6
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1971
EP 1995
DI 10.1007/s11042-017-4379-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400023
DA 2024-07-18
ER

PT J
AU Chyung, YJ
   Lee, JY
   Jung, SY
   Kim, PW
AF Chyung, Yun Joo
   Lee, Jee Yon
   Jung, Sun Young
   Kim, Pyoung Won
TI Weighted aggregation and fuzzy-concept-guided signal resemblance and
   expansion for video format conversion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deinterlacing; Super resolution; High-definition television;
   Convergence; Computer; Immersion education; Fuzzy concept
ID ALGORITHM; INTERPOLATION; MOTION; LOGIC
AB In this paper, we propose an efficient deinterlacing method for HDTV that preserves image structures, edges, and details. In the human visual system, the eyes are more sensitive to high-frequency information such as edge details than low-frequency information such as image background. Therefore, averaging low-pass filter results is not effective for image enhancement. The proposed method is a weighted filtering approach that generates a half-pixel 9-by-9 edge-based line average window. We also propose pixel-resemblance- and pixel-expansion-based fuzzy weights, which are assigned using a triangular membership function. Compared to conventional format conversion methods, the proposed method outperforms all benchmarks in terms of both objective and subjective qualities.
C1 [Chyung, Yun Joo; Lee, Jee Yon; Jung, Sun Young; Kim, Pyoung Won] Incheon Natl Univ, Inst Convergence Sci, 12 Gaetbeol Ro, Incheon 21999, South Korea.
   [Chyung, Yun Joo; Lee, Jee Yon; Jung, Sun Young; Kim, Pyoung Won] Incheon Natl Univ, Inst Technol, 12 Gaetbeol Ro, Incheon 21999, South Korea.
C3 Incheon National University; Incheon National University
RP Kim, PW (corresponding author), Incheon Natl Univ, Inst Convergence Sci, 12 Gaetbeol Ro, Incheon 21999, South Korea.; Kim, PW (corresponding author), Incheon Natl Univ, Inst Technol, 12 Gaetbeol Ro, Incheon 21999, South Korea.
EM pwkim@inu.ac.kr
OI Kim, Pyoung Won/0000-0002-3621-9480
FU Institutes of Convergence Science and Technology, Incheon National
   University
FX This work was supported by the Institutes of Convergence Science and
   Technology, Incheon National University Research Grant in 2015.
CR [Anonymous], 2 INT C IM PROC THEO
   Aubertin P, 2012, IEEE T VLSI SYST, V20, P2031, DOI 10.1109/TVLSI.2011.2170204
   Brox P, 2008, P 2008 IPMU, P1175
   Brox P, 2014, IEEE T CONSUM ELECTR, V60, P375, DOI 10.1109/TCE.2014.6937321
   Chen T, 2000, OPT ENG, V39, P2101, DOI 10.1117/1.1305262
   Chen X, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.10.107402
   DOYLE T, 1998, P 2 INT WORKSH SIGN, P412
   Jakhetiya V, 2017, IEEE T MULTIMEDIA, V19, P93, DOI 10.1109/TMM.2016.2609419
   Jeon G, 2006, IEEE T CONSUM ELECTR, V52, P1013, DOI 10.1109/TCE.2006.1706501
   Jeon G, 2009, OPT ENG, V48, DOI 10.1117/1.3265713
   Jeon G, 2009, IEEE T FUZZY SYST, V17, P1245, DOI 10.1109/TFUZZ.2009.2026638
   Jeon G, 2009, IEEE T CIRC SYST VID, V19, P842, DOI 10.1109/TCSVT.2009.2017309
   Jeon G, 2009, INFORM SCIENCES, V179, P2194, DOI 10.1016/j.ins.2009.01.044
   Jeon G, 2009, IMAGE VISION COMPUT, V27, P425, DOI 10.1016/j.imavis.2008.06.001
   Kovacevic J, 1997, IEEE T IMAGE PROCESS, V6, P339, DOI 10.1109/83.551707
   Kuo CJ, 1996, IEEE T CIRC SYST VID, V6, P317, DOI 10.1109/76.499841
   Lee K, 2013, IEEE T CONSUM ELECTR, V59, P182, DOI 10.1109/TCE.2013.6490258
   Li Y., 2002, IMAGE DATABASES, P261
   Mahvash H, 2011, IET IMAGE PROCESS, V6, P1041
   Park MK, 2003, IEEE T CONSUM ELECTR, V49, P1508, DOI 10.1109/TCE.2003.1261260
   Park SJ, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.2.023003
   Riquelme J, 2007, LECT NOTES ARTIF INT, V4578, P349
   Wang J, 2015, J DISP TECHNOL, V11, P183, DOI 10.1109/JDT.2014.2366997
   Wu J., 2016, SENSORS, V16, P1, DOI DOI 10.1186/S12885-016-2582-9
   Wu JJ, 2014, J DISP TECHNOL, V10, P746, DOI 10.1109/JDT.2014.2319232
   Wu JJ, 2011, OPT ENG, V50, DOI 10.1117/1.3572125
   Zhang H, 2015, IET IMAGE PROCESS, V9, P450, DOI 10.1049/iet-ipr.2014.0183
NR 27
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 24847
EP 24858
DI 10.1007/s11042-017-4641-x
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300015
DA 2024-07-18
ER

PT J
AU Li, B
   Lu, YJ
   Johan, H
   Fares, R
AF Li, Bo
   Lu, Yijuan
   Johan, Henry
   Fares, Ribel
TI Sketch-based 3D model retrieval utilizing adaptive view clustering and
   semantic information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sketch-based 3D model retrieval; Semantic information; Adaptive view
   sampling; Viewpoint entropy; Sketch recognition; Machine learning; Shape
   context matching
ID SHAPE; ALGORITHM; SELECTION
AB Searching for relevant 3D models based on hand-drawn sketches is both intuitive and important for many applications, such as sketch-based 3D modeling and recognition, human computer interaction, 3D animation, game design, and etc. In this paper, our target is to significantly improve the current sketch-based 3D retrieval performance in terms of both accuracy and efficiency. We propose a new sketch-based 3D model retrieval framework by utilizing adaptive view clustering and semantic information. It first utilizes a proposed viewpoint entropy-based 3D information complexity measurement to guide adaptive view clustering of a 3D model to shortlist a set of representative sample views for 2D-3D comparison. To bridge the gap between the query sketches and the target models, we then incorporate a novel semantic sketch-based search approach to further improve the retrieval performance. Experimental results on several latest benchmarks have evidently demonstrated our significant improvement in retrieval performance.
C1 [Li, Bo] Univ Southern Mississippi, Sch Comp, 730 E Beach Blvd, Long Beach, MS 39560 USA.
   [Lu, Yijuan; Fares, Ribel] Texas State Univ, Dept Comp Sci, 601 Univ Dr, San Marcos, TX 78666 USA.
   [Johan, Henry] Nanyang Technol Univ, Fraunhofer IDM NTU, 50 Nanyang Ave, Singapore 639798, Singapore.
C3 University of Southern Mississippi; Texas State University System; Texas
   State University San Marcos; Nanyang Technological University
RP Li, B (corresponding author), Univ Southern Mississippi, Sch Comp, 730 E Beach Blvd, Long Beach, MS 39560 USA.
EM bo.li@usm.edu; lu@txstate.edu; hjohan@fraunhofer.sg;
   ribelfares@gmail.com
RI Li, Bo/AAA-8968-2020; Li, bo/IWL-9318-2023; LU, YIJUAN/GNM-8769-2022
OI Li, Bo/0000-0002-7294-6888; LU, YIJUAN/0000-0002-9855-8365; LI,
   BO/0000-0002-3330-8103
FU Texas State University Research Enhancement Program (REP); Army Research
   Office [W911NF-12-1-0057]; NSF CNS [1305302]; National Research
   Foundation, Prime Minister's Office, Singapore under its International
   Research Centres in Singapore Funding Initiative; Direct For Computer &
   Info Scie & Enginr; Division Of Computer and Network Systems [1305302]
   Funding Source: National Science Foundation
FX The work of Bo Li and Yijuan Lu is supported by the Texas State
   University Research Enhancement Program (REP), Army Research Office
   grant W911NF-12-1-0057, and NSF CNS 1305302 to Dr. Yijuan Lu.; The
   research done by Henry Johan in Fraunhofer IDM@NTU is supported by the
   National Research Foundation, Prime Minister's Office, Singapore under
   its International Research Centres in Singapore Funding Initiative.
CR [Anonymous], 2013, P EUR WORKSH 3D OBJ, DOI DOI 10.2312/3DOR/3DOR13/049-056
   [Anonymous], 2007, P MIR 2007
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bezdek James C., 1981, PATTERN RECOGN
   Eitz M., 2012, ACM T GRAPHIC, V31, P1, DOI DOI 10.1145/2185520.2335395
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Eitz M, 2011, IEEE T VIS COMPUT GR, V17, P1624, DOI 10.1109/TVCG.2010.266
   Fang Y, 2015, PROC CVPR IEEE, P2319, DOI 10.1109/CVPR.2015.7298845
   Gong BQ, 2013, IEEE T MULTIMEDIA, V15, P369, DOI 10.1109/TMM.2012.2231059
   Jayanti S, 2006, COMPUT AIDED DESIGN, V38, P939, DOI 10.1016/j.cad.2006.06.007
   JONKER R, 1987, COMPUTING, V38, P325, DOI 10.1007/BF02278710
   LI B., 2012, EurographicsWorkshop on 3D Object Retrieval, P109
   Li B., 2013, 2013 IEEE International Symposium on Sensorless Control for Electrical Drives and Predictive Control of Electrical Drives and Power Electronics (SLED/PRECEDE), P1, DOI DOI 10.1109/ICMEW.2013.6618316
   Li B, 2012, MULTIMED TOOLS APPL, P1
   Li B., 2013, EUR WORKSH 3D OBJ RE, P89, DOI DOI 10.2312/3DOR/3DOR13/089
   Li B, 2014, EUR WORKSH 3D OBJ RE, P121
   Li B, 2015, COMPUT VIS IMAGE UND, V131, P1, DOI 10.1016/j.cviu.2014.10.006
   Li B, 2014, COMPUT VIS IMAGE UND, V119, P57, DOI 10.1016/j.cviu.2013.11.008
   Li B, 2013, MULTIMED TOOLS APPL, V62, P821, DOI 10.1007/s11042-011-0873-3
   Mokhtarian F, 2005, PATTERN RECOGN, V38, P1021, DOI 10.1016/j.patcog.2004.11.021
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Page DL, 2003, IEEE IMAGE PROC, P229
   Powers D.M.W., 2007, Technical Report, V2, P37
   Rossignac J, 2005, VISUAL COMPUT, V21, P985, DOI 10.1007/s00371-005-0362-7
   Saleem W, 2011, COMPUT GRAPH-UK, V35, P580, DOI 10.1016/j.cag.2011.03.006
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Suyu Hou, 2005, Computer-Aided Design and Applications, V2, P155
   Takahashi S, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P495
   Vázquez PP, 2003, COMPUT GRAPH FORUM, V22, P689, DOI 10.1111/j.1467-8659.2003.00717.x
   Vranic DV, 2004, THESIS
   Wang F, 2015, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2015.7298797
   Wessel Raoul., 2009, Eurographics 2009 Workshop on 3D Object Retrieval, P53
   YOON S.M., 2010, Proceedings of the international conference on Multimedia, P193
   Zhu F, 2016, AAAI CONF ARTIF INTE, P3683
   Zhu J, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1227, DOI 10.1145/2733373.2806323
NR 36
TC 17
Z9 19
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26603
EP 26631
DI 10.1007/s11042-016-4187-3
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500048
DA 2024-07-18
ER

PT J
AU Mohanapriya, D
   Mahesh, K
AF Mohanapriya, D.
   Mahesh, K.
TI A novel foreground region analysis using NCP-DBP texture pattern for
   robust visual tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Binary labeling; Boundary pattern; Computer vision; Clustering;
   Classification; Object tracking
ID SPARSE REPRESENTATION; OBJECT TRACKING
AB Robust visual tracking is the important stage in the computer vision applications such as robotics, man-free control systems, and the visual surveillance. Accurate motion states estimation and the target representation in visual tracking system are based on the appearances of the target. The factor affects the learning of target representation is the accumulated error due to the pose, illumination changes, and the uneven background. The presence of dynamic background and the shadowing effects causes the visual drift and destructive information. Besides, the misclassification of target region induces the false detection of moving objects. The K-means and Fuzzy-C-means clustering algorithms are available to segment the foreground/background and suppress the shadow region on the basis of the non-changing background of the surveillance area. This paper proposes the novel background normalization technique with textural pattern analysis to suppress the shadow region. The Neighborhood Chain Prediction (NCP) algorithm is used to cluster the uneven background and the Differential Boundary Pattern (DBP) extracts the texture of the video frame to suppress the shadow pixels present in the frame. The lower intensity estimation and the prediction of the area around the lower intensity in proposed work enhance the pixels for shadow removal. The shadow-free frame split up into several grids and the histograms of features are extracted from the grid formatted frame. Finally, the Machine Level Classification (MLC) finds the matching grid corresponds to the tracking region and provides the binary labeling to separate the background and foreground. The proposed DBP-based visual tracking system is high robustness over the sudden illumination changes and the dynamic background due to the texture pattern analysis. The comparison of proposed NCP-DBP combination with the existing segmentation techniques regarding the accuracy, precision, recall, F-measure, success and error rate assured the effectiveness in visual tracking applications.
C1 [Mohanapriya, D.; Mahesh, K.] Alagappa Univ, Dept Comp Applicat, Karaikkudi 630003, Tamil Nadu, India.
C3 Alagappa University
RP Mohanapriya, D (corresponding author), Alagappa Univ, Dept Comp Applicat, Karaikkudi 630003, Tamil Nadu, India.
EM mohanapriya.researchscholar@gmail.com
RI , Mohanapriya/I-3090-2018
OI , Mohanapriya/0000-0003-2961-0534
CR [Anonymous], 2014, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.230
   Bai TX, 2015, IEEE T CYBERNETICS, V45, P663, DOI 10.1109/TCYB.2014.2332279
   Bai TX, 2014, IEEE T IND INFORM, V10, P538, DOI 10.1109/TII.2013.2272089
   Bai TX, 2012, PATTERN RECOGN, V45, P2390, DOI 10.1016/j.patcog.2011.12.004
   Choi W, 2012, LECT NOTES COMPUT SC, V7575, P215, DOI 10.1007/978-3-642-33765-9_16
   Jeyabharathi D, 2016, J VIS COMMUN IMAGE R, V40, P816, DOI 10.1016/j.jvcir.2016.08.011
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Li X, 2013, IEEE T PATTERN ANAL, V35, P863, DOI 10.1109/TPAMI.2012.166
   Li Y, 2014, IEEE T IMAGE PROCESS, V23, P1666, DOI 10.1109/TIP.2014.2302896
   Lin L, 2012, IEEE T IMAGE PROCESS, V21, P4844, DOI 10.1109/TIP.2012.2211373
   Liu N, 2015, IEEE T CYBERNETICS, V45, P89, DOI 10.1109/TCYB.2014.2320493
   Liu X, 2015, IEEE T NEUR NET LEAR, V26, P1060, DOI 10.1109/TNNLS.2014.2333751
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P2502, DOI 10.1109/TIP.2015.2419084
   Liwicki S, 2015, IEEE T IMAGE PROCESS, V24, P2955, DOI 10.1109/TIP.2015.2428052
   Liwicki S, 2012, IEEE T NEUR NET LEAR, V23, P1624, DOI 10.1109/TNNLS.2012.2208654
   Lu JW, 2014, IEEE T INF FOREN SEC, V9, P51, DOI 10.1109/TIFS.2013.2291969
   Makris A, 2014, IEEE T GEOSCI REMOTE, V52, P7684, DOI 10.1109/TGRS.2014.2316600
   Nayak Nandita M, 2015, IEEE Trans Image Process, V24, P2025, DOI 10.1109/TIP.2015.2404034
   Park C, 2015, IEEE T PATTERN ANAL, V37, P611, DOI 10.1109/TPAMI.2014.2346202
   Salti S, 2015, IEEE T CIRC SYST VID, V25, P609, DOI 10.1109/TCSVT.2014.2355695
   Sui Y, 2015, IEEE T IMAGE PROCESS, V24, P4686, DOI 10.1109/TIP.2015.2462076
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang L, 2015, IEEE T IMAGE PROCESS, V24, P1424, DOI 10.1109/TIP.2015.2403231
   Wu L, 2015, IEEE T MULTIMEDIA, V17, P1137, DOI 10.1109/TMM.2015.2443556
   Yuan Y, 2015, IEEE T MULTIMEDIA, V17, P1125, DOI 10.1109/TMM.2015.2440996
   Zhang L, 2014, PROC CVPR IEEE, P1266, DOI 10.1109/CVPR.2014.165
   Zhang SL, 2015, IEEE T MULTIMEDIA, V17, P265, DOI 10.1109/TMM.2015.2390044
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 28
TC 1
Z9 1
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 25731
EP 25748
DI 10.1007/s11042-017-4409-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500012
DA 2024-07-18
ER

PT J
AU Peng, YJ
   Ma, YR
   Wang, YH
   Shan, JL
AF Peng, Yanjun
   Ma, Yingran
   Wang, Yuanhong
   Shan, Junliang
TI The application of interactive dynamic virtual surgical simulation
   visualization method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive dynamic simulation; Surgical simulation; Medical
   visualization; Soft tissue deformation
ID DEFORMABLE MODELS; DEFORMATIONS
AB In this paper, an interactive dynamic simulation method is proposed to solve computational models of soft tissue undergoing large deformation, collision detection, and volume conservation in medical surgical simulation visualization. During the process of implementation of the interactive dynamic simulation method, the point-based method is used to simulate the elastic solids undergoing large deformations and the position-based method is used to simulate the objects collision, friction and volume conservation. Numerical results demonstrate that the proposed method improves the efficiency and stability of the response of heterogeneous soft tissue undergoing contact or even the multi-organs interactions, and it can be extended to interactive biopsy and cutting simulation.
C1 [Peng, Yanjun; Ma, Yingran; Wang, Yuanhong; Shan, Junliang] Shandong Univ Sci & Technol, Coll Informat Sci & Engn, Qingdao 266590, Peoples R China.
   [Peng, Yanjun] Shandong Univ Sci & Technol, Shandong Prov Key Lab Wisdom Min Informat Technol, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Peng, YJ (corresponding author), Shandong Univ Sci & Technol, Coll Informat Sci & Engn, Qingdao 266590, Peoples R China.; Peng, YJ (corresponding author), Shandong Univ Sci & Technol, Shandong Prov Key Lab Wisdom Min Informat Technol, Qingdao 266590, Peoples R China.
EM pengyanjuncn@163.com
FU Natural Science Foundation of Shandong Province [ZR2015FM013]; National
   Natural Science Foundation of China [61502279]; National key research
   and development project of China [2016YFC0801406]; National key research
   and development project of the Shandong Province [2016GSF120012];
   Special Project Fund of Taishan Scholars of Shandong Province; Leading
   Talent Project of Shandong University of Science and Technology
FX This work is supported by the Natural Science Foundation of Shandong
   Province under Grant No. ZR2015FM013, the National Natural Science
   Foundation of China under Grant No. 61502279, the National key research
   and development project of China under Grant No. 2016YFC0801406, the
   National key research and development project of the Shandong Province
   under Grant No. 2016GSF120012, and by Special Project Fund of Taishan
   Scholars of Shandong Province, Leading Talent Project of Shandong
   University of Science and Technology.
CR [Anonymous], 2003, P ACM SIGGRAPH EUR S
   Basdogan C, 2007, IEEE COMPUT GRAPH, V27, P54, DOI 10.1109/MCG.2007.51
   BELYTSCHKO T, 1994, INT J NUMER METH ENG, V37, P229, DOI 10.1002/nme.1620370205
   Bro-Nielsen M, 1998, P IEEE, V86, P490, DOI 10.1109/5.662874
   Cotin S, 1999, IEEE T VIS COMPUT GR, V5, P62, DOI 10.1109/2945.764872
   Debunne G, 2001, COMP GRAPH, P31, DOI 10.1145/383259.383262
   Diziol Raphael., 2011, Proceedings of the 2011 ACM SIGGRAPH/eurographics symposium on computer animation, P237, DOI DOI 10.1145/2019406.2019438
   Doblaré M, 2005, COMPUT METHOD APPL M, V194, P801, DOI 10.1016/j.cma.2004.06.031
   Gerszewski D., 2009, SCA 09, P133, DOI DOI 10.1145/1599470.1599488
   Gray JP, 2001, COMPUT METHOD APPL M, V190, P6641, DOI 10.1016/S0045-7825(01)00254-7
   Guilkey JE, 2006, J BIOMECH, V39, P2074, DOI 10.1016/j.jbiomech.2005.06.017
   Hieber SE, 2008, J COMPUT PHYS, V227, P9195, DOI 10.1016/j.jcp.2008.05.016
   Jones B, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2560795
   Kelager M, 2010, P WORKSH VIRT REAL I, P31, DOI [10.2312/PE/vriphys/vriphys10/031-037, DOI 10.2312/PE/VRIPHYS/VRIPHYS10/031-037]
   Meier U, 2005, COMPUT METH PROG BIO, V77, P183, DOI 10.1016/j.cmpb.2004.11.002
   Molinari E, 2005, IEEE T BIO-MED ENG, V52, P1514, DOI 10.1109/TBME.2005.851529
   Monaghan JJ, 2005, REP PROG PHYS, V68, P1703, DOI 10.1088/0034-4885/68/8/R01
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Muller M, 2008, VRIPHYS 2008, P2008
   Muller M., 2004, P 2004 ACM SIGGRAPHE, P141, DOI [DOI 10.1145/1028523.1028542, 10.1145/1028523.1028542, 10]
   Nealen A, 2006, COMPUT GRAPH FORUM, V25, P809, DOI 10.1111/j.1467-8659.2006.01000.x
   Payan Y., 2012, SOFA MULTI MODEL FRA, P283
   Peterlík I, 2012, LECT NOTES COMPUT SC, V7510, P50, DOI 10.1007/978-3-642-33415-3_7
   Terzopoulos D., 1988, Visual Computer, V4, P306, DOI 10.1007/BF01908877
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   Teschner M, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P312, DOI 10.1109/CGI.2004.1309227
NR 26
TC 11
Z9 12
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25197
EP 25214
DI 10.1007/s11042-016-4331-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300036
DA 2024-07-18
ER

PT J
AU Hu, ZZ
   Bai, DF
AF Hu, Zhaozheng
   Bai, Dongfang
TI Planar object detection from 3D point clouds based on pyramid voxel
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Plane detection; Plane index; Pyramid voxel; Eigen value decomposition;
   Voxel combination
ID EXTRACTION; RANSAC
AB Planar detection is a fundamental task in many computer vision applications. This paper proposed a fast and reliable plane detection method from 3D point clouds to address the high computation cost problem in existing methods. The 3D space is first partitioned into pyramid voxels. Each 3D point is assigned to one voxel at each pyramid layer so that all the 3D points are represented by pyramid voxels. For each voxel, we apply the Eigen value decomposition to analyze 3D points inside and propose an index for fast plane detection. Especially, the plane index is efficiently computed with no explicit Eigen value decomposition to enhance the computation. The detected planar voxels are analyzed and merged for planar object detection based on geometric relationship between voxels. The proposed method uses voxel-wise instead of point-wise processing of the 3D point clouds so that it can greatly enhance the computation efficiency yet with good detection results. The proposed method has been validated with actual 3D point clouds collected by RGB-D sensor of Kinect 1.0 in both indoor and outdoor environments. The results demonstrate that the proposed method can quickly detect single and multiple planar objects in both environments. The precision and the accuracy of the proposed method are 97.1% and 94.5%, respectively. Compared to existing methods (e.g., Hough Transform, RANSAC), the proposed method can greatly enhance the computation efficiency in several orders of magnitudes.
C1 [Hu, Zhaozheng] Wuhan Univ Technol, ITS Res Ctr, Wuhan 430063, Hubei, Peoples R China.
   [Hu, Zhaozheng; Bai, Dongfang] Hebei Univ Technol, Sch Informat Engn, Tianjin 300401, Peoples R China.
C3 Wuhan University of Technology; Hebei University of Technology
RP Hu, ZZ (corresponding author), Wuhan Univ Technol, ITS Res Ctr, Wuhan 430063, Hubei, Peoples R China.; Hu, ZZ (corresponding author), Hebei Univ Technol, Sch Informat Engn, Tianjin 300401, Peoples R China.
EM zzhu@whut.edu.cn
RI Hu, Zhaozheng/AGC-2475-2022
OI Hu, Zhaozheng/0000-0002-7204-2459
FU National Natural Science Foundation of China (NSFC) [51208168,
   51679181]; Major Project of Technological Innovation of Hubei Province
   [2016AAA007]; Youth Chenguang Plan of Wuhan City [2015070404010196];
   Youth Top-Notch Talent Plan of Hebei and Hebei Department of Education
   [BJ2014013]
FX The work presented in this paper was funded by National Natural Science
   Foundation of China (NSFC) (No. 51208168, 51679181), the Major Project
   of Technological Innovation of Hubei Province (No. 2016AAA007), the
   Youth Chenguang Plan of Wuhan City (No. 2015070404010196), and the Youth
   Top-Notch Talent Plan of Hebei and Hebei Department of Education (No.
   BJ2014013).
CR [Anonymous], LNCS
   Arróspide J, 2010, IET INTELL TRANSP SY, V4, P149, DOI 10.1049/iet-its.2009.0073
   Bauer J., 2003, PROC 27 WORKSHOP AUS, P253
   Borrmann D, 2011, 3D RES, V2, DOI 10.1007/3DRes.02(2011)3
   Bosse M., P 2009 IEEE INT C RO, P4312, DOI [10.1109/ROBOT.2009.5152851, DOI 10.1109/ROBOT.2009.5152851]
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Choi S, 2014, INT C CONTR AUTOMAT, P1076, DOI 10.1109/ICCAS.2014.6987936
   Deschaud J. -E, 2010, P 3DPVT, P44
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fouhey D. F., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P336, DOI 10.1109/ICPR.2010.91
   Fujiwara T, 2013, C IND ELECT APPL, P1863
   Holzinger Andreas, 2014, Brain Informatics and Health. International Conference, BIH 2014. Proceedings: LNCS 8609, P552, DOI 10.1007/978-3-319-09891-3_50
   Holzinger A, 2014, LECT NOTES COMPUTER, P331
   KIRYATI N, 1991, PATTERN RECOGN, V24, P303, DOI 10.1016/0031-3203(91)90073-E
   Poppinga J, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3378, DOI 10.1109/IROS.2008.4650729
   Qian XF, 2014, IEEE T CYBERNETICS, V44, P2771, DOI 10.1109/TCYB.2014.2316282
   Qiu G., 2010, 2010 3 INT C ADV COM, P151
   Tseng YH, 2005, INT GEOSCI REMOTE SE, P3281
   Wang ZL, 2011, ADV AUTOMATION ROBOT, V2, P593
   Yoo HW, 2013, 2013 44 INT S ROB IS
NR 21
TC 9
Z9 10
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24343
EP 24357
DI 10.1007/s11042-016-4192-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700054
DA 2024-07-18
ER

PT J
AU Liu, H
   Zhao, QJ
   Wang, H
   Lv, P
   Chen, YM
AF Liu, Hao
   Zhao, Qingjie
   Wang, Hao
   Lv, Peng
   Chen, Yanming
TI An image-based near-duplicate video retrieval and localization using
   improved Edit distance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Near-duplicate video retrieval; Near-duplicate video localization; Video
   copy detection; Edit distance
ID FRAMEWORK
AB The rapid development of social network in recent years has spurred enormous growth of near-duplicate videos. The existence of huge volumes of near-duplicates shows a rising demand on effective near-duplicate video retrieval technique in copyright violation and search result reranking. In this paper, we propose an image-based algorithm using improved Edit distance for near-duplicate video retrieval and localization. By regarding video sequences as strings, Edit distance is used and extended to retrieve and localize near-duplicate videos. Firstly, bag-of-words (BOW) model is utilized to measure the frame similarities, which is robust to spatial transformations. Then, non-near-duplicate videos are filtered out by computing the proposed relative Edit distance similarity (REDS). Next, a detect-and-refine-strategy-based dynamic programming algorithm is proposed to generate the path matrix, which can be used to aggregate scores for video similarity measure and localize the similar parts. Experiments on CC_WEB_VIDEO and TREC CBCD 2011 datasets demonstrated the effectiveness and robustness of the proposed method in retrieval and localization tasks.
C1 [Liu, Hao; Zhao, Qingjie; Wang, Hao; Lv, Peng; Chen, Yanming] Beijing Inst Technol, Beijing Key Lab Intelligent Informat Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Liu, H (corresponding author), Beijing Inst Technol, Beijing Key Lab Intelligent Informat Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
EM liuhao@bit.edu.cn; zhaoqj@bit.edu.cn; 2120141053@bit.edu.cn;
   p1v@bit.edu.cn; cym@bit.edu.cn
FU National Natural Science Foundation of China [61175096]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61175096). The authors would like to thank the anonymous
   editor and reviewers who gave valuable suggestion that have helped to
   improve the quality of the manuscript.
CR [Anonymous], VIDEO HISTOGRAM NOVE
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], P 2 ACM INT C MULT R
   [Anonymous], TASK OV ONL P TRECVI
   [Anonymous], P IEEE INT C MULT EX
   [Anonymous], HAMMING EMBEDDING WE
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Awad G, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2629531
   Cherubini Mauro., 2009, Proceedings of the 17th ACM International Conference on Multimedia, number April in MM '09, P35, DOI DOI 10.1145/1631272.1631280
   Chiu CY, 2008, IEEE T CIRC SYST VID, V18, P412, DOI 10.1109/TCSVT.2008.918447
   Chiu CY, 2014, IEEE T MULTIMEDIA, V16, P1952, DOI 10.1109/TMM.2014.2342668
   Chou CL, 2015, IEEE T MULTIMEDIA, V17, P382, DOI 10.1109/TMM.2015.2391674
   Douze M, 2010, IEEE T MULTIMEDIA, V12, P257, DOI 10.1109/TMM.2010.2046265
   Esmaeili MM, 2011, IEEE T INF FOREN SEC, V6, P213, DOI 10.1109/TIFS.2010.2097593
   Huang Z, 2009, ACM T INFORM SYST, V27, DOI 10.1145/1508850.1508855
   Jun W, 2016, MULTIMED TOOLS APPL, V75, P15665, DOI 10.1007/s11042-015-2724-0
   Ligang Zheng, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2537, DOI 10.1109/ICIP.2011.6116179
   Liu JJ, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2501654.2501658
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Poullot S., 2008, Proceedings of the ACM International Conference on Multimedia, P61
   Roopalakshmi R, 2013, SIGNAL PROCESS, V93, P2339, DOI 10.1016/j.sigpro.2012.06.004
   Shang L., 2010, Proceedings of the International Conference on Multimedia, P531
   Song JK, 2013, IEEE T MULTIMEDIA, V15, P1997, DOI 10.1109/TMM.2013.2271746
   Su PC, 2017, MULTIMED TOOLS APPL, V76, P1331, DOI 10.1007/s11042-015-3132-1
   Tan HK, 2010, IEEE T CIRC SYST VID, V20, P1486, DOI 10.1109/TCSVT.2010.2077531
   Tian YH, 2015, ACM T INFORM SYST, V33, DOI 10.1145/2699662
   Wu A. G., 2007, P ACM MM, P218
   Wu X, 2009, IEEE T MULTIMEDIA, V11, P196, DOI 10.1109/TMM.2008.2009673
   Wu ZP, 2014, INT J MULTIMED INF R, V3, P1, DOI 10.1007/s13735-013-0049-1
   Yeh M.-C., 2009, Proceedings of the ACM International Conference on Image and Video Retrieval, P45
   Zhao WL, 2010, IEEE T MULTIMEDIA, V12, P448, DOI 10.1109/TMM.2010.2050651
   Zhou XM, 2007, LECT NOTES COMPUT SC, V4505, P176
   Zhou XM, 2012, IEEE T MULTIMEDIA, V14, P1220, DOI 10.1109/TMM.2012.2194481
   Zhu YY, 2016, NEUROCOMPUTING, V187, P83, DOI 10.1016/j.neucom.2015.09.114
NR 34
TC 11
Z9 12
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24435
EP 24456
DI 10.1007/s11042-016-4176-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700058
DA 2024-07-18
ER

PT J
AU Lu, L
   Cai, QL
   Zhan, YJ
AF Lu Lu
   Cai Qing-ling
   Zhan Yi-Ju
TI Activity Recognition in Smart Homes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart homes; Activity recognition; Latent features; BP-HMM
AB In recent years, activity recognition in smart homes is an active research area. It is an important problem of Human Computer Interaction (HCI), and has many applications in HCI, such as assistive living and healthcare. Recognition of users' common behaviors allows an environment to provide personalized service. Unlike activity recognition in computer vision which uses cameras, it studies activities by embedded sensors in smart homes. In this paper, we propose a method to extract latent features from sensor data by Beta Process Hidden Markov Model (BP-HMM). The contributions of our method are twofold: 1, we extend BP-HMM by dependent Beta process, and integrate state constraints of sensors into the sampling process of BP-HMM. 2, we extract latent features automatically by our dependent BP-HMM, and train a structural support vector machine (SVM) by these features in a supervised way for activity recognition. To evaluate the proposed method, we performed experiments on the real-world smart home datasets. Our results suggest that extracting latent features from sensor data leads to good performance for activity recognition.
C1 [Lu Lu] Guangdong Univ Finance & Econ, Sch Math & Stat, Guangzhou 510320, Guangdong, Peoples R China.
   [Cai Qing-ling; Zhan Yi-Ju] Sun Yat Sen Univ, Sch Engn, Guangzhou 510006, Guangdong, Peoples R China.
C3 Guangdong University of Finance & Economics; Sun Yat Sen University
RP Cai, QL (corresponding author), Sun Yat Sen Univ, Sch Engn, Guangzhou 510006, Guangdong, Peoples R China.
EM cqlsysu@126.com
FU Guangdong Public Welfare and Ability Construction Project
   [2015B010103003]; Guangdong Collaborative Innovation and Platform
   Construction Project [2016A040403048]
FX This work was supported by the following grants: Guangdong Public
   Welfare and Ability Construction Project 2015B010103003, and Guangdong
   Collaborative Innovation and Platform Construction Project
   2016A040403048.
CR Alemdar H, 2014, INT C PATT RECOG, P3804, DOI 10.1109/ICPR.2014.653
   Alon J, 2009, IEEE T PATTERN ANAL, V31, P1685, DOI 10.1109/TPAMI.2008.203
   [Anonymous], 2009, Advances in Neural Information Processing Systems
   Azkune G, 2015, EXPERT SYST APPL, V42, P3115, DOI 10.1016/j.eswa.2014.11.063
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPR.2009.5206800, 10.1109/CVPRW.2009.5206800]
   Cook D, 2009, P CHI WORKSH DEV SHA, P4763
   Diethe T., 2015, Bayesian Modelling of the Temporal Aspects of Smart Home Activity with Circular Statistics, P279
   Doshi-Velez F., 2009, Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, P143
   Fahad L., 2013, European Symposium on Artificial Neural Networks (ESANN), P419
   Fahad LG, 2014, INT C PATT RECOG, P1348, DOI 10.1109/ICPR.2014.241
   Fatima I, 2013, J SUPERCOMPUT, V66, P760, DOI 10.1007/s11227-013-0978-8
   Fleury A, 2010, IEEE T INF TECHNOL B, V14, P274, DOI 10.1109/TITB.2009.2037317
   Foerster F, 1999, COMPUT HUM BEHAV, V15, P571, DOI 10.1016/S0747-5632(99)00037-0
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Intille SS, 2006, LECT NOTES COMPUT SC, V3968, P349
   KIDD CD, 1999, P 2 INT WORKSH COOP, V1670, P191
   Krishnan NC, 2014, PERVASIVE MOB COMPUT, V10, P138, DOI 10.1016/j.pmcj.2012.07.003
   Krose B., 2008, INT C INT SOC GER PI, P101, DOI DOI 10.4017/GT.2008.07.02.083.00
   Lester J, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P766
   Mahmoud S, 2013, APPL SOFT COMPUT, V13, P1813, DOI 10.1016/j.asoc.2012.12.012
   Miller KT, 2008, PHYLOGENETIC INDIAN
   Ramage Daniel., 2009, EMNLP, DOI DOI 10.3115/1699510.1699543
   Rashidi P, 2011, IEEE T KNOWL DATA EN, V23, P527, DOI 10.1109/TKDE.2010.148
   Robert Christian P., 2004, Springer Texts in Statistics, Vsecond
   Singla G, 2010, J AMB INTEL HUM COMP, V1, P57, DOI 10.1007/s12652-009-0007-1
   Tolstikov Andrei, 2011, Journal of Control Theory and Applications, V9, P18, DOI 10.1007/s11768-011-0260-7
   Tsochantaridis Ioannis., 2004, PROC 21 INT C MACHIN, P104
   van Kasteren TLM, 2011, LECT NOTES COMPUT SC, V7040, P82, DOI 10.1007/978-3-642-25167-2_9
   Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1762, DOI 10.1109/TPAMI.2009.43
   Wen JH, 2015, EXPERT SYST APPL, V42, P6423, DOI 10.1016/j.eswa.2015.04.020
   Wen JH, 2015, EXPERT SYST APPL, V42, P5800, DOI 10.1016/j.eswa.2015.04.005
   Williamson S., 2010, P MACHINE LEARNING R, P924
   ZHOU M., 2011, INT C ART INT STAT, P883
   Zhu J., 2009, Proceedings of the 26th Annual International Conference on Machine Learning, ICML '09, P1257, DOI DOI 10.1145/1553374.1553535
NR 35
TC 19
Z9 21
U1 3
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24203
EP 24220
DI 10.1007/s11042-016-4197-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700048
DA 2024-07-18
ER

PT J
AU Mohammadi, R
   Javidan, R
AF Mohammadi, Reza
   Javidan, Reza
TI An adaptive type-2 fuzzy traffic engineering method for video
   surveillance systems over software defined networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Software defined networks; Type-2 fuzzy; Traffic engineering; Video
   streaming; Quality of service
ID LOGIC SYSTEMS; CHALLENGES
AB Software Defined Network (SDN) is a new network technology which allows network providers to afford predefined Quality of Service (QoS) for video streaming applications. Network administrators can develop desired traffic engineering techniques over SDN and support Quality of Experience (QoE) and QoS for their customers. One of the most important issues in traffic engineering is to find favorable links for routing between source and destination. The fitness of each link in the network depends on the end users QoE and the applications they are used. In this paper to achieve optimal routes, the fitness of each link is determined by type-2 fuzzy sets. Then, an adaptive traffic engineering method is proposed to find the best routes between source cameras and monitoring center in a video surveillance system. The proposed method is based on Constraint Shortest Path (CSP) problem and calculates minimum cost path which satisfies delay constraint. Due to NP-completeness of the CSP problems, LARAC algorithm is used to solve it. To the best of our knowledge, this is the first proposed traffic engineering technique which is based on type-2 fuzzy set for video streaming applications over SDN. The contribution of the proposed method regarding to the related works, is to apply type-2 and type-1 fuzzy logic for calculating the costs of network links based on QoE for providing QoS in a video surveillance system. In addition, this paper models the provisioning of QoS in a real scenario and emulates them in a network emulator. Many comparisons carried out between the proposed method and other well-known methods to show the effectiveness of the proposed method in terms of packet loss, delay and PSNR.
C1 [Mohammadi, Reza; Javidan, Reza] Shiraz Univ Technol, Dept Comp Engn & Informat Technol, Shiraz, Iran.
C3 Shiraz University of Technology
RP Javidan, R (corresponding author), Shiraz Univ Technol, Dept Comp Engn & Informat Technol, Shiraz, Iran.
EM r.mohammadi@sutech.ac.ir; javidan@sutech.ac.ir
RI Javidan, Reza/L-2861-2019; Mohammadi, Reza/Y-8249-2019
OI Javidan, Reza/0000-0002-7788-6597; Mohammadi, Reza/0000-0002-2139-4518
CR Akyildiz IF, 2014, COMPUT NETW, V71, P1, DOI 10.1016/j.comnet.2014.06.002
   Aladi JH, 2014, INT C FUZZ SYST FUZZ
   [Anonymous], 2011, P 19 ACM INT C MULT
   [Anonymous], 2012, P IEEE AS PAC SIGN I
   [Anonymous], 2013, 2013 19 IEEE INT C N, DOI DOI 10.1109/ICON.2013.6781969
   Baklouti N., 2012, Journal of Intelligent Learning Systems and Applications, V4, P291
   Castillo O, 2007, GRC: 2007 IEEE INTERNATIONAL CONFERENCE ON GRANULAR COMPUTING, PROCEEDINGS, P145
   Dely P., 2012, 20 INT C SOFTW TEL C
   Dijkstra EW., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   Dusi M, 2014, INT WIREL COMMUN, P340, DOI 10.1109/IWCMC.2014.6906380
   Egilmez HE, 2014, IEEE T MULTIMEDIA, V16, P1597, DOI 10.1109/TMM.2014.2325791
   Egilmez HE, 2013, IEEE T MULTIMEDIA, V15, P710, DOI 10.1109/TMM.2012.2232645
   Hagras H, 2012, IEEE COMPUT INTELL M, V7, P14, DOI 10.1109/MCI.2012.2200621
   Jammal M, 2014, COMPUT NETW, V72, P74, DOI 10.1016/j.comnet.2014.07.004
   Jüttner A, 2001, IEEE INFOCOM SER, P859, DOI 10.1109/INFCOM.2001.916277
   Karnik NN, 1999, IEEE T FUZZY SYST, V7, P643, DOI 10.1109/91.811231
   Kreutz D, 2015, P IEEE, V103, P14, DOI 10.1109/JPROC.2014.2371999
   Liu G, 2001, IEEE INFOCOM SER, P743, DOI 10.1109/INFCOM.2001.916263
   Mendel J. M., 2017, Uncertain Rule-Based Fuzzy Systems: Introduction and NewDirections, V2nd
   Mirzahossein K, 2013, ANAL RIP OSPF EIGRP
   Mohammadi R., 2015, J. Telecommun. Electron. Comput. Eng, V7, P81
   Ongaro F, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, NETWORKING AND COMMUNICATIONS (ICNC), P505, DOI 10.1109/ICCNC.2015.7069395
   Rakheja P., 2012, INT J COMPUTER APPL, V48, P6
   Rec I, 1996, T U T P 800 METH SUB
   Schulzrinne H., 1998, Real time streaming protocol (rtsp)
   Sezer S, 2013, IEEE COMMUN MAG, V51, P36, DOI 10.1109/MCOM.2013.6553676
   Tomovic S, 2014, 2014 22ND TELECOMMUNICATIONS FORUM TELFOR (TELFOR), P111, DOI 10.1109/TELFOR.2014.7034369
   Wang ZL, 1996, '96 CHINA-JAPAN SYMPOSIUM ON PARTICUOLOGY, PROCEEDINGS, P7
   Xiao Y, 2005, AKCE INT J GRAPHS CO, V2, P63
   Yu TF, 2015, 2015 INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P318, DOI 10.1109/ICOIN.2015.7057904
   ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90046-8
NR 31
TC 17
Z9 18
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23627
EP 23642
DI 10.1007/s11042-016-4137-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700023
DA 2024-07-18
ER

PT J
AU Tang, WJ
   Gong, F
   Dong, RR
   Sun, YJ
   Li, P
AF Tang Wenjing
   Gong Fei
   Dong Renren
   Sun Yujuan
   Li Ping
TI Face recognition based on the fusion of wavelet packet sub-images and
   fisher linear discriminant
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; PCA; Wavelet packet decomposition; Fisher linear
   discriminant; Weighted fusion
ID TRANSFORM; EIGENFACES
AB With the improvement of security requirements of individuals, businesses and countries, the identity authentication system based on face recognition technology is applied widely. The identity methods based on single theory, due to a variety of factors, have their own inherent limitations. In order to improve the efficiency and accuracy of face recognition, based on fusion of wavelet packet sub-images, a face recognition algorithm named FW-FLD is proposed in this paper by combining PCA (Principal Component Analysis) and FLD(Fisher Linear Discriminant). Firstly, the training samples are decomposed using wavelet packet. The fusion weights of the decomposed sub-images are calculated according to their energy distribution and the weighted fusion images are obtained, which reserve the images characteristic in the frequency. Then the features of the fused images are extracted using PCA, and the optimized Fisher space is constructed using FLD. Finally, face images are classified by measuring the projection coefficients of optimized training samples and testing samples in Fisher space. Experimental results on CMU PIE, JAFFE and AR face databases show that the proposed algorithm is robust, and can adapt to face recognition with various illumination, facial expressions and gestures. Compared with other algorithms, it not only improves the face recognition rate, but also has a higher time efficiency.
C1 [Tang Wenjing; Dong Renren; Sun Yujuan] Ludong Univ, Coll Informat & Elect Engn, Yantai 264025, Peoples R China.
   [Gong Fei] Ningbo Univ, Fac Elect Engn & Comp Sci, Ningbo 315211, Zhejiang, Peoples R China.
   [Li Ping] Guangzhou Univ, Sch Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
C3 Ludong University; Ningbo University; Guangzhou University
RP Tang, WJ (corresponding author), Ludong Univ, Coll Informat & Elect Engn, Yantai 264025, Peoples R China.
EM twj_tang@126.com
FU National Natural Science Foundation of China [61602229, 61472091];
   Natural Science Foundation of Shandong Province [ZR2016FM13]; Technology
   Planning Project of Guangdong Province, China [2015B010129015]
FX This work is partially supported by National Natural Science Foundation
   of China (Nos. 61602229, 61472091), the Natural Science Foundation of
   Shandong Province (ZR2016FM13) and Technology Planning Project of
   Guangdong Province, China (2015B010129015).
CR Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Borade SN, 2015, PROCEDIA COMPUT SCI, V58, P380, DOI 10.1016/j.procs.2015.08.038
   Bouzalmat Anissa, 2014, Journal of Emerging Technologies in Web Intelligence, V6, P64, DOI 10.4304/jetwi.6.1.64-68
   Draper BA, 2003, COMPUT VIS IMAGE UND, V91, P115, DOI 10.1016/S1077-3142(03)00077-8
   Hu K, 2016, MAGN RESON IMAGING, V34, P1128, DOI 10.1016/j.mri.2016.05.011
   Kekre HB, 2016, PROCEDIA COMPUT SCI, V89, P778, DOI 10.1016/j.procs.2016.06.059
   KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390
   Li J, 2015, IEEE T COMPUT, V64, P425, DOI 10.1109/TC.2013.208
   Lu GF, 2012, PATTERN RECOGN, V45, P2510, DOI 10.1016/j.patcog.2012.01.018
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Makbol NM, 2014, DIGIT SIGNAL PROCESS, V33, P134, DOI 10.1016/j.dsp.2014.06.012
   Martinez A., 1998, AR FACE DATABASE
   Minamoto T, 2014, APPL MATH COMPUT, V226, P306, DOI 10.1016/j.amc.2013.10.028
   Peiyi Shen, 2014, Journal of Networks, V9, P2728, DOI 10.4304/jnw.9.10.2728-2733
   Sharma A, 2012, PATTERN RECOGN LETT, V33, P1157, DOI 10.1016/j.patrec.2012.02.001
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wu Fengxiang, 2014, Journal of Multimedia, V9, P1017, DOI 10.4304/jmm.9.8.1017-1023
   Yuanzhi W, 2012, J DIGIT INF MANAG, V10, P137
NR 19
TC 10
Z9 12
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22725
EP 22740
DI 10.1007/s11042-017-4343-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200042
DA 2024-07-18
ER

PT J
AU Zhang, JY
   Zhang, YF
AF Zhang, Jinyu
   Zhang, Yifan
TI QoS-awareness peer coordination control for topology-converging P2P live
   streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Streaming media; Peer to peer (P2P); Streaming synchronization; Peer
   coordination, quality of service (QoS)
ID RATE ALLOCATION; VIDEO; MANAGEMENT; DESIGN
AB For Peer to Peer (P2P) live streaming media, the peer coordination control mechanism becomes complex under dynamic traffic fluctuation, different node distance and capacity as well as user dynamics. Due to the lack of the adjusting ability, the existing peer coordination control mechanisms perform worse, and have large overhead. In order to overcome these problems, a QoS-awareness peer coordination control mechanism is proposed. Specifically, firstly, a ring buffer mechanism is introduced to implement the cyclic coordination, and the algorithms of both cycle length and cycle time are suggested to implement the constant startup delay and smooth play. Secondly, the selection algorithms of both the content-likeness candidate and the shortest-distance peer are proposed to implement the QoS-awareness streaming synchronization. Thirdly, the peer task assignment algorithm is proposed to implement the variable trunk and similar Cycle Task Fulfillment Time (CTFT). Next, a self-adaptive adjusting mechanism is introduced to converge P2P topology and fight against the delivery abnormality. Finally, simulation is conducted to corroborate our studies and the results show that its performance outperforms the existing mechanisms.
C1 [Zhang, Jinyu] Beijing Jiaotong Univ, BJTU, Sch Comp & Informat Technol, 1 3 Shangyuancun, Beijing 100044, Peoples R China.
   [Zhang, Yifan] BUAA, Sch Econ & Management, Beijing 100191, Peoples R China.
C3 Beijing Jiaotong University; Beihang University
RP Zhang, JY (corresponding author), Beijing Jiaotong Univ, BJTU, Sch Comp & Informat Technol, 1 3 Shangyuancun, Beijing 100044, Peoples R China.
EM zjy@bjtu.edu.cn; zhangjinyu_ll@126.com
FU National Natural Science Foundation of China [61071077]; National Mobile
   Communications Research Laboratory, Southeast University [2013D03]
FX Manuscript received April 11, 2015. This work was supported in part by
   the National Natural Science Foundation of China under Grant No.
   61071077 and the open research fund of National Mobile Communications
   Research Laboratory, Southeast University under Grant No. 2013D03.
CR Abbasi U, 2012, IEEE ICC, P1986, DOI 10.1109/ICC.2012.6364625
   Akbari B, 2008, COMPUT COMMUN, V31, P551, DOI 10.1016/j.comcom.2007.08.025
   Bideh MK, 2016, PEER PEER NETW APPL, V9, P436, DOI 10.1007/s12083-015-0355-x
   Chang HS, 2011, IEEE ACM T NETWORK, V19, P55, DOI 10.1109/TNET.2010.2056382
   Endo R, 2012, 2012 9TH INTERNATIONAL CONFERENCE ON UBIQUITOUS INTELLIGENCE & COMPUTING AND 9TH INTERNATIONAL CONFERENCE ON AUTONOMIC & TRUSTED COMPUTING (UIC/ATC), P264, DOI 10.1109/UIC-ATC.2012.121
   Fan B, 2009, IEEE ACM T NETWORK, V17, P365, DOI 10.1109/TNET.2008.2002553
   Gong S., 2011, 2011 INT C COMP SCI, P114
   Huang ZY, 2006, DEP COMP 2006 PRDC 0, P221
   Kim J, 2012, J COMMUN NETW-S KOR, V14, P286, DOI 10.1109/JCN.2012.6253090
   Li B, 2008, IEEE INFOCOM SER, P1705
   Li J, 2007, MULTIMEDIA SYST, V13, P173, DOI 10.1007/s00530-006-0073-6
   Lima L, 2013, IEEE J SEL AREA COMM, V31, P200, DOI 10.1109/JSAC.2013.SUP.0513018
   Lin CS, 2016, MULTIMED TOOLS APPL, V75, P1009, DOI 10.1007/s11042-014-2341-3
   Liu B, 2009, IEEE T MULTIMEDIA, V11, P361, DOI 10.1109/TMM.2009.2012911
   Liu X, 2006, J MULTIMEDIA JMM, V1, P38
   Magharei N, 2009, IEEE ACM T NETWORK, V17, P1052, DOI 10.1109/TNET.2008.2007434
   Merani ML, 2016, PEER PEER NETW APPL, V9, P209, DOI 10.1007/s12083-014-0323-x
   Mokhtarian K, 2013, IEEE T MULTIMEDIA, V15, P181, DOI 10.1109/TMM.2012.2225042
   Pianese F, 2007, IEEE T MULTIMEDIA, V9, P1645, DOI 10.1109/TMM.2007.907466
   Quevedo GPL, 2012, 2012 I E REG 10 C TE, P1
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shen HY, 2013, IEEE T PARALL DISTR, V24, P2125, DOI 10.1109/TPDS.2012.302
   Takayama K., 2012, 2012 IEEE Workshops of International Conference on Advanced Information Networking and Applications (WAINA), P105, DOI 10.1109/WAINA.2012.170
   Thu THT, 2016, MULTIMED TOOLS APPL, V75, P1
   Traverso S, 2015, IEEE ACM T NETWORK, V23, P741, DOI 10.1109/TNET.2014.2307157
   Wang F, 2010, IEEE T PARALL DISTR, V21, P379, DOI 10.1109/TPDS.2009.77
   Wang M, 2013, IEEE ACM T NETWORK, V21, P162, DOI 10.1109/TNET.2012.2194165
   Wang Z, TSINGHUA SCI TECHNOL, V17, P29
   Wu D, 2010, IEEE ACM T NETWORK, V18, P1248, DOI 10.1109/TNET.2009.2038910
   Zhang M, 2009, IEEE T PARALL DISTR, V20, P97, DOI 10.1109/TPDS.2008.69
   Zhang XY, 2005, IEEE INFOCOM SER, P2102
   Zou JN, 2014, MULTIMED TOOLS APPL, V73, P1269, DOI 10.1007/s11042-013-1621-7
NR 32
TC 2
Z9 2
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23835
EP 23858
DI 10.1007/s11042-016-4092-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700033
DA 2024-07-18
ER

PT J
AU Castelló, V
   Traver, VJ
   Serrano, B
   Montoliu, R
   Botella, C
AF Castello, Vicente
   Javier Traver, V.
   Serrano, Berenice
   Montoliu, Raul
   Botella, Cristina
TI Assisting therapists in assessing small animal phobias by computer
   analysis of video-recorded sessions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Small-animal phobia; Computer vision; Visual representations;
   Therapists; Clinical diagnostics
ID VIRTUAL-REALITY; DISORDERS; EXPOSURE
AB Behavioural Avoidance Tests (BATs) are commonly used for assessing phobias. While easy to deploy, these tests have some practical difficulties. For instance, therapists have to make distance estimations that are hard to do with accuracy and objectivity; or information regarding the performance of the patients (e.g. their walking pattern) is lost. To alleviate these difficulties, a computerized tool has been developed to extract the walking pattern of patients while approaching the phobic stimulus. From a video-recorded BAT session, two visual representations have been explored to compactly summarize the patient's behavior: a static one (an image) and a dynamic one (an animation). A proof-of-concept prototype has been tested with 23 therapists. Most of the therapists preferred the animated representation, since it provides them with a better sense of the dynamics of how the patient really behaved. The participants agreed that this tool might be useful in assisting therapist when assessing phobia through BATs, since diagnostics could be made in a more accurate and objective way.
C1 [Castello, Vicente; Javier Traver, V.; Montoliu, Raul] Univ Jaume, Inst New Imaging Technol iNIT, Castellon de La Plana, Spain.
   [Serrano, Berenice; Botella, Cristina] Univ Jaume, Psychol Lab, Technol LABPSITEC, Castellon de La Plana, Spain.
C3 Universitat Jaume I; Universitat Jaume I
RP Traver, VJ (corresponding author), Univ Jaume, Inst New Imaging Technol iNIT, Castellon de La Plana, Spain.
EM vicastello@gmail.com; vtraver@uji.es; montoliu@uji.es; bserrano@uji.es;
   botella@uji.es
RI Botella, Cristina/F-9230-2010; Traver, V. Javier/F-8865-2016
OI Botella, Cristina/0000-0001-8783-6959; Traver, V.
   Javier/0000-0002-1596-8466
FU Fundacio Caixa-Castello [P1-1A2010-11]; Generalitat Valenciana
   [PROMETEOII2014062]
FX This work has been partly supported by Fundacio Caixa-Castello (through
   grant P1-1A2010-11) and Generalitat Valenciana (through grant
   PROMETEOII2014062).
CR [Anonymous], TECHNICAL REPORT
   [Anonymous], 2013, CHI 13 HUM FACT COMP
   Bailenson JN, 2008, INT J HUM-COMPUT ST, V66, P303, DOI 10.1016/j.ijhcs.2007.10.011
   Botella C, 2011, COMPUT HUM BEHAV, V27, P217, DOI 10.1016/j.chb.2010.07.043
   Botella C, 2010, CYBERPSYCH BEH SOC N, V13, P407, DOI 10.1089/cyber.2009.0224
   Botella C, 2010, BEHAV THER, V41, P401, DOI 10.1016/j.beth.2009.07.002
   Bretón-López J, 2010, CYBERPSYCH BEH SOC N, V13, P705, DOI 10.1089/cyber.2009.0170
   Davis JW, 1997, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.1997.609439
   Dix A., 2003, HUM FAC ER
   Gatica-Perez D, 2009, IMAGE VISION COMPUT, V27, P1775, DOI 10.1016/j.imavis.2009.01.004
   Gunes H, 2006, INT J HUM-COMPUT ST, V64, P1184, DOI 10.1016/j.ijhcs.2006.07.004
   Hashemi J, 2012, J IEEE I C DEVELOP L
   Kessler RC, 2005, ARCH GEN PSYCHIAT, V62, P593, DOI 10.1001/archpsyc.62.6.593
   Kröse B, 2011, COMPUTER ANALYSIS OF HUMAN BEHAVIOR, P325, DOI 10.1007/978-0-85729-994-9_12
   McDuff D, 2012, IEEE T AFFECT COMPUT, V3, P456, DOI 10.1109/T-AFFC.2012.19
   Meng CTT, 2004, BEHAV CHANGE, V21, P173, DOI 10.1375/bech.21.3.173.55994
   Muhlberger A., 2008, Journal of CyberTherapy and Rehabilitation, V1, P147
   Olesen J, 2012, EUR J NEUROL, V19, P155, DOI 10.1111/j.1468-1331.2011.03590.x
   OST LG, 1991, BEHAV THER, V22, P407, DOI 10.1016/S0005-7894(05)80374-0
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P333, DOI 10.1007/s11042-011-0786-1
   Rahman MA, 2015, MULTIMED TOOLS APPL, V74, P5463, DOI 10.1007/s11042-014-1864-y
   Rehg J., 2011, MVA, V11, P14
   Riva G, 1997, ST HEAL T, V44, P71
   Sharp Helen, 2007, Interaction Design: Beyond Human Computer Interaction, V2
   Trull TJ, 2007, PSYCHOL ASSESSMENT, V19, P1, DOI 10.1037/1040-3590.19.1.1
   Tversky B, 2002, INT J HUM-COMPUT ST, V57, P247, DOI 10.1006/ijhc.1017
   Valstar MF, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P38
   Wrzesien M, 2013, IEEE COMPUT GRAPH, V33, P80, DOI 10.1109/MCG.2013.12
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 30
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21033
EP 21049
DI 10.1007/s11042-016-3997-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400032
OA Green Published
DA 2024-07-18
ER

PT J
AU Guna, J
   Stojmenova, E
   Kos, A
   Pogacnik, M
AF Guna, Joze
   Stojmenova, Emilija
   Kos, Andrej
   Pogacnik, Matevz
TI The TV-WEB project - combining internet and television - lessons learnt
   from the user experience studies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SEE TV-WEB; TV; Internet; HBBTV; DVB; Digital divide; User study; User
   experience; User centered design; Human-computer interaction
AB We present the results of the user experience studies conducted as part of the European SEE TV-WEB project activities. The SEE TV-WEB project aims to use the free digital terrestrial television (DTT) broadcasting frequency spectrum capacities for transmitting selected Internet content and ensuring at least some Internet experience via TV devices to the certain less advantaged segments of the population, or those in rural areas without broadband access. Five different test study cases are presented, four in Slovenia and one in Austria, each with different specific target user groups and their own dynamics. According to the project disposition goals the focus was on the elderly. Methods, such as think-aloud protocol in combination with a guided interview and observation of verbal as well as of non-verbal responses, were used. To ensure the repeatability of tests and to help guide the process, a special questionnaire was developed. The research questions focused on: the navigation and interaction concept, the content, the readability, and the overall acceptance and the perception of value of the TV-WEB service. More than 74 users participated in the user experience studies, 27 of them 65 years old or older. The results indicate that the presented navigation and interaction concept is indeed intuitive and simple enough to be used by most users with no or little effort. This is especially proven by the results from studies at both elderly citizens homes, where the majority of participants were 65 years old or older.
C1 [Guna, Joze; Stojmenova, Emilija; Kos, Andrej; Pogacnik, Matevz] Univ Ljubljana, Fac Elect Engn, Trzaska 25, Ljubljana 1000 SLOVEN, Slovenia.
C3 University of Ljubljana
RP Guna, J (corresponding author), Univ Ljubljana, Fac Elect Engn, Trzaska 25, Ljubljana 1000 SLOVEN, Slovenia.
RI Guna, Jože/AAO-8714-2020
OI Guna, Jože/0000-0002-5161-7751; Pogacnik, Matevz/0000-0002-6134-2827
CR Albert W., 2013, Measuring the User Experience
   [Anonymous], TV WEB PROJ TACKL DI
   Carmichael A., 1999, STYLE GUIDE DESIGN I
   Chorianopoulos K., 2006, Universal Access in The Information Society, V5, P209, DOI [DOI 10.1007/S10209-006-0032-1, 10.1007/s10209-006-0032-1]
   Chorianopoulos K, 2008, INT J HUM-COMPUT INT, V24, P556, DOI 10.1080/10447310802205750
   Dickinson A, 2007, BEHAV INFORM TECHNOL, V26, P343, DOI 10.1080/01449290601176948
   Eisma R., 2004, Universal Access in the Information Society, V3, P131, DOI 10.1007/s10209-004-0092-z
   ETSI Digital Video Broadcasting (DVB), 2010, 102809 ETSI DVB TS
   Fisk A.D., 2012, Designing for Older Adults: Principles and Creative Human Factors Approaches, VSecond
   Guna J, 2013, P 1 WORKSH DEF EUR R
   Lowdermilk T., 2013, User-centered design: A developer's guide to building user-friendly applications
   Lugmayr A, 2013, MULTIMED TOOLS APPL, V66, P1, DOI 10.1007/s11042-012-1239-1
   OECD, 2001, 49 OECD
   Pak R., 2011, DESIGNING DISPLAYS O
   Pawson M, 2009, J USABILITY STUD, V4, P124
   Sayago S., 2006, HCI WEB OLD POP WORK, P11
   Stojmenova E, 2013, PROCEEDINGS OF THE 17TH INTERNATIONAL ACADEMIC MINDTREK CONFERENCE, P17
NR 17
TC 2
Z9 2
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20377
EP 20408
DI 10.1007/s11042-016-3243-3
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400001
DA 2024-07-18
ER

PT J
AU Zhao, FQ
   Li, GQ
   Zhang, RB
   Du, JL
   Guo, C
   Zhou, YR
   Lv, ZH
AF Zhao, Fengqiang
   Li, Guangqiang
   Zhang, Rubo
   Du, Jialu
   Guo, Chen
   Zhou, Yiran
   Lv, Zhihan
TI Swarm-based intelligent optimization approach for layout problem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Genetic algorithms; Particles warm optimization; Hybrid methods; Layout;
   Swarm intelligence
ID GENETIC ALGORITHMS
AB Layout problem is a kind of NP-Complete problem. It is concerned more and more in recent years and arises in a variety of application fields such as the layout design of spacecraft modules, plant equipment, platforms of marine drilling well, shipping, vehicle and robots. The algorithms based on swarm intelligence are considered powerful tools for solving this kind of problems. While usually swarm intelligence algorithms also have several disadvantages, including premature and slow convergence. Aiming at solving engineering complex layout problems satisfactorily, a new improved swarm-based intelligent optimization algorithm is presented on the basis of parallel genetic algorithms. In proposed approach, chaos initialization and multi-subpopulation evolution strategy based on improved adaptive crossover and mutation are adopted. The proposed interpolating rank-based selection with pressure is adaptive with evolution process. That is to say, it can avoid early premature as well as benefit speeding up convergence of later period effectively. And more importantly, proposed PSO update operators based on different versions PSO are introduced into presented algorithm. It can take full advantage of the outstanding convergence characteristic of particle swarm optimization (PSO) and improve the global performance of the proposed algorithm. An example originated from layout of printed circuit boards (PCB) and plant equipment shows the feasibility and effectiveness of presented algorithm.
C1 [Zhao, Fengqiang; Li, Guangqiang; Du, Jialu; Guo, Chen; Zhou, Yiran] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
   [Zhao, Fengqiang; Zhang, Rubo] Dalian Nationalities Univ, Coll Mech & Elect Engn, Dalian 116600, Peoples R China.
   [Li, Guangqiang] Univ Massachusetts, Dept Comp Sci, Lowell, MA 01854 USA.
   [Lv, Zhihan] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
C3 Dalian Maritime University; Dalian Minzu University; University of
   Massachusetts System; University of Massachusetts Lowell; Chinese
   Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS
RP Zhao, FQ; Li, GQ (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.; Zhao, FQ (corresponding author), Dalian Nationalities Univ, Coll Mech & Elect Engn, Dalian 116600, Peoples R China.; Li, GQ (corresponding author), Univ Massachusetts, Dept Comp Sci, Lowell, MA 01854 USA.; Lv, ZH (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
EM fqzhao2002@163.com; lgq@dlmu.edu.cn; zh.lv@siat.ac.cn
RI Lv, Zhihan/GLR-6000-2022; Lyu, Zhihan/I-3187-2014; guo,
   chen/KTR-9590-2024
OI Lv, Zhihan/0000-0003-2525-3074; Lyu, Zhihan/0000-0003-2525-3074; 
FU National Natural Science Foundation of China [61374114, 51579024];
   Fundamental Research Funds for the Central Universities of China
   [3132014321, DC120101014, DC110320]; Applied Basic Research Program of
   Ministry of Transport of China [2011-329-225-390, 2012-329-225-070];
   China Scholarship council [201306575010]; Higher Education Research Fund
   of Education Department of Liaoning Province of China [LT2010013];
   Doctor Startup Foundation of Liaoning Province [20131006]
FX Our research work is financially supported by the National Natural
   Science Foundation of China (No. 61374114 and No. 51579024), the
   Fundamental Research Funds for the Central Universities of China (No.
   3132014321, No. DC120101014, No. DC110320), the Applied Basic Research
   Program of Ministry of Transport of China (No. 2011-329-225-390, No.
   2012-329-225-070), the China Scholarship council (No. 201306575010), the
   Higher Education Research Fund of Education Department of Liaoning
   Province of China (No. LT2010013), and the Doctor Startup Foundation of
   Liaoning Province (No. 20131006).
CR Boneh D, 2004, J CRYPTOL, V17, P297, DOI 10.1007/s00145-004-0314-9
   Cagan J, 2002, COMPUT AIDED DESIGN, V34, P597, DOI 10.1016/S0010-4485(01)00109-9
   Che L., 2015, Smart Grid, IEEE Transactions on, VPP, P1
   Chen Z, 2016, MULTIMED TOOLS APPL
   Dang SP, 2014, 2014 14TH INTERNATIONAL CONFERENCE ON ENVIRONMENT AND ELECTRICAL ENGINEERING (EEEIC), P323, DOI 10.1109/EEEIC.2014.6835887
   de la Calle FJ, 2015, IEEE LAT AM T, V13, P1462, DOI 10.1109/TLA.2015.7112003
   Muritiba AEF, 2013, FLEX SERV MANUF J, V25, P443, DOI 10.1007/s10696-011-9123-2
   Gu W, 2016, MULTIMED TOOLS APPL
   Jankovits I, 2011, EUR J OPER RES, V214, P199, DOI 10.1016/j.ejor.2011.04.013
   Jiang D, 2015, J COMMUN NETW
   Jiang DD, 2016, WIRELESS PERS COMMUN, V86, P901, DOI 10.1007/s11277-015-2961-6
   Jiang DD, 2011, COMPUT ELECTR ENG, V37, P1106, DOI 10.1016/j.compeleceng.2011.06.009
   Jiang DD, 2011, COMPUT NETW, V55, P3533, DOI 10.1016/j.comnet.2011.06.027
   Jiang DD, 2009, IEEE COMMUN LETT, V13, P52, DOI 10.1109/LCOMM.2008.081271
   Kameyama K, 2009, IEICE T INF SYST, VE92D, P1354, DOI 10.1587/transinf.E92.D.1354
   Kennedy J, 2002, IEEE C EVOL COMPUTAT, P1671, DOI 10.1109/CEC.2002.1004493
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Knysh DS, 2010, J COMPUT SYS SC INT+, V49, P579, DOI 10.1134/S1064230710040088
   Li CS, 2012, NEUROCOMPUTING, V83, P98, DOI 10.1016/j.neucom.2011.12.009
   Li G., 2003, THESIS
   Li GQ, 2005, EVOLUTIONARY ALGORIT
   Li X., 2015, 15 IEEE ACM INT S CL
   Lin YC, 2015, SENSORS-BASEL, V15, P20925, DOI 10.3390/s150820925
   Liu S, 2015, MULTIMED TOOLS APPL
   Lv Z, 2015, PERS UBIQUIT COMPUT
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Lv ZH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057990
   Nickabadi A, 2011, APPL SOFT COMPUT, V11, P3658, DOI 10.1016/j.asoc.2011.01.037
   Pluhacek M, 2014, LECT NOTES COMPUT SC, V8838, P445, DOI 10.1007/978-3-662-45237-0_41
   Qian Zhiqin, 2002, China Mechanical Engineering, V13, P696
   Rocca P, 2015, IEEE ANTENN WIREL PR, V14, P131, DOI 10.1109/LAWP.2014.2356855
   Silva CP, 1996, IEEE MTT-S, P1871, DOI 10.1109/MWSYM.1996.512311
   Sokolov A, 2007, GENET PROGRAM EVOL M, V8, P221, DOI 10.1007/s10710-007-9030-1
   SRINIVAS M, 1994, IEEE T SYST MAN CYB, V24, P656, DOI 10.1109/21.286385
   Su TY, 2016, COMPUT GRAPH-UK, V54, P65, DOI 10.1016/j.cag.2015.07.019
   Tengfei Yin, 2011, Journal of Networks, V6, P990, DOI 10.4304/jnw.6.7.990-998
   Wang K, 2015, P IEEE INT C CLUST C
   Wang K, 2015, LOAD BALANCED LOCALI
   Wang Yi, 2015, P 27 INT C SCI STAT
   Xu CX, 2012, COMM COM INF SC, V308, P422
   Yang J., 2011, INT J ADV COMPUTING, V3, P144
   Yang J, 2016, MULTIMED TOOLS APPL
   Yang JC, 2015, SENSORS-BASEL, V15, P19618, DOI 10.3390/s150819618
   Zhang S, 2014, IEEE IMAGE PROC, P2724, DOI 10.1109/ICIP.2014.7025551
   Zhang Su., 2014, P 9 ACM S INFORM COM, P317, DOI DOI 10.1145/2590296.2590300
   Zhang X, 2013, IEEE DECIS CONTR P, P6798, DOI 10.1109/CDC.2013.6760966
NR 46
TC 1
Z9 2
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19445
EP 19461
DI 10.1007/s11042-015-3174-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500007
DA 2024-07-18
ER

PT J
AU Chen, ZW
   Huang, W
   Lv, ZH
AF Chen, Zhanwei
   Huang, Wei
   Lv, Zhihan
TI Towards a face recognition method based on uncorrelated discriminant
   sparse preserving projection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Feature extraction; Sparse preserving projection;
   Statistical uncorrelated restraint
ID NORMALIZATION; IMAGE; POSE
AB Feature extraction has always been an important step in face recognition, the quality of which directly determines recognition result. Based on making full use of advantages of Sparse Preserving Projection (SPP) on feature extraction, the discriminant information was introduced into SPP to arrive at a novel supervised feather extraction method that named Uncorrelated Discriminant SPP (UDSPP) algorithm. The obtained projection with the method by sparse preserving intra-class and maximizing distance inter-class can effectively express discriminant information, while preserving local neighbor relationship. Moreover, statistics uncorrelated constraint was also added to decrease redundancy among feature vectors so as to obtain more information as possible with little vectors as possible. The experimental results show that the recognition rate improved compared with SPP. The method is also superior to recognition methods based on Euclidean distance in processing face database in light.
C1 [Chen, Zhanwei] Zhoukou Normal Univ, Sch Comp Sci & Technol, Zhoukou 466001, Peoples R China.
   [Huang, Wei] Light Engn Inst Zhengzhou, Sch Comp & Commun Engn, Zhengzhou 450002, Henan, Peoples R China.
   [Lv, Zhihan] Chinese Acad Sci, SIAT, Beijing, Peoples R China.
C3 Zhoukou Normal University; Chinese Academy of Sciences; Shenzhen
   Institute of Advanced Technology, CAS
RP Lv, ZH (corresponding author), Chinese Acad Sci, SIAT, Beijing, Peoples R China.
EM lvzhihan@chinawalter.com
RI Lyu, Zhihan/I-3187-2014; Lv, Zhihan/GLR-6000-2022
OI Lyu, Zhihan/0000-0003-2525-3074; Lv, Zhihan/0000-0003-2525-3074
FU Science and Technology Department of Henan Province, China
   [132102210575]
FX The research was founded within the project No. 132102210575 entitled:
   "Research on image fusion technology based on Representation Learning",
   being a key scientific and technical tackle-key-problem plan project of
   Henan province, supported by The Science and Technology Department of
   Henan Province, China.
CR [Anonymous], APPL MATH INF SCI
   Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Biswas S, 2010, PROC CVPR IEEE, P2683, DOI 10.1109/CVPR.2010.5539987
   Chai XJ, 2007, IEEE T IMAGE PROCESS, V16, P1716, DOI 10.1109/TIP.2007.899195
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353
   Chen WL, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/829589
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Fan CN, 2011, PATTERN RECOGN LETT, V32, P1468, DOI 10.1016/j.patrec.2011.03.023
   Gao Y, 2001, IEE P-VIS IMAGE SIGN, V148, P248, DOI 10.1049/ip-vis:20010377
   González-Jiménez D, 2007, IEEE T INF FOREN SEC, V2, P413, DOI 10.1109/TIFS.2007.903543
   Gui J, 2012, PATTERN RECOGN, V45, P2884, DOI 10.1016/j.patcog.2012.02.005
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Kim TK, 2005, IEEE T PATTERN ANAL, V27, P318, DOI 10.1109/TPAMI.2005.58
   Li Xiaoming, 2015, ADV ENG SOFTW
   Liu S, 2015, MULTIMED TO IN PRESS
   Liu S, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/817496
   Liu S, 2014, APPL MATH COMPUT, V243, P767, DOI 10.1016/j.amc.2014.06.016
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   Lv ZH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057990
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Qin J, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P5144
   Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964
   Su Tianyun, 2015, COMPUT GRAPH
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Zhao WY, 2000, PROC CVPR IEEE, P286, DOI 10.1109/CVPR.2000.855831
   Zhihan L, 2014, ACM T MULTIM COMPUT, V11, P1
NR 29
TC 20
Z9 21
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17669
EP 17683
DI 10.1007/s11042-015-2882-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800004
DA 2024-07-18
ER

PT J
AU Grigorev, A
   Jiang, F
   Rho, S
   Sori, WJ
   Liu, SH
   Sai, S
AF Grigorev, Aleksei
   Jiang, Feng
   Rho, Seungmin
   Sori, Worku J.
   Liu, Shaohui
   Sai, Sergey
TI Depth estimation from single monocular images using deep hybrid network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CNN; LSTM; Depth estimation; Monocular image; RNN
ID SUPPORT; SCENE
AB Depth estimation is a significant task in the robotics vision. In this paper, we address the depth estimation from a single monocular image, which is a challenging problem in automated vision systems since a single image alone does not carry any additional measurements. To tackle our main objective, we design a deep hybrid neural network, which is composed of convolutional and recurrent layers (ReNet), where each ReNet layer is composed of the Long Short-Term Memory unit (LSTM), which is famous for the ability to memorize long-range context. In the proposed network, ReNet layers aim to enrich the features representation by directly capturing global context. The effective integration of ReNet and convolutional layers in the common CNN framework allows us to train the hybrid network in the end-to-end fashion. Experimental evaluation on the benchmarks dataset demonstrated, that hybrid network achieves the state-of-the-art results without any post-processing steps. Moreover, the composition of recurrent and convolutional layers provide more satisfying results.
C1 [Grigorev, Aleksei; Jiang, Feng; Sori, Worku J.; Liu, Shaohui] Harbin Inst Technol, Dept Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
   [Grigorev, Aleksei; Sai, Sergey] Pacific Natl Univ, Dept Comp Engn, Khabarovsk 680035, Russia.
   [Rho, Seungmin] Sungkyul Univ, Dept Media Software, Anyang, South Korea.
C3 Harbin Institute of Technology; Pacific National University; Sungkyul
   University
RP Jiang, F (corresponding author), Harbin Inst Technol, Dept Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
EM fjiang@hit.edu.cn
RI Liu, shaohui/HKE-1383-2023; JIANG, Feng/HTP-2862-2023; Liu,
   Shaohui/AAC-3092-2019; Rho, Seungmin/HTP-6683-2023
OI Liu, Shaohui/0000-0002-1810-5412; Sai, Sergey/0000-0002-4506-1857; Sori,
   Worku Jifara/0000-0001-6658-5142
FU MOE-Microsoft Key Laboratory of Natural Language Processing and Speech;
   Harbin Institute of Technology; Major State Basic Research Development
   Program of China (973 Program) [2015CB351804]; National Natural Science
   Foundation of China [61572155, 61672188, 61272386]
FX This work is partially funded by the MOE-Microsoft Key Laboratory of
   Natural Language Processing and Speech, Harbin Institute of Technology,
   the Major State Basic Research Development Program of China (973 Program
   2015CB351804) and the National Natural Science Foundation of China under
   Grant No. 61572155, 61672188 and 61272386. We would also like to
   acknowledge NVIDIA Corporation who kindly provided two sets of GPU.
CR [Anonymous], RENET RECURRENT NEUR
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2012, ECCV
   [Anonymous], CORR
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.241
   Bottou Leon, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P421, DOI 10.1007/978-3-642-35289-8_25
   Chen BW, 2016, IT PROF, V18, P18, DOI 10.1109/MITP.2016.64
   Chen BW, 2013, IEEE T SYST MAN CY-S, V43, P1279, DOI 10.1109/TSMC.2013.2244211
   Chen BW, 2009, IEEE T CONSUM ELECTR, V55, P713, DOI 10.1109/TCE.2009.5174444
   Chen BW, 2009, IEEE T MULTIMEDIA, V11, P295, DOI 10.1109/TMM.2008.2009703
   Chen L C, 2014, SEMANTIC IMAGE SEGME, P1
   Chen W., 2016, SINGLE IMAGE DEPTH P
   Eigen D, 2014, DEPTH MAP PREDICTION, P1
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Garg R., 2016, Unsupervised cnn for single view depth estimation: Geometry to the rescue
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Jia Y., 2014, P 22 ACM INT C MULT, P675
   Kang SJ, 2016, COMPUT ELECTR ENG, V54, P16, DOI 10.1016/j.compeleceng.2016.06.013
   Karsch K, 2014, IEEE T PATTERN ANAL, V36, P2144, DOI 10.1109/TPAMI.2014.2316835
   Kim S, 2015, IEEE IMAGE PROC, P1895, DOI 10.1109/ICIP.2015.7351130
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19
   Lecun Y., 2015, NAT METHODS, V521, P436, DOI DOI 10.1038/nmeth.3707
   Li B, 2015, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2015.7298715
   Liu BY, 2010, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2010.5539823
   Liu MM, 2014, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2014.97
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Nilsson N. J., 2009, The Quest for Artificial Intelligence
   Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2
   Radosavljevic V, 2010, FRONT ARTIF INTEL AP, V215, P809, DOI 10.3233/978-1-60750-606-5-809
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Ristovski K, 2012, 27 AAAI C ART INT, P840
   Saxena A, 2005, ADV IN NEURAL
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Simonyan K., 2014, 14091556 ARXIV
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0
   Wang P, 2015, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2015.7298897
   Xiao JX, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00506
   Xiaofeng R, 2012, DISCRIMINATIVELY TRA, P593
   Yan Z., 2016, Combining the Best of Convolutional Layers and Recurrent Layers: A Hybrid Network for Semantic Segmentation
   Zeller N, 2016, ISPRS J PHOTOGRAMM, V118, P83, DOI 10.1016/j.isprsjprs.2016.04.010
   Zhang S, 2016, COMPUT VIS IMAGE UND, V145, P148, DOI 10.1016/j.cviu.2015.12.007
   Zhuo W, 2015, PROC CVPR IEEE, P614, DOI 10.1109/CVPR.2015.7298660
   Zoran D, 2015, IEEE I CONF COMP VIS, P388, DOI 10.1109/ICCV.2015.52
NR 46
TC 13
Z9 15
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18585
EP 18604
DI 10.1007/s11042-016-4200-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800021
DA 2024-07-18
ER

PT J
AU Jang, SB
   Ko, YW
AF Jang, Sung-Bong
   Ko, Young-Woong
TI Image display time reduction scheme for mobile devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing time; Image decoding; Mobile image viewer
ID ALGORITHM
AB Image display time is defined as the time taken to load, decode, and render images on a screen. When users attempt to open images stored on a mobile phone, they can sometimes feel that it takes a lot of time to display the images. This paper analyzes the various causes of the delay and presents ideas to reduce the time and improve the customer's experience. To evaluate these ideas, an enhanced image viewer application was implemented and evaluated quantitatively and qualitatively by comparing it to the existing viewer. Experimental results show that the proposed solutions can reduce image display time by more than 10 % for high-pixel images. In addition, it can reduce thumbnail construction times effectively.
C1 [Jang, Sung-Bong] Kumoh Natl Inst Technol, Dept Comp Software Engn, 61 Daehak Ro, Gumi 730701, Kyoung Buk, South Korea.
   [Ko, Young-Woong] Hallym Univ, Dept Comp Engn, Chunchon 200702, Gangwon, South Korea.
C3 Kumoh National University Technology; Hallym University
RP Ko, YW (corresponding author), Hallym Univ, Dept Comp Engn, Chunchon 200702, Gangwon, South Korea.
EM yuko@hallym.ac.kr
FU Kumoh National Institute of Technology; Hallym University Research Fund
   [HRF-201412-010]
FX This paper was supported by Research Fund, Kumoh National Institute of
   Technology and this research was also supported by Hallym University
   Research Fund (HRF-201412-010).
CR Choi K, 2010, IEEE T CONSUM ELECTR, V56, P1822, DOI 10.1109/TCE.2010.5606332
   Cucchiara R, 2004, IEEE T MULTIMEDIA, V6, P539, DOI [10.1109/TMM.2004.830806, 10.1109/tmm.2004.830806]
   Heo Jinkyoung, 2011, [The Journal of The Institute of Internet, Broadcasting and Communication, 한국인터넷방송통신학회 논문지], V11, P87
   Ho HC, 2010, IEEE INT SYMP CIRC S, P2844, DOI 10.1109/ISCAS.2010.5536972
   Hong J, 2012, TASK PARALLEL JPEG D
   Jiang S, 2005, USENIX ASSOCIATION PROCEEDINGS OF THE 4TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P101
   Junior GGS, 2008, INT C CONS EL 2008, V2008, P1
   Karande SJ, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P513, DOI 10.1109/IC3I.2014.7019649
   Kasar M, 2013, INT ADV RES COMPUT S, V3, P211
   Klein ST, 2003, COMPUT J, V46, P487, DOI 10.1093/comjnl/46.5.487
   Milinkovic SA, 2012, 2012 20TH TELECOMMUNICATIONS FORUM (TELFOR), P1284, DOI 10.1109/TELFOR.2012.6419451
   Mody M, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P369, DOI 10.1109/ICIIP.2013.6707617
   Papadonikolakis M, 2007, DES AUT TEST EUROPE, P159
   Roy S., 2015, Proc. ACM/EDAC/IEEE Design Automation Conference, P1, DOI [10.1145/2791405.279, DOI 10.1145/2791405.279]
   Wang XH, 2013, IEEE IMAGE PROC, P3230, DOI 10.1109/ICIP.2013.6738665
   You JH, 2013, PROCEEDINGS OF THE ASME INTERNATIONAL MECHANICAL ENGINEERING CONGRESS AND EXPOSITION - 2012, VOL 7, PTS A-D, P3231
NR 16
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17891
EP 17905
DI 10.1007/s11042-015-3179-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800017
DA 2024-07-18
ER

PT J
AU Li, J
   Singh, R
   Singh, R
AF Li, Jun
   Singh, Rishav
   Singh, Ritika
TI RETRACTED: A novel large-scale multimedia image data classification
   algorithm based on mapping assisted deep neural network (Retracted
   article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Large-scale system; Multimedia architecture; Image data classification;
   Information retrieval; Deep learning; Convolutional neural network
AB With the increasing number of the images, how to effectively manage and use these images becomes an urgent problem to be solved. The classification of the images is one of the effective ways to manage and retrieve images. In this paper, we propose a novel large-scale multimedia image data classification algorithm based on deep learning. We firstly select the image characteristics to represent the flag for retrieval, which represents the color, texture and shape characteristics respectively. A feature of color is the most basic image data, mainly including the average brightness, color histogram and dominant color, etc. What the texture refers to is the image data in the anomalous, macroscopic as well as orderly one key character that on partial has. The contour feature extraction of image data needs to rely on the edge detection, edge of the detected edge through the connection or grouping to form a meaningful image event. Secondly, we revise the convolutional neural network model based on the pooling operation optimization, the pooling is in the process of the convolution operation to extract the image characteristics of the different locations to gather statistics. Furthermore, we integrate the parallel and could storage strategy to enhance the efficiency of the proposed methodology. The performance of the algorithm is verified, compared with the other state-of-the-art approaches, the proposed one obtains the better efficiency and accuracy.
C1 [Li, Jun] Chinese Acad Sci, Quanzhou Inst Equipment Mfg, Haixi Inst, Quanzhou 362200, Peoples R China.
   [Singh, Rishav] Infosys Ltd, Bhubaneswar, Orissa, India.
   [Singh, Ritika] Amity Univ, Noida, India.
C3 Chinese Academy of Sciences; Infosys Limited; Amity University Noida
RP Li, J (corresponding author), Chinese Acad Sci, Quanzhou Inst Equipment Mfg, Haixi Inst, Quanzhou 362200, Peoples R China.
EM lijuncas@163.com
RI wang, xiao/HZI-9156-2023; singh, rishav/AAA-6991-2021
OI singh, rishav/0000-0003-2947-9046
CR Abdelhamid N, 2012, J INF KNOWL MANAG, V11, DOI 10.1142/S0219649212500116
   [Anonymous], 2015, CMU PDL 15 107
   [Anonymous], 2015, P IEEE C COMP VIS PA
   [Anonymous], ARXIV160406620
   Bae C, 2014, INT J INNOV COMPUT I, V10, P151
   Blake K, 2015, CONTEMP CLIN TRIALS, V42, P105, DOI 10.1016/j.cct.2015.03.012
   Chen B, 2013, IEEE T PATTERN ANAL, V35, P1887, DOI 10.1109/TPAMI.2013.19
   Chen CF, 2013, ISPRS J PHOTOGRAMM, V82, P1, DOI 10.1016/j.isprsjprs.2013.05.001
   Chen GW, 2015, APPL COMP INF TECHN
   Chou YC, 2014, INT INF HID MULT SIG
   Dal Mas M, 2015, SMART INNOVATION SYS, P103, DOI DOI 10.1007/978-3-319-17744-1_7
   Das R, 2015, ANNU IEEE IND CONF
   de Freitas N, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P3, DOI 10.1145/2939672.2945358
   De Rosa R, 2015, DAT MIN ICDM 2015 I
   Dharani T, 2013, 2013 INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, INFORMATICS AND MEDICAL ENGINEERING (PRIME)
   Fang YT, 2014, IEEE T VLSI SYST, V22, P1450, DOI 10.1109/TVLSI.2013.2266668
   Gelman A, 2014, AM SCI, V102, P460, DOI 10.1511/2014.111.460
   Giesecke K, 2016, WORKING PAPER
   Hannagan T, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0084843
   Howell C, 2016, KI KUNSTLICHE INTELL, P1
   Islamoglu H, 2013, 36 ANN P ANN CONV AS, P444
   Jean N, 2016, SCIENCE, V353, P790, DOI 10.1126/science.aaf7894
   Jeong YS, 2015, MULTIMED TOOLS APPL, V74, P3413, DOI 10.1007/s11042-015-2586-5
   Jiang Bian, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8724, P132, DOI 10.1007/978-3-662-44848-9_9
   Jiu MY, 2014, PATTERN RECOGN LETT, V50, P122, DOI 10.1016/j.patrec.2013.09.021
   Krizhevsky A., 2011, P ESANN, VVolume 1, P2
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   Lee C-F, 2015, 2015 INT C INT INF H
   Liu Y., 2016, CoRR
   Madadi Y, 2013, INT J COMPUT INF TEC, V1, P198
   Miller Kieran, 2014, IEEE Multimedia, V21, P84, DOI 10.1109/MMUL.2014.6
   Naaman M, 2012, MULTIMED TOOLS APPL, V56, P9, DOI 10.1007/s11042-010-0538-7
   Noda K, 2015, APPL INTELL, V42, P722, DOI 10.1007/s10489-014-0629-7
   Norouzi B, 2014, MULTIMEDIA SYST, V20, P45, DOI 10.1007/s00530-013-0314-4
   Nouaouria N, 2014, APPL SOFT COMPUT, V21, P554, DOI 10.1016/j.asoc.2014.04.018
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   SANTHANAM A, 2016, MED PHYS 3, V43
   Sarisaray-Boluk P, 2015, INT J DISTRIB SENS N, V2015, P160
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schmidtler MAR, 2014, U.S. Patent, Patent No. [8,719,197, 8719197]
   Sklan JE, 2015, SPIE MED IMAGING
   Song BQ, 2014, IEEE T GEOSCI REMOTE, V52, P5122, DOI 10.1109/TGRS.2013.2286953
   Song J, 2016, IMAGE VIS COMPUT
   Suk HI, 2016, NEUROIMAGE, V129, P292, DOI 10.1016/j.neuroimage.2016.01.005
   SUN Xiao, 2016, NEUROCOMPUTING
   Taneja S, 2014, 4 INT C ADV COMP COM
   Triguero I, 2015, KNOWL-BASED SYST, V87, P69, DOI 10.1016/j.knosys.2015.05.027
   Tseng PH, 2013, LECT NOTES COMPUT SC, V8206, P178, DOI 10.1007/978-3-642-41278-3_22
   Visco C, 2012, LEUKEMIA, V26, P2103, DOI 10.1038/leu.2012.83
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang H, 2014, 2014 I E 26 INT TOOL
   Wang J, 2015, SYST MAN CYB SMC 201
   Yang S, 2015, IEEE I CONF COMP VIS, P3676, DOI 10.1109/ICCV.2015.419
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P64, DOI 10.1109/TMM.2014.2375793
   Zeng X, 2014, DEEP LEARN SC SPEC C
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
NR 57
TC 3
Z9 3
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18687
EP 18710
DI 10.1007/s11042-017-4364-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800026
DA 2024-07-18
ER

PT J
AU Yao, SH
   Wang, T
   Shen, WM
   Pan, SM
   Chong, YW
AF Yao, Shihong
   Wang, Tao
   Shen, Weiming
   Pan Shaoming
   Chong, Yanwen
TI Research of incoherence rotated chaotic measurement matrix in compressed
   sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Measurement matrix; Compressed sensing; Chaotic sequence; Restricted
   isometry property (RIP); The noncorrelation factor
ID SIGNAL RECOVERY; RECONSTRUCTION
AB Measurement matrix construction is the hot issue of compressed sensing. How to construct a measurement matrix of good performance and easy hardware implementation is the main research problem in compressed sensing. In this paper, we present a novel simple and efficient measurement matrix named Incoherence Rotated Chaotic (IRC) matrix. We take advantage of the well pseudorandom of chaotic sequence, introduce the concept of the incoherence factor and rotation, and adopt QR decomposition to obtain the IRC measurement matrix which is suited for sparse reconstruction. The IRC matrix satisfies the Restricted Isometry Property criterion in sparse reconstruction and has a smaller RIP ratio. Simulations demonstrate IRC matrix has better performance than Gaussian random matrix, Bernoulli random matrix, Fourier matrix and can efficiently work on both natural image and remote sensing image. The peak signal-to-noise ratios of reconstructed images using IRC matrix are improved at 1.5 dB to 2.5 dB at least.
C1 [Yao, Shihong; Wang, Tao; Shen, Weiming; Pan Shaoming; Chong, Yanwen] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Luoyu Rd 129, Wuhan 430079, Hubei, Peoples R China.
C3 Wuhan University
RP Chong, YW (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Luoyu Rd 129, Wuhan 430079, Hubei, Peoples R China.
EM yao_shi_hong@whu.edu.cn; wangtao.mac@whu.edu.cn; wmshen@whu.edu.cn;
   pansm@whu.edu.cn; apollobest@126.com
RI shen, Weiming/HJZ-2337-2023; Zhang, Can/JUU-9511-2023; Shen,
   Weiming/B-7400-2013
OI Shen, Weiming/0000-0001-5204-7992
FU Foundation Research Funds for the central Universities [204201kf0242,
   204201kf0263]; National Natural Science Foundation of China [61572372,
   41271398]; Shanghai Aerospace Science and Technology Innovation Fund
   Projects [SAST201425]
FX This paper was supported by the Foundation Research Funds for the
   central Universities (204201kf0242, 204201kf0263), National Natural
   Science Foundation of China (61572372, 41271398), Shanghai Aerospace
   Science and Technology Innovation Fund Projects (SAST201425).
CR [Anonymous], 2013, BREAKING COHERENCE B
   Bajwa WU, 2007, 2007 IEEE/SP 14TH WORKSHOP ON STATISTICAL SIGNAL PROCESSING, VOLS 1 AND 2, P294, DOI 10.1109/SSP.2007.4301266
   Baraniuk R, 2008, CONSTR APPROX, V28, P253, DOI 10.1007/s00365-007-9003-x
   Berinde R., 2008, Sparse recovery using sparse randommatrices
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   DeVore RA, 2007, J COMPLEXITY, V23, P918, DOI 10.1016/j.jco.2007.04.002
   Do TT, 2012, IEEE T SIGNAL PROCES, V60, P139, DOI 10.1109/TSP.2011.2170977
   Do TT, 2008, CONF REC ASILOMAR C, P581, DOI 10.1109/ACSSC.2008.5074472
   Donoho DL, 2012, IEEE T INFORM THEORY, V58, P1094, DOI 10.1109/TIT.2011.2173241
   Donoho DL, 2006, SIGNAL PROCESS, V86, P511, DOI 10.1016/j.sigpro.2005.05.027
   Donoho DL, 2006, TR20062 STANDF U DEP
   Elad M, 2002, IEEE T INFORM THEORY, V48, P2558, DOI 10.1109/TIT.2002.801410
   Gesen Zhang, 2010, Proceedings of the 2010 International Conference on Information and Automation (ICIA 2010), P455, DOI 10.1109/ICINFA.2010.5512379
   Huang W, 2004, ERGOD THEOR DYN SYST, V24, P825, DOI 10.1017/S0143385703000543
   Linh-Trung N, 2008, ATNAC: 2008 AUSTRALASIAN TELECOMMUNICATION NETWOKS AND APPLICATIONS CONFERENCE, P219, DOI 10.1109/ATNAC.2008.4783326
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Rauhut H., 2010, THEORETICAL FOUNDATI, V9, P1, DOI DOI 10.1515/9783110226157.1
   Rauhut H, 2012, APPL COMPUT HARMON A, V32, P242, DOI 10.1016/j.acha.2011.05.001
   Rudelson M, 2008, COMMUN PUR APPL MATH, V61, P1025, DOI 10.1002/cpa.20227
   Rui Sun, 2012, 2012 International Conference on Systems and Informatics (ICSAI 2012), P1994, DOI 10.1109/ICSAI.2012.6223441
   Sharon Y, 2007, UILUENG072208 CSL U
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang HY, 2011, COMPUT STAT DATA AN, V55, P2925, DOI 10.1016/j.csda.2011.04.021
   Yin W., 2010, P INT SOC OPT PHOT V
   Yu L, 2010, IEEE SIGNAL PROC LET, V17, P731, DOI 10.1109/LSP.2010.2052243
   Yu NY, 2013, EURASIP J ADV SIG PR, P1324
   Yu Y, 2011, IEEE T SIGNAL PROCES, V59, P5338, DOI 10.1109/TSP.2011.2162328
   Zhang BJ, 2013, EURASIP J WIREL COMM, DOI [10.1186/1687-1499-2013-161, 10.1155/2013/264742]
NR 32
TC 12
Z9 14
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17699
EP 17717
DI 10.1007/s11042-015-2953-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800006
DA 2024-07-18
ER

EF