FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Tabejamaat, M
   Mousavi, A
AF Tabejamaat, Mohsen
   Mousavi, Abdolmajid
TI A coding-guided holistic-based palmprint recognition approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Palmprint recognition; Feature-based method; Holistic-based method;
   Coding-based method
ID FACE; VERIFICATION
AB In the past few years, the need for accuracy and robustness against luminosity variations has drawn a considerable share of the palmprint research toward coding-based approaches. However, on the downside coding-based approaches require a high computational cost. On the contrary, while holistic-based palmprint recognition methods are easy to implement and have low computational burden, they usually do not result in a highly desirable accuracy. As a result, more recently hybridization of the holistic-based and coding-based methods has gained a boost. These hybridization schemes take advantages of both holistic and coding information to achieve a better performance. However, their computational burden due to incorporating the coding approach is still much heavier than the holistic methods. In this paper, we propose a new hybridization scheme based on Anisotropic Filter (AF) coding and the two-phase test sample representation (TPTSR) for the palmprint identification. In our scheme, the coding-based method is only applied on a super narrowed gallery in order to measure the classification confidence for a given test sample. Then, we apply our Guided Holistic (GH)-based method for classifying the test sample if the holistic-based algorithm is not sufficiently confident. Experimental results demonstrate the efficiency of our method in enhancing both the complexity cost and the accuracy of the results.
C1 [Tabejamaat, Mohsen; Mousavi, Abdolmajid] Lorestan Univ, Dept Elect Engn, Fac Engn, Khorramabad, Iran.
C3 Lorestan University
RP Mousavi, A (corresponding author), Lorestan Univ, Dept Elect Engn, Fac Engn, Khorramabad, Iran.
EM tabejamaat.m@fe.lu.ac.ir; mousavi.m@lu.ac.ir
CR [Anonymous], 1982, Digital Picture Processing
   Connie T, 2005, IMAGE VISION COMPUT, V23, P501, DOI 10.1016/j.imavis.2005.01.002
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Geng C, 2013, MACH VISION APPL, V24, P537, DOI 10.1007/s00138-012-0423-7
   Guo Z., 2011, 2011 IEEE Aerospace Conference, P1
   Guo ZH, 2009, PATTERN RECOGN LETT, V30, P1219, DOI 10.1016/j.patrec.2009.05.010
   Hengjian Li, 2012, Journal of Software, V7, P1827, DOI 10.4304/jsw.7.8.1827-1834
   Jia W, 2008, PATTERN RECOGN, V41, P1504, DOI 10.1016/j.patcog.2007.10.011
   Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971
   Kong A, 2009, PATTERN RECOGN, V42, P1408, DOI 10.1016/j.patcog.2009.01.018
   Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184
   Kumar A, 2010, IEEE IMAGE PROC, P3121, DOI 10.1109/ICIP.2010.5653214
   Liu L, 2007, IEEE T IMAGE PROCESS, V16, P1584, DOI 10.1109/TIP.2007.894288
   Liu ZH, 2013, APPL INTELL, V39, P307, DOI 10.1007/s10489-012-0414-4
   Lu GM, 2003, PATTERN RECOGN LETT, V24, P1463, DOI 10.1016/S0167-8655(02)00386-0
   Malioutov DM, 2005, INT CONF ACOUST SPEE, P733
   Mi JX, 2013, OPTIK, V124, P6786, DOI 10.1016/j.ijleo.2013.05.099
   Nibouche O, 2012, DIGIT SIGNAL PROCESS, V22, P348, DOI 10.1016/j.dsp.2011.10.011
   Ribaric S, 2005, IEEE T PATTERN ANAL, V27, P1698, DOI 10.1109/TPAMI.2005.209
   Tamrakar D, 2015, SIGNAL IMAGE VIDEO P, V9, P535, DOI 10.1007/s11760-013-0475-9
   Wu X, 2005, IEEE INT C IM PROC I, P29
   Wu X, 2014, NEURAL COMPUT APPL, V24, P1341, DOI 10.1007/s00521-013-1352-8
   Wu XQ, 2006, 2006 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PTS 1 AND 2, PROCEEDINGS, P751, DOI 10.1109/ICCIAS.2006.294235
   Wu XQ, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P4881
   Wu XQ, 2003, PATTERN RECOGN LETT, V24, P2829, DOI 10.1016/S0167-8655(03)00141-7
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang D, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071391
   Zhang SW, 2013, OPTIK, V124, P3340, DOI 10.1016/j.ijleo.2012.10.048
   Zhang YQ, 2012, NEURAL COMPUT APPL, V21, P1835, DOI 10.1007/s00521-011-0521-x
NR 31
TC 6
Z9 7
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 7731
EP 7747
DI 10.1007/s11042-016-3427-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800007
DA 2024-07-18
ER

PT J
AU Wieser, E
   Seidl, M
   Zeppelzauer, M
AF Wieser, Ewald
   Seidl, Markus
   Zeppelzauer, Matthias
TI A study on skeletonization of complex petroglyph shapes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skeletonization; Petroglyphs; Shape pre-processing; Real-world shape
   data
AB In this paper, we present a study on skeletonization of real-world shape data. The data stem from the cultural heritage domain and represent contact tracings of prehistoric petroglyphs. Automated analysis can support the work of archeologists on the investigation and categorization of petroglyphs. One strategy to describe petroglyph shapes is skeleton-based. The skeletonization of petroglyphs is challenging since their shapes are complex, contain numerous holes and are often incomplete or disconnected. Thus they pose an interesting testbed for skeletonization. We present a large real-world dataset consisting of more than 1100 petroglyph shapes. We investigate their properties and requirements for the purpose of skeletonization, and evaluate the applicability of state-of-the-art skeletonization and skeleton pruning algorithms on this type of data. Experiments show that pre-processing of the shapes is crucial to obtain robust skeletons. We propose an adaptive pre-processing method for petroglyph shapes and improve several state-of-the-art skeletonization algorithms to make them suitable for the complex material. Evaluations on our dataset show that 79.8 % of all shapes can be improved by the proposed pre-processing techniques and are thus better suited for subsequent skeletonization. Furthermore we observe that a thinning of the shapes produces robust skeletons for 83.5 % of our shapes and outperforms more sophisticated skeletonization techniques.
C1 [Wieser, Ewald; Seidl, Markus; Zeppelzauer, Matthias] St Polten Univ Appl Sci, Media Comp Res Grp, Matthias Corvinus Str 15, A-3100 St Polten, Austria.
C3 St. Polten University of Applied Sciences
RP Wieser, E (corresponding author), St Polten Univ Appl Sci, Media Comp Res Grp, Matthias Corvinus Str 15, A-3100 St Polten, Austria.
EM ewald.wieser@fhstp.ac.at; markus.seidl@fhstp.ac.at;
   matthias.zeppelzauer@fhstp.ac.at
OI Seidl, Markus/0000-0002-7966-3602; Zeppelzauer,
   Matthias/0000-0003-0413-4746
FU FH St. Polten-University of Applied Sciences; European Community
   [600545]
FX Open access funding provided by FH St. Polten-University of Applied
   Sciences. The images of petroglyph tracings used in this paper have been
   kindly provided by the CCSP - Centro Camuno di Studi Preistorici and by
   Alberto Marretta, who we thank. This work has been carried out in the
   project 3D-PITOTI which is funded from the European Community's Seventh
   Framework Programme (FP7/2007-2013) under grant agreement no 600545;
   2013-2016. Further information about the project can be found at
   http://3d-pitoti.eu.
CR [Anonymous], DIGITAL APPL ARCHAEO
   Arcelli C., 1996, Topological Algorithms for Digital Image Processing, volume 19 of Machine Intelligence and Pattern Recognition, V19, P99
   Bai X, 2007, LECT NOTES COMPUT SC, V4679, P362
   Bai X, 2007, IEEE T PATTERN ANAL, V29, P449, DOI 10.1109/TPAMI.2007.59
   BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0
   Blum H., 1967, MODELS PERCEPTION SP, P362, DOI DOI 10.1142/S0218654308001154
   Chaudhari A., 2013, IOSR Journal of Computer Engineering, V9, P53
   Chippindale C, 1998, NEW DIRECTIONS ARCHA
   di Baja GS, 2006, LECT NOTES COMPUT SC, V4225, P1
   Dinneen GeraldPaul., 1955, P MARCH 1 3 1955 W J, P94
   Ho S, 1984, 557 U WISC MAD DEP C
   Howe NR, 2004, CODE IMPLEMENTATIONS
   Kirkpatrick D. G., 1979, 20th Annual Symposium of Foundations of Computer Science, P18, DOI 10.1109/SFCS.1979.15
   Kirsch R A., 1958, Papers and discussions presented at the December 9-13, 1957, eastern joint computer conference, P221
   Krinidis S, 2013, IMAGE VISION COMPUT, V31, P533, DOI 10.1016/j.imavis.2013.04.005
   Krinidis S, 2009, IEEE T IMAGE PROCESS, V18, P1, DOI 10.1109/TIP.2008.2007351
   Latecki LJ, 1999, LECT NOTES COMPUT SC, V1682, P398
   Liu HZ, 2013, PATTERN RECOGN LETT, V34, P1138, DOI 10.1016/j.patrec.2013.03.013
   Liu HZ, 2012, PATTERN RECOGN LETT, V33, P2113, DOI 10.1016/j.patrec.2012.07.014
   MONTANARI U, 1968, J ACM, V15, P600, DOI 10.1145/321479.321486
   MONTANARI U, 1969, J ACM, V16, P534, DOI 10.1145/321541.321543
   Ogniewicz R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P63, DOI 10.1109/CVPR.1992.223226
   Parker J.R., 2011, ALGORITHMS IMAGE PRO, VSecond
   Seidl M, 2014, VISART WHERE COMPUTE
   Seidl M., 2012, P 8 IND C COMP VIS G, P66
   Shaked D, 1998, COMPUT VIS IMAGE UND, V69, P156, DOI 10.1006/cviu.1997.0598
   Shen W, 2013, SCI CHINA INFORM SCI, V56, DOI 10.1007/s11432-012-4715-3
   Shen W, 2011, PATTERN RECOGN, V44, P196, DOI 10.1016/j.patcog.2010.08.021
   Takaki R, 2006, FORMA, V21, P243
   Telea A, 2012, P VMLS, P153
   Van Wijk J. J., 2002, P VISSYM
   Vincent Luc, 1994, SHAPE IN PICTURE, P197, DOI [10.1007/978-3-662-03039-4_13, DOI 10.1007/978-3-662-03039-4_13]
   Yang Xinzhu., 2009, Proceedings of CSA 2009, P1, DOI DOI 10.1109/APPEEC.2009.4918470
   Zhu Q, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1057
NR 34
TC 8
Z9 9
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8285
EP 8303
DI 10.1007/s11042-016-3395-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800030
OA hybrid
DA 2024-07-18
ER

PT J
AU Banday, SA
   Mir, AH
AF Banday, Shoaib Amin
   Mir, Ajaz Hussain
TI Statistical textural feature and deformable model based brain tumor
   segmentation and volume estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Magnetic Resonance Imaging (MRI); Segmentation; Gray Level Co-occurrence
   Matrix (GLCM); Gray Level Run length Matrix (GLRLM); Volume estimation;
   Jackard's similarity Index (JSI); Overlap Index(OI); ActiveContourModel
   (ACM); Principle Component Analysis (PCA)
ID ABC/2 ESTIMATION TECHNIQUE; ISUP CONSENSUS CONFERENCE; IMAGE
   SEGMENTATION; INTERNATIONAL SOCIETY; FEATURE-SELECTION; FACE
   RECOGNITION; ACTIVE CONTOURS; MEDICAL IMAGES; MRI; GRADIENT
AB Segmentation and precise volume estimation of abnormalities is one of the main focus in medical image processing field for the purpose of diagnosis and treatment planning. The precise estimation of volume of the abnormality aids better prognosis, treatment planning and dose estimation. The work put forth in this paper has proposed and implemented a semiautomatic technique that yields appropriate segmented regions from MR brain images. The Segmentation technique here utilizes fusion of information beyond human perception from MR images to develop a fused feature map. The information beyond human perception include second order derivatives that are computed from an image which are discussed in detail in relevant section of this paper. This obtained feature map acts as a stopping function for the initialized curve in the framework of an active contour model to obtain a well segmented region of interest. The segmentation is carried out in all the slices of a particular dataset with initialization of the active contour required only on the first slice which makes this method fast. The obtained segmentation results are compared with ground truth segmentation results obtained from experts manually using Jackard's Co-efficient of Similarity and Overlap index. The boundaries of the segmented regions are utilized in surveyor's algorithm to compute the volume of the tumors with high accuracy. The efficacy of this volume estimation technique is illustrated with comparison to mostly used ABC/2 method and cavalieri method. The results obtained on various case studies like Craniophryngioma, High grade Glioma and Microadenoma show a good efficacy of the overall method.
C1 [Banday, Shoaib Amin; Mir, Ajaz Hussain] Natl Inst Technol, Dept Elect & Commun Engn, Srinagar 190006, Jammu & Kashmir, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Srinagar
RP Banday, SA (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Srinagar 190006, Jammu & Kashmir, India.
EM shoaibee.a@gmail.com
RI Mir, Ajaz Hussain/AAU-1265-2020
OI Mir, Ajaz Hussain/0000-0001-9777-0850
CR [Anonymous], 2010, INT J COMPUTER THEOR
   Bezdek James C., 1981, PATTERN RECOGN
   Bilgic S, 2005, CLIN NEUROL NEUROSUR, V107, P282, DOI 10.1016/j.clineuro.2004.08.001
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chakraborty A, 1996, IEEE T MED IMAGING, V15, P859, DOI 10.1109/42.544503
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Clausi DA, 2005, IEEE T IMAGE PROCESS, V14, P925, DOI 10.1109/TIP.2005.849319
   COLEMAN GB, 1979, P IEEE, V67, P773, DOI 10.1109/PROC.1979.11327
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   del Fresno M, 2009, COMPUT MED IMAG GRAP, V33, P369, DOI 10.1016/j.compmedimag.2009.03.002
   Dou WB, 2007, IMAGE VISION COMPUT, V25, P164, DOI 10.1016/j.imavis.2006.01.025
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Dunn J. C., 1973, Journal of Cybernetics, P32, DOI 10.1080/01969727308546046
   Gebel JM, 1998, STROKE, V29, P1799, DOI 10.1161/01.STR.29.9.1799
   Haffner J, 2009, PROSTATE, V69, P276, DOI 10.1002/pros.20881
   Hansasuta A, 2011, NEUROSURGERY, V69, P1200, DOI 10.1227/NEU.0b013e318222e451
   Haralick RM, ROC I971 I197 IEEE D, P650
   Huttner HB, 2006, STROKE, V37, P404, DOI 10.1161/01.STR.0000198806.67472.5c
   Jayadevappa D, 2011, IETE TECH REV, V28, P248, DOI 10.4103/0256-4602.81244
   Kapur T, 1996, Med Image Anal, V1, P109, DOI 10.1016/S1361-8415(96)80008-9
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855
   Kothari U, 1996, STROKE, V27, P1304, DOI 10.1161/01.STR.27.8.1304
   Li BN, 2011, COMPUT BIOL MED, V41, P1, DOI 10.1016/j.compbiomed.2010.10.007
   Li B, 2008, PATTERN RECOGN, V41, P3813, DOI 10.1016/j.patcog.2008.05.027
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Liew AWC, 2006, CURR MED IMAGING, V2, P91, DOI 10.2174/157340506775541604
   Luby M, 1901, J NUCL MED AJNR AM J, V34, P1901
   Magi-Galluzzi C, 2011, MODERN PATHOL, V24, P26, DOI 10.1038/modpathol.2010.158
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Massick DD, 2000, LARYNGOSCOPE, V110, P1843, DOI 10.1097/00005537-200011000-00015
   Masutani Y, 1998, LECT NOTES COMPUT SC, V1496, P1242, DOI 10.1007/BFb0056314
   MIR AH, 1995, IEEE ENG MED BIOL, V14, P781, DOI 10.1109/51.473275
   Montironi R, 2003, EUR UROL, V44, P626, DOI 10.1016/S0302-2838(03)00381-6
   Olabarriaga SD, 2001, MED IMAGE ANAL, V5, P127, DOI 10.1016/S1361-8415(00)00041-4
   Ortiz A, 2014, INFORM SCIENCES, V262, P117, DOI 10.1016/j.ins.2013.10.002
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Passat N, 2005, J MAGN RESON IMAGING, V21, P715, DOI 10.1002/jmri.20307
   Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315
   Pitas loannis., 1993, DIGITAL IMAGE PROCES
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Shang L, 2006, NEUROCOMPUTING, V69, P1782, DOI 10.1016/j.neucom.2005.11.004
   Solberg AHS, 1997, IEEE T GEOSCI REMOTE, V35, P475, DOI 10.1109/36.563288
   Unal B, 2010, EURASIAN J MED, V42, P66, DOI 10.5152/eajm.2010.20
   van der Kwast TH, 2011, MODERN PATHOL, V24, P16, DOI 10.1038/modpathol.2010.156
   Wang JZ, 2008, COMPUT MED IMAG GRAP, V32, P685, DOI 10.1016/j.compmedimag.2008.08.004
   Warfield SK, 2000, MED IMAGE ANAL, V4, P43, DOI 10.1016/S1361-8415(00)00003-7
   Weglinski T, P 7 INT C PERSP TECH, P185
   Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Xue JH, 2003, PATTERN RECOGN LETT, V24, P2549, DOI 10.1016/S0167-8655(03)00100-4
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang N, 2011, COMPUT VIS IMAGE UND, V115, P256, DOI 10.1016/j.cviu.2010.09.007
   Zhao ZQ, 2004, PATTERN RECOGN LETT, V25, P1351, DOI 10.1016/j.patrec.2004.05.008
NR 54
TC 14
Z9 14
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3809
EP 3828
DI 10.1007/s11042-016-3979-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200031
DA 2024-07-18
ER

PT J
AU Bhatnagar, G
AF Bhatnagar, Gaurav
TI Robust covert communication using high capacity watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Census transform; Hamming distance; Spectral
   decomposition
ID IMAGE WATERMARKING; MULTIPLE WATERMARKING; WAVELET TRANSFORM; HYBRID
   TECHNIQUE; SPREAD-SPECTRUM; MEDICAL IMAGES; DOMAIN; SVD; OWNERSHIP;
   SCHEME
AB Generally, in watermarking techniques the size of the watermark is very small when compared to the host image. In other words, a little amount of watermark is embedded in the huge quantity of image pixels as the notice of legitimate ownership. Contrary to that idea, this is an attempt in which the capacity of watermarking is improved by embedding huge amount of watermark efficiently in the less quantity of image pixels. The core idea behind the proposed approach is to select watermarkable pixels from the host image based on the census transform and hamming distance followed by the embedding which is done by proposed spectral decompositions, i. e., Hankel, Circulant and Topelitz spectral decomposition. Finally, a reliable watermark extraction scheme is developed which is free from the false-positive detection problem of singular values. The experimental evaluation demonstrates that the proposed scheme is expeditiously able to withstand a variety of extreme attacks and highly suitable for covert communications.
C1 [Bhatnagar, Gaurav] Indian Inst Technol Jodhpur, Dept Math, Jodhpur, Rajasthan, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Jodhpur
RP Bhatnagar, G (corresponding author), Indian Inst Technol Jodhpur, Dept Math, Jodhpur, Rajasthan, India.
EM goravdma@gmail.com
RI Bhatnagar, Gaurav/O-5817-2019
OI Bhatnagar, Gaurav/0000-0002-0282-3372
FU Science and Engineering Research Board, DST, India
FX This work was supported by the Science and Engineering Research Board,
   DST, India.
CR Agarwal H, 2015, MULTIMED TOOLS APPL, V74, P10883, DOI 10.1007/s11042-014-2212-y
   [Anonymous], COMP VIS ECCV, DOI DOI 10.1007/BFB0028345
   Barni M., 2004, WATERMARKING SYSTEMS, V1st
   Bhatnagar G, 2013, FUTURE GENER COMP SY, V29, P182, DOI 10.1016/j.future.2012.05.021
   Bhatnagar G, 2009, STUD COMPUT INTELL, V231, P375
   Bhatnagar G, 2009, COMPUT STAND INTER, V31, P1002, DOI 10.1016/j.csi.2008.09.031
   Chitla Arathi, 2016, Pattern Recognition and Image Analysis, V26, P69, DOI 10.1134/S1054661815040045
   Deng C, 2009, SIGNAL PROCESS, V89, P1531, DOI 10.1016/j.sigpro.2009.02.005
   Flusser J., 2009, Moments and Moment Invariants in Pattern Recognition
   Gray RM, 2006, FOUND TRENDS COMMUN, V2, DOI 10.1561/0100000006
   Guo JM, 2012, IEEE T IMAGE PROCESS, V21, P4808, DOI 10.1109/TIP.2012.2210236
   Hsia SC, 2002, IEICE T FUND ELECTR, VE85A, P463
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Huang HC, 2010, TELECOMMUN SYST, V44, P241, DOI 10.1007/s11235-009-9262-x
   Irany B., 2011, 17 INT C DIG SIGN PR, P1, DOI DOI 10.1109/ICDSP.2011.6004968
   Karner H, 2003, LINEAR ALGEBRA APPL, V367, P301, DOI 10.1016/S0024-3795(02)00664-X
   Korus P, 2014, MULTIMED TOOLS APPL, V68, P59, DOI 10.1007/s11042-011-0986-8
   Kundur D, 2004, IEEE T MULTIMEDIA, V6, P185, DOI 10.1109/TMM.2003.819747
   Li L, 2001, IEICE T FUND ELECTR, P889
   Li LD, 2011, AEU-INT J ELECTRON C, V65, P435, DOI 10.1016/j.aeue.2010.06.001
   Lian S., 2008, Multimedia Content Encryption: Techniques And Applications
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Luk F.T., 2003, American Mathematical Society, Fast Algorithms for Structured Matrices, V323, P169
   Pandey P, 2014, MULTIMED TOOLS APPL, V72, P2653, DOI 10.1007/s11042-013-1577-7
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Satish K, 2004, IEEE T CONSUM ELECTR, V50, P587, DOI 10.1109/TCE.2004.1309431
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2015, WIRELESS PERS COMMUN, V83, P2133, DOI 10.1007/s11277-015-2505-0
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Song CL, 2012, J VIS COMMUN IMAGE R, V23, P549, DOI 10.1016/j.jvcir.2012.01.017
   Tang LL, 2015, MULTIMED TOOLS APPL, V74, P4397, DOI 10.1007/s11042-013-1531-8
   Wang JW, 2015, MULTIMEDIA SYST, V21, P345, DOI 10.1007/s00530-013-0338-9
   Wu YD, 2005, IEEE T MULTIMEDIA, V7, P624, DOI 10.1109/TMM.2005.846774
   Zhang XP, 2005, IEEE T MULTIMEDIA, V7, P593, DOI 10.1109/TMM.2005.843357
NR 36
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3783
EP 3807
DI 10.1007/s11042-016-3978-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200030
DA 2024-07-18
ER

PT J
AU Celentano, A
   Dubois, E
AF Celentano, Augusto
   Dubois, Emmanuel
TI A layered structure for a design space dedicated to rich interactive
   multimedia content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Analytical approach; Design space; Multidimensional data; Multi-device;
   Multimedia; Zooming interface
AB In this paper we propose and discuss a layered organization for a design space suitable for the visualization of and interaction with rich information environments, made of multimedia and multidimensional information, supporting multi-device deployment. We propose to associate each design space layer to a different category of information, corresponding to different user goals and exploration spaces. Extending the focus+context and overview+detail approaches typical of complex information visualization, the layered design space and the associated information categories cover a wide range from a global universe of discourse down into the ultimate data items, through discrete intermediate steps corresponding to refinements of details and of navigation functions. Each category defines an association with a specific knowledge goal, the deployment on a suitable class of devices and the access through adequate interaction techniques. Such design process is applied to two case studies, one in the domain of cultural heritage fruition, the other in energy consumption management.
C1 [Celentano, Augusto] Univ Ca Foscari Venezia, DAIS, Venice, Italy.
   [Dubois, Emmanuel] Univ Toulouse III, Toulouse, France.
   [Dubois, Emmanuel] CNRS, IRIT, Toulouse, France.
C3 Universita Ca Foscari Venezia; Universite de Toulouse; Universite
   Toulouse III - Paul Sabatier; Universite Federale Toulouse Midi-Pyrenees
   (ComUE); Universite de Toulouse; Institut National Polytechnique de
   Toulouse; Centre National de la Recherche Scientifique (CNRS);
   Universite Toulouse III - Paul Sabatier
RP Celentano, A (corresponding author), Univ Ca Foscari Venezia, DAIS, Venice, Italy.; Dubois, E (corresponding author), Univ Toulouse III, Toulouse, France.; Dubois, E (corresponding author), CNRS, IRIT, Toulouse, France.
EM auce@dais.unive.it; emmanuel.dubois@irit.fr
RI Celentano, Andrea/JFJ-2728-2023; Celentano, Andrea/J-6190-2012
OI Celentano, Andrea/0000-0002-7104-2983; Celentano,
   Augusto/0000-0002-8574-4935
CR Abad Zahra Shakeri Hossein, 2014, P 9 ACM INT C INTERA, P69, DOI [10.1145/2669485.2669505, DOI 10.1145/2669485.2669505]
   [Anonymous], P 16 INT C 3D WEB TE
   Bark I, 2006, BCS CONF SERIES, P201, DOI 10.1007/1-84628-249-7_13
   Baudel, 2004, P OFACM CHI C HUMAN, V2, P765
   Baudisch P., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P31, DOI 10.1145/502348.502354
   Baudisch P., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P259, DOI 10.1145/503376.503423
   Beaudouin-Lafon M., 2004, Proceedings of the working conference on Advanced visual interfaces, P15, DOI DOI 10.1145/989863.989865
   Bederson B. B., 1994, UIST '94. Seventh Annual Symposium on User Interface Software and Technology. Proceedings of the ACM Symposium on User Interface Software and Technology, P17, DOI 10.1145/192426.192435
   Butkiewicz T, 2008, IEEE T VIS COMPUT GR, V14, P1165, DOI 10.1109/TVCG.2008.149
   Card SK, 1997, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P92, DOI 10.1109/INFVIS.1997.636792
   Celentano A, 2012, J VISUAL LANG COMPUT, V23, P63, DOI 10.1016/j.jvlc.2011.11.004
   Celentano Augusto, 2015, P 11 BIANN C IT SIGC, P34, DOI [10.1145/2808435.2808444, DOI 10.1145/2808435.2808444]
   Chi EH, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P69, DOI 10.1109/INFVIS.2000.885092
   Cockburn A, 2008, ACM COMPUT SURV, V41, DOI 10.1145/1456650.1456652
   Cossalter M, 2013, P VIS DAT AN VDA 201
   Coutrix C., 2006, P WORKING C ADV VISU, P43, DOI DOI 10.1145/1133265.1133274
   Elmqvist N, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1333
   Feiner S., 1990, UIST. Third Annual Symposium on User Interface Software and Technology. Proceedings of the ACM SIGGRAPH Symposium, P76, DOI 10.1145/97924.97933
   Folstad A., 2006, P 4 NORDIC C HUMAN C, P417
   Fuchs G., 2004, CODATA PRAG WORKSH I
   Hasan M, 2014, 2014 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P145, DOI 10.1109/CW.2014.28
   Hauser H., 2006, SCI VISUALIZATION VI, P305, DOI [DOI 10.1007/3-540-30790-7_18, 10.1007/354030790718]
   Hornbaek K., 2002, ACM Transactions on Computer-Human Interaction, V9, P362, DOI 10.1145/586081.586086
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Jourde F, 2008, LECT NOTES COMPUT SC, V5136, P281, DOI 10.1007/978-3-540-70569-7_25
   Kuhn W, 1996, P 7 INT S SPAT DAT H, P877
   Lam H, 2010, TR201011 UCB COMP SC
   Mackinlay J. D., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P173, DOI 10.1145/108844.108870
   May T, 2012, COMPUT GRAPH FORUM, V31, P985, DOI 10.1111/j.1467-8659.2012.03091.x
   Perlin K., 1993, Computer Graphics Proceedings, P57, DOI 10.1145/166117.166125
   Pietriga E, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1343
   Piringer H, 2004, SECOND INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P49
   Roberts JC, 2007, CMV 2007: FIFTH INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P61, DOI 10.1109/CMV.2007.20
   Sarkar M, 1993, TECH REP
   Schulz HJ, 2011, IEEE T VIS COMPUT GR, V17, P393, DOI 10.1109/TVCG.2010.79
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Stump G.M., 2003, Proceedings of ASME 2002 Design Engineering Technical Conferences, V2, P795, DOI DOI 10.1115/DETC2003/DAC-48785
   Toleman MA, 1998, SOFTWARE-CONC TOOL, V19, P109, DOI 10.1007/s003780050014
   Tufte ER, 1990, Envisioning Information
   Wang Baldonado M. Q., 2000, P WORK C ADV VIS INT, P110, DOI [10.1145/345513.345271, DOI 10.1145/345513.345271]
   Zimmerman J, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P493
NR 41
TC 3
Z9 3
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5191
EP 5220
DI 10.1007/s11042-016-3714-6
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500023
DA 2024-07-18
ER

PT J
AU Ranjani, JJ
AF Ranjani, J. Jennifer
TI Data hiding using pseudo magic squares for embedding high payload in
   digital images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Pseudo magic square; Steganography; High payload
ID MULTIPLE WATERMARKING; ROBUST
AB In this paper, a novel information hiding scheme based on pseudo magic squares is proposed. The pseudo magic square pattern is generated using the Knight's move algorithm, whereas diamond encoding (DE) and adaptive pixel pair matching (APPM) embedding schemes adapts rhombic shaped and non-uniform pattern respectively. The momentous feature of the proposed embedding scheme is its ability to generate several pseudo magic squares for a given embedding parameter. On contrary, DE and APPM map one fixed pattern to an embedding parameter. Thus, the proposed system can achieve higher payloads by concealing data using a pattern chosen from a variety of compact neighborhood sets. Depending on the size of the message bits, the order of the pseudo magic square is determined and one pattern among the set of the possible pseudo magic squares can be utilized during the embedding phase. The secret digits are embedded in the cover image based on a randomized sequence. The performance analysis in the experimental results reveal that the proposed algorithm not only provides increased payload with less distortion but also increases the security of the embedding processing by allowing the application to employ one among the several square patterns for every secure communication.
C1 [Ranjani, J. Jennifer] SASTRA Univ, Sch Comp, Tirumalaisamudram, Thanjavur, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Ranjani, JJ (corresponding author), SASTRA Univ, Sch Comp, Tirumalaisamudram, Thanjavur, India.
EM j.jenniferranjani@yahoo.co.in
RI Rajkumar, Jennifer Ranjani John/I-9753-2014
OI Rajkumar, Jennifer Ranjani John/0000-0001-8555-929X
CR [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   Chang C.-C., 2008, 2008 3 INT C INN COM, P17, DOI 10.1109/ICICIC.2008.149
   Chao RM, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/658047
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen J, 2014, SIGNAL PROCESS-IMAGE, V29, P375, DOI 10.1016/j.image.2014.01.003
   Conaire C, 2007, P IEEE INT C AC SPEE
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Hong W, 2008, ISISE 2008: INTERNATIONAL SYMPOSIUM ON INFORMATION SCIENCE AND ENGINEERING, VOL 1, P515, DOI 10.1109/ISISE.2008.153
   Kim HJ, 2010, COMPUT MATH APPL, V60, P319, DOI 10.1016/j.camwa.2010.01.006
   Lalys F, 2009, NEUROIMAGE
   Lee CF, 2008, IMAGE VISION COMPUT, V26, P1670, DOI 10.1016/j.imavis.2008.05.005
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Lin YK, 2012, J SYST SOFTWARE, V85, P2395, DOI 10.1016/j.jss.2012.05.032
   Liu YJ, 2016, IET IMAGE PROCESS, V10, P130, DOI 10.1049/iet-ipr.2014.1015
   Mali SN, 2012, DIGIT SIGNAL PROCESS, V22, P314, DOI 10.1016/j.dsp.2011.09.003
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Netravali A.N., 1988, DIGITAL PICTURES REP
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Sabeti V, 2010, PATTERN RECOGN, V43, P405, DOI 10.1016/j.patcog.2009.06.006
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Subhedar MS, 2014, COMPUT SCI REV, V95, P113
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Kieu TD, 2011, EXPERT SYST APPL, V38, P10648, DOI 10.1016/j.eswa.2011.02.122
   Voloshynovskiy S, 2001, SIGNAL PROCESS, V81, P1177, DOI 10.1016/S0165-1684(01)00039-1
   Wang HQ, 2004, COMMUN ACM, V47, P76, DOI 10.1145/1022594.1022597
   Wang JJ, 2010, SIGNAL PROCESS, V90, P2954, DOI 10.1016/j.sigpro.2010.04.022
   Wu HZ, 2015, MULTIMED TOOLS APPL, V74, P8171, DOI 10.1007/s11042-014-2050-y
   Wu N.-I., 2007, IJ Network Security, V4, P1
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 34
TC 8
Z9 8
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3715
EP 3729
DI 10.1007/s11042-016-3974-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200026
DA 2024-07-18
ER

PT J
AU Tao, DP
   Yang, XP
   Liu, WF
   Sun, SF
   Guo, YA
   Yu, Y
   Pang, JX
AF Tao, Dapeng
   Yang, Xipeng
   Liu, Weifeng
   Sun, Shuifa
   Guo, Yanan
   Yu, Ying
   Pang, Jianxin
TI Cauchy Estimator Discriminant Learning for RGB-D Sensor-based Scene
   Classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RGB-D sensors; Scene classification; Dimensional reduction; Patch
   alignment framework; Cauchy estimator
ID IMAGE CLASSIFICATION; TENSOR
AB Because depth information has shown its effectiveness in scene classification, RGB-D sensor-based scene classification has received wide attention. However, when images are polluted by noise in the transmission process, the recognition rate will decline significantly. Furthermore, after adopting feature representation schemes, the dimensionality of concatenated features that are extracted from the RGB image and depth image pair is very high. Therefore, a new dimensional reduction algorithm called Cauchy estimator discriminant learning (CEDL) is presented in this paper. CEDL simultaneously addresses two goals: (1) to decrease negative influences to some extent when there is noise in the input samples; (2) to preserve the local and global geometry structure of the input samples. Experiments with the frequently used NYU Depth V1 dataset suggest the effectiveness of CEDL compared with other state-of-the-art scene classification methods.
C1 [Tao, Dapeng; Yang, Xipeng; Guo, Yanan; Yu, Ying] Yunnan Univ, Coll Informat, Kunming, Peoples R China.
   [Tao, Dapeng; Yang, Xipeng; Sun, Shuifa] China Three Gorges Univ, Hubei Key Lab Intelligent Vis Based Monitoring, Yichang, Peoples R China.
   [Liu, Weifeng] China Univ Petr East China, Qingdao, Peoples R China.
   [Pang, Jianxin] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
C3 Yunnan University; China Three Gorges University; China University of
   Petroleum; Chinese Academy of Sciences; Shenzhen Institute of Advanced
   Technology, CAS
RP Liu, WF (corresponding author), China Univ Petr East China, Qingdao, Peoples R China.
EM liuwf@upc.edu.cn
RI liu, weifeng/B-7909-2008; Guo, yanan/KPY-7899-2024; Tao,
   Dapeng/E-8649-2013
OI Tao, Dapeng/0000-0003-0783-5273
FU National Natural Science Foundation of China [61572486, 61402458,
   61301242, 61271407, 61263048]; Guangdong Natural Science Funds
   [2014A030310252]; Shenzhen Technology Project [JCYJ20140901003939001];
   Hubei Key Laboratory of Intelligent Vision Based Monitoring for
   Hydroelectric Engineering Program [2014KLA01]; Young and Middle-Aged
   Backbone Teachers' Cultivation Plan of Yunnan University [XT412003];
   China University of Petroleum (East China) [14CX02203A]; Fundamental
   Research Funds for the Central Universities
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61572486, 61402458, 61301242, 61271407
   and 61263048, the Guangdong Natural Science Funds under Grant
   2014A030310252, the Shenzhen Technology Project under Grant
   JCYJ20140901003939001, Hubei Key Laboratory of Intelligent Vision Based
   Monitoring for Hydroelectric Engineering Program under Grant 2014KLA01,
   the Young and Middle-Aged Backbone Teachers' Cultivation Plan of Yunnan
   University under Grant XT412003, the Fundamental Research Funds for the
   Central Universities, China University of Petroleum (East China) under
   Grant 14CX02203A.
CR [Anonymous], P 17 ACM INT C MULT
   [Anonymous], 2003, P 11 ACM INT C MULT
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2011, P IEEE INT C COMP VI
   Bai S, 2014, 2014 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING (ICALIP), VOLS 1-2, P200, DOI 10.1109/ICALIP.2014.7009786
   Bo L., 2013, EXPT ROBOTICS VOLUME, P387, DOI DOI 10.1007/978-3-319-00065-7
   Bo LF, 2011, IEEE INT C INT ROBOT, P821, DOI 10.1109/IROS.2011.6048717
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389
   Chen Yixin, 2003, P 5 ACM SIGMM INT WO, P193
   Desingh K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.98
   Duan L, 2015, LECT NOTES COMPUT SC, V9050, P104, DOI 10.1007/978-3-319-18123-3_7
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Graham Daniel B, 1998, CHARACTERISING VIRTU, P446
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   He XF, 2004, ADV NEUR IN, V16, P153
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Li Li-Jia., 2012, Trends and Topics in Computer Vision, P57
   Liang Y, 2014, J SIGNAL PROCESS SYS, V74, P59, DOI 10.1007/s11265-013-0809-4
   Liu TL, 2016, IEEE T PATTERN ANAL, V38, P447, DOI 10.1109/TPAMI.2015.2456899
   Madokoro H, 2012, 2012 PROCEEDINGS OF SICE ANNUAL CONFERENCE (SICE), P1568
   Mariscal-Ramirez JA, 2015, MULTIMED TOOLS APPL, V74, P9175, DOI 10.1007/s11042-014-2074-3
   Mizera I, 2002, STAT PROBABIL LETT, V57, P79, DOI 10.1016/S0167-7152(02)00057-3
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shao L, 2014, IEEE T NEUR NET LEAR, V25, P1359, DOI 10.1109/TNNLS.2013.2293418
   Shao L, 2013, IEEE T CYBERNETICS, V43, P1314, DOI 10.1109/TCYB.2013.2276144
   Silberman N., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P601, DOI 10.1109/ICCVW.2011.6130298
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tom M, 2015, MULTIMED TOOLS APPL, V74, P9323, DOI 10.1007/s11042-014-2083-2
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   Wang DL, 2005, IEEE T NEURAL NETWOR, V16, P1401, DOI 10.1109/TNN.2005.852235
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang XY, 2015, MULTIMED TOOLS APPL, V74, P9491, DOI 10.1007/s11042-014-2130-z
   Wang XQ, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 4, PROCEEDINGS, P125, DOI 10.1109/ICNC.2008.718
   Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578
   Yuan Yao, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P705, DOI 10.1109/ICME.2012.48
   Zhang LF, 2015, PATTERN RECOGN, V48, P3102, DOI 10.1016/j.patcog.2014.12.016
   Zhang LF, 2015, SIGNAL PROCESS, V106, P245, DOI 10.1016/j.sigpro.2014.08.005
   Zhang TH, 2009, IEEE T KNOWL DATA EN, V21, P1299, DOI 10.1109/TKDE.2008.212
   Zhu F, 2014, INT J COMPUT VISION, V109, P42, DOI 10.1007/s11263-014-0703-y
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
NR 45
TC 1
Z9 1
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4471
EP 4489
DI 10.1007/s11042-016-3370-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200062
DA 2024-07-18
ER

PT J
AU Castellanos, WE
   Guerri, JC
   Arce, P
AF Castellanos, Wilder E.
   Guerri, Juan C.
   Arce, Pau
TI SVCEval-RA: an evaluation framework for adaptive scalable video
   streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video evaluation framework; Adaptive scalable video; SVC video
   streaming; Scalable video coding
ID TRANSMISSION; PERFORMANCE; MPEG-4; MODEL
AB Multimedia content adaption strategies are becoming increasingly important for effective video streaming over the actual heterogeneous networks. Thus, evaluation frameworks for adaptive video play an important role in the designing and deploying process of adaptive multimedia streaming systems. This paper describes a novel simulation framework for rate-adaptive video transmission using the Scalable Video Coding standard (H.264/SVC). Our approach uses feedback information about the available bandwidth to allow the video source to select the most suitable combination of SVC layers for the transmission of a video sequence. The proposed solution has been integrated into the network simulator NS-2 in order to support realistic network simulations. To demonstrate the usefulness of the proposed solution we perform a simulation study where a video sequence was transmitted over a three network scenarios. The experimental results show that the Adaptive SVC scheme implemented in our framework provides an efficient alternative that helps to avoid an increase in the network congestion in resource-constrained networks. Improvements in video quality, in terms of PSNR (Peak Signal to Noise Ratio) and SSIM (Structural Similarity Index) are also obtained.
C1 [Castellanos, Wilder E.; Guerri, Juan C.; Arce, Pau] Univ Politecn Valencia, Inst Telecommun & Multimedia Applicat iTEAM, Valencia, Spain.
C3 Universitat Politecnica de Valencia
RP Guerri, JC (corresponding author), Univ Politecn Valencia, Inst Telecommun & Multimedia Applicat iTEAM, Valencia, Spain.
EM wilcashe@upv.es; jcguerri@dcom.upv.es; paarvi@iteam.upv.es
RI Arce, Pedro/L-1268-2014; Guerri, Juan Carlos/K-9659-2014
OI Guerri, Juan Carlos/0000-0002-5807-1923; Castellanos,
   Wilder/0000-0003-0311-492X; Arce, Pau/0000-0001-5726-9228
CR Alabdulkarim MN, 2012, 2012 8 INT C WIR COM, P1
   [Anonymous], RECENT ADV VIDEO COD
   [Anonymous], 2011, Proc. second annu. acm conf. multimed. syst.-mmsys'11, DOI DOI 10.1145/1943552.1943574
   [Anonymous], ROUTE RECOVERY ALGOR, DOI DOI 10.1007/978-3-642-29479-2_7
   Birkos K, 2013, 2013 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE (WCNC), P1633
   Castellanos W, 2015, COMPUT COMMUN
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Choupani R, 2014, MULTIMED TOOLS APPL, V69, P843, DOI 10.1007/s11042-012-1150-9
   Dai M, 2009, IEEE T MULTIMEDIA, V11, P1010, DOI 10.1109/TMM.2009.2021802
   Detti A, 2009, IEEE SYMP COMP COMMU, P1017
   Espina F, 2014, MULTIMED TOOLS APPL, V72, P361, DOI 10.1007/s11042-012-1344-1
   Fiems D, 2012, MULTIMED TOOLS APPL, V58, P125, DOI 10.1007/s11042-010-0713-x
   Floyd S., Datagram congestion control protocol (DCCP)
   Floyd S., 2008, TCP Friendly Rate Control (TFRC): Protocol Specification
   Fraz M, 2009, 2 INT C COMP CONTR C, P1
   ISO/IEC, 2014, INF TECHN DYN AD S 1
   Ivrlac MT, 2009, SIGNAL PROCESS-IMAGE, V24, P651, DOI 10.1016/j.image.2009.04.005
   Karki R, 2010, NOSSDAV 2010: PROCEEDINGS OF THE 20TH INTERNATIONAL WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO, P111
   Ke CH, 2012, KSII T INTERNET INF, V6, P379, DOI 10.3837/tiis.2012.01.021
   Kei CH, 2008, J INF SCI ENG, V24, P425
   Klaue J, 2003, LECT NOTES COMPUT SC, V2794, P255, DOI 10.1007/978-3-540-45232-4_16
   Lie A, 2008, MULTIMEDIA SYST, V14, P33, DOI 10.1007/s00530-007-0110-0
   Moving Pictures Experts Group and ITU-T Video Coding Experts Group, 2011, H 264 SVC REF SOFTW
   Nightingale J, 2014, MULTIMED TOOLS APPL, V70, P2011, DOI 10.1007/s11042-012-1219-5
   Parmar H., 2012, Real-time messaging protocol (RTMP) specification
   Politis I, 2012, SIGNAL PROCESS-IMAGE, V27, P814, DOI 10.1016/j.image.2012.01.006
   Pozueco L, 2013, COMPUT ELECTR ENG, V39, P775, DOI 10.1016/j.compeleceng.2013.01.015
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Seo HY, 2013, ETRI J, V35, P655, DOI 10.4218/etrij.13.0112.0124
   Sohn H, 2010, IEEE T BROADCAST, V56, P269, DOI 10.1109/TBC.2010.2050628
   Sousa-Vieira ME, 2011, LECT NOTES COMPUT SC, V6751, P149
   Tanwir S, 2014, FOCUS SER, DOI DOI 10.1002/9781118931066
   Tanwir S, 2013, IEEE COMMUN SURV TUT, V15, P1778, DOI 10.1109/SURV.2013.010413.00071
   Le TA, 2014, MULTIMED TOOLS APPL, V72, P1239, DOI 10.1007/s11042-013-1444-6
   Van der Auwera G, 2008, ADV MULTIMED, V2008, DOI 10.1155/2008/164027
   Wang YB, 2005, MULTIMED TOOLS APPL, V27, P411, DOI 10.1007/s11042-005-3757-6
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Wien M, 2007, IEEE T CIRC SYST VID, V17, P1194, DOI 10.1109/TCSVT.2007.905530
NR 38
TC 6
Z9 7
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 437
EP 461
DI 10.1007/s11042-015-3046-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000020
OA Green Published
DA 2024-07-18
ER

PT J
AU Deng, X
   Da, FP
   Shao, HJ
AF Deng, Xing
   Da, Feipeng
   Shao, Haijian
TI Expression-robust 3D face recognition based on feature-level fusion and
   feature-region fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D face recognition; Feature-region fusion; Feature-level fusion;
   Dimensionality reduction; Non-rigid point set registration
ID REGISTRATION; MULTISCALE
AB 3D face shape is essentially a non-rigid free-form surface, which will produce non-rigid deformation under expression variations. In terms of that problem, a promising solution named Coherent Point Drift (CPD) non-rigid registration for the non-rigid region is applied to eliminate the influence from the facial expression while guarantees 3D surface topology. In order to take full advantage of the extracted discriminative feature of the whole face under facial expression variations, the novel expression-robust 3D face recognition method using feature-level fusion and feature-region fusion is proposed. Furthermore, the Principal Component Analysis and Linear Discriminant Analysis in combination with Rotated Sparse Regression (PL-RSR) dimensionality reduction method is presented to promote the computational efficiency and provide a solution to the curse of dimensionality problem, which benefit the performance optimization. The experimental evaluation indicates that the proposed strategy has achieved the rank-1 recognition rate of 97.91 % and 96.71 % based on Face Recognition Grand Challenge (FRGC) v2.0 and Bosphorus respectively, which means the proposed approach outperforms state-of-the-art approach.
C1 [Deng, Xing; Da, Feipeng; Shao, Haijian] Southeast Univ, Dept Automat, Nanjing 210096, Jiangsu, Peoples R China.
   [Deng, Xing; Da, Feipeng; Shao, Haijian] Southeast Univ, Minist Educ, Key Lab Measurement & Control Complex Syst, Nanjing 210096, Jiangsu, Peoples R China.
C3 Southeast University - China; Southeast University - China
RP Da, FP (corresponding author), Southeast Univ, Dept Automat, Nanjing 210096, Jiangsu, Peoples R China.; Da, FP (corresponding author), Southeast Univ, Minist Educ, Key Lab Measurement & Control Complex Syst, Nanjing 210096, Jiangsu, Peoples R China.
EM dafp@seu.edu.cn
FU National Natural Science Foundation of China [51175081, 51475092,
   61405034]; Doctoral Fund of Ministry of Education of China
   [20130092110027]
FX This research is supported by National Natural Science Foundation of
   China (No. 51175081, No. 51475092, No. 61405034), Doctoral Fund of
   Ministry of Education of China (No. 20130092110027).
CR Alyüz N, 2010, IEEE T INF FOREN SEC, V5, P425, DOI 10.1109/TIFS.2010.2054081
   [Anonymous], COMP VIS PATT REC IE
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bronstein AM, 2007, IEEE T IMAGE PROCESS, V16, P188, DOI 10.1109/TIP.2006.884940
   Cai L, 2012, IET COMPUT VIS, V6, P468, DOI 10.1049/iet-cvi.2011.0105
   Cai L, 2012, IEEE COMPUT GRAPH, V32, P37, DOI 10.1109/MCG.2010.99
   Chang KI, 2006, IEEE T PATTERN ANAL, V28, P1695, DOI 10.1109/TPAMI.2006.210
   Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389
   Daoudi M, 2013, 3D FACE MODELING, ANALYSIS AND RECOGNITION, pIX
   Drira H, 2013, IEEE T PATTERN ANAL, V35, P2270, DOI 10.1109/TPAMI.2013.48
   Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287
   Friedman J, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i01
   Gökberk B, 2009, ADV PATTERN RECOGNIT, P217, DOI 10.1007/978-1-84882-385-3_9
   Gu XF, 2002, ACM T GRAPHIC, V21, P355
   Gupta P, 2014, EXPRESSION INVARIANT, P266
   Hiremath P. S., 2014, International Journal of Image, Graphics and Signal Processing, V6, P36, DOI 10.5815/ijigsp.2014.07.05
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   Lee YH, 2004, IEEE IMAGE PROC, P1429
   Lei YJ, 2014, PATTERN RECOGN, V47, P509, DOI 10.1016/j.patcog.2013.07.018
   Lei YJ, 2013, PATTERN RECOGN, V46, P24, DOI 10.1016/j.patcog.2012.06.023
   Li HB, 2014, NEUROCOMPUTING, V133, P179, DOI 10.1016/j.neucom.2013.11.018
   Li XL, 2012, IMAGE VISION COMPUT, V30, P668, DOI 10.1016/j.imavis.2012.07.011
   Lin WY, 2014, MULTIMED TOOLS APPL, V68, P877, DOI 10.1007/s11042-012-1092-2
   Liu YH, 2004, PATTERN RECOGN, V37, P211, DOI 10.1016/S0031-3203(03)00239-5
   Lu XG, 2006, IEEE T PATTERN ANAL, V28, P31, DOI 10.1109/TPAMI.2006.15
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mian AS, 2008, INT J COMPUT VISION, V79, P1, DOI 10.1007/s11263-007-0085-5
   Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105
   Ming Y, 2014, NEUROCOMPUTING, V129, P445, DOI 10.1016/j.neucom.2013.09.014
   Mohammadzade H, 2013, IEEE T PATTERN ANAL, V35, P381, DOI 10.1109/TPAMI.2012.107
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Phillips P.J., 2006, P C COMP VIS PATT RE, P947
   Queirolo CC, 2010, IEEE T PATTERN ANAL, V32, P206, DOI 10.1109/TPAMI.2009.14
   Ritter J, 2002, WAVELET BASED IMAGE
   Savran A., 2008, BIOID, P47, DOI [DOI 10.1007/978-3-540-89991-4_6, DOI 10.1007/978-3-540-89991-4_]
   Smeets D, 2013, COMPUT VIS IMAGE UND, V117, P158, DOI 10.1016/j.cviu.2012.10.002
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Wang XQ, 2010, INT CONF SIGN PROCES, P86, DOI 10.1109/ICOSP.2010.5656654
   Yi Jin, 2011, 2011 6th International Conference on Computer Science & Education (ICCSE 2011), P860, DOI 10.1109/ICCSE.2011.6028773
   Zhang L, 2006, VISUAL COMPUT, V22, P43, DOI 10.1007/s00371-005-0352-9
NR 43
TC 6
Z9 6
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 13
EP 31
DI 10.1007/s11042-015-3012-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000002
DA 2024-07-18
ER

PT J
AU Krishnamoorthi, R
   Murali, P
AF Krishnamoorthi, R.
   Murali, P.
TI A selective image encryption based on square-wave shuffling with
   orthogonal polynomials transformation suitable for mobile devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Orthogonal polynomials transform (OPT); Zero-cross edge detection;
   Chaos; Region of interest (ROI); Selective encryption; Smart-phone
   security; Square-wave shuffling
ID ALGORITHM
AB In this paper, a selective image encryption algorithm based on square-wave shuffling in the orthogonal polynomials domain is proposed. This algorithm is adaptive to the user device's computing power, as it can operate in the spatial/frequency/hybrid domain. Simultaneous confusion and diffusion is performed on important regions, while in unimportant regions, shuffling is conducted; chaotic maps are used for both. To obtain the encrypted image, a new shuffling method, called square-wave shuffling, is proposed and applied. Extensive experiments have been conducted in PCs and in smart-phones with the Android programming environment. Its suitability to these devices is verified, and the superiority of the proposed method in comparison to other contemporary methods is also reported.
C1 [Krishnamoorthi, R.; Murali, P.] Anna Univ, Dept Comp Sci & Engn, Vis Lab, BIT Campus, Madras, Tamil Nadu, India.
C3 Anna University; Anna University Chennai
RP Krishnamoorthi, R (corresponding author), Anna Univ, Dept Comp Sci & Engn, Vis Lab, BIT Campus, Madras, Tamil Nadu, India.
EM rkrish07@yahoo.com; pmurali_me@rediffmail.com
RI P, Murali/IUN-8987-2023
OI P., Murali/0000-0003-4988-3345; Ramasamy,
   Krishnamoorthy/0000-0003-1823-5855
CR Bhatnagar G, 2012, DIGIT SIGNAL PROCESS, V22, P648, DOI 10.1016/j.dsp.2012.02.005
   Chen WB, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P94
   Fisch Mark M., 2004, EUR SIGN PROC C EUSI, P6
   Flayh NA, 2008, INT CONF SIGN PROCES, P797, DOI 10.1109/ICOSP.2008.4697770
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu C, 2011, OPT COMMUN, V284, P5415, DOI 10.1016/j.optcom.2011.08.013
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Krikor L., 2009, EUR J SCI RES, V32, P47
   Krishnamoorthi R, 2008, INT J COMPUT SCI NET, V8, P195
   Krishnamoorthi R, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P107, DOI 10.1109/SPIN.2014.6776931
   Krishnamoorthi R, 2012, J VIS COMMUN IMAGE R, V23, P18, DOI 10.1016/j.jvcir.2011.07.011
   Krishnamoorthi R, 2009, IMAGE VISION COMPUT, V27, P999, DOI 10.1016/j.imavis.2008.08.006
   Krishnamoorthi R, 1998, INFORM SCIENCES, V112, P51, DOI 10.1016/S0020-0255(98)10022-1
   Li SJ, 2005, INTERNET COMMUN SER, P133
   Lian SG, 2003, 2003 INTERNATIONAL CONFERENCE ON COMPUTER NETWORKS AND MOBILE COMPUTING, PROCEEDINGS, P372
   Liu HJ, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P3016, DOI 10.1109/ICYCS.2008.449
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Naeem EA, 2009, 2009 INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES 2009), P71, DOI 10.1109/ICCES.2009.5383309
   Pang CJ, 2009, NSWCTC 2009: INTERNATIONAL CONFERENCE ON NETWORKS SECURITY, WIRELESS COMMUNICATIONS AND TRUSTED COMPUTING, VOL 2, PROCEEDINGS, P711, DOI 10.1109/NSWCTC.2009.191
   Puech W., 2005, EUR SIGN PROC C EUSI
   Saga H, 1994, SPACE FILLING CURVES
   Schneier B., 1996, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Stallings W., 2006, Cryptography and Network Security, V4th
   Taneja Nidhi, 2011, MULTIMED TOOLS APPL, P1
   Van Droogenbroeck M., 2002, ACIVS'2002: Advanced Concepts for Intelligent Vision Systems, P90
   Van Droogenbroeck M., 2004, IEEE SIGNAL PROCESS, V1, P11
   Wang L, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P22, DOI 10.1109/CISP.2008.129
   Wang Y, 2009, CHAOS SOLITON FRACT, V41, P1773, DOI 10.1016/j.chaos.2008.07.031
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Ye RS, 2011, OPT COMMUN, V284, P5290, DOI 10.1016/j.optcom.2011.07.070
   Zhang SY, 2009, SCAND J FOREST RES, V24, P425, DOI 10.1080/02827580903124392
   Zhu Y, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 2, P217, DOI 10.1109/ICACC.2010.5486684
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 36
TC 11
Z9 12
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1217
EP 1246
DI 10.1007/s11042-015-3027-1
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000054
DA 2024-07-18
ER

PT J
AU Kumar, R
   Chand, S
AF Kumar, Rajeev
   Chand, Satish
TI A novel high capacity reversible data hiding scheme based on pixel
   intensity segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Pixel mapping function; Concealable pixel
ID HISTOGRAM-MODIFICATION; WATERMARKING
AB There have been discussed several data hiding techniques which can hide the secret data in an image. However, after extracting the secret data some of the image information gets lost. It is an important issue to have a data hiding scheme which can extract the secret data as well as can restore the original image without any loss of information. Such types of schemes are called reversible data hiding schemes which are commonly used in sensitive military, legal, and medical applications. The existing reversible data hiding schemes either provide good hiding capacity but inferior stego-image quality or good stego-image quality but poor hiding capacity because the stego-image quality and the hiding capacity are diametrically related parameters. In this paper, we propose a novel high capacity reversible data hiding scheme which has high data hiding capacity while maintaining good quality stego-image. In this scheme, we first cryptographically encode the secret data using a private key so that even if an attacker is able to extract the embedded secret data, he cannot get the original secret message unless he has the private key. Our scheme hides the secret data in two phases. In first phase, it uniformly divides the pixel intensity levels i.e., 0-255, into odd sized segments. Then the image is scanned in zigzag order to identify the concealable pixels, which have the same value as the middle elements of a segment. Some of the secret data is hidden into these identified pixels. In second phase, the intensity levels are again divided in reverse order, i.e., 255 to 0, into odd sized segments of uniform length like as in the first phase. The resultant image is again scanned in zigzag order and concealable pixels are identified. The remaining secret data is embedded into the concealable pixels. To ensure reversibility of our algorithm, a location map is maintained for each phase. The location maps are compressed using JBIG1 scheme and are transmitted through a secure channel along with other auxiliary information that contains private key and segment size. Experimentally our scheme achieves very high capacity without deteriorating the image quality. It is because we select the exact middle pixels of the segments to hide the secret data, which ensures that the pixel value does not get altered unevenly while embedding the secret data. It further helps in increasing the hiding capacity. Moreover, it is very simple as it does not require much computation for embedding the secret data.
C1 [Kumar, Rajeev; Chand, Satish] Netaji Subhas Inst Technol, Div Comp Engn, New Delhi, India.
C3 Netaji Subhas University of Technology
RP Kumar, R (corresponding author), Netaji Subhas Inst Technol, Div Comp Engn, New Delhi, India.
EM rajivgarg@outlook.com; schand20@gmail.com
RI Kumar, Rajeev/IUP-5006-2023
OI Kumar, Rajeev/0000-0002-5000-7644
CR Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chang CC, 2010, INFORM SCIENCES, V180, P2286, DOI 10.1016/j.ins.2010.01.034
   Chen XY, 2015, MULTIMED TOOLS APPL, V74, P5747, DOI 10.1007/s11042-014-1881-x
   Chang CC, 2007, INFORM SCIENCES, V177, P1796, DOI 10.1016/j.ins.2006.09.014
   Chung KL, 2012, APPL MATH COMPUT, V218, P5819, DOI 10.1016/j.amc.2011.10.056
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   Hsu FH, 2012, MULTIMED TOOLS APPL, P1
   JBIG1, 2010, JBIG KIT M KUHN
   Jung SW, 2011, IEEE SIGNAL PROC LET, V18, P95, DOI 10.1109/LSP.2010.2095498
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Lin CC, 2008, PATTERN RECOGN, V41, P1415, DOI 10.1016/j.patcog.2007.09.005
   Ni ZC, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P912
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P1983, DOI 10.1007/s11042-013-1733-0
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang ZH, 2013, J SYST SOFTWARE, V86, P315, DOI 10.1016/j.jss.2012.08.029
   Yang B, 2005, PROC SPIE, V5681, P218, DOI 10.1117/12.588147
   Yang B, 2004, PROC SPIE, V5306, P405, DOI 10.1117/12.527216
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 24
TC 8
Z9 8
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 979
EP 996
DI 10.1007/s11042-015-3069-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000042
DA 2024-07-18
ER

PT J
AU Masia, B
   Serrano, A
   Gutierrez, D
AF Masia, Belen
   Serrano, Ana
   Gutierrez, Diego
TI Dynamic range expansion based on image statistics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reverse tone mapping; Image processing; Dynamic range
ID TONE; ENHANCEMENT; DISPLAYS; VIDEO
AB As the dynamic range of displays keeps increasing, there is a need for reverse tone mapping methods, which aim at expanding the dynamic range of legacy low dynamic range images for viewing on higher dynamic range displays. While a number of strategies have been proposed, most of them are designed for well-exposed input images and are not optimal when dealing with ill-exposed (under- or over-exposed) content. Further, this type of content is more prone to artifacts which may arise when using local methods. In this work, we build on an existing, automatic, global reverse tone mapping operator based on a gamma expansion. We improve this method by providing a new way for automatic parameter calculation from the image statistics. We show that this method yields better results across the whole range of exposures.
C1 [Masia, Belen; Serrano, Ana; Gutierrez, Diego] Univ Zaragoza, Maria de Luna 1, Zaragoza 50018, Spain.
   [Masia, Belen] MPI Informat, Campus E1 4, D-66123 Saarbrucken, Germany.
C3 University of Zaragoza; Max Planck Society
RP Serrano, A (corresponding author), Univ Zaragoza, Maria de Luna 1, Zaragoza 50018, Spain.
EM bmasiac@mpi-inf.mpg.de; anase@unizar.es; diegog@unizar.es
RI Serrano, Ana/ABC-3358-2021
OI Serrano, Ana/0000-0002-7796-3177; Masia, Belen/0000-0003-0060-7278;
   Gutierrez Perez, Diego/0000-0002-7503-7022
FU Spanish Ministry of Science and Technology (project LIGHTSLICE); Max
   Planck Center for Visual Computing and Communication; FPI grant from the
   Spanish Ministry of Economy and Competitivity
FX This research has been funded by the Spanish Ministry of Science and
   Technology (project LIGHTSLICE). Belen Masia would like to acknowledge
   the support of the Max Planck Center for Visual Computing and
   Communication. Ana Serrano was additionally supported by an FPI grant
   from the Spanish Ministry of Economy and Competitivity.
CR Adams A., 1983, The print. The Ansel Adams Photography series
   Akyüz AO, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2238891
   [Anonymous], C ESP INF GRAF
   Aydin TO, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360668
   Banterle F, 2011, ADVANCED HIGH DYNAMIC RANGE IMAGING: THEORY AND PRACTICE, P1
   Banterle F, 2011, ACM SIGGRAPH ASIA 20
   Banterle F., 2006, P 4 INT C COMP GRAPH, P349
   BANTERLE F, 2008, P SPRING C COMP GRAP
   Banterle F, 2007, VISUAL COMPUT, V23, P467, DOI 10.1007/s00371-007-0124-9
   Cadík M, 2008, COMPUT GRAPH-UK, V32, P330, DOI 10.1016/j.cag.2008.04.003
   Didyk P, 2008, COMPUT GRAPH FORUM, V27, P1265, DOI 10.1111/j.1467-8659.2008.01265.x
   Dumouchel W, 1991, INTEGRATING ROBUST O, P41
   Eilertsen G, 2013, COMP GRAPH FOR P PAC, P32
   Heidrich Wolfgang, ERIK REINHARD
   Kovaleski RP, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P49, DOI 10.1109/SIBGRAPI.2014.29
   Kovaleski RP, 2009, VISUAL COMPUT, V25, P539, DOI 10.1007/s00371-009-0327-3
   Martin M., 2008, Congreso Espanol de Informatica Grafica, P189
   Masia B, 2013, COMPUT GRAPH-UK, V37, P1012, DOI 10.1016/j.cag.2013.10.003
   Masia B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618506
   MEYLAN L, 2006, IS T SID 14 COL IM C
   Meylan L, 2007, P IS T SPIE EL IM HU, V6492
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Rempel AG, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239490
   Seetzen H, 2004, ACM T GRAPHIC, V23, P760, DOI 10.1145/1015706.1015797
   Steiger JH, 2015, INTRO MULTIPLE REGRE
NR 25
TC 58
Z9 57
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 631
EP 648
DI 10.1007/s11042-015-3036-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000028
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Nikseresht, S
   Dezfouli, MA
   Alavi, SE
AF Nikseresht, Sajad
   Dezfouli, Mashallah Abbasi
   Alavi, Seyed. Enayatallah
TI ILSBMR: improved LSBMR (ILSBMR) method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Transparency; Security; Embedding capacity
ID STEGANALYSIS
AB The Least Significant Bit Matching Revisited (LSBMR) is among the most commonly used methods on image steganography, aiming to make only smaller changes in an image. While security is considered as one of the basic evaluation criteria for steganography techniques and notably, LSBMR can be easily recognized due to its well-known structure, it is important to find a way to help improve this approach so that it might cause less variation in the image and also increase security. To this end, the current paper deploys divided blocks of the original cover image and a selection of the best layout to embed secret message bits from each block into color images by using LSBMR. The simulation results indicate that this improved method makes small changes in the image and increases its security, compared to the LSBMR technique.
C1 [Nikseresht, Sajad; Dezfouli, Mashallah Abbasi] Islamic Azad Univ, Ahvaz Branch, Dept Comp, Coll Comp, Ahvaz, Iran.
   [Alavi, Seyed. Enayatallah] Shahid Chamran Univ Ahwaz, Dept Comp Engn, Ahvaz, Iran.
C3 Islamic Azad University; Shahid Chamran University of Ahvaz
RP Nikseresht, S (corresponding author), Islamic Azad Univ, Ahvaz Branch, Dept Comp, Coll Comp, Ahvaz, Iran.
EM nikseresht.sajad@yahoo.com
RI Alavi, seyed Enayatallah/AAK-9729-2021
OI Alavi, seyed Enayatallah/0000-0003-0495-5704; abbasi dezfouli,
   mashallah/0000-0002-6351-3159
CR [Anonymous], 2002, P WORKSHOP MULTIMEDI
   Chan C-S, 2009, 3 INT C UB INF MAN C, P246
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Dezfouli MA, 2013, ADV COMPUT SCI INT J, V2, P157
   Fridrich J, 2003, PROC SPIE, V5020, P178, DOI 10.1117/12.473140
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Lee K, 2006, LECT NOTES COMPUT SC, V4283, P35
   Lerch-Hostalot D, 2013, COMPUT SECUR, V32, P192, DOI 10.1016/j.cose.2012.11.005
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Papapanagiotou K, 2005, LECT NOTES ARTIF INT, V3802, P589
   Rabah K., 2004, Information Technology Journal, V3, P245
   Sharp Toby, 2001, Information Hiding, V2137, P13, DOI 10.1007/3-540-45496-9_2
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Xu H, 2010, INFORM SCIENCES, V180, P1201, DOI 10.1016/j.ins.2009.12.027
NR 14
TC 0
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 1857
EP 1874
DI 10.1007/s11042-015-3073-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000012
DA 2024-07-18
ER

PT J
AU Yuan, YH
   Li, Y
   Shen, XB
   Sun, QS
   Yang, JL
AF Yuan, Yun-Hao
   Li, Yun
   Shen, Xiao-Bo
   Sun, Quan-Sen
   Yang, Jin-Long
TI Laplacian multiset canonical correlations for multiview feature
   extraction and image recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image recognition; Multiset canonical correlations; Manifold learning;
   Multiview dimensionality reduction; Multiview learning
ID DIMENSIONALITY REDUCTION; FACE RECOGNITION; FEATURE FUSION;
   DISCRIMINANT; APPEARANCE; SETS; CONSISTENCY; EIGENMAPS; FRAMEWORK;
   MODELS
AB Multiset canonical correlation analysis (MCCA) aims at revealing the linear correlations among multiple sets of high-dimensional data. Therefore, it is only a linear multiview dimensionality reduction technique and such a linear model is insufficient to discover the nonlinear correlation information hidden in multiview data. In this paper, we incorporate the local structure information into MCCA and propose a novel algorithm for multiview dimensionality reduction, called Laplacian multiset canonical correlations (LapMCCs), which simultaneously considers local within-view and local between-view correlations by using nearest neighbor graphs. This makes LapMCC capable of discovering the nonlinear correlation information among multiview data by combining many locally linear problems together. Moreover, we also develop an orthogonal version of LapMCC to preserve the metric structure. The proposed LapMCC method is applied to face and object image recognition. The experimental results on AR, Yale-B, AT&T, and ETH-80 databases demonstrate the superior performance of LapMCC compared to existing multiview dimensionality reduction methods.
C1 [Yuan, Yun-Hao; Li, Yun] Yangzhou Univ, Sch Informat Engn, Yangzhou 225127, Jiangsu, Peoples R China.
   [Yuan, Yun-Hao; Yang, Jin-Long] Jiangnan Univ, Dept Comp Sci & Technol, Wuxi 214122, Peoples R China.
   [Shen, Xiao-Bo; Sun, Quan-Sen] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Shen, Xiao-Bo] Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld 4072, Australia.
C3 Yangzhou University; Jiangnan University; Nanjing University of Science
   & Technology; University of Queensland
RP Yuan, YH (corresponding author), Yangzhou Univ, Sch Informat Engn, Yangzhou 225127, Jiangsu, Peoples R China.; Yuan, YH (corresponding author), Jiangnan Univ, Dept Comp Sci & Technol, Wuxi 214122, Peoples R China.
EM yyhzbh@163.com
OI Shen, Xiaobo/0000-0001-8655-1265
FU National Natural Science Foundation of China [61402203, 61273251,
   61305017]; Fundamental Research Funds for the Central Universities
   [JUSRP11458]; Program for New Century Excellent Talents in University
   [NCET-12-0881]
FX This work is supported by the National Natural Science Foundation of
   China under Grant Nos. 61402203, 61273251, and 61305017, the Fundamental
   Research Funds for the Central Universities under Grant No. JUSRP11458,
   and the Program for New Century Excellent Talents in University under
   Grant No. NCET-12-0881. Moreover, we would like to thank the editor and
   all of the anonymous reviewers for their constructive comments, which
   significantly improved the quality of this paper.
CR [Anonymous], 2003, P ADV NEUR INF PROC
   [Anonymous], 2008, P 2008 SIAM INT C DA
   [Anonymous], TTITR20084 TTIC
   Bach FR, 2003, J MACH LEARN RES, V3, P1, DOI 10.1162/153244303768966085
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Chaudhuri K., 2009, P 26 ANN INT C MACH, P129
   Chu DL, 2013, IEEE T PATTERN ANAL, V35, P3050, DOI 10.1109/TPAMI.2013.104
   CHU MT, 1993, SIAM J SCI COMPUT, V14, P1089, DOI 10.1137/0914066
   Chung F. R. K., 1997, Spectral graph theory
   Donner R, 2006, IEEE T PATTERN ANAL, V28, P1690, DOI 10.1109/TPAMI.2006.206
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100
   DUCHENE J, 1988, IEEE T PATTERN ANAL, V10, P978, DOI 10.1109/34.9121
   Friman O, 2001, MAGNET RESON MED, V45, P323, DOI 10.1002/1522-2594(200102)45:2<323::AID-MRM1041>3.0.CO;2-#
   Fu Y, 2008, IEEE T PATTERN ANAL, V30, P2229, DOI 10.1109/TPAMI.2008.154
   Fukumizu K, 2007, J MACH LEARN RES, V8, P361
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gui J, 2014, IEEE T IMAGE PROCESS, V23, P3126, DOI 10.1109/TIP.2014.2326001
   Hardoon DR, 2011, MACH LEARN, V83, P331, DOI 10.1007/s10994-010-5222-7
   Hardoon DR, 2009, MACH LEARN, V74, P23, DOI 10.1007/s10994-008-5085-3
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   HORST P, 1961, PSYCHOMETRIKA, V26, P129, DOI 10.1007/BF02289710
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hou CP, 2010, PATTERN RECOGN, V43, P720, DOI 10.1016/j.patcog.2009.07.015
   Hou SD, 2011, NEURAL PROCESS LETT, V34, P259, DOI 10.1007/s11063-011-9197-6
   Huang H, 2010, PATTERN RECOGN, V43, P2532, DOI 10.1016/j.patcog.2010.02.007
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jing XY, 2011, SIGNAL PROCESS, V91, P2132, DOI 10.1016/j.sigpro.2011.02.016
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Kakade SM, 2007, LECT NOTES COMPUT SC, V4539, P82, DOI 10.1007/978-3-540-72927-3_8
   Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740
   KETTENRING JR, 1971, BIOMETRIKA, V58, P433, DOI 10.2307/2334380
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167
   Kimura Akisato, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2933, DOI 10.1109/ICPR.2010.719
   Lai P L, 2000, Int J Neural Syst, V10, P365, DOI 10.1016/S0129-0657(00)00034-X
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Leibe B, 2003, PROC CVPR IEEE, P409
   Liu WF, 2015, SIGNAL PROCESS, V110, P101, DOI 10.1016/j.sigpro.2014.08.002
   Liu WF, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0108474
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   MARTINEZ AM, 1998, 24 AUT U COMP VIS CT
   Melzer T, 2003, PATTERN RECOGN, V36, P1961, DOI 10.1016/S0031-3203(03)00058-X
   Nielsen AA, 2002, IEEE T IMAGE PROCESS, V11, P293, DOI 10.1109/83.988962
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Rupnik J., 2010, SIKDD
   Sargin ME, 2007, IEEE T MULTIMEDIA, V9, P1396, DOI 10.1109/TMM.2007.906583
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Sugiyama M., 2006, P 23 INT C MACH LEAR, P905, DOI DOI 10.1145/1143844.1143958
   Sugiyama M, 2007, J MACH LEARN RES, V8, P1027
   Sugiyama M, 2010, MACH LEARN, V78, P35, DOI 10.1007/s10994-009-5125-7
   Sun LA, 2011, IEEE T PATTERN ANAL, V33, P194, DOI 10.1109/TPAMI.2010.160
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Sun TK, 2007, IMAGE VISION COMPUT, V25, P531, DOI 10.1016/j.imavis.2006.04.014
   Sun TK, 2008, IEEE DATA MINING, P1043, DOI 10.1109/ICDM.2008.28
   Tao DP, 2013, IEEE T MULTIMEDIA, V15, P833, DOI 10.1109/TMM.2013.2238909
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Worsley KJ, 1997, NEUROIMAGE, V6, P305, DOI 10.1006/nimg.1997.0294
   Xia TA, 2010, IEEE T SYST MAN CY B, V40, P1438, DOI 10.1109/TSMCB.2009.2039566
   Xie B, 2011, IEEE T SYST MAN CY B, V41, P1088, DOI 10.1109/TSMCB.2011.2106208
   Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578
   Xu C, 2014, IEEE T PATTERN ANAL, V36, P1559, DOI 10.1109/TPAMI.2013.2296528
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008
   Yuan YH, 2014, IEEE T NEUR NET LEAR, V25, P1131, DOI 10.1109/TNNLS.2013.2288062
   Yuan YH, 2014, PATTERN RECOGN, V47, P1411, DOI 10.1016/j.patcog.2013.09.009
   Yuan YH, 2011, PATTERN RECOGN, V44, P1031, DOI 10.1016/j.patcog.2010.11.004
   Yun-Hao Yuan, 2012, 2012 15th International Conference on Information Fusion (FUSION 2012), P882
   Zhang Lei-Hong., 2009, MULTIVARIATE EIGENVA
   Zhu XF, 2012, PATTERN RECOGN, V45, P3003, DOI 10.1016/j.patcog.2012.02.007
NR 74
TC 24
Z9 24
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 731
EP 755
DI 10.1007/s11042-015-3070-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000032
DA 2024-07-18
ER

PT J
AU Huang, YZ
   Guan, YP
AF Huang, Yizhen
   Guan, Yepeng
TI Laplacian hashing for fast large-scale image retrieval and its
   applications for midway processing in a cascaded face detection
   structure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Laplacian hashing; Large-scale; Midway processing; Cascaded classifier;
   Face detection
AB In this paper, we propose a new philosophy different from that of the well-known Locality-Sensitive Hashing (LSH): if two data points are close, we wish that the probability for them to fall into the same hash buckets is high; whereas if two data points are far away, we do not care the probability of them falling into the same hash buckets. Our new philosophy is a relaxation of the LSH requirement, by ignoring the side effects of placing differently labeled data points into the same hash bucket. Based on such relaxation, a new hashing method, namely the Laplacian Hashing, is derived, which is natural to incorporate any kernel functions and "similar" / "dissimilar" weakly supervised information. Another contribution of this paper is that, it is the first time that a fast hashing method is applied for the midway processing in a cascaded face detection structure. Experimental results show that, our method is on average not worse than the state of the arts in terms of accuracy, but much faster and thus can handle much larger training datasets within reasonable computation time.
C1 [Huang, Yizhen; Guan, Yepeng] Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
   [Guan, Yepeng] Key Lab Adv Displays & Syst Applicat, Minist Educ, Shanghai, Peoples R China.
C3 Shanghai University
RP Guan, YP (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
EM ypguan@shu.edu.cn
RI Moureng, Huang/AAH-8485-2020
FU Natural Science Foundation of China [11176016, 60872117]; Specialized
   Research Fund for the Doctoral Program of Higher Education
   [20123108110014]
FX This research work is funded by Natural Science Foundation of China
   (Grant No. 11176016, 60872117), and Specialized Research Fund for the
   Doctoral Program of Higher Education (Grant No. 20123108110014).
CR [Anonymous], 2009, NIPS
   [Anonymous], 2009, NEURIPS
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928
   Dong W, 2008, P 17 ACM C INF KNOWL, P669
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   He J., 2010, ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P1129
   He JF, 2011, PROC CVPR IEEE, P753, DOI 10.1109/CVPR.2011.5995518
   He XF, 2004, ADV NEUR IN, V16, P153
   Huang YZ, 2006, J COMPUT ELECTRON, V5, P275, DOI 10.1007/s10825-006-0145-z
   Jain P, 2008, PROC CVPR IEEE, P3879
   Jian-qing Zhu, 2012, 2012 International Symposium on Intelligent Signal Processing and Communications Systems (ISPACS 2012), P33, DOI 10.1109/ISPACS.2012.6473448
   Joly A, 2011, PROC CVPR IEEE, P873, DOI 10.1109/CVPR.2011.5995709
   Korman S, 2011, IEEE I CONF COMP VIS, P1607, DOI 10.1109/ICCV.2011.6126421
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Li P, 2013, IEEE T MULTIMEDIA, V15, P141, DOI 10.1109/TMM.2012.2199970
   Liu WJ, 2011, E-POLYMERS
   Long YJ, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P419, DOI 10.1109/MMSP.2006.285343
   Lv Q, 2007, P 33 INT C VER LARG, P950
   Mu YD, 2010, PROC CVPR IEEE, P3344, DOI 10.1109/CVPR.2010.5540024
   Norouzi M.E., 2011, ICML
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750
   Shi JB, 1997, PROC CVPR IEEE, P731, DOI 10.1109/CVPR.1997.609407
   Springer J, 2013, INT CONF ACOUST SPEE, P1681, DOI 10.1109/ICASSP.2013.6637938
   Torralba A., 2008, PROC CVPR 08, P1
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Wang Jun., 2010, ICML, P1127
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Xu H, 2011, IEEE I CONF COMP VIS, P1631, DOI 10.1109/ICCV.2011.6126424
   Zhang D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P18
   Zhang D, 2010, LECT NOTES COMPUT SC, V5993, P577, DOI 10.1007/978-3-642-12275-0_51
NR 34
TC 2
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16315
EP 16332
DI 10.1007/s11042-015-2932-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700064
DA 2024-07-18
ER

PT J
AU Kim, M
   Lee, JY
AF Kim, Minseok
   Lee, Jae Yeol
TI Touch and hand gesture-based interactions for directly manipulating 3D
   virtual objects in mobile augmented reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural interaction; Hand gesture; Mobile augmented reality; 3D AR
   object manipulation
AB Mobile augmented reality (AR) has been widely used in smart and mobile device-based applications such as entertainment, games, visual experience, and information visualization. However, most of the mobile AR applications have limitations in natural user interaction and do not fully support the direct manipulation of 3D AR objects. This paper proposes a new method for naturally and directly manipulating 3D AR objects through touch and hand gesture-based interactions in handheld devices. The touch gesture is used for the AR object selection and the natural hand gesture is used for the direct and interactive manipulation of the selected objects. Thus, the hybrid interaction makes the user more accurately interact with and manipulate AR objects in the real 3D space, not in the 2D space. In particular, natural hand gestures are detected by the Leap Motion sensor attached to the front or back of mobile devices. Thus the user can easily interacts with 3D AR objects for 3D transformation to enhance usability and usefulness. In this research, comprehensive comparative analyses were performed among the proposed approach and the widely used screen touch-based approach and vision-based approach in terms of quantitative and qualitative aspects. Quantitative analysis was conducted by measuring task completion time and failure rate to perform given tasks such as 3D object matching and grasp-hang-release operation. Both tasks require simultaneous 3D translation and 3D rotation. In addition, we have compared the gesture performance depending on whether the gesture sensor is located in the front or the back of the mobile device. Furthermore, to support other complex operations, an assembly task has also been evaluated. The assembly task consists of a sequence of combining parts into a sub-assembly. Qualitative analysis was performed through enquiring questionnaire after the experiment that examines factors such as ease-of-use, ease-of-natural interaction, etc. Both analyses showed that the proposed approach can provide more natural and intuitive interaction and manipulation of mobile AR objects. Several implementation results will also be given to show the advantage and effectiveness of the proposed approach.
C1 [Kim, Minseok; Lee, Jae Yeol] Chonnam Natl Univ, Dept Ind Engn, 300 Yongbong Dong, Kwangju 500757, South Korea.
C3 Chonnam National University
RP Lee, JY (corresponding author), Chonnam Natl Univ, Dept Ind Engn, 300 Yongbong Dong, Kwangju 500757, South Korea.
EM jaeyeol@jnu.ac.kr
RI M, V/AAB-5389-2020
FU Program of Establishment of the Testbed for a Convergence of the IoTs
   and Manufacturing Technology - Ministry of Science, ICT and Future
   Planning [B0364-15-1003]
FX This research was supported by the Program of Establishment of the
   Testbed for a Convergence of the IoTs and Manufacturing Technology
   funded by the Ministry of Science, ICT and Future Planning
   (B0364-15-1003).
CR Bai H, 2013, P 3DUI 13, P129
   Baldauf M., 2011, Proceedings of the 13th International Conference on Human Computer Interaction with Mobile Devices and Services, P539, DOI DOI 10.1145/2037373.2037457
   Bellarbi Abdelkader, 2014, 2014 4th International Conference on Image Processing Theory, Tools and Applications (IPTA). Proceedings, P1, DOI 10.1109/IPTA.2014.7001995
   Bowman D. A., 1997, P I3D 97, P33
   Buchmann V., 2004, VIRTUAL REAL-LONDON, V1, P212
   Chun W. H., 2013, P 2013 INT C INT US, P307, DOI [DOI 10.1145/2449396.2449435, 10.1145/2449396.2449435]
   Coelho JoannaC., 2014, CREATING DIFFERENCE, P78
   Ha T, 2014, INT SYM MIX AUGMENT, P219, DOI 10.1109/ISMAR.2014.6948431
   Hürst W, 2013, MULTIMED TOOLS APPL, V62, P233, DOI 10.1007/s11042-011-0983-y
   Khademi M., 2014, Conference on Human Factors in Computing Systems - Proceedings, (February 2015), P1663, DOI [10.1145/2559206.2581203, DOI 10.1145/2559206.2581203]
   Kim D, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P167
   Kim M, 2015, P ACDDE 15
   Lee JY, 2010, INT J ADV MANUF TECH, V51, P1069, DOI 10.1007/s00170-010-2671-x
   Lee T, 2007, ELEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P83
   Lu G, 2012, VIRTUAL REAL-LONDON, V16, P243, DOI 10.1007/s10055-011-0195-9
   Moehring M, 2011, P IEEE VIRT REAL ANN, P131, DOI 10.1109/VR.2011.5759451
   Mossel A, 2013, P VRIC 13
   Oikonomidis I., 2011, P BRIT MACH VIS C 20
   Park H, 2014, J COMPUT DES ENG, V1, P289, DOI 10.7315/JCDE.2014.028
   Poupyrev I., 1996, P 9 ANN ACM S USER I, P79, DOI [DOI 10.1145/237091.237102, 10.1145/237091.237102]
   Radkowski R., 2012, 5 INT C ADV COMPUTER, P303
   Regenbrecht H., 2013, 25th Australian Computer-Human Interaction Conference: Augmentation, Application, Innovation, Collaboration, P281, DOI DOI 10.1145/2541016.2541053
   Ren Z, 2011, PROC FL STATE HORTIC, V124, P1
   Seo DW, 2013, EXPERT SYST APPL, V40, P3784, DOI 10.1016/j.eswa.2012.12.091
   Song J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3657, DOI 10.1145/2702123.2702601
   Wachs JP, 2011, COMMUN ACM, V54, P60, DOI 10.1145/1897816.1897838
   Wang R., 2011, Proceedings of the 24th annual ACM symposium on User interface software and technology. UIST '11, P549
NR 27
TC 40
Z9 43
U1 0
U2 82
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16529
EP 16550
DI 10.1007/s11042-016-3355-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700073
DA 2024-07-18
ER

PT J
AU Kim, S
   Yoon, Y
AF Kim, Svetlana
   Yoon, YongIk
TI Recommendation system for sharing economy based on multidimensional
   trust model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multidimensional; Tensor factorization; Context-awareness; Rating;
   Recommendation; SFS
ID SKYLINE
AB The recommendation system are widely adopted in today's mainstream online sharing services, providing useful prediction of user's rating or user's preferences of sharing items (such as products, movies, books, and news articles). A key challenge of recommendation systems in sharing economy is to employ prediction algorithms to estimate the matching items with considering their interests and needs. The environment-context has been recognized as an important factor to consider in personalized recommender systems. Since dynamic information in environment-context describes the situation of items and users, the information affects the user's decision process essentially to apply in recommender systems. However, most model-based collaborative filtering approaches such as Matrix Factorization do not provide an easy way of integrating context information into the model. In this paper, we introduce a Multidimensional Trust model based on Tensor Factorization. The generalization of Matrix Factorization allows for a flexible and generic integration of contextual information. According to the different types of context, the Multidimensional Trust model considers the additional dimensions for the representation of the data as a tensor. This is achieved by going through the collecting user's behavior based on rating analysis and identification of users' historical activity and viewing patterns. The benefits behavior solutions, which use the handle intelligently to meet the users' needs, are the focus of this paper.
C1 [Kim, Svetlana; Yoon, YongIk] Sookmyung Womens Univ, Dept Multimedia Sci, Seoul, South Korea.
C3 Sookmyung Women's University
RP Yoon, Y (corresponding author), Sookmyung Womens Univ, Dept Multimedia Sci, Seoul, South Korea.
EM xatyna@sm.ac.kr; yiyoon@sm.ac.kr
RI Kim, Svetlana/M-1423-2019; KIM, SVETLANA/JDW-0004-2023
OI Kim, Svetlana/0000-0002-9617-2610
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Science, ICT & Future Planning [2013015884]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Science, ICT & Future Planning (2013015884).
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   [Anonymous], J CONVERG
   Baltrunas L., 2011, P 5 ACM C REC SYST, P301, DOI DOI 10.1145/2043932.2043988
   Börzsönyi S, 2001, PROC INT CONF DATA, P421, DOI 10.1109/ICDE.2001.914855
   Chomicki J, 2003, PROC INT CONF DATA, P717, DOI 10.1109/ICDE.2003.1260846
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   Ekstrand Michael D., 2010, Foundations and Trends in Human-Computer Interaction, V4, P81, DOI 10.1561/1100000009
   Fouss F, 2007, IEEE T KNOWL DATA EN, V19, P355, DOI 10.1109/TKDE.2007.46
   Funk Simon, 2006, Netflix update: Try this at home
   Ge Y., 2010, P 16 ACM SIGKDD INT, P899, DOI [DOI 10.1145/1835804.1835918, 10.1145/1835804.1835918]
   Ghazanfar MA, 2014, EXPERT SYST APPL, V41, P3261, DOI 10.1016/j.eswa.2013.11.010
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Hidasi Balazs, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P67, DOI 10.1007/978-3-642-33486-3_5
   Howard N, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-9
   Jeong WH, 2013, J INF PROCESS SYST, V9, P157, DOI 10.3745/JIPS.2013.9.1.157
   Karatzoglou Alexandros, 2010, Multiverse recommendation: N-dimensional tensor factorization for context-aware collaborative filtering, P79, DOI DOI 10.1145/1864708.1864727
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Koren Y, 2011, RECOMMENDER SYSTEMS HANDBOOK, P145, DOI 10.1007/978-0-387-85820-3_5
   Koren Y, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P447
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Luo X, 2013, KNOWL-BASED SYST, V37, P154, DOI 10.1016/j.knosys.2012.07.016
   Rendle S, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P635
   Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI 10.1145/371920.372071
   Shi Y, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2556270
   Toledo RY, 2013, J INF PROCESS SYST, V9, P435, DOI 10.3745/JIPS.2013.9.3.435
NR 25
TC 18
Z9 18
U1 0
U2 93
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15297
EP 15310
DI 10.1007/s11042-014-2384-5
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700011
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, WH
   Wen, L
   Chen, YB
AF Li Weihong
   Wen Lei
   Chen Yebin
TI Spatial-temporal forecast research of property crime under the driven of
   urban traffic factors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatial-temporal analysis; GA-BP neural network; Property crime
   forecasting; Urban transport factors
ID GENETIC ALGORITHM; HOT-SPOTS; MODEL; EDUCATION
AB According to existing researches, robbery crime is remarkably impacted by urban transport development, road accessibility and complexity of land use. However, researches related to spatial-temporal data mining and forecasting on property crime driven by traffic factors are rare. The BP neural network model improved by genetic algorithm (GA-BP neural network), which utilize Machine Learning to mine the factor weights of the property crime, can describe these complicated relationships to forecast more effectively. This study collected spatialtemporal data of property crime that occurred at city A located in South China in the period from 2008 to 2012, filtered the factors of property crime by correlation analysis, and selected the neighbors by spatial autocorrelation. This study also standardized the data, with one year as the time window and 100mx100m as the spatial dimension. Property crime is forecasted based on the GA-BP neural network, and the root mean square error is 0.019. Current researches demonstrate that the correlation between property crime and factors, like urban transport, network density, floating population and economic indicator, is significant. This study confirms that the GA-BP neural network model based on GIS is a reasonable forecast model in the field of property crime forecast research. Given its features, the GA-BP neural network model can forecast other types of rational crime and can set the time window and spatial dimension to obtain the corresponding forecast result based on the accuracy of input data.
C1 [Li Weihong; Wen Lei; Chen Yebin] South China Normal Univ, Sch Geog, Guangzhou 510631, Guangdong, Peoples R China.
C3 South China Normal University
RP Li, WH (corresponding author), South China Normal Univ, Sch Geog, Guangzhou 510631, Guangdong, Peoples R China.
EM hongweili9981@163.com
CR Almeida JS, 2002, CURR OPIN BIOTECH, V13, P72, DOI 10.1016/S0958-1669(02)00288-4
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2002, INT J DRUG POLICY, DOI DOI 10.1016/S0955-3959(02)00075-0
   Anselin L, 2000, Measurement and analysis of crime and justice, V4, P213
   Blonigen DM, 2010, CLIN PSYCHOL REV, V30, P89, DOI 10.1016/j.cpr.2009.10.001
   BRANTINGHAM PL, 1993, J ENVIRON PSYCHOL, V13, P3, DOI 10.1016/S0272-4944(05)80212-9
   Buonanno P, 2009, ECON EDUC REV, V28, P11, DOI 10.1016/j.econedurev.2007.09.012
   Caplan JM, 2011, J EXP CRIMINOL, V7, P255, DOI 10.1007/s11292-011-9125-9
   Caplan JM, 2011, JUSTICE Q, V28, P360, DOI 10.1080/07418825.2010.486037
   Chainey S, 2008, SECUR J, V21, P4, DOI 10.1057/palgrave.sj.8350066
   Chen GY, 2014, FUEL, V126, P202, DOI 10.1016/j.fuel.2014.02.034
   CHERKASSKY V, 1992, IEEE EXPERT, V7, P43, DOI 10.1109/64.163672
   Cohen J, 2007, GEOGR ANAL, V39, P105, DOI 10.1111/j.1538-4632.2006.00697.x
   COHEN LE, 1979, AM SOCIOL REV, V44, P588, DOI 10.2307/2094589
   Copes Heith., 1999, J CRIME JUSTICE, V22, P125, DOI [DOI 10.1080/0735648X.1999.9721097, 10.1080/0735648X.1999.9721097]
   Corcoran JJ, 2003, INT J FORECASTING, V19, P623, DOI 10.1016/S0169-2070(03)00095-5
   Elonheimo H, 2014, J ADOLESCENCE, V37, P1269, DOI 10.1016/j.adolescence.2014.09.005
   Gorr W, 2003, INT J FORECASTING, V19, P551, DOI 10.1016/S0169-2070(03)00089-X
   Gorr W, 2003, INT J FORECASTING, V19, P579, DOI 10.1016/S0169-2070(03)00092-X
   Groot W, 2010, APPL ECON, V42, P279, DOI 10.1080/00036840701604412
   Gruenewald PJ, 2006, ADDICTION, V101, P666, DOI 10.1111/j.1360-0443.2006.01405.x
   Jiang D., 2015, TELECOMMUN SYST, P1
   Kaikhah K, 2006, APPL INTELL, V24, P51, DOI 10.1007/s10489-006-6929-9
   Kianrnehr K, 2008, APPL ARTIF INTELL, V22, P433, DOI 10.1080/08839510802028405
   Li ST, 2010, EXPERT SYST APPL, V37, P7108, DOI 10.1016/j.eswa.2010.03.004
   Li XM, 2016, ADV ENG SOFTW, V93, P1, DOI 10.1016/j.advengsoft.2015.11.003
   Li X, 2015, SHOCK VIB, V2015, DOI 10.1155/2015/431476
   Lu YM, 2007, SOC SCI RES, V36, P611, DOI 10.1016/j.ssresearch.2006.05.003
   Lu ZH, 2013, 2013 INTERNATIONAL CONFERENCE ON VIRTUAL REALITY AND VISUALIZATION (ICVRV 2013), P94, DOI 10.1109/ICVRV.2013.23
   Lv Z, 2015, ARXIV150401057
   Mohler G. O., 2012, J AM STAT ASS
   Piza EL, 2014, J QUANT CRIMINOL, V30, P237, DOI 10.1007/s10940-013-9202-5
   Rephann TJ, 2009, ANN REGIONAL SCI, V43, P435, DOI 10.1007/s00168-008-0215-1
   Salleh SA, 2012, PROCD SOC BEHV, V42, P212, DOI 10.1016/j.sbspro.2012.04.184
   SHERMAN LW, 1989, CRIMINOLOGY, V27, P27, DOI 10.1111/j.1745-9125.1989.tb00862.x
   Shoesmith GL, 2013, INT J FORECASTING, V29, P191, DOI 10.1016/j.ijforecast.2012.08.002
   Short MB, 2009, J QUANT CRIMINOL, V25, P325, DOI 10.1007/s10940-009-9068-8
   Spicer V, 2012, COMPUT ENVIRON URBAN, V36, P412, DOI 10.1016/j.compenvurbsys.2012.02.004
   Tekeli S., 2013, Procedia - Social and Behavioral Sciences, V106, P3012, DOI [10.1016/j.sbspro.2013.12, DOI 10.1016/J.SBSPRO.2013.12, https://doi.org/10.1016/j.sbspro.2013.12.347, DOI 10.1016/J.SBSPRO.2013.12.347]
   Tengfei Yin, 2011, Journal of Networks, V6, P990, DOI 10.4304/jnw.6.7.990-998
   TOBLER WR, 1970, ECON GEOGR, V46, P234, DOI 10.2307/143141
   Toomey TL, 2012, ALCOHOL CLIN EXP RES, V36, P1468, DOI 10.1111/j.1530-0277.2012.01753.x
   Townsley M, 2009, GEOGR ANAL, V41, P452, DOI 10.1111/j.1538-4632.2009.00775.x
   Wang JJ, 2012, OMEGA-INT J MANAGE S, V40, P758, DOI 10.1016/j.omega.2011.07.008
   Wang ST, 2013, MATER MANUF PROCESS, V29, P1, DOI 10.1080/10426914.2013.832852
   [徐冲 Xu Chong], 2015, [地理研究, Geographical Research], V34, P384
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Yu F, 2014, APPL ENERG, V134, P102, DOI 10.1016/j.apenergy.2014.07.104
   Yu H., 2012, J LIAONING TU NATURA, V2, P025
   Zhang Y, 2002, J TRANSCLUCTION TECH, V3
NR 50
TC 6
Z9 6
U1 2
U2 66
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17669
EP 17687
DI 10.1007/s11042-016-3467-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600043
DA 2024-07-18
ER

PT J
AU Rawashdeh, M
   Alhamid, MF
   Alja'am, JM
   Alnusair, A
   El Saddik, A
AF Rawashdeh, Majdi
   Alhamid, Mohammed F.
   Alja'am, Jihad Mohamad
   Alnusair, Awny
   El Saddik, Abdulmotaleb
TI Tag-based personalized recommendation in social media services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommendation; Personalization; Social tagging; Folksonomy
AB Users of ambient intelligence environments have been overwhelmed by the huge numbers of social media available, thus identifying the social media tailored to the user's need is becoming an important question to be discussed. This paper adapts the Katz proximity measure, for the use in social tagging system, to help users in ambient environment find relevant media suited to their interests. The method models the ternary relations among user, resource and tag as a weighted, undirected tripartite graph, then apply the Katz proximity measure to tripartite graph. Experiments on two real datasets are implemented and compared with many state-of-the-art algorithms. The experimental results prove that the adaptation of the Katz algorithm with the tripartite structure yields a significant improvement, and successfully ranks relevant search results according to the user's interests.
C1 [Rawashdeh, Majdi] New York Univ Abu Dhabi, Div Engn, POB 129188, Abu Dhabi, U Arab Emirates.
   [Alhamid, Mohammed F.] King Saud Univ, CCIS, Riyadh, Saudi Arabia.
   [Alja'am, Jihad Mohamad] Qatar Univ, Dept Comp Sci & Engn, Doha, Qatar.
   [Alnusair, Awny] Indiana Univ, Sch Sci Informat, Kokomo, IN USA.
   [El Saddik, Abdulmotaleb] Univ Ottawa, Sch Elect Engn & Comp Sci, Multimedia Commun Res Lab, MCRLab, Ottawa, ON, Canada.
C3 New York University Abu Dhabi; King Saud University; Qatar University;
   Indiana University System; Indiana University Kokomo; University of
   Ottawa
RP Rawashdeh, M (corresponding author), New York Univ Abu Dhabi, Div Engn, POB 129188, Abu Dhabi, U Arab Emirates.
EM majdi@nyu.edu; mohalhamid@ksu.edu.sa; jaam@qu.edu.qa; alnusair@iuk.edu;
   elsaddik@uottawa.ca
RI Alnusair, Awny/AAY-5066-2020; /D-4159-2009
OI Alnusair, Awny/0000-0001-9513-3022; /0000-0002-7690-8547
FU Qatar National Research Fund [NPRP 09-052-5-003]
FX This publication was made possible by a grant from the Qatar National
   Research Fund under its award NPRP 09-052-5-003. Its contents are solely
   the responsibility of the authors and do not necessarily represent the
   official views of the Qatar National Research Fund.
CR [Anonymous], WEB SEARCH DAT MIN C
   [Anonymous], INF KNOWL MAN C
   [Anonymous], SIGIR C RES DEV INF
   [Anonymous], P 12 IEEE INT C SOC
   [Anonymous], P 1 ACM INT C MULT R
   [Anonymous], RECOMMENDING ITEMS S
   [Anonymous], P 2 IEEE INT WORKSH
   [Anonymous], 2013, P 2013 INT C INT US, DOI DOI 10.1145/2449396.2449401
   [Anonymous], 2013, P 1 ACM INT WORKSHOP, DOI [DOI 10.1145/2505323.2505332, 10.1145/2505323.2505332]
   Cai Y, 2014, NEURAL NETWORKS, V58, P98, DOI 10.1016/j.neunet.2014.05.017
   Carmel D., 2009, P CIKM, P1227
   De Meo P, 2010, USER MODEL USER-ADAP, V20, P41, DOI 10.1007/s11257-010-9072-6
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Hossain MA, 2008, MOBILE NETW APPL, V13, P599, DOI 10.1007/s11036-008-0092-y
   Hossain MA, 2009, MULTIMED TOOLS APPL, V44, P407, DOI 10.1007/s11042-009-0285-9
   Hotho A, 2006, LECT NOTES COMPUT SC, V4011, P411
   Huang CL, 2014, KNOWL-BASED SYST, V56, P86, DOI 10.1016/j.knosys.2013.11.001
   Jäschke R, 2008, AI COMMUN, V21, P231, DOI 10.3233/AIC-2008-0438
   Katz L., 1953, Psychometrika, V18, P39, DOI [10.1007/BF02289026, DOI 10.1007/BF02289026]
   Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591
   Liu Dong., 2009, P 18 INT C WORLD WID, P351
   Ramezani Maryam, 2011, Journal of Emerging Technologies in Web Intelligence, V3, P168, DOI 10.4304/jetwi.3.2.168-176
   Sparck-Jones K, 2000, INFORM PROCESS MANAG, V36, P809, DOI 10.1016/S0306-4573(00)00016-9
   Vallet D, 2010, LECT NOTES COMPUT SC, V5993, P420, DOI 10.1007/978-3-642-12275-0_37
   Wang J, 2010, INFORM PROCESS MANAG, V46, P58, DOI 10.1016/j.ipm.2009.06.002
   Zanardi V, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P51
NR 26
TC 8
Z9 8
U1 2
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13299
EP 13315
DI 10.1007/s11042-015-2813-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800018
DA 2024-07-18
ER

PT J
AU Ji, XF
   Ju, ZJ
   Wang, C
   Wang, CH
AF Ji, Xiaofei
   Ju, Zhaojie
   Wang, Ce
   Wang, Changhui
TI Multi-view transition HMMs based view-invariant human action recognition
   method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; View-invariant; Multi-view transition; Hidden Markov
   Model
AB View-invariant human action recognition is a challenging research topic in computer vision. Hidden Markov Models(HMM) and their extensions have been widely used for view-invariant action recognition. However those methods are usually according to a large parameter space, requiring amounts of training data and with low classification accuracies for real application. A novel graphical structure based on HMM with multi-view transition is proposed to model the human action with viewpoint changing. The model consists of multiple sub action models, which correspond to the traditional HMM utilized to model the human action in a particular rotation viewpoint space. In the training process, the novel model can be built by connecting the sub action models between adjacent viewpoint spaces. In the recognition process, action with unknown viewpoint is recognized by using improved forward algorithm. The proposed model can not only simplify the model training process by decomposing the parameter space into multiple sub-spaces, but also improve the performance the algorithm by constraining the possible viewpoint changing. Experiment results on IXMAS dataset demonstrated that the proposed model obtains better performance than other recent view-invariant action recognition method.
C1 [Ji, Xiaofei; Wang, Ce; Wang, Changhui] Shenyang Aerosp Univ, Sch Automat, Shenyang, Peoples R China.
   [Ju, Zhaojie] Univ Portsmouth, Sch Comp, Portsmouth, Hants, England.
C3 Shenyang Aerospace University; University of Portsmouth
RP Ji, XF (corresponding author), Shenyang Aerosp Univ, Sch Automat, Shenyang, Peoples R China.
EM jixiaofei7804@126.com; zhaojie.ju@port.ac.uk
RI Ju, Zhaojie/AAA-5872-2019
OI Ju, Zhaojie/0000-0002-9524-7609
FU National Natural Science Foundation of China [61103123]; Program for
   Liaoning Excellent Talents in University [LJQ2014018]
FX The Project supported by the National Natural Science Foundation of
   China No. 61103123 and the Program for Liaoning Excellent Talents in
   University (No. LJQ2014018).
CR Ahmad M, 2006, INT C PATT RECOG, P263
   [Anonymous], 2007, 2007 IEEE C COMP VIS
   [Anonymous], 2007, IEEE C COMP VIS PATT
   Ashraf N, 2014, COMPUT VIS IMAGE UND, V123, P41, DOI 10.1016/j.cviu.2014.03.005
   Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779
   Holte M.B., 2011, Proceedings of the 2011 joint ACM workshop on Human gesture and behavior understanding, J-HGBU '11, P47, DOI [10.1145/2072572.2072588, DOI 10.1145/2072572.2072588]
   Ji X, 2014, INT J HUMANOID ROB, V11, P1
   Ji XF, 2010, IEEE T SYST MAN CY C, V40, P13, DOI 10.1109/TSMCC.2009.2027608
   Junejo IN, 2008, LECT NOTES COMPUT SC, V5303, P293, DOI 10.1007/978-3-540-88688-4_22
   Lee AR, 2014, INT C PATT RECOG, P501, DOI 10.1109/ICPR.2014.95
   Lim CH, 2015, PATTERN RECOGN, V48, P1773, DOI 10.1016/j.patcog.2014.11.016
   Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359
   Natarajan Pradeep., 2008, CVPR08, P1
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Peng Bo., 2008, Pattern Recognition, P1
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Qadir O, 2011, IEEE C EVOL COMPUTAT, P208
   Rogez G., 2006, Proceedings of British Machine Vision Conference, P659
   Singh VK, 2011, VISUAL COMPUT, V27, P1115, DOI 10.1007/s00371-011-0656-x
   Tran D, 2008, LECT NOTES COMPUT SC, V5302, P548, DOI 10.1007/978-3-540-88682-2_42
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Weinland D, 2010, LECT NOTES COMPUT SC, V6313, P635
   Wu D, 2014, NEUROCOMPUTING, V127, P98, DOI 10.1016/j.neucom.2013.08.038
   Wu XX, 2011, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.2011.5995624
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
   Yilmaz A, 2005, PROC CVPR IEEE, P984
NR 26
TC 8
Z9 8
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11847
EP 11864
DI 10.1007/s11042-015-2661-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200015
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kim, SH
   An, KJ
   Jang, SW
   Kim, GY
AF Kim, Sul-Ho
   An, Kwon-Jae
   Jang, Seok-Woo
   Kim, Gye-Young
TI Texture feature-based text region segmentation in social multimedia data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social multimedia; Artificial neural network; Candidate region;
   Background
ID MORPHOLOGICAL OPERATIONS; EXTRACTION; IMAGES; LOCALIZATION; INTERNET
AB This paper proposes a method of effectively segmenting text areas that exist in images by using the texture features of various types of input images obtained in social multimedia networks with an artificial neural network. The proposed text segmentation method consists of four main steps: a step for extracting candidate text areas, a step for localizing the text areas, a step for separating the text from the background, and a step for verifying the candidate text areas. In the candidate text area extraction step, candidate blocks that have any text areas are segmented in an input image on the basis of the texture features of the candidate blocks. In the text area localization step, only strings are extracted from the candidate text blocks. In the text and background separation step, the text areas are separated from the background area in the localized text blocks. In the candidate text area verification step, an artificial neural network is used to verify whether the extracted text blocks include actual text areas and exclude non-text areas. In the experimental results, the proposed method was applied to various types of news and non-news images, and it was found that the proposed method extracted text regions more accurately than existing methods.
C1 [Kim, Sul-Ho; An, Kwon-Jae; Kim, Gye-Young] Soongsil Univ, Sch Software, 369 Sangdo Ro, Seoul 156743, South Korea.
   [Jang, Seok-Woo] Anyang Univ, Dept Digital Media, 708-113,Anyang 5 Dong, Anyang 430714, South Korea.
C3 Soongsil University; Anyang University
RP Kim, GY (corresponding author), Soongsil Univ, Sch Software, 369 Sangdo Ro, Seoul 156743, South Korea.
EM sulho@ssu.ac.kr; ankwonjae@hanmail.net; swjang7285@gmail.com;
   gykim11@ssu.ac.kr
OI Jang, Seok-Woo/0000-0001-5580-4098
FU ICT R&D program of MSIP/IITP [2014(R0112-14-1014]
FX This work was supported by the ICT R&D program of MSIP/IITP.
   [2014(R0112-14-1014), The Development of Open Platform for Service of
   Convergence Contents.
CR Affonso C, 2015, EXPERT SYST APPL, V42, P9482, DOI 10.1016/j.eswa.2015.07.075
   Aggoune A, 2014, P INT S CONC TOOLS K, P1
   Angadi SA, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P42, DOI 10.1109/ICSIP.2014.11
   Caixia Deng, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P1189, DOI 10.1109/CISP.2011.6100499
   Chen DT, 2004, PATTERN RECOGN, V37, P595, DOI 10.1016/j.patcog.2003.06.001
   Dan Z, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON SERVICE OPERATIONS AND LOGISTICS, AND INFORMATICS (SOLI), P180, DOI 10.1109/SOLI.2013.6611406
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Haneda E, 2011, IEEE T IMAGE PROCESS, V20, P1611, DOI 10.1109/TIP.2010.2101611
   Herrera J, 2011, APPL SOFT COMPUT, V11, P4738, DOI 10.1016/j.asoc.2011.07.010
   Hsia SC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P321, DOI 10.1109/IIH-MSP.2014.86
   Huang ST, 2008, PATTERN RECOGN, V41, P2890, DOI 10.1016/j.patcog.2008.03.004
   Huang X, 2009, P INT C MAN SERV SCI, P1
   Hui Zhang, 2012, 2012 International Conference on Computer Science and Service System (CSSS), P238, DOI 10.1109/CSSS.2012.67
   Ilkuçar M, 2014, SIG PROCESS COMMUN, P762, DOI 10.1109/SIU.2014.6830341
   Jee HK, 2014, MULTIMED TOOLS APPL, V68, P225, DOI 10.1007/s11042-011-0880-4
   Ji-Wei Wu, 2010, Proceedings of the 2010 IEEE International Conference on Granular Computing (GrC-2010), P519, DOI 10.1109/GrC.2010.146
   Jiang N, 2012, COMPUT ELECTRON AGR, V85, P123, DOI 10.1016/j.compag.2012.04.004
   Kim T, 2015, MULTIMED TOOLS APPL, V74, P1697, DOI 10.1007/s11042-014-2215-8
   Kim W, 2009, IEEE T IMAGE PROCESS, V18, P401, DOI 10.1109/TIP.2008.2008225
   Kim WJ, 2008, SIGNAL PROCESS-IMAGE, V23, P442, DOI 10.1016/j.image.2008.04.010
   Kolesnikov A, 2015, PATTERN RECOGN, V48, P941, DOI 10.1016/j.patcog.2014.09.017
   Li J, 2008, IEEE IMAGE PROC, P3008, DOI 10.1109/ICIP.2008.4712428
   Lyu MR, 2005, IEEE T CIRC SYST VID, V15, P243, DOI 10.1109/TCSVT.2004.841653
   Marquez D, 2007, LECT NOTES COMPUT SC, V4816, P91
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Roy PP, 2012, PATTERN RECOGN, V45, P1972, DOI 10.1016/j.patcog.2011.09.026
   Qian XM, 2007, SIGNAL PROCESS-IMAGE, V22, P752, DOI 10.1016/j.image.2007.06.005
   Rahman MA, 2014, MULTIMED TOOLS APPL, V71, P1717, DOI 10.1007/s11042-012-1302-y
   Roccetti M, 2005, MULTIMED TOOLS APPL, V25, P217, DOI 10.1007/s11042-005-5606-z
   Song JQ, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P385
   Strauss O, 2007, PATTERN RECOGN, V40, P3578, DOI 10.1016/j.patcog.2007.05.003
   Su R, 2014, PATTERN RECOGN, V47, P3193, DOI 10.1016/j.patcog.2014.04.024
   Nguyen TN, 2015, VISUAL COMPUT, V31, P391, DOI 10.1007/s00371-014-0934-5
   Thepade SD, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P962, DOI 10.1109/ICACCI.2013.6637306
   Tian SX, 2014, INT C PATT RECOG, P2703, DOI 10.1109/ICPR.2014.467
   Vasudev T, 2007, PATTERN RECOGN LETT, V28, P2343, DOI 10.1016/j.patrec.2007.07.014
   Xiaodong Huang, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P474, DOI 10.1109/CISP.2011.6099946
   Zhang DQ, 2002, IEEE IMAGE PROC, P593
NR 38
TC 11
Z9 11
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12815
EP 12829
DI 10.1007/s11042-015-3237-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700030
DA 2024-07-18
ER

PT J
AU Ouyang, JH
   Li, XM
   Li, HT
AF Ouyang, Jihong
   Li, Ximing
   Li, Hongtu
TI Boosting scene understanding by hierarchical pachinko allocation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene understanding; VSIM; hPAM; Topic modeling
AB Scene understanding is a popular research direction. In this area, many attempts focus on the problem of naming objects in the complex natural scene, and visual semantic integration model (VSIM) is the representative. This model consists of two parts: semantic level and visual level. In the first level, it uses a four-level pachinko allocation model (PAM) to capture the semantics behind images. However, this four-level PAM is inflexible and lacks of considerations of common subtopics that represent the background semantics. To address these problems, we use hierarchical PAM (hPAM) to replace PAM. Since hPAM is flexible, we investigate two variations of hPAM to boost VSIM in this paper. We derive the Gibbs sampler to learn the proposed models. Empirical results validate that our works can obtain better performance than the state-of-the-art algorithms.
C1 [Ouyang, Jihong; Li, Ximing; Li, Hongtu] Jilin Univ, Coll Comp Sci & Technol, Changchun, Peoples R China.
   [Ouyang, Jihong; Li, Ximing; Li, Hongtu] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun, Peoples R China.
C3 Jilin University; Jilin University
RP Li, HT (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun, Peoples R China.; Li, HT (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun, Peoples R China.
EM lihongtu@jlu.edu.cn
FU National Nature Science Foundation of China (NSFC) [61170092, 61133011,
   61103091]
FX This work was supported by National Nature Science Foundation of China
   (NSFC) under the Grant No. 61170092, 61133011, and 61103091.
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009
   Chakraborty I, 2013, CORR
   Choi MJ, 2010, PROC CVPR IEEE, P129, DOI 10.1109/CVPR.2010.5540221
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Fürnkranz J, 2008, MACH LEARN, V73, P133, DOI 10.1007/s10994-008-5064-8
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li LJ, 2009, PROC CVPR IEEE, P2036, DOI 10.1109/CVPRW.2009.5206718
   Li Wei, 2006, P 23 INT C MACH LEAR, DOI [10.1145/1143844.1143917, DOI 10.1145/1143844.1143917]
   Liu LQ, 2011, IEEE I CONF COMP VIS, P2486, DOI 10.1109/ICCV.2011.6126534
   Luming Zhang, 2011, 2011 IEEE International Conference on Data Mining Workshops, P847, DOI 10.1109/ICDMW.2011.108
   Malisiewicz TJ, 2006, DETECTING OBJECTS VI
   Mimno D. M., 2007, ICML, V227, P633
   Rasiwasia N, 2013, IEEE T PATTERN ANAL, V35, P2665, DOI 10.1109/TPAMI.2013.69
   Russakovsky O, 2012, LECT NOTES COMPUT SC, V7573, P1, DOI 10.1007/978-3-642-33709-3_1
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang Y, 2014, IEEE T MULTIMEDIA, V16, P1677, DOI 10.1109/TMM.2014.2323014
   Yang Y, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2457450.2457456
   Yang Y, 2013, PATTERN RECOGN, V46, P1358, DOI 10.1016/j.patcog.2012.10.026
   Yang Y, 2011, WORLD WIDE WEB, V14, P133, DOI 10.1007/s11280-010-0099-8
   Zhang L, 2014, IEEE T IND ELECT
   Zhang L., 2014, IEEE T NEURAL NETWOR
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
NR 27
TC 0
Z9 0
U1 2
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12581
EP 12595
DI 10.1007/s11042-014-2414-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700017
DA 2024-07-18
ER

PT J
AU Shi, ZH
   Xu, BX
   Zheng, X
   Zhao, MH
AF Shi, Zhenghao
   Xu, Binxin
   Zheng, Xia
   Zhao, Minghua
TI An integrated method for ancient Chinese tablet images de-noising based
   on assemble of multiple image smoothing filters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image de-noising; Guided filter; Multi-scale Retinex; Scan-length
AB There are unavoidably lots of noises in tablet images due to natural or man-made decay, which have a significant affect on learning and studying of the ancient Chinese calligraphy works with Chinese tablet images. To address this problem, an integrated de-noising method, based on assemble of multiple image smoothing filters, is proposed in this paper. To avoid damaging characters and losing detail information, input Chinese tablet images are enhanced by the Guided filter and multi-scale Retinex filter firstly. Then the enhanced tablet images are converted to binary ones by the Otsu thresholding filter. Finally, most random and block noises are removed using an improved scan-length statistics filter based on connected region. The performance of the proposed method was validated on our Chinese tablet image data set, which consists of 200 Chinese tablet images with different kinds of noise. Experiments show that, the proposed method can effectively remove most image noise (including various block noise, linear noise and ant-like noise) and preserve characters better than existing methods.
C1 [Shi, Zhenghao; Xu, Binxin; Zhao, Minghua] Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Shaanxi, Peoples R China.
   [Zheng, Xia] Zhejiang Univ, Dept Culture Heritage & Museol, Hangzhou 310028, Zhejiang, Peoples R China.
C3 Xi'an University of Technology; Zhejiang University
RP Zheng, X (corresponding author), Zhejiang Univ, Dept Culture Heritage & Museol, Hangzhou 310028, Zhejiang, Peoples R China.
EM zhengxia@zju.edu.cn
FU National Natural Science Foundation of China [61202198, 61401355];
   Social Science Foundation of Zhejiang Province, China [11JCWH13YB];
   Nature Science Foundation of Shanxi Education Department [2013JK1136]
FX This work is partially supported by a grant from the National Natural
   Science Foundation of China (No. 61202198 and No. 61401355), Social
   Science Foundation of Zhejiang Province, China (No. 11JCWH13YB), Nature
   Science Foundation of Shanxi Education Department (No. 2013JK1136). The
   authors also gratefully acknowledge the helpful comments and suggestions
   of the reviewers.
CR [Anonymous], DOC AN REC 2001 P 6
   [Anonymous], IEEE SIGNAL PROCESS
   Chen RP, 2013, IEEE GEOSCI REMOTE S, V10, P826, DOI 10.1109/LGRS.2012.2225594
   Chiu HP, 1999, PATTERN RECOGN, V32, P1947, DOI 10.1016/S0031-3203(99)00003-5
   Fan Chao-dong, 2014, Journal on Communications, V35, P70, DOI 10.3969/j.issn.1000-436x.2014.05.010
   Guemri K, 2014, 2014 6TH INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), P279, DOI 10.1109/SOCPAR.2014.7008019
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Kandemir C, 2015, DIGIT SIGNAL PROCESS, V46, P164, DOI 10.1016/j.dsp.2015.08.012
   Li HJ, 2016, PATTERN RECOGN, V49, P237, DOI 10.1016/j.patcog.2015.05.028
   Lin HN, 2014, OPTIK, V125, P7143, DOI 10.1016/j.ijleo.2014.07.118
   Liu H, 2012, 2012 IEEE FIFTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P574, DOI 10.1109/ICACI.2012.6463230
   Liu XW, 2013, APPL MECH MATER, V411-414, P1348, DOI 10.4028/www.scientific.net/AMM.411-414.1348
   Singer H, 2015, IEEE T AUTOMAT CONTR, V60, P2476, DOI 10.1109/TAC.2015.2394952
   Tao DP, 2014, NEUROCOMPUTING, V129, P159, DOI 10.1016/j.neucom.2013.09.044
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   [肖蕾 XIAO Lei], 2009, [激光杂志, Laser Journal], V30, P44
   Zhang Jun-song, 2006, Journal of Zhejiang University (Science), V7, P1178, DOI 10.1631/jzus.2006.A1178
   Zheng X., 2015, MULTIMED TOOLS APPL, P1
   Zhou MK, 2016, PATTERN RECOGN, V49, P7, DOI 10.1016/j.patcog.2015.07.007
NR 19
TC 13
Z9 13
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 12245
EP 12261
DI 10.1007/s11042-016-3421-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200036
DA 2024-07-18
ER

PT J
AU Wang, Y
   Yu, Q
   Liu, ZX
   Lei, T
   Guo, Z
   Qi, M
   Fan, YY
AF Wang, Yi
   Yu, Qian
   Liu, Zhexing
   Lei, Tao
   Guo, Zhe
   Qi, Min
   Fan, Yangyu
TI Evaluation on diffusion tensor image registration algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diffusion tensor image; Image registration; Evaluation; Tensor-based;
   Scalar-based
ID TEMPLATE
AB With the application in many neuroimaging studies, diffusion tensor image (DTI) registration has generated considerable interest and been studied widely. Although a number of DTI registration methods have been developed, their performances have not yet been compared systematically. This work addresses this gap by comparing a large number of existing DTI registration methods and gives the comprehensive evaluation results. In this paper, the open-access IXI DTI dataset were used. In order to compare the accuracy of tensor matching, 11 open-source registration methods were evaluated with 7 quantitative and open-access evaluation criteria that measure the similarity among tensors (namely tensor-based techniques) or scalar images derived from diffusion tensors (namely scalar-based techniques). The evaluation results indicate that the diffeomorphic deformable tensor registration method (referred to as DTI-TK) is the best method, followed by the symmetric image normalization method (referred to as SyN).
C1 [Wang, Yi; Yu, Qian; Guo, Zhe; Qi, Min; Fan, Yangyu] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China.
   [Liu, Zhexing] Southern Med Univ, Sch Biomed Engn, Guangzhou 510515, Guangdong, Peoples R China.
   [Lei, Tao] Lanzhou Jiaotong Univ, Sch Informat & Elect Engn, Lanzhou 730070, Peoples R China.
C3 Northwestern Polytechnical University; Southern Medical University -
   China; Lanzhou Jiaotong University
RP Wang, Y (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China.
EM wangyi79@nwpu.edu.cn; 1061457644@qq.com; 460304534@qq.com;
   leitaoly@163.com; guozhe@nwpu.edu.cn; drqimin@nwpu.edu.cn;
   fan_yangyu@nwpu.edu.cn
RI wang, yi/KBB-3614-2024
OI Wang, Yi/0000-0002-7743-1779
FU National Nature Science Foundation of China [60903127, 61372063,
   61202314, 61402371]; Natural Science Basic Research Plan in Shaanxi
   Province of China [2015JM6317, 2013JQ8039]; Fundamental Research Funds
   for the Central Universities [3102014JCQ01060]; NPU Foundation for
   Fundamental Research [JCY20130130]; Graduate Starting Seed Fund of
   Northwestern Polytechnical University, Xi'an, Shaanxi, China [Z2014137]
FX This work was supported by the National Nature Science Foundation of
   China (Grant No. 60903127, 61372063, 61202314, 61402371); Natural
   Science Basic Research Plan in Shaanxi Province of China (Grant No.
   2015JM6317, 2013JQ8039); Fundamental Research Funds for the Central
   Universities (Grant No. 3102014JCQ01060); NPU Foundation for Fundamental
   Research (Grant No. JCY20130130); Graduate Starting Seed Fund of
   Northwestern Polytechnical University (Grant No. Z2014137), Xi'an,
   Shaanxi, China.
CR Adluru N, 2012, NEUROIMAGE, V59, P306, DOI 10.1016/j.neuroimage.2011.07.029
   Alexander DC, 2000, COMPUT VIS IMAGE UND, V77, P233, DOI 10.1006/cviu.1999.0817
   Andersson J.L., 2007, TR07JA2 U OXF FMRIB
   [Anonymous], 2001, INT C MEDICAL IMAGE
   Arsigny V, 2005, LECT NOTES COMPUT SC, V3749, P115
   Arsigny V, 2006, MAGN RESON MED, V56, P411, DOI 10.1002/mrm.20965
   Ashburner J, 2007, STATISTICAL PARAMETRIC MAPPING: THE ANALYSIS OF FUNCTIONAL BRAIN IMAGES, P49, DOI 10.1016/B978-012372560-8/50004-8
   Avants BB, 2008, MED IMAGE ANAL, V12, P26, DOI 10.1016/j.media.2007.06.004
   BASSER PJ, 1994, J MAGN RESON SER B, V103, P247, DOI 10.1006/jmrb.1994.1037
   Basser PJ, 2000, MAGNET RESON MED, V44, P41, DOI 10.1002/1522-2594(200007)44:1<41::AID-MRM8>3.0.CO;2-O
   Cao Y, 2005, IEEE T MED IMAGING, V24, P1216, DOI 10.1109/TMI.2005.853923
   de Groot M, 2013, NEUROIMAGE, V76, P400, DOI 10.1016/j.neuroimage.2013.03.015
   Hu YX, 2012, RES MULTIMODALITY ME
   Jones DK, 2002, NEUROIMAGE, V17, P592, DOI 10.1006/nimg.2002.1148
   Joshi S, 2004, NEUROIMAGE, V23, pS151, DOI 10.1016/j.neuroimage.2004.07.068
   Keihaninejad S, 2013, NEUROIMAGE, V72, P153, DOI 10.1016/j.neuroimage.2013.01.044
   Klein A, 2009, NEUROIMAGE, V46, P786, DOI 10.1016/j.neuroimage.2008.12.037
   Mattes D, 2003, IEEE T MED IMAGING, V22, P120, DOI 10.1109/TMI.2003.809072
   Mayer A., 2007, P WORKSH STAT REG PA
   Miller P, 2012, NEUROIMAGE, V60, P2309, DOI 10.1016/j.neuroimage.2012.02.033
   Ourselin S, 2000, LECT NOTES COMPUT SC, V1935, P557
   Shadmi R, 2010, I S BIOMED IMAGING, P528, DOI 10.1109/ISBI.2010.5490292
   Song ZL, 2010, RES IMAGE REGISTRATI
   Studholme C, 1999, PATTERN RECOGN, V32, P71, DOI 10.1016/S0031-3203(98)00091-0
   Sweet A, 2010, LECT NOTES COMPUT SC, V6204, P198, DOI 10.1007/978-3-642-14366-3_18
   Van Hecke W, 2007, IEEE T MED IMAGING, V26, P1598, DOI 10.1109/TMI.2007.906786
   Vercauteren T, 2009, NEUROIMAGE, V45, pS61, DOI 10.1016/j.neuroimage.2008.10.040
   Wang Y, 2011, NEUROIMAGE, V55, P1577, DOI 10.1016/j.neuroimage.2011.01.038
   Wang YJ, 2013, PHYS MED BIOL, V58, P6029, DOI 10.1088/0031-9155/58/17/6029
   Zhang H, 2006, MED IMAGE ANAL, V10, P764, DOI 10.1016/j.media.2006.06.004
   Zhang SW, 2013, J MAGN RESON IMAGING, V37, P372, DOI 10.1002/jmri.23842
   Zhang SW, 2011, NEUROIMAGE, V54, P974, DOI 10.1016/j.neuroimage.2010.09.008
   Zvitia O, 2010, IEEE T MED IMAGING, V29, P132, DOI 10.1109/TMI.2009.2029097
NR 33
TC 5
Z9 5
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 8105
EP 8122
DI 10.1007/s11042-015-2727-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600030
DA 2024-07-18
ER

PT J
AU Zheng, X
   Miao, QG
   Shi, ZH
   Fan, YC
   Shui, WY
AF Zheng, Xia
   Miao, Qiguang
   Shi, Zhenghao
   Fan, Yachun
   Shui, Wuyang
TI A new artistic information extraction method with multi channels and
   guided filters for calligraphy works
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artistic information extraction; Form information; Spirit information;
   Multi channels; Guided filter; Calligraphy works
ID MODEL
AB The artistic beauty of Chinese calligraphy is constituted by two elements: form and spirit. To learn and study calligraphy works, both of form and spirit should be extracted correctly. However, most currently used calligraphy image extraction methods can only obtain form information. To address this problem, an extraction method, based on multi-channel and guided filters, is proposed in this study. The proposed method consists of three major operations: color space transformation, tablet and writing discrimination, and information extraction using guided filter. To simulate the human visual perception of calligraphy work, the color space of a calligraphy image is converted from RGB to CIELAB firstly. Then the calligraphy image is distinguished as either a tablet or a writing based on channel b. Finally, information extraction using guided filter is performed. For a tablet, a two-stage guided filtering strategy based on L channel is employed to reduce noise and obtain form information. For a writing, a guided filter based on channels L and a is used to extract both form and spirit information. To demonstrate the accuracy and efficiency of the proposed method, comparison experiments are implemented on both types of images. Experimental results reveal the advantages of the proposed method.
C1 [Zheng, Xia] Zhejiang Univ, Dept Culture Heritage & Museol, Hangzhou 310028, Zhejiang, Peoples R China.
   [Miao, Qiguang] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
   [Shi, Zhenghao] Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Shaanxi, Peoples R China.
   [Fan, Yachun; Shui, Wuyang] Beijing Normal Univ, Coll Informat Sci & Technol, Beijing 100875, Peoples R China.
C3 Zhejiang University; Xidian University; Xi'an University of Technology;
   Beijing Normal University
RP Shi, ZH (corresponding author), Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Shaanxi, Peoples R China.
EM ylshi@xaut.edu.cn
OI Miao, Qiguang/0000-0002-2872-388X
FU National Natural Science Foundation of China [61202198]; Social Science
   Foundation of Zhejiang Province, China [11JCWH13YB]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 61202198) and Social Science Foundation of Zhejiang
   Province, China (Grant No. 11JCWH13YB).
CR [Anonymous], P 3 INT C MULT TECHN
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   Chen J., 2009, World Non-Grid-Connected Wind Power and Energy Conference (WNWEC), P1, DOI DOI 10.1007/978-1-84800-901-1_
   Connolly C, 1997, IEEE T IMAGE PROCESS, V6, P1046, DOI 10.1109/83.597279
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Ghamisi P, 2012, EXPERT SYST APPL, V39, P12407, DOI 10.1016/j.eswa.2012.04.078
   Guo F, 2014, INT J AUTOM COMPUT, V11, P78, DOI 10.1007/s11633-014-0768-7
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Immerkaer J, 1996, COMPUT VIS IMAGE UND, V64, P300, DOI 10.1006/cviu.1996.0060
   Liu J.Z., 1993, Acta Automatica Sin, V19, P101, DOI DOI 10.16383/J.AAS.1993.01.015
   Lu WM, 2011, J ZHEJIANG U-SCI C, V12, P873, DOI 10.1631/jzus.C1100005
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   QING YX, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P704, DOI 10.1109/ICPR.1992.202084
   Seo HJ, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-3
   Shi C, 2013, PROC SPIE, V8658, DOI 10.1117/12.2003633
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Wong STS, 2006, IEEE IMAGE PROC, P397, DOI 10.1109/ICIP.2006.312477
   Xia Y, 2013, COMPUT GRAPH FORUM, V32, P11, DOI 10.1111/cgf.12207
   Xu SH, 2012, IEEE INTELL SYST, V27, P63, DOI 10.1109/MIS.2012.46
   YASNOFF WA, 1977, PATTERN RECOGN, V9, P217, DOI 10.1016/0031-3203(77)90006-1
   Yin PY, 1999, SIGNAL PROCESS, V72, P85, DOI 10.1016/S0165-1684(98)00167-4
   Zeng F., 2013, CHIN C IM GRAPH TECH
   Zhang X., 2011, P 2011 WORKSHOP HIST, P37
   Zhang XF, 2012, PROC SPIE, V8297, DOI 10.1117/12.908872
   Zhang Y, 2013, ADV MECH ENG, V2013, P1, DOI DOI 10.4225/08/58B5BAAD4FCC2
   Zhuang Y, 2010, LECT NOTES COMPUT SC, V6184, P544, DOI 10.1007/978-3-642-14246-8_53
   Zhuang YT, 2009, J VIS COMMUN IMAGE R, V20, P84, DOI 10.1016/j.jvcir.2008.11.007
NR 28
TC 11
Z9 11
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8719
EP 8744
DI 10.1007/s11042-015-2788-x
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300027
DA 2024-07-18
ER

PT J
AU Keskinarkaus, A
   Huttunen, S
   Siipo, A
   Holappa, J
   Laszlo, M
   Juuso, I
   Väyrynen, E
   Heikkilä, J
   Lehtihalmes, M
   Seppänen, T
   Laukka, S
AF Keskinarkaus, Anja
   Huttunen, Sami
   Siipo, Antti
   Holappa, Jukka
   Laszlo, Magda
   Juuso, Ilkka
   Vayrynen, Eero
   Heikkila, Janne
   Lehtihalmes, Matti
   Seppanen, Tapio
   Laukka, Seppo
TI MORE - a multimodal observation and analysis system for social
   interaction research
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spherical video; Audio; Database; Social interaction; Collaboration;
   Metadata; Computer vision; Speech analysis; Web technologies
AB The MORE system is designed for observation and machine-aided analysis of social interaction in real life situations, such as classroom teaching scenarios and business meetings. The system utilizes a multichannel approach to collect data whereby multiple streams of data in a number of different modalities are obtained from each situation. Typically the system collects a 360-degree video and audio feed from multiple microphones set up in the space. The system includes an advanced server backend component that is capable of performing video processing, feature extraction and archiving operations on behalf of the user. The feature extraction services form a key part of the system and rely on advanced signal analysis techniques, such as speech processing, motion activity detection and facial expression recognition in order to speed up the analysis of large data sets. The provided web interface weaves the multiple streams of information together, utilizes the extracted features as metadata on the audio and video data and lets the user dive into analyzing the recorded events. The objective of the system is to facilitate easy navigation of multimodal data and enable the analysis of the recorded situations for the purposes of, for example, behavioral studies, teacher training and business development. A further unique feature of the system is its low setup overhead and high portability as the lightest MORE setup only requires a laptop computer and the selected set of sensors on site.
C1 [Keskinarkaus, Anja; Laszlo, Magda; Juuso, Ilkka; Vayrynen, Eero; Seppanen, Tapio] Univ Oulu, Fac Informat Technol & Elect Engn, Dept Comp Sci & Engn, Oulu, Finland.
   [Huttunen, Sami; Holappa, Jukka; Heikkila, Janne] Univ Oulu, Fac Informat Technol & Elect Engn, Ctr Machine Vis Res, Oulu, Finland.
   [Siipo, Antti; Laukka, Seppo] Univ Oulu, Fac Educ, Res Unit Psychol, Learning Res Lab,Learn Lab, Oulu, Finland.
   [Lehtihalmes, Matti] Univ Oulu, Fac Humanities, Logoped, Oulu, Finland.
C3 University of Oulu; University of Oulu; University of Oulu; University
   of Oulu
RP Huttunen, S (corresponding author), Univ Oulu, Fac Informat Technol & Elect Engn, Ctr Machine Vis Res, Oulu, Finland.
EM anja.keskinarkaus@ee.oulu.fi; sami.huttunen@ee.oulu.fi;
   antti.siipo@oulu.fi; jukka.holappa@ee.oulu.fi; laszlomagda@gmail.com;
   ilkka.juuso@ee.oulu.fi; eero.vayrynen@ee.oulu.fi;
   janne.heikkila@ee.oulu.fi; matti.lehtihalmes@oulu.fi;
   tapio.seppanen@oulu.fi; seppo.laukka@oulu.fi
CR Amidon E., 1967, ROLE TEACHER CLASSRO
   Anderson H, 1945, STUDIES TEACHERS CLA
   Anderson H, 1946, STUDIES TEACHERS CLA
   Anderson HH, 1939, CHILD DEV, V10, P73
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Derry SJ, 2010, J LEARN SCI, V19, P3, DOI 10.1080/10508400903452884
   eXist Solutions GmbH, 2000, EX DB OP SOURC NAT X
   Flanders N., 1970, ANAL TEACHER BEHAV
   Gatica-Perez D, 2009, IMAGE VISION COMPUT, V27, P1775, DOI 10.1016/j.imavis.2009.01.004
   Goldman R, 2007, ORION ONLINE DIGITAL, P507
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Horn E, 1914, CONTRIBUTIONS ED, V67
   International Telecommunication Union (ITU), 2012, P 56 OBJ MEAS ACT SP
   IRIS Connect, 2012, CLASS OBS LESS OBS T
   Kiema H, 2014, COLLA 2014, P28
   Mchenry V, 1968, USE VIDEO PROCESSES
   Noldus, 1989, SOFTW LABS BEH RES V
   Pea R, 2004, IEEE MULTIMEDIA, V11, P54, DOI 10.1109/MMUL.2004.1261108
   Pea R, 2008, IEEE T LEARN TECHNOL, V1, P235, DOI 10.1109/TLT.2009.5
   Point Grey Research Inc, 2013, ACC 360 SPHER IM MUL
   Powell B.A., 2003, Journal of Mathematical Behavior, V22, P405
   Puckett R.C., 1928, SCHOOL REV, V36, P209
   Schreer O, 2013, P IEEE, V101, P99, DOI 10.1109/JPROC.2012.2193850
   Siipo A, 2010, 3 INT ELBA SCI C, P60
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Stevens R, 2002, P C COMP SUPP COLL L
   Sun X., 2001, P ACM MULT, P329, DOI DOI 10.1145/500141.500191
   Sun XD, 2005, IEEE T MULTIMEDIA, V7, P981, DOI 10.1109/TMM.2005.854388
   Transana, 2005, QUAL AN SOFTW VID AU
   Vayrynen E, 2005, P 2 BALT C HUM LANG
   Väyrynen E, 2013, IEEE T AFFECT COMPUT, V4, P47, DOI 10.1109/T-AFFC.2012.35
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wong WK, 2010, 2 INT C COMP RES DEV, DOI [10.1109/ICCRD.2010.178, DOI 10.1109/ICCRD.2010.178]
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 34
TC 7
Z9 7
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6321
EP 6345
DI 10.1007/s11042-015-2574-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700014
DA 2024-07-18
ER

PT J
AU Khosroshahi, AA
   Yousefi, S
   Rahbar, AG
AF Khosroshahi, Abdol Agheli
   Yousefi, Saleh
   Rahbar, Akbar Ghaffarpour
TI IPTV channel switching delay reduction through predicting subscribers'
   behaviors and preferences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IPTV; Channel switching delay; Users' behaviors and preferences; WiMAX
   networks
ID TIME
AB This article aims at proposing a novel approach based on subscribers' behaviors and preferences in order to reduce channel switching delay in Internet protocol television (IPTV) over WiMAX networks. In the proposed scheme, first an algorithm is proposed for extracting users' preferences according to their behaviors so that the list of favorite channels is established for each user, where each channel is assigned a score. Having the channels clustered by the IPTV service providers, we propose two algorithms namely PGCP and P-PGCP based on which the favorite channels whose scores exceed a predefined threshold are pre-fetched in a low quality format. This procedure referred to as background channel transmission is the key idea in reducing channel switching latency. In PGCP, the dedicated bandwidth of pre-fetched channels is given to the highest score channels available at the top of each user's preference list. However in the p-PGCP, the popularity of the channels among all users is also taken into account in such a way that a channel which is popular among more users is assigned a higher priority of pre-fetching. Simulation results demonstrate the fact that the proposed two algorithms sufficiently take advantage of users' behavior patterns and is capable of reducing the channel switching time compared with existing approaches.
C1 [Khosroshahi, Abdol Agheli; Yousefi, Saleh] Urmia Univ, Dept Comp Engn, Orumiyeh 57561, Iran.
   [Rahbar, Akbar Ghaffarpour] Sahand Univ Technol, Comp Networks Res Lab, Elect Engn Res Ctr, Tabriz, Iran.
C3 Urmia University; Sahand University of Technology
RP Rahbar, AG (corresponding author), Sahand Univ Technol, Comp Networks Res Lab, Elect Engn Res Ctr, Tabriz, Iran.
EM agheli@sut.ac.ir; s.yousefi@urmia.ac.ir; ghaffarpour@sut.ac.ir
RI Yousefi, Saleh/AAM-2561-2020
OI Ghaffarpour Rahbar, Akbar/0000-0002-0902-379X
CR Ahmad MZ, 2009, INT CONF EMERG TECHN, P466, DOI 10.1109/ICET.2009.5353126
   [Anonymous], P 5 INT C APPL INF C
   Ardissono L., 2004, USER MODELING RECOMM
   Athari A, 2012, 20 IR C EL ENG ICEE
   Azgin A, 2011, IEEE IC COMP COM NET
   Beyragh AA, 2014, MULTIMED TOOLS APPL, V72, P1049, DOI 10.1007/s11042-013-1414-z
   Cheng ST, 2012, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2012-354
   Degrande N, 2008, IEEE COMMUN MAG, V46, P94, DOI 10.1109/MCOM.2008.4473090
   Hase JP, 2014, INT J COMPUT ENG RES, V04, P20
   Iniewski K., 2010, Convergence of mobile and stationary next-generation networks
   Junyu Lai, 2012, Wired/Wireless Internet Communication. Proceedings 10th International Conference (WWIC 2012), P76, DOI 10.1007/978-3-642-30630-3_7
   Kim H., 2012, IEEE INT S WORLD WIR, P1
   Kim Y., 2008, INTEGRATED MODELING, P1
   Koo J, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P845, DOI 10.1109/ICCE.2011.5722897
   Koo J, 2011, IEEE T CONSUM ELECTR, V57, P357, DOI 10.1109/TCE.2011.5955167
   Lee CY, 2010, IEEE T BROADCAST, V56, P321, DOI 10.1109/TBC.2010.2051494
   Lee J, 2007, LECT NOTES COMPUT SC, V4773, P235
   Lee Y, 2008, IEEE T CONSUM ELECTR, V54, P912, DOI 10.1109/TCE.2008.4560178
   Lloret J, 2013, MULTIMED TOOLS APPL, V67, P7, DOI 10.1007/s11042-011-0929-4
   Mandal S., 2008, Intelligent Pre-Fetching to Reduce Channel Switching Delay in IPTV Systems
   Manzato DAG, 2013, IEEE COMMUN MAG, V51, P120, DOI 10.1109/MCOM.2013.6576349
   Monteiro MMMDCF., 2009, A literacia em saude, P1, DOI 10.1155/2009/653481
   Sarni M, 2009, ICNS: 2009 FIFTH INTERNATIONAL CONFERENCE ON NETWORKING AND SERVICES, P396, DOI 10.1109/ICNS.2009.52
   Xiaowei SW, 2006, Informatics in Control, Automation and Robotics I, P105, DOI 10.1007/1-4020-4543-3_12
   Siebert P, 2009, IEEE T BROADCAST, V55, P407, DOI 10.1109/TBC.2008.2012019
   Sue CC, 2009, 2009 FIRST INTERNATIONAL CONFERENCE ON UBIQUITOUS AND FUTURE NETWORKS, P131, DOI 10.1109/ICUFN.2009.5174299
   Uzunalioglu H, 2009, P CONS COMM NETW C 2, P1
   Van Wallendael G, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P136, DOI 10.1109/ISM.2009.35
   Xiao B., 2009, P INT C MAN SERV SCI, P1
NR 29
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6283
EP 6302
DI 10.1007/s11042-015-2572-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700012
DA 2024-07-18
ER

PT J
AU Long, XZ
   Lu, HT
   Peng, Y
   Wang, XZ
   Feng, SK
AF Long, Xianzhong
   Lu, Hongtao
   Peng, Yong
   Wang, Xianzhong
   Feng, Shaokun
TI Image classification based on improved VLAD
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Scale-invariant feature transform; Vector of
   locally ggregated descriptors; K-means clustering algorithm
ID DESCRIPTORS; KERNEL; SPARSE
AB Recently, a coding scheme called vector of locally aggregated descriptors (VLAD) has got tremendous successes in large scale image retrieval due to its efficiency of compact representation. VLAD employs only the nearest neighbor visual word in dictionary to aggregate each descriptor feature. It has fast retrieval speed and high retrieval accuracy under small dictionary size. In this paper, we give three improved VLAD variations for image classification: first, similar to the bag of words (BoW) model, we count the number of descriptors belonging to each cluster center and add it to VLAD; second, in order to expand the impact of residuals, squared residuals are taken into account; thirdly, in contrast with one nearest neighbor visual word, we try to look for two nearest neighbor visual words for aggregating each descriptor. Experimental results on UIUC Sports Event, Corel 10 and 15 Scenes datasets show that the proposed methods outperform some state-of-the-art coding schemes in terms of the classification accuracy and computation speed.
C1 [Long, Xianzhong] Nanjing Univ Posts & Telecommun, Sch Software, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.
   [Lu, Hongtao; Peng, Yong; Wang, Xianzhong; Feng, Shaokun] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Key Lab Shanghai Educ Commiss Intelligent Interac, Shanghai 200240, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Shanghai Jiao Tong
   University
RP Long, XZ (corresponding author), Nanjing Univ Posts & Telecommun, Sch Software, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.
EM lxz@njupt.edu.cn; htlu@sjtu.edu.cn; pengyong851012@sjtu.edu.cn;
   wxz2453@sjtu.edu.cn; superkkking@sjtu.edu.cn
RI Peng, Yong/JCO-0601-2023; Feng, Shaokun/AHB-7025-2022
OI Peng, Yong/0000-0003-1208-972X; Feng, Shaokun/0000-0001-5841-1177
FU NUPTSF [NY214168]; National Natural Science Foundation of China
   [61300164, 61272247]; Shanghai Science and Technology Committee
   [13511500200]; European Union [247619]
FX This work is sponsored by NUPTSF (Grant No. NY214168), National Natural
   Science Foundation of China (Grant No. 61300164, 61272247), Shanghai
   Science and Technology Committee (Grant No. 13511500200) and European
   Union Seventh Framework Programme (Grant No. 247619).
CR [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], COMPUTATIONAL LEARNI
   [Anonymous], 2013, P 21 ACM INT C MULT, DOI 10.1145/2502081.2502171
   [Anonymous], 2009, P ADV NEUR INF PROC
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], IEEE C COMP VIS PATT
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Cinbis RG, 2012, PROC CVPR IEEE, P2184, DOI 10.1109/CVPR.2012.6247926
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Griffin Gregory, 2007, CALTECH 256 OBJECT C
   Harada T, 2011, PROC CVPR IEEE, P1617, DOI 10.1109/CVPR.2011.5995691
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Krapac J, 2011, IEEE I CONF COMP VIS, P1487, DOI 10.1109/ICCV.2011.6126406
   Kulkarni N, 2011, PROC CVPR IEEE, P1609, DOI 10.1109/CVPR.2011.5995701
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li Fei-Fei, 2007, INT C COMPUTER VISIO, P1
   Li Y., 2008, 4 INT C WIRELESS COM, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu ZW, 2009, PROC CVPR IEEE, P397, DOI 10.1109/CVPRW.2009.5206861
   Moosmann F., 2007, ADV NEURAL INFORM PR, V19
   Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Picard D, 2011, IEEE IMAGE PROC, P669, DOI 10.1109/ICIP.2011.6116641
   Quelhas P, 2005, IEEE I CONF COMP VIS, P883
   Rublee E., 2011, INT C COMP VIS, P24, DOI DOI 10.1109/ICCV.2011.6126544
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Xu D, 2008, IEEE T PATTERN ANAL, V30, P1985, DOI 10.1109/TPAMI.2008.129
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
NR 41
TC 11
Z9 13
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5533
EP 5555
DI 10.1007/s11042-015-2524-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600009
DA 2024-07-18
ER

PT J
AU Rabie, T
   Kamel, I
AF Rabie, Tamer
   Kamel, Ibrahim
TI On the embedding limits of the discrete cosine transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Space filling curves; Image watermarking; Steganography;
   Frequency-domain image embedding; Discrete cosine transform; Adaptive
   region DCT
ID STEGANOGRAPHIC METHOD; IMAGE; JPEG; WATERMARKING
AB This paper investigates the embedding capacity limits of high-capacity data hiding in color images based on a locally Adaptive-Region Discrete Cosine Transform (AR-DCT) frequency domain data hiding scheme, and explores the relationship between hiding capacity and image quality. It also compares the embedding capacities of various steganography schemes which have been recently published in the literature. Experimental results confirm that our proposed scheme successfully enhances hiding capacity while maintaining acceptable image quality and concludes that the capacity for our DCT hiding scheme can achieve extremely high bit rates of 20 bits-per-pixel, which is much higher than other DCT-based approaches, as well as other spatial and frequency domain schemes.
C1 [Rabie, Tamer; Kamel, Ibrahim] Univ Sharjah, Dept Elect & Comp Engn, Sharjah, U Arab Emirates.
C3 University of Sharjah
RP Rabie, T (corresponding author), Univ Sharjah, Dept Elect & Comp Engn, Sharjah, U Arab Emirates.
EM trabie@sharjah.ac.ae; kamel@sharjah.ac.ae
FU College of Graduate Studies and Research at the University of Sharjah
   [140440]
FX The authors would like to thank the anonymous reviewers for their
   valuable suggestions that helped improve the original manuscript. This
   work was funded by the College of Graduate Studies and Research at the
   University of Sharjah under project number 140440 for 2014.
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   [Anonymous], 2003, INT J DIG EVID
   [Anonymous], HIDE SEEK INTRO STEG
   Brisbane G, 2005, IEE P-VIS IMAGE SIGN, V152, P787, DOI 10.1049/ip-vis:20045047
   Castleman K. R., 1996, Digital Image Processing
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2002, INFORM SCIENCES, V141, P123, DOI 10.1016/S0020-0255(01)00194-3
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Chang CC, 2008, SOFT COMPUT, V13, P21
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chung KL, 2001, PATTERN RECOGN LETT, V22, P1051, DOI 10.1016/S0167-8655(01)00044-7
   IEC I, 1994, INF TECHN DIG COMPR, p[10, 918]
   Iwata M, 2004, IEICE T FUND ELECTR, VE87A, P929
   Jain A, 2002, P INT C PATT REC ICP
   Lee YK, 2000, IEE P-VIS IMAGE SIGN, V147, P288, DOI 10.1049/ip-vis:20000341
   Lin C.-C., 2010, J. Inf. Hiding Multimed. Signal Process, V1, P220
   Lin CH, 2009, PR ELECTROMAGN RES S, P327, DOI 10.1145/1516241.1516298
   Lin CY, 2008, IEICE T INF SYST, VE91D, P836, DOI 10.1093/ietisy/e91-d.3.836
   Marvel LM, 1999, IEEE T IMAGE PROCESS, V8, P1075, DOI 10.1109/83.777088
   Nozaki K., 1998, ACCV 98 P 3 AS C COM, VI, P112
   Pavildis G, 2003, SIGNAL PROCESS-IMAGE, V18, P497, DOI 10.1016/S0923-5965(03)00038-9
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Rabie T., 2007, International Journal of Advanced Media and Communication, V1, P298, DOI 10.1504/IJAMC.2007.013952
   Rabie T., 2012, 4 INT C NETW DIG TEC, P217, DOI DOI 10.1007/978-3-642-30567-2_18
   Rabie T, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P858, DOI 10.1109/CISP.2013.6745285
   Rao K.R, 2014, DISCRETE COSINE TRAN
   RODRIGUES J, 2004, 5 INT WORKSH IM AN M
   Solanki K, 2004, IEEE T IMAGE PROCESS, V13, P1627, DOI 10.1109/TIP.2004.837557
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   TSAI P., 2002, P PAC RIM WORKSH DIG, P54
   Wang X., 2005, IEEE INT C IMAGE PRO, V2, P1090
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P685, DOI 10.1109/TIP.2003.810588
   Yang B, 2004, PROC SPIE, V5306, P405, DOI 10.1117/12.527216
NR 37
TC 21
Z9 21
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5939
EP 5957
DI 10.1007/s11042-015-2557-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600027
DA 2024-07-18
ER

PT J
AU Ahn, J
   Wohn, K
AF Ahn, Jaehong
   Wohn, KwangYun
TI Interactive scan planning for heritage recording
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D scan; Terrestrial laser scanning; Scan planning; Scan position;
   Heritage recording
ID PHOTOGRAMMETRY; PROJECT
AB Terrestrial laser scanning has received attention as an efficient technology in the cultural heritage domain for recording the geometry of historic monuments quickly and precisely. It is important to find appropriate scanner configurations to make the scanning process efficient and to build reliable records. These configurations should satisfy required constraints such as full coverage, sufficient overlap, scan range limit, and laser incidence angle. This is called the view planning problem. We sought to develop a scan planning scheme for recording large monuments in the cultural heritage domain. Typical approaches to deal with the view planning problem, however, do not consider the specific requirements in this domain. In this paper, we propose an interactive scan planning approach that supports analytic computation as well as heuristic decision. It includes three supporting guides. A next scan grid supports semi-automated optimization in interactive planning, and scan geometry helps the user to intuitively decide the next best position in a feasible region. A knowledge guide, which is reasoned out by similar properties, provides the user with experts' heuristic solutions to aid practical planning. These guides support efficient scan planning in a complementary manner. We introduce the use of region of interest to obtain more accurate data for focused features. ScanPlanner is implemented on this basis. The result of tests showed that the proposed approach allows users to make efficient and reliable scan plans for heritage recording.
C1 [Ahn, Jaehong; Wohn, KwangYun] Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, 291 Daehak Ro, Taejon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Ahn, J (corresponding author), Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, 291 Daehak Ro, Taejon 305701, South Korea.
EM jaehong.ahn@gmail.com
RI Wohn, Kwangyun/C-2013-2011
FU NRF; BK21 Plus Framework
FX This research was partially supported by NRF and the BK21 Plus
   Framework.
CR Alshawabkeh Y, 2004, 3 INT C SCI TECHN AR, P7
   [Anonymous], 2007, INT ARCH PHOTOGRAMM
   [Anonymous], 2003, ACM COMPUTING SURVEY
   Balzani M., 2004, INT C REM SENS ARCH
   Banta J.E., 1995, P INT SOC OPT PHOT, P418
   Barber D., 2011, 3D Laser Scanning for Heritage (second edition)
   Barber D., 2003, CIPA INT ARCH DOCUME, V19, P619
   Bellian JA, 2005, J SEDIMENT RES, V75, P166, DOI 10.2110/jsr.2005.013
   Bernardini F, 2002, IEEE COMPUT GRAPH, V22, P59, DOI 10.1109/38.974519
   Blaer PS, 2008, THESIS COLUMBIA U NE
   Boehler W., 2003, INT ARCH PHOTOGRAMME, V34, P696, DOI DOI 10.1002/PBC.ABSTRACT
   Cabral Marcel, 2009, Proceedings of the 2009 IEEE Latin-American Conference on Communications (LATINCOM), DOI 10.1109/LATINCOM.2009.5304848
   Connolly C., 1985, PROC IEEE INT C ROBO, V2, P432
   COWAN CK, 1988, IEEE T PATTERN ANAL, V10, P407, DOI 10.1109/34.3905
   El-Hakim SF, 2004, IEEE COMPUT GRAPH, V24, P21, DOI 10.1109/MCG.2004.1297007
   Fujimoto K, 2008, ELECT IMAGING 2008
   GAIANI M., 2000, P EUR 2000 EUR ASS C, P369
   Grussenmeyer Pierre., 2008, 22 C INT SOC PHOTOGR, P213
   Guarnieri A., 2004, The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, V35, pB5
   Guidi G, 2009, INT J ARCHIT COMPUT, V7, P39, DOI 10.1260/147807709788549439
   Ikeuchi K, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P117, DOI 10.1109/IM.2001.924417
   Ikeuchi K, 2007, INT J COMPUT VISION, V75, P189, DOI 10.1007/s11263-007-0039-y
   Kersten T, 2008, INTEGRATING GENERATI
   Levoy M, 2000, COMP GRAPH, P131, DOI 10.1145/344779.344849
   Low K-L, 2006, THESIS U N CAROLINA
   Lerma JL, 2011, LASER SCANNING, THEORY AND APPLICATIONS, P413
   Massios N.A., 1998, BRIT MACH VIS C, P1
   MAVER J, 1993, IEEE T PATTERN ANAL, V15, P417, DOI 10.1109/34.211463
   Nagatani K, 2010, SPRINGER TRAC ADV RO, V62, P207
   Pito R, 1999, IEEE T PATTERN ANAL, V21, P1016, DOI 10.1109/34.799908
   Reed MK, 2000, IEEE T PATTERN ANAL, V22, P1460, DOI 10.1109/34.895979
   Remondino F, 2011, REMOTE SENS-BASEL, V3, P1104, DOI 10.3390/rs3061104
   Scott WR, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P127, DOI 10.1109/IM.2001.924419
   Sequeira V, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P776, DOI 10.1109/TDPVT.2002.1024159
   Soucy G, 1998, 1998 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - PROCEEDINGS, VOLS 1-3, P1682, DOI 10.1109/IROS.1998.724840
   Soudarissanane S., 2011, INT ARCH PHOT REM SE, P29
   Soudarissanane S., 2007, 3D NORDOST, P1, DOI [10.13140/RG.2.1.1877.6404, DOI 10.13140/RG.2.1.1877.6404]
   Soudarissanane S, 2011, ISPRS J PHOTOGRAMM, V66, P389, DOI 10.1016/j.isprsjprs.2011.01.005
   TARABANIS KA, 1995, IEEE T ROBOTIC AUTOM, V11, P86, DOI 10.1109/70.345940
   TARBOX GH, 1995, COMPUT VIS IMAGE UND, V61, P84, DOI 10.1006/cviu.1995.1007
   Voegtle T., 2009, P ISPRS WORK, V38, P68
   Yastikli N, 2007, J CULT HERIT, V8, P423, DOI 10.1016/j.culher.2007.06.003
NR 42
TC 34
Z9 35
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 3655
EP 3675
DI 10.1007/s11042-015-2473-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200005
DA 2024-07-18
ER

PT J
AU Chen, YW
   Lai, DH
   Qi, H
   Wang, JL
   Du, JX
AF Chen, Ye-Wang
   Lai, De-He
   Qi, Han
   Wang, Jiong-Liang
   Du, Ji-Xiang
TI A new method to estimate ages of facial image for large database
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Age estimation; TFIDF; AAM; Density peak; Local Binary Pattern (LBP)
ID CLASSIFICATION
AB As a common consensus that the appearances of different persons with the same age diverge widely, we have an opinion that the estimated result of a facial image should be a dynamic range or discrete candidate ages, not a specific one or classified into predefined age groups. Therefore, this paper presents a new method to estimate a set of possible ages of a facial image for large image database with a novel measurement. Firstly by transferring the shape and appearance features of a face into a set of Landmark-Terms, then the famous technology TFIDF in information retrieval and text mining fields is introduced to build a weight matrix of these Landmark-Terms for all age groups, and then some possible ages of a facial image are estimated by this matrix. Secondly, a new clustering method is also used to find the density peaks for each age group by processing the LBP features, then according to the distances of the facial image to the peaks, we obtain another possible estimated ages. Thirdly, we find the first density peak among the two sets of possible ages mentioned above, then choose those ages whose distances to the peak age are short enough in the two set as final estimated ages. Finally, a novel measurement is proposed to evaluate the performance for methods that provide more than one possible estimated ages. The experiments show that our method is promising, the best MAE and CS are close to the best performance of state-of-the-art, and the best BPMAE and NBPMAE also indicate the top possible ages could cover the neighborhood of the the ground-truth age with small errors, in other words, it narrows the age scope effectively.
C1 [Chen, Ye-Wang; Lai, De-He; Qi, Han; Wang, Jiong-Liang; Du, Ji-Xiang] Huaqiao Univ, Coll Comp Sci & Technol, Xiamen, Peoples R China.
C3 Huaqiao University
RP Chen, YW; Du, JX (corresponding author), Huaqiao Univ, Coll Comp Sci & Technol, Xiamen, Peoples R China.
EM ywchen@hqu.edu.cn; jxdu@hqu.edu.cn
RI Chen, Yewang/AAN-6803-2020
OI Chen, Yewang/0000-0001-9691-0807
FU National Science Foundation of China [61175121]; National Science
   Foundation of Fujian Province [2013J06014]; Promotion Program for Young
   and Middle-aged Teacher in Science and Technology Research of Huaqiao
   University [ZQNYX108]; Fundamental Research Funds for the Central
   Universities [JBZR1217]
FX Supported by the Grant of the National Science Foundation of China (No.
   61175121); the Grant of the National Science Foundation of Fujian
   Province (No. 2013J06014); the Promotion Program for Young and
   Middle-aged Teacher in Science and Technology Research of Huaqiao
   University(No. ZQNYX108); the Fundamental Research Funds for the Central
   Universities(No. JBZR1217).
CR [Anonymous], 2009, 2009 IEEE 3 INT C BI, DOI DOI 10.1109/BTAS.2009.5339053
   [Anonymous], P 8 IEEE INT C AUT F
   [Anonymous], 2007, P IEEE 11 INT C COMP
   [Anonymous], 2005, P 12 INT C NEUR INF
   [Anonymous], 2006, P 14 ANN ACM INT C M
   [Anonymous], 2001, J Appl Sci Eng, DOI DOI 10.6180/JASE.2001.4.3.05
   Chen YL, 2013, IEEE T INF FOREN SEC, V8, P2164, DOI 10.1109/TIFS.2013.2286265
   Choi SE, 2011, PATTERN RECOGN, V44, P1262, DOI 10.1016/j.patcog.2010.12.005
   Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847
   Fukai Hironobu, 2007, 2007 International Conference on Control, Automation and Systems - ICCAS '07, P2146
   Gao F, 2009, LECT NOTES COMPUT SC, V5558, P132
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   Kwon YH, 1999, COMPUT VIS IMAGE UND, V74, P1, DOI 10.1006/cviu.1997.0549
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Liu KH, 2014, IEEE WINT CONF APPL, P445, DOI 10.1109/WACV.2014.6836068
   Lu JW, 2013, IEEE T HUM-MACH SYST, V43, P249, DOI 10.1109/TSMCC.2012.2192727
   Ojala T., 2001, Advances in Pattern Recognition - ICAPR 2001. Second International Conference. Proceedings (Lecture Notes in Computer Science Vol.2013), P397
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   Wang XL, 2013, 2013 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2013), VOL 2, P309, DOI 10.1109/ICMLA.2013.141
NR 23
TC 33
Z9 41
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2877
EP 2895
DI 10.1007/s11042-015-2485-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000029
DA 2024-07-18
ER

PT J
AU Lu, GL
   Zhou, YQ
   Li, XY
   Kudo, M
AF Lu, Guoliang
   Zhou, Yiqi
   Li, Xueyong
   Kudo, Mineichi
TI Efficient action recognition via local position offset of 3D skeletal
   body joints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Skeletal body joints; RGB-D data; Bag-of-words
ID SELECTION; SPACE
AB To accurately recognize human actions in less computational time is one important aspect for practical usage. This paper presents an efficient framework for recognizing actions by a RGB-D camera. The novel action patterns in the framework are extracted via computing position offset of 3D skeletal body joints locally in the temporal extent of video. Action recognition is then performed by assembling these offset vectors using a bag-of-words framework and also by considering the spatial independence of body joints. We conducted extensive experiments on two benchmarking datasets: UCF dataset and MSRC-12 dataset, to demonstrate the effectiveness of the proposed framework. Experimental results suggest that the proposed framework 1) is very fast to extract action patterns and very simple in implementation; and 2) can achieve a comparable or a better performance in recognition accuracy compared with the state-of-the-art approaches.
C1 [Lu, Guoliang; Zhou, Yiqi; Li, Xueyong] Shandong Univ, Sch Mech Engn, Jinan 250100, Peoples R China.
   [Lu, Guoliang; Zhou, Yiqi; Li, Xueyong] Shandong Univ, Key Lab High Efficiency & Clean Mech Mfg MOE, Jinan 250100, Peoples R China.
   [Kudo, Mineichi] Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido, Japan.
C3 Shandong University; Shandong University; Hokkaido University
RP Lu, GL (corresponding author), Shandong Univ, Sch Mech Engn, Jinan 250100, Peoples R China.
EM luguoliang@sdu.edu.cn; yqzhou@sdu.edu.cn; lxy88@sdu.edu.cn;
   mine@main.ist.hokudai.ac.jp
RI Kudo, Mineichi/AAE-8899-2021
OI Kudo, Mineichi/0000-0003-1013-3870
FU National Natural Science Foundation of China [61403232]; Natural Science
   Foundation of Shandong Province, China [ZR2014FQ025]; Fundamental
   Research Funds of Shandong University [2014TB004]; Grants-in-Aid for
   Scientific Research [15H02719] Funding Source: KAKEN
FX This work is financially supported by National Natural Science
   Foundation of China (61403232), Natural Science Foundation of Shandong
   Province, China (ZR2014FQ025) and Fundamental Research Funds of Shandong
   University (2014TB004).
CR Chaaraoui AA, 2014, EXPERT SYST APPL, V41, P786, DOI 10.1016/j.eswa.2013.08.009
   [Anonymous], 2008, P 2008 IEEE C COMPUT, DOI DOI 10.1109/CVPR.2008.4587735
   [Anonymous], THESIS U STUDI NAPOL
   [Anonymous], IEEE I CONF COMP VIS
   [Anonymous], IEEE INT C MULT EXP, DOI DOI 10.1109/ICME.2012.8
   [Anonymous], KINECT GESTURE RECOG
   Beh J, 2014, PATTERN RECOGN LETT, V36, P144, DOI 10.1016/j.patrec.2013.10.007
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   Fothergill S., 2012, P SIGCHI C HUM FACT, P1737, DOI DOI 10.1145/2207676.2208303
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Kobayashi T, 2012, PATTERN RECOGN LETT, V33, P1188, DOI 10.1016/j.patrec.2012.01.007
   Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881
   Liu L., 2013, 23 INT JOINT C ART I
   Liu T, 2012, MULTIDIM SYST SIGN P, V23, P451, DOI 10.1007/s11045-011-0161-4
   Lu GL, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P96, DOI 10.1109/CISP.2013.6744073
   Lu GL, 2014, NEUROCOMPUTING, V123, P328, DOI 10.1016/j.neucom.2013.06.042
   Lu GL, 2013, PATTERN RECOGN LETT, V34, P1936, DOI 10.1016/j.patrec.2012.10.023
   Lu GL, 2013, IEICE T INF SYST, VE96D, P1238, DOI 10.1587/transinf.E96.D.1238
   Lu GL, 2012, IEICE T INF SYST, VE95D, P2514, DOI 10.1587/transinf.E95.D.2514
   Masood S. Z., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P422, DOI 10.1109/ICCVW.2011.6130272
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Rabie Ahmad, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P346, DOI 10.1007/978-3-642-23123-0_35
   Slama R, 2015, PATTERN RECOGN, V48, P556, DOI 10.1016/j.patcog.2014.08.011
   Song Y, 2013, IEEE INT CONF AUTOMA
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Weinland D, 2010, LECT NOTES COMPUT SC, V6313, P635
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Zhu YD, 2010, COMPUT VIS IMAGE UND, V114, P1362, DOI 10.1016/j.cviu.2009.11.005
NR 34
TC 22
Z9 24
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3479
EP 3494
DI 10.1007/s11042-015-2448-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600026
DA 2024-07-18
ER

PT J
AU Shao, X
   Gui, WM
   Xu, CS
AF Shao, Xi
   Gui, Wenming
   Xu, Changsheng
TI Note onset detection based on sparse decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Note onset detection; Sparse decomposition; Matching pursuit
ID SIGNALS; MUSIC
AB Music onset detection is significant and essential for obtaining the high-level music features such as rhythm, beat, music paragraph and structure. The traditional methods for onset detection which employ Short Time Fourier Transform (STFT)-based or Wavelet Transform (WT)-based features to characterize music signal generally lack adaptiveness for representing the stationary and non-stationary part of the music signal. This will lead to the degraded performance for music note onset detection. To solve this problem, a new algorithm for note onset detection based on sparse decomposition is proposed. Firstly, the musical signals are sparsely decomposed with Matching Pursuit (MP), and then the hybrid detection algorithm which combines namely the Degree of Explanation (DE) and the Change of Partials (CP) is applied to the sparse representation of the music signal. Finally, a modified peak-picking algorithm is employed to generate onset vectors. The experiments on the dataset with 2050 onsets show that our results are superior to those of MIREX 2013. For the polyphonic music which is the most widely used form in our real life, the proposed algorithm has better performance than the other algorithms.
C1 [Shao, Xi] Nanjing Univ Posts & Telecommun, Coll Commun & Informat Engn, 172,66 Xinmofan Rd, Nanjing 210003, Jiangsu, Peoples R China.
   [Gui, Wenming] Jinling Inst Technol, Nanjing 210003, Jiangsu, Peoples R China.
   [Xu, Changsheng] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Jinling Institute of
   Technology; Chinese Academy of Sciences; Institute of Automation, CAS
RP Shao, X (corresponding author), Nanjing Univ Posts & Telecommun, Coll Commun & Informat Engn, 172,66 Xinmofan Rd, Nanjing 210003, Jiangsu, Peoples R China.
EM shaoxi@njupt.edu.cn; guiwenming@gmail.com; csxu@nlpr.ia.ac.cn
RI xu, cj/HJZ-3488-2023; shao, xi/ABE-3263-2021
FU National Nature Science Foundation of China [60902065, 61401227];
   Beijing Natural Science Foundation [4152053]
FX This work is supported by the National Nature Science Foundation of
   China under Grant No. 60902065, No. 61401227, and by Beijing Natural
   Science Foundation(No. 4152053).
CR Bao BK, 2013, IEEE T IMAGE PROCESS, V22, P860, DOI 10.1109/TIP.2012.2219543
   Bello JP, 2005, IEEE T SPEECH AUDI P, V13, P1035, DOI 10.1109/TSA.2005.851998
   Bello JP, 2003, P 28 IEEE INT C AC S
   Benetos E, 2011, P 36 IEEE INT C AC S
   Benetos E, 2010, IEEE T AUDIO SPEECH, V18, P1968, DOI 10.1109/TASL.2010.2040785
   Daudet L, 2001, P COMP MUS C ICMC 01
   Daudet L, 2006, IEEE T AUDIO SPEECH, V14, P1808, DOI 10.1109/TSA.2005.858540
   Davy M., 2002, P IEEE INT C AC SPEE
   Duxbury C, P DIG AUD EFF C DAFX
   Fusan Z, 2005, BASIC MUSIC THEORY T
   Goto M, 2001, J NEW MUSIC RES, V30, P159, DOI 10.1076/jnmr.30.2.159.7114
   Gribonval R, 2003, IEEE T SIGNAL PROCES, V51, P101, DOI 10.1109/TSP.2002.806592
   Holzapfel A, 2010, IEEE T AUDIO SPEECH, V18, P1517, DOI 10.1109/TASL.2009.2036298
   Hoon H., 2013, P 2013 IEEE INT C MU, P1
   Hui LT, 2010, P 2010 IE INT S CIRC
   Jaggi S, 1998, APPL COMPUT HARMON A, V5, P428, DOI 10.1006/acha.1997.0239
   Jia-Yin S, 2009, J TSINGHUA U SCI TEC, V49, p[1369, 1379]
   KRSTULOVIC S, 2006, P IEEE INT C AC SPEE
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Masri P., 1996, Computer modeling of sound for transformation and synthesis of musical signals
   Pertusa A, 2010, THESIS U ALICANTE
   Ravelli E, 2008, IEEE T AUDIO SPEECH, V16, P1361, DOI 10.1109/TASL.2008.2004290
   Rodet X, 2001, P COMP MUS HAV CUB
   Wenming G., 2011, COMPUTER ENG APPL, V47, P9
   Xiangbin S, 2010, P INT C INT TECHN AP
   Yanan F, 2011, P 7 INT C NAT COMP I
NR 26
TC 7
Z9 9
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2613
EP 2631
DI 10.1007/s11042-015-2656-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000013
DA 2024-07-18
ER

PT J
AU Chen, JR
   Xiang, SJ
   Huang, HB
   Liu, WP
AF Chen, Jiaorong
   Xiang, Shijun
   Huang, Hongbin
   Liu, Weiping
TI Detecting and locating digital audio forgeries based on singularity
   analysis with wavelet packet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital audio forensics; Audio forgeries; Wavelet singularity analysis
ID IDENTIFICATION
AB Audio watermarking and signature are widely used for authentication. However, these techniques will become powerless in many actual situations because of their requirement of additional information. Audio forensic techniques are necessary for digital audio. In this paper, we propose an audio forensics scheme to detect and locate speech audio forged operations in time domain (including deletion, insertion, substitution and splicing) by performing discrete wavelet packet decomposition and analyzing singularity points of audio signals. We first analyze the forged operations and find that the audio signals will often generate new singular points because of the decrease or breaking of the correlation property of those samples close to the tampering position. Then we utilize the singularity analysis based on wavelet packet and design five parameters (which is different for the sample rate of digital audio file) to propose an approach which can detect and locate audio forgeries in time domain. Finally, extensive experimental results have demonstrated that the proposed method can better achieve the goals that identify whether a given speech file has been tampered (e.g., part of the content deleted or replaced) previously and further locate the forged positions in time domain.
C1 [Chen, Jiaorong; Xiang, Shijun; Huang, Hongbin; Liu, Weiping] Jinan Univ, Sch Informat Sci & Technol, Guangzhou 510632, Guangdong, Peoples R China.
C3 Jinan University
RP Liu, WP (corresponding author), Jinan Univ, Sch Informat Sci & Technol, Guangzhou 510632, Guangdong, Peoples R China.
EM wpl@jnu.edu.cn
FU NSFC [61272414]; University-Industry-Science Partnership Project of
   Guangdong Province; National Education Ministry [2012B091000155]
FX This work was supported in part by NSFC (No.61272414), and in part by
   The University-Industry-Science Partnership Project of Guangdong
   Province and National Education Ministry (2012B091000155).
CR [Anonymous], 1999, AIM1657 MIT
   [Anonymous], 2013, P 21 SIGN PROC COMM
   Buchholz R, 2009, LECT NOTES COMPUT SC, V5806, P235, DOI 10.1007/978-3-642-04431-1_17
   Chen G, 2012, P CIHW BEIJ CHIN, P164
   Chen Jiajia, 2013, Biomed Res Int, V2013, P658925, DOI 10.1155/2013/658925
   Ding Qi, 2010, Journal of Applied Sciences, V28, P142
   Fu L, 2013, IEEE T INF FOREN SEC, V8, P1173, DOI 10.1109/TIFS.2013.2265088
   Grigoras C, 2005, INT J SPEECH LANG LA, V12, P63, DOI 10.1558/sll.2005.12.1.63
   Gupta S, 2012, IEEE MULTIMEDIA, V19, P50, DOI 10.1109/MMUL.2011.74
   Hanilci C, 2013, P 1 ACM WORKSHOP INF, P141, DOI DOI 10.1145/2482513.2482520
   Ikram S, 2010, IEEE INT CON MULTI, P106, DOI 10.1109/ICME.2010.5582981
   Kotropoulos C, 2013, P INT WORKSH BIOM FO, P1
   Kraetzer C, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P63
   Liu QZ, 2010, COGN COMPUT, V2, P291, DOI 10.1007/s12559-010-9045-4
   Luo D, 2012, INT CONF ACOUST SPEE, P1733, DOI 10.1109/ICASSP.2012.6288233
   Malik H, 2012, INT CONF ACOUST SPEE, P1833, DOI 10.1109/ICASSP.2012.6288258
   Malik H, 2010, INT CONF ACOUST SPEE, P1710, DOI 10.1109/ICASSP.2010.5495479
   MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909
   MALLAT S, 1992, IEEE T INFORM THEORY, V38, P617, DOI 10.1109/18.119727
   MALLAT S, 1991, IEEE T INFORM THEORY, V37, P1019, DOI 10.1109/18.86995
   Nicolalde DP, 2009, INT CONF ACOUST SPEE, P1417, DOI 10.1109/ICASSP.2009.4959859
   Rodríguez DPN, 2010, IEEE T INF FOREN SEC, V5, P534, DOI 10.1109/TIFS.2010.2051270
   Pan XY, 2012, INT CONF ACOUST SPEE, P1841, DOI 10.1109/ICASSP.2012.6288260
   Qiao M., 2010, P P 18 ACM INT C MUL, P1011
   Shao Song-nian, 2009, Computer Engineering, V35, P224
   Shi Q, 2011, DETECTION AUDIO INTE, P287
   Yang R, 2010, ACM T MULTIM COMPUT, V8, P1
   Yang R, 2010, P SPIE, V7541
   Yang R, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P117
   Yang R, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P21, DOI 10.1145/1411328.1411334
   Yao Qiu-ming, 2006, Journal of Computer Applications, V26, P2598
   Zhao H, 2012, 2012 IEEE STATISTICAL SIGNAL PROCESSING WORKSHOP (SSP), P373, DOI 10.1109/SSP.2012.6319707
NR 32
TC 22
Z9 26
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 2303
EP 2325
DI 10.1007/s11042-014-2406-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000026
DA 2024-07-18
ER

PT J
AU Kalpana, J
   Krishnamoorthi, R
AF Kalpana, J.
   Krishnamoorthi, R.
TI Color image retrieval technique with local features based on orthogonal
   polynomials model and SIFT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based image retrieval (CBIR); Dimensionality reduction;
   Orthogonal polynomials; SIFT keypoint descriptors
ID DCT; CLASSIFICATION
AB In this paper, a new color image retrieval technique is proposed with local features given by Scale Invariant Feature Transform (SIFT) key points that are described in the integer-natured, computationally light Orthogonal Polynomials Transform (OPT) domain. The transform's point spread operators are derived from a generating function, modification to which has been proposed for alleviating computational complexity further. The expressive power of the transform coefficients has been exploited for forming the descriptors of SIFT key points of a given image. The key point descriptors, OPT-SIFT so formed have good expressive power, despite being shorter in length and having a reduced computational complexity. A retrieval technique has been proposed based on OPT-SIFT features. The proposed retrieval technique has been experimented with images from standard databases such COIL-100 and Corel and the results demonstrate the superiority of the proposed descriptors when compared to other descriptors.
C1 [Kalpana, J.; Krishnamoorthi, R.] Anna Univ Technol, Dept CSE, Image Vis Lab, Tiruchirappalli 620024, India.
C3 Anna University; Anna University of Technology Tiruchirappalli
RP Kalpana, J (corresponding author), Anna Univ Technol, Dept CSE, Image Vis Lab, Tiruchirappalli 620024, India.
EM kalpanalak@gmail.com
OI Ramasamy, Krishnamoorthy/0000-0003-1823-5855
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Andrews H.C., 1968, Proc. Hawaii Int.Conf. System Sciences, P677
   Bae HJ, 1997, P INT C INF COMM SEC, V2, P065
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Chang HS, 2005, IEEE T IMAGE PROCESS, V14, P145, DOI 10.1109/TIP.2004.840706
   Cheriyadat A, 2003, INT GEOSCI REMOTE SE, P3420
   Chui C. K., 1992, An Introduction to Wavelets, DOI 10.2307/2153134
   Cosmin A, 2007, P 5 INT S IM SIGN PR, P130
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Gao H., 2010, P IEEE GLOB TEL C GL, P1
   Hakim AE, 2006, P IEEE COMP SOC C CO, P1978
   Huang YL, 1999, INT CONF ACOUST SPEE, P3013, DOI 10.1109/ICASSP.1999.757475
   Jiang JM, 2008, IEEE T CIRC SYST VID, V18, P994, DOI 10.1109/TCSVT.2008.924106
   Jones GT, 2001, COMPUT GRAPH-UK, V25, P671, DOI 10.1016/S0097-8493(01)00095-4
   Ke Y, 2004, PROC CVPR IEEE, P506
   KIM DS, 1991, IEEE T COMMUN, V39, P549, DOI 10.1109/26.81743
   Kim HC, 2001, IEEE IJCNN, P430, DOI 10.1109/IJCNN.2001.939058
   Krishnamoorthi R, 2007, PATTERN RECOGN LETT, V28, P771, DOI 10.1016/j.patrec.2006.10.009
   Krishnamoorthi R, 2009, IMAGE VISION COMPUT, V27, P999, DOI 10.1016/j.imavis.2008.08.006
   Krishnamoorthy R, 1997, THESIS
   Lay JA, 1999, INT CONF ACOUST SPEE, P3009, DOI 10.1109/ICASSP.1999.757474
   LEE MH, 1994, IEE P-VIS IMAGE SIGN, V141, P39, DOI 10.1049/ip-vis:19949722
   Li HL, 2002, IEEE IMAGE PROC, P940
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu ZM, 2006, INT J INNOV COMPUT I, V2, P831
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   MARTUCCI SA, 1994, IEEE T SIGNAL PROCES, V42, P1038, DOI 10.1109/78.295213
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Poursistani P, 2013, MATH COMPUT MODEL, V57, P1005, DOI 10.1016/j.mcm.2011.11.064
   PRATT WK, 1969, P IEEE, V57, P58, DOI 10.1109/PROC.1969.6869
   Shen B, 1996, P SOC PHOTO-OPT INS, V2670, P404, DOI 10.1117/12.234779
   Sim DG, 2001, ELECTRON LETT, V37, P18, DOI 10.1049/el:20010035
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
NR 33
TC 7
Z9 7
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 49
EP 69
DI 10.1007/s11042-014-2262-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500003
DA 2024-07-18
ER

PT J
AU Li, YB
   Merialdo, B
AF Li, Yingbo
   Merialdo, Bernard
TI Multimedia maximal marginal relevance for multi-video summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-video summarization; Video summaries; MMR; Video-MMR; AV-MMR;
   Balanced AV-MMR
ID CAPACITY LIMITS; VISUALIZATION; SEGMENTATION
AB In this paper we propose several novel algorithms for multi-video summarization. The first and essential algorithm, Video Maximal Marginal Relevance (Video-MMR), mimics the principle of a classical algorithm of text summarization, Maximal Marginal Relevance (MMR). Video-MMR rewards relevant keyframes and penalizes redundant keyframes, only relying on visual features. We extend Video-MMR to Audio Video Maximal Marginal Relevance (AV-MMR) by exploiting audio features. We also propose Balanced AV-MMR, which exploits additional semantic features, the balance between audio information and visual information, and the balance of temporal information in different videos of a set. The proposed algorithms are generic and suitable for summarizing various video genres in multi-video set by using multimodal information. Our series of MMR algorithms for multi-video summarization are proved to be effective by the large-scale subjective and objective evaluation.
C1 [Li, Yingbo] EURECOM, Sophia Antipolis, France.
   [Merialdo, Bernard] EURECOM, Multimedia Dept, Sophia Antipolis, France.
C3 IMT - Institut Mines-Telecom; EURECOM; IMT - Institut Mines-Telecom;
   EURECOM
RP Li, YB (corresponding author), EURECOM, Sophia Antipolis, France.
EM yingbo.li@eurecom.fr; bernard.merialdo@eurecom.fr
CR Ajmal M, 2012, LECT NOTES COMPUT SC, V7594, P1, DOI 10.1007/978-3-642-33564-8_1
   Allen MJ, 2008, FORENSIC VISION WITH
   [Anonymous], SIGNAL PROCESSING IM
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], 2002, P 10 ACM INT C MULT
   [Anonymous], P 2011 JOINT ACM WOR
   Barbieri M, 2003, P SPIE
   Carbonell J, 1998, P ACM SIGIR C MELB A
   Chiu P, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1329, DOI 10.1109/ICME.2000.871011
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   Dale K, 2012, IEEE COMPUTER SOCIET, P1
   Das D, 2007, TECHICAL REPORT
   Delacourt P, 2000, SPEECH COMMUN, V32, P111, DOI 10.1016/S0167-6393(00)00027-3
   Dimitrova N, 2004, IEEE MULTIMEDIA, V11, P7, DOI 10.1109/MMUL.2004.6
   Ding D., 2012, P 2 ACM INT C MULT R, P2
   Dreyfus H., 1987, IEEE Expert, V2, P110, DOI [DOI 10.1109/MEX.1987.4307079, 10.1109/MEX.1987.4307079]
   Dumont E, 2008, PROCEEDINGS OF INTER, P451
   Ejaz N, 2012, J VIS COMMUN IMAGE R, V23, P1031, DOI 10.1016/j.jvcir.2012.06.013
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Fraternali P., 2012, SIGMOD
   Furini M, 2006, CONSUMER COMMUNICATI
   Gao SH, 2010, LECT NOTES COMPUT SC, V6314, P1
   Haroz S, 2012, IEEE T VIS COMPUT GR, V18, P2402, DOI 10.1109/TVCG.2012.233
   He LW, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P489, DOI 10.1145/319463.319691
   Jianguo Wang, 2011, Proceedings of the 2011 2nd International Conference on Control, Instrumentation, and Automation (ICCIA), P1, DOI 10.1109/ICCIAutom.2011.6183890
   Kemp T, 2000, INT CONF ACOUST SPEE, P1423, DOI 10.1109/ICASSP.2000.861862
   Kumar M., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2437, DOI 10.1109/ICIP.2011.6116136
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li Y., 2011, P 19 ACM INT C MULT, P1573
   Li Y., 2010, P 11 INT WORKSH IM A, P1
   Li Y, 2012, P 18 INT C MULT MOD
   Lienhart R., 1997, Communications of ACM, V40, P55
   Lin CY, 2004, P WORKSH TEXT SUMM B, P2004
   Lin K. H., 2011, INTELLIGENT SIGNAL P, P1, DOI DOI 10.1109/INEC.2011.5991718
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Mahmoud KM, 2013, LECT NOTES COMPUT SC, V8156, P733
   Marois R, 2005, TRENDS COGN SCI, V9, P296, DOI 10.1016/j.tics.2005.04.010
   McDonald R, 2007, LECT NOTES COMPUT SC, V4425, P557
   Mckeown K, 1998, P ACM SIGIR C MELB A
   Money AG, 2007, J VIS COMMUN IMAGE R
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Nilsson M, 2007, P IEEE INT C AC SPEE
   Over P, 2007, P ACM MM 07 AUGSB BA
   Peng WT, 2011, IEEE T MULTIMEDIA, V13, P539, DOI 10.1109/TMM.2011.2131638
   Rudinac S, 2013, LEARNING CROWDSOURCE
   Shapiro K., 2001, The limits of attention: Temporal constraints in human information processing, DOI [10.1093/acprof:oso/9780198505150.001.0001, DOI 10.1093/ACPROF:OSO/9780198505150.001.0001, 10.1093/acprof:oso/9780198505150.001.0001/acprof-9780198505150]
   Sugano M, 2002, P INT C IM PROC NEW
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Wactlar HD, 2001, P 12 NEW INF TECHN C
   Wang F, 2009, P INT C MULT EXP NEW
   Xu C, 2005, ACM SIGIR
   Xu C, 2013, ARXIV PREPRINT ARXIV
   Yahiaoui Itheri., 2001, Automatic video summarization
   Yang CC, 2003, DECIS SUPPORT SYST, V35, P89, DOI 10.1016/S0167-9236(02)00101-X
NR 56
TC 11
Z9 11
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 199
EP 220
DI 10.1007/s11042-014-2287-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500011
DA 2024-07-18
ER

PT J
AU Cui, JR
   Wen, JJ
   Fan, ZZ
AF Cui, Jinrong
   Wen, Jiajun
   Fan, Zizhu
TI Appearance-based bidirectional representation for palmprint recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pattern recognition; Palmprint recognition; Representation-based method
ID LOCALITY PRESERVING PROJECTIONS; FACE; LINE
AB The palmprint recognition methods can be categorized as the feature-based methods and the appearance-based methods. The conventional appearance-based representation methods merely express the test sample as a weighting sum of training samples and exploit the deviation between the test sample and the weighting sum of the training samples from each class for classification. In this paper we exploited an appearance-based palmprint recognition method called bidirectional representation method based pattern classification (BRBPC) on palmprint recognition. The BRBPC algorithm not only used the training samples to express the test sample, but also take into account the expression of the test sample to the training sample. Experiments on PolyU multi-spectral palmprint database and 2D and 3D palmprint database show that the proposed method outperforms the conventional appearance-based palmprint recognition methods.
C1 [Cui, Jinrong; Wen, Jiajun] Harbin Inst Technol, Shenzhen Grad Sch, Biocomp Res Ctr, Shenzhen, Peoples R China.
   [Cui, Jinrong; Wen, Jiajun] Key Lab Network Oriented Intelligent Computat, Shenzhen, Peoples R China.
   [Fan, Zizhu] East China Jiaotong Univ, Sch Basic Sci, Nanchang, Peoples R China.
C3 Harbin Institute of Technology; East China Jiaotong University
RP Cui, JR (corresponding author), Harbin Inst Technol, Shenzhen Grad Sch, Biocomp Res Ctr, Shenzhen, Peoples R China.
EM tweety1028@163.com
RI Cui, Jinrong/JYQ-3168-2024
CR Cook T, 2010, PATTERN RECOGN, V43, P630, DOI 10.1016/j.patcog.2009.08.012
   Cui J., 2012, NEURAL COMPUT APPL, P1
   Gan J, 2006, SIGN PROC 2006 8 INT, P3
   Hu DW, 2007, PATTERN RECOGN, V40, P339, DOI 10.1016/j.patcog.2006.06.022
   Huang DS, 2008, PATTERN RECOGN, V41, P1316, DOI 10.1016/j.patcog.2007.08.016
   Jia W, 2008, PATTERN RECOGN, V41, P1504, DOI 10.1016/j.patcog.2007.10.011
   Kong A, 2006, PATTERN RECOGN, V39, P478, DOI 10.1016/j.patcog.2005.08.014
   Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184
   Kong WK, 2003, PATTERN RECOGN, V36, P2339, DOI 10.1016/S0031-3203(03)00121-3
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007
   Li W, 2011, IEEE T SYST MAN CY C, V41, P274, DOI 10.1109/TSMCC.2010.2055849
   Lu GM, 2003, PATTERN RECOGN LETT, V24, P1463, DOI 10.1016/S0167-8655(02)00386-0
   Lu JW, 2011, NEUROCOMPUTING, V74, P3760, DOI 10.1016/j.neucom.2011.06.024
   Lu JW, 2009, INT CONF ACOUST SPEE, P1753, DOI 10.1109/ICASSP.2009.4959943
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Sang HF, 2009, LECT NOTES COMPUT SC, V5552, P831, DOI 10.1007/978-3-642-01510-6_93
   Wang XJ, 2006, INT C PATT RECOG, P503
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu XQ, 2003, PATTERN RECOGN LETT, V24, P2829, DOI 10.1016/S0167-8655(03)00141-7
   Xu Y, 2004, PATTERN RECOGN, V37, P381, DOI 10.1016/S0031-3203(03)00232-2
   Xu Y, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.1.017205
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Xu Y, 2011, OPT ENG, V50, DOI 10.1117/1.3554740
   Xu Y, 2010, PATTERN RECOGN, V43, P1106, DOI 10.1016/j.patcog.2009.09.013
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yu P, 2010, J GUANGDONG U TECHNO, V1
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang DP, 1999, PATTERN RECOGN, V32, P691, DOI 10.1016/S0031-3203(98)00117-4
   Zhang L, 2004, IEEE T SYST MAN CY B, V34, P1335, DOI 10.1109/TSMCB.2004.824521
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zuo WM, 2010, PROC CVPR IEEE, P2265, DOI 10.1109/CVPR.2010.5539909
NR 33
TC 23
Z9 23
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 10989
EP 11001
DI 10.1007/s11042-014-1887-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600001
DA 2024-07-18
ER

PT J
AU Long, Y
   He, DJ
   Song, HB
AF Long, Yan
   He, DongJian
   Song, Huaibo
TI Bottom-up saliency estimation using sparse representation and structural
   redundancy reduction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency estimation; Non-local means; Sparse representation; Redundancy
   reduction
ID VISUAL-ATTENTION; MODEL
AB As we all know that image saliency estimation is an important technique in many computer vision applications. We study bottom-up saliency estimation method based on sparse representation and structural redundancy reduction. Firstly, we learn a set of basis functions using independent component analysis on a large set of natural images and obtain image sparse coefficients. Secondly, we compute the Shannon entropy of the image sparse coefficients to represent its pixels information which build up the image information map. Finally, we discard the structural redundancy of the information map to yield the image saliency map. The performance of the proposed model is studied on natural scenes and psychophysical patterns, and evaluated with ground-truth data. The evaluation proves that the proposed model is highly consistent with the subjective visual attention.
C1 [Long, Yan; He, DongJian; Song, Huaibo] Northwest A&F Univ, Coll Mech & Elect Engn, Yangling 712100, Shaanxi, Peoples R China.
C3 Northwest A&F University - China
RP He, DJ (corresponding author), Northwest A&F Univ, Coll Mech & Elect Engn, Yangling 712100, Shaanxi, Peoples R China.
EM sdulongy@163.com
RI SONG, Huaibo/GXM-9402-2022
FU National Nature Science Foundation of China [60975007]; National High
   Technology Research and Development Program of China ("863" Program)
   [2013AA10230402]
FX This research is supported by National Nature Science Foundation of
   China (Grant No: 60975007) and National High Technology Research and
   Development Program of China ("863" Program) (Grant No. 2013AA10230402).
   We would like to thank Ming-Ming Chen for providing the saliency maps of
   the state-of-the-art approaches for result comparison.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], ACM MULT C MULT C
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], 2010, ACM INT C MULT
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Cheng G., 2008, TRANSPORTATION RES B, P1
   Fang MY, 2012, MULTIMED TOOLS APPL, V57, P501, DOI 10.1007/s11042-010-0655-3
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Fang YM, 2012, IEEE T MULTIMEDIA, V14, P187, DOI 10.1109/TMM.2011.2169775
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Gao Z, 2012, INT C PATT RECOG, P1868
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He DJ, 2011, OPT ENG, V50, DOI 10.1117/1.3625422
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Lang CY, 2012, IEEE T IMAGE PROCESS, V21, P1327, DOI 10.1109/TIP.2011.2169274
   Lee JS, 2011, J VIS COMMUN IMAGE R, V22, P704, DOI 10.1016/j.jvcir.2010.11.002
   Liang Z, 2012, PATTERN RECOGN, V45, P3886, DOI 10.1016/j.patcog.2012.04.017
   Liang ZJ, 2014, MULTIMED TOOLS APPL, V68, P517, DOI 10.1007/s11042-012-1040-1
   Liu HT, 2011, IEEE T CIRC SYST VID, V21, P971, DOI 10.1109/TCSVT.2011.2133770
   Liu Q, 2013, MULTIMED TOOLS APPL, V67, P231, DOI 10.1007/s11042-012-1077-1
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Sun XS, 2010, IEEE IMAGE PROC, P1101, DOI 10.1109/ICIP.2010.5653713
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P359, DOI 10.1098/rspb.1998.0303
   Wu JJ, 2012, J VIS COMMUN IMAGE R, V23, P1158, DOI 10.1016/j.jvcir.2012.07.010
   Zhang H, 2011, MULTIMED TOOLS APPL, V52, P221, DOI 10.1007/s11042-010-0470-x
   Zhu KF, 2013, PROC SPIE, V8653, DOI 10.1117/12.2002495
NR 32
TC 0
Z9 0
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9647
EP 9663
DI 10.1007/s11042-014-2144-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200027
DA 2024-07-18
ER

PT J
AU Pan, JS
   Li, W
   Yang, CS
   Yan, LJ
AF Pan, Jeng-Shyang
   Li, Wei
   Yang, Chun-Sheng
   Yan, Li-Jun
TI Image steganography based on subsampling and compressive sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Compressive Sensing(CS); Subsampling; Total variation
ID SECRECY
AB A new image steganography algorithm combining compressive sensing with subsampling is proposed, which can hide secret message into an innovative embedding domain. Considering that natural image tends to be compressible in a transform domain, the characteristics of compressive sensing (CS), dimensional reduction and random projection, are utilized to insert secret message into the compressive sensing transform domain of the sparse image and the measurement matrix which is generated by using a secret key is shared between sender and receiver. Then, stego-image is reconstructed approximately via Total Variation (TV) minimization algorithm. Through adopting different transform coefficients in sub-images gained by subsampling, high perceived quality of the stego-image can be guaranteed. Bit Correction Rate (BCR) between original secret message and extracted message are used to calculate the accuracy of this method. Numerical experiments show that this steganography algorithm has provided a novel data embedding domain and high security of information.
C1 [Pan, Jeng-Shyang; Li, Wei; Yang, Chun-Sheng; Yan, Li-Jun] Shenzhen Grad Sch, Harbin Inst Technol, Sch Comp Sci & Technol, IIIRC, Shenzhen, Peoples R China.
C3 Harbin Institute of Technology
RP Li, W (corresponding author), Shenzhen Grad Sch, Harbin Inst Technol, Sch Comp Sci & Technol, IIIRC, Shenzhen, Peoples R China.
EM jspan@cc.kuas.edu.tw; weil0819@gmail.com; starissim@gmail.com;
   yanlijun@126.com
RI Pan, Jeng-Shyang/AEO-3450-2022
OI Pan, Jeng-Shyang/0000-0002-3128-9025
CR [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   Chu WC, 2003, IEEE T MULTIMEDIA, V5, P34, DOI 10.1109/TMM.2003.808816
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Hsiang-Cheh Huang, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P223, DOI 10.1109/IIH-MSP.2012.60
   Liang YB, 2008, FOUND TRENDS COMMUN, V5, P355, DOI 10.1561/0100000036
   Liu XY, 2013, OPTIK, V124, P6590, DOI 10.1016/j.ijleo.2013.05.092
   Mayiami Mahmoud Ramezani, 2010, ARXIV10113985
   Patsakis C, 2011, INT ING HID MULT SIG, P169
   Patsakis C, 2011, SMART INNOV SYST TEC, V11, P219
   Rachlin Y, 2008, ANN ALLERTON CONF, P813, DOI 10.1109/ALLERTON.2008.4797641
   Ramezanpour Mahnaz, 2014, Cytotechnology, V66, P845, DOI 10.1007/s10616-013-9636-5
   Romberg J, 2008, IEEE SIGNAL PROC MAG, V25, P14, DOI 10.1109/MSP.2007.914729
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Tsai MJ, 2004, 24TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, PROCEEDINGS, P184
   Tsaig Y, 2006, SIGNAL PROCESS, V86, P549, DOI [10.1016/j.sigpro.2005.05.029, 10.1016/j.sigpro.2005.05.028]
   Valenzise G, 2009, IEEE IMAGE PROC, P1265, DOI 10.1109/ICIP.2009.5413615
NR 23
TC 37
Z9 37
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9191
EP 9205
DI 10.1007/s11042-014-2076-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200006
DA 2024-07-18
ER

PT J
AU Yan, XH
   Wang, S
   Abd El-Latif, AA
   Niu, XM
AF Yan, Xuehu
   Wang, Shen
   Abd El-Latif, Ahmed A.
   Niu, Xiamu
TI Random grids-based visual secret sharing with improved visual quality
   via error diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual secret sharing; Random grids; Boolean operations; Visual quality;
   Error diffusion
ID CRYPTOGRAPHY; ENCRYPTION
AB In this paper, a visual secret sharing scheme for case (k, n) based on random noise balanced error diffusion (RNBED) is proposed. The proposed scheme satisfies (k, n) threshold, requiring no codebook design, and avoiding the pixel expansion problem. In addition, it improves existing schemes in terms of contrast and evenness, which are two important metrics for evaluating the visual quality of recovered secret. Experimental results and security analyses show the effectiveness of the proposed scheme. Comparisons with previous approaches show the advantages of the proposed scheme.
C1 [Yan, Xuehu; Wang, Shen; Abd El-Latif, Ahmed A.; Niu, Xiamu] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
   [Abd El-Latif, Ahmed A.] Menoufia Univ, Fac Sci, Dept Math, Menoufia 32511, Egypt.
C3 Harbin Institute of Technology; Egyptian Knowledge Bank (EKB); Menofia
   University
RP Wang, S (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
EM xuehu.yan@ict.hit.edu.cn; shen.wang@hit.edu.cn; ahmed_rahiem@yahoo.com;
   xiamu.niu@ict.hit.edu.cn
RI Abd El-Latif, Ahmed A. A./GRO-1613-2022; Yan, Xuehu/AFK-3139-2022; Yan,
   Xuehu/AAG-1718-2022
OI Abd El-Latif, Ahmed A. A./0000-0002-5068-2033; Yan,
   Xuehu/0000-0001-6388-1720; Yan, Xuehu/0000-0001-6388-1720
FU National Natural Science Foundation of China [61100187, 61301099,
   61361166006]; Fundamental Research Funds for Central Universities [HIT.
   NSRIF. 2013061]; Ministry of Higher Education and Scientific Research
   (Egypt-Tunisia Cooperation Program) [4-13-A1]
FX The authors would like to thank the anonymous reviewers for their
   helpful and constructive comments that improved the clarity and quality
   of this paper. This work is supported by the National Natural Science
   Foundation of China (Grant Number: 61100187, 61301099, 61361166006), the
   Fundamental Research Funds for the Central Universities (Grant Number:
   HIT. NSRIF. 2013061) and Ministry of Higher Education and Scientific
   Research (Egypt-Tunisia Cooperation Program, Code Number:4-13-A1).
CR [Anonymous], MODERN DIGITAL HALFT
   Chen T., 2008, P 18 INF SEC C HUAL
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Feng YI, 2008, J TSINGHUA U SCI TEC, V48, P121
   FLOYD RW, 1975, INT S SOC INF DISPL, P36
   Hou YC, 2005, J RES PRACT INF TECH, V37, P179
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Liu F, 2012, J VIS COMMUN IMAGE R, V23, P331, DOI 10.1016/j.jvcir.2011.11.003
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Weir J, 2010, LECT NOTES COMPUT SC, V6010, P70, DOI 10.1007/978-3-642-14298-7_5
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P552, DOI 10.1016/j.jvcir.2013.03.002
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 18
TC 13
Z9 15
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9279
EP 9296
DI 10.1007/s11042-014-2080-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200010
DA 2024-07-18
ER

PT J
AU Liu, PL
   Liu, HT
   Jin, JH
   Li, J
AF Liu, Peilin
   Liu, Haoting
   Jin, Jianhai
   Li, Jie
TI Water wave visualization simulation using feedback of image texture
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visualization simulation; Water wave imitation; Navier-Stokes equations;
   Shallow water equations; Texture analysis; Gabor wavelet; Mojette
   transform; Detrended fluctuation analysis
ID NAVIER-STOKES EQUATIONS; BOUNDARY-CONDITIONS; SCHEME; EULER
AB In order to improve the visualization simulation effect of water wave, we use the images of actual water wave as a feedback to correct the control parameters of Shallow Water (SW) equations in this paper. First, we employ a kind of simplified numerical method to resolve the SW equations and create an initial water wave animation. The initial control parameters of SW equations can be set arbitrarily. Second we cut some water wave images from the artificial animation above to build an image dataset of Simulated Water Wave (SWW). Third, we capture the Actual Water Wave (AWW) images by cameras, which are fixed in the selected locations of a moving boat, to build another image dataset. After that, we make a correlation analysis of image texture between the artificial image dataset of SWW and the actual image dataset of AWW to compare their similarity. In this phase, some image quality metrics of Tamura's texture, together with the mathematic tools of Mojette transform, Gabor wavelet and Detrended Fluctuation Analysis (DFA) technique are utilized to accomplish the static and dynamic texture analysis tasks. Finally, we use the results of correlation analysis above as a feedback to give a guidance to tune the control parameters of SW equations and regenerate the water wave animation with better visualization effects. To enhance the fidelity of SWW images, we also use Gabor wavelet and the criterion of minimized distance to estimate the environment illumination direction of AWW if the texture definition is good enough. By this means, we can set proper light source parameters to the visualization animation of SWW. Extensive experiment results have shown us that the visualization simulation effect can be improved effectively by the application of our texture feedback based techniques.
C1 [Liu, Peilin] Jiangnan Univ, Sch Digital Media, Wuxi 214000, Peoples R China.
   [Liu, Peilin] Wuxi Inst Technol, Wuxi 214121, Peoples R China.
   [Liu, Haoting] Chinese Acad Aerosp Elect Technol, Beijing 100094, Peoples R China.
   [Jin, Jianhai] China Ship Sci Res Ctr, Wuxi 214082, Peoples R China.
   [Li, Jie] Chinese Astronaut Res & Training Ctr, Beijing 100094, Peoples R China.
C3 Jiangnan University; Wuxi Institute of Technology; China Ship Scientific
   Research Center
RP Liu, PL (corresponding author), Wuxi Inst Technol, Wuxi 214121, Peoples R China.
EM peilinliu_sytu@126.com; imkyran@hotmail.com; jinjianhai@cssrc.com.cn;
   lijie_nudt@aliyun.com
FU Key Technology R&D Program of Jiangsu Province, China [BE2012028]
FX This work is supported by the Key Technology R&D Program of Jiangsu
   Province, China (BE2012028). The authors thank Dr. Feng Li in China Ship
   Scientific Research Center for his helpful discussions on our research
   work.
CR Adams B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276437, 10.1145/1239451.1239499]
   Akoh R, 2010, J COMPUT PHYS, V229, P4567, DOI 10.1016/j.jcp.2010.02.023
   Anderson J. D., 1995, COMPUTATIONAL FLUID
   [Anonymous], 2002, Computational methods for fluid dynamics
   Arivazhagan S, 2006, PATTERN RECOGN LETT, V27, P1976, DOI 10.1016/j.patrec.2006.05.008
   Basson A, 2008, STOCH PROC APPL, V118, P417, DOI 10.1016/j.spa.2007.05.001
   Bianconi F, 2007, PATTERN RECOGN, V40, P3325, DOI 10.1016/j.patcog.2007.04.023
   Canestrelli A, 2012, ADV WATER RESOUR, V40, P54, DOI 10.1016/j.advwatres.2012.01.009
   Caussignac P, 2008, APPL NUMER MATH, V58, P1413, DOI 10.1016/j.apnum.2007.08.002
   CHEN JX, 1995, GRAPH MODEL IM PROC, V57, P107, DOI 10.1006/gmip.1995.1012
   Chow CK, 2010, PATTERN RECOGN, V43, P1700, DOI 10.1016/j.patcog.2009.10.008
   Dong J, 2012, J ELECTRON IMAGING, V21, P1
   Dong JY, 2008, IMAGE VISION COMPUT, V26, P1561, DOI 10.1016/j.imavis.2008.02.002
   Duan Q, 2011, J DIFFER EQUATIONS, V250, P2687, DOI 10.1016/j.jde.2011.01.010
   Felcman J, 2012, APPL MATH COMPUT, V219, P3354, DOI 10.1016/j.amc.2011.04.042
   Gie GM, 2012, J DIFFER EQUATIONS, V253, P1862, DOI 10.1016/j.jde.2012.06.008
   Guedon J, 2010, INT C IM PROC THEOR, P189
   Guo Q., 2011, 2011 19 INT C GEOINF, P1
   Han Y, 2007, IMAGE VISION COMPUT, V25, P1239, DOI 10.1016/j.imavis.2006.07.028
   Juang CF, 2009, IEEE T SYST MAN CY A, V39, P119, DOI 10.1109/TSMCA.2009.2008397
   Kress W, 2003, COMPUT FLUIDS, V32, P1093, DOI 10.1016/S0045-7930(02)00090-7
   Krishnamachari S, 1997, IEEE T IMAGE PROCESS, V6, P251, DOI 10.1109/83.551696
   Lagger P, 2008, COMPUT VIS IMAGE UND, V111, P207, DOI 10.1016/j.cviu.2007.11.002
   Li DHW, 2010, APPL ENERG, V87, P2109, DOI 10.1016/j.apenergy.2010.03.004
   [刘东健 Liu Dongjian], 2011, [实验流体力学, Journal of Experiments in Fluid Mechanics], V25, P65
   Liu H, 2010, IEEE INT C SIGN PROC, P968
   Liu X, 2008, COAST ENG, V55, P800, DOI 10.1016/j.coastaleng.2008.02.012
   Lopez-Moreno J, 2010, COMPUT GRAPH-UK, V34, P698, DOI 10.1016/j.cag.2010.08.004
   Majtner T, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P301, DOI 10.1109/3DIMPVT.2012.61
   Mitrea D., 2011, 2011 IEEE International Conference on Intelligent Computer Communication and Processing, P197, DOI 10.1109/ICCP.2011.6047869
   Muller M, REAL TIME PHYS CLASS
   Pan CH, 2006, J HYDRODYN, V18, P475, DOI 10.1016/S1001-6058(06)60123-6
   Péteri R, 2006, COMPUT IMAGING VIS, V32, P33, DOI 10.1007/1-4020-4179-9_6
   Phinyomark A., 2010, P 8 PSU ENG C, P333
   Qi YL, 2009, 2009 SECOND INTERNATIONAL SYMPOSIUM ON KNOWLEDGE ACQUISITION AND MODELING: KAM 2009, VOL 3, P174, DOI 10.1109/KAM.2009.39
   Rasulov M, 2005, APPL MATH COMPUT, V160, P343, DOI 10.1016/j.amc.2003.08.131
   Recur B., 2010, INT C IM PROC THEOR, P201
   Robert T, 2006, HUDSPETH WAVES WAVE
   Rodríguez JM, 2007, ADV ENG SOFTW, V38, P399, DOI 10.1016/j.advengsoft.2006.09.011
   Rogers Simon., 2012, A First Course in Machine Learning
   SHEN Lin-Lin, 2009, [自动化学报, Acta Automatica Sinica], V35, P350
   Shi DY, 2009, APPL MATH COMPUT, V207, P462, DOI 10.1016/j.amc.2008.10.058
   Shirokoff D, 2011, J COMPUT PHYS, V230, P8619, DOI 10.1016/j.jcp.2011.08.011
   Smith JR, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P437
   Tandianus B, 2012, ENTERTAIN COMPUT, V3, P129, DOI 10.1016/j.entcom.2011.11.004
   Tao JH, 2005, NUMERICAL SIMULATION
   Tessendorf J., SIMULATING OCEAN WAT
   van't Hof B, 2012, J COMPUT PHYS, V231, P4723, DOI 10.1016/j.jcp.2012.03.005
   Varma M, 2004, IMAGE VISION COMPUT, V22, P1175, DOI 10.1016/j.imavis.2004.03.012
   Xiaojun Tan, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P882, DOI 10.1109/CSSE.2008.935
   Xing GY, 2012, COMPUT GRAPH-UK, V36, P857, DOI 10.1016/j.cag.2012.07.005
   Xu N, 2009, CHAOS SOLITON FRACT, V41, P311, DOI 10.1016/j.chaos.2007.12.006
   Xu S, 2008, PATTERN RECOGN LETT, V29, P1639, DOI 10.1016/j.patrec.2008.04.007
   Zhang YZ, 2012, IEEE T VIS COMPUT GR, V18, P1281, DOI 10.1109/TVCG.2011.141
   Zhou F, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P610, DOI 10.1109/ICIP.2001.958567
   Zhu F, 2012, INT C MOD ID CONTR, P673
NR 56
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8379
EP 8400
DI 10.1007/s11042-013-1683-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600009
DA 2024-07-18
ER

PT J
AU Lu, T
   Jin, YK
   Su, F
   Shivakumara, P
   Tan, CL
AF Lu, Tong
   Jin, Yukang
   Su, Feng
   Shivakumara, Palaiahnakote
   Tan, Chew Lim
TI Content-oriented multimedia document understanding through cross-media
   correlation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia documents; Multimodal; MAD; MCN; Correlation propagation
ID RETRIEVAL; AUDIO; MODEL
AB This paper presents a novel method for multimedia document content analysis through modeling multimodal data correlations. We hypothesize that the correlation of different modalities from the same data source can help achieve better multimedia content understanding results than one which explores a single modality. We turn this task into two parts: multimedia data fusion and multimodal correlation propagation. During the first stage, we re-organize the training multimedia data into Modality semAntic Documents (MADs) after extracting quantized multimodal features, and then use multivariate Gaussian distributions to characterize the continuous quantity by latent topic modeling. Model parameters are asymmetrically learned to initialize multimodal correlations in the latent topic space. Accordingly, during the second stage, we construct a Multimodal Correlation Network (MCN) based on the initialized multimodal correlations, and a new mechanism of propagating inter-modality correlations and intra-modality similarities in MCN is further proposed to take the complementary from cross-modalities to facilitate multimedia content analysis. The experimental results of image-audio data retrieval on a 10-categories dataset and content-oriented web page recommendation on the USTODAY dataset show the effectiveness of our method.
C1 [Lu, Tong; Jin, Yukang; Su, Feng] Nanjing Univ, Dept Comp Sci, Natl Key Lab Novel Software Technol, Nanjing 210008, Jiangsu, Peoples R China.
   [Shivakumara, Palaiahnakote] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
   [Tan, Chew Lim] Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore.
C3 Nanjing University; Universiti Malaya; National University of Singapore
RP Lu, T (corresponding author), Nanjing Univ, Dept Comp Sci, Natl Key Lab Novel Software Technol, Nanjing 210008, Jiangsu, Peoples R China.
EM lutong@nju.edu.cn; mg1033012@smail.nju.edu.cn; suf@nju.edu.cn;
   hudempsk@yahoo.com; tancl@comp.nus.edu.sg
RI Palaiahnakote, Shivakumara/ITU-6488-2023; Palaiahnakote,
   Shivakumara/B-6261-2013
FU Natural Science Foundation of China [61272218, 61321491]; 973 Program of
   China [2010CB327903]; Program for New Century Excellent Talents
   [NCET-11-0232]
FX The work described in this paper was supported by the Natural Science
   Foundation of China under Grant No. 61272218 and No. 61321491, the 973
   Program of China under Grant No. 2010CB327903, and the Program for New
   Century Excellent Talents under NCET-11-0232. The authors thank the
   anonymous reviewers for their constructive comments, which helped to
   improve the paper.
CR AbdelRaouf A, 2010, INT J DOC ANAL RECOG, V13, P285, DOI 10.1007/s10032-010-0128-2
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Beal MJ, 2002, LECT NOTES COMPUT SC, V2350, P736
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Erol B, 2008, IEEE T MULTIMEDIA, V10, P711, DOI 10.1109/TMM.2008.922784
   Evangelopoulos G, 2009, INT CONF ACOUST SPEE, P3553, DOI 10.1109/ICASSP.2009.4960393
   Foote JT, 1997, P SOC PHOTO-OPT INS, V3229, P138, DOI 10.1117/12.290336
   Goto H, 2008, INT J DOC ANAL RECOG, V11, P1, DOI 10.1007/s10032-008-0061-9
   He JY, 2009, INT J DOC ANAL RECOG, V12, P185, DOI 10.1007/s10032-009-0089-5
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Iria J, 2009, IJCAI 09 WORKSH CROS
   Jiang P, 2010, IEEE MULTIMEDIA, V17, P64, DOI 10.1109/MMUL.2009.65
   JOURDAN M, 2001, INT C MED FUT, P25
   Karaoglu S, 2012, LECT NOTES COMPUT SC, V7585, P456, DOI 10.1007/978-3-642-33885-4_46
   Kyperountas M, 2007, IEEE T MULTIMEDIA, V9, P785, DOI 10.1109/TMM.2007.893337
   Li ZX, 2010, INT CONF ACOUST SPEE, P806, DOI 10.1109/ICASSP.2010.5494943
   Liang J, 2008, IEEE T PATTERN ANAL, V30, P591, DOI 10.1109/TPAMI.2007.70724
   Lin WX, 2012, LECT NOTES COMPUT SC, V7131, P740
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu XN, 2009, INT J DOC ANAL RECOG, V12, P65, DOI 10.1007/s10032-009-0081-0
   Ma XL, 2012, INT C PATT RECOG, P2590
   Mesaros A, 2011, EUR SIGNAL PR CONF, P1307
   Mi-Mi Lu, 2010, Proceedings 7th International Symposium on Chinese Spoken Language Processing (ISCSLP 2010), P420, DOI 10.1109/ISCSLP.2010.5684854
   Mitschick A., 2010, INT J ADV SOFTWARE, V3, P31
   Monay F., 2004, P 12 ANN ACM INT C M, P348, DOI [10.1145/1027527.1027608, DOI 10.1145/1027527.1027608]
   Monay F, 2007, IEEE T PATTERN ANAL, V29, P1802, DOI 10.1109/TPAMI.2007.1097
   Nguyen NV, 2012, ACCV 12, P382
   Poignant J., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P854, DOI 10.1109/ICME.2012.119
   Saathoff C, 2010, P 19 INT C WORLD WID, P831, DOI [10.1145/1772690.1772775, DOI 10.1145/1772690.1772775]
   Scherp A, 2008, MULTIMEDIA SYST, V14, P415, DOI 10.1007/s00530-008-0139-8
   Sidhom S, 2006, C 9 INT ISKO KNOWL O
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Staab S., 2008, REASONING WEB
   SU F., 2011, Proceedings of the 19th ACM international conference on Multimedia, P1389, DOI DOI 10.1145/2072298.2072022
   Tong L, 2009, IEEE T PATTERN ANAL, V31, P1444, DOI 10.1109/TPAMI.2008.161
   Phan TQ, 2013, PROC INT CONF DOC, P589, DOI 10.1109/ICDAR.2013.122
   Wang J., 2003, PROC SIGIR 03, P274, DOI DOI 10.1145/860435.860486
   Wang JJ, 2007, IEEE T MULTIMED, V9, P1520
   Wang L., 2011, Proceedings of the 19th ACM international conference on Multimedia, P1161, DOI [DOI 10.1145/2072298.2071964, 10.1145/2072298.2071964]
   Wang X., 2004, ACM INT C MULTIMEDIA, P944
   Weiss W, 2009, LECT NOTES COMPUT SC, V5887, P52, DOI 10.1007/978-3-642-10543-2_7
   Westerveld T, 2003, EURASIP J APPL SIG P, V2003, P186, DOI 10.1155/S111086570321101X
   Yamamoto M, 2005, IEEE INT SYM MULTIM, P29
   Yang Y, 2008, IEEE T MULTIMEDIA, V10, P437, DOI 10.1109/TMM.2008.917359
   Yang Y, 2010, PATTERN RECOGN, V43, P2927, DOI 10.1016/j.patcog.2010.02.015
   Yin WC, 2013, PROC INT CONF DOC, P1095, DOI 10.1109/ICDAR.2013.222
   Yukang Jin, 2012, Advanced Research in Applied Artificial Intelligence. Proceedings 25th International Conference on Industrial Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2012, P816, DOI 10.1007/978-3-642-31087-4_82
   Zhang H., 2007, P 15 INT C MULTIMEDI, P273
   Zhu Q., 2006, Proceedings of ACM MM'06, ACM, P211
   Zhu Y, 2005, ACM MULTIMEDIA 05, P638
   Zhuang YT, 2008, IEEE T MULTIMEDIA, V10, P221, DOI 10.1109/TMM.2007.911822
NR 52
TC 4
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 8105
EP 8135
DI 10.1007/s11042-014-2044-9
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200032
DA 2024-07-18
ER

PT J
AU Zheng, YF
   Jin, JX
AF Zheng, Yifeng
   Jin, Jianxiu
TI A novel image encryption scheme based on Henon map and compound
   spatiotemporal chaos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Spatiotemporal chaos; OCML; Henon map
AB In this paper, a novel image encryption algorithm based on H,non map and compound spatiotemporal chaos is proposed. Pixel positions permutation and pixel values shuffling are both implemented via the cryptosystem proposed. In the permutation process, H,non map is employed. In the shuffling stage, the merits of spatiotemporal chaos and compound chaos are combined. To enhance the security, an interception key and a modulation key based on the plain image are designed, which make the scheme robust against the known- and chosen-plaintext attacks and enlarge the key space as well. Experimental results and relevant security analysis show that the proposed cipher algorithm can provide adequate security for the confidentiality of images. In addition, compared with other competitive existing chaos-based image encryption schemes, the new algorithm has superiority in aspects such as key space, key sensitivity, plaintext sensitivity, and execution efficiency.
C1 [Zheng, Yifeng; Jin, Jianxiu] S China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Guangdong, Peoples R China.
C3 South China University of Technology
RP Jin, JX (corresponding author), S China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Guangdong, Peoples R China.
EM jxjin@scut.edu.cn
OI Zheng, Yifeng/0000-0001-7852-6051
FU National Natural Science Foundation of China [61101014, 51077057];
   Fundamental Research Funds for the Central Universities, SCUT
   [2013ZZ057]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61101014, 51077057), and the Fundamental Research Funds for
   the Central Universities, SCUT (No. 2013ZZ057).
CR Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JY, 2011, IEEE T CIRCUITS-II, V58, P110, DOI 10.1109/TCSII.2011.2106316
   Chen SL, 2010, IEEE T CIRCUITS-II, V57, P996, DOI 10.1109/TCSII.2010.2083170
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   HENON M, 1976, COMMUN MATH PHYS, V50, P69, DOI 10.1007/BF01608556
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Jastrzebski K., 2009, Engineering Transactions, V57, P89
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Liao XF, 2004, INT J COMMUN SYST, V17, P437, DOI 10.1002/dac.655
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Pisarchik AN, 2006, CHAOS, V16, DOI 10.1063/1.2242052
   Rhouma R, 2009, CHAOS SOLITON FRACT, V40, P309, DOI 10.1016/j.chaos.2007.07.083
   Sathyanarayana S. V., 2011, INT J NETWORK SECURI, V12, P137
   Shang ZW, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P2942, DOI 10.1109/ICYCS.2008.99
   Short KM, 1997, INT J BIFURCAT CHAOS, V7, P1579, DOI 10.1142/S0218127497001230
   Sun FY, 2008, CHAOS SOLITON FRACT, V38, P631, DOI 10.1016/j.chaos.2008.01.028
   Sun FY, 2010, OPT COMMUN, V283, P2066, DOI 10.1016/j.optcom.2010.01.028
   Tang ZJ, 2015, MULTIMED TOOLS APPL, V74, P5429, DOI 10.1007/s11042-014-1861-1
   Tong XJ, 2008, IMAGE VISION COMPUT, V26, P843, DOI 10.1016/j.imavis.2007.09.005
   Wang Pei-rong, 2006, Journal of China Institute of Communications, V27, P285
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Xiang T, 2006, PHYS LETT A, V349, P109, DOI 10.1016/j.physleta.2005.02.083
   Xiang T, 2007, CHAOS, V17, DOI 10.1063/1.2728112
   Yang T, 1998, PHYS LETT A, V245, P495, DOI 10.1016/S0375-9601(98)00425-3
   Ye GD, 2012, NONLINEAR DYNAM, V69, P2079, DOI 10.1007/s11071-012-0409-z
   Zhenjun Tang, 2011, Journal of Multimedia, V6, P202, DOI 10.4304/jmm.6.2.202-206
   Zhou Q, 2008, CHAOS SOLITON FRACT, V38, P1081, DOI 10.1016/j.chaos.2007.01.034
   Zhu Cong-xu, 2006, Journal of Central South University (Science and Technology), V37, P1142
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   Zhu LH, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P601
NR 37
TC 24
Z9 26
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7803
EP 7820
DI 10.1007/s11042-014-2024-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200018
DA 2024-07-18
ER

PT J
AU Wattanapongsakorn, N
   Charnsripinyo, C
AF Wattanapongsakorn, Naruemon
   Charnsripinyo, Chalermpol
TI Web-based monitoring approach for network-based intrusion detection and
   prevention
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web-based IDPS; Real-time detection; Intrusion detection system; Network
   security system; Machine learning technique
AB There were many reports about incidents of network attacks and security treats. Damages caused by network attacks and malwares can be extremely expensive or unaffordable. In this paper, we present a web-based management system for network-based intrusion detection and prevention. Users can get access from any mobile devices to see current network status, if there is an incident of network attack in the network environment. Our intrusion detection and prevention systems (IDPS) can be applied with different well-known detection algorithms which are C4.5 Decision Tree, Random Forest, Ripple Rule, Bayesian Network, Back-Propagation Neural Network. These algorithms can give very high detection accuracy for known attacks, where the attack type was previously trained/ learnt by the system. However, when new or unfamiliar/unknown attacks are encountered, the algorithms do not perform well. So, we develop a new detection technique based on Fuzzy Genetic Algorithm (Fuzzy GA) to handle the problem. Our IDPS can work in real-time, where detection results will be reported within 2-3 s. The IDPS will automatically protect the network by dropping the malicious network packets or block the network ports that are abused by the attackers. In addition, the proposed IDPS can detect network attacks at different locations inside the network by using several client machines to capture data packets and then send information to the server in order to classify types of network attacks. The proposed IDPS also allows system administrator to update existing detection rule sets or learn new training datasets with a friendly graphic user interface. In our experiments, we can correctly detect and prevent network attacks with high accuracy, more than 97 %.
C1 [Wattanapongsakorn, Naruemon] King Mongkuts Univ Technol, Dept Comp Engn, Bangkok, Thailand.
   [Charnsripinyo, Chalermpol] Natl Elect & Comp Technol Ctr, Klongluang, Pathumthani, Thailand.
C3 King Mongkuts University of Technology Thonburi; King Mongkuts
   University of Technology North Bangkok; National Science & Technology
   Development Agency - Thailand; National Electronics & Computer
   Technology Center (NECTEC)
RP Wattanapongsakorn, N (corresponding author), King Mongkuts Univ Technol, Dept Comp Engn, 126 Pracha Utit Rd, Bangkok, Thailand.
EM naruemon@cpe.kmutt.ac.th
FU King Mongkut's University of Technology Thonburi; National Research
   University Project of Thailand; Office of the Higher Education
   Commission
FX This work was supported by King Mongkut's University of Technology
   Thonburi, National Research University Project of Thailand and Office of
   the Higher Education Commission. The authors would like to thank the
   following members of the network security and optimization group at CPE,
   KMUTT; P. Jongsuebsuk, E. Wonghirunsombat, T. Assawaniwed and V.
   Hanchana for their assistance in software programming and running some
   experiments.
CR Amini M, 2006, COMPUT SECUR, V25, P459, DOI 10.1016/j.cose.2006.05.003
   [Anonymous], 2008, P 10 ANN C COMP GEN
   Bard H., 2005, CODE RED 2 ANAL
   Ferrie P, 2004, VIRUS B          AUG
   Gómez J, 2006, IEEE INT CONF FUZZY, P2286, DOI 10.1109/FUZZY.2006.1682017
   Hoogstraten J. V., 2003, CGIH PRACTICAL ASSIG
   Jongsuebsook P, 2013, ECTI CON IEEE C
   Li P, 2008, IEEE COMMUN SURV TUT, V10, P20, DOI 10.1109/COMST.2008.4483668
   McDowell M., US CERT DENIAL SERVI
   Puttini RS, 2003, AIP CONF PROC, V659, P150
   Sangkatsanee P, 2011, COMPUT COMMUN, V34, P2227, DOI 10.1016/j.comcom.2011.07.001
   Sarnsuwan N, 2010, 2010 6 INT C, P1
   Shannon C, 2004, IEEE SECUR PRIV, V2, P46, DOI 10.1109/MSP.2004.59
   Wattanapongsakorn N., 2012, 2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom), P209, DOI 10.1109/TrustCom.2012.46
   Weka library, DAT MIN SOFTW JAV
NR 15
TC 7
Z9 8
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6391
EP 6411
DI 10.1007/s11042-014-2097-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700019
DA 2024-07-18
ER

PT J
AU Shen, J
   Ti, CP
   Raghunathan, A
   Cheung, SCS
   Patel, R
AF Shen, Ju
   Ti, Changpeng
   Raghunathan, Anusha
   Cheung, Sen-ching S.
   Patel, Rita
TI Automatic video self modeling for voice disorder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video self modeling; Positive feedforward; Voice disorder; Computational
   multimedia; Frame interpolation; Voice imitation; Audio segmentation;
   Lip reading
ID EXTRACTION; SETTINGS; TRACKING; THERAPY; SPEECH
AB Video self modeling (VSM) is a behavioral intervention technique in which a learner models a target behavior by watching a video of him-or herself. In the field of speech language pathology, the approach of VSM has been successfully used for treatment of language in children with Autism and in individuals with fluency disorder of stuttering. Technical challenges remain in creating VSM contents that depict previously unseen behaviors. In this paper, we propose a novel system that synthesizes new video sequences for VSM treatment of patients with voice disorders. Starting with a video recording of a voice-disorder patient, the proposed system replaces the coarse speech with a clean, healthier speech that bears resemblance to the patient's original voice. The replacement speech is synthesized using either a text-to-speech engine or selecting from a database of clean speeches based on a voice similarity metric. To realign the replacement speech with the original video, a novel audiovisual algorithm that combines audio segmentation with lip-state detection is proposed to identify corresponding time markers in the audio and video tracks. Lip synchronization is then accomplished by using an adaptive video re-sampling scheme that minimizes the amount of motion jitter and preserves the spatial sharpness. Results of both objective measurements and subjective evaluations on a dataset with 31 subjects demonstrate the effectiveness of the proposed techniques.
C1 [Shen, Ju; Ti, Changpeng; Cheung, Sen-ching S.] Univ Kentucky, Ctr Visualizat & Virtual Environm, Lexington, KY 40506 USA.
   [Raghunathan, Anusha] Intel Corp, Folsom, CA 95630 USA.
   [Patel, Rita] Indiana Univ, Dept Speech & Hearing Sci, Bloomington, IN 47405 USA.
C3 University of Kentucky; Intel Corporation; Indiana University System;
   Indiana University Bloomington
RP Shen, J (corresponding author), Univ Kentucky, Ctr Visualizat & Virtual Environm, 329 Rose St, Lexington, KY 40506 USA.
EM jushen.tom@uky.edu; changpeng.ti@uky.edu; anusha.ragunathan@gmail.com;
   sccheung@ieee.org; patelrir@indiana.edu
RI Patel, Rita/ABC-2626-2021
OI Patel, Rita/0000-0002-5354-5210
FU National Science Foundation [1237134]; Direct For Computer & Info Scie &
   Enginr [1237134] Funding Source: National Science Foundation; Div Of
   Information & Intelligent Systems [1237134] Funding Source: National
   Science Foundation
FX Part of this material is based upon work supported by the National
   Science Foundation under Grant No. 1237134. Any opinions, findings, and
   conclusions or recommendations expressed in this material are those of
   the author(s) and do not necessarily reflect the views of the National
   Science Foundation.
CR Aleksic PS, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P481
   Alvero AM, 2004, J APPL BEHAV ANAL, V37, P457, DOI 10.1901/jaba.2004.37-457
   [Anonymous], IEEE T VIS COMPUT GR
   [Anonymous], SEEING BELIEVING VID
   Arsic I., 2006, 14 EUR SIGN PROC C
   Bandura A., 1997, SELF EFFIICACY EXERC
   Bonastre JF, 2004, P NIST SPEAK EV
   Boone D. R., 2006, VOICE VOICE THERAPY
   Chen JY, 2008, LECT NOTES COMPUT SC, V5359, P236, DOI 10.1007/978-3-540-89646-3_23
   Cui S, 2012, REV SCI INSTRUM, V83, P103
   Deng Z, 2008, COMPUT GRAPH FORUM, V27, P2096, DOI 10.1111/j.1467-8659.2008.01192.x
   Dowrick PW, 1983, SELF MODELING USING
   Eveno N, 2004, IEEE T CIRC SYST VID, V14, P706, DOI 10.1109/TCSVT.2004.826754
   Eveno N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA125
   Gowdy JN, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P993
   Hammal Z, 2005, IEEE J SIG PROCESS
   Hapner E, 2009, J VOICE, V23, P337, DOI 10.1016/j.jvoice.2007.10.009
   Hitchcock CH, 2003, REM SPEC EDUC, V24, P36, DOI 10.1177/074193250302400104
   Howitt A. W., 2000, THESIS
   Ju Shen, 2012, 2012 IEEE 14th International Conference on e-Health Networking, Applications and Services (Healthcom 2012), P244, DOI 10.1109/HealthCom.2012.6379415
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kaucic R., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P376
   Krouse HJ, 2001, J ADV NURS, V33, P748, DOI 10.1046/j.1365-2648.2001.01716.x
   Leung AWC, 2000, INT C IM PROC
   Li L, 2010, ARXIV13115590
   MacKenzie K, 2001, BRIT MED J, V323, P658, DOI 10.1136/bmj.323.7314.658
   McDaniel RW, 1998, CANCER NURS, V21, P143, DOI 10.1097/00002820-199804000-00008
   MERMELSTEIN P, 1975, J ACOUST SOC AM, V58, P880, DOI 10.1121/1.380738
   Mertens P, 1987, ECST, P2009
   Nakamura K, 2002, 2002 IEEE ASIA-PACIFIC CONFERENCE ON ASIC PROCEEDINGS, P303, DOI 10.1109/APASIC.2002.1031592
   Nguyen D, 2006, IEEE T SYST MAN CY B, V36, P902, DOI 10.1109/TSMCB.2005.862728
   Nielsen D, 2009, J APPL BEHAV ANAL, V42, P551, DOI 10.1901/jaba.2009.42-551
   Patel RR, 2011, J VOICE, V25, P562, DOI 10.1016/j.jvoice.2010.01.010
   Queiroz R, 2009, ACM COMPUTERS ENTERT, V7
   RAMACHANDRAN VS, 1995, NATURE, V377, P489, DOI 10.1038/377489a0
   Ramig LO, 1998, J SPEECH LANG HEAR R, V41, pS101, DOI 10.1044/jslhr.4101.s101
   Roy N, 1997, J VOICE, V11, P321, DOI 10.1016/S0892-1997(97)80011-2
   Roy N, 2003, J SPEECH LANG HEAR R, V46, P670, DOI 10.1044/1092-4388(2003/053)
   Shen J, 2013, IEEE T IMAGE PROCESS
   Shen J, 2013, PROC CVPR IEEE, P1187, DOI 10.1109/CVPR.2013.157
   Shen J, 2011, IEEE INT CON MULTI
   Sundermann D, 2004, SIGN PROC INF TECHN
   Verdolini K, 2001, Logoped Phoniatr Vocol, V26, P37, DOI 10.1080/140154301300109125
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Vogl W, 2006, IEEE T NANOTECHNOL, V5, P397, DOI 10.1109/TNANO.2006.877421
   Xie Z, 2006, INTERSPEECH 06
   Yang J, 2013, INT J DISTRIBUTED NE
   Yuzhu Zhou, 2010, 2010 2nd IEEE International Conference on Network Infrastructure and Digital Content (IC-NIDC 2010), P404, DOI 10.1109/ICNIDC.2010.5657800
   ZHENG QF, 1995, INT J COMPUT VISION, V15, P31, DOI 10.1007/BF01450849
NR 49
TC 1
Z9 4
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 14
BP 5329
EP 5351
DI 10.1007/s11042-014-2015-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XU
UT WOS:000358214900022
DA 2024-07-18
ER

PT J
AU Yan, WQ
   Chambers, J
   Garhwal, A
AF Yan, Wei Q.
   Chambers, J.
   Garhwal, A.
TI An empirical approach for currency identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Currency identification; Neural network; Empirical approach
AB Currency identification is the application of systematic methods to determine authenticity of questioned currency. However, identification analysis is a difficult task requiring specially trained examiners, the most important challenge is automating the analysis process reducing human labor and time. In this study, an empirical approach for automated currency identification is formulated and a prototype is developed. A two parts feature vector is defined comprised of color features and texture features. Finally the banknote in question is classified by a Feedforward Neural Network (FNN) and a measurement of the similarity between existing samples and suspect banknote is output.
C1 [Yan, Wei Q.; Chambers, J.; Garhwal, A.] AUT Univ, Auckland, New Zealand.
C3 Auckland University of Technology
RP Yan, WQ (corresponding author), AUT Univ, Auckland, New Zealand.
EM dcsyanwq@gmail.com
RI Garhwal, Abhimanyu Singh/AAE-5933-2019
OI Garhwal, Abhimanyu Singh/0000-0002-9810-6705
CR [Anonymous], 2011, J INF HIDING MULTIM
   Bender K W., 2006, Moneymakers: The Secret World of Banknote Printing
   Bu-Qing C, 2010, 2 INT C COMP MOD SIM, V2, P246
   Chae SH, 2009, COMM COM INF SC, V56, P477, DOI 10.1007/978-3-642-10844-0_55
   Chambers J., 2012, THESIS AUCKLAND U TE
   Chang FC, 2012, INFORM SCIENCES, V192, P39, DOI 10.1016/j.ins.2010.02.025
   Chia TH, 2009, OPT EXPRESS, V17, P22054, DOI 10.1364/OE.17.022054
   Daraee F., 2010, 6 IR MACH VIS IM PRO, P1
   Gou HL, 2011, COMM COM INF SC, V202, P243
   Grijalva F., 2010, IEEE ANDESCON 2010, P1
   Huang HC, 2011, INFORM SCIENCES, V181, P3379, DOI 10.1016/j.ins.2011.04.007
   Lamont FG, 2011, EXPERT SYSTEMS APPL, V39, P9651
   Liu L., 2010, IEEE Xplore, DOI [DOI 10.1109/ICMSS.2010.5576813, 10.1109/ICMSS.2010.5576813]
   MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448
   Orponen P., 1994, Nordic Journal of Computing, V1, P94
   Verma K. G., 2011, INT C CURR TRENDS TE, P1
   Yan WQ, 2013, IEEE INT SYMP CIRC S, P2988, DOI 10.1109/ISCAS.2013.6572507
NR 17
TC 7
Z9 7
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4723
EP 4733
DI 10.1007/s11042-013-1833-x
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400013
DA 2024-07-18
ER

PT J
AU Zhang, GS
   Wang, W
   Shin, S
   Hruska, CB
   Son, SH
AF Zhang, Gensheng
   Wang, Wei
   Shin, Sung
   Hruska, Carrie B.
   Son, Seong-Ho
TI Fourier irregularity index: A new approach to measure tumor mass
   irregularity in breast mammogram images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast masses classification; Contour analysis; Fourier Transform;
   Irregularity index
ID SHAPE-ANALYSIS; CLASSIFICATION; CALCIFICATIONS; LESIONS
AB Shape descriptors have been identified as important features in distinguishing malignant masses from benign masses. Thus, an effective morphological irregularity measure could provide a helpful reference to indicate the likelihood of malignancy of breast masses. In this paper, a new Fourier-Transform-based measure of irregularity-Fourier Irregularity Index (F (2) ), is proposed to provide reliable malignant/benign tumor/mass classification. The proposed measure has been evaluated on 418 breast masses, including 190 malignant masses and 218 benign lesions identified by radiologists on film mammograms. The results show the proposed measure has better performance than other approaches, such as Compactness Index (CI), Fractal Dimension (FD) and the Fourier-descriptor-based shape Factor (FF). Furthermore, these mentioned measures are paired to investigate the possibility of performance improvement. The results showed the combination of F (2) and CI further enhances the performance in indicating the likelihood of malignancy of breast masses.
C1 [Zhang, Gensheng] Univ Texas Arlington, Dept Comp Sci & Engn, Arlington, TX 76019 USA.
   [Zhang, Gensheng] S Dakota State Univ, Brookings, SD 57007 USA.
   [Wang, Wei; Shin, Sung] S Dakota State Univ, Dept Elect Engn & Comp Sci, Brookings, SD 57007 USA.
   [Hruska, Carrie B.] Mayo Clin, Dept Radiol, Rochester, MN 55905 USA.
   [Son, Seong-Ho] ETRI, Radio Technol Res Dept, Taejon 305700, South Korea.
C3 University of Texas System; University of Texas Arlington; South Dakota
   State University; South Dakota State University; Mayo Clinic;
   Electronics & Telecommunications Research Institute - Korea (ETRI)
RP Wang, W (corresponding author), S Dakota State Univ, Dept Elect Engn & Comp Sci, Brookings, SD 57007 USA.
EM gensheng.zhang@mavs.uta.edu; wei.wang@ieee.org; sung.shin@sdstate.edu;
   carrie_hruska@yahoo.com; shs@etri.re.kr
OI Son, Seong-Ho/0000-0003-1343-1806
CR Alto H, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1902996
   [Anonymous], 2004, Chaos and fractals: new frontiers of science
   D'Orsi C.J., 2003, Breast imaging reporting and data system (BI-RADS) breast imaging atlas
   DAVIES DH, 1990, PHYS MED BIOL, V35, P1111, DOI 10.1088/0031-9155/35/8/007
   Dey P, 2003, DIAGN CYTOPATHOL, V29, P85, DOI 10.1002/dc.10324
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Guo Q., 2005, P 3 IASTED INT C BIO, P180
   Heath M, 2001, IWDM 2000: 5TH INTERNATIONAL WORKSHOP ON DIGITAL MAMMOGRAPHY, P212
   KILDAY J, 1993, IEEE T MED IMAGING, V12, P664, DOI 10.1109/42.251116
   Kwon KC, 2012, J MED SYST, V36, P1757, DOI 10.1007/s10916-010-9635-4
   Lee TK, 2003, MED IMAGE ANAL, V7, P47, DOI 10.1016/S1361-8415(02)00090-7
   Liang Shen, 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P1403, DOI 10.1142/S0218001493000686
   Liberman L, 1998, AM J ROENTGENOL, V171, P35, DOI 10.2214/ajr.171.1.9648759
   Matsubara T, 1997, DEV NEW SCHEMES DETE, P63
   Pohlman S, 1996, MED PHYS, V23, P1337, DOI 10.1118/1.597707
   Rangayyan RM, 2007, J DIGIT IMAGING, V20, P223, DOI 10.1007/s10278-006-0860-9
   Rangayyan RM, 2000, MED BIOL ENG COMPUT, V38, P487, DOI 10.1007/BF02345742
   Rangayyan RM, 1997, IEEE T MED IMAGING, V16, P799, DOI 10.1109/42.650876
   Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260
   SHEN L, 1994, IEEE T MED IMAGING, V13, P263, DOI 10.1109/42.293919
   SPIESBERGER W, 1979, IEEE T BIO-MED ENG, V26, P213, DOI 10.1109/TBME.1979.326560
   WEE WG, 1975, RADIOLOGY, V116, P717, DOI 10.1148/116.3.717
   Wikipedia, 2012, FOURIER SERIES
   Xiangyang Xu, 2010, 2010 IEEE Fifth International Conference on Bio-Inspired Computing: Theories and Applications (BIC-TA), P485, DOI 10.1109/BICTA.2010.5645173
   Yang W, 2008, 2008 INTERNATIONAL MULTISYMPOSIUMS ON COMPUTER AND COMPUTATIONAL SCIENCES (IMSCCS), P51, DOI 10.1109/IMSCCS.2008.11
   ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508
   Zhang G, P 2011 ACM S RES APP, P232
   Zhang G, P 2012 ACM RES APPL, P153
NR 28
TC 8
Z9 8
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 3783
EP 3798
DI 10.1007/s11042-013-1799-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800009
DA 2024-07-18
ER

PT J
AU Park, J
   Lee, KH
AF Park, Jeongkyu
   Lee, Keung Hae
TI Design patterns for context-aware services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Context-aware; Pervasive computing; Uniquitous computing; End-user
   programming; Smart home; Smart space; Design pattern
AB Numerous context-aware applications were proposed in the literature. Relatively, little attention was paid to understanding how they are related. This paper introduces a framework for classifying context-aware services. We studied 48 context-aware service scenarios discussed in the literature, deriving a model of seven design patterns for context-aware services. This paper discusses the model and design patterns in detail. Also presented in this paper is a novel programming model for enabling the end-user to build context-aware services. The concept of Programming by Selection and its prototype implementation are presented. The feasibility of this method is demonstrated. It is argued that Programming by Selection offers an alternative end-user programming method for context-aware services.
C1 [Park, Jeongkyu] LIG Syst, R&D Ctr, Seoul, South Korea.
   [Lee, Keung Hae] Korea Aerosp Univ, Dept Comp Engn, Hwajondong 200-1,Hanggongdae Gil 100, Goyang City 412791, Gyeonggi Do, South Korea.
C3 Korea Aerospace University
RP Lee, KH (corresponding author), Korea Aerosp Univ, Dept Comp Engn, Hwajondong 200-1,Hanggongdae Gil 100, Goyang City 412791, Gyeonggi Do, South Korea.
EM jk.park@ligcorp.com; khlee@kau.ac.kr
CR Abowd GD, 1997, WIREL NETW, V3, P421, DOI 10.1023/A:1019194325861
   Brdiczka O, 2009, IEEE T SYST MAN CY B, V39, P56, DOI 10.1109/TSMCB.2008.923526
   Costa PD, 2007, CTIT PHD SERIES
   da Silva Santos Luiz Olavo Bonino, 2007, 2007 IEEE Congress on Services, P25
   Das SK, 2002, IEEE WIREL COMMUN, V9, P77, DOI 10.1109/MWC.2002.1160085
   Dey A.K., 2004, P SIGCHI C HUM FACT, P33, DOI DOI 10.1145/985692.985697
   Dey AK, 2006, LECT NOTES COMPUT SC, V3968, P254
   di Flora C, 2005, 25TH IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, PROCEEDINGS, P244, DOI 10.1109/ICDCSW.2005.77
   Fujinami K., 2004, ACM S APPL COMP, P1607
   García-Herranz M, 2010, J UNIVERS COMPUT SCI, V16, P1633
   Gu T, 2005, J NETW COMPUT APPL, V28, P1, DOI 10.1016/j.jnca.2004.06.002
   Holzner C., 2009, 18 IEEE INT WORKSH E
   Judd G, 2003, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS (PERCOM 2003), P133, DOI 10.1109/PERCOM.2003.1192735
   Kuflik T, 2006, INT C WIR COMM MOB C, P1283
   Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351
   Nguyen TV, 2010, P 3 INT C UB INF TEC
   Park Jeongkyu, 2013, [Journal of Internet Computing and Services, 인터넷정보학회논문지], V14, P1, DOI 10.7472/jksii.2013.14.4.01
   Park J, 2010, LECT NOTES COMPUT SC, V6406, P337, DOI 10.1007/978-3-642-16355-5_28
   Rodden T., 2004, 6 INT C DES COOP SYS, P11
   Schilit B., 1994, 1994 1 WORKSHOP MOBI, P85, DOI [DOI 10.1109/WMCSA.1994.16, 10.1109/WMCSA.1994.16]
   Shi W, 2006, FIRST INTERNATIONAL MULTI-SYMPOSIUMS ON COMPUTER AND COMPUTATIONAL SCIENCES (IMSCCS 2006), PROCEEDINGS, VOL 1, P560, DOI 10.1109/IMSCCS.2006.137
   Shin K, 2007, MUE: 2007 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING, PROCEEDINGS, P1227
   Thayer SM, 2003, PERS UBIQUIT COMPUT, V7, P82, DOI 10.1007/s00779-003-0234-y
   Trossen D, 2005, Proceedings of MobiQuitous 2005, P485
   Yau S. S., 2002, IEEE Pervasive Computing, V1, P33, DOI 10.1109/MPRV.2002.1037720
NR 25
TC 3
Z9 4
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 7
BP 2337
EP 2358
DI 10.1007/s11042-014-2001-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE0TU
UT WOS:000351520200010
DA 2024-07-18
ER

PT J
AU Qin, C
   Chang, CC
   Lin, CC
AF Qin, Chuan
   Chang, Chin-Chen
   Lin, Chia-Chun
TI An adaptive reversible steganographic scheme based on the just
   noticeable distortion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Just noticeable distortion; Embedding rate;
   Visual quality
ID HISTOGRAM-MODIFICATION
AB In this paper, we propose an adaptive reversible steganographic scheme based on the just noticeable distortion (JND). First, the JND value of each cover pixel is calculated using the frequency model of the human visual system (HVS). Then, the prediction value of the cover pixel is acquired by anisotropic interpolation, and also the pixel distribution characteristic is estimated. Finally, whether the cover pixel is embeddable or not is adaptively determined according to the relationship between the prediction error and the JND value. The embedding procedure is based on modifying the prediction error of each cover pixel, and the visual degradation caused by embedding is imperceptible due to the control of JND. Experimental results demonstrate that the proposed scheme provides a greater embedding rate and higher quality of stego image than other methods that have been reported recently.
C1 [Qin, Chuan] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Chang, Chin-Chen] Asia Univ, Dept Comp Sci & Informat Engn, Taichung 41354, Taiwan.
   [Lin, Chia-Chun] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 62102, Taiwan.
C3 University of Shanghai for Science & Technology; Feng Chia University;
   Asia University Taiwan; National Chung Cheng University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM qin@usst.edu.cn; alan3c@gmail.com; leonn1046@gmail.com
RI Qin, Chuan/C-1106-2017; Chang, Ching-Chun/JAN-6210-2023
OI Qin, Chuan/0000-0002-0370-4623; 
FU Natural Science Foundation of China [61303203]; Natural Science
   Foundation of Shanghai, China [13ZR1428400]; Innovation Program of
   Shanghai Municipal Education Commission [14YZ087]; OECE Innovation
   Foundation of USST
FX This work was supported by the Natural Science Foundation of China
   (61303203), the Natural Science Foundation of Shanghai, China
   (13ZR1428400), the Innovation Program of Shanghai Municipal Education
   Commission (14YZ087), and the OECE Innovation Foundation of USST.
CR Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   Jung SW, 2011, IEEE SIGNAL PROC LET, V18, P95, DOI 10.1109/LSP.2010.2095498
   Lee CF, 2010, J SYST SOFTWARE, V83, P1864, DOI 10.1016/j.jss.2010.05.078
   Liu YC, 2011, MULTIMED TOOLS APPL, V52, P263, DOI 10.1007/s11042-010-0496-0
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WATSON AB, 1993, P SOC PHOTO-OPT INS, V1913, P202, DOI 10.1117/12.152694
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 16
TC 16
Z9 16
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 1983
EP 1995
DI 10.1007/s11042-013-1733-0
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500013
DA 2024-07-18
ER

PT J
AU Elleuch, N
   Ben Ammar, A
   Alimi, AM
AF Elleuch, Nizar
   Ben Ammar, Anis
   Alimi, Adel M.
TI A generic framework for semantic video indexing based on visual
   concepts/contexts detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic indexing; Concepts; Contexts; SVI_REGIMVid
ID SCALE; RECOGNITION; RETRIEVAL; CONTEXT
AB Providing a semantic access to video data requires the development of concept detectors. However, semantic concepts detection is a hard task due to the large intra-class and the small inter-class variability of content. Moreover, semantic concepts co-occur together in various contexts and their occurrence may vary from one to another. Thus, it is interesting to exploit this knowledge in order to achieve satisfactory performances. In this paper we present a generic semantic video indexing scheme, called SVI_ REGIMVid. It is based on three levels of analysis. The first level (level1) focuses on low-level processing such as video shot boundary/ key-frame detection, annotation tools, key-points detection and visual features extraction tools. The second level (level2) aims to build the semantic models for supervised learning of concepts/ contexts. The third level (level3) enriches the semantic interpretation of concepts/ contexts by exploiting fuzzy knowledge. The obtained experimental results are promising for a semantic concept/ context detection process. Keywords Semantic indexing. Concepts.
C1 [Elleuch, Nizar; Ben Ammar, Anis; Alimi, Adel M.] Univ Sfax, Natl Sch Engn ENIS, Res Groups Intelligent Machines, REGIM Lab, Sfax 3038, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Elleuch, N (corresponding author), Univ Sfax, Natl Sch Engn ENIS, Res Groups Intelligent Machines, REGIM Lab, BP 1173, Sfax 3038, Tunisia.
EM nizar.elleuch@ieee.org; anis.benammar@ieee.org; adel.alimi@ieee.org
RI Alimi, Adel M./A-5697-2012
OI Alimi, Adel M./0000-0002-0642-3384
FU General Direction of Scientific Research (DGRST), Tunisia under the ARUB
   program
FX The authors would like to acknowledge the financial support of this work
   by grants from General Direction of Scientific Research (DGRST),
   Tunisia, under the ARUB program. Also, the authors are grateful to NIST
   and the TRECVID coordinators for the benchmark organization's effort.
CR Amir Arnon., 2003, NIST TRECVID-2003
   Amores J, 2007, IEEE T PATTERN ANAL, V29, P1818, DOI 10.1109/TPAMI.2007.1098
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], 2007, P ASS COMP MACH MULT
   [Anonymous], CVPR
   [Anonymous], 2007, CIVR
   [Anonymous], P TRECVID 2003 WORKS
   [Anonymous], CLUSTERING SELF ORG
   [Anonymous], EUROCON
   [Anonymous], TRECVID
   [Anonymous], 2008, CVPR
   [Anonymous], P 5 INT INT C MOD US
   Ayache S, 2008, LECT NOTES COMPUT SC, V4956, P187
   Bres S., 1999, Visual Information and Information Systems. Third International Conference, VISUAL'99. Proceedings (Lecture Notes in Computer Science Vol.1614), P427
   Crandall D, 2005, PROC CVPR IEEE, P10
   Deng J., 2009, IEEE C COMP VIS PATT
   Elleuch N, 2010, TRECVID 2010 CIT
   Elleuch N., 2011, MDMKDD, V11
   Elleuch N, 2010, I V COMM MOB NETW IS, P1
   Grauman K, 2005, PROC CVPR IEEE, P627
   HAUPTMANN A.G., 2002, TREC
   HAUPTMANN AG, 2003, P TRECVID
   Helmer S., 2004, WORKSH GEN MOD BAS V
   JIANG W, 2006, IEEE INT C IM PROC I
   Jiang Y.-G., 2009, INT C COMP VIS ICCV
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Karray H., 2008, TRECVID
   Kennedy L.S., 2007, Proceedings of the 6th ACM international conference on Image and video retrieval, P333
   Kohonen T., 2001, INFORM SCIENCES
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marszalek M., 2006, PROC IEEE INT C COMP, V2, P2118
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Murphy P, 2003, ADV NEUR INFORM PROC, V16
   Mylonas P, 2008, MULTIMED TOOLS APPL, V39, P293, DOI 10.1007/s11042-007-0161-4
   Mylonas P, 2009, IEEE T MULTIMEDIA, V11, P229, DOI 10.1109/TMM.2008.2009681
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   PETERSOHN C., 2004, P TRECVID WORKSH
   Punitha P, P INT C COGN REC REL
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith JF, 2003, J PHASE EQUILIB, V24, P2, DOI 10.1361/105497103770330947
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Snoek CGM, 2006, ACM T MULTIM COMPUT, V2, P91, DOI 10.1145/1142020.1142021
   Snoek CGM, 2006, IEEE T PATTERN ANAL, V28, P1678, DOI 10.1109/TPAMI.2006.212
   Spyrou E, 2008, HCP 2008 P 2, P25
   Torralba Antonio, 2005, P586, DOI 10.1016/B978-012375731-9/50100-2
   van Gemert Jan C., 2008, Computer Vision. Proceedings 10th European Conference on Computer Vision, ECCV 2008, P696, DOI 10.1007/978-3-540-88690-7_52
   Volkmer T., 2005, 13th Annual ACM International Conference on Multimedia, P892, DOI 10.1145/1101149.1101341
   Wang L., 2012, P 21 ACM INT C INF K, P1303
   Wei XY, 2009, P ACM INT C IM VID R, P15
   Wu L, 2009, IEEE T MULTIMEDIA, V11, P286, DOI 10.1109/TMM.2008.2009692
   Zampoglou M, 2010, J SIGNAL PROCESS SYS, V61, P75, DOI 10.1007/s11265-008-0314-3
NR 57
TC 11
Z9 11
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 4
BP 1397
EP 1421
DI 10.1007/s11042-014-1955-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZN
UT WOS:000349356300013
OA hybrid
DA 2024-07-18
ER

PT J
AU Riaz, S
   Lee, SW
AF Riaz, Sidra
   Lee, Sang-Woong
TI A robust multimedia authentication and restoration scheme in digital
   photography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia authentication; Image restoration; Multimedia security;
   Multiple watermarking
ID FRAGILE WATERMARKING
AB Image authentication and restoration is an important area of modern research. In digital photography, copyright protection is very crucial. Visible signatures distract from the meaning of the photograph as well as they are easy to be removed by using advanced softwares. Invisible watermarks provide protection, offer a better look to photographs than visible watermarking, and prevent the photographs from unauthorized manipulations. A robust multiple watermarking scheme is required which could invisibly protect the content and also should survive the manipulations for later verification and restoration. In this paper, a robust and imperceptible multimedia authentication and restoration scheme is proposed. The security of Advanced Encryption Standard (AES) is utilized to make an encrypted watermark. The encrypted watermark is then embedded into photographs in the salient regions by proposed Feature-Closest Point Transform (F-CPT) algorithm. The second watermark is generated by wavelet decomposition and embedded in the second and third level wavelet sub-bands of the cover photographs. Several security attacks are performed e. g. noise attack, compression attack, resizing attack, rotation attack, collage attack, and cropping attack on multiple watermarked photographs to examine the system robustness by normalized cross correlation (NCC) for retrieved authentication watermarks. Result of PSNR, MSE, and SSIM show the high imperceptibility of our technique and aesthetic score (AS) shows the aesthetic quality of watermarked photographs (WPs).
C1 [Riaz, Sidra; Lee, Sang-Woong] Chosun Univ, Dept Comp Engn, Kwangju, South Korea.
C3 Chosun University
RP Lee, SW (corresponding author), Chosun Univ, Dept Comp Engn, 375 Seosuk Dong, Kwangju, South Korea.
EM sidra.riaz426@gmail.com; swlee@chosun.ac.kr
RI Lee, Sang-Woong/ABF-6191-2020
OI Lee, Sang-Woong/0000-0001-8117-6566; Riaz, Sidra/0000-0002-0216-416X
FU Chosun University
FX This study was supported by research fund from Chosun University, 2012.
CR Ali Al-Haj M, 2010, ADV TECHNIQUES MULTI, P2
   Ali Hajjaji Mohamed, 2011, J EMERGING TRENDS CO, V2, P714
   Alomari R.S., 2004, International Journal of Computing and Information Sciences, V2, P27
   Barnes C, 2011, COMMUN ACM, V54, P103, DOI 10.1145/2018396.2018421
   Chamlawi R, 2007, J COMPUTER SCI TECHN, V2, P795
   Chamlawi R, 2010, COMPUT ELECTR ENG, V36, P578, DOI 10.1016/j.compeleceng.2009.12.003
   Chang-Tsun Li, 2003, Journal of the Chinese Institute of Electrical Engineering, V10, P99
   Christof P, 2010, UNDERSTANDING CRYPTO, P2
   DATTA R., 2006, European Conference on Computer Vision, P288, DOI DOI 10.1007/11744078_23
   Dobbertin H, 2005, LECT NOTES COMPUT SC, V3373, P1
   Furht B, 2006, MULTIMEDIA WATERMARK, P1
   Jeng-Shyang P, 2004, INTELLIGENT WATERMAR, p[12, 351]
   Kuo-Ming Hung, 2012, Proceedings of the 2012 8th International Conference on Information Science and Digital Content Technology (ICIS and IDCTA), P730
   Lin CY, 2000, PROC SPIE, V3971, P140, DOI 10.1117/12.384968
   Lin ET, 2000, P SOC PHOTO-OPT INS, V3971, P23
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Pan HK, 2000, IEEE SYMP COMP COMMU, P750, DOI 10.1109/ISCC.2000.860731
   Piva A, 2008, STUD COMPUT INTELL, V120, P227
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Radharani S., 2010, INT J COMPUTER APPL, V2, P24, DOI DOI 10.5120/658-925
   Randall A, 2011, NOVEL SEMI FRAGILE W
   Riaz S., 2012, AUNSEED NET REGIONAL, P76
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Sathik M.M., 2010, International Journal of Advanced Science and Technology, V24, P61
   Sencar HT, 2004, DATA HIDING FUNDAMEN, P35
   Shelly GB, 2008, DISCOVERING COMPUTER, P294
   Shih FY, 2012, MULTIMEDIA SECURITY, p[67, 201]
   Somayeh S, 2012, IJCSI INT J COMPUTER, V9, P1
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2002, P SOC PHOTO-OPT INS, V4675, P679, DOI 10.1117/12.465329
   Tseng YC, 2001, IEEE INFOCOM SER, P887, DOI 10.1109/INFCOM.2001.916280
   Weilin Huang, 2008, 5th International Conference on Visual Information Engineering, VIE 2008, P813, DOI 10.1049/cp:20080422
   Wu YD, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P843
   Yang H, 2007, IEEE C MULT UB ENG A, P26
   Zhang XP, 2008, IEEE T MULTIMEDIA, V10, P1490, DOI 10.1109/TMM.2008.2007334
   Zoran D, 2005, HDB STAT, P174
NR 36
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1291
EP 1321
DI 10.1007/s11042-013-1592-8
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200011
DA 2024-07-18
ER

PT J
AU Shih, PY
   Paul, A
   Wang, JF
   Chen, YH
AF Shih, Po-Yi
   Paul, Anand
   Wang, Jhing-Fa
   Chen, Yi-Hung
TI Speech-driven talking face using embedded confusable system for real
   time mobile multimedia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time speech driven; Lip-synch; Talking face; Hidden markov model
   (HMM); Multiclass support vector machine (MCSVM); Viseme histogram
   similarity; Confusion matrix
ID LIP-SYNC; ENHANCEMENT; RECOGNITION; ANIMATION; HEADS; SOUND
AB This paper presents a real-time speech-driven talking face system which provides low computational complexity and smoothly visual sense. A novel embedded confusable system is proposed to generate an efficient phoneme-viseme mapping table which is constructed by phoneme grouping using Houtgast similarity approach based on the results of viseme similarity estimation using histogram distance, according to the concept of viseme visually ambiguous. The generated mapping table can simplify the mapping problem and promote viseme classification accuracy. The implemented real time speech-driven talking face system includes: 1) speech signal processing, including SNR-aware speech enhancement for noise reduction and ICA-based feature set extractions for robust acoustic feature vectors; 2) recognition network processing, HMM and MCSVM are combined as a recognition network approach for phoneme recognition and viseme classification, which HMM is good at dealing with sequential inputs, while MCSVM shows superior performance in classifying with good generalization properties, especially for limited samples. The phoneme-viseme mapping table is used for MCSVM to classify the observation sequence of HMM results, which the viseme class is belong to; 3) visual processing, arranges lip shape image of visemes in time sequence, and presents more authenticity using a dynamic alpha blending with different alpha value settings. Presented by the experiments, the used speech signal processing with noise speech comparing with clean speech, could gain 1.1 % (16.7 % to 15.6 %) and 4.8 % (30.4 % to 35.2 %) accuracy rate improvements in PER and WER, respectively. For viseme classification, the error rate is decreased from 19.22 % to 9.37 %. Last, we simulated a GSM communication between mobile phone and PC for visual quality rating and speech driven feeling using mean opinion score. Therefore, our method reduces the number of visemes and lip shape images by confusable sets and enables real-time operation.
C1 [Shih, Po-Yi; Paul, Anand; Wang, Jhing-Fa; Chen, Yi-Hung] Natl Cheng Kung Univ, Dept Elect Engn, Tainan 70101, Taiwan.
   [Paul, Anand] Kyungpook Natl Univ, Sch Comp Sci & Engn, Taegu, South Korea.
C3 National Cheng Kung University; Kyungpook National University
RP Paul, A (corresponding author), Kyungpook Natl Univ, Sch Comp Sci & Engn, Taegu, South Korea.
EM poyi.shih@gmail.com; paul.editor@gmail.com
RI Chen, Yi-Hung/U-3254-2019; Paul, Anand/V-6724-2017
OI Chen, Yi-Hung/0000-0001-6731-1119; Paul, Anand/0000-0002-0737-2021;
   Paul, Anand/0000-0003-3115-2325
FU National Cheng Kung University; NSC
FX This research is partially support by National Cheng Kung University and
   NSC Research Fund.
CR [Anonymous], 10 AUSTR INT C SPEEC
   BREGLER C, 1997, P ACM SIGGRAPH 97
   Cambridge University Engineering Dept, HTK TOOLK 3 4
   Chen T, 1998, P IEEE, V86, P837, DOI 10.1109/5.664274
   Chen TH, 2001, IEEE SIGNAL PROC MAG, V18, P9
   Choi KH, 2001, J VLSI SIG PROC SYST, V29, P51, DOI 10.1023/A:1011171430700
   Cohen M. M., 1993, Models and Techniques in Computer Animation, P139
   Cosatto E, 2003, P IEEE, V91, P1406, DOI 10.1109/JPROC.2003.817141
   Cosatto E, 1998, COMP ANIM CONF PROC, P103, DOI 10.1109/CA.1998.681914
   Cosatto E, 2000, IEEE T MULTIMEDIA, V2, P152, DOI 10.1109/6046.865480
   CURINGA S, 1996, P EUSIPCO 96 SYST CO, P36
   EPHRAIM Y, 1995, IEEE T SPEECH AUDI P, V3, P251, DOI 10.1109/89.397090
   Ezzat T, 2002, ACM T GRAPHIC, V21, P388, DOI 10.1145/566570.566594
   Imperl B., 1999, Proc. EUROSPEECH, P887
   KOSTER BE, 1994, CONF REC ASILOMAR C, P583, DOI 10.1109/ACSSC.1994.471519
   Lee S., 2002, PRICAI 02, P563
   MCALLISTER DV, 1997, P SIGGRAPH 97 LOS AN, P225, DOI DOI 10.1145/259081.259312
   MORISHIMA S, 1998, P AVSP 98, P195
   Ostermann J, 2004, INT C PATT RECOG, P826, DOI 10.1109/ICPR.2004.1334656
   Park J, 2008, IEEE T MULTIMEDIA, V10, P1299, DOI 10.1109/TMM.2008.2004908
   Parke F., 1996, COMPUTER FACIAL ANIM
   TAMURA M, 1998, P AUD VIS SPEECH PRO, P221
   Theobald BJ, 2004, SPEECH COMMUN, V44, P127, DOI 10.1016/j.specom.2004.07.002
   Theobald BJ, 2007, AVSP 2007 INT C AUD
   Turunen E, 2001, ADV SOFT COMP, P313
   Wang HC, 1997, COMPUTATIONAL LINGUI, V2, P73
   Wang JC, 2008, IEEE T AUTOM SCI ENG, V5, P25, DOI 10.1109/TASE.2007.911680
   Wang JC, 2007, IEICE T INF SYST, VE90D, P1055, DOI 10.1093/ietisy/e90-d.7.1055
   Xie L, 2007, IEEE T MULTIMEDIA, V9, P500, DOI 10.1109/TMM.2006.888009
   Yamamoto E, 1998, SPEECH COMMUN, V26, P105, DOI 10.1016/S0167-6393(98)00054-5
   YE JJ, 2004, P 3 INT C IM GRAPH I, P377
   Zgank A, 2001, P EUR 2001 AALB DENM, P2725
   Zhong D, 2007, J PATT RECOG LETT, V28
NR 33
TC 4
Z9 4
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 417
EP 437
DI 10.1007/s11042-013-1609-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700021
DA 2024-07-18
ER

PT J
AU Bannour, H
   Hudelot, C
AF Bannour, Hichem
   Hudelot, Celine
TI Building and using fuzzy multimedia ontologies for semantic image
   annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image annotation; Multimedia ontology; Ontology building; Ontological
   reasoning; Fuzzy DL; Spatial information; Contextual information
ID RETRIEVAL
AB This paper proposes a methodology for building fuzzy multimedia ontologies dedicated to image annotation. The built ontology incorporates visual, conceptual, contextual and spatial knowledge about image concepts in order to model image semantics in an effective way. Indeed, our approach uses visual and conceptual information to build a semantic hierarchy that will serve as a backbone of our ontology. Contextual and spatial information about image concepts are then computed and incorporated in the ontology in order to model richer semantic relationships between these concepts. Fuzzy description logics are used as a formalism to represent our ontology and the inherent uncertainty and imprecision of this kind of information. Subsequently, we propose a new approach for image annotation based on hierarchical image classification and a multi-stage reasoning framework for reasoning about the consistency of the produced annotation. In this approach, fuzzy ontological reasoning is used in order to achieve a semantically relevant decision on the belonging of a given image to the set of concepts from the annotation vocabulary. An empirical evaluation of our approach on Pascal VOC'2009 and Pascal VOC'2010 datasets has shown a significant improvement on the average precision results.
C1 [Bannour, Hichem; Hudelot, Celine] Ecole Cent Paris, MAS Lab, F-92295 Chatenay Malabry, France.
C3 Universite Paris Saclay
RP Bannour, H (corresponding author), Ecole Cent Paris, MAS Lab, F-92295 Chatenay Malabry, France.
EM hichem.bannour@ecp.fr; celine.hudelot@ecp.fr
RI HUDELOT, CELINE/IRZ-2920-2023; Bannour, Hichem/B-8335-2013
OI HUDELOT, CELINE/0000-0003-3849-4133; 
CR [Anonymous], 2012, P 21 ACM INT C INFOR
   [Anonymous], 1999, P 7 IEEE INT C COMPU
   [Anonymous], 2010, PASCAL VISUAL OBJECT
   Baader F., 2003, DESCRIPTION LOGIC HD
   Bannour H, 2011, CONT BAS MULT IND CB
   Bannour H, 2012, LECT NOTES COMPUT SC, V7131, P4
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Bart E, 2008, COMPUTER VISION PATT, P1
   Bloch I, 2005, IMAGE VISION COMPUT, V23, P89, DOI 10.1016/j.imavis.2004.06.013
   Bobillo F, 2011, INFORM SCIENCES, V181, P758, DOI 10.1016/j.ins.2010.10.020
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Choi MJ, 2010, PROC CVPR IEEE, P129, DOI 10.1109/CVPR.2010.5540221
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dasiopoulou S, 2009, LECT NOTES COMPUT SC, V5850, P105, DOI 10.1007/978-3-642-10562-3_4
   Dasiopoulou S, 2010, MULTIMED TOOLS APPL, V46, P331, DOI 10.1007/s11042-009-0387-4
   Deng Jia, 2009, P CVPR
   Everingham M., 2009, The PASCAL Visual Object Classes Challenge 2009 (VOC) Results
   Fan JP, 2008, IEEE T IMAGE PROCESS, V17, P407, DOI 10.1109/TIP.2008.916999
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Griffin G., 2008, Computer Vision and Pattern Rrecognition (CVPR)
   Gruber TR, 1995, INT J HUM-COMPUT ST, V43, P907, DOI 10.1006/ijhc.1995.1081
   Gupta A, 2012, LECT NOTES COMPUT SC, V7667, P196, DOI 10.1007/978-3-642-34500-5_24
   HAUPTMANN A, 2007, INT C IM VID RETR CI
   Hollink L., 2004, INT WORKSH KNOWL MAR
   Horridge M, 2011, SEMANT WEB, V2, P11, DOI 10.3233/SW-2011-0025
   Hudelot C, 2008, FUZZY SET SYST, V159, P1929, DOI 10.1016/j.fss.2008.02.011
   Hudelot C, 2010, FRONT ARTIF INTEL AP, V215, P497, DOI 10.3233/978-1-60750-606-5-497
   Kompatsiaris Y., 2008, SEMANTIC MULTIMEDIA
   Lavrenko V., 2003, Neural Information Processing System (NIPS)
   Li LJ, 2010, COMPUTER VISION PATT
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Marszalek M., 2007, COMPUTER VISION PATT
   Simou N, 2008, SIGNAL IMAGE VIDEO P, V2, P321, DOI 10.1007/s11760-008-0084-1
   Simou N, 2005, WIAMIS
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Spaccapietra S, 2004, BRAZ S GEOINF
   Stoilos G, 2007, WORKSH OWL EXP DIR O
   Straccia U, 2001, J ARTIF INTELL RES, V14, P137, DOI 10.1613/jair.813
   Straccia U., 2006, FUZZY LOGIC SEMANTIC, P73, DOI 10.1016/S1574-9576(06)80006-7
   Straccia U, 2012, ARXIVABS12071410 COR
   Straccia U, 2010, INT SYM MVL, P319, DOI 10.1109/ISMVL.2010.65
   Tousch AM, 2012, PATTERN RECOGN, V45, P333, DOI 10.1016/j.patcog.2011.05.017
   Wu L, 2012, IEEE T PATTERN ANAL, V34, P863, DOI 10.1109/TPAMI.2011.195
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Yang JC, 2010, LECT NOTES COMPUT SC, V6315, P113, DOI 10.1007/978-3-642-15555-0_9
   Yao BZ, 2010, P IEEE, V98, P1485, DOI 10.1109/JPROC.2010.2050411
   Zhou X., 2010, EUR C COMP VIS ECCV
NR 47
TC 23
Z9 24
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2107
EP 2141
DI 10.1007/s11042-013-1491-z
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300003
DA 2024-07-18
ER

PT J
AU Altadmri, A
   Ahmed, A
AF Altadmri, Amjad
   Ahmed, Amr
TI A framework for automatic semantic video annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic video annotation; Video search engine; Video information
   retrieval; Commonsense knowledgebases; Semantic gap
ID VISUAL-SEARCH; CONCEPTNET; RETRIEVAL
AB The rapidly increasing quantity of publicly available videos has driven research into developing automatic tools for indexing, rating, searching and retrieval. Textual semantic representations, such as tagging, labelling and annotation, are often important factors in the process of indexing any video, because of their user-friendly way of representing the semantics appropriate for search and retrieval. Ideally, this annotation should be inspired by the human cognitive way of perceiving and of describing videos. The difference between the low-level visual contents and the corresponding human perception is referred to as the 'semantic gap'. Tackling this gap is even harder in the case of unconstrained videos, mainly due to the lack of any previous information about the analyzed video on the one hand, and the huge amount of generic knowledge required on the other. This paper introduces a framework for the Automatic Semantic Annotation of unconstrained videos. The proposed framework utilizes two non-domain-specific layers: low-level visual similarity matching, and an annotation analysis that employs commonsense knowledgebases. Commonsense ontology is created by incorporating multiple-structured semantic relationships. Experiments and black-box tests are carried out on standard video databases for action recognition and video information retrieval. White-box tests examine the performance of the individual intermediate layers of the framework, and the evaluation of the results and the statistical analysis show that integrating visual similarity matching with commonsense semantic relationships provides an effective approach to automated video annotation.
C1 [Altadmri, Amjad; Ahmed, Amr] Lincoln Univ, Sch Comp Sci, Lincoln, England.
C3 University of Lincoln
RP Altadmri, A (corresponding author), Lincoln Univ, Sch Comp Sci, Lincoln, England.
EM atadmri@lincoln.ac.uk; aahmed@lincoln.ac.uk
RI ; Ahmed, Amr/A-4585-2009
OI Altadmri, Amjad/0000-0002-9799-6638; Ahmed, Amr/0000-0002-7749-7911
CR Altadmri Amjad, 2009, 2009 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2009), P74, DOI 10.1109/ICSIPA.2009.5478723
   Altadmri A, 2009, IASTED INT C ART INT, V683, P34
   Altadmri A, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 3, P636, DOI 10.1109/ICICISYS.2009.5358084
   Amir A, 2004, COMPUT VIS IMAGE UND, V96, P216, DOI 10.1016/j.cviu.2004.02.006
   [Anonymous], 2007, PROC IEEE C COMPUT V
   [Anonymous], SEMANTIC MINING TECH
   Bagdanov AD, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P713, DOI 10.1109/ICSC.2007.30
   Basharat A, 2008, COMPUT VIS IMAGE UND, V110, P360, DOI 10.1016/j.cviu.2007.09.016
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Chandrasekaran B, 1999, IEEE INTELL SYST APP, V14, P20, DOI 10.1109/5254.747902
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng Y, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P534, DOI 10.1109/ICIP.1997.638826
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Fergus R, 2010, P IEEE, V98, P1453, DOI 10.1109/JPROC.2010.2048990
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83
   Haering N, 2000, IEEE T CIRC SYST VID, V10, P857, DOI 10.1109/76.867923
   Hauptmann AG, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P79, DOI 10.1109/ICSC.2007.68
   Hsu MH, 2008, LECT NOTES COMPUT SC, V4993, P213
   Ikizler N, 2007, LECT NOTES COMPUT SC, V4814, P271
   Jiang YG, 2010, IEEE T MULTIMEDIA, V12, P42, DOI 10.1109/TMM.2009.2036235
   Kapoor A, 2010, INT J COMPUT VISION, V88, P169, DOI 10.1007/s11263-009-0268-3
   LENAT DB, 1995, COMMUN ACM, V38, P33, DOI 10.1145/219717.219745
   Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Motulsky H.J., 1999, ANAL DATA GRAPHPAD P
   Ngo CW, 2009, TREC VID RETR EV WOR
   Over P, 2011, TRECVID 2010, P1
   Peijiang Yuan, 2008, 2008 IEEE International Conference on Data Mining Workshops, P847, DOI 10.1109/ICDMW.2008.114
   Shyu ML, 2008, IEEE T MULTIMEDIA, V10, P252, DOI 10.1109/TMM.2007.911830
   Siersdorfer S, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P395, DOI 10.1145/1571941.1572010
   Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111
   Smeaton AF, 2006, INFORM PROCESS MANAG, V42, P1330, DOI 10.1016/j.ipm.2005.11.003
   Stanford_NLP_Group, 2008, STANF NLP LOG LIN PA
   TrecVid, 2011, TREE VID RETR TRACK
   UCF_Computer_Vision_lab, 2011, UCF ACT DAT 11 11 20
   Ulges A, 2010, COMPUT VIS IMAGE UND, V114, P429, DOI 10.1016/j.cviu.2009.08.002
   Ventura C, 2012, LECT NOTES COMPUT SC, V7131, P652
   Wei XY, 2011, IEEE T CIRC SYST VID, V21, P62, DOI 10.1109/TCSVT.2011.2105597
   Zhao WL, 2010, IEEE T MULTIMEDIA, V12, P448, DOI 10.1109/TMM.2010.2050651
NR 44
TC 13
Z9 13
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1167
EP 1191
DI 10.1007/s11042-013-1363-6
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300008
DA 2024-07-18
ER

PT J
AU Kim, J
   Kim, S
   Yang, J
   Ryu, JH
   Wohn, K
AF Kim, Jonghak
   Kim, Sangtae
   Yang, Joonhyuk
   Ryu, Jung-hee
   Wohn, KwangYun
TI FaceCAPTCHA: a CAPTCHA that identifies the gender of face images
   unrecognized by existing gender classifiers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CAPTCHA; Crowdsourcing; Gender classification; Human computation; Image
   tagging; Web application
ID CLASSIFICATION; RECOGNITION
AB Computers tend to fail to classify human faces by gender, especially upon changes in viewpoint or upon occlusion that make it more difficult to extract the necessary image features. In contrast, humans are good at identifying gender but have difficulties in dealing with a large number of images. Accounting for this gap, we proposed FaceCAPTCHA, a novel image-based CAPTCHA that asks users to identify the gender of face images whose gender cannot be recognized by computers (gender-indiscernible faces). By converting the manual gender classification task into a CAPTCHA test, FaceCAPTCHA was designed to not only continuously identify the gender of gender-indiscernible faces but also differentiate between humans and computers and generate new test images. Our user studies showed that FaceCAPTCHA reliably identifies gender-indiscernible faces. A single eight-image FaceCAPTCHA test was completed in 12.41 s on average with a human success rate of 86.51 %, which can be further increased by filtering error-prone test images. In contrast, the probability of passing a FaceCAPTCHA test by random guessing was 0.006 %. We could therefore conclude that FaceCAPTCHA is robust against malicious attacks and easy enough for practical use.
C1 [Kim, Jonghak; Kim, Sangtae; Yang, Joonhyuk; Wohn, KwangYun] Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Taejon 305701, South Korea.
   [Ryu, Jung-hee] Olaworks Inc, Seoul, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Kim, J (corresponding author), Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, 291 Daehak Ro, Taejon 305701, South Korea.
EM defigner@kaist.ac.kr
RI Yang, Joonhyuk/A-5483-2009; Wohn, Kwangyun/C-2013-2011
OI Yang, Joonhyuk/0000-0002-2846-5868
CR Alexandre LA, 2010, PATTERN RECOGN LETT, V31, P1422, DOI 10.1016/j.patrec.2010.02.010
   [Anonymous], P SIGCHI C HUM FACT
   [Anonymous], 2011, P 2011 ANN C HUM FAC
   [Anonymous], ADV INT C TEL INT C
   Bekios-Calfa J, 2011, IEEE T PATTERN ANAL, V33, P858, DOI 10.1109/TPAMI.2010.208
   BROWN E, 1993, PERCEPTION, V22, P829, DOI 10.1068/p220829
   Chellapilla K., 2005, P SIGCHI C HUM FACT
   Chew M, 2004, P 7 INT INF SEC C PA
   Chow R., 2008, P HOTMOBILE
   Elson J., 2007, P 14 ACM C COMP COMM
   Goncalves D, 2008, CHI 08 EXT ABSTR HUM
   Gossweiler R., 2009, P 18 INT C WORLD WID
   Guanglei Sheng, 2012, 2012 Sixth International Conference on Internet Computing for Science and Engineering, P149, DOI 10.1109/ICICSE.2012.23
   Guo GD, 2010, LECT NOTES COMPUT SC, V5996, P236
   Kalsoom S, 2012, KSII T INTERNET INF, V6, P734, DOI 10.3837/tiis.2012.02.017
   Khot R. A., 2009, P 3 INT C US SOFTW I
   Kim JW, 2010, VISUAL COMPUT, V26, P1135, DOI 10.1007/s00371-010-0469-3
   Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48
   Lian XC, 2009, LECT NOTES COMPUT SC, V5507, P647, DOI 10.1007/978-3-642-03040-6_79
   MARLOW C, 2006, P 17 C HYP HYP OD DE
   Morrison D, 2009, P INT C MULT FIR IT
   Naaman M., 2004, P 12 ANN ACM INT C M
   Rui Y, 2004, MULTIMEDIA SYST, V9, P493, DOI 10.1007/s00530-003-0122-3
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Shakhnarovich G, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P16, DOI 10.1109/AFGR.2002.1004124
   Shan CF, 2012, PATTERN RECOGN LETT, V33, P431, DOI 10.1016/j.patrec.2011.05.016
   Thaler S, 2011, LECT NOTES COMPUT SC, V6644, P466, DOI 10.1007/978-3-642-21064-8_36
   Toews M, 2009, IEEE T PATTERN ANAL, V31, P1567, DOI 10.1109/TPAMI.2008.233
   Ueki K, 2004, INT C PATT RECOG, P446, DOI 10.1109/ICPR.2004.1333798
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   von Ahn L, 2003, LECT NOTES COMPUT SC, V2656, P294
   Von Ahn L., 2006, P SIGCHI C HUM FACT
   von Ahn L, 2008, SCIENCE, V321, P1465, DOI 10.1126/science.1160379
   VONAHN L, 2007, IEEE INT C AC SPEECH
   Wolf L, 2010, LECT NOTES COMPUT SC, V5995, P88
   Zheng J, 2011, NEUROCOMPUTING, V74, P1926, DOI 10.1016/j.neucom.2010.07.032
   Zhu B. B., 2010, P 17 ACM C COMP COMM
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 38
TC 8
Z9 8
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1215
EP 1237
DI 10.1007/s11042-013-1422-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300010
DA 2024-07-18
ER

PT J
AU Li, CY
   Ben Hamza, A
AF Li, Chunyuan
   Ben Hamza, A.
TI Symmetry discovery and retrieval of nonrigid 3D shapes using geodesic
   skeleton paths
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skeleton path; Symmetry discovery; Nonrigid 3D shapes; Retrieval
AB In this paper, we propose a skeleton path based approach for symmetry discovery and retrieval of nonrigid 3D shapes. The main idea is to match skeleton graphs by comparing the geodesic paths between skeleton endpoints. Our approach is motivated by the fact that the path feature is stable in the presence of articulation of components. The experimental results demonstrate the performance of our proposed method in terms of robustness to symmetry, discrimination against different graph structures, and high efficiency in the retrieval of nonrigid 3D shapes.
C1 [Li, Chunyuan; Ben Hamza, A.] Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ, Canada.
C3 Concordia University - Canada
RP Ben Hamza, A (corresponding author), Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ, Canada.
EM hamza@ciise.concordia.ca
RI Li, Chunyuan/AAG-1303-2020; li, chunyuan/IQW-1618-2023; Hamza,
   Abdessamad Ben/G-4571-2013
OI Ben Hamza, Abdessamad/0000-0002-3778-8167
CR Agathos A, 2009, P EUR S 3D OBJ RETR
   [Anonymous], SYMMETRY 3D GEOMETRY
   [Anonymous], 2011, PROC EUROGRAPHICS 20, P79, DOI DOI 10.2312/3DOR/3DOR11/079-088
   Au OKC, 2010, COMPUT GRAPH FORUM, V29, P645, DOI 10.1111/j.1467-8659.2009.01634.x
   Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   Bai X, 2008, IEEE T PATTERN ANAL, V30, P1282, DOI 10.1109/TPAMI.2007.70769
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Ben-Chen M., 2008, Proceedings of the 1st Eurographics Conference on 3D Object Retrieval, P1
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Cornea ND, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P366, DOI 10.1109/SMI.2005.1
   Cornea ND, 2005, VISUAL COMPUT, V21, P945, DOI 10.1007/s00371-005-0308-0
   Gebal K, 2009, COMPUT GRAPH FORUM, V28, P1405, DOI 10.1111/j.1467-8659.2009.01517.x
   Kazhdan M., 2003, Symposium on Geometry Processing, P156
   Kazhdan M, 2002, LECT NOTES COMPUT SC, V2351, P642
   Levy B., 2006, P IEEE INT C SHAP MO
   Liang Z., 2010, IEEE International Conference on Communications ICC, P1
   Ovsjanikov M, 2008, COMPUT GRAPH FORUM, V27, P1341, DOI 10.1111/j.1467-8659.2008.01273.x
   Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011
   Reuter M, 2010, INT J COMPUT VISION, V89, P287, DOI 10.1007/s11263-009-0278-1
   Rustamov Raif M, 2007, P S GEOM PROC, V257, P225
   Sfikas K, 2012, VISUAL COMPUT, V28, P943, DOI 10.1007/s00371-012-0714-z
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   SHINAGAWA Y, 1991, IEEE COMPUT GRAPH, V11, P66, DOI 10.1109/38.90568
   Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703
   Siddiqi K, 2008, MACH VISION APPL, V19, P261, DOI 10.1007/s00138-007-0097-8
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609
   Wang YS, 2008, IEEE T VIS COMPUT GR, V14, P926, DOI 10.1109/TVCG.2008.38
   Wu HY, 2010, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2010.5540180
NR 31
TC 8
Z9 10
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1027
EP 1047
DI 10.1007/s11042-013-1417-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300002
DA 2024-07-18
ER

PT J
AU Hare, JS
   Samangooei, S
   Lewis, PH
AF Hare, Jonathon S.
   Samangooei, Sina
   Lewis, Paul H.
TI Practical scalable image analysis and indexing using Hadoop
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MapReduce; Hadoop; Bag of visual words; Image retrieval
ID SCALE
AB The ability to handle very large amounts of image data is important for image analysis, indexing and retrieval applications. Sadly, in the literature, scalability aspects are often ignored or glanced over, especially with respect to the intricacies of actual implementation details. In this paper we present a case-study showing how a standard bag-of-visual-words image indexing pipeline can be scaled across a distributed cluster of machines. In order to achieve scalability, we investigate the optimal combination of hybridisations of the MapReduce distributed computational framework which allows the components of the analysis and indexing pipeline to be effectively mapped and run on modern server hardware. We then demonstrate the scalability of the approach practically with a set of image analysis and indexing tools built on top of the Apache Hadoop MapReduce framework. The tools used for our experiments are freely available as open-source software, and the paper fully describes the nuances of their implementation.
C1 [Hare, Jonathon S.; Samangooei, Sina; Lewis, Paul H.] Univ Southampton, Sch Elect & Comp Sci, Southampton SO17 1BJ, Hants, England.
C3 University of Southampton
RP Samangooei, S (corresponding author), Univ Southampton, Sch Elect & Comp Sci, Southampton SO17 1BJ, Hants, England.
EM jsh2@ecs.soton.ac.uk; ss@ecs.soton.ac.uk; phl@ecs.soton.ac.uk
OI Hare, Jonathon/0000-0003-2921-4283
FU European Union [270239, 231126, 287863]; LiveMemories project -
   Autonomous Province of Trento (Italy)
FX The development of the tools and techniques described in this paper was
   funded by the European Union Seventh Framework Programme (FP7/2007-2013)
   under grant agreements no 270239 (ARCOMEM), 231126 (LivingKnowledge) and
   287863 (TrendMiner) together with the LiveMemories project, graciously
   funded by the Autonomous Province of Trento (Italy).
CR Akram Hasan Ibne, 2010, NIPS WORKSH LEARN CO
   Ananthanarayanan R., 2009, P C HIGH PERF COMP
   [Anonymous], 2006, Advances in neural information processing systems
   [Anonymous], 2008, ICML
   [Anonymous], 2010, Parallel Distributed Processing, Workshops and Phd Forum (IPDPSW), 2010 IEEE International Symposium on
   [Anonymous], THESIS U OXFORD
   [Anonymous], INT S PERF AN SYST S
   [Anonymous], RECENT ADV PARALLEL
   [Anonymous], AM EL COMP CLOUD AM
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Asanovic Krste, 2006, The Landscape of Parallel Computing Research: A View from Berkeley
   Bornschein J, 2009, NIPS WORKSH LEARN CO
   Cadambi S, 2009, ANN IEEE SYM FIELD P, P115, DOI 10.1109/FCCM.2009.34
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Coates A, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P4287, DOI 10.1109/IROS.2009.5354084
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Dean J., 2009, WSDM 09 P 2 ACM INT, V10, DOI [10.1145/1498759.1498761.No.1498759.1498761, DOI 10.1145/1498759.1498761, 10.1145/1498759.1498761]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Farivar R., 2009, PROC IEEE INT C CLUS, P1
   Ghoting A, 2011, PROC INT CONF DATA, P231, DOI 10.1109/ICDE.2011.5767930
   Graf H.P., 2004, NIPS
   Hamada T., 2007, The Chamomile Scheme: An optimized algorithm for N-body simulations on programmable graphics processing units
   Hare J, 2012, ACM INT C MULT RETR
   Hare J, 2011, ACM INT C MULT RETR
   Hare J.S., 2011, Proceedings of the 19th ACM International Conference on Multimedia, P691, DOI 10.1145/2072298.2072421
   Heinz S, 2003, J AM SOC INF SCI TEC, V54, P713, DOI 10.1002/asi.10268
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MacQueen J, 1965, P 5 BER S MATH STAT, P281
   Matas J., 2002, BMVC
   McCreadie R, 2012, INFORM PROCESS MANAG, V48, P873, DOI 10.1016/j.ipm.2010.12.003
   Message Passing Interface Forum, 2021, MPI: A message-passing interface standard version 4.0
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2003, PROC CVPR IEEE, P257
   Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   O'Hara S., 2011, CoRR
   Raina R., 2009, ICML, P1
   Rice KL, 2009, J SUPERCOMPUT, V47, P21, DOI 10.1007/s11227-008-0195-z
   Shan Y, 2010, FPGA 10, P93
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Subramanya A, 2009, NIPS WORKSH LEARN CO
   White B., 2010, MDMKDD, P9
   Xu NY, 2009, ACM T RECONFIG TECHN, V1, P19
   Ye J., 2009, P 18 ACM C INF KNOWL, P2061, DOI [10.1145/1645953.1646301, DOI 10.1145/1645953.1646301]
   Yibin Li, 2009, 2009 IEEE International Conference on Automation and Logistics (ICAL), P1957, DOI 10.1109/ICAL.2009.5262626
NR 49
TC 7
Z9 7
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1215
EP 1248
DI 10.1007/s11042-012-1256-0
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000012
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Jung, KH
   Yoo, KY
AF Jung, Ki-Hyun
   Yoo, Kee-Young
TI Data hiding using edge detector for scalable images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Interpolation; Edge detection; Steganography
ID INTERPOLATION; IMPLEMENTATION; ROTATION; SCHEME
AB In this paper we propose a data hiding method that utilizes image interpolation and an edge detection algorithm. Image interpolation algorithm enlarges a cover image before hiding secret data in order to embed a large amount of secret data. Edge detection algorithm is applied to improve a quality of stego-image. Experimental results show that the proposed method can embed a large amount of secret data while keeping visual quality better than previous works. We demonstrate that the average capacity is 391,115bits, and the PSNR and quality index are 44.71dB, 0.9568 for gray images when threshold value is 4 and the embedding bits are given to 2 respectively.
C1 [Jung, Ki-Hyun] Yeungjin Coll, Sch Comp Informat, Taegu 702721, South Korea.
   [Yoo, Kee-Young] Kyungpook Natl Univ, Sch Comp Sci & Engn, Taegu 702701, South Korea.
C3 Kyungpook National University
RP Jung, KH (corresponding author), Yeungjin Coll, Sch Comp Informat, 218 Bokhyun Dong, Taegu 702721, South Korea.
EM kingjung@paran.com; yook.knu@gmail.com
FU National Research Foundation of Korea [21A20131600005] Funding Source:
   Korea Institute of Science & Technology Information (KISTI), National
   Science & Technology Information Service (NTIS)
CR Awrangjeb M, 2003, P 6 INT C COMP INF T, P75
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Celik MU, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P157
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2000, PROCEEDINGS OF THE FIFTH JOINT CONFERENCE ON INFORMATION SCIENCES, VOLS 1 AND 2, pA448
   Chang CC, 2002, INT J PATTERN RECOGN, V16, P399, DOI 10.1142/S0218001402001770
   Chen TS, 1998, IEEE T IMAGE PROCESS, V7, P1485, DOI 10.1109/83.718488
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   DANIELSSON PE, 1992, CVGIP-GRAPH MODEL IM, V54, P340, DOI 10.1016/1049-9652(92)90080-H
   Davis L.S., 1975, Comput. Graph. Image Process, V4, P248, DOI DOI 10.1016/0146-664X(75)90012-X
   De Vleeschouwer C, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P345, DOI 10.1109/MMSP.2001.962758
   Delcroix C. J., 1988, Proceedings of the SPIE - The International Society for Optical Engineering, V1001, P545, DOI 10.1117/12.968997
   DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9
   Evans OD, 1998, REAL-TIME IMAGING, V4, P417, DOI 10.1006/rtim.1998.7010
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Fridrich J, 2001, P 4 INF HID WORKSH P, V2137, P27
   GEMAN D, 1987, IMAGE VISION COMPUT, V5, P61, DOI 10.1016/0262-8856(87)90028-X
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Hsiao JY, 2009, SIGNAL PROCESS, V89, P556, DOI 10.1016/j.sigpro.2008.10.018
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Lee CC, 2008, PATTERN RECOGN, V41, P2097, DOI 10.1016/j.patcog.2007.11.018
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Macq B., 1999, TRUST HEAD MED IM DF
   MAELAND E, 1988, IEEE T MED IMAGING, V7, P213, DOI 10.1109/42.7784
   NEVATIA R, 1977, IEEE T SYST MAN CYB, V7, P820
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Parker J, 1983, IEEE Trans Med Imaging, V2, P31, DOI 10.1109/TMI.1983.4307610
   Pei SC, 1999, IEEE T IMAGE PROCESS, V8, P614, DOI 10.1109/83.760310
   Rowland S. W., 1979, Image reconstruction from projections. Implementation and applications, P9
   SCHULTZ RR, 1994, IEEE T IMAGE PROCESS, V3, P233, DOI 10.1109/83.287017
   Swanson MD, 1998, P IEEE, V86, P1064, DOI 10.1109/5.687830
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thien CC, 2003, PATTERN RECOGN, V36, P2875, DOI 10.1016/S0031-3203(03)00221-8
   Thurnhofer S, 1996, OPT ENG, V35, P1862, DOI 10.1117/1.600619
   Tsai P, 2002, REAL-TIME IMAGING, V8, P329, DOI 10.1006/rtim.2001.0286
   UNSER M, 1991, IEEE T PATTERN ANAL, V13, P277, DOI 10.1109/34.75515
   UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1371, DOI 10.1109/83.465102
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Xuan GR, 2002, ELECTRON LETT, V38, P1646, DOI 10.1049/el:20021131
   Yang CK, 1996, PATTERN RECOGN LETT, V17, P481, DOI 10.1016/0167-8655(95)00112-3
NR 44
TC 18
Z9 19
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1455
EP 1468
DI 10.1007/s11042-012-1293-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000022
DA 2024-07-18
ER

PT J
AU Guna, J
   Stojmenova, E
   Lugmayr, A
   Humar, I
   Pogacnik, M
AF Guna, Joze
   Stojmenova, Emilija
   Lugmayr, Artur
   Humar, Iztok
   Pogacnik, Matevz
TI User identification approach based on simple gestures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Accelerometer; Gesture; Human-computer interaction; Non-invasive; User
   identification
ID RECOGNITION; SYSTEMS
AB We present an intuitive, implicit, gesture based identification system suited for applications such as the user login to home multimedia services, with less strict security requirements. The term "implicit gesture" in this work refers to a natural physical hand manipulation of the control device performed by the user, who picks it up from its neutral motionless position or shakes it. For reference with other related systems, explicit and well defined identification gestures were used. Gestures were acquired by an accelerometer sensor equipped device in a form of the Nintendo WiiMote remote controller. A dynamic time warping method is used at the core of our gesture based identification system. To significantly increase the computational efficiency and temporal stability, the "super-gesture" concept was introduced, where acceleration features of multiple gestures are combined in only one super-gesture template per each user. User evaluation spanning over a period of 10 days and including 10 participants was conducted. User evaluation study results show that our algorithm ensures nearly 100 % recognition accuracy when using explicit identification signature gestures and between 88 % and 77 % recognition accuracy when the system needs to distinguish between 5 and 10 users, using the implicit "pick-up" gesture. Performance of the proposed system is comparable to the results of other related works when using explicit identification gestures, while showing that implicit gesture based identification is also possible and viable.
C1 [Guna, Joze; Stojmenova, Emilija; Humar, Iztok; Pogacnik, Matevz] Univ Ljubljana, Fac Elect Engn, Ljubljana 1000, Slovenia.
   [Lugmayr, Artur] Tampere Univ Technol, Dept Business Informat Management & Logist, EMMi Entertainment & Media Management Lab, FIN-33101 Tampere, Finland.
C3 University of Ljubljana; Tampere University
RP Guna, J (corresponding author), Univ Ljubljana, Fac Elect Engn, Trzaska 25, Ljubljana 1000, Slovenia.
EM joze.guna@fe.uni-lj.si
RI Lugmayr, Artur/AAY-7738-2020; Guna, Jože/AAO-8714-2020; Lugmayr,
   Artur/G-4357-2014
OI Guna, Jože/0000-0002-5161-7751; Lugmayr, Artur/0000-0001-6994-4470;
   Pogacnik, Matevz/0000-0002-6134-2827
FU European Union, European Social Fund; Slovenian research Agency
   [P2-0246]
FX The operation that led to this paper is partially financed by the
   European Union, European Social Fund and the Slovenian research Agency,
   grant No. P2-0246. The authors also thank the participants who took part
   in the evaluation study.
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   [Anonymous], P 5 INT WORKSH SEM A
   [Anonymous], 2008, HDB BIOMETRICS
   Cho SJ, 2004, P 9 INT WORKSH FRONT
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jun-qi K, 2009, P 2009 4 INT C COMP
   Kela J, 2006, PERS UBIQUIT COMPUT, V10, P285, DOI 10.1007/s00779-005-0033-8
   Keogh E, 2001, P 1 INT SIAM INT C D
   Liu J, 2009, P ACM INT C HUM COMP
   Liu J., 2009, P IEEE INT C PERV CO, P1
   Lugmayr A, 2009, HDB RES SYNTHETIC EM, P443
   Maltoni D, 2009, HDB FINGERPRINT RECO, VXVI, P496
   Matsuo K, 2007, P INT BIOM
   Montpetit M-J, 2010, Journal of Communications, V5, P358, DOI 10.4304/jcm.5.5.358-373
   Nabti M, 2008, PATTERN RECOGN, V41, P868, DOI 10.1016/j.patcog.2007.06.030
   Okumura F, 2006, P INT S INT SIGN PRO
   Orozco M, 2008, MULTIMED TOOLS APPL, V37, P73, DOI 10.1007/s11042-007-0169-9
   Schlmer T., 2008, Second International Conference on Tangible and Embedded Interaction, P11, DOI [DOI 10.1145/1347390.1347395, 10.1145/1347390.1347395]
   Sedlar U, 2008, IEEE COMMUN MAG, V46, P118, DOI 10.1109/MCOM.2008.4463782
   Toledano DT, 2006, INTERACT COMPUT, V18, P1101, DOI 10.1016/j.intcom.2006.01.004
   Varchol P, 2007, RADIOENGINEERING, V16, P82
   Varona J, 2009, INTERACT COMPUT, V21, P3, DOI 10.1016/j.intcom.2008.10.001
   Volk M, 2010, IEEE COMMUN MAG, V48, P126, DOI 10.1109/MCOM.2010.5534597
   Zaharis A, 2010, MOB LIGHTW WIR SYST
   Zappi P, 2009, ENTERTAIN COMPUT, V1, P75, DOI 10.1016/j.entcom.2009.09.005
NR 25
TC 5
Z9 8
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 1
BP 179
EP 194
DI 10.1007/s11042-013-1635-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK0QX
UT WOS:000338120700009
DA 2024-07-18
ER

PT J
AU Jiang, H
   Guo, SX
   Meng, SM
   Luo, XN
AF Jiang, Hao
   Guo, Shuxu
   Meng, Siming
   Luo, Xiaonan
TI 3D video components generation using object tracking technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 2D-to-3D conversion; Object tracking; Depth map; 3D sequence
AB 2D-to-3D conversion that would be a solution of the lack of 3D contents has been a worthy and challenging research field. In this paper, we propose a computer interactive conversion method to capture components which is used to generate 3D sequences. First, we divide the key frame into foreground and background, and then label the objects by convenient computer interactive operation. Depth information of objects is labeled after segmentation. Second, we use object tracking technique which synthesizes the advantages of kernel-based mean shift tracker and contour tracker to accomplish object depth capture for non-key frame. Finally, all the 3D information is prepared to render 3D sequences. After all, we propose our future work direction: a 2D-to-3D system which can generate 3D sequence interactively.
C1 [Jiang, Hao; Guo, Shuxu] Jilin Univ, Coll Elect Sci & Engn, Changchun 130012, Peoples R China.
   [Jiang, Hao; Meng, Siming; Luo, Xiaonan] Sun Yat Sen Univ, Natl Engn Res Ctr Digital Life, State Prov Joint Lab Digital Home Interact Applic, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Luo, Xiaonan] Sun Yat Sen Univ, Shenzhen Digital Home Key Technol Engn Lab, Shenzhen 518057, Peoples R China.
C3 Jilin University; Sun Yat Sen University; Sun Yat Sen University
RP Guo, SX (corresponding author), Jilin Univ, Coll Elect Sci & Engn, Changchun 130012, Peoples R China.
EM guosx@jlu.edu.cn; mengsm_zsu@163.com
FU National Key Basic Research and Development Program of China (973)
   [2013CB329505]; National Natural Science Foundation of China [61232011];
   NSFC-Guangdong Joint Fund [U0935004, U1201252]; National Key Technology
   RD Program [2011BAH27B01, 2011BHA16B08]
FX This research is supported by the National Key Basic Research and
   Development Program of China (973)(No. 2013CB329505), the National
   Natural Science Foundation of China (61232011), NSFC-Guangdong Joint
   Fund (No. U0935004, U1201252), the National Key Technology R&D Program
   (No. 2011BAH27B01, 2011BHA16B08).
CR [Anonymous], ACM SIGGRAPH
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chen WY, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1315
   Cheng CC, 2009, 2009 INT C CONS EL I, P10
   CHENG CC, 2009, P SPIE, V7237
   Fehn C., 2004, P SPIE, V5291
   Goesele M, 2007, IEEE I CONF COMP VIS, P825, DOI 10.1109/iccv.2007.4408933
   Guanbin Li, 2011, 2011 International Conference on Multimedia Technology, P3643
   Guttmann M, 2009, IEEE I CONF COMP VIS, P136, DOI 10.1109/ICCV.2009.5459158
   Harman P, 2002, PROC SPIE, V4660, P78, DOI 10.1117/12.468020
   Kim D, 2008, IEEE T BROADCAST, V54, P188, DOI 10.1109/TBC.2007.914714
   Kim J, 2011, 2011 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING (PACRIM), P358, DOI 10.1109/PACRIM.2011.6032919
   KIM M, 2005, P SPIE, V6016
   KIM M, 1998, P SPIE, V3295
   KNORR S, 2006, P 3DPVT
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Matsumoto Y, 1997, P SOC PHOTO-OPT INS, V3012, P108, DOI 10.1117/12.274446
   Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a
   ROTEM E, 2005, P SPIE, V5664
   Saxena A, 2007, IEEE I CONF COMP VIS, P1
   Tam WJ, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1869, DOI 10.1109/ICME.2006.262919
   Tsai YM, 2006, I S INTELL SIG PROC, P541
   XU F, 2008, IEEE 3DTV C
   Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96
   Zhang L, 2011, IEEE T BROADCAST, V57
   Zhang Liang, 2005, 2 IEE EUR C VIS MED, P122
NR 27
TC 0
Z9 0
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 435
EP 449
DI 10.1007/s11042-013-1451-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400004
DA 2024-07-18
ER

PT J
AU Chatzichristofis, SA
   Iakovidou, C
   Boutalis, YS
   Angelopoulou, E
AF Chatzichristofis, Savvas A.
   Iakovidou, Chryssanthi
   Boutalis, Yiannis S.
   Angelopoulou, Elli
TI Mean Normalized Retrieval Order (MNRO): a new content-based image
   retrieval performance measure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval performance measures; Mean Average Precision; Average
   Normalized Modified Retrieval Rank
ID FEATURES; COLOR; DESCRIPTORS; PRECISION; GRAPHS
AB The results of a content based image retrieval system can be evaluated by several performance measures, each one employing different evaluation criteria. Many of the methods used in the field of information retrieval have been adopted for use in image retrieval systems. This paper reviews the most widely used performance measures for retrieval evaluation with particular emphasis on the assumptions made during their design. More specifically, it focuses on the design principles of the commonly used Mean Average Precision (MAP) and Average Normalized Modified Retrieval Rank (ANMRR), pinpointing their limitations. It also proposes a new performance measure for image retrieval systems, the Mean Normalized Retrieval Order (MNRO), whose effectiveness is demonstrated through a wide range of experiments. Initial experiments were conducted on artificially produced query trials and evaluations. Experiments on a large database demonstrate the ability of MNRO to take into account the generality of the queries during the retrieval procedure. Furthermore, the results of a case study show that the proposed performance measure is closer to human evaluations, in comparison to MAP and ANMRR. Lastly, in order to encourage researchers and practitioners to use the proposed performance measure, we present the experimental results produced by a large number of state of the art descriptors applied on three well-known benchmarking databases.
C1 [Chatzichristofis, Savvas A.; Iakovidou, Chryssanthi; Boutalis, Yiannis S.] Democritus Univ Thrace, Dept Elect & Comp Engn, GR-67100 Xanthi, Greece.
   [Boutalis, Yiannis S.] Univ Erlangen Nurnberg, Dept Elect Elect & Commun Engn, D-91058 Erlangen, Germany.
   [Angelopoulou, Elli] Univ Erlangen Nurnberg, Pattern Recognit Lab, Dept Comp Sci, D-91054 Erlangen, Germany.
C3 Democritus University of Thrace; University of Erlangen Nuremberg;
   University of Erlangen Nuremberg
RP Chatzichristofis, SA (corresponding author), Democritus Univ Thrace, Dept Elect & Comp Engn, GR-67100 Xanthi, Greece.
EM schatzic@ee.duth.gr; ciakovid@ee.duth.gr; ybout@ee.duth.gr;
   elli@immd5.informatik.uni-erlangen.de
RI Chatzichristofis, Savvas/AAA-2698-2020
OI Chatzichristofis, Savvas/0000-0002-4657-4435
FU European Union (European Social Fund-ESF); Greek national funds through
   the Operational Program "Education and Lifelong Learning" of the
   National Strategic Reference Framework (NSRF)-Research Funding Program:
   Heracleitus II. Investing in knowledge society through the European
   Social Fund
FX This research has been co-financed by the European Union (European
   Social Fund-ESF) and Greek national funds through the Operational
   Program "Education and Lifelong Learning" of the National Strategic
   Reference Framework (NSRF)-Research Funding Program: Heracleitus II.
   Investing in knowledge society through the European Social Fund.
CR [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   [Anonymous], 2005, INTRO PRACTICE STAT
   [Anonymous], 1997, Image Databases and Multi-Media Search, DOI DOI 10.1142/9789812797988_
   Arampatzis A, 2011, LECT NOTES COMPUT SC, V6611, P326, DOI 10.1007/978-3-642-20161-5_33
   Arevalillo-Herráez M, 2008, SIGNAL PROCESS-IMAGE, V23, P490, DOI 10.1016/j.image.2008.04.016
   Aslam J. A., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P27, DOI 10.1145/1076034.1076042
   Borghesani D, 2009, LECT NOTES COMPUT SC, V5716, P902, DOI 10.1007/978-3-642-04146-4_96
   BOSTEELS K, 2007, FUZZY AUDIO SIMILARI, P361
   CHATZICHRISTOFI.SA, 2010, 6 IASTED INT C ADV C, P27
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Chatzichristofis SA, 2010, RADIOENGINEERING, V19, P725
   Chatzichristofis SA, 2010, ICAART 2010: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL 1: ARTIFICIAL INTELLIGENCE, P58
   Chatzichristofis SA, 2009, SISAP 2009: 2009 SECOND INTERNATIONAL WORKSHOP ON SIMILARITY SEARCH AND APPLICATIONS, PROCEEDINGS, P151, DOI 10.1109/SISAP.2009.16
   Chatzichristofis SA, 2010, INT J PATTERN RECOGN, V24, P207, DOI 10.1142/S0218001410007890
   Chatzichristofis SA, 2010, MULTIMED TOOLS APPL, V46, P493, DOI 10.1007/s11042-009-0349-x
   Choi Y, 2003, J AM SOC INF SCI TEC, V54, P498, DOI 10.1002/asi.10237
   Croft W. B., 2009, SEARCH ENGINES INFOR
   d'Onofrio A, 2011, MATH BIOSCI, V230, P45, DOI 10.1016/j.mbs.2011.01.001
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Davidson R., 2000, Econometric Reviews, V19, P55, DOI [10.1080/07474930008800459, DOI 10.1080/07474930008800459]
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Eidenberger H, 2007, MULTIMED TOOLS APPL, V35, P241, DOI 10.1007/s1142-007-0106-y
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Gompertz B., 1825, PHILOS T ROY SOC LON, V36, P513, DOI https://doi.org/10.1098/rstl.1825.0026
   Huang J., 2001, US Patent, Patent No. [6,246,790, 6246790]
   Huijsmans DP, 2005, IEEE T PATTERN ANAL, V27, P245, DOI 10.1109/TPAMI.2005.30
   Huijsmans DP, 2001, PROC CVPR IEEE, P26
   Huiskes MarkJ., 2010, Multimedia Information Retrieval, P527
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Jose J. M., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P232, DOI 10.1145/290941.291000
   Kraaij W., 1996, SIGIR Forum, P40
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   LUPU M, 2009, 18 TEXT RETRIEVAL C
   MacDonald C., 2009, 18 TEXT RETRIEVAL C
   Magdy W, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P611
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Martinet J, 2008, MULTIMED TOOLS APPL, V39, P263, DOI 10.1007/s11042-008-0200-9
   Martinet J, 2011, INFORM PROCESS MANAG, V47, P391, DOI 10.1016/j.ipm.2010.10.003
   McDonald S., 2001, SIGIR Forum, P232
   MENG X, 2006, ITNG, P578
   *MPEG, 2000, M6029 ISOWG11
   Müller H, 2002, LECT NOTES COMPUT SC, V2383, P38
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   MULLER H, 2005, ACM MULTIMEDIA, P1014
   Muller H., 2010, ImageCLEF: Experimental Evaluation in Visual Information Retrieval, V1st
   Nister David, 2006, CVPR
   Ohm J.-R., 2001, Computer Analysis of Images and Patterns. 9th International Conference, CAIP 2001. Proceedings (Lecture Notes in Computer Science Vol.2124), P2
   Popescu A., 2010, CLEF NOTEBOOK PAPERS
   RAGHAVAN VV, 1989, ACM T INFORM SYST, V7, P205, DOI 10.1145/65943.65945
   ROBERTSON S, 2008, SIGIR, P689
   Robertson SE, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P603
   Sakai T, 2008, INFORM RETRIEVAL, V11, P447, DOI 10.1007/s10791-008-9059-7
   Salton G., 1971, SMART RETRIEVAL SYST
   Sanderson M, 2010, INFORM RETRIEVAL SER, V32, P81, DOI 10.1007/978-3-642-15181-1_5
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   Smith JR, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P112, DOI 10.1109/IVL.1998.694520
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Taneva Bilyana., 2010, Proceedings of the third ACM international conference on Web search and data mining, P431
   Thomee B., 2010, P INT C MULTIMEDIA M, P1473
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wong KM, 2005, IEEE INT SYMP CIRC S, P1541
   Wu Z, 2011, IEEE T PATTERN ANAL, V33, P1991, DOI 10.1109/TPAMI.2011.111
   Yilmaz E, 2008, KNOWL INF SYST, V16, P173, DOI 10.1007/s10115-007-0101-7
   YUE Y, 2007, SIGIR 07, P271
   Zagoris K, 2009, SISAP 2009: 2009 SECOND INTERNATIONAL WORKSHOP ON SIMILARITY SEARCH AND APPLICATIONS, PROCEEDINGS, P154, DOI 10.1109/SISAP.2009.15
NR 66
TC 16
Z9 18
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1767
EP 1798
DI 10.1007/s11042-012-1192-z
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500019
DA 2024-07-18
ER

PT J
AU Mazurczyk, W
   Szaga, P
   Szczypiorski, K
AF Mazurczyk, Wojciech
   Szaga, Pawel
   Szczypiorski, Krzysztof
TI Using transcoding for hidden communication in IP telephony
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IP telephony; Network steganography; TranSteg; Information hiding
ID COVERT CHANNELS; STEGANOGRAPHY
AB The paper presents a new steganographic method for IP telephony called TranSteg (Transcoding Steganography). Typically, in steganographic communication it is advised for covert data to be compressed in order to limit its size. In TranSteg it is the overt data that is compressed to make space for the steganogram. The main innovation of TranSteg is to, for a chosen voice stream, find a codec that will result in a similar voice quality but smaller voice payload size than the originally selected. Then, the voice stream is transcoded. At this step the original voice payload size is intentionally unaltered and the change of the codec is not indicated. Instead, after placing the transcoded voice payload, the remaining free space is filled with hidden data. TranSteg proof of concept implementation was designed and developed. The obtained experimental results are enclosed in this paper. They prove that the proposed method is feasible and offers a high steganographic bandwidth while introducing small voice degradation. Moreover, TranSteg detection is difficult to perform when compared with existing VoIP steganography methods.
C1 [Mazurczyk, Wojciech; Szaga, Pawel; Szczypiorski, Krzysztof] Warsaw Univ Technol, Inst Telecommun, PL-00665 Warsaw, Poland.
C3 Warsaw University of Technology
RP Mazurczyk, W (corresponding author), Warsaw Univ Technol, Inst Telecommun, Nowowiejska 15-19, PL-00665 Warsaw, Poland.
EM wmazurczyk@tele.pw.edu.pl; P.Szaga@stud.elka.pw.edu.pl;
   ksz@tele.pw.edu.pl
RI Szczypiorski, Krzysztof/A-9664-2012
OI Szczypiorski, Krzysztof/0000-0001-8638-8584
FU Polish Ministry of Science and Higher Education; Polish National Science
   Centre [0349/IP2/2011/71, 2011/01/D/ST7/05054]
FX This work was supported by the Polish Ministry of Science and Higher
   Education and Polish National Science Centre under grants:
   0349/IP2/2011/71 and 2011/01/D/ST7/05054.
CR [Anonymous], 2001, ITU T REC P 862 PERC
   [Anonymous], P IEEE S SEC PRIV
   [Anonymous], 2007, ITU T REC P 862 3 AP
   [Anonymous], P 3 INT C SEC PRIV C
   [Anonymous], 2007, Technical report
   [Anonymous], P IEEE INT S CIRC SY
   [Anonymous], 2002, P ACM WORKSH MULT SE
   [Anonymous], IEEE INT S CIRC SYST
   [Anonymous], 2009, IEEE INT C COMM 2009
   [Anonymous], 2004, 3711 RFC
   [Anonymous], INT C INT INF HID MU
   Aoki N, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P608, DOI 10.1109/IIH-MSP.2008.122
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Dittmann J, 2005, P SOC PHOTO-OPT INS, V5681, P607, DOI 10.1117/12.586579
   Fisk G, 2003, LECT NOTES COMPUT SC, V2578, P18
   Forbes Christopher R., THESIS ROCHESTER I T
   Fraczek W, J UNIVERSAL COMPUTER
   Fridrich J, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P223, DOI 10.1109/ITCC.2001.918795
   Garofolo John, 1993, TIMIT ACOUSTIC PHONE
   Guha S, 2006, 6 INT WORKSH PEER PE
   Hamdaqa M., 2011, Proceedings of the 2011 Fifth International Conference on Secure Software Integration and Reliability Improvement (SSIRI 2011), P189, DOI 10.1109/SSIRI.2011.24
   Huang YF, 2011, IEEE T INF FOREN SEC, V6, P296, DOI 10.1109/TIFS.2011.2108649
   *ITU T, 2002, G107 ITUT
   ITU-T, 1996, ITU T REC P 800 METH
   ITU-T Recommendation G.114,, 2003, G114 ONE WAY TRANSMI
   Lee W, 2009, EUR T TELECOMMUN, V20, P594, DOI 10.1002/ett.1334
   Lubacz J, 2010, IEEE SPECTRUM, V47, P42, DOI 10.1109/MSPEC.2010.5397787
   Mazurczyk W., 2006, P 5 INT C COMP SCI R
   Mazurczyk W, INT J SECURITY COMMU, DOI [10.1002/sec.502, DOI 10.1002/SEC.502]
   Mazurczyk W, 2010, TELECOMMUNICATION SY, V45
   Mazurczyk W, 2008, COMM COM INF SC, V12, P65
   Mazurczyk W, 2008, LECT NOTES COMPUT SC, V5332, P1001
   Miao R, 2011, IEEE ICC
   Mills D., 2010, RFC 5905
   Murdoch SJ, 2005, LECT NOTES COMPUT SC, V3727, P247
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P247, DOI 10.1109/TIFS.2008.922456
   Schooler E., 2002, 3261 RFC
   Schulzrinne H., 2003, RTP TRANSPORT PROTOC
   SIMMONS GJ, 1994, EUR T TELECOMMUN, V5, P459
   Wang CY, 2007, IEEE INT SYM MULTIM, P255, DOI 10.1109/ISM.2007.33
   Zander S, 2007, IEEE COMMUN SURV TUT, V9, P44, DOI 10.1109/COMST.2007.4317620
   Zhou YG, 2007, EUR T TELECOMMUN, V18, P661, DOI 10.1002/ett.1168
NR 42
TC 51
Z9 54
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 2139
EP 2165
DI 10.1007/s11042-012-1224-8
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500034
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Ge, Y
   Yin, BC
   Sun, YF
   Jing, GD
AF Ge, Yun
   Yin, Bao-cai
   Sun, Yan-feng
   Jing, Guo-dong
TI Expansion of 3D face sample set based on genetic algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D face database; Sample expansion; Surface deformation; Texture
   stitching
AB 3D face database is an important data platform for model training and algorithm design. As these works are mainly based on statistical learning, the coverage of training set has a great impact on algorithm performance. However it is a tedious process to obtain a 3D face sample. So the capacities of current 3D face databases are relatively insufficient. To solve this problem, we present a framework to augment existing 3D databases based on Genetic Algorithm. First the prototypical face samples are divided into patches. Then the new face samples are generated by assembling randomly selected patches. Under the guidance of the genetic algorithm, we can perform a number of the generating works at a time. The experiment results show that the proposed method has good performance on face data expansion.
C1 [Ge, Yun; Yin, Bao-cai; Sun, Yan-feng; Jing, Guo-dong] Beijing Univ Technol, Beijing Municipal Key Lab Multimedia & Intelligen, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Sun, YF (corresponding author), Beijing Univ Technol, Beijing Municipal Key Lab Multimedia & Intelligen, Beijing 100124, Peoples R China.
EM geyun@emails.bjut.edu.cn; ybc@bjut.edu.cn; yfsun@bjut.edu.cn;
   jingguodong@emails.bjut.edu.cn
FU National Natural Science Foundation of China [60973057, 60825203,
   61133003, 61171169]; Guangdong Provincial Science and Technology project
   [2010A090100019]
FX This paper is supported by the National Natural Science Foundation of
   China (N0.60973057, 60825203, 61133003, 61171169), Guangdong Provincial
   Science and Technology project (2010A090100019).
CR [Anonymous], P 2 INT C AUD VID BA
   [Anonymous], IEEE C AUT FAC GEST
   [Anonymous], INT C MACH LEARN
   [Anonymous], CONSTRUCTIVE THEORY
   [Anonymous], SIGGRAPH 96 NEW ORL
   [Anonymous], 1990, GEN TOPOLOGY
   [Anonymous], INTELLIGENT CONTROL
   [Anonymous], 2 COST WORKSH BIOM I
   [Anonymous], IEEE COMP SOC C COMP
   [Anonymous], ACM T GRAPHIC
   [Anonymous], 1996, MACHINE LEARNING
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Davison A. C., 1997, BOOTSTRAP METHODS TH
   Efron B., 1987, The Jackknife, the Bootstrap
   Goh R, 2005, LECT NOTES COMPUT SC, V3723, P255
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390
   Lei Z, 2008, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2008.4587341
   Lu XG, 2003, LECT NOTES COMPUT SC, V2688, P869
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
NR 20
TC 1
Z9 2
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 781
EP 797
DI 10.1007/s11042-012-1102-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900010
DA 2024-07-18
ER

PT J
AU Zhang, W
   Gao, K
   Zhang, YD
   Li, JT
AF Zhang, Wei
   Gao, Ke
   Zhang, Yongdong
   Li, Jintao
TI Efficient binary code indexing with pivot based locality sensitive
   clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High dimensional indexing; Similarity search; Pivot based locality
   sensitive clustering; Density adaptive binary coding
AB High-dimensional indexing is fundamental in multimedia research field. Compact binary code indexing has achieved significant success in recent years for its effective approximation of high-dimensional data. However, most of existing binary code methods adopt linear scan to find near neighbors, which involve unnecessary computations and thus degrade search efficiency especially in large scale applications. To avoid searching codes that are not near neighbors with high probability, we propose a framework that index binary codes in clusters and only codes in relevant clusters are scanned. Consequently, Pivot Based Locality Sensitive Clustering (PLSC) is proposed and Density Adaptive Binary coding (DAB) method in PLSC clusters is presented. PLSC uses pivots to estimate similarities between data points and generates clusters based on the Locality Sensitive Hashing scheme. DAB adopts different binary code generation methods according to cluster densities. Experiments on open datasets show that offline indexing based on PLSC is efficient and DAB codes in PLSC clusters achieve significant improvement on search efficiency compared to the state of the art binary codes.
C1 [Zhang, Wei; Gao, Ke; Zhang, Yongdong; Li, Jintao] Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Adv Comp Res Lab, Beijing 100190, Peoples R China.
   [Zhang, Wei] Univ Chinese Acad Sci, Beijing 100080, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Zhang, YD (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Adv Comp Res Lab, 6 Kexueyuan South Rd, Beijing 100190, Peoples R China.
EM zhangwei@ict.ac.cn; zhyd@ict.ac.cn
FU National Nature Science Foundation of China [61271428, 61273247];
   National Key Technology Research and Development Program of China
   [2012BAH39B02]; National Basic Research Program of China (973Program)
   [2013CB329502]; Co-building Program of Beijing Municipal Education
   Commission
FX This work was supported by the National Nature Science Foundation of
   China (61271428, 61273247), National Key Technology Research and
   Development Program of China (2012BAH39B02), National Basic Research
   Program of China (973Program, 2013CB329502) and Co-building Program of
   Beijing Municipal Education Commission.
CR [Anonymous], P 17 ANN ACM SIAM S
   [Anonymous], P 19 ACM INT C MULT
   [Anonymous], 2010 IEEE COMP SOC C
   [Anonymous], P 17 ACM INT C MULT
   [Anonymous], 1998, STOC
   [Anonymous], P 6 ACM INT C IM VID
   [Anonymous], P 22 ANN C NEUR INF
   [Anonymous], 1999, 25 INT C VER LARG DA
   Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348
   Brandt J, 2010, PROC CVPR IEEE, P1815, DOI 10.1109/CVPR.2010.5539852
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Daoudi I, 2009, SIGNAL PROCESS-IMAGE, V24, P775, DOI 10.1016/j.image.2009.09.001
   Guttman Antonin., 1984, P 1984 ACM SIGMOD C, P47
   He JF, 2011, PROC CVPR IEEE, P753, DOI 10.1109/CVPR.2011.5995518
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Ji RR, 2009, PROC CVPR IEEE, P1161, DOI 10.1109/CVPRW.2009.5206680
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lv Q., 2007, P 33 INT C VER LARG
   Mu YD, 2010, LECT NOTES COMPUT SC, V6313, P748
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Sivic J, 2003, P 9 IEEE INT C COMP, V2, P1470
   Sivic J, 2008, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2008.4562950
   Tang Jinhui., 2009, Proceedings of ACM international conference on Multimedia, P223, DOI DOI 10.1145/1631272.1631305
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Wang WY, 2011, IEEE T MULTIMEDIA, V13, P1308, DOI 10.1109/TMM.2011.2165053
   Xie HT, 2011, IEEE T MULTIMEDIA, V13, P1319, DOI 10.1109/TMM.2011.2167224
   Zhao WL, 2007, IEEE T MULTIMEDIA, V9, P1037, DOI 10.1109/TMM.2007.898928
NR 28
TC 0
Z9 0
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 2
BP 491
EP 512
DI 10.1007/s11042-012-1354-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4FN
UT WOS:000333203400014
DA 2024-07-18
ER

PT J
AU Hwang, S
   Yu, D
AF Hwang, Soyoung
   Yu, Donghui
TI Data forwarding based on sensor device constraints in wireless
   multimedia sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cost estimation; Wireless multimedia sensor networks; ZigBee; IEEE
   802.15.4
AB A variety of data forwarding schemes have been proposed for wireless multimedia sensor networks where energy awareness and reliability are essential design issues. This paper proposes a data forwarding mechanism based on sensor device constraints in wireless multimedia sensor networks. A dynamic path cost function is defined considering the constraints and characteristics of wireless multimedia sensor networks. The cost function is applied to ZigBee mesh routing, and the performance of the proposed method is evaluated using a QualNet network simulator.
C1 [Hwang, Soyoung; Yu, Donghui] Catholic Univ Pusan, Dept Multimedia Engn, Pusan, South Korea.
C3 Catholic University Pusan
RP Yu, D (corresponding author), Catholic Univ Pusan, Dept Multimedia Engn, Pusan, South Korea.
EM soyoung@cup.ac.kr; dhyu@cup.ac.kr
CR Akkaya K., 2005, Ad Hoc Networks, V3, P325, DOI 10.1016/j.adhoc.2003.09.010
   Al-Karaki JN, 2004, IEEE WIREL COMMUN, V11, P6, DOI 10.1109/MWC.2004.1368893
   [Anonymous], RFC5867 IETF
   [Anonymous], ROUTING METRICS USED
   [Anonymous], RFC5826 IETF
   [Anonymous], 2007, 802154A2007 IEEE
   ZIGBEE ALLIANCE, 2008, 053474R17 ZIGBEE ALL
NR 7
TC 4
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 2
BP 297
EP 303
DI 10.1007/s11042-012-1064-6
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RI
UT WOS:000331083400007
DA 2024-07-18
ER

PT J
AU Kim, J
   Choi, Y
   Park, SE
AF Kim, Jinwoo
   Choi, Yoojung
   Park, Su-E
TI E-impression dimensions A multi-phase research on the development of
   parsimonious measurements for online impression within blog domains
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE E-impression; Blog; E-impression dimensions; Measurement development;
   Measurement model; Mixed-methods
ID COMPUTER-MEDIATED COMMUNICATION; SELF-PRESENTATION; PERSONALITY; CUES
AB As cyberspace becomes a social space, users are increasingly more interested in how they are presented to others online. Nevertheless, the concept of online impressions has not been defined or empirically verified clearly. The main purpose of the study is to empirically verify a set of measurements for e-impressions, which is defined as impressions formed through interpersonal online interactions in blogs. The measurement should be parsimonious in order to be used efficiently by academics and practitioners. In order to achieve the research goal, three consecutive studies were conducted. In the first study, a large-scale online survey was conducted with 8,836 participants to explore important dimensions of e-impressions from a blog visitor's point of view. In the second study, in-depth interviews with 52 blog authors were conducted to reorganize the dimensions into a parsimonious set of meta-dimensions from a blog author's view. Finally, in the third study, a confirmatory factor analysis was conducted through a paper-based survey to verify the meta-dimensions of e-impressions. As the final result, four meta-dimensions of e-impressions consisting of fifteen adjectives were identified, and their validity and reliability were verified. This result will be the basis of developing the system of social network services.
C1 [Kim, Jinwoo] Yonsei Univ, Human Comp Interact Lab, Seoul 120749, South Korea.
   [Choi, Yoojung] Pusan Natl Univ, Sch Business Adm, Pusan 609735, South Korea.
   [Park, Su-E] Seoul Womens Univ, Dept Contents Design, Seoul, South Korea.
   [Park, Su-E] Seoul Womens Univ, Coll Informat & Commun, Seoul 120749, South Korea.
C3 Yonsei University; Pusan National University; Seoul Women's University;
   Seoul Women's University
RP Park, SE (corresponding author), Seoul Womens Univ, Coll Informat & Commun, 126 Gonreung Dong, Seoul 120749, South Korea.
EM spark44@swu.ac.kr
FU Seoul Women's University
FX This work was supported by Special Research Grant from Seoul Women's
   University (2012).
CR Aaker JL, 1997, J MARKETING RES, V34, P347, DOI 10.2307/3151897
   Ambe M, 2005, CYBERPSYCHOL BEHAV, V8, P401, DOI 10.1089/cpb.2005.8.401
   [Anonymous], 1993, Western Journal of Communication, DOI DOI 10.1080/10570319309374463
   [Anonymous], KOREAN J SOC PERSONA
   Antheunis ML, 2011, J COMPUT-MEDIAT COMM, V16, DOI 10.1111/j.1083-6101.2011.01545.x
   ASCH SE, 1946, J ABNORM SOC PSYCH, V41, P258, DOI 10.1037/h0055756
   BARASH VLADIMIR., 2010, Proceedings of the Fourth International AAAI Conference on Weblogs and Social Media, Menlo Park, P207
   Bargh JA, 2002, J SOC ISSUES, V58, P33, DOI 10.1111/1540-4560.00247
   Brunswick E., 1956, PERCEPTION REPRESENT, DOI 10.1525/9780520350519
   Choi YK, 1993, J KOREA PSYCHOL, V12, P161
   CONNOLLY T, 1990, MANAGE SCI, V36, P689, DOI 10.1287/mnsc.36.6.689
   Costa P.T., 1992, REVISED NEO PERSONAL
   Ellison N, 2006, J COMPUT-MEDIAT COMM, V11
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Glaser B. G., 1967, DISCOV GROUNDED THEO
   Goffman E., 1959, PRESENTATION SELF EV
   Gosling S. D., 2007, ICWSM, V7, P1
   Hair JFJ., 2008, MULTIVARIATE DATA AN
   Hancock JT, 2001, COMMUN RES, V28, P325, DOI 10.1177/009365001028003004
   Herring S.C., 2004, P 37 HAWAII INT C SY
   HIGGINS ET, 1987, PSYCHOL REV, V94, P319, DOI 10.1037/0033-295X.94.3.319
   Hiltz S. R., 1989, Decision Support Systems, V5, P217, DOI 10.1016/0167-9236(89)90008-0
   John OP, 1990, HDB PERSONALITY THEO, P66
   KELLEY HH, 1950, J PERS, V18, P431, DOI 10.1111/j.1467-6494.1950.tb01260.x
   Kim J, 2003, INT J HUM-COMPUT ST, V59, P899, DOI 10.1016/j.ijhcs.2003.06.002
   Kim KS, 2000, KOR J CONSUM ADVERT, V1, P103
   Kim UK, 2000, J ADVERT STUD, V49, P29
   Lea M., 1992, Journal of Organizational Computing, V2, P321, DOI 10.1080/10919399209540190
   Liu YL, 2001, J UNIVERS COMPUT SCI, V7, P893
   McCrae RR, 1997, AM PSYCHOL, V52, P509, DOI 10.1037/0003-066X.52.5.509
   MCCRAE RR, 1989, J PERS SOC PSYCHOL, V56, P586, DOI 10.1037/0022-3514.56.4.586
   McKenna KYA, 2000, PERS SOC PSYCHOL REV, V4, P57, DOI 10.1207/S15327957PSPR0401_6
   McNeill L., 2005, Genre Under Construction: The Diary on the Internet
   Mehdizadeh S, 2010, CYBERPSYCH BEH SOC N, V13, P357, DOI 10.1089/cyber.2009.0257
   Miura A, 2007, J COMPUT-MEDIAT COMM, V12, P1452, DOI 10.1111/j.1083-6101.2007.00381.x
   Nardi B. A., 2004, Computer Supported Cooperative Work Conference Proceedings, P222, DOI 10.1145/1031607.1031643
   Nardi BA, 2004, COMMUN ACM, V47, P41, DOI 10.1145/1035134.1035163
   NORMAN WT, 1963, J ABNORM PSYCHOL, V66, P574, DOI 10.1037/h0040291
   Osgood C. E., 1957, The measurement of meaning
   Papacharissi Z, 2002, J MASS COMMUN Q, V79, P643, DOI 10.1177/107769900207900307
   Parks MR, 1996, J COMMUN, V46, P80, DOI 10.1111/j.1460-2466.1996.tb01462.x
   PEABODY D, 1967, J PERS SOC PSYCHOL, V7, P1, DOI 10.1037/h0025230
   Qin L, 2011, INT J HUM-COMPUT INT, V27, P885, DOI 10.1080/10447318.2011.555311
   RICE RE, 1987, COMMUN RES, V14, P85, DOI 10.1177/009365087014001005
   ROSENCRA.HA, 1969, GERONTOLOGIST, V9, P55, DOI 10.1093/geront/9.1.55
   Schau HJ, 2003, J CONSUM RES, V30, P385
   Schiano D.J., 2004, P CHI 2004, P1143, DOI DOI 10.1145/985921.986009
   Sherman RC, 2001, CYBERPSYCHOL BEHAV, V4, P123, DOI 10.1089/10949310151088497
   SPROULL L, 1986, MANAGE SCI, V32, P1492, DOI 10.1287/mnsc.32.11.1492
   Strauss E, 1998, CLIN ORTHOP RELAT R, P2
   Sutcliffe AG, 2011, INT J HUM-COMPUT INT, V27, P1037, DOI 10.1080/10447318.2011.555318
   Switzer J.S., 2008, Handbook of Research on Virtual Workplaces and the New Nature of Business Practices, P98
   Tanis M, 2003, J COMMUN, V53, P676, DOI 10.1111/j.1460-2466.2003.tb02917.x
   Tong ST, 2008, J COMPUT-MEDIAT COMM, V13, P531, DOI 10.1111/j.1083-6101.2008.00409.x
   Walther J.B., 2011, A networked self: Identity, community, and culture on social network sites, P17
   WALTHER JB, 1992, COMMUN RES, V19, P52, DOI 10.1177/009365092019001003
   Walther JB, 2009, COMMUN RES, V36, P229, DOI 10.1177/0093650208330251
   YANGYOON, 2002, [The Korean Journal of Consumer and Advertising Psychology, 한국심리학회지: 소비자Â·광고], V3, P25
   Yee N, 2009, COMMUN RES, V36, P285, DOI 10.1177/0093650208330254
   Zwier S, 2011, CYBERPSYCH BEH SOC N, V14, P571, DOI 10.1089/cyber.2010.0612
NR 60
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 2
BP 281
EP 296
DI 10.1007/s11042-012-1063-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AA4RI
UT WOS:000331083400006
DA 2024-07-18
ER

PT J
AU Liu, Q
   Han, T
   Sun, YT
   Chu, Z
   Shen, BW
AF Liu, Qiang
   Han, Tao
   Sun, Yantao
   Chu, Zhong
   Shen, Bingwen
TI A two step salient objects extraction framework based on image
   segmentation and saliency detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient objects extraction; Image segmentation; Saliency detection;
   Framework; SVM
AB Salient objects extraction from a still image is a very hot topic, as it owns a lot of useful applications (e.g., image compression, content-based image retrieval, digital watermarking). In this paper, targeted to improve the performance of the extraction approach, we propose a two step salient objects extraction framework based on image segmentation and saliency detection (TIS). Specially, during the first step, the image is segmented into several regions using image segmentation algorithm and the saliency map for the whole image is detected with saliency detection algorithm. In the second step, for each region, some features are extracted for the SVM algorithm to classify the region as a background region or a salient region twice. Experimental results show that our proposed framework can extract the salient objects more precisely and can achieve a good extraction results, compared with previous salient objects extraction methods.
C1 [Liu, Qiang; Sun, Yantao; Chu, Zhong; Shen, Bingwen] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
   [Han, Tao] Huazhong Univ Sci & Technol, Dept Elect & Informat Engn, Huazhong, Peoples R China.
C3 Beijing Jiaotong University; Huazhong University of Science & Technology
RP Han, T (corresponding author), Huazhong Univ Sci & Technol, Dept Elect & Informat Engn, Huazhong, Peoples R China.
EM liuq@bjtu.edu.cn; hantao@hust.edu.cn; ytsun@bjtu.edu.cn;
   chu.zhong@hotmail.com; ShenBW0320@gmail.com
RI Liu, Qiang/HHZ-3181-2022
FU Fundamental Research Funds for the Central Universities [2012JBM032];
   Hubei Provincial Science and Technology Department [2011BFA004]
FX This work was supported by "the Fundamental Research Funds for the
   Central Universities" (2012JBM032). Tao Han's research was supported by
   Hubei Provincial Science and Technology Department (Grant No.:
   2011BFA004).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353
   DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Han Z, 2009, P 8 IEEE ACIS INT C
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jing Zhang, 2008, 2008 International Conference on Neural Networks and Signal Processing, P375, DOI 10.1109/ICNNSP.2008.4590375
   Kim S, 2003, P INT C IM VID RETR, P3949
   Kwak SY, 2004, LECT NOTES COMPUT SC, V3332, P138
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Mangan AP, 1999, IEEE T VIS COMPUT GR, V5, P308, DOI 10.1109/2945.817348
   Müller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517
   Osberger W, 1998, INT C PATT RECOG, P701, DOI 10.1109/ICPR.1998.711240
   Park KT, 2007, P IEEE INT C AC SPEE
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Wang W, 2002, P INT C IM VID RETR, P2937
NR 22
TC 12
Z9 13
U1 1
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 1
BP 231
EP 247
DI 10.1007/s11042-012-1077-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 196PN
UT WOS:000322787800012
DA 2024-07-18
ER

PT J
AU Li, PJ
   Ma, HD
   Ming, AL
AF Li, Pengjie
   Ma, Huadong
   Ming, Anlong
TI Combining topological and view-based features for 3D model retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model retrieval; Topological structure; MRG; View-based; Bag of
   features
AB With the rapidly increasing of 3D models, the 3D model retrieval methods have been paid significant research attention. Most of the existing methods focus on taking advantage of one kind of feature. These methods can not achieve ideal retrieval results for different classes of 3D models. In this paper, we propose a novel 3D model retrieval algorithm by combining topological and view-based features. To preserve the topological structure of the 3D model, a multiresolutional reeb graph (MRG) is constructed according to the salient topological points. The view-based features are extracted from the images, which are rendered at each of the topological points. To preserve the spatial structure information of the images, we modify the bag-of-features (BOF) method by using the combined shell-sector model. We take the view-based features as the attribute information of the corresponding MRG nodes. The comparison between two 3D models is transformed to the problem of computing the similarity of the corresponding MRGs. Finally, we calculate the similarity between the query model and the models in the databases by adapting the earth mover distance method. Experimental results on two standard benchmarks show that our algorithm can achieve satisfactory retrieval performance.
C1 [Li, Pengjie; Ma, Huadong; Ming, Anlong] Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Ma, HD (corresponding author), Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
EM mhd@bupt.edu.cn
FU National Natural Science Foundation of China [60833009, 60903072];
   National Natural Science Foundation for Distinguished Young Scholars
   [60925010]; Fundamental Research Funds for the Central Universities
   [2009RC0213]; 111 Project [B08004]
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 60833009 and No. 60903072; the National Natural
   Science Foundation for Distinguished Young Scholars under Grant No.
   60925010; the Fundamental Research Funds for the Central Universities
   under Grant No. 2009RC0213 and the 111 Project under Grant No. B08004.
CR [Anonymous], P 1 ACM INT C MULT I
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Cao Y, 2010, PROC CVPR IEEE, P3352, DOI 10.1109/CVPR.2010.5540021
   Chaouch M, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P187, DOI 10.1109/SMI.2008.4547969
   Chen D-Y, 2002, COMP GRAPH WORKSH TA
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Cornea ND, 2005, VISUAL COMPUT, V21, P945, DOI 10.1007/s00371-005-0308-0
   Daras P, 2010, INT J COMPUT VISION, V89, P229, DOI 10.1007/s11263-009-0277-2
   Daras P, 2009, INT WORK CONTENT MUL, P115, DOI 10.1109/CBMI.2009.15
   Del Bimbo A, 2006, ACM T MULTIM COMPUT, V2, P20
   Del Bue A, 2007, IMAGE VISION COMPUT, V25, P297, DOI 10.1016/j.imavis.2005.10.004
   Fang R, 2008, LECT NOTES COMPUT SC, V5358, P381, DOI 10.1007/978-3-540-89639-5_37
   Gao Y, 2010, NEUROCOMPUTING, V73, P1900, DOI 10.1016/j.neucom.2009.11.050
   Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012
   Hartveldt J, 2009, INT C EUROGRAPH ICS
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Li XY, 2009, MODELLING SIMULATION, P437, DOI 10.1109/ICIP.2009.5414415
   Ling H, 2007, IEEE T PATTERN ANAL, V29, P840, DOI 10.1109/TPAMI.2007.1058
   Liu Y., 2006, Computer Vision and Pattern Recognition, P2025, DOI DOI 10.1109/CVPR.2006.278
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma WC, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P207
   Odone F, 2005, IEEE T IMAGE PROCESS, V14, P169, DOI 10.1109/TIP.2004.840701
   Ohbuchi R, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P93, DOI 10.1109/SMI.2008.4547955
   Ovsjanikov M, 2009, IEEE 12 INT C COMP V
   Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6
   Rabaud Vincent., 2008, CVPR
   SHIH JL, 2009, MULTIMED TOOLS APPL, V43, P45, DOI DOI 10.1007/S11042-008-0256-6
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Shilane P., 2005, COMPUT AIDED DESIGN, V37, P509
   Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609
   Tam GKL, 2007, IEEE T VIS COMPUT GR, V13, P470, DOI 10.1109/TVCG.2007.1011
   TAYLOR J, 2010, PROC CVPR IEEE, P2761, DOI DOI 10.1109/CVPR.2010.5540002
   Vranic DV, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P963
NR 33
TC 7
Z9 8
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2013
VL 65
IS 3
BP 335
EP 361
DI 10.1007/s11042-012-1000-9
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 144EO
UT WOS:000318922600002
DA 2024-07-18
ER

PT J
AU Hu, YL
   Duan, FQ
   Yin, BC
   Zhou, MQ
   Sun, YF
   Wu, ZK
   Geng, GH
AF Hu, Yongli
   Duan, Fuqing
   Yin, Baocai
   Zhou, Mingquan
   Sun, Yanfeng
   Wu, Zhongke
   Geng, Guohua
TI A hierarchical dense deformable model for 3D face reconstruction from
   skull
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D face reconstruction; Hierarchical deformable model; Dense mesh
   registration; Thin plate spline
ID FACIAL RECONSTRUCTION
AB 3D face reconstruction from skull has been investigated deeply by computer scientists in the past two decades because it is important for identification. The dominant methods construct 3D face from the soft tissue thickness measured at a set of landmarks on skull. The quantity and position of the landmarks are very vital for 3D face reconstruction, but there is no uniform standard for the selection of the landmarks. Additionally, the acquirement of the landmarks on skull is difficult without manual assistance. In this paper, an automatic 3D face reconstruction method based on a hierarchical dense deformable model is proposed. To construct the model, the skull and face samples are acquired by CT scanner and represented as dense triangle mesh. Then a non-rigid dense mesh registration algorithm is presented to align all the samples in point-to-point correspondence. Based on the aligned samples, a global deformable model is constructed, and three local models are constructed from the segmented patches of the eye, nose and mouth. For a given skull, the globe and local deformable models are iteratively matched with it, and the reconstructed facial surface is obtained by fusing the globe and local reconstruction results. To validate the presented method, a measurement in the coefficient domain of a face deformable model is defined. The experimental results indicate that the proposed method has good performance for 3D face reconstruction from skull.
C1 [Hu, Yongli; Yin, Baocai; Sun, Yanfeng] Beijing Univ Technol, Beijing Key Lab Multimedia & Intelligent Software, Coll Comp Sci & Technol, Beijing 100124, Peoples R China.
   [Duan, Fuqing; Zhou, Mingquan; Wu, Zhongke] Beijing Normal Univ, Coll Informat Sci & Technol, Beijing 100875, Peoples R China.
   [Geng, Guohua] NW Univ Xian, Dept Comp Sci, Xian 710069, Peoples R China.
C3 Beijing University of Technology; Beijing Normal University; Northwest
   University Xi'an
RP Sun, YF (corresponding author), Beijing Univ Technol, Beijing Key Lab Multimedia & Intelligent Software, Coll Comp Sci & Technol, Beijing 100124, Peoples R China.
EM huyongli@bjut.edu.cn; fqduan@bnu.edu.cn; ybc@bjut.edu.cn;
   mqzhou@bnu.edu.cn; yfsun@bjut.edu.cn; zwu@bnu.edu.cn; ghgeng@nwu.edu.cn
OI Hu, Yongli/0000-0003-0440-438X
FU National Basic Research Program (973 Program) of China [2011CB302703];
   National Natural Science Foundation of China [60825203, 61171169,
   61133003, 60973057, 60736008, 60872127]
FX This paper is partly supported by the National Basic Research Program
   (973 Program) of China (No. 2011CB302703) and the National Natural
   Science Foundation of China (No. 60825203, 61171169, 61133003, 60973057,
   60736008, 60872127).
CR [Anonymous], 1000088 GB
   Berar M., 2006, Journal of Computing and Information Technology - CIT, V14, P31, DOI 10.2498/cit.2006.01.04
   Berar M, 2005, 2 INT C REC SOFT FAC, P1
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Buter B., 2011, J CONVERG, V2, P87
   Claes P., 2006, Journal of Computing and Information Technology - CIT, V14, P21, DOI 10.2498/cit.2006.01.03
   Claes P, 2006, FORENSIC SCI INT, V159, pS147, DOI 10.1016/j.forsciint.2006.02.035
   Claes P, 2010, FORENSIC SCI INT, V201, P138, DOI 10.1016/j.forsciint.2010.03.008
   Claes P, 2010, FORENSIC SCI INT, V201, P146, DOI 10.1016/j.forsciint.2010.03.009
   De Greef S, 2006, FORENSIC SCI INT, V159, pS126, DOI 10.1016/j.forsciint.2006.02.034
   Gerasimov MM, 1971, THE FACE FINDER
   Greenspan M, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P442, DOI 10.1109/IM.2003.1240280
   Jones M. W., 2001, Vision, Modeling, and Visualization 2001. Proceedings, P135
   Klyuev Vitaly, 2011, International Journal of Information Technology, Communications and Convergence, V1, P221, DOI 10.1504/IJITCC.2011.039287
   Lebedinskaya G, 1993, FORENSIC ANAL SKULL, P105
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Nelson LA, 1998, FORENSIC SCI INT, V94, P167, DOI 10.1016/S0379-0738(98)00066-8
   Paysan P, 2009, LECT NOTES COMPUT SC, V5748, P232, DOI 10.1007/978-3-642-03798-6_24
   Pyshkin E, 2010, J CONVERG, V1, P1
   Quatrehomme G, 1997, J FORENSIC SCI, V42, P649
   RHINE JS, 1980, J FORENSIC SCI, V25, P847
   Tilotta F, 2009, FORENSIC SCI INT, V191, P112, DOI 10.1016/j.forsciint.2009.06.017
   Tilotta FM, 2010, FORENSIC SCI INT, V200, P50, DOI 10.1016/j.forsciint.2010.03.029
   Tyrrell AJ, 1997, J FORENSIC SCI, V42, P653
   Vanezis P, 2000, FORENSIC SCI INT, V108, P81, DOI 10.1016/S0379-0738(99)00026-2
   Wikipedia, 2011, FRANKF PLAN
   Yunming Ye, 2011, International Journal of Information Technology, Communications and Convergence, V1, P206, DOI 10.1504/IJITCC.2011.039286
NR 28
TC 35
Z9 51
U1 0
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 2
BP 345
EP 364
DI 10.1007/s11042-012-1005-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 116IM
UT WOS:000316876200008
DA 2024-07-18
ER

PT J
AU Jeong, HY
   Hong, BH
AF Jeong, Hwa-Young
   Hong, Bong-Hwa
TI A service component based CAT system with SCORM for advanced learning
   effects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBD; Service component; SCORM; CAT; Learning materials; Learning
   multimedia resources
AB In the web-based learning system, a variety of learning materials such as text, video, sound, and picture are employed with the objective of improving the learning effect. One of the main problems facing such systems is the systems' ability to support the materials and integrate them into the system in such a way that they can be tailored to the user's ability level. Accordingly, it is very difficult for the system to support user-oriented learning materials or courses efficiently. In this research, we applied the CAT (Computerized Adaptive Testing) system with SCORM interfaces to improve the learning effect. CAT is a method which focuses on analysis and evaluation of learning outcomes. SCORM is an international standard used to manage the learning materials. To support user-oriented learning and testing, we made a learning process using IRT (Item response theory). Throughout the process in this system, we implemented logic as a service component. The system process performs the learning test program's logic by interface between the service components. The structure of this system interlinks SCORM API with the learning contents and items through a separate e-learning server.
C1 [Jeong, Hwa-Young] Kyung Hee Univ, Humanitas Coll, Seoul 130701, South Korea.
   [Hong, Bong-Hwa] Kyunghee Cyber Univ, Dept Informat Commun, Seoul 130701, South Korea.
C3 Kyung Hee University
RP Hong, BH (corresponding author), Kyunghee Cyber Univ, Dept Informat Commun, Seoul 130701, South Korea.
EM hyjeong@khu.ac.kr; bhhong@khcu.ac.kr
OI Jeong, Hwa-Young/0000-0002-5017-934X
CR [Anonymous], 2008, COMP AD TEST CAT OV
   Bamasak Omaima, 2011, International Journal of Information Technology, Communications and Convergence, V1, P173, DOI 10.1504/IJITCC.2011.039284
   Beisiegel M, 2007, SERVICE COMPONENT AR
   Chao RJ, 2009, EXPERT SYST APPL, V36, P10657, DOI 10.1016/j.eswa.2009.02.047
   Chen CM, 2008, COMPUT EDUC, V51, P624, DOI 10.1016/j.compedu.2007.06.011
   Chen LH, 2010, COMPUT EDUC, V54, P1028, DOI 10.1016/j.compedu.2009.10.008
   Ding ZH, 2008, ELECTRON NOTES THEOR, V207, P33, DOI 10.1016/j.entcs.2008.03.084
   Gert J, 2006, WILEY INTERSCIENCE, V29, P2629
   Han J., 2008, J INFORM PROCESSING, V4
   Jeong H, 2011, COMM COM INF SC, V184, P230
   Jo M, 2006, J INF PROCESS SYST, V2, P178
   Li T., 2010, J CONVERGENCE, V2, P61
   Markus L, 2007, ELECT NOTES THEORETI, V182, P123
   Mozgovoy M, 2010, J CONVERG JOC, V1, P29
   Patricia AD, 1999, CONSIDERATIONS DEV U
   Rey-López M, 2009, COMPUT STAND INTER, V31, P309, DOI 10.1016/j.csi.2008.02.006
   Ronald DA, 2006, COMPUTERIZED ADAPTIV
   Yasar O, 2010, PROCD SOC BEHV, V2, P5682, DOI 10.1016/j.sbspro.2010.03.928
NR 18
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 1
BP 217
EP 226
DI 10.1007/s11042-012-1027-y
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105KY
UT WOS:000316069400014
DA 2024-07-18
ER

PT J
AU Ciobanu, L
   Côrte-Real, L
AF Ciobanu, Lucian
   Corte-Real, Luis
TI Sprite-based generation of side information for multi-view Distributed
   Video Coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed Video Coding (DVC); Wyner-Ziv (WZ); Side information
   generation; Scale-Invariant Feature Transform (SIFT); SIFT-based
   multi-view registration (SMVR); Global motion estimation (GME); Sprites;
   Multi-view registration metric (MVRM); Structural similarity (SSIM)
ID IMAGE
AB Generation of side information for multi-view Distributed Video Coding in multi-camera environments (e.g., video surveillance) poses challenges in scenarios with temporary non-overlapping among views and consequently, no resources for generating the side information at some time instants. In this paper we extend our previous work (Ciobanu and Corte-Real, Multimed Tools Appl 48(3):411-436, 2010) (for scenarios with permanent complete-overlapping among views) and propose a solution to this problem by exploiting the past visual data associated with each view, gathered over time as a panoramic image (sprite). The entire collection of temporal data from all the cameras is subsequently used for generating the side information. We tackle several topics related to these scenarios and propose solutions for the encountered issues. Optimization techniques are also discussed, e.g., temporal tags and block alternatives associated with the sprite contents for an improved generation of side information. This paper also presents a post-processing technique for additional refinement of generated side information. Practical results show an overall significant enhancement of side information by over 2 dB.
C1 [Ciobanu, Lucian; Corte-Real, Luis] Univ Porto, INESC Porto, Fac Engn, P-4100 Oporto, Portugal.
   [Corte-Real, Luis] Univ Porto, Fac Engn, Dept Engn Electrotecn & Comp, P-4100 Oporto, Portugal.
C3 Universidade do Porto; INESC TEC; Universidade do Porto
RP Ciobanu, L (corresponding author), Univ Porto, INESC Porto, Fac Engn, Rua Campo Alegre 823, P-4100 Oporto, Portugal.
EM lciobanu@inescporto.pt; lreal@inescporto.pt
RI Corte-Real, Luís/I-4852-2012
OI Ciobanu, Lucian/0000-0003-1102-8589; Corte-Real,
   Luis/0000-0003-2116-7056
FU Fundacao para a Ciencia e a Tecnologia, Portugal
FX The first author acknowledges the Fundacao para a Ciencia e a
   Tecnologia, Portugal, for the financial support.
CR Aaron A., 2004, P PICTURE CODING S P
   AARON A, 2004, P IEEE INT C IM PROC
   ARTIGAS X, 2006, 7 NORD SIGN PROC S N
   ASCENSO J, 2007, INT C IM PROC ICIP 2
   Benedek C, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P439
   Bergevin R, 1996, IEEE T PATTERN ANAL, V18, P540, DOI 10.1109/34.494643
   Ciobanu L, 2010, MULTIMED TOOLS APPL, V48, P411, DOI 10.1007/s11042-009-0315-7
   Dufaux F, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P673, DOI 10.1109/ICIP.1996.559588
   Dufaux F, 2007, SPIE DEF SEC S DSS 2
   Guo X, 2006, P SPIE IS T EL IM, V6077
   Izquierdo E, 2003, IEEE T MULTIMEDIA, V5, P293, DOI 10.1109/TMM.2003.814910
   Lee MC, 1997, IEEE T CIRC SYST VID, V7, P130, DOI 10.1109/76.554424
   OUARET M, 2007, EUR C SIGN PROC EUSI
   OUARET M, 2006, ACM INT WORKSH VID S
   Pereira F., 2002, IMSC Press multimedia series
   Puri R, 2003, P INT C IM PROC ICIP
   Sikora T, 2005, P IEEE, V93, P6, DOI 10.1109/JPROC.2004.839601
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Smolic A, 1999, IEEE T CIRC SYST VID, V9, P1227, DOI 10.1109/76.809158
   Szlávik Z, 2007, ISPRS J PHOTOGRAMM, V61, P298, DOI 10.1016/j.isprsjprs.2006.09.014
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Yeo C, 2007, VCIP 2007 SAN JOS CA
NR 22
TC 0
Z9 0
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2012
VL 60
IS 3
BP 609
EP 639
DI 10.1007/s11042-011-0831-0
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 965ZC
UT WOS:000305805300008
DA 2024-07-18
ER

PT J
AU Mehrabi, M
   Zargari, F
   Ghanbari, M
AF Mehrabi, Mahdi
   Zargari, Farzad
   Ghanbari, Mohammad
TI Compressed domain content based retrieval using H.264 DC-pictures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed domain image indexing and retrieval; DC-picture; H.264 video
   coding standard; Color histogram
ID VIDEO; EXTRACTION
AB A fast and simple method for content based retrieval using the DC-pictures of H.264 coded video without full decompression is presented. Compressed domain retrieval is very desirable for content analysis and retrieval of compressed image and video. Even though, DC-pictures are among the most widely used compressed domain indexing and retrieval methods in pre H.264 coded videos, they are not generally used in the H.264 coded video. This is due to two main facts, first, the I-frame in the H.264 standard are spatially predicatively coded and second, the H.264 standard employs Integer Discrete Cosine Transform. In this paper we have applied color histogram indexing method on the DC-pictures derived from H.264 coded I-frames. Since the method is based on independent I-frame coded pictures, it can be used either for video analysis of H.264 coded videos, or image retrieval of the I-frame based coded images such as advanced image coding. The retrieval performance of the proposed algorithm is compared with that the fully decoded images. Simulation results indicate that the performance of the proposed method is very close to the fully decompressed image systems. Moreover the proposed method has much lower computational load.
C1 [Zargari, Farzad] ITRC, Informat Technol Res Inst, Minist Telecommun & Informat Technol Iran, Tehran, Iran.
   [Mehrabi, Mahdi] Islamic Azad Univ, Sci & Res Branch, Dept Comp Engn, Tehran, Iran.
   [Ghanbari, Mohammad] Univ Essex, Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, Essex, England.
C3 Islamic Azad University; University of Essex
RP Zargari, F (corresponding author), ITRC, Informat Technol Res Inst, Minist Telecommun & Informat Technol Iran, Tehran, Iran.
EM mehrabi@iaushiraz.ac.ir; zargari@itrc.ac.ir; ghan@essex.ac.uk
RI Mehrabi, Mahdi/AAO-2879-2021; Ghanbari, Mohammad/L-4053-2019
OI Mehrabi, Mahdi/0000-0002-1551-5723; Ghanbari,
   Mohammad/0000-0002-5482-8378
CR Ballard D. H., 1997, INT J COMPUT VISION, V7, P11
   Divakaran A, 2000, IEEE T CONSUM ELECTR, V46, P637, DOI 10.1109/30.883424
   Feng Y, 2005, LECT NOTES COMPUT SC, V3687, P542
   Jiang J, 2002, PATTERN RECOGN, V35, P2511, DOI 10.1016/S0031-3203(01)00217-5
   Jiang JM, 2006, IMAGE VISION COMPUT, V24, P1269, DOI 10.1016/j.imavis.2006.04.009
   Jiang JM, 2002, IEEE T SIGNAL PROCES, V50, P1160, DOI 10.1109/78.995072
   Joyce RA, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P941, DOI 10.1109/ICIP.2000.899612
   Kobla V, 1996, P SOC PHOTO-OPT INS, V2916, P78, DOI 10.1117/12.257312
   Lee SM, 2005, COLOR RES APPL, V30, P265, DOI 10.1002/col.20122
   Li XW, 2009, WKDD: 2009 SECOND INTERNATIONAL WORKSHOP ON KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS, P199, DOI 10.1109/WKDD.2009.84
   Malvar HS, 2003, IEEE T CIRC SYST VID, V13, P598, DOI 10.1109/TCSVT.2003.814964
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Qian XM, 2006, IEEE T CIRC SYST VID, V16, P1245, DOI 10.1109/TCSVT.2006.881858
   Seo KD, 2009, IEEE T CONSUM ELECTR, V55, P831, DOI 10.1109/TCE.2009.5174462
   Tavanapong W, 2004, IEEE T MULTIMEDIA, V6, P517, DOI 10.1109/tmm.2004.830810
   Wang HL, 2003, J VIS COMMUN IMAGE R, V14, P150, DOI 10.1016/S1047-3203(03)00019-1
   Zhang ZB, 2008, 2008 COMPLEXITY & INTELLIGENCE OF THE ARTIFICIAL & NATURAL COMPLEX SYSTEMS, MEDICAL APPLICATIONS OF THE COMPLEX SYSTEMS, BIOMEDICAL COMPUTING, P110, DOI 10.1109/CANS.2008.21
   Zhao SL, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P224, DOI 10.1109/ICIG.2007.75
NR 18
TC 6
Z9 7
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2012
VL 60
IS 2
BP 443
EP 453
DI 10.1007/s11042-010-0597-9
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 958YH
UT WOS:000305276400011
DA 2024-07-18
ER

PT J
AU Waitelonis, J
   Sack, H
AF Waitelonis, Joerg
   Sack, Harald
TI Towards exploratory video search using linked data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Linked Open Data; Video search; Exploratory search
AB Keyword-based search in general is particularly applicable if the searcher really knows what she is looking for and how to find it, i.e. to know the appropriate keywords to obtain the desired results. But in many cases either the objectives of the searcher are intrinsically fuzzy or she is not aware of the appropriate keywords. One way to solve this problem is to navigate and explore the search space along guided routes. In this paper we show, how Linked Open Data can be adopted to facilitate an exploratory semantic search for video data. We present a prototype implementation of exploratory video search and show how traditional keyword-based search can be augmented by the use of Linked Open Data.
C1 [Waitelonis, Joerg; Sack, Harald] Hasso Plattner Inst Potsdam, D-14482 Potsdam, Germany.
RP Waitelonis, J (corresponding author), Hasso Plattner Inst Potsdam, Prof Dr Helmert Str 2-3, D-14482 Potsdam, Germany.
EM joerg.waitelonis@hpi.uni-potsdam.de; harald.sack@hpi.uni-potsdam.de
OI Sack, Harald/0000-0001-7069-9804
CR [Anonymous], CIVR
   [Anonymous], 2006, LINKED DATA WORLD WI
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], 2008, P 17 INT C WORLD WID, DOI DOI 10.1145/1367497.1367760
   [Anonymous], 2009, P 18 INT C WORLD WID, DOI [DOI 10.1145/1526709.1526773, 10.1145/1526709.1526773]
   Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Bizer Christian., 2007, How to Publish Linked Data on the Web
   Bollen J, 2007, J NETW COMPUT APPL, V30, P1059, DOI 10.1016/j.jnca.2005.12.009
   Borlund P, 2003, J AM SOC INF SCI TEC, V54, P913, DOI 10.1002/asi.10286
   Borlund P, 2003, INFORM RES, V8
   BRICKLEY DAN., 2007, FOAF VOCABULARY SPEC
   Chen X, 2006, IEEE DATA MINING, P129
   Christel M.G., 2008, Proceedings of the International Conference on Content-based Image and Video Retrieval (CIVR '08), P447
   Dan Brickley R, 2004, RDF VOCABULARY DESCR
   Day N, 2000, JTC1SC29WG11N3751 IS
   Duke A, 2009, SEMANTIC KNOWLEDGE M, P85
   Fouss Francois, 2008, Wl 2008. 2008 IEEE/WIC/ACM International Conference on Web Intelligence. IAT 2008. 2008 IEEE/WIC/ACM International Conference on Intelligent Agent Technology. Wl-IAT Workshop 2008 2008 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology Workshops, P735, DOI 10.1109/WIIAT.2008.252
   Garcia R, 2005, P 4 INT SEM WEB C KN
   Gruber TR, 1995, INT J HUM-COMPUT ST, V43, P907, DOI 10.1006/ijhc.1995.1081
   Guha R.V., 2003, Proceedings of the 12th international conference on World Wide Web, P700, DOI DOI 10.1145/775152.775250
   International Organization for Standardization, 2003, 15836 ISO
   Ivan Herman Ralph Swick DB, 2004, RESOURCE DESCRIPTION
   Mangold Christoph, 2007, International Journal of Metadata, Semantics and Ontologies, V2, P23, DOI 10.1504/IJMSO.2007.015073
   Marchionini G, 2006, COMMUN ACM, V49, P41, DOI 10.1145/1121949.1121979
   Meij EJ, 2009, 8 INT SEM WEB C ISWC
   Miles A., 2008, SKOS Simple Knowledge Organization System -
   Milne D, 2008, P 17 ACM C INF KNOWL, P509, DOI DOI 10.1145/1458082.1458150
   NEWMAN R, 2005, TAG ONTOLOGY
   Oren Eyal, 2008, International Journal of Metadata, Semantics and Ontologies, V3, P37, DOI 10.1504/IJMSO.2008.021204
   Petratos Panagiotis, 2008, Journal of Issues in Informing Science and Information Technology Journal, V5, P705
   POLLITT AS, 1994, J INFORM SCI, V20, P413, DOI 10.1177/016555159402000604
   Qu Y, 2008, INFORM PROCESS MANAG, V44, P534, DOI 10.1016/j.ipm.2007.09.006
   Sack H., 2006, P 1 SEM AUTH ANN WOR
   Sack H, 2006, P ESWC 2006 WORKSH M
   Schraefel MC, 2006, COMMUN ACM, V49, P47, DOI 10.1145/1121949.1121980
   Schreiber G, 2008, J WEB SEMANT, V6, P243, DOI 10.1016/j.websem.2008.08.001
   Seaborne A., 2008, SPARQL Query Language for RDF
   Singh H, 2006, SOFT COMPUTING INFOR, V164, P189
   Smeulders AWM, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING WORKSHOPS, PROCEEDINGS, P51, DOI 10.1109/ICIAPW.2007.39
   Smith M., 2004, OWL web ontology language: guide
   Stefaner M, 2008, INT WORKSHOP DATABAS, P397, DOI 10.1109/DEXA.2008.108
   Tran D. T., 2007, P 1 INT C THEOR INF
   Waitelonis J., 2009, P INT C SEM SYST 200
   Waitelonis J, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P540, DOI 10.1109/ISM.2009.111
   Yee Ka-Ping, 2003, P SIGCHI C HUM FACT, P401, DOI DOI 10.1145/642611.642681
NR 46
TC 36
Z9 39
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 2
BP 645
EP 672
DI 10.1007/s11042-011-0733-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 943OP
UT WOS:000304134000012
DA 2024-07-18
ER

PT J
AU Perkiö, J
   Tuominen, A
   Vähäkangas, T
   Myllymäki, P
AF Perkio, Jukka
   Tuominen, Antti
   Vahakangas, Taneli
   Myllymaki, Petri
TI Image similarity: from syntax to weak semantics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image similarity; Weak semantics; Image retrieval; Multimedia retrieval;
   Video retrieval
ID RETRIEVAL
AB Measuring image similarity is an important task for various multimedia applications. Similarity can be defined at two levels: at the syntactic (lower, context-free) level and at the semantic (higher, contextual) level. As long as one deals with the syntactic level, defining and measuring similarity is a relatively straightforward task, but as soon as one starts dealing with the semantic similarity, the task becomes very difficult. We examine the use of simple readily available syntactic image features combined with other multimodal features to derive a similarity measure that captures the weak semantics of an image. The weak semantics can be seen as an intermediate step between low level image understanding and full semantic image understanding. We investigate the use of single modalities alone and see how the combination of modalities affect the similarity measures. We also test the measure on multimedia retrieval task on a tv series data, even though the motivation is in understanding how different modalities relate to each other.
C1 [Perkio, Jukka; Tuominen, Antti; Vahakangas, Taneli; Myllymaki, Petri] Helsinki Inst Informat Technol, Helsinki, Finland.
C3 University of Helsinki
RP Perkiö, J (corresponding author), Helsinki Inst Informat Technol, Helsinki, Finland.
EM jperkio@cs.helsinki.fi; antti.tuominen@hiit.fi;
   taneli.vahakangas@cs.helsinki.fi; petri.myllymaki@cs.helsinki.fi
FU IST of the European Community under the PASCAL Network of Excellence;
   Academy of Finland; Finnish Funding Agency for Technology and Innovation
FX This work was supported in part by the IST Programme of the European
   Community under the PASCAL Network of Excellence and under the CLASS
   project, and by the Academy of Finland under projects VISCI and HPE, and
   by the Finnish Funding Agency for Technology and Innovation under the
   project MIFSAS.
CR [Anonymous], 1974, Syntactic Methods in Pattern Recognition
   [Anonymous], 2010, MULTIMED TOOLS APPL, DOI DOI 10.1007/s11042-009-0339-z
   [Anonymous], 2008, P 17 INT C WORLD WID
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Chen WF, 2009, SCI CHINA SER F, V52, P316, DOI 10.1007/s11432-009-0044-6
   Csillaghy A, 2000, INFORM RETRIEVAL, V3, P229, DOI 10.1023/A:1026568809834
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Fanzou GNT, 2008, INT CONF SIGN PROCES, P924, DOI 10.1109/ICOSP.2008.4697278
   Felipe JC, 2009, J DIGIT IMAGING, V22, P183, DOI 10.1007/s10278-007-9084-x
   Grigorova A, 2007, IEEE T MULTIMEDIA, V9, P1183, DOI 10.1109/TMM.2007.902828
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Hyvärinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71
   Jakulin A, 2006, DISCRETE COMPONENT A, P1
   Kak A, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P138, DOI 10.1109/TDPVT.2002.1024053
   Li M, 2004, IEEE T INFORM THEORY, V50, P3250, DOI 10.1109/TIT.2004.838101
   Lin W, 2003, IEEE WIC ACM INT C W
   LU SY, 1978, COMPUT VISION GRAPH, V7, P303, DOI 10.1016/S0146-664X(78)80001-X
   Durán ML, 2010, MACH VISION APPL, V21, P865, DOI 10.1007/s00138-009-0201-3
   Marcharnd-Maillet Stephane., 2006, ACM SIGMM International Workshop on Multimedia Information Retrieval, P297
   McDonald K, 2005, LECT NOTES COMPUT SC, V3568, P61
   Perkiö J, 2009, LECT NOTES COMPUT SC, V5769, P704, DOI 10.1007/978-3-642-04277-5_71
   Perkiö J, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P213, DOI 10.1109/MINES.2009.271
   PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Souvannavong F., 2004, MIR'04: Proceedings of the 6th ACM SIGMM International Workshop on Multimedia Information Retrieval, P243
   Tao DC, 2006, IEEE T MULTIMEDIA, V8, P716, DOI 10.1109/TMM.2005.861375
   Zhang J, 2009, IEEE T IMAGE PROCESS, V18, P2370, DOI 10.1109/TIP.2009.2026669
   Zhang RF, 2004, PROC CVPR IEEE, P996
NR 30
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2012
VL 57
IS 1
BP 5
EP 27
DI 10.1007/s11042-010-0562-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 898YR
UT WOS:000300778800002
DA 2024-07-18
ER

PT J
AU Cha, GH
AF Cha, Guang-Ho
TI Capturing contextual relationship for effective media search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contextual relationship; Media search; Semantic gap; Similarity search
AB One of the central problems regarding media search is the semantic gap between the low-level features computed automatically from media data and the human interpretation of them. This is because the notion of similarity is usually based on high-level abstraction but the low-level features do not sometimes reflect the human perception. In this paper, we assume the semantics of media is determined by the contextual relationship in a dataset, and introduce the method to capture the contextual information from a large media (especially image) dataset for effective search. Similarity search in an image database based on this contextual information shows encouraging experimental results.
C1 Seoul Natl Univ Sci & Technol, Dept Comp Engn, Seoul 139743, South Korea.
C3 Seoul National University of Science & Technology
RP Cha, GH (corresponding author), Seoul Natl Univ Sci & Technol, Dept Comp Engn, Seoul 139743, South Korea.
EM ghcha@snut.ac.kr
CR [Anonymous], 1988, Spatial Vision
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   ENNIS D, 1998, MULTIDIMENSIONAL MOD, P279
   Gang Wu, 2005, 13th Annual ACM International Conference on Multimedia, P725
   Goh K., 2002, P ACM INT C MULTIMED, P466
   Haykin S., 1994, NEURAL NETWORKS COMP
   He Xiaofei., 2004, ACM MULTIMEDIA, P17
   Hoi C.-H., 2004, PROC 12 ANN ACM INT, P24
   Ishikawa Y., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P218
   Jeon J., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P119, DOI DOI 10.1145/860435.860459
   Muneesawang P, 2004, IEEE T MULTIMEDIA, V6, P703, DOI 10.1109/TMM.2004.834866
   Pan JY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1987, DOI 10.1109/ICME.2004.1394652
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Rui Y, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P815, DOI 10.1109/ICIP.1997.638621
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Scholkopf B, 1997, IEEE T SIGNAL PROCES, V45, P2758, DOI 10.1109/78.650102
   SHEPARD RN, 1987, SCIENCE, V237, P1317, DOI 10.1126/science.3629243
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Srikanth M., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P552, DOI 10.1145/1076034.1076128
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Wu L., 2000, P INT C VERY LARGE D, P297
   Zhou D, 2004, LEARNING LOCAL GLOBA, P16
NR 23
TC 4
Z9 4
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2012
VL 56
IS 2
SI SI
BP 351
EP 364
DI 10.1007/s11042-010-0670-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 891AR
UT WOS:000300189100008
DA 2024-07-18
ER

PT J
AU Karasulu, B
   Korukoglu, S
AF Karasulu, Bahadir
   Korukoglu, Serdar
TI A software for performance evaluation and comparison of people detection
   and tracking methods in video processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surveillance systems; Multimedia performance evaluation; People
   detection; People tracking
ID MEAN SHIFT; SEGMENTATION; FLOW
AB Digital video content analysis is an important item for multimedia content-based indexing (MCBI), content-based video retrieval (CBVR) and visual surveillance systems. There are some frequently-used generic object detection and/or tracking (D&T) algorithms in the literature, such as Background Subtraction (BS), Continuously Adaptive Mean Shift (CMS), Optical Flow (OF) and etc. An important problem for performance evaluation is the absence of stable and flexible software for comparison of different algorithms. This software is able to compare them with the same metrics in real-time and at the same platform. In this paper, we have designed and implemented the software for the performance comparison and the evaluation of well-known video object D&T algorithms (for people D&T) at the same platform. The software works as an automatic and/or semi-automatic test environment in real-time, which uses the image and video processing essentials, e.g. morphological operations and filters, and ground-truth (GT) XML data files, charting/plotting capabilities and etc.
C1 [Karasulu, Bahadir; Korukoglu, Serdar] Ege Univ, Dept Comp Engn, TR-35100 Izmir, Turkey.
C3 Ege University
RP Karasulu, B (corresponding author), Ege Univ, Dept Comp Engn, TR-35100 Izmir, Turkey.
EM bahadir.karasulu@ege.edu.tr; serdar.korukoglu@ege.edu.tr
RI Karasulu, Bahadır/AAW-9151-2020; korukoglu, serdar/AAF-8089-2020
OI Karasulu, Bahadır/0000-0001-8524-874X; Korukoglu,
   Serdar/0000-0002-4230-8447
CR Aguilera J., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P293
   [Anonymous], 2009, CONTEXT AWARE VISION
   [Anonymous], P IEEE INT C COMP VI
   *AVITRACK, 2009, AIRCR SURR CAT VEH I
   Bashir F Porikli F., 2006, P 9 IEEE INT WORKSHO, P7
   Baumann A, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/824726
   Benezeth Y, 2008, INT C PATT RECOG, P237, DOI 10.1109/icpr.2008.4760998
   Bradski G., 2008, LEARNING OPENCV
   Bradski GR, 1998, INTEL TECHNOL J
   Brdiczka O, 2006, INT C PATT RECOG, P1175
   Carmona EJ, 2008, PATTERN RECOGN LETT, V29, P272, DOI 10.1016/j.patrec.2007.10.007
   Cheung  S., 2004, VIDEO COMMUNICATIONS
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416
   Comaniciu D, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P70, DOI 10.1109/ICIP.2000.899297
   Erdem CE, 2005, SIGNAL PROCESS-IMAGE, V20, P151, DOI 10.1016/j.image.2004.10.005
   Fleet DJ., 2005, MATH MODELS COMPUTER, P239
   Foresti G.L., 2003, MULTISENSOR SURVEILL
   FRANCOIS RJA, 2004, IRIS04423 U SO CAL
   Greenhill D, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P193
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   HOWLETT M, 2009, NPLOT NET CHARTING P
   JAYNES C, 2002, P 3 IEEE INT WORKSH, P32
   Jodoin PM, 2009, COMPUT VIS IMAGE UND, V113, P511, DOI 10.1016/j.cviu.2008.12.005
   KARASULU B, 2009, VICAMPEV
   Kasturi R, 2009, IEEE T PATTERN ANAL, V31, P319, DOI 10.1109/TPAMI.2008.57
   Lazarevic-McManus N, 2008, COMPUT VIS IMAGE UND, V111, P74, DOI 10.1016/j.cviu.2007.07.007
   List T, 2004, INT C PATT RECOG, P789, DOI 10.1109/ICPR.2004.1334335
   Lucas B. D., 1981, P IJCAI, P674
   Manohar V., 2006, P 9 IEEE INT WORKSH, P1
   MITSUBISHI MER, 2010, PEP PERFORMANCE EVAL
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Pauwels K, 2009, IMAGE VISION COMPUT, V27, P579, DOI 10.1016/j.imavis.2008.04.010
   PORIKLI F, 2002, THESIS POLYTECHNIC U
   Sacan A, 2008, BIOINFORMATICS, V24, P1647, DOI 10.1093/bioinformatics/btn247
   SCHUNCK BG, 1986, COMPUT VISION GRAPH, V35, P20, DOI 10.1016/0734-189X(86)90124-6
   Shan CF, 2007, PATTERN RECOGN, V40, P1958, DOI 10.1016/j.patcog.2006.12.012
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Thirde D, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/96568
   Viitaniemi V, 2007, SIGNAL PROCESS-IMAGE, V22, P557, DOI 10.1016/j.image.2007.05.003
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Yang C, 2005, PROC CVPR IEEE, P176
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   2009, VID AN CONT EXTR
   2009, CLASSIFICATION EVENT
   2009, VIEWPOINT INVARIANT
   2009, CALL REAL TIME EVENT
   2007, IEEE INT WORKSH PERF
   2009, OPEN COMPUTER VISION
NR 50
TC 16
Z9 17
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2011
VL 55
IS 3
BP 677
EP 723
DI 10.1007/s11042-010-0591-2
PG 47
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 815CV
UT WOS:000294504600014
DA 2024-07-18
ER

PT J
AU Mäkelä, J
   Luoto, M
   Sutinen, T
   Pentikousis, K
AF Makela, Jukka
   Luoto, Markus
   Sutinen, Tiia
   Pentikousis, Kostas
TI Distributed information service architecture for overlapping multiaccess
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobility management; Multiaccess; Event service; Information service
ID VIDEO TRANSMISSION
AB Multimedia delivery in mobile multiaccess network environments has emerged as a key area within the future Internet research domain. When network heterogeneity is coupled with the proliferation of multiaccess capabilities in mobile handheld devices, one can expect many new avenues for developing novel services and applications. New mechanisms for audio/video delivery over multiaccess networks will define the next generation of major distribution technologies, but will require significantly more information to operate according to their best potential. In this paper we present and evaluate a distributed information service, which can enhance media delivery over such multiaccess networks. We describe the proposed information service, which is built upon the new distributed control and management framework (DCMF) and the mobility management triggering functionality (TRG). We use a testbed which includes 3G/HSPA, WLAN and WiMAX network accesses to evaluate our proposed architecture and present results that demonstrate its value in enhancing video delivery and minimizing service disruption in an involved scenario.
C1 [Makela, Jukka; Luoto, Markus; Sutinen, Tiia] VTT Tech Res Ctr Finland, Oulu 90571, Finland.
   [Pentikousis, Kostas] Huawei Technol European Res Ctr, D-10587 Berlin, Germany.
C3 VTT Technical Research Center Finland; Huawei Technologies
RP Mäkelä, J (corresponding author), VTT Tech Res Ctr Finland, Kaitovayla 1,POB 1100, Oulu 90571, Finland.
EM jukka.makela@vtt.fi; markus.luoto@vtt.fi; tiia.sutinen@vtt.fi;
   k.pentikousis@huawei.com
OI Makela, Jukka/0000-0002-2106-7090
CR [Anonymous], 80221 IEEE
   CACAE F, 2006, P WMASH 06 29 SEPT 2
   Daniel L, 2008, INT J COMMUN NETW DI, V1, P433, DOI 10.1504/IJCNDS.2008.021078
   Dousson Christophe, 2007, 2007 IEEE Symposium on Computers and Communications, P305, DOI 10.1109/ISCC.2007.4381530
   DURANLIMON HA, 2003, INT WORKSH OBJ OR RE
   Giaffreda R, 2007, PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING AND NETWORKS, P21
   Gurtov A., 2008, HOST IDENTITY PROTOC
   Huusko J, 2007, SIGNAL PROCESS-IMAGE, V22, P317, DOI 10.1016/j.image.2006.12.011
   Johnson D., 2004, 3775 IETF
   Kofler Ingo, 2008, P NOSSDAV
   LUOTO M, 2008, P INT C COMM BEIJ CH
   LWI CH, 2004, INT C INF TECHN COD
   Makela Jukka, 2009, International Journal of Communications, Networks and System Sciences, V2, P211, DOI 10.4236/ijcns.2009.23023
   MAKELA J, 2009, P 3 EUR S MOB MED DE
   MAKELA J, 2007, P PERS IND MOB RAD C
   MEIER R, 2002, IEEE INT C DISTR COM
   MINGARDI C, 2009, P 11 IFIP IEEE INT S
   PIRI E, 2009, EUROPEAN WIRELESS
   PROKKOLA J, 2007, P IEEE INT C COMM
   Schierl T, 2007, IEEE T CIRC SYST VID, V17, P1204, DOI 10.1109/TCSVT.2007.905528
   SCHULZRINNE H, 2003, 3550 IETF
   STEVENSNAVARRO E, 2006, VEH TECHN C VTC 2006
   Vidales P, 2005, IEEE J SEL AREA COMM, V23, P2288, DOI 10.1109/JSAC.2005.857198
   YONEKI E, 2005, IEEE INT C PERV COMP
   ZHANG W, 2004, WIR COMM NETW C WCNC
NR 25
TC 6
Z9 6
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2011
VL 55
IS 2
SI SI
BP 289
EP 306
DI 10.1007/s11042-010-0589-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 808HU
UT WOS:000293969500006
DA 2024-07-18
ER

PT J
AU Wang, XY
   Niu, PP
   Meng, L
   Yang, HY
AF Wang, Xiang-Yang
   Niu, Pan-Pan
   Meng, Lan
   Yang, Hong-Ying
TI A robust content based image watermarking using local invariant
   histogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Desynchronization attacks; Multi-scale SIFT
   detector; Histogram; DFT
AB Desynchronization attack is known as one of the most difficult attacks to resist, which can desynchronize the location of the watermark and hence causes incorrect watermark detection. Based on multi-scale SIFT (Scale Invariant Feature Transform) detector and local image histogram shape invariance, we propose a new content based image watermarking algorithm with good visual quality and reasonable resistance toward desynchronization attacks in this paper. Firstly, the stable image feature points are extracted from the original host by using multi-scale SIFT detector, and the local feature regions (LFRs) are constructed adaptively according to the feature scale theory. Then, the discrete Fourier transform (DFT) is performed on the LFR, and the local image histogram is extracted from a selected DFT amplitude range. Finally, the bins of the histogram are divided into many groups, and the digital watermark is embedded into LFR by reassigning the number of DFT amplitudes in bin groups. By binding the watermark with the geometrically invariant image features, the watermark detection can be done without synchronization error. Experimental results show that the proposed image watermarking is not only invisible and robust against common image processing operations such as sharpening, noise adding, and JPEG compression, but also robust against the desynchronization attacks such as rotation, translation, scaling, row or column removal, and cropping.
C1 [Wang, Xiang-Yang; Meng, Lan; Yang, Hong-Ying] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
   [Niu, Pan-Pan] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
C3 Liaoning Normal University; Dalian Maritime University
RP Wang, XY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, 850 Huanghe Rd, Dalian 116029, Peoples R China.
EM wxy37@126.com
RI Yang, Jing/JFK-4046-2023
OI Yang, Jing/0009-0004-8274-9863
FU National Natural Science Foundation of China [60773031, 60873222]; Open
   Foundation of State Key Laboratory of Networking and Switching
   Technology of China [SKLNST-2008-1-01]; Open Foundation of State Key
   Laboratory of Information Security of China [03-06]; Open Foundation of
   State Key Laboratory for Novel Software Technology of China [A200702];
   Open Foundation of Key Laboratory of Modern Acoustics Nanjing University
   [08-02]; Liaoning Research Project for Institutions of Higher Education
   of China [2008351]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 60773031 & 60873222, the Open Foundation of State
   Key Laboratory of Networking and Switching Technology of China under
   Grant No. SKLNST-2008-1-01, the Open Foundation of State Key Laboratory
   of Information Security of China under Grant No. 03-06, the Open
   Foundation of State Key Laboratory for Novel Software Technology of
   China under Grant No. A200702, the Open Foundation of Key Laboratory of
   Modern Acoustics Nanjing University under Grant No. 08-02, and Liaoning
   Research Project for Institutions of Higher Education of China under
   Grant No. 2008351.
CR Barni M, 2005, IEEE SIGNAL PROC LET, V12, P158, DOI 10.1109/LSP.2004.840872
   Bas P, 2002, IEEE T IMAGE PROCESS, V11, P1014, DOI 10.1109/TIP.2002.801587
   BROWN M., 2002, BRIT MACHINE VISION, P656, DOI [10.5244/C.16.23, DOI 10.5244/C.16.23]
   CHAKRAVARTI R, 2009, 6 INT C TECHN NEW GE, P1323
   Lee HY, 2006, OPT ENG, V45, DOI 10.1117/1.2181887
   Lee HY, 2007, MULTIMED TOOLS APPL, V34, P337, DOI 10.1007/s11042-007-0112-0
   Lee HY, 2005, LECT NOTES COMPUT SC, V3710, P418
   LIAN S, 2009, INFORMATICA, V33, P3
   Liu Y, 2007, MULTIMED TOOLS APPL, V34, P57, DOI 10.1007/s11042-006-0072-9
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MOTALLEBI F, 2008, P 2008 C IM SIGN PRO, V5, P720
   Pham VQ, 2008, IEICE T INF SYST, VE91D, P2027, DOI 10.1093/ietisy/e91-d.7.2027
   Qi HY, 2008, SIGNAL PROCESS, V88, P174, DOI 10.1016/j.sigpro.2007.07.020
   Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414
   Seo JS, 2006, IEEE T SIGNAL PROCES, V54, P1537, DOI 10.1109/TSP.2006.870581
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   Wang S., 2010, Journal of Information Hiding and Multimedia Signal Processing, V1, P28
   Wang XY, 2008, IMAGE VISION COMPUT, V26, P980, DOI 10.1016/j.imavis.2007.10.014
   Wang XY, 2007, IEEE T INF FOREN SEC, V2, P655, DOI 10.1109/TIFS.2007.908233
   Xiang SJ, 2008, IEEE T CIRC SYST VID, V18, P777, DOI 10.1109/TCSVT.2008.918843
   Xiang SJ, 2007, IEEE T MULTIMEDIA, V9, P1357, DOI 10.1109/TMM.2007.906580
   Xin YQ, 2007, PATTERN RECOGN, V40, P3740, DOI 10.1016/j.patcog.2007.05.004
   Zhang L, 2007, OPT EXPRESS, V15, P2251, DOI 10.1364/OE.15.002251
   Zheng D, 2009, IEEE T IMAGE PROCESS, V18, P1055, DOI 10.1109/TIP.2009.2014807
   Zheng D, 2007, ACM COMPUT SURV, V39, DOI 10.1145/1242471.1242473
   [No title captured]
NR 26
TC 7
Z9 8
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 2
BP 341
EP 363
DI 10.1007/s11042-010-0534-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 781SK
UT WOS:000291953700007
DA 2024-07-18
ER

PT J
AU Zoric, G
   Forchheimer, R
   Pandzic, IS
AF Zoric, Goranka
   Forchheimer, Rober
   Pandzic, Igor S.
TI On creating multimodal virtual humans-real time speech driven facial
   gesturing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial gestures; Visual prosody; Multimodal interfaces; Facial
   animation; Speech processing; Human-computer interaction
AB Because of extensive use of different computer devices, human-computer interaction design nowadays moves towards creating user centric interfaces. It assumes incorporating different modalities that humans use in everyday communication. Virtual humans, who look and behave believably, fit perfectly in the concept of designing interfaces in more natural, effective, as well as social oriented way. In this paper we present a novel method for automatic speech driven facial gesturing for virtual humans capable of real time performance. Facial gestures included are various nods and head movements, blinks, eyebrow gestures and gaze. A mapping from speech to facial gestures is based on the prosodic information obtained from the speech signal. It is realized using a hybrid approach-Hidden Markov Models, rules and global statistics. Further, we test the method using an application prototype-a system for speech driven facial gesturing suitable for virtual presenters. Subjective evaluation of the system confirmed that the synthesized facial movements are consistent and time aligned with the underlying speech, and thus provide natural behavior of the whole face.
C1 [Zoric, Goranka; Pandzic, Igor S.] Univ Zagreb, Fac Elect Engn & Comp, Dept Telecommun, HR-10000 Zagreb, Croatia.
   [Forchheimer, Rober] Linkoping Univ, Dept Elect Engn, S-58183 Linkoping, Sweden.
C3 University of Zagreb; Linkoping University
RP Zoric, G (corresponding author), Univ Zagreb, Fac Elect Engn & Comp, Dept Telecommun, Unska 3, HR-10000 Zagreb, Croatia.
EM Goranka.Zoric@fer.hr; robert@isy.liu.se; Igor.Pandzic@fer.hr
FU Ministry of Science, Education and Sports of the Republic of Croatia;
   The National Foundation for Science, Higher Education and Technological
   Development of the Republic of Croatia; The Swedish Institute, Sweden
FX The work was partly carried out within the research project "Embodied
   Conversational Agents as interface for networked and mobile services"
   supported by the Ministry of Science, Education and Sports of the
   Republic of Croatia. This work was partly supported by grants from The
   National Foundation for Science, Higher Education and Technological
   Development of the Republic of Croatia and The Swedish Institute,
   Sweden.
CR Albrecht I, 2002, ADVANCES IN MODELLING, ANIMATION AND RENDERING, P283
   [Anonymous], QUESTION
   [Anonymous], P 2004 ACM SIGMM WOR
   [Anonymous], 1979, HUMAN ETHOLOGY CLAIM
   Cave C., 1996, P INT C SPOK LANG PR
   CHOVIL N, 1991, RES LANGUAGE SOCIAL
   Chuang E, 2005, ACM T GRAPHIC, V24, P331, DOI 10.1145/1061347.1061355
   Condon W.S., 1971, Perception of Language, P150
   Graf HP, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P396, DOI 10.1109/AFGR.2002.1004186
   GRANSTROM B, 1999, 3 SWED S MULT COMM
   HOFER G, 2007, P INT
   HONDA K, 2000, P LING PHOEN IT ORD
   House D., 2001, P EUR
   Kuratate T., 1999, Eurospeech'99, V3, P1279
   Levine S., 2009, P ACM SIGGRAPH AS, P1
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x
   Pandzic I., 2002, MPEG-4 Facial Animation: The Standard, Implementation and Applications
   Pelachaud C, 1996, COGNITIVE SCI, V20, P1, DOI 10.1207/s15516709cog2001_1
   Salvi G, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/191940
   SARGIN ME, 2007, ICASSP 07
   YEHIA H, 2000, 5 SEM SPEECH PROD MO
   ZORIC G, 2005, THESIS U ZAGREB
   Zoric G., 2007, CONVERSATIONAL INFOR, P161
   Zoric G, 2009, LECT NOTES ARTIF INT, V5398, P112
NR 24
TC 10
Z9 13
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 1
SI SI
BP 165
EP 179
DI 10.1007/s11042-010-0526-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 770BD
UT WOS:000291061100009
DA 2024-07-18
ER

PT J
AU Redondo, RPD
   Vilas, AF
   Rey-López, M
   Arias, JJP
   Solla, AG
   Cabrer, MR
   Duque, JG
AF Diaz Redondo, Rebeca P.
   Fernandez Vilas, Ana
   Rey-Lopez, Marta
   Pazos Arias, Jose Juan
   Gil Solla, Alberto
   Ramos Cabrer, Manuel
   Garcia Duque, Jorge
TI TVGuide2.0: applying the Web2.0 fundamentals to IDTV
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive Digital TV (IDTV); Social web; Folksonomy; Content
   recommender
AB In this paper we introduce our experiences in applying the Web 2.0 philosophy to build a TV guide system for Interactive Digital TV (IDTV) platforms. Subscribers give their opinion about TV content and, informally, a folksonomy is progressively built. Based on this shared knowledge, the TV guide obtains personal recommendations and allows users to browse among the multimedia content. Additionally, and over this collaborative layer, a more formal vision enables applying semantic reasoning to supplement the knowledge informally inferred.
C1 [Diaz Redondo, Rebeca P.; Fernandez Vilas, Ana; Rey-Lopez, Marta; Pazos Arias, Jose Juan; Gil Solla, Alberto; Ramos Cabrer, Manuel; Garcia Duque, Jorge] Univ Vigo, Dept Telemat Engn, Vigo 36310, Spain.
C3 Universidade de Vigo
RP Redondo, RPD (corresponding author), Univ Vigo, Dept Telemat Engn, Vigo 36310, Spain.
EM rebeca@det.uvigo.es; avilas@det.uvigo.es
RI José, Pazos Arias/F-6788-2016; Arias, José/ITR-8005-2023; Vilas, Ana
   Fernández/L-2055-2014; Díaz Redondo, Rebeca P./L-3108-2014; Ramos
   Cabrer, Manuel/F-5339-2016; Gil, Alberto/F-6827-2016
OI José, Pazos Arias/0000-0002-0424-5481; Vilas, Ana
   Fernández/0000-0003-1047-2143; Díaz Redondo, Rebeca
   P./0000-0002-2367-2219; Ramos Cabrer, Manuel/0000-0002-1684-2160; Gil,
   Alberto/0000-0002-9641-4149
FU Ministerio de Educacion y Ciencia (Gobierno de Espana) [TSI2007-61599];
   Conselleria de Educacion e Ordenacion Universitaria (Xunta de Galicia)
   [2007/000016-0]
FX Work funded by the Ministerio de Educacion y Ciencia (Gobierno de
   Espana) research project TSI2007-61599 and by the Conselleria de
   Educacion e Ordenacion Universitaria (Xunta de Galicia) incentives files
   2007/000016-0.
CR [Anonymous], WEB SERV DESCR LANG
   [Anonymous], WEB SERV ARCH
   [Anonymous], MPEG 7 OVERVIEW
   ARDISSONO L, 2004, HUMAN COMPUTER INTER, V6
   Basu C, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P714
   BLANCOFERNANDEZ Y, 2006, IEEE T CONSUM ELECTR, V52, P223
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   *CABLELABS, OCAP HEAD COMM DOWNL
   Chorianopoulos K, 2008, MULTIMED TOOLS APPL, V36, P1, DOI 10.1007/s11042-006-0081-8
   DIMITROVA N, 2003, P 3 WORKSH PERS FUT, P42
   *DVB PROJ, 2003, MULT HOM PLATF MHP S
   ETSI TS 102 822-3-1 V1.3.1, 2006, 10282231 ETSI TS
   Fernandez YB, 2007, INT J PATTERN RECOGN, V21, P397, DOI 10.1142/S0218001407005375
   Golder SA, 2006, J INF SCI, V32, P198, DOI 10.1177/0165551506062337
   HAN J, 2008, CONS EL 2008 ICCE
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   HOTHO A, 2006, WORKSH INF RETR 2006
   HOTHO A, 2006, LECT NOTES COMPUTER
   KIM M, 2007, USABILITY STUDY PERS, P892
   Ko SM, 2007, LECT NOTES COMPUT SC, V4552, P909
   Michlmayr E., 2007, 1 INT C WEBL SOC MED
   MOBASHER B, 2004, WEB MINING APPL TECH
   Niwa S, 2006, THIRD INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, PROCEEDINGS, P388, DOI 10.1109/ITNG.2006.140
   NORES ML, 2009, MULTIMED TOOLS APPL, V41, P407
   O'Reilly T, 2007, WEB 2 0 COMPACT DEFI
   PazosArias JJ, 2009, PERSONALIZATION OF INTERACTIVE MULTIMEDIA SERVICES: A RESEARCH AND DEVELOPMENT PERSPECTIVE, P1
   PRATA A, 2004, P 4 WORKSH PERS FUT, P274
   Smyth B, 2000, COMMUN ACM, V43, P107, DOI 10.1145/345124.345161
   Specia L, 2007, LECT NOTES COMPUT SC, V4519, P624
   SZOMSZOR M, 2007, 4 EUR SEM WEB C BRID
   *W3C REC, 2007, SOAP VER 1 2 1
   *W3C REC, 2004, OWL WEB ONT LANG OV
   WALL TV, 2007, FOLKSONOMY COINAGE D
   FREETAG OPEN SOURCE
   2005, UNIVERSAL DESCRIPTIO
   TRU2WAY BRAND SUCCEE
NR 36
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2011
VL 53
IS 1
BP 151
EP 179
DI 10.1007/s11042-010-0494-2
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 746AZ
UT WOS:000289214700007
DA 2024-07-18
ER

PT J
AU Zhang, WZ
   Zheng, QH
AF Zhang, Weizhan
   Zheng, Qinghua
TI Multi-channel live streaming in service overlay network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Service overlay network; Overlay multicast; Multi-channel; Live
   streaming
ID PEER; DELAY
AB Service overlay network (SON) provides an effective means to deploy quality of service (QoS)-guaranteed live streaming over today's Internet. A major challenge in designing such a network is dealing with resource sharing among multiple channels. To achieve the best overall QoS in SON, we devise a new multi-channel live streaming scheme. First, we propose a multi-tree construction algorithm by infrastructure-based overlay multicast. The algorithm employs pre-allocated session degree constraints in overlay nodes to reserve resources for multiple channels, and constructs multiple trees by considering the total resource utilization of overlay nodes. Second, we propose a tree-aware queue scheduling algorithm to reduce the overlay processing delay in view of the entire overlay network. Scheduling priority is identified to trade off session priority with node location in different trees. From simulation and experimental results, the scheme achieves a differentiated control among different sessions, provides load balancing among overlay nodes, and improves the delay performance on SON.
C1 [Zhang, Weizhan; Zheng, Qinghua] Xi An Jiao Tong Univ, MOE KLINNS Lab, Xian 710049, Peoples R China.
   [Zhang, Weizhan; Zheng, Qinghua] Xi An Jiao Tong Univ, SKLMS Lab, Xian 710049, Peoples R China.
   [Zhang, Weizhan; Zheng, Qinghua] Xi An Jiao Tong Univ, Dept Comp Sci & Technol, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University; Xi'an Jiaotong
   University
RP Zhang, WZ (corresponding author), Xi An Jiao Tong Univ, MOE KLINNS Lab, Xian 710049, Peoples R China.
EM zhangwzh@mail.xjtu.edu.cn; qhzheng@mail.xjtu.edu.cn
FU China NSF [60633020, 60921003, 60825202]; Ministry of Education of China
   [20090201110060]; National Key Technology R&D Program of China
   [2006BAJ07B06]; China CNGI [CNGI-09-01-13]
FX Funding for this work was provided by China NSF Grant (60633020,
   60921003, 60825202), Doctoral Fund of Ministry of Education of China
   (20090201110060), National Key Technology R&D Program of China
   (2006BAJ07B06), and China CNGI project (CNGI-09-01-13).
CR [Anonymous], P INFOCOM 08
   [Anonymous], TAXONOMY MESSAGE SCH
   [Anonymous], P IEEE LCN
   [Anonymous], P ACM SIGMETRIC 07
   [Anonymous], IEEE COMMUNICATIONS
   [Anonymous], P IEEE LCN
   [Anonymous], P INFOCOM 07
   [Anonymous], P INFOCOM 08
   Banerjee S, 2002, ACM SIGCOMM COMP COM, V32, P205, DOI 10.1145/964725.633045
   Cai Y, 2007, MULTIMED TOOLS APPL, V32, P115, DOI 10.1007/s11042-006-0049-8
   Capone A, 2009, COMPUT NETW, V53, P180, DOI 10.1016/j.comnet.2008.09.011
   Castro M., 2003, Operating Systems Review, V37, P298, DOI 10.1145/1165389.945474
   Dán G, 2007, IEEE INFOCOM SER, P2556, DOI 10.1109/INFCOM.2007.320
   Diot C, 2000, IEEE NETWORK, V14, P78, DOI 10.1109/65.819174
   Hei XJ, 2007, IEEE T MULTIMEDIA, V9, P1672, DOI 10.1109/TMM.2007.907451
   Lao L, 2007, IEEE T PARALL DISTR, V18, P449, DOI 10.1109/TPDS.2007.1008
   Li B, 2007, IEEE COMMUN MAG, V45, P94, DOI 10.1109/MCOM.2007.374425
   Liu JC, 2006, MULTIMED TOOLS APPL, V29, P211, DOI 10.1007/s11042-006-0013-7
   Magharei N, 2007, IEEE INFOCOM SER, P1415
   Padmanabhan V.N., 2002, P 12 INT WORKSHOP NE, P177
   Pompili D, 2008, COMPUT COMMUN, V31, P489, DOI 10.1016/j.comcom.2007.08.023
   Ren D, 2008, IEEE INFOCOM SER, P1732
   Tran DA, 2003, IEEE INFOCOM SER, P1283
   Venkataraman V, 2006, PROCEEDINGS OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, P2, DOI 10.1109/ICNP.2006.320193
   Wang F, 2008, IEEE INFOCOM SER, P2038
   Wu C, 2008, IEEE INFOCOM SER, P2029
   Wu C, 2007, IEEE J SEL AREA COMM, V25, P222, DOI 10.1109/JSAC.2007.070122
   Yang SY, 2007, GLOB TELECOMM CONF, P565
   Zegura EW, 1996, IEEE INFOCOM SER, P594, DOI 10.1109/INFCOM.1996.493353
   Zhang XY, 2005, IEEE INFOCOM SER, P2102
   ZhangW, 2009, P 6 IEEE CONSUMER CO, P1
NR 31
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2011
VL 53
IS 1
BP 97
EP 117
DI 10.1007/s11042-010-0492-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 746AZ
UT WOS:000289214700005
DA 2024-07-18
ER

PT J
AU Su, PC
   Hsu, CW
   Wu, CY
AF Su, Po-Chyi
   Hsu, Chih-Wei
   Wu, Ching-Yu
TI A practical design of content protection for H.264/AVC compressed videos
   by selective encryption and fingerprinting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Selective encryption; H.264/AVC; Digital watermark; Fingerprinting;
   Digital rights management; Trailer tracking
ID WATERMARKING
AB Digital Rights Management (DRM) of videos is an important issue nowadays. Considering that H.264/AVC videos will be widely used in various applications, we propose a practical design, which combines the methodologies of selective encryption and fingerprinting, for effective DRM of H.264/AVC streaming videos. A selective encryption scheme is first presented to scramble the video content by encrypting a small amount of data in the compressed bit-stream. The scrambled video is H.264-compliant to reduce the complexity of decoder since it can still be played without triggering errors in the decoding process. A fingerprinting scheme is then introduced to provide further protection. We extract a reasonable amount of data from the video and embed the watermark acting as the fingerprint of the video recipient. To acquire the high-quality video for viewing, the user has to decrypt the video obtained from a video server and then combine it with the watermarked data provided from a user information server. The resulting viewable video is thus fingerprinted to deter the user from illegally redistributing the content. Experimental results will demonstrate the feasibility of the proposed approach.
C1 [Su, Po-Chyi; Hsu, Chih-Wei; Wu, Ching-Yu] Natl Cent Univ, Dept Comp Sci & Informat Engn, Jhongli 32001, Taiwan.
C3 National Central University
RP Su, PC (corresponding author), Natl Cent Univ, Dept Comp Sci & Informat Engn, Jhongli 32001, Taiwan.
EM pochyisu@csie.ncu.edu.tw; realawei@gmail.com; 965202105@cc.ncu.edu.tw
RI SU, PO-CHYI/GWC-9682-2022
OI Su, Po-Chyi/0000-0002-7457-8409
FU National Science Council in Taiwan, R.O.C. [NSC96-2221-E-008-098-,
   NSC97-2752-E-008-001-PAE]
FX This research was supported by the National Science Council in Taiwan,
   R.O.C., under Grants NSC96-2221-E-008-098- and NSC97-2752-E-008-001-PAE.
CR Ahn J, 2004, LECT NOTES COMPUT SC, V3333, P386
   Anderson R, 1997, LECT NOTES COMPUT SC, V1267, P107
   BERGERON C, 2005, IEEE 7 WORKSH MULT S, P1
   Changgui Shi, 1998, Proceedings ACM Multimedia 98, P81
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   *ISO IEC MPEG ITU, 2003, H264 ITUT ISO IEC MP
   Kundur D, 2004, P IEEE, V92, P918, DOI 10.1109/JPROC.2004.827356
   Lei Tang, 1996, Proceedings ACM Multimedia 96, P219, DOI 10.1145/244130.244209
   LEMMA A, 2006, INT WORKSH DIG WAT J, P433
   Lian SG, 2005, LECT NOTES COMPUT SC, V3768, P281, DOI 10.1007/11582267_25
   Lian SG, 2006, IEEE IMAGE PROC, P1953, DOI 10.1109/ICIP.2006.312797
   Lian SG, 2007, IEEE T CIRC SYST VID, V17, P774, DOI 10.1109/TCSVT.2007.896635
   MIAN C, 2007, 3 INT C INT INF HID, V2, P41
   PARK SW, 2008, 4 INT C NETW COMP AD, V1, P371
   PARNES P, 2001, IFIP INT C COMM MULT, P17
   SHI T, 2006, P SPIE SEC STEG WAT, P461
   SPINSANTE S, 2005, 13 EUR SIGN PROC C A
   Wang JD, 2007, ASICON 2007: 2007 7TH INTERNATIONAL CONFERENCE ON ASIC, VOLS 1 AND 2, PROCEEDINGS, P802, DOI 10.1109/ICASIC.2007.4415752
   YEN JC, 1999, IEEE WORKSH SIGN PRO, P430
NR 20
TC 10
Z9 16
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2011
VL 52
IS 2-3
SI SI
BP 529
EP 549
DI 10.1007/s11042-009-0458-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 732IA
UT WOS:000288177000017
DA 2024-07-18
ER

PT J
AU Liu, RA
   Zhou, X
   Wang, NL
   Zhang, MM
AF Liu, Ruian
   Zhou, Xin
   Wang, Nailin
   Zhang, Mimi
TI Adaptive regulation of CCD camera for real time eye tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Congress on Image and Signal Processing
CY OCT 17-19, 2009
CL Tianjin, PEOPLES R CHINA
SP Tianjin Univ Technol, IEEE Engn Med & Biol Soc (EMBS)
DE Eye-gaze tracking system; CCD camera; Adaptive regulation; Automatic
   focusing; Eye tracking
ID GAZE
AB In this paper, an eye tracking method and an automatic focusing technique, which combine the regulation of the aperture with the adjustment of the focus of the camera lens, are proposed to acquire clear eye images in the eye-gaze tracking system. Firstly, the aperture of the CCD lens is controlled to adapt the system to external lighting circumstances with the average brightness value of the processed images as the basic value. Secondly, a sum-modulus-difference (SMD) operator is used for rough and quick focusing in a large scale to obtain the eye glints, and for the control of a pan-tilt unit to track and aim at the eye, and for regulation of the lens focus. Finally, a frequency selective weighted median (FSWM) operator is applied in the determined window to focus automatically and acquire clear eye images. If the pupil contour can be extracted from the eye image, then the average gradient value of the pupil's edge points can be used for real-time focusing. Experimental results show that this system can adapt to external lighting changes and to the user's head movements. It can track the eye and acquire clear eye images in real-time.
C1 [Liu, Ruian; Zhou, Xin; Wang, Nailin; Zhang, Mimi] Tianjin Normal Univ, Coll Phys & Elect Informat Sci, Tianjin 300387, Peoples R China.
C3 Tianjin Normal University
RP Liu, RA (corresponding author), Tianjin Normal Univ, Coll Phys & Elect Informat Sci, Tianjin 300387, Peoples R China.
EM wdxylra@mail.tjnu.edu.cn
CR Bao Ge-tang, 2005, Journal of Shanghai Jiaotong University, V39, P121
   CHERN NK, 2001, P 2001 IEEE INT C RO, P21
   Fu T, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P1054
   JARVIS RA, 1976, MICROSCOPE, V24, P163
   Jiang Wei, 2006, OPTICAL TECHNIQUE, V32, P218
   Kang Zong-ming, 2003, Acta Electronica Sinica, V31, P552
   LI QJ, 1998, OPTICS PRECISION ENG, V6, P105
   LIM CK, 2004, INT C IM PROC ICIP S, P873
   LIU RA, 2006, COMPUTER APPL, V26, P2101
   Morimoto CH, 2000, IMAGE VISION COMPUT, V18, P331, DOI 10.1016/S0262-8856(99)00053-0
   Noureddin B, 2005, COMPUT VIS IMAGE UND, V98, P52, DOI 10.1016/j.cviu.2004.07.005
   Ohno T., 2002, Proceedings ETRA 2002. Eye Tracking Research and Applications Symposium, P125, DOI 10.1145/507072.507098
   [任四刚 Ren Sigang], 2003, [光电工程, Opto-Electronic Engineering], V30, P53
   Rigling BD, 2006, IEEE T IMAGE PROCESS, V15, P1008, DOI 10.1109/TIP.2005.863943
   WOLFGANG K, 1998, OPTICAL ENG, V37, P369
   Xia Jingliang, 2005, Computer Measurement & Control, V13, P653
   Yoo DH, 2005, COMPUT VIS IMAGE UND, V98, P25, DOI 10.1016/j.cviu.2004.07.011
   Zhang Y, 2000, IMAGE VISION COMPUT, V18, P959, DOI 10.1016/S0262-8856(00)00038-X
   [周贤 Zhou Xian], 2006, [光学技术, Optical Technology], V32, P213
   [朱孔凤 ZHU Kongfeng], 2005, [光学技术, Optical Technology], V31, P910
   Zhu Zheng-tao, 2004, Optics and Precision Engineering, V12, P537
NR 21
TC 2
Z9 2
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2011
VL 52
IS 1
BP 33
EP 43
DI 10.1007/s11042-009-0455-9
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 716RF
UT WOS:000286990500004
DA 2024-07-18
ER

PT J
AU Yu, J
   Seah, HS
   Zhuang, YT
AF Yu, Jun
   Seah, Hock-Soon
   Zhuang, Yueting
TI Cartoon synthesis using constrained spreading activation network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cartoons; Synthesize; Features; Similarity; Constrained spreading
   activation algorithm; Perspective
AB In this paper, we propose an approach to synthesize cartoons from the existing cartoon data by controlling the character's path which is defined by the cartoonists in a background image. First, detailed pre-experiments are conducted in which different cartoon features are extracted and compared. During the pre-experiments, three features extracted from edge, motion and color are demonstrated effectively for evaluating cartoon similarity according to the quantitative analysis. The three features are then fused and a Cartoon Frame Relationship Network is constructed. Based on the graph, we propose a Constrained Spreading Activation Algorithm to select candidate frames which are visually similar to the current frame to generate the next frame. The cartoons are synthesized by choosing the most appropriate frame from the candidates in accordance with the path designed by the cartoonists. When the new cartoons are applied into the background image, our approach coordinates the cartoon character's size according to the image's perspective as well. The experiment results demonstrate that the combination of the three proposed features are effective in similarity evaluation, and the candidates selected by Constrained Spreading Activation Algorithm, are more similar to the current frame compared with other algorithms. The results also show that our approach can synthesize visually smooth cartoons from the existing cartoon library.
C1 [Yu, Jun; Seah, Hock-Soon] Nanyang Technol Univ, Sch Comp Engn, Singapore, Singapore.
   [Zhuang, Yueting] Zhejiang Univ, Coll Comp Sci, Hangzhou 310003, Zhejiang, Peoples R China.
C3 Nanyang Technological University; Zhejiang University
RP Yu, J (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore, Singapore.
EM yujun@ntu.edu.sg; ashsseah@ntu.edu.sg; yzhuang@cs.zju.edu.cn
RI Seah, Hock Soon/AAK-9900-2020
OI Seah, Hock Soon/0000-0003-2699-7147
FU National Research Foundation
FX This work has been supported by the National Research Foundation grant,
   which is administered by the Media Development Authority Interactive
   Digital Media Programme Office, MDA (IDMPO).
CR [Anonymous], P ACM MM
   [Anonymous], P S COMP AN
   [Anonymous], P ACM MULT
   [Anonymous], 1995, P 22 ANN C COMP GRAP, DOI DOI 10.1145/218380.218417
   BERGER H, 2004, P 1 AS PAC C CONC MO, P27
   CASTRO CL, 2008, BRAZ S NEUR NETW SBR, P141
   Chen H, 2002, USENIX ASSOCIATION PROCEEDINGS OF THE 11TH USENIX SECURITY SYMPOSIUM, P171
   CHRISTINA J, 2006, P ACM SIGGRAPH EUR S, P223
   Correa W.T., 1998, INT C COMPUTER GRAPH, P435
   Crestani F, 1997, ARTIF INTELL REV, V11, P453, DOI 10.1023/A:1006569829653
   Criminisi A, 2000, INT J COMPUT VISION, V40, P123, DOI 10.1023/A:1026598000963
   Flach PA, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P702
   Galvin B., 1998, PROC 9 BRIT MACHINE, V1, P195
   GARY K, 2007, P IEEE INT C INF REU, P104
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Kort A., 2002, NPAR 02, P125, DOI DOI 10.1145/508530.508552
   Kullback S., 1968, INFORM THEORY STAT
   LIU R, 2005, ACM T GRAPHIC, V24, P1090
   Mahmoudi F, 2003, PATTERN RECOGN, V36, P1725, DOI [10.1016/S0031-3203(03)00010-4, 10.1016/S0031-3203(03)000104]
   MARR D, 1980, J ROYAL SOC, V207, P187
   McDonnell R, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P259
   Petrovic L, 2000, COMP GRAPH, P511, DOI 10.1145/344779.345073
   Rastegari Mohammad, 2008, P DIG IM COMP TECHN, P320, DOI DOI 10.1109/DICTA.2008.51
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   SHRAGER J, 1987, SCIENCE, V236, P1092, DOI 10.1126/science.236.4805.1092
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Verma A, 2004, IEEE T MULTIMEDIA, V6, P791, DOI 10.1109/TMM.2004.837256
   WILLIAM VH, 2005, P INT C COMP GRAPH I, P245
   YU J, 2008, P INT C COMP AN SOC, P571
   Zhuang YT, 2008, IEEE T MULTIMEDIA, V10, P221, DOI 10.1109/TMM.2007.911822
NR 31
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2011
VL 51
IS 3
BP 1147
EP 1174
DI 10.1007/s11042-010-0477-3
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 717XL
UT WOS:000287081100014
DA 2024-07-18
ER

PT J
AU de Pinho, RD
   de Oliveira, MCF
   Lopes, AD
AF de Pinho, Roberto Dantas
   Ferreira de Oliveira, Maria Cristina
   Lopes, Alneu de Andrade
TI An incremental space to visualize dynamic data sets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic data set visualization; High-dimensional data visualization;
   Multidimensional scaling; Projection
ID SELF-ORGANIZING MAPS; ASSOCIATION; PROJECTION
AB In Information Visualization, adding and removing data elements can strongly impact the underlying visual space. We have developed an inherently incremental technique (incBoard) that maintains a coherent disposition of elements from a dynamic multidimensional data set on a 2D grid as the set changes. Here, we introduce a novel layout that uses pairwise similarity from grid neighbors, as defined in incBoard, to reposition elements on the visual space, free from constraints imposed by the grid. The board continues to be updated and can be displayed alongside the new space. As similar items are placed together, while dissimilar neighbors are moved apart, it supports users in the identification of clusters and subsets of related elements. Densely populated areas identified in the incSpace can be efficiently explored with the corresponding incBoard visualization, which is not susceptible to occlusion. The solution remains inherently incremental and maintains a coherent disposition of elements, even for fully renewed sets. The algorithm considers relative positions for the initial placement of elements, and raw dissimilarity to fine tune the visualization. It has low computational cost, with complexity depending only on the size of the currently viewed subset, V. Thus, a data set of size N can be sequentially displayed in O(N) time, reaching O(N (2)) only if the complete set is simultaneously displayed.
C1 [de Pinho, Roberto Dantas; Ferreira de Oliveira, Maria Cristina; Lopes, Alneu de Andrade] Univ Sao Paulo, BR-13560970 Sao Carlos, SP, Brazil.
C3 Universidade de Sao Paulo
EM robertopinho@acm.org; cristina@icmc.usp.br; alneu@icmc.usp.br
RI Lopes, Alneu D.A./F-1018-2011; Oliveira, Maria/ISB-2741-2023; Ferreira
   de Oliveira, Maria Cristina/D-9257-2011; Pinho, Roberto D/B-1241-2010
OI Ferreira de Oliveira, Maria Cristina/0000-0002-4729-5104; de Pinho,
   Roberto/0000-0002-2726-8731
FU FAPESP [2005/02263-2, 2008/046228]; CNPq [305861/20036-9]; CAPES [BEX
   0651-07-9]
FX The authors thank the financial support of FAPESP (Grants 2005/02263-2
   and 2008/046228) and CNPq (Grant 305861/20036-9). Part of Roberto
   Pinho's research was conducted while visiting Drexel University under
   the supervision of Dr. Chaomei Chen and the support of a CAPES PDEE
   Grant (BEX 0651-07-9). He wishes to thank Dr. Chen and fellow
   researchers at Drexel University for their invaluable contributions.
CR Alahakoon D, 2000, IEEE T NEURAL NETWOR, V11, P601, DOI 10.1109/72.846732
   Amarasiri R, 2005, 2005 IEEE/WIC/ACM International Conference on Web Intelligence, Proceedings, P215, DOI 10.1109/WI.2005.70
   [Anonymous], P 1 INT C MULT INF S
   Asuncion A., 2007, Uci machine learning repository
   Barioni M. C., 2002, Proceedings of the IASTED International Conference Information Systems and Databases, P264
   BASALAJ W, 2000, THESIS U CAMBRIDGE
   BEDERSON BB, 2001, UIST 01, P71, DOI DOI 10.1145/502348.502359
   Black PM, 1995, AUSTRALAS I MIN MET, V95, P55
   Börner K, 2003, ANNU REV INFORM SCI, V37, P179, DOI 10.1002/aris.1440370106
   Chalmers M, 1996, IEEE VISUAL, P127, DOI 10.1109/VISUAL.1996.567787
   Chen C., 2004, INFORM VISUALIZATION, V2nd
   Chen CM, 2006, J AM SOC INF SCI TEC, V57, P359, DOI 10.1002/asi.20317
   de Oliveira JBS, 2009, MULTIMED TOOLS APPL, V43, P275, DOI 10.1007/s11042-009-0267-y
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Kaski S, 1998, NEUROCOMPUTING, V21, P101, DOI 10.1016/S0925-2312(98)00039-3
   Kaski S., 1997, Ph.D. Thesis
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Kruskal JB, 1978, MULTIDIMENSIONAL SCA
   Law MHC, 2006, IEEE T PATTERN ANAL, V28, P377, DOI 10.1109/TPAMI.2006.56
   Law MHC, 2004, SIAM PROC S, P33
   Lewis DD, 2004, J MACH LEARN RES, V5, P361
   Li Y, 2005, IEEE I CONF COMP VIS, P1605
   Lopes AA, 2007, COMPUT GRAPH-UK, V31, P316, DOI 10.1016/j.cag.2007.01.023
   Malheiros Viviane, 2007, 2007 First International Symposium on Empirical Software Engineering and Measurement, P245
   Morrison A., 2004, Information Visualization, V3, P109, DOI 10.1057/palgrave.ivs.9500069
   Nürnberger A, 2002, IEEE IJCNN, P1912, DOI 10.1109/IJCNN.2002.1007811
   Paulovich FV, 2007, SIBGRAPI, P27, DOI 10.1109/SIBGRAPI.2007.21
   Paulovich FV, 2008, IEEE T VIS COMPUT GR, V14, P564, DOI 10.1109/TVCG.2007.70443
   Paulovich FV, 2006, INFORMATION VISUALIZATION-BOOK, P245
   PINHO R, 2009, SAC 09, P1757, DOI DOI 10.1145/1529282.1529679
   Pinho R, 2006, INFORMATION VISUALIZATION-BOOK, P39
   Pinho R, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P32, DOI 10.1109/IV.2009.12
   RODDEN K, 1999, P 1999 IEEE S INF VI
   RODDEN K, 2001, P SIGCHI C HUM FACT, P190, DOI DOI 10.1145/365024.365097
   SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678
   Wise JA, 1999, J AM SOC INFORM SCI, V50, P1224, DOI 10.1002/(SICI)1097-4571(1999)50:13<1224::AID-ASI8>3.0.CO;2-4
   Wong PC, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P97
NR 37
TC 7
Z9 7
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2010
VL 50
IS 3
SI SI
BP 533
EP 562
DI 10.1007/s11042-010-0483-5
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 630CC
UT WOS:000280248100006
DA 2024-07-18
ER

PT J
AU Valdés, V
   Martínez, JM
AF Valdes, Victor
   Martinez, Jose M.
TI A framework for video abstraction systems analysis and modelling from an
   operational point of view
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Video abstraction; Taxonomy; Algorithm performance
ID ALGORITHM; SCHEME
AB Nowadays the huge amount of video material stored in multimedia repositories makes its search and retrieval a very slow and usually difficult task. Existing video abstraction systems aim to relieve this problem by providing short versions of the original content which ease the search and navigation processes and reduce the browsing time. There are many approaches for video abstraction based on the optimal selection and presentation of a subset of fragments (keyframes, shots, etc.) from the original video attending to different criteria, usually dependent on the application scenario. Nevertheless, given the huge size and growth rate of existing video repositories there is an increasing need for providing efficient techniques. This paper presents a unified taxonomy and a generic architectural model aimed for the study of existing abstraction systems computational performance and characteristics. The taxonomy has been developed taking into account and identifying the operative characteristics of current state of the art video abstraction techniques. The proposed video abstraction architecture model characterizes the stages needed to build a generic abstraction process and establishes the basic architectural aspects and requirements for the modeling of systems with specific operative requirements.
C1 [Valdes, Victor; Martinez, Jose M.] Univ Autonoma Madrid, Escuela Politecn Super, E-28049 Madrid, Spain.
C3 Autonomous University of Madrid
RP Valdés, V (corresponding author), Univ Autonoma Madrid, Escuela Politecn Super, C Francisco Tomas & Valiente 11, E-28049 Madrid, Spain.
EM victor.valdes@uam.es; josem.martinez@uam.es
RI Martinez, Jose/A-1185-2008
OI Martinez, Jose/0000-0002-2236-1769
FU European Commission [IST-FP6-027685-Mesh]; Spanish Government
   [TEC2007-65400-SemanticVideo]; Comunidad de Madrid
   [S-0505/TIC-0223-ProMultiDis-CM]; Consejer a de Educacion of the
   Comunidad de Madrid; European Social Fund
FX Work supported by the European Commission (IST-FP6-027685-Mesh), Spanish
   Government (TEC2007-65400-SemanticVideo) and Comunidad de Madrid
   (S-0505/TIC-0223-ProMultiDis-CM), by the Consejer a de Educacion of the
   Comunidad de Madrid and by the European Social Fund.
CR Albanese M, 2006, INFORM SYST, V31, P679, DOI 10.1016/j.is.2005.12.003
   [Anonymous], 2018, WORKSHOP IIPHDW
   BERAN V, 2007, P ACM INT WORKSH TRE, P16
   Byrne D., 2007, Proceedings of 15th ACM International Conference on Multimedia, Workshop on TRECVID Video Summarization, P35
   Chang HS, 1999, IEEE T CIRC SYST VID, V9, P1269, DOI 10.1109/76.809161
   CHEN F, 2008, P ACM MULT 2008 TVS, P60
   CHRISTEL MG, 2006, P SOC PHOTO-OPT INS, V6073, P196
   CHRISTEL MG, 2008, P 2 ACM TRECVID VID, P35
   CIOCCA G, 2004, P SOC PHOTO-OPT INS, V5670, P137
   Divakaran A, 2002, IEEE IMAGE PROC, P932
   Doulamis ND, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P875, DOI 10.1109/ICIP.1998.723660
   DUMONT E, 2007, P INT WORKSH TRECVID, P55
   DUNDARAM H, 2001, P ICME2001, P273
   Fayzullin M, 2005, MULTIMED TOOLS APPL, V26, P153, DOI 10.1007/s11042-005-0451-7
   Gianluigi C, 2006, J REAL-TIME IMAGE PR, V1, P69, DOI 10.1007/s11554-006-0001-1
   GUNSEL B, 1998, P IEEE INT C IM PROC, V3, P128
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P1280, DOI 10.1109/76.809162
   HAUPTMANN AG, 2007, P ACM MULT 2007 INT, P94
   Hua XS, 2004, IEEE T CIRC SYST VID, V14, P572, DOI 10.1109/TCSVT.2004.826750
   KALIC J, 2002, P ITCC2002, P28
   KEBLAN J, 2007, P ACM MULT 2007 TVS, P84
   Koskela M., 2007, Proceedings of 15th ACM International Conference on Multimedia, Workshop on TRECVID Video Summarization, P45
   Latecki LJ, 2001, ISSPA 2001: SIXTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOLS 1 AND 2, PROCEEDINGS, P643, DOI 10.1109/ISSPA.2001.950227
   Lee HC, 2003, SIGNAL PROCESS-IMAGE, V18, P1, DOI 10.1016/S0923-5965(02)00089-9
   Li BX, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P169
   Li Y, 2006, IEEE SIGNAL PROC MAG, V23, P79
   Li Z, 2005, IEEE T IMAGE PROCESS, V14, P1550, DOI 10.1109/TIP.2005.854477
   Lienhart R, 1997, COMMUN ACM, V40, P54, DOI 10.1145/265563.265572
   Liu TC, 2002, LECT NOTES COMPUT SC, V2353, P403
   Liu TM, 2003, IEEE T CIRC SYST VID, V13, P1006, DOI 10.1109/TCSVT.2003.816521
   Liu Z., 2008, Proceedings of the TRECVID BBC Rushes Summarization Workshop (TVS 2008) at ACM Multimedia, P21, DOI [10.1145/1463563.1463565, DOI 10.1145/1463563.1463565]
   Ma Y.-F., 2002, ACM MULTIMEDIA, P533
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Over P., 2008, Proc. of the 2nd ACM TRECVid Video Summarization Workshop, P1, DOI [DOI 10.1145/1463563.1463564, 10.1145/1463563.1463564]
   Over P., 2007, TVS '07: Proc. of the International Workshop on TRECVID Video Summarization, P1, DOI DOI 10.1145/1290031.1290032
   RATAKONDA K, 1999, P SOC PHOTO-OPT INS, V3653, P1531
   Rilling J, 2007, 4TH IEEE INTERNATIONAL WORKSHOP ON VISUALIZING SOFTWARE FOR UNDERSTANDING AND ANALYSIS, PROCEEDINGS, P10
   TROUNG BT, 2007, ACM T MULTIM COMPUT, V3, P1
   Uchihashi S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P383, DOI 10.1145/319463.319654
   VALDES V, 2008, P 9 INT WORKSH IM AN, P88
   Valdes V., 2007, Proceedings of 15th ACM International Conference on Multimedia, Workshop on TRECVID Video Summarization, P94
   Valdés V, 2007, LECT NOTES COMPUT SC, V4816, P144
   Wildemuth BM, 2003, ACM-IEEE J CONF DIG, P221, DOI 10.1109/JCDL.2003.1204866
   Xiong ZY, 2003, IEEE IMAGE PROC, P5
   Yu XD, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P117
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 46
TC 6
Z9 6
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2010
VL 49
IS 1
SI SI
BP 7
EP 35
DI 10.1007/s11042-009-0392-7
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 595WF
UT WOS:000277643600002
DA 2024-07-18
ER

PT J
AU González-Castaño, FJ
   Asorey-Cacheda, R
   Cerezo-Costas, H
   Burguillo-Rial, JC
   Gil-Castiñeira, FJ
AF Gonzalez-Castano, Francisco J.
   Asorey-Cacheda, Rafael
   Cerezo-Costas, Hector
   Burguillo-Rial, Juan C.
   Gil-Castineira, Felipe J.
TI A zero-overhead error-correcting nVoD schema
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multicast; nVoD; Error correction
ID DEMAND; VIDEOS
AB In this paper we present a novel multicast near-Video on Demand (nVoD) coding schema, which relies on the intrinsic redundancy of the underlying nVoD protocol to provide implicit error correction, by employing content segments as blocks for coding operations. As a result, this implicit error correction has zero overhead, unlike the direct application of error-correcting codes, which increase content bitrate in the same proportion as target error probability. The findings in this paper indicate that our proposal outperforms previous approaches with explicit error correction (error protection within content segments) in terms of transmission bandwidth for the same packet loss probability. We present an analytical approach that can be used to tune implicit error correction (coding matrix selection), which we validate with simulations. We also simulate the impact of the coding schema on two different nVoD protocols, fast broadcasting (FB) and recursive frequency splitting (RFS). Finally, we show the benefits of applying this schema to a real scenario with WiMax transport.
C1 [Gonzalez-Castano, Francisco J.; Asorey-Cacheda, Rafael; Cerezo-Costas, Hector; Burguillo-Rial, Juan C.; Gil-Castineira, Felipe J.] Univ Vigo, Dept Enxeneria Telemat, Vigo 36310, Spain.
   [Gil-Castineira, Felipe J.] ETSE Telecomunicac, Galician Res & Dev Ctr Adv Telecommun, Vigo 36310, Spain.
C3 Universidade de Vigo; Universidade de Vigo
RP González-Castaño, FJ (corresponding author), Univ Vigo, Dept Enxeneria Telemat, Vigo 36310, Spain.
EM javier@det.uvigo.es; rasorey@det.uvigo.es; hcerezo@det.uvigo.es;
   jrial@det.uvigo.es; xil@det.uvigo.es
RI Gil-Castiñeira, Felipe/ABE-6411-2020; Burguillo, Juan
   Carlos/E-9091-2016; González-Castaño, Francisco J./D-2637-2018;
   Asorey-Cacheda, Rafael/K-1778-2015
OI Gil-Castiñeira, Felipe/0000-0002-5164-0855; Burguillo, Juan
   Carlos/0000-0001-9869-7448; Asorey-Cacheda, Rafael/0000-0003-0722-4181;
   Cerezo-Costas, Hector/0000-0003-2813-2462; Gonzalez-Castano, Francisco
   Javier/0000-0001-5225-8378
FU Xunta de Galicia, Spain [MIND-GAP-5 PGIDIT 08TIC010CT]; Ministerio de
   Educacion y Ciencia, Spain [CON-PARTE-2 TEC2007-67966-C03-02]
FX The work described in this paper has been supported by grants MIND-GAP-5
   PGIDIT 08TIC010CT (Xunta de Galicia, Spain) and CON-PARTE-2
   TEC2007-67966-C03-02 (Ministerio de Educacion y Ciencia, Spain).
CR Asorey-Cacheda R, 2008, IEEE ICC, P2017, DOI 10.1109/ICC.2008.387
   Azad SA, 2003, PROCEEDINGS OF THE 3RD IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, P339
   EAGER D, 1999, CST19991408 U WISC M
   Hua K. A., 1998, Proceedings ACM Multimedia 98, P191, DOI 10.1145/290747.290771
   Janakiraman R, 2002, IEEE INFOCOM SER, P920, DOI 10.1109/INFCOM.2002.1019339
   Juhn LS, 1997, FOURTH INTERNATIONAL WORKSHOP ON REAL-TIME COMPUTING SYSTEMS AND APPLICATIONS, PROCEEDINGS, P237, DOI 10.1109/RTCSA.1997.629229
   Juhn LS, 1997, IEEE T BROADCAST, V43, P268, DOI 10.1109/11.632927
   Ma HD, 2005, MULTIMED TOOLS APPL, V26, P101, DOI 10.1007/s11042-005-6851-x
   Ma HD, 2002, ACM SIGCOMM COMP COM, V32, P31, DOI 10.1145/510726.510729
   Mahanti A, 2003, IEEE ACM T NETWORK, V11, P195, DOI 10.1109/TNET.2003.810311
   Paris JF, 2005, IEEE IPCCC, P167
   Pâris JF, 2001, IEEE IC COMP COM NET, P418, DOI 10.1109/ICCCN.2001.956299
   PARIS JF, 1999, P 7 INT C COMP COMM, P690
   Peng C, 2006, LECT NOTES COMPUT SC, V4208, P642
   Reisslein M, 2004, MULTIMEDIA SYST, V9, P503, DOI 10.1007/s00530-003-0123-2
   Sujatha G, 2007, HORTIC SCI, V34, P1, DOI 10.17221/1842-HORTSCI
   Sun Y, 2005, LECT NOTES COMPUT SC, V3665, P190
   Tseng YC, 2002, IEEE T COMMUN, V50, P1348, DOI 10.1109/TCOMM.2002.801466
   XIE F, 2007, P 32 IEEE C LOC COMP, P287
   Yu HF, 2008, COMPUT COMMUN, V31, P2270, DOI 10.1016/j.comcom.2008.02.014
   Yu HF, 2008, IEEE T BROADCAST, V54, P304, DOI 10.1109/TBC.2008.915761
   Yu HF, 2007, IEEE T BROADCAST, V53, P103, DOI 10.1109/TBC.2006.888917
   Yu HF, 2009, MULTIMED TOOLS APPL, V42, P295, DOI 10.1007/s11042-008-0245-9
   Yu HF, 2009, IEEE T MULTIMEDIA, V11, P152, DOI 10.1109/TMM.2008.2008931
NR 24
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2010
VL 48
IS 2
BP 291
EP 312
DI 10.1007/s11042-009-0331-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 584AY
UT WOS:000276723600004
DA 2024-07-18
ER

PT J
AU Huang, F
   Klette, R
AF Huang, Fay
   Klette, Reinhard
TI Stereo panorama acquisition and automatic image disparity adjustment for
   stereoscopic visualization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereo panorama; Image-based rendering; Virtual reality system;
   High-accuracy panoramic imaging
AB Image-based visualization is popular for various virtual tour applications, due to high-quality photorealism or simplicity for rendering. Stereo panorama representations of the virtual world are already a common part of this, either in small (computer screen) format or on large-scale stereo displays or screens. This paper discusses methods for determining optimum parameters, both for high-accuracy stereo panoramic image recording and displaying, with a special focus on automatic image disparity enhancement while displaying (e.g., including zooming) a stereo panorama. Experiments show that the discussed parameters are indeed critical for ensuring high-quality stereo viewing. Derived formulas in this study are applicable to various kinds of technologies for stereo panorama imaging or stereoscopic displaying.
C1 [Huang, Fay] Natl Ilan Univ, Inst Comp Sci & Informat Engn, Yi Lan, Taiwan.
   [Klette, Reinhard] Univ Auckland, Dept Comp Sci, Auckland 1, New Zealand.
C3 National Ilan University; University of Auckland
RP Huang, F (corresponding author), Natl Ilan Univ, Inst Comp Sci & Informat Engn, Yi Lan, Taiwan.
EM fay@niu.edu.tw
RI Klette, Reinhard/B-7018-2012
OI Klette, Reinhard/0000-0001-8818-7145
FU National Science Council, Republic of China [NSC 95-2218-E-197-001]
FX This project is partially sponsored by the National Science Council,
   Republic of China, November 2006, (grant no. NSC 95-2218-E-197-001).
   Both authors thank colleagues at DLR Berlin-Adlershof for collaboration
   and support, especially with respect to data and experiments.
CR Chen CW, 2006, LECT NOTES COMPUT SC, V3851, P41
   Chen S. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P29, DOI 10.1145/218380.218395
   Howard I, 1995, OXFORD PSYCHOL SERIE, V29
   Huang F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P560, DOI 10.1109/ICCV.2001.937566
   HUANG F, 2001, CITRTR90 U AUCKL
   Huang F., 2008, PANORAMIC IMAGING SE
   Huang HC, 1998, GRAPH MODEL IM PROC, V60, P196, DOI 10.1006/gmip.1998.0467
   *HUMB U BERL, 2005, PAN PHOT WORKSH
   ISHIGURO H, 1992, IEEE T PATTERN ANAL, V14, P257, DOI 10.1109/34.121792
   Jiang AM, 2006, CMC-COMPUT MATER CON, V3, P1
   Kawanishi T, 1998, INT C PATT RECOG, P485, DOI 10.1109/ICPR.1998.711187
   Konrad J, 1999, P SOC PHOTO-OPT INS, V3639, P179, DOI 10.1117/12.349379
   *KST, 2008, KST EYESC M3D
   MURAKAMI M, 2006, STEREOMAKER STEREO P
   *NASA, 1998, MARS PATHF
   *NASA, STEREO PROJ
   Nayar SK, 1997, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1997.609369
   *PAN, 2008, PAN MK 3
   Peleg S, 2000, PROC CVPR IEEE, P208, DOI 10.1109/CVPR.2000.855821
   Peleg S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P395, DOI 10.1109/CVPR.1999.786969
   REULKE R, 1998, PHOTOGRAMM FERNERKUN, V3, P157
   Shum HY, 1999, COMP GRAPH, P299, DOI 10.1145/311535.311573
   SHUM HY, 1999, P INT C COMP VIS, P14
   Stürzl W, 2002, LECT NOTES COMPUT SC, V2525, P620
   VALYRUS N, 1966, STEREOSCOPY
   Viire E, 1997, COMMUN ACM, V40, P40, DOI 10.1145/257874.257882
   Wang C.-H., 2006, IEEE INT SOL STAT CI, P186
   Ware C, 1998, IEEE T SYST MAN CY A, V28, P56, DOI 10.1109/3468.650322
   Wei SK, 1999, LECT NOTES COMPUT SC, V1689, P542
NR 29
TC 13
Z9 14
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 47
IS 3
SI SI
BP 353
EP 377
DI 10.1007/s11042-009-0328-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 572BC
UT WOS:000275800200002
DA 2024-07-18
ER

PT J
AU Tsolis, DK
   Sioutas, S
   Papatheodorou, T
AF Tsolis, Dimitrios K.
   Sioutas, Spyros
   Papatheodorou, Theodore S.
TI A multimedia application for watermarking digital images based on a
   content based image retrieval technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Content based image retrieval; Spread spectrum analysis;
   Wavelet domain; Subband-DCT; Digital images
AB The current work is focused on the implementation of a robust multimedia application for watermarking digital images, which is based on an innovative spread spectrum analysis algorithm for watermark embedding and on a content-based image retrieval technique for watermark detection. The existing highly robust watermark algorithms are applying "detectable watermarks" for which a detection mechanism checks if the watermark exists or not (a Boolean decision) based on a watermarking key. The problem is that the detection of a watermark in a digital image library containing thousands of images means that the watermark detection algorithm is necessary to apply all the keys to the digital images. This application is non-efficient for very large image databases. On the other hand "readable" watermarks may prove weaker but easier to detect as only the detection mechanism is required. The proposed watermarking algorithm combine's the advantages of both "detectable" and "readable" watermarks. The result is a fast and robust multimedia application which has the ability to cast readable multibit watermarks into digital images. The watermarking application is capable of hiding 2(14) different keys into digital images and casting multiple zero-bit watermarks onto the same coefficient area while maintaining a sufficient level of robustness.
C1 [Tsolis, Dimitrios K.; Papatheodorou, Theodore S.] Univ Patras, Dept Comp Engn & Informat, Patras, Greece.
   [Sioutas, Spyros] Ionian Univ, Dept Informat, Corfu, Greece.
C3 University of Patras; Ionian University
RP Tsolis, DK (corresponding author), Univ Patras, Dept Comp Engn & Informat, Patras, Greece.
EM dkt@hpclab.ceid.upatras.gr
OI Tsolis, Dimitrios/0000-0003-0760-4942
CR Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Cox I. J., 2002, Digital Watermarking
   HOLT B, 2002, QBIC PROJECT DEP ART
   Kalker T, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P201, DOI 10.1109/MMSP.2001.962734
   KATZENBEISSER S, 2000, COMPUTER SERIES, P95
   KUTTER M, 1999, EL IM 99 SEC WAT MUL
   *NAT RES COUNC COM, 1999, DIG DIL INT PROP INF, P2
   Tsolis G.K., 2001, IEEE INT C IM PROC 2
   Wayner P., 2002, DISAPPEARING CRYPTOG, P291
NR 9
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 47
IS 3
SI SI
BP 581
EP 597
DI 10.1007/s11042-009-0338-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 572BC
UT WOS:000275800200011
DA 2024-07-18
ER

PT J
AU Konstantinidis, A
   Tsiatsos, T
   Pomportsis, A
AF Konstantinidis, A.
   Tsiatsos, Th.
   Pomportsis, A.
TI Collaborative virtual learning environments: design and evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collaborative learning; CSCL; Virtual classroom; Collaborative virtual
   environment; Educational multimedia application
AB E-learning systems have gone through a radical change from the initial text-based environments to more stimulating multimedia systems. Such systems are Collaborative Virtual Environments, which could be used in order to support collaborative e-learning scenarios. The main aim of this paper is to aid educational designers in selecting, designing and evaluating three dimensional collaborative virtual environments in order to gain the pedagogical benefits of Computer Supported Collaborative Learning. Therefore, this paper initially discusses the potential of three dimensional networked virtual environments for supporting collaborative learning. Furthermore, based on a two-step platform selection process this paper (a) presents and compares three dimensional multi-user virtual environments for supporting collaborative learning and (b) validates the most promising solution against a set of design principles for educational virtual environments. According to these principles, an educational environment has been implemented on top of the selected platform in order to support collaborative e-learning scenarios. The design of this environment is also presented. In addition, this paper presents the results of three small scale studies carried out in a tertiary education department, to assess the educational environment. This environment has been evaluated based on a hybrid evaluation methodology for uncovering usability problems, collecting further requirements for additional functionality to support collaborative virtual learning environments, and determining the appropriateness of different kinds of learning scenarios.
C1 [Konstantinidis, A.; Tsiatsos, Th.; Pomportsis, A.] Aristotle Univ Thessaloniki, Dept Comp Sci, GR-54006 Thessaloniki, Greece.
C3 Aristotle University of Thessaloniki
RP Tsiatsos, T (corresponding author), Aristotle Univ Thessaloniki, Dept Comp Sci, GR-54006 Thessaloniki, Greece.
EM akons@csd.auth.gr; tsiatsos@csd.auth.gr; apombo@csd.auth.gr
CR [Anonymous], 1992, Proceedings of the 1992 ACM Conference on Computer Supported Cooperative Work (CSCW'92), DOI DOI 10.1145/143457.143468
   [Anonymous], 1990, COGN ED MULTIMED EXP
   [Anonymous], 1997, JIGSAW CLASSROOM BUI
   ARONSON E, 1979, PERS SOC PSYCHOL B, V5, P438, DOI 10.1177/014616727900500405
   Bartle R., 2003, Designing Virtual Worlds
   Bedford Carly, 2006, Proceedings of the Second Life Education Workshop, P25
   BOURAS C, 2006, INT J MULTIMEDIA TOO
   Bouras C., 2008, International Journal of Web-Based Learning Teaching Technologies, V3, P1
   BRUCKMAN A, 2001, P COMP SUPP COLL LEA, P629
   Churchill E. F., 2001, COLLABORATIVE VIRTUA
   Dillenbourg P., 1996, Learning in humans and machines: Towards an interdisciplinary learning science, P189, DOI DOI 10.1007/978-1-4020-9827-7_1
   DIMITRACOPOULOU A, 2005, COMPUTER SUPPORT COL
   ELLIS CA, 1991, COMMUN ACM, V34, P1
   GRUDIN J, 1991, INT J MAN MACH STUD, V34, P435, DOI 10.1016/0020-7373(91)90029-7
   Gutwin C., 1999, ACM Transactions on Computer-Human Interaction, V6, P243, DOI 10.1145/329693.329696
   Gutwin Carl., 1996, Proc.ACMConferenceonComputer-SupportedCooperativeWork, P258, DOI [10.1145/240080.240298, DOI 10.1145/240080.240298]
   Kim Hock Ang Qiyun Wang., 2006, Proceedings of The First International LAMS Conference 2006: Designing the Future of Learning, P5
   Kreijns K, 2003, COMPUT HUM BEHAV, V19, P335, DOI 10.1016/S0747-5632(02)00057-2
   Lee EAL, 2008, LECT NOTES COMPUT SC, V5080, P231
   LOMBARDI M, 2005, STANDING PLATEAU LOO
   MULLER K, 2002, ACM SIG P NEW ORL LO
   Piaget J., 1926, The child's conception of the world
   Prasolova-Forland E, 2008, COMPUT HUM BEHAV, V24, P185, DOI 10.1016/j.chb.2007.01.009
   SALAHEDDIN O, 2007, INT J EMERGING TECHN, V2
   Schoder D., 2005, P2P COMPUTING EVOLUT
   Schuler D., 1993, Participatory Design: Principles and Practices
   SEBRECHTS MM, 1999, 22 ANN INT ACM SIGIR
   Strijbos J.W., 2004, What we know about CSCL: And implementing it in higher education
   Veerman A., 2001, Euro CSCL 2001, P625
   Vygotsky L.S., 1987, Thought and language, V2nd
   Winn W, 2002, EDUC PSYCHOL REV, V14, P331, DOI 10.1023/A:1016068530070
   Zhigeng P., 2005, COLLABORATIVE VIRTUA
NR 32
TC 21
Z9 31
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2009
VL 44
IS 2
BP 279
EP 304
DI 10.1007/s11042-009-0289-5
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 464ED
UT WOS:000267487100006
DA 2024-07-18
ER

PT J
AU Ruiz-Reyes, N
   Vera-Candeas, P
   Muñoz, JE
   García-Galán, S
   Cañadas, FJ
AF Ruiz-Reyes, N.
   Vera-Candeas, P.
   Munoz, J. E.
   Garcia-Galan, S.
   Canadas, F. J.
TI New speech/music discrimination approach based on fundamental frequency
   estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech/music discrimination; Signal features; Pitch; Fundamental
   frequency estimation; Multimedia; Pattern recognition; Fuzzy systems
ID REPRESENTATIONS; CLASSIFICATION; MUSIC
AB Automatic discrimination of speech and music is an important tool in many multimedia applications. The paper presents a robust and effective approach for speech/music discrimination, which relies on a set of features derived from fundamental frequency (F0) estimation. Comparison between the proposed set of features and some commonly used timbral features is performed, aiming to assess the good discriminatory power of the proposed F0-based feature set. The classification scheme is composed of a classical Statistical Pattern Recognition classifier followed by a Fuzzy Rules Based System. Comparison with other well-proven classification schemes is also performed. Experimental results reveal that our speech/music discriminator is robust enough, making it suitable for a wide variety of multimedia applications.
C1 [Ruiz-Reyes, N.; Vera-Candeas, P.; Munoz, J. E.; Garcia-Galan, S.; Canadas, F. J.] Univ Jaen, Polytech Sch, Dept Telecommun Engn, Jaen, Spain.
C3 Universidad de Jaen
RP Ruiz-Reyes, N (corresponding author), Univ Jaen, Polytech Sch, Dept Telecommun Engn, Jaen, Spain.
EM nicolas@ujaen.es; pvera@ujaen.es; jemunoz@ujaen.es; sgalan@ujaen.es;
   fcanadas@ujaen.es
RI Vera-Candeas, Pedro/L-3428-2014; Cañadas-Quesada, Francisco
   Jesús/H-8839-2015; Exposito, Jose Enrique Muñoz/I-2507-2015; Garcia
   Galan, Sebastian/H-9089-2015; Ruiz Reyes, Nicolas/R-5878-2018
OI Vera-Candeas, Pedro/0000-0003-0866-703X; Cañadas-Quesada, Francisco
   Jesús/0000-0002-3873-6078; Garcia Galan, Sebastian/0000-0002-3300-5794;
   Ruiz Reyes, Nicolas/0000-0003-4631-5326
CR [Anonymous], 2002, J ACOUST SOC AM, DOI DOI 10.1121/1.1458024
   [Anonymous], 2000, ISMIR
   [Anonymous], ADV FUZZY SYSTEMS AP
   [Anonymous], 1983, PITCH DETERMINATION, DOI DOI 10.1007/978-3-642-81926-1
   [Anonymous], 1982, THESIS U MICHIGAN AN
   Barbedo J. G. A., 2007, IEEE LATIN AM T, V5, P294
   Burred JJ, 2004, J AUDIO ENG SOC, V52, P724
   Carey M.J., 1999, IEEE international conference on acoustics, speech and signal processing (ICASSP), V1, P1432
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Duda R., 1973, Pattern Classification and Scene Analysis
   El-Maleh K, 2000, INT CONF ACOUST SPEE, P2445, DOI 10.1109/ICASSP.2000.859336
   Every MR, 2008, IEEE T AUDIO SPEECH, V16, P267, DOI 10.1109/TASL.2007.908128
   Expósito JEM, 2007, IEEE INT CONF FUZZY, P822
   EZZAIDI H, 2007, IEEE WORKSH MACH LEA, P241
   Fujiwara Hiroshi, 2006, Reproductive Medicine and Biology, V5, P19, DOI 10.1111/j.1447-0578.2006.00119.x
   Garau G, 2008, IEEE T AUDIO SPEECH, V16, P508, DOI 10.1109/TASL.2008.916519
   Gong C, 2006, PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, VOLS 1 AND 2, P68
   Harb H, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 2, PROCEEDINGS, P125, DOI 10.1109/ISSPA.2003.1224831
   Hess WolfgangJ., 1992, Advances in Speech Signal Processing
   HIROSE K, 2000, P IEEE INT C AC SPEE, V3, P1763
   Karneback S., 2001, EUR C SPEECH COMM TE, P1891
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5
   Keum JS, 2006, I S INTELL SIG PROC, P299
   Lu L, 2002, IEEE T SPEECH AUDI P, V10, P504, DOI 10.1109/TSA.2002.804546
   Malik H, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA257
   MATSUNAGTA S, 2004, P EUSIPCO SEP, P2104
   Minami K, 1998, IEEE MULTIMEDIA, V5, P17, DOI 10.1109/93.713301
   Molla Khademul Islam, 2007, Proceedings of the International Conference on Information and Communication Technology, ICICT 2007, P311
   Muñoz-Expósito JE, 2007, ENG APPL ARTIF INTEL, V20, P783, DOI 10.1016/j.engappai.2006.10.007
   Muñoz-Expósito JE, 2006, J NEW MUSIC RES, V35, P237, DOI 10.1080/09298210601045682
   Panagiotakis C, 2005, IEEE T MULTIMEDIA, V7, P155, DOI 10.1109/TMM.2004.840604
   Paradzinets A, 2007, INT WORK CONTENT MUL, P165
   POLITIS D, 2000, 10 MED EL C MELECON, V2, P725
   Qiao RY, 1997, TENCON IEEE REGION, P605, DOI 10.1109/TENCON.1997.648278
   RENTZOS D, 2004, IEEE INT C AC SPEECH, V1, P21
   Richard G, 2007, INT CONF ACOUST SPEE, P461
   SAITOU T, 2007, IEEE WORKSH APPL SIG, P215
   Saunders J, 1996, INT CONF ACOUST SPEE, P993, DOI 10.1109/ICASSP.1996.543290
   Scheirer E, 1997, INT CONF ACOUST SPEE, P1331, DOI 10.1109/ICASSP.1997.596192
   Smith S. F., 1980, A learning system based on genetic adaptive algorithms
   TANCEREL L, 2000, P IEEE WORKSH SPEECH, P17
   Tzanetakis George., 2002, IEEE T SPEECH AUDIO, V10
   VENTURINI G, 1992, P EUR C MACH LEARN E, P280
   Wang J, 2008, INT CONF ACOUST SPEE, P2033
   Wang WQ, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P1325
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang Tong., 2001, IEEE T SPEECH AUDIO, V9
NR 47
TC 8
Z9 10
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2009
VL 41
IS 2
BP 253
EP 286
DI 10.1007/s11042-008-0228-x
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Engineering
GA 387NI
UT WOS:000261958500005
DA 2024-07-18
ER

PT J
AU Mylonas, P
   Athanasiadis, T
   Wallace, M
   Avrithis, Y
   Kollias, S
AF Mylonas, Phivos
   Athanasiadis, Thanos
   Wallace, Manolis
   Avrithis, Yannis
   Kollias, Stefanos
TI Semantic representation of multimedia content: Knowledge representation
   and semantic indexing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia content semantics extraction; semantic indexing; semantic
   classification
ID ANNOTATION; RETRIEVAL; FRAMEWORK; SCENE
AB In this paper we present a framework for unified, personalized access to heterogeneous multimedia content in distributed repositories. Focusing on semantic analysis of multimedia documents, metadata, user queries and user profiles, it contributes to the bridging of the gap between the semantic nature of user queries and raw multimedia documents. The proposed approach utilizes as input visual content analysis results, as well as analyzes and exploits associated textual annotation, in order to extract the underlying semantics, construct a semantic index and classify documents to topics, based on a unified knowledge and semantics representation model. It may then accept user queries, and, carrying out semantic interpretation and expansion, retrieve documents from the index and rank them according to user preferences, similarly to text retrieval. All processes are based on a novel semantic processing methodology, employing fuzzy algebra and principles of taxonomic knowledge representation. The first part of this work presented in this paper deals with data and knowledge models, manipulation of multimedia content annotations and semantic indexing, while the second part will continue on the use of the extracted semantic information for personalized retrieval.
C1 [Mylonas, Phivos; Athanasiadis, Thanos; Avrithis, Yannis; Kollias, Stefanos] Natl Tech Univ Athens, Sch Elect & Comp Engn, GR-15773 Athens, Greece.
   [Wallace, Manolis] Univ Indianapolis, Dept Comp Sci, Athens 10557, Greece.
C3 National Technical University of Athens
RP Mylonas, P (corresponding author), Natl Tech Univ Athens, Sch Elect & Comp Engn, 9 Iroon Polytech Str,Zographou Campus, GR-15773 Athens, Greece.
EM fmylonas@image.ntua.gr; thanos@image.ntua.gr; wallace@uindy.gr;
   iavr@image.ntua.gr; stefanos@cs.ntua.gr
RI Mylonas, Phivos/AAF-2497-2019; Kollias, Stefanos/ACY-7285-2022
OI Mylonas, Phivos/0000-0002-6916-3129; Kollias,
   Stefanos/0000-0003-2899-0598; Wallace, Manolis/0000-0002-4629-5946
CR Akrivas G, 2004, IEEE T SYST MAN CY A, V34, P190, DOI 10.1109/TSMCA.2003.819498
   Altenschmidt C., 2003, Journal of Computer Security, V11, P365
   Altenschmidt C, 2002, LECT NOTES COMPUT SC, V2544, P103
   AMIR A, 2003, P NIST TRECVID WORKS
   [Anonymous], 1998, PATTERN RECOGNITION
   [Anonymous], P INT SEM WEB WORK S
   [Anonymous], P 5 INT WORKSH KNOWL
   [Anonymous], P IEEE INT C MULT EX
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], P IEEE INT C ART INT
   [Anonymous], P INT WORKSH VER LOW
   [Anonymous], P 5 INT INT C MOD US
   ATHANASIADIS T, 2004, P INT C IM VID RETR
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Benitez AB, 2002, IEEE IMAGE PROC, P137
   Benitez AB, 2000, SIGNAL PROCESS-IMAGE, V16, P235, DOI 10.1016/S0923-5965(00)00030-8
   BENITEZ AB, 2003, P IEEE INT C IM PROC
   BENITEZ AB, 2001, P INT C COMP AN IM P
   BENITEZ AB, 2001, P 9 ACM MULT OTT CAN
   BENITEZ AB, 2003, P 37 AS C SIGN SYST
   Benkhalifa M, 1999, 18TH INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS, P561, DOI 10.1109/NAFIPS.1999.781756
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Berry MW, 1995, SIAM REV, V37, P573, DOI 10.1137/1037127
   BERTINI M, 2005, P 13 ANN ACM INT C M
   BISKUP J, 1997, P 3 INT WORKSH MULT
   Bloehdorn S, 2005, LECT NOTES COMPUT SC, V3532, P592
   Brunelli R, 1999, J VIS COMMUN IMAGE R, V10, P78, DOI 10.1006/jvci.1997.0404
   BURGIN R, 1995, J AM SOC INFORM SCI, V46, P562, DOI 10.1002/(SICI)1097-4571(199509)46:8<562::AID-ASI2>3.0.CO;2-B
   Burnett I, 2003, IEEE MULTIMEDIA, V10, P60, DOI 10.1109/MMUL.2003.1237551
   Cai L., 2003, P 26 ANN INT ACM SIG, P182
   CUTTING DR, 1992, SIGIR 92 : PROCEEDINGS OF THE FIFTEENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P318
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   DENOYER L, 2003, P ACM DOCENG C GREN
   DOERR M, 2003, J DIGIT INF, V4
   DORAI C, 2001, IEEE MULTIMEDIA, V8, P10
   Fagin R, 2003, J COMPUT SYST SCI, V66, P614, DOI 10.1016/S0022-0000(03)00026-6
   FAGIN R, 2003, P 2003 ACM SIGMOD IN, P301, DOI DOI 10.1145/872757.872795
   GARCIA R, 2005, P 5 INT WORKSH KNOWL
   GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008
   Hauptmann AG, 2005, LECT NOTES COMPUT SC, V3568, P1
   HAUPTMANN AG, 2002, P TEXT RETR C TREC02
   HAUPTMANN AG, 2003, P NIST TRECVID WORKS
   HAUPTMANN AG, 2004, P 3 INT C IM VID RET
   Henderson JM, 1999, ANNU REV PSYCHOL, V50, P243, DOI 10.1146/annurev.psych.50.1.243
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   HOLLINK L, 2005, P ACM MULT SING NOV
   HOOGS A, 2003, P IEEE COMP SOC C CO
   Hunter J, 2003, IEEE T CIRC SYST VID, V13, P49, DOI 10.1109/TCSVT.2002.808088
   HUNTER J, 1999, MPEG 7 AHG TEST EV M
   *ISO IEC, 2002, JTC1SC29WG11N5231 IS
   *ISO IEC FDIS, 2001, 159385 ISOIEC FDIS, P442
   Klir G., 1995, Fuzzy sets and fuzzy logic, V4
   Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028
   MACLEOD K, 1990, P 4 ANN PAR PROC S, V1, P5
   Milanese R., 1993, THESIS U GENEVA SWIT
   Miyamoto S., 1990, FUZZY SETS INFORM RE
   Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141, DOI 10.1109/6046.909601
   Naphade MR, 2002, IEEE T CIRC SYST VID, V12, P40
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   OSBERGER W, 1998, P IEEE INT C PATT RE
   Papadopoulos GT, 2006, INT J SEMANT WEB INF, V2, P17, DOI 10.4018/jswis.2006070102
   Petridis K, 2006, IEE P-VIS IMAGE SIGN, V153, P255, DOI 10.1049/ip-vis:20050059
   SAHAMI, 1997, P NAT C ART INT, P845
   Salembier P, 2001, IEEE T CIRC SYST VID, V11, P748, DOI 10.1109/76.927435
   SCHUTZE, 1997, CRAIG PROJECTIONS EF, P74
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   SIMOU N, 2005, INT WORKSH VLBV05 SA
   SIMOU N, 2005, P WORKSH IM AN MULT
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SMITH JR, 2006, MARVEL MULTIMEDIA AN
   SMITH JR, 2004, HDB IMAGE VIDEO DATA
   SNOEK C, 2005, P ACM MULT SING NOV
   SNOEK C, 2006, P 2006 INT C MULT EX
   Snoek CGM, 2006, ACM T MULTIM COMPUT, V2, P91, DOI 10.1145/1142020.1142021
   Staab S., 2010, Handbook on Ontologies. International Handbooks on Information Systems
   Stamou G, 2005, MULTIMEDIA CONTENT AND THE SEMANTIC WEB: METHODS, STANDARDS AND TOOLS, P1, DOI 10.1002/0470012617
   Troncy R, 2003, LECT NOTES COMPUT SC, V2870, P566
   TSECHPENAKIS G, 2002, P EUR S INT TECHN HY
   TSINARAKI C, 2004, P 16 INT C ADV INF S
   TZITZIKAS Y, 2004, FDN INF KNOWL SYST 3
   VOISINE N, 2005, P 6 INT WORKSH IM AN
   *W3C, 2006, WEB ONT LANG OWL
   *W3C, 2006, SEM WEB
   *W3C, 2006, XML SCHEM
   *W3C, 2006, SWBPD MM TASK FORC D
   Wallace M, 2006, FUZZY SET SYST, V157, P341, DOI 10.1016/j.fss.2005.06.005
   WALLACE M, 2003, P 3 INT WORKSH CONT
   Wallace M, 2005, MULTIMEDIA CONTENT AND THE SEMANTIC WEB: METHODS, STANDARDS AND TOOLS, P299, DOI 10.1002/0470012617.ch12
   WILLETT P, 1988, INFORM PROCESS MANAG, V24, P577, DOI 10.1016/0306-4573(88)90027-1
   Zhao R, 2002, IEEE T MULTIMEDIA, V4, P189, DOI 10.1109/TMM.2002.1017733
   Zhong D, 1999, IEEE T CIRC SYST VID, V9, P1259, DOI 10.1109/76.809160
NR 92
TC 8
Z9 10
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2008
VL 39
IS 3
BP 293
EP 327
DI 10.1007/s11042-007-0161-4
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 328BF
UT WOS:000257771600001
DA 2024-07-18
ER

PT J
AU Farella, E
   Pieracci, A
   Benini, L
   Rocchi, L
   Acquaviva, A
AF Farella, Elisabetta
   Pieracci, Augusto
   Benini, Luca
   Rocchi, Laura
   Acquaviva, Andrea
TI Interfacing human and computer with wireless body area sensor networks:
   the WiMoCA solution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT Workshop on Natural Interaction
CY APR, 2004
CL Florence, ITALY
DE body area networks; wireless; movement tracking; human-computer
   interaction
ID POSTURAL SWAY; ACCELEROMETRY; BALANCE
AB Wireless Body Area Sensor Networks (WBASN) are an emerging technology enabling the design of natural human-computer interfaces (HCI). Automatic recognition of human motion, gestures, and activities is studied in several contexts. For example, mobile computing technology is being considered as a replacement of traditional input systems. Moreover, body posture and activity monitoring can be used for entertainment and health-care applications. However, until now, little work has been done to develop flexible and efficient WBASN solutions suitable for a wide range of applications. Their requirements pose new challenges for sensor network designs, such as optimizing traditional solutions for use as environmental monitoring-like applications and developing on-the-field stress tests. In this paper, we demonstrate the flexibility of a custom-designed WBASN called WiMoCA with respect to a wide range of posture and activity recognition applications by means of practical implementation and on-the-field testing. Nodes of the network mounted on different parts of the human body exploit tri-axial accelerometers to detect its movements. The advanced digital Micro-electro-mechanical system (MEMS) based inertial sensor has been chosen for WiMoCA because it demonstrated high flexibility of use in many different situations, providing the chance to exploit both static and dynamic acceleration components for different purposes. Furthermore, the sensibility and accuracy of the sensing element is perfectly adequate for monitoring human movement, while keeping cost low and size compact, thus meeting our requirements. We implemented three types of applications, stressing the WBASN in many aspects. In fact, they are characterized by different requirements in terms of accuracy, timeliness, and computation distributed on sensing nodes. For each application, we describe its implementation, and we discuss results about performance and power consumption.
C1 [Farella, Elisabetta; Pieracci, Augusto; Benini, Luca; Rocchi, Laura] Univ Bologna, DEIS, Bologna, Italy.
   [Acquaviva, Andrea] ISTI Urbino Univ, Urbino, Italy.
C3 University of Bologna; University of Urbino
RP Farella, E (corresponding author), Univ Bologna, DEIS, Bologna, Italy.
EM elisabetta.farella@unibo.it; augusto.pieracci@unibo.it;
   luca.benini@unibo.it; l.rocchi@unibo.it; acquaviva@sti.uniurb.it
RI Acquaviva, Andrea/E-7584-2012; Farella, Elisabetta/H-1937-2012
OI Farella, Elisabetta/0000-0001-9047-9868; BENINI,
   LUCA/0000-0001-8068-3806
CR Aminian K, 1998, LECT NOTES ARTIF INT, V1537, P1
   Angesleva J., 2003, P 16 ANN ACM S US IN
   [Anonymous], 1999, Encyclopedia of Statistical Sciences
   [Anonymous], SENSYS 2003
   [Anonymous], IEEE PERVASIVE COMPU
   BACHMANN ER, 2003, P 2003 IEEE INT C RO, P14
   Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1
   Barbieri R, 2004, CCNC 2004: 1ST IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE, PROCEEDINGS, P418
   Brunelli D, 2006, FOURTH ANNUAL IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS WORKSHOPS, PROCEEDINGS, P527, DOI 10.1109/PERCOMW.2006.27
   Bussmann JBJ, 2001, BEHAV RES METH INS C, V33, P349, DOI 10.3758/BF03195388
   Caccamo M, 2002, REAL TIM SYST SYMP P, P39, DOI 10.1109/REAL.2002.1181560
   Cattaneo D, 2005, ARCH PHYS MED REHAB, V86, P1381, DOI 10.1016/j.apmr.2004.12.029
   Chiari L, 2005, IEEE T BIO-MED ENG, V52, P2108, DOI 10.1109/TBME.2005.857673
   CHOEK AD, 2002, WEARABLE COMPUTERS 2, P223
   Coley B, 2005, GAIT POSTURE, V22, P287, DOI 10.1016/j.gaitpost.2004.08.008
   Culhane KM, 2005, AGE AGEING, V34, P556, DOI 10.1093/ageing/afi192
   Delac K, 2004, PROCEEDINGS ELMAR-2004: 46TH INTERNATIONAL SYMPOSIUM ELECTRONICS IN MARINE, P184
   FAIDLEY G, 2004, WEARABLE COMPUTERS 2, V1, P178
   Farella E, 2005, 2005 SYSTEMS COMMUNICATIONS, PROCEEDINGS, P342, DOI 10.1109/ICW.2005.39
   Farella E, 2005, IEEE MULTIMEDIA, V12, P46, DOI 10.1109/MMUL.2005.54
   Farella E, 2006, LECT NOTES COMPUT SC, V3968, P288
   Foxlin E, 2000, FOURTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, DIGEST OF PAPERS, P155, DOI 10.1109/ISWC.2000.888482
   HARADA T, 2003, MULTISENSOR FUSION I
   Headon R, 2003, P IEE EUR, P107
   JARNLO GB, 1991, ACTA ORTHOP SCAND, V62, P427, DOI 10.3109/17453679108996638
   Jovanov Emil, 2005, J Neuroeng Rehabil, V2, P6, DOI 10.1186/1743-0003-2-6
   Junker H, 2003, SEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P244, DOI 10.1109/ISWC.2003.1241420
   Kahn JM, 2000, J COMMUN NETW, V2, P188, DOI 10.1109/JCN.2000.6596708
   Kern N, 2003, LECT NOTES COMPUT SC, V2875, P220
   Lee SW, 2001, PROCEEDINGS OF THE 2001 IEEE INTERNATIONAL CONFERENCE ON CONTROL APPLICATIONS (CCA'01), P1152, DOI 10.1109/CCA.2001.974027
   Maki BE, 1996, CLIN GERIATR MED, V12, P635
   MANTYJARVI J, 2005, ACOUSTICS SPEECH SIG, V2
   Mathie MJ, 2004, PHYSIOL MEAS, V25, pR1, DOI 10.1088/0967-3334/25/2/R01
   Moe-Nilssen R, 1998, CLIN BIOMECH, V13, P320, DOI 10.1016/S0268-0033(98)00089-8
   Morris SJ, 2002, P ANN INT IEEE EMBS, P2468, DOI 10.1109/IEMBS.2002.1053379
   OAKLEY I, 2004, P EUROHAPTICS JUN, P313
   PARADISO J, 2002, ANOMALIE, V2, P34
   PERNG JK, 1999, IEEE S WEAR COMP, P178
   Randell C, 2000, FOURTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, DIGEST OF PAPERS, P175, DOI 10.1109/ISWC.2000.888488
   Rocchi L, 2002, J NEUROL NEUROSUR PS, V73, P267, DOI 10.1136/jnnp.73.3.267
   SAMA M, 2006, P IEEE DES AUT TEST
   Schmit JM, 2005, EXP BRAIN RES, V163, P370, DOI 10.1007/s00221-004-2185-6
   Stankovic JA, 2003, P IEEE, V91, P1002, DOI 10.1109/JPROC.2003.814620
   Uswatte G, 2000, STROKE, V31, P662, DOI 10.1161/01.STR.31.3.662
   Veltink P H, 1996, IEEE Trans Rehabil Eng, V4, P375, DOI 10.1109/86.547939
   Winter DA, 1996, J NEUROPHYSIOL, V75, P2334, DOI 10.1152/jn.1996.75.6.2334
   Zhu R, 2004, IEEE T NEUR SYS REH, V12, P295, DOI 10.1109/TNSRE.2004.827825
NR 47
TC 43
Z9 50
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2008
VL 38
IS 3
BP 337
EP 363
DI 10.1007/s11042-007-0189-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 300ZV
UT WOS:000255866300004
DA 2024-07-18
ER

PT J
AU Valli, A
AF Valli, Alessandro
TI The design of natural interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT Workshop on Natural Interaction
CY APR, 2004
CL Florence, ITALY
DE interaction design; multimodal interfaces; ubiquitous computing
AB This paper addresses the problem of the relationship between humans and technology-enhanced spaces and physical objects (later defined as artifacts). The class of cases here analyzed includes interactive digital signage, information kiosks, home media centers and interactive spaces whose purpose is the communication of a meaning. In this domain, complex interfaces are not needed, as common people interaction with information, content and media is in most cases extremely simple. The topic of specialized interfaces for expert users is not addressed here; the focus is on interfaces for the general public, whose main purpose is the basic fruition of digital information, although such information can be large and complex in its organization. This paper is centered on the need of conceiving computer sensing and information presentation as different aspects of the same interaction design problem, instead of separate research entities.
C1 Univ Florence, Florence, Italy.
C3 University of Florence
RP Valli, A (corresponding author), Univ Florence, Florence, Italy.
EM av@naturalinteraction.org
CR BEDERSON B, 1994, P USER INTERFACE SOF
   CHANG B, 1995, TR9533 SUN MICR
   Colombo C, 2003, IEEE T SYST MAN CY B, V33, P677, DOI 10.1109/TSMCB.2003.814281
   DOURISH P, 2000, CHI 2000 WORKSH SIT
   Ishii H., 1997, P CHI97ACM MARCH
   MAZALEK A, 2002, P 10 ACM INT C MULT
   Mitchell W., 1999, e-topia: Urban Life, Jim--but not as we know it
   Norman DonaldA., 2003, EMOTIONAL DESIGN
   Norman DonaldA., 1990, DESIGN EVERYDAY THIN
   Pentland AP, 1996, SCI AM, V274, P68, DOI 10.1038/scientificamerican0496-68
   SPARACINO F, 2003, P UB SEATTL US
   Sparacino F., 2002, 6 INT C GEN ART MIL
   Weiser Mark, 1995, DESIGNING CALM TECHN
NR 13
TC 53
Z9 67
U1 4
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2008
VL 38
IS 3
BP 295
EP 305
DI 10.1007/s11042-007-0190-z
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 300ZV
UT WOS:000255866300002
DA 2024-07-18
ER

PT J
AU Krepki, R
   Blankertz, B
   Curio, G
   Müller, KR
AF Krepki, Roman
   Blankertz, Benjamin
   Curio, Gabriel
   Mueller, Klaus-Robert
TI The Berlin Brain-Computer Interface (BBCI) -: towards a new
   communication channel for online control in gaming applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 9th International Conference on Distributed Multimedia Systems (DMS
   03)/6th International Conference on Visual Information Systems (VIS
   2003)
CY SEP   24, 2003-SEP 26, 2006
CL Miami, FL
DE brain-computer interface; electroencephalography; digital signal
   processing; machine learning; biofeedback; human-computer interaction;
   brain-gaming
ID SINGLE-TRIAL EEG; DEVICE
AB The investigation of innovative Human-Computer Interfaces (HCI) provides a challenge for future multimedia research and development. Brain-Computer Interfaces (BCI) exploit the ability of human communication and control bypassing the classical neuromuscular communication channels. In general, BCIs offer a possibility of communication for people with severe neuromuscular disorders, such as Amyotrophic Lateral Sclerosis (ALS) or spinal cord injury. Beyond medical applications, a BCI conjunction with exciting multimedia applications, e. g., a dexterity game, could define a new level of control possibilities also for healthy customers decoding information directly from the user's brain, as reflected in electroencephalographic (EEG) signals which are recorded non-invasively from user's scalp. This contribution introduces the Berlin Brain-Computer Interface (BBCI) and presents setups where the user is provided with intuitive control strategies in plausible gaming applications that use biofeedback. Yet at its beginning, BBCI thus adds a new dimension in multimedia research by offering the user an additional and independent communication channel based on brain activity only. First successful experiments already yielded inspiring proofs-of-concept. A diversity of multimedia application models, say computer games, and their specific intuitive control strategies, as well as various Virtual Reality (VR) scenarios are now open for BCI research aiming at a further speed up of user adaptation and increase of learning success and transfer bit rates.
C1 Fraunhofer Inst Comp Architecture & Software Tech, Res Grp Intelligent Data Anal, D-61462 Koenigstein I Ts, Germany.
   Free Univ Berlin, Klinikum Benjamin Franklin, Dept Neurol, Neurophys Grp, D-12203 Berlin, Germany.
   Univ Potsdam, Dept Comp Sci, D-14482 Potsdam, Germany.
C3 Fraunhofer Gesellschaft; Free University of Berlin; Humboldt University
   of Berlin; Charite Universitatsmedizin Berlin; University of Potsdam
RP Krepki, R (corresponding author), Fraunhofer Inst Comp Architecture & Software Tech, Res Grp Intelligent Data Anal, Bergweg 6, D-61462 Koenigstein I Ts, Germany.
EM roman_krepki@yahoo.de; blanker@first.fhg.de; curio@zedat.fu-berlin.de
RI Mueller, Klaus-Robert/C-3196-2013
OI Mueller, Klaus-Robert/0000-0002-3861-7685; Curio,
   Gabriel/0000-0002-3377-7735; Blankertz, Benjamin/0000-0002-2437-4846
CR [Anonymous], THESIS U TORONTO CAN
   Berger H, 1929, ARCH PSYCHIAT NERVEN, V87, P527, DOI 10.1007/BF01797193
   Birbaumer N, 1999, NATURE, V398, P297, DOI 10.1038/18581
   Birbaumer N., 1997, Brain and Behavior Past, Present, and Future, P25
   Blankertz B, 2002, ADV NEUR IN, V14, P157
   Blankertz B, 2003, IEEE T NEUR SYS REH, V11, P127, DOI 10.1109/TNSRE.2003.814456
   Cui RQ, 1999, NEUROIMAGE, V9, P124, DOI 10.1006/nimg.1998.0388
   DONCHIN E, 1970, ELECTROEN CLIN NEURO, V29, P201, DOI 10.1016/0013-4694(70)90124-0
   Ebrahimi T, 2003, IEEE SIGNAL PROC MAG, V20, P14, DOI 10.1109/MSP.2003.1166626
   Green JB, 1999, NEUROLOGY, V53, P736, DOI 10.1212/WNL.53.4.736
   HARDWICK A, 1996, PROGR GESTURAL INTER, P105
   Harel D, 2003, COMPUT BIOL CHEM, V27, P121, DOI 10.1016/S1476-9271(02)00092-0
   KREPKI R, 2004, THESIS TU BERLIN GER
   LANG W, 1989, EXP BRAIN RES, V74, P99
   MacIntyre B, 1996, MULTIMEDIA SYST, V4, P250, DOI 10.1007/s005300050027
   Mika S, 2001, ADV NEUR IN, V13, P591
   Müller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517
   Nicolelis MAL, 2002, SCI AM, V287, P46, DOI 10.1038/scientificamerican1002-46
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Pentland A., 1995, PROC 7 INT FORUM FRO, P757
   PFURTSCHELLER G, 1993, J MICROCOMPUT APPL, V16, P293, DOI 10.1006/jmca.1993.1030
   Pfurtscheller G., 1999, EEG event-related desynchronization (ERD) and event-related synchronization (ERS). Electroencephalography: basic principles, clinical applications, P958
   Sharbrough F., 1995, Journal of Clinical Neurophysiology, V8, P200, DOI DOI 10.1097/00004691-199104000-00007
   SUTTER EE, 1992, J MICROCOMPUT APPL, V15, P31, DOI 10.1016/0745-7138(92)90045-7
   Vapnik V., 1999, NATURE STAT LEARNING
   WOLPAW JR, 1991, ELECTROEN CLIN NEURO, V78, P252, DOI 10.1016/0013-4694(91)90040-B
   Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3
NR 27
TC 133
Z9 142
U1 2
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2007
VL 33
IS 1
BP 73
EP 90
DI 10.1007/s11042-006-0094-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 149FZ
UT WOS:000245133800006
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Wu, MY
   Shu, W
AF Zhang, Yun
   Wu, Min-You
   Shu, Wei
TI Adaptive channel allocation for large-scale streaming content delivery
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE pure-rate-control; multiple-service-class; modified-multi-service-class;
   adaptive algorithm
AB Scheduling algorithms are used in content delivery systems to control the resource allocation rate. They not only improve system efficiency, but also increase user satisfaction. Lower renege rate and less waiting time for users are the main goals for a scheduling algorithm. Among existing algorithms, On-Demand strategy does not perform well, while rate control channel allocation policies performs much better. Pure-Rate-Control (PRC) and Multiple-Service-Class (MSC) belong to the rate control algorithms. MSC performs well, but a drawback is that it uses the Hot Index, which is hard to decide and has significant effects on the performance. In order to solve this problem and to improve the overall system performance, two new algorithms, Modified MSC(MMSC) and Adaptive Algorithm (AA), are proposed in this paper. Both of them solved the problem of MSC very well and improved the overall performance. For example, the renege rate of AA is about 5.4% less than that of MMSC, and about 9.8% less than that of MSC.
C1 Univ New Mexico, Dept Elect & Comp Engn, Albuquerque, NM 87131 USA.
   Shanghai Jiao Tong Univ, Dept CSE, Shanghai 200030, Peoples R China.
C3 University of New Mexico; Shanghai Jiao Tong University
RP Zhang, Y (corresponding author), Univ New Mexico, Dept Elect & Comp Engn, Albuquerque, NM 87131 USA.
EM zhangyun@ece.unm.edu
RI Shu, Wei/A-9329-2009; Wu, MinYou/B-3780-2009
CR AGGARWAL C, 1996, INT C MULT COMP SYST
   Aggarwal CC, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P118, DOI 10.1109/MMCS.1996.534963
   ALMEROTH K, 2001, T CIRC SYST VID TECH
   Almeroth KC, 1996, IEEE J SEL AREA COMM, V14, P1110, DOI 10.1109/49.508282
   Almeroth KC, 1997, IEEE INFOCOM SER, P1333, DOI 10.1109/INFCOM.1997.631166
   [Anonymous], 1949, Human behaviour and the principle of least-effort
   BESTAVROS A, 1995, CHARACTERISTICS WWW
   Birk Y, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P226, DOI 10.1109/MMCS.1999.779198
   CAI Y, 1999, P SPIE ACM C MULT CO
   Dan A, 1996, MULTIMEDIA SYST, V4, P112, DOI 10.1007/s005300050016
   DAN A, 1996, SPIES C MULT COMP NE
   Dan A., 1994, ACM MULTIMEDIA
   DAN A, 1994, 19588 IBM RC
   EAGER DL, 1999, MULTIMEDIA COMPUTING
   Gao LX, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P117, DOI 10.1109/MMCS.1999.778179
   GLASSMAN S, 1994, P 1 INT C WORLD WID
   GOLUBCHIK L, 1995, MEASUREMENT MODELING
   HUA KA, 1997, SIGCOMM 97, P89
   HUA KA, 1998, 6 ACM INT MULT C ACM
   *IEEE, 1990, 8026 IEEE
   Little T. D. C., 1994, IEEE Multimedia, V1, P14, DOI 10.1109/MMUL.1994.318978
   MARCHOK DJ, 1991, IEEE INFOCOM SER, P850, DOI 10.1109/INFCOM.1991.147594
   SEN S, 1999, P 9 INT WORKSH NETW
   SHEU S, 1997, 5 DASFAA MELB AUSTR
   Viswanathan S, 1996, MULTIMEDIA SYST, V4, P197, DOI 10.1007/s005300050023
   ZHAO ZX, 1991, IEEE INFOCOM SER, P400, DOI 10.1109/INFCOM.1991.147530
NR 26
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2007
VL 32
IS 3
BP 253
EP 273
DI 10.1007/s11042-006-0051-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 137TK
UT WOS:000244314900002
DA 2024-07-18
ER

PT J
AU Babu, RV
   Ramakrishnan, KR
AF Babu, R. Venkatesh
   Ramakrishnan, K. R.
TI Compressed domain video retrieval using object and global motion
   descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE compressed domain; content-based video retrieval; motion descriptors;
   object trajectory; MPEG-7
AB Video content description has become an important task with the standardization effort of MPEG-7, which aims at easy and efficient access to visual information. In this paper we propose a system to extract object-based and global features from compressed MPEG video using the motion vector information for video retrieval. The reliability of the motion information is enhanced by a motion accumulation process. The global features like motion activity and camera motion parameters are extracted from the above enhanced motion information. The object features such as speed, area and trajectory are then obtained after the proposed object segmentation. The number of objects in a given video shot is determined by the proposed K-means clustering procedure. The object segmentation is done by applying EM algorithm.
C1 Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India.
C3 Indian Institute of Science (IISC) - Bangalore
RP Babu, RV (corresponding author), Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India.
EM venkatesh.babu@gmail.com
RI Radhakrishnan, Venkatesh Babu/D-5313-2009
OI Radhakrishnan, Venkatesh Babu/0000-0002-1926-1804
CR Ardizzone E, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P725, DOI 10.1109/MMCS.1999.778574
   Babu RV, 2002, PATTERN RECOGN LETT, V23, P1203, DOI 10.1016/S0167-8655(02)00067-3
   Chang SF, 1998, IEEE T CIRC SYST VID, V8, P602, DOI 10.1109/76.718507
   Courtney JD, 1997, PATTERN RECOGN, V30, P607, DOI 10.1016/S0031-3203(96)00107-0
   DAVIS JW, 1998, 487 MIT MED LAB
   DENG Y, 1998, SPIE, P202
   DIMITROVA N, 1995, ACM T INFORM SYST, V13, P408, DOI 10.1145/211430.211433
   FABLET R, 2000, VISUAL INFORMATION I, P96
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   *ISO IEC, 11172 ISO IEC
   Jeannin S, 2001, IEEE T CIRC SYST VID, V11, P720, DOI 10.1109/76.927428
   Jeannin S, 2000, SIGNAL PROCESS-IMAGE, V16, P59, DOI 10.1016/S0923-5965(00)00017-5
   Kobla V, 1997, P SOC PHOTO-OPT INS, V3022, P200, DOI 10.1117/12.263408
   Kobla V, 1996, P SOC PHOTO-OPT INS, V2916, P78, DOI 10.1117/12.257312
   Mandal MK, 1999, IMAGE VISION COMPUT, V17, P513, DOI 10.1016/S0262-8856(98)00143-7
   Nabil M, 2001, MULTIMED TOOLS APPL, V13, P35, DOI 10.1023/A:1009677223697
   SAHOURIA E, 1999, IEEE INT C IM PROC
   Sudhir G, 1996, J VIS COMMUN IMAGE R, V7, P354, DOI 10.1006/jvci.1996.0031
   Tan YP, 2000, IEEE T CIRC SYST VID, V10, P133, DOI 10.1109/76.825867
   TASKIAN C, 1998, IEEE C IM PROC, V3, P133
   Yoon K, 2000, INT C PATT RECOG, P819, DOI 10.1109/ICPR.2000.905531
   Zhong D, 1999, IEEE T CIRC SYST VID, V9, P1259, DOI 10.1109/76.809160
NR 22
TC 25
Z9 26
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2007
VL 32
IS 1
BP 93
EP 113
DI 10.1007/s11042-006-0048-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 119YC
UT WOS:000243049400005
DA 2024-07-18
ER

PT J
AU Kijak, E
   Gravier, G
   Oisel, L
   Gros, P
AF Kijak, Ewa
   Gravier, Guillaume
   Oisel, Lionel
   Gros, Patrick
TI Audiovisual integration for tennis broadcast structuring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video structure analysis; macro-segmentation; cross-modality; hidden
   Markov models
AB This paper focuses on the integration of multimodal features for sport video structure analysis. The method relies on a statistical model which takes into account both the shot content and the interleaving of shots. This stochastic modelling is performed in the global framework of Hidden Markov Models (HMMs) that can be efficiently applied to merge audio and visual cues. Our approach is validated in the particular domain of tennis videos. The model integrates prior information about tennis content and editing rules. The basic temporal unit is the video shot. Visual features are used to characterize the type of shot view. Audio features describe the audio events within a video shot. Two sets of audio features are used in this study: the first one is extracted from a manual segmentation of the soundtrack and is more reliable. The second one is provided by an automatic segmentation and classification process. As a result of the overall HMM process, typical tennis scenes are simultaneously segmented and identified. The experiments illustrate the improvement of HMM-based fusion over indexing using only the best single media, when both media are of similar quality.
C1 Univ Rennes 1, F-35042 Rennes, France.
   CNRS, F-35042 Rennes, France.
   Thomson Multimedia R&D, F-35510 Cesson Sevigne, France.
   IRISA, F-35042 Rennes, France.
C3 Universite de Rennes; Centre National de la Recherche Scientifique
   (CNRS); Universite de Rennes; Technicolor SA; Universite de Rennes
RP Kijak, E (corresponding author), Univ Rennes 1, Campus Univ Beaulieu, F-35042 Rennes, France.
EM ewa.kijak@lip6.fr
CR Alatan AA, 2001, MULTIMED TOOLS APPL, V14, P137, DOI 10.1023/A:1011395131992
   [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], 2001, International Journal of Image and Graphics (IJIG), Vol, DOI DOI 10.1142/S021946780100027X
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   BETSER M, 2003, 3 INT WORKSH CONT BA, P71
   CHANG P, 2002, P IEEE INT C IM PROC
   DAYHOT R, 2003, IEEE INT C AC SPEECH
   Duan LY, 2003, PROC SPIE, V5021, P300, DOI 10.1117/12.476259
   HUA W, 2002, IEEE INT C MULT EXP
   HUANG J, 1999, P INT WORKSH MULT SI, P53
   JIANG H, 2000, IEEE INT C MULT EXP, V3, P1551
   Kawashima T, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P871, DOI 10.1109/ICIP.1998.723657
   Kim K, 2002, LECT NOTES COMPUT SC, V2383, P278
   LIU Z, 1999, P IEEE INT C IM PROC, V1, P324
   Rousseeuw P.J., 1987, ROBUST REGRESSION OU
   SNOEK CGM, 2003, IN PRESS MULTIMED TO
   SUDHIR G, 1998, P IEEE WORKSH CONT B
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P12, DOI 10.1109/79.888862
   XU M, 2003, IEEE INT C AC SPEECH
   XU P, 2001, IEEE C MULT EXP, P928
   ZHONG D, 2001, IEEE INT C MULT EXP
   Zhou W., 2000, ACM Workshops on Multimedia, P213
NR 22
TC 22
Z9 38
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2006
VL 30
IS 3
BP 289
EP 311
DI 10.1007/s11042-006-0031-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 089WS
UT WOS:000240913200005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hemy, M
   Steenkiste, P
   Gross, T
AF Hemy, Michael
   Steenkiste, Peter
   Gross, Thomas
TI Adaptive filtering of MPEG system streams in IP networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MPEG System streams; adaptive filtering; system architecture;
   performance evaluation; TCP friendly
AB Congestion and large differences in available link bandwidth create challenges for the design of applications that want to deliver high quality video over the Internet. We present an efficient adaptive filter for MPEG System streams that can be placed in the network (e.g., as an active service). This filter adjusts the bandwidth demands of an MPEG System stream to the available bandwidth without transcoding while maintaining synchronization between the streams embedded in the MPEG System. The filter is network-friendly: it is fair with respect to other (TCP) competing streams and it avoids generating bursty traffic. This paper presents the system architecture and an evaluation of our implementation in three different operating environments: a networking testbed in a laboratory environment, a home-user scenario (DSL line with 640 Kbit/s), and a wide area network covering the Atlantic (server in Europe, client in the US). Moreover we examine the network-friendliness of the adaptation protocol and the relationship between the quality of the received continuous media and the protocol's aggressiveness. Our architecture is based on efficient MPEG System filtering to achieve high-quality video over best-effort networks.
C1 Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA.
C3 Carnegie Mellon University
RP Gross, T (corresponding author), Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA.
EM Thomas.gross@ethz.ch
OI Steenkiste, Peter/0000-0001-7079-8212
CR ALLAN M, 1999, 2581 RFC
   AMIR E, 1998, P ACM SIGCOMM SEPT, P178
   Bansal D, 2001, IEEE INFOCOM SER, P631, DOI 10.1109/INFCOM.2001.916251
   BHATTACHARJEE S, 1996, GITCC9602
   Boyce J. M., 1998, Proceedings ACM Multimedia 98, P181, DOI 10.1145/290747.290770
   CEN S, 1995, P NOSSDAV 95 DURH NE, P18
   CEN S, 1998, P MULT COMP NETW 199, P3310
   CHANDRA P, 1998, 6 INT C NETW PROT IE
   Chang G C, 1997, IEEE Trans Rehabil Eng, V5, P2, DOI 10.1109/86.559344
   CHEN Z, 1995, P 4 INT WORLD WID WE
   CHIU DM, 1989, COMPUT NETWORKS ISDN, V17, P1, DOI 10.1016/0169-7552(89)90019-6
   CHRISTE Y, 1995, CAH CIVILIS MEDIEVAL, V38, P4
   KARRER R, 2002, CLUSTER COMPUT, P365
   KOZEN D, 1998, DAT COMPR C
   LI X, 1997, P NOSSDAV 97 ST LOUI
   Mathis M., 1997, Computer Communication Review, V27, P67, DOI 10.1145/263932.264023
   MayerPatel K, 1997, P SOC PHOTO-OPT INS, V3020, P194, DOI 10.1117/12.264292
   NONNENMACHER J, 1997, P ACM SIGCOMM 97 CAN, P298
   PADHYE J, 1998, ACM SIGCOMM 98 ACM
   RAMKISHOR K, 2002, 6 DIG IM COMP TECHN
   SCHULZRINNE H, 1996, 1889 RFC
   STOICA I, 1997, P SIGCOMM 97 CANN AC
   TAN K, 2001, ACM MULTIMEDIA
   TRIPATHI A, 2002, P 2 INT WORKSH INT M
   Yeadon N, 1996, IEEE J SEL AREA COMM, V14, P1245, DOI 10.1109/49.536366
   Zheng B, 2001, 2001 IEEE WORKSHOP ON HIGH PERFORMANCE SWITCHING AND ROUTING, P43, DOI 10.1109/HPSR.2001.923601
   [No title captured]
NR 27
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2006
VL 30
IS 1
BP 1
EP 26
DI 10.1007/s11042-006-0004-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 082CF
UT WOS:000240363400001
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Szeto, WM
   Wong, MH
AF Szeto, Wai Man
   Wong, Man Hon
TI Stream segregation algorithm for pattern matching in polyphonic music
   databases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia databases; music information retrieval; clustering algorithms
ID RETRIEVAL
AB As music can be represented symbolically, most of the existing methods extend some string matching algorithms to retrieve musical patterns in a music database. However, not all retrieved patterns are perceptually significant because some of them are, in fact, inaudible. Music is perceived in groupings of musical notes called streams. The process of grouping musical notes into streams is called stream segregation. Stream-crossing musical patterns are perceptually insignificant and should be pruned from the retrieval results. This can be done if all musical notes in a music database are segregated into streams and musical patterns are retrieved from the streams. Findings in auditory psychology are utilized in this paper, in which stream segregation is modelled as a clustering process and an adapted single-link clustering algorithm is proposed. Supported by experiments on real music data, streams are identified by the proposed algorithm with considerable accuracy.
C1 Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong
RP Szeto, WM (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.
EM wmszeto@cse.cuhk.edu.hk; mwhong@cse.cuhk.edu.hk
RI Wong, Man Hon/GOH-0560-2022
CR [Anonymous], 1987, Speech communication: Human and machine
   [Anonymous], P AISB 99 S MUS CREA
   [Anonymous], 1975, Temporal coherence in the perception of tone sequences
   Bach JohannSebastian., 1991, INVENTIONS SINFONIAS
   Bergman A., 1990, Auditory Scene Analysis
   Butler D., 1992, MUSICIANS GUIDE PERC
   Byrd D, 2002, INFORM PROCESS MANAG, V38, P249, DOI 10.1016/S0306-4573(01)00033-4
   Crawford Tim., 1998, COMPUTING MUSICOLOGY, V11, P73
   Deutsch D, 1999, PSYCHOL MUSIC
   GJERDINGEN RO, 1994, MUSIC PERCEPT, V11, P335
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Lemstrom K., 2000, THESIS U HELSINKI FI
   LEMSTROM K, 2000, 1 INT S MUS INF RETR, P23
   LEMSTROM K, 2000, P CONT BAS MULT INF, V2, P1261
   Lerdahl Fred., 1983, A Generative Theory of Tonal Music
   MARSDEN A., 1992, COMPUTER REPRESENTAT, P239
   *MATHWORKS, 2002, STAT TOOLB VERS 4
   McCabe SL, 1997, J ACOUST SOC AM, V101, P1611, DOI 10.1121/1.418176
   McNab RJ, 2000, MULTIMED TOOLS APPL, V10, P113, DOI 10.1023/A:1009606600500
   MELUCCI M, 1999, P 4 ACM C DIG LIB, P152
   MEREDITH D, 2001, COMP SCI C DEP COMP
   *MUT PROJ, 2001, MUS LIST JS BACHS IN
   Pickens J., 2001, SURVEY FEATURE SELEC
   SCHACHTER C, 1994, CHOPIN STUDIES, V2, P140
   Temperley David., 2001, COGNITION BASIC MUSI
   Theodoridis S., 1999, Pattern recognition, P3
   Uitdenbogerd A, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P57, DOI 10.1145/319463.319470
NR 27
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2006
VL 30
IS 1
BP 109
EP 127
DI 10.1007/s11042-006-0011-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 082CF
UT WOS:000240363400005
DA 2024-07-18
ER

PT J
AU Korhonen, J
   Huang, YC
   Wang, Y
AF Korhonen, Jari
   Huang, Yicheng
   Wang, Ye
TI Generic forward error correction of short frames for IP streaming
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE forward error correction (FEC); interleaving; multimedia streaming;
   real-time transport protocol (RTP)
ID LOSS RECOVERY
AB If the frame size of a multimedia encoder is small, Internet Protocol (IP) streaming applications need to pack many encoded media frames in each Real-time Transport Protocol (RTP) packet to avoid unnecessary header overhead. The generic forward error correction (FEC) mechanisms proposed in the literature for RTP transmission do not perform optimally in terms of stability when the RTP payload consists of several individual data elements of equal priority. In this paper, we present a novel approach for generating FEC packets optimized for applications packing multiple individually decodable media frames in each RTP payload. In the proposed method, a set of frames and its corresponding FEC data are spread among multiple packets so that the experienced frame loss rate does not vary greatly under different packet loss patterns. We verify the performance improvement gained against traditional generic FEC by analyzing and comparing the variance of the residual frame loss rate in the proposed packetization scheme and in the baseline generic FEC.
C1 Natl Univ Singapore, Sch Comp, Dept Comp Sci, Singapore 117543, Singapore.
C3 National University of Singapore
RP Wang, Y (corresponding author), Natl Univ Singapore, Sch Comp, Dept Comp Sci, 3 Sci Dr 2, Singapore 117543, Singapore.
EM jari.ta.korhonen@nokia.com; huangyic@comp.nus.edu.sg;
   wangye@comp.nus.edu.sg
RI Korhonen, Jari/AAA-7906-2022; Korhonen, Jari/I-3033-2016; Wang,
   Ye/KGL-6405-2024; Huang, Yicheng/AFV-4905-2022
OI Korhonen, Jari/0000-0003-4354-5310; Korhonen, Jari/0000-0003-4354-5310;
   Wang, Ye/0000-0002-0123-1260; Huang, Yicheng/0000-0002-0293-6844
CR Bormann C., 2001, IETF RFC 3095
   Chan KI, 1999, IEEE T VEH TECHNOL, V48, P1002, DOI 10.1109/25.765034
   Claypool M, 2003, 23RD INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, P508
   Garey M.R., 1979, COMPUTERS INTRACTABI
   Korhonen J, 2002, INT CONF ACOUST SPEE, P2053
   Li VOK, 2002, P IEEE, V90, P360, DOI 10.1109/5.993404
   Loguinov D, 2001, IMW 2001: PROCEEDINGS OF THE FIRST ACM SIGCOMM INTERNET MEASUREMENT WORKSHOP, P281
   Markopoulou AP, 2003, IEEE ACM T NETWORK, V11, P747, DOI 10.1109/TNET.2003.818179
   NONNENMACHER J, 1998, IEEE ACM T NETWORK, V6, P289
   Perkins C., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), P111, DOI 10.1109/INFCOM.2000.832179
   Perkins C, 1998, IEEE NETWORK, V12, P40, DOI 10.1109/65.730750
   REY J, 2004, RTP RETRANSMISSION P
   ROSENBERG J, 1999, 2733 IETF RFC
   SCHULTZRINNE H, 2003, 3550 IETF RFC
   STOCKHAMMER T, 2003, P IEEE INT C IM PROC, V3, P481
   WAH BW, 2001, P IEEE INT S MULT SO, P17
   Wang Y, 2004, LECT NOTES COMPUT SC, V3182, P144
   ZHAI F, 2003, P ALL C COMM CONTR C
   Zhu QF, 1993, IEEE T CIRC SYST VID, V3, P248, DOI 10.1109/76.224235
   Zlatokrilov H, 2004, IEEE INFOCOM SER, P1170
NR 20
TC 5
Z9 6
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2006
VL 29
IS 3
BP 305
EP 323
DI 10.1007/s11042-006-0016-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 070XJ
UT WOS:000239559600006
DA 2024-07-18
ER

PT J
AU Safar, M
   Shahabi, C
AF Safar, Maytham
   Shahabi, Cyrus
TI NIBC-based shape retrieval: basics, optimizations, and open problems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia systems; multimedia digital libraries; image content; image
   indexing; shape representation; shape similarity
AB Shape of an object is an important feature for image and multimedia similarity retrievals. In our previous studies we introduced a new boundary-based technique (MBC-based) for shape retrieval and compared its performance to other techniques. In this study, we describe in detail the basics of our MBC-based shape representation techniques, and we show how they support different query types. In addition, we describe two original optimization techniques that can further improve the performance of our MBC-based methods in several aspects, and show that they are also applicable to other applications (e.g., pattern recognition techniques). Finally, we define open problems in the area (e.g., partial similarity) and provide some hints on how to approach those problems.
C1 Kuwait Univ, Dept Comp Engn, Safat, Kuwait.
   Univ So Calif, Dept Comp Sci, Integrated Media Syst Ctr, Los Angeles, CA 90089 USA.
C3 Kuwait University; University of Southern California
RP Safar, M (corresponding author), Kuwait Univ, Dept Comp Engn, Safat, Kuwait.
EM maytham@eng.kuniv.edu.kw; shahabi@usc.edu
RI Safar, Maytham H/E-9238-2010; Shahabi, Cyrus/C-5199-2014
OI Shahabi, Cyrus/0000-0001-9118-0681
CR Agrawal R., 1993, EFFICIENT SIMILARITY
   BEBIS GN, 1992, PATTERN RECOGN, V25, P25, DOI 10.1016/0031-3203(92)90004-3
   CHUNG C, 2000, IN PRESS P 16 INT C
   Faloutsos C., 1994, SIGMOD
   GARY J, 1995, IEEE COMPUTER    SEP
   Gonzalez R.C., 1987, DIGITAL IMAGE PROCES, VSecond
   Korn F, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P215
   LU G, 1992, MULTIMEDIA SYST J, V7, P165
   MEGIDDO N, 1984, SIAM J COMPUT, V12, P108
   MEHROTRA R, 1995, 2 AS C COMP VIS 5 8, P529
   Mokhtarian F., 1996, Proceedings of International Workshop on Image Databases and Multimedia Search, P35
   OOSTEROM PV, 1990, 4 INT S SPAT DAT HAN, P1016
   Oppenheim A. V., 1975, Digital signal processing
   PAPADIAS D, 1995, P ACM SIGMOD INT C M
   Pitas I., 1993, DIGITAL IMAGE PROCES
   SAFAR M, 2001, J APPL SYST STUD SPE
   SAFAR M, 2000, P IEEE INT C MULT EX
   Sajjanhar A., 1998, International Conference on Computational Intelligence and Multimedia Applications 1998. ICCIMA 1998, P854
   Sajjanhar A, 1997, AUST COMPUT J, V29, P131
   SAJJANHAR A, 1987, P 2 AUSTR DOC COMP S, P46
   Shahabi C, 1999, PROC INT CONF DATA, P259, DOI 10.1109/ICDE.1999.754939
   Shahabi C, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P611, DOI 10.1109/MMCS.1999.779270
   SHAHABI C, 1999, USCTR99694 U SO CAL
   TAO Y, 1999, P 7 SPIE S STOR RETR, P631
   TAO Y, 1999, P INT C DAT SEM DS 8, P59
   WELZL E, 1991, LECT NOTES COMPUT SC, V555, P359, DOI 10.1007/bfb0038202
NR 26
TC 2
Z9 2
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2006
VL 29
IS 2
BP 191
EP 208
DI 10.1007/s11042-006-0010-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 071KE
UT WOS:000239600300006
DA 2024-07-18
ER

PT J
AU Curcio, IDD
   Kalliokulju, J
   Lundan, M
AF Curcio, Igor D. D.
   Kalliokulju, Juha
   Lundan, Miikka
TI AMR mode selection enhancement in 3G networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3GPP; AMR; mode selection; voice over IP; VoIP; RTP
AB This paper describes methods for mode selection in multirate speech codecs, such as the AMR (Adaptive Multi-Rate), that is the mandatory speech codec selected in 3GPP (3rd Generation Partnership Project) defined mobile networks. Originally, the multirate functionality has been developed for coping with changing radio conditions. The algorithms described in this paper find applicability in IP-based mobile networks, where speech encoded data is encapsulated using the RTP (Real Time Protocol). The main advantages offered by these techniques are improved speech quality and congestion control along the network path between two mobile terminals.
C1 Nokia Electr Ltd, Tampere 33721, Finland.
C3 Nokia Corporation; Nokia Finland
RP Curcio, IDD (corresponding author), Nokia Electr Ltd, POB 88, Tampere 33721, Finland.
EM igor.curcio@nokia.com; juha.kalliokulju@nokia.com;
   miikka.lundan@nokia.com
CR Anjum FM, 1999, IEEE INFOCOM SER, P1412, DOI 10.1109/INFCOM.1999.752161
   Athuraliya S, 2001, IEEE NETWORK, V15, P48, DOI 10.1109/65.923940
   Atungsiri SA, 1997, IEE P-COMMUN, V144, P211, DOI 10.1049/ip-com:19971242
   Barberis A, 2001, COMPUT COMMUN, V24, P757, DOI 10.1016/S0140-3664(00)00349-2
   Benmohamed LN, 1998, BELL LABS TECH J, V3, P273, DOI 10.1002/bltj.2141
   Bolot JC, 1999, IEEE INFOCOM SER, P1453, DOI 10.1109/INFCOM.1999.752166
   BRUH S, 1999, P VEH TECHN C VTC HO, V3, P2451
   Christianson L., 1999, 1999 IEEE International Workshop on Mobile Multimedia Communications (MoMuC'99) (Cat. No.99EX384), P363, DOI 10.1109/MOMUC.1999.819512
   *CISC, 2001, CISC IOS QUAL SERV S
   De Cnodder S, 2000, IEEE SYMP COMP COMMU, P793, DOI 10.1109/ISCC.2000.860741
   *ETSI TR, 101505 ETSI TR
   Floyd S., 1997, ROUTER MECH SUPPORT
   FLOYD S, 2000, COMMUNICATION    OCT
   Floyd S., 2001, Adaptive RED: An algorithm for increasing the robustness of RED's active queue management
   FLOYD S, 1997, RED DISCUSSION BYTE
   FLOYD S, 1998, COMMUNICATION    JAN
   Floyd S, 1993, IEEE ACM T NETWORK, V1, P397, DOI 10.1109/90.251892
   Galiotos P, 2002, HSNMC 2002: 5TH IEEE INTERNATIONAL CONFERENCE ON HIGH SPEED NETWORKS AND MULTIMEDIA COMMUNICATIONS, P305, DOI 10.1109/HSNMC.2002.1032597
   Giner VC, 2001, TELECOMMUN SYST, V17, P31, DOI 10.1023/A:1016699902484
   *IETF RFC, 2002, 3267 IETF
   *IETF RFC, 2003, 3550
   *IETF RFC, 1998, 2309 IETF RFC
   Jain R., 1990, IEEE Network, V4, P24, DOI 10.1109/65.56532
   Lakaniemi A, 2002, 2002 IEEE SPEECH CODING WORKSHOP PROCEEDINGS, P147, DOI 10.1109/SCW.2002.1215753
   MAHAJAN R, 2001, TR01001 ICSI
   Matta J., 2003, Proceedings of the 13th international workshop on Network and operating systems support for digital audio and video, P92
   NANANUKUL S, 2000, IEEE C HIGH PERF SWI, P49
   NOMURA T, 1999, IEEE WORKSH SPEECH C, P132
   Parekh AK, 1993, IEEE ACM T NETWORK, V1, P344, DOI 10.1109/90.234856
   SEO JW, 2001, P IEEE INT C AC SPEE, V3, P1373
NR 30
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2006
VL 28
IS 3
BP 259
EP 281
DI 10.1007/s11042-006-7714-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 044FO
UT WOS:000237658000001
DA 2024-07-18
ER

PT J
AU Song, MS
   Shin, H
AF Song, Minseok
   Shin, Heonshik
TI Replication and retrieval strategies for resource-effective admission
   control in multi-resolution video servers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multi-resolution video severs; replication; striping unit size;
   admission control
ID MULTIMEDIA; STORAGE; DESIGN
AB Video-on-demand (VOD) service requires balanced use of system resources, such as disk bandwidth and buffer, to accommodate more clients. The data retrieval size and data rates of video streams directly affect the utilization of these resources. Given the data rates which vary widely in multi-resolution video servers, we need to determine the appropriate data retrieval size to balance the buffer with the disk bandwidth. Otherwise, the server may be unable to admit new clients even though one of the resources is available for use. To address this problem, we propose the following new schemes that work together: (1) A replication scheme called Splitting Striping units by Replication (SSR). To increase the number of admitted clients, SSR defines two sizes of striping unit, which allow data to be stored on the primary and backup copies in different ways. (2) A retrieval scheduling method which combines the merits of existing SCAN and grouped sweeping scheme (GSS) algorithms to balance the buffer and disk bandwidth usage. (3) Admission control algorithms which decide whether to read data from the primary or the backup copy. The effectiveness of the proposed schemes is demonstrated through simulations. Results show that our schemes are able to cope with various workloads efficiently and thus enable the server to admit a much larger number of clients.
C1 Inha Univ, Sch Engn & Comp Sci, Inchon 402751, South Korea.
   Seoul Natl Univ, Sch Engn & Comp Sci, Seoul 151742, South Korea.
C3 Inha University; Seoul National University (SNU)
RP Song, MS (corresponding author), Inha Univ, Sch Engn & Comp Sci, Inchon 402751, South Korea.
EM mssong@inha.ac.kr; shinhs@snu.ac.kr
RI Song, Minseok/U-9378-2019
OI Song, Minseok/0000-0002-6813-8853
CR [Anonymous], P 11 INT WORKSH NETW
   BARNETT SA, 1998, ACM MULTIMEDIA SYSTE, V6, P60
   Chang E, 1997, IEEE T CIRC SYST VID, V7, P758, DOI 10.1109/76.633494
   CHANG E, 1994, P SOC PHOTO-OPT INS, V2185, P208, DOI 10.1117/12.171778
   Chang E., 1996, THESIS U CALIFORNIA
   Chen HJ, 1996, IEEE T KNOWL DATA EN, V8, P855, DOI 10.1109/69.542035
   Cho J, 2003, MULTIMED TOOLS APPL, V20, P237, DOI 10.1023/A:1024072205156
   Dan A, 1997, MULTIMED TOOLS APPL, V4, P279, DOI 10.1023/A:1009637022889
   Golubchik L, 2001, IEEE T PARALL DISTR, V12, P363, DOI 10.1109/71.920587
   GOLUBCHIK L, 1994, DATA ENG B, V17, P14
   Huang YM, 1999, VLDB J, V8, P44, DOI 10.1007/s007780050073
   HUNTER J, 1997, REV VIDEO STREAMING
   *ISO IEC, 1998, JTC1SC29WG11 ISOIEC
   Kangasharju J, 2002, IEEE T COMPUT, V51, P622, DOI 10.1109/TC.2002.1009148
   KEETON K, 1993, P INT WORKSH NETW OP, P237
   Law KKW, 1999, VLDB J, V8, P133, DOI 10.1007/s007780050078
   Lee KO, 1998, INFORM PROCESS LETT, V68, P235, DOI 10.1016/S0020-0190(98)00168-9
   Liu J.S., 1992, PROC 1 INT WORKSHOP, P88
   Miao ZR, 2000, CONF REC ASILOMAR C, P1357, DOI 10.1109/ACSSC.2000.911213
   Ozden B, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P580, DOI 10.1109/MMCS.1996.535026
   Paek S., 1995, Proceedings of the 5th International Workshop on Network and Operating System Support for Digital Audio and Video, P363
   Rejaie R, 2000, IEEE J SEL AREA COMM, V18, P2530, DOI 10.1109/49.898735
   SAPARILLA D, 2002, P IEEE INFOCOM, P737
   SHENOY P, 1999, ACM SPRINGER MULTIME, V7, P241
   Shenoy PJ, 2000, MULTIMEDIA SYST, V8, P1, DOI 10.1007/s005300050001
   SHI W, 1997, ACM SIGMETRICS PERFO, V25, P13
   TAUBMAN D, 1994, IEEE T IMAGE PROCESS, V3, P572, DOI 10.1109/83.334984
   Won Y, 2000, MULTIMEDIA SYST, V8, P105, DOI 10.1007/s005300050154
   YU PS, 1993, MULTIMEDIA SYSTEMS, V1, P99
NR 29
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2006
VL 28
IS 3
BP 347
EP 372
DI 10.1007/s11042-006-7718-5
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 044FO
UT WOS:000237658000005
DA 2024-07-18
ER

PT J
AU Srinivasan, U
   Pfeiffer, S
   Nepal, S
   Lee, M
   Gu, LF
   Barrass, S
AF Srinivasan, U
   Pfeiffer, S
   Nepal, S
   Lee, M
   Gu, LF
   Barrass, S
TI A survey of MPEG-1 audio, video and semantic analysis techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MPEG-1; content analysis; audio analysis; video analysis; semantic
   analysis; feature extraction; scene change detection; audio-visual
   segmentation; sports highlights
ID SCENE-CHANGE DETECTION; RETRIEVAL; IMAGE
AB Digital audio & video data have become an integral part of multimedia information systems. To reduce storage and bandwidth requirements, they are commonly stored in a compressed format, such as MPEG-1. Increasing amounts of MPEG encoded audio and video documents are available online and in proprietary collections. In order to effectively utilise them, we need tools and techniques to automatically analyse, segment, and classify MPEG video content. Several techniques have been developed both in the audio and visual domain to analyse videos. This paper presents a survey of audio and visual analysis techniques on MPEG-1 encoded media that are useful in supporting a variety of video applications. Although audio and visual feature analyses have been carried out extensively, they become useful to applications only when they convey a semantic meaning of the video content. Therefore, we also present a survey of works that provide semantic analysis on MPEG-1 encoded videos.
C1 CSIRO Math & Informat Sci, PHI Syst, Sydney, NSW, Australia.
   CSIRO Math & Informat Sci, CSIRO ICT Ctr, Sydney, NSW, Australia.
   Univ Canberra, CSIRO Math & Informat Sci, Belconnen, ACT 2616, Australia.
C3 Commonwealth Scientific & Industrial Research Organisation (CSIRO);
   Commonwealth Scientific & Industrial Research Organisation (CSIRO);
   Information & Communication Technologies Centre; Commonwealth Scientific
   & Industrial Research Organisation (CSIRO); University of Canberra
RP CSIRO Math & Informat Sci, PHI Syst, Sydney, NSW, Australia.
RI Nepal, Surya/JBJ-1840-2023; Nepal, Surya/B-7523-2011; Barrass,
   Stephen/F-7553-2011
OI Nepal, Surya/0000-0002-3289-6599; Barrass, Stephen/0000-0002-1472-0522
CR Adams B., 2000, Proceedings ACM Multimedia 2000, P353, DOI 10.1145/354384.354530
   Ahanger G, 1996, J VIS COMMUN IMAGE R, V7, P28, DOI 10.1006/jvci.1996.0004
   [Anonymous], 1999, Auditory Scene Analysis: The Perceptual Organization of Sound, DOI DOI 10.7551/MITPRESS/1486.001.0001
   [Anonymous], P ACM INT C MULT
   Ardizzone E, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P725, DOI 10.1109/MMCS.1999.778574
   Arman F., 1993, Proceedings ACM Multimedia 93, P267, DOI 10.1145/166266.166297
   BARRASS S, 1997, 0198 CSIRO MATH INF
   Boccignone G, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P225
   Bordwell D., 1997, FILM ART INTRO
   BRUNELLI R, 961206 IRST
   Chang SF, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pA314
   CHANG SF, 1995, S MULT COMM VID COD
   CHEN Y, 2001, P SOC PHOTO-OPT INS, P4315
   DELBIMBO A, 1995, IEEE T KNOWL DATA EN, V7, P609, DOI 10.1109/69.404033
   DIMITROVA N, 1999, J INFORMING SCI 1, V2
   DISANTO M, 2001, P LECT NOT COMP SCI, V2184, P192
   FENG J, 1996, P IEEE INT C IM PROC, V2, P821
   Foote J, 1999, MULTIMEDIA SYST, V7, P2, DOI 10.1007/s005300050106
   Gamaz N, 1998, CAN J ELECT COMPUT E, V23, P95, DOI 10.1109/CJECE.1998.7102050
   Girgensohn A, 1999, INT CONF ACOUST SPEE, P3045, DOI 10.1109/ICASSP.1999.757483
   GREY JM, 1977, J ACOUST SOC AM, V61, P1270, DOI 10.1121/1.381428
   GU L, 2001, P INT WORKSH CONT BA
   GU L, 1998, P IASTED INT C SIGN
   GU L, 1999, P INT C IM AN PROC V
   Gu LF, 1997, 1997 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT PROCESSING SYSTEMS, VOLS 1 & 2, P1692, DOI 10.1109/ICIPS.1997.669337
   HAMMOUD R, 1998, P 1 INT FOR MULT IM
   HANJALIC A, 1999, LNCS, V1614, P229
   HASKELL BG, 1997, DIGITAL VIDEO INTRO, pCH4
   IDE I, 2000, COMMUN ACM, V43, P42
   Idris F, 1997, J VIS COMMUN IMAGE R, V8, P146, DOI 10.1006/jvci.1997.0355
   *ISO IEC, 1993, 111722 ISOIEC 2
   *ISO IEC, 1993, 111723 ISOIEC 3
   Jiang H, 1998, MULTIMEDIA SYST, V6, P186, DOI 10.1007/s005300050087
   Kang EK, 1999, IEEE T CONSUM ELECTR, V45, P932, DOI 10.1109/30.793648
   Kobla V, 2000, PROC SPIE, V3972, P332
   KOBLA V, 1996, CSTR3688 U MAR CTR A
   Koprinska I, 2001, SIGNAL PROCESS-IMAGE, V16, P477, DOI 10.1016/S0923-5965(00)00011-4
   LEE MH, 1994, IEE P-VIS IMAGE SIGN, V141, P453, DOI 10.1049/ip-vis:19941554
   LEE MH, 1994, IEE P-VIS IMAGE SIGN, V141, P39, DOI 10.1049/ip-vis:19949722
   LEE MH, 2001, 200128 CSIRO MATH IN
   LIU HCH, 1995, P SOC PHOTO-OPT INS, V2419, P26, DOI 10.1117/12.206370
   Lu GJ, 2001, MULTIMED TOOLS APPL, V15, P269, DOI 10.1023/A:1012491016871
   Mandal MK, 1999, IMAGE VISION COMPUT, V17, P513, DOI 10.1016/S0262-8856(98)00143-7
   Meng HJ, 1999, MULTIMEDIA SYST, V7, P282, DOI 10.1007/s005300050130
   MENG J, 1995, SPIE, V2419, P14
   MENG J, 1996, P ACM MULT, P43
   Meng JH, 1996, P SOC PHOTO-OPT INS, V2670, P180, DOI 10.1117/12.234795
   MORGUET P, 1997, P INT C IM PROC ICIP
   NAKAJIMA Y, 1999, P IEEE INT C AC SPEE, V4, P3005
   Naphade MR, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P536, DOI 10.1109/ICIP.1998.999041
   NEPAL S, 2002, 6 IFIP WORK C VIS DA, P29
   Nepal S., 2001, ACM Multimedia, P261
   NEPAL S, 2001, IEEE INT C MULT EXP, P301
   Noll P, 1997, IEEE SIGNAL PROC MAG, V14, P59, DOI 10.1109/79.618009
   OCONNOR N, 2001, P SSIP
   PAN D, 1995, IEEE MULTIMEDIA, V2, P60, DOI 10.1109/93.388209
   Patel NV, 1996, P SOC PHOTO-OPT INS, V2670, P373, DOI 10.1117/12.234776
   PFEIFFER S, 2001, 19601 CSIRO MATH INF
   PFEIFFER S, 1999, P 5 JOINT C INF SCI, V2, P513
   Rui Y., 2000, Proceedings ACM Multimedia 2000, P105, DOI 10.1145/354384.354443
   Saur DD, 1997, P SOC PHOTO-OPT INS, V3022, P176, DOI 10.1117/12.263406
   SENCAR T, 1999, P 1 EUR WORKSH CONT, P11
   Shen B, 1996, P SOC PHOTO-OPT INS, V2670, P404, DOI 10.1117/12.234779
   Shen B, 1996, J VIS COMMUN IMAGE R, V7, P411, DOI 10.1006/jvci.1996.0035
   Shen K, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pB252
   Srinivasan U, 1997, AUST COMPUT J, V29, P141
   SRINIVASAN U, P ISIMP 2001 HOG KON, P291
   SUDHIR G, 1997, HKUSTCS972 HONG KONG
   SUDIR G, 1998, INT WORKSH CONT BAS, P81
   Tzanetakis G, 2000, INT CONF ACOUST SPEE, P761
   VENUGOPAL S, 1999, IEEE 3 WORKSH MULT S, P191
   Viswanathan M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P493, DOI 10.1109/ICME.2000.869646
   Wang HL, 1997, IEEE T CIRC SYST VID, V7, P615, DOI 10.1109/76.611173
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P12, DOI 10.1109/79.888862
   WANG Y, 2001, P 9 ACM INT C MULT M, P194
   WEI G, 2000, P IEEE INT C MULT EX
   YANG J, 1997, CMUCS97146 SCH COMP
   Yapp L, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P624, DOI 10.1109/MMCS.1997.609787
   Yeo B.- L., 1996, THESIS PRINCETON U
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
   Yeo BL, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pB260
   Yoshitaka A, 1998, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS, P208, DOI 10.1109/MMCS.1998.693642
   Yoshitaka A, 1999, IEEE T KNOWL DATA EN, V11, P81, DOI 10.1109/69.755617
   ZHANG FJ, 1989, ACTA MATH APPL SIN-E, V1, P1
   ZHONG D, 2001, ICME 2001 TOK JAP
   Zhou W., 2000, ACM Workshops on Multimedia, P213
NR 86
TC 11
Z9 13
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2005
VL 27
IS 1
BP 105
EP 141
DI 10.1007/s11042-005-2716-6
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 955JI
UT WOS:000231221800005
DA 2024-07-18
ER

PT J
AU Bouras, C
   Gkamas, A
   Karaliotas, A
   Stamos, K
AF Bouras, C
   Gkamas, A
   Karaliotas, A
   Stamos, K
TI Architecture and performance evaluation for redundant multicast
   transmission supporting adaptive QoS
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IP based networks and services; multimedia systems and services;
   multicast; Quality of Service; adaptation mechanisms; CORBA
AB In this paper we describe the architecture of an application that was developed for the transmission of multimedia data, using the multicast mechanism, over the Internet. There are two major issues that have to be considered when designing and implementing such a service, the fairness and the adaptation schemes. The fairness problem results from the fact that Clients with different capabilities have to be served. In our application we use a mechanism that categorizes the Clients into a number of groups according to each Client's capabilities and ( the mechanism) serves each group of Clients with a different multicast stream. With the term "capabilities" we do not only mean the processing power of the Client, but also the capacity and the condition of the network path towards that Client. Because of today's Internet heterogeneity and the lack of Quality of Service (QoS) support, the Server cannot assume that the Clients will permanently be able to handle a specific bit rate. We have therefore implemented an additional mechanism for the intra-stream bit rate adaptation. The proposed mechanism uses a "friendly" to the network users congestion control policy to control the transmission of the data. We evaluate the adaptive multicast transmission mechanism through a number of experiments and a number of simulations in order to examine its behaviour to a heterogeneous group of Clients and its behaviour against TCP and UDP data streams.
C1 Univ Patras, Comp Engn & Informat Dept, GR-26500 Patras, Greece.
   Res Acad Comp Technol Inst, GR-26221 Patras, Greece.
C3 University of Patras
RP Univ Patras, Comp Engn & Informat Dept, GR-26500 Patras, Greece.
EM bouras@cti.gr; gkamas@cti.gr; karaliot@cti.gr; stamos@cti.gr
RI Gkamas, Apostolos/AAZ-1397-2020
OI Gkamas, Apostolos/0000-0003-0966-5140; Stamos,
   Kostas/0000-0002-2186-0304
CR Allman M., 1999, IETF RFC 2581
   [Anonymous], 2003, 3550 RFC
   [Anonymous], [No title captured]
   [Anonymous], JAVA MEDIA FRAMEWORK
   BOLOT JC, 1994, P SIGCOMM 1994 LOND, P139
   BOURAS C, 2001, 7 INT WORKSH MULT SY, P133
   BOURAS C, 2000, PROTOCOLS MULTIMEDIA, P129
   BOURAS C, 2001, 9 INT C SOFTW TEL CO, V2, P585
   Braden R., 1994, 1633 RFC
   BYERS J, 2000, P 2 INT WORKSH NETW, P71
   CEN S, 1998, P MULT COMP NETW
   CHANG Y, 2000, P 2000 IEEE INT C MU
   Cheung SY, 1996, IEEE INFOCOM SER, P553, DOI 10.1109/INFCOM.1996.493348
   Deering S., 1998, 2460 RFC
   DIOT C, 2001, WORKSH INT DES SLS D
   FLOYD S, 1998, UNPUB IEEE ACM T NET
   JIANG T, 1998, SIGMETRICS, P202
   JIANG T, 1999, P 9 INT WORKSH NETW, P103
   KIM T, 2001, P NOSSDAV 01 PORT JE
   LI X, 1999, IEEE NETWORK MAG APR
   MCCANNE S, 1996, 1996 ACM SIGC C AUG, P117
   MCCANNE S, UCB LBNL NETWORK SIM
   MUNDUR P, NETWORK DELAY JITTER
   NICHOLS K, 2474 RFC
   PANDHYE J, 1999, P INT WORKSH NETW OP
   Park K, 1996, 1996 INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P171, DOI 10.1109/ICNP.1996.564935
   RIZZO L, 2000, P SIGCOMM 2000 STOCK
   Sisalem D, 1998, ICC 98 - 1998 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS VOLS 1-3, P891, DOI 10.1109/ICC.1998.685140
   SISALEM D, 2000, 10 INT WORKSH NETW O
   SMITH H, IN PRESS J HIGH SPEE
   VICKERS BJ, 1998, P IEEE INF MARCH
   Walpole J., 1997, P 26 APPL IM PATT RE
   WIDMER J, 2001, P ACM SIGCOMM SAN DI
NR 33
TC 0
Z9 2
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2005
VL 25
IS 1
BP 85
EP 110
DI 10.1023/B:MTAP.0000046383.85914.de
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 866VY
UT WOS:000224802700004
DA 2024-07-18
ER

PT J
AU Balekai, R
   Holi, MS
AF Balekai, Raviteja
   Holi, Mallikarjun S.
TI Exploring the potential of Radiomics in identification and treatment of
   lung cancer: A systematic evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lung cancer; Radiomics; Machine learning
ID ARTIFICIAL-INTELLIGENCE; HISTOLOGICAL SUBTYPES; IMAGE SEGMENTATION;
   TEXTURAL FEATURES; PREDICTING EGFR; CT IMAGES; CLASSIFICATION;
   VARIABILITY; TUMOR; BIOMARKERS
AB Lung cancer is one of the most serious and life-threatening diseases in the world. Imaging modalities like computed tomography (CT) and Positron emission tomography (PET) play a crucial role in cancer diagnosis. Radiomics is an emerging field in medical imaging that uses advanced computational algorithms to extract quantitative features from medical images. Machine learning makes radiomics method of cancer diagnosis easier and more efficient by automating the process of feature selection and classification, which can save time and reduce the risk of human error in the diagnosis. It has the potential to revolutionize cancer detection by providing clinicians with valuable insights into tumour biology that can help in clinical decision-making and improve patient care outcomes. In this review paper, we primarily summarize the workflow of radiomics studies in the context of lung cancer and discussed the practical uses of radiomics in lung cancer, such as malignant tumour identification, classification of histologic subtypes, identification of tumour genotypes, and prediction of treatment response. Additionally, the paper addresses the key challenges associated with the clinical transition of radiomics, the limitations of current approaches, and potential future directions in this field.
C1 [Balekai, Raviteja] Affiliated Visvesvaraya Technol Univ, G M Inst Technol, Dept ECE, Davangere 590018, Karnataka, India.
   [Holi, Mallikarjun S.] Visvesvaraya Technol Univ, A Constituent Coll, Univ BDT Coll Engn, Dept E&IE, Davangere 590018, Karnataka, India.
C3 Visvesvaraya Technological University
RP Balekai, R (corresponding author), Affiliated Visvesvaraya Technol Univ, G M Inst Technol, Dept ECE, Davangere 590018, Karnataka, India.
EM ravitejj10@gmail.com
CR Abdel-Basset M, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0846-9
   Aerts HJWL, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5006
   American Cancer Society, 2023, Lung Cancer Survival Rates
   [Anonymous], 2021, Recommendation United States Preventive Services Taskforce
   Aydin OU, 2021, EUR RADIOL EXP, V5, DOI 10.1186/s41747-020-00200-2
   Bashir U, 2019, BRIT J RADIOL, V92, DOI 10.1259/bjr.20190159
   Benmazou S, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP)
   Bianconi F, 2018, ANTICANCER RES, V38, P2155, DOI 10.21873/anticanres.12456
   Binczyk F, 2021, TRANSL LUNG CANCER R, V10, P1186, DOI 10.21037/tlcr-20-708
   Bommert A, 2020, COMPUT STAT DATA AN, V143, DOI 10.1016/j.csda.2019.106839
   Brandao L, 2021, PROCEDIA COMPUT SCI, V181, P487, DOI 10.1016/j.procs.2021.01.194
   Chang C, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.603882
   Chaunzwa TL, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84630-x
   Chen CH, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0192002
   Chen S, 2022, FRONT MED-LAUSANNE, V9, DOI 10.3389/fmed.2022.1041034
   Chen X, 2019, PROC CVPR IEEE, P11624, DOI 10.1109/CVPR.2019.01190
   Chen Z, 2014, NAT REV CANCER, V14, P535, DOI 10.1038/nrc3775
   Coroller TP, 2017, J THORAC ONCOL, V12, P467, DOI 10.1016/j.jtho.2016.11.2226
   Court LE, 2016, TRANSL CANCER RES, V5, P340, DOI 10.21037/tcr.2016.06.17
   De Wever W, 2011, BREATHE, V7, P338, DOI 10.1183/20734735.022110
   Dong YY, 2021, QUANT IMAG MED SURG, V11, P2354, DOI 10.21037/qims-20-600
   Ganeshan B, 2013, CANCER IMAGING, V13, P140, DOI 10.1102/1470-7330.2013.0015
   Gillies RJ, 2016, RADIOLOGY, V278, P563, DOI 10.1148/radiol.2015151169
   Gong JW, 2022, BMC MED IMAGING, V22, DOI 10.1186/s12880-022-00822-5
   Guo YX, 2021, ACAD RADIOL, V28, pE258, DOI 10.1016/j.acra.2020.06.010
   Haider Stefan P, 2020, Cancers Head Neck, V5, P6, DOI 10.1186/s41199-020-00053-7
   Hawkins S, 2016, J THORAC ONCOL, V11, P2120, DOI 10.1016/j.jtho.2016.07.002
   Hayes DF, 2015, MOL ONCOL, V9, P960, DOI 10.1016/j.molonc.2014.10.004
   He BX, 2020, J IMMUNOTHER CANCER, V8, DOI 10.1136/jitc-2020-000550
   Hemalatha R., 2018, Medical and Biological Image Analysis, V4, P2, DOI [DOI 10.5772/INTECHOPEN.74576, 10.5772/interchopen.74576]
   Herbst RS, 2008, NEW ENGL J MED, V359, P1367, DOI 10.1056/NEJMra0802714
   Hou RP, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.679764
   Houseni M, 2021, POL J RADIOL, V86, pE64, DOI 10.5114/pjr.2021.103239
   Huang L, 2019, CLIN LUNG CANCER, V20, pE638, DOI 10.1016/j.cllc.2019.05.005
   Huang XM, 2022, FRONT ONCOL, V12, DOI 10.3389/fonc.2022.772770
   Hyun SH, 2019, CLIN NUCL MED, V44, P956, DOI 10.1097/RLU.0000000000002810
   Jain P, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.744724
   Jazieh K, 2022, J IMMUNOTHER CANCER, V10, DOI 10.1136/jitc-2021-003778
   Jonas DE, 2021, JAMA-J AM MED ASSOC, V325, P971, DOI 10.1001/jama.2021.0377
   Joskowicz L, 2019, EUR RADIOL, V29, P1391, DOI 10.1007/s00330-018-5695-5
   Kakino R, 2020, PHYS MEDICA, V69, P176, DOI 10.1016/j.ejmp.2019.12.019
   Khodabakhshi Z, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104752
   Khorrami M, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180012
   Kirienko M, 2018, EUR J NUCL MED MOL I, V45, P207, DOI 10.1007/s00259-017-3837-7
   Kociolek M, 2020, COMPUT MED IMAG GRAP, V81, DOI [10.1016/j.compmedimg.2020.101716, 10.1016/j.compmedimag.2020.101716]
   Lambin P, 2017, NAT REV CLIN ONCOL, V14, P749, DOI 10.1038/nrclinonc.2017.141
   Lee G, 2017, EUR J RADIOL, V86, P297, DOI 10.1016/j.ejrad.2016.09.005
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Li YW, 2022, GENOM PROTEOM BIOINF, V20, P850, DOI 10.1016/j.gpb.2022.11.003
   Liu J, 2019, MED PHYS, V46, P3091, DOI 10.1002/mp.13551
   Liu X, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.717039
   Liu Y, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.657615
   Liu ZY, 2019, THERANOSTICS, V9, P1303, DOI 10.7150/thno.30309
   Lo P, 2016, MED PHYS, V43, P4854, DOI 10.1118/1.4954845
   Lu JM, 2022, DIS MARKERS, V2022, DOI 10.1155/2022/2056837
   Luo D, 2021, FRONT MED TECHNOL, V3, DOI 10.3389/fmedt.2021.767836
   Maolood IY, 2018, OPEN MED-WARSAW, V13, P374, DOI 10.1515/med-2018-0056
   Marentakis P, 2021, MED BIOL ENG COMPUT, V59, P215, DOI 10.1007/s11517-020-02302-w
   Midya A, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.1.011020
   Mwangi B, 2014, NEUROINFORMATICS, V12, P229, DOI 10.1007/s12021-013-9204-3
   Le NQK, 2021, INT J MOL SCI, V22, DOI 10.3390/ijms22179254
   Oliver JA, 2015, TRANSL ONCOL, V8, P524, DOI 10.1016/j.tranon.2015.11.013
   Park S, 2019, KOREAN J RADIOL, V20, P1431
   Parmar C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102107
   Patil R, 2016, TOMOGRAPHY, V2, P374, DOI 10.18383/j.tom.2016.00244
   Primakov SP, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30841-3
   Rister B, 2017, IEEE T IMAGE PROCESS, V26, P4900, DOI 10.1109/TIP.2017.2722689
   Roberts T, 2017, STAT MED, V36, P1989, DOI 10.1002/sim.7264
   Said Y, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13030546
   Saif Muhammad Wasif, 2010, Yale Journal of Biology and Medicine, V83, P53
   Sha X, 2019, TRANSL CANCER RES, V8, P1741, DOI 10.21037/tcr.2019.08.20
   Shao D, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.721318
   Shrivastava N, 2020, INT J IMAGE GRAPH, V20, DOI 10.1142/S0219467820500187
   Song JD, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.30442
   Song L, 2020, FRONT ONCOL, V10, DOI 10.3389/fonc.2020.00369
   Sun XF, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0064-y
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Taha AA, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0068-x
   Tam AL, 2016, J VASC INTERV RADIOL, V27, P8, DOI 10.1016/j.jvir.2015.10.019
   Tibshirani R, 2011, J R STAT SOC B, V73, P273, DOI 10.1111/j.1467-9868.2011.00771.x
   Tu WT, 2019, LUNG CANCER, V132, P28, DOI 10.1016/j.lungcan.2019.03.025
   Vaidya P, 2020, LANCET DIGIT HEALTH, V2, pE116, DOI 10.1016/S2589-7500(20)30002-9
   Varma S, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-91
   Wang JT, 2023, FRONT ONCOL, V13, DOI 10.3389/fonc.2023.1157891
   Wang J, 2016, IEEE ENG MED BIO, P1272, DOI 10.1109/EMBC.2016.7590938
   Wang S, 2022, LANCET DIGIT HEALTH, V4, pE309, DOI 10.1016/S2589-7500(22)00024-3
   Wang S, 2019, EUR RESPIR J, V53, DOI 10.1183/13993003.00986-2018
   Weber NM, 2019, CURR PROBL DIAGN RAD, V48, P152, DOI 10.1067/j.cpradiol.2018.10.003
   Wei Mu, 2018, Proceedings of the SPIE - Progress in Biomedical Optics and Imaging, V10575, DOI 10.1117/12.2293376
   Wu HF, 2013, J DIGIT IMAGING, V26, P797, DOI 10.1007/s10278-012-9547-6
   Wu W, 2019, EUR RADIOL, V29, P6100, DOI 10.1007/s00330-019-06213-9
   Wu WM, 2016, FRONT ONCOL, V6, DOI 10.3389/fonc.2016.00071
   Xiao ZH, 2023, QUANT IMAG MED SURG, V13, P1286, DOI 10.21037/qims-22-760
   Xie YT, 2019, IEEE T MED IMAGING, V38, P991, DOI 10.1109/TMI.2018.2876510
   Yang FC, 2022, EUR RADIOL, V32, P1538, DOI 10.1007/s00330-021-08277-y
   Yang JZ, 2016, COMPUT MED IMAG GRAP, V48, P1, DOI 10.1016/j.compmedimag.2015.12.001
   Yang YY, 2022, EXPERT SYST APPL, V194, DOI 10.1016/j.eswa.2021.116436
   Yin GT, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.709137
   Zhang NS, 2020, THERANOSTICS, V10, P11707, DOI 10.7150/thno.50565
   Zhang RP, 2019, EUR J RADIOL, V121, DOI 10.1016/j.ejrad.2019.108735
   Zhang XP, 2022, FRONT ONCOL, V12, DOI 10.3389/fonc.2022.773840
   Zhao BS, 2014, TRANSL ONCOL, V7, P88, DOI 10.1593/tlo.13865
   Zheng Q, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/4504306
   Zhu R, 2012, J COMPUT, V7, P838, DOI 10.4304/jcp.7.4.838-841
   Zhu XZ, 2018, EUR RADIOL, V28, P2772, DOI 10.1007/s00330-017-5221-1
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
   Zou KH, 2004, ACAD RADIOL, V11, P178, DOI 10.1016/S1076-6332(03)00671-8
   Zwanenburg A, 2020, RADIOLOGY, V295, P328, DOI 10.1148/radiol.2020191145
NR 108
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 29
PY 2023
DI 10.1007/s11042-023-17922-1
EA DEC 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL1O1
UT WOS:001132108500015
DA 2024-07-18
ER

PT J
AU Tener, F
   Lanir, J
AF Tener, Felix
   Lanir, Joel
TI Investigating intervention road scenarios for teleoperation of
   autonomous vehicles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human-computer interaction; Automobile; User interface design;
   Teleoperation; Interview; Qualitative methods
ID OPPORTUNITIES
AB Autonomous vehicles (AVs) are quickly advancing and show promise to be a transformative mode of transportation. However, the prevailing consensus suggests that AVs will not be capable of addressing every traffic situation, necessitating remote human intervention in certain edge case scenarios. To facilitate the development of future teleoperation solutions, it is imperative to establish a clear and comprehensive set of intervention scenarios. To achieve this, we undertook a thorough investigation employing in-depth semi-structured interviews with 14 experts specializing in AV teleoperation. Employing thematic analysis to organize and classify the collected data, our study offers a comprehensive compilation of use cases that may require remote human assistance. By doing so, our findings provide a solid groundwork for the design and implementation of future teleoperation user interfaces. These interfaces may play a crucial role in enabling effective and efficient collaboration between humans and AVs in situations where remote intervention becomes necessary. Ultimately, our research contributes to the advancement of AV technology by identifying critical areas where human involvement can augment the capabilities of autonomous systems, thereby ensuring safer and more reliable transportation solutions.
C1 [Tener, Felix; Lanir, Joel] Univ Haifa, Informat Syst, Haifa, Israel.
C3 University of Haifa
RP Tener, F (corresponding author), Univ Haifa, Informat Syst, Haifa, Israel.
EM felix.tener@gmail.com; ylanir@is.haifa.ac.il
OI Lanir, Joel/0000-0002-9838-5142
FU Israeli Innovation Authority; Israeli Innovation Authority, IDIT PhD
   fellowship; Israeli Smart Transportation Research Center; Israeli
   Ministry of Aliyah and Integration
FX This work was supported and funded by the Israeli Innovation Authority,
   IDIT PhD fellowship, The Israeli Smart Transportation Research Center,
   and The Israeli Ministry of Aliyah and Integration. We also wish to
   thank DriveU and Cognata for their collaboration and specifically, Eli
   Shapira for his help throughout this work.
CR Adams J. A., 2007, P 2007 HUM SYST INT, P615
   [Anonymous], 2021, TAXONOMY DEFINITIONS
   [Anonymous], 2006, Proc Hum Factors Ergon Soc Annu Meet, DOI [DOI 10.1177/154193120605000135, DOI 10.1177/15419312060500013]
   Bogdoll D., 2021, arXiv
   Borojeni SS, 2018, 20TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI 2018), DOI 10.1145/3229434.3229464
   Borojeni SS, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173820
   Borojeni SS, 2016, 8TH INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS (AUTOMOTIVEUI 2016), P237, DOI 10.1145/3003715.3005409
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Chen JYC, 2011, IEEE T SYST MAN CY C, V41, P435, DOI 10.1109/TSMCC.2010.2056682
   Dixit VV, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168054
   Durantin G, 2014, BEHAV BRAIN RES, V259, P16, DOI 10.1016/j.bbr.2013.10.042
   Fagnant DJ, 2015, TRANSPORT RES A-POL, V77, P167, DOI 10.1016/j.tra.2015.04.003
   Favarò F, 2018, ACCIDENT ANAL PREV, V110, P136, DOI 10.1016/j.aap.2017.11.001
   Feng JC, 2020, 2020 3RD WORLD CONFERENCE ON MECHANICAL ENGINEERING AND INTELLIGENT MANUFACTURING (WCMEIM 2020), P36, DOI 10.1109/WCMEIM52463.2020.00014
   Fennel M, 2021, IEEE ROBOT AUTOM LET, V6, P4088, DOI 10.1109/LRA.2021.3067846
   Flemisch FO, 2014, ERGONOMICS, V57, P343, DOI 10.1080/00140139.2013.869355
   Fong T, 2001, P SOC PHOTO-OPT INS, V4195, P300, DOI 10.1117/12.417314
   Fong T, 2001, AUTON ROBOT, V11, P9, DOI 10.1023/A:1011295826834
   Goodall N, 2020, TRANSPORT RES A-POL, V142, P14, DOI 10.1016/j.tra.2020.09.024
   Grabowski A, 2021, INT J HUM-COMPUT ST, V156, DOI 10.1016/j.ijhcs.2021.102707
   Graf G., 2020, ADJ P 12 INT ACM C A, P85, DOI [DOI 10.1145/3409251.3411730, 10.1145/3409251.3411730]
   Graf G, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399942
   GreyB, 2021, Top 30 self driving technology and car companies
   Hampshire RC, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0232837
   Hedayati H, 2018, ACMIEEE INT CONF HUM, P78, DOI 10.1145/3171221.3171251
   Herger M., 2022, 2021 disengagement report from California
   Hill S. G., 2007, 2007 2nd Annual Conference on Human-Robot Interaction (HRI), P169
   Kalra N, 2016, TRANSPORT RES A-POL, V94, P182, DOI 10.1016/j.tra.2016.09.010
   Kay JS, 1995, C HUM FACT COMP SYST, V2, P107
   Kettwich C, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5050026
   Khattak ZH, 2021, IEEE T INTELL TRANSP, V22, P7485, DOI 10.1109/TITS.2020.3003527
   Kot T, 2018, INT J ADV ROBOT SYST, V15, DOI 10.1177/1729881417751545
   Lillemaa M, 2004, Encyclopedia of Human-Computer Interaction, P147
   Litman T., 2020, AUTONOMOUS VEHICLE I
   Lv C, 2018, IEEE-CAA J AUTOMATIC, V5, P58, DOI 10.1109/JAS.2017.7510745
   Macioszek E, 2018, ADV INTELL SYST, V631, P147, DOI 10.1007/978-3-319-62316-0_12
   Mutzenich C, 2021, COGN RES, V6, DOI 10.1186/s41235-021-00271-8
   Pollick F., P 7 INT C AUT US INT, P3, DOI [10.1145/2799250.2799262, DOI 10.1145/2799250.2799262]
   Murphy RR, 2020, Arxiv, DOI arXiv:2008.06976
   Schaefer KE, 2017, COGN SYST RES, V46, P26, DOI 10.1016/j.cogsys.2017.02.002
   Schitz D, 2020, IFAC PAPERSONLINE, V53, P15368, DOI 10.1016/j.ifacol.2020.12.2351
   SHERIDAN TB, 1963, IEEE T HUM FACT ENG, VHFE4, P25, DOI 10.1109/THFE.1963.231283
   SHERIDAN TB, 1989, AUTOMATICA, V25, P487, DOI 10.1016/0005-1098(89)90093-9
   Tener F, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501827
   Trabelsi Y., 2023, INT C INT US INT P I, P750, DOI [10.1145/3581641.3584068, DOI 10.1145/3581641.3584068]
   van Erp J, 2003, ERGONOMICS, V46, P1471, DOI 10.1080/0014013032000121624
   Zhang T, 2020, IEEE INTERNET THINGS, V7, P11347, DOI 10.1109/JIOT.2020.3028766
   Zimmerman J, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P493
NR 48
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 29
PY 2023
DI 10.1007/s11042-023-17851-z
EA DEC 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL1O1
UT WOS:001132108500007
DA 2024-07-18
ER

PT J
AU Hadjadji, I
   Falek, L
AF Hadjadji, Imene
   Falek, Leila
TI Evaluating degradation in emotional speech quality over a 4G telephone
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Emotional speech degradation; Speech emotion recognition; CNN; Mel
   frequency scale; Log frequency scale; Spectrogram; 4G network; Wireless
   network; Objective evaluation; Subjective evaluation
ID OBJECTIVE MEASUREMENT; NARROW-BAND; RECOGNITION; INTELLIGIBILITY;
   DATABASES; FEATURES
AB The present study focuses on the evaluation of the degradation of emotional expression in speech generated by a wireless telephone network. Two assessment approaches emerged: an objective one, deploying convolutional neural networks (CNNs) fed with spectrograms across three scales (Linear, Logarithmic, Mel), and a subjective method grounded in human perception. The study gathered expressive phrases in two different languages: from novice Arabic and proficient German speakers. These utterances underwent transmission on a real 4G network a rarity, as usual focus lies on bandwidth (BW) reduction or compression. Our innovation lies in utilizing the complete 4G infrastructure, accounting for all possible impairments. The results obtained indeed reveal a significant impact of transmission via the real 4G network on emotion recognition. Prior to transmission, the highest recognition rates, measured by the objective method using the Mel frequency scale, were 76% for Arabic and 91% for German. After transmission, these rates significantly decreased, reaching 70% for Arabic and 82% for German (a degradation of 6% and 9%), respectively. As for the subjective method, the recognition rates were 75% for Arabic and 70% for German before transmission and dropped to 67% for Arabic and 68% for German after transmission (a degradation of 8% and 2%). Our results were also compared to those found in the literature that used the same database.
C1 [Hadjadji, Imene; Falek, Leila] USTHB, LCPTS, BP 32 El Aliabab Ezzouar, Algiers 16111, Algeria.
C3 University Science & Technology Houari Boumediene
RP Hadjadji, I (corresponding author), USTHB, LCPTS, BP 32 El Aliabab Ezzouar, Algiers 16111, Algeria.
EM ihadjadji@usthb.dz; lfalek@usthb.dz
OI Hadjadji, Imene/0000-0002-4372-7627
FU Direction Gnrale de la Recherche Scientifique et du Dveloppement
   Technologique; DGRSDT
FX The authors would particularly like to thank the DGRSDT for supporting
   this research work carried out within the framework of the Doctoral
   thesis of the main author of this contribution.
CR Abu Shaqra Ftoon, 2023, International Journal of Speech Technology, P123, DOI 10.1007/s10772-022-09981-w
   Akçay MB, 2020, SPEECH COMMUN, V116, P56, DOI 10.1016/j.specom.2019.12.001
   Albahri A., 2016, Int J Signal Process Syst, V4, P55
   Albahri A, 2016, 2016 10 INT C SIGN P, P1, DOI [10.1109/ICSPCS.2016.7843353, DOI 10.1109/ICSPCS.2016.7843353]
   Aljuhani RH, 2021, IEEE ACCESS, V9, P127081, DOI 10.1109/ACCESS.2021.3110992
   [Anonymous], 2017, ISPRS J Photogramm Remote Sens
   [Anonymous], 2016, P 13 INT C NATURAL L
   Banerjee A, 2023, MULTIMED TOOLS APPL, V82, P10887, DOI 10.1007/s11042-022-13721-2
   Banik D, 2021, Communications in Computer and Information Science, V1459, DOI [10.1007/978-3, DOI 10.1007/978-3]
   Banik D, 2023, SOFT COMPUT, V27, P7513, DOI 10.1007/s00500-022-07700-w
   Banik D, 2020, SADHANA-ACAD P ENG S, V45, DOI 10.1007/s12046-020-01427-w
   Banik D, 2021, INT J SPEECH TECHNOL, V24, P903, DOI 10.1007/s10772-020-09676-0
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bhavan A, 2019, KNOWL-BASED SYST, V184, DOI 10.1016/j.knosys.2019.104886
   Boudraa M, 2000, ACUSTICA, V86, P870
   Breed G., 2003, High Frequency Electronics, P46
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Chandrasekar P, 2014, 2014 INTERNATIONAL CONFERENCE ON CIRCUITS, SYSTEMS, COMMUNICATION AND INFORMATION TECHNOLOGY APPLICATIONS (CSCITA), P341, DOI 10.1109/CSCITA.2014.6839284
   Chollet F., 2017, DEEP LEARNING PYTHON
   Chourasia Mayank, 2021, Intelligent Data Communication Technologies and Internet of Things. Proceedings of ICICI 2020. Lecture Notes on Data Engineering and Communications Technologies (LNDECT 57), P471, DOI 10.1007/978-981-15-9509-7_39
   Cipressi E, 2019, INT WIREL COMMUN, P1273
   Demri L, 2015, ACTA ACUST UNITED AC, V101, P1052, DOI 10.3813/AAA.918899
   Deo Satya, 2022, 2022 OITS International Conference on Information Technology (OCIT), P113, DOI 10.1109/OCIT56763.2022.00031
   Du K-L., 2010, Wireless Communication Systems: From RF Subsystems to 4G Enabling Technologies, DOI [10.1017/CBO9780511841453, DOI 10.1017/CBO9780511841453]
   Gamper H, 2019, IEEE WORK APPL SIG, P85, DOI [10.1109/waspaa.2019.8937202, 10.1109/WASPAA.2019.8937202]
   García N, 2015, 2015 20TH SYMPOSIUM ON SIGNAL PROCESSING, IMAGES AND COMPUTER VISION (STSIVA)
   Hadjadji I, 2020, Enhancement of the interlocutor emotion recognition rate from non-professionals speakers in Arabic database
   Hadjadji I, 2019, 2019 INTERNATIONAL CONFERENCE ON ADVANCED ELECTRICAL ENGINEERING (ICAEE), DOI 10.1109/icaee47123.2019.9014809
   Hodson TO, 2022, GEOSCI MODEL DEV, V15, P5481, DOI 10.5194/gmd-15-5481-2022
   Issa D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101894
   Jain M, 2020, Arxiv, DOI arXiv:2002.07590
   Jang BY, 2019, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-019-0155-y
   Jiang Xiaoqing, 2017, Journal of China Universities of Posts and Telecommunications, V24, P1, DOI 10.1016/S1005-8885(17)60193-6
   Jones D. L., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P2222, DOI 10.1109/ICASSP.1989.266906
   Khalil RA, 2019, IEEE ACCESS, V7, P117327, DOI 10.1109/ACCESS.2019.2936124
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lech M., 2018, Adv Sci Technol Eng Syst, V3, P363, DOI DOI 10.25046/AJ030437
   Lech M, 2020, FRONT COMP SCI-SWITZ, V2, DOI 10.3389/fcomp.2020.00014
   Lonkar Smita Avinash, 2022, International Journal of Information Technology, V14, P1981, DOI 10.1007/s41870-020-00455-3
   Lotz AF, 2017, Studientexte zur Sprachkommunikation: ElektronischeSprachsignalverarbeitung, P1
   McCrum-Gardner E, 2008, BRIT J ORAL MAX SURG, V46, P38, DOI 10.1016/j.bjoms.2007.09.002
   Mishra AR, 2018, Fundamentals of Network Planning and Optimization 2G/3G/4G Evolution to 5G, Patent No. 9781119331766
   Mohamed O., 2021, arXiv
   Mohammad SM, 2022, COMPUT LINGUIST, V48, P239, DOI 10.1162/coli_a_00433
   Mustaqeem, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010183
   Nogueira K, 2015, SIBGRAPI, P289, DOI 10.1109/SIBGRAPI.2015.39
   Pandey SK, 2019, 2019 29TH INTERNATIONAL CONFERENCE RADIOELEKTRONIKA (RADIOELEKTRONIKA), P197
   Parichehreh A, 2019, IEEE WCNC, DOI 10.1109/WCNC.2019.8885501
   Pérez P, 2022, MULTIMED TOOLS APPL, V81, P12287, DOI 10.1007/s11042-021-11251-x
   Pocta P, 2017, ACTA ACUST UNITED AC, V103, P311, DOI 10.3813/AAA.919059
   Pocta P, 2015, SPEECH COMMUN, V71, P1, DOI 10.1016/j.specom.2015.04.001
   Reddy AP, 2020, INT J SPEECH TECHNOL, V23, P277, DOI 10.1007/s10772-020-09689-9
   Reddy CKA, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6493, DOI 10.1109/ICASSP39728.2021.9414878
   Ruíz-Guirola DE, 2021, IET COMMUN, V15, P1000, DOI 10.1049/cmu2.12137
   Shahin I, 2022, EXPERT SYST APPL, V188, DOI 10.1016/j.eswa.2021.116080
   Shen J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4779, DOI 10.1109/ICASSP.2018.8461368
   Stolar M., 2018, 2018 12 INT C SIGN P, P1, DOI DOI 10.1109/ICSPCS.2018.8631752
   Stolar Melissa N., 2017, 2017 11 INT C SIGN P, P1, DOI [10.1109/ICSPCS.2017.8270472, DOI 10.1109/ICSPCS.2017.8270472]
   Swain M, 2018, INT J SPEECH TECHNOL, V21, P93, DOI 10.1007/s10772-018-9491-z
   Tomkos I., 2004, IEEE Communications Magazine, V42, pS40, DOI 10.1109/MCOM.2004.1321386
   Villette S, 2017, INT CONF ACOUST SPEE, P5110, DOI 10.1109/ICASSP.2017.7953130
   Wang M, 2016, AM STAT, V70, P195, DOI 10.1080/00031305.2015.1093027
   Zhang FY, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23111507
NR 63
TC 0
Z9 0
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 19
PY 2023
DI 10.1007/s11042-023-17785-6
EA DEC 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7T2
UT WOS:001126521200005
DA 2024-07-18
ER

PT J
AU Zhang, C
   Jiang, SJ
   Chen, Z
AF Zhang, Cheng
   Jiang, Shujuan
   Chen, Zhong
TI TENet: leveraging transformer encoders for steganalysis of QIM
   steganography in VoIP speech streams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE VoIP; Steganography; Audio steganalysis; Compressed speech
ID QUANTIZATION INDEX MODULATION; AUDIO STEGANALYSIS
AB Quantization index modulation (QIM) based steganography allows concealing confidential information in the Voice-over-Internet-Protocol (VoIP) speech streams. Cyber attackers and lawbreakers could take advantage of this technique to commence malicious activities. In this paper, we bring up the idea of polynomial codewords (PCs) and bag-of-codewords problems in VoIP steganalysis. To encounter the issues raised, we introduced a simple but more robust and dynamic way of applying codeword and position embeddings to VoIP streams. Then, depending on the codeword and position embeddings, we carefully designed a QIM-based VoIP steganalysis model named TENet. TENet could extract the latent codeword encoder representation that contains both the potential meanings of codewords and the correlations among them through codeword embedding, codeword position embedding, and the transformer encoder. The obtained codeword representation can then be used for sample classification. The experimental results showed that TENet outperforms other state-of-the-art QIM-based VoIP steganalysis methods. Meanwhile, TENet has excellent performance in the testing time and resource consumption experiments.
C1 [Zhang, Cheng; Jiang, Shujuan] China Univ Min & Technol, Sch Comp Sci & Technol, Da Xue Rd, Jiang Su, Xuzhou 221116, Peoples R China.
   [Zhang, Cheng; Jiang, Shujuan] China Univ Min & Technol, Engn Res Ctr Mine Digitalizat, Minist Educ, Da Xue Rd, Jiang Su, Xuzhou 221116, Peoples R China.
   [Chen, Zhong] China Univ Min & Technol, Sch Informat & Control Engn, Da Xue Rd, Jiang Su, Xuzhou 221116, Peoples R China.
C3 China University of Mining & Technology; China University of Mining &
   Technology; China University of Mining & Technology
RP Jiang, SJ (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Da Xue Rd, Jiang Su, Xuzhou 221116, Peoples R China.; Jiang, SJ (corresponding author), China Univ Min & Technol, Engn Res Ctr Mine Digitalizat, Minist Educ, Da Xue Rd, Jiang Su, Xuzhou 221116, Peoples R China.
EM zhangcheng@cumt.edu.cn; shjjiang@cumt.edu.cn; TB21060002B4@cumt.edu.cn
RI ZHANG, CHENG/ABS-8044-2022
OI ZHANG, CHENG/0000-0001-8721-0577; Jiang, Shujuan/0000-0003-0643-0565
FU National Natural Science Foundation of China
FX No Statement Available
CR Avcibas I, 2006, IEEE SIGNAL PROC LET, V13, P92, DOI 10.1109/LSP.2005.862152
   Bo XA, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.375
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen BL, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P85, DOI 10.1145/3082031.3083234
   Chen KJ, 2020, IEEE T CIRC SYST VID, V30, P2027, DOI 10.1109/TCSVT.2019.2918511
   Cogranne R, 2022, IEEE T INF FOREN SEC, V17, P1328, DOI 10.1109/TIFS.2021.3111713
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Giboulot Q, 2022, IEEE T INF FOREN SEC, V17, P1841, DOI 10.1109/TIFS.2022.3173184
   Hu YT, 2021, NEUROCOMPUTING, V419, P70, DOI 10.1016/j.neucom.2020.08.002
   Huang YF, 2011, IET COMMUN, V5, P929, DOI 10.1049/iet-com.2010.0348
   Huang YF, 2011, IEEE T INF FOREN SEC, V6, P296, DOI 10.1109/TIFS.2011.2108649
   Huang YF, 2017, SCI CHINA TECHNOL SC, V60, P1585, DOI 10.1007/s11431-016-0707-3
   Huang YF, 2012, IEEE T INF FOREN SEC, V7, P1865, DOI 10.1109/TIFS.2012.2218599
   Jin Liu, 2012, IEEE International Conference on Communications (ICC 2012), P1133, DOI 10.1109/ICC.2012.6363997
   Koçal OH, 2008, IEEE T INF FOREN SEC, V3, P651, DOI 10.1109/TIFS.2008.2004289
   Kraetzer C, 2007, PROC SPIE, V6505, DOI 10.1117/12.704040
   Li FF, 2018, LECT NOTES COMPUT SC, V11068, P312, DOI 10.1007/978-3-030-00021-9_29
   Li SB, 2012, J ZHEJIANG U-SCI C, V13, P624, DOI 10.1631/jzus.C1100374
   Li SB, 2021, IEEE-ACM T AUDIO SPE, V29, P1556, DOI 10.1109/TASLP.2021.3074752
   Li SB, 2017, IEEE-ACM T AUDIO SPE, V25, P1011, DOI 10.1109/TASLP.2017.2676356
   Lin ZN, 2018, IEEE T INF FOREN SEC, V13, P1854, DOI 10.1109/TIFS.2018.2806741
   Liu P, 2017, MULTIMED TOOLS APPL, V76, P2837, DOI 10.1007/s11042-016-3257-x
   Liu QZ, 2009, IEEE T INF FOREN SEC, V4, P359, DOI 10.1109/TIFS.2009.2024718
   O'Shaughnessy D., 1988, IEEE Potentials, V7, P29, DOI 10.1109/45.1890
   Paulin C, 2016, IEEE C EVOL COMPUTAT, P4831, DOI 10.1109/CEC.2016.7744409
   Paulin C, 2016, INT J SPEECH TECHNOL, V19, P585, DOI 10.1007/s10772-016-9352-6
   Rekik S., 2012, 2012 11th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA), P54, DOI 10.1109/ISSPA.2012.6310612
   Ren YZ, 2018, MULTIMED TOOLS APPL, V77, P12095, DOI 10.1007/s11042-017-4860-1
   Tian H, 2014, MULTIMEDIA SYST, V20, P143, DOI 10.1007/s00530-013-0302-8
   Union IT, 2007, G.729: Coding of speech at 8 kbit/s using conjugate structure algebraic-code-excited linear-prediction (CS-ACELP)
   Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762, 10.48550/arXiv.1706.03762]
   W B, 2021, INT C LEARN REPR
   Wei M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03608-9
   Wu ZJ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041032
   Wu ZJ, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12010017
   Yan SF, 2016, MULTIMED TOOLS APPL, V75, P11493, DOI 10.1007/s11042-015-2865-1
   Yang H, 2020, INT CONF ACOUST SPEE, P2822, DOI [10.1109/icassp40776.2020.9054361, 10.1109/ICASSP40776.2020.9054361]
   Yang H, 2020, LECT NOTES COMPUT SC, V11999, P783, DOI 10.1007/978-3-030-41579-2_45
   Yang H, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P204, DOI 10.1145/3335203.3335735
   Yang J, 2019, IEEE ACCESS, V7, P128313, DOI 10.1109/ACCESS.2019.2939629
   Yang ZL, 2021, IEEE T INF FOREN SEC, V16, P880, DOI 10.1109/TIFS.2020.3023279
   Yang ZL, 2019, IEEE T INF FOREN SEC, V14, P1280, DOI 10.1109/TIFS.2018.2871746
   Ye Jiaquan, 2021, arXiv
   Yi XW, 2019, IEEE T INF FOREN SEC, V14, P2217, DOI 10.1109/TIFS.2019.2895200
   Zhang C, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3160007
NR 45
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 15
PY 2023
DI 10.1007/s11042-023-17802-8
EA DEC 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5L8
UT WOS:001129325100003
DA 2024-07-18
ER

PT J
AU Asudani, DS
   Nagwani, NK
   Singh, P
AF Asudani, Deepak Suresh
   Nagwani, Naresh Kumar
   Singh, Pradeep
TI A comparative evaluation of machine learning and deep learning
   algorithms for question categorization of VQA datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Question Classification; Machine Learning; Deep Learning; SMOTE;
   BERT-based Transformers
AB Question classification primarily involves categorizing questions based on the type of answer, with less emphasis on the words or phrases used to form the query. Question classification is crucial in the Visual Question Answering (VQA) system, and the dataset's quality plays an essential role in the system's development. The available question categorization in the VQA and TDIUC datasets shows imbalance, and the VQA model trained on imbalanced datasets performs poorly in handling language-prior problems, failing to categorize questions, and predicting incorrect outcomes. Therefore, developing a better classification method for classifying questions into appropriate categories based on phrases is necessary. This paper examines the effectiveness of the synthetic minority oversampling technique (SMOTE) in addressing the class imbalance problem within the question classification task using the LSTM, selected machine learning models and BERT-based transformer model. The preprocessing and analysis module efficiently categorizes input question sets by identifying valuable phrases and obtaining an evenly distributed dataset based on question categories from both datasets. The performance evaluation of Naive Bayes, SVM, Random Forests, and XGBoost models shows that the XGBoost model outperforms other selected classifiers, and the LSTM model achieves higher accuracy but requires more computation time. The empirical assessment indicates that the BERT-based transformer model exceeds the traditional models employed for comparison. The ablation study also reveals that utilizing SMOTE techniques for question classification tasks achieves slightly improved accuracy at the expense of higher computation time and resources. It is concluded that the BERT-based transformer model efficiently and precisely performs question classification tasks.
C1 [Asudani, Deepak Suresh; Nagwani, Naresh Kumar; Singh, Pradeep] Natl Inst Technol, Dept Comp Sci & Engn, Raipur, Chhattisgarh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Asudani, DS (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Raipur, Chhattisgarh, India.
EM dsasudani.phd2021.cs@nitrr.ac.in; nknagwani.cs@nitrr.ac.in;
   psingh.cs@nitrr.ac.in
RI Nagwani, Naresh Kumar/AAC-7069-2019
OI Nagwani, Naresh Kumar/0000-0001-5306-5818; Asudani,
   Deepak/0000-0001-7793-2293
FU National Institute of Technology, Raipur
FX The authors gratefully acknowledge the National Institute of Technology,
   Raipur, for providing the GPU server used for this research.
CR Abdel-Nabi H, 2023, KNOWL INF SYST, V65, P1399, DOI 10.1007/s10115-022-01783-5
   Abdullah I, 2023, 2023 IEEE 14 CONTR S, P93, DOI [10.1109/ICSGRC57744.2023.10215477, DOI 10.1109/ICSGRC57744.2023.10215477]
   [Anonymous], 2010, J AM DENT ASSOC, V141, P658
   [Anonymous], 2003, P 26 ANN INT ACM SIG, DOI [DOI 10.1145/860435.860443, 10.1145/860435.860443]
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Asudani DS, 2023, ARTIF INTELL REV, V56, P10345, DOI 10.1007/s10462-023-10419-1
   Asudani DS, 2022, DATA TECHNOL APPL, V56, P483, DOI 10.1108/DTA-07-2021-0191
   Banerjee S, 2012, P WORK QUEST ANSW CO
   Borg A, 2021, NEURAL COMPUT APPL, V33, P1881, DOI 10.1007/s00521-020-05058-4
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Bu Qiong, 2019, International Journal of Crowd Science, V3, P222, DOI 10.1108/IJCS-06-2019-0017
   Budler LC, 2023, WIRES DATA MIN KNOWL, V13, DOI 10.1002/widm.1487
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cortes EG, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P5408
   Cui YM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8118, DOI 10.1109/ICCV48922.2021.00803
   Das A, 2022, MULTIMED TOOLS APPL, V81, P589, DOI 10.1007/s11042-021-11228-w
   Dedeturk BK, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106229
   Deepaisarn S, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-40332-0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dodiya T, 2016, 2016 IEEE INTERNATIONAL WIE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (IEEE WIECON-ECE 2016), P204, DOI 10.1109/WIECON-ECE.2016.8009118
   Eslami T, 2019, ACM-BCB'19: PROCEEDINGS OF THE 10TH ACM INTERNATIONAL CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY AND HEALTH INFORMATICS, P646, DOI 10.1145/3307339.3343482
   Etezadi R, 2023, APPL INTELL, V53, P4124, DOI 10.1007/s10489-022-03732-9
   Farazi M, 2021, INT C PATT RECOG, P3542, DOI 10.1109/ICPR48806.2021.9413330
   Feng F, 2023, MULTIMED TOOLS APPL, V82, P3231, DOI 10.1007/s11042-022-13240-0
   Ferreira LA., 2022, SN Comput Sci, V3, P1, DOI [10.1007/s42979-022-01322-7, DOI 10.1007/S42979-022-01322-7]
   Han C, 2023, INT C COMP VIS 2023, DOI [10.48550/arXiv.2307.13770, DOI 10.48550/ARXIV.2307.13770]
   Hao TY, 2022, NEURAL COMPUT APPL, V34, P2765, DOI 10.1007/s00521-021-06748-3
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ilhan E, 2023, IEEE SIGNAL PROC LET, V30, P1182, DOI 10.1109/LSP.2023.3309577
   Kafle K, 2017, IEEE I CONF COMP VIS, P1983, DOI 10.1109/ICCV.2017.217
   Kalbaliyev E, 2022, P 2 WORKSH NAT LANG, P520, DOI 10.18653/v1/2022.gem-1.48
   Khilji AFUR., 2023, SN Comput. Sci, V4, P421, DOI [10.1007/s42979-023-01870-6, DOI 10.1007/S42979-023-01870-6]
   Kumar T, 2023, MULTIMED TOOLS APPL, V82, P42373, DOI 10.1007/s11042-023-15150-1
   Lan YY, 2020, IEEE ACCESS, V8, P70401, DOI 10.1109/ACCESS.2020.2987101
   Li XM, 2002, POWERCON 2002: INTERNATIONAL CONFERENCE ON POWER SYSTEM TECHNOLOGY, VOLS 1-4, PROCEEDINGS, P556, DOI 10.1109/ICPST.2002.1053604
   Liang J, 2023, P 40 INT C MACH LEAR, DOI [10.48550/arXiv.2305.02187, DOI 10.48550/ARXIV.2305.02187]
   Liang J, 2022, IEEE-CAA J AUTOMATIC, V9, P1083, DOI 10.1109/JAS.2022.105632
   Liu DF, 2021, PROC CVPR IEEE, P9811, DOI 10.1109/CVPR46437.2021.00969
   Liu DF, 2021, INT C PATT RECOG, P3170, DOI 10.1109/ICPR48806.2021.9411961
   Loeff N, 2006, ACL, COLING
   Mallikarjuna C, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103094
   Manmadhan S, 2023, MULTIMED TOOLS APPL, V82, P34937, DOI 10.1007/s11042-023-14981-2
   Mishra Aakansha, 2023, IEEE Transactions on Artificial Intelligence, P81, DOI 10.1109/TAI.2022.3160418
   Mishra A, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206913
   Nassiri K, 2023, APPL INTELL, V53, P10602, DOI 10.1007/s10489-022-04052-8
   Pereira A, 2022, IET SOFTW, V16, P1, DOI 10.1049/sfw2.12028
   Rajpurkar P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P784
   Rezaeenour J, 2023, MULTIMED TOOLS APPL, V82, P17879, DOI 10.1007/s11042-022-14043-z
   Rogers A, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560260
   Roy PK, 2023, CAAI T INTELL TECHNO, V8, P95, DOI 10.1049/cit2.12081
   Sharma H, 2022, MULTIMED TOOLS APPL, V81, P12177, DOI 10.1007/s11042-022-12317-0
   Shi Y, 2018, LECT NOTES COMPUT SC, V11208, P158, DOI 10.1007/978-3-030-01225-0_10
   Shrestha A, 2018, IEEE J EM SEL TOP C, V8, P782, DOI 10.1109/JETCAS.2018.2856117
   Silva VA, 2019, IEEE T LEARN TECHNOL, V12, P485, DOI 10.1109/TLT.2018.2878447
   Supraja S, 2021, IEEE-ACM T AUDIO SPE, V29, P3604, DOI 10.1109/TASLP.2021.3126937
   Toor AS, 2019, MULTIMED TOOLS APPL, V78, P2921, DOI 10.1007/s11042-018-6097-z
   Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762, 10.48550/arXiv.1706.03762]
   Wang W., 2022, 36 C NEUR INF PROC S, DOI DOI 10.48550/ARXIV.2210.00911
   Williams O, 2010, Standford Univ, P1
   Yan H, 2023, MULTIMED TOOLS APPL, V82, P16343, DOI 10.1007/s11042-022-14167-2
   Yan L., 2022, 2022 IJCAI, P2769
   Yan LQ, 2022, IEEE T CIRC SYST VID, V32, P6642, DOI [10.1109/TCSVT.2022.3177320, 10.1109/tcsvt.2022.3177320]
   Zaib M, 2022, KNOWL INF SYST, V64, P3151, DOI 10.1007/s10115-022-01744-y
   Zekrallah SI., 2022, J Syst Manag Sci, V12, P428, DOI [10.33168/JSMS.2022.0320, DOI 10.33168/JSMS.2022.0320]
NR 66
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 13
PY 2023
DI 10.1007/s11042-023-17797-2
EA DEC 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB1N3
UT WOS:001122700100004
DA 2024-07-18
ER

PT J
AU Yang, Y
   Guo, RX
   Zou, CR
   Liang, RY
AF Yang, Yang
   Guo, Ruxue
   Zou, Cairong
   Liang, Ruiyu
TI A strategy scheme of self-fitting based on gain adjustment for digital
   hearing aids
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Digital hearing aids; Gain compensation; Gain adjusting; Self-fitting;
   Wide dynamic range compression
AB The widespread use of traditional digital hearing aids is limited to a certain extent due to the shortage of professionals, and the cumbersome fitting process required for high-performance hearing aids. Against this background, we propose a strategy scheme of self-fitting based on the gain adjustment for digital hearing aids in this paper. First, the scheme combines a multi-channel wide dynamic range compression algorithm and prescription formula to achieve personalized gain compensation for patients with hearing loss. Second, the proposed problem-based guided gain adjustment scheme is used to realize individualized gain adjustment for hearing loss patients. In the gain adjustment scheme, the daily environment factors of patients are considered, and the historical adjustment parameter groups similar to patients are accurately matched by combining the optimized acoustic discrimination algorithm with the similarity matching algorithm. The experimental simulation shows that the proposed scheme can effectively improve patients' speech recognition rate, speech intelligibility, and speech quality compared with traditional algorithms from both subjective and objective experiments.
C1 [Yang, Yang; Guo, Ruxue; Zou, Cairong] Southeast Univ, Sch Informat Sci & Engn, Nanjing 210096, Jiangsu, Peoples R China.
   [Liang, Ruiyu] Inst Nanjing Technol, Sch Informat & Commun Engn, Nanjing 211167, Jiangsu, Peoples R China.
C3 Southeast University - China; Nanjing Tech University
RP Yang, Y (corresponding author), Southeast Univ, Sch Informat Sci & Engn, Nanjing 210096, Jiangsu, Peoples R China.
EM ecokop@163.com; grx0904@sina.com; cairong@seu.edu.cn;
   liangry@njit.edu.cn
OI Yang, Yang/0000-0002-4289-4503
FU Key Technologies Research and Development Program [2020YFC2004002,
   2020YFC2004003]; National Key Research and Development Program of China
   [62001215]; National Natural Science Foundation of China
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant No. 2020YFC2004002 and
   2020YFC2004003, the National Natural Science Foundation of China under
   Grant No. 62001215.
CR Abu-Ghanem S, 2016, EUR ARCH OTO-RHINO-L, V273, P333, DOI 10.1007/s00405-015-3533-9
   Arndt S, 2011, OTOL NEUROTOL, V32, P39, DOI 10.1097/MAO.0b013e3181fcf271
   Chen J, 2013, J ACOUST SOC AM, V133, P2910, DOI 10.1121/1.4799807
   Choi JS, 2016, J AGING HEALTH, V28, P890, DOI 10.1177/0898264315614006
   Contrera KJ, 2016, LARYNGOSCOPE, V126, P2110, DOI 10.1002/lary.25848
   Convery E, 2019, EAR HEARING, V40, P794, DOI 10.1097/AUD.0000000000000663
   Furuki S, 2021, AURIS NASUS LARYNX, V48, P75, DOI 10.1016/j.anl.2020.07.010
   Haile LM, 2021, LANCET, V397, P996, DOI 10.1016/S0140-6736(21)00516-X
   Kates JM, 2021, SPEECH COMMUN, V131, P35, DOI 10.1016/j.specom.2020.05.001
   Kates JM, 2014, J AUDIO ENG SOC, V62, P99, DOI 10.17743/jaes.2014.0006
   Keidser G, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516643284
   Keidser G, 2012, TRENDS AMPLIF, V16, P211, DOI 10.1177/1084713812468511
   Keidser G, 2011, TRENDS AMPLIF, V15, P167, DOI 10.1177/1084713812438700
   Kenna MA, 2015, OTOLARYNG CLIN N AM, V48, P933, DOI 10.1016/j.otc.2015.07.011
   Killion M.C., 1995, J ACOUST SOC AM, V98, P2927, DOI DOI 10.1121/1.414129
   Li LS, 2013, GAIT POSTURE, V38, P25, DOI 10.1016/j.gaitpost.2012.10.006
   Li Y, 2017, MED SCI MONITOR, V23, P4549, DOI 10.12659/MSM.904254
   Liang R, 2017, Appl Sci., V7
   Liang RY, 2017, MOD PHYS LETT B, V31, DOI 10.1142/S0217984917400590
   Madsen SMK, 2015, J ACOUST SOC AM, V137, P1867, DOI 10.1121/1.4914988
   Nicholas JG, 2006, EAR HEARING, V27, P286, DOI 10.1097/01.aud.0000215973.76912.c6
   Nielsen JBB, 2015, IEEE-ACM T AUDIO SPE, V23, P162, DOI 10.1109/TASLP.2014.2377581
   Prathosh AP, 2014, J ACOUST SOC AM, V136, pEL122, DOI 10.1121/1.4885768
   Ricketts TA, 1996, EAR HEARING, V17, P124, DOI 10.1097/00003446-199604000-00006
   Stelmachowicz PG, 1998, EAR HEARING, V19, P131, DOI 10.1097/00003446-199804000-00005
   Takagi H, 2007, IEEE T EVOLUT COMPUT, V11, P414, DOI 10.1109/TEVC.2006.883465
   Xi J, 2017, MOD PHYS LETT B, V31, DOI 10.1142/S0217984917400942
NR 27
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 4
PY 2023
DI 10.1007/s11042-023-17705-8
EA DEC 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AW8Q2
UT WOS:001121582100002
DA 2024-07-18
ER

PT J
AU Omar, MA
   Khelifi, F
   Tahir, MA
AF Omar, Mohamed Albashir
   Khelifi, Fouad
   Tahir, Muhammad Atif
TI Exudate and drusen classification in retinal images using bagged colour
   vector angles and inter colour local binary patterns
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Diabetic retinopathy; Age-related macular degeneration; Inter colour
   local binary patterns; Colour vector angles; Retinal fundus image
ID AUTOMATED DETECTION; NEURAL-NETWORKS; BRIGHT LESIONS; FUNDUS IMAGES;
   RETINOPATHY; TEXTURE; DIFFERENTIATION; IDENTIFICATION; FEATURES
AB The presence of exudates is one of the most significant signs of Diabetic retinopathy (DR) whereas; white or tiny yellow deposits known as drusen mostly identify age-related macular degeneration (AMD). Exudates and drusen may share a similar appearance; hence discriminating them is of extreme importance in enhancing automated AMD and DR diagnosis. Fortunately, diagnosing these diseases in their early stages is extremely useful for effective treatment since they are usually treatable. The goal of this research is to develop an automated tool that helps the pathologist diagnose the type of disease correctly and distinguish between DR, AMD, and normal fundus images through accurate classification of exudates and drusen lesions. In this paper, an automatic retinal diagnosis system that combines different texture and colour features is proposed. New textural and colour features are used in a bag-of-features approach for efficient and accurate detection. A codebook is generated using a bagged combination of inter colour local binary pattern (ICLBP) and colour vector angles (CVA) features to exploit textural and colour information for efficient and accurate classification. Intensive experiments show that the proposed dictionary learning-based system can capture the variety of structures and patterns in retinal fundus images and produce discriminant descriptors for classification. Using an SVM classifier with the obtained bagged combination of the proposed ICLBP and CVA features, the system has been shown to offer high classification performance. The experimental performance has been obtained with a dataset of 798 retinal images collected from various standard datasets, namely: DIARETDB0, DIARETDB1, HEI-MED, STARE, and MESSIDOR. All experiments were conducted with 10-fold cross validation using the classification accuracy, sensitivity, specificity, and area under curve. Correct classification is reported with an average sensitivity of 98.37%, specificity of 99.64% and accuracy of 99.67% and an overall average area under the curve of 0.983%. This represents the best performance achieved so far when compared to existing state-of-the-art systems for the diagnosis of retinal disease with drusen and exudates being the key characteristics in fundus image classification.
C1 [Omar, Mohamed Albashir; Khelifi, Fouad] Buckinghamshire Coll Grp, Dept Creat Digital & Comp, Aylesbury, England.
   [Tahir, Muhammad Atif] Natl Univ Comp & Emerging Sci FAST NUCES, FAST Sch Comp, Karachi Campus, Islamabad, Pakistan.
RP Omar, MA (corresponding author), Buckinghamshire Coll Grp, Dept Creat Digital & Comp, Aylesbury, England.
EM mohamed.a.omar@northumbria.ac.uk; fouad.khelifi@northumbria.ac.uk;
   atif.tahir@nu.edu.pk
CR Afrin R, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ROBOTICS, ELECTRICAL AND SIGNAL PROCESSING TECHNIQUES (ICREST), P527, DOI [10.1109/icrest.2019.8644123, 10.1109/ICREST.2019.8644123]
   Aggarwal K., 2022, IRAQI J COMPUT SCI M, V3, P115, DOI [DOI 10.52866/IJCSM.2022.01.01.013, 10.52866/ijcsm.2022.01.01.013]
   Akram MU, 2013, PATTERN RECOGN, V46, P107, DOI 10.1016/j.patcog.2012.07.002
   Akram UM, 2012, J MED SYST, V36, P3151, DOI 10.1007/s10916-011-9802-2
   Antal B, 2014, KNOWL-BASED SYST, V60, P20, DOI 10.1016/j.knosys.2013.12.023
   Butt MM, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12071607
   Chaum E, 2008, RETINA-J RET VIT DIS, V28, P1463, DOI 10.1097/IAE.0b013e31818356dd
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   Deepak KS, 2012, IEEE T MED IMAGING, V31, P766, DOI 10.1109/TMI.2011.2178856
   Dony R. D., 1999, Engineering Solutions for the Next Millennium. 1999 IEEE Canadian Conference on Electrical and Computer Engineering (Cat. No.99TH8411), P687, DOI 10.1109/CCECE.1999.808005
   Fleming AD, 2007, PHYS MED BIOL, V52, P7385, DOI 10.1088/0031-9155/52/24/012
   Giancardo L, 2012, MED IMAGE ANAL, V16, P216, DOI 10.1016/j.media.2011.07.004
   Hari VS, 2017, PATTERN ANAL APPL, V20, P145, DOI 10.1007/s10044-015-0480-4
   Hassan T, 2020, Evaluation of Deep Segmentation Models for the Extraction of Retinal Lesions from Multi-modal Retinal Images
   Hoover A, 2003, IEEE T MED IMAGING, V22, P951, DOI 10.1109/TMI.2003.815900
   Hunter A, 2000, PERSP NEURAL COMP, P81
   Kalviainen RVJPH, 2007, DIARETDB1 diabetic retinopathy database and evaluation protocol, P61
   Kanski JJ., 2011, Clinical ophthalmology: a systematic approach, V382
   KARNON J., 2008, A preliminary model-based assessment of the cost-utility of a screening programme for early age-related macular degeneration
   Kauppi T., 2006, Machine Vision and Pattern Recognition Research Group, V73, P1
   Kaur J, 2022, ARCH COMPUT METHOD E, V29, P1673, DOI 10.1007/s11831-021-09635-1
   Khalid S, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION, COMPUTING AND DIGITAL SYSTEMS (C-CODE), P390, DOI 10.1109/C-CODE.2017.7918963
   Li H, 2019, Localisation of insulator strings' images based on colour filtering and texture matching, P2790
   Li ZM, 2021, ANAL BIOANAL CHEM, V413, P3541, DOI 10.1007/s00216-021-03305-8
   Nagi DK, 2009, DIABETIC MED, V26, P1301, DOI 10.1111/j.1464-5491.2009.02838.x
   Niemeijer M, 2007, INVEST OPHTH VIS SCI, V48, P2260, DOI 10.1167/iovs.06-0996
   Niemeijer M, 2009, MED IMAGE ANAL, V13, P859, DOI 10.1016/j.media.2009.08.003
   Nugroho HA., 2015, Texture Based Feature Extraction, V6, P04
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Omar M, 2014, I C SOFTWARE KNOWL I
   Omar M, 2016, 2016 INTERNATIONAL CONFERENCE ON CONTROL, DECISION AND INFORMATION TECHNOLOGIES (CODIT), P227, DOI 10.1109/CoDIT.2016.7593565
   Omar MA, 2017, INT C CONTROL DECISI, P202, DOI 10.1109/CoDIT.2017.8102591
   Osareh A, 2009, IEEE T INF TECHNOL B, V13, P535, DOI 10.1109/TITB.2008.2007493
   Sánchez CI, 2008, MED ENG PHYS, V30, P350, DOI 10.1016/j.medengphy.2007.04.010
   Sánchez CI, 2012, MED IMAGE ANAL, V16, P50, DOI 10.1016/j.media.2011.05.004
   Sidibé D, 2015, COMPUT BIOL MED, V62, P175, DOI 10.1016/j.compbiomed.2015.04.026
   Srinivasu PN, 2022, Mob Inf Syst
   Stolte S, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101742
   Tang ZJ, 2014, IET IMAGE PROCESS, V8, P142, DOI 10.1049/iet-ipr.2013.0332
   Turan C, 2018, J VIS COMMUN IMAGE R, V55, P331, DOI 10.1016/j.jvcir.2018.05.024
   van Grinsven MJJP, 2013, I S BIOMED IMAGING, P1444
   van Grinsven MJJP, 2016, BIOMED OPT EXPRESS, V7, P709, DOI 10.1364/BOE.7.000709
   Wan SH, 2018, COMPUT ELECTR ENG, V72, P274, DOI 10.1016/j.compeleceng.2018.07.042
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhou B, 2016, LANCET, V387, P1513, DOI 10.1016/S0140-6736(16)00618-8
NR 46
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 15
PY 2023
DI 10.1007/s11042-023-17169-w
EA NOV 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8YK4
UT WOS:001101241300004
DA 2024-07-18
ER

PT J
AU Spoorthi, S
   Mahesh, S
AF Spoorthi, S.
   Mahesh, Shanthi
TI Hybrid optimized MRF based lung lobe segmentation and lung cancer
   classification using Shufflenet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Firefly algorithm; Artificial hummingbird algorithm; Cuckoo search
   algorithm; Markov random field; ShuffleNet scheme
ID IMAGES
AB Lung cancer is a kind of harmful cancer type that originates from the lungs. In this research, the lung lobe segmentation is carried out using Markov Random Field (MRF)-based Artificial Hummingbird Cuckoo algorithm (AHCA). The AHCA algorithm is modelled by considering the benefits of both the Artificial Hummingbird algorithm (AHA) and the Cuckoo search (CS) algorithm. Moreover, the lung cancer classification is done with ShuffleNet, which is trained by the Artificial Hummingbird Firefly optimization algorithm (AHFO) which is the integration of AHA and Firefly algorithm (FA). In this research, two algorithms are devised for both segmentation and classification. From these two algorithms, the AHA algorithm is used for updating the location. The AHA algorithm had three phases, such as foraging, guided foraging and migrating foraging where the guided foraging stage is selected to update the location for both segmentation and classification. Besides, the developed AHFO-based ShuffleNet scheme attained superior performance with respect to the testing accuracy of 0.9071, sensitivity of 0.9137 and specificity of 0.9039. The performance improvement of the proposed method for testing accuracy is 6.615%, 3.197%, 2.756%, and 1.764% higher than the existing methods. In future, the performance will be boosted by the advanced scheme for identifying the grade of disease.
C1 [Spoorthi, S.] Visvesvaraya Technol Univ, Comp Sci & Engn, Atria Inst Technol, Bengaluru, India.
   [Mahesh, Shanthi] VTU, ISE Dept, Atria Inst Technol, Bengaluru, India.
C3 Visvesvaraya Technological University
RP Spoorthi, S (corresponding author), Visvesvaraya Technol Univ, Comp Sci & Engn, Atria Inst Technol, Bengaluru, India.
EM spoorthib48@gmail.com
FU I would like to express my very great appreciation to the co-authors of
   this manuscript for their valuable and constructive suggestions during
   the planning and development of this research work.
FX I would like to express my very great appreciation to the co-authors of
   this manuscript for their valuable and constructive suggestions during
   the planning and development of this research work.
CR Alqazzaz S, 2019, COMPUT VIS MEDIA, V5, P209, DOI 10.1007/s41095-019-0139-y
   [Anonymous], Lung Image Database Consortium image collection (LIDC-IDRI)dataset from the Cancer Imaging Archive (TCIA)
   Arora S., 2013, Int. J. Comput. Appl., V69, DOI 10.5120/11826-7528
   Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   Bai Y, 2009, IEEE IMAGE PROC, P3305, DOI 10.1109/ICIP.2009.5413938
   Bellotti R, 2007, MED PHYS, V34, P4901, DOI 10.1118/1.2804720
   Bushara AR, 2023, BIOMED SIGNAL PROCES, V85, DOI 10.1016/j.bspc.2023.104930
   Bushara AR, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-14893-1
   Cheng R, 2015, IEEE T CYBERNETICS, V45, P191, DOI 10.1109/TCYB.2014.2322602
   Freitas PG, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON QUALITY OF MULTIMEDIA EXPERIENCE (QOMEX)
   Ghosh S, 2020, PROCEEDINGS OF 2020 IEEE APPLIED SIGNAL PROCESSING CONFERENCE (ASPCON 2020), P163, DOI [10.1109/ASPCON49795.2020.9276669, 10.1109/aspcon49795.2020.9276669]
   Hung TY, 2014, IEEE IMAGE PROC, P239, DOI 10.1109/ICIP.2014.7025047
   Jain S, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104811
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P77, DOI 10.1016/j.patrec.2019.11.014
   Kukreja V, 2022, MULTIMED TOOLS APPL, V81, P28651, DOI 10.1007/s11042-022-12644-2
   Lakshmanaprabu SK, 2019, FUTURE GENER COMP SY, V92, P374, DOI 10.1016/j.future.2018.10.009
   Mahesh KM, 2020, IET IMAGE PROCESS, V14, P2541, DOI 10.1049/iet-ipr.2018.6682
   Pham TX, 2020, IEEE T IMAGE PROCESS, V29, P6507, DOI 10.1109/TIP.2020.2990346
   Rattan S, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P15, DOI 10.1109/ICIIP.2017.8313676
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1413-3
   Sakshi, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119028
   Sakshi, 2023, ARCH COMPUT METHOD E, V30, P457, DOI 10.1007/s11831-022-09805-9
   Sakshi, 2021, ENG APPL ARTIF INTEL, V103, DOI 10.1016/j.engappai.2021.104292
   Sakshi, 2023, Int J Comput Digital Syst, V13, P795, DOI [10.12785/ijcds/130163, DOI 10.12785/IJCDS/130163]
   Sakshi, 2023, ARTIF INTELL REV, V56, P7047, DOI 10.1007/s10462-022-10330-1
   Salama WM, 2022, MULTIMED TOOLS APPL, V81, P32705, DOI 10.1007/s11042-022-13005-9
   Sankar SP, 2021, J AMB INTEL HUM COMP, V12, P5571, DOI 10.1007/s12652-020-02069-w
   Spoorthi B, 2023, INT J IMAGE GRAPH, V23, DOI 10.1142/S0219467823500171
   Suresh S, 2020, NEURAL COMPUT APPL, V32, P15989, DOI 10.1007/s00521-020-04787-w
   Tripathi P, 2019, PATTERN RECOGN IMAGE, V29, P167, DOI 10.1134/S105466181901019X
   Wang Q, 2022, NEURAL COMPUT APPL, V34, P18881, DOI 10.1007/s00521-022-07481-1
   Wu YT, 2008, PATTERN RECOGN, V41, P1948, DOI 10.1016/j.patcog.2007.11.020
   Xin-She Yang, 2010, International Journal of Mathematical Modelling and Numerical Optimisation, V1, P330, DOI 10.1504/IJMMNO.2010.035430
   Yu H, 2020, IEEE ACCESS, V8, P86400, DOI 10.1109/ACCESS.2020.2992645
   Zhao WG, 2022, COMPUT METHOD APPL M, V388, DOI 10.1016/j.cma.2021.114194
NR 36
TC 1
Z9 1
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 15
PY 2023
DI 10.1007/s11042-023-17570-5
EA NOV 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8YK4
UT WOS:001101241300006
DA 2024-07-18
ER

PT J
AU Oza, RS
   Mehta, MA
   Kotecha, K
   Lin, JCW
AF Oza, Rachana S.
   Mehta, Mayuri A.
   Kotecha, Ketan
   Lin, Jerry Chun-Wei
TI Analytics of deep model-based spatiotemporal and spatial feature
   learning methods for surgical action classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Surgical action classification; Spatial features; Spatiotemporal
   features; Classification; Convolutional neural network
ID RECOGNITION; SEGMENTATION; VIDEOS
AB Classification of surgical actions from a real anatomy video sequence is a challenging task due to limited visibility, poorer lighting conditions, lower contrast, and obscured frames of a video sequence. Several deep model-based spatiotemporal and spatial feature learning methods have been presented to classify surgical actions. However, some of the methods have been evaluated on synthetic data due to unavailability of sufficient labeled data. Conversely, some methods have been evaluated on a real anatomy dataset, but produce lower accuracy. Therefore, in this paper, first we analyze the effects of both feature learning methods on surgical action classificaiton from a real anatomy dataset. Thereafter, we propose new methods to enhance surgical action classification. Specific contributions in this paper are as follows. First, two novel deep model-based spatiotemporal feature learning methods are proposed to classify surgical actions. Second, a hypothesis is proposed, stating that the elimination of spatiotemporal features does not affect the performance of the method. Third, to test the proposed hypothesis, a spatial feature learning method comprised of a unique custom Convolutional Neural Network (CNN) is also proposed. Fourth, performance analysis of the proposed spatiotemporal and spatial feature learning methods is presented using a real anatomy Surgical Actions 160 dataset. The experimental results demonstrate that the MobileNetV2-based spatial feature learning method achieves the highest accuracy of 97% in classifying surgical actions. It outperforms the other pre-trained CNN models significantly. Additionally, MobileNetV2 exhibits lower training time.
C1 [Oza, Rachana S.] Gujarat Technol Univ, Dept Comp IT Engn, Ahmadabad, Gujarat, India.
   [Mehta, Mayuri A.] Sarvajanik Coll Engn & Technol, Dept Comp Engn, Surat, India.
   [Kotecha, Ketan] Symbiosis Int, Symbiosis Ctr Appl Artificial Intelligence, Pune, Maharashtra, India.
   [Lin, Jerry Chun-Wei] Silesian Tech Univ, Fac Automat Control Elect & Comp Sci, Gliwice, Poland.
C3 Gujarat Technological University; Sarvajanik College of Engineering &
   Technology; Symbiosis International University; Silesian University of
   Technology
RP Oza, RS (corresponding author), Gujarat Technol Univ, Dept Comp IT Engn, Ahmadabad, Gujarat, India.
EM rachana.oza@scet.ac.in
RI Kotecha, Ketan/U-3927-2017
OI Oza, Rachana/0000-0001-8159-4055
CR Ahmidi N, 2017, IEEE T BIO-MED ENG, V64, P2025, DOI 10.1109/TBME.2016.2647680
   Bao H., 2022, BEiT: BERT Pre-Training of Image Transformers, DOI [DOI 10.48550/ARXIV.2106.08254, 10 . 48550/ARXIV.2106.08254, 10.48550/arXiv.2106.08254]
   Bichlmeier C, 2008, INT SYM MIX AUGMENT, P165, DOI 10.1109/ISMAR.2008.4637348
   Bramhe S, 2022, CUREUS J MED SCIENCE, V14, DOI 10.7759/cureus.29179
   Chao Z, 2023, MULTIMED TOOLS APPL, V82, P26971, DOI 10.1007/s11042-023-14990-1
   Chen YW, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0316-4
   Cheng K, 2022, SURG ENDOSC, V36, P3160, DOI 10.1007/s00464-021-08619-3
   Chittajallu DR, 2019, I S BIOMED IMAGING, P66, DOI [10.1109/ISBI.2019.8759428, 10.1109/isbi.2019.8759428]
   Funke I, 2019, INT J COMPUT ASS RAD, V14, P1217, DOI 10.1007/s11548-019-01995-1
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gao Y, 2014, P MOD MON COMP ASS I
   Garrow CR, 2021, ANN SURG, V273, P684, DOI 10.1097/SLA.0000000000004425
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Z., 2022, Machine Learn Health PMLR, P356
   Pham H, 2021, PROC CVPR IEEE, P11552, DOI 10.1109/CVPR46437.2021.01139
   Hou YQ, 2022, NEURAL COMPUT APPL, V34, P1577, DOI 10.1007/s00521-021-06368-x
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Janocha K, 2017, Arxiv, DOI [arXiv:1702.05659, DOI 10.4467/20838476SI.16.004.6185]
   Jin YM, 2018, IEEE T MED IMAGING, V37, P1114, DOI 10.1109/TMI.2017.2787657
   Katsuno H, 2020, SURG TODAY, V50, P240, DOI 10.1007/s00595-019-01874-x
   Khalid S, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.1664
   Khatibi T, 2020, MULTIMED TOOLS APPL, V79, P30111, DOI 10.1007/s11042-020-09540-y
   Kitaguchi D, 2020, SURG ENDOSC, V34, P4924, DOI 10.1007/s00464-019-07281-0
   Kolesnikov Alexander, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P491, DOI 10.1007/978-3-030-58558-7_29
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lavanchy JL, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84295-6
   Manoucheri E, 2014, J MINIM INVAS GYN, V21, P592, DOI 10.1016/j.jmig.2013.12.122
   Menon S., 2017, "Workflow Recognition in Cholesystectomy Videos", CS230: Deep Learning
   Morita S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-53091-8
   Namazi B, 2022, SURG ENDOSC, V36, P679, DOI 10.1007/s00464-021-08336-x
   Nwoye CI, 2022, Arxiv, DOI arXiv:2204.04746
   Nwoye CI, 2022, MED IMAGE ANAL, V78, DOI 10.1016/j.media.2022.102433
   Park J, 2021, IEEE ROBOT AUTOM LET, V6, P2365, DOI 10.1109/LRA.2021.3060410
   Patrini I, 2020, MED BIOL ENG COMPUT, V58, P1225, DOI 10.1007/s11517-020-02127-7
   Rimmer L, 2021, EUR J TRAUMA EMERG S, V47, P757, DOI 10.1007/s00068-020-01444-8
   Schoeffmann K, 2018, MULTIMED TOOLS APPL, V77, P16813, DOI 10.1007/s11042-017-5252-2
   Shi XY, 2020, INT J COMPUT ASS RAD, V15, P1573, DOI 10.1007/s11548-020-02198-9
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun YW, 2021, IEEE ROBOT AUTOM LET, V6, P3870, DOI 10.1109/LRA.2021.3066956
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tsuda OYK., 2019, Springer, DOI [10.1007/978-3-319-96866-7, DOI 10.1007/978-3-319-96866-7]
   Yang CM, 2020, COMPUT ASSIST SURG, V25, P15, DOI 10.1080/24699322.2020.1801842
   Zadeh SM, 2020, SURG ENDOSC, V34, P5377, DOI 10.1007/s00464-019-07330-8
   Zhang BK, 2021, INT J COMPUT ASS RAD, V16, P2029, DOI 10.1007/s11548-021-02473-3
   Zhao Y, 2020, MED BIOL ENG COMPUT, V58, P871, DOI 10.1007/s11517-020-02143-7
   Zia A, 2018, LECT NOTES COMPUT SC, V11073, P273, DOI 10.1007/978-3-030-00937-3_32
NR 47
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 14
PY 2023
DI 10.1007/s11042-023-17344-z
EA NOV 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JF3O4
UT WOS:001171713900005
DA 2024-07-18
ER

PT J
AU Korany, NO
   Elboghdadly, NM
   Elabdein, MZ
AF Korany, Noha O.
   Elboghdadly, Namat M.
   Elabdein, Mohamed Z.
TI High capacity, secure audio watermarking technique integrating spread
   spectrum and linear predictive coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Watermarking; Spread Spectrum (SS); Fast Fourier Transform (FFT);
   Discrete Wavelet Packet Transform (DWPT); Psychoacoustic Model (PM);
   Imperceptibility; Robustness
ID HARMONIC FOURIER MOMENTS; IMAGE
AB This paper introduces a method adjustable audio watermarking approach with high auditory quality by exploiting the Spread Spectrum (SS) and the psychoacoustic modeling-based Discrete Wavelet Packet Transform (DWPT). The psychoacoustic model is used to shape the amplitude of the watermark signal during the embedding phase, ensuring a high level of imperceptibility. The approach based DWPT carefully mimics the multi- resolution properties of the human ear and incorporates simultaneous and temporal auditory masking. This paper aims to increase data payload and security. The watermark bits positions in the watermarking domain are determined by the logistic chaotic map in a random manner ensuring a high security level. The watermark used is an audio signal in parametric representation using Linear Predictive Coding (LPC) to accomplish a higher data payload. The LPC technique predicts a small number of coefficients, which represent different speech parameters, that are then applied in digital filters to create a synthetic version of the original speech signal. Various host audio signals are examined under various watermarking threats to assess the performance of the watermarking system. Experimental results expose that the introduced scheme provides a good measure of imperceptibility and robustness which are evaluated by the Objective Difference Grade (ODG) and the Bit Error Rate (BER%) respectively. The ODG's values were between -0.74 and -2.75, while the BER was in the range of 0 to 7.54%. The comparison introduced between the standard psychoacoustic model-1 (Standard PM) and the enhanced psychoacoustic model-1 based DWPT (Enhanced PM) for audio watermarking shows that Enhanced PM enhances the status of insufficient time-frequency resolution. A comparison of the proposed method to other state-of-the-art audio watermarking algorithms shows that it is a feasible alternative.
C1 [Korany, Noha O.; Elboghdadly, Namat M.] Fac Engn, Elect Engn Dept, Alexandria 11865, Egypt.
   [Elabdein, Mohamed Z.] Alexandria Higher Inst Engn & Technol, Elect Engn Dept, Alexandria 11865, Egypt.
RP Elabdein, MZ (corresponding author), Alexandria Higher Inst Engn & Technol, Elect Engn Dept, Alexandria 11865, Egypt.
EM nokorany@hotmail.com; nemat.boghdadly@alexu.edu.eg;
   muhamed.zain90@gmail.com
RI Z Elabdein, Mohamed/JXN-7499-2024
OI Z Elabdein, Mohamed/0000-0003-2263-2597
CR Ahmad M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0123-1
   Ali Y.M., 2022, IJEECS, V28, P753
   Astuti Y, 2020, 2020 3 INT SEMINAR R
   Attari AA., 2018, Int J Electron Commun Eng, V12, P145
   Begum M, 2022, J KING SAUD UNIV-COM, V34, P5856, DOI 10.1016/j.jksuci.2021.07.012
   Bellaaj M, 2020, MULTIMED TOOLS APPL, V79, P27161, DOI 10.1007/s11042-020-09338-y
   Birkholz P, 2019, J ACOUST SOC AM, V146, P223, DOI 10.1121/1.5116137
   Breed G., 2003, High Frequency Electronics, P46
   Chen A, 2010, 2010 3 INT C IM SIGN
   [陈志刚 Chen Zhigang], 2016, [电子与信息学报, Journal of Electronics & Information Technology], V38, P1547
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   El-Khamy SE, 2018, 2018 35 NATL RADIO S
   Ghido F, 2013, IEEE T AUDIO SPEECH, V21, P12, DOI 10.1109/TASL.2012.2211014
   Hamid OK, 2017, signal 1: 5
   He X, 2006, J FRANKLIN I, V343, P738, DOI 10.1016/j.jfranklin.2006.07.005
   Hemis M, 2018, MULTIMED TOOLS APPL, V77, P11693, DOI 10.1007/s11042-017-4813-8
   Herre J, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9142854
   Hu HT, 2014, DIGIT SIGNAL PROCESS, V31, P115, DOI 10.1016/j.dsp.2014.04.014
   Isoyama T, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24050677
   Jabbar Z J, 2022, J Al-Qadisiyah Comput Sci Mathemat, V14, P55, DOI [10.29304/jqcm.2022.14.1.904, DOI 10.29304/JQCM.2022.14.1.904]
   Kim YG, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22093415
   Korany NO, 2021, Audio Watermarking Technique Integrating Spread Spectrum and CNN-autoencoder, P151
   Krimi S, 2007, IEEE INT C SETIT 200
   Kumaraswamy E, 2020, IOP Conference Series: Materials Science and Engineering, V981
   Kundur D, 2001, IEEE T SIGNAL PROCES, V49, P2383, DOI 10.1109/78.950793
   Kundur D, 1999, PROC ACM WORKSHOP MU, V99
   Lagerstrom K, 2001, Design and implementation of an MPEG-1 layer III audio decoder
   Liang XY, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107584
   Lim TY, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P646, DOI 10.1109/ICASSP.2018.8462049
   Lin W., 2015, AUDIO WATERMARK COMP, P15, DOI DOI 10.1007/978-3-319-07974-5
   Liu X, 2020, P AAAI C ARTIFICIAL, V34
   Malik H, 2008, IET INFORM SECUR, V2, P129, DOI 10.1049/iet-ifs:20070145
   Mohamed AG, 2021, IEEE ACCESS, V9, P14284, DOI 10.1109/ACCESS.2021.3052161
   Panchal UH, 2015, INT CONF COMM SYST, P591, DOI 10.1109/CSNT.2015.165
   pixabay, About us
   Pourhashemi SM, 2021, NEURAL COMPUT APPL, V33, P6161, DOI 10.1007/s00521-020-05389-2
   Salah E, 2021, APPL ACOUST, V172, DOI 10.1016/j.apacoust.2020.107652
   Salau Ayodeji Olalekan, 2019, 2019 International Conference on Signal Processing and Communication (ICSC), P158
   Sharma N, 2021, COMPUTING, V103, P1883, DOI 10.1007/s00607-020-00881-y
   Spanias A, 2022, Analysis of the MPEG-1 Layer III (MP3) Algorithm using MATLAB
   Thiede T, 2000, J AUDIO ENG SOC, V48, P3
   uic, US
   Wang C., 2018, J Inform Process Syst, V14, P3
   Wang CP, 2016, J VIS COMMUN IMAGE R, V41, P247, DOI 10.1016/j.jvcir.2016.10.004
   Wang CP, 2016, SIGNAL PROCESS-IMAGE, V45, P10, DOI 10.1016/j.image.2016.03.007
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang CP, 2018, INFORM SCIENCES, V450, P141, DOI 10.1016/j.ins.2018.03.040
   Wang CP, 2017, SIGNAL PROCESS, V134, P197, DOI 10.1016/j.sigpro.2016.12.010
   Wang XY, 2009, PATTERN RECOGN, V42, P3057, DOI 10.1016/j.patcog.2009.01.015
   Xia ZQ, 2021, DIGIT SIGNAL PROCESS, V116, DOI 10.1016/j.dsp.2021.103130
   Xia ZQ, 2022, APPL INTELL, V52, P607, DOI 10.1007/s10489-021-02476-2
   Xia ZQ, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2020.106568
   Xia ZQ, 2021, SIGNAL PROCESS, V180, DOI 10.1016/j.sigpro.2020.107864
   Xia ZQ, 2019, SIGNAL PROCESS, V164, P368, DOI 10.1016/j.sigpro.2019.06.025
   Xia ZQ, 2019, SIGNAL PROCESS, V157, P108, DOI 10.1016/j.sigpro.2018.11.011
   Xiang Y, 2015, IEEE-ACM T AUDIO SPE, V23, P2228, DOI 10.1109/TASLP.2015.2476755
   [熊晓军 Xiong Xiaojun], 2018, [地球物理学进展, Progress in Geophysiscs], V33, P1617
   Xue Y, 2019, DIGITAL FORENSICS WA
   You J, 2022, IEEE Trans Multimed
   Zailan MKN., 2023, ESTEEM Acad J, V19, P101, DOI [10.24191/esteem.v19iMarch.21337, DOI 10.24191/ESTEEM.V19IMARCH.21337]
   Zeyad T., 2005, Al-Khwarizmi Eng J, V1, P52
   Zhao X, 2010, STUD COMPUT INTELL, V282, P337
NR 63
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 8
PY 2023
DI 10.1007/s11042-023-17630-w
EA NOV 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8TR3
UT WOS:001101114600004
DA 2024-07-18
ER

PT J
AU Panchbhai, VV
   Varade, SW
AF Panchbhai, Vishal V.
   Varade, Suchita W.
TI Enhanced block based progressive visual secret sharing scheme for
   grayscale and color image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Visual cryptography; Progressive Visual Secret Sharing; Block based
   Progressive Visual Secret Sharing; OR based Visual Secret Sharing;
   Noise-like share generation; Meaningful share generation
ID CRYPTOGRAPHY SCHEME; ENCRYPTION; PICTURES; GRAY
AB Block by block, the secret image will be retrieved from user-friendly and noise-like shares in the Block Based Progressive Secret Sharing (BPVSS) scheme. The majority of existing BPVSS schemes had issues such as schemes that were not appropriate for grayscale and color secret image types, poor contrast in the rebuilt secret image, pixel expansion, more computational power and time required for post processing at the receiver side to recover the secret image, and some schemes that introduced blocking artifact in the rebuilt secret image. To solve the problems described above, we suggested a noise-like and meaningful share generation strategy based on BPVSS and the bit-slicing approach in this study. When compared to previous analogous systems, the proposed method exhibits several benefits, such as (1) it works for both color and grayscale secret images; (2) the contrast of both the rebuilt image and original secret image is exactly the same; (3) there is no pixel expansion issue; (4) the amount of time and computing power required to retrieve the secret image is very low; and (5) there is no blocking artifact issue. With the proposed algorithm for noise-like and meaningful share generation, the average time required to retrieve a secret image of size 256 x 384x3 is 0.1902s and 0.5399 s, respectively. Experimental results show that the suggested system gives better standard performance parameter readings than the BPVSS and Randomized Visual Secret Sharing (RVSS) schemes.
C1 [Panchbhai, Vishal V.; Varade, Suchita W.] Priyadarshini Coll Engn, Dept Elect & Telecommun Engn, Nagpur, Maharashtra, India.
RP Panchbhai, VV (corresponding author), Priyadarshini Coll Engn, Dept Elect & Telecommun Engn, Nagpur, Maharashtra, India.
EM vishal_panchbhai@rediffmail.com; swvarade@gmail.com
CR Ahmed Nisar, 2016, International Journal of Computer Network and Information Security, V8, P18, DOI 10.5815/ijcnis.2016.12.03
   [Anonymous], 2011, Univ South California Signal Image Process Inst
   Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Bao L, 2017, IEEE T IMAGE PROCESS, V26, P5618, DOI 10.1109/TIP.2017.2738561
   Chao HC, 2017, DISPLAYS, V49, P6, DOI 10.1016/j.displa.2017.05.004
   Chen SK, 2009, OPT ENG, V48, DOI 10.1117/1.3262345
   Cu DH, 2015, SIGNAL PROCESS, V108, P604, DOI 10.1016/j.sigpro.2014.10.011
   Fan TY, 2018, IET INFORM SECUR, V12, P398, DOI 10.1049/iet-ifs.2017.0546
   Fang Wen-Pinn, 2006, [Pattern Recognition and Image Analysis (Advances in Mathematical Theory and Applications), Pattern Recognition and Image Analysis. (Advances in Mathematical Theory and Applications)], V16, P632
   Fang WP, 2008, PATTERN RECOGN, V41, P1410, DOI 10.1016/j.patcog.2007.09.004
   Fu ZX, 2019, MULTIMED TOOLS APPL, V78, P2367, DOI 10.1007/s11042-018-6364-z
   Gonzalez Woods, ImageProcessingPlace.com
   Hou YC, 2013, INFORM SCIENCES, V233, P290, DOI 10.1016/j.ins.2013.01.006
   Hou YC, 2011, IEEE T CIRC SYST VID, V21, P1760, DOI 10.1109/TCSVT.2011.2106291
   Jia XX, 2019, MULTIMED TOOLS APPL, V78, P8207, DOI 10.1007/s11042-018-6779-6
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Kannojia SP, 2021, MULTIMED TOOLS APPL, V80, P14609, DOI 10.1007/s11042-020-10352-3
   Kite TD, 2000, IEEE T IMAGE PROCESS, V9, P1583, DOI 10.1109/83.862639
   Lee KH, 2013, IEEE T IMAGE PROCESS, V22, P3830, DOI 10.1109/TIP.2013.2262290
   Lee KH, 2012, IEEE T INF FOREN SEC, V7, P219, DOI 10.1109/TIFS.2011.2167611
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Liu F, 2010, Optimal XOR based (2,n)-Visual Cryptography Schemes
   Mese M, 2001, IEEE T IMAGE PROCESS, V10, P1566, DOI 10.1109/83.951541
   Mhala NC, 2021, VISUAL COMPUT, V37, P2097, DOI 10.1007/s00371-020-01972-9
   Mhala NC, 2018, IET IMAGE PROCESS, V12, P422, DOI 10.1049/iet-ipr.2017.0759
   Mohanasundaram A., 2022, Int J Intell Netw, V3, P109, DOI [10.1016/j.ijin.2022.08.004, DOI 10.1016/J.IJIN.2022.08.004]
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Panchbhai VV, 2020, BIOSCI BIOTECH RES C, V13, P268, DOI 10.21786/bbrc/13.14/63
   Panchbhai VV, 2022, 2022 10 INT C EM TRE, P1
   Prasetyo H, 2019, 2019 INT S ELECT SMA, P1
   Prasetyo H, 2019, 2019 5TH INTERNATIONAL CONFERENCE ON SCIENCE ININFORMATION TECHNOLOGY (ICSITECH), P49, DOI [10.1109/icsitech46713.2019.8987504, 10.1109/ICSITech46713.2019.8987504]
   Prasetyo H, 2019, MULTIMED TOOLS APPL, V78, P24837, DOI 10.1007/s11042-019-7710-5
   Shen G, 2017, MULTIMED TOOLS APPL, V76, P14511, DOI 10.1007/s11042-016-3867-3
   Shivani S, 2017, MULTIMED TOOLS APPL, V76, P8711, DOI 10.1007/s11042-016-3484-1
   Sridhar Srividhya, 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P0282, DOI 10.1109/ICCSP48568.2020.9182399
   Sridhar S, 2020, MULTIMED TOOLS APPL, V79, P11459, DOI 10.1007/s11042-019-08319-0
   Tan LD, 2020, MULTIMED TOOLS APPL, V79, P5719, DOI 10.1007/s11042-019-08351-0
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Wang RZ, 2009, IEEE SIGNAL PROC LET, V16, P659, DOI 10.1109/LSP.2009.2021334
   Wang RZ, 2007, 2 INT C INN COMP INF, P283
   Yan XH, 2018, MULTIMED TOOLS APPL, V77, P2653, DOI 10.1007/s11042-017-4421-7
   Yan XH, 2016, MULTIMED TOOLS APPL, V75, P8657, DOI 10.1007/s11042-015-2779-y
   Yang CN, 2016, THEOR COMPUT SCI, V609, P143, DOI 10.1016/j.tcs.2015.09.016
NR 43
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 7
PY 2023
DI 10.1007/s11042-023-17416-0
EA NOV 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3TF7
UT WOS:001097705200010
DA 2024-07-18
ER

PT J
AU Kanagaraj, S
   Hema, MS
   Guptha, MN
AF Kanagaraj, S.
   Hema, M. S.
   Guptha, M. Nageswara
TI Optimized supervised learning approach to predict Parkinson's disease
   with minimal attributes using PPMI Datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Parkinson's disease (PD); Machine learning; Normalization;
   Dimensionality reduction; Optimization algorithm
ID MDS-UPDRS; RATING-SCALE; NONMOTOR SYMPTOMS; MOTOR FUNCTION; VALIDATION;
   SEVERITY
AB Researchers can examine numerous ailments and forecast improved treatments using a huge number of medical databases. The Michael Fox PPMI data sets provide a baseline evaluation of the disease using the Unified Parkinson's Disease Rating Scales, the most prevalent sequential scales for identifying Parkinson's conditions. Existing research uses a Gaussian mixture model to predict PD disease using min-max normalization and dimensionality reduction based on principal component analysis. It significantly improved the findings, but it required more data to make predictions. This may be developed by decreasing the numbers of features utilized for prediction utilizing optimization algorithms. As a result, the ant-colony optimizations approach is suggested in this paper to enhance the classifier with few features. The ant colony approach uses this information to select the lowest features to use in training the regression neural network for disease prediction. When compared to various dimensionality reductions methods including Fast-ICA, PCAs, Kernel-PCA, as well as NMF, the findings suggest that the suggested optimization approaches performing-well. The neural regression network also reveals that the suggested strategy outperforms the Gaussian mixture model with the least patient information on the UPDRSs dataset.
C1 [Kanagaraj, S.] Kumaraguru Coll Technol, Dept Informat Technol, Coimbatore, India.
   [Hema, M. S.] Sri Venkateshwara Coll Engn, Dept Comp Sci & Engn, Vidya Nagar, Bengaluru 562157, Karnataka, India.
   [Guptha, M. Nageswara] Sri Venkateshwara Coll Engn, Vidya Nagar, Bengaluru 562157, Karnataka, India.
C3 Kumaraguru College of Technology
RP Kanagaraj, S (corresponding author), Kumaraguru Coll Technol, Dept Informat Technol, Coimbatore, India.
EM kanagarajsphd@gmail.com; hema.ms_ds@svcengg.edu.in; mnguptha@yahoo.Com
FU The Parkinsonapos;s Progression Markers Initiative (PPMI) is a
   collaborative effort between the public and business sectors. The
   Michael J. Fox Foundation for Parkinsonapos;s Research and its funding
   partners support PPMI. The PPMI database was utilized; Michael J. Fox
   Foundation for Parkinsonapos;s Research and its funding partners support
   PPMI
FX The Parkinson & apos;s Progression Markers Initiative (PPMI) is a
   collaborative effort between the public and business sectors. The
   Michael J. Fox Foundation for Parkinson & apos;s Research and its
   funding partners support PPMI. The PPMI database was utilized to get the
   information for this article.
CR Buongiorno D, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0987-5
   Vásquez-Correa JC, 2019, IEEE J BIOMED HEALTH, V23, P1618, DOI 10.1109/JBHI.2018.2866873
   Cernuda C, 2013, P 3 WORLD C INF TECH, V3, P7
   Dauer W, 2003, NEURON, V39, P889, DOI 10.1016/S0896-6273(03)00568-3
   Dinov ID, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157077
   Dorigo M., 2004, Ant colony optimization, DOI [10.7551/mitpress/1290.001.0001, DOI 10.7551/MITPRESS/1290.001.0001]
   Dorigo M, 2006, IEEE COMPUT INTELL M, V1, P28, DOI 10.1109/MCI.2006.329691
   Gallagher DA, 2012, MOVEMENT DISORD, V27, P79, DOI 10.1002/mds.23939
   Gil-Martín M, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8080907
   Goetz CG, 2003, MOVEMENT DISORD, V18, P738, DOI 10.1002/mds.10473
   Goetz CG, 2002, MOVEMENT DISORD, V17, P283, DOI 10.1002/mds.10024
   Huo WG, 2020, IEEE T NEUR SYS REH, V28, P1397, DOI 10.1109/TNSRE.2020.2978197
   Jane YN, 2016, J BIOMED INFORM, V60, P169, DOI 10.1016/j.jbi.2016.01.014
   Jankovic J, 2008, J NEUROL NEUROSUR PS, V79, P368, DOI 10.1136/jnnp.2007.131045
   Kanagaraj S, 2020, Oxidation Communications, V43
   Kaur H, 2020, NEURAL COMPUT APPL, V32, P12697, DOI 10.1007/s00521-020-04720-1
   Kleinholdermann U, 2021, CLIN NEUROPHYSIOL, V132, P1708, DOI 10.1016/j.clinph.2021.01.031
   Kshirsagar PR, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/2345600
   Lee W, 2016, J PARKINSON DIS, V6, P371, DOI 10.3233/JPD-150708
   Martinez-Martin P, 2015, EUR J NEUROL, V22, P37, DOI 10.1111/ene.12165
   Matarazzo M, 2019, MOVEMENT DISORD, V34, P1488, DOI 10.1002/mds.27772
   Mohana J, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/1892123
   Nilashi M, 2018, BIOCYBERN BIOMED ENG, V38, P1, DOI 10.1016/j.bbe.2017.09.002
   Parisi L, 2018, EXPERT SYST APPL, V110, P182, DOI 10.1016/j.eswa.2018.06.003
   Piro NE, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060930
   Prashanth R, 2018, NEUROCOMPUTING, V305, P78, DOI 10.1016/j.neucom.2018.04.049
   Raciti L, 2016, PARKINSONISM RELAT D, V27, P98, DOI 10.1016/j.parkreldis.2016.03.008
   Raza M, 2021, IEEE J SEL AREA COMM, V39, P593, DOI 10.1109/JSAC.2020.3021571
   Rehman RZU, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19245363
   Rita W, 2016, J PARKINSON DIS, V6, P257, DOI 10.3233/JPD-150726
   Salmanpour MR, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103347
   Samà A, 2017, COMPUT BIOL MED, V84, P114, DOI 10.1016/j.compbiomed.2017.03.020
   Sarankumar R, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/7223197
   Skorvanek M, 2015, J NEUROL SCI, V353, P87, DOI 10.1016/j.jns.2015.04.013
   Thomas I, 2018, IEEE J BIOMED HEALTH, V22, P1341, DOI 10.1109/JBHI.2017.2777926
   Vivar G, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092072
   Wan SH, 2018, IEEE ACCESS, V6, P36825, DOI 10.1109/ACCESS.2018.2851382
NR 37
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17582-1
EA NOV 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500009
DA 2024-07-18
ER

PT J
AU Wu, C
   Gao, YK
   Li, G
   Shi, CF
AF Wu, Chao
   Gao, Yakun
   Li, Guang
   Shi, Chunfeng
TI Encoding learning network combined with feature similarity constraints
   for human action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Extreme learning machine (ELM); Feature encoding; Similarity constraint;
   Human action recognition
ID MACHINE
AB Extreme learning machine (ELM) is a fast and efficient classifier. Due to the inability to process descriptor-level features extracted from video sequences, the networks based on ELM cannot be directly used to recognize human actions. Encoding learning network (ELN) is proposed to solve this problem. The network is composed of feature encoding module and double similarity-constrained extreme learning machine (DS-ELM). In feature encoding module, the sparse mapping weight matrix is combined with pyramid pooling to generate representation-level features. DS-ELM is used to classify generated features. In order to utilize the similarity information between the features of each layer, different weight matrices in ELN are separately trained to improve the recognition ability. In the training of sparse mapping weight matrix, the auto-encoded dictionary and similarity constrained linear coding (SCLC) method are proposed to encode the desired output. The sparse mapping weight matrix is trained by using partial descriptor features and corresponding desired outputs. In the training of the classification weights, the ELM objective function is updated by similarity relationship between hidden layer features to derive the training formula of DS-ELM, which improves the classification performance while avoiding iterative training. To verify the feasibility of the ELN, experiments are conducted on Olympic Sports, UCF11, Hollywood2, UCF101, and Self-collection databases. Experimental results show that the proposed ELN is able to directly process descriptor features. And, the similarity information between the features of each layer can be further utilized by ELN to obtain excellent recognition performance compared with other improved methods based on ELM.
C1 [Wu, Chao; Gao, Yakun; Li, Guang; Shi, Chunfeng] Henan Inst Technol, Sch Elect Engn & Automat, Xinxiang 453003, Peoples R China.
C3 Henan Institute of Technology
RP Gao, YK (corresponding author), Henan Inst Technol, Sch Elect Engn & Automat, Xinxiang 453003, Peoples R China.
EM yddqa311@163.com
CR Afza F, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104090
   Ahmad W, 2023, ALEX ENG J, V73, P771, DOI 10.1016/j.aej.2023.04.062
   Albtoush A, 2022, NEURAL COMPUT APPL, V34, P5923, DOI 10.1007/s00521-021-06727-8
   Alitaleshi A, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-022-03777-1
   Cai YM, 2021, NEUROCOMPUTING, V434, P21, DOI 10.1016/j.neucom.2020.12.064
   Cao JW, 2021, IEEE T NEUR NET LEAR, V32, P3748, DOI 10.1109/TNNLS.2020.3015356
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Crasto N, 2019, PROC CVPR IEEE, P7874, DOI 10.1109/CVPR.2019.00807
   Dai C, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105820
   Deng ZW, 2023, IEEE SENS J, V23, P7397, DOI 10.1109/JSEN.2023.3246133
   Ding XJ, 2022, J FRANKLIN I, V359, P1713, DOI 10.1016/j.jfranklin.2021.12.005
   Feichtenhofer C, 2020, PROC CVPR IEEE, P200, DOI 10.1109/CVPR42600.2020.00028
   Gao Q, 2022, IEEE SENS J, V22, P17421, DOI 10.1109/JSEN.2021.3059685
   Giveki D, 2021, MULTIMED TOOLS APPL, V80, P1223, DOI 10.1007/s11042-020-09759-9
   Gu FW, 2023, MULTIMED TOOLS APPL, V82, P40761, DOI 10.1007/s11042-023-15168-5
   He DW, 2020, J MED BIOL ENG, V40, P473, DOI 10.1007/s40846-020-00532-9
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Iosifidis A, 2016, IEEE T CYBERNETICS, V46, P311, DOI 10.1109/TCYB.2015.2401973
   Kalfaoglu M. Esat, 2020, Proceedings of the 16th European Conference on Computer Vision (ECCV 2020) Workshops. Lecture Notes in Computer Science (LNCS 12539), P731, DOI 10.1007/978-3-030-68238-5_48
   Kasun LLC, 2013, IEEE INTELL SYST, V28, P31
   Kim DH, 2021, IEEE ACCESS, V9, P39218, DOI 10.1109/ACCESS.2021.3064934
   Kiruba K, 2019, COGN SYST RES, V58, P71, DOI 10.1016/j.cogsys.2019.03.001
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Leyva R, 2019, IEEE T IMAGE PROCESS, V28, P6169, DOI 10.1109/TIP.2019.2922826
   Li GQ, 2014, NEURAL COMPUT APPL, V24, P1683, DOI 10.1007/s00521-013-1398-7
   Li P, 2016, NEUROCOMPUTING, V184, P36, DOI 10.1016/j.neucom.2015.07.136
   Li Q, 2019, COMPUT SCI ENG, V21, P26, DOI 10.1109/MCSE.2018.108164708
   Lin B, 2019, NEUROCOMPUTING, V348, P145, DOI 10.1016/j.neucom.2018.05.121
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Liu LQ, 2011, IEEE I CONF COMP VIS, P2486, DOI 10.1109/ICCV.2011.6126534
   Liu TY, 2022, INFORM SCIENCES, V606, P864, DOI 10.1016/j.ins.2022.05.092
   Majd M, 2020, NEUROCOMPUTING, V396, P224, DOI 10.1016/j.neucom.2018.10.095
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Min MC, 2021, J SYST ENG ELECTRON, V32, P209, DOI 10.23919/JSEE.2021.000018
   Moreira TP, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102771
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   Nooruddin S, 2023, INFORM FUSION, V100, DOI 10.1016/j.inffus.2023.101953
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Preeti, 2021, APPL INTELL, V51, P1669, DOI 10.1007/s10489-020-01890-2
   Quan YH, 2019, COMPUT VIS IMAGE UND, V187, DOI 10.1016/j.cviu.2019.102794
   Rezaei-Ravari M, 2021, ENG APPL ARTIF INTEL, V97, DOI 10.1016/j.engappai.2020.104062
   Sargano AB, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7010110
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shrinivasa SR, 2022, MULTIMED TOOLS APPL, V81, P1237, DOI 10.1007/s11042-021-11354-5
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sun QR, 2016, NEUROCOMPUTING, V174, P722, DOI 10.1016/j.neucom.2015.09.074
   Tian Y, 2018, IEEE T IMAGE PROCESS, V27, P1748, DOI 10.1109/TIP.2017.2788196
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2019, IEEE T PATTERN ANAL, V41, P2740, DOI 10.1109/TPAMI.2018.2868668
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xing HJ, 2013, NEURAL COMPUT APPL, V23, P1977, DOI 10.1007/s00521-012-1184-y
   Xu Y, 2020, IEEE ACCESS, V8, P167236, DOI 10.1109/ACCESS.2020.3023031
   Xu Y, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0234144
   Yahia S, 2022, NEUROCOMPUTING, V470, P280, DOI 10.1016/j.neucom.2020.04.158
   Yang G, 2022, MULTIMED TOOLS APPL, V81, P9875, DOI 10.1007/s11042-022-11937-w
   Yang XM, 2023, IMAGE VISION COMPUT, V137, DOI 10.1016/j.imavis.2023.104765
   Yuan C, 2021, KNOWL-BASED SYST, V214, DOI 10.1016/j.knosys.2020.106707
   Yuan D, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3266837
   Zhang BB, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107167
   Zhang CL, 2022, APPL INTELL, V52, P12771, DOI 10.1007/s10489-021-03068-w
   Zong M, 2021, IMAGE VISION COMPUT, V107, DOI 10.1016/j.imavis.2021.104108
NR 66
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17424-0
EA NOV 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500034
DA 2024-07-18
ER

PT J
AU Castillo, JR
   Flores, MJ
   Leray, P
AF Castillo, Jaime Ramirez
   Flores, M. Julia
   Leray, Philippe
TI Predicting spotify audio features from Last.fm tags
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Music information retrieval; Artificial intelligence
AB Music information retrieval (MIR) is an interdisciplinary research field that focuses on the extraction, processing, and knowledge discovery of information contained in music. While previous studies have utilized Spotify audio features and Last.fm tags as input values for classification tasks, such as music genre recognition, their potential as target values has remained unexplored. In this article, we address this notable gap in the research landscape by proposing a novel approach to predict Spotify audio features based on a set of Last.fm tags. By predicting audio features, we aim to explore the relationship between subjective perception and concrete musical features, shedding light on patterns and hidden correlations between how music is perceived, consumed, and discovered. Additionally, the predicted audio features can be leveraged in recommendation systems to provide users with explainable recommendations, bridging the gap between algorithmic suggestions and user understanding. Our experiments involve training models such as GPT-2, XGBRegressor, and Bayesian Ridge regressor to predict Spotify audio features from Last.fm tags. Through our findings, we contribute to the advancement of MIR research by demonstrating the potential of Last.fm tags as target values and paving the way for future research on the connection between subjective and objective music characterization. Our approach holds promise for both listeners and researchers, offering new insights into the intricate relationship between perception and audio signal in music. Our study aims to explore the feasibility and efficacy of this unique approach, where we intentionally refrain from using traditional audio-based or metadata-driven methods.
C1 [Castillo, Jaime Ramirez; Flores, M. Julia] Univ Castilla La Mancha, Dept Sistemas Informat, Campus Univ S-N, Albacete 02071, Spain.
   [Leray, Philippe] Univ Nantes, Ctr Natl Rech Sci, Lab Sci Numer Nantes, Nantes, France.
C3 Universidad de Castilla-La Mancha; Centre National de la Recherche
   Scientifique (CNRS); Nantes Universite
RP Flores, MJ (corresponding author), Univ Castilla La Mancha, Dept Sistemas Informat, Campus Univ S-N, Albacete 02071, Spain.
EM Jaime.Ramirez@alu.uclm.es; Julia.Flores@uclm.es
RI Flores, M. Julia/E-8526-2016
OI Flores, M. Julia/0000-0001-6956-3184
FU This work has been partially funded by the Government of Castilla - La
   Mancha (SBPLY/21/180225/000062) and by the Spanish Government
   (PID2022-139293NB-C32 and PID2019-106758GB-C33 funded by
   MCIN/AEI/10.13039/501100011033), and also by the UCLM (University
   [SBPLY/21/180225/000062]; Government of Castilla - La Mancha
   [PID2022-139293NB-C32, PID2019-106758GB-C33,
   MCIN/AEI/10.13039/501100011033]; Spanish Government; UCLM (University of
   Castilla-La Mancha) [2023-GRIN-34437]; ERDF A way of making Europe
FX This work has been partially funded by the Government of Castilla - La
   Mancha (SBPLY/21/180225/000062) and by the Spanish Government
   (PID2022-139293NB-C32 and PID2019-106758GB-C33 funded by
   MCIN/AEI/10.13039/501100011033), and also by the UCLM (University of
   Castilla-La Mancha) and "ERDF A way of making Europe" (2023-GRIN-34437).
CR [Anonymous], 2017, Computer Science & Information Technology (CS & IT), DOI DOI 10.5121/CSIT.2017.70603
   Benzi K, 2016, INT CONF ACOUST SPEE, P2439, DOI 10.1109/ICASSP.2016.7472115
   Bertin-Mahieux T., 2011, ISMIR, P591
   Bodó Z, 2018, ACTA U SAPIEN INFORM, V10, P158, DOI 10.2478/ausi-2018-0009
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Eck D., 2007, P INT C MUSIC INFORM, P367
   Jamdar A., 2015, INT J ARTIF INTELL E, V6, P35, DOI [10.5121/ijaia.2015.6304, https://doi.org/10.48550/arXiv.1506.05012, DOI 10.5121/IJAIA.2015.6304]
   Laurier C., 2009, ISMIR, P381
   Panda R., 2021, 18 SOUND MUS COMP C, P238, DOI DOI 10.5281/ZENODO.5045100
   Pinter AT., 2020, Proceedings of the International AAAI Conference on Web and Social Media, V14, P895, DOI [10.1609/icwsm.v14i1.7355, DOI 10.1609/ICWSM.V14I1.7355]
   Radford A., 2019, LANGUAGE MODELS ARE
   Ramirez J, 2022, 16 BAYES MOD APPL WO
   Ramírez J, 2020, J INTELL INF SYST, V55, P469, DOI 10.1007/s10844-019-00582-9
   Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236
   Wang Y., 2019, P INT AAAI C WEB SOC, V13, P517
NR 15
TC 1
Z9 1
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-17160-5
EA NOV 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X1LQ6
UT WOS:001096134900005
DA 2024-07-18
ER

PT J
AU Anagun, Y
AF Anagun, Yildiray
TI Smart brain tumor diagnosis system utilizing deep convolutional neural
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain Tumor; Diagnosis; Classification; MRI; Deep Learning; CNN
ID SEGMENTATION; CLASSIFICATION; CNN
AB The early diagnosis of cancer is crucial to provide prompt and adequate management of the diseases. Imaging tests, in particular magnetic resonance imaging (MRI), are the first preferred method for diagnosis. However, these tests have some limitations which can cause a delay in detection and diagnosis. The use of computer-aided intelligent systems can assist physicians in diagnosis. In this study, we established a Convolutional Neural Network (CNN)-based brain tumor diagnosis system using EfficientNetv2s architecture, which was improved with the Ranger optimization and extensive pre-processing. We also compared the proposed model with state-of-the-art deep learning architectures such as ResNet18, ResNet200d, and InceptionV4 in discriminating brain tumors based on their spatial features. We achieved the best micro-average results with 99.85% test accuracy, 99.89% Area under the Curve (AUC), 98.16% precision, 98.17% recall, and 98.21% f1-score. Furthermore, the experimental results of the improved model were compared to various CNN-based architectures using key performance metrics and were shown to have a strong impact on tumor categorization. The proposed system has been experimentally evaluated with different optimizers and compared with recent CNN architectures, on both augmented and original data. The results demonstrated a convincing performance in tumor detection and diagnosis.
C1 [Anagun, Yildiray] Eskisehir Osmangazi Univ, Dept Comp Engn, Eskisehir, Turkiye.
C3 Eskisehir Osmangazi University
RP Anagun, Y (corresponding author), Eskisehir Osmangazi Univ, Dept Comp Engn, Eskisehir, Turkiye.
EM yanagun@ogu.edu.tr
RI Anagun, Yildiray/AAH-6965-2021
OI Anagun, Yildiray/0000-0002-7743-0709
CR Abuhamad M, 2020, IEEE INTERNET THINGS, V7, P5008, DOI 10.1109/JIOT.2020.2975779
   Ahmad I, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11162514
   Abdelali HA, 2021, IEEE ACCESS, V9, P164282, DOI 10.1109/ACCESS.2021.3133529
   Alhassan AM, 2021, NEURAL COMPUT APPL, V33, P9075, DOI 10.1007/s00521-020-05671-3
   Ali Syed Imran, 2021, 2021 10th IEEE International Conference on Communication Systems and Network Technologies (CSNT), P639, DOI 10.1109/CSNT51715.2021.9509704
   Alok N, 2021, Mach. Learn. Healthc. Appl., P187, DOI DOI 10.1002/9781119792611.CH12
   Alqudah Ali Mohammad, 2020, arXiv
   Anjum S, 2022, INT J IMAG SYST TECH, V32, P307, DOI 10.1002/ima.22641
   Arunkumar N, 2019, SOFT COMPUT, V23, P9083, DOI 10.1007/s00500-018-3618-7
   Arunkumar N, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4962
   Badza MM, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10061999
   Banerjee S, 2019, LECT NOTES COMPUT SC, V11383, P170, DOI 10.1007/978-3-030-11723-8_17
   Brown CE, 2022, J TRANSL MED, V20, DOI 10.1186/s12967-022-03438-z
   Cabrera C, 2022, NEURAL COMPUT APPL, V34, P11035, DOI 10.1007/s00521-022-07029-3
   Chang K, 2017, Clin Cancer Res, V24, P5
   Cheng J, 2017, Dataset, DOI 10.6084002Fm9.figshare.1512427.v5
   Cheng J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140381
   COCHRAN WG, 1950, BIOMETRIKA, V37, P256, DOI 10.1093/biomet/37.3-4.256
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Ulloa CC, 2022, COMPUT ELECTRON AGR, V193, DOI 10.1016/j.compag.2022.106684
   Dabral I, 2021, Cancer detection using convolutional neural network, P290, DOI [10.1007/978-3-030-67187-7_30, DOI 10.1007/978-3-030-67187-7_30]
   Darbari A, 2021, CARDIOTHORAC SURG, V29, DOI 10.1186/s43057-021-00053-4
   Díaz-Pernas FJ, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9020153
   Frank Eibe, 2001, EUR C MACH LEARN, P145, DOI 10.1007/3-540-44795-413
   Fukuma R, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-56767-3
   Gupta RK, 2022, INTERDISCIP SCI, V14, P485, DOI 10.1007/s12539-022-00502-6
   Hamada A, 2020, Brain tumor detection
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heidari H, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116278
   Hossin M., 2015, INT J DATA MIN KNOWL, V5, P1, DOI DOI 10.5121/IJDKP.2015.5201
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang ML, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105604
   Husham S, 2022, Comparative Analysis between Active Contour and Otsu Thresholding Segmentation Algorithms in Segmenting Brain Tumor Magnetic Resonance Imaging
   Iriawan N, 2020, TELKOMNIKA (Telecommun. Comput. Electron. Control.), V18, P1310, DOI [10.12928/telkomnika.v18i3.14753, DOI 10.12928/TELKOMNIKA.V18I3.14753, 10.12928/TELKOMNIKA.v18i3.14753]
   Ji Z, 2021, IEEE T NEUR NET LEAR, V32, P1765, DOI 10.1109/TNNLS.2020.2991083
   Jia S, 2021, NEUROCOMPUTING, V448, P179, DOI 10.1016/j.neucom.2021.03.035
   Kan YY, 2019, J MAGN RESON IMAGING, V49, P304, DOI 10.1002/jmri.26209
   Kaur Taranjit, 2019, 2019 International Conference on Information Technology (ICIT), P94, DOI 10.1109/ICIT48102.2019.00023
   Kingma D. P., 2015, P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR, P1
   Kumar P., 2019, INT J RECENT TECHNOL, V8, P244
   Kumari Shreya, 2021, International Conference on Deep Learning, Artificial Intelligence and Robotics ICDLAIR 2019. Proceedings. Lecture Notes in Networks and Systems (LNNS 175), P339, DOI 10.1007/978-3-030-67187-7_35
   Lambin P, 2017, NAT REV CLIN ONCOL, V14, P749, DOI 10.1038/nrclinonc.2017.141
   Lim SC, 2022, ENERGIES, V15, DOI 10.3390/en15218233
   Liu DS, 2019, LECT NOTES COMPUT SC, V11953, P535, DOI 10.1007/978-3-030-36708-4_44
   Liu LY, 2021, Arxiv, DOI arXiv:1908.03265
   Liu SD, 2020, SCI REP-UK, V10, DOI [10.1038/s41598-020-64588-y, 10.1177/2158244020924052]
   Mansour RF, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104229
   Maurovich-Horvat P, 2019, JACC-CARDIOVASC IMAG, V12, P1377, DOI 10.1016/j.jcmg.2018.07.031
   Mekruksavanich S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21227519
   Muhammad K, 2021, IEEE T NEUR NET LEAR, V32, P507, DOI 10.1109/TNNLS.2020.2995800
   Negi A, 2021, Classification and detection of citrus diseases using deep learning, P23
   Negi A., 2022, Cyber-Physical Systems, P1
   Negi A., 2021, Agricultural Informatics: Automation using the IoT and Machine Learning, P117, DOI [10.1002/9781119769231.ch6, DOI 10.1002/9781119769231.CH6]
   Negi A, 2020, 2020 5TH IEEE INTERNATIONAL CONFERENCE ON RECENT ADVANCES AND INNOVATIONS IN ENGINEERING (IEEE - ICRAIE-2020), DOI 10.1109/ICRAIE51050.2020.9358337
   Pashaei A, 2018, 2018 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P314, DOI 10.1109/ICCKE.2018.8566571
   Rahman AU, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10020147
   Rajinikanth Venkatesan, 2022, 2022 Third International Conference on Intelligent Computing Instrumentation and Control Technologies (ICICICT), P987, DOI 10.1109/ICICICT54557.2022.9917904
   Ravishankar MV, 2022, J CLIN DIAGN RES, V16, pAD1, DOI 10.7860/JCDR/2022/51377.15889
   Sadad T, 2021, MICROSC RES TECHNIQ, V84, P1296, DOI 10.1002/jemt.23688
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Sarker MMK, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13010103
   Sifre L., 2014, arXiv
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stadlbauer A, 2022, CANCERS, V14, DOI 10.3390/cancers14102363
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2021, PR MACH LEARN RES, V139, P7102
   Tong QQ, 2022, NEUROCOMPUTING, V481, P333, DOI 10.1016/j.neucom.2022.01.014
   Wahid A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12094221
   Wong KCL, 2018, MED IMAGE ANAL, V49, P105, DOI 10.1016/j.media.2018.07.010
   Yu YY, 2022, IEEE T SYST MAN CY-S, V52, P1167, DOI 10.1109/TSMC.2020.3018757
   Zhang P, 2020, COMPUT ELECTRON AGR, V176, DOI 10.1016/j.compag.2020.105652
   Zhang YD, 2019, MULTIMED TOOLS APPL, V78, P3613, DOI 10.1007/s11042-017-5243-3
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 75
TC 9
Z9 9
U1 7
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44527
EP 44553
DI 10.1007/s11042-023-15422-w
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W3ZV0
UT WOS:001091051600001
PM 37362644
OA Bronze
DA 2024-07-18
ER

PT J
AU Ravinder, M
   Gupta, V
   Arora, K
   Ranjan, A
   Hu, YC
AF Ravinder, M.
   Gupta, Vaidehi
   Arora, Kanishka
   Ranjan, Arti
   Hu, Yu-Chen
TI Video-Captioning Evaluation Metric for Segments (VEMS): A Metric for
   Segment-level Evaluation of Video Captions with Weighted Frames
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video Captioning; Evaluation Metrics; BLEU; ROUGE; METEORO; CIDEr; MSVD;
   MSVD-S
AB Automated evaluation metrics for video captioning hold an important place in computer vision. Although some research has looked up in this direction, they produce subpar results or highlight the significance of a dataset with a certain domain. So far, evaluation metrics used in machine translation/ image captioning have been adapted for video captioning. At the same time, they don't give the desired result. This work intends to improve the performances of existing methods by proposing a new evaluation metric for the video captioning models. The proposed metric, Video-Captioning Evaluation Metric for Segments (VEMS), accounts for the main event, sub-actions, and background details. Thus VEMS evaluates captions at the segment level. A novel dataset structure called MSVD-S, a modified version of the MSVD dataset consisting of captions for multiple segments in a single video has also been proposed. Based on the MSVD-S dataset with weighted frames, VEMS captions to video in a frame-wise manner. Detailed performance analysis of the corner cases like the omission of actions, ignorance of sub-events, and lack of details has been done. The proposed metric provided improved performance as an evaluation score closer to an accuracy of 34.2% has been achieved.
C1 [Ravinder, M.; Gupta, Vaidehi; Arora, Kanishka; Ranjan, Arti] Indira Gandhi Delhi Tech Univ Women, Dept Comp Sci & Engn, Delhi, India.
   [Hu, Yu-Chen] TungHai Univ, Dept Comp Sci, 1727,Sec 4,Taiwan Blvd, Taichung 407224, Taiwan.
   [Hu, Yu-Chen] Providence Univ, Dept Comp Sci & Informat Management, 200,Sec 7,Taiwan Blvd, Taichung 43301, Taiwan.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW); Tunghai
   University; Providence University - Taiwan
RP Hu, YC (corresponding author), TungHai Univ, Dept Comp Sci, 1727,Sec 4,Taiwan Blvd, Taichung 407224, Taiwan.; Hu, YC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, 200,Sec 7,Taiwan Blvd, Taichung 43301, Taiwan.
EM ravinderm@igdtuw.ac.in; vaidehibhartiya@gmail.com;
   kanishka.arora24@gmail.com; arti.ranja@gmail.com; ychu@thu.edu.tw
OI Hu, Yu-Chen/0000-0002-5055-3645
CR Aafaq N, 2020, Arxiv, DOI arXiv:1806.00186
   Aafaq N, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3355390
   Aizawa A, 2003, INFORM PROCESS MANAG, V39, P45, DOI 10.1016/S0306-4573(02)00021-3
   Allen J., 1995, Natural Language Understanding
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   [Anonymous], 2016, PROC 24 ACM INT C MU, DOI [DOI 10.1145/2964284.2984065, 10.1145/2964284.2984065]
   Banerjee S., 2005, P WORKSHOP INTRINSIC, P65
   Chen D., 2011, P 49 ANN M ASS COMP, P190
   Chen H., 2020, arXiv
   Chen YY, 2018, Arxiv, DOI arXiv:1803.01457
   Chowdhury GG, 2003, ANNU REV INFORM SCI, V37, P51, DOI 10.1002/aris.1440370103
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Corley C.D., 2005, P ACL WORKSHOP EMPIR, P13, DOI [10.3115/1631862.1631865, DOI 10.3115/1631862.1631865]
   Cui Y, 2018, Arxiv, DOI arXiv:1806.06422
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121
   Das P, 2013, PROC CVPR IEEE, P2634, DOI 10.1109/CVPR.2013.340
   Deng J., 2009, Vision Sciences Society
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Ding D., 2012, 2 ACM INT C MULT RET
   Dong J., 2016, P 24 ACM INT C MULT
   Dong JF, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1082, DOI 10.1145/2964284.2984064
   Elliott D, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P452
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Fellbaum C., 1998, WORDNET, DOI [10.7551/mitpress/7287.001.0001, DOI 10.7551/MITPRESS/7287.001.0001]
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Felzenszwalb PF, 2010, PROC CVPR IEEE, P2241, DOI 10.1109/CVPR.2010.5539906
   Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Gella S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P968
   George A., 2017, P 17 ANN TREC VID RE
   Ghanem B, 2017, Arxiv, DOI arXiv:1710.08011
   github.com, About us
   Gong S., 2003, Computer Vision, P742, DOI DOI 10.1109/ICCV.2003.1238423
   Graham Y, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202789
   Graham Y, 2017, NAT LANG ENG, V23, P3, DOI 10.1017/S1351324915000339
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Guadarrama S., 2013, IEEE ICCV
   Guadarrama S, 2013, IEEE INT C INT ROBOT, P1640, DOI 10.1109/IROS.2013.6696569
   Hakeem A, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P263
   Han L., 2013, P 2 JOINT C LEX COMP, V1, P44
   Hanckmann P., 2012, The European Conference on Computer Vision (ECCV)
   Harwath D., 2018, The European Conference on Computer Vision (ECCV)
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hodosh M., 2016, P 5 WORKSH VIS LANG, P19
   Hongeng S, 2000, INT C PATT RECOG, P164, DOI 10.1109/ICPR.2000.905296
   Hudson D.A., 2018, INT C LEARN REPR ICL
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215
   Khan M. U. G., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1480, DOI 10.1109/ICCVW.2011.6130425
   Khan M.U. G., 2012, Workshop on Innovative Hybrid Approaches to the Processing of Textual Data, P27
   Kilickaya M, 2016, Arxiv, DOI arXiv:1612.07600
   Kim Jinkyu, 2018, The European Conference on Computer Vision (ECCV)
   Kondrak G, 2005, LECT NOTES COMPUT SC, V3772, P115
   Langkilde-Geary I., Halogen input representation
   Lebron L, 2022, Arxiv, DOI arXiv:2201.10243
   LUHN HP, 1957, IBM J RES DEV, V1, P309, DOI 10.1147/rd.14.0309
   M-VAD, Mila
   Malinowski M, 2014, ADV NEUR IN, V27
   Meng L., 2013, Int. J. Hybrid Inf. Technol, V6, P1
   Munková D, 2013, PROCEDIA COMPUT SCI, V18, P1198, DOI 10.1016/j.procs.2013.05.286
   Pan JY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1987, DOI 10.1109/ICME.2004.1394652
   Pan YW, 2017, PROC CVPR IEEE, P984, DOI 10.1109/CVPR.2017.111
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Park J, 2017, ICIIBMS 2017 TRACK 2
   Park J, 2017, INT CONF INTEL INFOR, P172, DOI 10.1109/ICIIBMS.2017.8279760
   Rohrbach M, 2013, IEEE I CONF COMP VIS, P433, DOI 10.1109/ICCV.2013.61
   Sharif N, 2019, INT J COMPUT VISION, V127, P1586, DOI 10.1007/s11263-019-01206-z
   Shen ZQ, 2017, PROC CVPR IEEE, P5159, DOI 10.1109/CVPR.2017.548
   Shetty R., 2016, P 24 ACM INT C MULTI, P1073
   SPARCKJONES K, 1972, J DOC, V28, P11, DOI 10.1108/eb026526
   Vedantam R, 2015, Arxiv, DOI arXiv:1411.5726
   Venugopalan S., 2015, NAACL-HTL Translating videos to natural language using deep recurrent neural networks
   Xiao HH, 2020, PATTERN RECOGN LETT, V129, P173, DOI 10.1016/j.patrec.2019.11.003
   Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571
   Yu HN, 2016, PROC CVPR IEEE, P4584, DOI 10.1109/CVPR.2016.496
   Zeng WJ, 2020, APSIPA TRANS SIGNAL, V9, DOI 10.1017/atsip.2019.26
NR 82
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 28
PY 2023
DI 10.1007/s11042-023-17328-z
EA OCT 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W7FP7
UT WOS:001093249700004
DA 2024-07-18
ER

PT J
AU Rajeshkumar, K
   Dhanasekaran, S
   Vasudevan, V
AF Rajeshkumar, K.
   Dhanasekaran, S.
   Vasudevan, V.
TI Efficient and secure medical big data management system using optimal
   map-reduce framework and deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cloud Computing; Big data; Hadoop Distributed File System; Blockchain;
   Map Reduce; Electronic Health Records; Encryption; and Decryption
ID HEALTH-CARE
AB Big Data (BD) and cloud computing (CC) are the two widely used technologies and focus of study in several industries. Amongst all, healthcare sources generate a tremendous amount of data daily. Traditional processing techniques cannot handle this data because they are huge. Furthermore, being large, this data is also dynamic and diverse. Large data sets are stored, processed, and analyzed under BD. However, as the volume of data increased, third parties could hack it easily. The data are regularly stored in the cloud in an encrypted form to protect the data from intruders. This paper proposes a secure and efficient medical BD management and classification scheme using optimal Map Reduce (MR) and deep learning framework in a cloud environment. The system comprises '4' phases: authentication of patients, BD management in the cloud, secure data transfer and BD classification. First, the patient who wants to upload the files to the cloud and access the resources from the cloud is registered with the TC. It generates hash value using the Whirlpool Hashing (WH) algorithm, and the user credentials are stored in Blockchain (BC) to protect the network from unauthorized access. Once the authentication is successful, the patient can access any data in the cloud. Before uploading the file to the cloud, the preprocessing is carried out using missing values imputation, numerical conversion, and normalization, which improves the data quality. It is fed into the MR framework using Kernelized K-Means (KKM) clustering and Enhanced Butterfly Optimization Algorithm (EBOA) for managing the data efficiently. Then the map-reduced data is encrypted using Whirlpool Hashing-based Enhanced Rivest Shamir Adelman (WHERSA) to upload into the cloud securely. Finally, the classification of BD is done using Enhanced Ant Colony Weight Optimization based Deep Belief Network (EACWODBN) for disease prediction. The experimental outcomes reveal that the proposed system outperformed state-of-art methods while offering effectual and secure data management.
C1 [Rajeshkumar, K.; Vasudevan, V.] Kalasalingam Acad Res & Educ, Dept Comp Sci & Engn, Krishnankoil, Tamil Nadu, India.
   [Dhanasekaran, S.] Kalasalingam Acad Res & Educ, Dept Informat Technol, Krishnankoil, Tamil Nadu, India.
C3 Kalasalingam Academy of Research & Education; Kalasalingam Academy of
   Research & Education
RP Rajeshkumar, K (corresponding author), Kalasalingam Acad Res & Educ, Dept Comp Sci & Engn, Krishnankoil, Tamil Nadu, India.
EM kumar85rajesh@gmail.com; srividhans@gmail.com; vasudevan_klu@yahoo.co.in
RI Subbiah, Dhanasekaran/ACE-3140-2022; K, Rajeshkumar/KHT-2196-2024
OI Subbiah, Dhanasekaran/0000-0002-5409-2057; K,
   Rajeshkumar/0000-0003-1646-5198
CR Abualigah L., 2021, Artificial Intelligence and IoT, P105
   Alabdulatif A, 2020, J PARALLEL DISTR COM, V137, P192, DOI 10.1016/j.jpdc.2019.10.008
   Alexandru A, 2016, management, V1
   Arora S, 2019, SOFT COMPUT, V23, P715, DOI 10.1007/s00500-018-3102-4
   Chen PT, 2020, INT J INFORM MANAGE, V53, DOI 10.1016/j.ijinfomgt.2020.102078
   Chen X, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbaa186
   Choi SY, 2020, PERS UBIQUIT COMPUT, V24, P571, DOI 10.1007/s00779-019-01230-3
   Dash S, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0217-0
   Deepa N., 2022, Future Generation Computer Systems
   Djemaiel Y, 2018, J GRID COMPUT, V16, P317, DOI 10.1007/s10723-018-9438-2
   Essa YM, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1250-4
   Farooqi MM, 2019, EAI SPRINGER INNOVAT, P143, DOI 10.1007/978-3-319-96139-2_14
   Game PS, 2019, Evol Intel, P1
   Gill SS, 2019, LECT NOTE DATA ENG, V26, P1376, DOI 10.1007/978-3-030-03146-6_161
   Gonzalez Ramirez Pedro Luis, 2018, 2018 5th International Conference on Computational Science and Computational Intelligence (CSCI), P996, DOI 10.1109/CSCI46756.2018.00193
   Gupta YK, 2020, ALGO INTELL SY, P19, DOI 10.1007/978-981-15-1100-4_2
   Harb H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071931
   Jagadeeswari V, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0049-x
   Jain P, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0193-4
   Khaleel MI., 2018, Kurdistan J Appl Res, V3, P20, DOI [10.24017/science.2018.3.4, DOI 10.24017/SCIENCE.2018.3.4]
   Khan M., 2019, INT J RECENT TECHNOL, V7, P413
   Kulkarni AJ., 2020, Big Data Analytics in Healthcare, DOI [10.1007/978-3-030-31672-3, DOI 10.1007/978-3-030-31672-3]
   Kulkarni O, 2020, J INTELL SYST, V29, P1496, DOI 10.1515/jisys-2018-0117
   Li JP, 2020, IEEE ACCESS, V8, P107562, DOI 10.1109/ACCESS.2020.3001149
   Lv ZH, 2020, FUTURE GENER COMP SY, V109, P103, DOI 10.1016/j.future.2020.03.039
   Masud M, 2021, PEER PEER NETW APPL, V14, P3043, DOI 10.1007/s12083-021-01162-x
   Mohamed A, 2020, ARTIF INTELL REV, V53, P989, DOI 10.1007/s10462-019-09685-9
   Mohan S, 2019, IEEE ACCESS, V7, P81542, DOI 10.1109/ACCESS.2019.2923707
   Mohiyuddin A, 2022, INT J FUZZY SYST, V24, P1203, DOI 10.1007/s40815-021-01104-y
   Namasudra S, 2020, COMPUT COMMUN, V151, P539, DOI 10.1016/j.comcom.2019.12.041
   Nguyen DC, 2019, IEEE ACCESS, V7, P66792, DOI 10.1109/ACCESS.2019.2917555
   Parthasarathy PR, 2019, Int J Innov Sci, Engin Technol, V6
   Premkamal PK, 2019, J AMB INTEL HUM COMP, V10, P2693, DOI 10.1007/s12652-018-0967-0
   Rajabion L, 2019, INT J INFORM MANAGE, V49, P271, DOI 10.1016/j.ijinfomgt.2019.05.017
   Rajendran S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-03019-y
   Ramachandra MN, 2022, BIG DATA COGN COMPUT, V6, DOI 10.3390/bdcc6040101
   Ramani R, 2020, SOFT COMPUT, V24, P16335, DOI 10.1007/s00500-020-04943-3
   Saeed MM, 2020, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.321
   Saranya P., 2019, 2019 International Conference on Smart Systems and Inventive Technology (ICSSIT). Proceedings, P46, DOI 10.1109/ICSSIT46314.2019.8987882
   Stergiou C., 2020, HDB COMPUTER NETWORK, P525, DOI [10.1007/978-3-030-22277-2_21, DOI 10.1007/978-3-030-22277-2_21]
   Subramanian EK, 2020, CLUSTER COMPUT, V23, P3057, DOI 10.1007/s10586-020-03069-3
   Tariq MI, 2020, DEEP LEARNING TECHNIQUES FOR BIOMEDICAL AND HEALTH INFORMATICS, P187, DOI 10.1016/B978-0-12-819061-6.00008-2
   Tawalbeh LA, 2021, J KING SAUD UNIV-COM, V33, P810, DOI 10.1016/j.jksuci.2019.05.007
   Thamrin A, 2020, P INT C SERV OR SYST, DOI [10.1109/SOSE52839.2021.00015, DOI 10.1109/SOSE52839.2021.00015]
   Vaishali G, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING TECHNOLOGIES AND INTELLIGENT DATA ENGINEERING (ICCTIDE'16)
   Venkatesh R, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1398-y
   Vione E., 2019, P 1 INT C SCI TECHN
   Zhang H, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1472-7
   Zhou YS, 2022, J CLOUD COMPUT-ADV S, V11, DOI 10.1186/s13677-022-00324-3
NR 49
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 25
PY 2023
DI 10.1007/s11042-023-17381-8
EA OCT 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U7WL5
UT WOS:001086870100004
DA 2024-07-18
ER

PT J
AU He, XS
   He, F
   Fan, YP
   Jiang, LM
   Liu, RZ
   Maalla, A
AF He, Xuansen
   He, Fan
   Fan, Yueping
   Jiang, Lingmin
   Liu, Runzong
   Maalla, Allam
TI An effective clustering scheme for high-dimensional data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE K-means algorithm; Clustering validity function; Initial center
   selection; Empirical rule; Linear discriminant analysis; Silhouette
   analysis
ID K-MEANS; ALGORITHM; NUMBER; CENTERS
AB While the classical K-means algorithm has been widely used in many fields, it still has some defects. Therefore, this paper proposes a scheme to improve the clustering quality of K-means algorithm. The farthest initial center selection and the min-max rule are used to improve the random initialization of K-means algorithm, which can avoid the empty clusters in the clustering results. For high-dimensional data sets, standardized feature scaling makes the data subject to normal distribution, and supervised linear discriminant analysis (LDA) is used to effectively reduce the data dimension and facilitate visualization. The empirical rule is used to estimate the range of the number of clusters. Within this range, the number of clusters of data is visually estimated by searching the elbow of the sum-of-squared-errors (SSE) curve. Further, a novel clustering validity function f(K) is proposed to determine the optimal number of clusters for complex real-world data sets. Through silhouette analysis, the clustering quality can be intuitively evaluated by calculating the silhouette coefficient of cluster and observing its size. The simulation results of different types of data sets show that this scheme can not only improve the clustering quality of K-means algorithm, but also provide a visual cluster analysis method for high-dimensional data sets.
C1 [He, Xuansen; Fan, Yueping; Jiang, Lingmin; Liu, Runzong] Guangzhou Coll Commerce, Sch Informat Technol & Engn, Guangzhou, Peoples R China.
   [He, Xuansen] Hunan Univ, Coll Informat Sci & Engn, Changsha, Peoples R China.
   [He, Fan] Beijing Inst Technol, Sch Management & Econ, Beijing, Peoples R China.
   [Maalla, Allam] Guangzhou Coll Technol & Business, Sch Engn, Guangzhou, Peoples R China.
C3 Guangzhou College of Commerce; Hunan University; Beijing Institute of
   Technology
RP He, XS (corresponding author), Guangzhou Coll Commerce, Sch Informat Technol & Engn, Guangzhou, Peoples R China.; He, XS (corresponding author), Hunan Univ, Coll Informat Sci & Engn, Changsha, Peoples R China.
EM xshe2010@163.com
FU This work was supported in part by the National Natural Science
   Foundation of China (No. 71972013), in part by the Special Projects in
   Key Fields of Ordinary Colleges and Universities in Guangdong Province
   (New Generation Information Technology) (No. 2021Z [71972013]; National
   Natural Science Foundation of China [2021ZDZX1035]; Special Projects in
   Key Fields of Ordinary Colleges and Universities in Guangdong Province
   (New Generation Information Technology)
FX This work was supported in part by the National Natural Science
   Foundation of China (No. 71972013), in part by the Special Projects in
   Key Fields of Ordinary Colleges and Universities in Guangdong Province
   (New Generation Information Technology) (No. 2021ZDZX1035)
CR Abdalameer AK, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116329
   Ahmad A, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114149
   Alminagorta O, 2021, ECOL INFORM, V64, DOI 10.1016/j.ecoinf.2021.101361
   Awan U, 2021, TECHNOL FORECAST SOC, V168, DOI 10.1016/j.techfore.2021.120766
   Bandyopadhyay S, 2001, IEEE T SYST MAN CY C, V31, P120, DOI 10.1109/5326.923275
   Batool F, 2021, COMPUT STAT DATA AN, V158, DOI 10.1016/j.csda.2021.107190
   Benrazek A E, 2020, Transactions on Emerg Telecommun Technol, V2020, P1, DOI [10.1002/ETT-19-0392.R1, DOI 10.1002/ETT-19-0392.R1]
   Biswas TK, 2023, EXPERT SYST APPL, V212, DOI 10.1016/j.eswa.2022.118862
   Cao FY, 2009, COMPUT MATH APPL, V58, P474, DOI 10.1016/j.camwa.2009.04.017
   Chen M, 2014, MOBILE NETW APPL, V19, P171, DOI 10.1007/s11036-013-0489-0
   Creighton J.H. C., 1994, A First Course in Probability Models and Statistical Inference
   Czarnowski I, 2021, IEEE ACCESS, V9, P151386, DOI 10.1109/ACCESS.2021.3125622
   Erilli NA, 2011, EXPERT SYST APPL, V38, P2248, DOI 10.1016/j.eswa.2010.08.012
   Erisoglu M, 2011, PATTERN RECOGN LETT, V32, P1701, DOI 10.1016/j.patrec.2011.07.011
   Feng MC, 2019, IEEE ACCESS, V7, P106111, DOI 10.1109/ACCESS.2019.2930410
   Gao KL, 2022, IEEE T IMAGE PROCESS, V31, P3449, DOI 10.1109/TIP.2022.3169689
   Huang D, 2021, IEEE T SYST MAN CY-S, V51, P508, DOI 10.1109/TSMC.2018.2876202
   Ikotun AM, 2023, INFORM SCIENCES, V622, P178, DOI 10.1016/j.ins.2022.11.139
   Karim A, 2018, PROCEDIA COMPUT SCI, V127, P16, DOI 10.1016/j.procs.2018.01.093
   Karimzadeh S, 2019, EXPERT SYST APPL, V126, P265, DOI 10.1016/j.eswa.2019.02.022
   Kariyam, 2023, METHODSX, V10, DOI 10.1016/j.mex.2023.102084
   Khan F, 2012, APPL SOFT COMPUT, V12, P3698, DOI 10.1016/j.asoc.2012.07.021
   Khan SS, 2004, PATTERN RECOGN LETT, V25, P1293, DOI 10.1016/j.patrec.2004.04.007
   Kumar KM, 2017, INFORM SCIENCES, V418, P286, DOI 10.1016/j.ins.2017.07.036
   Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114
   Lespinats S, 2007, IEEE T NEURAL NETWOR, V18, P1265, DOI 10.1109/TNN.2007.891682
   Li P, 2022, NEURAL NETWORKS, V152, P347, DOI 10.1016/j.neunet.2022.05.005
   Li SY, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109196
   Lippiello E, 2023, PHYSICA A, V616, DOI 10.1016/j.physa.2023.128592
   Lu JF, 2008, PATTERN RECOGN LETT, V29, P787, DOI 10.1016/j.patrec.2007.12.009
   Meng ZQ, 2020, KNOWL-BASED SYST, V193, DOI 10.1016/j.knosys.2020.105472
   Mo DY, 2012, IEEE T KNOWL DATA EN, V24, P59, DOI 10.1109/TKDE.2010.225
   Nock R, 2006, IEEE T PATTERN ANAL, V28, P1223, DOI 10.1109/TPAMI.2006.168
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   Peña JM, 1999, PATTERN RECOGN LETT, V20, P1027, DOI 10.1016/S0167-8655(99)00069-0
   Qiao KK, 2023, APPL SOFT COMPUT, V132, DOI 10.1016/j.asoc.2022.109718
   Redmond SJ, 2007, PATTERN RECOGN LETT, V28, P965, DOI 10.1016/j.patrec.2007.01.001
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Roux M, 2018, J CLASSIF, V35, P345, DOI 10.1007/s00357-018-9259-9
   SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81, DOI 10.1109/TPAMI.1984.4767478
   Smieja M, 2017, ADV DATA ANAL CLASSI, V11, P493, DOI 10.1007/s11634-016-0254-x
   Steinley D, 2006, BRIT J MATH STAT PSY, V59, P1, DOI 10.1348/000711005X48266
   Takeuchi A, 2007, J CLASSIF, V24, P123, DOI 10.1007/s00357-007-0002-1
   Turet JG, 2022, DATA KNOWL ENG, V141, DOI 10.1016/j.datak.2022.102056
   Viloria A, 2019, PROCEDIA COMPUT SCI, V151, P1201, DOI 10.1016/j.procs.2019.04.172
   Wang Z, 2022, NEUROCOMPUTING, V511, P399, DOI 10.1016/j.neucom.2022.09.006
   Xiao QG, 2021, IEEE T AUTOM SCI ENG, V18, P717, DOI 10.1109/TASE.2019.2961714
   Zanaty EA, 2012, EGYPT INFORM J, V13, P39, DOI 10.1016/j.eij.2012.01.004
   Zhang XY, 2020, P IEEE, V108, P894, DOI 10.1109/JPROC.2020.2989782
   Zhang YQ, 2017, INFORM SCIENCES, V415, P414, DOI 10.1016/j.ins.2017.05.024
   Zhu EZ, 2018, APPL SOFT COMPUT, V71, P608, DOI 10.1016/j.asoc.2018.07.026
   Zhu R, 2019, INFORM SCIENCES, V481, P69, DOI 10.1016/j.ins.2018.12.061
NR 52
TC 0
Z9 0
U1 7
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 19
PY 2023
DI 10.1007/s11042-023-17129-4
EA OCT 2023
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6OE7
UT WOS:001085969000022
DA 2024-07-18
ER

PT J
AU Wang, Y
   Jeong, WG
   Zhang, H
   Choi, Y
   Jin, GY
   Ko, SB
AF Wang, Yi
   Jeong, Won Gi
   Zhang, Hao
   Choi, Younhee
   Jin, Gong Yong
   Ko, Seok-Bum
TI Anterior mediastinal nodular lesion segmentation from chest computed
   tomography imaging using UNet based neural network with attention
   mechanisms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Anterior mediastinal nodular lesion segmentation; Computed tomography
   imaging; UNet; Self-attention; Convolutional block attention module
ID CT
AB Automated detection of anterior mediastinal nodular lesions (AMLs) has significance for clinical usage as it is challenging for radiologists to accurately identify AMLs from chest computed tomography (CT) imaging due to various factors, including poor resolution, variations in intensity and the similarity of the AMLs to other tissues. To assist radiologists in AML detection from chest CT imaging, a UNet-based computer-aided detection (CADe) system is proposed to segment AMLs from slice images of the chest CT scans. The proposed network adopts a modified UNet architecture. To guide the proposed network to selectively focus on AMLs and potentially disregard others in the image, different attention mechanisms are utilized in the proposed network, including the self-attention mechanism and the convolutional block attention module (CBAM). The proposed network was trained and evaluated on 180 chest CT scans which consist of 180 AMLs. 90 AMLs were identified as thymic cysts, and 90 AMLs were diagnosed as thymoma. The proposed network achieved an average dice similarity coefficient (DSC) of 93.23 with 5-fold cross-validation, for which the mean Intersection over Union (IoU), sensitivity and specificity were 90.29, 93.98 and 95.68 respectively. Our method demonstrated an improved segmentation performance over state-of-the-art segmentation networks, including UNet, ResUNet, TransUNet and UNet++. The proposed network employing attention mechanisms exhibited a promising result for segmenting AMLs from chest CT imaging and could be used to automate the AML detection process for achieving improved diagnostic reliability.
C1 [Wang, Yi; Choi, Younhee; Ko, Seok-Bum] Univ Saskatchewan, Dept Elect & Comp Engn, 57 Campus Dr, Saskatoon, SK, Canada.
   [Jeong, Won Gi] Chonnam Natl Univ, Hwasun Hosp, Dept Radiol, Hwasun, South Korea.
   [Zhang, Hao] Ocean Univ China, Fac Informat Sci & Engn, Qingdao, Peoples R China.
   [Jin, Gong Yong] Jeonbuk Natl Univ, Biomed Res Inst,Jeonbuk Natl Univ Hosp, Dept Radiol,Med Sch, Res Inst Clin Med, 20 Geonji Ro, Jeonju, South Korea.
C3 University of Saskatchewan; Chonnam National University; Ocean
   University of China; Jeonbuk National University; Jeonbuk National
   University Hospital
RP Ko, SB (corresponding author), Univ Saskatchewan, Dept Elect & Comp Engn, 57 Campus Dr, Saskatoon, SK, Canada.
EM seokbum.ko@usask.ca
RI Ko, Seokbum/H-8366-2012
OI Ko, Seokbum/0000-0002-9287-317X
FU The authors would like to thank the Natural Sciences and Engineering
   Research Council (NSERC) of Canada and the Department of Electrical and
   Computer Engineering at the University of Saskatchewan for their
   financial support for this research work.; Natural Sciences and
   Engineering Research Council (NSERC) of Canada; Department of Electrical
   and Computer Engineering at the University of Saskatchewan
FX The authors would like to thank the Natural Sciences and Engineering
   Research Council (NSERC) of Canada and the Department of Electrical and
   Computer Engineering at the University of Saskatchewan for their
   financial support for this research work.
CR Ackman JB, 2021, RADIOLOGY, V301, P443, DOI 10.1148/radiol.2021203593
   Aresta G, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48004-8
   Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204
   Bailey CR, 2022, RADIOGRAPHICS, V42, pE137, DOI 10.1148/rg.220037
   Castro-Zunti R, 2020, COMPUT MED IMAG GRAP, V82, DOI 10.1016/j.compmedimag.2020.101718
   Choe J, 2022, INSIGHTS IMAGING, V13, DOI 10.1186/s13244-022-01275-8
   de Koning HJ, 2020, NEW ENGL J MED, V382, P503, DOI 10.1056/NEJMoa1911793
   Haghanifar A, 2022, MULTIMED TOOLS APPL, V81, P30615, DOI 10.1007/s11042-022-12156-z
   Hemalatha R., 2018, Medical and Biological Image Analysis, V4, P2, DOI [DOI 10.5772/INTECHOPEN.74576, 10.5772/interchopen.74576]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang S, 2021, FRONT ONCOL, V10, DOI 10.3389/fonc.2020.618357
   Jung W, 2020, J THORAC DIS, V12, P1357, DOI 10.21037/jtd.2020.02.14
   Tomar NK, 2022, Arxiv, DOI arXiv:2206.08985
   Lei Ba J., 2016, arXiv
   Linsley D, 2019, Arxiv, DOI [arXiv:1805.08315, 10.48550/ARXIV.1805.08315, DOI 10.48550/ARXIV.1805.08315]
   Liu ZG, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.631964
   Long JAT, 2015, Arxiv, DOI [arXiv:1411.4038, DOI 10.48550/ARXIV.1411.4038]
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Munden RF, 2018, J AM COLL RADIOL, V15, P1087, DOI 10.1016/j.jacr.2018.04.029
   Nayan A, 2022, IEEE ACCESS, V10, P89289, DOI 10.1109/ACCESS.2022.3198996
   Oda H, 2018, PROC SPIE, V10575, DOI 10.1117/12.2287066
   Oktay O, 2018, Arxiv, DOI arXiv:1804.03999
   Ron Kikinis, 2014, Intraoperative Imaging and Image-Guided Therapy, P277, DOI DOI 10.1007/978-1-4614-7657-319
   Ronneberger O, 2015, Arxiv, DOI [arXiv:1505.04597, DOI 10.48550/ARXIV.1505.04597]
   Roth HR, 2016, IEEE T MED IMAGING, V35, P1170, DOI 10.1109/TMI.2015.2482920
   SANDOR T, 1991, INT J BIOMED COMPUT, V29, P133, DOI 10.1016/0020-7101(91)90004-X
   Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809
   Sui H, 2019, J THORAC DIS, V11, P1809, DOI 10.21037/jtd.2019.05.32
   Tong GF, 2018, OPTIK, V174, P460, DOI 10.1016/j.ijleo.2018.08.086
   Usman M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-69817-y
   Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762, 10.48550/arXiv.1706.03762]
   Wang WH, 2023, Arxiv, DOI arXiv:2106.13797
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang L, 2020, ANN TRANSL MED, V8, DOI 10.21037/atm.2020.02.183
   Ye XJ, 2010, INT J BIOMED IMAGING, V2010, DOI 10.1155/2010/983963
   Yoon SH, 2018, J THORAC ONCOL, V13, P359, DOI 10.1016/j.jtho.2017.11.124
   Yu FS, 2016, Arxiv, DOI [arXiv:1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Yu Q., 2021, arXiv
   Zhang DJ, 2022, Arxiv, DOI [arXiv:2111.12527, 10.48550/arXiv.2111.12527]
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 41
TC 0
Z9 0
U1 5
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 19
PY 2023
DI 10.1007/s11042-023-17210-y
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6OE7
UT WOS:001085969000010
DA 2024-07-18
ER

PT J
AU Li, J
   Wang, N
   Gong, S
   Jiang, XW
   Zhang, DM
AF Li, Jiang
   Wang, Ning
   Gong, Sai
   Jiang, Xinwei
   Zhang, Dongmei
TI Metric learning and local enhancement based collaborative representation
   for hyperspectral image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Collaborative representation; Hyperspectral image; Classification;
   Metric learning
ID NEAREST REGULARIZED SUBSPACE; SPARSE REPRESENTATION
AB Collaborative Representation (CR) models have been successfully employed for Hyperspectral Images (HSIs) classification because of the effectiveness and simplicity. However, when dealing with high-dimensional and noisy HSIs data, CR models which try to seek an approximation of each testing sample by a linear combination of training/dictionary data with different regularizators in Euclidean space could be ineffective. Although there are some variants of CR adopt various distance measurements like Mahalanobis distance or subdictionary data to address these issues, the performance of these models could be compromised due to the inaccurate distance calculation between the testing and dictionary/subdictionary data. In order to further improve the performance of CR models, we propose three novel CR models for HSIs classification. Firstly, Metric-learning based CR (MCR) adopts metric learning method to adaptively learn the correlation between the spectral bands from HSIs data which leads to more accurate distance measurement in CR. Then, Local-enhancement based CR (LCR) tries to enhance the contribution of the neighbor training samples and impose penalty over the non-neighbor training samples of each testing sample in the regularization term of CR models, leading to effective local structures representation. Finally, Metric-learning and Local-enhancement based CR (MLCR) is proposed to combine MCR with LCR, which could provide better classification accuracy. To further consider the spatial information in CR, the Metric-learning and Local-enhancement based Spatial-aware CR (MLSaCR) is also developed. The experimental results on three HSIs datasets demonstrate the effectiveness of the proposed models where the novel models outperform the classical and state-of-the-art CR models for HSIs classification.
C1 [Li, Jiang] Informat Ctr, Dept Nat Resources Hubei Prov, Wuhan 430071, Hubei, Peoples R China.
   [Wang, Ning] Changjiang Inst Survey Planning Design & Res, Wuhan 430010, Hubei, Peoples R China.
   [Gong, Sai; Jiang, Xinwei; Zhang, Dongmei] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Hubei, Peoples R China.
   [Gong, Sai; Jiang, Xinwei; Zhang, Dongmei] China Univ Geosci, Hubei Key Lab Intelligent Geoinformat Proc, Wuhan 430074, Hubei, Peoples R China.
C3 China University of Geosciences; China University of Geosciences
RP Jiang, XW (corresponding author), China Univ Geosci, Sch Comp Sci, Wuhan 430074, Hubei, Peoples R China.; Jiang, XW (corresponding author), China Univ Geosci, Hubei Key Lab Intelligent Geoinformat Proc, Wuhan 430074, Hubei, Peoples R China.
EM johnlee1124@126.com; wangning@cjwsjy.com.cn; gongsai@cug.edu.com;
   ysjxw@hotmail.com; cugzdm@foxmail.com
RI zhang, dongmei/B-8011-2013
FU This work was supported by the Nature Science Foundation of Hubei
   Province under Grant 2021CFB557, the National Natural Science Foundation
   of China under Grant 62106241, 61973285, the Science and Technology
   Project of Department of Natural Resources, Hubei [2021CFB557]; Nature
   Science Foundation of Hubei Province [62106241, 61973285]; National
   Natural Science Foundation of China [ZRZY2020KJ12]; Science and
   Technology Project of Department of Natural Resources, Hubei Province;
   Fundamental Research Founds for National University, China University of
   Geosciences (Wuhan)
FX This work was supported by the Nature Science Foundation of Hubei
   Province under Grant 2021CFB557, the National Natural Science Foundation
   of China under Grant 62106241, 61973285, the Science and Technology
   Project of Department of Natural Resources, Hubei Province, under Grant
   ZRZY2020KJ12, Fundamental Research Founds for National University, China
   University of Geosciences (Wuhan).
CR [Anonymous], 2006, Distance metric learning: a comprehensive survey
   Chakraborti Tapabrata, 2020, IEEE Letters of the Computer Society, V3, P34, DOI 10.1109/LOCS.2020.2997647
   Chen Y, 2011, IEEE T GEOSCI REMOTE, V49, P3973, DOI 10.1109/TGRS.2011.2129595
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Davis J., 2008, INT C MACHINE LEARNI
   Davis JV, 2006, Advances in neural information processing systems (NIPS), P337
   Dong YN, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10091415
   Globerson A., 2006, Advances in Neural Information Processing Systems (NIPS)
   He L, 2018, IEEE T GEOSCI REMOTE, V56, P1579, DOI 10.1109/TGRS.2017.2765364
   Jiang JJ, 2017, IEEE GEOSCI REMOTE S, V14, P404, DOI 10.1109/LGRS.2016.2645708
   Jiang XW, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3153041
   Karaca AC, 2021, IEEE GEOSCI REMOTE S, V18, P1264, DOI 10.1109/LGRS.2020.2998605
   Khan SS, 2022, MULTIMED TOOLS APPL, V81, P24869, DOI 10.1007/s11042-022-12263-x
   Khan SS, 2019, J APPL REMOTE SENS, V14, DOI 10.1117/1.JRS.14.032604
   Kulis B., 2006, P 23 INT C MACHINE L, P505
   Li JY, 2014, IEEE T GEOSCI REMOTE, V52, P3707, DOI 10.1109/TGRS.2013.2274875
   Li J, 2012, IEEE T GEOSCI REMOTE, V50, P809, DOI 10.1109/TGRS.2011.2162649
   Li W, 2019, IEEE T GEOSCI REMOTE, V57, P7246, DOI 10.1109/TGRS.2019.2912507
   Li W, 2016, PATTERN RECOGN LETT, V83, P115, DOI 10.1016/j.patrec.2015.09.010
   Li W, 2015, IEEE GEOSCI REMOTE S, V12, P48, DOI 10.1109/LGRS.2014.2325978
   Li W, 2014, IEEE J-STARS, V7, P2200, DOI 10.1109/JSTARS.2014.2306956
   Li W, 2014, IEEE J-STARS, V7, P1012, DOI 10.1109/JSTARS.2013.2295313
   Li W, 2014, IEEE T GEOSCI REMOTE, V52, P477, DOI 10.1109/TGRS.2013.2241773
   Liang HM, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8020099
   Liu N, 2018, IEEE J-STSP, V12, P1491, DOI 10.1109/JSTSP.2018.2877474
   Ma Y, 2018, IEEE GEOSCI REMOTE S, V15, P587, DOI 10.1109/LGRS.2018.2800080
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Ng A. Y., 2002, Advances in Neural Information Processing Systems, P1473
   Sathya P., 2015, Advances in Natural and Applied Sciences, V9, P338
   Su HJ, 2021, IEEE T GEOSCI REMOTE, V59, P6840, DOI 10.1109/TGRS.2020.3029578
   Tian CW, 2018, ARAB J SCI ENG, V43, P741, DOI 10.1007/s13369-017-2696-7
   Wang R, 2020, SIGNAL PROCESS, V177, DOI 10.1016/j.sigpro.2020.107718
   Weinberger K.Q., 2006, Advances in neural information processing systems, P1473
   Wen J, 2018, NEURAL NETWORKS, V102, P36, DOI 10.1016/j.neunet.2018.02.002
   Xie WY, 2019, IEEE ACCESS, V7, P76061, DOI 10.1109/ACCESS.2019.2921538
   Yang JH, 2020, IEEE GEOSCI REMOTE S, V17, P671, DOI 10.1109/LGRS.2019.2929840
   Yang JH, 2018, IEEE GEOSCI REMOTE S, V15, P112, DOI 10.1109/LGRS.2017.2776113
   Yang RC, 2023, MULTIMED TOOLS APPL, V82, P5823, DOI 10.1007/s11042-022-13597-2
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang Q, 2023, CAAI T INTELL TECHNO, V8, P331, DOI 10.1049/cit2.12110
   Zhang X, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3057701
   Zhang XY, 2015, IEEE T NEUR NET LEAR, V26, P2206, DOI 10.1109/TNNLS.2014.2371492
   Zhang Y, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3079994
   Zhang YS, 2021, INFORM SCIENCES, V546, P858, DOI 10.1016/j.ins.2020.09.009
   Zhang YX, 2016, IEEE T GEOSCI REMOTE, V54, P1376, DOI 10.1109/TGRS.2015.2479299
   Zheng CY, 2019, IEEE T GEOSCI REMOTE, V57, P7307, DOI 10.1109/TGRS.2019.2912330
   Zheng CY, 2019, PATTERN RECOGN LETT, V117, P30, DOI 10.1016/j.patrec.2018.11.005
   Zhou CL, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3083416
NR 48
TC 2
Z9 2
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17198-5
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400014
DA 2024-07-18
ER

PT J
AU Antony, B
   Revathy, S
AF Antony, Blessy
   Revathy, S.
TI Enhancing security in online social networks: introducing the DeepSybil
   model for Sybil attack detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sybil attack; Online social networks; Gannet optimization algorithm;
   Graph attention networks; One-hot encoding
ID IDENTIFICATION
AB Online Social Networks (OSNs) have become increasingly popular platforms for personal, professional, and social networking. However, the rise of fraudulent events such as fake news and rumors has created security threats within OSNs, leading to significant impacts. Among the major threats are Sybil attacks, where fake accounts, known as Sybils, are generated within OSNs to carry out various malicious activities. To address this issue, this paper proposes the DeepSybil model, which utilizes the Gannet Optimization Algorithm (GOA) and Graph Attention Networks (GATs) to detect Sybil attacks in OSNs. The proposed model starts by gathering various input information using the Social Network Fake Account (SNFA) dataset. This data is then preprocessed to eliminate redundant and irrelevant data points. Next, meaningful features are extracted to capture user behaviors and interactions, while an adjacency matrix represents the links between users to analyze the network structure of OSNs. Categorical features are encoded into binary features using One-hot encoding. The dataset is divided into training and testing sets to evaluate the model's efficiency. The GOA algorithm is employed to optimize the parameters of the proposed model, thereby improving the accuracy of Sybil attack detection. GATs leverage the attention mechanism to accurately identify Sybil attacks within OSNs. The model outputs a probability indicating the likelihood of an account being a Sybil. To evaluate the effectiveness of the proposed model, various performance metrics, including accuracy, precision, F1-score, recall, Receiver Operating Characteristic curve (ROC), and specificity, are employed. The results demonstrate that the proposed model achieves a high accuracy of 96.8%, outperforming existing methods. Thus, the proposed DeepSybil model proves to be a highly suitable solution for accurately detecting Sybil attacks in OSNs.
C1 [Antony, Blessy] Deemed Univ, Sathyabama Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, India.
   [Revathy, S.] Deemed Univ, Sathyabama Inst Sci & Technol, Dept IT, Chennai, India.
C3 Sathyabama Institute of Science & Technology; Sathyabama Institute of
   Science & Technology
RP Antony, B (corresponding author), Deemed Univ, Sathyabama Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, India.
EM blesi.antony@gmail.com; revathy.it@sathyabama.ac.in
CR Almesaeed R, 2022, WIREL NETW, V28, P1361, DOI 10.1007/s11276-021-02871-0
   Almogren A, 2021, IEEE INTERNET THINGS, V8, P4485, DOI 10.1109/JIOT.2020.3027440
   Antony B., 2018, INT C COMP VIS BIOIN, P675
   Benadla S, 2022, IEEE Transactions on Network and Service Management
   Chen Y, 2023, COMPUT NETW, V224, DOI 10.1016/j.comnet.2023.109608
   Concone F, 2022, PERVASIVE MOB COMPUT, V83, DOI 10.1016/j.pmcj.2022.101612
   Ellaky Z, 2023, J KING SAUD UNIV-COM, V35, DOI 10.1016/j.jksuci.2023.04.004
   Furutani S, 2023, IEEE T INF FOREN SEC, V18, P1225, DOI 10.1109/TIFS.2023.3237364
   Gao TY, 2020, IEEE ACCESS, V8, P38753, DOI 10.1109/ACCESS.2020.2975877
   Hai T, 2023, J CLOUD COMPUT-ADV S, V12, DOI 10.1186/s13677-023-00443-5
   Jain L, 2020, EXPERT SYST APPL, V142, DOI 10.1016/j.eswa.2019.113016
   Jethava G, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107753
   Jethava G, 2022, ARAB J SCI ENG, V47, P9615, DOI 10.1007/s13369-021-06332-w
   Jiang ZY, 2020, IEEE T CIRCUITS-II, V67, P3487, DOI 10.1109/TCSII.2020.3001182
   Li QH, 2019, IEEE T WIREL COMMUN, V18, P1805, DOI 10.1109/TWC.2019.2897308
   Li SY, 2022, KNOWL-BASED SYST, V258, DOI 10.1016/j.knosys.2022.110038
   Lu Y, 2019, Kaggle
   Ma GY, 2022, ENG APPL ARTIF INTEL, V113, DOI 10.1016/j.engappai.2022.104960
   Mao J, 2022, NEUROCOMPUTING, V500, P295, DOI 10.1016/j.neucom.2021.07.106
   Mao J, 2020, CHINA COMMUN, V17, P82, DOI 10.23919/JCC.2020.10.006
   Merzougui R, 2022, m fehamsecurity and privacy in cyberspace 2022, P25, DOI [10.1007/978-981-19-1960-2_2, DOI 10.1007/978-981-19-1960-2_2]
   Onyema EM, 2022, J CLOUD COMPUT-ADV S, V11, DOI 10.1186/s13677-022-00305-6
   Orabi M, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102250
   Pan JS, 2022, MATH COMPUT SIMULAT, V202, P343, DOI 10.1016/j.matcom.2022.06.007
   Parham M, 2020, WIRELESS PERS COMMUN, V113, P1149, DOI 10.1007/s11277-020-07272-8
   Parmaksiz H, 2023, KNOWL-BASED SYST, V268, DOI 10.1016/j.knosys.2023.110472
   Qu Z., 2022, IEEE Trans Netw Serv Manag
   Raja MS, 2022, WIRELESS PERS COMMUN, V127, P107, DOI 10.1007/s11277-021-08095-x
   Sahoo SR, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106983
   Uppada SK, 2022, SOC NETW ANAL MIN, V12, DOI 10.1007/s13278-022-00878-9
   Valliyammai C, 2019, CLUSTER COMPUT, V22, P14461, DOI 10.1007/s10586-018-2314-9
   Velayudhan NC, 2024, J EXP THEOR ARTIF IN, V36, P721, DOI 10.1080/0952813X.2022.2104387
   Vyawahare M, 2022, SOC NETW ANAL MIN, V12, DOI 10.1007/s13278-022-00997-3
   Wanda P, 2021, SOC NETW ANAL MIN, V11, DOI 10.1007/s13278-021-00742-2
   Wang C, 2022, IEEE T COMPUT SOC SY, V9, P428, DOI 10.1109/TCSS.2021.3092007
   Yu JJQ, 2021, IEEE T INTELL TRANSP, V22, P4622, DOI 10.1109/TITS.2020.3036085
   Zhang ZY, 2023, AD HOC NETW, V141, DOI 10.1016/j.adhoc.2023.103092
   Zhou QQ, 2020, IEEE ACCESS, V8, P123228, DOI 10.1109/ACCESS.2020.3007458
NR 38
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-16851-3
EA OCT 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U7JA3
UT WOS:001086519900008
DA 2024-07-18
ER

PT J
AU Ashwini, P
   Suguna, N
   Vadivelan, N
AF Ashwini, P.
   Suguna, N.
   Vadivelan, N.
TI Improved bald eagle search optimization with entropy-based deep feature
   fusion model for breast cancer diagnosis on digital mammograms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Breast cancer; Hybrid deep learning; Feature fusion; Mammogram;
   Hyperparameter tuning
AB Early and accurate diagnosis of breast cancer (BC) using digital mammograms can improve disease detection accuracy. Medical images can be detected, segmented, and classified for the design of computer-aided diagnosis (CAD) models which assist radiologists in accurately diagnosing breast lesions. Therefore, this study proposes an Improved Bald Eagle Search Optimization with Entropy-based Deep Feature Fusion (IBESO-EDFFM) model for BC Diagnosis on Digital Mammograms. The goal of the IBESO-EDFFM technique lies in the proper detection and segmentation of BC using feature fusion and hyperparameter tuning concepts. For the feature extraction process, the IBESO-EDFFM technique employs an entropy-based feature fusion process, comprising three deep learning models namely Capsule Network (CapsNet), Inception v3, and EfficientNet. Besides, Improved Bald Eagle Search Optimization (IBESO) with Bidirectional-Quasi Recurrent Neural Network (BiQRNN) is utilized for the identification and classification of breast cancer. Finally, a fully convolutional network with RMSProp optimizer is exploited for the segmentation of abnormal regions from the classified images. The experimental result analysis of the IBESO-EDFFM technique is tested on the MIAS mammography dataset from the Kaggle repository and the comparative results show the better performance of the IBESO-EDFFM technique over recent approaches with maximum accuracy of 98.96%.
C1 [Ashwini, P.; Suguna, N.; Vadivelan, N.] Annamalai Univ, Fac Engn & Technol, Dept Comp Sci & Engn, Chidambaram, India.
   [Vadivelan, N.] Teegala Krishna Reddy Engn Coll, Comp Sci & Engn, Hyderabad, India.
C3 Annamalai University
RP Ashwini, P (corresponding author), Annamalai Univ, Fac Engn & Technol, Dept Comp Sci & Engn, Chidambaram, India.
EM ashwinireddy90@gmail.com; rajusuguna81@gmail.com; velancse@gmail.com
RI N, Vadivelan/ABD-6430-2020
OI N, Vadivelan/0000-0002-5886-0121
CR Abdulla AA, 2020, IET IMAGE PROCESS, V14, P4435, DOI 10.1049/iet-ipr.2020.0978
   Ahmad S, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/8141530
   Al-Dhaifallah M, 2023, AIN SHAMS ENG J, V14, DOI 10.1016/j.asej.2023.102225
   Alkhaleefah M, 2018, IEEE SYS MAN CYBERN, P894, DOI 10.1109/SMC.2018.00159
   Aziz MH, 2023, UHD J Sci Technol, V7, P7, DOI [10.21928/uhdjst.v7n1y2023, DOI 10.21928/UHDJST.V7N1Y2023]
   Babu D. Vijendra, 2020, IOP Conference Series: Materials Science and Engineering, V993, DOI 10.1088/1757-899X/993/1/012080
   Chen CC, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-17606-0
   Chouhan N, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104318
   Darweesh MS, 2021, COGENT ENG, V8, DOI 10.1080/23311916.2021.1968324
   Din NMU, 2022, COMPUT BIOL MED, V149, DOI 10.1016/j.compbiomed.2022.106073
   Escorcia-Gutierrez J, 2022, CMC-COMPUT MATER CON, V71, P4221, DOI 10.32604/cmc.2022.022322
   Fu Y, 2021, IEEE J-STARS, V14, P2674, DOI 10.1109/JSTARS.2021.3057936
   Goh TY, 2018, MEASUREMENT, V114, P298, DOI 10.1016/j.measurement.2017.09.052
   Han LY, 2022, FRONT ONCOL, V12, DOI 10.3389/fonc.2022.1042964
   Kavitha T, 2022, INTERDISCIP SCI, V14, P113, DOI 10.1007/s12539-021-00467-y
   Khairi SSM, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10010010
   Kusnik D, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-19161-0
   Linda GM, 2022, INT J INTELL COMPUT, V15, P363, DOI 10.1108/IJICC-08-2021-0178
   Liu M, 2022, IEEE J BIOMED HEALTH, V26, P5025, DOI 10.1109/JBHI.2022.3187765
   Nassif AB, 2022, ARTIF INTELL MED, V127, DOI 10.1016/j.artmed.2022.102276
   Raaj RS, 2023, BIOMED SIGNAL PROCES, V82, DOI 10.1016/j.bspc.2022.104558
   Remya R., 2022, 2022 International Conference on Electronics and Renewable Systems (ICEARS), P1060, DOI 10.1109/ICEARS53579.2022.9751974
   Senan EM, 2021, J APPL SCI ENG, V24, P323, DOI 10.6180/jase.202106_24(3).0007
   Sonali, 2019, OPT LASER TECHNOL, V110, P87, DOI 10.1016/j.optlastec.2018.06.061
   Wang WC, 2023, WATER-SUI, V15, DOI 10.3390/w15040692
   Wang Y, 2022, ANN ONCOL, V33, P89, DOI 10.1016/j.annonc.2021.09.007
   Yadav P, 2022, COMPUT INTELL-US, V38, P1748, DOI 10.1111/coin.12532
   Yu KP, 2021, IEEE WIREL COMMUN, V28, P54, DOI 10.1109/MWC.001.2000374
   Yuanqin Chen, 2019, 2nd International Conference on Healthcare Science and Engineering. Proceedings: Lecture Notes in Electrical Engineering (LNEE 536), P83, DOI 10.1007/978-981-13-6837-0_7
   Zahoor S, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12020557
   Zeng Y, 2023, P 2022 3 INT C ARTIF, DOI [10.2991/978-94-6463-040-4_42, DOI 10.2991/978-94-6463-040-4_42]
   Zhai GH, 2022, SMART STRUCT SYST, V29, P237, DOI 10.12989/sss.2022.29.1.237
NR 32
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-17144-5
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW2V2
UT WOS:001155653100004
DA 2024-07-18
ER

PT J
AU Kazemi, V
   Shahzadi, A
   Bizaki, HK
AF Kazemi, Vahdat
   Shahzadi, Ali
   Bizaki, Hossein Khaleghi
TI Flexible deterministic compressive measurement matrix based on two
   finite fields
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Compressive sensing; Measurement matrix; Finite field; Gram matrix
AB The rapid development of information technology puts forward new demands for signal sampling technology. Compressed sensing is a novel signal sampling theory that can realize signal sampling and compression simultaneously. The measurement matrix is the decisive factor affecting the reconstruction ability of compressed sensing. Therefore, the construction of measurement matrices is the key problem of compressed sensing theory. Taking full advantage of the finite field structure of the polynomial measurement matrix, a novel method for the deterministic measurement matrix based on two finite fields is proposed. In this paper, for more available choices of polynomial matrix and flexible signal length, a new expansion of polynomial sensing matrix is proposed by using two finite field. Experiments show that, the improved matrix offers more options of sensing matrix and overcome the shortcoming of fixed length measurement. Further comparisons to the block-polynomial method, show that the proposed two finite field polynomial matrix can improve the PSNR of reconstructed image by 10% similar to 15%.
C1 [Kazemi, Vahdat; Shahzadi, Ali] Semnan Univ, Dept Elect & Comp Engn, Semnan, Iran.
   [Bizaki, Hossein Khaleghi] Malek Ashtar Univ Technol, Dept Elect & Comp Engn, Tehran, Iran.
C3 Semnan University; Malek Ashtar University of Technology
RP Shahzadi, A (corresponding author), Semnan Univ, Dept Elect & Comp Engn, Semnan, Iran.
EM Vahdat.kazemi@semnan.ac.ir; Shahzadi@semnan.ac.ir; Bizaki@gmail.com
RI , shahzadi/AAY-6128-2021
OI , shahzadi/0000-0001-6159-3792
CR Al-Azawi MKM, 2018, IET SIGNAL PROCESS, V12, P214, DOI 10.1049/iet-spr.2016.0708
   Amalladinne VK, 2022, IEEE T INFORM THEORY, V68, P2384, DOI 10.1109/TIT.2021.3136437
   Amini A, 2012, IEEE T SIGNAL PROCES, V60, P172, DOI 10.1109/TSP.2011.2169249
   Amini A, 2011, IEEE T INFORM THEORY, V57, P2360, DOI 10.1109/TIT.2011.2111670
   Arjoune Y, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3576
   Bhatti UA, 2022, POL J ENVIRON STUD, V31, P4029, DOI 10.15244/pjoes/148065
   DeVore RA, 2007, J COMPLEXITY, V23, P918, DOI 10.1016/j.jco.2007.04.002
   Eftekhari A, 2015, APPL COMPUT HARMON A, V38, P1, DOI 10.1016/j.acha.2014.02.001
   Entezari R, 2017, AEU-INT J ELECTRON C, V82, P321, DOI 10.1016/j.aeue.2017.09.015
   Feng ZP, 2017, MEASUREMENT, V103, P106, DOI 10.1016/j.measurement.2017.02.031
   He JA, 2022, WIRELESS PERS COMMUN, V123, P3003, DOI 10.1007/s11277-021-09274-6
   Huang SQ, 2020, IET IMAGE PROCESS, V14, P3324, DOI 10.1049/iet-ipr.2019.0772
   Jiang DD, 2020, IEEE T NETW SCI ENG, V7, P507, DOI 10.1109/TNSE.2018.2877597
   Khan I, 2018, AEU-INT J ELECTRON C, V89, P181, DOI 10.1016/j.aeue.2018.03.038
   Li HF, 2020, IET SIGNAL PROCESS, V14, P307, DOI 10.1049/iet-spr.2019.0478
   Li LX, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10175909
   Li ZL, 2018, FRONT COMPUT SCI-CHI, V12, P217, DOI 10.1007/s11704-017-6132-7
   Liu JX, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103691
   Melo K, 2020, Information Technology and Intelligent Transportation Systems, P125
   Mitra D, 2018, IEEE INT SYMP SIGNAL, P501, DOI 10.1109/ISSPIT.2018.8642762
   Monika R, 2021, MULTIMED TOOLS APPL, V80, P4751, DOI 10.1007/s11042-020-09932-0
   Ramalho D, 2020, Compressive Sens Healthc, P89
   Salahdine F, 2017, INT J COMMUN SYST, V30, DOI 10.1002/dac.3314
   Srinivas Kankanala., 2018, INT C ADV COMPUTING, P342
   Tong FH, 2021, SIGNAL PROCESS, V182, DOI 10.1016/j.sigpro.2020.107951
   Wang XY, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116246
   Xu QR, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041229
   Xu QY, 2019, OPT LASER ENG, V121, P203, DOI 10.1016/j.optlaseng.2019.04.011
   Xue Y, 2019, IEEE T MED IMAGING, V38, P2632, DOI 10.1109/TMI.2019.2907093
   Ye Jong Chul, 2019, BMC Biomed Eng, V1, P8, DOI 10.1186/s42490-019-0006-z
   Yi RJ, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9040329
   Yuan HY, 2016, CIRC SYST SIGNAL PR, V35, P977, DOI 10.1007/s00034-015-0100-y
   Zayed AI, 2021, SIGNAL PROCESS, V181, DOI 10.1016/j.sigpro.2020.107902
   Zhang R, 2021, J SENSORS, V2021, DOI 10.1155/2021/4024737
NR 34
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-17077-z
EA OCT 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY5Z5
UT WOS:001142522500001
DA 2024-07-18
ER

PT J
AU Kerkache, HM
   Sadeg-Belkacem, L
   Tayeb, FBS
AF Kerkache, Hassen Mohamed
   Sadeg-Belkacem, Lamia
   Tayeb, Fatima Benbouzid-Si
TI Improved artificial bee colony algorithm based on community detection
   for link prediction problem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Social networks; Link prediction problem; Community detection;
   Metaheuristics; Artificial bee colony
ID INFORMATION; NETWORKS
AB The problem of link prediction has recently gained a lot of attention from various domains, including sociology, anthropology, information science, and computer science. In this research, we formulated the link prediction problem as an optimization problem to predict the links of any type of network and proposed two artificial bee colony-based link prediction algorithms enhanced with some neighborhood structures borrowed from genetic algorithms. In an attempt to complete the network's missing links, the first algorithm optimizes weights, which are used in a linear combination with local and global similarity indexes, to capture the best of both schemes and compensate for each approach's weaknesses. In the second one, we make use of the community structure of the network to help predict the missing links present in the networks. Experimental results of the proposed algorithms on a number of real-world and synthetic networks provided interesting insights about the problem and showed that the proposed algorithms can enhance link prediction accuracy and are quite competitive with state-of-the-art algorithms.
C1 [Kerkache, Hassen Mohamed; Sadeg-Belkacem, Lamia] Ecole Mil Polytech, Algiers 16046, Algeria.
   [Tayeb, Fatima Benbouzid-Si] Ecole Natl Super Informat ESI, Lab methodes concept Syst LMCS, BP 68M, Oued Smar 16270, Algeria.
C3 Ecole Military Polytechnic; Ecole Nationale Superieure d'Informatique
RP Kerkache, HM (corresponding author), Ecole Mil Polytech, Algiers 16046, Algeria.
EM ker.hacene@gmail.com
OI kerkache, Hassen Mohamed/0000-0001-9807-5534
CR Adamic LA, 2003, SOC NETWORKS, V25, P211, DOI 10.1016/S0378-8733(03)00009-1
   Aziz F, 2020, PHYSICA A, V557, DOI 10.1016/j.physa.2020.124980
   Barabási AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509
   Barham R., 2018, Mod Appl Sci, V13, P10, DOI [10.5539/mas.v13n1p10, DOI 10.5539/MAS.V13N1P10]
   Barham R, 2017, 2017 INTERNATIONAL CONFERENCE ON NEW TRENDS IN COMPUTING SCIENCES (ICTCS), P55, DOI 10.1109/ICTCS.2017.41
   Barham RS, 2019, J INF SCI, V45, P794, DOI 10.1177/0165551518816296
   Biswas A, 2017, MULTIMED TOOLS APPL, V76, P18619, DOI 10.1007/s11042-016-4270-9
   Bliss CA, 2014, J COMPUT SCI-NETH, V5, P750, DOI 10.1016/j.jocs.2014.01.003
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Brandes U, 2001, J MATH SOCIOL, V25, P163, DOI 10.1080/0022250X.2001.9990249
   Chen BL, 2014, APPL INTELL, V41, P694, DOI 10.1007/s10489-014-0558-5
   Daud NN, 2020, J NETW COMPUT APPL, V166, DOI 10.1016/j.jnca.2020.102716
   Del Ser J, 2019, SWARM EVOL COMPUT, V48, P220, DOI 10.1016/j.swevo.2019.04.008
   Ding JY, 2016, KNOWL-BASED SYST, V98, P200, DOI 10.1016/j.knosys.2016.01.034
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Golbeck Jennifer., 2015, INTRO SOCIAL MEDIA I, P221, DOI DOI 10.1016/B978-0-12-801656-5.00021-4
   Karaboga D., 2005, Technical report-tr06
   Karaboga D, 2014, ARTIF INTELL REV, V42, P21, DOI 10.1007/s10462-012-9328-0
   Katz L., 1953, Psychometrika, V18, P39, DOI [10.1007/BF02289026, DOI 10.1007/BF02289026]
   Kumar A, 2020, PHYSICA A, V553, DOI 10.1016/j.physa.2020.124289
   Kumari A, 2022, COMPUTING, V104, P1077, DOI 10.1007/s00607-021-01035-4
   Kunegis J, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P1343
   Lancichinetti A, 2008, PHYS REV E, V78, DOI 10.1103/PhysRevE.78.046110
   Lei CW, 2013, BIOINFORMATICS, V29, P355, DOI 10.1093/bioinformatics/bts688
   Li Li, 2011, Bio-Inspired Computing and Applications. 7th International Conference on Intelligent Computing, ICIC 2011.Revised Selected Papers, P566, DOI 10.1007/978-3-642-24553-4_75
   Li ZP, 2018, ACM TRANS MANAG INF, V9, DOI 10.1145/3131782
   Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591
   Lü LY, 2011, PHYSICA A, V390, P1150, DOI 10.1016/j.physa.2010.11.027
   Luo J.-D., 2005, Management and Organization Review, V1, P437, DOI DOI 10.1111/J.1740-8784.2005.00022.X
   Martínez V, 2017, ACM COMPUT SURV, V49, DOI 10.1145/3012704
   Mastrandrea R, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0136497
   Newman MEJ, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.036104
   Opsahl T, 2009, SOC NETWORKS, V31, P155, DOI 10.1016/j.socnet.2009.02.002
   Osaba E, 2021, SWARM EVOL COMPUT, V64, DOI 10.1016/j.swevo.2021.100888
   Özcan A, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P381, DOI [10.1109/ICMLA.2016.0068, 10.1109/ICMLA.2016.164]
   Pulipati S, 2021, INT J SYST ASSUR ENG, DOI 10.1007/s13198-021-01125-8
   Qu ZG, 2014, SCI CHINA INFORM SCI, V57, DOI 10.1007/s11432-012-4688-2
   Raut Purva, 2020, 2020 2nd International Conference on Innovative Mechanisms for Industry Applications (ICIMIA). Proceedings, P479, DOI 10.1109/ICIMIA48430.2020.9074840
   Rossi RA, 2015, AAAI CONF ARTIF INTE, P4292
   Safdari H, 2022, J PHYS-COMPLEXITY, V3, DOI 10.1088/2632-072X/ac52e6
   Salha-Galvan G, 2022, NEURAL NETWORKS, V153, P474, DOI 10.1016/j.neunet.2022.06.021
   Shang KK, 2022, PHYS REV E, V105, DOI 10.1103/PhysRevE.105.024311
   Singh SS, 2020, INFORM SCIENCES, V514, P402, DOI 10.1016/j.ins.2019.11.026
   Soundarajan S, 2012, P WEB C, ppp607, DOI [DOI 10.1145/2187980.2188150, 10.1145/2187980.2188150]
   Srilatha P, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES FOR SMART NATION (SMARTTECHCON), P560, DOI 10.1109/SmartTechCon.2017.8358434
   Yan BW, 2012, PHYS REV E, V85, DOI 10.1103/PhysRevE.85.056112
   ZACHARY WW, 1977, J ANTHROPOL RES, V33, P452, DOI 10.1086/jar.33.4.3629752
   Zeng S, 2016, PHYSICA A, V443, P537, DOI 10.1016/j.physa.2015.10.016
NR 48
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-17197-6
EA OCT 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U7JA3
UT WOS:001086519900003
DA 2024-07-18
ER

PT J
AU Dougherty, ST
   Klobusicky, J
   Sahinkaya, S
   Ustun, D
AF Dougherty, Steven T.
   Klobusicky, Joseph
   Sahinkaya, Serap
   Ustun, Deniz
TI An <i>S</i>-Box construction from exponentiation in finite fields and
   its application in RGB color image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image encryption; S-Box; Legendre symbol
ID SUBSTITUTION BOX; SCHEME; DESIGN; CHAOS
AB In this study, the utilization of exponentiation in finite fields is investigated for the purpose of generating pseudo-random sequences which have a crucial role in cryptographic applications. More precisely, a novel method for generating pseudo-random sequences is proposed to construct an initial S-Box which is a key component in various encryption schemes. In addition to that, a shuffling algorithm that leverages the pseudo-random sequences is developed to enhance the effectiveness of the initial S-Box. The utilization of the proposed S-Box is applied to the RGB color images to showcase its performance and robustness in an image encryption scheme.
C1 [Dougherty, Steven T.; Klobusicky, Joseph] Univ Scranton, Scranton, PA 18518 USA.
   [Sahinkaya, Serap] Tarsus Univ, Fac Engn, Dept Nat & Math Sci, TR-33400 Mersin, Turkiye.
   [Ustun, Deniz] Tarsus Univ, Fac Engn, Dept Comp Engn, Mersin, Turkiye.
C3 University of Scranton; Tarsus University; Tarsus University
RP Ustun, D (corresponding author), Tarsus Univ, Fac Engn, Dept Comp Engn, Mersin, Turkiye.
EM denizustun@tarsus.edu.tr
RI USTUN, Deniz/G-2829-2015
OI USTUN, Deniz/0000-0002-5229-4018
CR Aboytes-González JA, 2018, NONLINEAR DYNAM, V94, P2003, DOI 10.1007/s11071-018-4471-z
   Ahmad M, 2022, IEEE ACCESS, V10, P112757, DOI 10.1109/ACCESS.2022.3209202
   Ahmad M, 2015, PROCEDIA COMPUT SCI, V57, P572, DOI 10.1016/j.procs.2015.07.394
   Ahmed HA, 2019, NEURAL COMPUT APPL, V31, P7201, DOI 10.1007/s00521-018-3557-3
   Alhadawi HS, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102671
   Alhadawi HS, 2021, MULTIMED TOOLS APPL, V80, P7333, DOI 10.1007/s11042-020-10048-8
   Ali TS, 2022, MULTIMED TOOLS APPL, V81, P20585, DOI 10.1007/s11042-022-12268-6
   Alsaif H, 2023, SYMMETRY-BASEL, V15, DOI 10.3390/sym15040833
   Artuger F, 2022, NEURAL COMPUT APPL, V34, P20203, DOI 10.1007/s00521-022-07589-4
   Basha SM, 2022, OPTIK, V259, DOI 10.1016/j.ijleo.2022.168956
   BIHAM E, 1991, LECT NOTES COMPUT SC, V537, P2
   Chen G, 2008, CHAOS SOLITON FRACT, V36, P1028, DOI 10.1016/j.chaos.2006.08.003
   Damg I, 1998, Advances in Cryptology Santa Barbara CA 163-172 Lecture Notes in Comput Sci, V403
   Davenport H., 1933, J Lond Math Soc, Vs1-8, P46, DOI [10.1112/jlms/s1-8.1.46, DOI 10.1112/JLMS/S1-8.1.46]
   Davenport H., 1931, J. Lond. Math. Soc., V1, P49
   de la Fraga LG, 2023, INTEGRATION, V90, P22, DOI 10.1016/j.vlsi.2023.01.001
   Deb S, 2019, MULTIMED TOOLS APPL, V78, P34901, DOI 10.1007/s11042-019-08086-y
   Demirtas M, 2022, OPTIK, V265, DOI 10.1016/j.ijleo.2022.169430
   Detombe J., 1993, Advances in Cryptology - AUSCRYPT '92. Workshop on the Theory and Application of Cryptographic Techniques Proceedings, P165
   Din M, 2022, INT J SYST ASSUR ENG, V13, P2963, DOI 10.1007/s13198-022-01766-3
   Dougherty ST, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15240-0
   Abd El-Latif AA, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10121392
   Farah T, 2017, NONLINEAR DYNAM, V88, P1059, DOI 10.1007/s11071-016-3295-y
   Haque A, 2022, IEEE ACCESS, V10, P116167, DOI 10.1109/ACCESS.2022.3218062
   Hematpour N, 2021, NEURAL COMPUT APPL, V33, P5111, DOI 10.1007/s00521-020-05304-9
   Hussain I, 2013, NEURAL COMPUT APPL, V23, P97, DOI 10.1007/s00521-012-0914-5
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Lai Q, 2023, APPL MATH COMPUT, V442, DOI 10.1016/j.amc.2022.127738
   Li L, 2022, J INF SECUR APPL, V66, DOI 10.1016/j.jisa.2022.103135
   Li Z, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12091497
   Mahboob A, 2022, IEEE ACCESS, V10, P119244, DOI 10.1109/ACCESS.2022.3218643
   Manivannan D, 2023, SN Comput Sci, V4, DOI [10.1007/s42979-022-01582-3, DOI 10.1007/S42979-022-01582-3]
   Manjula G, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT), P613, DOI 10.1109/ICATCCT.2016.7912073
   Manzoor A, 2022, IEEE ACCESS, V10, P74164, DOI 10.1109/ACCESS.2022.3184012
   Matsui M, 1993, LINEAR CRYPTANALYSIS, P386, DOI DOI 10.1007/3-540-48285-7
   Nyberg K., 1993, LNCS, V765, P55
   Ozturk I, Int J Inf Technol, V1, P108
   Razaq A, 2022, Multimed Tools Appl, P1
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Sosa PM, 2016, Calculating nonlinearity of Boolean functions with Walsh-Hadamard Transform, P1
   Teng L, 2021, NONLINEAR DYNAM, V105, P1859, DOI 10.1007/s11071-021-06663-1
   Tian Y, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/6969312
   Toktas A, 2022, NEURAL COMPUT APPL, V34, P4295, DOI 10.1007/s00521-021-06552-z
   Ullah A, 2018, NONLINEAR DYNAM, V91, P359, DOI 10.1007/s11071-017-3874-6
   Waheed A, 2023, MULTIMED TOOLS APPL, V82, P29689, DOI 10.1007/s11042-023-14910-3
   Wang Y, 2012, PHYS LETT A, V376, P827, DOI 10.1016/j.physleta.2012.01.009
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Webster AF, 1985, Advances in Cryptology-CRYPTO-85 Proceedings CRYPTO 1985 Lecture notes in computer science, V218, DOI [10.1007/3-540-39799-X-41, DOI 10.1007/3-540-39799-X-41]
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yang YG, 2021, INFORM SCIENCES, V580, P174, DOI 10.1016/j.ins.2021.08.073
   Zahid AH, 2021, IEEE ACCESS, V9, P67797, DOI 10.1109/ACCESS.2021.3077194
   Zamli KZ, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115305
   Zamli KZ, 2021, NEURAL COMPUT APPL, V33, P16641, DOI 10.1007/s00521-021-06260-8
   Zhang XQ, 2022, MULTIMED TOOLS APPL, V81, P31753, DOI 10.1007/s11042-022-13003-x
   Zhang YQ, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106040
NR 55
TC 3
Z9 3
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17046-6
EA OCT 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800004
DA 2024-07-18
ER

PT J
AU Heena, A
   Biradar, N
   Maroof, N
AF Heena, Ayesha
   Biradar, Nagashettappa
   Maroof, Najmuddin
TI Abnormality classification using convolutional neural network for
   echocardiographic images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE CNN model; Classification; Machine learning; Artificial intelligence;
   Deep learning; Decision support system
AB Presently issues related to the heart are mostly considered as the deadliest diseases resulting in the increasing death rate across the globe irrespective of gender and age. Accurate and early prediction of these heart abnormalities require enormous experience along with advanced technology. Artificial Intelligence and Machine learning have contributed extensively as an emerging technology for the prediction of the diseases including heart abnormalities. However, still high accuracy of prediction and less computational complexities remains challenge for the researchers. Currently the prevailing scenario existing post pandemic and new variants coming in, it is very essential to come up with an amalgamation of technology and techniques as assessment for doctors in diagnosis. Proposed article makes use of Convolutional Neural networks (CNN) for detecting and classifying the heart abnormality into three labels as mild, moderate or severe which helps in appropriate treatment of the heart diseases. CNN model is built. The model is trained with datasets corresponding to mild, moderate and severe conditions of heart abnormality. The model is tested extensively for the test data and the performance indices are obtained are with reference to accuracy, precision, recall, specificity, F1-Score. Proposed work is implemented in the Keras libraries with Tensorflow 2.1.1 as backend. Furthermore, prediction performance and complexity overhead are correlated with the other existing cutting-edge algorithms in predicting the heart abnormalities. Results demonstrates that the proposed model proved to be efficient than the others with high prediction accuracy (99%) and less computational complexities.
C1 [Heena, Ayesha] Sharnbasva Univ, Fac Engn & Technol, Dept Artificial Intelligence & Machine, Kalaburagi, Karnataka, India.
   [Biradar, Nagashettappa] Visveswaraya Technol Univ, Bheemanna Khandre Inst Technol, Dept Elect & Commun Engn, Belagavi, Karnataka, India.
   [Maroof, Najmuddin] KBN Univ, Fac Engn & Technol, Dept Elect & Commun Engn, Kalaburagi, Karnataka, India.
C3 Visvesvaraya Technological University
RP Heena, A (corresponding author), Sharnbasva Univ, Fac Engn & Technol, Dept Artificial Intelligence & Machine, Kalaburagi, Karnataka, India.
EM ayeshaheena31@gmail.com
CR [Anonymous], 2011, INDIAN J SCI TECHNOL
   Ansari MA, 2020, J Interdisc Math, P1
   Chaudhary Atish, 2020, International Journal of Information Technology, V12, P141, DOI 10.1007/s41870-018-0255-4
   Deperlioglu O, 2020, COMPUT COMMUN, V162, P31, DOI 10.1016/j.comcom.2020.08.011
   Gokulalakshmi A, 2020, SOFT COMPUT, V24, P18599, DOI 10.1007/s00500-020-05096-z
   Hafizah WM, 2022, Int J Biol Biomed Eng, V6, P26
   Heena A, 2020, P 2 INT C IOT SOL MO, DOI [10.2139/ssrn.3735736, DOI 10.2139/SSRN.3735736]
   Heena A, 2022, P INT C IM PROC CAPS, DOI [10.1007/978-3-030-84760-9_2, DOI 10.1007/978-3-030-84760-9_2]
   Heena A, 2022, Global Transit Proc, V3, P13, DOI [10.1016/j.gltp.2022.04.003, DOI 10.1016/J.GLTP.2022.04.003]
   Heena A, 2022, IJERA12, P23, DOI [10.9790/9622-12070123, DOI 10.9790/9622-12070123]
   Heena A, 2022, MULTIMED TOOLS APPL, DOI 10.1007/s11042-022-13516-5
   Wu EJ, 2008, MED BIOL ENG COMPUT, V46, P841, DOI 10.1007/s11517-008-0372-5
   Indriani O.R., IEEE, DOI DOI 10.1109/INNOCIT.2017.8319133
   Jain S., 2013, Int J Comput Sci Eng Technol (IJCSET), V4, P7
   Joshi J, 2010, P INT C COMP TECHN, V2, DOI [10.47893/IJCCT.2012.1118, DOI 10.47893/IJCCT.2012.1118]
   Monica KM, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5422428
   Rajesh T, 2019, CLUSTER COMPUT, V22, P13853, DOI 10.1007/s10586-018-2111-5
   Sivanandam SN, 1993, Principle of soft computing, P74
   Vijh S, 2020, LECT NOTE DATA ENG, V32, P171, DOI 10.1007/978-3-030-25797-2_8
   Xie J, 2005, IEEE T MED IMAGING, V24, P45, DOI 10.1109/TMI.2004.837792
NR 20
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17108-9
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800020
DA 2024-07-18
ER

PT J
AU Khan, ZA
   Raja, HA
   Chaudhary, NI
   Iqbal, S
   Mehmood, K
   Raja, MAZ
AF Khan, Zeshan Aslam
   Raja, Hafiz Anis
   Chaudhary, Naveed Ishtiaq
   Iqbal, Sumbal
   Mehmood, Khizer
   Raja, Muhammad Asif Zahoor
TI RP-SWSGD: Design of sliding window stochastic gradient descent method
   with user's ratings pattern for recommender systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Recommender systems; Sliding window; E-Commerce; Matrix factorization;
   Stochastic gradient descent
AB To offer relevant and useful recommendations, the crucial role of recommender systems in e-commerce industry is to predict the users' concern for various items by estimating items' attributes and users' preferences. The reliability of a recommender system is usually assessed through accuracy and speed of relevant recommendations for a variety of items. The matrix factorization-based stochastic gradient descent (SGD) methods proposed by researchers lack memory needed to capture the ratings history hidden in the previous iterations. Recently, sliding window-based SGD strategies designed for Recommender systems and Hammerstein nonlinear systems gained attention due to the improved performance in terms of convergence speed and estimated accuracy. The memory impact with regard to the historical information enhances the performance of sliding window-based SGD techniques. However, sliding window-based methods are deficient in capturing the ratings history based on the users' rating patterns. Hence utilizing the same window length for the set of observed ratings rated by users. Therefore, we propose an improved sliding window-based SGD strategy to acquire historical information of the ratings with respect to a user's rating patterns for efficient matrix factorization of recommender systems. The proposed strategy performs significantly by accomplishing fast convergence speed and accuracy for window sizes greater than 1. The accuracy of the suggested technique is verified for two benchmark datasets such as ML-100 K and Film-Trust. However, the authenticity of the proposed method as compared to the standard counterpart (window size = 1) is confirmed through Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE). The average improvements achieved by the proposed strategy in terms of RMSE and MAE over the baseline for ML-100 K dataset are 0.726% and 2.245% respectively. Whereas the proposed method accomplishes considerable average improvement of 7.89% and 9.41% for RMSE and MAE with FilmTrust dataset respectively.
C1 [Khan, Zeshan Aslam; Raja, Hafiz Anis; Iqbal, Sumbal; Mehmood, Khizer] Int Islamic Univ, Dept Elect & Comp Engn, Islamabad, Pakistan.
   [Chaudhary, Naveed Ishtiaq; Raja, Muhammad Asif Zahoor] Natl Yunlin Univ Sci & Technol, Future Technol Res Ctr, 123 Univ Rd,Sect 3, Touliu 64002, Yunlin, Taiwan.
C3 International Islamic University, Pakistan; National Yunlin University
   Science & Technology
RP Chaudhary, NI (corresponding author), Natl Yunlin Univ Sci & Technol, Future Technol Res Ctr, 123 Univ Rd,Sect 3, Touliu 64002, Yunlin, Taiwan.
EM zeeshan.aslam@iiu.edu.pk; anis.msee137@iiu.edu.pk;
   chaudni@yuntech.edu.tw; sumbal.iqbal@iiu.edu.pk;
   khizer.mehmood@iiu.edu.pk; rajamaz@yuntech.edu.tw
RI Raja, Muhammad Asif Zahoor/D-7325-2013; mehmood, khizer/AAM-3805-2020
OI Raja, Muhammad Asif Zahoor/0000-0001-9953-822X; mehmood,
   khizer/0000-0002-4278-6166
CR Aggarwal Charu C., 2016, Recommender systems, V1
   Ahamed M. T., 2019, 2nd Int Conf Electr Comput Commun Eng ECCE, P1
   Ahmadian S, 2020, KNOWL-BASED SYST, V192, DOI 10.1016/j.knosys.2019.105371
   Alhijawi Bushra, 2020, International Journal of Advanced Intelligence Paradigms, V15, P229
   Alhijawi B, 2023, MULTIMED TOOLS APPL, V82, P32421, DOI 10.1007/s11042-023-14728-z
   Altschuler JM., 2022, Advances in Neural Information Processing Systems, V35, P3788
   Aslam MS, 2017, NONLINEAR DYNAM, V87, P519, DOI 10.1007/s11071-016-3058-9
   Aslanian E., 2016, IEEE Transactions on Industrial Informatics, DOI DOI 10.1109/TII.2016.2631138
   Bell RM, 2007, IEEE DATA MINING, P43, DOI 10.1109/ICDM.2007.90
   Ben Schafer J, 2001, DATA MIN KNOWL DISC, V5, P115, DOI 10.1023/A:1009804230409
   Bergamo D, 2022, ECOL ECON, V199, DOI 10.1016/j.ecolecon.2022.107448
   Boyko N., 2021, CEUR Workshop Proc, V2870, P1878
   Chaudhary NI, 2022, CHAOS SOLITON FRACT, V163, DOI 10.1016/j.chaos.2022.112611
   Chaudhary NI, 2023, MATH METHOD APPL SCI, V46, P7013, DOI 10.1002/mma.8951
   Chen P, 2020, PROCEEDINGS OF THE 1ST INTERNATIONAL CONFERENCE ON DEEP LEARNING THEORY AND APPLICATIONS (DELTA), P89, DOI 10.5220/0009885600890097
   Chen R, 2018, IEEE ACCESS, V6, P64301, DOI 10.1109/ACCESS.2018.2877208
   Chen Y, 2023, MATH COMPUT SIMULAT, V206, P410, DOI 10.1016/j.matcom.2022.11.019
   Chin WS., 2015, A learning-rate schedule for stochastic gradient methods to matrix factorization
   Colace F, 2022, CONNECT SCI, V34, P2158, DOI 10.1080/09540091.2022.2106943
   Cunha T, 2018, INFORM SCIENCES, V423, P128, DOI 10.1016/j.ins.2017.09.050
   De Handschutter P, 2021, COMPUT SCI REV, V42, DOI 10.1016/j.cosrev.2021.100423
   Dozat T., 2016, INT C LEARN REPR WOR, P1
   Furtado F., 2020, Int. J. Res. Ind. Eng, V9, P84, DOI DOI 10.22105/RIEJ.2020.226178.1128
   Goyani M., 2020, ELCVIA Electron. Lett. Comput. Vis. Image Anal, V19, P18
   Guo GB, 2016, ACM T WEB, V10, DOI [10.1145/2996465, 10.1145/2856037]
   Guo X, 2019, IEEE ACCESS, V7, P11349, DOI 10.1109/ACCESS.2019.2891544
   Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872
   He HJ, 2022, NEURAL COMPUT APPL, V34, P9759, DOI 10.1007/s00521-022-06963-6
   Hernandez-Lobato JM., 2014, 31st Int Conf Mach Learn ICML, V2014, P3394
   Huang CL, 2014, KNOWL-BASED SYST, V56, P86, DOI 10.1016/j.knosys.2013.11.001
   Jannach D, 2019, ACM TRANS MANAG INF, V10, DOI 10.1145/3370082
   Jiang LL, 2019, J AMB INTEL HUM COMP, V10, P3023, DOI 10.1007/s12652-018-0928-7
   Jin C, 2016, 30 C NEUR INF PROC S
   Jing SX, 2023, MATH COMPUT SIMULAT, V207, P288, DOI 10.1016/j.matcom.2022.12.031
   Karimi M, 2018, INFORM PROCESS MANAG, V54, P1203, DOI 10.1016/j.ipm.2018.04.008
   Khan ZA, 2022, CHAOS SOLITON FRACT, V160, DOI 10.1016/j.chaos.2022.112204
   Khan ZA, 2022, INT J FUZZY SYST, V24, P686, DOI 10.1007/s40815-021-01177-9
   Khan ZA, 2019, IEEE ACCESS, V7, P141287, DOI 10.1109/ACCESS.2019.2940603
   Khan ZA, 2020, NEURAL COMPUT APPL, V32, P10245, DOI 10.1007/s00521-019-04562-6
   Khanal SS, 2020, EDUC INF TECHNOL, V25, P2635, DOI 10.1007/s10639-019-10063-9
   Kingma D. P., 2014, arXiv
   Köhler S, 2016, ELECTRON MARK, V26, P369, DOI 10.1007/s12525-016-0232-3
   Kulkarni PV., 2020, Recommender system in elearning: a survey, P119
   Kumar N, 2023, VIETNAM J COMPUT SCI, V10, P159, DOI 10.1142/S2196888822500361
   Kumar V, 2017, INFORM SCIENCES, V380, P1, DOI 10.1016/j.ins.2016.11.003
   Kywe SM, 2012, LECT NOTES COMPUT SC, V7710, P420, DOI 10.1007/978-3-642-35386-4_31
   Luo X, 2012, KNOWL-BASED SYST, V27, P271, DOI 10.1016/j.knosys.2011.09.006
   Madani Y, 2023, MULTIMED TOOLS APPL, V82, P27819, DOI 10.1007/s11042-023-14514-x
   Nasiri E, 2023, MULTIMED TOOLS APPL, V82, P3745, DOI 10.1007/s11042-022-12943-8
   Reddi S. J., 2018, INT C LEARN REPR
   Rustam F, 2022, MULTIMED TOOLS APPL, V81, P31929, DOI 10.1007/s11042-022-12897-x
   Salter J, 2006, IEEE INTELL SYST, V21, P35, DOI 10.1109/MIS.2006.4
   Samadianfard S, 2022, NEURAL COMPUT APPL, V34, P3033, DOI 10.1007/s00521-021-06550-1
   Sun RY, 2016, IEEE T INFORM THEORY, V62, P6535, DOI 10.1109/TIT.2016.2598574
   Sun X, 2023, PATTERN RECOGN, V138, DOI 10.1016/j.patcog.2022.109285
   Suryawanshi S., 2020, Int J Eng Appl Sci Technol, V5, P223
   Takács G, 2009, J MACH LEARN RES, V10, P623
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26, DOI DOI 10.1007/S12654-012-0173-1
   Wang Juan, 2019, Journal of Physics: Conference Series, V1314, DOI 10.1088/1742-6596/1314/1/012078
   Wojtowytsch S, 2023, J NONLINEAR SCI, V33, DOI [10.1007/s00332-023-09992-0, 10.1007/s00332-023-09903-3]
   Wu SW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3535101
   Xue F, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3314578
   Yengikand AK, 2023, MULTIMED TOOLS APPL, V82, P34513, DOI 10.1007/s11042-023-15021-9
NR 63
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17258-w
EA OCT 2023
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800010
DA 2024-07-18
ER

PT J
AU Mirza, FK
   Gürsoy, AF
   Baykas, T
   Hekimoglu, M
   Pekcan, O
AF Mirza, Fuat Kaan
   Gursoy, Ahmet Fazil
   Baykas, Tuncer
   Hekimoglu, Mustafa
   Pekcan, Onder
TI Residual LSTM neural network for time dependent consecutive pitch string
   recognition from spectrograms: a study on Turkish classical music makams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Musical information retrieval; Pitch sequence recognition; Modal music;
   Spectrogram; Residual LSTM neural network
ID GENRE CLASSIFICATION; SYSTEM
AB Turkish classical music, characterized by 'makam', specific melodic configurations delineated by sequential pitches and intervals, is rich in cultural significance and poses a considerable challenge in identifying a musical piece's particular makam. This identification complexity remains an issue even for experienced musical experts, emphasizing the need for automated and accurate classification techniques. In response, we introduce a residual LSTM neural network model that classifies makams by leveraging the distinct sequential pitch patterns discerned within various audio segments over spectrogram-based inputs. This model's design uniquely merges the spatial capabilities of two-dimensional convolutional layers with the temporal understanding of one-dimensional convolutional and LSTM mechanisms embedded within a residual framework. Such an integrated approach allows for detailed temporal analysis of shifting frequencies, as revealed in logarithmically scaled spectrograms, and is adept at recognizing consecutive pitch patterns within segments. Employing stratified cross-validation on a comprehensive dataset encompassing 1154 pieces spanning 15 unique makams, we found that our model demonstrated an accuracy of 95.60% for a subset of 9 makams and 89.09% for all 15 makams. Our approach demonstrated consistent precision even when distinguishing makam pairs known for their closely related pitch sequences. To further validate our model's prowess, we conducted benchmark tests against established methodologies found in current literature, providing a comparative assessment of our proposed workflow's abilities.
C1 [Mirza, Fuat Kaan; Gursoy, Ahmet Fazil; Baykas, Tuncer; Hekimoglu, Mustafa; Pekcan, Onder] Kadir Has Univ, Fac Engn & Nat Sci, Istanbul, Turkiye.
C3 Kadir Has University
RP Mirza, FK (corresponding author), Kadir Has Univ, Fac Engn & Nat Sci, Istanbul, Turkiye.
EM 20161905006@stu.khas.edu.tr; a.fazilgursoy@gmail.com; tbaykas@ieee.org;
   mustafa.hekimoglu@khas.edu.tr; pekcan@khas.edu.tr
RI MIRZA, FUAT KAAN/JJC-1595-2023; PEKCAN, Onder/Y-3158-2018
OI MIRZA, FUAT KAAN/0000-0002-7664-0632; Baykas,
   Tuncer/0000-0001-9535-2102; PEKCAN, Onder/0000-0002-0082-8209
CR Akkoç C, 2002, J NEW MUSIC RES, V31, P285, DOI 10.1076/jnmr.31.4.285.14169
   Akkoc C, 2015, MUSIC PERCEPT, V32, P322, DOI 10.1525/MP.2015.32.4.322
   Allen J. B., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P1012
   Alpkocak A, 2005, 2006 15 TURK S ART I
   Alqudah AM, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03247-0
   Anguita Davide., 2012, European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning
   Araño KA, 2021, COGN COMPUT, V13, P771, DOI 10.1007/s12559-021-09865-2
   Arbelaitz O, 2013, LECT NOTES COMPUT SC, V8109, P111, DOI 10.1007/978-3-642-40643-0_12
   Arpitha Y, 2022, J AMB INTEL HUM COMP, V13, P757, DOI 10.1007/s12652-021-02926-2
   Athulya MK, 2021, P INT C IOT BAS CONT, DOI [10.2139/ssrn.3883911, DOI 10.2139/SSRN.3883911]
   Baniya BK, 2016, MULTIMED TOOLS APPL, V75, P3013, DOI 10.1007/s11042-014-2418-z
   Beken M, 2006, Maqam Traditions of Turkic Peoples
   Benetos E, 2015, J ACOUST SOC AM, V138, P2118, DOI 10.1121/1.4930187
   Berrar D., 2019, Encyclopedia of Bioinformatics and Computational Biology, P542, DOI [DOI 10.1016/B978-0-12-809633-8.20349-X, 10.1016/B978-0-12-809633-8.203 49-X]
   Bozkurt Baris, 2009, 2009 IEEE 17th Signal Processing and Communications Applications Conference (SIU), P804, DOI 10.1109/SIU.2009.5136518
   Bozkurt B, 2015, J MATH MUSIC, V9, P1, DOI 10.1080/17459737.2014.927012
   Bozkurt B, 2014, J NEW MUSIC RES, V43, P375, DOI 10.1080/09298215.2014.924535
   Calvo-Zaragoza J, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3397499
   Calvo-Zaragoza J, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8040606
   Cheuk KW, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3918, DOI 10.1145/3474085.3475405
   Choi K, 2018, EUR SIGNAL PR CONF, P1870, DOI 10.23919/EUSIPCO.2018.8553106
   Choi K, 2017, INT CONF ACOUST SPEE, P2392, DOI 10.1109/ICASSP.2017.7952585
   Cholevas M, 2014, Mikrotonalitat-Praxis und Utopie, P197
   Chollet F, 2015, KERAS
   COHEN L, 1989, P IEEE, V77, P941, DOI 10.1109/5.30749
   Cornelis O, 2010, SIGNAL PROCESS, V90, P1008, DOI 10.1016/j.sigpro.2009.06.020
   Cortes C., 2012, P 25 C UNC ART INT U, DOI DOI 10.48550/ARXIV.1205.2653
   Costa YMG, 2017, APPL SOFT COMPUT, V52, P28, DOI 10.1016/j.asoc.2016.12.024
   de Cheveigné A, 2005, SPR HDB AUD, V24, P169
   Demirel E, 2018, Proceedings of the 8th International Workshop on Folk Music Analysis, P19
   DEUTSCH D, 1982, PERCEPT PSYCHOPHYS, V31, P407, DOI 10.3758/BF03204849
   Dieleman Sander, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6964, DOI 10.1109/ICASSP.2014.6854950
   Downie JS, 2003, ANNU REV INFORM SCI, V37, P295, DOI 10.1002/aris.1440370108
   Eck D, 2002, NEURAL NETWORKS FOR SIGNAL PROCESSING XII, PROCEEDINGS, P747, DOI 10.1109/NNSP.2002.1030094
   Estabrooks A, 2004, COMPUT INTELL-US, V20, P18, DOI 10.1111/j.0824-7935.2004.t01-1-00228.x
   Fong H, 2021, A theory-based interpretable deep learning architecture for music emotion, DOI [10.2139/ssrn.4025386, DOI 10.2139/SSRN.4025386]
   Gedik AC, 2009, J NEW MUSIC RES, V38, P103, DOI 10.1080/09298210903171152
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Hammarlund A, 2001, Sufism, music and society in Turkey and the Middle East, DOI [10.4324/9780203346976, DOI 10.4324/9780203346976]
   Han KP, 1998, IEEE T CONSUM ELECTR, V44, P33, DOI 10.1109/30.663728
   Harmanny RIA, 2014, EUROP RADAR CONF, P165, DOI 10.1109/EuRAD.2014.6991233
   Hawkins DM, 2004, J CHEM INF COMP SCI, V44, P1, DOI 10.1021/ci0342472
   Haykin S., 1994, NEURAL NETWORKS, V2
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hernandez-Olivan C, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10070810
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   HolzapfelA BenetosE, 2019, ISMIR
   James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI [10.1007/978-1-4614-7138-7, 10.1007/978-1-4614-7138-7_1]
   Japkowicz N., 2011, EVALUATING LEARNING, DOI [10.1017/CBO9780511921803, DOI 10.1017/CBO9780511921803]
   Karaosmanoglu MK, 2012, P ISMIR
   Karim F, 2018, IEEE ACCESS, V6, P1662, DOI 10.1109/ACCESS.2017.2779939
   Kingma D. P., 2014, arXiv
   Kingma DP, 2015, ADV NEUR IN, V28
   Kizrak MA, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA 2014), P394, DOI 10.1109/INISTA.2014.6873650
   Kizrak MA, 2015, SIG PROCESS COMMUN, P527, DOI 10.1109/SIU.2015.7129877
   KLATT DH, 1973, IEEE T ACOUST SPEECH, VAU21, P210, DOI 10.1109/TAU.1973.1162453
   Kong QQ, 2020, Arxiv, DOI arXiv:2010.14805
   Kong QQ, 2020, IEEE-ACM T AUDIO SPE, V28, P2880, DOI 10.1109/TASLP.2020.3030497
   Kumaraswamy B, 2022, MULTIMED TOOLS APPL, V81, P17071, DOI 10.1007/s11042-022-12254-y
   LASKE OE, 1988, COMPUT MUSIC J, V12, P43, DOI 10.2307/3679836
   Li JX, 2022, MULTIMED TOOLS APPL, V81, P4621, DOI 10.1007/s11042-020-10465-9
   Li XQ, 2023, COGN COMPUT, V15, P23, DOI 10.1007/s12559-022-10031-5
   Lin M, 2014, Arxiv, DOI [arXiv:1312.4400, DOI 10.48550/ARXIV.1312.4400]
   Liu CF, 2021, MULTIMED TOOLS APPL, V80, P7313, DOI 10.1007/s11042-020-09643-6
   MAK Sagun, 2016, 2016 INT S INN INT S, P1, DOI [10.1109/INISTA.2016.7571850, DOI 10.1109/INISTA.2016.7571850]
   Mannor S., 2005, P 22 INT C MACH LEAR, P561
   Mao YX, 2022, COGN COMPUT, V14, P2306, DOI 10.1007/s12559-022-10039-x
   McFee B., 2015, P 14 PYTH SCI C, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/Majora-7b98e3ed-003]
   McFee B, 2016, ISMIR
   Mehta Jash, 2021, Proceedings of 5th International Conference on Computing Methodologies and Communication (ICCMC 2021), P1101, DOI 10.1109/ICCMC51019.2021.9418035
   Moorer J.A., 1977, COMPUT MUSIC J, V1, P32
   Müller M, 2011, IEEE J-STSP, V5, P1088, DOI 10.1109/JSTSP.2011.2112333
   Muller M, 2005, P 6 INT C MUSIC INFO, P288
   mus2, Mu2 Software
   Nanni L, 2018, J NEW MUSIC RES, V47, P383, DOI 10.1080/09298215.2018.1438476
   OPPENHEIM AV, 1970, IEEE SPECTRUM, V7, P57, DOI 10.1109/MSPEC.1970.5213512
   Pappas M, 2007, ITU Dergisi, V4, P33
   Pappas M, 2007, Apostolos Konstas'in Nazariyat Kitabi
   Pes B, 2021, INFORMATION, V12, DOI 10.3390/info12080286
   Petran LA, 1932, PSYCHOL MONOGR, V42, P1
   Rabiner LR, 2011, Theory and applications of digital speech processing
   Sechidis K, 2011, LECT NOTES ARTIF INT, V6913, P145, DOI 10.1007/978-3-642-23808-6_10
   Fathollahi MS, 2021, INT J MULTIMED INF R, V10, P43, DOI 10.1007/s13735-021-00206-5
   Signell KarlL., 1977, Makam: Modal Practice in Turkish Art Music
   Sokolova M, 2006, LECT NOTES COMPUT SC, V4304, P1015
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Travieso CM, 2013, COGN COMPUT, V5, P397, DOI 10.1007/s12559-013-9237-9
   Typke R., 2005, ISMIR, P153, DOI DOI 10.5281/ZENODO.1417383
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Ünal E, 2014, J NEW MUSIC RES, V43, P132, DOI 10.1080/09298215.2013.870211
   van Laarhoven T, 2017, Arxiv, DOI [arXiv:1706.05350, DOI 10.48550/ARXIV.1706.05350]
   Wang Sida, 2013, P INT C MACH LEARN, P118
   Wang ZG, 2017, IEEE IJCNN, P1578, DOI 10.1109/IJCNN.2017.7966039
   Wright Owen., 1992, Words without Songs: A Musicological Study of an Early Ottoman Anthology and its Precursors
   Ycart A, 2017, 18 INT SOC MUS INF R
   Yore S, 2012, Zeitschrift fur die Welt der Turken, V4
   Yu Y, 2019, NEURAL COMPUT, V31, P1235, DOI 10.1162/neco_a_01199
   Zuo Z, 2016, IEEE T IMAGE PROCESS, V25, P2983, DOI 10.1109/TIP.2016.2548241
NR 98
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17105-y
EA OCT 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800026
DA 2024-07-18
ER

PT J
AU Chen, YJ
   Liu, PX
   Qin, FZ
   Liu, SM
AF Chen, Yujie
   Liu, Peixue
   Qin, Fuzhen
   Liu, Shumei
TI CoCluster-DAGCN: a dynamic aggregate graph convolution network by a
   co-attention LSTM cluster for ocean temperature predictions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Ocean temperature prediction; Spatiotemporal relationship; Multiscale
   graph convolution; Dynamic aggregation strategy; Graph topology
   structure
ID SEA-SURFACE TEMPERATURE; EMPIRICAL MODE DECOMPOSITION; SATELLITE
AB Considering that ocean temperature data contain much irrelevant noise if a traditional method is used to obtain a temperature prediction, it will be difficult to encode the spatiotemporal relationship effectively, and the prediction accuracy will be poor. Therefore, we propose a dynamic graph convolution framework of collaborative attention LSTM clustering (CoCluster-DAGCN) for ocean temperature prediction. The framework first uses a coattention LSTM to remove irrelevant and redundant information and performs pruning and clustering to simplify the graph topology. Second, a multiscale graph convolutional network is used to capture further the multiscale spatiotemporal semantics of the ocean temperature data. A dynamic aggregation strategy constructs a stable spatiotemporal relationship and performs local and global-local context modeling. Additionally, the topological structure generated by the clustering of the LSTM coattention module provides maps of different scales for the dynamic aggregation graph convolution module. Finally, the experimental results show that on ARGO and SST-9 baseline data, our proposed CoCluster-DAGCN ocean temperature prediction framework achieves better performance; namely, the MAE and RMSE values of the SST-9 data are 0.3961 and 0.4316, respectively, and the MAE and RMSE values of the ARGO data are 0.2133 and 0.2811, respectively.
C1 [Chen, Yujie; Liu, Peixue; Qin, Fuzhen; Liu, Shumei] Qingdao Huanghai Univ, Qingdao 266427, Peoples R China.
RP Chen, YJ (corresponding author), Qingdao Huanghai Univ, Qingdao 266427, Peoples R China.
EM chenyujie_cc@126.com
FU key R&D project of the Shandong Provincial Department of Science and
   Technology [2017GGX201004]; Key Science and Technology Project of
   Qingdao Huanghai University [2019KJ01, 2019KJ02]
FX This study was funded by the key R&D project of the Shandong Provincial
   Department of Science and Technology (2017GGX201004) and the Key Science
   and Technology Project of Qingdao Huanghai University (2019KJ01)
   (2019KJ02).
CR Ai B, 2019, INFRARED PHYS TECHN, V99, P231, DOI 10.1016/j.infrared.2019.04.022
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Aparna SG, 2018, INT J REMOTE SENS, V39, P4214, DOI 10.1080/01431161.2018.1454623
   Baptista M, 2018, COMPUT IND ENG, V115, P41, DOI 10.1016/j.cie.2017.10.033
   Chen C, 2020, Exploring rich and efficient spatial temporal interactions for real time video salient object detection
   Fu A, 2020, OCEANS-IEEE, DOI 10.1109/IEEECONF38699.2020.9389050
   He Q, 2020, ENERGIES, V13, DOI 10.3390/en13061369
   Jin DC, 2018, Q J ROY METEOR SOC, V144, P1490, DOI 10.1002/qj.3296
   Kim YJ, 2020, CRYOSPHERE, V14, P1083, DOI 10.5194/tc-14-1083-2020
   Kug JS, 2004, GEOPHYS RES LETT, V31, DOI 10.1029/2003GL019209
   Lee DE, 2016, CLIM DYNAM, V47, P95, DOI 10.1007/s00382-015-2825-5
   Li QJ, 2017, ATMOS OCEAN SCI LETT, V10, P261, DOI 10.1080/16742834.2017.1305867
   Li Y, 2017, ISPRS Annals of Photogrammetry, Remote Sensing Spatial Information Sciences, V4
   Lin Y., 2021, Journal of Physics. Conference Series, V1880
   Lins ID, 2013, COMPUT STAT DATA AN, V61, P187, DOI 10.1016/j.csda.2012.12.003
   Liu J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113797
   Patil K, 2017, OCEAN DYNAM, V67, P357, DOI 10.1007/s10236-017-1032-9
   Patil K, 2016, J ATMOS OCEAN TECH, V33, P1715, DOI 10.1175/JTECH-D-15-0213.1
   Qiao BY, 2021, INT CONF ADV COMMUN, P342, DOI 10.23919/ICACT51234.2021.9370514
   Sithara S, 2020, ACTA GEOPHYS, V68, P1779, DOI 10.1007/s11600-020-00484-3
   Tao YQ, 2019, GEOMAT NAT HAZ RISK, V10, P768, DOI 10.1080/19475705.2018.1544595
   Usharani B, 2023, SOFT COMPUT, V27, P13129, DOI 10.1007/s00500-022-06899-y
   Wu AM, 2006, NEURAL NETWORKS, V19, P145, DOI 10.1016/j.neunet.2006.01.004
   Wu ZY, 2019, OCEAN SCI, V15, P349, DOI 10.5194/os-15-349-2019
   Xiao CJ, 2019, REMOTE SENS ENVIRON, V233, DOI 10.1016/j.rse.2019.111358
   Xu LY, 2020, REMOTE SENS LETT, V11, P611, DOI 10.1080/2150704X.2020.1746853
   Yang YT, 2018, IEEE GEOSCI REMOTE S, V15, P207, DOI 10.1109/LGRS.2017.2780843
   Yu X, 2020, Math Probl Eng, V2020, P362
   Zang L, 2019, SCI TOTAL ENVIRON, V658, P1256, DOI 10.1016/j.scitotenv.2018.12.297
   Zhang K, 2020, IEEE GEOSCI REMOTE S, V17, P1303, DOI 10.1109/LGRS.2019.2947170
   Zhang Q, 2017, IEEE GEOSCI REMOTE S, V14, P1745, DOI 10.1109/LGRS.2017.2733548
NR 34
TC 0
Z9 0
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 10
PY 2023
DI 10.1007/s11042-023-15768-1
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3VG2
UT WOS:001077290900001
DA 2024-07-18
ER

PT J
AU Song, SS
   Jia, ZH
   Shi, F
   Wang, JN
   Yang, J
   Kasabov, N
AF Song, Sensen
   Jia, Zhenhong
   Shi, Fei
   Wang, Junnan
   Yang, Jie
   Kasabov, Nikola
TI Saliency optimization fused background feature with frequency domain
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Salient object detection; Background feature; Frequency domain feature;
   Self-attention mechanism; Fusion algorithm
ID OBJECT DETECTION
AB In the non-deep learning-based salient object detection methods known so far, the detection effect and robustness based on the background detection method are good. However, results are not desirable in small objects and complex scene images. This paper proposes a salient object detection algorithm, which employs a fusion framework to fuse background and frequency domain features to improve the accuracy of salient object detection. First, an improved background model is proposed for salient object detection to extract the background feature of the image. Simultaneously, the frequency domain features are obtained by the proposed frequency domain algorithm, which combines global information and local details by the Gaussian pyramid algorithm and different filters. Then, within our fusion framework, the fusion operations are guided by the self-attention mechanism to fuse background and multi-scale frequency domain features to obtain the self-attention maps. Finally, this paper introduces a fusion algorithm to derive the final saliency map from the self-attention maps. The results demonstrate that the proposed method consistently outperforms state-of-the-art approaches in four evaluation metrics on six challenging and complicated datasets and improves the accuracy of salient object detection in complex and small object scene images.
C1 [Song, Sensen; Jia, Zhenhong; Shi, Fei; Wang, Junnan] Xinjiang Univ, Coll Informat Sci & Engn, Key Lab Signal Detect & Proc, Urumqi 830046, Peoples R China.
   [Song, Sensen] Xinjiang Univ, Coll Math & Syst Sci, Urumqi, Xinjiang, Peoples R China.
   [Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200400, Peoples R China.
   [Kasabov, Nikola] Auckland Univ Technol, Knowledge Engn & Discovery Res Inst, Auckland 1020, New Zealand.
   [Kasabov, Nikola] Ulster Univ, George Moore Chair Data Analyt, Maggy BT48 7JL, North Ireland.
C3 Xinjiang University; Xinjiang University; Shanghai Jiao Tong University;
   Auckland University of Technology; Ulster University
RP Jia, ZH (corresponding author), Xinjiang Univ, Coll Informat Sci & Engn, Key Lab Signal Detect & Proc, Urumqi 830046, Peoples R China.
EM jzhh@xju.edu.cn
RI Kasabov, Nikola Kirilov/JQJ-5530-2023
FU This research was funded by the National Natural Science Foundation of
   China with Grant U1803261 and 62261053, and Scientific research plan of
   universities in Xinjiang Uygur Autonomous Region under grant
   XJEDU2019Y006. [U1803261, 62261053]; National Natural Science Foundation
   of China [XJEDU2019Y006]; Scientific research plan of universities in
   Xinjiang Uygur Autonomous Region
FX This research was funded by the National Natural Science Foundation of
   China with Grant U1803261 and 62261053, and Scientific research plan of
   universities in Xinjiang Uygur Autonomous Region under grant
   XJEDU2019Y006.
CR Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P742, DOI 10.1109/TIP.2014.2383320
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen SH, 2020, IEEE T IMAGE PROCESS, V29, P3763, DOI 10.1109/TIP.2020.2965989
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Elder, 2010, P IEEE C COMP VIS PA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   Gu YC, 2020, AAAI CONF ARTIF INTE, V34, P10869
   Guo CL, 2008, PROC CVPR IEEE, P2908
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hou XD, 2007, PROC CVPR IEEE, P2280
   Huo L, 2019, MULTIMED TOOLS APPL, V78, P1635, DOI 10.1007/s11042-018-6249-1
   Jia-Ying WU, 2019, Computer Science
   Kim KS, 2013, I SYMP CONSUM ELECTR, P259
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li CP, 2019, MACH VISION APPL, V30, P397, DOI 10.1007/s00138-018-0995-y
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li JY, 2021, IEEE T CYBERNETICS, V51, P3925, DOI 10.1109/TCYB.2020.3008280
   Li WP, 2020, IET IMAGE PROCESS, V14, P4039, DOI 10.1049/iet-ipr.2020.0773
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306
   Li XR, 2003, IEEE T AERO ELEC SYS, V39, P1333, DOI 10.1109/TAES.2003.1261132
   Liu ST, 2019, Arxiv, DOI arXiv:1911.09516
   Liu Z, 2019, IEEE ACCESS, V7, P89687, DOI 10.1109/ACCESS.2019.2926571
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Pillai MS, 2021, SOFT COMPUT, V25, P11929, DOI 10.1007/s00500-021-05576-w
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Ramsey JD, 2014, NEUROIMAGE, V84, P986, DOI 10.1016/j.neuroimage.2013.09.062
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Shoujia Wang, 2012, Journal of Multimedia, V7, P429, DOI 10.4304/jmm.7.6.429-433
   Song SS, 2022, INFORM SCIENCES, V618, P53, DOI 10.1016/j.ins.2022.10.103
   Tong N, 2015, PATTERN RECOGN, V48, P3258, DOI 10.1016/j.patcog.2014.12.005
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang CJ, 2020, IEEE T IND INFORM, V16, P2667, DOI 10.1109/TII.2019.2945362
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang WG, 2022, IEEE T PATTERN ANAL, V44, P3239, DOI 10.1109/TPAMI.2021.3051099
   Wang WG, 2016, IEEE T IMAGE PROCESS, V25, P5025, DOI 10.1109/TIP.2016.2601784
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Xu QZ, 2019, SOFT COMPUT, V23, P9413, DOI 10.1007/s00500-018-3608-9
   Xu QZ, 2019, PHYSICA A, V531, DOI 10.1016/j.physa.2019.121808
   Xu QZ, 2019, IMAGE VISION COMPUT, V87, P1, DOI 10.1016/j.imavis.2019.04.002
   Yan YJ, 2018, PATTERN RECOGN, V79, P65, DOI 10.1016/j.patcog.2018.02.004
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yuan YC, 2018, IEEE T IMAGE PROCESS, V27, P1311, DOI 10.1109/TIP.2017.2762422
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang ZP, 2019, LECT NOTES COMPUT SC, V11935, P517, DOI 10.1007/978-3-030-36189-1_43
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 54
TC 0
Z9 0
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 9
PY 2023
DI 10.1007/s11042-023-16760-5
EA OCT 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2OJ4
UT WOS:001083245400003
DA 2024-07-18
ER

PT J
AU Jitani, N
   Singha, BJ
   Barman, G
   Talukdar, A
   Sarmah, R
   Bhattacharyya, DK
AF Jitani, Nitya
   Singha, Bhaskar Jyoti
   Barman, Geetanjali
   Talukdar, Abhijit
   Sarmah, Rosy
   Bhattacharyya, Dhruba Kumar
TI Medical image segmentation using automated rough density approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE CT scan images; Density based clustering; Gallbladder; Medical image
   segmentation; Ultrasonography images
ID GALLBLADDER
AB Delineation of Gallbladder (GB) and identification of gallstones from Computed Tomography (CT) and Ultrasonography (USG) images is an essential step in the radiomic analysis of Gallbladder Cancer (GBC). In this study, we devise a method for effective segmentation of GB from 2D CT images and Gallstones from USG images, by introducing a Rough Density based Segmentation (RDS) method. Based on the threshold value obtained using rough entropy thresholding, the image is thresholded and passed as an input to the RDS method to obtain the desired segmented regions. To evaluate the performance of RDS method, we collected images from 30 patients exhibiting normal GB and 8 patients with gallstones. Additionally, the versatility of our RDS method has also been tested for segmenting lungs from a publicly available Covid-19 lung CT image dataset with cohort size of 20 patients. Our method has been compared with several well-known methods like hybrid fuzzy clustering, morphological active contour without edges, modified fuzzy c means and morphological geodesic active contours and found to give significantly better results with reference to Jaccard coefficient, Dice coefficient, accuracy, precision, sensitivity, specificity and McNemar's test.
C1 [Jitani, Nitya; Singha, Bhaskar Jyoti; Sarmah, Rosy; Bhattacharyya, Dhruba Kumar] Tezpur Univ, Dept Comp Sci & Engn, Tezpur, Assam, India.
   [Barman, Geetanjali] Dr B Borooah Canc Inst, Dept Radiol, Gauhati, Assam, India.
   [Talukdar, Abhijit] Dr B Borooah Canc Inst, Dept Surg Oncol, Gauhati, Assam, India.
C3 Tezpur University; Tata Memorial Centre (TMC); Dr. Bhubaneswar Borooah
   Cancer Institute; Tata Memorial Centre (TMC); Dr. Bhubaneswar Borooah
   Cancer Institute
RP Sarmah, R (corresponding author), Tezpur Univ, Dept Comp Sci & Engn, Tezpur, Assam, India.
EM jitani@tezu.ernet.in; cse22011@tezu.ac.in; geetanjali.barman@bbci.in;
   abhijit.talukdar@bbci.in; rosy8@tezu.ernet.in; dkb@tezu.ernet.in
RI Sarmah, Rosy/R-4375-2017
OI Sarmah, Rosy/0000-0003-2564-426X
FU ICMR
FX This work is an output of the research project titled "Radiomics with
   Machine Learning methodstowards Prediction of Gallbladder Cancer" funded
   by ICMR.
CR Abd Elaziz M, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0244416
   Arora K., 2018, Handbook of Research on Advanced Concepts in Real-time Image and Video Processing, P28, DOI 10.4018/978-1-5225-2848-7.ch002
   Ashfaq A, 2017, IFMBE PROC, V62, P531, DOI 10.1007/978-981-10-4166-2_81
   Bandyopadhyay Oishila, 2013, Pattern Recognition and Machine Intelligence. 5th International Conference, PReMI 2013. Proceedings: LNCS 8251, P465, DOI 10.1007/978-3-642-45062-4_64
   Baratloo A, 2015, EMERGENCY, V3, P48
   Bhattacharjee PK., 2018, J Med Sci, V38, P197
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chopra J, 2016, 2 INT C INNOVATIVE T
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   DS Maini and Ashwani Kumar Aggarwal, 2018, INT J INNOV ENG TECH, V10, P199, DOI DOI 10.21172/IJIET.102.29
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Gao Y, 2011, INT J REMOTE SENS, V32, P3747, DOI 10.1080/01431161003777189
   Glick Y, 2020, Viewing Playlist: COVID-19 Pneumonia
   Gu K, 2021, IEEE T NEUR NET LEAR, V32, P4278, DOI 10.1109/TNNLS.2021.3105394
   Gu K, 2021, IEEE T IND INFORM, V17, P2261, DOI 10.1109/TII.2020.2991208
   Gu K, 2020, IEEE T MULTIMEDIA, V22, P311, DOI 10.1109/TMM.2019.2929009
   Huang YP, 2020, IEEE ACCESS, V8, P25041, DOI 10.1109/ACCESS.2020.2969806
   Inbarani HH, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010188
   Jaccard P., 1912, New Phytologist, V11, P37, DOI [10.1111/j.1469-8137.1912.tb05611.x, DOI 10.1111/J.1469-8137.1912.TB05611.X]
   Jitani N., 2022, Advanced Computational Paradigms and Hybrid Intelligent Computing: Proceedings of ICACCP 2021. Advances in Intelligent Systems and Computing (1373), P651, DOI 10.1007/978-981-16-4369-9_62
   Jun Ma, 2020, Zenodo, DOI 10.5281/ZENODO.3757476
   Kapoor VK, 2007, J HEPATO-BILIARY-PAN, V14, P366, DOI 10.1007/s00534-006-1189-y
   Lei B, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105687
   Lian J, 2017, INT J COMPUT ASS RAD, V12, P553, DOI 10.1007/s11548-016-1515-z
   Powers DMW, 2020, Arxiv, DOI arXiv:2010.16061
   Márquez-Neila P, 2014, IEEE T PATTERN ANAL, V36, P2, DOI 10.1109/TPAMI.2013.106
   Nixon MS, 2020, Image processing, V3, P1, DOI [10.1016/B978-0-12-814976-8.00003-8, DOI 10.1016/B978-0-12-814976-8.00003-8]
   Paiva O, 2020, CORONACASES.ORG-helping radiologists to help people in more than 100 countries, coronavirus cases
   Pal SK, 2005, PATTERN RECOGN LETT, V26, P2509, DOI 10.1016/j.patrec.2005.05.007
   Prasad RK, 2023, EXPERT SYST APPL, V227, DOI 10.1016/j.eswa.2023.120250
   Sagheer SVM, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102036
   Srikanth R, 2021, AIN SHAMS ENG J, V12, P1, DOI 10.1016/j.asej.2020.09.003
   Stinton LM, 2012, GUT LIVER, V6, P172, DOI 10.5009/gnl.2012.6.2.172
   Taha AA, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0068-x
   Tan L., 2019, Image processing basics, DOI [10.1016/b978-0-12-815071-9.00013-0, DOI 10.1016/B978-0-12-815071-9.00013-0]
   Thukral R, 2022, P INT C REC TRENDS C, P827, DOI DOI 10.1007/978-981-16-7118-0_70
   Thukral R, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT COMMUNICATION AND COMPUTATIONAL TECHNIQUES (ICCT), P161, DOI [10.1109/icct46177.2019.8969036, 10.1109/ICCT46177.2019.8969036]
   Xian M., 2018, Infinite Study
   Yang YY, 2019, THIRD INTERNATIONAL SYMPOSIUM ON IMAGE COMPUTING AND DIGITAL MEDICINE (ISICDM 2019), P222, DOI 10.1145/3364836.3364880
   Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015
   Zhang HW, 2020, Arxiv, DOI arXiv:1910.07787
   Zhang W, 2017, PloS one, V12, P290
   Zhou J, 2010, INT CONF BIOMED, P536, DOI 10.1109/BMEI.2010.5639989
   Zhu JL, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P224, DOI 10.1109/CISP.2013.6743991
   Zimmer C., 2021, The Secret Life of a Coronavirus-An oily, 100-nanometer-wide bubble of genes has killed more than two million people and reshaped the world. Scientists don't quite know what to make of it
NR 45
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 5
PY 2023
DI 10.1007/s11042-023-16921-6
EA OCT 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ4I6
UT WOS:001156484900008
DA 2024-07-18
ER

PT J
AU Srivastava, M
   Meena, J
AF Srivastava, Meenakshi
   Meena, Jasraj
TI Plant leaf disease detection and classification using modified transfer
   learning models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Smart Agriculture; Plant leaf disease detection; Transfer Learning; Deep
   Learning
ID NEURAL-NETWORK; SMART AGRICULTURE; IDENTIFICATION
AB Agriculture is a dominating field that plays an essential role in the economic development of any country. In India, agriculture contributes about 17% of the total GDP. But, decreasing land under agriculture has become a prominent problem harming both, the economy and the interest of farmers. Alongside, every year farmers face many difficulties; one such is leaf disease problems. The farmers use unscientific approaches to identify leaf disease, which is a time-consuming process. This can be tackled by using plant disease detection and classification system based on ML and DL. Many researchers have used ML techniques to detect plant diseases, but most of them do not solve overfitting and testing problem. This paper initially proposes plant leaf disease detector and classifier framework using DL. Then these five Deep Convolutional Neural Network models (Vgg16, MobileNetV2, Xception, InceptionV3, and DenseNet121) are used to detect and classify plant diseases. Two datasets have been considered; First from Mendeley (plant leaf dataset), having 4590 leaf images split into twenty-two classes. Second from PlantVillage (Cherry Dataset), having 2052 leaf images split into two classes. Further, apply pre-processing techniques such as data augmentation, resizing, and rescaling to remove the problem of overfitting. Then testing and training of the proposed models have been on leaf images. To evaluate the quality and quantity of proposed models, quality matrix has been used, and the result shows that for dataset1, MobileNetV2 outperforms other existing models with 98.9% accuracy. For the Cherry Dataset, DenseNet121 outperforms other existing models with 99.9% accuracy.
C1 [Srivastava, Meenakshi] DTU, Dept Informat Technol, New Delhi, India.
   [Meena, Jasraj] JNU, Sch Comp & Syst Sci, New Delhi, India.
C3 Delhi Technological University
RP Meena, J (corresponding author), JNU, Sch Comp & Syst Sci, New Delhi, India.
EM meenakshisrivastava_2k21phdit03@dtu.ac.in; jasrajengg@gmail.com
CR Abbas A, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106279
   Ahmad M, 2021, IEEE ACCESS, V9, P140565, DOI 10.1109/ACCESS.2021.3119655
   Ahmed I, 2021, IEEE Trans Industr Inform, P1
   Alatawi AA, 2022, Plant Disease Detection using AI based VGG-16 Model
   Ali-Al-Alvy M, 2023, 7 INT C TRENDS ELECT, P1244, DOI [10.1109/ICOEI56765.2023.10126031, DOI 10.1109/ICOEI56765.2023.10126031]
   Andrew J, 2022, AGRONOMY-BASEL, V12, DOI 10.3390/agronomy12102395
   [Anonymous], Convolutional Neural Networks for Visual Recognition
   Basavaiah J, 2020, WIRELESS PERS COMMUN, V115, P633, DOI 10.1007/s11277-020-07590-x
   Bisogni C, 2022, IEEE T IND INFORM, V18, P5619, DOI 10.1109/TII.2022.3141400
   Boursianis AD, 2022, INTERNET THINGS-NETH, V18, DOI 10.1016/j.iot.2020.100187
   Neto JBC, 2019, INT CONF BIOMETR
   Chao XF, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11104614
   Chatterjee PS, 2021, IEEE T CONSUM ELECTR, V67, P257, DOI 10.1109/TCE.2021.3128236
   Chouhan SS, 2019, IEEE
   Enkvetchakul P., 2021, APPL SCI ENG PROG, V15, P3810, DOI [10.14416/j.asep.2021.01.003, DOI 10.14416/J.ASEP.2021.01.003]
   Garg G, 2023, IEEE INTERNET THINGS, V10, P2840, DOI 10.1109/JIOT.2021.3109019
   Gonzalez-Huitron V, 2021, COMPUT ELECTRON AGR, V181, DOI 10.1016/j.compag.2020.105951
   Hughes D.P., 2015, An open access repository of images on plant health to enable the development of mobile disease diagnostics
   Jha NK, 2023, P 2023 3 INT C INNOV, DOI [10.1109/ICIPTM57143.2023.10118290, DOI 10.1109/ICIPTM57143.2023.10118290]
   Joseph DS, 2023, MULTIMED TOOLS APPL, V82, P21415, DOI 10.1007/s11042-022-14004-6
   Karar ME, 2022, ALEX ENG J, V61, P5309, DOI 10.1016/j.aej.2021.10.050
   Karthickmanoj R, 2021, MATER TODAY-PROC, V47, P1887, DOI 10.1016/j.matpr.2021.03.651
   Khalil RA, 2021, IEEE INTERNET THINGS, V8, P11016, DOI 10.1109/JIOT.2021.3051414
   Khattak A, 2021, IEEE ACCESS, V9, P112942, DOI 10.1109/ACCESS.2021.3096895
   Kulkarni Pranesh, 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.10698
   Kumar M, 2021, IEEE SENS J, V21, P17455, DOI 10.1109/JSEN.2020.3046295
   Kundu N, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165386
   Li YT, 2023, IMAGE VISION COMPUT, V136, DOI 10.1016/j.imavis.2023.104726
   Liu S, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14133232
   Liu S, 2021, IEEE T FUZZY SYST, V29, P90, DOI 10.1109/TFUZZ.2020.3006520
   Mishra M, 2021, J AMB INTEL HUM COMP, V12, P691, DOI 10.1007/s12652-020-02051-6
   Morais R, 2019, COMPUT ELECTRON AGR, V162, P882, DOI 10.1016/j.compag.2019.05.028
   Nagasubramanian G, 2021, IEEE INTERNET THINGS, V8, P12847, DOI 10.1109/JIOT.2021.3072908
   Nalini S, 2021, CMC-COMPUT MATER CON, V68, P1117, DOI 10.32604/cmc.2021.012431
   NMR. SS and UMB, 2019, P 3 INT C ELECT COMM, P12
   Orchi H, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12010009
   Ouhami M, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13132486
   Prabu M, 2022, NEURAL COMPUT APPL, V34, P7311, DOI 10.1007/s00521-021-06726-9
   Rezk NG, 2021, MULTIMED TOOLS APPL, V80, P773, DOI 10.1007/s11042-020-09740-6
   Roy S., 2021, Data Analytics in Bioinformatics, P109
   Roy SK, 2021, IEEE INTERNET THINGS, V8, P5023, DOI 10.1109/JIOT.2020.3036126
   Russel NS, 2022, NEURAL COMPUT APPL, V34, P19217, DOI 10.1007/s00521-022-07521-w
   Saha R, 2021, IEEE INTERNET THINGS, V8, P8456, DOI 10.1109/JIOT.2020.3046509
   Saleem MH, 2020, PLANTS-BASEL, V9, DOI 10.3390/plants9111451
   Samie F, 2019, IEEE INTERNET THINGS, V6, P4921, DOI 10.1109/JIOT.2019.2893866
   Sengar N, 2018, COMPUTING, V100, P1189, DOI 10.1007/s00607-018-0638-1
   Shaha Manali, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P656, DOI 10.1109/ICECA.2018.8474802
   Sharma A, 2022, COMPUT IND ENG, V165, DOI 10.1016/j.cie.2022.107936
   Shorten C, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00492-0
   Shrivastava VK, 2021, J PLANT PATHOL, V103, P17, DOI 10.1007/s42161-020-00683-3
   Singh UP, 2019, IEEE ACCESS, V7, P43721, DOI 10.1109/ACCESS.2019.2907383
   Sinha BB, 2022, FUTURE GENER COMP SY, V126, P169, DOI 10.1016/j.future.2021.08.006
   Stevens JD., 2018, 2018 2 INT C SMART G
   Sujatha R, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103615
   Tan JW, 2020, IEEE ACM T COMPUT BI, V17, P82, DOI 10.1109/TCBB.2018.2848653
   Pham TN, 2020, IEEE ACCESS, V8, P189960, DOI 10.1109/ACCESS.2020.3031914
   Udutalapally V, 2021, IEEE SENS J, V21, P17525, DOI 10.1109/JSEN.2020.3032438
   V V., 2022, INT C APPL ART INT C, P885, DOI DOI 10.1109/ICAAIC53929.2022.9792736
   Varshney D., 2022, 2022 3 INT C EMERGIN, P1, DOI [10.1109/INCET54531.2022.9824653, DOI 10.1109/INCET54531.2022.9824653]
   Zhang KK, 2019, INT J AGRIC ENVIRON, V10, P98, DOI 10.4018/IJAEIS.2019040105
   Zhu NY, 2018, INT J AGR BIOL ENG, V11, P32, DOI 10.25165/j.ijabe.20181104.4475
NR 61
TC 2
Z9 2
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 5
PY 2023
DI 10.1007/s11042-023-16929-y
EA OCT 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ4I6
UT WOS:001156484900018
DA 2024-07-18
ER

PT J
AU Gera, UK
   Agrawal, S
AF Gera, Umesh Kumar
   Agrawal, Shikha
TI Image encryption using combination of 4D discrete hyperchaotic map and
   DNA encoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image encryption; Discrete hyperchaotic map; DNA encoding
AB A novel image encryption algorithm using a combination of 4D discrete hyperchaotic map and DNA encoding is proposed in this work. The used 4D discrete hyperchaotic map has a wider chaotic range, larger Lyapunov exponent, and is more complex than existing hyperchaotic maps. In this work, the generated hyperchaotic sequence is applied to almost every phase of encryption. Here the input image is first converted into binary image sequences and these sequences are globally scrambled by the used 4D discrete hyperchaotic map. To achieve a better encryption performance and to increase the diffusion in the proposed algorithm, DNA algebraic operations (such as DNA addition and subtraction) and complementation are used in the hyperchaotic sequence. The experimental findings demonstrate that the proposed encryption technique is more secure and resistant to common threats than certain other approaches.
C1 [Gera, Umesh Kumar; Agrawal, Shikha] UIT RGPV, Dept Comp Sci & Engn, Bhopal, India.
C3 Rajiv Gandhi Technological University
RP Gera, UK (corresponding author), UIT RGPV, Dept Comp Sci & Engn, Bhopal, India.
EM geraumesh2000@gmail.com; shikha@rgtu.net
CR Arab A, 2019, J SUPERCOMPUT, V75, P6663, DOI 10.1007/s11227-019-02878-7
   Arthi G, 2022, MULTIMED TOOLS APPL, V81, P15859, DOI 10.1007/s11042-022-12598-5
   Banu SA, 2020, MED BIOL ENG COMPUT, V58, P1445, DOI 10.1007/s11517-020-02178-w
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Boriga R, 2014, SIGNAL PROCESS-IMAGE, V29, P887, DOI 10.1016/j.image.2014.04.001
   Dagadu JC, 2019, WIRELESS PERS COMMUN, V108, P591, DOI 10.1007/s11277-019-06420-z
   Guan MM, 2019, IET IMAGE PROCESS, V13, P1535, DOI 10.1049/iet-ipr.2019.0051
   Gupta MD, 2021, INTEGRATION, V81, P137, DOI 10.1016/j.vlsi.2021.07.002
   Gupta M, 2021, MULTIMED TOOLS APPL, V80, P33843, DOI 10.1007/s11042-021-11160-z
   Gupta M, 2021, MULTIMED TOOLS APPL, V80, P10391, DOI 10.1007/s11042-020-10116-z
   Hosny KM, 2022, J AMB INTEL HUM COMP, V13, P973, DOI 10.1007/s12652-021-03675-y
   Hui YY, 2023, MULTIMED TOOLS APPL, V82, P21983, DOI 10.1007/s11042-021-10526-7
   Jasra B, 2022, EXPERT SYST APPL
   Leutcho GD, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S0218127422500018
   Li XJ, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S0218127422500353
   Liu ZT, 2019, IEEE ACCESS, V7, P78367, DOI 10.1109/ACCESS.2019.2922376
   Mohamed HG, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020158
   Nestor T, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14020424
   Patro KAK, 2019, MICROSYST TECHNOL, V25, P4593, DOI 10.1007/s00542-019-04395-2
   Roy M, 2021, MICROSYST TECHNOL, V27, P3617, DOI 10.1007/s00542-020-05120-0
   Wang X., 2022, New 4d discrete hyperchaotic map and its application in image encryption
   Zhan K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013021
NR 22
TC 2
Z9 2
U1 9
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 3
PY 2023
DI 10.1007/s11042-023-17150-7
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM0
UT WOS:001076638500009
DA 2024-07-18
ER

PT J
AU Singh, YP
   Lobiyal, DK
AF Singh, Yajuvendra Pratap
   Lobiyal, D. K.
TI A comparative analysis and classification of cancerous brain tumors
   detection based on classical machine learning and deep transfer learning
   models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Machine learning; Deep learning; MRI; Xception; Inceptionv3
ID CONVOLUTIONAL NEURAL-NETWORK
AB Brain tumor can be fatal for human life. Therefore, proper and timely diagnosis and treatment is important to save human lives. The similarity and variety between the normal and tumor tissues make it difficult for diagnosis through human assisted techniques. In the recent past, machine learning and deep learning techniques have been applied for the classification and segmentation of brain tumor. These techniques have shown promising results by improving the accuracy of classification and segmentation. In this paper, we proposed to implement various classical machine-learning techniques support vector machine, Naive Bayes classifier, K- Nearest Neighbor, random forest, and deep-learning CNN-based models Xception, Inceptionv3, VGG19, and DenseNet201 techniques to classify gliomas, meningiomas, and pituitary tumors and compare their performance. Further, we proposed to modify Xception model to improve the performance of classification and segmentation. In this research, we used the standard Figshare dataset consisting of 3064 images of size 112x112\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$112\times 112$$\end{document} each. The performance of these models is measured and compared in terms of precision, recall, F1-score, and accuracy. The classical Machine learning model gives scores varying from 88% to 93%. For the above four metrics. However, all the deep learning models give their scores of more than 96% for the above metrics. Our proposed modified Xception model gives scores more than 98% in all the above four metrics, which is comparable to the best scores reported in the literature.
C1 [Singh, Yajuvendra Pratap; Lobiyal, D. K.] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.
C3 Jawaharlal Nehru University, New Delhi
RP Singh, YP (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.
EM yajuve94_scs@jnu.ac.in; dkl@mail.jnu.ac.in
FU Department of Science and Technology (DST); Council of Scientific &
   Industrial Research (CSIR) [09/263(1097)/2016-EMR-I]
FX This research is financially supported by Department of Science and
   Technology (DST), and Council of Scientific & Industrial Research (CSIR)
   (File No: 09/263(1097)/2016-EMR-I)
CR Abd El Kader I, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11030352
   Abiwinanda N, 2019, IFMBE PROC, V68, P183, DOI 10.1007/978-981-10-9035-6_33
   Aggarwal K., 2022, IRAQI J COMPUT SCI M, V3, P115, DOI [DOI 10.52866/IJCSM.2022.01.01.013, 10.52866/ijcsm.2022.01.01.013]
   Ali N, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1356-9
   Arunachalam M, 2017, INT J IMAG SYST TECH, V27, P216, DOI 10.1002/ima.22227
   Bodapati JD, 2021, SIGNAL IMAGE VIDEO P, V15, P753, DOI 10.1007/s11760-020-01793-2
   Cheng J, 2017, Brain tumor dataset, V2017, P5, DOI [10.6084/m9.figshare, DOI 10.6084/M9.FIGSHARE]
   Cheng J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140381
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Çinar A, 2020, MED HYPOTHESES, V139, DOI 10.1016/j.mehy.2020.109684
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Deepak S, 2021, J AMB INTEL HUM COMP, V12, P8357, DOI 10.1007/s12652-020-02568-w
   Díaz-Pernas FJ, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9020153
   Fawagreh K, 2014, SYST SCI CONTROL ENG, V2, P602, DOI 10.1080/21642583.2014.956265
   Gudigar A, 2019, FUTURE GENER COMP SY, V90, P359, DOI 10.1016/j.future.2018.08.008
   Hemanth DJ, 2019, IEEE ACCESS, V7, P4275, DOI 10.1109/ACCESS.2018.2885639
   Khawaldeh S, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010027
   Khazaei Z, 2020, BMC PUBLIC HEALTH, V20, DOI 10.1186/s12889-020-09838-4
   Kleesiek J, 2016, NEUROIMAGE, V129, P460, DOI 10.1016/j.neuroimage.2016.01.024
   Lashkari A., 2010, Int J Comput Appl, V4, P9
   LeCun Y., 2015, Lenet-5, convolutional neural networks
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Mansour R.F, 2021, Neural Comput Appl, V1, P13
   Matsugu M, 2003, NEURAL NETWORKS, V16, P555, DOI 10.1016/S0893-6080(03)00115-1
   Mzoughi H, 2020, J DIGIT IMAGING, V33, P903, DOI 10.1007/s10278-020-00347-9
   Paul JS, 2017, PROC SPIE, V10137, DOI 10.1117/12.2254195
   Pradhan A, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9172095
   Raja PMS, 2020, BIOCYBERN BIOMED ENG, V40, P440, DOI 10.1016/j.bbe.2020.01.006
   Reddy AVN, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00311-y
   Rehman A, 2020, CIRC SYST SIGNAL PR, V39, P757, DOI 10.1007/s00034-019-01246-3
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sajja VR., 2021, TURK J COMPUT MATH E, V12, P2103, DOI [10.17762/turcomat.v12i9.3680, DOI 10.17762/TURCOMAT.V12I9.3680]
   Saxena P, 2023, Arxiv, DOI [arXiv:1911.02265, 10.48550/arXiv.1911.02265]
   Seetha J., 2018, BIOMED PHARMACOL J, V11, P1457, DOI [DOI 10.13005/bpj/1511, 10.13005/bpj/1511]
   Shaik NS, 2022, SIGNAL IMAGE VIDEO P, V16, P817, DOI 10.1007/s11760-021-02022-0
   Siddique MA., 2020, P 4 INT C I SMAC IOT, P909, DOI DOI 10.1109/I-SMAC49090.2020.9243461
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Srinivasu PN, 2020, DEEP LEARNING TECHNIQUES FOR BIOMEDICAL AND HEALTH INFORMATICS, P97, DOI 10.1016/B978-0-12-819061-6.00004-5
   Srinivasu PN, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.654
   Swati ZNK, 2019, COMPUT MED IMAG GRAP, V75, P34, DOI 10.1016/j.compmedimag.2019.05.001
   Tazin T, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/2392395
   Vargo Mary, 2011, Am J Phys Med Rehabil, V90, pS50, DOI 10.1097/PHM.0b013e31820be31f
   Varuna Shree N, 2018, Brain Inform, V5, P23, DOI 10.1007/s40708-017-0075-5
   Wang S.-H, DenseNet-201-based Deep Neural Network with Composite Learning Factor and Precomputation for Multiple Sclerosis Classification
   Wang SH, 2020, NEURAL COMPUT APPL, V32, P665, DOI 10.1007/s00521-018-3924-0
   Yang X, 2018, Medical Imaging 2018: Image Processing, V10574
   Zacharaki EI, 2009, MAGN RESON MED, V62, P1609, DOI 10.1002/mrm.22147
   Zhou YF, 2019, LECT NOTES COMPUT SC, V11383, P208, DOI 10.1007/978-3-030-11723-8_21
NR 49
TC 1
Z9 1
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 3
PY 2023
DI 10.1007/s11042-023-16637-7
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM0
UT WOS:001076638500013
DA 2024-07-18
ER

PT J
AU Alsheikhy, AA
   Said, YF
   Shawly, T
AF Alsheikhy, Ahmed A.
   Said, Yahia F.
   Shawly, Tawfeeq
TI A novel intelligent smart traffic system using a deep-learning
   architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Intelligent adaptive model; Smart traffic; Control system; Congestion;
   NDGANs; IoTs; CCU; WSNs
AB Traffic congestion increases day by day because of the number of vehicles, lack of traffic control, and the limitations of the technologies being deployed. People in big cities suffer from this issue and look for a permanent solution. This congestion causes air pollution, noise pollution, and may lead to a catastrophic situation. In big cities with large populations, traffic congestion happens daily and affects the quality of air. Various projects have been placed to resolve this issue; however, it remains unresolved, and drivers get totally annoyed. Numerous technologies, such as IoTs and deep learning are widely applied recently due to their results and costs. In this article, a novel Intelligent Adaptive Traffic Control and Management System (IATCMS) based on a deep-learning architecture and IoTs is proposed. This system utilizes Wireless sensor networks (WSNs), cameras, a Database, a Central Control Unit (CCU), and a newly developed Generative Adversarial Network (NDGAN). This approach aims to reduce congestion, provide air quality, reduce fuel consumption, control traffic, and save lives in case of accidents by letting ambulances reach destinations quickly. In addition, the method ensures smooth traffic with a reasonable speed. Various key factors, such as speed of vehicles, traffic density, length of roads, and allocated light signal times are considered to provide a feasible solution to remove or reduce congestion and minimize traffic waiting time at intersections. This algorithm determines which lane gets the highest priority to proceed first by computing the traffic density for each road and gives the lane with the highest density priority. The presented model is tested and analyzed in MATLAB. The approach reduces the average waiting time at intersections by nearly 34% to 48% and removes congestion in some scenarios. The achieved results indicate that the proposed system can be applied at any intersection around the world to provide a smooth trip and remove traffic congestion.
C1 [Alsheikhy, Ahmed A.; Said, Yahia F.] Northern Border Univ, Coll Engn, Elect Engn Dept, Ar Ar, Saudi Arabia.
   [Shawly, Tawfeeq] King Abdulaziz Univ, Fac Engn Rabigh, Elect Engn Dept, Jeddah, Saudi Arabia.
C3 Northern Border University; King Abdulaziz University
RP Alsheikhy, AA (corresponding author), Northern Border Univ, Coll Engn, Elect Engn Dept, Ar Ar, Saudi Arabia.
EM aalsheikhy@nbu.edu.sa
RI Said, Yahia/A-7333-2018; Shawly, Tawfeeq/AAM-5645-2020; Alsheikhy,
   Ahmed/AAJ-7904-2021
OI Said, Yahia/0000-0003-0613-4037; Shawly, Tawfeeq/0000-0002-7997-7038;
   Alsheikhy, Ahmed/0000-0002-9811-0341
FU The authors extend their appreciation to the Deanship of Scientific
   Research at Northern Border University, Arar, KSA for funding this
   research work through the project number "NBU-FFR-2023-0033".
   [NBU-FFR-2023-0033]; Deanship of Scientific Research at Northern Border
   University, Arar, KSA
FX The authors extend their appreciation to the Deanship of Scientific
   Research at Northern Border University, Arar, KSA for funding this
   research work through the project number "NBU-FFR-2023-0033".
CR Abdullah SM, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15075949
   Almawgani A.H., 2018, International Journal of Industrial Electronics and Electrical Engineering (IJEEE), V6, P43
   Anjum M., 2023, Electronics, V12, P1
   Chahal A., 2023, Information, V14, P1
   Chandan KK., 2017, Saudi J Eng Technol, V2, P192
   Gupta P., 2014, Int J Electron Electr Eng, V7, P505
   Joo H, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11219850
   Miyim AM, 2019, 15 INT C EL COMP COM, P1
   Mohamed SAE., 2021, J Adv Transp, V4037533, P23
   Omina JA., 2015, Int Acad J Inf Syst Technol, V1, P1
   Ponnle A, 2019, P 2019 ANN C SCH ENG, P815
   Prakash P., 2021, Int J Electr Electron Comput, V6, P6, DOI [10.22161/eec.65.2, DOI 10.22161/EEC.65.2]
   Prasad R., 2021, J Emerg Technol Innov Res, V8, pf744
   Sun C., 2021, J Phys Conf Ser AMMS, V2068, P1
   Yawle RU., 2016, SSRG Int J Electron Commun Eng, V3, P20, DOI [10.14445/23488549/IJECE-V3I3P106, DOI 10.14445/23488549/IJECE-V3I3P106]
NR 15
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 2
PY 2023
DI 10.1007/s11042-023-17003-3
EA OCT 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1KJ9
UT WOS:001082459100001
DA 2024-07-18
ER

PT J
AU Malhotra, D
   Saini, P
   Singh, AK
AF Malhotra, Diksha
   Saini, Poonam
   Singh, Awadhesh Kumar
TI Blockchain-based proof-of-authenticity frameworks for Explainable AI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Explainable Artificial Intelligence; Blockchain; Smart contract;
   Ethereum; Blockchain-database
ID ARTIFICIAL-INTELLIGENCE; TECHNOLOGY
AB Explainable Artificial Intelligence (XAI) model generates explanations that assist a regulator in tracing offenders responsible for failures and penalizing them accordingly. However, these explanations are traditionally stored in the central database and are hence susceptible to changes. The owner of an automated system intentionally forges the information and later denies the same to safeguard its company's reputation. Here, Blockchain technology can prove beneficial to the regulator in order to confirm the traceability, non-repudiation, and auditability of the records. Hence, the paper proposes a novel public Blockchain-based proof-of-authenticity framework (BXAI) to ensure traceability and auditability in XAI. The framework has been developed on the Ethereum Blockchain, Smart contract, and the Interplanetary File System (IPFS). Furthermore, we design a peer-to-peer network with a distributed database to incorporate another essential feature of Blockchain, i.e., queryability, and propose a novel Blockchain database-based framework (B(d)XAI). Lastly, to understand the use of both proposed frameworks based on the requirements and availability of resources, a detailed comparative analysis is presented on parameters like time taken, cost, and queryability. However, after analyzing, one can opt for either of the two Blockchain-based frameworks, depending on the user's needs and the availability of resources.
C1 [Malhotra, Diksha; Saini, Poonam] Deemed Univ, Punjab Engn Coll, Comp Sci & Engn Dept, Chandigarh, India.
   [Singh, Awadhesh Kumar] Natl Inst Technol, Comp Engn Dept, Kurukshetra, India.
C3 Punjab Engineering College (Deemed University); National Institute of
   Technology (NIT System); National Institute of Technology Kurukshetra
RP Malhotra, D (corresponding author), Deemed Univ, Punjab Engn Coll, Comp Sci & Engn Dept, Chandigarh, India.
EM Dikshamalhotra.dm@gmail.com
RI Singh, A K/A-2586-2016
CR Abou Jaoude J, 2019, IEEE ACCESS, V7, P45360, DOI 10.1109/ACCESS.2019.2902501
   Arndt Timothy, 2020, International Journal of Information and Education Technology, V10, P7, DOI 10.18178/ijiet.2020.10.2.1344
   Baseer K. K., 2023, 2023 Second International Conference on Electronics and Renewable Systems (ICEARS), P784, DOI 10.1109/ICEARS56392.2023.10085012
   Baumgart I, 2007, INT C PAR DISTRIB SY, P579
   Bhalerao Rahul, 2023, 2023 International Conference on Innovative Data Communication Technologies and Application (ICIDCA), P781, DOI 10.1109/ICIDCA56705.2023.10100060
   Borah MD., 2020, Supply Chain Management in Agriculture Using Blockchain and IoT, DOI [10.1007/978-981-13-8775-3_11, DOI 10.1007/978-981-13-8775-3_11]
   Christidis K, 2016, IEEE ACCESS, V4, P2292, DOI 10.1109/ACCESS.2016.2566339
   Collins H., 2019, Tacit and Explicit Knowledge
   Doshi-Velez F., 2017, arXivPrepr, V1, DOI 10.48550/arXiv.1702.08608
   Du MX, 2017, IEEE SYS MAN CYBERN, P2567, DOI 10.1109/SMC.2017.8123011
   Eberhardt J, 2017, LECT NOTES COMPUT SC, V10465, P3, DOI 10.1007/978-3-319-67262-5_1
   ec europa eu, Communication Artificial Intelligence for Europe
   Ethereum Price, About us
   eurlex europa eu, The European parliament and the council of the European union
   Sáez MIG, 2020, INT J INTERACT MULTI, V6, P73, DOI 10.9781/ijimai.2020.08.005
   Gunning D, 2019, AI MAG, V40, P44, DOI 10.1609/aimag.v40i2.2850
   Gupta P, 2019, arXivPrepr, P1, DOI [10.13140/RG.2.2.26981.35048, DOI 10.13140/RG.2.2.26981.35048]
   Hasan HR, 2019, IEEE ACCESS, V7, P41596, DOI 10.1109/ACCESS.2019.2905689
   ipfs, ABOUT US
   Jia B, 2016, Opus-Decentralized music distribution using InterPlanetary File Systems (IPFS) on the Ethereum blockchain V0. 8.3
   Jiang Y-H, 2023, Computer and Modernization, V02, P110
   Jurado F, 2020, INT J INTERACT MULTI, V6, P39, DOI 10.9781/ijimai.2020.06.003
   Kahn Michael, 1993, UCI Machine Learning Repository
   Kumar R., 2021, LARGE SCALE DATA STR, P91
   Lin QJ, 2019, IEEE ACCESS, V7, P20698, DOI 10.1109/ACCESS.2019.2897792
   Madathil V, 2022, INT WORKSH DAT PRIV, P239
   Marjit U., 2020, P 2020 INT C COMPUTE, P1, DOI [10.1109/ICCSEA49143.2020.9132841, DOI 10.1109/ICCSEA49143.2020.9132841]
   Metaspace, US
   Naik HM, 2020, International Journal of Next-Generation Computing, V11
   Neto MM, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ARCHITECTURE COMPANION (ICSA-C 2020), P95, DOI [10.1109/ICSA-C50368.2020.00027, 10.1109/ICSA-050368.2020.00027]
   Nizamuddin N, 2019, COMPUT ELECTR ENG, V76, P183, DOI 10.1016/j.compeleceng.2019.03.014
   Nizamuddin N, 2018, LECT NOTES COMPUT SC, V10974, P199, DOI 10.1007/978-3-319-94478-4_14
   Nyaletey E, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON BLOCKCHAIN (BLOCKCHAIN 2019), P18, DOI 10.1109/Blockchain.2019.00012
   Pandl KD, 2020, IEEE ACCESS, V8, P57075, DOI 10.1109/ACCESS.2020.2981447
   Rahut S.K., 2021, RES ANTHOLOGY BLOCKC, P1029
   Raikwar M, 2020, Arxiv, DOI arXiv:2003.05687
   Reen G.S., 2019, 2019 IEEE C INF COMM, P1, DOI 10.1109/cict48419.2019.9066212
   remix ethereum, Remix IDE
   Szabo N., 1997, Formalizing and Securing Relationships on Public Networks
   Tenorio-Fornes A, 2019, P 52 HAW INT C SYST, DOI [10.24251/hicss.2019.560, DOI 10.24251/HICSS.2019.560]
   Tiwari Anupam, 2021, International Journal of Information Technology, V13, P201, DOI 10.1007/s41870-020-00568-9
   Treleaven P, 2017, COMPUTER, V50, P14, DOI 10.1109/MC.2017.3571047
   Van Alstyne M, 2014, COMMUN ACM, V57, P30, DOI 10.1145/2594288
   Wu XG, 2020, COMM COM INF SC, V1149, P340, DOI 10.1007/978-981-15-3418-8_22
   Yajun Wang, 2020, 2020 IEEE 5th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA), P307, DOI 10.1109/ICCCBDA49378.2020.9095589
   Zhang QY, 2023, J SUPERCOMPUT, V79, P897, DOI 10.1007/s11227-022-04702-1
NR 46
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 2
PY 2023
DI 10.1007/s11042-023-16951-0
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1KJ9
UT WOS:001082459100017
DA 2024-07-18
ER

PT J
AU Pradeepthi, C
   Maheswari, BU
AF Pradeepthi, C.
   Maheswari, B. Uma
TI Network intrusion detection and prevention strategy with data encryption
   using hybrid detection classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Intrusion detection system; Attack types; Encryption; Deep learning;
   Machine learning; Four barrier authentications
ID ATTACK DETECTION; INTERNET; SCHEME
AB Advances in technology and communication have led to an increase in data and network sizes. As a result, many intrusions (attacks) are created and pose more challenges to network security. In order to protect the network's confidentiality, integrity, and availability from potential intrusions, an Intrusion Detection System (IDS) was employed to examine network traffic. Despite significant research efforts, IDS still has difficulties detecting novel intrusions and improving detection accuracy while lowering false alarm rates. To solve these problems, a novel intrusion detection approach with data encryption is proposed to detect intrusion and protect data from attackers. The operational process of the proposed approach is divided into three phases. First phase: Intrusion identification from the network through a novel hybrid machine learning and deep learning approach. Second phase: an advanced deep learning approach is utilized to detect the types of attack. The attack types that occur in the network are predicted, and an automatic alarm message is sent to the users. Third phase: advanced encryption model is utilized to store the data securely. The users from the network could able to access data from the storage after complete the four barrier authentication process. Each phase is separately analyzed and compared to existing approaches. Proposed hybrid intrusion detection phase provide 0.97 accuracy and 0.02 false positive rate, as well as proposed attack type detection phase offer 0.96 accuracy and 0.01 false positive rate. Observed values prove that the proposed model is most suitable for all network intrusion detection and data encryption.
C1 [Pradeepthi, C.; Maheswari, B. Uma] Amrita Vishwa Vidyapeetham, Amrita Sch Comp, Dept Comp Sci & Engn, Bengaluru 560035, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Bengaluru
RP Pradeepthi, C (corresponding author), Amrita Vishwa Vidyapeetham, Amrita Sch Comp, Dept Comp Sci & Engn, Bengaluru 560035, India.
EM c_pradeepthi@blr.amrita.edu; b_uma@blr.amrita.edu
CR Abdulla NN., 2022, J Algebraic Stat, V13, P3696
   Al-Abassi A, 2020, IEEE ACCESS, V8, P83965, DOI 10.1109/ACCESS.2020.2992249
   Almiani M, 2020, SIMUL MODEL PRACT TH, V101, DOI 10.1016/j.simpat.2019.102031
   Andresini G, 2021, INFORM SCIENCES, V569, P706, DOI 10.1016/j.ins.2021.05.016
   Andresini G, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2021.106798
   Anguraj DK, 2019, WIRELESS PERS COMMUN, V104, P1, DOI 10.1007/s11277-018-6005-x
   Anton SDD, 2019, INT CONF SOFTW, P465, DOI 10.23919/softcom.2019.8903672
   Baig ZA, 2020, FUTURE GENER COMP SY, V102, P198, DOI 10.1016/j.future.2019.08.007
   Cheng ZY, 2023, Arxiv, DOI arXiv:2301.13487
   Cheng ZY, 2022, LECT NOTES COMPUT SC, V13698, P514, DOI 10.1007/978-3-031-19839-7_30
   Cil AE, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114520
   Demertzis K, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10070781
   Deng H, 2021, Wireless Communications and Mobile Computing, V2021
   Dhanshri C., 2021, Int Res J Mod Eng Technol Sci, V3, P1492
   Dong S, 2020, IEEE ACCESS, V8, P5039, DOI 10.1109/ACCESS.2019.2963077
   Gu J, 2021, COMPUT SECUR, V103, DOI 10.1016/j.cose.2020.102158
   Guo AY, 2019, CLUSTER COMPUT, V22, P13405, DOI 10.1007/s10586-018-1944-2
   Han M, 2021, VEH COMMUN, V31, DOI 10.1016/j.vehcom.2021.100374
   Imran, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su131810057
   Khan MA, 2021, PROCESSES, V9, DOI 10.3390/pr9050834
   Khan MA, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9111771
   Kim J, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12060891
   Kim J, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060916
   Latif S, 2020, IEEE ACCESS, V8, P89337, DOI 10.1109/ACCESS.2020.2994079
   Maseer ZK, 2021, CMC-COMPUT MATER CON, V69, P3945, DOI 10.32604/cmc.2021.016074
   Melvin AAR, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.4287
   Mendonca RV, 2021, IEEE ACCESS, V9, P61024, DOI 10.1109/ACCESS.2021.3074664
   Mondal A, 2021, MICROPROCESS MICROSY, V81, DOI 10.1016/j.micpro.2020.103719
   Onyema EM, 2022, J CLOUD COMPUT-ADV S, V11, DOI 10.1186/s13677-022-00305-6
   Otoum Y, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.3803
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9070751
   Patil DR, 2018, ISECURE-ISC INT J IN, V10, P141
   Pei JM, 2022, COMPUT NETW, V209, DOI 10.1016/j.comnet.2022.108906
   Prabhakaran V, 2021, NEURAL COMPUT APPL, V33, P14459, DOI 10.1007/s00521-021-06085-5
   Prabhakaran V, 2021, COMPUT INTELL-US, V37, P344, DOI 10.1111/coin.12408
   Qiu H, 2021, IEEE INTERNET THINGS, V8, P10327, DOI 10.1109/JIOT.2020.3048038
   Spathoulas G, 2021, INT J INF SECUR, V20, P347, DOI 10.1007/s10207-020-00506-7
   Swarnalatha G., 2021, Turk J Comput Math Educ (TURCOMAT), V12, P74, DOI [10.17762/turcomat.v12i6.1269, DOI 10.17762/TURCOMAT.V12I6.1269]
   Toldinas J, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10151854
   Tuan TA, 2020, EVOL INTELL, V13, P283, DOI 10.1007/s12065-019-00310-w
   Van Huong P., 2020, J Sci Technol Inform Sec, V2, P31
   Wang WG, 2022, Arxiv, DOI arXiv:2209.07383
   Wisanwanichthan T, 2021, IEEE ACCESS, V9, P138432, DOI 10.1109/ACCESS.2021.3118573
   Xu MF, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3957
   Yaacoub JPA, 2020, MICROPROCESS MICROSY, V77, DOI 10.1016/j.micpro.2020.103201
   Yang AM, 2019, IEEE ACCESS, V7, P106043, DOI 10.1109/ACCESS.2019.2929919
   Zhang F, 2019, IEEE T IND INFORM, V15, P4362, DOI 10.1109/TII.2019.2891261
   Zhang H, 2021, FUTURE GENER COMP SY, V122, P130, DOI 10.1016/j.future.2021.03.024
   Zhou XK, 2022, IEEE INTERNET THINGS, V9, P9310, DOI 10.1109/JIOT.2021.3130434
NR 49
TC 0
Z9 0
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 30
PY 2023
DI 10.1007/s11042-023-16853-1
EA SEP 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T4DY8
UT WOS:001077522300012
DA 2024-07-18
ER

PT J
AU Wang, J
   Zhao, Q
   Jia, D
   Huang, ZQ
   Zhang, MH
   Ren, X
AF Wang, Jun
   Zhao, Qi
   Jia, Di
   Huang, Ziqing
   Zhang, Miaohui
   Ren, Xing
TI Spatial-temporal aware network for video-based person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video-based pedestrian re-identification; Temporal feature learning;
   Spatial feature learning; Feature relationship learning
AB Video-based pedestrian re-identification (ReID) is able to match the same pedestrian from various cameras in a complex real-world scene. The extracted representations can't contain all the useful information about the persons, due to the occlusion and misalignment of human areas between video sequences, and thus lack integrity and discrimination. To resolve this issue, we propose a new Spatial-Temporal Aware Network, which can mine and complement person features with feature relationships and intra-frame cues. According to the high correlation of the feature nodes of the same person between different video sequences, we employ the learned pedestrian feature nodes to construct the temporal relationship graph. In detail, the Temporal Interaction Module is designed to locate relevant pedestrian regions by modeling the correlation of feature nodes with reference nodes; and the Temporal Attention Module thatwe have designed is used to select more specific reference nodes. Then, we apply the designed Spatial Reference Module to adaptively mine each frame for fine-grained cues, making the spatial-temporal characteristics of persons more discriminative. We have implemented numerous experiments to demonstrate the excellent performance of STAN, such as achieving 88.0% mAP and 89.5% Rank-1 accuracy on the MARS dataset.
C1 [Wang, Jun; Zhao, Qi; Jia, Di; Huang, Ziqing; Zhang, Miaohui; Ren, Xing] Zhengzhou Univ, Sch Comp & Artificial Intelligence, Zhengzhou 450001, Henan, Peoples R China.
C3 Zhengzhou University
RP Ren, X (corresponding author), Zhengzhou Univ, Sch Comp & Artificial Intelligence, Zhengzhou 450001, Henan, Peoples R China.
EM auwangjun@henu.edu.cn; zhaoqi@henu.edu.cn; jd@henu.edu.cn;
   skyhuangzq@163.com; zhmh@henu.edu.cn; 10280031@vip.henu.edu.cn
CR Andriluka M, 2008, PROC CVPR IEEE, P1873, DOI 10.1109/CVPR.2008.4587583
   Bai ST, 2022, IEEE T CIRC SYST VID, V32, P3866, DOI 10.1109/TCSVT.2021.3119983
   Batool E, 2023, J SUPERCOMPUT, V79, P13090, DOI 10.1007/s11227-023-05169-4
   Bhuiyan A, 2022, IMAGE VISION COMPUT, V123, DOI 10.1016/j.imavis.2022.104474
   Chen L, 2020, SIGNAL PROCESS-IMAGE, V84, DOI 10.1016/j.image.2020.115835
   Chen XS, 2020, PROC CVPR IEEE, P3297, DOI 10.1109/CVPR42600.2020.00336
   Chen ZQ, 2020, AAAI CONF ARTIF INTE, V34, P10591
   Cheng L, 2020, NEURAL COMPUT APPL, V32, P12841, DOI 10.1007/s00521-020-04730-z
   Chung D, 2017, IEEE I CONF COMP VIS, P1992, DOI 10.1109/ICCV.2017.218
   Eom C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12016, DOI 10.1109/ICCV48922.2021.01182
   Fu H, 2022, IMAGE VISION COMPUT, V118, DOI 10.1016/j.imavis.2021.104356
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8287
   Gao JY, 2018, Arxiv, DOI arXiv:1805.02104
   Gong WC, 2020, NEUROCOMPUTING, V383, P295, DOI 10.1016/j.neucom.2019.11.050
   Gu XQ, 2022, IEEE T IMAGE PROCESS, V31, P3908, DOI 10.1109/TIP.2022.3175593
   Gu XQ, 2019, IEEE I CONF COMP VIS, P9646, DOI 10.1109/ICCV.2019.00974
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hou RB, 2019, PROC CVPR IEEE, P7176, DOI 10.1109/CVPR.2019.00735
   Jiang M, 2020, NEUROCOMPUTING, V381, P314, DOI 10.1016/j.neucom.2019.11.088
   Kiran M, 2021, IMAGE VISION COMPUT, V113, DOI 10.1016/j.imavis.2021.104246
   Li JN, 2019, IEEE I CONF COMP VIS, P3957, DOI 10.1109/ICCV.2019.00406
   Li JN, 2020, IEEE T IMAGE PROCESS, V29, P4461, DOI 10.1109/TIP.2020.2972108
   Li JY, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22083047
   Li PK, 2021, IEEE T CIRC SYST VID, V31, P503, DOI 10.1109/TCSVT.2020.2988034
   Lin GJ, 2021, NEUROCOMPUTING, V453, P777, DOI 10.1016/j.neucom.2020.05.111
   Liu CT, 2019, Arxiv, DOI arXiv:1908.01683
   Liu JW, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3231741
   Liu XH, 2021, Arxiv, DOI arXiv:2104.01745
   Liu YH, 2019, AAAI CONF ARTIF INTE, P8786
   Lu Z, 2022, INT J MACH LEARN CYB, V13, P2745, DOI 10.1007/s13042-022-01560-4
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Khan FM, 2016, Arxiv, DOI arXiv:1607.05975
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Ouyang DQ, 2019, PATTERN RECOGN LETT, V117, P153, DOI 10.1016/j.patrec.2018.05.009
   Pei SY, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23121686
   Porrello Angelo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P93, DOI 10.1007/978-3-030-58607-2_6
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Song WR, 2021, APPL INTELL, V51, P788, DOI 10.1007/s10489-020-01844-8
   Song WR, 2020, MULTIMED TOOLS APPL, V79, P12471, DOI 10.1007/s11042-019-08432-0
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Subramaniam A, 2019, IEEE I CONF COMP VIS, P562, DOI 10.1109/ICCV.2019.00065
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tagore NK, 2020, MULTIMED TOOLS APPL, V79, P28393, DOI 10.1007/s11042-020-09398-0
   Tang SY, 2017, PROC CVPR IEEE, P3701, DOI 10.1109/CVPR.2017.394
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wang XG, 2013, PATTERN RECOGN LETT, V34, P3, DOI 10.1016/j.patrec.2012.07.005
   Wang XY, 2019, IEEE IMAGE PROC, P2249, DOI [10.1109/ICIP.2019.8803321, 10.1109/icip.2019.8803321]
   Wang YQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12006, DOI 10.1109/ICCV48922.2021.01181
   Wang Z, 2021, IEEE Trans Circuits Syst Video Technol
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu DM, 2022, IEEE T INF FOREN SEC, V17, P115, DOI 10.1109/TIFS.2021.3075894
   Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543
   Xinqian Gu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P228, DOI 10.1007/978-3-030-58536-5_14
   Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507
   Yang F, 2022, NEUROCOMPUTING, V488, P424, DOI 10.1016/j.neucom.2022.03.032
   Yang X, 2021, IEEE T IMAGE PROCESS, V30, P6266, DOI 10.1109/TIP.2021.3093759
   Zhang G., 2021, P IEEE INT C MULT EX, P1
   Zhang RM, 2019, IEEE T IMAGE PROCESS, V28, P4870, DOI 10.1109/TIP.2019.2911488
   Zhang Z, 2020, Multi-granularity reference-aided attentive feature aggregation for video-based person re-identification
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
NR 62
TC 0
Z9 0
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
AR s11042-023-16911-8
DI 10.1007/s11042-023-16911-8
EA SEP 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600022
DA 2024-07-18
ER

PT J
AU Xiyu, S
   Zhong, C
AF Xiyu, Sun
   Zhong, Chen
TI A fast image encryption algorithm with variable key space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image encryption; Chaotic map; Variable key space; Key association
ID HENON MAP; CHAOTIC SYSTEM; CRYPTANALYSIS
AB The security of images is of great importance given the current development of Internet technology. The existing encryption algorithms have some defects, such as the key space is not large enough and the encryption speed is slow. A fast image encryption algorithm with variable key space is proposed. The algorithm key space is dynamically changeable and the variable key space is associated with the initial condition of Henon map, making this cryptosystem extremely sensitive to the key. The overall algorithm uses a permutation-diffusion-permutation-diffusion encryption structure. The first permutation process is implemented by cross-sampling and the first diffusion is implemented by modal operation. The second permutation is implemented using the chaotic sequence approach and the second diffusion is implemented using the XOR operation. The designed permutation and diffusion operations are executed with high efficiency, and the two different diffusion operations make the encryption process with nonlinear mapping capability, making the algorithm effective against existing typical differential attack schemes. Experiments show that the algorithm has a dynamically adjustable key space, high efficiency of algorithm encryption, good robustness, and effective resistance to statistical attack analysis and differential attack analysis.
C1 [Xiyu, Sun; Zhong, Chen] Hengyang Normal Univ, Coll Comp Sci & Technol, Hengyang 421002, Hunan, Peoples R China.
   [Zhong, Chen] Hunan Prov Key Lab Intelligent Informat Proc & App, Hengyang 421002, Hunan, Peoples R China.
C3 Hengyang Normal University
RP Zhong, C (corresponding author), Hengyang Normal Univ, Coll Comp Sci & Technol, Hengyang 421002, Hunan, Peoples R China.; Zhong, C (corresponding author), Hunan Prov Key Lab Intelligent Informat Proc & App, Hengyang 421002, Hunan, Peoples R China.
EM xiyu_sun_jiksn@163.com; chenzhong@hynu.edu.cn
OI Chen, Zhong/0000-0002-5459-2094
FU This work was supported by the National Natural Science Foundation of
   China (No. 11672104), the Chair Professor of Lotus Scholars Program in
   Hunan Province (No. XJT2015408). The authors also would like to thank
   the support from the scientific research proj [11672104]; National
   Natural Science Foundation of China [XJT2015408]; Chair Professor of
   Lotus Scholars Program in Hunan Province [18D24]; scientific research
   project of Hengyang Normal University [18D24]; Science and Technology
   Plan Project of Hunan Province [18A333, 19A066]; General Scientific
   Research Fund of Hunan Provincial Education Department
FX This work was supported by the National Natural Science Foundation of
   China (No. 11672104), the Chair Professor of Lotus Scholars Program in
   Hunan Province (No. XJT2015408). The authors also would like to thank
   the support from the scientific research project of Hengyang Normal
   University (NO.18D24), the Science and Technology Plan Project of Hunan
   Province (No. 2016TP1020), the General Scientific Research Fund of Hunan
   Provincial Education Department (No. 18A333,NO. 19A066).
CR Ali TS, 2020, MULTIMED TOOLS APPL, V79, P19853, DOI 10.1007/s11042-020-08850-5
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JX, 2021, IEEE T CIRC SYST VID, V31, P2494, DOI 10.1109/TCSVT.2020.3021908
   Cheng GF, 2020, MULTIMED TOOLS APPL, V79, P29243, DOI 10.1007/s11042-020-09542-w
   Dhall S, 2022, J KING SAUD UNIV-COM, V34, P1533, DOI 10.1016/j.jksuci.2018.09.015
   Ding Y, 2022, IEEE T NEUR NET LEAR, V33, P4915, DOI [10.1109/TNNLS.2021.3062754, 10.1080/00206814.2021.1969525]
   Fernández-Caramés TM, 2020, IEEE ACCESS, V8, P21091, DOI 10.1109/ACCESS.2020.2968985
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Ibrahim S, 2020, IEEE ACCESS, V8, P194289, DOI 10.1109/ACCESS.2020.3032403
   Idrees B, 2020, MULTIMED TOOLS APPL, V79, P6135, DOI 10.1007/s11042-019-08282-w
   Jain K, 2021, PATTERN RECOGN LETT, V152, P356, DOI 10.1016/j.patrec.2021.10.033
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Li CQ, 2018, IEEE MULTIMEDIA, V25, P46, DOI 10.1109/MMUL.2018.2873472
   Li Q, 2020, IEEE ACCESS, V8, P168166, DOI 10.1109/ACCESS.2020.3021103
   Li SJ, 2005, INT J BIFURCAT CHAOS, V15, P3119, DOI 10.1142/S0218127405014052
   Luo YL, 2019, IEEE ACCESS, V7, P38507, DOI 10.1109/ACCESS.2019.2906052
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Meranza-Castillón MO, 2019, AEU-INT J ELECTRON C, V107, P239, DOI 10.1016/j.aeue.2019.05.028
   Ogasahara Y, 2016, IEEE INT SYMP CIRC S, P758, DOI 10.1109/ISCAS.2016.7527351
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Ping P, 2018, NEUROCOMPUTING, V283, P53, DOI 10.1016/j.neucom.2017.12.048
   Kari AP, 2021, MULTIMED TOOLS APPL, V80, P2753, DOI 10.1007/s11042-020-09648-1
   Roy M, 2021, MULTIMED TOOLS APPL, V80, P24069, DOI 10.1007/s11042-021-10839-7
   Rukhin Andrew L., 2001, A statistical test suite for random and pseudorandom number generators for cryptographic applications, V22
   Sneha PS, 2020, J AMB INTEL HUM COMP, V11, P1289, DOI 10.1007/s12652-019-01385-0
   Sun FY, 2008, CHAOS SOLITON FRACT, V38, P631, DOI 10.1016/j.chaos.2008.01.028
   Sun SL, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.11.116117
   Talhaoui MZ, 2021, VISUAL COMPUT, V37, P541, DOI 10.1007/s00371-020-01822-8
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wang XY, 2020, OPT LASER ENG, V125, DOI 10.1016/j.optlaseng.2019.105851
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2018, OPT LASER ENG, V107, P370, DOI 10.1016/j.optlaseng.2017.06.015
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wu GC, 2019, CHAOS, V29, DOI 10.1063/1.5096645
   Wu JH, 2021, J MOD OPTIC, V68, P409, DOI 10.1080/09500340.2021.1900440
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Xiang HY, 2021, MULTIMED TOOLS APPL, V80, P22135, DOI 10.1007/s11042-021-10807-1
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Xu QY, 2019, OPT LASER ENG, V121, P203, DOI 10.1016/j.optlaseng.2019.04.011
   Ye GD, 2021, NONLINEAR DYNAM, V104, P2807, DOI 10.1007/s11071-021-06422-2
   Yu JW, 2022, CHAOS SOLITON FRACT, V162, DOI 10.1016/j.chaos.2022.112456
   Zhang XC, 2019, IEEE ACCESS, V7, P74734, DOI 10.1109/ACCESS.2019.2921309
   Zhang YQ, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106040
   Zheng YF, 2015, MULTIMED TOOLS APPL, V74, P7803, DOI 10.1007/s11042-014-2024-0
   Zhou MJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107484
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
NR 51
TC 0
Z9 0
U1 7
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-16981-8
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600014
DA 2024-07-18
ER

PT J
AU Chen, C
   Bu, YL
   Chen, Y
   Chen, DY
AF Chen, Chen
   Bu, Yulin
   Chen, Yong
   Chen, Deyun
TI Common latent representation learning for low-resourced spoken language
   identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Spoken language identification; Total variability space; I-vector;
   Common latent representation learning
ID RECOGNITION; SPEECH
AB The i-vector method is one of the mainstream methods in spoken language identification (SLID). It estimates the total variability space (TVS) to obtain a low-rank representation which can characterize the language, called the i-vector. However, on small-scale datasets, low learning resources can significantly degrade the performance of SLID system. Therefore, it is necessary to improve the performance of SLID system in low-resourced condition. In this paper, we propose a common latent representation learning (CLRL) method to learn the TVS, which introduces prior information to address the lack of information in low-resourced condition. The prior information includes category label and parameter prior hypothesis. The CLRL method is evaluated on the OLR2020 dataset. Compared with other state-of-the-art methods, the CLRL method shows better performance on all datasets of different data scales. Moreover, the CLRL method can effectively improve the performance of the SLID system on low-resourced/small-scale datasets.
C1 [Chen, Chen; Bu, Yulin; Chen, Yong; Chen, Deyun] Harbin Univ Sci & Technol, Sch Comp Sci & Technol, Harbin 150080, Heilongjiang, Peoples R China.
   [Chen, Chen; Chen, Deyun] Harbin Univ Sci & Technol, Postdoctoral Res Stn Comp Sci & Technol, Harbin 150080, Heilongjiang, Peoples R China.
C3 Harbin University of Science & Technology; Harbin University of Science
   & Technology
RP Chen, C (corresponding author), Harbin Univ Sci & Technol, Sch Comp Sci & Technol, Harbin 150080, Heilongjiang, Peoples R China.; Chen, C (corresponding author), Harbin Univ Sci & Technol, Postdoctoral Res Stn Comp Sci & Technol, Harbin 150080, Heilongjiang, Peoples R China.
EM chenc@hrbust.edu.cn; byl9931@163.com; chenyong_4297@163.com;
   chendeyun@hrbust.edu.cn
OI Chen, Deyun/0000-0002-5176-7725; Chen, Chen/0000-0003-1957-6432
FU This research is supported by the National Natural Science Foundation of
   China under Grant No. 62101163, China Postdoctoral Science Foundation
   under Grant No. 2021M701020, Natural Science Foundation of Heilongjiang
   Province of China under Grant No. LH2021F [62101163]; National Natural
   Science Foundation of China [2021M701020]; China Postdoctoral Science
   Foundation [LH2021F029]; Natural Science Foundation of Heilongjiang
   Province of China [LBH-Z20020]; Heilongjiang Postdoctoral Fund
   [2021-KYYWF-0762]; Fundamental Research Foundation for Universities of
   Heilongjiang Province
FX This research is supported by the National Natural Science Foundation of
   China under Grant No. 62101163, China Postdoctoral Science Foundation
   under Grant No. 2021M701020, Natural Science Foundation of Heilongjiang
   Province of China under Grant No. LH2021F029, Heilongjiang Postdoctoral
   Fund under Grant No. LBH-Z20020, Fundamental Research Foundation for
   Universities of Heilongjiang Province under Grant No. 2021-KYYWF-0762.
CR Abdurrahman AI, 2021, Bulletin of Electrical Engineering and Informatics, V10, P2237, DOI [10.11591/eei.v10i4.2893, DOI 10.11591/EEI.V10I4.2893]
   Alam Jahangir, 2021, Speech and Computer: 23rd International Conference, SPECOM 2021, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (12997), P1, DOI 10.1007/978-3-030-87802-3_1
   Alashban AA, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12189181
   Albadr MAA, 2023, MULTIMED TOOLS APPL, V82, P27165, DOI 10.1007/s11042-023-14473-3
   Albadr MAA, 2021, COGN COMPUT, V13, P1136, DOI 10.1007/s12559-021-09914-w
   Anjana JS, 2018, 2018 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET)
   Biswas M, 2023, MULTIMED TOOLS APPL, V82, P9565, DOI 10.1007/s11042-021-11439-1
   Cai WC, 2019, INT CONF ACOUST SPEE, P5991, DOI [10.1109/ICASSP.2019.8682386, 10.1109/icassp.2019.8682386]
   Chen CP, 2019, INT CONF ACOUST SPEE, P6211, DOI [10.1109/ICASSP.2019.8683185, 10.1109/icassp.2019.8683185]
   Chen ZY, 2022, INT CONF ACOUST SPEE, P6147, DOI 10.1109/ICASSP43922.2022.9747814
   Das HC, 2022, Pattern Recognition and Data Analysis with Applications, P311, DOI [10.1007/978-981-19-1520-8_24, DOI 10.1007/978-981-19-1520-8_24]
   Dehak N, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P864
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Desplanques B, 2014, OD 2014 SPEAK LANG R, P73, DOI [10.21437/odyssey.2014-16, DOI 10.21437/ODYSSEY.2014-16]
   Desplanques B, 2020, INTERSPEECH, P3830, DOI 10.21437/Interspeech.2020-2650
   Garcia-Romero D., 2011, INTERSPEECH
   Jin M, 2018, IEEE-ACM T AUDIO SPE, V26, P171, DOI 10.1109/TASLP.2017.2766023
   Kacprzak S, 2022, INT CONF ACOUST SPEE, P6867, DOI 10.1109/ICASSP43922.2022.9747515
   Kenny P, 2007, IEEE T AUDIO SPEECH, V15, P1435, DOI 10.1109/TASL.2006.881693
   Kim DK, 2000, 6 INT C SPOK LANG PR, DOI [10.21437/icslp.2000-640, DOI 10.21437/ICSLP.2000-640]
   Kohler MA, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, CONFERENCE PROCEEDINGS, P69
   Li J, 2021, INTERSPEECH, P3251, DOI 10.21437/Interspeech.2021-2171
   Li L, 2021, NEURAL NETWORKS, V141, P72, DOI 10.1016/j.neunet.2021.03.026
   Li Z, 2020, ASIAPAC SIGN INFO PR, P550
   Liu HX, 2022, IEEE J-STSP, V16, P1296, DOI 10.1109/JSTSP.2022.3201445
   Lu XG, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7228, DOI 10.1109/ICASSP39728.2021.9414045
   Ma B, 2006, INT CONF ACOUST SPEE, P1029
   Ma JB, 2018, IEEE SIGNAL PROC LET, V25, P1775, DOI 10.1109/LSP.2018.2874814
   Matejka P, 2011, INT CONF ACOUST SPEE, P4828
   Miao XX, 2020, CIRC SYST SIGNAL PR, V39, P2744, DOI 10.1007/s00034-019-01286-9
   Monteiro J, 2022, SPEECH COMMUN, V140, P42, DOI 10.1016/j.specom.2022.03.008
   Prince SJD, 2007, IEEE I CONF COMP VIS, P1751
   Punjabi S, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7213, DOI 10.1109/ICASSP39728.2021.9413734
   Qian Y, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7458, DOI 10.1109/ICASSP39728.2021.9414900
   Ravanelli M, 2019, INT CONF ACOUST SPEE, P6465, DOI [10.13140/rg.2.2.18985.44647, 10.1109/ICASSP.2019.8683713]
   Reynolds D., 1997, EUROSPEECH, P963
   Romero D, 2022, INT CONF ACOUST SPEE, P6872, DOI 10.1109/ICASSP43922.2022.9746459
   Snyder D, 2019, INT CONF ACOUST SPEE, P5796, DOI 10.1109/ICASSP.2019.8683760
   Tang ZY, 2018, IEEE-ACM T AUDIO SPE, V26, P134, DOI 10.1109/TASLP.2017.2764271
   Thukroo IA, 2022, MULTIMED TOOLS APPL, V81, P32593, DOI 10.1007/s11042-022-13054-0
   Tjandra A, 2022, INT CONF ACOUST SPEE, P6877, DOI 10.1109/ICASSP43922.2022.9747667
   Dat TT, 2015, INT CONF IT CONVERGE
   Villalba J, 2019, INTERSPEECH, P1488, DOI 10.21437/Interspeech.2019-2713
   Vuddagiri R.K., 2018, SLTU, P210
   Wang X, 2020, COMPUT SPEECH LANG, V64, DOI [10.1016/j.csl.2020.101114, 10.1016/j.csi.2020.101114]
   Wong E, 2002, 7 INT C SPOK LANG PR, P16, DOI [10.21437/icslp.2002-75, DOI 10.21437/ICSLP.2002-75]
   Yonghua Xu, 2010, 2010 International Conference on Measuring Technology and Mechatronics Automation (ICMTMA 2010), P656, DOI 10.1109/ICMTMA.2010.545
   Yu YQ, 2020, INTERSPEECH, P921, DOI 10.21437/Interspeech.2020-1275
   Zeinali H, 2019, INT CONF ACOUST SPEE, P6141, DOI [10.1109/ICASSP.2019.8683445, 10.1109/icassp.2019.8683445]
   Zissman MA., 1993, Sig Process. IEEE, V2, P399, DOI [10.1109/icassp.1993.319323, DOI 10.1109/ICASSP.1993.319323]
NR 50
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 26
PY 2023
DI 10.1007/s11042-023-16865-x
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S8YJ1
UT WOS:001073965700017
DA 2024-07-18
ER

PT J
AU Jian, M
   Yang, R
   Wang, XL
   Wu, LF
AF Jian, Meng
   Yang, Ran
   Wang, Xinling
   Wu, Lifang
TI Dynamic interest modeling via dual learning for recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Collaborative filtering; Personalized recommendation; User interest;
   Attention mechanism
AB The personalized recommendation has already taken a crucial role in online services to alleviate information overload. However, most existing works pay their attention to user interest modeling with a uniform embedding, which inevitably results in suboptimal recommendations. We argue that users' diverse and mixed interests are positively related to their interacted items with mutual effects, and they are partially matched in decision-making. This work introduces a novel dual interest activation network (DIAN), which forms dual embedding learning of users and items with a dynamic activation for personalized recommendation. By modeling mutual effects between users and items, DIAN constructs dual embedding learning on their identites (IDs) and neighbor groups to encode their diverse and mixed composition of interests implicitly. Specifically, considering the partial matching scenario, we introduce a dynamic interest activation with pairwise matching motivated attention on aggregating neighbor groups of users and items. Experimental analysis verifies the significance of mutual effects and dynamic matching, illustrating the effectiveness of DIAN for personalized recommendation.
C1 [Jian, Meng; Yang, Ran; Wu, Lifang] Beijing Univ Technol, Fac Informat Technol, Beijing, Peoples R China.
   [Wang, Xinling] Beijing Municipal Engn Res Inst, Beijing, Peoples R China.
C3 Beijing University of Technology
RP Jian, M (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing, Peoples R China.
EM jianmeng648@163.com
RI Wu, Li-fang/AAD-5382-2021
OI Jian, Meng/0000-0001-5659-5128
FU This work was supported by the National Natural Science Foundation of
   China under Grant NO. 62176011 and NO. 61976010, and Inner Mongolia
   Autonomous Region Science and Technology Foundation under Grant NO.
   2021GG0333. [62176011, 61976010]; National Natural Science Foundation of
   China [2021GG0333]; Inner Mongolia Autonomous Region Science and
   Technology Foundation
FX This work was supported by the National Natural Science Foundation of
   China under Grant NO. 62176011 and NO. 61976010, and Inner Mongolia
   Autonomous Region Science and Technology Foundation under Grant NO.
   2021GG0333.
CR Anwar T, 2022, MULTIMED TOOLS APPL, V81, P35693, DOI 10.1007/s11042-021-11883-z
   Arampatzis A, 2018, ACM T INFORM SYST, V36, DOI 10.1145/3125620
   Bai PZ, 2019, PATTERN RECOGN, V88, P729, DOI 10.1016/j.patcog.2018.12.003
   Cao D, 2017, ACM T INFORM SYST, V35, DOI 10.1145/3017429
   Cao D, 2017, INFORM SCIENCES, V381, P161, DOI 10.1016/j.ins.2016.11.025
   Caschera MC, 2019, EVOL SYST-GER, V10, P363, DOI 10.1007/s12530-018-9242-z
   Chen JY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P335, DOI 10.1145/3077136.3080797
   Covington P, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P191, DOI 10.1145/2959100.2959190
   Guo HF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1725
   He XN, 2018, IEEE T KNOWL DATA EN, V30, P2354, DOI 10.1109/TKDE.2018.2831682
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   He XN, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P549, DOI 10.1145/2911451.2911489
   Hu YF, 2008, IEEE DATA MINING, P263, DOI 10.1109/ICDM.2008.22
   Jian M, 2021, Pattern Recognit
   Jiang SH, 2015, IEEE T MULTIMEDIA, V17, P907, DOI 10.1109/TMM.2015.2417506
   Jing Du, 2023, WSDM '23: Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining, P481, DOI 10.1145/3539597.3570373
   Kabbur S, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P659
   Konstan J., 2001, P 10 INT C WORLD WID, P285
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Li Y., 2021, J Phys: Conf Ser, V1748, P32
   Liu MS, 2023, PROCEEDINGS OF THE 2023 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, ICMR 2023, P576, DOI 10.1145/3591106.3592222
   Lu YC, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P773, DOI 10.1145/3178876.3186158
   Rendle S., 2009, P 25 C UNC ART INT, P452, DOI DOI 10.5555/1795114.1795167
   Shi G, 2020, KNOWL-BASED SYST, V196, DOI 10.1016/j.knosys.2020.105833
   Sun Y, 2017, ACM T INFORM SYST, V35, DOI 10.1145/3041659
   Tewari AS, 2020, PROCEDIA COMPUT SCI, V167, P1934, DOI 10.1016/j.procs.2020.03.215
   Thaipisutikul T, 2020, IND MANAGE DATA SYST, V120, P1901, DOI 10.1108/IMDS-04-2020-0207
   van den Berg R., 2018, P 24 ACM SIGKDD INT
   Wan SS, 2022, KNOWL-BASED SYST, V254, DOI 10.1016/j.knosys.2022.109551
   Wang HW, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P417, DOI 10.1145/3269206.3271739
   Wang X, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1001, DOI 10.1145/3397271.3401137
   Wang X, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P165, DOI 10.1145/3331184.3331267
   Wang X, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P185, DOI 10.1145/3077136.3080771
   WU Y, 2020, IEEE T KNOWL DATA EN, DOI DOI 10.1109/TKDE.2020.3002531
   Xue F, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3314578
   Ying R, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P974, DOI 10.1145/3219819.3219890
   Yu X, 2019, PATTERN RECOGN, V94, P96, DOI 10.1016/j.patcog.2019.05.030
   Yuan FJ, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1469, DOI 10.1145/3397271.3401156
   Zhou GR, 2019, AAAI CONF ARTIF INTE, P5941
NR 40
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 26
PY 2023
DI 10.1007/s11042-023-16945-y
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S8YJ1
UT WOS:001073965700013
DA 2024-07-18
ER

PT J
AU Mandloi, S
   Zuber, M
   Gupta, RK
AF Mandloi, Saurabh
   Zuber, Mohd
   Gupta, Rajeev Kumar
TI An explainable brain tumor detection and classification model using deep
   learning and layer-wise relevance propagation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Explainable AI; Convolution neural network; Conditional
   generative adversarial network; Layer-wise relevance propagation;
   Transfer learning model
ID SEGMENTATION; FUSION
AB The Brain tumor is the most common and devastating problem nowadays. Many people die every day as a result of a tumor's late detection, and these lives could have been saved if the tumor had been detected at an earlier stage. The early diagnosis of the tumor is very challenging due to its complex structure and uncontrollable growth. With the advent of Convolution Neural Network (CNN) and pre-trained models, researchers have put forth many tumor detection models over the past few decades. We have observed most of the solutions only focus on accuracy, and there is a significant lack of explanation and interpretability of the model. This work proposed an explainable brain tumor detection and classification model by using pre-trained models. The suggested model consists of four phases. In the first phase, a conditional generative adversarial network (cGAN) is used to generate the synthesis MRI images of distinct classes to cope with the data unbalancing and overfitting. In the second phase brain tumor is detected by using different pre-trained models like MobileNet, InceptionResNet, EfficientNet and VGGNet, and if the tumor is detected, it is classified in the third phase by using different pre-trained models. In the last phase, layer-wise relevance propagation (LRP) is used to Interpret the model outcome. The training, validation, and testing accuracy for the tumor detection model are 99.6%, 99.2%, and 99.0%, respectively, experiment findings show that InceptionResNetV2 pre-trained model performs better as compared to another pre-trained model. However, When it came to tumor classification, EfficientNet-B0 performed significantly better than the other models. With accuracy rates of 99.3%, 99.2%, and 99.0% during training, validation, and testing, respectively.
C1 [Mandloi, Saurabh; Zuber, Mohd] Madhyanchal Profess Univ, Dept Comp Sci & Engn, Bhopal 462044, Madhya Pradesh, India.
   [Gupta, Rajeev Kumar] Pandit Deendayal Energy Univ, Dept Comp Sci & Engn, Gandhinagar 382007, India.
C3 Pandit Deendayal Energy University
RP Gupta, RK (corresponding author), Pandit Deendayal Energy Univ, Dept Comp Sci & Engn, Gandhinagar 382007, India.
EM saurabhm.research@gmail.com; mzmkhanugc@gmail.com;
   rajeevmanit12276@gmail.com
RI Gupta, Rajeev Kumar/AAF-7872-2021
OI Gupta, Rajeev Kumar/0000-0002-5317-9919
CR Abu-Srhan A, 2022, J KING SAUD UNIV-COM, V34, P6977, DOI 10.1016/j.jksuci.2022.02.018
   Amin J, 2022, COMPLEX INTELL SYST, V8, P3161, DOI 10.1007/s40747-021-00563-y
   Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140
   Banerjee S, 2017, BRAIN TUMOR DETECTIO, P1
   Devkota B, 2018, PROCEDIA COMPUT SCI, V125, P115, DOI 10.1016/j.procs.2017.12.017
   Díaz-Pernas FJ, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9020153
   Dvorak P., 2015, J. appl. res. technol, V13, P58
   Gaur L, 2022, FRONT GENET, V13, DOI 10.3389/fgene.2022.822666
   Gupta Rajeev Kumar, 2022, International Journal of Fuzzy System Applications, V11, P1, DOI 10.4018/IJFSA.296587
   Gupta RK, 2022, INT J HEALTHC INF SY, V17, DOI 10.4018/IJHISI.20220401.oa1
   Gupta RK, 2022, INTERDISCIP SCI, V14, P485, DOI 10.1007/s12539-022-00502-6
   heatmapping, US
   Hossain T., 2019, 2019 1 INT C ADV SCI, P1, DOI [DOI 10.1109/ICASERT.2019.8934561, 10.1109/ICASERT.2019.8934561]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Kumar KSA, 2022, BIOMED SIGNAL PROCES, V76, DOI 10.1016/j.bspc.2022.103631
   Lather M, 2020, PROCEDIA COMPUT SCI, V167, P121, DOI 10.1016/j.procs.2020.03.189
   Ma Y, 2021, COGN COMPUT, V13, P418, DOI 10.1007/s12559-020-09796-4
   More Shraddha S., 2021, 2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS), P1532, DOI 10.1109/ICICCS51141.2021.9432164
   Muhammad K, 2021, IEEE T NEUR NET LEAR, V32, P507, DOI 10.1109/TNNLS.2020.2995800
   Pathik N, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14137701
   Phiphiphatphaisit Sirawan, 2020, ICISS 2020: Proceedings of the 2020 The 3rd International Conference on Information Science and System, P51, DOI 10.1145/3388176.3388179
   Rudresh D, 2021, P INT C FOR AN BIG D, P1, DOI DOI 10.1109/FABS52071.2021.9702583
   Saba T, 2020, COGN SYST RES, V59, P221, DOI 10.1016/j.cogsys.2019.09.007
   Salama WM, 2022, MULTIMED TOOLS APPL, V81, P16441, DOI 10.1007/s11042-022-12362-9
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun LN, 2022, INT J SYST ASSUR ENG, V13, P54, DOI 10.1007/s13198-021-01221-9
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   TAN M, 2019, EPILEPSIA, P1, DOI DOI 10.48550/ARXIV.1905.11946
   van der Velden BHM, 2022, MED IMAGE ANAL, V79, DOI 10.1016/j.media.2022.102470
   Yang G, 2022, INFORM FUSION, V77, P29, DOI 10.1016/j.inffus.2021.07.016
NR 30
TC 2
Z9 2
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33753
EP 33783
DI 10.1007/s11042-023-16708-9
EA SEP 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001075272400007
DA 2024-07-18
ER

PT J
AU Moran, J
   Qing, H
AF Moran, Ju
   Qing, Hu
TI MTNet: A multi-task cascaded network for underwater image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-task; Deep learning; Underwater image enhancement; Adaptive fusion
ID COLOR; WATER
AB Underwater image enhancement has attracted much attention due to the rise of underwater vision research in recent years. In real-world underwater scene, the images are always with color distortion and low brightness and contrast because of light scattering and absorption, which hinders the practical applications of underwater images. To improve the quality of visual underwater scenes, in this paper, we introduced a Multi-Task Cascaded Network (MTNet) for underwater image enhancement, which contains three cascaded sub-tasks, namely color reconstruction task, contrast reconstruction task and content reconstruction task. For each task, the color loss, Hue Saturation Value (HSV) loss, Structure Similarity Index Measure (SSIM) loss and image gradient loss are employed to train MTNet in an end-to-end way. Furthermore, we design an Adaptive Fusion Module (AFM) to fuse the feature maps from different reconstruction task adaptively. To verify the performance of MTNet, we conducted the comparative experiments on both synthetic underwater images and real world underwater images. Experimental results show that our proposed method achieves better performance in both quantitative and qualitative evaluations.
C1 [Moran, Ju; Qing, Hu] Dalian Maritime Univ, Coll Informat Sci & Technol, Dalian 116026, Liaoning, Peoples R China.
C3 Dalian Maritime University
RP Moran, J (corresponding author), Dalian Maritime Univ, Coll Informat Sci & Technol, Dalian 116026, Liaoning, Peoples R China.
EM jumoran@dlmu.edu.cn
OI Ju, Moran/0000-0002-3158-4956
FU The authors acknowledge National Natural Science Foundation of China
   (Grant no. 62201114) and the Fundamental Research Funds for the Central
   Universities (Grant no. 3132023233). [62201114]; National Natural
   Science Foundation of China [3132023233]; Fundamental Research Funds for
   the Central Universities
FX The authors acknowledge National Natural Science Foundation of China
   (Grant no. 62201114) and the Fundamental Research Funds for the Central
   Universities (Grant no. 3132023233).
CR Akkaynak D, 2019, PROC CVPR IEEE, P1682, DOI 10.1109/CVPR.2019.00178
   Akkaynak D, 2018, PROC CVPR IEEE, P6723, DOI 10.1109/CVPR.2018.00703
   Ancuti C, 2012, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2012.6247661
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Drews PLJ, 2016, IEEE COMPUT GRAPH, V36, P24, DOI 10.1109/MCG.2016.26
   Fu XY, 2017, I S INTELL SIG PROC, P789, DOI 10.1109/ISPACS.2017.8266583
   Fu XY, 2014, IEEE IMAGE PROC, P4572, DOI 10.1109/ICIP.2014.7025927
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Ghani ASA, 2015, APPL SOFT COMPUT, V37, P332, DOI 10.1016/j.asoc.2015.08.033
   Ghani ASA, 2015, APPL SOFT COMPUT, V27, P219, DOI 10.1016/j.asoc.2014.11.020
   Hou WL, 2012, APPL OPTICS, V51, P2678, DOI 10.1364/AO.51.002678
   HUMMEL R, 1977, COMPUT VISION GRAPH, V6, P184, DOI 10.1016/S0146-664X(77)80011-7
   Iqbal K, 2010, IEEE INT C SYSTEMS M
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   JAFFE JS, 1990, IEEE J OCEANIC ENG, V15, P101, DOI 10.1109/48.50695
   Kansal I, 2020, MULTIMED TOOLS APPL, V79, P12069, DOI 10.1007/s11042-019-08240-6
   Kansal I, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500546
   Kansal I, 2018, J MOD OPTIC, V65, P2103, DOI 10.1080/09500340.2018.1499976
   Kansal I, 2017, J MOD OPTIC, V64, P2023, DOI 10.1080/09500340.2017.1333641
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li CY, 2018, IEEE SIGNAL PROC LET, V25, P323, DOI 10.1109/LSP.2018.2792050
   Li CY, 2016, IEEE IMAGE PROC, P1993, DOI 10.1109/ICIP.2016.7532707
   Li J, 2018, IEEE ROBOT AUTOM LET, V3, P387, DOI 10.1109/LRA.2017.2730363
   LIU YC, 1995, IEEE T CONSUM ELECTR, V41, P460, DOI 10.1109/30.468045
   Ludvigsen M, 2007, OCEANOGRAPHY, V20, P140, DOI 10.5670/oceanog.2007.14
   Othman MK., 2022, UHD J SCI TECHNOL, V6, P135, DOI [10.21928/uhdjst.v6n2y2022.pp135-146, DOI 10.21928/UHDJST.V6N2Y2022.PP135-146]
   Peng YT, 2018, IEEE T IMAGE PROCESS, V27, P2856, DOI 10.1109/TIP.2018.2813092
   Rizzi A, 2002, P SOC PHOTO-OPT INS, V4662, P367, DOI 10.1117/12.469534
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sheinin M, 2016, PROC CVPR IEEE, P3764, DOI 10.1109/CVPR.2016.409
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   STRACHAN NJC, 1993, IMAGE VISION COMPUT, V11, P2, DOI 10.1016/0262-8856(93)90027-E
   Trucco E, 2006, IEEE J OCEANIC ENG, V31, P511, DOI 10.1109/JOE.2004.836395
   Wang N., 2019, ARXIV
   Wang Y, 2021, SIGNAL PROC IMAGE CO, V96
   Zhang S, 2017, NEUROCOMPUTING, V245, P1, DOI 10.1016/j.neucom.2017.03.029
   Zhao XW, 2015, OCEAN ENG, V94, P163, DOI 10.1016/j.oceaneng.2014.11.036
NR 38
TC 2
Z9 2
U1 9
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17629
EP 17643
DI 10.1007/s11042-023-16967-6
EA SEP 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001075272400009
DA 2024-07-18
ER

PT J
AU Ullah, A
   Yasin, S
   Alam, T
AF Ullah, Arif
   Yasin, Saman
   Alam, Tanweer
TI Latency aware smart health care system using edge and fog computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fog; Edge computing; IoT applications; Neural network; Healthcare
   applications
ID GOVERNANCE; FRAMEWORK
AB Numerous gadgets are linked together globally by the Internet of Things (IoT). Health checking, exercise programmers and remote medical assistance are a few examples of emerging areas in the healthcare system. Implementing cloud computing functionality on edge devices is the constant goal of fog computing. The approach is anticipated to surpass the minimum latencies requirement when used with Internet of Things (IoT) medical equipment. IoT devices produce different amounts of healthcare data. Due to the enormous volume of data produced, networks get overloaded, increasing delay. Traditional cloud servers are unable to meet the low latency requirements of IoT medical equipment and consumers. IoT data transfer, it is therefore vital to reduce network latency, computation delay, and energy consumption. Using FC, data can be stored, processed, and analyzed. Cloud computing data is located at a network edge to reduce high latency. Here, a novel resolution to the problem mentioned earlier is proposed. It combines an analytical model with a hybrid fuzzy-based reinforced learning technique in an FC setting. The objective is to reduce energy usage and cloud server latency for health-care IoT. The Internet of Things-FC context is selected and placed by the proposed smart FC analysis technique and algorithm using a fuzzy inference system, optimization techniques, and development approaches. The results showed that our suggested strategy reduced latency by 1.2% in comparison to other techniques.
C1 [Ullah, Arif] Air Univ, Fac Comp & Artificial Intelligence, Dept Comp Sci, Islamabad, Pakistan.
   [Yasin, Saman] Riphah Int Univ, Sch Comp, Islamabad, Pakistan.
   [Alam, Tanweer] Islamic Univ Madinah, Fac Comp & Informat Syst, Medina, Saudi Arabia.
C3 Air University Islamabad; Islamic University of Al Madinah
RP Ullah, A (corresponding author), Air Univ, Fac Comp & Artificial Intelligence, Dept Comp Sci, Islamabad, Pakistan.
EM arifullah@mail.au.edu.pk
RI Alam, Tanweer/M-7780-2017
OI Alam, Tanweer/0000-0003-2731-4627
CR Aburukba RO, 2020, FUTURE GENER COMP SY, V111, P539, DOI 10.1016/j.future.2019.09.039
   Ahmad M, 2016, J SUPERCOMPUT, V72, P3677, DOI 10.1007/s11227-016-1634-x
   Al-Anzi FS, 2014, ARCHITECTURE, V7, P347
   Alam T, 2022, RECENT INNOVATIONS A, P135
   [Anonymous], 2016, 2016 MED AD HOC NETW
   Biswas AR, 2014, 2014 IEEE WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P375, DOI 10.1109/WF-IoT.2014.6803194
   Bonomi Flavio, 2012, P 1 MCC WORKSH MOB C, P13, DOI 10.1145/2342509.2342513
   Breivold HP, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA SCIENCE AND DATA INTENSIVE SYSTEMS, P532, DOI 10.1109/DSDIS.2015.11
   Cao Y., 2015, P MOB HANGZH CHIN, P43, DOI [10.1145/2757384.2757398, DOI 10.1145/2757384.2757398]
   Chaudhury S, 2023, BUILDING SECURE BUSI, P168
   Chen M, 2018, FUTURE GENER COMP SY, V86, P403, DOI 10.1016/j.future.2018.03.054
   Colomo-Palacios R, 2012, J UNIVERS COMPUT SCI, V18, P1544
   Currie M, 2015, BMC HEALTH SERV RES, V15, DOI 10.1186/s12913-015-0825-0
   Dolui K, 2017, 2017 GLOBAL INTERNET OF THINGS SUMMIT (GIOTS 2017), P19
   Dubey Harishchandra., 2015, Proceedings of the ASE BigData SocialInformatics 2015, P14, DOI 10.1145/2818869.2818889
   Dzombeta S, 2014, IT PROF, V16, P30, DOI 10.1109/MITP.2014.52
   Ejaz M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21072502
   Gazis V, 2015, INT CONF INTELL NEXT, P145, DOI 10.1109/ICIN.2015.7073822
   Greco L, 2020, PATTERN RECOGN LETT, V135, P346, DOI 10.1016/j.patrec.2020.05.016
   Hayyolalam V, 2021, ARXIV
   He DB, 2015, IEEE INTERNET THINGS, V2, P72, DOI 10.1109/JIOT.2014.2360121
   Henke C, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 3, P341
   Ho KF, 2015, IEEE INT CONGR BIG, P309, DOI 10.1109/BigDataCongress.2015.51
   Hou XS, 2016, IEEE T VEH TECHNOL, V65, P3860, DOI 10.1109/TVT.2016.2532863
   Indrawan-Santiago M, 2020, P 22 INT C INF INT W
   Kadhim QK, 2018, J PHYS CONF SER, V1018, DOI 10.1088/1742-6596/1018/1/012006
   Kosta S, 2012, IEEE INFOCOM SER, P945, DOI 10.1109/INFCOM.2012.6195845
   Kraemer FA, 2017, IEEE ACCESS, V5, P9206, DOI 10.1109/ACCESS.2017.2704100
   Krallmann H, 2008, AUTONOMOUS SYSTEMS - SELF-ORGANIZATION, MANAGEMENT, AND CONTROL, P127, DOI 10.1007/978-1-4020-8889-6_14
   Kumar P, 2023, ENG APPL ARTIF INTEL, V120, DOI 10.1016/j.engappai.2023.105894
   Kumari A, 2018, COMPUT ELECTR ENG, V72, P1, DOI 10.1016/j.compeleceng.2018.08.015
   Li F, 2013, IEEE INT CONF CLOUD, P740, DOI 10.1109/CLOUD.2013.64
   Li JX, 2020, IEEE ACCESS, V8, P135479, DOI 10.1109/ACCESS.2020.3011503
   Li YJ, 2014, IEEE INFOCOM SER, P1060, DOI 10.1109/INFOCOM.2014.6848036
   Mahmud R, 2019, ACM T INTERNET TECHN, V19, DOI 10.1145/3186592
   Maier M.V., 2016, The internet of things (iot): what is the potential of internet of things applications for consumer marketing?
   Maiti P, 2019, INTERNET THINGS-NETH, V8, DOI 10.1016/j.iot.2019.100091
   Mao Y, 2017, ARXIV
   Marín-Tordera E, 2017, COMPUT COMMUN, V109, P117, DOI 10.1016/j.comcom.2017.05.013
   Medina V, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2492705
   Mell P, 2010, COMMUN ACM, V53, P50
   Monti A, 2016, PHASOR MEASUREMENT UNITS AND WIDE AREA MONITORING SYSTEMS: FROM THE SENSORS TO THE SYSTEM, P1, DOI 10.1016/B978-0-12-804569-5.00001-X
   Nasralla MM, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23135882
   Ngu AH, 2017, IEEE INTERNET THINGS, V4, P1, DOI 10.1109/JIOT.2016.2615180
   Obaid W, 2022, 2022 ADV SCI ENG TEC
   Ogbuke N, 2023, ANN OPER RES, DOI 10.1007/s10479-023-05462-8
   Ouhame S, 2021, NEURAL COMPUT APPL, V33, P10043, DOI 10.1007/s00521-021-05770-9
   Ouhame S, 2020, INT J ONLINE BIOMED, V16, P4, DOI 10.3991/ijoe.v16i14.16623
   Pareek K, 2021, IOP C SERIES MAT SCI
   Petruch K, 2011, INT J WEB GRID SERV, V7, P268, DOI 10.1504/IJWGS.2011.043531
   Porter ME, 2014, HARVARD BUS REV, V92, P64
   Rahmani AM, 2018, FUTURE GENER COMP SY, V78, P641, DOI 10.1016/j.future.2017.02.014
   Ren J, 2019, 2019 IEEE WIR COMM N, P1, DOI DOI 10.1109/ISEMC48616.2019.898611
   Sabate E, 2003, ADHERENCE LONG TERM
   Shi WS, 2016, IEEE INTERNET THINGS, V3, P637, DOI 10.1109/JIOT.2016.2579198
   Shi WS, 2016, COMPUTER, V49, P78, DOI 10.1109/MC.2016.145
   Shukla S, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0224934
   Singh A, 2021, COMPUT SECUR, V108, DOI 10.1016/j.cose.2021.102353
   Stantchev V, 2009, HIGH ASSURANCE SERVI, P1
   Stantchev V, 2009, INT C GRID PERV COMP
   Stantchev VJICSI, 2008, BERKELEY CALIFORNIA, P2008
   Stantchev V, 2009, 2009 THIRD INTERNATIONAL CONFERENCE ON ADVANCED ENGINEERING COMPUTING AND APPLICATIONS IN SCIENCES (ADVCOMP 2009), P187, DOI 10.1109/ADVCOMP.2009.36
   Stantchev V, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON INTERNET AND WEB APPLICATIONS AND SERVICES (ICIW 2008), P696, DOI 10.1109/ICIW.2008.113
   Ullah A, 2021, J AMB INTEL HUM COMP, P1
   Ullah A, 2022, MULTIMED TOOLS APPL, V81, P29443, DOI 10.1007/s11042-022-12904-1
   Velciu M, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su151310330
NR 66
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 34055
EP 34081
DI 10.1007/s11042-023-16899-1
EA SEP 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001075272400017
DA 2024-07-18
ER

PT J
AU Liu, JL
   Ji, YJ
   Wang, GC
   Wang, H
AF Liu, Jiali
   Ji, Yujiao
   Wang, Guangcheng
   Wang, Han
TI Multiscale deformable convolution for RGB-FIR multimodal visibility
   estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Visibility estimation; RGB-FIR multimode; Multiscale deformable
   convolution
ID FUSION
AB Fog concentration, area, and boundary shape have a strong ability to distinguish various visibility ranges. However, standard convolution is challenging to provide an effective fog feature description for visibility range classification tasks due to the fixed grid kernel structure. To this aim, a multiscale deformable convolution model (MDCM) is proposed to describe fog features, which makes effectively sampling discriminating features from the atmospheric region in a foggy image. Moreover, to enhance robustness, we use RGB-FIR multimodal images as inputs and design a multimodal visibility range classification network based on the MDCM. Experimental results show that with the help of MDCM and multimodal observations, both the robustness and accuracy of visibility range classification performance are raised beyond 30% compared to standard convolutional neural networks.
C1 [Liu, Jiali; Ji, Yujiao; Wang, Guangcheng; Wang, Han] Nantong Univ, Sch Transportat & Civil Engn, Nantong, Peoples R China.
C3 Nantong University
RP Wang, GC; Wang, H (corresponding author), Nantong Univ, Sch Transportat & Civil Engn, Nantong, Peoples R China.
EM wanggc@ntu.edu.cn; hanwang@ntu.edu.cn
OI wang, han/0000-0003-1771-8134
FU This work was supported by the Natural Science Foundation of China under
   Grant 61872425 and Jiangsu Province Graduate Practice Innovation
   Program(SJCX23_1786). [61872425]; Natural Science Foundation of China
   [SJCX23_1786]; Jiangsu Province Graduate Practice Innovation Program
FX This work was supported by the Natural Science Foundation of China under
   Grant 61872425 and Jiangsu Province Graduate Practice Innovation
   Program(SJCX23_1786).
CR Alenezi F, 2022, CMC-COMPUT MATER CON, V71, P3425, DOI 10.32604/cmc.2022.023339
   Chen J., 2023, IET Signal Proc, V17, pe12164
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Eitel A, 2015, IEEE INT C INT ROBOT, P681, DOI 10.1109/IROS.2015.7353446
   Gao LG, 2016, IEEE ELECTR DEVICE L, V37, P870, DOI 10.1109/LED.2016.2573140
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jiang K, 2023, IEEE T NEUR NET LEAR, V34, P3594, DOI 10.1109/TNNLS.2021.3112235
   Jiang K, 2020, IEEE T MULTIMEDIA, V22, P2734, DOI 10.1109/TMM.2019.2960586
   Kaur H, 2021, ARCH COMPUT METHOD E, V28, P4425, DOI 10.1007/s11831-021-09540-7
   Kim J, 2022, ATMOS RES, V275, DOI 10.1016/j.atmosres.2022.106239
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li JP, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11030997
   Liu JW, 2022, IEEE ACCESS, V10, P120329, DOI 10.1109/ACCESS.2022.3218456
   Liu Z, 2022, ATMOS ENVIRON, V278, DOI 10.1016/j.atmosenv.2022.119085
   Liu ZY, 2020, IEEE T INSTRUM MEAS, V69, P9681, DOI 10.1109/TIM.2020.3001695
   Luo Y, 2022, OPTIK, V258, DOI 10.1016/j.ijleo.2022.168914
   Ortega LC, 2023, INT J FORECASTING, V39, P992, DOI 10.1016/j.ijforecast.2022.03.009
   Palvanov A, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061343
   Qin HS, 2022, IEEE ACCESS, V10, P25448, DOI 10.1109/ACCESS.2021.3101323
   Shengyan Li, 2017, International Journal of Computer Theory and Engineering, V9, P455, DOI 10.7763/IJCTE.2017.V9.1186
   Song MF, 2021, J CLOUD COMPUT-ADV S, V10, DOI 10.1186/s13677-021-00261-7
   Wang H, 2020, IEEE ACCESS, V8, P217057, DOI 10.1109/ACCESS.2020.3031283
   Wang HW, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/1714961
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiyu M, 2021, 2021 IEEE 31 INT WOR, P1
   Xun LN, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22166227
   Yang WH, 2020, IEEE T IMAGE PROCESS, V29, P5737, DOI 10.1109/TIP.2020.2981922
   Yin SB, 2022, KNOWL-BASED SYST, V258, DOI 10.1016/j.knosys.2022.109997
   You J, 2022, IEEE T INTELL TRANSP, V23, P22354, DOI 10.1109/TITS.2022.3180229
   You Y, 2019, IEEE T IMAGE PROCESS, V28, P45, DOI 10.1109/TIP.2018.2857219
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang F, 2023, ATMOSPHERE-BASEL, V14, DOI 10.3390/atmos14010061
   Zhang H, 2021, INFORM FUSION, V76, P323, DOI 10.1016/j.inffus.2021.06.008
NR 34
TC 0
Z9 0
U1 5
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 23
PY 2023
DI 10.1007/s11042-023-17047-5
EA SEP 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T5BU0
UT WOS:001078145100004
DA 2024-07-18
ER

PT J
AU Kaur, R
   Kaur, N
AF Kaur, Ramandeep
   Kaur, Navdeep
TI Ti-FCNet: Triple fused convolutional neural network-based automated skin
   lesion classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin cancer; Augmentation; Triple network features; Lesion segmentation;
   Feature fusion; Loss optimization
ID ORIGINAL RESEARCH
AB Cancer is one of the most severe forms of disease that adversely threaten human life in recent years. Considering different categories of cancer, skin cancer seems to be a high risk. The Deep learning (DL) method has been established to promote enhanced performance in classifying the diverse skin lesion stages. Manual detection is not accurate and time-consuming for lesion recognition, so automated DL models are presented in the existing models. However, the existing approaches are less accurate because of insufficient feature representation, high processing overhead and increased complexity. To conquer the existing drawbacks, a novel DL-based segmentation approach is proposed in this research work. Initially, the data are gathered from the International Skin Imaging Collaboration (ISIC 2019) dataset. The lesion and non-lesion regions are then segmented using a convolutional neural network (CNN). The segmented lesion images are augmented to increase the data size and pre-processed by image rescaling. The pre-processed images are fed into Triple Convolutional Neural Networks (T-CNN), where Deep Fused Feature Extraction and Classification process are performed. The features obtained from Densenet-201, Resnet-152 and SqueezeNet are fused to generate a feature vector, whereas melanoma and non-melanoma images are classified using softmax. The T-CNN network loss is optimized using the Weighted Sum method (WSM) to enhance the overall performance. The performances are evaluated using MATLAB, and an overall accuracy of 99.01% is obtained.
C1 [Kaur, Ramandeep; Kaur, Navdeep] Sri Guru Granth Sahib World Univ, Dept Comp Sci, Fatehgarh Sahib 140406, Punjab, India.
RP Kaur, R (corresponding author), Sri Guru Granth Sahib World Univ, Dept Comp Sci, Fatehgarh Sahib 140406, Punjab, India.
EM ramancheemachahal@gmail.com
CR Adegun A, 2021, ARTIF INTELL REV, V54, P811, DOI 10.1007/s10462-020-09865-y
   Ahmed S, 2020, INDIAN J RHEUMATOL, V15, P298, DOI 10.4103/injr.injr_3_20
   Akyel C, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10050736
   Ali R, 2021, ARXIV
   Anjum MA, 2020, IEEE ACCESS, V8, P129668, DOI 10.1109/ACCESS.2020.3009276
   [Anonymous], 2019, MelaNet: a deep dense attention network for melanoma detection in dermoscopy images
   [Anonymous], 2019, Skin lesion classification using loss balancing and ensembles of multi-resolution EfficientNets
   Bi L., 2017, Automatic Skin Lesion Analysis using Largescale Dermoscopy Images and Deep Residual Networks
   Datta SK, 2021, LECT NOTES COMPUT SC, V12929, P13, DOI 10.1007/978-3-030-87444-5_2
   Durgarao N, 2021, IET IMAGE PROCESS, V15, P2266, DOI 10.1049/ipr2.12194
   Fraiwan M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22134963
   Ganesan P, 2020, INT CONF ADVAN COMPU, P357, DOI [10.1109/ICACCS48705.2020.9074333, 10.1109/icaccs48705.2020.9074333]
   Garg S, 2021, MULTIMED TOOLS APPL, V80, P7397, DOI 10.1007/s11042-020-10064-8
   Gu YY, 2020, IEEE J BIOMED HEALTH, V24, P1379, DOI 10.1109/JBHI.2019.2942429
   Höhn J, 2021, EUR J CANCER, V149, P94, DOI 10.1016/j.ejca.2021.02.032
   Huang HW, 2021, J DERMATOL, V48, P310, DOI 10.1111/1346-8138.15683
   Javed R., 2019, BIOMED RES, V30, P1, DOI DOI 10.1016/J.MICRON.2018.09.015
   Kassem MA, 2020, IEEE ACCESS, V8, P114822, DOI 10.1109/ACCESS.2020.3003890
   Khan AH, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6907
   Khan MA, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12497
   Liu LN, 2021, J IMAGING, V7, DOI 10.3390/jimaging7040067
   Liu QD, 2020, IEEE T MED IMAGING, V39, P3429, DOI 10.1109/TMI.2020.2995518
   Maron RC, 2021, EUR J CANCER, V155, P191, DOI 10.1016/j.ejca.2021.06.047
   Mohakud R, 2022, J KING SAUD UNIV-COM, V34, P9889, DOI 10.1016/j.jksuci.2021.12.018
   Ning X, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108873
   Pitoya PA., 2021, J ELEKT ILMU KOMPUTE, V2301, P5373
   Pollastri F, 2019, AIMAGELAB PRHLT ISIC
   Pour MP, 2020, EXPERT SYST APPL, V144, DOI 10.1016/j.eswa.2019.113129
   Saba T, 2021, MICROSC RES TECHNIQ, V84, P1272, DOI 10.1002/jemt.23686
   Sun Q, 2021, BIOMED RES INT-UK, V2021
   Sushmithawathi K, 2021, INT RES J MOD ENG TE, P2582
   Thapar P., 2022, JO HEALTHCARE ENG, V18, P2022
   Thomas SM, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101915
   Wang C, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108498
   Wang CX, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3104907
   Wei LS, 2020, IEEE ACCESS, V8, P99633, DOI 10.1109/ACCESS.2020.2997710
   Xie FY, 2020, COMPUT METH PROG BIO, V186, DOI 10.1016/j.cmpb.2019.105241
   Xu ZY, 2020, OPEN MED-WARSAW, V15, P860, DOI 10.1515/med-2020-0131
   Zhang GK, 2019, IEEE ACCESS, V7, P140936, DOI 10.1109/ACCESS.2019.2943628
   Zhao C, 2021, IEEE ACCESS, V9, P8659, DOI 10.1109/ACCESS.2021.3049600
   Zhou S., 2019, Technical Report
NR 41
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32525
EP 32551
DI 10.1007/s11042-023-16594-1
EA SEP 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069968300001
DA 2024-07-18
ER

PT J
AU Ben Aissa, F
   Hamdi, M
   Zaied, M
   Mejdoub, M
AF Ben Aissa, Fatma
   Hamdi, Monia
   Zaied, Mourad
   Mejdoub, Mahmoud
TI An overview of GAN-DeepFakes detection: proposal, improvement, and
   evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generative adversarial networks; Image and video forensics; DeepFakes
   detection; Deep learning
AB Image source forensics is commonly regarded as one of the most effective methods for blindly verifying the authenticity and integrity of digital images. The most recent topic related to image source forensics is the detection of DeepFakes generated using Generative adversarial networks (GANs). In recent years, with the rapid growth of GANs, a photo-realistic image can be easily generated from a random vector. Moreover, the images generated by advanced GANs are very realistic. It is reasonable to acknowledge that even a well-trained viewer has difficulties distinguishing artificial from real images. Therefore, detecting DeepFakes generated by GANs is an important task. By reviewing the background of DeepFakes detection methods, this paper aims to provide readers with a systematic understanding of GAN, its variants used to create DeepFakes, and, more crucially, methods proposed to identify DeepFakes in the literature to date.
C1 [Ben Aissa, Fatma; Zaied, Mourad; Mejdoub, Mahmoud] Univ Gabes, Natl Engn Sch Gabes ENIG, Res Team Intelligent Machines RTIM, Gabes, Tunisia.
   [Hamdi, Monia] Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Technol, POB 84428, Riyadh 11671, Saudi Arabia.
C3 Universite de Gabes; Princess Nourah bint Abdulrahman University
RP Hamdi, M (corresponding author), Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Technol, POB 84428, Riyadh 11671, Saudi Arabia.
EM fatmabenaissa1@gmail.com; mshamdi@pnu.edu.sa; mourad.zaied@ieee.org;
   mah.mejdoub@gmail.com
RI Hamdi, Monia/ABG-1263-2021
OI Hamdi, Monia/0000-0003-3690-9868
FU Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia
   [PNURSP2023R125]
FX This research was funded by Princess Nourah bint Abdulrahman University
   Researchers Supporting Project number (PNURSP2023R125), Princess Nourah
   bint Abdulrahman University, Riyadh, Saudi Arabia
CR Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bansal A, 2018, LECT NOTES COMPUT SC, V11209, P122, DOI 10.1007/978-3-030-01228-1_8
   Ben Aissa F, 2020, PROC SPIE, V11433, DOI 10.1117/12.2559848
   Brock A., 2019, INT C LEARN REPR
   Ciftci UA, 2020, IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2020)
   Ciftci Umur Aybars, 2020, IEEE Trans Pattern Anal Mach Intell, VPP, DOI 10.1109/TPAMI.2020.3009287
   Dang H, 2020, PROC CVPR IEEE, P5780, DOI 10.1109/CVPR42600.2020.00582
   darkwebnews, VALUE STOLEN DATA DA
   Dolhansky Brian, 2019, ARXIV191008854
   Dufour Nicholas, Deepfakes detection dataset by Google JigSaw
   generated, 100K FACES GENERATED
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gray D., 2007, P IEEE INT WORKSH PE, V3, P41
   Guera D., 2018, 15 IEEE INT C ADV VI, P1, DOI [DOI 10.1109/AVSS.2018.8639163, 10.1109/AVSS.2018.8639163]
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He PS, 2019, IEEE IMAGE PROC, P2299, DOI [10.1109/icip.2019.8803740, 10.1109/ICIP.2019.8803740]
   He YA, 2021, PROC CVPR IEEE, P4358, DOI 10.1109/CVPR46437.2021.00434
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hsu CC, 2018, INT SYMP COMP CONS, P388, DOI 10.1109/IS3C.2018.00104
   Huh M, 2018, LECT NOTES COMPUT SC, V11215, P106, DOI 10.1007/978-3-030-01252-6_7
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Javed, 2021, P WEB C, DOI [10.48550/arXiv.2107.14480, DOI 10.48550/ARXIV.2107.14480]
   Jiang LM, 2020, PROC CVPR IEEE, P2886, DOI 10.1109/CVPR42600.2020.00296
   Juefei-Xu F, 2022, INT J COMPUT VISION, V130, P1678, DOI 10.1007/s11263-022-01606-8
   Karras T, 2018, P INT C LEARN REPR I
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Korshunov P., 2018, arXiv
   Lalonde J, 2017, IEEE INT C COMPUTER, P1, DOI [10.1109/ICCV.2007.4409107, DOI 10.1109/ICCV.2007.4409107]
   Le T, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.14480
   Li H., 2018, ARXIV
   Li Y., 2018, 2018 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2018.8630787
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Lima D, 2020, DEEPFAKE DETECTION U
   Liu X., 2020, P IEEE CVF C COMP VI, P8057
   Liu Z, 2015, 20TH INTERNATIONAL CONFERENCE ON COMPOSITE MATERIALS
   Mao XJ, 2016, ADV NEUR IN, V29
   Mirsky Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3425780
   Mittal T, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2823, DOI 10.1145/3394171.3413570
   Mo HX, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P43, DOI 10.1145/3206004.3206009
   Mustak M, 2023, J BUS RES, V154, DOI 10.1016/j.jbusres.2022.113368
   Nguyen T, 2022, ARXIV, DOI DOI 10.48550/ARXIV.1909.11573
   Nguyen T. T., 2019, CoRR
   Nhu T, 2018, P INT S INF TECHN CO
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   Pu JM, 2020, ANN COMPUT SECURITY, P913, DOI 10.1145/3427228.3427285
   Radford A., 2015, ARXIV
   Rossi A, 2020, IEEE T INTELL TRANSP, V21, P2980, DOI 10.1109/TITS.2019.2922002
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sabir E., 2019, INTERFACES GUI, V3, P80
   Salakhutdinov R., 2009, ARTIFICIAL INTELLIGE, V5, P448, DOI DOI 10.1109/CVPRW.2009.5206577
   Schroepfer M., 2019, Creating a data set and a challenge for deepfakes
   Schwartz O., 2018, You Thought Fake News was Bad? Deep Fakes are Where Truth goes to Die
   Tolosana Ruben, 2020, Information Fusion, V64, P131, DOI 10.1016/j.inffus.2020.06.014
   Turek M., 2019, Media Forensics (MediFor)
   Xuan XS, 2019, LECT NOTES COMPUT SC, V11818, P134, DOI 10.1007/978-3-030-31456-9_15
   Yadav D, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), P852, DOI [10.1109/iccs45141.2019.9065881, 10.1109/ICCS45141.2019.9065881]
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yi Dong, 2014, ARXIV14117923
   Yu N, 2019, PROC CVPR IEEE, P12156, DOI 10.1109/CVPR.2019.01244
   Zhai L, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2009.09205
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang T, 2022, MULTIMED TOOLS APPL, V81, P6259, DOI 10.1007/s11042-021-11733-y
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhuang YX, 2019, IEEE IMAGE PROC, P3212, DOI [10.1109/icip.2019.8803464, 10.1109/ICIP.2019.8803464]
NR 68
TC 2
Z9 2
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32343
EP 32365
DI 10.1007/s11042-023-16761-4
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001066465100001
DA 2024-07-18
ER

PT J
AU Guo, J
   Gong, R
   Ma, YL
   Liu, M
   Xi, XM
   Nie, XS
   Yin, YL
AF Guo, Jie
   Gong, Rui
   Ma, Yuling
   Liu, Meng
   Xi, Xiaoming
   Nie, Xiushan
   Yin, Yilong
TI A survey of micro-video analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Venue recognition; Popularity prediction; micro-video recommendation
ID LOW-RANK; REPRESENTATION; RECOMMENDATION
AB As opposed to traditional video, a micro-video is a short video that is spread on social platforms. As user-generated contents, micro-videos have stronger social attributes compared to ordinary videos. Research on micro-video analysis has been conducted in both industry and academia and includes venue classification, tag prediction, popularity prediction, action prediction, click prediction, and recommendation. In this paper, we first review the studies on these tasks in terms of micro-video classification, prediction, and recommendation. Thereafter, we present an overview of the methods, features, datasets, and evaluation metrics relating to these studies. Finally, we analyze the challenges of micro-video analysis. Because of the limited research work on micro-video analysis, we can not summarize some aspects of micro-video analysis, such as micro-video classification.We believe that this survey will aid in enhancing the knowledge of researchers and practitioners who are interested in micro-video analysis.
C1 [Guo, Jie; Gong, Rui; Ma, Yuling; Liu, Meng; Xi, Xiaoming; Nie, Xiushan] Shandong Jianzhu Univ, Jinan, Peoples R China.
   [Yin, Yilong] Shandong Univ, Jinan, Peoples R China.
C3 Shandong Jianzhu University; Shandong University
RP Nie, XS (corresponding author), Shandong Jianzhu Univ, Jinan, Peoples R China.
EM guojiesdu@163.com; niexiushan@163.com
RI Gong, Rui/JYO-4823-2024
FU National Natural Science Foundation of China [62176141, 62176139,
   61876098]; Major Basic Research Project of Natural Science Foundation of
   Shandong Province [ZR2021ZD15]; Taishan Scholar Project of Shandong
   Province [tsqn202103088]; Shandong Provincial Natural Science Foundation
   for Distinguished Young Scholars [ZR2021JQ26]; Natural Science
   Foundation of Shandong Province [ZR2021QF119, ZR2022MF272]; Shandong
   Jianzhu University
FX This work was supported in part by the National Natural Science
   Foundation of China (62176141, 62176139, 61876098), Major Basic Research
   Project of Natural Science Foundation of Shandong Province (ZR2021ZD15),
   Taishan Scholar Project of Shandong Province (tsqn202103088), Shandong
   Provincial Natural Science Foundation for Distinguished Young Scholars
   (ZR2021JQ26), Natural Science Foundation of Shandong Province
   (ZR2021QF119, ZR2022MF272) and special funds for distinguished
   professors of Shandong Jianzhu University.
CR Cao D, 2020, KNOWL-BASED SYST, V203, DOI 10.1016/j.knosys.2020.106114
   Chen J, 2019, LECT NOTES ARTIF INT, V11775, P371, DOI 10.1007/978-3-030-29551-6_33
   Chen JY, 2018, LECT NOTES COMPUT SC, V10705, P327, DOI 10.1007/978-3-319-73600-6_28
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1454, DOI 10.1145/2964284.2971477
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P898, DOI 10.1145/2964284.2964314
   Chen XS, 2021, IEEE T MULTIMEDIA, V23, P484, DOI 10.1109/TMM.2020.2978618
   Chen XS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1146, DOI 10.1145/3240508.3240617
   Ding Jingtao, 2018, 2018 SIAM International Conference on Data Mining (SDM). SIAM, P198
   Gu XW, 2020, NEUROCOMPUTING, V410, P441, DOI 10.1016/j.neucom.2020.05.026
   Guo J, 2021, INFORM SCIENCES, V543, P504, DOI 10.1016/j.ins.2020.05.064
   Guo J, 2020, IEEE ACCESS, V8, P29518, DOI 10.1109/ACCESS.2020.2973240
   Guo J, 2019, MULTIMED TOOLS APPL, V78, P24539, DOI 10.1007/s11042-018-6999-9
   Guo J, 2018, LECT NOTES COMPUT SC, V11164, P721, DOI 10.1007/978-3-030-00776-8_66
   Han YQ, 2021, WORLD WIDE WEB, V24, P1045, DOI 10.1007/s11280-020-00858-z
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He L, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P4721, DOI 10.1145/3459637.3481979
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang L, 2018, LECT NOTES COMPUT SC, V10735, P564, DOI 10.1007/978-3-319-77380-3_54
   Huang L, 2017, MULTIMED TOOLS APPL, V76, P20341, DOI 10.1007/s11042-017-4781-z
   Jian MW, 2021, INFORM SCIENCES, V576, P819, DOI 10.1016/j.ins.2021.08.069
   Jian MW, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114219
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P1, DOI 10.1016/j.jvcir.2018.10.008
   Jiang H, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3487, DOI 10.1145/3394171.3413653
   Jiang YG, 2014, AAAI CONF ARTIF INTE, P73
   Jin YY, 2019, LECT NOTES COMPUT SC, V11902, P607, DOI 10.1007/978-3-030-34110-7_51
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lei CY, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3161, DOI 10.1145/3447548.3467189
   Li MM, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P509, DOI 10.1145/3357384.3357912
   Li YQ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1464, DOI 10.1145/3343031.3350950
   Liu M, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P970, DOI 10.1145/3123266.3123341
   Liu M, 2019, IEEE T IMAGE PROCESS, V28, P1235, DOI 10.1109/TIP.2018.2875363
   Liu S, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3020, DOI 10.1145/3308558.3313513
   Liu S, 2019, IEEE INT CON MULTI, P460, DOI 10.1109/ICME.2019.00086
   Liu SM, 2020, INT SYMPOS VLSI DES, DOI 10.1109/vlsi-dat49148.2020.9196335
   Liu W, 2020, MULTIMED TOOLS APPL, V79, P6709, DOI 10.1007/s11042-019-08147-2
   Liu W, 2018, LECT NOTES COMPUT SC, V11165, P705, DOI 10.1007/978-3-030-00767-6_65
   Liu W, 2019, IEEE ACCESS, V7, P77091, DOI 10.1109/ACCESS.2019.2922430
   Liu YY, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P1099, DOI 10.1145/3459637.3482417
   Liu ZZ, 2016, 2016 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P526, DOI 10.1109/CompComm.2016.7924756
   Lu XW, 2022, MULTIMEDIA SYST, V28, P1689, DOI 10.1007/s00530-022-00940-8
   Lu Y., 2021, ARXIV
   Ma JW, 2019, DATA SCI ENG, V4, P240, DOI 10.1007/s41019-019-00101-4
   Ma JW, 2019, LECT NOTES COMPUT SC, V11447, P384, DOI 10.1007/978-3-030-18579-4_23
   Ma JW, 2018, MULTIMED TOOLS APPL, V77, P2991, DOI 10.1007/s11042-017-4827-2
   Ma SJ, 2019, IEEE INT CON MULTI, P472, DOI 10.1109/ICME.2019.00088
   Nguyen PX, 2016, ARXIV
   Nie L., 2019, Multimodal learning toward micro-video understanding
   Nie LQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1192, DOI 10.1145/3123266.3123313
   Redi M, 2014, PROC CVPR IEEE, P4272, DOI 10.1109/CVPR.2014.544
   Sano S, 2014, IEEE IMAGE PROC, P5182, DOI 10.1109/ICIP.2014.7026049
   Shang S., 2016, COMP INF SCI ICIS 20, P1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su YT, 2020, IEEE SIGNAL PROC LET, V27, P740, DOI 10.1109/LSP.2020.2983831
   Su YT, 2020, MULTIMEDIA SYST, V26, P519, DOI 10.1007/s00530-020-00660-x
   Wan WB, 2022, NEUROCOMPUTING, V488, P226, DOI 10.1016/j.neucom.2022.02.083
   Wang B, 2022, COMPUT ELECTR ENG, V102, DOI 10.1016/j.compeleceng.2022.108127
   Wang B, 2022, J INTELL FUZZY SYST, V43, P3337, DOI 10.3233/JIFS-213191
   Wei YW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1446, DOI 10.1145/3343031.3350858
   Wei YW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1437, DOI 10.1145/3343031.3351034
   Wei YW, 2020, IEEE T IMAGE PROCESS, V29, P1, DOI 10.1109/TIP.2019.2923608
   Xie JY, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2542, DOI 10.1145/3366423.3380004
   Yang C, 2020, IEEE ACCESS, V8, P78252, DOI 10.1109/ACCESS.2020.2989473
   Yao D, 2021, AAAI CONF ARTIF INTE, V35, P15945
   Yi J, 2023, IEEE T MULTIMEDIA, V25, P515, DOI 10.1109/TMM.2021.3128254
   Yuting S., 2021, INFORM SCIENCES, V575, P587
   Zhang J., 2016, P ACM INT C MULT, P1415
   Zhang J, 2020, IEEE ACCESS, V8, P87266, DOI 10.1109/ACCESS.2020.2992436
   Zhu Y, 2003, ARXIV
NR 69
TC 0
Z9 0
U1 11
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32191
EP 32212
DI 10.1007/s11042-023-16691-1
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001066465100002
DA 2024-07-18
ER

PT J
AU Saravanan, V
   Madiajagan, M
   Rafee, SM
   Sanju, P
   Rehman, TB
   Pattanaik, B
AF Saravanan, V.
   Madiajagan, M.
   Rafee, Shaik Mohammad
   Sanju, P.
   Rehman, Tasneem Bano
   Pattanaik, Balachandra
TI IoT-based blockchain intrusion detection using optimized recurrent
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Intrusion detection system; Deep learning;
   Identity-based encryption; African buffalo optimization; Blockchain
AB In recent years, Intrusion Detection Systems (IDS) monitor the computer network system by collecting and analyzing data or information by identifying the behavior of the user or predicting the attacks by the automatic response. So, in this paper, the Blockchain-based African Buffalo (BbAB) scheme with Recurrent Neural Network (RNN) model is proposed for detecting the intrusion by enhancing security. Furthermore, normal and malware user datasets are collected and trained in the system and the dataset is encrypted using Identity Based Encryption (IBE). The encrypted data are securely stored in the blockchain in the cloud. Hereafter, Recurrent Neural Network (RNN) was employed to detect the intrusion in a cloud environment. African buffalo optimization was used in the RNN prediction phase for continuous monitoring of intrusion. Finally, the performance results of the developed technique are compared with other conventional models in terms of accuracy, precision, recall, F1-score, and detection rate. The outperformance of the designed model attains better accuracy of 99.87% and high recall of 99.92%.it shows the efficiency of the designed model to protect data and security in cloud computing.
C1 [Saravanan, V.] Dambi Dollo Univ, Coll Engn & Technol, Dept Comp Sci, Dambi Dollo, Oromia Region, Ethiopia.
   [Madiajagan, M.] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, India.
   [Rafee, Shaik Mohammad] Sasi Inst Technol & Engn, Dept EEE, Tadepalligudem, Andhra Pradesh, India.
   [Sanju, P.] Univ Coll Engn Tindivanam, Comp Sci & Engn, UCET, Tindivanam 604001, India.
   [Rehman, Tasneem Bano] SAGE Univ Bhopal, Dept Comp Sci & Engn, Bhopal, Madhya Pradesh, India.
   [Pattanaik, Balachandra] Wollega Univ, Coll Engn & Technol, Dept Elect & Comp Engn, Nekemte, Ethiopia.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Saravanan, V (corresponding author), Dambi Dollo Univ, Coll Engn & Technol, Dept Comp Sci, Dambi Dollo, Oromia Region, Ethiopia.
EM saravanan.vace675@gmail.com
RI PATTANAIK, BALACHANDRA/AGV-4417-2022; Shaik, Mohammad
   rafee/JPW-7828-2023
OI PATTANAIK, BALACHANDRA/0000-0002-8493-6978; Shaik, Mohammad
   rafee/0000-0002-8869-1656; Muthaiyan, Madiajagan/0000-0002-8499-8976
CR Al Makdi K, 2020, 2020 3 INT C SIGN PR
   Alashhab ZR., 2021, SCI TECHNOL HUM VAL, V19
   Albanese G, 2020, J AMB INTEL HUM COMP, V11, P4909, DOI 10.1007/s12652-020-01761-1
   Alkadi O, 2021, IEEE INTERNET THINGS, V8, P9463, DOI 10.1109/JIOT.2020.2996590
   Anthi E, 2019, IEEE INTERNET THINGS, V6, P9042, DOI 10.1109/JIOT.2019.2926365
   Arif YM., 2020, INT J INTELL ENG INF, V13, P472, DOI DOI 10.22266/IJIES2020.1231.42
   Belhadi A, 2023, CLUSTER COMPUT, V26, P1147, DOI 10.1007/s10586-022-03779-w
   Borangiu T, 2019, COMPUT IND, V108, P150, DOI 10.1016/j.compind.2019.01.006
   Brown IL, 2018, APPROPRIATE TECH
   Das S, 2022, COMPUT ELECTR ENG, V101, DOI 10.1016/j.compeleceng.2022.107991
   Datta P, 2020, 2020 2 INT C ADV INF
   Derhab A, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/6689134
   Firdaus M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11010414
   HaddadPajouh H, 2018, FUTURE GENER COMP SY, V85, P88, DOI 10.1016/j.future.2018.03.007
   Jayasinghe U, 2019, WIREL COMMUN MOB COM, V2019, DOI 10.1155/2019/2014697
   Kerr M, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P349
   Khoa TA, 2020, WIREL COMMUN MOB COM, V2020
   Khraisat A, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8111210
   Lee JY, 2019, BUS HORIZONS, V62, P773, DOI 10.1016/j.bushor.2019.08.003
   Liang C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9071120
   Mansour RF, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-17043-z
   Nathiya T, 2019, ADV INTELL SYST, V839, P483, DOI 10.1007/978-981-13-1274-8_36
   Nguyen DC, 2021, IEEE INTERNET THINGS, V8, P12806, DOI 10.1109/JIOT.2021.3072611
   Perwej Y., 2019, Int. J. Comput. Appl, V975, P182, DOI DOI 10.5120/IJCA2019918763
   Kumar MVR, 2021, WIRELESS PERS COMMUN, V117, P987, DOI 10.1007/s11277-020-07907-w
   Rath M, 2018, INT J HUMAN RIGHTS H
   Sharafaldin I, 2019, INT CARN CONF SECU
   Swetha MS, 2020, 2020 IEEE INT C MACH
   Thilagam T, 2021, ICT EXPRESS, V7, P512, DOI 10.1016/j.icte.2021.04.006
   Velmurugadass P, 2021, MATER TODAY-PROC, V37, P2653, DOI 10.1016/j.matpr.2020.08.519
   Zhang K., 2018, Towards Dependable, Scalable, and Pervasive Distributed Ledgers with Blockchains
NR 31
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31505
EP 31526
DI 10.1007/s11042-023-16662-6
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001066958500001
DA 2024-07-18
ER

PT J
AU Lilhore, UK
   Simaiya, S
   Dalal, S
   Damasevicius, R
AF Lilhore, Umesh Kumar
   Simaiya, Sarita
   Dalal, Surjeet
   Damasevicius, Robertas
TI A smart waste classification model using hybrid CNN-LSTM with transfer
   learning for sustainable environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart waste; Classification; Sustainable development; Deep learning;
   CNN-LSTM; Transfer learning
AB Waste collection, classification, and planning have become crucial as industrialization and smart city advancement activities have increased. A recycling process of waste relies on the ability to retrieve the characteristics as it was in their natural position, and it reduces pollution and helps in a sustainable environment. Recently, deep learning (DL) methods have been employed intelligently to support the administration's strategized waste management and related procedure, including capture, classification, composting, and dumping. The selection of the optimum DL technique for categorizing and forecasting waste is a long and arduous process. This research presents a smart waste classification using Hybrid CNN-LSTM with transfer learning for sustainable development. The waste can be classified into recyclable and organic categories. To classify waste statistics, implement a hybrid model combining Convolutional neural networks (CNN) and long short-term memory (LSTM). The proposed model also uses the transfer learning (TL) method, which incorporates the advantage of ImageNet, to classify and forecast the waste category. The proposed model also utilises an improved data augmentation process for overfitting and data sampling issues. An experimental analysis was conducted on the TrashNet dataset sample, with 27027 images separated into two classes of organic waste 17005 and recyclable waste 10 025 used to evaluate the performance of the proposed model. The proposed hybrid model and various existing CNN models (i.e., VGG-16, ResNet-34, ResNet-50, and AlexNet) were implemented using Python and tested based on performance measuring parameters, i.e., precision, recall, testing and training loss, and accuracy. Each model was created with a range of epochs and an adaptive moment estimator (AME) optimisation algorithm. For the proposed method, the AME optimisation achieved the best optimisation and accuracy and the least modelling loss for training, validation, and testing. The proposed model performed the highest precision of 95.45%, far better than the existing deep learning method.
C1 [Lilhore, Umesh Kumar] Chandigarh Univ, Dept Comp Sci & Engn, Mohali, Punjab, India.
   [Simaiya, Sarita] Chandigarh Univ, Dept Comp Sci & Engn, APEX Inst Technol, Mohali, Punjab, India.
   [Dalal, Surjeet] Amity Univ, Dept Comp Sci & Engn, Gurgaon, Haryana, India.
   [Damasevicius, Robertas] Vytautas Magnus Univ, Dept Appl Informat, Kaunas, Lithuania.
C3 Chandigarh University; Chandigarh University; Vytautas Magnus University
RP Damasevicius, R (corresponding author), Vytautas Magnus Univ, Dept Appl Informat, Kaunas, Lithuania.
EM robertas.damasevicius@vdu.lt
RI Damaševičius, Robertas/E-1387-2017; Dalal, Surjeet/AAK-1179-2021;
   Lilhore, Dr Umesh Kumar/AAQ-3392-2021
OI Damaševičius, Robertas/0000-0001-9990-1084; Dalal,
   Surjeet/0000-0002-4325-9237; Lilhore, Dr Umesh Kumar/0000-0001-6073-3773
CR Abdallah M, 2020, WASTE MANAGE, V109, P231, DOI 10.1016/j.wasman.2020.04.057
   Abeygunawardhana A. G. D. T., 2020, 2020 2nd International Conference on Advancements in Computing (ICAC), P482, DOI 10.1109/ICAC51239.2020.9357151
   Alrayes FS, 2023, URBAN CLIM, V49, DOI 10.1016/j.uclim.2023.101483
   Alsabei A, 2021, INT J COMPUT SCI NET, V21, P65, DOI 10.22937/IJCSNS.2021.21.8.9
   Andeobu L, 2022, SCI TOTAL ENVIRON, V834, DOI 10.1016/j.scitotenv.2022.155389
   [Anonymous], Recycle Waste image dataset (organic, recyclable waste)
   B Soundarya, 2022, 2022 4th International Conference on Smart Systems and Inventive Technology (ICSSIT), P1405, DOI 10.1109/ICSSIT53264.2022.9716437
   Bao NX, 2023, STRUCT CONTROL HLTH, V2023, DOI 10.1155/2023/8899806
   Bharti S, 2022, Environmental Informatics, P97
   Bobulski J, 2019, 25 ACM SIGKDD C KNOW
   Diqi M, 2022, INT C SCI TECHN INN, V1, P130
   Ozdemir ME, 2021, J MATER CYCLES WASTE, V23, P855, DOI 10.1007/s10163-021-01182-y
   Franchitti E, 2020, ATMOSPHERE-BASEL, V11, DOI 10.3390/atmos11050452
   Gondal AU, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144916
   Gothai E., 2022, 2022 INT C COMP COMM, P1
   Gyawali D, 2020, Arxiv, DOI arXiv:2004.02168
   Hussain A, 2020, ENERGIES, V13, DOI 10.3390/en13153930
   Ihsanullah I, 2022, CHEMOSPHERE, V309, DOI 10.1016/j.chemosphere.2022.136631
   Jahanbakhshi A, 2020, SCI HORTIC-AMSTERDAM, V263, DOI 10.1016/j.scienta.2019.109133
   Kumar NM, 2021, PROCESS SAF ENVIRON, V152, P482, DOI 10.1016/j.psep.2021.06.026
   Kumar S, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10010014
   Li NH, 2023, URBAN CLIM, V49, DOI 10.1016/j.uclim.2023.101462
   Liang S, 2021, WASTE MANAGE, V126, P247, DOI 10.1016/j.wasman.2021.03.017
   Lilhore U.K., 2022, Cyber-Physical, IoT, P179
   Lilhore UK, 2022, 2022 INT C EM SMART, P1
   Lilhore UK, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10040580
   Lin KS, 2022, J CLEAN PROD, V346, DOI 10.1016/j.jclepro.2022.130943
   Nowakowski P, 2020, WASTE MANAGE, V109, P1, DOI 10.1016/j.wasman.2020.04.041
   Patil M, 2022, Waste classification using ANN, CNN and transfer learning, DOI [10.2139/ssrn.4133206, DOI 10.2139/SSRN.4133206]
   Rajesh V., 2021, Natural Volatiles & Essential Oils, V8, P4486
   Rubab S, 2022, CHEMBIOENG REV, V9, P212, DOI 10.1002/cben.202100044
   Sallang NCA, 2021, IEEE ACCESS, V9, P153560, DOI 10.1109/ACCESS.2021.3128314
   Sidharth R., 2020, 2020 5 INT C COMM EL, P1086, DOI 10.1109/ICCES48766.2020.9137938
   Simaiya Sarita, 2022, Ambient Communications and Computer Systems: Proceedings of RACCCS 2021. Lecture Notes in Networks and Systems (356), P181, DOI 10.1007/978-981-16-7952-0_17
   Sunny MS, 2019, 2019 1 INT C ADV SCI, P1
   Tiwari Rishabh, 2022, 2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE), P2178, DOI 10.1109/ICACITE53722.2022.9823449
   Khoa TA, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/6138637
   Trivedi NK., 2021, Int J Cur Res Rev, V13, P150, DOI [10.31782/IJCRR.2021.SP192, DOI 10.31782/IJCRR.2021.SP192]
   Ullah S, 2021, MED BIOL ENG COMPUT, V59, P1167, DOI 10.1007/s11517-021-02368-0
   Uzma, 2022, NEURAL COMPUT APPL, V34, P8309, DOI 10.1007/s00521-020-05101-4
   Velis CA, 2021, WASTE MANAGE RES, V39, P1113, DOI 10.1177/0734242X211051199
   Wang C, 2021, WASTE MANAGE, V135, P20, DOI 10.1016/j.wasman.2021.08.028
   Wang Q, 2023, INFORM SCIENCES, V626, P694, DOI 10.1016/j.ins.2023.01.004
   Windrim L, 2023, GEOSCI FRONT, V14, DOI 10.1016/j.gsf.2023.101562
   Wu TW, 2023, RESOUR CONSERV RECY, V190, DOI 10.1016/j.resconrec.2022.106813
   Yu DM, 2023, CHEMOSPHERE, V328, DOI 10.1016/j.chemosphere.2023.138606
   Zhang Hui, 2022, Procedia CIRP, P264, DOI 10.1016/j.procir.2022.02.189
   Zhang HP, 2023, URBAN CLIM, V49, DOI 10.1016/j.uclim.2023.101485
   Zhao F, 2023, ENVIRON RES, V228, DOI 10.1016/j.envres.2023.115902
   Zheng H, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10040427
   Zhou K, 2023, ENG APPL ARTIF INTEL, V117, DOI 10.1016/j.engappai.2022.105580
NR 51
TC 2
Z9 2
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29505
EP 29529
DI 10.1007/s11042-023-16677-z
EA SEP 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001081631900015
DA 2024-07-18
ER

PT J
AU Rezapour, MM
   Fatemi, A
   Nematbakhsh, MA
AF Rezapour, Mohammad Mahdi
   Fatemi, Afsaneh
   Nematbakhsh, Mohammad Ali
TI DeepSkill: A methodology for measuring teams' skills in massively
   multiplayer online games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skill assessment; Team performance; MMO; Deep learning; Gameplay data;
   KSAVE
ID AUDIO; ALIGNMENT; TIME
AB The game industry is witnessing a significant trend of players toward massively multiplayer online games (MMO). Players are keen on forming teams and cooperating/competing in these games. Real-time measurement of players' performance is one of the subjects of researchers' attention to dynamically adjust the game difficulty and immerse players in the game. However, our extensive studies show that real-time measuring of teams' skill levels has received much less attention. In this paper, a general real-time method called DeepSkill is proposed to measure the MMOs teams' skills directly using players' gameplay raw low-level data. The proposed method, which is based on the evidence-centered assessment design, was tested under six different configurations using popular machine learning techniques, including deep neural network (DNN), extreme gradient boosting (XGBoost), light gradient boosting machine (LightGBM), CatBoost, random forest (RF), and linear support vector regression (LinearSVR). According to the results, the proposed method provides accurate skill estimations and expertise level classifications. Specifically, Deepskill's DNN-based evidence model provided the lowest mean absolute error of 0.09 in team skill estimation. Additionally, the proposed method achieved an accuracy of 0.973 in classifying the teams' expertise level for the expert-novice classification task. Furthermore, a cost-effectiveness analysis was performed on the two top-performing evidence models. The LightGBM-based evidence model yielded the best results in both training and prediction phases in terms of low resource consumption alongside considerable accuracy.
C1 [Rezapour, Mohammad Mahdi; Fatemi, Afsaneh; Nematbakhsh, Mohammad Ali] Univ Isfahan, Fac Comp Engn, Esfahan, Iran.
C3 University of Isfahan
RP Fatemi, A (corresponding author), Univ Isfahan, Fac Comp Engn, Esfahan, Iran.
EM mm.rezapour@ec.iut.ac.ir; a_fatemi@eng.ui.ac.ir;
   nematbakhsh@eng.ui.ac.ir
OI Fatemi, Afsaneh/0000-0003-1184-5917; Rezapour, Mohammad
   Mahdi/0000-0002-4233-2412
CR [Anonymous], 1975, Beyond Boredom and Anxiety. The Jossey-Bass behavioral science series
   Anwar SM, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010018
   Anwar SM, 2016, INT CONF FRONT INFO, P315, DOI [10.1109/FIT.2016.61, 10.1109/FIT.2016.064]
   Bandeira IN, 2022, LECT NOTES COMPUT SC, V13334, P69, DOI 10.1007/978-3-031-05637-6_5
   Bartle R. A., 2004, DESIGNING VIRTUAL WO
   Binkley M, 2012, ASSESSMENT AND TEACHING OF 21ST CENTURY SKILLS, P17, DOI 10.1007/978-94-007-2324-5_2
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen Tianqi, 2015, R package version 0.4-2 1.4, V1, P1
   Csikszentmihalyi M., 2008, FLOW PSYCHOL OPTIMAL
   Csikszentmihalyi M, 1997, FINDING FLOW PSYCHOL, DOI 10.5860/choice.35-1828
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   De Groot A.D., 2014, Thought and choice in chess, DOI DOI 10.1515/9783110800647
   Delalleau O, 2012, IEEE T COMP INTEL AI, V4, P167, DOI 10.1109/TCIAIG.2012.2188833
   Drachen A., 2013, GAMES ANAL MAXIMIZIN, P13
   Dreyfus SE, 2004, Bulletin of science, technology & society, V24, P17
   Dreyfus StuartE., 1980, 5 STAGE MODEL MENTAL, DOI DOI 10.21236/ADA084551
   Ehatisham-ul-Haq M, 2021, EXPERT SYST APPL, V174, DOI 10.1016/j.eswa.2021.114700
   Ericsson KA, 2007, HARVARD BUS REV, V85, P114
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Glickman M.E., 2012, Example of the glicko-2 system, P1
   Glickman M.E., 1995, The glicko system, V16, P16
   Glickman Mark E, 1995, Boston University, V16, P16
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Haubruck P, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.9956
   Herbrich Ralf., 2006, Adv. Neural Inf. Process. Syst, P569, DOI DOI 10.7551/MITPRESS/7503.003.0076
   Ho CH, 2012, J MACH LEARN RES, V13, P3323
   Hodge VJ, 2021, IEEE T GAMES, V13, P368, DOI 10.1109/TG.2019.2948469
   Indulkar Y, 2021, 2021 INTERNATIONAL CONFERENCE ON EMERGING SMART COMPUTING AND INFORMATICS (ESCI), P300, DOI 10.1109/ESCI50559.2021.9396823
   Jaccard P., 1912, New Phytologist, V11, P37, DOI [10.1111/j.1469-8137.1912.tb05611.x, DOI 10.1111/J.1469-8137.1912.TB05611.X]
   Joharestani MZ, 2019, ATMOSPHERE-BASEL, V10, DOI 10.3390/atmos10070373
   Johnson ES, 2018, EDUC MEAS-ISSUES PRA, V37, P35, DOI 10.1111/emip.12182
   Kamikokuryo K, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22124499
   Ke GL, 2017, ADV NEUR IN, V30
   Kingma D. P., 2014, arXiv
   Larose D. T., 2014, Discovering Knowledge in Data: an Introduction to Data Mining, V4
   Loh CS, 2015, COMPUT HUM BEHAV, V49, P147, DOI 10.1016/j.chb.2015.02.053
   Loh CS, 2014, COMPUT HUM BEHAV, V39, P322, DOI 10.1016/j.chb.2014.07.022
   Loh CS, 2013, Education and Information Technologies, P1
   Louppe G, 2015, Arxiv, DOI [arXiv:1407.7502, DOI 10.48550/ARXIV.1407.7502]
   Minka T, 2018, Technical Report MSR-TR-2018-8
   Mishra P., 2007, SOC INFORM TECHNOLOG, V2007, P2227
   Mislevy RJ, 2013, MIL MED, V178, P107, DOI 10.7205/MILMED-D-13-00213
   Moschovitis Paraschos, 2022, IEEE T GAMES
   Paraschos PD, 2023, INT J HUM-COMPUT INT, V39, P1, DOI 10.1080/10447318.2021.2020008
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pei K, 2018, Kaggle
   Prokhorenkova L, 2018, ADV NEUR IN, V31
   Reis Simao, 2019, New Knowledge in Information Systems and Technologies. Advances in Intelligent Systems and Computing (AISC 931), P263, DOI 10.1007/978-3-030-16184-2_26
   Schell Jesse., 2008, The Art of Game Design: A Book of Lenses, P1, DOI [DOI 10.1201/9780080919171, 10.1201/9780080919171]
   Shaffer DW, 2005, wcer working paper no. 2005-4
   Silva MP, 2017, ENTERTAIN COMPUT, V18, P103, DOI 10.1016/j.entcom.2016.10.002
   Sourmelis T, 2017, COMPUT HUM BEHAV, V67, P41, DOI 10.1016/j.chb.2016.10.020
   Spatharioti SE, 2021, IEEE CONF COMPU INTE, P111, DOI 10.1109/COG52621.2021.9619125
   Stein A, 2018, ENTERTAIN COMPUT, V25, P14, DOI 10.1016/j.entcom.2017.11.003
   Taylor N., 2018, Social interactions in virtual worlds: An interdisciplinary perspective, P162, DOI [10.1017/9781316422823, DOI 10.1017/9781316422823]
   Tukey J.W., 1997, EXPLORATORY DATA ANA
   Wang XZ, 2020, INT J MACH LEARN CYB, V11, P747, DOI 10.1007/s13042-020-01096-5
NR 58
TC 2
Z9 2
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 31049
EP 31079
DI 10.1007/s11042-023-15796-x
EA SEP 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066976400009
DA 2024-07-18
ER

PT J
AU Aldeen, YAAS
   Jaber, MM
   Ali, MH
   Abd, SK
   Alkhayyat, A
   Malik, RQ
AF Aldeen, Yousra Abdul Alsahib S.
   Jaber, Mustafa Musa
   Ali, Mohammed Hasan
   Abd, Sura Khalil
   Alkhayyat, Ahmed
   Malik, R. Q.
TI Electric charging station management using IoT and cloud computing
   framework for sustainable green transportation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicle; Fuel consumption; Transportation; Electric system
ID DEPLOYMENT; BUSES
AB Environmentally friendly and intelligent transportation options have been developed to tackle pollution and fuel shortages during the past several years. Numerous standards organizations and transportation authorities have provided a range of alternative energy sources intending to create a more environmentally friendly and sustainable atmosphere. However, some obstacles remain to clear before the goal may be fulfilled in green transportation. The research examines and identifies transportation pollution and greenhouse gas emissions. An electric vehicle-centric approach to green mobility is taken, emphasizing electric vehicle architecture and current solutions initiatives, and essential for effectively done. Regarding an Electric Vehicle Charging Station (EVCS), location is key; according to the study, EVSC location selection may be improved using an Internet of Things (IoT) with a cloud computing (IoT-CC) approach. Carbon-producing vehicles such as trains and buses are being phased out globally for more eco-friendly transportation. Electrified vehicles are a significant step toward a more environmentally friendly mode of transportation. However, electric vehicles are becoming more common, and the infrastructure for charging must be expanded and seamless. Solar panels may be used to electric power vehicles and generate their energy by certain entities. There are plans to develop EVSC-IoT service architecture to minimize carbon dioxide emissions and fuel consumption in a smart transportation system. It gathers data from telematics, digital systems, and roadside camera to assist fuel consumption. Electric vehicle drivers may use electronic wallets to pay for their charging costs. The suggested EVSC-IoT model enhances the charging demand, charging time, time distribution, and traveling velocity compared to other existing methods.
C1 [Aldeen, Yousra Abdul Alsahib S.] Univ Baghdad, Coll Sci Women, Dept Comp Sci, Baghdad, Iraq.
   [Jaber, Mustafa Musa] Dijlah Univ Coll, Dept Comp Sci, Baghdad 10021, Iraq.
   [Jaber, Mustafa Musa; Abd, Sura Khalil] Al Turath Univ Coll, Dept Comp Sci, Baghdad, Iraq.
   [Ali, Mohammed Hasan] Imam Jaafar Al Sadiq Univ, Fac Informat Technol, Comp Tech Engn Dept, Najaf 10023, Iraq.
   [Alkhayyat, Ahmed] Islamic Univ, Coll Tech Engn, Najaf, Iraq.
   [Malik, R. Q.] Al Mustaqbal Univ Coll, Med Instrumentat Tech Engn Dept, Babylon, Iraq.
C3 University of Baghdad; Imam Jaa'far al-Sadiq University; Islamic
   University College; Al-Mustaqbal University College
RP Jaber, MM (corresponding author), Dijlah Univ Coll, Dept Comp Sci, Baghdad 10021, Iraq.; Jaber, MM (corresponding author), Al Turath Univ Coll, Dept Comp Sci, Baghdad, Iraq.
EM yousraalkaalesi@gmail.com; Mustafa.jaber@turath.edu.iq;
   mh180250@gmail.com; sura.khalil@duc.edu.iq;
   ahmedalkhayyat85@iunajaf.edu.iq; ramiqays@gmail.com
RI alkhayyat, ahmed/B-6434-2018
OI alkhayyat, ahmed/0000-0002-1270-4713
CR Abraham DS, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10161895
   Afshar S, 2021, RENEW SUST ENERG REV, V152, DOI 10.1016/j.rser.2021.111654
   Asensio OI, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00956-1
   Asensio OI, 2020, NAT SUSTAIN, V3, P463, DOI 10.1038/s41893-020-0533-6
   Chakraborty S, 2019, ENERGIES, V12, DOI 10.3390/en12081569
   Cui Y, 2021, IEEE T SMART GRID, V12, P3278, DOI 10.1109/TSG.2021.3053026
   Das HS, 2020, RENEW SUST ENERG REV, V120, DOI 10.1016/j.rser.2019.109618
   Erbas M, 2018, ENERGY, V163, P1017, DOI 10.1016/j.energy.2018.08.140
   Farid AM, 2021, SMART CITIES-BASEL, V4, P1039, DOI 10.3390/smartcities4030055
   Flammini MG, 2019, ELECTR POW SYST RES, V166, P136, DOI 10.1016/j.epsr.2018.09.022
   Gampa SR, 2020, J ENERGY STORAGE, V27, DOI 10.1016/j.est.2019.101117
   Gan W, 2020, IEEE T SMART GRID, V11, P4005, DOI 10.1109/TSG.2020.2989751
   Gong D, 2019, ADV PROD ENG MANAG, V14, P65, DOI 10.14743/apem2019.1.312
   González LG, 2021, RENEW SUST ENERG REV, V141, DOI 10.1016/j.rser.2021.110768
   Huang P, 2019, APPL ENERG, V255, DOI 10.1016/j.apenergy.2019.113855
   Ji ZY, 2018, RENEW SUST ENERG REV, V90, P710, DOI 10.1016/j.rser.2018.04.011
   Kaya Ö, 2020, SUSTAIN CITIES SOC, V62, DOI 10.1016/j.scs.2020.102396
   Lajunen A, 2018, J CLEAN PROD, V172, P56, DOI 10.1016/j.jclepro.2017.10.066
   Lee S, 2021, APPL ENERG, V304, DOI 10.1016/j.apenergy.2021.117754
   Li WX, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10072528
   Lin YP, 2019, TRANSPORT RES C-EMER, V107, P423, DOI 10.1016/j.trc.2019.08.009
   Luo YG, 2020, ENERGY, V194, DOI 10.1016/j.energy.2019.116807
   Ma CT, 2019, ENERGIES, V12, DOI 10.3390/en12214201
   Macioszek E, 2020, INT C TRANSP SYST TE, P124, DOI DOI 10.1007/978-3-030-59270-7_10
   Minh PV, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13063528
   Miralinaghi Mohammad, 2020, 2020 Forum on Integrated and Sustainable Transportation Systems (FISTS), P95, DOI 10.1109/FISTS46898.2020.9264883
   Miri I, 2021, INT J ENERG RES, V45, P501, DOI 10.1002/er.5700
   Pagany R, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11082301
   Pan L, 2020, SUSTAIN CITIES SOC, V59, DOI 10.1016/j.scs.2020.102192
   Shahraki N, 2015, TRANSPORT RES D-TR E, V41, P165, DOI 10.1016/j.trd.2015.09.011
   Shahriar S, 2020, IEEE ACCESS, V8, P168980, DOI 10.1109/ACCESS.2020.3023388
   Thananusak T, 2021, WORLD ELECTR VEHIC J, V12, DOI 10.3390/wevj12010002
   Türk S, 2021, INFORM SCIENCES, V547, P641, DOI 10.1016/j.ins.2020.08.076
   Vazifeh MM, 2019, TRANSPORT RES A-POL, V121, P75, DOI 10.1016/j.tra.2019.01.002
   Wei GW, 2020, ECON RES-EKON ISTRAZ, V33, P828, DOI 10.1080/1331677X.2020.1734851
   Wu XM, 2021, ENERGY, V224, DOI 10.1016/j.energy.2021.120106
   Xu M, 2020, TRANSPORT RES C-EMER, V114, P164, DOI 10.1016/j.trc.2020.02.001
   Yu JJ, 2022, PROD OPER MANAG, V31, P681, DOI 10.1111/poms.13564
NR 38
TC 1
Z9 1
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28705
EP 28728
DI 10.1007/s11042-023-16630-0
EA SEP 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001060763900005
DA 2024-07-18
ER

PT J
AU El-Shafai, W
   Ali, AM
   Abd El-Nabi, S
   El-Rabaie, EM
   Abd El-Samie, FE
AF El-Shafai, Walid
   Ali, Anas M.
   Abd El-Nabi, Samy
   El-Rabaie, El-Sayed M.
   Abd El-Samie, Fathi E.
TI Single image super-resolution approaches in medical images based-deep
   learning: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical images; Deep learning; Image super-resolution; SISR; GAN
ID QUALITY ASSESSMENT; RECONSTRUCTION; SIMILARITY; NETWORK
AB Medical image Super-Resolution (SR) reconstruction refers to the process of regenerating a High-Resolution (HR) image from a degraded Low-Resolution (LR) image or images. Due to the breakthrough in Deep Learning (DL) for medical computer vision applications, researchers are attempting to introduce deep neural networks and tackle the challenge of image SR reconstruction by establishing an end-to-end deep-level network. Recently, the medical field has gained the attention of researchers, especially the field of computer vision. An intuitive grasp of the fundamental concepts underlying neural network applications in medical imaging and a working knowledge of technical jargon will significantly assist the reader in comprehending current and future applications. This paper aims to provide a complete overview of current improvements in Single Image Super-Resolution (SISR) in the medical field through the use of DL techniques. We can generally classify extant research on SR techniques into four major groups: traditional SR, LR network SR, HR network SR, and perceptual quality SR. Additionally, we discuss several other critical topics, including publicly available benchmark medical datasets, performance evaluation metrics, and the implementation of the famous SR models. Finally, we end this survey by identifying several potential paths and open issues that the community should address in the future.
C1 [El-Shafai, Walid] Prince Sultan Univ, Dept Comp Sci, Secur Engn Lab, Riyadh 11586, Saudi Arabia.
   [El-Shafai, Walid; Ali, Anas M.; Abd El-Nabi, Samy; El-Rabaie, El-Sayed M.; Abd El-Samie, Fathi E.] Menoufia Univ, Dept Elect & Elect Commun Engn, Fac Elect Engn, Menoufia 32952, Egypt.
   [Ali, Anas M.] Prince Sultan Univ, Robot & Internet Things Lab, Riyadh 12435, Saudi Arabia.
   [Abd El-Nabi, Samy] King Salman Int Univ KSIU, Fac Comp Sci & Engn, Dept Artificial Intelligence Engn, South Sinai 46511, Egypt.
   [Abd El-Samie, Fathi E.] Princess Nourah bint Abdulrahman Univ, Dept Informat Technol, Coll Comp & Informat Sci, POB 84428, Riyadh 11671, Saudi Arabia.
C3 Prince Sultan University; Egyptian Knowledge Bank (EKB); Menofia
   University; Prince Sultan University; King Salman International
   University; Princess Nourah bint Abdulrahman University
RP El-Shafai, W (corresponding author), Prince Sultan Univ, Dept Comp Sci, Secur Engn Lab, Riyadh 11586, Saudi Arabia.; El-Shafai, W (corresponding author), Menoufia Univ, Dept Elect & Elect Commun Engn, Fac Elect Engn, Menoufia 32952, Egypt.
EM walid.elshafai@al-eng-menofia.edu.eg; aaboessa@psu.edu.sa;
   sami.abdelnabi@ksiu.edu.eg; elsayedelrabaie@gmail.com;
   fathi_sayed@yahoo.com
RI Ali, Anas/AFI-5616-2022; El-Shafai, Walid/AAG-4796-2021
OI El-Shafai, Walid/0000-0001-7509-2120; M. Ali, Anas/0000-0003-0836-6931
CR ABIDE, US
   acrdsi, DAT DIR AM COLL RAD
   adni.loni.usc, ADNI ALZH DIS NEUR I
   Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Ahn N, 2018, IEEE COMPUT SOC CONF, P904, DOI 10.1109/CVPRW.2018.00123
   Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Ali AM, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23052385
   Antun V, 2020, P NATL ACAD SCI USA, V117, P30088, DOI 10.1073/pnas.1907377117
   Anwar S, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3390462
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   aylward, AYLW ORG OP ACC MED
   Barron JT, 2019, PROC CVPR IEEE, P4326, DOI 10.1109/CVPR.2019.00446
   Bei YJ, 2018, IEEE COMPUT SOC CONF, P987, DOI 10.1109/CVPRW.2018.00132
   Bengio Y., 2009, P 26 ANN INT C MACH, V60, P6, DOI [DOI 10.1145/1553374.1553380, 10.1145/1553374.1553380]
   Bulat A, 2018, PROC CVPR IEEE, P109, DOI 10.1109/CVPR.2018.00019
   caffe.berkeleyvision, CAFF DEEP LEARN FRAM
   cancerimagingarchive, WELC CANC IM ARCH CA
   capterra, BEST DEEP LEARN SOFT
   Chen R, 2018, IEEE COMPUT SOC CONF, P922, DOI 10.1109/CVPRW.2018.00125
   Cruz C, 2018, IEEE T IMAGE PROCESS, V27, P1376, DOI 10.1109/TIP.2017.2779265
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Deeba F, 2020, IEEE ACCESS, V8, P37035, DOI 10.1109/ACCESS.2020.2974278
   Deeplearning4J, About us
   Dittimi Tamarafinide V., 2020, Pattern Recognition and Artificial Intelligence. International Conference, ICPRAI 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12068), P660, DOI 10.1007/978-3-030-59830-3_57
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dosovitskiy A., 2016, Advances in Neural Information Processing Systems, P658
   Egiazarian K, 2007, IEEE IMAGE PROC, P549
   Egiazarian K, 2015, EUR SIGNAL PR CONF, P2849, DOI 10.1109/EUSIPCO.2015.7362905
   El-Shafai W, 2022, CMC-COMPUT MATER CON, V70, P6107, DOI 10.32604/cmc.2022.020698
   El-Shafai W, 2022, CMC-COMPUT MATER CON, V70, P1141, DOI 10.32604/cmc.2022.018547
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   fastmri.med.nyu, FASTMRI DAT
   Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Gao YX, 2017, CHIN AUTOM CONGR, P5310, DOI 10.1109/CAC.2017.8243724
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Ghodrati V, 2019, QUANT IMAG MED SURG, V9, P1516, DOI 10.21037/qims.2019.08.10
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Goyal M, 2015, INT J ADV RES ENG AP, V5, P108
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Gulrajani I, 2017, ADV NEUR IN, V30
   Jiang MF, 2021, COMPUT MED IMAG GRAP, V92, DOI 10.1016/j.compmedimag.2021.101969
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   kaggle, FIND OP DAT MACH LEA
   Kaissis GA, 2020, NAT MACH INTELL, V2, P305, DOI 10.1038/s42256-020-0186-1
   Kawaguchi K., 2017, ARXIV
   keras, Keras: the Python deep learning API
   Ha VK, 2018, LECT NOTES ARTIF INT, V10989, P106, DOI 10.1007/978-3-030-00563-4_11
   Nguyen K, 2018, PATTERN RECOGN, V78, P23, DOI 10.1016/j.patcog.2018.01.002
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim J, 2018, PRECIS FUTURE MED, V2, P37, DOI 10.23838/pfm.2018.00030
   Kim M, 2019, NEUROSPINE, V16, P657
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2021, PHOTOREALISTIC SINGL
   Lee K, 2018, PROC CVPR IEEE, P3702, DOI 10.1109/CVPR.2018.00390
   Li K, 2020, IET IMAGE PROCESS, V14, P2273, DOI 10.1049/iet-ipr.2019.1438
   Li XF, 2020, J REAL-TIME IMAGE PR, V17, P1885, DOI 10.1007/s11554-019-00925-3
   Li Y, 2021, IRBM, V42, P120, DOI 10.1016/j.irbm.2020.08.004
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Liang X, 2021, MACH LEARN-SCI TECHN, V2, DOI 10.1088/2632-2153/abb214
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu AR, 2023, IEEE T PATTERN ANAL, V45, P5461, DOI 10.1109/TPAMI.2022.3203009
   Liu PJ, 2018, IEEE COMPUT SOC CONF, P886, DOI 10.1109/CVPRW.2018.00121
   Ma Y, 2021, NUCL INSTRUM METH A, V992, DOI 10.1016/j.nima.2021.165053
   microsoft, MICROSOFT COGNITIVE
   Miyato T, 2018, INT C LEARN REPR
   Moraes T, 2020, COMP M BIO BIO E-IV, V8, P294, DOI 10.1080/21681163.2019.1683469
   mxnet.apache, AP MXNET FLEX EFF LI
   neuraldesigner, EXPL AI PLATF NEUR D
   Neyshabur B, 2017, ADV NEUR IN, V30
   Ooi YK, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10070867
   openneuro, FREE OP PLATF SHAR M
   opensourceimaging, OP SOURC IM OP SOURC
   Park D, 2018, IEEE COMPUT SOC CONF, P995, DOI 10.1109/CVPRW.2018.00133
   Park SJ, 2018, LECT NOTES COMPUT SC, V11220, P455, DOI 10.1007/978-3-030-01270-0_27
   Parsania MPS., 2016, INT J ADV RES COMPUT, V5, P29, DOI [DOI 10.17148/IJARCCE.2016.5107, 10.17148/ijarcce.2016.5107]
   Patil VH, 2007, INNOVATIONS AND ADVANCED TECHNIQUES IN COMPUTER AND INFORMATION SCIENCES AND ENGINEERING, P483, DOI 10.1007/978-1-4020-6268-1_85
   Qiu DF, 2021, FUTURE GENER COMP SY, V116, P200, DOI 10.1016/j.future.2020.11.001
   radiopaedia, IM DAT SETS ART INT
   radrounds, LIST OP ACC MED IM D
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Ren S, 2023, NEURAL COMPUT APPL, V35, P22781, DOI 10.1007/s00521-021-06287-x
   Romano Y, 2017, IEEE T COMPUT IMAG, V3, P110, DOI 10.1109/TCI.2016.2629284
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sajjadi Mehdi S. M., 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P4501, DOI 10.1109/ICCV.2017.481
   Sara U., 2019, J COMPUT COMMUN, V7, P8, DOI [10.4236/jcc.2019.73002, DOI 10.4236/JCC.2019.73002]
   Shah AJ, 2012, IMAGE SUPER RESOLUTI
   Shahidi F, 2021, IEEE ACCESS, V9, P32795, DOI 10.1109/ACCESS.2021.3057497
   Shahsavari Ali, 2021, Informatics in Medicine Unlocked, V24, DOI 10.1016/j.imu.2021.100628
   Shi W., 2016, ARXIV
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh N.K., 2021, Health Informatics: A Computational Perspective in Healthcare, P77
   sipi.usc, SIPI IMAGE DATABASE
   Siu WC, 2012, ASIAPAC SIGN INFO PR
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   tensorflow, TensorFlow
   Thung KH, 2009, 2009 INTERNATIONAL CONFERENCE FOR TECHNICAL POSTGRADUATES (TECHPOS 2009), P153
   Tian C., 2022, arXiv
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Timofte R, 2016, PROC CVPR IEEE, P1865, DOI 10.1109/CVPR.2016.206
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   torch, TORCH SCI COMP LUAJI
   ukbiobank, UK BIOB UK BIOB
   van Ouwerkerk JD, 2006, IMAGE VISION COMPUT, V24, P1039, DOI 10.1016/j.imavis.2006.02.026
   Wang G, 2016, IEEE ACCESS, V4, P8914, DOI 10.1109/ACCESS.2016.2624938
   Wang JX, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0226963
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Wang YF, 2018, IEEE COMPUT SOC CONF, P977, DOI 10.1109/CVPRW.2018.00131
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Yamashita K, 2020, LECT NOTES COMPUT SC, V12141, P496, DOI 10.1007/978-3-030-50426-7_37
   Yan Lv, 2021, 2021 6th International Conference on Intelligent Computing and Signal Processing (ICSP), P595, DOI 10.1109/ICSP51882.2021.9408850
   Yang CY, 2013, IEEE I CONF COMP VIS, P561, DOI 10.1109/ICCV.2013.75
   Yang WM, 2019, IEEE T MULTIMEDIA, V21, P3106, DOI 10.1109/TMM.2019.2919431
   Yao TT, 2020, LECT NOTES ELECTR EN, V516, P119, DOI 10.1007/978-981-13-6504-1_16
   Yu L, 2021, SINGLE IMAGE SUPER R
   Yuan Y, 2018, IEEE COMPUT SOC CONF, P814, DOI 10.1109/CVPRW.2018.00113
   Yue LW, 2016, SIGNAL PROCESS, V128, P389, DOI 10.1016/j.sigpro.2016.05.002
   Zhang H, 2022, J SPINAL CORD MED, V45, P270, DOI 10.1080/10790268.2020.1778353
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
   Zhao M, 2020, COMPUT MED IMAG GRAP, V80, DOI 10.1016/j.compmedimag.2020.101698
   ZHU Y, 2020, 2020 IEEE 91 VEH TEC, P1, DOI DOI 10.1109/VTC2020-SPRING48590.2020.9129469
NR 136
TC 0
Z9 0
U1 6
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30467
EP 30503
DI 10.1007/s11042-023-16197-w
EA SEP 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001060763900006
DA 2024-07-18
ER

PT J
AU Forouzeshfar, P
   Safaei, AA
   Ghaderi, F
   Kamangar, SH
   Kaviani, H
   Haghi, S
AF Forouzeshfar, Parsa
   Safaei, Ali A.
   Ghaderi, Foad
   Kamangar, Sedighesadat Hashemi
   Kaviani, Hanieh
   Haghi, Sahebeh
TI Dental caries diagnosis using neural networks and deep learning: a
   systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dental caries; Neural networks; Convolutional Neural Networks (CNN);
   Diagnosis; Detection; Classification
AB Dental caries is one of the oral health problems and the most common chronic infectious disease of childhood, and neural networks and artificial intelligence are increasingly being used in the field of dentistry. This review study aims to review studies published in the field of artificial intelligence and neural networks and dentistry. A search for studies in four databases, including Springer, ScienceDirect, PubMed (MedLine), and Institute of Electrical and Electronics Engineers (IEEE) was done. Finally, 28 studies were reviewed, most of which used Bitewing and Periapical images for the classification and detection of dental caries. The image databases ranged from 55 to 3000 and several evaluation metrics were used in the selected studies. The research questions were designed and reviewed based on PICOS (P stands for patient or problem, I stands for intervention, C stands for control or comparison, and O stands for outcomes). The majority of the studies also used pre-processing and data augmentation methods. The diversity between the networks used and the output evaluation criteria have made direct research comparisons challenging. The main focus of this research was on caries detection using deep learning methods and neural networks, especially convolutional neural networks that are suitable for images. The traditional methods of detecting caries, other than the methods based on artificial intelligence, have not been investigated in this research. Also, the main caries were interproximal and proximal caries in molars and premolars. The main difference between this and previous works is the use of more up-to-date articles (2016 to 2023) studies with an organized manner of reviewing, which is based on the types of images used.
C1 [Forouzeshfar, Parsa] Tarbiat Modares Univ, Fac Math Sci, Dept Data Sci, Tehran, Iran.
   [Safaei, Ali A.] Tarbiat Modares Univ, Dept Med Informat, Fac Med Sci, Tehran, Iran.
   [Safaei, Ali A.; Ghaderi, Foad] Tarbiat Modares Univ, Fac Interdisciplinary Sci & Technol, Dept Data Sci, Tehran, Iran.
   [Ghaderi, Foad] Tarbiat Modares Univ, Elect & Comp Engn Dept, Human Comp Interact Lab, Tehran, Iran.
   [Kamangar, Sedighesadat Hashemi] Univ Tehran Med Sci, Sch Dent, Restorat Dept, Tehran, Iran.
   [Kaviani, Hanieh] Univ Tehran Med Sci, Sch Dent, Dept Oral & Maxillofacial Radiol, Tehran, Iran.
   [Haghi, Sahebeh] Univ Tehran Med Sci, Sch Dent, Dept Operat Dent, Tehran, Iran.
C3 Tarbiat Modares University; Tarbiat Modares University; Tarbiat Modares
   University; Tarbiat Modares University; Tehran University of Medical
   Sciences; Tehran University of Medical Sciences; Tehran University of
   Medical Sciences
RP Safaei, AA (corresponding author), Tarbiat Modares Univ, Dept Med Informat, Fac Med Sci, Tehran, Iran.; Safaei, AA (corresponding author), Tarbiat Modares Univ, Fac Interdisciplinary Sci & Technol, Dept Data Sci, Tehran, Iran.
EM aa.safaei@modares.ac.ir
RI Ghaderi, Foad/JCO-9951-2023; Safaei, Ali/ABD-3920-2021
OI Safaei, Ali/0000-0003-1985-8720; ForouzeshFar, Parsa/0009-0008-6319-0442
CR Ali R.B., 2016, ICSEA 2016 ELEV INT, V2016, P236
   Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   Baydar O, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13030453
   Bayrakdar IS, 2022, ORAL RADIOL, V38, P468, DOI 10.1007/s11282-021-00577-9
   Bayraktar Y, 2022, CLIN ORAL INVEST, V26, P623, DOI 10.1007/s00784-021-04040-1
   Casalegno F, 2019, J DENT RES, V98, P1227, DOI 10.1177/0022034519871884
   Santos CMD, 2007, REV LAT-AM ENFERM, V15, P508, DOI 10.1590/S0104-11692007000300023
   Ding BC, 2021, ANN TRANSL MED, V9, DOI 10.21037/atm-21-4805
   Dixit LP, 2013, BMC ORAL HEALTH, V13, DOI 10.1186/1472-6831-13-20
   Estai M, 2022, OR SURG OR MED OR PA, V134, P262, DOI 10.1016/j.oooo.2022.03.008
   Faria VD, 2021, J DIGIT IMAGING, V34, P1237, DOI 10.1007/s10278-021-00487-6
   Fouladi S, 2021, COMPUT COMMUN, V176, P234, DOI 10.1016/j.comcom.2021.06.011
   García-Cañas A, 2023, CARIES RES, V56, P503, DOI 10.1159/000527491
   Geetha V, 2020, HEALTH INF SCI SYST, V8, DOI 10.1007/s13755-019-0096-y
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gomez J, 2015, BMC ORAL HEALTH, V15, DOI 10.1186/1472-6831-15-S1-S3
   Haridas R., 2019, Int J Appl Eng Res, V14, P780, DOI DOI 10.37622/IJAER/14.3.2019.780-789
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holtkamp A, 2021, J CLIN MED, V10, DOI 10.3390/jcm10050961
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Imak A, 2022, IEEE ACCESS, V10, P18320, DOI 10.1109/ACCESS.2022.3150358
   Ismail A I, 2004, J Dent Res, V83 Spec No C, pC56
   Kaki M, 2023, 2023 3 INT C INTELL, P1, DOI [10.1109/ICCT56969.2023.10075992, DOI 10.1109/ICCT56969.2023.10075992]
   Karlsson L, 2010, INT J DENT, V2010, DOI 10.1155/2010/270729
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lakens D, 2022, COLLABRA-PSYCHOL, V8, DOI 10.1525/collabra.33267
   Lee JH, 2018, J DENT, V77, P106, DOI 10.1016/j.jdent.2018.07.015
   Li Z, 2020, CNN survey
   Lian LY, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11091672
   Mao YC, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134613
   Mertens S, 2021, J DENT, V115, DOI 10.1016/j.jdent.2021.103849
   Moran M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21155192
   Moutselos K, 2019, IEEE ENG MED BIO, P1617, DOI [10.1109/embc.2019.8856553, 10.1109/EMBC.2019.8856553]
   Oztekin F, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13020226
   Panyarak W, 2023, CLIN ORAL INVEST, V27, P1743, DOI 10.1007/s00784-023-04865-y
   Park EY, 2022, BMC ORAL HEALTH, V22, DOI 10.1186/s12903-022-02589-1
   Prados-Privado M, 2020, J CLIN MED, V9, DOI 10.3390/jcm9113579
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saini Devesh, 2021, 2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS), P958, DOI 10.1109/ICACCS51430.2021.9442001
   Shah N, 2014, WORLD J RADIOL, V6, P794, DOI 10.4329/wjr.v6.i10.794
   Sharbati K, 2023, Intell, V2, DOI [10.5281/ZENODO.7816266, DOI 10.5281/ZENODO.7816266]
   Shitie A, 2021, INT J DENT, V2021, DOI 10.1155/2021/6637196
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh P, 2021, MULTIMED TOOLS APPL, V80, P5255, DOI 10.1007/s11042-020-09891-6
   Sornam M, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON POWER, CONTROL, SIGNALS AND INSTRUMENTATION ENGINEERING (ICPCSI), P2698, DOI 10.1109/ICPCSI.2017.8392208
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taha AA, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0068-x
   Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27
   Tan MX, 2019, PR MACH LEARN RES, V97
   Turner DP, 2020, HEADACHE, V60, P8, DOI 10.1111/head.13707
   Ying S, 2022, J DENT, V119, DOI 10.1016/j.jdent.2022.104076
   Yu HB, 2020, IEEE ACCESS, V8, P185776, DOI 10.1109/ACCESS.2020.3029454
   Zhu HH, 2023, NEURAL COMPUT APPL, V35, P16051, DOI 10.1007/s00521-021-06684-2
NR 55
TC 1
Z9 2
U1 12
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30423
EP 30466
DI 10.1007/s11042-023-16599-w
EA SEP 2023
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001060763900013
DA 2024-07-18
ER

PT J
AU Zhu, XY
   Liu, LH
AF Zhu, Xinying
   Liu, Linhu
TI Diverse image search with explanations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image retrieval; Sentence generation; Relationship detection; Graph
   matching
ID RETRIEVAL; SIMILARITY
AB In this paper, we propose a novel content based image search framework with explanations, which can not only compare the similarity among images from different perspectives, but also describe the commonalities of two images with language. Specifically, we develop a graph matching method to calculate the similarity of two images and locate their commonalities, where each graph includes perceptual information, conceptual information and relational information. Furthermore, we utilize a language model based method to generate sentences to describe the similarities of two images. Comparing with different perspectives, we follow the principle that rich structured representations are more important than simple ones. To evaluate this principle, we conduct the experiment on the Visual Genome dataset, where each image contains lots of objects and multiple object relationships. The experimental results demonstrate the effectiveness of the principle. We also evaluate our method in the explanation of similar images, and the experimental results demonstrate that our method can obtain comparable performance.
C1 [Zhu, Xinying] Nanchang Inst Technol, Coll Business Adm, Nanchang 330044, Peoples R China.
   [Liu, Linhu] Lenovo Res, Beijing 100085, Peoples R China.
C3 Nanchang Institute Technology; Legend Holdings; Lenovo
RP Liu, LH (corresponding author), Lenovo Res, Beijing 100085, Peoples R China.
EM liulh7@lenovo.com
CR [Anonymous], 2013, P INT ACM C MULTIMED, DOI DOI 10.1145/2502081.2502093
   Berretti S, 2001, IEEE T PATTERN ANAL, V23, P1089, DOI 10.1109/34.954600
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen W, 2022, Arxiv, DOI arXiv:2101.11282
   Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Elhoseiny M, 2016, SHERLOCK SCALABLE FA
   ESHERA MA, 1986, IEEE T PATTERN ANAL, V8, P604, DOI 10.1109/TPAMI.1986.4767835
   Gentner D, 1998, COGNITION, V65, P263, DOI 10.1016/S0010-0277(98)00002-X
   GOLDSTONE RL, 1994, J EXP PSYCHOL LEARN, V20, P3, DOI 10.1037/0278-7393.20.1.3
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Grauman K, 2010, COMMUN ACM, V53, P84, DOI 10.1145/1743546.1743570
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Kafle K, 2016, PROC CVPR IEEE, P4976, DOI 10.1109/CVPR.2016.538
   Kawano Y, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P589, DOI 10.1145/2638728.2641339
   Krishna R, 2016, Arxiv, DOI arXiv:1602.07332
   Krishnamoorthy Niveda., 2013, Generating natural-language video descriptions using text-mined knowledge, P541
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li XR, 2019, IEEE T MULTIMEDIA, V21, P2347, DOI 10.1109/TMM.2019.2896494
   Li XR, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2906152
   Li YA, 2022, PROC CVPR IEEE, P17969, DOI 10.1109/CVPR52688.2022.01746
   Li YK, 2017, Arxiv, DOI arXiv:1702.07191
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51
   Lu JS, 2016, ADV NEUR IN, V29
   Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z
   Min WQ, 2020, IEEE T MULTIMEDIA, V22, P3128, DOI 10.1109/TMM.2020.2974326
   NAVON D, 1977, COGNITIVE PSYCHOL, V9, P353, DOI 10.1016/0010-0285(77)90012-3
   Paulin M, 2015, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2015.19
   Qin J, 2017, PROC CVPR IEEE, P6728, DOI 10.1109/CVPR.2017.712
   Rahman T, 2021, IEEE COMPUT SOC CONF, P1653, DOI 10.1109/CVPRW53098.2021.00181
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roth K., 2020, INT C MACH LEARN
   Sadeghi F, 2015, PROC CVPR IEEE, P1456, DOI 10.1109/CVPR.2015.7298752
   Sagi E, 2012, COGNITIVE SCI, V36, P1019, DOI 10.1111/j.1551-6709.2012.01250.x
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Suhail M, 2021, PROC CVPR IEEE, P13931, DOI 10.1109/CVPR46437.2021.01372
   Thomason J., 2014, INTEGRATING LANGUAGE
   Tzelepi M, 2018, NEUROCOMPUTING, V275, P2467, DOI 10.1016/j.neucom.2017.11.022
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang S, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700292
   Wu L, 2019, IEEE T IMAGE PROCESS, V28, P1602, DOI 10.1109/TIP.2018.2878970
   Wu Z, 2009, PROC CVPR IEEE, P25, DOI 10.1109/CVPRW.2009.5206566
   Xu H, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P275
   Yang X, 2021, PROC CVPR IEEE, P9842, DOI 10.1109/CVPR46437.2021.00972
   Yu J, 2008, IEEE T PATTERN ANAL, V30, P451, DOI 10.1109/TPAMI.2007.70714
   ZHANG D.-Q., 2004, PROC ACM INT C MULTI, P877, DOI DOI 10.1145/1027527.1027730
   Zhao WL, 2007, IEEE T MULTIMEDIA, V9, P1037, DOI 10.1109/TMM.2007.898928
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou F, 2016, IEEE T PATTERN ANAL, V38, P1774, DOI 10.1109/TPAMI.2015.2501802
   Zhou W., 2010, P 18 ACM INT C MULTI, P511
   Zhu YH, 2018, AAAI CONF ARTIF INTE, P7623
   Zhu YH, 2017, IEEE INT CON MULTI, P379, DOI 10.1109/ICME.2017.8019448
NR 60
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 10
PY 2023
DI 10.1007/s11042-023-16393-8
EA AUG 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O8QT2
UT WOS:001046412000002
DA 2024-07-18
ER

PT J
AU Garg, A
AF Garg, Ankit
TI Content-aware image retargeting technique and iterated function system:
   frameworks, applications, and possible future advancements
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Seam carving; Iterated function system; Image retargeting; Image quality
   assessment; Fractal; Affine transformation
AB The objective of the image retargeting operator is to reduce the size of the image in a content-aware fashion. To strengthen the process of single operator-based image retargeting different hybrid sequences are being investigated. The visual quality of fractal images can be improved by utilizing efficient retargeting operators. In this paper, three frameworks are developed and combined to minimize the deficiencies of image retargeting operations. In framework-1, a seam diversion-based image retargeting technique is developed to overcome the drawbacks of the existing seam carving (SC) technique. In framework-2, the technique developed in framework-1 is combined with other retargeting operators to produce an efficient hybrid sequence of image retargeting operators. The objective of framework-2 is to overcome the limitation of single operator based image retargeting. In framework-3, an improved affine transformation function is developed that incorporates hybrid sequence of operator proposed in the framework-2. The main objective of framework-3 is to replace the scaling operator from the existing affine transformation. The structural similarity index measure (SSIM) metric is used to measure the performance of framework-1. The comparative analysis reveals that the performance of the retargeting technique proposed in framework-1 is 7% higher as compared to the existing SC technique. The superiority of framework-2 and 3 is analyzed using an optimization function in which Image Euclidian Distance (IMED) and Dominant Color Descriptor (DCD) techniques are incorporated. Finally, the performance analysis of framework-2 and 3 discloses their higher efficacy as compared to existing state-of-the-art.
C1 [Garg, Ankit] Chandigarh Univ, Apex Inst Technol CSE, Mohali 140413, Punjab, India.
   [Garg, Ankit] Chandigarh Univ, Univ Ctr Res & Dev UCRD, Mohali 140413, Punjab, India.
C3 Chandigarh University; Chandigarh University
RP Garg, A (corresponding author), Chandigarh Univ, Apex Inst Technol CSE, Mohali 140413, Punjab, India.; Garg, A (corresponding author), Chandigarh Univ, Univ Ctr Res & Dev UCRD, Mohali 140413, Punjab, India.
EM ankitgitm@gmail.com
RI Garg, Ankit/ABD-9886-2020
OI Garg, Dr. Ankit/0000-0002-6466-2738
CR Abhayadev M., 2017, SABA J INF TECHNOL N, V5, P8
   Ahmad MI, 2020, INT J ADV MANUF TECH, V108, P3645, DOI 10.1007/s00170-020-05620-3
   Al-Jaberi A., 2018, EAI ENDORSED T IND N, V5, P1
   Andreadis I., 2005, P IEEE INSTR MEAS TE, V3, P2028, DOI DOI 10.1109/IMTC.2005.1604529
   [Anonymous], 2005, P 18 ANN ACM S US IN
   [Anonymous], 2015, IEEE INT C MULT EXP
   Arai K., 2019, EDITORIAL PREFACE DE, V10, P145
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Balakrishnan G, 2018, PROC CVPR IEEE, P9252, DOI 10.1109/CVPR.2018.00964
   Chai XL, 2020, IEEE T MULTIMEDIA, V22, P1208, DOI 10.1109/TMM.2019.2939707
   Chen YX, 2015, NEUROCOMPUTING, V151, P645, DOI 10.1016/j.neucom.2014.05.089
   Cheng JJ, 2016, J CHIN INST ENG, V39, P447, DOI 10.1080/02533839.2015.1117947
   Choi J, 2016, J SIGNAL PROCESS SYS, V85, P275, DOI 10.1007/s11265-015-1084-3
   Cui J, 2020, SIGNAL PROCESS, V166, DOI 10.1016/j.sigpro.2019.107242
   Fang YM, 2017, IEEE T SYST MAN CY-S, V47, P2956, DOI 10.1109/TSMC.2016.2557225
   Fragoso-Navarro E, 2022, J KING SAUD UNIV-COM, V34, P4499, DOI 10.1016/j.jksuci.2021.03.010
   Garg A., 2019, INT J ADV SCI TECHNO, V28, P1223
   Garg A., 2018, INT J ENG TECHNOLOGY, V7, P50
   Garg A, 2023, MULTIMED TOOLS APPL, V82, P23207, DOI 10.1007/s11042-022-14157-4
   Garg A, 2023, VISUAL COMPUT, V39, P2683, DOI 10.1007/s00371-022-02486-2
   Garg A, 2022, MULTIMED TOOLS APPL, V81, P12883, DOI 10.1007/s11042-022-12003-1
   Garg A, 2020, IET IMAGE PROCESS, V14, P2965, DOI 10.1049/iet-ipr.2019.1032
   Garg A, 2020, KSII T INTERNET INF, V14, P2997, DOI 10.3837/tiis.2020.07.015
   Garg A, 2021, SIGNAL IMAGE VIDEO P, V15, P185, DOI 10.1007/s11760-020-01736-x
   Guo Z, 2017, 2 INT C ART INT ENG, P651, DOI [10.12783/dtcse/aiea2017/14995, DOI 10.12783/DTCSE/AIEA2017/14995]
   Gupta R, 2018, IEEE T INSTRUM MEAS, P1, DOI [10.1109/IWAIT.2018.8369799, DOI 10.1109/IWAIT.2018.8369799]
   Hsi-Chin Hsin, 2017, The Journal of Engineering, DOI 10.1049/joe.2017.0003
   Hsin HC, 2020, J ENG-JOE, V2020, P870, DOI 10.1049/joe.2020.0116
   Hui Lin, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P2184, DOI 10.1109/CISP.2010.5647722
   Jadhav S, 2015, 2015 INTERNATIONAL CONFERENCE ON ENERGY SYSTEMS AND APPLICATIONS, P636, DOI 10.1109/ICESA.2015.7503427
   Kajiura N, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1755, DOI 10.1145/3394171.3413857
   Kim I, 2015, J SUPERCOMPUT, V71, P3500, DOI 10.1007/s11227-015-1446-4
   Li K, 2015, 2015 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING, P672, DOI 10.1109/ChinaSIP.2015.7230489
   Li K, 2015, SIGNAL PROCESS-IMAGE, V39, P509, DOI 10.1016/j.image.2015.07.005
   Liang Y, 2013, IET IMAGE PROCESS, V7, P61, DOI 10.1049/iet-ipr.2012.0308
   Lifang Wu, 2014, Journal of Multimedia, V9, P483, DOI 10.4304/jmm.9.4.483-492
   Lin W., 2018, INT C SMART VEH TECH, V86, P282, DOI [10.1007/978-3-319-70730-3_34, DOI 10.1007/978-3-319-70730-3_34]
   Lin X, 2014, J ZHEJIANG U-SCI C, V15, P697, DOI 10.1631/jzus.C1400102
   Lin YQ, 2016, 2016 17TH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES (PDCAT), P366, DOI [10.1109/PDCAT.2016.084, 10.1109/PDCAT.2016.83]
   Liu DR, 2022, VEHICLE SYST DYN, V60, P433, DOI 10.1080/00423114.2020.1817508
   Madaan A, 2018, LECT NOTE NETW SYST, V38, P49, DOI 10.1007/978-981-10-8360-0_5
   Maheswari SU, 2017, MULTIMED TOOLS APPL, V76, P415, DOI 10.1007/s11042-015-3035-1
   Makovetskii A., 2017, APPL DIGIT IMAGE PRO, V10396, P513
   Miculescu R, 2020, NUMER ALGORITHMS, V83, P1399, DOI 10.1007/s11075-019-00730-w
   Nag Amitava, 2011, Proceedings 2011 International Conference on Signal Processing, Communication, Computing and Networking Technologies (ICSCCN 2011), P309, DOI 10.1109/ICSCCN.2011.6024565
   Negi A, 2014, INT J COMPUTER APPL, Vl85, P25, DOI [10.5120/14830-3081, DOI 10.5120/14830-3081]
   Noh H., 2012, P 20 ACM INT C MULTI, P709, DOI DOI 10.1145/2393347.2396293
   Patel D, 2019, PATTERN RECOGN LETT, V125, P179, DOI 10.1016/j.patrec.2019.04.013
   Patel D, 2019, NATL CONF COMMUN, DOI 10.1109/ncc.2019.8732245
   Patel D, 2019, IET IMAGE PROCESS, V13, P885, DOI 10.1049/iet-ipr.2018.5283
   Qi SY, 2016, IEEE T IMAGE PROCESS, V25, P2222, DOI 10.1109/TIP.2016.2528040
   Rachor K., 2016, SCH HORIZ U MINN MOR, V3, P4
   Ran LQ, 2014, INT C INTEL HUM MACH, P59, DOI 10.1109/IHMSC.2014.117
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Shah D, 2020, MULTIDIM SYST SIGN P, V31, P885, DOI 10.1007/s11045-019-00689-w
   Shen JB, 2013, IEEE T CYBERNETICS, V43, P1453, DOI 10.1109/TCYB.2013.2273270
   Singh P, 2017, OPT APPL, V47, P421, DOI 10.5277/oa170308
   Solanki P, 2017, ADV INTELL SYST, V459, P467, DOI 10.1007/978-981-10-2104-6_42
   Suh Bongwon, 2003, P ACM S US INT SOFTW, P95, DOI DOI 10.1145/964696.964707
   Tang ZH, 2022, MULTIMED TOOLS APPL, V81, P1501, DOI 10.1007/s11042-021-11376-z
   Toony Z, 2010, FIFTH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY, AND SECURITY: ARES 2010, PROCEEDINGS, P702, DOI 10.1109/ARES.2010.54
   Valdez-Balderas D, 2021, IEEE IMAGE PROC, P1849, DOI 10.1109/ICIP42928.2021.9506584
   Wang S, 2020, PROCEEDINGS OF 2020 IEEE 5TH INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC 2020), P1609, DOI 10.1109/ITOEC49072.2020.9141774
   Wei D., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508216
   Wen-Jiin Tsai, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457847
   Yan Z, 2014, INT CONF MEAS, P60, DOI 10.1109/ICMTMA.2014.21
   Zaifeng Shi, 2008, 2008 International Conference on Neural Networks and Signal Processing, P388, DOI 10.1109/ICNNSP.2008.4590378
   Zhang LX, 2017, SOFT COMPUT, V21, P447, DOI 10.1007/s00500-015-1795-1
   Zhang Q, 2018, LECT NOTES COMPUT SC, V10736, P306, DOI 10.1007/978-3-319-77383-4_30
   Zhang Y, 2017, MULTIMED TOOLS APPL, V76, P8067, DOI 10.1007/s11042-016-3318-1
   Zhou B, 2016, J VIS COMMUN IMAGE R, V41, P21, DOI 10.1016/j.jvcir.2016.09.002
   Zhou Y, 2021, IEEE T CIRC SYST VID, V31, P126, DOI 10.1109/TCSVT.2020.2977943
NR 72
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20759
EP 20803
DI 10.1007/s11042-023-16348-z
EA AUG 2023
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001042010700002
DA 2024-07-18
ER

PT J
AU Bakir, H
   Cayir, AN
   Navruz, TS
AF Bakir, Halit
   cayir, Ayse Nur
   Navruz, Tugba Selcen
TI A comprehensive experimental study for analyzing the effects of data
   augmentation techniques on voice classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Voice recognition; Convolutional neural networks; Data augmentation;
   Hyperparameters tuning; Random search
AB It is not always possible to find enough data for deep learning studies. So, various data augmentation techniques have been developed and thus the success of deep learning models has increased. In this work, a comprehensive study has been conducted to evaluate the efficiency of different data augmentation techniques in terms of improving the voice classification models' performance. To this end, we proposed extracting MFCC features from the audio files, converting them into RGB images, and using CNN deep learning model for classifying the constructed RGB images into 12 classes. Moreover, Random search algorithm has been adopted for tuning the hyperparameters and selecting the best CNN model that can achieve this task with as high performance as possible. After that, some voice augmentation and image augmentation techniques have been used to increase the number of samples in the original dataset, and 17 different datasets have been constructed and used for training the proposed model. Particularly, 5 different voice augmentation techniques have been used for constructing 5 different datasets from the original dataset. When the proposed model has been trained using these voice augmentation-based datasets the validation accuracy and F1-score exceed 95%. Then, we suggested using image augmentation techniques for constructing another dataset from the original dataset. By training the model using this dataset we noted that the validation accuracy and F1-score of the proposed model dropped down to 81,92 and 81.67 respectively. Afterward, we suggested applying image augmentation techniques to the voice augmentation techniques-based datasets, and 5 different datasets have been constructed using this method. The results obtained by training the proposed model using these datasets showed that the classification accuracy and F1-score dropped down to 77.25 and 77.08 respectively. So, we concluded that the image augmentation techniques are not so suitable for voice recognition and classification tasks. To prof this hypothesis, we suggested merging the image augmentation-based dataset with voice augmentation-based datasets (i.e. the dataset gave the best results in this study), and 5 different datasets, each of which contains 18,000 samples, have been constructed using this method. When the proposed model has been trained using these datasets the classification accuracy and F1-score did not exceed 84.33% and 84.41% respectively in the best case. Furthermore, in order to prove the obtained results we suggested testing the proposed method using one more dataset from a different language namely the Turkish language dataset. The proposed approach gave more than 96% of classification accuracy when tested using this dataset i.e. Turkish dataset. The obtained results showed that it is preferred to apply voice augmentation techniques to the raw audio files instead of applying image augmentation techniques to the extracted feature matrixes in order to improve the performance of voice classification deep learning models.
C1 [Bakir, Halit] Sivas Univ Sci & Technol, Dept Comp Engn, Sivas, Turkiye.
   [cayir, Ayse Nur] Sivas Univ Sci & Technol, Dept Def Technol, Sivas, Turkiye.
   [Navruz, Tugba Selcen] Gazi Univ, Dept Elect & Elect Engn, Ankara, Turkiye.
C3 Sivas University of Science & Technology; Sivas University of Science &
   Technology; Gazi University
RP Bakir, H (corresponding author), Sivas Univ Sci & Technol, Dept Comp Engn, Sivas, Turkiye.
EM halit.bakir@sivas.edu.tr; 210101003@sivas.edu.tr; selcen@gazi.edu.tr
RI Bakır, Halit/AAE-1218-2022
OI Bakır, Halit/0000-0003-3327-2822
CR Abeysinghe A, 2023, APPL ACOUST, V203, DOI 10.1016/j.apacoust.2023.109209
   Ali MH, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031091
   Alim S. A., 2018, IntechOpen
   [Anonymous], 2015, International Journal of Emerging Technology and Advanced Engineering
   Aswad Ali, 2023, Advances in Artificial Systems for Medicine and Education VI. Lecture Notes on Data Engineering and Communications Technologies (159), P115, DOI 10.1007/978-3-031-24468-1_11
   Ates E, 2019, DERIN OGRENME ILE SE
   ?ayir AN., 2021, DEEP LEARNING BASED
   Bansal M., 2020, J ENG SCI, V11, P285
   Boddapati V, 2017, PROCEDIA COMPUT SCI, V112, P2048, DOI 10.1016/j.procs.2017.08.250
   Cayir AN, 2021, 2021 3 INT C HUM COM, P1, DOI [10.1109/HORA52670.2021.9461395, DOI 10.1109/HORA52670.2021.9461395]
   Code R., 2018, INTRO CONVOLUTIONAL
   Creative Commons, 2018, CREAT COMM INT ATTR
   Davis N, 2018, 2018 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), P41, DOI 10.1109/RAICS.2018.8635051
   Demir A, 2019, 2019 MEDICAL TECHNOLOGIES CONGRESS (TIPTEKNO), P533, DOI [10.1109/tiptekno47231.2019.8972045, 10.1109/CLEOE-EQEC.2019.8871518]
   ER MB., 2020, GAZI U J SCI PART C, V8, P830, DOI DOI 10.29109/GUJSC.758325
   Fang SH, 2019, J VOICE, V33, P634, DOI 10.1016/j.jvoice.2018.02.003
   Kir??i??ek Y., 2007, DOGRUSAL ONGORU ILE
   Kocer HE, 2019, VERI BILIMI, V2, P39
   Kumar Y, 2022, SOFT COMPUT, V2022, P1
   Kurtkaya M, 2021, SEARCH TURKISH SPEEC
   Lauraitis A, 2020, IEEE ACCESS, V8, P96162, DOI 10.1109/ACCESS.2020.2995737
   Lezhenin I, 2019, FED CONF COMPUT SCI, P57, DOI 10.15439/2019F185
   Lu R, 2017, IEEE WORK APPL SIG, P1, DOI 10.1109/WASPAA.2017.8169983
   Madhu A, 2019, EUR SIGNAL PR CONF, DOI 10.23919/eusipco.2019.8902819
   Mao JH, 2022, J INF SECUR APPL, V65, DOI 10.1016/j.jisa.2021.103085
   Maskeliunas R, 2022, CANCERS, V14, DOI 10.3390/cancers14102366
   Nanni L, 2020, ECOL INFORM, V57, DOI 10.1016/j.ecoinf.2020.101084
   Nassif AB, 2019, IEEE ACCESS, V7, P19143, DOI 10.1109/ACCESS.2019.2896880
   Piczak Karol J., 2015, 2015 IEEE 25th International Workshop on Machine Learning for Signal Processing (MLSP). Proceedings, DOI 10.1109/MLSP.2015.7324337
   Pleshkova-Bekiarska S., 2019, P INT C CREAT BUS SM, P1, DOI DOI 10.1109/ELECTRONICA.2019.8825618
   Ravichandran NK., 2022, INT J RES ENG SCI MA, V5, P79
   Shrawankar U, 2013, ARXIV
   Solovyev RA, 2020, 2020 IEEE 40TH INTERNATIONAL CONFERENCE ON ELECTRONICS AND NANOTECHNOLOGY (ELNANO), P688, DOI [10.1109/elnano50318.2020.9088863, 10.1109/ELNANO50318.2020.9088863]
   Suppakitjanusant P, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-98742-x
   tensorflow, 2018, SPEECH COMMANDS V2
   Warden P, 2018, ArXiv e-prints: 1804.03209
NR 36
TC 6
Z9 6
U1 5
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17601
EP 17628
DI 10.1007/s11042-023-16200-4
EA AUG 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001040922800002
OA hybrid
DA 2024-07-18
ER

PT J
AU Hu, K
   Li, Q
   Xie, J
   Pu, YY
   Guo, Y
AF Hu, Kai
   Li, Qing
   Xie, Jie
   Pu, Yingyan
   Guo, Ya
TI Using pre-trained models and graph convolution networks to find the
   causal relations among events in the Chinese financial text data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Causal relation; Pre-trained models; BERT; Graph convolution network;
   FinBERT; Dependency parsing
ID RELATION EXTRACTION
AB Nowadays, information explosion happens in every field. In the stock market of China, automatically understanding the market dynamics is extremely important. However, the information and datasets in Chinese are overwhelming for researchers in the field. How to extract useful information and understand the underlying logic in the Chinese corpus are the research hotspot. Causal relation identification is one of the most central tasks. Many works have made important progress in finding the causal relations in open-domain text, however, there is still space for further explorations in the specific domain of the financial field. In this paper, we propose to use the graph convolution network (GCN) to help represent the dependency relations among the entities in the logical networks provided by the Chinese dependency parsing tool, language technology platform(LTP). The motivation for using the GCN method to help represent the dependency relations is that the causal relations are highly correlated with language structures. Besides, we also choose to use the domain-specific pre-trained model FinBERT because this pre-trained model is specific to the financial field. Results show that the GCN-based method and pertained models of FinBERT in our proposed model play a key role in outperforming the baseline model of the traditional sequential labeling method and the start of art method from F1 of 0.4573 and 0.5506 to 0.6254. Our approach also wins third place in the Eastern District of software service outsourcing competition in China in the year 2021. We believe the proposed methods can contribute as at least an alternative option in future relation extraction tasks.
C1 [Hu, Kai; Li, Qing; Xie, Jie; Guo, Ya] Jiangnan Univ, Key Lab Adv Proc Control Light Ind, Minist Educ, Lihu Rd 1800, Wuxi 214122, Jiangsu, Peoples R China.
   [Hu, Kai; Li, Qing; Xie, Jie; Guo, Ya] Jiangnan Univ, Sch Internet Things, Lihu Rd 1800, Wuxi 214122, Jiangsu, Peoples R China.
   [Pu, Yingyan] Beijing Univ Agr, Econ & Management Sch, Beinong Rd 7, Beijing 102206, Peoples R China.
C3 Jiangnan University; Jiangnan University; Beijing University of
   Agriculture
RP Pu, YY (corresponding author), Beijing Univ Agr, Econ & Management Sch, Beinong Rd 7, Beijing 102206, Peoples R China.
EM hukai_wlw@Jiangnan.edu.cn; 1034190311@stu.jiangnan.edu.cn;
   xiej2018@jiangnan.edu.cn; puyingyan@bua.edu.cn; guoy@jiangnan.edu.cn
RI Li, Qing/JMH-1365-2023
OI Li, Qing/0000-0003-3370-471X
FU Open Research Fund of State Laboratory of Information Engineering in
   Surveying, Mapping and Remote Sensing, Wuhan University [18I04];
   National Natural Science Foundation of China [71904064, 61902154];
   Natural Science Foundation of Jiangsu Province [BK20190580,
   BK2019043526]; 111 Project; Research Funds for New Faculty of Jiangnan
   University [JUSRP11922, JUSRP11924]
FX This work is supported by Open Research Fund of State Laboratory of
   Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan
   University (Grant no. 18I04). The National Natural Science Foundation of
   China partially supports this research (Grant no. 71904064, 61902154) .
   The Natural Science Foundation of Jiangsu Province (Grant no.
   BK20190580, BK2019043526). The research is also supported by the 111
   Project and the Research Funds for New Faculty of Jiangnan University
   (Grant no. JUSRP11922, JUSRP11924).
CR Braud A, 2018, KNOWL-BASED SYST, V160, P119, DOI 10.1016/j.knosys.2018.06.011
   Bustos O, 2020, EXPERT SYST APPL, V156, DOI 10.1016/j.eswa.2020.113464
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cui Y, 2019, ARXIV
   Cuzzocrea A, 2020, SEBD
   Devlin J., 2018, BERT PRE TRAINING DE
   Geng ZQ, 2020, INFORM SCIENCES, V509, P183, DOI 10.1016/j.ins.2019.09.006
   Guo ZJ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P241
   Gururangan S., 2020, ARXIV
   Hassanzadeh O, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5003
   Hui B, 2020, EURASIP J WIREL COMM, V2020, DOI 10.1186/s13638-020-01720-6
   Jin YL, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12101729
   Lau JH., 2016, ARXIV
   Li PF, 2019, EXPERT SYST APPL, V115, P512, DOI 10.1016/j.eswa.2018.08.009
   Li XY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P465, DOI 10.1007/978-981-15-3863-6_51
   Liu Yinhan, 2019, ARXIV190711692
   Liu Zemin, 2021, IJCAI
   Luo L, 2018, BIOINFORMATICS, V34, P1381, DOI 10.1093/bioinformatics/btx761
   Marcus M.P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   Mrini K, 2019, EMNLP
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Sag IA, 1994, HEAD DRIVEN PHRASE S
   Stede M, 2008, STEP
   Velickovic P., 2018, ARXIV
   Yang J., 2021, arXiv
   Yang XF, 2014, EXPERT SYST APPL, V41, P7171, DOI 10.1016/j.eswa.2014.05.044
   Zhang YX, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6279, DOI 10.1109/ICASSP.2018.8462291
   Zhou J, 2019, ARXIV
   Zhu XY, 2022, IEEE T CIRC SYST VID, V32, P1273, DOI 10.1109/TCSVT.2021.3078436
   Zhu Xiangyuan, 2021, IEEE Transactions on Multimedia
NR 32
TC 0
Z9 0
U1 8
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 18699
EP 18720
DI 10.1007/s11042-023-15496-6
EA JUL 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040586800007
DA 2024-07-18
ER

PT J
AU Hemati, A
   Bastanfard, A
AF Hemati, Aref
   Bastanfard, Azam
TI Adjustable method based on body parts for improving the accuracy of 3D
   reconstruction in visually important body parts from silhouettes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D human body and pose; Shape from silhouettes; Body parts; 2D rigid
   registration; Pairwise matching
ID HUMAN SHAPE; MODEL; POSE
AB This research proposes a novel adjustable algorithm for reconstructing 3D body shapes from front and side silhouettes. Most recent silhouette-based approaches use a deep neural network trained by silhouettes and key points to estimate the shape parameters but cannot accurately fit the model to the body contours and consequently are struggling to cover detailed body geometry, especially in the torso. In addition, in most of these cases, body parts have the same accuracy priority, making the optimization harder and avoiding reaching the optimum possible result in essential body parts, like the torso, which is visually important in most applications, such as virtual garment fitting. In the proposed method, the expected accuracy for each body part can be adjusted based on the purpose by assigning coefficients for the distance of each body part between the projected 3D body and 2D silhouettes. To measure this distance, the correspondent body parts are first recognized using body segmentation in both views. Individual body parts are aligned by 2D rigid registration and matched using pairwise matching. The objective function tries to minimize the distance cost for the individual body parts in both views based on distances and coefficients by optimizing the statistical model parameters. The slight variation in the degree of arms and limbs is also handled by matching the pose. The proposed method was evaluated with images of synthetic and real body meshes. The result shows that the algorithm accurately reconstructs visually important body parts with high coefficients.
C1 [Hemati, Aref] Islamic Azad Univ, Dept Comp & Informat Technol Engn, Qazvin Branch, Qazvin, Iran.
   [Bastanfard, Azam] Islamic Azad Univ, Dept Comp Engn, Karaj Branch, Karaj, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Bastanfard, A (corresponding author), Islamic Azad Univ, Dept Comp Engn, Karaj Branch, Karaj, Iran.
EM aref.hemati@qiau.ac.ir; bastanfard@kiau.ac.ir
RI Bastanfard, Azam/AAX-8571-2020
OI Bastanfard, Azam/0000-0002-7935-819X
CR Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   [Anonymous], 2010, International Journal of Image Processing
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Bastanfard A, 2022, MULTIMED TOOLS APPL, V81, P23473, DOI 10.1007/s11042-022-12584-x
   Benezeth Y, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3456695
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491
   Boisvert J, 2013, MACH VISION APPL, V24, P145, DOI 10.1007/s00138-011-0353-9
   Bouaziz S, 2014, EUROGRAPHICS TUTORIA, P1, DOI [10.2312/egt.20141021, DOI 10.1118/1.4830428]
   Caesar I, 2020, MOST COMPREHENSIVE S
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chambers JM, 2021, ACTUATORS, V10, DOI 10.3390/act10040072
   Chen Y, 2010, LECT NOTES COMPUT SC, V6313, P300
   Chen Y, 2011, COMPUT VIS IMAGE UND, V115, P586, DOI 10.1016/j.cviu.2010.10.015
   Dibra E, 2017, PROC CVPR IEEE, P5504, DOI 10.1109/CVPR.2017.584
   Dibra E, 2016, INT CONF 3D VISION, P108, DOI 10.1109/3DV.2016.19
   Dibra E, 2016, LECT NOTES COMPUT SC, V9908, P88, DOI 10.1007/978-3-319-46493-0_6
   Everingham M., 2010, BMVC, V2, P5
   Fetic Azra, 2012, 2012 35th International Convention on Information and Communication Technology, Electronics and Microelectronics, P1752
   Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745
   Guan P, 2009, IEEE I CONF COMP VIS, P1381, DOI 10.1109/iccv.2009.5459300
   Hafiz AM, 2020, INT J MULTIMED INF R, V9, P171, DOI 10.1007/s13735-020-00195-x
   Hasler N, 2009, COMPUT GRAPH FORUM, V28, P337, DOI 10.1111/j.1467-8659.2009.01373.x
   Hasler N., 2008, US
   Horprasert T., 1999, Proceedings of IEEE ICCV Frame-Rate Workshop, P1
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jain A, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866174
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Kolotouros N, 2019, PROC CVPR IEEE, P4496, DOI 10.1109/CVPR.2019.00463
   LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735
   Li Z, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365707
   Lin YL, 2012, EXPERT SYST APPL, V39, P5012, DOI 10.1016/j.eswa.2011.10.011
   Lin YL, 2011, EXPERT SYST APPL, V38, P2585, DOI 10.1016/j.eswa.2010.08.048
   Lipman Y, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P181, DOI 10.1109/SMI.2004.1314505
   Liu B, 2022, J COMPUT INF SCI ENG, V22, DOI 10.1115/1.4054001
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Mahmood N, 2019, IEEE I CONF COMP VIS, P5441, DOI 10.1109/ICCV.2019.00554
   Mansourifar H., 2011, Proceedings of the 2011 Eighth International Conference on Computer Graphics, Imaging and Visualization (CGIV 2011), P65, DOI 10.1109/CGIV.2011.23
   Mansourifar H., 2011, Proceedings of the 2011 Eighth International Conference on Computer Graphics, Imaging and Visualization (CGIV 2011), P59, DOI 10.1109/CGIV.2011.33
   Mansourifar H, 2011, 2011 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P152, DOI 10.1109/CW.2011.26
   Minoofam SAH, 2010, P INT C CELL AUT RES, P70, DOI [10.1007/978-3-642-15979-4_8, DOI 10.1007/978-3-642-15979-4_8]
   Minoofam SAH, 2012, J CELL AUTOM, V7, P321
   Mochimaru M., 1998, INT ARCH PHOTOGRAMME, V32, P888
   Movahedi Z, 2021, MULTIMED TOOLS APPL, V80, P26773, DOI 10.1007/s11042-021-10968-z
   Nealen A, 2005, ACM T GRAPHIC, V24, P1142, DOI 10.1145/1073204.1073324
   Pavlakos G, 2018, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2018.00055
   Pishchulin L, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.5
   Pishchulin L, 2017, PATTERN RECOGN, V67, P276, DOI 10.1016/j.patcog.2017.02.018
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Reddy PR., 2012, INT J COMPUT SCI INF, V3, P3888, DOI DOI 10.4108/eai.21-12-2018.159334
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Seo H, 2006, LECT NOTES COMPUT SC, V3942, P849
   Sigal L., 2008, ADV NEURAL INFORM PR, P1337
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Smith BM, 2019, INT CONF 3D VISION, P279, DOI 10.1109/3DV.2019.00039
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   UK National Sizing Survey, 2020, US
   Varol G, 2017, PROC CVPR IEEE, P4627, DOI 10.1109/CVPR.2017.492
   Wang WG, 2022, IEEE T PATTERN ANAL, V44, P3508, DOI 10.1109/TPAMI.2021.3055780
   Wu Y., 2019, DETECTRON2
   Xi PC, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P139, DOI 10.1109/PG.2007.45
   Yan S, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2101.02515
   Yan S, 2021, INT C PATT RECOG, P7804, DOI 10.1109/ICPR48806.2021.9412708
   Yang JL, 2016, LECT NOTES COMPUT SC, V9908, P439, DOI 10.1007/978-3-319-46493-0_27
   Zhang X, 2023, ARXIV, DOI DOI 10.48550/ARXIV.2301.12416
   Zhang Y., 2014, SIMULATIONS SERIOUS, P31, DOI [10.1007/978-981-4560-32-0_3, DOI 10.1007/978-981-4560-32-0_3]
   Zhou T, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2103.04570
NR 70
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21583
EP 21613
DI 10.1007/s11042-023-16170-7
EA JUL 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037378900008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Dai, Q
   Cheng, X
   Zhang, L
AF Dai, Qiang
   Cheng, Xi
   Zhang, Li
TI Image denoising using channel attention residual enhanced Swin
   Transformer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Deep learning; Swin Transformer; Channel attention
ID FRAMEWORK; CNN
AB Transformers have achieved remarkable results in high-level vision tasks, but their application in low-level computer vision tasks such as image denoising remains largely unexplored. In this paper, we propose a novel channel attention residual enhanced Swin Transformer denoising network (CARSTDn), which is an efficient and effective Transformer-based architecture. CARSTDn consists of three modules: shallow feature extraction, deep feature extraction, and image reconstruction modules. The deep feature extraction module is the core of CARSTDn, and it employs a channel attention residual Swin Transformer block (CARSTB). Our bench-marking results demonstrate that CARSTDn outperforms existing state-of-the-art methods, showcasing its superiority. We hope that our work will inspire further research into the use of Transformer-based architectures for image denoising tasks.
C1 [Dai, Qiang; Zhang, Li] Soochow Univ, Sch Comp Sci & Technol, Suzhou 215006, Peoples R China.
   [Cheng, Xi] Nanjing Univ Posts & Telecommun, Sch Commun & Informat Engn, Nanjing 210003, Peoples R China.
   [Cheng, Xi] Hong Kong Polytech Univ, Dept Elect & Informat Engn, Hong Kong, Peoples R China.
C3 Soochow University - China; Nanjing University of Posts &
   Telecommunications; Hong Kong Polytechnic University
RP Zhang, L (corresponding author), Soochow Univ, Sch Comp Sci & Technol, Suzhou 215006, Peoples R China.
EM zhangliml@suda.edu.cn
FU Natural Science Foundation of the Jiangsu Higher Education Institutions
   of China [19KJA550002]; Six Talent Peak Project of Jiangsu Province of
   China [XYDXX-054]; Priority Academic Program Development of Jiangsu
   Higher Education Institutions; Collaborative Innovation Center of Novel
   Software Technology and Industrialization
FX AcknowledgementsThe authors would like to thank the editor and the
   anonymous reviewers for their critical and constructive comments and
   suggestions.This work was supported in part by the Natural Science
   Foundation of the Jiangsu Higher Education Institutions of China under
   [Grant No. 19KJA550002], by the Six Talent Peak Project of Jiangsu
   Province of China under [Grant No. XYDXX-054], by the Priority Academic
   Program Development of Jiangsu Higher Education Institutions, and by the
   Collaborative Innovation Center of Novel Software Technology and
   Industrialization.
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Ahmad S, 2022, CLUSTER COMPUT, V25, P3733, DOI 10.1007/s10586-022-03598-z
   Aljadaany R, 2019, LECT NOTES COMPUT SC, V11662, P3, DOI 10.1007/978-3-030-27202-9_1
   Anwar S, 2019, IEEE I CONF COMP VIS, P3155, DOI 10.1109/ICCV.2019.00325
   Cao Hu, 2023, Computer Vision - ECCV 2022 Workshops: Proceedings. Lecture Notes in Computer Science (13803), P205, DOI 10.1007/978-3-031-25066-8_9
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Jia XX, 2019, PROC CVPR IEEE, P6047, DOI 10.1109/CVPR.2019.00621
   Lebrun M, 2012, IMAGE PROCESS ON LIN, V2, P175, DOI 10.5201/ipol.2012.l-bm3d
   Li Y., 2021, ARXIV
   Liang, 2021, ARXIV
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu PJ, 2018, IEEE COMPUT SOC CONF, P886, DOI 10.1109/CVPRW.2018.00121
   Liu Y., 2021, ARXIV
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Loshchilov I., 2018, arXiv
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Plötz T, 2018, ADV NEUR IN, V31
   Quan YH, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107639
   Ramachandran P, 2019, ADV NEUR IN, V32
   Roth S, 2005, PROC CVPR IEEE, P860
   Shi Q, 2021, IEEE T GEOSCI REMOTE, V59, P10348, DOI 10.1109/TGRS.2020.3045273
   Tian CW, 2020, NEURAL NETWORKS, V124, P117, DOI 10.1016/j.neunet.2019.12.024
   Tian CW, 2020, NEURAL NETWORKS, V121, P461, DOI 10.1016/j.neunet.2019.08.022
   Tian CW, 2019, CAAI T INTELL TECHNO, V4, P17, DOI 10.1049/trit.2018.1054
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Vaswani A, 2021, PROC CVPR IEEE, P12889, DOI 10.1109/CVPR46437.2021.01270
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Z., 2021, ARXIV
   Wu B., 2020, Visual transformers: Token-based image representation and processing for computer vision
   Wu H., 2021, ARXIV
   Xiao J, 2021, SIGNAL PROCESS-IMAGE, V96, DOI 10.1016/j.image.2021.116299
   Xu J, 2015, IEEE I CONF COMP VIS, P244, DOI 10.1109/ICCV.2015.36
   Yuan Kun, 2021, ARXIV
   Zhang K, 2022, IEEE T PATTERN ANAL, V44, P6360, DOI 10.1109/TPAMI.2021.3088914
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang Y., 2019, arXiv
   Zheng Sixiao, 2020, ARXIV201215840, DOI [DOI 10.1109/CVPR46437.2021.00681, 10.1109/CVPR46437.2021.00681]
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 47
TC 0
Z9 0
U1 26
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19041
EP 19059
DI 10.1007/s11042-023-16209-9
EA JUL 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001036798900008
DA 2024-07-18
ER

PT J
AU Joshi, A
   Sharma, KK
AF Joshi, Abhilasha
   Sharma, K. K.
TI Dense deep transformer for medical image segmentation: DDTraMIS
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vision transformer; Medical image segmentation; Attention network;
   Convolution neural network; Shift-invariant feature
AB In this work, DDTraMIS architecture based on vision has been designed for medical image segmentation for different medical imaging such as MRI and CT-scan. This methodology contributes novel hybrid features extracted with a bi-directional attention-based transformer encoder-decoder network along with all stage features fused with an approximation fusing algorithm. The novelty is to combine Convolution neural networks (CNNs) and shift-invariant methods to develop hybrid features. For the verification of this novel network experiment, three different datasets, such as the ACDC, LiTS, and BraTS datasets have been used. Performance analysis has been conducted using the dice similarity coefficient (DSC) and the Hausdorff distance (HD) metrics. The proposed architecture accomplished DSC values of 92.80, 96.45, 72.80, and 73.12 for ACDC, LiTS Liver, LiTS tumor, and BraTS tumor segmentation analysis, respectively. Similarly, HD metric numeric values are 8.53, 12.84, 9.69, and 10.38 for ACDC, LiTS Liver, LiTS tumor, and BraTS tumor segmentation analysis, respectively. With advantageous performance for highly features incorporated, this method learned from tiny to extensive scaling information. Comparative and quantitative analysis has proven its superior performance and effective segmenting architecture.
C1 [Joshi, Abhilasha; Sharma, K. K.] Malaviya Natl Inst Technol, Elect & Commun Engn, Jaipur 302017, Rajasthan, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur
RP Joshi, A (corresponding author), Malaviya Natl Inst Technol, Elect & Commun Engn, Jaipur 302017, Rajasthan, India.
EM 2017rec9045@mnit.ac.in; kksharma.ece@mnit.ac.in
OI Joshi, Abhilasha/0000-0002-3624-802X
CR Azad R, 2019, IEEE INT CONF COMP V, P406, DOI 10.1109/ICCVW.2019.00052
   Bakas Spyridon, 2018, ARXIV181102629, DOI DOI 10.17863/CAM.38755
   Bernard O, 2018, IEEE T MED IMAGING, V37, P2514, DOI 10.1109/TMI.2018.2837502
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Bilic P, 2019, ARXIV
   Chen JP, 2021, NAT PHOTONICS, V15, P570, DOI 10.1038/s41566-021-00828-5
   Ciresan D., 2012, NIPS, P2843
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Hatamizadeh A, 2022, IEEE WINT CONF APPL, P1748, DOI 10.1109/WACV51458.2022.00181
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Heravi EJ, 2016, FRONT ARTIF INTEL AP, V288, P163, DOI 10.3233/978-1-61499-696-5-163
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Isensee F, 2021, NAT METHODS, V18, P203, DOI 10.1038/s41592-020-01008-z
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Joshi Abhilasha, 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P1529, DOI 10.1109/ICAIS50930.2021.9395914
   Joshi A, 2022, PHYS ENG SCI MED, DOI 10.1007/s13246-022-01154-y
   Kumar S, 2012, INT J IMAGE GRAPH, V4, P1, DOI DOI 10.5815/IJIGSP.2012.06.01
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Nithesh K., 2022, 2022 International Conference on Knowledge Engineering and Communication Systems (ICKES), P1, DOI 10.1109/ICKECS56523.2022.10059844
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Peiris H, 2021, ARXIV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Samala RK, 2019, IEEE T MED IMAGING, V38, P686, DOI 10.1109/TMI.2018.2870343
   Seixas JL, 2015, COMP MED SY, P50, DOI 10.1109/CBMS.2015.48
   Simpson A.L., 2019, LARGE ANNOTATED MEDI
   Tan CC, 2009, IEEE T INF TECHNOL B, V13, P926, DOI 10.1109/TITB.2009.2033055
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Valanarasu Jeya Maria Jose, 2021, Medical Image Computing and Computer Assisted Intervention - MICCAI 2021: 24th International Conference, Proceedings. Lecture Notes in Computer Science, Image Processing, Computer Vision, Pattern Recognition, and Graphics (12901), P36, DOI 10.1007/978-3-030-87193-2_4
   Wang CB, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-78799-w
   Wang WX, 2021, LECT NOTES COMPUT SC, V12901, P109, DOI 10.1007/978-3-030-87193-2_11
   Xie YT, 2021, LECT NOTES COMPUT SC, V12903, P171, DOI 10.1007/978-3-030-87199-4_16
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zheng X, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0309-3
   Zhou M., 2022, arXiv
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
NR 38
TC 0
Z9 0
U1 8
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18073
EP 18089
DI 10.1007/s11042-023-16252-6
EA JUL 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035725700010
DA 2024-07-18
ER

PT J
AU Tan, ZH
   Xia, ZC
   Wang, PF
   Wu, DK
   Li, L
AF Tan, Zhenhua
   Xia, Zhenche
   Wang, Pengfei
   Wu, Danke
   li, Li
TI SCTF: an efficient neural network based on local spatial compression and
   full temporal fusion for video violence detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE 3DCNN; Violence detection; Spatiotemporal fusion; Action recognition
ID HUMAN ACTION RECOGNITION
AB Spatiotemporal modeling is key for action recognition in videos. In this paper, we propose a Spatial features Compression and Temporal features Fusion (SCTF) block, including a Local Spatial features Compression (LSC) module and a Full Temporal features Fusion (FTF) module, we call the network equipped with SCTF block SCTF-NET, which is a human action recognition network more suitable for violent video detection. The spatial extraction and temporal fusions in previous works are typically achieved by stacking large numbers of convolution layers or adding some complex recurrent neural layers. In contrast, the SCTF module extracts the spatial information of video frames by LSC module, and the temporal sequence information of continuous frames is fused by FTF module, which can effectively conduct spatiotemporal modeling. Finally, our approach achieves good performance on action recognition benchmarks such as HMDB51 and UCF101. Meanwhile, it is more efficient in training and detection. What's more, experiments on violence datasets Hockey Fights, Movie Fight and Violent Flow show that, our proposed SCTF block is more suitable for violent action recognition. Our code is available at https://github.com/TAN-OpenLab/SCTF-Net.
C1 [Tan, Zhenhua; Xia, Zhenche; Wang, Pengfei; Wu, Danke; li, Li] Northeastern Univ, Software Coll, Heping, Shenyang 110819, Liaoning, Peoples R China.
C3 Northeastern University - China
RP Tan, ZH (corresponding author), Northeastern Univ, Software Coll, Heping, Shenyang 110819, Liaoning, Peoples R China.
EM tanzh@mail.neu.edu.cn; xiazhenche@stumail.neu.edu.cn;
   wangpengfei@stumail.neu.edu.cn; wudk2019@stumail.neu.edu.cn;
   lili02@stumail.neu.edu.cn
RI Wang, Pengfei/ABC-9076-2021
OI Tan, Zhenhua/0000-0002-9870-8925
FU National Key Research and Development Program of China [2019YFB1405803]
FX AcknowledgementsThis research was funded by the National Key Research
   and Development Program of China under Grant No. 2019YFB1405803.
CR Afza F, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104090
   Amelio A, 2023, EXPERT SYST APPL, V215, DOI 10.1016/j.eswa.2022.119391
   Nievas EB, 2011, LECT NOTES COMPUT SC, V6855, P332, DOI 10.1007/978-3-642-23678-5_39
   Bilen H, 2016, PROC CVPR IEEE, P3034, DOI 10.1109/CVPR.2016.331
   Bin Jiang, 2019, 2019 International Conference on Intelligent Computing and its Emerging Applications (ICEA). Proceedings, P59, DOI 10.1109/ICEA.2019.8858306
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Roman DGC, 2020, SIBGRAPI, P248, DOI 10.1109/SIBGRAPI51738.2020.00041
   Das Srijan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P72, DOI 10.1007/978-3-030-58545-7_5
   Diba A, 2017, PROC CVPR IEEE, P1541, DOI 10.1109/CVPR.2017.168
   Dosovitskiy Alexey, 2020, ABS201011929 CORR
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Girdhar R, 2019, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2019.00033
   Gu CN, 2020, IEEE ACCESS, V8, P85958, DOI 10.1109/ACCESS.2020.2992617
   Guo J, 2021, NEUROCOMPUTING, V458, P14, DOI 10.1016/j.neucom.2020.11.074
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   Hassner T., 2012, 2012 IEEE COMP SOC C, P1, DOI [DOI 10.1109/CVPRW.2012.6239348, 10.1109/CVPRW.2012.6239348]
   He JY, 2021, NEUROCOMPUTING, V444, P319, DOI 10.1016/j.neucom.2020.05.118
   Jiang SQ, 2021, IEEE T IND INFORM, V17, P4584, DOI 10.1109/TII.2020.3018487
   Keçeli AS, 2017, ELECTRON LETT, V53, P1047, DOI 10.1049/el.2017.0970
   Klaser A., 2008, BMVC 2008 19 BRIT MA, P1
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Li C, 2022, IEEE T NEUR NET LEAR, V33, P4800, DOI 10.1109/TNNLS.2021.3061115
   Li CH, 2021, NEUROCOMPUTING, V453, P383, DOI 10.1016/j.neucom.2020.07.148
   Liu RX, 2021, INT J COMPUT VISION, V129, P1596, DOI 10.1007/s11263-021-01436-0
   Misra D, 2020, Arxiv, DOI arXiv:1908.08681
   Naik AJ, 2021, MULTIMED TOOLS APPL, V80, P18365, DOI 10.1007/s11042-021-10682-w
   Nam J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P353, DOI 10.1109/ICIP.1998.723496
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Ranasinghe K, 2021, ARXIV
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soliman Mohamed Mostafa, 2019, 2019 Ninth International Conference on Intelligent Computing and Information Systems (ICICIS), P80, DOI 10.1109/ICICIS46948.2019.9014714
   Song W, 2019, IEEE ACCESS, V7, P39172, DOI 10.1109/ACCESS.2019.2906275
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Sudhakaran S., 2017, 2017 14 IEEE INT C A, P1, DOI DOI 10.1109/AVSS.2017.8078468
   Sun C, 2019, IEEE I CONF COMP VIS, P7463, DOI 10.1109/ICCV.2019.00756
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan ZH, 2023, APPL INTELL, V53, P4218, DOI 10.1007/s10489-022-03708-9
   Traoré A, 2020, IEEE SYS MAN CYBERN, P154, DOI [10.1109/smc42975.2020.9282971, 10.1109/SMC42975.2020.9282971]
   Ullah A, 2021, NEUROCOMPUTING, V435, P321, DOI 10.1016/j.neucom.2019.12.151
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang ZW, 2021, PROC CVPR IEEE, P13209, DOI 10.1109/CVPR46437.2021.01301
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Wu HP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P22, DOI 10.1109/ICCV48922.2021.00009
   Xu J, 2021, NEUROCOMPUTING, V441, P350, DOI 10.1016/j.neucom.2020.04.150
   Zheng C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11636, DOI 10.1109/ICCV48922.2021.01145
   Zhou PP, 2017, J PHYS CONF SER, V844, DOI 10.1088/1742-6596/844/1/012044
NR 52
TC 0
Z9 0
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUL 24
PY 2023
DI 10.1007/s11042-023-16269-x
EA JUL 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA N2YI0
UT WOS:001035725700019
DA 2024-07-18
ER

PT J
AU Topal, K
   Günhan, AC
   Bagci, GB
AF Topal, Kamil
   Gunhan, Ali Can
   Bagci, G. Baris
TI Predicting annus mirabilis with machine learning: Turkish movie industry
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quantification of success; Actor; Actress; Zipf's law; Annus mirabilis;
   Data mining; Machine learning prediction; Deformed logarithms
ID NETWORKS; SUCCESS; BITCOIN
AB There has recently been an increasing interest in the quantification of success in different fields of human activities. However, most of the research in this field solely focuses on success as a collective phenomenon to be understood in terms of a network structure or overall statistics. Moreover, research in this field rarely attempts to predict success. In this work, we consider real data in the Turkish movie industry, with a focus on individual criteria of success and predict annus mirabilis, also known as the miracle year of the performers, through several machine learning algorithms. We find that this prediction can be achieved best by using a random forest model yielding 92 and 90 percent accuracy for actresses and actors, respectively. Next, we provided a novel q-deformed generalization of the k-Nearest Neighbor (kNN) algorithm, which yields the unnormalized kNN algorithm when the parameter q = 0, and logarithmic normalized kNN algorithm for q = 1. This generalization increases the prediction accuracy of the miracle year by one percent for the optimal value q = -3 of the parameter compared to the random forest algorithm. In addition, we found out that the probability of career length follows an exponential distribution in the intermediate region, hence distinguishing two outlier groups. The former group is formed by those with only one movie credit (almost seventy five percent of the acting guild), and the latter group corresponds to those with a career length exceeding thirty five years (almost one percent). The probability distribution of acting in n movies, on the other hand, is observed to be a power law with an exponent corresponding to Zipf's law if ordered in rank. This behavior seems to be the norm in the film industry and is a signature of the memory-dependent (namely, popularity dependent) choices of directors and producers. We investigated whether gender plays a role in the Turkish film industry, and found out that it does, favoring actors in terms of duration of activity. However, after a certain threshold of career length, namely L = 55 years, it is more likely to find active actresses.
C1 [Topal, Kamil] Balikesir Univ, Dept Comp Engn, TR-10145 Balikesir, Turkiye.
   [Gunhan, Ali Can; Bagci, G. Baris] Mersin Univ, Dept Phys, TR-33343 Mersin, Turkiye.
C3 Balikesir University; Mersin University
RP Günhan, AC (corresponding author), Mersin Univ, Dept Phys, TR-33343 Mersin, Turkiye.
EM kamiltopal@balikesir.edu.tr; alicangunhan@mersin.edu.tr;
   gbagci@mersin.edu.tr
OI GUNHAN, Ali Can/0000-0003-0050-2484
FU Mersin University [2018-3-AP5-3093]
FX One of us, A.C.G., thanks to Arinna B. Guenhan for manual data
   annotation and Ilayda Agar for proofreading. G.B.B. acknowledges support
   from Mersin University under the project 2018-3-AP5-3093
CR Bai XM, 2021, SCIENTOMETRICS, V126, P7993, DOI 10.1007/s11192-021-04078-8
   Bonaventura M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-57209-w
   Bouri E, 2017, FINANC RES LETT, V20, P192, DOI 10.1016/j.fri.2016.09.025
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Center for Turkish cinema studies (TSA), US
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Du JF, 2014, EXPERT SYST APPL, V41, P1680, DOI 10.1016/j.eswa.2013.08.065
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   IMDb, about us
   Jang H, 2018, IEEE ACCESS, V6, P5427, DOI 10.1109/ACCESS.2017.2779181
   Janosov M, 2020, EPJ DATA SCI, V9, DOI 10.1140/epjds/s13688-020-00227-w
   Kart O, 2020, PHYSICA A, V553, DOI 10.1016/j.physa.2020.124287
   Li WH, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13130-4
   Lipizzi C, 2016, TECHNOL FORECAST SOC, V109, P35, DOI 10.1016/j.techfore.2016.05.013
   Liu L, 2018, NATURE, V559, P396, DOI 10.1038/s41586-018-0315-8
   Maimone VM, 2021, ROY SOC OPEN SCI, V8, DOI 10.1098/rsos.210617
   Petrantonakis PC, 2019, IEEE ACCESS, V7, P37565, DOI 10.1109/ACCESS.2019.2905049
   Pluchino A, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0218793
   Pluchino A, 2018, ADV COMPLEX SYST, V21, DOI 10.1142/S0219525918500145
   Ram SK, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-10837-1
   Ren ZM, 2018, PHYS REV E, V97, DOI 10.1103/PhysRevE.97.052311
   Sage A., 2018, THESIS IOWA STATE U
   Sharda R, 2006, EXPERT SYST APPL, V30, P243, DOI 10.1016/j.eswa.2005.07.018
   Sobkowicz P, 2020, PHYSICA A, V557, DOI 10.1016/j.physa.2020.124899
   Tsallis C., 2009, INTRO NONEXTENSIVE S, DOI DOI 10.1007/978-0-387-85359-8
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Williams OE, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-10213-0
   Yin Y, 2019, NATURE, V575, P190, DOI 10.1038/s41586-019-1725-y
   Zhang L, 2009, EXPERT SYST APPL, V36, P6580, DOI 10.1016/j.eswa.2008.07.064
   Zhang YL, 2015, PHYSICA A, V417, P261, DOI 10.1016/j.physa.2014.09.012
NR 30
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17357
EP 17372
DI 10.1007/s11042-023-16212-0
EA JUL 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035768900001
DA 2024-07-18
ER

PT J
AU Sironmani, PP
   Augasta, MG
AF Sironmani, P. Pravin
   Augasta, M. Gethsiyal
TI A novel CNN Architecture with an efficient Channelization for
   Histopathological Medical Image Classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Channelization; Convolutional neural network; Histopathological medical
   image classification; Feature extraction; Adaptive histogram
   equalization; Adaptive hysteresis thresholding
ID ADAPTIVE HISTOGRAM EQUALIZATION; MODEL
AB Diagnosing the issues in the tissues has always been a challenging task on medical images like MRI, Mammogram, Computed Tomography, X-Ray, Retinal Image, etc. In recent years, CNN has proven to be better at extracting features from images for classification through various image classification research studies. Still, CNN seems to be struggling to provide the most accurate results for the task of classifying histopathological medical images. In this research, a new technique called Channelization is introduced to replace the first convolution layer, which helps the model to extract the refined features easily. The main aim of the proposed technique is to make the CNN more efficient with a new start-up mechanism for directing the model towards better classification with more enhanced features. In the proposed method, initially, the adaptive histogram equalization technique is used for contrast stretching the grayscale image. Then the adaptive hysteresis thresholding technique is employed for creating various segmented versions of the grayscale image by varying the threshold values. The different versions of the histogram equalized image are then stacked into the third dimension of the actual grayscale image for making it into the channelized image. Finally, the channelized image is fed into the subsequent layer of the proposed lightweight CNN architecture for better classification. The proposed architecture is experimentally evaluated on four benchmark datasets, namely COVID-19 (2019), APTOS-19, Cancer and COVID-19 (2021), and it is justified that the proposed model can efficiently classify the histopathological medical images better than the other existing state-of-the art architectures.
C1 [Sironmani, P. Pravin] Manonmaniam Sundaranar Univ, St Johns Coll, Tirunelveli, Tamil Nadu, India.
   [Augasta, M. Gethsiyal] Manonmaniam Sundaranar Univ, Kamaraj Coll, Thoothukudi, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University; Manonmaniam Sundaranar University
RP Augasta, MG (corresponding author), Manonmaniam Sundaranar Univ, Kamaraj Coll, Thoothukudi, Tamil Nadu, India.
EM siron.pravin@gmail.com; augastaglady@gmail.com
RI M, Gethsiyal Augasta/AAS-2164-2020
OI M, Gethsiyal Augasta/0000-0002-1975-7623
CR Abdillah B, 2018, INT SYM MICRO-NANOM
   Abdulsahib AA, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11091295
   Abdulsahib AA, 2021, NETW MODEL ANAL HLTH, V10, DOI 10.1007/s13721-021-00294-7
   Alizadeh S, ABS170406756 CORR
   [Anonymous], 2015, PROC IEEE C COMPUT V
   [Anonymous], 2016, COMPUT MATH METHOD M
   ConduracheAP AachT, 2005, P 9 IAPR C MACH VIS, P269
   Dachapally P. R., 2017, Facial Emotion Detection Using Convolutional Neural Networks and Representational Autoencoder Units
   Dash S, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14020194
   El-Sappagh S, 2022, NEUROCOMPUTING, V512, P203, DOI 10.1016/j.neucom.2022.09.009
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Han ZY, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04075-z
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Ivakhnenko A.G., 1965, Cybernetic predicting devices
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li Q, 2014, I C CONT AUTOMAT ROB, P844, DOI 10.1109/ICARCV.2014.7064414
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   McCulloch WS, 2016, EMBODIMENTS OF MIND, P19
   Mughal B, 2019, INT J MED INFORM, V126, P26, DOI 10.1016/j.ijmedinf.2019.02.001
   Mukhlif AA, 2022, J INTELL SYST, V31, P1085, DOI 10.1515/jisys-2022-0198
   Rachapudi V, 2021, EVOL INTELL, V14, P1337, DOI 10.1007/s12065-020-00367-y
   Rafiq A, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13101700
   Rumelhart D.E., 2013, Learning internal representations by error propagation, P399, DOI [10.1016/b978-1-4832-1446-7.50035-2, 10.1016/B978-1-4832-1446-7.50035-2]
   Saha M, 2018, COMPUT MED IMAG GRAP, V64, P29, DOI 10.1016/j.compmedimag.2017.12.001
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Vulli A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082988
   Werbos P. J., 1981, SYSTEM MODELING OPTI, P762, DOI [10.1007/BFb0006203, DOI 10.1007/BFB0006203]
   Zheng YS, 2017, PATTERN RECOGN, V71, P14, DOI 10.1016/j.patcog.2017.05.010
   Zhu YL, 2012, PHYSCS PROC, V25, P601, DOI 10.1016/j.phpro.2012.03.132
   ZIMMERMAN JB, 1988, IEEE T MED IMAGING, V7, P304, DOI 10.1109/42.14513
NR 34
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17983
EP 18003
DI 10.1007/s11042-023-16232-w
EA JUL 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001032703400001
DA 2024-07-18
ER

PT J
AU Li, GQ
   Wang, J
   Tan, YL
   Shen, LY
   Jiao, DL
   Zhang, Q
AF Li, Guoqin
   Wang, Jin
   Tan, Yanli
   Shen, Lingyun
   Jiao, Dongli
   Zhang, Quan
TI Semi-supervised medical image segmentation based on GAN with the pyramid
   attention mechanism and transfer learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image segmentation; GAN; encoder-decoder; Transfer learning;
   Image pyramid
AB Deep learning-based medical image segmentation requires a large number of labeled data to train the model. Obtaining large-scale labeled medical image datasets is time-consuming and expensive. In contrast, it is easy to obtain unlabeled data, which also deserve to be effectively explored to improve the segmentation quality. To solve this problem, we proposed a semi-supervised deep learning method based on Generative Adversarial Network (GAN) in combination with a pyramid attention mechanism and transfer learning (TP-GAN). In this work, TP-GAN consisted of a generator (segmentation network) and a discriminator (evaluation network). The generator adopted the encoder-decoder architecture for image segmentation (the output was called the predicted map), and the discriminator adopted convolutional neural network (CNN) to evaluate the quality of the predicted map. Through adversarial training between generator and discriminator, TP-GAN could achieve high segmentation quality since discriminator guides the generator to generate more accurate segmentation maps with more similar distribution as ground truth for unlabeled data in semi-supervised learning. Furthermore, the encoder in generator utilized the VGG16 model which had been trained for image classification on ImageNet data, meanwhile constituted a new segmentation model with the decoder. Transfer learning strategy could reduce the training time and overcome the limitation of small-scale labeled data in semi-supervised learning. And the generator used image pyramid attention mechanism to extract more detailed features to enhance the information of feature maps. The proposed TP-GAN model and other segmentation models were trained and tested on two different datasets (Hippocampus and Spleen). The results demonstrated that TP-GAN could achieve higher segmentation accuracy on the Hippocampus and Spleen than other semi-supervised segmentation methods based on different evaluation metrics (Dice, IoU, HD, and RVE). The proposed TP-GAN model could effectively utilize the unlabeled data to improve the segmentation quality. And TP-GAN could relieve the burden of a tedious image annotation process and reduce the influence of physicians' subjective experiences in clinical practice.
C1 [Li, Guoqin; Wang, Jin; Tan, Yanli; Shen, Lingyun; Jiao, Dongli] Taiyuan Inst Technol, Dept Elect Engn, Taiyuan 030008, Shanxi, Peoples R China.
   [Zhang, Quan] North Univ China, Sch Informat & Commun Engn, Taiyuan 030008, Shanxi, Peoples R China.
C3 Taiyuan Institute of Technology; North University of China
RP Li, GQ (corresponding author), Taiyuan Inst Technol, Dept Elect Engn, Taiyuan 030008, Shanxi, Peoples R China.
EM liguoqin@studyedus.cn
FU Scientific and Technological Innovation Programs of Higher Education
   Institutions in Shanxi [2022L538, 2022L533]; Natural Science Foundation
   of Shanxi province [201901D111153]; Youth Foundation of Taiyuan
   Institute of Technology [2018LG08]
FX This work was supported by Scientific and Technological Innovation
   Programs of Higher Education Institutions in Shanxi (STIP 2022L538; and
   2022L533), the Natural Science Foundation of Shanxi province
   (201901D111153), and the Youth Foundation of Taiyuan Institute of
   Technology (2018LG08).
CR Adal KM, 2018, IEEE T BIO-MED ENG, V65, P1382, DOI 10.1109/TBME.2017.2752701
   Amer A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12073676
   Anping Xu, 2010, Proceedings 2010 3rd International Conference on Intelligent Networks and Intelligent Systems (ICINIS 2010), P703, DOI 10.1109/ICINIS.2010.181
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chaitanya K, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101934
   Chanchal AK, 2022, MULTIMED TOOLS APPL, V81, P9201, DOI 10.1007/s11042-021-11873-1
   Cheng ZM, 2022, VISUAL COMPUT, V38, P749, DOI 10.1007/s00371-021-02075-9
   Çigla C, 2008, IEEE IMAGE PROC, P2272, DOI 10.1109/ICIP.2008.4712244
   Conze PH, 2020, COMPUT MED IMAG GRAP, V83, DOI 10.1016/j.compmedimag.2020.101733
   Gerig G., 2001, Medical Image Computing and Computer-Assisted InterventionMICCAI 2001, Proceedings of the 4th International Conference Utrecht, The Netherlands, 1417 October 2001, P516
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Han LY, 2020, COMPUT METH PROG BIO, V189, DOI 10.1016/j.cmpb.2019.105275
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   Iqbal A, 2022, INT J MULTIMED INF R, V11, P333, DOI 10.1007/s13735-022-00240-x
   Iriawan N, 2020, TELKOMNIKA (Telecommun. Comput. Electron. Control.), V18, P1310, DOI [10.12928/telkomnika.v18i3.14753, DOI 10.12928/TELKOMNIKA.V18I3.14753, 10.12928/TELKOMNIKA.v18i3.14753]
   Kalinin A.A., 2020, Deep Learning Applications, P39, DOI 10.1007/978-981-15-1816-4_3
   Kar SS, 2018, IEEE T BIO-MED ENG, V65, P608, DOI 10.1109/TBME.2017.2707578
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Liu XB, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13031224
   Luc P., 2016, ARXIV
   Luo XD, 2022, MED IMAGE ANAL, V80, DOI 10.1016/j.media.2022.102517
   Marwa F, 2022, MULTIMED TOOLS APPL, V81, P13537, DOI 10.1007/s11042-022-12322-3
   Min SB, 2021, IEEE T MULTIMEDIA, V23, P899, DOI 10.1109/TMM.2020.2990063
   Morid MA, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104115
   Nie D, 2018, LECT NOTES COMPUT SC, V11073, P370, DOI 10.1007/978-3-030-00937-3_43
   Omiotek Z, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020500
   Peng JZ, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107269
   Rasyid DA, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P393, DOI 10.1109/Confluence51648.2021.9377093
   Son J, 2019, J DIGIT IMAGING, V32, P499, DOI 10.1007/s10278-018-0126-3
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun YR, 2020, IEEE ACCESS, V8, P26457, DOI 10.1109/ACCESS.2020.2971542
   Theckedath D., 2020, SN COMPUT SCI, V1, P1
   Wenjia Bai, 2017, Medical Image Computing and Computer-Assisted Intervention, MICCAI 2017. 20th International Conference. Proceedings: LNCS 10434, P253, DOI 10.1007/978-3-319-66185-8_29
   Xun SY, 2022, COMPUT BIOL MED, V140, DOI 10.1016/j.compbiomed.2021.105063
   Yizhe Zhang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P408, DOI 10.1007/978-3-319-66179-7_47
   Zhang K, 2019, IEEE ACCESS, V7, P9872, DOI 10.1109/ACCESS.2018.2890127
   Zhao C, 2022, MULTIMED TOOLS APPL, V81, P8691, DOI 10.1007/s11042-022-12067-z
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao YQ, 2005, P ANN INT IEEE EMBS, P6492, DOI 10.1109/IEMBS.2005.1615986
   Zhou SH, 2020, IEEE T IMAGE PROCESS, V29, P461, DOI 10.1109/TIP.2019.2919937
   Zunair H, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104699
NR 41
TC 0
Z9 0
U1 10
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17811
EP 17832
DI 10.1007/s11042-023-16213-z
EA JUL 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001029126000012
DA 2024-07-18
ER

PT J
AU Rajasree, RS
   Rajakumari, SB
AF Rajasree, R. S.
   Rajakumari, S. Brintha
TI Ensemble-of-classifiers-based approach for early Alzheimer's Disease
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Early Alzheimer's detection; WGM-PCA; IAR; MLP; QDNN; BI-GRU; EMOAOA
ID MILD COGNITIVE IMPAIRMENT; IMAGING GENETICS; PREDICTION; REGRESSION;
   CONVERSION; DIAGNOSIS; BIOMARKER; MODEL
AB Alzheimer's disease (AD) is a deadly neurological condition. Deep learning approaches (DL) techniques have just been utilized to track the evolution of Alzheimer's disease. These studies only employed baseline neuro imaging data. Because of the high cost of neuro imaging data, it is constantly restricted or unavailable. As a result, this research developed a novel, four-phase early Alzheimer's disease detection approach: "(a) pre-processing, (b) feature extraction, (c) feature selection, and (d) classification". Data cleaning and normalization is used in pre-processing. Consequently, features like "Weighted Geometric Mean Principle Component Analysis (WGM-PCA), Statistical Features, higher-order statistical features, and Weighted modified correlation-based features" are retrieved from the pre-processed data. Employing the Improved Attribute Ranker (IAR), the most relevant characteristics are chosen. Furthermore, the disease classification phase is represented by a deep learning model based on an ensemble of classifiers, containing optimized "Bi-GRU, Multi-Layer Perceptron (MLP), and Quantum Neural Network (QDNN)", respectively. The ultimate decision is obtained via optimal Bi-GRU, which is trained using MLP and QDNN outcomes. Both the MLP and the QDNN would be trained using the chosen IAR-based features. Interestingly, to improve the network's detection accuracy, the weight of the QDNN model is adjusted using the recently proposed Enhanced Math Optimizer Accelerated Arithmetic Optimization (EMOAOA) technique. Particularly, the proposed EMOAOA+EC achieved detecting accuracies of 95% at the 60th LR, 95.5% at the 70th LR, 98% at the 80th LR, and 98.7% at the 90th LR. The development of the optimized ensemble classifier is responsible for this improvement.
C1 [Rajasree, R. S.] Bharath Inst Higher Educ & Res, Dept Comp Sci & Engn, Chennai 600073, Tamilnadu, India.
   [Rajakumari, S. Brintha] Bharath Inst Higher Educ & Res, Dept Comp Sci, Chennai 600073, Tamilnadu, India.
C3 Bharath Institute of Higher Education & Research; Bharath Institute of
   Higher Education & Research
RP Rajasree, RS (corresponding author), Bharath Inst Higher Educ & Res, Dept Comp Sci & Engn, Chennai 600073, Tamilnadu, India.
EM rsrajasree44@gmail.com
RI S, Brintha Rajakumari/ADR-3141-2022; cse, rajasree/JVO-0475-2024
OI S, Brintha Rajakumari/0000-0003-4381-3493; 
CR Abedi M, 2020, J NANOMATER, V2020, DOI 10.1155/2020/6749150
   Abualigah L, 2021, COMPUT METHOD APPL M, V376, DOI 10.1016/j.cma.2020.113609
   Afsal S, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P1439, DOI 10.1109/WiSPNET.2016.7566374
   Afzal S, 2019, IEEE ACCESS, V7, P115528, DOI 10.1109/ACCESS.2019.2932786
   Basaia S, 2019, NEUROIMAGE-CLIN, V21, DOI 10.1016/j.nicl.2018.101645
   Basher A, 2021, IEEE ACCESS, V9, P29870, DOI 10.1109/ACCESS.2021.3059658
   Batmanghelich NK, 2016, IEEE T MED IMAGING, V35, P1765, DOI 10.1109/TMI.2016.2527784
   Beheshti I, 2017, COMPUT BIOL MED, V83, P109, DOI 10.1016/j.compbiomed.2017.02.011
   Bi XA, 2020, IEEE J BIOMED HEALTH, V24, P2973, DOI 10.1109/JBHI.2020.2973324
   Boo Y, 2020, IEEE WRK SIG PRO SYS, P117, DOI 10.1109/sips50750.2020.9195245
   Casanova R, 2018, NEUROIMAGE, V183, P401, DOI 10.1016/j.neuroimage.2018.08.040
   Chehade A, 2019, IEEE T AUTOM SCI ENG, V16, P192, DOI 10.1109/TASE.2018.2829770
   Cui RX, 2019, COMPUT MED IMAG GRAP, V73, P1, DOI 10.1016/j.compmedimag.2019.01.005
   Cui Yumeng, 2020, 2020 2nd International Conference on Machine Learning, Big Data and Business Intelligence (MLBDBI), P392, DOI 10.1109/MLBDBI51377.2020.00084
   Dadar M, 2017, IEEE T MED IMAGING, V36, P1758, DOI 10.1109/TMI.2017.2693978
   El-Sappagh S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-82098-3
   El-Sappagh S, 2021, FUTURE GENER COMP SY, V115, P680, DOI 10.1016/j.future.2020.10.005
   Goceri E, 2019, INT J NUMER METH BIO, V35, DOI 10.1002/cnm.3225
   Guo HB, 2020, IEEE ACCESS, V8, P115383, DOI 10.1109/ACCESS.2020.3003424
   Gupta MK, 2014, IEEE INT CONF INNOV, P7, DOI [10.1109/INNOVATIONS.2014.6987553, 10.1109/ICIINFS.2014.7036550]
   Haider F, 2020, IEEE J-STSP, V14, P272, DOI 10.1109/JSTSP.2019.2955022
   Hao Wang, 2020, 2020 Proceedings of Asia-Pacific Conference on Image Processing, Electronics and Computers (IPEC), P197, DOI 10.1109/IPEC49694.2020.9115194
   Hlaing CS, 2017, IEEE GLOB CONF CONSU
   Huang MY, 2021, IEEE T MED IMAGING, V40, P1461, DOI 10.1109/TMI.2021.3057660
   Jie B, 2017, IEEE T BIO-MED ENG, V64, P238, DOI 10.1109/TBME.2016.2553663
   Kavitha C, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.853294
   Khan NM, 2019, IEEE ACCESS, V7, P72726, DOI 10.1109/ACCESS.2019.2920448
   Kruthika K. R., 2019, Informatics in Medicine Unlocked, V14, P34, DOI 10.1016/j.imu.2018.12.003
   Kruthika K. R., 2019, Informatics in Medicine Unlocked, V14, P59, DOI 10.1016/j.imu.2018.12.001
   Lahmiri S, 2019, BIOMED SIGNAL PROCES, V52, P414, DOI 10.1016/j.bspc.2018.08.009
   Li W, 2019, IEEE J BIOMED HEALTH, V23, P1234, DOI 10.1109/JBHI.2018.2839771
   Li X, 2021, IEEE J BIOMED HEALTH, V25, P3677, DOI 10.1109/JBHI.2021.3093027
   Liu K, 2018, I S BIOMED IMAGING, P1402, DOI 10.1109/ISBI.2018.8363834
   Liu MX, 2016, IEEE T BIO-MED ENG, V63, P1473, DOI 10.1109/TBME.2015.2496233
   Liu MX, 2016, IEEE T MED IMAGING, V35, P1463, DOI 10.1109/TMI.2016.2515021
   Luo P, 2019, IEEE ACM T COMPUT BI, V16, P222, DOI 10.1109/TCBB.2017.2770120
   Manners HN, 2018, COMPUT BIOL CHEM, V77, P373, DOI 10.1016/j.compbiolchem.2018.10.014
   Martinez-Murcia FJ, 2020, IEEE J BIOMED HEALTH, V24, P17, DOI 10.1109/JBHI.2019.2914970
   Mattsson N, 2019, ALZHEIMERS DEMENT, V15, P570, DOI 10.1016/j.jalz.2018.12.001
   Minhas S, 2018, IEEE J BIOMED HEALTH, V22, P818, DOI 10.1109/JBHI.2017.2703918
   Moscoso A, 2019, NEUROIMAGE-CLIN, V23, DOI 10.1016/j.nicl.2019.101837
   Nawaz H, 2021, MULTIMED TOOLS APPL, V80, P35789, DOI 10.1007/s11042-020-09087-y
   Ning ZY, 2021, IEEE T MED IMAGING, V40, P1632, DOI 10.1109/TMI.2021.3063150
   Ozansoy C, 2020, IEEE T POWER SYST, V35, P4952, DOI 10.1109/TPWRS.2020.3018634
   Rahim M, 2016, IEEE J-STSP, V10, P1204, DOI 10.1109/JSTSP.2016.2600400
   Ren FJ, 2019, IEEE ACCESS, V7, P181423, DOI 10.1109/ACCESS.2019.2920241
   Samper-González J, 2018, NEUROIMAGE, V183, P504, DOI 10.1016/j.neuroimage.2018.08.042
   Shaikh TA, 2019, MAGN RESON IMAGING, V62, P167, DOI 10.1016/j.mri.2019.06.019
   Shi J, 2018, IEEE J BIOMED HEALTH, V22, P173, DOI 10.1109/JBHI.2017.2655720
   Tong T, 2017, IEEE T BIO-MED ENG, V64, P155, DOI 10.1109/TBME.2016.2549363
   Vaithinathan K, 2019, J NEUROSCI METH, V318, P84, DOI 10.1016/j.jneumeth.2019.01.011
   Wang R, 2021, CHIN CONTR CONF, P3155, DOI 10.23919/CCC52363.2021.9550664
   Zhou T, 2019, IEEE T MED IMAGING, V38, P2411, DOI 10.1109/TMI.2019.2913158
NR 53
TC 1
Z9 1
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16067
EP 16095
DI 10.1007/s11042-023-16023-3
EA JUL 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001028770200001
DA 2024-07-18
ER

PT J
AU Kaduru, R
   Mercy, P
   Srinivas, GN
AF Kaduru, Raju
   Mercy, P.
   Srinivas, G. N.
TI Power distribution system reliability evaluation using weight-optimised
   ANN approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep Learning; Artificial Neural Network; Enriched BPSO approach;
   State-space categorisation; Reliability; Distribution System
ID DISTRIBUTION NETWORKS; MANAGEMENT; OUTAGE
AB Power systems are identified as the most complex infrastructure over the globe. That Power distribution system is a critical network section with the greatest concentration of failure occurrences. An evaluation of the reliability of the power distribution network is exhaustive trouble. However, analysation of effectiveness and failure rate interpretation is the most significant barrier to limiting the real-time application of distribution system reliability evaluation. The methodology proposed in this paper is to integrate deep learning-based techniques implemented to execute network reliability for the preferred distribution test system-execution of reliability evaluations obtained by combining MCS models for improving the accuracy of computing PDN reliability indices. Subsequently, for system state observation, an ANN-based state-space categorisation-dependent (SSC) system with Enriched Binary Particle Swarm Optimization (EBPSO) is introduced to seek failure states throughout uncategorised subspaces. Moreover, the reliability evaluation framework is being implemented in Roy Billinton Test System (RBTS) bus 2 systems, and MATLAB Software analyses its reliability indices. The reliability indices for the third component fault case scenario provide a better outcome than other scenario cases. The reliability indices values such as SAIFI, SAIDI, AENS, and ASAI at scenario 3 condition are 0.232,3.497,17.48,0.99905. The proposed structure's outcome promotes an excellent reliability evaluation pattern, confirming lesser loss and providing robust reliability indices computation.
C1 [Kaduru, Raju; Mercy, P.] TKR Coll Engn & Technol, Hyderabad 500097, India.
   [Srinivas, G. N.] JNTUH UCESTH, Hyderabad 500085, India.
RP Kaduru, R (corresponding author), TKR Coll Engn & Technol, Hyderabad 500097, India.
EM kadururaju@tkrcet.com; mercyhepcibarani@gmail.com;
   gnsgns.srinivas785@gmail.com
CR Allan R. N., 2013, Reliability Evaluation of Power Systems
   Aslani M, 2022, IET RENEW POWER GEN, V16, P2816, DOI 10.1049/rpg2.12541
   Benidris M, 2015, IET GENER TRANSM DIS, V9, P1865, DOI 10.1049/iet-gtd.2015.0581
   Bera Atri., 2020, International Conference on Probabilistic Methods Applied to Power Systems (PMAPS), P1
   Cai BP, 2019, IEEE T IND INFORM, V15, P2146, DOI 10.1109/TII.2018.2858281
   Castillo A, 2014, ELECTR POW SYST RES, V107, P9, DOI 10.1016/j.epsr.2013.09.002
   Chen YY, 2016, IET RENEW POWER GEN, V10, P1562, DOI 10.1049/iet-rpg.2015.0608
   Farzin H, 2018, IEEE T POWER SYST, V33, P2359, DOI 10.1109/TPWRS.2017.2746180
   Garro BA, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/369298
   Hamilton W. L., 2017, B TECHNICAL COMMITTE, V40, P52
   Helmi AM, 2022, IEEE T AUTOM SCI ENG, V19, P82, DOI 10.1109/TASE.2021.3072862
   Jia H, 2016, 2016 INT C PROB METH, P1
   Kamruzzaman M, 2022, INT J ELEC POWER, V135, DOI 10.1016/j.ijepes.2021.107468
   Li GF, 2020, IET GENER TRANSM DIS, V14, P2282, DOI 10.1049/iet-gtd.2019.1520
   Li W., 2013, Reliability Assessment of Electric Power Systems Using Monte Carlo Methods
   Li W., 1994, RELIABILITY ASSESSME
   Liu WX, 2018, IEEE T POWER SYST, V33, P7096, DOI 10.1109/TPWRS.2018.2854642
   Midence D, 2008, PROC IEEE-PES, P53
   Mudgal Soumya., 2020, 21st National Power Systems Conference (NPSC), P1
   Pan QJ, 2017, STRUCT SAF, V67, P85, DOI 10.1016/j.strusafe.2017.04.006
   Urgun D, 2020, INT CONF PR ME A P S, DOI 10.1109/pmaps47429.2020.9183474
   Urgun Dogan., 2019, IEEE Power Energy Society General Meeting (PESGM), P1
   Wadi M, 2022, ELECTR POW COMPO SYS, V49, P696, DOI 10.1080/15325008.2021.2004476
   Xie KG, 2003, IEE P-GENER TRANSM D, V150, P686, DOI 10.1049/ip-gtd:20030797
   Yong P, 2019, IEEE T POWER SYST, V34, P1630, DOI 10.1109/TPWRS.2018.2878324
   Yu S, 2017, PROCEDIA COMPUT SCI, V109, P1200, DOI 10.1016/j.procs.2017.05.399
NR 26
TC 0
Z9 0
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13905
EP 13927
DI 10.1007/s11042-023-16114-1
EA JUL 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001025616000001
DA 2024-07-18
ER

PT J
AU Saeidi, S
AF Saeidi, Shahram
TI Identifying personality traits of WhatsApp users based on frequently
   used emojis using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social Network Analysis; Emoji; WhatsApp; Deep Leaning; LSTM; Image
   Processing
ID NETWORKS
AB Social networks have become an element of individual life in the present era and have many applications in economic, social, commercial, and even educational and academic fields and aspects. Daily use of various messaging applications affects people's lifestyles, and the usage method of such applications differs depending on the user's personality. WhatsApp messenger is one of the most popular social media applications widely used by people enabling them to send messages in text, voice, image, and emojis. In this paper, a Long Short-Term Memory (LSTM) neural network is designed to identify the personality trait of WhatsApp users by analyzing the most frequently used emojis. The users are classified into 16 classes involving four psychological aspects considered as introverted or extroverted, happy or depressed, optimistic or pessimistic, and neurotic or calm. For this purpose, 13,688 samples were collected from volunteer users, including screenshots of frequently used emojis and their beliefs about mentioned feelings. The screenshot images were converted to numerical codes using image processing, and the proposed LSTM is implemented in MATLAB 2021b using the deep learning toolbox. The simulation results show that the proposed network is trained with 96.3% accuracy and can predict the personality type of individuals with 95.48% accuracy based on users' most frequently used emojis. The proposed method also achieves a minimum 93.99% score in the Precision, Recall, and F-measure criteria. The comparison of the results obtained by the Random Forest algorithm shows the superiority of the proposed model.
C1 [Saeidi, Shahram] Islamic Azad Univ, Dept Ind Engn, Tabriz Branch, Tabriz, Iran.
C3 Islamic Azad University
RP Saeidi, S (corresponding author), Islamic Azad Univ, Dept Ind Engn, Tabriz Branch, Tabriz, Iran.
EM sh_saeidi@iaut.ac.ir
RI Saeidi, Shahram/AAN-5752-2021
OI Saeidi, Shahram/0000-0002-6990-0950
CR Abayomi-Alli O, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6989
   Abkenar SB, 2021, TELEMAT INFORM, V57, DOI 10.1016/j.tele.2020.101517
   Agarwal G, 2022, INT J ADAPT CONTROL, V36, P1835, DOI 10.1002/acs.3425
   Ahan MR., 2018, INT RES J ENG TECHNO, V5, P3084
   [Anonymous], 2012, LSTM RECURRENT NEURA
   Bai QY, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02221
   Bala Rajni, 2017, INT J COMPUT INTELL, V13, P1811
   Abkenar SB, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6381
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cui HL, 2021, EURASIP J IMAGE VIDE, V2021, DOI 10.1186/s13640-020-00545-z
   Eagle N, 2009, P NATL ACAD SCI USA, V106, P15274, DOI 10.1073/pnas.0900282106
   Evans V., 2017, The emoji code: The linguistics behind smiley faces and scaredy cats
   Hussain A, 2019, LECT NOTE NETW SYST, V39, P177, DOI 10.1007/978-981-13-0277-0_15
   Hussain SJ., 2021, TURKISH J COMPUT MAT, V12, P2038
   James R, 2015, TAYLORHEARING
   Khemphila A., 2011, 2011 21st International Conference on Systems Engineering, P406, DOI 10.1109/ICSEng.2011.80
   Kukharenko A. I., 2015, Pattern Recognition and Image Analysis, V25, P461, DOI 10.1134/S1054661815030128
   Kumar N., 2020, INT J INNOV TECHNOL, V9, P696, DOI DOI 10.35940/IJITEE.C8378.019320
   Li W., 2018, 12 INT AAAI C WEB SO
   Marengo D, 2017, PERS INDIV DIFFER, V112, P74, DOI 10.1016/j.paid.2017.02.037
   Ryan T, 2011, COMPUT HUM BEHAV, V27, P1658, DOI 10.1016/j.chb.2011.02.004
   SALCHENBERGER LM, 1992, DECISION SCI, V23, P899, DOI 10.1111/j.1540-5915.1992.tb00425.x
   Singh H, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.13038
   Skues JL, 2012, COMPUT HUM BEHAV, V28, P2414, DOI 10.1016/j.chb.2012.07.012
   Sperl G, 2016, THESIS VIENNA U TECH
   Tan QY, 2019, FRONT BIG DATA, V2, DOI 10.3389/fdata.2019.00002
   Wu TM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.4209
   Zhu Y, 2020, INT J ELEC ENG EDUC, DOI 10.1177/0020720920936839
NR 28
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13873
EP 13886
DI 10.1007/s11042-023-15209-z
EA JUL 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001026613700002
DA 2024-07-18
ER

PT J
AU Memon, I
   Shaikh, RA
   Shaikh, H
AF Memon, Imran
   Shaikh, Riaz Ahmed
   Shaikh, Hidayatullah
TI Dynamic pseudonyms trust-based model to protect attack scenario for
   internet of vehicle ad-hoc networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VANET; Trust model; IoV; MiTM attacks; Security
ID MULTIPLE MIX-ZONES; PRIVACY PROTECTION; MANAGEMENT SCHEME; CHANGING
   STRATEGY; LOCATION PRIVACY; FRAMEWORK; REPUTATION; SECURE;
   AUTHENTICATION; ARCHITECTURE
AB The Intelligent transport systems (ITS) have evolved with the Internet of Vehicles (IoV) and the growth of advanced wireless technology associated with billions of smart devices connected to Internet. The rapidly evolving use of the Internet of Things (IoT) has led to significant growth in VANETs have transformed the traditional VANET topology into an Internet of vehicles (IoV),an improving road safety and automatic traffic monitoring to reduce issues related to traffic congestion. However, the security risk is expanding due to VANET communications' dependence on resources such as computing as well as a lack of standards due to rapidly evolving technologies. Existing methods have proposed very limited protections in using a single pseudonym or invalidating the trust scheme that anonymous attackers can easily compromise. During vehicular communication, messages in VANET might be associated with reliability since the transaction of messages in vehicular communication needs to be comprehensive enough and secure enough to withstand the security threats by achieving trustworthiness transmission of the dynamic pseudonyms trust model (DPTM). Conversely, the severe challenge is to protect information exchange between vehicles because some malicious nodes might perform as Man-in-the-Middle (MiTM) network attackers due to dishonest vehicles in VANET. The increasing trustworthiness between nodes can thus lead to an increase in VANET's trustworthy sharing of knowledge, privacy, security, accuracy, and authenticity. In this paper, we proposed a dynamic trust-based model in the term of dynamic pseudonyms changing scheme that first identify the honest vehicles as nodes to broadcast messages to normal vehicles on the road and secondly change their pseudonyms in only some specific zone to identify the dishonest nodes for protection assurance in the State of MiTM and Sybil attacks. Furthermore, it has addressed the use of pseudonym schemes for privacy and security requirements. All VANET nodes have built the trust given initially by the various RSUs and servers, trusted communication in the network. The experiment was performed based on various network scenarios to assess the accuracy and efficacy of the dynamic trust-based model. We have extensively evaluated performance measures of the F-Score, Recall, and Precision indices to demonstrate that the proposed model has outperformed the MARINE and PPARTM models already reported. The experimental results have verified the proposed lightweight model for certifying the recognized trust level of 40% of MiTM attackers with an F-Score of 95% compared to the MARINE model's highest recognized detection of 90%.
C1 [Memon, Imran; Shaikh, Riaz Ahmed; Shaikh, Hidayatullah] Shah Abdul Latif Univ, Inst Comp Sci, Khairpur, Sindh, Pakistan.
C3 Shah Abdul Latif University
RP Memon, I (corresponding author), Shah Abdul Latif Univ, Inst Comp Sci, Khairpur, Sindh, Pakistan.
EM imran.memon@salu.edu.pk
RI memon, imran/K-1647-2017
OI memon, imran/0000-0002-8202-6604
CR Agrawal A., 2013, International Journal of Emerging Technology and Advanced Engineering, V3, P231
   Ahmad F, 2020, IEEE INTERNET THINGS, V7, P3310, DOI 10.1109/JIOT.2020.2967568
   Ahmad F, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P314, DOI 10.1109/iccisci.2019.8716450
   Ahmed N, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/6503299
   Ahmed S, 2018, J SENSORS, V2018, DOI 10.1155/2018/6576841
   Al Junaid Mohammed Ali Hezam, 2018, MATEC Web of Conferences, V150, DOI 10.1051/matecconf/201815006038
   Al-kahtani MohammedSaeed., 2012, Signal Processing and Communication Systems (ICSPCS), 2012 6th International Conference on, P1
   Al-Turjman F, 2020, COMPUT ELECTR ENG, V87, DOI 10.1016/j.compeleceng.2020.106776
   [Anonymous], 2005, Workshop on Hot Topics in Networks (HotNets-IV)
   Arain QA, 2017, CHINA COMMUN, V14, P89, DOI 10.1109/CC.2017.7927579
   Asgharzadeh Mohammadmahdi, 2018, 2018 2nd URSI Atlantic Radio Science Meeting (AT-RASC), DOI 10.23919/URSI-AT-RASC.2018.8471408
   Buttyan Levente., 2009, P IEEE VEHICULAR NET, P1, DOI DOI 10.1109/VNC.2009.5416380
   Cavalcanti ER, 2018, ACM SIGCOMM COMP COM, V48, P31, DOI 10.1145/3213232.3213237
   Chen C., 2010, Information Technology Convergence and Services (ITC S), 2010 2nd International Conference on, P1, DOI DOI 10.1109/ITCS.2010.5581298
   Chen C, 2010, IEEE ICC
   Chen JM, 2019, IEEE ACCESS, V7, P148913, DOI 10.1109/ACCESS.2018.2876153
   Chukwuocha C, 2021, PEER TO PEER NETWORK, P1
   De-Fuentes J.M., 2011, Handbook of Research on Mobility and Computing: Evolving Technologies and Ubiquitous Impacts, P894
   Deshpande A., 2021, INT J GRID DISTRIB, V14, P1771
   Dötzer F, 2005, I S WORLD WIREL MOBI, P454, DOI 10.1109/WOWMOM.2005.109
   Eltahir AA, 2016, EURASIP J WIREL COMM, DOI 10.1186/s13638-016-0666-5
   Emara K, 2016, ARXIV
   Fabian P, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3882
   Fan N, 2018, AD HOC NETW
   Förster D, 2016, AD HOC NETW, V37, P122, DOI 10.1016/j.adhoc.2015.09.011
   Gerlach M, 2007, EIGHTH INTERNATIONAL SYMPOSIUM ON AUTONOMOUS DECENTRALIZED SYSTEMS, PROCEEDINGS, P295, DOI 10.1109/ISADS.2007.76
   Guerrero-Ibanez J., 2013, Next-Generation Wireless Technologies, P49
   Gurung S., 2013, International Journal of Security, Privacy and Trust Management (IJSPTM), P94
   Halabi T, 2019, IEEE ICC
   Hartenstein H, 2008, IEEE COMMUN MAG, V46, P164, DOI 10.1109/MCOM.2008.4539481
   Hasan MK, 2021, IEEE ACCESS, V9, P14446, DOI 10.1109/ACCESS.2021.3052368
   Hasrouny H, 2019, WIREL NETW, V25, P4639, DOI 10.1007/s11276-018-1756-6
   Hesham A, 2011, IFIP WIREL DAY
   Iqbal R, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719825820
   Islam S, 2020, WIRELESS PERS COMMUN, V114, P1133, DOI 10.1007/s11277-020-07412-0
   Islam S, 2017, WIRELESS PERS COMMUN, V95, P457, DOI 10.1007/s11277-016-3903-7
   Javed AR, 2021, IEEE T NETW SCI ENG, V8, P1456, DOI 10.1109/TNSE.2021.3059881
   Jayasinghe U, 2017, 2017 ITU KALEIDOSCOPE: CHALLENGES FOR A DATA-DRIVEN SOCIETY (ITU K)
   Junejo MH., 2021, PROCEDIA COMPUT SCI, V194, P45, DOI [10.1016/j.procs.2021.10.058, DOI 10.1016/J.PROCS.2021.10.058]
   Junejo MH, 2020, SCI PROGRAM 2020
   Kerrache CA, 2016, IEEE ACCESS, V4, DOI 10.1109/ACCESS.2016.2645452
   Khan U, 2015, PROCEDIA COMPUT SCI, V46, P965, DOI 10.1016/j.procs.2015.01.006
   Krajzewicz D., 2002, P 4 MIDDLE E S SIMUL, P183
   Kumari S, 2016, SECUR COMMUN NETW, V9, P4255, DOI 10.1002/sec.1602
   Li H, 2019, PEER PEER NETW APPL, V12, P1178, DOI 10.1007/s12083-019-00786-4
   Li H, 2017, IEEE INT C COMPUT, P63, DOI 10.1109/CSE-EUC.2017.197
   Li WF, 2020, AD HOC NETW, V98, DOI 10.1016/j.adhoc.2019.102033
   Li WJ, 2016, IEEE T INTELL TRANSP, V17, P960, DOI 10.1109/TITS.2015.2494017
   Liao D, 2018, J NETW COMPUT APPL, V110, P108, DOI 10.1016/j.jnca.2018.02.002
   Liu Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124305
   Liu ZQ, 2016, MOB INF SYST, V2016, DOI 10.1155/2016/7628231
   Lo NW, 2009, EURASIP J WIREL COMM, DOI 10.1155/2009/125348
   Lu RX, 2012, IEEE T VEH TECHNOL, V61, P86, DOI 10.1109/TVT.2011.2162864
   Lu ZJ, 2018, IEEE ACCESS, V6, DOI [10.1109/ACCESS.2018.2864189, 10.1109/LSP.2018.2810121]
   Mansour MB, 2018, INT J NETWORK SECURI, P10, DOI DOI 10.2139/SSRN.3290553
   Mármol FG, 2012, J NETW COMPUT APPL, V35, P934, DOI 10.1016/j.jnca.2011.03.028
   Memon I, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091068
   Memon I, 2021, WIRELESS PERS COMMUN, V116, P3309, DOI 10.1007/s11277-020-07854-6
   Memon I, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3795
   Memon I, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3704
   Memon I, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3437
   Memon I, 2017, WORLD WIDE WEB, V20, P639, DOI 10.1007/s11280-016-0403-3
   Memon I, 2015, WIRELESS PERS COMMUN, V85, P1167, DOI 10.1007/s11277-015-2833-0
   Minhas UF, 2011, IEEE T SYST MAN CY C, V41, P407, DOI 10.1109/TSMCC.2010.2084571
   Mishra B., 2011, Proceedings of the 2011 World Congress on Information and Communication Technologies (WICT), P880, DOI 10.1109/WICT.2011.6141364
   Mokhtar B, 2015, ALEX ENG J, V54, P1115, DOI 10.1016/j.aej.2015.07.011
   Mondal A., 2016, Health, P1
   Muniyandi RC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10175759
   Nafi N. S., 2012, 2012 International Conference on Computer and Communication Engineering (ICCCE), P738, DOI 10.1109/ICCCE.2012.6271315
   Nurelmadina N, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13010338
   Pan YY, 2013, J NETW COMPUT APPL, V36, P1599, DOI 10.1016/j.jnca.2013.02.003
   PATWARDHAN A., 2006, Mobile and Ubiquitous Systems: Networking Services, 2006 Third Annual International Conference on, P1, DOI 10.1109/MOBIQW.2006.361754
   Petit J, 2015, IEEE COMMUN SURV TUT, V17, P228, DOI 10.1109/COMST.2014.2345420
   Rai IA, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147720939372
   Ravi C, 2022, ACM T INTERNET TECHN, V22, DOI 10.1145/3412353
   Ravie CM, 2021, J ADV TRANSP, V2021
   Raya M, 2008, IEEE INFOCOM SER, P1912
   Salem AH, 2016, ARXIV
   Samara, 2017, ARXIV
   Sedjelmaci H, 2015, COMPUT ELECTR ENG, V43, P33, DOI 10.1016/j.compeleceng.2015.02.018
   Sengar JS, 2015, INT J GRID DISTRIB, V8, P301, DOI 10.14257/ijgdc.2015.8.4.29
   Shaikh RA., 2013, QUALITY RELIABILITY, DOI [10.1007/978-3-642-37949-9_70, DOI 10.1007/978-3-642-37949-9_70]
   Shaikh RA, 2014, SECUR COMMUN NETW, V7, P1652, DOI 10.1002/sec.862
   Sharma S, 2021, ARCH COMPUT METHOD E, V28, P2081, DOI 10.1007/s11831-020-09447-9
   Sheikh MS, 2019, WIREL COMMUN MOB COM, V2019, DOI 10.1155/2019/2423915
   Shrivastava S., 2019, Connected Vehicles, P117
   Soleymani SA, 2021, VEH COMMUN, V29, DOI 10.1016/j.vehcom.2021.100335
   Sommer C, 2019, EAI SPRINGER INNOVAT, P215, DOI 10.1007/978-3-030-12842-5_6
   Sumra IA., 2020, LGURJCSIT, V4, P59
   Sun A, 2021, MOB NETW APPL, V2021, P1
   Sun YP, 2015, PEER PEER NETW APPL, V8, P1108, DOI 10.1007/s12083-014-0269-z
   Tajeddine A., 2010, Proceedings of the 2010 IEEE 10th International Conference on Computer and Information Technology (CIT 2010), P832, DOI 10.1109/CIT.2010.157
   Tangade SS, 2013, 2013 4 INT C COMPUTI
   Wang C, 2021, IEEE T EMERG TOP COM, V9, P1386, DOI 10.1109/TETC.2020.2978866
   Wang J, 2016, INT J DISTRIB SENS N, DOI 10.1155/2016/6138251
   Wang SB, 2019, WIREL NETW, V25, P1099, DOI 10.1007/s11276-018-1681-8
   Yan XM, 2021, WIRELESS PERS COMMUN, V118, P489, DOI 10.1007/s11277-020-08027-1
   Yang NH, 2013, INT J FUTUR GENER CO, V6, P25
   Zhang J, 2011, INT CON ADV INFO NET, P105, DOI 10.1109/AINA.2011.86
   Zhao H., 2018, IJNS, V20, P157
NR 100
TC 2
Z9 2
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13395
EP 13426
DI 10.1007/s11042-023-16110-5
EA JUL 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001024891800001
DA 2024-07-18
ER

PT J
AU Kumar, MKP
   Kumaraswamy, R
AF Kumar, M. K. Prasanna
   Kumaraswamy, R.
TI A hybrid model for unsupervised single channel speech separation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Voice recognition platform; Single channel; Speech separation;
   Unsupervised; Speech segmentation; NMF; Masking
AB The performance of any voice recognition platform in real environment depends on how well the desired speech signal is separated from unwanted signals like background noise or background speakers. In this paper, we propose a three stage hybrid model to separate two speakers from single channel speech mixture under unsupervised condition. Proposed method combines three techniques namely speech segmentation, NMF (Nonnegative Matrix Factorization) and Masking. Speech segmentation groups the short speech frames belonging to individual speakers by identifying the speaker change over points. The segmentation block groups the speech frames belonging to individual speakers but lacks in continuity of the speech samples. Therefore a second stage is built using NMF. NMF algorithm performs better in separating the speech mixture when parts of the individual speech signals are known a priori. This requirement is satisfied by speech segmentation stage. NMF further separates the individual speech signals in the mixture by maintaining continuity of speech samples over time. To further improve the accuracy of separated speech signals, various masking methods like TFR (Time frequency Ratio), SM (Soft Mask) and HM (Hard Mask) are applied. The separation results are compared with other unsupervised algorithms. The proposed hybrid model produces promising results in unsupervised single channel speech separation. This model can be applied at the front end of any voice recognition platform to further improve the recognition efficiency.
C1 [Kumar, M. K. Prasanna] BMS Coll Engn, Dept Elect & Telecommun, Bangalore, India.
   [Kumaraswamy, R.] Siddaganga Inst Technol, Dept Elect & Commun, Tumakuru, India.
C3 BMS College of Engineering; Siddaganga Institute of Technology
RP Kumar, MKP (corresponding author), BMS Coll Engn, Dept Elect & Telecommun, Bangalore, India.
EM prasannamk.tce@bmsce.ac.in; hyrkswamy@gmail.com
CR Boldt Jesper B., 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P1849
   Du J, 2016, IEEE-ACM T AUDIO SPE, V24, P1424, DOI 10.1109/TASLP.2016.2558822
   Ellis D., 2006, MODEL BASED SCENE AN
   Fevotte C, 2005, 1706 IRISA
   Gao B, 2013, IEEE T CIRCUITS-I, V60, P662, DOI 10.1109/TCSI.2012.2215735
   Jang GJ, 2004, J MACH LEARN RES, V4, P1365, DOI 10.1162/jmlr.2003.4.7-8.1365
   Karhunen J, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P113
   Krishna PKM, 2017, IET SIGNAL PROCESS, V11, P579, DOI 10.1049/iet-spr.2016.0450
   Kumar MKP, 2015, INT J SPEECH TECHNOL, V18, P649, DOI 10.1007/s10772-015-9309-1
   Kumar MKP, 2021, INT J SPEECH TECHNOL, V24, P1101, DOI 10.1007/s10772-021-09875-3
   Kumar MKP, 2017, INT J SPEECH TECHNOL, V20, P109, DOI 10.1007/s10772-016-9392-y
   Kumar MKP, 2017, INT J SPEECH TECHNOL, V20, P1, DOI 10.1007/s10772-016-9381-1
   Kwang M, 2020, P INT C CONS EL LAS, P1
   Li X, 2019, INT CONF ACOUST SPEE, P6870, DOI 10.1109/ICASSP.2019.8683850
   Liu QJ, 2019, IEEE SIGNAL PROC LET, V26, P1872, DOI 10.1109/LSP.2019.2951894
   Kumar MK, 2017, INT J SPEECH TECHNOL, V20, P1037, DOI 10.1007/s10772-017-9468-3
   Schmidt MN, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2614
   Stark M, 2011, IEEE T AUDIO SPEECH, V19, P242, DOI 10.1109/TASL.2010.2047419
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881
   Tengtrairat N, 2013, IEEE T NEUR NET LEAR, V24, P1722, DOI 10.1109/TNNLS.2013.2258680
   Vincent E, 2006, IEEE T AUDIO SPEECH, V14, P1462, DOI 10.1109/TSA.2005.858005
   Virtanen T, 2007, IEEE T AUDIO SPEECH, V15, P1066, DOI 10.1109/TASL.2006.885253
   Wang DL, 2018, IEEE-ACM T AUDIO SPE, V26, P1702, DOI 10.1109/TASLP.2018.2842159
   Wang K, 2019, INT CONF ACOUST SPEE, P296, DOI 10.1109/ICASSP.2019.8683138
   Yegnanarayana B, 2009, IEEE T AUDIO SPEECH, V17, P1196, DOI 10.1109/TASL.2009.2016230
   Zhang XL, 2016, IEEE-ACM T AUDIO SPE, V24, P967, DOI 10.1109/TASLP.2016.2536478
   Zhu CS, 2019, 2019 15TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS 2019), P387, DOI 10.1109/CIS.2019.00090
NR 27
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13241
EP 13259
DI 10.1007/s11042-023-16108-z
EA JUL 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023897700011
DA 2024-07-18
ER

PT J
AU Dai, CG
   Lin, MX
AF Dai, Chenggang
   Lin, Mingxing
TI Adjustable enhancer for low-light image enhancement using
   multi-expressions fusion and convolutional kernel calibration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-light image enhancement; Multi-expressions fusion; Dynamic
   calibration on kernels; Adjustable brightness
ID ILLUMINATION; NETWORK; FRAMEWORK
AB Owing to constant convolutional kernels in trained network, conventional enhancer for low-light image can only generate enhanced image with an invariable level of brightness. To address this issue, we propose a novel enhancer based on multi-expressions fusion and kernel calibration, which can improve visibility, remove noise, and flexibly adjust the brightness of enhanced image. In this study, a strategy of fusing multiple expressions is incorporated into the enhancer to improve the performance in terms of representation learning. Subsequently, a kernel calibration network is designed to generate dynamic kernel calibration maps. With these dynamic calibration maps combining with static convolutional kernels, dynamic convolution and adjustable brightness are incapable of being achieved. Furthermore, a method of synthesizing training data is employed for generating simulated low-light images to remove noise while enhancing low-light image. Comprehensive experiments validate the exceptional performance of the proposed enhancer in improving the visual quality of low-light image and flexibly adjusting the brightness of enhanced image.
C1 [Dai, Chenggang] Qingdao Univ Technol, Sch Mech & Automot Engn, Qingdao 266520, Shandong, Peoples R China.
   [Lin, Mingxing] Shandong Univ, Sch Mech Engn, Jinan 250061, Shandong, Peoples R China.
C3 Qingdao University of Technology; Shandong University
RP Dai, CG (corresponding author), Qingdao Univ Technol, Sch Mech & Automot Engn, Qingdao 266520, Shandong, Peoples R China.
EM 901020210157@qut.edu.cn; mxlin@sdu.edu.cn
FU Natural Science Foundation of Shandong Province [ZR2020ME267]; Major
   Science and Technology Innovation Project of Shandong Province
   [2019JZZY020703]
FX AcknowledgementsThis work is supported in part by Natural Science
   Foundation of Shandong Province (ZR2020ME267) and in part by Major
   Science and Technology Innovation Project of Shandong Province
   (2019JZZY020703).
CR Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Celik T, 2014, IEEE T IMAGE PROCESS, V23, P5298, DOI 10.1109/TIP.2014.2364537
   Cui HS, 2022, ENG APPL ARTIF INTEL, V116, DOI 10.1016/j.engappai.2022.105411
   Dai CG, 2021, SIGNAL PROCESS, V189, DOI 10.1016/j.sigpro.2021.108280
   Dai CG, 2019, IEEE ACCESS, V7, P178685, DOI 10.1109/ACCESS.2019.2958078
   Dhara SK, 2022, IEEE T CIRC SYST VID, V32, P3438, DOI 10.1109/TCSVT.2021.3113559
   Fu XY, 2015, IEEE T IMAGE PROCESS, V24, P4965, DOI 10.1109/TIP.2015.2474701
   Guo MT, 2022, IEEE T PATTERN ANAL, V44, P6094, DOI 10.1109/TPAMI.2021.3087485
   Guo XJ, 2023, INT J COMPUT VISION, V131, P48, DOI 10.1007/s11263-022-01667-9
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   He L, 2023, MULTIMED TOOLS APPL, V82, P6071, DOI 10.1007/s11042-022-13598-1
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jeon JJ, 2022, SIGNAL PROCESS, V196, DOI 10.1016/j.sigpro.2022.108523
   Li CY, 2022, IEEE T PATTERN ANAL, V44, P9396, DOI 10.1109/TPAMI.2021.3126387
   Li JQ, 2021, IEEE T MULTIMEDIA, V23, P3153, DOI 10.1109/TMM.2020.3021243
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Liang JX, 2022, IEEE T CIRC SYST VID, V32, P7332, DOI 10.1109/TCSVT.2022.3181781
   Lim S, 2021, IEEE T MULTIMEDIA, V23, P4272, DOI 10.1109/TMM.2020.3039361
   Lin YH, 2022, IEEE T IMAGE PROCESS, V31, P4897, DOI 10.1109/TIP.2022.3189805
   Liu JY, 2021, INT J COMPUT VISION, V129, P1153, DOI 10.1007/s11263-020-01418-8
   Liu SX, 2022, MULTIMED TOOLS APPL, V81, P22087, DOI 10.1007/s11042-021-11505-8
   Liu XK, 2023, PATTERN RECOGN, V133, DOI 10.1016/j.patcog.2022.109039
   Lv FF, 2021, INT J COMPUT VISION, V129, P2175, DOI 10.1007/s11263-021-01466-8
   Ma L, 2022, IEEE T NEUR NET LEAR, V33, P5666, DOI 10.1109/TNNLS.2021.3071245
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P4364, DOI 10.1109/TIP.2019.2910412
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tian QC, 2018, SIGNAL PROCESS, V153, P210, DOI 10.1016/j.sigpro.2018.07.022
   Vazquez-Corral J, 2020, J REAL-TIME IMAGE PR, V17, P607, DOI 10.1007/s11554-018-0816-6
   Wang P, 2021, MULTIMED TOOLS APPL, V80, P17705, DOI 10.1007/s11042-021-10607-7
   Wang YF, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2922106
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei C, 2018, ARXIV
   Xu YD, 2021, INFORM SCIENCES, V548, P378, DOI 10.1016/j.ins.2020.09.066
   Yang WH, 2021, IEEE T IMAGE PROCESS, V30, P3461, DOI 10.1109/TIP.2021.3062184
   Yang WH, 2021, IEEE T IMAGE PROCESS, V30, P2072, DOI 10.1109/TIP.2021.3050850
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhai GT, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3457905
   Zhang Y, 2022, IEEE T IMAGE PROCESS, V31, P759, DOI 10.1109/TIP.2021.3135473
NR 40
TC 2
Z9 2
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14609
EP 14636
DI 10.1007/s11042-023-15851-7
EA JUL 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001020157200006
DA 2024-07-18
ER

PT J
AU Karsh, B
   Laskar, RH
   Karsh, RK
AF Karsh, Bhumika
   Laskar, R. H.
   Karsh, R. K.
TI mIV3Net: modified inception V3 network for hand gesture recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand gesture recognition (HGR); Inception V3; Sign language recognition;
   Deep learning; Transfer learning; Human-computer interaction (HCI)
ID SYSTEM
AB Hand gesture plays an important role in communication among the hearing and speech disorders people. Hand gesture recognition (HGR) is the backbone of human-computer interaction (HCI). Most of the reported hand gesture recognition techniques suffer due to the complex backgrounds. As per the literature, most of the existing HGR methods have only selected a few inter-class similar gestures for recognition performance. This paper proposes a two-phase deep learning-based HGR system to mitigate the complex background issue and consider all gesture classes. In the first phase, inception V3 architecture is improved and named mIV3Net: modified inception V3 network to reduce the computational resource requirement. In the second phase, mIV3Net has been fine-tuned to offer more attention to prominent features. As a result, better abstract knowledge has been used for gesture recognition. Hence, the proposed algorithm has more discrimination characteristics. The efficacy of the proposed two-phase-based HGR system is validated and generalized through experimentation using five publicly available standard datasets: MUGD, ISL, ArSL, NUS-I, and NUS-II. The accuracy values of the proposed system on five datasets in the above order are 97.14%, 99.3%, 97.4%, 99%, and 99.8%, which indicates significant improvement, i.e., 12.58%, 2.54%, 2.73%, 0.56%, and 2.02%, respectively, than the state-of-the-art HGR systems.
C1 [Karsh, Bhumika; Laskar, R. H.; Karsh, R. K.] NIT Silchar, Dept ECE, Speech & Image Proc Lab, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Karsh, B (corresponding author), NIT Silchar, Dept ECE, Speech & Image Proc Lab, Silchar 788010, Assam, India.
EM bhumika21_rs@ece.nits.ac.in; rhlaskar@ece.nits.ac.in; ram@ece.nits.ac.in
OI Karsh, Ram/0000-0002-2341-341X; Karsh, Bhumika/0000-0001-7745-6928
CR Agarwal S., 2020, 5 INT C NEXT GEN COM
   Aly S, 2020, IEEE ACCESS, V8, P83199, DOI 10.1109/ACCESS.2020.2990699
   [Anonymous], 2011, Res Lett Inf Math Sci
   Badi H, 2016, INT J DATA SCI ANAL, V1, P77, DOI DOI 10.1007/S41060-016-0008-Z
   BansalnAff SR, 2022, ARAB J SCI ENG, V47, P10365, DOI 10.1007/s13369-021-06456-z
   Bhaumik G, 2023, MULTIMED TOOLS APPL, DOI [10.1007/s11042-023-16988-1, 10.1007/s11042-021-11623-3]
   Bose SR, 2021, J INTELL FUZZY SYST, V41, P6983, DOI 10.3233/JIFS-210875
   Can C, 2021, BIOMED PHYS ENG EXPR, V7, DOI 10.1088/2057-1976/ac0d91
   Chevtchenko SF, 2018, APPL SOFT COMPUT, V73, P748, DOI 10.1016/j.asoc.2018.09.010
   Dadashzadeh A, 2019, IET COMPUT VIS, V13, P700, DOI 10.1049/iet-cvi.2018.5796
   Gupta Barun, 2016, 2016 41st International Conference on Infrared, Millimeter and Terahertz Waves (IRMMW-THz), DOI 10.1109/IRMMW-THz.2016.7758759
   Hasan H, 2012, INT CONF ADV COMPUT, P55, DOI 10.1109/ACSAT.2012.37
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hsien-I Lin, 2014, 2014 IEEE International Conference on Automation Science and Engineering (CASE), P1038, DOI 10.1109/CoASE.2014.6899454
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huesser C, 2021, LECT NOTES COMPUT SC, V12934, P151, DOI 10.1007/978-3-030-85613-7_11
   Jadooki S, 2017, NEURAL COMPUT APPL, V28, P3285, DOI 10.1007/s00521-016-2244-5
   Jaramillo-Yánez A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092467
   Joshi G, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102834
   Kamruzzaman MM, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/3685614
   Kowdiki M, 2022, MULTIMED TOOLS APPL, P1
   Latif G, 2019, DATA BRIEF, V23, DOI 10.1016/j.dib.2019.103777
   Li GF, 2019, MULTIMED TOOLS APPL, V78, P29765, DOI 10.1007/s11042-018-6293-x
   Li SZ, 2015, NEUROCOMPUTING, V151, P565, DOI 10.1016/j.neucom.2014.06.086
   Li Y, 2018, INFORM SCIENCES, V441, P66, DOI 10.1016/j.ins.2018.02.024
   Liu PD, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/3258018
   Mujahid A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11094164
   Nagarajan S., 2013, Int. J. Comput. Appl, V82, DOI [10.5120/14106-2145, DOI 10.5120/14106-2145]
   Neethu PS, 2020, SOFT COMPUT, V24, P15239, DOI 10.1007/s00500-020-04860-5
   Oudah M, 2020, J IMAGING, V6, DOI 10.3390/jimaging6080073
   Oyedotun OK, 2017, NEURAL COMPUT APPL, V28, P3941, DOI 10.1007/s00521-016-2294-8
   Ozcan T, 2019, NEURAL COMPUT APPL, V31, P8955, DOI 10.1007/s00521-019-04427-y
   Pabendon E, 2017, INT C INSTR COMMUN, P261, DOI 10.1109/ICICI-BME.2017.8537742
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Pinto RF, 2019, J ELECTR COMPUT ENG, V2019, DOI 10.1155/2019/4167890
   Pisharady PK, 2013, INT J COMPUT VISION, V101, P403, DOI 10.1007/s11263-012-0560-5
   Ranga V, 2018, J ENG SCI TECHNOL, V13, P2655
   Rastgoo R, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.113794
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shanthakumar VA, 2020, MULTIMED TOOLS APPL, V79, P17707, DOI 10.1007/s11042-019-08520-1
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan YS, 2021, EXPERT SYST APPL, V175, DOI 10.1016/j.eswa.2021.114797
   Tharwat A, 2015, ADV INTELL SYST, V334, P359, DOI 10.1007/978-3-319-13572-4_30
   Tsai TH, 2020, MULTIMED TOOLS APPL, V79, P5989, DOI 10.1007/s11042-019-08274-w
   Von Hardenberg Christian, 2001, Proceedings of the 2001 workshop on Perceptive user interfaces, PUI'01, P1, DOI DOI 10.1145/971478.971513
   Wadhawan A, 2020, NEURAL COMPUT APPL, V32, P7957, DOI 10.1007/s00521-019-04691-y
   Wang C, 2015, IEEE T MULTIMEDIA, V17, P29, DOI 10.1109/TMM.2014.2374357
   XiaoLin Li, 2021, 2021 International Symposium on Computer Technology and Information Science (ISCTIS), P116, DOI 10.1109/ISCTIS51085.2021.00031
   Xie B, 2018, J ENG-JOE, P1515, DOI 10.1049/joe.2018.8327
   Yasen M, 2019, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.218
   Zakariah M, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/4567989
   Zhang T, 2020, INT J FUZZY SYST, V22, P1330, DOI 10.1007/s40815-020-00825-w
   Zhang WJ, 2021, IEEE-CAA J AUTOMATIC, V8, P110, DOI 10.1109/JAS.2020.1003465
   Zhao JB, 2020, VIRTUAL REAL-LONDON, V24, P515, DOI 10.1007/s10055-019-00416-7
   Zhou WA, 2022, DISPLAYS, V74, DOI 10.1016/j.displa.2022.102226
NR 57
TC 5
Z9 5
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10587
EP 10613
DI 10.1007/s11042-023-15865-1
EA JUN 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001014722500012
DA 2024-07-18
ER

PT J
AU Martins, T
   Carvalho, V
   Soares, F
   Leao, C
AF Martins, Tiago
   Carvalho, Vitor
   Soares, Filomena
   Leao, Celina
TI Physioland: a motivational complement of physical therapy for patients
   with neurological diseases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobility problems; Neurological diseases; Neuronal plasticity; Physical
   therapy; Serious games; Physioland; Patient motivation
ID SERIOUS GAMES; REHABILITATION
AB The number of patients with mobility constraints is increasing as a result of neurological diseases. From the substantiation of the lost functions recoveries, it was possible to determine that the nervous system is able to reorganize itself expressing its property called neuroplasticity. Physical therapy is the well-known way to encourage and promote this ability. However, repetitive traditional physical therapy exercises may become boring and patients eventually abandon their physiotherapeutic programs. The development of new environments that motivate patients to continue with their treatments may be a suitable alternative or complementary tool. Serious games seems to be the ideal tool to provide them. Thus, the purpose of this paper is to present Physioland, a serious game already developed which can be a motivational complement for the physical therapy of patients with neurological diseases. Physioland is a non-invasive system that uses Image Processing Techniques and Artificial Intelligence to monitor patients and adapts some exercises of traditional physical therapy to electronic game situations. To determine whether Physioland would be motivating and challenging enough to increase a patient's desire to perform the exercises and continue/complete the rehabilitation process the game was tested in a clinical environment using two samples: one with twelve health professionals in the area of physiotherapy and the other with eleven patients with neurological diseases. The research team carried out a questionnaire-based survey. This questionnaire is an adaptation of another one already validated in the literature-the Technology Acceptance Model (TAM). For the analysis of the data obtained with the Likert scale, percentages were calculated. The answers to the open questions were subject to a content analysis. The results showed that the developed game, Physioland, proved to be highly motivating for patients at the physiotherapy clinic where it was tested. If the results are similar in other clinics, Physioland, can be used as a good and effective complement to traditional physical therapy for patients with neurological diseases.
C1 [Martins, Tiago; Carvalho, Vitor; Soares, Filomena; Leao, Celina] Univ Minho, Sch Engn, Algoritmi Res Ctr LASI, Guimaraes, Portugal.
   [Martins, Tiago; Carvalho, Vitor] IPCA, Sch Technol, 2Ai, Barcelos, Portugal.
   [Martins, Tiago] Catholic Univ Portugal, Braga, Portugal.
C3 Universidade do Minho; Instituto Politecnico do Cavado e do Ave - IPCA;
   Universidade Catolica Portuguesa
RP Carvalho, V (corresponding author), Univ Minho, Sch Engn, Algoritmi Res Ctr LASI, Guimaraes, Portugal.; Carvalho, V (corresponding author), IPCA, Sch Technol, 2Ai, Barcelos, Portugal.
EM tiagomartins@dsi.uminho.pt; vcarvalho@ipca.pt; fsoares@dei.uminho.pt;
   cpl@dps.uminho.pt
RI Leão, Celina P/A-1673-2012; Martins, Tiago/HJY-7033-2023; Carvalho,
   Vítor/H-4740-2019; Soares, Filomena/H-7936-2015
OI Leão, Celina P/0000-0003-3725-5771; Martins, Tiago/0000-0003-2638-237X;
   Carvalho, Vítor/0000-0003-4658-5844; Soares,
   Filomena/0000-0002-4438-6713
FU national funds through FCT - Fundacao para a Ciencia e Tecnologia
   [UID/CEC/00319/2019, UIDB/00319/2020, UIDB/05549/2020, UIDP/05549/2020,
   UIDP/04077/2020, UIDB/04077/2020]; Portuguese Foundation (FCT)
   [SFRH/BD/74852/2010]
FX This work has been supported by national funds through FCT - Fundacao
   para a Ciencia e Tecnologia within the Projects Scope:
   UID/CEC/00319/2019, UIDB/00319/2020, UIDB/05549/2020, UIDP/05549/2020,
   UIDP/04077/2020,& nbsp;and UIDB/04077/2020. The authors are also
   grateful to the Portuguese Foundation (FCT) for funding through
   SFRH/BD/74852/2010 Ph.D. scholarship.
CR Amiri Z, 2022, ENTERTAIN COMPUT, V42, DOI 10.1016/j.entcom.2022.100487
   Araujo E.M., 2015, O desenho de videojogos na motivacao de pacientes com necessidades de reabilitacao fisioterapeutica
   Ashwini K., 2021, Handbook of Decision Support Systems for Neurological Disorders, P187, DOI [10.1016/B978-0-12-822271-3.00006-2, DOI 10.1016/B978-0-12-822271-3.00006-2]
   Avola D, 2019, J BIOMED INFORM, V89, P81, DOI 10.1016/j.jbi.2018.11.012
   Baqai A, 2019, WIRELESS PERS COMMUN, V106, P1719, DOI 10.1007/s11277-018-5382-5
   Burke JW, 2009, VISUAL COMPUT, V25, P1085, DOI 10.1007/s00371-009-0387-4
   Cuesta-Gómez A, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00718-x
   Cyrino G, 2020, XR EXPERIENCE S REAL, V22, P67, DOI [10.5753/svr_estendido.2020.12960, DOI 10.5753/SVR_ESTENDIDO.2020.12960]
   Faria C, 2015, DISABIL REHABIL-ASSI, V10, P67, DOI 10.3109/17483107.2013.839749
   Feigin VL, 2022, NEUROEPIDEMIOLOGY, V56, P2, DOI 10.1159/000521586
   Ferreira Bruno, 2019, 2019 5th Experiment@ International Conference (exp.at'19). Proceedings, P383, DOI 10.1109/EXPAT.2019.8876493
   Ghassemi M, 2019, IEEE T NEUR SYS REH, V27, P283, DOI 10.1109/TNSRE.2019.2894102
   Grunert R, 2019, INT J NEUROSCI, V129, P770, DOI 10.1080/00207454.2019.1567510
   Kempitiya T, 2022, P 15 INT C HUM SYST, P1, DOI [10.1109/HSI55341.2022.9869454, DOI 10.1109/HSI55341.2022.9869454]
   Keshner Emily A, 2004, J Neuroeng Rehabil, V1, P8, DOI 10.1186/1743-0003-1-8
   Larsen DS, 2012, J NEUROL PHYS THER, V36, P110, DOI 10.1097/NPT.0b013e3182567076
   Lohse K, 2013, J NEUROL PHYS THER, V37, P166, DOI 10.1097/NPT.0000000000000017
   Maclean N, 2000, SOC SCI MED, V50, P495
   Martins T., 2013, INT J BIOMEDICAL CLI, V2, P37, DOI [10.4018/ijbce.2013070104, DOI 10.4018/IJBCE.2013070104]
   Martins T., 2016, CONTROLO16 12 PORTUG, DOI DOI 10.1007/978-3-319-43671-5_37
   Martins T, 2020, ENTERTAIN COMPUT, V34, DOI 10.1016/j.entcom.2020.100356
   Martins T, 2013, 2013 IEEE 2ND INTERNATIONAL CONFERENCE ON SERIOUS GAMES AND APPLICATIONS FOR HEALTH (SEGAH)
   Martins T, 2015, PROCEDIA COMPUT SCI, V64, P1115, DOI 10.1016/j.procs.2015.08.571
   Mubin O, 2022, DISABIL REHABIL-ASSI, V17, P159, DOI 10.1080/17483107.2020.1768309
   Noveletto F, 2020, IEEE T NEUR SYS REH, V28, P1481, DOI 10.1109/TNSRE.2020.2988362
   Postolache O, 2021, IEEE J SEL AREA COMM, V39, P562, DOI 10.1109/JSAC.2020.3020600
   Price L, 2016, Translational Research in Traumatic Brain Injury, DOI DOI 10.1201/B18959
   Proença JP, 2018, DISABIL REHABIL-ASSI, V13, P95, DOI 10.1080/17483107.2017.1290702
   Rozevink SG, 2021, J NEUROENG REHABIL, V18, DOI 10.1186/s12984-021-00841-3
   Shahmoradi L, 2020, J EDUC HEALTH PROMOT, V9, DOI 10.4103/jehp.jehp_736_19
   Shieh CC, 2000, PHARMACOL REV, V52, P557
   Stein D.G., 1995, BRAIN REPAIR
   Torner-Ribe J, 2021, OMNIASCIENCE, V2, P159
   Turolla A, 2018, NEURAL PLAST, V2018, DOI 10.1155/2018/6565418
   Xu YF, 2021, JMIR SERIOUS GAMES, V9, DOI 10.2196/20916
NR 35
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 12035
EP 12057
DI 10.1007/s11042-023-16051-z
EA JUN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019116600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Ali, A
   Sarkar, R
   Das, DK
AF Ali, Asfak
   Sarkar, Ram
   Das, Debesh Kumar
TI IRUVD: a new still-image based dataset for automatic vehicle detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicle detection; Vehicle classification; Deep learning; Traffic
   management; Dataset
AB One of the difficult tasks in the field of computer vision is the classification and detection of vehicles. Researchers from all over the world are working to create autonomous vehicle detection (AVD) systems due to their numerous practical applications, including highway management and surveillance systems. Deep learning techniques, which require a lot of data for proper model training, are the current AVD trend. However, a number of vehicles are discovered in India, the second-largest nation in terms of population, that are not included in the vehicle detection datasets that are currently in use. Furthermore, India's over crowding makes traffic management difficult and unusual. In this research, we present a dataset for still-image-based vehicle detection that includes one class of pedestrians and 13 different types of vehicles that are seen on Indian urban and rural roads. Initially, we provide baseline results using some state-of-the-art deep learning models on this dataset. To improve the accuracy further, we present an ensemble-based object detection and classification model. The dataset consists of 4K images and 14.3K bounding boxes of various vehicles; that is researchers are provided with appropriately annotated rectangular boxes for use with these vehicles in the future. A 16-megapixel Sony IMX519 high-resolution camera was used to take all images while travelling throughout West Bengal, an Indian state on the eastern side. Dataset can be found at:https://github.com/IRUVD/IRUVD.git.
C1 [Ali, Asfak] Dept Elect & Telecommun Engn, 188 Raja SC Mallick Rd, Kolkata 700032, W Bengal, India.
   [Sarkar, Ram; Das, Debesh Kumar] Dept Comp Sci Engn, 188 Raja SC Mallick Rd, Kolkata 700032, W Bengal, India.
RP Ali, A (corresponding author), Dept Elect & Telecommun Engn, 188 Raja SC Mallick Rd, Kolkata 700032, W Bengal, India.
EM asfakali.etce@gmail.com; ramjucse@gmail.com; debeshd@hotmail.com
OI Ali, Asfak/0000-0002-4034-1956
FU DST (ICPS) [CPS-Individual/2018/403(G)]
FX A part of this work is funded by DST (ICPS) CPS-Individual/2018/403(G).
CR [Anonymous], 2021, WORLD BANK REPORT
   [Anonymous], 2018, UD SELF DRIV CAR
   Bhat A, 2023, PROCEEDINGS OF THE 24TH ACM/IFIP INTERNATIONAL MIDDLEWARE CONFERENCE, MIDDLEWARE 2023, P1, DOI [10.1145/3590140.3592848, 10.30420/566091117]
   Bileschi SM, 2006, CBCI STREETSCENES
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Bodla N., 2017, ARXIV
   Cordts M, 2016, ARXIV
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Dong Z, 2015, IEEE T INTELL TRANSP, V16, P2247, DOI 10.1109/TITS.2015.2402438
   Du X, 2019, ARXIV
   Ershad S F, 2013, DEV FEATURE REPRESEN
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Ge Z., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.08430
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Jian MW, 2019, APPL SOFT COMPUT, V80, P425, DOI 10.1016/j.asoc.2019.04.025
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Jocher G. J., 2021, Ultralytics/Yolov5: V6. 0-YOLOv5nNanomodels, Roboflow Integration, TensorFlow Export, OpenCV DNN Support
   Khosravi H, 2020, IRVD LARGE SCALE DAT
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Le QV, 2019, ARXIV
   Li C., 2022, ARXIV
   Lin T., 2016, arXiv
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S, 2019, ARXIV
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Maity S, 2023, APPL BIOCHEM BIOTECH, V195, P4832, DOI 10.1007/s12010-022-04288-7
   Munder S, 2006, IEEE T PATTERN ANAL, V28, P1863, DOI 10.1109/TPAMI.2006.217
   Neuhold G, 2017, IEEE I CONF COMP VIS, P5000, DOI 10.1109/ICCV.2017.534
   Peng Y, 2012, IEEE INT CONF MULTI, P384, DOI 10.1109/ICMEW.2012.73
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Sai Srinath Namburi Gnvv Satya, 2020, Procedia Computer Science, V171, P207, DOI 10.1016/j.procs.2020.04.022
   Sener E, 2021, J POLYTECHNIC
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan M., 2019, arXiv
   Tzutalin, 2015, LAB GIT COD
   Varma G, 2018, ARXIV
   Wang C., 2020, ARXIV
   Wang C, 2019, ARXIV
   Wang Chen, 2021, arXiv
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wojek C, 2009, PROC CVPR IEEE, P794, DOI 10.1109/CVPRW.2009.5206638
   Yu F., 2018, ARXIV
   Zhang LB, 2020, IEEE J-STARS, V13, P2778, DOI 10.1109/JSTARS.2020.2995703
   Zhang SS, 2017, PROC CVPR IEEE, P4457, DOI 10.1109/CVPR.2017.474
   Zhao Q., 2018, Annals of Statistics
   Zhou B, 2016, ARXIV
NR 47
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6755
EP 6781
DI 10.1007/s11042-023-15365-2
EA JUN 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012324600002
DA 2024-07-18
ER

PT J
AU Cardoso, LFD
   Kimura, BYL
   Zorzal, ER
AF Cardoso, Luis Fernando de Souza
   Kimura, Bruno Yuji Lino
   Zorzal, Ezequiel Roberto
TI Towards augmented and mixed reality on future mobile networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Mixed reality; Mobile extended reality; 5G; 6G
ID WEB AR; 5G; EDGE; ARCHITECTURE; CHALLENGES; INTERNET; SYSTEM; RADIO;
   FUNDAMENTALS; TECHNOLOGIES
AB Augmented and Mixed Reality (AR/MR) technologies enhance the human perception of the world by combining virtual and real environments. With the increase of mobile devices and the advent of 5G, this technology has the potential to become part of people's life. This article aims to evaluate the impact of 5G and beyond mobile networks in the future of AR/MR. To attend to this objective, we surveyed four digital libraries to identify articles and reviews concerning AR/MR use based on mobile networks. The results describe the state-of-the-art of mobile AR/MR applications and the benefits and challenges of the technology. Finally, after the review, we propose a roadmap concerning AR/MR hardware and software development to run applications supported by future mobile networks.
C1 [Cardoso, Luis Fernando de Souza] Tech Univ Ilmenau, Ilmenau, Germany.
   [Cardoso, Luis Fernando de Souza; Kimura, Bruno Yuji Lino; Zorzal, Ezequiel Roberto] Univ Fed Sao Paulo, Sao Jose Dos Campos, Brazil.
   [Cardoso, Luis Fernando de Souza] Univ Virtual Estado Sao Paulo, Sao Jose Dos Campos, Brazil.
   [Zorzal, Ezequiel Roberto] INESC ID Lisboa, Lisbon, Portugal.
C3 Technische Universitat Ilmenau; Universidade Federal de Sao Paulo
   (UNIFESP); Universidade de Lisboa; INESC-ID
RP Cardoso, LFD (corresponding author), Tech Univ Ilmenau, Ilmenau, Germany.; Cardoso, LFD (corresponding author), Univ Fed Sao Paulo, Sao Jose Dos Campos, Brazil.; Cardoso, LFD (corresponding author), Univ Virtual Estado Sao Paulo, Sao Jose Dos Campos, Brazil.
EM luis.cardoso@tu-ilmenau.de; bruno.kimura@unifesp.br; ezorzal@unifesp.br
RI KIMURA, BRUNO Y L/U-8620-2019
OI KIMURA, BRUNO Y L/0000-0002-2174-2762; de Souza Cardoso, Luis
   Fernando/0000-0003-4537-5183; ZORZAL, EZEQUIEL/0000-0002-0938-7374
FU Projekt DEAL; Conselho Nacional de Desenvolvimento Cientifico e
   Tecnologico (CNPq) [423521/2021-7]; Fundacao para a Ciencia e a
   Tecnologia (FCT) [UIDB/50021/2020]; Sao Paulo Research Foundation
   (FAPESP) [2022/14503-3]
FX Open Access funding enabled and organized by Projekt DEAL. The last
   author would like to thank the Conselho Nacional de Desenvolvimento
   Cientifico e Tecnologico (CNPq) for partially supporting this research
   with reference 423521/2021-7 and the Fundacao para a Ciencia e a
   Tecnologia (FCT) with reference UIDB/50021/2020. The second author would
   like to thank the Sao Paulo Research Foundation (FAPESP), grant
   #2022/14503-3.
CR Abd El-Atty SM, 2013, 2013 6TH JOINT IFIP WIRELESS AND MOBILE NETWORKING CONFERENCE (WMNC 2013)
   Szczurek KA, 2022, IEEE ACCESS, V10, P87182, DOI 10.1109/ACCESS.2022.3198984
   Ahmad H, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11167351
   Akyildiz Ian F., 2009, Ad Hoc Networks, V7, P810, DOI 10.1016/j.adhoc.2009.01.001
   Akyildiz I. F., 2022, ITU J. Future Evolving Technol., V3, P273
   Alchalabi Alaa Eddin, 2021, IEEE Transactions on Artificial Intelligence, V2, P519, DOI 10.1109/TAI.2021.3105087
   Aloqaily M, 2022, IEEE CONSUM ELECTR M, DOI [10.1109/MCE.2022.Doi.https://www.ieee.org/publications/rights/index.html, DOI 10.1109/MCE.2022.DOI.HTTPS://WWW.IEEE.ORG/PUBLICATIONS/RIGHTS/INDEX.HTML]
   Alraih S, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030762
   Alyousify A.L., 2022, Virtual Reality & Intelligent Hardware, V4, P263
   Antevski K, 2021, IEEE ACCESS, V9, P131420, DOI 10.1109/ACCESS.2021.3114593
   Arunglabi R., 2022, INT J COMMUNICATION, V14, P99
   Atherton S, 2013, J VIS COMMUN MED, V36, P6, DOI 10.3109/17453054.2013.790794
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Baashar Yahia, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20053940
   Bansal G, 2022, IEEE ACCESS, V10, P119914, DOI 10.1109/ACCESS.2022.3219845
   Baranyi P, 2021, ACTA POLYTECH HUNG, V18, P225
   Batalla JM, 2020, IEEE ACCESS, V8, P118534, DOI 10.1109/ACCESS.2020.3005641
   Bhattacharya A, 2021, SIGSENSE MOBILE CROW, DOI DOI 10.1007/S11277-021-09267-5, Patent No. 0123456789
   Billinghurst M, 2002, COMMUN ACM, V45, P64, DOI 10.1145/514236.514265
   Buchholz K, 2022, 5G TECHNOLOGY HAS BE
   Budgen D., 2006, P 28 INT C SOFTW ENG, P1051, DOI DOI 10.1145/1134285.1134500
   Calandra D, 2024, DIGIT COMMUN NETW, V10, P315, DOI 10.1016/j.dcan.2022.10.007
   Chakrabarti K, 2021, COMPUT ELECTR ENG, V95, DOI 10.1016/j.compeleceng.2021.107381
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Checko A, 2015, IEEE COMMUN SURV TUT, V17, P405, DOI 10.1109/COMST.2014.2355255
   Chen SY, 2022, IEEE T VIS COMPUT GR, V28, P2157, DOI 10.1109/TVCG.2022.3150522
   Cheng Y, 2020, COMPUT COMMUN, V158, P24, DOI 10.1016/j.comcom.2020.04.054
   Chettri L, 2020, IEEE INTERNET THINGS, V7, P16, DOI 10.1109/JIOT.2019.2948888
   Chmielewski M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9214577
   Ciccone BA, 2023, ERGON DES, V31, P24, DOI 10.1177/10648046211002578
   Colman-Meixner C, 2019, IEEE T BROADCAST, V65, P392, DOI 10.1109/TBC.2019.2901387
   Comsa I., 2018, 2018 10 INT C QUALIT, P1, DOI [10.1109/QoMEX.2018.8463409, DOI 10.1109/QOMEX.2018.8463409]
   Costanza E, 2009, LECT NOTES COMPUT SC, V5440, P47, DOI 10.1007/978-3-642-00437-7_3
   CoWomen, 2019, 3 WOM SITT AR TABL U
   Dananjayan S, 2021, IRISH J MED SCI, V190, P497, DOI 10.1007/s11845-020-02329-w
   Dang TN, 2021, IEEE INTERNET THINGS, V8, P17382, DOI 10.1109/JIOT.2021.3080709
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Cardoso LFD, 2020, COMPUT IND ENG, V148, DOI 10.1016/j.cie.2020.106712
   Cardoso LFD, 2020, COMPUT IND ENG, V139, DOI 10.1016/j.cie.2019.106159
   Cardoso LFD, 2018, SYMP VIRTUAL AUGMENT, P143, DOI 10.1109/SVR.2018.00030
   Dolezal J, 2019, ADV ELECTR ELECTRON, V17, P413, DOI 10.15598/aeee.v17i4.2695
   Duong TQ, 2022, IEEE OPEN J COMM SOC, V3, P1347, DOI 10.1109/OJCOMS.2022.3195219
   Elawady Mohamed, 2020, Internet of ThingsApplications and Future. Proceedings of ITAF 2019. Lecture Notes in Networks and Systems (LNNS 114), P125, DOI 10.1007/978-981-15-3075-3_9
   Fizza M, 2016, P IOARP INT C COMM N, P18
   Fourati H, 2021, INT J MACH LEARN CYB, V12, P385, DOI 10.1007/s13042-020-01178-4
   Fraga-Lamas P, 2018, IEEE ACCESS, V6, P13358, DOI 10.1109/ACCESS.2018.2808326
   French AM, 2020, COMMUN ASSOC INF SYS, V46, P603, DOI 10.17705/1CAIS.04625
   Garcia-Aviles G, 2020, COMPUT COMMUN, V150, P1, DOI 10.1016/j.comcom.2019.11.003
   Morín DG, 2022, IEEE COMMUN MAG, V60, P46, DOI 10.1109/MCOM.001.2100225
   Gramaglia M, 2018, PROCEEDINGS OF THE 12TH INTERNATIONAL WORKSHOP ON WIRELESS NETWORK TESTBEDS, EXPERIMENTAL EVALUATION & CHARACTERIZATION (WINTECH'18), P11, DOI 10.1145/3267204.3267216
   Gupta A, 2015, IEEE ACCESS, V3, P1206, DOI 10.1109/ACCESS.2015.2461602
   Gupta R, 2021, COMPUT STAND INTER, V77, DOI 10.1016/j.csi.2021.103521
   Gupta R, 2019, INT J COMMUN SYST, V32, DOI 10.1002/dac.3981
   Haibeh LA, 2022, IEEE ACCESS, V10, P27591, DOI 10.1109/ACCESS.2022.3152787
   Hamza R., 2022, VIRT REAL INTELL HAR, V4, P210, DOI DOI 10.1016/J.VRIH.2022.01.007
   Han B, 2023, IEEE NETWORK, V37, P124, DOI 10.1109/MNET.126.2200385
   Hernandes E., 2012, CLEI ELECT J, V15, P3, DOI DOI 10.19153/CLEIEJ.15.1.2
   Hoeschele T, 2021, TELECOMMUN POLICY, V45, DOI 10.1016/j.telpol.2020.102091
   Hong XM, 2014, IEEE COMMUN MAG, V52, P46, DOI 10.1109/MCOM.2014.6852082
   Huang ZH, 2022, FUTURE INTERNET, V14, DOI 10.3390/fi14060166
   Hub i4.0, 2020, REAL AUM CONSTR CIV
   Iradier E, 2022, IEEE T BROADCAST, V68, P143, DOI 10.1109/TBC.2021.3128049
   Irlitti A, 2019, IEEE T VIS COMPUT GR, V25, P3178, DOI 10.1109/TVCG.2019.2932173
   Ito K, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11156802
   Jang SB, 2017, MULTIMED TOOLS APPL, V76, P16893, DOI 10.1007/s11042-016-3627-4
   Jedari B, 2021, IEEE COMMUN SURV TUT, V23, P431, DOI 10.1109/COMST.2020.3035427
   Jin AH, 2022, MOBILE NETW APPL, V27, P900, DOI 10.1007/s11036-021-01814-5
   Joo HJ, 2021, J SUPERCOMPUT, V77, P10791, DOI 10.1007/s11227-021-03700-z
   Jumani MA, 2022, DETAILED OVERVIEW 6G, DOI [10.54614/electrica.2022.21069, DOI 10.54614/ELECTRICA.2022.21069]
   Jun SH, 2017, ICEC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON ELECTRONIC COMMERCE, DOI 10.1145/3154943.3154947
   Jun Zhuang, 2019, Advances in Human Factors in Wearable Technologies and Game Design. Proceedings of the AHFE 2018 International Conferences on Human Factors and Wearable Technologies, and Human Factors in Game Design and Virtual Environments. Advances in Intelligent Systems and Computing (AISC 795), P98, DOI 10.1007/978-3-319-94619-1_10
   Kanter T., 2016, International Journal of Multimedia and Ubiquitous Engineering, V11, P43
   Khan D, 2015, COMPUT STAND INTER, V41, P56, DOI 10.1016/j.csi.2015.02.006
   Khan LU, 2022, IEEE COMMUN MAG, V60, P74, DOI 10.1109/MCOM.001.21143
   Khan MA, 2022, IEEE ACCESS, V10, P120514, DOI 10.1109/ACCESS.2022.3220694
   Kim J, 2022, J IND INTEGR MANAG, V07, P535, DOI 10.1142/S2424862222500038
   Klein George, 2007, P1
   Kowalczuk P, 2021, J BUS RES, V124, P357, DOI 10.1016/j.jbusres.2020.10.050
   LaPES, 2018, START
   Li B, 2021, PHYS COMMUN-AMST, V49, DOI 10.1016/j.phycom.2021.101446
   Li CL, 2021, FUTURE GENER COMP SY, V123, P48, DOI 10.1016/j.future.2021.04.012
   Li JPO, 2021, PROG RETIN EYE RES, V82, DOI 10.1016/j.preteyeres.2020.100900
   Li JN, 2020, IEEE INTERNET THINGS, V7, P5861, DOI 10.1109/JIOT.2019.2953988
   Li YN, 2021, J MED INTERNET RES, V23, DOI 10.2196/23635
   Li Y, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/4005210
   Liang B, 2022, J NETW COMPUT APPL, V199, DOI 10.1016/j.jnca.2021.103308
   Liao SY, 2021, IEEE INTERNET THINGS, V8, P5172, DOI 10.1109/JIOT.2020.3030718
   Lima JP, 2017, EXPERT SYST APPL, V82, P100, DOI 10.1016/j.eswa.2017.03.060
   Liu J, 2022, DIGIT COMMUN NETW
   Liu JH, 2019, IEEE ACCESS, V7, P11222, DOI 10.1109/ACCESS.2019.2891113
   Liu SJ, 2018, PROCEDIA COMPUT SCI, V141, P151, DOI 10.1016/j.procs.2018.10.161
   Liu T, 2020, INT J MED ROBOT COMP, V16, DOI 10.1002/rcs.2160
   Lu L., 2022, FRONT BIOENG BIOTECH, V10, P1
   Lu Y, 2020, J IND INF INTEGR, V19, DOI 10.1016/j.jii.2020.100158
   Marsch P, 2016, IEEE COMMUN MAG, V54, P24, DOI 10.1109/MCOM.2016.1600147CM
   Martín-Pérez J, 2019, IEEE T BROADCAST, V65, P464, DOI 10.1109/TBC.2019.2901406
   Martins BR, 2023, INTERACT LEARN ENVIR, V31, P2305, DOI 10.1080/10494820.2021.1879872
   Mertes J, 2022, J MANUF SYST, V64, P578, DOI 10.1016/j.jmsy.2022.08.009
   Mettiti Abderrahmane El, 2022, Ingenierie des systemes d'information, V27, P1, DOI 10.18280/isi.270101
   Microsoft, 2020, START DES PROT
   Mihai S, 2022, IEEE COMMUN SURV TUT, V24, P2255, DOI 10.1109/COMST.2022.3208773
   Minopoulos G, 2023, IEEE CONSUM ELECTR M, V12, P9, DOI 10.1109/MCE.2022.3156305
   Minopoulos G, 2019, INT J FUTUR GENER CO, V12, P37, DOI 10.33832/ijfgcn.2019.12.2.04
   Mourtzis D, 2018, PROC CIRP, V70, P368, DOI 10.1016/j.procir.2018.02.045
   Nadir Z, 2021, IEEE NETWORK, V35, P299, DOI 10.1109/MNET.121.2100172
   Orlosky J., 2017, J INF PROCESS SYST, V25, P133, DOI [DOI 10.2197/IPSJJIP.25.133, 10.2197/ipsjjip.25.133, DOI 10.2197/IPSJJIP.25, 10.2197/ipsjjip.25]
   Osama M, 2022, ULTRA RELIABLE LOW L, DOI [10.3390/info13090430, DOI 10.3390/INFO13090430]
   Osseiran A, 2014, IEEE COMMUN MAG, V52, P26, DOI 10.1109/MCOM.2014.6815890
   Panwar N, 2016, PHYS COMMUN-AMST, V18, P64, DOI 10.1016/j.phycom.2015.10.006
   Park GS., 2022, IEEE T MOBILE COMPUT, V1233, P1
   Pätzold M, 2019, IEEE VEH TECHNOL MAG, V14, P4, DOI 10.1109/MVT.2018.2884042
   Peng J, 2022, DYNAMIC VISUAL SLAM, DOI [10.1186/s13638-022-02181-9, DOI 10.1186/S13638-022-02181-9]
   Qian P, 2022, IEEE T BROADCAST, V68, P451, DOI 10.1109/TBC.2022.3161745
   Qiao XQ, 2019, CHINA COMMUN, V16, P141, DOI 10.23919/JCC.2019.09.010
   Qiao XQ, 2019, P IEEE, V107, P651, DOI 10.1109/JPROC.2019.2895105
   Qiao XQ, 2018, IEEE INTERNET COMPUT, V22, P46, DOI 10.1109/MIC.2018.043051464
   Pham QV, 2020, IEEE ACCESS, V8, P116974, DOI 10.1109/ACCESS.2020.3001277
   Qureshi KN, 2021, BIG DATA, V9, P253, DOI 10.1089/big.2020.0282
   Rahimi H, 2021, IEEE T COMPUT, V70, P1213, DOI 10.1109/TC.2021.3066579
   Ranaweera P, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3474552
   Rao SK, 2018, WIRELESS PERS COMMUN, V100, P145, DOI 10.1007/s11277-018-5615-7
   Rauschnabel PA, 2021, INT J INFORM MANAGE, V57, DOI 10.1016/j.ijinfomgt.2020.102279
   Ren P., 2021, IEEE T SERV COMPUT, VXX, P1
   Ren P, 2023, IEEE T SERV COMPUT, V16, P1778, DOI 10.1109/TSC.2022.3190375
   Ren P, 2022, IEEE T CLOUD COMPUT, V10, P2521, DOI 10.1109/TCC.2020.3046128
   Ren P, 2020, IEEE NETWORK, V34, P254, DOI 10.1109/MNET.011.1900305
   Rinaldi C, 2021, IEEE ACCESS, V9, P155197, DOI 10.1109/ACCESS.2021.3128786
   Ripka P, 2007, MODERN SENSORS HDB, DOI [10.1002/9780470612231, DOI 10.1002/9780470612231]
   Roesner F, 2014, COMMUN ACM, V57, P88, DOI 10.1145/2580723.2580730
   Sadeghi-Niaraki A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102997
   Sadok D, 2022, INT J INTELL ROBOT, V6, P270, DOI 10.1007/s41315-021-00206-y
   Sathya V, 2023, WIRELESS PERS COMMUN, V128, P2779, DOI 10.1007/s11277-022-10070-z
   Schneir JR, 2022, TELECOMMUN POLICY, V46, DOI 10.1016/j.telpol.2021.102264
   Sharma S, 2011, 2011 IEEE 17TH PACIFIC RIM INTERNATIONAL SYMPOSIUM ON DEPENDABLE COMPUTING (PRDC), P71, DOI [10.1109/PRDC.2011.18, 10.1109/ICCCET.2011.5762441]
   Sharma SK, 2020, IEEE ACCESS, V8, P56948, DOI 10.1109/ACCESS.2020.2980369
   Shi LN, 2020, IEEE T BROADCAST, V66, P534, DOI 10.1109/TBC.2020.2981755
   Shin H, 2020, TECHNOL FORECAST SOC, V153, DOI 10.1016/j.techfore.2020.119948
   Silveira A. C., 2022, WORKSHOP MULTISENSOR, p2nd, DOI [https://doi.org/10.5753/sensoryx.2022.20005, DOI 10.5753/SENSORYX.2022.20005]
   Silverman ME, 2020, ARCH WOMEN MENT HLTH, V23, P779, DOI 10.1007/s00737-020-01061-9
   Singh D, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11172700
   Siriwardhana Y, 2021, IEEE COMMUN SURV TUT, V23, P1160, DOI 10.1109/COMST.2021.3061981
   Siriwardhana YS, 2020, IEEE INTERNET THINGS, V7, P11559, DOI 10.1109/JIOT.2020.3024875
   Song J, 2022, IEEE T COMMUN, V70, P7294, DOI 10.1109/TCOMM.2022.3208113
   Song TY, 2023, DIGIT COMMUN NETW, V9, P723, DOI 10.1016/j.dcan.2022.04.014
   Sukhmani S, 2019, IEEE MULTIMEDIA, V26, P21, DOI 10.1109/MMUL.2018.2879591
   Tai Y., 2022, IEEE INTERNET THINGS, V4662, P1
   Tai Yonghang, 2021, IEEE Internet Things J, V8, P15965, DOI 10.1109/JIOT.2021.3055804
   Taleb Tarik, 2021, IEEE Communications Standards Magazine, V5, P114, DOI 10.1109/MCOMSTD.001.2000053
   Taleb T, 2023, IEEE INTERNET THINGS, V10, P3567, DOI 10.1109/JIOT.2022.3222103
   Tan ZJ, 2020, IEEE INTERNET THINGS, V7, P4872, DOI 10.1109/JIOT.2020.2971325
   Vargic R, 2018, ADV INTELL SYST, V725, P421, DOI 10.1007/978-3-319-75175-7_42
   Vatalaro F, 2020, IEEE ACCESS, V8, P135075, DOI 10.1109/ACCESS.2020.3010348
   Vega MT, 2020, J NETW SYST MANAG, V28, P796, DOI 10.1007/s10922-020-09545-w
   Verde S., 2020, SENSORS SWITZERLAND, V20, P1
   Vilela J, 2017, J SYST SOFTWARE, V125, P68, DOI 10.1016/j.jss.2016.11.031
   Virbela, 2021, VIRB VIRT WORLD BANK
   Viswanathan H, 2020, IEEE ACCESS, V8, P57063, DOI 10.1109/ACCESS.2020.2981745
   Wang CW, 2023, IEEE T GREEN COMMUN, V7, P972, DOI 10.1109/TGCN.2022.3186314
   Wang CX, 2014, IEEE COMMUN MAG, V52, P122, DOI 10.1109/MCOM.2014.6736752
   Wang W, 2014, IEEE WIREL COMMUN, V21, P42, DOI 10.1109/MWC.2014.6812290
   Wang Y, 2014, IEEE VEH TECHNOL MAG, V9, P39, DOI 10.1109/MVT.2014.2333694
   Wersényi G, 2022, INFOCOMMUNICATIONS J, V14, P11, DOI 10.36244/ICJ.2022.4.2
   Wu CW, 2022, IEEE SYST J, V16, P6590, DOI 10.1109/JSYST.2022.3169553
   Yaakob M., 2022, INT J INTERACT MOB T, V16, P23
   Yagol P, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7120478
   Yan Y, 2019, ADV INTELL SYST, V777, P239, DOI 10.1007/978-3-319-94706-8_27
   Yang Samuel C., 2012, Campus-Wide Information Systems, V29, P344, DOI 10.1108/10650741211275107
   Yang X, 2021, IEEE-CAA J AUTOMATIC, V8, P273, DOI 10.1109/JAS.2020.1003536
   Yin Y, 2023, ROBOT CIM-INT MANUF, V81, DOI 10.1016/j.rcim.2022.102515
   Yung R, 2019, CURR ISSUES TOUR, V22, P2056, DOI 10.1080/13683500.2017.1417359
   Zhang L, 2024, IEEE T MOBILE COMPUT, V23, P409, DOI 10.1109/TMC.2022.3232543
   Zhang SY, 2022, NEUROSURG FOCUS, V52, DOI 10.3171/2022.3.FOCUS2249
   Zhong LJ, 2022, IEEE T BROADCAST, V68, P559, DOI 10.1109/TBC.2022.3147098
   Zorzal ER, 2020, J BIOMED INFORM, V107, DOI 10.1016/j.jbi.2020.103463
NR 175
TC 0
Z9 0
U1 8
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 9067
EP 9102
DI 10.1007/s11042-023-15301-4
EA JUN 2023
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001003131400001
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, W
   Fan, GD
   Gan, M
AF Li, Wang
   Fan, Guodong
   Gan, Min
TI Progressive encoding-decoding image dehazing network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image dehazing; Deep convolutional network; Scene depth; Real scene
ID COLOR
AB In this paper, we propose a progressive encoding-decoding network (PEDN) for image dehazing. First, we built a basic dehaze unit to progressively process the image to achieve image dehazing in stages. The basic dehaze unit is composed of a feature memory module and an encoding-decoding network. The feature memory module is used to transfer features at different progressive stages. The encoding-decoding network is responsible for feature extraction, encodes and decodes images by fusing different levels of pyramid features. The basic dehaze unit shares parameters during the progressive process, which effectively reduces the difficulty of network training and improves the fitting speed. The proposed model is an end-to-end image dehazing network, which does not depend on the atmospheric scattering model. In addition, we extracted the depth information of the hazy image and obtained its pyramid features, and incorporated the depth information into the feature extraction to guide the network to restore clear images more accurately. Experiments show that the our method not only performs well on synthetic datasets, but also has excellent performance on real world hazy images. It is superior to current image dehaze methods in quantitative indexes and visual perception. Code has been made available at https://github.com/LWQDU/PEDN.
C1 [Li, Wang; Fan, Guodong; Gan, Min] Qingdao Univ, Sch Comp Sci & Technol, Qingdao 266071, Shandong, Peoples R China.
   [Gan, Min] Fuzhou Univ, Coll Comp & Data Sci, Fuzhou 350108, Fujian, Peoples R China.
C3 Qingdao University; Fuzhou University
RP Fan, GD (corresponding author), Qingdao Univ, Sch Comp Sci & Technol, Qingdao 266071, Shandong, Peoples R China.
EM liwangliman@163.com; fgd96@outlook.com; aganmin@aliyun.com
OI Fan, Guodong/0000-0003-0382-6142
CR Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Ancuti C, 2018, LECT NOTES COMPUT SC, V11182, P620, DOI 10.1007/978-3-030-01449-0_52
   Ancuti C, 2016, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP.2016.7532754
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen C, 2021, IEEE T CIRC SYST VID
   Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P3995, DOI 10.1109/TIP.2021.3068644
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P1090, DOI 10.1109/TIP.2019.2934350
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   Fan GD, 2021, APPL INTELL, V51, P7262, DOI 10.1007/s10489-021-02236-2
   Fan Z., 2018, ARXIV
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Fazlali H, 2020, MULTIMED TOOLS APPL, V79, P29493, DOI 10.1007/s11042-020-09383-7
   Feng X, 2021, APPL INTELL, P1
   Fu XY, 2020, IEEE T NEUR NET LEAR, V31, P1794, DOI 10.1109/TNNLS.2019.2926481
   Galdran A, 2017, IEEE SIGNAL PROC LET, V24, P151, DOI 10.1109/LSP.2016.2643168
   Gibson KB, 2014, IEEE T IMAGE PROCESS, V23, P3179, DOI 10.1109/TIP.2014.2328180
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hua Z, 2020, IEEE ACCESS, V8, P167693, DOI 10.1109/ACCESS.2020.3023906
   Jia H., 2020, AAAI, P11908
   Jin YX, 2021, IEEE T NEUR NET LEAR, V32, P2330, DOI 10.1109/TNNLS.2020.3004634
   Khorram A, 2021, APPL INTELL, V51, P736, DOI 10.1007/s10489-020-01859-1
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim JY, 2001, IEEE T CIRC SYST VID, V11, P475, DOI 10.1109/76.915354
   Kingma D. P., 2014, arXiv
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li J, 2021, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS51556.2021.9401687
   Lin HY, 2017, APPL INTELL, V47, P1099, DOI 10.1007/s10489-017-0942-z
   Ling ZG, 2019, MULTIMED TOOLS APPL, V78, P213, DOI 10.1007/s11042-018-5687-0
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Liu X, 2017, COMPUT VIS IMAGE UND, V162, P23, DOI 10.1016/j.cviu.2017.08.002
   Mei K., 2018, P AS C COMP VIS
   Min XK, 2019, IEEE T MULTIMEDIA, V21, P2319, DOI 10.1109/TMM.2019.2902097
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Nguyen HD, 2021, INT J INFORM MANAGE, V57, DOI 10.1016/j.ijinfomgt.2020.102282
   Pang YW, 2018, IEEE T NEUR NET LEAR, V29, P1587, DOI 10.1109/TNNLS.2017.2676130
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Raj NB, 2020, 2020 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS SIGNAL PROCESSING AND NETWORKING (WISPNET), P37, DOI [10.1109/WiSPNET48689.2020.9198400, 10.1109/wispnet48689.2020.9198400]
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shahid F, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110212
   Shao YJ, 2020, PROC CVPR IEEE, P2805, DOI 10.1109/CVPR42600.2020.00288
   Sharma T, 2020, MULTIMED TOOLS APPL, V79, P30769, DOI 10.1007/s11042-020-09496-z
   Singh D, 2019, APPL INTELL, V49, P4276, DOI 10.1007/s10489-019-01504-6
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Wang YK, 2014, IEEE T IMAGE PROCESS, V23, P4826, DOI 10.1109/TIP.2014.2358076
   Wiedemann S, 2020, IEEE T NEUR NET LEAR, V31, P772, DOI 10.1109/TNNLS.2019.2910073
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang TL, 2021, IET IMAGE PROCESS, V15, P1583, DOI 10.1049/ipr2.12127
   Zhang WW, 2021, IEEE J-STARS, V14, P3719, DOI 10.1109/JSTARS.2021.3068274
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 61
TC 0
Z9 0
U1 11
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7657
EP 7679
DI 10.1007/s11042-023-15638-w
EA JUN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001006598900007
DA 2024-07-18
ER

PT J
AU Peng, YJ
   Ma, K
   Zhang, Y
   He, ZQ
AF Peng, Yunjie
   Ma, Kang
   Zhang, Yang
   He, Zhiqiang
TI Learning rich features for gait recognition by integrating skeletons and
   silhouettes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait recognition; Biometrics; Feature-level fusion; Convolutional neural
   networks; Graph convolutional neural networks
ID FUSION
AB Gait recognition captures gait patterns from the walking sequence of an individual for identi-fication. Most existing gait recognition methods learn features from silhouettes or skeletons for the robustness to clothing, carrying, and other exterior factors. The combination of the two data modalities, however, is not fully exploited. Previous multimodal gait recognition methods mainly employ the skeleton to assist the local feature extraction where the intrinsic discrimination of the skeleton data is ignored. To fill this gap and make full use of the two complementary data modalities, this paper proposes a simple yet effective Bimodal Fusion (BiFusion) network which mines discriminative gait patterns in skeletons and integrates with silhouette representations to learn rich features for better identification. Particularly, the inherent hierarchical semantics of body joints in a skeleton is leveraged to design a novel Multi-Scale Gait Graph (MSGG) network for the feature extraction of skeletons. Extensive experiments on CASIA-B and OUMVLP demonstrate both the superiority of the proposed MSGG network in modeling skeletons and the effectiveness of the bimodal fusion for gait recognition. Under the most challenging condition of cross-clothing gait recognition on CASIA-B, our method achieves the rank-1 accuracy of 94.0%, which outperforms previ-ous state-of-the-art methods by a large margin. The code is released at https://github.com/ YunjiePeng/BimodalFusion.
C1 [Peng, Yunjie; He, Zhiqiang] Beihang Univ, Sch Comp Sci & Technol, Xueyuan Rd, Beijing 100191, Peoples R China.
   [Peng, Yunjie; Ma, Kang] Watrix Technol Ltd Co Ltd, XueYuan Rd, Beijing 100083, Peoples R China.
   [Zhang, Yang; He, Zhiqiang] Lenovo Co Ltd, Xibeiwang Rd, Beijing 100085, Peoples R China.
C3 Beihang University
RP He, ZQ (corresponding author), Beihang Univ, Sch Comp Sci & Technol, Xueyuan Rd, Beijing 100191, Peoples R China.; He, ZQ (corresponding author), Lenovo Co Ltd, Xibeiwang Rd, Beijing 100085, Peoples R China.
EM yunjiepeng@buaa.edu.cn; kangx.ma@gmail.com; zhangyang20@lenovo.com;
   zqhe1963@gmail.com
OI He, Zhiqiang/0000-0003-3103-1902; Peng, Yunjie/0000-0002-9275-0356
CR Aggarwal H, 2018, IEEE T COGN DEV SYST, V10, P397, DOI 10.1109/TCDS.2017.2658674
   Bodla N, 2017, IEEE WINT CONF APPL, P586, DOI 10.1109/WACV.2017.71
   Bouchrika I, 2011, J FORENSIC SCI, V56, P882, DOI 10.1111/j.1556-4029.2011.01793.x
   Boulgouris NV, 2013, IEEE T IMAGE PROCESS, V22, P3636, DOI 10.1109/TIP.2013.2266578
   Cai C, 2019, P 2019 8 INT C COMPU, P89
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chai TR, 2022, PROC CVPR IEEE, P20217, DOI 10.1109/CVPR52688.2022.01961
   Chao Fan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14213, DOI 10.1109/CVPR42600.2020.01423
   Chao HQ, 2022, IEEE T PATTERN ANAL, V44, P3467, DOI 10.1109/TPAMI.2021.3057879
   Chao HQ, 2019, AAAI CONF ARTIF INTE, P8126
   Chen X, 2021, IEEE T IMAGE PROCESS, V30, P3041, DOI 10.1109/TIP.2021.3055936
   Ching-Hang Chen, 2017, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P5759, DOI 10.1109/CVPR.2017.610
   Deng MQ, 2019, IEEE T CIRC SYST VID, V29, P3636, DOI 10.1109/TCSVT.2018.2883449
   Dhiman C, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3441628
   Dhiman C, 2020, IEEE T IMAGE PROCESS, V29, P3835, DOI 10.1109/TIP.2020.2965299
   Ding XN, 2021, NEUROCOMPUTING, V463, P411, DOI 10.1016/j.neucom.2021.08.054
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Faundez-Zanuy M, 2005, IEEE AERO EL SYS MAG, V20, P34, DOI 10.1109/MAES.2005.1396793
   Gallego G, 2022, IEEE T PATTERN ANAL, V44, P154, DOI 10.1109/TPAMI.2020.3008413
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hermans Alexander, 2017, ARXIV170307737
   Huang XH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12889, DOI 10.1109/ICCV48922.2021.01267
   Iwama H, 2012, IEEE T INF FOREN SEC, V7, P1511, DOI 10.1109/TIFS.2012.2204253
   Larsen PK, 2008, J FORENSIC SCI, V53, P1149, DOI 10.1111/j.1556-4029.2008.00807.x
   Liang J., 2022, ARXIV
   Liao RJ, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107069
   Lin BB, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3054, DOI 10.1145/3394171.3413861
   Lin BB, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14628, DOI 10.1109/ICCV48922.2021.01438
   Lishani AO, 2019, MULTIMED TOOLS APPL, V78, P5715, DOI 10.1007/s11042-018-5752-8
   Liu JW, 2021, PROC CVPR IEEE, P4368, DOI 10.1109/CVPR46437.2021.00435
   Liu XK, 2022, PATTERN RECOGN, V125, DOI 10.1016/j.patcog.2022.108520
   Makihara Y., 2012, IPSJ T COMPUT VISION, V4, P53, DOI DOI 10.2197/IPSJTCVA.4.53
   Maltoni D., 2005, CH SYNTHETIC FINGERP, V33, P1314
   Mao MG, 2020, IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2020), DOI 10.1109/ijcb48548.2020.9304916
   Marín-Jiménez MJ, 2021, IEEE T INF FOREN SEC, V16, P5452, DOI 10.1109/TIFS.2021.3132579
   Paszke A., 2019, ADV NEURAL INFORM PR, P8026, DOI DOI 10.48550/ARXIV.1912.01703
   Ross A, 2005, PROC SPIE, V5779, P196, DOI 10.1117/12.606093
   Saihui Hou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P382, DOI 10.1007/978-3-030-58545-7_22
   Shekhar S, 2014, IEEE T PATTERN ANAL, V36, P113, DOI 10.1109/TPAMI.2013.109
   Singh T, 2021, MULTIMED TOOLS APPL, V80, P33505, DOI 10.1007/s11042-021-11415-9
   Singh T, 2021, NEURAL COMPUT APPL, V33, P469, DOI 10.1007/s00521-020-05018-y
   Sun JD, 2018, MULTIMED TOOLS APPL, V77, P24909, DOI 10.1007/s11042-018-5722-1
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Sun Y, 2014, ADV NEUR IN, V27
   Takemura Noriko, 2018, IPSJ Transactions on Computer Vision and Applications, V10, DOI 10.1186/s41074-018-0039-6
   Teepe T, 2021, IEEE IMAGE PROC, P2314, DOI 10.1109/ICIP42928.2021.9506717
   Tong SB, 2018, IEEE ACCESS, V6, P57583, DOI 10.1109/ACCESS.2018.2874073
   Wang YX, 2022, IEEE T PATTERN ANAL, V44, P3436, DOI 10.1109/TPAMI.2021.3054886
   Weizhi An, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P421, DOI 10.1109/TBIOM.2020.3008862
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Xiang Li, 2021, Computer Vision - ACCV 2020. 15th Asian Conference on Computer Vision. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12624), P3, DOI 10.1007/978-3-030-69535-4_1
   Xin Y, 2018, IEEE ACCESS, V6, P21418, DOI 10.1109/ACCESS.2018.2815540
   Xu C, 2019, MULTIMED TOOLS APPL, V78, P26509, DOI 10.1007/s11042-019-7712-3
   Xu HH, 2020, IEEE ACCESS, V8, P228088, DOI 10.1109/ACCESS.2020.3044580
   Xu K, 2021, 2021 IEEE INT C MULT, P1, DOI [10.1109/icme51207.2021.9428123, DOI 10.1109/ICME51207.2021.9428123]
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yao LX, 2022, IEEE T CIRC SYST VID, V32, P3615, DOI 10.1109/TCSVT.2021.3112564
   Yu SQ, 2006, INT C PATT RECOG, P441
   Yu SQ, 2017, NEUROCOMPUTING, V239, P81, DOI 10.1016/j.neucom.2017.02.006
   Zhang ZY, 2022, IEEE T PATTERN ANAL, V44, P345, DOI 10.1109/TPAMI.2020.2998790
   Zhang ZY, 2019, PROC CVPR IEEE, P4705, DOI 10.1109/CVPR.2019.00484
   Zheng Liang, 2016, ARXIV
NR 63
TC 2
Z9 2
U1 8
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7273
EP 7294
DI 10.1007/s11042-023-15483-x
EA JUN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001004157400002
DA 2024-07-18
ER

PT J
AU Akram, A
   Khan, N
AF Akram, Arbish
   Khan, Nazar
TI US-GAN: on the importance of ultimate skip connection for facial
   expression synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression synthesis; Generative adversarial network; Skip
   connection; Image-to-image translation; Residual block
AB We demonstrate the benefit of using an ultimate skip (US) connection for facial expression synthesis using generative adversarial networks (GAN). A direct connection transfers identity, facial, and color details from input to output while suppressing artifacts. The intermediate layers can therefore focus on expression generation only. This leads to a light-weight US-GAN model comprised of encoding layers, a single residual block, decoding layers, and an ultimate skip connection from input to output. US-GAN has 3 x fewer parameters than state-of-the-art models and is trained on 2 orders of magnitude smaller dataset. It yields 7% increase in face verification score (FVS) and 27% decrease in average content distance (ACD). Based on a randomized user-study, US-GAN outperforms the state of the art by 25% in face realism, 43% in expression quality, and 58% in identity preservation.
C1 [Akram, Arbish; Khan, Nazar] Univ Punjab, Dept Comp Sci, Lahore, Pakistan.
C3 University of Punjab
RP Akram, A (corresponding author), Univ Punjab, Dept Comp Sci, Lahore, Pakistan.
EM arbishakram@pucit.edu.pk; nazarkhan@pucit.edu.pk
OI Akram, Arbish/0000-0003-2661-4855
CR Akram A, 2021, INT C PATT RECOG, P9733, DOI 10.1109/ICPR48806.2021.9413065
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Benitez-Quiroz CF, 2016, PROC CVPR IEEE, P5562, DOI 10.1109/CVPR.2016.600
   Chen CF, 2021, IEEE T IMAGE PROCESS, V30, P1219, DOI 10.1109/TIP.2020.3043093
   Chen YC, 2020, PROC CVPR IEEE, P5273, DOI 10.1109/CVPR42600.2020.00532
   Chen Y, 2018, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2018.00264
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   d'Apolito S, 2021, PROC CVPR IEEE, P568, DOI 10.1109/CVPR46437.2021.00063
   Ding H, 2018, AAAI CONF ARTIF INTE, P6781
   Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111
   FUKUSHIMA K, 1975, BIOL CYBERN, V20, P121, DOI 10.1007/BF00342633
   Gao Y, 2021, PROC CVPR IEEE, P16110, DOI 10.1109/CVPR46437.2021.01585
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Khan N, 2020, INT J COMPUT VISION, V128, P1433, DOI 10.1007/s11263-019-01256-3
   Kingma D. P., 2014, arXiv
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Liu M, 2019, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2019.00379
   Lundqvist D., 1998, The Karolinska Directed Emotional Faces-KDEF
   Mao XJ, 2016, ADV NEUR IN, V29
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Perarnau G, 2016, ARXIV
   Pumarola A, 2020, INT J COMPUT VISION, V128, P698, DOI 10.1007/s11263-019-01210-3
   Qiao F, 2018, ARXIV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shen W, 2017, PROC CVPR IEEE, P1225, DOI 10.1109/CVPR.2017.135
   Tang J, 2021, IEEE MULTIMEDIA
   Ulyanov Dmitry, 2016, arXiv
   Wu PW, 2019, IEEE I CONF COMP VIS, P5913, DOI 10.1109/ICCV.2019.00601
   Wu RL, 2020, PROC CVPR IEEE, P5020, DOI 10.1109/CVPR42600.2020.00507
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 36
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7231
EP 7247
DI 10.1007/s11042-023-15268-2
EA JUN 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001003562600008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kumar, M
   Rai, A
   Surbhit
   Kumar, N
AF Kumar, Mohit
   Rai, Atul
   Surbhit
   Kumar, Neeraj
TI Autonomic edge cloud assisted framework for heart disease prediction
   using RF-LRG algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cloud computing; Edge computing; Healthcare system; Internet of things;
   Accuracy; Machine learning
ID HEALTH; THINGS; INTERNET; EFFICIENT; SYSTEM
AB Due to changing lifestyles, human physical exercise has dropped rapidly which leads to several health-related problems. It is not easy to detect heart-related diseases, but with the emergence and advancement in technologies like Edge, Fog computing, Machine learning, Cloud computing, and the Internet of Things (IoT), it's a cinch to track heart diseases. Cloud computing provides the resources for computation as well as online storage over the internet, but it does not support latency-sensitive and real-time applications. To overcome this bottleneck, a new emerging technology named Edge Computing is used to bring the computation resource to local nodes for the services and reduces the latency as compared to the cloud. Current Edge computing-based models failed to achieve the output of real-time applications along with high accuracy and low latency simultaneously. Hence, we have proposed an autonomic Edge-assisted Cloud-IoT framework for smart healthcare that used a Random Forest and Logistic Regression Grid (RF-LRG) approach at edge nodes for analysis of heart disease and improves the various influential parameters such as accuracy (3.88%, 7.66% and 14.18%), precision (3.7%, 9%, and 16.6%), F1 Score (5%, 7.7%, and 16.9%.), recall (3.7%, 10.5%, and 15.06%.) compared with LR, RF and KNN algorithm. The simulation results ensured that the proposed framework using the RF-LRG algorithm predicted and diagnosed heart diseases with more accuracy and reduced the latency and energy consumption significantly when compared between the cloud and edge paradigms.
C1 [Kumar, Mohit; Rai, Atul; Surbhit] Dr B R Ambedkar NIT, Dept Informat Technol, Jalandhar, India.
   [Rai, Atul; Surbhit] Dr B R Ambedkar NIT, Dept Comp Sci & Engn, Jalandhar, India.
   [Kumar, Neeraj] TIET, Dept Comp Sci & Engn, Patiala, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar; National Institute of Technology (NIT
   System); Dr B R Ambedkar National Institute of Technology Jalandhar;
   Thapar Institute of Engineering & Technology
RP Kumar, M (corresponding author), Dr B R Ambedkar NIT, Dept Informat Technol, Jalandhar, India.
EM kumarmohit@nitj.ac.in; atulr.is.19@nitj.ac.in; luvjangra1999@gmail.com;
   neeraj.kumar@thapar.edu
RI KUMAR, MOHIT/GNP-6004-2022
OI KUMAR, MOHIT/0000-0003-1600-6872
CR Aazam M, 2014, INT BHURBAN C APPL S, P414, DOI 10.1109/IBCAST.2014.6778179
   Ali S, 2017, CAN CON EL COMP EN
   Antoniou Athanas.ios, 2017, Proceedings of the first international workshop on human-centered sensing, networking, and systems, P25, DOI DOI 10.1145/3144730.3144736
   Aslam F.A., 2015, International Journal of Advanced Research in Computer Science, V6
   Azimi I, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERECE ON CONNECTED HEALTH: APPLICATIONS, SYSTEMS AND ENGINEERING TECHNOLOGIES (CHASE), P63, DOI 10.1145/3278576.3278597
   Barik RK, 2018, Int J Fog Comput (IJFC), V1, P15, DOI 10.4018/IJFC.2018010102
   Charyyev B, 2020, IEEE GLOB COMM CONF, DOI 10.1109/GLOBECOM42002.2020.9322406
   Chen Y.C., 2017, Biostatistics Epidemiology, V1, P161, DOI [10.1080/24709360.2017.1396742, DOI 10.1080/24709360.2017.1396742]
   Choi E, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P787, DOI 10.1145/3097983.3098126
   Constant N., 2017, Fog-Assisted wIoT: A Smart Fog Gateway for End-to-End Analytics in Wearable Internet of Things
   Cowling TE, 2020, J CLIN EPIDEMIOL
   Farahani B, 2018, FUTURE GENER COMP SY, V78, P659, DOI 10.1016/j.future.2017.04.036
   Ganesan M, 2019, 2019 IEEE INT C SYST, P1
   Ghosh A, 2020, INTERNET THINGS-NETH, V9, DOI 10.1016/j.iot.2020.100166
   Gia TN, 2019, FUTURE GENER COMP SY, V93, P198, DOI 10.1016/j.future.2018.10.029
   Gill SS, 2022, INTERNET THINGS-NETH, V19, DOI 10.1016/j.iot.2022.100514
   Gubbi J, 2012, CLOUDSTR20122
   Gupta H, 2017, SOFTWARE PRACT EXPER, V47, P1275, DOI 10.1002/spe.2509
   HANJURA A., 2014, HEROKU CLOUD APPL DE, V1st
   He SQ, 2017, CHINA COMMUN, V14, P1, DOI 10.1109/CC.2017.8233646
   Hossain MS, 2016, COMPUT NETW, V101, P192, DOI 10.1016/j.comnet.2016.01.009
   Kaur P, 2019, MULTIMED TOOLS APPL, V78, P19905, DOI 10.1007/s11042-019-7327-8
   Kumar M, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P257, DOI 10.1109/Confluence51648.2021.9377050
   Kumar M, 2019, J NETW COMPUT APPL, V143, P1, DOI 10.1016/j.jnca.2019.06.006
   Kumari A, 2018, COMPUT ELECTR ENG, V72, P1, DOI 10.1016/j.compeleceng.2018.08.015
   Lapp D, Heart disease dataset: Public health dataset. kaggle
   Li LZ, 2018, IEEE T IND INFORM, V14, P4665, DOI 10.1109/TII.2018.2842821
   Mahmoud MME, 2018, COMPUT ELECTR ENG, V67, P58, DOI 10.1016/j.compeleceng.2018.02.047
   Mahmud R, 2018, ICDCN'18: PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING AND NETWORKING, DOI 10.1145/3154273.3154347
   Mohan S, 2019, IEEE ACCESS, V7, P81542, DOI 10.1109/ACCESS.2019.2923707
   Moroney L., 2017, FIREBASE REAL TIME D
   Mukherjee A, 2021, J AMB INTEL HUM COMP, V12, P943, DOI 10.1007/s12652-020-02113-9
   Parvin S, 2021, LECT NOTES NETWORKS, V182, DOI [10.1007/978-3-030-65796, DOI 10.1007/978-3-030-65796]
   Rajasekaran M, 2019, FUTURE GENER COMP SY, V98, P565, DOI 10.1016/j.future.2019.01.021
   Sze V, 2017, IEEE CUST INTEGR CIR
   Tuli S, HEALTHFOG ENSEMBLE D
   Uddin S, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-1004-8
   Verma P, 2018, J PARALLEL DISTR COM, V116, P27, DOI 10.1016/j.jpdc.2017.11.018
   Vilela PH, 2019, FUTURE GENER COMP SY, V97, P379, DOI 10.1016/j.future.2019.02.055
   Zhan ZQ, 2020, ANN NONINVAS ELECTRO, V25, DOI 10.1111/anec.12783
   Zhang C, 2018, FUTURE GENER COMP SY, V79, P16, DOI 10.1016/j.future.2017.09.002
NR 41
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 29
PY 2023
DI 10.1007/s11042-023-15736-9
EA MAY 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H8LP5
UT WOS:000998414300008
DA 2024-07-18
ER

PT J
AU Amiri, Z
   Hassanpour, H
   Beghdadi, A
AF Amiri, Zahra
   Hassanpour, Hamid
   Beghdadi, Azeddine
TI Combining deep features and hand-crafted features for abnormality
   detection in WCE images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Abnormality Detection; Capsule Endoscopy; Feature Selection; Region of
   Interest; Transfer Learning; Traditional Learning
ID CAPSULE ENDOSCOPY; SELECTION
AB In this paper, a computer-aided method is proposed for abnormality detection in Wireless Capsule Endoscopy (WCE) video frames. Common abnormalities in WCE images include ulcers, bleeding, Angiodysplasia, Lymphoid Hyperplasia, and polyp. In this paper, deep features and Hand-crafted features are combined to detect these abnormalities in WCE images. There are not sufficient images available to train deep structures, therefore the ResNet50 pre-trained model is used to extract deep features. Hand-crafted features are associated with color, shape, and texture. We used a novel idea to reveal unexpected color changes in the background due to existing lesions as a color feature set. Histogram of gradient (HOG) and local binary pattern (LBP) were used respectively for shape and texture features. They are extracted from the region of interest (ROI), i.e. suspicious region. The expectation Maximization (EM) algorithm is used to extract more distinct areas in the background as ROI. The expectation Maximization (EM) algorithm is configured in a way that can extract areas with a distinct texture and color as ROI. The EM algorithm is also initialized with a new fast method which leads to an increase in the accuracy of the method. A large number of features are created by the method, so the minimum redundancy maximum relevance approach is used to select a subset of more effective features. These selected features are then fed to a Support Vector Machine for classification. The results show that the proposed approach can detect mentioned abnormalities in WCE frames with the accuracy of 97.82%
C1 [Amiri, Zahra; Hassanpour, Hamid] Shahrood Univ Technol, Fac Comp Engn, Shahrood, Iran.
   [Beghdadi, Azeddine] Univ Sorbonne Paris Nord, Inst Galilee, Paris, France.
C3 Shahrood University of Technology
RP Hassanpour, H (corresponding author), Shahrood Univ Technol, Fac Comp Engn, Shahrood, Iran.
EM zahra.amiri@shahroodut.ac.ir; h.hassanpour@shahroodut.ac.ir;
   beghdadi@sorbonne-paris-nord.fr
RI Beghdadi, Azeddine/ABF-9801-2022; Amiri, Zahra/HHC-9302-2022;
   Hassanpour, Hamid/AAL-7271-2020; Amiri, Zahra/KHU-7955-2024
OI Beghdadi, Azeddine/0000-0002-5595-0615; Amiri,
   Zahra/0000-0001-8714-723X; Hassanpour, Hamid/0000-0002-5513-9822; 
CR Ajam A, 2019, 2019 5TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS 2019), DOI 10.1109/icspis48872.2019.9066062
   AlyanNezhadi M. M., 2020, International journal of Engineering, V33, P949, DOI 10.5829/ije.2020.33.05b.28
   Amiri Z, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103219
   Amiri Z, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/7863113
   Amiri Z, 2019, 2019 5TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS 2019), DOI 10.1109/icspis48872.2019.9066008
   Amiri Z, 2019, EUR W VIS INF PROCES, P217, DOI 10.1109/EUVIP47703.2019.8946168
   [Anonymous], 2021, GASTROINTESTINAL IMA
   [Anonymous], 2017, P AAAI C ARTIFICIAL
   Caroppo A, 2021, COMPUT MED IMAG GRAP, V88, DOI 10.1016/j.compmedimag.2020.101852
   Coelho P, 2018, LECT NOTES COMPUT SC, V10882, P553, DOI 10.1007/978-3-319-93000-8_63
   Constantinescu A. F., 2015, Applied Medical Informatics, V36, P31
   Dalal N., 2005, 2005 IEEE COMP SOC C, V1, P886
   de Maissin A, 2021, ENDOSC INT OPEN, V09, pE1136, DOI 10.1055/a-1468-3964
   Deeba F, BLEEDING IMAGES CORR
   Deeba F, 2018, J MED BIOL ENG, V38, P325, DOI 10.1007/s40846-017-0299-0
   Deeba F, 2018, BIOMED SIGNAL PROCES, V40, P415, DOI 10.1016/j.bspc.2017.10.011
   Ding Chris, 2005, Journal of Bioinformatics and Computational Biology, V3, P185, DOI 10.1142/S0219720005001004
   Fonseca Filipe, 2022, Procedia Computer Science, P469, DOI 10.1016/j.procs.2021.12.038
   Gobpradit S, 2020, LECT NOTES ARTIF INT, V12033, P283, DOI 10.1007/978-3-030-41964-6_25
   Hajabdollahi M, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.101565
   Iwamuro M, 2016, INT J COLORECTAL DIS, V31, P313, DOI 10.1007/s00384-015-2392-6
   Jia X, 2017, I S BIOMED IMAGING, P179, DOI 10.1109/ISBI.2017.7950496
   Jia X, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (IEEE RCAR), P266, DOI 10.1109/RCAR.2016.7784037
   Khuroo MS, 2011, BMC GASTROENTEROL, V11, DOI 10.1186/1471-230X-11-36
   Koulaouzidis A, 2017, ENDOSC INT OPEN, V5
   Lecleire S, 2012, ENDOSCOPY, V44, P337, DOI 10.1055/s-0031-1291614
   Li Z., 2014, HDB CAPSULE ENDOSCOP, P5
   Liao C, 2021, COMPUT METH PROG BIO, V208, DOI 10.1016/j.cmpb.2021.106189
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Mohammed A, 2018, J IMAGING, V4, DOI 10.3390/jimaging4060075
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Noya F, 2017, IEEE ENG MED BIO, P3158, DOI 10.1109/EMBC.2017.8037527
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Saraiva MM, 2022, GE PORT J GASTROENT, V29, P331, DOI 10.1159/000518901
   Shahril R., 2016, INT J ELECT COMPUT E, V6, P1617, DOI 10.11591/ijece.v6i4.9688
   Shvets AA, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P612, DOI 10.1109/ICMLA.2018.00098
   Smedsrud PH, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00920-z
   Souaidi M, 2019, MULTIMED TOOLS APPL, V78, P13091, DOI 10.1007/s11042-018-6086-2
   Sundaram PS, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1153-9
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.7017.09.004, 10.1016/j.cmpb.2012.09.004]
   Usman M, 2016, COMPUT MED IMAG GRAP, V09
   Vallée R, 2021, PRO BIOMED OPT IMAG, V11317, DOI 10.1117/12.2543584
   Vieira PM, 2019, ANN BIOMED ENG, V47, P1446, DOI 10.1007/s10439-019-02248-7
   Vieira PM, 2016, IEEE ENG MED BIO, P1184, DOI 10.1109/EMBC.2016.7590916
   Voderholzer WA, 2005, GUT, V54, P369, DOI 10.1136/gut.2004.040055
   Wang GN, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0129530
   Xuan D, 2011, IEEE INT C MULT BARC
   Yu JS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1822, DOI 10.1109/ROBIO.2015.7419037
   Yuan Y, 2015, IEEE T MED IMAGING, V34
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
NR 50
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 25
PY 2023
DI 10.1007/s11042-023-15198-z
EA MAY 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3NP9
UT WOS:000995070900003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Bie, M
   Liu, QL
   Xu, H
   Gao, Y
   Che, XJ
AF Bie, Mei
   Liu, Quanle
   Xu, Huan
   Gao, Yan
   Che, Xiangjiu
TI FEMFER: feature enhancement for multi-faces expression recognition in
   classroom images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Data science applications in education; Educational assessment; Facial
   expression recognition; Feature enhancement; YOLOv5
ID DEEP; STUDENTS; MODELS
AB Facial expression recognition is gradually being integrated into the classroom environment for educational assessment. Most existing algorithms are based on single frontal faces and are less effective for processing multi-facial images in a real classroom environment. In particular, detecting small faces is a common and challenging problem due to low video resolution, blurred images and little feature information. To address these issues, we improved YOLOv5 with the idea of feature enhancement (FE-YOLOv5) and applied it to classroom teaching scenarios. With Resnet-34_Focal as the expression classification network, the overall framework was FEMFER. The Feature Enhancement fused more information of feature maps by the proposed upsampling (UPS) module and the Convolution-Batch normalization-Leaky ReLU (CBL) module. The UPS module reduced the network's local perceptual field and effectively learned detailed information from the backbone. The CBL module speeded up the model convergence while increasing the nonlinearity of the features. The network with the feature enhancement method could extract and fuse features efficiently, which was more suitable for small face detection in the classroom situation and solved the problem of inaccurate recognition of small targets in the original network. Our method achieved 81.42% (+7.18%) in mAP compared with the original YOLOv5 algorithm. The FEMFER intelligently assessed positive, neutral, and negative emotions, but it was currently limited to single-modal information extraction. Further research could be carried out from the perspective of fusing multi-modal information such as gestures and voice to realize more accurate affective computing.
C1 [Bie, Mei; Liu, Quanle; Xu, Huan; Gao, Yan; Che, Xiangjiu] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Bie, Mei] Changchun Normal Univ, Inst Educ, Changchun 130032, Peoples R China.
C3 Jilin University; Changchun Normal University
RP Che, XJ (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
EM chexj@jlu.edu.cn
FU National Natural Science Foundation of China [62172184]; Science and
   Technology Development Plan of Jilin Province of China [20200401077GX,
   20200201292JC]; Social Science Research of the Education Department of
   Jilin Province [JJKH20210901SK]; Jilin Educational Scientific Research
   Leading Group [ZD21003]; Humanities and Social Science Foundation of
   Changchun Normal University [2020[011]]
FX This work was financially supported by National Natural Science
   Foundation of China under Grant 62172184, Science and Technology
   Development Plan of Jilin Province of China under Grant 20200401077GX,
   20200201292JC, Social Science Research of the Education Department of
   Jilin Province (JJKH20210901SK), Jilin Educational Scientific Research
   Leading Group (ZD21003) and Humanities and Social Science Foundation of
   Changchun Normal University(2020[011]).
CR Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Bougourzi F, 2020, EXPERT SYST APPL, V156, DOI 10.1016/j.eswa.2020.113459
   Calvo RA, 2011, NEW PERSPECTIVES ON AFFECT AND LEARNING TECHNOLOGIES, P1, DOI 10.1007/978-1-4419-9625-1
   Chen WJ, 2021, VISUAL COMPUT, V37, P805, DOI 10.1007/s00371-020-01831-7
   Chen Z, 2021, INT CONF BIG DATA, P52, DOI 10.1109/BigComp51126.2021.00019
   Chen ZZ, 2019, CHIN CONT DECIS CONF, P4626, DOI [10.1109/CCDC.2019.8833363, 10.1109/ccdc.2019.8833363]
   Deng ZR, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8010093
   DeVries T, 2017, Arxiv, DOI [arXiv:1708.04552, DOI 10.48550/ARXIV.1708.04552]
   github, LAB TOOL GITH REP
   Glenn J., 2020, YOLOv5
   Goswami G, 2018, P AAAI C ART INT, V32
   Gotwals AW, 2016, RES SCI EDUC, V46, P365, DOI 10.1007/s11165-015-9461-2
   Graesser A, 2007, FRONT ARTIF INTEL AP, V158, P569
   Gupta SK, 2019, MULTIMED TOOLS APPL, V78, P25321, DOI 10.1007/s11042-019-7651-z
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   jian Li Z., 2021, 2021 2 INT C COMPUTI, DOI [10.1145/3468691.3468719, DOI 10.1145/3468691.3468719]
   Joshi A, 2019, PROC FRONT EDUC CONF, DOI 10.1109/fie43999.2019.9028638
   Kansal S, 2018, MULTIMED TOOLS APPL, V77, P26919, DOI 10.1007/s11042-018-5894-8
   Khan M. Q., 2021, ARAB J SCI ENG, P1, DOI DOI 10.1007/s13369-021-05881-4
   Khan MA, 2021, CMC-COMPUT MATER CON, V68, P3841, DOI 10.32604/cmc.2021.016864
   Khan MA, 2021, MULTIMED TOOLS APPL, V80, P35827, DOI 10.1007/s11042-020-09408-1
   Khan S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21237941
   Kim J.-H., 2022, arXiv
   Kiran S, 2021, CMC-COMPUT MATER CON, V69, P4061, DOI 10.32604/cmc.2021.017800
   Kuo CM, 2018, IEEE COMPUT SOC CONF, P2202, DOI 10.1109/CVPRW.2018.00286
   Ledan Qian, 2021, 2021 IEEE International Conference on Artificial Intelligence and Industrial Design (AIID), P369, DOI 10.1109/AIID51893.2021.9456471
   Lee HJ, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10010054
   Lehman BA, 2018, IEEE T LEARN TECHNOL, V11, P41, DOI 10.1109/TLT.2018.2810878
   Li J, 2019, PROC CVPR IEEE, P5055, DOI 10.1109/CVPR.2019.00520
   Li JX, 2017, PROCEDIA COMPUT SCI, V107, P135, DOI 10.1016/j.procs.2017.03.069
   Li MZ, 2021, J REAL-TIME IMAGE PR, V18, P2111, DOI 10.1007/s11554-021-01088-w
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Li TF, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03042-x
   Liu P, 2014, PROC CVPR IEEE, P1805, DOI 10.1109/CVPR.2014.233
   Lu ZJ, 2018, IEEE ACCESS, V6, DOI [10.1109/ACCESS.2018.2864189, 10.1109/LSP.2018.2810121]
   Majeed, 2021, 2021 MOHAMMAD ALI JI, P1, DOI [10.1109/MAJICC53071.2021.9526254, DOI 10.1109/MAJICC53071.2021.9526254]
   Mehrabian A., 2017, Communication theory, P193
   Mindoro JN, 2020, 2020 11TH IEEE CONTROL AND SYSTEM GRADUATE RESEARCH COLLOQUIUM (ICSGRC), P328, DOI 10.1109/ICSGRC49013.2020.9232659
   Nasir Inzamam Mashood, 2021, 2021 1st International Conference on Artificial Intelligence and Data Analytics (CAIDA), P182, DOI 10.1109/CAIDA51941.2021.9425202
   Nasir IM, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107805
   Nie XH, 2021, J INTELL FUZZY SYST, V40, P7171, DOI 10.3233/JIFS-189545
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Qi D., 2021, arXiv
   Rong Chen, 2020, Web Information Systems and Applications. 17th International Conference, WISA 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12432), P326, DOI 10.1007/978-3-030-60029-7_30
   Shan SG, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P157
   Sharma P, 2020, Arxiv, DOI [arXiv:1909.12913, 10.48550/arXiv.1909.12913]
   Shi DM, 2022, J ELECTR COMPUT ENG, V2022, DOI 10.1155/2022/4260543
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Solovyev R, 2021, IMAGE VISION COMPUT, V107, DOI 10.1016/j.imavis.2021.104117
   Sun A, 2018, LECT NOTES COMPUT SC, V11003, P111, DOI 10.1007/978-3-319-99737-7_11
   Sun X, 2019, COGN COMPUT, V11, P587, DOI 10.1007/s12559-019-09654-y
   Tang CG, 2015, LECT NOTES COMPUT SC, V9428, P439, DOI 10.1007/978-3-319-25417-3_52
   Tian WX, 2019, Arxiv, DOI arXiv:1811.08557
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang F, 2020, NEUROPSYCHOLOGIA, V146, DOI 10.1016/j.neuropsychologia.2020.107506
   Wang K, 2020, IEEE T IMAGE PROCESS, V29, P4057, DOI 10.1109/TIP.2019.2956143
   Wang Y, 2021, SIGNAL IMAGE VIDEO P, V15, P1635, DOI 10.1007/s11760-021-01899-1
   Wang ZZ, 2021, IEEE ACCESS, V9, P56416, DOI 10.1109/ACCESS.2021.3072211
   Whitehill J, 2014, IEEE T AFFECT COMPUT, V5, P86, DOI 10.1109/TAFFC.2014.2316163
   Wilson M, 2000, APPL MEAS EDUC, V13, P181, DOI 10.1207/S15324818AME1302_4
   Yang L, 2020, KNOWL-BASED SYST, V204, DOI 10.1016/j.knosys.2020.106217
   Zeng YL, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/5536152
   Zhang FF, 2018, PROC CVPR IEEE, P3359, DOI 10.1109/CVPR.2018.00354
NR 63
TC 1
Z9 1
U1 6
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 17
PY 2023
DI 10.1007/s11042-023-15808-w
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7EQ1
UT WOS:000990751100008
DA 2024-07-18
ER

PT J
AU Fang, LL
   Jiang, YM
AF Fang, Lingling
   Jiang, Yumeng
TI Cerebral hemorrhage extraction with modified shuffled frog leaping
   algorithm based on the blood clot clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Blood clot extraction; Cerebral hemorrhage; Clustering algorithm; CT
   images; Shuffled frog leaping algorithm
ID SEGMENTATION
AB Rapid extraction of brain lesions can help doctors speed up clinical diagnosis and provide help for follow-up treatment. The spatial location, shape, and distribution of Cerebral hemorrhage are very changeable. Besides, there is a particular case where a blood clot adhesion to the skull (called Skull adhesion). Based on the features of a blood clot, combined with the modified shuffled frog leaping algorithm (MSFLA) and clustering ideas, this paper proposes a C-MSFLA based on the cerebral hemorrhage clot clustering algorithm and establishes the intracranial blood clot extraction framework. Here, the brain uncorrelated tissue is removed by the two-dimensional prefix summation eliminate algorithm, and then the complete blood clot is extracted by regional morphological operation. The proposed method can automatically and accurately extract blood clots. The experiments are tested using clinical cerebral hemorrhage CT images of patients in the Second Affiliated Hospital of Dalian Medical University and verified by the evaluation indicators of JAC, Dice, and Acc. Experiments verify that the proposed method has good performance. It can assist doctors in detecting lesions in time, which can make an efficient, automatic, and accurate clinical diagnosis.
C1 [Fang, Lingling; Jiang, Yumeng] Liaoning Normal Univ, Dept Comp & Informat Technol, Dalian, Liaoning, Peoples R China.
C3 Liaoning Normal University
RP Fang, LL (corresponding author), Liaoning Normal Univ, Dept Comp & Informat Technol, Dalian, Liaoning, Peoples R China.
EM fanglingling@lnnu.edu.cn
RI ; Fang, Lingling/N-1534-2018
OI Jiang, Yumeng/0009-0003-1847-9275; Fang, Lingling/0000-0002-4397-7212
FU Natural Science Foundation of Liaoning Province [2021-MS-272]; Education
   Department of Liaoning Province [LJKQZ2021088]
FX AcknowledgementsThis work was supported in part by the Natural Science
   Foundation of Liaoning Province under Grant 2021-MS-272; Education
   Department of Liaoning Province under Grant LJKQZ2021088. Thanks to
   Dongmei Guo, professor of the Second Affiliated Hospital of Dalian
   Medical University, for providing clinical hospital data for this paper.
CR Ambati L. S., 2021, AMCIS
   Ambati LS., 2019, J MIDWEST ASS INF SY, V2021, P49, DOI DOI 10.17705/3JMWA.000065
   Amritha PP, 2021, ANN HEPATO-BIL-PANCR, V25, P160, DOI 10.14701/ahbps.2021.25.1.160
   Ayadi W, 2022, PROCEEDINGS OF THE 2022 5TH INTERNATIONAL CONFERENCE ON ADVANCED SYSTEMS AND EMERGENT TECHNOLOGIES IC_ASET'2022), P285, DOI 10.1109/IC_ASET53395.2022.9765885
   Chahal PK, 2023, NEURAL COMPUT APPL, V35, P23877, DOI 10.1007/s00521-021-06010-w
   Chakravarty A, 2017, COMPUT METH PROG BIO, V147, P51, DOI 10.1016/j.cmpb.2017.06.004
   Chen JW, 2021, SOFT COMPUT, V25, P15021, DOI 10.1007/s00500-021-06391-z
   Chen Y, 2022, EXPERT SYST APPL, V194, DOI 10.1016/j.eswa.2022.116511
   Chowdhary CL, 2017, J BIOMIM BIOMATER BI, V30, P12, DOI 10.4028/www.scientific.net/JBBBE.30.12
   Currie S, 2016, POSTGRAD MED J, V92, P41, DOI 10.1136/postgradmedj-2014-133211
   Dahiya P, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5465279
   Dawod AY., 2021, ENG LET, V29, P795
   De U., 2018, Int. J. Eng. Technol., V7, P1801, DOI [10.14419/ijet.v7i3.12425, DOI 10.14419/IJET.V7I3.12425]
   Deng Y, 2021, NEUROL SCI, V42, P141, DOI 10.1007/s10072-020-04515-1
   Dong JJ, 2021, SCI PROGRAMMING-NETH, V2021, DOI 10.1155/2021/7880477
   El-Gayar OmarF., 2020, BIG DATAS POTENTIAL, P104, DOI DOI 10.4018/978-1-5225-9687-5.CH005
   Eusuff MM, 2003, J WATER RES PLAN MAN, V129, P210, DOI 10.1061/(ASCE)0733-9496(2003)129:3(210)
   Fang LL, 2022, BIOMED SIGNAL PROCES, V76, DOI 10.1016/j.bspc.2022.103709
   Fang LL, 2020, SOFT COMPUT, V24, P18611, DOI 10.1007/s00500-020-05097-y
   Frassanito P, 2021, CHILD NERV SYST, V37, P3465, DOI 10.1007/s00381-021-05158-z
   Gunasekara SR, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/6695108
   Hashim FA, 2021, APPL INTELL, V51, P1531, DOI 10.1007/s10489-020-01893-z
   Hassan N.S., 2021, Asian Journal of Research in Computer Science, V9, P23, DOI [10.9734/ajrcos/2021/v9i130212, DOI 10.9734/AJRCOS/2021/V9I130212]
   He JW, 2019, MULTIMED TOOLS APPL, V78, P8669, DOI 10.1007/s11042-018-5952-2
   Hooda H, 2022, MULTIMED TOOLS APPL, V81, P29633, DOI 10.1007/s11042-022-12336-x
   Hssayeni MD, 2020, DATA, V5, DOI 10.3390/data5010014
   Kollem S, 2021, MULTIMED TOOLS APPL, V80, P409, DOI 10.1007/s11042-020-09675-y
   Krishnakumar S, 2021, J AMB INTEL HUM COMP, V12, P6751, DOI 10.1007/s12652-020-02300-8
   Kumar Adesh, 2021, International Journal of Organizational and Collective Intelligence, V11, P1, DOI 10.4018/IJOCI.2021070105
   Lai X, 2019, BIOCHEM BIOPH RES CO, V519, P721, DOI 10.1016/j.bbrc.2019.09.057
   Li K, 2021, FRONT NEUROL, V12, DOI 10.3389/fneur.2021.608403
   Li L, 2021, IEEE J BIOMED HEALTH, V25, P1646, DOI 10.1109/JBHI.2020.3028243
   Maruyama T, 2021, RADIOL PHYS TECHNOL, V14, P358, DOI 10.1007/s12194-021-00633-3
   Nomura Y, 2021, INT J COMPUT ASS RAD, V16, P1901, DOI 10.1007/s11548-021-02504-z
   Ouchicha C, 2023, EVOL INTELL, V16, P651, DOI 10.1007/s12065-021-00689-5
   Pratondo A, 2017, J VIS COMMUN IMAGE R, V43, P1, DOI 10.1016/j.jvcir.2016.11.019
   Reddy KR, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13020312
   Ruan WW, 2020, EJNMMI RES, V10, DOI 10.1186/s13550-020-00648-8
   Sai Ambati L., 2020, Issues Inform Syst, V21, P103
   Sawlani V, 2020, INSIGHTS IMAGING, V11, DOI 10.1186/s13244-020-00888-1
   Saxena S, 2021, INT J HEALTHC INF SY, V16, P1, DOI 10.4018/IJHISI.20210701.oa1
   Shimony N, 2021, ACTA NEUROL BELG, V121, P823, DOI 10.1007/s13760-021-01626-0
   Shivhare SN, 2019, MULTIMED TOOLS APPL, V78, P34207, DOI 10.1007/s11042-019-08048-4
   Sirisha P. G. K., 2021, IOP Conference Series: Materials Science and Engineering, V1074, DOI 10.1088/1757-899X/1074/1/012001
   Srikrishna M, 2022, FRONT COMPUT NEUROSC, V15, DOI 10.3389/fncom.2021.785244
   Vishnuvarthanan G, 2016, APPL SOFT COMPUT, V38, P190, DOI 10.1016/j.asoc.2015.09.016
   Wang QY, 2021, BIOMED RES INT, V2021, DOI 10.1155/2021/9962905
   Xu LQ, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/6536294
   Zheng J, 2022, ABDOM RADIOL, V47, P85, DOI 10.1007/s00261-021-03321-3
   Zhou XY, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2021.114566
   Zhu GY, 2017, APPL SOFT COMPUT, V51, P294, DOI 10.1016/j.asoc.2016.11.047
NR 51
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 17
PY 2023
DI 10.1007/s11042-023-15781-4
EA MAY 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7EQ1
UT WOS:000990751100005
DA 2024-07-18
ER

PT J
AU Wang, B
   Song, Y
   Wang, FM
   Zhao, Y
   Shu, XB
   Rui, Y
AF Wang, Bin
   Song, Yan
   Wang, Fanming
   Zhao, Yang
   Shu, Xiangbo
   Rui, Yan
TI Dilation-erosion for single-frame supervised temporal action
   localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Temporal action localization; Single-frame supervision;
   Dilation-Erosion; Convolutional neural network
AB To balance the annotation labor and the granularity of supervision, single-frame annotation has been introduced in temporal action localization. It provides a rough temporal location for an action but implicitly overstates the supervision from the annotated-frame during training, leading to the confusion between actions and backgrounds, i.e., action incompleteness and background false positives. To tackle the two challenges, in this work, we present the Snippet Classification model and the Dilation-Erosion module. In the Dilation-Erosion module, we expand the potential action segments with a loose criterion to alleviate the problem of action incompleteness and then remove the background from the potential action segments to alleviate the problem of action incompleteness. Relying on the single-frame annotation and the output of the snippet classification, the Dilation-Erosion module mines pseudo snippet-level ground-truth, hard backgrounds and evident backgrounds, which in turn further trains the Snippet Classification model. It forms a cyclic dependency. Furthermore, we propose a new embedding loss to aggregate the features of action instances with the same label and separate the features of actions from backgrounds. Experiments on THUMOS14 and ActivityNet 1.2 validate the effectiveness of the proposed method. Code has been made publicly available (https://github.com/LingJun123/single-frame-TAL).
C1 [Wang, Bin; Song, Yan; Zhao, Yang; Shu, Xiangbo; Rui, Yan] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Wang, Fanming] Nanjing Xidao Culture Commun Ltd, Nanjing 210094, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Song, Y (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM lingjun@njust.edu.cn; songyan@njust.edu.cn; 527288991@qq.com;
   zhaoyang@njust.edu.cn; shuxb@njust.edu.cn; ruiyan@njust.edu.cn
RI Rui, Yan/KEI-1307-2024
OI Song, Yan/0000-0001-8431-7037
FU National Key R&D Program of China [2018AAA0102002]; National Natural
   Science Foundation of China [61672285, 62072245, 61932020]
FX This work was supported by National Key R & D Program of China (No.
   2018AAA0102002), the National Natural Science Foundation of China (Grant
   No. 61672285, 62072245, and 61932020).
CR Bearman Amy, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9911, P549, DOI 10.1007/978-3-319-46478-7_34
   Bojanowski P, 2013, IEEE I CONF COMP VIS, P2280, DOI 10.1109/ICCV.2013.283
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chao YW, 2018, PROC CVPR IEEE, P1130, DOI 10.1109/CVPR.2018.00124
   Cheplygina V, 2019, MED IMAGE ANAL, V54, P280, DOI 10.1016/j.media.2019.03.009
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Deng ST, 2021, IEEE T IMAGE PROCESS, V30, P1556, DOI 10.1109/TIP.2020.3045636
   Ding XP, 2020, Arxiv, DOI arXiv:2007.01598
   Fan Ma, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P420, DOI 10.1007/978-3-030-58548-8_25
   Fang F, 2020, IEEE T IMAGE PROCESS, V29, P2052, DOI 10.1109/TIP.2019.2947792
   Fu LY, 2022, IEEE T NEUR NET LEAR, V33, P130, DOI 10.1109/TNNLS.2020.3027588
   Fukui H, 2019, PROC CVPR IEEE, P10697, DOI 10.1109/CVPR.2019.01096
   Gao JY, 2017, Arxiv, DOI arXiv:1705.01180
   Gao JY, 2017, IEEE I CONF COMP VIS, P3648, DOI 10.1109/ICCV.2017.392
   Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Laradji IH, 2019, Arxiv, DOI arXiv:1906.06392
   Heilbron FC, 2017, PROC CVPR IEEE, P3175, DOI 10.1109/CVPR.2017.338
   Huang ZL, 2018, PROC CVPR IEEE, P7014, DOI 10.1109/CVPR.2018.00733
   Idrees H, 2017, COMPUT VIS IMAGE UND, V155, P1, DOI 10.1016/j.cviu.2016.10.018
   Islam A, 2020, IEEE WINT CONF APPL, P536, DOI 10.1109/WACV45572.2020.9093620
   Jain M, 2014, PROC CVPR IEEE, P740, DOI 10.1109/CVPR.2014.100
   Kalchbrenner N, 2016, Arxiv, DOI arXiv:1507.01526
   Kingma D. P., 2014, arXiv
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Laradji IH, 2018, LECT NOTES COMPUT SC, V11206, P560, DOI 10.1007/978-3-030-01216-8_34
   Lee P, 2020, AAAI CONF ARTIF INTE, V34, P11320
   Lin CM, 2021, PROC CVPR IEEE, P3319, DOI 10.1109/CVPR46437.2021.00333
   Lin TW, 2018, LECT NOTES COMPUT SC, V11208, P3, DOI 10.1007/978-3-030-01225-0_1
   Lin TW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P988, DOI 10.1145/3123266.3123343
   Liu DC, 2019, PROC CVPR IEEE, P1298, DOI 10.1109/CVPR.2019.00139
   Liu YF, 2019, PROC CVPR IEEE, P7099, DOI [10.1109/CVPR.2019.00726, 10.1109/CVPR.2019.00372]
   Liu ZY, 2019, IEEE I CONF COMP VIS, P3898, DOI 10.1109/ICCV.2019.00400
   Long FC, 2019, PROC CVPR IEEE, P344, DOI 10.1109/CVPR.2019.00043
   Ma SG, 2016, PROC CVPR IEEE, P1942, DOI 10.1109/CVPR.2016.214
   Moltisanti D, 2019, PROC CVPR IEEE, P9907, DOI 10.1109/CVPR.2019.01015
   Narayan S, 2019, IEEE I CONF COMP VIS, P8678, DOI 10.1109/ICCV.2019.00877
   Paul S, 2018, LECT NOTES COMPUT SC, V11208, P588, DOI 10.1007/978-3-030-01225-0_35
   Peisen Zhao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P539, DOI 10.1007/978-3-030-58598-3_32
   Nguyen PX, 2019, IEEE I CONF COMP VIS, P5501, DOI 10.1109/ICCV.2019.00560
   Rashid M, 2020, IEEE WINT CONF APPL, P604, DOI [10.1109/wacv45572.2020.9093404, 10.1109/WACV45572.2020.9093404]
   Richard A, 2019, IEEE INT CONF COMP V, P1533, DOI 10.1109/ICCVW.2019.00191
   Rui Yan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P208, DOI 10.1007/978-3-030-58598-3_13
   Shi BF, 2020, PROC CVPR IEEE, P1006, DOI 10.1109/CVPR42600.2020.00109
   Shou Z, 2018, LECT NOTES COMPUT SC, V11220, P162, DOI 10.1007/978-3-030-01270-0_10
   Shou Z, 2017, PROC CVPR IEEE, P1417, DOI 10.1109/CVPR.2017.155
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Singh KK, 2017, IEEE I CONF COMP VIS, P3544, DOI 10.1109/ICCV.2017.381
   Su H., 2018, P AS C COMP VIS, P558
   Su R, 2021, IEEE T IMAGE PROCESS, V30, P2103, DOI 10.1109/TIP.2020.3044218
   Vaudaux-Ruth G, 2021, IEEE WINT CONF APPL, P1268, DOI 10.1109/WACV48630.2021.00131
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang LM, 2017, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2017.678
   Yan R, 2023, IEEE T PATTERN ANAL, V45, P6955, DOI 10.1109/TPAMI.2020.3034233
   Yan R, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1292, DOI 10.1145/3240508.3240572
   Yang L, 2020, IEEE T IMAGE PROCESS, V29, P8535, DOI 10.1109/TIP.2020.3016486
   Yang S, 2013, INT CONF ACOUST SPEE, P2415, DOI 10.1109/ICASSP.2013.6638088
   Ye QL, 2019, IEEE T NEUR NET LEAR, V30, P3818, DOI 10.1109/TNNLS.2019.2944869
   Yu T, 2019, IEEE I CONF COMP VIS, P5521, DOI 10.1109/ICCV.2019.00562
   Yuan J, 2016, PROC CVPR IEEE, P3093, DOI 10.1109/CVPR.2016.337
   Yuan ZH, 2017, PROC CVPR IEEE, P3215, DOI 10.1109/CVPR.2017.342
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zeng RH, 2019, IEEE I CONF COMP VIS, P7093, DOI 10.1109/ICCV.2019.00719
   Zeng RH, 2019, IEEE T IMAGE PROCESS, V28, P5797, DOI 10.1109/TIP.2019.2922108
   Zhao T, 2021, INT J COMPUT VISION, V129, P2474, DOI 10.1007/s11263-021-01473-9
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
   Zhekun Luo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12374), P729, DOI 10.1007/978-3-030-58526-6_43
   Zhong JX, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P35, DOI 10.1145/3240508.3240511
NR 69
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 16
PY 2023
DI 10.1007/s11042-023-15196-1
EA MAY 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G5FI8
UT WOS:000989408100008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Abdel-Hamid, L
AF Abdel-Hamid, Lamiaa
TI Multiresolution analysis for COVID-19 diagnosis from chest CT images:
   wavelet vs. contourlet transforms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE COVID-19; Chest CT images; Classification; Contourlet transform; Wavelet
   transform
ID TEXTURE CLASSIFICATION; ALGORITHMS; FAMILIES
AB Chest computer tomography (CT) provides a readily available and efficient tool for COVID-19 diagnosis. Wavelet and contourlet transforms have the advantages of being localized in both space and time. In addition, multiresolution analysis allows for the separation of relevant image information in the different subbands. In the present study, transform-based features were investigated for COVID-19 classification using chest CT images. Several textural and statistical features were computed from the approximation and detail subbands in order to fully capture disease symptoms in the chest CT images. Initially, multiresolution analysis was performed considering three different wavelet and contourlet levels to determine the transform and decomposition level most suitable for feature extraction. Analysis showed that contourlet features computed from the first decomposition level (L1) led to the most reliable COVID-19 classification results. The complete feature vector was computed in less than 25 ms for a single image having of resolution 256 x 256 pixels. Next, particle swarm optimization (PSO) was implemented to find the best set of L1-Contourlet features for enhanced performance. Accuracy, sensitivity, specificity, precision, and F-score of a 100% were achieved by the reduced feature set using the support vector machine (SVM) classifier. The presented contourlet-based COVID-19 detection method was also shown to outperform several state-of-the-art deep learning approaches from literature. The present study demonstrates the reliability of transform-based features for COVID-19 detection with the advantage of reduced computational complexity. Transform-based features are thus suitable for integration within real-time automatic screening systems used for the initial screening of COVID-19.
C1 [Abdel-Hamid, Lamiaa] Misr Int Univ MIU, Fac Engn, Dept Elect & Commun, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Misr International University
RP Abdel-Hamid, L (corresponding author), Misr Int Univ MIU, Fac Engn, Dept Elect & Commun, Cairo, Egypt.
EM Lamiaa.a.hamid@miuegypt.edu.eg
OI Abdel-Hamid, Lamiaa/0000-0002-4066-6021
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Abdel-Hamid L, 2017, RETINAL IMAGE ANAL U
   Abdel-Hamid L, 2022, INT J IMAG SYST TECH, V32, P387, DOI 10.1002/ima.22621
   Abdel-Hamid L, 2020, J DIGIT IMAGING, V33, P151, DOI 10.1007/s10278-019-00189-0
   Abdel-Hamid L, 2018, SIGNAL IMAGE VIDEO P, V12, P9, DOI 10.1007/s11760-017-1124-5
   Abdel-Hamid L, 2016, J BIOMED OPT, V21, DOI 10.1117/1.JBO.21.9.096007
   Aggarwal P, 2022, COMPUT BIOL MED, V144, DOI 10.1016/j.compbiomed.2022.105350
   Ahuja S, 2021, APPL INTELL, V51, P571, DOI 10.1007/s10489-020-01826-w
   Al-Saffar ZA, 2020, IEEE ACCESS, V8, P52575, DOI 10.1109/ACCESS.2020.2980728
   Ali TF, 2020, EGYPT J RADIOL NUC M, V51, DOI 10.1186/s43055-020-00245-8
   Angelov P, 2020, medRxiv, DOI [10.1101/2020.04.24.20078584, 10.1101/2020.04.24.20078584, DOI 10.1101/2020.04.24.20078584]
   Avci E, 2008, APPL SOFT COMPUT, V8, P225, DOI 10.1016/j.asoc.2007.01.003
   Bhuyan HK, 2021, INTERNET MED THINGS, V55
   Bozkurt F, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6725
   Centers for Disease Control and Prevention (CDC), SYMPT COR
   Chen Y., 2021, COVID-19: Prediction, Decision-Making, and Its Impacts, P47, DOI DOI 10.1007/978-981-15-9682-76
   Clausi DA, 2002, CAN J REMOTE SENS, V28, P45, DOI 10.5589/m02-004
   COIFMAN RR, 1992, IEEE T INFORM THEORY, V38, P713, DOI 10.1109/18.119732
   CONNERS RW, 1984, COMPUT VISION GRAPH, V25, P273, DOI 10.1016/0734-189X(84)90197-X
   Cucinotta Domenico, 2020, Acta Biomed, V91, P157, DOI 10.23750/abm.v91i1.9397
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Dogantekin A, 2019, MEASUREMENT, V137, P332, DOI 10.1016/j.measurement.2019.01.060
   Dong D, 2021, IEEE REV BIOMED ENG, V14, P16, DOI 10.1109/RBME.2020.2990959
   Dumic E, 2009, PROCSPIE
   Elelimy E, 2018, PROCEEDINGS OF 2018 13TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), P299, DOI 10.1109/ICCES.2018.8639219
   Gao ZG, 2008, IEEE T CIRC SYST VID, V18, P910, DOI 10.1109/TCSVT.2008.920744
   Garg A, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116540
   Gaur P, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103076
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Hanif M., 2010, Universities Power Engineering Conference (UPEC), 2010 45th International (p, P1
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Hicks SA, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09954-8
   Islam MR, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116554
   Ismael AM, 2020, HEALTH INF SCI SYST, V8, DOI 10.1007/s13755-020-00116-6
   Jaiswal A, 2021, J BIOMOL STRUCT DYN, V39, P5682, DOI 10.1080/07391102.2020.1788642
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khan MA, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/4254631
   Kutlu H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19091992
   Liang S, 2022, APPL SOFT COMPUT, V125, DOI 10.1016/j.asoc.2022.109111
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu Q, 2020, IEEE ACCESS, V8, P213718, DOI 10.1109/ACCESS.2020.3040245
   Mary Shyni H, 2022, Comput Methods Programs Biomed Update, V2, P100054, DOI 10.1016/j.cmpbup.2022.100054
   mathworks, DISCR 2 D WAV TRANSF
   Mathworks, 2021, WAV FAM
   Matsuyama E., 2020, J. Biomed. Sci. Eng., V13, P140, DOI DOI 10.4236/JBISE.2020.137014
   mayoclinic, COVID 19 DIAGN TEST
   Minh Do o., CONTOURLET TOOLBOX
   Ning W., 2020, iCTCF: an integrative resource of chest computed tomography images and clinical features of patients with COVID-19 pneumonia
   Pathak Y, 2021, IEEE ACM T COMPUT BI, V18, P1234, DOI 10.1109/TCBB.2020.3009859
   Qiu JJ, 2018, J MED IMAG HEALTH IN, V8, P1539, DOI 10.1166/jmihi.2018.2507
   Radiology Assistant, 2020, COVID 19 IM FIND
   Radiopaedia, 2021, CASES
   Ragab DA, 2020, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.306
   Sahidan SI, 2008, IFMBE PROC, V21, P583
   Sarker Iqbal H, 2021, SN Comput Sci, V2, P420, DOI 10.1007/s42979-021-00815-1
   Semler L, 2005, COMP MED SY, P265, DOI 10.1109/CBMS.2005.105
   Stolojescu C, 2010, P INT CONF OPTIM EL, P932, DOI 10.1109/OPTIM.2010.5510403
   Tan HB, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76141-y
   Tayarani NMH, 2021, CHAOS SOLITON FRACT, V142, DOI 10.1016/j.chaos.2020.110338
   Uppuluri A., 2008, Glcm texture features
   Worldometer, Coronavirus statistics
   Xue B, 2014, APPL SOFT COMPUT, V18, P261, DOI 10.1016/j.asoc.2013.09.018
   Yao X., 2021, COVID 19 DETECTION V, P69
   Zhou YY, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0241469
NR 64
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 12
PY 2023
DI 10.1007/s11042-023-15485-9
EA MAY 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G0SA7
UT WOS:000986346600001
PM 37362648
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Wang, XY
   Wang, XQ
   Niu, PP
   Yang, HY
AF Wang, Xiang-yang
   Wang, Xing-qi
   Niu, Pan-pan
   Yang, Hong-ying
TI Accurate and robust image copy-move forgery detection using adaptive
   keypoints and FQGPCET-GLCM feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE CMFD; Adaptive keypoints; FQGPCET; Robust hybrid feature; DBQ-LSH;
   Two-step filtering and clustering
ID OF-THE-ART; DIGITAL IMAGES
AB With the rapid development of image editing software, forged images have become a serious social problem because of their great destructiveness. Copy-move is one of the most commonly used types of forgery. The keypoint-based copy-move forgery detection (CMFD) techniques identify forged regions by extracting image keypoints and using local visual features. These methods show remarkable detection capability in some areas, such as memory requirements and computational cost. After years of research, the challenges of the current keypoint-based methods are as follows: 1) The number or distribution of extracted keypoints is not satisfactory, especially in smoothed and textured areas. 2) Many local visual features have poor robustness to geometric attacks and post-processing disturbances, which fundamentally limits the performance of algorithms. 3) The existing post-processing algorithms can't effectively filter out false matched pairs and accurately locate the tampered areas. To overcome these problems, an accurate and robust image copy-move forgery detection method using adaptive keypoints and hybrid features is proposed. Firstly, an adaptive keypoint extraction method based on the simple linear iterative clustering (SLIC) and the K-multiple-means (KMM) is proposed, which can extract the dense and uniform keypoints in the whole image. Then, we combine the transform domain features based on the Fast Quaternion Generic Polar Complex Exponential Transform (FQGPCET) and the texture features based on the Gray-level co-occurrence matrix (GLCM) to obtain the robust hybrid features. The hybrid features have outstanding descriptive power. Then the feature matching is performed by the double-bit quantized locally sensitive hash (DBQ-LSH). Finally, a high-precision post-processing algorithm includes two-step filtering and two-step clustering is proposed. The experimental results demonstrate that the overall performance of the proposed algorithm is superior to that of other solutions for detecting copy-move forgery images.
C1 [Wang, Xiang-yang; Wang, Xing-qi; Niu, Pan-pan; Yang, Hong-ying] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Wang, XY; Yang, HY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com; yhy_65@126.com
RI xie, jing/KDO-9486-2024; Yang, Jing/JFK-4046-2023; Niu,
   Panpan/Q-9953-2017
OI Yang, Jing/0009-0004-8274-9863; 
FU National Natural Science Foundation of China [61472171, 61701212]; Key
   Scientific Research Project of Liaoning Provincial Education Department
   [LJKZZ20220115]; Scientific Research Project of Liaoning Provincial
   Education Department [LJKMZ20221420]
FX AcknowledgmentsThis work was supported partially by the National Natural
   Science Foundation of China (Nos. 61472171 & 61701212), Key Scientific
   Research Project of Liaoning Provincial Education Department (No.
   LJKZZ20220115), and Scientific Research Project of Liaoning Provincial
   Education Department (No. LJKMZ20221420).
CR Abdel-Basset M, 2020, MULTIMED TOOLS APPL, V79, P5419, DOI [10.1007/s11042-018-6266-0, 10.1007/s11042-018-5840-9]
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Anbu T, 2021, MULTIMED TOOLS APPL, V80, P2713, DOI 10.1007/s11042-020-09585-z
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Barni M, 2021, IEEE T INF FOREN SEC, V16, P1825, DOI 10.1109/TIFS.2020.3045903
   Chang IC, 2013, IMAGE VISION COMPUT, V31, P57, DOI 10.1016/j.imavis.2012.09.002
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Emam M, 2016, MULTIMED TOOLS APPL, V75, P11513, DOI 10.1007/s11042-015-2872-2
   Fadl SM, 2017, NEUROCOMPUTING, V265, P57, DOI 10.1016/j.neucom.2016.11.091
   Fridrich AJ, 2013, P DIGITAL FORENSIC R, P55
   Gan YN, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102783
   Gani G, 2021, MULTIMED TOOLS APPL, V80, P32219, DOI 10.1007/s11042-021-11174-7
   Gani G, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102510
   Garg M, 2021, NEURAL COMPUT APPL, V33, P1311, DOI 10.1007/s00521-020-05017-z
   Hailing Huang, 2008, 2008 Pacific-Asia Workshop on Computational Intelligence and Industrial Application. PACIIA 2008, P272, DOI 10.1109/PACIIA.2008.240
   Hoang TV, 2011, IEEE IMAGE PROC, P829, DOI 10.1109/ICIP.2011.6116685
   Johansson H., 2014, ACAD PRESS LIB SIGNA, V1, P169, DOI [10.1016/B978-0-12-396502-8.00005-X, DOI 10.1016/B978-0-12-396502-8.00005-X]
   Jwaid MF, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, CONTROL AND AUTOMATION (ICCUBEA)
   Kalsi DK, 2017, 2017 INTERNATIONAL CONFERENCE ON RECENT INNOVATIONS IN SIGNAL PROCESSING AND EMBEDDED SYSTEMS (RISE), P284, DOI 10.1109/RISE.2017.8378168
   Kim KS, 2013, I SYMP CONSUM ELECTR, P259
   Kong Weihao., 2012, AAAI
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li YM, 2019, IEEE T INF FOREN SEC, V14, P1307, DOI 10.1109/TIFS.2018.2876837
   Liu YQ, 2018, MULTIMED TOOLS APPL, V77, P18269, DOI 10.1007/s11042-017-5374-6
   Lyu QY, 2021, J VIS COMMUN IMAGE R, V76, DOI 10.1016/j.jvcir.2021.103057
   Mahmood T, 2018, J VIS COMMUN IMAGE R, V53, P202, DOI 10.1016/j.jvcir.2018.03.015
   Nie FP, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P959, DOI 10.1145/3292500.3330846
   Niu P, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103068
   Priyanka, 2020, MULTIMED TOOLS APPL, V79, P13011, DOI 10.1007/s11042-019-08354-x
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Sadeghi S, 2018, PATTERN ANAL APPL, V21, P291, DOI 10.1007/s10044-017-0678-8
   Soni B, 2018, IET IMAGE PROCESS, V12, P2092, DOI 10.1049/iet-ipr.2018.5576
   Soni B, 2018, IET IMAGE PROCESS, V12, P167, DOI 10.1049/iet-ipr.2017.0441
   Tahaoglu G, 2021, MULTIMED TOOLS APPL, V80, P23419, DOI 10.1007/s11042-020-10241-9
   Wang XY, 2021, PATTERN ANAL APPL, V24, P1025, DOI 10.1007/s10044-021-00968-y
   Wang XY, 2020, MULTIDIM SYST SIGN P, V31, P857, DOI 10.1007/s11045-019-00688-x
   Wang XY, 2018, APPL INTELL, V48, P3630, DOI 10.1007/s10489-018-1168-4
   Wang XY, 2018, PATTERN ANAL APPL, V21, P451, DOI 10.1007/s10044-016-0588-1
   Wang YL, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102536
   Wang Y, 2017, IEEE INT SYM MULTIM, P553, DOI 10.1109/ISM.2017.108
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu Y, 2018, IEEE WINT CONF APPL, P1907, DOI 10.1109/WACV.2018.00211
   Yang HY, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115747
   Yang JX, 2021, DIGIT SIGNAL PROCESS, V113, DOI 10.1016/j.dsp.2021.103032
   Zhong JL, 2020, IEEE T INF FOREN SEC, V15, P2134, DOI 10.1109/TIFS.2019.2957693
   Zhong JL, 2020, INFORM SCIENCES, V512, P675, DOI 10.1016/j.ins.2019.09.085
NR 49
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 12
PY 2023
DI 10.1007/s11042-023-15499-3
EA MAY 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G0SA7
UT WOS:000986346600006
DA 2024-07-18
ER

PT J
AU Wang, HC
   Lu, HX
   Guo, HM
   Jian, HF
   Gan, C
   Liu, W
AF Wang, Hongchang
   Lu, Huaxiang
   Guo, Huimin
   Jian, Haifang
   Gan, Chuang
   Liu, Wu
TI Bird-Count: a multi-modality benchmark and system for bird population
   counting in the wild
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Benchmark; Bird population counting; Morphology prior knowledge;
   Ecosystem conservation; Monitoring system
ID CROWD
AB The fluctuation of the bird population reflects the change in the ecosystem, which plays a vital role in ecosystem conservation. However, manual counting is still the mainstream method for bird population counting, which is time-consuming and laborious. One major bottleneck in developing efficient, accurate, and intelligent learning algorithms to counting birds is the lack of large-scale datasets. In this paper, the first large-scale bird population counting dataset, named Bird-Count, with multi-modality morphology annotations is proposed. This paper first evaluates various state-of-the-art (SOTA) models for crowd counting on the Bird-Count and gets poor results. The reason is that the forms, appearances, and postures among different birds are more variant than the crowd. To mitigate these challenges, a simple yet effective plug-and-play framework, called Morphology Prior Knowledge Fusion Network (MPKNet), which can be used on-site to help generate a high-precision bird population density map by incorporating morphological prior knowledge, is proposed. Comprehensive evaluations show that the proposed method can reduce the error rate by 6.02% compared with the current SOTA crowd counting algorithms on average. Moreover, with the above technologies, the intelligent bird population monitoring system is deployed in several important wetland national nature reserves for bird protection.
C1 [Wang, Hongchang; Lu, Huaxiang; Guo, Huimin; Jian, Haifang] Chinese Acad Sci, Inst Semicond, Beijing, Peoples R China.
   [Wang, Hongchang; Guo, Huimin] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Lu, Huaxiang] Univ Chinese Acad Sci, Mat & Optoelect Res Ctr, Beijing, Peoples R China.
   [Lu, Huaxiang] Univ Chinese Acad Sci, Coll Microelect, Beijing, Peoples R China.
   [Gan, Chuang] MIT IBM Watson Lab, Cambridge, MA USA.
   [Liu, Wu] Explore Acad JD com, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Semiconductors, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; University of Chinese Academy of
   Sciences, CAS
RP Lu, HX (corresponding author), Chinese Acad Sci, Inst Semicond, Beijing, Peoples R China.; Lu, HX (corresponding author), Univ Chinese Acad Sci, Mat & Optoelect Res Ctr, Beijing, Peoples R China.; Lu, HX (corresponding author), Univ Chinese Acad Sci, Coll Microelect, Beijing, Peoples R China.
EM hcwang@semi.ac.cn; luhx@semi.ac.cn; ghm@semi.ac.cn; jhf@semi.ac.cn;
   ganchuang1990@gmail.com; liuwu@live.cn
RI Huaxiang, Lu/AGC-0970-2022
FU Chinese Academy of Sciences (CAS) [CAS-WX2021SF-0501]; National Natural
   Science Foundation of China (NSFC) [U19A2080, U1936106]; Leading Project
   of the Chinese Academy of Sciences (CAS) [XDA27040303, XDA18040400,
   XDB44000000]; High Technology Project [31513070501, 1916312ZD00902201]
FX This study is funded by the Chinese Academy of Sciences
   (CAS)(CAS-WX2021SF-0501), the National Natural Science Foundation of
   China (NSFC) (U19A2080, U1936106), the Leading Project of the Chinese
   Academy of Sciences (CAS)(XDA27040303, XDA18040400, XDB44000000), and
   the High Technology Project (31513070501, 1916312ZD00902201).
CR Agrawal D, 2021, IEEE 15TH INTERNATIONAL SYMPOSIUM ON APPLIED COMPUTATIONAL INTELLIGENCE AND INFORMATICS (SACI 2021), P199, DOI 10.1109/SACI51354.2021.9465609
   Arteta C, 2016, LECT NOTES COMPUT SC, V9911, P483, DOI 10.1007/978-3-319-46478-7_30
   Buckland ST, 2006, AUK, V123, P345, DOI 10.1642/0004-8038(2006)123[345:PSFSRM]2.0.CO;2
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Chakraborty R, 2021, J AMB INTEL HUM COMP, V12, P7793, DOI 10.1007/s12652-020-02506-w
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Chen L, 2021, MULTIMED TOOLS APPL, V80, P6661, DOI 10.1007/s11042-020-10002-8
   Devi D, 2020, INT J DATA WAREHOUS, V16, P60, DOI 10.4018/IJDWM.2020070104
   Doreswamy, 2020, CAAI T INTELL TECHNO, V5, P283, DOI 10.1049/trit.2020.0073
   Fu HY, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P877, DOI 10.1145/2647868.2655040
   Grenzdorffer G., 2013, INT ARCH PHOTOGRAMM, V1, P2
   Huang SY, 2020, INT CONF ACOUST SPEE, P2578, DOI [10.1109/icassp40776.2020.9053070, 10.1109/ICASSP40776.2020.9053070]
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Jiang XL, 2019, PROC CVPR IEEE, P6126, DOI 10.1109/CVPR.2019.00629
   Kasper-Eulaers M, 2021, ALGORITHMS, V14, DOI 10.3390/a14040114
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524
   Ma ZH, 2019, IEEE I CONF COMP VIS, P6141, DOI 10.1109/ICCV.2019.00624
   Meng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3401, DOI 10.1109/CVPR.2011.5995698
   Namasudra S, 2022, IEEE T SERV COMPUT, V15, P2289, DOI 10.1109/TSC.2020.3046471
   Namasudra S, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3392665
   Paszke A, 2019, ADV NEUR IN, V32
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Sebastián-González E, 2018, AVIAN CONSERV ECOL, V13, DOI 10.5751/ACE-01224-130207
   Shen Z, 2018, PROC CVPR IEEE, P5245, DOI 10.1109/CVPR.2018.00550
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan X, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1907, DOI 10.1145/3343031.3350914
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Wang C, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1299, DOI 10.1145/2733373.28063370-12345-67-8/90/01
   Wang Q, 2021, IEEE T PATTERN ANAL, V43, P2141, DOI 10.1109/TPAMI.2020.3013269
   Wu B, 2005, IEEE I CONF COMP VIS, P90
   Yan ZY, 2019, IEEE I CONF COMP VIS, P952, DOI 10.1109/ICCV.2019.00104
   Zeng LK, 2017, IEEE IMAGE PROC, P465, DOI 10.1109/ICIP.2017.8296324
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhou X, 2019, PSYCHOL HEALTH, V34, P811, DOI 10.1080/08870446.2019.1574348
   Zou Z, 2020, MULTIMED TOOLS APPL, V79, P29145, DOI 10.1007/s11042-020-09541-x
NR 41
TC 0
Z9 0
U1 6
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45293
EP 45315
DI 10.1007/s11042-023-14833-z
EA APR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000978530200001
DA 2024-07-18
ER

PT J
AU Ali, U
   Mahmood, MT
AF Ali, Usman
   Mahmood, Muhammad Tariq
TI Enforcing spatially coherent structures in shape from focus
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shape from focus; Focus measure; Guided image filtering; Nonconvex
   optimization
ID 3-DIMENSIONAL SHAPE; DEPTH; RECONSTRUCTION; RECOVERY
AB Most of the depth optimization schemes in shape from focus (SFF) enforce spatial coherence through convex energy functionals which oversmooth depth edges. Further, usually, no additional information about the scene is incorporated while estimating depth. In this work, we tackle the first issue by employing a nonconvex penalty that preserves depth edges effectively. For the second issue, we design a novel guidance map for SFF based on the cross-correlation between image sequence and focus volume (FV). This cross-correlation-based guidance enforces the coherent structures between the image sequence and FV. The proposed regularization framework fuses information from the guidance map, iteratively updated depth map, and the structural similarity between them. The nonconvex objective function has been solved through the majorize-minimization algorithm. An analysis has been presented that indicates the convergence behavior of the solver. Experiments have been conducted using a variety of synthetic and real image sequences. Qualitative and quantitative comparison with state-of-the-art methods indicates that the proposed method provides better depth maps.
C1 [Ali, Usman] Sungkyunkwan Univ, Dept Elect & Comp Engn, 2066 Seobu Ro, Suwon 16419, South Korea.
   [Mahmood, Muhammad Tariq] Korea Univ Technol & Educ, Future Convergence Engn, 1600 Chungjeolno,Byeogchunmyun, Cheonan 31253, Chungcheongnamd, South Korea.
C3 Sungkyunkwan University (SKKU); Korea University of Technology &
   Education
RP Mahmood, MT (corresponding author), Korea Univ Technol & Educ, Future Convergence Engn, 1600 Chungjeolno,Byeogchunmyun, Cheonan 31253, Chungcheongnamd, South Korea.
EM usman.ali@skku.edu; tariq@Koreatech.ac.kr
FU Creative Challenge Research Program - Ministry of Education
   [2021R1I1A1A01052521]; Korea government (MSIT: Ministry of Science and
   ICT) through the National Research Foundation (NRF) of Korea
   [2022R1F1A1071452, 2022R1A4A3033571]
FX This work was supported in parts by Creative Challenge Research Program
   (2021R1I1A1A01052521) funded by the Ministry of Education, by the Basic
   Research Program(2022R1F1A1071452) and Basic Science Research Program
   (2022R1A4A3033571) funded by the Korea government (MSIT: Ministry of
   Science and ICT) through the National Research Foundation (NRF) of
   Korea.
CR Ahmad MB, 2005, IEEE T CIRC SYST VID, V15, P566, DOI 10.1109/TCSVT.2005.844450
   Ali Usman, 2018, 2018 IEEE International Conference on Consumer Electronics - Asia (ICCE-Asia), P206, DOI 10.1109/ICCE-ASIA.2018.8552125
   Ali U, 2021, I C INF COMM TECH CO, P1504, DOI 10.1109/ICTC52510.2021.9621188
   Ali U, 2021, IEEE T IMAGE PROCESS, V30, P7215, DOI 10.1109/TIP.2021.3100268
   Ali U, 2020, J MATH IMAGING VIS, V62, P54, DOI 10.1007/s10851-019-00918-8
   Alicona B, 2022, OPTICAL MEASUREMENT
   [Anonymous], 2009, 19 INT C COMPUTER GR
   Asif M, 2001, IEEE T IMAGE PROCESS, V10, P1670, DOI 10.1109/83.967395
   Boshtayeva M, 2015, PATTERN RECOGN, V48, P3310, DOI 10.1016/j.patcog.2014.10.008
   Ceruso S, 2021, SIGNAL PROCESS-IMAGE, V99, DOI 10.1016/j.image.2021.116417
   Choi TS, 2000, OPT ENG, V39, P1321, DOI 10.1117/1.602498
   Dansereau D, 2022, LIGHT FIELD TOOLBOX
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Fujimura Y, 2022, ARXIV
   Guo XJ, 2020, IEEE T PATTERN ANAL, V42, P694, DOI 10.1109/TPAMI.2018.2883553
   Ham B, 2018, IEEE T PATTERN ANAL, V40, P192, DOI 10.1109/TPAMI.2017.2669034
   Hazirbas C, 2019, LECT NOTES COMPUT SC, V11363, P525, DOI 10.1007/978-3-030-20893-6_33
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Honauer K, 2017, LECT NOTES COMPUT SC, V10113, P19, DOI 10.1007/978-3-319-54187-7_2
   Huang SJ, 2012, PATTERN ANAL APPL, V15, P189, DOI 10.1007/s10044-010-0197-3
   Javidnia H, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023019
   Mahmood MT, 2012, IEEE T IMAGE PROCESS, V21, P2866, DOI 10.1109/TIP.2012.2186144
   Mairal J, 2015, SIAM J OPTIMIZ, V25, P829, DOI 10.1137/140957639
   Maximov M, 2020, PROC CVPR IEEE, P1068, DOI 10.1109/CVPR42600.2020.00115
   Minhas R, 2009, LECT NOTES COMPUT SC, V5627, P573, DOI 10.1007/978-3-642-02611-9_57
   Moeller M, 2015, IEEE T IMAGE PROCESS, V24, P5369, DOI 10.1109/TIP.2015.2479469
   Muhammad MS, 2012, IEEE T PATTERN ANAL, V34, P564, DOI 10.1109/TPAMI.2011.144
   NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479
   Peng SF, 2021, PATTERN ANAL APPL, V24, P1777, DOI 10.1007/s10044-021-01017-4
   Pertuz S, 2013, PATTERN RECOGN, V46, P1415, DOI 10.1016/j.patcog.2012.11.011
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Saini D, 2017, J KING SAUD UNIV-COM, V29, P116, DOI 10.1016/j.jksuci.2014.12.010
   Shim SO, 2010, PATTERN RECOGN, V43, P3338, DOI 10.1016/j.patcog.2010.05.029
   Sotoca JM, 2019, PATTERN ANAL APPL, V22, P33, DOI 10.1007/s10044-018-0721-4
   SUBBARAO M, 1995, IEEE T PATTERN ANAL, V17, P266, DOI 10.1109/34.368191
   Suwajanakorn S, 2015, PROC CVPR IEEE, P3497, DOI 10.1109/CVPR.2015.7298972
   Tseng CY, 2014, IEEE T CIRC SYST VID, V24, P2063, DOI 10.1109/TCSVT.2014.2358873
   Wang NH., 2021, IEEECVF INT C COMPUT, P12621
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060
   Yang F., 2022, P IEEECVF C COMPUTER, P12642
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
   Zhang Zhihua., 2004, Proceedings of the twenty-first international conference on Machine learning, page, P117
NR 43
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36431
EP 36447
DI 10.1007/s11042-023-14984-z
EA MAR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000961632300002
DA 2024-07-18
ER

PT J
AU Sinaga, KBM
   Yudistira, N
   Santoso, E
AF Sinaga, Kenno B. M.
   Yudistira, Novanto
   Santoso, Edy
TI Efficient CNN for high-resolution remote sensing imagery understanding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE EfficientNet; Transfer learning; Freeze layer; Weighted loss; Sparse
   regularization; Pruning
ID CONVOLUTION NETWORK; SCENE
AB The analysis of remote sensing data and the classification of images are complex problems because understanding spatial patterns and intricate geometric structures of the data from which meaningful interrelationship pixels are extracted is essential in the remote sensing community. CNN is one of the Machine Learning methods often used in Remote Sensing problems. However, high-resolution aerial view classification often leverages large-scale data with a huge number of parameters of the CNN model. A large number of parameters makes it hard to be applied to remote imaging peripherals because it requires high capacity of storage and memory. We propose a training framework to solve that problem that produces a model with minimum parameters without sacrificing accuracy. To this end, we train EfficientNet using Weighted Loss of INS to compensate imbalanced classes while keeping the upper layer frozen to preserve essential features deriving from transfer learning. Moreover, we utilize Sparse Regularization on the loss function to make the model focussing on the global object. Finally, as post-training, the trained model is pruned to reduce the number of parameters within the network. Using this method on the AID Dataset, the best results are achieved by EfficientNet-B0 with Freeze 2 Layer, INS Weighted Loss, Sparse regularization with lambda = 0.001, and Global Unstructured Conv2D Pruning with an accuracy of 96.81% on test data with total parameters of 2,463,501. This study proves that Weighted Loss and Sparse Regularization can help the model to improve accuracy while Pruning enhances efficiency by reducing the number of parameters by half without significantly lowering performance.
C1 [Sinaga, Kenno B. M.; Yudistira, Novanto; Santoso, Edy] Brawijaya Univ, Fac Comp Sci, Informat Dept, Jalan Vet 8, Malang 65145, Indonesia.
C3 Brawijaya University
RP Yudistira, N (corresponding author), Brawijaya Univ, Fac Comp Sci, Informat Dept, Jalan Vet 8, Malang 65145, Indonesia.
EM kennosinaga@student.ub.ac.id; yudistira@ub.ac.id; edy144@ub.ac.id
RI Yudistira, Novanto/AAR-9802-2021
OI Yudistira, Novanto/0000-0001-5330-5930
CR [Anonymous], 2015, PROC IEEE C COMPUT V
   Anwer RM, 2018, ISPRS J PHOTOGRAMM, V138, P74, DOI 10.1016/j.isprsjprs.2018.01.023
   Bakara J., 2011, PENELITI BIDANG PENG, V12, P38
   Bi Q, 2020, IEEE T IMAGE PROCESS, V29, P4911, DOI 10.1109/TIP.2020.2975718
   Bi Q, 2020, NEUROCOMPUTING, V377, P345, DOI 10.1016/j.neucom.2019.11.068
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Eberhard O, 2021, ARXIV210204097, P1
   Fernando KRM, 2022, IEEE T NEUR NET LEAR, V33, P2940, DOI 10.1109/TNNLS.2020.3047335
   France J, 2018, HIST WARFARE, V116, P1, DOI 10.1163/9789004349599_002
   Hajizadeh Y, 2018, CAFFENET 1 2
   Hakim L, 2021, PATTERN RECOGN LETT, V149, P83, DOI 10.1016/j.patrec.2021.05.023
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He NJ, 2018, IEEE T GEOSCI REMOTE, V56, P6899, DOI 10.1109/TGRS.2018.2845668
   Hu Q, 2013, REMOTE SENS-BASEL, V5, P6026, DOI 10.3390/rs5116026
   Ide H, 2020, PATTERN RECOGN LETT, V135, P90, DOI 10.1016/j.patrec.2020.03.034
   Ide H, 2017, IEEE IJCNN, P2684, DOI 10.1109/IJCNN.2017.7966185
   Li F, 2020, IEEE T CIRC SYST VID, V30, P1511, DOI 10.1109/TCSVT.2019.2906428
   Liebenwein L., 2021, arXiv
   Lu XQ, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2386
   Mitsuno K, 2021, INT C PATT RECOG, P1089, DOI 10.1109/ICPR48806.2021.9413113
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Petrovska B., 2020, APPL SCI-BASEL, V10, P1
   Romero A, 2016, IEEE T GEOSCI REMOTE, V54, P1349, DOI 10.1109/TGRS.2015.2478379
   Shi CP, 2020, IEEE J-STARS, V13, P5194, DOI 10.1109/JSTARS.2020.3018307
   Shrivastava I., 2020, HANDLING CLASS IMBAL
   Sun H, 2020, IEEE T GEOSCI REMOTE, V58, P82, DOI 10.1109/TGRS.2019.2931801
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Thiodorus G, 2021, PROCEEDINGS OF 2021 INTERNATIONAL CONFERENCE ON SUSTAINABLE INFORMATION ENGINEERING AND TECHNOLOGY, SIET 2021, P301, DOI 10.1145/3479645.3479687
   Torrey Lisa, 2010, Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques, P242
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Xu Z, 2019, Arxiv, DOI arXiv:1909.09712
   Yalcin O, 2020, 4 PRETRAINED CNN MOD
   Yu YL, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/8639367
   Yudistira N, 2020, JURNAL TEKNOLOGI INF, V7
NR 37
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 27
PY 2023
DI 10.1007/s11042-023-14759-6
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F6NF3
UT WOS:000983485500008
DA 2024-07-18
ER

PT J
AU Yao, JA
   Chu, YZ
   Xiang, XJ
   Huang, BQ
   Xiaoli, W
AF Yao, Jiana
   Chu, Yinze
   Xiang, Xinjian
   Huang, Bingqiang
   Xiaoli, Wu
TI Research on detection and classification of traffic signs with data
   augmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic sign detection and recognition system (TSDR); Instance
   segmentation; Object detection; Data augmentation
ID CONVOLUTIONAL NEURAL-NETWORK
AB Traffic Sign Detection and Recognition (TSDR) system is an important part of autonomous driver-assistance systems (ADAS), and a hot topic in computer vision research. With the instance segmentation framework proposed, deep learning has entered a new stage. However, the current traffic sign dataset can only evaluate the performance of object detection framework. In this paper, a new large-scale ZUST Chinese traffic sign dataset benchmark (ZCTSDB) is created to assess the performance of the object detection and instance segmentation framework. ZCTSDB adopts seven different image amplification strategies to enhance the data, which improves the balance of the traffic sign category in the training concentration. The results showed that the average accuracy of ZCTSDB-augmentation object detection and instance segmentation increased by 1.963% and 1.4218%, respectively, especially for large traffic signs. Mask R-CNN has better detection and anti-interference performance than Faster RCNN. The mAP of Mask R-CNN is as high as 74.0580.
C1 [Yao, Jiana; Chu, Yinze; Xiang, Xinjian; Huang, Bingqiang; Xiaoli, Wu] Zhejiang Univ Science&Technol, Sch Automat & Elect Engn, Hangzhou 310023, Peoples R China.
RP Xiang, XJ; Huang, BQ (corresponding author), Zhejiang Univ Science&Technol, Sch Automat & Elect Engn, Hangzhou 310023, Peoples R China.
EM 18817718656@163.com; 1103970509@qq.com; 188002@zust.edu.cn;
   bqhuang@zust.edu.cn; wuxiaoli@zust.edu.cn
FU Zhejiang Public Welfare Technology Application Research Project
   [LGG19F030005]
FX Zhejiang Public Welfare Technology Application Research
   Project(LGG19F030005).
CR Abdi L, 2018, J SIGNAL PROCESS SYS, V90, P1729, DOI 10.1007/s11265-017-1324-9
   Arcos-García A, 2018, NEUROCOMPUTING, V316, P332, DOI 10.1016/j.neucom.2018.08.009
   Chen LC, 2018, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2018.00422
   Cheng P, 2018, LECT NOTES COMPUT SC, V10704, P329, DOI 10.1007/978-3-319-73603-7_27
   Dewi C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060889
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Hafiz AM, 2020, INT J MULTIMED INF R, V9, P171, DOI 10.1007/s13735-020-00195-x
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Houben S, 2013, IEEE INT C INTELL TR, P7, DOI 10.1109/ITSC.2013.6728595
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu HP, 2014, INFORM SCIENCES, V266, P75, DOI 10.1016/j.ins.2014.01.010
   Liu ZG, 2019, IEEE ACCESS, V7, P57120, DOI 10.1109/ACCESS.2019.2913882
   Mogelmose A, 2012, IEEE T INTELL TRANSP, V13, P1484, DOI 10.1109/TITS.2012.2209421
   Nguyen H, 2020, J SENSORS, V2020, DOI 10.1155/2020/8844348
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Serna CG, 2020, IEEE T INTELL TRANSP, V21, P4388, DOI 10.1109/TITS.2019.2941081
   Sharma VK, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100301
   Shi GM, 2021, NEUROCOMPUTING, V426, P70, DOI 10.1016/j.neucom.2020.09.075
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Sun C, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226570
   Wali SB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092093
   Wan JX, 2021, J SIGNAL PROCESS SYS, V93, P899, DOI 10.1007/s11265-020-01614-2
   Wang X., 2020, Advances in Neural information processing systems
   Yang SM, 2020, IEEE T NEUR NET LEAR, V31, P148, DOI 10.1109/TNNLS.2019.2899936
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhang JM, 2017, ALGORITHMS, V10, DOI 10.3390/a10040127
   Zhu Z, 2016, PROC CVPR IEEE, P2110, DOI 10.1109/CVPR.2016.232
NR 29
TC 0
Z9 0
U1 6
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38875
EP 38899
DI 10.1007/s11042-023-14895-z
EA MAR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000983485500013
DA 2024-07-18
ER

PT J
AU Malathi, V
   Manikandan, A
   Krishnan, K
AF Malathi, V.
   Manikandan, A.
   Krishnan, Kalimuthu
TI Optimzied resnet model of convolutional neural network for under sea
   water object detection and classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE ResNetCNN; Underwater images; Detection of objects; SRAD filter;
   Autoencoder; Denoising; Hybrid capuchin-based coevolving particle swarm
   optimization
AB The world's ocean depths conceal a big mystery, and obtaining the information contained therein is a significant challenge that must be overcome. With the advent of computer vision technologies and robotics, the underwater environment is explored recently. The vast data collected from numerous underwater sensors have a variety of complications related to inadequate image quality, difficulty in acquiring training samples, and uncontrolled objects in the underwater environment. When these images are processed using machine learning techniques that involve manual intervention, the time taken to process a huge amount of images will be relatively high and prone to errors. To tackle these, we propose a novel hybrid capuchin-based coevolving particle swarm optimization ((HCPSO)-P-2) algorithm with a ResNet model of Convolutional Neural Network (CNN) architecture for underwater object identification. This work mainly aims to explore different underwater objects such as fish, corals, sea urchins, etc. The speckle-reducing anisotropic diffusion (SRAD) filter performs the pre-processing step. The denoising autoencoder (DA) is used for feature extraction which can enhance the partially distorted sample images and offer increased robustness. To overcome the overfitting issue in CNN, the (HCPSO)-P-2 algorithm is used. The experimental works are handled in MATLAB software. Both with and without pre-processing results in terms of SRAD filter are checked and evaluated. The proposed method's effectiveness is evaluated through various measures like accuracy, specificity, sensitivity, false-positive rate, false-negative rates, etc. The accuracy of the (HCPSO)-P-2-CNN classifier is higher when compared to the standard CNN classifier in recognizing the underwater objects when evaluated with different performance metrics.
C1 [Malathi, V.] Periyar Univ, Dept Comp Sci, Salem, India.
   [Manikandan, A.] Muthayammal Mem Coll Arts & Sci, Dept Comp Sci, Rasipuram, India.
   [Krishnan, Kalimuthu] SRM Inst Sci & Technol, Dept Elect & Commun Engn, Chennai, India.
C3 Periyar University; SRM Institute of Science & Technology Chennai
RP Malathi, V (corresponding author), Periyar Univ, Dept Comp Sci, Salem, India.
EM malathi.vace@gmail.com
CR Berman D, 2021, IEEE T PATTERN ANAL, V43, P2822, DOI 10.1109/TPAMI.2020.2977624
   Braik M, 2021, NEURAL COMPUT APPL, V33, P2515, DOI 10.1007/s00521-020-05145-6
   Chen W, 2020, CHIN AUTOM CONGR, P2821, DOI 10.1109/CAC51589.2020.9326737
   Fayaz S, 2022, MULTIMED TOOLS APPL, V81, P20871, DOI 10.1007/s11042-022-12502-1
   Gehring J, 2013, INT CONF ACOUST SPEE, P3377, DOI 10.1109/ICASSP.2013.6638284
   Han FL, 2020, J SENSORS, V2020, DOI 10.1155/2020/6707328
   Jalled F, 2016, Arxiv, DOI arXiv:1611.07791
   Krohling RA, 2006, IEEE T SYST MAN CY B, V36, P1407, DOI 10.1109/TSMCB.2006.873185
   Kvasic I, 2019, OCEANS-IEEE, DOI 10.1109/oceanse.2019.8867461
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Lin WH, 2020, INT CONF ACOUST SPEE, P2588, DOI [10.1109/icassp40776.2020.9053829, 10.1109/ICASSP40776.2020.9053829]
   Lu HM, 2017, MOBILE NETW APPL, V22, P1204, DOI 10.1007/s11036-017-0863-4
   Lu HM, 2016, IEEE IMAGE PROC, P1998, DOI 10.1109/ICIP.2016.7532708
   Mitra V, 2006, IEEE T NEURAL NETWOR, V17, P717, DOI 10.1109/TNN.2006.873279
   Pan TS, 2021, SIGNAL IMAGE VIDEO P, V15, P941, DOI 10.1007/s11760-020-01818-w
   Qin XM, 2021, IEEE ACCESS, V9, P29416, DOI 10.1109/ACCESS.2021.3052206
   Ranganath HS, 1999, IEEE T NEURAL NETWOR, V10, P615, DOI 10.1109/72.761720
   Shakya Subarna, 2020, J. Innov. Image Process., V2, P44
   Singh Shweta, 2021, Machine Learning and Information Processing. Proceedings of ICMLIP 2020. Advances in Intelligent Systems and Computing (AISC 1311), P153, DOI 10.1007/978-981-33-4859-2_15
   Wang Z., 2020, ARXIV
   Wei XY, 2021, MULTIMED TOOLS APPL, V80, P33747, DOI 10.1007/s11042-021-11230-2
   Yoo H, 2021, IEEE ACCESS, V9, P55802, DOI 10.1109/ACCESS.2021.3068597
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
   Zhang J, 2019, IET COMMUN, V13, P1998, DOI 10.1049/iet-com.2019.0243
   Zhao ZX, 2021, IEEE T IMAGE PROCESS, V30, P4719, DOI 10.1109/TIP.2021.3074738
   Zhiguo Li, 2021, 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2021), P1485, DOI 10.1109/ICASSP39728.2021.9413848
NR 26
TC 1
Z9 1
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 23
PY 2023
DI 10.1007/s11042-023-15041-5
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A5CE8
UT WOS:000955293100002
DA 2024-07-18
ER

PT J
AU Gupta, A
AF Gupta, Abhishek
TI On imaging modalities for cephalometric analysis: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE X-ray; Cephalograms; Cephalometric analysis; Computed tomography (CT);
   Cone beam computed tomography (CBCT); Imaging modality; And
   computer-aided diagnosis
ID BEAM COMPUTED-TOMOGRAPHY; CONE-BEAM; LANDMARK IDENTIFICATION; ANGULAR
   MEASUREMENTS; 3-DIMENSIONAL ANALYSIS; LINEAR ACCURACY; RELIABILITY; 3D;
   REPRODUCIBILITY; IMAGES
AB Cephalometrics is an integral part of orthodontic diagnosis and treatment planning. It has been extensively used to study variation in human face and craniofacial growth. Cephalometrics is an established and valuable tool to assess outcome of orthodontic and orthognathic surgical procedures, follow up and relapse. Cephalometric has also been used a research instrument for huge number of investigations. Cephalometric measurement techniques has progressed over the years from a manual tracing of analog X-Ray film over acetate tracing sheets to the modern practice of on-screen computerized cephalometric analysis on a digital two-dimensional (2-D) image. Cephalometric analysis can also be performed on-screen on image derived from CT scans or CBCT. Each imaging modality is associated with its own quality features of the X-Ray image, and radiation protocol. The objective of this review was to critically analyze diagnostic limitations associated with three types of imaging modality being used for cephalometric analyses. These limitations can vary in terms of accuracy, repeatability, reproducibility, reliability, feasibility of craniofacial landmark localization and radiation exposure to patient.
C1 [Gupta, Abhishek] CSIR Cent Sci Instruments Org, Biomed Applicat Div, Chandigarh 160030, India.
C3 Council of Scientific & Industrial Research (CSIR) - India; CSIR -
   Central Scientific Instruments Organisation (CSIO)
RP Gupta, A (corresponding author), CSIR Cent Sci Instruments Org, Biomed Applicat Div, Chandigarh 160030, India.
EM abhishekgupta10@yahoo.co.in
RI Gupta, Abhishek/O-3016-2019
OI Gupta, Abhishek/0000-0002-8592-9964
CR Adams GL, 2004, AM J ORTHOD DENTOFAC, V126, P397, DOI 10.1016/j.ajodo.2004.03.023
   AHLQVIST J, 1986, EUR J ORTHODONT, V8, P141, DOI 10.1093/ejo/8.3.141
   [Anonymous], 2012, J INF TECHNOL SOFTWA
   BAUMRIND S, 1980, AM J ORTHOD DENTOFAC, V78, P41, DOI 10.1016/0002-9416(80)90039-1
   BAUMRIND S, 1971, AMER J ORTHODONTICS, V60, P111, DOI 10.1016/0002-9416(71)90028-5
   Bayome M, 2013, KOREAN J ORTHOD, V43, P62, DOI 10.4041/kjod.2013.43.2.62
   Berco M, 2009, AM J ORTHOD DENTOFAC, V136, DOI 10.1016/j.ajodo.2008.08.021
   Bholsithi W, 2009, Biomed Imaging Interv J, V5, pe21, DOI 10.2349/biij.5.4.e21
   Brown AA, 2009, ANGLE ORTHOD, V79, P150, DOI 10.2319/122407-599.1
   Cattaneo PM, 2008, AM J ORTHOD DENTOFAC, V134, P798, DOI 10.1016/j.ajodo.2008.07.008
   Cevidanes L, 2009, ANGLE ORTHOD, V79, P971, DOI 10.2319/090208-460.1
   Cevidanes Lucia H C, 2011, Semin Orthod, V17, P72, DOI 10.1053/j.sodo.2010.08.012
   Cheung LK, 2011, ORAL SURG ORAL MED O, V112, pE56, DOI 10.1016/j.tripleo.2011.02.045
   Chidiac J J, 2002, Orthod Craniofac Res, V5, P104, DOI 10.1034/j.1600-0544.2002.01170.x
   Chien PC, 2009, DENTOMAXILLOFAC RAD, V38, P262, DOI 10.1259/dmfr/81889955
   Couceiro Carolina Perez, 2010, Dental Press J. Orthod., V15, P40
   Damstra J, 2011, AM J ORTHOD DENTOFAC, V140, pE107, DOI 10.1016/j.ajodo.2011.02.020
   de Oliveira AEF, 2009, ORAL SURG ORAL MED O, V107, P256, DOI 10.1016/j.tripleo.2008.05.039
   Dibbets JMH, 2002, AM J ORTHOD DENTOFAC, V122, P196, DOI 10.1067/mod.2002.125565
   Dot G, 2022, MEDRXIV, P2022
   DOWNS WB, 1948, AM J ORTHOD DENTOFAC, V34, P812, DOI 10.1016/0002-9416(48)90015-3
   Farman AG, 2006, AM J ORTHOD DENTOFAC, V130, P257, DOI 10.1016/j.ajodo.2005.10.021
   Fuyamada M, 2011, ANGLE ORTHOD, V81, P843, DOI 10.2319/010711-5.1
   Grauer D, 2010, ANGLE ORTHOD, V80, P286, DOI 10.2319/030909-135.1
   Gray Crawford F, 2010, Prim Dent Care, V17, P161, DOI 10.1308/135576110792936113
   Greiner M, 2007, J OROFAC ORTHOP, V68, P290, DOI 10.1007/s00056-007-0710-5
   Gribel BF, 2011, ANGLE ORTHOD, V81, P3, DOI 10.2319/032910-173.1
   Gupta A., 2020, Int J Comput Vis Robot, V10, P360, DOI [10.1504/IJCVR.2020.108153, DOI 10.1504/IJCVR.2020.108153]
   Gupta A, 2022, Multimed Tools Appl, P1
   Gupta A, 2019, US Patent, Patent No. [US10318839B2, 10318839]
   Gupta A, 2019, COMPUT SCI-AGH, V20, P389, DOI 10.7494/csci.2019.20.4.3163
   Gupta A, 2017, AM J ORTHOD DENTOFAC, V151, P118, DOI 10.1016/j.ajodo.2016.06.027
   Gupta A, 2016, INT J COMPUT ASS RAD, V11, P1297, DOI 10.1007/s11548-015-1334-7
   Gupta A, 2015, INT J COMPUT ASS RAD, V10, P1737, DOI 10.1007/s11548-015-1173-6
   Halazonetis DJ, 2005, AM J ORTHOD DENTOFAC, V127, P627, DOI 10.1016/j.ajodo.2005.01.004
   Hanzelka T, 2010, MED HYPOTHESES, V75, P610, DOI 10.1016/j.mehy.2010.07.046
   Hassan B, 2013, EUR J ORTHODONT, V35, P38, DOI 10.1093/ejo/cjr050
   Hassan B, 2009, EUR J ORTHODONT, V31, P129, DOI 10.1093/ejo/cjn088
   Holberg Christof, 2005, J Orofac Orthop, V66, P434, DOI 10.1007/s00056-005-0519-z
   Horner K, 2009, DENTOMAXILLOFAC RAD, V38, P187, DOI 10.1259/dmfr/74941012
   Ibragimov B, 2016, COMPUTERIZED CEPHALO
   Instron, ABOUT US
   Kang SH, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-97116-7
   Kang SH, 2020, COMP M BIO BIO E-IV, V8, P210, DOI 10.1080/21681163.2019.1674696
   Kapila S, 2011, DENTOMAXILLOFAC RAD, V40, P24, DOI 10.1259/dmfr/12615645
   Katkar RA, 2013, DENTOMAXILLOFAC RAD, V42, DOI 10.1259/dmfr.20130059
   Kau CH, 2005, J ORTHOD, V32, P282, DOI 10.1179/146531205225021285
   Kim JH, 2022, BRIT J ORAL MAX SURG, V60, P320, DOI 10.1016/j.bjoms.2021.07.003
   Kim SG, 2012, IMAGNG SCI DENT, V42, P175, DOI 10.5624/isd.2012.42.3.175
   Kragskov J, 1997, CLEFT PALATE-CRAN J, V34, P111, DOI 10.1597/1545-1569(1997)034<0111:COTROC>2.3.CO;2
   Kumar V, 2007, DENTOMAXILLOFAC RAD, V36, P263, DOI 10.1259/dmfr/98032356
   Kumar V, 2008, ANGLE ORTHOD, V78, P873, DOI 10.2319/082907-399.1
   Lagravère MO, 2010, AM J ORTHOD DENTOFAC, V137, P598, DOI 10.1016/j.ajodo.2008.07.018
   Lagravère MO, 2009, ANGLE ORTHOD, V79, P1047, DOI 10.2319/010509-10R.1
   Lamichane M, 2009, AM J ORTHOD DENTOFAC, V136, DOI [10.1016/j.ajodo.2009.01.019, 10.1016/j.ajodo.2009.04.006]
   Lecomber AR, 2001, DENTOMAXILLOFAC RAD, V30, P255, DOI 10.1038/sj.dmfr.4600627
   Lee H, 2017, PROC SPIE, V10134
   Lee JH, 2020, BMC ORAL HEALTH, V20, DOI 10.1186/s12903-020-01256-7
   Lee SM, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab00c9
   Liedke GS, 2012, DENTOMAXILLOFAC RAD, V41, P136, DOI 10.1259/dmfr/22287302
   Lindner C, 2016, SCI REP-UK, V6, DOI 10.1038/srep33581
   Lofthag-Hansen Sara, 2010, Swed Dent J Suppl, P4
   Lopes PML, 2008, ORAL SURG ORAL MED O, V105, P224, DOI 10.1016/j.tripleo.2007.08.036
   Ludlow JB, 2007, ORAL SURG ORAL MED O, V103, P534, DOI 10.1016/j.tripleo.2006.04.008
   Ludlow JB, 2009, AM J ORTHOD DENTOFAC, V136, DOI 10.1016/j.ajodo.2008.12.018
   Ma QC, 2020, INT J MED ROBOT COMP, V16, DOI 10.1002/rcs.2093
   Maken P, 2023, ARCH COMPUT METHOD E, V30, P85, DOI 10.1007/s11831-022-09790-z
   Martin CJ, 2007, BRIT J RADIOL, V80, P639, DOI 10.1259/bjr/25922439
   Montúfar J, 2018, AM J ORTHOD DENTOFAC, V154, P140, DOI 10.1016/j.ajodo.2017.08.028
   Montúfar J, 2018, AM J ORTHOD DENTOFAC, V153, P449, DOI 10.1016/j.ajodo.2017.06.028
   Moreira CR, 2009, ORAL SURG ORAL MED O, V108, P430, DOI 10.1016/j.tripleo.2009.01.032
   Moshiri M, 2007, AM J ORTHOD DENTOFAC, V132, P550, DOI 10.1016/j.ajodo.2006.09.046
   Naji P, 2013, ANGLE ORTHOD
   Nalçaci R, 2010, DENTOMAXILLOFAC RAD, V39, P100, DOI 10.1259/dmfr/82724776
   Neelapu BC, 2018, DENTOMAXILLOFAC RAD, V47, DOI 10.1259/dmfr.20170054
   Neelapu BC, 2017, OR SURG OR MED OR PA, V124, P577, DOI 10.1016/j.oooo.2017.08.020
   Neelapu BC, 2017, INT J COMPUT ASS RAD, V12, P1877, DOI 10.1007/s11548-017-1650-1
   Neelapu BC, 2018, US Patent, Patent No. [US10699415B2, 10699415]
   Nervina JM, 2012, AUST DENT J, V57, P95, DOI 10.1111/j.1834-7819.2011.01662.x
   Ngan Daniel C S, 2003, Aust Orthod J, V19, P67
   Nur M, 2012, ANGLE ORTHOD, V82, P579, DOI 10.2319/080311-488.1
   Olmez H, 2011, ANGLE ORTHOD, V81, P375, DOI 10.2319/070810-387.1
   Olszewski R, 2008, DENTOMAXILLOFAC RAD, V37, P261, DOI 10.1259/dmfr/33343444
   Olszewski R, 2006, NEURORADIOLOGY, V48, P853, DOI 10.1007/s00234-006-0140-x
   Olszewski R, 2013, CLIN ORAL INVEST, V17, P285, DOI 10.1007/s00784-012-0688-2
   Olszewski R, 2010, J CRANIO MAXILL SURG, V38, P214, DOI 10.1016/j.jcms.2009.05.005
   Oz U, 2011, DENTOMAXILLOFAC RAD, V40, P492, DOI 10.1259/dmfr/15644321
   Park CS, 2012, IMAGNG SCI DENT, V42, P201, DOI 10.5624/isd.2012.42.4.201
   Park SH, 2006, AM J ORTHOD DENTOFAC, V129, DOI 10.1016/j.ajodo.2005.11.032
   Pauwels R, 2012, EUR J RADIOL, V81, P267, DOI 10.1016/j.ejrad.2010.11.028
   Periago DR, 2008, ANGLE ORTHOD, V78, P387, DOI 10.2319/122106-52.1
   Qian JH, 2019, I S BIOMED IMAGING, P868, DOI [10.1109/ISBI.2019.8759437, 10.1109/isbi.2019.8759437]
   Ramírez-Sotelo LR, 2012, ANGLE ORTHOD, V82, P827, DOI 10.2319/072711-473.1
   Scarfe WC, 2006, J CAN DENT ASSOC, V72, P75
   Schendel SA., 2009, Semin in Orthod, V15, P48
   Schlicher W, 2012, EUR J ORTHODONT, V34, P263, DOI 10.1093/ejo/cjq144
   Shahidi S, 2014, BMC MED IMAGING, V14, DOI 10.1186/1471-2342-14-32
   Song Y, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072547
   Spin-Neto R, 2013, DENTOMAXILLOFAC RAD, V42, DOI 10.1259/dmfr/32310645
   SPOLYAR JL, 1987, ANGLE ORTHOD, V57, P77
   Swennen GRJ, 2006, J CRANIOFAC SURG, V17, P314, DOI 10.1097/00001665-200603000-00019
   Swennen GRJ, 2006, AM J ORTHOD DENTOFAC, V130, P410, DOI 10.1016/j.ajodo.2005.11.035
   Titiz I, 2012, EUR J ORTHODONT, V34, P276, DOI 10.1093/ejo/cjq190
   Tomasi C, 2011, DENTOMAXILLOFAC RAD, V40, P244, DOI [10.1259/dmfr/1742330, 10.1259/dmfr/17432330]
   Torosdagli N, 2019, IEEE T MED IMAGING, V38, P919, DOI 10.1109/TMI.2018.2875814
   Trivedi M, 2022, MULTIMED TOOLS APPL, V81, P5515, DOI 10.1007/s11042-021-11807-x
   Tulunoglu Ozlem, 2011, Eur J Dent, V5, P451
   TWEED CH, 1953, AM J ORTHOD DENTOFAC, V39, P81, DOI 10.1016/0002-9416(53)90014-1
   van Vlijmen OJC, 2009, J ORAL MAXIL SURG, V67, P92, DOI 10.1016/j.joms.2008.04.025
   Vandaele R, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-017-18993-5
   Wang SM, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/1797502
   Williams FL, 2003, CLIN ANAT, V16, P494, DOI 10.1002/ca.10095
   WU J, 2010, OPEN ANTHR J, V3, P85, DOI DOI 10.2174/1874912701003010085
   Wu MC, 2010, EUR J ORTHODONT, V32, P627, DOI 10.1093/ejo/cjq026
   Yitschaky O, 2011, ANGLE ORTHOD, V81, P11, DOI 10.2319/031710-157.1
   Yoon YJ, 2001, ANGLE ORTHOD, V71, P396
   Yu SH, 2008, AM J ORTHOD DENTOFAC, V133, DOI 10.1016/j.ajodo.2007.10.036
   Yue WN, 2006, IEEE T BIO-MED ENG, V53, P1615, DOI 10.1109/TBME.2006.876638
   Zamora N, 2012, MED ORAL PATOL ORAL, V17, pE678, DOI 10.4317/medoral.17721
NR 119
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 21
PY 2023
DI 10.1007/s11042-023-14971-4
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F6PQ0
UT WOS:000983548500003
DA 2024-07-18
ER

PT J
AU Yi, W
   Wang, SJ
   Ji, NN
   Wang, CP
   Xiao, YZ
   Song, XL
AF Yi, Wen
   Wang, Shijie
   Ji, Nannan
   Wang, Changpeng
   Xiao, Yuzhu
   Song, Xueli
TI SAR image change detection based on Gabor wavelets and convolutional
   wavelet neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Synthetic aperture radar images; Change detection; Fuzzy C-means
   clustering; Gabor wavelets; Convolutional wavelet neural networks
ID AUTOMATIC CHANGE DETECTION
AB Synthetic aperture radar (SAR) image change detection technology is of great significance. In the existing convolutional wavelet neural networks (CWNN) based SAR image change detection methods, the precision of preclassification is not high. The precision of preclassification will affect the performance of the network, and thus affect the accuracy of image change detection. In order to further improve the accuracy of change detection, the method based on Gabor wavelets and convolutional wavelet neural networks (GWCWNN) is applied to SAR image change detection in this paper. This method combines Gabor wavelets and fuzzy C-means clustering algorithm to provide high precision training samples for the networks, so as to improve the accuracy of image change detection. The results on three real data sets respectively show that the proposed method is better than the existing four methods.
C1 [Yi, Wen; Wang, Shijie; Ji, Nannan; Wang, Changpeng; Xiao, Yuzhu; Song, Xueli] Changan Univ, Coll Sci, Erhuannan Rd, Xian 710064, Shaanxi, Peoples R China.
C3 Chang'an University
RP Xiao, YZ; Song, XL (corresponding author), Changan Univ, Coll Sci, Erhuannan Rd, Xian 710064, Shaanxi, Peoples R China.
EM yuzhuxiao@chd.edu.cn; xlsung@chd.edu.cn
FU Special Fund for Basic Scientific Research of Central Colleges in
   Chang'an University [310812163504, 300102129202]
FX AcknowledgmentsThis work was supported by the Special Fund for Basic
   Scientific Research of Central Colleges in Chang'an University
   (310812163504 and 300102129202).
CR Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Campos AB., 2020, IEEE GEOSCI REMOTE S, V17, P4004805
   Davari N, 2021, IEEE T POWER DELIVER, V36, P3640, DOI 10.1109/TPWRD.2020.3046161
   Huong DTV, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.083626
   Duan YP, 2017, PATTERN RECOGN, V64, P255, DOI 10.1016/j.patcog.2016.11.015
   Gao F, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.046019
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gao P, 2019, IEEE GEOSCI REMOTE S, V16, P1240, DOI 10.1109/LGRS.2019.2895656
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Han ZM, 2022, KNOWL-BASED SYST, V253, DOI 10.1016/j.knosys.2022.109512
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hossein A., 2012, J APPL REMOTE SENS, V6
   Hu HT, 2014, IEEE J-STARS, V7, P3248, DOI 10.1109/JSTARS.2014.2344017
   Jian MW, 2021, INFORM SCIENCES, V576, P819, DOI 10.1016/j.ins.2021.08.069
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P1, DOI 10.1016/j.jvcir.2018.10.008
   Jian MW, 2014, INFORM SCIENCES, V262, P1, DOI 10.1016/j.ins.2013.12.001
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   Lavanya PV, 2020, J ENG RES-KUWAIT, V8, P154
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li HC, 2015, IEEE GEOSCI REMOTE S, V12, P2458, DOI 10.1109/LGRS.2015.2484220
   Liu JW, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-97195-6
   Lu XW, 2022, MULTIMEDIA SYST, V28, P1689, DOI 10.1007/s00530-022-00940-8
   Lunetta RS, 2006, REMOTE SENS ENVIRON, V105, P142, DOI 10.1016/j.rse.2006.06.018
   Manonmani R., 2010, International Journal of Geomatics and Geosciences, V1, P60
   Pettinato S, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.084684
   Ponmani E, 2021, MULTIMED TOOLS APPL, V80, P26547, DOI 10.1007/s11042-021-10871-7
   Qu X., 2022, IEEE GEOSCI REMOTE S, V17, P4013405
   Rosin PL, 2003, PATTERN RECOGN LETT, V24, P2345, DOI 10.1016/S0167-8655(03)00060-6
   Saha S, 2021, IEEE T GEOSCI REMOTE, V59, P1917, DOI 10.1109/TGRS.2020.3000296
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Sharan TS, 2021, J APPL SPECTROSC+, V88, P117, DOI 10.1007/s10812-021-01149-9
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P230, DOI 10.1109/TITS.2017.2749964
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P1457, DOI 10.1109/TITS.2017.2726546
   Wang R, 2022, INT J INTELL SYST, V37, P9982, DOI 10.1002/int.23024
   Wang Y, 2020, J HYDROL, V582, DOI 10.1016/j.jhydrol.2019.124482
   Wen Z, 1761, J PHYS C SERIES, V2021
   Yousif O, 2014, IEEE J-STARS, V7, P4288, DOI 10.1109/JSTARS.2014.2347171
   Zhang XW, 2021, MULTIMED TOOLS APPL, V80, P28989, DOI 10.1007/s11042-021-11054-0
NR 44
TC 1
Z9 1
U1 6
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30895
EP 30908
DI 10.1007/s11042-023-15106-5
EA MAR 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000983548500006
DA 2024-07-18
ER

PT J
AU Rathore, NK
   Khan, Y
   Kumar, S
   Singh, P
   Varma, S
AF Rathore, Neeraj Kumar
   Khan, Yunus
   Kumar, Sudesh
   Singh, Pawan
   Varma, Sunita
TI An evolutionary algorithmic framework cloud based evidence collection
   architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Evolutionary computing; Performance parameters; Fuzzy logic; Graph
   neural network; Blockchain technology; Evidence collection; Neural
   science; SHA-3; Smart contracts; Backtracking search optimization
   algorithm SDN control plane
ID JOB MIGRATION
AB Forensic in cloud computing is an advancement of evolutionary modern forensic science that protects against cyber criminals. Single centralize point compilation and storage of data, however, overcome the authenticity of digital evidence. In order to address this serious issue, this article suggests a evolutionary modern algorithm automated forensic platform leveraging infrastructure as a cloud service (IaaS) based on Blockchain concept. This proposed forensic structural design, evidence collection of evidence and stored on a blockchain which is circulated around several peer blocks. Secure Block Verification Mechanism (SBVM) is proposed to Safeguarding the device from unauthorised users. Using the Backtracking Search Optimization Algorithm search optimization algorithm for strengthening of the cloud environment, secret keys are optimally generated. On the bases of level of confidentiality, all data is stored and encrypted at cloud authentication server. Confidentiality-based Algebraically Homomorphic Cryptosystems learning is presented with a fast-forwarding algorithm for encryption. A block in the SDN controller is created for every data and information is stored in the cloud service provider and the history is recorded as metadata data about data. A hash based tree is constructed in each block by Secure Hash Algorithm version - 3 of 512 bits. By implementing graph theory-based graph neural networks in Smart Contracts, our framework enables users to track their data (GNNSC). Finally, the construction of a evidence graph using blockchain data enables evidence analysis. Experiments was carried out in a Python programming and blockchain integrated cloud environment with network simulator-3.30 (for Software Defined Network). As part of result our newly designed forensic architecture using blochchain (FAuB) good results in terms of evidence response time, insertion times of cloud evidence, verification time of evidence, computational overhead of evidence, hashes calculation time, keys generations times of evidence, evidence encryption time, evidence decryptions time, and total overall change rate of evidence, according to a comprehensive comparative study.
C1 [Rathore, Neeraj Kumar; Kumar, Sudesh] Indira Gandhi Natl Tribal Univ, Dept Comp Sci, Amarkantak 484887, Madhya Pradesh, India.
   [Khan, Yunus; Varma, Sunita] Shri Govindram Seksaria Inst Technol & Sci, Dept Comp Sci & Engn, Indore 452003, Madhya Pradesh, India.
   [Singh, Pawan] Cent Univ Rajasthan, Dept Comp Sci, Ajmer 305817, Rajasthan, India.
C3 Indira Gandhi National Tribal University; Shri Govindram Seksaria
   Institute of Technology & Science; Central University of Rajasthan
   (CURAJ)
RP Khan, Y (corresponding author), Shri Govindram Seksaria Inst Technol & Sci, Dept Comp Sci & Engn, Indore 452003, Madhya Pradesh, India.
EM neerajrathore37@gmail.com; callyunuskhan@gmail.com;
   sudesh.kumar@igntu.ac.in; pawan.singh@igntu.ac.in;
   sunita.varma19@gmail.com
RI kumar, sudesh/ABB-8845-2021
OI kumar, sudesh/0000-0002-9405-1890; Singh, Pawan/0000-0001-6122-4575
CR Abdelhafid E., 2022, INT J EMERG TECHNOL, V12, P186, DOI [10.46338/ijetae0722_19, DOI 10.46338/IJETAE0722_19]
   Abdullahi AK, 2019, MACE TECH J MTJ, V1, P8
   Agustono I, 2022, INT J EMERG TECHNOL, V12, P1
   Ahmed A, 2019, J CLOUD COMPUT, V8, P11
   Akbarzadeh A, 2015, INT J COMPUT AIDED T, V2
   Akter O., 2020, INT J MODERN ED COMP, V10, P1, DOI [10.5815/ijmecs.2020.06.03, DOI 10.5815/IJWMT.2020.05.01]
   AlKhateeb Haya, 2019, Proceedings of the International Conferences. Interfaces and Human Computer Interaction 2019, Game and Entertainment Technologies 2019, Computer Graphics, Visualization, Computer Vision and Image Processing 2019, P149
   [Anonymous], 2015, J CLOUD COMPUTING, V2, P29
   Apipawinwongsa P., 2022, INT J EMERG TECHNOL, V12, P41, DOI [10.46338/ijetae0922_05, DOI 10.46338/IJETAE0922_05]
   Baharun N., 2022, INT J EMERG TECHNOL, V12, P15, DOI [10.46338/ijetae0522_03, DOI 10.46338/IJETAE0522_03]
   Bhujade RK, 2022, INT J EMERG TECHNOL, V12, P153
   Casino F, 2019, TELEMAT INFORM, V36, P55, DOI 10.1016/j.tele.2018.11.006
   Chana I, 2010, IEEE CSI MPCET, V8, P32
   Clarin JA., 2022, INT J EMERG TECHNOL, V12, P20, DOI [10.46338/ijetae0722_03, DOI 10.46338/IJETAE0722_03]
   Ezz EH, MULTIMED TOOLS APPL, V80, P14255
   Goel A, 2020, INT J EMERG TECHNOL, V10, P97
   Gopalan S.H., 2019, Int. J. Recent Technol. Eng, V8, P182
   Guerroum M., 2022, International Journal of Emerging Technology and Advanced Engineering, V12, P122, DOI [10.46338/ijetae1022_14, DOI 10.46338/IJETAE1022_14]
   Hasan KK., 2022, INT J EMERG TECHNOL, V12, P65, DOI [10.46338/ijetae1122_07, DOI 10.46338/IJETAE1122_07]
   Infusi MZ., 2022, INT J EMERG TECHNOL, V12, P63, DOI [10.46338/ijetae0122_07, DOI 10.46338/IJETAE0122_07]
   Jain N., 2017, INTERCIENCIA J, V42, P95
   Jain N, 2020, NAT ACAD SCI LETT SP, V604
   Jain NK, 2018, WIRELESS PERS COMMUN, V101, P1983, DOI 10.1007/s11277-018-5802-6
   Khan F., 2018, J CLOUD COMPUT JCC, V5, P20
   Kumar N, 2016, INT J SOFTWARE COMPU, V1, P1
   Kumar N., 2015, J COMPUTER SCI JCOM, V3, P11, DOI DOI 10.26634/JCOM.3.3.3661
   Kumar N, 2016, J CLOUD COMPUTING JC, V3, P27
   Kumar N., 2018, J CLOUD COMPUT JCC, V1, P1
   Kumar N., 2019, INT J ENG COMPUT SCI, V1, P59
   Kumar Sudesh, 2023, Journal of Ambient Intelligence and Humanized Computing, P9343, DOI 10.1007/s12652-022-04434-3
   Laxkar P, 2020, WIRELESS PERS COMMUN, V63
   Liwen P., 2020, 3 INT C ART INT BIG
   Malvin Dylan., 2022, INT J EMERG TECHNOL, V12, P130, DOI [10.46338/ijetae0222_15, DOI 10.46338/IJETAE0222_15]
   Meshram S., 2020, INT J EMERG TECHNOL, V10, P113
   Mndeep K, 2016, INT J ADV RES COMPUT, V5
   Pandey D, 2022, IRBM, V43, P151, DOI 10.1016/j.irbm.2020.07.003
   Pandey D, 2020, J SUPERCOMPUT
   Pandi GS, 2020, PROCEDIA COMPUT SCI, V167, P163, DOI 10.1016/j.procs.2020.03.194
   Pedro RB., 2019, BUDAPEST INT RES EXA, V1, P71, DOI [10.33258/birex.v1i1.141, DOI 10.33258/BIREX.V1I1.141]
   Perez-Siguas R., 2022, INT J EMERG TECHNOL, V12, P32, DOI [10.46338/ijetae0422_05, DOI 10.46338/IJETAE0422_05]
   Rathore N., 2016, J POWER SYSTEMS ENG, V4, P47
   Rathore N., 2015, J SOFTWARE ENG JSE, V10, P21
   Rathore N., 2017, J COMPUTER SCI JCS, V5, P23
   Rathore N., 2016, I-Manager's Journal on Information Technology, V5, P7
   Rathore N., 2013, J. Inform. Technol, V2, P21
   Rathore N, NOVEL SECURITY TECHN, DOI [10.1007/s11277-021-08630-w, DOI 10.1007/S11277-021-08630-W]
   Rathore N, 2018, WIRELESS PERS COMMUN, V101, P1233, DOI 10.1007/s11277-018-5758-6
   Rathore N, 2016, WIRELESS PERS COMMUN, V91, P151, DOI 10.1007/s11277-016-3452-0
   Rathore N, 2014, J INTELL FUZZY SYST, V27, P2821, DOI 10.3233/IFS-141243
   Rathore N, 2015, ENG COMPUT-GERMANY, V31, P597, DOI 10.1007/s00366-014-0364-z
   Rathore N, 2014, WIRELESS PERS COMMUN, V79, P2089, DOI 10.1007/s11277-014-1975-9
   Rathore NK, 2020, NATL ACAD SCI LETT, V43, P177, DOI 10.1007/s40009-019-00834-w
   Rathore NK, 2016, WIRELESS PERS COMMUN, V89, P241, DOI 10.1007/s11277-016-3264-2
   Rathore NK, 2021, HOTEL MANAGEMENT
   Rathore NK., 2016, J COMPUTER SCI JCOM, V4, P1
   Rathore NK, 2020, APPROACHES DIGITAL I
   Samuel AK, 2020, IEEE INT C INF TECHN
   Sebastian S, 2020, BOOK SERIES STUDIES, V74, P175
   Sharma V., 2015, J WIRELESS MOBILE NE, V6, P54
   Shweta NJ., 2020, 4 INT C I SMAC IOT S
   Singh H., 2017, J MOBILE APPL TECHNO, V4, P32
   Siva RKT, 2020, WIRELESS PERS COMMUN
   Srivastava P, 2021, LECT NOTES NETWORKS, P670
   Syed AA, 2020, INT C COMP NETW TEL, DOI DOI 10.1109/CONTESA50436.2020.9302862
   Wei Y., 2022, INT J EMERG TECHNOL, V12, P45, DOI [10.46338/ijetae0822_06, DOI 10.46338/IJETAE0822_06]
   Ye F, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.4178
NR 66
TC 1
Z9 1
U1 5
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 39867
EP 39895
DI 10.1007/s11042-023-14838-8
EA MAR 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000984224700006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Qureshi, AA
   Ahmad, M
   Ullah, S
   Yasir, MN
   Rustam, F
   Ashraf, I
AF Qureshi, Ali Adil
   Ahmad, Maqsood
   Ullah, Saleem
   Yasir, Muhammad Naveed
   Rustam, Furqan
   Ashraf, Imran
TI Performance evaluation of machine learning models on large dataset of
   android applications reviews
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Opinion mining; Sentiment analysis; Mobile apps reviews; Google Play
   Store
ID CLASSIFICATION
AB With an ever-increasing number of mobile users, the development of mobile applications (apps) has become a potential market during the past decade. Billions of users download mobile apps for divergent use from Google Play Store, fulfill tasks and leave comments about their experience. Such reviews are replete with a variety of feedback that serves as a guide for the improvement of existing apps and intuition for novel mobile apps. However, application reviews are challenging and very broad to approach. Such reviews, when segregated into different classes guide the user in the selection of suitable apps. This study proposes a framework for analyzing the sentiment of reviews for apps of eight different categories like shopping, sports, casual, etc. A large dataset is scrapped comprising 251661 user reviews with the help of 'Regular Expression' and 'Beautiful Soup'. The framework follows the use of different machine learning models along with the term frequency-inverse document frequency (TF-IDF) for feature extraction. Extensive experiments are performed using preprocessing steps, as well as, the stats feature of app reviews to evaluate the performance of the models. Results indicate that combining the stats feature with TF-IDF shows better performance and the support vector machine obtains the highest accuracy. Experimental results can potentially be used by other researchers to select appropriate models for the analysis of app reviews. In addition, the provided dataset is large, diverse, and balanced with eight categories and 59 app reviews and provides the opportunity to analyze reviews using state-of-the-art approaches.
C1 [Qureshi, Ali Adil; Ullah, Saleem] Khwaja Fareed Univ Engn & Informat Technol, Dept Comp Sci, Rahim Yar Khan 64200, Pakistan.
   [Ahmad, Maqsood] Islamia Univ Bahawalpur, Dept Informat Secur, Bahawalpur 63100, Punjab, Pakistan.
   [Yasir, Muhammad Naveed] Univ Narowal, Dept Comp Sci, Narowal 51600, Pakistan.
   [Rustam, Furqan] Univ Coll Dublin, Sch Comp Sci, Dublin, Ireland.
   [Ashraf, Imran] Yeungnam Univ, Informat & Commun Engn, Gyongsan 38541, South Korea.
C3 Khwaja Fareed University of Engineering & Information Technology,
   Pakistan; Islamia University of Bahawalpur; University College Dublin;
   Yeungnam University
RP Rustam, F (corresponding author), Univ Coll Dublin, Sch Comp Sci, Dublin, Ireland.; Ashraf, I (corresponding author), Yeungnam Univ, Informat & Commun Engn, Gyongsan 38541, South Korea.
EM aliadil2201@gmail.com; maqsoodzee@gmail.com; Saleem.ullah@kfueit.edu.pk;
   naveed.yasir@gmail.com; furqan.rustam1@gmail.com; imranashraf@ynu.ac.kr
RI Rustam, Furqan/ABE-4772-2020; Ullah, Saleem/D-2644-2014; Ashraf,
   Imran/T-3635-2019
OI Rustam, Furqan/0000-0001-8403-1047; Ullah, Saleem/0000-0003-3747-1263;
   Ashraf, Imran/0000-0002-8271-6496
CR A G, 2021, IEEE INT SYMP CIRC S, V99
   Alshamrani SS, 2021, MATH PROBL ENG, V2021, DOI [10.1155/2021/3697733, 10.1155/2021/9944363]
   [Anonymous], 2022, APPBRAIN FREE VERSUS
   Aralikatte R, 2018, PROCEEDINGS OF THE ACM INDIA JOINT INTERNATIONAL CONFERENCE ON DATA SCIENCE AND MANAGEMENT OF DATA (CODS-COMAD'18), P57, DOI 10.1145/3152494.3152500
   Ashraf I, 2021, CMC-COMPUT MATER CON, V67, P3009, DOI 10.32604/cmc.2021.015140
   Ashraf I, 2018, MICROMACHINES-BASEL, V9, DOI 10.3390/mi9100534
   Assegie T.A., 2021, J. Robot. Control (JRC), V2, P115, DOI DOI 10.18196/JRC.2363
   Behmanesh I, 2015, MECH SYST SIGNAL PR, V64-65, P360, DOI 10.1016/j.ymssp.2015.03.026
   Bhatia M., 2021, Recent Adv. Comput. Sci. Commun., V14, P1390, DOI [10.2174/2213275912666190716114919, DOI 10.2174/2213275912666190716114919]
   Bird Steven., 2005, NLTK-Lite: Efficient Scripting for Natural Language Processing
   Byvatov Evgeny, 2003, Appl Bioinformatics, V2, P67
   Dawoud NN, 2012, LECT NOTES ENG COMP, P726
   Di Sorbo A, 2021, J SOFTW-EVOL PROC, V33, DOI 10.1002/smr.2316
   Din Q, 2018, MATCH-COMMUN MATH CO, V79, P577
   Ezhilarasi S., 2021, International Journal of Aquatic Science, V12, P1718
   Gao F, 2021, ACCOUNT FINANC, P1919
   Ghaleb M, 2021, EVALUATING VARIOUS T
   Guzman E, 2014, INT REQUIR ENG CONF, P153, DOI 10.1109/RE.2014.6912257
   Handani SW, 2019, J PHYS C SERIES, V1196
   Hassan S, 2020, IEEE T SOFTWARE ENG, V46, P773, DOI 10.1109/TSE.2018.2869395
   Huang SJ, 2018, CANCER GENOM PROTEOM, V15, P41, DOI 10.21873/cgp.20063
   Iacob C, 2013, IEEE WORK CONF MIN S, P41, DOI 10.1109/MSR.2013.6624001
   Jiao SB, 2021, APPL ACOUST, V175, DOI 10.1016/j.apacoust.2020.107857
   Käck M, 2021, INT J PROD ECON, V231, DOI 10.1016/j.ijpe.2020.107837
   Khalid M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082788
   Moslem Y, 2020, P 6 WORKSH NAT LANG, P11
   Mueez A, 2018, EXPLORATORY DATA ANA
   Nayebi M, 2018, EMPIR SOFTW ENG, V23, P2764, DOI 10.1007/s10664-018-9601-1
   Noble W.S., 2004, KERNEL METHODS COMPU, P71
   Oktaviani V., 2021, J. Phys. Conf. Ser, V1943, P012147, DOI [10.1088/1742-6596/1943/1/012147, DOI 10.1088/1742-6596/1943/1/012147]
   Pagano D, 2013, S VIS LANG HUM CEN C, P125, DOI 10.1109/RE.2013.6636712
   Pal M, 2005, INT J REMOTE SENS, V26, P217, DOI 10.1080/01431160412331269698
   Pallathadka Harikumar, 2023, Materials Today: Proceedings, P2610, DOI 10.1016/j.matpr.2021.06.419
   Pappas N, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P773
   Prasad GNR., 2021, TURKISH J COMPUT MAT, V12, P1872
   Pu Y., 2015, Using conjoint analysis to investigate the value of interdependent privacy in social app adoption scenarios
   Qin Y, 2022, INT J FUZZY SYST, V24, P755, DOI 10.1007/s40815-021-01131-9
   Raghavendra NS, 2014, APPL SOFT COMPUT, V19, P372, DOI 10.1016/j.asoc.2014.02.002
   Rahman ANCA, 2021, GEMA ONLINE J LANG S, V21, P1, DOI 10.17576/gema-2021-2102-01
   Ramalingam V.V., 2018, International Journal of Engineering Technology, V7, P684, DOI [10.14419/ijet.v7i2.8.10557, DOI 10.14419/IJET.V7I2.8.10557]
   Rehan MS, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03149-1
   Ruan SF, 2022, NEURAL COMPUT APPL, V34, P2729, DOI 10.1007/s00521-021-05989-6
   Rupapara V, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.745
   Rustam F, 2020, IEEE ACCESS, V8, P101489, DOI 10.1109/ACCESS.2020.2997311
   Rustam F, 2020, IEEE ACCESS, V8, P30234, DOI 10.1109/ACCESS.2020.2972632
   Rustam F, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21111078
   Rymarczyk T, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19153400
   Saad E, 2021, IEEE ACCESS, V9, P85721, DOI 10.1109/ACCESS.2021.3088838
   Trafalis T. B., 2000, IEEE IJCNN, V6, P348, DOI DOI 10.1109/IJCNN.2000.859420
   Umer M, 2021, ETRI J, V43, P95, DOI 10.4218/etrij.2019-0443
   Vinodhini G, 2012, International Journal, V2, P282
   Wahyuni WA., 2022, JURNAL MANTIK, V5, P2203
   Watzlawik M., 2012, The Oxford Handbook of Culture and Psychology, V2, P1930, DOI [10.1093/oxfordhb/9780195396430.013.0038, DOI 10.1093/OXFORDHB/9780195396430.013.0038]
   Wu HY, 2021, PROC INT CONF SOFTW, P922, DOI 10.1109/ICSE43902.2021.00088
   Ye H, 2021, IEEE ACCESS, V9, P17787, DOI 10.1109/ACCESS.2021.3052835
   Yousaf A, 2021, IEEE ACCESS, V9, P6286, DOI 10.1109/ACCESS.2020.3047831
   Zabor EC, 2022, INT J RADIAT ONCOL, V112, P271, DOI 10.1016/j.ijrobp.2021.08.007
   Zhan CJ, 2021, IEEE INTERNET THINGS, V8, P15906, DOI 10.1109/JIOT.2021.3066575
   Zhao PP, 2021, L N INST COMP SCI SO, V398, P418, DOI 10.1007/978-3-030-90019-9_21
   Zimmeck S, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI 10.14722/ndss.2017.23034
NR 60
TC 2
Z9 2
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 18
PY 2023
DI 10.1007/s11042-023-14713-6
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A0QJ4
UT WOS:000952258900008
PM 37362743
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Sreeja, MU
   Kovoor, BC
AF Sreeja, M. U.
   Kovoor, Binsu C.
TI GenSpecVidOnt: a reference ontology for knowledge based video analytics
   with multimodal genre detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Genre-specific; Ontology; Multimodal features; Video analytics;
   Summarization
ID CLASSIFICATION
AB Video analytics refers to the process of automatically analysing a video for spatial and temporal events. Effective video analytics require exploitation of genre-related information leading to knowledge-based video analysis. The proposed model implements an ontology for inferring genre-specific information namely GenSpecVidOnt- Genre Specific Video Ontology, based on a combined multimodal feature set and ontology inference. The collective set of features utilized for detecting the video genre are dominant colour, aural and visual quality, camera status, shot boundaries and redundancy factor. The proposed ontology is one of a kind that bridges the semantic gap prevailing in the current video analytics by exploiting genre related information of videos. The architecture of the ontology has been verified and validated proving the efficacy of the architecture. Quantitative evaluations of the proposed multimodal genre detection phase proves that the model could achieve an elevated precision, recall, f-score, and accuracy values of 73.16%, 75.68%, 72.06% and 71.43% respectively compared to the prominent machine learning based classifiers. The results further substantiate the relevance of the multimodal feature set identified in the proposed model for accurate genre detection along with the superiority of the model in extracting domain-related information for knowledge-based video analytics based on ontology inferences.
C1 [Sreeja, M. U.; Kovoor, Binsu C.] Cochin Univ Sci & Technol, Div Informat Technol, Kochi, Kerala, India.
C3 Cochin University Science & Technology
RP Sreeja, MU (corresponding author), Cochin Univ Sci & Technol, Div Informat Technol, Kochi, Kerala, India.
EM kishan.sreeja@gmail.com; binsu.kovoor@gmail.com
CR Alvarez F, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0211406
   Apostolidis E, 2021, ARXIV
   Bakels JH, 2020, LANCET
   Bellard, 2016, FFMPEG FILTERS DOCUM
   Börner J, 2018, IEEE PES INNOV SMART
   Cavaliere D, 2019, IEEE ACCESS, V7, P105342, DOI 10.1109/ACCESS.2019.2932442
   Choros K, 2019, J INTELL FUZZY SYST, V37, P7657, DOI 10.3233/JIFS-179370
   Choros K, 2018, LECT NOTES ARTIF INT, V11056, P509, DOI 10.1007/978-3-319-98446-9_48
   Dandashi A., 2018, RECENT TRENDS COMPUT, P33
   Daudpota SM, 2019, SIGNAL IMAGE VIDEO P, V13, P1413, DOI 10.1007/s11760-019-01488-3
   Doulaty M, 2016, ARXIV
   Ekenel HK, 2013, MULTIMED TOOLS APPL, V63, P547, DOI 10.1007/s11042-011-0923-x
   Fernandez M., 1997, Methontology: From ontological art towards ontological engineering, P33
   Godbehere AB, 2012, P AMER CONTR CONF, P4305
   Greco L, 2017, P 7 INT C WEB INT, P1
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Hlomani H., 2014, Semantic Web Journal, V1, P1
   Ibrahim ZA, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0573-6
   KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135
   Kahar N. F., 2017, 7th Latin American Conference on Networked and Electronic Media (LACNEM 2017), P62
   Kaushal V, 2019, IEEE WINT CONF APPL, P666, DOI 10.1109/WACV.2019.00076
   Khoorshed NK., 2021, INFORM SCIENCES, V12, P1132, DOI [10.17762/turcomat.v12i6.2431, DOI 10.17762/TURCOMAT.V12I6.2431]
   Kim S, 2013, INT CONF ACOUST SPEE, P798, DOI 10.1109/ICASSP.2013.6637758
   Lamy JB, 2017, ARTIF INTELL MED, V80, P11, DOI 10.1016/j.artmed.2017.07.002
   Lovrencic Sandra, 2008, 19th Central European Conference on Information and Intelligent Systems, P657
   Meng JJ, 2016, PROC CVPR IEEE, P1039, DOI 10.1109/CVPR.2016.118
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Musen Mark A, 2015, AI Matters, V1, P4
   Park W, 2017, INT CONF ADV COMMUN, P560, DOI 10.23919/ICACT.2017.7890152
   Patel AS, 2021, SEMANT WEB, V12, P467, DOI 10.3233/SW-200393
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Raut Vrushali, 2020, E3S Web of Conferences, V170, DOI 10.1051/e3sconf/202017003005
   Rouvier M, 2015, IEEE-ACM T AUDIO SPE, V23, P1031, DOI 10.1109/TASLP.2014.2387411
   Sageder Gerhard, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P29, DOI 10.1007/978-3-319-27671-7_3
   Saz O, 2014, IEEE W SP LANG TECH, P118, DOI 10.1109/SLT.2014.7078560
   Sikos LF, 2018, J INFORM TELECOMMUN, V2, P192, DOI 10.1080/24751839.2018.1437696
   Sikos LF, 2017, FED CONF COMPUT SCI, P91, DOI 10.15439/2017F66
   Sobhani E, 2016, IEEE IMAGE PROC, P913, DOI 10.1109/ICIP.2016.7532490
   Sobhani F, 2017, INT ICE CONF ENG, P584, DOI 10.1109/ICE.2017.8279938
   Sreeja MU, 2021, COMPUT ELECTR ENG, V92, DOI 10.1016/j.compeleceng.2021.107161
   Sreeja MU, 2019, J VIS COMMUN IMAGE R, V62, P340, DOI 10.1016/j.jvcir.2019.06.004
   Tani MYK, 2017, INT J MULTIMED INF R, V6, P295, DOI 10.1007/s13735-017-0133-z
   Tani MYK., 2014, LECT NOTES COMPUT SC
   Varghese Jina, 2019, Information and Communication Technology for Intelligent Systems. Proceedings of ICTIS 2018. Smart Innovation, Systems and Technologies (SIST 106), P685, DOI 10.1007/978-981-13-1742-2_68
   Vizcarra J, 2021, IEEE INT C SEMANT CO, P262, DOI 10.1109/ICSC50631.2021.00052
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wickstrom, 2013, TUCS TECHNICAL REPOR, P50
   Wu LF, 2020, IEEE T CIRC SYST VID, V30, P2178, DOI 10.1109/TCSVT.2019.2912529
   Zhang K, 2016, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2016.120
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
NR 50
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35815
EP 35852
DI 10.1007/s11042-023-15040-6
EA MAR 2023
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000947594500001
DA 2024-07-18
ER

PT J
AU Kahlon, GS
   Singh, H
   Saini, M
   Kaur, S
AF Kahlon, Gursimran Singh
   Singh, Harnoor
   Saini, Munish
   Kaur, Sandeep
TI An intelligent framework to detect and generate alert while cattle lying
   on road in dangerous states using surveillance videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surveillance videos; Traffic; National Highways; Animals; cattle; Object
   detection; Accidents
AB This paper presents the framework for early detection of cattle lying dead, blocking the road, or in a condition to cause an accident on highways based on video scrutiny. The suggested framework works with feature extraction, feature expression, and assessment criteria. It also includes a method that can identify the status of cattle on road i.e., cattle lying dead after an accident, a method for assessing stray cattle's blocking the road, and rules for assessing other dangerous states. The framework is trained over 6000 images covering almost all the highway collision possibilities and tested on real images depicting different scenarios on highways. The proposed framework can achieve the mAP of up to 95.10% with precision and recall values of 0.98 and 0.94 respectively, which outperforms all other approaches taken into consideration. The outcomes of the study will assist the concerned authorities to take preventive steps to avoid road accidents or traffic-related issues.
C1 [Kahlon, Gursimran Singh; Singh, Harnoor; Saini, Munish; Kaur, Sandeep] Guru Nanak Dev Univ, Dept Comp Engn Technol, Amritsar, India.
C3 Guru Nanak Dev University
RP Kahlon, GS (corresponding author), Guru Nanak Dev Univ, Dept Comp Engn Technol, Amritsar, India.
EM gursimrankahlon89@gmail.com
RI Saini, Munish/J-4196-2016
OI Saini, Munish/0000-0003-4129-2591; Singh, Harnoor/0000-0003-3184-0822
CR Abhilash PC, 2009, J HAZARD MATER, V165, P1, DOI 10.1016/j.jhazmat.2008.10.061
   Ajmi C, 2020, ADV MATER SCI ENG, V2020, DOI 10.1155/2020/1574350
   Alcon M, 2020, IEEE REAL TIME, P267, DOI 10.1109/RTAS48715.2020.000-1
   [Anonymous], 2011, COWS CARS CYCLE RICK
   [Anonymous], ROAD TRAFFIC INJURIE
   Benjdira B, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON UNMANNED VEHICLE SYSTEMS-OMAN (UVS), DOI 10.1109/uvs.2019.8658300
   Burghardt T, 2006, IEE P-VIS IMAGE SIGN, V153, P305, DOI 10.1049/ip-vis:20050052
   Chen JW, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10040372
   Dogru N, 2018, 2018 15TH LEARNING AND TECHNOLOGY CONFERENCE (L&T), P40, DOI 10.1109/LT.2018.8368509
   Elmaghraby AS, 2014, J ADV RES, V5, P491, DOI 10.1016/j.jare.2014.02.006
   Fabre-Thorpe M, 2001, J COGNITIVE NEUROSCI, V13, P171, DOI 10.1162/089892901564234
   Gadd ME, 2012, FENCING FOR CONSERVATION: RESTRICTION OF EVOLUTIONARY POTENTIAL OR A RIPOSTE TO THREATENING PROCESSES?, P153, DOI 10.1007/978-1-4614-0902-1_9
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   Gibson DP, 2003, P 2003 INT C IMAGE P, V3, pIII
   Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Goniewicz K, 2016, EUR J TRAUMA EMERG S, V42, P433, DOI 10.1007/s00068-015-0544-6
   Gordon TJ, 2015, VEHICLE SYST DYN, V53, P958, DOI 10.1080/00423114.2015.1037774
   Hussain M, 2019, ADV INTELL SYST, V840, P191, DOI 10.1007/978-3-319-97982-3_16
   Jia W, 2021, IET IMAGE PROCESS, V15, P3623, DOI 10.1049/ipr2.12295
   Jones P, 2012, J TRANSP GEOGR, V21, P4, DOI 10.1016/j.jtrangeo.2012.01.012
   Jose C, 2021, THESIS QUEEN MARY U
   Kaarmukilan SP, 2020, P 4 INT C COMPUTING, P471, DOI [10.1109/ICCMC48092.2020.ICCMC-00088, DOI 10.1109/ICCMC48092.2020.ICCMC-00088]
   Kawasaki N, 1993, THESIS DEPT ELECT EN
   Langbein J, 2006, REPORT SCOTTISH EXEC
   Li ZB, 2021, COMPUT ELECTRON AGR, V182, DOI 10.1016/j.compag.2021.106054
   Maeda H, 2018, Arxiv, DOI arXiv:1801.09454
   McGrath RM., 2000, ENTREPRENEURIAL MIND
   Mittal P, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104046
   Morelle K, 2013, NAT CONSERV-BULGARIA, P53, DOI 10.3897/natureconservation.5.4634
   Murray-Tuite P, 2013, TRANSPORT RES C-EMER, V27, P25, DOI 10.1016/j.trc.2012.11.005
   Nascimento JC, 2006, IEEE T MULTIMEDIA, V8, P761, DOI 10.1109/TMM.2006.876287
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Prabhakar G, 2017, IEEE REGION 10 SYMP
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren Y, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8050813
   Sadeghniiat-Haghighi Khosro, 2015, Ind Psychiatry J, V24, P12, DOI 10.4103/0972-6748.160915
   Shao ZF, 2018, IEEE T BIG DATA, V4, P105, DOI 10.1109/TBDATA.2017.2715815
   Sharma SU, 2017, IEEE ACCESS, V5, P347, DOI 10.1109/ACCESS.2016.2642981
   Chahal KS, 2018, Arxiv, DOI arXiv:1808.07256
   Slobogin C, 2002, MISS LJ, V72, P213, DOI [DOI 10.2139/SSRN.364600, 10.2139/ssrn.364600]
   Soni AN., 2018, INT J ADV RES ELECT, V7, P1849, DOI [10.15662/IJAREEIE.2018.0704058, DOI 10.15662/IJAREEIE.2018.0704058]
   Southworth M, 2005, J URBAN PLAN DEV, V131, P246, DOI 10.1061/(ASCE)0733-9488(2005)131:4(246)
   Speakman JR, 2011, MOL ASPECTS MED, V32, P159, DOI 10.1016/j.mam.2011.07.001
   Summala H, 1996, SAFETY SCI, V22, P103, DOI 10.1016/0925-7535(96)00009-4
   Sun ZH, 2004, ITSC 2004: 7TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, PROCEEDINGS, P585
   The Times of India, 2022, The Times of India
   Tian-Hao Wu, 2021, 2021 3rd World Symposium on Artificial Intelligence (WSAI), P24, DOI 10.1109/WSAI51899.2021.9486316
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang F, 2022, SIGNAL IMAGE VIDEO P, V16, P29, DOI 10.1007/s11760-021-01953-y
   Wolf M, 2007, EURASIP J EMBED SYST, DOI 10.1155/2007/74706
   Yang Q, 1996, TRANSPORT RES C-EMER, V4, P113, DOI 10.1016/S0968-090X(96)00006-X
   Yang ZJ, 2018, COMP MATER SCI, V151, P278, DOI 10.1016/j.commatsci.2018.05.014
   Yilin Zhao, 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P55, DOI 10.1109/6979.869021
   Zou Z., 2019, arXiv
NR 55
TC 2
Z9 2
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34589
EP 34607
DI 10.1007/s11042-023-15019-3
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000945792800015
DA 2024-07-18
ER

PT J
AU Neelakantan, P
AF Neelakantan, P.
TI A secure framework for the cloud to protect the virtual machine from
   malicious events
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual machine; Malicious activity; Detects attacks; Secure data
   sharing; User needs; Cloud computing
ID CHALLENGES; MITIGATION; NETWORK; PRIVACY
AB In recent years, Virtual Machine (VM) has played an important role for cloud computing applications to execute the assigned user tasks. However, the cloud is a big open environment, so it is vulnerable to attack; happening attack in VM can disturb the entire data sharing process. So the current research has proposed a novel Whale-based CatBoost (WbCB) mechanism to protect VM from malicious activities and to afford security for the connected VM's in cloud computing. The main aim of this present article is to enhance the confidential score of the VM cloud sharing model. The required number of VM is primarily designed in the MATLAB environment, then a novel WbCB model was designed with suitable parameters to secure the data during transmission. The confidential score of the proposed model in front of the Cloud Malware Injection (CMI) attack has been investigated. Still, the proposed WbCB has reported the best confidential rate as 99%, data sharing rate as 0.965, and attack detection score as 99.8%. Also, the time taken for scheduling 6000 jobs is 1000s, and the reported lower false rate is 5%. Thus compared to the recent existing models, the proposed WbCB model has tremendously maximized the performance rate.
C1 [Neelakantan, P.] VNR Vignana Jyothi Inst Engn & Technol, Hyderabad 500090, Telangana, India.
C3 Vallurupalli Nageswara Rao Vignana Jyothi Institute of Engineering
   &Technology (VNR VJIET)
RP Neelakantan, P (corresponding author), VNR Vignana Jyothi Inst Engn & Technol, Hyderabad 500090, Telangana, India.
EM pneelakantanme@gmail.com
CR Ali A, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.4272
   Aljumah A, 2020, IET COMMUN, V14, P1185, DOI 10.1049/iet-com.2019.0040
   Alkadi O, 2021, IEEE INTERNET THINGS, V8, P9463, DOI 10.1109/JIOT.2020.2996590
   Alkadi O, 2020, IEEE ACCESS, V8, P104893, DOI 10.1109/ACCESS.2020.2999715
   Alouffi B, 2021, IEEE ACCESS, V9, P57792, DOI 10.1109/ACCESS.2021.3073203
   Alshehri M, 2020, 2020 7TH IEEE INTERNATIONAL CONFERENCE ON CYBER SECURITY AND CLOUD COMPUTING (CSCLOUD 2020)/2020 6TH IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING AND SCALABLE CLOUD (EDGECOM 2020), P36, DOI 10.1109/CSCloud-EdgeCom49738.2020.00016
   Aluvalu R., 2021, INTELLIGENT COMPUTIN, P271, DOI [10.1007/978-981-15-7421-4_25, DOI 10.1007/978-981-15-7421-4_25]
   Arora G, 2016, 2016 1ST INTERNATIONAL CONFERENCE ON INNOVATION AND CHALLENGES IN CYBER SECURITY (ICICCS 2016), P1, DOI 10.1109/ICICCS.2016.7542312
   Baker T, 2015, IEEE ACM INT SYMP, P961, DOI 10.1109/CCGrid.2015.37
   Bhushan K, 2019, MULTIMED TOOLS APPL, V78, P4267, DOI 10.1007/s11042-017-5522-z
   Chen CL, 2020, HUM-CENT COMPUT INFO, V10, DOI 10.1186/s13673-020-00221-1
   Chen YH, 2020, IEEE T POWER SYST, V35, P711, DOI 10.1109/TPWRS.2019.2930706
   Chennam K.K., 2021, ARCHITECTURAL WIRELE, V196, P13, DOI [10.1007/978-981-16-0386-0_2, DOI 10.1007/978-981-16-0386-0_2]
   Choe H., 2020, CONVERGENCE ICT SMAR, P119, DOI [10.1007/978-3-030-41368-2_6, DOI 10.1007/978-3-030-41368-2_6]
   Durga Devi TJB, 2021, J AMB INTEL HUM COMP, V12, P3869, DOI 10.1007/s12652-020-01728-2
   Gerard A, 2020, INT C APPL HUMAN FAC, DOI [10.1007/978-3-030-51041-1_52, DOI 10.1007/978-3-030-51041-1_52]
   Goncalves CF, 2020, 2020 IEEE INT S SOFT, DOI [10.1109/ISSREW51248.2020.00078, DOI 10.1109/ISSREW51248.2020.00078]
   Gonçalves CF, 2017, IEEE INT SYMP SOFTW, P100, DOI 10.1109/ISSREW.2017.70
   Gupta BB, 2018, MULTIMED TOOLS APPL, V77, P9203, DOI 10.1007/s11042-017-5301-x
   Gupta BB, 2017, MULTIMED TOOLS APPL, V76, P22669, DOI 10.1007/s11042-017-5110-2
   Kohli R, 2021, IOT HEALTHCARE AMBIE, P293, DOI 10.1007/978-981-15-9897-5_14
   Kumar AMS, 2019, CLUSTER COMPUT, V22, P2179, DOI 10.1007/s10586-018-2515-2
   Masood A, 2020, IEEE COMMUN SURV TUT, V22, P2725, DOI 10.1109/COMST.2020.3012961
   Moustafa N, 2017, MIL COMM INF SYST CO
   Namasudra S, 2020, COMPUT COMMUN, V151, P539, DOI 10.1016/j.comcom.2019.12.041
   Negi PS, 2020, PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING, P129, DOI [10.1109/confluence47617.2020.9057961, 10.1109/Confluence47617.2020.9057961]
   Pallavi G. B., 2022, International Journal of Information Technology, V14, P703, DOI 10.1007/s41870-019-00416-5
   Patil R, 2019, COMPUT SECUR, V85, P402, DOI 10.1016/j.cose.2019.05.016
   Praveena D, 2020, MULTIMED TOOLS APPL, V79, P5161, DOI 10.1007/s11042-018-6339-0
   Qureshi KN, 2021, COMPUT NETW, V184, DOI 10.1016/j.comnet.2020.107647
   Rabbani M, 2020, J NETW COMPUT APPL, V151, DOI 10.1016/j.jnca.2019.102507
   Rawas S, 2021, MULTIMED TOOLS APPL, V80, P15541, DOI 10.1007/s11042-021-10616-6
   Sun PJ, 2020, J NETW COMPUT APPL, V160, DOI 10.1016/j.jnca.2020.102642
   Thanka MR, 2019, CLUSTER COMPUT, V22, P10905, DOI 10.1007/s10586-017-1223-7
   Wang H, 2020, WORLD WIDE WEB, V23, P951, DOI 10.1007/s11280-019-00704-x
   Wu YL, 2021, IEEE T DEPEND SECURE, V18, P2820, DOI 10.1109/TDSC.2020.2966632
NR 36
TC 0
Z9 0
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 33811
EP 33834
DI 10.1007/s11042-023-14740-3
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000945792800012
DA 2024-07-18
ER

PT J
AU Su, H
   Ye, ZG
   Liu, YP
   Yu, SS
AF Su, Hai
   Ye, Zigui
   Liu, Yaping
   Yu, SongSen
TI Seam carving based on dynamic energy regulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Seam carving; Significance area; Image structure; Dynamic energy change
ID ALGORITHM
AB Seam carving algorithm is widely used in content-based image scaling. By calculating the energy map of the image, it repeatedly removes the pixel line with the lowest energy sum, which can effectively retain the proportion of significant areas within the image after the image is scaled down. The traditional seam carving does not take into account the variation in full-image energy caused by each carving, which is based on the energy map calculated at the first time. The results of these methods are prone to distortion. So we put forward a dynamic energy regulation method to simulate the energy change in each carving to improve the effect of seam carving. Our method adjusts the energy value of each pixel after each carving according to how much each pixel is affected by carving, so as to simulate the extra energy introduced by each carving. In the paper, we discuss the way to regulate energy. We designed a randomized double-blind experiment to compare our method with several current typical methods. The experimental results demonstrated the advantages of our method over other methods.
C1 [Su, Hai; Ye, Zigui; Yu, SongSen] South China Normal Univ, Coll Software, Foshan 528225, Peoples R China.
   [Liu, Yaping] South China Normal Univ, Coll Int Business, Foshan 528225, Peoples R China.
C3 South China Normal University; South China Normal University
RP Yu, SS (corresponding author), South China Normal Univ, Coll Software, Foshan 528225, Peoples R China.
EM yss8109@163.com
CR Aghchehkohal MG, 2015, 2015 SIGNAL PROCESSING AND INTELLIGENT SYSTEMS CONFERENCE (SPIS), P43, DOI 10.1109/SPIS.2015.7422309
   Ahmad M, 2020, 2020 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC)
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Dong WM, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618471
   Geem ZW, 2001, SIMULATION, V76, P60, DOI 10.1177/003754970107600201
   Guo YC, 2018, J ELECTRON INF TECHN, V40, P331, DOI 10.11999/JEIT170501
   [郭正红 Guo Zhenghong], 2018, [云南大学学报. 自然科学版, Journal of Yunnan University. Natural Science], V40, P222
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   [林晓 Lin Xiao], 2015, [计算机科学, Computer Science], V42, P289
   Lin X, 2012, SCI CHINA INFORM SCI, V55, P1073, DOI 10.1007/s11432-012-4565-z
   Lin YQ, 2020, INT J COMPUT SCI ENG, V22, P190, DOI 10.1504/IJCSE.2020.107341
   Mukherjee P, 2020, SIGNAL PROCESS-IMAGE, V87, DOI 10.1016/j.image.2020.115890
   Peng G., 2011, J WUHAN UNIV TECHNOL, V18, P74
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Song E, 2019, IEEE ACCESS, V7, P284, DOI 10.1109/ACCESS.2018.2885347
   Suresha D, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT), P387, DOI 10.1109/ICATCCT.2016.7912029
   Thévenaz P, 2000, IEEE T MED IMAGING, V19, P739, DOI 10.1109/42.875199
   WHITLEY D, 1994, STAT COMPUT, V4, P65, DOI 10.1007/BF00175354
   [肖志涛 Xiao Zhitao], 2015, [电子与信息学报, Journal of Electronics & Information Technology], V37, P1892
   [赵伟伟 Zhao Weiwei], 2014, [云南大学学报. 自然科学版, Journal of Yunnan University. Natural Science], V36, P181
   Zhou B, 2016, J VIS COMMUN IMAGE R, V41, P21, DOI 10.1016/j.jvcir.2016.09.002
NR 23
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 25795
EP 25810
DI 10.1007/s11042-023-14516-9
EA MAR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000943970200016
DA 2024-07-18
ER

PT J
AU Roopa, YM
   Reddy, BB
   Babu, MR
   Nayak, RK
AF Roopa, Y. Mohana
   Reddy, B. Bhaskar
   Babu, Meenigi Ramesh
   Nayak, R. Krishna
TI Teaching learning-based brain storm optimization tuned Deep-CNN for
   Alzheimer's disease classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alzheimer's disease; Segmentation; Deep CNN; Optimization; Features
AB Alzheimer's disease (AD) as an incurable disease that affects the mental functions of the patients. The early diagnosis of AD requires automatic Computer-Aided Diagnosis, which needs advanced technical practices like Deep Learning algorithms. This paper proposes a hybrid optimization tuned Deep convolutional neural network (Deep CNN) based automatic AD detection strategy. The significance of the proposed strategy lies in the optimal segmentation of Magnetic resonance imaging (MRI) and the classification of AD using the Deep CNN, which is trained using the proposed teaching learning-based brainstorm (TLBS) optimization algorithm that inherits the characteristic features of learning search agents and the associative search agents to obtain the global optimal solution for tuning the weights of the classifier. The performance evaluation using the accuracy, sensitivity, specificity, and F-Measure are obtained 97.03%, 97.18%, 97.03%, and 97.39% respectively, which shows the effectiveness of the proposed method in detecting the AD of patients.
C1 [Roopa, Y. Mohana] Inst Aeronaut Engn, Comp Sci & Engn, Hyderabad 500043, India.
   [Reddy, B. Bhaskar] St Peters Engn Coll, Elect & Commun Engn, Hyderabad, Telangana, India.
   [Babu, Meenigi Ramesh] Cognizant Technol Solut India Pvt Ltd, AIA Dept, Hyderabad, India.
   [Nayak, R. Krishna] Vignan Inst Technol & Management Women, Comp Sci & Engn, Hyderabad, India.
C3 St. Peter's Institute of Higher Education & Research
RP Roopa, YM (corresponding author), Inst Aeronaut Engn, Comp Sci & Engn, Hyderabad 500043, India.
EM ymohanap97@gmail.com
RI , Y Mohana Roopa/HKO-2182-2023
OI , Y Mohana Roopa/0000-0002-8528-9637
CR Aderghal K, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e05652
   Altinkaya E., 2020, J Institut Electron Comp, V1, P39
   Alzheimer's Assoc, 2018, ALZHEIMERS DEMENT, V14, P367, DOI 10.1016/j.jalz.2018.02.001
   An N, 2020, J BIOMED INFORM, V105, DOI 10.1016/j.jbi.2020.103411
   An X, 2020, DYNAMIC FUNCTIONAL C
   [Anonymous], ADNI DATASET
   [Anonymous], ALZHMEIRS DATASET
   Anwar SM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1088-1
   Bi XL, 2020, NEUROCOMPUTING, V392, P296, DOI 10.1016/j.neucom.2018.11.111
   Binu D., 2020, IEEE T IND ELECTRON, V68, P1
   Gottapu RD, 2018, PROCEDIA COMPUT SCI, V140, P179, DOI 10.1016/j.procs.2018.10.327
   Hinrichs C, 2009, NEUROIMAGE, V48, P138, DOI 10.1016/j.neuroimage.2009.05.056
   Hosseini-Asl E, 2016, IEEE IMAGE PROC, P126, DOI 10.1109/ICIP.2016.7532332
   Ishaq A, 2021, IEEE ACCESS, V9, P39707, DOI 10.1109/ACCESS.2021.3064084
   Jain R, 2019, COGN SYST RES, V57, P147, DOI 10.1016/j.cogsys.2018.12.015
   Janghel RR, 2020, DEEP LEARNING NEURAL
   Kara A, 2021, EXPERT SYST APPL, V180, DOI 10.1016/j.eswa.2021.115153
   Koh JEW, 2020, PATTERN RECOGN LETT, V135, P106, DOI 10.1016/j.patrec.2020.03.014
   Kumar PR, 2018, COMPUT ELECTR ENG, V72, P283, DOI 10.1016/j.compeleceng.2018.09.019
   Lahmiri S, 2019, BIOMED SIGNAL PROCES, V52, P414, DOI 10.1016/j.bspc.2018.08.009
   Lloyd K, 2017, MACH VISION APPL, V28, P361, DOI 10.1007/s00138-017-0830-x
   Naganandhini S, 2020, CURR CONTENTS, P351
   Nawaz A, 2020, P IEEE 23 INT MULTIT, P1
   Park JH, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0256-0
   Patel SK, 2022, CURR CONTENTS
   Previtali F, 2017, COMPUT METH PROG BIO, V143, P89, DOI 10.1016/j.cmpb.2017.03.006
   Puente-Castro A, 2020, COMPUT BIOL MED, V120, DOI 10.1016/j.compbiomed.2020.103764
   Rao RV., 2016, Teach. Learn. Based Optim. Algorithm, P9, DOI DOI 10.1007/978-3-319-22732-02
   Rupapara V, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-04835-6
   Shi YH, 2011, LECT NOTES COMPUT SC, V6728, P303, DOI 10.1007/978-3-642-21515-5_36
   Song TA, 2019, I S BIOMED IMAGING, P414, DOI 10.1109/ISBI.2019.8759531
   Suresha H.S., 2020, P 3 INT C ADV ELECT, P1, DOI 10.1109/ICAECC50550.2020.9339504
   Zhang J, 2021, MAGN RESON IMAGING, V78, P119, DOI 10.1016/j.mri.2021.02.001
   Zhou X, 2021, ALZHEIMERS RES THER, V13, DOI 10.1186/s13195-021-00797-5
NR 34
TC 1
Z9 1
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 33333
EP 33356
DI 10.1007/s11042-023-14815-1
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943163700001
DA 2024-07-18
ER

PT J
AU Chen, L
   Wang, RD
   Dong, L
   Yan, DQ
AF Chen, Lang
   Wang, Rangding
   Dong, Li
   Yan, Diqun
TI Imperceptible adversarial audio steganography based on psychoacoustic
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio steganography; Adversarial examples; Psychoacoustic model; Masking
   threshold
AB Recently, deep learning based audio steganalysis methods have demonstrated superior performance in detecting the conventional audio steganography, which poses great chanllegnes to the conveiontional audio steganography. In this work, observed that the neural network can easily be deceived by specially perturbed inputs, i.e., adversarial examples, we propose an imperceptible audio steganography method based on psychoacoustic model. Specifically, we first add perturbation on the stego audio for constructing noise stego audio, which is delivered to the trained steganalyzer for misclassification. The perturbation is optimized in the adversarial process, aiming to seek an optimal perturbation that guarantee the imperceptibility and undetectability of stego audio. Further consider that the difficulty to optimize the threshold loss function using gradient back-progagation, we adopt two-stage optimization strategy to minimize the loss function. The first stage attempts to find a suitable perturbation to deceive the steganalyzer. The second stage concentrates on further optimizing the perturbation to make the stego imperceptible. For the practical steganography, the optimal perturbation obtained from the adversarial attack process is added on the original cover audio to construct the adversarial cover audio. Then one can use information embedding algorithm to embed the secret message on the adversarial cover to generate stego audio. Extensive experiments show that the proposed method can generate the adversarial cover audio with high perceptual quality and the undetectability performance outperforms the conventional audio steganography schemes.
C1 [Chen, Lang; Wang, Rangding; Dong, Li; Yan, Diqun] Ningbo Univ, Fac Elect Engn & Comp Sci, Ningbo, Peoples R China.
C3 Ningbo University
RP Wang, RD; Dong, L (corresponding author), Ningbo Univ, Fac Elect Engn & Comp Sci, Ningbo, Peoples R China.
EM chenlang683@163.com; wangrangding@nbu.edu.cn; dongli@nbu.edu.cn;
   yandiqun@nbu.edu.cn
RI Yan, Diqun/AAY-6775-2021
OI Yan, Diqun/0000-0002-5241-7276; Chen, Lang/0000-0003-2493-8717
FU National Natural Science Foundation of China [62171244]; Ningbo Natural
   Science Foundation-Young Doctoral Innovation Research Project
   [2022J080]; Major Special Projects of "Unveiling the List and Taking the
   Lead" [2022Z074]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 62171244), Ningbo Natural Science Foundation-Young
   Doctoral Innovation Research Project (Grant No. 2022J080), and Major
   Special Projects of "Unveiling the List and Taking the Lead" and
   "Scientific and Technological Innovation 2025" in Ningbo (Grant No.
   2022Z074).
CR Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Bengio S, 2016, ARXIV
   Bosi M., 2002, Introduction to digital audio coding and standards
   Chen BL, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P85, DOI 10.1145/3082031.3083234
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Garofolo JS, 1993, NIST SPEECH DISC, V1-1.1
   Goodfellow I. J., 2014, ARXIV
   Hayes J., 2017, ARXIV
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Li B, 2014, IEEE T INF FOREN SEC, V9, P1264, DOI 10.1109/TIFS.2014.2326954
   Lin Y., 2015, PRINCIPLES PSYCHOACO, DOI DOI 10.1007/978-3-319-07974-5_2
   Lin YZ, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P210, DOI 10.1145/3335203.3335736
   Luo WQ, 2017, LECT NOTES COMPUT SC, V10431, P177, DOI 10.1007/978-3-319-64185-0_14
   Luo WQ, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3190575
   Madry A., 2018, ARXIV
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Priority areas, 2002, ADV UT MULT PROM HIG
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023
   Sharp Toby, 2001, Information Hiding, V2137, P13, DOI 10.1007/3-540-45496-9_2
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang WX, 2021, IEEE T INF FOREN SEC, V16, P952, DOI 10.1109/TIFS.2020.3025438
   Tang WX, 2019, IEEE T INF FOREN SEC, V14, P2074, DOI 10.1109/TIFS.2019.2891237
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Volkhonskiy D, 2017, ARXIV
   Wu ST, 2018, MULTIMED TOOLS APPL, V77, P10437, DOI 10.1007/s11042-017-4440-4
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Zhang YW, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P67, DOI 10.1145/3206004.3206012
NR 31
TC 0
Z9 1
U1 6
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26451
EP 26463
DI 10.1007/s11042-023-14772-9
EA MAR 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000943009100019
DA 2024-07-18
ER

PT J
AU Zang, Y
   Yu, B
   Zhao, SG
AF Zang, Ying
   Yu, Bo
   Zhao, Shuguang
TI Lightweight seatbelt detection algorithm for mobile device
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Seatbelt detection; Channel pruning; SlimSSDMV2; LSD linear detection
AB It is an important task of modern traffic management for traffic police to inspect whether drivers wear seatbelts, and mobile law enforcement brings convenience to traffic police. However, due to the efficiency and memory constraints of mobile devices, the intelligent algorithm with significant parameters cannot be directly used on mobile devices. So, it is a challenge to detect driver and seatbelt by object detection algorithm on mobile. In order to solve this problem, we propose an efficient and lightweight model for seatbelt detection. First, we visualize the layers of SSD MobileNet V2 and delete the feature channels with low contribution and high similarity. Then we can get the pruned SlimSSDMV2 model for driver and seatbelt detection. Second, the LSD liner segment detection multipoint fitting algorithm is used for screening the undetected seatbelt area, which can further improve the detection performance of the model. We compare our model with other existing methods, and the experimental results demonstrate that our model performs better in practice.
C1 [Zang, Ying] Huzhou Univ, Sch Informat Engn, Huzhou 313000, Peoples R China.
   [Yu, Bo] Jilin Univ, Sch Artificial Intelligence, Changchun 130012, Peoples R China.
   [Zhao, Shuguang] Trial Retail Engn Co Ltd, Yantai 110168, Peoples R China.
C3 Huzhou University; Jilin University
RP Zang, Y (corresponding author), Huzhou Univ, Sch Informat Engn, Huzhou 313000, Peoples R China.
EM 02750@zjhu.edu.cn; byu20@mails.jlu.edu.cn
RI wang, mengyi/KEI-9461-2024; WANG, YANG/JFA-8821-2023; Zhang,
   Yusi/JNS-2335-2023; Sun, Xinyu/JXX-2281-2024; Chen, Chao/JHS-6563-2023;
   Liu, Jingyi/JWP-6326-2024; LI, LIXIN/KFS-0074-2024; zhao,
   lin/JPK-8436-2023; li, wl/JJC-0768-2023; Li, Shuyao/JRY-8603-2023; liu,
   kaiyuan/JHU-0258-2023; LI, Xiang/JBJ-8387-2023; Liu, Yuan/JFB-4766-2023;
   Wang, Han/JJF-2614-2023; li, jiaxin/JNT-5073-2023
CR [Anonymous], 2020, COMMON OBJECTS CONTE
   Chen Y., 2015, ELECT MEAS TECHNOL, V38, P123
   Guo H, 2011, P 2011 IEEE INT C VE
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Li Zechao, 2021, IEEE Trans Pattern Anal Mach Intell
   Liu W., 2016, arXiv
   Lou JA, 2023, IEEE T NEUR NET LEAR, V34, P1732, DOI 10.1109/TNNLS.2020.3027822
   Luo X, 2021, IEEE T NETW SCI ENG, V8, P463, DOI 10.1109/TNSE.2020.3040407
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Sandler M, 2017, ARXIV
   Tian T., 2016, J CHIN PEOPLES PUBLI, V2, P71
   von Gioi RG, 2012, IMAGE PROCESS ON LIN, V2, P35, DOI 10.5201/ipol.2012.gjmr-lsd
   Wang M., 2016, KNOWL-BASED SYST, V11, P240
   [吴天舒 Wu Tianshu], 2019, [计算机辅助设计与图形学学报, Journal of Computer-Aided Design & Computer Graphics], V31, P126
   Wu Y., 2017, COLD REG SCI TECHNOL, V4, P175
   Yang D, 2020, 32TH CHINESE CONTROL
   Yang K., 2017, J. China Univ. Metrol, V28, P326
   Ye Jianbo, 2018, P INT C LEARN REPR
   Zeiler M.D., 2013, arXiv
   Zhang P., 2019, ARXIV
   Zhao HL., 2009, PREDICTION MODELING
   Zhou HJ, 2017, IEEE INT CONF COMP V, P760, DOI 10.1109/ICCVW.2017.95
   Zhu XB, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107619
NR 26
TC 2
Z9 2
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24505
EP 24519
DI 10.1007/s11042-023-14555-2
EA MAR 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000941926100005
DA 2024-07-18
ER

PT J
AU Thanikkal, JG
   Dubey, AK
   Thomas, MT
AF Thanikkal, Jibi G.
   Dubey, Ashwani Kumar
   Thomas, M. T.
TI Deep-Morpho Algorithm (DMA) for medicinal leaves features extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Leaf morphology; Medicinal plant; Plant recognition;
   Feature recognition
ID SHAPE
AB Presently, for the identification and classification of images, various deep learning techniques are being used. In these techniques, the whole image is considered to produce similar feature sets for many images. As a result, this mechanism loses many of its features at the final stage. Therefore, to analyze and identify medicinal leaves through an artificial eye of botanists, it was emphasized that the leaf image features should remain preserved till the final stage of classification for better accuracy. The existing plant identification approaches are trained using the leaf images. So leaf features are lost in the different stages of the convolution process and the same feature values are generated for similar type leaf images. This raises ambiguity in the results and affects the accuracy of leaf image identification. But here, in this proposed deep learning-based plant leaves morphological feature recognition system, leaf morphological features are used to train the system. Morphological features are identified to recognize a plant leaf. Here, morphological features of medicinal plant leaves, venation, shapes, apices, and bases are extracted and analyzed to predict the image class. So, the leaf features remain persevered until the final stage. The proposed feature recognition analysis improves the accuracy of the leaf identification method. In this, more than 300 leaves from 18 different plant families are collected and trained to build the deep learning classifier and achieve 96% accuracy. The performance evaluation was also conducted over "Flavia", "Swedish" and "Leaf" data set and obtained 91%, 87% and 91% accuracy. The performance of image classification and feature preservation algorithms with less computational power are indicating the potential applicability of the proposed Deep - Morpho Algorithm (DMA) in medicinal plants and leaves identification.
C1 [Thanikkal, Jibi G.] Amity Univ Uttar Pradesh, Amity Sch Engn & Technol, Dept Comp Sci & Engn, Noida 201313, UP, India.
   [Dubey, Ashwani Kumar] Amity Univ Uttar Pradesh, Amity Sch Engn & Technol, Dept Elect & Commun Engn, Noida 201313, UP, India.
   [Thomas, M. T.] St Thomas Coll, Dept Bot, Trichur, Kerala, India.
C3 Amity University Noida; Amity University Noida
RP Dubey, AK (corresponding author), Amity Univ Uttar Pradesh, Amity Sch Engn & Technol, Dept Elect & Commun Engn, Noida 201313, UP, India.
EM jibimary@gmail.com; dubey1ak@gmail.com; thomastbgri@gmail.com
RI Dubey, Ashwani Kumar/ABI-1337-2020
OI Dubey, Ashwani Kumar/0000-0003-0778-9262; M T,
   Thomas/0000-0001-5952-5125; Thanikkal, Jibi/0000-0002-5577-1158
CR Amlekar MM, 2015, INT C PERV COMP, P1, DOI DOI 10.1109/PERVASIVE.2015.7087088
   Arun Priya C., 2012, Proceedings of the 2012 International Conference on Pattern Recognition, Informatics and Medical Engineering (PRIME), P428, DOI 10.1109/ICPRIME.2012.6208384
   Atoum Y, 2016, PATTERN RECOGN, V53, P287, DOI 10.1016/j.patcog.2015.11.021
   Cohen Marc Maurice, 2014, J Ayurveda Integr Med, V5, P251, DOI 10.4103/0975-9476.146554
   Demisse GG, 2018, IEEE T PATTERN ANAL, V40, P1338, DOI 10.1109/TPAMI.2017.2711607
   George Juby, 2017, 2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS), P2216, DOI 10.1109/ICECDS.2017.8389846
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Janahiraman TV, 2019, 2019 7TH INTERNATIONAL CONFERENCE ON SMART COMPUTING & COMMUNICATIONS (ICSCC), P79
   Kadir A., 2011, International Journal of Computer Trends and Technology, P225, DOI DOI 10.48550/ARXIV.1401.4447
   Kadir Abdul., 2012, International Journal of Advanced Science and Technology, V44, P113
   Kebapci H, 2011, COMPUT J, V54, P1475, DOI 10.1093/comjnl/bxq037
   Kheirkhah FM, 2019, IET COMPUT VIS, V13, P369, DOI 10.1049/iet-cvi.2018.5028
   Kim W, 2012, IEEE SIGNAL PROC LET, V19, P127, DOI 10.1109/LSP.2011.2182648
   Kolivand H, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191447
   Kumar M, 2019, IEEE ACCESS, V7, P163912, DOI 10.1109/ACCESS.2019.2952176
   Kumar S., 2012, INDIAN J COMPUTER SC, V3, P436
   Lam BSY, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107153
   Larese MG, 2014, PATTERN RECOGN, V47, P158, DOI 10.1016/j.patcog.2013.06.012
   Lee S, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI [10.14722/ndss.2017.23457, 10.1016/j.patcog.2017.05.015]
   Leong KK, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC CONTROL AND INTELLIGENT SYSTEMS (I2CACIS 2020), P39, DOI [10.1109/I2CACIS49202.2020.9140103, 10.1109/i2cacis49202.2020.9140103]
   Liu XY, 2019, IEEE ACCESS, V7, P139635, DOI 10.1109/ACCESS.2019.2942144
   López A, 2017, IEEE LAT AM T, V15, P2185, DOI 10.1109/TLA.2017.8070425
   Mall PK, 2022, INT J SYST ASSUR ENG, V13, P658, DOI 10.1007/s13198-021-01580-3
   Mzoughi O, 2012, LECT NOTES COMPUT SC, V7324, P348, DOI 10.1007/978-3-642-31295-3_41
   Neto JC, 2006, COMPUT ELECTRON AGR, V50, P121, DOI 10.1016/j.compag.2005.09.004
   Pawara P, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107528
   Randrianasoa JF, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107667
   Raut SP, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P1579, DOI 10.1109/ICCONS.2018.8663028
   Salima A, 2015, INT C ADV COMP SCI I, P275, DOI 10.1109/ICACSIS.2015.7415152
   Shu H, 2019, AAAI CONF ARTIF INTE, P4943
   Silva PFB, 2013, LECT NOTES COMPUT SC, V7950, P197, DOI 10.1007/978-3-642-39094-4_23
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soderkvist O., 2001, COMPUTER VISION CLAS, P1
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Tan JW, 2020, IEEE ACM T COMPUT BI, V17, P82, DOI 10.1109/TCBB.2018.2848653
   Thanikkal JG, 2018, 7 INT C RELIABILITY, P1
   Thanikkal JG, 2020, IEEE SENS J, V20, P13103, DOI 10.1109/JSEN.2020.3002909
   Thanikkal JG, 2017, 2017 RECENT DEVELOPMENTS IN CONTROL, AUTOMATION AND POWER ENGINEERING (RDCAPE), P404, DOI 10.1109/RDCAPE.2017.8358305
   Wang B, 2019, IEEE T IMAGE PROCESS, V28, P5963, DOI 10.1109/TIP.2019.2921526
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120
   Yang CZ, 2019, IEEE ACCESS, V7, P178108, DOI 10.1109/ACCESS.2019.2958416
   Zeng JX, 2019, IEEE ACCESS, V7, P57163, DOI 10.1109/ACCESS.2019.2913688
   Zhang J, 2019, PATTERN RECOGN, V91, P175, DOI 10.1016/j.patcog.2019.02.024
   Zhang SW, 2013, PATTERN RECOGN, V46, P1891, DOI 10.1016/j.patcog.2013.01.015
   Zhang Y, 2020, IEEE ACCESS, V8, P56607, DOI 10.1109/ACCESS.2020.2982456
   Zhao C, 2015, PATTERN RECOGN, V48, P3203, DOI 10.1016/j.patcog.2015.04.004
   Zhao TM, 2019, IEEE ACCESS, V7, P49691, DOI 10.1109/ACCESS.2019.2911056
NR 48
TC 0
Z9 0
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27905
EP 27925
DI 10.1007/s11042-023-14567-y
EA FEB 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000939106800009
DA 2024-07-18
ER

PT J
AU Wang, YW
   Liu, JC
   Feng, LZ
AF Wang, Youwei
   Liu, Jiangchun
   Feng, Lizhou
TI Text length considered adaptive bagging ensemble learning algorithm for
   text classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ensemble learning; Base classifier; Text classification; Deep learning;
   Random sampling
ID SMOTE; PREDICTION
AB Ensemble learning constructs strong classifiers by training multiple weak classifiers, and is widely used in text classification field. In order to improve the text classification accuracy, a text length considered adaptive bootstrap aggregating (Bagging) ensemble learning algorithm (called TC_Bagging) for text classification is proposed. Firstly, the performances of different typical deep learning methods in processing long and short texts are compared, and the optimal base classifier groups are constructed for long and short texts. Secondly, an adaptive threshold group based random sampling method is proposed to realize the training of long text and short text sample subsets while retaining the proportions of samples in different categories. Finally, in order to avoid the problem that the sampling process may decrease the accuracy, the smooth inverse frequency (SIF) based text vector generation algorithm is combined with the traditional weighted voting classifier ensemble method to obtain the final classification result. By comparing TC_Bagging with several other baseline methods on three datasets, our evaluation suggests that the results of TC_Bagging are approximately 0.120, 0.300 and 0.060 better than that of RF, WAVE, RF_WMVE and RF_WAVE in terms of average F-1, average sensitivity and average specificity measurements, respectively, showing that TC_Bagging has obvious advantage over typical ensemble learning algorithms.
C1 [Wang, Youwei] Cent Univ Finance & Econ, Sch Informat, Beijing 100081, Peoples R China.
   [Liu, Jiangchun] Credit Card Ctr Agr Bank China Ltd, Shanghai 200001, Peoples R China.
   [Feng, Lizhou] Tianjin Univ Finance & Econ, Sch Stat, Tianjin 300222, Peoples R China.
C3 Central University of Finance & Economics; Tianjin University of Finance
   & Economics
RP Feng, LZ (corresponding author), Tianjin Univ Finance & Econ, Sch Stat, Tianjin 300222, Peoples R China.
EM lzfeng15@126.com
FU National Natural Science Foundation of China [61906220]; Ministry of
   education of Humanities and Social Science project [19YJCZH178];
   National Social Science Foundation of China [18CTJ008]; Natural Science
   Foundation of Tianjin Province [18JCQNJC69600]; National Key R&D Program
   of China [2017YFB1400700]; Emerging Interdisciplinary Project of CUFE
FX AcknowledgmentsThis research is supported by the National Natural
   Science Foundation of China (No. 61906220), the Ministry of education of
   Humanities and Social Science project (No. 19YJCZH178), National Social
   Science Foundation of China (No.18CTJ008), the Natural Science
   Foundation of Tianjin Province (No. 18JCQNJC69600), the National Key R&D
   Program of China (2017YFB1400700) and the Emerging Interdisciplinary
   Project of CUFE.
CR Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Arora S., 2016, T ASS COMPUTATIONAL, V4, P385, DOI [10.1162/tacl_a_00106, DOI 10.1162/TACL_A_00106]
   Arora S, 2019, 5 INT C LEARN REPR I
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Bunkhumpornpat C, 2009, LECT NOTES ARTIF INT, V5476, P475, DOI 10.1007/978-3-642-01307-2_43
   Charbuty B., 2021, J APPL SCI TECHNOL T, VVol. 2, P20, DOI [10.38094/jastt20165, DOI 10.38094/JASTT20165]
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Cui Y, 2019, ARXIV
   de Morais RFAB, 2019, NEUROCOMPUTING, V343, P3, DOI 10.1016/j.neucom.2018.04.088
   De'ath G, 2000, ECOLOGY, V81, P3178, DOI 10.1890/0012-9658(2000)081[3178:CARTAP]2.0.CO;2
   Deng JF, 2021, COMPUT SPEECH LANG, V68, DOI 10.1016/j.csl.2020.101182
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Diao SZ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3336
   Ding H, 2020, MULTIMED TOOLS APPL, V79, P14871, DOI 10.1007/s11042-019-07856-y
   Dogan A, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P366, DOI 10.1109/ubmk.2019.8907028
   Du C, 2018, INT J COMPUT COMMUN, V13, P50, DOI 10.15837/ijccc.2018.1.3142
   Galar M, 2012, IEEE T SYST MAN CY C, V42, P463, DOI 10.1109/TSMCC.2011.2161285
   García S, 2009, EVOL COMPUT, V17, P275, DOI 10.1162/evco.2009.17.3.275
   Giveki D, 2021, MULTIMED TOOLS APPL, V80, P1223, DOI 10.1007/s11042-020-09759-9
   Guo B, 2019, NEUROCOMPUTING, V363, P366, DOI 10.1016/j.neucom.2019.07.052
   Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   Hsu KW, 2012, FRONT COMPUT SCI-CHI, V6, P498, DOI 10.1007/s11704-012-1163-6
   Huang Lang, 2019, ARXIV
   Xu JY, 2020, NEUROCOMPUTING, V386, P42, DOI 10.1016/j.neucom.2019.08.080
   Johnson R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P562, DOI 10.18653/v1/P17-1052
   Joulin A., 2016, ARXIV
   Khoshgoftaar TM, 2011, IEEE T SYST MAN CY A, V41, P552, DOI 10.1109/TSMCA.2010.2084081
   Kim Ahhyoun, 2020, [Journal of the Korean Data And Information Science Sociaty, 한국데이터정보과학회지], V31, P427, DOI 10.7465/jkdi.2020.31.2.427
   Kim H, 2011, J KOREAN STAT SOC, V40, P437, DOI 10.1016/j.jkss.2011.03.002
   Kim Y., 2014, P 2014 C EMP METH NA, P1746, DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/D14-1181]
   Kingma D. P., 2014, arXiv
   Lacy SE, 2015, IEEE C EVOL COMPUTAT, P758, DOI 10.1109/CEC.2015.7256967
   Lan Z., 2019, ARXIV190911942, DOI DOI 10.48550/ARXIV.1909.11942
   Li Chen, 2021, IJCAI
   Li Q, 2022, ACM T INTEL SYST TEC, V13, DOI 10.1145/3495162
   Li S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P138
   Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078
   Liu XY, 2009, IEEE T SYST MAN CY B, V39, P539, DOI 10.1109/TSMCB.2008.2007853
   Luengo J, 2011, SOFT COMPUT, V15, P1909, DOI 10.1007/s00500-010-0625-8
   Luo WL, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/4330701
   Marcinczuk M., 2021, P 11 GLOB WORDN C, P207
   Matloob F, 2021, IEEE ACCESS, V9, P98754, DOI 10.1109/ACCESS.2021.3095559
   Muliono Y., 2018, JURNAL INFORMATIKA J, V3, P157
   Murphree DH, 2018, COMPUT BIOL MED, V103, P109, DOI 10.1016/j.compbiomed.2018.10.017
   Pappagari R, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P838, DOI [10.1109/asru46091.2019.9003958, 10.1109/ASRU46091.2019.9003958]
   Peng H, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1063, DOI 10.1145/3178876.3186005
   Shah K., 2020, AUGMENT HUMAN RES, V5, P1, DOI DOI 10.1007/S41133-020-00032-0
   Sun B, 2018, FRONT COMPUT SCI-CHI, V12, P331, DOI 10.1007/s11704-016-5306-z
   Tang D., 2016, 26 INT C COMPUTATION, P3298, DOI DOI 10.48550/ARXIV.1512.01100
   Vaswani A, 2017, ADV NEUR IN, V30
   Xie JB, 2020, COMPUTING, V102, P683, DOI 10.1007/s00607-019-00766-9
   Yan P, 2021, 2021 ASIA-PACIFIC CONFERENCE ON COMMUNICATIONS TECHNOLOGY AND COMPUTER SCIENCE (ACCTCS 2021), P271, DOI 10.1109/ACCTCS52002.2021.00061
   Yang M, 2017, AAAI CONF ARTIF INTE, P5013
   Yang Z., 2016, P 2016 C N AM CHAPT, P1480, DOI [DOI 10.18653/V1/N16-1174, 10.18653/v1/n16-1174]
   Yao L, 2019, AAAI CONF ARTIF INTE, P7370
   Ye ZQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3014
   Zhang H, 2020, P 2020 C EMPIRICAL M
   Zhang YF, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P334
   Zhou Y, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2020.113864
   Zhou Z.-H., 2021, MACH LEARN, P315, DOI [10.1007/978-981-15-1967-313, DOI 10.1007/978-981-15-1967-3, 10.1007/978-981-15-1967-3]
   Zulqarnain M, 2021, ARAB J SCI ENG, V46, P8953, DOI 10.1007/s13369-021-05691-8
NR 64
TC 0
Z9 0
U1 6
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27681
EP 27706
DI 10.1007/s11042-023-14578-9
EA FEB 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000934850300009
DA 2024-07-18
ER

PT J
AU Misra, R
   Ray, KS
AF Misra, Rajesh
   Ray, Kumar S.
TI Swarm intelligence based object tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dual tracking; Dominant point; KLT (Kanade-Lucas-Tomasi) tracker; PSO
   tracker; Particle Swarm Optimization (PSO); Polygonal approximation
ID OPTICAL-FLOW; FLUID; OPTIMIZATION; MOTION
AB Though object tracking is a very old problem still there are several challenges to be solved; for instance, variation of illumination of light, noise, occlusion, sudden start and stop of moving object, shading etc. In this paper we propose a dual approach for object tracking based on optical flow and swarm Intelligence. The optical flow based KLT tracker, tracks the dominant points of the target object from first frame to last frame of a video sequence; whereas swarm Intelligence based PSO tracker simultaneously tracks the boundary information of the target object from second frame to last frame of the same video sequence. The boundary information of the target object is captured by the polygonal approximation of the same. The dual approach to object tracking is inherently robust with respect to the above stated problems. We compare the performance of the proposed dual tracking algorithm with several benchmark datasets and in most of the cases we obtain superior results.
C1 [Misra, Rajesh] SA Jaipuria Coll, 10 Raja Naba Krishna St, Kolklata, W Bengal, India.
   [Ray, Kumar S.] GLA Univ, 17KM Stone, NH2, Mathura 281406, Uttar Pradesh, India.
C3 GLA University
RP Misra, R (corresponding author), SA Jaipuria Coll, 10 Raja Naba Krishna St, Kolklata, W Bengal, India.
EM rajeshmisra.85@gmail.com; kumarsankar.ray@gla.ac.in
CR Ackerman PL, 2000, J GERONTOL B-PSYCHOL, V55, pP69, DOI 10.1093/geronb/55.2.P69
   Ackerman PL, 2005, PSYCHOL BULL, V131, P30, DOI 10.1037/0033-2909.131.1.30
   Ahmed H., 2012, Swarm Intelligence: Concepts, Models, and Applications
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   Ashton MC, 2006, INTELLIGENCE, V34, P469, DOI 10.1016/j.intell.2006.03.004
   Aslani S., 2013, INT J EL COMP ENG SY, V7, P1252
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bertinetto L, 2021, ARXIV
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Birchfield S, 2001, DERIVATION KAN UNPUB
   Blair C, 2006, BEHAV BRAIN SCI, V29, P109
   Bogdan K., 2013, MULTIOBJECT TRACKING, P109
   Röhler AB, 2011, LECT NOTES ARTIF INT, V7106, P271, DOI 10.1007/978-3-642-25832-9_28
   Brox T, 2006, LECT NOTES COMPUT SC, V3952, P98
   Buxton B. F., 1984, Image and Vision Computing, V2, P59, DOI 10.1016/0262-8856(84)90001-5
   CATTELL RB, 1963, J EDUC PSYCHOL, V54, P1, DOI 10.1037/h0046743
   Cattell RB, 1987, THEORY INTELLIGENCE
   Chen C-H, 2011, COMMUN COMPUT PHYS, P1096
   Chen CS, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/1127017
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   de Melo VV, 2012, INFORM SCIENCES, V193, P36, DOI 10.1016/j.ins.2011.12.037
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fakheredine K, 2012, INT J COMPUT APPL, P1
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Geiger A., 2012, C COMPUTER VISION PA
   Geiger A., 2012, CVPR
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Gray JR, 2003, NAT NEUROSCI, V6, P316, DOI 10.1038/nn1014
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   HORN BKP, 1993, ARTIF INTELL, V59, P81, DOI 10.1016/0004-3702(93)90173-9
   HORN JL, 1968, PSYCHOL REV, V75, P242, DOI 10.1037/h0025662
   Hsu C., 2012, World Academy of Science, Engineering and Technology, V68, P41, DOI DOI 10.5281/ZENODO.1075523
   Husseini S, 2017, WORLD ACAD SCI ENG T, P41
   Jepson A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P760, DOI 10.1109/CVPR.1993.341161
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Jiang M, 2007, INFORM PROCESS LETT, V102, P8, DOI 10.1016/j.ipl.2006.10.005
   John V, 2010, IMAGE VISION COMPUT, V28, P1530, DOI 10.1016/j.imavis.2010.03.008
   Kale Kiran, 2015, 2015 4th International Conference on Reliability, Infocom Technologies and Optimization (ICRITO) (Trends and Future Directions), P1, DOI 10.1109/ICRITO.2015.7359323
   Kim SW, 2013, MACH VISION APPL, V24, P1015, DOI 10.1007/s00138-012-0448-y
   Kim SW, 2012, MACH VISION APPL, P1015
   Lee R, 2020, 2ND INTERNATIONAL CONFERENCE ON MATHEMATICS AND COMPUTERS IN SCIENCE AND ENGINEERING (MACISE 2020), P178, DOI 10.1109/MACISE49704.2020.00039
   Lin XY, 2015, PROCEEDINGS OF 2015 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT 2015), P1554, DOI 10.1109/ICCSNT.2015.7491026
   Liu Y, 2012, INT C PATT RECOG, P898
   Marcus G., 2018, ARXIV180100631
   McGrew S.K., 2005, CONT INTELLECTUAL AS, V2nd, P136, DOI DOI 10.5860/CHOICE.34-5370
   Melo VV, 2009, INT CONF INTELL SYST, P19, DOI 10.1109/ISDA.2009.250
   Misra R, 2021, ARXIV
   Moudgil A., 2017, ARXIV
   Nam H, 2016, ARXIV
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Potok T, 2016, DOE WORKSH OAK RIDG
   RAY BK, 1992, PATTERN RECOGN LETT, V13, P443, DOI 10.1016/0167-8655(92)90051-Z
   Ray KS, 2021, ARTIFICAL 833 INTELL
   Ray KS, 2013, POLYGONAL APPROXIMAT, P661
   Richards M, 2004, IEEE IJCNN, P2309
   Rymut B, 2015, CONCURR COMP-PRACT E, V27, P1551, DOI 10.1002/cpe.3329
   Schneider W. J., 2012, Contemporary intellectual assessment: Theories, tests, and issues, P99
   Schwarz LA, 2012, IMAGE VISION COMPUT, V30, P217, DOI 10.1016/j.imavis.2011.12.001
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146
   Shin J, 2005, REAL-TIME IMAGING, V11, P204, DOI 10.1016/j.rti.2005.03.006
   Shin J, 2005, OPTICAL FLOW BASED R
   Simpson AJR, 2015, ARXIV
   Song Y., 2017, ARXIV
   Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279
   Stiefelhagen R, 2007, LECT NOTES COMPUT SC, V4122, P1
   Sundaram N, 2010, LECT NOTES COMPUT SC, V6311, P438, DOI 10.1007/978-3-642-15549-9_32
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Tsutsui H, 2001, MFI2001: INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS, P91, DOI 10.1109/MFI.2001.1013514
   Wolff JG, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01584
   Wolff JG, 2014, SPRINGERPLUS, V3, DOI 10.1186/2193-1801-3-552
   Wolff JG, 2013, INFORMATION, V4, P283, DOI 10.3390/info4030283
   Wolff JG, 2016, IEEE ACCESS, V4, P216, DOI 10.1109/ACCESS.2015.2513822
   Wolff JG, 2014, IEEE ACCESS, V2, P1629, DOI 10.1109/ACCESS.2014.2382753
   Wolff JG, 2004, ARXIV
   Wolff JG, 2016, ARXIV
   Wolff JG, 2018, ARXIV
   Wu WY, 2003, PATTERN RECOGN, V36, P2231, DOI 10.1016/S0031-3203(03)00087-6
   Wu WY, 2003, IMAGE VISION COMPUT, V21, P517, DOI 10.1016/S0262-8856(03)00031-3
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiaoqin Z, 2008, IMAGE VISION COMPUT
   Nguyen XS, 2013, LECT NOTES COMPUT SC, V8047, P319, DOI 10.1007/978-3-642-40261-6_38
   Yun S, 2017, ACTION DECISION NETW
   Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148
   Zhang Ben Jun., 2014, J MULTIMED
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang XQ, 2008, PROC CVPR IEEE, P1317, DOI 10.1109/CVPR.2008.4587512
   Zheng YH, 2007, 2007 INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, P65
   Zheng YH, 2008, IEEE C EVOL COMPUTAT, P405, DOI 10.1109/CEC.2008.4630829
   Zhiwen Chen, 2011, Proceedings of the 2011 International Conference on Computer Science and Network Technology (ICCSNT), P1096, DOI 10.1109/ICCSNT.2011.6182151
NR 94
TC 1
Z9 1
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28009
EP 28039
DI 10.1007/s11042-023-14343-y
EA FEB 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000926356600002
DA 2024-07-18
ER

PT J
AU Bhagat, M
   Kumar, D
AF Bhagat, Monu
   Kumar, Dilip
TI Performance evaluation of PCA based reduced features of leaf images
   extracted by DWT using random Forest and XGBoost classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Leaf images; Feature extraction; Image classification; Feature
   reduction; DWT; PCA; RF; XGBoost; K-fold cross validation
ID SELECTION APPROACH; DISEASE DETECTION; IDENTIFICATION; OPTIMIZATION
AB The leaf disease classification is a method for putting diseases into groups based on their properties, like texture, shape, and color. Even though DL features are very good at classifying leaf diseases, some authors focused on handcrafted features for leaf disease classification and got quite good results with similar accuracy. In this paper, we have also focused on handcrafted features and ML based shallow classifier to get comparable accuracy of DL models. Handcrafted features and shallow ML based classifier are used for leaf disease detection and classification mainly for three species such as tomato, bell pepper and potato. Here we have used 3- level decomposition based 2D-DWT for image feature extraction and PCA for dimensionality reduction of features. We have used stratified K-Fold validation because the dataset is small and there is a need to maintain the class ratio for classification. For classification Random Forest and XGBoost are used. The proposed method is made up of 4 steps: image pre-processing, feature extraction, feature reduction, and classification. We evaluate the proposed model's classification accuracy against the classification accuracy of several scholarly works. When applied to Datasets 1, 2, 3, and 4, RF classifiers achieve accuracies of 98.45%, 100%, 98.33%, and 98.55%, respectively, while XGBoost achieves accuracies of 99.11%, 98.72%, 98.23%, and 97.73%.
C1 [Bhagat, Monu; Kumar, Dilip] Natl Inst Technol Jamshedpur, Dept Comp Sci & Engn, Jamshedpur, Jharkhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Bhagat, M (corresponding author), Natl Inst Technol Jamshedpur, Dept Comp Sci & Engn, Jamshedpur, Jharkhand, India.
EM 2018rscs002@nitjsr.ac.in
RI Bhagat, Dr. Monu/GLS-1071-2022
OI Bhagat, Dr. Monu/0000-0001-9074-9653
CR Arjunagi S, 2019, TEXTURE BASED LEAF D
   Bhagat Monu, 2019, 2019 Devices for Integrated Circuit (DevIC). Proceedings, P141, DOI 10.1109/DEVIC.2019.8783800
   Bhagat M, 2022, MULTIMED TOOLS APPL, V81, P33897, DOI 10.1007/s11042-022-12984-z
   Cai J, 2012, IET IMAGE PROCESS, V6, P687, DOI 10.1049/iet-ipr.2011.0281
   Chhikara RR, 2016, INT J MACH LEARN CYB, V7, P1195, DOI 10.1007/s13042-015-0448-0
   Chouhan SS, 2018, IEEE ACCESS, V6, P8852, DOI 10.1109/ACCESS.2018.2800685
   Chowdhury MEH, 2021, AGRIENGINEERING, V3, P294, DOI 10.3390/agriengineering3020020
   Deepa N, 2020, IEEE ACCESS, V8, P183749, DOI 10.1109/ACCESS.2020.3028595
   Dey AK, 2016, PROCEDIA COMPUT SCI, V85, P748, DOI 10.1016/j.procs.2016.05.262
   Dhaka VS, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144749
   Emary E, 2015, ADV INTELL SYST, V334, P1, DOI 10.1007/978-3-319-13572-4_1
   Es-Saady Y, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL AND INFORMATION TECHNOLOGIES (ICEIT), P561, DOI 10.1109/EITech.2016.7519661
   Fuentes A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092022
   Gadekallu TR, 2021, J REAL-TIME IMAGE PR, V18, P1383, DOI 10.1007/s11554-020-00987-8
   Haque I., 2020, 2 INT C DAT ENG APPL, P1, DOI [DOI 10.1109/IDEA49133.2020.9170725, 10.1109/IDEA49133.2020.9170725]
   Hassan SM, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10121388
   Hlaing Chit Su, 2018, 2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS). Proceedings, P439, DOI 10.1109/ICIS.2018.8466483
   Hu J, 2018, IEEE SIGNAL PROC LET, V25, P853, DOI 10.1109/LSP.2018.2809688
   Hu RX, 2012, IEEE T IMAGE PROCESS, V21, P4667, DOI 10.1109/TIP.2012.2207391
   Hussain R, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13234941
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   JACKSON RD, 1986, IEEE T GEOSCI REMOTE, V24, P99, DOI 10.1109/TGRS.1986.289690
   Johannes A, 2017, COMPUT ELECTRON AGR, V138, P200, DOI 10.1016/j.compag.2017.04.013
   Kaur S, 2019, ARCH COMPUT METHOD E, V26, P507, DOI 10.1007/s11831-018-9255-6
   Kharrat A, 2010, LEONARDO J SCI
   Kundu N, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165386
   Li S, 2020, NEURAL COMPUT APPL, V32, P2037, DOI 10.1007/s00521-019-04341-3
   Mohammadi FG, 2014, ENG APPL ARTIF INTEL, V31, P35, DOI 10.1016/j.engappai.2013.09.016
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Naik J, 2014, INT J COMPUT SCI NET, V14, P87
   Ngugi LC, 2021, INFORM PROCESS AGR, V8, P27, DOI 10.1016/j.inpa.2020.04.004
   Padol PB, 2016, 2016 CONFERENCE ON ADVANCES IN SIGNAL PROCESSING (CASP), P175
   Pantazi XE, 2019, COMPUT ELECTRON AGR, V156, P96, DOI 10.1016/j.compag.2018.11.005
   Qin F, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168274
   Ramesh S., 2020, Information Processing in Agriculture, V7, P249, DOI 10.1016/j.inpa.2019.09.002
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Sabrol H, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1242, DOI 10.1109/ICCSP.2016.7754351
   Sambasivam G, 2021, EGYPT INFORM J, V22, P27, DOI 10.1016/j.eij.2020.02.007
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Singh V, 2019, ARTIF INTELL AGR, V3, P62, DOI 10.1016/j.aiia.2019.09.002
   Singh V, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENGINEERING AND APPLICATIONS (ICACEA), P1028, DOI 10.1109/ICACEA.2015.7164858
   Sulistyo SB, 2018, IEEE T AUTOM SCI ENG, V15, P1243, DOI 10.1109/TASE.2017.2770170
   Sulistyo SB, 2017, IEEE T IND INFORM, V13, P103, DOI 10.1109/TII.2016.2628439
   Tiwari VM., 2017, Int J Eng Manag Technol, V5, P11
   Wang HG, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P894, DOI 10.1109/CISP.2012.6469998
   Wang X, 2015, IEEE T BIO-MED ENG, V62, P80, DOI 10.1109/TBME.2014.2339295
   Wang Z, 2003, IEE P-VIS IMAGE SIGN, V150, P34, DOI 10.1049/ip-vis:20030160
   Zhang Y, 2010, PROG ELECTROMAGN RES, V109, P325, DOI 10.2528/PIER10090105
NR 48
TC 4
Z9 4
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26225
EP 26254
DI 10.1007/s11042-023-14370-9
EA JAN 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000949190900005
DA 2024-07-18
ER

PT J
AU Lam, MC
   Nizam, SSM
   Arshad, H
   Suwadi, NA
AF Lam, Meng Chun
   Muhammad Nizam, Siti Soleha
   Arshad, Haslina
   Suwadi, Nur Afyfah
TI Tangible interaction technique with authoring capability for kitchen
   design
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile augmented reality; Tangible interaction; Authoring; Kitchen
   design; Usability
ID AUGMENTED REALITY
AB Augmented reality (AR) technology allows users to view and interact in real-time with virtual information layered on top of the physical environment. Interaction technique development is based on the AR application context. In some cases, using an AR basic interaction technique is unsuitable as it only allows translation and rotation of the virtual object. For example, kitchen design requires various manipulation functions, especially in changing the features of a virtual kitchen cabinet. Existing AR tangible interaction techniques specified to the kitchen design context enable alteration of the features of virtual furniture despite requiring extra input and output devices, such as a stylus, head-mounted displays (HMDs), and projectors. Such devices are not suitable for AR as they are rarely accessible in daily life. Therefore, this study aimed to develop an AR tangible interaction technique on a mobile platform with authoring capabilities for the kitchen design process. The technique uses a cube and a card as the physical medium and features manipulation functions, such as virtual object placement, position changing, deletion, and changing kitchen cabinet features. The tangible interaction technique recorded a faster mean task completion time than the AR basic interaction technique. The tangible interaction technique also recorded higher usability than the basic interaction technique. Younger and experienced users performed better. Gender did not impact the interaction technique.
C1 [Lam, Meng Chun; Muhammad Nizam, Siti Soleha; Arshad, Haslina; Suwadi, Nur Afyfah] Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Ctr Artificial Intelligence Technol, Mixed Real & Pervas Comp Lab, Bangi 43600, Malaysia.
C3 Universiti Kebangsaan Malaysia
RP Lam, MC (corresponding author), Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Ctr Artificial Intelligence Technol, Mixed Real & Pervas Comp Lab, Bangi 43600, Malaysia.
EM lammc@ukm.edu.my; sitisoleha1610@gmail.com; haslinarshad@ukm.edu.my;
   nurafyfahsuwadi94@gmail.com
RI ; Lam, Meng Chun/M-5273-2017; Muhammad Nizam, Siti Soleha/S-9491-2017
OI ARSHAD, HASLINA/0000-0003-1327-1793; SUWADI, NUR
   AFYFAH/0000-0002-7551-0393; Lam, Meng Chun/0000-0002-9435-9473; Muhammad
   Nizam, Siti Soleha/0000-0002-4318-7288
FU Ministry of Higher Education (MOHE) Malaysia
   [FRGS/1/2018/ICT04/UKM/02/4]
FX This work was supported by the Ministry of Higher Education (MOHE)
   Malaysia Grant (FRGS/1/2018/ICT04/UKM/02/4).
CR Abd Majid N. A., 2018, J. ICT Res. Appl, V8, P1494, DOI [10.18517/ijaseit.8.4-2.6801, DOI 10.18517/IJASEIT.8.4-2.6801]
   Ali Z, 2016, INDIAN J ANAESTH, V60, P662, DOI 10.4103/0019-5049.190623
   [Anonymous], 2017, ICAT EGVE, P79, DOI [10.5555/3298830.3298845, DOI 10.5555/3298830.3298845]
   [Anonymous], 2008, Proceedings of the 2nd International Conference on Tangible and Embedded Interaction-TEI'08, DOI DOI 10.1145/1347390.1347433
   Bach B, 2018, IEEE T VIS COMPUT GR, V24, P457, DOI 10.1109/TVCG.2017.2745941
   Bellucci A, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206508
   Besancon L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4727, DOI 10.1145/3025453.3025863
   Billinghurst M., 2008, ACM SIGGRAPH ASIA, V7, P1, DOI [10.1145/1508044.1508051, DOI 10.1145/1508044.1508051]
   Billinghurst M, 2009, LECT NOTES COMPUT SC, V5622, P13, DOI 10.1007/978-3-642-02771-0_2
   Blender, 2021, FREED CREAT
   Budhiraja R, 2013, INT SYM MIX AUGMENT
   Cabero-Almenara J, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e01597
   Damala A, 2016, MEDITERR ARCHAEOL AR, V16, P73, DOI 10.5281/zenodo.204970
   Dirin Amir, 2019, International Journal of Interactive Mobile Technologies, V13, P93, DOI 10.3991/ijim.v13i06.10487
   Englmeier D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P221, DOI [10.1109/VR46266.2020.00-63, 10.1109/VR46266.2020.1581027011745]
   Ferrer V, 2017, 2017 IEEE VIRTUAL REALITY WORKSHOP ON K-12 EMBODIED LEARNING THROUGH VIRTUAL & AUGMENTED REALITY (KELVAR)
   Guimaraes MD, 2014, SYMP VIRTUAL AUGMENT, P45, DOI 10.1109/SVR.2014.17
   Hashim NC, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/9753979
   Hilken T, 2022, J INTERACT MARK, V57, P356, DOI 10.1177/10949968221083555
   Horn MS, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P975
   Hui J, 2015, PROCEEDINGS 2015 SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND ENGINEERING APPLICATIONS ISDEA 2015, P163, DOI 10.1109/ISDEA.2015.50
   Ishii H., 1997, P ACM SIGCHI C HUM F, P234, DOI DOI 10.1145/258549.258715
   Jafri R, 2015, PROCEDIA MANUF, V3, P5562, DOI 10.1016/j.promfg.2015.07.734
   Jeong Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173985
   Johri Prashant, 2021, 2021 10th IEEE International Conference on Communication Systems and Network Technologies (CSNT), P176, DOI 10.1109/CSNT51715.2021.9509694
   Kamilakis M, 2016, LECT NOTES COMPUT SC, V9768, P388, DOI 10.1007/978-3-319-40621-3_27
   Kán P, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10030245
   Kyriakou Panayiotis, 2019, Digital Applications in Archaeology and Cultural Heritage, V12, DOI 10.1016/j.daach.2018.e00088
   Lam MC, 2021, VIRTUAL REAL-LONDON, V25, P695, DOI 10.1007/s10055-020-00484-0
   Lam MC, 2020, TEM J, V9, P351, DOI 10.18421/TEM91-48
   Lee KT., 2018, ENG TECHNOL, V7, P101, DOI [10.14419/ijet.v7i2.14.11463, DOI 10.14419/IJET.V7I2.14.11463]
   Lee LN, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9173556
   Li JZ, 2018, L N INST COMP SCI SO, V229, P105, DOI 10.1007/978-3-319-76908-0_11
   Lu Y., 2020, J INTERNET SERVICES, V10, P50, DOI [10.22667/JISIS.2020.02.29.050, DOI 10.22667/JISIS.2020.02.29.050]
   Marner MR, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P155, DOI 10.1109/3DUI.2013.6550225
   Narazani M, 2019, ADJUNCT PUBLICATION OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST'19 ADJUNCT), P116, DOI 10.1145/3332167.3356891
   Nizam SSM, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/5320984
   Othman MK, 2022, UNIVERSAL ACCESS INF, V21, P995, DOI 10.1007/s10209-021-00820-4
   Palfrey J.G., 2011, Born digital: understanding the first generation of digital natives, DOI DOI 10.3917/SIM.102.0128
   Pampattiwar K., 2016, INT J INNOV RES SCI, V5, P17789, DOI [10.15680/IJIRSET.2016.0510041, DOI 10.15680/IJIRSET.2016.0510041]
   Rainie L., 2006, Digital Natives Invade the Workplace: Young people may be newcomers to the world of work, but it's their bosses who are immigrants into the digitla world
   Saat A., 2021, Asia-Pacific Journal of Information Technology and Multimedia, V10, P74, DOI DOI 10.17576/APJITM-2021-1001-07
   Saif AFMS, 2021, INT J ADV COMPUT SC, V12, P614
   Sandu Mihai, 2018, Informatica Economica, V22, P5, DOI 10.12948/issn14531305/22.3.2018.01
   Sapounidis Theodosios, 2019, International Journal of Child-Computer Interaction, V19, P67, DOI 10.1016/j.ijcci.2018.12.001
   Shin JG, 2018, ACM INT CONF PR SER, DOI 10.1145/3174910.3174930
   Son K, 2020, 2020 IEEE MTT-S INTERNATIONAL CONFERENCE ON NUMERICAL ELECTROMAGNETIC AND MULTIPHYSICS MODELING AND OPTIMIZATION (NEMO 2020), DOI 10.1109/NEMO49486.2020.9343473
   Sridhar S, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P103, DOI 10.1109/ZINC50678.2020.9161789
   Tan SY., 2018, INT J ADV SCI ENG IN, V8, P1672, DOI [10.18517/ijaseit.8.4-2.6810, DOI 10.18517/IJASEIT.8.4-2.6810]
   Tang SJ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030533
   Ullmer B, 2000, IBM SYST J, V39, P915, DOI 10.1147/sj.393.0915
   Urdan TC, 2016, STAT PLAIN ENGLISH, V2016
   Volman M, 2005, COMPUT EDUC, V45, P35, DOI 10.1016/j.compedu.2004.03.001
   Vuforia, 2021, DES VUMARK AD ILL
   WASSERTHEIL S, 1970, BIOMETRICS, V26, P588, DOI 10.2307/2529115
   Xue H, 2019, COMPUTERS, V8, DOI 10.3390/computers8010009
   Yoonsik Yang, 2016, 2016 IEEE Tenth International Conference on Semantic Computing (ICSC). Proceedings, P358, DOI 10.1109/ICSC.2016.42
   Zuckerman O, 2013, INT J HUM-COMPUT ST, V71, P803, DOI 10.1016/j.ijhcs.2013.04.003
NR 58
TC 0
Z9 0
U1 4
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 30125
EP 30150
DI 10.1007/s11042-023-14376-3
EA JAN 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000917999700002
DA 2024-07-18
ER

PT J
AU Xu, CE
   Ni, DD
   Wang, BY
   Wu, MY
   Gan, HH
AF Xu, Caie
   Ni, Dandan
   Wang, Bingyan
   Wu, Mingyang
   Gan, Honghua
TI Two-stage anomaly detection for positive samples and small samples based
   on generative adversarial networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Small samples; Positive samples; Generative
   adversarial networks
AB Anomaly detection approaches based on generative adversary networks usually directly input the image into the generator for reconstruction. As a result, the results of anomaly detection are not ideal. This paper proposes a novel anomaly detection model based on a two-stage generative adversarial network to improve the results. It consists of feature extraction and anomaly detection networks. The former combines a convolutional neural network and multi-scale feature extraction to study latent code. The latent code from the former model instead of the original image is fed to the generator of the anomaly detection module. The experiment shows the proposed method outperforms several existing anomaly detection methods with multiple datasets. Additionally, the quantitative result indicates the proposed model optimizes anomaly detection performance and improves by 8.8% and 19.2% on both the liver CT image medical dataset and the CIFAR10 public dataset respectively compared to the baseline of the skip-GANomaly model.
C1 [Xu, Caie; Wang, Bingyan; Wu, Mingyang] Zhejiang Univ Sci & Technol, Sch Informat & Elect Engn, 318 Liuhe Rd, Hangzhou 310023, Zhejiang, Peoples R China.
   [Ni, Dandan; Gan, Honghua] Zhejiang Univ, Coll Comp Sci & Technol, 38,Zheda Rd, Hangzhou 310013, Zhejiang, Peoples R China.
C3 Zhejiang University of Science & Technology; Zhejiang University
RP Gan, HH (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, 38,Zheda Rd, Hangzhou 310013, Zhejiang, Peoples R China.
EM caiexu@163.com; nidd@zju.edu.cn; amz950411@163.com;
   201200205120@zust.edu.cn; hgan@zju.edu.cn
RI Wu, Mingyang/JRX-1464-2023
CR Akcay S, 2018, GANOMALY SEMISUPERVI, DOI [10.1007/978-3-030-2089339, DOI 10.1007/978-3-030-2089339]
   Akçay S, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8851808
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bergmann P, 2020, PROC CVPR IEEE, P4182, DOI 10.1109/CVPR42600.2020.00424
   Bhatti UA, 2021, J MED IMAG HEALTH IN, V11, P7, DOI 10.1166/jmihi.2021.3313
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Boriah S., 2008, P 8 SIAM INT C DAT M, P243, DOI DOI 10.1137/1.9781611972788.22
   Chalapathy R, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1802.06360
   Chalapathy Raghavendra, 2019, ARXIV190103407
   Chen X, 2011, IEEE INT C BIOINFORM, P3, DOI 10.1109/BIBM.2011.12
   Chen Y, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2101.10043
   Fu J, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1809.02983
   Goodfellow I. J., 2014, ARXIV
   Haloui I, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1812.02463
   He ZY, 2003, PATTERN RECOGN LETT, V24, P1641, DOI 10.1016/S0167-8655(03)00003-5
   King DB, 2015, ACS SYM SER, V1214, P1
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Michelucci U, 2022, ARXIV, DOI DOI 10.48550/ARXIV.2201.03898
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Nawaz SA, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256971
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Perera P, 2019, PROC CVPR IEEE, P2893, DOI 10.1109/CVPR.2019.00301
   Radford A., 2015, ARXIV
   Rifai S, 2013, CONTRACTING AUTOENCO
   Salehi M, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2011.11108
   Salvador S, 2003, 17 INT FLOR ART INT
   Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Song JW, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2103.16851
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Ye N, 2001, QUAL RELIAB ENG INT, V17, P105, DOI 10.1002/qre.392
   Zeeshan Z, 2021, INTELL DATA ANAL, P25
   Zenati H, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1802.06222
   Zhao J, 2016, ARXIV, DOI DOI 10.48550/ARXIV:1609.03126
NR 35
TC 2
Z9 2
U1 16
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20197
EP 20214
DI 10.1007/s11042-022-14306-9
EA JAN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000911269000002
DA 2024-07-18
ER

PT J
AU AlQudah, MM
   Otair, MA
   Alqudah, MAY
   AlAzzam, SI
   Alqudah, SA
AF AlQudah, Mohammad M.
   Otair, Mohammed A.
   Alqudah, Mohammad A. Y.
   AlAzzam, Sayer I.
   Alqudah, Safa'a Ali
TI Prediction of hidden patterns in rheumatoid arthritis patients records
   using data mining
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data mining; Rheumatoid arthritis; RJ48; DAS 28; Methotrexate; WEKA;
   Classification; Feature selection
ID DISEASE-ACTIVITY; CLASSIFICATION; ALGORITHMS; RISK
AB Rheumatoid Arthritis (RA) disease is an inflammatory disease, which is characterized by persistent synovitis and autoantibodies that eventually lead to joint damage and reduced quality of life. This paper implements two data mining methodologies to explore the most important attributes that correlated with RA disease activity: (1) Feature selection algorithms to be used by Association rules (Apriori and Predictive) or Classification algorithms (J48 and J48 Consolidated), (2) Predictive rules (Rule Induction), Feature weight (Information Gain) and Trees algorithms (CHAID). This study experiments a pre-collected dataset consists of 260 patient records with a confirmed diagnosis of RA. The experimented algorithms are measured in terms of F-Measure, Accuracy, and the output tree. The accuracy of the J48 classification algorithm result was 79.18%. Many new rules were found by using the Predictive- Apriori technique from the association rules algorithms. By using the Information Gain algorithm, the most important attributes that highly correlated with the disease discovered were identified. This study revealed a model that validates the previous RA studies and includes new parameters that include both non-pharmacologic measures (No smoking, physical exercise and patient compliance) and pharmacologic therapies (MTX dose above 20 mg /week, prednisone dose > 5 mg/day as add-on therapy and biologic DMARDs (adalimumab, preferred in our study) and Hb > 10.8 g/dl). The model would help RA patients to have will controlled and low disease activity.
C1 [AlQudah, Mohammad M.; Otair, Mohammed A.] Amman Arab Univ, Sch Comp & Informat Technol, Amman, Jordan.
   [Alqudah, Mohammad A. Y.] Univ Sharjah, Coll Pharm, Dept Pharm Practice & Pharmacotherapeut, Sharjah 27272, U Arab Emirates.
   [Alqudah, Mohammad A. Y.; AlAzzam, Sayer I.] Jordan Univ Sci & Technol, Fac Pharm, Dept Clin Pharm, Irbid 22110, Jordan.
   [Alqudah, Safa'a Ali] Al Balqa Appl Univ, Allied Med Sci Dept, Al Salt, Jordan.
C3 University of Sharjah; Jordan University of Science & Technology;
   Al-Balqa Applied University
RP AlQudah, MM (corresponding author), Amman Arab Univ, Sch Comp & Informat Technol, Amman, Jordan.
EM mmaq78@gmail.com; otair@aau.edu.jo
OI Alqudah, Mohammad A Y/0000-0001-7210-7964; al-azzam,
   sayer/0000-0002-3414-7970
CR Ahmed A., 2014, World Journal of Computer Application and Technology, V2, P43
   Akin M, 2017, PLANT CELL TISS ORG, V128, P303, DOI 10.1007/s11240-016-1110-6
   Aletaha D, 2005, CLIN EXP RHEUMATOL, V23, pS100
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali M, 2015, PAK J ZOOL, V47, P1579
   Alqudah MAY, 2017, INFLAMMOPHARMACOLOGY, V25, P431, DOI 10.1007/s10787-017-0315-6
   Bardhan S, 2019, AUSTRALAS PHYS ENG S, V42, P259, DOI 10.1007/s13246-019-00726-9
   Bascol K, 2019, PR MACH LEARN RES, V89
   Beniwal S, 2012, INT J ENG RES TECHNO, V1, P6
   Chaurasia V., 2014, International Journal of Advanced Computer Science and Information Technology, V2, P56
   Chaurasia V., 2017, International Journal of Innovative Research in Computer and Communication Engineering (An ISO 3297 2007 Certified Organisation), V2, P2456
   Curtis JR, 2014, ARTHRIT CARE RES, V66, P990, DOI 10.1002/acr.22281
   Damberg E, 2014, BIOMED RES INT, DOI [10.1155/2017/3292849, DOI 10.1155/2017/3292849]
   Demisse GB, 2017, ARXIV170805072
   Durairaj M., 2013, International Journal of Scientific Technology Research, V2, P29
   Garcia S., 2016, DATA PREPROCESSING D
   Gosselt HR, 2021, J PERS MED, V11, DOI 10.3390/jpm11010044
   Guo Y, 2022, SOFT COMPUT, P1
   Hajar T.L, 2015, J PALLIAT CARE MED, V5, P221, DOI [10.4172/2165-7386.1000221, DOI 10.4172/2165-7386.1000221]
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Jiang P, 2015, CLIN EXP RHEUMATOL, V33, P115
   Koh Hian Chye, 2005, J Healthc Inf Manag, V19, P64
   Kumar A, 2020, Advances in Computing and Data Sciences, V4, P507
   Levi EH, 2016, AUTOIMMUN REV, V15, P393, DOI 10.1016/j.autrev.2016.01.006
   Maimon Oded Z, 2014, Data mining with decision trees: theory and applications, V81
   Myasoedova E, 2010, ARTHRITIS RHEUM-US, V62, P1576, DOI 10.1002/art.27425
   Nahar K, 2021, EDUC INF TECHNOL, V26, P6051, DOI 10.1007/s10639-021-10575-3
   Nakagawa C, 2021, THER ADV MUSCULOSKEL, V13, DOI 10.1177/1759720X211047057
   Nourisson C, 2017, RMD OPEN, V3, DOI 10.1136/rmdopen-2017-000515
   Pinjarkar V, 2022, ROLE IOT BLOCKCHAIN, P441
   Prajna B, 2016, INT J COMPUT SCI TEC, V7
   Ramotra Atul Kumar, 2020, Smart Trends in Computing and Communications. Proceedings of SmartCom 2019. Smart Innovation, Systems and Technologies (SIST 165), P89, DOI 10.1007/978-981-15-0077-0_10
   Rashidi S, 2014, TRANSPORT RES REC, P74, DOI 10.3141/2418-09
   Saad M.K., 2010, IMPACT TEXT PREPROCE
   Scott David L, 2010, Lancet, V376, P1094, DOI 10.1016/S0140-6736(10)60826-4
   Shanmugam S, 2019, J SUPERCOMPUT, V75, P5507, DOI 10.1007/s11227-019-02800-1
   Shanmugam S, 2017, INT J RES ENG APPL M, V03, DOI [10.18231/2454-9150.2017.0006, DOI 10.18231/2454-9150.2017.0006]
   Singh JA, 2016, ARTHRIT CARE RES, V68, P1, DOI 10.1002/acr.22783
   Singh P., 2021, Int. J. Appl. Res. Bioinformatics, V11, P51
   Smyrnova G, 2014, REV BRAS REUMATOL, V54, P437, DOI 10.1016/j.rbr.2014.06.002
   Sornalakshmi M, 2022, NEURAL COMPUT APPL, V34, P10597, DOI 10.1007/s00521-020-04862-2
   Sundaramurthy S., 2020, P 2020 INT C DEC AID, P17, DOI [10.1109/DASA51403.2020.9317253, DOI 10.1109/DASA51403.2020.9317253]
   Taylor Andrew, 2011, ISRN Rheumatol, V2011, P437281, DOI 10.5402/2011/437281
   Traore BB, 2017, EXPERT SYST APPL, V72, P443, DOI 10.1016/j.eswa.2016.10.010
   Wong TT, 2015, PATTERN RECOGN, V48, P2839, DOI 10.1016/j.patcog.2015.03.009
   Wu CT, 2020, HEALTHCARE-BASEL, V8, DOI 10.3390/healthcare8020085
   Zhang HN, 2022, MOB NETW APPL, P1
NR 49
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 369
EP 388
DI 10.1007/s11042-022-13331-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000905724300017
DA 2024-07-18
ER

PT J
AU Rana, M
   Bhushan, M
AF Rana, Meghavi
   Bhushan, Megha
TI Machine learning and deep learning approach for medical image analysis:
   diagnosis to detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Deep learning; Medical image processing; Convolutional
   neural network; Transfer learning; Healthcare; Tumor classification
ID CONVOLUTIONAL NEURAL-NETWORK; EEG SIGNALS; WAVELET TRANSFORM;
   CLASSIFICATION; SEIZURE; SEGMENTATION; TECHNOLOGIES
AB Computer-aided detection using Deep Learning (DL) and Machine Learning (ML) shows tremendous growth in the medical field. Medical images are considered as the actual origin of appropriate information required for diagnosis of disease. Detection of disease at the initial stage, using various modalities, is one of the most important factors to decrease mortality rate occurring due to cancer and tumors. Modalities help radiologists and doctors to study the internal structure of the detected disease for retrieving the required features. ML has limitations with the present modalities due to large amounts of data, whereas DL works efficiently with any amount of data. Hence, DL is considered as the enhanced technique of ML where ML uses the learning techniques and DL acquires details on how machines should react around people. DL uses a multilayered neural network to get more information about the used datasets. This study aims to present a systematic literature review related to applications of ML and DL for the detection along with classification of multiple diseases. A detailed analysis of 40 primary studies acquired from the well-known journals and conferences between Jan 2014-2022 was done. It provides an overview of different approaches based on ML and DL for the detection along with the classification of multiple diseases, modalities for medical imaging, tools and techniques used for the evaluation, description of datasets. Further, experiments are performed using MRI dataset to provide a comparative analysis of ML classifiers and DL models. This study will assist the healthcare community by enabling medical practitioners and researchers to choose an appropriate diagnosis technique for a given disease with reduced time and high accuracy.
C1 [Rana, Meghavi; Bhushan, Megha] DIT Univ, Sch Comp, Dehra Dun, India.
C3 DIT University
RP Bhushan, M (corresponding author), DIT Univ, Sch Comp, Dehra Dun, India.
EM meghavi.rana16@outlook.com; mb.meghabhushan@gmail.com
RI Bhushan, Megha/KIJ-4277-2024; Bhushan, Megha/ABC-8720-2020; Rana,
   Meghavi/CAJ-3941-2022; Bhushan, Megha/KIJ-1166-2024
OI Bhushan, Megha/0000-0003-4309-875X; Bhushan, Megha/0000-0003-4309-875X;
   Rana, Meghavi/0000-0002-3683-5873; Bhushan, Megha/0000-0003-4309-875X
CR Abdulbaqi AS, 2022, INT J NONLINEAR ANAL, V13, P773, DOI 10.22075/IJNAA.2022.5590
   Aceto G, 2018, J NETW COMPUT APPL, V107, P125, DOI 10.1016/j.jnca.2018.02.008
   Acharya UR, 2017, INFORM SCIENCES, V415, P190, DOI 10.1016/j.ins.2017.06.027
   Aggarwal P, 2019, SKIN RES TECHNOL, V25, P815, DOI 10.1111/srt.12726
   Al-Najdawi N, 2015, APPL SOFT COMPUT, V35, P175, DOI 10.1016/j.asoc.2015.06.029
   Altan G, 2020, IEEE J BIOMED HEALTH, V24, P1344, DOI 10.1109/JBHI.2019.2931395
   Anbeek P, 2005, NEUROIMAGE, V27, P795, DOI 10.1016/j.neuroimage.2005.05.046
   [Anonymous], NOISY DATA DATA MINI
   Arya Resham, 2022, International Journal of Fuzzy System Applications, V11, P1, DOI 10.4018/IJFSA.296596
   Arya R, 2021, COMPUTATIONAL METHOD, P529, DOI DOI 10.1007/978-981-15-7907-3_40
   Beam AL, 2018, JAMA-J AM MED ASSOC, V319, P1317, DOI 10.1001/jama.2017.18391
   Bhatt C, 2021, MULTIMEDIA SYST, V27, P599, DOI 10.1007/s00530-020-00694-1
   Bhattacharya P, 2021, IEEE T NETW SCI ENG, V8, P1242, DOI 10.1109/TNSE.2019.2961932
   Bhattacharyya A, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7040385
   Bhushan M., 2021, P 2021 10 INT C SYST, P562, DOI [10.1109/SMART52563.2021.9676289, DOI 10.1109/SMART52563.2021.9676289]
   Bhushan M, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114167
   Bhushan M, 2020, SOFTWARE QUAL J, V28, P1507, DOI 10.1007/s11219-020-09522-1
   Bhushan M, 2018, EXPERT SYST, V35, DOI 10.1111/exsy.12256
   Bhushan M, 2017, 2017 INTERNATIONAL CONFERENCE ON INFOCOM TECHNOLOGIES AND UNMANNED SYSTEMS (TRENDS AND FUTURE DIRECTIONS) (ICTUS), P376
   Bhushan M, 2018, J SYST SOFTWARE, V137, P605, DOI 10.1016/j.jss.2017.06.002
   Bhushan M, 2016, SADHANA-ACAD P ENG S, V41, P1381, DOI 10.1007/s12046-016-0571-y
   Caballé-Cervigón N, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155135
   Cabitza F, 2017, JAMA-J AM MED ASSOC, V318, P517, DOI 10.1001/jama.2017.7797
   Caliskan Abdullah., 2017, IU-J. Electr. Electron. Eng., V17, P3311
   Chaganti S.Y., 2020, 2020 INT C COMPUTER, P1
   Currie G, 2019, J MED IMAGING RADIAT, V50, P477, DOI 10.1016/j.jmir.2019.09.005
   de Bruijne M, 2016, MED IMAGE ANAL, V33, P94, DOI 10.1016/j.media.2016.06.032
   Fatima M., 2017, Journal of Intelligent Learning Systems and Applications, V09, P1, DOI DOI 10.4236/JILSA.2017.91001
   Feng YL, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11052415
   George ST, 2020, BIOCYBERN BIOMED ENG, V40, P709, DOI 10.1016/j.bbe.2020.02.001
   Ghassemi Marzyeh, 2020, AMIA Jt Summits Transl Sci Proc, V2020, P191
   Giger ML, 2018, J AM COLL RADIOL, V15, P512, DOI 10.1016/j.jacr.2017.12.028
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Grover Srishti, 2018, Procedia Computer Science, V132, P1788, DOI 10.1016/j.procs.2018.05.154
   Gupta Rajan, 2020, ACM Digital Government: Research and Practice, V1, DOI 10.1145/3411761
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hoque MZ, 2021, COMPUT MED IMAG GRAP, V90, DOI 10.1016/j.compmedimag.2021.101901
   Houssein EH, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114161
   Italinna V, 2021, DETECTING MILD TRAUM
   Jaiswal AK, 2018, AUSTRALAS PHYS ENG S, V41, P81, DOI 10.1007/s13246-017-0610-y
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Kaplan A, 2021, J ALLER CL IMM-PRACT, V9, P2255, DOI 10.1016/j.jaip.2021.02.014
   Karimi D, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101759
   Kashani MH, 2021, J NETW COMPUT APPL, V192, DOI 10.1016/j.jnca.2021.103164
   Kaur P, 2018, CURR MED IMAGING REV, V14, P675, DOI 10.2174/1573405613666170428154156
   Kedia S., 2022, P 2022 2 INT C EMERG, P1, DOI DOI 10.1109/ICEFEET51821.2022.9848348
   Khan SI, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103445
   Kitchenham B., 2007, GUIDELINES PERFORMIN
   Kitchenham B, 2009, INFORM SOFTWARE TECH, V51, P7, DOI 10.1016/j.infsof.2008.09.009
   Kostas D, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38612-9
   Kriti, 2021, ARCH COMPUT METHOD E, V28, P2567, DOI 10.1007/s11831-020-09469-3
   Kriti, 2020, MULTIMED TOOLS APPL, V79, P27257, DOI 10.1007/s11042-020-09337-z
   Krittanawong C, 2019, EUR HEART J, V40, P2058, DOI 10.1093/eurheartj/ehz056
   Kwekha-Rashid AS, 2021, APPL NANOSCI, DOI 10.1007/s13204-021-01868-7
   Lahmiri S, 2019, IEEE T INSTRUM MEAS, V68, P791, DOI 10.1109/TIM.2018.2855518
   Pham L, 2020, IEEE ENG MED BIO, P164, DOI 10.1109/EMBC44109.2020.9175704
   Latif J, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON COMPUTING, MATHEMATICS AND ENGINEERING TECHNOLOGIES (ICOMET), DOI 10.1109/icomet.2019.8673502
   Lee JG, 2017, KOREAN J RADIOL, V18, P570, DOI 10.3348/kjr.2017.18.4.570
   Lundervold AS, 2019, Z MED PHYS, V29, P102, DOI 10.1016/j.zemedi.2018.11.002
   Ma Y, 2019, BIOMED CIRC SYST C, DOI 10.1109/biocas.2019.8919021
   Matsumoto T, 2020, INT HEART J, V61, P781, DOI 10.1536/ihj.19-714
   Megha, 2017, COMM COM INF SC, V750, P258, DOI 10.1007/978-981-10-6544-6_24
   Nadakinamani RG, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/2973324
   Nagarajan SM, 2021, INT J SYST ASSUR ENG, DOI 10.1007/s13198-021-01126-7
   Oh SL, 2019, COMPUT BIOL MED, V105, P92, DOI 10.1016/j.compbiomed.2018.12.012
   Oh SL, 2018, COMPUT BIOL MED, V102, P278, DOI 10.1016/j.compbiomed.2018.06.002
   Pal Someswar, 2022, 2022 International Mobile and Embedded Technology Conference (MECON), P588, DOI 10.1109/MECON53876.2022.9752176
   Pal S, 2019, J NETW COMPUT APPL, V139, P57, DOI 10.1016/j.jnca.2019.04.013
   Pantazis D, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134278
   Pathan S., 2020, J CRIT REV, V7, P7877, DOI [10.31838/jcr.07.19.896, DOI 10.31838/JCR.07.19.896]
   Patidar S, 2017, BIOMED SIGNAL PROCES, V34, P74, DOI 10.1016/j.bspc.2017.01.001
   Pirrone D, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12115413
   Plis SM, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00229
   Poongodi M, 2022, Pers Ubiquitous Comput, V26, P25, DOI 10.1007/s00779-021-01541-4
   Rai P, 2021, APPL MICROBIOL BIOT, V105, P441, DOI 10.1007/s00253-020-11061-5
   Rana Meghavi, 2022, 2022 International Mobile and Embedded Technology Conference (MECON), P157, DOI 10.1109/MECON53876.2022.9752020
   Ray PP, 2019, J NETW COMPUT APPL, V140, P1, DOI 10.1016/j.jnca.2019.05.005
   Samad MD, 2018, EUR HEART J-CARD IMG, V19, P730, DOI 10.1093/ehjci/jey003
   Samant P, 2019, NEURAL COMPUT APPL, V31, P8441, DOI 10.1007/s00521-019-04551-9
   Samant P, 2018, COMPUT METH PROG BIO, V157, P121, DOI 10.1016/j.cmpb.2018.01.004
   Samant Piyush, 2018, Journal of Medical Engineering & Technology, V42, P35, DOI 10.1080/03091902.2017.1412521
   Saminu S, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11050668
   Schoepf UJ, 2007, RADIOLOGY, V244, P48, DOI 10.1148/radiol.2441052145
   Shakeel PM, 2022, NEURAL COMPUT APPL, V34, P9579, DOI 10.1007/s00521-020-04842-6
   Shan J, 2016, ULTRASOUND MED BIOL, V42, P980, DOI 10.1016/j.ultrasmedbio.2015.11.016
   Sharma M, 2017, J MECH MED BIOL, V17, DOI 10.1142/S0219519417400036
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Singh Sarab Nidhaan, 2022, 2022 IEEE VLSI Device Circuit and System (VLSI DCS)., P304, DOI 10.1109/VLSIDCS53788.2022.9811433
   Singh VK, 2022, MULTIMED TOOLS APPL, V81, P3, DOI 10.1007/s11042-021-11158-7
   Singh VJ, 2015, P WORLD C ENG, V1
   Spadarella G, 2022, CURR CARDIOVASC IMAG, V15, P11, DOI 10.1007/s12410-022-09563-z
   Strijkers GJ, 2011, DIFFUSION MRI THEORY, P672
   Sun J, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83350-6
   Sworna NS, 2021, J NETW COMPUT APPL, V196, DOI 10.1016/j.jnca.2021.103244
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tzimourta KD, 2019, HEALTH TECHNOL-GER, V9, P135, DOI 10.1007/s12553-018-0265-z
   Vamathevan J, 2019, NAT REV DRUG DISCOV, V18, P463, DOI 10.1038/s41573-019-0024-5
   Wang XS, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020219
   Wang Y, 2020, ULTRASOUND MED BIOL, V46, P1119, DOI 10.1016/j.ultrasmedbio.2020.01.001
   Wani SM, 2019, ADV INTELL SYST, V810, P739, DOI 10.1007/978-981-13-1513-8_75
   Widodo C. E., 2020, Journal of Physics: Conference Series, V1524, DOI 10.1088/1742-6596/1524/1/012003
   Willemink MJ, 2020, RADIOLOGY, V295, P4, DOI 10.1148/radiol.2020192224
   Yan Xu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1626, DOI 10.1109/ICASSP.2014.6853873
   Yanowitz F.G., 2012, Introduction to ECG interpretation
   Zubarev I, 2019, NEUROIMAGE, V197, P425, DOI 10.1016/j.neuroimage.2019.04.068
   US
NR 106
TC 31
Z9 31
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26731
EP 26769
DI 10.1007/s11042-022-14305-w
EA DEC 2022
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000903299800003
PM 36588765
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Deepak, VK
   Sarath, R
AF Deepak, V. K.
   Sarath, R.
TI An intelligent brain tumor segmentation using improved Deep Learning
   Model Based on Cascade Regression method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor segmentation; Pre- processing; Feature extraction; DLCR;
   FCNN; GMM
ID HISTONE DEACETYLASE INHIBITORS; CENTRAL-NERVOUS-SYSTEM; CELLS
AB The brain tumor is formed by abnormal cells that develop and reproduce unpredictably. A timely diagnosis of a brain tumor amplifies the likelihood of living for the patient. Specialists generally deploy a manual methodology of segmentation when diagnosing brain tumours. In medical image processing, brain tumour fragmentation is significant. The Physicians typically employed a manual process of fragmentation when identifying brain tumours. It is not exact, is subject to inter-and intra-observer variability, and may include non-enhancing tissue. It is also time demanding. A new and Improved Deep Learning Model formulated on the Cascade Regression method (DLCR) is proposed for image segmentation to resolve these issues. The proposed method uses the normalization procedure for Pre-processing of Magnetic resonance imaging (MRI) images using Fully Convolutional Neural Network (FCNN) method. Then the feature extraction using the Gaussian Mixture Model (GMM) is utilized to to decrease the data and obtain the relevant characteristic from every feature vector. Then the Current methodologies, namely Machine Learning Predictive Model (MLPM), Deep Learning Framework (DLF) and Extreme Learning Machine Local Receptive Fields (ELM-LRF) were compared to our suggested method. The results show the proposed DLCR method has achieved a better sensitivity, specificity, recall ratio, precision ratio, peak signal-to-noise ratio (PSNR), and low Root Mean Square Error (RMSE) than the existing methods.
C1 [Deepak, V. K.] Noorul Islam Ctr Higher Educ, Dept Elect & Commun, Kumaracoil, Tamilnadu, India.
   [Sarath, R.] Noorul Islam Ctr Higher Educ, Dept Elect & Instrumentat, Kumaracoil, Tamilnadu, India.
RP Deepak, VK (corresponding author), Noorul Islam Ctr Higher Educ, Dept Elect & Commun, Kumaracoil, Tamilnadu, India.
EM deepakvk2@gmail.com; sarathraveendran@gmail.com
CR Alkassar Sinan, 2019, 2019 2nd International Conference on Electrical, Communication, Computer, Power and Control Engineering (ICECCPCE), P188, DOI 10.1109/ICECCPCE46549.2019.203771
   Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   Banerjee S, 2019, LECT NOTES COMPUT SC, V11383, P170, DOI 10.1007/978-3-030-11723-8_17
   Borole V. Y., 2015, International Journal of Emerging Trends & Technology in Computer Science (IJETTCS), V4, P1
   Bowden SG, 2018, NEUROSURGERY, V82, P719, DOI 10.1093/neuros/nyx271
   Buckner JC, 2003, SEMIN ONCOL, V30, P10, DOI 10.1053/j.seminoncol.2003.11.031
   Ciresan D, 2021, 2012 IEEE C COMPUTER, P3642
   Coburger J, 2016, NEUROSURGERY, V78, P775, DOI 10.1227/NEU.0000000000001081
   Ertosun Mehmet Gunhan, 2015, AMIA Annu Symp Proc, V2015, P1899
   Haocheng Shen, 2017, Medical Image Computing and Computer-Assisted Intervention, MICCAI 2017. 20th International Conference. Proceedings: LNCS 10434, P433, DOI 10.1007/978-3-319-66185-8_49
   Holland EC, 2001, CURR OPIN NEUROL, V14, P683, DOI 10.1097/00019052-200112000-00002
   Karar ME, 2016, COMPUT MED IMAG GRAP, V50, P31, DOI 10.1016/j.compmedimag.2014.09.005
   Karimi N, 2017, MEASUREMENT, V107, P68, DOI 10.1016/j.measurement.2017.05.009
   Kazantsev AG, 2008, NAT REV DRUG DISCOV, V7, P854, DOI 10.1038/nrd2681
   Ker J, 2019, J CLIN NEUROSCI, V66, P239, DOI 10.1016/j.jocn.2019.05.019
   Ker J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092167
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Le THN, 2018, LECT NOTES COMPUT SC, V11072, P646, DOI 10.1007/978-3-030-00931-1_74
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Lemke J, 2014, INT J MOL SCI, V15, P16816, DOI 10.3390/ijms150916816
   Liffers K, 2014, EUR J CANCER, V50, pS62, DOI 10.1016/S0959-8049(14)50233-X
   Louis DN, 2007, ACTA NEUROPATHOL, V114, P547, DOI 10.1007/s00401-007-0278-6
   Louis DN, 2016, ACTA NEUROPATHOL, V131, P803, DOI 10.1007/s00401-016-1545-1
   Madhupriya G., 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P758, DOI 10.1109/ICOEI.2019.8862575
   Manogaran G, 2019, IEEE ACCESS, V7, P12, DOI 10.1109/ACCESS.2018.2878276
   McKinley R, 2019, LECT NOTES COMPUT SC, V11384, P456, DOI 10.1007/978-3-030-11726-9_40
   Miller KD, 2019, CA-CANCER J CLIN, V69, P363, DOI 10.3322/caac.21565
   Miner RC, 2017, J MED IMAGING RADIAT, V48, P328, DOI 10.1016/j.jmir.2017.06.005
   Myronenko A, 2019, LECT NOTES COMPUT SC, V11384, P311, DOI 10.1007/978-3-030-11726-9_28
   Ouyang WL, 2017, IEEE T PATTERN ANAL, V39, P1320, DOI 10.1109/TPAMI.2016.2587642
   Razzak MI, 2019, IEEE J BIOMED HEALTH, V23, P1911, DOI 10.1109/JBHI.2018.2874033
   Siekmann M, 2018, INT J COMPUT ASS RAD, V13, P471, DOI 10.1007/s11548-018-1705-y
   Smith-Bindman R, 2012, JAMA-J AM MED ASSOC, V307, P2400, DOI 10.1001/jama.2012.5960
   Sridhar KP, 2019, J AMB INTEL HUM COMP, V10, P3287, DOI 10.1007/s12652-018-1058-y
   Sun L, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00810
   Wu PC, 2020, 2020 13TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2020), P635, DOI 10.1109/CISP-BMEI51763.2020.9263614
   Wu W, 2014, INT J COMPUT ASS RAD, V9, P241, DOI 10.1007/s11548-013-0922-7
   Xu H, 2019, LECT NOTES COMPUT SC, V11766, P420, DOI 10.1007/978-3-030-32248-9_47
   Yadav SS, 2019, J BIG DATA-GER, V6, DOI [10.12921/jas.v6i1.14911, 10.1186/s40537-019-0276-2]
   Zhou CH, 2019, LECT NOTES COMPUT SC, V11384, P497, DOI 10.1007/978-3-030-11726-9_44
   Zhou CH, 2018, LECT NOTES COMPUT SC, V11072, P637, DOI 10.1007/978-3-030-00931-1_73
NR 41
TC 5
Z9 5
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20059
EP 20078
DI 10.1007/s11042-022-13945-2
EA DEC 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000898472600001
DA 2024-07-18
ER

PT J
AU Jallouli, M
   Lajmi, S
   Amous, I
AF Jallouli, Maryam
   Lajmi, Sonia
   Amous, Ikram
TI REMOVE: REcommendation Model based on sOcio-enVironmental contExt
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; Tensor factorization; Context; Social information;
   Environnemental information
ID MATRIX FACTORIZATION; SYSTEMS; REAL
AB Recommender Systems (RS) suffer from the typical new user and data sparsity problems. In order to reduce these issues, a RecommEndation Model based on sOcio-enVironmental contExt called REMOVE is proposed in this paper. By elaborating the state-of-the-art recommendation algorithms, we conclude that the merge of both social and environmental information should be taken into consideration in a recommendation model. Hence, in our model, we argue that modifying the vector of characteristics of items as well that of the users can significantly improve recommendation quality. To the best of our knowledge, there has been no prior work that investigated matrix factorization by modelling item vector characteristic and considering social and environmental information. For the experimentation, we compared our approach to those that integrate contextual information. This evaluation provided encouraging results in terms of Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE), and demonstrates that's REMOVE can better handle the concerned issues.
C1 [Jallouli, Maryam; Lajmi, Sonia; Amous, Ikram] Univ Sfax, Technopole Sfax, MIRACL Lab, POB 242, Sfax 3031, Tunisia.
   [Lajmi, Sonia] Al Baha Univ, Al Bahah, Saudi Arabia.
C3 Multimedia, InfoRmation Systems & Advancing Computing Laboratory
   (MIRACL); Universite de Sfax; Centre de Recherche en Numerique de Sfax
   (CRNS); Al Baha University
RP Jallouli, M (corresponding author), Univ Sfax, Technopole Sfax, MIRACL Lab, POB 242, Sfax 3031, Tunisia.
EM jallouli.maryam@gmail.com
RI lajmi, sonia/HSH-0909-2023
OI lajmi, sonia/0009-0009-1744-9078; Amous, Ikram/0000-0002-5893-9833
CR Abowd GD, 1999, LECT NOTES COMPUT SC, V1707, P304
   Adomavicius G, 2005, ACM T INFORM SYST, V23, P103, DOI 10.1145/1055709.1055714
   Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Alfian G, 2019, ASIA PAC J MARKET LO, V31, P265, DOI 10.1108/APJML-03-2018-0088
   [Anonymous], P 39 INT ACM SIGIR C, DOI DOI 10.1145/2911451.2911502
   [Anonymous], 2014, 4 IMP COLL COMP STUD
   Baltrunas L., 2011, P 5 ACM C REC SYST, P301, DOI DOI 10.1145/2043932.2043988
   Bathla G, 2020, MULTIMED TOOLS APPL, V79, P20845, DOI 10.1007/s11042-020-08932-4
   Breese J.S., 2013, ARXIV
   Daouadi KE, 2021, INFORM SYST, V101, DOI 10.1016/j.is.2021.101801
   Daouadi KE, 2019, COMPUT SIST, V23, P273, DOI [10.13053/CyS-23-2-3192, 10.13053/cys-23-2-3192]
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696
   Delporte J, 2013, SOCIALLY ENABLED PRE, DOI [10.1007/978-3-642-40991-2_10, DOI 10.1007/978-3-642-40991-2_10]
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   Eldén L, 2006, ACT NUMERIC, V15, P327, DOI 10.1017/S0962492906240017
   Goel S.S., 2021, J. Reliab. Intell. Environ, DOI 10.1007/s40860-020-00127-w
   Gu YL, 2018, WEB INTELL, V16, P53, DOI 10.3233/WEB-180373
   Guo GB, 2016, IEEE T KNOWL DATA EN, V28, P1607, DOI 10.1109/TKDE.2016.2528249
   Guo GB, 2014, 2014 PROCEEDINGS OF THE IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2014), P540, DOI 10.1109/ASONAM.2014.6921639
   Guo GB, 2015, AAAI CONF ARTIF INTE, P123
   Harshman R.A., 1970, UCLA Working Papers in Phonetics, V16, P84, DOI DOI 10.1134/S0036023613040165
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   HyPeRM, HYBR PERS AW REC MOV
   Ijaz MF, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10103756
   Ijaz MF, 2016, SUSTAINABILITY-BASEL, V8, DOI 10.3390/su8060511
   Jallouli Maryam, 2022, International Journal of Computers and Applications, V44, P349, DOI 10.1080/1206212X.2020.1752971
   Jallouli Maryam, 2018, International Journal of Strategic Information Technology and Applications, V9, P38, DOI 10.4018/IJSITA.2018100103
   Jallouli M, 2017, LECT NOTES BUS INF P, V299, P606, DOI 10.1007/978-3-319-65930-5_47
   Jallouli M, 2017, PROCEDIA COMPUT SCI, V112, P1701, DOI 10.1016/j.procs.2017.08.195
   Jallouli M, 2017, ADV INTELL SYST, V557, P1041, DOI 10.1007/978-3-319-53480-0_102
   Jamali M., 2010, P 4 ACM C REC SYST, P135, DOI DOI 10.1145/1864708.1864736
   Karatzoglou Alexandros, 2010, Multiverse recommendation: N-dimensional tensor factorization for context-aware collaborative filtering, P79, DOI DOI 10.1145/1864708.1864727
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Koren Y, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1644873.1644874
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Kumar M, 2022, IEEE T SUST COMPUT, V7, P386, DOI 10.1109/TSUSC.2021.3110245
   Kumar M, 2019, J NETW COMPUT APPL, V143, P1, DOI 10.1016/j.jnca.2019.06.006
   Liu Xin., 2013, WWW, P781, DOI DOI 10.1145/2488388.2488457
   Ma H, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P203, DOI 10.1145/1571941.1571978
   MovieLens, 2013, GROUPLENS
   Ono C, 2009, LECT NOTES COMPUT SC, V5535, P102, DOI 10.1007/978-3-642-02247-0_12
   Pu Pearl, 2011, P 5 ACM C RECOMMENDE, P157, DOI 10.1145/2043932.2043962
   pubmed, HLTH REC SYST SYST R
   Revanur A, 2021, 15TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS 2021), P463, DOI 10.1145/3460231.3474233
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Roy S, 2020, MULTIMED TOOLS APPL, V79, P24119, DOI 10.1007/s11042-020-09126-8
   Schafer J. B., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P291
   Shani G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P257, DOI 10.1007/978-0-387-85820-3_8
   Shao W Tensor Completion, 2012, U SAARL SAARBR
   Shi L., 2014, OASICSOPENACCESS SER, V43, P74, DOI [10.4230/OASIcs.ICCSW.2014.74, DOI 10.4230/OASICS.ICCSW.2014.74]
   Shi Y, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P155, DOI 10.1145/2348283.2348308
   Troudi A, 2021, COMPUT J, V64, P369, DOI 10.1093/comjnl/bxaa126
   Tu WT, 2018, ACM T WEB, V12, DOI 10.1145/3121407
   Yeo C, 2019, CUSTOMER ORIENTATION, V11
   Zheng C, 2016, NEUROCOMPUTING, V205, P141, DOI 10.1016/j.neucom.2016.04.016
NR 56
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24803
EP 24840
DI 10.1007/s11042-022-14239-3
EA DEC 2022
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000894530200004
DA 2024-07-18
ER

PT J
AU Pandey, AC
   Kulhari, A
   Mittal, H
   Tripathi, AK
   Pal, R
AF Pandey, Avinash Chandra
   Kulhari, Ankur
   Mittal, Himanshu
   Tripathi, Ashish Kumar
   Pal, Raju
TI Improved exponential cuckoo search method for sentiment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentimental data; Data processing; Feature extraction; Improved
   exponential cuckoo search; Clustering
ID ALGORITHM
AB Sentiment analysis is a type of contextual text mining that determines how people feel about emotional issues that are frequently discussed on social media. The sentiments of emotive data are analyzed using a variety of sentiment analysis approaches, including lexicon-based, machine learning-based, and hybrid methods. Unsupervised approaches, particularly clustering methods are preferred over other methods since they can be applied directly to unlabeled datasets. Therefore, a clustering method based on an improved exponential cuckoo search has been proposed in this study for sentiment analysis. The proposed clustering method finds the optimal cluster centers from emotive datasets, which are then utilized to determine the sentiment polarity of emotive contents. The proposed improved exponential cuckoo search is first tested on standard and CEC-2013 benchmark functions before being utilized to determine the best cluster centroids from sentimental datasets. To assess the efficiency of the proposed method, it has been compared with K-means, cuckoo search, grey wolf optimizer, grey wolf optimizer with simulated annealing, hybrid step size-based cuckoo search, and spiral cuckoo search on nine sentimental datasets. The Experimental results and statistical analysis have proven the efficacy of the proposed method.
C1 [Pandey, Avinash Chandra] PDPM Indian Inst Informat Technol, Discipline Comp Sci & Engn, Design & Mfg, Jabalpur, India.
   [Kulhari, Ankur] Govt Polytechn Coll, Bundi, Rajasthan, India.
   [Mittal, Himanshu] Indira Gandhi Delhi Syst Univ Women, Dept Comp Sci & Engn, Delhi, India.
   [Tripathi, Ashish Kumar] Malaviya Natl Inst Technol, Dept Comp Sci, Jaipur, India.
   [Pal, Raju] Jaypee Inst Informat Technol, Dept Comp Sci & Informat Technol, Noida, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur; National Institute of Technology (NIT System); Malaviya
   National Institute of Technology Jaipur; Jaypee Institute of Information
   Technology (JIIT)
RP Pandey, AC (corresponding author), PDPM Indian Inst Informat Technol, Discipline Comp Sci & Engn, Design & Mfg, Jabalpur, India.
EM avish.nsit@gmail.com; ankur.jii@gmail.com; himanshu.mittal224@gmail.com;
   mail2ashish07@gmail.com; raju3131.pal@gmail.com
RI Pal, Raju/AAC-2589-2020; Pandey, Avinash Chandra/AAN-1729-2020
OI Pal, Raju/0000-0001-5715-5204; Pandey, Avinash
   Chandra/0000-0002-0487-6742
CR Abed-alguni B, 2020, J INTELL SYST, V29, P1043, DOI 10.1515/jisys-2018-0331
   Agarwal P., 2019, NATURE INSPIRED ALGO, P47, DOI [10.4018/978-1-5225-5852-1.ch003, DOI 10.4018/978-1-5225-5852-1.CH003]
   Agrawal RK, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106092
   Ahuja S, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON TELECOMMUNICATION AND NETWORKS (TEL-NET), P420
   Aljarah I, 2020, KNOWL INF SYST, V62, P507, DOI 10.1007/s10115-019-01358-x
   Amiri E, 2016, APPL SOFT COMPUT, V41, P15, DOI 10.1016/j.asoc.2015.12.008
   Bartolo N, 2004, PHYS REP, V402, P103, DOI 10.1016/j.physrep.2004.08.022
   Bezdek J. C., 1994, Proceedings of the First IEEE Conference on Evolutionary Computation. IEEE World Congress on Computational Intelligence (Cat. No.94TH0650-2), P589, DOI 10.1109/ICEC.1994.349993
   Bondielli A, 2019, INFORM SCIENCES, V497, P38, DOI 10.1016/j.ins.2019.05.035
   Boonmee A, 2016, EUR J OPER RES, V250, P652, DOI 10.1016/j.ejor.2015.09.020
   boston, 2021, TWITTER SANDERS APPL
   Brest J, 2013, 2013 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P377
   Canuto S, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P53, DOI 10.1145/2835776.2835821
   Chen T, 2017, EXPERT SYST APPL, V72, P221, DOI 10.1016/j.eswa.2016.10.065
   Chiong R., 2018, P GENETIC EVOLUTIONA, P278, DOI DOI 10.1145/3205651.3205682
   Chourasia S, 2019, ADV INTELL SYST, V741, P449, DOI 10.1007/978-981-13-0761-4_44
   Cobos C, 2014, INFORM SCIENCES, V281, P248, DOI 10.1016/j.ins.2014.05.047
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Devi KL, 2015, ADV INTELL SYST, V415, P1, DOI 10.1007/978-3-319-27212-2_1
   El Alaoui I, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0120-0
   El Ansari O, 2018, COMM COM INF SC, V929, P91, DOI 10.1007/978-3-030-02852-7_8
   Emary E, 2016, NEUROCOMPUTING, V172, P371, DOI 10.1016/j.neucom.2015.06.083
   Emary E, 2015, ADV INTELL SYST, V334, P1, DOI 10.1007/978-3-319-13572-4_1
   Fernández-Gavilanes M, 2016, EXPERT SYST APPL, V58, P57, DOI 10.1016/j.eswa.2016.03.031
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Gong Y, 2018, ACM-BCB'18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY, AND HEALTH INFORMATICS, P523, DOI 10.1145/3233547.3233632
   Hai Shen, 2010, 2010 IEEE Fifth International Conference on Bio-Inspired Computing: Theories and Applications (BIC-TA), P531, DOI 10.1109/BICTA.2010.5645181
   Hemmatian F, 2019, ARTIF INTELL REV, V52, P1495, DOI 10.1007/s10462-017-9599-6
   Hu X., 2013, P 22 INT C WORLD WID, P607, DOI DOI 10.1145/2488388.2488442
   Hu X., 2013, WSDM
   Hussain K, 2019, ARTIF INTELL REV, V52, P2191, DOI 10.1007/s10462-017-9605-z
   Jian Zhu, 2010, 2010 2nd IEEE International Conference on Information Management and Engineering (ICIME 2010), P193, DOI 10.1109/ICIME.2010.5478084
   Katarya R, 2018, NEURAL COMPUT APPL, V30, P1679, DOI 10.1007/s00521-016-2817-3
   Kumar A, 2019, INT J INF RETR RES, V9, P1, DOI 10.4018/IJIRR.2019010101
   Kumar V, 2017, J INTELL SYST, V26, P153, DOI 10.1515/jisys-2014-0137
   Li J, 2020, NEURAL COMPUT APPL, V32, P11967, DOI 10.1007/s00521-019-04178-w
   Likas A, 2003, PATTERN RECOGN, V36, P451, DOI 10.1016/S0031-3203(02)00060-2
   Loria Steven., 2018, Release 0.15, V2, P269
   Ma BJ, 2017, J INF SCI, V43, P54, DOI 10.1177/0165551515617374
   Mandal S, 2021, INT J INF TECHNOL, P1
   McHaney R, 2018, DECIS SUPPORT SYST, V111, P1, DOI 10.1016/j.dss.2018.04.002
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mirjalili SZ, 2018, APPL INTELL, V48, P805, DOI 10.1007/s10489-017-1019-8
   Mohammed Abdul Salam, 2020, International Journal of Intelligent Information and Database Systems, V13, P208, DOI 10.1504/IJIIDS.2020.109456
   Monish H, 2020, PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING, P117, DOI [10.1109/confluence47617.2020.9057968, 10.1109/Confluence47617.2020.9057968]
   Mukherjee Arjun, 2013, P INT AAAI C WEB SOC, DOI DOI 10.1609/ICWSM.V7I1.14389
   Nagamma P, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P933, DOI 10.1109/CCAA.2015.7148530
   Naidu G. Janardana, 2021, Smart Computing Techniques and Applications: Proceedings of the Fourth International Conference on Smart Computing and Informatics. Smart Innovation, Systems and Technologies (224), P253, DOI 10.1007/978-981-16-1502-3_26
   Nasiri J, 2018, COGENT MATH STAT, V5, DOI 10.1080/25742558.2018.1483565
   Nawaz MS, 2021, APPL SOFT COMPUT, V104, DOI 10.1016/j.asoc.2021.107200
   Newman D., 1998, UCI REPOSITORY MACHI
   Norris P., 2012, ELECT DEMOCRACY, V10, P55, DOI DOI 10.2307/J.CTVDDZWCG.6
   Ott M., 2011, ACL HLT 2011 P 49 AN, V1, P309, DOI DOI 10.1145/2567948.2577293
   Panda A., 2019, 2019 12 INT C CONT C, P1
   Panda AK, 2017, INT J RF MICROW C E, V27, DOI 10.1002/mmce.21122
   Pandey Anshuman, 2018, 2018 AIAA Aerospace Sciences Meeting, P1
   Pandey Avinash Chandra, 2019, 2019 4th International Conference on Information Systems and Computer Networks (ISCON), P722, DOI 10.1109/ISCON47742.2019.9036293
   Pandey AC., 2019, RECENT ADV COMPUT SC, V14, P635, DOI [10.2174/2213275912666190408111828, DOI 10.2174/2213275912666190408111828]
   Pandey AC, 2020, RECENT ADV COMPUT SC, V13, P627, DOI DOI 10.2174/2213275912666190328200012
   Pandey AC, 2022, J AMB INTEL HUM COMP, V13, P629, DOI 10.1007/s12652-021-03603-0
   Pandey AC, 2021, COMPLEX INTELL SYST, V7, P1649, DOI 10.1007/s40747-021-00294-0
   Pandey AC, 2020, J AMB INTEL HUM COMP, V11, P719, DOI 10.1007/s12652-019-01330-1
   Pandey AC, 2018, INT J SYST ASSUR ENG, V9, P821, DOI 10.1007/s13198-017-0660-2
   Pandey AC, 2016, INT CONF CONTEMP, P25
   Pandey AC, 2017, INFORM PROCESS MANAG, V53, P764, DOI 10.1016/j.ipm.2017.02.004
   Phu VN., 2018, COMPUT MODEL NEW TEC, V22, P20
   Poria S, 2016, KNOWL-BASED SYST, V108, P42, DOI 10.1016/j.knosys.2016.06.009
   Ray P, 2017, 2017 1ST IEEE INTERNATIONAL CONFERENCE ON DATA MANAGEMENT, ANALYTICS AND INNOVATION (ICDMAI), P211, DOI 10.1109/ICDMAI.2017.8073512
   Riazul Islam S. M., 2017, Cloud and Fog Computing in 5G Mobile Networks: Emerging Advances and Applications, P1, DOI 10.1049/PBTE070E_ch1
   SELIM SZ, 1991, PATTERN RECOGN, V24, P1003, DOI 10.1016/0031-3203(91)90097-O
   sentiment140, 2021, TESTDATA MANUAL
   Simon D, 2008, IEEE T EVOLUT COMPUT, V12, P702, DOI 10.1109/TEVC.2008.919004
   Sohangir S, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-017-0111-6
   Strapparava Carlo., 2006, Proceedings of the Fifth International Conference on Language Resources and Evaluation, P423
   Sun H, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P1088
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Tijare Poonam Vijay, 2022, Cyber Security and Digital Forensics: Proceedings of ICCSDF 2021. Lecture Notes on Data Engineering and Communications Technologies (73), P459, DOI 10.1007/978-981-16-3961-6_38
   Tripathi AK, 2018, BIG DATA RES, V14, P93, DOI 10.1016/j.bdr.2018.05.002
   twitter, 2021, TWITTER DATASET
   Vashishtha S, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114323
   Wang H, 2010, Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P783, DOI [DOI 10.1145/1835804.1835903, 10.1145/1835804.1835903]
   Xia R, 2016, INFORM PROCESS MANAG, V52, P36, DOI 10.1016/j.ipm.2015.04.003
   Xiong SF, 2016, INFORM SCIENCES, V367, P689, DOI 10.1016/j.ins.2016.07.002
   Xu D., 2015, Annals of Data Science, V2, P165, DOI [DOI 10.1007/S40745-015-0040-1, 10.1007/s40745-015-0040-1]
   Xue D, 2018, APPL INTELL, V48, P4232, DOI 10.1007/s10489-018-1212-4
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Yang XS, 2014, NEURAL COMPUT APPL, V24, P169, DOI 10.1007/s00521-013-1367-1
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Yang Xin-She., 2014, Cuckoo Search and Firefly Algorithm, P1, DOI DOI 10.1007/978-3-319-02141-61
   Yue L, 2019, KNOWL INF SYST, V60, P617, DOI 10.1007/s10115-018-1236-4
   Yusof NN, 2015, COMM COM INF SC, V545, P43, DOI 10.1007/978-981-287-936-3_5
   Zainuddin N, 2018, APPL INTELL, V48, P1218, DOI 10.1007/s10489-017-1098-6
   Zaw Moe Moe, 2013, International Journal of Innovation and Applied Studies, V4, P182
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
   Zhang QK, 2017, INFORM SCIENCES, V394, P273, DOI 10.1016/j.ins.2017.01.038
   Zhang QP, 2005, LECT NOTES COMPUT SC, V3482, P181
NR 98
TC 1
Z9 1
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 23979
EP 24029
DI 10.1007/s11042-022-14229-5
EA NOV 2022
PG 51
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000890126800003
DA 2024-07-18
ER

PT J
AU Luo, XQ
   Xi, XX
   Zhang, ZC
   Jiang, YT
   You, QJ
   Dong, J
   Wu, XJ
AF Luo, Xiaoqing
   Xi, Xinxing
   Zhang, Zhancheng
   Jiang, Yuting
   You, Qingjun
   Dong, Jing
   Wu, Xiao-Jun
TI Multimodal medical volumetric image fusion using 3-D Shearlet transform
   and T-S fuzzy reasoning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; 3-D Shearlet transform; Three-dimensional medical images;
   Contextual hidden Markov model; Fuzzy reasoning
AB Multimodal medical volumetric image fusion is a hot topic in medical image processing. Currently, most multi-scale based medical image fusion methods are put forward in two-dimensional space. However, they often fail to deal with multimodal medical volumetric image fusion due to the inaccurate image representation caused by ignoring the correlation between adjacent slices and the inappropriate design of fusion rule based on individual feature. To overcome the above drawbacks, a novel multimodal fusion method using 3-D Shearlet transform and T-S fuzzy reasoning is proposed, named as 3DSTSF. Firstly, the low frequency subbands and high frequency subbands of multimodal medical volumetric images are obtained by using the 3-D Shearlet transform. For comprehensive interpretation of source image, a contextual hidden Markov model is established for 3-D Shearlet transform high frequency subbands to model multiple dependency relationship among coefficients. Then, a fuzzy reasoning rule based on contextual hidden Markov model statistical characteristics, interval type-2 fuzzy entropy and region energy of high-frequency coefficients is designed to fuse high frequency subbands, which can accurately describe volumetric images and avoid introducing false information. Besides, a novel and simple local energy based fusion rule is performed on low frequency subbands to ensure the visual quality of fused image. Finally, the fused medical volumetric image is reconstructed by the inverse 3-D Shearlet transform. A series of experimental results demonstrate the superiority of 3DSTSF.
C1 [Luo, Xiaoqing; Xi, Xinxing; Jiang, Yuting; Wu, Xiao-Jun] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Jiangsu, Peoples R China.
   [Zhang, Zhancheng] Suzhou Univ Sci & Technol, Sch Elect & Informat Engn, Suzhou 215009, Peoples R China.
   [You, Qingjun] Jiangnan Univ, Affiliated Hosp, Dept Thorac Surg, Wuxi 214122, Jiangsu, Peoples R China.
   [Dong, Jing] Nanjing Tech Univ, Coll Elect Engn & Control Sci, Nanjing 211816, Peoples R China.
C3 Jiangnan University; Suzhou University of Science & Technology; Jiangnan
   University; Nanjing Tech University
RP Zhang, ZC (corresponding author), Suzhou Univ Sci & Technol, Sch Elect & Informat Engn, Suzhou 215009, Peoples R China.
EM cimszhang@163.com
RI Luo, Xiaoqing/AAM-2176-2021
FU National Natural Science Foundation of China [61772237, 61906087]; Six
   Talent Climax Foundation of Jiangsu [XYDXX030]; Translational Medicine
   Special Project of Wuxi Health and Safety Commission [ZZ002]; Natural
   Science Foundation of Jiangsu Province [BK20180692]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61772237, 61906087, in part by the Six
   Talent Climax Foundation of Jiangsu under Grant XYDXX030 and
   Translational Medicine Special Project of Wuxi Health and Safety
   Commission under Grant ZZ002 and Natural Science Foundation of Jiangsu
   Province under Grant BK20180692. Thanks are due to Miss Anqi Wang of
   Jiangnan university for assistance with the experiments.
CR Bhatnagar G, 2013, IEEE T MULTIMEDIA, V15, P1014, DOI 10.1109/TMM.2013.2244870
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   Crouse MS., 1997, SYSTEMS COMPUTERS, P95
   Deng Ting-quan, 2012, Control and Decision, V27, P408
   Du SC, 2015, PRECIS ENG, V40, P55, DOI 10.1016/j.precisioneng.2014.10.004
   Fu KR, 2022, IEEE T PATTERN ANAL, V44, P5541, DOI 10.1109/TPAMI.2021.3073689
   Haribabu M., 2012, 2012 INT C ADV MOB N, P127, DOI [10.1109/MNCApps.2012.33, DOI 10.1109/MNCAPPS.2012.33]
   Huang F, 2019, IEEE T CYBERNETICS, P1
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li XS, 2021, INFORM SCIENCES, V569, P302, DOI 10.1016/j.ins.2021.04.052
   Li XS, 2021, KNOWL-BASED SYST, V224, DOI 10.1016/j.knosys.2021.107087
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Marchi, 2012, J DATA SCI, V10, P711, DOI [10.6339/JDS.201210_10(4).0008, DOI 10.6339/JDS.201210_10(4).0008]
   Melin P, 2014, IEEE T FUZZY SYST, V22, P1515, DOI 10.1109/TFUZZ.2013.2297159
   Po DDY, 2006, IEEE T IMAGE PROCESS, V15, P1610, DOI 10.1109/TIP.2006.873450
   Sahu A, 2015, 2014 INTERNATIONAL CONFERENCE ON MEDICAL IMAGING, M-HEALTH & EMERGING COMMUNICATION SYSTEMS (MEDCOM), P448
   Shen R, 2013, IEEE T BIO-MED ENG, V60, P1069, DOI 10.1109/TBME.2012.2211017
   Srivastava R, 2016, IET COMPUT VIS, V10, P513, DOI 10.1049/iet-cvi.2015.0251
   Sutton D, 1999, BRIT MED J, V319, P1507, DOI 10.1136/bmj.319.7223.1507
   TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116, DOI 10.1109/TSMC.1985.6313399
   Wang L, 2014, IEEE T BIO-MED ENG, V61, P197, DOI 10.1109/TBME.2013.2279301
   Wang SS, 2017, 2017 IEEE/ACIS 15TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT AND APPLICATIONS (SERA), P143, DOI 10.1109/SERA.2017.7965720
   Wang ZY, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2021.114574
   Wang ZB, 2008, INFORM FUSION, V9, P176, DOI 10.1016/j.inffus.2007.04.003
   Wu DR, 2012, IEEE T FUZZY SYST, V20, P832, DOI 10.1109/TFUZZ.2012.2186818
   Xu H, 2022, IEEE T PATTERN ANAL, V44, P502, DOI 10.1109/TPAMI.2020.3012548
   Yang Y, 2020, IEEE GEOSCI REMOTE S, V17, P1943, DOI 10.1109/LGRS.2019.2956286
   Yu JM, 2020, INT J IMAG SYST TECH, V30, P1132, DOI 10.1002/ima.22442
   Yu L, 2020, IEEE T CLOUD COMPUT, V8, P459, DOI [10.1109/TCC.2016.2525984, 10.1109/TSG.2016.2640453]
   Zhang HY, 2014, INT C PATT RECOG, P1067, DOI 10.1109/ICPR.2014.193
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhang ZC, 2021, MULTIMED TOOLS APPL, V80, P2847, DOI 10.1007/s11042-020-09647-2
   Zhou T, 2020, IEEE T MED IMAGING, V39, P2772, DOI 10.1109/TMI.2020.2975344
NR 33
TC 1
Z9 1
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22577
EP 22612
DI 10.1007/s11042-022-14266-0
EA NOV 2022
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000888710500002
DA 2024-07-18
ER

PT J
AU He, JJ
   Liu, ZH
   Lin, KJ
   Qian, Q
AF He, Junjie
   Liu, Zhenghui
   Lin, Kejia
   Qian, Qing
TI A novel audio watermarking algorithm robust against recapturing attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio watermarking; Copyright protection; Robust feature; Recapturing
   attack; De-synchronization attacks
ID PATCHWORK ALGORITHM; SPREAD-SPECTRUM; SPEECH; IMPERCEPTIBILITY;
   AUTHENTICATION; MODULATION; SCHEME
AB Digital watermarking is a promising technology used in copyright protection for digital audio. However, in audio watermarking, it is still a challenge to achieve robustness against recapturing attacks, although much effort has been made in recent years. In this paper, a novel audio watermarking based on the frequency domain power spectrum (FDPS) feature is proposed to resist recapturing attacks. We divide a long audio signal into segments and split each segment into fragments. We embed synchronization codes in some fragments by quantifying the feature generated by discrete wavelet transform (DWT) approximate coefficients and copyright information in other fragments based on the FDPS feature. For the incoming audio, we extract synchronization codes to locate the watermarked fragments, further to extract copyright information. Experimental results demonstrate that the proposed method performs well under recapturing attacks and the bit error ratio (BER) value is decreased by more than 13% by comparing with the state-of-the-art methods.
C1 [He, Junjie] Xinyang Normal Univ, Sch Math & Stat, Xinyang 464000, Peoples R China.
   [Liu, Zhenghui] Shenzhen Univ, Guangdong Key Lab Intelligent Informat Proc, Shenzhen 518060, Peoples R China.
   [Liu, Zhenghui] Shenzhen Univ, Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.
   [Liu, Zhenghui] Guangdong Prov Key Lab Informat Secur Technol, Guangzhou 510275, Guangdong, Peoples R China.
   [Lin, Kejia] Xinyang Normal Univ Lib, Xinyang 464000, Peoples R China.
   [Qian, Qing] Guizhou Univ Finance & Econ, Guiyang 550025, Peoples R China.
   [Liu, Zhenghui] Xinyang Normal Univ, Sch Comp & Informat Technol, Xinyang, Peoples R China.
C3 Xinyang Normal University; Shenzhen University; Shenzhen University;
   Guizhou University of Finance & Economics; Xinyang Normal University
RP Liu, ZH (corresponding author), Shenzhen Univ, Guangdong Key Lab Intelligent Informat Proc, Shenzhen 518060, Peoples R China.; Liu, ZH (corresponding author), Shenzhen Univ, Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.; Liu, ZH (corresponding author), Guangdong Prov Key Lab Informat Secur Technol, Guangzhou 510275, Guangdong, Peoples R China.; Liu, ZH (corresponding author), Xinyang Normal Univ, Sch Comp & Informat Technol, Xinyang, Peoples R China.
EM zhenghui.liu@163.com
FU National Natural Science Foundation of China [61902085]; Nanhu Scholars
   Program for Young Scholars of XYNU; Science and Technology Project of
   Henan Province [212102310993]; Natural Science Foundation of Henan
   Province [222300420274]; Opening Project of Guangdong Provincial Key
   Laboratory of Information Security Technology
FX This paper is supported by the National Natural Science Foundation of
   China (Grant No. 61902085), Nanhu Scholars Program for Young Scholars of
   XYNU, the Science and Technology Project of Henan Province (No.
   212102310993), Natural Science Foundation of Henan Province (No.
   222300420274), and the Opening Project of Guangdong Provincial Key
   Laboratory of Information Security Technology (No.2020B1212060078-1). We
   would like to thank the anonymous reviewers for their constructive
   suggestions.
CR Chen OTC, 2007, IEEE T AUDIO SPEECH, V15, P1605, DOI 10.1109/TASL.2007.896658
   Hu HT, 2019, DIGIT SIGNAL PROCESS, V87, P75, DOI 10.1016/j.dsp.2019.01.006
   Hu P, 2016, ELECTRON LETT, V52, P5, DOI 10.1049/el.2015.1508
   Hua G, 2015, IEEE-ACM T AUDIO SPE, V23, P227, DOI 10.1109/TASLP.2014.2387385
   Jiang WZ, 2019, SIGNAL PROCESS, V162, P153, DOI 10.1016/j.sigpro.2019.04.017
   Kalantari NK, 2009, IEEE T AUDIO SPEECH, V17, P1133, DOI 10.1109/TASL.2009.2019259
   Kang H, 2008, IEICE T INF SYST, VE91D, P2731, DOI 10.1093/ietisy/e91-d.11.2731
   Kang XG, 2011, IEEE T MULTIMEDIA, V13, P181, DOI 10.1109/TMM.2010.2098850
   Korycki R, 2014, FORENSIC SCI INT, V238, P33, DOI 10.1016/j.forsciint.2014.02.008
   Li RK, 2016, IET SIGNAL PROCESS, V10, P266, DOI 10.1049/iet-spr.2014.0388
   Liu ZH, 2016, SIGNAL PROCESS, V123, P157, DOI 10.1016/j.sigpro.2015.10.023
   Liu ZH, 2014, DIGIT SIGNAL PROCESS, V24, P197, DOI 10.1016/j.dsp.2013.09.007
   Malvar HS, 2003, IEEE T SIGNAL PROCES, V51, P898, DOI 10.1109/TSP.2003.809385
   Nadeau A, 2017, IEEE T INF FOREN SEC, V12, P1393, DOI 10.1109/TIFS.2017.2661724
   Natgunanathan I, 2017, IEEE-ACM T AUDIO SPE, V25, P2176, DOI 10.1109/TASLP.2017.2749001
   Natgunanathan I, 2012, IEEE T AUDIO SPEECH, V20, P2232, DOI 10.1109/TASL.2012.2199111
   Pavlovic K, 2022, DIGIT SIGNAL PROCESS, V122, DOI 10.1016/j.dsp.2021.103381
   Salah E, 2021, APPL ACOUST, V172, DOI 10.1016/j.apacoust.2020.107652
   Wu SQ, 2005, IEEE T BROADCAST, V51, P69, DOI 10.1109/TBC.2004.838265
   Xiang Y, 2015, IEEE-ACM T AUDIO SPE, V23, P2228, DOI 10.1109/TASLP.2015.2476755
   Xiang Y, 2014, IEEE-ACM T AUDIO SPE, V22, P1413, DOI 10.1109/TASLP.2014.2328175
   Xiang Y, 2011, IEEE T MULTIMEDIA, V13, P2, DOI 10.1109/TMM.2010.2080668
   Yamni M, 2022, DIGIT SIGNAL PROCESS, V120, DOI 10.1016/j.dsp.2021.103251
   Yeo IK, 2003, IEEE T SPEECH AUDI P, V11, P381, DOI 10.1109/TSA.2003.812145
   Zhao J, 2023, IEEE T CYBERNETICS, V53, P5510, DOI 10.1109/TCYB.2022.3156973
NR 25
TC 1
Z9 1
U1 13
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18599
EP 18616
DI 10.1007/s11042-022-14197-w
EA NOV 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000886859100001
DA 2024-07-18
ER

PT J
AU Younas, F
   Usman, M
   Yan, WQ
AF Younas, Farah
   Usman, Muhammad
   Yan, Wei Qi
TI An ensemble framework of deep neural networks for colorectal polyp
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Colorectal cancer deep learning; Prediction; Polypectomy; Transfer
   learning; Virtual biopsy
ID COMPUTER-AIDED DIAGNOSIS; CANCER; RISK; SOCIETY
AB Colorectal cancer (CRC) is caused by malignant polyps which must be resected and examined for accurate classification. Biopsy, the manual workflow of polyp classification is time-intensive task and requires an automated solution. The objective of this study is to develop an accurate virtual biopsy tool for polyp classification. Moreover, automated assessment of polyps is a challenging task due to the similarities in their patterns, and in contrast to existing studies on binary classification, the outcome of multi-class classification requires evaluation through advanced evaluation measures. The proposed method combined the strength of individual weak learner for an accurate weighted-average ensemble deep learning classification. At first, base-classifiers were pretrained on the ImageNet database. Second, an average ensemble was built and evaluated for enhancing the performance, an appropriate combination of weights was chosen through grid search and assigned to the models. The performance evaluation of the proposed method in terms of F1-micro (0.80), F1-macro (0.81), F1-weighted (0.84) metrics, model reliability using Cohen's Kappa Coefficient (0.60) and Mathew Correlation Co-efficient value (0.49) for binary dataset shows the superiority over existing models. The higher rates of precision and recall show potential usage of the proposed system in the development of a virtual biopsy tool.
C1 [Younas, Farah; Usman, Muhammad; Yan, Wei Qi] Auckland Univ Technol, 55 Wellesley St East, Auckland 1010, New Zealand.
   [Usman, Muhammad] Shaheed Zulfikar Ali Bhutto Inst Sci & Technol, Islamabad 44000, Pakistan.
C3 Auckland University of Technology; Shaheed Zulfikar Ali Bhutto Institute
   of Science & Technology
RP Younas, F (corresponding author), Auckland Univ Technol, 55 Wellesley St East, Auckland 1010, New Zealand.
EM kpj7505@autuni.ac.nz; musman@aut.ac.nz; weiqi.yan@aut.ac.nz
RI Usman, Muhammad/JEP-1477-2023
CR Chan HP, 2020, ADV EXP MED BIOL, V1213, P3, DOI 10.1007/978-3-030-33128-3_1
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMoa1309086, 10.1056/NEJMc1405329]
   Geboes K., 2013, ENDOSCOPY, V1, P3, DOI DOI 10.5772/52739
   Gomes HM, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3054925
   Hsu CM, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21185995
   Ishaq S, 2017, DIGEST LIVER DIS, V49, P721, DOI 10.1016/j.dld.2017.03.030
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kim J, 2018, PRECIS FUTURE MED, V2, P37, DOI 10.23838/pfm.2018.00030
   Kim NH, 2017, INTEST RES, V15, P411, DOI 10.5217/ir.2017.15.3.411
   Kim YS, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80231-2
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Levin B, 2008, GASTROENTEROLOGY, V134, P1570, DOI 10.1053/j.gastro.2008.02.002
   Lyon F, 2018, COLORECTAL CANC FACT
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Min JK, 2019, GUT LIVER, V13, P388
   Nogueira-Rodríguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Patino-Barrientos S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020501
   Poudel S, 2020, IEEE ACCESS, V8, P99227, DOI 10.1109/ACCESS.2020.2996770
   Rahman Mohammad Motiur, 2021, Informatics in Medicine Unlocked, V24, P458, DOI 10.1016/j.imu.2021.100603
   Sánchez-Peralta LF, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10238501
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Sohail A, 2021, MED IMAGE ANAL, V72, DOI 10.1016/j.media.2021.102121
   Suzuki K, 2012, QUANT IMAG MED SURG, V2, P163, DOI 10.3978/j.issn.2223-4292.2012.09.02
   Wei JW, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.3398
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
NR 28
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18925
EP 18946
DI 10.1007/s11042-022-14177-0
EA NOV 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000886737800001
DA 2024-07-18
ER

PT J
AU Yu, ZG
AF Yu, Zhonggen
TI The effects of the superstar learning system on learning interest,
   attitudes, and academic achievements
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE The superstar learning system; The multimedia projecting system;
   Learning interest; Attitudes; Academic achievements
ID MOBILE; ACCEPTANCE
AB The COVID-19 pandemic has contributed to the production of a mobile learning app--the Superstar Learning System. Designed by Superstar Company, the Superstar Learning System is a mobile application for curriculum learning assisted with PPTs, knowledge dissemination, and management sharing based on micro-service architecture. To identify the effects of the Superstar Learning System, we randomly selected 71 tertiary students to participate in the study. The data were obtained through three research instruments: a scale to measure learning interest, a scale to measure learning attitudes, and a scale to measure academic achievements. Based on the analysis of a Mann-Whitney U test, it was concluded that the Superstar Learning System could: (1) enhance significantly more learning interest than the multimedia projecting system, (2) cultivate significantly more positive attitudes of students than the multimedia projecting system, and (3) lead to significantly better academic achievements than the multimedia projecting system. In the future, interdisciplinary cooperation, involving statistics, computer sciences, education, linguistics, and related disciplines, is necessary to arrive at solid conclusions.
C1 [Yu, Zhonggen] Beijing Language & Culture Univ, Fac Foreign Studies, Dept English Studies, 15 Xueyuan Rd, Beijing 100083, Peoples R China.
C3 Beijing Language & Culture University
RP Yu, ZG (corresponding author), Beijing Language & Culture Univ, Fac Foreign Studies, Dept English Studies, 15 Xueyuan Rd, Beijing 100083, Peoples R China.
EM 401373742@qq.com
RI Yu, Zhonggen/AAE-5514-2020; Yu, Zhonggen/AAJ-3063-2020
OI Yu, Zhonggen/0000-0002-3873-980X; Yu, Zhonggen/0000-0002-3873-980X
FU Beijing Language and Culture University [MOOC201902]; Special fund of
   Beijing Co-construction Project-Research and reform of the
   "Undergraduate Teaching Reform and Innovation Project" of Beijing higher
   education in 2020-innovative "multilingual +" excellent talent training
   system [202010032003]; Graduate Students of Beijing Language and Culture
   University "Xi Jinping: The Governance of China" [SJTS202108]
FX Partial financial support was received from 2019 MOOC of Beijing
   Language and Culture University (MOOC201902) (Important) "Introduction
   to Linguistics"; "Introduction to Linguistics" of online and offline
   mixed courses in Beijing Language and Culture University in 2020;
   Special fund of Beijing Co-construction Project-Research and reform of
   the "Undergraduate Teaching Reform and Innovation Project" of Beijing
   higher education in 2020-innovative "multilingual +" excellent talent
   training system (202010032003); The research project of Graduate
   Students of Beijing Language and Culture University "Xi Jinping: The
   Governance of China" (SJTS202108).
CR Alsharif W, 2018, INSIGHTS IMAGING, V9, P721, DOI 10.1007/s13244-018-0635-0
   Cao F., 2018, OFFICE AUTOMATION, V23, P37
   Chen J., 2017, J HUBEI CORRES U, V30, P145
   Cheng G, 2022, INT J EMERG TECHNOL, V17, P90, DOI 10.3991/ijet.v17i01.28465
   Cruz P, 2022, ADV SPACE RES, V69, P4001, DOI 10.1016/j.asr.2022.03.003
   Fan W., 2017, J KAIFENG I ED, V37, P64
   George D, 2010, SPSS for Windows step by step: A simple guide and reference. 11.0 update
   Hu L., 2019, TEXTILE IND TECHNOL, V4, P65
   Hwang GJ, 2011, COMPUT EDUC, V56, P1023, DOI 10.1016/j.compedu.2010.12.002
   Jin Y., 2018, FOREIGN LANGUAGE WOR, V2, P29
   Kim JH, 2019, ASIAN NURS RES, V13, P20, DOI 10.1016/j.anr.2019.01.005
   Kizilcec RF, 2021, AERA OPEN, V7, DOI 10.1177/23328584211014860
   Kuimova M, 2018, TEM J, V7, P837, DOI 10.18421/TEM74-22
   Ladeji-Osias JO, 2018, IEEE T EDUC, V61, P274, DOI 10.1109/TE.2018.2826466
   Li L., 2022, CHEM ED CHINESE ENGL, V4, P65, DOI [10.13884/J.1003-3807hxJY.2020110009, DOI 10.13884/J.1003-3807HXJY.2020110009]
   Li M., 2018, HENAN ED HIGHER ED, V5, P74
   Liu L., 2017, CHINA ED INFORM, V21, P27
   Liu RX, 2022, J COMPUT ASSIST LEAR, V38, P1422, DOI 10.1111/jcal.12688
   Liu TC, 2019, BRIT J EDUC TECHNOL, V50, P574, DOI 10.1111/bjet.12605
   Lu T, 2018, EURASIA J MATH SCI T, V14, P1719, DOI 10.29333/ejmste/85110
   Ma A., 2018, AUTOMOTIVE PRACT TEC, V8, P191, DOI [10.25236/icited.2022.037, DOI 10.25236/ICITED.2022.037]
   Ozdal H, 2017, J UNIVERS COMPUT SCI, V23, P1256
   Pechenkina E, 2017, INT J EDUC TECHNOL H, V14, DOI 10.1186/s41239-017-0069-7
   Saputra MRD, 2019, INT J INSTR, V12, P471, DOI 10.29333/iji.2019.12230a
   Sharifi R, 2017, J FUNDAM APPL SCI, V9, P1986, DOI 10.4314/jfas.v9i1s.837
   Sinha N, 2018, INT J TECHNOL HUM IN, V14, P63, DOI 10.4018/IJTHI.2018100104
   Sun W., 2018, ED TEACH FORUM, V31, P212
   Tian Q., 2017, DIGIT, V6, P138
   Viberg O, 2021, INTERACT LEARN ENVIR, V29, P130, DOI 10.1080/10494820.2018.1548488
   Wang J, 2022, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.803212
   Wang X., 2018, CHINA ADULT ED, V3, P88
   Wang Z., 2018, J LIAODONG U SOCIAL, V20, P121
   Wardaszko M, 2017, SIMULAT GAMING, V48, P435, DOI 10.1177/1046878117704350
   Yu Z G, 2022, RES ANTHOLOGY FEMINI, P335, DOI [10.4018/978-1-6684-4511-2.ch020, DOI 10.4018/978-1-6684-4511-2.CH020]
   Yu ZG, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.897327
   Yu ZG, 2022, EDUC INF TECHNOL, V27, P11669, DOI 10.1007/s10639-022-11081-w
   Yu ZG, 2022, TECHNOL PEDAGOG EDUC, V31, P381, DOI 10.1080/1475939X.2022.2045215
   Yu ZG, 2021, INT J MOB BLENDED LE, V13, P63, DOI 10.4018/IJMBL.2021100104
   Yu ZG, 2022, TECHNOL KNOWL LEARN, V27, P1215, DOI 10.1007/s10758-021-09524-3
   Yu ZG, 2021, INT J EDUC TECHNOL H, V18, DOI 10.1186/s41239-021-00252-3
   Yu ZG, 2020, J EDUC COMPUT RES, V58, P1121, DOI 10.1177/0735633120923772
   Yu ZG, 2020, J INF TECHNOL RES, V13, P77, DOI 10.4018/JITR.2020010106
   Yu ZG, 2019, INT J DIST EDUC TECH, V17, P21, DOI 10.4018/IJDET.2019100102
   Yu ZG, 2019, INT J MOB BLENDED LE, V11, P19, DOI 10.4018/IJMBL.2019040102
   Yu ZG, 2019, COMPUT APPL ENG EDUC, V27, P721, DOI 10.1002/cae.22111
   Yu ZG, 2019, COMPUT ASSIST LANG L, V32, P323, DOI 10.1080/09588221.2018.1517093
   Zeng Xue L., 2018, ED TEACH FORUM, V48, P277
   Zhang L., 2016, INF TECHNOL INFORM, V12, P91
   Zhang MM, 2023, LIBR HI TECH, V41, P1420, DOI 10.1108/LHT-12-2021-0431
   Zhang X., 2018, J LANGFANG NORMAL U, V18, P112
NR 50
TC 4
Z9 4
U1 9
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 17947
EP 17962
DI 10.1007/s11042-022-14217-9
EA NOV 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000884953300003
PM 36415332
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Gupta, D
   Sharma, A
   KaurnAff, P
   GuptanAff, R
AF Gupta, Deeksha
   Sharma, Akashdeep
   KaurnAff, Pavit
   GuptanAff, Ritika
TI Experimental analysis of clustering based models and proposal of a novel
   evaluation metric for static video summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Static video summarization; Keyframe extraction; Video abstraction;
   Clustering algorithms; Evaluation metric
ID KEY-FRAME EXTRACTION
AB Video summarization deals with the identification of relevant and important frames from a video for facilitating efficient storage, browsing and indexing of the videos. Automatic video summarization is a challenging task due to the varied genre, structure and domain of videos. Amongst several video summarization mechanisms, clustering-based approaches have become popular because of their independence from the expensive and time-consuming task of collecting user annotated summaries. The work aims to investigate and compare the behaviour of different nature clustering algorithms and frame descriptors for video summarization tasks. The scope of the presented study is twofold. Firstly, 30 clustering-based video summarization models are implemented and analysed. Secondly, a novel quantitative performance metric, CUS-F (Comparison of User Studies F-Score) is proposed to gauge the quality of generated summaries via a straightforward and concise score value. For comparative evaluation, all experiments are performed on a benchmarking static video summarization dataset - OpenVideo (OV) dataset. The study discovered that DBSCAN clustering shows the best performance when used with local features. The experiments also identifie K-means as a robust clustering method and colour as the most consistent frame descriptor for summarization tasks. In addition, the study demonstrates the effectiveness of the proposed evaluation metric CUS-F in obtaining the assessment of automatic key-frame based summaries by considering both true positive and false positive keyframes.
C1 [Gupta, Deeksha] Panjab Univ, Mehr Chand Mahajan DAV Coll Women, Chandigarh, India.
   [Gupta, Deeksha; Sharma, Akashdeep; KaurnAff, Pavit; GuptanAff, Ritika] Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
C3 Panjab University; Panjab University
RP Sharma, A (corresponding author), Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
EM akashdeep@pu.ac.in; deeksha.784@gmail.com; pavitk1@gmail.com;
   ritikagupta8734@gmail.com
FU Ministry of Electronics and Information Technology (MeITy), Government
   of India, New Delhi, India through the Visvesvaraya Research Fellowship
FX This research work is supported by the Ministry of Electronics and
   Information Technology (MeITy), Government of India, New Delhi, India
   through the Visvesvaraya Research Fellowship.
CR Aldavert D, 2015, INT J DOC ANAL RECOG, V18, P223, DOI 10.1007/s10032-015-0245-z
   [Anonymous], TRACK YOUTUBE AN FUT
   [Anonymous], 2006, Grouping Multidimensional Data: Rescent Advances in Clustering, DOI DOI 10.1007/3-540-28349-8_2
   [Anonymous], OP VID PROJ
   Arias-Castro E, 2011, ELECTRON J STAT, V5, P1537, DOI 10.1214/11-EJS651
   Asadi E., 2012, 2012 20th Iranian Conference on Electrical Engineering (ICEE 2012), P690, DOI 10.1109/IranianCEE.2012.6292442
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Botchkarev A., 2019, IJIKM, V14, P45, DOI [10.48550/arXiv.1809.03006, 10.28945/4184, DOI 10.28945/4184]
   Camastra F, 2008, Machine learning for audio, image and video analysis, P117, DOI [10.1007/978-1-84800-007-0_6, DOI 10.1007/978-1-84800-007-0_6]
   Chamasemani FF, 2018, VISUAL COMPUT, V34, P1299, DOI 10.1007/s00371-017-1432-3
   Chih-Fong Tsai, 2012, ISRN Artificial Intelligence, DOI 10.5402/2012/376804
   Choi J, 2016, MULTIMED TOOLS APPL, V75, P15975, DOI 10.1007/s11042-015-2909-6
   DASH A, 2017, INT C ADV CONCEPTS I, DOI DOI 10.1007/978-3-319-70353-4_37
   Daszykowski M, 2009, COMPREHENSIVE CHEMOMETRICS: CHEMICAL AND BIOCHEMICAL DATA ANALYSIS, VOLS 1-4, pA635
   Davidson I, 2005, LECT NOTES ARTIF INT, V3721, P59
   Dimitrovski I, 2016, INFORM SCIENCES, V329, P851, DOI 10.1016/j.ins.2015.05.012
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Ejaz N, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0280-z
   Ejaz N, 2012, J VIS COMMUN IMAGE R, V23, P1031, DOI 10.1016/j.jvcir.2012.06.013
   Elharrouss O, 2021, APPL INTELL, V51, P690, DOI 10.1007/s10489-020-01823-z
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P1280, DOI 10.1109/76.809162
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Humeau-Heurtier A, 2019, IEEE ACCESS, V7, P8975, DOI 10.1109/ACCESS.2018.2890743
   John AA, 2017, ADV INTELL SYST, V573, P494, DOI 10.1007/978-3-319-57261-1_49
   Kalita S, 2018, APPL INTELL, V48, P204, DOI 10.1007/s10489-017-0970-8
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P7383, DOI 10.1007/s11042-017-4642-9
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahmoud KM, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P811, DOI 10.1109/ICCVW.2013.111
   Mahmoud KM, 2013, LECT NOTES COMPUT SC, V8156, P733
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Ou SH, 2015, IEEE J-STSP, V9, DOI 10.1109/JSTSP.2014.2331916
   Reynolds D., 2015, ENCY BIOMETRICS, P827, DOI 10.1007/978-1-4899-7488-4_196
   Sebastian T., 2015, International Journal of Computer Applications, V132, P30, DOI DOI 10.5120/IJCA2015907592
   Sharghi A, 2016, LECT NOTES COMPUT SC, V9912, P3, DOI 10.1007/978-3-319-46484-8_1
   Shroff N, 2010, IEEE T MULTIMEDIA, V12, P853, DOI 10.1109/TMM.2010.2058795
   Tilson L., 1988, P INT GEOSC REM SENS, VVolume 3, P1783, DOI [10.1109/igarss.1988.569600, DOI 10.1109/IGARSS.1988.569600]
   Trinh H, 2012, INT C PATT RECOG, P2226
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Viguier R, 2015, IEEE INT SYM MULTIM, P249, DOI 10.1109/ISM.2015.124
   Wei HW, 2018, AAAI CONF ARTIF INTE, P216
   Wu JX, 2017, MULTIMED TOOLS APPL, V76, P9625, DOI 10.1007/s11042-016-3569-x
   Zhao Y, 2020, MULTIMED TOOLS APPL, V79, P33417, DOI 10.1007/s11042-019-7582-8
   Zhou YH, 2015, APPL INTELL, V43, P386, DOI 10.1007/s10489-015-0649-y
NR 46
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 NOV 15
PY 2022
DI 10.1007/s11042-022-14081-7
EA NOV 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6G6WP
UT WOS:000884893600003
DA 2024-07-18
ER

PT J
AU Xue, CH
   Yu, M
   Yan, G
   Gao, Y
   Liu, YA
AF Xue, Cuihong
   Yu, Ming
   Yan, Gang
   Gao, Yang
   Liu, Yuehao
TI Continuous sign language recognition based on iterative alignment
   network and attention mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Weak supervision; Spatio-temporal residual network; Temporal convolution
   module; Iterative alignment network; CTC; Attention mechanisms
AB The biggest challenge of continuous sign language recognition is the weak supervision of sign language labels. This paper proposes a continuous sign language recognition framework based on iterative alignment network and attention mechanism to solve this problem. The iterative alignment network uses a spatial-temporal residual network (STRN) to extract block-level features, a temporal convolutional module (TCM) to enhance the temporal correlation between block-level features, and Bidirectional Gated neural network(BGRU) and connectionist temporal classification (CTC) to generate pseudo-labels for each block-level feature; this in turn performs strong supervised learning with STRN and TCM, optimizes the network parameters, and uses CTC to learn new mapping relationships based on the optimized parameters in the next iteration. Then, the word-level features generated by the iterative alignment network are input into the encoder-decoder network, which is based on an attention mechanism. The attention module is used to fully pay attention to the relevant time-step information of the input feature sequence during decoding to obtain more accurate decoding results. The method is evaluated experimentally on three large-scale continuous sign language data sets (RWTH-Phoenix-Weather 2014, CSL and CSL daily), and the experimental results prove the method's effectiveness.
C1 [Xue, Cuihong] Tianjin Univ Technol, Tech Coll Deaf, Tianjin 300384, Peoples R China.
   [Yu, Ming; Yan, Gang; Gao, Yang; Liu, Yuehao] Hebei Univ Technol, Sch Artificial Intelligence, Tianjin 300401, Peoples R China.
C3 Tianjin University of Technology; Hebei University of Technology
RP Xue, CH (corresponding author), Tianjin Univ Technol, Tech Coll Deaf, Tianjin 300384, Peoples R China.
EM redxuech@tjut.edu.cn
OI Xue, Cuihong/0000-0003-0653-9202
FU Collaborative Education Project of Industry University Cooperation of
   the Ministry of Education [202102594001]; Key Teaching Reform Projects
   of Tianjin University of Technology [ZD21-17]; National Natural Science
   Foundation of China [61806071, 62102129]; Major Research Plan of the
   National Natural Science Foundation of China [91746207]; National Key
   R&D Program of China [2018YFC08]; Natural Science Foundation of Hebei
   Province [F2019202381, F2019202464, F2020202025, F2021202030]; Key
   Research and Development Program of Xinjiang Province [2020B03001];
   Technical Expert Project of Tianjin [19JCTPJC55800, 19JCTPJC57000];
   Sci-tech Research Project of Higher Education of Hebei Province
   [QN2019207, QN2020185]
FX This work was supported by the Collaborative Education Project of
   Industry University Cooperation of the Ministry of Education under grant
   202102594001, the Key Teaching Reform Projects of Tianjin University of
   Technology under grant ZD21-17, the National Natural Science Foundation
   of China under grants 61806071 and 62102129, the Major Research Plan of
   the National Natural Science Foundation of China under grant 91746207,
   the National Key R&D Program of China under grant 2018YFC08, the Natural
   Science Foundation of Hebei Province under grants F2019202381,
   F2019202464, F2020202025 and F2021202030, the Key Research and
   Development Program of Xinjiang Province under grant 2020B03001, the
   Technical Expert Project of Tianjin under grants 19JCTPJC55800 and
   19JCTPJC57000 and the Sci-tech Research Project of Higher Education of
   Hebei Province under grants QN2019207 and QN2020185.
CR Camgoz Necati Cihan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10020, DOI 10.1109/CVPR42600.2020.01004
   Camgoz NC, 2017, IEEE I CONF COMP VIS, P3075, DOI 10.1109/ICCV.2017.332
   Camgoz NC, 2018, PROC CVPR IEEE, P7784, DOI 10.1109/CVPR.2018.00812
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Cui RP, 2019, IEEE T MULTIMEDIA, V21, P1880, DOI 10.1109/TMM.2018.2889563
   Cui RP, 2017, PROC CVPR IEEE, P1610, DOI 10.1109/CVPR.2017.175
   Goswami Tilottama, 2021, ICCCE 2020. Proceedings of the 3rd International Conference on Communications and Cyber Physical Engineering. Lecture Notes in Electrical Engineering (LNEE 698), P55, DOI 10.1007/978-981-15-7961-5_6
   Guo D, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P751
   Guo D, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P744
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang J, 2019, IEEE T CIRC SYST VID, V29, P2822, DOI 10.1109/TCSVT.2018.2870740
   Huang J, 2018, AAAI CONF ARTIF INTE, P2257
   Ka Leong Cheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P697, DOI 10.1007/978-3-030-58586-0_41
   Koller O, 2020, IEEE T PATTERN ANAL, V42, P2306, DOI 10.1109/TPAMI.2019.2911077
   Koller O, 2018, INT J COMPUT VISION, V126, P1311, DOI 10.1007/s11263-018-1121-3
   Koller O, 2017, PROC CVPR IEEE, P3416, DOI 10.1109/CVPR.2017.364
   Koller O, 2016, PROC CVPR IEEE, P3793, DOI 10.1109/CVPR.2016.412
   Koller O, 2015, COMPUT VIS IMAGE UND, V141, P108, DOI 10.1016/j.cviu.2015.09.013
   Koller Oscar., 2016, P BMVC, P1, DOI 10.5244/C.30.136
   Kumar K, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3513004
   Li D., 2020, NeurIPS, V33, P12034
   Pu JF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1497, DOI 10.1145/3394171.3413931
   Pu JF, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P885
   Pu JF, 2019, PROC CVPR IEEE, P4160, DOI 10.1109/CVPR.2019.00429
   Rastgoo R, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.113794
   Sharma S, 2021, MULTIMED TOOLS APPL, V80, P26319, DOI 10.1007/s11042-021-10768-5
   Vijayvergia A, 2021, MULTIMED TOOLS APPL, V80, P28349, DOI 10.1007/s11042-021-10997-8
   Yang Z, 2019, ARXIV, DOI DOI 10.48550/ARXIV.1908.01341
   Zhe Niu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P172, DOI 10.1007/978-3-030-58517-4_11
   Zhou H, 2021, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR46437.2021.00137
   Zhou H, 2020, AAAI CONF ARTIF INTE, V34, P13009
   Zhou H, 2019, IEEE INT CON MULTI, P1282, DOI 10.1109/ICME.2019.00223
   Zhou YZ, 2018, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2018.00054
NR 33
TC 0
Z9 0
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17195
EP 17212
DI 10.1007/s11042-022-14085-3
EA NOV 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000881546800004
DA 2024-07-18
ER

PT J
AU Lu, YC
   Liu, TP
   Lin, CH
AF Lu, Ying Cheng
   Liu, Tzu Pu
   Lin, Chang Hong
TI Two-stage single image Deblurring network based on deblur kernel
   estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image Deblurring; Image quality improvement; Deep learning; Convolution
   neural network (CNN); Joint learning
ID CNN
AB Image deblurring for dynamic scenes is a serious challenge in computer vision. Motion blur is caused by camera shaking or object movement during the exposure time. Many photos cannot be reproduced at the moment they were taken, its contents cannot be restored if motion blur occurs. In this article, we proposed a deblurring system that uses a two-stage convolutional neural network (CNN) to achieve image deblurring through a joint learning strategy. The first-stage network predicts the deblur kernel of each pixel and pre-deblurs the input image, and then the second-stage network directly predicts clear images based on U-Net architecture. In the first-stage network, the deblur kernel uses the surrounding information to restore the centre pixel, which can effectively remove the tiny motion blur. To additionally deal with large motion blur, we extend the second-stage network is used to compensate for the limited receptive field of the first-stage deblurring kernel. We evaluate the proposed method on benchmark blur datasets. Experimental results show that the proposed method can produce better results than state-of-the-art methods, both quantitatively and qualitatively. The proposed method can achieve the best PSNR at 32.59db, 27.21db and 31.96db for the GOPRO, Kohler, and Su datasets, respectively.
C1 [Lu, Ying Cheng; Liu, Tzu Pu; Lin, Chang Hong] Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, 43 Keelung Rd, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology
RP Lin, CH (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, 43 Keelung Rd, Taipei, Taiwan.
EM chlin@mail.ntust.edu.tw
RI Lin, Chang Hong/GRE-7807-2022
OI Lin, Chang Hong/0000-0003-3646-3261
FU ministry of Science and Technology in Taiwan [MOST 108-2221-E-011-130]
FX This study was funded by the ministry of Science and Technology in
   Taiwan under MOST 108-2221-E-011-130-.
CR Ahmed AH, 2022, IEEE T MED IMAGING, V41, P2693, DOI 10.1109/TMI.2022.3168559
   Anwar S, 2019, IEEE I CONF COMP VIS, P3155, DOI 10.1109/ICCV.2019.00325
   Brooks T, 2019, PROC CVPR IEEE, P11028, DOI 10.1109/CVPR.2019.01129
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   De Brabandere B, 2016, ADV NEUR IN, V29
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Gao HY, 2019, PROC CVPR IEEE, P3843, DOI 10.1109/CVPR.2019.00397
   Gupta A, 2010, LECT NOTES COMPUT SC, V6311, P171, DOI 10.1007/978-3-642-15549-9_13
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hirsch M, 2011, IEEE I CONF COMP VIS, P463, DOI 10.1109/ICCV.2011.6126276
   Jo Y, 2018, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2018.00340
   Kim TH, 2013, IEEE I CONF COMP VIS, P3160, DOI 10.1109/ICCV.2013.392
   Kim TH, 2014, PROC CVPR IEEE, P2766, DOI 10.1109/CVPR.2014.348
   Kingma D. P., 2014, arXiv
   Köhler R, 2012, LECT NOTES COMPUT SC, V7578, P27, DOI 10.1007/978-3-642-33786-4_3
   Lai WS, 2016, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2016.188
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Liang CH, 2022, IEEE T MULTIMEDIA, V24, P61, DOI 10.1109/TMM.2020.3045303
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lim S, 2020, IEEE SIGNAL PROC LET, V27, P835, DOI 10.1109/LSP.2020.2995106
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Pan JS, 2016, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2016.56
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schuler CJ, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481418
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Sim H, 2019, IEEE COMPUT SOC CONF, P2140, DOI 10.1109/CVPRW.2019.00267
   Su SC, 2017, PROC CVPR IEEE, P237, DOI 10.1109/CVPR.2017.33
   Suin M, 2020, PROC CVPR IEEE, P3603, DOI 10.1109/CVPR42600.2020.00366
   Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Tien HJ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80803-2
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang W., 2017, PROC CVPR IEEE, P1685, DOI DOI 10.1109/CVPR.2017.183
   Ye MY, 2020, IEEE ACCESS, V8, P18316, DOI 10.1109/ACCESS.2020.2967823
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407
   Zhang HG, 2019, PROC CVPR IEEE, P5971, DOI 10.1109/CVPR.2019.00613
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zou WB, 2021, IEEE INT CONF COMP V, P1895, DOI 10.1109/ICCVW54120.2021.00216
NR 45
TC 2
Z9 2
U1 7
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17055
EP 17074
DI 10.1007/s11042-022-14116-z
EA NOV 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000879267000003
DA 2024-07-18
ER

PT J
AU Jiang, B
   Huang, Y
   Huang, W
   Yang, C
   Xu, FQ
AF Jiang, Bin
   Huang, Yun
   Huang, Wei
   Yang, Chao
   Xu, Fangqiang
TI Multi-scale dual-modal generative adversarial networks for text-to-image
   synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text-to-image synthesis; Generative adversarial network; Cross-modal;
   Attention mechanism
AB Generating images from text descriptions is a challenging task due to the natural gap between the textual and visual modalities. Despite the promising results of existing methods, they suffer from two limitations: (1) focus more on the image semantic information while fails to fully explore the texture information; (2) only consider to model the correlation between words and image with a fixed scale, thus decreases the diversity and discriminability of the network representations. To address above issues, we propose a Multi-scale Dual-modal Generative Networks (MD-GAN). The core components of MD-GAN are the dual-modal modulation attention (DMA) and the multi-scale consistency discriminator (MCD). The DMA includes two blocks: the textual guiding module that captures the correlation between images and text descriptions to rectify the image semantic content, and the channel sampling module that adjusts image texture by selectively aggregating the channel-wise information on spatial space. In addition, the MCD constructs the correlation between text and image region of various sizes, enhancing the semantic consistency between text and images. Extensive experiments on CUB and MS-COCO datasets show the superiority of MD-GAN over state-of-the-art methods.
C1 [Jiang, Bin; Huang, Yun; Huang, Wei; Yang, Chao; Xu, Fangqiang] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
C3 Hunan University
RP Jiang, B (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
EM jiangbin@hnu.edu.cn
OI Xu, Fangqiang/0000-0001-6057-7686; Jiang, Bin/0000-0002-5840-9664
FU National Natural Science Foundation of China [62072169, 62172156];
   National Key Research and Development Program of China [2020YFB1713003]
FX This work was supported in part by the National Natural Science
   Foundation of China under grant 62072169 and 62172156, and the National
   Key Research and Development Program of China under grant
   2020YFB1713003.
CR Chen YT, 2021, VISUAL COMPUT, V37, P1691, DOI 10.1007/s00371-020-01932-3
   Chen ZJ, 2020, SAFETY SCI, V130, DOI 10.1016/j.ssci.2020.104812
   Chen ZJ, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.06.041
   Cheng J., 2020, IEEE C COMP VIS PATT, P10911
   Dash A., 2017, arXiv
   Fan X, 2022, VISUAL COMPUT, V38, P279, DOI 10.1007/s00371-020-02015-z
   Fang Z, 2022, VISUAL COMPUT, V38, P1151, DOI 10.1007/s00371-021-02074-w
   Gao LL, 2019, AAAI CONF ARTIF INTE, P8312
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Gregor K, 2015, PR MACH LEARN RES, V37, P1462
   Jiang B, 2020, IEEE ACCESS, V8, P205088, DOI 10.1109/ACCESS.2020.3037346
   Jiang B, 2020, IEEE ACCESS, V8, P156828, DOI 10.1109/ACCESS.2020.3019826
   Jiang B, 2020, IEEE T IMAGE PROCESS, V29, P5079, DOI 10.1109/TIP.2020.2978583
   Karimi M, 2020, IEEE COMPUT SOC CONF, P2353, DOI 10.1109/CVPRW50498.2020.00284
   Kimura D, 2020, IEEE WINT CONF APPL, P2161, DOI [10.1109/WACV45572.2020.9093428, 10.1109/wacv45572.2020.9093428]
   Kingma D. P., 2014, arXiv
   Kingma DP, 2013, ARXIV
   Li B., 2020, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P7880
   Li B, 2021, J NEUROL, V268, P2042, DOI 10.1007/s00415-019-09596-3
   Li R, 2020, IEEE T MULTIMEDIA
   Li WH, 2019, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2019.00514
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Nam S., 2018, Advances in Neural Information Processing Systems, P42
   Odena A, 2017, PR MACH LEARN RES, V70
   Peng DL, 2021, NEURAL NETWORKS, V138, P57, DOI 10.1016/j.neunet.2021.01.023
   Qiao TT, 2019, PROC CVPR IEEE, P1505, DOI 10.1109/CVPR.2019.00160
   Radford A., 2015, ARXIV
   Reed S., 2016, arXiv
   Reed S. E., 2016, ADV NEURAL INFORM PR, V29, P217
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan HC, 2019, IEEE I CONF COMP VIS, P10500, DOI 10.1109/ICCV.2019.01060
   Tao M, 2020, ARXIV
   van den Oord A, 2016, PR MACH LEARN RES, V48
   Vaswani A, 2017, ADV NEUR IN, V30
   Wah C, 2011, CALTECH UCSD BIRDS 2
   Wang Y, 2020, ARXIV
   Wang Z, 2021, IEEE T KNOWL DATA EN, V33, P3634, DOI 10.1109/TKDE.2020.2971490
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xia WH, 2021, PROC CVPR IEEE, P2256, DOI 10.1109/CVPR46437.2021.00229
   Xian WQ, 2018, PROC CVPR IEEE, P8456, DOI 10.1109/CVPR.2018.00882
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Yang YH, 2021, IEEE T IMAGE PROCESS, V30, P2798, DOI 10.1109/TIP.2021.3055062
   Yin GJ, 2019, PROC CVPR IEEE, P2322, DOI 10.1109/CVPR.2019.00243
   Yuan MK, 2020, IEEE T MULTIMEDIA, V22, P1955, DOI 10.1109/TMM.2019.2951463
   Zhang H, 2021, PROC CVPR IEEE, P833, DOI 10.1109/CVPR46437.2021.00089
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhang ZZ, 2018, PROC CVPR IEEE, P6199, DOI 10.1109/CVPR.2018.00649
   Zhou XN, 2019, VISUAL COMPUT, V35, P385, DOI 10.1007/s00371-018-1471-4
   Zhu MF, 2019, PROC CVPR IEEE, P5795, DOI 10.1109/CVPR.2019.00595
NR 51
TC 2
Z9 2
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15061
EP 15077
DI 10.1007/s11042-022-14080-8
EA OCT 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000876660800004
DA 2024-07-18
ER

PT J
AU Han, CM
   Jiang, B
   Tang, J
AF Han, Chengmei
   Jiang, Bo
   Tang, Jin
TI Multi-granularity cross attention network for person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Common challenges; Multi-granularity; Cross;
   Attention mechanism
AB Typical person re-identification (Re-ID) methods suffer from common challenges from body misalignment, occlusion issues, background perturbance, pose variations, and other aspects. In solving these problems, the combination of global features and local features makes the network pay attention to the global information and local information in the image. The attention mechanism is found to be effective, which aims to strengthen the salient information and suppress the irrelevant ones. To further enhance the contribution of global information to significant information, in this paper, we propose a multi-granularity cross attention (MGCA) network for person Re-ID. The key component of our framework is the multi-granularity cross attention module, where the attention module selectively aggregates the features of each location and extracts the weighted sum of the features of each location based on each pixel's contribution to significance. Thus, it obtains the global view of the image and the spatial correlation between any two positions. The related semantic features reinforce each other, further improving compactness and semantic consistency within the classes, gaining feature refinement and feature-pair alignment, respectively. Extensive experiments demonstrate that our method is comparable to the most advanced methods.
C1 [Han, Chengmei] Hefei Normal Univ, Sch Comp Sci & Technol, Hefei, Peoples R China.
   [Han, Chengmei; Jiang, Bo; Tang, Jin] Anhui Univ, Sch Comp Sci & Technol, Anhui Prov Key Lab Multimodal Cognit Computat, Hefei, Peoples R China.
C3 Hefei Normal University; Anhui University
RP Han, CM (corresponding author), Hefei Normal Univ, Sch Comp Sci & Technol, Hefei, Peoples R China.; Han, CM (corresponding author), Anhui Univ, Sch Comp Sci & Technol, Anhui Prov Key Lab Multimodal Cognit Computat, Hefei, Peoples R China.
EM cmhan@hfnu.edu.cn
FU Major Project for New Generation of AI [2018AAA0100400]; National
   Natural Science Foundation of China [61976002, 61860206004, U20B2068];
   Natural Science Foundation of Anhui Higher Education Institutions of
   China [KJ2019A0033]; Key scientific research project of Hefei Normal
   University [2021KJZD18, 2021KJZD13]
FX This research is partially funded by the Major Project for New
   Generation of AI under Grant (2018AAA0100400 ), the National Natural
   Science Foundation of China (No. 61976002, 61860206004 and U20B2068),
   the Natural Science Foundation of Anhui Higher Education Institutions of
   China (KJ2019A0033 ), and the Key scientific research project of Hefei
   Normal University(2021KJZD18, 2021KJZD13 ).
CR Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chen WB, 2022, MULTIMED TOOLS APPL, V81, P4649, DOI 10.1007/s11042-020-10494-4
   Chen XS, 2020, PROC CVPR IEEE, P3297, DOI 10.1109/CVPR42600.2020.00336
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Cordonnier Jean-Baptiste, 2019, ARXIV
   Dai ZZ, 2019, IEEE I CONF COMP VIS, P3690, DOI 10.1109/ICCV.2019.00379
   Das A, 2014, LECT NOTES COMPUT SC, V8690, P330, DOI 10.1007/978-3-319-10605-2_22
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Eom Sungwook, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1411, DOI 10.1007/s12652-018-0698-2
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Gong SG, 2011, VISUAL ANALYSIS OF BEHAVIOUR: FROM PIXELS TO SEMANTICS, P301, DOI 10.1007/978-0-85729-670-2_14
   Hermans Alexander, 2017, ARXIV170307737
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Khatun A, 2021, ARXIV
   Kumar V, 2017, PROC CVPR IEEE, P6797, DOI 10.1109/CVPR.2017.719
   Lee H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030785
   Leng QM, 2020, IEEE T CIRC SYST VID, V30, P1092, DOI 10.1109/TCSVT.2019.2898940
   Li MX, 2020, IEEE T PATTERN ANAL, V42, P1770, DOI 10.1109/TPAMI.2019.2903058
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu CX, 2012, LECT NOTES COMPUT SC, V7583, P391, DOI 10.1007/978-3-642-33863-2_39
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Ma AJ, 2013, IEEE I CONF COMP VIS, P3567, DOI 10.1109/ICCV.2013.443
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Quan RJ, 2019, IEEE I CONF COMP VIS, P3749, DOI 10.1109/ICCV.2019.00385
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Shen Y, 2015, IEEE I CONF COMP VIS, P3200, DOI 10.1109/ICCV.2015.366
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Ustinova E., 2017, AVSS, P1
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu CY, 2017, IEEE I CONF COMP VIS, P2859, DOI 10.1109/ICCV.2017.309
   Wu Y, 2019, IEEE T IMAGE PROCESS, V28, P2872, DOI 10.1109/TIP.2019.2891895
   Xia B, 2019, IEEE I CONF COMP VIS, P3759, DOI 10.1109/ICCV.2019.00386
   Xiao Q, 2017, ARXIV
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Yang F, 2019, PATTERN RECOGN, V86, P143, DOI 10.1016/j.patcog.2018.08.015
   Yao HT, 2019, IEEE T IMAGE PROCESS, V28, P2860, DOI 10.1109/TIP.2019.2891888
   Zhang X, 2017, ARXIV
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zheng F, 2019, PROC CVPR IEEE, P8506, DOI 10.1109/CVPR.2019.00871
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zou GF, 2021, MULTIMED TOOLS APPL, V80, P26855, DOI 10.1007/s11042-021-10953-6
NR 61
TC 3
Z9 3
U1 4
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14755
EP 14773
DI 10.1007/s11042-022-13833-9
EA OCT 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000864589600007
DA 2024-07-18
ER

PT J
AU Saritas, OF
   Ozturk, S
AF Saritas, Omer Faruk
   Ozturk, Serkan
TI A blind CT and DCT based robust color image watermarking method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image watermarking; Contourlet Transform (CT); Copyright
   protection; Discrete Cosine Transform (DCT)
ID ALGORITHM; EFFICIENT
AB With the development of multimedia and communication technology, the protection of image copyright arises as a necessity. In the protection of copyright, image watermarking techniques are mostly used to improve robustness, invisibility, and security features. In this article, we present a novel hybrid Contourlet Transform (CT) and Discrete Cosine Transform (DCT) based blind and robust color image watermarking method to improve these features. This method is based on embedding 24-bit watermark information into an 8 x 8 image block using one-level CT and block DCT in Cb color channel of the image in YCbCr color space. In this embedding process, the DCT block is modified by using a new natural logarithm function based on the block DC coefficient. Also, a color image is used as a watermark and scrambled using Arnold transform to increase security before embedding process. The performance of the proposed method is demonstrated by applying image enhancement, geometric, and compression attacks to the watermarked images. Also, the proposed method is compared with some state-of-art methods. Experimental results illustrate that the proposed method protects the transparency of the watermarked image and has effective robustness against the attacks. The source code of this paper can be obtained from .
C1 [Saritas, Omer Faruk] Kayseri Univ, Develi Huseyin Sahin Vocat Coll, Comp Technol Dept, TR-38400 Kayseri, Turkey.
   [Ozturk, Serkan] Erciyes Univ, Comp Engn Dept, TR-38039 Kayseri, Turkey.
C3 Kayseri University; Erciyes University
RP Saritas, OF (corresponding author), Kayseri Univ, Develi Huseyin Sahin Vocat Coll, Comp Technol Dept, TR-38400 Kayseri, Turkey.
EM omer@kayseri.edu.tr; serkan@erciyes.edu.tr
RI SARITAS, Omer Faruk/ABD-1323-2020; Ozturk, Serkan/B-4673-2013
OI SARITAS, Omer Faruk/0000-0003-2383-3059; 
CR Abdulrahman AK, 2019, MULTIMED TOOLS APPL, V78, P17027, DOI 10.1007/s11042-018-7085-z
   Abraham J, 2019, J KING SAUD UNIV-COM, V31, P125, DOI 10.1016/j.jksuci.2016.12.004
   Anuradha R., 2012, International Journal of Electronics and Computer Science Engineering, V1, P1
   Azizi S, 2013, IEEE INT CONF MULTI
   Byun SW, 2019, IEEE ACCESS, V7, P100706, DOI 10.1109/ACCESS.2019.2931039
   Cedillo-Hernandez M, 2015, SIGNAL IMAGE VIDEO P, V9, P1163, DOI 10.1007/s11760-013-0555-x
   Chen L, 2018, MULTIMED TOOLS APPL, V77, P7187, DOI 10.1007/s11042-017-4628-7
   Das S, 2011, LECT NOTES COMPUT SC, V6744, P286
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Do MN, 2002, IEEE IMAGE PROC, P357
   Fares K, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2020.164562
   Fazlali HR, 2017, MULTIMED TOOLS APPL, V76, P3105, DOI 10.1007/s11042-015-3200-6
   Giri Kaiser J., 2018, International Journal of Information Technology, V10, P139, DOI 10.1007/s41870-017-0075-y
   Gul E, 2019, MULTIMED TOOLS APPL, V78, P17701, DOI 10.1007/s11042-018-7084-0
   Hassan O., 2020, VOL, V83, P16979
   Hu HT, 2020, INFORM SCIENCES, V519, P161, DOI 10.1016/j.ins.2020.01.019
   Huang HC, 2001, ELECTRON LETT, V37, P826, DOI 10.1049/el:20010567
   Jeswani T, 2014, INT J COMPUT APPL, V92, DOI [10.5120/16081-5371, DOI 10.5120/16081-5371]
   Jimson N, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P567, DOI 10.1109/ICCONS.2018.8663122
   Kaviani, 2012, ELEVATING WATERMARK, P6739
   Li JY, 2020, MULTIMED TOOLS APPL, V79, P1373, DOI 10.1007/s11042-019-08213-9
   Li ZY, 2021, DIGIT SIGNAL PROCESS, V115, DOI 10.1016/j.dsp.2021.103062
   Liu DC, 2021, VISUAL COMPUT, V37, P2355, DOI 10.1007/s00371-020-01991-6
   Moosazadeh M, 2019, J INF SECUR APPL, V47, P28, DOI 10.1016/j.jisa.2019.04.001
   Pandey MK, 2019, MICROSYST TECHNOL, V25, P3071, DOI 10.1007/s00542-018-4162-1
   Parnami A., 2014, INT J COMPUTER APPL, V100, P6, DOI [10.5120/17543-8127, DOI 10.5120/17543-8127]
   Pradhan, 2019, INT J INF TECHNOL, P1
   Saleh, 2008, EFFICIENT MIDBAND EX, P1
   Singh B, 2014, 2014 IEEE 3RD GLOBAL CONFERENCE ON CONSUMER ELECTRONICS (GCCE), P289, DOI 10.1109/GCCE.2014.7031330
   Su QT, 2020, MULTIMED TOOLS APPL, V79, P30023, DOI 10.1007/s11042-020-09436-x
   Su QT, 2019, IEEE ACCESS, V7, P30398, DOI 10.1109/ACCESS.2019.2895062
   Su QT, 2019, IEEE ACCESS, V7, P4358, DOI 10.1109/ACCESS.2018.2888857
   Su QT, 2018, MULTIDIM SYST SIGN P, V29, P1055, DOI 10.1007/s11045-017-0487-7
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P8781, DOI 10.1007/s11042-016-3522-z
   Thomas R, 2021, INT CONF ELECTR ENER, P641, DOI 10.1109/ICEES51510.2021.9383746
   Wu XQ, 2019, MULTIMED TOOLS APPL, V78, P8463, DOI 10.1007/s11042-018-6877-5
   Yuan ZH, 2020, OPTIK, V204, DOI 10.1016/j.ijleo.2019.164152
   Zeki A.M., 2009, WORLD ACAD SCI ENG T, V50, P989
   Zhang FY, 2019, MULTIMED TOOLS APPL, V78, P20133, DOI 10.1007/s11042-019-7326-9
   Zhang LN, 2020, DIGIT SIGNAL PROCESS, V106, DOI 10.1016/j.dsp.2020.102805
   Zhang XT, 2020, OPTIK, V219, DOI 10.1016/j.ijleo.2020.165272
NR 41
TC 3
Z9 3
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15475
EP 15491
DI 10.1007/s11042-022-13928-3
EA OCT 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000864310100001
DA 2024-07-18
ER

PT J
AU Chen, L
   Wu, MT
AF Chen, Liang
   Wu, Mengting
TI Research on interactive analysis report in data analysis and
   visualization platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data analysis; Data visualization; Intelligent manufacturing
AB In order to solve the problem that the traditional data analysis visualization tools cannot fully express the potential information behind the quality data. Firstly, the text generation technology based on template is proposed to add text description to visual chart, which combines text and visual chart to help users enrich visual representation and discover data rules; Secondly, a new method of combining text and visualization is proposed to generate interactive data analysis report, which helps users to explore data visualization through the interaction between text and visualization chart, and embeds sparkline into text to reduce frequent switching between them; Finally, taking the manufacturing quality inspection of an enterprise as an example, the application of the above technology is verified. The results show that the text and visualization enrich each other, enhance the visualization effect, and the interactive analysis report realizes the user's visual exploration of data.
C1 [Chen, Liang; Wu, Mengting] Xian Polytech Univ, Sch Comp Sci, Dept Comp Applicat, Xian, Peoples R China.
C3 Xi'an Polytechnic University
RP Wu, MT (corresponding author), Xian Polytech Univ, Sch Comp Sci, Dept Comp Applicat, Xian, Peoples R China.
EM wumengting2020@163.com
FU Key Scientific Research Plan project of Shaanxi Provincial Department of
   Education [22JS021]
FX This work was supported by Key Scientific Research Plan project of
   Shaanxi Provincial Department of Education (No. 22JS021).
CR Ayres P., 2005, The Cambridge Handbook of Multimedia Learning, P135, DOI [DOI 10.1017/CBO9781139547369.011, 10.1017/cbo9780511816819.009, DOI 10.1017/CBO9780511816819.009]
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Beck F, 2017, 2017 IEEE WORKING CONFERENCE ON SOFTWARE VISUALIZATION (VISSOFT 2017), P1, DOI 10.1109/VISSOFT.2017.11
   Beck F, 2017, IEEE T VIS COMPUT GR, V23, P1576, DOI 10.1109/TVCG.2017.2674958
   Chen L, 2017, 2016 INT C AUD LANG
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   Goffin P, 2015, C INF VIS IEEE
   Goffin P, 2014, IEEE T VIS COMPUT GR, V20, P2291, DOI 10.1109/TVCG.2014.2346435
   Gong JP, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P499
   Gupta S, 2021, ARCH COMPUT METHOD E, V28, P2209, DOI 10.1007/s11831-020-09452-y
   Kalamaras I, 2018, IEEE T INTELL TRANSP, V19, P487, DOI 10.1109/TITS.2017.2727143
   Kong N, 2014, EXTRACTING REFERENCE
   Koytek P, 2018, IEEE T VIS COMPUT GR, V24, P605, DOI 10.1109/TVCG.2017.2743859
   Kwon B.C., 2014, P POSTER COMPENDIUM, V3, P3
   Latif Shahid, 2018, Computing in Science & Engineering, V20, P96, DOI 10.1109/MCSE.2018.2875316
   Latif S, 2019, IEEE T VIS COMPUT GR, V25, P152, DOI 10.1109/TVCG.2018.2865022
   Li Xixing, 2016, Computer Integrated Manufacturing Systems, V22, P672, DOI 10.13196/j.cims.2016.03.011
   Narang SR, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (IEEE PDGC), P215, DOI 10.1109/PDGC.2018.8745903
   Schultheiss LA, 1963, TECHNIQUES FLOW CHAR
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Tufte ER, 1997, Beautiful Evidence
   Wei L, 2019, 2019 IEEE 4 INT C CL
   Zhang Jie, 2016, Computer Integrated Manufacturing Systems, V22, P1220, DOI 10.13196/j.cims.2016.05.007
NR 23
TC 0
Z9 0
U1 5
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13765
EP 13778
DI 10.1007/s11042-022-13652-y
EA OCT 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000862219500001
DA 2024-07-18
ER

PT J
AU Xiong, LY
   Yi, H
   Huang, XH
   Huang, WC
AF Xiong, Liyan
   Yi, Hu
   Huang, Xiaohui
   Huang, Weichun
TI An efficient multi-scale contextual feature fusion network for counting
   crowds with varying densities and scales
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd counting; Crowd density map; Multi-scale; Contextual feature
AB The crowd counting problem aims to predict the number of pedestrians in a surveillance video or an image and produce a crowd density map. Achieving accurate crowd counting in different crowded scenes is still challenging due to drastic scale changes and severe occlusions. This paper proposes an efficient multi-scale contextual feature fusion network for counting crowds with varying densities and scales, abbreviated as MSC-FFN. We design a spatial pyramid feature extraction module that enables rich contextual feature extraction to adapt to rapid scale changes. To further enhance the model's ability to suppress background and focus on main features, we also design a spatial channel attention module to integrate feature map correlations from spatial and channel dimensions, so that the network can focus on main crowd features and filter out irrelevant background information, which outputs a high-quality density map. We conduct extensive experiments on multiple challenging crowds counting datasets, including UCF_CC_50, ShanghaiTech, WorldExpo'10, and Mall dataset, and the results demonstrate that MSC-FFN outperforms many state-of-the-art methods in counting performance and generated density maps.
C1 [Xiong, Liyan; Yi, Hu; Huang, Xiaohui] East China Jiaotong Univ, Sch Informat Engn, Nanchang 330013, Jiangxi, Peoples R China.
   [Huang, Weichun] East China Jiaotong Univ, Sch Software, Nanchang 330013, Jiangxi, Peoples R China.
C3 East China Jiaotong University; East China Jiaotong University
RP Yi, H (corresponding author), East China Jiaotong Univ, Sch Informat Engn, Nanchang 330013, Jiangxi, Peoples R China.
EM yh_hnjx@163.com
RI Huang, Weichun/O-6474-2018; wang, yan/GSE-6489-2022; huang,
   xiaohui/KRP-2903-2024
OI Yi, Hu/0000-0002-3136-0522
FU National Natural Science Foundation of China [62067002, 61967006,
   62062033]; Science and Technology Project of the Transportation
   Department of Jiangxi Province, China [2021X0011, 2022X0040]
FX This work was supported in part by the National Natural Science
   Foundation of China (Nos.62067002, 61967006, and 62062033), and in part
   by the Science and Technology Project of the Transportation Department
   of Jiangxi Province, China (Nos.2021X0011, 2022X0040).
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Azizpour H, 2012, LECT NOTES COMPUT SC, V7572, P836, DOI 10.1007/978-3-642-33718-5_60
   Bai S, 2020, PROC CVPR IEEE, P4593, DOI 10.1109/CVPR42600.2020.00465
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Chan AB, 2012, IEEE T IMAGE PROCESS, V21, P2160, DOI 10.1109/TIP.2011.2172800
   Chen JW, 2021, IET IMAGE PROCESS, V15, P1221, DOI 10.1049/ipr2.12099
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Ding XH, 2021, IEEE T INTELL TRANSP, V22, P4776, DOI 10.1109/TITS.2020.2983475
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Fu HY, 2014, MULTIMED TOOLS APPL, V73, P273, DOI 10.1007/s11042-013-1608-4
   Gao JY, 2019, NEUROCOMPUTING, V363, P1, DOI 10.1016/j.neucom.2019.08.018
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hu CR, 2020, MULTIMED TOOLS APPL, V79, P15059, DOI 10.1007/s11042-020-08888-5
   Idrees H, 2018, COSMPOSITION LOSS CO
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Jiang XH, 2020, PROC CVPR IEEE, P4705, DOI 10.1109/CVPR42600.2020.00476
   Khan SD, 2021, ARAB J SCI ENG, V46, P3051, DOI 10.1007/s13369-020-04990-w
   Kingma Diederik P, 2014, ADAM METHOD STOCHAS
   Kumagai S., 2017, MIXTURE COUNTING CNN
   Li H, 2019, IET COMPUT VIS, V13, P556, DOI 10.1049/iet-cvi.2019.0085
   Li PF, 2021, SCI PROGRAMMING-NETH, V2021, DOI 10.1155/2021/5596488
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Liu L, 2021, IEEE T MULTIMEDIA, V23, P1060, DOI 10.1109/TMM.2020.2992979
   Liu LB, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2645, DOI 10.1145/3394171.3413938
   Ma TJ, 2018, IET IMAGE PROCESS, V12, P2258, DOI 10.1049/iet-ipr.2018.5368
   Miao YQ, 2020, AAAI CONF ARTIF INTE, V34, P11765
   Mnih V, 2014, ADV NEUR IN, V27
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Sheng BY, 2018, IEEE T CIRC SYST VID, V28, P1788, DOI 10.1109/TCSVT.2016.2637379
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sindagi VA, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   Song Q., 2021, Rethinking counting and localization in crowds: A purely point-based framework, P3365
   Tang C, 2021, IEEE T MULTIMEDIA, V23, P624, DOI 10.1109/TMM.2020.2985541
   Tang C, 2022, IEEE T PATTERN ANAL, V44, P955, DOI 10.1109/TPAMI.2020.3014629
   Thanasutives P, 2021, INT C PATT RECOG, P2382, DOI 10.1109/ICPR48806.2021.9413286
   Vaswani A, 2017, ADV NEUR IN, V30
   Pham VQ, 2015, IEEE I CONF COMP VIS, P3253, DOI 10.1109/ICCV.2015.372
   Walach E, 2016, LECT NOTES COMPUT SC, V9906, P660, DOI 10.1007/978-3-319-46475-6_41
   Wang C., 2021, P IEEE CVF INT C COM, P3234
   Wang JW, 2018, PROC CVPR IEEE, P7190, DOI 10.1109/CVPR.2018.00751
   Wang Q, 2019, PROC CVPR IEEE, P8190, DOI 10.1109/CVPR.2019.00839
   Wang SZ, 2020, NEUROCOMPUTING, V404, P227, DOI 10.1016/j.neucom.2020.04.139
   Wang YJ, 2020, MULTIMED TOOLS APPL, V79, P1057, DOI 10.1007/s11042-019-08208-6
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
   Zhang AR, 2019, IEEE I CONF COMP VIS, P6787, DOI 10.1109/ICCV.2019.00689
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhu L, 2019, DUAL PATH MULTISCALE
NR 51
TC 4
Z9 4
U1 6
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13929
EP 13949
DI 10.1007/s11042-022-13920-x
EA SEP 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000859866600003
DA 2024-07-18
ER

PT J
AU Zhang, B
   Rahmatullah, B
   Wang, SL
   Liu, ZY
AF Zhang, Bin
   Rahmatullah, Bahbibi
   Wang, Shir Li
   Liu, Zhaoyan
TI A plain-image correlative semi-selective medical image encryption
   algorithm using enhanced 2D-logistic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image; Image encryption; Selective encryption; Partial
   encryption; Chaotic map; SHA-256
ID SECURE; CHAOS; SCHEME; TRANSMISSION; EFFICIENT; CRYPTOGRAPHY; DCT
AB Modern medical examinations have produced a large number of medical images. It is a great challenge to transmit and store them quickly and securely. Existing solutions mainly use medical image encryption algorithms, but these encryption algorithms, which were developed for ordinary images, are time-consuming and must cope with insufficient security considerations when encrypting medical images. Compared with ordinary images, medical images can be divided into the region of interest and the region of background. In this paper, based on this characteristic, a plain-image correlative semi-selective medical image encryption algorithm using the enhanced two dimensional Logistic map was proposed. First, the region of interest of a plain medical image is permuted at the pixel level, then for the whole medical image, substitution is performed pixel by pixel. An ideal compromise between encryption speed and security can be achieved by full-encrypting the region of interest and semi-encrypting the region of background. Several main types of medical images and some normal images were selected as the samples for simulation, and main image cryptanalysis methods were used to analyze the results. The results showed that the cipher-images have a good visual quality, high information entropy, low correlation between adjacent pixels, as well as uniformly distribute histogram. The algorithm is sensitive to the initial key and plain-image, and has a large keyspace and low time complexity. The time complexity is lower when compared with the current medical image full encryption algorithm, and the security performance is better when compared with the current medical image selective encryption algorithm.
C1 [Zhang, Bin; Rahmatullah, Bahbibi; Wang, Shir Li] Sultan Idris Educ Univ UPSI, Fac Arts Comp & Creat Ind, Data Intelligence & Knowledge Management, Tanjong Malim, Perak, Malaysia.
   [Zhang, Bin] Baoji Univ Arts & Sci, Sch Comp Sci, Baoji, Peoples R China.
   [Liu, Zhaoyan] Xidian Univ, Sch Cyber Engn, Xian, Peoples R China.
C3 Universiti Pendidikan Sultan Idris; Baoji University of Arts & Sciences;
   Xidian University
RP Rahmatullah, B (corresponding author), Sultan Idris Educ Univ UPSI, Fac Arts Comp & Creat Ind, Data Intelligence & Knowledge Management, Tanjong Malim, Perak, Malaysia.
EM bahbibi@fskik.upsi.edu.my
OI Wang, Shir Li/0000-0003-4417-3213
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P1073, DOI 10.1109/ACCESS.2017.2777869
   Abdmouleh MK, 2017, I C COMP GRAPH IM VI, P79, DOI 10.1109/CGiV.2017.10
   Akkasaligar PT, 2020, INF SECUR J, V29, P91, DOI 10.1080/19393555.2020.1718248
   Al-Haj A, 2015, IET INFORM SECUR, V9, P365, DOI 10.1049/iet-ifs.2014.0245
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Arumugham S, 2018, J BIOMED INFORM, V86, P90, DOI 10.1016/j.jbi.2018.08.010
   Arunkumar S, 2019, MEASUREMENT, V139, P426, DOI 10.1016/j.measurement.2019.02.069
   Bakshi A, 2019, J INF SECUR APPL, V46, P281, DOI 10.1016/j.jisa.2019.03.004
   Balasamy K, 2021, MULTIMED TOOLS APPL, V80, P7167, DOI 10.1007/s11042-020-09981-5
   Banik A, 2019, J INF SECUR APPL, V49, DOI 10.1016/j.jisa.2019.102398
   Banu SA, 2020, MED BIOL ENG COMPUT, V58, P1445, DOI 10.1007/s11517-020-02178-w
   Barik RC, 2021, MULTIMED TOOLS APPL, V80, P10723, DOI 10.1007/s11042-020-09930-2
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Cao WJ, 2017, SIGNAL PROCESS, V132, P96, DOI 10.1016/j.sigpro.2016.10.003
   Chandrasekaran J, 2017, SECUR COMMUN NETW, P1, DOI 10.1155/2017/6729896
   Chen MM, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106026
   Chen X., 2017, Biomedical Research (India), V28, P8834
   Chen X, 2017, SAUDI J BIOL SCI, V24, P1821, DOI 10.1016/j.sjbs.2017.11.023
   Chirakkarottu S, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-019-1685-8
   Dagadu JC, 2019, WIRELESS PERS COMMUN, V108, P591, DOI 10.1007/s11277-019-06420-z
   Dai Y, 2016, TECHNOL HEALTH CARE, V24, pS435, DOI 10.3233/THC-161166
   Dai Y, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416570019
   Devi RS, 2019, INT J THEOR PHYS, V58, P1937, DOI 10.1007/s10773-019-04088-6
   Dridi M, 2016, IET IMAGE PROCESS, V10, P830, DOI 10.1049/iet-ipr.2015.0868
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gafsi M, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/6612390
   Ge J, 2020, CMES-COMP MODEL ENG, V125, P1083, DOI 10.32604/cmes.2020.013039
   Gupta Ranu, 2018, Molecular & Cellular Biomechanics, V15, P63, DOI 10.3970/mcb.2018.00114
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Ismail SM, 2018, J ADV RES, V10, P85, DOI 10.1016/j.jare.2018.01.009
   Jain M, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P291, DOI 10.1109/IC3I.2016.7917977
   Jiao G., 2019, INT J PERFORM ENG, V15, P1436, DOI [10.23940/ijpe.19.05.p20.14361444, DOI 10.23940/IJPE.19.05.P20.14361444]
   Jiao G, 2019, KSII T INTERNET INF, V13, P1064, DOI 10.3837/tiis.2019.02.031
   Kanso A, 2018, J VIS COMMUN IMAGE R, V56, P245, DOI 10.1016/j.jvcir.2018.09.018
   Kanso A, 2015, COMMUN NONLINEAR SCI, V24, P98, DOI 10.1016/j.cnsns.2014.12.005
   Khashan OA, 2020, MULTIMED TOOLS APPL, V79, P26369, DOI 10.1007/s11042-020-09264-z
   Khond S., 2019, INT J ENG ADV TECHNO, V8, P1062, DOI [10.35940/ijeat.F1202.0886S19, DOI 10.35940/IJEAT.F1202.0886S19]
   Koppu S, 2018, EVOL INTELL, V11, P53, DOI 10.1007/s12065-018-0159-z
   Kumar CV., 2015, APPL MATH SCI, V9, P2381
   Kumar S, 2019, MED BIOL ENG COMPUT, V57, P2517, DOI 10.1007/s11517-019-02037-3
   Laiphrakpam DS, 2017, OPTIK, V147, P88, DOI 10.1016/j.ijleo.2017.08.028
   Lakshmi C, 2021, NEURAL COMPUT APPL, V33, P6671, DOI 10.1007/s00521-020-05447-9
   Li-bo Zhang, 2015, Mathematical Problems in Engineering, V2015, DOI 10.1155/2015/940638
   Liu J, 2019, CMC-COMPUT MATER CON, V61, P889, DOI 10.32604/cmc.2019.06034
   Liu JZ, 2018, MULTIMED TOOLS APPL, V77, P22787, DOI 10.1007/s11042-017-5534-8
   Madhusudhan KN, 2021, J AMB INTEL HUM COMP, V12, P5413, DOI 10.1007/s12652-020-02028-5
   Manikandan V, 2021, MULTIMED TOOLS APPL, V80, P23511, DOI 10.1007/s11042-021-10943-8
   Manikandan V, 2022, MED BIOL ENG COMPUT, V60, P701, DOI 10.1007/s11517-021-02499-4
   Mortajez S., 2020, Inform. Med. Unlocked, V20, DOI [10.1016/j.imu.2020.100396, DOI 10.1016/J.IMU.2020.100396]
   Muthu JS, 2022, OPTIK, V251, DOI 10.1016/j.ijleo.2021.168416
   Norcen R, 2003, COMPUT BIOL MED, V33, P277, DOI 10.1016/S0010-4825(02)00094-X
   Noura M, 2018, MULTIMED TOOLS APPL, V77, P31397, DOI 10.1007/s11042-018-6051-0
   Ping P, 2022, MULT TOOLS APPL, P1
   Prabhakar K.K., 2017, 2017 IEEE Power Energy Society General Meeting, P1, DOI [DOI 10.1109/ICEECCOT.2017.8284614, https://doi.org/10.1109/ICEECCOT.2017.8284614]
   Praveenkumar P, 2018, MULTIMED TOOLS APPL, V77, P8393, DOI 10.1007/s11042-017-4741-7
   Qasim KR., 2020, MEDICO LEGAL UPDATE, V20, P1248
   Rahmatullah B, 2007, J MECH MED BIOL, V7, P247, DOI 10.1142/S0219519407002327
   Rahmatullah Bahbibi., 2013, INT C BIOM INF TECHN, P207
   Raja SP, 2019, INT J WAVELETS MULTI, V17, DOI 10.1142/S0219691319500346
   Ravichandran D, 2021, MED BIOL ENG COMPUT, V59, P589, DOI 10.1007/s11517-021-02328-8
   Ravichandran D, 2017, IEEE T NANOBIOSCI, V16, P850, DOI 10.1109/TNB.2017.2780881
   Ravichandran D, 2016, COMPUT BIOL MED, V72, P170, DOI 10.1016/j.compbiomed.2016.03.020
   Sangavi V, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102626
   Sasikaladevi N, 2022, J KING SAUD UNIV-COM, V34, P676, DOI 10.1016/j.jksuci.2019.01.014
   Shafique A, 2021, IEEE ACCESS, V9, P59108, DOI 10.1109/ACCESS.2021.3071535
   Shahzadi R, 2019, IEEE ACCESS, V7, P52858, DOI 10.1109/ACCESS.2019.2909554
   Shankar K, 2018, IEEE ACCESS, V6, P77145, DOI 10.1109/ACCESS.2018.2874026
   Stalin S, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1389-z
   Tamilselvi R., 2015, INT J CHEMTECH RES, V8, P843
   Tamrin KF, 2015, J MOD OPTIC, V62, P701, DOI 10.1080/09500340.2014.1003257
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yang Y, 2019, IEEE ACCESS, V7, P96900, DOI 10.1109/ACCESS.2019.2929298
   Ye CH, 2015, INT J SECUR APPL, V9, P409, DOI 10.14257/ijsia.2015.9.1.39
   Zhang B, 2023, MULTIMED TOOLS APPL, V82, P21867, DOI 10.1007/s11042-020-09629-4
   Zhang LB, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/913476
   Zhou J, 2020, IEEE ACCESS, V8, P122210, DOI 10.1109/ACCESS.2020.3007550
NR 76
TC 7
Z9 7
U1 17
U2 93
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15735
EP 15762
DI 10.1007/s11042-022-13744-9
EA SEP 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000857279500004
PM 36185323
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Wu, YZ
   Li, JH
AF Wu, Yongzhen
   Li, Jinhua
TI Multi-modal emotion identification fusing facial expression and EEG
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion identification; Multi-level convolutional neural network; Stack
   bidirectional long short-term memory model (Bi-LSTM); Decision-level
   information fusion
AB Aiming at solving the matter of low accuracy of emotion identification way in traditional facial expression images, this paper presents a new way of multi-modal emotion identification. Based on the modal information of facial expression, the method designs a multi-level convolutional neural network(CNN) model for facial expression emotion identification. Based on electroencephalograhpy (EEG) information modes, the method creates a stacked bidirectional LSTM(Bi-LSTM) model for emotion identification. At the decision level, D-S evidence theory is used to fuse the emotion identification results. The consequences show that the identification accuracy of multi-mode decision-level information fusion method in the two dimensions of valence and arousal in DEAP dataset reaches 95.30% and 94.94% respectively. The multi-level CNN feature extraction model proposed in this paper has a identification accuracy of 96.36% and 73.00% on CK+ dataset and Fer2013 dataset respectively. Compared with other ways, our way improves the accuracy of emotion identification
C1 [Wu, Yongzhen] Qingdao Univ, Coll Comp Sci & Technol, Qingdao, Shandong, Peoples R China.
   [Li, Jinhua] Qingdao Engn Res Ctr Ship Bldg Intelligent Precis, Qingdao, Shandong, Peoples R China.
C3 Qingdao University
RP Li, JH (corresponding author), Qingdao Engn Res Ctr Ship Bldg Intelligent Precis, Qingdao, Shandong, Peoples R China.
EM lijh@qdu.edu.cn
RI Li, Jinhua/A-1163-2014
OI Wu, Yongzhen/0000-0001-9194-0521
FU Key Research and Development Plan-Major Scientific and Technological
   Innovation Projects of ShanDong Province [2019JZZY020101]
FX We want to thank to Dr. Jinhua Li for his guidance in the writing of
   this paper, who served as its scientific advisor. This work is supported
   by the Key Research and Development Plan-Major Scientific and
   Technological Innovation Projects of ShanDong Province (2019JZZY020101).
CR Acharya D., 2021, INT ADV COMPUTING C, V1367, DOI DOI 10.1007/978-981-16-0401-0_38
   Alchalabi B, 2021, J NEURAL ENG, V18, DOI 10.1088/1741-2552/abee51
   [Anonymous], 2020, A Mathematical Theory of Evidence, DOI DOI 10.1515/9780691214696
   Bao-Liang L., 2021, CHIN J INTELL SCI TE, V1, P36, DOI DOI 10.11959/J.ISSN.2096-6652.202104
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Chao H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092212
   De Nadai S., 2016, 2016 11 SYST SYST EN, P1, DOI [10.1109/SYSOSE.2016.7542941, DOI 10.1109/SYSOSE.2016.7542941]
   DEMPSTER AP, 1967, ANN MATH STAT, V38, P325, DOI 10.1214/aoms/1177698950
   Do LN, 2021, J SUPERCOMPUT, V77, P10773, DOI 10.1007/s11227-021-03690-y
   Duan RN, 2013, I IEEE EMBS C NEUR E, P81, DOI 10.1109/NER.2013.6695876
   Fridman L, 2015, COMPUT ELECTR ENG, V41, P142, DOI 10.1016/j.compeleceng.2014.10.018
   Guo R, 2013, INT CONF PER COMP, P436, DOI 10.4108/icst.pervasivehealth.2013.252133
   Guo Zizheng, 2017, Journal of Beijing University of Technology, V43, P929, DOI 10.11936/bjutxb2016030034
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang YR, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11050105
   Istiake Sunny Md Arif, 2020, 2020 2nd Novel Intelligent and Leading Emerging Sciences Conference (NILES), P87, DOI 10.1109/NILES50944.2020.9257950
   Jinxiang Liao, 2020, IOP Conference Series: Materials Science and Engineering, V782, DOI 10.1088/1757-899X/782/3/032005
   Kaggle, FER2013 DAT
   Khorrami P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P19, DOI 10.1109/ICCVW.2015.12
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Liu S, 2023, INTERACT LEARN ENVIR, V31, P3340, DOI 10.1080/10494820.2021.1927115
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Morris JD, 1995, J ADVERTISING RES, V35, P63
   Pusarla N, 2020, NATL CONF COMMUN, DOI 10.1109/ncc48643.2020.9056002
   Qiaohong C., 2020, J ZHEJIANG SCI TECH, V06, P815
   Schoneveld L, 2021, PATTERN RECOGN LETT, V146, P1, DOI 10.1016/j.patrec.2021.03.007
   Simard PY, 2003, PROC INT CONF DOC, P958
   Song J., 2021, Dissertation
   Tang H, 2017, LECT NOTES COMPUT SC, V10637, P811, DOI 10.1007/978-3-319-70093-9_86
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Waltz EL, 1990, MULTISENSOR DATA FUS, V1990, P585
   Wang M, 2021, COMPUT ELECTR ENG, V94, DOI 10.1016/j.compeleceng.2021.107319
   Wenfen L., 2021, CHIN J INTELL SCI TE, V1, P76
   Yin YQ, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106954
   Yin Z, 2017, FRONT NEUROROBOTICS, V11, DOI 10.3389/fnbot.2017.00019
   Zhenyue Q, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1811.04544
   Ziyu D., 2021, CHIN J SENS ACTUATOR, V4, P496
NR 39
TC 4
Z9 5
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10901
EP 10919
DI 10.1007/s11042-022-13711-4
EA SEP 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000852346600001
DA 2024-07-18
ER

PT J
AU Juang, LH
AF Juang, Li-Hong
TI Humanoid robot runs maze mode using depth-first traversal algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE NAO robot; Obstacle avoidance; Maze; Image processing
ID NAVIGATION
AB This paper focuses on the humanoid robot walking in the maze. In this research, we proposed the depth-first traversal algorithm for the maze searching with the single-view model and sonar obstacle avoidance theory then follow the "turn right first" principle to successfully avoid obstacles and efficiently walk out of the maze. The superiority of the proposed algorithm is that it can be for various complex mazes. In the three-dimensional maze, the visual system of the NAO robot was firstly used to perceive its surrounding environment, and then the image processing technology was used to identify the position of the surrounding obstacles. After that, the NAO robot can successfully avoid obstacles and walk out of the maze. Today, intelligent robots have a wide range of applications. In order to allow them to quickly integrate into our daily lives, they need to be able to recognize obstacles and walk freely like humans. This requires robots equipped with image processing technology which is able to help robots identify obstacles. During walking, robot will comply right turn in the first. We will use sonar to perceive the obstacles on the left and right sides. And at the turn image processing will be used probe obstacles at right and left. Finally, they will preserve memory of what they have been walked. The experimental results indicate that this method provides a reliable guarantee for the NAO robot to successfully avoid obstacles and get out of the maze.
C1 [Juang, Li-Hong] Lunghwa Univ Sci & Technol, Dept Elect Engn, 300,Sec 1,Wanshou Rd, Taoyuan 333326, Taiwan.
RP Juang, LH (corresponding author), Lunghwa Univ Sci & Technol, Dept Elect Engn, 300,Sec 1,Wanshou Rd, Taoyuan 333326, Taiwan.
EM lipuu@qq.com
CR Aldana-Murillo NG, 2015, LECT NOTES COMPUT SC, V9116, P179, DOI 10.1007/978-3-319-19264-2_18
   Aldebaran Robotic, 2022, NAO SOFTW 1 12 5 DOC
   Alexiadis DS, 2013, IEEE T MULTIMEDIA, V15, P339, DOI 10.1109/TMM.2012.2229264
   [Anonymous], P IEEE 10 AS CONTR C
   Antonelli G, 2007, IEEE T FUZZY SYST, V15, P211, DOI 10.1109/TFUZZ.2006.879998
   Armesto L., 2009, P IEEE C EM TECHN FA, P1, DOI DOI 10.1109/ETFA.2009.5347051
   Bazylev D, 2017, MED C CONTR AUTOMAT, P1310, DOI 10.1109/MED.2017.7984299
   Brandao AS, 2015, ICIMCO 2015 PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS, VOL. 2, P314
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   De San Bernabe A, 2017, INFORM FUSION, V36, P296, DOI 10.1016/j.inffus.2016.11.001
   Delfin J, 2014, IEEE-RAS INT C HUMAN, P354, DOI 10.1109/HUMANOIDS.2014.7041384
   Faragasso A, 2013, IEEE INT CONF ROBOT, P3190, DOI 10.1109/ICRA.2013.6631021
   Han S, 2012, IEEE T AUTOM SCI ENG, V9, P467, DOI 10.1109/TASE.2012.2193568
   Hornung A, 2010, AUTON ROBOT, V29, P137, DOI 10.1007/s10514-010-9190-3
   Lin H., 2012, MANUF AUTOM, V34, P80
   Lu Y, 2015, IEEE T ROBOT, V31, P736, DOI 10.1109/TRO.2015.2424032
   Luo B, 2015, CHIN AUTOM CONGR, P371, DOI 10.1109/CAC.2015.7382527
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Martínez S, 2007, IEEE CONTR SYST MAG, V27, P75, DOI 10.1109/MCS.2007.384124
   Morrison JG, 2016, IEEE CONTR SYST MAG, V36, P75, DOI 10.1109/MCS.2015.2512032
   Ng KH, 2012, PROCEDIA ENGINEER, V41, P237, DOI 10.1016/j.proeng.2012.07.168
   ORIOLO G, 1995, IEEE INT CONF ROBOT, P2900, DOI 10.1109/ROBOT.1995.525695
   Oriolo G, 2013, IEEE-RAS INT C HUMAN, P118, DOI 10.1109/HUMANOIDS.2013.7029965
   Quigley M, 2022, ICRA WORKSHOP OPEN S
   Rincon JA, 2016, ADV PRACTICAL APPL S
   Ryberg A, 2006, 2006 IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS, VOLS 1-7, P2798, DOI 10.1109/ISIE.2006.296058
   Sun Yichao, 2014, HUMANOID ROBOT CONTR
   Tessier C, 2010, INFORM FUSION, V11, P283, DOI 10.1016/j.inffus.2009.09.006
   [吴俊君 Wu Junjun], 2014, [自动化学报, Acta Automatica Sinica], V40, P267
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
NR 30
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11847
EP 11871
DI 10.1007/s11042-022-13729-8
EA SEP 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000852138100003
DA 2024-07-18
ER

PT J
AU Lu, C
   Zhou, GX
   Li, MX
AF Lu, Chao
   Zhou, Guoxiong
   Li, Mingxuan
TI Research on information fusion method for heat model and weather model
   based on HOGA-SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heat model; Weather model; DEVS-FIRE; HOGA; SVM; Wildfire spread
   simulation
ID FIRE SPREAD PREDICTION; DEVS-FIRE
AB Modeling the heat released from a burning wildfire is essential to support an accurate representation of the heat flux of wildfire. At present, the commonly used heat model is combustion heat modeling in the wildfire spread model of DEVS-FIRE. DEVS-FIRE employs Rothermel's model to calculate the rate of fire spread, but it is poorly suitable for the actual situation in China. Forest fire spreading is a dynamic and complex system. In the process of spreading, the heat released by forest fire will affect the weather conditions in the current fire area, and the weather conditions such as temperature, humidity, wind speed and wind direction are the important factors affecting the spread of forest fire in turn. Therefore, the interaction between heat and weather conditions must be considered in order to accurately predict the spread of forest fires. This paper proposes heat model based on Zhengfei Wang's wildfire spread model. The heat model was used to fuse with the weather model, and the information was fused based on the hybrid orthogonal genetic algorithm (HOGA) and support vector machine (SVM). The fused data was input into DEVS-Fire to simulate the spread of wildfire. Experiment results demonstrate that this method improves the precision of wildfire spread.
C1 [Lu, Chao; Zhou, Guoxiong; Li, Mingxuan] Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha 410004, Peoples R China.
C3 Central South University of Forestry & Technology
RP Zhou, GX (corresponding author), Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha 410004, Peoples R China.
EM 1244414754@qq.com; zhougx01@163.com; 173523919@qq.com
RI li, yansong/JXL-5023-2024; liu, jianyang/JXL-6273-2024; 陆,
   超/AFD-5669-2022
OI Zhou, Guoxiong/0000-0002-5142-4845
CR ALBINI FA, 1995, INT J WILDLAND FIRE, V5, P81, DOI 10.1071/WF9950081
   Artés T, 2013, PROCEDIA COMPUT SCI, V18, P2278, DOI 10.1016/j.procs.2013.05.399
   Balbi JH, 2007, COMBUST SCI TECHNOL, V179, P2511, DOI 10.1080/00102200701484449
   Chao L, 2015, DISSERTATION
   Clark TL, 2004, INT J WILDLAND FIRE, V13, P49, DOI 10.1071/WF03043
   Cunningham P, 2007, J GEOPHYS RES-ATMOS, V112, DOI 10.1029/2006JD007638
   Fernandes PAM, 2001, FOREST ECOL MANAG, V144, P67, DOI 10.1016/S0378-1127(00)00363-7
   Filippi JB, 2009, J ADV MODEL EARTH SY, V1, DOI 10.3894/JAMES.2009.1.11
   Finney M.A., 1999, SPATIAL MODELING POS
   Li XD, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13214325
   Li ZX, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-6, P925, DOI 10.1109/ICMLC.2009.5212442
   Linn R R., 1997, Tech. Rep. La-13334-T, DOI DOI 10.2172/505313
   Mandel J, 2011, GEOSCI MODEL DEV, V4, P591, DOI 10.5194/gmd-4-591-2011
   Mangiameli M, 2021, GEOMATICS-BASEL, V1, P50, DOI 10.3390/geomatics1010005
   Ntaimo L, 2008, SIMUL-T SOC MOD SIM, V84, P137, DOI 10.1177/0037549708094047
   Sharma R, 2020, MULTIMED TOOLS APPL, V79, P28155, DOI 10.1007/s11042-020-09347-x
   Xue HD, 2012, PROCEDIA COMPUT SCI, V9, P302, DOI 10.1016/j.procs.2012.04.032
   Zhang SY, 2021, CERNE, V27, DOI 10.1590/01047760202127012932
   Zhou Guoxiong, 2018, Journal of System Simulation, V30, P3642, DOI 10.16182/j.issn1004731x.joss.201810006
   Zou Ziming, 2013, Science & Technology Review, V31, P18, DOI 10.3981/j.issn.1000-7857.2013.10.001
NR 20
TC 1
Z9 1
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9381
EP 9398
DI 10.1007/s11042-022-13743-w
EA SEP 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000849487500007
DA 2024-07-18
ER

PT J
AU Sulaiman, A
   Feizollah, A
   Mostafa, MM
   Zakaria, Z
AF Sulaiman, Ainin
   Feizollah, Ali
   Mostafa, Mohamed M.
   Zakaria, Zalina
TI Profiling the halal food consumer on Instagram: integrating image,
   textual, and social tagging data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Instagram; Halal food; Associate networks; sentiment analysis; Social
   tagging
ID ONLINE; INSIGHTS; MAPS
AB With more than one billion active users, Instagram is one of the most widely utilized social media platforms. Although recent research has begun to analyze brand-related images, Instagram remains largely neglected within halal food research. In this study, we aim to fill this research gap by collecting, labeling, aggregating, clustering, analyzing, and mapping halal food images, text, and social tagging on Instagram. In total, approximately 95,000 photos related to #halalfood tag were extracted from Instagram along with data related to photo captions, social tags, and comments on the posted photos. Google's Cloud Vision Application Programming Interface (API) was employed for image labeling to represent context of the photos. The photos were categorized, based on their label, into food, place, advertisement, event, and unhealthy food. The captions and comments in each category were analyzed using the associate network and sentiment analysis approaches. The study found the most frequent tags in Instagram posts, besides the obvious halal food related tags, were #halalfoodexpo, #halalfoodkorea, #halalfoodfestival, and #burger. Furthermore, the most influential tags, besides the halal food related tags, were #halalfoodexpo, #chicken, #halalfoodkorea, #halaltourism, and #repost. In addition, it was found that most of the Instagram data contain positive sentiments towards halal food.
C1 [Sulaiman, Ainin; Feizollah, Ali; Zakaria, Zalina] Univ Malaya, Univ Malaya Halal Res Ctr UMHRC, Kuala Lumpur, Malaysia.
   [Feizollah, Ali] Univ Malaya, Fac Comp Sci & Informat Technol, Dept Comp Syst & Technol, Kuala Lumpur 50603, Malaysia.
   [Mostafa, Mohamed M.] Gulf Univ Sci & Technol, Kuwait, Kuwait.
   [Zakaria, Zalina] Univ Malaya, Acad Islamic Studies, Kuala Lumpur 50603, Malaysia.
C3 Universiti Malaya; Universiti Malaya; Gulf University for Science &
   Technology (GUST); Universiti Malaya
RP Feizollah, A (corresponding author), Univ Malaya, Univ Malaya Halal Res Ctr UMHRC, Kuala Lumpur, Malaysia.; Feizollah, A (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Dept Comp Syst & Technol, Kuala Lumpur 50603, Malaysia.
EM ali.feizollah@um.edu.my
RI ZAKARIA, ZALINA/GYD-6953-2022; Sulaiman, Ainin/HTT-0500-2023; Feizollah,
   Ali/JMB-4153-2023
OI Feizollah, Ali/0000-0003-2439-8482; Mostafa, Mohamed/0000-0002-1145-4919
FU Universiti Malaya
FX We would like to thank the UM Halal Research Centre staff for the
   administrative and technical support. This research was partly funded by
   Universiti Malaya, grant number BKS001-2019. The second author would
   like to thank Universiti Malaya for funding the postdoc position.
CR Ab Talib MS, 2016, MANAG RES REV, V39, P987, DOI 10.1108/MRR-06-2015-0147
   Agarwal Amit, 2018, 2018 International Conference on Advances in Computing and Communication Engineering (ICACCE), P189, DOI 10.1109/ICACCE.2018.8441696
   Ali MH, 2016, INT J PROD ECON, V181, P303, DOI 10.1016/j.ijpe.2016.06.003
   Anderson J. R., 1974, HUMAN ASS MEMORY, DOI [10.4324/9781315802886, DOI 10.4324/9781315802886]
   Atwal G, 2019, BRIT FOOD J, V121, P454, DOI 10.1108/BFJ-02-2018-0076
   Awan HM, 2015, MANAG RES REV, V38, P640, DOI 10.1108/MRR-01-2014-0022
   Bloom N, 2015, P 24 INT C WORLD WID
   Borgatti S. P., 2006, Computational & Mathematical Organization Theory, V12, P21, DOI 10.1007/s10588-006-7084-x
   Buckner RL, 2009, J NEUROSCI, V29, P1860, DOI 10.1523/JNEUROSCI.5062-08.2009
   Chen JY, 2020, J AM ACAD DERMATOL, V83, P1175, DOI 10.1016/j.jaad.2020.02.001
   Davies T, 2019, J GEOGR HIGHER EDUC, V43, P362, DOI 10.1080/03098265.2019.1608428
   des Robert M, 2021, J REPROD INFANT PSYC, V39, P342, DOI 10.1080/02646838.2020.1720910
   Feizollah A, 2019, IEEE ACCESS, V7, P83354, DOI 10.1109/ACCESS.2019.2923275
   Gensler S, 2016, INT J ELECTRON COMM, V20, P112, DOI 10.1080/10864415.2016.1061792
   Ginsburg K., 2015, The Elon Journal of Undergraduate Research in Communications, V6, P78
   Halal Malaysia Portal, HAL MAL PORT 2021
   Henderson GR, 1998, EUR J OPER RES, V111, P306, DOI 10.1016/S0377-2217(98)00151-9
   Hu Yuheng., 2014, P 8 INT AAAI C WEBLO, P595
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI [DOI 10.1609/ICWSM.V8I1.14550, 10.1609/icwsm.v8i1.14550]
   Ichau E, 2019, TELEMAT INFORM, V44, DOI 10.1016/j.tele.2019.101275
   Ilich KL, 2020, INFORM COMMUN SOC, V23, P1, DOI 10.1080/1369118X.2018.1478983
   John DR, 2006, J MARKETING RES, V43, P549, DOI 10.1509/jmkr.43.4.549
   Johnson L., 2015, FOOD BRANDS CAN NAIL
   Kusumasondjaja S, 2019, INTERNET RES, V29, P659, DOI 10.1108/IntR-11-2017-0459
   Laestadius L., 2017, SAGE HDB SOCIAL MEDI, P573, DOI DOI 10.4135/9781473983847.N34
   Lister M, 2019, 33 MIND BOGGLING INS
   Liu HL, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10093216
   Liu L., 2017, SSRN ELECT J, V2, P1, DOI [10.2139/ssrn.2978805, DOI 10.2139/SSRN.2978805]
   Mazloom M., 2016, P ACM MULT, P197, DOI [10.1145/2964284.2967210, 10]
   McKeown JKL, 2020, ANN LEIS RES, V23, P645, DOI 10.1080/11745398.2019.1613245
   Mirhadyan Leila, 2020, Journal of Research Development in Nursing and Midwifery, V17, P52, DOI 10.29252/jgbfnm.17.1.52
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x
   Mostafa M.M., 2020, J INT COMMUNICATION, V26, P211, DOI 10.1080/13216597.2020.1795702
   Mostafa MM, 2019, INT J MARKET RES, V61, P320, DOI 10.1177/1470785318771451
   Mostafa MM, 2018, J FOOD PROD MARK, V24, P858, DOI 10.1080/10454446.2017.1418695
   Nam H, 2017, J MARKETING, V81, P88, DOI 10.1509/jm.16.0044
   Robu V, 2009, ACM T WEB, V3, DOI 10.1145/1594173.1594176
   Salleh S, 2015, E REV TOURISM RES ER
   Saunders S, 2012, INT J PHARM HEALTHC, V6, P55, DOI 10.1108/17506121211216905
   Secinaro S, 2021, BRIT FOOD J, V123, P225, DOI 10.1108/BFJ-03-2020-0234
   Silva M., 2019, Journal of Relationship Marketing, V19, P1, DOI [10.1080/15332667.2019.1664872, DOI 10.1080/15332667.2019.1664872]
   Sudira H, 2019, 2019 4TH INTERNATIONAL WORKSHOP ON BIG DATA AND INFORMATION SECURITY (IWBIS 2019), P21, DOI 10.1109/iwbis.2019.8935700
   Susarla A, 2016, J MANAGE INFORM SYST, V33, P139, DOI 10.1080/07421222.2016.1172454
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Wedel M, 2016, J MARKETING, V80, P97, DOI 10.1509/jm.15.0413
   Wu Y, 2014, INT J INTERCULT REL, V39, P1, DOI 10.1016/j.ijintrel.2013.08.008
   Xiong J, 2020, ASIA PAC J TOUR RES, V25, P189, DOI 10.1080/10941665.2019.1687535
   Ye Z, 2018, J HOSP MARKET MANAG, V27, P386, DOI 10.1080/19368623.2018.1382415
   Zhan M, 2018, PROCEEDINGS OF 2018 THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ARTIFICIAL INTELLIGENCE (CSAI 2018) / 2018 THE 10TH INTERNATIONAL CONFERENCE ON INFORMATION AND MULTIMEDIA TECHNOLOGY (ICIMT 2018), P33, DOI 10.1145/3297156.3297270
   Zhu ZG, 2015, COMPUT HUM BEHAV, V52, P184, DOI 10.1016/j.chb.2015.04.072
   Zulli D, 2018, CRIT STUD MEDIA COMM, V35, P137, DOI 10.1080/15295036.2017.1394582
NR 51
TC 1
Z9 1
U1 5
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10867
EP 10886
DI 10.1007/s11042-022-13685-3
EA SEP 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000849153800001
DA 2024-07-18
ER

PT J
AU Agilandeeswari, L
   Meena, SD
AF Agilandeeswari, L.
   Meena, S. Divya
TI SWIN transformer based contrastive self-supervised learning for animal
   detection and classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Swin transformer; Contrastive self-supervised
   learning; Clustering; And mutual information
AB The subdomain of computer vision applications is Image Classification which helps in categorizing the images. The advent of handheld devices and image sensors leads to the availability of a huge amount of data without labels. Hence, to categorize these images, a supervised learning algorithm won't be suitable as it requires labels. On the other hand, unsupervised learning uses clustering that also not useful as its accuracy is not reliable as the data are not labeled in advance. Self-Supervised Learning techniques can be used to overcome this problem. In this work, we present a novel Swin Transformer based Contrastive Self-Supervised Learning (Swin-TCSSL), where the paired sample is formed using the transformation of the given input image and this paired sample is passed to the Swin-T transformer which produces a feature vector. The maximum Mutual Information of these feature vectors is used to form robust clusters and these cluster labels get propagates to the Swin Transformer block until the appropriate clusters are obtained. It is then followed by contrastive learning and finally produces the classified output. The experimental results prove that the proposed system is invariant to occlusion, viewpoint variation, and illumination effects. The proposed Swin-TSSCL achieves state-of-the-art results in 5 benchmark datasets namely CIFAR-10, Snapshot Serengeti, Stanford dogs, Animals with attributes, and ImageNet dataset. As evident from the rigorous experiments, the proposed Swin-TCSSL has set a new global state-of-the-art with an average accuracy of 97.63%, which is comparatively higher than the state-of-the-art systems.
C1 [Agilandeeswari, L.] VIT, Sch Informat Technol & Engn, Vellore, TN, India.
   [Meena, S. Divya] VIT, Sch Comp Sci & Engn, Amaravathi, Andhra Pradesh, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; VIT-AP University
RP Agilandeeswari, L (corresponding author), VIT, Sch Informat Technol & Engn, Vellore, TN, India.
EM agila.1@vit.ac.in
RI L, Agilandeeswari/P-8997-2016
OI L, Agilandeeswari/0000-0001-6147-9535
CR Al-Halah Z, 2015, IEEE WINT CONF APPL, P837, DOI 10.1109/WACV.2015.116
   Bau D., 2019, ARXIV
   BECKER S, 1992, NATURE, V355, P161, DOI 10.1038/355161a0
   Caron M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9630, DOI 10.1109/ICCV48922.2021.00951
   Chapelle O., 2006, SEMISUPERVISED LEARN
   Chen T, 2020, PR MACH LEARN RES, V119
   Chen XL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9620, DOI 10.1109/ICCV48922.2021.00950
   Dhillon IS, 2003, P 9 ACM SIGKDD INT C, P89, DOI DOI 10.1145/956750.956764
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Dosovitskiy A, 2014, ADV NEUR IN, V27
   Fanti C, 2004, ADV NEUR IN, V16, P1603
   Friedman N., 2013, arXiv
   Goyal P, 2019, IEEE I CONF COMP VIS, P6400, DOI 10.1109/ICCV.2019.00649
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2020, C COMP VIS PATT REC, P2, DOI [DOI 10.1109/CVPR42600.2020.00975, 10.1109/CVPR42600.2020.00975]
   Hjelm R. D., 2018, ARXIV
   Hu W., 2017, ARXIV
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ji X, 2019, IEEE I CONF COMP VIS, P9864, DOI 10.1109/ICCV.2019.00996
   Jing LL, 2021, IEEE T PATTERN ANAL, V43, P4037, DOI 10.1109/TPAMI.2020.2992393
   Khosla A., 2011, P CVPR WORKSHOP FINE, V2, P1
   Li C, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2106.09785
   Li J, 2020, ARXIV
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu X, 2021, IEEE Transactions on Knowledge & Data Engineering
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Long MS, 2014, IEEE T KNOWL DATA EN, V26, P1805, DOI 10.1109/TKDE.2013.97
   Meena D, 2020, INT J FUZZY SYST, V22, P1868, DOI 10.1007/s40815-020-00907-9
   Meena SD, 2020, ENVIRON SCI POLLUT R, V27, P39619, DOI 10.1007/s11356-020-09950-3
   Meena SD, 2020, ADV INTELL SYST COMP, V1057, P513, DOI 10.1007/978-981-15-0184-5_44
   Meena SD, 2019, IEEE ACCESS, V7, P151783, DOI 10.1109/ACCESS.2019.2947717
   Meena SD, ADABOOST CASCADE CLA
   Misra I, 2020, PROC CVPR IEEE, P6706, DOI 10.1109/CVPR42600.2020.00674
   Mohanrajan SN, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12136387
   MohanRajan SN, 2021, J INDIAN SOC REMOTE, V49, P913, DOI 10.1007/s12524-020-01258-6
   Navin MS, 2020, MULTIMED TOOLS APPL, V79, P29751, DOI 10.1007/s11042-020-09531-z
   Prabukumar M, 2018, J AMBIENT INTELL HUM
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Selvaraju R.R., 2016, arXiv
   Sohn Kihyuk, 2020, Advances in Neural Information Processing Systems, P596, DOI DOI 10.48550/ARXIV.2001.07685
   Sundaram DM, 2020, J APPL REMOTE SENS, V14, DOI 10.1117/1.JRS.14.026521
   Sundaram DM, 2020, NEURAL PROCESS LETT, V52, P727, DOI 10.1007/s11063-020-10246-3
   Swanson A, 2015, SCI DATA, V2, DOI 10.1038/sdata.2015.26
   Tian Y., 2019, ARXIV
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   VanGansbeke W., 2020, ARXIV
   Vaswani A, 2017, ADV NEUR IN, V30
   Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393
   Xie JY, 2016, PR MACH LEARN RES, V48
   Zhong H, 2020, ARXIV
   Zou W., 2012, ADV NEURAL INFORM PR, V25, P3203, DOI DOI 10.5555/2999325.2999492
NR 52
TC 11
Z9 11
U1 8
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10445
EP 10470
DI 10.1007/s11042-022-13629-x
EA SEP 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000849298700001
DA 2024-07-18
ER

PT J
AU Xu, QZ
   Liu, S
   Qiao, H
   Li, M
AF Xu, Qingzhen
   Liu, Shuang
   Qiao, Han
   Li, Miao
TI Cross-modal retrieval with dual optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-modal retrieval; Modality gap; Inter-modal optimization;
   Intra-modal optimization
ID REPRESENTATION
AB For the flexible retrieval of data in different modalities, cross-modal retrieval has gradually attracted the attention of researchers. However, there is a heterogeneity gap between the data of different modalities, which cannot be measured directly. To solve this problem, researchers project data of different modalities into a common representation space to compensate for the heterogeneity of data of different modalities. However, existing methods with pair or triple constraints ignore the rich information between samples, which leads to the degradation of retrieval performance. In order to fully mine the information of samples, this paper proposes a cross-modal retrieval method (CMRDO) with dual optimization. First, the method optimizes the common representation space from inter-modal and intra-modal, respectively. Secondly, we introduce an efficient sample construction strategy to avoid sample pairs with less information. Finally, the bi-directional retrieval strategy we introduced can effectively capture the potential structure of query modal. In the three public datasets, the proposed CMRDO can effectively improve the final cross-modal retrieval accuracy, and has strong generalization ability.
C1 [Xu, Qingzhen; Liu, Shuang; Qiao, Han; Li, Miao] South China Normal Univ, Sch Comp Sci, Guangzhou, Peoples R China.
C3 South China Normal University
RP Xu, QZ (corresponding author), South China Normal Univ, Sch Comp Sci, Guangzhou, Peoples R China.
EM xqz1997@126.com
OI Xu, Qingzhen/0000-0001-6687-8367
CR Bellet A., 2013, CoRR
   Cao Y, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P197, DOI 10.1145/2911996.2912000
   Chao Wang, 2021, Personal and Ubiquitous Computing, V25, P485, DOI 10.1007/s00779-019-01247-8
   Chua Tat-Seng., 2009, P 8 ACM INT C IMAGE
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Huang X, 2020, IEEE T CYBERNETICS, V50, P1047, DOI 10.1109/TCYB.2018.2879846
   Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348
   Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740
   Kan MN, 2012, LECT NOTES COMPUT SC, V7572, P808, DOI 10.1007/978-3-642-33718-5_58
   Kang CC, 2015, IEEE T MULTIMEDIA, V17, P370, DOI 10.1109/TMM.2015.2390499
   Li D., 2003, P 11 ACM INT C MULTI, P604
   Liong VE, 2017, IEEE T MULTIMEDIA, V19, P1234, DOI 10.1109/TMM.2016.2646180
   Peng Y, 2016, P INT JOINT C ART IN, P3846
   Peng YX, 2018, IEEE T MULTIMEDIA, V20, P405, DOI 10.1109/TMM.2017.2742704
   Ranjan V, 2015, IEEE I CONF COMP VIS, P4094, DOI 10.1109/ICCV.2015.466
   Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.5555/1866696.1866717
   Sohn K, 2016, ADV NEUR IN, V29
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Sun C, 2019, PHYSICA A, V532, DOI 10.1016/j.physa.2019.121812
   Unar S, 2019, IET IMAGE PROCESS, V13, P1191, DOI 10.1049/iet-ipr.2019.0098
   Unar S, 2019, IET IMAGE PROCESS, V13, P515, DOI 10.1049/iet-ipr.2018.5277
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang, 2016, 4 INT C LEARNING REP
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang C, 2019, CLUSTER COMPUT, V22, P13337, DOI 10.1007/s10586-018-1904-x
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang K, 2016, CORR, V6215
   Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311
   Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261
   Wang W, 2016, VLDB J, V25, P79, DOI 10.1007/s00778-015-0391-4
   Wang XY, 2014, PATTERN RECOGN, V47, P3293, DOI 10.1016/j.patcog.2014.04.020
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Wang XS, 2019, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR.2019.00535
   Wei Y, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P791, DOI 10.1145/2623330.2623688
   Wei YC, 2017, IEEE T CYBERNETICS, V47, P449, DOI 10.1109/TCYB.2016.2519449
   Wu F., 2013, P ACM INT C MULT, P877
   Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966
   Yang ZG, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3374754
   Ye M, 2020, IEEE T INF FOREN SEC, V15, P407, DOI 10.1109/TIFS.2019.2921454
   Yuan YH, 2017, IEEE I CONF COMP VIS, P814, DOI 10.1109/ICCV.2017.94
   Zhai XH, 2014, IEEE T CIRC SYST VID, V24, P965, DOI 10.1109/TCSVT.2013.2276704
   Zhang J, 2020, IEEE T CYBERNETICS, V50, P489, DOI 10.1109/TCYB.2018.2868826
   Zhang L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1355, DOI 10.1145/2964284.2964336
   Zhen LL, 2019, PROC CVPR IEEE, P10386, DOI 10.1109/CVPR.2019.01064
NR 46
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7141
EP 7157
DI 10.1007/s11042-022-13650-0
EA AUG 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000841079100001
DA 2024-07-18
ER

PT J
AU Khan, LS
   Khan, M
   Hazzazi, MM
   Jamal, SS
AF Khan, Lal Said
   Khan, Majid
   Hazzazi, Mohammad Mazyad
   Jamal, Sajjad Shaukat
TI A novel combination of information confidentiality and data hiding
   mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information hiding; Encrypted secret information; Chaotic map
ID CHAOTIC SYSTEM; ENCRYPTION; SCHEME; MAP; STEGANOGRAPHY
AB Due to the widespread accessibility of the Internet, communicating and sharing multimedia content between people is extremely easy today. At the same time, however, a critical issue is the secure transfer of personal and protected material. In this article, we have proposed a new information security mechanism. The proposed system comprises two phases. In the first phase, the digital data is encrypted and in the second phase, the encrypted data is embedded into the cover data. The encryption scheme consists of both diffusion and confusion. For diffusion, we have utilized a logistic chaotic map-based novel diffusion. For confusion pre-defined highly nonlinear S-boxes are used. This mechanism provides dual layers of security to the confidential information, which makes it difficult for the intruder to extract the confidential information. The security analysis of the encryption and data hiding schemes are carried out and tabulated. For implementation on hardware the time analysis is carried out, and the time for encryption and data hiding comes out to be 1.662 seconds, which is reasonable for real-time implementation. The security analysis of encryption and data hiding shows the immunity of the proposed system to withstand different attacks.
C1 [Khan, Lal Said] Inst Space Technol, Dept Av Engn, Islamabad, Pakistan.
   [Khan, Lal Said] Inst Space Technol, Dept Elect Engn, Islamabad, Pakistan.
   [Khan, Majid] Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
   [Hazzazi, Mohammad Mazyad; Jamal, Sajjad Shaukat] King Khalid Univ, Coll Sci, Dept Math, Abha 61413, Saudi Arabia.
C3 King Khalid University
RP Khan, LS (corresponding author), Inst Space Technol, Dept Av Engn, Islamabad, Pakistan.; Khan, LS (corresponding author), Inst Space Technol, Dept Elect Engn, Islamabad, Pakistan.
EM engrlalsaid@yahoo.com
RI Hazzazi, Mohammad Mazyad/ABB-4202-2021; Jamal, Sajjad/AHE-6498-2022;
   Khan, Majid/T-9408-2019
OI Hazzazi, Mohammad Mazyad/0000-0002-7945-9994; Khan,
   Majid/0000-0001-5454-3770; , LALSAID/0000-0002-5325-6443
FU Deanship of Scientific Research at King Khalid University [R. G. P.
   2/109/43]
FX Dr. Sajjad Shaukat Jamal extends his gratitude to the Deanship of
   Scientific Research at King Khalid University for funding this work
   through the research groups program under grant number R. G. P.
   2/109/43.
CR Abd El-Latif AA, 2020, PHYSICA A, V541, DOI 10.1016/j.physa.2019.123687
   Alanazi N, 2021, MULTIMED TOOLS APPL, V80, P1403, DOI 10.1007/s11042-020-09667-y
   Alghafis A, 2020, MATH COMPUT SIMULAT, V177, P441, DOI 10.1016/j.matcom.2020.05.016
   Alghafis A, 2020, WIREL NETW, DOI 10.1007/s11276-020-02363-7
   Alghafis A, 2020, PHYSICA A, V554, DOI 10.1016/j.physa.2019.123908
   Alghafis A, 2020, INT J THEOR PHYS, V59, P1227, DOI 10.1007/s10773-020-04402-7
   Ali KM, 2019, MULTIMED TOOLS APPL, V78, P32585, DOI 10.1007/s11042-019-07866-w
   Arshad U, 2020, PHYSICA A, V546, DOI 10.1016/j.physa.2019.123458
   Attaullah, 2020, WIRELESS PERS COMMUN, V110, P1429, DOI 10.1007/s11277-019-06793-1
   Batool S, 2014, NEURAL COMPUT APPL, V25, P2037, DOI 10.1007/s00521-014-1691-0
   Gu ZQ, 2022, IEEE T GREEN COMMUN, V6, P89, DOI 10.1109/TGCN.2021.3095707
   He Y, 2020, NEURAL COMPUT APPL, V32, P247, DOI 10.1007/s00521-018-3577-z
   Hussain I, 2014, Z NATURFORSCH A, V69, P249, DOI 10.5560/ZNA.2014-0016
   Jamal SS, 2019, CHINESE J PHYS, V61, P301, DOI 10.1016/j.cjph.2019.09.006
   Jamal SS, 2019, WIREL NETW, V25, P1491, DOI 10.1007/s11276-017-1606-y
   Jamal SS, 2016, WIRELESS PERS COMMUN, V90, P2033, DOI 10.1007/s11277-016-3436-0
   Jamal SS, 2013, NONLINEAR DYNAM, V73, P1469, DOI 10.1007/s11071-013-0877-9
   Khan LS, 2021, CHINESE J PHYS, V72, P558, DOI 10.1016/j.cjph.2021.03.029
   Khan LS, 2018, EAI ENDORSED T SCALA, V5, pe13
   Khan M, 2021, COMPLEX INTELL SYST, V7, P2751, DOI 10.1007/s40747-021-00460-4
   Khan M, 2020, NEURAL COMPUT APPL, V32, P11837, DOI 10.1007/s00521-019-04667-y
   Khan M, 2020, MULTIMED TOOLS APPL, V79, P30983, DOI 10.1007/s11042-020-09610-1
   Khan M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0225031
   Li Q, 2020, IEEE ACCESS, V8, P168166, DOI 10.1109/ACCESS.2020.3021103
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Marvel LM, 1999, IEEE T IMAGE PROCESS, V8, P1075, DOI 10.1109/83.777088
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Mukherjee Srilekha, 2018, Procedia Computer Science, V132, P461, DOI 10.1016/j.procs.2018.05.160
   Munir N, 2020, WIREL NETW, DOI 10.1007/s11276-020-02361-9
   Norouzi B, 2017, MULTIMED TOOLS APPL, V76, P13681, DOI 10.1007/s11042-016-3769-4
   Sheela S, 2016, ACCENTS T INFORM SEC, V2, P1, DOI [10.19101/tis.2017.25001, DOI 10.19101/TIS.2017.25001]
   Song W, 2011, J CENT SOUTH UNIV T, V18, P116, DOI 10.1007/s11771-011-0668-8
   Taburet T, 2021, IEEE T INF FOREN SEC, V16, P173, DOI 10.1109/TIFS.2020.3007354
   Tariq S, 2020, MULTIMED TOOLS APPL, V79, P23507, DOI 10.1007/s11042-020-09134-8
   Tsafack N, 2020, IEEE ACCESS, V8, P137731, DOI 10.1109/ACCESS.2020.3010794
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Waqas UA, 2020, MULTIMED TOOLS APPL, V79, P6891, DOI 10.1007/s11042-019-08570-5
   Waseem HM, 2019, APPL PHYS B-LASERS O, V125, DOI 10.1007/s00340-019-7142-y
NR 38
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6917
EP 6941
DI 10.1007/s11042-022-13623-3
EA AUG 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000839516900002
DA 2024-07-18
ER

PT J
AU Zhang, JL
   Shi, JX
   Li, MY
   Guo, MT
   Pan, ZG
AF Zhang, Jiulong
   Shi, Jiaxi
   Li, Mengyang
   Guo, Mingtao
   Pan, Zhigeng
TI Triple discriminators-equipped GAN for Denoising of Chinese calligraphic
   tablet images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chinese calligraphy; Generative adversarial network; Image denoising;
   CycleGAN; Deep learning
ID SPARSE
AB Denoising of Chinese calligraphic tablet images is of great importance in regard to the study of both content and character shapes in these images. Formerly GAN (generative adversarial network) based image denoising methods model the noise in the generator and then perform denoising by CNN (convolutional neural networks) algorithms. These methods still leave room for improvement. In this paper, a triple discriminators equipped GAN for generative denoising is proposed, with the three channels of discriminators enhancing the denoising result by different means. Another noise modeling module based on CycleGAN is used to produce the paired input data. Quantitative index are obtained for these methods; the PSNR and SSIM of our method on publicly available data is 21.84 and 0.93 respectively, which is preferable to BM3D, DnCNN, FormResNet, CycleGAN and our previous method.
C1 [Zhang, Jiulong; Shi, Jiaxi; Li, Mengyang] Xian Univ Technol, Inst Comp Sci & Engn, Xian, Peoples R China.
   [Zhang, Jiulong] Shaanxi Key Lab Network Comp & Secur Technol, Xian, Peoples R China.
   [Guo, Mingtao] Sichuan Univ, Natl Key Lab Fundamental Sci Synthet Vis, Chengdu, Peoples R China.
   [Pan, Zhigeng] Nanjing Univ Informat Sci & Technol, Nanjing, Peoples R China.
C3 Xi'an University of Technology; Sichuan University; Nanjing University
   of Information Science & Technology
RP Zhang, JL (corresponding author), Xian Univ Technol, Inst Comp Sci & Engn, Xian, Peoples R China.; Zhang, JL (corresponding author), Shaanxi Key Lab Network Comp & Secur Technol, Xian, Peoples R China.
EM zjl@xaut.edu.cn; gmt798714378@hotmail.com
FU Shaanxi Department of science and technology [2022QFY01-17, 2022JM-326]
FX This work is supported under the support of funds of Shaanxi Department
   of science and technology 2022QFY01-17, 2022JM-326. We thank Professor
   Songhua Xu for his kind discussion of the method in the paper.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2010, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2010.5539801
   Buades A, 2011, IMAGE PROCESS ON LIN, V1, P208, DOI 10.5201/ipol.2011.bcm_nlm
   Chen Y, 2018, PROC CVPR IEEE, P9465, DOI 10.1109/CVPR.2018.00986
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   El Helou M, 2020, IEEE T IMAGE PROCESS, V29, P4885, DOI 10.1109/TIP.2020.2976814
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Gan J, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107025
   Goodfellow I., 2016, arXiv
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hou B, 2020, IEEE TRANSACT GEOSCI, P1
   Huang Gao., IEEE C COMPUTER VISI
   Huang ZK, 2016, NEUROCOMPUTING, V188, P102, DOI 10.1016/j.neucom.2014.11.106
   Isola P., 2018, P IEEE C COMPUTER VI
   Jain V., 2009, ADV NEURAL INFORM PR, P769, DOI DOI 10.5555/2981780.2981876
   Jia XX, 2019, PROC CVPR IEEE, P6047, DOI 10.1109/CVPR.2019.00621
   Jiao JB, 2017, IEEE COMPUT SOC CONF, P1034, DOI 10.1109/CVPRW.2017.140
   Kingma D. P., 2014, arXiv
   Luo CJ, 2019, PATTERN RECOGN, V90, P109, DOI 10.1016/j.patcog.2019.01.020
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Mao XJ, 2016, ADV NEUR IN, V29
   My VD, INFORM SCIENCES, V570
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu Y, 2022, INFORM FUSION, V77, P62, DOI 10.1016/j.inffus.2021.07.003
   Xia Yingce, 2016, P 2016 30 C NEUR INF
   Xie Junyuan, 2012, ADV NEURAL INFORM PR, P341, DOI [DOI 10.5555/2999134.2999173, DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605]
   Zhang JL, 2020, MULTIMED TOOLS APPL, V79, P119, DOI 10.1007/s11042-019-08052-8
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 32
TC 1
Z9 1
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42691
EP 42711
DI 10.1007/s11042-022-13478-8
EA AUG 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000835601400006
DA 2024-07-18
ER

PT J
AU Jaradat, Y
   Masoud, M
   Jannoud, I
   Alia, M
   Alheyasat, O
   Jebril, I
AF Jaradat, Yousef
   Masoud, Mohammad
   Jannoud, Ismael
   Alia, Mohammad
   Alheyasat, Omar
   Jebril, Iqbal
TI Analysis of the optimal number of clusters and probability in
   homogeneous unreliable WSNs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Noisy LEACH; Network lifetime; Energy conservation; Noisy WSN;
   Clustering algorithms
ID WIRELESS SENSOR NETWORKS; PROTOCOL; PERFORMANCE
AB In this paper, we propose a simple simulation model for analyzing and evaluating the low energy adaptive clustering hierarchy (LEACH) protocol's performance in a noisy realistic wireless environment. A general parameter called probability of reception (p(r)) describes the noise level in this model. The success or failure of packet reception between sender and receiver can be used to assess the impact of network noise. The LEACH algorithm's energy model has been modified to include the noise factor (p(r)). Based on the new modified energy model, new analytical formulas for the optimal number of clusters and the optimal probability of a node becoming a cluster head are derived. Furthermore, we investigate what network dimensions are required to achieve the optimal number of clusters in a noisy environment, as this will increase the network's lifetime. It is demonstrated that the optimal number of clusters, and thus the optimal probability of CHs, are shown to be achieved by two factors: short wireless links formed within the clusters and equal network layout dimensions. Noise is shown to have a significant negative impact on the LEACH protocol's operation, particularly on network life time, throughput, and the protocol's stability and instability periods.
C1 [Jaradat, Yousef; Masoud, Mohammad; Jannoud, Ismael] Al Zaytoonah Univ Jordan, Commun & Comp Engn Dept, Amman, Jordan.
   [Alia, Mohammad] Al Zaytoonah Univ Jordan, Comp Informat Syst Dept, Amman, Jordan.
   [Alheyasat, Omar] AlBalqa Appl Univ, Comp Engn Dept, Salt, Jordan.
   [Jebril, Iqbal] Al Zaytoonah Univ Jordan, Math Dept, Amman, Jordan.
C3 Al-Zaytoonah University of Jordan; Al-Zaytoonah University of Jordan;
   Al-Balqa Applied University; Al-Zaytoonah University of Jordan
RP Jaradat, Y (corresponding author), Al Zaytoonah Univ Jordan, Commun & Comp Engn Dept, Amman, Jordan.
EM y.jaradat@zuj.edu.jo
RI Alheyasat, Omar/I-2449-2017
OI Jebril, Iqbal H/0000-0003-4348-6197; Jaradat, Yousef/0000-0003-0038-3251
FU Al-Zaytoonah University of Jordan fund [15/12/2019-2020]
FX This research was supported by Al-Zaytoonah University of Jordan fund.
   Project number 15/12/2019-2020.
CR Al-Bahadili H, 2010, ARXIV
   Barani H, 2018, IET COMMUN, V12, P941, DOI 10.1049/iet-com.2017.1040
   Bhattacharyya D, 2010, SENSORS-BASEL, V10, P10506, DOI 10.3390/s101210506
   Buratti C., 2005, EURASIP Journal on Wireless Communications and Networking, V2005, P672, DOI 10.1155/WCN.2005.672
   Cheffena M, 2012, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2012-297
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Depedri A., 2003, Proceedings of Autonomous Intelligent Networks and Systems (AINS), P1
   Elbes M, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.3867
   Handy MJ, 2002, 2002 4TH INTERNATIONAL WORKSHOP ON MOBILE AND WIRELESS COMMUNICATION NETWORK, P368, DOI 10.1109/MWCN.2002.1045790
   Heiniger R. W., 2000, Proceedings of the 5th International Conference on Precision Agriculture, Bloomington, Minnesota, USA, 16-19 July, 2000, P1
   Heinzelman WB, 2002, IEEE T WIREL COMMUN, V1, P660, DOI 10.1109/TWC.2002.804190
   Hoad K, 2010, J OPER RES SOC, V61, P1632, DOI 10.1057/jors.2009.121
   Jaradat Y, 2021, WIREL NETW, V27, P1821, DOI 10.1007/s11276-020-02527-5
   Jaradat Y, 2020, INT J SENS NETW, V33, P202, DOI 10.1504/IJSNET.2020.109187
   Jaradat Y, 2019, I C SCI TECH AUTO CO, P590, DOI [10.1109/STA.2019.8717254, 10.1109/sta.2019.8717254]
   Jaradat Y, 2019, IEEE SENS J, V19, P2378, DOI 10.1109/JSEN.2018.2885927
   Kandris D, 2020, APPL SYST INNOV, V3, DOI 10.3390/asi3010014
   Kiyang ST, 2014, J ENG DES TECHNOL, V12, P29, DOI 10.1108/JEDT-02-2012-0006
   Liaqat M, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161340
   Masoud M, 2019, J SENSORS, V2019, DOI 10.1155/2019/6514520
   Oliveira LB, 2006, NCA 2006: FIFTH IEEE INTERNATIONAL SYMPOSIUM ON NETWORK COMPUTING AND APPLICATIONS, PROCEEDINGS, P145
   Shafiq, 2020, MOB NETW APPL, V3, P25
   Singh SK, 2017, IEEE ACCESS, V5, P4298, DOI 10.1109/ACCESS.2017.2666082
   Voigt T, 2004, IEEE SYMP COMP COMMU, P238
   Wang Y, 2012, INT J COMMUN SYST, V25, P1139, DOI 10.1002/dac.2355
   Xu DW, 2011, PROCEDIA ENVIRON SCI, V10, P595, DOI 10.1016/j.proenv.2011.09.096
   Yang Lei, 2008, 2008 First International Conference on Intelligent Networks and Intelligent Systems (ICINIS), P147, DOI 10.1109/ICINIS.2008.69
NR 27
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39633
EP 39652
DI 10.1007/s11042-022-13510-x
EA AUG 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000836366300004
DA 2024-07-18
ER

PT J
AU Song, XF
   Yang, CF
   Han, K
   Ding, SC
AF Song, Xiaofeng
   Yang, Chunfang
   Han, Kun
   Ding, Shichang
TI Robust JPEG steganography based on DCT and SVD in nonsubsampled shearlet
   transform domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE JPEG steganography; Robustness; Anti-detection capability; Shearlet DCT;
   SVD
ID IMAGE WATERMARKING; MODULATION; DETECTOR
AB Social media platform such as WeChat provides rich cover images for covert communication by steganography. However, in order to save band-width, storage space and make images load faster, the images often will be compressed, which makes the image steganography algorithms designed for lossless network channels unusable. Based on DCT and SVD in nonsubsampled shearlet transform domain, a robust JPEG steganography algorithm is proposed, which can resist image compression and correctly extract the embedded secret message from the compressed stego image. First, by combining the advantages of nonsubsampled shearlet transform, DCT and SVD, the construction method for robust embedding domain is proposed. Then, based on minimal distortion principle, the framework of the proposed robust JPEG steganography algorithm is given and the key steps are described in details. The experimental results show that the proposed JPEG steganography algorithm can achieve competitive robustness and anti-detection capability in contrast to the state-of-the-art robust steganography algorithms. Moreover, it can extract the secret message correctly even if the stego image is compressed by WeChat.
C1 [Song, Xiaofeng; Han, Kun] Natl Univ Def Technol, Xian 710106, Peoples R China.
   [Yang, Chunfang; Ding, Shichang] Zhengzhou Sci & Technol Inst, Zhengzhou 450001, Peoples R China.
   [Ding, Shichang] Univ Gottingen, Gottingen, Germany.
C3 National University of Defense Technology - China; PLA Information
   Engineering University; University of Gottingen
RP Song, XF (corresponding author), Natl Univ Def Technol, Xian 710106, Peoples R China.
EM xiaofengsong@sina.com
FU National Natural Science Foundation of China [61872448, U1804263];
   Natural Science Basic Research Plan in Shanxi Province of China
   [2021JQ-379]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61872448, U1804263) and the Natural Science Basic Research
   Plan in Shanxi Province of China (No. 2021JQ-379).
CR Bao P, 2005, IEEE T CIRC SYST VID, V15, P96, DOI 10.1109/TCSVT.2004.836745
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen XY, 2022, IEEE T NETW SCI ENG, V9, P219, DOI 10.1109/TNSE.2020.3041529
   Das R, 2019, COMPUT SYST SCI ENG, V34, P23
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Guo LJ, 2014, IEEE T INF FOREN SEC, V9, P814, DOI 10.1109/TIFS.2014.2312817
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Kang XB, 2018, MULTIMED TOOLS APPL, V77, P13197, DOI 10.1007/s11042-017-4941-1
   Ker A.D., 2013, P 1 ACM WORKSH INF H, P4558, DOI DOI 10.1145/2482513.2482965
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Luo YJ, 2021, IEEE T CIRC SYST VID, V31, P2779, DOI 10.1109/TCSVT.2020.3033945
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P635, DOI 10.1109/TIFS.2008.2002936
   Qian ZX, 2017, SMART INNOV SYST TEC, V63, P25, DOI 10.1007/978-3-319-50209-0_4
   Tao JY, 2019, IEEE T CIRC SYST VID, V29, P594, DOI 10.1109/TCSVT.2018.2881118
   Tian C, 2020, MULTIMED TOOLS APPL, V79, P7515, DOI 10.1007/s11042-019-08530-z
   Wang XY, 2016, INFORM SCIENCES, V372, P634, DOI 10.1016/j.ins.2016.08.076
   Xiang LY, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8091558
   Yang ZL, 2021, IEEE T INF FOREN SEC, V16, P880, DOI 10.1109/TIFS.2020.3023279
   Yi S, 2009, IEEE T IMAGE PROCESS, V18, P929, DOI 10.1109/TIP.2009.2013082
   Yu XZ, 2020, SIGNAL PROCESS, V168, DOI 10.1016/j.sigpro.2019.107343
   Zhang Y, 2020, IEEE T CIRC SYST VID, V30, P2750, DOI 10.1109/TCSVT.2019.2923980
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P17913, DOI 10.1007/s11042-017-4506-3
   Zhang Y, 2015, PROCEEDINGS 10TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY ARES 2015, P461, DOI 10.1109/ARES.2015.53
   Zhao ZZ, 2019, IEEE T INF FOREN SEC, V14, P1843, DOI 10.1109/TIFS.2018.2885438
NR 27
TC 4
Z9 4
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36453
EP 36472
DI 10.1007/s11042-022-13525-4
EA AUG 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000836366300002
DA 2024-07-18
ER

PT J
AU Lang, J
   Ma, CL
AF Lang, Jun
   Ma, Chunlei
TI Novel zero-watermarking method using the compressed sensing significant
   feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Zero-watermark; Compressed sensing; Scrambled block Hadamard ensemble;
   Robustness; Confidentiality
ID FRACTIONAL FOURIER-TRANSFORM
AB In this paper, we proposed a novel zero- watermarking method using the compressed sensing (CS) significant feature. The original image is segmented into non-overlapping blocks and then constructs a scrambled block Hadamard ensemble (SBHE) matrix as a sensing matrix to sense every block. CS significant feature can be represented by the sum of each block's measurements. Then each pixel value of the binary zero-watermark is embedded by modifying the CS significant features. At last zero-watermark is registered, and the sensing matrix is stored as extra key. With the CS significant feature, the robustness of the zero-watermarking algorithm can be greatly improved. SBHE matrix can reduce the computational complexity of the compressed sensing and also reduce storage costs. In addition, because of the randomness of SBHE matrix, the proposed zero-watermarking method can provide excellent confidentiality. Moreover, our algorithm is different from the traditional zero-watermarking methods with pure meaningless image features, copyright holders can be legally recognized by the identity's image which is embedded into the zero-watermark, so the authentication process of the zero-watermark is more intuitive and convenient.
C1 [Lang, Jun; Ma, Chunlei] Northeastern Univ, Coll Comp Sci & Engn, Shenyang 110819, Liaoning, Peoples R China.
C3 Northeastern University - China
RP Lang, J (corresponding author), Northeastern Univ, Coll Comp Sci & Engn, Shenyang 110819, Liaoning, Peoples R China.
EM langjun@mail.neu.edu.cn
FU "985 Project" of Northeastern University [985-3-DC-F24]; National
   Natural Science Foundation of China [61202446]; Fundamental Research
   Funds for the Central Universities [N150404004]
FX The authors would like to thank the anonymous reviewers for their great
   efforts and valuable comments that are greatly helpful to improve the
   clarity and quality of this manuscript. Special thanks are also due to
   the instrumental and data analysis from Analytical and Testing Center,
   Northeastern University. This work was supported by "985 Project" of
   Northeastern University (No. 985-3-DC-F24), National Natural Science
   Foundation of China (No. 61202446), and Fundamental Research Funds for
   the Central Universities (N150404004).
CR Chao JIA., 2013, COMPUT TECHNOL DEV, V4, P144
   Chen H, 2012, 2012 INTERNATIONAL CONFERENCE ON INDUSTRIAL CONTROL AND ELECTRONICS ENGINEERING (ICICEE), P490, DOI 10.1109/ICICEE.2012.136
   Davenport M., 2013, FUNDAMENTALS COMPRES, V12
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Gan HP, 2018, SIGNAL PROCESS-IMAGE, V68, P129, DOI 10.1016/j.image.2018.06.004
   Gan L., 2008, P EUR SIGN PROC C LA
   Hao S., 2014, J INFORM COMPUT SCI, V11, P2505, DOI [10.12733/jics20103699, DOI 10.12733/JICS20103699]
   Hu CJ, 2009, 2009 INTERNATIONAL FORUM ON INFORMATION TECHNOLOGY AND APPLICATIONS, VOL 3, PROCEEDINGS, P193, DOI 10.1109/IFITA.2009.40
   Jing L, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2118
   Lang J, 2014, OPT LASER ENG, V53, P112, DOI 10.1016/j.optlaseng.2013.08.021
   Li Fan, 2010, Wuhan University Journal of Natural Sciences, V15, P408, DOI 10.1007/s11859-010-0675-x
   Jing L, 2007, ELE COM ENG, P39
   Li Zhang, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P1016, DOI 10.1109/CISP.2011.6100325
   Liu C., 2019, J LIAONING U ENG TEC, V38, P372
   Liu Jingjie, 2012, Computer Engineering and Applications, V48, P90, DOI 10.3778/j.issn.1002-8331.2012.16.020
   Mengyue Hu, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P1035, DOI 10.1109/CISP.2011.6100270
   Orsdemir A, 2008, IEEE MILIT COMMUN C, P1040
   Rachlin Y, 2008, ANN ALLERTON CONF, P813, DOI 10.1109/ALLERTON.2008.4797641
   Rahmani Hossein, 2010, Proceedings of the 2010 6th International Conference on Digital Content, Multimedia Technology and its Applications (IDC 2010), P28
   Ramezanpour Mahnaz, 2014, Cytotechnology, V66, P845, DOI 10.1007/s10616-013-9636-5
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   Sang J, 2006, OPT ENG, V45, DOI 10.1117/1.2354076
   Shen ZL, 2017, INT C WAVEL ANAL PAT, P78, DOI 10.1109/ICWAPR.2017.8076667
   Wen Quan, 2003, Acta Electronica Sinica, V31, P214
   Yang KY, 2018, PROCEEDINGS OF 2018 IEEE 3RD ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC 2018), P236, DOI 10.1109/IAEAC.2018.8577943
   Ye Tian-yu, 2010, Journal of Beijing University of Posts and Telecommunications, V33, P126
   Yu NY, 2017, EURASIP J ADV SIG PR, DOI 10.1186/s13634-017-0508-6
   [赵春晖 Zhao Chunhui], 2012, [电子学报, Acta Electronica Sinica], V40, P681
NR 28
TC 6
Z9 6
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4551
EP 4567
DI 10.1007/s11042-022-13601-9
EA JUL 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000832844000005
DA 2024-07-18
ER

PT J
AU Upadhyay, R
   Pasi, G
   Viviani, M
AF Upadhyay, Rishabh
   Pasi, Gabriella
   Viviani, Marco
TI Vec4Cred: a model for health misinformation detection in web pages
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Health misinformation; Consumer health; Natural language processing;
   Machine learning; Deep learning
ID INFORMATION; QUALITY; CREDIBILITY; LITERACY; FEATURES; INTERNET
AB Research aimed at finding solutions to the problem of the diffusion of distinct forms of non-genuine information online across multiple domains has attracted growing interest in recent years, from opinion spam to fake news detection. Currently, partly due to the COVID-19 virus outbreak and the subsequent proliferation of unfounded claims and highly biased content, attention has focused on developing solutions that can automatically assess the genuineness of health information. Most of these approaches, applied both to Web pages and social media content, rely primarily on the use of handcrafted features in conjunction with Machine Learning. In this article, instead, we propose a health misinformation detection model that exploits as features the embedded representations of some structural and content characteristics of Web pages, which are obtained using an embedding model pre-trained on medical data. Such features are employed within a deep learning classification model, which categorizes genuine health information versus health misinformation. The purpose of this article is therefore to evaluate the effectiveness of the proposed model, namely Vec4Cred, with respect to the problem considered. This model represents an evolution of a previous one, with respect to which new features and architectural choices have been considered and illustrated in this work.
C1 [Upadhyay, Rishabh; Pasi, Gabriella; Viviani, Marco] Univ Milano Bicocca, Dept Informat Syst & Commun, Edificio U14 ABACUS,Viale Sarca, I-20126 Milan, Italy.
C3 University of Milano-Bicocca
RP Upadhyay, R; Viviani, M (corresponding author), Univ Milano Bicocca, Dept Informat Syst & Commun, Edificio U14 ABACUS,Viale Sarca, I-20126 Milan, Italy.
EM r.upadhyay@campus.unimib.it; gabriella.pasi@unimib.it;
   marco.viviani@unimib.it
RI Pasi, Gabriella/JNT-5582-2023; Upadhyay, Rishabh/P-1054-2016
OI Upadhyay, Rishabh/0000-0001-9937-6494; Viviani,
   Marco/0000-0002-2274-9050
FU Universita degli Studi di Milano - Bicocca within the CRUICARE
   Agreement; European Union [860721]; Marie Curie Actions (MSCA) [860721]
   Funding Source: Marie Curie Actions (MSCA)
FX Open access funding provided by Universita degli Studi di Milano -
   Bicocca within the CRUICARE Agreement.; This research work is part of
   the DoSSIER Project: "Domain Specific Systems for Information Extraction
   and Retrieval", which has received funding from the European Union's
   Horizon 2020 Research and Innovation Programme under the Marie
   Sklodowska-Curie Grant Agreement No 860721.
CR Al-Jefri MM, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON DIGITAL HEALTH (DH'17), P167, DOI 10.1145/3079452.3079470
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bal R., 2020, P INT AAAI C WEB SOC, V14, P924
   BLYTH CR, 1983, J AM STAT ASSOC, V78, P108, DOI 10.2307/2287116
   Boyer C, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.3831
   Campos R, 2020, INFORM SCIENCES, V509, P257, DOI 10.1016/j.ins.2019.09.013
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Choi W, 2015, J ASSOC INF SCI TECH, V66, P2399, DOI 10.1002/asi.23543
   Chou WYS, 2018, JAMA-J AM MED ASSOC, V320, P2417, DOI 10.1001/jama.2018.16865
   Choudhary A, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114171
   Cui LM, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P492, DOI 10.1145/3394486.3403092
   Diviani N, 2016, PATIENT EDUC COUNS, V99, P1017, DOI 10.1016/j.pec.2016.01.007
   Eysenbach G, 2007, STUD HEALTH TECHNOL, V129, P162
   Feng J, 2020, IEEE ACCESS, V8, P221214, DOI 10.1109/ACCESS.2020.3043188
   Fernandez-Pichel M, 2021, EUR C INF RETR LUCC
   Fogg B.J., 2003, PERSUASIVE TECHNOLOG, DOI [DOI 10.1016/B978-1-55860-643-2.X5000-8, 10.1016/B978-1-55860-643-2.X5000-8]
   Fogg B. J., 1999, P SIGCHI C HUM FACT, P80, DOI [DOI 10.1145/302979.303001, 10.1145/302979.303001.3]
   Girgis S, 2018, PROCEEDINGS OF 2018 13TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), P93, DOI 10.1109/ICCES.2018.8639198
   Goeuriot Lorraine, 2020, Experimental IR Meets Multilinguality, Multimodality, and Interaction. 11th International Conference of the CLEF Association, CLEF 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12260), P255, DOI 10.1007/978-3-030-58219-7_19
   Gupta A, 2014, LECT NOTES COMPUT SC, V8851, P228, DOI 10.1007/978-3-319-13734-6_16
   HIRST DE, 1994, J ACCOUNTING RES, V32, P113, DOI 10.2307/2491390
   Hong T, 2006, J AM SOC INF SCI TEC, V57, P114, DOI 10.1002/asi.20258
   Horne Benjamin, 2017, 11 INT AAAI C WEB SO, V11
   Hovland CI, 1951, PUBLIC OPIN QUART, V15, P635, DOI 10.1086/266350
   Ketkar N., 2017, Deep learning with python: a hands-on introduction, P97, DOI [DOI 10.1007/978-1-4842-2766-47, 10.1007/978-1-4842-2766-4_7, DOI 10.1007/978-1-4842-2766-4_7, 10.1007/978-1-4842-2766-47]
   Kickbusch IS, 2001, HEALTH PROMOT INT, V16, P289, DOI 10.1093/heapro/16.3.289
   Kim Y, 2016, HEALTH INFORM J, V22, P355, DOI 10.1177/1460458214559432
   Kinkead L, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01131-z
   Malhotra P., 2003, 14 AUSTR C INF SYST
   Markowitz DM, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0105937
   Marton C, 2010, J Hosp Librariansh, V10, P235, DOI [10.1080/15323269.2010.491422, DOI 10.1080/15323269.2010.491422]
   Meppelink CS, 2021, PATIENT EDUC COUNS, V104, P1460, DOI 10.1016/j.pec.2020.11.013
   Metzger MJ, 2003, COMM YEARB, V27, P293, DOI 10.1207/s15567419cy2701_10
   Mihalcea R., 2004, P 2004 C EMPIRICAL M, P404, DOI DOI 10.3115/1219044.1219064
   Norman CD, 2006, J MED INTERNET RES, V8, DOI 10.2196/jmir.8.2.e9
   Pan X, 2017, QUAL RELIAB ENG INT, V33, P1299, DOI 10.1002/qre.2111
   Pasi, 2020, ARXIV
   Patel N.A., 2018, P 2018 4 INT C COMP, P1, DOI [10.1109/CCAA.2018.8777594, DOI 10.1109/CCAA.2018.8777594]
   Payton FC, 2014, INTERNET RES, V24, P520, DOI 10.1108/IntR-09-2013-0193
   Perez-Rosas V., 2017, ARXIV
   Popat K, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2173, DOI 10.1145/2983323.2983661
   Purcell GP, 2002, BMJ-BRIT MED J, V324, P557, DOI 10.1136/bmj.324.7337.557
   Rieh SY, 2000, P ASIS ANN, V37, P25
   Samuel Hamman, 2018, Advances in Artificial Intelligence. 31st Canadian Conference on Artificial Intelligence, Canadian AI 2018. Proceedings: LNAI 10832, P108, DOI 10.1007/978-3-319-89656-4_9
   Sbaffi L, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7579
   Scantlebury A, 2017, INT J MED INFORM, V103, P103, DOI 10.1016/j.ijmedinf.2017.04.018
   Schwarz J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1245
   Self C.C., 2014, An integrated approach to communication theory and research, V2nd, P449, DOI DOI 10.4324/9780203887011
   Silberg WM, 1997, JAMA-J AM MED ASSOC, V277, P1244, DOI 10.1001/jama.1997.03540390074039
   Sondhi Parikshit, 2012, Advances in Information Retrieval. Proceedings of the 34th European Conference on IR Research (ECIR 2012), P219, DOI 10.1007/978-3-642-28997-2_19
   Song SY, 2019, IEEE C ELEC DEVICES, DOI 10.1109/edssc.2019.8754152
   Sorensen K, 2015, EUR J PUBLIC HEALTH, V25, P1053, DOI 10.1093/eurpub/ckv043
   Suarez-Lledo V, 2021, J MED INTERNET RES, V23, DOI 10.2196/17187
   Suominen H, 2018, LECT NOTES COMPUT SC, V11018, P286, DOI 10.1007/978-3-319-98932-7_26
   Upadhyay Rishabh, 2021, GoodIT '21: Proceedings of the Conference on Information Technology for Social Good, P19, DOI 10.1145/3462203.3475898
   Viviani M, 2017, WIRES DATA MIN KNOWL, V7, DOI 10.1002/widm.1209
   Wardle C., 2017, Information disorder: Toward an interdisciplinary framework for research and policymaking
   Williams P, 2003, ASLIB PROC, V55, P304, DOI 10.1108/00012530310498879
   Xie J., 2009, AMCIS 2009 P
   Xie J, 2011, LECT NOTES COMPUT SC, V6637, P526
   Yang F, 2018, IEEE ACCESS, V6, P57460, DOI 10.1109/ACCESS.2018.2873327
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
NR 63
TC 10
Z9 11
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5271
EP 5290
DI 10.1007/s11042-022-13368-z
EA JUL 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000832565900005
PM 35915807
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Hu, HY
   Cao, YH
   Hao, J
   Li, XJ
   Mou, J
AF Hu, Haiying
   Cao, Yinghong
   Hao, Jin
   Li, Xuejun
   Mou, Jun
TI A novel chaotic system with hidden attractor and its application in
   color image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fractional-order no-equilibrium chaotic system; Hidden attractor; Color
   image encryption
ID ALGORITHM; SYNCHRONIZATION; IMPLEMENTATION; OSCILLATIONS; COMPRESSION;
   SCHEME
AB In this paper, a novel fractional-order no-equilibrium chaotic system with hidden attractor is presented. The dynamical characteristics of the fractional-order system are analyzed by the phase diagram, Lyapunov exponents, bifurcation diagram, complexity, and attractor basin. Based on the above analysis, an image encryption scheme performs discrete cosine transform on the R, G, and B channels of the original color image to get the corresponding sparse coefficient matrices. Then, the measurement matrix generated by the Hadamard matrix and the chaotic pseudo-random sequence is used to compress and perceive the sparse coefficient matrices. In addition, the row and column scrambling and GF (257) domain diffusion algorithm are performed on the compressed pixel matrix to obtain the final cipher image. Experimental results and performance analysis display that the scheme has high compressibility and security. Even if the compression rate is 0.25, the calculated PSNR values are around 30. In addition, the chi(2)-value of the encrypted Lena image is 248.2824, and the algorithm has passed the UACI and NPCR tests and can resist differential attacks. Therefore, the proposed algorithm is effectively.
C1 [Hu, Haiying; Cao, Yinghong; Hao, Jin; Li, Xuejun; Mou, Jun] Dalian Polytech Univ, Sch Informat Sci & Engn, Dalian 116000, Peoples R China.
C3 Dalian Polytechnic University
RP Cao, YH; Mou, J (corresponding author), Dalian Polytech Univ, Sch Informat Sci & Engn, Dalian 116000, Peoples R China.
EM caoyinghong@dlpu.edu.cn; moujun@csu.edu.cn
FU National Natural Science Foundation of China [62061014]; Natural Science
   Foundation of Liaoning province [2020-MS-274]; Basic Scientific Research
   Projects of Colleges and Universities of Liaoning Province [LJKZ0545]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 62061014); The Natural Science Foundation of Liaoning
   province(2020-MS-274); The Basic Scientific Research Projects of
   Colleges and Universities of Liaoning Province (Grant Nos. LJKZ0545).
CR Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chai XL, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107525
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P15561, DOI 10.1007/s11042-016-3858-4
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chen CJ, 2021, NONLINEAR DYNAM, V106, P2559, DOI 10.1007/s11071-021-06910-5
   Chen LP, 2020, FRONT INFORM TECH EL, V21, P866, DOI 10.1631/FITEE.1900709
   Gao XY, 2022, J KING SAUD UNIV-COM, V34, P1535, DOI 10.1016/j.jksuci.2022.01.017
   Gao XY, 2022, NONLINEAR DYNAM, V108, P613, DOI 10.1007/s11071-021-07192-7
   Gu WJ, 2017, IEEE-CAA J AUTOMATIC, V4, P107, DOI 10.1109/JAS.2017.7510340
   Han XT, 2022, EUR PHYS J PLUS, V137, DOI 10.1140/epjp/s13360-022-02734-3
   Hasanzadeh E, 2020, MULTIMED TOOLS APPL, V79, P7279, DOI 10.1007/s11042-019-08342-1
   Hu HY, 2021, IEEE ACCESS, V9, P22141, DOI 10.1109/ACCESS.2021.3054842
   Hu XC, 2020, IEEE ACCESS, V8, P12452, DOI 10.1109/ACCESS.2020.2965740
   Huang R, 2014, MULTIMED TOOLS APPL, V72, P71, DOI 10.1007/s11042-012-1337-0
   Huang R, 2020, MULTIMED TOOLS APPL, V79, P27483, DOI 10.1007/s11042-020-09163-3
   Iqbal N, 2020, IEEE ACCESS, V8, P178167, DOI 10.1109/ACCESS.2020.3025241
   Jafari S, 2013, PHYS LETT A, V377, P699, DOI 10.1016/j.physleta.2013.01.009
   Jia HY, 2014, IEEE T CIRCUITS-I, V61, P845, DOI 10.1109/TCSI.2013.2283999
   Kaige Zhu, 2020, MATEC Web of Conferences, V309, DOI 10.1051/matecconf/202030903017
   Kuznetsov N. V., 2011, IFAC P, V44, P2506, DOI DOI 10.3182/20110828-6-IT-1002.03316
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Leonov GA, 2014, NONLINEAR DYNAM, V77, P277, DOI 10.1007/s11071-014-1292-6
   Leonov GA, 2011, DOKL MATH, V84, P475, DOI 10.1134/S1064562411040120
   Leonov GA, 2011, PHYS LETT A, V375, P2230, DOI 10.1016/j.physleta.2011.04.037
   Leonov G. A., 2011, IFAC P, V18, P2494, DOI 10.3182/20110828-6-IT-1002.03315
   Li B, 2021, EUR PHYS J PLUS, V136, DOI 10.1140/epjp/s13360-020-01001-7
   Li XJ, 2022, CHAOS SOLITON FRACT, V159, DOI 10.1016/j.chaos.2022.112133
   Li XJ, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S0218127422500353
   Liu HJ, 2019, OPT LASER ENG, V122, P123, DOI 10.1016/j.optlaseng.2019.05.027
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Ma CG, 2021, EUR PHYS J-SPEC TOP, V230, P1945, DOI 10.1140/epjs/s11734-021-00133-w
   Ma CG, 2021, NONLINEAR DYNAM, V103, P2867, DOI 10.1007/s11071-021-06276-8
   Malik MGA, 2020, IEEE ACCESS, V8, P88093, DOI 10.1109/ACCESS.2020.2990170
   Min FH, 2021, INT J BIFURCAT CHAOS, V31, DOI 10.1142/S0218127421501674
   Mou J, 2021, MOBILE NETW APPL, V26, P1849, DOI 10.1007/s11036-019-01293-9
   Musanna F, 2019, MULTIMED TOOLS APPL, V78, P14867, DOI 10.1007/s11042-018-6827-2
   Ojoniyi OS, 2016, CHAOS SOLITON FRACT, V87, P172, DOI 10.1016/j.chaos.2016.04.004
   Pham VT, 2015, EUR PHYS J-SPEC TOP, V224, P1507, DOI 10.1140/epjst/e2015-02476-9
   Pham V. T., 2017, STUDIES COMPUTATIONA, P449
   Ruan JY, 2018, EUR PHYS J PLUS, V133, DOI 10.1140/epjp/i2018-11828-0
   Shakir HR, 2019, MULTIMED TOOLS APPL, V78, P26073, DOI 10.1007/s11042-019-07766-z
   Sharma PR, 2015, EUR PHYS J-SPEC TOP, V224, P1485, DOI 10.1140/epjst/e2015-02474-y
   Vaidyanathan S, 2016, STUD FUZZ SOFT COMP, V337, P529, DOI 10.1007/978-3-319-30340-6_22
   Pham VT, 2016, STUD FUZZ SOFT COMP, V337, P35, DOI 10.1007/978-3-319-30340-6_2
   Pham VT, 2014, SCI WORLD J, DOI 10.1155/2014/368986
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wang SC, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2019.105995
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wang X, 2013, NONLINEAR DYNAM, V71, P429, DOI 10.1007/s11071-012-0669-7
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xu C, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420500601
   Xu QY, 2019, OPT LASER ENG, V121, P203, DOI 10.1016/j.optlaseng.2019.04.011
   Xu YX, 2016, EUR PHYS J PLUS, V131, DOI 10.1140/epjp/i2016-16186-3
   Yang FF, 2019, IEEE ACCESS, V7, P118188, DOI 10.1109/ACCESS.2019.2937126
   Yang FF, 2019, IEEE ACCESS, V7, P58751, DOI 10.1109/ACCESS.2019.2914722
   Yang FF, 2019, PHYS SCRIPTA, V94, DOI 10.1088/1402-4896/ab0033
   Zhang LL, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/6/064209
NR 58
TC 6
Z9 7
U1 3
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4343
EP 4369
DI 10.1007/s11042-022-13414-w
EA JUL 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000830266500001
DA 2024-07-18
ER

PT J
AU Zhao, HY
   Min, WD
   Wang, Q
   Wei, ZT
AF Zhao, Haoyu
   Min, Weidong
   Wang, Qi
   Wei, Zitai
TI Memory-efficient document layout analysis method using LD-net
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optical character recognition; Document layout analysis; Image
   processing; Lightweight dilated network
ID ALGORITHM
AB Document layout analysis is a critical step in optical character recognition. Traditional handcraft feature-based methods cannot handle various formats to obtain high accuracy. Although, deep-learning based methods obtain satisfactory accuracy, they are not memory-efficient for low-memory devices such as mobile phone. To alleviate such problems, a memory-efficient approach to layout analysis with the Lightweight Dilated Network (LD-Net) is proposed in this study. The initial document page image is segmented into blocks of content via Otsu algorithm and RLSA. Each block is sent into the LD-Net to classify them into four common different classes, figure, table, text, and formula. The main structure of the LD-Net is a shallow network, which performs better than deeper network for layout analysis task. Each convolution layer is composed of depthwise separable convolution and residual structure. In addition, the dilated convolution is also employed in the LD-Net to improve the accuracy of detection results. Experimental results based on benchmarks show that the proposed approach gets better performance in accuracy and memory occupied. The accuracy of the model on ICDAR dataset is 95.7% and the memory of the model occupies 39.7MB, which outperforms the existing methods.
C1 [Zhao, Haoyu; Min, Weidong; Wei, Zitai] Nanchang Univ, Sch Math & Comp Sci, Nanchang 330031, Jiangxi, Peoples R China.
   [Min, Weidong] Nanchang Univ, Inst Metaverse, Nanchang 330031, Jiangxi, Peoples R China.
   [Min, Weidong] Jiangxi Key Lab Smart City, Nanchang 330031, Jiangxi, Peoples R China.
   [Wang, Qi] Nanchang Univ, Sch Software, Nanchang 330047, Jiangxi, Peoples R China.
C3 Nanchang University; Nanchang University; Nanchang University
RP Min, WD (corresponding author), Nanchang Univ, Sch Math & Comp Sci, Nanchang 330031, Jiangxi, Peoples R China.; Min, WD (corresponding author), Nanchang Univ, Inst Metaverse, Nanchang 330031, Jiangxi, Peoples R China.; Min, WD (corresponding author), Jiangxi Key Lab Smart City, Nanchang 330031, Jiangxi, Peoples R China.
EM zhaohaoyu@email.ncu.edu.cn; minweidong@ncu.edu.cn; wangqi@ncu.edu.cn;
   weizitai@email.ncu.edu.cn
RI Min, Weidong/D-4585-2017
OI Min, Weidong/0000-0003-2526-2181
FU National Natural Science Foundation of China [62076117, 62166026];
   Natural Science Foundation of Jiangxi Province, China [20161ACB20004];
   Jiangxi Key Laboratory of Smart City [20192BCD40002]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 62076117 and No. 62166026), the Natural Science
   Foundation of Jiangxi Province, China (Grant No. 20161ACB20004) and
   Jiangxi Key Laboratory of Smart City (Grant No. 20192BCD40002).
CR [Anonymous], CoRR abs/1511.07122
   Bhowmik S, 2021, MULTIMED TOOLS APPL, V80, P8471, DOI 10.1007/s11042-020-09832-3
   Binmakhashen GM, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3355610
   Oliveria DAB, 2017, IEEE INT CONF COMP V, P1173, DOI 10.1109/ICCVW.2017.142
   Bosch V, 2016, INT CONF FRONT HAND, P313, DOI [10.1109/ICFHR.2016.0066, 10.1109/ICFHR.2016.61]
   Breuel TM, 2008, PROC SPIE, V6815, DOI 10.1117/12.783598
   Breuel TM, 2002, LECT NOTES COMPUT SC, V2423, P188
   Bukhari SS, 2011, SPIE DOCUMENT RECOGN, p78740D
   Bukhari SS, 2013, PROC INT CONF DOC, P748, DOI 10.1109/ICDAR.2013.153
   Bukhari SS, 2013, INT J DOC ANAL RECOG, V16, P33, DOI 10.1007/s10032-011-0176-2
   Chang F, 2005, PATTERN RECOGN, V38, P261, DOI 10.1016/j.patcog.2004.05.010
   De R, 2020, IEEE SIGNAL PROC LET, V27, P1090, DOI 10.1109/LSP.2020.3003828
   Gao LC, 2017, PROC INT CONF DOC, P1417, DOI 10.1109/ICDAR.2017.231
   Dai-Ton H, 2016, PATTERN RECOGN LETT, V80, P137, DOI 10.1016/j.patrec.2016.06.011
   Hesham AM, 2017, PATTERN ANAL APPL, V20, P1275, DOI 10.1007/s10044-017-0595-x
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Kasar T, 2013, PROC INT CONF DOC, P1185, DOI 10.1109/ICDAR.2013.240
   Koci E, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P139, DOI 10.1109/DAS.2018.48
   Li YX, 2018, LECT NOTES ARTIF INT, V10956, P266, DOI 10.1007/978-3-319-95957-3_30
   Min WD, 2018, IEEE T INTELL TRANSP, V19, P174, DOI 10.1109/TITS.2017.2756989
   Moysset B, 2019, INT J DOC ANAL RECOG, V22, P193, DOI 10.1007/s10032-019-00325-0
   Nayef N, 2015, PROC INT CONF DOC, P776, DOI 10.1109/ICDAR.2015.7333867
   Nguyen NV, 2019, INT J DOC ANAL RECOG, V22, P265, DOI 10.1007/s10032-019-00330-3
   Niu Y, 2019, IEEE SIGNAL PROC LET, V26, P1907, DOI 10.1109/LSP.2019.2953953
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Phillips I, 1995, USERS REFERENCE MANU
   Qin XR, 2017, PROC INT CONF DOC, P1074, DOI 10.1109/ICDAR.2017.178
   Royer E, 2017, PROC INT CONF DOC, P9, DOI 10.1109/ICDAR.2017.342
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Tran Dieu Ni, 2015, International Journal of Contents, V11, P77
   Tran TA, 2017, EXPERT SYST APPL, V85, P99, DOI 10.1016/j.eswa.2017.05.030
   Tran TA, 2016, INT J DOC ANAL RECOG, V19, P191, DOI 10.1007/s10032-016-0265-3
   Le VP, 2015, PROC INT CONF DOC, P1096, DOI 10.1109/ICDAR.2015.7333930
   Wang Q, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-2811-8
   WONG KY, 1982, IBM J RES DEV, V26, P647, DOI 10.1147/rd.266.0647
   Yang J, 2019, INT J DOC ANAL RECOG, V22, P407, DOI 10.1007/s10032-019-00337-w
   Yi XH, 2017, PROC INT CONF DOC, P230, DOI 10.1109/ICDAR.2017.46
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
NR 38
TC 0
Z9 0
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4371
EP 4386
DI 10.1007/s11042-022-12497-9
EA JUL 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000830266500002
DA 2024-07-18
ER

PT J
AU Izhar, F
   Ali, S
   Ponum, M
   Mahmood, MT
   Ilyas, H
   Iqbal, A
AF Izhar, Faisal
   Ali, Sajid
   Ponum, Mahvish
   Mahmood, Muhammad Tahir
   Ilyas, Hamida
   Iqbal, Amna
TI Detection & recognition of veiled and unveiled human face on the basis
   of eyes using transfer learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; LBPH; Classification; Verification; Feature extraction
AB Face detection and recognition are the most substantial research areas in computer vision and transfer learning due to the inspiring nature of faces as an object. In this paper, we show that we can obtain promising results on the standard face databanks when the features are extracted merely from the eye. The contributions of this work are divided into three parts, specifically face detection, eyes detection and recognition for individual identification. The key features for face recognition, used in this study are the eyes, nostrils, and mouth. The key features for eyes recognition are center of left eye, center of right eye, midpoint of eyes and extraction of eyebrows. Extracted Local Binary Pattern Histogram (LBPH) method is used to extract the facial features of face images whose computational complexity is very low and these features contain simple pixel values. Furthermore, neighborhood pixels are calculated to extract effective facial feature to realize eyes recognition and person verification. This study is able to identify an individual on the basis of even a single eye. The algorithm finds the brighter eye from the face and then, on the basis of that eye, the person is identified and the name of person is provided. The experimental results of this study show that faces are recognized accurately and LBPH method has achieved 98.2% accuracy.
C1 [Izhar, Faisal; Ali, Sajid; Ilyas, Hamida] Inst Southern Punjab, Dept Comp Sci, Multan, Pakistan.
   [Ali, Sajid] Univ Educ, Dept Informat Sci, Multan Campus, Lahore, Pakistan.
   [Ponum, Mahvish] Univ Lahore, Dept Software Engn, 1-Km Def Rd,Near Bhuptian Chowk, Lahore, Pakistan.
   [Mahmood, Muhammad Tahir] Univ Engn & Technol, Dept Comp Sci, Taxila, Pakistan.
   [Iqbal, Amna] COMSATS Univ Islamabad, Dept Comp Sci, Vehari, Pakistan.
C3 University of Lahore; University of Engineering & Technology Taxila;
   COMSATS University Islamabad (CUI)
RP Ponum, M (corresponding author), Univ Lahore, Dept Software Engn, 1-Km Def Rd,Near Bhuptian Chowk, Lahore, Pakistan.
EM raofaisal1979@gmail.com; sajid.ali@ue.edu.pk;
   mponum.msit15seccs@seees.edu.pk; mtahitishere@outlook.com;
   hamida.ilyas@yahoo.com; amnaiqbal962@yahoo.com
RI Ali, Sajid/IWD-7100-2023; Ali, Sk/JEO-9086-2023; Ali,
   Shujat/JJF-4668-2023
OI Ali, Sajid/0000-0002-1287-849X; Ali, Shujat/0000-0002-4467-6091; Ponum,
   Mahvish/0000-0002-9432-1395
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], EUCLIDEAN DISTANCE
   [Anonymous], 2010, P INT MULT ENG COMP
   [Anonymous], 2017, PERIOCULAR BIOMETRIC, V6
   Balya D, 1999, J VLSI SIG PROC SYST, V23, P497, DOI 10.1023/A:1008121908145
   Belhumeur Peter N., 2012, METHOD SYSTEM LOCALI
   Chen S, 2015, IMAGE VISION COMPUT, V33, P68, DOI 10.1016/j.imavis.2014.10.007
   Chinsatit W., 2017, Applied Computational Intelligence and Soft Computing
   Daugman J.G., 1994, U.S. Patent, Patent No. 5291560
   Devi B. Thirumaleshwari, 2021, IOP Conference Series: Materials Science and Engineering, V1042, DOI 10.1088/1757-899X/1042/1/012017
   Dhanaseely AJ, 2012, PERFORMANCE COMP CAS
   Fahad H, 2013, FACIAL GENDER RECOGN
   Fu H, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/7831469
   Fuhl W., 2016, ARXIV
   Gosselin F, 2001, VISION RES, V41, P2261, DOI 10.1016/S0042-6989(01)00097-9
   Hadid A, 2007, HDB TEXTURE ANAL
   Hajare Raju, GLOBAL TRANSITIONS P, V2, P467, DOI [10.1016/j.gltp.2021.08.009, DOI 10.1016/J.GLTP.2021.08.009]
   Han Seongwon, 2012, P 12 WORKSH MOB COMP, P1
   Heitmeyer R., 2000, ICAO J, V55, P10
   Hjelm A, 2018, IMPORTANCE DIGNITY K
   Huang LL, 2003, NEUROCOMPUTING, V51, P197, DOI 10.1016/S0925-2312(02)00616-1
   Kaur U, 1988, STUDY BIOMETRIC TECH
   Kroon B, 2009, COMPUT VIS IMAGE UND, V113, P921, DOI 10.1016/j.cviu.2009.03.013
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   Messer K., 1999, P 2 INT C AUD VID BA
   MOGHADDAM B, 1994, P SOC PHOTO-OPT INS, V2277, P12, DOI 10.1117/12.191877
   Nirgish Kumar K, 2017, PERIOCULAR BIOMETRIC, V6
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 1999, PATTERN RECOGN, V32, P477, DOI 10.1016/S0031-3203(98)00038-7
   Padilla R., 2012, EVALUATION HAAR CASC
   Paul T., 2018, Int. J. Biomed. Soft Comput. Hum. Sci. Off. J. Biomed. Fuzzy Syst. Assoc, V23, P27
   Phillips PJ, 1997, LECT NOTES COMPUT SC, V1206, P395, DOI 10.1007/BFb0016020
   Pietikainen, 2010, SCHOLARPEDIA, V5, P9775, DOI DOI 10.4249/SCHOLARPEDIA.9775.REVISION#188481
   Rodriguez Y., 2006, THESIS ECOLE POLYTEC
   Royer J, 2018, COGNITION, V181, P12, DOI 10.1016/j.cognition.2018.08.004
   Sahithullah M, 2018, HARMONIC REDUCTION H, V24, P16907
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Soukupova T., 2016, 21 COMPUTER VISION W
   Suma SL, 2018, INT J SCI
   Torrey L., 2010, IGI Global, P242, DOI 10.4018/978-1-60566-766-9.CH011
   Valstar M.F., 2006, International Conference on Multimodal Interfaces, P162, DOI DOI 10.1145/1180995.1181031
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wroldseny J, 1988, RECOGNIZING FACES EY
   Xie DF, 2017, APPL COMPUT INTELL S, V2017, DOI 10.1155/2017/1320780
   YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169
   Zhang L, 2017, APPL COMPUT INTELL S, V2017, DOI 10.1155/2017/7571043
NR 46
TC 1
Z9 1
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4257
EP 4287
DI 10.1007/s11042-022-13402-0
EA JUL 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000830853600005
PM 35912060
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Debnath, S
   Roy, R
   Changder, S
AF Debnath, Soma
   Roy, Ratnakirti
   Changder, Suvamoy
TI A novel approach using deep convolutional neural network to classify the
   photographs based on leading-line by fine-tuning the pre-trained VGG16
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep neural network; Image aesthetic evaluation; Leading line detection;
   Pre-trained VGG16; Photographic compositions; Transfer learning
ID VISUAL QUALITY ASSESSMENT; ENHANCEMENT; SYSTEM
AB Leading lines are used to draw the viewer's attention towards the main subject present in a photograph. These lines may be straight or curved, and generally, start from the left or right bottom corner of the frame. It leads the viewer's eyes to the region of interest, which could be any object or the vanishing point. It has been observed that the photograph containing leading lines achieves a higher aesthetic score in several photographic competitions and different photo-sharing communities. Automatic detection of the leading line may solve numerous real-time applications like on-site aesthetic value evaluation, assisting amateur photographer to get a better composition, and so on. However, implementation of the same is not easy due to the subjective nature of the problem. From the literature survey, we can notice that no such work exists that considers the presence of leading line in a photograph. This paper introduces a novel approach using deep convolutional neural network (DCNN) framework to detect the presence of leading line in a photograph as well as classify the photographs based on the leading line. The proposed model automatically extracts features by fine-tuning the pre-trained VGG16 CNN (a transfer learning method) to accomplish the classification task. The model has been examined by executing on the ground truth dataset, and the satisfying result has been observed. Another contribution of the proposed work is creating a new dataset named as Leading-line Containing Image (LCI) which will be beneficial for future work in this area.
C1 [Debnath, Soma; Changder, Suvamoy] NIT, Dept CSE, Durgapur, India.
   [Roy, Ratnakirti] Dr BC Roy Engn Coll, Durgapur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Durgapur; Dr. B. C. Roy Engineering College
RP Debnath, S (corresponding author), NIT, Dept CSE, Durgapur, India.
EM sd.16ca1102@phd.nitdgp.ac.in; rroy.nitdgp@gmail.com;
   suvamoy.changder@cse.nitdgp.ac.in
CR [Anonymous], 2010, P ACM INT C MULT INF, DOI 10.1145/1743384.1743457
   [Anonymous], 2010, ACM MULTIMEDIA 2010
   Bishop Andrew, 2014, Evolutionary and Biologically Inspired Music, Sound, Art and Design. Third European Conference, EvoMUSART 2014. Revised Selected Papers: LNCS 8601, P62, DOI 10.1007/978-3-662-44335-4_6
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23
   Guo GJ, 2018, IEEE T MULTIMEDIA, V20, P2073, DOI 10.1109/TMM.2018.2794262
   Islam MB, 2017, MULTIMED TOOLS APPL, V76, P9517, DOI 10.1007/s11042-016-3561-5
   Jin X, 2019, IET COMPUT VIS, V13, P206, DOI 10.1049/iet-cvi.2018.5249
   Kao YY, 2017, IEEE T IMAGE PROCESS, V26, P1482, DOI 10.1109/TIP.2017.2651399
   Kao YY, 2016, SIGNAL PROCESS-IMAGE, V47, P500, DOI 10.1016/j.image.2016.05.004
   Lee HJ, 2017, IEEE T MULTIMEDIA, V19, P1921, DOI 10.1109/TMM.2017.2687759
   Li CC, 2009, IEEE J-STSP, V3, P236, DOI 10.1109/JSTSP.2009.2015077
   Lo KY, 2012, INT C PATT RECOG, P2186
   Lu P, 2019, SIGNAL PROCESS-IMAGE, V72, P105, DOI 10.1016/j.image.2018.12.007
   Lu X, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P457, DOI 10.1145/2647868.2654927
   Mai L, 2016, PROC CVPR IEEE, P497, DOI 10.1109/CVPR.2016.60
   Marchesotti L, 2015, INT J COMPUT VISION, V113, P246, DOI 10.1007/s11263-014-0789-2
   Mei-Chen Yeh, 2014, 2014 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P91, DOI 10.1109/ICCE-TW.2014.6904116
   Ni BB, 2013, IEEE T MULTIMEDIA, V15, P1138, DOI 10.1109/TMM.2013.2241042
   Nishiyama M, 2011, PROC CVPR IEEE, P33, DOI 10.1109/CVPR.2011.5995539
   Pramila A, 2017, MULTIMED TOOLS APPL, V76, P16063, DOI 10.1007/s11042-016-3895-z
   See J., 2019, P IEEE CVF C COMP VI
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su HH, 2012, IEEE T MULTIMEDIA, V14, P833, DOI 10.1109/TMM.2012.2186123
   Suler J., 2013, Photographic psychology: Image and Psyche
   Tang XO, 2013, IEEE T MULTIMEDIA, V15, P1930, DOI 10.1109/TMM.2013.2269899
   Tian XM, 2015, IEEE T MULTIMEDIA, V17, P2035, DOI 10.1109/TMM.2015.2479916
   Wang WN, 2015, SIGNAL PROCESS-IMAGE, V39, P499, DOI 10.1016/j.image.2015.07.006
   Yang JC, 2019, SIGNAL PROCESS-IMAGE, V78, P51, DOI 10.1016/j.image.2019.05.011
   Zhang C, 2018, SIGNAL PROCESS-IMAGE, V67, P12, DOI 10.1016/j.image.2018.05.006
   Zhang FL, 2013, IEEE T MULTIMEDIA, V15, P1480, DOI 10.1109/TMM.2013.2268051
   Zhang J, 2020, INKTHETICS COMPREHEN
   Zhang TT, 2020, IEEE ACCESS, V8, P13467, DOI 10.1109/ACCESS.2020.2966523
   Zhang XD, 2019, SIGNAL PROCESS-IMAGE, V78, P42, DOI 10.1016/j.image.2019.05.021
   Zhao MQ, 2016, SIGNAL PROCESS-IMAGE, V47, P511, DOI 10.1016/j.image.2016.05.009
   Zhu XH, 2016, 2016 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS 2016), P222, DOI 10.1109/HPCSim.2016.7568339
NR 35
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 JUL 18
PY 2022
DI 10.1007/s11042-022-13338-5
EA JUL 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Z8NT
UT WOS:000826828100002
DA 2024-07-18
ER

PT J
AU Dharshini, GP
   Rao, KS
AF Dharshini, Priya G.
   Rao, K. Sreenivasa
TI Accent classification from an emotional speech in clean and noisy
   environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Accent classification; Spectral features; Machine learning classifier;
   Emotion classification
ID IDENTIFICATION; RECOGNITION; FEATURES
AB The performance of speech emotion recognition systems (SER) suffers when emotional speech is spoken in different accents. One possible solution to such a problem is to identify the accent beforehand and use this knowledge in the SER task. The present work is one of the novel attempts in this regard to build effective accent recognition systems based on emotional speech. In this regard, statistical aggregation functions (like mean, std, kurtosis, etc.) have been applied on frame-level feature representations such as perceptual linear prediction (PLP), log filterbank energies (LFBE), Mel frequency cepstral coefficients (MFCC), spectral subband centroid (SSC), constant-Q cepstral coefficients (CQCC), chroma vector and Mel frequency discrete wavelet coefficients (MFDWC) to obtain utterance-level features from CREMA-D, an emotional dataset. The performance of the features for different standard classifiers is obtained by conducting experiments using clean and noisy speech signals. Finally, the experimental results show that the SSC features perform well on noisy data only when it is trained with noisy data. On the other hand, the combined MFDWC features perform well on noisy data for both clean and noisy training data. This hints at the noise-robustness of this feature set. On the other hand, we can only say that SSC is conditionally robust. We hope this work will initiate a new line of research in emotion recognition.
C1 [Dharshini, Priya G.] Indian Inst Technol Kharagpur, Adv Technol Developement Ctr, Kharagpur 721302, W Bengal, India.
   [Rao, K. Sreenivasa] Indian Inst Technol Kharagpur, Dept Comp Sci, Kharagpur 721302, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Kharagpur
RP Dharshini, GP (corresponding author), Indian Inst Technol Kharagpur, Adv Technol Developement Ctr, Kharagpur 721302, W Bengal, India.
EM priyagdarshi@gmail.com
OI G, Priya Dharshini/0000-0003-4925-7264
CR Amino K, 2014, SPEECH COMMUN, V56, P70, DOI 10.1016/j.specom.2013.07.010
   Angkititrakul P, 2006, IEEE T AUDIO SPEECH, V14, P634, DOI 10.1109/TSA.2005.851980
   [Anonymous], 2016, NEW FEATURE AUTOMATI
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cao HW, 2014, IEEE T AFFECT COMPUT, V5, P377, DOI 10.1109/TAFFC.2014.2336244
   Chen M., 2014, P ANN C INT SPEECH C, P2170
   Chen MM, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3620
   Chen YC, 2020, INT CONF ACOUST SPEE, P6979, DOI [10.1109/icassp40776.2020.9053098, 10.1109/ICASSP40776.2020.9053098]
   Chu S, 2009, IEEE T AUDIO SPEECH, V17, P1142, DOI 10.1109/TASL.2009.2017438
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gajic B, 2006, IEEE T AUDIO SPEECH, V14, P600, DOI 10.1109/TSA.2005.855834
   Giannakopoulos T., 2014, Introduction to Audio Analysis, P59, DOI DOI 10.1016/B978-0-08-099388-1.00004-2
   Gowdy JN, 2000, INT CONF ACOUST SPEE, P1351, DOI 10.1109/ICASSP.2000.861829
   Haeb-Umbach R., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P13, DOI 10.1109/ICASSP.1992.225984
   Hanani A, 2011, INT CONF ACOUST SPEE, P4876
   Hansen JHL, 2016, SPEECH COMMUN, V78, P19, DOI 10.1016/j.specom.2015.12.004
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   Honnavalli Dweepa, 2021, Advances in Artificial Intelligence and Data Engineering. Select Proceedings of AIDE 2019. Advances in Intelligent Systems and Computing (AISC 1133), P55, DOI 10.1007/978-981-15-3514-7_5
   Huang RQ, 2007, IEEE T AUDIO SPEECH, V15, P453, DOI 10.1109/TASL.2006.881695
   Ikeno A, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P437
   Jiang N, 2011, P 42 ND AES C, V198
   Ke GL, 2017, ADV NEUR IN, V30
   Kolly MJ, 2017, SPEECH COMMUN, V86, P121, DOI 10.1016/j.specom.2016.11.006
   Kua JMK, 2010, ODYSSEY 2010: THE SPEAKER AND LANGUAGE RECOGNITION WORKSHOP, P34
   Mannepalli K, 2016, INT J SPEECH TECHNOL, V19, P87, DOI 10.1007/s10772-015-9328-y
   Najafian M, 2020, SPEECH COMMUN, V122, P44, DOI 10.1016/j.specom.2020.05.003
   PAL SK, 1992, IEEE T NEURAL NETWOR, V3, P683, DOI 10.1109/72.159058
   Paliwal KK, 1998, INT CONF ACOUST SPEE, P617, DOI 10.1109/ICASSP.1998.675340
   Pappagari R, 2020, INT CONF ACOUST SPEE, P7169, DOI [10.1109/icassp40776.2020.9054317, 10.1109/ICASSP40776.2020.9054317]
   Pikrakis A, 2008, IEEE T MULTIMEDIA, V10, P846, DOI 10.1109/TMM.2008.922870
   Rajpal A, 2016, INTERSPEECH, P2383, DOI 10.21437/Interspeech.2016-1100
   Rasipuram R, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P648
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Saleem S, 2020, FORENS SCI INT-DIGIT, V34, DOI 10.1016/j.fsidi.2020.300982
   Schörkhuber C, 2013, J AUDIO ENG SOC, V61, P562
   Sharma G, 2020, APPL ACOUST, V158, DOI 10.1016/j.apacoust.2019.107020
   Speech Processing Transmission and Quality Aspects (STQ), 2008, 2023961 ETSI EG, P45
   Srivastava S, 2007, J MACH LEARN RES, V8, P1277
   Unni V, 2020, INT CONF ACOUST SPEE, P8254, DOI [10.1109/ICASSP40776.2020.9052912, 10.1109/icassp40776.2020.9052912]
   Vieru B, 2011, SPEECH COMMUN, V53, P292, DOI 10.1016/j.specom.2010.10.002
   Viswanathan R, 2018, INTERSPEECH, P1958
   Waldekar S, 2018, INTERSPEECH, P3323, DOI 10.21437/Interspeech.2018-2083
   Waldekar S, 2018, DIGIT SIGNAL PROCESS, V75, P71, DOI 10.1016/j.dsp.2017.12.012
   Weninger F, 2019, INTERSPEECH, P510, DOI 10.21437/Interspeech.2019-2737
   Wu TY, 2010, SPEECH COMMUN, V52, P83, DOI 10.1016/j.specom.2009.08.010
   Wu Y, 2018, KNOWL-BASED SYST, V161, P90, DOI 10.1016/j.knosys.2018.07.033
   Yang XS, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5989, DOI [10.1109/ICOPS35962.2018.9575654, 10.1109/ICASSP.2018.8462557]
   Zhan Y, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P2246
   Zhang TT, 2021, ENVIRON TECHNOL, V42, P571, DOI 10.1080/09593330.2019.1637464
   Zhong J, 2019, MULTIMED TOOLS APPL, V78, P30749, DOI 10.1007/s11042-018-6590-4
NR 51
TC 1
Z9 1
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3485
EP 3508
DI 10.1007/s11042-022-13236-w
EA JUL 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000825016300003
DA 2024-07-18
ER

PT J
AU Lin, CY
   Li, YL
AF Lin, Chen-Yi
   Li, Yueh-Lun
TI Predicting happiness contagion on online social networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotional contagion; Impact factors; Happiness influences; Online social
   networks
ID EMOTIONAL CONTAGION; CENTRALITY
AB In the real world, emotions guide the minds of human beings, which further influences their behaviors. During the recent years, with the increasing popularity of the internet, Online Social Networks (OSNs) have been attracting increasing number of users. It is confirmed that the emotional contagion phenomenon exists in OSNs similar to the real world. This was mostly studied through texts in current researches. Apart from the texts, however, OSNs provide their users several other interaction functions. To understand whether these interaction functions generate various levels of emotional influences to their users, this study investigates Facebook users, through interactions including the posts, number of likes, number of shares, number of fans, and number of comments, to speculate the relevant levels of user happiness. Furthermore, we propose an algorithm to identify the top-n users with the most happiness influences. According to the experimental results, among the Facebook users, various interactions generate different levels of happiness influences on members in its community. The members with a higher level of happiness are also better known in the community. In addition, we experimentally confirm that the proposed algorithm can effectively determine the top-n users of the most happiness influences.
C1 [Lin, Chen-Yi; Li, Yueh-Lun] Natl Taichung Univ Sci & Technol, Dept Informat Management, Taichung, Taiwan.
C3 National Taichung University of Science & Technology
RP Lin, CY (corresponding author), Natl Taichung Univ Sci & Technol, Dept Informat Management, Taichung, Taiwan.
EM cylin@nutc.edu.tw; s1810631007@nutc.edu.tw
OI Lin, Chen-Yi/0000-0002-8271-1935
FU Ministry of Science and Technology of Republic of China [MOST
   107-2221-E-025-008, MOST 108-2221-E-025-007, MOST 109-2221-E-025-012]
FX We would like to thank the anonymous reviewers for their constructive
   comments. In addition, this work was supported by the Ministry of
   Science and Technology of Republic of China under grant MOST
   107-2221-E-025-008, MOST 108-2221-E-025-007, and MOST
   109-2221-E-025-012.
CR [Anonymous], 1993, Emotional Contagion
   Aral S, 2012, SCIENCE, V337, P337, DOI 10.1126/science.1215842
   Barsade SG, 2002, ADMIN SCI QUART, V47, P644, DOI 10.2307/3094912
   Bollen J, 2011, ARXIV 11030784
   Borgatti SP, 2005, SOC NETWORKS, V27, P55, DOI 10.1016/j.socnet.2004.11.008
   Chakhmakhchyan L, 2013, PHYS LETT A, V377, P3119, DOI 10.1016/j.physleta.2013.10.003
   Coviello L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090315
   Dodds PS, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0026752
   Fornito A., 2016, Fundamentals of Brain Network Analysis
   Frey B., 2008, HAPPINESS REVOLUTION, DOI DOI 10.7551/MITPRESS/9780262062770.001.0001
   Gómez D, 2013, EUR J OPER RES, V226, P354, DOI 10.1016/j.ejor.2012.11.027
   Kramer ADI, 2014, P NATL ACAD SCI USA, V111, P8788, DOI 10.1073/pnas.1320040111
   Lenzenweger MF, 2004, AM J PSYCHIAT, V161, P936, DOI 10.1176/appi.ajp.161.5.936
   Meghanathan N, 2018, J KING SAUD UNIV-COM, V30, P391, DOI 10.1016/j.jksuci.2017.04.006
   Metz M, 2020, INFORM COMMUN SOC, V23, P1481, DOI 10.1080/1369118X.2019.1581244
   Nykl M, 2015, J INFORMETR, V9, P777, DOI 10.1016/j.joi.2015.07.002
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   Sharara H., 2011, IJCAI Proceedings-International Joint Conference on Artificial Intelligence, V22, P1485
   Sharifirad S, 2019, ARXIV 190203089
   Shugars S, 2019, SAGE OPEN, V9, DOI 10.1177/2158244019828850
   Sumith N, 2018, FUTURE GENER COMP SY, V89, P777, DOI 10.1016/j.future.2018.07.015
   Tang DL, 2019, KNOWL-BASED SYST, V164, P426, DOI 10.1016/j.knosys.2018.11.014
   Tang J, 2012, IEEE T AFFECT COMPUT, V3, P132, DOI 10.1109/T-AFFC.2011.23
   Tsiotas D, 2015, ANN OPER RES, V227, P93, DOI 10.1007/s10479-013-1434-0
   Yustiawan Y, 2015, PROCEDIA COMPUT SCI, V59, P419, DOI 10.1016/j.procs.2015.07.559
   Zhang X, 2017, P PACIFIC ASIA C KNO
NR 26
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2821
EP 2838
DI 10.1007/s11042-022-11989-y
EA JUL 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000825016300001
DA 2024-07-18
ER

PT J
AU Sani, RH
   Behnia, S
   Ziaei, J
AF Sani, R. Hoseini
   Behnia, S.
   Ziaei, J.
TI Construction of S-box based on chaotic piecewise map: Watermark
   application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; S-box; Finite ridglet transform; Piecewise non-linear
   chaotic maps
ID FRAGILE WATERMARKING; DIGITAL WATERMARKING; ENCRYPTION; SCHEME;
   TRANSFORM; ROBUST; ALGORITHM; BLIND; CRYPTOGRAPHY; WAVELET
AB The spread of using communication technologies has made it necessary to take certain measures to prevent illegal copying. Watermarking techniques are of great potential value in this regard. The present study introduces a watermarking scheme as a block cypher. We use entropy for sorting the blocks. The sorted blocks after finite ridgelet transformation are hosting the logo. The logo's information encrypts before transferring into the blocks by the proposed S-box. We introduce a piecewise non-linear chaotic map for generating the S-box. The ergodic nature of introducing a map is proved by the invariant measure. The ergodic nature of the map is providing an excellent confusion property for encryption. The ability of the watermarked image to resist the attacks is an exam with statistical analysis(PSNR and MSE). The performance of generated S-box is studying with corresponding attacks (Non-linearity, SAC, BIC, LP, and DP). The results are close to the optimal value.
C1 [Sani, R. Hoseini; Behnia, S.; Ziaei, J.] Urmia Univ Technol, Dept Phys, Orumiyeh, Iran.
C3 Urmia University of Technology
RP Behnia, S (corresponding author), Urmia Univ Technol, Dept Phys, Orumiyeh, Iran.
EM s.behnia@sci.uut.ac.ir
RI Behnia, Sohrab/H-3794-2014; Ziaei, Javid/E-5670-2018
OI Behnia, Sohrab/0000-0001-6794-6560; Ziaei, Javid/0000-0002-7003-8595
CR Akhshani A, 2010, INT J MOD PHYS C, V21, P275, DOI 10.1142/S0129183110015117
   Al Solami E, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20070525
   Al-Haj Ali, 2007, Journal of Computer Sciences, V3, P740, DOI 10.3844/jcssp.2007.740.746
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   Anees A, 2015, WIRELESS PERS COMMUN, V82, P1497, DOI 10.1007/s11277-015-2295-4
   [Anonymous], 2012, INT J NETW SECUR
   Bagadi KP, 2013, NEURAL COMPUT APPL, V23, P1071, DOI 10.1007/s00521-012-1033-z
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Batool S, 2014, NEURAL COMPUT APPL, V25, P2037, DOI 10.1007/s00521-014-1691-0
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Behnia S, 2007, PHYS LETT A, V366, P391, DOI 10.1016/j.physleta.2007.01.081
   Behnia S, 2017, CHAOS SOLITON FRACT, V104, P6, DOI 10.1016/j.chaos.2017.07.020
   Behnia S, 2014, APPL SOFT COMPUT, V21, P481, DOI 10.1016/j.asoc.2014.03.022
   Behnia S, 2011, J COMPUT APPL MATH, V235, P3455, DOI 10.1016/j.cam.2011.02.006
   Behnia S, 2010, COMMUN NONLINEAR SCI, V15, P2469, DOI 10.1016/j.cnsns.2009.09.042
   Biham E., 1991, Journal of CRYPTOLOGY, V4, P3, DOI DOI 10.1007/BF00630563
   Bilgin B, 2013, INT C SMART CARD RES
   Campisi P, 2004, IEEE SIGNAL PROC LET, V11, P826, DOI 10.1109/LSP.2004.835463
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chen G, 2008, CHAOS SOLITON FRACT, V36, P1028, DOI 10.1016/j.chaos.2006.08.003
   Chen G, 2007, CHAOS SOLITON FRACT, V31, P571, DOI 10.1016/j.chaos.2005.10.022
   Chen YH, 2015, NEURAL COMPUT APPL, V26, P291, DOI 10.1007/s00521-014-1615-z
   Cornfeld I, 1982, ERGODIC THEORY, P193
   Cusick TW, 2017, CRYPTOGRAPHIC BOOLEAN FUNCTIONS AND APPLICATIONS, 2ND EDITION, P1
   Djurovic I, 2001, J NETW COMPUT APPL, V24, P167, DOI 10.1006/jnca.2000.0128
   Do MN, 2003, IEEE T IMAGE PROCESS, V12, P16, DOI 10.1109/TIP.2002.806252
   Dorfman J.R., 1999, An Introduction to Chaos in Nonequilibrium Statistical Mechanics
   Thakkar F, 2021, MULTIMED TOOLS APPL, V80, P12275, DOI 10.1007/s11042-020-10220-0
   Farah T, 2017, NONLINEAR DYNAM, V88, P1059, DOI 10.1007/s11071-016-3295-y
   Farri E, 2018, NONLINEAR DYNAM, V93, P1875, DOI 10.1007/s11071-018-4295-x
   Ghosal SK, 2014, J INF SECUR APPL, V19, P272, DOI 10.1016/j.jisa.2014.07.004
   Hu HT, 2016, AEU-INT J ELECTRON C, V70, P172, DOI 10.1016/j.aeue.2015.11.003
   Huifang H., 2016, APPL RES COMPUTERS, V6, P47
   Hussain I, 2013, MATH COMPUT MODEL, V57, P963, DOI 10.1016/j.mcm.2012.10.007
   Hussain I, 2012, NONLINEAR DYNAM, V70, P1791, DOI 10.1007/s11071-012-0573-1
   Hussain I, 2012, COMPUT MATH APPL, V64, P2450, DOI 10.1016/j.camwa.2012.05.017
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Islam M, 2020, NEURAL COMPUT APPL, V32, P1379, DOI 10.1007/s00521-018-3647-2
   Barani MJ, 2020, MULTIMED TOOLS APPL, V79, P2127, DOI 10.1007/s11042-019-08225-5
   Jakimoski G, 2001, IEEE T CIRCUITS-I, V48, P163, DOI 10.1109/81.904880
   Jamal SS, 2016, WIRELESS PERS COMMUN, V90, P2033, DOI 10.1007/s11277-016-3436-0
   Khan M, 2016, NEURAL COMPUT APPL, V27, P677, DOI 10.1007/s00521-015-1887-y
   Khan M, 2015, NONLINEAR DYNAM, V82, P527, DOI 10.1007/s11071-015-2173-3
   Khan M, 2015, NEURAL COMPUT APPL, V26, P845, DOI 10.1007/s00521-014-1747-1
   Khan M, 2013, NONLINEAR DYNAM, V73, P1795, DOI 10.1007/s11071-013-0904-x
   Khan M, 2012, NONLINEAR DYNAM, V70, P2303, DOI 10.1007/s11071-012-0621-x
   Lambic D, 2020, NONLINEAR DYNAM, V100, P699, DOI 10.1007/s11071-020-05503-y
   Lin SD, 2000, IEEE T CONSUM ELECTR, V46, P415, DOI 10.1109/30.883387
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P7739, DOI 10.1007/s11042-015-2691-5
   Lou DC, 2007, COMPUT STAND INTER, V29, P125, DOI 10.1016/j.csi.2006.02.003
   Matsui M, 1993, LINEAR CRYPTANALYSIS, P386, DOI DOI 10.1007/3-540-48285-7
   Özkaynak F, 2010, PHYS LETT A, V374, P3733, DOI 10.1016/j.physleta.2010.07.019
   Paar C., 2009, UNDERSTANDING CRYPTO
   Posada-Gomez R, 2011, PRACTICAL APPL SOLUT
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Tang GN, 2003, PHYS LETT A, V318, P388, DOI 10.1016/j.physleta.2003.09.042
   Tang GP, 2005, CHAOS SOLITON FRACT, V23, P413, DOI 10.1016/j.chaos.2004.04.023
   Thanki R, 2019, MULTIMED TOOLS APPL, V78, P13905, DOI 10.1007/s11042-018-6746-2
   Tian Y, 2018, NONLINEAR DYNAM, V94, P2115, DOI 10.1007/s11071-018-4478-5
   Varsaki EE, 2010, PROC SPIE, V7723, DOI 10.1117/12.854220
   Vasudev R., 2016, Journal of Image and Graphics, V4, P150
   Wang XY, 2014, NONLINEAR DYNAM, V75, P567, DOI 10.1007/s11071-013-1086-2
   Wang Y, 2012, PHYS LETT A, V376, P827, DOI 10.1016/j.physleta.2012.01.009
   Waqas UA, 2020, MULTIMED TOOLS APPL, V79, P6891, DOI 10.1007/s11042-019-08570-5
   Xia Z, 2021, APPL INTELL, P115
   Yaroslavsky L.P., 2012, Digital picture processing: an introduction, V9
   Yen JC, 2001, ELECTRON LETT, V37, P80, DOI 10.1049/el:20010065
   Zhang Q, 2012, J APPL RES TECHNOL, V10, P405
   ?zkaynak F., 2016, SIVIP, V4, P659
NR 70
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1131
EP 1148
DI 10.1007/s11042-022-13278-0
EA JUN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000810821800004
DA 2024-07-18
ER

PT J
AU Stankovic, I
   Brajovic, M
   Lerga, J
   Dakovic, M
   Stankovic, L
AF Stankovic, Isidora
   Brajovic, Milos
   Lerga, Jonatan
   Dakovic, Milos
   Stankovic, Ljubisa
TI Image denoising using RANSAC and compressive sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image; Denoising; Impulsive noise; Compressive sensing; Pixel selection;
   RANSAC
ID MIXED NOISE REMOVAL; ADAPTIVE KUWAHARA; SIGNALS; ALGORITHM; RECOVERY;
   RECONSTRUCTION; QUANTIZATION; PROJECTION
AB Image denoising is a vital image processing phase aiming to improve the quality of images and to make them more informative. In this paper, we propose a blind denoising approach for removing the outliers (impulsive disturbances) from digital images, by combining the random sample consensus (RANSAC) and compressive sensing (CS) principles. The proposed approach exploits the fact that images are highly concentrated in the domain of two-dimensional discrete cosine transform (2D-DCT). The sparsity (high concentration) in the transform domain is used in both detection and reconstruction of pixels affected by high disturbances. The image pixels not affected by the noise are found using the RANSAC-based methodology and they are further used as available measurements in the CS reconstruction. The affected pixels are considered unavailable and they are recovered by the CS procedure. The presented approach does not require any disturbance-related assumptions regarding the statistical behavior of the noise or about the range of its values. The theory is verified on examples with 55 images. The comparative analysis against several state-of-the-art methods, done with full-reference and no-reference quality metrics, suggests that the proposed method can be used as an efficient tool for image denoising.
C1 [Stankovic, Isidora; Brajovic, Milos; Dakovic, Milos; Stankovic, Ljubisa] Univ Montenegro, Fac Elect Engn, Podgorica 81000, Montenegro.
   [Lerga, Jonatan] Univ Rijeka, Fac Engn, Rijeka 51000, Croatia.
   [Lerga, Jonatan] Univ Rijeka, Ctr Artificial Intelligence & Cybersecur, Rijeka 51000, Croatia.
C3 University of Montenegro; University of Rijeka; University of Rijeka
RP Stankovic, I (corresponding author), Univ Montenegro, Fac Elect Engn, Podgorica 81000, Montenegro.
EM isidoras@ucg.ac.me; milosb@ucg.ac.me; jlerga@riteh.hr; milos@ucg.ac.me;
   ljubisa@ucg.ac.me
RI Lerga, Jonatan/F-8348-2017; Stankovic, Ljubisa/J-8988-2013
OI Lerga, Jonatan/0000-0002-4058-8449; Stankovic,
   Isidora/0000-0003-3942-7194
CR Aggarwal HK, 2016, IEEE GEOSCI REMOTE S, V13, P442, DOI 10.1109/LGRS.2016.2518218
   [Anonymous], IM DAT 2021 COMP VIS
   Arad B, 2016, LECT NOTES COMPUT SC, V9911, P19, DOI 10.1007/978-3-319-46478-7_2
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718
   Bartyzel K, 2016, SIGNAL IMAGE VIDEO P, V10, P663, DOI 10.1007/s11760-015-0791-3
   Blumensath T, 2011, IEEE T INFORM THEORY, V57, P4660, DOI 10.1109/TIT.2011.2146550
   Boufounos PT, 2015, APPL NUMER HARMON AN, P193, DOI 10.1007/978-3-319-16042-9_7
   Brajovi M, 2020, MULTIMED TOOLS APPL, P80, DOI [10.1007/s11042-020-09998-w https://doi.org/10.1007/s11042-020-09998-w, DOI 10.1007/S11042-020-09998-WHTTPS://DOI.ORG/10.1007/S11042-020-09998-W]
   Brajovic M, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/4314527
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Carrillo RE, 2010, IEEE J-STSP, V4, P392, DOI 10.1109/JSTSP.2009.2039177
   Caselles V, 2011, HDB MATH METHOD IMAG
   Cetin AE, 2015, IEEE SIGNAL PROC MAG, V32, P120, DOI 10.1109/MSP.2015.2440051
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   Davis G, 1997, CONSTR APPROX, V13, P57, DOI 10.1007/BF02678430
   Djurovic I, 2018, IEEE SIGNAL PROC LET, V25, P447, DOI 10.1109/LSP.2018.2795554
   Djurovic I, 2017, SIGNAL IMAGE VIDEO P, V11, P753, DOI 10.1007/s11760-016-1019-x
   Djurovic I, 2017, SIGNAL PROCESS, V130, P142, DOI 10.1016/j.sigpro.2016.06.022
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430
   Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P1, DOI 10.1007/978-1-4419-7011-4
   Fadili MJ, 2009, COMPUT J, V52, P64, DOI 10.1093/comjnl/bxm055
   Figueiredo MAT, 2006, IEEE IMAGE PROC, P2633
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Jiang JL, 2014, IEEE T IMAGE PROCESS, V23, P2651, DOI 10.1109/TIP.2014.2317985
   Lebrun M, 2012, IMAGE PROCESS ON LIN, V2, P175, DOI 10.5201/ipol.2012.l-bm3d
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Ma H, 2018, MATH PROBL ENG, V2018
   Manolis L, TV L1 IMAGE DENOISIN
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002
   Ramadan ZM, 2012, CIRC SYST SIGNAL PR, V31, P1397, DOI 10.1007/s00034-011-9380-z
   Rani M, 2018, IEEE ACCESS, V6, P4875, DOI 10.1109/ACCESS.2018.2793851
   Shah AW, 2022, J KING SAUD UNIV-COM, V34, P505, DOI 10.1016/j.jksuci.2020.03.007
   Stankovic I, 2020, SIGNAL IMAGE VIDEO P, V14, P1545, DOI 10.1007/s11760-020-01694-4
   Stankovic I, 2020, IEEE ACCESS, V8, P50611, DOI 10.1109/ACCESS.2020.2979935
   Stankovic I, 2018, MULTIMED TOOLS APPL, V77, P5885, DOI 10.1007/s11042-017-4502-7
   Stankovic L, 2013, IEEE SIGNAL PROC LET, V20, P499, DOI 10.1109/LSP.2013.2252899
   Stankovic L, 2019, CIRC SYST SIGNAL PR, V38, P1206, DOI 10.1007/s00034-018-0909-2
   Stankovic L, 2021, CIRC SYST SIGNAL PR, V40, P3907, DOI 10.1007/s00034-021-01654-4
   Stankovic L, 2014, SIGNAL PROCESS, V94, P401, DOI 10.1016/j.sigpro.2013.07.002
   Stansfield SK, 2012, Monitoring and evaluation of health systems strengthening: An operational framework, V2nd, P1
   Studer C, 2012, IEEE T INFORM THEORY, V58, P3115, DOI 10.1109/TIT.2011.2179701
   Turlach BA, 2005, ALGORITHMS SOLVING L
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WRIGHT SJ, 1990, J OPTIMIZ THEORY APP, V65, P531, DOI 10.1007/BF00939565
   Yang Y, 2020, IEEE T PATTERN ANAL, V42, P521, DOI 10.1109/TPAMI.2018.2883941
   Zhang BX, 2016, J VIS COMMUN IMAGE R, V38, P814, DOI 10.1016/j.jvcir.2016.04.025
   Zhuang LN, 2020, IEEE J-STARS, V13, P1143, DOI 10.1109/JSTARS.2020.2979801
NR 56
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 44311
EP 44333
DI 10.1007/s11042-022-13192-5
EA JUN 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000805063200005
DA 2024-07-18
ER

PT J
AU Zou, WB
   Peng, YQ
   Zhang, ZY
   Tian, SS
   Li, X
AF Zou, Wenbin
   Peng, Yingqing
   Zhang, Zhengyu
   Tian, Shishun
   Li, Xia
TI RGB-D Gate-guided edge distillation for indoor semantic segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RGB-D Semantic Segmentation; Edge Distillation; Gate; Deep Learning
AB Fusing the RGB and depth information can significantly improve the performance of semantic segmentation since the depth data represents the geometric information. In this paper, we propose a novel Gate-guided Edge Distillation (GED) based approach to effectively generate edge-aware features by fusing the RGB and depth data, assisting the high-level semantic prediction. The proposed GED consists of two modules: gated fusion and edge distillation. The gated fusion module adaptively learns the relationship between RGB and depth data to generate complementary features. To address the adverse effects caused by redundant information of edge-aware features, edge distillation module enhances the semantic features of the same object while preserving the discrimination of the semantic features belonging to different objects. Besides, by using distilled edge-aware features as detailed guidance, the proposed edge-guided fusion module effectively fuses with semantic features. In addition, the complementary features are leveraged in multi-level feature fusion module to further enhance detailed information. Extensive experiments on the widely used SUN-RGBD and NYU-Dv2 datasets demonstrate that the proposed approach with ResNet-50 achieves state-of-the-art performance.
C1 [Zou, Wenbin; Peng, Yingqing; Zhang, Zhengyu; Tian, Shishun; Li, Xia] Shenzhen Univ, Coll Elect & Informat Engn, Shenzhen 518060, Peoples R China.
   [Zou, Wenbin; Peng, Yingqing; Zhang, Zhengyu; Tian, Shishun; Li, Xia] Shenzhen Univ, Guangdong Prov Key Lab Intelligent Informat Proc, Shenzhen Key Lab Adv Machine Learning & Applicat, Shenzhen 518060, Peoples R China.
C3 Shenzhen University; Shenzhen University
RP Tian, SS (corresponding author), Shenzhen Univ, Coll Elect & Informat Engn, Shenzhen 518060, Peoples R China.; Tian, SS (corresponding author), Shenzhen Univ, Guangdong Prov Key Lab Intelligent Informat Proc, Shenzhen Key Lab Adv Machine Learning & Applicat, Shenzhen 518060, Peoples R China.
EM wzouszu@sina.com; phoebe_pyq@163.com; zyzhang23@163.com;
   stian@szu.edu.cn
OI Tian, Shishun/0000-0002-7616-8382
FU National Natural Science Foundation of China [62101344, 62171294,
   61771321, 61871273, 61872429]; DEGP [2018KCXTD027]; Natural Science
   Foundation of Guangdong Province, China [2020A1515010959]; Natural
   Science Foundation of Shenzhen [JCYJ20200109105832261,
   JSGG20180508152022006, JCYJ20190808122409660]; Interdisciplinary
   Innovation Team of Shenzhen University
FX This work was supported in part by the National Natural Science
   Foundation of China under grants 62101344, 62171294, 61771321, 61871273,
   61872429, in part by the key Project of DEGP under grants 2018KCXTD027,
   in part by the Natural Science Foundation of Guangdong Province, China
   under grants 2020A1515010959, in part by Natural Science Foundation of
   Shenzhen under grants JCYJ20200109105832261, JSGG20180508152022006,
   JCYJ20190808122409660 and in part by the Interdisciplinary Innovation
   Team of Shenzhen University.
CR Acuna D, 2019, PROC CVPR IEEE, P11067, DOI 10.1109/CVPR.2019.01133
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen ZY, 2021, IEEE T IMAGE PROCESS, V30, P7012, DOI 10.1109/TIP.2020.3028289
   Cheng YH, 2017, PROC CVPR IEEE, P1475, DOI 10.1109/CVPR.2017.161
   Couprie C., 2013, ARXIV13013572, P1
   Deng L., 2019, ARXIV PREPRINT ARXIV
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Geng QC, 2021, IEEE T IMAGE PROCESS, V30, P2436, DOI 10.1109/TIP.2020.3046921
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79
   Hazirbas C, 2017, LECT NOTES COMPUT SC, V10111, P213, DOI 10.1007/978-3-319-54181-5_14
   He Y, 2017, PROC CVPR IEEE, P7158, DOI 10.1109/CVPR.2017.757
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Jiang, 2018, ARXIV PREPRINT ARXIV, DOI DOI 10.5194/ACP-2018-920
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781
   Li W, 2020, MULTIMED TOOLS APPL, V79, P35475, DOI 10.1007/s11042-019-07882-w
   Li X., 2019, P 5 WORKSH NOIS US G, P34
   Li Z, 2016, LECT NOTES COMPUT SC, V9906, P541, DOI 10.1007/978-3-319-46475-6_34
   Lin D, 2020, IEEE T PATTERN ANAL, V42, P2642, DOI 10.1109/TPAMI.2019.2923513
   Lin D, 2017, IEEE I CONF COMP VIS, P1320, DOI 10.1109/ICCV.2017.147
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Liu H, 2018, MULTIMED TOOLS APPL, V77, P22475, DOI 10.1007/s11042-018-6056-8
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Park SJ, 2017, IEEE I CONF COMP VIS, P4990, DOI 10.1109/ICCV.2017.533
   Qi XJ, 2017, IEEE I CONF COMP VIS, P5209, DOI 10.1109/ICCV.2017.556
   Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Takikawa T, 2019, IEEE I CONF COMP VIS, P5228, DOI 10.1109/ICCV.2019.00533
   Thogersen M, 2016, PATTERN RECOGN LETT, V80, P208, DOI 10.1016/j.patrec.2016.06.024
   Wang JH, 2016, LECT NOTES COMPUT SC, V9909, P664, DOI 10.1007/978-3-319-46454-1_40
   Wang WY, 2018, LECT NOTES COMPUT SC, V11215, P144, DOI 10.1007/978-3-030-01252-6_9
   Xing YJ, 2019, IEEE IMAGE PROC, P1850, DOI [10.1109/icip.2019.8803146, 10.1109/ICIP.2019.8803146]
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu ZD, 2018, LECT NOTES COMPUT SC, V11207, P400, DOI 10.1007/978-3-030-01219-9_24
   Zheng Y, 2017, MULTIMED TOOLS APPL, V76, P4427, DOI 10.1007/s11042-016-3423-1
NR 37
TC 5
Z9 5
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35815
EP 35830
DI 10.1007/s11042-021-11395-w
EA JUN 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000804560500008
DA 2024-07-18
ER

PT J
AU Abhilasha, A
   Naidu, PA
AF Abhilasha, Akkala
   Naidu, P. Annan
TI Self-boosted with dynamic semi-supervised clustering method for
   imbalanced big data classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data; Machine learning; Data mining; Imbalanced data; Self-boosted
   with dynamic semi-supervised clustering method; Hybrid associated
   nearest neighbor heuristic over-sampling; Heterogeneous weight ensemble
   classifier; Self-managed ensample optimizer
ID SELECTION
AB Big data plays a major role in the learning, manipulation, and forecasting of information intelligence. Due to the imbalance of data delivery, the learning and retrieval of information from such large datasets can result in limited classification outcomes and wrong decisions. Traditional machine learning classifiers successfully handling the imbalanced datasets still there is inadequacy in overfitting problems, training cost, and sample hardness in classification. To forecast a better classification, the research work proposed the novel "Self-Boosted with Dynamic Semi-Supervised Clustering Method". The method is initially preprocessed by constructing sample blocks using Hybrid Associated Nearest Neighbor heuristic over-sampling to replicate the minority samples and merge each copy with every sub-set of majority samples to remove the overfitting issue thus slightly reduce noise with the imbalanced data. After preprocessing the data, massive data classification requires big data space which leads to large training costs. Therefore, the approach suggested a Heterogeneous Weight Ensemble classifier which calculates data space in each data sample by its nearest neighbors and adaptive weight adjustment to resolve the training cost with unstable sample problems. Subsequently, the classification acquires poor performance due to sample hardness. Thus the work introduced a Self-Managed Ensample Optimizer which separates the bulk of specimens into the bins according to their rigidity values and provides better classification results. Consequently, the proposed work effectively classifies the imbalanced dataset with high accuracy of 99%, to obtain balanced data with improved classification results.
C1 [Abhilasha, Akkala; Naidu, P. Annan] Centurion Univ Technol & Management, Bhubaneswar, Odisha, India.
C3 Centurion University of Technology & Management
RP Abhilasha, A (corresponding author), Centurion Univ Technol & Management, Bhubaneswar, Odisha, India.
EM abhilasha0923@gmail.com; annanpaidi@gmail.com
RI Naidu, Paidi Annan/ABH-4023-2020
OI Naidu, Paidi Annan/0000-0003-4919-3686
CR [Anonymous], 2019, CLOUD COMPUTING BIG
   Basgall MJ, 2018, J COMPUT SCI TECHNOL, V18, P203, DOI 10.24215/16666038.18.e23
   Chen GC, 2019, J PROCESS CONTR, V81, P54, DOI 10.1016/j.jprocont.2019.06.011
   Elkano M, 2018, FUZZY SET SYST, V348, P75, DOI 10.1016/j.fss.2017.07.003
   Fernandez A., 2018, LEARNING IMBALANCED, P327, DOI [10.1007/978-3-319-98074-4_13, DOI 10.1007/978-3-319-98074-4_13]
   Fernández A, 2017, INT J NEURAL SYST, V27, DOI 10.1142/S0129065717500289
   Fernández A, 2017, COMPLEX INTELL SYST, V3, P105, DOI 10.1007/s40747-017-0037-9
   García S, 2018, INFORM SCIENCES, V445, P22, DOI 10.1016/j.ins.2018.03.002
   Guo T, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2406
   Hassib EM, 2020, SOFT COMPUT, V24, P5573, DOI 10.1007/s00500-019-03901-y
   Hassib EM, 2019, IEEE ACCESS, V7, P170774, DOI 10.1109/ACCESS.2019.2955983
   Komamizu T, 2020, LECT NOTES COMPUT SC, V12392, P213, DOI 10.1007/978-3-030-59051-2_14
   Koziarski M, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107262
   Leevy JL, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0151-6
   Lin WC, 2017, INFORM SCIENCES, V409, P17, DOI 10.1016/j.ins.2017.05.008
   Luengo J., 2020, Big data preprocessing, P147, DOI DOI 10.1007/978-3-030-39105-8_8
   Maldonado S, 2018, APPL SOFT COMPUT, V67, P94, DOI 10.1016/j.asoc.2018.02.051
   Patil SS, 2017, 2017 THIRD IEEE INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE AND APPLICATIONS (IEEE BIGDATASERVICE 2017), P1, DOI 10.1109/BigDataService.2017.19
   Rendón E, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041276
   Sáez JA, 2016, PATTERN RECOGN, V57, P164, DOI 10.1016/j.patcog.2016.03.012
   Triguero I, 2016, IEEE C EVOL COMPUTAT, P640, DOI 10.1109/CEC.2016.7743853
   Vuttipittayamongkol P, 2018, LECT NOTES COMPUT SC, V11314, P689, DOI 10.1007/978-3-030-03493-1_72
   Wang ZQ, 2017, TSINGHUA SCI TECHNOL, V22, P160
   Zhai JH, 2018, SOFT COMPUT, V22, P3519, DOI 10.1007/s00500-018-3085-1
   Zhai JH, 2017, INT J MACH LEARN CYB, V8, P1009, DOI 10.1007/s13042-015-0478-7
NR 25
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43083
EP 43106
DI 10.1007/s11042-022-12038-4
EA MAY 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800827600004
DA 2024-07-18
ER

PT J
AU He, K
   Peng, YL
   Liu, SG
   Li, J
AF He, Kai
   Peng, Yali
   Liu, Shigang
   Li, Jun
TI Regularized label relaxation with negative technique for image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Linear regression; Negative epsilon dragging; Manifold learning; Class
   compactness graph
ID PRESERVING PROJECTION; RECOGNITION; REPRESENTATION; REGRESSION; GRAPH
AB Multiclass classification is a challenging task in the field of pattern recognition. Recently, linear regression (LR) and a number of its variants play a key role in classification problems. However, most of these methods manage to transform the training samples into a rigorous binary label matrix, which result in little freedom to fit the samples adequately. In addition, these variants cannot obtain a robust classification performance when dealing with noisy and contaminated data. In order to address the problems, we propose a new learning framework, which holds the following extraordinary advantages. First, a negative epsilon dragging technique is introduced to release the binary label matrix, which has more freedom to fit the samples and reduces the class margins between different classes for getting robust results from noisy data Second, the manifold learning, as a regularized item, is applied to construct the class compactness graph, which can prevent the overfitting problem. In this paper, the proposed algorithm is designed based on the l(2,1)-norm loss function as it takes both superiorities of the systemic representation of l(2)-norm and the discriminative nature of the l(1)-norm. A large number of experiments show that our method has a good performance.
C1 [He, Kai; Peng, Yali] Minist Educ, Key Lab Modern Teaching Technol, Xian 710062, Peoples R China.
   [He, Kai; Peng, Yali; Liu, Shigang] Shaanxi Normal Univ, Sch Comp Sci, Xian 710119, Peoples R China.
   [Li, Jun] Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210046, Peoples R China.
C3 Shaanxi Normal University; Nanjing Normal University
RP Peng, YL (corresponding author), Minist Educ, Key Lab Modern Teaching Technol, Xian 710062, Peoples R China.; Peng, YL (corresponding author), Shaanxi Normal Univ, Sch Comp Sci, Xian 710119, Peoples R China.
EM pengyl@snnu.edu.cn
FU National Natural Science Foundation of China [61873155]; Transfer and
   Promotion Plan of Scientific and Technological Achievements of Shaanxi
   Province [2019CGXNG-019]; National Natural Science Foundation of Shaanxi
   Province [2018JM6050]
FX This work is supported by the National Natural Science Foundation of
   China (No.61873155), Transfer and Promotion Plan of Scientific and
   Technological Achievements of Shaanxi Province (No.2019CGXNG-019), the
   National Natural Science Foundation of Shaanxi Province (No.2018JM6050).
CR Bemporad A, 2016, IEEE T AUTOMAT CONTR, V61, P1111, DOI 10.1109/TAC.2015.2459211
   Cao JH, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/287816
   Cao JW, 2015, J FRANKLIN I, V352, P4528, DOI 10.1016/j.jfranklin.2015.07.002
   Chen CH, 2016, MATH PROGRAM, V155, P57, DOI 10.1007/s10107-014-0826-5
   Cohen G., 2017, SMAI J. Com-put. Math, V3, P181, DOI DOI 10.5802/SMAI-JCM.24
   Davis D, 2017, MATH OPER RES, V42, P783, DOI 10.1287/moor.2016.0827
   Deng YJ, 2018, IEEE GEOSCI REMOTE S, V15, P277, DOI 10.1109/LGRS.2017.2786223
   Du B, 2017, IEEE T MULTIMEDIA, V19, P67, DOI 10.1109/TMM.2016.2608780
   Du L, 2015, INT C ART INTELL
   Fang XZ, 2015, IEEE T IMAGE PROCESS, V24, P2760, DOI 10.1109/TIP.2015.2425545
   Fernández-Delgado M, 2014, J MACH LEARN RES, V15, P3133
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   He K, 2020, NEURAL PROCESS LETT, V51, P2629, DOI 10.1007/s11063-020-10219-6
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Huang XY, 2018, IEEE T IMAGE PROCESS, V27, P2966, DOI 10.1109/TIP.2018.2815759
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740
   Lai ZH, 2014, IEEE T CIRC SYST VID, V24, P1651, DOI 10.1109/TCSVT.2014.2305495
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Leski J, 2003, PATTERN RECOGN LETT, V24, P2281, DOI 10.1016/S0167-8655(03)00054-0
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu ZH, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2020.107456
   Liu ZH, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105768
   Luo D, 2010, INT C DATA MINING
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Nie F, 2010, NEURAL INF PROCESS S
   Nie F, 2013, INT JOINT C ART INT
   Peng YL, 2018, PATTERN RECOGN LETT, V116, P170, DOI 10.1016/j.patrec.2018.10.016
   Peng YL, 2018, IEEE ACCESS, V6, P488, DOI 10.1109/ACCESS.2017.2767907
   Raghavendra U, 2016, APPL SOFT COMPUT, V46, P151, DOI 10.1016/j.asoc.2016.04.036
   Song K, 2017, AAAI CONF ARTIF INTE, P2555
   Sun L, 2016, PARTIAL LEAST SQUARE, P4362
   Tang YC, 2007, IEEE ACM T COMPUT BI, V4, P365, DOI 10.1109/TCBB.2007.1028
   Wang WQ, 2018, IEEE T SIGNAL PROCES, V66, P2724, DOI 10.1109/TSP.2018.2816568
   Wen JJ, 2016, PATTERN RECOGN, V60, P515, DOI 10.1016/j.patcog.2016.06.006
   Xiang SM, 2012, IEEE T NEUR NET LEAR, V23, P1738, DOI 10.1109/TNNLS.2012.2212721
   Xu Y, 2015, NEUROCOMPUTING, V168, P566, DOI 10.1016/j.neucom.2015.05.070
   Xu Y, 2014, IEEE T CYBERNETICS, V44, P1950, DOI 10.1109/TCYB.2014.2300175
   Xu Y, 2014, IEEE T CYBERNETICS, V44, P1738, DOI 10.1109/TCYB.2013.2293391
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Zhang Y, 2018, PATTERN RECOGN, V76, P662, DOI 10.1016/j.patcog.2017.09.043
   Zhang Z, 2017, IEEE T IMAGE PROCESS, V26, P1607, DOI 10.1109/TIP.2017.2654163
   Zhu B, 2018, NATURE, V555, P487, DOI 10.1038/nature25988
NR 43
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 41131
EP 41149
DI 10.1007/s11042-022-12417-x
EA MAY 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000797297600002
DA 2024-07-18
ER

PT J
AU Mataei, B
   Nejad, FM
   Zakeri, H
AF Mataei, Behrouz
   Nejad, Fereidoon Moghadas
   Zakeri, Hamzeh
TI An improved multiresolution technique for pavement texture image
   evaluating
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pavement surface drainage; Pavement classification; Image processing;
   Enhanced shearlet transform
ID SKID RESISTANCE; SHEARLET TRANSFORM; PARSEVAL FRAMES; REPRESENTATIONS;
   ACQUISITION; CONCRETE; WEATHER; DESIGN
AB The texture assessment of pavement surface plays an important role in nearly all Pavement Management System (PMS). The Surface drainage, which related to the surface texture condition and plays a vital role in pavement safety and accident rate reduction, is a generally neglected part in these systems. The present study conducted to present an image-based method for assessment of the surface drainage capability of pavements. The presented method consists of three steps: image preprocessing, feature extraction and evaluation of pavement surface drainage. In the first step, a Modified Shearlet Transform (MST) with specific filter and parameters is presented for image denoising and then a set of morphological features are extracted to present proper evaluation parameters for surface drainage assessment. Finally, a method based on feature selection for surface drainage evaluation proposed and a classification for the pavements based on surface drainage quality by the C5.0 algorithm conducted considering the extracted parameters. Experimental results demonstrate that the MST is fast and efficient for evaluation of pavement surface drainage.
C1 [Mataei, Behrouz; Nejad, Fereidoon Moghadas; Zakeri, Hamzeh] Amirkabir Univ Technol, Dept Civil & Environm Engn, 424 Hafez Ave, Tehran, Iran.
C3 Amirkabir University of Technology
RP Mataei, B (corresponding author), Amirkabir Univ Technol, Dept Civil & Environm Engn, 424 Hafez Ave, Tehran, Iran.
EM behrouz.mataei@aut.ac.ir; moghadas@aut.ac.ir; h-zakeri@aut.ac.ir
RI Mataei, Behrouz/HZJ-0209-2023; Moghadas Nejad, Fereidoon/M-2828-2018
OI Moghadas Nejad, Fereidoon/0000-0003-3830-4555; ,
   behrouz/0000-0002-4232-9811
CR Andersson AK, 2011, ACCIDENT ANAL PREV, V43, P284, DOI 10.1016/j.aap.2010.08.025
   Asi IM, 2007, BUILD ENVIRON, V42, P325, DOI 10.1016/j.buildenv.2005.08.020
   Baqersad M, 2017, ADV MATER SCI ENG, V2017, DOI 10.1155/2017/9493408
   Brijs T, 2008, ACCIDENT ANAL PREV, V40, P1180, DOI 10.1016/j.aap.2008.01.001
   Candès EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Do MT, 2000, TRANSPORT RES REC, P66
   Du YC, 2022, INT J PAVEMENT ENG, V23, P1851, DOI 10.1080/10298436.2020.1825712
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Ergun M, 2005, J TRANSP ENG-ASCE, V131, P311, DOI 10.1061/(ASCE)0733-947X(2005)131:4(311)
   Flintsch GW, 2003, TRANSPORT RES REC, P168, DOI 10.3141/1860-19
   Gibert X, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-64
   Guo K, 2013, MATH MODEL NAT PHENO, V8, P82, DOI 10.1051/mmnp/20138106
   Guo K, 2007, SIAM J MATH ANAL, V39, P298, DOI 10.1137/060649781
   Guo KH, 2012, J FOURIER ANAL APPL, V18, P488, DOI 10.1007/s00041-011-9209-y
   Guo KH, 2012, SIAM J MATH ANAL, V44, P851, DOI 10.1137/100813397
   Guo KH, 2009, SIAM J IMAGING SCI, V2, P959, DOI 10.1137/080741537
   Hall J. W., 2009, Guide for pavement friction
   Hou B, 2012, IEEE J-STARS, V5, P809, DOI 10.1109/JSTARS.2012.2196680
   Kim JK, 1999, IEEE T MED IMAGING, V18, P231, DOI 10.1109/42.764896
   Kutyniok G, 2012, APPL NUMER HARMON AN, P1, DOI 10.1007/978-0-8176-8316-0
   Kutyniok G., 2005, Wavelets XI, V5914, P254, DOI DOI 10.1117/12.613494
   Kutyniok G, 2016, ACM T MATH SOFTWARE, V42, DOI 10.1145/2740960
   Kutyniok G, 2012, SIAM J IMAGING SCI, V5, P1291, DOI 10.1137/110854497
   Li QJ, 2019, J TRANSP ENG B-PAVE, V145, DOI 10.1061/JPEODX.0000105
   Liang J, 2020, MEASUREMENT, V166, DOI 10.1016/j.measurement.2020.108265
   Masad E., 2010, Field evaluation of asphalt mixture skid resistance and its relationship to aggregate characteristics (No. 0-5627-3)
   Mataei, 2019, U.S. Patent Application, Patent No. [15/927,627, 15927627]
   Mataei B, 2019, ARCH COMPUT METHOD E, V26, P143, DOI 10.1007/s11831-017-9230-7
   Mataei B, 2018, AUTOMAT CONSTR, V86, P240, DOI 10.1016/j.autcon.2017.11.010
   Mataei Behrouz., 2016, OPEN J CIVIL ENG, V60, P537, DOI [10.4236/ojce.2016.64046, DOI 10.4236/OJCE.2016.64046]
   Moghadas Nejad F, 2016, AUTOMAT CONSTR, V71, P414, DOI 10.1016/j.autcon.2016.08.003
   Murphy JM, 2016, IEEE T GEOSCI REMOTE, V54, P1685, DOI 10.1109/TGRS.2015.2487457
   Hoang ND, 2019, ENG COMPUT-GERMANY, V35, P487, DOI 10.1007/s00366-018-0611-9
   Ong GP, 2005, TRANSPORT RES REC, P166, DOI 10.3141/1905-19
   Mayora JMP, 2009, ACCIDENT ANAL PREV, V41, P881, DOI 10.1016/j.aap.2009.05.004
   Pelloli R., 1977, TRANSPORTATION RES R, P27
   Prowell BD, 2005, TRANSPORT RES REC, P88, DOI 10.3141/1929-11
   Ranjbar S, 2022, INT J PAVEMENT ENG, V23, P4080, DOI 10.1080/10298436.2021.1932881
   Ranjbar S, 2021, INT J PAVEMENT RES T, V14, P437, DOI 10.1007/s42947-020-0098-9
   Savkoor A. R., 1991, TRIBOLOGY SERIES, V18, P213, DOI [10.1016/S0167-8922(08)70137-8, DOI 10.1016/S0167-8922(08)70137-8]
   Starck J.-L., 2010, Sparse image and signal processing: wavelets, curvelets, morphological diversity, DOI DOI 10.1017/CBO9780511730344
   Wang WF, 2011, TRANSPORT RES C-EMER, V19, P682, DOI 10.1016/j.trc.2010.12.001
   Xu CC, 2013, J SAFETY RES, V46, P135, DOI 10.1016/j.jsr.2013.04.007
   Xu K, 2015, IMAGE VISION COMPUT, V35, P23, DOI 10.1016/j.imavis.2015.01.001
   Yang HY, 2014, NEURAL NETWORKS, V57, P152, DOI 10.1016/j.neunet.2014.06.007
   Yi S, 2009, IEEE T IMAGE PROCESS, V18, P929, DOI 10.1109/TIP.2009.2013082
   Zakeri H, 2017, ARCH COMPUT METHOD E, V24, P935, DOI 10.1007/s11831-016-9194-z
   Zakeri H, 2016, AUTOMAT CONSTR, V72, P211, DOI 10.1016/j.autcon.2016.09.002
   Zhan Y, 2020, J TRANSP ENG B-PAVE, V146, DOI 10.1061/JPEODX.0000187
   Zhu L, 2019, CONSTR BUILD MATER, V224, P534, DOI 10.1016/j.conbuildmat.2019.07.007
   Zhu XY, 2021, TRIBOL INT, V153, DOI 10.1016/j.triboint.2020.106589
NR 52
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 3007
EP 3031
DI 10.1007/s11042-022-13112-7
EA MAY 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000795177900009
DA 2024-07-18
ER

PT J
AU Thomas, R
   Zhang, WS
AF Thomas, Rachel
   Zhang, Wenshu
TI Real-time fracturing in video games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video game destruction; Real-time mesh fracturing; Voronoi diagrams
AB Destruction in video games traditionally use pre-fracturing techniques to efficiently swap out game objects at run-time, which requires artists to create multiple models in various states of destruction. Real-time methods require less design time and can produce more realistic results but often come at a cost of performance. If real-time methods can perform at similar levels as tradition pre-fracturing means, this could increase the current standards of realistic destruction in video games. This paper explores and implements real-time fracturing techniques, comparing these to traditional pre-fracturing methods in terms of visual realism and performance. The results of the implementation were then distributed in an online questionnaire, to view how participants perceived the differences of both techniques and whether the visual or performance aspects affected their preferences of one method over the other.
C1 [Thomas, Rachel] Cardiff Metropolitan Univ, Sch Technol, Cardiff, Wales.
   [Zhang, Wenshu] Cardiff Metropolitan Univ, EUREKA Robot Ctr Sch Technol, Cardiff, Wales.
C3 Cardiff Metropolitan University; Cardiff Metropolitan University
RP Zhang, WS (corresponding author), Cardiff Metropolitan Univ, EUREKA Robot Ctr Sch Technol, Cardiff, Wales.
EM WZhang@cardiffmet.ac.uk
RI Thomas, Rachel/JPK-1292-2023
OI Zhang, Wenshu/0000-0003-0776-7709
CR [Anonymous], 2020, Epic Games
   Battlefield Wiki, 2019, DESTR
   BOWYER A, 1981, COMPUT J, V24, P162, DOI 10.1093/comjnl/24.2.162
   Coumans E, 2011, ACM SIGGRAPH 2011 OV
   de Berg M., 2008, DELAUNAY TRIANGULATI, P191
   DICE, 2011, BATTL 3 VID GAM PLAY
   Gronberg A, 2017, REAL TIME MESH DESTR
   L'Heureux J, 2016, RAINBOW 6 SIEGE
   Langetepe Elmar., 2006, Geometric Data Structures for Computer Graphics
   Ledoux H, 2007, ISVD 2007: The 4th International Symposium on Voronoi Diagrams in Science and Engineering 2007, Proceedings, P117
   LucasArts, 2008, STAR WARS FORC UNL
   Marschner S., 2018, Fundamentals of Computer Graphics
   Middleditch AE, 1988, THEORETICAL FDN COMP, P211
   Müller M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461934
   Najim YAH, 2018, 2018 3DTV C TRUE VIS, P1
   Nielsen JK, 2013, MODELLING OBJECTS SI
   Nordic THQ, 2016, RED FACT
   Okabe A., 1992, Spatial Tessellations: Concepts and Applications of Voronoi Diagrams
   Parker E.G., 2009, PROC S COMP ANIM, P165, DOI DOI 10.1145/1599470.1599492.
   Rainbow Six Wiki, 2020, BULL PEN
   Red Faction Wiki, 2020, GEOMOD
   Ronnegren J, 2020, REAL TIME MESH FRACT
   Tht M, 2018, REAL TIME CAVE DESTR
   Ubisoft, 2015, Dijital Oyun
   Van Gemert J.C., 2011, ACM International Conference on Multimedia Retrieval, P1
   WATSON DF, 1981, COMPUT J, V24, P167, DOI 10.1093/comjnl/24.2.167
NR 26
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4709
EP 4734
DI 10.1007/s11042-022-13049-x
EA MAY 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000795177900013
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, SL
   Chen, SZ
   Zhang, JF
   Cai, ZJ
   Hu, LH
AF Zhang, Sulan
   Chen, Songzan
   Zhang, Jifu
   Cai, Zhenjiao
   Hu, Lihua
TI Image annotation of ancient chinese architecture based on visual
   attention mechanism and GCN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ancient Chinese architecture; Image annotation; Roof ridge decoration;
   Visual attention mechanism; Convolution neural network; Graph
   convolution network
AB Ancient Chinese architecture(ACA), especially like roof ridge decoration, vividly exhibits Chinese civilization and the typical, accurate image semantics can well reflect the historical style of ACA at that time. However, the current research on the 2D image annotation method of ACA lacks the annotation of historical and cultural information(such as dynasties, regions, etc.). In addition, with the enrichment of ACA labels, the number of irrelevant labels will increase. To solve these problems, we propose an ACA image annotation method based on visual attention mechanism and graph convolutional network (GCN). Firstly, according to the uniqueness of the roof ridge decoration of ACA, we introduce the visual attention mechanism into the convolution neural network (CNN) to focus on the roof ridge decoration area and the corresponding image features are extracted. Secondly, to avoid the output of irrelevant labels, we construct a correlation matrix in the GCN to transfer the correlation between the labels of ACA and then obtain the label-related classifier. Finally, the classifier is applied to the extracted image features for multi-label loss training. Experiments on six types of ACA datasets demonstrate that the proposed method can effectively improve the annotation accuracy and enrich the semantic information of ACA.
C1 [Zhang, Sulan; Chen, Songzan; Zhang, Jifu; Cai, Zhenjiao; Hu, Lihua] Taiyuan Univ Sci & Technol, Sch Comp Sci & Technol, Taiyuan 030024, Shanxi, Peoples R China.
C3 Taiyuan University of Science & Technology
RP Zhang, SL (corresponding author), Taiyuan Univ Sci & Technol, Sch Comp Sci & Technol, Taiyuan 030024, Shanxi, Peoples R China.
EM zhsulan@126.com
FU Natural Science Foundation of Shanxi Province, China [202103021224285];
   Key Scientific and Technological Innovation Team of Shanxi Province,
   China [201805D131007]
FX This work was supported by the Natural Science Foundation of Shanxi
   Province, China (Grant No. 202103021224285) and the Key Scientific and
   Technological Innovation Team of Shanxi Province, China (201805D131007)
   for Big Data Analysis and Parallel Computing.
CR [Anonymous], 2014, ATTENTION FINE GRAIN
   Bacci G, 2019, INT ARCH PHOTOGRAMM, V42-2, P121, DOI 10.5194/isprs-archives-XLII-2-W11-121-2019
   Battaglia P.W., 2016, ARXIV
   Chaudhari S, 2019, ARXIV 190402874
   Chen JJ, 2020, ELECTRON LIBR, V38, P769, DOI 10.1108/EL-02-2020-0039
   Chen Z., 2019, IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
   Croce V., 2020, Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci.-ISPRS Arch, DOI [10.5194/isprs-archives-XLIII-B2-2020-829-2020, DOI 10.5194/ISPRS-ARCHIVES-XLIII-B2-2020-829-2020]
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dutta A, 2018, MULTIMED TOOLS APPL, V77, P31991, DOI 10.1007/s11042-018-6247-3
   Fu J, 2017, IEEE C COMPUTER VISI
   Gong Y, 2013, COMPUTER SCI, V1312
   Hamaguchi, 2017, P 26 INT JOINT C ART
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   Jin C, 2019, MULTIMED TOOLS APPL, V78, P11815, DOI 10.1007/s11042-018-6742-6
   Kipf T, 2017, ARXIV 160902907
   Li L, 2017, ISPRS INT J GEO-INF, V6, DOI 10.3390/ijgi6050132
   Li Y, 2017, IEEE C COMPUTER VISI
   Liu J, 2016, ACM J COMPUT CULT HE, V9, DOI 10.1145/2835495
   Liu N, 2016, IEEE C COMPUTER VISI
   Lowe, P 7 IEEE INT C COMP, V2
   Manuel A., 2016, 14 EUROGRAPHICS WORK
   Messaoudi T, 2018, J CULT HERIT, V29, P100, DOI 10.1016/j.culher.2017.05.017
   [聂瑶瑶 Nie Yaoyao], 2020, [计算机辅助设计与图形学学报, Journal of Computer-Aided Design & Computer Graphics], V32, P437
   Peng YX, 2018, IEEE T IMAGE PROCESS, V27, P1487, DOI 10.1109/TIP.2017.2774041
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Shuman DI, 2013, IEEE SIGNAL PROC MAG, V30, P83, DOI 10.1109/MSP.2012.2235192
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song XP, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11110245
   Stefani C., 2013, ACM J COMPUT CULT HE, V6, pArticl, DOI 10.1145/2499931.2499934
   Stefani C, 2014, J CULT HERIT, V15, P1, DOI 10.1016/j.culher.2013.01.011
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Uijlings J., 2013, INT J COMPUT VISION, V104
   Wang L, 2018, P 27 INT JOINT C ART
   Wang W, 2018, IEEECVF C COMPUTER V
   Weston J, 2011, IJCAI
   Xu H, 2011, HUAZHONG ARCHITECTUR
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
   Zhang P, 2017, IEEE INT C COMPUTER
   Zhou B, 2016, IEEE C COMPUTER VISI
   Zhou J., 2018, arXiv 1812.08434
   Zhou Y, 2018, INT CONF 3D VISION, P523, DOI 10.1109/3DV.2018.00066
   Zhu PP, 2020, IEEE T GEOSCI REMOTE, V58, P4047, DOI 10.1109/TGRS.2019.2960466
NR 43
TC 5
Z9 5
U1 5
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 39963
EP 39980
DI 10.1007/s11042-022-12618-4
EA MAY 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000791088200003
DA 2024-07-18
ER

PT J
AU Ha, S
   Kim, G
   Kwon, J
AF Ha, Suhyeon
   Kim, Guisik
   Kwon, Junseok
TI Style transfer with target feature palette and attention coloring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-Photorealistic rendering (NPR); Style transfer
ID TEXTURE SYNTHESIS
AB Style transfer has attracted a lot of attentions, as it can change a given image into one with splendid artistic styles while preserving the image structure. However, conventional approaches easily lose image details and tend to produce unpleasant artifacts during style transfer. In this paper, to solve these problems, a novel artistic stylization method with target feature palettes is proposed, which can transfer key features accurately. Specifically, our method contains two modules, namely feature palette composition (FPC) and attention coloring (AC) modules. The FPC module captures representative features based on K-means clustering and produces a feature target palette. The following AC module calculates attention maps between content and style images, and transfers colors and patterns based on the attention map and the target palette. These modules enable the proposed stylization to focus on key features and generate plausibly transferred images. Thus, the contributions of the proposed method are to propose a novel deep learning-based style transfer method and present target feature palette and attention coloring modules, and provide in-depth analysis and insight on the proposed method via exhaustive ablation study. Qualitative and quantitative results show that our stylized images exhibit state-of-the-art performance, with strength in preserving core structures and details of the content image.
C1 [Ha, Suhyeon; Kim, Guisik; Kwon, Junseok] Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
C3 Chung Ang University
RP Kwon, J (corresponding author), Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
EM tngus3752@gmail.com; specialre@naver.com; jskwon@cau.ac.kr
OI kwon, junseok/0000-0001-9526-7549; Kim, Guisik/0000-0002-8254-0881
FU Institute of Information communications Technology Planning Evaluation
   (IITP) - Korea government(MSIT) [2021-0-01341]; Ministry of Culture,
   Sports and Tourism; Korea Creative Content Agency [R2021040032]
FX This work was partly supported by Institute of Information
   communications Technology Planning Evaluation (IITP) grant funded by the
   Korea government(MSIT) (No.2021-0-01341, Artificial Intelligence
   Graduate School Program(ChungAng university)) and partly by the Ministry
   of Culture, Sports and Tourism and Korea Creative Content Agency under
   Project R2021040032.
CR Chen TC, 2017, AGEING SOC, V37, P1798, DOI 10.1017/S0144686X16000623
   Cheng G, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3081421
   Cheng MM, 2020, IEEE T IMAGE PROCESS, V29, P909, DOI 10.1109/TIP.2019.2936746
   Deng YY, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2719, DOI 10.1145/3394171.3414015
   Dumoulin V., 2016, A guide to convolution arithmetic for deep learning[J
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Heeger DJ, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC648
   Hong K, 2021, ICCV
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   King DB, 2015, ACS SYM SER, V1214, P1
   Li C, 2016, ARXIV PREPRINT ARXIV
   Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272
   Li YT, 2017, ADV NEUR IN, V30
   Liang L, 2001, ACM T GRAPHIC, V20, P127, DOI 10.1145/501786.501787
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S., 2021, ICCV
   Liu X.C., 2017, Proceedings of the Symposium on Non-Photorealistic Animation and Rendering, page, P1
   Nichol K, 2016, Painter by numbers
   Park DY, 2019, PROC CVPR IEEE, P5873, DOI 10.1109/CVPR.2019.00603
   Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983
   Qian XL, 2021, IEEE SIGNAL PROC LET, V28, P180, DOI 10.1109/LSP.2021.3049997
   Ramamonjisoa M, 2021, PROC CVPR IEEE, P11084, DOI 10.1109/CVPR46437.2021.01094
   Sheng L, 2018, PROC CVPR IEEE, P8242, DOI 10.1109/CVPR.2018.00860
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tomei M, 2019, PROC CVPR IEEE, P5842, DOI 10.1109/CVPR.2019.00600
   Ulyanov D, 2016, PR MACH LEARN RES, V48
   Ulyanov D, 2017, PROC CVPR IEEE, P4105, DOI 10.1109/CVPR.2017.437
   Wang H, 2020, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR42600.2020.00193
   Wang ZZ, 2020, PROC CVPR IEEE, P5041, DOI 10.1109/CVPR42600.2020.00509
   Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009
   Wu Z, 2020, AAAI
   Yao Y, 2019, PROC CVPR IEEE, P1467, DOI 10.1109/CVPR.2019.00156
   Zhang H., 2017, MULTISTYLE GENERATIV
   Zhang YL, 2019, IEEE I CONF COMP VIS, P5942, DOI 10.1109/ICCV.2019.00604
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 39
TC 0
Z9 0
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39675
EP 39694
DI 10.1007/s11042-022-13123-4
EA MAY 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000789768900004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Sau, PC
   Bansal, A
AF Sau, Paresh Chandra
   Bansal, Atul
TI A novel diabetic retinopathy grading using modified deep neural network
   with segmentation of blood vessels and retinal abnormalities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic retinopathy grading; Deep neural network; Optic disc removal;
   Blood vessel segmentation; Abnormality segmentation; Fitness-based newly
   updated grasshopper optimization algorithm
ID OPTIC DISC; BOUNDARY EXTRACTION; ALGORITHM; LOCALIZATION; OPTIMIZATION;
   CLASSIFICATION
AB This paper proposes a new DR grading for solving the aforementioned problems. The initial process of the proposed model is the pre-processing, which is performed by median filtering. The segmentation of blood vessels and retinal abnormalities like exudates, microaneurysm, and hemorrhages is also done for grading the DR. Before initiating the segmentation of those components, optic disc removal is opted using the open-close watershed transform. Once the optic disc is removed, adaptive active contour methodology is used for performing the blood vessel segmentation. As a major contribution, the threshold value of the active contour method is optimized using proposed FNU-GOA with the aim of maximizing the accuracy of the blood vessel segmented images. Further, the retinal abnormalities like exudates, microaneurysm, and hemorrhages are performed by Otsu thresholding with morphological operation. From both segmented blood vessels and retinal abnormalities, the features like "Gray-Level Co-occurrence Matrix (GLCM)", "area of Region of Interest (RoI)" and "Local Ternary Pattern (LTP)" are extracted. These features are subjected to the Modified Deep Neural Network (MDNN) for grading the DR. This MDNN focuses on solving the over fitting problems of DNN with the aim of maximizing the accuracy in terms of grading. The improvement of adaptive active contour-based blood vessel segmentation and MDNN-based grading is progressively dependent on the proposed Fitness-based Newly Updated Grasshopper Optimization Algorithm (FNU-GOA). This new algorithm improves the efficiency of grading with better convergence results. The experimental results show promising results as compared with other systems when analyzing various performance measures.
C1 [Sau, Paresh Chandra; Bansal, Atul] GLA Univ, ECE Dept, Mathura, India.
C3 GLA University
RP Sau, PC (corresponding author), GLA Univ, ECE Dept, Mathura, India.
EM paresh.chandra@gla.ac.in; atul.bansal@gla.ac.in
CR A. A. of Ophthalmology. The Eye M.D. Association, 2002, INT CLIN DIAB RET DI
   AbdelMaksoud E, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.104039
   Akhade SB, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES)
   Akram MU, 2014, COMPUT BIOL MED, V45, P161, DOI 10.1016/j.compbiomed.2013.11.014
   Alyoubi W.L., 2020, INFORM MED UNLOCKED, DOI 10.1016/j.imu.2020.100377
   Amalia R, J PHYS, V1722
   Anitha A, 2021, INT J BIOMED ENG TEC, V34
   Araújo T, 2020, MED IMAGE ANAL, V63, DOI 10.1016/j.media.2020.101715
   Arora S, 2019, IEEE ACCESS, V7, P26343, DOI 10.1109/ACCESS.2019.2897325
   Basit A, 2015, APPL OPTICS, V54, P3440, DOI 10.1364/AO.54.003440
   Bharkad S, 2017, BIOMED SIGNAL PROCES, V31, P483, DOI 10.1016/j.bspc.2016.09.009
   Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P2350, DOI 10.1109/TIP.2021.3052069
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P4296, DOI 10.1109/TIP.2020.2968250
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P1090, DOI 10.1109/TIP.2019.2934350
   de Bruijne M, 2016, MED IMAGE ANAL, V33, P94, DOI 10.1016/j.media.2016.06.032
   de la Calleja J, 2014, LECT NOTES COMPUT SC, V8669, P110, DOI 10.1007/978-3-319-10840-7_14
   de la Torre J, 2020, NEUROCOMPUTING, V396, P465, DOI 10.1016/j.neucom.2018.07.102
   Esmaeili M, 2012, PATTERN RECOGN, V45, P2832, DOI 10.1016/j.patcog.2012.01.002
   Faust O, 2012, J MED SYST, V36, P145, DOI 10.1007/s10916-010-9454-7
   Fiandono, 2018, KINETIK GAME TECHNOL, V3
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P1597, DOI 10.1109/TMI.2018.2791488
   Gadekallu TR, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01963-7
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Haneda S, 2010, NIPPON RINSHO JAPANE
   HARDING SP, 1995, BMJ-BRIT MED J, V311, P1131, DOI 10.1136/bmj.311.7013.1131
   Hassan G, 2015, 2015 11TH INTERNATIONAL COMPUTER ENGINEERING CONFERENCE (ICENCO), P290, DOI 10.1109/ICENCO.2015.7416364
   He AL, 2021, IEEE T MED IMAGING, V40, P143, DOI 10.1109/TMI.2020.3023463
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Jayanthi J, 2021, J MED IMAG HEALTH IN, V11, P803, DOI 10.1166/jmihi.2021.3362
   Kipli K, 2018, INT J ENG TECHNOL, P7
   Lu SJ, 2011, IEEE T MED IMAGING, V30, P2126, DOI 10.1109/TMI.2011.2164261
   Madhumitha S, 2018, QUANTITATIVE ANAL MA, V114
   Martinez-Murcia FJ, 2021, NEUROCOMPUTING, V452, P424, DOI 10.1016/j.neucom.2020.04.148
   Megalai M, 2019, INT J ADV INTELL PAR, V14
   Panda R, 2017, BIOCYBERN BIOMED ENG, V37, P466, DOI 10.1016/j.bbe.2017.05.008
   Porwal P, 2020, MED IMAGE ANAL, V59, DOI 10.1016/j.media.2019.101561
   Pratt H, 2016, PROCEDIA COMPUT SCI, V90, P200, DOI 10.1016/j.procs.2016.07.014
   Pundikal M., 2020, INT J INTELL ENG SYS, V13, P208
   Raghavendra U, 2018, INFORM SCIENCES, V441, P41, DOI 10.1016/j.ins.2018.01.051
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sabanayagam C, 2019, LANCET DIABETES ENDO, V7, P140, DOI 10.1016/S2213-8587(18)30128-1
   Sarathi MP, 2016, BIOMED SIGNAL PROCES, V25, P108, DOI 10.1016/j.bspc.2015.10.012
   Saremi S, 2017, ADV ENG SOFTW, V105, P30, DOI 10.1016/j.advengsoft.2017.01.004
   Sayres R, 2019, OPHTHALMOLOGY, V126, P552, DOI 10.1016/j.ophtha.2018.11.016
   Sekou TB, 2019, ARXIVABS190403892
   Seoud L., 2015, P OPHTH MED IM AN IN
   Shaban M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0233514
   Sharma, 2020, INTJ INNOV TECHNOL E, V9, P1771
   Wang XH, 2021, IEEE T IMAGE PROCESS, V30, P458, DOI 10.1109/TIP.2020.3037470
   Welfer D, 2013, PATTERN RECOGN LETT, V34, P476, DOI 10.1016/j.patrec.2012.12.011
   Wu Z., 2020, COMPUTER VISION PATT
   Wu Z, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101936
   Zhang W, 2019, KNOWL-BASED SYST, V175, P12, DOI 10.1016/j.knosys.2019.03.016
   Zhang Y, 2008, MEDIVIS 2008: FIFTH INTERNATIONAL CONFERENCE BIOMEDICAL VISUALIZATION - INFORMATION VISUALIZATION IN MEDICAL AND BIOMEDICAL INFORMATICS, PROCEEDINGS, P71, DOI 10.1109/MediVis.2008.12
   Zou BJ, 2018, COMPUT GRAPH-UK, V70, P281, DOI 10.1016/j.cag.2017.07.031
NR 55
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39605
EP 39633
DI 10.1007/s11042-022-13056-y
EA APR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000789073100002
DA 2024-07-18
ER

PT J
AU Fan, M
   Cai, ZY
   Zhang, TF
   Wang, BY
AF Fan, Min
   Cai, Ziyun
   Zhang, Tengfei
   Wang, Baoyun
TI A survey of deep domain adaptation based on label set classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Domain adaptation; Transfer learning; Label set
ID NETWORK; KERNEL
AB Traditional machine learning requires good tags to obtain excellent performance, while manual tagging usually consumes a lot of time and money. Due to the influence of domain shift, using the trained model on the source domain directly on the target domain is not good. Domain adaptation is used to solve the above problems. The deep domain adaptation method uses deep neural networks to complete domain adaptation. This article has carried out a comprehensive review of the deep domain adaptation method of image classification. The main contributions are the following four aspects. Firstly, we divided the deep domain adaptation into several categories based on the label set of the source domain and the target domain. Secondly, we summarized various methods of Closed-set domain adaptation. Thirdly, we discussed current methods of multi-source domain adaptation. Finally, we discussed future research directions, challenges, and possible solutions.
C1 [Fan, Min; Cai, Ziyun; Zhang, Tengfei; Wang, Baoyun] Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing 210023, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Cai, ZY (corresponding author), Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing 210023, Peoples R China.
EM fanmin0330@163.com; caiziyun@163.com; tfzhang@126.com;
   bywang@njupt.edu.cn
RI Min, Fan/AAC-8566-2020
OI Min, Fan/0000-0002-3290-1036; Cai, Ziyun/0000-0001-6822-915X
FU Natural Science Foundation of China [62006127, 61833011, 62073173];
   NUPTSF [NY218120, NY220021]; Jiangsu Shuang-Chuang Project
   [CZ005SC19019]; Nanjing Overseas Innovation Project [RK005NLX20001];
   National Science Foundation of Jiangsu Province, China [BK20191376,
   BK20190728]
FX This work is partly supported by the Natural Science Foundation of China
   (Grant No. 62006127, 61833011 and 62073173), partly supported by NUPTSF
   under Grant NY218120 and Grant NY220021, and partly supported by Jiangsu
   Shuang-Chuang Project under Grant CZ005SC19019 and Nanjing Overseas
   Innovation Project Grant RK005NLX20001. It is also supported by National
   Science Foundation of Jiangsu Province, China (Grant No. BK20191376 and
   BK20190728).
CR Ahmed A, 2021, MULTIMED TOOLS APPL, V80, P20759, DOI 10.1007/s11042-021-10760-z
   Meda-Campaña JA, 2018, IEEE ACCESS, V6, P31968, DOI 10.1109/ACCESS.2018.2846483
   Alyafeai Z, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112951
   Aquino G, 2020, IEEE ACCESS, V8, P46324, DOI 10.1109/ACCESS.2020.2979141
   Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Bo Fu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P567, DOI 10.1007/978-3-030-58555-6_34
   Bousmalis K, 2016, ADV NEUR IN, V29
   Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18
   Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57
   Busto PP, 2017, IEEE I CONF COMP VIS, P754, DOI 10.1109/ICCV.2017.88
   Cai ZP, 2021, IEEE T MOBILE COMPUT, V20, P2576, DOI 10.1109/TMC.2020.2987881
   Cai ZY, 2018, IEEE T IMAGE PROCESS, V27, P2471, DOI 10.1109/TIP.2018.2806839
   Cai ZY, 2017, MULTIMED TOOLS APPL, V76, P4313, DOI 10.1007/s11042-016-3374-6
   Cao ZJ, 2018, LECT NOTES COMPUT SC, V11212, P139, DOI 10.1007/978-3-030-01237-3_9
   Cao ZJ, 2019, PROC CVPR IEEE, P2980, DOI 10.1109/CVPR.2019.00310
   Cao ZJ, 2018, PROC CVPR IEEE, P2724, DOI 10.1109/CVPR.2018.00288
   Chakraborty S, 2021, MULTIMED TOOLS APPL, V80, P20547, DOI 10.1007/s11042-021-10753-y
   Chang WG, 2019, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2019.00753
   Chen C, 2020, AAAI CONF ARTIF INTE, V34, P3422
   Chen MH, 2020, AAAI CONF ARTIF INTE, V34, P3521
   Chiang HS, 2019, IEEE ACCESS, V7, P103255, DOI 10.1109/ACCESS.2019.2929266
   Chu Chenhui, 2018, P COLING 2018 C
   Chu Wen-Sheng, 2013, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, V2013, P3515
   Csurka G, 2017, ARXIV 170205374
   Rubio JD, 2009, IEEE T FUZZY SYST, V17, P1296, DOI 10.1109/TFUZZ.2009.2029569
   Dou Q, 2018, ARXIV18041091
   Fang XH, 2020, NEURAL NETWORKS, V127, P182, DOI 10.1016/j.neunet.2020.03.025
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Gehring J, 2013, INT CONF ACOUST SPEE, P3377, DOI 10.1109/ICASSP.2013.6638284
   Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36
   Gong B., 2013, P INT C MACH LEARN, P222
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Hernández G, 2020, NEUROCOMPUTING, V390, P327, DOI 10.1016/j.neucom.2019.08.095
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Gulrajani I, 2017, ADV NEUR IN, V30
   Iwendi C, 2023, MULTIMEDIA SYST, V29, P1839, DOI 10.1007/s00530-020-00701-5
   Iwendi C, 2020, COMPUT COMMUN, V161, P160, DOI 10.1016/j.comcom.2020.07.032
   Jinghua Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P329, DOI 10.1007/978-3-030-58589-1_20
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Kouw W. M., 2018, ARXIV181211806
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kutia S, 2019, IEEE ACCESS, V7, P90777, DOI 10.1109/ACCESS.2019.2924584
   Larsen ABL, 2016, PR MACH LEARN RES, V48
   LeCun Y., 2015, Lenet-5, convolutional neural networks
   Lee H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030785
   Li S, 2020, AAAI CONF ARTIF INTE, V34, P11386
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Liu H, 2019, PROC CVPR IEEE, P2922, DOI 10.1109/CVPR.2019.00304
   Liu SC, 2018, ADV NEUR IN, V31
   Long MS, 2017, PR MACH LEARN RES, V70
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Ma XH, 2019, IEEE T MULTIMEDIA, V21, P2419, DOI 10.1109/TMM.2019.2902100
   Mansour Y., 2009, P 21 INT C NEUR INF, P1041
   Mohamed AR, 2012, INT CONF ACOUST SPEE, P4273, DOI 10.1109/ICASSP.2012.6288863
   Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382
   Narang SR, 2021, MULTIMED TOOLS APPL, V80, P20671, DOI 10.1007/s11042-021-10775-6
   Norouzi M, 2013, ARXIV13125650
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P53, DOI 10.1109/MSP.2014.2347059
   Pei ZY, 2018, AAAI CONF ARTIF INTE, P3934
   Peng KC, 2018, LECT NOTES COMPUT SC, V11215, P793, DOI 10.1007/978-3-030-01252-6_47
   Peng X., 2017, ARXIV
   Peng XC, 2019, IEEE I CONF COMP VIS, P1406, DOI 10.1109/ICCV.2019.00149
   Rakshit RD, 2021, MULTIMED TOOLS APPL, V80, P20733, DOI 10.1007/s11042-021-10745-y
   Rubio JD, 2021, IEEE T NEUR NET LEAR, V32, P3510, DOI 10.1109/TNNLS.2020.3015200
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Saito K, 2019, IEEE I CONF COMP VIS, P8049, DOI 10.1109/ICCV.2019.00814
   Saito K, 2018, LECT NOTES COMPUT SC, V11209, P156, DOI 10.1007/978-3-030-01228-1_10
   Saito Kuniaki, 2017, ARXIV171101575
   Saito Kuniaki, 2020, Adv. Neural Inf. Process. Syst.
   Sankaranarayanan S, 2018, PROC CVPR IEEE, P8503, DOI 10.1109/CVPR.2018.00887
   Seo YS, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8020164
   Shen J, 2018, AAAI CONF ARTIF INTE, P4058
   Shi HY, 2020, PROC CVPR IEEE, P4573, DOI 10.1109/CVPR42600.2020.00463
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sothmann T, 2018, PROC SPIE, V10576, DOI 10.1117/12.2291481
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Sun SL, 2015, INFORM FUSION, V24, P84, DOI 10.1016/j.inffus.2014.12.003
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tang H, 2020, AAAI CONF ARTIF INTE, V34, P5940
   Tzeng E., 2014, ARXIV14123474
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   van Engelen JE, 2020, MACH LEARN, V109, P373, DOI 10.1007/s10994-019-05855-6
   Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang JH, 2019, IEEE I CONF COMP VIS, P3374, DOI 10.1109/ICCV.2019.00347
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Wang W, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3293318
   Wen J., 2020, PMLR, V119, P10214
   Wilson G, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3400066
   Xu MH, 2020, AAAI CONF ARTIF INTE, V34, P6502
   Xu RJ, 2018, PROC CVPR IEEE, P3964, DOI 10.1109/CVPR.2018.00417
   Yang J., 2007, P 15 ACM INT C MULT, P188
   Yosinski J, 2014, ADV NEUR IN, V27
   You KC, 2019, PROC CVPR IEEE, P2715, DOI 10.1109/CVPR.2019.00283
   Zellinger Werner, 2017, ARXIV170208811
   Zhai XH, 2019, IEEE I CONF COMP VIS, P1476, DOI 10.1109/ICCV.2019.00156
   Zhang GQ, 2021, MULTIMED TOOLS APPL, V80, P20687, DOI 10.1007/s11042-021-10671-z
   Zhang J, 2018, PROC CVPR IEEE, P8156, DOI 10.1109/CVPR.2018.00851
   Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321
   Zhang M, 2021, MULTIMED TOOLS APPL, V80, P34973, DOI 10.1007/s11042-021-10633-5
   Zhang WC, 2021, IEEE T IMAGE PROCESS, V30, P3293, DOI 10.1109/TIP.2021.3052083
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
NR 109
TC 3
Z9 4
U1 15
U2 63
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39545
EP 39576
DI 10.1007/s11042-022-12630-8
EA APR 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000788451300002
DA 2024-07-18
ER

PT J
AU Wu, YL
   Wo, Y
   Han, GQ
AF Wu, Yuanlu
   Wo, Yan
   Han, Guoqiang
TI Joint manipulation trace attention network and adaptive fusion mechanism
   for image splicing forgery localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Splicing forgery detection; Convolutional neural networks;
   Content-remove convolutional layer; Adaptive multi-scale fusion module
AB Splicing forgery, which manipulates images by copying regions from donor images and pasting them to host images, is one of the common types of image forgery in life, where the copied regions include object regions or background regions. In order to accurately detect these forgery regions, the most mainstream approach is to use an encoder-decoder network architecture that extracts enough manipulation traces to determine whether each pixel of the input image has been spliced or not. However, due to the limited receptive field of such networks, only local manipulation traces can be learned, and therefore some large object area forgery and background forgery cannot be well localized. To address these issues, in this paper, an end-to-end splicing detection framework is proposed, which includes localization network L-Net, manipulation traces attention network MTA-Net, and adaptive multi-scale fusion module. The localization network L-Net is designed as an encoder-decoder network to extract local manipulation traces for each pixel and implement localization of splicing areas. MTA-Net uses the proposed content-remove convolutional layer (CRCL) to suppress image content information that would hinder the network from learning to manipulate traces, and then uses subsequent convolutional layers to extract features to discriminate whether the input image is a spliced image or not. In this process, the regions in the feature map of the convolutional layers with large activation values are the ones that contain global manipulation traces. These global manipulation traces are fused with the local manipulation traces learned by L-Net through the proposed adaptive multi-scale fusion module (AMSFM), thus allowing L-Net to effectively handle object forgery and background region forgery images of various sizes. Ablation experiments showed an increase of 4.6% and 3.9% in F1-score and MCC after the introduction of MTA-Net and AMSFM, respectively The splicing region detection performance on three standard datasets, CASIA, COLUMB, and CARVALHO, shows that the proposed method outperforms the state-of-the-art methods for both object forgery and background forgery, and is more robust to post-processing methods such as JPEG compression and noise addition.
C1 [Wu, Yuanlu; Wo, Yan; Han, Guoqiang] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
C3 South China University of Technology
RP Wo, Y (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
EM woyan@scut.edu.cn
FU National Natural Science Foundation of Guangdong [2021A1515012020];
   Guangzhou science and technology plan project [202002030298]
FX This work is supported by National Natural Science Foundation of
   Guangdong [Grant No. 2021A1515012020], and Guangzhou science and
   technology plan project [Grant No.202002030298].
CR Bappy JH, 2017, IEEE I CONF COMP VIS, P4980, DOI 10.1109/ICCV.2017.532
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Bondi L, 2017, IEEE COMPUT SOC CONF, P1855, DOI 10.1109/CVPRW.2017.232
   Chen H, 2021, MULTIMED SYST, P1
   Chen X, 2021, ARXIV210406832
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Ding HW, 2023, NEURAL COMPUT APPL, V35, P5015, DOI 10.1007/s00521-021-06329-4
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Goljan M, 2015, PROC SPIE, V9409, DOI 10.1117/12.2078399
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hsu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P549, DOI 10.1109/ICME.2006.262447
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huh M, 2018, LECT NOTES COMPUT SC, V11215, P106, DOI 10.1007/978-3-030-01252-6_7
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Kingma D. P., 2014, arXiv
   Krawetz Neal, 2007, Hacker Factor Solut., V6, P2
   Li HD, 2021, LECT NOTES COMPUT SC, V13020, P610, DOI 10.1007/978-3-030-88007-1_50
   Li WH, 2009, SIGNAL PROCESS, V89, P1821, DOI 10.1016/j.sigpro.2009.03.025
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   Pham NT, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010083
   Pan X, 2012, INT CONF E BUS ENG, P17, DOI 10.1109/ICEBE.2012.13
   Pannu HS, 2020, MULTIMED TOOLS APPL, V79, P21941, DOI 10.1007/s11042-020-08905-7
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Wang XY, 2019, MATH BIOSCI ENG, V16, P4581, DOI 10.3934/mbe.2019229
   Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI [10.1109/CSTIC.2018.8369274, 10.1007/s11263-019-01198-w]
   Xiao B, 2020, INFORM SCIENCES, V511, P172, DOI 10.1016/j.ins.2019.09.038
   Xuefeng Hu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P312, DOI 10.1007/978-3-030-58589-1_19
   Yang C, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102825
   Yang CJ, 2021, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS51556.2021.9401588
   Yu F., 2015, ARXIV
   Yu LH, 2021, MULTIMED TOOLS APPL, V80, P19157, DOI 10.1007/s11042-020-10355-0
   Zampoglou M, 2017, MULTIMED TOOLS APPL, V76, P4801, DOI 10.1007/s11042-016-3795-2
   Zhang Y, 2016, CRYPTOL INF SEC SER, V14, P1, DOI 10.3233/978-1-61499-617-0-1
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
NR 42
TC 3
Z9 3
U1 3
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38757
EP 38780
DI 10.1007/s11042-022-13151-0
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787666500012
DA 2024-07-18
ER

PT J
AU Limbu, N
   Alsadoon, A
   Prasad, PWC
   Abdullah, S
   Rashid, TA
   Alsadoon, OH
   Jerew, OD
   Alrubaie, A
AF Limbu, Narayan
   Alsadoon, Abeer
   Prasad, P. W. C.
   Abdullah, Salma
   Rashid, Tarik A.
   Alsadoon, Omar Hisham
   Jerew, Oday D.
   Alrubaie, Ahmad
TI A novel solution of deep learning for sleep apnea detection: enhancement
   of SC and elimination of GVICS
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Sleep apnea; Internal covariate shift;
   Gradient vanishing; ECG signal segmentation
ID NEURAL-NETWORK
AB Convolutional neural network (CNN) classification has not achieved a medically-satisfied level of accuracy in sleep apnea detection due to the negative effect of the ECG data segmentation process, Gradient vanishing issues, and internal Covariate shift. This research aims to enhance segmentation, classification accuracy, and eliminate gradient vanishing and internal covariate shift to increase the sleep apnea detection classification accuracy. The proposed system consists of a novel enhancement of segmentation and classification technique (Enhancement of SC) and elimination of gradient vanishing and internal covariate shift (Elimination of GVICS). The enhancement of SC considers the time-dependent nature of apnea events during the classification process and the elimination of GVICS reduces the instability of the neural network due to inactive neurons and improves classification accuracy by removing large input distribution of data during the training phases. The results show that the proposed system achieves better classification performance in four different datasets tested and given accuracy 98.9% against the current accuracy of 94.5% processing time per sample 3 milliseconds against the current processing time 5 milliseconds. Besides, the model has achieved its optimal accuracy in fewer epochs 8 against the current optimal accuracy time of 11 epochs. The proposed solution has improved the accuracy of sleep apnea classification and reduced time to achieve optimal accuracy of the neural network by using the ESCEGCs algorithm; the study has solved the issues of gradient vanishing and internal covariate shift and enhances the overall classification accuracy.
C1 [Limbu, Narayan; Alsadoon, Abeer; Prasad, P. W. C.] Charles Sturt Univ CSU, Sch Comp Math & Engn, Wagga Wagga, NSW, Australia.
   [Alsadoon, Abeer] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Kent Inst Australia, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Jerew, Oday D.] Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
   [Abdullah, Salma] Univ Technol Baghdad, Dept Comp Engn, Baghdad, Iraq.
   [Rashid, Tarik A.] Univ Kurdistan Hewler, Comp Sci & Engn, Erbil, Krg, Iraq.
   [Alsadoon, Omar Hisham] Al Iraqia Univ, Dept Islamic Sci, Baghdad, Iraq.
   [Alrubaie, Ahmad] Univ New South Wales, Fac Med, Sydney, NSW, Australia.
C3 Charles Sturt University; Western Sydney University; University of
   Technology- Iraq; University of Kurdistan Hewler; Al-Iraqia University;
   University of New South Wales Sydney
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp Math & Engn, Wagga Wagga, NSW, Australia.; Alsadoon, A (corresponding author), Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Rashid, Tarik A./P-3473-2019; Abdullah, Salma Hameedi/GRJ-1117-2022;
   Rashid, Tarik A./HLX-0184-2023; Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Rashid, Tarik A./0000-0002-8661-258X; Abdullah, Salma
   Hameedi/0000-0003-2087-0153; Rashid, Tarik A./0000-0002-8661-258X;
   Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; Alsadoon, Omar
   Hisham/0000-0001-7797-6392
CR Berry RB, 2017, J CLIN SLEEP MED, V13, P665, DOI 10.5664/jcsm.6576
   De Falco I, 2019, FUTURE GENER COMP SY, V98, P377, DOI 10.1016/j.future.2019.01.049
   Dey D, 2018, BIOMED ENG LETT, V8, P95, DOI 10.1007/s13534-017-0055-y
   Erdenebayar U, 2019, COMPUT METH PROG BIO, V180, DOI 10.1016/j.cmpb.2019.105001
   Gao WD, 2019, MATH BIOSCI ENG, V16, P5672, DOI 10.3934/mbe.2019282
   Godfrey LB, 2019, IEEE SYS MAN CYBERN, P3006, DOI [10.1109/smc.2019.8913972, 10.1109/SMC.2019.8913972]
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Hafezi M, 2020, IEEE ACCESS, V8, P22641, DOI 10.1109/ACCESS.2020.2969227
   Nakano H, 2019, J CLIN SLEEP MED, V15, P1125, DOI 10.5664/jcsm.7804
   Nikkonen S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49330-7
   Penzel T, 2000, COMPUT CARDIOL, V27, P255, DOI 10.1109/CIC.2000.898505
   Perero-Codosero JM, 2020, IEEE J-STSP, V14, P240, DOI 10.1109/JSTSP.2019.2957977
   Pinho A, 2019, APPL SOFT COMPUT, V83, DOI 10.1016/j.asoc.2019.105568
   Shirwaikar RD, 2019, ARTIF INTELL MED, V98, P59, DOI 10.1016/j.artmed.2019.07.008
   Simply RM, 2020, IEEE J-STSP, V14, P251, DOI 10.1109/JSTSP.2019.2955019
   Wang T, 2019, BIOMED RES INT, V2019, DOI 10.1155/2019/9768072
   Wang T, 2019, PEERJ, V7, DOI 10.7717/peerj.7731
   Wong HB, 2011, PROC SINGAP HEALTHC, V20, P316, DOI 10.1177/201010581102000411
   Yüzer AH, 2020, APPL ACOUST, V163, DOI 10.1016/j.apacoust.2020.107225
NR 19
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38569
EP 38592
DI 10.1007/s11042-022-13142-1
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787139200005
DA 2024-07-18
ER

PT J
AU Hossain, S
   Mukhopadhyay, S
   Ray, B
   Ghosal, SK
   Sarkar, R
AF Hossain, Sabbir
   Mukhopadhyay, Souradeep
   Ray, Biswarup
   Ghosal, Sudipta Kr
   Sarkar, Ram
TI A secured image steganography method based on ballot transform and
   genetic algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ballot transform; Genetic algorithm; LSB; Transformed domain
ID HIGH PAYLOAD; DCT
AB Rapid advances in digital technology have facilitated us to transfer a huge amount of electronic files over the internet. But in the presence of malicious attackers, the security, as well as the integrity of such important files, becomes of utmost importance. Steganography, an art of hiding the data, ensures the security of these files over the internet, and this method has been used for a long. In this paper, our purpose is two-fold. First, the Ballot transform (BaT) produces an integer polynomial sequence in coefficient form for each non-overlapping m-pixel groups (m = 2 or 3) of the cover image. Second, the Genetic Algorithm (GA) is applied to generate a k-digit password using a method called Index Value Mapping (IVM) which decides positions of the transformed coefficients where the bits of the secret data can be embedded. The key idea of using GA here is to produce an optimal output in terms of stego image quality instead of using an exhaustive search considering all combinations of k number of bits. Experimental results show that the proposed method not only offers acceptable Peak Signal-to-Noise Ratio (PSNR) values with considerable payload but also provides two-way security of the data being transmitted over the digital medium.
C1 [Hossain, Sabbir; Mukhopadhyay, Souradeep; Ray, Biswarup; Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
   [Ghosal, Sudipta Kr] Nalhati Govt Polytech, Dept Comp Sci & Technol, Nalhati 731243, Birbhum, India.
C3 Jadavpur University
RP Ghosal, SK (corresponding author), Nalhati Govt Polytech, Dept Comp Sci & Technol, Nalhati 731243, Birbhum, India.
EM sudipta.ghosal@gmail.com
RI Sarkar, Ram/AAX-3822-2020
OI Sarkar, Ram/0000-0001-8813-4086; Ray, Biswarup/0000-0002-7378-0920
CR Al-Dmour H, 2016, EXPERT SYST APPL, V46, P293, DOI 10.1016/j.eswa.2015.10.024
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Atta R, 2018, J VIS COMMUN IMAGE R, V53, P42, DOI 10.1016/j.jvcir.2018.03.009
   Baby D, 2015, PROCEDIA COMPUT SCI, V46, P612, DOI 10.1016/j.procs.2015.02.105
   Bajwa, 2011, INT C COMP NETW INF
   Barry P, 2005, J INTEGER SEQ, V8
   Bhattacharyya T, 2020, IEEE ACCESS, V8, P195929, DOI 10.1109/ACCESS.2020.3031718
   Boehm Benedikt, 2014, ARXIV14106656
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Chao RM, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/658047
   Chen WY, 2008, APPL MATH COMPUT, V196, P40, DOI 10.1016/j.amc.2007.05.063
   Chen YL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106335
   Dumitrescu S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P641, DOI 10.1109/ICIP.2002.1039052
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Falahi A., 2012, 9 INT ISC C INF SEC
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Gashkov SB, 2015, MATH NOTES+, V97, P531, DOI 10.1134/S0001434615030256
   Ghosal S., 2014, ADV MODELL ANAL B, V57, P68
   Ghosal SK, 2014, J INF SECUR APPL, V19, P272, DOI 10.1016/j.jisa.2014.07.004
   Ghosal SK, 2021, COMPUT ELECTR ENG, V89, DOI 10.1016/j.compeleceng.2020.106964
   Ghosal SK, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3984
   Hajizadeh H, 2013, IRAN CONF ELECTR ENG
   Holland J. H., 1992, Scientific American (International Edition), V267, P44, DOI 10.1038/scientificamerican0792-66
   Jothy, 2016, 2016 10 INT C INT SY
   Kalita M, 2019, COMPUT J, V62, P1639, DOI 10.1093/comjnl/bxz014
   Khodaei M, 2010, LECT NOTES COMPUT SC, V6134, P404, DOI 10.1007/978-3-642-13681-8_47
   Kumar V, 2010, COMM COM INF SC, V101, P596
   Li HR, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106593
   Li HR, 2020, SWARM EVOL COMPUT, V58, DOI 10.1016/j.swevo.2020.100743
   Liang YQ, 2020, INTEGR COMPUT-AID E, V27, P417, DOI 10.3233/ICA-200641
   Muhuri PK, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106257
   Mukhopadhyay S, 2021, MULTIMED TOOLS APPL, V80, P14495, DOI 10.1007/s11042-020-10424-4
   Nazari M, 2020, MULTIMED TOOLS APPL, V79, P13693, DOI 10.1007/s11042-019-08415-1
   Redely H. S. Manjunatha, 2011, International Journal of Advanced Networking and Applications, V3, P1203
   Saidi M, 2017, MULTIMED TOOLS APPL, V76, P13493, DOI 10.1007/s11042-016-3722-6
   Seyyedi SA, 2014, INT J SECUR APPL, V8, P183, DOI 10.14257/ijsia.2014.8.4.17
   Shet KS, 2015, ADV INTELL SYST, V327, P839, DOI 10.1007/978-3-319-11933-5_95
   Stanley C.A., 2005, CITESTEER, P1
   Sugathan S, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT), P609, DOI 10.1109/ICATCCT.2016.7912072
   Weber A.G., 2019, The USC-SIPI Image Database: Version 5, Original Release
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Younus ZS, 2019, J KING SAUD U COMPUT
   Zhang H, 2019, SIGNAL PROCESS-IMAGE, V78, P331, DOI 10.1016/j.image.2019.07.019
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
NR 44
TC 10
Z9 10
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38429
EP 38458
DI 10.1007/s11042-022-13158-7
EA APR 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000785933600001
DA 2024-07-18
ER

PT J
AU Paul, LSJ
   Gracias, C
   Desai, A
   Thanikaiselvan, V
   Shanthini, SS
   Rengarajan, A
AF Paul, L. Shane John
   Gracias, Carlton
   Desai, Anurag
   Thanikaiselvan, V
   Shanthini, S. Suba
   Rengarajan, Amirtharajan
TI A novel colour image encryption scheme using dynamic DNA coding, chaotic
   maps, and SHA-2
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Combined logistic-tent map; Hyperchaotic maps; Image encryption;
   Zaslavskii map; SHA-2 hash
ID SYSTEM
AB In this paper, a novel encryption scheme that combines hyperchaotic maps schemes, SHA-2, and a pixel-shifting based on the Zaslavskii map is proposed. The plain image is first scrambled based on values obtained from a 2-D hyperchaotic map. A cover image is then generated using the combined logistic-tent map. A mask image is then created based on a novel bit indexing scheme based on the SHA-2 value of the cover image. DNA encoding is carried out on both images, using a dynamically chosen logistic-tent map. Then diffusion using the exclusive-OR method was executed. Lastly, multiple diffusion operations are carried out to produce the cipher image. By simulational analysis, this proposed scheme has been determined to yield high security. The proposed method supersedes the previously developed method by the authors.
C1 [Paul, L. Shane John; Gracias, Carlton; Desai, Anurag; Thanikaiselvan, V] Vellore Inst Technol VIT, Sch Elect Engn, Vellore 632014, Tamil Nadu, India.
   [Shanthini, S. Suba] Vellore Inst Technol VIT, Sch Informat Technol, Vellore 632014, Tamil Nadu, India.
   [Rengarajan, Amirtharajan] SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Vellore; Shanmugha Arts, Science, Technology &
   Research Academy (SASTRA)
RP Rengarajan, A (corresponding author), SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
EM amir@ece.sastra.edu
RI Amirtharajan, Rengarajan/C-6471-2011
OI Amirtharajan, Rengarajan/0000-0003-1574-3045; Thanikaiselvan,
   V/0000-0003-2418-5217
CR Akhavan A, 2017, OPT LASER TECHNOL, V95, P94, DOI 10.1016/j.optlastec.2017.04.022
   Alarood AA, 2022, AIN SHAMS ENG J, V13, DOI 10.1016/j.asej.2021.09.010
   Banu SA, 2020, MED BIOL ENG COMPUT, V58, P1445, DOI 10.1007/s11517-020-02178-w
   Banu SA, 2020, MULTIMED TOOLS APPL, V79, P28807, DOI 10.1007/s11042-020-09501-5
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Devi RS, 2020, MULTIMED TOOLS APPL, V79, P12093, DOI 10.1007/s11042-019-08562-5
   Duan CF, 2022, OPT LASER ENG, V150, DOI 10.1016/j.optlaseng.2021.106881
   Gao XH, 2021, OPT LASER TECHNOL, V142, DOI 10.1016/j.optlastec.2021.107252
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Kumar S, 2019, MED BIOL ENG COMPUT, V57, P2517, DOI 10.1007/s11517-019-02037-3
   Kumar V, 2021, MULTIMED TOOLS APPL, V80, P3749, DOI 10.1007/s11042-020-09854-x
   Lakshmi C, 2021, NEURAL COMPUT APPL, V33, P6671, DOI 10.1007/s00521-020-05447-9
   Lakshmi C, 2020, NEURAL COMPUT APPL, V32, P11477, DOI 10.1007/s00521-019-04637-4
   Liu LD, 2021, J INF SECUR APPL, V60, DOI 10.1016/j.jisa.2021.102854
   Mahmud M, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105818
   Paul LSJ, 2020, IJAST, V29, P4510
   Rajagopalan S, 2019, MULTIMED TOOLS APPL, V78, P10513, DOI 10.1007/s11042-018-6574-4
   Ravichandran D, 2021, MED BIOL ENG COMPUT, V59, P589, DOI 10.1007/s11517-021-02328-8
   Sivaraman R, 2020, MULTIMED TOOLS APPL, V79, P13841, DOI 10.1007/s11042-019-08592-z
   Sivaraman R, 2020, IET IMAGE PROCESS, V14, P2987, DOI 10.1049/iet-ipr.2019.0168
   Sun SL, 2019, IEEE ACCESS, V7, P28539, DOI 10.1109/ACCESS.2019.2901870
   Talhaoui MZ, 2021, VISUAL COMPUT, V37, P1757, DOI 10.1007/s00371-020-01936-z
   Wang SM, 2022, OPT LASER TECHNOL, V148, DOI 10.1016/j.optlastec.2021.107753
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wang XY, 2018, MULTIMED TOOLS APPL, V77, P6243, DOI 10.1007/s11042-017-4534-z
   Yang YG, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105661
   Zhang XQ, 2021, OPT LASER TECHNOL, V141, DOI 10.1016/j.optlastec.2021.107073
   Zhou WJ, 2022, OPT LASER ENG, V149, DOI 10.1016/j.optlaseng.2021.106782
NR 30
TC 12
Z9 12
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37873
EP 37894
DI 10.1007/s11042-022-13095-5
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000786824500006
DA 2024-07-18
ER

PT J
AU Wang, HY
   Su, QT
AF Wang, Huanying
   Su, Qingtang
TI A color image watermarking method combined QR decomposition and spatial
   domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatial transform; Transform domain; QR decomposition; Color image
   watermark
ID ROBUST WATERMARKING; SCHEME; FACTORIZATION; ALGORITHM
AB For protecting the digital copyright of color image, a color image watermarking method should have strong robustness and short running-time at same time. To achieve these two goals, an effective color image watermarking method is presented in this paper. Firstly, the element in the first row and first column of the R matrix of QR decomposition is obtained by the presented method in spatial domain. Secondly, the obtained element of R matrix is selected to protect the copyright of color image in spatial domain without the true QR decomposition. Finally, the processes of the presented watermarking technique are performed in spatial domain. In the compared experimentations, the imperceptibility of the presented method is about 40 dB, its average NC is 0.9435, its average running-time is 0.703613 s, its embedding capacity is 0.03125 bpp, and its key space is 2(138), which proves the proposed new method has better performances in terms of the robustness and real-time feature.
C1 [Wang, Huanying] Ludong Univ, Dept Educ & Informat Technol, Yantai 264025, Peoples R China.
   [Su, Qingtang] Ludong Univ, Sch Informat & Elect Engn, Yantai 264025, Peoples R China.
C3 Ludong University; Ludong University
RP Wang, HY (corresponding author), Ludong Univ, Dept Educ & Informat Technol, Yantai 264025, Peoples R China.
EM ldumaster@163.com
OI Wang, Huanying/0000-0001-5390-0967
FU National Natural Science Foundations of China [61771231, 61772253,
   61873117, 61872170, 61803253]; Key Project of Shandong Natural Science
   Foundation [ZR2020KF023]
FX The work was supported by the National Natural Science Foundations of
   China (No. 61771231, 61772253, 61873117, 61872170 and 61803253), and the
   Key Project of Shandong Natural Science Foundation (No. ZR2020KF023). In
   addition, we would like to express our sincere gratitude to the
   Editor-in-Chief, the Associate Editor and the anonymous reviewers for
   their valuable comments and suggestions.
CR Abraham J, 2019, J KING SAUD UNIV-COM, V31, P125, DOI 10.1016/j.jksuci.2016.12.004
   Agilandeeswari L, 2016, MULTIMED TOOLS APPL, V75, P8745, DOI 10.1007/s11042-015-2789-9
   [Anonymous], 1992, RFC1321
   Cao XY, 2016, J ELECTR COMPUT ENG, V2016, DOI 10.1155/2016/3219042
   Chen HY, 2012, J ZHEJIANG U-SCI C, V13, P573, DOI 10.1631/jzus.C1100338
   Chou CH, 2003, EURASIP J APPL SIG P, V2003, P32, DOI 10.1155/S1110865703211227
   Golea N., 2010, IEEE INT C COMPUTER, P1
   Golub GH., 1989, MATRIX COMPUTATIONS, P1
   Hsu CS, 2020, MULTIMED TOOLS APPL, V79, P11297, DOI 10.1007/s11042-019-08367-6
   Jia SL, 2014, OPTIK, V125, P2868, DOI 10.1016/j.ijleo.2014.01.002
   Kahlessenane F, 2021, MULTIMED TOOLS APPL, V80, P19827, DOI 10.1007/s11042-021-10713-6
   Kumar S, 2021, MULTIMED TOOLS APPL, V80, P13975, DOI 10.1007/s11042-020-10397-4
   Li XH, 2000, IEEE T SIGNAL PROCES, V48, P60
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Liu XL, 2017, IEEE T SIGNAL PROCES, V65, P1894, DOI 10.1109/TSP.2017.2652383
   Mehta R, 2016, MULTIMED TOOLS APPL, V75, P4129, DOI 10.1007/s11042-015-3084-5
   Naderahmadian Y, 2014, MULTIMED TOOLS APPL, V72, P2597, DOI 10.1007/s11042-013-1559-9
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Song W, 2011, J CENT SOUTH UNIV T, V18, P116, DOI 10.1007/s11771-011-0668-8
   Su Q, 2016, Color Image Watermarking: Algorithms and Technologies, DOI [10.1515/9783110487732, DOI 10.1515/9783110487732]
   Su QT, 2019, IEEE ACCESS, V7, P4358, DOI 10.1109/ACCESS.2018.2888857
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P24221, DOI 10.1007/s11042-016-4164-x
   Su QT, 2016, IET IMAGE PROCESS, V10, P817, DOI 10.1049/iet-ipr.2016.0048
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   University of Granada Computer Vision Group, CVG UGR IMAGE DATABA
   University of Southern California, SIGNAL IMAGE PROCESS
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang FY, 2019, MULTIMED TOOLS APPL, V78, P20133, DOI 10.1007/s11042-019-7326-9
NR 28
TC 7
Z9 7
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37895
EP 37916
DI 10.1007/s11042-022-13064-y
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000786824500003
DA 2024-07-18
ER

PT J
AU Li, Y
AF Li, Yang
TI Moving object detection for unseen videos via truncated weighted robust
   principal component analysis and salience convolution neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moving object detection; Convolution neural network; Truncated weighted
   robust principal component analysis; Salience; Unseen videos
ID FOREGROUND SEGMENTATION; BACKGROUND SUBTRACTION
AB Moving object detection is a basic and important work in intelligent video analysis. Recently, a lot of methods have sprung up. Among them, the methods based on deep learning have achieved very amazing results. However, the methods based on deep learning rely on special annotated data to train the model. Thus they have weak generalization ability and can only deal with the data related to the training data. In order to handle this issue, this paper proposes a method based on Truncated Weighted Robust Principal Component Analysis and Salience Convolution Neural Network. Unlike other deep learning methods, the input of the proposed method does not contain the scene information. The proposed method uses the salient information obtained by the proposed Truncated Weighted Robust Principal Component Analysis as input. This improves the generalization ability of the proposed method. The experimental results show the superior performance of the proposed method for unseen videos on CDNET 2014 database.
C1 [Li, Yang] Jiangsu Vocat Coll Informat Technol, Sch IoT Engn, Sch Informat Secur, 1 Qianou Rd, Wuxi 214153, Jiangsu, Peoples R China.
C3 Jiangsu Vocational College of Information Technology
RP Li, Y (corresponding author), Jiangsu Vocat Coll Informat Technol, Sch IoT Engn, Sch Informat Secur, 1 Qianou Rd, Wuxi 214153, Jiangsu, Peoples R China.
EM liyang_19901222@163.com
OI Yang, Li/0000-0002-0087-3472
FU Jiangsu Provincial Colleges of Natural Science General Program
   [21KJB520006]; Research Project of Jiangsu Vocational College of
   Information Technology [10072020028(001)]; Higher Vocational Education
   Teaching Fusion Production Integration Platform Construction Projects of
   Jiangsu Province [2019(26)]; Qing Lan Project" Teaching Team in Colleges
   and Universities of Jiangsu Province [2017(15)]; High Level of Jiangsu
   Province Key Construction Project Fund [2017(17)]; Jiangsu Province
   Higher Vocational Education High Level Professional Group Construction
   Project Funding [1]; General Project fund of Natural Science Research in
   Universities of Jiangsu Province [18KJD510011]; Excellent Teaching Teams
   of "Qinglan Project" in Universities of Jiangsu Province
   (SuJiaoShi[2020] *)
FX This work was supported in part by the Jiangsu Provincial Colleges of
   Natural Science General Program under Grant 21KJB520006, in part by
   Research Project of Jiangsu Vocational College of Information Technology
   under Grant 10072020028(001), in part by Higher Vocational Education
   Teaching Fusion Production Integration Platform Construction Projects of
   Jiangsu Province under Grant No.2019(26), in part by "Qing Lan Project"
   Teaching Team in Colleges and Universities of Jiangsu Province under
   Grant No.2017(15), in part by High Level of Jiangsu Province Key
   Construction Project Fund under Grant No.2017(17), in part by Jiangsu
   Province Higher Vocational Education High Level Professional Group
   Construction Project Funding (SuJiaoZhiHan[2021] No.1), in part by The
   General Project fund of Natural Science Research in Universities of
   Jiangsu Province (18KJD510011), in part by Excellent Teaching Teams of
   "Qinglan Project" in Universities of Jiangsu Province (SuJiaoShi[2020]
   *).
CR Barnich O, 2009, INT CONF ACOUST SPEE, P945, DOI 10.1109/ICASSP.2009.4959741
   Bouwmans T, 2019, NEURAL NETWORKS, V117, P8, DOI 10.1016/j.neunet.2019.04.024
   Braham M, 2016, INT CONF SYST SIGNAL, P113
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1014, DOI 10.1109/TCYB.2015.2419737
   Ebadi SE, 2018, IEEE T PATTERN ANAL, V40, P2273, DOI 10.1109/TPAMI.2017.2745573
   Elgammal A, 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48
   Evangelio RH, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P300, DOI 10.1109/AVSS.2012.69
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   Isik S, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023002
   Li Y, 2019, NEUROCOMPUTING, V323, P352, DOI 10.1016/j.neucom.2018.10.012
   Liao J, 2018, LECT NOTES COMPUT SC, V11164, P524, DOI 10.1007/978-3-030-00776-8_48
   Lim LA, 2020, PATTERN ANAL APPL, V23, P1369, DOI 10.1007/s10044-019-00845-9
   Lim LA, 2018, PATTERN RECOGN LETT, V112, P256, DOI 10.1016/j.patrec.2018.08.002
   Rahmani M, 2017, IEEE T SIGNAL PROCES, V65, P2004, DOI 10.1109/TSP.2017.2649482
   Sakkos D, 2018, MULTIMED TOOLS APPL, V77, P23023, DOI 10.1007/s11042-017-5460-9
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sultana M, 2019, MACH VISION APPL, V30, P375, DOI 10.1007/s00138-018-0993-0
   Tezcan MO, 2020, IEEE WINT CONF APPL, P2763, DOI [10.1109/WACV45572.2020.9093464, 10.1109/wacv45572.2020.9093464]
   Wang Y, 2017, PATTERN RECOGN LETT, V96, P66, DOI 10.1016/j.patrec.2016.09.014
   Xiao X, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P327, DOI 10.1109/ITME.2018.00080
   Zeng DD, 2018, IEEE ACCESS, V6, P16010, DOI 10.1109/ACCESS.2018.2817129
NR 21
TC 1
Z9 1
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 32779
EP 32790
DI 10.1007/s11042-022-12832-0
EA APR 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000782544500002
DA 2024-07-18
ER

PT J
AU Huang, YG
   Zheng, YB
   Wu, HY
AF Huang, Yonggang
   Zheng, Yunbo
   Wu, Huiyan
TI Learning user-emotion and user-feature couplings for image emotion
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image emotion classification; Emotion subjectivity; Coupled
   representation; Clustering-based embedding; Convolutional neural network
AB Over the past few years, image emotion classification (IEC) has received increasing research interest. Existing works usually define IEC as a multi-class classification problem from features to emotions, while the subjectivity of user perception is often ignored. However, our experimental study shows that there are coupling relationships between users and emotions, as well as users and features. To address such issues, in this paper, we propose a new IEC model, called CoupledIEC. In CoupledIEC, to capture the user-emotion coupling, a clustering-based embedding model is proposed to encode users of similar emotion preferences with close representations. To model the user-feature coupling, a convolutional neural network-based coupling learning model is developed, where the Hadamard product and the matrix product are employed respectively to capture the explicit and the implicit user-feature coupling information. The two models are then integrated in a unified neural network. The experimental results on real-world image collection demonstrate that the IEC performance can be improved significantly by taking into account user-emotion and user-feature couplings.
C1 [Huang, Yonggang; Zheng, Yunbo; Wu, Huiyan] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Huang, YG (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
EM yonggang.h@gmail.com; 3220190930@bit.edu.cn; 3220200973@bit.edu.cn
RI Huang, Yonggang/AAI-8032-2020
OI Huang, Yonggang/0000-0001-9899-8590
FU National Natural Science Foundation of China [61972035, U19B2020]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61972035 and No. U19B2020).
CR [Anonymous], 2016, Proceedings of the 24th ACM international conference on Multimedia, DOI DOI 10.1145/2964284.2967196
   Bhattacharya S, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102589
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Cao LB, 2015, INFORM PROCESS MANAG, V51, P167, DOI 10.1016/j.ipm.2014.08.007
   Cheng B, 2018, IEEE CONF COMPUT
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gadekallu TR, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01963-7
   Jian SL, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1937
   Kipf TN, 2016, ARXIV
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee J, 2011, IEEE T MULTIMEDIA, V13, P1031, DOI 10.1109/TMM.2011.2158530
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   Mikels JA, 2005, BEHAV RES METHODS, V37, P626, DOI 10.3758/BF03192732
   Rao TR, 2016, IEEE IMAGE PROC, P634, DOI 10.1109/ICIP.2016.7532434
   Rao Tianrong, 2016, NEURAL PROCESSING LE, P1
   Tonge A, 2016, AAAI CONF ARTIF INTE, P4266
   Wang C, 2015, IEEE T SYST MAN CY-S, V45, P1109, DOI 10.1109/TSMC.2015.2399862
   Wang Jingwen., 2016, IJCAI, P3484
   Yang P, 2010, PROC CVPR IEEE, P2638, DOI 10.1109/CVPR.2010.5539978
   Yao L, 2019, AAAI CONF ARTIF INTE, P7370
   You QZ, 2016, AAAI CONF ARTIF INTE, P308
   You QZ, 2015, AAAI CONF ARTIF INTE, P381
   Yuan J., 2013, P 2 INT WORKSH ISS S, P1
   Zhang QG, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3662
   Zhao SC, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5534
   Zhao Sicheng, 2016, P 24 ACM INT C MULT, P1385, DOI DOI 10.1145/2964284.2964289
   Zhu XG, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3595
NR 27
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 32739
EP 32754
DI 10.1007/s11042-022-12867-3
EA APR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000782544600003
DA 2024-07-18
ER

PT J
AU Khamaneh, PA
   Khakpour, A
   Shoaran, M
   Karimian, G
AF Khamaneh, Paria Ansar
   Khakpour, Ali
   Shoaran, Maryam
   Karimian, Ghader
TI Real-time memory efficient SLIC accelerator for low-power applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Superpixel; SLIC; Augmented reality; Memory efficiency
ID SALIENCY DETECTION; SHIFT
AB Superpixel segmentation is one of the popular segmentation methods used in computer vision. One of the major algorithms in superpixel segmentation literature is the Simple Linear Iterative Clustering (SLIC) algorithm. SLIC is an iterative algorithm that data-dependency of its two main steps, i.e., assignment and update, challenges the parallel implementation of the original structure. Also, there are lots of coefficients computed in each step which are needed for the next step and require large throughput. This makes the SLIC algorithm inefficient from memory point of view. The memory inefficiency prevents this algorithm from being used in low-power applications such as augmented reality (AR). In this manuscript, we propose a new structure for SLIC algorithm to improve the memory efficiency. This new structure modifies the Assignment step of SLIC to ignore main non required parameters. To overcome this problem, we propose a new memory-efficient structure for SLIC algorithm. In the basic SLIC algorithm, the main memory consuming parameters are Label and Distance Index which the second one is removed in proposed structure. This new technique works based on simultaneous calculation and comparison of Distance Index of pixels and leads to 25% memory saving. SLIC algorithm works in CIELAB color space which requires more memory space and throughput compared to RGB color space. Proposed structure works in RGB color space rather than CIELAB color space, by implementing a real-time (single clock) RGB-to-CIELAB convertor. This modification resulted to another 37% memory saving. The overall structure is 62% efficient compared to the basic SLIC algorithm and the most efficient one in the literature, to the knowledge of authors. To minimize the execution time of proposed structure, a new structure is proposed for Update step of SLIC algorithm. This memory-efficient SLIC algorithm is implemented and validated on a Stratix-III FPGA family. The implementation results validate real-time behavior of the proposed structure (24 frames per second).
C1 [Khamaneh, Paria Ansar; Khakpour, Ali; Shoaran, Maryam; Karimian, Ghader] Univ Tabriz, Fac Elect & Comp Engn, Tabriz, Iran.
C3 University of Tabriz
RP Shoaran, M (corresponding author), Univ Tabriz, Fac Elect & Comp Engn, Tabriz, Iran.
EM mshoaran@tabrizu.ac.ir
RI Karimian, Ghader/IYJ-4021-2023
OI Khakpour, Ali/0000-0002-6244-696X; Karimian, Ghader/0000-0001-5030-6970;
   Shoaran, Maryam/0000-0002-4105-0835
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Akagic A, 2018, IEEE INT SYMP DESIGN, P55, DOI 10.1109/DDECS.2018.00-12
   Amal A., 2017, MULTIMED TOOLS APPL, V7, P83723
   [Anonymous], 2016, 19th International Conference on OFDM and Frequency Domain Techniques ICOF
   Bommisetty RM, 2019, MULTIMED TOOLS APPL, V78, P25185, DOI 10.1007/s11042-019-7554-z
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Giordano D, 2015, PROC CVPR IEEE, P4814, DOI 10.1109/CVPR.2015.7299114
   Hong I., 2016, 2016 53ND ACMEDACIEE, P1
   Jia SY, 2015, IEEE IMAGE PROC, P4738, DOI 10.1109/ICIP.2015.7351706
   Kim G, 2015, IEEE J SOLID-ST CIRC, V50, P113, DOI 10.1109/JSSC.2014.2352303
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Liu Z, 2014, IEEE T CIRC SYST VID, V24, P1522, DOI 10.1109/TCSVT.2014.2308642
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Lucchi A, 2010, LECT NOTES COMPUT SC, V6362, P463
   Massoudifar P, 2014, IEEE COMPUT SOC CONF, P287, DOI 10.1109/CVPRW.2014.51
   Mori G, 2005, IEEE I CONF COMP VIS, P1417
   Psalta A., 2016, Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS), 2016 8th Workshop on, P1, DOI DOI 10.1109/WHISPERS.2016.8071793
   Rafi M, 2019, MULTIMED TOOLS APPL, V78, P19735, DOI 10.1007/s11042-019-7153-z
   Ren C.Y., 2015, gSLICr: SLIC superpixels at over 250Hz
   Ren C. Y, 2011, Technical Report
   Su TF, 2019, MULTIMED TOOLS APPL, V78, P34173, DOI 10.1007/s11042-019-08224-6
   Thapa A, 2021, MULTIMED TOOLS APPL, V80, P25411, DOI 10.1007/s11042-021-10869-1
   Ullah S, 2021, MULTIMED TOOLS APPL
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Wang YZ, 2018, MULTIMED TOOLS APPL, V77, P11883, DOI 10.1007/s11042-017-4839-y
   Wu C, 2021, IEEE T CIRC SYST VID, V31, P2114, DOI 10.1109/TCSVT.2020.3019109
   Xu LF, 2014, SIGNAL IMAGE VIDEO P, V8, P181, DOI 10.1007/s11760-013-0520-8
   Zhang YX, 2020, IEEE GEOSCI REMOTE S, V17, P1440, DOI 10.1109/LGRS.2019.2945546
   Zitnick CL, 2007, INT J COMPUT VISION, V75, P49, DOI 10.1007/s11263-006-0018-8
NR 30
TC 2
Z9 2
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32449
EP 32467
DI 10.1007/s11042-022-12594-9
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000783454600003
DA 2024-07-18
ER

PT J
AU Halabi, O
   Salahuddin, T
   Karkar, AG
   Alinier, G
AF Halabi, Osama
   Salahuddin, Tooba
   Karkar, Abdel Ghani
   Alinier, Guillaume
TI Virtual reality for ambulance simulation environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality simulation; Ambulance design; Ambulance patient
   compartment; Equipment positioning
ID DESIGN
AB Simulations are beneficial in evaluating clinicians' empirical competencies through practical skills, prioritizing, and decision-making as part of patient care scenarios generally run in a full-scale physical context. However, such simulations require physical space, manufacturing, and replacement of damaged or used equipment. On the other hand, virtual reality (VR) computerized simulators are comparatively modern instruments for use in practical training. VR can be employed to simulate real-world situations without the actual need for physical devices. This work presents an ambulance patient compartment VR simulation that can be used by emergency medical services (EMS) staff to customize the configuration of the ambulance patient compartment according to their preference as well as for vehicle orientation or training purposes. The proposed simulation can be used repeatedly enabling the paramedics to access equipment in a fully immersive and safe environment. The user studies have demonstrated the usability and perceived effectiveness of the proposed simulation.
C1 [Halabi, Osama; Salahuddin, Tooba; Karkar, Abdel Ghani] Qatar Univ, Coll Engn, Dept Comp Sci & Engn, Doha, Qatar.
   [Salahuddin, Tooba] Qatar Univ, KINDI Ctr Comp Res, Doha, Qatar.
   [Alinier, Guillaume] Hamad Med Corp Ambulance Serv, Doha, Qatar.
   [Alinier, Guillaume] Univ Hertfordshire, Sch Hlth & Social Work, Hatfield, Herts, England.
   [Alinier, Guillaume] Weill Cornell Med Qatar, Doha, Qatar.
   [Alinier, Guillaume] Northumbria Univ, Newcastle Upon Tyne, Tyne & Wear, England.
C3 Qatar University; Qatar University; Hamad Medical Corporation;
   University of Hertfordshire; Qatar Foundation (QF); Weill Cornell
   Medical College Qatar; Northumbria University
RP Halabi, O (corresponding author), Qatar Univ, Coll Engn, Dept Comp Sci & Engn, Doha, Qatar.
EM ohalabi@qu.edu.qa; t.salahuddin@qu.edu.qa; a.karkar@qu.edu.qa;
   galinier@hamad.qa
RI Halabi, Osama/C-6985-2014
OI Halabi, Osama/0000-0002-2052-0500
FU Qatar National Library
FX Open Access funding provided by the Qatar National Library.
CR Alinier G., 2013, INT PARAMEDIC PRACTI, V3, P35, DOI [10.12968/ippr.2013.3.2.35, DOI 10.12968/IPPR.2013.3.2.35]
   Andreatta PB, 2010, ACAD EMERG MED, V17, P870, DOI 10.1111/j.1553-2712.2010.00728.x
   [Anonymous], 2013, INT PARAMEDIC PRACTI, DOI DOI 10.12968/IPPR.2013.3.1.11
   Calkins H, 2017, J ARRYTHM, V33, P369, DOI 10.1016/j.joa.2017.08.001
   Cochrane T, 2018, PR IEEE INT CONF TEA, P645, DOI 10.1109/TALE.2018.8615124
   Cohen D, 2013, RESUSCITATION, V84, P78, DOI 10.1016/j.resuscitation.2012.05.014
   Desai P R., 2014, International Journal of Engineering Trends and Technology (IJETT), V13, P175, DOI [DOI 10.14445/22315381/IJETT-V13P237, 10.14445/22315381/IJETT-V13P237]
   Dubovsky Steven L, 2017, BMC Res Notes, V10, P15, DOI 10.1186/s13104-016-2337-3
   Engstrom Henrik, 2016, Adv Simul (Lond), V1, P8, DOI 10.1186/s41077-016-0009-y
   Hagiwara Magnus Andersson, 2016, Adv Simul (Lond), V1, P17, DOI 10.1186/s41077-016-0018-x
   Halabi O, 2018, ADV INTELL SYST, V716, P27, DOI 10.1007/978-3-319-73204-6_4
   Halabi O, 2020, MULTIMED TOOLS APPL, V79, P2987, DOI 10.1007/s11042-019-08214-8
   Halabi O, 2017, INT J EMERG TECHNOL, V12, P50, DOI 10.3991/ijet.v12i05.6766
   Hsu E.B., 2013, PLoS Curr, V5, DOI DOI 10.1371/CURRENTS.DIS.1-A2B2-71237D5337FA53982A38B2AFF
   Kardong-Edgren S, 2019, CLIN SIMUL NURS, V31, P28, DOI 10.1016/j.ecns.2019.02.006
   Kibira D., 2013, SIW, V2013, P102
   Kibira D, 2015, SIMUL-T SOC MOD SIM, V91, P691, DOI 10.1177/0037549715592716
   Koutitas G, 2021, VIRTUAL REAL-LONDON, V25, P83, DOI 10.1007/s10055-020-00436-8
   Lee EAL, 2010, COMPUT EDUC, V55, P1424, DOI 10.1016/j.compedu.2010.06.006
   Lv ZH, 2020, NEURAL COMPUT APPL, V32, P9593, DOI 10.1007/s00521-019-04472-7
   Lv ZH, 2016, IEEE INTERNET THINGS, V3, P1015, DOI 10.1109/JIOT.2016.2546307
   Mills B, 2020, PREHOSP EMERG CARE, V24, P525, DOI 10.1080/10903127.2019.1676345
   Mossel A, 2017, P IEEE VIRT REAL ANN, P357, DOI 10.1109/VR.2017.7892324
   Padilha JM, 2018, CLIN SIMUL NURS, V15, P13, DOI 10.1016/j.ecns.2017.09.005
   Ricciardi F, 2014, INT J COMPUT GAMES T, V2014, DOI 10.1155/2014/787968
   Roberts MH, 2015, OCCUP ENVIRON MED, V72, P489, DOI 10.1136/oemed-2014-102574
   Schiff JL, 2018, IOP CONCISE PHYS, P1, DOI 10.1088/978-1-64327-004-3
   Schild J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1389, DOI 10.1109/VR.2019.8798365
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Taylor-Nelms L, 2014, INT J SERIOUS GAMES, V1, P3, DOI 10.17083/ijsg.v1i4.40
   Vaughan N, 2019, 2019 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P21, DOI 10.1109/CW.2019.00012
   Wilkerson W, 2008, ACAD EMERG MED, V15, P1152, DOI 10.1111/j.1553-2712.2008.00223.x
   Worldviz, 2016, VIZ VIRT REAL SOFTW
NR 35
TC 2
Z9 2
U1 7
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32119
EP 32137
DI 10.1007/s11042-022-12980-3
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781941600002
OA hybrid
DA 2024-07-18
ER

PT J
AU Bodapati, JD
AF Bodapati, Jyostna Devi
TI Stacked convolutional auto-encoder representations with spatial
   attention for efficient diabetic retinopathy diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic retinopathy; Convolutional neural networks; Spatial attention;
   Convolutional auto-encoder; Neural induced support vector machine;
   Attention; Deep features
ID FUNDUS PHOTOGRAPHS; NEURAL-NETWORKS; SYSTEM
AB Recently, the attention mechanism has been effectively implemented in convolutional neural networks to boost performance of several computer vision tasks. Recognizing the potential of the attention mechanism in medical imaging, we present an end-to-end-trainable spatial Attention based convolutional neural network architecture for recognizing diabetic retinopathy severity level. Initially spatial representations of the fundus images are projected to reduced space using a stacked convolutional Auto-Encoder. In order to enhance discrimination in reduced space, the auto-encoder is jointly trained with the classifier in an end-to-end manner. Attention mechanism introduced in the classification module ensures high emphasis on lesion regions compared to the non-lesion regions. The proposed model is evaluated on two benchmark datasets, and the experimental outcomes indicate that joint training favors stability and complements the learned representations when used along with attention. The proposed approach outperforms several existing models by achieving an accuracy of 84.17%, 63.24% respectively on Kaggle APTOS19 and IDRiD datasets. In addition, ablation studies validate our contributions and the behavior of the proposed model on both the datasets.
C1 [Bodapati, Jyostna Devi] Vignans Fdn Sci Technol & Res, Amaravati 522213, Andhra Pradesh, India.
   [Bodapati, Jyostna Devi] Indian Inst Technol, IIT Madras, Chennai 600036, Tamil Nadu, India.
C3 Vignan's Foundation for Science, Technology & Research (VFSTR); Indian
   Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Madras
RP Bodapati, JD (corresponding author), Vignans Fdn Sci Technol & Res, Amaravati 522213, Andhra Pradesh, India.; Bodapati, JD (corresponding author), Indian Inst Technol, IIT Madras, Chennai 600036, Tamil Nadu, India.
EM jyostna.bodapati82@gmail.com
CR Acharya UR, 2016, COMPUT BIOL MED, V75, P54, DOI 10.1016/j.compbiomed.2016.04.015
   Amin J, 2016, SCIENTIFICA, V2016, DOI 10.1155/2016/6838976
   Bodapati JD, 2019, INT J INNOVATIVE TEC, P2278
   Bodapati JD, 2021, INT J PATTERN RECOGN, V35, DOI 10.1142/S0218001421570056
   Bodapati JD, 2021, SIGNAL IMAGE VIDEO P, V15, P923, DOI 10.1007/s11760-020-01816-y
   Bodapati JD, 2021, J AMB INTEL HUM COMP, V12, P9825, DOI 10.1007/s12652-020-02727-z
   Bodapati JD, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060914
   Chen NC, 2017, IEEE INT CONGR BIG, P1, DOI 10.1109/BigDataCongress.2017.10
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dondeti Venkatesulu, 2020, Revue d'Intelligence Artificielle, V34, P307, DOI 10.18280/ria.340308
   Eftekhari N, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0675-9
   Fang LY, 2019, IEEE T MED IMAGING, V38, P1959, DOI 10.1109/TMI.2019.2898414
   Fukui H, 2019, PROC CVPR IEEE, P10697, DOI 10.1109/CVPR.2019.01096
   Habib M. M., 2017, Informatics in Medicine Unlocked, V9, P44, DOI 10.1016/j.imu.2017.05.006
   He AL, 2021, IEEE T MED IMAGING, V40, P143, DOI 10.1109/TMI.2020.3023463
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Kaggle APTOS, 2019, BLINDN DET KAGGL
   Kandel I, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10062021
   Kassani SH, 2019, IEEE INT S SIGN PROC, P2019
   Kaur N., 2016, 2016 5 INT C WIRELES, P1, DOI 10.1109/WECON.2016.7993461
   Li XM, 2020, IEEE T MED IMAGING, V39, P1483, DOI 10.1109/TMI.2019.2951844
   Lin ZW, 2018, LECT NOTES COMPUT SC, V11071, P74, DOI 10.1007/978-3-030-00934-2_9
   Long SC, 2019, BIOMED RES INT, V2019, DOI 10.1155/2019/3926930
   Luong T., 2015, P 2015 C EMP METH NA, DOI [DOI 10.18653/V1/D15-1166, 10.18653/v1/D15-1166]
   Mansour RF, 2018, BIOMED ENG LETT, V8, P41, DOI 10.1007/s13534-017-0047-y
   Mateen M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010001
   Math L, 2021, MULTIMED TOOLS APPL, V80, P5173, DOI 10.1007/s11042-020-09793-7
   Mohammedhasan M, 2020, TRAIT SIGNAL, V37, P711, DOI 10.18280/ts.370503
   Niemeijer M, 2009, IEEE T MED IMAGING, V28, P775, DOI 10.1109/TMI.2008.2012029
   Poplin R, 2018, NAT BIOMED ENG, V2, P158, DOI 10.1038/s41551-018-0195-0
   Porwal P, 2020, MED IMAGE ANAL, V59, DOI 10.1016/j.media.2019.101561
   Porwal P, 2018, DATA, V3, DOI 10.3390/data3030025
   Prentasic P, 2016, COMPUT METH PROG BIO, V137, P281, DOI 10.1016/j.cmpb.2016.09.018
   Qureshi I, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11060749
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Riaz H, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10010024
   Shaban M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0233514
   Sikder N, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13040670
   Stolte S, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101742
   Thomas RL, 2019, DIABETES RES CLIN PR, V157, DOI 10.1016/j.diabres.2019.107840
   Wiering MA, 2013, BNAIC 2013
   Yang YL, 2022, IEEE T CYBERNETICS, V52, P13762, DOI 10.1109/TCYB.2021.3108034
   Zhang XW, 2014, MED IMAGE ANAL, V18, P1026, DOI 10.1016/j.media.2014.05.004
   Zhao ZY, 2019, IEEE IMAGE PROC, P1385, DOI [10.1109/ICIP.2019.8803074, 10.1109/icip.2019.8803074]
NR 45
TC 13
Z9 13
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32033
EP 32056
DI 10.1007/s11042-022-12811-5
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781124000008
DA 2024-07-18
ER

PT J
AU Hossein-Nejad, Z
   Nasri, M
AF Hossein-Nejad, Zahra
   Nasri, Mehdi
TI Adaptive RANSAC and extended region-growing algorithm for object
   recognition over remote-sensing images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Object recognition; Image matching; RANSAC; SIFT;
   Remote -sensing image
ID RANDOM SAMPLE CONSENSUS; SIFT KEYPOINTS; SEGMENTATION; FEATURES; RGB
AB In this paper, a new approach is proposed for object recognition in remote-sensing images. In the proposed approach, the matching process between the object in the template and test images is done based on Scale Invariant Feature Transform (SIFT). To decrease the false matches of SIFT, an adaptive Random sample consensus (RANSAC) algorithm is used. In the proposed RANSAC, the threshold value is calculated adaptively based on the mean and variance of the correct and false matched points. Finally, the exact object boundary is extracted using the extended region-growing algorithm. The proposed algorithm uses the correct matched points as multiple seed points instead of a single seed point. The proposed method is implemented in MATLAB, and compared with classic object detection methods. Simulation results confirm the superiority of the proposed method based on some evaluation criteria such as precision, correct detection ratio and false alarm rate.
C1 [Hossein-Nejad, Zahra] Islamic Azad Univ, Dept Elect Engn, Sirjan Brach, Kerman, Iran.
   [Nasri, Mehdi] Islamic Azad Univ, Dept Elect Engn, Khomeinishahr Branch, Esfahan, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Nasri, M (corresponding author), Islamic Azad Univ, Dept Elect Engn, Khomeinishahr Branch, Esfahan, Iran.
EM hoseinnejad.zahra@yahoo.com; nasri_me@iaukhsh.ac.ir
RI Nasri, Mehdi/C-2071-2016
OI Nasri, Mehdi/0000-0002-9254-3584
CR Aldoma A, 2012, LECT NOTES COMPUT SC, V7574, P511, DOI 10.1007/978-3-642-33712-3_37
   [Anonymous], 2017, J Mach Vision Image Process, P39
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Borotschnig H, 2000, IMAGE VISION COMPUT, V18, P715, DOI 10.1016/S0262-8856(99)00075-X
   Cheng L., 2016, IEEE J SEL TOP QUANT, V9, P1
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Ferrari V, 2006, INT J COMPUT VISION, V67, P159, DOI 10.1007/s11263-005-3964-7
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Flitton Greg, 2010, BMVC, DOI [DOI 10.5244/C.24.11, 10.5244/C.24.11]
   Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408, DOI 10.1007/3-540-47977-5_27
   Gul-e-Saman, 2008, THIRD INTERNATIONAL WORKSHOP ON SEMANTIC MEDIA ADAPTATION AND PERSONALIZATION, PROCEEDINGS, P33, DOI 10.1109/SMAP.2008.12
   Guo H, 2016, TELKOMNIKA TELECOMMU, V14
   Gupta S, 2019, MULTIMED TOOLS APPL, V78, P34157, DOI 10.1007/s11042-019-08232-6
   Hossein-Nejad Z., 2019, CRYPTOGRAPHIC INFORM, P773
   Hossein-Nejad Z., 2020, J Mach Vision Image Process, V7, P165
   Hossein-Nejad Z, 2019, IRAN CONF ELECTR ENG, P1294, DOI [10.1109/iraniancee.2019.8786443, 10.1109/IranianCEE.2019.8786443]
   Hossein-Nejad Z, 2018, BIOMED SIGNAL PROCES, V45, P325, DOI 10.1016/j.bspc.2018.06.002
   Hossein-Nejad Z, 2017, COMPUT ELECTR ENG, V62, P524, DOI 10.1016/j.compeleceng.2016.11.034
   Hossein-Nejad Z, 2017, IET IMAGE PROCESS, V11, P273, DOI 10.1049/iet-ipr.2016.0440
   Hu XL, 2007, 2008 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND SIGNAL PROCESSING, VOLS 1 AND 2, P412
   Johnson AE, 1997, PROC CVPR IEEE, P684, DOI 10.1109/CVPR.1997.609400
   Kamdi S, 2012, INT J COMPUT TECHNOL, P2
   Kimmel R, 2011, IEEE T PATTERN ANAL, V33, P2316, DOI 10.1109/TPAMI.2011.133
   Lee H, 2014, INT CONF SYST SCI EN, P273, DOI 10.1109/ICSSE.2014.6887948
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Li QL, 2009, IEEE GEOSCI REMOTE S, V6, P287, DOI 10.1109/LGRS.2008.2011751
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Loncomilla P, 2016, PATTERN RECOGN, V60, P499, DOI 10.1016/j.patcog.2016.05.021
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Luo S, 2015, IEEE SENS J, V15, P5001, DOI 10.1109/JSEN.2015.2432127
   Mian AS, 2006, IEEE T PATTERN ANAL, V28, P1584, DOI 10.1109/TPAMI.2006.213
   Nasir H, 2010, EUR SIGNAL PR CONF, P299
   Cherloo MN, 2020, SIGNAL IMAGE VIDEO P, V14, P425, DOI 10.1007/s11760-019-01572-8
   Pavel FA, 2009, IEEE INT WORKSH MULT, P368
   Sedaghat A, 2015, IEEE T GEOSCI REMOTE, V53, P5283, DOI 10.1109/TGRS.2015.2420659
   Seidenari L, 2014, IEEE T PATTERN ANAL, V36, P1033, DOI 10.1109/TPAMI.2013.232
   Shah SAA, 2016, NEUROCOMPUTING, V205, P1, DOI 10.1016/j.neucom.2015.11.019
   Shweta Yakkali VN., 2015, INT J ADV RES COMP S, V5, P683
   Sirmaçek B, 2009, IEEE T GEOSCI REMOTE, V47, P1156, DOI 10.1109/TGRS.2008.2008440
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Surkutlawar S, 2013, INT J ADV COMPUT SC, V4, P164
   Tao C, 2011, IEEE GEOSCI REMOTE S, V8, P128, DOI 10.1109/LGRS.2010.2051792
   Tranos Zuva OOO, 2011, CANAD J IMAGE PROCES, V2, P20
   Wang C, 2019, J PHYS C SER
   Wang SH, 2012, IEEE GEOSCI REMOTE S, V9, P649, DOI 10.1109/LGRS.2011.2177437
   Xie BJ, 2016, NEUROCOMPUTING, V182, P94, DOI 10.1016/j.neucom.2015.12.007
   Ye YX, 2014, ISPRS J PHOTOGRAMM, V90, P83, DOI 10.1016/j.isprsjprs.2014.01.009
   Zhang S, 2015, IEEE SENS J, V15, P2679, DOI 10.1109/JSEN.2014.2382174
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
   Zhu CZ, 2003, NEUROIMAGE, V18, P685, DOI 10.1016/S1053-8119(03)00006-5
   Zohrevand A, 2014, INTELLIGENT SYSTEMS, P1
   Zucker S. W., 1976, Computer Graphics and Image Processing, V5, P382, DOI 10.1016/S0146-664X(76)80014-7
NR 54
TC 6
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31685
EP 31708
DI 10.1007/s11042-022-13021-9
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000779973300003
DA 2024-07-18
ER

PT J
AU Shantkumari, M
   Uma, SV
AF Shantkumari, M.
   Uma, S., V
TI Grape leaf image classification based on machine learning technique for
   accurate leaf disease detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Grape leaf disease; Classification; IKKN model; Histogram gradient
   features; Convolutional neural network (CNN)
AB Grape leaf diseases have a major impact on the growth of grape industry and grape crop yield. Thus, there is a need of a grape disease detection in early stages of disease so that disease spread and their impact could be controlled and development and production of grape industry remain continuous and active. However, the detection of grape leaf disease in initial stages is highly critical and challenging. Therefore, in this article, machine learning technique is adopted for the early detection of grape leaf disease and accurately distinguish between various classes of disease. Furthermore, Convolutional Neural Network based Classification (CNNC) model and improvised K- Nearest Neighbor (IKNN) model are introduced for classification of leaf diseases. High quality histogram and extended histogram features are obtained to provide structural, pattern, boundary and discriminative information. Then, classification process is performed on the obtained high quality gradient based features. Classification accuracy is improved to a great extent using proposed CNNC and IKNN model. The accuracy of the proposed CNNC and IKKN model is tested with the help of public dataset named as Plant-Village Dataset. The performance of proposed CNNC and IKKN model is compared with various traditional classification models considering classification accuracy.
C1 [Shantkumari, M.] VTU RC, Belagavi, Karnataka, India.
   [Uma, S., V] RNSIT, Bangalore, Karnataka, India.
C3 Visvesvaraya Technological University
RP Shantkumari, M (corresponding author), VTU RC, Belagavi, Karnataka, India.
EM shantkumarim@rediffmail.com; umakeshav2000@gmail.com
RI V, Uma S/AAE-8882-2021
OI V, Uma S/0000-0002-2389-011X
CR Amara J., 2017, DEEP LEARNING BASED, P79
   [Anonymous], 2000, REPORT EXPERT CONSUL
   Burrell J, 2004, IEEE PERVAS COMPUT, V3, P38, DOI 10.1109/MPRV.2004.1269130
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Colomina I, 2014, ISPRS J PHOTOGRAMM, V92, P79, DOI 10.1016/j.isprsjprs.2014.02.013
   Hall A, 2002, AUST J GRAPE WINE R, V8, P36, DOI 10.1111/j.1755-0238.2002.tb00209.x
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   International Organization of Vine and Wine (OIV), 2009, BAL OIV SIT VIT MUND
   Jogekar R, 2020, PROCEEDINGS OF THE 2020 FOURTH WORLD CONFERENCE ON SMART TRENDS IN SYSTEMS, SECURITY AND SUSTAINABILITY (WORLDS4 2020), P745, DOI [10.1109/WorldS450073.2020.9210401, 10.1109/worlds450073.2020.9210401]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu B, 2020, IEEE ACCESS, V8, P102188, DOI 10.1109/ACCESS.2020.2998839
   Padol PB, 2016, 2016 CONFERENCE ON ADVANCES IN SIGNAL PROCESSING (CASP), P175
   Ruiz-Garcia L, 2009, SENSORS-BASEL, V9, P4728, DOI 10.3390/s90604728
   Seng KP, 2018, IEEE ACCESS, V6, P67494, DOI 10.1109/ACCESS.2018.2875862
   Shikhamany S., 2000, GRAPE PRODUCTION IND
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sinha A, 2020, IET IMAGE PROCESS, V14, P1427, DOI 10.1049/iet-ipr.2018.6210
   Zhu JH, 2020, MULTIMED TOOLS APPL, V79, P14539, DOI 10.1007/s11042-018-7092-0
NR 19
TC 7
Z9 7
U1 5
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1477
EP 1487
DI 10.1007/s11042-022-12976-z
EA APR 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000781124000009
DA 2024-07-18
ER

PT J
AU Kohli, A
   Gupta, A
AF Kohli, Aditi
   Gupta, Abhinav
TI Light-weight 3DCNN for DeepFakes, FaceSwap and Face2Face facial forgery
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3DCNN; Face forensics
AB Detecting facial forgery in real time application such as video conferencing, netbanking, verification of identity etc. is a major concern. Highly accurate facial forgery detectors will be incompatible with limited computation and storage space devices like smartphones, tablets, PCs due to their deep complex architectures. Therefore, we propose a light weight 3D convolutional neural networks (3DCNN) to detect popular facial forgeries namely, DeepFakes, Face2Face and FaceSwap. The proposed 3DCNN is a five layered architecture with only 2.69M trainable parameters. The proposed network learns spatio-temporal features to detect forged videos. Further, to understand the detection process of 3DCNN, activation maps are studied in detail. The popular FaceForensic++ dataset is employed to train and test the proposed method. In addition, the effectiveness of the proposed method is evaluated and compared with state-of-the art methods in terms of both, number of trainable parameters and binary detection accuracy.
C1 [Kohli, Aditi] Jaypee Inst Informat Technol, Dept Elect & Commun Engn, A-10,Sect 62, Noida 201309, Uttar Pradesh, India.
   [Gupta, Abhinav] RBS Serv India Private Ltd, NatWest Grp, Candor Techspace, Sect 21, Gurugram 122016, Haryana, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Gupta, A (corresponding author), RBS Serv India Private Ltd, NatWest Grp, Candor Techspace, Sect 21, Gurugram 122016, Haryana, India.
EM abhinav.gupta1@natwest.com
OI GUPTA, ABHINAV/0000-0002-1939-5407
FU Council of Scientific and Industrial Research, India (CSIR)
   [09/1132(0010)/2019 EMR-I]
FX The authors would thank Council of Scientific and Industrial Research,
   India (CSIR) for providing financial support to conduct research work,
   file No. 09/1132(0010)/2019 EMR-I.
CR Amerini I, 2019, IEEE INT CONF COMP V, P1205, DOI 10.1109/ICCVW.2019.00152
   Amirkhani D, 2021, MULTIMED TOOLS APPL, V80, P26199, DOI 10.1007/s11042-021-10883-3
   Baek JY, 2020, IEEE ACCESS, V8, P45421, DOI 10.1109/ACCESS.2020.2968612
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cozzolino D, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P159, DOI 10.1145/3082031.3083247
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Iandola Forrest N, 2016, SQUEEZENET ALEXNET L
   Kohli A, 2021, MULTIMED TOOLS APPL, V80, P18461, DOI 10.1007/s11042-020-10420-8
   Rahmouni N, 2017, IEEE INT WORKS INFOR
   Rossi A, 2020, IEEE T INTELL TRANSP, V21, P2980, DOI 10.1109/TITS.2019.2922002
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Theobalt Chris- tian, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.262
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang YH, 2020, IEEE INT CONF AUTOMA, P515, DOI 10.1109/FG47880.2020.00089
   Yang ZC, 2015, IEEE I CONF COMP VIS, P1476, DOI 10.1109/ICCV.2015.173
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
NR 26
TC 5
Z9 5
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31391
EP 31403
DI 10.1007/s11042-022-12778-3
EA APR 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000779805700003
DA 2024-07-18
ER

PT J
AU Wang, JJ
   Huang, CW
   Zhao, LY
   Li, Z
AF Wang, Junjie
   Huang, Chengwei
   Zhao, Liye
   Li, Zhi
TI Lightweight identification of retail products based on improved
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Smart retail; Object identification
AB Due to the similar appearances among many retail products, it is a big challenge to identify the product with high accuracy and low computational cost in smart retail scenes. In this paper, we proposed a lightweight retail product identification and localization method based on an improved convolutional neural network. First, we use group convolution and deep separable convolution to optimize the structure of the backbone network and reduce the amount of calculation. Second, the multiscale structure was adjusted to optimal scales. We further use the k-means clustering algorithm to re-cluster six anchors with different sizes. Third, we introduced spatial pyramid pooling (SPP) to replace pooling by convolution to effectively improve the robustness against image distortion, such as cropping and scaling. Finally, we use mosaic data enhancement method to improved the robustness of the network. Experiments on the RPC dataset show that, compared with YOLOv5, the number of parameters is reduced by 1/6.4 times, and FLOPs is reduced by 1/9 times. Experiments on the DeepBlue Retail Dataset show that compared with YOLOv5, the number of parameters is reduced by 1/7.8 times, and FLOPs is reduced by 1/9.3 times. Realtime evaluation under the same hardware show that the FPS of the proposed model is 123 in the forward inference test, while the FPS of the YOLOv5 model under the same conditions is 58.
C1 [Wang, Junjie; Zhao, Liye] Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China.
   [Huang, Chengwei] Jiangsu Intever Energy Technol Co Ltd, Nanjing, Peoples R China.
   [Li, Zhi] Southeast Univ, Sch Elect Engn, Nanjing 210096, Peoples R China.
C3 Southeast University - China; Southeast University - China
RP Zhao, LY (corresponding author), Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China.
EM chunchiehwang@seu.edu.cn; chengwei.huang@hotmail.com;
   liyezhao@seu.edu.cn; lizhi95@seu.edu.cn
CR Baz I, 2016, 2016 IEEE 12TH IMAGE, VIDEO, AND MULTIDIMENSIONAL SIGNAL PROCESSING WORKSHOP (IVMSP)
   Bochkovskiy A., 2020, PREPRINT
   Chong T, 2016, SEMANTIC SCHOLAR, P1
   Cui Q., 2019, DEEP LEARNING FINE G
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Efraty B., 2011, IJCB, P1
   Farren D., 2017, CLASSIFYING FOOD ITE
   Geng WD, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1706, DOI 10.1145/3240508.3240522
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang C, 2012, IEEE INT WORKS INFOR, P13, DOI 10.1109/WIFS.2012.6412618
   Huang C, 2009, 3 INT C AFF COMP INT, P1
   Huang C, 2013, MATH PROBL ENG
   Huang Cheng-wei, 2010, Technical Acoustics, V29, P396, DOI 10.3969/j.issn1000-3630.2010.04.010
   Huang CW, 2019, MULTIMED TOOLS APPL, V78, P20679, DOI 10.1007/s11042-019-7440-8
   Jin Yun, 2010, Technical Acoustics, V29, P63, DOI 10.3969/j.issn1000-3630.2010.01.015
   Jin Y, 2009, PROCEEDINGS OF THE 2009 WRI GLOBAL CONGRESS ON INTELLIGENT SYSTEMS, VOL III, P242, DOI 10.1109/GCIS.2009.175
   Jund P, 2016, ARXIV PREPRINT ARXIV
   Karlinsky L, 2017, PROC CVPR IEEE, P965, DOI 10.1109/CVPR.2017.109
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar Krishan, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 704), P37, DOI 10.1007/978-981-10-7898-9_4
   Kumar K, 2021, MULTIMED TOOLS APPL, V80, P11079, DOI 10.1007/s11042-020-10157-4
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P26635, DOI 10.1007/s11042-018-5882-z
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P7383, DOI 10.1007/s11042-017-4642-9
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu LZ, 2018, IEEE INT WORKSH COMP, P98
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   [罗武骏 Luo Wujun], 2013, [信号处理, Journal of Signal Processing], V29, P1423
   Melek CG, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P145, DOI 10.1109/UBMK.2017.8093584
   Merler M, 2007, PROC CVPR IEEE, P3634
   Milella Annalisa, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12662), P447, DOI 10.1007/978-3-030-68790-8_35
   Paolanti M, 2019, ROBOT AUTON SYST, V118, P179, DOI 10.1016/j.robot.2019.01.021
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Santra B, 2019, IMAGE VISION COMPUT, V86, P45, DOI 10.1016/j.imavis.2019.03.005
   Shankar V, 2021, J RETAILING, V97, P13, DOI 10.1016/j.jretai.2020.10.006
   Sharma S, 2017, 2017 IEEE 7TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE IEEE CCWC-2017
   Sharma S, 2021, MULTIMED TOOLS APPL, V80, P26319, DOI 10.1007/s11042-021-10768-5
   Singh H, 2017, 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT - 2017), P29, DOI 10.1145/3154979.3154996
   Sriram T, 1996, IEEE IND ELEC, P641, DOI 10.1109/IECON.1996.571035
   Srivastava Muktabh Mayank, 2020, Image Analysis and Recognition. 17th International Conference, ICIAR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12131), P71, DOI 10.1007/978-3-030-50347-5_8
   Sun H, 2020, TEMPLATEFREE PRODUCT, V15
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tonioni A, 2019, COMPUT VIS IMAGE UND, V182, P81, DOI 10.1016/j.cviu.2019.03.005
   Wang WY, 2020, NEURAL COMPUT APPL, V32, P14613, DOI 10.1007/s00521-020-05148-3
   Want R, 2006, IEEE PERVAS COMPUT, V5, P25, DOI 10.1109/MPRV.2006.2
   Wu CJ, 2015, LECT NOTES COMPUT SC, V9502, P427, DOI 10.1007/978-3-319-27293-1_37
   Yan J, 2020, IEEE T AFFECT COMPUT, DOI 10.1109/TAFFC.2020.3030296
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
NR 54
TC 2
Z9 2
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31313
EP 31328
DI 10.1007/s11042-022-12872-6
EA APR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781336100002
DA 2024-07-18
ER

PT J
AU Wang, XL
   Xie, D
   Chen, FL
   Wu, B
   Zen, YY
AF Wang, Xueli
   Xie, Dong
   Chen, Fulong
   Wu, Bin
   Zen, Yangyang
TI Progressive and multi-level secret image sharing scheme with
   hierarchical shadows
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret image sharing; Lagrange interpolation; Hierarchical shadows;
   Progressive reconstruction; Multi-level secret image; Birkhoff
   interpolation
ID CONSTRUCTIONS
AB Multi-level secret image sharing is a scheme combining hierarchical shadows with progressive reconstruction. But in previous schemes, the generated shadows are divided into two hierarchies, and these hierarchy layers are stationary without considering dynamic environment demand. In this paper, we propose an improve secret image sharing based on Lagrange interpolation and Birkhoff interpolation. Generated shadows can divided any hierarchy according to specific application needs. In the proposed scheme, the secret image is divided into sub-images with different quality. And the corresponding temporary shadows are generated using some distinctive algorithms. Afterwards, the final shadows with any hierarchy can be generated by combining those temporary shadows. In the image reconstruction, sub-images can be partially reconstructed when the collected shadows come from different hierarchies. The original secret image can be reconstructed progressively by combining sub-images. The higher hierarchy and the more the number of participating shadows, the higher the quality of reconstructed image. When all requirements are met or n shadows have participated, the lossless secret image can be obtained. When some parts of shadows lost, most exist schemes cannot reconstruct the secret completely. However, the proposed method has the capability of the loss recovery. Correctness and security analysis is also given in the experiment.
C1 [Wang, Xueli; Xie, Dong; Chen, Fulong; Wu, Bin; Zen, Yangyang] Anhui Prov Key Lab Network & Informat Secur, Wuhu, Peoples R China.
   [Wang, Xueli; Xie, Dong; Chen, Fulong; Wu, Bin; Zen, Yangyang] Anhui Normal Univ, Sch Comp & Informat, Wuhu 241002, Peoples R China.
C3 Anhui Normal University
RP Xie, D (corresponding author), Anhui Prov Key Lab Network & Informat Secur, Wuhu, Peoples R China.; Xie, D (corresponding author), Anhui Normal Univ, Sch Comp & Informat, Wuhu 241002, Peoples R China.
EM xiedong@ahnu.edu.cn
RI Wu, Bin/KHD-4133-2024
FU National Natural Science Foundation of China [61801004, 61572036,
   61771071]; Natural Science Foundation of Anhui Province [1808085QF211]
FX This paper is supported by the National Natural Science Foundation of
   China (Grant Nos. 61801004, 61572036 and 61771071), and the Natural
   Science Foundation of Anhui Province (Grant No.1808085QF211).
CR Alsharif MH, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010088
   Bao L, 2017, IEEE T IMAGE PROCESS, V26, P5618, DOI 10.1109/TIP.2017.2738561
   Bhattacharjee T, 2018, SIGNAL PROCESS-IMAGE, V61, P21, DOI 10.1016/j.image.2017.10.012
   Chang J, 2018, CRYPTOGRAPHY-BASEL
   Charoghchi S, 2021, INFORM SCIENCES, V552, P220, DOI 10.1016/j.ins.2020.11.034
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   De Prisco R, 2014, IEEE T INF FOREN SEC, V9, P653, DOI 10.1109/TIFS.2014.2305574
   Ding WM, 2018, INT J DIGIT CRIME FO, V10, P120, DOI 10.4018/IJDCF.2018040107
   Fu AM, 2017, WIREL NETW, V23, P2165, DOI 10.1007/s11276-016-1277-0
   Gong QH, 2019, IEEE ACCESS, V7, P113216, DOI 10.1109/ACCESS.2019.2934999
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Hou YC, 2014, IEEE T CIRC SYST VID, V24, P733, DOI 10.1109/TCSVT.2013.2280097
   Kalita DJ, 2020, LECT NOTES NETWORKS, V100
   Kang I, 2011, IEEE T IMAGE PROCESS, V20, P132, DOI 10.1109/TIP.2010.2056376
   Li P, 2013, J VIS COMMUN IMAGE R, V24, P1106, DOI 10.1016/j.jvcir.2013.07.005
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin PY, 2009, PATTERN RECOGN, V42, P886, DOI 10.1016/j.patcog.2008.09.014
   Lin YY, 2010, IEEE SIGNAL PROC LET, V17, P316, DOI 10.1109/LSP.2009.2038113
   Liu YX, 2014, SECUR COMMUN NETW, V7, P2237, DOI 10.1002/sec.930
   Liu YX, 2017, SIGNAL PROCESS-IMAGE, V58, P49, DOI 10.1016/j.image.2017.06.011
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Qiu Y, 2010, SCAND J IMMUNOL, V72, P425, DOI 10.1111/j.1365-3083.2010.02456.x
   Reddy LS, 2016, SMART INNOV SYST TEC, V44, P249, DOI 10.1007/978-81-322-2529-4_26
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SJ, 2013, IEEE T INF FOREN SEC, V8, P733, DOI 10.1109/TIFS.2013.2250432
   Tassa T, 2007, J CRYPTOL, V20, P237, DOI 10.1007/s00145-006-0334-8
   Wang DS, 2013, IEEE T INF FOREN SEC, V8, P2059, DOI 10.1109/TIFS.2013.2281108
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Wu Z, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8030448
   Yan XH, 2019, SIGNAL PROCESS-IMAGE, V71, P66, DOI 10.1016/j.image.2018.11.002
   Yang CN, 2011, J SYST SOFTWARE, V84, P1726, DOI 10.1016/j.jss.2011.05.008
   Yang CN, 2010, OPT COMMUN, V283, P1750, DOI 10.1016/j.optcom.2009.12.077
NR 33
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 31039
EP 31059
DI 10.1007/s11042-022-12951-8
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000781336500007
DA 2024-07-18
ER

PT J
AU Cocoma-Ortega, JA
   Patricio, F
   Limon, ID
   Martinez-Carranza, J
AF Cocoma-Ortega, J. Arturo
   Patricio, Felipe
   Limon, Ilhuicamina Daniel
   Martinez-Carranza, Jose
TI A deep learning-based approach for real-time rodent detection and
   behaviour classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Rat behaviours; Locomotion; Real-time
ID OPEN-FIELD; LOCOMOTOR-ACTIVITY; DETECTION SYSTEM; VIDEO TRACKING;
   ANXIETY
AB Animal models are helpful to evaluate the effects of some drugs in the treatment of brain diseases, such as the case of the Open Field Maze. Usually, these tests are recorded in video and analysed afterwards to carry out manual annotations about the activity and behaviour of the rat. Usually, these videos must be watched repeatedly to ensure correct annotations, but they are prone to become a tedious task and are highly likely to produce human errors. Existing commercial systems for automatic detection of the rat and classification of its behaviours may become inaccessible for research teams that cannot afford the license cost. Motivated by the latter, we propose a methodology for simultaneous rat detection and behaviour classification using inexpensive hardware in this work. Our proposal is a Deep Learning-based two-step methodology to simultaneously detect the rat in the test and classify its behaviour. In the first step, a single shot detector network is used to detect the rat; then, the systems crop the image using the bounding box to generate a sequence of six images that input our BehavioursNet network to classify the rodent's behaviour. Finally, based on the results of these steps, the system generates an ethogram for the complete video, a trajectory plot, a heatmap plot for most visited regions and a video showing the rat's detection and its behaviours. Our results show that it is possible to perform these tasks at a processing rate of 23 Hz, with a low error of 6 pixels in the detection and a first approach to classify ambiguous behaviours such as resting and grooming, with an average precision of 60%, which is competitive with that reported in the literature.
C1 [Cocoma-Ortega, J. Arturo; Martinez-Carranza, Jose] Inst Nacl Astrofis Opt & Electr, Dept Computat Sci, Luis Enrique Erro 1, Puebla 72840, Mexico.
   [Patricio, Felipe; Limon, Ilhuicamina Daniel] Benemerita Univ Autonoma Puebla, Lab Neurofarmacol, Av San Claudio, Puebla 72570, Mexico.
C3 Instituto Nacional de Astrofisica, Optica y Electronica; Benemerita
   Universidad Autonoma de Puebla
RP Martinez-Carranza, J (corresponding author), Inst Nacl Astrofis Opt & Electr, Dept Computat Sci, Luis Enrique Erro 1, Puebla 72840, Mexico.
EM cocoma@inaoep.mx; felipe.patmar@gmail.com; ilhlimon@yahoo.com.mx;
   carranza@inaoep.mx
RI Patricio, Felipe/GPK-4293-2022; Martinez-Carranza, Jose/Y-1190-2019;
   Patricio-Martínez, Felipe/GOK-1794-2022
OI Patricio, Felipe/0000-0003-0531-7229; Martinez-Carranza,
   Jose/0000-0002-8914-1904; Patricio-Martínez, Felipe/0000-0003-0531-7229;
   Limon Perez de Leon, Daniel/0000-0003-4669-2199
FU Consejo Nacional de Ciencia y Tecnologia (CONACYT) [719218]
FX First author thanks to Consejo Nacional de Ciencia y Tecnologia
   (CONACYT) for the scholarship no. 719218
CR Arac A, 2019, FRONT SYST NEUROSCI, V13, DOI 10.3389/fnsys.2019.00020
   Aragao RD, 2011, J NEUROSCI METH, V195, P216, DOI 10.1016/j.jneumeth.2010.12.016
   Cocoma-Ortega JA, 2019, LECT NOTES COMPUT SC, V11524, P159, DOI 10.1007/978-3-030-21077-9_15
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Brenes JC, 2009, BEHAV BRAIN RES, V197, P125, DOI 10.1016/j.bbr.2008.08.014
   Bryda Elizabeth C, 2013, Mo Med, V110, P207
   Chanchanachitkul W, 2013, 6 2013 BIOM ENG INT, P1
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Cocoma-Ortega JA, 2022, J REAL-TIME IMAGE PR, V19, P73, DOI 10.1007/s11554-021-01162-3
   da Silva Monteiro JP, 2012, THESIS FACULTY ENG U
   Dai Z., 2021, 35 C NEURAL INFORM P
   de Menezes R, 2020, AN 47 SEM INT SOFTW, P162
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Geuther BQ, 2018, ROBUST MOUSE TRACKIN, DOI 10.1101/336685
   Geuther BQ, 2021, ELIFE, V10, DOI 10.7554/eLife.63207
   Giancardo L, 2012, INT C PATT RECOG, P2520
   Gianelli S, 2018, J NEUROSCI METH, V294, P40, DOI 10.1016/j.jneumeth.2017.10.021
   GIULIAN D, 1975, PHYSIOL BEHAV, V14, P109, DOI 10.1016/0031-9384(75)90150-X
   Gomez-Marin A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0041642
   Hånell A, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00252
   Heredia-López FJ, 2013, BEHAV RES METHODS, V45, P183, DOI 10.3758/s13428-012-0221-1
   Higaki A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0197003
   Hong WZ, 2015, P NATL ACAD SCI USA, V112, pE5351, DOI 10.1073/pnas.1515982112
   Howerton CL, 2012, J NEUROSCI METH, V209, P74, DOI 10.1016/j.jneumeth.2012.06.001
   Linares-Sánchez LJ, 2015, IEEE ENG MED BIO, P755, DOI 10.1109/EMBC.2015.7318472
   Jia YY, 2016, IEEE ENG MED BIO, P6323, DOI 10.1109/EMBC.2016.7592174
   Jin TL, 2019, IEEE ACCESS, V7, P62152, DOI 10.1109/ACCESS.2019.2916339
   Kalueff AV, 2007, NAT PROTOC, V2, P2538, DOI 10.1038/nprot.2007.367
   Kalueff AV, 2016, NAT REV NEUROSCI, V17, P45, DOI 10.1038/nrn.2015.8
   Kalueff AV, 2005, J NEUROSCI METH, V143, P169, DOI 10.1016/j.jneumeth.2004.10.001
   Kim JH, 2018, DISPLAYS, V55, P38, DOI 10.1016/j.displa.2018.08.001
   Kobayashi K, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-79965-w
   Kraeuter AK, 2019, METHODS MOL BIOL, V1916, P99, DOI 10.1007/978-1-4939-8994-2_9
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Lai PL, 2011, 3 TRACKING MOUSE LOC
   Lamprea MR, 2008, BRAZ J MED BIOL RES, V41, P135, DOI 10.1590/S0100-879X2008000200010
   Lee CC, 2019, 2019 9 INT C IM PROC, P1
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2021, ARXIV 211109883
   Lv XD, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010002
   Macrì S, 2015, IEEE ENG MED BIO, P4946, DOI 10.1109/EMBC.2015.7319501
   Matsumoto J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0078460
   Mazur-Milecka M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10175979
   Moulin TC, 2021, NEUROSCI BIOBEHAV R, V120, P1, DOI 10.1016/j.neubiorev.2020.11.014
   O'Connor C, 2003, J NEUROTRAUM, V20, P985, DOI 10.1089/089771503770195830
   Ohayon S, 2013, J NEUROSCI METH, V219, P10, DOI 10.1016/j.jneumeth.2013.05.013
   Ou-Yang TH, 2011, J NEUROSCI METH, V201, P116, DOI 10.1016/j.jneumeth.2011.07.019
   Park SJ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21216954
   Prut L, 2003, EUR J PHARMACOL, V463, P3, DOI 10.1016/S0014-2999(03)01272-X
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren ZZ, 2017, IEEE WINT CONF APPL, P1277, DOI 10.1109/WACV.2017.147
   Rojas-Perez LO, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164524
   Samson AL, 2015, SCI REP-UK
   Saré RM, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11040522
   Seibenhener ML, 2015, JOVE-J VIS EXP, DOI 10.3791/52434
   Sourioux M, 2018, J NEUROSCI METH, V295, P51, DOI 10.1016/j.jneumeth.2017.11.016
   Spink AJ, 2001, PHYSIOL BEHAV, V73, P731, DOI 10.1016/S0031-9384(01)00530-3
   Sturman O, 2020, NEUROPSYCHOPHARMACOL, V45, P1942, DOI 10.1038/s41386-020-0776-y
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tungtur SK, 2017, BIOTECHNIQUES, V63, P215, DOI 10.2144/000114607
   Valletta JJ, 2017, ANIM BEHAV, V124, P203, DOI 10.1016/j.anbehav.2016.12.005
   van Dam EA, 2020, J NEUROSCI METH, V332, DOI 10.1016/j.jneumeth.2019.108536
   Vuralli D, 2019, J HEADACHE PAIN, V20, DOI 10.1186/s10194-019-0963-6
   Wang ZY, 2015, BIOMED CIRC SYST C, P684, DOI 10.1109/BioCAS.2015.7348456
   Whishaw I.Q., 1999, Modern techniques in neuroscience research, P1243, DOI DOI 10.1007/978-3-642-58552-4_44
   Wilson JC, 2015, J NEUROSCI METH, V253, P78, DOI 10.1016/j.jneumeth.2015.06.015
   Xie XS, 2012, RODENT BEHAV ASSESSM, P205, DOI DOI 10.1007/978-1-61779-576-3_13
   Ziegelaar, 2015, THESIS SCH MECH MINI
NR 70
TC 1
Z9 1
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30329
EP 30350
DI 10.1007/s11042-022-12664-y
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000778917900006
DA 2024-07-18
ER

PT J
AU Bencherqui, A
   Daoui, A
   Karmouni, H
   Qjidaa, H
   Alfidi, M
   Sayyouri, M
AF Bencherqui, Ahmed
   Daoui, Achraf
   Karmouni, Hicham
   Qjidaa, Hassan
   Alfidi, Mohammed
   Sayyouri, Mhamed
TI Optimal reconstruction and compression of signals and images by Hahn
   moments and artificial bee Colony (ABC) algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hahn polynomials; Hahn moments; Bio-signal and image reconstruction;
   Bio-signal and image compression; Artificial bee Colony (ABC)
ID CLASSIFICATION; PERFORMANCE
AB In this paper, we present an efficient and optimal method for optimization of Hahn parameters a and b using the Artificial Bee Colony algorithm (ABC) in order to improve the quality of reconstruction and the compression of bio-signals and 2D / 3D color images of large sizes. The proposed methods are essentially based on two concepts: the development of a recursive calculation of the initial terms of Hahn polynomials in order to avoid the problems of instability of polynomial values and the use of ABC algorithm to optimize the values of the parameters a and b of the discrete orthogonal Hahn polynomials (HPs) during the reconstruction and the compression of bio-signals and 2D / 3D color images. The simulation results performed on bio-signals and on large size 2D /3D color images clearly show the efficiency and superiority of the proposed methods over conventional methods in terms of reconstruction of signals and images.
C1 [Bencherqui, Ahmed; Daoui, Achraf; Karmouni, Hicham; Alfidi, Mohammed; Sayyouri, Mhamed] Sidi Mohamed Ben Abdellah Fez Univ, Natl Sch Appl Sci, Lab Engn Syst & Applicat, Fes, Morocco.
   [Qjidaa, Hassan] Sidi Mohamed Ben Abdellah Fez Univ, Fac Sci, Lab Elect Signals & Syst Informat, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Bencherqui, A (corresponding author), Sidi Mohamed Ben Abdellah Fez Univ, Natl Sch Appl Sci, Lab Engn Syst & Applicat, Fes, Morocco.
EM ahmed.bencherqui@usmba.ac.ma; achraf.daoui@usmba.ac.ma;
   hicham.karmouni@usmba.ac.ma; qjidah@yahoo.fr; alfidi_mohammed@yahoo.fr;
   mhamed.sayyouri@usmba.ac.ma
RI Sayyouri, Mhamed/AAB-5496-2020; Karmouni, Hicham/ACB-0232-2022
OI Sayyouri, Mhamed/0000-0002-1615-419X; Karmouni,
   Hicham/0000-0001-9225-8380
CR Aslan S, 2020, APPL SOFT COMPUT, V88, DOI 10.1016/j.asoc.2019.106053
   Bencherqui A, 2020, 2020 4 INT C INT COM, P1
   Benouini R, 2019, PATTERN RECOGN LETT, V123, P39, DOI 10.1016/j.patrec.2019.03.001
   Bolourchi P, 2020, J DEF MODEL SIMUL-AP, V17, P205, DOI 10.1177/1548512919844610
   Braren H, 2020, HIGH RESOLUTION INDI
   Camacho-Bello C, 2018, PATTERN RECOGN LETT, V112, P332, DOI 10.1016/j.patrec.2018.08.020
   Daoui A., 2020, Embedded Systems and Artificial Intelligence. Proceedings of ESAI 2019. Advances in Intelligent Systems and Computing (AISC 1076), P369, DOI 10.1007/978-981-15-0947-6_35
   Daoui A., 2020, 2020 INT C INT SYST, P1, DOI DOI 10.1109/ISCV49265.2020.9204132
   Daoui A, 2020, NEW ALGORITHM LARGE
   Daoui A, 2021, SIGNAL PROCESS, V180, DOI 10.1016/j.sigpro.2020.107854
   Daoui A, 2021, MULTIMED TOOLS APPL, V80, P1641, DOI 10.1007/s11042-020-09739-z
   Daoui A, 2020, INFORM SCIENCES, V521, P251, DOI 10.1016/j.ins.2020.02.019
   Deng AW, 2016, PATTERN RECOGN, V56, P16, DOI 10.1016/j.patcog.2016.02.014
   Ernawan F, 2017, OPTIK, V148, P106, DOI 10.1016/j.ijleo.2017.08.007
   Flusser J., 2016, 2D and 3D image analysis by moments, P1, DOI 10.1002/9781119039402
   Hmimid A, 2018, MULTIMED TOOLS APPL, V77, P23607, DOI 10.1007/s11042-018-5623-3
   Hosny K.M., 2019, RECENT ADV COMPUTER, P169, DOI DOI 10.1007/978-3-030-03000-1_7
   Hosny KM, 2020, SOFT COMPUT, V24, P409, DOI 10.1007/s00500-019-03922-7
   Karaboga D, 2008, APPL SOFT COMPUT, V8, P687, DOI 10.1016/j.asoc.2007.05.007
   Karmouni H, 2019, CIRC SYST SIGNAL PR, V38, P3715, DOI 10.1007/s00034-019-01025-0
   Kumar R, 2021, AIN SHAMS ENG J, V12, P2227, DOI 10.1016/j.asej.2021.01.003
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Peng C, 2019, FRONT OPTOELECTRON, V12, P413, DOI 10.1007/s12200-019-0862-0
   Pooyan, 2004, INT J SIGNAL PROCESS, V1
   Sayyouri M, 2016, MULTIMED TOOLS APPL, V75, P547, DOI 10.1007/s11042-014-2307-5
   Sayyouri M, 2013, J OPT SOC AM A, V30, P2381, DOI 10.1364/JOSAA.30.002381
   Sornmo L., 2005, Bioelectrical signal processing in cardiac and neurological applications, V8
   Tahiri MA, 2020, 2020 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING IN DATA SCIENCES (ICDS), DOI [10.1109/icds50568.2020.9268685, 10.1109/TPEC48276.2020.9042513]
   Tohumoglu G, 2007, COMPUT BIOL MED, V37, P173, DOI 10.1016/j.compbiomed.2005.11.004
   Xiao B, 2016, NEUROCOMPUTING, V214, P587, DOI 10.1016/j.neucom.2016.06.050
   Zhang GJ, 2010, PATTERN RECOGN LETT, V31, P548, DOI 10.1016/j.patrec.2009.12.007
   Zhao ZJ, 2021, J REAL-TIME IMAGE PR, V18, P431, DOI 10.1007/s11554-020-00979-8
   Zhu H, 2010, IET IMAGE PROCESS, V4, P335, DOI 10.1049/iet-ipr.2009.0195
   Zhu HQ, 2007, PATTERN RECOGN LETT, V28, P1688, DOI 10.1016/j.patrec.2007.04.013
   Zhu HQ, 2007, SIGNAL PROCESS, V87, P687, DOI 10.1016/j.sigpro.2006.07.007
NR 36
TC 9
Z9 8
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 29753
EP 29783
DI 10.1007/s11042-022-12978-x
EA APR 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500021
PM 35401027
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Sun, B
   Wang, SF
   Kong, DH
   Li, JH
   Yin, BC
AF Sun, Bin
   Wang, Shaofan
   Kong, Dehui
   Li, Jinghua
   Yin, Baocai
TI Grassmannian graph-attentional landmark selection for domain adaptation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Domain adapation; Transfer learning; Landmark; Manifold
ID FRAMEWORK; ALIGNMENT
AB Domain adaptation aims to leverage information from the source domain to improve the classification performance in the target domain. It mainly utilizes two schemes: sample reweighting and feature matching. While the first scheme allocates different weights to individual samples, the second scheme matches the feature of two domains using global structural statistics. The two schemes are complementary with each other, which are expected to jointly work for robust domain adaptation. Several methods combine the two schemes, but the underlying relationship of samples is insufficiently analyzed due to the neglect of the hierarchy of samples and the geometric properties between samples. To better combine the advantages of the two schemes, we propose a Grassmannian graph-attentional landmark selection (GGLS) framework for domain adaptation. GGLS presents a landmark selection scheme using attention-induced neighbors of the graphical structure of samples and performs distribution adaptation and knowledge adaptation over Grassmann manifold. the former treats the landmarks of each sample differently, and the latter avoids feature distortion and achieves better geometric properties. Experimental results on different real-world cross-domain visual recognition tasks demonstrate that GGLS provides better classification accuracies compared with state-of-the-art domain adaptation methods.
C1 [Sun, Bin; Wang, Shaofan; Kong, Dehui; Li, Jinghua; Yin, Baocai] Beijing Univ Technol, BJUT Fac Informat Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing 100124, Peoples R China.
   [Sun, Bin] Li Auto, Beijing, Peoples R China.
C3 Beijing University of Technology
RP Wang, SF (corresponding author), Beijing Univ Technol, BJUT Fac Informat Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing 100124, Peoples R China.
EM binsun008@gmail.com; wangshaofan@bjut.edu.cn
FU National Natural Science Foundation of China [61772049, 61632006,
   61876012]; Scientific Research Common Program of Beijing Municipal
   Commission of Education [KM201710005022, KM201510005024]
FX The work is supported by National Natural Science Foundation of China
   (Grant Nos. 61772049, 61632006, 61876012), and Scientific Research
   Common Program of Beijing Municipal Commission of Education (Grant Nos.
   KM201710005022, KM201510005024).
CR Aljundi R, 2015, PROC CVPR IEEE, P56, DOI 10.1109/CVPR.2015.7298600
   Ben-David S., 2007, ADV NEURAL INFORM PR, V19
   Bo Sun, 2015, 2015 IEEE Power & Energy Society General Meeting, P1, DOI 10.1109/PESGM.2015.7286184
   Cao Y, 2018, AAAI CONF ARTIF INTE, P2795
   Carlucci FM, 2017, IEEE I CONF COMP VIS, P5077, DOI 10.1109/ICCV.2017.542
   Chen C, 2019, AAAI CONF ARTIF INTE, P3296
   Chen CQ, 2019, PROC CVPR IEEE, P627, DOI 10.1109/CVPR.2019.00072
   Chen X, 2019, MULTIMED TOOLS APPL, V78, P11173, DOI 10.1007/s11042-018-6690-1
   Cui Z, 2014, IEEE T CYBERNETICS, V44, P2264, DOI 10.1109/TCYB.2014.2305701
   Dai Wenyuan, 2007, P 24 INT C MACHINE L, P193
   Daras P, 2012, IEEE T MULTIMEDIA, V14, P734, DOI 10.1109/TMM.2011.2181343
   Ding ZM, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3453
   Donahue J, 2014, PR MACH LEARN RES, V32
   Fang C, 2013, IEEE I CONF COMP VIS, P1657, DOI 10.1109/ICCV.2013.208
   Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368
   Ganin Y, 2016, J MACH LEARN RES, V17
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Ghifary M, 2017, IEEE T PATTERN ANAL, V39, P1414, DOI 10.1109/TPAMI.2016.2599532
   Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344
   Griffin G., 2007, CALTECH 256 OBJECT C
   Gu Q., 2011, Proceedings of the Twenty-Second international joint conference on Artificial Intelligence, V2, P1294
   Hou CA, 2016, IEEE T IMAGE PROCESS, V25, P5552, DOI 10.1109/TIP.2016.2609820
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A., 2018, NEURAL INFORM PROCES
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li HR, 2020, SOFT COMPUT, V24, P6851, DOI 10.1007/s00500-019-04324-5
   Li J., 2016, P 25 INT JOINT C ART, P1697
   Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174
   Liang YQ, 2020, INTEGR COMPUT-AID E, V27, P417, DOI 10.3233/ICA-200641
   Long MS, 2014, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2014.183
   Long MS, 2015, IEEE T KNOWL DATA EN, V27, P1519, DOI 10.1109/TKDE.2014.2373376
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Ma XH, 2019, IEEE T MULTIMEDIA, V21, P2419, DOI 10.1109/TMM.2019.2902100
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Niu L, 2016, LECT NOTES COMPUT SC, V9910, P550, DOI 10.1007/978-3-319-46466-4_33
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Qian SS, 2018, IEEE T MULTIMEDIA, V20, P2086, DOI 10.1109/TMM.2017.2785227
   Roy S, 2019, PROC CVPR IEEE, P9463, DOI 10.1109/CVPR.2019.00970
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Sun BC, 2016, AAAI CONF ARTIF INTE, P2058
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Tahmoresnezhad J, 2017, KNOWL INF SYST, V50, P585, DOI 10.1007/s10115-016-0944-x
   Tsai YHH, 2016, PROC CVPR IEEE, P5081, DOI 10.1109/CVPR.2016.549
   Tzeng E., 2014, ARXIV14123474
   Velickovic Petar, 2018, INT C LEARN REPR
   Wan C., 2011, P INT JOINT C ART IN, P1535, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-258
   Wang JD, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P402, DOI 10.1145/3240508.3240512
   Wang Q, 2020, AAAI CONF ARTIF INTE, V34, P6243
   Wang QY, 2019, 11TH ASIA-PACIFIC SYMPOSIUM ON INTERNETWARE (INTERNETWARE 2019), DOI [10.1007/s11104-019-04156-0, 10.1145/3361242.3361254]
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Xu Y, 2016, IEEE T IMAGE PROCESS, V25, P850, DOI 10.1109/TIP.2015.2510498
   Xu YH, 2017, IEEE T KNOWL DATA EN, V29, P1158, DOI 10.1109/TKDE.2017.2669193
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang Y, 2016, AAAI CONF ARTIF INTE, P3648
   Zhang J, 2017, PROC CVPR IEEE, P5150, DOI 10.1109/CVPR.2017.547
   Zhang L, 2017, IEEE T MULTIMEDIA, V19, P1220, DOI 10.1109/TMM.2016.2646219
   Zhang WC, 2018, PROC CVPR IEEE, P3801, DOI 10.1109/CVPR.2018.00400
   Zheng YH, 2019, IEEE T MULTIMEDIA, V21, P2292, DOI 10.1109/TMM.2019.2900166
   Zhuo JB, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P261, DOI 10.1145/3123266.3123292
NR 63
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30243
EP 30266
DI 10.1007/s11042-022-12733-2
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500008
DA 2024-07-18
ER

PT J
AU Hamache, A
   Boudaren, ME
   Pieczynski, W
AF Hamache, Ali
   Boudaren, Mohamed El Yazid
   Pieczynski, Wojciech
TI Kernel smoothing classification of multiattribute data in the belief
   function framework: Application to multichannel image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Dempster-Shafer theory; Hidden Markov fields; Mass
   determination; Multiattribute data; Multichannel image segmentation
ID DEMPSTER-SHAFER FUSION; MARKOV-FIELDS; UNSUPERVISED SEGMENTATION; SENSOR
   RELIABILITY; HIDDEN; RULE
AB Bayesian approaches turn out to be inefficient when decision making involves many uncertain, imprecise or unreliable sources of information. The same problem occurs in multiattribute data classification where each attribute can be perceived as a source of information. The theory of belief functions has been extensively used to overcome this issue. Moreover, Markov field approaches involving this theory have shown their interest in image modeling and processing. The aim of this paper is to propose a new approach for multichannel (typically remote sensing) image segmentation through hidden Markov fields, which better manage non Gaussian noise forms, by adopting Weighted Parzen-Rosenblatt Dempster-Shafer likelihood model. More explicitly, observations are modeled through belief functions constructed through a kernel smoothing- based scheme rather than using plain Gaussian densities as in the typical hidden Markov fields. The interest of the proposed approach is shown through experiments conducted on sampled and real multichannel remote sensing images.
C1 [Hamache, Ali; Boudaren, Mohamed El Yazid] Ecole Mil Polytech, POB 17, Algiers 16111, Algeria.
   [Pieczynski, Wojciech] Inst Polytech Paris, Telecom SudParis, SAMOVAR, 9 Rue Charles Fourier, F-91000 Evry, France.
C3 Ecole Military Polytechnic; IMT - Institut Mines-Telecom; Institut
   Polytechnique de Paris; Telecom SudParis; Institut Mines-Telecom
   Business School
RP Hamache, A (corresponding author), Ecole Mil Polytech, POB 17, Algiers 16111, Algeria.
EM d.hamacheali@gmail.com
CR An L, 2018, INT J APPROX REASON, V102, P41, DOI 10.1016/j.ijar.2018.08.001
   Bendjebbour A, 2001, IEEE T GEOSCI REMOTE, V39, P1789, DOI 10.1109/36.942557
   BESAG J, 1974, J ROY STAT SOC B MET, V36, P192
   Boudaren ME, 2016, INT J APPROX REASON, V74, P13, DOI 10.1016/j.ijar.2016.03.006
   Boudaren ME, 2012, IEEE SIGNAL PROC LET, V19, P619, DOI 10.1109/LSP.2012.2209639
   Bowman A., 1997, Applied Smoothing Techniques for Data Analysis: The Kernel Approach with S-Plus Illustrations
   Cao XY, 2017, NEUROCOMPUTING, V226, P90, DOI 10.1016/j.neucom.2016.11.034
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Delmas JP, 1997, IEEE T SIGNAL PROCES, V45, P2613, DOI 10.1109/78.640732
   DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493
   DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871
   Dezert J., 2006, Adv. Appl. DSmT Inf. Fusion Collect. Works, V2, P3
   Ding IJ, 2016, MULTIMED TOOLS APPL, V75, P15537, DOI 10.1007/s11042-015-2505-9
   Dubois D., 2007, IEEE Cybernetic Systems Conference, Dublin, Ireland, P4
   Dubois D.J., 1980, Fuzzy Sets and Systems: Theory and Applications, V144
   Duin R., 2000, PRTOOLS VERSION, V3, P109
   Elouedi Z, 2004, IEEE T SYST MAN CY B, V34, P782, DOI 10.1109/TSMCB.2003.817056
   Elouedi Z., 2010, 2010 Proceedings of 22nd International Conference on Tools with Artificial Intelligence (ICTAI 2010), P287, DOI 10.1109/ICTAI.2010.49
   Fedrizzi M., 1994, ADV DEMPSTER SHAFER
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Freund Y, 1999, MACHINE LEARNING, PROCEEDINGS, P124
   Ghamisi P, 2014, IEEE T GEOSCI REMOTE, V52, P2565, DOI 10.1109/TGRS.2013.2263282
   Guo HW, 2006, IEEE T SYST MAN CY B, V36, P970, DOI 10.1109/TSMCB.2006.872269
   Hamache A, 2018, LECT NOTES ARTIF INT, V11069, P103, DOI 10.1007/978-3-319-99383-6_14
   Hu BG, 2014, IEEE T NEUR NET LEAR, V25, P249, DOI 10.1109/TNNLS.2013.2274799
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Ising E, 1925, Z PHYS, V31, P253, DOI 10.1007/BF02980577
   Khaleghi B, 2013, INFORM FUSION, V14, P28, DOI 10.1016/j.inffus.2011.08.001
   Lama RK, 2016, MULTIMED TOOLS APPL, V75, P16487, DOI 10.1007/s11042-016-3245-1
   LeHegaratMascle S, 1997, IEEE T GEOSCI REMOTE, V35, P1018, DOI 10.1109/36.602544
   Lichman M., 2013, UCI MACHINE LEARNING
   Liu YT, 2018, IEEE T FUZZY SYST, V26, P338, DOI 10.1109/TFUZZ.2017.2659764
   Mercier D, 2012, INT J APPROX REASON, V53, P146, DOI 10.1016/j.ijar.2011.06.005
   Mor B, 2021, ARCH COMPUT METHOD E, V28, P1429, DOI 10.1007/s11831-020-09422-4
   Murphy CK, 2000, DECIS SUPPORT SYST, V29, P1, DOI 10.1016/S0167-9236(99)00084-6
   PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472
   Pieczynski W, 2006, IMAGE VISION COMPUT, V24, P61, DOI 10.1016/j.imavis.2005.09.012
   POTTS RB, 1952, P CAMB PHILOS SOC, V48, P106, DOI 10.1017/S0305004100027419
   ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190
   Salzenstein F, 2001, ISSPA 2001: SIXTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOLS 1 AND 2, PROCEEDINGS, P152, DOI 10.1109/ISSPA.2001.949798
   Sebbak F, 2014, 17 INT C INF FUS FUS, P1
   SHAFER G, 1987, ARTIF INTELL, V33, P271, DOI 10.1016/0004-3702(87)90040-3
   Shafer G, 2016, INT J APPROX REASON, V79, P41, DOI 10.1016/j.ijar.2016.05.003
   Shafer Glenn, 1976, MATH THEORY EVIDENCE, P2
   Singh A, 2020, IEEE ACCESS, V8, P112985, DOI 10.1109/ACCESS.2020.3003874
   SMETS P, 1994, ARTIF INTELL, V66, P191, DOI 10.1016/0004-3702(94)90026-4
   Smolka B, 2020, MULTIMED TOOLS APPL, V79, P32857, DOI 10.1007/s11042-020-09550-w
   Veenman CJ, 2005, IEEE T PATTERN ANAL, V27, P1417, DOI 10.1109/TPAMI.2005.187
   Walley P., 1991, Statistical Reasoning with Imprecise Probabilities
   Wand M.P., 1994, KERNEL SMOOTHING
   Witten IH, 2011, MOR KAUF D, P1
   Xu PD, 2013, KNOWL-BASED SYST, V46, P69, DOI 10.1016/j.knosys.2013.03.005
   Xu P, 2016, INT J APPROX REASON, V72, P55, DOI 10.1016/j.ijar.2015.05.002
   Zadeh LA, 2002, J STAT PLAN INFER, V105, P233, DOI 10.1016/S0378-3758(01)00212-9
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zadeh LA., 1979, VALIDITY DEMPSTERS R
   Zimmermann H.-J., 2001, Fuzzy Set Theory-and Its Applications, V4th
NR 58
TC 5
Z9 5
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29587
EP 29608
DI 10.1007/s11042-022-12086-w
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000778057700008
DA 2024-07-18
ER

PT J
AU Karanwal, S
AF Karanwal, Shekhar
TI Robust local binary pattern for face recognition in different challenges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local descriptors; Sign binary pattern; Magnitude binary pattern; Robust
   LBP; Feature extraction; Classification
AB In Local Binary Pattern (LBP), the minute pixel difference introduces image noise as the virtue of which recognition rate decreases. Or in other words, LBP and most of the other descriptors possesses noisy thresholding function. To overcome this, the center pixel in 3 x 3 patch is replaced by the mean of whole patch. Then 2 descriptors are launched so-called Sign Binary Pattern (SBP) and Magnitude Binary Pattern (MABP). In SBP, the values induced from neighbors & mean (by taking difference) are absorbed by thresholding function for building the SBP size. In MABP, the absolute values induced from all pixels and mean (by taking difference) are availed by thresholding function for building MABP size. The SBP & MABP features are merged next for making discriminant feature called Robust LBP (RLBP). As SBP is characterized by mean comparison and MABP is characterized by absolute mean comparison, therefore their combination generate more robustness than various descriptors, which possesses noisy thresholding functions (proved experimentally in result section). Their combination also yields discriminativity against the other challenges such as light, pose, emotion and scale. SBP and MABP whole feature size are build by integrating features region wise. The methodology used for developing these descriptors is totally novel. As length of feature aligned on higher side so compression in feature length is gained by PCA and then SVMs and NN are used for matching. The RLBP ability is examined on ORL and GT by comparing with several methods. The proposed RLBP justifies its efficacy by conquering all of them. The numerous methods include those which are evaluated with proposed ones and they are LBP, HELBP and MBP. The rest compared methods are literature work.
C1 [Karanwal, Shekhar] Graph Era Deemed Univ, Dept CSE, Dehra Dun, Uttarakhand, India.
C3 Graphic Era University
RP Karanwal, S (corresponding author), Graph Era Deemed Univ, Dept CSE, Dehra Dun, Uttarakhand, India.
EM shekhar.karanwal@gmail.com
RI Karanwal, Dr. Shekhar/AGF-1442-2022
OI Karanwal, Dr. Shekhar/0000-0003-2932-4132
CR Abbas F., 2021, MED C PATT REC ART I, P188
   Al-wajih E, 2021, MULTIMED TOOLS APPL, V80, P24399, DOI 10.1007/s11042-021-10762-x
   Bin Iqbal MT, 2020, IEEE T AFFECT COMPUT, V11, P125, DOI 10.1109/TAFFC.2018.2829707
   Boudra S., 2018, BARK IDENTIFICATION
   Chi-Kien Tran, 2021, International Journal of Computer Theory and Engineering, V13, P1, DOI 10.7763/IJCTE.2021.V13.1282
   Dubey SR, 2020, MULTIMED TOOLS APPL, V79, P6363, DOI 10.1007/s11042-019-08370-x
   Dubey SR, 2019, MULTIMED TOOLS APPL, V78, P28063, DOI 10.1007/s11042-019-07908-3
   El Merabet Y, 2019, ENG APPL ARTIF INTEL, V78, P158, DOI 10.1016/j.engappai.2018.11.011
   Gautam A, 2020, PATTERN ANAL APPL, V23, P797, DOI 10.1007/s10044-019-00838-8
   Hafiane A, 2007, LECT NOTES COMPUT SC, V4633, P387
   Hassaballah M, 2020, MULTIMED TOOLS APPL, V79, P31183, DOI 10.1007/s11042-020-09456-7
   Hatibaruah R., 2020, NAT C COMM, P1
   He W, 2019, MULTIMED TOOLS APPL, V78, P31415, DOI 10.1007/s11042-019-7688-z
   Van HT, 2019, ISCIT 2019: PROCEEDINGS OF 2019 19TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P311, DOI 10.1109/ISCIT.2019.8905179
   Hu M, 2022, CLIN TRANSL ONCOL, V24, P48, DOI 10.1007/s12094-021-02667-w
   Huu-Tuan Nguyen, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P85, DOI 10.1007/978-3-642-37410-4_8
   Huy NQ, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P54, DOI [10.1109/ZINC50678.2020.9161798, 10.1109/zinc50678.2020.9161798]
   Jia Y, 2022, INT J NEUROSCI, V132, P1221, DOI 10.1080/00207454.2021.1879064
   Karanwal S, 2021, DIGIT SIGNAL PROCESS, V110, DOI 10.1016/j.dsp.2020.102948
   Karanwal S, 2021, MULTIMED TOOLS APPL, V80, P12195, DOI 10.1007/s11042-020-09833-2
   Karanwal S, 2021, PATTERN ANAL APPL, V24, P741, DOI 10.1007/s10044-020-00948-8
   Karanwal S, 2021, OPTIK, V226, DOI 10.1016/j.ijleo.2020.166007
   khadiri IEIE., 2020, SIGNAL PROCESS-IMAGE, V84, P1
   Kou QQ, 2019, OPTIK, V193, DOI 10.1016/j.ijleo.2019.162999
   Kumar TGS, 2018, SIGNAL IMAGE VIDEO P, V12, P591, DOI 10.1007/s11760-017-1197-1
   Liang K, 2021, MULTIMED TOOLS APPL, V80, P4367, DOI 10.1007/s11042-020-09782-w
   Liu L, 2016, INFORM SCIENCES, V358, P56, DOI 10.1016/j.ins.2016.04.021
   Long T., INT JOINT C NEUR NET
   Lu JL, 2021, INFORM SCIENCES, V544, P564, DOI 10.1016/j.ins.2020.08.062
   Maafiri A, 2021, IEEE ACCESS, V9, P65091, DOI 10.1109/ACCESS.2021.3076359
   Mandal B, 2016, NEUROCOMPUTING, V184, P107, DOI 10.1016/j.neucom.2015.07.121
   Khanbebin SN, 2021, NEURAL COMPUT APPL, V33, P7691, DOI 10.1007/s00521-020-05512-3
   Nigam S, 2018, MULTIMED TOOLS APPL, V77, P28725, DOI 10.1007/s11042-018-6040-3
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Perumal, 2018, KNOWLEDGE COMPUTING, P129
   Raja Rohit, 2018, International Journal of Information and Computer Security, V10, P303
   Raja R., 2015, Assoc. Adv. Model. Simul. Tech. Enterp. Adv. B, V58, P14
   Raja R., 2017, Int. J. Lumin. Appl., V7, P507
   Raja R, 2020, WIRELESS PERS COMMUN, V112, P169, DOI 10.1007/s11277-019-07021-6
   Srivastava P, 2018, MULTIMED TOOLS APPL, V77, P12377, DOI 10.1007/s11042-017-4894-4
   Su Z., BRIT MACHINE VISION, V1, P12
   Tan SB, 2017, IEEE T IMAGE PROCESS, V26, P4661, DOI 10.1109/TIP.2017.2716180
   Tao DC, 2008, IEEE T CIRC SYST VID, V18, P1397, DOI 10.1109/TCSVT.2008.2002825
   Verma SB, 2022, INDIAN J DERMATOL VE, V88, P798, DOI 10.25259/IJDVL_1090_2021
   Wadhera Ankita, 2020, 2020 6th International Conference on Signal Processing and Communication (ICSC), P173, DOI 10.1109/ICSC48311.2020.9182715
   Wang W, 2020, 2020 IEEE 3RD INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND SIGNAL PROCESSING (ICICSP 2020), P274, DOI [10.1109/ICICSP50920.2020.9232056, 10.1109/icicsp50920.2020.9232056]
   Xu Y, 2020, IEEE ACCESS, V8, P183972, DOI 10.1109/ACCESS.2020.3028905
   Yang WK, 2020, NEUROCOMPUTING, V373, P109, DOI 10.1016/j.neucom.2019.09.102
   Zhaohui Ma, 2020, International Journal of Computational Science and Engineering, V23, P224, DOI 10.1504/IJCSE.2020.111431
   Zhilai FA, 2018, INT C IND ENT SYST E, P103
NR 50
TC 6
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29405
EP 29421
DI 10.1007/s11042-022-13006-8
EA APR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777642100003
DA 2024-07-18
ER

PT J
AU Al Hamad, HA
   Abualigah, L
   Shehab, M
   Al-Shqeerat, KHA
   Otair, M
AF Al Hamad, Husam Ahmed
   Abualigah, Laith
   Shehab, Mohammad
   Al-Shqeerat, Khalil H. A.
   Otair, Mohammad
TI Improved linear density technique for segmentation in Arabic handwritten
   text recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arabic handwritten; Image segmentation; Image processing; Arabic
   handwriting; Text recognition; Vertical linear density
AB The challenge in handwriting recognition, especially in the segmentation process, took the researchers' attention. These Arabic handwritten text processes are a challenging job because their characters are generally both cursive and unconstrained. In this paper, a new segmentation technique is proposed for solving the problem of Arabic handwritten scripts, called ILDT. The proposed technique's main objective is to use the word image's vertical linear density for clarifying character boundaries and districting between characters. In the proposed method, three pre-processing steps are applied: fill close and open holes (missing circle), remove punctuation to clarify the area of ligature points and avoid characters overlapping, and crop the word image to remove excess white space. The goal of filling close and open holes is to increase the character's pixel density and then apply the vertical linear density. The proposed technique calculates the distance histogram of vertical linear, aiming to discover local minima points to precisely determine the segmentation points. Several experiments were conducted, including elapsed CPU times and accuracies values. All comparative techniques are examined on a local benchmark database. The proposed method (ILDT) got almost all the best segmentation and recognition accuracy compared with other comparative methods.
C1 [Al Hamad, Husam Ahmed; Abualigah, Laith; Otair, Mohammad] Amman Arab Univ, Fac Comp Sci & Informat, Amman 11953, Jordan.
   [Shehab, Mohammad] World Islamic Sci & Educ Univ, Informat Technol, Amman, Jordan.
   [Al-Shqeerat, Khalil H. A.] Qassim Univ, Comp Sci Dept, Buraydah, Saudi Arabia.
C3 Qassim University
RP Abualigah, L (corresponding author), Amman Arab Univ, Fac Comp Sci & Informat, Amman 11953, Jordan.
EM hhamad@aau.edu.jo; Aligah.2020@gmail.com; mohshehab12@gmail.com;
   Khalil@qu.edu.sa; otair@aau.edu.jo
RI Shehab, Mohammad/Q-1436-2019; Shehab, Mohammad/AFK-4694-2022; Abualigah,
   Laith/ABC-9695-2020; Al Hamad, Dr. Husam Ahmad/KIB-6051-2024
OI Shehab, Mohammad/0000-0003-0211-3503; Shehab,
   Mohammad/0000-0003-0211-3503; Abualigah, Laith/0000-0002-2203-4549; Al
   Hamad, Dr. Husam Ahmad/0000-0002-5530-1658
CR Abualigah L. M. Q., 2019, Feature selection and enhanced krill herd algorithm for text document clustering, DOI [DOI 10.1007/978-3-030-10674-4, 10.1007/978-3-030-10674-4]
   Abualigah L, 2021, COMPUT METHOD APPL M, V376, DOI 10.1016/j.cma.2020.113609
   Abualigah L, 2021, ARTIF INTELL REV, V54, P2567, DOI 10.1007/s10462-020-09909-3
   Abualigah L, 2020, NEURAL COMPUT APPL, V32, P11195, DOI 10.1007/s00521-019-04629-4
   Abualigah LM, 2018, APPL INTELL, V48, P4047, DOI 10.1007/s10489-018-1190-6
   Ahmad I, 2019, INT J DOC ANAL RECOG, V22, P329, DOI 10.1007/s10032-019-00339-8
   Akhtar MS., 2019, INT J ADV SCI ENG IN, V9, P700, DOI [10.18517/ijaseit.9.2.6809, DOI 10.18517/IJASEIT.9.2.6809]
   Al Hamad H. A., 2012, Proceedings of the 2012 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR), P180, DOI 10.1109/ICWAPR.2012.6294775
   Al Hamad H. A., 2016, Int. J. Eng. Res. Dev., V12, P24
   Al Hamad HA., 2013, 21 INT C COMP GRAPH
   Al Hamad HA., 2012, EUR C COMPUTER SCI E, P85
   Al Hamad HA, 2010, PATTERN RECOGN, V43, P2773, DOI 10.1016/j.patcog.2010.03.005
   Al Hamad HA, 2015, INT J ADV COMPUT SC, V6, P1
   Al Hamad HA, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (IEEE ICSIPA 2013), P269, DOI 10.1109/ICSIPA.2013.6708016
   Al-Dmour Ayman, 2014, International Journal of Advancements in Computing Technology, V6, P109
   Ali A.A.A., 2019, EMERGING RES COMPUTI, P387
   Ali A, 2019, UEEE INT SYM PERS IN, P1615, DOI [10.1109/pimrc.2019.8904367, 10.1109/ccnc.2019.8651812, 10.1109/icomet.2019.8673494]
   Ali AAA, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1294-6
   AlKhateeb JH., 2008, P WORLD AC SCI ENG T, P1307
   [Anonymous], 2015, P INT C IM PROC COMP
   Ashiquzzaman Akm, 2019, Data Management, Analytics and Innovation. Proceedings of ICDMAI 2018. Advances in Intelligent Systems and Computing (AISC 808), P299, DOI 10.1007/978-981-13-1402-5_23
   Athoillah M., 2019, KINETIK GAME TECHNOL, V4, P99, DOI [10.22219/kinetik.v4i2.724, DOI 10.22219/KINETIK.V4I2.724]
   Daifallah Khaled, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P886, DOI 10.1109/ICDAR.2009.169
   Hadjadji B, 2019, PATTERN ANAL APPL, V22, P99, DOI 10.1007/s10044-018-0735-y
   Hamid A, 2001, ACS/IEEE INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, PROCEEDINGS, P110, DOI 10.1109/AICCSA.2001.933960
   Jemni SK, 2019, PATTERN RECOGN, V93, P507, DOI 10.1016/j.patcog.2019.05.003
   Khorsheed MS, 2003, PATTERN RECOGN LETT, V24, P2235, DOI 10.1016/S0167-8655(03)00050-3
   Lorigo LM, 2006, IEEE T PATTERN ANAL, V28, P712, DOI 10.1109/TPAMI.2006.102
   Maliki M, 2012, PROC SPIE, V8406, DOI 10.1117/12.917555
   Parvez MT, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2431211.2431222
   Shehab M, 2020, NEURAL COMPUT APPL, V32, P9859, DOI 10.1007/s00521-019-04570-6
NR 31
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28531
EP 28558
DI 10.1007/s11042-022-12717-2
EA MAR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000774644000001
DA 2024-07-18
ER

PT J
AU Beg, S
   Baig, F
   Hameed, Y
   Anjum, A
   Khan, A
AF Beg, Saira
   Baig, Faisal
   Hameed, Yousaf
   Anjum, Adeel
   Khan, Ahmed
TI Thermal image encryption based on laser diode feedback and 2D logistic
   chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Logistic map; Laser diode feedback; S-box; Encryption; Thermal image;
   Cryptography
ID S-BOX DESIGN; CONSTRUCTION
AB Importance of thermal images in an electric power station, nuclear plants, for extraction of petroleum products, biological and medical is not unseen. Based on that, security of thermal images is very important but due to their unique features like correlation, energy, homogeneity, entropy, and contrast make it harder to encrypt with conventional image encryption scheme. Therefore, we proposed a scheme that will encrypt the thermal images based on a time delay laser feedback chaotic system-based substitution box (S-box) for substitution of image pixel value with S-box and two-dimensional logistic chaotic map for image bit permutation. The results proposed in this work shows good strength against well known statistical and security analysis tools which confirms that the proposed scheme offers a good and imperative approach for real-time image encryption.
C1 [Beg, Saira; Anjum, Adeel] COMSATS Univ Islamabad, Dept Comp Sci, Islamabad, Pakistan.
   [Baig, Faisal; Hameed, Yousaf] Fed Urdu Univ Arts Sci & Technol, Dept Elect Engn, Islamabad, Pakistan.
   [Khan, Ahmed] Monash Univ Malaysia, Sch Informat Technol, Subang Jaya, Malaysia.
C3 COMSATS University Islamabad (CUI); Federal Urdu University of Arts
   Science & Technology; Monash University; Monash University Malaysia
RP Khan, A (corresponding author), Monash Univ Malaysia, Sch Informat Technol, Subang Jaya, Malaysia.
EM saira.beg@comsats.edu.pk; engr.fsl.baig@gmail.com;
   yousaf.hameedk@gmail.com; adeel.anjum@comsats.edu.pk;
   ahmed.khan1@monash.edu
RI Anjum, Adeel/L-4391-2013; Khattak, Yousaf Hameed/K-6923-2014
OI Anjum, Adeel/0000-0001-5083-0019; Khattak, Yousaf
   Hameed/0000-0002-7565-192X
CR Abdullah S, 2015, NONLINEAR DYNAM, V79, P1679, DOI 10.1007/s11071-014-1767-5
   Aboytes-González JA, 2018, NONLINEAR DYNAM, V94, P2003, DOI 10.1007/s11071-018-4471-z
   Belazi A, 2017, OPTIK, V130, P1438, DOI 10.1016/j.ijleo.2016.11.152
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Bibi N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194343
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   Çavusoglu Ü, 2017, NONLINEAR DYNAM, V87, P1081, DOI 10.1007/s11071-016-3099-0
   Farwa S, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3298-7
   Hamza R, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/1625678
   Hamza R, 2020, INFORM SCIENCES, V527, P493, DOI 10.1016/j.ins.2019.01.070
   Hua ZY, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.107998
   Hussain I, 2018, CHINESE J PHYS, V56, P1609, DOI 10.1016/j.cjph.2018.04.013
   Hussain Iqtadar, 2018, J Integr Neurosci, V17, P447, DOI 10.3233/JIN-180081
   Hussain I, 2013, NEURAL COMPUT APPL, V22, P1085, DOI 10.1007/s00521-012-0870-0
   Jiang WG, 2017, NAT COMMUN, V8, P1, DOI 10.1038/ncomms15066
   Khan M, 2018, NEURAL COMPUT APPL, V29, P993, DOI 10.1007/s00521-016-2511-5
   Khan MA, 2018, IJST-T ELECTR ENG, V42, P219, DOI 10.1007/s40998-018-0061-9
   Kulkarni S., 2021, P DATA INTELLIGENCE, P131
   Lambic D, 2014, CHAOS SOLITON FRACT, V58, P16, DOI 10.1016/j.chaos.2013.11.001
   Lokesh BS, 2015, 2015 INT C INN INF E, P1
   Lokesh BS., 2018, INT J ENG TECHNOL, V7, P1944, DOI [10.14419/ijet.v7i3.15878, DOI 10.14419/IJET.V7I3.15878]
   Mohan Mamtha, 2017, International Journal of Biomedical and Clinical Engineering, V6, P46, DOI 10.4018/IJBCE.2017070104
   Ohtsubo J, 1999, OPT REV, V6, P1, DOI 10.1007/s10043-999-0001-z
   Özkaynak F, 2017, SIGNAL IMAGE VIDEO P, V11, P659, DOI 10.1007/s11760-016-1007-1
   Picek S, 2014, LECT NOTES COMPUT SC, V8501, P140, DOI 10.1007/978-3-662-43826-8_10
   Quesada JIP, 2017, BIOL MED PHYS BIOMED, P297, DOI 10.1007/978-3-319-47410-6_12
   Rumbaugh LK, 2016, PROC SPIE, V9827, DOI 10.1117/12.2224498
   RYAN AT, 1994, IEEE J QUANTUM ELECT, V30, P668, DOI 10.1109/3.286153
   Shah T, 2017, COMPUT APPL MATH, V36, P843, DOI 10.1007/s40314-015-0265-9
   Uchida A., 2012, OPTICAL COMMUNICATIO, DOI [10.1002/9783527640331, DOI 10.1002/9783527640331]
   Ullah A, 2018, NONLINEAR DYNAM, V91, P359, DOI 10.1007/s11071-017-3874-6
   Wang B, 2019, OPTIK, V178, P1264, DOI 10.1016/j.ijleo.2018.09.165
   Wang Y, 2009, ECBI: 2009 INTERNATIONAL CONFERENCE ON ELECTRONIC COMMERCE AND BUSINESS INTELLIGENCE, PROCEEDINGS, P125, DOI 10.1109/ECBI.2009.15
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
NR 34
TC 3
Z9 3
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26403
EP 26423
DI 10.1007/s11042-022-12724-3
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000780464800013
DA 2024-07-18
ER

PT J
AU Phan, TDK
AF Tran Dang Khoa Phan
TI A corner-weighted bounded Hessian model for image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Variational model; Total variation; Bounded Hessian;
   Split Bregman
ID TOTAL VARIATION REGULARIZATION; VARIATIONAL MODEL; ALGORITHM
AB Image denoising is an essential step in the image processing task. The first-order variational model can remove noise while preserving edges, but it also generates the staircase effect. Although the bounded Hessian regulariser can reduce this side effect, it tends to blur object edges. In this paper, we propose a corner-weighted bounded Hessian model (CWBH) for image denoising, which has capability of removing noise without causing blurring object edges and artifacts. The bounded Hessian regularization at each pixel is controlled by a weight function which has an exponential form and depends on the corner response of the pixel. The split Bregman algorithm is adapted to decompose the proposed minimization problem into several subproblems which are solved directly using fast Fourier transform and the shrinkage operators. The proposed model is evaluated on synthetic and real noisy images for both spatially invariant and variant additive white Gaussian noise (AWGN). Extensive experiments demonstrate that our proposed model outperforms some state-of-the-art variational models for various types of noise and images. For uniform AWGN, CWBH surpasses other models on average by 0.014 for SSIM and by 0.77dB for PSNR; for spatially variant AWGN, these figures are 0.033 and 0.89dB, respectively.
C1 [Tran Dang Khoa Phan] Univ Danang, Fac Elect & Telecommun Engn, Univ Sci & Technol, Danang, Vietnam.
C3 University of Danang
RP Phan, TDK (corresponding author), Univ Danang, Fac Elect & Telecommun Engn, Univ Sci & Technol, Danang, Vietnam.
EM ptdkhoa@dut.udn.vn
OI Phan, Tran Dang Khoa/0000-0002-1580-4138
FU Funds for Science and Technology Development of the University of Danang
   [B2020-DN02-79]
FX This research is funded by Funds for Science and Technology Development
   of the University of Danang under project number B2020-DN02-79.
CR Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Calatroni L, 2019, INVERSE PROBL, V35, DOI 10.1088/1361-6420/ab291a
   Chan RH, 2015, INVERSE PROBL IMAG, V9, P55, DOI 10.3934/ipi.2015.9.55
   Chan TF, 2010, IEEE IMAGE PROC, P4137, DOI 10.1109/ICIP.2010.5653199
   Pham CT, 2020, INFORMATICA-LITHUAN, V31, P539, DOI 10.15388/20-INFOR407
   Duan JM, 2017, DIGIT SIGNAL PROCESS, V69, P323, DOI 10.1016/j.dsp.2017.07.001
   Duan JM, 2016, DIGIT SIGNAL PROCESS, V49, P162, DOI 10.1016/j.dsp.2015.10.010
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Getreuer P, 2012, IMAGE PROCESS ON LIN, V2, P74, DOI 10.5201/ipol.2012.g-tvd
   Glowinski R, 2016, SCI COMPUT, P19, DOI 10.1007/978-3-319-41589-5_2
   Goldluecke B, 2011, IEEE I CONF COMP VIS, P1267, DOI 10.1109/ICCV.2011.6126378
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Harris C., 1988, ALVEY VISION C, V15, P10
   Hintermuller M, 2018, INVERSE PROBL, V34, DOI 10.1088/1361-6420/aab586
   Phan TDK, 2020, IEEE SIGNAL PROC LET, V27, P535, DOI 10.1109/LSP.2020.2980373
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Kumar M, 2020, ARTIF INTELL REV, V53, P2075, DOI 10.1007/s10462-019-09727-2
   Lebrun M, 2015, IMAGE PROCESS ON LIN, V5, P1, DOI 10.5201/ipol.2015.125
   Liu CX, 2019, PROC CVPR IEEE, P82, DOI 10.1109/CVPR.2019.00017
   Lu WQ, 2016, MATH METHOD APPL SCI, V39, P4208, DOI 10.1002/mma.3858
   Milanfar P, 2013, IEEE SIGNAL PROC MAG, V30, P106, DOI 10.1109/MSP.2011.2179329
   Minaei S, 2022, INT J SPORT NUTR EXE, V32, P16, DOI 10.1123/ijsnem.2021-0090
   Papafitsoros K, 2014, J MATH IMAGING VIS, V48, P308, DOI 10.1007/s10851-013-0445-4
   Papafitsoros K, 2013, IMAGE PROCESS ON LIN
   Pham C.T., 2019, CYBERNETICS PHYS, V8, P73
   PHAN TDK, 2020, OPTIK, V217
   Prasath VBS, 2015, IEEE T IMAGE PROCESS, V24, P5220, DOI 10.1109/TIP.2015.2479471
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Setiadi DIM, 2021, MULTIMED TOOLS APPL, V80, P8423, DOI 10.1007/s11042-020-10035-z
   Tian C., 2018, INT C GEN EV COMP, P563
   Tian CW, 2020, NEURAL NETWORKS, V124, P117, DOI 10.1016/j.neunet.2019.12.024
   Phan TDK, 2018, IMAGING SCI J, V66, P220, DOI 10.1080/13682199.2017.1408254
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan J, 2015, MULTIDIM SYST SIGN P, V26, P243, DOI 10.1007/s11045-013-0255-2
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
   Zhu W, 2013, INVERSE PROBL IMAG, V7, P1409, DOI 10.3934/ipi.2013.7.1409
   Zhu W, 2012, SIAM J IMAGING SCI, V5, P1, DOI 10.1137/110822268
NR 41
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25557
EP 25580
DI 10.1007/s11042-021-11800-4
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000772288200002
DA 2024-07-18
ER

PT J
AU Bernacki, J
AF Bernacki, Jaroslaw
TI Digital camera identification by fingerprint's compact representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camera identification; Digital forensics; Hardwaremetry; Individual
   source camera identification; Sensor identification
AB In this paper we deal with the issue of digital camera identification (DCI) based on images. This area matches the digital forensics (DF) research. This topic has attracted many researchers and number of algorithms for DCI have been proposed. However, majority of them focus only on camera identification with high accuracy without taking into account the speed of image processing. In this paper we propose an effective algorithm for much faster camera identification than state-of-the-art algorithms. Experimental evaluation conducted on two large image datasets including almost 14.000 images confirms that the proposed algorithm achieves high classification accuracy of 97 [%] in much shorter time compared with state-of-the-art algorithms which obtained 92.0 - 96.0 [%]. We also perform a statistical analysis of obtained results which confirms their reliability.
C1 [Bernacki, Jaroslaw] Czestochowa Tech Univ, Al Armii Krajowej 36, PL-42200 Czestochowa, Poland.
C3 Technical University Czestochowa
RP Bernacki, J (corresponding author), Czestochowa Tech Univ, Al Armii Krajowej 36, PL-42200 Czestochowa, Poland.
EM jaroslaw.bernacki@pcz.pl
OI Bernacki, Jaroslaw/0000-0002-4488-3488
CR [Anonymous], 2019, PRNU COMPARE PROFESS
   [Anonymous], 2017, Electron. Imaging
   Salazar DA, 2021, LECT NOTES COMPUT SC, V12725, P282, DOI 10.1007/978-3-030-77004-4_27
   Bernacki J, 2021, MULTIMED TOOLS APPL, V80, P29657, DOI 10.1007/s11042-021-11129-y
   Bondi L, 2017, IEEE SIGNAL PROC LET, V24, P259, DOI 10.1109/LSP.2016.2641006
   Borole M., 2021, INT J COMPUT VIS ROB, V11, P374, DOI [10.1504/IJCVR.2021.116559, DOI 10.1504/IJCVR.2021.116559]
   Bruno A, 2020, ARXIV200812700
   Chen C, 2021, MULTIMED TOOLS APPL, V80, P11365, DOI 10.1007/s11042-020-09011-4
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Chen L., 2020, ARTIF INTELL, P466
   Chen YS, 2017, IEEE IMAGE PROC, P4337, DOI 10.1109/ICIP.2017.8297101
   Chowdhury DP, 2020, PATTERN RECOGN LETT, V130, P139, DOI 10.1016/j.patrec.2018.10.009
   Cozzolino D, 2021, IEEE COMPUT SOC CONF, P990, DOI 10.1109/CVPRW53098.2021.00110
   Ferrara P, 2021, J IMAGING, V7, DOI 10.3390/jimaging7070116
   Freire-Obregon D, 2017, ARXIV171001257
   Freire-Obregón D, 2019, PATTERN RECOGN LETT, V126, P86, DOI 10.1016/j.patrec.2018.01.005
   Galdi C, 2015, LECT NOTES COMPUT SC, V9280, P406, DOI 10.1007/978-3-319-23234-8_38
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   Goljan M, 2011, IEEE T INF FOREN SEC, V6, P227, DOI 10.1109/TIFS.2010.2099220
   Gupta B, 2018, DIGIT INVEST, V24, P121, DOI 10.1016/j.diin.2018.02.003
   Iuliani M, 2021, IEEE ACCESS, V9, P52455, DOI 10.1109/ACCESS.2021.3070478
   Jiang X, 2016, ARXIV161007728
   Kang XG, 2012, IEEE T INF FOREN SEC, V7, P393, DOI 10.1109/TIFS.2011.2168214
   Kirchner M, 2020, ARXIV200202927
   Li RZ, 2018, PATTERN RECOGN, V74, P556, DOI 10.1016/j.patcog.2017.09.027
   Lin H, 2021, COMPUT SECUR, V100, DOI 10.1016/j.cose.2020.102079
   Liu YX, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144701
   Lukas J, 2016, MATLAB IMPLEMENTATIO
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Mandelli S, 2020, IEEE SIGNAL PROC LET, V27, P1285, DOI 10.1109/LSP.2020.3008855
   Marra F, 2015, LECT NOTES COMPUT SC, V9281, P11, DOI 10.1007/978-3-319-23222-5_2
   Martin-Rodriguez, 2021, TESTING ROBUSTNESS C
   Meij C, 2018, DIGIT INVEST, V24, P142, DOI 10.1016/j.diin.2018.02.005
   Mieremet A, 2019, FORENSIC SCI INT, V301, P46, DOI 10.1016/j.forsciint.2019.05.008
   Picetti F, 2020, ARXIV201203581
   Quintanar-Reséndiz AL, 2021, MULTIMED TOOLS APPL, V80, P19513, DOI 10.1007/s11042-021-10653-1
   Rafi AM, 2021, NEURAL COMPUT APPL, V33, P3655, DOI 10.1007/s00521-020-05220-y
   Rafi Rafi A. M. A. M., CVPR WORKSHOPS, P19
   Rodriguez FM, 2021, ARXIV210701885
   Sarkar Bhola Nath, 2021, Proceedings of International Conference on Frontiers in Computing and Systems. COMSYS 2020. Advances in Intelligent Systems and Computing (AISC 1255), P637, DOI 10.1007/978-981-15-7834-2_59
   Sutcu Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P24
   Tiwari M, 2018, FORENSIC SCI INT, V285, P111, DOI 10.1016/j.forsciint.2018.02.005
   Tuama A, 2016, IEEE INT WORKS INFOR
   Tuama A, 2016, EUR SIGNAL PR CONF, P1183, DOI 10.1109/EUSIPCO.2016.7760435
   Valsesia D, 2015, IEEE T INF FOREN SEC, V10, P1472, DOI 10.1109/TIFS.2015.2415461
   Yang PP, 2017, LECT NOTES COMPUT SC, V10082, P119, DOI 10.1007/978-3-319-53465-7_9
   Yang WC, 2021, MULTIMED TOOLS APPL, V80, P6617, DOI 10.1007/s11042-020-09763-z
   Yao HW, 2018, IEEE ACCESS, V6, P24973, DOI 10.1109/ACCESS.2018.2832066
   Zeng H, 2020, IEEE ACCESS, V8, P18874, DOI 10.1109/ACCESS.2020.2968855
   Zhimao Lai, 2021, Artificial Intelligence and Security: 7th International Conference, ICAIS 2021. Lecture Notes in Computer Science, Information Systems and Applications, incl. Internet/Web, and HCI (12737), P715, DOI 10.1007/978-3-030-78612-0_58
NR 50
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21641
EP 21674
DI 10.1007/s11042-022-12468-0
EA MAR 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000769836800004
DA 2024-07-18
ER

PT J
AU Lebcir, M
   Awang, S
   Benziane, A
AF Lebcir, Mohamed
   Awang, Suryanti
   Benziane, Ali
TI Robust blind watermarking approach against the compression for
   fingerprint image using 2D-DCT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fingerprint image watermarking; Embedding process; Extracting process;
   Two-dimensional discrete cosine transform; Compression robust
ID SCHEME
AB This article presents a recent blind and robust fingerprint image watermarking scheme based on a two-dimensional discrete cosine transform (2D-DCT). The main focus is to compress the fingerprint image watermarked data for the purpose of reducing the volume of storage or sending over the network. The fingerprint features might be affected by the embedded watermark, compression of fingerprint images and the sending across network, thereby leading to various sets of features or watermark data. In order to address this goal in a differential way, the watermark sequence bit two sub-vectors were utilized. The two sub-vectors were achieved by the two-dimensional discrete cosine transform of the host image. Throughout the extraction stage, the essential distinction between the corresponding sub-vectors of the watermarked fingerprint image resulted explicitly in an embedded watermark sequence. The advantage of the proposed method is that it can develop a new simple blind and robust watermarking scheme by 2D-DCT frequency domain on the whole image. Accomplished results relative to other reliable compression schemes showed that the proposed scheme has greater or equivalent robustness to common image processing and geometric attacks, such as cropping, resizing, and rotation. To extract watermark data, the initial fingerprint image was not necessary. The proposed study was tested using 80 fingerprint images from 10 persons, for each from CASIA-FingerprintV5 and FVC2002 fingerprint databases. Eight fingerprint images for each individual were set as the format at which the watermark was embedded in each one.
C1 [Lebcir, Mohamed; Awang, Suryanti] Univ Malaysia Pahang, Fac Comp, Pekan 26600, Pahang, Malaysia.
   [Benziane, Ali] Univ Djelfa, Fac Sci & Technol, Djelfa, Algeria.
C3 Universiti Malaysia Pahang Al-Sultan Abdullah (UMPSA); Universite de
   Djelfa
RP Lebcir, M (corresponding author), Univ Malaysia Pahang, Fac Comp, Pekan 26600, Pahang, Malaysia.
EM mlebcir78@gmail.com
RI Awang, Suryanti/L-8747-2016; ., SURYANTI BINTI AWANG/JPX-6637-2023
FU Universiti Malaysia Pahang (RDU) [RDU180380]
FX The researcher would like to show gratitude to Universiti Malaysia
   Pahang (RDU vote number RDU180380) for supporting this study.
CR Alkhathami M, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1717, DOI 10.1109/CISP.2013.6743953
   Benoraira A, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0239-5
   Bousnina N, 2016, IEEE INT CONF INNOV, P127
   Dixit, 2017, INT J IMAGE GRAPH SI, V9
   Ghany K.K.A., 2014, INF EL VIS ICIEV 201, P1, DOI 10.1109/ICIEV.2014.6850836
   Haddada LR, 2017, SIGNAL PROCESS-IMAGE, V55, P23, DOI 10.1016/j.image.2017.03.008
   Hamghalam M, 2014, IET IMAGE PROCESS, V8, P162, DOI 10.1049/iet-ipr.2013.0386
   Huang HC, 2011, INFORM SCIENCES, V181, P3379, DOI 10.1016/j.ins.2011.04.007
   Islam M, 2018, J INTELL FUZZY SYST, V34, P1691, DOI 10.3233/JIFS-169462
   Jain AK, 2000, IEEE T IMAGE PROCESS, V9, P846, DOI 10.1109/83.841531
   Kasana G, 2017, OPTIK, V142, P191, DOI 10.1016/j.ijleo.2017.05.027
   Kundur D, 2004, IEEE T MULTIMEDIA, V6, P185, DOI 10.1109/TMM.2003.819747
   Lebcir, 2020, IRAQI J SCI, V61, P2715, DOI [10.24996/ijs.2020.61.10.29, DOI 10.24996/IJS.2020.61.10.29]
   Lin SD, 2010, COMPUT STAND INTER, V32, P54, DOI 10.1016/j.csi.2009.06.004
   Mansouri H, 2017, SIGNAL IMAGE VIDEO P, V11, P1543, DOI 10.1007/s11760-017-1118-3
   Mehta R, 2016, MULTIMED TOOLS APPL, V75, P4129, DOI 10.1007/s11042-015-3084-5
   Mousavi SM, 2014, J DIGIT IMAGING, V27, P714, DOI 10.1007/s10278-014-9700-5
   Noore A, 2007, FORENSIC SCI INT, V169, P188, DOI 10.1016/j.forsciint.2006.08.019
   Peralta D, 2015, INFORM SCIENCES, V315, P67, DOI 10.1016/j.ins.2015.04.013
   Qadir G, 2010, PROC SPIE, V7723, DOI 10.1117/12.855085
   Shih FY, 2003, PATTERN RECOGN, V36, P969, DOI 10.1016/S0031-3203(02)00122-X
   Verma VS, 2015, J VIS COMMUN IMAGE R, V31, P75, DOI 10.1016/j.jvcir.2015.06.001
   Wang XY, 2016, INFORM SCIENCES, V372, P634, DOI 10.1016/j.ins.2016.08.076
   Zhao Y, 2004, IEEE T IMAGE PROCESS, V13, P428, DOI 10.1109/TIP.2003.821552
NR 24
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20561
EP 20583
DI 10.1007/s11042-022-12365-6
EA MAR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767748600020
DA 2024-07-18
ER

PT J
AU Qureshi, F
   Rajput, A
   Mujtaba, G
   Fatima, N
AF Qureshi, Faiza
   Rajput, Asif
   Mujtaba, Ghulam
   Fatima, Noureen
TI A novel offline handwritten text recognition technique to convert
   ruled-line text into digital text through deep neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Offline hand-written text recognition; Ruled-line handwritten text
   recognition; Ruled-lines; Deep learning; Machine learning; Digital image
   processing
ID SLANT CORRECTION; SEGMENTATION; CLASSIFICATION
AB Offline Handwritten Text Recognition (HTR) has been an active area of research due to its wide range of applications and challenges. Recently, many offline HTR techniques have been developed. However, most of the existing techniques were trained on the datasets that contain the handwritten text images on plain pages. Nevertheless, in real life, the handwritten text can be written on either plain pages or ruled-line pages. Therefore, the approaches proposed in recent literature are unable to convert the digital text accurately written on ruled-line pages. Hence, this study proposes a tailor-made end-to-end offline HTR technique that can accurately convert the offline handwritten text written on ruled-line pages into digital text with the help of computer vision and deep neural network-based techniques. To Evaluate the performance of our proposed technique, we developed a relatively complex dataset that contains the hand-written text images on the ruled-line pages. Our experimental results show that our proposed technique is capable of converting the hand-written text on ruled-line pages into digital text with an overall accuracy of 76.7%. Moreover, the experimental results show that our proposed technique obtained 20% more accurate results compared to baseline techniques. We believe that our proposed technique will contribute positively in the body of knowledge in the field of offline HTR. Moreover, the modular design of our proposed technique allows tailored modifications with respect to data while eliminating the need to retrain the neural network-based models.
C1 [Qureshi, Faiza; Rajput, Asif; Mujtaba, Ghulam; Fatima, Noureen] Sukkur IBA Univ, Ctr Excellence Robot Artificial Intelligence & Bl, Dept Comp Sci, Sukkur, Pakistan.
C3 Sukkur IBA University
RP Qureshi, F (corresponding author), Sukkur IBA Univ, Ctr Excellence Robot Artificial Intelligence & Bl, Dept Comp Sci, Sukkur, Pakistan.
EM faiza.qureshi@iba-suk.edu.pk; asifali@iba-suk.edu.pk;
   mujtaba@iba-suk.edu.pk; noureen.mscss19@iba-suk.edu.pk
RI Mujtaba, Ghulam/AAJ-9326-2020; Fatima, Noureen/ABU-4411-2022
OI Mujtaba, Ghulam/0000-0001-9244-5346; Fatima,
   Noureen/0000-0001-7423-9346; Rajput, Asif/0000-0002-0157-129X
CR Abiodun OI, 2018, HELIYON, V4, DOI 10.1016/j.heliyon.2018.e00938
   Agrawal AK, 2021, LEARNING, V2
   Albawi S, 2017, I C ENG TECHNOL
   Sanchez JA, 2019, PATTERN RECOGN, V94, P122, DOI 10.1016/j.patcog.2019.05.025
   Sánchez JA, 2017, PROC INT CONF DOC, P1383, DOI 10.1109/ICDAR.2017.226
   Aradillas JC, 2020, ARXIV201202544
   Bal A, 2016, PROCEDIA COMPUT SCI, V93, P403, DOI 10.1016/j.procs.2016.07.227
   Bertolami R, 2007, PROC INT CONF DOC, P18
   Bluche T, 2017, PROC INT CONF DOC, P1050, DOI 10.1109/ICDAR.2017.174
   BOZINOVIC RM, 1989, IEEE T PATTERN ANAL, V11, P68, DOI 10.1109/34.23114
   Bunke Horst, 2001, Hidden Markov models: applications vision, V45
   Cai JH, 1996, ANZIIS 96 - 1996 AUSTRALIAN NEW ZEALAND CONFERENCE ON INTELLIGENT INFORMATION SYSTEMS, PROCEEDINGS, P199, DOI 10.1109/ANZIIS.1996.573933
   Carbonell M, 2019, PROC INT CONF DOC, P29, DOI 10.1109/ICDARW.2019.40077
   Chudasama D., 2015, Int. J. Comput. Appl., V117
   Chung J, 2019, PROC INT CONF DOC, P35, DOI 10.1109/ICDARW.2019.40078
   Daniyar N, 2019, INT CONF ELECT COMP, DOI 10.1109/icecco48375.2019.9043266
   Dargan Shaveta, 2020, 2020 Sixth International Conference on Parallel, Distributed and Grid Computing (PDGC), P544, DOI 10.1109/PDGC50313.2020.9315842
   Das Gupta J, 2014, PROC INT CONF EMERG, P204, DOI 10.1109/EAIT.2014.19
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Gandhi M., 2016, INT J SCI ENG RES, V7, P193
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hassanein AS, 2015, ARXIV150202160
   Jurafsky D., 2000, Speech and language processing: An introduction to natural language processing, computational linguistics, and speech recognition
   Kaur H, MULTIMED TOOLS APPL, P1
   Liu S, 2021, IEEE T FUZZY SYST, V29, P90, DOI 10.1109/TFUZZ.2020.3006520
   Manmatha R, 1999, LECT NOTES COMPUT SC, V1682, P22
   Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071
   Muthukrishnan R., 2011, International Journal of Computer Science & Information Technology, V3, P259, DOI 10.5121/ijcsit.2011.3620
   Nag S, 2018, INT CONF FRONT HAND, P523, DOI 10.1109/ICFHR-2018.2018.00097
   Nurseitov D, 2021, ARXIV210204816
   Papamarkos N, 1996, ICECS 96 - PROCEEDINGS OF THE THIRD IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS, CIRCUITS, AND SYSTEMS, VOLS 1 AND 2, P684, DOI 10.1109/ICECS.1996.584454
   Philips JP, 2020, ARXIV200206300
   Rahman Md Atiqur, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P234, DOI 10.1007/978-3-319-50835-1_22
   Rani NS, 2018, P INT C COGN REC, P83, DOI DOI 10.1007/978-981-10-5146
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Roy PP, 2017, FRONT INFORM TECH EL, V18, P978, DOI 10.1631/FITEE.1600996
   Roy PP, 2017, EXPERT SYST APPL, V76, P113, DOI 10.1016/j.eswa.2017.01.027
   Saba T, 2014, NEURAL COMPUT APPL, V25, P1337, DOI 10.1007/s00521-014-1618-9
   Scheidl H, 2019, HANDWRITTEN TEXT REC
   Scheidl H, 2018, INT CONF FRONT HAND, P253, DOI 10.1109/ICFHR-2018.2018.00052
   Singh Santosh Kumar, 2015, 2015 International Conference on Energy Economics and Environment (ICEEE), P1, DOI 10.1109/EnergyEconomics.2015.7235065
   Sonkusare M., 2016, Adv vis Comput Int J, V3, P1, DOI DOI 10.5121/AVC.2016.3101
   Sui BL, 2015, PROC INT CONF DOC, P386, DOI 10.1109/ICDAR.2015.7333789
   Taira E, 2004, IEICE T INF SYST, VE87D, P1247
   Vidal E., 2015, P 3 INT WORKSH HIST
   Wang WL, 2015, PROCEDIA COMPUT SCI, V61, P402, DOI 10.1016/j.procs.2015.09.171
   Wang YB, 2021, IEEE INT CONF MULTI, DOI 10.1109/ICMEW53276.2021.9456015
   Zaitoun NM, 2015, PROCEDIA COMPUT SCI, V65, P797, DOI 10.1016/j.procs.2015.09.027
   Zhong GQ, 2015, PATTERN RECOGN, V48, P1211, DOI 10.1016/j.patcog.2014.09.025
NR 49
TC 4
Z9 4
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18223
EP 18249
DI 10.1007/s11042-022-12097-7
EA MAR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766438300004
DA 2024-07-18
ER

PT J
AU Tsai, CS
   Zhang, YS
   Weng, CY
AF Tsai, Chwei-Shyong
   Zhang, Yung-Sung
   Weng, Chi-Yao
TI Separable reversible data hiding in encrypted images based on Paillier
   cryptosystem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encrypted image; Reversible data hiding; Histogram shifting; Paillier
   cryptosystem
ID DIFFERENCE
AB Many researchers pay attention on performing reversible data hiding in encrypted images; after extracting the embedded secret information, the objective is not only to perfectly recover the original image but to also protect the privacy of content. This paper proposes a separable and reversible data hiding in encrypted images scheme based on histogram shifting and the Paillier cryptosystem. The proposed scheme is divided into three parts: the image owner, data hider and receiver. First, the image owner takes the receiver's public key to encrypt the cover image using the Paillier cryptosystem. According to the difference between two adjacent pixels, the data hider collects all the differences to generate the differencing distribution, and then, embeds secret data into differencing using the histogram shifting and hiding key. Finally, the receiver can simultaneously extract the secret information and recover the original image if the receiver has the hiding key and private key. In the experimental results, it is completely shown that compared to other scheme, the proposed scheme has better performance of image quality at the same number of embedded bits.
C1 [Tsai, Chwei-Shyong; Zhang, Yung-Sung] Natl Chung Hsing Univ, Dept Management Informat Syst, Taichung 402, Taiwan.
   [Weng, Chi-Yao] Natl Pingtung Univ, Dept Comp Sci, Pingtung 90003, Taiwan.
C3 National Chung Hsing University; National Pingtung University
RP Weng, CY (corresponding author), Natl Pingtung Univ, Dept Comp Sci, Pingtung 90003, Taiwan.
EM cyweng@mail.nptu.edu.tw
FU Ministry of Science and Technology of the Republic of China; MOST
   [108-2221-E-153-004-MY2, MOST 110-2221-E-153 -002 -MY2]
FX This work was partially supported by the Ministry of Science and
   Technology of the Republic of China under the Grant No. MOST
   108-2221-E-153-004-MY2 and MOST 110-2221-E-153 -002 -MY2.
CR Agrawal S, 2017, OPTIK, V130, P922, DOI 10.1016/j.ijleo.2016.11.059
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chen B, 2019, SIGNAL PROCESS, V164, P48, DOI 10.1016/j.sigpro.2019.05.036
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Fridrich J, 2005, IEEE T SIGNAL PROCES, V53, P3923, DOI 10.1109/TSP.2005.855393
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Jiang CL, 2020, MULTIMED TOOLS APPL, V79, P693, DOI 10.1007/s11042-019-07874-w
   Li M, 2017, SIGNAL PROCESS, V130, P190, DOI 10.1016/j.sigpro.2016.07.002
   Li M, 2015, SIGNAL PROCESS-IMAGE, V39, P234, DOI 10.1016/j.image.2015.10.001
   Li M, 2014, ETRI J, V36, P325, DOI 10.4218/etrij.14.0213.0449
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Lin PY, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2000486.2000489
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Malik A, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102374
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Sharma M, 2020, MULTIMED TOOLS APPL, V79, P355, DOI 10.1007/s11042-019-08079-x
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tang ZJ, 2019, MULTIMED TOOLS APPL, V78, P9691, DOI 10.1007/s11042-018-6567-3
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wu HT, 2016, J VIS COMMUN IMAGE R, V40, P765, DOI 10.1016/j.jvcir.2016.08.021
   Wu XT, 2016, J VIS COMMUN IMAGE R, V41, P58, DOI 10.1016/j.jvcir.2016.09.005
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xiang SJ, 2017, EURASIP J ADV SIG PR, DOI 10.1186/s13634-017-0496-6
   Xiao D, 2017, J VIS COMMUN IMAGE R, V45, P1, DOI 10.1016/j.jvcir.2017.02.001
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 35
TC 9
Z9 10
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18807
EP 18827
DI 10.1007/s11042-022-12684-8
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766063900001
DA 2024-07-18
ER

PT J
AU Liu, QX
   Li, HJ
   Liu, Z
AF Liu, Qiuxu
   Li, Hongjiao
   Liu, Zheng
TI Image forgery localization based on fully convolutional network with
   noise feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Forgery localization; Image forensics; Deep learning; Fully
   convolutional network
AB To detect the maliciously tampered region in digital images, this paper proposes an image forgery localization method based on a fully convolutional network (FCN). In the pre-processing phase of the network, noise features are used to adequately expose the subtle changes in the image caused by manipulation operations, thus enhancing the generalization ability of the network. The convolutional layer is used in a fully convolutional network instead of the fully connected layer to generate a pixel-wise prediction. In addition, the region proposal network used in object detection is added to improve the robustness. Experiments on standard datasets show that our method can accurately locate the tampered regions of images and improve generalization ability and robustness.
C1 [Liu, Qiuxu; Li, Hongjiao; Liu, Zheng] Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 201306, Peoples R China.
C3 Shanghai University of Electric Power
RP Li, HJ (corresponding author), Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 201306, Peoples R China.
EM hjli@shiep.edu.cn
CR [Anonymous], 2017, Electronic Imaging
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bondi L, 2017, IEEE COMPUT SOC CONF, P1855, DOI 10.1109/CVPRW.2017.232
   Chen BJ, 2018, IEEE ACCESS, V6, P69472, DOI 10.1109/ACCESS.2018.2880433
   Chen JX, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116287
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gao SD, 2019, J REAL-TIME IMAGE PR, V16, P741, DOI 10.1007/s11554-019-00860-3
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Kohli R, 2019, ADV INTELLIGENT SYST, V904, DOI [10.1007/978-981-13-5934-7_6, DOI 10.1007/978-981-13-5934-7_6]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li WH, 2009, SIGNAL PROCESS, V89, P1821, DOI 10.1016/j.sigpro.2009.03.025
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Lin X, 2018, ENGINEERING-PRC, V4, P29, DOI 10.1016/j.eng.2018.02.008
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Liu B, 2018, SIGNAL PROCESS-IMAGE, V66, P103, DOI 10.1016/j.image.2018.04.011
   Liu YQ, 2019, IEEE T INF FOREN SEC, V14, P2551, DOI 10.1109/TIFS.2019.2902826
   Liu YQ, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P85, DOI 10.1145/3206004.3206010
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   Rao Y, 2016, IEEE INT WORKS INFOR
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Srivastava D, 2017, ADV COMPUTER COMPUTA, V553, DOI [10.1007/978-981-10-3770-2_20, DOI 10.1007/978-981-10-3770-2_20]
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Wu Y, 2019, PROC CVPR IEEE, P9535, DOI 10.1109/CVPR.2019.00977
   Wu Y, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1480, DOI 10.1145/3123266.3123411
   Yang C, 2020, CONSTRAINED R CNN GE
   Ye SM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P12
   Zhang Y, 2016, CRYPTOL INF SEC SER, V14, P1, DOI 10.3233/978-1-61499-617-0-1
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
NR 33
TC 1
Z9 1
U1 3
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 17919
EP 17935
DI 10.1007/s11042-022-12758-7
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766064000008
DA 2024-07-18
ER

PT J
AU Xu, DW
   Guan, B
AF Xu, Dawen
   Guan, Bo
TI An improved commutative encryption and data hiding scheme for HEVC video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video data hiding; Selective encryption; High efficiency video coding
   (HEVC); Security analysis
ID SELECTIVE ENCRYPTION; ENCODED VIDEO; H.264/AVC; WATERMARKING
AB With the popularity of cloud computing and High Efficiency Video Coding (HEVC) codec, commutative encryption and data hiding schemes designed for HEVC has attracted great attention. This paper proposes an improved commutative encryption and data hiding scheme for HEVC video. In order to produce sufficient visual distortion, in addition to the syntax elements of context-based adaptive binary arithmetic coding in bypass mode, some syntax elements in regular mode including luma intra-prediction mode (IPM) and chroma IPM are selected for encryption. Quantized transform coefficient (QTC)'s amplitude is exploited for data embedding. An improved data embedding technology is designed by combining bin-string pairing, which improves the embedding capacity to a certain extent. In the framework, video encryption and data hiding are fully commutative, and the marked encrypted bitstream is format compatible. Experimental results demonstrate that the improved scheme can enhance the security while increasing the embedding capacity.
C1 [Xu, Dawen; Guan, Bo] Ningbo Univ Technol, Sch Elect & Informat Engn, Ningbo 315016, Peoples R China.
C3 Ningbo University of Technology
RP Xu, DW (corresponding author), Ningbo Univ Technol, Sch Elect & Informat Engn, Ningbo 315016, Peoples R China.
EM dawenxu@126.com
OI xu, dawen/0000-0002-9619-8407
FU National Natural Science Foundation of China [61771270, 62071267];
   Zhejiang Provincial Natural Science Foundation of China [LR20F020001,
   LY21F020007]
FX This work is supported by the National Natural Science Foundation of
   China (61771270, 62071267), Zhejiang Provincial Natural Science
   Foundation of China (LR20F020001, LY21F020007).
CR Asikuzzaman M, 2018, IEEE T CIRC SYST VID, V28, P2131, DOI 10.1109/TCSVT.2017.2712162
   Boyadjis B, 2017, IEEE T CIRC SYST VID, V27, P892, DOI 10.1109/TCSVT.2015.2511879
   Chang PC, 2014, J VIS COMMUN IMAGE R, V25, P239, DOI 10.1016/j.jvcir.2013.10.007
   Chen YL, 2021, IEEE T DEPEND SECURE, V18, P1320, DOI 10.1109/TDSC.2019.2932983
   Dutta T, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3002178
   Dutta T, 2016, J VIS COMMUN IMAGE R, V38, P29, DOI 10.1016/j.jvcir.2015.12.007
   Gaj S, 2020, MULTIMED TOOLS APPL, V79, P18089, DOI 10.1007/s11042-019-08301-w
   Guan B, 2020, IEEE ACCESS, V8, P60232, DOI 10.1109/ACCESS.2020.2983330
   He JH, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115994
   Lian SG, 2007, IEEE T CIRC SYST VID, V17, P774, DOI 10.1109/TCSVT.2007.896635
   Lian SG, 2009, MULTIMED TOOLS APPL, V43, P91, DOI 10.1007/s11042-008-0258-4
   Liu YX, 2015, NEUROCOMPUTING, V151, P1076, DOI 10.1016/j.neucom.2014.03.089
   Long M, 2018, J REAL-TIME IMAGE PR, V14, P171, DOI 10.1007/s11554-017-0727-y
   Mareen H, 2019, IEEE T INF FOREN SEC, V14, P1432, DOI 10.1109/TIFS.2018.2879301
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Peng F, 2020, IEEE T CIRC SYST VID, V30, P2765, DOI 10.1109/TCSVT.2019.2924910
   Ramos FLL, 2020, IEEE T CIRCUITS-I, V67, P475, DOI 10.1109/TCSI.2019.2932891
   Sallam AI, 2018, IEEE T MULTIMEDIA, V20, P1636, DOI 10.1109/TMM.2017.2777470
   Shahid Z, 2014, IEEE T MULTIMEDIA, V16, P24, DOI 10.1109/TMM.2013.2281029
   Sole J, 2012, IEEE T CIRC SYST VID, V22, P1765, DOI 10.1109/TCSVT.2012.2223055
   Stütz T, 2014, IEEE T MULTIMEDIA, V16, P1337, DOI 10.1109/TMM.2014.2310595
   Stütz T, 2012, IEEE T CIRC SYST VID, V22, P325, DOI 10.1109/TCSVT.2011.2162290
   Sze V, 2012, IEEE T CIRC SYST VID, V22, P1778, DOI 10.1109/TCSVT.2012.2221526
   Tew Y, 2018, MULTIMED TOOLS APPL, V77, P24165, DOI 10.1007/s11042-018-5611-7
   Tew Y, 2014, IEEE T CIRC SYST VID, V24, P305, DOI 10.1109/TCSVT.2013.2276710
   Thiyagarajan K, 2019, IEEE T CIRC SYST VID, V29, P610, DOI 10.1109/TCSVT.2018.2808174
   Wang YS, 2013, IEEE T CIRC SYST VID, V23, P1476, DOI 10.1109/TCSVT.2013.2248588
   Wang Y, 2021, IEEE T INF FOREN SEC, V16, P333, DOI 10.1109/TIFS.2020.3013523
   Xu DW, 2019, IEEE ACCESS, V7, P66028, DOI 10.1109/ACCESS.2019.2916484
   Xu DW, 2017, J VIS COMMUN IMAGE R, V45, P34, DOI 10.1016/j.jvcir.2017.02.008
   Xu DW, 2016, J VIS COMMUN IMAGE R, V36, P229, DOI 10.1016/j.jvcir.2016.02.002
   Xu DW, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.3.033028
   Xu DW, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.5.053022
   Xu DW, 2014, IEEE T INF FOREN SEC, V9, P596, DOI 10.1109/TIFS.2014.2302899
   Xu DW, 2011, OPT ENG, V50, DOI 10.1117/1.3622759
   Yang J, 2018, MULTIMED TOOLS APPL, V77, P11979, DOI 10.1007/s11042-017-4844-1
   Yao YZ, 2016, SIGNAL PROCESS, V128, P531, DOI 10.1016/j.sigpro.2016.05.004
NR 37
TC 5
Z9 5
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18105
EP 18127
DI 10.1007/s11042-022-12676-8
EA MAR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766064000005
DA 2024-07-18
ER

PT J
AU Jemimma, TA
   Vetharaj, YJ
AF Jemimma, T. A.
   Vetharaj, Y. Jacob
TI Fractional probabilistic fuzzy clustering and optimization based brain
   tumor segmentation and classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fractional theory; Clustering; Optimization; Automatic segmentation;
   Brain tumor detection
AB Brain tumor detection concentrates on the automatic segmentation and classification of the brain tumors using the MRI brain images. The proposed work includes pre-processing, segmentation, feature extraction and classification. In the pre-processing step the RGB image is subjected to hue colour transformation and then thresholding and Morphological operations are performed. The automatic segmentation is initiated using Fractional probabilistic Fuzzy C Means (Fr-pFCM) by combining the fractional theory and probabilistic Fuzzy Clustering (probabilistic FCM) to enable the highly accurate segments. The features are extracted from the segments for which the descriptors, Empirical Mode Decomposition (EMD), Local Directional Pattern (LDP), wavelet transform, and theoretic information measures are employed. The final classification is done using the Whale-Cat Swarm Optimization based Deep Belief Network (WCSO-DBN). The experimentation using the images from the BRATS database outperformed the existing classification methods with higher accuracy, sensitivity, and specificity of 0.923, 0.95, and 0.96, respectively.
C1 [Jemimma, T. A.] Marthandam Manonmaniam Sunadaranar Univ, Nesamony Mem Christian Coll, Tirunelveli 627012, Tamil Nadu, India.
   [Vetharaj, Y. Jacob] Marthandam Manonmaniam Sunadaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University; Manonmaniam Sundaranar University
RP Jemimma, TA (corresponding author), Marthandam Manonmaniam Sunadaranar Univ, Nesamony Mem Christian Coll, Tirunelveli 627012, Tamil Nadu, India.
EM jemisudhar@gmail.com; jacobvetharaj@gmail.com
OI Jemimma, T.A/0000-0001-5715-1393
CR Ahmadvand A, 2018, MULTIMED TOOLS APPL, V77, P8001, DOI 10.1007/s11042-017-4696-8
   Amin J, 2020, PATTERN RECOGN LETT, V139, P118, DOI 10.1016/j.patrec.2017.10.036
   Anbeek Petronella., 2008, MIDAS Journal
   Angulakshmi M, 2020, J KING SAUD UNIV-COM, V32, P1182, DOI 10.1016/j.jksuci.2018.01.009
   Anitha V, 2016, IET COMPUT VIS, V10, P9, DOI 10.1049/iet-cvi.2014.0193
   Armstrong Terri S, 2004, Semin Oncol Nurs, V20, P231, DOI 10.1016/S0749-2081(04)00087-7
   Bahrami M, 2018, STUD COMPUT INTELL, V720, P9, DOI [10.1007/978-981-10-5221-7_2, 10.1007/978-3-319-72929-9_2]
   Bauer S, 2013, PHYS MED BIOL, V58, pR97, DOI 10.1088/0031-9155/58/13/R97
   Bhaladhare PR, 2014, ADV COMPUT ENG, P1
   Cabria I, 2017, INFORM FUSION, V36, P1, DOI 10.1016/j.inffus.2016.10.003
   Chen H, 2020, NEUROCOMPUTING, V392, P305, DOI 10.1016/j.neucom.2019.01.111
   Clark MC, 1998, IEEE T MED IMAGING, V17, P187, DOI 10.1109/42.700731
   Deng W, 2020, IEEE ACCESS, V8, P26665, DOI 10.1109/ACCESS.2020.2966879
   Devi Nilakshi, 2018, Proceedings of the International Conference on Computing and Communication Systems. I3CS 2016. Lecture Notes in Networks and Systems (LNNS 24), P125, DOI 10.1007/978-981-10-6890-4_11
   Huang SQ, 2016, Adv Inform Managemen, P615, DOI 10.1109/IMCEC.2016.7867283
   Ilunga-Mbuyamba E, 2017, COMPUT BIOL MED, V91, P69, DOI 10.1016/j.compbiomed.2017.10.003
   Jui SL, 2016, IEEE INTELL SYST, V31, P66, DOI 10.1109/MIS.2015.93
   Khan H, 2020, COMPUT COMMUN, V153, P196, DOI 10.1016/j.comcom.2020.01.013
   Kharat KD., 2012, INT J COMPUT SCI INF, P112, DOI DOI 10.47893/IJCSI.2012.1075
   Li YH, 2016, ARTIF INTELL MED, V73, P1, DOI 10.1016/j.artmed.2016.08.004
   Ludwig O, 2014, NEUROCOMPUTING, V124, P33, DOI 10.1016/j.neucom.2013.08.005
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Mills S, 2017, LOOP descriptor: Encoding repeated local patterns for fine-grained visual identification of Lepidoptera
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Nefti S, 2004, IEEE SYS MAN CYBERN, P4786
   Padma A, 2011, AUTOMATIC DIAGNOSIS, P17
   Pourreza R, 2018, LECT NOTES COMPUT SC, V10670, P320, DOI 10.1007/978-3-319-75238-9_28
   Raja PMS, 2020, BIOCYBERN BIOMED ENG, V40, P440, DOI 10.1016/j.bbe.2020.01.006
   Raju AR, 2018, BIOCYBERN BIOMED ENG, V38, P646, DOI 10.1016/j.bbe.2018.05.001
   Ramakrishnan T, 2017, PATTERN RECOGN LETT, V94, P163, DOI 10.1016/j.patrec.2017.03.026
   Shehab LH, 2020, J KING SAUD U ENG SC, P1
   Vojt J, 2016, DEEP NEURAL NETWORKS, P96
   Wang GT, 2018, IEEE T MED IMAGING, V37, P1562, DOI 10.1109/TMI.2018.2791721
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhang SC, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2990508
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
NR 36
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 17889
EP 17918
DI 10.1007/s11042-022-11969-2
EA MAR 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000765701900013
DA 2024-07-18
ER

PT J
AU Bansalr, H
   Sharma, K
   Khari, M
AF Bansalr, Himani
   Sharma, Kavita
   Khari, Manju
TI Crowd analytics: literature and technological assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd analysis; Crowd management; Crowd-sourcing; Disaster management;
   Human detection; Human tracking; Human segmentation; Action recognition;
   Abnormal behaviour detection
AB In previous years, the world has gone through several natural disasters like Tsunami, earthquakes, floods, tornadoes, hurricanes, cyclones, etc., and manufactured disasters such as stampedes, fire, terror attacks, etc. A large number of causalities are reported, with a massive loss to life, economy, and other things. Knowing this, we should make a transit from a reliable and flexible disaster management approach to a proactive one by leveraging advances in science and technology. A colossal increase in worldwide population points out that the occurrence of a crowd at any place is becoming more and more familiar with each passing day. It is undeniable that these mass gatherings often become a source of a crowd-related catastrophe such as sudden escape, terror attacks, mob lynching, human stampede, or human crushing. Prior research on the crowd's social, psychological, and computational dynamics has indicated that the crowd's behavior under such devastating conditions is greatly decisive for crowd safety, its access or escape from the affected region, and emergency evacuation. Despite this, there is a certain paucity of pragmatic research on extreme crowd-related use cases and how to deal with such situations effectively. Through the past years, people and media have shared the details of such happenings and their experiences on a micro-level through various social network mediums. Attempts are being made to analyze this data using advanced technological tools and methods to extract the trends out of such happenings and predict any future happenings so that countermeasures can be taken and they can be prevented. This paper makes a structured literature assessment on the current scenario and systematically surveys the studies made in this field. It paves the path for future rendezvous in this area to unearth the hidden gold mine of information along the timeline. Also, an attempt is made to develop a technological solution or system that may help achieve an elevated level of social security via holistic video surveillance capable of detecting any crowd-related anomaly and proactively warning the concerned authorities about any such casualty. This will ensure that crowd disasters can be prevented well in time by gaining prior insights about them. The system is developed that encompasses everything from human detection, tracking, and counting to any abnormal behavior detection. The same has been achieved with 93.33% accuracy.
C1 [Bansalr, Himani] Jaypee Inst Informat Technol, Dept CSE & IT, Noida, India.
   [Sharma, Kavita] Galgotias Coll Engn & Technol, Dept CSE, Greater Noida, India.
   [Khari, Manju] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.
C3 Jaypee Institute of Information Technology (JIIT); Galgotias College of
   Engineering & Technology (GCET); Jawaharlal Nehru University, New Delhi
RP Bansalr, H (corresponding author), Jaypee Inst Informat Technol, Dept CSE & IT, Noida, India.
EM singal.himani@gmail.com; kavitasharma_06@yahoo.co.in;
   manjukhari@yahoo.co.in
RI Khari, Manju/B-6040-2017
CR Altamimi AB, 2020, ENG TECHNOL APPL SCI, V10, P5412
   Amarilli A, 2014, LECT NOTES COMPUT SC, V8505, P351, DOI 10.1007/978-3-662-43984-5_27
   Ammar Sirine, DEEP DETECTOR CLASSI
   Amsterdamer Y, 2014, PROC VLDB ENDOW, V7, P1597, DOI 10.14778/2733004.2733039
   Amsterdamer Y, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P589, DOI 10.1145/2588555.2610514
   Amsterdamer Y, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1433, DOI 10.1145/2723372.2735370
   Amsterdamer Yael., 2013, P ACM SIGMOD INT C M, P241
   Bansal, 2015, ARXIV PREPRINT ARXIV
   Biswas S, 2014, IEEE IMAGE PROC, P2319, DOI 10.1109/ICIP.2014.7025470
   Butenuth M., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P150, DOI 10.1109/ICCVW.2011.6130237
   Chaudhari MD., 2018, INT J COMPUT SCI ENG, V6, P424, DOI DOI 10.26438/IJCSE/V6I4.424428
   Chaudhary S, 2018, PROCEDIA COMPUT SCI, V125, P336, DOI 10.1016/j.procs.2017.12.045
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   DAVIES AC, 1995, ELECTRON COMMUN ENG, V7, P37, DOI 10.1049/ecej:19950106
   Goyal A., 2020, LECT NOTES ELECT ENG
   Guo XT, 2014, EXPERT SYST APPL, V41, P7987, DOI 10.1016/j.eswa.2014.06.044
   Hao Y, 2019, INT J AUTOM COMPUT, V16, P27, DOI 10.1007/s11633-018-1141-z
   He FX, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392407
   Ilyas N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010043
   Isella L, 2011, J THEOR BIOL, V271, P166, DOI 10.1016/j.jtbi.2010.11.033
   Ji HX, 2020, PROCEEDINGS OF 2020 5TH INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP 2020), P1, DOI 10.1145/3381271.3381273
   Johansson A, 2008, ADV COMPLEX SYST, V11, P497, DOI 10.1142/S0219525908001854
   Kumar M, 2017, INT J COMPUT INT SYS, V10, P234, DOI 10.2991/ijcis.2017.10.1.16
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Li XL, 2020, IEEE T IMAGE PROCESS, V29, P5571, DOI 10.1109/TIP.2020.2985284
   Liu CY, 2018, IEICE T INF SYST, VE101D, P1968, DOI 10.1587/transinf.2018EDL8005
   Ma JZ, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR 2019), P10, DOI 10.1145/3357254.3357273
   Nayan N, 2019, SIVIP, P1
   Truong NB, 2019, IEEE T INF FOREN SEC, V14, P2705, DOI 10.1109/TIFS.2019.2903659
   Patel SP, 2013, INT J ADV RES COMPUT, V4
   Prasanna, 2015, 2 WORLD C DIS MAN
   Reddy, United States Patent, Patent No. [10, 375, 150 B2, 10375150]
   Rodríguez C, 2014, LECT NOTES COMPUT SC, V8659, P51, DOI 10.1007/978-3-319-10172-9_4
   Rogstadius J, 2011, P CHI WORKSH CROWDS
   Jacques JCS, 2010, IEEE SIGNAL PROC MAG, V27, P66, DOI 10.1109/MSP.2010.937394
   Singh K, 2020, NEUROCOMPUTING, V371, P188, DOI 10.1016/j.neucom.2019.08.059
   Solmaz B, 2012, IEEE T PATTERN ANAL, V34, P2064, DOI 10.1109/TPAMI.2012.123
   Sreenu G, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0212-5
   Vashistha A, 2015, LECT NOTES COMPUT SC, V9297, P505, DOI 10.1007/978-3-319-22668-2_39
   Wang J., 2015, 6 INT C IM CRIM PREV, P4
   Wu XY, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-3, P214, DOI 10.1109/ROBIO.2006.340379
   XU M, 2016, GEOMAT NAT HAZ RISK, V7, P1
   Yang B, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/2087574
   Yogameena B, 2014, INT J INNOV RES SCI, V3
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
NR 45
TC 0
Z9 0
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15249
EP 15283
DI 10.1007/s11042-022-12274-8
EA FEB 2022
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600015
DA 2024-07-18
ER

PT J
AU Tran, TT
   Pham, VT
AF Thi-Thao Tran
   Van-Truong Pham
TI Fully convolutional neural network with attention gate and fuzzy active
   contour model for skin lesion segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin lesion segmentation; Fuzzy active contour model; SegNet; Attention
   gate; Fully convolutional network
ID DERMOSCOPIC IMAGE SEGMENTATION
AB This study proposes an approach for segmentation of skin lesions from dermoscopic images based on fully convolutional neural network and active contour model (ACM). The architecture of fully convolutional neural network (FCN) is adapted from the SegNet neural network. Particularly, the paper proposes to use the skip connection architecture and integrate the additive attention gate (AG) into the SegNet architecture. So that the model can better handle the variation in shapes and sizes of desired objects and produce more accurate segmentation. In addition, the fuzzy energy-based shape distance is introduced to the loss function for minimizing the dissimilarity between the prediction and reference masks. Moreover, the fuzzy energy-based ACM, with contours initialized from the network predicted masks, is employed to further evolve the contour toward desired object boundary. The proposed model therefore can take the advantages of the neural network and the fuzzy ACM to build a fully automatic and robust approach for segmentation of skin lesions. The proposed approach is evaluated on the ISIC 2017 and PH2 challenge databases. Comparative results on the two databases show desired performances of the approach while compared to other state-of-the-arts.
C1 [Thi-Thao Tran; Van-Truong Pham] Hanoi Univ Sci & Technol, Sch Elect Engn, Hanoi, Vietnam.
C3 Hanoi University of Science & Technology (HUST)
RP Pham, VT (corresponding author), Hanoi Univ Sci & Technol, Sch Elect Engn, Hanoi, Vietnam.
EM truong.phamvan@hust.edu.vn
RI Pham, Van-Truong/KRP-5967-2024
OI Tran, Thi-Thao/0009-0008-0862-1262; Pham, Van-Truong/0000-0003-3489-0569
FU Vietnam National Foundation for Science and Technology Development
   (NAFOSTED) [102.05-2018.302]; Hanoi University of Science and Technology
   (HUST) [T2021-PC-005]
FX This research is funded by Vietnam National Foundation for Science and
   Technology Development (NAFOSTED) under grant number 102.05-2018.302,
   and partly supported by the Hanoi University of Science and Technology
   (HUST) under project number T2021-PC-005.
CR Abraham N, 2019, I S BIOMED IMAGING, P683, DOI 10.1109/ISBI.2019.8759329
   [Anonymous], 2015, Dermoscopy image analysis, DOI DOI 10.1201/B19107
   [Anonymous], CORR
   Arora M, 2021, MULTIMED TOOLS APPL, V80, P3039, DOI 10.1007/s11042-020-09726-4
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Baghersalimi S, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0467-y
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Bi L., 2017, Automatic Skin Lesion Analysis using Largescale Dermoscopy Images and Deep Residual Networks
   Bi L, 2019, PATTERN RECOGN, V85, P78, DOI 10.1016/j.patcog.2018.08.001
   Bi L, 2017, IEEE T BIO-MED ENG, V64, P2065, DOI 10.1109/TBME.2017.2712771
   Bozorgtabar B, 2016, LECT NOTES COMPUT SC, V10019, P254, DOI 10.1007/978-3-319-47157-0_31
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Cao Y, 2020, IET IMAGE PROCESS, V14, P2682, DOI 10.1049/iet-ipr.2019.1527
   Chan TE, 2000, J VIS COMMUN IMAGE R, V11, P130, DOI 10.1006/jvci.1999.0442
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen X, 2019, PROC CVPR IEEE, P11624, DOI 10.1109/CVPR.2019.01190
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Ibtehaz N., 2019, MultiResUNet: Rethinking the U-Net Architecture for Multimodal Biomedical Image Segmentation
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Jahanifar M, 2019, IEEE J BIOMED HEALTH, V23, P509, DOI 10.1109/JBHI.2018.2839647
   Krinidis S, 2009, IEEE T IMAGE PROCESS, V18, P2747, DOI 10.1109/TIP.2009.2030468
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Kumar A, 2019, ARTIF INTELL REV, V52, P927, DOI 10.1007/s10462-018-9650-2
   Kumar M. M., 2020, COMPUT METHODS DATA, V1227, P207
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu X., 2020, ECCV, V12348, P661, DOI DOI 10.1007/978-3-030-58580-8_39
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   LU XQ, 2021, IEEE T IND INFORM, V17, P1483, DOI DOI 10.1109/TII.2020.2985905
   Mendonca Teresa, 2013, 2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), P5437, DOI 10.1109/EMBC.2013.6610779
   MISHRAA NK, 2016, ARXIV160107843
   Mondal A, 2020, MULTIMED TOOLS APPL, V79, P1535, DOI 10.1007/s11042-019-08207-7
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Pellacani G, 2002, CLIN DERMATOL, V20, P222, DOI 10.1016/S0738-081X(02)00231-6
   Ninh QC, 2019, PROCEEDINGS OF 2019 6TH NATIONAL FOUNDATION FOR SCIENCE AND TECHNOLOGY DEVELOPMENT (NAFOSTED) CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS), P575, DOI [10.1109/nics48868.2019.9023862, 10.1109/NICS48868.2019.9023862]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Salehi SSM, 2017, LECT NOTES COMPUT SC, V10541, P379, DOI 10.1007/978-3-319-67389-9_44
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Soltaninejad S., 2018, ARXIV180607554
   Tang YJ, 2019, I S BIOMED IMAGING, P1407, DOI [10.1109/isbi.2019.8759535, 10.1109/ISBI.2019.8759535]
   Tran TT, 2014, J VIS COMMUN IMAGE R, V25, P1732, DOI 10.1016/j.jvcir.2014.06.006
   Tu WL, 2019, IEEE ACCESS, V7, P77037, DOI 10.1109/ACCESS.2019.2921815
   Ünver HM, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030072
   Vu Tran P., 2016, ARXIV160400494
   Wu Y, 2015, APPL SOFT COMPUT, V34, P301, DOI 10.1016/j.asoc.2015.04.058
   Xue Y, 2018, NEUROINFORMATICS, V16, P383, DOI 10.1007/s12021-018-9377-x
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Yuan YD, 2019, IEEE J BIOMED HEALTH, V23, P519, DOI 10.1109/JBHI.2017.2787487
   Yuan YD, 2017, IEEE T MED IMAGING, V36, P1876, DOI 10.1109/TMI.2017.2695227
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
   Zongyuan Ge, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P250, DOI 10.1007/978-3-319-66179-7_29
NR 54
TC 9
Z9 9
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13979
EP 13999
DI 10.1007/s11042-022-12413-1
EA FEB 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761886300007
DA 2024-07-18
ER

PT J
AU Wang, XY
   Su, YN
   Luo, C
   Nian, FZ
   Teng, L
AF Wang, Xingyuan
   Su, Yining
   Luo, Chao
   Nian, Fuzhong
   Teng, Lin
TI Color image encryption algorithm based on hyperchaotic system and
   improved quantum revolving gate
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Four-wing chaotic system; Quantum rotation; NEQR; Quantum color image
   encryption
ID HYPER-CHAOTIC SYSTEM; SEMI-TENSOR PRODUCT; TRANSFORM; SECRET
AB Because quantum computing can break encryption systems based on mathematical models, this paper proposes a new color quantum image encryption algorithm based on hyperchaotic system and quantum revolving gate. First, the classic image is diffused, the matrix generated by the four-wing chaotic system is serialized, and XORed with the key and plaintext to obtain the semi-ciphertext image. Then, the quantum rotation method is used to perform scrambling operations on images quantized using the improved novelty enhanced quantum representation (NEQR) model. The angle of rotation is determined by the sequence generated by the piecewise chaotic map. Finally, the experimental results and performance analysis prove that the algorithm has high security performance.
C1 [Wang, Xingyuan; Su, Yining; Teng, Lin] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
   [Wang, Xingyuan] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Luo, Chao] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Peoples R China.
   [Nian, Fuzhong] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
C3 Dalian Maritime University; Guangxi Normal University; Shandong Normal
   University; Lanzhou University of Technology
RP Wang, XY (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.; Wang, XY (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
EM xywang@dlmu.edu.cn
RI Wang, Xing-yuan/I-6353-2015
OI Teng, Lin/0000-0002-3758-4439
FU National Natural Science Foundation of China [61672124]; Password Theory
   Project of the 13th FiveYear Plan National Cryptography Development Fund
   [MMJJ20170203]; Liaoning Province Science and Technology Innovation
   Leading Talents Program Project [XLYC1802013]; Key RAMP;D Projects of
   Liaoning Province [2019020105-JH2/103]; Jinan City '20 universities'
   Funding Projects Introducing Innovation Team Program [2019GXRC031];
   Research Fund of Guangxi Key Lab of Multi-source Information Mining
   Security [MIMS20-M-02]
FX This research is supported by the National Natural Science Foundation of
   China (No: 61672124), the Password Theory Project of the 13th FiveYear
   Plan National Cryptography Development Fund (No: MMJJ20170203), Liaoning
   Province Science and Technology Innovation Leading Talents Program
   Project (No: XLYC1802013), Key R&D Projects of Liaoning Province (No:
   2019020105-JH2/103), Jinan City '20 universities' Funding Projects
   Introducing Innovation Team Program (No: 2019GXRC031), Research Fund of
   Guangxi Key Lab of Multi-source Information Mining & Security (No:
   MIMS20-M-02).
CR Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abuturab MR, 2015, OPT LASER ENG, V69, P49, DOI 10.1016/j.optlaseng.2015.01.001
   Alghafis A, 2020, PHYSICA A, V554, DOI 10.1016/j.physa.2019.123908
   Atali G, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.2.023026
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   GEIST K, 1990, PROG THEOR PHYS, V83, P875, DOI 10.1143/PTP.83.875
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P4505, DOI 10.1007/s11071-021-06472-6
   Jiang N, 2019, INT J THEOR PHYS, V58, P979, DOI 10.1007/s10773-018-3989-7
   Khan M, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-019-2410-7
   Kumar M, 2019, MULTIMED TOOLS APPL, V78, P28025, DOI 10.1007/s11042-019-07893-7
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Li Q, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107618
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Liu HJ, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501734
   Liu HJ, 2019, APPL MATH COMPUT, V360, P83, DOI 10.1016/j.amc.2019.04.078
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Luo YL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105836
   Luo YL, 2018, MULTIMED TOOLS APPL, V77, P26191, DOI 10.1007/s11042-018-5844-5
   Monika, 2021, Computational Methods and Data Engineering. Proceedings of ICMDE 2020. Advances in Intelligent Systems and Computing (AISC 1227), P207, DOI 10.1007/978-981-15-6876-3_16
   Musanna F, 2020, QUANTUM INF PROCESS, V19, DOI 10.1007/s11128-020-02724-3
   Patro KAK, 2019, J INF SECUR APPL, V46, P23, DOI 10.1016/j.jisa.2019.02.006
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Sui LS, 2015, OPT LASER ENG, V75, P17, DOI 10.1016/j.optlaseng.2015.06.005
   Sun XC, 2021, MULTIMED TOOLS APPL, V80, P13491, DOI 10.1007/s11042-020-10392-9
   Tan RC, 2016, INT J THEOR PHYS, V55, P5368, DOI 10.1007/s10773-016-3157-x
   Wang HQ, 2019, INT J THEOR PHYS, V58, P1626, DOI 10.1007/s10773-019-04057-z
   Wang L, 2020, MULTIMED TOOLS APPL, V79, P6661, DOI 10.1007/s11042-019-08514-z
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wang W, 2016, J SENSORS, V2016, DOI 10.1155/2016/2646205
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wang XY, 2022, IEEE T CIRCUITS-I, V69, P1291, DOI 10.1109/TCSI.2021.3133318
   Wang XY, 2021, INFORM SCIENCES, V569, P217, DOI 10.1016/j.ins.2021.04.013
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Y, 2015, OPT COMMUN, V344, P147, DOI 10.1016/j.optcom.2015.01.045
   Xian YJ, 2022, IEEE T CIRC SYST VID, V32, P4028, DOI 10.1109/TCSVT.2021.3108767
   Yang YG, 2016, INFORM SCIENCES, V345, P257, DOI 10.1016/j.ins.2016.01.078
   Yassen MT, 2008, CHAOS SOLITON FRACT, V37, P465, DOI 10.1016/j.chaos.2006.09.045
   Zhan Kai, 2017, Computer Engineering and Applications, V53, P36, DOI 10.3778/j.issn.1002-8331.1601-0059
   Zhang Y, 2013, QUANTUM INF PROCESS, V12, P3103, DOI 10.1007/s11128-013-0587-8
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1902-1
   Zhou NR, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-017-1612-0
NR 48
TC 27
Z9 28
U1 10
U2 72
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13845
EP 13865
DI 10.1007/s11042-022-12220-8
EA FEB 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300004
DA 2024-07-18
ER

PT J
AU Aghamaleki, JA
AF Aghamaleki, Javad Abbasi
TI Combined and optimized 2-steps ratio map for shadow detection in aerial
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shadow detection; Color aerial image; Combined ratio map; RGB color
   space; YCbCr color space; Color attenuation relationship
ID REMOVAL; SURFACES
AB Shadow is a malicious phenomenon in aerial image processing algorithms. Locating shadow regions is very helpful in aerial image processing. This paper presents a new optimized algorithm for extracting shadows from a single aerial color image. Most of similar approaches extract shadows by using a suite color space. In this work, two RGB and YCbCr color spaces are combined and a powerful 2-steps ratio map has been created. Furthermore, as a new idea, effect of the blue color of sky is used to improve performance of the proposed ratio map. Candidate shadow and non-shadow regions are separated by applying Otsu's thresholding method. Because of the performance of the ratio map, it is not necessary to analyse the image locally and region by region. Therefore, it leads to decrease computational cost and it can be used in online applications. In order to demonstrate the superior performance of the proposed method, both qualitative and quantitative comparisons of the method with other state-of-the-art techniques are provided.
C1 [Aghamaleki, Javad Abbasi] Damgham Univ, Fac Engn Dept, Damghan, Iran.
RP Aghamaleki, JA (corresponding author), Damgham Univ, Fac Engn Dept, Damghan, Iran.
EM J.a.aghamaleki@du.ac.ir
CR Sabri MA, 2019, MULTIMED TOOLS APPL, V78, P11263, DOI 10.1007/s11042-018-6678-x
   Arbel E, 2011, IEEE T PATTERN ANAL, V33, P1202, DOI 10.1109/TPAMI.2010.157
   Bameri S., 2010, J ELECT ENG TABRIZ U, V40, P12
   Cao XC, 2007, COMPUT VIS IMAGE UND, V105, P60, DOI 10.1016/j.cviu.2006.08.003
   Chung KL, 2009, IEEE T GEOSCI REMOTE, V47, P671, DOI 10.1109/TGRS.2008.2004629
   Finlayson GD, 2006, IEEE T PATTERN ANAL, V28, P59, DOI 10.1109/TPAMI.2006.18
   Finlayson GD, 2004, LECT NOTES COMPUT SC, V3023, P582
   Finlayson GD, 2002, LECT NOTES COMPUT SC, V2353, P823
   Finlayson G, 2007, IEEE I CONF COMP VIS, P2041
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Guo RQ, 2013, IEEE T PATTERN ANAL, V35, P2956, DOI 10.1109/TPAMI.2012.214
   Hai-Yan Yu, 2010, 2010 International Conference on Machine Learning and Cybernetics (ICMLC 2010), P780, DOI 10.1109/ICMLC.2010.5580577
   Jianjun Huang, 2004, Fifth World Congress on Intelligent Control and Automation (IEEE Cat. No.04EX788), P3098
   Khan Saiqa, 2019, 2019 Third International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P723, DOI 10.1109/I-SMAC47947.2019.9032447
   Lalonde JF, 2010, LECT NOTES COMPUT SC, V6312, P322, DOI 10.1007/978-3-642-15552-9_24
   Liu QG, 2011, IEEE T INF FOREN SEC, V6, P1111, DOI 10.1109/TIFS.2011.2139209
   Liu XL, 2017, INT J REMOTE SENS, V38, P5357, DOI 10.1080/01431161.2017.1338785
   Makarau A, 2011, IEEE T GEOSCI REMOTE, V49, P2049, DOI 10.1109/TGRS.2010.2096515
   McFeely R, 2011, IET IMAGE PROCESS, V5, P233, DOI 10.1049/iet-ipr.2009.0198
   Murali S, 2019, MULTIMED TOOLS APPL, V78, P21167, DOI 10.1007/s11042-019-7435-5
   Murali S, 2013, CYBERN INF TECHNOL, V13, P95, DOI 10.2478/cait-2013-0009
   Polidorio AM, 2003, XVI BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P270, DOI 10.1109/SIBGRA.2003.1241019
   Shi WX, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-141
   Silva GF, 2018, ISPRS J PHOTOGRAMM, V140, P104, DOI 10.1016/j.isprsjprs.2017.11.005
   Su YF, 2010, IEEE T IMAGE PROCESS, V19, P2749, DOI 10.1109/TIP.2010.2050626
   Tian JD, 2016, PATTERN RECOGN, V51, P85, DOI 10.1016/j.patcog.2015.09.006
   Tian JD, 2009, IEEE T IMAGE PROCESS, V18, P2355, DOI 10.1109/TIP.2009.2026682
   Tsai VJD, 2006, IEEE T GEOSCI REMOTE, V44, P1661, DOI 10.1109/TGRS.2006.869980
   Wehrwein S, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P460, DOI 10.1109/3DV.2015.58
   Xing Chao, 2010, Proceedings 2010 Sixth International Conference on Natural Computation (ICNC 2010), P572, DOI 10.1109/ICNC.2010.5583419
   Zhu JJ, 2010, PROC CVPR IEEE, P223, DOI 10.1109/CVPR.2010.5540209
   Zhu X, 2015, NEUROCOMPUTING, V151, P252, DOI 10.1016/j.neucom.2014.09.045
NR 32
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 13025
EP 13043
DI 10.1007/s11042-022-11944-x
EA FEB 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000760059700007
DA 2024-07-18
ER

PT J
AU Wu, D
   Liu, S
   Sun, HF
   Zhang, LY
AF Wu, Di
   Liu, Sheng
   Sun, Hongfang
   Zhang, Lanyong
TI Short-message communication Lossy data compression algorithm for
   BeiDou-3 satellite information transmission
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BeiDou-3 satellites; Lossy data compression; Swinging door trend; Chaos
   multilayer particle swarm optimization
ID FREE ADAPTIVE-CONTROL; MODEL; NAVIGATION
AB BeiDou-3 satellites have short-message communication capabilities, which are not available in other navigation systems. However, the information transmission capacities of BeiDou-3 satellites are limited, which means that the string length of a single transmission is restricted. To improve transmission performance, this paper proposes a lossy data compression algorithm to transmit ship data. First, due to the large amount of measurement noise in the ship data and the difficulty of adaptively adjusting the compression threshold of the swinging door trend, a dynamic threshold adjustment strategy based on model-free adaptive control is designed. Furthermore, because the performance of the strategy depends on the initial value, chaos multilayer particle swarm optimization is employed to optimize the strategy and achieve better generalization and convergence performance. In addition, this paper introduces an experimental system and uses real ship motor vibration and electromagnetic radiation data to verify the compression algorithm. The experimental results indicate that the proposed algorithm displays reasonable performance. Presently, the system designed in this paper has been operating stably for more than six months.
C1 [Wu, Di; Liu, Sheng; Zhang, Lanyong] Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, 145 Nantong St, Harbin, Peoples R China.
   [Liu, Sheng; Sun, Hongfang; Zhang, Lanyong] HEU Qingdao Ship Sci & Technol Co Ltd, Qingdao 266426, Shandong, Peoples R China.
C3 Harbin Engineering University
RP Liu, S (corresponding author), Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, 145 Nantong St, Harbin, Peoples R China.; Liu, S (corresponding author), HEU Qingdao Ship Sci & Technol Co Ltd, Qingdao 266426, Shandong, Peoples R China.
EM 13704804113@163.com
OI WU, DI/0000-0003-0379-9703
FU National Natural Science Foundation of China subsidization project
   [51579047]; Natural Science Foundation of Heilongjiang Province
   [QC2017048]; Natural Science Foundation of Harbin [2016RAQXJ077];
   fundamental research funds for the central universities
FX This work was supported by the National Natural Science Foundation of
   China subsidization project (51579047), Natural Science Foundation of
   Heilongjiang Province (QC2017048), Natural Science Foundation of Harbin
   (2016RAQXJ077), and fundamental research funds for the central
   universities.
CR Birman R, 2020, MULTIMED TOOLS APPL, V79, P11699, DOI 10.1007/s11042-019-08572-3
   Brack A, 2020, GPS SOLUT, V25, DOI 10.1007/s10291-020-01043-5
   Chen SG, 2019, J NETW COMPUT APPL, V129, P37, DOI 10.1016/j.jnca.2019.01.002
   Coelho LD, 2009, CHAOS SOLITON FRACT, V41, P2001, DOI 10.1016/j.chaos.2008.08.004
   Cui MJ, 2019, IEEE T POWER SYST, V34, P454, DOI 10.1109/TPWRS.2018.2859323
   Cui Y, 2021, RENEW ENERG, V171, P542, DOI 10.1016/j.renene.2021.02.123
   Guo ZP, 2020, MULTIMED TOOLS APPL, V79, P14919, DOI 10.1007/s11042-019-08357-8
   Han S, 2016, MEASUREMENT, V88, P165, DOI 10.1016/j.measurement.2016.03.051
   He KF, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12244167
   Hou ZS, 2019, IEEE T AUTOMAT CONTR, V64, P4555, DOI 10.1109/TAC.2019.2894586
   Islam MA, 2018, IEEE T FUZZY SYST, V26, P1908, DOI 10.1109/TFUZZ.2017.2755002
   Ji SY, 2019, J GEODESY, V93, P1589, DOI 10.1007/s00190-019-01273-7
   Jie YM, 2019, MULTIMED TOOLS APPL, V78, P31137, DOI 10.1007/s11042-019-07947-w
   Kovelan P, 2021, MULTIMED TOOLS APPL, V80, P1273, DOI 10.1007/s11042-020-09358-8
   Li MW, 2021, NONLINEAR DYNAM, V103, P1167, DOI 10.1007/s11071-020-06111-6
   Li XM, 2020, IEEE ACCESS, V8, P49574, DOI 10.1109/ACCESS.2020.2979859
   Liao XPL, 2017, MULTIMED TOOLS APPL, V76, P21073, DOI 10.1007/s11042-016-4001-2
   Liu SD, 2020, IET CONTROL THEORY A, V14, P2084, DOI 10.1049/iet-cta.2020.0073
   Nie ZX, 2020, J GEODESY, V94, DOI 10.1007/s00190-020-01411-6
   Pan XQ, 2019, MULTIMED TOOLS APPL, V78, P29921, DOI 10.1007/s11042-018-6602-4
   Peng ZK, 2005, MECH SYST SIGNAL PR, V19, P974, DOI 10.1016/j.ymssp.2004.01.006
   Qu YY, 2020, J SENSORS, V2020, DOI 10.1155/2020/4575721
   Ravikumar K, 2020, MULTIMED TOOLS APPL, V79, P3929, DOI 10.1007/s11042-019-7583-7
   Sousa H, 2018, MEASUREMENT, V122, P630, DOI 10.1016/j.measurement.2017.10.042
   Suh W, 2017, MULTIMED TOOLS APPL, V76, P25253, DOI 10.1007/s11042-016-4318-x
   Tang ZJ, 2019, MULTIMED TOOLS APPL, V78, P9691, DOI 10.1007/s11042-018-6567-3
   Wang JS, 2018, ICIIP'18: PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION PROCESSING, P5, DOI 10.1145/3232116.3232118
   Wang W, 2015, J COMPUT THEOR NANOS, V12, P2556, DOI 10.1166/jctn.2015.4063
   Yang DP, 2021, CIRC SYST SIGNAL PR, V40, P5533, DOI 10.1007/s00034-021-01731-8
   Yu X, 2018, IFAC PAPERSONLINE, V51, P527, DOI 10.1016/j.ifacol.2018.06.149
   Zhang R, 2021, ADV SPACE RES, V67, P4011, DOI 10.1016/j.asr.2021.02.027
   Zhang ZH., 2017, CHINA MEAS TEST, V43, P104, DOI [10.11857/j.issn.1674-5124.2017.02.021, DOI 10.11857/J.ISSN.1674-5124.2017.02.021]
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
   Zhuang XQ, 2021, SENSOR MATER, V33, P715, DOI 10.18494/SAM.2021.3038
NR 34
TC 3
Z9 3
U1 5
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12833
EP 12855
DI 10.1007/s11042-022-12467-1
EA FEB 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758977800003
DA 2024-07-18
ER

PT J
AU Chmiel, W
   Derkacz, J
   Jedrusik, S
   Kadluczka, P
   Mikrut, Z
   Niemiec, M
   Palka, D
   Rogus, G
   Skalna, I
   Turek, M
AF Chmiel, Wojciech
   Derkacz, Jan
   Jedrusik, Stanislaw
   Kadluczka, Piotr
   Mikrut, Zbigniew
   Niemiec, Marcin
   Palka, Dariusz
   Rogus, Grzegorz
   Skalna, Iwona
   Turek, Michal
TI Workflow management system with smart procedures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE INRED; Workflow; Smart procedures; 3D device models; IoT; Image analysis
AB Supervision of repair and diagnostic works aimed at improving the safety of maintenance crews is one of the key objectives of the distributed INRED system. Working in a real industrial environment, the INRED system includes, among others, the so-called INRED-Workflow, which provides an infrastructure for process automation. Participants of the service processes, managed by the INRED-Workflow, are controlled at each stage of the performed service procedures, both by the system and other process participants, such as quality managers and technologists. All data collected from the service processes is stored in the System Knowledge Repository (SKR) for further processing by using advanced algorithms, and the so-called Smart Procedures merge services supplied by other INRED system modules. The applicability of workflow management systems in conjunction with image recognition and machine learning methods has not yet been thoroughly explored. The presented paper shows the innovative usage of such systems in the supervision of the repair and diagnostic works.
C1 [Chmiel, Wojciech; Derkacz, Jan; Jedrusik, Stanislaw; Kadluczka, Piotr; Mikrut, Zbigniew; Niemiec, Marcin; Palka, Dariusz; Rogus, Grzegorz; Skalna, Iwona; Turek, Michal] AGH Univ Sci & Technol, Krakow, Poland.
C3 AGH University of Krakow
RP Chmiel, W (corresponding author), AGH Univ Sci & Technol, Krakow, Poland.
EM wch@agh.edu.pl; derkacz@kt.agh.edu.pl; stj@agh.edu.pl; pkad@agh.edu.pl;
   zibi@agh.edu.pl; niemiec@kt.agh.edu.pl; dpalka@agh.edu.pl;
   rogus@agh.edu.pl; skalna@agh.edu.pl; mitu@agh.edu.pl
RI Niemiec, Marcin/D-1271-2011; Skalna, Iwona/A-6570-2017
OI Niemiec, Marcin/0000-0002-3909-9592; Skalna, Iwona/0000-0001-5707-7525;
   Chmiel, Wojciech/0000-0002-4773-9123; Mikrut,
   Zbigniew/0000-0002-2513-0501
FU European Regional Development Fund under the Innovative Economy
   Operational Programme [POIR.01.01.01-00-0170/17]
FX This work was supported by the European Regional Development Fund under
   the Innovative Economy Operational Programme, POIR.01.01.01-00-0170/17.
CR [Anonymous], 2018, MATLAB REL 2018A
   [Anonymous], 1994, WORKFLOW MANAGEMENT
   Belli Laura., 2019, Frontiers in ICT, V6, P17, DOI [10.3389/fict.2019.00017, DOI 10.3389/FICT.2019.00017]
   Bermudez-Edo M, 2018, AUTOMAT CONSTR, V88, P87, DOI 10.1016/j.autcon.2017.12.036
   Castaño JG, 2003, INDIN 2003: IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS, PROCEEDINGS, P65, DOI 10.1109/INDIN.2003.1300205
   Chaudhary S, 2018, PROCEDIA COMPUT SCI, V125, P336, DOI 10.1016/j.procs.2017.12.045
   Chmiel W., 2020, MULTIMEDIA COMMUNICA, V1284, P182, DOI [10.1007/978-3-030-59000-0_14, DOI 10.1007/978-3-030-59000-0_14]
   Dasani S, 2015, IFAC PAPERSONLINE, V48, P451, DOI 10.1016/j.ifacol.2015.09.009
   De Pace F., 2018, AM J COMPUTER SCI IN, V6, P17, DOI DOI 10.21767/2349-3917.100017
   Elmagarmid AD, 2012, WORKFLOW MANAGEMENT, P1
   Gore R.N., 2019, 2019 INT C DATA SCI, P1
   HARRIS SE, 1991, MIS QUART, V15, P333, DOI 10.2307/249645
   Haslgrübler M, 2017, IOT'17: PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON THE INTERNET OF THINGS, P157, DOI 10.1145/3131542.3131561
   Kammerer K, 2018, 2018 4TH INTERNATIONAL WORKSHOP ON REQUIREMENTS ENGINEERING FOR SELF-ADAPTIVE, COLLABORATIVE, AND CYBER PHYSICAL SYSTEMS (RESACS 2018), P44, DOI 10.1109/RESACS.2018.00013
   Kania P, 2016, REMONT ZASUW SREDNIO
   Kyjanek O., 2019, Proc. 36th Int. Symp. Autom. Robot. Constr. ISARC, V2019, P1223, DOI [10.22260/ISARC2019/0164, DOI 10.22260/ISARC2019/0164]
   Leta F.R., 2006, ABCM Symposium Series in Mechatronics, V2, P645
   Li B, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0339-x
   Louis J, 2018, AUTOMAT CONSTR, V94, P317, DOI 10.1016/j.autcon.2018.07.005
   Magliulo M, 2015, E-HEALTH BIOENG CONF
   Makantasis K, 2016, IEEE IMAGE PROC, P1609, DOI 10.1109/ICIP.2016.7532630
   Shrouf F, 2014, IN C IND ENG ENG MAN, P697, DOI 10.1109/IEEM.2014.7058728
   Song Z, 2020, P ASME 20 INT MECH E, V2, DOI [10.1115/IMECE2020-23149, DOI 10.1115/IMECE2020-23149]
   SWANSON EB, 1994, MANAGE SCI, V40, P1069, DOI 10.1287/mnsc.40.9.1069
   Teslya N, 2017, PROC CONF OPEN INNOV, P321, DOI 10.23919/FRUCT.2017.8250199
   Ustundag A, 2018, SPRINGER SER ADV MAN, P1, DOI 10.1007/978-3-319-57870-5
   van der Aalst WilM. P., 2003, J INTEGR DES PROCESS, V7, P49
   Xu Y, 2018, J CIV STRUCT HEALTH, V8, P91, DOI 10.1007/s13349-017-0261-4
   Yang YJ, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P311, DOI 10.1109/CIS2018.2018.00075
   Zimmermann A, 2016, COMM COM INF SC, V567, P308, DOI 10.1007/978-3-319-33313-7_24
NR 30
TC 0
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9505
EP 9526
DI 10.1007/s11042-021-11658-6
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000758308400001
OA hybrid
DA 2024-07-18
ER

PT J
AU Lin, HW
   Li, XQ
   Gao, ML
   Deng, KY
   Xu, YS
AF Lin, HongWei
   Li, Xiangqun
   Gao, Mingliang
   Deng, Keyan
   Xu, Yongsheng
TI Perceptual importance analysis-based rate control method for HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Rate control; Perceptual importance; Bit allocation; Parameter
   update
ID RATE-DISTORTION OPTIMIZATION; LEVEL RATE CONTROL; OPTIMAL BIT
   ALLOCATION; RATE CONTROL SCHEME; QUALITY ASSESSMENT; FRAME RATE; VIDEO;
   EFFICIENCY; ALGORITHM
AB High efficiency video coding (HEVC) has achieved high coding efficiency as the video coding standard. For rate control in HEVC, the conventional R-lambda scheme is based on mean absolute difference in allocating bits; however, the scheme does not fully utilize the perceptual importance variation to guide rate control, thus the subjective and objective quality of coded videos has room to improve. Therefore, in this paper, we propose a rate control scheme that considers perceptual importance. We first develop a perceptual importance analysis scheme to accurately abstract the spatial and temporal perceptual importance maps of video contents. The results of the analysis are then used to guide the bit allocation. Utilizing this model, a region-level bit allocation procedure is developed to maintain video quality balance. Subsequently, a largest coding unit (LCU)-level bit allocation scheme is designed to obtain the target bit of each LCU. To achieve a more accurate bitrate, an improved R-lambda model based on the Broyden-Fletcher-Goldfarb-Shanno model is utilized to update the R-lambda parameter. The experimental results showed that our method not only improved subjective and objective video quality with lower bitrate errors compared to the original RC in HEVC, but also outperformed state-of-the-art methods.
C1 [Lin, HongWei; Li, Xiangqun; Gao, Mingliang; Deng, Keyan; Xu, Yongsheng] Northwest Minzu Univ, Coll Elect Engn, 1 Xibeixincun, Lanzhou 730030, Peoples R China.
C3 Northwest Minzu University
RP Lin, HW (corresponding author), Northwest Minzu Univ, Coll Elect Engn, 1 Xibeixincun, Lanzhou 730030, Peoples R China.
EM linhongwei@xbmu.edu.cn; xiangqunli@xbmu.edu.cn;
   mingliang_Gao@xbmu.edu.cn; dky0603@163.com; 563359741@qq.com
RI ma, long/JHU-2289-2023; Xu, Yongsheng/GZA-6022-2022; wang,
   juan/IUO-6218-2023; Gao, Mingliang/AEK-9687-2022; Li,
   Yaqi/JEF-2795-2023; wang, yu/IUQ-6654-2023; Wang, Yiping/IZQ-2052-2023;
   Wang, Xuezhen/IUN-6267-2023; Zhao, Chunxia/KBB-4190-2024; ZHAO,
   S/IWV-4219-2023
OI Xu, Yongsheng/0000-0002-5064-9284; Lin, Hongwei/0000-0001-9080-0615
FU National Natural Science Foundation of China [62041109, 61861038];
   Fundamental Research Funds for the Central Universities [31920210073,
   31920180115, 31920190039]; Gansu Province Natural Sciences Fund
   [21JR1RA206]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 62041109, No. 61861038), the Fundamental Research Funds
   for the Central Universities (Grant No. 31920210073, 31920180115,
   31920190039) and Gansu Province Natural Sciences Fund (21JR1RA206).
CR An C, 2008, IEEE T IMAGE PROCESS, V17, P1605, DOI 10.1109/TIP.2008.2001046
   [Anonymous], 2013, PROC VIS COMMUN IMAG
   Bazen AM, 2002, IEEE T PATTERN ANAL, V24, P905, DOI 10.1109/TPAMI.2002.1017618
   Bross B, 2012, P JOINT COLL TEAM VI
   Chadha A., 2021, P IEEECVF C COMPUTER, P14852
   Chen ZZ, 2019, IEEE T IMAGE PROCESS, V28, P4541, DOI 10.1109/TIP.2019.2911180
   Choi H, 2012, I0094 JCTVC ITUTISOI
   Choi H.-J., 2012, SEMICONDUCTOR NANOST, P1, DOI DOI 10.1109/OCEANS-YEOSU.2012.6263424
   Dong JP, 2009, IEEE T CIRC SYST VID, V19, P1108, DOI 10.1109/TCSVT.2009.2020338
   Gao W, 2019, IEEE T BROADCAST, V65, P94, DOI 10.1109/TBC.2018.2865647
   Gao W, 2017, IEEE T IMAGE PROCESS, V26, P6074, DOI 10.1109/TIP.2017.2745099
   Gao YB, 2017, IEEE T IMAGE PROCESS, V26, P4457, DOI 10.1109/TIP.2017.2713598
   Girod Bernd, 1993, P207
   Gong YC, 2019, IEEE T CIRC SYST VID, V29, P156, DOI 10.1109/TCSVT.2017.2769703
   Guo HW, 2020, IEEE T BROADCAST, V66, P113, DOI 10.1109/TBC.2019.2917402
   ITU-R, 2000, ITU R RECOMMENDATION
   Lee B, 2014, IEEE T CIRC SYST VID, V24, P465, DOI 10.1109/TCSVT.2013.2276880
   Lee JS, 2012, IEEE J-STSP, V6, P684, DOI 10.1109/JSTSP.2012.2215006
   Li B, 2012, JCTVCK0103 ITUTISOIE
   Li B, 2013, JCTVCM0036 ITUTISOIE
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P3841, DOI 10.1109/TIP.2014.2336550
   Li D, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEM AND ARTIFICIAL INTELLIGENCE (ISAI 2016), P1, DOI [10.1109/ISAI.2016.59, 10.1109/ISAI.2016.0010]
   Li L, 2018, IEEE T CIRC SYST VID, V28, P130, DOI 10.1109/TCSVT.2016.2598672
   Li SX, 2017, IEEE T CIRC SYST VID, V27, P2409, DOI 10.1109/TCSVT.2016.2589878
   Li SX, 2015, SIGNAL PROCESS-IMAGE, V38, P127, DOI 10.1016/j.image.2015.04.011
   Li Y., 2014, MULTIMEDIA EXPO WORK, P1, DOI DOI 10.1109/ICMEW.2014.6890644
   Lin HW, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.4.043008
   Liu Y, 2007, IEEE T CIRC SYST VID, V17, P68, DOI 10.1109/TCSVT.2006.887081
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Meddeb M, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/ATSIP.2014.15
   Nami S, 2020, IEEE INT CONF MULTI
   Oh H, 2013, IEEE T IMAGE PROCESS, V22, P1524, DOI 10.1109/TIP.2012.2233485
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Ou YF, 2011, IEEE T CIRC SYST VID, V21, P286, DOI 10.1109/TCSVT.2010.2087833
   Park S, 2006, LECT NOTES COMPUT SC, V4261, P722
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   svn_HEVCSoftware, HM REF SOFTW 16 19
   Takeuchi M, 2018, PICT COD SYMP, P179, DOI 10.1109/PCS.2018.8456297
   Wang H, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351023
   Wang ZX, 2014, C IND ELECT APPL, P1169, DOI 10.1109/ICIEA.2014.6931342
   Wei HL, 2018, ASIAPAC SIGN INFO PR, P36, DOI 10.23919/APSIPA.2018.8659729
   Wei HL, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043009
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P688, DOI 10.1109/TCSVT.2003.815168
   Wiegand T., 2005, JVTO079
   Wong CW, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P361
   Yang Z., 2021, IEEE TRANSS PATTERN, P1
   Ye YY, 2018, MULTIMED TOOLS APPL, V77, P14557, DOI 10.1007/s11042-017-5047-5
   Zeng HQ, 2016, MULTIMED TOOLS APPL, V75, P10383, DOI 10.1007/s11042-015-2997-3
   Zhang W, 2018, IEEE T CIRC SYST VID, V28, P1462, DOI 10.1109/TCSVT.2017.2650910
   Zhou ML, 2019, IEEE T MULTIMEDIA, V21, P1921, DOI 10.1109/TMM.2019.2895281
   Zhu C, 2021, PROC IEEE INT PICTUR, P1
NR 52
TC 1
Z9 1
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12495
EP 12518
DI 10.1007/s11042-022-12146-1
EA FEB 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758308400009
DA 2024-07-18
ER

PT J
AU Mohite, NB
   Gonde, AB
AF Mohite, Nilima B.
   Gonde, Anil B.
TI Deep features based medical image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Abstraction levels; Content based image retrieval; Data augmentation;
   Deep learning; Deep features
ID LOCAL TERNARY PATTERNS; BINARY PATTERNS; NEURAL-NETWORKS; GRAY-SCALE;
   CLASSIFICATION; TEXTURE; MRI; SYSTEM
AB In this paper, deep convolutional neural network model is developed for classification and image retrieval purpose. Deep learning techniques obtained deep features from different abstraction levels represented using multiple hidden layers. This ultimately improves retrieval performance. We developed a framework based on multilayered convolutional neural network to represent medical images as deep features which are used for retrieval purpose. The proposed network's architecture is similar to Alexnet. The extracted deep features are used to calculate similarity index between the images using distance measures and based on similarity index, retrieval is done. By using a data augmentation technique the model achieved better retrieval accuracy. The model is evaluated on different medical databases using evaluation criteria like average retrieval precision and average retrieval recall and results are compared with the state of the art image retrieval techniques. From comparison retrieval results are significantly improved.
C1 [Mohite, Nilima B.; Gonde, Anil B.] SGGSIET, Dept Elect & Telecommun Engn, Nanded, Maharashtra, India.
C3 Shri Guru Gobind Singhji Institute of Engineering & Technology
RP Mohite, NB (corresponding author), SGGSIET, Dept Elect & Telecommun Engn, Nanded, Maharashtra, India.
EM nilima.mohite7@gmail.com
CR Alzu'bi A, 2017, NEUROCOMPUTING, V249, P95, DOI 10.1016/j.neucom.2017.03.072
   Baby CG, 2013, INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, IMAGE PROCESSING AND PATTERN RECOGNITION (ICSIPR 2013), P195, DOI 10.1109/ICSIPR.2013.6497987
   Bai C, 2018, NEUROCOMPUTING, V303, P60, DOI 10.1016/j.neucom.2018.04.034
   Dubey SR, 2016, IEEE J BIOMED HEALTH, V20, P1139, DOI 10.1109/JBHI.2015.2437396
   Galshetwar GM, 2017, PROCEDIA COMPUT SCI, V115, P440, DOI 10.1016/j.procs.2017.09.103
   Gao Z, 2014, 1 WORKSH PATT REC TE
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Han DM, 2018, EXPERT SYST APPL, V95, P43, DOI 10.1016/j.eswa.2017.11.028
   Kuruvilla J, 2014, COMPUT METH PROG BIO, V113, P202, DOI 10.1016/j.cmpb.2013.10.011
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu HL, 2017, PROCEDIA COMPUT SCI, V107, P749, DOI 10.1016/j.procs.2017.03.159
   Marcus DS, 2007, J COGNITIVE NEUROSCI, V19, P1498, DOI 10.1162/jocn.2007.19.9.1498
   Mohite N, 2019, INT J MULTIMEDIA INF, P8115
   Mu MR, 2011, NEUROCOMPUTING, V74, P3351, DOI 10.1016/j.neucom.2011.05.026
   Murala S, 2015, NEUROCOMPUTING, V149, P1502, DOI 10.1016/j.neucom.2014.08.042
   Murala S, 2014, IEEE J BIOMED HEALTH, V18, P929, DOI 10.1109/JBHI.2013.2288522
   Murala S, 2014, SIGNAL PROCESS-IMAGE, V29, P400, DOI 10.1016/j.image.2013.12.002
   Murala S, 2013, NEUROCOMPUTING, V119, P399, DOI 10.1016/j.neucom.2013.03.018
   Murala S, 2012, J MED SYST, V36, P2865, DOI 10.1007/s10916-011-9764-4
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pang SC, 2018, COMPUT METH PROG BIO, V158, P53, DOI 10.1016/j.cmpb.2018.02.003
   Qayyum A, 2017, NEUROCOMPUTING, V266, P8, DOI 10.1016/j.neucom.2017.05.025
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Senechal T, 2012, IEEE T SYST MAN CY B, V42, P993, DOI 10.1109/TSMCB.2012.2193567
   Shinde AA, 2017, INT J MULTIMED INF R, V6, P281, DOI 10.1007/s13735-017-0132-0
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tzelepi M, 2018, NEUROCOMPUTING, V275, P2467, DOI 10.1016/j.neucom.2017.11.022
   Vipparthi SK, 2016, IET COMPUT VIS, V10, P182, DOI 10.1049/iet-cvi.2015.0035
   Vipparthi SK, 2015, INT J SIGNAL IMAGING, V8, P137, DOI 10.1504/IJSISE.2015.070485
   Vipparthi SK, 2014, EXPERT SYST APPL, V41, P8016, DOI 10.1016/j.eswa.2014.07.001
   Vogado LHS, 2018, ENG APPL ARTIF INTEL, V72, P415, DOI 10.1016/j.engappai.2018.04.024
   Yang SF, 2012, IEEE T SYST MAN CY B, V42, P980, DOI 10.1109/TSMCB.2012.2192269
   Yao CH, 2003, PATTERN RECOGN, V36, P913, DOI 10.1016/S0031-3203(02)00124-3
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang M, 2014, J VIS COMMUN IMAGE R, V25, P1574, DOI 10.1016/j.jvcir.2014.06.016
NR 36
TC 7
Z9 8
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11379
EP 11392
DI 10.1007/s11042-022-12085-x
EA FEB 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757200200006
DA 2024-07-18
ER

PT J
AU Mool, A
   Panda, J
   Sharma, K
AF Mool, Akshay
   Panda, J.
   Sharma, Kapil
TI Optimizable face detection and tracking model with occlusion resolution
   for high quality videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; Feature tracking; Interpolation
ID INTERPOLATION; SHAPE
AB Recent state-of-the-art Face Detection algorithms in the field of Computer Vision focus greatly on real-time processing and results. The applications using these algorithms deal with low quality video feeds having less Pixels Per Inch (ppi) and/or low frame rate. The algorithms perform well with such video feeds, but their performance deteriorates towards high quality, high data-per-frame videos. Such video files mostly exist in offline mode, that could be used for post processing by the Computer Vision applications. This paper focuses on developing such an algorithm that gives faster results on high quality videos, at par with the algorithms working on live low quality video feeds. The proposed algorithm uses Convolutional-MTCNN as base algorithm, and speeds it up for high definition videos. This paper also presents a novel solution to the problem of occlusion and detecting partial or fully hidden faces in the videos. This is achieved by using probabilistic approaches, given that the face has been identified in first few frames, to give the algorithm an estimate of where the face should be in the occluded region.
C1 [Mool, Akshay; Sharma, Kapil] Delhi Technol Univ, Dept Informat Technol, Main Bawana Rd, Delhi 110042, India.
   [Panda, J.] Delhi Technol Univ, Dept Elect & Commun Engn, Main Bawana Rd, Delhi 110042, India.
C3 Delhi Technological University; Delhi Technological University
RP Mool, A (corresponding author), Delhi Technol Univ, Dept Informat Technol, Main Bawana Rd, Delhi 110042, India.
EM akshaymool_phd2k17@dtu.ac.in
RI Mool, Akshay/JZU-0001-2024
CR Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015
   Chrysos GG, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P954, DOI 10.1109/ICCVW.2015.126
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Nguyen DT, 2019, IEEE T VLSI SYST, V27, P1861, DOI 10.1109/TVLSI.2019.2905242
   Ismail N, 2009, PROCEEDINGS OF THE 8TH WSEAS INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, MAN-MACHINE SYSTEMS AND CYBERNETICS (CIMMACS '09), P30
   Jia, 2017, POLYNOMIAL INTERPOLA
   Li JC, 2018, IEEE-CAA J AUTOMATIC, V5, P1136, DOI 10.1109/JAS.2017.7510442
   Luo JP, 2020, PATTERN RECOGN LETT, V133, P180, DOI 10.1016/j.patrec.2020.03.002
   Meijering E, 2002, P IEEE, V90, P319, DOI 10.1109/5.993400
   Pairo W, 2019, J INTELL ROBOT SYST, V95, P99, DOI 10.1007/s10846-018-0840-6
   Raja Rohit, 2018, International Journal of Information and Computer Security, V10, P303
   Raja R., 2015, Assoc. Adv. Model. Simul. Tech. Enterp. Adv. B, V58, P14
   Ranftl A, 2017, IET BIOMETRICS, V6, P468, DOI 10.1049/iet-bmt.2016.0202
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shen J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1003, DOI 10.1109/ICCVW.2015.132
   Singh S, 2020, FACE RECOGNITION USI, V8, P6437
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yang B., 2014, PROC IEEE INT JOINT, P1
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yu BS, 2019, IEEE T IMAGE PROCESS, V28, P2490, DOI 10.1109/TIP.2018.2886790
   Zeng D, 2019, PATTERN RECOGN LETT, V119, P180, DOI 10.1016/j.patrec.2018.05.024
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 25
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10391
EP 10406
DI 10.1007/s11042-022-11958-5
EA FEB 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000755422300005
DA 2024-07-18
ER

PT J
AU Agarwal, B
AF Agarwal, Basant
TI Financial sentiment analysis model utilizing knowledge-base and
   domain-specific representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Financial sentiment analysis; Domain-specific words representation;
   Unseen words; Out of vocabulary words; Deep learning
ID MARKET PREDICTION; NEWS
AB Financial sentiment analysis is a very challenging problem because the market is influenced by various factors, such as company-specific/political news, sentiment/opinions of users, and other regional financial market. Good news can drive the market to grow positively, while negative news can drag the market downwards. For this reason, it is crucial to understand the impacts of news and social media on the stock market trends. Motivated by this, this paper focuses on developing an effective and efficient company-specific financial sentiment analysis model which can detect the trends of a company's stock price. More specifically, we develop a novel neural network model that transforms pretrained general word embeddings into domain-specific embeddings. In addition, we use a knowledge-base to enrich the training vocabulary, and thus extend the domain-specific embedding space. The main challenge for natural language processing (NLP) applications is to learn the representation for the rare and unseen words. Another challenge for financial sentiment analysis models addressed in this paper is to deal with words that change their polarities depending upon the domain in which they are used. We thoroughly evaluate the performance of the proposed model on a benchmark dataset of SemEval-2017 shared task on financial sentiment analysis. The experimental results show that the proposed model delivers state-of-the-art performance when applied on Twitter and news headlines datasets, thus demonstrating its feasibility and effectiveness.
C1 [Agarwal, Basant] Indian Inst Informat Technol Kota IIIT Kota, Dept Comp Sci & Engn, MNIT Campus, Jaipur, Rajasthan, India.
RP Agarwal, B (corresponding author), Indian Inst Informat Technol Kota IIIT Kota, Dept Comp Sci & Engn, MNIT Campus, Jaipur, Rajasthan, India.
EM basant.cse@iiitkota.ac.in
RI Agarwal, Basant/HCH-7681-2022
CR Akhtar M. S., 2017, P 2017 C EMP METH NA, P540, DOI DOI 10.18653/V1/D17-1057
   Bahdanau D, LEARNING COMPUTE WOR
   Cabanski T., 2017, Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017) (, P832
   Chenlo JM, 2014, INFORM SCIENCES, V280, P275, DOI 10.1016/j.ins.2014.05.009
   Cortis K., 2017, P 11 INT WORKSHOP SE, P519
   Deborah A.S., 2017, Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017) (, P823, DOI DOI 10.18653/V1/S17-2139.URL
   Geethapriya A, 2021, INFORM SYST FRONT, V23, P791, DOI 10.1007/s10796-020-10094-5
   Ghosal D., 2017, Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017) (, P899
   Gombar P., 2017, P 6 WORKSH BALT SLAV, P54
   Hamilton William L, 2016, Proc Conf Empir Methods Nat Lang Process, V2016, P595, DOI 10.18653/v1/D16-1057
   Han, 2021, P EMPIRICAL METHODS
   Jaech A, 2016, INTERSPEECH, P690, DOI 10.21437/Interspeech.2016-1598
   Jiang Mengxiao, 2017, P SEMEVAL 2017, P888, DOI DOI 10.18653/V1/S17-2152
   Kar S., 2017, Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017) (, P877
   Kim Y., 2014, P 2014 C EMP METH NA, P1746, DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/D14-1181]
   Kumar A., 2017, Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017) (, P894
   Kumar A, 2019, MULTIMED TOOLS APPL, V78, P24103, DOI 10.1007/s11042-019-7390-1
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Madhyastha, 2017, P 1 WORKSH REPR LEAR, P100
   Mansar Youness., 2017, Proceedings of the 11th International Workshop on Semantic Evaluations (SemEval-2017), P817, DOI DOI 10.18653/V1/S17-2138
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Moore Andrew., 2017, Proceedings of the 11th International Workshop on Semantic Evaluations (SemEval-2017), P581
   Nandwani P, 2021, SOC NETW ANAL MIN, V11, DOI 10.1007/s13278-021-00776-6
   Nardo M, 2016, J ECON SURV, V30, P356, DOI 10.1111/joes.12102
   Nasim Z., 2017, P 11 INT WORKSH SEM, P827, DOI [10.18653/v1/S17-2140, DOI 10.18653/V1/S17-2140]
   Nassirtoussi AK, 2015, EXPERT SYST APPL, V42, P306, DOI 10.1016/j.eswa.2014.08.004
   Nassirtoussi AK, 2014, EXPERT SYST APPL, V41, P7653, DOI 10.1016/j.eswa.2014.06.009
   Bach NX, 2016, PROCEEDINGS OF THE SEVENTH SYMPOSIUM ON INFORMATION AND COMMUNICATION TECHNOLOGY (SOICT 2016), P159, DOI 10.1145/3011077.3011104
   Nuij W, 2014, IEEE T KNOWL DATA EN, V26, P823, DOI 10.1109/TKDE.2013.133
   O'Hare N., 2009, Proceeding of the 1st International CIKM Workshop on Topic-Sentiment Analysis for Mass Opinion Mining, TSA '09. New York, NY, P9
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Pilehvar M. T., 2017, Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, V2, P388
   Pilehvar M. T., 2016, P 15 WORKSH BIOM NAT, P12, DOI [10.18653/v1/W16-2902, DOI 10.18653/V1/W16-2902]
   Ravi K, 2017, APPL SOFT COMPUT, V60, P786, DOI 10.1016/j.asoc.2017.05.028
   Ren YF, 2016, INFORM SCIENCES, V369, P188, DOI 10.1016/j.ins.2016.06.040
   Rotim Leon, 2017, P 11 INT WORKSHOP SE, P866, DOI DOI 10.18653/V1/S17-2148
   Roy A, LEARNING DOMAIN SPEC
   Si J., 2013, Short Papers, V2, P24
   Sohangir S, J BIG DATA, V5
   Tafforeau J, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1408
   Tsai MF, 2016, ACM TRANS MANAG INF, V7, DOI 10.1145/2948072
   Van de Kauter M, 2015, EXPERT SYST APPL, V42, P4999, DOI 10.1016/j.eswa.2015.02.007
   Wang J, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2915
   Zipf GK, 1950, J CLIN PSYCHOL, V6, P306
NR 45
TC 4
Z9 5
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8899
EP 8920
DI 10.1007/s11042-022-12181-y
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000756497800004
DA 2024-07-18
ER

PT J
AU Moitra, D
   Mandal, RK
AF Moitra, Dipanjan
   Mandal, Rakesh Kr
TI Classification of malignant tumors by a non-sequential recurrent
   ensemble of deep neural network model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Malignant; Tumor; Classification; Deep learning; Staging
ID CANCER; FEATURES
AB Many significant efforts have so far been made to classify malignant tumors by using various machine learning methods. Most of the studies have considered a particular tumor genre categorized according to its originating organ. This has enriched the domain-specific knowledge of malignant tumor prediction, we are devoid of an efficient model that may predict the stages of tumors irrespective of their origin. Thus, there is ample opportunity to study if a heterogeneous collection of tumor images can be classified according to their respective stages. The present research work has prepared a heterogeneous tumor dataset comprising eight different datasets from The Cancer Imaging Archives and classified them according to their respective stages, as suggested by the American Joint Committee on Cancer. The proposed model has been used for classifying 717 subjects comprising different imaging modalities and varied Tumor-Node-Metastasis stages. A new non-sequential deep hybrid model ensemble has been developed by exploiting branched and re-injected layers, followed by bidirectional recurrent layers to classify tumor images. Results have been compared with standard sequential deep learning models and notable recent studies. The training and validation accuracy along with the ROC-AUC scores have been found satisfactory over the existing models. No model or method in the literature could ever classify such a diversified mix of tumor images with such high accuracy. The proposed model may help radiologists by acting as an auxiliary decision support system and speed up the tumor diagnosis process.
C1 [Moitra, Dipanjan; Mandal, Rakesh Kr] Univ North Bengal, Siliguri, India.
C3 University of North Bengal
RP Moitra, D (corresponding author), Univ North Bengal, Siliguri, India.
EM tataijal@gmail.com; tataijal@yahoo.in
RI Moitra, Dipanjan/Y-3143-2019
CR Alghamdi A, 2024, MULTIMED TOOLS APPL, V83, P14913, DOI 10.1007/s11042-020-08769-x
   Alghamdi AS, 2020, APPL ACOUST, V164, DOI 10.1016/j.apacoust.2020.107279
   Ali AM, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122422
   Alom MZ, 2020, NEURAL COMPUT APPL, V32, P279, DOI 10.1007/s00521-018-3627-6
   [Anonymous], 2018, CLASSIFYING MAMMOGRA
   Bektas CT, 2019, EUR RADIOL, V29, P1153, DOI 10.1007/s00330-018-5698-2
   Ben-Cohen A, 2018, NEUROCOMPUTING, V275, P1585, DOI 10.1016/j.neucom.2017.10.001
   Bharti P, 2018, ULTRASONIC IMAGING, V40, P357, DOI 10.1177/0161734618787447
   Bhatia S, 2019, ADV INTELL SYST COMP, V817, P699, DOI 10.1007/978-981-13-1595-4_55
   Blagus R, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-106
   Cha KH, 2019, ACAD RADIOL, V26, P1137, DOI 10.1016/j.acra.2018.10.010
   Chollet F., 2018, Towards Data Science
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Das A, 2019, COGN SYST RES, V54, P165, DOI 10.1016/j.cogsys.2018.12.009
   Dhungel N, 2017, MED IMAGE ANAL, V37, P114, DOI 10.1016/j.media.2017.01.009
   Diamant A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39206-1
   Du C, 2020, PATTERN RECOGN LETT, V129, P108, DOI 10.1016/j.patrec.2019.11.015
   Edge SB, 2010, ANN SURG ONCOL, V17, P1471, DOI 10.1245/s10434-010-0985-4
   Eminaga O, 2018, JCO CLIN CANCER INFO, V2, DOI 10.1200/CCI.17.00126
   Farihah A G, 2018, Med J Malaysia, V73, P9
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Gupta P, 2018, 2018 INT C SMART CIT, P1, DOI [10.1109/ICSCET.2018.8537291, DOI 10.1109/ICSCET.2018.8537291]
   Halicek M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50313-x
   Halicek M, 2017, J BIOMED OPT, V22, DOI 10.1117/1.JBO.22.6.060503
   Han S, 2019, J DIGIT IMAGING, V32, P638, DOI 10.1007/s10278-019-00230-2
   Ikeda A., 2018, EUR UROL SUPPL, V17, pe1230
   Ing N, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-13196-4
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   JOHNSON RW, 1979, P APL79, P24
   Kocak B, 2019, AM J ROENTGENOL, V212, pW55, DOI 10.2214/AJR.18.20443
   Li SS, 2018, FRONT ONCOL, V8, DOI 10.3389/fonc.2018.00648
   Lin P, 2020, EUR RADIOL, V30, P547, DOI 10.1007/s00330-019-06371-w
   Liu XL, 2018, PATTERN RECOGN, V77, P262, DOI 10.1016/j.patcog.2017.12.022
   Lo TY, 2018, ICRAI 2018: PROCEEDINGS OF 2018 4TH INTERNATIONAL CONFERENCE ON ROBOTICS AND ARTIFICIAL INTELLIGENCE -, P18, DOI 10.1145/3297097.3297108
   Ma L, 2019, VIS COMPUT IND BIOME, V2, DOI 10.1186/s42492-019-0023-8
   Ma L, 2017, PROC SPIE, V10137, DOI 10.1117/12.2255562
   Malek M, 2019, EUR J RADIOL, V110, P203, DOI 10.1016/j.ejrad.2018.11.009
   Mao KM., 2018, COMPLEXITY, V2018, P1
   Moitra D., 2017, INDIAN J COMPUT SCI, V8, P575
   Moitra D., 2017, INT J COMPUT SCI ENG, V5, P121
   Moitra D., 2019, CLASSIFICATION MALIG
   Moitra D, 2018, INT J ADV RES COMPUT, V9, P129, DOI [10.26483/ijarcs.v9i3.6010, DOI 10.26483/IJARCS.V9I3.6010]
   Moitra D, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113564
   Moitra D, 2020, J DIGIT IMAGING, V33, P895, DOI 10.1007/s10278-020-00337-x
   Moitra D, 2019, NETW MODEL ANAL HLTH, V8, DOI 10.1007/s13721-019-0204-6
   Moitra D, 2019, HEALTH INF SCI SYST, V7, DOI 10.1007/s13755-019-0077-1
   Moitra Dipanjan, 2015, INT J COMPUTER SCI E, V03, P157
   Munir K, 2019, CANCERS, V11, DOI 10.3390/cancers11091235
   Noreen N, 2020, IEEE ACCESS, V8, P55135, DOI 10.1109/ACCESS.2020.2978629
   P B Shanthi, 2019, Asian Pac J Cancer Prev, V20, P3447, DOI 10.31557/APJCP.2019.20.11.3447
   Park VY, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-54434-1
   Romero Francisco Perdigon, 2019, 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019), P1243, DOI 10.1109/ISBI.2019.8759257
   Sato M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-43336-x
   Sedik A, 2020, VIRUSES-BASEL, V12, DOI 10.3390/v12070769
   Shen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48995-4
   Shkolyar E, 2019, EUR UROL, V76, P714, DOI 10.1016/j.eururo.2019.08.032
   Sun H, 2020, IEEE J BIOMED HEALTH, V24, P1664, DOI 10.1109/JBHI.2019.2944977
   Tabibu S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46718-3
   Tian K, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222641
   Torab-Miandoab A., 2017, INT C CURR RES COMP, P133
   Vaka AR, 2020, ICT EXPRESS, V6, P320, DOI 10.1016/j.icte.2020.04.009
   Vivanti R, 2017, INT J COMPUT ASS RAD, V12, P1945, DOI 10.1007/s11548-017-1660-z
   Wang XQ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010194
   Wang YJ, 2019, ANN TRANSL MED, V7, DOI 10.21037/atm.2019.08.54
   Wu Q, 2019, ENERGIES, V12, DOI 10.3390/en12081572
   Xu XP, 2017, ABDOM RADIOL, V42, P1896, DOI 10.1007/s00261-017-1079-6
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yao HS, 2020, ADV INTELL SYST COMP, V1069, P276, DOI 10.1007/978-3-030-32520-6_22
   You Y, 2018, PROC INT CONF PARAL, DOI 10.1145/3225058.3225069
   Yu Z, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P338, DOI 10.1109/ASRU.2015.7404814
   Zebin T, 2021, APPL INTELL, V51, P1010, DOI 10.1007/s10489-020-01867-1
   Zhang B, 2019, THYROID, V29, P858, DOI 10.1089/thy.2018.0380
   Zheng JJ, 2019, CANCER-AM CANCER SOC, V125, P4388, DOI 10.1002/cncr.32490
   Zhou LL, 2019, TRANSL ONCOL, V12, P292, DOI 10.1016/j.tranon.2018.10.012
NR 74
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 FEB 14
PY 2022
DI 10.1007/s11042-022-12229-z
EA FEB 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZA9TO
UT WOS:000756497800026
PM 35194379
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Yadav, KS
   Monsley, KA
   Laskar, RH
AF Yadav, Kuldeep Singh
   Monsley, Anish K.
   Laskar, Rabul Hussain
TI Gesture objects detection and tracking for virtual text entry keyboard
   interface
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture recognition system; Bare-hand detection; Red-color marker
   detection; AlexNet; Detection and tracking algorithm
ID CONVOLUTIONAL NEURAL-NETWORKS; FILTER-BASED TRACKING; HAND DETECTION;
   RECOGNITION
AB Detection and tracking of the gesturing object is a vital stage in the field of dynamic gesture recognition. It becomes more challenging in the practical environment due to the variation in illumination, occlusion, pose, rotation, speed, and presence of impostors. To overcome these complexities and provides ease to the user, we designed algorithms to (i) detect and track the gesture objects (red-color marker, bare-hand); (ii) recognize the gesture. To detect the red-color marker, a region of interest-based detection model is proposed by utilizing movement and color information. This model achieves similar to 13% improvement over the existing baseline models. For bare hand detection, a three-degree-information algorithm is proposed by incorporating region of interest (color, movement) and AlexNet. An improvement of 14% is achieved over the baseline models. To track the bare hand, a detection and tracking algorithm is proposed by utilizing AlexNet and point-tracker. This model achieves similar to 10% improvement over the baseline models. Evaluation of the proposed models for detection and tracking is performed on NITS hand gesture (I-IV. VII), Oxford hand. OUHands. EgoHands databases. To recognize gesture trajectories, the deep convolutional neural network is utilized. This model is able to achieve a relative improvement of similar to 7% over the baseline recognition models. To evaluate the performance of the recognition model, the NITS hand gesture (I-IV, VII), MNIST, and SVHN databases are used. In addition, we introduce the NITS-Net database consisting of bare-hand, non-bare-hand images.
C1 [Yadav, Kuldeep Singh; Monsley, Anish K.; Laskar, Rabul Hussain] NIT Silchar, Elect & Commun Engn, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Yadav, KS (corresponding author), NIT Silchar, Elect & Commun Engn, Silchar 788010, Assam, India.
EM kuldeeptheyadav@gmail.com
RI KIRUPAKARAN, ANISH MONSLEY/AFT-0411-2022; Laskar, Rabul
   Hussain/AFU-7180-2022; Yadav, Kuldeep Singh/JKJ-1356-2023
OI KIRUPAKARAN, ANISH MONSLEY/0000-0002-4927-3785; Laskar, Rabul
   Hussain/0000-0003-3988-394X; Yadav, Kuldeep Singh/0000-0002-9761-9023
FU SERB [IMPRINT - IMP/2018/000098, SERB/F/10220/2018-19]
FX This research work is funded by the SERB IMPRINT - IMP/2018/000098
   project [sanction order SERB/F/10220/2018-19] We thank the department of
   electronics and communication engineering of NITS for providing us with
   the necessary facilities to carry out this work. The authors thank the
   anonymous reviewers whose valuable comments greatly improved the
   article.
CR Abavisani M, 2019, PROC CVPR IEEE, P1165, DOI 10.1109/CVPR.2019.00126
   CHAN YT, 1979, IEEE T AERO ELEC SYS, V15, P237, DOI 10.1109/TAES.1979.308710
   Duan Yongyong, 2020, 2020 International Conference on Computer Vision, Image and Deep Learning (CVIDL), P44, DOI 10.1109/CVIDL51233.2020.00016
   Farahi F, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115751
   Gao Q, 2019, IEEE T IND ELECTRON, V66, P9663, DOI 10.1109/TIE.2019.2898624
   Han Y, 2020, INT C CONTR AUTOMAT, P184, DOI [10.23919/iccas50221.2020.9268239, 10.23919/ICCAS50221.2020.9268239]
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Le THN, 2017, IEEE COMPUT SOC CONF, P1203, DOI 10.1109/CVPRW.2017.159
   Li C, 2013, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2013.458
   Li SE, 2018, MECH SYST SIGNAL PR, V98, P173, DOI 10.1016/j.ymssp.2017.04.041
   McBride TJ, 2019, 2019 SOUTHERN AFRICAN UNIVERSITIES POWER ENGINEERING CONFERENCE/ROBOTICS AND MECHATRONICS/PATTERN RECOGNITION ASSOCIATION OF SOUTH AFRICA (SAUPEC/ROBMECH/PRASA), P211, DOI [10.1109/RoboMech.2019.8704839, 10.1109/robomech.2019.8704839]
   Misra S, 2020, 11 INT C COMP COMM N
   Misra S., 2021, INT J COMPUTATIONAL, V11, P175, DOI 10.1504/ijcvr.2021.113399
   Misra S, 2019, MULTIMED TOOLS APPL, V78, P34927, DOI 10.1007/s11042-019-08105-y
   Misra S, 2019, J AMB INTEL HUM COMP, V10, P4901, DOI 10.1007/s12652-019-01189-2
   Misra S, 2019, IET IMAGE PROCESS, V13, P1460, DOI 10.1049/iet-ipr.2018.5978
   Misra S, 2018, NEURAL COMPUT APPL, V29, P117, DOI 10.1007/s00521-017-2838-6
   Monsley KA, 2021, IET IMAGE PROCESS, V15, P1166, DOI 10.1049/ipr2.12095
   Mukherjee S, 2019, EXPERT SYST APPL, V136, P217, DOI 10.1016/j.eswa.2019.06.034
   Nayak T., 2020, GLOB J COMP SCI TECH
   Ong EJ, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P889
   Ozcan T, 2019, NEURAL COMPUT APPL, V31, P8955, DOI 10.1007/s00521-019-04427-y
   Roy A, 2017, IET IMAGE PROCESS, V11, P352, DOI 10.1049/iet-ipr.2016.0320
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saboo S, 2022, MULTIMEDIA SYST, V28, P183, DOI 10.1007/s00530-021-00811-8
   Saboo S, 2021, MULTIMED TOOLS APPL, V80, P20579, DOI 10.1007/s11042-021-10669-7
   Schlemper J, 2018, IEEE T MED IMAGING, V37, P491, DOI 10.1109/TMI.2017.2760978
   Sigal L, 2004, IEEE T PATTERN ANAL, V26, P862, DOI 10.1109/TPAMI.2004.35
   Singha J, 2017, MULTIMEDIA SYST, V23, P499, DOI 10.1007/s00530-016-0510-0
   Singha J, 2018, NEURAL COMPUT APPL, V29, P1129, DOI 10.1007/s00521-016-2525-z
   Singha J, 2016, NEUROCOMPUTING, V208, P269, DOI 10.1016/j.neucom.2016.05.049
   Skaria S, 2019, IEEE SENS J, V19, P3041, DOI 10.1109/JSEN.2019.2892073
   Yadav KS, 2020, MULTIMED TOOLS APPL, V79, P13089, DOI 10.1007/s11042-019-08443-x
   Yanay T, 2020, PERVASIVE MOB COMPUT, V66, DOI 10.1016/j.pmcj.2020.101183
   Zhang M., 2020, AMIA ANN S P AMIA S, P1373
NR 35
TC 7
Z9 7
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5317
EP 5342
DI 10.1007/s11042-021-11874-0
EA JAN 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000749055500009
DA 2024-07-18
ER

PT J
AU Tsai, MF
   Huang, SH
AF Tsai, Ming-Fong
   Huang, Sheng-Hong
TI Enhancing accuracy of human action Recognition System using Skeleton
   Point correction method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Skeleton key point correction
ID POSTURE
AB In view of the fact that the study of human action recognition systems is a very important research field in the field of artificial intelligence, the use of a continuous image of the human skeleton's key points for deep learning action training and identification is the current development focus. However, it is limited by the image shooting angle and the motion attitude transformation of the visual masking problem, resulting in the misjudgment of human skeleton key points affecting the accuracy of motion training and identification. This research paper puts forward a human body motion recognition system that uses a human skeleton key point correction method to improve the accuracy of human body motion recognition. The basic correction algorithm of a human skeleton key candidate point is based on the principle of the symmetrical characteristics of the human skeleton key points, and the human skeleton key candidate point advanced correction algorithm is based on using the human body shield map as the limit of the human skeleton key point range. This research paper proposes a performance comparison of this system and the relevant human action identification systems ST-GCN, 2 S-AGCN, GCN-NAS, with Gaussian filter for the ST-GCN, GCN-NAS and 2 S-AGCN. Human motion recognition accuracy is increased by at least 68%, 40%, 56%, 68%, 50% and 46%, respectively, for the experimental data.
C1 [Tsai, Ming-Fong; Huang, Sheng-Hong] Natl United Univ, Dept Elect Engn, Miaoli, Taiwan.
C3 National United University
RP Tsai, MF (corresponding author), Natl United Univ, Dept Elect Engn, Miaoli, Taiwan.
EM mingfongtsai@gmail.com
OI Tsai, Ming-Fong/0000-0001-9046-2513
FU Ministry of Science and Technology of Taiwan [MOST
   109-2622-E-239-002-CC3]
FX We thank the Ministry of Science and Technology of Taiwan for supports
   of this project under grant number MOST 109-2622-E-239-002-CC3 and
   Industrial Technology Research Institute. We thank co-authors and
   reviewers for their valuable opinions.
CR Chen JY, 2017, AUTOMAT CONSTR, V77, P67, DOI 10.1016/j.autcon.2017.01.020
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Huang J, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16111825
   Jain A, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENGINEERING AND APPLICATIONS (ICACEA), P760, DOI 10.1109/ICACEA.2015.7164804
   McNally W, 2019, IEEE COMPUT SOC CONF, P2553, DOI 10.1109/CVPRW.2019.00311
   Osokin D, 2019, ICPRAM: PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P744, DOI 10.5220/0007555407440748
   Papandreou G, 2018, LECT NOTES COMPUT SC, V11218, P282, DOI 10.1007/978-3-030-01264-9_17
   Peng WT, 2020, IEEE INT C ELECTR TA, DOI 10.1109/icce-taiwan49838.2020.9258245
   Pisharady PK, 2015, COMPUT VIS IMAGE UND, V141, P152, DOI 10.1016/j.cviu.2015.08.004
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Tsai MF, 2021, IEEE ACCESS, V9, P13870, DOI 10.1109/ACCESS.2021.3052246
   Tsai MF, 2020, IEEE ACCESS, V8, P220848, DOI 10.1109/ACCESS.2020.3042539
   Wang J, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P3432, DOI 10.1109/BigData.2016.7841004
   Yan C, 2016, IET COMPUT VIS, V10, P103, DOI 10.1049/iet-cvi.2015.0175
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yao L., 2015, proceedings of the 12th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services on 12th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services, P120
NR 16
TC 8
Z9 8
U1 2
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7439
EP 7459
DI 10.1007/s11042-022-12000-4
EA JAN 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000748678300006
DA 2024-07-18
ER

PT J
AU Xu, WT
   Nong, G
AF Xu, Wentao
   Nong, Ge
TI A study for extracting keywords from data with deep learning and suffix
   array
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Extracting keywords; Chinese word segmentation; Neural network; Suffix
   array
AB While a suffix index built on a suffix array is capable of supporting full-text searches over any data, its search speed can be accelerated using a keyword index for the set of keywords extracted from data. We attempt to design a method for extracting keywords from data using deep learning and a suffix array in this article. In particular, the study starts with Chinese texts because many word segmentation results on Chinese are available for performance evaluation. A new method combining the use of a neural network and a suffix array of training data is proposed for Chinese word segmentation. The suffix array of training data is constructed to divide long sentences in the input text into short fragments for better word segmentation by our neural network method without a context window. Our experiments on the typical datasets reveal that the proposed method achieves encouraging results in terms of the precision, recall and F-1 score compared to other existing advanced methods while avoiding the drawback of a context window. This study provides some helpful experience for designing a general solution to extract keywords from data using a suffix array.
C1 [Xu, Wentao; Nong, Ge] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
C3 Sun Yat Sen University
RP Nong, G (corresponding author), Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
EM xuwt7@mail2.sysu.edu.cn; issng@mail.sysu.edu.cn
RI Nong, Ge/N-3967-2015; XU, Wentao/GVU-6771-2022
OI XU, Wentao/0000-0001-6231-4302
FU National Natural Science Foundation of China [61872391]; Special Funds
   for Guangzhou Scientific and Technological Innovation and Development
   [201802010011]
FX This work was funded by the National Natural Science Foundation of China
   (Grant number 61872391), the Special Funds for Guangzhou Scientific and
   Technological Innovation and Development (Grant number 201802010011).
CR Cai D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P608, DOI 10.18653/v1/P17-2096
   Cai D, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P409
   Chen X.C., 2015, C EMP METH NAT LANG, P1197
   Chen XC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1193, DOI 10.18653/v1/P17-1110
   Chen XC, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1744
   Chen YP, 2015, IEEE INTELL SYST, V30, P50, DOI 10.1109/MIS.2015.71
   Daume H, 2009, MACH LEARN, V75, P297, DOI 10.1007/s10994-009-5106-x
   Deng XL, 2019, MULTIMED TOOLS APPL, V78, P3797, DOI 10.1007/s11042-018-6083-5
   Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015
   Goldberg Y, 2014, ARXIV PREPRINT ARXIV
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Jinchao Zhang, 2016, Chinese Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data. 15th China National Conference, CCL 2016, and 4th International Symposium, NLP-NABD 2016. Proceedings: LNAI 10035, P450, DOI 10.1007/978-3-319-47674-2_37
   Kumar A, 2019, MULTIMED TOOLS APPL, V78, P24103, DOI 10.1007/s11042-019-7390-1
   Liu QT, 2011, KNOWL-BASED SYST, V24, P1254, DOI 10.1016/j.knosys.2011.06.001
   MANBER U, 1993, SIAM J COMPUT, V22, P935, DOI 10.1137/0222058
   Mo Jian-wen, 2013, Computer Engineering and Design, V34, P1802
   Nong G, 2013, ACM T INFORM SYST, V31, DOI 10.1145/2493175.2493180
   Nong G, 2011, IEEE T COMPUT, V60, P1471, DOI 10.1109/TC.2010.188
   Peng HY, 2018, KNOWL-BASED SYST, V148, P167, DOI 10.1016/j.knosys.2018.02.034
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang HB, 2018, KNOWL-BASED SYST, V159, P132, DOI 10.1016/j.knosys.2018.07.006
   Xiao H., 2021, INFORM TECHNOLOGY, V45, P78
   Xu JJ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P567
   Xu WT, 2021, J SUPERCOMPUT, V77, P7149, DOI 10.1007/s11227-020-03526-1
   Xue N., 2003, Int. J. Comput. Linguistics Chin. Lang. Process., V8, P29
   Zhang Y, 2007, P 45 ACL, V45, P840
   Zhao LJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4602
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
NR 31
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7419
EP 7437
DI 10.1007/s11042-021-11762-7
EA JAN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000748678300009
DA 2024-07-18
ER

PT J
AU Soto, CP
   Nunes, GMS
   Gomes, JGRC
   Nedjah, N
AF Soto, Claver P.
   Nunes, Gustavo M. S.
   Gomes, Jose Gabriel R. C.
   Nedjah, Nadia
TI Application-specific word embeddings for hate and offensive language
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Word embeddings; Convolutional neural network; Hate and offensive
   language detection; Multi-criteria analysis
AB For the task of hate speech and offensive language detection, this paper explores the potential advantages of using small datasets to develop efficient word embeddings used in models for deep learning. We investigate the impact of feature vectors generated by four selected word embedding techniques (word2vec, wang2vec, fastText, and GloVe) applied to text datasets with size in the order of a billion tokens. After training the classifiers using pre-trained word embeddings, we compare the classification performance with the results from using feature vectors generated from small datasets with size in the order of thousands of tokens. Using numerical examples, we show that the word embeddings with the smallest size yield slightly worse accuracy values but, in combination with smaller training times, such embeddings lead to non-dominated solutions. That fact has an immediate application in significantly reducing training time at a small penalty in classification accuracy. We explore two ways to rank the studied alternatives based on performance factors and on PROMETHEE-II scores. According to both rankings, GloVe is the best method for NILC-embedding, and fastText is the best method for dataset-specific embedding. It is expected that specific word embedding should yield a better fit to a particular dataset, which should yield shorter training and better accuracy. However, the obtained results indicate that NILC-embeddings would lead to an equally good fit.
C1 [Soto, Claver P.] Univ Fed Rural Rio de Janeiro, Dept Computat, Rio De Janeiro, Brazil.
   [Soto, Claver P.; Nunes, Gustavo M. S.; Gomes, Jose Gabriel R. C.] Univ Fed Rio de Janeiro, Elect Engn Program, Rio De Janeiro, Brazil.
   [Nedjah, Nadia] Univ Estado Rio De Janeiro, Engn Fac, Dept Elect Engn & Telecommun, Rio De Janeiro, Brazil.
C3 Universidade Federal Rural do Rio de Janeiro (UFRRJ); Universidade
   Federal do Rio de Janeiro; Universidade do Estado do Rio de Janeiro
RP Soto, CP (corresponding author), Univ Fed Rural Rio de Janeiro, Dept Computat, Rio De Janeiro, Brazil.
EM claver@pads.ufrj.br; gustavo_mn@poli.ufrj.br; gabriel@pads.ufrj.br;
   nadia@eng.uerj.br
OI Nunes, Gustavo/0000-0003-0351-7585
FU Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPq -
   Brazil) [432997/2018-0, 310841/2019-4, 440074/2020-7]; FundacAo Carlos
   Chagas Filho de Amparo a Pesquisa do Estado do Rio de Janeiro (FAPERJ-
   Brazil) [210.364/2018, 203.111/2018]
FX This work was supported by Conselho Nacional de Desenvolvimento
   Cientifico e Tecnologico (CNPq - Brazil), research grants 432997/2018-0,
   310841/2019-4 and 440074/2020-7, and by FundacAo Carlos Chagas Filho de
   Amparo a Pesquisa do Estado do Rio de Janeiro (FAPERJ- Brazil), research
   grant 210.364/2018 and 203.111/2018.
CR Abadi Martin, 2016, arXiv
   [Anonymous], 2015, NAACL HLT 2015
   [Anonymous], 2016, P 2 INT WORKSHOP KNO
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Brans JP, 2005, INT SER OPER RES MAN, V78, P163, DOI 10.1007/b100605
   Cer D, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P169
   Conneau A., 2017, P 2017 C EMPIRCAL ME, P670, DOI [DOI 10.18653/V1/D17-1070, 10.18653/v1/d17-1070]
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cristina Paula, 2017, Automatic detection of hate speech in text: an overview of the topic and dataset annotation with hierarchical classes
   de Pelle R, 2017, OFFENSIVE COMMENTS B
   Dhiman H., 2020, MULTICRITERIA DECISI, V253
   EIBAND M, 2018, BERT PRETRAINING DEE, P211
   Ezeibe C, 2021, J ASIAN AFR STUD, V56, P919, DOI 10.1177/0021909620951208
   Fortuna P, 2019, THIRD WORKSHOP ON ABUSIVE LANGUAGE ONLINE, P94
   Fortuna P, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3232676
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hartmann N, 2017, P 11 BRAZ S INF HUM, P122
   Joulin A., 2017, P 15 C EUR CHAPT ASS, P427, DOI DOI 10.18653/V1/E17-2068
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Leite JA, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P914
   Lima Cleiton., 2019, Anais da XV Escola Regional de Banco de Dados, P61
   Mikolov T., 2013, INT C LEARN REPR SCO, DOI 10.48550/ARXIV.1301.3781
   Pari C, 2019, 16 ENC NAC INT ART C, P1020, DOI DOI 10.5753/ENIAC.2019.9354
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846
   Petrolito R, 2018, WORD EMBEDDINGS SENT
   Poletto F, 2021, LANG RESOUR EVAL, V55, P477, DOI 10.1007/s10579-020-09502-8
   Pugliero F, 2018, COMO ODIO VIRALIZOU
   Rodrigues J, 2016, LECT NOTES ARTIF INT, V9727, P259, DOI 10.1007/978-3-319-41552-9_27
   Roy PK, 2020, IEEE ACCESS, V8, P204951, DOI 10.1109/ACCESS.2020.3037073
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Silva S, 2018, S KNOWL DISC MIN LEA, P2018
   Spertus E., 1997, Proceedings of the 8th Annual Conference on Innovative Applications of Artificial Intelligence (IAAI-97), P1058
   Thireou T, 2007, IEEE ACM T COMPUT BI, V4, P441, DOI 10.1109/TCBB.2007.1015
   Vargas F, 2021, ARXIV210412265
   Zampieri M., 2019, P 13 INT WORKSH SEM, P75, DOI DOI 10.18653/V1/S19-2010
   Zhang Y, 2017, ADV SOC SCI EDUC HUM, V185, P253
NR 38
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27111
EP 27136
DI 10.1007/s11042-021-11880-2
EA JAN 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000746780700002
DA 2024-07-18
ER

PT J
AU Elias, P
   Macko, M
   Sedmidubsky, J
   Zezula, P
AF Elias, Petr
   Macko, Matus
   Sedmidubsky, Jan
   Zezula, Pavel
TI Tracking subjects and detecting relationships in crowded city videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-subject tracking; Relationship detection; 2D skeleton sequences;
   Video analysis; Smart cities
ID ASSIGNMENT; FEATURES
AB Multi-subject tracking in crowded videos is an established yet challenging research direction in computer vision and information processing. High applicability of multi-subject tracking is demonstrated in smart cities (e.g., public safety, crowd management, urban planning), autonomous driving vehicles, robotic vision, or psychology (e.g., social interaction and crowd behavior understanding). In this work, we propose a real-time approach that reveals tracks of subjects in ordinary videos, captured in highly populated pedestrian areas, such as squares, malls, and stations. The tracks are discovered based on the proximity of detected bounding boxes of subjects in consecutive video frames. The reduction of track fragmentation and identity switching is achieved by the re-identification phase that uses caching of unassociated detections and mutual projection of interrupted tracks. As the proposed approach does not require time-consuming extraction of appearance-based features, the superior tracking speed is achieved. In addition, we demonstrate tracker usability and applicability by extracting valuable information about body-joint positions from discovered tracks, which opens promising possibilities for detecting human relationships and interactions. We demonstrate accurate detection of couples based on their holding hand activity and families based on children's body proportions. The discovery of these entitative groups is especially challenging in crowded city scenes where many subjects appear in each frame.
C1 [Elias, Petr; Macko, Matus; Sedmidubsky, Jan; Zezula, Pavel] Masaryk Univ, Brno, Czech Republic.
C3 Masaryk University Brno
RP Elias, P (corresponding author), Masaryk Univ, Brno, Czech Republic.
EM xelias3@fi.muni.cz
RI Elias, Petr/ABE-6672-2020; Sedmidubsky, Jan/J-3195-2013
OI Elias, Petr/0000-0003-4558-6802; Sedmidubsky, Jan/0000-0002-7668-8521
FU Czech Science Foundation [GA19-02033S]
FX This research is supported by the Czech Science Foundation project No.
   GA19-02033S.
CR [Anonymous], 2019, CVPR
   [Anonymous], 2018, ARXIV181104091
   Bera A, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281524
   Bergmann P, 2019, IEEE I CONF COMP VIS, P941, DOI 10.1109/ICCV.2019.00103
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bochinski Erik, 2017, 2017 14th IEEE International Conference on Advanced Video and Signal-Based Surveillance (AVSS), DOI 10.1109/AVSS.2017.8078516
   Brasó G, 2020, PROC CVPR IEEE, P6246, DOI 10.1109/CVPR42600.2020.00628
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carrara F, 2019, MULTIMED TOOLS APPL, V78, P27309, DOI 10.1007/s11042-019-07827-3
   Chen L, 2019, IEEE SIGNAL PROC LET, V26, P1613, DOI 10.1109/LSP.2019.2940922
   Choi W, 2012, LECT NOTES COMPUT SC, V7575, P215, DOI 10.1007/978-3-642-33765-9_16
   Chu J, 2020, IEEE ACCESS, V8, P856, DOI 10.1109/ACCESS.2019.2961778
   Chu P, 2019, IEEE I CONF COMP VIS, P6171, DOI 10.1109/ICCV.2019.00627
   Cong RM, 2019, IEEE T CIRC SYST VID, V29, P2941, DOI 10.1109/TCSVT.2018.2870832
   Cristani M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.23
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Davenport CB, 1917, GENETICS, V2, P313
   Dendorfer P, 2003, ARXIV200309003CS
   Evangelidis GD, 2008, IEEE T PATTERN ANAL, V30, P1858, DOI 10.1109/TPAMI.2008.113
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Gang Pan, 2013, IEEE Communications Magazine, V51, P108, DOI 10.1109/MCOM.2013.6525604
   Henschel R, 2019, IEEE COMPUT SOC CONF, P770, DOI 10.1109/CVPRW.2019.00105
   Henschel R, 2018, IEEE COMPUT SOC CONF, P1509, DOI 10.1109/CVPRW.2018.00192
   Hu T, 2019, MULTIMED TOOLS APPL, V78, P28715, DOI 10.1007/s11042-018-6074-6
   Insafutdinov E, 2017, PROC CVPR IEEE, P1293, DOI 10.1109/CVPR.2017.142
   Iqbal U, 2017, PROC CVPR IEEE, P4654, DOI 10.1109/CVPR.2017.495
   JONKER R, 1987, COMPUTING, V38, P325, DOI 10.1007/BF02278710
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kim DY, 2014, INFORM SCIENCES, V278, P641, DOI 10.1016/j.ins.2014.03.080
   Kok VJ, 2016, NEUROCOMPUTING, V177, P342, DOI 10.1016/j.neucom.2015.11.021
   Krausz B, 2012, COMPUT VIS IMAGE UND, V116, P307, DOI 10.1016/j.cviu.2011.08.006
   Leal-Taixé L, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130233
   Li HX, 2016, IEEE T IMAGE PROCESS, V25, P1834, DOI 10.1109/TIP.2015.2510583
   Li K, 2019, IEEE SYST J, V13, P2966, DOI 10.1109/JSYST.2018.2880028
   Li SM, 2020, IEEE ACCESS, V8, P122772, DOI 10.1109/ACCESS.2020.3007261
   Liciotti D, 2014, LECT NOTES COMPUT SC, V8811, P146, DOI 10.1007/978-3-319-12811-5_11
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Mahmoudi N, 2019, MULTIMED TOOLS APPL, V78, P7077, DOI 10.1007/s11042-018-6467-6
   Mehmood R, 2020, EAI SPRINGER INNOVAT, P1, DOI 10.1007/978-3-030-13705-2
   Milan A., 2016, ARXIV160300831
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Pirsiavash H, 2011, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2011.5995604
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Salmerón-García JJ, 2019, MULTIMEDIA SYST, V25, P535, DOI 10.1007/s00530-017-0558-5
   Sedmidubsky J, 2019, INFORM SYST, V80, P148, DOI 10.1016/j.is.2018.04.002
   Sedmidubsky J, 2018, MULTIMED TOOLS APPL, V77, P12073, DOI 10.1007/s11042-017-4859-7
   Sheng H, 2019, IEEE T CIRC SYST VID, V29, P3269, DOI 10.1109/TCSVT.2018.2882192
   Sime JD, 1995, SAFETY SCI, V21, P1, DOI 10.1016/0925-7535(96)81011-3
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Tran KN, 2014, PATTERN RECOGN LETT, V44, P49, DOI 10.1016/j.patrec.2013.09.015
   Vascon S, 2016, COMPUT VIS IMAGE UND, V143, P11, DOI 10.1016/j.cviu.2015.09.012
   Wang GA, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P482, DOI 10.1145/3343031.3350853
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu HM, 2018, IEEE T HUM-MACH SYST, V48, P304, DOI 10.1109/THMS.2017.2776211
   Xu RH, 2018, IEEE ICC
   Yang B, 2012, PROC CVPR IEEE, P2034, DOI 10.1109/CVPR.2012.6247907
   Yang F, 2016, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2016.234
   Yigitcanlar T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102988
   Yoon K, 2020, ONESHOTDA ONLINE MUL, V8
   Yuan Li, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2953, DOI 10.1109/CVPRW.2009.5206735
   Yuan Y, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-0496-6
   Zhang H, 2019, MULTIMED TOOLS APPL, V78, P27809, DOI 10.1007/s11042-019-07898-2
   Zhang L, 2008, INT C WAVEL ANAL PAT, P11, DOI 10.1109/ICWAPR.2008.4635742
NR 66
TC 3
Z9 3
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 15339
EP 15361
DI 10.1007/s11042-021-11891-z
EA JAN 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000743891900007
DA 2024-07-18
ER

PT J
AU Gomaa, N
   Ashiba, HI
   El-Dolil, SA
   Fouad, M
   Abd El-Samie, FE
AF Gomaa, Nahid
   Ashiba, H., I
   El-Dolil, Sami A.
   Fouad, Mohamed
   Abd El-Samie, Fathi E.
TI Proposed Approaches for Cooperative Cognitive Radio
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cooperative cognitive radio; CR; ED; HDWT; AWT; HW
ID NETWORKS; OPTIMIZATION
AB This paper in this topic concentrates on an important part is spectrum sensing (SS). It can detect the idle hole in spectrum by detection methods. This paper uses the sensing technique is called energy detector(ED). The ED depends on only the energy of the signal without other needs such as the modulation of signal or pre-knowledge about the signal and this is considered as advantage. This research proposed new two techniques are the additive wavelet transform (AWT) with Homomorphic Way (HW) and Haar Discrete Wavelet Transform (HDWT) approach. We apply these techniques are applied in wide band wireless signal by using the Cognitive Radio (CR) network. Each technique reduces the noise of signal before enter to the detection method ED. The HW is considered new technique in the wireless communication. This study will have these techniques as hybrid with the ED to increase the throughput for the cognitive user with a sufficient protection to the PU transmission. Also, it improves the probability of detection and reduces the probability of false alarm and the probability of error. The cooperative CR is used in this work which more than the non-cooperative cognitive user to detect the holes. The final decision for detection built on four fusion rules are the logic OR, logic AND, MAJORITY and K-Out-Of-M fusion rule. The two proposed are applied techniques on four fusion rule at constant sensing time. Then; study the four metric detection performances for each fusion rule by using the Additive White Gaussian Noise (AWGN) channel. At the end, comparison between two these proposed techniques with each fusion rule. Simulation results prove that the proposed scenario increases the probability of detection in the range of SNR of the PU from -20 to -5 dB using the theses proposed approaches.
C1 [Gomaa, Nahid; Ashiba, H., I] Bilbis Higher Inst Engn, Dept Elect & Elect Commun Engn, Bilbis, Sharqia, Egypt.
   [El-Dolil, Sami A.; Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Engn, Menoufia 32952, Egypt.
   [Fouad, Mohamed] Zagazig Univ, Fac Engn, Zagazig, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Zagazig University
RP Ashiba, HI (corresponding author), Bilbis Higher Inst Engn, Dept Elect & Elect Commun Engn, Bilbis, Sharqia, Egypt.
EM eng_h_2006@yahoo.com
RI Sayed, Fathi/HRA-4752-2023; ashiba, huda/GQI-4310-2022
OI Sayed, Fathi/0000-0001-8749-9518; ashiba, huda/0000-0002-4926-8919
CR Abdulsattar M., 2012, Int. J. Comput. Networks Commun, V4, P223
   Abou ElHassan M, 2019, WIRELESS PERS COMMUN, V109, P2095, DOI 10.1007/s11277-019-06234-z
   Akyildiz IF, 2006, COMPUT NETW, V50, P2127, DOI 10.1016/j.comnet.2006.05.001
   An CQ, 2011, IEEE SYMP COMP COMMU
   Ashiba HI, 2020, MULTIMED TOOLS APPL, V79, P2543, DOI 10.1007/s11042-019-08154-3
   Ashiba HI, 2019, MULTIMED TOOLS APPL, V78, P11277, DOI 10.1007/s11042-018-6545-9
   Ashiba H. I., 2008, Progress In Electromagnetics Research C, V1, P123, DOI 10.2528/PIERC08012301
   Barry J. R., 2012, Digital communication
   Chen XM, 2014, IEEE COMMUN SURV TUT, V16, P1180, DOI 10.1109/SURV.2014.021414.00066
   Du XY, 2015, PROCEEDINGS OF THE ASME 34TH INTERNATIONAL CONFERENCE ON OCEAN, OFFSHORE AND ARCTIC ENGINEERING, 2015, VOL 8
   Elhassan MA, 2019, MULTIMED TOOLS APPL, V78, P34999, DOI 10.1007/s11042-019-07782-z
   Fan RF, 2010, IEEE T WIREL COMMUN, V9, P1128, DOI 10.1109/TWC.2010.03.090467
   Ghasemi A, 2008, IEEE COMMUN MAG, V46, P32, DOI 10.1109/MCOM.2008.4481338
   Gomaa N, 2021, WIRELESS PERS COMMUN, V118, P2151, DOI 10.1007/s11277-021-08117-8
   Haykin S, 2005, IEEE J SEL AREA COMM, V23, P201, DOI 10.1109/JSAC.2004.839380
   Jakoubek R. R., 2011, U.S. Patent, Patent No. [7,885,409, 7885409]
   Kaporis A, 2020, INFORM COMPUT, V270, DOI 10.1016/j.ic.2019.104465
   Kobeissi H, 2013, 2013 20TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (ICT)
   Liu X, 2013, RADIO SCI, V48, P23, DOI 10.1029/2012RS005009
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lv Q, 2015, 2015 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING, P305, DOI 10.1109/ChinaSIP.2015.7230413
   Maleki S, 2011, SPAWC 2011: 2011 IEEE 12TH INTERNATIONAL WORKSHOP ON SIGNAL PROCESSING ADVANCES IN WIRELESS COMMUNICATIONS, P71, DOI 10.1109/SPAWC.2011.5990482
   Plata DMM, 2012, PROCEDIA ENGINEER, V35, P135, DOI 10.1016/j.proeng.2012.04.174
   Patil VM, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN HUMAN MACHINE INTERACTION (HMI), P149, DOI 10.1109/HMI.2016.7449196
   Peh E, 2007, IEEE WCNC, P27, DOI 10.1109/WCNC.2007.11
   Petrovic VS, 2004, IEEE T IMAGE PROCESS, V13, P228, DOI 10.1109/tip.2004.823821
   Rao, 2010, SASTECH, V9, P73
   Sangeetha P, 2017, IET SIGNAL PROCESS, V11, P604, DOI 10.1049/iet-spr.2016.0165
   Su Y, 2019, OPT LASER ENG, V114, P60, DOI 10.1016/j.optlaseng.2018.10.012
   Tang L, 2011, IEEE T WIREL COMMUN, V10, P1063, DOI 10.1109/TWC.2011.020111.101870
   Tian YZ, 2018, APPL OPTICS, V57, P3864, DOI 10.1364/AO.57.003864
   Vadivelu R., 2014, Journal of Theoretical and Applied Information Technology, V62, P107
   Wang HJ, 2010, VEH TECHNOL CONFE
   Xu James Y., 2009, Proceedings of the 2009 12th International Conference on Computer and Information Technology (ICCIT 2009), P547, DOI 10.1109/ICCIT.2009.5407298
   Yücek T, 2009, IEEE COMMUN SURV TUT, V11, P116, DOI 10.1109/SURV.2009.090109
   Zhang QQ, 2011, IEEE J-STSP, V5, P1, DOI 10.1109/JSTSP.2010.2101150
NR 36
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5645
EP 5668
DI 10.1007/s11042-021-11703-4
EA DEC 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000735344900005
DA 2024-07-18
ER

PT J
AU Sethy, PK
   Pandey, C
   Sahu, YK
   Behera, SK
AF Sethy, Prabira Kumar
   Pandey, Chanki
   Sahu, Yogesh Kumar
   Behera, Santi Kumari
TI Hyperspectral imagery applications for precision agriculture-a systemic
   survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral imaging; Precision Agriculture; Remote sensing
ID PRINCIPAL COMPONENT ANALYSIS; NEAR-INFRARED SPECTROSCOPY; SINGLE MAIZE
   SEED; VARIABLE SELECTION; VEGETATION INDEXES; MOISTURE-CONTENT;
   NITROGEN-CONTENT; RAPID ASSESSMENT; PROTEIN-CONTENT; PREDICTION
AB Hyperspectral imaging has been extensively investigated as an emerging, promising technique for measuring the quality and protection of horticultural and agricultural products over the past 20 years. This technology evolved from remote sensing and joins the machine vision and point spectroscopy realms to provide superior image segmentation for defect and contamination detection. In this paper, we have incorporated spatial and spectral information into hyperspectral imaging techniques. It can efficiently and non-destructively provide helpful information on both external physical and internal chemical characteristics of agricultural and food products. This paper has reviewed the sum of crucial aspect applications of hyperspectral imaging in precision agriculture. This paper reviews hyperspectral imaging's current and past development in the agriculture industry, such as classification, chromatic, climatic, convergence, etc. This analysis aims to refer to potential work on key issues and promote deployed end-user solutions to fulfill the existing global sustainability objectives.
C1 [Sethy, Prabira Kumar] Sambalpur Univ, Dept Elect, Sambalpur, Odisha, India.
   [Pandey, Chanki; Sahu, Yogesh Kumar] Govt Engn Coll, Dept ET&T Engn, Jagdalpur, CG, India.
   [Behera, Santi Kumari] VSSUT, Dept Comp Sci & Engn, Burla, Odisha, India.
C3 Sambalpur University; Veer Surendra Sai University of Technology
RP Sethy, PK (corresponding author), Sambalpur Univ, Dept Elect, Sambalpur, Odisha, India.
EM prabirsethy.05@gmail.com
RI Behera, Santi Kumari/GPF-3681-2022; Pandey, Chanki/AAW-6794-2020; Sethy,
   Prabira kumar/W-5929-2019
OI Behera, Santi Kumari/0000-0003-4857-7821; Pandey,
   Chanki/0000-0002-6801-0825; Sethy, Prabira kumar/0000-0003-3477-6715
CR Abdel-Rahman EM, 2017, COMPUT ELECTRON AGR, V132, P21, DOI 10.1016/j.compag.2016.11.008
   Abdulridha J, 2020, PRECIS AGRIC, V21, P955, DOI 10.1007/s11119-019-09703-4
   Al Makdessi N, 2019, PRECIS AGRIC, V20, P237, DOI 10.1007/s11119-018-9613-2
   Al-Gaadi KA, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162219
   Arias F, 2021, AIMS AGRIC FOOD, V6, P273, DOI 10.3934/agrfood.2021018
   Banerjee S, 2021, ADV SPACE RES, V67, P266, DOI 10.1016/j.asr.2020.09.045
   Bangelesa F, 2020, APPL ENVIRON SOIL SC, V2020, DOI 10.1155/2020/2158573
   Barbin D, 2012, MEAT SCI, V90, P259, DOI 10.1016/j.meatsci.2011.07.011
   Barbin DF, 2013, FOOD CHEM, V138, P1162, DOI 10.1016/j.foodchem.2012.11.120
   Barbin DF, 2012, ANAL CHIM ACTA, V719, P30, DOI 10.1016/j.aca.2012.01.004
   Bock CH, 2010, CRIT REV PLANT SCI, V29, P59, DOI 10.1080/07352681003617285
   Caporaso N, 2018, APPL SPECTROSC REV, V53, P667, DOI 10.1080/05704928.2018.1425214
   Chang C. I., 2003, HYPERSPECTRAL IMAGIN
   Chen SS, 2015, FOOD CHEM, V172, P788, DOI 10.1016/j.foodchem.2014.09.119
   Chen YR, 2002, COMPUT ELECTRON AGR, V36, P173, DOI 10.1016/S0168-1699(02)00100-X
   Chen Y, 2019, FORESTS, V10, DOI 10.3390/f10030217
   Chen ZL, 2021, COMPUT ELECTRON AGR, V183, DOI 10.1016/j.compag.2021.105996
   Costa C, 2011, FOOD BIOPROCESS TECH, V4, P673, DOI 10.1007/s11947-011-0556-0
   Cubero S, 2011, FOOD BIOPROCESS TECH, V4, P487, DOI 10.1007/s11947-010-0411-8
   Dixit Y, 2021, MEAT SCI, V181, DOI 10.1016/j.meatsci.2020.108410
   Du L, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060526
   Du ZJ, 2020, TRENDS FOOD SCI TECH, V99, P133, DOI 10.1016/j.tifs.2020.02.024
   ElMasry G, 2013, J FOOD ENG, V117, P235, DOI 10.1016/j.jfoodeng.2013.02.016
   Eshkabilov S, 2021, COMPUT ELECTRON AGR, V181, DOI 10.1016/j.compag.2020.105968
   Fact MR, 2019, HYPERSPECTRAL IMAGIN
   Falkovskaya A, 2020, POULTRY SCI, V99, P3709, DOI 10.1016/j.psj.2020.04.013
   Fei BW, 2020, DATA HANDL SCI TECHN, V32, P523, DOI 10.1016/B978-0-444-63977-6.00021-3
   Femenias A, 2021, FOOD RES INT, V139, DOI 10.1016/j.foodres.2020.109925
   Feng L, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0476-y
   Forchetti DAP, 2017, LWT-FOOD SCI TECHNOL, V76, P337, DOI 10.1016/j.lwt.2016.06.046
   Foster AJ, 2017, PRECIS AGRIC, V18, P192, DOI 10.1007/s11119-016-9455-8
   Fowler SM, 2015, MEAT SCI, V110, P70, DOI 10.1016/j.meatsci.2015.06.016
   Fox G, 2014, J SCI FOOD AGR, V94, P174, DOI 10.1002/jsfa.6367
   Gao DH, 2021, COMPUT ELECTRON AGR, V184, DOI 10.1016/j.compag.2021.106077
   Gao ZM, 2020, COMPUT ELECTRON AGR, V179, DOI 10.1016/j.compag.2020.105807
   Geipel J, 2021, PRECIS AGRIC, V22, P1437, DOI 10.1007/s11119-021-09790-2
   Gevaert CM, 2015, IEEE J-STARS, V8, P3140, DOI 10.1109/JSTARS.2015.2406339
   GOETZ AFH, 1985, SCIENCE, V228, P1147, DOI 10.1126/science.228.4704.1147
   Gold KM, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020286
   Gorretta N, 2019, WORK HYPERSP IMAG, DOI 10.1109/whispers.2019.8921066
   Gowen AA, 2008, J CHEMOMETR, V22, P259, DOI 10.1002/cem.1127
   Grafton M, 2019, AGRICULTURE-BASEL, V9, DOI 10.3390/agriculture9030055
   Green RO, 1998, REMOTE SENS ENVIRON, V65, P227, DOI 10.1016/S0034-4257(98)00064-9
   Guo JB, 2021, PRECIS AGRIC, V22, P1634, DOI 10.1007/s11119-021-09804-z
   Guo L, 2021, GEODERMA, V398, DOI 10.1016/j.geoderma.2021.115118
   Guo L, 2019, GEODERMA, V337, P32, DOI 10.1016/j.geoderma.2018.09.003
   Gutiérrez S, 2019, COMPUT ELECTRON AGR, V157, P126, DOI 10.1016/j.compag.2018.12.041
   He XM, 2021, INFRARED PHYS TECHN, V114, DOI 10.1016/j.infrared.2021.103652
   Hong YS, 2020, GEODERMA, V365, DOI 10.1016/j.geoderma.2020.114228
   Hu J, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11070736
   Hu NY, 2021, FOOD CHEM, V343, DOI 10.1016/j.foodchem.2020.128473
   Huang B, 2018, SMALL, V14, DOI 10.1002/smll.201703246
   Huang LS, 2019, J PLANT PATHOL, V101, P1035, DOI 10.1007/s42161-019-00334-2
   Ishida T, 2018, COMPUT ELECTRON AGR, V144, P80, DOI 10.1016/j.compag.2017.11.027
   Jawaid S, 2013, FOOD CHEM, V141, P3066, DOI 10.1016/j.foodchem.2013.05.106
   Ji YM, 2019, INFRARED PHYS TECHN, V99, P71, DOI 10.1016/j.infrared.2019.04.007
   Jiang HZ, 2021, SPECTROCHIM ACTA A, V249, DOI 10.1016/j.saa.2020.119307
   Jin XL, 2018, PRECIS AGRIC, V19, P1, DOI 10.1007/s11119-016-9469-2
   Kamruzzaman M, 2011, J FOOD ENG, V104, P332, DOI 10.1016/j.jfoodeng.2010.12.024
   Khan MJ, 2018, IEEE ACCESS, V6, P14118, DOI 10.1109/ACCESS.2018.2812999
   Kim DM, 2015, SCI REP-UK, V5, DOI 10.1038/srep15919
   Kimiya T, 2013, J FOOD ENG, V116, P758, DOI 10.1016/j.jfoodeng.2013.01.008
   Koppanati RK, 2019, ICICCS 2018, P1820, DOI [10.1109/ICCONS.2018.8662840, DOI 10.1109/ICCONS.2018.8662840]
   Kumar K, 2017, 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT - 2017), P100, DOI 10.1145/3154979.3154998
   Kumar K, 2019, J VIS COMMUN IMAGE R, V58, P345, DOI 10.1016/j.jvcir.2018.12.009
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P26635, DOI 10.1007/s11042-018-5882-z
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P7383, DOI 10.1007/s11042-017-4642-9
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kumar K, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN ELECTRONICS, SIGNAL PROCESSING AND COMMUNICATION (IESC), P106, DOI 10.1109/IESPC.2017.8071874
   Lan WJ, 2021, POSTHARVEST BIOL TEC, V175, DOI 10.1016/j.postharvbio.2021.111497
   Lassalle Guillaume, 2021, Sci Rep, V11, P2, DOI 10.1038/s41598-020-79439-z
   Li B, 2020, ISPRS J PHOTOGRAMM, V162, P161, DOI 10.1016/j.isprsjprs.2020.02.013
   Li W, 2021, FRONT PLANT SCI, V12, DOI 10.3389/fpls.2021.657578
   Li X., 2017, HYPERSPECTRAL IMAGIN, P27, DOI DOI 10.5772/INTECHOPEN.72250
   Li Z, 2016, J APPL SPECTROSC+, V83, P240, DOI 10.1007/s10812-016-0276-3
   Lim J, 2016, TALANTA, V151, P183, DOI 10.1016/j.talanta.2016.01.035
   Liu C, 2020, INFRARED PHYS TECHN, V110, DOI 10.1016/j.infrared.2020.103462
   Liu SY, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061243
   Liu ZY, 2018, PRECIS AGRIC, V19, P973, DOI 10.1007/s11119-018-9567-4
   Lowe A, 2017, PLANT METHODS, V13, DOI 10.1186/s13007-017-0233-z
   Lu JS, 2021, PRECIS AGRIC, V22, P51, DOI 10.1007/s11119-020-09729-z
   Lu JS, 2020, PRECIS AGRIC, V21, P324, DOI 10.1007/s11119-019-09670-w
   Lu JZ, 2018, PRECIS AGRIC, V19, P379, DOI 10.1007/s11119-017-9524-7
   Ma CY, 2021, VIB SPECTROSC, V114, DOI 10.1016/j.vibspec.2021.103230
   Ma DD, 2020, BIOSYST ENG, V200, P40, DOI 10.1016/j.biosystemseng.2020.09.002
   Ma J, 2019, ANNU REV FOOD SCI T, V10, P197, DOI 10.1146/annurev-food-032818-121155
   Mahajan GR, 2017, PRECIS AGRIC, V18, P736, DOI 10.1007/s11119-016-9485-2
   Mahlein AK, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19102281
   Manley M, 2009, J AGR FOOD CHEM, V57, P8761, DOI 10.1021/jf9018323
   Manolakis D. G., 2016, Hyperspectral Imaging Remote Sensing: Physics, Sensors, and Algorithms, DOI DOI 10.1017/CBO9781316017876
   Bianchini VDM, 2021, PLANT METHODS, V17, DOI 10.1186/s13007-021-00709-6
   Menesatti P., 2010, hyperspectral imaging for food quality analysis and control, P273, DOI [10.1016/B978-0-12-374753-2.10008-5, DOI 10.1016/B978-0-12-374753-2.10008-5]
   Moghadam P, 2017, 2017 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING - TECHNIQUES AND APPLICATIONS (DICTA), P384
   Mozgeris G, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101668
   Murphy RJ, 2019, PRECIS AGRIC, V20, P767, DOI 10.1007/s11119-018-9610-5
   Naganathan GK, 2008, COMPUT ELECTRON AGR, V64, P225, DOI 10.1016/j.compag.2008.05.020
   Nagasubramanian K, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0479-8
   Nagasubramanian K, 2018, PLANT METHODS, V14, DOI 10.1186/s13007-018-0349-9
   Naik BB, 2020, J INDIAN SOC REMOTE, V48, P1787, DOI 10.1007/s12524-020-01200-w
   Nakariyakul S, 2009, J FOOD ENG, V94, P358, DOI 10.1016/j.jfoodeng.2009.04.001
   Nandibewoor A, 2019, CLUSTER COMPUT, V22, P443, DOI 10.1007/s10586-018-2243-7
   Nguyen HDD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105458
   Nogales-Bueno J, 2015, FOOD CHEM, V172, P559, DOI 10.1016/j.foodchem.2014.09.112
   Nogales-Bueno J, 2015, TALANTA, V131, P412, DOI 10.1016/j.talanta.2014.07.086
   Nyalala I, 2021, POULTRY SCI, V100, DOI 10.1016/j.psj.2021.101072
   Onoyama H, 2018, PRECIS AGRIC, V19, P721, DOI 10.1007/s11119-017-9552-3
   Paliwal J, 2018, ENCY FOOD CHEM, P446, DOI [10.1016/B978-0-08-100596-5.22349-4, DOI 10.1016/B978-0-08-100596-5.22349-4]
   Pallottino F, 2018, TALANTA, V190, P167, DOI 10.1016/j.talanta.2018.07.082
   Pan LQ, 2016, FOOD BIOPROCESS TECH, V9, P1177, DOI 10.1007/s11947-016-1710-5
   Pandey P, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.01348
   Pang L, 2020, IEEE ACCESS, V8, P123026, DOI 10.1109/ACCESS.2020.3006495
   Parfitt J, 2010, PHILOS T R SOC B, V365, P3065, DOI 10.1098/rstb.2010.0126
   Park B, 2007, BIOSYST ENG, V96, P323, DOI 10.1016/j.biosystemseng.2006.11.012
   Patel AK, 2020, IEEE J-STARS, V13, P6495, DOI 10.1109/JSTARS.2020.3039844
   Patel AK, 2019, PROC SPIE, V11149, DOI 10.1117/12.2533115
   Pearlman JS, 2003, IEEE T GEOSCI REMOTE, V41, P1160, DOI 10.1109/TGRS.2003.815018
   Peng YF, 2021, J INDIAN SOC REMOTE, V49, P377, DOI 10.1007/s12524-020-01197-2
   da Conceiçao RRP, 2021, FOOD CHEM, V344, DOI 10.1016/j.foodchem.2020.128615
   Persistence Market Research, 2016, IM TECHN PREC AGR MA
   PRIYA TR, 2021, J FOOD MEAS CHARACT, P1
   Pu HB, 2014, J FOOD ENG, V143, P44, DOI 10.1016/j.jfoodeng.2014.06.025
   Qiu GJ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041010
   Rabanera JD, 2021, J FOOD MEAS CHARACT, V15, P3069, DOI 10.1007/s11694-021-00894-x
   Rady A, 2017, POSTHARVEST BIOL TEC, V129, P37, DOI 10.1016/j.postharvbio.2017.03.007
   Rahman A, 2018, FOOD ANAL METHOD, V11, P3042, DOI 10.1007/s12161-018-1275-1
   Ravikanth L, 2016, AGR RES, V5, P285, DOI 10.1007/s40003-016-0227-5
   Reis AS, 2021, REMOTE SENS APPL, V22, DOI 10.1016/j.rsase.2021.100492
   Riccioli C, 2021, POSTHARVEST BIOL TEC, V176, DOI 10.1016/j.postharvbio.2021.111504
   Rubio-Delgado J, 2021, PRECIS AGRIC, V22, P1, DOI 10.1007/s11119-020-09727-1
   Schmid T, 2016, IEEE J-STARS, V9, P845, DOI 10.1109/JSTARS.2015.2462125
   Sendin K, 2019, FOOD ANAL METHOD, V12, P1612, DOI 10.1007/s12161-019-01464-0
   Sendin K, 2018, CRIT REV FOOD SCI, V58, P575, DOI 10.1080/10408398.2016.1205548
   Serranti S, 2018, WASTE MANAGE, V75, P141, DOI 10.1016/j.wasman.2018.02.013
   Shen Q, 2019, SPECTROCHIM ACTA A, V222, DOI 10.1016/j.saa.2019.117191
   Shi TZ, 2016, J HAZARD MATER, V308, P243, DOI 10.1016/j.jhazmat.2016.01.022
   Silva LCR, 2020, VIB SPECTROSC, V111, DOI 10.1016/j.vibspec.2020.103158
   Singh H, 2017, 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT - 2017), P29, DOI 10.1145/3154979.3154996
   Song X, 2016, PRECIS AGRIC, V17, P721, DOI 10.1007/s11119-016-9445-x
   Song YQ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18093086
   Stuart MB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143071
   Suarez LA, 2020, PRECIS AGRIC, V21, P1304, DOI 10.1007/s11119-020-09722-6
   Sun DW, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0432-x
   Sun Y, 2017, FOOD ANAL METHOD, V10, P1535, DOI 10.1007/s12161-016-0722-0
   Susic N, 2018, SENSOR ACTUAT B-CHEM, V273, P842, DOI 10.1016/j.snb.2018.06.121
   Tahmasbian I, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13061128
   Tan K, 2020, J HAZARD MATER, V382, DOI 10.1016/j.jhazmat.2019.120987
   Tan K, 2018, INT J REMOTE SENS, V39, P3029, DOI 10.1080/01431161.2018.1433893
   Tian SQ, 2020, ACTA GEOCHIM, V39, P423, DOI 10.1007/s11631-019-00388-0
   Tian YC, 2011, FIELD CROP RES, V120, P299, DOI 10.1016/j.fcr.2010.11.002
   Tong X, 2019, PRECIS AGRIC, V20, P477, DOI 10.1007/s11119-018-9592-3
   Trong NND, 2011, J FOOD ENG, V105, P617, DOI 10.1016/j.jfoodeng.2011.03.031
   Vanegas F, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010260
   Wakholi C, 2018, SENSOR ACTUAT B-CHEM, V255, P498, DOI 10.1016/j.snb.2017.08.036
   Wang GD, 2020, ENVIRON SCI POLLUT R, V27, P39029, DOI 10.1007/s11356-020-09973-w
   Wang J, 2020, PLANT METHODS, V16, DOI 10.1186/s13007-020-00576-7
   Wang LJ, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2019.105209
   Wang YJ, 2018, J SCI FOOD AGR, V98, P4659, DOI 10.1002/jsfa.8996
   Wang ZL, 2021, SPECTROCHIM ACTA A, V254, DOI 10.1016/j.saa.2021.119666
   Wang ZL, 2021, INFRARED PHYS TECHN, V112, DOI 10.1016/j.infrared.2020.103596
   Wang ZL, 2020, IEEE ACCESS, V8, P195229, DOI 10.1109/ACCESS.2020.3033582
   Wei LF, 2020, IEEE ACCESS, V8, P168137, DOI 10.1109/ACCESS.2020.3023690
   Wen PF, 2021, PRECIS AGRIC, V22, P984, DOI 10.1007/s11119-020-09769-5
   Wu D, 2013, TALANTA, V116, P266, DOI 10.1016/j.talanta.2013.05.030
   Xie AG, 2015, TALANTA, V139, P208, DOI 10.1016/j.talanta.2015.02.027
   Xing FG, 2019, CRIT REV FOOD SCI, V59, P173, DOI 10.1080/10408398.2017.1363709
   Yan Y, 2019, ACM INT C P SERIES, P64
   Yang S, 2017, FOOD ANAL METHOD, V10, P424, DOI 10.1007/s12161-016-0597-0
   Yang W, 2021, COMPUT ELECTRON AGR, V184, DOI 10.1016/j.compag.2021.106092
   Yang W, 2019, IEEE ACCESS, V7, P118239, DOI 10.1109/ACCESS.2019.2936892
   Ye XJ, 2020, PRECIS AGRIC, V21, P198, DOI 10.1007/s11119-019-09661-x
   Zaeem M, 2021, GEODERMA, V385, DOI 10.1016/j.geoderma.2020.114831
   Zeng FG, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9235058
   Zhang BH, 2014, FOOD RES INT, V62, P326, DOI 10.1016/j.foodres.2014.03.012
   Zhang C, 2020, INFRARED PHYS TECHN, V111, DOI 10.1016/j.infrared.2020.103550
   Zhang C, 2017, FOOD BIOPROCESS TECH, V10, P213, DOI 10.1007/s11947-016-1809-8
   Zhang GS, 2020, AUSTRALAS PLANT PATH, V49, P571, DOI 10.1007/s13313-020-00736-2
   Zhang HL, 2020, J FOOD COMPOS ANAL, V92, DOI 10.1016/j.jfca.2020.103567
   Zhang J, 2021, FOOD ANAL METHOD, V14, P389, DOI 10.1007/s12161-020-01871-8
   Zhang J, 2021, J FOOD MEAS CHARACT, V15, P484, DOI 10.1007/s11694-020-00646-3
   Zhang SW, 2019, SPECTROCHIM ACTA A, V211, P393, DOI 10.1016/j.saa.2018.12.032
   Zheng HB, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10060824
   Zovko M, 2019, PRECIS AGRIC, V20, P335, DOI 10.1007/s11119-019-09640-2
NR 182
TC 28
Z9 28
U1 11
U2 64
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 3005
EP 3038
DI 10.1007/s11042-021-11729-8
EA NOV 2021
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000718080900001
DA 2024-07-18
ER

PT J
AU Kuo, LW
   Chang, T
   Lai, CC
AF Kuo, Lungwen
   Chang, Tsuiyueh
   Lai, Chih-Chun
TI Multimedia webpage visual design and color emotion test
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Html5; Design; Multimedia; Web; Color
ID WEB; ATTRACTIVENESS; INTERFACE; ENHANCE; QUALITY; MEDIA
AB Colors and visual design are the main visual languages for expressing the emotions and content of a webpage. The layout of a webpage is crucial to website aesthetics and affects user preference. A webpage's title, image, colors, and structure affects the design style of its visual interface. This study consisted of two experiments. Experiment 1 focused on the color emotional characteristics of multimedia webpage color combinations and identified the most popular dual-tone color designs for multimedia webpages. Experiment 2 involved an examination of the optimal visual effect design for multimedia webpage composition. Ten types of geometric shapes were selected and combined with dynamic pictures, and the combined products were then used to conduct a multimedia dynamic pictorial webpage experiment; the purpose of the experiment was to test the effects of geometrical dynamic shapes on webpage psychology and determine the most popular multimedia dynamic picture visual design style. The researchers used semantic differential and Likert scales to conduct psychological tests aimed at measuring psychological reactions to various webpage colors and visual designs. The results indicated that the most popular color combinations for multimedia webpages are cyan and gray, cyan and black, and blue violet and gray. The most suitable graphic shape for multimedia visual designs is the oval and square dynamic picture composition. The results of the multimedia webpage color and visual effect design experiments can serve as a reference for webpage design-related research and to webpage designers.
C1 [Kuo, Lungwen] Sanming Univ, Dept Prod Design, Sanming, Fujian, Peoples R China.
   [Chang, Tsuiyueh] Tzu Chi Acad, Dept Educ, Cupertino, CA USA.
   [Lai, Chih-Chun] Tatung Univ, Dept Ind Design, Taipei, Taiwan.
C3 Sanming University; Tatung University
RP Chang, T (corresponding author), Tzu Chi Acad, Dept Educ, Cupertino, CA USA.
EM yueh5031162@yahoo.com.tw
RI Kuo, Lungwen/AAV-1958-2021; lai, chih chun/AAE-6772-2021
OI Kuo, Lungwen/0000-0001-9894-2706; Lai, Chih-Chun/0000-0003-4261-6228
FU Sanming University [21YG02S]
FX Sanming University. Research Foundation for Advanced Talents, Grant
   Number: 21YG02S.
CR Adami E, 2016, VISUAL COMMUN-US, V15, P263, DOI 10.1177/1470357216644153
   Breves P, 2021, MULTIMED TOOLS APPL, V80, P27299, DOI 10.1007/s11042-021-11057-x
   Caple H, 2012, VISUAL COMMUN-US, V11, P207, DOI 10.1177/1470357211434032
   Castellano G, 2021, MULTIMED TOOLS APPL, V80, P6599, DOI 10.1007/s11042-020-09995-z
   Celentano A, 2017, MULTIMED TOOLS APPL, V76, P5511, DOI 10.1007/s11042-016-3790-7
   Chen YL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106335
   Chen Y, 2021, COLOR RES APPL, V46, P557, DOI 10.1002/col.22631
   Cyr D, 2004, J AM SOC INF SCI TEC, V55, P1199, DOI 10.1002/asi.20075
   Demir Ü, 2020, COLOR RES APPL, V45, P871, DOI 10.1002/col.22522
   Dionisio M, 2021, MULTIMED TOOLS APPL, V80, P34813, DOI 10.1007/s11042-021-10949-2
   Duce D, 2002, COMPUT GRAPH FORUM, V21, P43, DOI 10.1111/1467-8659.00565
   Fateminia M, 2020, COLOR RES APPL, V45, P743, DOI 10.1002/col.22503
   Frery AC, 2000, COLOR RES APPL, V25, P435, DOI 10.1002/1520-6378(200012)25:6<435::AID-COL8>3.0.CO;2-J
   Gu ZY, 2016, COMPUT AIDED DESIGN, V77, P46, DOI 10.1016/j.cad.2016.03.001
   Guo F, 2020, COLOR RES APPL, V45, P156, DOI 10.1002/col.22447
   Gürsimsek ÖA, 2016, VISUAL COMMUN-US, V15, P329, DOI 10.1177/1470357216645481
   Hsu CC, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2011.01.009
   Hunt R. W. G., 2001, Journal of the Society for Information Display, V9, P79, DOI 10.1889/1.1828774
   Jaklic A, 2017, DISPLAYS, V46, P25, DOI 10.1016/j.displa.2016.12.002
   Jalali NY, 2016, QME-QUANT MARK ECON, V14, P353, DOI 10.1007/s11129-016-9178-1
   Jeon E, 2020, PSYCHOL MARKET, V37, P980, DOI 10.1002/mar.21348
   Jeong SH., 2005, J Korean Soc Des Sci, V18, P69
   Jessen IB, 2013, VISUAL COMMUN-US, V12, P437, DOI 10.1177/1470357213497665
   Jin H, 2021, MULTIMED TOOLS APPL, V80, P34571, DOI 10.1007/s11042-020-08819-4
   Katerattanakul P, 2008, J AM SOC INF SCI TEC, V59, P63, DOI 10.1002/asi.20717
   KODZOMAN D, 2021, COLOR RES APPL, P1, DOI DOI 10.1002/COL.22705
   Koivunen-Niemi L, 2020, MULTIMED TOOLS APPL, V79, P919, DOI 10.1007/s11042-019-08186-9
   Lin HY, 2014, DISPLAYS, V35, P202, DOI 10.1016/j.displa.2014.05.009
   Liu X, 2021, FUTURE GENER COMP SY, V117, P433, DOI 10.1016/j.future.2020.12.014
   MacKay B, 2012, J AM SOC INF SCI TEC, V63, P1183, DOI 10.1002/asi.22610
   Man ZL, 2021, MULTIMED TOOLS APPL, V80, P27445, DOI 10.1007/s11042-021-10979-w
   Na N, 2017, COLOR RES APPL, V42, P60, DOI 10.1002/col.22044
   Ng AWY, 2018, APPL ERGON, V70, P18, DOI 10.1016/j.apergo.2018.02.004
   Pan YT, 2020, WORLD WIDE WEB, V23, P2259, DOI 10.1007/s11280-020-00793-z
   Pelet JÉ, 2012, EUR J INFORM SYST, V21, P438, DOI 10.1057/ejis.2012.17
   Pichl M, 2021, MULTIMED TOOLS APPL, V80, P22509, DOI 10.1007/s11042-020-09890-7
   Pollet TV, 2019, DISPLAYS, V56, P23, DOI 10.1016/j.displa.2018.10.008
   Rinaldi AM, 2021, MULTIMED TOOLS APPL, V80, P3885, DOI 10.1007/s11042-020-09761-1
   Rodriguez-Gil L, 2018, MULTIMED TOOLS APPL, V77, P6471, DOI 10.1007/s11042-017-4556-6
   Saito D, 2006, ELECTR ENG JPN, V157, P32, DOI 10.1002/eej.20400
   Shen ZF, 2021, DISPLAYS, V67, DOI 10.1016/j.displa.2021.101999
   Sun LT, 2018, MULTIMED TOOLS APPL, V77, P5189, DOI 10.1007/s11042-017-4424-4
   Walsh TA, 2020, SOFTW TEST VERIF REL, V30, DOI 10.1002/stvr.1748
   Wan HY, 2021, INFORM SCIENCES, V576, P589, DOI 10.1016/j.ins.2021.06.071
   Wang MY, 2021, INFORM SYST FRONT, V23, P607, DOI 10.1007/s10796-020-09981-8
   Wang YZ, 2021, DISPLAYS, V68, DOI 10.1016/j.displa.2021.102007
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Xu C, 2019, J ASSOC INF SCI TECH, V70, P942, DOI 10.1002/asi.24118
   Yang CC, 2009, J AM SOC INF SCI TEC, V60, P495, DOI 10.1002/asi.20990
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Yu N, 2016, INFORM SCIENCES, V330, P427, DOI 10.1016/j.ins.2015.06.004
   Zhao NX, 2018, COMPUT GRAPH FORUM, V37, P385, DOI 10.1111/cgf.13576
   Zhu Y, 2017, SOFTWARE PRACT EXPER, V47, P709, DOI 10.1002/spe.2434
NR 53
TC 11
Z9 11
U1 9
U2 81
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2621
EP 2636
DI 10.1007/s11042-021-11684-4
EA NOV 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000713543500001
DA 2024-07-18
ER

PT J
AU Ren, H
   Niu, SZ
AF Ren, Hua
   Niu, Shaozhang
TI Separable reversible data hiding in homomorphic encrypted domain using
   POB number system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Homomorphism encryption; POB number system
ID SEMI-TENSOR PRODUCT; IMAGE; ALGORITHM
AB In this paper, a novel separable reversible data hiding in homomorphic encrypted images (RDHEI) using POB number system is proposed. The frame of the proposed RDHEI includes three parties: content owner, data hider, and receiver. The content owner divides original image contents into a series of non-overlapping equal-size 2 x 2 blocks, and encrypts all pixels in each block with the same key. The encryption process is carried out in an additive homomorphism manner. The data hider divides the encrypted images into the same size blocks as the encryption phase, and further categories all of the obtained blocks into two sets according to the corresponding block entropy. The embedding processes of the two sets are performed through utilizing permutation ordered binary (POB) number system. For the set with smaller entropies, all pixels in addition to the first pixel in each block are compressed by the POB number system; for the set with larger entropies, only u LSBs of all pixels are compressed in order to vacate room for embedding. The receiver can conduct image decryption, data extraction, and image reconstruction in a separable manner. Experimental results verify the superiority of the proposed method.
C1 [Ren, Hua; Niu, Shaozhang] Beijing Univ Posts & Telecommun, Sch Comp, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Niu, SZ (corresponding author), Beijing Univ Posts & Telecommun, Sch Comp, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
EM renhuahtu@163.com; szniu@bupt.edu.cn
OI Niu, Shaozhang/0000-0002-9639-5910
FU National Natural Science Foundation of China [61370195]; Joint Funds of
   the National Natural Science Foundation of China [U1536121]
FX This work is supported by the National Natural Science Foundation of
   China (No.61370195) and the Joint Funds of the National Natural Science
   Foundation of China (No. U1536121).
CR CHEN T, 2020, MULTIMED TOOLS APPL, V3, P1
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Gao H, 2020, J FRANKLIN I, V357, P9107, DOI 10.1016/j.jfranklin.2020.07.026
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Jiang CL, 2020, MULTIMED TOOLS APPL, V79, P693, DOI 10.1007/s11042-019-07874-w
   Li M, 2019, IEEE ACCESS, V7, P69808, DOI 10.1109/ACCESS.2019.2919376
   Li M, 2015, ELECTRON LETT, V51, P690, DOI 10.1049/el.2014.4476
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu L, 2021, MOBILE NETW APPL, V26, P1145, DOI 10.1007/s11036-020-01624-1
   Liu Y, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107293
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Malik A, 2020, MULTIMED TOOLS APPL, V79, P11591, DOI 10.1007/s11042-019-08460-w
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qian ZX, 2016, IEEE SIGNAL PROC LET, V23, P1672, DOI 10.1109/LSP.2016.2585580
   Qin C, 2018, SIGNAL PROCESS, V153, P109, DOI 10.1016/j.sigpro.2018.07.008
   Qin C, 2018, INFORM SCIENCES, V465, P285, DOI 10.1016/j.ins.2018.07.021
   Ren H, 2019, IEEE ACCESS, V7, P149527, DOI 10.1109/ACCESS.2019.2946929
   Rivest Ronald L., 1978, Found. Secure Comput., V4, P169
   Romero Grecia, 2017, SIGNAL IMAGE PROCESS
   Singh P, 2018, IEEE T CIRC SYST VID, V28, P2116, DOI 10.1109/TCSVT.2017.2716828
   Singh P, 2018, FUTURE GENER COMP SY, V88, P156, DOI 10.1016/j.future.2018.04.097
   Singh P, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3077140
   Sundar S., 2009, INT J INF PROCESS, P1
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
NR 37
TC 8
Z9 10
U1 3
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2161
EP 2187
DI 10.1007/s11042-021-11341-w
EA OCT 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000709762100002
DA 2024-07-18
ER

PT J
AU Cai, HH
   Huang, L
   Zhang, WF
   Wei, ZQ
AF Cai, Huanhuan
   Huang, Lei
   Zhang, Wenfeng
   Wei, Zhiqiang
TI Learning discriminative features for semi-supervised person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Part segmentation (PS) constraint; Multi-task
   training strategy; Semi-supervised learning; Few-example learning
ID NETWORK; FILTER
AB We focus on the one-example person re-identification (Re-ID) task, where each identity has only one labeled example along with many unlabeled examples. Since each identity has only one labeled example, the number of initialized label examples is small, and the body parts of person are not aligned due to changes in person pose and camera angle under the camera. Therefore, the distinguishing information of learning labeled and unlabeled examples is challenging. To overcome these problems, we propose an end-to-end multi-task training network for semi-supervised Re-ID. First, we impose a part segmentation (PS) constraint on feature maps, forcing a module to predict part labels from the feature maps and enhance alignment. Second, we carefully design the network named Multiple Branch Network (MBN). MBN is a multi-branch deep network architecture, which consisting of one branch for global feature representation and two branches for local feature representation, local feature representation that including horizontal stripes representation and PS representation, respectively. Finally, loss function fusion is designed to learn discriminative features for semi-supervised Re-ID. Specifically, the MBN model is optimized by mining the object classification loss, exclusive loss and PS loss simultaneously. We validate the effectiveness of our approach by demonstrating its superiority over the state-of-the-art methods on the standard benchmark datasets, including Market-1501, DukeMTMC-reID. Notably, the rank-1 accuracy of our method outperforms the state-of-the-art method by 15.9 points (absolute, i.e., 71.7% vs. 55.8%) on Market-1501 and 8.9 points on DukeMTMC-reID.
C1 [Cai, Huanhuan; Huang, Lei; Zhang, Wenfeng; Wei, Zhiqiang] Ocean Univ China, Coll Informat Sci & Engn, Qingdao 266000, Peoples R China.
   [Cai, Huanhuan] Jining Polytech, Jining 272000, Peoples R China.
C3 Ocean University of China
RP Huang, L (corresponding author), Ocean Univ China, Coll Informat Sci & Engn, Qingdao 266000, Peoples R China.
EM caihuanhuan@stu.ouc.edu.cn; huangl@ouc.edu.cn;
   zhangwenfeng@stu.ouc.edu.cn; weizhigiang@ouc.edu.cn
RI wei, zhiqiang/M-8868-2013
OI Huang, Lei/0000-0003-4087-3677
FU National Natural Science Foundation of China [61872326, 61672475];
   Shandong Provincial Natural Science Foundation [ZR2019MF044]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61872326, No.61672475); Shandong Provincial Natural Science
   Foundation (ZR2019MF044).
CR Aliyu A.L., 2019, P 2019 IEEE 18 INT S, P1
   Aljubairy A, 2020, COMPUTING, V102, P2025, DOI 10.1007/s00607-020-00794-w
   Bak S, 2017, PROC CVPR IEEE, P1571, DOI 10.1109/CVPR.2017.171
   Banerjee S, 2019, 2019 IEEE INTERNATIONAL ELECTROMAGNETICS AND ANTENNA CONFERENCE (IEMANTENNA), P8, DOI [10.1109/iemantenna.2019.8928920, 10.1109/IEMANTENNA.2019.8928920]
   Deng C, 2018, IEEE T IMAGE PROCESS, V27, P3893, DOI 10.1109/TIP.2018.2821921
   Dong XY, 2018, PROC CVPR IEEE, P379, DOI 10.1109/CVPR.2018.00047
   Dong XY, 2019, IEEE T IMAGE PROCESS, V28, P518, DOI 10.1109/TIP.2018.2867747
   Esmaeilpour M, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105912
   Foerster KT, 2019, 2019 IEEE 18TH INTERNATIONAL SYMPOSIUM ON NETWORK COMPUTING AND APPLICATIONS (NCA), P19, DOI 10.1109/nca.2019.8935035
   Gao F, 2024, MULTIMED TOOLS APPL, V83, P15061, DOI 10.1007/s11042-020-09361-z
   Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Guo ZQ, 2018, IEEE IPCCC
   Han JG, 2012, IEEE T CONSUM ELECTR, V58, P255, DOI 10.1109/TCE.2012.6227420
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hermans Alexander, 2017, ARXIV170307737
   Huang Hsin-Yuan, 2018, CoRR
   Kingma DP, 2014, ADV NEUR IN, V27
   Kipf TN, 2017, INT C LEARN REPR
   Li JW, 2018, INT J COMPUT VISION, V126, P855, DOI 10.1007/s11263-018-1075-5
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu JL, 2019, IEEE ACCESS, V7, P114021, DOI 10.1109/ACCESS.2019.2933910
   Liu XC, 2018, IEEE T MULTIMEDIA, V20, P645, DOI 10.1109/TMM.2017.2751966
   Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI [10.1109/ICCVW.2017.361, 10.1109/ICCV.2017.478]
   Luan SZ, 2018, IEEE T IMAGE PROCESS, V27, P4357, DOI 10.1109/TIP.2018.2835143
   Ma F, 2017, PR MACH LEARN RES, V70
   Ma HD, 2018, IEEE MULTIMEDIA, V25, P76, DOI 10.1109/MMUL.2017.265091429
   Masoumi A, 2020, APPL SOFT COMPUT, V88, DOI 10.1016/j.asoc.2019.105979
   Nie J, 2019, IEEE ACCESS, V7, P15007, DOI 10.1109/ACCESS.2019.2894347
   Noroozi V, 2018, IEEE INT CONF BIG DA, P56, DOI 10.1109/BigData.2018.8622015
   Rasmus A, 2015, ADV NEUR IN, V28
   Raz O, 2019, 2019 IEEE 18TH INTERNATIONAL SYMPOSIUM ON NETWORK COMPUTING AND APPLICATIONS (NCA), P69, DOI 10.1109/nca.2019.8935013
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Roy A, 2018, J CIRCUIT SYST COMP, V27, DOI 10.1142/S0218126618501396
   Roy A, 2016, SIGNAL PROCESS, V128, P262, DOI 10.1016/j.sigpro.2016.04.007
   Salimans T, 2016, ADV NEUR IN, V29
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tan SB, 2018, IEEE T CIRC SYST VID, V28, P356, DOI 10.1109/TCSVT.2016.2555739
   Nguyen TB, 2019, MULTIMED TOOLS APPL, V78, P33939, DOI 10.1007/s11042-019-08183-y
   Wu Y, 2019, IEEE T IMAGE PROCESS, V28, P2872, DOI 10.1109/TIP.2019.2891895
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Yang QZ, 2019, IEEE INT CON MULTI, P1096, DOI 10.1109/ICME.2019.00192
   Ye M, 2017, IEEE I CONF COMP VIS, P5152, DOI 10.1109/ICCV.2017.550
   Zhang WF, 2019, LECT NOTES COMPUT SC, V11296, P302, DOI 10.1007/978-3-030-05716-9_25
   Zhang X., 2020, NEURAL COMPUT APPL, P1
   Zhedong Zheng, 2017, ACM Transactions on Multimedia Computing, Communications and Applications, V14, DOI 10.1145/3159171
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
NR 51
TC 1
Z9 1
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 1787
EP 1809
DI 10.1007/s11042-021-11420-y
EA OCT 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000706943000001
DA 2024-07-18
ER

PT J
AU Qureshi, KN
   Alhudhaif, A
   Arshad, N
   Kalsoom, U
   Jeon, G
AF Qureshi, Kashif Naseer
   Alhudhaif, Adi
   Arshad, Noman
   Kalsoom, Um
   Jeon, Gwanggil
TI Data analysis based dynamic prediction model for public security in
   internet of multimedia things networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IoMT; Technology; Network; Prediction; Security; Data
AB Internet of Multimedia Things (IoMT) has gained popularity due to its immersive growth and real-time applications range from smart health to smart transportation systems. These systems always have various threats related to security breaches and privacy. With the passage of time, all types of cybercrimes and terrorism activities and its planning were initiated by using these networks and technologies. Terrorist attacks are unavoidable because of well-organized and well-planned attack planning. The all the data among these threat actors transmitted by using IoMT sensors and devices. Therefore, there is a need to analyze this type of data and predict the terrorist activities for in-time decision making. This paper presents a complete overview of existing models for such type of data and proposes a Terrorist Attacks Internet of Multimedia Things (TA-IoMT) model and a predictive model for public security in IoMT networks. The proposed model provides more effective data handling, cloud storage data management, and prediction to control and detect these kinds of activities. The results show an average of 89% accuracy, 0.73% sensitivity, and 0.92% specificity as compared to existing solutions.
C1 [Qureshi, Kashif Naseer; Arshad, Noman; Kalsoom, Um] Bahria Univ, Dept Comp Sci, Islamabad, Pakistan.
   [Alhudhaif, Adi] Prince Sattam Bin Abdulaziz Univ, Coll Comp Engn & Sci Al Kharj, Dept Comp Sci, POB 151, Al Kharj 11942, Saudi Arabia.
   [Jeon, Gwanggil] Incheon Natl Univ, Dept Embedded Syst Engn, Incheon, South Korea.
C3 Prince Sattam Bin Abdulaziz University; Incheon National University
RP Jeon, G (corresponding author), Incheon Natl Univ, Dept Embedded Syst Engn, Incheon, South Korea.
EM kashifnq@gmail.com; a.alhudhaif@psau.edu.sa; Nomanarshad5602@gmail.com;
   kalsoomattique@gmail.com; gjeon@inu.ac.kr
RI Alhudhaif, Adi/AAF-1937-2021; Qureshi, Kashif Naseer/HJB-2945-2022;
   Alhudhaif, Adi/AAN-6541-2021
OI Qureshi, Kashif Naseer/0000-0003-3045-8402; Alhudhaif,
   Adi/0000-0002-7201-6963
CR Akgun I, 2010, EXPERT SYST APPL, V37, P3561, DOI 10.1016/j.eswa.2009.10.035
   Aladi HB, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES FOR SMART NATION (SMARTTECHCON), P1010, DOI 10.1109/SmartTechCon.2017.8358523
   Alanazi HO, 2018, IRISH J MED SCI, V187, P501, DOI 10.1007/s11845-017-1655-3
   [Anonymous], 2013, GLOB TERR DAT
   Bahga A, 2015, COMPUTER, V48, P50, DOI 10.1109/MC.2015.46
   Berlusconi G, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154244
   Devi RDH., 2016, Int J Eng Adv Technol, V7, P93
   Dugan EMGLL, 2020, GLOBAL TERRORISM DAT
   Fatih Ozgul ZE, PREDICTION UNSOLVED
   Garg S, 2020, FUTURE GENER COMP SY, V104, P105, DOI 10.1016/j.future.2019.09.038
   Garg S, 2019, IEEE T NETW SERV MAN, V16, P924, DOI 10.1109/TNSM.2019.2927886
   Guo GD, 2003, LECT NOTES COMPUT SC, V2888, P986
   Hollywood J.S., 2018, Using social media and social network analysis in law enforcement
   Jiang LX, 2009, IEEE T KNOWL DATA EN, V21, P1361, DOI 10.1109/TKDE.2008.234
   Jin SZ, 2016, 2016 IEEE 15TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC), P403, DOI 10.1109/ICCI-CC.2016.7862068
   Kumar V, 2018, INT C SOFTW ENG DEF, P146
   Lin ZK, 2020, CHIN CONT DECIS CONF, P3622, DOI 10.1109/CCDC49329.2020.9164626
   Liu Q, 2017, P IEEE C COMPUTER VI, P1329
   Meng X, 2019, COMPUT ELECTR ENG, V77, P120, DOI 10.1016/j.compeleceng.2019.05.013
   Nuti G., 2019, STAT-US, V1050, P11
   Olajide F, 2016, J ENG SCI TECHNOL, V11, P1629
   Qureshi KN, 2021, COMPUT NETW, V184, DOI 10.1016/j.comnet.2020.107647
   Stephenson N, 2019, CURR DRUG METAB, V20, P185, DOI 10.2174/1389200219666180820112457
   Teira D, 2007, HIST POLIT ECON, V39, P511, DOI 10.1215/00182702-2007-020
   Toure I, 2016, 2016 IEEE S TECHN HO, P1, DOI DOI 10.1109/THS.2016.7568906
   Uddin MI, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/1373087
   Zamin Norshuhani, 2010, Proceedings of 2010 International Symposium on Information Technology (ITSim 2010), P1211, DOI 10.1109/ITSIM.2010.5561483
NR 27
TC 4
Z9 4
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19705
EP 19721
DI 10.1007/s11042-021-11462-2
EA SEP 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000696143500005
DA 2024-07-18
ER

PT J
AU Sharma, D
   Selwal, A
AF Sharma, Deepika
   Selwal, Arvind
TI An intelligent approach for fingerprint presentation attack detection
   using ensemble learning with improved local image features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fingerprint biometrics; Cyber physical systems (CPS); Spoof attacks;
   Presentation attack detection (PAD); Ensemble; AdaBoost
ID LIVENESS DETECTION; TEXTURE CLASSIFICATION; SYSTEMS; SCALE
AB The fingerprint-based authentication systems are being extensively deployed as security tool for providing access to the critical Cyber Physical Systems (CPS). However, this rapid relocation to fingerprint-based recognition poses many security concerns that are primarily due to presentation or spoofing attacks on sensor module. To alleviate these attacks, presentation attack detection (PAD) mechanisms are developed that mainly rely on micro-textural properties of the fingerprint images. In this paper, we expound a novel intelligent fingerprint PAD (IFPAD) approach for securing typical CPS that exploits two micro-textural features from an image. We propose a new Local Adaptive Binary Patterns (LABP) descriptor that extracts more refined local information by using dynamically adapted threshold. Moreover, to augment more discriminative power, the Uniform Local Binary patterns (ULBP) descriptor is coalesced with our LABP feature. To yield better detection accuracy, an Adaptive Boosting (AdaBoost) ensemble is created on two base estimators using Support Vector Machine (SVM) that learns LABP and ULBP features. The IFPAD is experimentally evaluated on three benchmark datasets; LivDet 2009, LivDet 2011, and LivDet 2013 where an average classification error rate (ACER) of 4.23%, 3.83% and 3.57% is achieved respectively. In addition, the promising performance of IFPAD in case of cross-database and cross-sensor scenario confirms its good generalization capabilities in unknown environment. Besides, overall analysis of the proposed IFPAD demonstrates superiority as compared to both handcrafted and deep learning-based state-of-the-art PAD methods.
C1 [Sharma, Deepika; Selwal, Arvind] Cent Univ Jammu, Dept Comp Sci & Informat Technol, Jammu 181143, Jammu & Kashmir, India.
C3 Central University of Jammu
RP Sharma, D (corresponding author), Cent Univ Jammu, Dept Comp Sci & Informat Technol, Jammu 181143, Jammu & Kashmir, India.
EM sharmadeepika749@gmail.com
RI Selwal, Arvind/HTR-1625-2023
OI Selwal, Arvind/0000-0002-1075-6966
CR Abhyankar A, 2009, PATTERN RECOGN, V42, P452, DOI 10.1016/j.patcog.2008.06.012
   Agarwal D, 2020, J KING SAUD UNIV-COM, DOI DOI 10.1016/J.JKSUCI.2020.10.003
   Agarwal S, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2019.113160
   Alshdadi AA, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102039
   [Anonymous], 2017, IJCCI
   [Anonymous], 2002, Inf. Secur. Tech. Rep., DOI DOI 10.1016/S1363-4127(02)00407-7
   Baldisserra D, 2006, LECT NOTES COMPUT SC, V3832, P265
   Chattopadhyay A, 2017, DES AUT TEST EUROPE, P1104, DOI 10.23919/DATE.2017.7927154
   Chugh T, 2021, IEEE T INF FOREN SEC, V16, P42, DOI 10.1109/TIFS.2020.2990789
   Chugh T, 2019, INT CONF BIOMETR, DOI 10.1109/icb45273.2019.8987374
   Chugh T, 2018, IEEE T INF FOREN SEC, V13, P2190, DOI 10.1109/TIFS.2018.2812193
   Chugh T, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P581, DOI 10.1109/BTAS.2017.8272745
   Drahansky M, 2006, 2006 IEEE INFORMATION ASSURANCE WORKSHOP, P42, DOI 10.1109/IAW.2006.1652075
   Dubey RK, 2016, IEEE T INF FOREN SEC, V11, P1461, DOI 10.1109/TIFS.2016.2535899
   Gajawada R, 2019, INT CONF BIOMETR
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Galbally J, 2012, FUTURE GENER COMP SY, V28, P311, DOI 10.1016/j.future.2010.11.024
   Galbally Javier, 2019, Advances in Computer Vision and Pattern Recognition, P3, DOI DOI 10.1007/978-3-319
   Ghiani L, 2017, IET BIOMETRICS, V6, P224, DOI 10.1049/iet-bmt.2016.0007
   Ghiani L, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS)
   Ghiani L, 2013, INT CONF BIOMETR, DOI 10.1109/ICB.2013.6613027
   Ghiani L, 2012, INT C PATT RECOG, P537
   González-Soler LJ, 2021, IEEE ACCESS, V9, P5806, DOI 10.1109/ACCESS.2020.3048756
   Gragnaniello D, 2014, ELECTRON LETT, V50, P439, DOI 10.1049/el.2013.4044
   Gragnaniello Diego, 2013, Proceedings of the 2013 IEEE Workshop on Biometric Measurements and Systems for Security and Medical Applications (BIOMS), P46, DOI 10.1109/BIOMS.2013.6656148
   Gragnaniello D, 2015, PATTERN RECOGN, V48, P1050, DOI 10.1016/j.patcog.2014.05.021
   Grosz SA, 2019, COMPUT VIS PATTERN R
   Jain A, 2007, IEEE T PATTERN ANAL, V29
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jain AK, 2006, IEEE T INF FOREN SEC, V1, P125, DOI 10.1109/TIFS.2006.873653
   Jian W, 2021, IEEE ACCESS, V9, P2229, DOI 10.1109/ACCESS.2020.3047723
   Jiang YJ, 2018, J ELECTR COMPUT ENG, V2018, DOI 10.1155/2018/1539298
   Jung HY, 2018, ELECTRON LETT, V54, P564, DOI 10.1049/el.2018.0621
   Kim W, 2017, IEEE SIGNAL PROC LET, V24, P51, DOI 10.1109/LSP.2016.2636158
   Kolberg J, 2020, ADV COMPUT VIS PATT, P435, DOI 10.1007/978-3-030-27731-4_14
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee JE, 2008, 2008 BIOMETRICS SYMPOSIUM (BSYM), P1, DOI [10.1109/PLASMA.2008.4591032, 10.1109/BSYM.2008.4655515]
   Lu MY, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATIONS (CSA), P77, DOI 10.1109/CSA.2015.79
   Manivanan N, 2010, ELECTRON LETT, V46, P1268, DOI 10.1049/el.2010.1549
   Marasco E, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2617756
   Marcialis GL, 2009, LECT NOTES COMPUT SC, V5716, P12, DOI 10.1007/978-3-642-04146-4_4
   Martinsen OG, 2007, IEEE T BIO-MED ENG, V54, P891, DOI 10.1109/TBME.2007.893472
   Moon YS, 2005, ELECTRON LETT, V41, P1112, DOI 10.1049/el:20052577
   Nikam SB, 2009, NEUROCOMPUTING, V72, P2491, DOI 10.1016/j.neucom.2008.11.003
   Nogueira RF, 2016, IEEE T INF FOREN SEC, V11, P1206, DOI 10.1109/TIFS.2016.2520880
   Nogueira RF, 2014, 2014 IEEE WORKSHOP ON BIOMETRIC MEASUREMENTS AND SYSTEMS FOR SECURITY AND MEDICAL APPLICATIONS (BIOMS) PROCEEDINGS, P22, DOI 10.1109/BIOMS.2014.6951531
   Ojala T, 2000, LECT NOTES COMPUT SC, V1842, P404
   Park E., 2016, BIOSIG LECT NOTES IN, V2016, P2016
   Park EY, 2019, IMMUNOPHARM IMMUNOT, V41, P477, DOI 10.1080/08923973.2019.1628044
   Ratha NK, 2001, LECT NOTES COMPUT SC, V2091, P223
   Reddy PV, 2008, IEEE T BIOMED CIRC S, V2, P328, DOI 10.1109/TBCAS.2008.2003432
   Sharma RP, 2019, VISUAL COMPUT, V35, P1393, DOI 10.1007/s00371-018-01618-x
   Shi, 2018, IEEE T SYST MAN CYBE
   Toosi A, 2017, IEEE ACCESS, V5, P23695, DOI 10.1109/ACCESS.2017.2763419
   Topi M, 2000, INT C PATT RECOG, P935, DOI 10.1109/ICPR.2000.903698
   Uliyan DM, 2020, ENG SCI TECHNOL, V23, P264, DOI 10.1016/j.jestch.2019.06.005
   Wang CG, 2015, LECT NOTES COMPUT SC, V9428, P241, DOI 10.1007/978-3-319-25417-3_29
   Wei-Yun Y, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P962, DOI 10.1109/ICARCV.2008.4795648
   Xia ZH, 2017, SIGNAL IMAGE VIDEO P, V11, P381, DOI 10.1007/s11760-016-0936-z
   Yambay D., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P208, DOI 10.1109/ICB.2012.6199810
   Yuan CS, 2020, IEEE T COGN DEV SYST, V12, P461, DOI 10.1109/TCDS.2019.2920364
   Yuan CS, 2019, SOFT COMPUT, V23, P5157, DOI 10.1007/s00500-018-3182-1
   Yuan CS, 2019, IEEE ACCESS, V7, P26953, DOI 10.1109/ACCESS.2019.2901235
   Yuan CS, 2018, J INTERNET TECHNOL, V19, P1499, DOI 10.3966/160792642018091905021
   Zhang YL, 2020, IEEE ACCESS, V8, P183391, DOI 10.1109/ACCESS.2020.3027846
   Zhang YL, 2020, IEEE ACCESS, V8, P84141, DOI 10.1109/ACCESS.2020.2990909
   Zhang YL, 2019, IEEE ACCESS, V7, P91476, DOI 10.1109/ACCESS.2019.2927357
   Zhang YL, 2014, LECT NOTES COMPUT SC, V8833, P191, DOI 10.1007/978-3-319-12484-1_21
NR 68
TC 10
Z9 10
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22129
EP 22161
DI 10.1007/s11042-021-11254-8
EA SEP 2021
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000692075600004
DA 2024-07-18
ER

PT J
AU Khan, S
   Singh, YV
   Rai, AK
AF Khan, Shadab
   Singh, Yash Veer
   Rai, Arun Kumar
TI An efficient edge preserving universal noise removal algorithm using
   kernel ridge regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Universal noise; Global characteristics; Pixel classification; Image
   denoising
ID BILATERAL FILTER; IMPULSE NOISE; MEDIAN FILTER
AB Images captured by cameras are sometimes contaminated either during acquisition or transmission. Therefore, a preprocessing step is required which reduces noise from images. In this paper, a novel and efficient edge preserving universal noise removal algorithm is proposed which exploits both the local and global characteristics of the neighboring non-corrupted pixels. In the proposed algorithm, corrupted pixels are detected by robust outlying ratio (ROR) and replaced with the weighted sum (local characteristics) of the neighboring non-corrupted pixels in 3 x 3 window and these weights are obtained by solving the kernel ridge regression (KRR) which uses the global mean and covariance (global characteristics). Extensive experimental results demonstrate that our algorithm has better noise removal capability in terms of both objective and subjective evaluation as compared to existing denoising algorithms.
C1 [Khan, Shadab] Jamia Millia Islamia, Fac Engn & Technol, Comp Sci & Technol Res Grp, New Delhi, India.
   [Singh, Yash Veer] ABES Engn Coll, Dept Informat Technol, Ghaziabad 201009, UP, India.
   [Rai, Arun Kumar] ITS Engn Coll, Dept Comp Sci & Engn, Greater Noida, UP, India.
C3 Jamia Millia Islamia
RP Singh, YV (corresponding author), ABES Engn Coll, Dept Informat Technol, Ghaziabad 201009, UP, India.
EM shadab1212@gmail.com; yashveersingh85@gmail.com; arunrai.dei@gmail.com
CR Abreu E, 1996, IEEE T IMAGE PROCESS, V5, P1012, DOI 10.1109/83.503916
   Akkoul S, 2008, LECT NOTES COMPUT SC, V5099, P163, DOI 10.1007/978-3-540-69905-7_19
   Akkoul S, 2010, IEEE SIGNAL PROC LET, V17, P587, DOI 10.1109/LSP.2010.2048646
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chen BH, 2020, IEEE SIGNAL PROC LET, V27, P1670, DOI 10.1109/LSP.2020.3024990
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Crnojevic V, 2004, IEEE SIGNAL PROC LET, V11, P589, DOI 10.1109/LSP.2004.830117
   Dong YQ, 2007, IEEE T IMAGE PROCESS, V16, P1112, DOI 10.1109/TIP.2006.891348
   Dong YQ, 2007, IEEE SIGNAL PROC LET, V14, P193, DOI 10.1109/LSP.2006.884014
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   Gonzales RC, 2010, DIGITAL IMAGE PROCES, P613
   Katkovnik V, 2010, INT J COMPUT VISION, V86, P1, DOI 10.1007/s11263-009-0272-7
   Lin CH, 2010, IEEE T IMAGE PROCESS, V19, P2307, DOI 10.1109/TIP.2010.2047906
   Lin Y, 2020, CROSS STRAIT RAD SCI, DOI 10.1109/CSRSWTC50769.2020.9372617
   Liu XM, 2011, IEEE T IMAGE PROCESS, V20, P3455, DOI 10.1109/TIP.2011.2150234
   Luo WB, 2005, IEICE T FUND ELECTR, VE88A, P2579, DOI 10.1093/ietfec/e88-a.10.2579
   Nair P, 2020, INT CONF ACOUST SPEE, P2078, DOI [10.1109/icassp40776.2020.9053275, 10.1109/ICASSP40776.2020.9053275]
   SUN T, 1994, PATTERN RECOGN LETT, V15, P341, DOI 10.1016/0167-8655(94)90082-5
   Thaipanich T, 2010, IEEE T CONSUM ELECTR, V56, P2623, DOI 10.1109/TCE.2010.5681149
   Toh KKV, 2010, IEEE T CONSUM ELECTR, V56, P2560, DOI 10.1109/TCE.2010.5681141
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Xiong B, 2012, IEEE T IMAGE PROCESS, V21, P1663, DOI 10.1109/TIP.2011.2172804
   Yu HC, 2011, IEEE T CONSUM ELECTR, V57, P682, DOI 10.1109/TCE.2011.5955208
   Zheng JY, 2020, IET IMAGE PROCESS, V14, P1539, DOI 10.1049/iet-ipr.2019.1591
NR 24
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19863
EP 19877
DI 10.1007/s11042-021-11274-4
EA AUG 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000690817500001
DA 2024-07-18
ER

PT J
AU Soltani, R
   Pashazadeh, S
AF Soltani, Reza
   Pashazadeh, Saeid
TI A lightweight improvement of PeDAAC protocol for 6LoWPAN in the Internet
   of Things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of Things; IPV6; 6LoWPAN; Privacy; Anonymity; Congruence
   relationship
ID SECURITY; SCHEME; CLOUD
AB The transfer of IPv6 packets over the low-power personal area network (6LoWPAN) using IPv6 routing protocol enables small devices with limited processing power to transmit wirelessly. Privacy enabled disjoint and dynamic address auto-configuration (PeDAAC) is one of the 6LoWPAN protocols designed to ensure the privacy of the nodes by changing IPv6 and MAC addresses. One of the main purposes of this protocol is to keep the identity of the sender and receiver secret, so it can have different applications, such as hiding the identity of patients in the hospital or military applications to send data anonymously. PeDAAC is a dynamic protocol whose purpose is to create a conflict-free, auto-configuring IPv6 addressing scheme, eliminating the need for duplicate address detection. It results in lower latency and optimal communication costs, and the IPV6 addresses of each node will be unique. Two successful attacks on the PeDAAC protocol are discussed in this paper. An adversary can attack the availability of the nodes and can cause a denial of service attack. Also, by detecting the node's identity, changes over time can gather more messages, which increases the likelihood of successful eavesdropping. The greatest common divisor-based lightweight improvement (GCDLi) is a proposed lightweight extension of this paper to PeDAAC protocol to protect against these attacks. Beyond that, it counteracts two types of security threats: eavesdropping and denial of service attack. The proposed extension of the protocol improves the privacy and anonymity of the nodes. The time complexity of the proposed method is theta(logn), and due to the limited range of input values (maximum 16 bit), it is considered a lightweight improvement.
C1 [Soltani, Reza] Univ Southern Denmark, Maersk McKinney Moller Inst, Odense, Denmark.
   [Pashazadeh, Saeid] Univ Tabriz, Fac Elect & Comp Engn, 29th Bahman Blvd, Tabriz 5166616471, East Azerbaijan, Iran.
C3 University of Southern Denmark; University of Tabriz
RP Pashazadeh, S (corresponding author), Univ Tabriz, Fac Elect & Comp Engn, 29th Bahman Blvd, Tabriz 5166616471, East Azerbaijan, Iran.
EM resol@mmmi.sdu.dk; pashazadeh@tabrizu.ac.ir
RI Soltani, Reza/AAI-7856-2021; Pashazadeh, Saeid/ABB-9656-2021;
   Pashazadeh, Saeid/Q-5311-2017
OI Soltani, Reza/0000-0003-4585-1602; Pashazadeh, Saeid/0000-0002-8949-9180
CR Al-Ani A, 2020, SADHANA-ACAD P ENG S, V45, DOI 10.1007/s12046-019-1244-4
   Alaba FA, 2017, J NETW COMPUT APPL, V88, P10, DOI 10.1016/j.jnca.2017.04.002
   Alshahrani M, 2019, J INF SECUR APPL, V45, P156, DOI 10.1016/j.jisa.2019.02.003
   [Anonymous], 2011, IPV6 LOW POWER WPAN
   [Anonymous], 2014, Int. J. Comput. Appl.
   Aufner P, 2020, INT J INF SECUR, V19, P3, DOI 10.1007/s10207-019-00445-y
   Bilal M, 2017, CLUSTER COMPUT, V20, P2779, DOI 10.1007/s10586-017-0853-0
   Chanal PM, 2020, WIRELESS PERS COMMUN, V115, P1667, DOI 10.1007/s11277-020-07649-9
   Gao LJ, 2020, WIRELESS PERS COMMUN, V115, P1603, DOI 10.1007/s11277-020-07645-z
   Glissaa G, 2019, AD HOC NETW, V82, P100, DOI 10.1016/j.adhoc.2018.01.013
   Granjal J, 2010, GLOB TELECOMM CONF
   Hussen HR, 2013, INT CONF UBIQ FUTUR, P246, DOI 10.1109/ICUFN.2013.6614820
   Jiang H, 2015, FUTURE GENER COMP SY, V49, P133, DOI 10.1016/j.future.2014.11.009
   Joshitta R.S.M., 2016, Int. J. Inf. Technol. Mech. Eng., V2, P1
   Kanuparthi A., 2013, CYCAR 13 P 2013 ACM, P61
   Kouicem DE, 2018, COMPUT NETW, V141, P199, DOI 10.1016/j.comnet.2018.03.012
   Li J, 2018, COMPUT SECUR, V72, P1, DOI 10.1016/j.cose.2017.08.007
   Li LS, 2018, TSINGHUA SCI TECHNOL, V23, P13, DOI 10.26599/TST.2018.9010020
   Lohachab A, 2019, J INF SECUR APPL, V46, P1, DOI 10.1016/j.jisa.2019.02.005
   Lokulwar PP, 2017, 2017 INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC), P721, DOI 10.1109/I-SMAC.2017.8058273
   Lynn B., EUCLIDS ALGORITHM
   Mavani M, 2020, PEER PEER NETW APPL, V13, P333, DOI 10.1007/s12083-019-00792-6
   Mavani M, 2018, AD HOC NETW, V79, P72, DOI 10.1016/j.adhoc.2018.06.010
   Mavani M, 2017, COMPUT SECUR, V70, P95, DOI 10.1016/j.cose.2017.05.004
   Mayzaud A., 2016, A Taxonomy of Attacks in RPL-based Internet of Things, V18, P459
   Newsome J, 2004, IPSN '04: THIRD INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING IN SENSOR NETWORKS, P259
   Puthal D, 2016, IEEE CLOUD COMPUT, V3, P64, DOI 10.1109/MCC.2016.63
   Rana S, 2020, MULTIMED TOOLS APPL, V79, P20319, DOI 10.1007/s11042-020-08683-2
   Raoof A, 2019, IEEE COMMUN SURV TUT, V21, P1582, DOI 10.1109/COMST.2018.2885894
   Sun ZZ, 2018, IEEE T CIRC SYST VID, V28, P193, DOI 10.1109/TCSVT.2016.2605045
   Tan YA, 2018, J NETW COMPUT APPL, V107, P69, DOI 10.1016/j.jnca.2018.01.011
   Vishwakarma R, 2020, TELECOMMUN SYST, V73, P3, DOI 10.1007/s11235-019-00599-z
   Yang YC, 2017, IEEE INTERNET THINGS, V4, P1250, DOI 10.1109/JIOT.2017.2694844
   Yao XX, 2015, FUTURE GENER COMP SY, V49, P104, DOI 10.1016/j.future.2014.10.010
   Zarpelao BB, 2017, J NETW COMPUT APPL, V84, P25, DOI 10.1016/j.jnca.2017.02.009
   Zhang XS, 2018, INFORM SCIENCES, V445, P66, DOI 10.1016/j.ins.2018.03.007
   Zhao K, 2013, 2013 9TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P663, DOI 10.1109/CIS.2013.145
   Zheng JM, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9212-2
   Zhu HF, 2017, FUTURE GENER COMP SY, V73, P106, DOI 10.1016/j.future.2017.01.031
NR 39
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 31467
EP 31486
DI 10.1007/s11042-021-11236-w
EA AUG 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000690516400003
DA 2024-07-18
ER

PT J
AU Motrenko, A
   Simchuk, E
   Khairullin, R
   Inyakin, A
   Kashirin, D
   Strijov, V
AF Motrenko, Anastasia
   Simchuk, Egor
   Khairullin, Renat
   Inyakin, Andrey
   Kashirin, Daniil
   Strijov, Vadim
TI Continuous physical activity recognition for intelligent labour
   monitoring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Time series classification; Wearable sensing; Human activity
   recognition; Labour monitoring
ID CLASSIFICATION
AB The paper addresses the problem of human activity recognition based on the data from wearable sensors. Human activity recognition depends on a wide context of actions. Activities can not be recognised from the local shape of sensor signals only. We propose a solution to the problem of human activity recognition applied to labour monitoring. The solution is based on the hierarchical representation of activities as sets of low-level actions. Viewing activities as sequences of actions allows to explore activities in more condensed representation in comparison to time series. The hierarchical representation provides an interpretable description of studied activities in terms of actions. To obtain this hierarchical representation one has to solve the problem of low-level action recognition first. The problem of action recognition, though widely studied, requires overcoming a number of difficulties. Firstly, we show that using noise-aware self-learning methods can significantly improve classification quality in human activity recognition. Since time series are human-labeled, errors are inevitable and abundant. Noisy labels significantly worsen classification quality. Noise-aware learning allows to relax requirements for labeling precision and lower annotation costs. Secondly, we propose an algorithm of automatic pattern selection to generate low-level description as an alternative in an unsupervised manner. The proposed method is based on Eamonn Keogh's time series indexing methods. We introduce local PCA projections to make the method more robust to spatial rotations of a wearable device.
C1 [Motrenko, Anastasia; Simchuk, Egor; Khairullin, Renat; Inyakin, Andrey; Kashirin, Daniil; Strijov, Vadim] Forecsys LLC, Moscow, Russia.
RP Motrenko, A (corresponding author), Forecsys LLC, Moscow, Russia.
EM motrenko@forecsys.ru; egorsimchuk@forecsys.ru; khairullin@forecsys.ru;
   inyakin@forecsys.ru; kashirin@forecsys.ru; strjov@phystech.edu
RI Strijov, Vadim Victor/A-4786-2011; Motrenko, Anastasia P/J-2727-2014
OI Motrenko, Anastasia P/0000-0002-5110-1667; Strijov,
   Vadim/0000-0002-2194-8859
CR [Anonymous], 2004, P INT C VERY LARGE D
   Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bevilacqua A., 2018, MACHINE LEARNING KNO, P541
   Blanke Ulf, 2010, 2010 8th IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops), P18, DOI 10.1109/PERCOMW.2010.5470597
   Bulling A, 2008, LECT NOTES COMPUT SC, V5013, P19, DOI 10.1007/978-3-540-79576-6_2
   Fawaz HI, 2018, IEEE INT CONF BIG DA, P1367, DOI 10.1109/BigData.2018.8621990
   Figo D, 2010, PERS UBIQUIT COMPUT, V14, P645, DOI 10.1007/s00779-010-0293-9
   Fontana J., 2014, Wearable Sensors: Fundamentals, Implementation and Applications, P591
   Grandvalet Y., 2005, CAP, V367, P281
   Hammerla N.Y., 2016, P 25 INT JOINT C ART
   Hausdorff JM, 1996, J APPL PHYSIOL, V80, P1448, DOI 10.1152/jappl.1996.80.5.1448
   Hu Bing., 2013, International Conference on Data Mining SDM, P578
   Ignatov AD, 2016, MULTIMED TOOLS APPL, V75, P7257, DOI 10.1007/s11042-015-2643-0
   Iwata T, 2020, ARXIV200914379
   Jansi R, 2018, MULTIMED TOOLS APPL, V77, P31261, DOI 10.1007/s11042-018-6117-z
   KANG WJ, 1995, IEEE T BIO-MED ENG, V42, P777
   Karim F, 2018, IEEE ACCESS, V6, P1662, DOI 10.1109/ACCESS.2017.2779939
   Khan AM, 2010, IEEE T INF TECHNOL B, V14, P1166, DOI 10.1109/TITB.2010.2051955
   Kim E, 2010, IEEE PERVAS COMPUT, V9, P48, DOI 10.1109/MPRV.2010.7
   Kolen JF, 2009, A Field Guide to Dynamical Recurrent Networks, DOI [DOI 10.1109/9780470544037.CH14, 10.1109/9780470544037]
   Vinh LT, 2011, APPL INTELL, V35, P226, DOI 10.1007/s10489-010-0216-5
   Liao L, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P773
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Lundberg S.M., 2019, ARXIV180203888V3
   Minnen D, 2006, TENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P11
   Motrenko A, 2016, IEEE J BIOMED HEALTH, V20, P1466, DOI 10.1109/JBHI.2015.2466440
   Mysore P., 2005, AAAI, V5, P1541
   Nyan MN, 2006, J BIOMECH, V39, P2647, DOI 10.1016/j.jbiomech.2005.08.014
   Ordóñez FJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010115
   Patterson DJ, 2005, NINTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P44, DOI 10.1109/ISWC.2005.22
   Preece SJ, 2009, IEEE T BIO-MED ENG, V56, P871, DOI 10.1109/TBME.2008.2006190
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Sun J, 2018, J SENSORS, V2018, DOI 10.1155/2018/8580959
   Huynh T, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P10
   van Kasteren T, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P1, DOI 10.1145/1409635.1409637
   Vaswani A, 2020, ARXIV200914379
   Wang HJ, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/2132138
   Wang ZG, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3939
   Ward JA, 2006, IEEE T PATTERN ANAL, V28, P1553, DOI 10.1109/TPAMI.2006.197
   Zhang M., 2011, P BODYNETS, P92
NR 42
TC 1
Z9 1
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4877
EP 4895
DI 10.1007/s11042-021-11288-y
EA AUG 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000688418200002
DA 2024-07-18
ER

PT J
AU Kumari, P
   Seeja, KR
AF Kumari, Punam
   Seeja, K. R.
TI An optimal feature enriched region of interest (ROI) extraction for
   periocular biometric system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Periocular biometrics; Region of interest; Convolutional neural network;
   COVID-19
ID RECOGNITION; IRIS
AB With the onset of COVID-19 pandemic, wearing of face mask became essential and the face occlusion created by the masks deteriorated the performance of the face biometric systems. In this situation, the use of periocular region (region around the eye) as a biometric trait for authentication is gaining attention since it is the most visible region when masks are used. One important issue in periocular biometrics is the identification of an optimal size periocular ROI which contains enough features for authentication. The state of the art ROI extraction algorithms use fixed size rectangular ROI calculated based on some reference points like center of the iris or centre of the eye without considering the shape of the periocular region of an individual. This paper proposes a novel approach to extract optimum size periocular ROIs of two different shapes (polygon and rectangular) by using five reference points (inner and outer canthus points, two end points and the midpoint of eyebrow) in order to accommodate the complete shape of the periocular region of an individual. The performance analysis on UBIPr database using CNN models validated the fact that both the proposed ROIs contain enough information to identify a person wearing face mask.
C1 [Kumari, Punam; Seeja, K. R.] Indira Gandhi Delhi Tech Univ Women, Dept Comp Sci & Engn, Delhi, India.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW)
RP Seeja, KR (corresponding author), Indira Gandhi Delhi Tech Univ Women, Dept Comp Sci & Engn, Delhi, India.
EM punam_taurus@hotmail.com; seeja@igdtuw.ac.in
RI K.R., Seeja/AHA-1124-2022
OI K.R., Seeja/0000-0001-6618-6758
CR Agarwal S, 2019, UNLEASHING POWER DIS
   Ahmed NU, 2017, PATTERN RECOGN LETT, V91, P11, DOI 10.1016/j.patrec.2017.03.003
   Bakshi S, 2013, BIOMED RES INT, V2013, DOI 10.1155/2013/481431
   Bharadwaj Samarth., 2010, 2010 4 IEEE INT C BI, P1, DOI DOI 10.1109/BTAS.2010.5634498
   Cabani Adnane, 2021, Smart Health (Amst), V19, P100144, DOI 10.1016/j.smhl.2020.100144
   Castrillon-Santana M, 2016, PATTERN RECOGN LETT, V82, P181, DOI 10.1016/j.patrec.2015.09.014
   Damer N, 2020, LECT NOTE INFORM, VP-306
   Dong YH, 2012, INT J PROD RES, V50, P2681, DOI 10.1080/00207543.2011.579637
   Fii Geva, 2020, FACE ID FIRMS BATTLE, DOI [10.1016/S0969-4765(20)30042-4, DOI 10.1016/S0969-4765(20)30042-4]
   Hussain M, 2019, ADV INTELL SYST, V840, P191, DOI 10.1007/978-3-319-97982-3_16
   Keshari R, 2016, IEEE IMAGE PROC, P3116, DOI 10.1109/ICIP.2016.7532933
   Kumari P, 2020, ADV INTELL SYST COMP, V1034, P143, DOI 10.1007/978-981-15-1084-7_15
   Le T.H. N., 2014, Biometrics (IJCB), 2014 IEEE International Joint Conference on, P1, DOI [10.1109/BTAS.2014.6996262, DOI 10.1109/BTAS.2014.6996262]
   Liu PZ, 2017, IEEE T IMAGE PROCESS, V26, P5070, DOI 10.1109/TIP.2017.2713041
   Mahalingam G, 2014, IEEE T INF FOREN SEC, V9, P2180, DOI 10.1109/TIFS.2014.2361479
   Nguyen H, 2020, LECT NOTE INFORM, VP-306
   Nie L, 2014, INT C PATT RECOG, P399, DOI 10.1109/ICPR.2014.77
   Okereafor K., 2020, JMIR Biomed. Eng, V5, pe19623, DOI DOI 10.2196/19623
   Padole C. N., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P439, DOI 10.1109/ICB.2012.6199790
   Park U, 2011, IEEE T INF FOREN SEC, V6, P96, DOI 10.1109/TIFS.2010.2096810
   Park U, 2009, 2009 IEEE 3RD INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P153
   Proença H, 2018, IEEE T INF FOREN SEC, V13, P888, DOI 10.1109/TIFS.2017.2771230
   Proença H, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Raffei AFM, 2019, J ELECT ENG INF, V7, P543, DOI [10.11591/ijeei.v7i3.1147, DOI 10.11591/IJEEI.V7I3.1147]
   Raja KB, 2014, 2014 IEEE WORKSHOP ON BIOMETRIC MEASUREMENTS AND SYSTEMS FOR SECURITY AND MEDICAL APPLICATIONS (BIOMS) PROCEEDINGS, P15, DOI 10.1109/BIOMS.2014.6951530
   Smereka JM, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY AND BEHAVIOR ANALYSIS (ISBA)
   Zhao ZJ, 2018, IEEE T INF FOREN SEC, V13, P2937, DOI 10.1109/TIFS.2018.2833018
NR 27
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 24
BP 33573
EP 33591
DI 10.1007/s11042-021-11402-0
EA AUG 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WJ3HO
UT WOS:000686512700001
PM 34429711
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Garg, P
   Kishore, RR
AF Garg, Preeti
   Kishore, R. Rama
TI An efficient and secured blind image watermarking using ABC optimization
   in DWT and DCT domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Multi-objective function; DCT; DWT; ABC
ID COLOR IMAGES; ROBUST; SVD; ALGORITHM; WAVELET
AB In today's digital world, all content is available over the internet, which anyone can use. Securing this data by adding copyright protection or ownership is called watermarking. This paper proposes a blind watermarking technique based on frequency domain transform to provide robustness and imperceptibility, and it also uses Artificial Bee Colony (ABC) optimization technique for optimization purposes. The ABC algorithm helps in finding the best embedding factor used during the embedding of the watermark. During extraction, only the watermarked image is needed that makes this technique blind watermarking. In this paper, a hybrid method using the logic of 2-level Discrete Wavelet Transform (DWT) and Discrete Cosine Transform (DCT) is used for embedding and for providing security to the scheme, an encrypted image is embedded in the cover image as the watermark. The proposed technique is applied to several images to prove its robustness and imperceptibility. The proposed scheme is implemented on various images, and its performance is measured by performing several attacks to compare with other existing methods. The experimental results show that Peak Signal to Noise Ratio (PSNR) value greater than 40 is achieved here. Furthermore, normalized Correlation (NC) value is greater than 0.9, proving its robustness against various attacks.
C1 [Garg, Preeti] Guru Gobind Singh Indraprastha Univ, Univ Sch Informat Commun & Technol, New Delhi, India.
   [Kishore, R. Rama] KIET Grp Inst, Dept CSE, Ghaziabad, India.
C3 GGS Indraprastha University; KIET Group of Institutions
RP Garg, P (corresponding author), Guru Gobind Singh Indraprastha Univ, Univ Sch Informat Commun & Technol, New Delhi, India.
EM preeti.itgarg@gmail.com; ram_kish@yahoo.com
OI Garg, Preeti/0000-0001-6635-3296
CR Abd-Ellah MK, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0332-4
   Abdelhakim AM, 2017, EXPERT SYST APPL, V72, P317, DOI 10.1016/j.eswa.2016.10.056
   Al-Gindy A., 2008, 2008 Mosharaka International Conference on Communications, Computers and Applications (MIC-CCA 2008), P26, DOI 10.1109/MICCCA.2008.4669845
   AL-Nabhani Y, 2015, J KING SAUD UNIV-COM, V27, P393, DOI 10.1016/j.jksuci.2015.02.002
   Ansari I., 2016, INT J SYST ASSUR ENG, V9, P10
   Ansari IA, 2017, MULTIMED TOOLS APPL, V76, P18001, DOI 10.1007/s11042-016-3680-z
   Ansari IA, 2016, ENG APPL ARTIF INTEL, V49, P114, DOI 10.1016/j.engappai.2015.12.004
   Cox I. J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P6, DOI 10.1109/ITCC.2000.844175
   Dehghan H, 2010, ICEE C ARXIV, P1
   Dubolia R., 2011, 2011 International Conference on Communication Systems and Network Technologies (CSNT), P593, DOI 10.1109/CSNT.2011.127
   Garg P, 2020, MULTIMED TOOLS APPL, V79, P25921, DOI 10.1007/s11042-020-09262-1
   Hai T, 2014, J APPL RES TECHNOL, V12, P122, DOI 10.1016/S1665-6423(14)71612-8
   Hong W., 2006, IEEE T SIGNAL PROCES, V12, P1
   Hu DH, 2019, IEEE T KNOWL DATA EN, V31, P1024, DOI 10.1109/TKDE.2018.2851517
   Karaboga D., 2005, Technical Report-TR06
   Karaboga D, 2007, LECT NOTES COMPUT SC, V4529, P789, DOI 10.1007/978-3-540-72950-1_77
   Karaboga D, 2009, APPL MATH COMPUT, V214, P108, DOI 10.1016/j.amc.2009.03.090
   Lai CC, 2012, INT CONF GENET EVOL, P476, DOI 10.1109/ICGEC.2012.103
   Lin Y, 2011, IET SIGNAL PROCESS, V5, P623, DOI 10.1049/iet-spr.2010.0069
   Makbol NM, 2017, INFORM SCIENCES, V417, P381, DOI 10.1016/j.ins.2017.07.026
   Marini E, 2007, PROC SPIE, V6505, DOI 10.1117/12.704359
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Moeinaddini E, 2017, MULTIMED TOOLS APPL, P1
   Moosazadeh M, 2017, OPTIK, V140, P975, DOI 10.1016/j.ijleo.2017.05.011
   Parah S., 2016, ROBUST BLIND WATERMA, P1
   Perwej Y., 2012, Int J Multimed Its Appl, V4, P21, DOI [10.5121/ijma.2012.4202, DOI 10.5121/IJMA.2012.4202]
   Phi BN, 2010, LECT NOTES COMPUT SC, V6297, P685, DOI 10.1007/978-3-642-15702-8_63
   Qiumei Z., 2020, MATHEMATICS-BASEL, V8, P1
   Sharma S, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105696
   Sharmin S., 2019, P IEMIS 2018, V3, DOI [10.1007/978-981-13-1501-5_18, DOI 10.1007/978-981-13-1501-5_18]
   Singh A, 2014, MANAGING EMOTION IN DESIGN INNOVATION, P1
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Tapkan P, 2007, SWARM INTELLIGENCE F
   Vaidya SP, 2017, MULTIMED TOOLS APPL, V76, P25623, DOI 10.1007/s11042-017-4355-0
   Xu HC, 2018, INT J ELECTRON SECUR, V10, P79, DOI 10.1504/IJESDF.2018.089215
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
NR 36
TC 12
Z9 12
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 36947
EP 36964
DI 10.1007/s11042-021-11237-9
EA AUG 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000684916500001
DA 2024-07-18
ER

PT J
AU Kumari, M
   Gupta, S
AF Kumari, Manju
   Gupta, Shailender
TI Performance comparison between Chaos and quantum-chaos based image
   encryption techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptography; Security attacks; Chaos techniques; Encryption;
   Quantum-chaos techniques
AB Today's digital era has undertaken most of the responsibilities of public and private sectors, not only the industries or big organizations dependent on the internet but individual's household needs also lying on it. To make the data transmission/reception confidential and secure for both internet users and internet service providers, a large number of researches have been done in this field. It has proved that cryptography is the best solution for solving this purpose. Mostly, digital images are continuously transferring on the network rather than texts. Enciphering a digital image is a much bulkier and a complex task. It has been evident from many types of research that chaotic logistic map-based equations provide a great level of randomness. Hence Chaotic logistic maps-based image encryption techniques (also called chaos techniques) were implemented to obtain highly random cipher images. On the other hand, time consumption must be as low as it can be possible to sustain real-time communication. Presently, the advanced encryption schemes based on quantum technology have enhanced efficiency and security because of having a large key-space and less time complexity along with randomness. The quantum-chaos based encryption is done by utilizing uncertainty principles of quantum mechanics on logistic maps. This paper is an effort to compare chaos and quantum chaos-based image encryption schemes. MATLAB 2016a software is used for the execution and the comparison is made based on various security attack analyses. Based on the study and experimental results, the quantum chaos techniques used for bit plane scrambling provides better results in terms of effectiveness, efficiency, and trustworthy that can be adopted for highly secured image encryption.
C1 [Kumari, Manju; Gupta, Shailender] JC Bose Univ Sci & Technol YMCA, Elect Engn Dept, Faridabad, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Kumari, M (corresponding author), JC Bose Univ Sci & Technol YMCA, Elect Engn Dept, Faridabad, India.
EM manjunimesh88@gmail.com; shailender81@gmail.com
RI gupta, shailender/Y-8231-2019
OI gupta, shailender/0000-0003-1383-7152
CR Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Akhshani A, 2012, COMMUN NONLINEAR SCI, V17, P4653, DOI 10.1016/j.cnsns.2012.05.033
   Al-Maytami BA, 2020, AD HOC NETW, V98, DOI 10.1016/j.adhoc.2019.102028
   Ali M., 2019, Int J Adv Res Comput Sci, V10, P9, DOI [10.26483/ijarcs.v10i1.6350, DOI 10.26483/IJARCS.V10I1.6350]
   Alloghani M, 2021, SYSTEMATIC REV STATU
   [Anonymous], 2017, INNOVATIVE IMAGE ENC
   [Anonymous], 2019, CISO BENCHMARK REPOR
   Chandra S, 2014, 2014 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMMUNICATION AND COMPUTATIONAL ENGINEERING (ICECCE), P83, DOI 10.1109/ICECCE.2014.7086640
   El-Zoghdy Said F., 2011, International Journal of Advanced Networking and Applications, V2, P796
   Fluhrer S., 2001, Selected Areas in Cryptography: 8th Annual International Workshop Proceedings. Lecture Notes in Computer Science, V2259
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Hanchinamani G, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0062-7
   John Justin M, 2013, INT J SOFT COMPUTING, V2
   Kevadia KT, 2016, LIT SURVEY IMAGE ENC, V2, P741
   Kumar M., 2020, J. Comput. Eng, V14, P31, DOI DOI 10.9790/0661-2201013137
   Kumar P., 2019, INT J NETW SECUR ITS, V11, P49, DOI [10.5121/ijnsa.2019.11404, DOI 10.5121/IJNSA.2019.11404]
   Kumari M, 2020, MULTIMED TOOLS APPL, V79, P33161, DOI 10.1007/s11042-020-09627-6
   Kumari M, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0162-2
   Kumari M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0148-5
   La CY, 2019, DESIGN CODE CRYPTOGR, V87, P1961, DOI 10.1007/s10623-018-00597-3
   Liu H, 2017, 3D RES, V8, DOI 10.1007/s13319-016-0114-7
   Liu XB, 2019, IEEE ACCESS, V7, P6937, DOI 10.1109/ACCESS.2018.2889896
   Mitchell CJ, 2016, IEEE T INFORM THEORY, V62, P6260, DOI 10.1109/TIT.2016.2611003
   Mohammad O. F., 2017, INT J APPL ENG RES, V12, P13265
   National Institute of Standards and Technology, 2001, NIST FIPS PUB, P197
   Padmavathi B, 2013, INT J SCI RES IJSR, V2
   Pandya A., 2018, INT RES J ENG TECHNO, V05, P2010
   Patel S., 2020, J Sci Res, V64, P291
   Rhee M.Y., 2003, Internet Security: Cryptographic Principles, Algorithms and Protocols
   Sam IS, 2012, NONLINEAR DYNAM, V69, P1995, DOI 10.1007/s11071-012-0402-6
   Sam IS, 2012, MULTIMED TOOLS APPL, V56, P315, DOI 10.1007/s11042-010-0652-6
   Schneier B., 1994, Lecture Notes in Computer Science, V809
   Sirichotedumrong W, 2019, APSIPA TRANS SIGNAL, V8, DOI 10.1017/ATSIP.2018.33
   Tanwar G, 2015, INT J ADV RES COMPUT, V5
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1902-1
NR 36
TC 13
Z9 13
U1 2
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 24
BP 33213
EP 33255
DI 10.1007/s11042-021-11178-3
EA AUG 2021
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WJ3HO
UT WOS:000684784900001
PM 34413701
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Doan, TNC
   Retraint, F
   Zitzniann, C
AF Doan, Thi Ngoc Canh
   Retraint, Florent
   Zitzniann, Cathel
TI Image tampering detection based on a statistical model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forgery detection signal-dependent noise model hypothesis testing
   statistical image modelling
ID INDIVIDUAL CAMERA DEVICE; SPLICING DETECTION; NOISE MODEL;
   IDENTIFICATION; FORENSICS
AB This paper presents a novel method for image manipulation iden- tification of natural images in JPEG format. The image forgery detection technique is based on a signal-dependent noise model that is relevant to de- scribe a natural image acquired by a digital camera. This parametric model is characterized by two fingerprints which are used to falsification identification. The problem is cast in the framework of the hypothesis testing theory. For practical use, the Generalized Likelihood Ratio Tests (GLRT) are presented and their performance is theoretically established. There are different types of image forgery which have been considered in this paper for example re- sampling, Gaussian filtering and median filtering. Experiments with real and simulated images highlight the relevance of the proposed approach.
C1 [Doan, Thi Ngoc Canh; Retraint, Florent] Univ Technol Troyes, Troyes, France.
   [Zitzniann, Cathel] EPF Coll Engn Montpellier, Comp Sci, Montpellier, France.
C3 Universite de Technologie de Troyes
RP Retraint, F (corresponding author), Univ Technol Troyes, Troyes, France.
EM thingoccanh.doan@utt.fr; Florent.retraint@utt.fr; cathel.zitzmann@epf.fr
OI RETRAINT, Florent/0000-0001-9273-4260
FU ANR project DEFACTO [ANR-16-DEFA-0002]; Agence Nationale de la Recherche
   (ANR) [ANR-16-DEFA-0002] Funding Source: Agence Nationale de la
   Recherche (ANR)
FX This work was supported by ANR project DEFACTO ANR-16-DEFA-0002.
CR Bayar B, 2017, INT CONF ACOUST SPEE, P2152, DOI 10.1109/ICASSP.2017.7952537
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   Nguyen HP, 2019, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS SECURITY AND PRIVACY (ICISSP), P487, DOI 10.5220/0007412804870494
   Hwang JJ, 2016, 2016 IEEE RIVF INTERNATIONAL CONFERENCE ON COMPUTING & COMMUNICATION TECHNOLOGIES, RESEARCH, INNOVATION, AND VISION FOR THE FUTURE (RIVF), P153, DOI 10.1109/RIVF.2016.7800286
   Jin X, 2018, IEEE ACCESS, V6, P50459, DOI 10.1109/ACCESS.2018.2867370
   Julliand T, 2016, LECT NOTES COMPUT SC, V10016, P126, DOI 10.1007/978-3-319-48680-2_12
   Le N, 2019, IEEE ACCESS, V7, P125038, DOI 10.1109/ACCESS.2019.2938467
   Le N, 2018, IEEE INT SYMP SIGNAL, P331, DOI 10.1109/ISSPIT.2018.8642651
   Liu XL, 2018, IEEE T CIRC SYST VID, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Liu YQ, 2019, IEEE T INF FOREN SEC, V14, P2551, DOI 10.1109/TIFS.2019.2902826
   Luo SH, 2019, IEEE ACCESS, V7, P80614, DOI 10.1109/ACCESS.2019.2923000
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Niu YK, 2017, SIGNAL PROCESS-IMAGE, V53, P65, DOI 10.1016/j.image.2017.01.008
   Qiao T, 2018, IEEE ACCESS, V6, P78038, DOI 10.1109/ACCESS.2018.2884710
   Qiao T, 2018, MULTIMED TOOLS APPL, V77, P1501, DOI 10.1007/s11042-016-4314-1
   Qiao T, 2017, SIGNAL PROCESS-IMAGE, V52, P74, DOI 10.1016/j.image.2016.12.011
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Rhee KH, 2017, TURK J ELECTR ENG CO, V25, P3811, DOI 10.3906/elk-1606-410
   Rhee KH, 2016, 2016 IEEE IEMCON 7 A, P1, DOI DOI 10.1109/IEMCON.2016.7746310
   Rhee RH, 2019, IEEE ACCESS, V7, P92586, DOI 10.1109/ACCESS.2019.2927540
   Romano Joseph P, 2005, Testing statistical hypotheses
   ROUSSEEUW PJ, 1993, J AM STAT ASSOC, V88, P1273, DOI 10.2307/2291267
   Scott C, 2007, IEEE T INFORM THEORY, V53, P2852, DOI 10.1109/TIT.2007.901152
   Sheng HD, 2018, IET IMAGE PROCESS, V12, P1815, DOI 10.1049/iet-ipr.2017.1131
   Su YT, 2017, J VIS COMMUN IMAGE R, V48, P480, DOI 10.1016/j.jvcir.2017.01.009
   Thai T. H., 2012, 2012 19th IEEE International Conference on Image Processing (ICIP 2012), P2525, DOI 10.1109/ICIP.2012.6467412
   Thai TH, 2016, DIGIT SIGNAL PROCESS, V48, P285, DOI 10.1016/j.dsp.2015.10.002
   Thai TH, 2015, SIGNAL PROCESS, V114, P164, DOI 10.1016/j.sigpro.2015.02.020
   Thai TH, 2014, IEEE T IMAGE PROCESS, V23, P250, DOI 10.1109/TIP.2013.2290596
   Doan TNC, 2017, IEEE INT SYMP SIGNAL, P18, DOI 10.1109/ISSPIT.2017.8388312
   Yu L, 2019, IEEE ACCESS, V7, P120594, DOI 10.1109/ACCESS.2019.2932810
NR 31
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32905
EP 32924
DI 10.1007/s11042-021-11213-3
EA AUG 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000683639000002
DA 2024-07-18
ER

PT J
AU Joshi, RC
   Singh, D
   Tiwari, V
   Dutta, MK
AF Joshi, Rakesh Chandra
   Singh, Divyanshu
   Tiwari, Vaibhav
   Dutta, Malay Kishore
TI An efficient deep neural network based abnormality detection and
   multi-class breast tumor classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Breast tumor; Cancer diagnosis; Convolutional neural
   network; Data augmentation; Deep learning; Ultrasound imaging
ID COMPUTER-AIDED DIAGNOSIS; ELASTOGRAPHY; SEGMENTATION; NODULES; BENIGN;
   MASSES; US
AB Breast tumor is one of the major cause of death among women all over the world. Ultrasound imaging-based breast abnormality detection and classification play a vital role to develop an automatic computer-aided diagnostic system. In this paper, deep learning technology is integrated with ultrasound images for pre-screening of breast cancer. Two breast ultrasound image datasets are trained on different deep-learning architectures with image augmentation. Convolutional neural network extracts the features from training ultrasound images which are fine-tuned for multiple iterations. The experimental outcomes indicate accurate and rapid prediction performance on the test dataset of 2D B-mode ultrasound images, signifying a promising approach for assistance to radiologists in clinical applications with the use of deep learning. Results demonstrate the proposed method attains an accuracy, sensitivity, and specificity of 96.31%, 92.63%, and 96.71% respectively. About 12 B-mode 2D ultrasound image frames can be processed per second which marks it as a highly efficient system. The proposed method gives better performance compared to other methods which shows its effectiveness in real-time computer-aided diagnosis of breast tumor and benign-malignant classification.
C1 [Joshi, Rakesh Chandra; Singh, Divyanshu; Tiwari, Vaibhav; Dutta, Malay Kishore] Dr APJ Abdul Kalam Tech Univ, Ctr Adv Studies, Lucknow, Uttar Pradesh, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Centre for Advanced
   Studies (CAS, AKTU)
RP Dutta, MK (corresponding author), Dr APJ Abdul Kalam Tech Univ, Ctr Adv Studies, Lucknow, Uttar Pradesh, India.
EM rakeshchandraindia@gmall.com; divyanshu0495@gmail.com;
   vaibhavtiwari09@gmail.com; malaykishoredutta@gmail.com
RI Joshi, Rakesh Chandra/Y-7428-2019
OI Joshi, Rakesh Chandra/0000-0003-1264-9010; Dutta, Malay
   Kishore/0000-0003-2462-737X; Tiwari, Vaibhav/0000-0003-0205-0514
FU Department of Science and Technology, Government of India
   [SEED/TIDE/2018/6/G]
FX This research was supported in parts by the Grants from Department of
   Science and Technology, Government of India, grant number
   SEED/TIDE/2018/6/G.
CR Al-Dhabyani W, 2020, DATA BRIEF, V28, DOI 10.1016/j.dib.2019.104863
   American Cancer Society, 2019, AM CANC SOC, V70, P515
   Atrey K, 2020, BREAST CANC DETECTIO, P454, DOI [10.1109/icpc2t48082.2020.9071501, DOI 10.1109/ICPC2T48082.2020.9071501]
   Cai LY, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0022-8
   Chen ZL, 2015, IEEE T BIO-MED ENG, V62, P1203, DOI 10.1109/TBME.2014.2385102
   Corsetti V, 2011, EUR J CANCER, V47, P1021, DOI 10.1016/j.ejca.2010.12.002
   Costantini M, 2006, J ULTRAS MED, V25, P649, DOI 10.7863/jum.2006.25.5.649
   da Silva R, 2019, IEEE LAT AM T, V17, P1964, DOI 10.1109/TLA.2019.9011540
   Eltrass AS, 2020, IET IMAGE PROCESS, V14, P495, DOI 10.1049/iet-ipr.2018.5953
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang QH, 2020, IEEE T KNOWL DATA EN, V32, P728, DOI 10.1109/TKDE.2019.2891622
   Huang QH, 2017, INT J COMPUT ASS RAD, V12, P493, DOI 10.1007/s11548-016-1513-1
   Huang YL, 2006, NEURAL COMPUT APPL, V15, P164, DOI 10.1007/s00521-005-0019-5
   Huang YL, 2005, P ANN INT IEEE EMBS, P1802
   Krizhevsky A, 2020, ALEXNET ACM INT C P
   Kuo WJ, 2001, BREAST CANCER RES TR, V66, P51, DOI 10.1023/A:1010676701382
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liao WX, 2020, IEEE J BIOMED HEALTH, V24, P984, DOI 10.1109/JBHI.2019.2960821
   Liew DD, 2021, J VASC ACCESS, V22, P121, DOI 10.1177/1129729820927235
   Mendelson EB, 2013, ACR BI-RADS Ultrasound, ACR BI-RADS Atlas, Breast Imaging Reporting and Data System
   Moon WK, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105361
   Paulinelli RR, 2005, J ULTRAS MED, V24, P635, DOI 10.7863/jum.2005.24.5.635
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Sahiner B, 2007, RADIOLOGY, V242, P716, DOI 10.1148/radiol.2423051464
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C., 2014, P IEEE COMP SOC C CO
   Tang X, 2020, INT J SCI EDUC, V42, P598, DOI [10.1109/JIOT.2020.3010258, 10.1080/09500693.2020.1719290]
   Thitaikumar A, 2008, PHYS MED BIOL, V53, P4809, DOI 10.1088/0031-9155/53/17/022
   Wang Y, 2020, IEEE T MED IMAGING, V39, P866, DOI 10.1109/TMI.2019.2936500
   Whitney HM, 2020, P IEEE, V108, P163, DOI [10.1109/jproc.2019.2950187, 10.1109/JPROC.2019.2950187]
   Wu JX, 2020, IEEE ACCESS, V8, P54019, DOI 10.1109/ACCESS.2020.2980292
   Yap MH, 2018, IEEE J BIOMED HEALTH, V22, P1218, DOI 10.1109/JBHI.2017.2731873
   Yu X, 2021, IEEE ACM T COMPUT BI, V18, P94, DOI 10.1109/TCBB.2020.2986544
   Zhang EL, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/ab7e7d
   Zhao F, 2014, I S BIOMED IMAGING, P685
   Zou Y, 2003, MED ENG PHYS, V25, P79, DOI 10.1016/S1350-4533(02)00194-7
NR 37
TC 16
Z9 16
U1 5
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13691
EP 13711
DI 10.1007/s11042-021-11240-0
EA AUG 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000682643900003
DA 2024-07-18
ER

PT J
AU Baral, S
   Alsadoon, A
   Prasad, PWC
   Al Aloussi, S
   Alsadoon, OH
AF Baral, Samit
   Alsadoon, Abeer
   Prasad, P. W. C.
   Al Aloussi, Sarmad
   Alsadoon, Omar Hisham
TI A novel solution of using deep learning for early prediction cardiac
   arrest in Sepsis patient: enhanced bidirectional long short-term memory
   (LSTM)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cardiac arrest; Time series data; Vital signs; Deep learning;
   Bidirectional LSTM
ID CLASSIFICATION
AB Cardiac arrest is a common issue in Intensive Care Units (ICU) with low survival rate. Deep learning algorithms have been used to predict cardiac arrest unsuccessfully due to low sensitivity and high false alarm rate. The aims of this research are to decrease the false alarm rate and increase sensitivity and specificity. The proposed system is based on Medical Information Mart for Intensive Care (MIMIC-III) database where two sets of data are created. These two datasets are time-series data and combination of time series and baseline data. Time series dataset is divided into six-time groups. The system model consists of a hybrid model: Multilayer Perceptron (MLP) and enhanced Bidirectional Long Short-Term Memory (LSTM). MLP processes baselines feature like age, sex, chief complaints whereas the bidirectional LSTM is used to handle time series vital signs data from forward and backward direction so that it considers both present and future inputs. The model predicts cardiac arrest up to six hours earlier before the incidence. We achieved better performance for combined dataset where the prediction time window is 1 h. Accuracy, sensitivity, specificity, and Area Under Curve (AUC) equal to 85.7%, 87.7%,84.9%, and 0.86 respectively for the state of art, for proposed solution are 92.6%, 94.3%, 93.6% and 0.94 respectively. The proposed system is reducing the false alarm rate and increasing accuracy, sensitivity, specificity, and the area under curve for the prediction of cardiac arrest using enhanced Bidirectional LSTM model. The problem of missing values, irregularities of time series, and imbalance data set is solved too.
C1 [Baral, Samit; Alsadoon, Abeer] Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.] Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Kent Inst Australia, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
   [Al Aloussi, Sarmad] Massasoit Community Coll, Comp Technol & Informat Management Dept, Brockton, MA USA.
   [Alsadoon, Omar Hisham] Al Iraqia Univ, Dept Islamic Sci, Baghdad, Iraq.
C3 Charles Sturt University; Western Sydney University; Al-Iraqia
   University
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.; Alsadoon, A (corresponding author), Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; withana,
   chandana/0000-0002-3007-687X; Alsadoon, Omar Hisham/0000-0001-7797-6392
CR Acharya UR, 2018, FUTURE GENER COMP SY, V79, P952, DOI 10.1016/j.future.2017.08.039
   Acharya UR, 2017, COMPUT BIOL MED, V89, P389, DOI 10.1016/j.compbiomed.2017.08.022
   Acharya UR, 2017, INFORM SCIENCES, V415, P190, DOI 10.1016/j.ins.2017.06.027
   Acharya UR, 2017, INFORM SCIENCES, V405, P81, DOI 10.1016/j.ins.2017.04.012
   Akrivos E, 2017, PRECISION MED POWERE, P25
   Al Rahhal MM, 2016, INFORM SCIENCES, V345, P340, DOI 10.1016/j.ins.2016.01.082
   Andersen RS, 2019, EXPERT SYST APPL, V115, P465, DOI 10.1016/j.eswa.2018.08.011
   [Anonymous], Keras
   Attia ZI, 2019, J CARDIOVASC ELECTR, V30, P668, DOI 10.1111/jce.13889
   Attia ZI, 2019, NAT MED, V25, P70, DOI 10.1038/s41591-018-0240-2
   Chaudharyl K, 2018, CLIN CANCER RES, V24, P1248, DOI 10.1158/1078-0432.CCR-17-0853
   Churpek MM, 2016, CRIT CARE MED, V44, P368, DOI 10.1097/CCM.0000000000001571
   Cournapeau D., SCIKIT LEARN
   Desai U, 2016, J MECH MED BIOL, V16, DOI 10.1142/S0219519416400054
   Downey CL, 2017, INT J NURS STUD, V76, P106, DOI 10.1016/j.ijnurstu.2017.09.003
   Ebrahimzadeh E, 2019, COMPUT METH PROG BIO, V169, P19, DOI 10.1016/j.cmpb.2018.12.001
   Ebrahimzadeh E, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0081896
   Fujita H, 2019, APPL INTELL, V49, P3383, DOI 10.1007/s10489-019-01461-0
   Goto Y, 2013, CRIT CARE, V17, DOI 10.1186/cc12812
   Hargrove DS, 2011, PSYCCRITIQUES, V56, DOI [10.1037/a0023953, DOI 10.1037/A0023953]
   Hossain M, 2018, SVDB COMPREHENSIVE D, DOI [10.20944/preprints201809.0454.v1, DOI 10.20944/PREPRINTS201809.0454.V1]
   Islam MM, 2019, COMPUT METH PROG BIO, V170, P1, DOI 10.1016/j.cmpb.2018.12.027
   Jang DH, 2020, AM J EMERG MED, V38, P43, DOI 10.1016/j.ajem.2019.04.006
   Javan SL, 2019, COMPUT METH PROG BIO, V178, P47, DOI 10.1016/j.cmpb.2019.06.010
   Javan SL, 2018, J BIOMED INFORM, V88, P70, DOI 10.1016/j.jbi.2018.10.008
   Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35
   Kennedy CE, 2015, PEDIATR CRIT CARE ME, V16, pE332, DOI 10.1097/PCC.0000000000000560
   Kwon JM, 2019, RESUSCITATION, V139, P84, DOI 10.1016/j.resuscitation.2019.04.007
   Kwon JM, 2019, ECHOCARDIOGR-J CARD, V36, P213, DOI 10.1111/echo.14220
   Kwon JM, 2018, J AM HEART ASSOC, V7, DOI 10.1161/JAHA.118.008678
   Matam BR, 2019, J CLIN MONIT COMPUT, V33, P713, DOI 10.1007/s10877-018-0198-0
   McCoy Andrea, 2017, BMJ Open Qual, V6, pe000158, DOI 10.1136/bmjoq-2017-000158
   Nguyen MT, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-33424-9
   Sannino G, 2018, FUTURE GENER COMP SY, V86, P446, DOI 10.1016/j.future.2018.03.057
   Sharma LN, 2015, IEEE T BIO-MED ENG, V62, P1827, DOI 10.1109/TBME.2015.2405134
   Shashikant R, 2023, APPL COMPUT INFORM, V19, P174, DOI 10.1016/j.aci.2019.06.002
   Smith GB, 2013, RESUSCITATION, V84, P465, DOI 10.1016/j.resuscitation.2012.12.016
   Voets M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217541
   Zhang JP, 2019, MED IMAGE ANAL, V54, P10, DOI 10.1016/j.media.2019.02.010
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
NR 40
TC 10
Z9 10
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32639
EP 32664
DI 10.1007/s11042-021-11176-5
EA AUG 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000679884900002
DA 2024-07-18
ER

PT J
AU Li, L
   Yu, XL
   Liu, ZL
   Zhao, ZM
   Zhang, K
   Zhou, SH
AF Li, Lin
   Yu, Xiaolei
   Liu, Zhenlu
   Zhao, Zhimin
   Zhang, Ke
   Zhou, Shanhao
TI Multi-scale recursive codec network with authority parameters (MRCN-AP)
   for RFID multi-label deblurring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; RFID tags; Blind deblurring; Convolution neural
   network; Recurrent neural network
ID EMPIRICAL MODE DECOMPOSITION; SUPPORT VECTOR REGRESSION
AB The dynamic non-uniform blur caused by Radio Frequency Identification (RFID) multi-label motion seriously affects the identification and location of labels. It is an ill-posed inverse problem for that the blur kernel and sharp image are unknown. The traditional method of removing the blur is very time-consuming. In this work, we propose Multi-scale Recursive Codec Network based on the Authority Parameter (MRCN-AP) to deblur RFID multi-label images in a vision-based RFID multi-label 3D measurement system. This network is composed of a stack of three encoder-decoder subnets of different scales, which restores the blurry image in an end-to-end manner, and extracts the detail edge on each scale effectively from coarse to fine. The proposed authority parameters reduce the parameters memory of redundant networks and improve the speed of the deblurring network. Also, we propose new large-scale RFID multi-label blur-sharp image pairs captured by the dual CCD camera. The proposed model is implemented on an extended dataset. We prove that our method improves the speed by at least 0.55 s, and also increases Peak Signal to Noise Ratio (PSNR) by 2.43dB. Besides, better visual effects are obtained by MRCN-AP deblurring network for RFID multi-label image, which is more conducive to subsequent positioning and optimization.
C1 [Li, Lin; Yu, Xiaolei; Liu, Zhenlu; Zhao, Zhimin; Zhang, Ke; Zhou, Shanhao] Nanjing Univ Aeronaut & Astronaut, Nanjing, Peoples R China.
   [Li, Lin; Yu, Xiaolei] Natl Qual Supervis & Testing Ctr RFID Prod Jiangs, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Yu, XL (corresponding author), Nanjing Univ Aeronaut & Astronaut, Nanjing, Peoples R China.; Yu, XL (corresponding author), Natl Qual Supervis & Testing Ctr RFID Prod Jiangs, Nanjing, Jiangsu, Peoples R China.
EM nuaaxiaoleiyu@126.com
RI l, l/HTL-7067-2023; L, L/HGA-1686-2022; -, Li/JMB-7112-2023; l,
   l/HJH-2933-2023; L, L/KCY-3050-2024; l, l/GZH-2874-2022; wang,
   yi/KBB-3614-2024
FU National Natural Science Foundation of China (NNSFC) [61771240]; Fund
   Project of Jiangsu Engineering Laboratory for Lake Environment Remote
   Sensing Technologies [JSLERS-2018-003]; China Postdoctoral Science
   Foundation [2016T90452]; Six Talent Peaks Project in Jiangsu Province of
   China [XYDXX-058]
FX This work was supported by National Natural Science Foundation of China
   (NNSFC) (61771240), Fund Project of Jiangsu Engineering Laboratory for
   Lake Environment Remote Sensing Technologies (JSLERS-2018-003), China
   Postdoctoral Science Foundation (2016T90452), and Six Talent Peaks
   Project in Jiangsu Province of China (XYDXX-058).
CR Bahat Y, 2017, IEEE I CONF COMP VIS, P3306, DOI 10.1109/ICCV.2017.356
   Benvenuto F, 2010, INVERSE PROBL, V26, DOI 10.1088/0266-5611/26/2/025004
   Cai J., 2019, ARXIV190300763
   Carasso AS, 1999, SIAM J NUMER ANAL, V36, P1659, DOI 10.1137/S0036142997320413
   Deng XY, 2012, NEUROCOMPUTING, V86, P170, DOI 10.1016/j.neucom.2012.01.017
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Fan GF, 2020, SUSTAIN CITIES SOC, V61, DOI 10.1016/j.scs.2020.102320
   Fan GF, 2020, J FORECASTING, V39, P737, DOI 10.1002/for.2655
   Fan GF, 2016, NEUROCOMPUTING, V173, P958, DOI 10.1016/j.neucom.2015.08.051
   Fan GF, 2013, ENERGIES, V6, P1887, DOI 10.3390/en6041887
   Fan YY, 2018, MULTIMED TOOLS APPL, V77, P11425, DOI 10.1007/s11042-017-5303-8
   Gong D, 2017, PROC CVPR IEEE, P3806, DOI 10.1109/CVPR.2017.405
   Hong WC, 2019, ENERGIES, V12, DOI 10.3390/en12061093
   Joshi N, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778767
   Khan MK, 2008, NEUROCOMPUTING, V71, P3026, DOI 10.1016/j.neucom.2007.12.017
   Kim TH, 2013, IEEE I CONF COMP VIS, P3160, DOI 10.1109/ICCV.2013.392
   Kim TH, 2014, PROC CVPR IEEE, P2766, DOI 10.1109/CVPR.2014.348
   Köhler R, 2012, LECT NOTES COMPUT SC, V7578, P27, DOI 10.1007/978-3-642-33786-4_3
   Leal B, 2010, INTERNET OF THINGS-BOOK, P3, DOI 10.1007/978-1-4419-1674-7_1
   Lee D, 2018, LECT NOTES COMPUT SC, V11220, P300, DOI 10.1007/978-3-030-01270-0_18
   Li LRH, 2018, PROC CVPR IEEE, P6616, DOI 10.1109/CVPR.2018.00692
   Li L, 2020, MEASUREMENT, V152, DOI 10.1016/j.measurement.2019.107367
   Li M, 2019, LECT NOTES COMPUT SC, V11604, P175, DOI 10.1007/978-3-030-23597-0_14
   LI MW, 2019, NONLINEAR DYNAM
   Liu R, 2018, ARXIV180711706
   Mao XJ, 2016, ADV NEUR IN, V29
   MEI J, 2019, MULTIMED TOOLS APPL, V78
   Nah S, 2019, PROC CVPR IEEE, P8094, DOI 10.1109/CVPR.2019.00829
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   Pan JS, 2016, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2016.56
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Vallabhaneni RB, 2018, ALEX ENG J, V57, P2387, DOI 10.1016/j.aej.2017.09.011
   Wang Y, 2018, ADV NEUR IN, V31
   Wen F., 2019, ARXIV190606642
   Wieschollek P, 2017, IEEE I CONF COMP VIS, P231, DOI 10.1109/ICCV.2017.34
   Xiao F, 2018, IEEE ACM T NETWORK, V26, P161, DOI 10.1109/TNET.2017.2766526
   Yu K, 2018, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR.2018.00259
   Yu X, 2019, SEMIPHYSICAL VERIFIC, P105
   Yu YS, 2018, IEEE T INSTRUM MEAS, V67, P839, DOI 10.1109/TIM.2017.2789122
   Yu YS, 2016, IET SCI MEAS TECHNOL, V10, P449, DOI 10.1049/iet-smt.2015.0202
   Zaremba W., 2014, RECURRENT NEURAL NET, P1, DOI DOI 10.1016/S0893-6080(96)00073-1
   Zhang FJ, 2018, MULTIMED TOOLS APPL, V77, P26239, DOI 10.1007/s11042-018-5847-2
   Zhang JW, 2018, PROC CVPR IEEE, P2521, DOI 10.1109/CVPR.2018.00267
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   ZHANG Z, 2020, NEUROCOMPUTING, V410
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
   Zhongqin Wang, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3314416
   Zhuang X, 2019, MEASUREMENT, V136, P25, DOI 10.1016/j.measurement.2018.12.071
   Zhuang X, 2018, METROL MEAS SYST, V25, P475, DOI 10.24425/123898
   Zhuang X, 2018, MEAS SCI TECHNOL, V29, DOI 10.1088/1361-6501/aabcac
NR 53
TC 1
Z9 1
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32149
EP 32169
DI 10.1007/s11042-021-11216-0
EA JUL 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000677229000004
DA 2024-07-18
ER

PT J
AU Domingo, JD
   Gómez-García-Bermejo, J
   Zalama, E
AF Domingo, Jaime Duque
   Gomez-Garcia-Bermejo, Jaime
   Zalama, Eduardo
TI Optimization and improvement of a robotics gaze control system using
   LSTM networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gaze control; Gaze engagement; Humanoid robot; ROS; HRI; Competitive
   network; Computer vision; Deep neural network; Recurrent neural network;
   RNN; LSTM
ID LOCALIZATION
AB Gaze control represents an important issue in the interaction between a robot and humans. Specifically, deciding who to pay attention to in a multi-party conversation is one way to improve the naturalness of a robot in human-robot interaction. This control can be carried out by means of two different models that receive the stimuli produced by the participants in an interaction, either an on-center off-surround competitive network or a recurrent neural network. A system based on a competitive neural network is able to decide who to look at with a smooth transition in the focus of attention when significant changes in stimuli occur. An important aspect in this process is the configuration of the different parameters of such neural network. The weights of the different stimuli have to be computed to achieve human-like behavior. This article explains how these weights can be obtained by solving an optimization problem. In addition, a new model using a recurrent neural network with LSTM layers is presented. This model uses the same set of stimuli but does not require its weighting. This new model is easier to train, avoiding manual configurations, and offers promising results in robot gaze control. The experiments carried out and some results are also presented.
C1 [Domingo, Jaime Duque; Gomez-Garcia-Bermejo, Jaime; Zalama, Eduardo] CARTIF Fdn, Div Sistemas Ind & Digitales, Parque Tecnol Boecillo, Valladolid 47151, Spain.
   [Gomez-Garcia-Bermejo, Jaime; Zalama, Eduardo] Univ Valladolid, ITAP DISA, Pl Santa Cruz 8, Valladolid 47002, Spain.
C3 Universidad de Valladolid
RP Domingo, JD (corresponding author), CARTIF Fdn, Div Sistemas Ind & Digitales, Parque Tecnol Boecillo, Valladolid 47151, Spain.
EM jaiduq@cartif.es
RI ; Zalama, Eduardo/K-9332-2014; Gomez Garcia-Bermejo, Jaime/L-4920-2014
OI Duque Domingo, Jaime/0000-0001-6649-5550; Zalama,
   Eduardo/0000-0001-7283-5574; Gomez Garcia-Bermejo,
   Jaime/0000-0003-4763-5356
FU Programa Retos Investigacion del Ministerio de Ciencia, Innovacion y
   Universidades [RTI2018-096652-B-I00]; Programa de Apoyo a Proyectos de
   Investigacion de la Junta de Castilla y Leon [VA233P18]; FEDER funds
FX The present research has been partially financed by "Programa Retos
   Investigacion del Ministerio de Ciencia, Innovacion y Universidades
   (Ref. RTI2018-096652-B-I00)" and by "Programa de Apoyo a Proyectos de
   Investigacion de la Junta de Castilla y Leon (Ref. VA233P18)",
   cofinancied with FEDER funds.
CR Abd El-Moneim S, 2020, MULTIMED TOOLS APPL, V79, P24013, DOI 10.1007/s11042-019-08293-7
   Admoni H, 2017, J HUM-ROBOT INTERACT, V6, P25, DOI 10.5898/JHRI.6.1.Admoni
   Alonso-Martín F, 2012, SENSORS-BASEL, V12, P9913, DOI 10.3390/s120709913
   Andrist S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3603, DOI 10.1145/2702123.2702592
   Bendris M., 2010, P INT C MACH VIS KAI, P187
   Benrachou DE, 2015, LECT NOTES ELECTR EN, V321, P659, DOI 10.1007/978-3-319-10380-8_63
   Carrara F, 2019, MULTIMED TOOLS APPL, V78, P27309, DOI 10.1007/s11042-019-07827-3
   Chen YY, 2020, IEEE ROBOT AUTOM LET, V5, P2754, DOI 10.1109/LRA.2020.2972868
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Domingo JD, 2020, WORKSH PHYS AG, P213, DOI DOI 10.1007/978-3-030-62579-5
   Duque-Domingo J, 2020, FRONT NEUROROBOTICS, V14, DOI 10.3389/fnbot.2020.00034
   Emery NJ, 2000, NEUROSCI BIOBEHAV R, V24, P581, DOI 10.1016/S0149-7634(00)00025-7
   Fan LF, 2019, IEEE I CONF COMP VIS, P5723, DOI 10.1109/ICCV.2019.00582
   Garau M., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P309, DOI 10.1145/365024.365121
   Gergle D, 2013, HUM-COMPUT INTERACT, V28, P1, DOI 10.1080/07370024.2012.678246
   GROSSBERG S, 1973, STUD APPL MATH, V52, P213
   HALL ET, 1968, CURR ANTHROPOL, V9, P83, DOI 10.1086/200975
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Kiesler S, 2004, HUM-COMPUT INTERACT, V19, P1, DOI 10.1207/s15327051hci1901&2_1
   King DE, 2009, J MACH LEARN RES, V10, P1755
   King E, 2015, ARXIV150200046
   Koochaki F, 2019, IEEE ENG MED BIO, P1310, DOI [10.1109/EMBC.2019.8857054, 10.1109/embc.2019.8857054]
   Kousidis Spyros, 2015, 2015 AAAI SPRING S S
   Kraft D., 1989, SLSQP A NONLINEAR PR
   Lathuilière S, 2019, PATTERN RECOGN LETT, V118, P61, DOI 10.1016/j.patrec.2018.05.023
   Liu F, 2019, MULTIMED TOOLS APPL, V78, P4527, DOI 10.1007/s11042-018-6058-6
   Masse, 2018, THESIS
   Meng B, 2018, MULTIMED TOOLS APPL, V77, P26901, DOI 10.1007/s11042-018-5893-9
   Nguyen DC, 2018, LECT NOTES COMPUT SC, V10903, P164, DOI 10.1007/978-3-319-91250-9_13
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rosales R, 1998, IMPROED TRACKING MUL
   Saldien J, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/58402
   Shiomi M., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P1340
   Siatras S, 2009, IEEE T CIRC SYST VID, V19, P133, DOI 10.1109/TCSVT.2008.2009262
   Sidner C. L., 2004, P 9 INT C INT US INT, P78, DOI DOI 10.1145/964442.964458
   Thrun S, 2004, HUM-COMPUT INTERACT, V19, P9, DOI 10.1207/s15327051hci1901&2_2
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Vega J, 2013, SENSORS-BASEL, V13, P1268, DOI 10.3390/s130101268
   Viciana-Abad R, 2014, SENSORS-BASEL, V14, P9522, DOI 10.3390/s140609522
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Zaraki A, 2014, IEEE T HUM-MACH SYST, V44, P157, DOI 10.1109/THMS.2014.2303083
NR 42
TC 6
Z9 6
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3351
EP 3368
DI 10.1007/s11042-021-11112-7
EA JUL 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000670722800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, XS
   Meng, FC
   Zhao, FD
   Guo, DD
   Lou, FW
   Jing, R
AF Li, Xianshan
   Meng, Fengchan
   Zhao, Fengda
   Guo, Dingding
   Lou, Fengwei
   Jing, Rong
TI Two-stream adaptive-attentional subgraph convolution networks for
   skeleton-based action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Adaptive sub-graph convolution; Convolution block
   attention module; Two-stream framework; Spatio-temporal domain
AB Recently, skeleton-based action recognition has modeled the human skeleton as a graph convolution network (GCN), and has achieved remarkable results. However, most of the methods convolute directly on the whole graph, neglecting that the human skeleton is made up of multiple body parts, which cannot accomplish the task well. We recognize that the physical property of bones (i.e., length and direction) can provide identifiable information which helps effectively to build the multi-level network structure. As the existing methods treat the channel domain and the spatial domain with equal importance, many computing resources are wasted on neglectable features. In our paper, we modify the Convolution Block Attention Module (CBAM) and apply it to the adaptive network. By capturing the implicit weighted information in the channel domain and spatial domain, the network can focus more attention on the key channels and nodes. A new two-stream adaptive-attentional subgraph convolution network (2s-AASGCN) is proposed to extract features in the spatio-temporal domain. We validate 2s-AASGCN on two skeleton datasets, i.e., NTU-RGB+D60 and NTU-RGB+D120. Our model achieves excellent results on these two datasets.
C1 [Li, Xianshan; Meng, Fengchan; Zhao, Fengda; Guo, Dingding; Lou, Fengwei; Jing, Rong] Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.
   [Zhao, Fengda] Xinjiang Univ Sci & Technol, Korla 841000, Peoples R China.
   [Li, Xianshan; Meng, Fengchan; Zhao, Fengda; Guo, Dingding; Lou, Fengwei; Jing, Rong] Yanshan Univ, Key Lab Software Engn Hebei Prov, Qinhuangdao 066004, Hebei, Peoples R China.
C3 Yanshan University; Xinjiang University of Science & Technology; Yanshan
   University
RP Zhao, FD (corresponding author), Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.; Zhao, FD (corresponding author), Yanshan Univ, Key Lab Software Engn Hebei Prov, Qinhuangdao 066004, Hebei, Peoples R China.
EM xjlxs@ysu.edu.cn; mfc@stumail.ysu.edu.cn; zfd@ysu.edu.cn;
   gdd@ysu.edu.cn; xjlfw@ysu.edu.cn; jingrong@ysu.edu.cn
OI Guo, Dadong/0000-0002-1712-0055
FU Natural Science Foundation of Hebei Province [F2018203390]; Qinhuangdao
   City Science and Technology Research and Development Plan Grant
   [202003B043]; Xinjiang Uygur Autonomous Region University Scientific
   Research Project (Key Natural Science Project) [XJEDU2021I029]
FX This work was supported by the Natural Science Foundation of Hebei
   Province Grant No. F2018203390, Qinhuangdao City Science and Technology
   Research and Development Plan Grant No.202003B043 and Xinjiang Uygur
   Autonomous Region University Scientific Research Project (Key Natural
   Science Project) XJEDU2021I029. The authors also gratefully acknowledge
   the helpful comments and suggestions of the reviewers, which have
   improved the paper.
CR [Anonymous], 2019, IEEE T PATTERN ANAL
   [Anonymous], 2017, Hierarchical representations for efficient architecture search
   Cheng K, 2020, PROC CVPR IEEE, P180, DOI 10.1109/CVPR42600.2020.00026
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176
   Gao X, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P601, DOI 10.1145/3343031.3351170
   Gaur U, 2011, IEEE I CONF COMP VIS, P2595, DOI 10.1109/ICCV.2011.6126548
   Hu J, 2018, ADV NEURAL INFORM PR, P9401, DOI DOI 10.5555/3327546.3327612
   Ke QH, 2018, IEEE T IMAGE PROCESS, V27, P2842, DOI 10.1109/TIP.2018.2812099
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Li B, 2017, IEEE INT C COMPUT, P187, DOI 10.1109/CSE-EUC.2017.217
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572
   Liu J, 2018, IEEE T IMAGE PROCESS, V27, P1586, DOI 10.1109/TIP.2017.2785279
   Liu J, 2017, PROC CVPR IEEE, P3671, DOI 10.1109/CVPR.2017.391
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu MY, 2018, PROC CVPR IEEE, P1159, DOI 10.1109/CVPR.2018.00127
   Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030
   Liu ZY, 2020, PROC CVPR IEEE, P140, DOI 10.1109/CVPR42600.2020.00022
   Peng WT, 2020, IEEE INT C ELECTR TA, DOI 10.1109/icce-taiwan49838.2020.9258245
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shi HB, 2020, IEEE T FUZZY SYST, V28, P3244, DOI 10.1109/TFUZZ.2020.2991147
   Shi HB, 2020, ISA T, V98, P434, DOI 10.1016/j.isatra.2019.08.054
   Shi L, 2020, IEEE T IMAGE PROCESS, V29, P9532, DOI 10.1109/TIP.2020.3028207
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Song S, 2015, ARXIV PREPRINT ARXIV
   Sudha MR, 2017, INT J AMBIENT COMPUT, V8, P1, DOI 10.4018/IJACI.2017100101
   Tang YS, 2018, PROC CVPR IEEE, P5323, DOI 10.1109/CVPR.2018.00558
   Thakkar K. C., 2018, PRAC BRIZ MACH VIS C, P270
   Vaswani A, 2017, ADV NEUR IN, V30
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang W., 2019, ARXIV PREPRINT ARXIV
   Zhang P, 2018, IEEE T PATTERN ANAL
   Zhang PF, 2020, PROC CVPR IEEE, P1109, DOI 10.1109/CVPR42600.2020.00119
   Zhang PF, 2017, IEEE I CONF COMP VIS, P2136, DOI [10.1109/ICCV.2017.233, 10.1109/ICCV.2017.231]
   Zhang X., 2020, P IEEE CVF C COMP VI, P14333, DOI DOI 10.1109/CVPR42600202001434
NR 42
TC 4
Z9 5
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4821
EP 4838
DI 10.1007/s11042-021-11026-4
EA JUL 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000670723300001
DA 2024-07-18
ER

PT J
AU Hu, WT
   Wu, T
   Chen, YF
   Shen, YZ
   Yuan, LF
AF Hu, Weitong
   Wu, Ting
   Chen, Yuanfang
   Shen, Yanzhao
   Yuan, Lifeng
TI A lossless secret image sharing scheme using a larger finite field
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret image sharing; Cellular automata; Galois field; Reversible
ID STEGANOGRAPHY
AB Recent research has made an effort to take 8b-bit value as a polynomial coefficient and use a random number as the maximum coefficient term in a Shamir's polynomial, where b > 0. These can help improve computationl efficiency by reducing the sum of calculating polynomials, and avoid the case of the coefficient of x(k- 1) being zero. However, such research still has the issues of requiring much extra storage space, lossy secret image, shadow images with large size, and storing permutation key. To solve the above issues, in this paper, we propose a novel scheme which takes 8b-bit value as a polynomial coefficient, designs a bit-level method and runs under Galois Field GF(2(8b)). Experimental results show that this scheme improves existing similar schemes on several aspects, such as less extra storage space and higher computational performance.
C1 [Hu, Weitong; Wu, Ting; Chen, Yuanfang; Shen, Yanzhao] Hangzhou Dianzi Univ, Sch Cyberspace, Hangzhou 310018, Zhejiang, Peoples R China.
   [Yuan, Lifeng] Anhui Prov Key Lab Network & Informat Secur, Wuhu 240002, Anhui, Peoples R China.
C3 Hangzhou Dianzi University
RP Chen, YF (corresponding author), Hangzhou Dianzi Univ, Sch Cyberspace, Hangzhou 310018, Zhejiang, Peoples R China.
EM yuanfang.chen.tina@gmail.com
FU National Natural Science Foundation of China [61802097]; Project of
   Qianjiang Talent [QJD1802020]; open fund of Anhui Provincial Key
   Laboratory of Network and Information Security [AHNIS2019004]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61802097), the Project of Qianjiang Talent (Grant No.
   QJD1802020), and the open fund of Anhui Provincial Key Laboratory of
   Network and Information Security (Grant No. AHNIS2019004).
CR Bao L, 2017, IEEE T IMAGE PROCESS, V26, P5618, DOI 10.1109/TIP.2017.2738561
   Bassham III Lawrence E., 2010, SP 800 22 REV 1A STA
   Bharti M, 2020, COMPUT ELECTR ENG, V86, DOI 10.1016/j.compeleceng.2020.106693
   Bharti M, 2021, J SUPERCOMPUT, V77, P1739, DOI 10.1007/s11227-020-03315-w
   Bharti M, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4278
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   Ghebleh M, 2018, MULTIMED TOOLS APPL, V77, P11903, DOI 10.1007/s11042-017-4841-4
   Hu WT, 2012, SECUR COMMUN NETW, V5, P1267, DOI 10.1002/sec.567
   Hu WT, 2019, MOBILE NETW APPL, V24, P1317, DOI 10.1007/s11036-018-1168-y
   Kanso A, 2017, MULTIMED TOOLS APPL, V76, P16369, DOI 10.1007/s11042-016-3917-x
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Liu YX, 2019, MULTIMED TOOLS APPL, V78, P18653, DOI 10.1007/s11042-019-7205-4
   Ott E, 2002, CHAOS DYNAMICAL SYST
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   SHANNON CE, 1951, BELL SYST TECH J, V30, P50, DOI 10.1002/j.1538-7305.1951.tb01366.x
   Wang P, 2019, COMPUT SECUR, V85, P107, DOI 10.1016/j.cose.2019.04.010
   Wu XT, 2019, SIGNAL PROCESS-IMAGE, V78, P437, DOI 10.1016/j.image.2019.08.007
   Wu XT, 2019, DIGIT SIGNAL PROCESS, V93, P22, DOI 10.1016/j.dsp.2019.06.016
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yang CH, 2014, IEEE PHOTON CONF, P1, DOI 10.1109/IPCon.2014.6994959
   Zhao R, 2009, COMPUT STAND INTER, V31, P252, DOI 10.1016/j.csi.2007.10.012
   Zhou ZL, 2018, IEEE ACCESS, V6, P15021, DOI 10.1109/ACCESS.2018.2811722
NR 23
TC 9
Z9 9
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 28731
EP 28743
DI 10.1007/s11042-021-11104-7
EA JUN 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000659016300001
DA 2024-07-18
ER

PT J
AU Liao, HB
   Wang, DH
   Fan, P
   Ding, L
AF Liao, Haibin
   Wang, Dianhua
   Fan, Ping
   Ding, Ling
TI Deep learning enhanced attributes conditional random forest for robust
   facial expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature extraction; Facial expression recognition; Deep learning; Random
   forest
ID FACE; MULTICLASS
AB Automated Facial Expression Recognition (FER) has remained challenging because of the high inter-subject (e.g. the variations of age, gender and ethnic backgrounds) and intra-subject variations (e.g. the variations of low image resolution, occlusion and illumination). To reduce the variations of age, gender and ethnic backgrounds, we have introduced a conditional random forest architecture. Moreover, a deep multi-instance learning model has been proposed for reducing the variations of low image resolution, occlusion and illumination. Unlike most existing models are trained with facial expression labels only, other attributes related to facial expressions such as age and gender are also considered in our proposed model. A large number of experiments were conducted on the public CK+, ExpW, RAF-DB and AffectNet datasets, and the recognition rates reached 99% and 69.72% on the normalized CK+ face database and the challenging natural scene database respectively. The experimental results shows that our proposed method outperforms the state-of-the-art methods and it is robust to occlusion, noise and resolution variation in the wild.
C1 [Liao, Haibin; Wang, Dianhua; Fan, Ping; Ding, Ling] Hubei Univ Sci & Technol, Sch Comp Sci & Technol, Xianning, Peoples R China.
   [Liao, Haibin] ZICT Technol Co Ltd, Shenzhen, Peoples R China.
C3 Hubei University of Science & Technology
RP Liao, HB (corresponding author), Hubei Univ Sci & Technol, Sch Comp Sci & Technol, Xianning, Peoples R China.; Liao, HB (corresponding author), ZICT Technol Co Ltd, Shenzhen, Peoples R China.
EM liao_haibing@163.com
RI Ding, Ling/JXL-3787-2024
OI Ding, Ling/0000-0002-3208-2528
FU Xianning Natural Science Foundation [2019kj130]; Cultivation Fund of
   Hubei University of Science and Technology [2020- 22GP03]
FX We want to thank the helpful comments and suggestions from the Yicun
   Ouyang and Bin Xu. This work is supported partially by the Xianning
   Natural Science Foundation (No. 2019kj130) and the Cultivation Fund of
   Hubei University of Science and Technology (No. 2020- 22GP03).
CR [Anonymous], 2010, ECCV
   Bargal SA, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P433, DOI 10.1145/2993148.2997627
   Benitez-Garcia G, 2018, IEICE T INF SYST, VE101D, P1317, DOI 10.1587/transinf.2017MVP0025
   Bulò SR, 2014, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2014.18
   Chen CM, 2019, IEEE ACCESS, V7, P12047, DOI 10.1109/ACCESS.2019.2891105
   Criminisi A., 2011, Microsoft Research Cambridge, Tech. Rep. MSRTR-2011-114, V5, P12
   Dantone M, 2012, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2012.6247976
   Dapogny A, 2019, IEEE T AFFECT COMPUT, V10, P167, DOI 10.1109/TAFFC.2017.2708106
   Dapogny A, 2015, IEEE I CONF COMP VIS, P3783, DOI 10.1109/ICCV.2015.431
   Donahue J, 2014, PR MACH LEARN RES, V32
   EKMAN P, 1994, PSYCHOL BULL, V115, P268, DOI 10.1037/0033-2909.115.2.268
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Fang BF, 2018, INT J MACH LEARN CYB, V9, P1955, DOI 10.1007/s13042-017-0679-3
   Hassaballah M, 2020, DEEP LEARNING COMPUT, P33
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Jack RE, 2012, P NATL ACAD SCI USA, V109, P7241, DOI 10.1073/pnas.1200155109
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Kim BK, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P427, DOI 10.1145/2818346.2830590
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Li S, 2019, IEEE T IMAGE PROCESS, V28, P356, DOI 10.1109/TIP.2018.2868382
   Liu MY, 2013, IEEE INT CONF AUTOMA
   Liu YY, 2018, PATTERN RECOGN, V84, P251, DOI 10.1016/j.patcog.2018.07.016
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Luo LK, 2018, ARAB J SCI ENG, V43, P7679, DOI 10.1007/s13369-018-3132-3
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Moore S, 2011, COMPUT VIS IMAGE UND, V115, P541, DOI 10.1016/j.cviu.2010.12.001
   Nguyen HV, 2015, IEEE T IMAGE PROCESS, V24, P5479, DOI 10.1109/TIP.2015.2479405
   Pillai A, 2018, FUTURE GENER COMP SY, V81, P297, DOI 10.1016/j.future.2017.09.055
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rudovic O, 2010, LECT NOTES COMPUT SC, V6312, P350, DOI 10.1007/978-3-642-15552-9_26
   Sun M, 2012, PROC CVPR IEEE, P3394, DOI 10.1109/CVPR.2012.6248079
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P966, DOI 10.1109/TSMCB.2012.2200675
   Xu M, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION (ICNC), P702, DOI 10.1109/ICNC.2015.7378076
   Yang M, 2017, PATTERN RECOGN, V66, P117, DOI 10.1016/j.patcog.2016.12.028
   Yuan XH, 2018, STUD BIG DATA, V33, P433, DOI 10.1007/978-3-319-63639-9_18
   Yuan XH, 2018, PATTERN RECOGN, V77, P160, DOI 10.1016/j.patcog.2017.12.017
   Zhang K, 2017, IEEE ACCESS, V5, P22492, DOI 10.1109/ACCESS.2017.2761849
   Zhang SF, 2019, INT J COMPUT VISION, V127, P537, DOI 10.1007/s11263-019-01159-3
   Zhang T, 2016, IEEE T MULTIMEDIA, V18, P2528, DOI 10.1109/TMM.2016.2598092
   Zhang X, 2015, MACH VISION APPL, V26, P467, DOI 10.1007/s00138-015-0677-y
   Zhang ZP, 2018, INT J COMPUT VISION, V126, P550, DOI 10.1007/s11263-017-1055-1
   Zhang ZP, 2015, IEEE I CONF COMP VIS, P3631, DOI 10.1109/ICCV.2015.414
   Zheng WM, 2014, IEEE T AFFECT COMPUT, V5, P71, DOI 10.1109/TAFFC.2014.2304712
NR 49
TC 7
Z9 7
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 28627
EP 28645
DI 10.1007/s11042-021-10951-8
EA JUN 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000659016500003
DA 2024-07-18
ER

PT J
AU Dash, JK
   Mukhopadhyay, S
   Gupta, RD
   Khandelwal, N
AF Dash, Jatindra Kumar
   Mukhopadhyay, Sudipta
   Gupta, Rahul Dash
   Khandelwal, Niranjan
TI Content-based image retrieval system for HRCT lung images: assisting
   radiologists in self-learning and diagnosis of Interstitial Lung
   Diseases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Interstitial Lung Diseases;
   Learning-based retrieval system; Texture feature
ID COMPUTER-AIDED DIAGNOSIS; LOW-DOSE CT; CLASSIFICATION; FEATURES
AB Content-based Image Retrieval (CBIR) is a technique that can exploit the wealth of the data stored in a repository and help radiologists in decision making by providing references to the image in hand. A CBIR system for High-Resolution Computed Tomography (HRCT) lung images depicting signs of Interstitial Lung Diseases (ILDs) can be built and used as a self-learning tool for budding radiologists. The study of a few lung image retrieval systems available in the literature identifies some important issues that need to be taken care of. In most of the works, the creation of the reference database involves painstaking manual activity, which is time-consuming and needs skilled labor. A lot of human interventions are required, particularly for the proper delineation of the region of interest (ROI) that represents pathology in each of the images in a database. In most cases, the size of the ROIs representing different disease findings are fixed (i.e., either a fixed size square or circle), which at times may not be a proper representation of the disease pattern and as a consequence, it might limit the system's performance. Until date, a few learning-based approaches have been developed for content-based image retrieval of HRCT lung images, which either learn the similarity using a classifier or get trained through relevance feedback. For medical image analysis, the availability of labelled data for learning makes these learning-based retrieval systems meaningful as it enhances their performance in contrast to their simple distance-based counterpart. The objective of this paper is to develop a CBIR system for ILDs that is reliable and needs minimal human intervention. The paper evaluates the performance of three popular segmentation algorithms. It identifies the best for the effective and automated delineation of an arbitrary region of interest (AROI) depicting the sign of ILDs on HRCT images of the thorax in contrast to the manual delineation of fixed size ROI. This minimizes the manual effort for the creation and maintenance of the reference database, as well as the manual delineation of AROI during query formation. Moreover, AROI created through the automated clustering is found to have a better representation of disease patterns. Three recently proposed general-purpose learning based CBIR techniques are implemented and tested for retrieval of HRCT lung images depicting the sign of ILDs. The best method is suggested after careful evaluation of all the competing techniques.
C1 [Dash, Jatindra Kumar] SRM Univ AP, Amaravati 522503, Andhra Pradesh, India.
   [Mukhopadhyay, Sudipta; Gupta, Rahul Dash] Indian Inst Technol Kharagpur, Kharagpur 721302, W Bengal, India.
   [Khandelwal, Niranjan] Post Grad Inst Med Educ & Res, Chandigarh 160012, India.
C3 SRM University-AP; Indian Institute of Technology System (IIT System);
   Indian Institute of Technology (IIT) - Kharagpur; Post Graduate
   Institute of Medical Education & Research (PGIMER), Chandigarh
RP Dash, JK (corresponding author), SRM Univ AP, Amaravati 522503, Andhra Pradesh, India.
EM jatinkdash@gmail.com; smukho@iitkgp.ac.in; rahulcsjuiitkgp@gmail.com;
   khandelwaln@hotmail.com
RI Dash, Jatindra/JNT-5949-2023
CR [Anonymous], 2012, ARXIV12073510
   Anthimopoulos M, 2014, IEEE ENG MED BIO, P6040, DOI 10.1109/EMBC.2014.6945006
   Aziz ZA, 2004, THORAX, V59, P506, DOI 10.1136/thx.2003.020396
   Chen JY, 1998, P SOC PHOTO-OPT INS, V3299, P563, DOI 10.1117/12.320147
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dash JK, 2018, MULTIMED TOOLS APPL, V77, P459, DOI 10.1007/s11042-016-4228-y
   Dash JK, 2015, IET IMAGE PROCESS, V9, P836, DOI 10.1049/iet-ipr.2014.0299
   Dash JK, 2014, IEEE STUDENT TECHNOL, P264, DOI 10.1109/TechSym.2014.6808058
   Dash JK, 2013, SPIE MED IMAGING, P86702
   Depeursinge A, 2012, COMPUT MED IMAG GRAP, V36, P227, DOI 10.1016/j.compmedimag.2011.07.003
   Depeursinge A, 2012, INT J COMPUT ASS RAD, V7, P97, DOI 10.1007/s11548-011-0618-9
   Depeursinge A, 2010, ARTIF INTELL MED, V50, P13, DOI 10.1016/j.artmed.2010.04.006
   Depeursinge A, 2010, LECT NOTES COMPUT SC, V5853, P39, DOI 10.1007/978-3-642-11769-5_4
   Dy JG, 2003, IEEE T PATTERN ANAL, V25, P373, DOI 10.1109/TPAMI.2003.1182100
   Farnoosh R., 2008, International Journal on Engineering and Science, V19, P29
   Fu ZX, 2012, COMM COM INF SC, V346, P61
   Gangeh MJ, 2010, LECT NOTES COMPUT SC, V6363, P595
   Georgescu B, 2003, EDGE DETECTION IMAGE
   Guo GD, 2000, LECT NOTES COMPUT SC, V1842, P178
   Gupta RD, 2018, THESIS INDIAN I TECH
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   Huang KW, 2015, IEEE ENG MED BIO, P2968, DOI 10.1109/EMBC.2015.7319015
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Kim KG, 2005, RADIOLOGY, V237, P657, DOI 10.1148/radiol.2372041461
   King TE, 2005, AM J RESP CRIT CARE, V172, P268, DOI 10.1164/rccm.200503-483OE
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leader JK, 2005, AM J ROENTGENOL, V185, P973, DOI 10.2214/AJR.04.1225
   Liu C-T, 2001, 2001 IEEE INT C MULT
   Liu Y, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1891, DOI 10.1109/ICME.2004.1394628
   Lu J, 2011, IFAC P, V44, P9656
   Ma WY, 1996, PROC CVPR IEEE, P425, DOI 10.1109/CVPR.1996.517107
   MacArthur SD, 2002, COMPUT VIS IMAGE UND, V88, P55, DOI 10.1006/cviu.2002.0977
   Minka TP, 1997, PATTERN RECOGN, V30, P565, DOI 10.1016/S0031-3203(96)00113-6
   Mukhopadhyay S, 2013, PATTERN RECOGN LETT, V34, P646, DOI 10.1016/j.patrec.2013.01.001
   Park SC, 2011, PHYS MED BIOL, V56, P1139, DOI 10.1088/0031-9155/56/4/016
   Prakash R.M., 2017, 2017 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS), Coimbatore, P1, DOI DOI 10.1109/ICIIECS.2017.8276142
   Prasad M, 2008, LECT NOTES COMPUT SC, V5241, P59, DOI 10.1007/978-3-540-85988-8_8
   Ragothaman S, 2016, IEEE COMPUT SOC CONF, P1374, DOI 10.1109/CVPRW.2016.173
   Raj CSR, 2018, CURR MED IMAGING, V14, P289, DOI 10.2174/1573405613666170504152628
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Santini S, 1999, IEEE T PATTERN ANAL, V21, P871, DOI 10.1109/34.790428
   Shyu CR, 2002, COMPUT VIS IMAGE UND, V88, P119, DOI 10.1006/cviu.2002.0972
   Shyu CR, 1999, COMPUT VIS IMAGE UND, V75, P111, DOI 10.1006/cviu.1999.0768
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sorensen L, 2010, IEEE T MED IMAGING, V29, P559, DOI 10.1109/TMI.2009.2038575
   Sorensen L, 2008, LECT NOTES COMPUT SC, V5241, P934
   Vo KT, 2010, IEEE ENG MED BIO, P3085, DOI 10.1109/IEMBS.2010.5626113
   Vo KT, 2009, LECT NOTES COMPUT SC, V5702, P663, DOI 10.1007/978-3-642-03767-2_81
   Webb WR, 2001, HIGH RESOLUTION CT L, V1
NR 49
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22589
EP 22618
DI 10.1007/s11042-020-10173-4
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UD4ZK
UT WOS:000687215900001
DA 2024-07-18
ER

PT J
AU Dhoju, R
   Alsadoon, A
   Prasad, PWC
   Al-Saiyd, NA
   Alrubaie, A
AF Dhoju, Ramesh
   Alsadoon, Abeer
   Prasad, P. W. C.
   Al-Saiyd, Nedhal A.
   Alrubaie, Ahmad
TI Augmented reality navigation for liver surgery: an enhanced coherent
   point drift algorithm based hybrid optimization scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Deformable image registration; Iterative closest
   point (ICP); Coherent point drift algorithm (CPD); 3D point clouds;
   Surgical navigation
ID REGISTRATION; RECONSTRUCTION; IMAGE
AB Augmented reality (AR) based bowel or liver surgery still has not been implemented successfully due to limitations of accurate and proper image registration of uterus and gallbladder during surgery. This research aims to improve target registration error, which helps to navigate through hidden uterus and gallbladder during surgery. Therefore, it will reduce risk of cutting uterus or common bile duct during surgery, which can be fatal and cause devastating effects on the patient. The proposed system integrates the enhanced Coherent Point Drift (CPD) Algorithm with hybrid optimization scheme that incorporates Nelder-Mead simplex and genetic algorithm, to optimize the obtained weight parameter, which in turns improves the target image registration error and processing time of image registration. The system has minimized the target registration error by 0.31 mm in average. It provides a substantial accuracy in terms of target registration error, where the root mean square error is enhanced from 1.28 +/- 0.68 mm to 0.97 +/- 0.41 mm and improves processing time from 16 similar to 18 ms/frame to 11 similar to 12 ms/frame. The proposed system is focused on improving the accuracy of deformable image registration accuracy of soft tissues and hidden organs, which then helps in proper navigation and localization of the uterus hidden behind bowel and gallbladder hidden behind liver.
C1 [Dhoju, Ramesh; Alsadoon, Abeer; Prasad, P. W. C.] Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.
   [Alsadoon, Abeer] Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Monash Univ, Melbourne, Vic, Australia.
   [Alsadoon, Abeer] Kent Inst Australia, Informat Technol Dept, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.
   [Al-Saiyd, Nedhal A.] Appl Sci Private Univ, Fac Informat Technol, Amman, Jordan.
   [Alrubaie, Ahmad] Univ New South Wales, Fac Med, Sydney, NSW, Australia.
C3 Charles Sturt University; Western Sydney University; Monash University;
   University of New South Wales Sydney
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.; Alsadoon, A (corresponding author), Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Monash Univ, Melbourne, Vic, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Informat Technol Dept, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021; Al-Saiyd, Nedhal/JMB-0807-2023
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; Al-Saiyd,
   Nedhal/0000-0002-9282-890X; withana, chandana/0000-0002-3007-687X
CR Azer SA., 2016, Health Professions Education, V2, P80, DOI [10.1016/j.hpe.2016.05.002, DOI 10.1016/J.HPE.2016.05.002]
   Basnet BR, 2018, ORAL MAXILLOFAC SURG, V22, P385, DOI 10.1007/s10006-018-0719-5
   Bernhardt S, 2017, MED IMAGE ANAL, V37, P66, DOI 10.1016/j.media.2017.01.007
   Bernhardt S, 2016, MED IMAGE ANAL, V30, P130, DOI 10.1016/j.media.2016.01.008
   Cash DM, 2005, IEEE T MED IMAGING, V24, P1479, DOI 10.1109/TMI.2005.855434
   Chen L, 2018, COMPUT METH PROG BIO, V158, P135, DOI 10.1016/j.cmpb.2018.02.006
   De Paolis LT, 2019, MED BIOL ENG COMPUT, V57, P995, DOI 10.1007/s11517-018-1929-6
   Fan YF, 2014, MED PHYS, V41, DOI 10.1118/1.4895847
   Haouchine N, 2015, IEEE T VIS COMPUT GR, V21, P584, DOI 10.1109/TVCG.2014.2377772
   Jae-Hak Kim, 2012, Biomedical Image Registration. Proceedings 5th International Workshop, WBIR 2012, P246, DOI 10.1007/978-3-642-31340-0_26
   Kopelman Y, 2013, JSLS-J SOC LAPAROEND, V17, P171, DOI 10.4293/108680813X13693422522196
   LEE CP, 2015, P SPIE INT SOC OPT E, V9413
   Ma LF, 2019, MED BIOL ENG COMPUT, V57, P47, DOI 10.1007/s11517-018-1861-9
   Mahmoud N, 2019, IEEE T MED IMAGING, V38, P79, DOI 10.1109/TMI.2018.2856109
   Meng FL, 2018, INT J COMPUT ASS RAD, V13, P253, DOI 10.1007/s11548-017-1675-5
   Montiel, 2017, ICRA 2017, DOI 10.1016/j.cmpb.2018.02.006
   Morrison MA, 2016, J NEUROSURG, V124, P938, DOI 10.3171/2015.4.JNS15312
   Mountney P, 2014, LECT NOTES COMPUT SC, V8673, P423, DOI 10.1007/978-3-319-10404-1_53
   Murugesan YP, 2018, INT J MED ROBOT COMP, V14, DOI 10.1002/rcs.1889
   Nicolau S, 2011, SURG ONCOL, V20, P189, DOI 10.1016/j.suronc.2011.07.002
   Penza V, 2016, INT J COMPUT ASS RAD, V11, P197, DOI 10.1007/s11548-015-1276-0
   Peterlík I, 2018, MED IMAGE ANAL, V45, P24, DOI 10.1016/j.media.2017.12.006
   Peters TM, 2016, MED IMAGE ANAL, V33, P56, DOI 10.1016/j.media.2016.06.004
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Shu LX, 2017, INT J MED ROBOT COMP, V13, DOI 10.1002/rcs.1818
   Singh P, 2020, INT J MED ROBOT COMP, V16, DOI 10.1002/rcs.2055
   Somogyi-Ganss E, 2015, CLIN ORAL IMPLAN RES, V26, P882, DOI 10.1111/clr.12414
   Stoyanov D, 2008, J DISP TECHNOL, V4, P491, DOI 10.1109/JDT.2008.926497
   Su LM, 2009, UROLOGY, V73, P896, DOI 10.1016/j.urology.2008.11.040
   Tang R, 2018, HEPATOB PANCREAT DIS, V17, P101, DOI 10.1016/j.hbpd.2018.02.002
   Wang JC, 2019, INT J COMPUT ASS RAD, V14, P763, DOI 10.1007/s11548-019-01921-5
   Wang P, 2011, SCI CHINA INFORM SCI, V54, P2639, DOI 10.1007/s11432-011-4465-7
   Wang R, 2017, DISPLAYS, V48, P50, DOI 10.1016/j.displa.2017.03.003
   Yasuda J, 2018, INT J MED ROBOT COMP, V14, DOI 10.1002/rcs.1921
   Yu F, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0992-8
   Zhang XH, 2019, INT J COMPUT ASS RAD, V14, P1285, DOI 10.1007/s11548-019-01974-6
NR 36
TC 1
Z9 1
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28179
EP 28200
DI 10.1007/s11042-021-11070-0
EA MAY 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000656384900003
DA 2024-07-18
ER

PT J
AU Bera, A
   Dey, R
   Bhattacharjee, D
   Nasipuri, M
   Shum, HPH
AF Bera, Asish
   Dey, Ratnadeep
   Bhattacharjee, Debotosh
   Nasipuri, Mita
   Shum, Hubert P. H.
TI Spoofing detection on hand images using quality assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand biometrics; Image quality metric; Gradient magnitude; Presentation
   attack; Spoofing detection; Convolutional neural network
ID SHAPE; SIMILARITY
AB Recent research on biometrics focuses on achieving a high success rate of authentication and addressing the concern of various spoofing attacks. Although hand geometry recognition provides adequate security over unauthorized access, it is susceptible to presentation attack. This paper presents an anti-spoofing method toward hand biometrics. A presentation attack detection approach is addressed by assessing the visual quality of genuine and fake hand images. A threshold-based gradient magnitude similarity quality metric is proposed to discriminate between the real and spoofed hand samples. The visual hand images of 255 subjects from the Bogazici University hand database are considered as original samples. Correspondingly, from each genuine sample, we acquire a forged image using a Canon EOS 700D camera. Such fake hand images with natural degradation are considered for electronic screen display based spoofing attack detection. Furthermore, we create another fake hand dataset with artificial degradation by introducing additional Gaussian blur, salt and pepper, and speckle noises to original images. Ten quality metrics are measured from each sample for classification between original and fake hand image. The classification experiments are performed using the k-nearest neighbors, random forest, and support vector machine classifiers, as well as deep convolutional neural networks. The proposed gradient similarity-based quality metric achieves 1.5% average classification error using the k-nearest neighbors and random forest classifiers. An average classification error of 2.5% is obtained using the baseline evaluation with the MobileNetV2 deep network for discriminating original and different types of fake hand samples.
C1 [Bera, Asish] Edge Hill Univ, Dept Comp Sci, Ormskirk L39 4QP, Lancs, England.
   [Dey, Ratnadeep; Bhattacharjee, Debotosh; Nasipuri, Mita] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
   [Bhattacharjee, Debotosh] Univ Hradec Kralove, Fac Informat & Management, Ctr Basic & Appl Sci, Rokitanskeho 62, Hradec Kralove 50003, Czech Republic.
   [Shum, Hubert P. H.] Univ Durham, Dept Comp Sci, Stockton Rd, Durham DH1 3LE, England.
C3 Edge Hill University; Jadavpur University; University of Hradec Kralove;
   Durham University
RP Bera, A (corresponding author), Edge Hill Univ, Dept Comp Sci, Ormskirk L39 4QP, Lancs, England.
EM beraa@edgehill.ac.uk; ratnadipdey@gmail.com; debotosh@ieee.org;
   mitanasipuri@gmail.com; hubert.shum@durham.ac.uk
RI Shum, Hubert P. H./E-8060-2015; Bhattacharjee, Debotosh/Q-4065-2019;
   Bhattacharjee, Debotosh/L-8521-2015; BERA, ASISH/G-6169-2019
OI Shum, Hubert P. H./0000-0001-5651-6039; Bhattacharjee,
   Debotosh/0000-0002-1163-6413; Bhattacharjee,
   Debotosh/0000-0002-1163-6413; BERA, ASISH/0000-0002-4546-076X
CR [Anonymous], 2018, 2018 INT C BIOMETRIC
   Banitalebi-Dehkordi M, 2019, MULTIMED TOOLS APPL, V78, P11507, DOI 10.1007/s11042-018-6700-3
   Bapat A, 2017, IEEE REGION 10 SYMP
   Barra S, 2019, INFORM SCIENCES, V479, P472, DOI 10.1016/j.ins.2018.01.010
   Bera A, 2020, IEEE T SYST MAN CY-S, V50, P747, DOI 10.1109/TSMC.2017.2744669
   Bera A, 2017, MULTIMED TOOLS APPL, V76, P21451, DOI 10.1007/s11042-016-4075-x
   Bera A, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415560054
   Bera A, 2014, STUD COMPUT INTELL, V555, P145, DOI 10.1007/978-3-319-05885-6_8
   Bhilare S, 2018, PATTERN ANAL APPL, V21, P769, DOI 10.1007/s10044-017-0606-y
   Biggio B, 2017, IEEE T PATTERN ANAL, V39, P561, DOI 10.1109/TPAMI.2016.2558154
   Bondzulic B, 2018, ACTA POLYTECH HUNG, V15, P83, DOI 10.12700/APH.15.4.2018.4.5
   Bong DBL, 2014, SIGNAL PROCESS-IMAGE, V29, P699, DOI 10.1016/j.image.2014.03.003
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chatterjee A, 2018, IEEE SENSOR LETT, V2, DOI 10.1109/LSENS.2018.2837879
   Chen H., 2005, BIOMETRIC CONSORTIUM
   Chen LK, 2017, IEEE T INSTRUM MEAS, V66, P294, DOI 10.1109/TIM.2016.2622860
   Chingovska I, 2014, IEEE T INF FOREN SEC, V9, P2264, DOI 10.1109/TIFS.2014.2349158
   Chugh T, 2018, IEEE T INF FOREN SEC, V13, P2190, DOI 10.1109/TIFS.2018.2812193
   Czajka A, 2013, INT CONF BIOMETR
   Doi J, 2005, IEEE T INSTRUM MEAS, V54, P2213, DOI 10.1109/TIM.2005.858820
   Dutagaci H, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2890986
   Farmanbar M, 2017, SIGNAL IMAGE VIDEO P, V11, P1253, DOI 10.1007/s11760-017-1082-y
   Faundez-Zanuy M, 2014, COGN COMPUT, V6, P230, DOI 10.1007/s12559-013-9230-3
   Ferrer MA, 2014, INFORM SCIENCES, V268, P3, DOI 10.1016/j.ins.2013.10.011
   Fourati E, 2020, MULTIMED TOOLS APPL, V79, P865, DOI 10.1007/s11042-019-08115-w
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Gamassi M, 2005, IEEE T INSTRUM MEAS, V54, P1489, DOI 10.1109/TIM.2005.851087
   Gao H, 2018, IEEE ACCESS, V6, P47181, DOI 10.1109/ACCESS.2018.2832722
   Guan JW, 2017, IEEE T MULTIMEDIA, V19, P2505, DOI 10.1109/TMM.2017.2703148
   Harvey J, 2019, IEEE T INSTRUM MEAS, V68, P1071, DOI 10.1109/TIM.2018.2861998
   Jaswal Gaurav, 2019, Computational Intelligence: Theories, Applications and Future DirectionsVolume II. ICCI-2017. Advances in Intelligent Systems and Computing (AISC 799), P557, DOI 10.1007/978-981-13-1135-2_42
   Jia S, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.11.004
   Kharola A, 2016, IEEE I C COMP INT CO, P13
   Klonowski M, 2018, PATTERN RECOGN, V73, P189, DOI 10.1016/j.patcog.2017.08.017
   Korshunov P, 2017, IEEE J-STSP, V11, P695, DOI 10.1109/JSTSP.2017.2692389
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Martini MG, 2012, SIGNAL PROCESS-IMAGE, V27, P875, DOI 10.1016/j.image.2012.01.012
   Nasipuri, 2019, BIOMETR COMPUT RECOG, V87
   Nogueira RF, 2016, IEEE T INF FOREN SEC, V11, P1206, DOI 10.1109/TIFS.2016.2520880
   Pinto A, 2020, IEEE T INF FOREN SEC, V15, P3347, DOI 10.1109/TIFS.2020.2988168
   Qiu XW, 2018, IEEE T INF FOREN SEC, V13, P465, DOI 10.1109/TIFS.2017.2756598
   Raghavendra R, 2015, IEEE T INF FOREN SEC, V10, P703, DOI 10.1109/TIFS.2015.2400393
   Rahul K, 2019, IET IMAGE PROCESS, V13, P1170, DOI 10.1049/iet-ipr.2018.5496
   Rathgeb C, 2020, I W BIOMETRIC FORENS, DOI 10.1109/iwbf49977.2020.9107961
   Reenu M, 2013, 2013 SECOND INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING, NETWORKING AND SECURITY (ADCONS 2013), P79, DOI 10.1109/ADCONS.2013.25
   Sajjad M, 2019, PATTERN RECOGN LETT, V126, P123, DOI 10.1016/j.patrec.2018.02.015
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sellahewa H, 2010, IEEE T INSTRUM MEAS, V59, P805, DOI 10.1109/TIM.2009.2037989
   Shi, 2018, IEEE T SYST MAN CYBE
   Sun W, 2018, IEEE T IMAGE PROCESS, V27, P4232, DOI 10.1109/TIP.2018.2837341
   Tolosana R, 2020, IEEE T INF FOREN SEC, V15, P1261, DOI 10.1109/TIFS.2019.2934867
   Travieso CM, 2014, INFORM SCIENCES, V275, P45, DOI 10.1016/j.ins.2014.02.031
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu ZZ, 2017, IEEE J-STSP, V11, P588, DOI 10.1109/JSTSP.2017.2671435
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yörük E, 2006, IEEE T IMAGE PROCESS, V15, P1803, DOI 10.1109/TIP.2006.873439
   Zhang XD, 2013, IEEE SIGNAL PROC LET, V20, P319, DOI 10.1109/LSP.2013.2244081
   Zhou F, 2019, IEEE T IMAGE PROCESS, V28, P3528, DOI 10.1109/TIP.2019.2898638
NR 58
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 28603
EP 28626
DI 10.1007/s11042-021-10976-z
EA MAY 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000655825400001
DA 2024-07-18
ER

PT J
AU Xia, KJ
   Zhou, QH
   Jiang, YZ
   Chen, B
   Gu, XQ
AF Xia, Kaijian
   Zhou, Qinghua
   Jiang, Yizhang
   Chen, Bo
   Gu, Xiaoqing
TI Deep residual neural network based image enhancement algorithm for low
   dose CT images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep residual neural network; Image enhancement; Alternate optimization;
   Fidelity constraint; Low dose CT images
ID ABDOMINAL CT; RECONSTRUCTION
AB Current deep learning based image enhancement algorithms attempt to learn the mapping relationship between degraded images and clear images directly. These algorithms often ignore the fidelity constraint of the observational model. In order to improve the image enhancement performance, an improved deep residual neural network based image enhancement algorithm (DRNN-IE) for low dose CT images is proposed in this paper. DRNN-IE embeds the image enhancement task into a deep neural network, and achieves data consistency using multiple enhancement modules and back-projection modules. The enhancement modules in DRNN-IE produce new features through fusing low-level and high-level features. In order to improve the algorithm's generalization ability, a dual-parameter loss function is adopted to train and optimize the neural network. Experiments on real CT images show that the proposed algorithm has excellent enhancement performance and retains detailed information of low-dose CT images.
C1 [Xia, Kaijian; Chen, Bo] Soochow Univ, Affiliated Changshu Hosp, Changshu Peoples Hosp 1, Changshu 215500, Jiangsu, Peoples R China.
   [Xia, Kaijian; Jiang, Yizhang] Jiangnan Univ, Jiangsu Key Lab Media Design & Software Technol, Wuxi 214122, Jiangsu, Peoples R China.
   [Zhou, Qinghua] Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.
   [Jiang, Yizhang] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Jiangsu, Peoples R China.
   [Gu, Xiaoqing] Changzhou Univ, Sch Informat Sci & Engn, Changzhou 213164, Jiangsu, Peoples R China.
C3 Soochow University - China; Jiangnan University; University of
   Leicester; Jiangnan University; Changzhou University
RP Gu, XQ (corresponding author), Changzhou Univ, Sch Informat Sci & Engn, Changzhou 213164, Jiangsu, Peoples R China.
EM guxq@cczu.edu.cn
RI Gu, Xiaoqing/GPP-6913-2022; Jiang, Yizhang/V-2171-2019
OI Jiang, Yizhang/0000-0002-4558-9803; Gu, Xiaoqing/0000-0001-9942-0651
FU Jiangsu Committee of Health [H2018071]; Changshu Committee of Health
   [csws201820]; National Natural Science Foundation of China [61806026];
   Natural Science Foundation of Jiangsu Province [BK 20180956]
FX This work was supported in part by the Jiangsu Committee of Health under
   Grant H2018071, Changshu Committee of Health under Grant csws201820,
   National Natural Science Foundation of China under Grants 61806026, and
   Natural Science Foundation of Jiangsu Province under Grant BK 20180956.
CR Ahn CK, 2019, PROC SPIE, V10948, DOI 10.1117/12.2513144
   Amid E., 2019, Advances in Neural Information Processing Systems, P14987
   Chen LL, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P682, DOI 10.1109/TENCON.2016.7848089
   Chen YQ, 2017, 2017 INTERNATIONAL CONFERENCE ON ROBOTS & INTELLIGENT SYSTEM (ICRIS), P350, DOI 10.1109/ICRIS.2017.94
   Cheng JL, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102145
   Chi JN, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19153348
   Chu JH, 2018, IEEE SIGNAL PROC LET, V25, P946, DOI 10.1109/LSP.2018.2820057
   Dong WS, 2019, IEEE T PATTERN ANAL, V41, P2305, DOI 10.1109/TPAMI.2018.2873610
   Fadden C, 2019, PROC SPIE, V10878, DOI 10.1117/12.2510607
   Gu PJ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010207
   Helland IS, 2018, J CHEMOMETR, V32, DOI 10.1002/cem.3044
   Higaki T, 2018, P 24 EUR C RAD VIENN, P1
   Jeon J, 2018, LECT NOTES COMPUT SC, V11220, P438, DOI 10.1007/978-3-030-01270-0_26
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lin TY, 2015, SIAM J OPTIMIZ, V25, P1478, DOI 10.1137/140971178
   Liu J, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab18db
   Liu Peter J., 2019, ARXIV191000998
   MacRedmond R, 2004, THORAX, V59, P237, DOI 10.1136/thx.2003.008821
   Mohammadi S, 2019, BIOMED PHYS ENG EXPR, V5, DOI 10.1088/2057-1976/ab0fb9
   NAIDICH DP, 1990, RADIOLOGY, V175, P729, DOI 10.1148/radiology.175.3.2343122
   Pan XC, 2009, INVERSE PROBL, V25, DOI 10.1088/0266-5611/25/12/123009
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Qian PJ, 2018, IEEE ACCESS, V6, P28594, DOI 10.1109/ACCESS.2018.2825352
   Qing Lyu, 2019, Proceedings of the SPIE, V11113, DOI 10.1117/12.2530592
   Raket LL, 2012, P 21 INT C PATT REC, P10232
   Sagara Y, 2010, AM J ROENTGENOL, V195, P713, DOI 10.2214/AJR.09.2989
   Seo H, 2020, IEEE T MED IMAGING, V39, P1316, DOI 10.1109/TMI.2019.2948320
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   SHUKLA AK, 2020, MULTIM TOOLS APPL ON
   Singh S, 2010, RADIOLOGY, V257, P373, DOI 10.1148/radiol.10092212
   Tang C, 2019, COMPUT MATH METHOD M, V2019, DOI 10.1155/2019/8639825
   Tang ZH, 2017, J PHYS CONF SER, V787, DOI 10.1088/1742-6596/787/1/012008
   Thillaikkarasi R, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1223-7
   Wang Y, 2019, IEEE ACCESS, V7, P140233, DOI 10.1109/ACCESS.2019.2932130
   Watanabe H, 2010, AM J ROENTGENOL, V195, P986, DOI 10.2214/AJR.10.4456
   Xie YX, 2016, MULTIMED TOOLS APPL, V75, P14367, DOI 10.1007/s11042-016-3358-6
   Xu CE, 2020, MULTIMED TOOLS APPL, V79, P9435, DOI 10.1007/s11042-019-07776-x
   Yang WM, 2019, IEEE SIGNAL PROC LET, V26, P538, DOI 10.1109/LSP.2018.2890770
   Yu Z, 2019, P 15 INT M FULL 3 DI
   Zhao TT, 2019, MED PHYS, V46, P190, DOI 10.1002/mp.13252
   Zhao W, 2020, INT J RADIAT ONCOL, V108, pS43
   Zhao Z, 2019, INT J NUMER ANAL MET, V43, P2565, DOI 10.1002/nag.2993
   Zhu HC, 2020, INT J COMPUT ASS RAD, V15, P193, DOI 10.1007/s11548-019-02082-1
NR 43
TC 4
Z9 4
U1 5
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36007
EP 36030
DI 10.1007/s11042-021-11024-6
EA MAY 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000651689300002
DA 2024-07-18
ER

PT J
AU Abbas, SZ
   Ibrahim, H
   Khan, M
AF Abbas, Syed Zeeshan
   Ibrahim, Haroon
   Khan, Majid
TI A hybrid chaotic blowfish encryption for high-resolution satellite
   imagery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blowfish encryption; Digital contents privacy; Satellite imagery
ID INFORMATION SECURITY; QUANTUM SPIN; ALGORITHM; MAP
AB In this article, we have designed a new information confidentiality mechanism based on the combination of Blowfish encryption algorithm along with Henon and Chen chaotic dynamical systems. We have authenticated our proposed encryption algorithm over satellite and other standard digital images of image processing. Our proposed encryption algorithm is equally deployed as an encrtpter and decrypter while at the sending and receiving ends in satellite communication. In satellite communication, typical wireless mediums are used for transferring heavy payloads and usual telemetry. The priciple aim of this article is to design a new mechanism for the privacy of digital contents mainly satellite images. We have authenticated our anticipated mechanism with security performace analyses.
C1 [Abbas, Syed Zeeshan; Ibrahim, Haroon] Inst Space Technol, Dept Elect Engn, WiSP Lab, Islamabad, Pakistan.
   [Ibrahim, Haroon] Inst Space Technol, Dept Elect Engn, iVis Lab, Islamabad, Pakistan.
   [Khan, Majid] Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
   [Khan, Majid] Inst Space Technol, Cyber & Informat Secur Lab CISL, Islamabad, Pakistan.
RP Khan, M (corresponding author), Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.; Khan, M (corresponding author), Inst Space Technol, Cyber & Informat Secur Lab CISL, Islamabad, Pakistan.
EM mk.cfd1@gmail.com
RI Khan, Majid/T-9408-2019
OI Khan, Majid/0000-0001-5454-3770
CR Abd Ulkareem Nasser M., 2013, J BASRAH RES SCI, V39, P68
   Ahmad R., 2016, J TELECOM ELECT COMP, V8, P147
   Alghafis A, 2020, MATH COMPUT SIMULAT, V177, P441, DOI 10.1016/j.matcom.2020.05.016
   Alghafis A, 2020, WIREL NETW, DOI 10.1007/s11276-020-02363-7
   Alghafis A, 2020, PHYSICA A, V554, DOI 10.1016/j.physa.2019.123908
   Alghafis A, 2020, INT J THEOR PHYS, V59, P1227, DOI 10.1007/s10773-020-04402-7
   Ali KM, 2019, INT J THEOR PHYS, V58, P3091, DOI 10.1007/s10773-019-04188-3
   [Anonymous], 2009, TENCON 2009 2009 IEE, DOI DOI 10.1109/ICIECS.2009.5364290
   [Anonymous], 2011, INT J EMERGING TECHN
   Arshad U, 2020, PHYSICA A, V546, DOI 10.1016/j.physa.2019.123458
   Arshad U, 2019, INT J THEOR PHYS, V58, P3565, DOI 10.1007/s10773-019-04221-5
   Batool SI, 2020, PHYSICA A, V537, DOI 10.1016/j.physa.2019.122677
   Batool SI, 2019, MULTIMED TOOLS APPL, V78, P27611, DOI 10.1007/s11042-019-07881-x
   Blömer J, 2003, LECT NOTES COMPUT SC, V2742, P162
   Bulgurcu B, 2010, MIS QUART, V34, P523
   Buscarino A., 2014, CONCISE GUIDE CHAOTI, DOI [10.1007/978-3-319-05900-6, DOI 10.1007/978-3-319-05900-6]
   Cataltas O, 2017, 2017 INT ART INT DAT, P1, DOI [10.1109/IDAP.2017.8090342, DOI 10.1109/IDAP.2017.8090342]
   Çavusoglu Ü, 2017, CHAOS SOLITON FRACT, V95, P92, DOI 10.1016/j.chaos.2016.12.018
   COOPERSMITH D, 1994, IBM J RES DEV, V38, P243, DOI 10.1147/rd.383.0243
   ERDMANN D, 1992, ELECTRON LETT, V28, P893, DOI 10.1049/el:19920563
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Hamza R, 2017, J INF SECUR APPL, V35, P119, DOI 10.1016/j.jisa.2017.06.005
   Jawad LM, 2015, NONLINEAR DYNAM, V81, P2079, DOI 10.1007/s11071-015-2127-9
   Khan M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0225031
   Khan M, 2019, INT J THEOR PHYS, V58, P4293, DOI 10.1007/s10773-019-04301-6
   Khan M, 2019, INT J THEOR PHYS, V58, P2720, DOI 10.1007/s10773-019-04162-z
   Khan M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206460
   Khan M, 2014, NEURAL COMPUT APPL, V25, P1717, DOI 10.1007/s00521-014-1663-4
   Krishnamurthy GN, 2010, ARXIV PREPRINT ARXIV
   Lee CS, 1997, FUZZY SET SYST, V89, P157, DOI 10.1016/S0165-0114(96)00075-9
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Mousa A, 2005, Proceedings ELMAR-2005, P131
   Nath A, 2010, IN SECURITY MANAGEME, P234
   Pal K, 2013, 2013 IEEE 1ST INTERNATIONAL CONFERENCE ON CONDITION ASSESSMENT TECHNIQUES IN ELECTRICAL SYSTEMS (CATCON), P368, DOI 10.1109/CATCON.2013.6737529
   Prasetyo Kurniawan Nur, 2014, 2014 2nd International Conference on Information and Communication Technology (ICoICT), P75, DOI 10.1109/ICoICT.2014.6914043
   Schneier B., 1993, INT WORKSH FAST SOFT, P191, DOI DOI 10.1007/3-540-58108-1_24
   Shah T., 2011, STAT ANAL S BOX IMAG, V6, P4110
   Singh P., 2013, International Journal of Scientific Engineering Research, V4, P150
   Tariq S, 2020, MULTIMED TOOLS APPL, V79, P23507, DOI 10.1007/s11042-020-09134-8
   Ueta T, 2000, INT J BIFURCAT CHAOS, V10, P1917, DOI 10.1142/S0218127400001183
   von Solms R, 2013, COMPUT SECUR, V38, P97, DOI 10.1016/j.cose.2013.04.004
   Wang Q, 2019, PROC CVPR IEEE, P8190, DOI 10.1109/CVPR.2019.00839
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang YL, 2009, PROCEEDINGS OF THE FIRST INTERNATIONAL WORKSHOP ON EDUCATION TECHNOLOGY AND COMPUTER SCIENCE, VOL III, P453, DOI 10.1109/ETCS.2009.630
   Waqas UA, 2020, MULTIMED TOOLS APPL, V79, P6891, DOI 10.1007/s11042-019-08570-5
   Waseem HM, 2020, IEEE ACCESS, V8, P71821, DOI 10.1109/ACCESS.2020.2987097
   Waseem HM, 2019, APPL PHYS B-LASERS O, V125, DOI 10.1007/s00340-019-7142-y
   Waseem HM, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.6.063022
   Weber A., 1997, The usc-sipi image database
   Whitman M. E., 2011, PRINCIPLES INFORM SE
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Yen JC, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL IV, P49, DOI 10.1109/ISCAS.2000.858685
NR 54
TC 5
Z9 5
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26069
EP 26091
DI 10.1007/s11042-021-10898-w
EA APR 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000644761700003
DA 2024-07-18
ER

PT J
AU Jiao, JC
   Liu, WL
   Mo, YK
   Jiao, J
   Deng, ZL
   Chen, XP
AF Jiao, Jichao
   Liu, Weilun
   Mo, Yaokai
   Jiao, Jian
   Deng, Zhongliang
   Chen, Xinping
TI Dyn-arcFace: dynamic additive angular margin loss for deep face
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Convolutional neural networks; Dynamic loss function;
   Over-fitting
AB Deep convolutional neural networks (CNNs) are widely used in face recognition, because they can extract features with higher discrimination, which is the basis for correctly identifying the identity of a face image. In order to improve the face recognition performance, in addition to improving the structures of convolutional neural networks, many new loss functions have been proposed to enhance the distinguishing ability of extract features. However, according to our research, it is found that when using the present loss functions in CNNs, there is overfitting of the training dataset and redeuces the effect of face recognition. Therefore, a new loss function called Dyn-arcFace(Dynamic Additive Angular Margin Loss for Deep Face Recognition) is proposed in this paper. In Dyn-arcFace, the traditional fixed additive angular margin is developed into a dynamic one, which can reduce the degree of overfitting caused by the fixed additive angular margin. To verify the effect of Dyn-arcFace, we tested on different layers of neural networks. The proposed algorithm achieved state-of-the-art performance on the most popular public-domain face recognition datasets.
C1 [Jiao, Jichao; Liu, Weilun; Mo, Yaokai; Jiao, Jian; Deng, Zhongliang; Chen, Xinping] Beijing Univ Posts & Telecommun, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Jiao, JC (corresponding author), Beijing Univ Posts & Telecommun, Beijing, Peoples R China.
EM jiaojichao@bupt.edu.cn
RI Chen, Xinping/C-7877-2018
OI JIAO, JICHAO/0000-0002-1200-5525
FU National Key Research and Development Program [2016YFB0502002];
   Fundamental Research Funds for the Central Universities [2019PTB-010]
FX The project sponsored by the National Key Research and Development
   Program (No.2016YFB0502002) and the Fundamental Research Funds for the
   Central Universities under Grant 2019PTB-010. We would like to express
   our sincere appreciation to Prof. Ning Li, Prof. Wei Xu served as
   scientific advisors. Bedides, we also thank the anonymous reviewers for
   their insightful comments, which have greatly aided us in improving the
   quality of the paper.
CR Abualigah L. M. Q., 2019, Feature selection and enhanced krill herd algorithm for text document clustering, DOI [DOI 10.1007/978-3-030-10674-4, 10.1007/978-3-030-10674-4]
   Abualigah L, 2020, NEURAL COMPUT APPL, V32, P12381, DOI 10.1007/s00521-020-04839-1
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   AlWaisy AS, 2020, DEEP LEARNING COMPUT, P89
   [Anonymous], 2017, One-shot face recognition by promoting underrepresented classes
   DENG J, 2017, P IEEE C COMPUTER VI, P60, DOI DOI 10.1109/CVPRW.2017.251
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Dong XP, 2018, LECT NOTES COMPUT SC, V11217, P472, DOI 10.1007/978-3-030-01261-8_28
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Liu L, 2019, IEEE I CONF COMP VIS, P2570, DOI 10.1109/ICCV.2019.00266
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Liu WL, 2019, LECT NOTES COMPUT SC, V11903, P642, DOI 10.1007/978-3-030-34113-8_53
   Liu WY, 2016, PR MACH LEARN RES, V48
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250
   Parkhi OM, 2015, Proceedings of the British Machine Vision Conference, DOI DOI 10.5244/C.29.41
   Prasoon A, 2013, LECT NOTES COMPUT SC, V8150, P246, DOI 10.1007/978-3-642-40763-5_31
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sengupta S, 2016, IEEE WINT CONF APPL
   Sharma P, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901319
   Simard PY, 2003, PROC INT CONF DOC, P958
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Wang F, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1041, DOI 10.1145/3123266.3123359
   Wang F, 2018, IEEE SIGNAL PROC LET, V25, P926, DOI 10.1109/LSP.2018.2822810
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Zhang X, 2017, IEEE I CONF COMP VIS, P5419, DOI 10.1109/ICCV.2017.578
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 35
TC 10
Z9 11
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25741
EP 25756
DI 10.1007/s11042-021-10865-5
EA APR 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000642836400001
DA 2024-07-18
ER

PT J
AU Shaily, S
   Krishnan, S
   Natarajan, S
   Periyasamy, S
AF Shaily, Shubhi
   Krishnan, Srikaran
   Natarajan, Saisriram
   Periyasamy, Sasikumar
TI Smart driver monitoring system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; OBD-II; Raspberry pi; Mobile app; On-board camera;
   Drowsiness; Fatigue
AB Driver fatigue and drowsiness is an ever-rising issue that could place a lot of entities at risk. The associated problems are not only dangerous for the driver and the passenger but they pose a negative image on an industry that functions using drivers that work long hours in tough road conditions. In this work, proposed to develop a driver drowsiness detector based on image processing. The system created will work based on vehicle details received from the OBD-II and the camera mounted on the dashboard to monitor the driver. The system is developed with the aim to provide a novel solution to driver drowsiness detection on-board whilst the car is being driven. The mechanism provided is both non-intrusive and involves the use of machine learning that will provide an accurate result that averts the major cause of road-based accidents.
C1 [Shaily, Shubhi; Krishnan, Srikaran; Natarajan, Saisriram; Periyasamy, Sasikumar] Vellore Inst Technol, Sch Elect Engn, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Periyasamy, S (corresponding author), Vellore Inst Technol, Sch Elect Engn, Vellore 632014, Tamil Nadu, India.
EM sasikumar.p@vit.ac.in
RI P, Sasikumar/J-1953-2019
OI P, Sasikumar/0000-0003-3510-3694
CR Alajrami E, 2019, 2019 INTERNATIONAL CONFERENCE ON PROMISING ELECTRONIC TECHNOLOGIES (ICPET 2019), P91, DOI 10.1109/ICPET.2019.00024
   Gaspar JG, 2017, TRAFFIC INJ PREV, V18, pS58, DOI 10.1080/15389588.2017.1303140
   Ibrahim LF, 2014, MULTIMED TOOLS APPL, V71, P1857, DOI 10.1007/s11042-012-1308-5
   Isaza C, 2019, MULTIMED TOOLS APPL, V78, P19543, DOI 10.1007/s11042-019-7218-z
   Kamarudin Nora, 2019, Universal Journal of Electrical and Electronic Engineering, V6, P67, DOI DOI 10.13189/UJEEE.2019.061609
   Kiashari SEH, 2020, MULTIMED TOOLS APPL, V79, P17793, DOI 10.1007/s11042-020-08696-x
   Li YT, 2016, MULTIMED TOOLS APPL, V75, P16959, DOI 10.1007/s11042-015-2969-7
   Lim SM, 2015, SINGAP MED J, V56, P92, DOI 10.11622/smedj.2014169
   Lin YN, 2020, MULTIMED TOOLS APPL, V79, P34339, DOI 10.1007/s11042-020-08907-5
   Maior CS, 2018, P PROB SAF ASS MAN P
   Shi-Huang Chen, 2011, Proceedings of the 2011 Fifth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing (IMIS), P567, DOI 10.1109/IMIS.2011.108
   Smys S, 2019, COMPUTATIONAL VISION
   Vesselenyi T, 2017, IOP CONF SER-MAT SCI, V252, DOI 10.1088/1757-899X/252/1/012097
   Zhang Y, 2019, MULTIMED TOOLS APPL, V78, P26661, DOI 10.1007/s11042-019-07836-2
NR 14
TC 5
Z9 6
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25633
EP 25648
DI 10.1007/s11042-021-10877-1
EA APR 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000642049300001
DA 2024-07-18
ER

PT J
AU Lohala, S
   Alsadoon, A
   Prasad, PWC
   Ali, RS
   Altaay, AJ
AF Lohala, Saurav
   Alsadoon, Abeer
   Prasad, P. W. C.
   Ali, Rasha S.
   Altaay, Alaa Jabbar
TI A novel deep learning neural network for fast-food image classification
   and prediction using modified loss function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep convolutional neural network; Classification; Modified loss
   function regularization
ID DIETARY ASSESSMENT; RECOGNITION
AB Accurate food image classification is often critical to accurately monitor the dietary assessment to reduce the risk of different heart-related diseases, obesity, diabetes, and other related health conditions. The accuracy and efficiency of image classification results when using traditional deep learning methods were less than optimal. This research aimed at enhancing the classification and prediction accuracy of food images and reducing the processing time by using the Deep Convolutional Neural Network (DCN) algorithm. The solution starts by using the Modified Loss function, the images are fed into the DCN for features extraction through alternating between convolutional layers and pooling layers, then this is followed by a fully connected layer. Finally, the Softmax function is used to classify the images. The result was compared during the classification phase in the DCN. The proposed solution enhanced the accuracy of the classification by using the regularized loss function and lowered the processing time by decreasing the weights of the neurons in the neural network. Probability score is used as the evaluation metric for the accuracy, and total execution time is used as the evaluation metric for the speed of the algorithm. The combination of deep neural network with regularized cross entropy cost function has improved the fast-food images classification by ahcieving better processing time by 40 similar to 50s and accuracy by 5% in average.
C1 [Lohala, Saurav; Alsadoon, Abeer; Prasad, P. W. C.] Charles Sturt Univ CSU, Sch Comp & Math, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Kent Inst Australia, Informat Technol Dept, Sydney, NSW, Australia.
   [Ali, Rasha S.] AL Nisour Univ Coll, Dept Comp Tech Engn, Baghdad, Iraq.
   [Altaay, Alaa Jabbar] Mustansiriyah Univ, Coll Sci, Dept Comp Sci, Baghdad, Iraq.
C3 Charles Sturt University; Western Sydney University; Al-Nisour
   University College; Mustansiriya University
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp & Math, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Informat Technol Dept, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Quispe Calcina, Willian/JRX-9094-2023; Ali, Rasha Subhi/X-9445-2018;
   ALI, Rasha/JBJ-4318-2023; Alsadoon, A/Prof. Abeer/AAU-1532-2021; Altaay,
   Alaa A. Jabbar/F-3660-2019
OI Ali, Rasha Subhi/0000-0002-9767-7151; Alsadoon, A/Prof.
   Abeer/0000-0002-2309-3540; withana, chandana/0000-0002-3007-687X;
   Altaay, Alaa A. Jabbar/0000-0001-8654-142X; Subhi,
   Rasha/0000-0001-6718-5618; Ali, Rasha/0000-0003-3427-423X
CR Bossard L, 2014, FOOD 101 MINING DISC
   Chen YT, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02066-z
   Ciocca G, 2017, IEEE J BIOMED HEALTH, V21, P588, DOI 10.1109/JBHI.2016.2636441
   Emmanuel WRS, 2018, SADHANA-ACAD P ENG S, V43, DOI 10.1007/s12046-018-0865-3
   Graesser L, 2016, REGULARIZATION NEURA
   Khaw HY, 2017, IET IMAGE PROCESS, V11, P1238, DOI 10.1049/iet-ipr.2017.0374
   Laarhoven TV, 2017, L2 REGULARIZATION VE
   Lee MC, 2017, INFORM PROCESS LETT, V128, P14, DOI 10.1016/j.ipl.2017.07.010
   Liang HJ, 2019, IEEE T SYST MAN CY-S, V49, P299, DOI [10.1109/TSMC.2018.2791513, 10.1080/1206212X.2018.1486558]
   Liu C, 2018, IEEE T SERV COMPUT, V11, P249, DOI 10.1109/TSC.2017.2662008
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2386, DOI 10.1109/TPAMI.2020.3041332
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   McAllister P, 2018, COMPUT BIOL MED, V95, P217, DOI 10.1016/j.compbiomed.2018.02.008
   Mezgec S, 2019, PUBLIC HEALTH NUTR, V22, P1193, DOI 10.1017/S1368980018000708
   Mezgec S, 2017, NUTRIENTS, V9, DOI 10.3390/nu9070657
   Minija SJ, 2017, IMAGING SCI J, V65, P379, DOI 10.1080/13682199.2017.1356610
   Murphy J, 2016, SEMANTIC SCHOLAR
   Nielsen M.A., 2015, Determination Press
   Ochiai T, 2016, AUTOMATIC NODE SELEC
   OShea K., 2015, arXiv
   Pelt DM, 2018, P NATL ACAD SCI USA, V115, P254, DOI 10.1073/pnas.1715832114
   Podutwar AA., 2017, INT J ADV RES COMPUT, V6, P243, DOI [10.17148/IJARCCE.2017.6146, DOI 10.17148/IJARCCE.2017.6146]
   Poernomo A, 2018, NEURAL NETWORKS, V104, P60, DOI 10.1016/j.neunet.2018.03.016
   Pouladzadeh P, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3063592
   Salvador A, 2019, PROC CVPR IEEE, P10445, DOI 10.1109/CVPR.2019.01070
   Sun X, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0156327
   Zhang XJ, 2016, J COMPUT SCI TECH-CH, V31, P489, DOI 10.1007/s11390-016-1642-6
NR 27
TC 4
Z9 5
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25453
EP 25476
DI 10.1007/s11042-021-10916-x
EA APR 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000640862600008
DA 2024-07-18
ER

PT J
AU Ma, KY
   Teng, L
   Wang, XY
   Meng, J
AF Ma, Kaiyun
   Teng, Lin
   Wang, Xingyuan
   Meng, Juan
TI Color image encryption scheme based on the combination of the
   fisher-yates scrambling algorithm and chaos theory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fisher-yates scrambling algorithm; SHA-384; Three-dimensional Chen
   chaotic system; Color image encryption
ID ARNOLD TRANSFORM; SYSTEM; MAP
AB In order to obtain a more secure and effective image encryption scheme, a color image encryption scheme based on Fisher-Yates scrambling algorithm and chaos theory is proposed. First, the (secure hash algorithm) SHA-384 is used to generate the key by combining the plaintext image and the encrypted time point. Then, three groups of chaotic sequences are obtained by iterating the three-dimensional Chen chaotic system, and three groups of pseudo-random sequences are obtained by processing with the key. The first group of pseudo-random sequences combined with the Fisher's algorithm for image pixel position scrambling. A new pixel value substitution method is proposed using the second group of sequences to control each pixel value substitution of the image. The last group generated the matrix after pixel substitution was used for diffusion transformation to obtain the final encrypted image. The test results show that the scheme has broad application prospects.
C1 [Teng, Lin; Wang, Xingyuan] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
   [Ma, Kaiyun; Meng, Juan] Dalian Ocean Univ, Sch Informat Engn, Dalian 116023, Liaoning, Peoples R China.
C3 Dalian Maritime University; Dalian Ocean University
RP Teng, L (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
EM tenglin@mail.dlut.edu.com; wangxy@dlmu.edu.cn
RI Wang, Xing-yuan/I-6353-2015
OI Teng, Lin/0000-0002-3758-4439
FU China Postdoctoral Science Foundation [2020 M680933]; National Natural
   Science Foundation of China [61701070, 61672124]; Doctoral Start-up
   Foundation of Liaoning Province [2018540090]; Liaoning Province Science
   and Technology Innovation Leading Talents Program Project [XLYC1802013];
   Key R&D Projects of Liaoning Province [2019020105-JH2/103]; Jinan City
   `20 universities' Funding Projects Introducing Innovation Team Program
   [2019GXRC031]
FX This work is supported by the China Postdoctoral Science Foundation (No:
   2020 M680933), National Natural Science Foundation of China (Nos:
   61701070, 61672124), the Doctoral Start-up Foundation of Liaoning
   Province (No: 2018540090), Liaoning Province Science and Technology
   Innovation Leading Talents Program Project (No: XLYC1802013), Key R&D
   Projects of Liaoning Province (No: 2019020105-JH2/103), Jinan City `20
   universities' Funding Projects Introducing Innovation Team Program (No:
   2019GXRC031).
CR Abd EL-Latif AA, 2020, PHYSICA A, V547, DOI 10.1016/j.physa.2019.123869
   Abuturab MR, 2020, OPT LASER ENG, V129, DOI 10.1016/j.optlaseng.2020.106038
   Al-Odat Z, 2019, INT C FRONT INF TECH
   Azimi Z, 2020, MULTIMED TOOLS APPL, V79, P1727, DOI 10.1007/s11042-019-08375-6
   Babaei A, 2020, OPTIK, V203, DOI 10.1016/j.ijleo.2019.164000
   Chen GR, 1999, INT J BIFURCAT CHAOS, V9, P1465, DOI 10.1142/S0218127499001024
   Chen JX, 2020, INFORM SCIENCES, V520, P130, DOI 10.1016/j.ins.2020.02.024
   Chen Y, 2019, IEEE ACCESS
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Dong H, 2020, IEEE ACCESS, V8, P163524, DOI 10.1109/ACCESS.2020.3022398
   ElKamchouchi DH, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020180
   Hu WW, 2020, QUANTUM INF PROCESS, V19, DOI 10.1007/s11128-020-02641-5
   Huang X, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/6567198
   Kaur M, 2020, FUTURE GENER COMP SY, V107, P333, DOI 10.1016/j.future.2020.02.029
   Kumar S, 2017, MULTIMED TOOLS APPL, V76, P8757, DOI 10.1007/s11042-016-3504-1
   Liu H, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21040343
   Liu XB, 2019, IEEE ACCESS, V7, P57188, DOI 10.1109/ACCESS.2019.2914184
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   MAHALAKSHMI B, 2019, IMAGE ENCRYPTION MET, P363
   Musanna F, 2019, MULTIMED TOOLS APPL, V78, P14867, DOI 10.1007/s11042-018-6827-2
   Niyat AY, 2020, MULTIMED TOOLS APPL, V79, P1497, DOI 10.1007/s11042-019-08247-z
   Tsafack N, 2020, IEEE ACCESS, V8, P137731, DOI 10.1109/ACCESS.2020.3010794
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Wang LY, 2016, OPT LASER ENG, V77, P118, DOI 10.1016/j.optlaseng.2015.07.015
   WANG X, 2019, CHINESE PHYS B, V28
   Wang XY, 2019, J FRANKLIN I, V356, P11638, DOI 10.1016/j.jfranklin.2019.10.006
   Wang XY, 2020, OPT LASER ENG, V125, DOI 10.1016/j.optlaseng.2019.105851
   Wu J, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22010005
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Zhang YQ, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106040
NR 30
TC 22
Z9 22
U1 3
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24737
EP 24757
DI 10.1007/s11042-021-10847-7
EA APR 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000638867400002
DA 2024-07-18
ER

PT J
AU Dou, YQ
   Li, M
AF Dou, Yuqiang
   Li, Ming
TI An image encryption algorithm based on a novel 1D chaotic map and
   compressive sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Compressive sensing; Novel 1D chaotic map; Bit-level
   operation
AB A new image encryption algorithm is presented based on a novel chaotic map and compressive sensing with excellent performance. At first, the sparse coefficient matrix is acquired by discrete wavelet transform (DWT) of the original image. Secondly, the SHA-512 hash value of the original image are regarded as the initial values of two novel 1D chaotic maps to generate two chaotic sequences. Furthermore, the measurement matrix is generated by one of the two chaotic maps. Next, the measurement result is scrambled based on bit-plane operations by another chaotic sequence. At last, the diffusion and rotation operations are carried out on the shuffled matrix to improve the security index of the proposed algorithm. It is indicated through the analyses of simulation experiment that the presented encryption algorithm is effective to resist statistical attacks, plaintext attacks and brute-force attacks and has good compression effect and robustness.
C1 [Dou, Yuqiang; Li, Ming] Henan Normal Univ, Big Data Engn Lab Teaching Resources & Assessment, Xinxiang 453007, Henan, Peoples R China.
C3 Henan Normal University
RP Dou, YQ (corresponding author), Henan Normal Univ, Big Data Engn Lab Teaching Resources & Assessment, Xinxiang 453007, Henan, Peoples R China.
EM douyuqiang@htu.edu.cn
FU National Natural Science Foundation of China [62072159, U1804164]; PhD
   Scientific Research Foundation of Henan Normal University [qd18027]
FX This work was supported by the National Natural Science Foundation of
   China (Grant no. 62072159, U1804164) and PhD Scientific Research
   Foundation of Henan Normal University (Grant no. qd18027).
CR [Anonymous], 2015, CHIN PHYS B
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Chai XL, 2020, NEURAL COMPUT APPL, V32, P4961, DOI 10.1007/s00521-018-3913-3
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Han J, 1995, LECT NOTES COMPUT SC, V930, P195
   Hu GQ, 2017, J VIS COMMUN IMAGE R, V44, P116, DOI 10.1016/j.jvcir.2017.01.022
   Huang Y, 2019, CARDIOL RES PRACT, V2019, DOI 10.1155/2019/3786024
   Idrees B, 2020, MULTIMED TOOLS APPL, V79, P6135, DOI 10.1007/s11042-019-08282-w
   Jain A, 2016, MULTIMED TOOLS APPL, V75, P5455, DOI 10.1007/s11042-015-2515-7
   Kaige Zhu, 2020, MATEC Web of Conferences, V309, DOI 10.1051/matecconf/202030903017
   kumar R. Ranjith, 2014, ICTACT J IMAGE VIDEO, V4, P795, DOI [DOI 10.21917/IJIVP.2014.0114, 10.21917/ijivp.2014.0114]
   Li T, 2017, CHINESE SOCIOL REV, V49, P212, DOI 10.1080/21620555.2016.1271701
   Liu JY, 2018, MULTIMED TOOLS APPL, V77, P10217, DOI 10.1007/s11042-017-5406-2
   Liu XY, 2013, OPTIK, V124, P6590, DOI 10.1016/j.ijleo.2013.05.092
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Machkour M, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0068-1
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Norouzi B, 2015, MULTIMED TOOLS APPL, V74, P781, DOI 10.1007/s11042-013-1699-y
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Pak C, 2019, MULTIMED TOOLS APPL, V78, P12027, DOI 10.1007/s11042-018-6739-1
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Pati YC, P 27 ANN AS C SIGN S
   Ponuma R, 2018, MULTIMED TOOLS APPL, V77, P19209, DOI 10.1007/s11042-017-5378-2
   Shaila SG, 2016, J VIS COMMUN IMAGE R, V36, P40, DOI 10.1016/j.jvcir.2016.01.003
   Shaila SG, 2012, PROC TECH, V1, P526, DOI 10.1016/j.protcy.2012.10.063
   Shao W., 2019, IEEE ACCESS, V7, P1, DOI 10.1109/ACCESS.2018.2876146
   Wang J., 2020, IEEE ACCESS, P1
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Xu L, 2018, OPT LASER TECHNOL
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
   Yin XF, 2020, MATER EXPRESS, V10, P1317, DOI 10.1166/mex.2020.1734
   Yu L, 2010, IEEE SIGNAL PROC LET, V17, P731, DOI 10.1109/LSP.2010.2052243
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang YS, 2014, NONLINEAR DYNAM, V76, P1645, DOI 10.1007/s11071-014-1235-2
   Zhang YS, 2013, SIGNAL PROCESS-IMAGE, V28, P292, DOI 10.1016/j.image.2012.12.009
   Zhang YS, 2013, NONLINEAR DYNAM, V72, P751, DOI 10.1007/s11071-013-0750-x
   Zhang Z., 2020, COMPLEXITY, V12, P1
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou NR, 2014, OPTIK, V125, P5075, DOI 10.1016/j.ijleo.2014.06.054
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhu HG, 2013, SIGNAL PROCESS-IMAGE, V28, P670, DOI 10.1016/j.image.2013.02.004
NR 45
TC 15
Z9 15
U1 4
U2 59
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24437
EP 24454
DI 10.1007/s11042-021-10850-y
EA APR 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000637475700002
DA 2024-07-18
ER

PT J
AU Liu, GQ
   Rehman, MU
   Wu, YH
AF Liu, Guoqi
   Rehman, Mujeeb Ur
   Wu, Yuhou
TI Personal trajectory analysis based on informative lifelogging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lifelog; Informative lifelogging; Personal trajectory
AB Facing a great deal of Lifelog data and complex information, how to extract valuable information and making it easily understood for users is the most urgent and important issue. This paper introduces a method to find personal trajectories from a Lifelog dataset named informative lifelogging which the author collected over the past 8 years. After introducing the Lifelog system and the data structure, this paper propose a method to find personal trajectory in the dataset. Experiment result in the last chapter shows the correctness of this method. The method proposed in this paper provides some way of managing and retrieving the Lifelog data efficiently.
C1 [Liu, Guoqi] Shenyang Jianzhu Univ, Sch Sci, Shenyang, Liaoning, Peoples R China.
   [Rehman, Mujeeb Ur] Northeastern Univ, Software Coll, Shenyang, Liaoning, Peoples R China.
   [Wu, Yuhou] Shenyang Jianzhu Univ, Sch Mech Engn, Shenyang, Liaoning, Peoples R China.
C3 Shenyang Jianzhu University; Northeastern University - China; Shenyang
   Jianzhu University
RP Liu, GQ (corresponding author), Shenyang Jianzhu Univ, Sch Sci, Shenyang, Liaoning, Peoples R China.
EM liuguoqi@sjzu.edu.cn; engrmujeebshinwari@gmail.com; giantliu@126.com
RI Rehman, Mujeeb/AAE-7374-2019
OI Liu, Guoqi/0000-0001-6427-5650
CR Belhadi A, 2020, ACM TRANS MANAG INF, V11, DOI 10.1145/3399631
   Belhassena A, 2019, TSINGHUA SCI TECHNOL, V24, P317, DOI 10.26599/TST.2018.9010087
   Bianchini M., 2005, ACM Transactions on Internet Technology, V5, P92, DOI 10.1145/1052934.1052938
   Cho SJ, 2019, GEOGR ANAL, V51, P203, DOI 10.1111/gean.12186
   Clinch S, 2016, IEEE PERVAS COMPUT, V15, P58, DOI 10.1109/MPRV.2016.6
   Fayyad U M., ADV KNOWLEDGE DISCOV
   Gurrin C., 2014, LIFELOGGING PERSONAL
   Hamid A., 2017, 2017 INT C WIR TECHN, P1
   Han J, 2012, MOR KAUF D, P1
   Jo H, 2010, IEEE T VIS COMPUT GR, V16, P221, DOI 10.1109/TVCG.2009.68
   Junjie Y., 2019, COMPUTER ENG
   Keller EF, 2005, BIOESSAYS, V27, P1060, DOI 10.1002/bies.20294
   Kim PH, 2011, NEXT GEN WEB SERV PR
   Langville A., 2004, INTERNET MATH, V1, P335, DOI DOI 10.1080/15427951.2004.10129091
   Li F., 2019, IEEE ACCESS
   Li Q., 2008, P 16 ACM SIGSPATIAL, P1, DOI DOI 10.1145/1463434.1463477
   Li Zhenhui, 2010, P KDD10 P 16 ACM SIG, P1099, DOI DOI 10.1145/1835804.1835942
   Liu XL, 2016, MULTIMED TOOLS APPL, V75, P1495, DOI 10.1007/s11042-014-2085-0
   Mann S, 1997, COMPUTER, V30, P25, DOI 10.1109/2.566147
   Mazimpaka JD, 2016, J SPAT INF SCI, P61, DOI 10.5311/JOSIS.2016.13.263
   Page L, 1998, PAGERANK CITATION RA
   Paulraj MP, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING & COMMUNICATION SYSTEMS (ICACCS)
   Pelekis N, 2014, MOBILITY DATA MANAGE, DOI [10.1007/978-1-4939-0392-4, DOI 10.1007/978-1-4939-0392-4]
   Saloot MA, 2013, 2013 FIRST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, MODELLING AND SIMULATION (AIMS 2013), P123, DOI 10.1109/AIMS.2013.27
   Spinsanti L, 2013, MOBILITY DATA: MODELING, MANAGEMENT, AND UNDERSTANDING, P315
   Wang JW, 2020, IEEE T VEH TECHNOL, V69, P2487, DOI 10.1109/TVT.2020.2967865
   Wang N, 2020, DISTRIB PARALLEL DAT, V38, P667, DOI 10.1007/s10619-020-07290-2
   Wang YL, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P25, DOI 10.1145/2623330.2623656
   Yuan J, 2013, IEEE T KNOWL DATA EN, V25, P220, DOI 10.1109/TKDE.2011.200
   Yuan NJ, 2013, IEEE T KNOWL DATA EN, V25, P2390, DOI 10.1109/TKDE.2012.153
   Zhou YR, 2020, IEEE INTERNET THINGS, V7, P4442, DOI 10.1109/JIOT.2020.2972062
NR 31
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 22177
EP 22191
DI 10.1007/s11042-021-10755-w
EA MAR 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000632315900001
DA 2024-07-18
ER

PT J
AU Raghuvanshi, KK
   Kumar, S
   Kumar, S
   Kumar, S
AF Raghuvanshi, Kamlesh Kumar
   Kumar, Subodh
   Kumar, Sushil
   Kumar, Sunil
TI Development of new encryption system using Brownian motion based
   diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 2D Brownian motion; Diffusion; Intertwining logistic map; Encryption
ID INTERTWINING CHAOTIC MAPS; CRYPTOGRAPHIC MODEL; EMBEDDING CAPACITY;
   LEVEL PERMUTATION; IMAGE; ALGORITHM; SCHEME; CRYPTANALYSIS; DNA;
   EFFICIENT
AB A new cryptographic model is proposed incorporating intertwining logistic map based confusion process and two dimensional Brownian Motion based diffusion algorithm. An intertwining logistic map is utilized in the algorithm to provide better distribution of random numbers and to overcome blank and stable windows noticed in the schematic of logistic map's bifurcation. Most of the existing image encryptionmodels use raw images without any modification for the confusion and diffusion processes. Their main drawback is that original pixel values remain the same. This problem is overcome by a Pseudo random generator based key stream that modifies pixel values. Further, an intertwining logistic map based confusion process enhances the key sensitivity and complex relationship is created between cipher and test image. Finally, two dimensional Brownian motion based diffusion is applied to bind pixels with each other to such a degree that even one bit modification in the original image affects most of the pixels in the cipher. This makes the model sensitive to change in pixel value or secret key. Various test results indicate that the proposed encryption model can encrypt the plain image into a cipher of random binary sequence. Correlation coefficients among cipher image pixels is found to be negligible, NPCR values are greater than 99.60% (average) and the model is resistive against brute-force, statistical and differential attacks.
C1 [Raghuvanshi, Kamlesh Kumar; Kumar, Subodh] Univ Delhi, Ramanujan Coll, Dept Comp Sci, Delhi, India.
   [Kumar, Sushil] Univ Delhi, Shyam Lal Coll M, North Campus, Delhi, India.
   [Kumar, Sunil] Univ Delhi, Inst Informat & Commun, South Campus,Benito Juarez Rd, New Delhi 110021, India.
C3 University of Delhi; University of Delhi; University of Delhi
RP Raghuvanshi, KK (corresponding author), Univ Delhi, Ramanujan Coll, Dept Comp Sci, Delhi, India.; Kumar, S (corresponding author), Univ Delhi, Inst Informat & Commun, South Campus,Benito Juarez Rd, New Delhi 110021, India.
EM raghukamlesh@gmail.com; sunilkumar104@gmail.com
RI Raghuvanshi, Kamlesh kumar/AAH-8349-2020; Kumar, Sunil/IZP-8008-2023;
   Kumar, Sunil/AAS-9326-2020; Kumar, Sunil/C-9559-2018
OI Raghuvanshi, Kamlesh kumar/0000-0001-9887-3392; Kumar,
   Sunil/0000-0002-7996-6427; KUMAR, SUNIL/0000-0003-2593-3432
FU University Grant Commission [3540/(NET-JUNE 2014)]
FX Sunil Kumar acknowledges University Grant Commission for the financial
   support provided under UGC-Ref.No: 3540/(NET-JUNE 2014).
CR Abbas NA, 2016, EGYPT INFORM J, V17, P139, DOI 10.1016/j.eij.2015.10.001
   Abdelfatah RI, 2020, MULTIMED TOOLS APPL, V79, P19717, DOI 10.1007/s11042-020-08788-8
   Akhavan A, 2017, OPT LASER TECHNOL, V95, P94, DOI 10.1016/j.optlastec.2017.04.022
   Amani HR, 2019, MULTIMED TOOLS APPL, V78, P21537, DOI 10.1007/s11042-018-6989-y
   Annaby MH, 2018, OPT LASER ENG, V103, P9, DOI 10.1016/j.optlaseng.2017.11.005
   Ariatmanto D, 2020, MULTIMED TOOLS APPL, V79, P12041, DOI 10.1007/s11042-019-08338-x
   Bansal R, 2017, MULTIMED TOOLS APPL, V76, P16529, DOI 10.1007/s11042-016-3926-9
   Bhatnagar G, 2013, INFORM SCIENCES, V223, P297, DOI 10.1016/j.ins.2012.09.053
   Biswas P, 2020, MULTIMED TOOLS APPL, V79, P31715, DOI 10.1007/s11042-020-09497-y
   Brahim AH, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106489
   Chai XL, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/2/020504
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Chan J, 2015, POLITICS IN THE CORRIDOR OF DYING: AIDS ACTIVISM AND GLOBAL HEALTH GOVERNANCE, P1
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JX, 2015, SIGNAL PROCESS, V111, P294, DOI 10.1016/j.sigpro.2015.01.003
   Chen JX, 2014, NONLINEAR DYNAM, V77, P1191, DOI 10.1007/s11071-014-1370-9
   Dong CE, 2014, SIGNAL PROCESS-IMAGE, V29, P628, DOI 10.1016/j.image.2013.09.006
   Dou YQ, 2017, OPTIK, V145, P456, DOI 10.1016/j.ijleo.2017.08.050
   El Ogri O, 2021, OPT LASER ENG, V137, DOI 10.1016/j.optlaseng.2020.106346
   Elmanfaloty RA, 2019, CHAOS SOLITON FRACT, V118, P134, DOI 10.1016/j.chaos.2018.11.019
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Etem T, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.122750
   Fu C, 2013, COMPUT BIOL MED, V43, P1000, DOI 10.1016/j.compbiomed.2013.05.005
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P27919, DOI 10.1007/s11042-018-5974-9
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Hua ZY, 2021, INFORM SCIENCES, V546, P1063, DOI 10.1016/j.ins.2020.09.032
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Huang LL, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/3965281
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Islam MO, 2012, INT CONF COMPUT INFO, P458, DOI 10.1109/ICCITechn.2012.6509735
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Kaur M, 2018, MOD PHYS LETT B, V32, DOI 10.1142/S0217984918501154
   Kumar Manish, 2016, 2016 International Conference on Computational Techniques in Information and Communication Technologies (ICCTICT). Proceedings, P618, DOI 10.1109/ICCTICT.2016.7514653
   Kumar M, 2018, J INF SECUR APPL, V40, P134, DOI 10.1016/j.jisa.2018.03.007
   Kumar M, 2017, J INF SECUR APPL, V32, P47, DOI 10.1016/j.jisa.2016.09.002
   Kumar S, 2019, J INF SECUR APPL, V46, P70, DOI 10.1016/j.jisa.2019.02.011
   Kumar S, 2018, PROCEDIA COMPUT SCI, V143, P804, DOI 10.1016/j.procs.2018.10.386
   Kumar S, 2018, J INF SECUR APPL, V43, P123, DOI 10.1016/j.jisa.2018.10.011
   Kumari M, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0162-2
   Kwok HS, 2007, CHAOS SOLITON FRACT, V32, P1518, DOI 10.1016/j.chaos.2005.11.090
   Li CQ, 2017, IEEE MULTIMEDIA, V24, P64, DOI 10.1109/MMUL.2017.3051512
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Li ZY, 2017, IEEE T APPL SUPERCON, V27, DOI [10.1109/TASC.2016.2634326, 10.1142/S0218127417501553]
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Liu HJ, 2015, OPT COMMUN, V338, P340, DOI 10.1016/j.optcom.2014.10.021
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Liu YX, 2019, SIGNAL PROCESS-IMAGE, V78, P216, DOI 10.1016/j.image.2019.07.013
   Mollaeefar M, 2017, MULTIMED TOOLS APPL, V76, P607, DOI 10.1007/s11042-015-3064-9
   Noura H, 2010, PROCEEDINGS OF THE 2010 8TH INTERNATIONAL CONFERENCE ON COMMUNICATIONS (COMM), P423, DOI 10.1109/ICCOMM.2010.5509114
   Özkaynak F, 2018, NONLINEAR DYNAM, V92, P305, DOI 10.1007/s11071-018-4056-x
   Özkaynak F, 2016, OPTIK, V127, P5190, DOI 10.1016/j.ijleo.2016.03.018
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Patel S, 2020, MULTIMED TOOLS APPL, V79, P31739, DOI 10.1007/s11042-020-09551-9
   Patidar V, 2009, COMMUN NONLINEAR SCI, V14, P3056, DOI 10.1016/j.cnsns.2008.11.005
   Peng XN, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110044
   Rhouma R, 2009, CHAOS SOLITON FRACT, V40, P309, DOI 10.1016/j.chaos.2007.07.083
   Sam IS, 2012, NONLINEAR DYNAM, V69, P1995, DOI 10.1007/s11071-012-0402-6
   Seyedzadeh SM, 2015, NONLINEAR DYNAM, V81, P511, DOI 10.1007/s11071-015-2008-2
   Sharma SS, 2020, MULTIMED TOOLS APPL, V79, P32769, DOI 10.1007/s11042-020-09555-5
   UbaidurRahman NH, 2015, PROCEDIA COMPUT SCI, V46, P463, DOI 10.1016/j.procs.2015.02.045
   Wang XF, 2021, MULTIMED TOOLS APPL, V80, P943, DOI 10.1007/s11042-020-09533-x
   Wang XY, 2020, CHAOS SOLITON FRACT, V141, DOI 10.1016/j.chaos.2020.110309
   Wang XY, 2016, NONLINEAR DYNAM, V84, P1417, DOI 10.1007/s11071-015-2579-y
   Wang XY, 2014, NONLINEAR DYNAM, V75, P345, DOI 10.1007/s11071-013-1070-x
   Wang XY, 2013, COMMUN NONLINEAR SCI, V18, P3075, DOI 10.1016/j.cnsns.2013.04.008
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu JH, 2018, SIGNAL PROCESS, V142, P292, DOI 10.1016/j.sigpro.2017.06.014
   Wu XJ, 2014, COMMUN NONLINEAR SCI, V19, P1884, DOI 10.1016/j.cnsns.2013.10.025
   Wu XY, 2015, PLOS ONE, V10, DOI [10.1371/journal.pone.0118041, 10.1371/journal.pone.0119607]
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Yang CN, 2019, MULTIMED TOOLS APPL, V78, P18595, DOI 10.1007/s11042-019-7220-5
   Yao SY, 2017, OPT LASER TECHNOL, V97, P234, DOI 10.1016/j.optlastec.2017.07.005
   Ye GD, 2017, NEUROCOMPUTING, V251, P45, DOI 10.1016/j.neucom.2017.04.016
   Zhang LY, 2018, IEEE T CYBERNETICS, V48, P1163, DOI 10.1109/TCYB.2017.2682561
   Zhang LY, 2012, J SYST SOFTWARE, V85, P2077, DOI 10.1016/j.jss.2012.04.002
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhao FX, 2021, OPT LASER TECHNOL, V135, DOI 10.1016/j.optlastec.2020.106610
   Zhao TY, 2016, OPT COMMUN, V376, P47, DOI 10.1016/j.optcom.2016.05.016
   Zhu CX, 2015, NONLINEAR DYNAM, V79, P1511, DOI 10.1007/s11071-014-1757-7
NR 85
TC 4
Z9 4
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21011
EP 21040
DI 10.1007/s11042-021-10665-x
EA MAR 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000628104400001
DA 2024-07-18
ER

PT J
AU Tian, Y
   Zhou, XL
   Wang, XF
   Wang, ZF
   Yao, H
AF Tian, Yuan
   Zhou, Xiaolei
   Wang, Xuefan
   Wang, Zhifeng
   Yao, Huang
TI Registration and occlusion handling based on the FAST ICP-ORB method for
   augmented reality systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; 3D registration; Occlusion handling
AB Spatial position consistency and occlusion consistency are two important problems in augmented reality systems. In this paper, we proposed a novel method that can address the registration problem and occlusion problem simultaneously by using an RGB-D camera. First, to solve the image alignment errors caused by the imaging mode of the RGB-D camera, we developed a depth map inpainting method that combines the FMM and RGB-D information. Second, we established an automatic method to judge the close-range mode based on the depth histogram to solve the registration failure problem caused by hardware limitations. In the close-range mode, the registration method combining the fast ICP and ORB was adopted to calculate the camera pose. Third, we developed an occlusion handling method based on the geometric analysis of the scene. Several experiments were performed to validate the performance of the proposed method. The experimental results indicate that our method can obtain stable and accurate registration and occlusion handling results in both the close-range and non-close-range modes. Moreover, the mutual occlusion problem can be handled effectively, and the proposed method can satisfy the real-time requirements of augmented reality systems.
C1 [Tian, Yuan; Zhou, Xiaolei; Wang, Xuefan; Wang, Zhifeng; Yao, Huang] Cent China Normal Univ, Sch Educ Informat Technol, Wuhan 430079, Peoples R China.
C3 Central China Normal University
RP Tian, Y (corresponding author), Cent China Normal Univ, Sch Educ Informat Technol, Wuhan 430079, Peoples R China.
EM tianyuan_ccnu@163.com
RI Tian, Yuan/B-1553-2009; Wang, Zhifeng/ITT-2561-2023; Yao,
   Huang/JDV-5932-2023
OI Wang, Zhifeng/0000-0001-6960-509X; TIAN, Yuan/0000-0002-9097-4639
FU Humanities and Social Sciences Foundation of the Ministry of Education
   [19YJC880079]; CCNU from the colleges' basic research and operation of
   MOE [CCNU20ZN002]
FX This work is financially supported by the Humanities and Social Sciences
   Foundation of the Ministry of Education (No: 19YJC880079) and
   self-determined research funds of CCNU from the colleges' basic research
   and operation of MOE (No. CCNU20ZN002).
CR Abu Alhaija H, 2018, INT J COMPUT VISION, V126, P961, DOI 10.1007/s11263-018-1070-x
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Du C, 2016, INT SYM MIX AUGMENT, P54, DOI 10.1109/ISMAR.2016.17
   Feng Q., 2018, P 24 ACM S VIRT REAL
   Guan T, 2015, ACM T INTEL SYST TEC, V7, DOI 10.1145/2795234
   Hebborn AK, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P62, DOI 10.1109/ISMAR.2017.23
   KASPERI J, 2017, P ACM S VIRT REAL SO
   Klein G, 2008, INT SYM MIX AUGMENT, P57, DOI 10.1109/ISMAR.2008.4637324
   Leal-Melendrez J.A., 2013, PROGR PATTERN RECOGN, P447
   Lieberknecht S., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P147, DOI 10.1109/ISMAR.2011.6092380
   Markman A, 2016, OPT LETT, V41, P297, DOI 10.1364/OL.41.000297
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Ong KC, 1998, VISUAL COMPUT, V14, P153, DOI 10.1007/s003710050131
   Tan W, 2013, INT SYM MIX AUGMENT, P209, DOI 10.1109/ISMAR.2013.6671781
   Tian Y, 2018, MULTIMED TOOLS APPL, V77, P16561, DOI 10.1007/s11042-017-5228-2
   Tian Y, 2015, NEUROCOMPUTING, V156, P96, DOI 10.1016/j.neucom.2014.12.081
   Tian YA, 2010, SENSOR REV, V30, P210, DOI 10.1108/02602281011051399
   Wei BC, 2015, MULTIMEDIA SYST, V21, P381, DOI 10.1007/s00530-014-0364-2
   Xu C, 2008, LECT NOTES ARTIF INT, V5315, P121
   Yilmaz O, 2013, 2013 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMPUTER AND COMPUTATION (ICECCO), P115, DOI 10.1109/ICECCO.2013.6718242
   Yun K, 2018, PATTERN RECOGNIT TRA, V28, P10649
NR 21
TC 3
Z9 3
U1 3
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21041
EP 21058
DI 10.1007/s11042-020-10342-5
EA MAR 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000628104400005
DA 2024-07-18
ER

PT J
AU Ahmed, A
   Yousif, H
   He, ZH
AF Ahmed, Ahmed
   Yousif, Hayder
   He, Zhihai
TI Ensemble diversified learning for image classification with noisy labels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Noisy labels; Deep neural networks; Encoder networks; K-means clustering
ID DEEP NEURAL-NETWORKS
AB In this work, we develop a new approach for learning a deep neural network for image classification with noisy labels using ensemble diversified learning. We first partition the training set into multiple subsets with diversified image characteristics. For each subset, we train a separate deep neural network image classifier. These networks are then used to encode the input image into different feature vectors, providing diversified observations of the input image. The encoded features are then fused together and further analyzed by a decision network to produce the final classification output. We study image classification on noisy labels with and without the access to clean samples. Our extensive experimental results on the CIFAR-10 and MNIST datasets demonstrate that our proposed method outperforms existing methods by a large margin.
C1 [Ahmed, Ahmed; He, Zhihai] Univ Missouri, Dept Elect Engn & Comp Sci, Columbia, MO 65211 USA.
   [Yousif, Hayder] Southern Tech Univ, Basra Engn Tech Coll, Dept Elect Power Engn, Basra, Iraq.
C3 University of Missouri System; University of Missouri Columbia; Southern
   Technical University
RP He, ZH (corresponding author), Univ Missouri, Dept Elect Engn & Comp Sci, Columbia, MO 65211 USA.
EM hezhi@missouri.edu
RI Ahmed, Ahmed Q./ABH-6918-2020; Yousif, Hayder/AAG-2259-2020
OI Yousif, Hayder/0000-0002-7638-9505; AHMED, AHMED/0000-0002-9852-1570
CR Ahmed A, 2020, ECOL INFORM, V57, DOI 10.1016/j.ecoinf.2020.101063
   Azadi S., 2015, Auxiliary image regularization for deep cnns with noisy labels
   Barandela R, 2000, LECT NOTES COMPUT SC, V1876, P621
   Beigman Eyal, 2009, P JOINT C 47 ANN M A, P280
   Brodley CE, 1999, J ARTIF INTELL RES, V11, P131, DOI 10.1613/jair.606
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding YF, 2018, IEEE WINT CONF APPL, P1215, DOI 10.1109/WACV.2018.00138
   Fawzi A, 2017, IEEE SIGNAL PROC MAG, V34, P50, DOI 10.1109/MSP.2017.2740965
   Fergus R, 2010, P IEEE, V98, P1453, DOI 10.1109/JPROC.2010.2048990
   Ghosh A, 2015, NEUROCOMPUTING, V160, P93, DOI 10.1016/j.neucom.2014.09.081
   Han B, 2018, ADV NEUR IN, V31, DOI 10.5555/3327757.3327944
   Hendrycks D, 2018, ADV NEUR IN, V31
   Hinton GE, 2021, ADV NEURAL INFORM PR
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Jindal I, 2016, IEEE DATA MINING, P967, DOI [10.1109/ICDM.2016.124, 10.1109/ICDM.2016.0121]
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee KH, 2018, PROC CVPR IEEE, P5447, DOI 10.1109/CVPR.2018.00571
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2011, COMM COM INF SC, V186, P122
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Li JN, 2019, PROC CVPR IEEE, P5046, DOI 10.1109/CVPR.2019.00519
   Li YC, 2017, IEEE I CONF COMP VIS, P1928, DOI 10.1109/ICCV.2017.211
   Lu J, 2018, PR MACH LEARN RES, V80
   Manwani N, 2013, IEEE T CYBERNETICS, V43, P1146, DOI 10.1109/TSMCB.2012.2223460
   Masnadi-Shirazi Hamed, 2008, Advances in Neural Information Processing Systems, P1049
   Miranda ALB, 2009, LECT NOTES ARTIF INT, V5572, P417, DOI 10.1007/978-3-642-02319-4_50
   Nettleton DF, 2010, ARTIF INTELL REV, V33, P275, DOI 10.1007/s10462-010-9156-z
   Niu L, 2015, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR.2015.7298894
   Patrini G, 2017, PROC CVPR IEEE, P2233, DOI 10.1109/CVPR.2017.240
   Reed S, 2014, Training deep neural networks on noisy labels with bootstrapping
   Ren MY, 2018, PR MACH LEARN RES, V80
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rolnick David, 2017, ARXIV170510694
   Rooyen B. V., 2015, P ADV NEUR INF PROC, P10
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sukhbaatar Sainbayar, 2014, Training convolutional networks with noisy labels
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Tang ZC, 2019, IEEE ACCESS, V7, P128185, DOI 10.1109/ACCESS.2019.2940034
   Van Horn G, 2015, PROC CVPR IEEE, P595, DOI 10.1109/CVPR.2015.7298658
   Vandat A, 2017, ADV NEUR IN, V30
   Veit A, 2017, PROC CVPR IEEE, P6575, DOI 10.1109/CVPR.2017.696
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang YS, 2018, PROC CVPR IEEE, P8688, DOI 10.1109/CVPR.2018.00906
   Xiao T, 2015, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2015.7298885
   Yu Xingrui, 2019, PROC INT C MACH LEAR, P7164
   Yuan BD, 2018, IEEE WINT CONF APPL, P757, DOI 10.1109/WACV.2018.00088
   Zhang ZL, 2018, ADV NEUR IN, V31
NR 53
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 20759
EP 20772
DI 10.1007/s11042-021-10760-z
EA MAR 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000626812700001
DA 2024-07-18
ER

PT J
AU Babapour, S
   Lakestani, M
   Fatholahzadeh, A
AF Babapour, Shahab
   Lakestani, Mehrdad
   Fatholahzadeh, Abolfazl
TI AFISTA: Accelerated FISTA for sparse signal recovery and compressive
   sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Proximal algorithms; Compressed sensing; L-1 minimization; Basis pursuit
ID LINEAR CONVERGENCE; MONOTONE-OPERATORS; BREGMAN; L(1)-MINIMIZATION;
   SHRINKAGE; ALGORITHM; ITERATION
AB This paper presents a new fast iterative shrinkage-thresholding algorithm, termed AFISTA. The essential idea is to improve the convergence rate of FISTA using a new continuation strategy leading to a less number of iterations compared to FISTA. The convergence theorem of the AFISTA is proposed. In order to further accelerate the AFISTA method, it is equipped with the Barzilai-Borwein (BB) method. Also, for applications with orthogonal sensing matrix A, we proposed a specialized version of the AFISTA method. AFISTA is tailored for solving the basis pursuit problem which can be applied successfully on a variety of problems arising in signal and image processing issues such as sparse signal recovery, signal and image denoising, image restoration, and compressive sensing. To show the efficiency of the method, we compare our results with generalizations of linearized Bregman and fixed - point continuation (FPC) methods in sparse signal recovery applications, with split Bregman method in compressive sensing for sparse MRI and with Gradient projection for sparse reconstruction (GPSR) method in image deconvolution. Numerical results demonstrate that AFISTA overcomes all of the compared methods in convergence rate and some of them in both convergence rate and quality of reconstructed results.
C1 [Babapour, Shahab; Lakestani, Mehrdad; Fatholahzadeh, Abolfazl] Univ Tabriz, Fac Math Sci, Tabriz, Iran.
C3 University of Tabriz
RP Lakestani, M (corresponding author), Univ Tabriz, Fac Math Sci, Tabriz, Iran.
EM sh.falcon32@gmail.com; lakestani@tabrizu.ac.ir; abfzadeh@gmail.com
RI Lakestani, Mehrdad/AAE-4455-2019
OI Lakestani, Mehrdad/0000-0002-2752-0167
CR Ahani H, 2020, BIOMED ENG LETT, P1
   BARZILAI J, 1988, IMA J NUMER ANAL, V8, P141, DOI 10.1093/imanum/8.1.141
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Beck AR, 2009, AUGMENT ALTERN COMM, V25, P42, DOI 10.1080/07434610802131059
   Becker S, 2011, SIAM J IMAGING SCI, V4, P1, DOI 10.1137/090756855
   Ben-Tal A, 2001, MPSSIAM SER OPTIM
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   Bredies K, 2008, J FOURIER ANAL APPL, V14, P813, DOI 10.1007/s00041-008-9041-1
   BRUCK RE, 1977, J MATH ANAL APPL, V61, P159, DOI 10.1016/0022-247X(77)90152-4
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Chambolle A, 2015, J OPTIMIZ THEORY APP, V166, P968, DOI 10.1007/s10957-015-0746-4
   Chen S, IEEE P 1994 28 AS C
   Chen SL, 2017, CHIN CONT DECIS CONF, P2190, DOI 10.1109/CCDC.2017.7978878
   Combettes PL, 2005, MULTISCALE MODEL SIM, V4, P1168, DOI 10.1137/050626090
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Facchinei F., 2003, FINITE DIMENSIONAL V, VII, DOI DOI 10.1007/B97544
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Hale ET, 2008, SIAM J OPTIMIZ, V19, P1107, DOI 10.1137/070698920
   Han J., 2017, P SEG AUG, P2174, DOI [10.1190/segam2017-17632255.1, DOI 10.1190/SEGAM2017-17632255.1]
   Huang B, 2013, J SCI COMPUT, V54, P428, DOI 10.1007/s10915-012-9592-9
   Islam SMR, 2015, INT J MULTIMEDIA ITS, V7
   Karimi S, 2017, SIAM J OPTIMIZ, V27, P583, DOI 10.1137/140966587
   Lorenz DA, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2689662
   Lorenz DA, 2014, COMPUT OPTIM APPL, V57, P271, DOI 10.1007/s10589-013-9602-3
   Malioutov DM, 2005, INT CONF ACOUST SPEE, P733
   Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389
   Osher S, 2010, COMMUN MATH SCI, V8, P93
   Parikh Neal, 2014, Foundations and Trends in Optimization, V1, P127, DOI 10.1561/2400000003
   PASSTY GB, 1979, J MATH ANAL APPL, V72, P383, DOI 10.1016/0022-247X(79)90234-8
   Rockafellar RT, 1970, Convex analysis, DOI DOI 10.1515/9781400873173
   Saha T, 2019, APPL MATH COMPUT, V355, P385, DOI 10.1016/j.amc.2019.02.073
   Tao SZ, 2016, SIAM J OPTIMIZ, V26, P313, DOI 10.1137/151004549
   Tesfamicael S, 2014, INT J INF ELECT ENG, V4
   Tesfamicael SA, 2015, INT J ELECT COMPUT E, V5
   van den Berg E, 2020, MATH PROGRAM COMPUT, V12, P1, DOI 10.1007/s12532-019-00163-5
   Wen ZW, 2010, SIAM J SCI COMPUT, V32, P1832, DOI 10.1137/090747695
   Yin WT, 2010, SIAM J IMAGING SCI, V3, P856, DOI 10.1137/090760350
   Yin WT, 2008, SIAM J IMAGING SCI, V1, P143, DOI 10.1137/070703983
   Zhang Y, 2007, FXED POINT CONTINUAT
   Zhu T, 2020, SIGNAL IMAGE VIDEO P, V14, P771, DOI 10.1007/s11760-019-01603-4
NR 42
TC 6
Z9 6
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20707
EP 20731
DI 10.1007/s11042-021-10701-w
EA MAR 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000626812700003
DA 2024-07-18
ER

PT J
AU Seeja, RD
   Suresh, A
AF Seeja, R. D.
   Suresh, A.
TI Melanoma classification employing inter neighbor statistical color and
   mean order pattern texture feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Melanoma; Benign; Dermoscopy; Inter neighbor mean order pattern; Inter
   neighbor statistical color feature; Accuracy
ID ACCURACY
AB Automatic melanoma diagnosis is very important to lower the mortality rate by detecting the disease in earlier stages and accurate diagnosis. The main aim of this paper is to improve the classification accuracy of melanoma using a proposed novel color and texture feature descriptor. Initially, the skin lesion area of input dermoscopy image is segmented using a convolutional neural network-based U-Net algorithm. Then extract discriminate color, texture and combined color-texture features with the help of proposed Inter Neighbor Statistical Color Feature (INSCF), Inter Neighbor Mean Order Pattern (INMOP) and Inter Neighbor Statistical Color Mean Order Pattern (INSCMOP) by incorporating inter color channel values. This proposed feature descriptors are capable to discriminate the detailed information derived from spatial inter-chromatic texture patterns of different channels within a region. Finally, three classifiers namely, K-Nearest Neighbors (KNN), Random Forest (RF), and Support Vector Machine (SVM) are used to classify the skin lesion in a dermoscopic image as benign lesion or melanoma. Experimental results indicate that the proposed INSCMOP with Random Forest classifier achieves the highest classification performance based on accuracy of 93.27% for ISIC 2016 dataset, 86% for ISIC 2017 dataset and 92.31% for ISBI 2019 dataset. Moreover, comparing the proposed method with other systems shows that this approach has an excellent performance in melanoma classification. In this research, without any manual interaction, the classification process is performed in an automated way. It would set up a valuable assistance for dermatologist in clinical practice.
C1 [Seeja, R. D.] Periyar Univ, Dept Comp Sci, Salem 636011, Tamil Nadu, India.
   [Suresh, A.] Siri PSG Arts & Sci Coll Women, Salem 637301, Tamil Nadu, India.
C3 Periyar University
RP Seeja, RD (corresponding author), Periyar Univ, Dept Comp Sci, Salem 636011, Tamil Nadu, India.
EM sheejarufus.r.d@gmail.com
RI RUFUS, SEEJA/ABK-5583-2022
OI R D, SEEJA/0000-0002-9009-8675
CR Al-masni MA, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105351
   Al-Masni MA, 2018, COMPUT METH PROG BIO, V162, P221, DOI 10.1016/j.cmpb.2018.05.027
   Almansour E, 2016, INT J COMPUT SCI NET, V16, P135
   Arasi Munya A., 2017, 2017 Eighth International Conference on Intelligent Computing and Information Systems (ICICIS). Proceedings, P403, DOI 10.1109/INTELCIS.2017.8260079
   Argenziano G, 2012, J AM ACAD DERMATOL, V67, P54, DOI 10.1016/j.jaad.2011.07.019
   Argenziano G, 2001, LANCET ONCOL, V2, P443, DOI 10.1016/S1470-2045(00)00422-8
   Baghersalimi S, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0467-y
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Brown Ani, 2017, WIRELESS PERS COMMUN, V98
   ChitraDevi M, 2020, MEDICO LEGAL UPDATE, V20
   Codella Noel, 2015, Machine Learning in Medical Imaging. 6th International Workshop, MLMI 2015, held in conjunction with MICCAI 2015. Proceedings: LNCS 9352, P118, DOI 10.1007/978-3-319-24888-2_15
   Garcia-Arroyo JL, 2019, arXiv1703.03888v1, V168, P11
   Goyal M, 2017, ARXIV PREPRINT ARXIV, P1
   Gutman, 2016, ARXIV160501397V1
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Harangi B, 2018, J BIOMED INFORM, V86, P25, DOI 10.1016/j.jbi.2018.08.006
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   International Skin Imaging Collaboration (ISIC), 2017, ARXIV171005006CSCV
   Jayapriya K, 2020, INT J IMAG SYST TECH, V30, P348, DOI 10.1002/ima.22377
   Khan MA, 2018, BMC CANCER, V18, DOI 10.1186/s12885-018-4465-8
   Khan MA, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P63, DOI 10.1109/iccisci.2019.8716400
   Kittler H, 2002, LANCET ONCOL, V3, P159, DOI 10.1016/S1470-2045(02)00679-4
   Kruk M, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0099-9
   Li YX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020556
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lopez AR, 2017, 2017 13TH IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (BIOMED), P49, DOI 10.2316/P.2017.852-053
   Mahagaonkar R.S., 2017, BMC PLANT BIOL, V171, P1
   Narayanan DL, 2010, INT J DERMATOL, V49, P978, DOI 10.1111/j.1365-4632.2010.04474.x
   Pomponiu V, 2016, IEEE IMAGE PROC, P2623, DOI 10.1109/ICIP.2016.7532834
   R D Seeja, 2019, Asian Pac J Cancer Prev, V20, P1555
   Rengini, 2015, INT J INNOV RES COMP, V3, P8692
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saba T., 2018, MICROSC RES TECHNIQ, P1
   Sultana NN, 2018, IET COMPUT VIS, V12, P1096, DOI 10.1049/iet-cvi.2018.5238
   Wang Y, 2019, INT C PION COMP SCI, P214, DOI DOI 10.1007/978-981-15-0121-0_17
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Yu Z, 2017, I S BIOMED IMAGING, P301, DOI 10.1109/ISBI.2017.7950524
   Zhu W., 2010, Northeast SAS Users Group 2010: Health Care and Life Sciences, P1
NR 38
TC 8
Z9 8
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20045
EP 20064
DI 10.1007/s11042-021-10685-7
EA MAR 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625344600004
DA 2024-07-18
ER

PT J
AU Zhou, MM
   Zhao, P
AF Zhou, Mengmeng
   Zhao, Ping
TI Enhanced total generalized variation method based on moreau envelope
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Total generalized variation; Moreau envelope; Convex analysis;
   Forward-backward splitting; Adaptive parameter estimation ADMM; Image
   restoration
AB Image restoration with total generalized variation (TGV) regularization has been proved to be a creditable method and used broadly, but this method is imperfect in retaining image details. This paper proposes a non-convex and non-separable regularization term based on TGV enhancement, which can maintain the strict convexity of the total cost function and avoid the underestimation of the TGV method. The new regularization is obtained by subtracting the Moreau envelope of TGV from the TGV term, in which the former is defined by infimal convolution. To minimize the cost function, the proximal forward-backward splitting (FBS) algorithm is applied, and the alternating direction method of multipliers with adaptive parameter estimation (APE-ADMM), which avoids the drawbacks of FBS algorithm, is proposed by applying the variable splitting and the augment Lagrangian method (ALM). This proposed algorithm can update the regularization parameter adaptively. Experiments varify that the proposed method is more accurate in solution estimation than the other promoted ones, and the new ADMM algorithm with new regularization shows improved effects of image restoration.
C1 [Zhou, Mengmeng; Zhao, Ping] Beijing Jiaotong Univ, Sch Sci, Beijing, Peoples R China.
C3 Beijing Jiaotong University
RP Zhou, MM (corresponding author), Beijing Jiaotong Univ, Sch Sci, Beijing, Peoples R China.
EM 18121651@bjtu.edu.cn; pingzhao@bjtu.edu.cn
CR Afonso MV, 2011, IEEE T IMAGE PROCESS, V20, P681, DOI 10.1109/TIP.2010.2076294
   Aujol JF, 2009, J MATH IMAGING VIS, V34, P307, DOI 10.1007/s10851-009-0149-y
   Bauschke HH, 2011, CMS BOOKS MATH, P1, DOI 10.1007/978-1-4419-9467-7
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258
   Chan SH, 2011, IEEE T IMAGE PROCESS, V20, P3097, DOI 10.1109/TIP.2011.2158229
   Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169
   Chan TF, 2010, IEEE IMAGE PROC, P4137, DOI 10.1109/ICIP.2010.5653199
   Combettes P, 2013, ARXIV13055828
   Combettes PL, 2011, SPRINGER SER OPTIM A, V49, P185, DOI 10.1007/978-1-4419-9569-8_10
   Dadashi V, 2020, ARAB J MATH, V9, P89, DOI 10.1007/s40065-018-0236-2
   Ding Y, 2015, IEEE SIGNAL PROC LET, V22, P1364, DOI 10.1109/LSP.2015.2406314
   Easley GR, 2009, IEEE T IMAGE PROCESS, V18, P260, DOI 10.1109/TIP.2008.2008070
   Gelb A, 2019, J SCI COMPUT, V81, P1240, DOI 10.1007/s10915-019-00982-7
   Getreuer P, 2012, IMAGE PROCESS ON LIN, V2, P147, DOI 10.5201/ipol.2012.g-tvi
   Gholami A, 2013, SIGNAL PROCESS, V93, P1945, DOI 10.1016/j.sigpro.2012.12.008
   Gu YA, 2019, J MATH IMAGING VIS, V61, P1329, DOI 10.1007/s10851-019-00909-9
   He C., 2014, Math Probl Eng, P1, DOI [DOI 10.1155/2014/157893, 10.1155/2014/157893]
   He C, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2360133
   Holt KM, 2014, IEEE T IMAGE PROCESS, V23, P3975, DOI 10.1109/TIP.2014.2332397
   Huang YY, 2014, APPL MATH COMPUT, V237, P60, DOI 10.1016/j.amc.2014.03.062
   Knoll F, 2011, MAGN RESON MED, V65, P480, DOI 10.1002/mrm.22595
   Lanza A, 2016, J MATH IMAGING VIS, V56, P195, DOI 10.1007/s10851-016-0655-7
   Lanza A, 2016, J SCI COMPUT, V68, P64, DOI 10.1007/s10915-015-0129-x
   Lee CO, 2019, J SCI COMPUT, V78, P951, DOI 10.1007/s10915-018-0791-x
   Malek-Mohammadi M, 2016, IEEE T SIGNAL PROCES, V64, P6650, DOI 10.1109/TSP.2016.2612179
   Nasonov AV, 2018, 2018 7 EUR WORKSH VI, P26
   Nikolova M, 2010, IEEE T IMAGE PROCESS, V19, P3073, DOI 10.1109/TIP.2010.2052275
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Selesnick I, 2017, IEEE T SIGNAL PROCES, V65, P4481, DOI 10.1109/TSP.2017.2711501
   Selesnick I, 2017, IEEE SIGNAL PROC LET, V24, P216, DOI 10.1109/LSP.2017.2647948
   Selesnick IW, 2016, IEEE T SIGNAL PROCES, V64, P2298, DOI 10.1109/TSP.2016.2518989
   Selesnick IW, 2015, IEEE SIGNAL PROC LET, V22, P141, DOI 10.1109/LSP.2014.2349356
   Selesnick IW, 2013, INT CONF ACOUST SPEE, P5696, DOI 10.1109/ICASSP.2013.6638755
   Setzer S, 2011, COMMUN MATH SCI, V9, P797
   Tikhonov A., 1977, Solution of Ill-Posed Problems
   Wali S, 2018, NUMER MATH-THEORY ME, V11, P49, DOI 10.4208/nmtma.OA-2017-0046
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen YW, 2012, IEEE T IMAGE PROCESS, V21, P1770, DOI 10.1109/TIP.2011.2181401
   Wu CL, 2010, SIAM J IMAGING SCI, V3, P300, DOI 10.1137/090767558
   Yu YC, 2017, J COMPUT APPL MATH, V322, P109, DOI 10.1016/j.cam.2017.03.014
   Zhang HL, 2018, SIGNAL PROCESS, V143, P69, DOI 10.1016/j.sigpro.2017.08.021
NR 45
TC 4
Z9 5
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19539
EP 19566
DI 10.1007/s11042-021-10586-9
EA FEB 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000622668700006
DA 2024-07-18
ER

PT J
AU Sheng, CY
   Hu, B
   Meng, FJ
   Yin, D
AF Sheng, Chiyun
   Hu, Bin
   Meng, Fanjun
   Yin, Dong
TI Lightweight dual-branch network for vehicle exhausts segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicle exhausts segmentation; Lightweight; Dual-branch; Residual
   modules; Pyramid attention structure; Skip modules
ID SURVEILLANCE VIDEO; SMOKE DETECTION
AB Visual vehicle exhausts segmentation is a novel and highly challenging task. In this paper, we introduce a lightweight dual-branch vehicle exhausts segmentation network to quickly and accurately infer segmentation masks from multi-interference traffic scenes. Firstly, we propose an encoder-decoder architecture with lightweight residual modules, which is divided into a deep branch for global prediction and a shallow branch for spatial details. Secondly, pyramid attention structure and skip modules are used to expand the receiving range and integrate multi-scale features. Finally, we advance a fusion network to merge the results of two branches so that the entire model can be easily trained end-to-end. To replace the complicated manual annotation, we employ dynamic fluid simulation and computer graphics technology to generate synthetic vehicle exhausts datasets VED. Comprehensive experiments on our synthetic and real datasets demonstrate that the proposed network outperforms existing segmentation networks in terms of speed and accuracy trade-off. Vehicle exhausts segmentation results on real videos are also appealing.
C1 [Sheng, Chiyun; Hu, Bin; Meng, Fanjun; Yin, Dong] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Anhui, Peoples R China.
   [Sheng, Chiyun; Hu, Bin; Meng, Fanjun; Yin, Dong] Chinese Acad Sci, Key Lab Electromagnet Space Informat, Hefei 230027, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences
RP Yin, D (corresponding author), Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Anhui, Peoples R China.; Yin, D (corresponding author), Chinese Acad Sci, Key Lab Electromagnet Space Informat, Hefei 230027, Anhui, Peoples R China.
EM yindong@ustc.edu.cn
RI , CH/AAT-2453-2021
FU Key Research and Development Program Project Foundation of Anhui
   Province, China [1804a09020049]
FX This work is supported by the Key Research and Development Program
   Project Foundation of Anhui Province, China, under Grant No.
   1804a09020049.
CR Chen L.-C., 2018, Pertanika J. Trop. Agric. Sci., P801, DOI [10.1007/978-3-030-01234-2_49, DOI 10.1007/978-3-030-01234-249, DOI 10.1007/978-3-030-01234-2_49]
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen YT, 2021, VISUAL COMPUT, V37, P1691, DOI 10.1007/s00371-020-01932-3
   Chen YT, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02066-z
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Ding YJ, 2018, INT CONF DIGIT SIG
   Filonenko A, 2018, IEEE T IND INFORM, V14, P725, DOI 10.1109/TII.2017.2757457
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   He K., 2015, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2015.7299173, DOI 10.1109/CVPR.2015.7299173]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang H, 2017, INT C COMPUT GRAPHIC
   Jia Yang, 2016, Computer Engineering, V42, P206, DOI 10.3969/j.issn.1000-3428.2016.02.037
   Kajiya J. T., 1984, Computers & Graphics, V18, P165
   Li HC, 2019, PROC CVPR IEEE, P9514, DOI 10.1109/CVPR.2019.00975
   Li XQ, 2020, IEEE T CIRC SYST VID, V30, P89, DOI 10.1109/TCSVT.2018.2889193
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Paszke A., 2017, NAT COMMUN, P1, DOI DOI 10.1038/S41467-016-0009-6
   Poudel R. P., 2018, ARXIV180504554
   Poudel R.P.K., 2019, ARXIV190204502, P289
   Pyykönen P, 2016, INT C INTELL COMP CO, P233, DOI 10.1109/ICCP.2016.7737152
   Romera E, 2018, IEEE T INTELL TRANSP, V19, P263, DOI 10.1109/TITS.2017.2750080
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Sun LH, 2020, INT GEOL REV, V62, P1094, DOI 10.1080/00206814.2019.1669079
   Tao H, 2019, J REAL-TIME IMAGE PR, P1
   TAO H, 2018, SIGNAL IMAGE VIDEO P
   Tao HJ, 2019, SIGNAL IMAGE VIDEO P, V13, P217, DOI 10.1007/s11760-018-1348-z
   Tao HJ, 2019, IET INTELL TRANSP SY, V13, P252, DOI 10.1049/iet-its.2018.5039
   Tao HJ, 2018, IEEE ACCESS, V6, P57180, DOI 10.1109/ACCESS.2018.2873757
   Tian HD, 2014, INT J COMPUT VISION, V106, P192, DOI 10.1007/s11263-013-0656-6
   Tsafack N, 2020, IEEE ACCESS, V8, P137731, DOI 10.1109/ACCESS.2020.3010794
   Wang HT, 2019, J FOR SCI-PRAGUE, V65, P321, DOI 10.17221/34/2019-JFS
   Wang Y, 2019, IEEE IMAGE PROC, P1860, DOI [10.1109/icip.2019.8803154, 10.1109/ICIP.2019.8803154]
   Xi YM, 2020, CELL BIOL INT, V44, P583, DOI 10.1002/cbin.11258
   Xu G, 2019, FIRE SAFETY J, V105, P277, DOI 10.1016/j.firesaf.2019.03.004
   Yan, 2017, J FRONT COMPUT SCI T
   Yuan FN, 2020, IEEE T IMAGE PROCESS, V29, P2301, DOI 10.1109/TIP.2019.2946126
   Yuan FN, 2019, NEUROCOMPUTING, V357, P248, DOI 10.1016/j.neucom.2019.05.011
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao Y, 2015, J ELECTR COMPUT ENG, V2015, DOI 10.1155/2015/706187
NR 44
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17785
EP 17806
DI 10.1007/s11042-021-10601-z
EA FEB 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000617415000004
DA 2024-07-18
ER

PT J
AU Rao, CS
   Karunakara, K
AF Rao, Champakamala Sundar
   Karunakara, K.
TI A comprehensive review on brain tumor segmentation and classification of
   MRI images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE MRI; Brain tumor; Segmentation; Bias field; Tissue; Image processing
ID MULTI-ATLAS SEGMENTATION; AUTOMATIC SEGMENTATION; UNIFIED FRAMEWORK;
   EXTRACTION; REGION; ALGORITHM; SELECTION; ACCURACY; NETWORKS; MACHINE
AB In the analysis of medical images, one of the challenging tasks is the recognition of brain tumours via medical resonance images (MRIs). The diagnosis process is still tedious due to its complexity and considerable variety in tissues of tumor perception. Therefore, the necessities of tumor identification techniques are improving nowadays for medical applications. In the past decades, different approaches in the segmentation of various precisions and complexity degree have been accomplished, which depends on the simplicity and the benchmark of the technique. An overview of this analysis is to give out the summary of the semi-automatic techniques for brain tumor segmentation and classification utilizing MRI. An enormous amount of MRI based image data is accomplished using deep learning approaches. There are several works, dealing on the conventional approaches for MRI-based segmentation of brain tumor. Alternatively, in this review, we revealed the latest trends in the methods of deep learning. Initially, we explain the several threads in MRI pre-processing, including registration of image, rectification of bias field, and non-brain tissue dismissal. And terminally, the present state evaluation of algorithm is offered and forecasting the growths to systematise the MRI-based brain tumor into a regular cyclic routine in the clinical field are focussed.
C1 [Rao, Champakamala Sundar; Karunakara, K.] Sri Siddhartha Inst Technol, Dept Informat Sci & Engn, Tumakuru 572107, Karnataka, India.
RP Rao, CS (corresponding author), Sri Siddhartha Inst Technol, Dept Informat Sci & Engn, Tumakuru 572107, Karnataka, India.
EM champaka.ssit@gmail.com
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   Ahmmed R., 2018, ADV SCI TECHNOL ENG, V3, P40, DOI 10.25046/aj030205
   Anaraki AK, 2019, BIOCYBERN BIOMED ENG, V39, P63, DOI 10.1016/j.bbe.2018.10.004
   Angulakshmi M, 2017, J ENG SCI TECHNOL, V12, P875
   Anitha V, 2016, IET COMPUT VIS, V10, P9, DOI 10.1049/iet-cvi.2014.0193
   Aslam A, 2015, PROCEDIA COMPUT SCI, V58, P430, DOI 10.1016/j.procs.2015.08.057
   Balafar MA, 2014, ARTIF INTELL REV, V41, P441, DOI 10.1007/s10462-012-9318-2
   Bankman, 2000, HDB MEDICAL IMAGING
   Bao SQ, 2018, COMP M BIO BIO E-IV, V6, P113, DOI 10.1080/21681163.2016.1182072
   Battaglini M, 2008, NEUROIMAGE, V40, P583, DOI 10.1016/j.neuroimage.2007.10.067
   Bauer S, 2011, LECT NOTES COMPUT SC, V6893, P354, DOI 10.1007/978-3-642-23626-6_44
   Ben Naceur M, 2018, COMPUT METH PROG BIO, V166, P39, DOI 10.1016/j.cmpb.2018.09.007
   BEZDEK JC, 1993, MED PHYS, V20, P1033, DOI 10.1118/1.597000
   Birenbaum A, 2016, LECT NOTES COMPUT SC, V10008, P58, DOI 10.1007/978-3-319-46976-8_7
   Brosch T, 2016, IEEE T MED IMAGING, V35, P1229, DOI 10.1109/TMI.2016.2528821
   Brosch T, 2015, LECT NOTES COMPUT SC, V9351, P3, DOI 10.1007/978-3-319-24574-4_1
   Chang HH, 2007, IEEE T BIO-MED ENG, V54, P1798, DOI 10.1109/TBME.2007.895104
   Chen JC, 2016, SCI REP-UK, V6, DOI [10.1038/srep24454, 10.1038/srep25671]
   Chen PF, 2009, INT CONF ACOUST SPEE, P417, DOI 10.1109/ICASSP.2009.4959609
   Chen W, 2018, INT MICCAI BRAINL WO
   Chita SM, 2013, PROC SPIE, V8669, DOI 10.1117/12.2006753
   Chithambaram T, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON POWER, CONTROL, SIGNALS AND INSTRUMENTATION ENGINEERING (ICPCSI), P970, DOI 10.1109/ICPCSI.2017.8391855
   Crum WR, 2006, IEEE T MED IMAGING, V25, P1451, DOI 10.1109/TMI.2006.880587
   Dalca AV, 2019, LECT NOTES COMPUT SC, V11766, P356, DOI 10.1007/978-3-030-32248-9_40
   Dalca AV, 2018, PROC CVPR IEEE, P9290, DOI 10.1109/CVPR.2018.00968
   Darling K, 2017, COMPLEMENTARY ALTERN
   de Brebisson Alexandre, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P20, DOI 10.1109/CVPRW.2015.7301312
   De Momi, 2019, 2019 41 ANN INT C IE
   Deimling, GLIOMAS, V171
   Despotovic I, 2010, IEEE ENG MED BIO, P5038, DOI 10.1109/IEMBS.2010.5627196
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Dokur Z, 2008, EXPERT SYST APPL, V34, P611, DOI 10.1016/j.eswa.2006.09.017
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Drakopoulos F, 2016, COMP M BIO BIO E-IV, V4, P112, DOI 10.1080/21681163.2015.1067869
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   Iglesias JE, 2015, MED IMAGE ANAL, V24, P205, DOI 10.1016/j.media.2015.06.012
   EVANS AC, 1993, NUCLEAR SCIENCE SYMPOSIUM & MEDICAL IMAGING CONFERENCE, VOLS 1-3, P1813, DOI 10.1109/NSSMIC.1993.373602
   Gaikwad SB., 2015, INT J COMPUT APPL, V120, P5, DOI DOI 10.5120/21205-3885
   Galimzianova A, 2016, NEUROIMAGE, V124, P1031, DOI 10.1016/j.neuroimage.2015.09.047
   Girard F, 2019, ARTIF INTELL MED, V94, P96, DOI 10.1016/j.artmed.2019.02.004
   Gonzalez R.C., 2002, Digital Image Processing, V2nd
   Gordillo N, 2013, MAGN RESON IMAGING, V31, P1426, DOI 10.1016/j.mri.2013.05.002
   Gumaei A, 2019, IEEE ACCESS, V7, P36266, DOI 10.1109/ACCESS.2019.2904145
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Huang MY, 2014, IEEE T BIO-MED ENG, V61, P2633, DOI 10.1109/TBME.2014.2325410
   Hussain S, 2017, IEEE ENG MED BIO, P1998, DOI 10.1109/EMBC.2017.8037243
   Iglesias JE, 2013, MED IMAGE ANAL, V17, P1181, DOI 10.1016/j.media.2013.08.001
   Ilhan U, 2017, PROCEDIA COMPUT SCI, V120, P580, DOI 10.1016/j.procs.2017.11.282
   Ilunga-Mbuyamba E, 2017, COMPUT BIOL MED, V91, P69, DOI 10.1016/j.compbiomed.2017.10.003
   Ji ZX, 2012, COMPUT METH PROG BIO, V108, P644, DOI 10.1016/j.cmpb.2011.10.010
   Kang WX, 2009, 2009 1 INT WORKSH IE
   Kannan SR, 2010, COMPUT BIOL MED, V40, P572, DOI 10.1016/j.compbiomed.2010.04.001
   Karimaghaloo Z, 2015, IEEE T MED IMAGING, V34, P1227, DOI 10.1109/TMI.2014.2382561
   Kaus MR, 2001, RADIOLOGY, V218, P586, DOI 10.1148/radiology.218.2.r01fe44586
   Khan, 2020, HYBRID UNSUPERVISED
   Kharrat A., 2019, Applied Medical Informatics, V41, P9
   KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855
   Kleesiek J, 2016, NEUROIMAGE, V129, P460, DOI 10.1016/j.neuroimage.2016.01.024
   KLEIHUES P, 1993, BRAIN PATHOL, V3, P255, DOI 10.1111/j.1750-3639.1993.tb00752.x
   Kooi T, 2017, MED IMAGE ANAL, V35, P303, DOI 10.1016/j.media.2016.07.007
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2019, APPL SOFT COMPUT, V82, DOI 10.1016/j.asoc.2019.105528
   Kumar N., 2018, international conference on Research in Intelligent and Computing in Engineering (RICE), Research in Intelligent and Computing in Engineering (RICE), P1, DOI [DOI 10.1109/RICE.2018.8509072, 10.1109/ICCTCT.2018.8551004]
   Lafferty John, 2001, INT C MACH LEARN ICM
   Lee W-S, 2016, ARXIV PREPRINT ARXIV
   Lewis EB, 2004, NEUROIMAGE, V23, P75, DOI 10.1016/j.neuroimage.2004.04.030
   Li BN, 2011, COMPUT BIOL MED, V41, P1, DOI 10.1016/j.compbiomed.2010.10.007
   Li JC, 2019, NEUROCOMPUTING, V358, P10, DOI 10.1016/j.neucom.2019.05.025
   Li JP, 2020, NEUROCOMPUTING, V378, P335, DOI 10.1016/j.neucom.2019.10.032
   Li WQ, 2017, LECT NOTES COMPUT SC, V10265, P348, DOI 10.1007/978-3-319-59050-9_28
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Lin D, 2016, NEUROCOMPUTING, V216, P700, DOI 10.1016/j.neucom.2016.08.039
   Litjens G, 2016, SCI REP-UK, V6, DOI 10.1038/srep26286
   Livne M, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00097
   Lötjönen JMP, 2010, NEUROIMAGE, V49, P2352, DOI 10.1016/j.neuroimage.2009.10.026
   Lyksborg Mark, 2015, Image Analysis. 19th Scandinavian Conference, SCIA 2015. Proceedings: LNCS 9127, P201, DOI 10.1007/978-3-319-19665-7_17
   Mahmoud D., 2012, J SCI TECHNOL, V13, P31
   Makropoulos A, 2014, IEEE T MED IMAGING, V33, P1818, DOI 10.1109/TMI.2014.2322280
   Masutani Y, 1998, LECT NOTES COMPUT SC, V1496, P1242, DOI 10.1007/BFb0056314
   Meena, 2019, STOCHASTIC GRADIENT
   Mittal M, 2019, APPL SOFT COMPUT, V78, P346, DOI 10.1016/j.asoc.2019.02.036
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Moeskops P, 2015, NEUROIMAGE, V118, P628, DOI 10.1016/j.neuroimage.2015.06.007
   Mohsen Heba, 2018, Future Computing and Informatics Journal, V3, P68, DOI 10.1016/j.fcij.2017.12.001
   Motagi AC., 2018, INT J SCI RES COMPUT, V6, P76, DOI [10.26438/ijsrcse/v6i3.7680, DOI 10.26438/IJSRCSE/V6I3.7680]
   Murgasova M., 2008, Segmentation of brain mri during early childhood
   Ourselin, 2003, NEW DEFORMABLE MODEL
   Payabvash S, 2020, FRONT ONCOL, V10, DOI 10.3389/fonc.2020.00071
   Prakash RM, 2016, INT J IMAG SYST TECH, V26, P116, DOI 10.1002/ima.22166
   Prastawa M., 2008, GRAND CHALLENGE WORK, P1
   Rao RR., 2020, BRAIN IMAGE CLASSIFI, P635, DOI DOI 10.1007/978-981-15-2780-7_69
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Saraswathi D., 2019, 2019 IEEE INT C SYST, P1, DOI DOI 10.1109/BHI.2019.8834621
   Sathik MJ, 2020, IEEE T CIRCUITS-II, V67, P3287, DOI 10.1109/TCSII.2020.2988155
   Seetha J., 2018, BIOMED PHARMACOL J, V11, P1457, DOI [DOI 10.13005/bpj/1511, 10.13005/bpj/1511]
   Shattuck DW, 2008, NEUROIMAGE, V39, P1064, DOI 10.1016/j.neuroimage.2007.09.031
   Shi F, 2011, HUM BRAIN MAPP, V32, P382, DOI 10.1002/hbm.21023
   Shivhare SN, 2019, MULTIMED TOOLS APPL, V78, P34207, DOI 10.1007/s11042-019-08048-4
   Sudre CH, 2015, IEEE T MED IMAGING, V34, P2079, DOI 10.1109/TMI.2015.2419072
   Tandel GS, 2019, CANCERS, V11, DOI 10.3390/cancers11010111
   Tarkhaneh O, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.07.037
   Thiyagarajan A., 2015, INT ARAB J INF TECHN, V12, P772
   Tu Z, 2008, IEEE T MED IMAGING, V27, P495, DOI 10.1109/TMI.2007.908121
   Vansteenkiste E., 2007, Quantitative analysis of ultrasound images of the preterm brain
   Vashisth S, 2017, ARXIV PREPRINT ARXIV
   Verma R, 2008, ACAD RADIOL, V15, P966, DOI 10.1016/j.acra.2008.01.029
   Verma VS, 2019, MAGN RESON IMAGING
   Wang L, 2015, NEUROIMAGE, V108, P160, DOI 10.1016/j.neuroimage.2014.12.042
   Warfield SK, 2000, MED IMAGE ANAL, V4, P43, DOI 10.1016/S1361-8415(00)00003-7
   Weiss N, 2013, LECT NOTES COMPUT SC, V8149, P735, DOI 10.1007/978-3-642-40811-3_92
   Xue H, 2007, NEUROIMAGE, V38, P461, DOI 10.1016/j.neuroimage.2007.07.030
   Xue JH, 2003, PATTERN RECOGN LETT, V24, P2549, DOI 10.1016/S0167-8655(03)00100-4
   Zeng ZT, 2019, IEEE ACCESS, V7, P21420, DOI 10.1109/ACCESS.2019.2896920
   Zhang J., 2004, International Workshop on Advanced Image Technology, P207211
   Zhang T, 2014, BIOMED SIGNAL PROCES, V12, P10, DOI 10.1016/j.bspc.2013.07.010
   Zhang WL, 2015, NEUROIMAGE, V108, P214, DOI 10.1016/j.neuroimage.2014.12.061
   Zhang YD, 2011, EXPERT SYST APPL, V38, P10049, DOI 10.1016/j.eswa.2011.02.012
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
NR 120
TC 26
Z9 27
U1 0
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17611
EP 17643
DI 10.1007/s11042-020-10443-1
EA FEB 2021
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000616467500005
DA 2024-07-18
ER

PT J
AU Huu, QN
   Viet, DC
   Thuy, QDT
AF Huu, Quynh Nguyen
   Viet, Dung Cu
   Thuy, Quynh Dao Thi
TI Semantic class discriminant projection for image retrieval with
   relevance feedback
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval (CBIR); Relevance feedback; Subspace
   learning
ID NONLINEAR DIMENSIONALITY REDUCTION; SUBSPACE; GRAPHS
AB With the user's feedback, projections are often used to reduce dimension and enhance class discrimination. The existing projections either use only the global euclidean structure or refer to the local manifold structure. However, global statistics such as variance (ie the method using the global euclidean structure) is difficult to estimate when there are not enough training samples. As for the methods that use the local manifold structure, the class discriminant is limited. In this paper, a Semantic Class Discriminant Projection (SCDP) is proposed for enhancing the performance of content-based image retrieval schemas with relevance feedback. SCDP can take advantage of the local geometry information of labeled and unlabeled images to learn a semantic subspace, and it obtains the most important properties of the subspaces to enhance classification. The experimental results performed on the two benchmark datasets have confirmed the superiority of the proposed method.
C1 [Huu, Quynh Nguyen; Viet, Dung Cu] Thuyloi Univ, Fac Comp Sci & Engn, 175 Tayson, Hanoi, Vietnam.
   [Thuy, Quynh Dao Thi] Posts & Telecommun Inst Technol, Fac Informat Technol, Hanoi, Vietnam.
C3 Thuyloi University
RP Thuy, QDT (corresponding author), Posts & Telecommun Inst Technol, Fac Informat Technol, Hanoi, Vietnam.
EM quynhnh@tlu.edu.vn; dungcv@tlu.edu.vn; thuyquynhtn90@gmail.com
FU Vietnam National Foundation for Science and Technology Development
   (NAFOSTED) [102.01-2020.10]
FX This research is funded by Vietnam National Foundation for Science and
   Technology Development (NAFOSTED) under grant number 102.01-2020.10".
CR Cai D, 2007, IEEE I CONF COMP VIS, P222
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Ding CT, 2015, PATTERN RECOGN, V48, P1734, DOI 10.1016/j.patcog.2014.08.025
   Dornaika F, 2016, IEEE T CYBERNETICS, V46, P206, DOI 10.1109/TCYB.2015.2399456
   Duda RO., 2000, Pattern classification, V2nd ed., P688
   Gao QX, 2015, NEUROCOMPUTING, V152, P69, DOI 10.1016/j.neucom.2014.11.018
   Geng X, 2005, IEEE T SYST MAN CY B, V35, P1098, DOI 10.1109/TSMCB.2005.850151
   Gou JP, 2020, EXPERT SYST APPL, V144, DOI 10.1016/j.eswa.2019.113079
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2004, ADV NEUR IN, V16, P153
   He X, 2008, IEEE T KNOWL DATA EN, V20, P189, DOI 10.1109/TKDE.2007.190692
   Huijsmans DP, 2005, IEEE T PATTERN ANAL, V27, P245, DOI 10.1109/TPAMI.2005.30
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Lai ZH, 2020, INT J MACH LEARN CYB, V11, P2247, DOI 10.1007/s13042-020-01113-7
   Lin Y-Y, 2005, P 13 ANN ACM INT C M, P24
   Liu L, 2015, IEEE T IMAGE PROCESS, V24, P956, DOI 10.1109/TIP.2015.2390975
   Liu ZH, 2020, MULTIMED TOOLS APPL, V79, P11993, DOI 10.1007/s11042-019-08434-y
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sathiamoorthy S, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-1941-y
   Shao L, 2015, IEEE T NEUR NET LEAR, V26, P1019, DOI 10.1109/TNNLS.2014.2330900
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Song YQ, 2008, PATTERN RECOGN, V41, P2789, DOI 10.1016/j.patcog.2008.01.001
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   Tao DC, 2006, IEEE T MULTIMEDIA, V8, P716, DOI 10.1109/TMM.2005.861375
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Tao YT, 2018, NEURAL PROCESS LETT, V47, P1149, DOI 10.1007/s11063-017-9691-6
   Vlachos M., 2002, INT C KNOWLEDGE DISC, P645
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wong WK, 2012, PATTERN RECOGN, V45, P186, DOI 10.1016/j.patcog.2011.05.014
   Xu Y, 2010, PATTERN RECOGN, V43, P4165, DOI 10.1016/j.patcog.2010.06.016
   Yan SC, 2005, PROC CVPR IEEE, P830
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Zhang LN, 2016, IEEE T IMAGE PROCESS, V25, P1275, DOI 10.1109/TIP.2016.2516947
   Zhang W, 2006, PATTERN RECOGN, V39, P2240, DOI 10.1016/j.patcog.2006.05.011
   Zhao HT, 2006, PATTERN RECOGN, V39, P1546, DOI 10.1016/j.patcog.2006.02.023
NR 37
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15351
EP 15376
DI 10.1007/s11042-020-10400-y
EA FEB 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000614341400002
DA 2024-07-18
ER

PT J
AU Lu, YF
   Yu, KM
   Lv, X
AF Lu, Yuefeng
   Yu, Kaimin
   Lv, Xiang
TI Image encryption with one-time password mechanism and pseudo-features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE One-time password mechanism; Pseudo-feature; Chaotic matrix; Image
   encryption
AB An image encryption algorithm based on chaotic sequence and permutation matrix is presented in this paper, with the ability to create pseudo-features and realize one-time password mechanism. Firstly, the original image and the matrix which containing incremental key information are operated with XOR by chaotic matrix constructed by Logistic model. Then it is embedded in a larger matrix with pseudo-features. Finally, the permutation matrix is used to shuffle the pixel position of the image to get the encrypted image. The simulation results and security analysis show that the encryption algorithm has the advantages of stable one-time password mechanism, strong capacity to resist various attacks and ability to create pseudo-features.
C1 [Lu, Yuefeng; Lv, Xiang] Zhejiang Normal Univ, Coll Phys & Elect Informat Engn, Jinhua 321004, Zhejiang, Peoples R China.
   [Yu, Kaimin] Zhejiang Normal Univ, Coll Math & Comp Sci, Jinhua 321004, Zhejiang, Peoples R China.
C3 Zhejiang Normal University; Zhejiang Normal University
RP Lu, YF (corresponding author), Zhejiang Normal Univ, Coll Phys & Elect Informat Engn, Jinhua 321004, Zhejiang, Peoples R China.
EM yuefenglu@zjnu.edu.cn; xianglv@zjnu.cn
OI Lu, Yuefeng/0000-0003-4150-9762
CR Akhavan A, 2017, OPT LASER TECHNOL, V95, P94, DOI 10.1016/j.optlastec.2017.04.022
   Akin E, 2012, TOPOL APPL, V159, P2815, DOI 10.1016/j.topol.2012.04.016
   Arroyo D, 2013, SIGNAL PROCESS, V93, P1358, DOI 10.1016/j.sigpro.2012.11.019
   Artiles JAP, 2019, SIGNAL PROCESS-IMAGE, V79, P24, DOI 10.1016/j.image.2019.08.014
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Bianchi T, 2009, IEEE T INF FOREN SEC, V4, P86, DOI 10.1109/TIFS.2008.2011087
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Curiac DI, 2014, COMMUN NONLINEAR SCI, V19, P3617, DOI 10.1016/j.cnsns.2014.03.020
   Dong CE, 2014, SIGNAL PROCESS-IMAGE, V29, P628, DOI 10.1016/j.image.2013.09.006
   Elgendy F, 2016, MULTIMED TOOLS APPL, V75, P11529, DOI 10.1007/s11042-015-2883-z
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Hermassi H, 2014, MULTIMED TOOLS APPL, V72, P2211, DOI 10.1007/s11042-013-1533-6
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Kalpana J, 2015, OPTIK, V126, P5703, DOI 10.1016/j.ijleo.2015.09.091
   Li CQ, 2016, SIGNAL PROCESS, V118, P203, DOI 10.1016/j.sigpro.2015.07.008
   Li CQ, 2009, IMAGE VISION COMPUT, V27, P1035, DOI 10.1016/j.imavis.2008.09.004
   Lingling Wu, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P1164, DOI 10.1109/ICISE.2009.347
   Liu HJ, 2013, J SYST SOFTWARE, V86, P826, DOI 10.1016/j.jss.2012.11.026
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Merah L., 2013, APPL MATH SCI, V7, P2719
   Özkaynak F, 2012, OPT COMMUN, V285, P4946, DOI 10.1016/j.optcom.2012.07.106
   Quyen NX, 2016, COMPUT NETW, V109, P4, DOI 10.1016/j.comnet.2016.06.022
   Sarvabhatla M, 2015, PROCEDIA COMPUT SCI, V50, P81, DOI 10.1016/j.procs.2015.04.064
   Sokouti M, 2018, COMPUT SCI REV, V29, P14, DOI 10.1016/j.cosrev.2018.05.002
   Solak E, 2010, OPT COMMUN, V283, P232, DOI 10.1016/j.optcom.2009.09.070
   Stockmann H.-J., 2000, QUANTUM CHAOS INTRO
   Tuna M, 2019, MICROPROCESS MICROSY, V66, P72, DOI 10.1016/j.micpro.2019.02.012
   Wang XY, 2018, OPT LASER ENG, V107, P370, DOI 10.1016/j.optlaseng.2017.06.015
   Wang XY, 2018, OPT LASER ENG, V103, P1, DOI 10.1016/j.optlaseng.2017.11.009
   Wong KW, 2002, PHYS LETT A, V298, P238, DOI 10.1016/S0375-9601(02)00431-0
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu Y., 2011, CYBER J J SEL AREAS
   Zeng L, 2015, OPTIK, V126, P5022, DOI 10.1016/j.ijleo.2015.09.219
   ZHANG L, 2017, INT J BIFURCAT CHAOS, V27, DOI DOI 10.1109/TASC.2016.2634326
   Zhang YS, 2015, NONLINEAR DYNAM, V82, P1831, DOI 10.1007/s11071-015-2280-1
   Zhenjun Tang, 2011, Journal of Multimedia, V6, P202, DOI 10.4304/jmm.6.2.202-206
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 41
TC 4
Z9 4
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15041
EP 15055
DI 10.1007/s11042-021-10522-x
EA FEB 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000613628000008
DA 2024-07-18
ER

PT J
AU Rim, Z
   Ridha, E
   Mourad, Z
AF Rim, Zahmoul
   Ridha, Ejbali
   Mourad, Zaied
TI An improved partial image encryption scheme based on lifting wavelet
   transform, wide range Beta chaotic map and Latin square
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Partial Encryption; Beta Chaotic Map; Lifting wavelet transform; Latin
   square
ID PERMUTATION-DIFFUSION; ALGORITHM; CRYPTOGRAPHY; EFFICIENT; SECURE
AB In this paper, an improved image cryptography method based on lifting wavelet transform, Latin square and wide range Beta chaotic map, is proposed. This scheme tends to encrypt solely the requisite components of the sensitive data in Lifting-Wavelet which is the LL (Low-Low) decomposition. The introduced scheme is composed of different procedures. After the creation of the Latin square S-box, we used the wide range Beta map to generate the random key. The obtained key is applied in the encryption stage. Following the encryption steps, the ciphered images have been tested by a variety of tests including the histogram analysis, differential analysis, and information entropy analysis. Compared with previous schemes, The results are good and provide an efficient technique for partial image encryption and decryption in the theme of secure communication.
C1 [Rim, Zahmoul; Ridha, Ejbali; Mourad, Zaied] Natl Engn Sch Gabes, Res Team Intelligent Machines, BP W 6072, Gabes, Tunisia.
C3 Universite de Gabes
RP Rim, Z (corresponding author), Natl Engn Sch Gabes, Res Team Intelligent Machines, BP W 6072, Gabes, Tunisia.
EM rima.zahmoul@gmail.com; ridha_ejbali@ieee.org; mourad.zaied@ieee.org
RI Ejbali, Ridha/K-4234-2012
OI Ejbali, Ridha/0000-0002-8148-1621; ZAHMOUL, RIM/0000-0002-2746-5911
FU General Direction of Scientific Research (DGRST), Tunisia, under the
   ARUB program
FX The authors would like to acknowledge the financial support of this work
   by grants from General Direction of Scientific Research (DGRST),
   Tunisia, under the ARUB program.
CR Alimi, 2003, TUNISIA MARS, V1, P185
   Asgari-Chenaghlu M, 2019, SIGNAL PROCESS, V157, P1, DOI 10.1016/j.sigpro.2018.11.010
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Bhatnagar G, 2012, DIGIT SIGNAL PROCESS, V22, P648, DOI 10.1016/j.dsp.2012.02.005
   Çavusoglu U, 2018, NONLINEAR DYNAM, V92, P1745, DOI 10.1007/s11071-018-4159-4
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen CL, 2012, ARXIV12042310
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Chuman T, 2019, IEEE T INF FOREN SEC, V14, P1515, DOI 10.1109/TIFS.2018.2881677
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Elkhalil N, 2019, ICSEA, P130
   Enayatifar R, 2019, OPT LASER ENG, V115, P131, DOI 10.1016/j.optlaseng.2018.11.017
   Fan CL, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20060445
   Gao HJ, 2006, CHAOS SOLITON FRACT, V29, P393, DOI 10.1016/j.chaos.2005.08.110
   Hsiao HI, 2015, SIGNAL PROCESS, V113, P169, DOI 10.1016/j.sigpro.2015.01.024
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Huang LQ, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20070535
   Janakiraman S, 2012, RES J INFORM TECHNOL, V4, P61
   Janakiraman S, 2018, MICROPROCESS MICROSY, V56, P1, DOI 10.1016/j.micpro.2017.10.013
   Jeong ES, 2014, MULTIMED TOOLS APPL, V72, P2087, DOI 10.1007/s11042-013-1389-9
   Jiao G, 2019, KSII T INTERNET INF, V13, P1064, DOI 10.3837/tiis.2019.02.031
   Jolfaei A, 2016, IEEE T INF FOREN SEC, V11, P235, DOI 10.1109/TIFS.2015.2489178
   Jonathan Satish T., 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P704, DOI 10.1109/ICECA.2018.8474930
   Kalsi S, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0851-z
   Khan MA, 2017, J MOD OPTIC, V64, P531, DOI 10.1080/09500340.2016.1246680
   Kumar M, 2017, J KING SAUD UNIV-COM
   Kumar R, 2017, OPT LASER TECHNOL, V95, P51, DOI 10.1016/j.optlastec.2017.03.041
   Li CQ, 2018, IEEE ACCESS, V6, P75834, DOI 10.1109/ACCESS.2018.2883690
   Li CL, 2018, OPTIK, V171, P277, DOI 10.1016/j.ijleo.2018.06.029
   Li W, 2019, IEEE ACCESS
   Liu Q, 2018, OPT REV, V25, P46, DOI 10.1007/s10043-017-0390-3
   Lizhi Xiong, 2018, Multidimensional Systems and Signal Processing, V29, P1191, DOI 10.1007/s11045-017-0497-5
   Luo YL, 2015, COMMUN NONLINEAR SCI, V20, P447, DOI 10.1016/j.cnsns.2014.05.022
   Machkour M, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0068-1
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Mazloom S, 2009, CHAOS SOLITON FRACT, V42, P1745, DOI 10.1016/j.chaos.2009.03.084
   Mondal B., 2018, RECENT PATENTS ENG, V12, P5, DOI [10.2174/1872212111666170223165916, DOI 10.2174/1872212111666170223165916]
   Panduranga HT, 2014, EUR PHYS J-SPEC TOP, V223, P1663, DOI 10.1140/epjst/e2014-02119-9
   Ponuma, 2019, MULTIDIMENSIONAL SYS, P1
   Prajwalasimha SN, 2019, STUD COMPUT INTELL, V771, P575, DOI 10.1007/978-981-10-8797-4_58
   RAMADAN N, 2017, J CENT SOUTH UNIV, V24, P2049, DOI DOI 10.1007/s11771-017-3614-6
   Ratnavelu K, 2017, SIGNAL PROCESS, V140, P87, DOI 10.1016/j.sigpro.2017.05.002
   Ravi R.V., 2017, INT J APPL ENG RES, V12, P3961
   Recipes N., 2007, ART SCI COMPUTING
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Rim Z., 2019, 12 INT C COMPUTATION, P97, DOI [10.1007/978-3-030-20005-3, DOI 10.1007/978-3-030-20005-3]
   Stinson D. R., 2006, Cryptography Theory and Practice, V3rd
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yang M, 2004, IEEE POTENTIALS, V23, P28
   Zahmoul R, 2016, IEEE SYS MAN CYBERN, P4052, DOI 10.1109/SMC.2016.7844867
   Zhang LY, 2014, COMMUN NONLINEAR SCI, V19, P3653, DOI 10.1016/j.cnsns.2014.03.016
   Zhang XJ, 2013, SIGNAL PROCESS, V93, P2422, DOI 10.1016/j.sigpro.2013.03.017
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhao JF, 2017, J ELECTR COMPUT ENG, V2017, DOI 10.1155/2017/8672716
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
NR 56
TC 7
Z9 7
U1 2
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15173
EP 15191
DI 10.1007/s11042-020-10263-3
EA FEB 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000613170400001
DA 2024-07-18
ER

PT J
AU Wen, GH
   Wang, KW
   Li, HH
   Huang, YH
   Zhang, SJ
AF Wen, Guihua
   Wang, Kewen
   Li, Huihui
   Huang, Yuhua
   Zhang, Shijun
TI Recommending prescription via tongue image to assist clinician
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traditional chinese medicine; Prescription; Recommendation; Herbs; Deep
   learning; Tongue image
AB Traditional Chinese Medicine often use the prescription composed of herbs to cure the disease, which requires doctors with the rich professional knowledge and experience. It is much expected that the prescription can be generated automatically to assist doctors in prescribing using such as machine learning on the tongue images. However, it is confronted with two challenges. First, there is not a larger tongue image database available for machine learning. Second, there is no such machine learning method available for generating prescription according to the given tongue image. This paper begins with constructing a larger tongue image database, where each image corresponds to a prescription. It then uses auto-encoder to extract features for the tongue image, on which the recommendation neural network is proposed to recommend herbs for the prescription. Finally, a new prescription generation method is proposed to select optimal herbs from the recommended herbs to form the final prescription. Experimental results on our constructed databases validate the effectiveness and the superior performance of the proposed methods.
C1 [Wen, Guihua; Wang, Kewen; Huang, Yuhua] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
   [Li, Huihui] Guangdong Polytech Normal Univ, Sch Comp Sci, Guangzhou, Peoples R China.
   [Zhang, Shijun] Sun Yat Sen Univ, Affiliated Hosp 1, Guangzhou, Peoples R China.
C3 South China University of Technology; Guangdong Polytechnic Normal
   University; Sun Yat Sen University
RP Li, HH (corresponding author), Guangdong Polytech Normal Univ, Sch Comp Sci, Guangzhou, Peoples R China.
EM 29777562@qq.com
RI Huang, Yuhua/JVO-2770-2024
OI Huang, Yuhua/0000-0001-8340-3582; LI, HUIHUI/0000-0003-0463-8178; Wen,
   Guihua/0000-0002-9709-1126
FU China National Science Foundation [61273363, 61976092]; Guangdong
   Province Key Area RD Plan Project [2020B1111120001]; Guangzhou Science
   and Technology Planning Project [201604020179, 201803010088]
FX This study was supported by China National Science Foundation (Grant
   Nos. 61273363 and 61976092), Guangdong Province Key Area R&D Plan
   Project (2020B1111120001), and Guangzhou Science and Technology Planning
   Project (Grant No. 201604020179 and 201803010088).
CR [Anonymous], 2018, ARXIV180109030
   Chen HY, 2019, J CHEM INF MODEL, V59, P1605, DOI 10.1021/acs.jcim.9b00041
   Cheung F, 2011, NATURE, V480, pS82, DOI 10.1038/480S82a
   Cyranoski D, 2018, NATURE, V561, P448, DOI 10.1038/d41586-018-06782-7
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Fu MS, 2019, IEEE T CYBERNETICS, V49, P1084, DOI 10.1109/TCYB.2018.2795041
   Guang M.J., 2014, Data Analytics for Traditional Chinese Medicine Research, P97, DOI DOI 10.1007/978-3-319-03801-8_5
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Hong W, 2019, ARTIF INTELL REV
   Hu QN, 2019, COMPUT METH PROG BIO, V174, P9, DOI 10.1016/j.cmpb.2018.10.011
   Hu Y., 2019, IEEE T CYBERNETICS
   Ji WD, 2017, WORLD WIDE WEB, V20, P1071, DOI 10.1007/s11280-017-0443-3
   Kan M, 2017, ARXIV170805024
   Kawale J, 2015, P 24 ACM INT C INF K, P811, DOI DOI 10.1145/2806416.2806527
   Ko Mi Mi, 2013, Evid Based Complement Alternat Med, V2013, P508918, DOI 10.1155/2013/508918
   Li HT, 2016, LECT NOTES COMPUT SC, V9887, P128, DOI 10.1007/978-3-319-44781-0_16
   Li HH, 2019, MULTIMED TOOLS APPL, V78, P6847, DOI 10.1007/s11042-018-6279-8
   Li S, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-S11-S6
   Li W., 2017, DISTRIBUTED REPRESEN
   Li XQ, 2019, IEEE T CYBERNETICS, V49, P380, DOI 10.1109/TCYB.2017.2772289
   Liang ZH, 2019, COMPUT METH PROG BIO, V174, P17, DOI 10.1016/j.cmpb.2018.05.008
   Liao HQ, 2019, MULTIMED TOOLS APPL, V78, P35665, DOI 10.1007/s11042-019-08118-7
   Liu P, 2016, INT C SMART HLTH, P78
   [陆冠龙 Lu Guanlong], 2019, [时珍国医国药, Lishizhen Medicine and Materia Medica Research], V30, P244
   Ma JJ, 2019, ARTIF INTELL MED, V96, P123, DOI 10.1016/j.artmed.2019.03.008
   Mi X, 2016, P SPIE
   Okura S, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1933, DOI 10.1145/3097983.3098108
   Ping D, 2009, ICCIT: 2009 FOURTH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND CONVERGENCE INFORMATION TECHNOLOGY, VOLS 1 AND 2, P279, DOI 10.1109/ICCIT.2009.201
   Qiu J, 2007, NATURE, V448, P126, DOI 10.1038/448126a
   Ruan CY, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3346
   Ruan CY, 2019, LECT NOTES COMPUT SC, V11448, P310, DOI 10.1007/978-3-030-18590-9_35
   Shu ZX, 2019, COMPUT METH PROG BIO, V174, P41, DOI 10.1016/j.cmpb.2018.02.014
   Ting SL, 2010, EXPERT SYST APPL, V37, P8079, DOI 10.1016/j.eswa.2010.05.080
   Vargas S., 2011, P 5 ACM C RECOMMENDE, P109, DOI DOI 10.1145/2043932.2043955
   Vocaturo E, 2019, INT DATABASE ENG APP, P87, DOI 10.1145/3331076.3331124
   Wang H, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1235, DOI 10.1145/2783258.2783273
   Wang Hao, 2015, Chinese Pharmacological Bulletin, V31, P1770, DOI 10.3969/j.issn.1001-1978.2015.12.028
   Wang J, 2013, AM J CHINESE MED, V41, P253, DOI 10.1142/S0192415X13500183
   Wang JG, 2018, EXPERT REV MOL MED, V20, DOI 10.1017/erm.2018.3
   Wang RX, 2019, J PHYS CONF SER, V1168, DOI 10.1088/1742-6596/1168/5/052051
   Wang XY, 2019, LECT NOTES COMPUT SC, V11446, P709, DOI 10.1007/978-3-030-18576-3_42
   Wei J, 2017, EXPERT SYST APPL, V69, P29, DOI 10.1016/j.eswa.2016.09.040
   Wu CH, 2019, J INTELL FUZZY SYST, V36, P861, DOI 10.3233/JIFS-169864
   Wu GS, 2019, J ETHNOPHARMACOL, V242, DOI 10.1016/j.jep.2019.112057
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yao L, 2018, IEEE T KNOWL DATA EN, V30, P1007, DOI 10.1109/TKDE.2017.2787158
   Yao L, 2014, ADV INTELL SYST, V278, P95, DOI 10.1007/978-3-642-54930-4_10
   Ying Z., 2017, J COMPUT APPL, VS1, P303
   Yu T, 2017, ARTIF INTELL MED, V77, P48, DOI 10.1016/j.artmed.2017.04.001
   Yuan WW, 2018, NEURAL COMPUT APPL, V30, P2071, DOI 10.1007/s00521-018-3394-4
   Zaixing Jiang, 2012, 2012 IEEE 14th International Conference on e-Health Networking, Applications and Services (Healthcom 2012), P15, DOI 10.1109/HealthCom.2012.6380057
   Zhang B, 2014, IEEE T BIO-MED ENG, V61, P491, DOI 10.1109/TBME.2013.2282625
   Zhang FZ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P353, DOI 10.1145/2939672.2939673
   Zhang JW, 2015, 2015 12TH INTERNATIONAL COMPUTER CONFERENCE ON WAVELET ACTIVE MEDIA TECHNOLOGY AND INFORMATION PROCESSING (ICCWAMTIP), P251, DOI 10.1109/ICCWAMTIP.2015.7493986
   Zhang Nevin L., 2012, New Frontiers in Applied Data Mining. PAKDD 2011 International Workshops. Revised Selected Papers, P353, DOI 10.1007/978-3-642-28320-8_30
   Zhang QC, 2019, J NETW COMPUT APPL, V129, P1, DOI 10.1016/j.jnca.2018.12.012
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
   Zhao GS, 2018, INT C DIGITAL HOME, P160, DOI 10.1109/ICDH.2018.00037
   Zhou BC, 2019, J ETHNOPHARMACOL, V243, DOI 10.1016/j.jep.2019.112108
   Zhou H, 2018, 2018 11TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2018)
   Zhou Y, 2019, 2019 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE WORKSHOPS (WI 2019 COMPANION), P144, DOI 10.1145/3358695.3360938
   Zhu JJ, 2019, NEUROCOMPUTING, V338, P207, DOI 10.1016/j.neucom.2019.02.017
   Zhuo L, 2014, NEUROCOMPUTING, V134, P111, DOI 10.1016/j.neucom.2012.12.080
NR 64
TC 7
Z9 9
U1 7
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14283
EP 14304
DI 10.1007/s11042-020-10441-3
EA JAN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000610019400010
DA 2024-07-18
ER

PT J
AU Liang, Y
   Lee, D
   Li, Y
   Shin, BS
AF Liang, Yihuai
   Lee, Dongho
   Li, Yan
   Shin, Byeong-Seok
TI Unpaired medical image colorization using generative adversarial network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generative adversarial network; Medical image colorization; TV loss;
   Perceptual loss
AB We consider medical image transformation problems where a grayscale image is transformed into a color image. The colorized medical image should have the same features as the input image because extra synthesized features can increase the possibility of diagnostic errors. In this paper, to secure colorized medical images and improve the quality of synthesized images, as well as to leverage unpaired training image data, a colorization network is proposed based on the cycle generative adversarial network (CycleGAN) model, combining a perceptual loss function and a total variation (TV) loss function. Visual comparisons and experimental indicators from the NRMSE, PSNR, and SSIM metrics are used to evaluate the performance of the proposed method. The experimental results show that GAN-based style conversion can be applied to colorization of medical images. As well, the introduction of perceptual loss and TV loss can improve the quality of images produced as a result of colorization better than the result generated by only using the CycleGAN model.
C1 [Liang, Yihuai; Lee, Dongho; Li, Yan; Shin, Byeong-Seok] Inha Univ, Dept Elect & Comp Engn, 100 Inha Ro, Incheon, South Korea.
C3 Inha University
RP Shin, BS (corresponding author), Inha Univ, Dept Elect & Comp Engn, 100 Inha Ro, Incheon, South Korea.
EM bsshin@inha.ac.kr
RI Liang, Yihuai/GPK-1965-2022; liang, yihuai/GVT-8718-2022; Li,
   Yan/ABG-1759-2022
OI Liang, Yihuai/0000-0002-6254-9969; LI, YAN/0000-0003-3950-4575
FU National Research Foundation of Korea (NRF) - Korea government
   [NRF-2019R1A2C1090713]; BK21 Four Program (Pioneer Program in
   Next-generation Artificial Intelligence for Industrial Convergence) -
   Ministry of Education (MOE, Korea) [5199991014250]; National Research
   Foundation of Korea (NRF)
FX This work was supported by a National Research Foundation of Korea (NRF)
   grant funded by the Korea government (No.NRF-2019R1A2C1090713). This
   research was supported by the BK21 Four Program (Pioneer Program in
   Next-generation Artificial Intelligence for Industrial Convergence,
   5199991014250) funded by the Ministry of Education (MOE, Korea) and
   National Research Foundation of Korea (NRF).
CR [Anonymous], DRIVE GRAND CHALLENG
   [Anonymous], image-to-image translation using cycle-consistent adver
   Anwar S, 2020, ARXIV200810774CSEESS
   Blanch MG, 2019, IEEE INT WORKSH MULT, DOI 10.1109/mmsp.2019.8901712
   Charpiat G, 2008, LECT NOTES COMPUT SC, V5304, P126, DOI 10.1007/978-3-540-88690-7_10
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Chetlur S., 2014, ARXIV14100759
   Chia AYS, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024190
   Fukumoto Y, 2008, J AM COLL CARDIOL, V51, P645, DOI 10.1016/j.jacc.2007.10.030
   Furusawa C, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149430
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   IIZUKA S, 2016, ACM T GRAPHIC, V35, P1, DOI DOI 10.1145/2897824.2925974
   Ironi R., 2005, RENDERING TECHNIQUES, P201
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jheng-Wei Su, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7965, DOI 10.1109/CVPR42600.2020.00799
   Jing YH, 2021, IEEE T CYBERNETICS, V51, P568, DOI 10.1109/TCYB.2019.2904768
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kingma D. P., 2014, arXiv
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee DH, 2020, HUM-CENT COMPUT INFO, V10, DOI 10.1186/s13673-020-00220-2
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li B, 2019, IEEE T IMAGE PROCESS, V28, P4606, DOI 10.1109/TIP.2019.2912291
   Luan Q., 2007, Proceedings of the 18th Eurographics conference on Rendering Techniques, P309
   Mehri A, 2019, IEEE COMPUT SOC CONF, P971, DOI 10.1109/CVPRW.2019.00128
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Morimoto Y, 2009, SIGGRAPH 2009 TALKS
   Nazeri Kamyar, 2018, Articulated Motion and Deformable Objects. 10th International Conference, AMDO 2018. Proceedings: LNCS 10945, P85, DOI 10.1007/978-3-319-94544-6_9
   Park YS, 2020, J INF PROCESS SYST, V16, P171, DOI 10.3745/JIPS.02.0127
   Qu YG, 2006, ACM T GRAPHIC, V25, P1214, DOI 10.1145/1141911.1142017
   Sharma M, 2019, IEEE COMPUT SOC CONF, P2188, DOI 10.1109/CVPRW.2019.00272
   Song Q, 2018, IEEE ACCESS, V6, P1647, DOI 10.1109/ACCESS.2017.2779875
   Taigman Y., 2016, INT C LEARN REPR
   Wan SH, 2020, IEEE T MULTIMEDIA, V22, P1756, DOI 10.1109/TMM.2020.2976573
   WELSH T, 2002, P 29 ANN C COMP GRAP, P277, DOI DOI 10.1145/566570.566576
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
   Yi X, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101552
   Yi-Chin Huang, 2005, 13th Annual ACM International Conference on Multimedia, P351, DOI 10.1145/1101149.1101223
   You SD, 2018, HUM-CENT COMPUT INFO, V8, DOI 10.1186/s13673-018-0158-1
   Yu N, 2017, J INF PROCESS SYST, V13, P204
   Zhang R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073703
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 43
TC 15
Z9 15
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 26669
EP 26683
DI 10.1007/s11042-020-10468-6
EA JAN 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000608669300002
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, CJ
   Luo, ZM
   Zhong, Z
   Li, SZ
AF Wang, Chengji
   Luo, Zhiming
   Zhong, Zhun
   Li, Shaozi
TI SAFD: single shot anchor free face detector
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network (CNN); Face detection; Multi-scale;
   Anchor-free; Attention; Context
AB The anchor-free based face detection methods can cover a large range of scales and perform better in the speed. However, their performance still bears a large gap compared with anchor-based methods, especially for detecting small faces. Because they are troubled by the context modeling and scale imbalance problems. In this study, to address these problems, we propose a novel single shot anchor-free face detector (SAFD) for detecting multi-scale faces by leveraging the multi-scale context aware information of multi-layer features. In the SAFD, we use the dilated convolution layers and attention mechanism to select the informative features that can accommodate to different scales. We also propose a scale-aware sampling strategy to mitigate the scale imbalance problem by adaptivity selecting the positive training samples. The experimental results on two public benchmark datasets, Wider Face and FDDB dataset, demonstrate that our SAFD can achieve competitive performance with the anchor-based detectors while with lower computation cost.
C1 [Wang, Chengji; Zhong, Zhun; Li, Shaozi] Xiamen Univ, Dept Artificial Intelligence, Xiamen, Peoples R China.
   [Luo, Zhiming] Xiamen Univ, Postdoctoral Mobile Stn Informat & Commun Engn, Xiamen, Peoples R China.
C3 Xiamen University; Xiamen University
RP Li, SZ (corresponding author), Xiamen Univ, Dept Artificial Intelligence, Xiamen, Peoples R China.; Luo, ZM (corresponding author), Xiamen Univ, Postdoctoral Mobile Stn Informat & Commun Engn, Xiamen, Peoples R China.
EM zhiming.luo@xmu.edu.cn; szlig@xmu.edu.cn
RI Wang, Chengji/AAB-5307-2022; Li, SZ/G-3959-2010
OI Wang, Chengji/0000-0002-3770-8892; Luo, Zhiming/0000-0002-3411-9582
CR [Anonymous], 2015, P 5 ACM INT C MULT R, DOI DOI 10.1145/2671188.2749408
   Atallah RR, 2018, IEEE ACCESS, V6, P28290, DOI 10.1109/ACCESS.2018.2836924
   Bai YL, 2018, LECT NOTES COMPUT SC, V11216, P21, DOI 10.1007/978-3-030-01258-8_2
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   CAI Z, 2016, EUR C COMP VIS, P354, DOI DOI 10.1007/978-3-319-46493-0_22
   Chen Z, 2018, LECT NOTES COMPUT SC, V11212, P74, DOI 10.1007/978-3-030-01237-3_5
   Chu WQ, 2018, NEUROCOMPUTING, V275, P1035, DOI 10.1016/j.neucom.2017.09.048
   Dakhia A, 2019, NEUROCOMPUTING, V333, P211, DOI 10.1016/j.neucom.2018.12.045
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Davis L. S., 2017, P IEEE INT C COMPUTE
   Deng J., 2019, ARXIV, DOI 10.48550/arXiv.1905.00641
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu PY, 2017, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2017.166
   Huang L., 2015, Comput. Sci.
   Jain V., 2010, Fddb: A benchmark for face detection in unconstrained settings
   Jiang HZ, 2017, IEEE INT CONF AUTOMA, P650, DOI [10.1109/FG.2017.82, 10.1109/MWSYM.2017.8058653]
   Li J, 2019, PROC CVPR IEEE, P5055, DOI 10.1109/CVPR.2019.00520
   Li YZ, 2016, LECT NOTES COMPUT SC, V9907, P420, DOI 10.1007/978-3-319-46487-9_26
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu NA, 2018, IEEE T NEUR NET LEAR, V29, P392, DOI 10.1109/TNNLS.2016.2628878
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   LIU Z, 2015, P ICCV, P3730, DOI DOI 10.1109/ICCV.2015.425
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mathias M, 2014, LECT NOTES COMPUT SC, V8692, P720, DOI 10.1007/978-3-319-10593-2_47
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shen YH, 2018, IEEE T NEUR NET LEAR, V29, P5960, DOI 10.1109/TNNLS.2018.2816021
   Shi BG, 2018, IEEE T NEUR NET LEAR, V29, P183, DOI 10.1109/TNNLS.2016.2618340
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun XD, 2018, NEUROCOMPUTING, V299, P42, DOI 10.1016/j.neucom.2018.03.030
   Tang X, 2018, LECT NOTES COMPUT SC, V11213, P812, DOI 10.1007/978-3-030-01240-3_49
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang CJ, 2018, INT C PATT RECOG, P1554, DOI 10.1109/ICPR.2018.8545814
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yan JJ, 2014, PROC CVPR IEEE, P2497, DOI 10.1109/CVPR.2014.320
   Yang B., 2014, IEEE INT JOINT C BIO, P1
   Yang S, 2017, ARXIV COMPUTER VISIO
   YANG S, 2016, PROC CVPR IEEE, P5525, DOI DOI 10.1109/CVPR.2016.596
   Yang S, 2015, IEEE I CONF COMP VIS, P3676, DOI 10.1109/ICCV.2015.419
   Yu F., 2015, ARXIV
   Yu J., 2016, P 24 ACM INT C MULT, P516, DOI DOI 10.1145/2964284.2967274
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zeng XY, 2016, LECT NOTES COMPUT SC, V9911, P354, DOI 10.1007/978-3-319-46478-7_22
   Zhai Y, 2018, PROC CVPR IEEE, P4139, DOI 10.1109/CVPR.2018.00435
   Zhang KP, 2017, IEEE I CONF COMP VIS, P3190, DOI 10.1109/ICCV.2017.344
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang SF, 2018, NEUROCOMPUTING, V284, P119, DOI 10.1016/j.neucom.2018.01.012
   Zhang SF, 2017, IEEE I CONF COMP VIS, P192, DOI 10.1109/ICCV.2017.30
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhu CC, 2018, PROC CVPR IEEE, P5127, DOI 10.1109/CVPR.2018.00538
   Zhu CC, 2017, ADV COMPUT VIS PATT, P57, DOI 10.1007/978-3-319-61657-5_3
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 59
TC 3
Z9 3
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13761
EP 13785
DI 10.1007/s11042-020-10401-x
EA JAN 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000608669300001
DA 2024-07-18
ER

PT J
AU Kim, J
   Moon, N
AF Kim, Jinah
   Moon, Nammee
TI A deep bidirectional similarity learning model using dimensional
   reduction for multivariate time series clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multivariate time series; Similarity learning; Time series clustering;
   Dimensional reduction
ID NEURAL-NETWORKS; ALGORITHM
AB To analyze multivariate time series, research through dimension reduction is being conducted, but flexible dimension reduction cannot be achieved by reflecting the characteristics or types of data. This paper proposed a Deep Bidirectional Similarity Learning model (DBSL) that predicts similarities for multivariate time series clustering. This model is a feature extraction-based on Convolutional Neural Networks (CNN). By setting the filter and pooling size according to the size of the data, the convolution operation for attributes and time series and the pooling process for time series are repeated to perform dimension reduction, and the similarities in the time series are predicted through bidirectional Long Short Term Memory (LSTM). To improve the data noise problem for missing values, which is the biggest problem in time series, a simple moving average was applied to the model. In addition, it deals with the overall type, and the model is not specialized for one data type. The experiment was conducted by classifying the data according to whether it was multivariate or missing, and it was confirmed that the performance of the proposed model was higher than other proposed methods.
C1 [Kim, Jinah; Moon, Nammee] Hoseo Univ, Dept Comp Sci, Asan, Chungcheongnam, South Korea.
C3 Hoseo University
RP Moon, N (corresponding author), Hoseo Univ, Dept Comp Sci, Asan, Chungcheongnam, South Korea.
EM jina9406@gmail.com; nammee.moon@gmail.com
FU Ministry of Culture, Sports and Tourism (MCST); Korea Creative Content
   Agency (KOCCA) in the Culture Technology (CT) Research & Development
   Program [R2018020083]
FX This research is supported by Ministry of Culture, Sports and Tourism
   (MCST) and Korea Creative Content Agency (KOCCA) in the Culture
   Technology (CT) Research & Development Program 2020(R2018020083).
CR Bagnall Anthony, 2018, The uea & ucr time series classification repository
   Bankó Z, 2012, EXPERT SYST APPL, V39, P12814, DOI 10.1016/j.eswa.2012.05.012
   Blondel, 2017, ARXIV PREPRINT ARXIV
   Büyüksahin ÜÇ, 2019, NEUROCOMPUTING, V361, P151, DOI 10.1016/j.neucom.2019.05.099
   Che Z., 2017, WORKSHOP MINING LEAR
   Cuturi M, 2011, P 28 INT C MACH LEAR, P929
   Ding R, 2015, PROC VLDB ENDOW, V8, P473, DOI 10.14778/2735479.2735481
   Egri A, 2017, IEEE INT CONF INTELL, P241, DOI 10.1109/INES.2017.8118563
   Fawaz HI, 2019, DATA MIN KNOWL DISC, V33, P917, DOI 10.1007/s10618-019-00619-1
   Fu TC, 2011, ENG APPL ARTIF INTEL, V24, P164, DOI 10.1016/j.engappai.2010.09.007
   Hallac D, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P215, DOI 10.1145/3097983.3098060
   Huang MX, 2019, INFORMATION, V10, DOI 10.3390/info10030103
   Huang XH, 2016, INFORM SCIENCES, V367, P1, DOI 10.1016/j.ins.2016.05.040
   Kamber, 2011, DATA MINING CONCEPTS
   Karim F, 2019, NEURAL NETWORKS, V116, P237, DOI 10.1016/j.neunet.2019.04.014
   Kim J., 2019, J AMB INTEL HUM COMP, DOI [10.1007/s12652-019-01398-9, DOI 10.1007/S12652-019-01398-9]
   Kwon DH, 2019, J INF PROCESS SYST, V15, P694
   Li HL, 2019, NEUROCOMPUTING, V349, P239, DOI 10.1016/j.neucom.2019.03.060
   Lin T, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2273
   Liu CL, 2019, IEEE T IND ELECTRON, V66, P4788, DOI 10.1109/TIE.2018.2864702
   Madan R, 2018, INT CONF CONTEMP, P1
   Namin A.S, 2018, ARXIV PREPRINT ARXIV
   Nweke HF, 2019, HUM-CENTRIC COMPUT I, V9, DOI 10.1186/s13673-019-0194-5
   Pei W., 2016, ARXIV
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Shahabi C, 2017, ARXIV PREPRINT ARXIV
   Singhal A, 2005, J CHEMOMETR, V19, P427, DOI 10.1002/cem.945
   Tavenard R, 2020, J MACH LEARN RES, V21
   Yin CY, 2019, HUM-CENT COMPUT INFO, V9, DOI 10.1186/s13673-019-0177-6
   You SD, 2018, HUM-CENT COMPUT INFO, V8, DOI 10.1186/s13673-018-0158-1
   Zhang CX, 2019, AAAI CONF ARTIF INTE, P1409
   Zhao BD, 2017, J SYST ENG ELECTRON, V28, P162, DOI 10.21629/JSEE.2017.01.18
   Zhong X, 2017, EXPERT SYST APPL, V67, P126, DOI 10.1016/j.eswa.2016.09.027
NR 33
TC 2
Z9 2
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34269
EP 34281
DI 10.1007/s11042-020-10476-6
EA JAN 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000607776300002
DA 2024-07-18
ER

PT J
AU Abdulla, AA
   Ahmed, MW
AF Abdulla, Alan Anwer
   Ahmed, Mariwan Wahid
TI An improved image quality algorithm for exemplar-based image inpainting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Inpainting; Exemplar; Euclidean distance; PSNR
AB Image inpainting is a common technique for repairing image regions that are scratched or damaged. This process involves reconstructing damaged parts and filling-in regions in which data/colour information is missing. There are many potential applications for image inpainting, such as repairing old images, repairing scratched images, removing unwanted objects, and filling-in missing areas. This paper develops an exemplar-based algorithm, one of the most important and popular image inpainting techniques, to fill-in missing regions caused by removing unwanted objects, image compression, scratches, or image transformation via the Internet. The proposed algorithm includes two phases of searching to select the best-matching information. In the first phase, the searching mechanism uses the entire image to find and select the most similar patches using the Euclidean distance. The second phase measures the distance between the location of the selected patches and the location of the patch to be filled. The performance of the proposed approach is evaluated through comprehensive experiments on several well-known images used in this area of research. The experimental results demonstrate the superior performance of the proposed approach over some state-of-the-art approaches in terms of quality in terms of both objective (using the peak signal-to-noise ratio (PSNR) as well as the structural similarity index method (SSIM)) and subjective (i.e., visual) measures.
C1 [Abdulla, Alan Anwer] Univ Sulaimani, Dept Informat Technol, Coll Commerce, Sulaymaniyah, Iraq.
   [Ahmed, Mariwan Wahid] Univ Sulaimani, Dept Comp, Coll Sci, Sulaymaniyah, Iraq.
C3 University of Sulimanyah; University of Sulimanyah
RP Abdulla, AA (corresponding author), Univ Sulaimani, Dept Informat Technol, Coll Commerce, Sulaymaniyah, Iraq.
EM alan.abdulla@univsul.edu.iq; mariwan.ahmed@univsul.edu.iq
CR Aarti D, 2012, 2012 1 INT C 19 21 D, P1
   Abdulla A. A., 2015, Ph.D. dissertation
   Ahmed MW., 2020, UHD J SCI TECHNOL, V4, P1, DOI DOI 10.21928/UHDJST.V4N1Y2020.PP1-8
   [Anonymous], 2008, SURVEY VARIATIONAL I
   [Anonymous], 2010, THESIS U KENTUCKY
   Cheng W.-H., 2005, P INT C COMP GRAPH I, P64
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Criminisi Antonio, 2003, 2003 IEEE COMP SOC C, V2, pII, DOI [10.1109/CVPR.2003.1211538, DOI 10.1109/CVPR.2003.1211538]
   Deng LJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141199
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Joao F., 2018, IEEE ACCESS, V7, P3459
   Komal s Mahajan., 2012, IOSR Journal of Computer Engineering (IOSRJCE), V5, P45
   Lu X., 2019, IEEE T CIRCUITS SYST
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Mosleh A, 2013, IEEE T IMAGE PROCESS, V22, P4460, DOI 10.1109/TIP.2013.2273672
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Rao HC, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON COMPUTATIONAL TECHNIQUES, ELECTRONICS AND MECHANICAL SYSTEMS (CTEMS), P162, DOI 10.1109/CTEMS.2018.8769238
   Smith T, 2016, 2016 ONL INT C GREEN, P1, DOI [DOI 10.1109/GET.2016.7916848, DOI 10.1109/GET.2016.7916794]
   Ubale, 2015, INT J COMP SCI INFO, V6, P4559
   Vijay B., 2015, INT J COMPUT APPL, V975, P8887
   Wang J, 2014, NEUROCOMPUTING, V123, P150, DOI 10.1016/j.neucom.2013.06.022
   Xu YS, 2013, 2013 3RD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT), P364, DOI 10.1109/ICCSNT.2013.6967130
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
   Zahra N, 2020, 25 INT COMP C COMP S, P1
NR 24
TC 8
Z9 10
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13143
EP 13156
DI 10.1007/s11042-020-10414-6
EA JAN 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607504000001
DA 2024-07-18
ER

PT J
AU Aslam, A
   Curry, E
AF Aslam, Asra
   Curry, Edward
TI Investigating response time and accuracy in online classifier learning
   for multimedia publish-subscribe systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online training; Internet of Multimedia Things; Event-based systems;
   Multimedia stream processing; Hyperparameter tuning; Object detection;
   Smart cities
ID LIBRARY
AB The enormous growth of multimedia content in the field of the Internet of Things (IoT) leads to the challenge of processing multimedia streams in real-time. Event-based systems are constructed to process event streams. They cannot natively consume multimedia event types produced by the Internet of Multimedia Things (IoMT) generated data to answer multimedia-based user subscriptions. Machine learning-based techniques have enabled rapid progress in solving real-world problems and need to be optimised for the low response time of the multimedia event processing paradigm. In this paper, we describe a classifier construction approach for the training of online classifiers, that can handle dynamic subscriptions with low response time and provide reasonable accuracy for the multimedia event processing. We find that the current object detection methods can be configured dynamically for the construction of classifiers in real-time, by tuning hyperparameters even when training from scratch. Our experiments demonstrate that deep neural network-based object detection models, with hyperparameter tuning, can improve the performance within less training time for the answering of previously unknown user subscriptions. The results from this study show that the proposed online classifier training based model can achieve accuracy of 79.00% with 15-min of training and 84.28% with 1-hour training from scratch on a single GPU for the processing of multimedia events.
C1 [Aslam, Asra; Curry, Edward] NUI Galway, Insight Ctr Data Analyt, Galway, Ireland.
C3 Ollscoil na Gaillimhe-University of Galway
RP Aslam, A (corresponding author), NUI Galway, Insight Ctr Data Analyt, Galway, Ireland.
EM asra.aslam@insight-centre.org; edward.curry@insight-centre.org
RI Aslam, Asra/GLT-8541-2022
OI Aslam, Asra/0000-0002-2654-4255
FU Science Foundation Ireland (SFI) [SFI/12/RC/2289 P2]; European Regional
   Development Fund; NVIDIA Corporation
FX This publication has emanated from research conducted with the financial
   support of Science Foundation Ireland (SFI) under Grant Number
   SFI/12/RC/2289 P2, co-funded by the European Regional Development Fund.
   We also gratefully acknowledge the support of NVIDIA Corporation for the
   donation of GPU (Titan Xp).
CR Aguilera M. K., 1999, Proceedings of the Eighteenth Annual ACM Symposium on Principles of Distributed Computing, P53, DOI 10.1145/301308.301326
   [Anonymous], P 2003 C APPL TECHN
   Aslam A, 2017, P 11 ACM INT C DISTR, P347
   Aslam A, 2018, IEEE ACCESS, V6, P25573, DOI 10.1109/ACCESS.2018.2823590
   Bacon J, 2000, COMPUTER, V33, P68, DOI 10.1109/2.825698
   Baldoni R, 2005, 5 DIS U ROM SAP, P5
   Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26
   Berger J, 2014, PHILOS PSYCHOL, V27, P829, DOI 10.1080/09515089.2013.771241
   Bergstra J., 2011, Adv. Neural Inf. Process. Syst., V24
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Boll S, 2018, IEEE MULTIMEDIA, V25, P51, DOI 10.1109/MMUL.2018.011921235
   Boonma Pruet, 2012, WIRELESS TECHNOLOGIE, P819
   Boyd Kendrick, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2013. Proceedings: LNCS 8190, P451, DOI 10.1007/978-3-642-40994-3_29
   Burcea I, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT, P39
   Campailla A, 2001, PROC INT CONF SOFTW, P443, DOI 10.1109/ICSE.2001.919117
   Carzaniga A, 2001, ACM T COMPUT SYST, V19, P332, DOI 10.1145/380749.380767
   Carzaniga A., 2000, Proceeding of the Nineteenth Annual ACM Symposium on Principles of Distributed Computing, P219, DOI 10.1145/343477.343622
   Collins B, 2008, LECT NOTES COMPUT SC, V5302, P86, DOI 10.1007/978-3-540-88682-2_8
   Cugola G., 2002, ACM SIGMOBILE Mobile Computing and Communications Review, V6, P25
   Cugola G, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2187671.2187677
   Cvetkovic B., 2011, IJCAI, P24
   Cvetkovic B, 2015, J AMB INTEL SMART EN, V7, P171, DOI 10.3233/AIS-150308
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dandala TT, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATION AND SIGNAL PROCESSING (ICCCSP), P201
   Davies S., 2005, Websphere mq v6 fundamentals
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Eugster PT, 2003, ACM COMPUT SURV, V35, P114, DOI 10.1145/857076.857078
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fabret F, 2001, SIGMOD RECORD, V30, P115, DOI 10.1145/376284.375677
   Fabret F, 2000, P COOP IS
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Gough J., 1995, Australian Computer Science Communications, V17, P173
   Group OM, 2000, CORB COMM OBJ SERV S
   Hasan S., 2016, THESIS
   Hasan S., 2012, Proc. 6th ACM Int'l Conf. on Distributed Event-Based Systems (DEBS '12), P252, DOI DOI 10.1145/2335484.2335512
   Hoi SCH, 2014, J MACH LEARN RES, V15, P495
   Huan J, 2017, IEEE INT C BIOINFORM, P4
   IBM, 2006, IBM White Pap., V36, P34
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kale S, 2005, 25TH IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, PROCEEDINGS, P363, DOI 10.1109/ICDCSW.2005.40
   Kanungo A, 2014, 2014 RECENT ADVANCES IN ENGINEERING AND COMPUTATIONAL SCIENCES (RAECS)
   Ko AHR, 2008, PATTERN RECOGN, V41, P1718, DOI 10.1016/j.patcog.2007.10.015
   Krasin I., 2017, Openimages: A public dataset for large-scale multi-label and multi-class image classification
   Lai CH, 2010, CONF TECHNOL APPL, P195, DOI 10.1109/TAAI.2010.41
   Lee M, 2013, IEEE INT C COMPUT, P833, DOI 10.1109/CSE.2013.126
   Lewis D. D., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P3
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luo G, 2016, NETW MODEL ANAL HLTH, V5, DOI 10.1007/s13721-016-0125-6
   Marques O, 2003, LECT NOTES COMPUT SC, V2870, P550
   Melville P, 2003, Creating Diverse Ensemble Classifiers
   Pereira J, 2000, LECT NOTES COMPUT SC, V1901, P162
   Pietzuch PR, 2002, 22ND INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOP, PROCEEDINGS, P611, DOI 10.1109/ICDCSW.2002.1030837
   Probst P, 2019, J MACH LEARN RES, V20
   Provost F, 1998, MACH LEARN, V30, P127, DOI 10.1023/A:1007442505281
   Pulit SL, 2018, NEUROL-GENET, V4, DOI 10.1212/NXG.0000000000000293
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rjaibi Walid., 2002, Proceedings of the 2002 conference of the Centre for Advanced Studies on Collaborative research, CASCON '02, P9
   Roy Nicholas, 2001, Toward optimal active learning through monte carlo estimation of error reduction, P441
   Sahoo D, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2660
   Seung H. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P287, DOI 10.1145/130385.130417
   Shalev-Shwartz Shai, 2007, Online learning: Theory, algorithms, and applications
   Shu CF, 2005, AVSS 2005: Advanced Video and Signal Based Surveillance, Proceedings, P318
   Snoek J., 2012, Advances in Neural Information Processing Systems, V25, DOI DOI 10.48550/ARXIV.1206.2944
   Thornton C, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P847, DOI 10.1145/2487575.2487629
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang Haixun, 2003, ACM SIGKDD, P226, DOI DOI 10.1145/956750.956778
   Wu Y, 2017, NEUROCOMPUTING, V260, P9, DOI 10.1016/j.neucom.2017.03.077
   Yadav P, 2019, IEEE INT CONF BIG DA, P2513, DOI 10.1109/BigData47090.2019.9006018
   YAN TW, 1994, ACM T DATABASE SYST, V19, P332, DOI 10.1145/176567.176573
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhu XQ, 2011, KNOWL INF SYST, V28, P523, DOI 10.1007/s10115-010-0331-y
   Zhukov Alexei, 2017, APPL COMPUTING INFOR
   Zliobaite I, 2014, IEEE T KNOWL DATA EN, V26, P309, DOI 10.1109/TKDE.2012.147
NR 78
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13021
EP 13057
DI 10.1007/s11042-020-10277-x
EA JAN 2021
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000606409000003
PM 34720665
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Chen, C
   Stamm, MC
AF Chen, Chen
   Stamm, Matthew C.
TI Robust camera model identification using demosaicing residual features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camera model identification; Demsoaicing residual; Geometric pattern;
   Co-ocurrence matrix; Ensemble classifier
ID INTERPOLATION; FORENSICS
AB In this paper, we propose a new framework for performing accurate and robust camera model identification by fully exploiting demosaicing information in a camera's output images. Instead of fitting a camera's demosaicing process into parametric models, our framework works by exposing and extracting a diverse set of intra-channel and inter-channel color value correlations originated from the demosaicing process. To expose these correlations, we first apply a number of diversified baseline demosaicing algorithms to re-demosaic the image under investigation, and gather a set of both linear and nonlinear demosaicing residuals. To further extract demosaicing correlations with respect to the color filter array (CFA) structure, co-occurrence matrices are calculated using a new set of geometric patterns. These patterns are specifically designed to extract different types of color value dependencies within the repeated lattice of the CFA pattern. We design a multi-class ensemble classifier to utilize all extracted color value correlations to perform camera model identification. A series of experiments show that our proposed framework can achieve an accuracy of 98.14% on a database with 68 camera models, and is highly robust to post-JPEG compression and contrast enhancement.
C1 [Chen, Chen; Stamm, Matthew C.] Drexel Univ, Dept Elect & Comp Engn, Philadelphia, PA 19104 USA.
C3 Drexel University
RP Stamm, MC (corresponding author), Drexel Univ, Dept Elect & Comp Engn, Philadelphia, PA 19104 USA.
EM cc3359@drexel.edu; mstamm@coe.drexel.edu
FU National Science Foundation [1553610]
FX This material is based upon work supported by the National Science
   Foundation under Grant No. 1553610. Any opinions, findings, and
   conclusions or recommendations expressed in this material are those of
   the authors and do not necessarily reflect the views of the National
   Science Foundation.
CR Aly M., 2005, NEURAL NETWORKS, V19, P9
   [Anonymous], 2017, Electronic Imaging
   Bayram S, 2005, IEEE IMAGE PROC, P2793
   Bondi L, 2017, IEEE SIGNAL PROC LET, V24, P259, DOI 10.1109/LSP.2016.2641006
   Cao H, 2009, IEEE T INF FOREN SEC, V4, P899, DOI 10.1109/TIFS.2009.2033749
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Cheng CQ, 2015, INT ARCH PHOTOGRAMM, V47, P1, DOI 10.5194/isprsarchives-XL-7-W4-1-2015
   Choi KS, 2006, TENCON IEEE REGION, P656
   Choi KS, 2006, PROC SPIE, V6069, DOI 10.1117/12.649775
   Deng ZH, 2011, IEEE I CONF COMP VIS, P57, DOI 10.1109/ICCV.2011.6126225
   Filler T, 2008, IEEE IMAGE PROC, P1296
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gunturk BK, 2002, IEEE T IMAGE PROCESS, V11, P997, DOI 10.1109/TIP.2002.801121
   Kee E, 2011, IEEE T INF FOREN SEC, V6, P1066, DOI 10.1109/TIFS.2011.2128309
   Kharrazi M, 2004, IEEE IMAGE PROC, P709
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Marra F, 2017, MULTIMED TOOLS APPL, V76, P4765, DOI 10.1007/s11042-016-3663-0
   Mckay C, 2008, INT CONF ACOUST SPEE, P1657, DOI 10.1109/ICASSP.2008.4517945
   Milani S, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6854082
   Paliy D, 2007, INT J IMAG SYST TECH, V17, P105, DOI 10.1002/ima.20109
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   Swaminathan A, 2007, IEEE T INF FOREN SEC, V2, P91, DOI 10.1109/TIFS.2006.890307
   Tuama A, 2016, IEEE INT WORKS INFOR
   Van LT, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P883
   Zhao XW, 2016, IEEE IMAGE PROC, P151, DOI 10.1109/ICIP.2016.7532337
NR 26
TC 6
Z9 7
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11365
EP 11393
DI 10.1007/s11042-020-09011-4
EA JAN 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000605119700001
DA 2024-07-18
ER

PT J
AU Gómez-Silva, MJ
AF Gomez-Silva, Maria J.
TI Deep multi-shot network for modelling appearance similarity in
   multi-person tracking applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep neural network; Appearance similarity; Multi-shot recognition;
   Multi-object tracking
ID ONLINE MULTIOBJECT TRACKING; MULTITARGET
AB The automatization of Multi-Object Tracking becomes a demanding task in real unconstrained scenarios, where the algorithms have to deal with crowds, crossing people, occlusions, disappearances and the presence of visually similar individuals. In those circumstances, the data association between the incoming detections and their corresponding identities could miss some tracks or produce identity switches. In order to reduce these tracking errors, and even their propagation in further frames, this article presents a Deep Multi-Shot neural model for measuring the Degree of Appearance Similarity (MS-DoAS) between person observations. This model provides temporal consistency to the individuals' appearance representation, and provides an affinity metric to perform frame-by-frame data association, allowing online tracking. The model has been deliberately trained to be able to manage the presence of previous identity switches and missed observations in the handled tracks. With that purpose, a novel data generation tool has been designed to create training tracklets that simulate such situations. The model has demonstrated a high capacity to discern whether a new observation corresponds to a certain track or not, achieving a classification accuracy of 97% in a hard test that simulates tracks with previous mistakes. Moreover, the tracking efficiency of the model in a Surveillance application has been demonstrated by integrating that into the frame-by-frame association of a Tracking-by-Detection algorithm.
C1 [Gomez-Silva, Maria J.] Univ Carlos III Madrid, Intelligent Syst Lab LSI Res Grp, Avda Univ 30, Madrid 28911, Spain.
C3 Universidad Carlos III de Madrid
RP Gómez-Silva, MJ (corresponding author), Univ Carlos III Madrid, Intelligent Syst Lab LSI Res Grp, Avda Univ 30, Madrid 28911, Spain.
EM magomezs@ing.uc3m.es
RI GÓMEZ-SILVA, MARÍA/AAX-7833-2020
OI GÓMEZ-SILVA, MARÍA/0000-0002-8506-1499
FU Spanish Government through the CICYT [TRA2016-78886-C3-1-R,
   RTI2018-096036-B-C21]; Universidad Carlos III of Madrid
   [PEAVAUTO-CM-UC3M]; Comunidad de Madrid through SEGVAUTO-4.0-CM
   [P2018/EMT-4362]
FX Research supported by the Spanish Government through the CICYT projects
   (TRA2016-78886-C3-1-R and RTI2018-096036-B-C21), Universidad Carlos III
   of Madrid through (PEAVAUTO-CM-UC3M) and the Comunidad de Madrid through
   SEGVAUTO-4.0-CM (P2018/EMT-4362). We gratefully acknowledge the support
   of NVIDIA Corporation with the donation of the GPUs used for this
   research
CR [Anonymous], 2019, CVPR
   Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159
   Bae SH, 2014, IEEE T IMAGE PROCESS, V23, P2820, DOI 10.1109/TIP.2014.2320821
   Ben Shitrit H, 2014, IEEE T PATTERN ANAL, V36, P1614, DOI 10.1109/TPAMI.2013.210
   Ben Shitrit H, 2011, IEEE I CONF COMP VIS, P137, DOI 10.1109/ICCV.2011.6126235
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Chen XJ, 2015, IEEE SENS J, V15, P2692, DOI 10.1109/JSEN.2015.2392781
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Ess A, 2008, PROC CVPR IEEE, P1857
   Ess Andreas, 2009, ICRA WORKSH PEOPL DE, V2
   Fan JL, 2010, IEEE T NEURAL NETWOR, V21, P1610, DOI 10.1109/TNN.2010.2066286
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Gómez-Silva MJ, 2019, J IMAGING SCI TECHN, V63, DOI 10.2352/J.ImagingSci.Technol.2019.63.2.020401
   Gómez-Silva MJ, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 6, P277, DOI 10.5220/0006167002770285
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kim C, 2015, IEEE I CONF COMP VIS, P4696, DOI 10.1109/ICCV.2015.533
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le N, 2016, LECT NOTES COMPUT SC, V9914, P43, DOI 10.1007/978-3-319-48881-3_4
   Leal-Taixé L, 2016, IEEE COMPUT SOC CONF, P418, DOI 10.1109/CVPRW.2016.59
   Liu JC, 2013, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2013.239
   McLaughlin N, 2015, IEEE WINT CONF APPL, P71, DOI 10.1109/WACV.2015.17
   Meijering E, 2009, SEMIN CELL DEV BIOL, V20, P894, DOI 10.1016/j.semcdb.2009.07.004
   Milan A., 2016, ARXIV160300831
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sadeghian A, 2017, IEEE I CONF COMP VIS, P300, DOI 10.1109/ICCV.2017.41
   Schulter S, 2017, PROC CVPR IEEE, P2730, DOI 10.1109/CVPR.2017.292
   Shu G, 2012, PROC CVPR IEEE, P1815, DOI 10.1109/CVPR.2012.6247879
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang SY, 2016, LECT NOTES COMPUT SC, V9914, P100, DOI 10.1007/978-3-319-48881-3_8
   Yang B, 2012, PROC CVPR IEEE, P2034, DOI 10.1109/CVPR.2012.6247907
   Yang F, 2016, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2016.234
   Yang M, 2016, COMPUT VIS IMAGE UND, V153, P16, DOI 10.1016/j.cviu.2016.05.003
   Zhai Mengyao, 2018, P EUR C COMP VIS ECC, P681
   Zhang L, 2008, INT C WAVEL ANAL PAT, P11, DOI 10.1109/ICWAPR.2008.4635742
   Zhang S, 2015, COMPUT VIS IMAGE UND, V134, P64, DOI 10.1016/j.cviu.2015.01.002
NR 41
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23701
EP 23721
DI 10.1007/s11042-020-10256-2
EA JAN 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000605548700003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ranade, SK
   Anand, S
AF Ranade, Sukhjeet K.
   Anand, Supriya
TI Color face recognition using normalized-discriminant hybrid color space
   and quaternion moment vector features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Color space; Quaternion moments; Multi-channel
   moments; Similarity measure
ID ZERNIKE MOMENTS; IMAGE-ANALYSIS; SAMPLE; METHODOLOGY; INFORMATION;
   INVARIANTS; ACCURATE; ROBUST
AB The Zernike and pseudo-Zernike moments (ZMs/PZMs) have been found useful for a variety of applications requiring feature extraction due to their favorable properties, such as low information redundancy, rotational invariance, higher noise resilience and extendibility to the color space. In this paper, we propose an approach for color face recognition based on Zernike/pseudo-Zernike quaternion moment vector (QMV) features and a novel normalized-discriminant hybrid color space. The proposed (XSBr)-S-n color space is composed by taking X-n from the normalized-XYZ, S from HSV and Br from the discriminant RGB-r color spaces to capture the features efficiently. In addition, we propose the use of quaternion vector distance (QVD) similarity measure for the QMV features in order to enhance the recognition accuracy. The exhaustive comparative performance analyses with the state-of-the-art approaches in the different color spaces demonstrate the superiority of the proposed approach in terms of accuracy and speed.
C1 [Ranade, Sukhjeet K.] Punjabi Univ, Dept Comp Sci, Patiala, Punjab, India.
   [Anand, Supriya] Punjabi Univ, Dept Comp Sci & Engn, Patiala, Punjab, India.
C3 Punjabi University; Punjabi University
RP Anand, S (corresponding author), Punjabi Univ, Dept Comp Sci & Engn, Patiala, Punjab, India.
EM mrsdjjr@gmail.com; supriya.anand70@gmail.com
OI Kaur, Sukhjeet/0000-0003-2192-2285
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Al-Mohair FI.K., 2014, 2014 International Conference on Computer and Information Sciences (ICCOINS), P1, DOI DOI 10.1109/ICCOINS.2014.6868362
   Anbarjafari G, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-6
   Bao SZ, 2019, INT J MACH LEARN CYB, V10, P385, DOI 10.1007/s13042-017-0722-4
   Belk J, 2012, QUATERNION DISTANCE
   Chakraborty S, 2019, MULTIMED TOOLS APPL, V78, P25143, DOI 10.1007/s11042-019-7707-0
   Chen BJ, 2012, SIGNAL PROCESS, V92, P308, DOI 10.1016/j.sigpro.2011.07.018
   Chen BJ, 2017, J VIS COMMUN IMAGE R, V49, P283, DOI 10.1016/j.jvcir.2017.08.011
   Chen BJ, 2017, NEUROCOMPUTING, V266, P293, DOI 10.1016/j.neucom.2017.05.047
   Chen BJ, 2016, INT C PATT RECOG, P704, DOI 10.1109/ICPR.2016.7899717
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Chen SC, 2004, PATTERN RECOGN, V37, P1553, DOI 10.1016/j.patcog.2003.12.010
   Choi JY, 2012, IEEE T IMAGE PROCESS, V21, P1366, DOI 10.1109/TIP.2011.2168413
   Choi JY, 2009, IEEE T SYST MAN CY B, V39, P1217, DOI 10.1109/TSMCB.2009.2014245
   Deng WH, 2010, PATTERN RECOGN, V43, P1748, DOI 10.1016/j.patcog.2009.12.004
   Ell TA, 2007, IEEE T IMAGE PROCESS, V16, P22, DOI 10.1109/TIP.2006.884955
   Guo LQ, 2014, INFORM SCIENCES, V273, P132, DOI 10.1016/j.ins.2014.03.037
   Hamilton W., 1866, ELEMENTS QUATERNIONS
   Karakasis EG, 2014, IEEE T IMAGE PROCESS, V23, P596, DOI 10.1109/TIP.2013.2289997
   Kuffner JJ, 2004, IEEE INT CONF ROBOT, P3993, DOI 10.1109/ROBOT.2004.1308895
   Lee SH, 2012, IEEE T IMAGE PROCESS, V21, P2347, DOI 10.1109/TIP.2011.2181526
   Li J, 2016, NEUROCOMPUTING, V182, P111, DOI 10.1016/j.neucom.2015.12.005
   Li S, 2009, IEEE T SYST MAN CY A, V39, P227, DOI 10.1109/TSMCA.2008.2007988
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P49, DOI 10.1109/MIC.2020.2971447
   Li ZM, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419560044
   Liu CJ, 2013, NEUROCOMPUTING, V101, P43, DOI 10.1016/j.neucom.2012.05.029
   Liu CJ, 2011, PATTERN RECOGN LETT, V32, P1796, DOI 10.1016/j.patrec.2011.07.024
   Liu JJ, 2019, INT J MACH LEARN CYB, V10, P1051, DOI 10.1007/s13042-017-0782-5
   Liu Q, 2011, 2011 8 INT C INF COM, DOI 10.1109/ICICS.2011.6174265
   Liu Q, 2014, OPTIK, V125, P6366, DOI 10.1016/j.ijleo.2014.06.103
   Liu ZM, 2008, IEEE T IMAGE PROCESS, V17, P1975, DOI 10.1109/TIP.2008.2002837
   Liu ZM, 2016, INT J POLYM SCI, V2016, DOI 10.1155/2016/9351725
   Liu ZM, 2010, PATTERN RECOGN, V43, P2882, DOI 10.1016/j.patcog.2010.03.003
   Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70
   Lu Z, 2018, PATTERN RECOGN, V83, P456, DOI 10.1016/j.patcog.2018.06.015
   Martinez A., 1998, AR FACE DATABASE
   Nefian AV.AraNefian, 1999, FACE RECOGNITION PAG
   Niu PP, 2016, MULTIMED TOOLS APPL, V75, P7655, DOI 10.1007/s11042-015-2687-1
   Ortiz EG, 2014, COMPUT VIS IMAGE UND, V118, P153, DOI 10.1016/j.cviu.2013.09.004
   Peng F, 2018, MULTIMED TOOLS APPL, V77, P8883, DOI 10.1007/s11042-017-4780-0
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Rajapakse M, 2004, IEEE IMAGE PROC, P2007
   Singh Chandan, 2011, Pattern Recognition and Image Analysis, V21, P71, DOI 10.1134/S1054661811010044
   Singh C, 2018, DIGIT SIGNAL PROCESS, V78, P376, DOI 10.1016/j.dsp.2018.04.001
   Singh C, 2016, OPTIK, V127, P2158, DOI 10.1016/j.ijleo.2015.11.115
   Spacek L, 2008, COLLECTION FACIAL IM
   Sun YF, 2011, PATTERN RECOGN LETT, V32, P597, DOI 10.1016/j.patrec.2010.11.004
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Torres L., 1999, IEEE INT C IM PROC, P627, DOI 10.1109/ICIP.1999.81719
   Uçar A, 2014, SCI WORLD J, DOI 10.1155/2014/628494
   Wang CP, 2018, INFORM SCIENCES, V450, P141, DOI 10.1016/j.ins.2018.03.040
   Wang JW, 2016, PATTERN RECOGN, V57, P31, DOI 10.1016/j.patcog.2016.03.021
   Wang XY, 2014, INFORM SCIENCES, V277, P731, DOI 10.1016/j.ins.2014.02.158
   Wee CY, 2007, IMAGE VISION COMPUT, V25, P967, DOI 10.1016/j.imavis.2006.07.010
   Wu S, 2014, OPTIK, V125, P2344, DOI 10.1016/j.ijleo.2013.10.071
   Yadav S, 2019, EXPERT SYST APPL, V116, P265, DOI 10.1016/j.eswa.2018.09.032
   Yan HB, 2014, NEUROCOMPUTING, V143, P134, DOI 10.1016/j.neucom.2014.06.012
   Yang J, 2010, PATTERN RECOGN, V43, P1454, DOI 10.1016/j.patcog.2009.11.014
   Yip AW, 2002, PERCEPTION, V31, P995, DOI 10.1068/p3376
   Zhang LB, 2018, J VIS COMMUN IMAGE R, V51, P56, DOI 10.1016/j.jvcir.2018.01.001
   Zhou SR, 2012, NEUROCOMPUTING, V116, P260
   Zou CM, 2016, IEEE T IMAGE PROCESS, V25, P3287, DOI 10.1109/TIP.2016.2567077
NR 62
TC 7
Z9 8
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10797
EP 10820
DI 10.1007/s11042-020-10244-6
EA JAN 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000604479100006
DA 2024-07-18
ER

PT J
AU Algarni, AD
   Soliman, NF
   Abdallah, HA
   Abd El-Samie, FE
AF Algarni, Abeer D.
   Soliman, Naglaa F.
   Abdallah, Hanaa A.
   Abd El-Samie, Fathi E.
TI Encryption of ECG signals for telemedicine applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ECG signals -fusion; encryption; chaotic systems; random projection;
   salting; logistic map
AB Multimedia security has been extensively used in content protection, image authentication, data hiding and signal encryption. Similarly, transmission of biomedical data or information remotely for healthcare applications should be secure. One of the important medical signals that need to be transmitted to healthcare centers is the Electrocardiogram (ECG) signal. This paper is concerned mainly with ECG signal encryption for security applications. The paper presents three cryptosystems for ECG signal encryption based on the fusion of ECG signals with other masking signals that are rich in activities such as speech signals. The common thread between these cryptosystems is the operation on sample values of the ECG signal rather than adopting encoding and decoding schemes, and this saves much time and is more immune to both noise and hacking scenarios. The proposed cryptosystems are compared to the encryption technique that uses 1-D logistic map. The performances of the proposed cryptosystems are evaluated through simulation experiments in terms of histogram, structural similarity index, Signal-to-Noise Ratio (SNR), log-likelihood ratio, spectral distortion and correlation coefficient. It is clear from the experiments that the utilization of more levels of encryption increases the security.
C1 [Algarni, Abeer D.; Soliman, Naglaa F.; Abdallah, Hanaa A.; Abd El-Samie, Fathi E.] Princess Nourah Bint Abdulrahman Univ, Dept Informat Technol, Coll Comp & Informat Sci, Riyadh 84428, Saudi Arabia.
   [Soliman, Naglaa F.; Abdallah, Hanaa A.] Zagazig Univ, Dept Elect & Commun, Fac Engn, Zagazig, Egypt.
   [Abd El-Samie, Fathi E.] Menoufia Univ, Dept Elect & Elect Commun Engn, Fac Elect Engn, Menoufia 32952, Egypt.
C3 Princess Nourah bint Abdulrahman University; Egyptian Knowledge Bank
   (EKB); Zagazig University; Egyptian Knowledge Bank (EKB); Menofia
   University
RP Algarni, AD (corresponding author), Princess Nourah Bint Abdulrahman Univ, Dept Informat Technol, Coll Comp & Informat Sci, Riyadh 84428, Saudi Arabia.
EM adalqarni@pnu.edu.sa; nagla_soliman@yahoo.com;
   dr.hanaaabdalaziz@gmail.com; fathi_sayed@yahoo.com
RI abdalaziz, hanaa/GLQ-8305-2022; Algarni, Abeer/HIZ-6134-2022; Soliman,
   Naglaa/HJY-8292-2023; Sayed, Fathi/HRA-4752-2023
OI Sayed, Fathi/0000-0001-8749-9518; abdallah, Hanaa A.
   Abdallah/0000-0003-0307-1384; Soliman, Naglaa/0000-0001-7322-1857
FU Deanship of Scientific Research at Princess Nourah bint Abdulrahman
   University through the Fast-track Research Funding Program
FX This research was funded by the Deanship of Scientific Research at
   Princess Nourah bint Abdulrahman University through the Fast-track
   Research Funding Program.
CR Acharya R, 2004, COMPUT METH PROG BIO, V76, P13, DOI 10.1016/j.cmpb.2004.02.009
   Al Saad SN., 2014, INT J COMPUT APPL, V93, P19
   Bai T, 2019, FUTURE GENER COMP SY, V92, P800, DOI 10.1016/j.future.2018.01.031
   Baig MM, 2019, HEALTH INFORM J, V25, P1091, DOI 10.1177/1460458217740722
   Bhalerao S, 2019, PATTERN RECOGN LETT, V125, P463, DOI 10.1016/j.patrec.2019.06.004
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Clifford G. D., 2006, Advanced Methods and Tools for ECG Data Analysis, P55
   De Capua C, 2010, IEEE T INSTRUM MEAS, V59, P2530, DOI 10.1109/TIM.2010.2057652
   Ding H, 2016, CHIN SPOK LANG PROC
   El-Hoseny HM, 2019, MULTIMED TOOLS APPL, V78, P26373, DOI 10.1007/s11042-019-7552-1
   Fang SC, 2009, PATTERN RECOGN, V42, P1824, DOI 10.1016/j.patcog.2008.11.020
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Golpîra H, 2009, IEEE INT SYMP SIGNAL, P31, DOI 10.1109/ISSPIT.2009.5407489
   Hameed M.E., 2019, International Journalof Electrical and Computer Engineering, V9, P4850
   Hashad FG, 2019, MULTIMED TOOLS APPL, V78, P27351, DOI 10.1007/s11042-019-7580-x
   Huang P, 2016, IEEE GLOB COMM CONF
   Kumar V, 2006, INT J SYST SCI, V37, P45, DOI 10.1080/00319100500412337
   Lucani D, 2006, 2006 28TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOLS 1-15, P2926
   Manjunath G, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P553, DOI 10.1109/ICME.2002.1035841
   Mathivanan P, 2019, CRYPTOLOGIA, V43, P233, DOI 10.1080/01611194.2018.1549122
   Merone M, 2017, EXPERT SYST APPL, V67, P189, DOI 10.1016/j.eswa.2016.09.030
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Murillo-Escobar MA, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0698-3
   Mushtaq MF, 2017, INT J ADV COMPUT SC, V8, P333
   Nadda V, 2017, ADV MARKETING CUSTOM, P1, DOI 10.4018/978-1-5225-2206-5
   Nayak J, 2009, J MED SYST, V33, P163, DOI 10.1007/s10916-008-9176-2
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Pandey A, 2019, BIOCYBERN BIOMED ENG, V39, P282, DOI 10.1016/j.bbe.2018.11.012
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151
   Pillai JK, 2011, IEEE T PATTERN ANAL, V33, P1877, DOI 10.1109/TPAMI.2011.34
   Raeiatibanadkooki M, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0433-5
   Rajabion L, 2019, INT J INFORM MANAGE, V49, P271, DOI 10.1016/j.ijinfomgt.2019.05.017
   RajendraAcharya U, 2007, ADV CARDIAC SIGNAL P
   Sanaz Rahimi Moosavi, 2017, CRYPTOGRAPHIC KEY GE, DOI [10.1109/CCNC.2017.7983280, DOI 10.1109/CCNC.2017.7983280]
   Sankari V., 2014, INF COMM EMB SYST IC, P1, DOI DOI 10.1109/ICICES.2014.7033925
   Scalart P, 1996, INT CONF ACOUST SPEE, P629, DOI 10.1109/ICASSP.1996.543199
   Wang F, 2019, COMPUT METH PROG BIO, V175, P139, DOI 10.1016/j.cmpb.2019.03.019
   Wang X, 2013, NONLINEAR DYNAM, V71, P429, DOI 10.1007/s11071-012-0669-7
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Zhang GH, 2012, IEEE T INF TECHNOL B, V16, P176, DOI 10.1109/TITB.2011.2173946
   Zhang YS, 2014, OPTIK, V125, P1562, DOI 10.1016/j.ijleo.2013.09.018
   Zheng KM, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, VOLS 1 AND 2, PROCEEDINGS, P295, DOI 10.1109/CIS.2008.71
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 44
TC 25
Z9 25
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10679
EP 10703
DI 10.1007/s11042-020-09369-5
EA NOV 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000593447300001
DA 2024-07-18
ER

PT J
AU Abdelaziz, M
   Zhang, ZP
AF Abdelaziz, Mounir
   Zhang, Zuping
TI Few-shot learning with saliency maps as additional visual information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Few-Shot learning; Saliency detection; Second-Order statistics; Object
   recognition
ID RECOGNITION
AB Few-shot learning aims to learn to recognize new object categories from few training examples. Recently, few-shot learning methods have made significant progress. However, most of these methods are based on the concept of learning relations between only the image features in order to recognize objects and this alone may not be sufficient due to the training data scarcity. Therefore, this study focuses on providing saliency maps as additional visual information that describes the shape of the objects and supports few-shot visual learning. In this paper, we propose a simple few-shot learning method called Few-shot Learning with Saliency Maps as Additional Visual Information (SMAVI). Our method encodes the images and the saliency maps, then it learns the deep relations between the combined image features and saliency map features of the objects, where the saliency maps are extracted from the images using a saliency network. The experimental results show that the proposed method outperforms the related state of the art methods on standard few-shot learning datasets.
C1 [Abdelaziz, Mounir; Zhang, Zuping] Cent South Univ, Sch Comp Sci, Engn, 932 South Lushan Rd, Changsha 410083, Hunan, Peoples R China.
C3 Central South University
RP Zhang, ZP (corresponding author), Cent South Univ, Sch Comp Sci, Engn, 932 South Lushan Rd, Changsha 410083, Hunan, Peoples R China.
EM mouniraziz@csu.edu.cn; zpzhang@csu.edu.cn
OI Abdelaziz, Mounir/0000-0003-0071-3679
FU National Natural Science Foundation of China [61379109, M1321007]; Hunan
   Key Laboratory for internet of Things in Electricity [2019TP1016]
FX This study was funded by the National Natural Science Foundation of
   China (Grant No.61379109, M1321007) and Hunan Key Laboratory for
   internet of Things in Electricity (Grant/Award Number: 2019TP1016).
CR [Anonymous], 2013, HIGHERORDER OCCURREN
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   Boureau Y. L., 2010, P 27 INT C MACH LEAR, P111
   Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32
   Chen ZT, 2019, PROC CVPR IEEE, P8672, DOI 10.1109/CVPR.2019.00888
   Chen ZT, 2019, IEEE T IMAGE PROCESS, V28, P4594, DOI 10.1109/TIP.2019.2910052
   Chu WH, 2019, PROC CVPR IEEE, P6244, DOI 10.1109/CVPR.2019.00641
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Finn C, 2017, PR MACH LEARN RES, V70
   Gao ZF, 2020, IEEE NETWORK, V34, P216, DOI 10.1109/MNET.001.1900260
   Hariharan B, 2017, IEEE I CONF COMP VIS, P3037, DOI 10.1109/ICCV.2017.328
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jégou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609
   Khosla A., 2011, P CVPR WORKSH FIN GR
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Koniusz P, 2018, LECT NOTES COMPUT SC, V11220, P815, DOI 10.1007/978-3-030-01270-0_48
   Koniusz P, 2018, PROC CVPR IEEE, P5774, DOI 10.1109/CVPR.2018.00605
   Koniusz P, 2017, IEEE T PATTERN ANAL, V39, P313, DOI 10.1109/TPAMI.2016.2545667
   Koniusz P, 2013, COMPUT VIS IMAGE UND, V117, P479, DOI 10.1016/j.cviu.2012.10.010
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lake B., 2011, P ANN M COGNITIVE SC, V33, P1
   Lee K, 2019, PROC CVPR IEEE, P10649, DOI 10.1109/CVPR.2019.01091
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li WB, 2019, PROC CVPR IEEE, P7253, DOI 10.1109/CVPR.2019.00743
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Oh K, 2016, IMAGE VISION COMPUT, V54, P31, DOI 10.1016/j.imavis.2016.07.007
   Oreshkin BN, 2018, ADV NEUR IN, V31
   Paszke A, 2019, ADV NEUR IN, V32
   Peng QM, 2017, IEEE T SYST MAN CY-S, V47, P86, DOI 10.1109/TSMC.2016.2564922
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Ravi S., 2016, INT C LEARNING REPRE
   Romero A, 2013, P INT C COMP VIS COM, P10
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Santoro A., 2016, INT C MACH LEARN, P1842, DOI DOI 10.5555/3045390.3045585
   Schwartz Eli, 2019, CVPR
   Snell J, 2017, ADV NEUR IN, V30
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Tao A., 2020, Arxiv
   Touvron Hugo, 2020, ARXIV201212877
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wang YX, 2018, PROC CVPR IEEE, P7278, DOI 10.1109/CVPR.2018.00760
   Welinder P., 2010, Technical Report CNS-TR-2010-001
   Xie C, 2020, PROC CVPR IEEE, P816, DOI 10.1109/CVPR42600.2020.00090
   XING C, 2019, 33 C NEUR INF PROC S, P4848
   Zhang HG, 2019, PROC CVPR IEEE, P2765, DOI 10.1109/CVPR.2019.00288
   Zhang HG, 2019, IEEE WINT CONF APPL, P1185, DOI 10.1109/WACV.2019.00131
   Zhang J, 2018, PROC CVPR IEEE, P9029, DOI 10.1109/CVPR.2018.00941
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 56
TC 5
Z9 5
U1 0
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10491
EP 10508
DI 10.1007/s11042-020-09875-6
EA NOV 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000592153400001
DA 2024-07-18
ER

PT J
AU Huang, ZY
   Ling, BWK
AF Huang, Ziyin
   Ling, Bingo Wing-Kuen
TI Mathematical model for shape description in DCT domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mathematical model; Shape description; DCT domain
AB This paper derives a mathematical relationship between the shape information of an object and their discrete cosine transform (DCT) coefficients. Here, each column of the object is put into a matrix. As the lengths of different columns in the object are different, the lengths of the columns of the matrix are reset to the maximum value among these lengths of the columns of the object and the rest elements in the columns of the matrix are set to zero. The mathematical relationship between the shape information of the object and the DCT coefficients is derived. By substituting the DCT coefficients in the derived model, the shape of the object can be obtained directly in the DCT domain. Since most of the images are coded in the DCT domain, the derived result can significantly improve the efficiency for identifying the objects.
C1 [Huang, Ziyin; Ling, Bingo Wing-Kuen] Guangdong Univ Technol, Sch Informat Engn, Guangzhou Higher Educ Mega Ctr, 100 Waihuan Xi Rd, Guangzhou 510006, Guangdong, Peoples R China.
C3 Guangdong University of Technology
RP Ling, BWK (corresponding author), Guangdong Univ Technol, Sch Informat Engn, Guangzhou Higher Educ Mega Ctr, 100 Waihuan Xi Rd, Guangzhou 510006, Guangdong, Peoples R China.
EM shmillehzy@gmail.com; yongquanling@gdut.edu.cn
FU National Nature Science Foundation of China [U1701266, 61372173,
   61671163]; Team Project of the Education Ministry of the Guangdong
   Province [2017KCXTD011]; Guangdong Higher Education Engineering
   Technology Research Center for Big Data on Manufacturing Knowledge
   Patent [501130144]; Guangdong Province Intellectual Property Key
   Laboratory Project [2018B030322016]; Hong Kong Innovation and Technology
   Commission, Enterprise Support Scheme [S/E/070/17]
FX This paper was supported partly by the National Nature Science
   Foundation of China (no. U1701266, no. 61372173 and no. 61671163), the
   Team Project of the Education Ministry of the Guangdong Province (no.
   2017KCXTD011), the Guangdong Higher Education Engineering Technology
   Research Center for Big Data on Manufacturing Knowledge Patent (no.
   501130144), the Guangdong Province Intellectual Property Key Laboratory
   Project (no. 2018B030322016) and Hong Kong Innovation and Technology
   Commission, Enterprise Support Scheme (no. S/E/070/17).
CR Foi A, 2007, IEEE T IMAGE PROCESS, V16, P1395, DOI 10.1109/TIP.2007.891788
   Gonzalez R.C., 2000, Digital Image Processing, V2nd
   Guo HW, 2016, NEUROCOMPUTING, V204, P106, DOI 10.1016/j.neucom.2015.07.153
   Guobin Shen, 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P838, DOI 10.1109/ICIP.1999.823015
   NG WK, 2000, ACOUST SPEECH SIG PR, V4, P2115
   Pang CY, 2019, INFORM SCIENCES, V473, P121, DOI 10.1016/j.ins.2018.08.067
   PERSOON E, 1986, IEEE T PATTERN ANAL, V8, P388, DOI 10.1109/TPAMI.1986.4767799
   Shen GB, 2001, IEEE T CIRC SYST VID, V11, P67, DOI 10.1109/76.894284
   Tahir Md. Nooritawati, 2007, 2007 IEEE International Symposium on Signal Processing and Information Technology, P636
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
   Zhang DS, 2002, SIGNAL PROCESS-IMAGE, V17, P825, DOI 10.1016/S0923-5965(02)00084-X
   Zhang P, 2019, IEEE ACCESS, V7, P54712, DOI 10.1109/ACCESS.2019.2912976
   Zhu SY, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P193, DOI 10.1109/ICME.2008.4607404
NR 13
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10101
EP 10112
DI 10.1007/s11042-020-09463-8
EA NOV 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000590232700004
DA 2024-07-18
ER

PT J
AU Lbachir, IA
   Daoudi, I
   Tallal, S
AF Lbachir, Ilhame Ait
   Daoudi, Imane
   Tallal, Saadia
TI Automatic computer-aided diagnosis system for mass detection and
   classification in mammography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer-aided diagnosis; Mass detection; Mammography; Mass
   classification
ID SEGMENTATION
AB Mammography is currently the most powerful technique for early detection of breast cancer. To assist radiologists to better interpret mammogram images, computer-aided detection and diagnosis (CAD) systems have been proposed. This paper proposes a complete CAD system for mass detection and diagnosis, which consists of four steps. The first step consists of the preprocessing where the image is enhanced and the noise removed. In the second step, the abnormalities are segmented using the proposed HRAK algorithm. In the third step, the false positives are reduced using texture and shape features and the bagged trees classifier. Finally, the support vector machine (SVM) is used to classify the abnormalities as malignant or benign. The proposed CAD system is verified with both the MIAS and CBIS-DDSM databases. The experimental results proved to be successful. The accuracy detection rate achieves 93,15% for sensitivity and 0,467 FPPI for MIAS and 90,85% for sensitivity and 0,65 FPPI for CBIS-DDSM. The accuracy classification rate achieves 94,2% and the AUC 0,95 for MIAS and 90,44% and 0,9 for CBIS-DDSM.
C1 [Lbachir, Ilhame Ait; Daoudi, Imane; Tallal, Saadia] ENSEM Hassan II Univ, Engn Res Lab, BP 8118, Casablanca, Morocco.
RP Lbachir, IA (corresponding author), ENSEM Hassan II Univ, Engn Res Lab, BP 8118, Casablanca, Morocco.
EM ilhame.aitlbachir@ensem.ac.ma; im.daoudi@yahoo.fr; s.tallal@ensem.ac.ma
OI Ait Lbachir, Ilhame/0000-0002-7416-2972
CR Agrawal P, 2014, SIGNAL PROCESS, V99, P29, DOI 10.1016/j.sigpro.2013.12.010
   Ait Lbachir I, 2017, ADV UBIQUIT NETW, P2
   Al-antari MA, 2018, INT J MED INFORM, V117, P44, DOI 10.1016/j.ijmedinf.2018.06.003
   Anitha J, 2017, COMPUT METH PROG BIO, V138, P93, DOI 10.1016/j.cmpb.2016.10.026
   [Anonymous], 1995, IMAGE PROCESS LABOR
   Balleyguier C, 2007, EUR J RADIOL, V61, P192, DOI 10.1016/j.ejrad.2006.08.033
   Basheer NM, 2013, INT J RECENT TECHNOL, P2277
   Berber T, 2013, BREAST MASS CONTOUR
   Braz G, 2019, MULTIMED TOOLS APPL, V78, P13005, DOI 10.1007/s11042-018-6259-z
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Elmoufidi A, 2018, IET IMAGE PROCESS, V12, P320, DOI 10.1049/iet-ipr.2017.0536
   Fan D.-P., 2018, ARXIV 1805 10421
   Gaikwad VJ, 2015, DETECTION BREAST CAN
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hu K, 2011, IEEE T INSTRUM MEAS, V60, P462, DOI 10.1109/TIM.2010.2051060
   Jalalian A, 2017, EXCLI J
   Jasionowska M, 2019, ADV INTELL SYST, V1011, P199, DOI 10.1007/978-3-030-23762-2_18
   Kashyap KL, 2018, MULTIMED TOOLS APPL
   Kurt B, 2014, COMPUT METH PROG BIO, V114, P349, DOI 10.1016/j.cmpb.2014.02.014
   Lbachir IA, 2018, 9TH INTERNATIONAL SYMPOSIUM ON SIGNAL, IMAGE, VIDEO AND COMMUNICATIONS (ISIVC 2018), P16, DOI 10.1109/ISIVC.2018.8709241
   Lbachir IA, 2017, I C COMP SYST APPLIC, P166, DOI 10.1109/AICCSA.2017.40
   Lee RS, 2017, RES SCI DATA
   Lu YY, 2018, INTERVIROLOGY, V61, P111, DOI 10.1159/000493316
   Makandar A, 2016, J COMPUT, V11, P472, DOI 10.17706/jcp.11.6.472-478
   Neto OPS, 2017, MULTIMED TOOLS APPL, V76, P19263, DOI 10.1007/s11042-017-4710-1
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pezeshki H, 2019, MULTIMED TOOLS APPL, V78, P19979, DOI 10.1007/s11042-019-7185-4
   Ragab DA, 2019, PEERJ, V7, DOI 10.7717/peerj.6201
   Rajkumar KK, 2015, CURR J APPL SCI TECH, P378
   Ramani RG, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P66, DOI 10.1109/ICACCI.2013.6637148
   Rampun A, 2018, ENSEMBLE CONVOLUTION
   Rouhi R, 2016, EXPERT SYST APPL, V46, P45, DOI 10.1016/j.eswa.2015.10.011
   Saravanan M, 2017, INT J ADV TECHNOLOGY
   Sarosa SJA, 2018, PROCEEDINGS OF 2018 3RD INTERNATIONAL CONFERENCE ON SUSTAINABLE INFORMATION ENGINEERING AND TECHNOLOGY (SIET 2018), P54, DOI 10.1109/SIET.2018.8693146
   Sharma S, 2015, J DIGIT IMAGING, V28, P77, DOI 10.1007/s10278-014-9719-7
   Singh SP, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0454-0
   Soulami KB, 2019, MULTIMED TOOLS APPL, V78, P12835, DOI 10.1007/s11042-018-5934-4
   Suckling J, 1994, EXERPTA MEDICA INT C
   Tosteson ANA, 2014, JAMA INTERN MED, V174, P954, DOI 10.1001/jamainternmed.2014.981
   Vikhe PS, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0435-3
   Wang H, 2018, BREAST MASS DETECTIO
   Zhao J, 2019, PROCEEDINGS OF 2019 IEEE 8TH JOINT INTERNATIONAL INFORMATION TECHNOLOGY AND ARTIFICIAL INTELLIGENCE CONFERENCE (ITAIC 2019), P1875, DOI [10.1109/ITAIC.2019.8785506, 10.1109/itaic.2019.8785506]
   Zhou Z.-H., 2012, ENSEMBLE METHODS FDN, DOI DOI 10.1201/B12207
NR 43
TC 28
Z9 28
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9493
EP 9525
DI 10.1007/s11042-020-09991-3
EA NOV 2020
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000588614300003
DA 2024-07-18
ER

PT J
AU Latif, RAM
   Hussain, K
   Jhanjhi, NZ
   Nayyar, A
   Rizwan, O
AF Amir Latif, Rana M.
   Hussain, Khalid
   Jhanjhi, N. Z.
   Nayyar, Anand
   Rizwan, Osama
TI RETRACTED: A remix IDE: smart contract-based framework for the
   healthcare sector by using Blockchain technology (Retracted article. See
   SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Blockchain; Healthcare distributed ledger; Health information
   management; Patient data; Remix IDE
ID PATIENT-CENTERED CARE
AB Technology is continually evolving, and Blockchain development in recent years has shown tremendous adaptability. Blockchain's emphasis lies mainly in the finance sector, but some latent fields such as healthcare still grow and transform the future. In this paper, we introduced a smart contract-based framework for Blockchain-based healthcare system. According to our hypotheses, the proposed framework in the healthcare system will be changed by leveraging the principles and technologies of a public ledger, which will change the healthcare industry's vision based on Blockchain. Health records, laboratory evaluation results, doctoral perceptions, and precise information about health care can be decentralized in the form of blocks in the form of transactions. These blocks can be linked in Blockchain as distributed ledgers according to the series of events. It can eliminate a highly complex process and manual intervention. Through adding an Identity Manager, fully open and secure applications can be based on Blockchain technologies. Based on the expected outcomes, we are optimistic that the proposed Blockchain-based framework will be helpful in the healthcare context; to evaluate the maturity level of our proposed framework we map the framework on Ethereum-based application and evaluated in the hospital setting, for the evaluation of the proposed framework. At the initial stage, we are confident that the proposed framework will be helpful in the hospital environment and contribute to enhancing the performance of the healthcare environment.
C1 [Amir Latif, Rana M.; Rizwan, Osama] COMSATS Univ Islamabad, Dept Comp Sci, Sahiwal Campus, Sahiwal, Pakistan.
   [Hussain, Khalid] ARID Agr Univ Rawalpindi, Barani Inst Sci, Sahiwal Campus, Rawalpindi, Pakistan.
   [Jhanjhi, N. Z.] Taylors Univ, Sch Comp Sci & Engn SCE, Subang, Jaya, Malaysia.
   [Nayyar, Anand] Duy Tan Univ, Grad Sch, Fac Informat Technol, Da Nang 550000, Vietnam.
C3 COMSATS University Islamabad (CUI); Arid Agriculture University;
   Taylor's University; Duy Tan University
RP Jhanjhi, NZ (corresponding author), Taylors Univ, Sch Comp Sci & Engn SCE, Subang, Jaya, Malaysia.
EM ranaamir10611@gmail.com; kusmani.utm@gmail.com;
   noorzaman.jhanjhi@taylors.edu.my; anandnayyar@duytan.edu.vn;
   rizwan.osama.official@gmail.com
RI Jhanjhi, Prof Dr Noor Zaman/F-3051-2011; HUSSAIN, KHALID/HGD-3806-2022
OI Jhanjhi, Prof Dr Noor Zaman/0000-0001-8116-4733; Hussain,
   Khalid/0000-0002-3714-8696
CR Abeyratne S. A., 2016, INT J RES ENG TECHNO, V5, P1, DOI [10.15623/ijret.2016.0509001, DOI 10.15623/IJRET.2016.0509001]
   Agbo CC, 2019, HEALTHCARE-BASEL, V7, DOI 10.3390/healthcare7020056
   Allen M., 2016, Juristat. Statistics Canada catalogue
   [Anonymous], 2020, BITC VAL USD LAST YE
   [Anonymous], 2020, BITCOIN HASH RATE PE
   Arsenijevic J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157765
   Arundel A, 2013, ELGAR ORIG REF, P60
   Augenstein I, 2017, ARXIV170402853V3
   Barsh J., 2011, Unlocking the full potential of women in the U.S. economy
   Bernstein DJ, 2017, NATURE, V549, P188, DOI 10.1038/nature23461
   Casino F, 2019, TELEMAT INFORM, V36, P55, DOI 10.1016/j.tele.2018.11.006
   Chen Y, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1121-4
   Dagher GG, 2018, SUSTAIN CITIES SOC, V39, P283, DOI 10.1016/j.scs.2018.02.014
   di Angelo M, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON DECENTRALIZED APPLICATIONS AND INFRASTRUCTURES (DAPPCON), P69, DOI 10.1109/DAPPCON.2019.00018
   Di Pierro M, 2017, COMPUT SCI ENG, V19, P92, DOI 10.1109/MCSE.2017.3421554
   Doocy S, 2016, CONFL HEALTH, V10, DOI 10.1186/s13031-016-0088-3
   Dubovitskaya Alevtina, 2017, AMIA Annu Symp Proc, V2017, P650
   Durneva P, 2020, J MED INTERNET RES, V22, DOI 10.2196/18619
   Enaizan O, 2020, HEALTH TECHNOL-GER, V10, P795, DOI 10.1007/s12553-018-0278-7
   Engelhardt MA, 2017, TECHNOL INNOV MANAG, V7, P22, DOI 10.22215/timreview/1111
   Omolara AE, 2020, HEALTH INFORM J, V26, P2083, DOI 10.1177/1460458219894479
   Eyal I, 2016, 13TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI '16), P45
   Glymour MM., 2014, SOCIAL EPIDEMIOLOGY, V2, P17, DOI DOI 10.1093/MED/9780195377903.003.0002
   Alonso SG, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1195-7
   Guang Chen, 2018, Smart Learning Environments, V5, DOI 10.1186/s40561-017-0050-x
   Hofmann F, 2017, 2017 ITU KALEIDOSCOPE: CHALLENGES FOR A DATA-DRIVEN SOCIETY (ITU K)
   Hölbl M, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10100470
   Humayun Mamoona, 2020, IEEE Internet of Things Magazine, V3, P58, DOI 10.1109/IOTM.0001.1900097
   Hussien HM, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1445-8
   Kelsey T, 2014, PERSONALISED HLTH CA, P1
   Khan F, 2020, INF SCI LETT, V8, P67, DOI [10.18576/isl/080204, DOI 10.18576/ISL/080204]
   Kitson A, 2013, J ADV NURS, V69, P4, DOI 10.1111/j.1365-2648.2012.06064.x
   Koshy P, 2014, LECT NOTES COMPUT SC, V8437, P469, DOI 10.1007/978-3-662-45472-5_30
   Kossoy A., 2015, State and Trends of Carbon Pricing 2015, DOI [10.1596/ 978-1-4648-0725-1, DOI 10.1596/978-1-4648-0725-1]
   Kuri S., 2017, 2017 IEEE Symposium Series on Computational Intelligence (SSCI), P1
   Latif RMA, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON COMMUNICATION, COMPUTING AND DIGITAL SYSTEMS (C-CODE), P264, DOI [10.1109/C-CODE.2019.8681027, 10.1109/c-code.2019.8681027]
   Liu B, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS 2017), P468, DOI 10.1109/ICWS.2017.54
   Lopez-Pintado O, 2017, CATERPILLAR BLOCKCHA
   Mackey TK, 2019, BMC MED, V17, DOI 10.1186/s12916-019-1296-7
   Malak A, INT J COMPUT SCI NET, V19, P244
   McGhin T, 2019, J NETW COMPUT APPL, V135, P62, DOI 10.1016/j.jnca.2019.02.027
   N. C. f. H. Statistics, 2014, HLTH US 2013 SPEC FE
   Nagasubramanian G, 2020, NEURAL COMPUT APPL, V32, P639, DOI 10.1007/s00521-018-3915-1
   Pebody RG, 2015, EUROSURVEILLANCE, V20, P6, DOI [10.2807/1560-7917.ES.2015.20.36.30013, 10.2807/1560-7917.ES2015.20.5.21025]
   Peters GW, 2016, NEW ECON WINDOWS, P239, DOI 10.1007/978-3-319-42448-4_13
   Piotrowski SJ, 2017, J PUBL ADM RES THEOR, V27, P710, DOI 10.1093/jopart/mux010
   Rathee G, 2019, AD HOC NETW, V94, DOI 10.1016/j.adhoc.2019.101933
   Saghiri AM, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON WEB RESEARCH (ICWR), P138, DOI 10.1109/ICWR.2018.8387250
   Saha A, 2019, SECUR PRIVACY, V2, DOI 10.1002/spy2.83
   Shen ZR, 2019, HEALTHINF: PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES - VOL 5: HEALTHINF, P294, DOI 10.5220/0007378702940301
   Sikorski JJ, 2017, APPL ENERG, V195, P234, DOI 10.1016/j.apenergy.2017.03.039
   Siyal AA, 2019, CRYPTOGRAPHY-BASEL, V3, DOI 10.3390/cryptography3010003
   Stewart M, 2001, BRIT MED J, V322, P444, DOI 10.1136/bmj.322.7284.444
   Suberg W, 2017, CROSS CRYPTO MARKET
   Taskinsoy J, 2019, BLOCKCHAIN MOVING BI, DOI [10.2139/ssrn.3471413, DOI 10.2139/SSRN.3471413]
   Tieu L, 2017, J AM MED INFORM ASSN, V24, pE47, DOI 10.1093/jamia/ocw098
   Underwood S, 2016, COMMUN ACM, V59, P15, DOI 10.1145/2994581
   Viotti P, 2016, PROCEEDINGS OF THE 2ND WORKSHOP ON THE PRINCIPLES AND PRACTICE OF CONSISTENCY FOR DISTRIBUTED DATA, PAPOC 2016, DOI 10.1145/2911151.2911162
   Viriyasitavat W, 2020, J INTELL MANUF, V31, P1737, DOI 10.1007/s10845-018-1422-y
   Vora J, 2018, IEEE GLOBE WORK
   Wong MC, 2018, STUD HEALTH TECHNOL, V247, P636, DOI 10.3233/978-1-61499-852-5-636
   Yaeger K., 2019, Journal of Scientific Innovation in Medicine, V2, P1, DOI DOI 10.29024/jsim.7
   Yohan A, 2018, 2018 IEEE CONFERENCE ON DEPENDABLE AND SECURE COMPUTING (DSC), P22
   Yue X, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0574-6
   Zyskind G, 2015, 2015 IEEE SECURITY AND PRIVACY WORKSHOPS (SPW), P180, DOI 10.1109/SPW.2015.27
NR 65
TC 33
Z9 33
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 26609
EP 26632
DI 10.1007/s11042-020-10087-1
EA NOV 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000588276000002
DA 2024-07-18
ER

PT J
AU Ghamsarian, N
   Schoeffmann, K
   Khademi, M
AF Ghamsarian, Negin
   Schoeffmann, Klaus
   Khademi, Morteza
TI Blind MV-based video steganalysis based on joint inter-frame and
   intra-frame statistics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind steganalysis; Video steganography; Information security; Motion
   vector; Video compression; H264; AVC
ID STEGANOGRAPHY ALGORITHM; MOTION
AB Despite all its irrefutable benefits, the development of steganography methods has sparked ever-increasing concerns over steganography abuse in recent decades. To prevent the inimical usage of steganography, steganalysis approaches have been introduced. Since motion vector manipulation leads to random and indirect changes in the statistics of videos, MV-based video steganography has been the center of attention in recent years. In this paper, we propose a 54-dimentional feature set exploiting spatio-temporal features of motion vectors to blindly detect MV-based stego videos. The idea behind the proposed features originates from two facts. First, there are strong dependencies among neighboring MVs due to utilizing rate-distortion optimization techniques and belonging to the same rigid object or static background. Accordingly, MV manipulation can leave important clues on the differences between each MV and the MVs belonging to the neighboring blocks. Second, a majority of MVs in original videos are locally optimal after decoding concerning the Lagrangian multiplier, notwithstanding the information loss during compression. Motion vector alteration during information embedding can affect these statistics that can be utilized for steganalysis. Experimental results have shown that our features' performance far exceeds that of state-of-the-art steganalysis methods. This outstanding performance lies in the utilization of complementary spatio-temporal statistics affected by MV manipulation as well as feature dimensionality reduction applied to prevent overfitting. Moreover, unlike other existing MV-based steganalysis methods, our proposed features can be adjusted to various settings of the state-of-the-art video codec standards such as sub-pixel motion estimation and variable-block-size motion estimation.
C1 [Ghamsarian, Negin; Schoeffmann, Klaus] Klagenfurt Univ, Inst Informat Technol, Klagenfurt, Austria.
   [Ghamsarian, Negin; Khademi, Morteza] Ferdowsi Univ Mashhad, Dept Elect Engn, Mashhad, Razavi Khorasan, Iran.
C3 University of Klagenfurt; Ferdowsi University Mashhad
RP Schoeffmann, K (corresponding author), Klagenfurt Univ, Inst Informat Technol, Klagenfurt, Austria.
EM negin@itec.aau.at; ks@itec.aau.at; khademi@um.ac.ir
RI Ghamsarian, Negin/AFS-1341-2022
OI Ghamsarian, Negin/0000-0002-0908-8972
FU University of Klagenfurt
FX Open access funding provided by University of Klagenfurt.
CR Aly HA, 2011, IEEE T INF FOREN SEC, V6, P14, DOI 10.1109/TIFS.2010.2090520
   [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   Böhme R, 2010, ADVANCED STATISTICAL STEGANALYSIS, P11
   Bohme R., 2010, INFORM SECURITY CRYP, Vfirst
   Cao Y., 2015, P 3 ACM WORKSH INF H, P25, DOI DOI 10.1145/2756601.2756609
   Cao Y, 2012, VIDEO STEGANALYSIS E, V19, P35, DOI DOI 10.1109/LSP.2011.2176116
   Cao Y, 2015, IEEE COMMUN LETT, V19, P203, DOI 10.1109/LCOMM.2014.2387160
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02066-z
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Cox Ingemar, 2008, DIGITAL WATERMARKING, V2
   Dalal Mukesh, 2018, Proceedings of the International Conference on Computing and Communication Systems. I3CS 2016. Lecture Notes in Networks and Systems (LNNS 24), P705, DOI 10.1007/978-981-10-6890-4_67
   Fang DY, 2006, DATA HIDING DIGITAL
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Feng Pan, 2010, 2010 IEEE International Conference on Software Engineering and Service Sciences (ICSESS 2010), P592, DOI 10.1109/ICSESS.2010.5552283
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J, 2005, IEEE T SIGNAL PROCES, V53, P3923, DOI 10.1109/TSP.2005.855393
   Fridrich J, 1999, ONLINE
   Fridrich J., 2004, MMSEC 04, P4
   Fridrich J, 2001, STEGANALYSIS BASED J, V4518, P11
   Ghamsarian N, 2020, MULTIMED TOOLS APPL, V79, P18909, DOI 10.1007/s11042-020-08617-y
   Ghasemzadeh H, 2017, ARXIV171001230
   Hu Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1231
   Idbeaa TF, 2015, PROC INT CONF ADV, P50, DOI 10.1109/ATC.2015.7388379
   Kapotas SK, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P277, DOI 10.1109/ICME.2008.4607425
   Ker A.D., 2013, P 1 ACM WORKSH INF H, P4558, DOI DOI 10.1145/2482513.2482965
   Kodovsky J, 2013, PROC SPIE, V8665, DOI 10.1117/12.2001563
   Kok Sheik Wong, 2009, IEEE Transactions on Circuits and Systems for Video Technology, V19, P1499, DOI 10.1109/TCSVT.2009.2022781
   Li Y, 2010, INT CONF SIGN PROCES, P1833, DOI 10.1109/ICOSP.2010.5656918
   Liao K, 2012, TELECOMMUN SYST, V49, P261, DOI 10.1007/s11235-010-9372-5
   Liu B, 2008, ARES 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON AVAILABILITY, SECURITY AND RELIABILITY, P1382, DOI 10.1109/ARES.2008.140
   Mstafa R.J., 2015, IEEE Long Island Systems, Applications and Technology Conference (LISAT), P1, DOI 10.1109/LISAT.2015.7160192
   Neufeld A, 2013, PROC SPIE, V8665, DOI 10.1117/12.2003680
   Pevny T, 2012, IEEE T INF FOREN SEC, V7, P445, DOI 10.1109/TIFS.2011.2175918
   Rana S, 2018, ADV INTELL SYST, V624, P719, DOI 10.1007/978-981-10-5903-2_74
   Rout N, 2018, ADV INTELL SYST, V628, P431, DOI 10.1007/978-981-10-5272-9_39
   Sadat ES, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040244
   Schöffmann K, 2007, LECT NOTES COMPUT SC, V4641, P782
   Shanableh T, 2012, IEEE T INF FOREN SEC, V7, P455, DOI 10.1109/TIFS.2011.2177087
   ShengDun Hu, 2011, Proceedings of the 2011 IEEE 14th International Conference on Computational Science and Engineering (CSE 2011). 11th International Symposium on Pervasive Systems, Algorithms, Networks (I-SPAN 2011). 10th IEEE International Conference on Ubiquitous Computing and Communications (IUCC 2011), P57, DOI 10.1109/CSE.2011.24
   Su YT, 2011, SIGNAL PROCESS, V91, P1901, DOI 10.1016/j.sigpro.2011.02.012
   Tasdemir K, 2016, IEEE T IMAGE PROCESS, V25, P3316, DOI 10.1109/TIP.2016.2567073
   Wang CP, 2017, MULTIMED TOOLS APPL, V76, P26355, DOI 10.1007/s11042-016-4130-7
   Wang CP, 2016, J VIS COMMUN IMAGE R, V41, P247, DOI 10.1016/j.jvcir.2016.10.004
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang CP, 2017, SIGNAL PROCESS, V134, P197, DOI 10.1016/j.sigpro.2016.12.010
   Wang KR, 2014, IEEE T INF FOREN SEC, V9, P741, DOI 10.1109/TIFS.2014.2308633
   Wilcox RR., 2012, STAT MODELING DECISI, V3
   Wu HT, 2014, IEEE IMAGE PROC, P5512, DOI 10.1109/ICIP.2014.7026115
   Xia ZQ, 2019, SIGNAL PROCESS, V164, P368, DOI 10.1016/j.sigpro.2019.06.025
   Xia ZQ, 2019, SIGNAL PROCESS, V157, P108, DOI 10.1016/j.sigpro.2018.11.011
   Yang GB, 2011, AEU-INT J ELECTRON C, V65, P331, DOI 10.1016/j.aeue.2010.03.011
   Yao YZ, 2015, MULTIMED TOOLS APPL, V74, P11163, DOI 10.1007/s11042-014-2223-8
   Yun Cao, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P193, DOI 10.1007/978-3-642-24178-9_14
   Zhang H., 2014, P 2 ACM WORKSH INF H, P115
   Zhang H, 2017, IEEE T INF FOREN SEC, V12, P465, DOI 10.1109/TIFS.2016.2623587
   Zhang H, 2016, MULTIMED TOOLS APPL, V75, P13503, DOI 10.1007/s11042-015-2743-x
   Zhang MS, 2014, C IND ELECT APPL, P940, DOI 10.1109/ICIEA.2014.6931298
   Zhang YN, 2017, TSINGHUA SCI TECHNOL, V22, P198
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
NR 61
TC 9
Z9 9
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9137
EP 9159
DI 10.1007/s11042-020-10001-9
EA NOV 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587660400003
OA hybrid
DA 2024-07-18
ER

PT J
AU Seo, SB
   Yadav, P
   Singh, D
AF Seo, Seung Byum
   Yadav, Pamul
   Singh, Dhananjay
TI LoRa based architecture for smart town traffic management system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic management; Smart town; LPWAN; LoRa; Machine learning; Logistic
   regression; Cross-layer architecture
AB While traffic congestion has been pointed out as everyday driving stress, few attempts are specialized in traffic management by using current IoT technology. In order to help alleviate traffic stress from drivers, this article proposes a cross-layer LoRa architecture and a machine-learning algorithm for smart town's traffic management systems. LoRa is selected since it has strengths in range and power when compared to other wireless communication technologies. We introduce the cross-layer LoRa architecture, which is devised to facilitate its cognitive analysis. By dynamically allocating network and information resources, it complements the limitations of the standard LoRa protocol. We also have designed the logistic regression algorithm-which runs above its cognitive engine. The proposed algorithm outputs traffic coefficients based on density and travel time. This algorithm has achieved 97% of accuracy in the simulation. With further research, we believe the proposed system could be an excellent solution for smart traffic management.
C1 [Seo, Seung Byum; Singh, Dhananjay] Hankuk Univ Foreign Studies, ReSENSE Lab, Dept Elect Engn, Global Campus, Seoul, South Korea.
   [Yadav, Pamul] Ulsan Natl Inst Sci & Technol, Dept Comp Sci & Engn, Ulsan, South Korea.
C3 Hankuk University Foreign Studies; Ulsan National Institute of Science &
   Technology (UNIST)
RP Singh, D (corresponding author), Hankuk Univ Foreign Studies, ReSENSE Lab, Dept Elect Engn, Global Campus, Seoul, South Korea.
EM dsingh@hufs.ac.kr
RI Singh, Dhananjay/ABA-9824-2020; Yadav, Pamul/GQI-1933-2022
OI Singh, Dhananjay/0000-0003-3822-9348; Yadav, Pamul/0000-0002-6559-882X;
   Seo, Seung Byum/0000-0003-3413-6793
FU Hankuk University of Foreign Studies research fund; VESTELLA
FX This research work was supported by VESTELLA and Hankuk University of
   Foreign Studies research fund.
CR Ali SSM, 2012, IEEE T INSTRUM MEAS, V61, P1353, DOI 10.1109/TIM.2011.2175037
   Bingöl E, 2019, 2019 7TH INTERNATIONAL ISTANBUL SMART GRIDS AND CITIES CONGRESS AND FAIR (ICSG ISTANBUL 2019), P66, DOI 10.1109/SGCF.2019.8782413
   Boon MAA, 2012, PROBAB ENG INFORM SC, V26, P337, DOI 10.1017/S0269964812000058
   Cunningham J. A., 2020, INTERNET THINGS ENTR, P121
   Ding W, GLOBECOM 01 IEEE GLO
   Frank SL, 2015, BRAIN LANG, V140, P1, DOI 10.1016/j.bandl.2014.10.006
   Han JK, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822555
   Haxhibeqiri J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113995
   Hennessy DA, 1999, AGGRESSIVE BEHAV, V25, P409, DOI 10.1002/(SICI)1098-2337(1999)25:6<409::AID-AB2>3.0.CO;2-0
   Hobbs F, 1979, TRAFFIC PLANNING ENG, P332
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Jiang Y, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1542-x
   Liepins M, 2013, 2013 21ST TELECOMMUNICATIONS FORUM (TELFOR), P601, DOI 10.1109/TELFOR.2013.6716302
   Lingani GM, 2019, 2019 IEEE 9TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P101, DOI [10.1109/CCWC.2019.8666539, 10.1109/ccwc.2019.8666539]
   Ma WT, 2014, IEEE T INTELL TRANSP, V15, P104, DOI 10.1109/TITS.2013.2273488
   McKinney W., 2010, P 9 PYTHON SCI C, P51, DOI DOI 10.25080/MAJORA-92BF1922-00A
   Nair KK, 2019, 2019 CONFERENCE ON INFORMATION COMMUNICATIONS TECHNOLOGY AND SOCIETY (ICTAS), DOI 10.1109/ictas.2019.8703630
   Pérez F, 2007, COMPUT SCI ENG, V9, P21, DOI 10.1109/MCSE.2007.53
   Qu CH, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3148149
   Seneviratne C, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020567
   Silva JD, 2017, 2017 2ND INTERNATIONAL MULTIDISCIPLINARY CONFERENCE ON COMPUTER AND ENERGY SCIENCE (SPLITECH), P143
   Trevor H., 2009, The Elements of Statistical Learning: Data Mining, Inference, and Prediction
   Wen-Yu C, 2007, IET C WIR MOB SENS N
   Workgroup TM, 2015, LORAWAN101
   Yaqoob I, 2017, IEEE WIREL COMMUN, V24, P10, DOI 10.1109/MWC.2017.1600421
NR 25
TC 5
Z9 5
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 26593
EP 26608
DI 10.1007/s11042-020-10091-5
EA NOV 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000587279700006
DA 2024-07-18
ER

PT J
AU Hu, J
   Yan, CG
   Liu, X
   Li, ZY
   Ren, CW
   Zhang, JY
   Peng, DL
   Yang, Y
AF Hu, Ji
   Yan, Chenggang
   Liu, Xin
   Li, Zhiyuan
   Ren, Chengwei
   Zhang, Jiyong
   Peng, Dongliang
   Yang, Yi
TI An integrated classification model for incremental learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Incremental learning; Transfer learning; Confidence weight; Image
   classification; Masked-face dataset
ID ONLINE; PERCEPTRON
AB Incremental Learning is a particular form of machine learning that enables a model to be modified incrementally, when new data becomes available. In this way, the model can adapt to the new data without the lengthy and time-consuming process required for complete model re-training. However, existing incremental learning methods face two significant problems: 1) noise in the classification sample data, 2) poor accuracy of modern classification algorithms when applied to modern classification problems. In order to deal with these issues, this paper proposes an integrated classification model, known as a Pre-trained Truncated Gradient Confidence-weighted (Pt-TGCW) model. Since the pre-trained model can extract and transform image information into a feature vector, the integrated model also shows its advantages in the field of image classification. Experimental results on ten datasets demonstrate that the proposed method outperform the original counterparts.
C1 [Hu, Ji; Yan, Chenggang; Liu, Xin; Li, Zhiyuan; Ren, Chengwei; Zhang, Jiyong; Peng, Dongliang] HangZhou DianZi Univ, Hangzhou, Zhejiang, Peoples R China.
   [Yang, Yi] Univ Technol Sydney, Ctr Artificial Intelligence, Ultimo, Australia.
C3 Hangzhou Dianzi University; University of Technology Sydney
RP Hu, J (corresponding author), HangZhou DianZi Univ, Hangzhou, Zhejiang, Peoples R China.
EM huji@hdu.edu.cn
RI yang, yang/GVT-5210-2022; Yang, Yi/B-9273-2017; Lang,
   Ming/HIK-0758-2022; yang, yang/HGT-7999-2022; li, zhiyuan/HGD-9581-2022;
   yang, yang/GWB-9426-2022
OI Yang, Yi/0000-0002-0512-880X; 
CR [Anonymous], 1999, P WORKSH SUPP VECT M
   Beichen Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8753, DOI 10.1109/CVPR42600.2020.00878
   BenDavid S, 1997, MACH LEARN, V29, P45, DOI 10.1023/A:1007465907571
   Bottou L., 2012, Neural networks: Tricks of the trade, P421, DOI DOI 10.1007/978-3-642-35289-8_25
   Crammer K, 2006, J MACH LEARN RES, V7, P551
   Crammer K., 2009, Empirical Methods in Natural Language Proc, P496
   Crammer K, 2013, MACH LEARN, V91, P155, DOI 10.1007/s10994-013-5327-x
   Dredze M., 2008, Machine Learning, Proceedings of the Twenty-Fifth International Conference (ICML 2008), Helsinki, Finland, June 5-9, 2008, ACM International Conference Proceeding Series, V307, P264, DOI DOI 10.1145/1390156.1390190
   Duchi J, 2009, J MACH LEARN RES, V10, P2899
   Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062
   Giraud-Carrier C, 2000, AI COMMUN, V13, P215
   Hu J, 2019, IEEE INT CON MULTI, P133, DOI [10.1109/ICME.2019.00031, 10.1109/ICME2019.00031]
   Kivinen J, 2004, IEEE T SIGNAL PROCES, V52, P2165, DOI 10.1109/TSP.2004.830991
   Langford J, 2009, J MACH LEARN RES, V10, P777
   Orabona F., 2010, Proc. Adv. Neural Inf. Process. Syst, P1840
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shalev-Shwartz S, 2012, FOUND TRENDS MACH LE, V4, P107, DOI 10.1561/2200000018
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang JL, 2016, ACM T INTEL SYST TEC, V8, DOI 10.1145/2932193
   Wang JL, 2014, IEEE T KNOWL DATA EN, V26, P2425, DOI 10.1109/TKDE.2013.157
   Xie HT, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3231737
   Xie HT, 2019, PATTERN RECOGN, V85, P109, DOI 10.1016/j.patcog.2018.07.031
   Yang L, 2009, INT C MACH LEARN
   Yosinski J, 2014, ADV NEUR IN, V27
NR 25
TC 6
Z9 7
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17275
EP 17290
DI 10.1007/s11042-020-10070-w
EA OCT 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000581952100003
PM 33106746
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Ali, W
   Tian, WH
   Din, SU
   Iradukunda, D
   Khan, AA
AF Ali, Waqar
   Tian, Wenhong
   Din, Salah Ud
   Iradukunda, Desire
   Khan, Abdullah Aman
TI Classical and modern face recognition approaches: a complete review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Face recognition; Face identification; Artificial intelligence; Computer
   vision; Machine learning; Visual surveillance
ID FACIAL EXPRESSION RECOGNITION; CONVOLUTIONAL NEURAL-NETWORK; HUMAN AGE
   ESTIMATION; SPARSE-REPRESENTATION; OBJECT RECOGNITION; SOFT BIOMETRICS;
   ILLUMINATION NORMALIZATION; GENDER CLASSIFICATION; FEATURE-EXTRACTION;
   LEVEL FUSION
AB Human face recognition have been an active research area for the last few decades. Especially, during the last five years, it has gained significant research attention from multiple domains like computer vision, machine learning and artificial intelligence due to its remarkable progress and broad social applications. The primary goal of any face recognition system is to recognize the human identity from the static images, video data, data-streams and the knowledge of the context in which these data components are being actively used. In this review, we have highlighted major applications, challenges and trends of face recognition systems in social and scientific domains. The prime objective of this research is to sum-up recent face recognition techniques and develop a broad understanding of how these techniques behave on different datasets. Moreover, we discuss some key challenges such as variability in illumination, pose, aging, cosmetics, scale, occlusion, and background. Along with classical face recognition techniques, most recent research directions are deeply investigated, i.e., deep learning, sparse models and fuzzy set theory. Additionally, basic methodologies are briefly discussed, while contemporary research contributions are examined in broader details. Finally, this research presents future aspects of face recognition technologies and its potential significance in the upcoming digital society.
C1 [Ali, Waqar; Khan, Abdullah Aman] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.
   [Ali, Waqar] Univ Lahore, Fac Informat Technol, Lahore 54000, Pakistan.
   [Tian, Wenhong] Univ Elect Sci & Technol China, Sch Informat & Software Engn, Chengdu 611731, Peoples R China.
   [Din, Salah Ud] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Data Min Lab, Chengdu 611731, Peoples R China.
   [Iradukunda, Desire] Univ Elect Sci & Technol China, Sch Elect Sci & Engn, Chengdu 611731, Peoples R China.
C3 University of Electronic Science & Technology of China; University of
   Lahore; University of Electronic Science & Technology of China;
   University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China
RP Ali, W (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.; Ali, W (corresponding author), Univ Lahore, Fac Informat Technol, Lahore 54000, Pakistan.
EM sirwaqar_it@yahoo.com
RI Din, Salah Ud/KHU-6469-2024; Ali, Waqar/HJJ-0226-2023; Khan, Abdullah
   Aman/ACI-8034-2022
OI Din, Salah Ud/0000-0002-4145-7176; Ali, Waqar/0000-0003-0846-7281; Khan,
   Abdullah Aman/0000-0001-9048-5352
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   Abbe E, 2018, ARXIV181206369 CORR
   Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229
   Afifi M, 2019, J VIS COMMUN IMAGE R, V62, P77, DOI 10.1016/j.jvcir.2019.05.001
   Aghamaleki JA, 2019, MULTIMED TOOLS APPL, V78, P22861, DOI 10.1007/s11042-019-7530-7
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Akram MU, 2014, INT CONF IMAG PROC, P289
   Al-Shannaq AS, 2019, IEEE ACCESS, V7, P93229, DOI 10.1109/ACCESS.2019.2927825
   Al-Wajih E, 2020, INT ARAB J INF TECHN, V17, P178, DOI 10.34028/iajit/17/2/5
   Ali Waqar, 2019, [电子科技大学学报, Journal of University of Electronic Science and Technology of China], V48, P655
   Almudhahka NY, 2018, COMP FACE SOFT BIOME, P25
   An L, 2017, MULTIMED TOOLS APPL, V76, P12117, DOI 10.1007/s11042-016-4070-2
   Andreopoulos A, 2013, COMPUT VIS IMAGE UND, V117, P827, DOI 10.1016/j.cviu.2013.04.005
   Annamalai P., 2018, INT J NETWORK SECURI, V20, P423
   [Anonymous], 1973, PICTURE PROCESSING S
   [Anonymous], 1999, Subspace Linear Discriminant Analysis for Face Recognition
   [Anonymous], 2016, Face Recognition cross the Imaging Spectrum
   [Anonymous], 2017, 2017 IEEE International Conference on Identity, Security and Behavior Analysis (ISBA)
   [Anonymous], 2018, ARXIV180309014
   [Anonymous], 2002, P IEEE COMP SOC C CO, DOI [DOI 10.1109/CVPR.1997.609310, 10.1109/CVPR.1997.609310]
   Arashloo SR, 2016, IET COMPUT VIS, V10, P466, DOI 10.1049/iet-cvi.2015.0222
   Arigbabu OA, 2015, VISUAL COMPUT, V31, P513, DOI 10.1007/s00371-014-0990-x
   Azeem A, 2014, INT ARAB J INF TECHN, V11, P1
   Bailly-Bailliére E, 2003, LECT NOTES COMPUT SC, V2688, P625
   Bair S, 2019, PROCEEDINGS OF THE 2019 ACM WORKSHOP ON WIRELESS SECURITY AND MACHINE LEARNING (WISEML '19), P25, DOI 10.1145/3324921.3328785
   Baocai Yin., 2009, J COMPUTER RES DEV, V6, P020
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Bashbaghi S, 2018, ARXIV180209990 CORR
   Becerra-Riera F, 2019, ARTIF INTELL REV, V52, P1155, DOI 10.1007/s10462-019-09689-5
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Benamara NK, 2018, IFIP ADV INF COMM TE, V522, P549, DOI 10.1007/978-3-319-89743-1_47
   Benavente R, 1998, 24 COMP VIS CTR
   Beveridge J. R., 2013, 2013 IEEE Sixth International Conference on Biometrics: Theory, Applications and Systems (BTAS), P1
   Beveridge JR, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   BSAT M., 2001, CMURITR0102
   Byoung-Moo Kwon, 2018, International Journal of Information Technology and Management, V17, P33
   Calo SB, 2018, US Patent app, Patent No. [15/876,307, 15876307]
   Campomanes-Alvarez C, 2017, FUZZY SET SYST, V318, P100, DOI 10.1016/j.fss.2016.06.015
   Chatzis V, 1999, IEEE T SYST MAN CY A, V29, P674, DOI 10.1109/3468.798073
   Chen BC, 2014, LECT NOTES COMPUT SC, V8694, P768, DOI 10.1007/978-3-319-10599-4_49
   Chen GY, 2019, MULTIMED TOOLS APPL, V78, P26615, DOI 10.1007/s11042-019-07810-y
   Chen JL, 2017, IEEE IMAGE PROC, P1602, DOI 10.1109/ICIP.2017.8296552
   Chen JC, 2018, INT J COMPUT VISION, V126, P272, DOI 10.1007/s11263-017-1029-3
   Chen YC, 2012, LECT NOTES COMPUT SC, V7577, P766, DOI 10.1007/978-3-642-33783-3_55
   Cheng H, 2015, ADV COMPUTER VISION
   Chihaoui M, 2016, COMPUTERS, V5, DOI 10.3390/computers5040021
   Choi SI, 2012, PATTERN RECOGN LETT, V33, P1083, DOI 10.1016/j.patrec.2012.01.005
   Chugh T, 2017, IEEE COMPUT SOC CONF, P619, DOI 10.1109/CVPRW.2017.90
   Conde C, 2006, IEEE IMAGE PROC, P2061, DOI 10.1109/ICIP.2006.312863
   Cox IJ, 1996, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.1996.517076
   Cunningham JP, 2015, J MACH LEARN RES, V16, P2859
   Dagnes N, 2018, MACH VISION APPL, V29, P789, DOI 10.1007/s00138-018-0933-z
   Danelakis A, 2015, MULTIMED TOOLS APPL, V74, P5577, DOI 10.1007/s11042-014-1869-6
   Dantcheva A, 2016, IEEE T INF FOREN SEC, V11, P441, DOI 10.1109/TIFS.2015.2480381
   Dantcheva A, 2011, MULTIMED TOOLS APPL, V51, P739, DOI 10.1007/s11042-010-0635-7
   De Carrera PF, 2010, THESIS
   de Souza GB, 2017, P 22 IB C PROGR PATT, P643
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Ding CX, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2845089
   Du YJ, 2018, INTELL DATA ANAL, V22, P675, DOI 10.3233/IDA-173365
   Edwards G. J., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P581, DOI 10.1007/BFb0054766
   Efremova N, 2019, IEEE INT CONF AUTOMA, P616, DOI 10.1109/fg.2019.8756562
   Elad M, 2012, IEEE SIGNAL PROC LET, V19, P922, DOI 10.1109/LSP.2012.2224655
   Elag MM, 2017, ENVIRON MODELL SOFTW, V94, P100, DOI 10.1016/j.envsoft.2017.03.032
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   Feltwell T, 2017, DIS'17 COMPANION: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P44, DOI 10.1145/3064857.3079117
   Fianyi I, 2016, INT J CYBER WARF TER, V6, P28, DOI 10.4018/IJCWT.2016100103
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Galea C, 2018, IEEE T INF FOREN SEC, V13, P1421, DOI 10.1109/TIFS.2017.2788002
   Galiani S, 2019, J INFORMETR, V13, P738, DOI 10.1016/j.joi.2019.03.014
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Garain J, 2019, MULTIMED TOOLS APPL, V78, P18443, DOI 10.1007/s11042-018-7132-9
   Gautam G, 2019, MULTIMED TOOLS APPL, V78, P6655, DOI 10.1007/s11042-018-6371-0
   Geetha A, 2019, SOFT COMPUT, V23, P2525, DOI 10.1007/s00500-018-03679-5
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gilbert A, 2008, LECT NOTES COMPUT SC, V5302, P222, DOI 10.1007/978-3-540-88682-2_18
   Gong DH, 2017, IEEE T IMAGE PROCESS, V26, P2079, DOI 10.1109/TIP.2017.2651380
   Gonzalez-Sosa E, 2018, IEEE T INF FOREN SEC, V13, P2001, DOI 10.1109/TIFS.2018.2807791
   GOSWAMI G, 2018, P 32 AAAI C ART INT
   Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2
   Grm K, 2018, IET BIOMETRICS, V7, P81, DOI 10.1049/iet-bmt.2017.0083
   Guo B. H., 2018, Ph. D. thesis), P1, DOI 10.1109/isba.2018.8311457
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   Guo SR, 2017, MULTIMED TOOLS APPL, V76, P8677, DOI 10.1007/s11042-016-3470-7
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Guodong Guo, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P196, DOI 10.1109/AFGR.2000.840634
   Gutta S, 1997, PATTERN RECOGN, V30, P539, DOI 10.1016/S0031-3203(96)00111-2
   Haghiri S, 2014, IEEE IMAGE PROC, P5242, DOI 10.1109/ICIP.2014.7026061
   Han PY, 2011, DISCRETE DYN NAT SOC, V2011, DOI 10.1155/2011/521935
   Han XJ, 2020, IEEE T MULTIMEDIA, V22, P1619, DOI 10.1109/TMM.2019.2945197
   HasanPour SH, 2018, ARXIV180206205 CORR
   Hashemi VH, 2015, American Journal of Networks and Communications, P90, DOI [10.11648/j.ajnc.20150404.12, DOI 10.11648/J.AJNC.20150404.12]
   He LX, 2019, IEEE T IMAGE PROCESS, V28, P791, DOI 10.1109/TIP.2018.2870946
   He QQ, 2019, MULTIMED TOOLS APPL, V78, P24035, DOI 10.1007/s11042-019-7209-0
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Heisele B, 2003, COMPUT VIS IMAGE UND, V91, P6, DOI 10.1016/S1077-3142(03)00073-0
   Heng W, 2019, IEEE T CIRC SYST VID, V29, P2229, DOI 10.1109/TCSVT.2018.2866701
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hu CH, 2019, IEEE T IMAGE PROCESS, V28, P2624, DOI 10.1109/TIP.2018.2887346
   Hu CH, 2020, IEEE ACCESS, V8, P63202, DOI 10.1109/ACCESS.2020.2983837
   Hu PF, 2017, IEEE T IND INFORM, V13, P1910, DOI 10.1109/TII.2016.2607178
   Huan EY, 2020, MULTIMED TOOLS APPL, V79, P11905, DOI 10.1007/s11042-019-08376-5
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Huang KK, 2017, IEEE T NEUR NET LEAR, V28, P1082, DOI 10.1109/TNNLS.2016.2522431
   Huang P, 2017, IEEE ACCESS, V5, P4340, DOI 10.1109/ACCESS.2017.2680437
   Huang R, 2004, INT C PATT RECOG, P157, DOI 10.1109/ICPR.2004.1334492
   Iliadis M, 2017, IEEE T IMAGE PROCESS, V26, P2203, DOI 10.1109/TIP.2017.2675206
   Iranmanesh SM, 2018, INT CONF BIOMETR, P166, DOI 10.1109/ICB2018.2018.00034
   Jaha ES, 2016, IEEE T INF FOREN SEC, V11, P2377, DOI 10.1109/TIFS.2016.2584001
   Jain AK, 2009, IEEE IMAGE PROC, P37, DOI 10.1109/ICIP.2009.5413921
   Jha D, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2385, DOI 10.1145/3292500.3330703
   Jiang B, 2017, ARXIV170802721 CORR
   Jing LP, 2013, IEEE T NEUR NET LEAR, V24, P1188, DOI 10.1109/TNNLS.2013.2253123
   Jing XY, 2016, PATTERN RECOGN, V59, P14, DOI 10.1016/j.patcog.2016.01.023
   Jiu MY, 2019, PATTERN RECOGN, V88, P447, DOI 10.1016/j.patcog.2018.12.005
   Kang WX, 2019, IEEE T INF FOREN SEC, V14, P858, DOI 10.1109/TIFS.2018.2866330
   Kasapakis V, 2017, MULTIMED TOOLS APPL, V76, P9829, DOI 10.1007/s11042-016-3581-1
   Kasturi R, 2009, IEEE T PATTERN ANAL, V31, P319, DOI 10.1109/TPAMI.2008.57
   Kawulok M, 2011, PATTERN RECOGN, V44, P929, DOI 10.1016/j.patcog.2010.10.010
   Keinert F, 2019, IEEE T IMAGE PROCESS, V28, P2785, DOI 10.1109/TIP.2018.2890312
   Kemelmacher-Shlizerman I, 2011, IEEE T PATTERN ANAL, V33, P394, DOI 10.1109/TPAMI.2010.63
   Kepenekci B, 2001, THESIS
   Khan K, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21070647
   Khan S, 2020, IEEE T AFFECT COMPUT, V11, P348, DOI 10.1109/TAFFC.2017.2780838
   Khanna A, 2022, NUTR NEUROSCI, V25, P1240, DOI 10.1080/1028415X.2020.1853410
   Kim D, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P133, DOI 10.1109/BTAS.2017.8272691
   Kim K, 2005, LECT NOTES COMPUT SC, V3497, P147
   Kreutz-Delgado K, 2003, NEURAL COMPUT, V15, P349, DOI 10.1162/089976603762552951
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kwak KC, 2005, PATTERN RECOGN, V38, P1717, DOI 10.1016/j.patcog.2005.01.018
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   Lahasan B, 2019, ARTIF INTELL REV, V52, P949, DOI 10.1007/s10462-017-9578-y
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Lavanya B, 2018, NEURAL COMPUT APPL, V29, P289, DOI 10.1007/s00521-017-2994-8
   Lee H, 2018, INT C CYBER WARFARE, P379
   Li DL, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-92
   Li H., 2014, Asian Conference on Computer Vision, P17
   Li QM, 2016, INT J SEMANT COMPUT, V10, P569, DOI 10.1142/S1793351X16400213
   Li X, 2018, MULTIMED TOOLS APPL, V77, P28333, DOI 10.1007/s11042-018-6049-7
   Li XX, 2013, IEEE T IMAGE PROCESS, V22, P1889, DOI 10.1109/TIP.2013.2237920
   Li XD, 2014, J ELECTR COMPUT ENG, V2014, DOI 10.1155/2014/919041
   Li XD, 2013, NEUROCOMPUTING, V122, P266, DOI 10.1016/j.neucom.2013.06.025
   Li Y, 2018, PATTERN RECOGN, V75, P51, DOI 10.1016/j.patcog.2017.10.015
   Li Y, 2015, COMM COM INF SC, V546, P296, DOI 10.1007/978-3-662-48558-3_30
   Li ZM, 2017, IEEE T NEUR NET LEAR, V28, P278, DOI 10.1109/TNNLS.2015.2508025
   Liao HB, 2019, MULTIMED TOOLS APPL, V78, P2181, DOI 10.1007/s11042-018-6342-5
   Liao MM, 2019, DIGIT SIGNAL PROCESS, V90, P110, DOI 10.1016/j.dsp.2019.04.006
   Lin S., 2019, 2019 14 IEEE INT C A, P1
   Lin SL, 2017, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON INTERNET OF THINGS, DATA AND CLOUD COMPUTING (ICC 2017), DOI 10.1145/3018896.3025149
   Liu BD, 2017, MULTIMED TOOLS APPL, V76, P4159, DOI 10.1007/s11042-015-3042-2
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu CJ, 2000, IEEE T PATTERN ANAL, V22, P570, DOI 10.1109/34.862196
   Liu H, 2018, IEEE T INF FOREN SEC, V13, P292, DOI 10.1109/TIFS.2017.2746062
   Liu JY, 2019, MULTIMED TOOLS APPL, V78, P33703, DOI 10.1007/s11042-019-08203-x
   Liu JJ, 2019, INT J MACH LEARN CYB, V10, P1051, DOI 10.1007/s13042-017-0782-5
   Liu KH, 2015, IEEE T INF FOREN SEC, V10, P2408, DOI 10.1109/TIFS.2015.2462732
   Liu N, 2020, IEEE ACCESS, V8, P92441, DOI 10.1109/ACCESS.2020.2994322
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Liu XG, 2018, FUTURE GENER COMP SY, V80, P653, DOI 10.1016/j.future.2016.07.007
   Lu CY, 2013, J VIS COMMUN IMAGE R, V24, P111, DOI 10.1016/j.jvcir.2012.05.003
   Lu C, 2015, AAAI CONF ARTIF INTE, P3811
   Lu XG, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P13
   Luo J, 2007, INT CONF ACOUST SPEE, P593
   Luu K, 2016, DEEP LEARNING APPROA, P1, DOI DOI 10.1007/978-3-319-25958-11
   Mahmood A, 2018, IEEE ACCESS, V6, P12993, DOI 10.1109/ACCESS.2018.2794357
   Malioutov DM, 2004, INT CONF ACOUST SPEE, P793
   Mamadou D, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P209, DOI 10.1109/SITIS.2016.41
   Mandavkar AA, 2015, IEEE INT ADV COMPUT, P644, DOI 10.1109/IADCC.2015.7154786
   Marszalec E, 2000, J ELECTRON IMAGING, V9, P32, DOI 10.1117/1.482722
   Meng FR, 2017, MULTIMED TOOLS APPL, V76, P895, DOI 10.1007/s11042-015-3083-6
   Miikkulainen R, 2019, ARTIFICIAL INTELLIGENCE IN THE AGE OF NEURAL NETWORKS AND BRAIN COMPUTING, P293, DOI 10.1016/B978-0-12-815480-9.00015-3
   Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X
   Mohammadi A, 2018, IET BIOMETRICS, V7, P15, DOI 10.1049/iet-bmt.2017.0079
   Nakano R, 2015, IEEE SYS MAN CYBERN, P2273, DOI 10.1109/SMC.2015.397
   Nixon MS, 2015, PATTERN RECOGN LETT, V68, P218, DOI 10.1016/j.patrec.2015.08.006
   Nojavanasghari B, 2017, INT CONF AFFECT, P209, DOI 10.1109/ACII.2017.8273602
   Oulefki A, 2018, SIGNAL IMAGE VIDEO P, V12, P421, DOI 10.1007/s11760-017-1174-8
   Ouyang DQ, 2019, PATTERN RECOGN LETT, V117, P153, DOI 10.1016/j.patrec.2018.05.009
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Parchami M, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Park U, 2010, IEEE T INF FOREN SEC, V5, P406, DOI 10.1109/TIFS.2010.2049842
   Pei WJ, 2020, IEEE T IMAGE PROCESS, V29, P1972, DOI 10.1109/TIP.2019.2948288
   Peng CL, 2019, IEEE T IMAGE PROCESS, V28, P4553, DOI 10.1109/TIP.2019.2912360
   Peng YL, 2018, SIGNAL PROCESS, V147, P101, DOI 10.1016/j.sigpro.2018.01.013
   Phillips P.J., 2011, Proc. IEEE Conference on Automatic Face and Gesture Recognition, P346
   Phillips PJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P15
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Pitas K, 2019, ARXIV190509677 CORR
   Plenge E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0131968
   Poder E, 2017, ARXIV170709775 CORR
   Poon G, 2019, MULTIMED TOOLS APPL, V78, P23469, DOI 10.1007/s11042-019-7660-y
   Pujol FA, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19010026
   Punyani P, 2020, ARTIF INTELL REV, V53, P3299, DOI 10.1007/s10462-019-09765-w
   Qian JJ, 2014, IEEE COMPUT SOC CONF, P21, DOI 10.1109/CVPRW.2014.9
   Qian JY, 2018, J PHYS CONF SER, V960, DOI 10.1088/1742-6596/960/1/012030
   Queirolo CC, 2010, IEEE T PATTERN ANAL, V32, P206, DOI 10.1109/TPAMI.2009.14
   Radford A., 2016, INT C LEARN REPR
   Rajan S, 2019, IET IMAGE PROCESS, V13, P1031, DOI 10.1049/iet-ipr.2018.6647
   Rakshit RD, 2018, EXPERT SYST APPL, V92, P82, DOI 10.1016/j.eswa.2017.09.038
   Ramalingam S, 2018, FUZZY SET SYST, V337, P25, DOI 10.1016/j.fss.2017.06.002
   Ranjan R, 2018, IEEE SIGNAL PROC MAG, V35, P66, DOI 10.1109/MSP.2017.2764116
   Rassadin A., 2017, ACM INT C MULTIMODAL, P544
   Rejeesh MR, 2019, MULTIMED TOOLS APPL, V78, P22691, DOI 10.1007/s11042-019-7577-5
   Roberts L., 1963, MACHINE PERCEPTION 3
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   Saeed U, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.051220
   Sajjad M, 2019, INFORM SCIENCES, V479, P416, DOI 10.1016/j.ins.2018.07.027
   Salici A, 2017, COMM COM INF SC, V766, P8, DOI 10.1007/978-3-319-67639-5_2
   Sargano AB, 2017, IEEE IJCNN, P463, DOI 10.1109/IJCNN.2017.7965890
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Sawant MM, 2019, ARTIF INTELL REV, V52, P981, DOI 10.1007/s10462-018-9661-z
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sepas-Moghaddam A, 2019, ARXIV190100713 CORR
   Serre T, 2005, PROC CVPR IEEE, P994
   Shang K, 2018, APPL MATH COMPUT, V320, P99, DOI 10.1016/j.amc.2017.07.058
   Shao CB, 2017, INFORM SCIENCES, V393, P1, DOI 10.1016/j.ins.2017.02.017
   Shi BG, 2018, IEEE T NEUR NET LEAR, V29, P183, DOI 10.1109/TNNLS.2016.2618340
   Shreyamsha Kumar BK, 2019, MULTIMED TOOLS APPL, V78, P7243, DOI 10.1007/s11042-018-6453-z
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Sing JK, 2019, INFORM FUSION, V47, P60, DOI 10.1016/j.inffus.2018.07.005
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   Skocaj D, 2007, PATTERN RECOGN, V40, P1556, DOI 10.1016/j.patcog.2006.09.019
   Soltanpour S, 2017, PATTERN RECOGN, V72, P391, DOI 10.1016/j.patcog.2017.08.003
   Stonham T. J., 1986, Practical Face Recognition and Verification with Wisard, P426
   Su YC, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P670, DOI 10.1109/ACPR.2015.7486587
   Sun PH, 2019, IEEE INT CON MULTI, P260, DOI 10.1109/ICME.2019.00053
   Sun Y., 2015, ARXIV150200873
   Sun Y, 2014, ADV NEUR IN, V27
   Sun Y, 2013, IEEE I CONF COMP VIS, P1489, DOI 10.1109/ICCV.2013.188
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Sun YL, 2018, IEEE T PATTERN ANAL, V40, P332, DOI 10.1109/TPAMI.2017.2669035
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tang JH, 2018, PATTERN RECOGN, V75, P25, DOI 10.1016/j.patcog.2017.03.028
   Tang ZJ, 2018, APPL MATH COMPUT, V321, P721, DOI 10.1016/j.amc.2017.11.017
   Tolba AS, 2000, CYBERNET SYST, V31, P837, DOI 10.1080/019697200750038968
   Tome P, 2014, IEEE T INF FOREN SEC, V9, P464, DOI 10.1109/TIFS.2014.2299975
   Tosic I, 2011, IEEE SIGNAL PROC MAG, V28, P27, DOI 10.1109/MSP.2010.939537
   Tsai CJ, 2019, APPL SOFT COMPUT, V80, P125, DOI 10.1016/j.asoc.2019.03.033
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vezzetti E, 2018, MULTIMED TOOLS APPL, V77, P14177, DOI 10.1007/s11042-017-5025-y
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Vishwakarma VP, 2020, MULTIMED TOOLS APPL, V79, P11503, DOI 10.1007/s11042-019-08537-6
   Vishwakarma VP, 2019, MULTIMED TOOLS APPL, V78, P15213, DOI 10.1007/s11042-018-6837-0
   Nguyen V, 2018, STUD COMPUT INTELL, V769, P367, DOI 10.1007/978-3-319-76081-0_31
   Wagner A, 2009, PROC CVPR IEEE, P597, DOI 10.1109/CVPRW.2009.5206654
   Wang DX, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1225, DOI 10.1145/2939672.2939753
   Wang HJ, 2018, IEEE ACCESS, V6, P6001, DOI 10.1109/ACCESS.2017.2784842
   Wang K, 2020, IEEE T IMAGE PROCESS, V29, P4057, DOI 10.1109/TIP.2019.2956143
   Wang L, 2018, J ELECTR COMPUT ENG, V2018, DOI 10.1155/2018/2179049
   Ying-Hong Wang, 2009, 2009 Symposia and Workshops on Ubiquitous, Autonomic and Trusted Computing in conjunction with the UIC 2009 and ATC 2009 Conferences, P1, DOI [10.1109/ICBBE.2009.5163482, 10.1109/UIC-ATC.2009.19]
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   WEN YD, 2016, PROC CVPR IEEE, P4893, DOI DOI 10.1109/CVPR.2016.529
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu F, 2020, IEEE T CYBERNETICS, V50, P1009, DOI 10.1109/TCYB.2018.2876591
   Wu HM, 2018, IEEE T HUM-MACH SYST, V48, P304, DOI 10.1109/THMS.2017.2776211
   Xie JC, 2020, IEEE T INF FOREN SEC, V15, P2361, DOI 10.1109/TIFS.2020.2965298
   Xie JC, 2019, IEEE T INF FOREN SEC, V14, P2500, DOI 10.1109/TIFS.2019.2902823
   Xu JJ, 2018, LECT NOTES ARTIF INT, V10619, P721, DOI 10.1007/978-3-319-73618-1_62
   Xu Y, 2017, IEEE T NEUR NET LEAR, V28, P2233, DOI 10.1109/TNNLS.2016.2580572
   Xue YG, 2007, THESIS
   Yang M, 2013, IEEE T IMAGE PROCESS, V22, P1753, DOI 10.1109/TIP.2012.2235849
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Yang MH, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P215
   Yang WK, 2008, INT C PATT RECOG, P3699
   Yongkang Wong, 2011, 2011 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops 2011), P74, DOI 10.1109/CVPRW.2011.5981881
   Yoo B, 2018, IEEE SIGNAL PROC LET, V25, P808, DOI 10.1109/LSP.2018.2822241
   Yu D, 2018, MULTIMED TOOLS APPL, V77, P12919, DOI 10.1007/s11042-017-4923-3
   YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zafar U, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0406-y
   Zhang FF, 2020, IEEE T IMAGE PROCESS, V29, P4445, DOI 10.1109/TIP.2020.2972114
   Zhang HC, 2013, PATTERN RECOGN, V46, P1511, DOI 10.1016/j.patcog.2012.10.025
   Zhang L, 2012, IEEE T SIGNAL PROCES, V60, P1684, DOI 10.1109/TSP.2011.2179539
   Zhang LP, 2020, GEO-SPAT INF SCI, V23, P98, DOI 10.1080/10095020.2020.1720529
   Zhang MJ, 2020, IEEE T IMAGE PROCESS, V29, P1507, DOI 10.1109/TIP.2019.2942514
   Zhang Q.Z.Q., 2010, PROC CVPR IEEE, DOI [10.1109/CVPR.2010.5539989, DOI 10.1109/CVPR.2010.5539989]
   Zhang SH, 2018, MULTIMED TOOLS APPL, V77, P9753, DOI 10.1007/s11042-018-5822-y
   Zhang WM, 2019, IEEE T PATTERN ANAL, V41, P611, DOI 10.1109/TPAMI.2018.2803179
   Zhang X, 2009, PATTERN RECOGN, V42, P2876, DOI 10.1016/j.patcog.2009.04.017
   Zhang Y, 2019, J VIS COMMUN IMAGE R, V59, P501, DOI 10.1016/j.jvcir.2019.02.007
   Zhang YH, 2018, INT C PATT RECOG, P3341, DOI 10.1109/ICPR.2018.8545498
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhao W., 1999, Robust Face Recognition using Symmetric Shape from Shading
   Zheng Y., 2006, P 6 WORLD C INT CONT, V2, P9669
   Zheng YF, 2011, IEEE INT SYMP SIGNAL, P543
   Zhi RC, 2020, VISUAL COMPUT, V36, P1067, DOI 10.1007/s00371-019-01707-5
   Zhong Y., 2019, 2019 13th European Conference on Antennas and Propagation, P1
   Zhu CC, 2017, ADV COMPUT VIS PATT, P57, DOI 10.1007/978-3-319-61657-5_3
   Zhu S, 2018, 19TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2018), P391
NR 297
TC 53
Z9 55
U1 8
U2 173
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4825
EP 4880
DI 10.1007/s11042-020-09850-1
EA OCT 2020
PG 56
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000574727600010
DA 2024-07-18
ER

PT J
AU Yadav, H
   Chhikara, R
   Kumari, AC
AF Yadav, Hitesh
   Chhikara, Rita
   Kumari, A. Charan
TI A novel hybrid approach for feature selection in software product lines
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Particle swarm optimization; Hyper-heuristic; Biogeography-based
   optimization; Firefly; Genetic algorithm (GA); Bird swarm optimization
   (BSA); Software product lines (SPL); Feature model (FM)
ID BIOGEOGRAPHY-BASED OPTIMIZATION; PARTICLE SWARM; ALGORITHM; PSO
AB Software Product Line (SPL) customizes software by combining various existing features of the software with multiple variants. The main challenge is selecting valid features considering the constraints of the feature model. To solve this challenge, a hybrid approach is proposed to optimize the feature selection problem in software product lines. The Hybrid approach 'Hyper-PSOBBO' is a combination of Particle Swarm Optimization (PSO), Biogeography-Based Optimization (BBO) and hyper-heuristic algorithms. The proposed algorithm has been compared with Bird Swarm Algorithm (BSA), PSO, BBO, Firefly, Genetic Algorithm (GA) and Hyper-heuristic. All these algorithms are performed in a set of 10 feature models that vary from a small set of 100 to a high-quality data set of 5000. The detailed empirical analysis in terms of performance has been carried out on these feature models. The results of the study indicate that the performance of the proposed method is higher to other state-of-the-art algorithms.
C1 [Yadav, Hitesh; Chhikara, Rita] NorthCap Univ, Gurugram, Haryana, India.
   [Kumari, A. Charan] Dayalbagh Educ Inst, Gurugram, Haryana, India.
C3 The Northcap University; Dayalbagh Educational Institute (DEI)
RP Yadav, H (corresponding author), NorthCap Univ, Gurugram, Haryana, India.
EM hiteshyadav@ncuindia.edu; ritachhikara@ncuindia.edu;
   charankumari@yahoo.co.in
CR Ababneh J, 2015, INT J INTELL COMPUT, V8, P28, DOI 10.1108/IJICC-01-2014-0003
   [Anonymous], 2012, INT J PHOTO
   [Anonymous], 2014, INF SCI, DOI DOI 10.1016/j.ins.2014.03.128
   [Anonymous], 2002, Antennas and Propagation Society International Symposium, 2002
   [Anonymous], 2009, INT J COMPUT SCI INF
   [Anonymous], 2013, MATH PROBLEMS ENG
   Chen X, 2016, APPL SOFT COMPUT, V45, P71, DOI 10.1016/j.asoc.2016.04.022
   Chhikara RR, 2016, INT J MACH LEARN CYB, V7, P1195, DOI 10.1007/s13042-015-0448-0
   Cowling P, 2001, LECT NOTES COMPUT SC, V2079, P176
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Goodarzi M, 2014, ANAL CHIM ACTA, V852, P20, DOI 10.1016/j.aca.2014.09.045
   Guo JM, 2011, J SYST SOFTWARE, V84, P2208, DOI 10.1016/j.jss.2011.06.026
   Hitesh, 2020, PROCEDIA COMPUT SCI, V167, P1696, DOI 10.1016/j.procs.2020.03.380
   Hitesh, 2018, Procedia Computer Science, V132, P1477, DOI 10.1016/j.procs.2018.05.082
   Jianjie Ding, 2011, 2011 2nd International Conference on Artificial Intelligence, Management Science and Electronic Commerce (AIMSEC 2011), P3542, DOI 10.1109/AIMSEC.2011.6011387
   Kashyap Neeti, 2018, Electronic Government, V14, P321
   Kumari AC, 2016, J SYST SOFTWARE, V117, P384, DOI 10.1016/j.jss.2016.04.007
   Li J, 2011, ADV INTEL SOFT COMPU, V124, P459
   Lohokare MR, 2012, IEEE T SYST MAN CY C, V42, P641, DOI 10.1109/TSMCC.2012.2190401
   Ma HP, 2013, INFORM SCIENCES, V220, P492, DOI 10.1016/j.ins.2012.07.007
   Ma HP, 2010, INFORM SCIENCES, V180, P3444, DOI 10.1016/j.ins.2010.05.035
   Meng XB, 2016, J EXP THEOR ARTIF IN, V28, P673, DOI 10.1080/0952813X.2015.1042530
   Niu B, 2008, LECT NOTES COMPUT SC, V5227, P156
   Northrop L., 2001, SOFTWARE PRODUCT LIN
   Rarick R, 2009, IEEE SYS MAN CYBERN, P1003, DOI 10.1109/ICSMC.2009.5346046
   Silva M., 2010, 23 C NAC TRANSP AQ C, P1
   Simon D, 2008, IEEE T EVOLUT COMPUT, V12, P702, DOI 10.1109/TEVC.2008.919004
   Tsafarakis S, 2011, INT J RES MARK, V28, P13, DOI 10.1016/j.ijresmar.2010.05.002
   Yadav H, 2020, INT J EMBED SYST, V13, P50
   Yadav Hitesh, 2018, INT J EDUC MANAG, V8, P48
   Yang X.S., 2019, Mathematical Foundations of Nature-Inspired Methods
   Zhang P, 2013, COMPEL, V32, P575, DOI 10.1108/03321641311296954
   Zhu WR, 2014, AEROSP SCI TECHNOL, V32, P153, DOI 10.1016/j.ast.2013.11.003
NR 33
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 4919
EP 4942
DI 10.1007/s11042-020-09956-6
EA OCT 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000574376100001
DA 2024-07-18
ER

PT J
AU Randhawa, S
   Alsadoon, A
   Prasad, PWC
   Al-Dala'in, T
   Dawoud, A
   Alrubaie, A
AF Randhawa, Simranjeet
   Alsadoon, Abeer
   Prasad, P. W. C.
   Al-Dala'in, Thair
   Dawoud, Ahmed
   Alrubaie, Ahmad
TI Deep learning for liver tumour classification: enhanced loss function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Computer-aided diagnosis; Spinal metastases; Liver
   cancer; Watershed transform; Gray level co-occurrence matrix; Support
   vector matrix
ID IMAGE SEGMENTATION; NEURAL-NETWORKS; SHAPE
AB Background and Aim: deep learning has not been successfully implemented in liver tumour feature extraction and classification using computer-aided diagnosis. This study aims to enhance classification accuracy and improves the processing time to better differentiate tumour types. Methodology: This study proposed a hybrid model, which combines the regularization function with the current loss function for the support vector machine (SVM) classifier. Regularization function is used for prioritizing image classes before feeding it to the linear mapping. The proposed model consists of the region growing algorithm to get the region-of-interest (ROI), and Weiner filtering algorithm for image enhancement and noise removal. The gray level co-occurrence matrix (GLCM) was performed to extract the feature from the image. The extracted feature then fed to SVM classifier using selected feature vectors to classify the affected region and neglecting the unwanted areas. Results: classification accuracy was calculated using probability score, and the processing time was calculated based on the total execution time. The proposed system was able to achieve an average classification accuracy of 98.9%, which is about 2-3% higher than the current system. The results showed that 12 ms reduced the processing time on average. Conclusion: The proposed system focused on improving feature extraction and classification for different types of tumours from the MRI images. The study solved the problem in linear mapping of support vector machine and enhanced the classification accuracy and the processing time of early diagnosis of three different types of tumours in liver MRI images.
C1 [Randhawa, Simranjeet; Alsadoon, Abeer; Prasad, P. W. C.; Al-Dala'in, Thair; Dawoud, Ahmed] Charles Sturt Univ, Sch Comp & Math, Sydney, NSW, Australia.
   [Alrubaie, Ahmad] Univ New South Wales, Fac Med, Sydney, NSW, Australia.
C3 Charles Sturt University; University of New South Wales Sydney
RP Alsadoon, A (corresponding author), Charles Sturt Univ, Sch Comp & Math, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Dawoud, Ahmed/AAD-1295-2022; Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; Dawoud,
   Ahmed/0000-0002-2051-5920; withana, chandana/0000-0002-3007-687X
CR Acharya UR, 2018, COMPUT BIOL MED, V94, P11, DOI 10.1016/j.compbiomed.2017.12.024
   Alirr OI, 2018, INT J COMPUT ASS RAD, V13, P1169, DOI 10.1007/s11548-018-1801-z
   Anter AM, 2013, FED CONF COMPUT SCI, P193
   Bi L, 2017, ARXIVORG
   Brunetti A, 2019, NEUROCOMPUTING, V335, P274, DOI 10.1016/j.neucom.2018.06.080
   Chlebus G, 2017, ABS170600842 CORR
   Christ Patrick Ferdinand, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P415, DOI 10.1007/978-3-319-46723-8_48
   Damodharan S, 2015, INT ARAB J INF TECHN, V12, P42
   Das A, 2019, COGN SYST RES, V54, P165, DOI 10.1016/j.cogsys.2018.12.009
   Fang CH, 2019, EBIOMEDICINE, V41, P693, DOI 10.1016/j.ebiom.2019.02.017
   Gao ZG, 2018, CRYST GROWTH DES, V18, P4275, DOI 10.1021/acs.cgd.8b00883
   Jiang HY, 2019, IEEE ACCESS, V7, P24898, DOI 10.1109/ACCESS.2019.2899608
   Ke Q, 2019, EXPERT SYST APPL, V126, P218, DOI 10.1016/j.eswa.2019.01.060
   Kim B, 2020, IEEE T IMAGE PROCESS, V29, P1856, DOI 10.1109/TIP.2019.2941265
   Lang N, 2019, MAGN RESON IMAGING, V64, P4, DOI 10.1016/j.mri.2019.02.013
   Laukamp KR, 2019, EUR RADIOL, V29, P124, DOI 10.1007/s00330-018-5595-8
   Li W., 2015, J COMPUT COMMUN, V3, P146, DOI DOI 10.4236/JCC.2015.311023
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Lin JY, 2018, MED IMAGE ANAL, V48, P162, DOI 10.1016/j.media.2018.06.004
   Maharjan S, 2020, J NEUROSCI METH, V330, DOI 10.1016/j.jneumeth.2019.108520
   Meng L, 2020, J APPL CLIN MED PHYS, V21, P144, DOI 10.1002/acm2.12784
   Moriya T, 2018, PROC SPIE, V10578, DOI 10.1117/12.2293414
   Pham TT, 2018, IEEE INT CONF ROBOT, P3213
   Sun MJ, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107465
   Sundaram PS, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1153-9
   Tavani H.T., 2015, Ethics and technology: Controversies, questions, and strategies for ethical computing, V5th
   Thillaikkarasi R, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1223-7
   Trivizakis E, 2019, IEEE J BIOMED HEALTH, V23, P923, DOI 10.1109/JBHI.2018.2886276
   Wang GT, 2018, IEEE T MED IMAGING, V37, P1562, DOI 10.1109/TMI.2018.2791721
   Wang J, 2020, PATTERN RECOGN LETT, V130, P207, DOI 10.1016/j.patrec.2019.01.001
   Xu V. Z, 2018, ABC
   Yang D, 2017, ARXIVORG
   Yuan Y, 2017, ARXIVORG
   Zhou LL, 2019, TRANSL ONCOL, V12, P292, DOI 10.1016/j.tranon.2018.10.012
NR 34
TC 13
Z9 13
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4729
EP 4750
DI 10.1007/s11042-020-09900-8
EA OCT 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000574376900001
DA 2024-07-18
ER

PT J
AU Deb, D
   Roy, S
AF Deb, Daizy
   Roy, Sudipta
TI Brain tumor detection based on hybrid deep neural network in MRI by
   adaptive squirrel search optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Flying squirrel; Frog leap; Optimization; Segmentation; Classification;
   Brain tumor detection
ID MEANS CLUSTERING-ALGORITHM; IMAGE SEGMENTATION; FEATURES
AB In the medical field, image segmentation is a paramount and challenging task. The head and vertebral column make up the central nervous system (CNS), which control all the paramount functions. These include thinking, speaking, and gestures. The uncontrolled growth in the CNS can affect a person's thinking of communication or movement. The tumor is known as the uncontrolled growth of cells in brain. The tumor can be recognized by MRI image. Brain tumor detection is mostly affected with inaccurate classification. This proposed work designed a novel classification and segmentation algorithm for the brain tumor detection. The proposed system uses the Adaptive fuzzy deep neural network with frog leap optimization to detect normality and abnormality of the image. Accurate classification is achieved with error minimization strategy through our proposed method. Then, the abnormal image is segmented using adaptive flying squirrel algorithm and the size of the tumor is detected, which is used to find out the severity of the tumor. The proposed work is implemented in the MATLAB simulation platform. The proposed work Accuracy, sensitivity, specificity, false positive rate and false negative rate are 99.6%, 99.9%, 99.8%, 0.0043 and 0.543, respectively. The detection accuracy is better in our proposed system than the existing teaching and learning based algorithm, social group algorithm and deep neural network.
C1 [Deb, Daizy; Roy, Sudipta] Assam Univ, Triguna Sen Sch Technol, Dept Comp Sci & Engn, Silchar 788011, India.
C3 Assam University
RP Deb, D (corresponding author), Assam Univ, Triguna Sen Sch Technol, Dept Comp Sci & Engn, Silchar 788011, India.
EM daizydeb17@gmail.com
RI Roy, Sudipta/T-5231-2019; Roy, Sudipta/V-7932-2018
OI Roy, Sudipta/0000-0001-5161-9311; Roy, Sudipta/0000-0003-0244-6455
CR Amin J, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1483-2
   Balla-Arabé S, 2013, IEEE T CYBERNETICS, V43, P910, DOI 10.1109/TSMCB.2012.2218233
   Benaichouche AN, 2013, DIGIT SIGNAL PROCESS, V23, P1390, DOI 10.1016/j.dsp.2013.07.005
   Caldairou B, 2011, PATTERN RECOGN, V44, P1916, DOI 10.1016/j.patcog.2010.06.006
   Chen HF, 2020, INT J MACH LEARN CYB, V11, P185, DOI 10.1007/s13042-019-00966-x
   Chen SM, 2008, IEEE T FUZZY SYST, V16, P1626, DOI 10.1109/TFUZZ.2008.2008412
   Chen YB, 2020, J CONTEMP CHINA, V29, P1, DOI [10.1080/10670564.2019.1621526, 10.1080/01932691.2020.1791172, 10.1007/s12652-020-02066-z]
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   Diwakar M, 2018, IET IMAGE PROCESS, V12, P708, DOI 10.1049/iet-ipr.2017.0639
   Dolz J, 2018, NEUROIMAGE, V170, P456, DOI 10.1016/j.neuroimage.2017.04.039
   Forouzanfar M, 2010, ENG APPL ARTIF INTEL, V23, P160, DOI 10.1016/j.engappai.2009.10.002
   Han C, 2020, SMART INNOV SYST TEC, V151, P291, DOI 10.1007/978-981-13-8950-4_27
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Hussain S, 2018, NEUROCOMPUTING, V282, P248, DOI 10.1016/j.neucom.2017.12.032
   Juang LH, 2010, MEASUREMENT, V43, P941, DOI 10.1016/j.measurement.2010.03.013
   Kaya IE, 2017, COMPUT METH PROG BIO, V140, P19, DOI 10.1016/j.cmpb.2016.11.011
   Kim HJ, 2012, RADIAT ONCOL J, V30, P70, DOI 10.3857/roj.2012.30.2.70
   Kumar Manoj, 2018, Journal of King Saud University - Computer and Information Sciences, V30, P41, DOI 10.1016/j.jksuci.2016.03.003
   Kumar M, 2019, J KING SAUD UNIV-COM, V31, P113, DOI 10.1016/j.jksuci.2016.12.002
   Kumar S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-45605-1
   Lahmiri S, 2017, BIOMED SIGNAL PROCES, V31, P148, DOI 10.1016/j.bspc.2016.07.008
   Li CM, 2014, MAGN RESON IMAGING, V32, P913, DOI 10.1016/j.mri.2014.03.010
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li GF, 2019, CLUSTER COMPUT, V22, pS2719, DOI 10.1007/s10586-017-1435-x
   Litjens G, 2014, MED IMAGE ANAL, V18, P359, DOI 10.1016/j.media.2013.12.002
   Makropoulos A, 2014, IEEE T MED IMAGING, V33, P1818, DOI 10.1109/TMI.2014.2322280
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Moftah HM, 2014, NEURAL COMPUT APPL, V24, P1917, DOI 10.1007/s00521-013-1437-4
   Mukhopadhyay A, 2011, APPL SOFT COMPUT, V11, P872, DOI 10.1016/j.asoc.2010.01.007
   Norouzi A, 2014, IETE TECH REV, V31, P199, DOI 10.1080/02564602.2014.906861
   Paul S, 2014, IEEE STUDENT TECHNOL, P56, DOI 10.1109/TechSym.2014.6807914
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Rad A.E., 2013, TELKOMNIKA Indonesian Journal of Electrical Engineering, V11, P3109, DOI DOI 10.11591/TELKOMNIKA.V11I6.2655
   Raja PMS, 2020, BIOCYBERN BIOMED ENG, V40, P440, DOI 10.1016/j.bbe.2020.01.006
   Rajendran A, 2012, PROCEDIA ENGINEER, V30, P327, DOI 10.1016/j.proeng.2012.01.868
   Rajinikanth V, 2018, ARAB J SCI ENG, V43, P4365, DOI 10.1007/s13369-017-3053-6
   Rajinikanth V, 2017, PATTERN RECOGN LETT, V94, P87, DOI 10.1016/j.patrec.2017.05.028
   Sajid S, 2019, ARAB J SCI ENG, V44, P9249, DOI 10.1007/s13369-019-03967-8
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Sharif M, 2020, PATTERN RECOGN LETT, V129, P150, DOI 10.1016/j.patrec.2019.11.017
   Shi F, 2010, NEUROIMAGE, V49, P391, DOI 10.1016/j.neuroimage.2009.07.066
   Soltaninejad M, 2017, INT J COMPUT ASS RAD, V12, P183, DOI 10.1007/s11548-016-1483-3
   Toth R, 2012, IEEE T MED IMAGING, V31, P1638, DOI 10.1109/TMI.2012.2201498
   Tu ZW, 2010, IEEE T PATTERN ANAL, V32, P1744, DOI 10.1109/TPAMI.2009.186
   Varuna Shree N, 2018, BRAIN INFORM, V5, P23, DOI DOI 10.1007/S40708-017-0075-5
   Wang ZM, 2013, COMPUT VIS IMAGE UND, V117, P1412, DOI 10.1016/j.cviu.2013.05.001
   Yu M, 2021, J MOTOR BEHAV, V53, P419, DOI 10.1080/00222895.2020.1790486
   Zhang N, 2011, COMPUT VIS IMAGE UND, V115, P256, DOI 10.1016/j.cviu.2010.09.007
NR 50
TC 39
Z9 39
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2621
EP 2645
DI 10.1007/s11042-020-09810-9
EA SEP 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569701000003
DA 2024-07-18
ER

PT J
AU Mahabadi, A
   Besmi, MR
AF Mahabadi, Aminollah
   Besmi, Mohammad Reza
TI Risk-aware service level agreement modeling in smart grid
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart grid; Service level agreements; Risk-aware service level
   agreements; Risk level agreements; Quality of service; Petri net model
ID ENERGY MANAGEMENT; DEMAND RESPONSE; PETRI NETS; STORAGE; MICROGRIDS;
   SYSTEM; SLA
AB As advanced Smart Grid environments grow from a simple grid towards a complex provider ecosystem, there is an uncertain challenge on those grid environments that need to manage a risk paradigm. We present an automated risk-aware service level agreements modeling to the grid provider for speed automated pricing and getting better performance to program as an agent-oriented platform. The key idea of ournovel approachis proposing arisk level agreementscontract and apricing modelto decrease the complexity of previous methods from an off-lineservice level agreementto an on-linerisk level agreementfor managing the risk lifecycle of contracts used to record the rights and obligations of the services and their consumers. Based on a risk level agreements contract the model optimizes resource management according to the business objective level of the provider with an online risk-aware rendezvous to define the penalty level of the cost model. The corresponding quality of service criteria is defined based on multi-class risk-aware service level agreements between Smart Grid providers and their power consumers which include the tail distributions of the per-class costs in addition to the more standard quality of service metrics such as throughput and mean delays. Our empirical experiments show the benefits of the proposed approach.
C1 [Mahabadi, Aminollah] Shahed Univ, Comp Engn Dept, Tehran, Iran.
   [Mahabadi, Aminollah] Shahed Univ, Acoust Res Ctr, Tehran, Iran.
   [Mahabadi, Aminollah] Inst Res Fundamental Sci IPM, Sch Comp Sci, Tehran, Iran.
   [Besmi, Mohammad Reza] Shahed Univ, Elect Engn Dept, Tehran, Iran.
C3 Shahed University; Shahed University; Shahed University
RP Mahabadi, A (corresponding author), Shahed Univ, Comp Engn Dept, Tehran, Iran.; Mahabadi, A (corresponding author), Shahed Univ, Acoust Res Ctr, Tehran, Iran.; Mahabadi, A (corresponding author), Inst Res Fundamental Sci IPM, Sch Comp Sci, Tehran, Iran.
EM mahabadi@shahed.ac.ir
CR [Anonymous], 2017, SUPERCAPACITOR US MA, V07
   Bakraouy Z, 2018, 2018 IEEE 5TH INTERNATIONAL CONGRESS ON INFORMATION SCIENCE AND TECHNOLOGY (IEEE CIST'18), P48, DOI 10.1109/CIST.2018.8596656
   Baldan P, 2010, NAT COMPUT, V9, P955, DOI 10.1007/s11047-010-9180-6
   de Carvalho CAB, 2017, COMPUT ELECTR ENG, V59, P141, DOI 10.1016/j.compeleceng.2016.12.030
   Bessa RJ, 2017, ENERGIES, V10, DOI 10.3390/en10091402
   Bird S, 2014, ENERGY SUSTAIN DEV, V19, P83, DOI 10.1016/j.esd.2013.12.006
   Carpinelli G, 2017, IEEE T POWER DELIVER, V32, P841, DOI 10.1109/TPWRD.2016.2587063
   Chrysoulas C, 2017, J COMMUN SOFTW SYST, V13, P77
   Djemame K, 2011, CONCURR COMP-PRACT E, V23, P1558, DOI 10.1002/cpe.1721
   Faheem M, 2018, COMPUT SCI REV, V30, P1, DOI 10.1016/j.cosrev.2018.08.001
   Gandhi R, 2014, ACM SIGCOMM COMP COM, V44, P27, DOI 10.1145/2740070.2626317
   Garcia-Valls M, 2017, MOB CLOUD COMPUT, P171
   Gouveia C, 2013, IEEE T SMART GRID, V4, P1898, DOI 10.1109/TSG.2013.2257895
   Hassan Hussein Al Haj, 2019, IEEE T GREEN COMMUNI
   Huang WX, 2018, RADIAT DETECT TECHNO, V2, DOI 10.1007/s41605-017-0031-1
   Hussain I, 2019, RENEW ENERG, V134, P1017, DOI 10.1016/j.renene.2018.11.085
   ITIL (IT Infrastructure Library), 2014, ITIL VERS 3 SERV IMP
   Jones KB, 2017, ENVIRON HAZARDS-UK, V16, P99, DOI 10.1080/17477891.2016.1257974
   Kakran S, 2018, RENEW SUST ENERG REV, V81, P524, DOI 10.1016/j.rser.2017.07.045
   Keskinen J., 2018, TAMPERE U TECHNOLOGY, V1562
   Khatibzadeh A, 2017, ENERGIES, V10, DOI 10.3390/en10020169
   Kopka R, 2017, NANOSCALE RES LETT, V12, DOI 10.1186/s11671-017-2396-y
   Kouchachvili L, 2018, J POWER SOURCES, V374, P237, DOI 10.1016/j.jpowsour.2017.11.040
   Lou X, 2013, IEEE T SMART GRID, V4, P1411, DOI 10.1109/TSG.2013.2249672
   Methenitis Georgios., 2018, ENERGY INF, V1, P1, DOI [10.1186/s42162-018-0062-y, DOI 10.1186/S42162-018-0062-Y]
   MURATA T, 1989, P IEEE, V77, P541, DOI 10.1109/5.24143
   Nunna HSVSK, 2013, IEEE T POWER DELIVER, V28, P939, DOI 10.1109/TPWRD.2013.2239665
   Pedram M., 2010, INT S LOW POW EL DES
   Ramey SM, 2018, MICROELECTRON RELIAB, V82, P42, DOI 10.1016/j.microrel.2018.01.004
   Saleem A, 2020, SUSTAIN CITIES SOC, V59, DOI 10.1016/j.scs.2020.102234
   Seim LH, 2012, THESIS
   Silva W, 2017, J FINANC STABIL, V28, P91, DOI 10.1016/j.jfs.2016.12.004
   Tiemann PH, 2020, ENERG CONVERS MANAGE, V208, DOI 10.1016/j.enconman.2020.112539
   Yeo CS, 2009, J GRID COMPUT, V7, P1, DOI 10.1007/s10723-008-9103-2
   Ying-Chao H, 2018, IEEE T SMART GRID
   Zafar R, 2018, RENEW SUST ENERG REV, V82, P1675, DOI 10.1016/j.rser.2017.07.018
   Zikria YB, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082334
NR 37
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1433
EP 1456
DI 10.1007/s11042-020-09787-5
EA SEP 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000567642600007
DA 2024-07-18
ER

PT J
AU Yu, DJ
   Wanyan, WB
   Wang, DJ
AF Yu, Dongjin
   Wanyan, Wenbo
   Wang, Dongjing
TI Leveraging contextual influence and user preferences for
   point-of-interest recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; POI recommendation; POI embedding; Matrix
   factorization
ID MUSIC
AB The effective Point-of-Interest (POI) recommendation can significantly assist users to find their preferred POIs and help POI owners to attract more customers. As a result, a variety of methods have been proposed to tackle the issue of POI recommendation recently. However, it is still very difficult to precisely model the strong correlations between the POIs visited by the user and the POIs to be visited next, which leads to the poor performance of POI recommendation. In this paper, we propose a context- and preference- aware model (CPAM) to incorporate both contextual influence and user preferences into POI recommendation. Firstly, we design a Skip-Gram based POI Embedding Model (SG-PEM) to capture the contextual influence of POIs and learn the vector representation (embedding) of POIs from visiting sequences. The users' preferences for the target POIs are obtained from the learned embeddings via similarity metric. Secondly, for the implicit feedback information contained in the check-in data, we use the Logistic Matrix Factorization (LMF) algorithm to model the users' personalized preferences for POI. Finally, we unify SG-PEM and LMF as the CPAM model to perform personalized recommendation by leveraging contextual influence and user preferences. The experimental results on two real-world datasets of Foursquare and Gowalla show that the proposed model outperforms the state-of-the-art baselines.
C1 [Yu, Dongjin; Wanyan, Wenbo; Wang, Dongjing] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
C3 Hangzhou Dianzi University
RP Wang, DJ (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
EM yudj@hdu.edu.cn; berg1996@hdu.edu.cn; dongjing.wang@hdu.edu.cn
RI Wang, Dongjing/JMJ-5616-2023
OI Wang, Dongjing/0000-0003-2152-0446
FU Zhejiang Provincial Natural Science Foundation of China [LQ20F020015];
   Fundamental Research Funds for the Provincial University of Zhejiang
   [GK199900299012-017]
FX This research is supported by Zhejiang Provincial Natural Science
   Foundation of China under No. LQ20F020015, and the Fundamental Research
   Funds for the Provincial University of Zhejiang under No.
   GK199900299012-017.
CR Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bin CZ, 2019, MULTIMED TOOLS APPL, V78, P35135, DOI 10.1007/s11042-019-08096-w
   Cao HC, 2020, IEEE T MOBILE COMPUT, V19, P1096, DOI 10.1109/TMC.2019.2902403
   Chang BR, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3301
   Chen CH, 2012, ACTIVATION AND DETOXIFICATION ENZYMES: FUNCTIONS AND IMPLICATIONS, P17, DOI 10.1007/978-1-4614-1049-2_3
   Chen JP, 2019, MULTIMED TOOLS APPL, V78, P2667, DOI 10.1007/s11042-018-5745-7
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen R, 2020, MULTIMED TOOLS APPL, V79, P14147, DOI 10.1007/s11042-020-08620-3
   CHENG X, 2013, IEEE IJCNN
   Cui Q, 2020, IEEE T KNOWL DATA EN, V32, P317, DOI 10.1109/TKDE.2018.2881260
   da Costa AF, 2019, EXPERT SYST APPL, V115, P427, DOI 10.1016/j.eswa.2018.08.020
   Deng SG, 2017, IEEE T CYBERNETICS, V47, P1380, DOI 10.1109/TCYB.2016.2545688
   Gao H, 2013, CHIN CONT DECIS CONF, P92
   Gao Q, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1689
   Goyal P, 2018, KNOWL-BASED SYST, V151, P78, DOI 10.1016/j.knosys.2018.03.022
   Guo L, 2019, SOFT COMPUT, V23, P11935, DOI 10.1007/s00500-018-03748-9
   He J, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1837
   He J, 2016, AAAI CONF ARTIF INTE, P137
   Hu B, 2014, IEEE DATA MINING, P845, DOI 10.1109/ICDM.2014.124
   Huang X, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P105, DOI 10.1145/3289600.3290956
   Johnson CC, 2014, ADV NEUR INF PROC SY, V27
   Kant S, 2019, MULTIMED TOOLS APPL, V78, P4107, DOI 10.1007/s11042-017-5260-2
   Kim Y, 2019, MULTIMED TOOLS APPL, V78, P3009, DOI 10.1007/s11042-018-5610-8
   [李晓莎 Li Xiaosha], 2017, [干旱地区农业研究, Agricultural Research in the Arid Areas], V35, P1
   Liu Q, 2016, AAAI CONF ARTIF INTE, P194
   Liu W, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1807
   Liu W, 2020, WORLD WIDE WEB, V23, P131, DOI 10.1007/s11280-019-00681-1
   Liu YD, 2017, PROC VLDB ENDOW, V10, P1010, DOI 10.14778/3115404.3115407
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Rahmani H. A., 2019, AS INF RETR S, P66
   Rendle S., 2010, P 19 INT C WORLD WID, P811, DOI DOI 10.1145/1772690.1772773
   Stepan T, 2016, IEEE TRANS COMPUT SO, V3, P164, DOI 10.1109/TCSS.2016.2631473
   Tu CC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1722, DOI 10.18653/v1/P17-1158
   Wang DJ, 2018, WORLD WIDE WEB, V21, P1399, DOI 10.1007/s11280-017-0521-6
   Wang DJ, 2018, INFORM RETRIEVAL J, V21, P230, DOI 10.1007/s10791-017-9317-7
   Wang W, 2021, INT J NEUROSCI, V131, P336, DOI 10.1080/00207454.2020.1744594
   Wang Z., 2017, ATMOS CHEM PHYS DISC, V2017, P1, DOI DOI 10.5194/ACP-2017-253
   Yin HZ, 2016, IEEE T KNOWL DATA EN, V28, P2566, DOI 10.1109/TKDE.2016.2580511
   Yu DJ, 2019, INT J SOFTW ENG KNOW, V29, P1781, DOI 10.1142/S0218194019400217
   Yuan T, 2014, AAAI CONF ARTIF INTE, P222
   Zhang J., 2015, ACM SIGSPATIAL Special, V7, P26, DOI DOI 10.1145/2876480.2876486
   Zhang J.D., 2013, P 21 ACM SIGSPATIAL, P334, DOI DOI 10.1145/2525314.2525339
   Zhao KZ, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3216
   Zhao SL, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P153
NR 44
TC 23
Z9 24
U1 1
U2 62
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1487
EP 1501
DI 10.1007/s11042-020-09746-0
EA SEP 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000567642600003
DA 2024-07-18
ER

PT J
AU Bashir, Z
   Iqbal, N
   Hanif, M
AF Bashir, Zia
   Iqbal, Nadeem
   Hanif, Muhammad
TI A novel gray scale image encryption scheme based on pixels' swapping
   operations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Encryption; Decryption; Swapping; Confusion; Diffusion
ID LEVEL PERMUTATION; ALGORITHM; CHAOS; CRYPTANALYSIS; SYSTEM; MAP
AB Design principles for image encryption schemes abound in the literature. Among these schemes, few were built upon the philosophy of swapping of the pixels in the given input image. Swapping is a very straightforward and a naive approach for image scrambling. We believe that fuller potential of swapping has not been realized yet. In this work, a novel image encryption scheme is being presented through the swapping of pixel values of the given gray scale input image. The 5D multi-wing hyperchaotic system rendering five key streams of random numbers have been used in the proposed cipher. After the gray scale image is input, its pixels are swapped randomly. The random numbers given through the first two key streams jointly determine the address of the first pixel to be swapped with the second pixel whose address is determined by the random numbers given through the third and fourth key streams. In this way, the pixels of the given image are swapped abundantly. The selection of both the pixels for swapping is purely arbitrary and random in character having no restriction of linearity and sequentiality as was done by other schemes previously. To create the diffusion effects, an XOR operation is carried out between this scrambled image and the key image formed through the fifth stream of random numbers given by the chaotic system. SHA-384 hash codes have been used in the proposed scheme to embed the plaintext sensitivity. The simulation and the extensive security analyses carried out at the end expressly portray the good security effects and the potential for the real world application of the reported scheme.
C1 [Bashir, Zia] Quaid i Azam Univ, Dept Math, Islamabad 45320, Pakistan.
   [Iqbal, Nadeem; Hanif, Muhammad] Natl Coll Business Adm & Econ, Dept Comp Sci, Lahore, Pakistan.
   [Iqbal, Nadeem] Imperial Coll Business Studies, Sch Comp & Informat Sci, Lahore, Pakistan.
   [Hanif, Muhammad] Bahria Univ, Dept Comp Sci, Lahore Campus, Lahore, Pakistan.
C3 Quaid I Azam University
RP Iqbal, N (corresponding author), Natl Coll Business Adm & Econ, Dept Comp Sci, Lahore, Pakistan.; Iqbal, N (corresponding author), Imperial Coll Business Studies, Sch Comp & Informat Sci, Lahore, Pakistan.
EM nadeem.iqbal537@gmail.com; nadeem.iqbal537@gmail.com;
   mhanif.bulc@bahria.edu.pk
RI Bashir, Zia/AAK-1971-2021
OI Iqbal, Nadeem/0000-0002-0954-5563; , Muhammad Hanif/0000-0002-6520-4464;
   Bashir, Zia/0000-0002-6051-8413; Hanif, Dr. Muhammad/0000-0003-2669-2327
CR Aqeel-ur-Rehman, 2018, OPTIK, V153, P117, DOI 10.1016/j.ijleo.2017.09.099
   Aqeel-ur-Rehman, 2016, MULTIMED TOOLS APPL, V75, P11241, DOI 10.1007/s11042-015-2851-7
   Babaei M, 2013, NAT COMPUT, V12, P101, DOI 10.1007/s11047-012-9334-9
   Bashir Zia, 2016, Pacific Science Review A: Natural Science and Engineering, V18, P254, DOI 10.1016/j.psra.2016.11.003
   Boriga R, 2014, SIGNAL PROCESS-IMAGE, V29, P887, DOI 10.1016/j.image.2014.04.001
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P15561, DOI 10.1007/s11042-016-3858-4
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JX, 2014, NONLINEAR DYNAM, V77, P1191, DOI 10.1007/s11071-014-1370-9
   Chen JX, 2013, OPT EXPRESS, V21, P27873, DOI 10.1364/OE.21.027873
   Chen L, 2017, NONLINEAR DYNAM, V87, P1797, DOI 10.1007/s11071-016-3153-y
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Floating-Point Working Group, 1985, IEEE STAND BIN FLOAT, P754
   Fu C., 2013, P 2013 IEEE INT C IE, P1
   Hanif M, 2020, IEEE ACCESS, V8, P123536, DOI 10.1109/ACCESS.2020.3004536
   Jain A, 2016, MULTIMED TOOLS APPL, V75, P5455, DOI 10.1007/s11042-015-2515-7
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Li CQ, 2011, SIGNAL PROCESS, V91, P949, DOI 10.1016/j.sigpro.2010.09.014
   Li S, 2004, IACR's Crypto ePrint Arch Rep, V374, P2004
   Li SJ, 2005, INT J BIFURCAT CHAOS, V15, P3119, DOI 10.1142/S0218127405014052
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu HJ, 2013, OPTIK, V124, P3527, DOI 10.1016/j.ijleo.2012.10.068
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Norouzi B, 2014, NONLINEAR DYNAM, V78, P995, DOI 10.1007/s11071-014-1492-0
   Özkaynak F, 2016, OPTIK, V127, P5190, DOI 10.1016/j.ijleo.2016.03.018
   Öztürk I, 2014, INT J BIFURCAT CHAOS, V24, DOI 10.1142/S0218127414501077
   Parvees MYM, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0611-5
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Song CY, 2013, OPTIK, V124, P3329, DOI 10.1016/j.ijleo.2012.11.002
   Sun SL, 2019, IEEE ACCESS, V7, P28539, DOI 10.1109/ACCESS.2019.2901870
   Taneja N, 2012, MULTIMED TOOLS APPL, V59, P775, DOI 10.1007/s11042-011-0775-4
   Hoang TM, 2018, OPTIK, V155, P366, DOI 10.1016/j.ijleo.2017.10.072
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wong KW, 2009, CHAOS SOLITON FRACT, V41, P2652, DOI 10.1016/j.chaos.2008.09.047
   Wu JH, 2018, SIGNAL PROCESS, V142, P292, DOI 10.1016/j.sigpro.2017.06.014
   Xiong Z, 2019, MULTIMED TOOLS APPL, P1
   Xiong ZG, 2019, MULTIMED TOOLS APPL, V78, P31035, DOI 10.1007/s11042-018-7081-3
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Ye RS, 2016, 2016 FIRST IEEE INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND THE INTERNET (ICCCI 2016), P374, DOI 10.1109/CCI.2016.7778946
   Zhang Q, 2014, AEU-INT J ELECTRON C, V68, P186, DOI 10.1016/j.aeue.2013.08.007
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P584, DOI 10.1016/j.cnsns.2012.08.010
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zhou GM, 2015, NEUROCOMPUTING, V169, P150, DOI 10.1016/j.neucom.2014.11.095
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 50
TC 20
Z9 20
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1029
EP 1054
DI 10.1007/s11042-020-09695-8
EA SEP 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566665500005
DA 2024-07-18
ER

PT J
AU Mzoughi, H
   Njeh, I
   Ben Slima, M
   Ben Hamida, A
   Mhiri, C
   Ben Mahfoudh, K
AF Mzoughi, Hiba
   Njeh, Ines
   Slima, Mohamed Ben
   Ben Hamida, Ahmed
   Mhiri, Chokri
   Mahfoudh, Kheireddine Ben
TI Towards a computer aided diagnosis (CAD) for brain MRI glioblastomas
   tumor exploration based on a deep convolutional neuronal networks
   (D-CNN) architectures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Magnetic resonance imaging (MR); Glioblastomas; Preprocessing;
   Convolutional neural networks (CNNs); Fully convolutional networks
   (FCNs); U-net; Segmentation; Classification
ID HISTOGRAM EQUALIZATION; IMAGE; NOISE; FEATURES
AB Manuel brain glioblastomas tumor exploration through MRI modalities is time-consuming. It is considered as a harmful and critical task due to highly inhomogeneous tumor regions composition. For this reason, clinicians recommend the Computer-Aided Diagnosis (CAD) tools to ensure a more accurate diagnostic. Based on convolutional Deep-Learning algorithms, this paper investigates a fully automatic CAD for brain Glioblastomas tumors exploration including three steps: pre-processing, segmentation, and finally classification. A denoising and an automatic contrast enhancement method have been applied to preprocess the MRI scans. A Multi-Modal Cascaded U-net architecture, based on Fully Convolutional deep Network (FCN), has been adopted for the Region of Interest (ROI) extraction and finally, Deep Convolutional Neural Network (D-CNN) architecture has been used to classify brain glioblastomas tumor into High-Grade (HG) and Low-Grade (LG). Experiments were performed on the Multimodal Brain Tumor Segmentation Challenge BraTS-2018 datasets benchmark. Several validations metric have been adopted to assess the CAD's performances. The Dice Metric (DM) parameter has been calculated between the obtained segmentation results and the available ground truth data. The accuracy parameter has been computed for classification performance evaluation. The higher DM and accuracy values could attest the performance and the efficiency of the proposed CAD tool.
C1 [Mzoughi, Hiba; Njeh, Ines; Slima, Mohamed Ben; Ben Hamida, Ahmed] Sfax Univ, ATMS Adv Technol Med & Signal, ENIS, Sfax, Tunisia.
   [Mzoughi, Hiba] Gabes Univ, Natl Engn Sch Gabes, Gabes, Tunisia.
   [Njeh, Ines] Gabes Univ, Higher Inst Comp Sci & Multimedia Gabes, Gabes, Tunisia.
   [Slima, Mohamed Ben] Sfax Univ, Natl Sch Elect & Telecommun Sfax, Sfax, Tunisia.
   [Ben Hamida, Ahmed] Sfax Univ, Natl Engn Sch Sfax, Sfax, Tunisia.
   [Mhiri, Chokri] Habib Bourguiba Univ Hosp, Dept Neurol, Sfax, Tunisia.
   [Mahfoudh, Kheireddine Ben] Habib Bourguiba Univ Hosp, Dept Radiol, Sfax, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Gabes; Universite de Gabes; Universite de Sfax; Universite
   de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS); Universite de Sfax;
   Hopital Habib Bourguiba; Universite de Sfax; Hopital Habib Bourguiba
RP Mzoughi, H (corresponding author), Sfax Univ, ATMS Adv Technol Med & Signal, ENIS, Sfax, Tunisia.; Mzoughi, H (corresponding author), Gabes Univ, Natl Engn Sch Gabes, Gabes, Tunisia.
EM hiba.mzoughi@yahoo.fr
CR Anila S, 2017, NATL ACAD SCI LETT, V40, P39, DOI 10.1007/s40009-016-0498-1
   Banerjee S, 2020, SN Comput. Sci, V1, P1, DOI [10.1007/s42979-020-00214-y, DOI 10.1007/S42979-020-00214-Y]
   Bhateja V, 2015, IEEE SENS J, V15, P6783, DOI 10.1109/JSEN.2015.2465935
   Brown MS., 2000, HDB MEDICAL IMAGING, V2, P399
   Chang YC, 2019, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, MINING AND SEMANTICS (WIMS 2019), DOI 10.1145/3326467.3326482
   Cheng J, 2010, INT C MED IM COMP CO
   Cho HH, 2018, PEERJ, V6, DOI 10.7717/peerj.5982
   Cho HH, 2017, IEEE ENG MED BIO, P3081, DOI 10.1109/EMBC.2017.8037508
   Coupé P, 2008, IEEE T MED IMAGING, V27, P425, DOI 10.1109/TMI.2007.906087
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Erden B., 2017, 3D CONVOLUTIONAL NEU
   Ge CJ, 2018, IEEE ENG MED BIO, P5894, DOI 10.1109/EMBC.2018.8513556
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Khan H, 2020, COMPUT COMMUN, V153, P196, DOI 10.1016/j.comcom.2020.01.013
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krupinski EA, 2004, RADIOLOGY, V231, P7, DOI 10.1148/radiol.2311031864
   Kwon D., 2014, MICCAI brain tumor segmentation challenge manuscripts, P18
   Latif G, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONIC ENGINEERING (ICEEE 2017), P333, DOI 10.1109/ICEEE2.2017.7935845
   Lazli L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051894
   Lit ZY, 2018, 2018 INTERNATIONAL CONFERENCE ON ALGORITHMS, COMPUTING AND ARTIFICIAL INTELLIGENCE (ACAI 2018), DOI [10.1109/INTMAG.2018.8508740, 10.1145/3302425.3302460]
   Liu HY, 2019, LECT NOTES COMPUT SC, V11846, P102, DOI 10.1007/978-3-030-33226-6_12
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Louis DN, 2016, ACTA NEUROPATHOL, V131, P803, DOI 10.1007/s00401-016-1545-1
   Ma JW, 2010, IEEE SIGNAL PROC MAG, V27, P118, DOI 10.1109/MSP.2009.935453
   Magudeeswaran V, 2017, INT J IMAG SYST TECH, V27, P153, DOI 10.1002/ima.22219
   Majumdar A, 2012, MAGN RESON IMAGING, V30, P9, DOI 10.1016/j.mri.2011.07.021
   MCVEIGH ER, 1985, MED PHYS, V12, P586, DOI 10.1118/1.595679
   Mlynarski P, 2019, COMPUT MED IMAG GRAP, V73, P60, DOI 10.1016/j.compmedimag.2019.02.001
   Mohan J, 2013, BIOMED SIGNAL PROCES, V8, P779, DOI 10.1016/j.bspc.2013.07.005
   Mohan J, 2014, BIOMED SIGNAL PROCES, V9, P56, DOI 10.1016/j.bspc.2013.10.007
   Moradmand H, 2020, J APPL CLIN MED PHYS, V21, P179, DOI 10.1002/acm2.12795
   Moussavi A, 2014, MAGN RESON MED, V71, P308, DOI 10.1002/mrm.24643
   Myronenko A, 2019, LECT NOTES COMPUT SC, V11384, P311, DOI 10.1007/978-3-030-11726-9_28
   Mzoughi H, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.4.044002
   Mzoughi H, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP)
   Nema S, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101641
   Nyúl LG, 2000, IEEE T MED IMAGING, V19, P143, DOI 10.1109/42.836373
   Oster J, 2015, ADV STATE SPACE METH
   Pan YH, 2015, IEEE ENG MED BIO, P699, DOI 10.1109/EMBC.2015.7318458
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Rezaei M., 2017, INT MICCAI BRAINL WO, P241
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roth HR, 2018, COMPUT MED IMAG GRAP, V66, P90, DOI 10.1016/j.compmedimag.2018.03.001
   Shabeer S, 2020, AIP C P
   Shahzadi I, 2018, IEEE EMBS CONF BIO, P633, DOI 10.1109/IECBES.2018.8626704
   Sijbers J, 2004, MAGNET RESON MED, V51, P586, DOI 10.1002/mrm.10728
   Tustison NJ, 2015, NEUROINFORMATICS, V13, P209, DOI 10.1007/s12021-014-9245-2
   Xue Y, 2018, NEUROINFORMATICS, V16, P383, DOI 10.1007/s12021-018-9377-x
   Yu JH, 2017, EUR RADIOL, V27, P3509, DOI 10.1007/s00330-016-4653-3
   Zhang LY, 2018, BIOMED ENG ONLINE, V17, DOI 10.1186/s12938-018-0604-3
   Zhang ZD, 2024, J MANAGE ORGAN, V30, P331, DOI [10.1007/s10278-020-00322-4, 10.1017/jmo.2020.5]
   Zhuge Y, 2020, MED PHYS, V47, P3044, DOI 10.1002/mp.14168
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 57
TC 6
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 899
EP 919
DI 10.1007/s11042-020-09786-6
EA SEP 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566318900009
OA Bronze
DA 2024-07-18
ER

PT J
AU Fu, K
   Peng, JS
   He, QW
   Zhang, HX
AF Fu, Kui
   Peng, Jiansheng
   He, Qiwen
   Zhang, Hanxiao
TI Single image 3D object reconstruction based on deep learning: A review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Single image 3D reconstruction; Deep learning; Computer vision; 3D shape
   representation
ID SHAPE RECONSTRUCTION; FACE RECONSTRUCTION; STEREO
AB The reconstruction of 3D object from a single image is an important task in the field of computer vision. In recent years, 3D reconstruction of single image using deep learning technology has achieved remarkable results. Traditional methods to reconstruct 3D object from a single image require prior knowledge and assumptions, and the reconstruction object is limited to a certain category or it is difficult to accomplish a good reconstruction from a real image. Although deep learning can solve these problems well with its own powerful learning ability, it also faces many problems. In this paper, we first discuss the challenges faced by applying the deep learning method to reconstruct 3D objects from a single image. Second, we comprehensively review encoders, decoders and training details used in 3D reconstruction of a single image. Then, the common datasets and evaluation metrics of single image 3D object reconstruction in recent years are introduced. In order to analyze the advantages and disadvantages of different 3D reconstruction methods, a series of experiments are used for comparison. In addition, we simply give some related application examples involving 3D reconstruction of a single image. Finally, we summarize this paper and discuss the future directions.
C1 [Fu, Kui; Peng, Jiansheng; He, Qiwen] Hechi Univ, Sch Phys & Mech & Elect Engn, Yizhou 546300, Guangxi, Peoples R China.
   [Peng, Jiansheng; Zhang, Hanxiao] Guangxi Univ Sci & Technol, Sch Elect & Informat Engn, Liuzhou 545006, Guangxi, Peoples R China.
C3 Hechi University; Guangxi University of Science & Technology
RP Peng, JS (corresponding author), Hechi Univ, Sch Phys & Mech & Elect Engn, Yizhou 546300, Guangxi, Peoples R China.; Peng, JS (corresponding author), Guangxi Univ Sci & Technol, Sch Elect & Informat Engn, Liuzhou 545006, Guangxi, Peoples R China.
EM sheng120410@163.com
OI Peng, Jiansheng/0000-0002-5749-3403; Fu, Kui/0000-0001-7824-2454
FU Development Research Center of Guangxi Relatively Sparse-populated
   Minorities [GXRKJSZ201901]; Natural Science Foundation of Guangxi
   Province [2018GXNSFAA281164]; project of outstanding thousand young
   teachers' training in higher education institutions of Guangxi, Guangxi
   Colleges and Universities Key Laboratory Breeding Base of System Control
   and Information Processing
FX The authors are highly thankful to the Development Research Center of
   Guangxi Relatively Sparse-populated Minorities (ID: GXRKJSZ201901), to
   the Natural Science Foundation of Guangxi Province
   (NO.2018GXNSFAA281164),This research was financially supported by the
   project of outstanding thousand young teachers' training in higher
   education institutions of Guangxi, Guangxi Colleges and Universities Key
   Laboratory Breeding Base of System Control and Information Processing.
CR Alldieck T, 2019, PROC CVPR IEEE, P1175, DOI 10.1109/CVPR.2019.00127
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   Atick JJ, 1996, NEURAL COMPUT, V8, P1321, DOI 10.1162/neco.1996.8.6.1321
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Baka N, 2011, MED IMAGE ANAL, V15, P840, DOI 10.1016/j.media.2011.04.001
   Bane C, 2017, INT CONF 3D VISION, P412, DOI 10.1109/3DV.2017.00054
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Chang Angel X., 2015, arXiv
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen W., 2019, P INT C NEUR INF PRO, P9605
   Chen ZQ, 2019, PROC CVPR IEEE, P5932, DOI 10.1109/CVPR.2019.00609
   Chinaev N., 2018, EUR C COMP VIS ECCV
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   Dekhtiar J, 2018, COMPUT IND, V100, P227, DOI 10.1016/j.compind.2018.04.005
   Dou PF, 2018, IMAGE VISION COMPUT, V80, P80, DOI 10.1016/j.imavis.2018.09.004
   Dou P, 2017, PROC CVPR IEEE, P1503, DOI 10.1109/CVPR.2017.164
   Dovgard R, 2004, LECT NOTES COMPUT SC, V3022, P99
   Eckart B, 2016, P IEEE C COMP VIS PA, P5496
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Feng Y, 2018, LECT NOTES COMPUT SC, V11218, P557, DOI 10.1007/978-3-030-01264-9_33
   Furukawa Y, 2010, PROC CVPR IEEE, P1434, DOI 10.1109/CVPR.2010.5539802
   Gadelha M, 2017, INT CONF 3D VISION, P402, DOI 10.1109/3DV.2017.00053
   Genova K, 2018, PROC CVPR IEEE, P8377, DOI 10.1109/CVPR.2018.00874
   Girdhar R, 2016, LECT NOTES COMPUT SC, V9910, P484, DOI 10.1007/978-3-319-46466-4_29
   Gkioxari G, 2019, IEEE I CONF COMP VIS, P9784, DOI 10.1109/ICCV.2019.00988
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Gwak J, 2017, INT CONF 3D VISION, P263, DOI 10.1109/3DV.2017.00038
   Ham H., 2019, International Journal of Electrical and Computer Engineering, V9, P2394, DOI [10.11591/ijece.v9i4.pp2394-2402, DOI 10.11591/IJECE.V9I4.PP2394-2402]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hepp B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3233794
   Huang PH, 2018, PROC CVPR IEEE, P2821, DOI 10.1109/CVPR.2018.00298
   Huang QX, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766890
   Insafutdinov E, 2018, ADV NEUR IN, V31
   Jack Dominic, 2018, ICCV, P317
   Jackson AS, 2017, IEEE I CONF COMP VIS, P1031, DOI 10.1109/ICCV.2017.117
   Jackson Aaron S, 2018, ECCVW
   Jeon YH, 2017, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2017.200
   Jiang L, 2018, LECT NOTES COMPUT SC, V11212, P820, DOI 10.1007/978-3-030-01237-3_49
   Jiang L, 2018, IEEE T IMAGE PROCESS, V27, P4756, DOI 10.1109/TIP.2018.2845697
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Jongmoo Choi, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3959, DOI 10.1109/ICPR.2010.963
   Kanazawa A, 2018, LECT NOTES COMPUT SC, V11219, P386, DOI 10.1007/978-3-030-01267-0_23
   Kar A, 2015, PROC CVPR IEEE, P1966, DOI 10.1109/CVPR.2015.7298807
   Kato H, 2019, PROC CVPR IEEE, P9770, DOI 10.1109/CVPR.2019.01001
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   Kemelmacher-Shlizerman I, 2013, IEEE I CONF COMP VIS, P3256, DOI 10.1109/ICCV.2013.404
   Khan SH, 2019, PROC CVPR IEEE, P9731, DOI 10.1109/CVPR.2019.00997
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   King DB, 2015, ACS SYM SER, V1214, P1
   Klokov R, 2017, P IEEE INT C COMP VI, P2380
   Kolotouros N, 2019, PROC CVPR IEEE, P4496, DOI 10.1109/CVPR.2019.00463
   Kulon D, 2019, ARXIV190501326
   Larsen A.B.L, 2015, ARXIV151209300, DOI DOI 10.3390/RS12223815
   Le T, 2018, PROC CVPR IEEE, P9204, DOI 10.1109/CVPR.2018.00959
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li Chun-Liang, 2018, ARXIV181005795, P2
   Li K, 2018, IEEE ANN INT CONF CY, P498, DOI 10.1109/CYBER.2018.8688272
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lim JJ, 2013, IEEE I CONF COMP VIS, P2992, DOI 10.1109/ICCV.2013.372
   Lin CH, 2018, AAAI CONF ARTIF INTE, P7114
   Liu SC, 2019, IEEE I CONF COMP VIS, P7707, DOI 10.1109/ICCV.2019.00780
   Loh A. M., 2005, P BRIT MACH VIS C, P69
   Tran L, 2018, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2018.00767
   Lun ZL, 2017, INT CONF 3D VISION, P67, DOI 10.1109/3DV.2017.00018
   MANDIKAL P, 2018, ARXIV180707796
   Mandikal P, 2019, IEEE WINT CONF APPL, P1052, DOI 10.1109/WACV.2019.00117
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Michalkiewicz M., 2019, ARXIV190106802
   Montefusco LB, 2011, IEEE T MED IMAGING, V30, P1064, DOI 10.1109/TMI.2010.2068306
   Navaneet KL, 2019, AAAI CONF ARTIF INTE, P8819
   Niu CJ, 2018, PROC CVPR IEEE, P4521, DOI 10.1109/CVPR.2018.00475
   Omran M, 2018, INT CONF 3D VISION, P484, DOI 10.1109/3DV.2018.00062
   Oswald MR, 2013, INNOVATIONS SHAPE AN, P343, DOI DOI 10.1007/978-3-642-34141-0
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Pavlakos G, 2018, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2018.00055
   Pavlakos G, 2017, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2017.138
   Pollefeys M, 2000, ISPRS J PHOTOGRAMM, V55, P251, DOI 10.1016/S0924-2716(00)00023-X
   Pontes JK, 2019, LECT NOTES COMPUT SC, V11361, P365, DOI 10.1007/978-3-030-20887-5_23
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Radford A., 2015, ARXIV
   Rezende D.J., 2016, ADV NEURAL INFORM PR, P4996
   Richardson E, 2017, PROC CVPR IEEE, P5553, DOI 10.1109/CVPR.2017.589
   Richter SR, 2018, PROC CVPR IEEE, P1936, DOI 10.1109/CVPR.2018.00207
   Riegler G, 2017, INT CONF 3D VISION, P57, DOI 10.1109/3DV.2017.00017
   Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701
   Rock J, 2015, PROC CVPR IEEE, P2484, DOI 10.1109/CVPR.2015.7298863
   Samaras D, 2000, PROC CVPR IEEE, P480, DOI 10.1109/CVPR.2000.855858
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Sharma A, 2016, LECT NOTES COMPUT SC, V9915, P236, DOI 10.1007/978-3-319-49409-8_20
   Sharma SK, 2020, INT J ADV APPL SCI, V7, P1, DOI 10.21833/ijaas.2020.05.001
   Shen W, 2019, P IEEE C COMP VIS PA, P4471
   Shi XH, 2018, INT C DIGITAL HOME, P187, DOI 10.1109/ICDH.2018.00041
   Shin D., 2019, P IEEE C COMPUTER VI, P39
   Shin D, 2018, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2018.00323
   Sinha A, 2017, PROC CVPR IEEE, P791, DOI 10.1109/CVPR.2017.91
   Smith E, 2018, ADV NEURAL INFORM PR, P6479
   Smith Edward J., 2017, P MACH LEARN RES, V78, P87
   Smith Edward J, 2019, ARXIV190111461
   Soltani AA, 2017, PROC CVPR IEEE, P2511, DOI 10.1109/CVPR.2017.269
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28
   Song SR, 2014, LECT NOTES COMPUT SC, V8694, P634, DOI 10.1007/978-3-319-10599-4_41
   Sra M, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P191, DOI 10.1145/2993369.2993372
   Sun XY, 2018, PROC CVPR IEEE, P2974, DOI 10.1109/CVPR.2018.00314
   Tatarchenko M, 2019, PROC CVPR IEEE, P3400, DOI 10.1109/CVPR.2019.00352
   Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230
   Tchapmi LP, 2019, PROC CVPR IEEE, P383, DOI 10.1109/CVPR.2019.00047
   Tulsiani S, 2017, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.2017.30
   Tulsiani S, 2017, PROC CVPR IEEE, P1466, DOI 10.1109/CVPR.2017.160
   Varol G, 2018, LECT NOTES COMPUT SC, V11211, P20, DOI 10.1007/978-3-030-01234-2_2
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang HQ, 2019, AAAI CONF ARTIF INTE, P8941
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Wang PS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073608
   Wang Peng-Shuai, 2018, ACM T GRAPH SIGGRAPH, V37, P6
   Wang W., 2019, ARXIV190510711
   Wang WY, 2019, PROC CVPR IEEE, P1038, DOI 10.1109/CVPR.2019.00113
   Wei Y, 2019, PROC CVPR IEEE, P9643, DOI 10.1109/CVPR.2019.00988
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu JJ, 2018, LECT NOTES COMPUT SC, V11215, P673, DOI 10.1007/978-3-030-01252-6_40
   Wu JJ, 2016, ADV NEUR IN, V29
   Wu YQ, 2020, INT J COOP INF SYST, V29, DOI 10.1142/S0218843020400067
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Xiang Y, 2016, LECT NOTES COMPUT SC, V9912, P160, DOI 10.1007/978-3-319-46484-8_10
   Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101
   Xiao JX, 2016, INT J COMPUT VISION, V119, P3, DOI 10.1007/s11263-014-0748-y
   Xie H., 2019, ARXIV190111153
   Yan N, 2018, GREEN ENERGY ENVIRON, V3, P309, DOI 10.1016/j.gee.2018.09.003
   Yan XC, 2016, ADV NEUR IN, V29
   Yang B, 2020, INT J COMPUT VISION, V128, P53, DOI 10.1007/s11263-019-01217-w
   Yang X., 2018, ARXIV180503081
   Yang YQ, 2018, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2018.00029
   Yu LQ, 2018, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2018.00295
   Yuniarti A, 2019, PROCEEDINGS OF 2019 12TH INTERNATIONAL CONFERENCE ON INFORMATION & COMMUNICATION TECHNOLOGY AND SYSTEM (ICTS), P327, DOI [10.1109/icts.2019.8850991, 10.1109/ICTS.2019.8850991]
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zeng W., 2018, ARXIV181201402
   Zhang DJ, 2016, INTEGR COMPUT-AID E, V23, P31, DOI 10.3233/ICA-150499
   Zhang J, 2017, NEUROCOMPUTING, V257, P67, DOI 10.1016/j.neucom.2016.11.062
   Zhang Xiuming., 2018, ADV NEURAL INFORM PR
   Zhao RQ, 2016, LECT NOTES COMPUT SC, V9914, P590, DOI 10.1007/978-3-319-48881-3_41
   Zheng ZR, 2019, IEEE I CONF COMP VIS, P7738, DOI 10.1109/ICCV.2019.00783
   Zhou C, 2017, INT WIREL COMMUN, P85, DOI 10.1109/IWCMC.2017.7986267
   Zhu H, 2019, PROC CVPR IEEE, P4486, DOI 10.1109/CVPR.2019.00462
   Zou CH, 2017, IEEE I CONF COMP VIS, P900, DOI 10.1109/ICCV.2017.103
NR 151
TC 57
Z9 62
U1 45
U2 385
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 463
EP 498
DI 10.1007/s11042-020-09722-8
EA SEP 2020
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000565837600002
DA 2024-07-18
ER

PT J
AU Das, D
   Nayak, DR
   Dash, R
   Majhi, B
AF Das, Dibyasundar
   Nayak, Deepak Ranjan
   Dash, Ratnakar
   Majhi, Banshidhar
TI MJCN: Multi-objective Jaya Convolutional Network for handwritten optical
   character recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-handcrafted feature; Multi-objective Jaya optimizer; Handwritten
   character recognition; Feature extraction; Convolution
ID BANGLA; CLASSIFIER; SYSTEM; MACHINE
AB In recent years, the non-handcrafted feature extraction methods have gained increasing popularity for solving pattern classification tasks due to their inherent ability to extract robust features and handle outliers. However, the design of such features demands a large set of training data. Meta-heuristic optimization schemes can facilitate feature learning even with a small amount of training data. This paper presents a new feature learning mechanism called multi-objective Jaya convolutional network (MJCN) that attempts to learn meaningful features directly from the images. The proposed scheme, unlike the convolutional neural networks, comprises a convolution layer, a multiplication layer, an activation layer and an optimizer known as multi-objective Jaya optimizer (MJO). The convolution layer searches meaningful patterns in an image through the local neighborhood connections and the multiplication layer projects the convolutional response to a more compact feature space. The weights used in these layers are initialized randomly and MJO is then introduced to optimize the weights. The main objective of MJO is to maximize the inter-class distance and minimize the intra-class variance. The feature vectors are finally derived using the optimized weights. The derived features are finally fed to a set of standard classifiers for recognition of characters. The performance of the proposed model is evaluated on various benchmark datasets, namely, NITR Odia handwritten character, ISI Kolkata Odia numeral, ISI Kolkata Bangla numeral, and MNIST as well as a newly developed dataset NITR Bangla numeral. The experimental results show that the proposed scheme outperforms other state-of-the-art approaches in terms of recognition accuracy.
C1 [Das, Dibyasundar; Nayak, Deepak Ranjan; Dash, Ratnakar; Majhi, Banshidhar] Natl Inst Technol, Dept Comp Sci & Engn, Pattern Recognit Lab, Rourkela 769008, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Nayak, DR (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Pattern Recognit Lab, Rourkela 769008, India.
EM depakranjannayak@gmail.com
RI Das, Dibyasundar/IYT-4023-2023; Dash, Ratnakar/F-1498-2018; Nayak,
   Deepak Ranjan/AED-5548-2022
OI Das, Dibyasundar/0000-0002-0285-2560; Nayak, Deepak
   Ranjan/0000-0002-8929-5778
CR [Anonymous], 2014, INDIAN J SCI TECHNOL
   [Anonymous], 2009, P 26 ANN INT C MACH, DOI [10.1145/1553374.1553439, DOI 10.1145/1553374.1553439]
   [Anonymous], 2014, **DROPPED REF**
   Bag S, 2013, SADHANA-ACAD P ENG S, V38, P133, DOI 10.1007/s12046-013-0121-9
   Basu S, 2010, PATTERN RECOGN, V43, P3507, DOI 10.1016/j.patcog.2010.05.018
   Battacharya U, 2005, PROC INT CONF DOC, P789
   Bhalerao M, 2018, L N COMPUT VIS BIOME, V28, P45, DOI 10.1007/978-3-319-71767-8_4
   Bhattacharya U, 2009, IEEE T PATTERN ANAL, V31, P444, DOI 10.1109/TPAMI.2008.88
   Bhowmik TK, 2006, ICIT 2006: 9TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, PROCEEDINGS, P105
   Cecotti H, 2016, IEEE IJCNN, P3628, DOI 10.1109/IJCNN.2016.7727666
   Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052
   Das N, 2015, PATTERN RECOGN, V48, P2054, DOI 10.1016/j.patcog.2014.12.011
   Dash KS, 2016, PATTERN RECOGN LETT, V83, P413, DOI 10.1016/j.patrec.2016.05.031
   Dash KS, 2014, IEEE REGION 10 SYMP, P531, DOI 10.1109/TENCONSpring.2014.6863091
   Dash KS, 2016, PATTERN ANAL APPL, P1
   DUTTA A, 1993, PATTERN RECOGN, V26, P1757, DOI 10.1016/0031-3203(93)90174-U
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Keysers D, 2007, IEEE T PATTERN ANAL, V29, P1422, DOI 10.1109/TPAMI.2007.1153
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu CL, 2009, PATTERN RECOGN, V42, P3287, DOI 10.1016/j.patcog.2008.10.007
   Mahmoud SA, 2011, APPL INTELL, V35, P445, DOI 10.1007/s10489-010-0235-2
   Mahto Manoj Kumar, 2011, INT J APPL SCI TECHN, V1, P17
   Mishra S, 2016, IEEE T SUSTAIN ENERG, V7, P1672, DOI 10.1109/TSTE.2016.2570256
   Mishra T. K., 2016, INT J COMPUTATIONAL, V6, P168, DOI DOI 10.1504/IJCVR.2016.073765
   Mishra TK, 2014, FRONT COMPUT SCI-CHI, V8, P916, DOI 10.1007/s11704-014-3354-9
   Mishra TK, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P790, DOI 10.1109/ICACCI.2013.6637276
   Mohammadpour R, 2016, NAT HAZARDS, V80, P1891, DOI 10.1007/s11069-015-2044-8
   Mohaparata R.K., 2015, 2015 International Conference on Computing, Communication and Security (ICCCS),IEEE, P1
   Mohapatra RK, 2017, INT J APPL PATTERN R, V4, P44, DOI 10.1504/IJAPR.2017.082658
   Mohapatra RK, 2015, INT J APPL PATTERN R, V2, P235, DOI 10.1504/IJAPR.2015.073854
   Nayak DR, 2018, MULTIMED TOOLS APPL, V77, P22705, DOI 10.1007/s11042-017-5281-x
   Nayaka DR, 2019, APPL SOFT COMPUT, V83, DOI 10.1016/j.asoc.2019.105626
   Nebti S, 2013, APPL INTELL, V38, P146, DOI 10.1007/s10489-012-0362-z
   Pal U, 2006, IETE J RES, V52, P27, DOI 10.1080/03772063.2006.11416437
   Pal U, 2007, 10 INT C INFORM TECH, P227, DOI [10.1109/ICIT.2007.63, DOI 10.1109/ICIT.2007.63]
   Pal U, 2003, INT C KNOWL BAS COMP, P11
   Purkait P., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P363, DOI 10.1109/ICFHR.2010.63
   Rao R., 2016, Int J Ind Eng Comput, V7, P19, DOI [DOI 10.5267/J.IJIEC.2015.8.004, 10.5267/j.ijiec.2015.8.004]
   Roy K, 2005, INDICON 2005 PROCEEDINGS, P570
   Roy K, 2005, PROC INT CONF DOC, P770, DOI 10.1109/ICDAR.2005.183
   Sampath AK, 2017, SADHANA-ACAD P ENG S, V42, P1513, DOI 10.1007/s12046-017-0706-9
   Sethy A., 2019, RECENT PATENTS ENG, V13, P136, DOI [10.2174/1872212112666180601085544, DOI 10.2174/1872212112666180601085544]
   Sethy A, 2018, ADV INTELL SYST COMP, V563, P187, DOI 10.1007/978-981-10-6872-0_18
   Tang JX, 2016, IEEE T NEUR NET LEAR, V27, P809, DOI 10.1109/TNNLS.2015.2424995
   Wen Y, 2007, PATTERN RECOGN, V40, P99, DOI 10.1016/j.patcog.2006.07.001
   Wen Y, 2012, EXPERT SYST APPL, V39, P948, DOI 10.1016/j.eswa.2011.07.092
   Xie TS, 2019, APPL POWER ELECT CO, P1, DOI 10.1109/APEC.2019.8721951
NR 49
TC 7
Z9 7
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 33023
EP 33042
DI 10.1007/s11042-020-09457-6
EA AUG 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000564527000009
DA 2024-07-18
ER

PT J
AU Guleria, V
   Mishra, DC
AF Guleria, Vandana
   Mishra, D. C.
TI A new multi-layer RGB image encryption algorithm based on Diffie-Hellman
   cryptography associated with FrDCT and arnold transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diffie-Hellman key agreement; Arnold transform; Fractional discrete
   cosine transform; Image encryption and image decryption
ID FRACTIONAL FOURIER-TRANSFORM; DISCRETE COSINE TRANSFORM; GYRATOR
   TRANSFORM; OPTICAL ENCRYPTION; DOMAIN
AB To protect sensitive data from unauthorized access is a prime agenda nowadays. Cryptography helps us to achieve this goal. An image encryption algorithm for the secure transmission of image data over a public communication channel is proposed. The encryption algorithm uses encryption scheme based on Diffie-Hellman key agreement protocol, fractional discrete cosine transform and Arnold transform. The earlier developed encryption algorithms, pixel values are not disturbed. They are only shifted to other coordinate positions. However, in our approach, pixel values are both disturbed and moved to different coordinate locations. The proposed scheme is secure in both time and frequency domain and gives multi-layer security for RGB image data. In contrast to similar schemes available in the literature, the security of our proposed technique depends upon shared secret keys, and their proper arrangements. The proposed encryption algorithm is susceptible to secret keys. A complete simulation analysis is provided to verify the validity of the algorithm.
C1 [Guleria, Vandana] Birla Inst Technol Mesra, Dept Math, Ranchi, Bihar, India.
   [Mishra, D. C.] Govt PG Coll Jaiharikhal, Dept Math, Lansdowne, Uttarakhand, India.
C3 Birla Institute of Technology Mesra
RP Guleria, V (corresponding author), Birla Inst Technol Mesra, Dept Math, Ranchi, Bihar, India.
EM vandana.math@gmail.com; deepiitdelhi@gmail.com
CR Abuturab MR, 2012, OPT LASER ENG, V50, P1383, DOI 10.1016/j.optlaseng.2012.04.011
   Abuturab MR, 2012, OPT LASER ENG, V50, P772, DOI 10.1016/j.optlaseng.2011.12.006
   Alfalou A, 2010, OPT LETT, V35, P2185, DOI 10.1364/OL.35.002185
   Alfalou A, 2010, OPT LETT, V35, P1914, DOI 10.1364/OL.35.001914
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Cariolaro G, 2002, IEEE T SIGNAL PROCES, V50, P902, DOI 10.1109/78.992138
   Chen LF, 2008, OPTIK, V119, P286, DOI 10.1016/j.ijleo.2006.11.005
   Chen LF, 2009, OPT COMMUN, V282, P3433, DOI 10.1016/j.optcom.2009.05.044
   Chen LF, 2006, OPT LETT, V31, P3438, DOI 10.1364/OL.31.003438
   Chen W, 2009, OPT COMMUN, V282, P3680, DOI 10.1016/j.optcom.2009.06.014
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Gantmakher F. R., 2000, THEORY MATRICES, V131
   Hahn J, 2006, OPT EXPRESS, V14, P11103, DOI 10.1364/OE.14.011103
   Hennelly B, 2003, OPT LETT, V28, P269, DOI 10.1364/OL.28.000269
   Joshi AB, 2020, J MOD OPTIC, V67, P933, DOI 10.1080/09500340.2020.1789233
   Joshi AB, 2020, OPT LASER ENG, V133, DOI 10.1016/j.optlaseng.2020.106139
   Joshi M, 2008, OPT COMMUN, V281, P5713, DOI 10.1016/j.optcom.2008.08.024
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Liu ZJ, 2009, OPT COMMUN, V282, P518, DOI 10.1016/j.optcom.2008.10.068
   MERKLE RC, 1978, COMMUN ACM, V21, P294, DOI 10.1145/359460.359473
   Mishra DC, 2017, J INF SECUR APPL, V37, P65, DOI 10.1016/j.jisa.2017.09.006
   Mishra DC, 2013, APPL APPL MATH, V8, P777
   Mishra DC, 2014, FRACTALS, V22, DOI 10.1142/S0218348X1450011X
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Shan MG, 2012, OPT COMMUN, V285, P4227, DOI 10.1016/j.optcom.2012.06.023
   Shi XY, 2013, OPT COMMUN, V306, P90, DOI 10.1016/j.optcom.2013.05.041
   Singh N, 2009, OPT LASER ENG, V47, P539, DOI 10.1016/j.optlaseng.2008.10.013
   Sui LS, 2013, OPT LASER TECHNOL, V48, P530, DOI 10.1016/j.optlastec.2012.11.020
   Sui LS, 2013, OPT LASER TECHNOL, V48, P117, DOI 10.1016/j.optlastec.2012.10.016
   Wang XG, 2011, OPT COMMUN, V284, P148, DOI 10.1016/j.optcom.2010.09.034
   Yong-Liang XA, 2011, OPT LASER TECHNOL, V43, P889, DOI 10.1016/j.optlastec.2010.10.003
   Yu SS, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105816
   Zhang SQ, 1999, MICROW OPT TECHN LET, V21, P318, DOI 10.1002/(SICI)1098-2760(19990605)21:5<318::AID-MOP4>3.0.CO;2-A
   Zhang Y, 2002, OPT COMMUN, V202, P277, DOI 10.1016/S0030-4018(02)01113-6
   Zhang YS, 2013, OPT LASER ENG, V51, P472, DOI 10.1016/j.optlaseng.2012.11.001
   Zhong Z, 2012, OPT COMMUN, V285, P584, DOI 10.1016/j.optcom.2011.11.025
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-2104-6
   Zhou NR, 2012, OPT LASER TECHNOL, V44, P2270, DOI 10.1016/j.optlastec.2012.02.027
NR 38
TC 6
Z9 6
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 33119
EP 33160
DI 10.1007/s11042-020-09615-w
EA AUG 2020
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000564527000001
DA 2024-07-18
ER

PT J
AU Feng, XM
   Li, JJ
   Hua, Z
AF Feng, Xiaomei
   Li, Jinjiang
   Hua, Zhen
TI Low-light image enhancement algorithm based on an atmospheric physical
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-light image; Low-light enhancement; Low-light imaging model
ID HISTOGRAM EQUALIZATION; QUALITY ASSESSMENT; CONSTRAINT
AB Under low illumination, the colour constancy of human vision can be used for correctly determining the colour of objects according to the fixed reflection coefficient of external light and objects. However, video image acquisition equipment does not implement the colour constancy characteristic of the human visual system. Under low illumination, only a small amount of light is reflected from the surface of the imaged object; as a result, the captured image is underexposed. After statistical analysis of low-light images, these inverted underexposed images appear foggy. Inversion is a uniform and reversible operation that is performed on the entire image. Hereby, a method is proposed for resolving low-light images using conventional physical models. First, a low-light image is inverted for obtaining a foggy image. Subsequently, a pyramid-type dense residual block network and a dark channel prior K-means classification method are applied to the foggy image, to calculate the transmission and atmospheric light. Finally, the parameters obtained from this solution are incorporated into the low-light imaging model to obtain a clear image. We subjectively and qualitatively analysed the experimental results, and used information entropy and average gradient for objective quantitative analysis. We demonstrate that the algorithm improves the overall brightness and contrast of the imaged scenes, and the obtained enhanced images are clear and natural.
C1 [Feng, Xiaomei; Li, Jinjiang; Hua, Zhen] Shandong Technol & Business Univ, Sch Informat & Elect Engn, Yantai 264005, Peoples R China.
   [Feng, Xiaomei; Li, Jinjiang] Coinnovat Ctr Shandong Coll & Univ Future Intell, Yantai 264005, Peoples R China.
C3 Shandong Technology & Business University
RP Li, JJ (corresponding author), Shandong Technol & Business Univ, Sch Informat & Elect Engn, Yantai 264005, Peoples R China.; Li, JJ (corresponding author), Coinnovat Ctr Shandong Coll & Univ Future Intell, Yantai 264005, Peoples R China.
EM xiaomeifeng19@gmail.com; lijinjiang@gmail.com; huazhen@sdtbu.edu.cn
RI Hua, Zhen/AGN-6068-2022; Hua, Zhen/ABG-8734-2021
FU National Natural Science Foundation of China [61772319, 61976125,
   61873177, 61773244]; Shandong Natural Science Foundation of China
   [ZR2017MF049]
FX The authors acknowledge the National Natural Science Foundation of China
   (Grant nos. 61772319, 61976125, 61873177 and 61773244), and Shandong
   Natural Science Foundation of China (Grant no. ZR2017MF049).
CR Abu Arqub O, 2020, SOFT COMPUT, V24, P12501, DOI 10.1007/s00500-020-04687-0
   Abu Arqub O, 2017, SOFT COMPUT, V21, P7191, DOI 10.1007/s00500-016-2262-3
   Abu Arqub O, 2017, NEURAL COMPUT APPL, V28, P1591, DOI 10.1007/s00521-015-2110-x
   Abu Arqub O, 2016, SOFT COMPUT, V20, P3283, DOI 10.1007/s00500-015-1707-4
   [Anonymous], 2017, IJCAI
   [Anonymous], 2018, BRIT MACH VIS C
   [Anonymous], 2001, RET IM PROC
   [Anonymous], 2016, ARXIV161201105CS
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Celik T, 2011, IEEE T IMAGE PROCESS, V20, P3431, DOI 10.1109/TIP.2011.2157513
   Chandrasekharan R, 2018, IEEE SIGNAL PROC LET, V25, P813, DOI 10.1109/LSP.2018.2812861
   Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347
   Conde MH, 2016, IEEE PHOTONICS J, V8, DOI 10.1109/JPHOT.2016.2528122
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong XC, 2011, INT C PAR DISTRIB SY, P9, DOI 10.1109/ICPADS.2011.115
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Kim TK, 1998, IEEE T CONSUM ELECTR, V44, P82, DOI 10.1109/30.663733
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Lee C, 2012, IEEE IMAGE PROC, P965, DOI 10.1109/ICIP.2012.6467022
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li J., 2018, IEEE ACCESS, P1
   Li LL, 2018, J MED IMAG HEALTH IN, V8, P431, DOI 10.1166/jmihi.2018.2328
   Li L, 2015, IEEE IMAGE PROC, P3730, DOI 10.1109/ICIP.2015.7351501
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Loh YP, 2019, COMPUT VIS IMAGE UND, V178, P30, DOI 10.1016/j.cviu.2018.10.010
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Ma JX, 2017, INT J MOD PHYS B, V31, DOI 10.1142/S0217979217440775
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Omer I., 2004, P IEEE INT C CVPR, V2, P11
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Shen L., 2017, ARXIV PREPRINT ARXIV, P171102488
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Huynh-The T, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-44
   Vonikakis V, 2018, MULTIMED TOOLS APPL, V77, P9211, DOI 10.1007/s11042-017-4783-x
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang T, 2016, INFORM SCIENCES, V358, P92, DOI 10.1016/j.ins.2016.04.017
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Xu Z, 2018, BRIT MACH VIS C, P243
   Ying ZQ, 2017, LECT NOTES COMPUT SC, V10425, P36, DOI 10.1007/978-3-319-64698-5_4
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang H, 2018, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2018.00079
   Zhang WB, 2018, MULTIMED TOOLS APPL, V77, P2947, DOI 10.1007/s11042-017-4547-7
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
NR 57
TC 10
Z9 11
U1 3
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32973
EP 32997
DI 10.1007/s11042-020-09562-6
EA AUG 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000567296900003
DA 2024-07-18
ER

PT J
AU Khan, AH
   Zubair, M
AF Khan, Ayaz H.
   Zubair, Muhammad
TI Classification of multi-lingual tweets, into multi-class model using
   Naive Bayes and semi-supervised learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Twitter; Sentiment analysis; Sentiment classification; Semi-supervised
   learning
AB Twitter is a social media platform which has been proven to be a great tool for insights of emotions about products, policies etc. through a 280-character message called tweet, containing direct and unfiltered emotions by a large amount of user population. Twitter has attracted the attention of many researchers owing to the fact that every tweet is by default, public in nature which is not the case with Facebook. This paper proposes a model for multi-lingual (English and Roman Urdu) classification of tweets over diversely ranged classes (non-hierarchical architecture). Previous work in tweet classification is narrowly focused either on single language or either on uniform set of classes at most (Positive, Extremely Positive, Negative and Extremely Negative). The proposed model is based on semi-supervised learning and proposed feature selection approach makes it less dependent and highly adaptive for grabbing trending terms. This makes it a strong contender of choice for streaming data. In the methodology, using Naive Bayes learning algorithm for each phase, obtained remarkable accuracy of up to 87.16% leading from both KNN and SVM models which are popular for NLP and Text classification domains.
C1 [Khan, Ayaz H.] Habib Univ, Dept Comp Sci, Karachi, Pakistan.
   [Zubair, Muhammad] Karachi Inst Econ & Technol, Coll Comp & Informat & Sci, Karachi, Pakistan.
RP Khan, AH (corresponding author), Habib Univ, Dept Comp Sci, Karachi, Pakistan.
EM ayaz.hassan@sse.habib.edu.pk; mzubairz700@gmail.com
RI Khan, Ayaz ul Hassan/E-4025-2010
OI Khan, Ayaz ul Hassan/0000-0003-1167-7319
CR Amalarethinam D. I. George, 2017, 2017 2nd International Conference on Computing and Communications Technologies (ICCCT), P69, DOI 10.1109/ICCCT2.2017.7972250
   Bhavitha BK, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P216, DOI 10.1109/ICICCT.2017.7975191
   Bifet A, 2010, LECT NOTES ARTIF INT, V6332, P1, DOI 10.1007/978-3-642-16184-1_1
   Bilal M, 2016, J KING SAUD UNIV-COM, V28, P330, DOI 10.1016/j.jksuci.2015.11.003
   Blessy Trencia Lincy S. S., 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 898), P395, DOI 10.1007/978-981-13-3393-4_41
   Deshwal A, 2016, INT CONF RELI INFO, P251, DOI 10.1109/ICRITO.2016.7784960
   Essam Kazem Al-Yasiri AAA, 2019, INT J ADV COMPUT TEC, V8, P3150
   Go A., 2009, Twitter sentiment classification using distant supervision, V150, DOI DOI 10.1016/J.SEDGEO.2006.07.004
   Gupta B., 2017, International Journal of Computer Applications, V165, P29, DOI DOI 10.5120/IJCA2017914022
   Harshita Mandloi SM., 2018, ENG INFORM TECHNOL I, V3, P428
   Hartmann T, 2011, P 7 INT C DAT MIN DM
   Hasan M, 2018, J INF SCI, V44, P443, DOI 10.1177/0165551517698564
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Keramatfar A, 2019, J INF SCI, V45, P3, DOI 10.1177/0165551518761013
   Leskovec J, 2014, MINING OF MASSIVE DATASETS, 2ND EDITION, P1
   Liu YH, 2018, J INF SCI, V44, P594, DOI 10.1177/0165551517722741
   Pandarachalil R, 2015, COGN COMPUT, V7, P254, DOI 10.1007/s12559-014-9310-z
   Parveen H, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT), P416, DOI 10.1109/ICATCCT.2016.7912034
   Rettig L, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P1113, DOI 10.1109/BigData.2015.7363865
   Rodrigues AP, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON COMPUTATIONAL SYSTEMS AND INFORMATION TECHNOLOGY FOR SUSTAINABLE SOLUTION (CSITSS-2017), P175, DOI 10.1109/CSITSS.2017.8447656
   Singh R, 2019, LECT NOTE NETW SYST, V40, P763, DOI 10.1007/978-981-13-0586-3_74
   Thiruvathukal GK, 2019, CORR
   Yang YB, 2018, IEEE TRUST BIG, P1791, DOI 10.1109/TrustCom/BigDataSE.2018.00270
   Younes MaramBani., 2017, Communications (ICC), 2017 IEEE International Conference on, P1, DOI 10.1109/CloudTech.2017.8284714
   Yu J, 2022, IEEE T PATTERN ANAL, V44, P563, DOI 10.1109/TPAMI.2019.2932058
   Zvarevashe K, 2018, 2018 CONFERENCE ON INFORMATION COMMUNICATIONS TECHNOLOGY AND SOCIETY (ICTAS)
NR 28
TC 5
Z9 5
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32749
EP 32767
DI 10.1007/s11042-020-09512-2
EA AUG 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000563739900010
DA 2024-07-18
ER

PT J
AU Yao, XJ
   Wang, XY
   Wang, SH
   Zhang, YD
AF Yao, Xujing
   Wang, Xinyue
   Wang, Shui-Hua
   Zhang, Yu-Dong
TI A comprehensive survey on convolutional neural network in medical image
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Feedforward Neural Network; Convolutional neural network;
   Breast Cancer; Lung Nodule; Brain Tumor; Medical image analysis
ID BREAST-CANCER; DEEP CNN; CLASSIFICATION; SEGMENTATION; RECOGNITION
AB CNN is inspired from Primary Visual (V1) neurons. It is a typical deep learning technique and can help teach machine how to see and identify objects. In the most recent decade, deep learning develops rapidly and has been well used in various fields of expertise such as computer vision and natural language processing. As the representative algorithm of deep learning, Convolution Neural Network (CNN) has been regarded as a breakthrough of historic significance in image processing and visual recognition tasks since the astonishing results achieved on ImageNet Large Scale Visual Recognition Competition (ILSVRC) Unlike methods based on handcrafted features, CNN models can build high-level features from low-level ones in a data-driven fashion and have displayed great potential in medical image analysis among the aspects of segmentation of histological images identification, lesion detection, tissue classification, etc. This paper provides a review on CNN from the perspectives of its basic mechanism introduction, structure, typical architecture and main application in medical image analysis through analyzing over 100 references from Google Scholar, PubMed, Web of Science and various sources published from 1958 to 2020.
C1 [Yao, Xujing; Wang, Xinyue; Wang, Shui-Hua; Zhang, Yu-Dong] Univ Leicester, Sch Informat, Leicester LE1 7RH, Leics, England.
   [Wang, Shui-Hua; Zhang, Yu-Dong] King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Informat Syst, Jeddah 21589, Saudi Arabia.
   [Wang, Shui-Hua] Loughborough Univ, Sch Architecture Bldg & Civil Engn, Loughborough LE11 3TU, Leics, England.
C3 University of Leicester; King Abdulaziz University; Loughborough
   University
RP Wang, SH; Zhang, YD (corresponding author), Univ Leicester, Sch Informat, Leicester LE1 7RH, Leics, England.; Wang, SH; Zhang, YD (corresponding author), King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Informat Syst, Jeddah 21589, Saudi Arabia.; Wang, SH (corresponding author), Loughborough Univ, Sch Architecture Bldg & Civil Engn, Loughborough LE11 3TU, Leics, England.
EM xy147@le.ac.uk; fireswxy@163.com; shuihuawng@ieee.org;
   yudongzhang@ieee.org
RI 姚, 旭婧/AAI-4724-2021; Wang, Shuihua/G-7326-2016; Zhang,
   Yudong/I-7633-2013
OI Zhang, Yudong/0000-0002-4870-1493
FU Royal Society International Exchanges Cost Share Award, UK [RP202G0230];
   Medical Research Council Confidence in Concept Award, UK [MC_PC_17171];
   Hope Foundation for Cancer Research, UK [RM60G0680]; British Heart
   Foundation Accelerator Award, UK; Guangxi Key Laboratory of Trusted
   Software [kx201901]; Fundamental Research Funds for the Central
   Universities [CDLS-2020-03]; Key Laboratory of Child Development and
   Learning Science (Southeast University), Ministry of Education
FX This work was partially supported by Royal Society International
   Exchanges Cost Share Award, UK (RP202G0230); Medical Research Council
   Confidence in Concept Award, UK (MC_PC_17171); Hope Foundation for
   Cancer Research, UK (RM60G0680); British Heart Foundation Accelerator
   Award, UK; Guangxi Key Laboratory of Trusted Software (kx201901);
   Fundamental Research Funds for the Central Universities (CDLS-2020-03);
   Key Laboratory of Child Development and Learning Science (Southeast
   University), Ministry of Education.
CR Agarap A. F., 2018, ARXIV
   Alakwaa W, 2017, INT J ADV COMPUT SC, V8, P409
   Anaraki AK, 2019, BIOCYBERN BIOMED ENG, V39, P63, DOI 10.1016/j.bbe.2018.10.004
   [Anonymous], CoRR abs/1511.07122
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Azamjah Nasrindokht, 2019, Asian Pac J Cancer Prev, V20, P2015, DOI 10.31557/APJCP.2019.20.7.2015
   Baldassi C, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.170602
   Bardou D, 2018, IEEE ACCESS, V6, P24680, DOI 10.1109/ACCESS.2018.2831280
   Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980
   Bottou L., 2012, Neural networks: Tricks of the trade, P421, DOI DOI 10.1007/978-3-642-35289-8_25
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Bray F., 2018, GLOBOCAN estimates of incidence and mortality worldwide for 36 cancers in 185 countries
   Che ZG, 2011, INT J INNOV COMPUT I, V7, P5839
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Chung H, 2016, IEEE IJCNN, P348, DOI 10.1109/IJCNN.2016.7727219
   Dasgupta A, 2017, I S BIOMED IMAGING, P248, DOI 10.1109/ISBI.2017.7950512
   de Koning HJ, 2020, NEW ENGL J MED, V382, P503, DOI 10.1056/NEJMoa1911793
   Du J, 2018, J PHYS C SERIES
   Dumoulin V, 2018, Arxiv, DOI [arXiv:1603.07285, DOI 10.48550/ARXIV.1603.07285]
   Gao F, 2018, COMPUT MED IMAG GRAP, V70, P53, DOI 10.1016/j.compmedimag.2018.09.004
   Gauen K, 2017, 2017 22 AS S PAC DES
   Girshick R., 2015, IEEE I CONF COMP VIS, DOI [DOI 10.1109/ICCV.2015.169, 10.1109/ICCV.2015.169]
   Gkioxari G, 2015, IEEE I CONF COMP VIS, P1080, DOI 10.1109/ICCV.2015.129
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hamidian S, 2017, MED IMAGING 2017 COM
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hinton G, 2012, NEURAL NETW MACHINE, V575
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Howard A. G., 2013, Some improvements on deep convolutional neural network based image classification
   Huang JT, 2015, INT CONF ACOUST SPEE, P4989, DOI 10.1109/ICASSP.2015.7178920
   Hussain S, 2018, NEUROCOMPUTING, V282, P248, DOI 10.1016/j.neucom.2017.12.032
   Hussein S, 2017, 2017 IEEE 14 INT S B
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Jiang YZ, 2021, IEEE T INTELL TRANSP, V22, P1752, DOI 10.1109/TITS.2020.2973673
   Jiang YZ, 2021, IEEE ACM T COMPUT BI, V18, P40, DOI 10.1109/TCBB.2019.2963873
   Jiang YZ, 2019, IEEE ACCESS, V7, P119644, DOI 10.1109/ACCESS.2019.2937124
   Jiang YZ, 2019, J MED IMAG HEALTH IN, V9, P1865, DOI 10.1166/jmihi.2019.2807
   Jiang YZ, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1245-1
   Jiang YZ, 2017, IEEE T NEUR SYS REH, V25, P2270, DOI 10.1109/TNSRE.2017.2748388
   Jiang YZ, 2017, IEEE T FUZZY SYST, V25, P3, DOI 10.1109/TFUZZ.2016.2637405
   Jiang YZ, 2015, IEEE T CYBERNETICS, V45, P688, DOI 10.1109/TCYB.2014.2334595
   Kamnitsas K., 2015, Ischemic stroke lesion segmentation, V13, P46, DOI DOI 10.1016/J.MEDIA.2016.10.004
   Khan H, 2020, COMPUT COMMUN, V153, P196, DOI 10.1016/j.comcom.2020.01.013
   Khirirat S, 2017, IEEE DECIS CONTR P
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lemarechal Claude, 2012, Doc. Math. (Bielefeld) Extra Vol. Optimization Stories, P251
   Lenc K, 2015, ARXIV150606981
   Levy D., 2016, Breast Mass Classification from Mammograms using Deep Convolutional Neural Networks, (Nips)
   Li J., 2017, 2017 IEEE INT C AC S
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Liu K, 2017, INT J IMAG SYST TECH, V27, P12, DOI 10.1002/ima.22206
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Marsalli M, 2006, 2008 ANN M CONS COGN
   Mateen M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010001
   McCulloch WS, 2016, EMBODIMENTS OF MIND, P19
   Mehta RM-NET., 2017, 2017 IEEE 14 INT S B, DOI 10.0/Linux-x86_64
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Minsky M., 1969, PERCEPTRONS INTRO CO
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Mordang JJ, 2016, LECT NOTES COMPUT SC, V9699, P35, DOI 10.1007/978-3-319-41546-8_5
   Nielsen M. A., 2015, NEURAL NETWORKS DEEP, DOI DOI 10.1145/2939672.2945397
   Pascanu R., 2013, INT C MACH LEARN, P1310
   Pedamonti D, 2018, ARXIV180402763
   Purkait P., 2017, ARXIV171203452
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Reddy, 2018, EHEALTHMAKING HLTH C, P81
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Rouhi R, 2015, EXPERT SYST APPL, V42, P990, DOI 10.1016/j.eswa.2014.09.020
   Ruder S., 2016, ARXIV
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Salehi SSM, 2017, IEEE T MED IMAGING, V36, P2319, DOI 10.1109/TMI.2017.2721362
   Salekin MS, 2019, 2019 INT C ROB EL SI
   Scardapane S, 2019, NEURAL NETWORKS, V110, P19, DOI 10.1016/j.neunet.2018.11.002
   Schairer C, 2004, JNCI-J NATL CANCER I, V96, P1311, DOI 10.1093/jnci/djh253
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schmidt WF, 1993, IEEE INT C NEUR NETW
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shen Wei, 2015, Inf Process Med Imaging, V24, P588, DOI 10.1007/978-3-319-19992-4_46
   Sheng T, 2018, 2018 1ST WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING FOR EMBEDDED APPLICATIONS (EMC2), P14, DOI 10.1109/EMC2.2018.00011
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su H, 2015, I S BIOMED IMAGING, P55, DOI 10.1109/ISBI.2015.7163815
   Sun ML, 2017, NEUROCOMPUTING, V224, P96, DOI 10.1016/j.neucom.2016.10.049
   Sun WQ, 2017, COMPUT MED IMAG GRAP, V57, P4, DOI 10.1016/j.compmedimag.2016.07.004
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Ting FF, 2019, EXPERT SYST APPL, V120, P103, DOI 10.1016/j.eswa.2018.11.008
   Togaçar M, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109531
   Waks Adrienne G, 2019, JAMA, V321, P288, DOI 10.1001/jama.2018.19323
   Xu J, 2017, PROC CVPR IEEE, P5807, DOI 10.1109/CVPR.2017.615
   Xue Y, 2020, NEUROIMAGE-CLIN, V25, DOI 10.1016/j.nicl.2019.102118
   Yu D., 2014, INT C ROUGH SETS KNO
   Yuan ZW, 2016, PROC SPIE, V10033, DOI 10.1117/12.2243849
   Zarandy a, 2015, 2015 IEEE INT S CIRC
   Zeiler M.D., 2013, ARXIV201313013557, P1
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474
   Zhang Z, 1993, P 1993 INT C NEUR NE
   Zubair S, 2013, DIGIT SIGNAL PROCESS, V23, P960, DOI 10.1016/j.dsp.2013.01.004
NR 107
TC 30
Z9 30
U1 7
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41361
EP 41405
DI 10.1007/s11042-020-09634-7
EA AUG 2020
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000562360200001
DA 2024-07-18
ER

PT J
AU Ren, YJ
   Zhu, FJ
   Zhu, K
   Sharma, PK
   Wang, J
AF Ren, Yongjun
   Zhu, Fujian
   Zhu, Kui
   Sharma, Pradip Kumar
   Wang, Jin
TI Blockchain-based trust establishment mechanism in the internet of
   multimedia things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of multimedia things; Trust; Blockchain
ID MANAGEMENT; IOT; MODEL
AB Through the application of powerful semiconductors and high-speed communication technologies such as 5G, large-scale or even ultra-large-scale Internet of Multimedia Things (IoMT) will soon appear. Secure communication and cooperation in the Multimedia Internet of Things (IoT) will thus increase, and trust between these devices is important. However, existing IoT trust mechanisms either rely on additional trusted third parties or assume that trusted devices exist between trusted domains; these assumptions are difficult to satisfy simultaneously in the IoMT context. Accordingly, this paper utilizes blockchain technology to propose a trust establishment mechanism suitable for the distributed IoMT. Highly secure and scalable trust mechanisms are established without the need to assume that a third party exists or that these CAs (Certification Authorities) are trusted. We design the IoMT node authentication and key agreement protocols across the trust domain. Our experimental results prove that our proposed method reduces the number of trust domain conversions.
C1 [Ren, Yongjun; Zhu, Fujian; Zhu, Kui] Nanjing Univ Informat Sci & Technol, Engn Res Ctr Digital Forens, Sch Comp & Software, Minist Educ, Nanjing 210044, Peoples R China.
   [Ren, Yongjun; Zhu, Fujian; Zhu, Kui] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Peoples R China.
   [Sharma, Pradip Kumar] Dongguk Univ, Dept Multimedia Engn, Seoul 04620, South Korea.
   [Wang, Jin] Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410004, Peoples R China.
   [Wang, Jin] Fujian Univ Technol, Sch Informat Sci & Engn, Fuzhou 350118, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Dongguk University;
   Changsha University of Science & Technology; Fujian University of
   Technology
RP Wang, J (corresponding author), Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410004, Peoples R China.; Wang, J (corresponding author), Fujian Univ Technol, Sch Informat Sci & Engn, Fuzhou 350118, Peoples R China.
EM renyj100@126.com; zhufujian1995@gmail.com; jinwang@csust.edu.cn
RI wang, yi/HOF-6668-2023; wang, jie/HTQ-4920-2023; Zhu,
   Fujian/JVN-2969-2024; wang, yue/ISA-4119-2023; wang, jing/HJA-5384-2022;
   WANG, JINGYI/GSJ-1241-2022; wang, jing/GVT-8700-2022; Sharma, Pradip
   Kumar/I-8803-2019; Wang, Jin/GYA-2019-2022
OI Zhu, Fujian/0000-0002-5521-8360; Sharma, Pradip
   Kumar/0000-0001-6620-9083; 
FU NSFC [61772280, 61772454, 61811530332, 61811540410]; PAPD fund from
   NUIST
FX This work is supported by the NSFC (61772280, 61772454, 61811530332,
   61811540410), the PAPD fund from NUIST. Jin Wang is the corresponding
   author.
CR Alexopoulos N, 2018, PROCEEDINGS OF THE 2018 WORKSHOP ON IOT SECURITY AND PRIVACY (IOT S&P '18), P49, DOI 10.1145/3229565.3229569
   Amann Bernhard., 2013, PROC ACSAC 13, P179
   Bairinhas S, 2018, 6TH INTERNATIONAL CONFERENCE ON ILLUSTRATION AND ANIMATION (CONFIA 2018), P248
   Basin D, 2014, CCS'14: PROCEEDINGS OF THE 21ST ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P382, DOI 10.1145/2660267.2660298
   Ben Saied Y, 2013, COMPUT SECUR, V39, P351, DOI 10.1016/j.cose.2013.09.001
   Benkerrou H, 2017, IDT2017, P295
   Blaze M, 1996, P IEEE S SECUR PRIV, P164, DOI 10.1109/SECPRI.1996.502679
   Braun J, 2014, J COMPUT SECUR, V22, P913, DOI 10.3233/JCS-140509
   Chen D, 2011, COMPUT SCI INF SYST, V8, P1207, DOI 10.2298/CSIS110303056C
   Chen IR, 2016, IEEE T DEPEND SECURE, V13, P684, DOI 10.1109/TDSC.2015.2420552
   Di Pietro R, 2018, SACMAT'18: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON ACCESS CONTROL MODELS & TECHNOLOGIES, P77, DOI 10.1145/3205977.3205993
   Durand A., 2017, ARXIV170601730, P1
   Fang LM, 2020, IEEE INTERNET THINGS, V7, P5745, DOI 10.1109/JIOT.2019.2944301
   Ge CP, 2021, IEEE T DEPEND SECURE, V18, P1214, DOI 10.1109/TDSC.2019.2899300
   Gu LZ, 2014, CHINA COMMUN, V11, P148, DOI 10.1109/CC.2014.6821746
   Gupta M., 2003, P 13 ACM INT WORKSHO, P144
   Li GS, 2019, IEEE ACCESS, V7, P159688, DOI 10.1109/ACCESS.2019.2950443
   Lin J, 2017, PROCEEDINGS OF 2017 2ND INTERNATIONAL CONFERENCE ON CROWD SCIENCE AND ENGINEERING ICCSE 2017, P38, DOI 10.1145/3126973.3126980
   [刘文懋 Liu Wenmao], 2012, [计算机学报, Chinese Journal of Computers], V35, P846
   McKnight DH, 2001, INT J ELECTRON COMM, V6, P35, DOI 10.1080/10864415.2001.11044235
   Mui L, 2002, COMPUTATION MODELS T
   Nitti M, 2014, IEEE T KNOWL DATA EN, V26, P1253, DOI 10.1109/TKDE.2013.105
   Rafey SEA, 2016, INT CONF SEL TOP MOB, P166
   Ren YJ, 2020, CMC-COMPUT MATER CON, V63, P1471, DOI 10.32604/cmc.2020.06745
   Ren YJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010207
   Ren YL, 2021, INTERNET TECHNOL LET, V4, DOI 10.1002/itl2.160
   Resnick P, 2000, IEEE S SEC PRIV, V1996, P64
   Sun YL, 2006, IEEE J SEL AREA COMM, V24, P305, DOI [10.1109/JSAC.2005.0861389, 10.1109/JSAC.2005.861389]
   Szalachowski P, 2014, CCS'14: PROCEEDINGS OF THE 21ST ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P406, DOI 10.1145/2660267.2660355
   Wan WN, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.06.013
   Wang J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112579
   Wang J, 2019, HUM-CENTRIC COMPUT I, V9, DOI 10.1186/s13673-019-0179-4
   Wang J, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719839581
   Wang J, 2019, CMC-COMPUT MATER CON, V58, P711, DOI 10.32604/cmc.2019.05450
   Wang J, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/9472075
   Xiao HN, 2015, INT WIREL COMMUN, P600, DOI 10.1109/IWCMC.2015.7289151
   Yin B, 2019, IEEE INTERNET THINGS, V6, P3352, DOI 10.1109/JIOT.2018.2882820
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
   Zhang XR, 2019, INT J SENS NETW, V31, P24, DOI 10.1504/IJSNET.2019.101567
   Zhang YN, 2020, IEEE T IND INFORM, V16, P7369, DOI 10.1109/TII.2020.2976053
   Zhang YS, 2018, IEEE INTERNET THINGS, V5, P3442, DOI 10.1109/JIOT.2017.2781737
   Zhao W, 2018, IEEE NETWORK, V32, P101, DOI 10.1109/MNET.2018.1700164
   Zhu QY, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3359982
NR 43
TC 4
Z9 4
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30653
EP 30676
DI 10.1007/s11042-020-09578-y
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000560297300011
DA 2024-07-18
ER

PT J
AU Sharma, T
   Agrawal, I
   Verma, NK
AF Sharma, Teena
   Agrawal, Isha
   Verma, Nishchal K.
TI CSIDNet: Compact single image dehazing network for outdoor scene
   enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Outdoor scene enhancement; Dark channel; Illumination channel;
   Convolutional neural networks; Residual learning
ID HAZE REMOVAL; FRAMEWORK; WEATHER; VISION
AB This paper proposes a novel deep learning-based single image dehazing network named as Compact Single Image Dehazing Network (CSIDNet) for outdoor scene enhancement. CSIDNet directly outputs a haze-free image from the given hazy input. The remarkable features of CSIDNet are that it has been designed only with three convolutional layers and it requires lesser number of images for training without diminishing the performance in comparison to the other commonly observed deep learning-based dehazing models. The performance of CSIDNet has been analyzed on natural hazy scene images and REalistic Single Image DEhazing (RESIDE) dataset. RESIDE dataset consists of Outdoor Training Set (OTS), Synthetic Objective Testing Set (SOTS), and real-world synthetic hazy images from Hybrid Subjective Testing Set (HSTS). The performance metrics used for comparison are Peak Signal to Noise Ratio (PSNR) and Structural SIMilarity (SSIM) index. The experimental results obtained using CSIDNet outperform several well known state-of-the-art dehazing methods in terms of PSNR and SSIM on images of SOTS and HSTS from RESIDE dataset. Additionally, the visual comparison shows that the dehazed images obtained using CSIDNet are more appealing with better edge preservation. Since the proposed network requires minimal resources and is faster to train along with lesser run-time, it is more practical and feasible for real-time applications.
C1 [Sharma, Teena; Verma, Nishchal K.] IIT Kanpur, Dept Elect Engn, Kanpur 208016, Uttar Pradesh, India.
   [Agrawal, Isha] IIITDM Jabalpur, Dept Comp Sci & Engn, Jabalpur 482005, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kanpur; Indian Institute of Information Technology
   Design & Manufacturing, Jabalpur
RP Sharma, T (corresponding author), IIT Kanpur, Dept Elect Engn, Kanpur 208016, Uttar Pradesh, India.
EM tee.shar6@gmail.com; ishaagrawal2017@gmail.com; nishchal@iitk.ac.in
CR Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Ancuti C, 2014, IEEE GEOSCI REMOTE S, V11, P1871, DOI 10.1109/LGRS.2014.2312314
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   Burger W., 2016, DIGITAL IMAGE PROCES, DOI [10.1007/978-1-4471-6684-9, DOI 10.1007/978-1-4471-6684-9]
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chaudhry AM, 2018, IEEE GEOSCI REMOTE S, V15, P932, DOI 10.1109/LGRS.2018.2814016
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Gonzalez RC, 2006, DIGITAL IMAGE PROCES, P3
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He KM, 2010, PROC CVPR IEEE, P2165, DOI 10.1109/CVPR.2010.5539896
   Jia H., 2020, AAAI, P11908
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Liu Z, 2019, IEEE SIGNAL PROC LET, V26, P833, DOI 10.1109/LSP.2019.2910403
   Long J, 2014, IEEE GEOSCI REMOTE S, V11, P59, DOI 10.1109/LGRS.2013.2245857
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Lu XK, 2019, NEUROCOMPUTING, V349, P133, DOI 10.1016/j.neucom.2019.02.021
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Rosolia U, 2017, IEEE T CONTR SYST T, V25, P469, DOI 10.1109/TCST.2016.2569468
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Wang AN, 2019, IEEE T IMAGE PROCESS, V28, P381, DOI 10.1109/TIP.2018.2868567
   Yang X, 2019, IEEE T MULTIMEDIA, V21, P2545, DOI 10.1109/TMM.2019.2908375
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 38
TC 7
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30769
EP 30784
DI 10.1007/s11042-020-09496-z
EA AUG 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560297300008
DA 2024-07-18
ER

PT J
AU Vidhya, R
   Brindha, M
AF Vidhya, R.
   Brindha, M.
TI A novel dynamic chaotic image encryption using butterfly network
   topology based diffusion and decision based permutation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Zig-zag scan; BNT; Diffusion; Security
ID LEVEL PERMUTATION; BLOCK CIPHER; SCHEME; CRYPTANALYSIS; COMBINATION;
   SYSTEM; SECURITY
AB Many techniques like encryption, steganography, watermarking are used for sending multimedia information securely over the internet. This paper focuses on encryption technique for secure transmission of images. For this, a Secure Dynamic Decision based Permutation and Butterfly Network Topology (BNT) based Diffusion ((SDPBD)-P-2) model is proposed for images. Two different models are enforced for creating initial vectors of Henon map which in turn used to generate the random key sequence for every encryption to achieve high plain image sensitivity. For confusing the pixels, a simple chaotic and decision based four-way Zig-zag scan is employed and after performing this three level diffusion with BNT architecture is proposed. The BNT architecture has internal bit-wise permutation. It is an additional advantage of this encryption scheme with less computation time. Simulations are done with different type of quantitative measurements in order to analyze the effectiveness of the present technique with respect to different types of attacks. From the NPCR and UACI analysis, the proposed scheme is proved to be secure against differential attacks.
C1 [Vidhya, R.; Brindha, M.] Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Brindha, M (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli, Tamil Nadu, India.
EM vidhu.cs111@gmail.com; brindham@nitt.edu
RI M, Brindha/AAM-3828-2021; m, b/IWM-4244-2023
CR Akhavan A, 2017, OPT LASER TECHNOL, V95, P94, DOI 10.1016/j.optlastec.2017.04.022
   Arnold V. I., 1967, Problemes Ergodiques de la Mecanique Classique
   Borujeni SE, 2013, TELECOMMUN SYST, V52, P525, DOI 10.1007/s11235-011-9458-8
   Brindha M, 2016, APPL SOFT COMPUT, V40, P379, DOI 10.1016/j.asoc.2015.09.055
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Chen JX, 2015, SIGNAL PROCESS, V111, P294, DOI 10.1016/j.sigpro.2015.01.003
   Chen JX, 2015, OPT LASER ENG, V67, P191, DOI 10.1016/j.optlaseng.2014.11.017
   Chen JX, 2015, COMMUN NONLINEAR SCI, V20, P846, DOI 10.1016/j.cnsns.2014.06.032
   Dong CE, 2014, SIGNAL PROCESS-IMAGE, V29, P628, DOI 10.1016/j.image.2013.09.006
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Fouda JSAE, 2014, APPL SOFT COMPUT, V25, P435, DOI 10.1016/j.asoc.2014.08.059
   Fouda JSAE, 2014, COMMUN NONLINEAR SCI, V19, P578, DOI 10.1016/j.cnsns.2013.07.016
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Hussain I, 2012, NONLINEAR DYNAM, V70, P181, DOI 10.1007/s11071-012-0440-0
   Jolfaei A, 2016, IEEE T INF FOREN SEC, V11, P235, DOI 10.1109/TIFS.2015.2489178
   Kadir A, 2017, OPTIK, V129, P231, DOI 10.1016/j.ijleo.2016.10.036
   Kocarev L., 2001, IEEE Circuits and Systems Magazine, V1, P6, DOI 10.1109/7384.963463
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Murugan B, 2016, IET COMPUT VIS, V10, P593, DOI 10.1049/iet-cvi.2015.0344
   Norouzi B, 2016, OPTIK, V127, P5695, DOI 10.1016/j.ijleo.2016.03.076
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Özkaynak F, 2016, OPTIK, V127, P5190, DOI 10.1016/j.ijleo.2016.03.018
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Parvaz R, 2018, OPT LASER TECHNOL, V101, P30, DOI 10.1016/j.optlastec.2017.10.024
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wu XJ, 2016, INFORM SCIENCES, V349, P137, DOI 10.1016/j.ins.2016.02.041
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Zahmoul R, 2017, OPT LASER ENG, V96, P39, DOI 10.1016/j.optlaseng.2017.04.009
   Zhang LY, 2014, COMMUN NONLINEAR SCI, V19, P3653, DOI 10.1016/j.cnsns.2014.03.016
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
NR 41
TC 6
Z9 7
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30281
EP 30310
DI 10.1007/s11042-020-09462-9
EA AUG 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000559953900007
DA 2024-07-18
ER

PT J
AU Wang, GJ
AF Wang, Guojun
TI A sub-pixel circle detection algorithm combined with improved RHT and
   fitting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bias effect; Invalid sampling; Subpixel; RHT; Circle detection
ID RANDOMIZED HOUGH TRANSFORM; CURVES; RECOGNITION
AB Circle extraction is usually a pre-completed task used in different applications related to medical, robotics, biometrics image analysis among others. Randomized Hough Transform (RHT) determines the parameters of the circle by randomly obtaining three edge pixels, if they are not precisely located on the circumference. The detected circle will not perfectly match the ideal circle. At the same time, three random points are largely not on a circle, which leads to some invalid sampling and parameter accumulation. In this paper, an improved RHT combined with fitting subpixel circle detection algorithm is proposed. The improved RHT algorithm calculates and accumulates parameters by using 1 point obtained from random sampling and another two points obtained from horizontal and vertical search respectively. The algorithm introduces the edge map of the de-soliton point and small region, and improves the probability that three points belong to the same circle. Then, the set of edge pixels corresponding to the identified circle is fitted to reduce the bias effect caused by only using three edge pixels to calculate the circle parameters. In this way, the reliability of the fitting and the precision of the parameters are improved while removing the noise. Experimental tests were conducted for detection performance, accuracy of parameter estimation and noise robustness. Compared with other methods, the proposed method has strong anti-interference ability and high calculation accuracy.
C1 [Wang, Guojun] Army Engn Univ PLA, Field Engn Coll, Nanjing 21007, Peoples R China.
C3 Army Engineering University of PLA
RP Wang, GJ (corresponding author), Army Engn Univ PLA, Field Engn Coll, Nanjing 21007, Peoples R China.
EM wgj0122@163.com
CR Akinlar C, 2013, PATTERN RECOGN, V46, P725, DOI 10.1016/j.patcog.2012.09.020
   Atherton TJ, 1999, IMAGE VISION COMPUT, V17, P795, DOI 10.1016/S0262-8856(98)00160-7
   Baker L, 2016, INT CONF IMAG VIS, P134
   Cai J, 2016, ADV SPACE RES, V57, P2359, DOI 10.1016/j.asr.2016.03.026
   Chia CM, 2016, OPT ENG, V55, DOI 10.1117/1.OE.55.1.013105
   Chung KL, 2012, PATTERN RECOGN, V45, P252, DOI 10.1016/j.patcog.2011.07.004
   Cuevas E, 2012, SOFT COMPUT, V16, P281, DOI 10.1007/s00500-011-0741-0
   Cuevas E, 2011, PATTERN ANAL APPL, V14, P93, DOI 10.1007/s10044-010-0183-9
   DAVIES ER, 1988, PATTERN RECOGN LETT, V7, P37, DOI 10.1016/0167-8655(88)90042-6
   De Marco T, 2015, PATTERN RECOGN, V48, P411, DOI 10.1016/j.patcog.2014.08.007
   Du GG, 2018, MULTIMED TOOLS APPL, V77, P19171, DOI 10.1007/s11042-017-5396-0
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Greminger M, 2016, MEAS SCI TECHNOL, V27, DOI 10.1088/0957-0233/27/2/025304
   HumbertoSossa EDDM-C, 2011, INFORM SCI, V182, P40
   Ioannou D, 1999, IMAGE VISION COMPUT, V17, P15, DOI 10.1016/S0262-8856(98)00090-0
   Kaur M, 2017, INT J ADV RES COMPUT, V8, P719
   Kwon YC, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071539
   Li DF.N, 2017, IEEE INT C MECH AUT, DOI [10.1109/ICMA.2017.8015824, DOI 10.1109/ICMA.2017.8015824]
   Li SD, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419540132
   Liang QK, 2019, MATH BIOSCI ENG, V16, P1244, DOI 10.3934/mbe.2019060
   Lopez-Martinez A, 2019, APPL INTELL, V49, P2001, DOI 10.1007/s10489-018-1372-2
   Luo JX, 2020, IEEE T INSTRUM MEAS, V69, P1327, DOI 10.1109/TIM.2019.2910345
   Mukhopadhyay P, 2015, PATTERN RECOGN, V48, P993, DOI 10.1016/j.patcog.2014.08.027
   Nausheen N, 2018, MICROPROCESS MICROSY, V56, P84, DOI 10.1016/j.micpro.2017.10.011
   ROSIN PL, 1995, IEEE T PATTERN ANAL, V17, P1140, DOI 10.1109/34.476507
   THOMAS SM, 1989, COMPUT VISION GRAPH, V45, P362, DOI 10.1016/0734-189X(89)90088-1
   Torrente ML, 2018, PATTERN RECOGN, V73, P111, DOI 10.1016/j.patcog.2017.08.008
   Wang GJ, 2020, ENVIRON TECHNOL, V41, P2920, DOI 10.1080/09593330.2019.1588384
   Wang H, 2020, INFORM SCIENCES, V527, P227, DOI 10.1016/j.ins.2020.03.064
   Xiao F, 2018, MULTIMED TOOLS APPL, V77, P25333, DOI 10.1007/s11042-018-5787-x
   XU L, 1993, CVGIP-IMAG UNDERSTAN, V57, P131, DOI 10.1006/ciun.1993.1009
   Yao ZJ, 2016, EXPERT SYST APPL, V51, P26, DOI 10.1016/j.eswa.2015.12.019
   YUEN HK, 1990, IMAGE VISION COMPUT, V8, P71, DOI 10.1016/0262-8856(90)90059-E
   Zhu J, 2019, PHOTONIC SENS, V9, P49, DOI 10.1007/s13320-018-0432-x
NR 34
TC 14
Z9 15
U1 2
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29825
EP 29843
DI 10.1007/s11042-020-09514-0
EA AUG 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000567227300001
DA 2024-07-18
ER

PT J
AU Zhang, QY
   Li, GL
   Huang, YB
AF Zhang, Qiu-yu
   Li, Gai-li
   Huang, Yi-bo
TI An efficient retrieval approach for encrypted speech based on biological
   hashing and spectral subtraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encrypted speech retrieval; Biological hashing; DWT; Pseudo-random
   matrix; Spectral subtraction; Speech authentication
ID ALGORITHM
AB In this paper, an efficient retrieval approach for encrypted speech based on biological hashing and spectral subtraction is proposed. The proposed approach improves the impact of noise on the robustness and discrimination of speech hashing scheme, as well as improves the retrieval efficiency, accuracy, and security of search digests, and realizes the authentication of the query result. The speech owner firstly secure the original speech file by encrypting it with two-dimensional Arnold mapping and uploading it to the encrypted speech library on cloud. Then, the pre-processed speech signal is subjected to spectral subtraction and noise reduction, as well as the discrete wavelet transform (DWT) is performed to obtain the wavelet low-frequency coefficient and reconstruct the speech signal, calculating the normalized autocorrelation function to obtain the matrix feature vector, and using the Chebychew mapping algorithm to generate the pseudo-random matrix, and generate the pseudo-random Fourier matrix by fast Fourier transform (FFT). Finally, iterate the matrix feature vector and pseudo-random matrix. After the thresholding, the hash sequence is constructed and uploaded to the system hash index table on cloud. When speech's user retrieval, the Hamming distance algorithm is used for the matching retrieval operation during the search and integrity authentication of the query result. The experimental results show that the proposed approach effectively reduces the noise of speech, with strong robustness and discrimination, and the retrieval efficiency, accuracy and security have been significantly improved.
C1 [Zhang, Qiu-yu; Li, Gai-li] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
   [Huang, Yi-bo] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
C3 Lanzhou University of Technology; Northwest Normal University - China
RP Zhang, QY (corresponding author), Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
EM zhangqylz@163.com; ligaili01@163.com; huangyibo1982@163.com
RI Zhang, Qiu-yu/V-9223-2019
OI Zhang, Qiu-yu/0000-0003-1488-388X
FU National Natural Science Foundation of China [61862041, 61363078]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61862041, 61363078). The authors also gratefully acknowledge
   the helpful comments and suggestions of the reviewers, which have
   improved the presentation.
CR Ali Z, 2018, FUTURE GENER COMP SY, V85, P76, DOI 10.1016/j.future.2018.02.040
   Aljawarneh S, 2017, MULTIMED TOOLS APPL, V76, P22703, DOI 10.1007/s11042-016-4333-y
   Balasundaram R, 2021, J KING SAUD UNIV-COM, V33, P110, DOI 10.1016/j.jksuci.2018.02.003
   Das D, 2018, IEEE ENG MED BIO, P5398, DOI 10.1109/EMBC.2018.8513667
   Dash D, 2018, IEEE GLOB CONF SIG, P489, DOI 10.1109/GlobalSIP.2018.8646401
   Espin JM, 2018, P 2018 IEEE 28 INT W, P1, DOI [10.1109/mlsp.2018.8517013, DOI 10.1109/MLSP.2018.8517013]
   Glackin C, 2017, INT CONF ACOUST SPEE, P6414, DOI 10.1109/ICASSP.2017.7953391
   He SF, 2017, COMPUT SCI INF SYST, V14, P703, DOI 10.2298/CSIS170112024H
   Iliev A, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P222, DOI 10.1109/MIPR.2018.00054
   Kamper H, 2019, IEEE-ACM T AUDIO SPE, V27, P89, DOI 10.1109/TASLP.2018.2872106
   Knospe H, 2013, P 2013 INT C SEC CRY, P1
   Liao HY, 2004, IEEE T SIGNAL PROCES, V52, P1315, DOI 10.1109/TSP.2004.826175
   Lin QG, 2018, INTERSPEECH, P2097
   Paliwal K, 2010, SPEECH COMMUN, V52, P450, DOI 10.1016/j.specom.2010.02.004
   Patil NM, 2019, ADV INTELL SYST, V924, P263, DOI 10.1007/978-981-13-6861-5_23
   Sasikaladevi N, 2019, MULTIMED TOOLS APPL, V78, P18339, DOI 10.1007/s11042-019-7208-1
   Seo JS, 2017, IEICE T INF SYST, VE100D, P57, DOI 10.1587/transinf.2016MUL0003
   [孙甲松 Sun Jiasong], 2017, [清华大学学报. 自然科学版, Journal of Tsinghua University. Science and Technology], V57, P382
   Tam WM, 2004, IEEE T CIRCUITS-II, V51, P473, DOI 10.1109/TCSII.2004.832773
   Thangapandiyan M, 2016, IEEE I C COMP INT CO, P351
   Wang H, 2015, BIOCHEM INSIGHTS, V8, P14, DOI 10.4137/BCI.S30377
   Wang HX, 2013, LNCS, P423, DOI DOI 10.1007/978-3-662-43886-2_3
   Xue W, 2018, IEEE-ACM T AUDIO SPE, V26, P1833, DOI 10.1109/TASLP.2018.2845665
   Yadava TG, 2019, INT J SPEECH TECHNOL, V22, P639, DOI 10.1007/s10772-018-9506-9
   Ye GD, 2012, NONLINEAR DYNAM, V69, P2079, DOI 10.1007/s11071-012-0409-z
   Zhang QY, 2019, MULTIMED TOOLS APPL, V78, P17825, DOI 10.1007/s11042-019-7180-9
   Zhang QY, 2018, MULTIMED TOOLS APPL, V77, P1555, DOI 10.1007/s11042-017-4381-y
   Zhao H, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1840, DOI 10.1109/FSKD.2016.7603458
   Zheng Y, 2018, METHODS MOL BIOL, V1724, P1, DOI 10.1007/978-1-4939-7562-4_1
   Zou FH, 2018, MULTIMED TOOLS APPL, V77, P3677, DOI 10.1007/s11042-017-5219-3
NR 30
TC 5
Z9 6
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29775
EP 29798
DI 10.1007/s11042-020-09446-9
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000567227300011
DA 2024-07-18
ER

PT J
AU Madichetty, S
   Sridevi, M
AF Madichetty, Sreenivasulu
   Sridevi, M.
TI Classifying informative and non-informative tweets from the twitter by
   adapting image features during disaster
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial neural network; VGG-16 architecture; Disaster; Late fusion
AB During the crisis, people post a large number of informative and non-informative tweets on Twitter. Informative tweets provide helpful information such as affected individuals, infrastructure damage, availability and resource requirements, etc. In contrast, non-informative tweets do not provide helpful information related to either humanitarian organizations or victims. Identifying informative tweets is a challenging task during the disaster. People often post images along with text on Twitter during the disaster. In addition to tweet text features, image features are also crucial for identifying informative tweets. However, existing methods use only text features but do not use image features to identify crisis-related tweets during the disaster. This paper proposes a novel approach by considering the image features along with the text features. It includes a text-based classification model, an image-based classification model and a late fusion. The text-based classification model uses the Convolutional Neural Network (CNN) and the Artificial Neural Network (ANN). CNN is used to extract text features from a tweet and the ANN is used to classify tweets based on extracted text features of CNN. The image-based classification model uses the fine-tuned VGG-16 architecture to extract the image features from the image and classify the image in a tweet. The output of the text-based classification model and the image-based classification model are combined using the late fusion technique to predict the tweet label. Extensive experiments are carried out on Twitter datasets of various crises, such as the Mexico earthquake, California Wildfires, etc., to demonstrate the effectiveness of the proposed method. The proposed method outperforms the state-of-the-art methods on various parameters to identify informative tweets during the disaster.
C1 [Madichetty, Sreenivasulu; Sridevi, M.] Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli 620015, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Madichetty, S (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli 620015, Tamil Nadu, India.
EM sreea568@gmail.com; msridevi@nitt.edu
RI M, Sreenivasulu/AAM-6040-2021; Madichetty, sreedhar/N-9849-2017
OI Madichetty, sreedhar/0000-0002-0373-9092
CR Alam F, 2018, P INT AAAI C WEB SOC
   Alam F, 2019, AUG MOB NETWORKS APP
   Alam F, 2020, BEHAV INFORM TECHNOL, V39, P288, DOI 10.1080/0144929X.2019.1610908
   [Anonymous], 2019, J BIOMOL STRUCT 0312, DOI DOI 10.1080/07391102.2019.1585952
   [Anonymous], 2000, INT J MASS EMERG DIS
   Basu M, 2019, IEEE T COMPUT SOC SY, V6, P604, DOI 10.1109/TCSS.2019.2914179
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Burel G, 2018, P 15 ISCRAM
   Caragea C, 2014, MAPPING MOODS GEOMAP
   Caragea C, 2016, INT C INF SYST CRIS, P137
   Castillo C, 2016, BIG CRISIS DATA: SOCIAL MEDIA IN DISASTERS AND TIME-CRITICAL SITUATIONS
   Chollet F, 2015, KERAS
   Dunning T., 1993, Computational Linguistics, V19, P61
   Enenkel M, 2018, ABS180202631 CORR
   Fan C, 2020, IEEE ACCESS, V8, P10478, DOI 10.1109/ACCESS.2020.2965550
   Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Houston JB, 2015, DISASTERS, V39, P1, DOI 10.1111/disa.12092
   Howard A. G., 2017, PREPRINT
   Imran M, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1638
   Imran M, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P159, DOI 10.1145/2567948.2577034
   Imran M, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2771588
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Kingma D P, 2015, 3 INT C LEARN REPR I
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kryvasheyeu Y, 2016, SCI ADV, V2, DOI 10.1126/sciadv.1500779
   LUHN HP, 1957, IBM J RES DEV, V1, P309, DOI 10.1147/rd.14.0309
   Madichetty S, 2018, INT J COMPUTATIONAL, V1
   Madichetty S, 2019, SOC NETW ANAL MIN, V9, DOI 10.1007/s13278-019-0579-5
   Madichetty S, 2019, INT CONF COMMUN SYST, P709, DOI [10.1109/COMSNETS.2019.8711095, 10.1109/comsnets.2019.8711095]
   McCulloch W.S., 1943, B MATH BIOPHYS, V5, P115, DOI 10.1007/BF02478259
   Nguyen Dat T., 2017, 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P569, DOI 10.1145/3110025.3110109
   Nguyen D T, 2017, 11 INT AAAI C WEB SO, P632
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pennington J, 2014, P C EMP METH NAT LAN, P1532
   Purohit H., 2014, 1 MONDAY, V19, P1
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Rudra K, 2018, ACM T WEB, V12, DOI 10.1145/3178541
   Rudra K, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON DIGITAL HEALTH (DH'17), P104, DOI 10.1145/3079452.3079491
   Rudra K, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P96, DOI 10.1109/ASONAM.2016.7752219
   Rudra S., 2015, P 24 ACM INT C INF K, P583, DOI DOI 10.1145/2806416.2806485
   Sarter N. B., 1991, INT J AVIATION PSYCH, V1, P45
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Vapnik V., 1999, NATURE STAT LEARNING
   Vieweg S, 2014, LECT NOTES COMPUT SC, V8851, P444, DOI 10.1007/978-3-319-13734-6_32
   Werbos P. J., 1974, REGRESSION NEW TOOLS
   Zeiler M. D., 2012, CoRR
NR 50
TC 16
Z9 17
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28901
EP 28923
DI 10.1007/s11042-020-09343-1
EA AUG 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000557124000003
DA 2024-07-18
ER

PT J
AU Ding, XL
   Huang, YM
   Li, Y
   He, JL
AF Ding, Xiangling
   Huang, Yanming
   Li, Yue
   He, Jiale
TI Forgery detection of motion compensation interpolated frames based on
   discontinuity of optical flow
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video forensics; Identification; Motion-compensation
   frame-interpolation; Optical flow
ID PERIODIC PROPERTIES; CLASSIFICATION
AB Motion Compensated Frame Interpolation (MCFI), a frame-based video operation to increase the motion continuity of low frame rate video, can be adopted by falsifiers for forging high bitrate video or splicing videos with different frame-rates. For existing MCFI detectors, their performance are degraded by stronger video compression, and noise. To deal with this problem, we propose a blind forensics method to detect the adopted MCFI operation. After investigating the synthetic process of interpolated frames, we discover that motion regions of interpolated frames exist some local slight artifacts, causing the optical flow based inter-frame discontinuity. To capture this irregularities introduced by various MCFI techniques, compact features are designed, which are calculated as Temporal Frame Difference-weighted histogram of Local Binary Pattern computed on Optical Flow field (TFD-OFLBP). Meanwhile, Local Inter-block and Edge-block difference Features (LIEF) are further proposed to detect interpolation frames with stable content. Besides, a set of forensics tools are adopted to eliminate the side effects of possible interferences of the scenes change, sudden lighting change, focus vibration, and some original frames with inherent local artifacts. Experimental results on four representative MCFI software and techniques show that the proposed approach outperforms existing MCFI detectors and also with robustness to compression, and noise.
C1 [Ding, Xiangling; Huang, Yanming] Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan 411004, Peoples R China.
   [Li, Yue] Univ South China, Comp Sch, Hengyang 421001, Peoples R China.
   [He, Jiale] Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
C3 Hunan University of Science & Technology; University of South China;
   Hunan University
RP Ding, XL (corresponding author), Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan 411004, Peoples R China.
EM xianglingding@163.com
OI ding, xiangling/0000-0002-6581-4633
FU Doctoral research foundation of Hunan University of Science and
   Technology [E51974]; Scientific Research Foundation of Hunan Provincial
   Education Department of China [19B199]; Natural Science Foundation of
   Hunan Province of China [2020JJ4029]
FX This work was supported in part by Doctoral research foundation of Hunan
   University of Science and Technology under E51974, the Scientific
   Research Foundation of Hunan Provincial Education Department of China
   under 19B199, and the Natural Science Foundation of Hunan Province of
   China under Grant 2020JJ4029.
CR Adato Y, 2011, PROC CVPR IEEE, P1145, DOI 10.1109/CVPR.2011.5995419
   Bestagini P, 2013, INT CONF ACOUST SPEE, P3033, DOI 10.1109/ICASSP.2013.6638215
   Bian S, 2014, MULTIMED TOOLS APPL, V72, P437, DOI 10.1007/s11042-013-1364-5
   Black M. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P231, DOI 10.1109/ICCV.1993.378214
   Chao J, 2012, INT WORKSH DIG WAT, P267, DOI DOI 10.1007/978-3-642-40099-5_22
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Choi BD, 2007, IEEE T CIRC SYST VID, V17, P407, DOI 10.1109/TCSVT.2007.893835
   Dar Yehuda, 2015, IEEE Trans Image Process, V24, P2051, DOI 10.1109/TIP.2015.2412378
   Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2, P263
   Ding XL, 2019, IEEE T CIRC SYST VID, V29, P1893, DOI 10.1109/TCSVT.2018.2852799
   Ding XL, 2019, MULTIMED TOOLS APPL, V78, P7453, DOI 10.1007/s11042-018-6504-5
   Ding X, 2018, IEEE T CIRC SYST VID, V28, P1497, DOI 10.1109/TCSVT.2017.2676162
   Feng CH, 2017, IEEE T CIRC SYST VID, V27, P2543, DOI 10.1109/TCSVT.2016.2593612
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Hastie T, 1998, ANN STAT, V26, P451
   Hsu CC, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P170, DOI 10.1109/MMSP.2008.4665069
   Jia S., 2014, P MULT COMM COMP APP, P177
   Jia S, 2018, IEEE ACCESS, V6, P25323, DOI 10.1109/ACCESS.2018.2819624
   Jung D.J., 2017, MULTIMED TOOLS APPL, P1
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Li QH, 2016, IEEE SIGNAL PROC LET, V23, P541, DOI 10.1109/LSP.2016.2537321
   Li R., 2016, MIKROCHIM ACTA, P1
   Li R, 2014, J DISP TECHNOL, V10, P1010, DOI 10.1109/JDT.2014.2334598
   Mahdian B, 2008, IEEE T INF FOREN SEC, V3, P529, DOI 10.1109/TIFS.2004.924603
   Milani S, 2012, APSIPA TRANS SIGNAL, V1, DOI 10.1017/ATSIP.2012.2
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Portz T, 2012, PROC CVPR IEEE, P1752, DOI 10.1109/CVPR.2012.6247871
   Rijsbergen C. J. V., 1979, Information Retrieval
   Singh RD, 2017, J CIRCUIT SYST COMP, V26, DOI 10.1142/S0218126617501079
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Stamm MC, 2012, IEEE T INF FOREN SEC, V7, P1315, DOI 10.1109/TIFS.2012.2205568
   Su LC, 2018, IEEE T MULTIMEDIA, V20, P825, DOI 10.1109/TMM.2017.2760098
   Sun DQ, 2014, INT J COMPUT VISION, V106, P115, DOI 10.1007/s11263-013-0644-x
   Wang W, 2013, IEEE INT CON DIS, P244, DOI 10.1109/ICDCSW.2013.69
   Wang W, 2007, IEEE T INF FOREN SEC, V2, P438, DOI 10.1109/TIFS.2007.902661
   Xia M, 2017, MULTIMED TOOLS APPL, V76, P8399, DOI 10.1007/s11042-016-3468-1
   Yao H., 2019, J REAL-TIME IMAGE PR, P1
   Yao YX, 2016, J INF SECUR APPL, V26, P39, DOI 10.1016/j.jisa.2015.12.001
   YIN S, 2018, FUTURE INTERNET, V10, P9, DOI DOI 10.1039/C7AY02501G
   Yoo DG, 2013, J DISP TECHNOL, V9, P840, DOI 10.1109/JDT.2013.2263374
   Yuxing Wu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2674, DOI 10.1109/ICASSP.2014.6854085
NR 41
TC 5
Z9 5
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28729
EP 28754
DI 10.1007/s11042-020-09340-4
EA AUG 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000556646300006
DA 2024-07-18
ER

PT J
AU Lee, WY
   Kim, KH
   Yang, H
   Ko, YW
AF Lee, Wan Yeon
   Kim, Kyong Hoon
   Yang, Hyeim
   Ko, Young Woong
TI Automatic reconstruction of deleted AVI video files composed of
   scattered and corrupted fragments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic reconstruction; Scattered video fragments; Corrupted video;
   AVI format; FAT32
ID LINUX FAT32 ALLOCATOR
AB Video files of surveillance cameras frequently play a role of major evidence for criminals or accidents. But, if the video file containing the evidence is deleted, we need to recover it if possible. In this paper, we propose a recovery scheme for deleted video files with AVI format on FAT32 file system. The proposed scheme first recovers deleted video files from unallocated storage space exploiting both signatures of video frames and behaviours of file systems. The scheme finds fragments of deleted video files based on the start indicator of video frames or the file header signature, and connects the found fragments based on the file allocation patterns of FAT32 file system. Next, if a recovered video file is partially corrupted, the scheme automatically reconstructs the corrupted AVI video file so that the video file can be played back. The lost file header of the corrupted video file is reconstructed based on the file header of a reference video file, and the lost data multimedia data is filled with zero. Through practical implementation, we show that the proposed scheme recovers deleted video files from unallocated storage space and reconstructs corrupted AVI video files.
C1 [Lee, Wan Yeon; Yang, Hyeim] Dongduk Womens Univ, Dept Comp Sci, Seoul 02748, South Korea.
   [Kim, Kyong Hoon] Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu 41566, South Korea.
   [Ko, Young Woong] Hallym Univ, Dept Comp Sci & Engn, Chunchon 24252, South Korea.
C3 Dongduk Women's University; Kyungpook National University; Hallym
   University
RP Lee, WY (corresponding author), Dongduk Womens Univ, Dept Comp Sci, Seoul 02748, South Korea.
EM wanlee@dongduk.ac.kr
RI Kim, Sun/GSN-4867-2022
FU Basic Science Research Program through the National Research Foundation
   Korea (NRF) - Ministry of Education [NRF-2018R1D1A1B07045806]; National
   Research Foundation of Korea [21A20131600005] Funding Source: Korea
   Institute of Science & Technology Information (KISTI), National Science
   & Technology Information Service (NTIS)
FX This research was supported by Basic Science Research Program through
   the National Research Foundation Korea (NRF) funded by the Ministry of
   Education (NRF-2018R1D1A1B07045806).
CR Alghafli K, 2016, INT CONF INTERNET, P267, DOI 10.1109/ICITST.2016.7856710
   [Anonymous], 2005, File System Forensic Analysis
   Casey E, 2014, DIGIT INVEST, V11, pS30, DOI 10.1016/j.diin.2014.05.010
   Garfinkel SL, 2007, DIGIT INVEST, V4, pS2, DOI 10.1016/j.diin.2007.06.017
   Lee WY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9245522
   Lee WY, 2015, DIGIT INVEST, V15, P119, DOI 10.1016/j.diin.2015.09.003
   Microsoft, 2000, MICR EXT FIRMW IN FA
   Microsoft, 2018, AVI FIL FORM
   Minnaard W, 2014, DIGIT INVEST, V11, P224, DOI 10.1016/j.diin.2014.06.008
   Na G.H., 2013, IEEE T IMAGE PROCESS, V23, P317
   Poisel Rainer, 2013, 2013 International Conference on Availability, Reliability and Security (ARES), P475, DOI 10.1109/ARES.2013.62
   Poisel R, 2013, INT J MOB COMPUT MUL, V5, P50, DOI 10.4018/jmcmc.2013070104
   Richard G., 2005, P1
   Sim S.G., 2019, U.S. Patent, Patent No. [10,382,835, 10382835]
   Song J, 2016, DIGIT INVEST, V18, P1, DOI 10.1016/j.diin.2016.06.001
   Yang YT, 2017, MULTIMED TOOLS APPL, V76, P3293, DOI 10.1007/s11042-016-3716-4
   Yoo B, 2012, MULTIMED TOOLS APPL, V61, P243, DOI 10.1007/s11042-010-0704-y
NR 17
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28355
EP 28367
DI 10.1007/s11042-020-09404-5
EA AUG 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000554436700002
DA 2024-07-18
ER

PT J
AU Karmakar, J
   Nandi, D
   Mandal, MK
AF Karmakar, J.
   Nandi, D.
   Mandal, M. K.
TI A novel hyper-chaotic image encryption with sparse-representation based
   compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dictionary learning; Sparse-representation; Run-length encoding; Image
   compression; Hyper-chaotic system; Image encryption
ID ALGORITHM; DICTIONARIES
AB This digital era uses lots of images in communication, which are confidential and large in volume. The transmission channel thus arises the question of security as well as transmission load. To date, several works are there to solve this issue. However, they fail to provide a single unit that gives these two facilities in a unified way. This paper presents a novel technique of unification of image compression and encryption in a single module via sparse-representation of image frames and hyper-chaotic encryption techniques. In this work, we have proposed a method to estimates the sparse vectors of a given image using a regularized trained over-complete dictionary and encrypt the non-zero coefficients of the sparse vectors using key-streams generated by a hyper-chaotic system. This sparse coding based encryption technique provides a higher compression ratio (CR) compared to some recently proposed techniques on one side and increases security level on the other side. Moreover, the security is strengthened by using this key-sequence in different steps in the encryption scheme. Thus the compressed-encrypted outputs are stronger than simple chaotic encryption against any intruder. The efficiency and authenticity of the proposed algorithm are verified through several quality-index e.g. entropy, CR, etc. The resistivity of the proposed algorithm toward the known or chosen-plaintext attack is also analyzed. The results of the key sensitivity test, and cropping attack test also ensure the authors' claim. The comparison of the proposed technique with some recently published works justifies the reliability of this work.
C1 [Karmakar, J.; Mandal, M. K.] Natl Inst Technol, Dept Phys, Durgapur 713209, India.
   [Nandi, D.] Natl Inst Technol, Dept Comp Sci & Engn, Durgapur 713209, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Durgapur; National Institute of Technology (NIT System);
   National Institute of Technology Durgapur
RP Mandal, MK (corresponding author), Natl Inst Technol, Dept Phys, Durgapur 713209, India.
EM mrinalkanti.mandal@phy.nitdgp.ac.in
RI Mandal, Mrinal Kanti/AAB-7729-2019
OI Mandal, Dr. Mrinal Kanti/0000-0001-6031-9329; Karmakar,
   Jayashree/0000-0001-9771-1711
FU National Institute of Technology Durgapur, India
FX This work was supported by the National Institute of Technology
   Durgapur, India.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2006, ADV NEURAL INF PROCE
   Blake A.Isard., 2012, Active Contours: The Application of Techniques from Graphics, Vision, Control Theory and Statistics to Visual Tracking of Shapes in Motion
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Çavusoglu Ü, 2016, SECUR COMMUN NETW, V9, P1285, DOI 10.1002/sec.1414
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chan KS, 2004, IEEE T SIGNAL PROCES, V52, P2975, DOI 10.1109/TSP.2004.833864
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Dachselt F, 2001, IEEE T CIRCUITS-I, V48, P1498, DOI 10.1109/TCSI.2001.972857
   Faragallah OS, 2011, INF SECUR J, V20, P135, DOI 10.1080/19393555.2011.560926
   Guan KY, 2014, IMPORTANT NOTES LYAP
   Hermassi H, 2014, MULTIMED TOOLS APPL, V72, P2211, DOI 10.1007/s11042-013-1533-6
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Li CQ, 2013, NONLINEAR DYNAM, V73, P2083, DOI 10.1007/s11071-013-0924-6
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Memos VA, 2018, FUTURE GENER COMP SY, V83, P619, DOI 10.1016/j.future.2017.04.039
   Ning K, 2010, ARXIV09032693
   Pavan RL, 1998, RC6 BLOCK CIPHER V1
   Plageras AP, 2018, FUTURE GENER COMP SY, V82, P349, DOI 10.1016/j.future.2017.09.082
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Psannis KE, 2006, EURASIP J WIREL COMM, DOI 10.1155/WCN/2006/24616
   Rivest RonaldL., 1995, The RC5 Encryption Algorithm
   Setyaningsih E, 2017, INT J ADV COMPUT SC, V8, P83
   Stergiou C., 2018, Journal of Multimedia Information System, V5, P27
   Stergiou C, 2018, FUTURE GENER COMP SY, V78, P964, DOI 10.1016/j.future.2016.11.031
   Stergiou C, 2017, MULTIMED TOOLS APPL, V76, P22803, DOI 10.1007/s11042-017-4590-4
   Taheri AM, 2018, MULTIMED TOOLS APPL, V77, P31095, DOI 10.1007/s11042-018-6197-9
   Tong XJ, 2016, NONLINEAR DYNAM, V84, P2333, DOI 10.1007/s11071-016-2648-x
   Tong XJ, 2013, NONLINEAR DYNAM, V72, P229, DOI 10.1007/s11071-012-0707-5
   Wang H, 2019, SIGNAL PROCESS, V155, P218, DOI 10.1016/j.sigpro.2018.10.001
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu CP, 2005, IEEE T MULTIMEDIA, V7, P828, DOI 10.1109/TMM.2005.854469
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhan K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.6.063004
   ZHANG GY, 2017, ADV DIFFER EQU 0801
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang XP, 2017, MULTIMED TOOLS APPL, V76, P15641, DOI 10.1007/s11042-016-3861-9
   Zhang YS, 2016, IEEE ACCESS, V4, P2507, DOI 10.1109/ACCESS.2016.2569421
   Zhang Z, 2016, ARXIV160207017V1CSCV
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   Zhu HG, 2013, SIGNAL PROCESS-IMAGE, V28, P670, DOI 10.1016/j.image.2013.02.004
NR 44
TC 17
Z9 17
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28277
EP 28300
DI 10.1007/s11042-020-09125-9
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000554436800004
DA 2024-07-18
ER

PT J
AU Sameer, VU
   Naskar, R
AF Sameer, Venkata Udaya
   Naskar, Ruchira
TI Deep siamese network for limited labels classification in source camera
   identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camera; Classification; Few shot; Limited labels; Siamese; Source camera
   identification
ID PRNU; MODEL
AB Source Camera Identification is a well-known digital forensic challenge of mapping an image to its authentic source. The current state-of-the-art provides a number of successful and efficient solutions to this problem. However, in almost all such existing techniques, a sufficiently large number of image samples is required for pre-processing, before source identification.Limited labels classificationis a realistic scenario for a forensic analyst where s/he has access only to afewlabelled training samples, available for source camera identification. In such contexts, where obtaining a vast number of image samples (per camera) is infeasible, correctness of existing source identification schemes, is threatened. In this paper, we address the problem of performing accurate source camera identification, with a limited set of labelled training samples, per camera model. We use afew shot learning techniqueknown asdeep siamese networkhere, and achieve significantly improved classification accuracy than the state-of-the-art. Here, the main principle of operation is to form pairs of samples from the same camera models, as well as from different camera models, to enhance the training space. Subsequently, a deep neural network is used to perform source classification. We perform experiments on traditional camera model identification, as well asintra-makeandintra-devicesource identification. We also show that our proposed methodology under limited labels scenario, is robust to image transformations such as rotation, scaling, compression, and additive noise.
C1 [Sameer, Venkata Udaya] Natl Inst Technol, Dept Comp Sci & Engn, Rourkela 769008, India.
   [Naskar, Ruchira] Indian Inst Engn Sci & Technol, Dept Informat Technol, Sibpur 711103, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela; Indian Institute of Engineering Science Technology
   Shibpur (IIEST)
RP Sameer, VU (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Rourkela 769008, India.
EM sameer.udaya.venkata@gmail.com; ruchira@it.iiests.ac.in
CR Akshatha KR, 2016, DIGIT INVEST, V19, P69, DOI 10.1016/j.diin.2016.10.002
   [Anonymous], 2010, J DIGITAL FORENSIC P
   [Anonymous], 2009, MEDIA FORENSICS SECU
   [Anonymous], 2016, IEEE INT WORKS INFOR
   [Anonymous], 2006, PROC IEEE COMPUT SOC
   Bayram S, 2015, IEEE T INF FOREN SEC, V10, P597, DOI 10.1109/TIFS.2014.2385634
   Berlemont S, 2018, NEUROCOMPUTING, V273, P47, DOI 10.1016/j.neucom.2017.07.060
   Bondi L, 2017, IEEE SIGNAL PROC LET, V24, P259, DOI 10.1109/LSP.2016.2641006
   Çeliktutan O, 2008, IEEE T INF FOREN SEC, V3, P553, DOI 10.1109/TIFS.2008.926993
   Chen C, 2015, J SENSORS, V2015, DOI 10.1155/2015/506909
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Dirik AE, 2008, IEEE T INF FOREN SEC, V3, P539, DOI 10.1109/TIFS.2008.926987
   Dirik AE, 2014, IEEE T INF FOREN SEC, V9, P2277, DOI 10.1109/TIFS.2014.2361200
   Divekar P, 2015, P AMER CONTR CONF, P13, DOI 10.1109/ACC.2015.7170704
   Gloe Thomas, 2012, Transactions on Data Hiding and Multimedia Security VIII. Pattern Recognition for IT Security, P42, DOI 10.1007/978-3-642-31971-6_3
   Huang YG, 2015, IEEE T INF FOREN SEC, V10, P2692, DOI 10.1109/TIFS.2015.2474836
   Karaküçük A, 2015, DIGIT INVEST, V12, P66, DOI 10.1016/j.diin.2015.01.017
   Kharrazi M, 2004, IEEE IMAGE PROC, P709
   Koch G, 2015, 32 INT C MACH LEARN, V37
   Lawgaly A, 2017, IEEE T INF FOREN SEC, V12, P392, DOI 10.1109/TIFS.2016.2620280
   Li CT, 2010, IEEE T INF FOREN SEC, V5, P280, DOI 10.1109/TIFS.2010.2046268
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Lin XF, 2017, IEEE T INF FOREN SEC, V12, P793, DOI 10.1109/TIFS.2016.2636086
   Lin XF, 2016, IEEE T INF FOREN SEC, V11, P126, DOI 10.1109/TIFS.2015.2478748
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Marra F, 2017, IEEE T INF FOREN SEC, V12, P2197, DOI 10.1109/TIFS.2017.2701335
   Marra F, 2017, MULTIMED TOOLS APPL, V76, P4765, DOI 10.1007/s11042-016-3663-0
   Sabri M, 2018, NEUROCOMPUTING, V313, P143, DOI 10.1016/j.neucom.2018.06.054
   Shullani D, 2017, EURASIP J INF SECUR, DOI 10.1186/s13635-017-0067-2
   Thai TH, 2016, DIGIT SIGNAL PROCESS, V48, P285, DOI 10.1016/j.dsp.2015.10.002
   Thai TH, 2015, DIGIT SIGNAL PROCESS, V40, P88, DOI 10.1016/j.dsp.2015.01.002
   Tuama A., 2015, INT WORKSHOP DIGITAL, P83
   Tuama A, 2016, IEEE INT WORKS INFOR
   Xu BC, 2016, NEUROCOMPUTING, V207, P131, DOI 10.1016/j.neucom.2016.05.012
   Xu G, 2012, PROCEEDINGS OF THE ASME SUMMER BIOENGINEERING CONFERENCE, PTS A AND B, P397
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P1635, DOI 10.1109/TPAMI.2012.253
   Zeng H, 2016, MULTIMED TOOLS APPL, V75, P13871, DOI 10.1007/s11042-015-3072-9
NR 38
TC 14
Z9 16
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28079
EP 28104
DI 10.1007/s11042-020-09106-y
EA JUL 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000559382200002
DA 2024-07-18
ER

PT J
AU Rodrigues, GD
   Albertini, MK
   Yang, XM
AF Rodrigues, Gabriel Damasceno
   Albertini, Marcelo Keese
   Yang, Xiaomin
TI An empirical evaluation of random transformations applied to ensemble
   clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data clustering; Clustering ensembles; Random transformations;
   Mahalanobis
AB Ensemble clustering techniques have improved in recent years, offering better average performance between domains and data sets. Benefits range from finding novelty clustering which are unattainable by any single clustering algorithm to providing clustering stability, such that the quality is little affected by noise, outliers or sampling variations. The main clustering ensemble strategies are: to combine results of different clustering algorithms; to produce different results by resampling the data, such as in bagging and boosting techniques; and to execute a given algorithm multiple times with different parameters or initialization. Often ensemble techniques are developed for supervised settings and later adapted to the unsupervised setting. Recently, Blaser and Fryzlewicz proposed an ensemble technique to classification based on resampling and transforming input data. Specifically, they employed random rotations to improve significantly Random Forests performance. In this work, we have empirically studied the effects of random transformations based in rotation matrices, Mahalanobis distance and density proximity to improve ensemble clustering. Our experiments considered 12 data sets and 25 variations of random transformations, given a total of 5580 data sets applied to 8 algorithms and evaluated by 4 clustering measures. Statistical tests identified 17 random transformations that are viable to be applied to ensembles and standard clustering algorithms, which had positive effects on cluster quality. In our results, the best performing transforms were Mahalanobis-based transformations.
C1 [Rodrigues, Gabriel Damasceno; Albertini, Marcelo Keese] Univ Fed Uberlandia, Fac Comp Sci, Ave Joao Naves de Avila 2-121,1B-150, Uberlandia, MG, Brazil.
   [Yang, Xiaomin] Sichuan Univ, Coll Elect & Informat Engn, 24 South Sect 1,1st Ring Rd,Room 501-510, Chengdu, Sichuan, Peoples R China.
C3 Universidade Federal de Uberlandia; Sichuan University
RP Rodrigues, GD (corresponding author), Univ Fed Uberlandia, Fac Comp Sci, Ave Joao Naves de Avila 2-121,1B-150, Uberlandia, MG, Brazil.
EM gabriel.grs@live.com; albertini@ufu.br; yxmyxm2001@163.com
RI Albertini, Marcelo K/J-7495-2012; yang, xiao/HJI-7815-2023
OI Albertini, Marcelo/0000-0002-1846-946X
FU CoordenacAo de Aperfeicoamento de Pessoal de Nivel Superior - Brasil
   (CAPES) [001]; CAPES-PrInt internationalization funding program
FX This study was financed in part by the CoordenacAo de Aperfeicoamento de
   Pessoal de Nivel Superior - Brasil (CAPES) - Finance Code 001, and also
   it is funded by CAPES-PrInt internationalization funding program.
CR [Anonymous], PATTERN RECOGNITION
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Bache K, 2013, UCI machine learning repository
   Barthelemy J, 1991, MATH SUBJECT CLASSIF, V19, P34
   Ben-Hur Asa, 2002, Pac Symp Biocomput, P6
   Blaser R, 2016, J MACH LEARN RES, V17
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Brijnesh JJ, 2016, ARXIV160407711
   Campello RJGB, 2015, ACM T KNOWL DISCOV D, V10, DOI 10.1145/2733381
   Conover W. J., 1979, Los Alamos Sci. Lab. Tech. Rep. LA-7677-MS1
   da Silva GR, 2017, 2017 6TH BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS), P312, DOI 10.1109/BRACIS.2017.78
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   DIACONIS P, 1994, J APPL PROBAB, V31A, P49, DOI 10.2307/3214948
   Dudoit S, 2003, BIOINFORMATICS, V19, P1090, DOI 10.1093/bioinformatics/btg038
   Dunn J. C., 1974, Journal of Cybernetics, V4, P95, DOI 10.1080/01969727408546059
   EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Fern X. Z., 2003, P 20 INT C MACHINE L, P186
   Fred ALN, 2005, IEEE T PATTERN ANAL, V27, P835, DOI 10.1109/TPAMI.2005.113
   Fred ALN, 2002, INT C PATT RECOG, P276, DOI 10.1109/ICPR.2002.1047450
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Frossyniotis D, 2004, PATTERN RECOGN LETT, V25, P641, DOI 10.1016/j.patrec.2003.12.018
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   HOUSEHOLDER AS, 1958, J ACM, V5, P339, DOI 10.1145/320941.320947
   HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Leisch F., 1999, WORKING PAPERS SFB, V51
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Mahalanobis P. C., 1936, P NATL I SCI INDIA, V2, P49
   Mehta P, 2019, PHYS REP, V810, P1, DOI 10.1016/j.physrep.2019.03.001
   Minaei-Bidgoli B, 2004, ITCC 2004: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 2, PROCEEDINGS, P188, DOI 10.1109/ITCC.2004.1286629
   Minaei-Bidgoli B, 2014, ARTIF INTELL REV, V41, P27, DOI 10.1007/s10462-011-9295-x
   Ostrovsky R, 2006, ANN IEEE SYMP FOUND, P165
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760
   Siersdorfer S., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P226, DOI 10.1145/1008992.1009032
   Stoyanov K, 2015, THESIS
   Strehl A, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P93, DOI 10.1162/153244303321897735
   Topchy A, 2004, SIAM PROC S, P379
   Topchy A, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P331
   Vendramin Lucas, 2010, Statistical Analysis and Data Mining, V3, P209, DOI 10.1002/sam.10080
   Witten IH, 2011, MOR KAUF D, P1
   Wu JJ, 2015, IEEE T KNOWL DATA EN, V27, P155, DOI 10.1109/TKDE.2014.2316512
   Yu ZW, 2016, IEEE T KNOWL DATA EN, V28, P701, DOI 10.1109/TKDE.2015.2499200
NR 45
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34253
EP 34285
DI 10.1007/s11042-020-08947-x
EA JUL 2020
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000555554200002
DA 2024-07-18
ER

PT J
AU Ouvrard, X
   Le Goff, JM
   Marchand-Maillet, S
AF Ouvrard, Xavier
   Le Goff, Jean-Marie
   Marchand-Maillet, Stephane
TI Exchange-based diffusion in Hb-Graphs Highlighting complex relationships
   in multimedia collections (extended version)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Exchange; Diffusion; Multiset; Hyper-bag-graph; Information retrieval;
   Ranking
AB Highlighting important information of a network is commonly achieved by using random walks related to diffusion over such structures. Complex networks, where entities can have multiple relationships, call for a modeling based on hypergraphs. But, the limitation of hypergraphs to binary entities in co-occurrences has led us to introduce a new mathematical structure called hyperbaggraphs, that relies on multisets. This is not only a shift in the designation but a real change of mathematical structure, with a new underlying algebra. Diffusion processes commonly start with a stroke at one vertex and diffuse over the network. In the original conference article-(Ouvrard et al.2018)-that this article extends we have proposed a two-phase step exchange-based diffusion scheme, in the continuum of spectral network analysis approaches, that takes into account the multiplicities of entities. This diffusion scheme allows to highlight information not only at the level of the vertices but also at the regrouping level. In this paper, we present new contributions: the proofs of conservation and convergence of the extracted sequences of the diffusion process, as well as the illustration of the speed of convergence and comparison between classical and modified random walks; the algorithms of the exchange-based diffusion and the modified random walk; the application to two use cases, one based on Arxiv publications and another based on Coco dataset images. All the figures have been revisited in this extended version to take the new developments into account.
C1 [Ouvrard, Xavier; Le Goff, Jean-Marie] Univ Geneva, CUI, Battelle Bat A,Route Drize 7, CH-1227 Carouge, Switzerland.
   [Ouvrard, Xavier; Marchand-Maillet, Stephane] CERN, 1 Esplanade Particules, CH-1211 Geneva, Switzerland.
C3 University of Geneva; European Organization for Nuclear Research (CERN)
RP Ouvrard, X (corresponding author), Univ Geneva, CUI, Battelle Bat A,Route Drize 7, CH-1227 Carouge, Switzerland.; Ouvrard, X (corresponding author), CERN, 1 Esplanade Particules, CH-1211 Geneva, Switzerland.
EM xavier.ouvrard@cern.ch
RI OUVRARD, Xavier/AAU-7983-2021
OI OUVRARD, Xavier/0000-0003-4054-2771; Marchand-Maillet,
   Stephane/0000-0002-4875-6101
CR [Anonymous], 2007, Novi Sad Journal of Mathematics
   Bellaachia A., 2013, P 2013 INT C APPL MA, P187
   Bendersky M, 2012, MODELING HIGHER ORDE, V941
   Berge C., 1973, Graphs and Hypergraphs
   Bretto Alain, 2013, MATH ENG
   Bu J, 2010, P INT C MULT MM 10 F, V391
   Chauve Cedric, 2013, Combinatorial Algorithms. 24th International Workshop, IWOCA 2013. Revised Selected Papers: LNCS 8288, P428, DOI 10.1007/978-3-642-45278-9_37
   Chih-Fong Tsai, 2012, ISRN Artificial Intelligence, DOI 10.5402/2012/376804
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Cummins N, 2018, IEEE INT C AC SPEECH, P2018
   Deselaers T, 2008, INT C PATT RECOG, P2100
   Ducournau A, 2014, COMPUT VIS IMAGE UND, V120, P91, DOI 10.1016/j.cviu.2013.10.012
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Girish KP., 2012, Theory Appl Math Comput Sci, V2, P37
   Grossman J, 1995, C NUM, P129, DOI [DOI 10.1016/S0304-5412, 10.1016/S0304-5412]
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Karypis G, 1999, IEEE T VLSI SYST, V7, P69, DOI 10.1109/92.748202
   Kim HK, 2017, NEUROCOMPUTING, V266, P336, DOI 10.1016/j.neucom.2017.05.046
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lu L, 2011, HIGH ORDERED RANDOM
   Ma SM, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P332
   Marchand-Maillet S., 2018, ARXIV180511952
   Minaee S., 2017, P IEEE INT S CIRC SY, P1, DOI DOI 10.1109/ISCAS.2017.8050421
   Newman MEJ, 2001, PHYS REV E, V64, DOI [10.1103/PhysRevE.64.016132, 10.1103/PhysRevE.64.016131]
   Ouvrard X, 2018, CBMI P
   Ouvrard X, 2020, LNCS
   Ouvrard X, 2019, J COMBINATORIAL MATH
   Ouvrard X, 2019, ARXIV180900190V2
   Ouvrard X., 2018, ELECT NOTES DISCRETE, V70, P65
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Purda L, 2015, CONTEMP ACCOUNT RES, V32, P1193, DOI 10.1111/1911-3846.12089
   Schmitt M, 2016, BAG OF AUDIO WORDS A
   Shekhar R., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P297, DOI 10.1109/DAS.2012.96
   Shin D, 2011, AUTON SYST, P201, DOI 10.1007/978-3-0348-0031-0_11
   Silva FB, 2018, PATTERN RECOGN, V74, P266, DOI 10.1016/j.patcog.2017.09.018
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Taramasco C, 2010, SCIENTOMETRICS, V85, P721, DOI 10.1007/s11192-010-0226-4
   Temkin Oleg N, 2020, CHEM REACTION NETWOR
   Wang YX, 2018, IEEE T IMAGE PROCESS, V27, P4437, DOI 10.1109/TIP.2018.2837219
   Xu ZH, 2016, INT CONF CLOUD COMPU, P494, DOI 10.1109/CCIS.2016.7790309
   Zhao J, 2013, IEEE T VIS COMPUT GR, V19, P2080, DOI 10.1109/TVCG.2013.167
   Zhou D, 2007, 2007 IEEE NORTH-EAST WORKSHOP ON CIRCUITS AND SYSTEMS, P167, DOI 10.1109/CADCG.2007.4407875
   Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389
NR 43
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22429
EP 22464
DI 10.1007/s11042-020-09176-y
EA JUL 2020
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000549799000004
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Dong, QJ
   He, XD
   Ge, HY
   Liu, Q
   Han, AF
   Zhou, SZ
AF Dong, Qiujie
   He, Xuedong
   Ge, Haiyan
   Liu, Qin
   Han, Aifu
   Zhou, Shengzong
TI Improving model drift for robust object tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Correlation filters; Primary and secondary peaks
   detection; Confidence function; Adaptive discriminant; Adaptive merge
AB Discriminative correlation filters show excellent performance in object tracking. However, in complex scenes, the apparent characteristics of the tracked target are variable, which makes it easy to pollute the model and cause the model drift. In this paper, considering that the secondary peak has a greater impact on the model update, we propose a method for detecting the primary and secondary peaks of the response map. Secondly, a novel confidence function which uses the adaptive update discriminant mechanism is proposed, which yield good robustness. Thirdly, we propose a robust tracker with correlation filters, which uses hand-crafted features and can improve model drift in complex scenes. Finally, in order to cope with the current trackers' multi-feature response merge, we propose a simple exponential adaptive merge approach. Extensive experiments are performed on OTB2013, OTB100 and TC128 datasets. Our approach performs superiorly against several state-of-the-art trackers while runs in real-time.
C1 [Dong, Qiujie; Liu, Qin; Han, Aifu; Zhou, Shengzong] Chinese Acad Sci, Fujian Inst Res Struct Matter, Fuzhou 350002, Peoples R China.
   [Dong, Qiujie; Han, Aifu] North Univ China, Taiyuan 030051, Peoples R China.
   [He, Xuedong] Sun Yat Sen Univ, Sch Intelligent Syst Engn, Shenzhen, Peoples R China.
   [Ge, Haiyan] Shandong Univ Technol, Zibo 255049, Peoples R China.
C3 Chinese Academy of Sciences; Fujian Institute of Research on the
   Structure of Matter, CAS; North University of China; Sun Yat Sen
   University; Shandong University of Technology
RP Zhou, SZ (corresponding author), Chinese Acad Sci, Fujian Inst Res Struct Matter, Fuzhou 350002, Peoples R China.
EM zhousz@fjirsm.ac.cn
OI He, Xuedong/0000-0003-4048-6976
FU Chinese Academy of Sciences STS Projects [2019 T31020008, 2019
   T31020010]; Fujian Provincial Department of Science and Technology
   Project [cyzx201805063]
FX The authors acknowledge the Chinese Academy of Sciences STS Projects.
   (Grant: 2019 T31020008, 2019 T31020010), the Fujian Provincial
   Department of Science and Technology Project (Grant: cyzx201805063).
CR Bertinetto L, 2016, ARXIV E PRINTS
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chen BY, 2019, PATTERN RECOGN, V87, P80, DOI 10.1016/j.patcog.2018.10.005
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   Fan H, 2018, ARXIV E PRINTS
   [葛宝义 Ge Baoyi], 2018, [中国图象图形学报, Journal of Image and Graphics], V23, P1091
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Kristan M., 2018, P EUROPEAN C COMPUTE
   Li B, 2018, ARXIV E PRINTS
   Li Y., 2017, ARXIV E PRINTS
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Ma C, 2018, INT J COMPUT VISION, V126, P771, DOI 10.1007/s11263-018-1076-4
   Nam H, 2015, ARXIV E PRINTS
   Valmadre J, 2017, ARXIV E PRINTS
   Wang M, 2017, ARXIV E PRINTS
   Wang Q, 2017, ARXIV E PRINTS
   Wang Q. Y., 2018, EURASIP J WIREL COMM, V2018, P1, DOI DOI 10.1155/2018/5798453
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Zhang Z, 2019, ARXIV E PRINTS
   Zhu Z, 2018, LECT NOTES COMPUT SC, V11213, P103, DOI 10.1007/978-3-030-01240-3_7
NR 31
TC 4
Z9 4
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25801
EP 25815
DI 10.1007/s11042-020-09032-z
EA JUL 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000546222500001
DA 2024-07-18
ER

PT J
AU Niu, Y
   Zhou, Z
   Zhang, XC
AF Niu, Ying
   Zhou, Zheng
   Zhang, Xuncai
TI An image encryption approach based on chaotic maps and genetic
   operations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaotic map; Genetic operation; DNA code; Nucleotide
   sequences database
ID DNA-SEQUENCE OPERATION; ALGORITHM; SYSTEM; MODEL
AB This paper puts forward an image encryption approach using chaotic maps and genetic operations. First, the Keccak algorithm is employed to compute the hash values of a plain-image as the initial values for chaotic map. The sensitivity and pseudo randomness of chaotic map used for the initial conditions allows for pseudorandom sequences to be obtained by iterative logistic map to shuffle and permute the pixel positions and values of the image. Second, in combination with the Henon map and the DNA coding technique, genetic operations at the bit level are used to achieve pixel selection, crossover and mutation, as well as further completion of pixel diffusion and scrambling, which significantly increases the difficulty of deciphering the algorithm. Finally, the diffusion and confusion features of the algorithm are further strengthened by bidirectional exclusive OR operations with chaotic sequences. The theoretical analysis and simulation results indicate that the algorithm is sensitive to keys and can effectively defend statistical and differential attacks, indicating that it has good security and application potential.
C1 [Niu, Ying] Zhengzhou Univ Light Ind, Sch Architecture Environm Engn, Zhengzhou 450002, Peoples R China.
   [Zhou, Zheng; Zhang, Xuncai] Zhengzhou Univ Light Ind, Sch Elect & Informat Engn, Zhengzhou 450002, Peoples R China.
C3 Zhengzhou University of Light Industry; Zhengzhou University of Light
   Industry
RP Zhang, XC (corresponding author), Zhengzhou Univ Light Ind, Sch Elect & Informat Engn, Zhengzhou 450002, Peoples R China.
EM zhangxuncai@163.com
RI ; Zhou, Zheng/P-7221-2018
OI Zhang, Xuncai/0000-0002-2190-7651; Zhou, Zheng/0000-0002-8971-5226
FU National Natural Science Foundation of China [61572446, 61602424]; Key
   Research and Development Program of Henan Province [202102210177,
   192102210134]
FX The work for this paper was supported by the National Natural Science
   Foundation of China (Grant nos. 61572446, 61602424), and the Key
   Research and Development Program of Henan Province (Grant nos.
   202102210177, 192102210134).
CR Abdallah EE, 2007, P GRAPH INT 2007 C M
   Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   Askar SS, 2018, IET IMAGE PROCESS, V12, P158, DOI 10.1049/iet-ipr.2016.0906
   Bakhshandeh A, 2013, OPT LASER ENG, V51, P665, DOI 10.1016/j.optlaseng.2013.01.001
   Benjeddou A, 2009, GLOB INF INFR S, V2009, P1
   Clelland CT, 1999, NATURE, V399, P533, DOI 10.1038/21092
   Dhall S, 2018, SIGNAL PROCESS, V146, P22, DOI 10.1016/j.sigpro.2017.12.021
   Elsheh E, 2011, EXPERT SYST APPL, V38, P13906, DOI 10.1016/j.eswa.2011.04.197
   Emad EAbdallah, 2009, SIGNAL IMAGE VIDEO P
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Erlich Y, 2017, SCIENCE, V355, P950, DOI 10.1126/science.aaj2038
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Hu GQ, 2017, NONLINEAR DYNAM, V88, P1305, DOI 10.1007/s11071-016-3311-2
   Kaur M, 2018, ELECTRON LETT, V54, P562, DOI 10.1049/el.2017.4426
   Kwok HS, 2007, CHAOS SOLITON FRACT, V32, P1518, DOI 10.1016/j.chaos.2005.11.090
   Li SJ, 2003, INT J BIFURCAT CHAOS, V13, P3063, DOI 10.1142/S0218127403008442
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Özkaynak F, 2018, NONLINEAR DYNAM, V92, P305, DOI 10.1007/s11071-018-4056-x
   Özkaynak F, 2014, NONLINEAR DYNAM, V78, P1311, DOI 10.1007/s11071-014-1517-8
   Peng J., 2009, 5 INT C NAT COMP
   Preishuber M, 2018, IEEE T INF FOREN SEC, P1
   Pujari SK, 2018, PROCEDIA COMPUT SCI, V125, P165, DOI 10.1016/j.procs.2017.12.023
   Raj R, 2016, CSI T ICT, V4, P1
   Ravichandran D, 2017, IEEE T NANOBIOSCI, V16, P850, DOI 10.1109/TNB.2017.2780881
   Shiu HJ, 2010, INFORM SCIENCES, V180, P2196, DOI 10.1016/j.ins.2010.01.030
   Sivakumar T., 2014, International Journal of Computer and Information Technology, V3, P1468
   Tinos R, 2018, IEEE T EVOLUTIONARY
   Wang XY, 2018, IEEE ACCESS, V6, P23733, DOI 10.1109/ACCESS.2018.2805847
   Wang XY, 2016, NONLINEAR DYNAM, V83, P333, DOI 10.1007/s11071-015-2330-8
   Wang XY, 2014, NONLINEAR DYNAM, V75, P345, DOI 10.1007/s11071-013-1070-x
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wei ZC, 2011, PHYS LETT A, V376, P102, DOI 10.1016/j.physleta.2011.10.040
   Wen WY, 2017, NONLINEAR DYNAM, V87, P383, DOI 10.1007/s11071-016-3049-x
   Zhang J., 2014, MATH PROBL ENG, V2014, P10, DOI DOI 10.1016/J.IJEPES.2014.09.041
   Zhang LY, 2018, IEEE T CYBERNETICS, V48, P1163, DOI 10.1109/TCYB.2017.2682561
   Zhang XQ, 2019, MULTIMED TOOLS APPL, V78, P7841, DOI 10.1007/s11042-018-6496-1
   Zhang X, 2018, IEEE PHOTONICS J, V10, DOI [10.1109/JPHOT.2018.2859257, 10.1109/JPHOT.2018.2818715]
   Zhang XC, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/6919675
   Zhang XC, 2009, COMPUT MATH APPL, V57, P2001, DOI 10.1016/j.camwa.2008.10.038
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 42
TC 47
Z9 48
U1 0
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25613
EP 25633
DI 10.1007/s11042-020-09237-2
EA JUL 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000545292000002
DA 2024-07-18
ER

PT J
AU Bulfone, A
   Drioli, C
   Ferrin, G
   Foresti, GL
AF Bulfone, Andrea
   Drioli, Carlo
   Ferrin, Giovanni
   Foresti, Gian Luca
TI A scalable system for the monitoring of video transmission components in
   delay-sensitive networked applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Delayed video communication; Distributed interaction; Networked
   teleoperation
ID LATENCY; TRACKING; ROBOT
AB The paper addresses the issue of measuring the end-to-end video delay due to the grabbing, display, and transmission components in networked video communication. We discuss the design and implementation of a scalable tool for the analysis and design of applications involving video based networked interaction or teleoperation, such as remotely operated devices and collaborative environments. The tool is intended for providing an accurate measure of the video lag involved in the encoding and streaming of video over packet networks, and for assessing the impact that delays in the video communication has in terms of human performance. The system is demonstrated through two different tasks: first, the measurement of video end-to-end delay for different networking configurations. Then, a visuomotor experiment is reported in which a subject is requested to accomplish a remote control task by using delayed video feedback, under different delay conditions.
C1 [Bulfone, Andrea; Drioli, Carlo; Foresti, Gian Luca] Univ Udine, Dept Math Comp Sci & Phys DMIF, Via Sci 206, Udine, Italy.
   [Ferrin, Giovanni] Univ Udine, Polyfunct Ctr CEPO, Via Prasecco 8, Pordenone, Italy.
C3 University of Udine; University of Udine
RP Drioli, C (corresponding author), Univ Udine, Dept Math Comp Sci & Phys DMIF, Via Sci 206, Udine, Italy.
EM andrea.bulfone@uniud.it; carlo.drioli@uniud.it;
   giovanni.ferrin@uniud.it; gianluca.foresti@uniud.it
CR ALLEN PK, 1993, IEEE T ROBOTIC AUTOM, V9, P152, DOI 10.1109/70.238279
   Boyaci O, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P194, DOI 10.1109/ISM.2009.46
   BUTTAZZO GC, 1993, PROCEEDINGS : IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, pC932
   Chafe C., 2004, P INT S MUS AC
   Chen HM, 2015, APSIPA TRANS SIGNAL, V4, DOI 10.1017/ATSIP.2015.21
   Di Luca M, 2010, PRESENCE-TELEOP VIRT, V19, P569, DOI 10.1162/pres_a_00023
   Drioli C, 2015, SIGNAL PROCESS-IMAGE, V39, P84, DOI 10.1016/j.image.2015.08.003
   Ellis SR, 1999, P IEEE VIRT REAL ANN, P218, DOI 10.1109/VR.1999.756954
   Gergle D., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1303
   Goel A, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1386109.1386113
   Gopalan K, 2006, ACM T MULTIM COMPUT, V2, P258, DOI 10.1145/1201730.1201732
   Hager GD, 2008, IEEE ROBOT AUTOM MAG, V15, P84, DOI 10.1109/MRA.2008.930401
   He WB, 2008, ACM T MULTIM COMPUT, V5, DOI 10.1145/1413862.1413869
   Hill R, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P89, DOI 10.1109/DICTA.2009.23
   Honda Takuya., 2012, PLoS ONE, V7
   Konstantas D, 1998, P ACM S APPL COMP SA, P456
   Kryczka A, 2013, IEEE INT SYM MULTIM, P271, DOI 10.1109/ISM.2013.52
   Lee YS, 2019, MULTIMEDIA TOOLS APP
   LEUNG GMH, 1995, IEEE T ROBOTIC AUTOM, V11, P105, DOI 10.1109/70.345941
   Li YT, 2017, MULTIMED TOOLS APPL, V76, P20781, DOI 10.1007/s11042-016-4002-1
   Lippi V, 2010, 2010 IEEE RO-MAN, P446, DOI 10.1109/ROMAN.2010.5598607
   Liu ZK, 2017, MULTIMED TOOLS APPL, V76, P26675, DOI 10.1007/s11042-016-4193-5
   Marescaux J, 2002, ANN SURG, V235, P487, DOI 10.1097/00000658-200204000-00005
   Martinel N, 2014, IEEE T SYST MAN CY-S, V44, P653, DOI 10.1109/TSMC.2013.2279661
   Miller K, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2990505
   Morice AHP, 2008, J NEUROSCI METH, V169, P255, DOI 10.1016/j.jneumeth.2007.11.020
   Nahrstedt K, 2011, MULTIMED TOOLS APPL, V51, P99, DOI 10.1007/s11042-010-0627-7
   Niemeyer G, 2004, INT J ROBOT RES, V23, P873, DOI 10.1177/0278364904045563
   Oboe R, 1998, INT J ROBOT RES, V17, P433, DOI 10.1177/027836499801700408
   Piciarelli C, 2016, IEEE T CIRC SYST VID, V26, P965, DOI 10.1109/TCSVT.2015.2426575
   Qi X, 2016, IEEE T MULTIMEDIA, V18, P1640, DOI 10.1109/TMM.2016.2572001
   Rodriguez-Gil L, 2018, MULTIMED TOOLS APPL, V77, P6471, DOI 10.1007/s11042-017-4556-6
   Sanders D, 2009, IND ROBOT, V36, P570, DOI 10.1108/01439910910994641
   Saunders JA, 2004, J NEUROSCI, V24, P3223, DOI 10.1523/JNEUROSCI.4319-03.2004
   Spearing R, 2005, 4 0 NASA COMMUNICATI
   Teather RJ, 2009, 3DUI : IEEE SYMPOSIUM ON 3D USER INTERFACES 2009, PROCEEDINGS, P43, DOI 10.1109/3DUI.2009.4811204
   van Angeren J, 2013, I C DIGIT ECOSYST TE, P37, DOI 10.1109/DEST.2013.6611326
   Ware C., 1994, ACM T COMPUT-HUM INT, V1, P331, DOI [DOI 10.1145/198425.198426[39]B, DOI 10.1145/198425.198426]
   Watson B, 1998, HUM FACTORS, V40, P403, DOI 10.1518/001872098779591287
   Winck RC, 2014, IEEE INT CONF ROBOT, P5952, DOI 10.1109/ICRA.2014.6907736
   Wu WX, 2013, PRESENCE-TELEOP VIRT, V22, P20, DOI 10.1162/PRES_a_00131
   Xu J., 2013, PROC 4 ACM MULTIMEDI, P238, DOI 10.1145/2483977.2484006
   Xu Y, 2014, IEEE ACM T NETWORK, V22, P826, DOI 10.1109/TNET.2013.2260354
   Zhang J, 2010, INT ASIA CONF INFORM, P269, DOI 10.1109/CAR.2010.5456849
   Zhang LR, 2002, COMPUT COMMUN, V25, P863, DOI 10.1016/S0140-3664(01)00418-2
   Zimmermann R, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1352012.1352018
NR 46
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18727
EP 18745
DI 10.1007/s11042-020-08743-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800065
DA 2024-07-18
ER

PT J
AU Filisbino, TA
   Giraldi, GA
   Thomaz, CE
AF Filisbino, Tiene A.
   Giraldi, Gilson A.
   Thomaz, Carlos E.
TI Support vector machine ensembles for discriminant analysis for ranking
   principal components
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE PCA; Ranking PCA components; Separating hyperplanes; Ensemble methods;
   AdaBoost; Face image analysis
ID GENE SELECTION; IMAGE
AB The problemof ranking linear subspaces in principal component analysis (PCA), for multi-class classification tasks, has been addressed by building support vector machine (SVM) ensembles and AdaBoost.M2 technique. This methodology, named multi-class discriminant principal components analysis (Multi-Class.M2 DPCA), is motivated by the fact that the first PCA components do not necessarily represent important discriminant directions to separate sample groups. The Multi-Class.M2 DPCA proposal presents fundamental issues related to the weakening methodology, parametrization, strategy for SVM bias, and classification versus reconstruction performance. Also, it is observed a lack of comparisons between Multi-Class.M2 DPCA and feature weighting techniques. Motivated by these facts, this paper firstly presents a unified formulation to generate weakened SVM approaches and to derive different strategies of the literature. These strategies are analyzed within Multi-Class.M2 DPCA methodology and its parametrization to realize the best one for ranking PCA features in face image analysis. Moreover, this work proposes variants to improve that Multi-Class.M2 DPCA configuration using strategies that incorporate SVM bias and sensitivity analysis results. The obtained Multi-Class.M2 DPCA setups are applied in the computational experiments for both classification and reconstruction problems. The results show that Multi-Class.M2 DPCA achieves higher recognition rates using less PCA features, as well as robust reconstruction and interpretation of the data.
C1 [Filisbino, Tiene A.; Giraldi, Gilson A.] Natl Lab Sci Comp, Coordinat Math & Computat Methods, BR-25651075 Petropolis, RJ, Brazil.
   [Thomaz, Carlos E.] FEI, Dept Elect Engn, BR-09850901 Sao Bernardo Do Campo, SP, Brazil.
C3 Laboratorio Nacional de Computacao Cientifica (LNCC); Centro
   Universitario da FEI
RP Filisbino, TA (corresponding author), Natl Lab Sci Comp, Coordinat Math & Computat Methods, BR-25651075 Petropolis, RJ, Brazil.
EM tiene@lncc.br; gilson@lncc.br; cet@fei.edu.br
OI Thomaz, Carlos/0000-0001-5566-1963
CR Ang JC, 2016, IEEE ACM T COMPUT BI, V13, P971, DOI 10.1109/TCBB.2015.2478454
   [Anonymous], 2015, ARXIV151104707
   Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980
   Brezhneva OA, 2009, OPTIM LETT, V3, P7, DOI 10.1007/s11590-008-0096-3
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Cunningham JP, 2015, J MACH LEARN RES, V16, P2859
   Díaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3
   Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523, DOI 10.1109/CSB.2003.1227396
   Dong YQ, 2018, ENERGIES, V11, DOI 10.3390/en11041009
   Duan SR, 2018, IEEE ACCESS, V6, P51365, DOI 10.1109/ACCESS.2018.2869901
   Fang Yan, 2018, Journal of Shanghai Jiaotong University (Science), V23, P297, DOI 10.1007/s12204-018-1938-5
   Ferreira A, 2017, EXPERT SYST APPL, V84, P1, DOI 10.1016/j.eswa.2017.04.053
   FILISBINO T, 2015, 36 IB LAT AM C COMP
   FILISBINO T, 2016, 12 WORKSH VIS COMP W
   Filisbino TA, 2017, 10 EAMC, P1
   Filisbino TA, 2016, GRAPH PATT IM SIBGRA
   Filisbino TA, 2016, WORKSH FAC PROC APPL
   Filisbino TA, 2017, 2017 WORKSHOP OF COMPUTER VISION (WVC), P19, DOI 10.1109/WVC.2017.00011
   Filisbino TA, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S021800141751003X
   Filisbino TA, 2015, INT J IMAGE GRAPH, V15, DOI 10.1142/S0219467815500060
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Garcia E, 2007, ADVANCES IN CLIMBING AND WALKING ROBOTS, PROCEEDINGS, P153, DOI 10.1142/9789812770189_0019
   Garcia-Garcia A, 2018, APPL SOFT COMPUT, V70, P41, DOI 10.1016/j.asoc.2018.05.018
   Garg S, 2019, IEEE T NETW SERV MAN, V16, P924, DOI 10.1109/TNSM.2019.2927886
   Grigory A, 2015, ACM MULTIMEDIA
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hall M. A., 2000, P 17 INT C MACH LEAR, P359, DOI DOI 10.5555/645529.657793
   Hastie T., 2001, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7_2
   Hira Zena M., 2015, Advances in Bioinformatics, V2015, P198363, DOI 10.1155/2015/198363
   Hong WC, 2019, APPL MATH MODEL, V72, P425, DOI 10.1016/j.apm.2019.03.031
   Ioffe S, 2006, LECT NOTES COMPUT SC, V3954, P531
   Jankowski N, 2006, STUD FUZZ SOFT COMP, V207, P29
   Jovic A, 2015, 2015 8TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1200, DOI 10.1109/MIPRO.2015.7160458
   Koch P, 2013, P 23 WORKSH COMP INT, P119
   Kononenko I, 1997, APPL INTELL, V7, P39, DOI 10.1023/A:1008280620621
   LAN Z, 2015, ARXIV151105045
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Li JD, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3136625
   Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131
   Liu Y, 2005, IEEE IJCNN, P849
   Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277
   Lundqvist D., 1998, PSYCHOL SECTION
   Miglani A, 2019, VEH COMMUN, V20, DOI 10.1016/j.vehcom.2019.100184
   Mohri M., 2012, Foundations of Machine Learning
   Park CH, 2005, SIAM J MATRIX ANAL A, V27, P87, DOI 10.1137/S0895479804442334
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Safavi H, 2008, PROC SPIE, V6966, DOI 10.1117/12.778014
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Seuret M, 2017, PROC INT CONF DOC, P877, DOI 10.1109/ICDAR.2017.148
   Sheela A, 2007, J MULTIMEDIA
   Shieh MD, 2008, EXPERT SYST APPL, V35, P531, DOI 10.1016/j.eswa.2007.07.043
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Stuhlsatz A, 2012, IEEE T NEUR NET LEAR, V23, P596, DOI 10.1109/TNNLS.2012.2183645
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   Tang J., 2014, Data Classification, V37, DOI DOI 10.1201/B17320
   Tao Q, 2005, IEEE T NEURAL NETWOR, V16, P1561, DOI 10.1109/tnn.2005.857955
   Terzopoulos D, 2002, MULTILINEAR ANAL IMA
   Thomaz C.E., 2006, Journal of the Brazilian Computer Society, V12, P7
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Wickramaratna J, 2001, P 2 INT WORKSH MULT, P11
   Wu L, 2017, PATTERN RECOGN, V65, P238, DOI 10.1016/j.patcog.2016.12.022
   Yang PY, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-S1-S5
   Yildizer E, 2012, EXPERT SYST APPL, V39, P2385, DOI 10.1016/j.eswa.2011.08.086
   Zhang ZC, 2019, J FLUID ENG-T ASME, V141, DOI 10.1115/1.4042885
   Zhou Nina, 2007, Genomics Proteomics & Bioinformatics, V5, P242, DOI 10.1016/S1672-0229(08)60011-X
   Zhou Y, 2017, IEEE T CYBERNETICS, V47, P830, DOI 10.1109/TCYB.2016.2529299
   Zhou Z.-H., 2012, ENSEMBLE METHODS FDN, DOI DOI 10.1201/B12207
   Zhu M., 2006, IEEE C COMPUTER VISI, V1, P132, DOI DOI 10.1109/CVPR.2006.271
NR 70
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25277
EP 25313
DI 10.1007/s11042-020-09187-9
EA JUL 2020
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000544580800002
DA 2024-07-18
ER

PT J
AU Yang, AYQ
   Lv, BHJ
   Chen, CN
   Wu, DY
   Zheng, EZX
AF Yang, A. Yongquan
   Lv, B. Haijun
   Chen, C. Ning
   Wu, D. Yang
   Zheng, E. Zhongxi
TI FTBME: feature transferring based multi-model ensemble
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-model ensemble; ensemble selection; deep neural networks; feature
   transferring
AB Multi-model ensemble is an important fundamental technique of practical value for many artificial intelligence applications. However, the usage for multi-model ensemble has been limited when it is combined with deep neural networks to construct ensemble of deep neural networks. Due to the big time and computing resources required to train and to integrate multiple deep neural networks for the achievement of multi-model ensemble, the engineering application field where developing time and computing resources are usually restricted, has not yet widespreadly benefited from ensemble of deep neural networks. To alleviate this situation, we present a new multi-model ensemble approach entitled feature transferring based multi-model ensemble (FTBME), for ensemble of deep neural networks. Primarily, we propose a feature transferring based multi-model training strategy to more affordably find multiple extra models based on a given previously optimized deep neural network model. Sequentially, to develop better ensemble solutions, we design a more effective random greedy based ensemble selection strategy to filter out models non-positive to ensemble generalization. Finally, inspired by the idea of averaging parameter points, we propose to fuse the obtained models in weight space which eventually reduces the expense of ensemble at the testing stage to a single deep neural network model while retaining the generalization. These three advances constitute the resulting technique FTBME. We conducted extensive experiments using deep neural networks, from light weight to complex, on ImageNet, CIFAR-10 and CIFAR-100. Results show that, given a deep neural network model which has been well-optimized and reaching its limit, FTBME can obtain better generalization with minor extra training expense while maintaining the expense to a single model at ensemble testing. This promising property of FTBME make us believe that it could be leveraged to broaden the usage for ensemble of deep neural networks, alleviating the situation that the engineering application field has not yet widespreadly benefited from ensemble of deep neural networks.
C1 [Yang, A. Yongquan; Zheng, E. Zhongxi] Sichuan Univ, Pathol Lab, West China Hosp, 37 Guo Xue Rd, Chengdu 610041, Peoples R China.
   [Lv, B. Haijun] Baidu Co Ltd, AIDP, 701 Na Xian Rd, Shanghai 201210, Peoples R China.
   [Chen, C. Ning] Xian Polytech Univ, Sch Elect & Informat, 19 Jin Hua Rd, Xian 710048, Peoples R China.
   [Wu, D. Yang] Nara Inst Sci & Technol, Int Collaborat Lab Robot Vis, 8916-5 Takayamacho Ikoma, Nara 6300192, Japan.
C3 Sichuan University; Baidu; Xi'an Polytechnic University; Nara Institute
   of Science & Technology
RP Zheng, EZX (corresponding author), Sichuan Univ, Pathol Lab, West China Hosp, 37 Guo Xue Rd, Chengdu 610041, Peoples R China.
EM digitalpathology@scu.edu.cn
RI Yang, Yongquan/ABH-8736-2022
OI Yang, Yongquan/0000-0002-3965-4816
CR [Anonymous], 2004, CHOICE REV ONLINE, DOI [10.5860/choice.42-1619, DOI 10.5860/CH0ICE.42-1619]
   [Anonymous], 2014, ADV NEURAL INFORM PR
   Azimi J, 2009, IJCAI INT JOINT C AR
   Bauer E., 1999, MACH LEARN
   Bossard L, 2014, LECT NOTES COMPUTER
   Caruana R., 2006, P IEEE INT C DAT MIN, DOI 10.1109/ICDM.2006.103
   Caruana Rich, 2004, P 21 INT C MACH LEAR, DOI [10.1145/1015330.1015432, DOI 10.1145/1015330.1015432]
   Cormen T.H., 2009, INTRO ALGORITHMS SEL
   Cruz R.M.O., 2018, DESLIB DYNAMIC ENSEM
   Cruz RMO, 2018, INFORM FUSION, V41, P195, DOI 10.1016/j.inffus.2017.09.010
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Dreyfus S, 2002, OPER RES, V50, P48, DOI 10.1287/opre.50.1.48.17791
   Duchi J, 2010, COLT 2010
   Fern XZ, 2008, SOC IND APPL MATH, P130
   Garipov T, 2018, ADV NEUR IN, V31
   Han B, 2018, ADV NEUR IN, V31
   HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871
   Izmailov P., 2018, 34 C UNC ART INT 201, P2018
   Jungnickel D., 1999, Graphs, Networks and Algorithms, P129
   Kawaguchi K., 2016, ADV NEURAL INFORM PR, V29, P586
   Kingma D. P., 2014, arXiv
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krogh A., 1995, Advances in Neural Information Processing Systems 7, P231
   Kumar PR, 2010, CONTROL SYSTEMS HDB
   Laine S., 2016, ARXIV161002242
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lin H, 2011, ACL HLT 2011
   Loshchilov I., 2017, INT C LEARN REPR
   McDiarmid CJH, 1995, B LOND MATH SOC, DOI [10.1112/blms/27.6.611, DOI 10.1112/BLMS/27.6.611]
   Moghimi M, 2016, BRIT MACH VIS 2016 B
   Neel DL, 2009, MATH MAG, DOI [10.4169/193009809x469020, DOI 10.4169/193009809X469020]
   Panigrahi S., 2021, IEEE Transactions on Knowledge and Data Engineering, V194, P781, DOI [DOI 10.1109/TKDE.2009.191, 10.1007/978-981-15-5971-6_83]
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schrijver A, 2005, HDB OPER RES MANAG S
   Swann A, 1998, ELECTRON LETT, V34, P1408, DOI 10.1049/el:19981000
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan C., 2018, LECT NOTES COMPUTER
   Tao DP, 2016, IEEE T NEUR NET LEAR, V27, P1392, DOI 10.1109/TNNLS.2014.2357794
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Xie J., 2013, HORIZONTAL VERTICAL
   Xie L, 2017, IJCAI INT JOINT C AR
   Yang YQ, 2019, MULTIMED TOOLS APPL, V78, P2269, DOI 10.1007/s11042-018-6347-0
   Yang YQ, 2018, MULTIMED TOOLS APPL, V77, P7283, DOI 10.1007/s11042-017-4633-x
   Zhao T, 2017, NAT BIOMED ENG, V1, DOI 10.1038/s41551-016-0006
NR 45
TC 11
Z9 11
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18767
EP 18799
DI 10.1007/s11042-020-08746-4
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800067
DA 2024-07-18
ER

PT J
AU Mehdi, MZ
   Ben Ayed, NG
   Masmoudi, AD
   Sellami, D
AF Mehdi, Mouna Zouari
   Ben Ayed, Norhene Gargouri
   Masmoudi, Alima Damak
   Sellami, Dorra
TI A Textural Wavelet Quantization approach for an efficient breast
   microcalcifcation's detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast tissue; Mammography; Microcalcifications; Texture; Wavelet
   quantization; Classification
ID CANCER DIAGNOSIS; CLUSTERED MICROCALCIFICATIONS; FEATURE-EXTRACTION;
   CLASSIFICATION; MAMMOGRAMS; FEATURES; TUMOR
AB Microcalcifications are very small deposit of calcium. Their detection is a crucial task. Their presence affects the texture of a breast tissue. Texture information has the ability of mapping microcalcification's characteristics. Thus, texture based features allow to carry in a more accurate analysis for microcalcification detection. In this paper, a texture based microcalcification detection method based on Textural Wavelet Quantization (TWQ) is proposed. It is based on a quantization of textural information on a wavelet transform domain. Firstly, to further highlight microcalcification details, we apply a nonlinear enhancement technique. The resulting enhanced image will be subsequently used to extract textural features in order to detect the presence of microcalcifications by means of local information. A product between wavelet coefficients of the enhanced image and those of the Gaussian Derivative filter is done highlight microcalcification's frequency and remove the other frequencies. The resulting coefficients are subsequently quantized in a feature vector. This feature vector is considered subsequently as input vector for the classification step of the corresponding breast tissue. Indeed, our proposed texture descriptor allows to distinguish breast tissue with microcalcifications from safe one. A comparative study illustrates the efficiency of such approach, among existing ones, in classifying breast tissue. The proposed approach yields an area Under the Receiver Operating Characteristic (ROC) curve (AUC) of 99.93%.
C1 [Mehdi, Mouna Zouari; Masmoudi, Alima Damak; Sellami, Dorra] Univ Sfax, Sfax Engn Sch, Control & Energy Management CEM Lab, BP W, Sfax 3038, Tunisia.
   [Ben Ayed, Norhene Gargouri] Digital Res Ctr Sfax, Km 10 3021 Tunis Rd, Sfax, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Sfax; Centre de Recherche en Numerique de Sfax (CRNS)
RP Mehdi, MZ (corresponding author), Univ Sfax, Sfax Engn Sch, Control & Energy Management CEM Lab, BP W, Sfax 3038, Tunisia.
EM zouarimouna88@gmail.com
RI Gargouri, Norhene/GZN-1041-2022; Sellami, Dorra/KSL-6903-2024
OI Gargouri, Norhene/0000-0003-1613-2115; zouari, mouna/0000-0002-7061-3158
CR Ali J.A., 2013, J COMPUT APPL JCA, V6, P19
   [Anonymous], 1996, 3 INT WORKSH DIG MAM
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Chan HP, 1998, MED PHYS, V25, P2007, DOI 10.1118/1.598389
   Chan HP, 1997, PHYS MED BIOL, V42, P549, DOI 10.1088/0031-9155/42/3/008
   Chen CH, 1997, GRAPH MODEL IM PROC, V59, P349, DOI 10.1006/gmip.1997.0443
   COOMANS D, 1982, ANAL CHIM ACTA, V136, P15, DOI 10.1016/S0003-2670(01)95359-0
   Dehghani S, 2011, WORLD APPL SCI J
   dosSantos RJV, 1997, J MATH PHYS, V38, P4104, DOI 10.1063/1.532107
   Duarte MA, 2019, MEDITERRANEAN C MEDI, P322
   Eltoukhy MM, 2012, COMPUT BIOL MED, V42, P123, DOI 10.1016/j.compbiomed.2011.10.016
   Eltoukhy MM, 2010, COMPUT BIOL MED, V40, P384, DOI 10.1016/j.compbiomed.2010.02.002
   Fanizzi A, 2020, BMC BIOINFORMATICS, V21, DOI 10.1186/s12859-020-3358-4
   Gargouri N., 2014, INT IM PROC APPL SYS, P1
   Gedik N, APPL SOFT COMPUTING, V44
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   James D, 2001, J MAGN RESON IMAGING, V13, P876, DOI 10.1002/jmri.1125
   Karahaliou A, 2007, BRIT J RADIOL, V80, P648, DOI 10.1259/bjr/30415751
   Karahaliou AN, 2008, IEEE T INF TECHNOL B, V12, P731, DOI 10.1109/TITB.2008.920634
   Kurani AS, 2004, Proceedings of the Seventh IASTED International Conference on Computer Graphics and Imaging, P447
   LAINE A, 1993, IEEE T PATTERN ANAL, V15, P1186, DOI 10.1109/34.244679
   Maria K, 2004, MED PHYS, V31
   Omer Ashgan Mohamed, 2019, THESIS SUDAN U SCI T
   Papadopoulos A, 2005, ARTIF INTELL MED, V34, P141, DOI 10.1016/j.artmed.2004.10.001
   Pérez NP, 2015, ARTIF INTELL MED, V63, P19, DOI 10.1016/j.artmed.2014.12.004
   Saraswathi D, 2016, COMPUT METHOD BIOMEC, V0, P1
   Setiawan AS, 2015, PROCEDIA COMPUT SCI, V59, P92, DOI 10.1016/j.procs.2015.07.341
   Shi P, 2018, COMPUT BIOL MED, V96, P178, DOI 10.1016/j.compbiomed.2018.03.011
   Soltanian-Zadeh H, 2004, PATTERN RECOGN, V37, P1973, DOI 10.1016/j.patcog.2003.03.001
   Strickland RN, 1996, IEEE T MED IMAGING, V15, P218, DOI 10.1109/42.491423
   Tiedeu A, 2012, DIGIT SIGNAL PROCESS, V22, P124, DOI 10.1016/j.dsp.2011.09.004
   Wei LY, 2005, IEEE T MED IMAGING, V24, P371, DOI 10.1109/TMI.2004.842457
   Xi XM, 2017, NEUROCOMPUTING, V259, P210, DOI 10.1016/j.neucom.2016.06.082
   Zhou SC, 2013, BIOMED SIGNAL PROCES, V8, P688, DOI 10.1016/j.bspc.2013.06.011
   Zouari M, 2014, 2014 1ST INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP 2014), P193, DOI 10.1109/ATSIP.2014.6834605
   Zurada J. M, 1992, INTRO ARTIFICIAL NEU, V8
   Zyout I, 2009, J BIOMED IMAGING, V2009, P30
NR 37
TC 6
Z9 6
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24911
EP 24927
DI 10.1007/s11042-020-09105-z
EA JUN 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000543615200005
DA 2024-07-18
ER

PT J
AU Kutbay, U
AF Kutbay, Ugurhan
TI Automated hemangioma detection using Otsu based binarized Kaze features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hemangioma; CT; Otsu; Histogram of gradients; Kaze features; Diagnosis
   system; Biomedical image processing
ID FOCAL LIVER-LESIONS; DIAGNOSIS
AB This study aims to detect liver hemangioma on CT images by using hybrid image processing methods as well as binarized histogram of gradients based Kaze feature extraction. Using hybrid strategies, automatic hemangioma detector design is the state of art of this study. Our study helps doctors to detect the solid liver masses. Proposed algorithm includes detection of hemangioma using Otsu auto-threshold based Histogram of Gradients (HOG) and Kaze feature extraction implementation. 48 liver CT images, 28 of which are hemangiomas and 20 of which are healthy liver images, are used as the dataset. CT images are obtained by the Department of the Radiology at Firat University. Presented work was implemented to 48-CT images and 91,66% accuracy was achieved for different shaped and sized hemangiomas. These results show that the developed algorithm could ease the process of detecting liver masses for radiologist and doctors could evaluate their findings easily.
C1 [Kutbay, Ugurhan] Gazi Univ, Dept Elect & Elect Engn, Ankara, Turkey.
C3 Gazi University
RP Kutbay, U (corresponding author), Gazi Univ, Dept Elect & Elect Engn, Ankara, Turkey.
EM ukutbay@gazi.edu.tr
RI KUTBAY, Ugurhan/AAP-8534-2020
OI KUTBAY, Ugurhan/0000-0003-2167-9107
CR Acharya UR, 2018, COMPUT BIOL MED, V94, P11, DOI 10.1016/j.compbiomed.2017.12.024
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   Bahirwani R, 2008, ALIMENT PHARM THER, V28, P953, DOI 10.1111/j.1365-2036.2008.03805.x
   Balbin JR, 2018, PROC SPIE, V10828, DOI 10.1117/12.2502020
   Chan YK, 2018, J MED BIOL ENG, V38, P857, DOI 10.1007/s40846-017-0352-z
   D'Onofrio M, 2015, AM J ROENTGENOL, V205, pW56, DOI 10.2214/AJR.14.14203
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fan DP, 2019, IEEE I CONF COMP VIS, P5611, DOI 10.1109/ICCV.2019.00571
   Firuzi K, 2019, IEEE T POWER DELIVER, V34, P542, DOI 10.1109/TPWRD.2018.2872820
   GANDOLFI L, 1991, GUT, V32, P677, DOI 10.1136/gut.32.6.677
   Getzin T, 2018, EUR RADIOL, V28, P4455, DOI 10.1007/s00330-018-5380-8
   Huang ZW, 2018, IEEE T PATTERN ANAL, V40, P2827, DOI 10.1109/TPAMI.2017.2776154
   Jain N, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0623-1
   Koc M, 2017, J TURGUT OZAL MED CE, V24, P301, DOI [10.5455/jtomc.2017.04.058, DOI 10.5455/JTOMC.2017.04.058]
   Lee KL, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON ELECTRONIC DESIGN (ICED), P181, DOI 10.1109/ICED.2014.7015795
   Lee WL, 2013, APPL SOFT COMPUT, V13, P3683, DOI 10.1016/j.asoc.2013.03.009
   Li JP, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1164-1
   Li X, 2019, ONCOL LETT, V17, P981, DOI 10.3892/ol.2018.9661
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Liu Y, 2018, SEMANTIC EDGE DETECT
   Mehta N, 2019, AM J OPHTHALMOL, V205, P54, DOI 10.1016/j.ajo.2019.03.008
   Navale P, 2018, J CLIN EXP HEPATOL, V8, P474, DOI 10.1016/j.jceh.2018.07.003
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pournik O, 2014, HEPAT MON, V14, DOI 10.5812/hepatmon.15167
   Sanchez-Morillo D, 2018, CLASSIFICATION BREAS, P276
   Siegel R, 2014, CA-CANCER J CLIN, V64, P9, DOI 10.3322/caac.21208
   Stankevieius G., 2018, 2018 IEEE 6th Workshop on Advances in Information, Electronic and Electrical Engineering (AIEEE), P1, DOI DOI 10.1109/AIEEE.2018.8592033
   Su T-Y, 2019, INT FORUM MED IMAGIN, P54
   Sugo Hiroyuki, 2018, Case Reports Hepatol, V2018, P7353170, DOI 10.1155/2018/7353170
   TAIT N, 1992, AUST NZ J SURG, V62, P521, DOI 10.1111/j.1445-2197.1992.tb07043.x
   Virmani J, 2014, J DIGIT IMAGING, V27, P520, DOI 10.1007/s10278-014-9685-0
   Wang XM, 2018, EVID-BASED COMPL ALT, V2018, DOI 10.1155/2018/2072091
   Wu HZ, 2018, MEDICINE, V97, DOI 10.1097/MD.0000000000012071
   Xu QZ, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0904-y
   Yuan XC, 2015, APPL SURF SCI, V349, P472, DOI 10.1016/j.apsusc.2015.05.033
   Zhu HJ, 2017, MULTIMED TOOLS APPL, V76, P8951, DOI 10.1007/s11042-016-3486-z
NR 36
TC 4
Z9 4
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24781
EP 24793
DI 10.1007/s11042-020-09156-2
EA JUN 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000543064800002
DA 2024-07-18
ER

PT J
AU Ai, XS
   Sheng, VS
   Fang, W
   Ling, CX
AF Ai, Xusheng
   Sheng, Victor S.
   Fang, Wei
   Ling, Charles X.
TI An optimal model with a lower bound of recall for imbalanced speech
   emotion recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Imbalance; Deep neural network; Convolutional neural network; Speech
   emotion recognition
ID NEURAL-NETWORK
AB In an early complain warning system, we encounter a common problem - the lack of angry emotions for training classification models. Moreover, the recognition of angry emotion is more important than that of no-anger emotion. Based on this, the main purpose of this paper is to train an optimal model which achieves a high recall above a lower bound and a maximum ofF(1)score. It is divided into three aspects: 1) A variant ofF(1)score (TF(1)score) takes recall above a lower bound andF(1)score into consideration; 2) A Single Emotion Deep Neural Network (SEDNN) and its training process are designed to find an optimal model with a maximum ofTF(1)score. 3) A performance comparison of different methods is conducted on IEMOCAP and Emo-DB database. Extensive experiments show that when a BCE loss function or a focal loss function is used, the training process can find a model with a recall above a high threshold and a maximum ofF(1)score. Especially, SEDNN with the focal loss function performs better than SEDNN with the BCE loss function.
C1 [Ai, Xusheng] Suzhou Vocat Inst Ind Technol, Software & Serv Outsourcing Coll, Suzhou 215104, Peoples R China.
   [Sheng, Victor S.] Texas Tech Univ, Dept Comp Sci, Lubbock, TX 79409 USA.
   [Fang, Wei] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Jiangsu Engn Ctr Network Monitoring, Nanjing, Peoples R China.
   [Ling, Charles X.] Western Univ, Dept Comp Sci, London, ON N6A 5B7, Canada.
C3 Texas Tech University System; Texas Tech University; Nanjing University
   of Information Science & Technology; Western University (University of
   Western Ontario)
RP Ai, XS (corresponding author), Suzhou Vocat Inst Ind Technol, Software & Serv Outsourcing Coll, Suzhou 215104, Peoples R China.; Sheng, VS (corresponding author), Texas Tech Univ, Dept Comp Sci, Lubbock, TX 79409 USA.
EM 00754@siit.edu.cn; victor.sheng@ttu.edu; hsfangwei@sina.com;
   charles.ling@uwo.ca
RI Ai, Xusheng/ABD-8813-2020
OI Ai, Xusheng/0000-0001-5629-9134
FU Natural Science Foundation of China [61472267, 61702351]; Natural
   Science Foundation of the Jiangsu Higher Education Institutions of China
   [17KJB520036]; Foundation of Key Laboratory in Science and Technology
   Development Project of Suzhou [SZS201609]; Suzhou Science and Technology
   Plan Project [SYG201903]
FX This study was funded by Natural Science Foundation of China (grant
   number: 61472267, 61702351), Natural Science Foundation of the Jiangsu
   Higher Education Institutions of China (grant number: 17KJB520036), and
   Foundation of Key Laboratory in Science and Technology Development
   Project of Suzhou (grant number: SZS201609), Suzhou Science and
   Technology Plan Project (grant number: SYG201903).
CR [Anonymous], 2015, 16 ANN C INT SPEECH
   Buda M, 2018, NEURAL NETWORKS, V106, P249, DOI 10.1016/j.neunet.2018.07.011
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Chen MY, 2018, IEEE SIGNAL PROC LET, V25, P1440, DOI 10.1109/LSP.2018.2860246
   Chen X, 2017, INTERSPEECH, P269, DOI 10.21437/Interapeech.2017-513
   Chollet Francois, 2018, KERAS PYTHON DEEP LE
   Dong YQ, 2018, ENERGIES, V11, DOI 10.3390/en11041009
   Eyben F., 2009, 3 INT C AFF COMP INT, P1, DOI DOI 10.1109/ACII.2009.5349350
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Han K, 2014, INTERSPEECH, P223
   Hong WC, 2019, APPL MATH MODEL, V72, P425, DOI 10.1016/j.apm.2019.03.031
   Huang CW, 2016, INTERSPEECH, P1387, DOI 10.21437/Interspeech.2016-448
   Huang CW, 2017, IEEE INT CON MULTI, P583, DOI 10.1109/ICME.2017.8019296
   Kingma D. P., 2014, arXiv
   Kundra H., 2015, RES J INF TECHNOL, V7, P58, DOI DOI 10.3923/RJIT.2015.58.69
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Maas A.L., 2013, P 30 INT C MACH LEAR, V30, P3
   Masko D., 2015, Degree Project
   Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552
   Sohn H., 2001, 2001 ASME International Mechanical Engineering Congress and Exposition, P573
   Trigeorgis G, 2016, INT CONF ACOUST SPEE, P5200, DOI 10.1109/ICASSP.2016.7472669
   Vuckovic F, 2015, 23 INT S GLYC GLYCO
   Wang KX, 2015, IEEE T AFFECT COMPUT, V6, P69, DOI 10.1109/TAFFC.2015.2392101
   Yang N, 2012, IEEE W SP LANG TECH, P455, DOI 10.1109/SLT.2012.6424267
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang Z, 2019, NONLINEAR DYNAMICS, V98
   Zhang ZC, 2020, IEEE ACCESS, V8, P14642, DOI 10.1109/ACCESS.2020.2966712
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
NR 28
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24281
EP 24301
DI 10.1007/s11042-020-09155-3
EA JUN 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000543633200001
DA 2024-07-18
ER

PT J
AU Toor, AA
   Usman, M
   Younas, F
   Habib, M
   Fong, ACM
AF Toor, Affan Ahmed
   Usman, Muhammad
   Younas, Farah
   Habib, Mohamed
   Fong, A. C. M.
TI Efficient mining of IoT based data streams for advanced computer vision
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stream mining; Image stream; Machine learning; Smart cities; Computer
   vision; IoT
ID CONCEPT DRIFT DETECTION; DETECTING CONCEPT DRIFT
AB With emergence of Internet of Things (IoT) and subsequent technologies, smart devices are being increasingly used in various domains such as smart homes, smart parking, intelligent transportation etc. Vast amount of image and video data has been produced by IoT based systems in the form of continuous and possibly infinite image and video streams. This demands the development of advanced predictive vision systems which exploits stream mining concepts for intelligent processing of visual data streams. Among other challenges faced by visual data streams, a major challenge is concept drift, which is caused by overtime change in data distribution. In the presence of skewed data, the detection of concept drift becomes more challenging. When analyzing the data generated from smart devices and other performance critical wireless sensors, concept drift affects data integrity and accuracy of prediction results. EWMA for Concept Drift Detection (ECDD) has been proposed in the literature for detecting data streams. However, ECDD has a high prediction error rate which makes it less useful for performance critical data streams generated by imaging and video data streams. In this paper, Vision based Drift Detection Method (VisDDM) is proposed, which systematically handles abrupt and gradual concept drift in data streams. Experiments have been performed using synthetic and real world datasets from different application domains. Our proposed VisDDM algorithm is able to handle abrupt and gradual drift types and outperformed the existing drift detection methods in terms of accuracy and mean evaluation time.
C1 [Toor, Affan Ahmed; Usman, Muhammad; Younas, Farah] Shaheed Zulfikar Ali Bhutto Inst Sci & Technol, Dept Comp Sci, Islamabad, Pakistan.
   [Habib, Mohamed] Saudi Elect Univ, Coll Comp & Informat, Riyadh, Saudi Arabia.
   [Habib, Mohamed] Port Said Univ, Fac Engn, Port Fuad City, Egypt.
   [Fong, A. C. M.] Western Michigan Univ, Kalamazoo, MI 49008 USA.
C3 Shaheed Zulfikar Ali Bhutto Institute of Science & Technology; Saudi
   Electronic University; Egyptian Knowledge Bank (EKB); Port Said
   University; Western Michigan University
RP Fong, ACM (corresponding author), Western Michigan Univ, Kalamazoo, MI 49008 USA.
EM alvis.fong@wmich.edu
RI Usman, Muhammad/JEP-1477-2023
CR BAENAGARCIA M, P 4 INT WORKSH KNOWL, P77
   Barros RSM, 2017, EXPERT SYST APPL, V90, P344, DOI 10.1016/j.eswa.2017.08.023
   Demsar J, 2018, EXPERT SYST APPL, V92, P546, DOI 10.1016/j.eswa.2017.10.003
   Duda P, 2017, 2017 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P1821
   Escovedo T, 2018, APPL SOFT COMPUT, V62, P119, DOI 10.1016/j.asoc.2017.10.031
   Frías-Blanco I, 2015, IEEE T KNOWL DATA EN, V27, P810, DOI 10.1109/TKDE.2014.2345382
   Huang DTJ, 2014, IEEE DATA MINING, P863, DOI 10.1109/ICDM.2014.50
   Karkanis S, 2000, MINIM INVASIV THER, V9, P225, DOI 10.1080/13645700009169652
   Kithulgoda CI, 2018, EXPERT SYST APPL, V97, P1, DOI 10.1016/j.eswa.2017.12.023
   Kithulgoda CI, 2016, IEEE IJCNN, P1, DOI 10.1109/IJCNN.2016.7727173
   Liu AJ, 2018, PATTERN RECOGN, V76, P256, DOI 10.1016/j.patcog.2017.11.009
   Liu SL, 2017, COMPUT ELECTR ENG, V58, P327, DOI 10.1016/j.compeleceng.2016.09.006
   Lughofer E, 2016, INFORM SCIENCES, V355, P127, DOI 10.1016/j.ins.2016.03.034
   Maciel BIF, 2015, PROC INT C TOOLS ART, P1061, DOI 10.1109/ICTAI.2015.151
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Nishida K, 2007, LECT NOTES ARTIF INT, V4755, P264
   Pears R, 2014, MACH LEARN, V97, P259, DOI 10.1007/s10994-013-5433-9
   Ross GJ, 2012, PATTERN RECOGN LETT, V33, P191, DOI 10.1016/j.patrec.2011.08.019
   SAKTHITHASAN S, 2013, LECT NOTES COMPUTER, V7819
   SAKTHITHASAN S, 2015, 2015 INT JOINT C NEU, P1, DOI DOI 10.1109/IJCNN.2015.7280583
   Sethi TS, 2017, EXPERT SYST APPL, V82, P77, DOI 10.1016/j.eswa.2017.04.008
   Sun Y, 2016, IEEE T KNOWL DATA EN, V28, P1532, DOI 10.1109/TKDE.2016.2526675
   Woo WH, 2017, EUR J INORG CHEM, P5372, DOI 10.1002/ejic.201701169
NR 23
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 15027
EP 15042
DI 10.1007/s11042-020-09175-z
EA JUN 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000540942000001
DA 2024-07-18
ER

PT J
AU Vagish, KD
   Rajakumaran, C
   Kavitha, R
AF Vagish, Deepak K.
   Rajakumaran, C.
   Kavitha, R.
TI Chaos based encryption of quantum images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quantum image encryption; Quantum Hilbert image scrambling; Chaotic maps
ID REPRESENTATION; ALGORITHM
AB Content, be it any form text, image or video, which needs to be sent from one place to another is vulnerable to third party attacks if it is sent without proper encryption. Therefore, each encryption should be extremely sensitive to change, that is a small change in the key should drastically change the cipher text. In this paper we propose such an image encryption algorithm which is extremely sensitive to such changes. A novel encryption algorithm for quantum images based on chaotic maps is designed. The image is converted into a scrambled state using quantum circuits using the principle of Quantum Hilbert Image Scrambling algorithm. The scrambled image is encrypted using the quantum XOR gate using the chaotic maps algorithm. Numerical and simulation analyses show that the proposed quantum image encryption approach is robust, realizable, and has high efficiency compared to its classical counterpart.
C1 [Vagish, Deepak K.] SASTRA Deemed Univ, B Tech ICT, Thanjavur, Tamil Nadu, India.
   [Rajakumaran, C.] SASTRA Deemed Univ, B Tech ECE, Thanjavur, Tamil Nadu, India.
   [Kavitha, R.] SASTRA Deemed Univ, Sch Comp, Thanjavur, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Vagish, KD (corresponding author), SASTRA Deemed Univ, B Tech ICT, Thanjavur, Tamil Nadu, India.
EM deepakvagish@gmail.com; rajakumaran0908@gmail.com;
   kavitha_r@cse.sastra.edu
OI raju, kavitha/0000-0003-2698-7192
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P1073, DOI 10.1109/ACCESS.2017.2777869
   Caraiman S., 2012, P 16 INT C SYST THEO, P1
   Gong LH, 2016, INT J THEOR PHYS, V55, P3234, DOI 10.1007/s10773-016-2954-6
   Hua TX, 2015, INT J THEOR PHYS, V54, P526, DOI 10.1007/s10773-014-2245-z
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Jiang N, 2014, INT J THEOR PHYS, V53, P2463, DOI 10.1007/s10773-014-2046-4
   Jiang N, 2014, QUANTUM INF PROCESS, V13, P1223, DOI 10.1007/s11128-013-0721-7
   Kamata S, 1999, IEEE T IMAGE PROCESS, V8, P964, DOI 10.1109/83.772242
   Le PQ, 2011, QUANTUM INF PROCESS, V10, P63, DOI 10.1007/s11128-010-0177-y
   Liang HR, 2016, QUANTUM INF PROCESS, V15, P2701, DOI 10.1007/s11128-016-1304-1
   Wang W, 2016, J SENSORS, V2016, DOI 10.1155/2016/2646205
   Yan F, 2016, QUANTUM INF PROCESS, V15, P1, DOI 10.1007/s11128-015-1195-6
   Yang Yu-Guang, 2016, QUANTUM HASH FUNCTIO
   Yuan SZ, 2014, QUANTUM INF PROCESS, V13, P1353, DOI 10.1007/s11128-014-0733-y
   Zhang Y, 2013, QUANTUM INF PROCESS, V12, P3103, DOI 10.1007/s11128-013-0587-8
   Zhang Y, 2013, QUANTUM INF PROCESS, V12, P2833, DOI 10.1007/s11128-013-0567-z
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
   Zhou NR, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-016-1461-2
   Zhou RG, 2013, INT J THEOR PHYS, V52, P1802, DOI 10.1007/s10773-012-1274-8
NR 19
TC 11
Z9 11
U1 6
U2 63
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 23849
EP 23860
DI 10.1007/s11042-020-09043-w
EA JUN 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000539939200001
DA 2024-07-18
ER

PT J
AU Xiao, YZ
   Tian, ZQ
   Yu, JC
   Zhang, YS
   Liu, S
   Du, SY
   Lan, XG
AF Xiao, Youzi
   Tian, Zhiqiang
   Yu, Jiachen
   Zhang, Yinshu
   Liu, Shuai
   Du, Shaoyi
   Lan, Xuguang
TI A review of object detection based on deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Object detection; Deep learning; Deep convolutional neural networks;
   Computer vision
ID CONVOLUTIONAL NEURAL-NETWORK; ABSOLUTE ERROR MAE; VISUAL-ATTENTION;
   ARCHITECTURES; HISTOGRAMS; EXTRACTION; FEATURES; MODELS; IMAGES; RMSE
AB With the rapid development of deep learning techniques, deep convolutional neural networks (DCNNs) have become more important for object detection. Compared with traditional handcrafted feature-based methods, the deep learning-based object detection methods can learn both low-level and high-level image features. The image features learned through deep learning techniques are more representative than the handcrafted features. Therefore, this review paper focuses on the object detection algorithms based on deep convolutional neural networks, while the traditional object detection algorithms will be simply introduced as well. Through the review and analysis of deep learning-based object detection techniques in recent years, this work includes the following parts: backbone networks, loss functions and training strategies, classical object detection architectures, complex problems, datasets and evaluation metrics, applications and future development directions. We hope this review paper will be helpful for researchers in the field of object detection.
C1 [Xiao, Youzi; Tian, Zhiqiang; Yu, Jiachen; Zhang, Yinshu; Liu, Shuai] Xi An Jiao Tong Univ, Sch Software Engn, Xian, Peoples R China.
   [Du, Shaoyi; Lan, Xuguang] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University
RP Tian, ZQ (corresponding author), Xi An Jiao Tong Univ, Sch Software Engn, Xian, Peoples R China.
EM zhiqiangtian@xjtu.edu.cn
RI li, jing/KHY-5337-2024; Liu, Chenyu/KBQ-8899-2024
FU NSFC [61876148, 61866022, 61703328]; Fundamental Research Funds for the
   Central Universities [XJJ2018254]; China Postdoctoral Science Foundation
   [2018M631164]; key project of Shaanxi province [2018ZDCXL-GY-06-07]; key
   project of Trico-Robot plan of NSFC [91748208]
FX This work was supported in part by NSFC under grant No. 61876148, No.
   61866022, and No. 61703328. This work was also supported in part by the
   key project of Trico-Robot plan of NSFC under grant No. 91748208, key
   project of Shaanxi province No.2018ZDCXL-GY-06-07, the Fundamental
   Research Funds for the Central Universities No. XJJ2018254, and China
   Postdoctoral Science Foundation NO. 2018M631164.
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   An K, 2017, IEEE ICC, DOI 10.1109/ICC.2017.7996553
   [Anonymous], 2016, ARXIV161201452
   [Anonymous], 2015, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, DOI DOI 10.1109/CVPR.2015.7299188
   Anwar S, 2016, Coarse pruning of convolutional neural networks with random masks
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   BAE SH, 2019, P AAAI C ART INT
   Bartlett PL, 2008, J MACH LEARN RES, V9, P1823
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Borji A, 2019, COMPUT VIS MEDIA, V5, P117, DOI 10.1007/s41095-019-0149-9
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   *CAFFE2, 2020, NEW LIGHTW MOD SCAL
   Cai LL, 2019, PROC CVPR IEEE, P9348, DOI 10.1109/CVPR.2019.00958
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   CAO G, 2018, 9 INT C GRAPH IM PRO
   Caron Mathilde, 2018, P EUR C COMP VIS ECC, P132, DOI [DOI 10.1007/978-3-030-01264-9_9, 10.48550/arXiv.1807.05520, DOI 10.48550/ARXIV.1807.05520]
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Castro FM, 2018, LECT NOTES COMPUT SC, V11216, P241, DOI 10.1007/978-3-030-01258-8_15
   Chai T, 2014, GEOSCI MODEL DEV, V7, P1247, DOI 10.5194/gmd-7-1247-2014
   Chao Peng, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6181, DOI 10.1109/CVPR.2018.00647
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Chen G., 2017, ADV NEURAL INFORM PR, P742
   Chen H, 2018, AAAI CONF ARTIF INTE, P2836
   CHEN K, 2020, OPEN MMLAB DETECTION
   Chen Q, 2015, IEEE T PATTERN ANAL, V37, P13, DOI 10.1109/TPAMI.2014.2343217
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen X., 2017, PROC CVPR IEEE, V1, P3, DOI DOI 10.1109/CVPR.2017.691
   Chen XZ, 2015, ADV NEUR IN, V28
   Chen XL, 2017, IEEE I CONF COMP VIS, P4106, DOI 10.1109/ICCV.2017.440
   Chen XY, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P181, DOI 10.1109/ACPR.2013.33
   Cheng BW, 2018, LECT NOTES COMPUT SC, V11219, P473, DOI 10.1007/978-3-030-01267-0_28
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cox D., 2017, INT C LEARNING REPRE
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Denton E, 2014, ADV NEUR IN, V27
   Divvala SK, 2009, PROC CVPR IEEE, P1271, DOI 10.1109/CVPRW.2009.5206532
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   DUNDAR A, 2016, INT C LEARN REPR
   Endres I, 2010, LECT NOTES COMPUT SC, V6315, P575, DOI 10.1007/978-3-642-15555-0_42
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   *FAC AL RES, 2020, FAIRS RES PLATF OBJ
   Fan QF, 2016, IEEE INT VEH SYM, P124, DOI 10.1109/IVS.2016.7535375
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Gao MF, 2018, PROC CVPR IEEE, P6926, DOI 10.1109/CVPR.2018.00724
   Geiger A., 2012, CVPR
   Gentile C, 1999, ADV NEUR IN, V11, P225
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Ghodrati A, 2015, IEEE I CONF COMP VIS, P2578, DOI 10.1109/ICCV.2015.296
   Gholami A, 2018, IEEE COMPUT SOC CONF, P1719, DOI 10.1109/CVPRW.2018.00215
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graf, 2017, ARXIV160808710, P1, DOI DOI 10.48550/ARXIV.1608.08710
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Griffin G., 2007, CALTECH 256 OBJECT C
   Gu CH, 2018, PROC CVPR IEEE, P6047, DOI 10.1109/CVPR.2018.00633
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Han S., 2016, ARXIV151000149
   Hao Y, 2019, IEEE INT CON MULTI, P1, DOI 10.1109/ICME.2019.00009
   Hao ZK, 2017, PROC CVPR IEEE, P1913, DOI 10.1109/CVPR.2017.207
   Hariharan B, 2017, IEEE T PATTERN ANAL, V39, P627, DOI 10.1109/TPAMI.2016.2578328
   Harzallah H, 2009, IEEE I CONF COMP VIS, P237, DOI 10.1109/ICCV.2009.5459257
   Hastie T., 2009, ELEMENTS STAT LEARNI, P485, DOI DOI 10.1007/978-0-387-84858-7_7
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He K., 2018, arXiv
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0
   He Y., 2018, Softer-nms: Rethinking bounding box regression for accurate object detection
   HETANG C, 2017, ARXIV171205896
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hoi S.C.H., 2015, IEEE T PATT AN MACH, V46, P2403
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu PY, 2017, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2017.166
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang J, 2017, IEEE INT C INT ROBOT, P3296, DOI 10.1109/IROS.2017.8206166
   Huang WL, 2014, LECT NOTES COMPUT SC, V8692, P497, DOI 10.1007/978-3-319-10593-2_33
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Janocha Katarzyna, 2017, Theor Found Mach Learn, DOI [DOI 10.4467/20838476SI.16.004.6185, 10.4467/20838476SI.16. 004.6185]
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Jiang HZ, 2017, IEEE INT CONF AUTOMA, P650, DOI [10.1109/FG.2017.82, 10.1109/MWSYM.2017.8058653]
   Kang K, 2018, IEEE T CIRC SYST VID, V28, P2896, DOI 10.1109/TCSVT.2017.2736553
   Kang K, 2016, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2016.95
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kavukcuoglu K., 2010, Advances in neural information processing systems, P1
   Kawahara J, 2016, LECT NOTES COMPUT SC, V10019, P164, DOI 10.1007/978-3-319-47157-0_20
   Kim SW, 2018, LECT NOTES COMPUT SC, V11209, P239, DOI 10.1007/978-3-030-01228-1_15
   Kleban J, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1077, DOI 10.1109/ICME.2008.4607625
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Kong L, 2016, INT CONF UBIQ FUTUR, P264, DOI 10.1109/ICUFN.2016.7537029
   Kong T, 2017, PROC CVPR IEEE, P5244, DOI 10.1109/CVPR.2017.557
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Krähenbühl P, 2014, LECT NOTES COMPUT SC, V8693, P725, DOI 10.1007/978-3-319-10602-1_47
   Krasin I., 2016, OPENIMAGES PUBLIC DA, V2, P7
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuo WC, 2015, IEEE I CONF COMP VIS, P2479, DOI 10.1109/ICCV.2015.285
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   LaLonde R., 2018, P INT C MED IM DEEP
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Li JN, 2017, IEEE T MULTIMEDIA, V19, P944, DOI 10.1109/TMM.2016.2642789
   Li K, 2018, IEEE T GEOSCI REMOTE, V56, P2337, DOI 10.1109/TGRS.2017.2778300
   Li L, 2019, PROC CVPR IEEE, P10563, DOI 10.1109/CVPR.2019.01082
   Li S, 2019, IEEE I CONF COMP VIS, P6608, DOI 10.1109/ICCV.2019.00671
   Li YN, 2017, PROC CVPR IEEE, P5207, DOI 10.1109/CVPR.2017.553
   Li YR, 2017, IEEE CONF NANOTECH, P230, DOI 10.1109/NANO.2017.8117419
   Li Z., 2017, CORR
   Li ZM, 2018, LECT NOTES COMPUT SC, V11213, P339, DOI [10.1007/978-3-030-01240-3_21, 10.1007/978-3-030-01219-9_23]
   Li ZQ, 2018, PROC CVPR IEEE, P2041, DOI 10.1109/CVPR.2018.00218
   LIANG M, 2015, PROC CVPR IEEE, P3367, DOI [10.1109/CVPR.2015.7298958, DOI 10.1109/CVPR.2015.7298958]
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lin LK, 2018, J SYST ENG ELECTRON, V29, P947, DOI 10.21629/JSEE.2018.05.07
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu Chenxi, 2018, P EUR C COMP VIS, P19
   Liu LZ, 2018, J COMPUT BIOL, V25, P586, DOI 10.1089/cmb.2017.0114
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278091
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Long Y, 2017, IEEE T GEOSCI REMOTE, V55, P2486, DOI 10.1109/TGRS.2016.2645610
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu YF, 2019, IEEE IC COMP COM NET, DOI [10.1109/icccn.2019.8847083, 10.23919/apnoms.2019.8893042]
   Luo J.-H., 2017, An entropy-based pruning method for cnn compression
   Ma Ningning, 2018, P EUR C COMP VIS ECC, DOI [10.1007/978-3-030-01264-9_8, DOI 10.1007/978-3-030-01264-9_8]
   Mahajan Pooja., 2020, Understanding regularization with PyTorch: Dealing with issue of Overfitting
   Mao HZ, 2018, IEEE T EMERG TOP COM, V6, P417, DOI 10.1109/TETC.2016.2593643
   Mao JY, 2017, PROC CVPR IEEE, P6034, DOI 10.1109/CVPR.2017.639
   MATE K, 2019, P IEEE C COMP VIS PA
   Miller G.A., 1990, Int. J. Lexicogr, V3, P235, DOI [DOI 10.1093/IJL/3.4.235, 10.1093/ijl/3.4.235]
   MOORE R, 2013, S MACH LEARN SPEECH
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Najibi M, 2017, IEEE I CONF COMP VIS, P4885, DOI 10.1109/ICCV.2017.522
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   NI K, 2015, ARXIV150203409
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Pang JM, 2019, IEEE T GEOSCI REMOTE, V57, P5512, DOI 10.1109/TGRS.2019.2899955
   Peng JR, 2019, IEEE I CONF COMP VIS, P9606, DOI 10.1109/ICCV.2019.00970
   Peng Junran., 2019, Proc. Adv. Neural Inf. Process. Syst, P14290
   Pinheiro P.O., 2015, NEURIPS, P1990
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986
   Radford A., 2016, INT C LEARN REPR
   RAHMAN S, 2018, EUR C COMP VIS ECCV
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon Joseph, 2013, Darknet: Open Source Neural Networks in C, DOI DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren XF, 2013, PROC CVPR IEEE, P3246, DOI 10.1109/CVPR.2013.417
   Ren Y, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8050813
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sangheum Hwang, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P239, DOI 10.1007/978-3-319-46723-8_28
   Sermanet P., 2014, INT C LEARN REPR
   Shelhamer E, 2016, LECT NOTES COMPUT SC, V9915, P852, DOI 10.1007/978-3-319-49409-8_69
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Shigeto Y, 2015, LECT NOTES ARTIF INT, V9284, P135, DOI 10.1007/978-3-319-23528-8_9
   Shmelkov K, 2017, IEEE I CONF COMP VIS, P3420, DOI 10.1109/ICCV.2017.368
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241
   SIMON M, 2018, EUR C COMP VIS WORKS
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Sun Baochen., 2014, BMVC, DOI DOI 10.1109/TPAMI.2013.163
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   TANNER G, 2020, OBJECT DETECTION API
   Teichmann M, 2018, IEEE INT VEH SYM, P1013, DOI 10.1109/IVS.2018.8500504
   *TENSORFLOW, 2020, LARG SCAL MACH LEARN
   Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Tychsen-Smith L, 2017, IEEE I CONF COMP VIS, P428, DOI 10.1109/ICCV.2017.54
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Van Etten A., 2018, ARXIV E PRINTS
   Van Horn G, 2018, PROC CVPR IEEE, P8769, DOI 10.1109/CVPR.2018.00914
   Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wagstaff K., 2001, P 18 INT C MACH LEAR, P577, DOI DOI 10.1109/TPAMI.2002.1017616
   Wang C, 2019, IEEE GEOSCI REMOTE S, V16, P310, DOI 10.1109/LGRS.2018.2872355
   Wang H, 2018, PROC CVPR IEEE, P1248, DOI 10.1109/CVPR.2018.00136
   Wang J, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060620
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wang R. J., 2018, P 2018 ANN C NEUR IN, P1963
   Wang SY, 2018, LECT NOTES COMPUT SC, V11217, P557, DOI 10.1007/978-3-030-01261-8_33
   Wang W., 2019, ARXIV190409146
   Wang WH, 2015, LECT NOTES COMPUT SC, V8944, P812, DOI 10.1007/978-3-319-15554-8_73
   Wang XL, 2017, PROC CVPR IEEE, P3039, DOI 10.1109/CVPR.2017.324
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wang XL, 2018, PROC CVPR IEEE, P7774, DOI 10.1109/CVPR.2018.00811
   Wang YH, 2019, IEEE ICC
   Wei YT, 2016, PATTERN RECOGN, V58, P216, DOI 10.1016/j.patcog.2016.04.002
   Weimer D, 2016, CIRP ANN-MANUF TECHN, V65, P417, DOI 10.1016/j.cirp.2016.04.072
   Weston J., 1999, PROC EUROPEAN S ARTI, P219
   Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   WU X, 2016, ARXIV160403058
   Xiao JX, 2016, INT J COMPUT VISION, V119, P3, DOI 10.1007/s11263-014-0748-y
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu M., 2018, ARXIV PREPRINT ARXIV
   Xue J, 2013, INTERSPEECH, P2364
   Yanai K, 2015, 2015 IEEE INT C MULT, P1, DOI DOI 10.1109/ICMEW.2015.7169816
   Yang B., 2014, IEEE INT JOINT C BIO, P1
   Yang S, 2018, IEEE T PATTERN ANAL, V40, P1845, DOI 10.1109/TPAMI.2017.2738644
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Yang Z, 2019, IEEE ICC
   Yildirim G, 2015, LECT NOTES COMPUT SC, V9005, P514, DOI 10.1007/978-3-319-16811-1_34
   Yu F., 2017, PROC CVPR IEEE, P472, DOI [DOI 10.1109/CVPR.2017.75, 10.1109/CVPR.2017.75]
   Yu F., 2015, ARXIV
   YU Y, 2010, EUR C COMP VIS WORKS
   Yu ZW, 2007, IEEE T MULTIMEDIA, V9, P766, DOI 10.1109/TMM.2007.893351
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
   Zeng XY, 2016, LECT NOTES COMPUT SC, V9911, P354, DOI 10.1007/978-3-319-46478-7_22
   Zhang H., 2019, ARXIV190706881
   Zhang JM, 2016, PROC CVPR IEEE, P5733, DOI 10.1109/CVPR.2016.618
   Zhang J, 2018, PROC CVPR IEEE, P9029, DOI 10.1109/CVPR.2018.00941
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang SF, 2018, LECT NOTES COMPUT SC, V11207, P657, DOI 10.1007/978-3-030-01219-9_39
   Zhang SF, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P1, DOI 10.1109/BTAS.2017.8272675
   Zhang SF, 2017, IEEE I CONF COMP VIS, P192, DOI 10.1109/ICCV.2017.30
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang XS, 2019, ADV NEUR IN, V32
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhang Z, 2015, PROC CVPR IEEE, P2558, DOI 10.1109/CVPR.2015.7298871
   Zhang ZS, 2018, PROC CVPR IEEE, P5813, DOI 10.1109/CVPR.2018.00609
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhao ZN, 2019, IEEE ACM T COMPUT BI, V16, P1753, DOI 10.1109/TCBB.2017.2706682
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhou P, 2018, PROC CVPR IEEE, P528, DOI 10.1109/CVPR.2018.00062
   Zhou XL, 2019, IEEE INT CON MULTI, P850, DOI 10.1109/ICME.2019.00151
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
   Zhu R, 2019, PROC CVPR IEEE, P2263, DOI 10.1109/CVPR.2019.00237
   Zhu XZ, 2018, PROC CVPR IEEE, P7210, DOI 10.1109/CVPR.2018.00753
   Zhu XZ, 2017, IEEE I CONF COMP VIS, P408, DOI 10.1109/ICCV.2017.52
   Zhu XZ, 2017, PROC CVPR IEEE, P4141, DOI 10.1109/CVPR.2017.441
   Zhu YS, 2017, IEEE I CONF COMP VIS, P4146, DOI 10.1109/ICCV.2017.444
   Zhu Y, 2015, PROC CVPR IEEE, P4703, DOI 10.1109/CVPR.2015.7299102
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 288
TC 189
Z9 206
U1 205
U2 1065
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 23729
EP 23791
DI 10.1007/s11042-020-08976-6
EA JUN 2020
PG 63
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000539857100004
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Ann, B
   Jang, SW
AF Ann, Byeongtae
   Jang, Seok-Woo
TI Multimodal approach for multimedia injurious contents blocking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Obsceneness; Violence; Harmful contents; Multimedia
ID SYSTEM
AB Due to the development of IT technology, harmful multimedia contents are spreading out. In addition, obscene and violent contents have a negative impact on children. Therefore, in this paper, we propose a multimodal approach for blocking obscene and violent video contents. Within this approach, there are two modules each detects obsceneness and violence. In the obsceneness module, there is a model that detects obsceneness based on adult and racy score. In the violence module, there are two models for detecting violence: one is the blood detection model using RGB region and the other is motion extraction model for observation that violent actions have larger magnitude and direction change. Through result of these three models, this approach judges whether or not the content is harmful. This can contribute to the blocking obscene and violent contents that are distributed indiscriminately.
C1 [Ann, Byeongtae] Anyang Univ, Liberal & Arts Coll, 22,37 Beongil, Anyang 430714, Manan Gu, South Korea.
   [Jang, Seok-Woo] Anyang Univ, Dept Software, 22,37 Beongil, Anyang 430714, Manan Gu, South Korea.
C3 Anyang University; Anyang University
RP Jang, SW (corresponding author), Anyang Univ, Dept Software, 22,37 Beongil, Anyang 430714, Manan Gu, South Korea.
EM ahnbt@anyang.ac.kr; swjang7285@gmail.com
OI Jang, Seok-Woo/0000-0001-5580-4098
CR [Anonymous], 2013, SURVEY MEDIA AUDIENC
   Chiu SH, 2005, PATTERN RECOGN LETT, V26, P121, DOI 10.1016/j.patrec.2004.09.037
   Clarin C., 2005, PCSC, V6, P150
   Fradi H, 2017, IEEE T CIRC SYST VID, V27, P589, DOI 10.1109/TCSVT.2016.2615443
   Gao Y, 2016, IMAGE VISION COMPUT, V48-49, P37, DOI 10.1016/j.imavis.2016.01.006
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hu WM, 2007, IEEE T PATTERN ANAL, V29, P1019, DOI 10.1109/TPAMI.2007.1133
   Keçeli AS, 2017, ELECTRON LETT, V53, P1047, DOI 10.1049/el.2017.0970
   Kim CY, 2011, IEEE T CONSUM ELECTR, V57, P646, DOI 10.1109/TCE.2011.5955203
   Kim Kwang Soo, 2017, [JOURNAL OF BROADCAST ENGINEERING, 방송공학회 논문지], V22, P234, DOI 10.5909/JBE.2017.22.2.234
   Lee S, 2009, IEEE T CONSUM ELECTR, V55, P677, DOI 10.1109/TCE.2009.5174439
   Marmanis D, 2016, IEEE GEOSCI REMOTE S, V13, P105, DOI 10.1109/LGRS.2015.2499239
   Perez M, 2017, NEUROCOMPUTING, V230, P279, DOI 10.1016/j.neucom.2016.12.017
   Senst T, 2017, IEEE T INF FOREN SEC, V12, P2945, DOI 10.1109/TIFS.2017.2725820
   Zheng H, 2004, P IEEE INT C MULT C
NR 15
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16459
EP 16472
DI 10.1007/s11042-019-7527-2
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600036
DA 2024-07-18
ER

PT J
AU Ayas, S
   Ekinci, M
AF Ayas, Selen
   Ekinci, Murat
TI Microscopic image super resolution using deep convolutional neural
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Microscopic imaging; Super resolution; Deep residual learning;
   Convolutional neural networks
ID SUPERRESOLUTION; INTERPOLATION
AB Recently, deep convolutional neural networks (CNNs) have achieved excellent results in single image super resolution (SISR). Owing to the strength of deep CNNs, it gives promising results compared to state-of-the-art learning based models on natural images. Therefore, deep CNNs techniques have also been successfully applied to medical images to obtain better quality images. In this study, we present the first multi-scale deep CNNs capable of SISR for low resolution (LR) microscopic images. To achieve the difficulty of training deep CNNs, residual learning scheme is adopted where the residuals are explicitly supervised by the difference between the high resolution (HR) and the LR images and HR image is reconstructed by adding the lost details into the LR image. Furthermore, gradient clipping is used to avoid gradient explosions with high learning rates. Unlike the deep CNNs based SISR on natural images where the corresponding LR images are obtained by blurring and subsampling HR images, the proposed deep CNNs approach is tested using thin smear blood samples that are imaged at lower objective lenses and the performance is compared with the HR images taken at higher objective lenses. Extensive evaluations show that the superior performance on SISR for microscopic images is obtained using the proposed approach.
C1 [Ayas, Selen; Ekinci, Murat] Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkey.
C3 Karadeniz Technical University
RP Ayas, S (corresponding author), Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkey.
EM selenguven@ktu.edu.tr
RI Ekinci, Murat/A-9653-2012; Ayas, Selen/AAJ-8030-2021
OI Ayas, Selen/0000-0002-8226-2359
CR [Anonymous], 2018, Depression
   Ayas S, 2014, SIGNAL IMAGE VIDEO P, V8, pS49, DOI 10.1007/s11760-014-0708-6
   Bauschke HH, 1996, SIAM REV, V38, P367, DOI 10.1137/S0036144593251710
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   DUCHON CE, 1979, J APPL METEOROL, V18, P1016, DOI 10.1175/1520-0450(1979)018<1016:LFIOAT>2.0.CO;2
   Eaton-Rosen Z., 2018, INT C MED IM DEEP LE
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Hussain Zeshan, 2017, AMIA Annu Symp Proc, V2017, P979
   Irani M., 1993, Journal of Visual Communication and Image Representation, V4, P324, DOI 10.1006/jvci.1993.1030
   Jain V., 2009, ADV NEURAL INFORM PR, P769, DOI DOI 10.5555/2981780.2981876
   Jan Z, 2018, MULTIMED TOOLS APPL, V77, P9801, DOI 10.1007/s11042-017-4495-2
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Lewis JP, 1994, PROC CANAD IMAG PROC, P120
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Li M, 2008, IEEE T IMAGE PROCESS, V17, P1121, DOI 10.1109/TIP.2008.924289
   Li Q, 2014, I C CONT AUTOMAT ROB, P844, DOI 10.1109/ICARCV.2014.7064414
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nie LQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1192, DOI 10.1145/3123266.3123313
   Pascanu R., 2013, INT C MACH LEARN, P1310
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rivenson Y, 2017, OPTICA, V4, P1437, DOI 10.1364/OPTICA.4.001437
   Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915
   Shi Hongjian, 2002, 2002 IEEE INT S CIRC, V1, pI
   Song X, 2018, NEURAL COMPATIBILITY
   Song XM, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P753, DOI 10.1145/3123266.3123314
   Spanhol FA, 2016, IEEE IJCNN, P2560, DOI 10.1109/IJCNN.2016.7727519
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Tsai DM, 2003, PATTERN RECOGN LETT, V24, P2625, DOI 10.1016/S0167-8655(03)00106-5
   Wang Q, 2007, IEEE T IMAGE PROCESS, V16, P889, DOI 10.1109/TIP.2007.891794
   Wang S, 2018, FRONT ENV SCI ENG, V12, DOI 10.1007/s11783-017-0980-0
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WHO, 2017, GLOB RES INN ED ASS
   Xie Junyuan, 2012, ADV NEURAL INFORM PR, P341, DOI [DOI 10.5555/2999134.2999173, DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605]
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang YD, 2018, J COMPUT SCI-NETH, V28, P1, DOI 10.1016/j.jocs.2018.07.003
NR 48
TC 5
Z9 6
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15397
EP 15415
DI 10.1007/s11042-019-7397-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900058
DA 2024-07-18
ER

PT J
AU Baykal, E
   Dogan, H
   Ercin, ME
   Ersoz, S
   Ekinci, M
AF Baykal, Elif
   Dogan, Hulya
   Ercin, Mustafa Emre
   Ersoz, Safak
   Ekinci, Murat
TI Transfer learning with pre-trained deep convolutional neural networks
   for serous cell classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Serous effusion; Cytopathological assessment; Cell classification;
   Convolutional neural networks; Transfer learning
ID GRAPH
AB Serous effusion is a condition of excess accumulation of fluids in serous cavities due to different underlying pathological conditions. The basis of cytopathological assessment of serous effusions is the identification of cells in the fluid based on their morphology and texture. This assessment is a physically and mentally laborious task, and it can also lead to variability among pathologists. In literature, only a small number of feature-based methods are conducted for automated serous cell classification. In this study, a transfer learning with pre-trained deep convolutional neural networks (ConvNets) is proposed to automatically identify 11 different categories of serous cells in effusion cytology. Unlike the methods which rely on the extraction of cellular features such as morphology and texture, this method is an appearance-based machine learning approach. We fine-tuned four pre-trained ConvNet architectures that are AlexNet, GoogleNet, ResNet and DenseNet on the serous cell dataset. To reduce the overfitting effect, we augmented the data by image rotation, translation, and mirroring. The proposed method was evaluated on both original and augmented sets of serous cells derived from a publicly available dataset. Among the four ConvNet models, ResNet and DenseNet obtained the highest accuracies of 93.44% and 92.90%. However, when two models were compared in terms of accuracy and model complexity, ResNet-TL was selected as the best network model. When compared to the results without data augmentation, data augmentation increased the accuracy rate approximately 10%. Results show that higher classification results were achieved than other traditional methods without requiring precise segmentation.
C1 [Baykal, Elif; Dogan, Hulya; Ekinci, Murat] Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkey.
   [Ercin, Mustafa Emre; Ersoz, Safak] Karadeniz Tech Univ, Fac Med, Dept Pathol, TR-61080 Trabzon, Turkey.
C3 Karadeniz Technical University; Karadeniz Technical University
RP Baykal, E (corresponding author), Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkey.
EM ebaykal@ktu.edu.tr; hulya@ktu.edu.tr; drmustafaemreercin@ktu.edu.tr;
   sersoz@ktu.edu.tr; ekinci@ktu.edu.tr
RI Dogan, Hulya/AAW-9173-2021; Baykal Kablan, Elif/JCP-1902-2023; ersöz,
   safak/AAM-9041-2021; Kablan, Elif Baykal/AAS-4282-2020; Ercin, Mustafa
   Emre/AAU-6389-2020; Ekinci, Murat/A-9653-2012; Baykal Kablan,
   Elif/JVO-0310-2024
OI Baykal Kablan, Elif/0000-0003-3552-638X; Ercin, Mustafa
   Emre/0000-0002-7340-8045; Baykal Kablan, Elif/0000-0003-3552-638X
CR [Anonymous], P VISION INTERFACE
   [Anonymous], EUR C STER
   [Anonymous], 2017, COMP M BIO BIO E-IV, DOI DOI 10.1080/21681163.2015.1061448
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], IEEE J BIOMEDICAL HL
   [Anonymous], MED IMAGING
   [Anonymous], 2014, P ADV NEUR INF PROC
   [Anonymous], ARXIV81006058
   [Anonymous], SEROUS EFFUSIONS ETI
   [Anonymous], 2015, CLEF WORKING NOTES
   [Anonymous], IMAGE ANAL STEREOL
   Baykal E, 2017, P 25 SIGN PROC COMM, P1
   Bedrossian CWM, 1998, DIAGN CYTOPATHOL, V19, P131, DOI 10.1002/(SICI)1097-0339(199808)19:2<131::AID-DC14>3.0.CO;2-G
   Breiman L., 2001, Mach. Learn., V45, P5
   Cakir E, 2009, DIAGN CYTOPATHOL, V37, P4, DOI 10.1002/dc.20938
   Cardot H, 2002, INT C PATT RECOG, P873, DOI 10.1109/ICPR.2002.1048441
   Carneiro G, 2015, LECT NOTES COMPUT SC, V9351, P652, DOI 10.1007/978-3-319-24574-4_78
   Chen H, 2015, IEEE J BIOMED HEALTH, V19, P1627, DOI 10.1109/JBHI.2015.2425041
   Cheng L, 2012, ADV INTEL SOFT COMPU, V120, P209
   Cheng L, 2011, LECT NOTES COMPUT SC, V6891, P637, DOI 10.1007/978-3-642-23623-5_80
   CIREAN DC, 2011, ARXIV11020183
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   DeBiasi EM, 2015, EUR RESPIR J, V46, P495, DOI 10.1183/09031936.00217114
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jantzen J., 2005, P NISIS 2005 NATURE, P1
   Jin MG, 2014, I S BIOMED IMAGING, P1251, DOI 10.1109/ISBI.2014.6868103
   LeCun Y., 2012, Lecture Notes in Computer Science
   Lezoray O, 2003, MACH VISION APPL, V14, P166, DOI 10.1007/s00138-002-0120-z
   Lezoray O, 2002, IEEE T IMAGE PROCESS, V11, P783, DOI 10.1109/TIP.2002.800889
   Lu L, 2017, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-3-319-42999-1
   Öz SD, 2018, FLORENCE NIGHTINGALE, V26, P1, DOI 10.26650/FNJN.387142
   Papanicolaou G. N., 1942, Science, V95, P438, DOI 10.1126/science.95.2469.438
   Penatti Otavio A. B., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P44, DOI 10.1109/CVPRW.2015.7301382
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   SHEPPARD CJR, 1978, OPT LETT, V3, P115, DOI 10.1364/OL.3.000115
   Shidham VB., 2007, Cytopathologic diagnosis of serous fluids, V1st
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   SHOTTON DM, 1989, J CELL SCI, V94, P175
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Ta VT, 2009, PATTERN RECOGN, V42, P1113, DOI 10.1016/j.patcog.2008.10.029
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
NR 46
TC 18
Z9 20
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15593
EP 15611
DI 10.1007/s11042-019-07821-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900067
DA 2024-07-18
ER

PT J
AU Fernandez, DG
   Botella, G
   Del Barrio, AA
   Garcia, C
   Prieto-Matias, M
   Grecos, C
AF Fernandez, D. G.
   Botella, Guillermo
   Del Barrio, Alberto A.
   Garcia, Carlos
   Prieto-Matias, Manuel
   Grecos, Christos
TI HEVC optimization based on human perception for real-time environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; CU size decision; Spatial homogeneity; Temporal homogeneity; HVS
   metrics; GPU; Mode decision; Intra prediction; Inter prediction; Texture
   analysis
ID CU SIZE DECISION; IMAGE QUALITY ASSESSMENT; MODE DECISION; COMPLEXITY
   REDUCTION; INFORMATION; SELECTION
AB High-Efficiency Video Coding (HEVC) is the new emerging video coding standard of the ITU-T Video Coding Experts Group (VCEG) and the ISO/IEC Moving Picture Experts Group (MPEG). The HEVC standard provides a significant improvement in compression efficiency in comparison with existing standards such as H264/AVC by means of greater complexity. In this paper we will examine several HEVC optimizations based on image analysis to reduce its huge CPU, resource and memory expensive encoding process. The proposed algorithms optimize the HEVC quad-tree partitioning procedure, intra/inter prediction and mode decision by means of H264-based methods and spatial and temporal homogeneity analysis which is directly applied to the original video. The validation process of these approaches was conducted by taking into account the human visual system (HVS). The adopted solution makes it possible to perform HEVC real time encoding for HD sequences on a low cost processor with negligible quality loss. Moreover, the frames pre-processing leverages the logic units and embedded hardware available on an Intel GPU, so the execution time of these stages are negligible for the encoding processor.
C1 [Fernandez, D. G.; Botella, Guillermo; Del Barrio, Alberto A.; Garcia, Carlos; Prieto-Matias, Manuel] Univ Complutense Madrid, Dept Comp Architecture & Automat, Madrid 28040, Spain.
   [Grecos, Christos] Cent Washington Univ, Dept Comp Sci, Washington, WA 98926 USA.
C3 Complutense University of Madrid; Central Washington University
RP Del Barrio, AA (corresponding author), Univ Complutense Madrid, Dept Comp Architecture & Automat, Madrid 28040, Spain.
EM davidgfe@ucm.es; gbotella@ucm.es; abarriog@uem.es; garsanca@ucm.es;
   mpmatias@ucm.es; christos.graikos@cwu.edu
RI Prieto-Matias, Manuel/K-8325-2012; Botella, Guillermo/H-1877-2015; Del
   Barrio Garcia, Alberto Antonio/G-9962-2015; Garcia Sanchez,
   Carlos/R-5056-2018
OI Prieto-Matias, Manuel/0000-0003-0687-3737; Del Barrio Garcia, Alberto
   Antonio/0000-0002-6769-1200; Garcia Sanchez, Carlos/0000-0002-3470-1097
CR Ahn S, 2015, IEEE T CIRC SYST VID, V25, P422, DOI 10.1109/TCSVT.2014.2360031
   Alcocer E., 2016, J REAL TIME IMAGE PR
   [Anonymous], 2017, GNU GPL 2 LIC SOURC
   [Anonymous], 2012, Document JCTVC-K1100
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], 2012, P 2012 VISUAL COMMUN
   [Anonymous], OPENCL SPEC VERS 1 1
   [Anonymous], 2000, EE392J
   [Anonymous], 2012, METH SUBJ ASS QUAL T
   [Anonymous], P 5 INT C INT MULT C
   [Anonymous], IEEE INT C IM PROC I
   [Anonymous], IEEE T CIRCUITS SYST
   Bjontegarrd G, 2001, 13 VCEG M
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   de-Frutos-López M, 2010, SIGNAL PROCESS-IMAGE, V25, P709, DOI 10.1016/j.image.2010.10.005
   Fernández DG, 2018, MULTIMED TOOLS APPL, V77, P5907, DOI 10.1007/s11042-017-4503-6
   Fernández DG, 2018, DIGIT SIGNAL PROCESS, V73, P24, DOI 10.1016/j.dsp.2017.11.001
   Fernández DG, 2017, PROC SPIE, V10223, DOI 10.1117/12.2262604
   Fernández DG, 2016, PROC SPIE, V9871, DOI 10.1117/12.2224777
   Fernando DAIP, 2016, STUD COMPUT INTELL, V656, P1, DOI 10.1007/978-3-319-40171-3_1
   Fraunhofer Institute for Telecommunications, 2018, PERC OPT VID COD
   Goswami K, 2014, J REAL TIME IMAGE PR
   Intel Corporation, 2016, INTR ADV MOT EXT OPE
   Intel Corporation White Paper, 2012, PERFORMANCE INTERACT
   Jiang W, 2012, INT C WIREL COMM NET
   Khan MUK, 2013, DES AUT TEST EUROPE, P125
   Khronos OpenCL Working Group, 2016, ONL DOC CL INT ADV M
   Koumaras H., 2012, FUTURE NETWORK MOBIL
   Leal da Silva T, 2015, J REAL TIME IMAGE PR
   Lee JH, 2013, IEEE INT C IM PROC I
   Liu X, 2016, IEEE T CIRCUITS SYST, V99
   MALLIKARACHCHI T, 2014, IEEE INT CON MULTI, DOI DOI 10.1109/ICME.2014.6890319
   Fernández JMM, 2016, RED-REV EDUC DISTANC, DOI 10.6018/red/51/4
   McCann K., 2014, JCT VC HIGH EFFICIEN
   Min B, 2014, IEEE T CIRCUITS SYST, V25, P1
   Moorthy AK, 2010, PROC SPIE, V7527, DOI 10.1117/12.844198
   MSU Graphics & Media Lab (Video Group), 2016, MSU VIDEO QUALITY ME
   Multimedia Signal Processing Group (MMSPG), 2016, VQMT VID QUAL MEAS T
   Na S, 2014, I SYMP CONSUM ELECTR, P13
   Oztekin A., 2015, J REAL TIME IMAGE PR
   Pastuszak G., 2015, J REAL TIME IMAGE PR
   Peng XG, 2013, J MOL CELL CARDIOL, V59, P1, DOI 10.1016/j.yjmcc.2013.01.018
   Ponomarenko N, 2007, P 3 INT WORKSHOP VID
   Ramezanpour M, 2016, J REAL TIME IMAGE PR
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Shen LQ, 2008, IEEE T MULTIMEDIA, V10, P1208, DOI 10.1109/TMM.2008.2001358
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Shen Liquan, 2009, IEEE T BROADCASTING, V55
   Shen Liquan, 2010, IEEE T CIRCUITS SYST, V20
   Sullivan G.J., 2014, High Efficiency Video Coding (HEVC)"
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tian GF, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P405, DOI 10.1109/PCS.2012.6213317
   Ting YC, 2014, IEEE INT SYMP CIRC S, P1929, DOI 10.1109/ISCAS.2014.6865538
   Vanne J, 2014, IEEE T CIRC SYST VID, V24, P1579, DOI 10.1109/TCSVT.2014.2308453
   Wang HM, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P709, DOI 10.1109/ICME.2006.262412
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2003, 37 AS C SIGN SYST CO
   Watson AB, 1998, P SOC PHOTO-OPT INS, V3299, P139, DOI 10.1117/12.320105
   Wei Jiang, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1836, DOI 10.1109/CECNet.2012.6201851
   Wu D, 2005, IEEE T CIRC SYST VID, V15, P953, DOI 10.1109/TCSVT.2005.848304
   Xiong J, 2015, IEEE T MULTIMEDIA, V17, P2147, DOI 10.1109/TMM.2015.2491018
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P2141, DOI 10.1109/TMM.2014.2356795
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P559, DOI 10.1109/TMM.2013.2291958
   xiph.org, 2016, DERFS TEST MED COLL
   Ye T, 2013, 5 INT C INT MULT COM
   Yoon HJ, 2009, PROC SPIE, V7248, DOI 10.1117/12.805626
   Zhang CJ, 2013, INT CONF MEASURE, P17, DOI 10.1109/MIC.2013.6757907
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
NR 70
TC 5
Z9 5
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16001
EP 16033
DI 10.1007/s11042-018-7033-y
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600012
DA 2024-07-18
ER

PT J
AU He, P
   Chang, XC
   Xu, XH
   Zhang, ZJ
   Jing, TY
   Lou, Y
AF He, Ping
   Chang, Xincheng
   Xu, Xiaohua
   Zhang, Zhijun
   Jing, Tianyu
   Lou, Yuan
TI Discriminative locally linear mapping for medical diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical diagnosis; Manifold learning; Classification; Locally linear
   embedding; Out-of-sample extension
ID GEODESIC PROPAGATION
AB Medical diagnosis based on machine learning has received growing interest in recent years. However, traditional classification algorithms often fail to appropriately deal with medical datasets because of their high dimensionality. Manifold learning is a branch of nonlinear dimension reduction algorithms that can map the high dimensional data into a low-dimensional space. In this paper, we propose a novel manifold-based medical diagnosis algorithm named Discriminative Locally Linear Mapping (DL2M). DL2M is built on the basis of the well-known manifold leaning algorithm LLE (Locally Linear Embedding). It incorporates the discriminative information of training data into the manifold transformation of LLE, and then propagates the discriminative mapping into out-of-sample extension. DL2M is not only advantageous in preserving the local structure of original manifold, but also maps the different classes of data as far as possible in the low-dimensional feature space. The time complexity of DL2M algorithm is also discussed. Sufficient experimental results demonstrate that our method exhibits promising classification performance on the real-world medical datasets.
C1 [He, Ping; Chang, Xincheng; Xu, Xiaohua; Zhang, Zhijun; Jing, Tianyu; Lou, Yuan] Yangzhou Univ, Dept Comp Sci, Yangzhou 225002, Jiangsu, Peoples R China.
C3 Yangzhou University
RP Xu, XH (corresponding author), Yangzhou Univ, Dept Comp Sci, Yangzhou 225002, Jiangsu, Peoples R China.
EM arterx@gmail.com
CR [Anonymous], 2002, Computer Science, DOI DOI 10.1007/978-3-642-27733-7299-3
   [Anonymous], 2007, J ELECT IMAGING
   [Anonymous], 2016, CONCURR COMPUT PRACT
   Chen XW, 2012, LECT NOTES COMPUT SC, V7574, P553, DOI 10.1007/978-3-642-33712-3_40
   de Bruijne M, 2016, MED IMAGE ANAL, V33, P94, DOI 10.1016/j.media.2016.06.032
   de Ridder D, 2003, LECT NOTES COMPUT SC, V2714, P333
   de Ridder D., 2002, TECHNICAL REPORT, P1
   Jin X, 2019, OPT LASER TECHNOL, V110, P7, DOI 10.1016/j.optlastec.2017.11.008
   Li Q, 2014, IEEE T IMAGE PROCESS, V23, P4812, DOI 10.1109/TIP.2014.2358193
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu F, 2016, PATTERN RECOGN LETT, V75, P30, DOI 10.1016/j.patrec.2016.03.003
   Liu X, 2009, J ZHEJIANG UNIV-SC A, V2, P19
   Liu X, 2013, NEUROIMAGE, V83, P148, DOI 10.1016/j.neuroimage.2013.06.033
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Ma YY, 2013, INT STAT REV, V81, P134, DOI 10.1111/j.1751-5823.2012.00182.x
   Platt J.C, 1998, J INF TECHNOL-UK, V2, P1
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Trambaiolli LR, 2011, CLIN EEG NEUROSCI, V42, P160, DOI 10.1177/155005941104200304
   Wang D, 2016, IEEE T CIRC SYST VID, V26, P1709, DOI 10.1109/TCSVT.2015.2462012
   Wang D, 2014, PROC CVPR IEEE, P3478, DOI 10.1109/CVPR.2014.445
   Wang D, 2015, IEEE T IMAGE PROCESS, V24, P2646, DOI 10.1109/TIP.2015.2427518
   Weston J., 1999, 7th European Symposium on Artificial Neural Networks. ESANN'99. Proceedings, P219
   Xiang SM, 2009, IEEE T KNOWL DATA EN, V21, P1285, DOI 10.1109/TKDE.2008.204
   Xu X, 2019, WORLD WIDE WEB, V22, P657, DOI 10.1007/s11280-018-0541-x
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang X, 2017, MED IMAGE ANAL, V42, P212, DOI 10.1016/j.media.2017.08.006
   Zhang SC, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2990508
NR 29
TC 2
Z9 2
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14573
EP 14591
DI 10.1007/s11042-018-7064-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900015
DA 2024-07-18
ER

PT J
AU Jiang, XW
   Lu, MZ
   Wang, SH
AF Jiang, Xianwei
   Lu, Mingzhou
   Wang, Shui-Hua
TI An eight-layer convolutional neural network with stochastic pooling,
   batch normalization and dropout for fingerspelling recognition of
   Chinese sign language
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Hyperparameter optimization; Deep
   learning; Stochastic pooling; Batch normalization; Dropout
ID IMAGE
AB Fingerspelling recognition of Chinese sign language rendered an opportunity to smooth the communication barriers of hearing-impaired people and health people, which occupies an important position in sign language recognition. This study proposed an eight-layer convolutional neural network, combined with three advanced techniques: batch normalization, dropout, and stochastic pooling. The output of the stochastic pooling was obtained via sampling from a multinomial distribution formed from the activations of each pooling region. In addition, we used data augmentation method to enhance the training set. In total 10 runs were implemented with the hold-out randomly set for each run. Our method achieved the highest accuracy of 90.91% and overall accuracy of 89.32 +/- 1.07%, which was superior to three state-of-the-art approaches compared.
C1 [Jiang, Xianwei] Nanjing Normal Univ Special Educ, Nanjing 210038, Peoples R China.
   [Lu, Mingzhou] Nanjing Agr Univ, Jiangsu Prov Engn Lab Modern Facil Agr Technol &, Coll Engn, Nanjing 210031, Peoples R China.
   [Wang, Shui-Hua] Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454000, Henan, Peoples R China.
   [Wang, Shui-Hua] Loughborough Univ, Sch Architecture Bldg & Civil Engn, Loughborough LE11 3TU, Leics, England.
C3 Nanjing Normal University of Special Education; Nanjing Agricultural
   University; Henan Polytechnic University; Loughborough University
RP Wang, SH (corresponding author), Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454000, Henan, Peoples R China.; Wang, SH (corresponding author), Loughborough Univ, Sch Architecture Bldg & Civil Engn, Loughborough LE11 3TU, Leics, England.
EM jxw@njts.edu.cn; lmz@njau.edu.cn; shuihuawang@ieee.org
RI Jiang, Xianwei/AAC-1953-2019; Wang, Shuihua/G-7326-2016
OI Jiang, Xianwei/0000-0001-9854-6682; 
CR [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   Chen LJ, 2010, INT CONF SIGN PROCES, P2202, DOI 10.1109/ICOSP.2010.5656765
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B
   Dingqian SXG, 2005, CHIN J SPEC ED, V2, P65
   Du T, 2018, PROCEEDINGS 2018 33RD YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P782, DOI 10.1109/YAC.2018.8406477
   Huang J, 2018, AAAI CONF ARTIF INTE, P2257
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Khan SH, 2019, NEURAL NETWORKS, V110, P82, DOI 10.1016/j.neunet.2018.09.009
   Koller O, 2018, INT J COMPUT VISION, V126, P1311, DOI 10.1007/s11263-018-1121-3
   Kong FQ, 2018, MULTIMED TOOLS APPL, V77, P22857, DOI 10.1007/s11042-018-5976-7
   Kumar P, 2018, MULTIMED TOOLS APPL, V77, P8823, DOI 10.1007/s11042-017-4776-9
   Lee GC, 2016, MULTIMED TOOLS APPL, V75, P261, DOI 10.1007/s11042-014-2290-x
   Leopold HA, 2019, J IMAGING, V5, DOI 10.3390/jimaging5020026
   Li THS, 2016, IEEE T SYST MAN CY-S, V46, P150, DOI 10.1109/TSMC.2015.2435702
   Li X, 2017, Research on Chinese Sign Language Recognition for Middle and Small Vocabulary Based on Neural Network, P1
   Lichtenauer JF, 2008, IEEE T PATTERN ANAL, V30, P2040, DOI 10.1109/TPAMI.2008.123
   Liu J, 2016, IEEE ASIAN SOLID STA, P221, DOI 10.1109/ASSCC.2016.7844175
   Lu SY, 2019, J COMPUT SCI-NETH, V30, P41, DOI 10.1016/j.jocs.2018.11.008
   Pariwat T, 2017, INT CONF KNOWL SMART, P116, DOI 10.1109/KST.2017.7886111
   Rao G. A., 2017, Far East Journal of Electronics and Communications, V17, P49, DOI [10.17654/EC017010049, DOI 10.17654/EC017010049]
   Sellami A, 2019, EXPERT SYST APPL, V122, P75, DOI 10.1016/j.eswa.2018.12.037
   Wang S, 2018, FRONT ENV SCI ENG, V12, DOI 10.1007/s11783-017-0980-0
   Yang JY, 2019, J COMPUT SCI-NETH, V30, P11, DOI 10.1016/j.jocs.2018.11.001
   Zhang Y, 2011, J ELECTROMAGNET WAVE, V25, P1081, DOI 10.1163/156939311795762024
   Zhang YD, 2018, J COMPUT SCI-NETH, V28, P1, DOI 10.1016/j.jocs.2018.07.003
   Zhang YD, 2018, J COMPUT SCI-NETH, V27, P57, DOI 10.1016/j.jocs.2018.05.005
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22875, DOI 10.1007/s11042-018-6003-8
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22821, DOI 10.1007/s11042-018-5765-3
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22671, DOI 10.1007/s11042-017-5146-3
   Zhang YD, 2019, MULTIMED TOOLS APPL, V78, P3613, DOI 10.1007/s11042-017-5243-3
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22629, DOI 10.1007/s11042-017-5023-0
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22589, DOI 10.1007/s11042-017-4703-0
   Zhang YD, 2008, SCI CHINA SER F, V51, P2115, DOI 10.1007/s11432-008-0124-z
   Zhang YD, 2011, ENTROPY-SWITZ, V13, P841, DOI 10.3390/e13040841
   Zhang YD, 2010, SCI CHINA INFORM SCI, V53, P1963, DOI 10.1007/s11432-010-4075-9
   Zhang YD, 2008, SENSORS-BASEL, V8, P7518, DOI 10.3390/s8117518
   Zhang YD, 2010, EXPERT SYST APPL, V37, P1911, DOI 10.1016/j.eswa.2009.07.025
   Zhang YD, 2009, SCI CHINA SER F, V52, P914, DOI 10.1007/s11432-009-0019-7
NR 39
TC 16
Z9 16
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15697
EP 15715
DI 10.1007/s11042-019-08345-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900072
DA 2024-07-18
ER

PT J
AU Khedr, WI
AF Khedr, Walid, I
TI A new efficient and configurable image encryption structure for secure
   transmission
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Stream ciphers; Image hashing; Privacy; Security
ID SYSTEM
AB This paper presents a novel robust symmetric image encryption structure (IES) based on stream ciphers and perceptual hashing for secure image transmission over public networks. The main design objectives of the proposed structure are to utilize, without modifications, any stream ciphers, and perceptual hash functions, easy replaceability of both stream cipher and hashing algorithms, preserve the original performance of the embedded algorithms and to retain all the security of the underlying algorithms. In the proposed structure, a one-time session key is generated from both the image and a pre-shared key between the sender and the recipient of the image. This one-time session key is used by a stream cipher to encrypt the image, which achieves high plaintext sensitivity (diffusion) and high key sensitivity (confusion). To achieve the robustness property of the proposed structure against incidental modifications of the encrypted image, a one-time key encryption key (KEK) is generated from both the perceptual hash of the encrypted image and the pre-shared key. The KEK is used to encrypt the one-time session key which is then embedded into the encrypted image. To demonstrate the efficiency and the robustness of the proposed IES, an image encryption algorithm based on the IES is proposed. Experimental results demonstrate the high security, low complexity and high speed of the proposed IES.
C1 [Khedr, Walid, I] Zagazig Univ, Fac Comp & Informat, Zagazig 44519, Egypt.
C3 Egyptian Knowledge Bank (EKB); Zagazig University
RP Khedr, WI (corresponding author), Zagazig Univ, Fac Comp & Informat, Zagazig 44519, Egypt.
EM wkhedr@zu.edu.eg
CR Aissa B, 2014, I C SCI TECH AUTO CO, P498, DOI 10.1109/STA.2014.7086692
   [Anonymous], 2017, TECHNICAL REPORT
   [Anonymous], 7693 IETF RFC
   [Anonymous], 1994, Mathematica Journal, DOI DOI 10.1016/0165-1684(90
   [Anonymous], 2012, ISO166841
   Ashur T, 2017, BOOSTING AUTHENTICAT, P3
   Aumasson J.P., 2014, HASH FUNCTION BLAKE
   Bahrami S, 2012, ADV MULTIMED, V2012, DOI 10.1155/2012/767364
   Borujeni SE, 2013, TELECOMMUN SYST, V52, P525, DOI 10.1007/s11235-011-9458-8
   Boyd Colin., 2013, PROTOCOLS AUTHENTICA
   Chen JX, 2015, NONLINEAR DYNAM, V81, P1151, DOI 10.1007/s11071-015-2057-6
   Chen JX, 2014, OPTIK, V125, P2472, DOI 10.1016/j.ijleo.2013.12.001
   Cheng H., 2014, INTELLIGENT DATA ITS, V298, P301, DOI DOI 10.1007/978-3-319-07773-4_30
   Cheng Z, 2014, J APPL MATH, DOI 10.1155/2014/369350
   Daemen J., 2013, DESIGN RIJNDAEL AES
   Das A., 2015, Guide to signals and patterns in image processing: foundations, methods and applications
   Diab H, 2018, IEEE ACCESS, V6, P42227, DOI 10.1109/ACCESS.2018.2858839
   Faragallah O., 2013, IMAGE ENCRYPTION COM
   Fei MJ, 2017, MULTIMED TOOLS APPL, V76, P4617, DOI 10.1007/s11042-016-3723-5
   Hadmi A, 2012, PERCEPTUAL IMAGE HAS, DOI [10.5772/37435, DOI 10.5772/37435.AVAILABLE]
   Huang CG, 2015, 2015 THIRD INTERNATIONAL CONFERENCE ON ROBOT, VISION AND SIGNAL PROCESSING (RVSP), P163, DOI 10.1109/RVSP.2015.46
   Jallouli O, 2018, MULTIMED TOOLS APPL, V77, P13391, DOI 10.1007/s11042-017-4953-x
   Kaur M, 2018, ARAB J SCI ENG, V43, P8127, DOI 10.1007/s13369-018-3355-3
   Kim H, 2007, P 2007 ACM S APPL CO
   Klinger E, 2018, PHASH THE OPEN SOURC
   Kumari M, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0162-2
   Kunze J., 2007, 5013 RFC IETF
   Kwok HS, 2007, CHAOS SOLITON FRACT, V32, P1518, DOI 10.1016/j.chaos.2005.11.090
   Liu H, 2016, MULTIMED TOOLS APPL, V75, P7681, DOI 10.1007/s11042-015-2688-0
   Nir Y, 2015, 7539 RFC IETF
   Norouzi B, 2015, MULTIMED TOOLS APPL, V74, P781, DOI 10.1007/s11042-013-1699-y
   Norouzi B, 2014, MULTIMEDIA SYST, V20, P45, DOI 10.1007/s00530-013-0314-4
   Paul PV, 2017, INT CONF COMPUT POW, P421, DOI 10.1109/ICCPEIC.2017.8290405
   Sreelaja NK, 2012, APPL SOFT COMPUT, V12, P2879, DOI 10.1016/j.asoc.2012.04.002
   Stallings W., 2016, Cryptography and Network Security: Principles and Practice, V7th
   Wang XY, 2018, IEEE ACCESS, V6, P23733, DOI 10.1109/ACCESS.2018.2805847
   Weber A, USC SIPI IMAGE DATAB
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Wong KW, 2009, CHAOS SOLITON FRACT, V41, P2652, DOI 10.1016/j.chaos.2008.09.047
   www.bouncycastle.org, 2018, LEG BOUNC CASTL JAV
   Xiao D, 2017, MULTIMED TOOLS APPL, V76, P9265, DOI 10.1007/s11042-016-3532-x
   Xu M, 2018, OPTIK, V171, P891, DOI 10.1016/j.ijleo.2018.06.112
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P6647, DOI 10.1007/s11042-017-4577-1
NR 43
TC 11
Z9 11
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16797
EP 16821
DI 10.1007/s11042-019-7235-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600056
DA 2024-07-18
ER

PT J
AU Kumar, A
   Garg, G
AF Kumar, Akshi
   Garg, Geetanjali
TI Systematic literature review on context-based sentiment analysis in
   social multimedia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Context; Sentiment analysis; Social multimedia; Systematic literature
   review
ID NETWORK; CLASSIFICATION; SEMANTICS
AB The opinion seeking behavior of people for good decision making has greatly enhanced the importance of social media as a platform for exchange of information. This trend has led to a sudden spurt of information overflow on the Web. The huge volume of such information has to be technically processed for segregating the relevant knowledge. Sentiment analysis is the popular method extensively used for this purpose. It is defined as the computational study of mining the opinions from the available content about the entity of interest. Existing Sentiment analysis techniques quite efficiently capture opinions from text written in syntactically correct and explicit language. However, while dealing with the informal data, limitation has been observed in performance of sentiment analysis techniques. With a view to deal with the imperfect and indirect language used by the netizens, it has become necessary to work on improvement in the existing sentiment analysis techniques. In this regard, the conventional sentiment analysis techniques have shown some improvement on applying the appropriate context information. However, still there is ample scope for further research to find the relevant "context" and applying it to a given scenario. This systematic literature review paper intends to explore and analyze the existing work on the context-based sentiment analysis and to report gaps and future directions in the said research area.
C1 [Kumar, Akshi; Garg, Geetanjali] Delhi Technol Univ, Dept Comp Sci & Engn, New Delhi, India.
C3 Delhi Technological University
RP Garg, G (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, New Delhi, India.
EM akshikumar@dce.ac.in; geetudtu@gmail.com
OI Kumar, Akshi/0000-0003-4263-7168
CR Aisopos F., 2012, L3Sde, P187, DOI DOI 10.1145/2309996.2310028
   Akers J., 2009, Systematic reviews: CRD's guidance for undertaking reviews in health care
   Anjaria M, 2014, SOC NETW ANAL MIN, V4, DOI 10.1007/s13278-014-0181-9
   [Anonymous], 2001, P APFA
   [Anonymous], 2016, INDIAN J SCI TECHNOL, DOI DOI 10.17485/IJST/2015/V8I1/105286
   Bhatia M. P. S., 2010, WEBOLOGY, V7, P1
   Bhatia MPS, 2008, WEBOLOGY, V5, P2
   Bosco C, 2013, IEEE INTELL SYST, V28, P55, DOI 10.1109/MIS.2013.28
   Deng SY, 2017, ACM TRANS MANAG INF, V8, DOI 10.1145/3046684
   Dey L, 2009, INT J DOC ANAL RECOG, V12, P205, DOI 10.1007/s10032-009-0090-z
   Dragoni M, 2015, COGN COMPUT, V7, P186, DOI 10.1007/s12559-014-9308-6
   Dukkipati R, 2008, ROAD VEHICLE DYNAMICS, P1
   Feng S, 2019, WORLD WIDE WEB, V22, P59, DOI 10.1007/s11280-018-0529-6
   Fersini E, 2017, WORLD WIDE WEB, V20, P831, DOI 10.1007/s11280-016-0419-8
   Frankenstein W, 2016, LECT NOTES COMPUTER
   Gaspar R, 2016, COMPUT HUM BEHAV, V56, P179, DOI 10.1016/j.chb.2015.11.040
   Gelli F, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P907, DOI 10.1145/2733373.2806361
   Han H, 2019, NEURAL COMPUT APPL, V31, P8475, DOI 10.1007/s00521-018-3698-4
   Hridoy S.A. A., 2015, Decision Analytics, V2, P8, DOI DOI 10.1186/S40165-015-0016-4
   Hung CL, 2017, INFORM PROCESS MANAG, V53, P751, DOI 10.1016/j.ipm.2017.02.007
   Jimenez-Zafra S.M., 2017, Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017), P634, DOI DOI 10.18653/V1/S17-2104
   Jurek A., 2015, SECURITY INFORM, V4, P9166, DOI [10.1186/s13388-015-0024-x, DOI 10.1186/S13388-015-0024-X]
   Kitchenham B, 2009, INFORM SOFTWARE TECH, V51, P7, DOI 10.1016/j.infsof.2008.09.009
   Korenek P, 2014, WORLD WIDE WEB, V17, P847, DOI 10.1007/s11280-013-0247-z
   Kumar Akshi, 2020, International Journal of Information Technology, V12, P1159, DOI 10.1007/s41870-017-0072-1
   Kumar Akshi, 2012, International Journal of Intelligent Systems and Applications, V4, P1, DOI 10.5815/ijisa.2012.10.01
   Kumar A., 2017, P WORLD C ENG COMP S, V1
   Kumar Akshi, 2012, International Journal of Computer Science Issues (IJCSI), V9, P372
   Lau RYK, 2014, DECIS SUPPORT SYST, V65, P80, DOI 10.1016/j.dss.2014.05.005
   Li YM, 2014, INT J ELECTRON COMM, V19, P99, DOI 10.2753/JEC1086-4415190103
   Liu B, 2010, CH CRC MACH LEARN PA, P627
   Liu Y, 2013, WORLD WIDE WEB, V16, P477, DOI 10.1007/s11280-012-0179-z
   Majumder N, 2018, KNOWL-BASED SYST, V161, P124, DOI 10.1016/j.knosys.2018.07.041
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Meire M, 2016, DECIS SUPPORT SYST, V89, P98, DOI 10.1016/j.dss.2016.06.013
   Muhammad A, 2016, KNOWL-BASED SYST, V108, P92, DOI 10.1016/j.knosys.2016.05.032
   Nakov P, 2016, LANG RESOUR EVAL, V50, P1, DOI 10.1007/s10579-016-9337-8
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Philip S.S., 2018, DATA ENG INTELLIGENT, P207, DOI DOI 10.1007/978-981-10-3223-3_19
   Poria S, 2014, KNOWL-BASED SYST, V69, P45, DOI 10.1016/j.knosys.2014.05.005
   Ravi K, 2015, KNOWL-BASED SYST, V89, P14, DOI 10.1016/j.knosys.2015.06.015
   Recupero DR, 2015, COGN COMPUT, V7, P211, DOI 10.1007/s12559-014-9302-z
   Ren FJ, 2013, IEEE T AFFECT COMPUT, V4, P412, DOI 10.1109/T-AFFC.2013.22
   Saif H, 2017, SEMANT WEB, V8, P643, DOI 10.3233/SW-170265
   Saif H, 2016, INFORM PROCESS MANAG, V52, P5, DOI 10.1016/j.ipm.2015.01.005
   Tao W, 2017, INTELL AUTOM SOFT CO, P1
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Vanzo A., 2014, The 25th International Conference on Computational Linguistics: Technical Papers, P2345
   Vechtomova O, 2017, INFORM PROCESS MANAG, V53, P1062, DOI 10.1016/j.ipm.2017.03.007
   Wang S. H., 2016, MSC THESIS, P1
   Wang SH, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00818
   Weichselbraun A, 2013, IEEE INTELL SYST, V28, P39, DOI 10.1109/MIS.2013.41
   Wiebe J, 2004, COMPUT LINGUIST, V30, P277, DOI 10.1162/0891201041850885
   Wilson TS, 2005, PHIL EDUC, P347, DOI 10.3115/1220575.1220619
   Wu FZ, 2016, NEUROCOMPUTING, V175, P599, DOI 10.1016/j.neucom.2015.10.101
   Yang BS, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P325
   Zhang YS, 2018, MULTIDIM SYST SIGN P, V29, P999, DOI 10.1007/s11045-017-0482-z
   Zhang YD, 2018, J COMPUT SCI-NETH, V27, P57, DOI 10.1016/j.jocs.2018.05.005
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22821, DOI 10.1007/s11042-018-5765-3
   Zhou Y., 2017, P 11 INT WORKSH SEM, P812
NR 60
TC 27
Z9 27
U1 3
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15349
EP 15380
DI 10.1007/s11042-019-7346-5
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900056
DA 2024-07-18
ER

PT J
AU Noura, H
   Noura, M
   Salman, O
   Couturier, R
   Chehab, A
AF Noura, Hassan
   Noura, Mohamad
   Salman, Ola
   Couturier, Raphael
   Chehab, Ali
TI Efficient & secure image availability and content protection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lightweight data protection; Dynamic key-dependent cryptographic
   algorithms; Data availability; Integrity and confidentiality; Security
   and performance analysis
ID SCHEME
AB Digital images are among the most communicated multimedia data types. Many of these images include private data that require a high level of security. The traditional image security schemes rely on cryptographic solutions to ensure the confidentiality or the authentication of image contents, and to ensure that the encryption key is not compromised. However, the continuous evolution of the attackers' capabilities is making it harder than ever to achieve the goal of safeguarding the private data against breaches. Moreover, the centralization aspect of images' storage makes them prone to availability attacks. In this paper, we propose a distributed and secure storage scheme for images, based on the Modified Information Dispersal Algorithm (MIDA), and taking into consideration the trade-off between the high security level and the associated computational overhead. The proposed solution applies block permutation on the image to ensure data confidentiality and then, divides it into k fragments that are encoded using the proposed parallel modified IDA. The output consists of n encoded fragments, instead of k, to ensure data availability. Next, each encoded fragment is authenticated using a lightweight Message Authentication Algorithm (MAA) to ensure data integrity with source authentication. Finally, the encoded fragments are distributed over n storage nodes (or multi-cloud providers). The resilience degree of such redundancy is (n - k), since only k fragments are required to reconstruct the original images. All the cryptographic steps such as permutation, IDA encoding and MAA consist of simple operations and they are based on a dynamic key. This ensures a high level of security since in each session, a new key is used to produce different cryptographic primitives as well as the update primitives, which are used to update the permutation and selection tables. The implementation results show that the proposed scheme meets the desired cryptographic properties to guard against different attacks. Finally, the performance tests show that the proposed scheme is lightweight with low overhead in terms of computations, communication and storage.
C1 [Noura, Hassan] Arab Open Univ, Fac Comp Studies, Beirut, Lebanon.
   [Noura, Hassan; Salman, Ola; Chehab, Ali] Amer Univ Beirut, Elect & Comp Engn, Beirut, Lebanon.
   [Noura, Mohamad; Couturier, Raphael] Univ Bourgogne Franche Comte, FEMTO ST Inst, CNRS, UMR 6174, Belfort, France.
C3 American University of Beirut; Centre National de la Recherche
   Scientifique (CNRS); CNRS - Institute for Engineering & Systems Sciences
   (INSIS); Universite de Franche-Comte; Universite de Technologie de
   Belfort-Montbeliard (UTBM)
RP Couturier, R (corresponding author), Univ Bourgogne Franche Comte, FEMTO ST Inst, CNRS, UMR 6174, Belfort, France.
EM raphael.couturier@univ-fcomte.fr
RI Couturier, Raphaël/C-1095-2013; Noura, Hassan/U-8729-2018
OI Couturier, Raphaël/0000-0003-1490-9592; Chehab, Ali/0000-0002-1939-2740;
   Noura, Hassan/0000-0002-2589-5053
FU Maroun Semaan Faculty of Engineering and Architecture at the American
   University of Beirut; EIPHI Graduate School [ANR-17-EURE-0002]
FX This paper is partially supported with funds from the Maroun Semaan
   Faculty of Engineering and Architecture at the American University of
   Beirut and also from the EIPHI Graduate School (contract
   "ANR-17-EURE-0002"). We also thank the supercomputer facilities of the M
   ' esocentre de calcul de Franche-Comte.
CR *ACM, 2016, P 2016 ACM SIGSAC C, P1745
   Adi S, 1979, APPL COMPUTATIONAL M, V22
   Ahmadian AM, 2019, SIGNAL PROCESS-IMAGE, V74, P78, DOI 10.1016/j.image.2019.01.006
   [Anonymous], 2018, MULTIMEDIA TOOLS APP
   Bao L, 2017, IEEE T IMAGE PROCESS, V26, P5618, DOI 10.1109/TIP.2017.2738561
   Barker EB, 2011, RECOMMENDATION RANDO
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Blundo C, 2001, CODES CRYPTOGRAPHY, V24
   Cimato S., 2017, VISUAL CRYPTOGRAPHY
   Cincilla P, 2015, 2015 12TH INTERNATIONAL JOINT CONFERENCE ON E-BUSINESS AND TELECOMMUNICATIONS (ICETE), VOL 4, P361
   Daemen J., 2013, DESIGN RIJNDAEL AES
   Dwivedi AD, 2018, INFORM PROCESS LETT, V136, P5, DOI 10.1016/j.ipl.2018.03.010
   Fabre J-C, 1994, DESIGNING SECURE REL, V21, P38
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   KAPUSTA K, 2017, 1 CYB SEC NETW C CSN, P1
   Krawczyk Hugo, 1993, Proceedings of the 13th Annual International Cryptology Conference on Advances in Cryptology, P136
   Lee KH, 2014, IEEE T INF FOREN SEC, V9, P88, DOI 10.1109/TIFS.2013.2292509
   LI M, 2012, ARXIV12064123 CORR
   Li P, 2013, J VIS COMMUN IMAGE R, V24, P1106, DOI 10.1016/j.jvcir.2013.07.005
   Lin CC, 2003, PATTERN RECOGN LETT, V24, P349, DOI 10.1016/S0167-8655(02)00259-3
   Lukac R, 2005, PATTERN RECOGN, V38
   Massoudi A, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/179290
   Mostefaoui A, 2015, AD HOC NETW, V32, P81, DOI 10.1016/j.adhoc.2015.01.007
   NAOR M, 2017, LECT NOTES COMPUT SC, V950, P1
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Noura H, 2017, MOL CELL ENDOCRINOL, P1
   Noura H, 2018, INT WIREL COMMUN, P1267, DOI 10.1109/IWCMC.2018.8450330
   Noura H, 2015, L N INST COMP SCI SO, V155, P225, DOI 10.1007/978-3-319-25067-0_18
   Noura H, 2015, IEEE WCNC, P2103, DOI 10.1109/WCNC.2015.7127792
   Noura H, 2014, COMPUT NETW, V75, P99, DOI 10.1016/j.comnet.2014.09.013
   Noura HN, 2019, SIGNAL PROCESS-IMAGE, V78, P448, DOI 10.1016/j.image.2019.08.005
   Noura HN, 2019, MULTIMED TOOLS APPL, V78, P14837, DOI 10.1007/s11042-018-6845-0
   Paar C., 2009, UNDERSTANDING CRYPTO
   Paul G., 2011, RC4 Stream Cipher and Its Variants
   RABIN MO, 1989, J ACM, V36, P335, DOI 10.1145/62044.62050
   Resch J.K., 2011, Proc. of USENIX FAST, P14
   Rivest RL, 1997, ALL OR NOTHING ENCRY, V210, P218
   Shankar K, 2020, J AMB INTEL HUM COMP, V11, P1821, DOI 10.1007/s12652-018-1161-0
   Shi RH, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P3, DOI 10.1109/CISP.2008.504
   Shyu SJ, 2006, PATTERN RECOGN, V39
   Stallings W., 2017, Cryptography and Network Security: Principles and Practice, V7th ed.
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Ulutas G, 2013, PATTERN RECOGN LETT, V34, P283, DOI 10.1016/j.patrec.2012.10.017
   Verheul ER, 1997, DES CODES CRYPT, V11
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei SC, 2015, COMPUT STAND INTER, V40, P53, DOI 10.1016/j.csi.2015.01.002
   Wu XT, 2018, SIGNAL PROCESS, V143, P269, DOI 10.1016/j.sigpro.2017.09.017
   Yan XH, 2015, MULTIMED TOOLS APPL, V74, P3231, DOI 10.1007/s11042-013-1784-2
   Yang CN, 2010, OPT COMMUN, V283, P1750, DOI 10.1016/j.optcom.2009.12.077
   Yang CN, 2000, DESIGN CODE CRYPTOGR, V20, P325, DOI 10.1023/A:1008382327051
NR 52
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22869
EP 22904
DI 10.1007/s11042-020-09057-4
EA JUN 2020
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000537402100002
OA Bronze
DA 2024-07-18
ER

PT J
AU Wang, XS
   Pang, SM
   Zhu, JH
   Wang, JX
   Wang, L
AF Wang, Xinsheng
   Pang, Shanmin
   Zhu, Jihua
   Wang, Jiaxing
   Wang, Lin
TI Unsupervised semantic-based convolutional features aggregation for image
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Deep convolutional features; Selection and aggregation;
   Unsupervised object localization; VGG16
AB Deep features extracted from the convolutional layers of pre-trained CNNs have been widely used in the image retrieval task. These features, however, are in a large number and probably cannot be directly used for similarity evaluation due to lack of efficiency. Thus, it is of great importance to study how to aggregate deep features into a global yet distinctive image vector. This paper first introduces a simple but effective method to select informative features based on semantic content of feature maps. Then, we propose an effective channel weighting method (CW) for selected features by analyzing relations between the discriminative activation and distribution parameters of feature maps, including standard variance, non-zero responses and sum value. Furthermore, we provide a solution to pick semantic detectors that are independent on gallery images. Based on the aforementioned three strategies, we derive a global image vector generation method, and demonstrate its state-of-the-art performance on benchmark datasets.
C1 [Wang, Xinsheng; Pang, Shanmin; Zhu, Jihua; Wang, Jiaxing] Xi An Jiao Tong Univ, Sch Software Engn, Xian, Peoples R China.
   [Wang, Lin] Northwest Univ, Sch Informat Sci & Technol, Xian, Peoples R China.
C3 Xi'an Jiaotong University; Northwest University Xi'an
RP Zhu, JH (corresponding author), Xi An Jiao Tong Univ, Sch Software Engn, Xian, Peoples R China.
EM wangxinsheng@stu.xjtu.edu.cn; pangsm@xjtu.edu.cn; zhujh@xjtu.edu.cn;
   csuwjx@stu.xjtu.edu.cn; wanglin@nwu.edu.cn
RI Pang, Shanmin/KBQ-6978-2024
CR [Anonymous], 2014, INF SOFTW TECHNOL
   [Anonymous], 2016, IMAGE RESTORATION US
   Azizpour Hossein, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P36, DOI 10.1109/CVPRW.2015.7301270
   Babenko A, 2015, COMPUTER SCI
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Cao XG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030737
   Chang G, 2016, AER ADV ENG RES, V99, P1
   Chum O., 2007, TOTAL RECALL AUTOMAT, P1
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Gordo A, 2016, INT J COMPUT VISION, P1
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   He L, 2017, IEEE INT CON MULTI, P1153, DOI 10.1109/ICME.2017.8019549
   Hoang T, 2018, SELECTIVE DEEP CONVO
   Husari G, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS (ISI), P1, DOI 10.1109/ISI.2018.8587343
   Jégou H, 2014, PROC CVPR IEEE, P3310, DOI 10.1109/CVPR.2014.417
   Jégou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55
   Jégou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609
   Jian X, 2018, ARXIV10, P10
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Kim DS, 2018, SENSORS, V18, P4
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu H, 2018, FUTUR GENER COMPUT S, P82
   Lu HM, 2018, MULTIMED TOOLS APPL, V77, P21847, DOI 10.1007/s11042-017-4585-1
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Ma Y, 2017, PROCEEDINGS OF 2017 7TH IEEE INTERNATIONAL SYMPOSIUM ON MICROWAVE, ANTENNA, PROPAGATION, AND EMC TECHNOLOGIES (MAPE), P44, DOI 10.1109/MAPE.2017.8250792
   Pang S, IEEE T MULTIMED, P1
   Philbin J, 2008, PROC CVPR IEEE, P2285
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Ran LY, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102421
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Razavian AS, 2014, COMPUTER SCI
   Ren S., 2017, IEEETransactionsonPatternAnalysisandMachineIntelligence, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Scott BL, 2018, J ACOUST SOC AM, V109, P864
   Serikawa S, 2014, UNDERWATER IMAGE DEH
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Tolias G, 2015, COMPUTER SCI
   Tollari S, 2009, LECT NOTES COMPUT SC, V5478, P701, DOI 10.1007/978-3-642-00958-7_70
   Tuan Hoang, 2017, arXiv
   Wang J, 2018, ADAPTIVE COWEIGHTING
   Wang L, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030769
   Wang X, 2018, INT S ART INT ROB NA
   Xiu-Shen Wei, 2016, arXiv
   Xu J, 2017, UNSUPERVISED PART BA
   Xu XD, 2019, INT J CONTROL, V92, P778, DOI 10.1080/00207179.2017.1369575
   Xu X, 2016, NEUROCOMPUTING, V213, P191, DOI 10.1016/j.neucom.2015.11.133
   Xu XW, 2018, EUROPLOP 2018: PROCEEDINGS OF THE 23RD EUROPEAN CONFERENCE ON PATTERN LANGUAGES OF PROGRAMS, DOI [10.3897/phytokeys.96.23142, 10.1145/3282308.3282312]
   Yandex Artem Babenko, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1269, DOI 10.1109/ICCV.2015.150
   Yang JG, 2019, IEEE GEOSCI REMOTE S, V16, P727, DOI 10.1109/LGRS.2018.2879909
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang XP, 2016, PROC CVPR IEEE, P1134, DOI 10.1109/CVPR.2016.128
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, P1713, DOI 10.1109/TIP.2016.2531289
NR 57
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14465
EP 14489
DI 10.1007/s11042-018-6915-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900009
DA 2024-07-18
ER

PT J
AU Zhou, Q
   Cheng, J
   Lu, HM
   Fan, YW
   Zhang, SF
   Wu, XF
   Zheng, BT
   Ou, WH
   Latecki, LJ
AF Zhou, Quan
   Cheng, Jie
   Lu, Huimin
   Fan, Yawen
   Zhang, Suofei
   Wu, Xiaofu
   Zheng, Baoyu
   Ou, Weihua
   Latecki, Longin Jan
TI Learning adaptive contrast combinations for visual saliency detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Contrast combinations; Visual attention; Multiple
   kernel learning
ID OBJECT DETECTION; REGION DETECTION; IMAGE; ATTENTION; FEATURES; MODEL;
   SCALE; COLOR
AB Visual saliency detection plays a significant role in the fields of computer vision. In this paper, we introduce a novel saliency detection method based on weighted linear multiple kernel learning (WLMKL) framework, which is able to adaptively combine different contrast measurements in a supervised manner. As most influential factor is contrast operation in bottom-up visual saliency, an average weighted corner-surround contrast (AWCSC) is first designed to measure local visual saliency. Combined with common-used center-surrounding contrast (CESC) and global contrast (GC), three types of contrast operations are fed into our WLMKL framework to produce the final saliency map. We show that the assigned weights for each contrast feature maps are always normalized in our WLMKL formulation. In addition, the proposed approach benefits from the advantages of the contribution of each individual contrast feature maps, yielding more robust and accurate saliency maps. We evaluated our method for two main visual saliency detection tasks: human fixed eye prediction and salient object detection. The extensive experimental results show the effectiveness of the proposed model, and demonstrate the integration is superior than individual subcomponent.
C1 [Zhou, Quan; Fan, Yawen; Wu, Xiaofu; Zheng, Baoyu] Nanjing Univ Posts & Telecommun, Natl Engn Res Ctr Commun & Networking, Nanjing, Peoples R China.
   [Zhou, Quan] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
   [Cheng, Jie] Huawei Technol Co Ltd, Shenzhen, Peoples R China.
   [Lu, Huimin] Kyushu Inst Technol, Dept Mech & Control Engn, Kitakyushu, Fukuoka, Japan.
   [Zhang, Suofei] Nanjing Univ Posts & Telecommun, Sch Internet Things, Nanjing, Peoples R China.
   [Ou, Weihua] Guizhou Normal Univ, Sch Big Data & Comp Sci, Guiyang, Peoples R China.
   [Latecki, Longin Jan] Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA.
C3 Nanjing University of Posts & Telecommunications; Nanjing University;
   Huawei Technologies; Kyushu Institute of Technology; Nanjing University
   of Posts & Telecommunications; Guizhou Normal University; Pennsylvania
   Commonwealth System of Higher Education (PCSHE); Temple University
RP Zhou, Q (corresponding author), Nanjing Univ Posts & Telecommun, Natl Engn Res Ctr Commun & Networking, Nanjing, Peoples R China.; Zhou, Q (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.; Zhang, SF (corresponding author), Nanjing Univ Posts & Telecommun, Sch Internet Things, Nanjing, Peoples R China.
EM quan.zhou@njupt.edu.cn; jiecheng2009@gmail.com; luhuimin@ieee.org;
   ywfan@njupt.edu.cn; zhangsuofei@njupt.edu.cn; xfuwu@njupt.edu.cn;
   zby@njupt.edu.cn; ouweihuahust@gmail.com; latecki@temple.edu
RI Ou, Weihua/AAD-9887-2020
OI Latecki, Longin Jan/0000-0002-5102-8244
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   [Anonymous], 2011, MACH LEARN RES
   [Anonymous], 2008, NIPS
   [Anonymous], 2010, J VIS
   [Anonymous], 2004, KERNEL METHODS PATTE
   Bach Francis R, 2004, P 21 INT C MACH LEAR, P6, DOI 10.1145/1015330.1015424
   BONNANS F, 2006, OPTIMISATION CONTINU
   Borji A., 2012, CVPR, DOI DOI 10.1109/CVPR.2012.6247706
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Bucak SS, 2014, IEEE T PATTERN ANAL, V36, P1354, DOI 10.1109/TPAMI.2013.212
   Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333
   Cornia M, 2016, INT C PATT RECOG, P3488, DOI 10.1109/ICPR.2016.7900174
   Duan L, 2011, VISUAL SALIENCY DETE
   Fernández-Carbajales V, 2016, PATTERN RECOGN, V60, P571, DOI 10.1016/j.patcog.2016.06.007
   Fu P, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 2, P1
   Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27
   Gao D, 2008, J VISION, V8, DOI 10.1167/8.7.13
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gopalakrishnan V, 2009, IEEE T MULTIMEDIA, V11, P892, DOI 10.1109/TMM.2009.2021726
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Jetley S, 2016, PROC CVPR IEEE, P5753, DOI 10.1109/CVPR.2016.620
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Jing PG, 2018, CSVT, DOI [10.1109/TCSVT.2018.2832095, DOI 10.1109/TCSVT.2018.2832095]
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620
   Kruthiventi SSS, 2016, PROC CVPR IEEE, P5781, DOI 10.1109/CVPR.2016.623
   Kummerer M, 2015, ICLRW, P262
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu NA, 2018, IEEE T NEUR NET LEAR, V29, P392, DOI 10.1109/TNNLS.2016.2628878
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Lu HC, 2017, IEEE T IMAGE PROCESS, V26, P414, DOI 10.1109/TIP.2016.2627804
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Ma Q, 2008, INT C PATT RECOG, P2783
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Nilufar S, 2012, IEEE T IMAGE PROCESS, V21, P3744, DOI 10.1109/TIP.2012.2192130
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Quan Z, 2018, ROSENET
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193
   Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531
   Tatler BW, 2015, VISION RES, V45, P643
   Thiagarajan JJ, 2014, IEEE T IMAGE PROCESS, V23, P2905, DOI 10.1109/TIP.2014.2322938
   Tian HW, 2014, IEEE T IMAGE PROCESS, V23, P4389, DOI 10.1109/TIP.2014.2350914
   Torralba A, 2003, J OPT SOC AM A, V20, P1407, DOI 10.1364/JOSAA.20.001407
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Varma M, 2007, IEEE I CONF COMP VIS, P369
   Vladimir V, 1993, NATURE STAT LEARNING
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang Wenguan, 2018, IEEE Trans Image Process, V27, P38, DOI 10.1109/TIP.2017.2754941
   Xu Z., 2010, P 27 INT C MACHINE L, P1175
   Yu JG, 2016, IEEE T MULTIMEDIA, V18, P273, DOI 10.1109/TMM.2015.2505908
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhou Q, 2014, ACCV, P221
   Zhou Q, 2013, IEEE IMAGE PROC, P2665, DOI 10.1109/ICIP.2013.6738549
NR 72
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14419
EP 14447
DI 10.1007/s11042-018-6770-2
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900007
DA 2024-07-18
ER

PT J
AU Sakthisaravanan, B
   Meenakshi, R
AF Sakthisaravanan, B.
   Meenakshi, R.
TI OPBS-SSHC: outline preservation based segmentation and search based
   hybrid classification techniques for liver tumor detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE GLOBOCAN12; Frequency based edge sharpening technique; Outline
   Preservation Based Segmentation (OPBS) algorithm; Novel similarity
   search based hybrid classification distance; Support Vector Machine
   (SVM); Probabilistic neural network (PNN); Relevance Vector Machine
   (RVM)
ID CT
AB Cancer in Liver is the one among all other types of cancer which causes death of carcinogenic victim people throughout the world. GLOBOCAN12 was an initiative for simultaneously generating the expected dominance and mortality incidence that raised out of the cancer over the whole globe. It reported that about 782,000 new cases in the population were reported to have liver cancer, in which around 745,000 people loosed their lives from these kind of diseases worldwide. Some traditional algorithms were found to be widely used in liver segmentation processes. However, it had some limitations such as less effective outcomes in terms of proceeded segmentation operations and also it was very difficult to apply tumor segmentation especially for larger severity intensities of tumor region, which usually gave rise to high computational cost. It was also required to improve the performance of those algorithms for diagnosing even the tiniest parts of liver along with the improvisation needed when there was misclassification of the tumors near the liver boundaries. Along this way as an improvising methodology, an efficient method is proposed in order to overcome all the above discussed issues one by one through our work. The novelty/major contribution of this proposed method is being contributed in three stages namely, preprocessing, segmentation and classification. In preprocessing, the noises of image will be removed and then, the input image edge will be sharpened by using a frequency-based edge sharpening technique which aids in taking the pixels in the images into consideration for proceeding with the next operation of segmentation. The segmentation process gets the appropriated preprocessed images as input and the Outline Preservation Based Segmentation (OPBS) algorithm is used to segment the images in the segmentation phase. The algorithms involving features extraction were preferably deployed to extract the corresponding features from an image. So, the features present in the segmented image serves as the necessary information for the classification purposes. Next, the features were classified in the classification phase by using novel similarity search based hybrid classification technique. The Outline Preservation Based Segmentation and Search Based Hybrid Classification (OPBS-SSHC) used the 3D IR CAD dataset. It was used to analyze with various parameters such as accuracy, precision, recall, and F-measures. Volumetric Overlap Error (VOE), Jaccard, Dice, and Kappa will be determined later on to predict the errors in the segmentation process undertaken. The proposed method of OPBS-SSHC performance was found to be better than other classification techniques of Relevance Vector Machine (RVM), Probabilistic Neural Network (PNN), and Support Vector Machine (SVM), which were considered for comparison by taking the above metrics and coefficients as and when required throughout this extensive comparative study.
C1 [Sakthisaravanan, B.] Saveetha Univ, Dept Comp Sci & Engn, Chennai 602105, Tamil Nadu, India.
   [Meenakshi, R.] Anna Univ, Chennai, Tamil Nadu, India.
C3 Saveetha Institute of Medical & Technical Science; Anna University; Anna
   University Chennai
RP Sakthisaravanan, B (corresponding author), Saveetha Univ, Dept Comp Sci & Engn, Chennai 602105, Tamil Nadu, India.
EM sakthisaravananphd@oudook.com
CR AlZu'bi S., 2018, MULTIMED TOOLS APPL, P1, DOI DOI 10.1007/S11042-020-08676-1
   Baazaoui A, 2017, IRBM, V38, P98, DOI 10.1016/j.irbm.2017.02.003
   Christ P.F., 2017, Automatic liver and tumor segmentation of ct and mri volumes using cascaded fully convolutional neural networks
   Cui H, 2020, IEEE T IMAGE PROCESS, V29, P1271, DOI 10.1109/TIP.2019.2940693
   Dakua SP, 2016, J VIS COMMUN IMAGE R, V34, P89, DOI 10.1016/j.jvcir.2015.10.016
   El-Sayed M. A., 2016, J. Signal Inf. Process, V7, P49, DOI [10.4236/jsip.2016.71007, DOI 10.4236/JSIP.2016.71007]
   Hoogi A, 2017, MED IMAGE ANAL, V37, P46, DOI 10.1016/j.media.2017.01.002
   Kumar SS, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICCICCT), P763, DOI 10.1109/ICCICCT.2014.6993061
   Lazaridis M, 2013, SIGNAL PROCESS-IMAGE, V28, P351, DOI 10.1016/j.image.2012.04.001
   Li GD, 2015, IEEE T IMAGE PROCESS, V24, P5315, DOI 10.1109/TIP.2015.2481326
   Li H, 2013, APPL MECH MATER, V291-294, P2412, DOI 10.4028/www.scientific.net/AMM.291-294.2412
   Liao M, 2017, COMPUT METH PROG BIO, V143, P1, DOI 10.1016/j.cmpb.2017.02.015
   Liao M, 2016, PHYS MEDICA, V32, P1383, DOI 10.1016/j.ejmp.2016.10.002
   Lu XQ, 2014, OPTIK, V125, P2142, DOI 10.1016/j.ijleo.2013.10.049
   Sayed GI, 2015, 2015 11TH INTERNATIONAL COMPUTER ENGINEERING CONFERENCE (ICENCO), P144, DOI 10.1109/ICENCO.2015.7416339
   Schueller F, 2018, INT J MOL SCI, V19, DOI 10.3390/ijms19010261
   Selver MA, 2014, STUD HEALTH TECHNOL, V205, P1133, DOI 10.3233/978-1-61499-432-9-1133
   Sun C., 2017, Artificial Intelligence in Medicine
   Wu W, 2017, BIOMED RES INT, V2017, P1
   Xie L, 2017, DYNAMIC MULTI VIEW H
   Xie L, 2016, 13 AAAI C ART INT
   Xie L, 2018, LECT NOTES COMPUT SC, V11164, P808, DOI 10.1007/978-3-030-00776-8_74
   Xu Y, 2016, MED PHYS, V43, DOI 10.1118/1.4945021
   Yang X, 2014, COMPUT METH PROG BIO, V113, P69, DOI 10.1016/j.cmpb.2013.08.019
   Yu SP, 2018, RNA BIOL, V15, P1215, DOI 10.1080/15476286.2018.1521210
   Zareei A, 2016, COMPUT BIOL MED, V75, P139, DOI 10.1016/j.compbiomed.2016.05.009
   Zeng YZ, 2017, COMPUT METH PROG BIO, V150, P31, DOI 10.1016/j.cmpb.2017.07.002
   Zhu L, 2017, IEEE T CYBERNETICS, V47, P3941, DOI 10.1109/TCYB.2016.2591068
   Zhuo Li, 2010, Journal of Multimedia, V5, P200, DOI 10.4304/jmm.5.3.200-207
NR 29
TC 34
Z9 34
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22497
EP 22523
DI 10.1007/s11042-019-08582-1
EA MAY 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000535434200002
DA 2024-07-18
ER

PT J
AU Bu, XX
   Zhu, JH
   Qian, XM
AF Bu, Xuxiao
   Zhu, Jihua
   Qian, Xueming
TI Personalized product search based on user transaction history and
   hypergraph learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personalized product search; Hypergraph; Transaction history
AB As the e-commerce shopping websites like Amazon become more and more popular, amounts of products spring up on the internet and bring great difficulties to product search. However, the conventional text-based search is confined to retrieving products relevant to query and personalized product search is still a challenging problem in e-commerce. Consequently, in this paper, we propose a personalized product search approach, which combines personalized multimedia recommendation into searching. First, we construct a hypergraph based on products' descriptions and user's transaction history. Then the similarity between products and the user is calculated based on two kind of textural feature extraction methods. After that, iterative procedure is introduced to obtain the final relevance score of each product to the user. Experimental results on our collected Amazon dataset show the effectiveness of the proposed approach. The MAP@5 of our method can reach 0.48 and the MAP@10 can reach 0.44. We propose a new re-ranking method for personalized product search, in which we utilize user's transaction history to choose products which is closer to the user's preference into the higher positions. Experimental results on our collected dataset show that our method is much better than the comparison methods.
C1 [Bu, Xuxiao; Zhu, Jihua] Xi An Jiao Tong Univ, Sch Software Engn, Xian, Peoples R China.
   [Qian, Xueming] Xi An Jiao Tong Univ, Sch Informat & Commun Engn, Key Lab Intelligent Networks & Network Secur, Minist Educ,SMILES LAB, Xian, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University
RP Qian, XM (corresponding author), Xi An Jiao Tong Univ, Sch Informat & Commun Engn, Key Lab Intelligent Networks & Network Secur, Minist Educ,SMILES LAB, Xian, Peoples R China.
EM bo951024@stu.xjtu.edu.cn; jhzhu@mail.xjtu.edu.cn;
   qianxm@mail.xjtu.edu.cn
FU NSFC [61772407, 61732008]; National Key R&D Program of China
   [2016A010101005]; WorldClass Universities (Disciplines) and the
   Characteristic Development Guidance Funds for the Central Universities
   [PY3A022]
FX This work was supported in part by the NSFC under Grant 61772407, Grant
   61732008; in part by the National Key R&D Program of China under Grant
   2016A010101005; and in part by the WorldClass Universities (Disciplines)
   and the Characteristic Development Guidance Funds for the Central
   Universities (PY3A022).
CR Ai QY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P645, DOI 10.1145/3077136.3080813
   [Anonymous], 2017, P 30 INT FLOR ART IN
   [Anonymous], NEUROCOMPUTING
   Bennett PN, 2015, ACM T INFORM SYST, V33, DOI 10.1145/2691351
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Duan LX, 2011, IEEE T IMAGE PROCESS, V20, P3280, DOI 10.1109/TIP.2011.2159227
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gray Chester, 2015, 2015 Systems and Information Engineering Design Symposium. proceedings, P91, DOI 10.1109/SIEDS.2015.7117018
   Gupta M, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2087, DOI 10.1145/3132847.3133061
   Hamano S, 2017, IEEE IMAGE PROC, P1327, DOI 10.1109/ICIP.2017.8296497
   Jeh Glen, 2003, P 12 INT C WORLD WID, P271, DOI DOI 10.1145/775152.775191
   Jiang DX, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508038
   Jiang S, 2018, IEEE T MULTIMEDIA, V17, P907
   Khan MA, 2019, EXPERT SYST APPL, V134, P138, DOI 10.1016/j.eswa.2019.05.040
   Liu D, 2009, INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL : ICACC 2009 - PROCEEDINGS, P351, DOI 10.1109/ICACC.2009.21
   Liu QS, 2017, IEEE T IMAGE PROCESS, V26, P452, DOI 10.1109/TIP.2016.2621671
   Long B, 2012, ENHANCING PRODUCT SE, P2479
   Lu D, 2016, IEEE T MULTIMEDIA, V18, P1628, DOI 10.1109/TMM.2016.2568099
   Lu XQ, 2017, IEEE T IMAGE PROCESS, V26, P355, DOI 10.1109/TIP.2016.2627801
   Manotumruksa J, 2017, PERSONALIZED RANKING
   Mei T., 2020, IEEE T CIRCUITS SYST
   Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943
   Pliakos K, 2014, IEEE INT WORKSH MULT
   Pliakos K, 2014, 2014 6TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING (ISCCSP), P306, DOI 10.1109/ISCCSP.2014.6877875
   Qian X, 2018, IEEE T IMAGE PROCESS, V25, P195, DOI [10.1109/TIP.2015.2497145, DOI 10.1109/TIP.2015.2497145]
   Qian XM, 2017, P IEEE, V105, P1937, DOI 10.1109/JPROC.2017.2731600
   Qian XM, 2017, IEEE T IMAGE PROCESS, V26, P3734, DOI 10.1109/TIP.2017.2699623
   Qian XM, 2014, IEEE T CYBERNETICS, V44, P2493, DOI 10.1109/TCYB.2014.2309593
   Qian XM, 2014, IEEE T KNOWL DATA EN, V26, P1763, DOI 10.1109/TKDE.2013.168
   Shi XX, 2019, KNOWL-BASED SYST, V186, DOI 10.1016/j.knosys.2019.104955
   Shuhui Jiang, 2016, IEEE Transactions on Big Data, V2, P43, DOI 10.1109/TBDATA.2016.2541160
   Wang C., 2010, P 18 ACM INT C MULT, P391, DOI [10.1145/ 1873951.1874005, DOI 10.1145/1873951.1874005]
   Wang L, 2020, IEEE T CIRCUITS SYST
   Wang L, 2021, IEEE T CYBERNETICS, V51, P5522, DOI 10.1109/TCYB.2020.3022852
   Wang LQ, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P330, DOI 10.1109/VCIP.2014.7051573
   Wang YX, 2018, IEEE T IMAGE PROCESS, V27, P4437, DOI 10.1109/TIP.2018.2837219
   Wu C, 2017, ENSEMBLE METHODS PER
   Yu S, 2017, COLOR IMAGE RETRIEVA
   Zhang YT, 2016, IEEE T MULTIMEDIA, V18, P1604, DOI 10.1109/TMM.2016.2568138
   Zhao G, 2020, IEEE T KNOWL DATA EN
   Zhao GS, 2019, IEEE T MULTIMEDIA, V21, P771, DOI 10.1109/TMM.2018.2863598
   Zhou D, 2006, Learning with hypergraphs: clustering, classification, and embedding
   Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389
NR 44
TC 7
Z9 8
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22157
EP 22175
DI 10.1007/s11042-020-08963-x
EA MAY 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000533180200001
DA 2024-07-18
ER

PT J
AU Wu, Q
   Fan, CX
   Li, Y
   Lie, Y
   Hu, JH
AF Wu, Qiong
   Fan, Chunxiao
   Li, Yong
   Lie, Yang
   Hu, Jiahao
TI A novel perceptual loss function for single image super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image super-resolution; Deep neural network; Perceptual loss function
ID NETWORK
AB In recent years, various deep neural networks have been proposed to improve the performance in the single image super-resolution (SISR) task. The commonly used per-pixel MSE loss function captures less perceptual difference and tends to make the super-resolved images overly smooth, while the perceptual loss function defined on image features extracted from one or two layers of a pretrained network yields more visually pleasing results. We propose a new perceptual loss function via combining features from multiple levels, which incorporates the discrepancy between the reconstruction and the ground truth in different structures. In addition, some variants of the proposed perceptual loss are explored. Extensive quantitative and qualitative comparisons with the state-of-the-art methods demonstrate that our loss function can drive the same network to produce better results when used alone or combined with other loss functions.
C1 [Wu, Qiong; Fan, Chunxiao; Li, Yong; Hu, Jiahao] Beijing Univ Posts & Telecommun, Sch Elect Engn, Beijing 100876, Peoples R China.
   [Lie, Yang] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Tsinghua University
RP Fan, CX (corresponding author), Beijing Univ Posts & Telecommun, Sch Elect Engn, Beijing 100876, Peoples R China.
EM qiongwu@buptedu.cn; cxfan@bupt.edu.cn; yli@bupt.edu.cn;
   mingyang@Tsinghua.edu.cn; hjhao@bupt.edu.cn
FU National Natural Science Foundation of China [NSFC-61471067, 81671651];
   National Great Science Specific Project [2015ZX03002008]; Beijing
   Municipal Natural Science Foundation [1472024]; Beijing University of
   Posts and Telecommunications [2013XD-04, 2015XD-02]; Beijing Key
   Laboratory of Work Safety and Intelligent Monitoring Foundation
FX Thanks to the National Natural Science Foundation of China (No.
   NSFC-61471067, 81671651), the National Great Science Specific Project
   (No. 2015ZX03002008), the Beijing Municipal Natural Science Foundation
   (No. 1472024), Beijing University of Posts and Telecommunications (No.
   2013XD-04, 2015XD-02), the Beijing Key Laboratory of Work Safety and
   Intelligent Monitoring Foundation.
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   BLAU Y, 2018, PIRM CHALLENGE PERCE
   Blau Y, 2018, PROC CVPR IEEE, P6228, DOI 10.1109/CVPR.2018.00652
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   BRUNA J, 2016, INT C LEARAN REPR IC
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Greenspan H, 2009, COMPUT J, V52, P43, DOI 10.1093/comjnl/bxm075
   Hochstein S, 2002, NEURON, V36, P791, DOI 10.1016/S0896-6273(02)01091-7
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Mahendran A, 2016, INT J COMPUT VISION, V120, P233, DOI 10.1007/s11263-016-0911-8
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Park SJ, 2018, LECT NOTES COMPUT SC, V11220, P455, DOI 10.1007/978-3-030-01270-0_27
   Sajjadi Mehdi S. M., 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P4501, DOI 10.1109/ICCV.2017.481
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan WM, 2018, PROC CVPR IEEE, P3994, DOI 10.1109/CVPR.2018.00420
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang CY, 2014, LECT NOTES COMPUT SC, V8692, P372, DOI 10.1007/978-3-319-10593-2_25
   Yosinski J., 2015, ARXIV150606579, V2015, P12
   Zeyde Roman., 2010, On single image scale‐up using sparse‐representations. In: International Conference on Curves and Surfaces, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang LP, 2010, SIGNAL PROCESS, V90, P848, DOI 10.1016/j.sigpro.2009.09.002
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
NR 33
TC 5
Z9 6
U1 3
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21265
EP 21278
DI 10.1007/s11042-020-08878-7
EA MAY 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000529768200001
DA 2024-07-18
ER

PT J
AU Iñiguez-Jarrín, C
   Panach, JI
   López, OP
AF Iniguez-Jarrin, Carlos
   Ignacio Panach, Jose
   Pastor Lopez, Oscar
TI Improvement of usability in user interfaces for massive data analysis:
   an empirical study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User interface; Big data; Usability; Interaction design patterns
ID PATTERNS
AB Big Data challenges the conventional way of analyzing massive data and creates the need to improve the usability of existing user interfaces (UIs) in order to deal with massive amounts of data. How the UIs facilitate the search for information and helps in the end-user's decision-making depends on developers and designers, who have no guides for producing usable UIs. We have proposed a set of interaction patterns for designing massive data analysis UIs by studying 27 real case studies of massive data analysis. We evaluate if the proposed patterns improve the usability of the massive data analysis UIs in the context of literature search. We conducted two replications of the same controlled experiment, one with 24 undergraduate students experienced in scientific literature search and the other with eight researchers who are experienced in biomedical literature search. The experiment, which was planned as a repeated measures design, compares UIs that have been enhanced with the proposed patterns versus original UIs in terms of three response variables: effectiveness, efficiency, and satisfaction. The outcomes show that the use of interaction patterns in UIs for massive data analysis yields better and more significant effects for the three response variables, enhancing the discovery and visualization of the data. The use of the proposed interaction design patterns improves the usability of the UIs that deal with massive data. The patterns can be considered as guides for helping designers and developers to design usable UIs for massive data analysis web applications.
C1 [Iniguez-Jarrin, Carlos; Pastor Lopez, Oscar] Univ Politecn Valencia, Res Ctr Software Prod Methods PROS, Camino Vera S-N, Valencia 46022, Spain.
   [Iniguez-Jarrin, Carlos] Escuela Politec Nacl, Dept Informat & Ciencias Computac, E11-253, Quito, Ecuador.
   [Ignacio Panach, Jose] Univ Valencia, Dept Informat, Escola Tecn Super Engn, Ave Univ S-N, Valencia 46100, Spain.
C3 Universitat Politecnica de Valencia; Escuela Politecnica Nacional
   Ecuador; University of Valencia
RP Iñiguez-Jarrín, C (corresponding author), Univ Politecn Valencia, Res Ctr Software Prod Methods PROS, Camino Vera S-N, Valencia 46022, Spain.; Iñiguez-Jarrín, C (corresponding author), Escuela Politec Nacl, Dept Informat & Ciencias Computac, E11-253, Quito, Ecuador.
EM ciniguez@pros.upv.es; joigpana@uv.es; opastor@pros.upv.es
RI Panach, Jose Ignacio/ABF-2099-2020
OI Panach, Jose Ignacio/0000-0002-7043-6227; Iniguez,
   Carlos/0000-0003-1338-7542
CR [Anonymous], 2010, DESIGNING INTERFACES
   Arthur, 2017, MODERATOR VARIABLES
   Borchers J., 2001, PATTERN APPROACH INT
   Borchers J.O., 2000, INTERACTION DESIGN P
   Borchers J, 2009, COMPUT SUPP COOP WOR, P261, DOI 10.1007/978-1-84800-098-8_10
   Cohen J., 1988, STAT POWER ANAL BEHA
   Cremonesi P, 2015, P 11 BIANN C IT SIGC, P66, DOI [10.1145/2808435.2808442., DOI 10.1145/2808435.2808442]
   Cremonesi P, 2017, MULTIMED TOOLS APPL, V76, P5275, DOI 10.1007/s11042-016-3946-5
   Datamer e-book, 2016, TOP 5 HIGH IMP US CA
   DigitalScience, 2018, DIMENSIONS
   Douglas SM, 2005, GENOME BIOL, V6, DOI 10.1186/gb-2005-6-9-r80
   Elliott A.C., 2006, STAT ANAL QUICK REFE
   Ellis PD, 2010, ESSENTIAL GUIDE TO EFFECT SIZES: STATISTICAL POWER, META-ANALYSIS AND THE INTERPRETATION OF RESEARCH RESULTS, P1
   Fiorini N, 2018, DATABASE-OXFORD, DOI 10.1093/database/bay094
   Folmer E, 2006, FUTUR PLAY, V6
   Genomenon, 2018, MAST COMPR GEN SEARC
   Good Benjamin M, 2012, J Biomed Semantics, V3 Suppl 1, pS6, DOI 10.1186/2041-1480-3-S1-S6
   Graham I., 2003, A pattern language for web usability, V1st
   Guerra Eduardo M., 2010, Proceedings of the 8th Latin American Conference on Pattern Languages of Programs, SugarLoafPLoP 2010, Salvador, Bahia, Brazil, September 23-27, 2010, p18:1, DOI [DOI 10.1145/2581507.2581525, https://doi.org/10.1145/2581507.2581525]
   Hautojrvi P., 1979, Experimentation in software engineering, V1ST, DOI [10.1007/978-3-642-81316-0, 10.1007/978-3-642-29044-2., DOI 10.1007/978-3-642-29044-2]
   IBM, 2015, IBM BIG DAT US CAS W
   Iñiguez-Jarrín C, 2018, LECT NOTES COMPUT SC, V10816, P490, DOI 10.1007/978-3-319-91563-0_30
   Kuehl RO., 2001, DISENO EXPT PRINCIPI
   Lafreniere D, 2001, PATTERN SUPPORTED AP
   Laskowski N, 2015, 10 BIG DATA CASE STU, pSearchCIOcom
   LEWIS JR, 1995, INT J HUM-COMPUT INT, V7, P57, DOI 10.1080/10447319509526110
   Lu ZY, 2011, DATABASE-OXFORD, DOI 10.1093/database/baq036
   Marill JL, 2006, J MED LIBR ASSOC, V94, P30
   Martin-Rodilla P, 2014, APPL CONTEXT CULTURA
   Nilsson EG, 2009, ADV ENG SOFTW, V40, P1318, DOI 10.1016/j.advengsoft.2009.01.017
   Pentaho, 2015, BIG DAT US CAS PENT
   Pituch K.A. Stevens., 2015, APPL MULTIVARIATE ST, V6th, DOI DOI 10.4324/9781315814919
   Riley RD, 2010, BMJ-BRIT MED J, V340, DOI 10.1136/bmj.c221
   Schmettow M, 2006, EUROPLOP 2006, P489
   Scott B., 2009, Designing web interfaces: principles and patterns for rich interactions
   Seffah A, 2012, INNOV SYST SOFTW ENG, V8, P93, DOI 10.1007/s11334-011-0178-8
   Seidel N, 2017, PROCEEDINGS OF THE 22ND EUROPEAN CONFERENCE ON PATTERN LANGUAGES OF PROGRAMS (EUROPLOP 2017), DOI 10.1145/3147704.3147719
   Seltman H.J., 2012, Experimental Design and Analysis
   Tanger P, 2013, FRONT PLANT SCI, V4, DOI 10.3389/fpls.2013.00218
   Templeton GF, 2011, COMMUN ASS INF, V28
   The Hillside Group, 1994, HOLD WRIT WORKSH 199
   Thimthong T., 2012, 2012 IEEE Symposium on Humanities, Science and Engineering Research (SHUSER), P1165, DOI 10.1109/SHUSER.2012.6268796
   Tidwell J., 1999, Common ground: A pattern language for human--‐computer interface design
   Toxboe A, 2018, USER INTERFACE DESIG
   Van Duyne D.K., 2003, DESIGN SITES PATTERN
   Van Solingen R., 2002, ENCY SOFTW ENG
   van Welie Martijn., 2008, Patterns in interaction design
   Vegas S, 2016, IEEE T SOFTWARE ENG, V42, P120, DOI 10.1109/TSE.2015.2467378
   VOSviewer, 2015, VIS SCI LANDSC
   Wu CL, 2016, NUCLEIC ACIDS RES, V44, pD313, DOI 10.1093/nar/gkv1104
NR 50
TC 0
Z9 0
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12257
EP 12288
DI 10.1007/s11042-019-08456-6
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400044
OA Green Published
DA 2024-07-18
ER

PT J
AU She, QS
   Mu, GY
   Gan, HT
   Fan, YL
AF She, Qingshan
   Mu, Gaoyuan
   Gan, Haitao
   Fan, Yingle
TI Spatio-temporal SRU with global context-aware attention for 3D human
   action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D action recognition; Recurrent neural networks; Simple recurrent unit;
   Spatio-temporal analysis; Attention mechanism
AB 3D action recognition has attracted much attention in machine learning fields in recent years, and recurrent neural networks (RNNs) have been widely used for 3D action recognition due to their efficiency in processing sequential data. However, in order to achieve good performance, traditional RNN architectures are usually time-consuming for the training and inference process. To address the problem, a global context-aware attention spatio-temporal SRU (GCA-ST-SRU) method is proposed and applied for 3D action recognition in this paper, through extending the original simple recurrent unit (SRU) algorithm to joint spatio-temporal domain with an attention mechanism. First, deep neural networks were employed to learn the features of skeleton joints at each frame, and then these new high-level feature sequences were classified using the GCA-ST-SRU method which can learn the spatio-temporal dependence between different joints in the same frame and pay more attention to informative joints. Extensive experiments were conducted on the UT-Kinect and SBU-Kinect Interaction datasets to evaluate the effectiveness of the proposed method. Compared with several existing algorithms including SRU, long short-term memory (LSTM), spatio-temporal LSTM (ST-LSTM) and global context-aware attention LSTM (GCA-LSTM), our method has exhibited better performance in classification accuracy and computational efficiency. The experimental results demonstrate the effectiveness and practicability of our algorithm. Compared to the methods with similar performance, our algorithms can reduce training time and improve the inference speed, and thus it achieves a balance between speed and accuracy.
C1 [She, Qingshan; Mu, Gaoyuan; Gan, Haitao; Fan, Yingle] Hangzhou Dianzi Univ, Sch Automat, Hangzhou 310018, Zhejiang, Peoples R China.
   [She, Qingshan; Mu, Gaoyuan; Gan, Haitao; Fan, Yingle] Hangzhou Dianzi Univ, Inst Intelligent Control & Robot, Hangzhou 310018, Zhejiang, Peoples R China.
C3 Hangzhou Dianzi University; Hangzhou Dianzi University
RP She, QS (corresponding author), Hangzhou Dianzi Univ, Sch Automat, Hangzhou 310018, Zhejiang, Peoples R China.; She, QS (corresponding author), Hangzhou Dianzi Univ, Inst Intelligent Control & Robot, Hangzhou 310018, Zhejiang, Peoples R China.
EM qsshe@hdu.edu.cn; 1171791288@qq.com; htgan@hdu.edu.cn; fan@hdu.edu.cn
RI gan, jerry/AFT-1901-2022; gan, haitao/JFA-9149-2023
OI She, Qingshan/0000-0001-5206-9833
CR [Anonymous], ARXIV180504185
   [Anonymous], 2016, P 29 INT C COMP AN S
   [Anonymous], ARXIV171108238
   Baradel F, 2017, IEEE INT CONF COMP V, P604, DOI 10.1109/ICCVW.2017.77
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Chen C, 2016, J REAL-TIME IMAGE PR, V12, P155, DOI 10.1007/s11554-013-0370-1
   Cho K., 2014, ARXIV14061078
   De Mulder W, 2015, COMPUT SPEECH LANG, V30, P61, DOI 10.1016/j.csl.2014.09.005
   Gal Y, 2016, ADV NEUR IN, V29
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang HG, 2019, AAAI CONF ARTIF INTE, P6538
   King DB, 2015, ACS SYM SER, V1214, P1
   Kong Y., 2018, ARXIV180611230
   Koniusz P, 2016, LECT NOTES COMPUT SC, V9908, P37, DOI 10.1007/978-3-319-46493-0_3
   Lei T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4470
   Liu J, 2018, IEEE T IMAGE PROCESS, V27, P1586, DOI 10.1109/TIP.2017.2785279
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Park C, 2019, ETRI J, V41, P371, DOI 10.4218/etrij.2017-0279
   Park J, 2018, INT C ELECTR MACH SY, P2060, DOI 10.23919/ICEMS.2018.8549235
   Simonyan K, 2014, ADV NEUR IN, V27
   Slama R, 2015, PATTERN RECOGN, V48, P556, DOI 10.1016/j.patcog.2014.08.011
   Tamamori A, 2018, APSIPA TRANS SIGNAL, V7, DOI 10.1017/ATSIP.2018.25
   Tang YS, 2018, PROC CVPR IEEE, P5323, DOI 10.1109/CVPR.2018.00558
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang D, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P707
   Xi R, 2018, IEEE ACCESS, V6, P53381, DOI 10.1109/ACCESS.2018.2870841
   Yang ZK, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE 2018), P232, DOI 10.1109/ICISCE.2018.00056
   Yun K., 2012, 2012 IEEE COMP SOC C, P28, DOI DOI 10.1109/CVPRW.2012.6239234
   Zhang PF, 2018, LECT NOTES COMPUT SC, V11213, P136, DOI 10.1007/978-3-030-01240-3_9
   Zhang SY, 2017, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2017.24
   Zhang YP, 2012, IEEE VTS VEH TECHNOL
   Zhu W., 2016, 13 AAAI C ART INT
   Zhu Y, 2013, IEEE COMPUT SOC CONF, P486, DOI 10.1109/CVPRW.2013.78
NR 34
TC 3
Z9 5
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12349
EP 12371
DI 10.1007/s11042-019-08587-w
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400048
DA 2024-07-18
ER

PT J
AU Wang, XH
   Chen, HW
   Wu, LS
AF Wang, XiaoHui
   Chen, HuaWei
   Wu, LuShen
TI Feature extraction of point clouds based on region clustering
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Point clouds; Feature extraction; Region clustering
   segmentation; Local feature weight; Curvature
AB This paper proposes a feature extraction method for scattered point clouds. First, a clustering algorithm is used to divide point clouds into different regions that represent the original features. In each sub-region, we calculate the angles between the directed line segments from sampling points to the neighborhood points and set the angle threshold to identify edge feature points of uniform distribution. For the edge points of non-uniform distribution, we introduce the local neighborhood size as a discrete scale parameter for edge point detection, and then accurately identify and record the detected edge points. Then, according to the mean curvature of point clouds, the local feature weights of sampling points in the sub-region are calculated so that potential sharp feature points in a local area are detected. Finally, a minimum spanning tree of feature points is established to construct connected regions and generate feature point sets. A Bidirectional Principal Component Analysis (BD-PCA) search method is used to trim and break the small branches and multiline segments to generate feature curves. We carried out experiments on point cloud models with different densities to verify the effectiveness and superiority of our method. Results show that the edge features and sharp features are effectively extracted, and our method is not affected by the noise, neighborhood scale, or quality of sampling.
C1 [Wang, XiaoHui] Chifeng Univ, Sch Architectural & Mech Engn, Chifeng 024000, Peoples R China.
   [Wang, XiaoHui; Wu, LuShen] Nanchang Univ, Sch Mechatron Engn, Nanchang 330031, Jiangxi, Peoples R China.
   [Chen, HuaWei] Guizhou Normal Univ, Sch Mech & Elect Engn, Guiyang 550025, Peoples R China.
C3 Chifeng University; Nanchang University; Guizhou Normal University
RP Wang, XH (corresponding author), Chifeng Univ, Sch Architectural & Mech Engn, Chifeng 024000, Peoples R China.; Wang, XH (corresponding author), Nanchang Univ, Sch Mechatron Engn, Nanchang 330031, Jiangxi, Peoples R China.
EM babywxh@126.com; chwei0130@126.com; wulushen@163.com
RI Wang, Xiaohui/I-2314-2015
CR [Anonymous], 2001, P IMR 2001 NEWP BEAC
   Bazazian D, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 4, P317, DOI 10.5220/0006092503170325
   Buchanan M, 2007, PUBLISHERS WKLY, V11, P303
   Elkhrachy I, 2017, J INDIAN SOC REMOTE, V45, P1, DOI 10.1007/s12524-016-0569-2
   Fan JJ, 2020, MEASUREMENT, V149, DOI 10.1016/j.measurement.2019.107023
   Feng Q, 2013, LI ZI QUN SUAN FA JI
   Fu SY, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0227-x
   Hu JB, 2019, ACTA OPT SIN, V39, DOI 10.3788/AOS201939.0615002
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Li Q, 2018, MEAS SCI TECHNOL, V29, DOI 10.1088/1361-6501/aadff6
   [林洪彬 Lin Hongbin], 2017, [图学学报, Journal of Graphics], V38, P137
   Liu X., 2014, J. Comput. Inf. Syst, V10, P3503
   Liu Ying, 2017, Optics and Precision Engineering, V25, P245, DOI 10.3788/OPE.20172501.0245
   MIN K P, 2012, GRAPH MODELS, V74, P197, DOI DOI 10.1016/j.gmod.2012.04.008
   Ni H, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090710
   Nie Jianhui, 2015, Journal of Computer Aided Design & Computer Graphics, V27, P2332
   Pauly M, 2003, COMPUT GRAPH FORUM, V22, P281, DOI 10.1111/1467-8659.00675
   Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146
   Wang Y, 2013, COMPUT AIDED DESIGN, V45, P1333, DOI 10.1016/j.cad.2013.06.003
   Weber Christopher, 2010, Proceedings of the Shape Modeling International (SMI 2010), P175, DOI 10.1109/SMI.2010.32
   Xun JY, 2015, J COMPUT DES ENG, V2, P79, DOI 10.1016/j.jcde.2014.12.002
   Zhang Yuhe, 2017, Journal of Xidian University, V44, P114, DOI 10.3969/j.issn.1001-2400.2017.02.020
   Zhang YH, 2016, COMPUT GRAPH-UK, V56, P31, DOI 10.1016/j.cag.2016.01.004
NR 23
TC 20
Z9 21
U1 4
U2 74
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11861
EP 11889
DI 10.1007/s11042-019-08512-1
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400027
DA 2024-07-18
ER

PT J
AU Zhu, HH
   Tong, XJ
   Wang, Z
   Ma, J
AF Zhu, Honghong
   Tong, Xiaojun
   Wang, Zhu
   Ma, Jing
TI A novel method of dynamic S-box design based on combined chaotic map and
   fitness function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Combined chaotic system; Substitution box; Fitness function; Dynamic
   S-box
ID CONSTRUCTION; COMBINATION; EFFICIENT; ALGORITHM
AB This paper introduces a method of generating a strong S-box by using combined chaotic system and fitness function. Our method presents an algorithm which has two stages: static S-box generation and dynamic S-box optimization. Chaotic sequences generation, sequences discretization are involved in the first stage. Moreover, the proposed static S-box is converted into a dynamic S-box with the help of fitness function. The optimal S-box satisfies the following criteria: bijectivity, nonlinearity, strict avalanche criteria, output bits independence criterion, equiprobable inputs/outputs XOR distribution. Extensive experiments demonstrate that the proposed algorithm has excellent performance in cryptography and attacks resistance.
C1 [Zhu, Honghong; Tong, Xiaojun] Harbin Inst Technol, Sch Comp Sci & Technol, Weihai 264209, Peoples R China.
   [Wang, Zhu] Harbin Inst Technol, Sch Informat, Weihai 264209, Peoples R China.
   [Ma, Jing] Sci & Technol Informat Assurance Lab, Beijing, Peoples R China.
C3 Harbin Institute of Technology; Harbin Institute of Technology
RP Tong, XJ (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Weihai 264209, Peoples R China.
EM 510587891@qq.com; tong_xiaojun@163.com; wangzhu@hit.edu.cn;
   13863103050@139.com
CR Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   Chen G, 2008, CHAOS SOLITON FRACT, V36, P1028, DOI 10.1016/j.chaos.2006.08.003
   Chen X, 2017, SAUDI J BIOL SCI, V24, P1821, DOI 10.1016/j.sjbs.2017.11.023
   Daor J, 1998, JOAN DAEMEN VINCENT
   Farah T, 2017, NONLINEAR DYNAM, V88, P1059, DOI 10.1007/s11071-016-3295-y
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Jakimoski G, 2001, IEEE T CIRCUITS-I, V48, P163, DOI 10.1109/81.904880
   Khan M, 2018, NEURAL COMPUT APPL, V29, P993, DOI 10.1007/s00521-016-2511-5
   Khan M, 2015, NONLINEAR DYNAM, V82, P527, DOI 10.1007/s11071-015-2173-3
   Khan M, 2013, NONLINEAR DYNAM, V71, P489, DOI 10.1007/s11071-012-0675-9
   LEWIS PAW, 1969, IBM SYST J, V8, P136, DOI 10.1147/sj.82.0136
   Matsui M, 1993, LINEAR CRYPTANALYSIS, P386, DOI DOI 10.1007/3-540-48285-7
   Özkaynak F, 2017, SIGNAL IMAGE VIDEO P, V11, P659, DOI 10.1007/s11760-016-1007-1
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Tong X, 2012, INT S DISTR COMP APP
   Tong XJ, 2012, J SYST SOFTWARE, V85, P850, DOI 10.1016/j.jss.2011.10.051
   Ullah A, 2018, NONLINEAR DYNAM, V91, P359, DOI 10.1007/s11071-017-3874-6
   Ullah A, 2017, NONLINEAR DYNAM, V88, P2757, DOI 10.1007/s11071-017-3409-1
   Wang Y, 2012, PHYS LETT A, V376, P827, DOI 10.1016/j.physleta.2012.01.009
   Webster AF, 1986, DESIGN S BOXES
   Wu D, 2011, J COMPUT CIVIL ENG, V25, P57, DOI 10.1061/(ASCE)CP.1943-5487.0000065
   XiangYang X, 2010, INT C COMP DES APPL
   Zaibi G, 2014, SECUR COMMUN NETW, V7, P279, DOI 10.1002/sec.728
   Zhang QH, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/9329812
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 26
TC 27
Z9 30
U1 1
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12329
EP 12347
DI 10.1007/s11042-019-08478-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400047
DA 2024-07-18
ER

PT J
AU Huang, CB
   Abeo, TA
   Luo, XZ
   Shen, XJ
   Gou, JP
   Niu, DJ
AF Huang Chang-Bin
   Abeo, Timothy Apasiba
   Luo Xiao-Zhen
   Shen Xiang-Jun
   Gou Jian-Ping
   Niu De-Jiao
TI Semi-supervised manifold alignment with multi-graph embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semi-supervised; Manifold alignmen; Multi-graph embedding;
   Correspondence information
ID NETWORKS; FRAMEWORK
AB In this paper, a novel semi-supervised manifold alignment approach via multiple graph embeddings (MA-MGE) is proposed. Different from the traditional manifold alignment algorithms that use a single graph embedding to learn the latent manifold structure of each data set, our approach utilizes multiple graph embeddings to learn a joint latent manifold structure. Therefore a composite manifold representation with complete and more useful information is obtained from each dataset through a dynamic reconstruction of multiple graphs. Also, an optimization strategy based on eigen-value solutions is provided. Experimental results on Protein, COIL-20 and Face-10 datasets demonstrate superior performance of the proposed method compared with the state-of-the-art methods, such as semi-supervised manifold alignment (SSMA), manifold alignment using Procrustes analysis (PAMA) and manifold alignment without correspondence (UNMA).
C1 [Huang Chang-Bin; Abeo, Timothy Apasiba; Luo Xiao-Zhen; Shen Xiang-Jun; Gou Jian-Ping; Niu De-Jiao] JiangSu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Abeo, Timothy Apasiba] Tamale Tech Univ, Sch Appl Sci, Box 3ER, Tamale, Ghana.
C3 Jiangsu University
RP Shen, XJ (corresponding author), JiangSu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
EM xjshen@ujs.edu.cn
RI Abeo, Timothy/AAN-1878-2020; Abeo, Timothy/HGE-8474-2022; Gou,
   Jianping/JQX-2453-2023
OI Abeo, Timothy/0000-0002-6220-8371; Gou, Jianping/0000-0003-1413-0693
FU National Natural Science Foundation of China [61572240, 61806086]
FX This work was funded in part by the National Natural Science Foundation
   of China (No.61572240, 61806086).
CR Andersson T, 2013, IEEE T IMAGE PROCESS, V22, P621, DOI 10.1109/TIP.2012.2220148
   [Anonymous], 2008, ACM International Conference Proceeding Series, DOI [DOI 10.1145/1390156.1390297, 10.1145/1390156.1390297]
   [Anonymous], 2014, P 2014 C EMPIRICAL M
   Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235
   Blouvshtein Leonid, 2018, IEEE T PATTERN ANAL, V1, P1
   BOUCHER T, 2015, 29 AAAI C ART INT
   Cai D, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P714
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Diaz F, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2727
   Fu SC, 2020, INFORM SCIENCES, V514, P484, DOI 10.1016/j.ins.2019.11.019
   Gajalakshmi P, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATION, AND SIGNAL PROCESSING (ICCCSP): SPECIAL FOCUS ON TECHNOLOGY AND INNOVATION FOR SMART ENVIRONMENT, P170, DOI 10.1109/ICOPS35962.2018.9575422
   Gao QX, 2014, NEURAL NETWORKS, V54, P49, DOI 10.1016/j.neunet.2014.02.009
   GUERRERO R, 2014, LECT NOTES COMPUTER, V8679
   Gui J, 2012, PATTERN RECOGN, V45, P2884, DOI 10.1016/j.patcog.2012.02.005
   HAM J, 2005, INT WORKSH ART INT S
   Heirendt L, 2013, INTERNATIONAL MECHANICAL ENGINEERING CONGRESS AND EXPOSITION - 2012, VOL 3, PTS A-C: DESIGN, MATERIALS, AND MANUFACTURING, P1743
   Hong DF, 2019, ISPRS J PHOTOGRAMM, V147, P193, DOI 10.1016/j.isprsjprs.2018.10.006
   Houari R, 2016, EXPERT SYST APPL, V64, P247, DOI 10.1016/j.eswa.2016.07.041
   Huang R, 2019, INT J MACH LEARN CYB, V10, P1269, DOI 10.1007/s13042-018-0809-6
   Li S, 2018, EXP THERM FLUID SCI, V99, P1, DOI 10.1016/j.expthermflusci.2018.07.026
   Li XJ, 2017, NEUROCOMPUTING, V224, P195, DOI 10.1016/j.neucom.2016.11.002
   Lu JW, 2010, IEEE T SYST MAN CY B, V40, P958, DOI 10.1109/TSMCB.2009.2032926
   Malik ZK, 2016, NEUROCOMPUTING, V173, P127, DOI 10.1016/j.neucom.2014.12.119
   Nene S. A., 1996, Tech. Rep. CUCS-005-96
   Nie FP, 2014, PR MACH LEARN RES, V32, P1062
   Nigam K., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P86, DOI 10.1145/354756.354805
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   SOCHER R, 2010, PROC CVPR IEEE, P966, DOI DOI 10.1109/CVPR.2010.5540112
   Tan SL, 2014, AAAI CONF ARTIF INTE, P159
   Wang C, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1273
   Wang CW, 2009, GLOB TELECOMM CONF, P2009
   Wang J, 2017, NEUROCOMPUTING, V230, P322, DOI 10.1016/j.neucom.2016.12.010
   Wang LL, 2018, ENG LET, V26
   Wang XG, 2018, KNOWL-BASED SYST, V156, P100, DOI 10.1016/j.knosys.2018.05.023
   Yan SC, 2005, PROC CVPR IEEE, P830
   Yang HL, 2016, IEEE T GEOSCI REMOTE, V54, P51, DOI 10.1109/TGRS.2015.2449736
   Yang HL, 2013, INT GEOSCI REMOTE SE, P1047, DOI 10.1109/IGARSS.2013.6721343
   Zhang G, 2016, IET COMPUT VIS, V10, P728, DOI 10.1049/iet-cvi.2015.0287
   Zhang SW, 2011, NEUROCOMPUTING, V74, P2284, DOI 10.1016/j.neucom.2011.03.007
   Zhao YR, 2018, PROCEEDINGS OF THE 2018 2ND INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND COMMUNICATION ENGINEERING (ICTCE 2018), P154, DOI [10.1145/3291842.3291895, 10.1016/j.patcog.2018.01.012]
NR 40
TC 1
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 20241
EP 20262
DI 10.1007/s11042-020-08868-9
EA APR 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000526210000005
DA 2024-07-18
ER

PT J
AU Pan, C
   Yan, WQ
AF Pan, Chen
   Yan, Wei Qi
TI Object detection based on saturation of visual perception
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Fixational eye movement; Machine learning; Positive
   feedback; Saturation of visual perception
ID SALIENT REGION DETECTION; IMAGE
AB This paper presents a framework to detect salient objects from natural images through simulating human perception. We think perception saturation, generated by microsaccades in gaze, is the primary reason why human brains export consciousness of salient objects. Perception saturation is represented by using amplitude of microsaccades (AOM). When the AOM or changes of the AOM tend to zero, human perception becomes saturated. Motivated by this analysis, we construct a group of learning-based models to detect a salient object in a coarse-to-fine sequence. Firstly, a small image is selected to minimize the AOM so as to saturate the perception. Then, neural networks with random weights (NNRW) are chosen to simulate the received visual stimuli. In order to examine the changes of AOM, a positive feedback loop is constructed which executes the procedure of "pixel sampling-learning classification" iteratively. The final fixation area after iterations is regarded as a salient object. The proposed algorithm is based on unsupervised learning and data-driven completely. Our results based on open image datasets show that the proposed method achieves better performance compared to those existing unsupervised algorithms.
C1 [Pan, Chen] China Jiliang Univ, Hangzhou 310018, Zhejiang, Peoples R China.
   [Yan, Wei Qi] Auckland Univ Technol, Auckland, New Zealand.
C3 China Jiliang University; Auckland University of Technology
RP Yan, WQ (corresponding author), Auckland Univ Technol, Auckland, New Zealand.
EM dcsyanwq@gmail.com
FU Natural Science Foundation of Zhejiang Province of China [LY19F030013]
FX This research project was supported by the Natural Science Foundation of
   Zhejiang Province of China (No. LY19F030013).
CR Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Cao WP, 2018, NEUROCOMPUTING, V275, P278, DOI 10.1016/j.neucom.2017.08.040
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Garcia-Garcia A, 2018, APPL SOFT COMPUT, V70, P41, DOI 10.1016/j.asoc.2018.05.018
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Guo CL, 2008, PROC CVPR IEEE, P2908
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hosang J, 2016, IEEE T PATTERN ANAL, V38, P814, DOI 10.1109/TPAMI.2015.2465908
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Huang F, 2017, IEEE T IMAGE PROCESS, V26, P1911, DOI 10.1109/TIP.2017.2669878
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Lu S, 2014, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2014.357
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Pan C., 2018, IEEE International Conference on High Voltage Engineering and Application (ICHVE), P1
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Rolfs M, 2009, VISION RES, V49, P2415, DOI 10.1016/j.visres.2009.08.010
   Siva P, 2013, PROC CVPR IEEE, P3238, DOI 10.1109/CVPR.2013.416
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   [吴祯 Wu Zhen], 2017, [中国图象图形学报, Journal of Image and Graphics], V22, P946
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
   Zhang JB, 2020, IEEE T KNOWL DATA EN, V32, P468, DOI [10.1109/TMI.2019.2893944, 10.1109/TKDE.2019.2891537]
   Zhang L, 2016, NEUROCOMPUTING, V218, P103, DOI 10.1016/j.neucom.2016.08.066
   Zhao JW, 2014, NEURAL COMPUT APPL, V24, P1317, DOI 10.1007/s00521-013-1356-4
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 30
TC 11
Z9 12
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19925
EP 19944
DI 10.1007/s11042-020-08866-x
EA APR 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000523108900001
DA 2024-07-18
ER

PT J
AU Cao, LY
   Dey, N
   Ashour, AS
   Fong, S
   Sherratt, RS
   Wu, LJ
   Shi, FQ
AF Cao, Luying
   Dey, Nilanjan
   Ashour, Amira S.
   Fong, Simon
   Sherratt, R. Simon
   Wu, Lijun
   Shi, Fuqian
TI Diabetic plantar pressure analysis using image fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biomedical signal processing; Image fusion; Plantar pressure sensors;
   Wavelet transforms; Gaussian laplace pyramid
ID INFORMATION FUSION; HAAR; CLASSIFICATION; RETRIEVAL; MODEL; FOURIER;
   SYSTEM
AB Plantar pressure images analysis is the key issue of designing comfortable shoe products through last customizing system, which has attracted the researchers' curiosity toward image fusion as an application of medical and industrial imaging. In the current work, image fusion has been applied using wavelet transform and compared with Laplace Pyramid. Using image fusion rules of Mean-Max, we presented a plantar pressure image fusion method employing haar wavelet transform. It was compared in different composition layers with the Laplace pyramid transform. The experimental studies deployed the haar, db2, sym4, coif2, and bior5.5 wavelet basis functions for image fusion under decomposition layers of 3, 4, and 5. Evaluation metrics were measured in the case of the different layer number of wavelet decomposition to determine the best decomposition level and to evaluate the fused image quality using with different wavelet functions. The best wavelet basis function and decomposition layers were selected through the analysis and the evaluation measurements. This study established that haar wavelet transform with five decomposition levels on plantar pressure image achieved superior performance of 89.2817% mean, 89.4913% standard deviation, 5.4196 average gradient, 14.3364 spatial frequency, 5.9323 information entropy and 0.2206 cross entropy.
C1 [Cao, Luying; Dey, Nilanjan; Ashour, Amira S.; Fong, Simon; Sherratt, R. Simon; Wu, Lijun; Shi, Fuqian] Wenzhou Med Univ, Coll Informat & Engn, Wenzhou 325035, Peoples R China.
C3 Wenzhou Medical University
RP Shi, FQ (corresponding author), Wenzhou Med Univ, Coll Informat & Engn, Wenzhou 325035, Peoples R China.
EM 1294502807@qq.com; nilanjan.dey@tict.edu.in; amirasashour@yahoo.com;
   ccfong@umac.mo; r.s.sherratt@reading.ac.uk; biomech@163.com;
   sfq@wmu.edu.cn
RI Ashour, Amira S./T-5454-2019; Fong, Simon/C-9388-2009
OI Ashour, Amira S./0000-0003-3217-6185; Fong, Simon/0000-0002-1848-7246
CR Al-Angari HM, 2017, GAIT POSTURE, V51, P261, DOI 10.1016/j.gaitpost.2016.11.006
   Banerjee A, 2013, PROC TECH, V10, P623, DOI 10.1016/j.protcy.2013.12.403
   Bennetts CJ, 2013, J BIOMECH, V46, P19, DOI 10.1016/j.jbiomech.2012.09.007
   Bhandari KA, 2016, PROCEDIA COMPUT SCI, V79, P391, DOI 10.1016/j.procs.2016.03.051
   Bhosale B, 2014, P ROMANIAN ACAD A, V15, P18
   Boussaa M, 2015, PROCEDIA COMPUT SCI, V73, P32, DOI 10.1016/j.procs.2015.12.045
   Chang Zheng, 2016, Journal of China Universities of Posts and Telecommunications, V23, P91, DOI 10.1016/S1005-8885(16)60050-X
   Chatzistergos PE, 2014, MED ENG PHYS, V36, P1205, DOI 10.1016/j.medengphy.2014.06.006
   Chen WM, 2015, J BIOMECH, V48, P659, DOI 10.1016/j.jbiomech.2014.12.043
   Deschamps K, 2015, GAIT POSTURE, V41, P852, DOI 10.1016/j.gaitpost.2014.12.013
   Domnguez HJO, 2015, DETE ASS EQUIPT, V784, P581, DOI [10.1016/j.nima.2014.12.109, DOI 10.1016/J.NIMA.2014.12.109]
   Frye TP, 2017, J UROLOGY, V197, P640, DOI 10.1016/j.juro.2016.08.109
   He CK, 2017, NEUROCOMPUTING, V253, P70, DOI 10.1016/j.neucom.2016.09.129
   Kamal Md Sarwar, 2017, International Journal of Information Technology, V9, P59, DOI 10.1007/s41870-017-0005-z
   Kamal S, 2018, NEURAL COMPUT APPL, V29, P1015, DOI 10.1007/s00521-016-2513-3
   Kamal S, 2017, COMPUT BIOL CHEM, V68, P231, DOI 10.1016/j.compbiolchem.2017.04.003
   Kamal S, 2016, COMPUT METH PROG BIO, V131, P191, DOI 10.1016/j.cmpb.2016.04.005
   Keijsers NLW, 2013, CLIN BIOMECH, V28, P350, DOI 10.1016/j.clinbiomech.2013.01.012
   Koç A, 2017, EXPERT SYST APPL, V77, P247, DOI 10.1016/j.eswa.2017.01.046
   Li Z, 2017, SCI REP-UK, V7, DOI 10.1038/srep42742
   Li ZR, 2015, J INTELL FUZZY SYST, V29, P2335, DOI 10.3233/IFS-151932
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Moraru L, 2013, COMPUT BIOL MED, V43, P967, DOI 10.1016/j.compbiomed.2013.04.014
   Oliva D, 2017, EXPERT SYST APPL, V79, P164, DOI 10.1016/j.eswa.2017.02.042
   Piras L, 2017, INFORM FUSION, V37, P50, DOI 10.1016/j.inffus.2017.01.003
   Qian JJ, 2016, NEUROCOMPUTING, V213, P162, DOI 10.1016/j.neucom.2015.11.135
   Ray SS, 2013, APPL MATH COMPUT, V220, P659, DOI 10.1016/j.amc.2013.07.036
   Tedmori S, 2014, INFORM SCIENCES, V269, P21, DOI 10.1016/j.ins.2014.02.004
   Valerio M, 2017, UROL ONCOL-SEMIN ORI, V35, DOI 10.1016/j.urolonc.2016.11.008
   Wang D, 2017, IEEE ACCESS, V5, P4887, DOI 10.1109/ACCESS.2017.2677950
   Wang D, 2017, IEEE SENS J, V17, P1407, DOI 10.1109/JSEN.2016.2641501
   Wang Z, 2017, APPL SOFT COMPUT, DOI [10.1016/j.asoc.2017.02.03519, DOI 10.1016/J.ASOC.2017.02.03519]
   Zhang Y, 2017, INFORM FUSION, V35, P81, DOI 10.1016/j.inffus.2016.09.006
   Zhou WJ, 2017, INFORM SCIENCES, V397, P1, DOI 10.1016/j.ins.2017.02.049
   Zong JJ, 2017, BIOMED SIGNAL PROCES, V34, P195, DOI 10.1016/j.bspc.2017.02.005
NR 36
TC 7
Z9 7
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 11213
EP 11236
DI 10.1007/s11042-018-6269-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600079
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Krishnammal, PM
   Raja, SS
AF Krishnammal, P. Muthu
   Raja, S. Selvakumar
TI Medical image segmentation using fast discrete curvelet transform and
   classification methods for MRI brain images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical imaging; Hybrid mean filtering; Fast discrete curvelet
   transform; Multi-resolution geometric analysis; Feature extraction;
   Segmentation; FCM; AMS-FCM; Modified FCM; PNN; SVM; ANFIS
ID ALGORITHM
AB Image segmentation and classification are indispensable steps in the therapeutic image processing. Clustering based methods plays an inevitable role in the segmentation stage of the biomedical images especially for distinguishingcerebrum tumors from MRI brain images which is a very challenging task. This paper introduces a curvelet transform to extract features for the computerized detection of abnormalities in the MR brain images. Statistical and texture feature of the brain image using MRI are extracted in the curvelet domain. As manual segmentation is time consuming, an automatic support system for segmentation and classification of tumor stages is preferred. In this paper, the variants of Fuzzy CMeans (FCM) clustering segmentation such as Adaptive FCM, AMS modified FCM and other methods like genetic algorithm and snake algorithms are dealt for which the features extracted using the Curvelet transform serves as the input. The segmented image serves as the input for classifiers like Support Vector machine, Probabilistic neural network, and ANFIS which predict the inputs into the two possible classes being normal and abnormal.
C1 [Krishnammal, P. Muthu] Sathyabama Inst Sci & Technol, Fac Elect, Chennai, Tamil Nadu, India.
   [Raja, S. Selvakumar] Khakathiya Inst Sci & Technol Women, Nizamabad, India.
C3 Sathyabama Institute of Science & Technology
RP Krishnammal, PM (corresponding author), Sathyabama Inst Sci & Technol, Fac Elect, Chennai, Tamil Nadu, India.
EM anumerline1584@gmail.com; selvakumarraja@yahoo.com
RI P, muthu krishnammal/AAY-4558-2020
OI P, muthu krishnammal/0000-0003-1680-1307; S, Dr.
   Selvakumar/0000-0001-9795-3569
CR A Javadpour, 2016, J Biomed Phys Eng, V6, P95
   Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Al-Marzouqi H, 2017, SIGNAL PROCESS-IMAGE, V53, P24, DOI 10.1016/j.image.2017.01.009
   Albregtsen F., 2008, STAT TEXTURE MEASURE, DOI [10.5209/ARIS.6586, DOI 10.5209/ARIS.6586]
   Aledo A, 2013, REV ESP INVESTIG SOC, P3, DOI 10.5477/cis/reis.142.3
   Amin S.E., 2012, 2012 8 INT C INF SYS
   Anandan P., 2016, Circuits Syst, V7, P2059
   [Anonymous], 2017, INT J INNOVATIVE RES
   [Anonymous], 2012, 29 IEEE NATL RAD SCI
   Arora N, 2015, 2015 15 INT C INT SY
   Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   BalaAnand M, 2020, INT J PARALLEL PROG, V48, P329, DOI 10.1007/s10766-018-0598-2
   Bargaje A, 2017, INT RES J ENG TECHNO, V4
   Bezdek J., 1999, FUZZY MODELS ALGORIT
   Bezdek J. C., 1981, Pattern recognition with fuzzy objective function algorithms
   Bharathi D, 2013, ADV INTELL SYST, V177, P905
   Bhardwaj A., 2013, IJCTT, V4, P236
   Buragohain M, 2009, THESIS
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Cui YB, 2011, PROCEDIA ENGINEER, V23, DOI 10.1016/j.proeng.2011.11.2500
   Francis SV, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0023-3
   Goswami S, 2013, 2013 INT C COMM SYST
   Guo FF, 2016, IET IMAGE PROCESS, V10, P272, DOI 10.1049/iet-ipr.2015.0236
   Gupta B, 2019, CAAI T INTELLIGENCE
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Ilango G., 2011, ARPN J ENG APPL SCI, V6, P15, DOI [10.5120/4571-6732, DOI 10.5120/4571-6732]
   Joshi DM, 2010, 2010 2 INT C EL COMP
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Kou L, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040402
   Krishnammal PM, 2015, BIOSCI BIOTECH RES C, V12, P699, DOI [10.13005/bbra/2250, DOI 10.13005/BBRA/2250]
   Li S, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942097
   Li YC, 2010, EXPERT SYST APPL, V37, P3063, DOI 10.1016/j.eswa.2009.09.024
   Ma JW, 2010, IEEE SIGNAL PROC MAG, V27, P118, DOI 10.1109/MSP.2009.935453
   Maram B, 2019, SERV ORIENTED COMPUT, V13, P3, DOI 10.1007/s11761-018-0249-x
   Mayer A, 2009, IEEE T MED IMAGING, V28, P1238, DOI 10.1109/TMI.2009.2013850
   Natarajan Prem, 2012, 2012 IEEE INT C COMP, P1
   Neha DK, 3 INT C BIOM ENG ASS, P255
   Othman MF, 2011, 2011 2 INT C INT SYS
   PALAIAHNAKOTE S, 2019, CAAI T INTELLIGENCE
   Pieciak T, 2012, LECT N BIOINFORMAT, V7339, P24
   Rakesh M. R, 2013, INT J ADV RES ELECT, V2, P5117
   Ramteke Ramteke R. R., Int J Adv Comput Res, V2 2, P190
   Saehdeva J, 2012, MAGN RESON IMAGING, V30, P694, DOI 10.1016/j.mri.2012.01.006
   Sapra Pankaj., 2013, International Journal of Science and Modern Engineering (IJISME)
   Shahnazar A, 2017, ENVIRON EARTH SCI, V76, DOI 10.1007/s12665-017-6864-6
   Sharma K., 2014, Int. J. Comput. Appl., V103
   Singh D, 2012, International Journal of Engineering and Advanced Technology (IJEAT), V1, P243
   Sivakumar N, 2017, HYBRID MEDICAL IMAGE
   Sivaparthipan CB, 2018, MULTIMED TOOLS APPL
   Skinner Sarah, 2013, Aust Fam Physician, V42, P794
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Tian CW, 2019, CAAI T INTELL TECHNO, V4, P17, DOI 10.1049/trit.2018.1054
   Varatharajan R, 2018, MULTIMED TOOLS APPL, V77, P17573, DOI [10.1007/s11042-017-4768-9, 10.1007/s11042-017-5318-1]
   Wang JZ, 2008, COMPUT MED IMAG GRAP, V32, P685, DOI 10.1016/j.compmedimag.2008.08.004
   Wang XY, 2011, PATTERN RECOGN, V44, P777, DOI 10.1016/j.patcog.2010.08.008
   YANOWITZ SD, 1989, COMPUT VISION GRAPH, V46, P82, DOI 10.1016/S0734-189X(89)80017-9
   Zhou W, 2013, COMPUTATIONAL MATH M
   Zhu YL, 2012, PHYSCS PROC, V25, P609, DOI 10.1016/j.phpro.2012.03.133
NR 58
TC 6
Z9 7
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10099
EP 10122
DI 10.1007/s11042-019-08089-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600020
DA 2024-07-18
ER

PT J
AU Ma, M
AF Ma, Min
TI RETRACTED: Infrared pedestrian detection algorithm based on multimedia
   image recombination and matrix restoration (Retracted article. See SEP,
   2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Digital image processing; Video continuous image; Moving object; Pattern
   recognition; Infrared pedestrian detection algorithm
ID FLUORESCENCE; RECOGNITION
AB Computer vision and digital image processing technology can be widely used in various fields. Among them, analysis of infrared pedestrian detection in video continuous images is one of the most widely used directions. This paper focuses on pattern recognition-based image processing and its recognition in infrared pedestrian detection. The moving object analysis of video sequence images proposes infrared pedestrian detection algorithm from continuous video sequence images, this method can identify and track the extracted infrared pedestrian detection, which can solve and describe their behaviours. This article describes a moving object tracking algorithm that has used to achieve the detection of a moving target in the background and implement specific warnings. The algorithm uses the background difference method to get the static background model in the current frame, detects the foreground image in the constantly updated video image, and extracts the moving target. The experimental results show that this method can achieve the detection of infrared pedestrian detection in video sequences, it has real-time performance, and the infrared pedestrian detection algorithm can get better detection results.
C1 [Ma, Min] Jiangsu Food & Pharmaceut Sci Coll, Sch Basic Educ, Huaian 223000, Peoples R China.
C3 Jiangsu Food & Pharmaceutical Science College
RP Ma, M (corresponding author), Jiangsu Food & Pharmaceut Sci Coll, Sch Basic Educ, Huaian 223000, Peoples R China.
EM 19941017@jsfpc.edu.cn
RI ma, min/IWV-2792-2023
CR Al-Mohair HK, 2015, APPL SOFT COMPUT, V33, P337, DOI 10.1016/j.asoc.2015.04.046
   Chaaraoui AA, 2014, EXPERT SYST APPL, V41, P786, DOI 10.1016/j.eswa.2013.08.009
   [Anonymous], MICROELECTROMECHANIC
   Blaschke T, 2014, ISPRS J PHOTOGRAMM, V87, P180, DOI 10.1016/j.isprsjprs.2013.09.014
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Craxton A, 2015, CELL DEATH DIFFER, V22, P890, DOI 10.1038/cdd.2015.22
   de Oliveira RM, 2018, J ANAL ATOM SPECTROM, V33, P1700, DOI 10.1039/c8ja00179k
   Dell AI, 2014, TRENDS ECOL EVOL, V29, P417, DOI 10.1016/j.tree.2014.05.004
   Feng JH, 2018, SENSOR ACTUAT B-CHEM, V270, P104, DOI 10.1016/j.snb.2018.05.015
   Gong FD, 2015, GENE DEV, V29, P197, DOI 10.1101/gad.252189.114
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Huck CW, 2016, CURR MED CHEM, V23, P3052, DOI 10.2174/0929867323666160607110507
   Jin X, 2017, INFRARED PHYS TECHN, V85, P478, DOI 10.1016/j.infrared.2017.07.010
   Laplante C, 2016, P NATL ACAD SCI USA, V113, pE5876, DOI 10.1073/pnas.1608252113
   Lee JH, 2016, INSTRUM SCI TECHNOL, V44, P504, DOI 10.1080/10739149.2016.1159220
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shen QM, 2015, ANAL CHEM, V87, P4949, DOI 10.1021/acs.analchem.5b00679
   Theophilou G, 2018, ANAL BIOANAL CHEM, V410, P4541, DOI 10.1007/s00216-018-1111-x
   Wang H, 2016, INT J COMPUT VISION, V119, P219, DOI 10.1007/s11263-015-0846-5
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Wu CY, 2016, J MATER CHEM C, V4, P10804, DOI 10.1039/c6tc03856e
   Yuan YS, 2016, SENSOR ACTUAT B-CHEM, V236, P565, DOI 10.1016/j.snb.2016.06.007
NR 24
TC 5
Z9 5
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9267
EP 9282
DI 10.1007/s11042-019-7444-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600051
DA 2024-07-18
ER

PT J
AU Murugan, GVK
   Subramaniyam, RU
AF Murugan, Guru Vimal Kumar
   Subramaniyam, Ragupathy Uthandipalayam
TI Performance analysis of image steganography using wavelet transform for
   safe and secured transaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Steganography; DWT; Security
ID DOMAIN
AB Internet applications are increased and growing at efficient way. By this technological growth, data communication in the internet in secured way has got a challenging task. Transmitting information in network is a great risk. Hacking the data and use those data for their benefits is done by intruders. To control these unwanted acts, steganography is used. It ensures safety of secret message. Invisible communication is a study by Steganography and it denotes with communicating message hiding. Data embedding can make in transform and spatial domain for secret communication, military communication, multimedia (hiding, copyright protection), authentication etc. A best steganography algorithm will have maximum embedding capacity, high fidelity and the good security level. Image Steganography has the robustness and security problem in the existing work. For the defence application, social problems such as terrorists, more number of attacks (cyber) and Geometric attack are caused. To overcome such drawbacks, this research work proposes Discrete Wavelet Transform (DWT) which has more advantages than other transforms technique like DCT (Discrete Cosine Transform). This is because of quality scalability, Interest in region coding, low bit rate transmission which is quickly operating and also it is compatible to Visual System by Human that provides good perception quality. Geometric attack induces synchronization errors between the first image and also the extracted stego image throughout the detection method during which its positions are modified. Image characters are analyzed well by Wavelet Space - frequency property of localization which makes additional strong to the attack such as geometric. This property will enlarge the embedded area and improves the security. Hence DWT results in high imperceptibility and PSNR in range of 30-54 dB.
C1 [Murugan, Guru Vimal Kumar; Subramaniyam, Ragupathy Uthandipalayam] Kongu Engn Coll, Dept Elect & Instrumentat Engn, Erode, India.
C3 Kongu Engineering College
RP Murugan, GVK (corresponding author), Kongu Engn Coll, Dept Elect & Instrumentat Engn, Erode, India.
EM guruvima109@gmail.com; ragupathy.us@gmail.com
RI MURUGAN, GURU VIMAL KUMAR/HZL-5980-2023
OI MURUGAN, GURU VIMAL KUMAR/0000-0002-5379-1155
CR Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   [Anonymous], 2016, COMPUT ELECTR ENG, DOI DOI 10.1016/J.COMPELECENG.2016.09.001
   Baby D, 2015, PROCEDIA COMPUT SCI, V46, P612, DOI 10.1016/j.procs.2015.02.105
   BalaAnand M, 2020, INT J PARALLEL PROG, V48, P329, DOI 10.1007/s10766-018-0598-2
   Balasubramanian C, 2014, MULTIMED TOOLS APPL, V73, P2223, DOI 10.1007/s11042-013-1640-4
   Hemalatha S, 2015, PROCEDIA COMPUT SCI, V47, P272, DOI 10.1016/j.procs.2015.03.207
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Hussain M, 2016, SYMMETRY-BASEL, V8, DOI 10.3390/sym8060041
   Jeevitha S., 2019, HLTH TECHNOLOGY, P1
   Johnson K, 1998, TLS-TIMES LIT SUPPL, P26
   Johnson NF, 2000, ART H COMP SCI LIBR, P43
   Kumar M. Guru Vimal, 2016, IEEE INT C WIR COMM
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   LIN ET, 1999, P IM PROC IM QUAL IM
   Malathi P, 2017, PROCEDIA COMPUT SCI, V115, P651, DOI 10.1016/j.procs.2017.09.151
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Mumthas S, 2017, PROCEDIA COMPUT SCI, V115, P660, DOI 10.1016/j.procs.2017.09.152
   Nair NS, 2015, PROCEDIA COMPUT SCI, V46, P1510, DOI 10.1016/j.procs.2015.02.071
   Nipanikar S., 2017, SPARSE REPRESENTATIO
   Saeed MA, 2016, IEEE INT CONF INTELL, P1, DOI 10.1109/INTELSE.2016.7475142
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Sidhik S, 2015, OPTIK, V126, P3755, DOI 10.1016/j.ijleo.2015.08.208
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Wakure MA, 2015, INT J COMPUTER APPL, V129, P0975
   Yuan HD, 2014, INFORM SCIENCES, V254, P197, DOI 10.1016/j.ins.2013.08.012
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
NR 28
TC 7
Z9 7
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9101
EP 9115
DI 10.1007/s11042-019-7507-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600039
DA 2024-07-18
ER

PT J
AU Velammal, BL
AF Velammal, B. L.
TI Integrating compositional pattern-producing networks and optimized
   convolution neural networks using deep learning techniques for detecting
   brain abnormalities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neural Networks; Independent component analysis; Electroencephalography
   (EEG); Discrete wavelet transform; Image slicing
ID TUMOR SEGMENTATION
AB In brain abnormality approach, accurate and reliable diagnosis is a critical component, because it provides potential abnormality in tissues as well as functional structures significantly to demarcate surgical plan. In the recent past, various diagnosing procedures have been carried out such as Double Density Discrete Wavelet Transform (DDDWT), Support Vector Machine (SVM) classifier, Convolutional Neural Networks etc., whereas treatment outcome and planning are the critical components. Build upon the successful deep learning approach, a novel brain abnormality diagnostic method has been developed by integrating Compositional Pattern Producing (CPP) and Optimized Convolutional Neural Networks (OCNN) in an unified framework. This hybrid approach includes Independent Component Analysis (ICA) with parallel factor and region of interest (ROI) for preprocessing, training CPP using image patches and fine tuning CPP-OCNN using image slices for segmentation as well as for extraction. This model could segment the images by slices than patches which are more accurate and less complex in segmentation with optimized kernel SVM classifier for abnormality detection. The system is evaluated based on MRI imaging datasets provided by CHB-MIT scalp EEG of micro bleeds dataset and efficiently validated with the help of the experimental results by minimizing the Root mean square and by improving the accuracy, smoothness, correlation, sensitivity and specificity using state of the art techniques.
C1 [Velammal, B. L.] Anna Univ, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 Anna University; Anna University Chennai
RP Velammal, BL (corresponding author), Anna Univ, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM velammalblceg@gmail.com
RI Bhagavathiappan, Velammal/AAA-7569-2022
OI Bhagavathiappan, Velammal/0000-0002-4878-193X
CR Ahammad N, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/450573
   Becker BG, 2018, NEUROIMAGE, V175, P246, DOI 10.1016/j.neuroimage.2018.03.075
   Blair Gordon W, 2017, Curr Treat Options Cardiovasc Med, V19, P56, DOI 10.1007/s11936-017-0555-1
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Kumar Y, 2014, NEUROCOMPUTING, V133, P271, DOI 10.1016/j.neucom.2013.11.009
   Li MY, 2016, BIOCYBERN BIOMED ENG, V36, P708, DOI 10.1016/j.bbe.2016.07.004
   Liu MX, 2018, MED IMAGE ANAL, V43, P157, DOI 10.1016/j.media.2017.10.005
   Mullally WJ, 2018, AM J MED, V131, P438, DOI 10.1016/j.amjmed.2017.10.042
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Samanta AK, 2018, ADV INTELL SYST COMP, V723, P343, DOI 10.1007/978-3-319-74690-6_34
   Shaker M, 2017, MED IMAGE ANAL, V37, P56, DOI 10.1016/j.media.2017.01.005
   Siuly S, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/576437
   Siuly S, 2015, COMPUT METH PROG BIO, V119, P29, DOI 10.1016/j.cmpb.2015.01.002
NR 14
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10489
EP 10503
DI 10.1007/s11042-019-7174-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600041
DA 2024-07-18
ER

PT J
AU Zhao, KF
   Jiang, YZ
   Xia, KJ
   Zhou, LY
   Chen, YY
   Xu, K
   Qian, PJ
AF Zhao, Kaifa
   Jiang, Yizhang
   Xia, Kaijian
   Zhou, Leyuan
   Chen, Yangyang
   Xu, Ke
   Qian, Pengjiang
TI View-collaborative fuzzy soft subspace clustering for automatic medical
   image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiview clustering; Soft subspace clustering; Medical image
   segmentation; Collaborative learning
ID ALGORITHM; FUSION
AB With the rapid development of medical imaging methodologies, such as magnetic resonance (MR) and positron emission tomography (PET)/MR, various types of MR images, which are acquired using inconsistent MR pulse sequences on the same patient, have been applied in medical-image-based diagnoses. A feature map extracted from an MR image describes the patient's condition from one perspective. By effectively using all feature maps from various MR images, it is possible to completely describe the intrinsic characteristics of the patient's condition to facilitate a diagnosis. Facing such a scenario, classic machine learning algorithms typically stack these feature maps for unified processing and do not explore the importance of each feature within a single feature map or the relationships among feature maps. To address these challenges, both multiview and subspace learning scenarios are considered in this study, and the multiview collaboration-based fuzzy soft subspace clustering (MVC-FSSC) algorithm is proposed. The MVC-FSSC algorithm not only strives to exploit the agreement of decisions across all views via collaborative learning but also strives to utilize the soft subspace-based weighting mechanism to automatically evaluate the contribution of each dimensional feature to each estimated cluster within a single view. Our experimental results indicate that the proposed MVC-FSSC algorithm can effectively explore the collaborative relations among all views and the importance of features in their respective views. Additionally, our MVC-FSSC method has substantial advantages over traditional clustering algorithms in MR image segmentation. Applying the MVC-FSSC algorithm to five patients' MR images, the average mean absolute prediction deviation (MAPD) is 98.62 +/- 8.34, which is significantly better than the score of 131.90 +/- 16.03 that was obtained using the collaborative fuzzy k-means (CO-FKM) algorithm and the score of 128.87 +/- 11.32 that was obtained using the quadratic weights and Gini-Simpson diversity-based fuzzy clustering (QWGSD-FC) algorithm.
C1 [Zhao, Kaifa; Jiang, Yizhang; Chen, Yangyang; Xu, Ke; Qian, Pengjiang] Jiangnan Univ, Sch Digital Media, Wuxi 214121, Jiangsu, Peoples R China.
   [Xia, Kaijian] Changshu 1 Peoples Hosp, Suzhou 215500, Peoples R China.
   [Zhou, Leyuan] Jiangnan Univ, Affiliated Hosp, Wuxi 214000, Jiangsu, Peoples R China.
C3 Jiangnan University; Jiangnan University
RP Qian, PJ (corresponding author), Jiangnan Univ, Sch Digital Media, Wuxi 214121, Jiangsu, Peoples R China.
EM zhaokaifa@live.com; jyz0512@163.com; xiakaijian@163.com;
   zhouleyuan99@126.com; chcnyangyang0620@163.com; 2428915905@qq.com;
   qianpjiang@jiangnan.edu.cn
RI Jiang, Yizhang/V-2171-2019
OI Jiang, Yizhang/0000-0002-4558-9803; Qian, Pengjiang/0000-0002-5596-3694;
   ZHAO, Kaifa/0000-0002-3102-7498; Xia, Kaijian/0000-0002-1650-9982
CR Aggarwal CC, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P61, DOI 10.1145/304181.304188
   Aggarwal CC, 2000, SIGMOD REC, V29, P70, DOI 10.1145/335191.335383
   Batuwita R, 2012, J BIOINF COMPUT BIOL, V10, DOI 10.1142/S0219720012500035
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Cao YQ, 2002, NEURAL NETWORKS, V15, P105, DOI 10.1016/S0893-6080(01)00108-3
   Chitsaz E, 2016, SOFT COMPUT, V20, P4463, DOI 10.1007/s00500-015-1756-8
   Cleuziou G, 2009, IEEE DATA MINING, P752, DOI 10.1109/ICDM.2009.138
   Deng ZH, 2010, PATTERN RECOGN, V43, P767, DOI 10.1016/j.patcog.2009.09.010
   Desgraupes B., 2013, CLUSTERING INDICES, V1, P34
   DESOETE G, 1986, QUAL QUANT, V20, P169, DOI 10.1007/BF00227423
   Domeniconi C, 2007, DATA MIN KNOWL DISC, V14, P63, DOI 10.1007/s10618-006-0060-8
   Gao Y, 2005, PROC CVPR IEEE, P468
   Hooijmans MT, 2015, J MAGN RESON IMAGING, V42, P217, DOI 10.1002/jmri.24775
   Hotho A., 2002, KUNSTL INTELL, V16, P48
   Huang J, 2015, 2015 IEEE 6TH INTERNATIONAL SYMPOSIUM ON MICROWAVE, ANTENNA, PROPAGATION, AND EMC TECHNOLOGIES (MAPE), P4, DOI 10.1109/MAPE.2015.7510254
   Jiang YZ, 2015, IEEE T CYBERNETICS, V45, P688, DOI 10.1109/TCYB.2014.2334595
   LI RP, 1995, PROCEEDINGS OF 1995 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS I-IV, P2227, DOI 10.1109/FUZZY.1995.409989
   Liang F, 2018, ARTIF INTELL MED, V90, P34, DOI 10.1016/j.artmed.2018.07.001
   Liu J, 2006, BIOINFORMATICS, V22, P1971, DOI 10.1093/bioinformatics/btl185
   Loeff N., 2006, P COLINGACL, P547
   Miyamoto S, 1998, 1998 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AT THE IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE - PROCEEDINGS, VOL 1-2, P1394, DOI 10.1109/FUZZY.1998.686323
   Nie FP, 2012, IEEE T SYST MAN CY B, V42, P17, DOI 10.1109/TSMCB.2011.2161607
   Parsons L., 2004, ACM SIGKDD EXPLOR NE, V6, P90, DOI DOI 10.1145/1007730.1007731
   Qian PJ, 2016, PATTERN RECOGN, V50, P155, DOI 10.1016/j.patcog.2015.08.009
   Rokach L, 2010, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, SECOND EDITION, P269, DOI 10.1007/978-0-387-098234_14
   Roth HR., 2018, Med. IMAGING Technol, V36, P63, DOI [10.11409/mit.36.63, DOI 10.11409/MIT.36.63]
   Sim K, 2013, DATA MIN KNOWL DISC, V26, P332, DOI 10.1007/s10618-012-0258-x
   Su KH, 2015, MED PHYS, V42, P4974, DOI 10.1118/1.4926756
   Tzortzis G, 2012, IEEE DATA MINING, P675, DOI 10.1109/ICDM.2012.43
   Wang GH, 2015, ALGORITHMS, V8, P234, DOI 10.3390/a8020234
   Wang GT, 2018, IEEE T MED IMAGING, V37, P1562, DOI 10.1109/TMI.2018.2791721
   Xiaopeng W., 2014, J CHEM PHARM RES, V6, P2008
   Zaidi H, 2011, PHYS MED BIOL, V56, P3091, DOI 10.1088/0031-9155/56/10/013
   Zhao K, 2019, J MED IMAGING HLTH I
NR 34
TC 4
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9523
EP 9542
DI 10.1007/s11042-019-07974-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600066
DA 2024-07-18
ER

PT J
AU Zhao, Y
AF Zhao, Yue
TI RETRACTED: Test and simulation of health balance training equipment
   based on medical multimedia image for exercise balance ability
   (Retracted article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Medical multimedia image; Balance; Tennis players; Lumbar muscle strain;
   Mechanics analysis
ID ADULTS
AB The lack of balance ability and lumbar muscle strain caused by asymmetric lower limb function have become the studied hot topics of many kinematics disciplines recently. The strength asymmetry of lower limbs of young tennis players is considered to be an intrinsic risk factor for lumbar muscle injury. Therefore, using dynamic balance instrument to scientifically evaluate the balance ability of tennis players' lower limbs and evaluate the balance rehabilitation training method is of great significance to the recovery effect of tennis players with lumbar muscle strain and to improve their sports performance. At present, the balanced rehabilitation training method used in clinical practice is mainly based on medical multimedia images, relying on the doctor's artificial rehabilitation treatment mode. Due to lack of manpower and lack of experience, doctors may need some rehabilitation equipment to assist the patient. This paper mainly focuses on the mechanical body design of the dynamic balance instrument. After analyzing the medical image of the patient's diseased part, it completes a set of motion balance table with 2 degrees of freedom. Through the simulation and actual test, it detects the help of the balance table to the rehabilitation of human exercise balance ability effect. Finally, the rehabilitation test was performed on the tennis players with lumbar muscle strain, and the effect was good. It is a training equipment with high application value.
C1 [Zhao, Yue] Beijing Sport Univ, Sch Educ, Beijing 100084, Peoples R China.
C3 Beijing Sport University
RP Zhao, Y (corresponding author), Beijing Sport Univ, Sch Educ, Beijing 100084, Peoples R China.
EM zhaoyue@bsu.edu.cn
CR Armstrong LE, 2015, J STRENGTH COND RES, V29, P869, DOI 10.1519/JSC.0000000000000822
   Bohren O, 2016, EUR FINANC MANAG, V22, P3, DOI 10.1111/eufm.12060
   de Boer RA, 2018, CURR ZOOL, V64, P631, DOI 10.1093/cz/zox076
   Denson N, 2018, RES HIGH EDUC, V59, P226, DOI 10.1007/s11162-017-9464-0
   Dietrich O, 2017, ECOHYDROLOGY, V10, DOI 10.1002/eco.1867
   Dong HW, 2015, INT J CONTROL AUTOM, V13, P887, DOI 10.1007/s12555-014-0038-z
   Geesmann Bjoern, 2017, Int J Sports Physiol Perform, V12, P984, DOI 10.1123/ijspp.2016-0061
   Larsen CF, 2015, GEOPHYS RES LETT, V42, P5902, DOI 10.1002/2015GL064349
   Leimer S, 2018, ECOHYDROLOGY, V11, DOI 10.1002/eco.1945
   Lesinski M, 2015, SPORTS MED, V45, P557, DOI 10.1007/s40279-014-0284-5
   Moutzouri M, 2016, PHYSIOTHERAPY, V102, P136, DOI 10.1016/j.physio.2015.11.001
   Pickering V, 2007, ORAL ONCOL, V43, P37, DOI 10.1016/j.oraloncology.2005.12.027
   Saghravani SR, 2015, ENVIRON EARTH SCI, V73, P4419, DOI 10.1007/s12665-014-3727-2
   Silva Wagner Henrique Souza, 2015, Motriz: rev. educ. fis., V21, P237
   Smulter N, 2018, J CARDIOTHOR VASC AN, V32, P684, DOI 10.1053/j.jvca.2017.08.035
   Tainsky S, 2017, APPL ECON, V49, P263, DOI 10.1080/00036846.2016.1197363
   Vail DM, 2000, CANCER INVEST, V18, P781, DOI 10.3109/07357900009012210
   Xie T, 2016, MOL BIOL EVOL, V33, P2368, DOI 10.1093/molbev/msw108
   Zaheer S, 2017, ANN SURG, V265, P916, DOI 10.1097/SLA.0000000000001878
   Zettel-Watson L, 2017, GERIATR GERONTOL INT, V17, P108, DOI 10.1111/ggi.12682
NR 20
TC 1
Z9 1
U1 2
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10639
EP 10654
DI 10.1007/s11042-019-08013-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600050
DA 2024-07-18
ER

PT J
AU Xu, YJ
   Mao, ZD
   Chen, ZN
   Wen, X
   Li, YY
AF Xu, Yajun
   Mao, Zhendong
   Chen, Zhineng
   Wen, Xin
   Li, Yangyang
TI Context propagation embedding network for weakly supervised semantic
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Weakly supervised; Semantic segmentation; Context propagation;
   High-quality visual cues
AB Weakly-supervised semantic segmentation with image-level labels has much significance as it facilitates related practical applications under lightweight manual annotations. Recent researches first infer the visual cues, referred as discriminative regions corresponding to each object category on images using deep convolutional classification networks. Then they expand visual cues to generate initial segmentation masks. Despite the remarkable progress, the segmentation performance still remains unsatisfactory due to the absence of complete visual cues. Using these low-quality visual cues as prior will have the limitation on improving segmentation performance. To overcome this problem, we propose a novel context propagation embedding network, i.e., the CPENet to generate high-quality visual cues, which focuses on learning semantic relationship between each region and its surrounding neighbors and selectively propagates discriminative information to non-discriminative, object related regions. Our methods can provide reliable initial segmentation masks for training subsequent segmentation network to generate final segmentation results. In addition, we refined convolutional block attention module (CBAM) [30] to hierarchically extract more category-aware features by capturing global context related information and further promote the propagation process. Experiments on benchmark demonstrate that our proposed method obtains superior performance over the state-of-the-arts.
C1 [Xu, Yajun; Wen, Xin] Chinese Acad Sci, Inst Informat Engn, Sch Cyber Secur, Beijing, Peoples R China.
   [Mao, Zhendong] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei, Peoples R China.
   [Chen, Zhineng] Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
   [Li, Yangyang] China Acad Elect & Informat Technol, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Chinese Academy of Sciences; University of
   Science & Technology of China, CAS; Chinese Academy of Sciences;
   Institute of Automation, CAS
RP Mao, ZD (corresponding author), Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei, Peoples R China.
EM xuyajun@iie.ac.cn; maozhendong2008@gmail.com; zhineng.chen@ia.ac.cn;
   wenxin@iie.ac.cn; yli@csdclab.net
RI chen, zhineng/AAD-6723-2020; Li, Yangyang/HTL-9531-2023
OI Li, Yangyang/0000-0001-5737-8678
FU National Natural Science Foundation of China
FX Zhendong Mao is the corresponding author. This work is supported by the
   National Natural Science Foundation of China (grants No.U19A2057).
CR Ahn J, 2018, PROC CVPR IEEE, P4981, DOI 10.1109/CVPR.2018.00523
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Dai JF, 2015, IEEE I CONF COMP VIS, P1635, DOI 10.1109/ICCV.2015.191
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Durand T., 2017, IEEE C COMP VIS PATT, V2
   Hong S, 2016, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR.2016.349
   Hong Seunghoon, 2017, Conference on Computer Vision and Pattern Recognition
   Huang ZL, 2018, PROC CVPR IEEE, P7014, DOI 10.1109/CVPR.2018.00733
   Jun F, 2018, ARXIV180902983180902
   Kolesnikov A, 2016, LECT NOTES COMPUT SC, V9908, P695, DOI 10.1007/978-3-319-46493-0_42
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Lee JH, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P149, DOI 10.1145/2702123.2702264
   Li KP, 2018, PROC CVPR IEEE, P9215, DOI 10.1109/CVPR.2018.00960
   Lin Di, 2016, P IEEE C COMP VIS PA
   Lu J, KNOWING LOOK ADAPTIV
   Pathak D, 2015, IEEE I CONF COMP VIS, P1796, DOI 10.1109/ICCV.2015.209
   Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780
   Qi XJ, 2016, LECT NOTES COMPUT SC, V9912, P90, DOI 10.1007/978-3-319-46484-8_6
   Saleh FS, 2018, IEEE T PATTERN ANAL, V40, P1382, DOI 10.1109/TPAMI.2017.2713785
   Saleh F, 2016, LECT NOTES COMPUT SC, V9912, P413, DOI 10.1007/978-3-319-46484-8_25
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song X, 2018, NEURAL COMPATIBILITY
   Song X, 2017, NEUROSTYLIST NEURAL
   Wang X, 2018, PROC CVPR IEEE, P1354, DOI 10.1109/CVPR.2018.00147
   Wei YC, 2018, PROC CVPR IEEE, P7268, DOI 10.1109/CVPR.2018.00759
   Wei YC, 2016, PATTERN RECOGN, V59, P234, DOI 10.1016/j.patcog.2016.01.015
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   Woo S., 2018, P EUR C COMP VIS ECC, DOI DOI 10.1007/978-3-030-01234-2_1
   Yang Z., STACKED ATTENTION NE
   Yuan Y, 2018, OCNET OBJECT CONTEXT
   Yunchao Wei, 2017, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P6488, DOI 10.1109/CVPR.2017.687
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 35
TC 1
Z9 3
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33925
EP 33942
DI 10.1007/s11042-020-08787-9
EA MAR 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000522592200005
DA 2024-07-18
ER

PT J
AU Xiao, GN
   Wang, RN
   Zhang, CQ
   Ni, AN
AF Xiao, Guangnian
   Wang, Ruinan
   Zhang, Chunqin
   Ni, Anning
TI Demand prediction for a public bike sharing program based on
   spatio-temporal graph convolutional networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-view data; Public bike sharing program; Demand prediction; Deep
   learning; Spatio-temporal graph convolutional network
ID SYSTEM
AB The operation of public bike sharing (PBS) programs has attracted attention again due to numerous problems encountered by free-floating bike sharing programs. These problems include malicious damage, theft, chaotic parking, large-scale deficit and bankruptcy. The short-time demand prediction is a key issue for the successful operation of PBS programs. In this study, we use a novel spatio-temporal graph convolutional network (STGCN) to predict the picking up/returning demand by exploring potential information from multi-view data. We apply graph convolutional neural networks (CNNs) to represent the spatial dependency based on the geographic information system data denoting the location of docks. Moreover, we use gated CNNs to denote the temporal dependency according to the time-series data representing the demand for picking up/returning public bikes. The STGCN and three recurrent neural network (RNN)-based competitors are trained and validated using the multi-view data from the Wenling PBS program for one month. The RNN-based competitors consist of the SimpleRNN, long short term memory and gated recurrent unit. Results show that the STGCN achieves higher prediction accuracy compared with its competitors. Although the STGCN consumes a longer training time compared with the SimpleRNN, it requires a minimal number of epochs to achieve convergence precision. The complete CNN structure in the STGCN can effectively address the spatial and temporal dependencies for PBS demand prediction.
C1 [Xiao, Guangnian; Wang, Ruinan] Shanghai Maritime Univ, Sch Econ & Management, 1550 Haigang Ave, Shanghai 201306, Peoples R China.
   [Xiao, Guangnian; Ni, Anning] Shanghai Jiao Tong Univ, Sch Naval Architecture Ocean & Civil Engn, 800 Dongchuan RD, Shanghai 200240, Peoples R China.
   [Zhang, Chunqin] Zhejiang Sci Tech Univ, Sch Civil Engn & Architecture, 928,2 St,Xiasha Higher Educ Pk, Hangzhou, Zhejiang, Peoples R China.
C3 Shanghai Maritime University; Shanghai Jiao Tong University; Zhejiang
   Sci-Tech University
RP Ni, AN (corresponding author), Shanghai Jiao Tong Univ, Sch Naval Architecture Ocean & Civil Engn, 800 Dongchuan RD, Shanghai 200240, Peoples R China.
EM nianning@sjtu.edu.cn
RI , 张春勤/ABE-1367-2020
OI zhang, chunqin/0000-0001-5257-1268
FU National Natural Science Foundation of China [71701125, 71901196];
   Shanghai Commission of Science and Technology [17692109300, 17DZ1204000]
FX This work was supported by the National Natural Science Foundation of
   China (71701125, 71901196) and Shanghai Commission of Science and
   Technology (17692109300, 17DZ1204000).
CR Ai Y, 2019, NEURAL COMPUT APPL, V31, P1665, DOI 10.1007/s00521-018-3470-9
   An J, 2018, MULTIMED TOOLS APPL, V77, P28991, DOI 10.1007/s11042-018-5992-7
   [Anonymous], 2019, SUSTAINABILITY BASEL, DOI DOI 10.3390/su11061539
   Bao J, 2018, IEEE ACCESS, V6, P76049, DOI 10.1109/ACCESS.2018.2883462
   Caggiani L, 2018, TRANSPORT RES C-EMER, V87, P159, DOI 10.1016/j.trc.2018.01.001
   Chai D, 2018, 26TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2018), P397, DOI 10.1145/3274895.3274896
   Chang PC, 2019, SOFT COMPUT, V23, P613, DOI 10.1007/s00500-017-2909-8
   Chen LB, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P841, DOI 10.1145/2971648.2971652
   Chmiel W, 2019, MULTIMED TOOLS APPL, V78, P4693, DOI 10.1007/s11042-018-6714-x
   de Chardon CM, 2015, TRANSPORT RES B-METH, V78, P260, DOI 10.1016/j.trb.2015.05.003
   Fishman E, 2016, TRANSPORT REV, V36, P92, DOI 10.1080/01441647.2015.1033036
   Gu TQ, 2019, TRANSPORT RES A-POL, V119, P122, DOI 10.1016/j.tra.2018.11.007
   Li YX, 2015, 23RD ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2015), DOI 10.1145/2820783.2820837
   MIAO Y, 2019, SUSTAINABILITY-BASEL, V11, DOI DOI 10.3390/su11082237
   Park MW, 2017, MULTIMED TOOLS APPL, V76, P25343, DOI 10.1007/s11042-017-4521-4
   Schuijbroek J, 2017, EUR J OPER RES, V257, P992, DOI 10.1016/j.ejor.2016.08.029
   Shaheen S. A., 2012, TECHNICAL REPORT
   Shen Y, 2018, INT J SUSTAIN TRANSP, V12, P686, DOI 10.1080/15568318.2018.1429696
   Si HY, 2019, J CLEAN PROD, V213, P415, DOI 10.1016/j.jclepro.2018.12.157
   TOBLER WR, 1970, ECON GEOGR, V46, P234, DOI 10.2307/143141
   Vogel P, 2011, LECT NOTES COMPUT SC, V6971, P127, DOI 10.1007/978-3-642-24264-9_10
   Wang D, 2019, IEEE T PATTERN ANAL, V41, P2466, DOI 10.1109/TPAMI.2018.2861000
   Xiao GN, 2019, IEEE ACCESS, V7, P116741, DOI 10.1109/ACCESS.2019.2936443
   Xiao GN, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719844156
   Xu L, 2019, RAIRO-OPER RES, V53, P1675, DOI 10.1051/ro/2018094
   Yahya BN, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9112070
   Yu B., 2017, ABS170904875 CORR
   Zhang JB, 2018, ARTIF INTELL-AMST, V259, P147, DOI 10.1016/j.artint.2018.03.002
   Zhang LH, 2015, J CLEAN PROD, V97, P124, DOI 10.1016/j.jclepro.2014.04.006
   Zhang Y, 2017, J TRANSP GEOGR, V58, P59, DOI 10.1016/j.jtrangeo.2016.11.014
   Zong F, 2019, IEEE T INTELL TRANSP, V20, P571, DOI 10.1109/TITS.2018.2816938
   Zong F, 2019, PHYSICA A, V515, P258, DOI 10.1016/j.physa.2018.09.090
NR 32
TC 54
Z9 56
U1 14
U2 80
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22907
EP 22925
DI 10.1007/s11042-020-08803-y
EA MAR 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000564403600001
DA 2024-07-18
ER

PT J
AU Zhang, C
   Wu, XP
   Gao, XP
AF Zhang, Chao
   Wu, Xiaopei
   Gao, Xiangping
TI An improved Gaussian mixture modeling algorithm combining foreground
   matching and short-term stability measure for motion detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Foreground modeling; Gaussian mixture modeling; Short-term stability
   measure; Motion detection
ID SEGMENTATION; RECOGNITION; BEHAVIOR; VIDEOS
AB Although deep learning has been successfully applied in image analysis, the conventional Gaussian Mixture Modeling (GMM) method still has great potential for multi-mode motion detection because it does not require the support of specialized hardware such as GPUs and massive training data. Under the framework of GMM, this paper combines foreground matching and short-term stability measure to detect slow-moving objects. Foreground models built and updated using the detected foreground pixels have the priority to match potential foreground in the incoming pixels. Meanwhile, the pixel-level stability is measured to make sure that an integrated foreground is detected when a dynamic foreground process is followed. The combination of foreground matching and short-term stability measure greatly improves GMM's tolerance to slow-moving objects. The quantitative evaluation demonstrates the effectiveness of the proposed algorithm to robustly detect slow-moving objects under a variety of real environments with distracting motions such as illumination changes.
C1 [Zhang, Chao; Wu, Xiaopei; Gao, Xiangping] Anhui Univ, Sch Comp Sci & Technol, Hefei 230601, Peoples R China.
C3 Anhui University
RP Wu, XP (corresponding author), Anhui Univ, Sch Comp Sci & Technol, Hefei 230601, Peoples R China.
EM 14042@ahu.edu.cn; liphci_ahu@163.com; 514207713@qq.com
CR Agaian SS, 2016, ELECT IMAGING, V15, P1
   [Anonymous], TENCON 2008 2008B IE
   [Anonymous], 2016, SENSORS BASEL, DOI DOI 10.3390/S16091528
   Bommes M, 2016, TRANSP RES PROC, V14, P4495, DOI 10.1016/j.trpro.2016.05.372
   Boulmerka A, 2018, IEEE T CIRC SYST VID, V28, P1330, DOI 10.1109/TCSVT.2017.2665970
   Burt Peter, 2000, VSAM final report, P1
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1014, DOI 10.1109/TCYB.2015.2419737
   Cao YZH, 2017, IEEE T IMAGE PROCESS, V26, P836, DOI 10.1109/TIP.2016.2621673
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chen CLZ, 2016, PATTERN RECOGN, V52, P410, DOI 10.1016/j.patcog.2015.09.033
   Cheng KW, 2015, IEEE T IMAGE PROCESS, V24, P5288, DOI 10.1109/TIP.2015.2479561
   Diego O, 2018, IEEE T CIRCUITS SYST, V29, P1645
   Haag M, 2000, IMAGE VISION COMPUT, V18, P137, DOI 10.1016/S0262-8856(99)00021-9
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Kaiming H, 2017, IEEE T PATTERN ANAL, V99, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar AN, 2015, J ELECTR ENG TECHNOL, V10, P372, DOI 10.5370/JEET.2015.10.1.372
   Kumar PMA, 2013, INT CONF RECENT, P551, DOI 10.1109/ICRTIT.2013.6844262
   Kumaran N, 2018, MULTIMED TOOLS APPL, V77, P23115, DOI 10.1007/s11042-017-5591-z
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Liu W, 2015, IET COMPUT VIS, V9, P13, DOI 10.1049/iet-cvi.2013.0242
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Onofri L, 2016, EXPERT SYST APPL, V63, P97, DOI 10.1016/j.eswa.2016.06.011
   Parekh H.S., 2014, INT J INNOVATIVE RES, V2, P2970
   Park JG, 2016, MEDIAT INFLAMM, V2016, DOI 10.1155/2016/1903849
   Puhan S., 2013, AM J SIGNAL PROCESS, V3, P121
   Rasouli A, 2018, IEEE T INTELL VEHICL, V3, P61, DOI 10.1109/TIV.2017.2788193
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sahoo PK, 2018, SIGNAL IMAGE VIDEO P, V12, P1265, DOI 10.1007/s11760-018-1278-9
   Sehairi K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.2.023025
   Shafiee MJ, 2017, 201705943 ARXIV
   Shafiee MJ, 2018, J SIGNAL PROCESS SYS, V90, P931, DOI 10.1007/s11265-017-1265-3
   Sivaraman S, 2013, IEEE T INTELL TRANSP, V14, P1773, DOI 10.1109/TITS.2013.2266661
   Song YM, 2014, INT CONF CONTR AUTO, P132, DOI 10.1109/ICCAIS.2014.7020544
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Tsai CL, 2013, J MAR SCI TECH-TAIW, V21, P639, DOI 10.6119/JMST-012-0829-3
   Utasi A., 2007, 2007 14th International Workshop in Systems, Signals and Image Processing and 6th EURASIP Conference focused on Speech and Image Processing, Multimedia Communications and Services - EC-SIPMCS 2007, P157, DOI 10.1109/IWSSIP.2007.4381177
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Wang HZ, 2005, INT CONF ACOUST SPEE, P1017
   Wang Y, 2017, PATTERN RECOGN LETT, V96, P66, DOI 10.1016/j.patrec.2016.09.014
   Wu M, 2018, NEUROCOMPUTING, V314, P120, DOI 10.1016/j.neucom.2018.03.001
   XIN B, 2015, PROC CVPR IEEE, V2015, P4676
   Xu Y, 2016, CAAI T INTELL TECHNO, V1, P43, DOI 10.1016/j.trit.2020.03.005
   Yan JH, 2017, J IMAGING SCI TECHN, V61, DOI 10.2352/J.ImagingSci.Technol.2017.61.2.020507
   Zhang G, 2016, INT J SIMULATION SYS, V17, P61
NR 48
TC 5
Z9 5
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7049
EP 7071
DI 10.1007/s11042-019-08210-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100007
DA 2024-07-18
ER

PT J
AU Pramanik, S
   Singh, RP
   Ghosh, R
AF Pramanik, Sabyasachi
   Singh, R. P.
   Ghosh, Ramkrishna
TI Application of bi-orthogonal wavelet transform and genetic algorithm in
   image steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Particle swarm optimization; Bi-orthogonal wavelet
   transform; Genetic algorithm; PSNR; Visual information fidelity
ID SCHEME
AB The Internet is used for exchanging information. Sometimes it is required to transmit confidential data over the internet. Here the authors use image steganography to embed confidential data within a cover image. To construct the technique, this article combines the help of Particle Swarm Optimization (PSO), Bi-Orthogonal Wavelet Transform (BWT) and Genetic Algorithm (GA). PSO is included to take the enhanced version of the host image. The enhanced version of the host images is more sharp and bright. Bi-Orthogonal Wavelet Transform is included to choose the selective sub-bands of the host image. Genetic Algorithm is used to select the fittest hidden image among a set of hidden images which are created after mutation. Later, the hidden image would produce a confidential password using an innovative technique. Thus an innovative technique of image steganography is introduced to transmit confidential data in a cover image. This combinational approach of image steganography is quite safe for confidential data transmission and really difficult for the attackers to retrieve the confidential data.
C1 [Pramanik, Sabyasachi] Haldia Inst Technol, Dept Comp Sci & Engn, Haldia, India.
   [Singh, R. P.] Sri Satya Sai Univ Technol & Med Sci, Dept Comp Sci & Engn, Sehore, Madhya Pradesh, India.
   [Ghosh, Ramkrishna] Haldia Inst Technol, Dept Informat Technol, Haldia, India.
C3 Haldia Institute of Technology; Haldia Institute of Technology
RP Pramanik, S (corresponding author), Haldia Inst Technol, Dept Comp Sci & Engn, Haldia, India.
EM sabyalnt@gmail.com
RI Pramanik, Sabyasachi/AAR-1342-2020
OI Pramanik, Sabyasachi/0000-0002-9431-8751
CR Amsaveni A., 2015, INT J INFORM COMMUNI, V7, P406
   Bedi P, 2013, COMPUT ELECTR ENG, V39, P640, DOI 10.1016/j.compeleceng.2012.12.021
   Chen L, 2017, MULTIMED TOOLS APPL, V76, P2467, DOI 10.1007/s11042-015-3145-9
   Fakhredanesh M, 2019, MULTIMED TOOLS APPL, V78, P18475, DOI 10.1007/s11042-019-7238-8
   Ghasemi E., 2012, LECT NOTES ELECT ENG, V110, P395, DOI [10.1007/978-1-4614-1695-1_30, DOI 10.1007/978-1-4614-1695-1_30]
   Gu XW, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0348-9
   Hemanth DJ, 2018, J INTELL FUZZY SYST, V35, P197, DOI 10.3233/JIFS-169580
   Hemanth DJ, 2016, OPEN PHYS, V14, P452, DOI 10.1515/phys-2016-0052
   Kaur S, 2017, P 5 INT C ADV ENG TE
   Kuar A, 2015, 1 INT C NEXT GEN COM, DOI [10.1109/NGCT.2015.7375269, DOI 10.1109/NGCT.2015.7375269]
   Kumar V, 2018, MULTIMED TOOLS APPL, V77, P13279, DOI 10.1007/s11042-017-4947-8
   Lima R., 2017, INT J COMPUT APPL, V164, P1, DOI 10.5120/ijca2017913686
   Maheswari SU, 2017, MULTIMED TOOLS APPL, V76, P415, DOI 10.1007/s11042-015-3035-1
   MK S., 2018, INT J ENG TECHNOLOGY, V7, P474, DOI [10.14419/ijet.v7i2.24.12139, DOI 10.14419/IJET.V7I2.24.12139]
   Newaj Bhuiyan SS., 2018, INDONES J ELECT ENG, V10, P569
   Nosrati M, 2015, INT C ADV COMPUT COM, P102, DOI 10.1109/ACCT.2015.57
   Pramanik S, 2014, INT J INNOVATIVE RES, V1, P17
   Pramanik S., 2013, Int J Comput Technol, V10, P1791, DOI [10.24297/ijct.v10i7.7027, DOI 10.24297/IJCT.V10I7.7027]
   Pramanik S, 2019, INDONESIAN J ELECT E, V14, P1412, DOI [10.11591/ijeecs.v13.i3.pp1412-1419, DOI 10.11591/IJEECS.V13.I3.PP1412-1419]
   Saidi M, 2017, MULTIMED TOOLS APPL, V76, P13493, DOI 10.1007/s11042-016-3722-6
   Soria-Lorente A, 2017, SECUR COMMUN NETW, DOI 10.1155/2017/5397082
   Sung JM, 2014, PROC SPIE, V9024, DOI 10.1117/12.2040990
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
NR 23
TC 12
Z9 12
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17463
EP 17482
DI 10.1007/s11042-020-08676-1
EA FEB 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516442400001
DA 2024-07-18
ER

PT J
AU Shukla, AK
   Pandey, RK
   Reddy, PK
AF Shukla, Anil K.
   Pandey, Rajesh K.
   Reddy, P. K.
TI Generalized fractional derivative based adaptive algorithm for image
   denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fractional calculus; Image denoising; Enhancement; Texture
ID PEPPER NOISE REMOVAL; MEDIAN FILTER; IMPULSE NOISE; MEAN FILTER; SALT;
   SELECTION; DENSITY; MODEL
AB This paper presents a new image denoising algorithm based on fractional filters. The fractional filters are derived using a newly introduced fractional operator. The proposed algorithm identifies the noisy pixels based on pixel-density and upgrades them by an adaptive fractional integral mask. To maintain the correlation and recover the lost information, the noise-free pixels are also processed by an adaptive fractional differential mask. We formulate the order function for the fractional mask with the help of gradient features and variance of the image. The algorithm is applied to standard images of different characteristics. The experimental results are compared with some other existing techniques. Evaluation parameters and visual perceptions show that the proposed method performs better than most of the discussed methods. The proposed approach is applicable for image denoising due to its applicability over different types of noises and denoising performance.
C1 [Shukla, Anil K.; Pandey, Rajesh K.; Reddy, P. K.] Indian Inst Technol BHU, Dept Math Sci, Varanasi 221005, Uttar Pradesh, India.
   [Pandey, Rajesh K.] Indian Inst Technol BHU, Ctr Adv Biomat & Tissue Engn, Varanasi 221005, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi); Indian Institute of
   Technology System (IIT System); Indian Institute of Technology BHU
   Varanasi (IIT BHU Varanasi)
RP Pandey, RK (corresponding author), Indian Inst Technol BHU, Dept Math Sci, Varanasi 221005, Uttar Pradesh, India.; Pandey, RK (corresponding author), Indian Inst Technol BHU, Ctr Adv Biomat & Tissue Engn, Varanasi 221005, Uttar Pradesh, India.
EM anil1shukla2@gmail.com; rkpandey.mat@iitbhu.ac.in
RI P, Krishna Reddy/JYO-4331-2024; SHUKLA, ANIL KUMAR/AAQ-7621-2021
OI Pandey, Rajesh K/0000-0002-5198-4340
CR Agrawal OP, 2010, COMPUT MATH APPL, V59, P1852, DOI 10.1016/j.camwa.2009.08.029
   [Anonymous], 2000, APPL FRACTIONAL CALC
   [Anonymous], 1981, Median filtering: statistical properties, DOI DOI 10.1007/BFB0057597
   [Anonymous], 2002, DIGITAL IMAGE PROCES
   [Anonymous], 1998, Fractional differential equations: an introduction to fractional derivatives, fractional differential equations, to methods of their solution and some of their applications
   Bai J, 2007, IEEE T IMAGE PROCESS, V16, P2492, DOI 10.1109/TIP.2007.904971
   Bai T, 2014, SIGNAL PROCESS, V102, P247, DOI 10.1016/j.sigpro.2014.03.023
   Bhatnagar G, 2013, INFORM SCIENCES, V223, P297, DOI 10.1016/j.ins.2012.09.053
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Chen PY, 2008, IEEE SIGNAL PROC LET, V15, P833, DOI 10.1109/LSP.2008.2005047
   Chen QQ, 2017, IET IMAGE PROCESS, V11, P709, DOI 10.1049/iet-ipr.2016.0692
   Cuesta E, 2012, SIGNAL PROCESS, V92, P553, DOI 10.1016/j.sigpro.2011.09.001
   Deng XY, 2016, PATTERN RECOGN LETT, V79, P8, DOI 10.1016/j.patrec.2016.04.019
   Dong FF, 2015, COMPUT MATH APPL, V70, P789, DOI 10.1016/j.camwa.2015.05.026
   Erkan U, 2018, COMPUT ELECTR ENG, V70, P789, DOI 10.1016/j.compeleceng.2018.01.019
   Erkan U, 2018, TURK J ELECTR ENG CO, V26, P162, DOI 10.3906/elk-1705-256
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   González-Hidalgo M, 2018, APPL SOFT COMPUT, V63, P167, DOI 10.1016/j.asoc.2017.11.030
   He N, 2015, SIGNAL PROCESS, V112, P180, DOI 10.1016/j.sigpro.2014.08.025
   Hu JR, 2011, J COMPUT, V6, P1332, DOI 10.4304/jcp.6.7.1332-1338
   Ibrahim H, 2008, IEEE T CONSUM ELECTR, V54, P1920, DOI 10.1109/TCE.2008.4711254
   Ieno E, 2016, IEEE LAT AM T, V14, P2120, DOI 10.1109/TLA.2016.7530404
   Jalab HA, 2015, SIGNAL PROCESS, V107, P340, DOI 10.1016/j.sigpro.2014.06.004
   Jayasree S, 2014, J VIS COMMUN IMAGE R, V25, P1349, DOI 10.1016/j.jvcir.2014.05.004
   Jin KH, 2018, IEEE T IMAGE PROCESS, V27, P1448, DOI 10.1109/TIP.2017.2771471
   Jin R, 2017, MULTIMED TOOLS APPL, V76, P5927, DOI 10.1007/s11042-015-2694-2
   Kalra GS, 2016, MULTIMED TOOLS APPL, V75, P4467, DOI 10.1007/s11042-015-2484-x
   Li B, 2016, NEUROCOMPUTING, V175, P704, DOI 10.1016/j.neucom.2015.10.115
   Li ZY, 2015, NEUROCOMPUTING, V159, P172, DOI 10.1016/j.neucom.2014.12.087
   Li ZY, 2014, PATTERN RECOGN LETT, V40, P113, DOI 10.1016/j.patrec.2013.12.022
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pu YF, 2010, IEEE T IMAGE PROCESS, V19, P491, DOI 10.1109/TIP.2009.2035980
   Samko SG, 1993, Fractional integral and derivatives, theory and applications
   Shaveta A., 2018, PATTERN RECOGN LETT, V139, P1
   Shukla AK, 2018, INT J PURE APPL MATH, V119, P5147
   Toh KKV, 2010, IEEE SIGNAL PROC LET, V17, P281, DOI 10.1109/LSP.2009.2038769
   Varatharajan R, 2018, COMPUT ELECTR ENG, V70, P447, DOI 10.1016/j.compeleceng.2017.05.035
   Vijaykumar VR, 2014, AEU-INT J ELECTRON C, V68, P1145, DOI 10.1016/j.aeue.2014.06.002
   Wang XT, 2016, J VIS COMMUN IMAGE R, V38, P440, DOI 10.1016/j.jvcir.2016.03.024
   Wang Y, 2016, IEEE SIGNAL PROC LET, V23, P1582, DOI 10.1109/LSP.2016.2607785
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang Q, 2016, FRACT CALC APPL ANAL, V19, P1222, DOI 10.1515/fca-2016-0063
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
   Yu JM, 2017, IEEE ACCESS, V5, P12275, DOI 10.1109/ACCESS.2017.2718558
   Zhang JW, 2017, MULTIMED TOOLS APPL, V76, P11471, DOI 10.1007/s11042-016-4214-4
   Zhang PX, 2014, IEEE SIGNAL PROC LET, V21, P1280, DOI 10.1109/LSP.2014.2333012
   Zhang XM, 2009, IEEE SIGNAL PROC LET, V16, P295, DOI 10.1109/LSP.2009.2014293
   Zheng YH, 2018, MULTIMED TOOLS APPL, V77, P30121, DOI 10.1007/s11042-018-6360-3
   Zhou HY, 2010, MULTIMED TOOLS APPL, V49, P447, DOI 10.1007/s11042-009-0443-0
NR 49
TC 8
Z9 8
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 14201
EP 14224
DI 10.1007/s11042-020-08641-y
EA FEB 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000516247600001
DA 2024-07-18
ER

PT J
AU Dawood, H
   Dawood, H
   Guo, P
   Mehmood, R
   Daud, A
   Alamri, A
   Alowibdi, JS
AF Dawood, Hussain
   Dawood, Hassan
   Guo, Ping
   Mehmood, Rashid
   Daud, Ali
   Alamri, Abdullah
   Alowibdi, Jalal S.
TI Probability weighted moments regularization based blind image
   De-blurring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind image de-blurring; Image regularization; Kernel estimation;
   Probability weighted moments
ID DECONVOLUTION; CAMERA
AB The main objective of blind image de-blurring is to recover a sharp image from a given blurry image. A good estimation of the kernel plays an important role in recovering a sharp image. However, if the local object textures are neglected when the kernel is being estimated, this can lead to over-smoothing or can produce a strong ringing effect. In this paper, a new image regularization term based on the Probability Weighted Moments (PWM) for kernel estimation is proposed named as Probability Weighted Moments Regularization (PWMR). PWMR has the ability to preserve the small local texture structure in an image while minimizing the artifacts. Further, it can preserve the better contrast information between neighboring pixels and their corresponding central pixels in a current sliding window; moreover, it has the ability to resist outliers even in a small sample size. The kernel estimated by PWMR is subsequently used to recover the sharp latent image. An extensive comparison of synthetic and real standard benchmark images indicates the effectiveness of PWMR compared to current state-of-the-art blind image de-blurring methods.
C1 [Dawood, Hussain] Univ Jeddah, Coll Comp Sci & Engn, Dept Comp & Network Engn, Jeddah, Saudi Arabia.
   [Dawood, Hassan] Univ Engn & Technol, Dept Software Engn, Taxila, Pakistan.
   [Guo, Ping] Beijing Normal Univ, Sch Syst Sci, Beijing, Peoples R China.
   [Mehmood, Rashid] Univ Kotli, Dept Software Engn, Azad Jammu Kashmir, Pakistan.
   [Daud, Ali] Int Islamic Univ, Dept Comp Sci & Software Engn, Islamabad, Pakistan.
   [Alamri, Abdullah; Alowibdi, Jalal S.] Univ Jeddah, Coll Comp Sci & Engn, Jeddah, Saudi Arabia.
C3 University of Jeddah; University of Engineering & Technology Taxila;
   Beijing Normal University; International Islamic University, Pakistan;
   University of Jeddah
RP Dawood, H (corresponding author), Univ Jeddah, Coll Comp Sci & Engn, Dept Comp & Network Engn, Jeddah, Saudi Arabia.
EM hdaoud@uj.edu.sa; hasandawod@yahoo.com; pguo@ieee.org;
   gulkhan007@gmail.com; ali.daud@iiu.edu.pk; amalamri@uj.cdu.sa;
   jalowibdi@uj.edu.sa
RI GUO, Ping/AAG-2160-2019; Daud, Ali/ABA-8422-2020; Dawood,
   Hassan/AAZ-8114-2021; Daud, Ali/ABD-4485-2020; Mehmood,
   Rashid/GLV-4450-2022; Dawood, Hussain/G-7453-2017
OI GUO, Ping/0000-0002-7122-1084; Daud, Ali/0000-0002-8284-6354; Dawood,
   Hassan/0000-0003-1355-6457; Mehmood, Rashid/0000-0002-3488-9413; Dawood,
   Hussain/0000-0003-2653-9541
CR [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], IET COMPUT VIS
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2006, EC QUALITY CONTROL
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Dawood H., 2012, Proceedings of the 2012 IEEE International Conference on Computer Science and Automation Engineering (CSAE 2012), P203, DOI 10.1109/CSAE.2012.6272939
   Dong JX, 2017, IEEE I CONF COMP VIS, P2497, DOI 10.1109/ICCV.2017.271
   DOWNTON F, 1966, BIOMETRIKA, V53, P129, DOI 10.1093/biomet/53.1-2.129
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Krishnan D., 2009, Adv Neural Inform Process Syst (NIPS), P1041
   Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521
   Lai WS, 2015, PROC CVPR IEEE, P64, DOI 10.1109/CVPR.2015.7298601
   Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2657, DOI 10.1109/CVPR.2011.5995308
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Lian J, 2018, MED BIOL ENG COMPUT, V56, P1107, DOI 10.1007/s11517-017-1743-6
   Michaeli T, 2014, LECT NOTES COMPUT SC, V8691, P783, DOI 10.1007/978-3-319-10578-9_51
   Muhammad F, 2008, J MOD APPL STAT METH, V7, P501
   Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180
   Perrone D, 2014, PROC CVPR IEEE, P2909, DOI 10.1109/CVPR.2014.372
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Singh D, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.1.013004
   Singh D, 2017, J MOD OPTIC, V64, P2165, DOI 10.1080/09500340.2017.1344736
   Tofighi M, 2018, IEEE SIGNAL PROC LET, V25, P273, DOI 10.1109/LSP.2017.2782570
   Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7
   Wipf David, 2013, Energy Minimization Methods in Computer Vision and Pattern Recognition. 9th International Conference, EMMCVPR 2013. Proceedings. LNCS 8081, P40, DOI 10.1007/978-3-642-40395-8_4
   Wipf D, 2014, J MACH LEARN RES, V15, P3595
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Yue T, 2014, LECT NOTES COMPUT SC, V8695, P79, DOI 10.1007/978-3-319-10584-0_6
   Zhang HC, 2013, PROC CVPR IEEE, P1051, DOI 10.1109/CVPR.2013.140
   Zhong L, 2013, PROC CVPR IEEE, P612, DOI 10.1109/CVPR.2013.85
   Zhou YP, 2014, LECT NOTES COMPUT SC, V8690, P142, DOI 10.1007/978-3-319-10605-2_10
   Zuo WM, 2016, IEEE T IMAGE PROCESS, V25, P1751, DOI 10.1109/TIP.2016.2531905
NR 36
TC 4
Z9 4
U1 5
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4483
EP 4498
DI 10.1007/s11042-019-7520-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500014
DA 2024-07-18
ER

PT J
AU Huang, MX
   Chen, Q
   Wang, H
AF Huang, Mengxing
   Chen, Qiong
   Wang, Hao
TI A multivariable optical remote sensing image feature discretization
   method applied to marine vessel targets recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote sensing image; Feature discretization; Vessel targets
   recognition; Information entropy; Rough set
ID CLASSIFICATION; SELECTION; ATTRIBUTES; PREDICTION; SALIENCY; ENTROPY;
   FUSION; SYSTEM
AB The effective extraction of continuous features in ocean optical remote sensing image is the key to achieve the automatic detection and identification for marine vessel targets. Since many of the existing data mining algorithms can only deal with discrete attributes, it is necessary to transform the continuous features into discrete ones for adapting to these intelligent algorithms. However, most of the current discretization methods do not consider the mutual exclusion within the attribute set when selecting breakpoints, and cannot guarantee that the indiscernible relationship of information system is not destroyed. Obviously, they are not suitable for processing ocean optical remote sensing data with multiple features. Aiming at this problem, a multivariable optical remote sensing image feature discretization method applied to marine vessel targets recognition is presented in this paper. Firstly, the information equivalent model of remote sensing image is established based on the theories of information entropy and rough set. Secondly, the change extent of indiscernible relationship in the model before and after discretization is evaluated. Thirdly, multiple scans are executed for each band until the termination condition is satisfied for generating the optimal number of intervals. Finally, we carry out the simulation analysis of the high-resolution remote sensing image data collected near the coast of South China Sea. In addition, we also compare the proposed method with the current mainstream discretization algorithms. Experiments validate that the proposed method has better comprehensive performance in terms of interval number, data consistency, running time, prediction accuracy and recognition rate.
C1 [Huang, Mengxing; Chen, Qiong] State Key Lab Marine Resource Utilizat South Chin, Haikou 570228, Hainan, Peoples R China.
   [Huang, Mengxing; Chen, Qiong] Hainan Univ, Coll Informat Sci & Technol, Haikou 570228, Hainan, Peoples R China.
   [Wang, Hao] Norwegian Univ Sci & Technol, Dept Comp Sci, Big Data Lab, N-2815 Gjovik, Norway.
C3 Hainan University; Norwegian University of Science & Technology (NTNU)
RP Huang, MX (corresponding author), State Key Lab Marine Resource Utilizat South Chin, Haikou 570228, Hainan, Peoples R China.; Huang, MX (corresponding author), Hainan Univ, Coll Informat Sci & Technol, Haikou 570228, Hainan, Peoples R China.
EM huangmx09@163.com
RI Wang, Hao/B-3650-2019
OI Wang, Hao/0000-0001-9301-5989
CR Ali Z, 2016, INT CONF FRONT INFO, P87, DOI [10.1109/FIT.2016.22, 10.1109/FIT.2016.024]
   CATLETT J, 1991, LECT NOTES ARTIF INT, V482, P164, DOI 10.1007/BFb0017012
   Chen HY, 2018, MULTIMED TOOLS APPL, V77, P3857, DOI 10.1007/s11042-016-4243-z
   Chen ZZ, 2017, IEEE GEOSCI REMOTE S, V14, P1076, DOI 10.1109/LGRS.2017.2697458
   Cheng JR, 2018, COMPUT J, V61, P959, DOI 10.1093/comjnl/bxy025
   Cheng JR, 2018, CMC-COMPUT MATER CON, V55, P95, DOI 10.3970/cmc.2018.055.095
   de Sá CR, 2016, INFORM SCIENCES, V329, P921, DOI 10.1016/j.ins.2015.04.022
   Di W, 2017, STUDY ASSESSMENT MET, P1
   FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1007/BF00994007
   García S, 2013, IEEE T KNOWL DATA EN, V25, P734, DOI 10.1109/TKDE.2012.35
   Grzymala-Busse JW, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18030069
   He X, 2014, CAN J ELECT COMPUT E, V37, P157, DOI 10.1109/CJECE.2014.2343258
   HEERMANN PD, 1992, IEEE T GEOSCI REMOTE, V30, P81, DOI 10.1109/36.124218
   Jin RM, 2009, KNOWL INF SYST, V19, P1, DOI 10.1007/s10115-008-0142-6
   Kaur J, 2017, CMC-COMPUT MATER CON, V53, P23
   Kumar DA, 2017, IEEE J-STARS, V10, P5201, DOI 10.1109/JSTARS.2017.2743982
   Lavangnananda K, 2017, INT CONF KNOWL SMART, P50, DOI 10.1109/KST.2017.7886082
   Lee CI, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 1, PROCEEDINGS, P472, DOI 10.1109/FSKD.2007.129
   Li WK, 2017, IEEE GEOSCI REMOTE S, V14, P936, DOI 10.1109/LGRS.2017.2688357
   Liu H, 2002, DATA MIN KNOWL DISC, V6, P393, DOI 10.1023/A:1016304305535
   Liu H, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P206, DOI 10.1109/ICMLC.2008.4620405
   Liu XJ, 2017, CHINA COMMUN, V14, P54, DOI 10.1109/CC.2017.8014347
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Morente-Molinera JA, 2017, IEEE T FUZZY SYST, V25, P1078, DOI 10.1109/TFUZZ.2016.2594275
   Ohsaki M, 2017, IEEE T KNOWL DATA EN, V29, P1806, DOI 10.1109/TKDE.2017.2682249
   Pai GAV, 2017, IEEE T FUZZY SYST, V25, P377, DOI 10.1109/TFUZZ.2016.2633972
   Patel V, 2018, 2018 CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION ENGINEERING SYSTEMS (SPACES), P171, DOI 10.1109/SPACES.2018.8316339
   Patra S, 2015, IEEE T GEOSCI REMOTE, V53, P5495, DOI 10.1109/TGRS.2015.2424236
   Pawlak Z, 1992, ROUGH SET THEORETICA
   Qi SX, 2015, IEEE GEOSCI REMOTE S, V12, P1451, DOI 10.1109/LGRS.2015.2408355
   Qi SX, 2013, IEEE GEOSCI REMOTE S, V10, P495, DOI 10.1109/LGRS.2012.2211094
   Qu W, 2008, 10 AS PAC WEB C, P560
   Ramírez-Gallego S, 2016, WIRES DATA MIN KNOWL, V6, P5, DOI 10.1002/widm.1173
   Ren L, 2018, IEEE ACCESS, V6, P13041, DOI 10.1109/ACCESS.2018.2804930
   Rosati S, 2015, IEEE INT SYM MED MEA, P297, DOI 10.1109/MeMeA.2015.7145216
   Schoyen H, 2017, TRANSNAV, V11, P265, DOI 10.12716/1001.11.02.08
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Stender DHS, 2017, CLASSIFICATION PERFO, P1
   Sun YH, 2015, CHINA COMMUN, V12, P76, DOI 10.1109/CC.2015.7315060
   Vieira S. M., 2010, 2010 IEEE International Conference on Fuzzy Systems, DOI 10.1109/FUZZY.2010.5584447
   Wang CY, 2018, MULTIMED TOOLS APPL, V77, P10615, DOI 10.1007/s11042-017-4686-x
   Wu B, 2014, IEEE T GEOSCI REMOTE, V52, P2593, DOI 10.1109/TGRS.2013.2263510
   Wu QY, 2012, IEEE T NANOBIOSCI, V11, P216, DOI 10.1109/TNB.2012.2214232
   Xie L, 2016, COMPUT GEOSCI-UK, V89, P252, DOI 10.1016/j.cageo.2015.12.015
   Xu XD, 2018, IEEE T GEOSCI REMOTE, V56, P937, DOI 10.1109/TGRS.2017.2756851
   Xu Y, 2015, IEEE GEOSCI REMOTE S, V12, P1795, DOI 10.1109/LGRS.2015.2427738
   Yan DQ, 2014, NEUROCOMPUTING, V133, P507, DOI 10.1016/j.neucom.2013.12.005
   Yildizel SA, 2016, CMC-COMPUT MATER CON, V52, P41
   Zeng DJ, 2018, CMC-COMPUT MATER CON, V55, P121, DOI 10.3970/cmc.2018.055.121
   Zhang GF, 2008, PROCEEDINGS OF THE 8TH INTERNATIONAL SYMPOSIUM ON SPATIAL ACCURACY ASSESSMENT IN NATURAL RESOURCES AND ENVIRONMENTAL SCIENCES, VOL II, P195
   Zheng R, 2009, APPL DISCRETIZATION, P1695
NR 51
TC 8
Z9 9
U1 2
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4597
EP 4618
DI 10.1007/s11042-019-07920-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500019
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Janney, B
   Roslin, SE
AF Janney J, Bethanney
   Roslin, S. Emalda
TI Classification of melanoma from Dermoscopic data using machine learning
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Melanoma; Image enhancement; Segmentation; Feature extraction; Machine
   learning
ID SKIN-CANCER; SEGMENTATION
AB Melanoma is a skin disorder, occurring in melanocytes. They are classified as Benign and Malignant. The cure of melanoma is effective, if it can be recognized early. The most crucial part in the cure of melanoma is the exact classification and determining the group of melanoma. A comparative study for classifying the group of melanoma using the supervised machine learning algorithms is discussed in this proposed work. Classification of melanoma from dermoscopic data is proposed to help the clinical utilization of dermatoscopy imaging methods for skin sores classification. The images were enhanced using anisotropic diffusion filter and unsharp masking. The melanoma was segmented from the background using adaptive k-means clustering algorithm with two clusters followed by feature extraction methods are based on intensity and texture features from the segmented data, which is followed by training of classifier and finally testing on unknown dermoscopic data. Classifiers such as k-nearest neighbour, support vector machine, multi-layer perceptron, decision tree and random forest were used. To test the performance of the classifiers, the area under the receiver operating characteristics curve (ROC) is utilized. The Random forest method is found to achieve 93% accuracy and classifies melanoma significantly good as compared to other classifiers.
C1 [Janney J, Bethanney; Roslin, S. Emalda] Sathyabama Inst Sci & Technol, Sch Elect & Elect, Chennai, Tamilnadu, India.
C3 Sathyabama Institute of Science & Technology
RP Janney, B (corresponding author), Sathyabama Inst Sci & Technol, Sch Elect & Elect, Chennai, Tamilnadu, India.
EM Jannydoll@gmail.com
RI s, emalda roslin/AAT-9092-2021; Roslin, Emalda/ABB-5162-2021; Janney J,
   Bethanney/AAO-7794-2020; Janney, Dr. Bethanney/KBQ-7400-2024
OI s, emalda roslin/0000-0001-8699-9510; Janney J,
   Bethanney/0000-0001-6367-1336; 
CR Almansour E, 2016, INT J COMPUT SCI NET, V16, P135
   Anas M., 2017, International Journal of Technical Research and Applications, V5, P62
   [Anonymous], 2017, CORR
   [Anonymous], COMPUT VISION PATTER
   [Anonymous], 2007, MULTIPLE CLASSIFIER
   [Anonymous], CORE PYTHON PROGRAMM
   [Anonymous], 2016, PRIME MINISTER ARCHI
   [Anonymous], AM J INTELLIGENT SYS
   [Anonymous], 2018, SCI REP-UK, DOI DOI 10.1038/S41598-018-19907-9
   [Anonymous], 6 INT C HUM SYST INT
   [Anonymous], SL CLIN MED ONCOL
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Bhatia SK, 2004, FLAIRS C, P695
   Breiman L., 2001, Mach. Learn., V45, P5
   Eltayef K, 2017, J PHYS CONF SER, V787, DOI 10.1088/1742-6596/787/1/012034
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   FALCIDIENO B, 1989, COMPUT VISION GRAPH, V48, P93, DOI 10.1016/0734-189X(89)90106-0
   Feng Y, 2016, J APPL CLIN MED PHYS, V17, P441, DOI 10.1120/jacmp.v17i2.5820
   Gautam D, 2018, INT J NUMER METH BIO, V34, DOI 10.1002/cnm.2953
   Gershenwald JE, 2017, CA-CANCER J CLIN, V67, P472, DOI 10.3322/caac.21409
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Jain S, 2015, PROCEDIA COMPUT SCI, V48, P735, DOI 10.1016/j.procs.2015.04.209
   Khalid S, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3211-4
   Li YX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020556
   Lu C, 2015, PATTERN RECOGN, V48, P2738, DOI 10.1016/j.patcog.2015.02.023
   Nasir M, 2018, MICROSC RES TECHNIQ, V81, P528, DOI 10.1002/jemt.23009
   National Toxicology Program, 2002, Rep Carcinog, V10, P250
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pennisi A, 2016, COMPUT MED IMAG GRAP, V52, P89, DOI 10.1016/j.compmedimag.2016.05.002
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Ping Hu, 2016, Proceedings of the SPIE, V10024, DOI 10.1117/12.2245149
   Polesel A, 2000, IEEE T IMAGE PROCESS, V9, P505, DOI 10.1109/83.826787
   Ruck D W, 1990, IEEE Trans Neural Netw, V1, P296, DOI 10.1109/72.80266
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Salerni G, 2013, J EUR ACAD DERMATOL, V27, P805, DOI 10.1111/jdv.12032
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Soh LK, 1999, IEEE T GEOSCI REMOTE, V37, P780, DOI 10.1109/36.752194
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Taha AA, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0068-x
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   van de Weijer J, 2006, LECT NOTES COMPUT SC, V3952, P334
   Victor A, 2017, BIOMED RES-INDIA, V28, P6947
   Zakeri A, 2018, BIOCYBERN BIOMED ENG, V38, P456, DOI 10.1016/j.bbe.2018.03.005
   Zhang H, 2008, COMPUT VIS IMAGE UND, V110, P260, DOI 10.1016/j.cviu.2007.08.003
   Zou KH, 2004, ACAD RADIOL, V11, P178, DOI 10.1016/S1076-6332(03)00671-8
NR 46
TC 16
Z9 17
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3713
EP 3728
DI 10.1007/s11042-018-6927-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700033
DA 2024-07-18
ER

PT J
AU Li, ZX
   Zhou, FQ
   Yang, L
   Li, XJ
   Li, J
AF Li, Zuoxin
   Zhou, Fuqiang
   Yang, Lu
   Li, Xiaojie
   Li, Juan
TI Accelerate neural style transfer with super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Style transfer; Neural network optimization; Image
   generation; Single image super-resolution
ID IMAGE QUALITY ASSESSMENT
AB Style transfer is a task of migrating a style from one image to another. Recently, Full Convolutional Network (FCN) is adopted to create stylized images and make it possible to perform style transfer in real-time on advanced GPUs. However, problems are still existing in memory usage and time-consumption when processing high-resolution images. In this work, we analyze the architecture of the style transfer network and divide it into three parts: feature extraction, style transfer, and image reconstruction. And a novel way is proposed to accelerate the style transfer operation and reduce the memory usage at run-time by conducting the super-resolution style transfer network (SRSTN), which can generate super-resolution stylized images. Compared with other style transfer networks, SRSTN can produce competitive quality resulting images with a faster speed as well as less memory usage.
C1 [Li, Zuoxin; Zhou, Fuqiang; Li, Xiaojie; Li, Juan] Beihang Univ, Beijing 100191, Peoples R China.
   [Yang, Lu] Beijing Univ Posts & Telecommun, Beijing 100876, Peoples R China.
C3 Beihang University; Beijing University of Posts & Telecommunications
RP Zhou, FQ (corresponding author), Beihang Univ, Beijing 100191, Peoples R China.
EM lizuoxin@buaa.edu.cn; zfq@buaa.edu.cn; soeaver@bupt.edu.cn;
   xiaojieli@buaa.edu.cn; sy1617314@buaa.edu.cn
RI Li, Zuoxin/AGU-9407-2022; yang, lu/GLV-5144-2022
OI Li, Zuoxin/0000-0003-4090-7726; 
CR Aly HA, 2005, IEEE T IMAGE PROCESS, V14, P1647, DOI 10.1109/TIP.2005.851684
   [Anonymous], 2011, P 2011 INT WORKSHOP
   [Anonymous], IEEE COMPUTER VISION
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen DD, 2017, PROC CVPR IEEE, P2770, DOI 10.1109/CVPR.2017.296
   Chen TQ, 2016, ARXIV161204337 CORR
   Collobert R, 2011, BIGLEARN NIPS WORKSH, P1
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   DUCHON CE, 1979, J APPL METEOROL, V18, P1016, DOI 10.1175/1520-0450(1979)018<1016:LFIOAT>2.0.CO;2
   Dumoulin V.., 2017, P INT C LEARN REPR I
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239546, 10.1145/1276377.1276496]
   Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Howard A., 2018, CVPR
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Jing YH, 2021, IEEE T CYBERNETICS, V51, P568, DOI 10.1109/TCYB.2019.2904768
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim J, 2016, IEEE CONF COMPUT
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Kingma D. P., 2014, arXiv
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li Z, 2017, ARXIV171200960 CORR
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W., 2016, ICLR
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Na Qi, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457926
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Odena A., 2016, DISTILL, V1, pe3, DOI 10.23915/distill.00003.-URL
   Ruder M, 2016, LECT NOTES COMPUT SC, V9796, P26, DOI 10.1007/978-3-319-45886-1_3
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Ulyanov D, 2016, PR MACH LEARN RES, V48
   Ulyanov D, 2017, PROC CVPR IEEE, P4105, DOI 10.1109/CVPR.2017.437
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiong ZW, 2010, IEEE T IMAGE PROCESS, V19, P2017, DOI 10.1109/TIP.2010.2045707
   Yang CY, 2014, P EUR C COMP VIS ECC
   Yang J, 2008, PROC CVPR IEEE, P173
   Yang JC, 2013, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2013.141
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhang H, 2017, ARXIV170306953 CORR
   Zhou FQ, 2018, NEUROCOMPUTING, V290, P34, DOI 10.1016/j.neucom.2018.02.027
NR 48
TC 8
Z9 8
U1 1
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4347
EP 4364
DI 10.1007/s11042-018-6929-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500007
DA 2024-07-18
ER

PT J
AU Manikandan, R
   Saravanan, V
AF Manikandan, R.
   Saravanan, V.
TI A novel approach on Particle Agent Swarm Optimization (PASO) in semantic
   mining for web page recommender system of multimedia data: a health care
   perspective
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web usage mining; Semantic web; Ontology; Web page recommendation; Page
   clustering; Particle Agent Swarm Optimization (PASO)
ID USAGE
AB Recent decades have seen huge amounts of information collected in clinical databases for mining patients' health states from multimedia data. Since on the web diverse type of web recommendation is made obtainable toward user every day with the purpose of consists of Image, Video, Audio, query suggestion and web page. Therefore, multimedia data accessible designed for patient-oriented decision making has improved significantly however is often scattered across various sites. In this perspective, Web page recommender systems with multimedia data might provide patients with further laymen-friendly information helping toward enhanced understand their health status as represented by their record. In this research work, Web Page health recommender systems are introduced via the use of certain agents in order to provide extremely appropriate web pages for patients. The main feature of Particle Agent Swarm Optimization (PASO) is that the creation of the algorithm is denoted by a set of Particle agents who cooperate in attaining the objective of the task under consideration. In the research method, two kinds of agents are presented: web user particle agent and semantic particle agent. PASO Based Web Page Recommendation (PASO-WPR) system is an intermediate program (or a particle agent) containing a user interface, which wisely produces a collection of info that suits an individual's requirements. PASO-WPR is carried out dependent upon incorporating semantic info with data mining techniques on the web usage data as well as clustering of pages dependent upon similarity in their semantics. As the Web pages with multimedia files are viewed as ontology individuals, the pattern of patients' navigation are like instances of ontology rather than the uniform resource locators, and with the help of semantic similarity, page clustering is carried out. For producing web page recommendations to users, the outcome is utilized. The recommender engine concentrates on the semantic info and as well exploits a particle agent to reform the outcomes of web pages recommendation. Consequently, the system response time is enhanced and as a result, creating the framework scalable. The outcomes recommend that the PASO-WPR system is improved in identifying the web page that a user is about to request while matched up other approaches. The outcome proves that the presented PASO-WPR system is carried out well in regard to the accuracy measures aspects such as accuracy, coverage and M-Metric are identified to contain greater values compared to the previous item based collaborative filtering recommendation systems.
C1 [Manikandan, R.] Anna Univ, Chennai, Tamil Nadu, India.
   [Saravanan, V.] Sri Venkateswara Coll Comp Applicat & Management, Dept Comp Applicat, Coimbatore, Tamil Nadu, India.
C3 Anna University; Anna University Chennai
RP Manikandan, R (corresponding author), Anna Univ, Chennai, Tamil Nadu, India.
EM mani4gift@gmail.com
RI R, Dr. Manikandan/IUH-0603-2023; Venkataraman, Saravanan/M-5757-2015
OI R, Dr. Manikandan/0000-0001-7915-0180; Venkataraman,
   Saravanan/0000-0002-0854-0269
CR Abrishami S, 2012, LECT NOTES COMPUT SC, V7710, P393, DOI 10.1007/978-3-642-35386-4_29
   [Anonymous], ARXIV13117204
   [Anonymous], 2010, PARTICLE SWARM OPTIM
   [Anonymous], 2011, HDB SEMANTIC WEB TEC
   Bari Pranit., 2013, Journal of Engineering Computers Applied Sciences, V2, P34
   Batmaz Z, 2019, ARTIF INTELL REV, V52, P1, DOI 10.1007/s10462-018-9654-y
   Berendt B, 2004, LECT NOTES COMPUT SC, V3209, P1
   Bratton D, 2007, 2007 IEEE SWARM INTELLIGENCE SYMPOSIUM, P120, DOI 10.1109/SIS.2007.368035
   Cooley R., 1999, Knowledge and Information Systems, V1, P5
   Du K.-L., 2016, Search and optimization by metaheuristics, P153, DOI [10.1007/978-3-319-41192-7, DOI 10.1007/978-3-319-41192-7]
   Etminani K., 2010, 2010 5th International Symposium on Telecommunications (IST), P1013, DOI 10.1109/ISTEL.2010.5734169
   Frikha M, 2015, ADCAIJ-ADV DISTRIB C, V4, P90
   GARNAUT R, 1992, ECONOMIC REFORM AND INTERNATIONALISATION: CHINA AND THE PACIFIC REGION, P1
   Göksedef M, 2007, LECT NOTES ARTIF INT, V4632, P287
   Göksedef M, 2010, EXPERT SYST APPL, V37, P2911, DOI 10.1016/j.eswa.2009.09.046
   Gulzar Z, 2018, PROCEDIA COMPUT SCI, V125, P518, DOI 10.1016/j.procs.2017.12.067
   Havens TC, 2012, IEEE T FUZZY SYST, V20, P1130, DOI 10.1109/TFUZZ.2012.2201485
   Jin X, 2005, ITCC 2005: International Conference on Information Technology: Coding and Computing, Vol 1, P213
   Johnson Faustina., 2012, International Journal of Computer Applications, V47, P44, DOI 10.5120/7236-0266
   Kumar V, 2012, SCI WORLD J, P1, DOI 10.1100/2012/127014
   Li J, 2004, LECT NOTES COMPUT SC, V3182, P305
   Mobasher B., 2007, WEB DATA MINING EXPL, P449, DOI DOI 10.1007/978-3-540-37882-2_12
   Mohr G, 2004, 4 INT WEB ARCH WORKS, P109
   Rani M, 2015, KNOWL-BASED SYST, V90, P33, DOI 10.1016/j.knosys.2015.10.002
   Rettinger A, 2012, DATA MIN KNOWL DISC, V24, P613, DOI 10.1007/s10618-012-0253-2
   Román PE, 2010, STUD COMPUT INTELL, V311, P143
   Schlicht A, 2007, K-CAP'07: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON KNOWLEDGE CAPTURE, P171
   Senkul P, 2012, KNOWL INF SYST, V30, P527, DOI 10.1007/s10115-011-0386-4
   Stumme G, 2006, J WEB SEMANT, V4, P124, DOI 10.1016/j.websem.2006.02.001
   Thangaraj M, 2014, INT J ADV COMPUT SC, V5, P103
   Nguyen TTS, 2014, IEEE T KNOWL DATA EN, V26, P2574, DOI 10.1109/TKDE.2013.78
   Xu GD, 2011, WEB INF SYST ENG INT, P3, DOI 10.1007/978-1-4419-7735-9
   Zhang LM, 2015, APPL SOFT COMPUT, V28, P138, DOI 10.1016/j.asoc.2014.11.018
   Zhang SH, 2007, PHYSICA A, V374, P483, DOI 10.1016/j.physa.2006.07.023
NR 34
TC 10
Z9 11
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3807
EP 3829
DI 10.1007/s11042-018-7141-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700039
DA 2024-07-18
ER

PT J
AU Zaniolo, L
   Marques, O
AF Zaniolo, Luiz
   Marques, Oge
TI On the use of variable stride in convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Image classification; Variable stride;
   Deep learning; Machine learning
ID CNN; SEGMENTATION; RECOGNITION
AB This paper explores the idea of changing the stride value in convolutional neural networks depending on the position of the pixel within the image: a smaller stride value is used when processing the center of the image, while a larger one is used for pixels close to the edges. We show several examples of image classification tasks where the proposed approach outperforms a baseline solution of same computational cost using fixed stride and several counterexamples where it does not - and explain why this is so. The proposed method has been successfully tested using several contemporary datasets and can be easily implemented and extended to other image classification tasks.
C1 [Zaniolo, Luiz; Marques, Oge] Florida Atlantic Univ, 777 Glades Rd, Boca Raton, FL 33431 USA.
C3 State University System of Florida; Florida Atlantic University
RP Marques, O (corresponding author), Florida Atlantic Univ, 777 Glades Rd, Boca Raton, FL 33431 USA.
EM lzaniolo@fau.edu; omarques@fau.edu
OI Marques, Tiffany/0000-0001-6662-7998
CR [Anonymous], CoRR abs/1511.07122
   Bengio Yoshua, 2012, P ICML WORKSH UNS TR, P17
   BROCK A, 2016, ARXIV160907093 CORR
   Chandra S, 2016, LECT NOTES COMPUT SC, V9911, P402, DOI 10.1007/978-3-319-46478-7_25
   Chen L, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278067
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Cheng ZY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3748
   Dai JF, 2015, PROC CVPR IEEE, P3992, DOI 10.1109/CVPR.2015.7299025
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Gao Z, 2018, J VIS COMMUN IMAGE R, V56, P305, DOI 10.1016/j.jvcir.2018.10.007
   Gao Z, 2018, IEEE ACCESS, V6, P68989, DOI 10.1109/ACCESS.2018.2878313
   Guo C, 2019, MULTIMED TOOLS APPL, V78, P30027, DOI 10.1007/s11042-018-6861-0
   Hariharan B, 2017, IEEE T PATTERN ANAL, V39, P627, DOI 10.1109/TPAMI.2016.2578328
   Jaderberg M, 2015, ADV NEUR IN, V28
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Milletari F, 2017, COMPUT VIS IMAGE UND, V164, P92, DOI 10.1016/j.cviu.2017.04.002
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Xiao H., 2017, ARXIV170807747
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhou BL, 2014, ADV NEUR IN, V27
NR 27
TC 8
Z9 10
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13581
EP 13598
DI 10.1007/s11042-019-08385-4
EA JAN 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515798800003
DA 2024-07-18
ER

PT J
AU Subramani, B
   Veluchamy, M
AF Subramani, Bharath
   Veluchamy, Magudeeswaran
TI A fast and effective method for enhancement of contrast resolution
   properties in medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Histogram; Clipping; Exposure; Brightness preservation; Contrast
ID BI-HISTOGRAM EQUALIZATION; SCHEME
AB In medical imaging, the poor quality image specifically the low contrast image may deliver inadequate data for the visual interpretation of affected portions. Hence, a combined approach called exposure based contrast limited bi-histogram equalization method is proposed to improve the visual quality of medical images. The proposed method has three stages: At first, input histogram is sub-divided into two histograms based on the exposure threshold to preserve mean brightness and strengthen the fine details. Then, the two sub histograms are clipped to limit the contrast amplification and a new dynamic range is assigned to each clipped sub-histogram by its exposure threshold value. At last, a contrast-enhanced image is gained by equalizing each clipped sub-histogram individually. Experiments were conducted on a wide variety of medical images to evaluate the performance of proposed method both qualitatively and quantitatively. Extensive quantitative measures show that the proposed technique achieves better performance in terms of peak signal to noise ratio, entropy, contrast ratio, enhancement measures and computational complexity when compared to state of art enhancement methods. The proposed algorithm improves contrast while preserving brightness and visual quality. The proposed method provides better quality for disease examination and diagnosis.
C1 [Subramani, Bharath; Veluchamy, Magudeeswaran] PSNA Coll Engn & Technol, Dept Elect & Commun Engn, Dindigul 624622, Tamil Nadu, India.
C3 PSNA College of Engineering & Technology
RP Subramani, B (corresponding author), PSNA Coll Engn & Technol, Dept Elect & Commun Engn, Dindigul 624622, Tamil Nadu, India.
EM bharath.psna@psnacet.edu.in; magudeeswaran@psnacet.edu.in
RI Subramani, Bharath/AAM-9681-2020; Veluchamy, Magudeeswaran/O-6428-2016;
   Veluchamy, Magudeeswaran/AAS-1568-2020
OI Subramani, Bharath/0000-0001-8989-9320; Veluchamy,
   Magudeeswaran/0000-0001-6427-1094; Veluchamy,
   Magudeeswaran/0000-0002-7260-7608
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   Al-Ameen Z, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0214-1
   [Anonymous], 2013, INT J INNOV RES ELEC
   Aquino-Morínigo PB, 2017, SIGNAL IMAGE VIDEO P, V11, P857, DOI 10.1007/s11760-016-1032-0
   Benson CC, 2014, 2014 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING APPLICATIONS (ICICA 2014), P254, DOI 10.1109/ICICA.2014.61
   Chaira T, 2014, APPL SOFT COMPUT, V25, P293, DOI 10.1016/j.asoc.2014.09.004
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Deng H, 2017, IEEE T BIO-MED ENG, V64, P1803, DOI 10.1109/TBME.2016.2624306
   Gambino O, 2011, IEEE ENG MED BIO, P5040, DOI 10.1109/IEMBS.2011.6091248
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Magudeeswaran V, 2017, INT J IMAG SYST TECH, V27, P98, DOI 10.1002/ima.22214
   Ooi CH, 2009, IEEE T CONSUM ELECTR, V55, P2072, DOI 10.1109/TCE.2009.5373771
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Satheesh S., 2011, Proceedings of 2011 International Conference on Computer Science and Network Technology, P2627
   Sengee N, 2008, IEEE T CONSUM ELECTR, V54, P1329, DOI 10.1109/TCE.2008.4637624
   Shakeri M, 2017, DIGIT SIGNAL PROCESS, V62, P224, DOI 10.1016/j.dsp.2016.10.013
   Singh K, 2014, OPTIK, V125, P4646, DOI 10.1016/j.ijleo.2014.04.093
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Tang JR, 2017, APPL SOFT COMPUT, V55, P31, DOI 10.1016/j.asoc.2017.01.053
   Tang JR, 2014, COMPUT ELECTR ENG, V40, P86, DOI 10.1016/j.compeleceng.2014.05.017
   Wang XW, 2017, SIGNAL PROCESS-IMAGE, V58, P187, DOI 10.1016/j.image.2017.07.009
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wang Y, 2017, INFRARED PHYS TECHN, V86, P59, DOI 10.1016/j.infrared.2017.08.005
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Zhao CY, 2019, BIOMED SIGNAL PROCES, V48, P189, DOI 10.1016/j.bspc.2018.10.008
   Zhu YL, 2012, PHYSCS PROC, V25, P601, DOI 10.1016/j.phpro.2012.03.132
NR 30
TC 15
Z9 15
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7837
EP 7855
DI 10.1007/s11042-019-08521-0
EA JAN 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000505356600004
DA 2024-07-18
ER

PT J
AU Gu, Q
   Cao, J
   Liu, YC
AF Gu, Qi
   Cao, Jian
   Liu, Yancen
TI Entity resolution for media metadata based on structural clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Entity resolution; Structural clustering; Iterative propagation; Graph
   structure
AB An increasing amount of media metadata are published by different organizations on the Web which leads to a fragmented dataset landscape. Identifying media metadata from disparate datasets and integrating heterogeneous datasets have many applications but also pose significant challenges. To tackle this problem, entity resolution methods are commonly used as an essential prerequisite for integrating media information from different sources and effectively foster the re-use of existing data sources. While the amount of media metadata published on the Web grows steadily, how to scale it well to large media knowledge bases while maintaining a high matching quality is a critical challenge. This article investigates the relationships between media entities. To that end, the media database is formulated as a knowledge graph with entities as nodes and the associations between related entities as edges. Thus, media entities are grouped into communities by how they share neighbors. Then, a structural clustering-based model is proposed to detect communities and discover anchor vertices as well as isolated vertices. Specifically, an initial seed set of matched anchor vertex pairs is obtained. Furthermore, an iterative propagation approach for identifying the matched entities in the whole graph is developed, where community similarity is introduced into the measure function to control the total measurement of candidate pairs. Therefore, starting with the elements of the initial seed set, the entity resolution algorithm updates the matching information over the whole network along with the neighbor relationships iteratively. Extensive experiments are conducted on real datasets to evaluate how the seed set impacts the matching process and performance. The experiment results show this model can achieve an excellent balance between accuracy and efficiency and is a clear improvement compared to state-of-the-art methods.
C1 [Gu, Qi; Cao, Jian; Liu, Yancen] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Sch Elect Informat & Elect Engn, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
   [Gu, Qi] Nantong Univ, Sch Informat Sci & Technol, Dept Comp Sci, 9 Seyuan Rd, Nantong 226019, Peoples R China.
C3 Shanghai Jiao Tong University; Nantong University
RP Cao, J (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Sch Elect Informat & Elect Engn, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
EM guqi@sjtu.edu.cn; cao-jian@sjtu.edu.cn; LiuYancen@sjtu.edu.cn
FU National Key Research and Development Plan [2018YFB1003800]
FX This work is partially supported by National Key Research and
   Development Plan (No. 2018YFB1003800).
CR [Anonymous], 2011, 22 INT JOINT C ART I, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-385
   Balduzzi M, 2010, LECT NOTES COMPUT SC, V6307, P422, DOI 10.1007/978-3-642-15512-3_22
   Bates S, 2005, IEEE PACIF, P85
   Baxter R., 2003, ACM SIGKDD 03 WORKSH, P25, DOI DOI 10.1007/978-3-319-11257-2
   Bhattacharya I., 2007, ACM T KNOWL DISCOV D, V1, P1, DOI [10.1145/1217299.1217304, DOI 10.1145/1217299.1217304]
   Christen P, 2012, IEEE T KNOWL DATA EN, V24, P1537, DOI 10.1109/TKDE.2011.127
   Doan A, 2005, AI MAG, V26, P83
   Elmagarmid AK, 2007, IEEE T KNOWL DATA EN, V19, P1, DOI 10.1109/TKDE.2007.250581
   FELLEGI IP, 1969, J AM STAT ASSOC, V64, P1183, DOI 10.2307/2286061
   Getoor L, 2012, PROC VLDB ENDOW, V5, P2018, DOI 10.14778/2367502.2367564
   Gu Q, 2014, 2014 INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED ANALYTICS (DSAA), P97, DOI 10.1109/DSAA.2014.7058058
   He JL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0145283
   Jain P., 2012, ARXIV12126147
   Jeh G., 2002, PROC 8 ACM SIGKDD IN, P538
   Jentzsch A., P 9 INT SEM WEB C IS
   Korula N, 2014, PROC VLDB ENDOW, V7, P377, DOI 10.14778/2732269.2732274
   Lacoste-Julien S, ACM SIGKDD INT C KNO, P572
   Lacoste-Julien S, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P572
   Lee T, 2017, 2017 IEEE INTERNATIONAL SYMPOSIUM ON SYSTEMS ENGINEERING (ISSE 2017), P245
   Li JZ, 2013, KNOWL-BASED SYST, V50, P112, DOI 10.1016/j.knosys.2013.06.004
   Livi L, 2013, PATTERN ANAL APPL, V16, P253, DOI 10.1007/s10044-012-0284-8
   Mahdisoltani F., 2014, P 7 BIENN C INN DAT
   Narayanan A, 2009, P IEEE S SECUR PRIV, P173, DOI 10.1109/SP.2009.22
   Otero-Cerdeira L, 2015, EXPERT SYST APPL, V42, P949, DOI 10.1016/j.eswa.2014.08.032
   Papadakis G, 2016, PROC VLDB ENDOW, V9, P684
   Shao C, 2016, J COMPUT SCI TECH-CH, V31, P185, DOI 10.1007/s11390-016-1620-z
   Shu K., 2017, ACM SIGKDD Explor. Newslett, V18, P5, DOI 10.1145/3068777.3068781
   Suchanek FM, 2011, PROC VLDB ENDOW, V5, P157, DOI 10.14778/2078331.2078332
   Xu XW, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P824, DOI 10.1145/1281192.1281280
   Yu MH, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P21
   Zhang YT, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1485, DOI 10.1145/2783258.2783268
   Zhu H, 2017, IEEE IND ELEC, P6425, DOI 10.1109/IECON.2017.8217119
NR 32
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 219
EP 242
DI 10.1007/s11042-019-08062-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600010
DA 2024-07-18
ER

PT J
AU Chang, JW
   Chiou, CY
   Liao, JY
   Hung, YK
   Huang, CC
   Lin, KC
   Pu, YH
AF Chang, Jia-Wei
   Chiou, Ching-Yi
   Liao, Jia-Yi
   Hung, Ying-Kai
   Huang, Chien-Che
   Lin, Kuan-Cheng
   Pu, Ying-Hung
TI Music recommender using deep embedding-based features and behavior-based
   reinforcement learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music recommendation; Content based recommendation; Reinforcement
   learning
ID ARTIFICIAL NEURAL-NETWORK; CLASSIFICATION
AB With the rapid increase of digital music on online music platforms, it has become difficult for users to find unknown but interesting songs. Although many collaborative filtering or content based recommendation methods have been proposed, they have various relatively serious some problems, including cold start, diversity of recommendations. etc. Therefore, we propose a reinforcement personal music recommendation system (RPMRS) to address these problems. RPMRS comprises two main components. First, deep representation of audio and lyrics extracted by WaveNet and Word2Vec models, respectively, and apply a proposed content based recommendation method from these. Second, we employ reinforcement learning is to learn user preferences from their song playing log. Experimental results confirm, that hybrid features are superior to audio or lyrics based features for content recommendation, largely because independent audio features significantly outperform lyrics features; and reinforcement learning improves personalized recommendations. Overall, the proposed RPMRS provides dynamic and personalized music recommendations for the user.
C1 [Chang, Jia-Wei; Liao, Jia-Yi; Hung, Ying-Kai] Natl Taichung Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
   [Huang, Chien-Che] Natl Taichung Univ Sci & Technol, Dept Leisure & Recreat Management, Taichung, Taiwan.
   [Pu, Ying-Hung] Natl Taichung Univ Sci & Technol, Coll Languages, Taichung, Taiwan.
   [Chiou, Ching-Yi; Lin, Kuan-Cheng] Natl Chung Hsing Univ, Dept Informat Management, Taichung, Taiwan.
C3 National Taichung University of Science & Technology; National Taichung
   University of Science & Technology; National Taichung University of
   Science & Technology; National Chung Hsing University
RP Pu, YH (corresponding author), Natl Taichung Univ Sci & Technol, Coll Languages, Taichung, Taiwan.
EM yinghong.pu@gmail.com
RI Huang, Charles/ABI-3072-2020; Chang, Jia-Wei/AEA-7852-2022
OI Huang, Charles/0000-0001-5927-7918; Chang, Jia-Wei/0000-0002-9321-6278
FU Ministry of Science and Technology, Taiwan, R.O.C. [MOST
   108-2218-E-025-002-MY3, MOST 108-2218-E-001-001]
FX This work was supported by the Ministry of Science and Technology,
   Taiwan, R.O.C. [grant number MOST 108-2218-E-025-002-MY3], [grant number
   MOST 108-2218-E-001-001].
CR Chang JW, 2016, COMPUT IND, V78, P29, DOI 10.1016/j.compind.2015.10.007
   Chang JW, 2017, COMPUT ASSIST LANG L, V30, P44, DOI 10.1080/09588221.2016.1241806
   Cheng ZY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P655, DOI 10.1145/3077136.3080772
   Choi K, 2018, ACM-IEEE J CONF DIG, P327, DOI 10.1145/3197026.3203883
   Delbouys Remi., 2018, P 19 INT SOC MUS INF, P370
   Engel J. H., 2017, P INT C MACH LEARN, V70, P1068
   Gao HJ, 2015, AAAI CONF ARTIF INTE, P1721
   Huang JW, 2018, ENG APPL ARTIF INTEL, V75, P11, DOI 10.1016/j.engappai.2018.07.010
   Huang PS, 2019, J INTERNET TECHNOL, V20, P839, DOI 10.3966/160792642019052003017
   Hurley N, 2011, ACM T INTERNET TECHN, V10, DOI 10.1145/1944339.1944341
   Iyyer M, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1681
   Kim YoungmooE., 2010, Proceedings of the 11th International Society for Music Information Retrieval Conference (ISMIR 2010), P255
   King J, 2015, ESSAYS IN CONVEYANCING AND PROPERTY LAW IN HONOUR OF PROFESSOR ROBERT RENNIE, P317, DOI 10.11647/OBP.0056.16
   Lee MC, 2014, SCI WORLD J, DOI 10.1155/2014/437162
   Li T., 2003, Detecting emotion in music
   Logan B, 2004, MUSIC RECOMMENDATION, P425
   Lu ZQ, 2015, AAAI CONF ARTIF INTE, P217
   Ma CY, 2015, INTERNATIONAL CONFERENCE ON MECHANICS AND CONTROL ENGINEERING (MCE 2015), P295
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Mokhsin MB, 2014, FRONT ARTIF INTEL AP, V265, P3, DOI 10.3233/978-1-61499-434-3-3
   Peeters G, 2008, P INT C MUS INF RETR
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Soares M, 2015, MULTIMED TOOLS APPL, V74, P7015, DOI 10.1007/s11042-014-1950-1
   Srivihok A, 2005, SEVENTH INTERNATIONAL CONFERENCE ON ELECTRONIC COMMERCE, VOLS 1 AND 2, SELECTED PROCEEDINGS, P287
   Taghipour N, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P1164
   Tzanetakis G, 2007, P INT C MUS INF RETR
   Van Den Oord A, 2016, 125 SSW
   Wang XX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P627, DOI 10.1145/2647868.2654940
   Watkins C. J. C. H., 1989, Learning from Delayed Rewards
   Yeh CH, 2014, MULTIMED TOOLS APPL, V73, P2103, DOI 10.1007/s11042-013-1687-2
   Zhao XY, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1040, DOI 10.1145/3219819.3219886
   Zheng GJ, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P167, DOI 10.1145/3178876.3185994
NR 32
TC 10
Z9 11
U1 2
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34037
EP 34064
DI 10.1007/s11042-019-08356-9
EA DEC 2019
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000504481300001
DA 2024-07-18
ER

PT J
AU Kordatos, G
   Stavrakis, M
AF Kordatos, George
   Stavrakis, Modestos
TI Design and evaluation of a wearable system to increase adherence to
   rehabilitation programmes in acute cruciate ligament (CL) rupture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wearable health technologies; Smart wearables; mHealth; Cruciate
   ligament rupture; Rehabilitation; Monitoring; Self-efficacy; Home
   exercise programmes
ID ANTERIOR; EXERCISE; RECOMMENDATIONS; ACCEPTANCE; MANAGEMENT; DIAGNOSIS;
   KNEE
AB Smart wearables for health monitoring, prevention, and patient support play a significant role in today's treatment and home rehabilitation. The effectiveness of rehabilitation in acute cruciate ligament (CL) rupture is dependent upon patient adherence to personalised Home Exercise Programmes (HEPs) and development of self-efficacy. This paper presents the research, preliminary design stages and a formative evaluation of a digital wearable system for monitoring, tracking, guiding and motivating users during HEP. The aim of the prototype is to support patients' rehabilitation program by reducing the risk of re-injury during the process and motivate them to adhere to their HEPs by monitoring, providing constructive feedback, encouraging understanding and thus promoting self-efficacy. The digital infrastructure is composed of three main parts, a physical product of two smart bracelets for sensing data from the patient's knee, a smartphone application for the user to interact with and a web-based service for collecting, storing, analysing, and sharing data. The evaluation of the wearable system was based on a randomised group of 15 subject participants.
C1 [Kordatos, George; Stavrakis, Modestos] Univ Aegean, Dept Prod & Syst Design Engn, Syros, Greece.
C3 University of Aegean
RP Stavrakis, M (corresponding author), Univ Aegean, Dept Prod & Syst Design Engn, Syros, Greece.
EM kordatos.g@gmail.com; modestos@aegean.gr
RI Stavrakis, Modestos/Y-2264-2018
OI Stavrakis, Modestos/0000-0002-0694-6038
CR Ahn JW, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19091991
   Ananthanarayan S., 2013, P SIGCHI C HUMAN FAC, P1247
   [Anonymous], 2015, CRUCIATE LIGAMENTS
   Bachmann C, 2018, PHYS MED REHAB KUROR, V28, P20, DOI 10.1055/s-0043-120527
   BANDURA A, 1982, AM PSYCHOL, V37, P122, DOI 10.1037/0003-066X.37.2.122
   Bandura A., 1997, SELF EFFICACY EXERCI
   Bassett SF., 2003, NZ J PHYSIOTHERAPY, V31, P60
   Behar JA, 2019, PHYSIOL MEAS, V40, DOI 10.1088/1361-6579/ab2057
   Bonato Paolo, 2005, J Neuroeng Rehabil, V2, P2, DOI 10.1186/1743-0003-2-2
   Boulemtafes A, 2016, WEARABLE HLTH MONITO, P17
   Boulemtafes A, 2020, INCORPORATING INTERN, P212, DOI 10.4018/978-1-7998-1090-2.ch013
   Brown JR, 2004, PRIMARY CARE, V31, P925, DOI 10.1016/j.pop.2004.07.004
   Chan DK, 2009, ARCH PHYS MED REHAB, V90, P1977, DOI 10.1016/j.apmr.2009.05.024
   Darwish A, 2011, SENSORS-BASEL, V11, P5561, DOI 10.3390/s110605561
   Di Rienzo M, 2005, P ANN INT IEEE EMBS, P7167, DOI 10.1109/IEMBS.2005.1616161
   Dias D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082414
   England Nathan, 2018, 2018 Systems and Information Engineering Design Symposium (SIEDS), P165, DOI 10.1109/SIEDS.2018.8374729
   Essery R, 2017, DISABIL REHABIL, V39, P519, DOI 10.3109/09638288.2016.1153160
   Fensli R, 2008, COMM COM INF SC, V25, P402
   Gao YW, 2015, IND MANAGE DATA SYST, V115, P1704, DOI 10.1108/IMDS-03-2015-0087
   Gemperle F, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P116, DOI 10.1109/ISWC.1998.729537
   Goodwin KimAlan Cooper., 2009, DESIGNING DIGITAL AG
   Guk K, 2019, NANOMATERIALS-BASEL, V9, DOI 10.3390/nano9060813
   Haladjian J, 2015, P 2015 ACM INT S WEA, P181
   Heintzman Nathaniel D, 2015, J Diabetes Sci Technol, V10, P35, DOI 10.1177/1932296815622453
   Ireland ML, 2002, ORTHOP CLIN N AM, V33, P637, DOI 10.1016/S0030-5898(02)00028-7
   Jack K, 2010, MANUAL THER, V15, P220, DOI 10.1016/j.math.2009.12.004
   Kaeding CC, 2017, CLIN SPORT MED, V36, P1, DOI 10.1016/j.csm.2016.08.001
   Kim J, 2019, NAT BIOTECHNOL, V37, P389, DOI 10.1038/s41587-019-0045-y
   Kolt GS, 2003, MANUAL THER, V8, P110, DOI 10.1016/S1356-689X(02)00156-X
   Kordatos G, 2018, CRUCIATE LIGAMENT CL
   LaBella CR, 2014, PEDIATRICS, V133, pE1437, DOI 10.1542/peds.2014-0623
   Li JD, 2019, APPL ERGON, V75, P162, DOI 10.1016/j.apergo.2018.10.006
   Malasinghe LP, 2019, J AMB INTEL HUM COMP, V10, P57, DOI 10.1007/s12652-017-0598-x
   Manas M, 2019, J AMB INTEL HUM COMP, V10, P2817, DOI 10.1007/s12652-018-1101-z
   Micheo W, 2010, PM&R, V2, P935, DOI 10.1016/j.pmrj.2010.06.014
   Motti VG, 2014, ERGON SOC ANN MEET, V58, P1824, DOI 10.1177/1541931214581381
   Mukhopadhyay SC, 2015, IEEE SENS J, V15, P1321, DOI 10.1109/JSEN.2014.2370945
   Munro BJ, 2008, SENSOR ACTUAT B-CHEM, V131, P541, DOI 10.1016/j.snb.2007.12.041
   NOYES FR, 1983, J BONE JOINT SURG AM, V65, P154, DOI 10.2106/00004623-198365020-00003
   Parette P, 2004, EDUC TRAIN DEV DISAB, V39, P217
   Partheniadis Konstantinos, 2018, Smart Objects and Technologies for Social Good. Third International Conference, GOODTECHS 2017. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 233), P1, DOI 10.1007/978-3-319-76111-4_1
   Partheniadis K, 2019, MULTIMED TOOLS APPL, V78, P3365, DOI 10.1007/s11042-018-6514-3
   Pastorino M, 2013, J PHYS CONF SER, V450, DOI 10.1088/1742-6596/450/1/012055
   Patel S, 2012, J NEUROENG REHABIL, V9, DOI 10.1186/1743-0003-9-21
   Peek K, 2019, PHYSIOTHER THEOR PR, V35, P1304, DOI 10.1080/09593985.2018.1474402
   Picha KJ, 2018, MUSCULOSKELET CARE, V16, P233, DOI 10.1002/msc.1194
   Qiu Y, 2017, IEEE INT CONF COMMUN, P557
   Raines BT, 2017, INDIAN J ORTHOP, V51, P563, DOI 10.4103/ortho.IJOrtho_245_17
   Redl A, 2019, SPRINTING VIENNA UNS
   Reimann R, 2014, FACE ESSENTIALS INTE, P4
NR 51
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33549
EP 33574
DI 10.1007/s11042-019-08502-3
EA DEC 2019
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000563497200001
DA 2024-07-18
ER

PT J
AU Furuya, T
   Ohbuchi, R
AF Furuya, Takahiko
   Ohbuchi, Ryutarou
TI Feature set aggregator: unsupervised representation learning of sets for
   their comparison
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised learning; Feature aggregation; Set-to-set comparison;
   Multimedia information retrieval; Autoencoder; Neural network
ID PROJECTION; MODELS; SCALE
AB Unsupervised representation learning of unlabeled multimedia data is important yet challenging problem for their indexing, clustering, and retrieval. There have been many attempts to learn representation from a collection of unlabeled 2D images. In contrast, however, less attention has been paid to unsupervised representation learning for unordered sets of high-dimensional feature vectors, which are often used to describe multimedia data. One such example is set of local visual features to describe a 2D image. This paper proposes a novel algorithm called Feature Set Aggregator (FSA) for accurate and efficient comparison among sets of high-dimensional features. FSA learns representation, or embedding, of unordered feature sets via optimization using a combination of two training objectives, that are, set reconstruction and set embedding, carefully designed for set-to-set comparison. Experimental evaluation under three multimedia information retrieval scenarios using 3D shapes, 2D images, and text documents demonstrates efficacy as well as generality of the proposed algorithm.
C1 [Furuya, Takahiko; Ohbuchi, Ryutarou] Univ Yamanashi, Dept Comp Sci, 4-3-11 Takeda, Kofu, Yamanashi 4008511, Japan.
C3 University of Yamanashi
RP Furuya, T (corresponding author), Univ Yamanashi, Dept Comp Sci, 4-3-11 Takeda, Kofu, Yamanashi 4008511, Japan.
EM takahikof@yamanashi.ac.jp; ohbuchi@yamanashi.ac.jp
RI Ohbuchi, Ryutarou/A-5821-2013
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 1997, ACT ICM 97 P 14 INT
   [Anonymous], ENGLISH LSA SPACE
   [Anonymous], PROC CVPR IEEE
   [Anonymous], P ICLR 2014
   [Anonymous], TPAMI
   [Anonymous], P ICLR 2015 WORKSH
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2009, NATURAL IMAGE STAT P
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], 2015, P ICCV
   [Anonymous], 2011, P 4 INT C ART INT ST
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2017, ARXIV171207262
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, 31 INT CONFNEURAL IN
   [Anonymous], P BMVC
   [Anonymous], P STA 2011
   Blitzer J., 2007, Proceedings of the 45th annual meeting of the association of computational linguistics, V45, P440
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Funkhouser T.A., 2015, P COMP VIS PATT REC
   Furuya T, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P171, DOI 10.1145/2671188.2749380
   Furuya T, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P293, DOI 10.1145/2911996.2912054
   Gavrila D. M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P87, DOI 10.1109/ICCV.1999.791202
   Goodfellow I., 2016, Advances in Neural Information Processing Systems, P2672
   Guo YL, 2013, INT J COMPUT VISION, V105, P63, DOI 10.1007/s11263-013-0627-y
   Henrikson Jeff, 1999, MIT Undergraduate Journal of Mathematics, V1, P10
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Kingma Diederik P., 2015, ICLR POST
   Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028
   Lang K., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P331
   Lee HY, 2017, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2017.79
   Lehmann J, 2012, J WEB SEMANT, V12-13, P1, DOI 10.1016/j.websem.2011.12.004
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Lin H, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION ENGINEERING (ICRAE), P206, DOI 10.1109/ICRAE.2018.8586770
   Lin SY, 2018, LECT NOTES COMPUT SC, V11207, P639, DOI 10.1007/978-3-030-01219-9_38
   Liu Y, 2017, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2017.499
   Liu ZQ, 2016, NEUROCOMPUTING, V173, P1183, DOI 10.1016/j.neucom.2015.08.076
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Mitliagkas I., 2017, Learning representations and generative models for 3d point clouds
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Ohbuchi R, 2005, INT J COMPUT APPL T, V23, P70, DOI 10.1504/IJCAT.2005.006466
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Papadakis P, 2007, PATTERN RECOGN, V40, P2437, DOI 10.1016/j.patcog.2006.12.026
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701
   Sfikas K, 2018, COMPUT GRAPH-UK, V71, P208, DOI 10.1016/j.cag.2017.12.001
   Shi BG, 2015, IEEE SIGNAL PROC LET, V22, P2339, DOI 10.1109/LSP.2015.2480802
   Simonyan K., 2014, 14091556 ARXIV
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wahl E, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P474, DOI 10.1109/IM.2003.1240284
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang XL, 2015, IEEE I CONF COMP VIS, P2794, DOI 10.1109/ICCV.2015.320
   Wei X, 2018, LECT NOTES COMPUT SC, V11207, P365, DOI 10.1007/978-3-030-01219-9_22
   Xu X, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P46, DOI 10.1145/3206025.3206033
   Yoshimura K, 2014, SPRINGERPLUS, V3, DOI 10.1186/2193-1801-3-352
   Zaheer M, 2017, ADV NEUR IN, V30
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
NR 73
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35157
EP 35178
DI 10.1007/s11042-019-08078-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800041
DA 2024-07-18
ER

PT J
AU Liang, XK
   Tan, X
   Tao, LM
AF Liang, Xikun
   Tan, Xiao
   Tao, Limin
TI Plaintext related image hybrid encryption scheme using algebraic
   interpolation and generalized chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-linear methods; Lagrange interpolation; Chaotic map; Plaintext
   related; Image encryption
AB In this paper, a plaintext related image hybrid encryption scheme is proposed based on Lagrange interpolation, generalized Henon map and nonlinear operations of matrices. The proposed scheme consists of three parts. In the first part, a generalized chaotic map is constructed on the basis of Henon map. Using the novel map, a chaotic sequence is built. And then, both the chaotic sequence and the plaintext pixels are used to implement the first nonlinear operation for generating the first cipher matrix associated with the plaintext. By performing an exclusive XOR operation between the original pixels matrix and the first cipher matrix, the diffusion encryption is carried out. In the second part, Lagrange interpolation is used to create the second cipher matrix related to the diffused image; the second nonlinear transformation is developed between the diffused image and the second cipher matrix; and sequence rearrangement is adopted to scramble the diffused image. In the third part, the third nonlinear transformation of matrices based on point operation and rounding operation is implemented on the scrambled image to complete the image encryption. Accordingly, the decryption process is executed by the inverse operations in the opposite order. The proposed algorithm has some distinctive features: a variety of nonlinear tools such as nonlinear polynomial interpolation, nonlinear chaotic map, and nonlinear operations were involved in the scheme. The cryptosystem is designed with the plaintext to enhance the algorithm security. Due to the combination of multiple nonlinear methods and random factors, the scheme is one time pad, which can withstand multiple types of attacks. The algorithm has a clear structure and a simple calculation, so it is easy to program. In addition, encryption simulation and performance analysis are carried out. The feasibility and effectiveness of the algorithm are verified by the simulated results. The security of the algorithm are proved by the objective indicators such as the running time, key space, statistical properties, key sensitivity, and differential analysis, etc.
C1 [Liang, Xikun; Tan, Xiao; Tao, Limin] Hangzhou Normal Univ, Coll Informat Sci & Engn, Hangzhou 311121, Zhejiang, Peoples R China.
   [Liang, Xikun; Tan, Xiao; Tao, Limin] Hangzhou Normal Univ, Hangzhou Inst Serv Engn, Hangzhou 311121, Zhejiang, Peoples R China.
C3 Hangzhou Normal University; Hangzhou Normal University
RP Liang, XK (corresponding author), Hangzhou Normal Univ, Coll Informat Sci & Engn, Hangzhou 311121, Zhejiang, Peoples R China.; Liang, XK (corresponding author), Hangzhou Normal Univ, Hangzhou Inst Serv Engn, Hangzhou 311121, Zhejiang, Peoples R China.
EM schenken@163.com; xiaotan_cs@163.com; thn5460@163.com
OI Liang, Xikun/0000-0001-7280-3062
CR Akif OZ, 2012, IBN AL HAITHAM J PUR, V25, P478
   Amalarethinam DIG, 2015, IEEE INT C COMP COMM
   [Anonymous], 2019, 101 OBJECTCATEGORIES
   [Anonymous], 2018, CONTOUR DETECTION IM
   [Anonymous], 2019, CIFAR 10 MATLAB VERS
   [Anonymous], 2016, CHAOTIC DIGITAL IMAG
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen Y, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-00859-5
   Cheng PG, 2015, NONLINEAR DYNAM, V79, P2121, DOI 10.1007/s11071-014-1798-y
   Ganesan K, 2014, EUR PHYS J-SPEC TOP, V223, P1611, DOI 10.1140/epjst/e2014-02123-1
   Guo F., 2015, Applications of Chaos Theory to Cryptography, V1st ed.
   Hamdi M, 2017, SIGNAL PROCESS, V131, P514, DOI 10.1016/j.sigpro.2016.09.011
   Jin X, 2018, MULTIMED TOOLS APPL, V77, P15851, DOI 10.1007/s11042-017-5159-y
   Kanso A, 2015, COMMUN NONLINEAR SCI, V24, P98, DOI 10.1016/j.cnsns.2014.12.005
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P2943, DOI 10.1016/j.cnsns.2011.11.030
   Liu C L., 2017, IMAGE PROCESSING MAT
   Liu Q, 2015, COMMUN NONLINEAR SCI, V20, P506, DOI 10.1016/j.cnsns.2014.06.005
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Miller J. E., 2011, ELEMENTARY THEORY AP
   Norouzi B, 2014, MULTIMEDIA SYST, V20, P45, DOI 10.1007/s00530-013-0314-4
   Prasad M., 2011, COMPUTER SCI, P169, DOI 10.5121/csit.2011.1217
   Ritwik MG., 2017, IMAGE VIS COMPUT, V23, P89
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Sun X., 2013, Image Encryption Algorithm and Practice-Based on C Sharp Language Implementation
   Wang XY, 2015, NONLINEAR DYNAM, V79, P2449, DOI 10.1007/s11071-014-1824-0
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Yong Zhang, 2014, IAES TELKOMNIKA Indonesian Journal of Electrical Engineering, V12, P635
   Zhang LY, 2014, COMMUN NONLINEAR SCI, V19, P3653, DOI 10.1016/j.cnsns.2014.03.016
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P2066, DOI 10.1016/j.cnsns.2012.12.012
   Zhang Y., 2014, TELKOMNIKA INDONES J, V12, P7952
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 33
TC 3
Z9 3
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2719
EP 2743
DI 10.1007/s11042-019-08295-5
EA DEC 2019
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000499684700001
DA 2024-07-18
ER

PT J
AU Meena, KB
   Tyagi, V
AF Meena, Kunj Bihari
   Tyagi, Vipin
TI A copy-move image forgery detection technique based on Gaussian-Hermite
   moments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gaussian-Hermite moments; Image forgery; Image forgery detection;
   Copy-move forgery; Key-point; Passive forgery detection;
   Post-processing; Tampering detection
ID REGION; LOCALIZATION; INVARIANTS; ROTATION
AB Images are one of the most prominently used digital information sharing medium now a days. Due to availability of state-of-the-art image editing tools it has become very easy to forge an image. Among various types of image forgeries, copy-move (region-duplication) forgery cases are emerging very frequently. In copy-move image forgery one or more regions of an image are replicated within the same image. In this paper, a new robust copy-move image forgery detection technique is proposed using Gaussian-Hermite Moments (GHM). The proposed technique divides the input image into overlapping blocks of fixed size and then the Gaussian-Hermite moments are extracted for each block. The matching of similar blocks is done by sorting all the features lexicographically. The experimental results show that the proposed technique can locate the copy-move forged regions in a forged image very accurately. The proposed technique shows promising results in the presence of various post-processing operations scaling, blurring, color reduction, adjustment of brightness, rotation, and JPEG compression.
C1 [Meena, Kunj Bihari; Tyagi, Vipin] Jaypee Univ Engn & Technol, Dept CSE, Guna, MP, India.
   [Tyagi, Vipin] Jaypee Univ Engn & Technol, Fac Math Sci, Guna, MP, India.
RP Tyagi, V (corresponding author), Jaypee Univ Engn & Technol, Dept CSE, Guna, MP, India.; Tyagi, V (corresponding author), Jaypee Univ Engn & Technol, Fac Math Sci, Guna, MP, India.
EM dr.vipin.tyagi@gmail.com
RI Meena, Kunj Bihari/ABF-5314-2020; Tyagi, Vipin/I-2451-2013
OI Meena, Kunj Bihari/0000-0001-8159-9024; Tyagi, Vipin/0000-0003-4994-3686
CR Alahmadi A, 2017, SIGNAL IMAGE VIDEO P, V11, P81, DOI 10.1007/s11760-016-0899-0
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], INF SCI NY
   Ansari MD, 2014, IETE Journal of Education, V55, P40, DOI DOI 10.1080/09747338.2014.921415
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Bashar M, 2010, IEEE Trans Image Process, DOI 10.1109/TIP.2010.2046599
   Belghini N, 2012, INT J COMPUT APPL, V975, P3
   Bi XL, 2018, PATTERN RECOGN, V81, P161, DOI 10.1016/j.patcog.2018.03.028
   Bi XL, 2016, INFORM SCIENCES, V345, P226, DOI 10.1016/j.ins.2016.01.061
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Chen LK, 2013, J VIS COMMUN IMAGE R, V24, P244, DOI 10.1016/j.jvcir.2013.01.008
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cozzolino D, 2014, IEEE IMAGE PROC, P5312, DOI 10.1109/ICIP.2014.7026075
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Gürbüz E, 2015, 2015 9TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONICS ENGINEERING (ELECO), P202, DOI 10.1109/ELECO.2015.7394451
   Hosny KM, 2018, IMAGING SCI J, V66, P330, DOI 10.1080/13682199.2018.1461345
   Isaac MM, 2018, J INTELL FUZZY SYST, V34, P1679, DOI 10.3233/JIFS-169461
   Lee JC, 2015, INFORM SCIENCES, V321, P250, DOI 10.1016/j.ins.2015.03.009
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Liu XWY, 2016, PATTERN ANAL APPL
   Liu YQ, 2018, MULTIMED TOOLS APPL, V77, P18269, DOI 10.1007/s11042-017-5374-6
   Lu JF, 2010, PROCEEDINGS OF THE ASME 29TH INTERNATIONAL CONFERENCE ON OCEAN, OFFSHORE AND ARCTIC ENGINEERING, 2010, VOL 1, P883
   Luo WQ, 2006, INT C PATT RECOG, P746
   Ma X., 2010, P 2 INT WORKSH ED TE, V3, P11
   Mahmood T, 2018, J VIS COMMUN IMAGE R, V53, P202, DOI 10.1016/j.jvcir.2018.03.015
   Manu VT, 2018, SIGNAL IMAGE VIDEO P, V12, P549, DOI 10.1007/s11760-017-1191-7
   Meena K.B., 2019, DATA ENG APPL, P163, DOI [DOI 10.1007/978-981-13-6351-1_14, 10.1007/978-981-13-6351-1_14]
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Popescu A.C., 2004, Comput. Sci. Tech. Rep, P1
   Prakash CS, 2018, MULTIMED TOOLS APPL, V77, P26939, DOI 10.1007/s11042-018-5899-3
   Pun CM, 2018, INFORM SCIENCES, V463, P33, DOI 10.1016/j.ins.2018.06.040
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Shen J, 1997, P SOC PHOTO-OPT INS, V3208, P224, DOI 10.1117/12.290295
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Tralic D, 2016, MULTIMED TOOLS APPL, V75, P16881, DOI 10.1007/s11042-015-2961-2
   Tralic D, 2014, INT CONF SYST SIGNAL, P167
   Tyagi V., 2018, UNDERSTANDING DIGITA
   Ustubioglu B, 2016, AEU-INT J ELECTRON C, V70, P1076, DOI 10.1016/j.aeue.2016.05.005
   Wang S, 2016, MULTIMED TOOLS APPL, V75, P3353, DOI 10.1007/s11042-014-2438-8
   Wu YF, 2005, EURASIP J APPL SIG P, V2005, P588, DOI 10.1155/ASP.2005.588
   Wu YF, 2004, PROC SPIE, V5308, P841, DOI 10.1117/12.525427
   Yang B, 2013, RADIOENGINEERING, V22, P1098
   Yang B, 2017, SIGNAL PROCESS, V132, P77, DOI 10.1016/j.sigpro.2016.09.013
   Yang B, 2011, PATTERN RECOGN LETT, V32, P1283, DOI 10.1016/j.patrec.2011.03.012
   Yang HY, 2018, MULTIMED TOOLS APPL, V77, P13615, DOI 10.1007/s11042-017-4978-1
   Zandi M, 2016, IEEE T INF FOREN SEC, V11, P2499, DOI 10.1109/TIFS.2016.2585118
   ZHAO J, 2013, MATH PROBL ENG, V4, P1
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
   Zhong JL, 2016, NONLINEAR DYNAM, V84, P189, DOI 10.1007/s11071-015-2374-9
   Zhu Y, 2016, MULTIMED TOOLS APPL, V75, P3221, DOI 10.1007/s11042-014-2431-2
NR 56
TC 32
Z9 32
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33505
EP 33526
DI 10.1007/s11042-019-08082-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600043
DA 2024-07-18
ER

PT J
AU Wang, XY
   Sun, HH
AF Wang, Xingyuan
   Sun, Huaihuai
TI A chaotic image encryption algorithm based on zigzag-like transform and
   DNA-like coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Zigzag-like transformation; DNA-like coding; Chaotic sequence; Image
   encryption
ID SEQUENCE OPERATION; PERMUTATION; MAPS
AB This paper proposes an encryption algorithm that uses the initial values and parameters of the chaotic system as the key, and mainly uses the similar deoxyribonucleic acid (DNA-like) coding method and the similar Zigzag (Zigzag-like) transform to encrypt the image. Firstly, the image is pre-scrambled by the method of Zigzag-like transformation, and then the second scrambling is performed by a sorting scrambling algorithm with identification value. Secondly, the image is diffused by DNA-like coding method. Finally, the image is again diffused using the ortho exclusive OR (XOR) method with chaotic perturbation terms. The experimental results show that the chaotic image encryption algorithm proposed in this paper has satisfactory results. In addition, the algorithm is compared to the previously proposed chaotic image encryption algorithm for the Zigzag transform method or the deoxyribonucleic acid (DNA) coding method. The contribution is to improve the Zigzag transformation method and the DNA coding method, so that it has the advantages of higher security and higher sensitivity. It can also effectively resist exhaustive and differential attacks with better statistical characteristics.
C1 [Wang, Xingyuan; Sun, Huaihuai] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
C3 Dalian Maritime University
RP Wang, XY; Sun, HH (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
EM xywang@dlmu.edu.cn; 2471054392@qq.com
RI Wang, Xing-yuan/I-6353-2015
FU National Natural Science Foundation of China [61672124, 61370145];
   Password Theory Project of the 13th Five-Year Plan National Cryptography
   Development Fund [MMJJ20170203]
FX This research is supported by the National Natural Science Foundation of
   China (Nos: 61672124, and 61370145), the Password Theory Project of the
   13th Five-Year Plan National Cryptography Development Fund (No:
   MMJJ20170203).
CR Abdo AA, 2013, COMMUN NONLINEAR SCI, V18, P136, DOI 10.1016/j.cnsns.2012.05.023
   [Anonymous], MULTIMED TOOLS APPL
   Bakhshandeh A, 2013, OPT LASER ENG, V51, P665, DOI 10.1016/j.optlaseng.2013.01.001
   Chen JX, 2018, NONLINEAR DYNAM, V93, P2399, DOI 10.1007/s11071-018-4332-9
   Dhawan Sanjeev, 2012, IJETCAS, V2, P36
   [董虎胜 Dong Husheng], 2013, [计算机应用与软件, Computer Applications and Software], V30, P132
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   [郭毅 Guo Yi], 2015, [计算机应用研究, Application Research of Computers], V32, P1131
   Hermassi H, 2014, MULTIMED TOOLS APPL, V72, P2211, DOI 10.1007/s11042-013-1533-6
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Khellat F, 2011, CHAOS SOLITON FRACT, V44, P934, DOI 10.1016/j.chaos.2011.07.015
   Ling, 2011, IEEE COMPUT INTELL M, V6, P68, DOI [10.1109/MCI.2010.939582, DOI 10.1109/MCI.2010.939582]
   [刘艮 Liu Gen], 2013, [计算机工程与科学, Computer Engineering and Science], V35, P106
   Ma J., 2015, J NETWORK NEW MEDIA, V4, P37
   Niu Ying, 2017, Computer Engineering and Applications, V53, P130, DOI 10.3778/j.issn.1002-8331.1702-0122
   Peng J, 2013, PROCEEDINGS OF THE 2013 12TH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI CC 2013), P403, DOI 10.1109/ICCI-CC.2013.6622274
   Seyedzadeh SM, 2015, NONLINEAR DYNAM, V81, P511, DOI 10.1007/s11071-015-2008-2
   Wang XY, 2014, NONLINEAR DYNAM, V75, P345, DOI 10.1007/s11071-013-1070-x
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Xu X, 2010, EBM 2010: INTERNATIONAL CONFERENCE ON ENGINEERING AND BUSINESS MANAGEMENT, VOLS 1-8, P552
   Yang YY., 2011, NETINFO SECURITY, V11, P57
   Ye GD, 2016, NONLINEAR DYNAM, V83, P2067, DOI 10.1007/s11071-015-2465-7
   Zhang YQ, 2016, OPT LASER ENG, V82, P95, DOI 10.1016/j.optlaseng.2016.02.002
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P6647, DOI 10.1007/s11042-017-4577-1
   Zhang Y, 2016, IETE TECH REV, V33, P310, DOI 10.1080/02564602.2015.1087350
   Zhao JF, 2015, NONLINEAR DYNAM, V80, P1721, DOI 10.1007/s11071-015-1911-x
   Zhou CJ, 2010, J COMPUT THEOR NANOS, V7, P1904, DOI 10.1166/jctn.2010.1558
NR 30
TC 16
Z9 17
U1 3
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34981
EP 34997
DI 10.1007/s11042-019-08085-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800033
DA 2024-07-18
ER

PT J
AU Zhang, AJ
   Zhao, Y
   Wang, SG
AF Zhang, Aijia
   Zhao, Yan
   Wang, Shigang
TI Illumination estimation for augmented reality based on a global
   illumination model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Illumination estimation; Photon mapping; Global illumination; Relighting
AB With the rapid development of 3D technology, the illumination consistency plays an important role in realistic rendering of virtual objects which are superimposed into the real scene. In this paper we proposed a new approach to estimate illumination, given the images of a scene. Our algorithm is designed from principles in optics, which is based on a global illumination model. First, we get the images of a scene and perform scene reconstruction using images. Then, a photon emission hemispherical model is built for emitting photons into the scene. The photons are traced, meanwhile the result is stored in multiple photon maps. Finally, the estimated illumination is obtained by estimating the photon radiance value in the photon emission hemispherical model. Experiments on our newly collected real scene databases and virtual scene databases show the accuracy of our method subjectively and objectively. By comparing with related work, it is found that more accurate results can be obtained using the global illumination inversely.
C1 [Zhang, Aijia; Zhao, Yan; Wang, Shigang] Jilin Univ, Sch Commun Engn, Changchun, Jilin, Peoples R China.
C3 Jilin University
RP Zhao, Y (corresponding author), Jilin Univ, Sch Commun Engn, Changchun, Jilin, Peoples R China.
EM zhao_y@jlu.edu.cn
RI Zhao, Yan/AAF-8988-2019; wang, shigang/F-3718-2011
FU National Key RD Plan [2017YFB1002900]; National Natural Science
   Foundation of China [61771220, 61631009]
FX This work was supported by the National Key R&D Plan (2017YFB1002900)
   and the National Natural Science Foundation of China (No. 61771220 and
   No. 61631009).
CR [Anonymous], INFORM CONTROL AUTOM
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2018, ARXIV180910820
   [Anonymous], 2014, MICROCOMPUTER ITS AP
   Boom B J, 2017, COMPUTER ANIMATION V
   Chen R, 2014, BIOCHEM SYST ECOL, V57, P1, DOI 10.1016/j.bse.2014.07.011
   Cignoni P, 2018, ERCIM NEWS
   Gardner M.-A., 2017, ACM TOG, V9
   Georgoulis S, 2018, IEEE T PATTERN ANAL, V40, P1932, DOI 10.1109/TPAMI.2017.2742999
   Hold-Geoffroy Y, 2016, IEEE C COMP VIS PATT
   Jensen HW, 1996, EUR WORKSH REND TECH
   Jianbing Shen, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3481, DOI 10.1109/CVPR.2011.5995507
   Jiddi S, 2017, IEEE INT S MIX AUGM
   Karaoglu S, 2017, IEEE T IMAGE PROCESS, V1
   Knorr SB, 2014, IEEE INT S MIX AUGM
   Li X, 2010, INT C AUD LANG IM PR
   Liu B, 2017, J COMPUT SCI TECH-CH, V32, P430, DOI 10.1007/s11390-017-1734-y
   Neverova N, 2012, EUR C COMP VIS
   Panagopoulos A, 2011, IEEECONFERENCE COMP
   Panagopoulos A, 2009, IEEE C COMP VIS PATT
   Sato A, 2003, ACTA HORTIC, P25, DOI 10.17660/ActaHortic.2003.601.2
   Shim HJ, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.7.077002
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Song MC, 2018, PROC INT WORKSH ADV
   Weber H, 2018, INT CONF 3D VISION, P199, DOI 10.1109/3DV.2018.00032
   Wu C., 2013, INT C 3D VIS
   Wu HZ, 2016, IEEE T VIS COMPUT GR, V22, P2012, DOI 10.1109/TVCG.2015.2498617
   Yuan L, 2018, MULTIMED TOOLS APPL, P1
   Zhang G, 2010, EUR C COMP VIS
NR 29
TC 7
Z9 10
U1 3
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33487
EP 33503
DI 10.1007/s11042-019-08155-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600042
DA 2024-07-18
ER

PT J
AU Zhang, JH
   Li, M
   Feng, Y
   Yang, CG
AF Zhang, Jiahao
   Li, Miao
   Feng, Ying
   Yang, Chenguang
TI Robotic grasp detection based on image processing and random forest
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time grasp detection; Novel objects; Improved graph segmentation
   method; Morphological image processing; Random forest; Baxter
AB Real-time grasp detection plays a key role in manipulation, and it is also a complex task, especially for detecting how to grasp novel objects. This paper proposes a very quick and accurate approach to detect robotic grasps. The main idea is to perform grasping of novel objects in a typical RGB-D scene view. Our goal is not to find the best grasp for every object but to obtain the local optimal grasps in candidate grasp rectangles. There are three main contributions to our detection work. Firstly, an improved graph segmentation approach is used to do objects detection and it can separate objects from the background directly and fast. Secondly, we develop a morphological image processing method to generate candidate grasp rectangles set which avoids us to search grasp rectangles globally. Finally, we train a random forest model to predict grasps and achieve an accuracy of 94.26%. The model is mainly used to score every element in our candidate grasps set and the one gets the highest score will be converted to the final grasp configuration for robots. For real-world experiments, we set up our system on a tabletop scene with multiple objects and when implementing robotic grasps, we control Baxter robot with a different inverse kinematics strategy rather than the built-in one.
C1 [Zhang, Jiahao; Feng, Ying] South China Univ Technol, Key Lab Autonomous Syst & Networked Control, Coll Automat Sci & Engn, Guangzhou, Guangdong, Peoples R China.
   [Li, Miao] Wuhan Univ, Inst Technol Sci, Wuhan, Hubei, Peoples R China.
   [Yang, Chenguang] Univ West England, Bristol Robot Lab, Bristol BS16 1QY, Avon, England.
C3 South China University of Technology; Wuhan University; University of
   Bristol; University of West England
RP Yang, CG (corresponding author), Univ West England, Bristol Robot Lab, Bristol BS16 1QY, Avon, England.
EM cyang@ieee.org
RI Yang, Chenguang/AAJ-2509-2020
OI Yang, Chenguang/0000-0001-5255-5559
FU Engineering and Physical Sciences Research Council (EPSRC) [EP/S001913];
   EPSRC [EP/S001913/2] Funding Source: UKRI
FX This work was partially supported by Engineering and Physical Sciences
   Research Council (EPSRC) under Grant EP/S001913.
CR [Anonymous], 2018, arXiv
   Aristidou A, 2018, COMPUT GRAPH FORUM, V37, P35, DOI 10.1111/cgf.13310
   Bicchi A., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P348, DOI 10.1109/ROBOT.2000.844081
   Daniilidis K, 1999, INT J ROBOT RES, V18, P286, DOI 10.1177/02783649922066213
   de Berg M., 2000, COMPUTATIONAL GEOMET
   Diankov Rosen, 2008, Tech. Rep. CMU-RI-TR-08-34
   Ding D, 2001, IEEE INT CONF ROBOT, P2217, DOI 10.1109/ROBOT.2001.932952
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   FISCHINGER D, 2012, SYROCO, P787
   Fischinger D, 2015, INT J ROBOT RES, V34, P1167, DOI 10.1177/0278364915577105
   Fischinger D, 2012, IEEE INT C INT ROBOT, P2051, DOI 10.1109/IROS.2012.6386137
   Gualtieri M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P598, DOI 10.1109/IROS.2016.7759114
   Guo D, 2017, INT J ADV ROBOT SYST, V14, DOI 10.1177/1729881416682706
   HUAMAN AC, 2016, THESIS
   Jiang Y, 2011, IEEE INT CONF ROBOT
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumra S, 2017, IEEE INT C INT ROBOT, P769, DOI 10.1109/IROS.2017.8202237
   Lenz I, 2015, INT J ROBOT RES, V34, P705, DOI 10.1177/0278364914549607
   Li JW, 2003, IEEE INT CONF ROBOT, P1800, DOI 10.1109/ROBOT.2003.1241855
   MACIEJEWSKI AA, 1985, INT J ROBOT RES, V4, P109, DOI 10.1177/027836498500400308
   Makhal A, 2018, 2018 SECOND IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC), P292, DOI 10.1109/IRC.2018.00062
   Miller AT, 2004, IEEE ROBOT AUTOM MAG, V11, P110, DOI 10.1109/MRA.2004.1371616
   Miller AT, 2003, IEEE INT CONF ROBOT, P1824, DOI 10.1109/ROBOT.2003.1241860
   Morrison D, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   PAS AT, 2016, EXPT ROBOTICS
   PAS AT, 2015, ARXIV15010
   Paul R.P., 1981, Robot Manipulators: Mathematics, Programming, and Control: The Computer Control of Robot Manipulators
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   RAO CR, 1972, IC C
   Rao D, 2010, IEEE INT C INT ROBOT, P2578, DOI 10.1109/IROS.2010.5650493
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Redmon J, 2015, IEEE INT CONF ROBOT, P1316, DOI 10.1109/ICRA.2015.7139361
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   ten Pas A, 2018, SPR PROC ADV ROBOT, V2, P307, DOI 10.1007/978-3-319-51532-8_19
   ten Pas A, 2017, INT J ROBOT RES, V36, P1455, DOI 10.1177/0278364917735594
   Trottier L, 2017, 2017 14TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2017), P168, DOI 10.1109/CRV.2017.14
   Zeng XY, 2018, IEEE T PATTERN ANAL, V40, P2109, DOI 10.1109/TPAMI.2017.2745563
   Zhang H, 2018, ARXIV180810313
   Zhang JH, 2018, LECT NOTES ARTIF INT, V11357, P160, DOI 10.1007/978-3-030-05204-1_16
NR 40
TC 23
Z9 24
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2427
EP 2446
DI 10.1007/s11042-019-08302-9
EA NOV 2019
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000497812200003
OA hybrid
DA 2024-07-18
ER

PT J
AU Singh, D
   Kumar, V
   Kaur, M
AF Singh, Dilbag
   Kumar, Vijay
   Kaur, Manjit
TI Image dehazing using window-based integrated means filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dehazing; Gradient sensitive loss; Restoration model; Transmission map;
   WIMF
ID SINGLE IMAGE; HAZE; TRANSMISSION; ALGORITHM
AB Image acquisition is generally susceptible to poor environmental conditions such as fog, smog, haze, etc. However, designing an efficient image dehazing technique is still an ill posed problem. Extensive review of the competitive haze removal approaches reveal that the texture preservation and computational speed are still a challenging issues. Therefore, in this paper, initially, a mask is utilized to decompose an input image into low and high frequency regions based on image gradient magnitude. Thereafter, a Gradient sensitive loss (GSL) is designed to obtain the depth information from an input hazy image. Thereafter, transmission map is refined by designing an efficient filter named as Window-based integrated means filter (WIMF). Finally, the restoration model is utilized to recover the hazy images. Experimental analysis reveals that the proposed dehazing technique achieves considerable results beyond the prototypes of the benchmarks. Additionally, the proposed technique outperforms the state-of-the-arts in single image dehazing approaches.
C1 [Singh, Dilbag] Manipal Univ Jaipur, Dept Comp Sci & Engn, Sch Comp & Informat Technol, Jaipur 303007, Rajasthan, India.
   [Kumar, Vijay] Natl Inst Technol Hamirpur, Dept Comp Sci & Engn, Hamirpur 177005, Himachal Prades, India.
   [Kaur, Manjit] Manipal Univ Jaipur, Dept Comp & Commun Engn, Sch Comp & Informat Technol, Jaipur 303007, Rajasthan, India.
C3 Manipal University Jaipur; National Institute of Technology (NIT
   System); National Institute of Technology Hamirpur; Manipal University
   Jaipur
RP Kaur, M (corresponding author), Manipal Univ Jaipur, Dept Comp & Commun Engn, Sch Comp & Informat Technol, Jaipur 303007, Rajasthan, India.
EM Dilbag.Singh@jaipur.manipal.edu; vijaykumarchahar@gmail.com;
   manjit.kaur@jaipur.manipal.edu
RI Singh, Dilbag/AAQ-6339-2020; kaur, manjit/J-2846-2019; Chahar, Vijay
   Kumar/A-2782-2015
OI Singh, Dilbag/0000-0001-6475-4491; kaur, manjit/0000-0001-6259-2046;
   Chahar, Vijay Kumar/0000-0002-3460-6989
CR Alajarmeh A, 2018, INFORM SCIENCES, V436, P108, DOI 10.1016/j.ins.2018.01.009
   Ali M, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC), P184, DOI 10.1109/ICSPCC.2014.6986179
   Ancuti C, 2016, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP.2016.7532754
   [Anonymous], 2017, IEEE T MULTIMED
   Bala J, 2019, MOD PHYS LETT B, V33, DOI 10.1142/S0217984919500568
   Bouguelia MR, 2018, INT J MACH LEARN CYB, V9, P1307, DOI 10.1007/s13042-017-0645-0
   Chen BH, 2016, J DISP TECHNOL, V12, P964, DOI 10.1109/JDT.2016.2552232
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Emberton S, 2018, COMPUT VIS IMAGE UND, V168, P145, DOI 10.1016/j.cviu.2017.08.003
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Ge GY, 2015, OPTIK, V126, P3245, DOI 10.1016/j.ijleo.2015.07.138
   Gibson KB, 2012, IEEE T IMAGE PROCESS, V21, P662, DOI 10.1109/TIP.2011.2166968
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hu HJ, 2016, J SCI COMPUT, V67, P103, DOI 10.1007/s10915-015-0073-9
   Jiang YT, 2017, COMPUT VIS IMAGE UND, V165, P17, DOI 10.1016/j.cviu.2017.10.014
   Jung SW, 2013, IEEE T CIRC SYST VID, V23, P269, DOI 10.1109/TCSVT.2012.2203734
   Koschmieder H, 1938, NATURWISSENSCHAFTEN, V26, P521, DOI 10.1007/BF01774261
   Kushwaha AKS, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.5.051005
   Li B, 2011, SCI CHINA INFORM SCI, V54, P51, DOI 10.1007/s11432-010-4128-0
   Li Boyi, 2017, ARXIV171204143
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P5432, DOI 10.1109/TIP.2015.2482903
   Ling ZG, 2017, NEUROCOMPUTING, V224, P82, DOI 10.1016/j.neucom.2016.10.050
   Ma KD, 2015, IEEE IMAGE PROC, P3600, DOI 10.1109/ICIP.2015.7351475
   McCartney E.J., 1976, Optics of the atmosphere: Scattering by molecules and particles, P421
   Nair D, 2018, J VIS COMMUN IMAGE R, V50, P9, DOI 10.1016/j.jvcir.2017.11.005
   Obaidullah SM, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.051214
   Qi M, 2015, OPTIK, V126, P3400, DOI 10.1016/j.ijleo.2015.07.114
   Rong Z, 2014, OPTIK, V125, P3064, DOI 10.1016/j.ijleo.2013.12.077
   SAINI R, 2018, INT J MACH LEARN CYB, P1
   Shi LF, 2018, IEEE T MULTIMEDIA, V20, P2503, DOI 10.1109/TMM.2018.2807593
   Shu QL, 2019, OPTIK, V185, P943, DOI 10.1016/j.ijleo.2019.04.002
   Singh D, 2019, SIGNAL PROCESS-IMAGE, V70, P131, DOI 10.1016/j.image.2018.09.011
   Singh D, 2018, MOD PHYS LETT B, V32, DOI 10.1142/S0217984918500513
   Tarel JP, 2012, IEEE INTEL TRANSP SY, V4, P6, DOI 10.1109/MITS.2012.2189969
   Tarel JP, 2010, IEEE INT VEH SYM, P478, DOI 10.1109/IVS.2010.5548128
   Ukil S, 2020, NEURAL COMPUT APPL, V32, P2829, DOI 10.1007/s00521-019-04111-1
   Xia P, 2016, OPTIK, V127, P7350, DOI 10.1016/j.ijleo.2016.05.071
   Xu L, 2019, INFORM SCIENCES, V489, P50, DOI 10.1016/j.ins.2019.02.058
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhao D, 2019, SIGNAL PROCESS-IMAGE, V74, P253, DOI 10.1016/j.image.2019.02.004
   Zuo WM, 2014, IEEE T IMAGE PROCESS, V23, P2459, DOI 10.1109/TIP.2014.2316423
NR 42
TC 25
Z9 25
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 34771
EP 34793
DI 10.1007/s11042-019-08286-6
EA NOV 2019
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000495944500004
DA 2024-07-18
ER

PT J
AU He, Z
   Yun, T
AF He, Zhang
   Yun, Tan
TI Implement intelligent dynamic analysis of bottom-hole pressure with
   naive Bayesian models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bottom-hole pressure; K-means clustering; Naive bayes; Hydraulic model;
   Correction
ID CLASSIFIERS
AB During the drilling process, measured bottom-hole pressure data were prone to distortion and even no data are fed back, besides, the bottom-hole pressure calculation model could not reflect the live measured values. As a consequence, inaccurate bottom-hole pressure monitoring would bring enormous safety risks to drilling operations. Data mining was an advanced method used to sort out, discover and set up models from large relevant data sets. In the monitoring of bottom-hole pressures, it was necessary to conduct an effective and overall monitoring during the drilling process. Therefore, this paper proposed the k-means clustering method to optimize Naive Bayesian models in combination with the bottom-hole pressure monitoring theory, a k-means clustering optimized Naive Bayesian model for implementation of intelligent dynamic analysis of bottom-hole pressure was established. Such model could be utilized for correcting bottom-hole pressures calculated by the traditional hydraulic model, and then the corrections were taken for comparison with measured bottom-hole pressures so as to make calculations be of minimal errors. Field data were also taken for analysis, and the results suggested that the k-means based Naive Bayesian models for correction to calculated bottom-hole pressures had smaller deviations which fell within safe deviation monitoring range of drilling pressures, and could meet the requirements of normal drilling operation.
C1 [He, Zhang; Yun, Tan] Southwest Petr Univ, Sch Mech Engn, Chengdu 610500, Sichuan, Peoples R China.
C3 Southwest Petroleum University
RP Yun, T (corresponding author), Southwest Petr Univ, Sch Mech Engn, Chengdu 610500, Sichuan, Peoples R China.
EM zhanghe@swpu.edu.cn; 405809238@qq.com
OI Tan, Yun/0000-0002-7467-0280
FU Young Scholars Development Found of SWPU [201599010079]; Sichuan
   Province Applied Basic Research Project [2016JY0049]
FX This work wos supported by the Young Scholars Development Found of
   SWPU(No.201599010079) and Sichuan Province Applied Basic Research
   Project(No.2016JY0049).
CR [Anonymous], 66132005 SYT
   Bi Xiaojun, 2010, Chinese Journal of Scientific Instrument, V31, P2368
   Chunguang B, 2010, AGR NETWORK INFORM, P19
   [代明 Dai Ming], 2016, [南京大学学报. 自然科学版, Journal of Nanjing University. Natural Sciences], V52, P908
   Guojun M, 2011, PRINCIPLES ALGORITHM
   Hao W, 2014, HENAN SCI, V31, P42
   He JZ, 2012, INT J SYST SCI, V43, P1805, DOI 10.1080/00207721.2011.627475
   Hongfeng Z, 2012, CHINA NEW TECHNOLOGI, P127
   Huanqiang Q, 2017, FUJIAN QUALITY MANAG, P235
   Jiang L., 2010, International Journal of Computers & Applications, V32, P328, DOI 10.2316/Journal.202.2010.3.202-2747
   Jiang LX, 2013, J EXP THEOR ARTIF IN, V25, P273, DOI 10.1080/0952813X.2012.721010
   Jianhong F, 2015, KEY TECHNIQUES CROWD, P16
   Karakostas B, 2016, PROCEDIA COMPUT SCI, V83, P11, DOI 10.1016/j.procs.2016.04.093
   Liang Hai-bo, 2012, Automation & Instrumentation, V27, P9
   Liang HB, 2014, PAK J STAT, V30, P1251
   Menggang L, 2008, FAULT BLOCK OIL GAS, V15, P123
   Taheri S, 2014, NEURAL COMPUT APPL, V24, P995, DOI 10.1007/s00521-012-1329-z
   Tiantai L, 2002, PRACTICAL DRILLING H, P74
   Wentao Z, 2016, MEAS CONTROL, P143
   Xiangjie P, 2015, COMPUTER TECHNOLOGY, V25, P89
   Xiaoxi Y, 2015, APPL ASS CLUSTERING
   Yan C, 2016, DATA MINING TECHNOLO
   Yan Z, 2016, RES MINING METHODS B
   Zai S, 2011, CHINA SCI TECHNOLOGY, P81
NR 24
TC 5
Z9 5
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 29805
EP 29821
DI 10.1007/s11042-018-6340-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200010
DA 2024-07-18
ER

PT J
AU Pak, C
   Kim, J
   An, K
   Kim, C
   Kim, K
   Pak, C
AF Pak, Chanil
   Kim, Jonggun
   An, Kwangil
   Kim, Changho
   Kim, Kwanghun
   Pak, Cholmyong
TI A novel color image LSB steganography using improved 1D chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Chaotic system; LSB; Steganography
ID ALGORITHM; SCHEME; DOMAIN
AB Conventional one-dimensional (1D) chaotic map have a simple structure, which is easy to implement and has a low computational cost, but has a drawback that the range of chaotic behaviors is narrow and the distribution of key sequence is uniform. In order to overcome the drawback, we proposed an improved 1D chaotic system model and evaluate the proposed model through experiments with the logistic map and a sine map. Simulation and performance evaluation shows that the 1D chaotic map improved by the proposed model can overcome the existing defects sufficiently. We also proposed a color image LSB steganography algorithm using the improved 1D chaotic map. Through experiments, we confirmed the accuracy of the proposed color image LSB steganography algorithm. Experimental results proved that the algorithm has a better performance than the previous methods, showing an excellent performance against statistical analysis attacks. We also analyzed the effect of secret data type on the quality of stego image.
C1 [Pak, Chanil; An, Kwangil] Kim Chaek Univ Technol, Informat Ctr, Pyongyang 950003, North Korea.
   [Kim, Jonggun] Kim Il Sung Univ, Inst Informat Sci, Pyongyang 999093, North Korea.
   [Kim, Changho] Kim Hyong Jik Univ, Dept Informat, Pyongyang 950007, North Korea.
   [Kim, Kwanghun] Univ Mech Engn, Dept Engn Machine, Pyongyang 999093, North Korea.
   [Pak, Cholmyong] Kim Il Sung Univ, Informat Sci Coll, Pyongyang 999093, North Korea.
RP Pak, C (corresponding author), Kim Chaek Univ Technol, Informat Ctr, Pyongyang 950003, North Korea.; Kim, J (corresponding author), Kim Il Sung Univ, Inst Informat Sci, Pyongyang 999093, North Korea.
EM pakchanil@126.com; jonggun_kim@126.com
RI Kwanghun, Kim/AFH-6460-2022; Kwanghun, Kim/AAG-2930-2022
OI An, Kwangil/0000-0002-9342-6427; Pak, ChanIl/0000-0002-4855-9546; Pak,
   Chanil/0000-0003-2344-6438
CR Akgul A, 2017, NONLINEAR DYNAM, V90, P1123, DOI 10.1007/s11071-017-3714-8
   Anees A, 2014, NONLINEAR DYNAM, V75, P807, DOI 10.1007/s11071-013-1105-3
   [Anonymous], 2017, Multimed. Tools. Appl
   Aziz M, 2015, NONLINEAR DYNAM, V80, P1271, DOI 10.1007/s11071-015-1943-2
   Bilal M, 2014, MULTIMED TOOLS APPL, V72, P1073, DOI 10.1007/s11042-013-1415-y
   Dogan S, 2016, ARTIF INTELL REV, V46, P129, DOI 10.1007/s10462-016-9459-9
   ELLOCO G, FEW TOOLS DISCOVER H
   Farschi SMR, 2012, NONLINEAR DYNAM, V69, P1525, DOI 10.1007/s11071-012-0367-5
   Martínez-González RF, 2016, COMPUT ELECTR ENG, V54, P435, DOI 10.1016/j.compeleceng.2015.12.005
   Ghebleh M, 2014, COMMUN NONLINEAR SCI, V19, P1898, DOI 10.1016/j.cnsns.2013.10.014
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P3287, DOI 10.1016/j.cnsns.2011.12.012
   Liao X, 2011, J VIS COMMUN IMAGE R, V22, P1, DOI 10.1016/j.jvcir.2010.08.007
   Lou DC, 2004, IEEE T MULTIMEDIA, V6, P501, DOI 10.1109/TMM.2004.827493
   Mukherjee S, 2018, MULTIMED TOOLS APPL, V77, P27851, DOI 10.1007/s11042-018-5996-3
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Roy R, 2013, PROC TECH, V10, P138, DOI 10.1016/j.protcy.2013.12.346
   Sharif A, 2017, MULTIMED TOOLS APPL, V76, P7849, DOI 10.1007/s11042-016-3398-y
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Valandar MY, 2017, J INF SECUR APPL, V34, P142, DOI 10.1016/j.jisa.2017.04.004
   Walia GS, 2018, OPTIK, V170, P106, DOI 10.1016/j.ijleo.2018.04.135
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Yadav GS, 2018, COMPUT ELECTR ENG, V69, P447, DOI 10.1016/j.compeleceng.2018.02.022
NR 24
TC 29
Z9 30
U1 5
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1409
EP 1425
DI 10.1007/s11042-019-08103-0
EA NOV 2019
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000493494000001
DA 2024-07-18
ER

PT J
AU Sun, FD
   Li, WH
   Guan, YY
AF Sun, Fengdong
   Li, Wenhui
   Guan, Yuanyuan
TI Self-attention recurrent network for saliency detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Recurrent convolutional layer; Self attention module
ID VISUAL-ATTENTION; IMAGE; MODEL
AB Feature maps in deep neural networks generally contain different semantics. Existing methods often omit their characteristics that may lead to sub-optimal results. In this paper, we propose a novel end-to-end deep saliency network which could effectively utilize multi-scale feature maps according to their characteristics. Shallow layers generally contain more local information, and deep layers have advantages in global semantics. Therefore, our network could generate elaborate saliency maps by exploiting the different semantics of feature maps in different layers. On one hand, local information of shallow layers is enhanced by a recurrent structure which shared convolution kernels at different time steps. On the other hand, global information of deep layers is utilized by a self-attention module, which generates attention weights for salient objects and backgrounds thus achieve better performance. Experimental results on four widely used datasets demonstrate that our method has advantages in performance over existing algorithms.
C1 [Sun, Fengdong; Li, Wenhui; Guan, Yuanyuan] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.
C3 Jilin University
RP Li, WH (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.
EM liwh@jlu.edu.cn
RI Zeng, Yun/JFK-6190-2023; LI, Wenhui/JCD-9947-2023
FU Science and Technology Development Plan of Jilin Province
   [20170204020GX]; National Science Foundation of China [U1564211]
FX This work was supported by the Science and Technology Development Plan
   of Jilin Province under Grant 20170204020GX, the National Science
   Foundation of China under Grant U1564211.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2018, ICML
   Borji A., 2012, 2012 IEEE COMPUTER S, P23, DOI 10.1109/CVPRW.2012.6239191
   Cheng MM, 2017, J COMPUT SCI TECH-CH, V32, P110, DOI 10.1007/s11390-017-1681-7
   Cheng MM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778820
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Glorot X., 2010, P INT C ART INT STAT, P249
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hou Qibin, IEEE T PATTERN ANAL, V41, P815, DOI [10.1109/TPAMI.2018.2815688, DOI 10.1109/TPAMI.2018.2815688]
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Ji M, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT RAIL TRANSPORTATION (ICIRT), P32, DOI 10.1109/ICIRT.2013.6696263
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuen J, 2016, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2016.399
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li Y, 2014, PR IEEE COMP DESIGN, P521, DOI 10.1109/ICCD.2014.6974732
   Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Ma Y.-F., 2002, ACM MULTIMEDIA, P533
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433
   Wang TT, 2016, LECT NOTES COMPUT SC, V9912, P450, DOI 10.1007/978-3-319-46484-8_27
   Wang Y, 2015, IEEE INT C MULT EXP, P1
   Wang Y, 2018, IEEE T NEUR NET LEAR, V29, P4833, DOI 10.1109/TNNLS.2017.2777489
   Wang Y, 2018, NEURAL NETWORKS, V103, P1, DOI 10.1016/j.neunet.2018.03.006
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang Y, 2017, IEEE T NEUR NET LEAR, V28, P57, DOI 10.1109/TNNLS.2015.2498149
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Wu L, 2019, IEEE T CYBERNETICS, V49, P1791, DOI 10.1109/TCYB.2018.2813971
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang JM, 2012, PROC CVPR IEEE, P2296, DOI 10.1109/CVPR.2012.6247940
   Yu Y., 2014, J. Image Graph., V2, P151, DOI DOI 10.12720/JOIG.2.2.151-157
   Zhang GX, 2009, COMPUT GRAPH FORUM, V28, P1897, DOI 10.1111/j.1467-8659.2009.01568.x
   Zhang J, 2016, MINIMUM BARRIER SALI, P1404, DOI [10.1109/ICCV.2015.165, DOI 10.1109/ICCV.2015.165]
   Zhang P., 2018, ARXIV180206960
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhang W., 2016, P INT JOINT C ART IN, P2153
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhu L, 2014, IEEE T IMAGE PROCESS, V23, P5094, DOI 10.1109/TIP.2014.2361024
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 46
TC 15
Z9 16
U1 8
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30793
EP 30807
DI 10.1007/s11042-018-6591-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200063
DA 2024-07-18
ER

PT J
AU Sur, C
AF Sur, Chiranjib
TI Survey of deep learning and architectures for visual
   captioning-transitioning between media and natural languages
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neural network; Deep learning; Natural language processing; Visual
   features; Representation learning; Sequential memory network
ID NEURAL-NETWORK; CLASSIFICATION; ALGORITHM; ATTENTION; SYSTEMS
AB Deep Learning Architectures has been researched the most in this decade because of its capability to scale up and solve problems that couldn't be solved before. Mean while many NLP applications cropped up and there is a requirement to understand how the concepts gradually evolved till date after perceptron was introduced in 1959. This document will provide a detailed description of the computational neuroscience starting from artificial neural network and how researchers retrospected the drawbacks faced by the previous architectures and paved the way for modern deep learning. Modern deep learning is more than what it had been perceived decades ago and had been extended to architectures, with exceptional intelligence, scalability and precision, beyond imagination. This document will provide an overview of the continuation of work and will also specifically deal with applications of various domains related to natural language processing and visual and media contents.
C1 [Sur, Chiranjib] Univ Florida, Comp & Informat Sci & Engn Dept, Gainesville, FL 32611 USA.
C3 State University System of Florida; University of Florida
RP Sur, C (corresponding author), Univ Florida, Comp & Informat Sci & Engn Dept, Gainesville, FL 32611 USA.
EM chiranjib@ufl.edu
RI Sur, Chiranjib/Z-4268-2019
OI Sur, Chiranjib/0000-0002-1563-9304
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   [Anonymous], 2015, ARXIV150205698
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2014, ABS14091259 CORR
   [Anonymous], 2014, Transactions of the Association for Computational Linguistics
   [Anonymous], 2017, ICCV
   [Anonymous], 2015, P IEEE C COMP VIS PA
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2017, CVPR
   [Anonymous], 2013, NIPS
   [Anonymous], 2012, P INT C NEUR INF PRO
   [Anonymous], 2007, ADV NEURAL INFORM PR
   [Anonymous], 2011, P 15 C COMP NAT LANG
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2009, AISTATS
   [Anonymous], 2015, ARXIV150501809
   [Anonymous], 2015, P IEEE C COMP VIS PA
   [Anonymous], 2018, ARXIV180400887
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   [Anonymous], PRINCIPLES ARTIFICIA
   [Anonymous], 2016, P IEEE C COMP VIS PA
   [Anonymous], 2008, PROC INT C MACHINE L
   [Anonymous], 2017, ARXIV170205658
   [Anonymous], 2015, FINITE ELEMENT METHO
   [Anonymous], 2016, ADV NEURAL INFORM PR
   [Anonymous], ARXIV13011880
   [Anonymous], 2010, P NEURIPS
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2015, Compressing deep neural networks using a rank-constrained topology
   [Anonymous], 2014, EMNLP
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2015, ARXIV150404788
   [Anonymous], 2015, P IEEE C COMPUTER VI
   [Anonymous], P 13 C EUR CHAPT ASS
   [Anonymous], 2015, NIPS
   [Anonymous], 2016, P IEEE C COMP VIS PA
   [Anonymous], 2018, ARXIV180407889
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2018, ARXIV180308314
   [Anonymous], 2018, ARXIV180500063
   [Anonymous], 2017, NPJ BREAST CANCER
   [Anonymous], 2016, AAAI
   [Anonymous], 2017, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, DOI DOI 10.1109/CVPR.2017.681
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2017, P 2017 ACM MULT C, DOI DOI 10.1145/3123266.3123275
   [Anonymous], 2011, P C EMP METH NAT LAN
   [Anonymous], 2015, 3 INT C LEARNING REP
   [Anonymous], 2018, ARXIV180508389
   [Anonymous], 2015, FINANCIAL REPORTING
   [Anonymous], 2015, P IEEE INT C COMP VI
   [Anonymous], 2012, P ICML WORKSH UNS TR
   [Anonymous], 2017, CVPR
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], AISTATS
   [Anonymous], 2015, ICML
   [Anonymous], P ASS COMP LING
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2018, ARXIV180405417
   [Anonymous], 2017, ARXIV170406972
   [Anonymous], 1986, P 8 ANN C COGN SCI S, DOI DOI 10.1109/69.917563
   [Anonymous], 2009, ADVNEURAL INF PROCES
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2010, INTERSPEECH, DOI DOI 10.1016/J.CSL.2010.08.008
   [Anonymous], ARXIV170403899
   [Anonymous], ARXIV160507683
   [Anonymous], 2015, P IEEE INT C COMP VI
   [Anonymous], 2010, EUR C COMP VIS
   Bayer J, 2009, LECT NOTES COMPUT SC, V5769, P755, DOI 10.1007/978-3-642-04277-5_76
   Bebis G., 1994, IEEE Potentials, V13, P27, DOI 10.1109/45.329294
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bengio Y, 2013, INT CONF ACOUST SPEE, P8624, DOI 10.1109/ICASSP.2013.6639349
   Bordes A., 2015, ARXIV150602075
   Chen FH, 2018, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2018.00146
   Chen H., 2017, ARXIV171202051
   Chen H, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P606
   Chen MH, 2017, AAAI CONF ARTIF INTE, P3981
   CHEN S, 1991, IEEE T NEURAL NETWOR, V2, P302, DOI 10.1109/72.80341
   Chen T., 2018, ARXIV180703871
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Cornia M, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3177745
   Dhillon PS, 2015, J MACH LEARN RES, V16, P3035
   Doersch C., 2016, CORR
   Du B, 2017, IEEE T CYBERNETICS, V47, P1017, DOI 10.1109/TCYB.2016.2536638
   Tran DN, 2015, IEEE INT CON MULTI
   Fu K., 2018, IEEE T NEUR NET LEAR, V29, P5910, DOI DOI 10.1109/TNNLS.2018.2813306
   Fu K, 2017, IEEE T PATTERN ANAL, V39, P2321, DOI 10.1109/TPAMI.2016.2642953
   FUNAHASHI K, 1993, NEURAL NETWORKS, V6, P801, DOI 10.1016/S0893-6080(05)80125-X
   Gan Z, 2016, ARXIV161108002
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goldberg Y., 2014, ARXIV PREPRINT ARXIV, V1402, P3722
   Graves A., 2014, ABS14105401 CORR
   Han S., 2015, ARXIV151000149
   Harzig P, 2018, ARXIV180201958
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HEERMANN PD, 1992, IEEE T GEOSCI REMOTE, V30, P81, DOI 10.1109/36.124218
   Herculano-Houzel S, 2009, FRONT HUM NEUROSCI, V3, DOI 10.3389/neuro.09.031.2009
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Huang E.H., 2012, ACL
   HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574, DOI 10.1113/jphysiol.1959.sp006308
   Hutchinson B, 2013, IEEE T PATTERN ANAL, V35, P1944, DOI 10.1109/TPAMI.2012.268
   Irsoy O, 2014, ADV NEUR IN, V27
   Izhikevich EM, 2004, IEEE T NEURAL NETWOR, V15, P1063, DOI 10.1109/TNN.2004.832719
   Jiang Z, 2016, IEEE INT CONF COMMUN, DOI 10.1109/ICCChinaW.2016.7586710
   Karpathy A., 2015, P IEEE C COMP VIS PA
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kilickaya M, 2017, IET COMPUT VIS, V11, P398, DOI 10.1049/iet-cvi.2016.0286
   Kiros R, 2014, Arxiv, DOI arXiv:1411.2539
   Kohonen T, 1998, NEUROCOMPUTING, V21, P19, DOI 10.1016/S0925-2312(98)00031-9
   Kohonen T, 1995, SPRINGER SERIES INFO, P175, DOI DOI 10.1007/978-3-642-97610-0_6
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Kumar A., 2015, CoRR
   Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028
   Lee H., 2009, P 26 ANN INT C MACH, P609
   Levy O, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P302, DOI 10.3115/v1/p14-2050
   Liu CX, 2017, AAAI CONF ARTIF INTE, P4176
   Lo SCB, 1995, NEURAL NETWORKS, V8, P1201, DOI 10.1016/0893-6080(95)00061-5
   Lu JS, 2018, PROC CVPR IEEE, P7219, DOI 10.1109/CVPR.2018.00754
   Luong Thang, 2013, P 17 C COMP NAT LANG, P104
   Mao Junhua, 2014, CoRR
   Mnih A., 2013, Advances in Neural Information Processing Systems, V26, P2265
   Mnih Andriy, 2009, Advances in Neural Information Processing Systems, P1081
   Mnih V., 2013, P ADV C NEUR INF PRO, P1
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Perozzi B., 2014, KDD, P701, DOI DOI 10.1145/2623330.2623732
   Pfister T, 2015, LECT NOTES COMPUT SC, V9003, P538, DOI 10.1007/978-3-319-16865-4_35
   Salakhutdinov R, 2013, IEEE T PATTERN ANAL, V35, P1958, DOI 10.1109/TPAMI.2012.269
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   Salakhutdinov Ruslan, 2011, P 24 INT C NEUR INF, P2061
   SCHMIDHUBER J, 1992, NEURAL COMPUT, V4, P234, DOI 10.1162/neco.1992.4.2.234
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Shaw AM, 1997, COMPUT CHEM ENG, V21, P371, DOI 10.1016/S0098-1354(96)00281-5
   Socher R., 2011, PROC INT C MACH LEAR, P129
   Socher R., 2014, Trans Assoc Comput Linguist, V2, P207, DOI [DOI 10.1162/TACLA00177, 10.1162/tacl_a_00177, DOI 10.1162/TACL_A_00177]
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Strobl EV, 2013, 2013 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2013), VOL 1, P414, DOI 10.1109/ICMLA.2013.84
   Sur C, 2019, J AMB INTEL HUM COMP, V10, P3573, DOI 10.1007/s12652-018-1084-9
   Sur C, 2018, J EXP THEOR ARTIF IN, V30, P733, DOI 10.1080/0952813X.2018.1467496
   Sutskever I., 2009, Advances in Neural Information Processing Systems, P1601
   Sutskever Ilya, 2011, P 28 INT C MACH LEAR, P1017
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Tavakoli HR, 2017, IEEE I CONF COMP VIS, P2506, DOI 10.1109/ICCV.2017.272
   Turian J, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P384
   Tymoshenko K., 2016, 2016 C N AM CHAPTER, P1268
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Vinyals, 2015, 29 ANN C NEURAL INFO, V28
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Wang C, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3115432
   Wu CL, 2018, SIGNAL PROCESS-IMAGE, V67, P100, DOI 10.1016/j.image.2018.06.002
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Xu J, 2018, ARXIV180508661
   Yao T, 2017, PROC CVPR IEEE, P5263, DOI 10.1109/CVPR.2017.559
   Ye SM, 2018, IEEE T IMAGE PROCESS, V27, P5514, DOI 10.1109/TIP.2018.2855406
   You Quanzeng, 2018, ARXIV180110121
   Young P., 2014, T ASSOC COMPUT LING, V2, P67, DOI [DOI 10.1162/TACL_A_00166, 10.1162/tacl_a_00166]
   Yu D, 2013, IEEE T AUDIO SPEECH, V21, P388, DOI 10.1109/TASL.2012.2227738
   Zhang L, 2017, ARXIV PREPRINT ARXIV
   Zhang MX, 2019, IEEE T IMAGE PROCESS, V28, P32, DOI 10.1109/TIP.2018.2855415
   Zhang X., 2015, Character-level convolutional networks for text classification, P649
   Zhang Xiang., 2015, Text Understanding From Scratch
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22821, DOI 10.1007/s11042-018-5765-3
   Zhang YD, 2019, MULTIMED TOOLS APPL, V78, P3613, DOI 10.1007/s11042-017-5243-3
   Zhao W, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1205
   Zhuang Jinfeng, 2011, JMLR Proceedings, V15, P909
NR 172
TC 13
Z9 14
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32187
EP 32237
DI 10.1007/s11042-019-08021-1
PG 51
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000052
DA 2024-07-18
ER

PT J
AU Zhang, J
   Wang, HB
   Ren, YG
AF Zhang, Jing
   Wang, Huibing
   Ren, Yonggong
TI Robust tracking via weighted online extreme learning machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Target tracking; Extreme learning machine; Online sequential extreme
   learning machine; Imbalance dataset
ID VISUAL TRACKING; NETWORKS; SELECTION
AB The tracking method based on the extreme learning machine (ELM) is efficient and effective. ELM randomly generates input weights and biases in the hidden layer, and then calculates and computes the output weights by reducing the iterative solution to the problem of linear equations. Therefore, ELM offers the satisfying classification performance and fast training time than other discriminative models in tracking. However, the original ELM method often suffers from the problem of the imbalanced classification distribution, which is caused by few target objects, leading to under-fitting and more background samples leading to over-fitting. Worse still, it reduces the robustness of tracking under special conditions including occlusion, illumination, etc. To address above problems, in this paper, we present a robust tracking algorithm. First, we introduce the local weight matrix that is the dynamic creation from the data distribution at the current frame in the original ELM so as to balance between the empirical and structure risk, and fully learn the target object to enhance the classification performance. Second, we improve it to the incremental learning method ensuring tracking real-time and efficient. Finally, the forgetting factor is used to strengthen the robustness for changing of the classification distribution with time. Meanwhile, we propose a novel optimized method to obtain the optimal sample as the target object, which avoids tracking drift resulting from noisy samples. Therefore, our tracking method can fully learn both of the target object and background information to enhance the tracking performance, and it is evaluated in 20 challenge image sequences with different attributes including illumination, occlusion, deformation, etc., which achieves better performance than several state-of-the-art methods in terms of effectiveness and robustness.
C1 [Zhang, Jing; Ren, Yonggong] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116081, Liaonig, Peoples R China.
   [Wang, Huibing] Dalian Maritime Univ, Informat Sci & Technol Coll, Dalian 116024, Liaoning, Peoples R China.
C3 Liaoning Normal University; Dalian Maritime University
RP Ren, YG (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116081, Liaonig, Peoples R China.
EM zhangjing_0412@163.com; whb08421005@mail.dlut.edu.cn; ryg@lnnu.edu.cn
FU Doctoral Scientific Research Foundation of Liaoning Province
   [20170520207]
FX This study was funded by the Doctoral Scientific Research Foundation of
   Liaoning Province (20170520207).
CR [Anonymous], 2006, P BRIT MACH VIS C
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2015, ACM MULTIMEDIA
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247881
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bala A, 2016, ENG SCI TECHNOL, V19, P101, DOI 10.1016/j.jestch.2015.06.008
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Chi JN, 2014, NEUROCOMPUTING, V128, P42, DOI 10.1016/j.neucom.2013.03.052
   Chrysos GG, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P954, DOI 10.1109/ICCVW.2015.126
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Deng CW, 2015, SCI CHINA INFORM SCI, V58, DOI 10.1007/s11432-014-5269-3
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Elkan C., 2001, IJCAI 2001, V17, P973, DOI DOI 10.5555/1642194.1642224
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Exner D., 2010, Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on, P9
   Grabner H., 2006, BMVC, P47
   He X, 2014, IEEE T IND ELECTRON, V61, P1454, DOI 10.1109/TIE.2013.2261038
   Huang G, 2015, NEURAL NETWORKS, V61, P32, DOI 10.1016/j.neunet.2014.10.001
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kasun LLC, 2016, IEEE T IMAGE PROCESS, V25, P3906, DOI 10.1109/TIP.2016.2570569
   Li HX, 2015, LECT NOTES COMPUT SC, V9007, P194, DOI 10.1007/978-3-319-16814-2_13
   Li HX, 2011, PROC CVPR IEEE, P1305, DOI 10.1109/CVPR.2011.5995483
   Li X, 2011, IEEE I CONF COMP VIS, P1156, DOI 10.1109/ICCV.2011.6126364
   LIU IC, 1993, IEEE T MED IMAGING, V12, P334, DOI 10.1109/42.232264
   Mei X, 2011, PROC CVPR IEEE, P1257
   PARAG T., 2008, IEEE C COMPUTER VISI, P1, DOI [DOI 10.1109/CVPR.2008.4587556, 10.1109/CVPR.2008.4587556]
   Revaud J, 2015, PROC CVPR IEEE, P1164, DOI 10.1109/CVPR.2015.7298720
   Rong HJ, 2009, IEEE T SYST MAN CY B, V39, P1067, DOI 10.1109/TSMCB.2008.2010506
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Schindelin J, 2015, MOL REPROD DEV, V82, P518, DOI 10.1002/mrd.22489
   Tang JX, 2016, IEEE T NEUR NET LEAR, V27, P809, DOI 10.1109/TNNLS.2015.2424995
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Wang Y., 2016, P 25 INT JOINT C ART, P2153
   Wang Y., 2015, ACM SIGIR
   Wang Y, 2018, IEEE T NEURAL NETWOR
   Wang Y, 2018, NEURAL NETWORKS, V103, P1, DOI 10.1016/j.neunet.2018.03.006
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang Y, 2017, IEEE T NEUR NET LEAR, V28, P57, DOI 10.1109/TNNLS.2015.2498149
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Wen J, 2010, NEUROCOMPUTING, V73, P827, DOI 10.1016/j.neucom.2009.10.013
   Wu L, 2013, ACM MULTIMEDIA
   Wu L, 2018, ARXIV180411013
   Wu L, 2019, IEEE T MULTIMEDIA, V21, P1412, DOI 10.1109/TMM.2018.2877886
   Wu L, 2018, COMPUT VIS IMAGE UND, V167, P63, DOI 10.1016/j.cviu.2017.11.009
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Wu L, 2017, IMAGE VISION COMPUT, V57, P58, DOI 10.1016/j.imavis.2016.11.008
   Yeh YJ, 2009, IEEE T CIRC SYST VID, V19, P442, DOI 10.1109/TCSVT.2009.2013520
   Zhang J., 2016, J MATER CIVIL ENG, V28, P1
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhou X, 2015, IEEE IMAGE PROC, P4892, DOI 10.1109/ICIP.2015.7351737
   Zong WW, 2013, NEUROCOMPUTING, V101, P229, DOI 10.1016/j.neucom.2012.08.010
NR 57
TC 1
Z9 1
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30723
EP 30747
DI 10.1007/s11042-018-6500-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200060
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhou, ZH
   Dai, M
   Wang, TL
   Zhao, RZ
AF Zhou, Zhiheng
   Dai, Ming
   Wang, Tianlei
   Zhao, Ruzheng
TI Prior distribution-based statistical active contour model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active contour model; Level-set method; Image segmentation; Prior
   distribution
ID INFORMATION; FRAMEWORK; MUMFORD; DRIVEN; SNAKES; MRI
AB Employing prior information can greatly improve the segmentation result of many image segmentation problems. For example, a commonly used prior information is the shape of the object. In this paper, we introduce a different kind of prior information called the prior distribution. On the basis of non-parametric statistical active contour model, we add prior distribution energy to build a novel prior active contour model. During the convergence of contour curve, distribution difference between the inside and outside of the active contour is maximized while the distribution difference between the inside/outside of contour and the prior object/background is minimized. Furthermore, in order to improve the computation speed, a method to accelerate the computation speed is also proposed, which significantly relieves the burden of estimating probability density functions. As the experimental results suggest, satisfactory effects can be achieved in the segmentation of synthetic images and natural images via the our algorithm. Compared with the traditional non-parametric statistical active contour model without prior information, our method achieves a distinct improvement in both accuracy and computation efficiency.
C1 [Zhou, Zhiheng; Dai, Ming; Zhao, Ruzheng] South China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Guangdong, Peoples R China.
   [Wang, Tianlei] Wuyi Univ, Dept Intelligent Mfg, Jiangmen 529020, Guangdong, Peoples R China.
C3 South China University of Technology; Wuyi University
RP Zhou, ZH (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Guangdong, Peoples R China.
EM zhouzh@scut.edu.cn; tianlei.wang@aliyun.com
RI Zhou, zhiheng/HNC-4591-2023
FU National Key R&D Program of China [2018YFC0309400]; National Natural
   Science Foundation of China [61871188]; Guangzhou city science and
   technology research projects [201902020008]
FX The work is supported by National Key R&D Program of China
   (2018YFC0309400), National Natural Science Foundation of China
   (61871188), Guangzhou city science and technology research
   projects(201902020008).
CR Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   [Anonymous], 2007, 2007 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2007.383014
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Bresson X, 2006, INT J COMPUT VISION, V68, P145, DOI 10.1007/s11263-006-6658-x
   Brown ES, 2012, INT J COMPUT VISION, V98, P103, DOI 10.1007/s11263-011-0499-y
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan T, 2005, PROC CVPR IEEE, P1164
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen Z, 2018, NEUROCOMPUTING, V289, P180, DOI 10.1016/j.neucom.2018.02.002
   Chen Z, 2017, IEEE SIGNAL PROC LET, V24, P1443, DOI 10.1109/LSP.2017.2736159
   Cheng ZY, 2016, MULTIMEDIA SYST, V22, P509, DOI 10.1007/s00530-014-0432-7
   COHEN LD, 1991, CVGIP-IMAG UNDERSTAN, V53, P211, DOI 10.1016/1049-9660(91)90028-N
   Cremers D, 2003, PATTERN RECOGN, V36, P1929, DOI 10.1016/S0031-3203(03)00056-6
   Foulonneau A, 2006, IEEE T PATTERN ANAL, V28, P1352, DOI 10.1109/TPAMI.2006.154
   Gong MG, 2016, IEEE T FUZZY SYST, V24, P1176, DOI 10.1109/TFUZZ.2015.2505328
   Hsieh CW, 2018, MULTIMED TOOLS APPL, V77, P20087, DOI 10.1007/s11042-017-5434-y
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kim JM, 2005, IEEE T IMAGE PROCESS, V14, P1486, DOI 10.1109/TIP.2005.854442
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Leventon M., 2000, P IEEE C COMPUTER VI, P316, DOI DOI 10.1109/CVPR.2000.855835
   Leventon ME, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P4, DOI 10.1109/MMBIA.2000.852354
   Li B, 2007, IEEE T IMAGE PROCESS, V16, P2096, DOI 10.1109/TIP.2007.899601
   Li CM, 2005, PROC CVPR IEEE, P430
   Michailovich O, 2007, IEEE T IMAGE PROCESS, V16, P2787, DOI 10.1109/TIP.2007.908073
   Mitiche A, 2010, SPRINGER TOP SIGN PR, V5, P1
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Paragios N, 2002, J VIS COMMUN IMAGE R, V13, P249, DOI 10.1006/jvci.2001.0475
   Peng Y, 2017, NEUROCOMPUTING, V261, P242, DOI 10.1016/j.neucom.2016.05.113
   RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153
   Schoenemann T, 2012, INT J COMPUT VISION, V99, P53, DOI 10.1007/s11263-012-0518-7
   Shao D. P., 2009, Chin. J. Stereol. Image Anal, V3, P7
   Unal G, 2005, INT J COMPUT VISION, V62, P199, DOI 10.1007/s11263-005-4880-6
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wu H, 2013, IEEE T PATTERN ANAL, V35, P1298, DOI 10.1109/TPAMI.2012.207
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
   Zhuo T, 2018, ARXIV181003783
NR 38
TC 6
Z9 6
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35813
EP 35833
DI 10.1007/s11042-019-08101-2
EA OCT 2019
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000491551600004
DA 2024-07-18
ER

PT J
AU Jin, C
   Li, Q
   Jin, HW
AF Jin, Cong
   Li, Qian
   Jin, Hu-Wei
TI An adaptive VPDE image denoising model based on structure tensor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Structure tensor; Total variation; Norm parameter;
   Partial differential equation
ID PARTIAL-DIFFERENTIAL-EQUATION; VARIATIONAL MODEL; REGULARIZATION
AB Image denoising is one of the challenging topics in image processing. Since the formation mechanism of the degraded image is unknown, it is difficult to achieve effective image denoising. Most existing denoising methods are easy to blur the edges of the image so that it is difficult to maintain more image detail information. In recent years, partial differential equation (PDE) has been applied to image denoising, which has shown good application prospects. However, the image denoising methods based on PDE are easy to appear staircase effect and edge blur, and can not achieve satisfactory denoising effect. To avoid some problems, an adaptive variational PDE (VPDE) image denoising model based on the structure tensor is proposed and analyzed. In the proposed model, since the structure tensor can provide more local structural information and direction information of the gradient, the eigenvalues of the structure tensor of an image are used to construct the norm parameter. Through theoretical analysis and experiments, we can confirm that the proposed norm parameter has the following adaptive characteristics: (1) In the flat region of the image, the proposed norm parameter tends to 2, so which has the characteristic of isotropic diffusion. (2) At the edge region of the image, the norm parameter tends to 1, and which spreads only along the tangential direction of the image edge. The experimental results from both subjective and objective aspects show that using these adaptive characteristics, the proposed image denoising model can effectively avoid staircase effect, preserve the image details, and obtain satisfactory denoising effect.
C1 [Jin, Cong; Li, Qian] Cent China Normal Univ, Sch Comp, Wuhan 430079, Hubei, Peoples R China.
   [Jin, Hu-Wei] Ecole Normale Super, Dept Phys, 24 Rue Lhomond, F-75231 Paris 5, France.
C3 Central China Normal University; Universite PSL; Ecole Normale
   Superieure (ENS)
RP Jin, C (corresponding author), Cent China Normal Univ, Sch Comp, Wuhan 430079, Hubei, Peoples R China.
EM jincong@mail.ccnu.edu.cn
CR [Anonymous], 2016, DIGITAL IMAGE PROCES, DOI DOI 10.1007/978-1-4471-6684-9_23
   Bo L, 2019, J SUPERCOMPUT, V75, P770, DOI 10.1007/s11227-018-2611-3
   Brox T, 2006, IMAGE VISION COMPUT, V24, P41, DOI 10.1016/j.imavis.2005.09.010
   Chen Q, 2010, IMAGE VISION COMPUT, V28, P298, DOI 10.1016/j.imavis.2009.04.012
   Chen YJ, 2015, PROC CVPR IEEE, P5261, DOI 10.1109/CVPR.2015.7299163
   Chierchia G, 2014, IEEE T IMAGE PROCESS, V23, P5531, DOI 10.1109/TIP.2014.2364141
   Drogoul A, 2016, INVERSE PROBL IMAG, V10, P51, DOI 10.3934/ipi.2016.10.51
   Duran J, 2015, REV OCCIDENTE, P141
   Estellers V, 2015, IEEE T IMAGE PROCESS, V24, P1777, DOI 10.1109/TIP.2015.2409562
   Everts I, 2014, IEEE T IMAGE PROCESS, V23, P1569, DOI 10.1109/TIP.2014.2302677
   Gu GY, 2017, INVERSE PROBL, V33, DOI 10.1088/1361-6420/aa9383
   Jin C, 2013, J OPTICS-UK, V15, DOI 10.1088/2040-8978/15/2/025402
   Kamalaveni V, 2017, MULTIMED TOOLS APPL, V76, P18815, DOI 10.1007/s11042-016-4341-y
   Lefkimmiatis S., 2013, Proceedings, P48
   Lefkimmiatis S, 2015, IEEE T COMPUT IMAG, V1, P16, DOI 10.1109/TCI.2015.2434616
   Lefkimmiatis S, 2015, SIAM J IMAGING SCI, V8, P1090, DOI 10.1137/14098154X
   Li Bo, 2008, Acta Automatica Sinica, V34, P849, DOI 10.3724/SP.J.1004.2008.00849
   Liu D, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P842
   Liu Y, 2019, NEUROCOMPUTING, V330, P465, DOI 10.1016/j.neucom.2018.11.039
   Liu Y, 2018, DIGIT SIGNAL PROCESS, V78, P42, DOI 10.1016/j.dsp.2018.01.017
   Lu Z., 2012, THESIS
   Pu YF, 2014, MATH METHOD APPL SCI, V37, P1784, DOI 10.1002/mma.2935
   Shahdoosti HR, 2018, MULTIMED TOOLS APPL, V77, P22649, DOI 10.1007/s11042-017-5067-1
   Shi ZH, 2017, MULTIMED TOOLS APPL, V76, P14921, DOI 10.1007/s11042-016-4284-3
   Siddig A, 2018, COMPUT MATH APPL, V76, P1056, DOI 10.1016/j.camwa.2018.05.040
   Song B., 2003, THESIS
   Song XM, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P753, DOI 10.1145/3123266.3123314
   Talebi H, 2014, IEEE T IMAGE PROCESS, V23, P755, DOI 10.1109/TIP.2013.2293425
   Tao DC, 2008, IEEE T CIRC SYST VID, V18, P1397, DOI 10.1109/TCSVT.2008.2002825
   Tikhonov A. N, 2013, NUMERICAL METHODS SO
   Tu ZG, 2017, PATTERN RECOGN, V65, P11, DOI 10.1016/j.patcog.2016.10.027
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   Wright J., 2005, P IEEE WORKSHOP MOTI, V2, P14
   Xie J., 2012, ADV NEURAL INFORM PR, P341
   Xu JL, 2019, SIGNAL IMAGE VIDEO P, V13, P967, DOI 10.1007/s11760-019-01434-3
   Yan J, 2015, MULTIDIM SYST SIGN P, V26, P243, DOI 10.1007/s11045-013-0255-2
   Yuan QQ, 2012, IEEE T GEOSCI REMOTE, V50, P3660, DOI 10.1109/TGRS.2012.2185054
   Zeng W, 2015, MULTIMED TOOLS APPL, V74, P743, DOI 10.1007/s11042-013-1692-5
   [张红英 ZHANG Hongying], 2006, [光电工程, Opto-Electronic Engineering], V33, P50
   Zheng Yuhui, 2008, Journal of Computer Aided Design & Computer Graphics, V20, P506
NR 40
TC 3
Z9 4
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 28331
EP 28354
DI 10.1007/s11042-019-07912-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000069
DA 2024-07-18
ER

PT J
AU Lu, ZC
   Yeung, HWF
   Qu, Q
   Chung, YY
   Chen, XM
   Chen, ZB
AF Lu, Zhicheng
   Yeung, Henry W. F.
   Qu, Qiang
   Chung, Yuk Ying
   Chen, Xiaoming
   Chen, Zhibo
TI Improved image classification with 4D light-field and interleaved
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Light field image; Image classification; Convolutional neural network
ID DEPTH ESTIMATION; STEREO
AB Image classification is a well-studied problem. However, there remains challenges for some special categories of images. This paper proposes a new deep convolutional neural network to improve image classification using extra light-field angular information. The proposed network model employs transfer learning by replacing the fully connected layer of a VGG network with a set of interleaved spatial-angular filters. The resulting model takes advantage of both the spatial and angular information of light-field images (LFIs), thus providing more accurate classification performance over traditional models. To evaluate the proposed network model, we established a light-field image dataset, currently consisting of 560 captured LFIs, which have been divided into 11 labeled categories. Based on this dataset, our experimental results show that the proposed LFI model yields an average of 92% classification accuracy as oppose to 84% from the model using traditional 2D images and 85% from the model using stereo pair images. In particular, on classifying challenging objects such as the "screen" images, the proposed LFI model demonstrated to have significant improvement of 16% and 12% respectively over the 2D image model and the stereo image model.
C1 [Lu, Zhicheng; Chen, Xiaoming; Chen, Zhibo] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei, Anhui, Peoples R China.
   [Lu, Zhicheng; Yeung, Henry W. F.; Qu, Qiang; Chung, Yuk Ying] Univ Sydney, Sch Informat Technol, Sydney, NSW, Australia.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; University of Sydney
RP Chen, XM; Chen, ZB (corresponding author), Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei, Anhui, Peoples R China.
EM xiaoming.chen@iat.ustc.edu.cn; chenzhibo@ustc.edu.cn
OI Qu, Qiang/0000-0002-6648-5050; Lu, Zhicheng/0000-0002-2995-0996
FU National Key Research and Development Program of China [2016YFC0801001];
   National Program on Key Basic Research Projects (973 Program)
   [2015CB351803]; NSFC [61571413, 61632001, 61390514]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant No. 2016YFC0801001, the
   National Program on Key Basic Research Projects (973 Program) under
   Grant 2015CB351803, NSFC under Grant 61571413, 61632001, 61390514.
CR ADELSON EH, 1992, IEEE T PATTERN ANAL, V14, P99, DOI 10.1109/34.121783
   [Anonymous], BEGINNERS GUIDE UN 2
   [Anonymous], IM TREE VIEW
   [Anonymous], 2005, Comput. Sci. Tech. Rep.
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2018, IEEE T CIRCUITS SYST
   [Anonymous], 2017, TINY IMAGENET IMAGE
   [Anonymous], 2017, arXiv
   [Anonymous], 2017, ARXIV171209216
   Chen J, 2018, IEEE SIGNAL PROC LET, V25, P1403, DOI 10.1109/LSP.2018.2861212
   Chen J, 2018, IEEE T IMAGE PROCESS, V27, P4889, DOI 10.1109/TIP.2018.2839524
   Chen J, 2018, IEEE T IMAGE PROCESS, V27, P314, DOI 10.1109/TIP.2017.2750413
   Chen YL, 2017, COMM COM INF SC, V772, P577, DOI 10.1007/978-981-10-7302-1_48
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Eckert S, 2017, J ENVIRON MANAGE, V193, P592, DOI 10.1016/j.jenvman.2017.02.061
   Gao XHW, 2016, PROCEEDINGS OF THE 2016 SAI COMPUTING CONFERENCE (SAI), P28, DOI 10.1109/SAI.2016.7555958
   Hahnloser RHR, 2000, NATURE, V405, P947, DOI 10.1038/35016072
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762
   Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251
   Kooi FL, 2004, DISPLAYS, V25, P99, DOI 10.1016/j.displa.2004.07.004
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Raghavendra R, 2015, IEEE T IMAGE PROCESS, V24, P1060, DOI 10.1109/TIP.2015.2395951
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Wang TC, 2016, LECT NOTES COMPUT SC, V9907, P121, DOI 10.1007/978-3-319-46487-9_8
   Wang YL, 2016, IEEE IMAGE PROC, P1459, DOI 10.1109/ICIP.2016.7532600
   Wu GC, 2017, IEEE J-STSP, V11, P926, DOI 10.1109/JSTSP.2017.2747126
   Yoon Y, 2015, PROCEEDINGS 2015 IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN-CENTRIC COMPUTING (VL/HCC), P95, DOI 10.1109/VLHCC.2015.7357203
   Yosinski J, 2014, ADV NEUR IN, V27
   Zhang YB, 2017, IEEE T CIRC SYST VID, V27, P739, DOI 10.1109/TCSVT.2016.2555778
   Zhao SY, 2017, IEEE IMAGE PROC, P4562, DOI 10.1109/ICIP.2017.8297146
NR 36
TC 13
Z9 13
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29211
EP 29227
DI 10.1007/s11042-018-6597-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700045
DA 2024-07-18
ER

PT J
AU Zhang, X
   Zhao, WQ
   Luo, HZ
   Chen, L
   Peng, JY
   Fan, JP
AF Zhang, Xiang
   Zhao, Wanqing
   Luo, Hangzai
   Chen, Long
   Peng, Jinye
   Fan, Jianping
TI Plant recognition via leaf shape and margin features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Plant recognition; Leaf shape; Leaf margin; Feature set
ID DISTANCE; REPRESENTATION
AB Botanists and foresters empirically determine plant categories mainly via visual features of leaves, e.g. leaf shape, leaf margin, leaf arrangement and leaf venation. The leaf shape and leaf margin can be captured easily with cheap devices. As a result, automatic plant recognition is generally based on leaf shape or margin features. In this paper, a set of features that depict leaf shape and margin are proposed to improve the performance of plant recognition. The proposed margin features utilize the area ratio to quantify the convexity/concavity of each contour point at different scales and such margin features are effective in capturing the global information and contour details. The area ratio is the ration of the disk to the inside of the contour. The proposed shape features use a combination of morphological features to characterize the global shape of the leaf, which has merits in preserving the geometric properties of leaf shape. Additionally, a series of multi-grained fusion methods that combine the margin feature and global shape feature are proposed as a better representation of a leaf. To validate the effectiveness and generalization, we evaluate our methods on two public datasets: Swedish Leaf dataset and ICL Leaf dataset. The experimental results show the superiority of our methods over state-of-the-art shape methods.
C1 [Zhang, Xiang; Zhao, Wanqing; Luo, Hangzai; Chen, Long; Peng, Jinye] Northwestern Univ, Sch Informat & Technol, Xian 710127, Shaanxi, Peoples R China.
   [Fan, Jianping] UNC, Dept Comp Sci, Charlotte, NC 28223 USA.
C3 Northwest University Xi'an; University of North Carolina; University of
   North Carolina Charlotte
RP Luo, HZ (corresponding author), Northwestern Univ, Sch Informat & Technol, Xian 710127, Shaanxi, Peoples R China.
EM ZhangXiang2015@stumail.nwu.edu.cn; zhaowq@nwu.edu.cn; hzluo@nwu.edu.cn;
   longchen@stumail.nwu.edu.cn; pjy@nwu.edu.cn; jfan@uncc.edu
RI Zhao, Wanqing/ADL-9932-2022; Peng, Jin/HZH-6965-2023
OI Zhang, Xiang/0000-0001-8521-569X; Zhao, Wanqing/0000-0001-7622-0665
FU National Key R&D Program of China [2018YFB0204100]; National Nature
   Science Foundation of China [61772419]; Changjiang Scholars and
   Innovative Research Team in University [IRT_17R87]
FX This work was supported by National Key R&D Program of China under grant
   no. 2018YFB0204100, National Nature Science Foundation of China under
   grant no. 61772419, Changjiang Scholars and Innovative Research Team in
   University under grant no. IRT_17R87.
CR Alajlan N, 2007, PATTERN RECOGN, V40, P1911, DOI 10.1016/j.patcog.2006.12.005
   [Anonymous], PLANT LEAF CLASSIFIC
   [Anonymous], 2007, 2007 IEEE C COMP VIS, DOI 10.1109/CVPR.2007.383018
   [Anonymous], TROP AGR RES
   [Anonymous], 2013, ARXIV14014447
   [Anonymous], INT J ADV COMPUT RES
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Arun Priya C., 2012, Proceedings of the 2012 International Conference on Pattern Recognition, Informatics and Medical Engineering (PRIME), P428, DOI 10.1109/ICPRIME.2012.6208384
   Belhumeur PN, 2008, LECT NOTES COMPUT SC, V5305, P116, DOI 10.1007/978-3-540-88693-8_9
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Chaki J, 2015, PATTERN RECOGN LETT, V58, P61, DOI 10.1016/j.patrec.2015.02.010
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Cristianini N., 2001, AI MAG, V30, P103, DOI [DOI 10.1108/K.2001.30.1.103.6, DOI 10.1609/AIMAG.V22I2.1566, 10.1609/aimag.v22i2.1566]
   Cui CR, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1013, DOI 10.1145/3077136.3080704
   Du JX, 2007, APPL MATH COMPUT, V185, P883, DOI 10.1016/j.amc.2006.07.072
   Hu RX, 2012, IEEE T IMAGE PROCESS, V21, P4667, DOI 10.1109/TIP.2012.2207391
   Kalyoncu C, 2015, COMPUT VIS IMAGE UND, V133, P102, DOI 10.1016/j.cviu.2014.11.001
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36
   Lee SH, 2015, IEEE IMAGE PROC, P452, DOI 10.1109/ICIP.2015.7350839
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Rojanamontien M, 2017, INT JOINT CONF COMP
   Satti V., 2013, International Journal of Engineering Science and Technology (IJEST), V4, P874
   Simonyan K., 2014, Very Deep Convolutional Networks for Large-Scale Image Recognition
   Soderkvist Oskar., 2001, COMPUTER VISION CLAS, P74
   Tzionas P, 2005, 5 INT C TECHNOLOGY A, P365, DOI [10.15388/Informatica.2005.104, DOI 10.15388/INFORMATICA.2005.104]
   Wang JW, 2012, PATTERN RECOGN LETT, V33, P134, DOI 10.1016/j.patrec.2011.09.042
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120
   Xu CJ, 2009, IEEE T PATTERN ANAL, V31, P180, DOI 10.1109/TPAMI.2008.199
   Yang CZ, 2016, FRONT ARTIF INTEL AP, V285, P269, DOI 10.3233/978-1-61499-672-9-269
   Yang XW, 2009, PROC CVPR IEEE, P357, DOI 10.1109/CVPRW.2009.5206844
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
NR 33
TC 14
Z9 14
U1 6
U2 59
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27463
EP 27489
DI 10.1007/s11042-019-07846-0
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000031
DA 2024-07-18
ER

PT J
AU Bonny, T
   Rabie, T
   Baziyad, M
   Balid, W
AF Bonny, Talal
   Rabie, Tamer
   Baziyad, Mohammed
   Balid, Walid
TI SHORT: Segmented histogram technique for robust real-time object
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time; Object recognition; FPGA; YALE database; Road signs;
   Eigenfaces
ID FACE RECOGNITION
AB Object recognition is a broad area that covers several topics including face recognition, gesture recognition, human gait recognition, traffic road signs recognition, among many others. Object recognition plays a vital role in several real-time applications such as video surveillance, traffic analysis, security systems, and image retrieval. This work introduces a novel, real-time object recognition approach, namely "SHORT": segmented histogram object recognition technique. "SHORT" implements segmentation technique applied on the histogram of selected vectors of an image to identify similar image(s) in a database. The proposed technique performance was evaluated by means of two different image databases, namely the Yale Faces and Traffic Road Signs. The robustness was also assessed by applying different levels of distortion on both databases using Gaussian noise and blur, and testing distortion impact on recognition rates. Additionally, the efficiency was evaluated by comparing the recognition execution time of the proposed technique with another well-known recognition algorithm called "Eigenfaces". The experimental results revealed successful recognition on clear and distorted objects. Moreover, "SHORT" performed 4.5X faster than the "Eigenfaces" algorithm under the same conditions. Furthermore, the "SHORT" algorithm was implemented on FPGA hardware by exploiting data parallelism to improve the execution performance. The results showed that the FPGA hardware version is 28X faster than the "Eigenfaces" algorithm, which makes "SHORT" a robust and practical solution for real-time applications.
C1 [Bonny, Talal; Rabie, Tamer; Baziyad, Mohammed] Univ Sharjah, Dept Elect & Comp Engn, Sharjah, U Arab Emirates.
   [Balid, Walid] Univ Oklahoma, Dept Elect & Comp Engn, Norman, OK 73019 USA.
C3 University of Sharjah; University of Oklahoma System; University of
   Oklahoma - Norman
RP Bonny, T (corresponding author), Univ Sharjah, Dept Elect & Comp Engn, Sharjah, U Arab Emirates.
EM tbonny@sharjah.ac.ae; trabie@sharjah.ac.ae; mbaziyad@sharjah.ac.ae;
   walid@ou.edu
RI Bonny, Talal/HLX-3107-2023
OI Bonny, Talal/0000-0003-1111-0304
CR [Anonymous], 2016, TRAFFIC ROAD SIGN DA
   [Anonymous], SIGNAL IMAGE VIDEO P
   [Anonymous], IEEE T NEURAL NETWOR
   [Anonymous], 2013, ARXIV PREPRINT ARXIV
   Bateux Q, 2017, IEEE ROBOT AUTOM LET, V2, P80, DOI 10.1109/LRA.2016.2535961
   Beheshti I, 2017, J ALZHEIMERS DIS, P1
   Bonny T, 2018, MULTIMEDIA TOOLS APP
   Bonny T, 2019, CIRC SYST SIGNAL PR, V38, P1342, DOI 10.1007/s00034-018-0905-6
   Bonny T, 2018, J CIRCUIT SYST COMP, V27, DOI 10.1142/S0218126618502092
   Bonny T, 2018, NONLINEAR DYNAM, V93, P819, DOI 10.1007/s11071-018-4229-7
   Bonny T, 2010, CAIRO INT BIOM ENG, P112, DOI 10.1109/CIBEC.2010.5716098
   Cha SH, 2002, PATTERN RECOGN, V35, P1355, DOI 10.1016/S0031-3203(01)00118-2
   Cinaroglu I, 2016, SIGNAL IMAGE VIDEO P, V10, P413, DOI 10.1007/s11760-015-0768-2
   Demirel H, 2008, IEEE SIGNAL PROC LET, V15, P537, DOI 10.1109/LSP.2008.926729
   Déniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   Georgescu D., 2011, J MOBILE EMBEDDED DI, V3, P193
   Georghiades A., 1997, Yale Face dataset, P2
   Gross R, 2004, IEEE T PATTERN ANAL, V26, P449, DOI 10.1109/TPAMI.2004.1265861
   Inc. Xilinx, 2012, AXI REF GUID, V14
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kshirsagar V. P., 2011, 2011 3rd International Conference on Computer Research and Development (ICCRD 2011), P302, DOI 10.1109/ICCRD.2011.5764137
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Masoud O, 2001, IEEE T VEH TECHNOL, V50, P1267, DOI 10.1109/25.950328
   Or-El R, 2015, PROC CVPR IEEE, P5407, DOI 10.1109/CVPR.2015.7299179
   Rabie T, 2017, INFORM SCIENCES, V418, P218, DOI 10.1016/j.ins.2017.08.015
   Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152
   Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1
   Schiele B, 2000, INT J COMPUT VISION, V36, P31, DOI 10.1023/A:1008120406972
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Sun ZH, 2004, PATTERN RECOGN, V37, P2165, DOI 10.1016/j.patcog.2004.03.013
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Turk M, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2490824
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Xilinx, 2016, VIV DES SUIT HLX ED
   Xilinx Inc, 2014, 7 SER FPGAS OV, V1
NR 39
TC 5
Z9 5
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25781
EP 25806
DI 10.1007/s11042-019-07826-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700025
DA 2024-07-18
ER

PT J
AU Carrega, A
   Portomauro, G
   Repetto, M
   Robino, G
AF Carrega, Alessandro
   Portomauro, Giancarlo
   Repetto, Matteo
   Robino, Giorgio
TI Energy efficiency for edge multimedia elastic applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Energy-efficiency; Quality of service; Elastic transcoding; Edge
   computing
ID SERVICE; COST
AB With the rise of edge computing paradigms, multimedia applications will have to tackle unprecedented management issues, pursuing an optimal balance between performance, Quality of Service (QoS), and power consumption. In this paper, we investigate a novel paradigm to deploy multimedia elastic applications at the edge in a very energy-efficient manner. Our approach is based on pre-provisioning virtual resources that remain "frozen" until the application scales out. Frozen resources are treated in a special way by the infrastructure, leveraging aggressive power-saving mechanisms that keep negligible their impact on energy consumption and performance. We report extensive measurements on QoS and power consumption that we carried out in a real testbed, which is the first working implementation of the proposed paradigm. Our work shows how resource utilization and performance can be increased by leveraging SDN technologies and conscious setting of cloud parameters. We investigate the trade-off between performance and power consumption (i.e., energy efficiency), in relation to different consolidation strategies. Finally, we measure power consumption and estimate energy saving for an elastic video transcoding application deployed at the network edge.
C1 [Carrega, Alessandro; Repetto, Matteo; Robino, Giorgio] CNIT, S3ITILab, Via Opera Pia 13, I-16145 Genoa, Italy.
   [Portomauro, Giancarlo] Univ Genoa, TNT Lab, Via Opera Pia 13, I-16145 Genoa, Italy.
C3 University of Genoa
RP Carrega, A (corresponding author), CNIT, S3ITILab, Via Opera Pia 13, I-16145 Genoa, Italy.
EM alessandro.carrega@cnit.it; giancarlo.portomauro@edu.unige.it;
   matteo.repetto@cnit.it; giorgio.robino@cnit.it
RI Carrega, Alessandro/ABA-9190-2021; Repetto, Matteo/GPK-8352-2022
OI Carrega, Alessandro/0000-0002-5944-7582; Repetto,
   Matteo/0000-0001-8478-2633
FU European Commission under the projects ARCADIA [645372, 761898]; H2020 -
   Industrial Leadership [761898, 645372] Funding Source: H2020 -
   Industrial Leadership
FX This work was supported in part by the European Commission under the
   projects ARCADIA (contract no. 645372) and MATILDA (contract no.
   761898).
CR [Anonymous], 2013, TOPOLOGY ORCHESTRATI
   [Anonymous], 2016, 003 ETSI GS MEC
   [Anonymous], 2014, 001 ETSI GS NFVMAN
   [Anonymous], 2017, ACPI SPEC VERS 6 2 E
   [Anonymous], P 18 INT C INT NEXT
   Baker T, 2017, J NETW COMPUT APPL, V89, P96, DOI 10.1016/j.jnca.2017.03.008
   Barroso LA, 2007, COMPUTER, V40, P33, DOI 10.1109/MC.2007.443
   Beloglazov A, 2015, CONCURR COMP-PRACT E, V27, P1310, DOI 10.1002/cpe.3314
   Bjorklund M., 2017, RFC 8040
   Bolla R, 2013, COMMUNICATIONS SURVE, VPP, P1
   Buyya R., 2010, ENERGY EFFICIENT MAN
   Carrega A, 2017, 1 INT WORKSH SOFTW I
   Carrega A, 2018, 3 IEEE INT C FOG EDG
   Chen J, 2012, IEEE INT CONF ROBOT, P4204, DOI 10.1109/ICRA.2012.6225014
   Cheng R, 2014, P 2 IEEE INT C MOB C
   Cima V., 2015, Sustainable Internet and ICT for Sustainability (SustainIT), 2015, P1
   Dutta S, 2016, P IEEE GLOB COMM C G
   Heller B., 2010, P NSDI
   Jokhio F., 2012, Proceedings of the 2012 20th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP 2012), P206, DOI 10.1109/PDP.2012.59
   Kim M, 2014, CLUSTER COMPUT, V17, P605, DOI 10.1007/s10586-014-0381-0
   Lao F, 2012, P IEEE INT S CIRC SY
   Li B, 2009, IEEE INT CONF CLOUD, P17, DOI 10.1109/CLOUD.2009.72
   Fajardo JO, 2015, IEEE NETWORK, V29, P40, DOI 10.1109/MNET.2015.7340423
   Rossigneux F., 2014, 4 IEEE INT C SUST CO
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shirayanagi H, 2012, 2012 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATIONS (ISCC), P460, DOI 10.1109/ISCC.2012.6249339
   Tran TX, 2016, ARXIV161201436
   Voorsluys W, 2009, LECT NOTES COMPUT SC, V5931, P254, DOI 10.1007/978-3-642-10665-1_23
   Wang F, 2012, IEEE INFOCOM SER, P199, DOI 10.1109/INFCOM.2012.6195578
   Wu Y., 2013, P ACM SPEC INT GROUP, P33
   Zhang WW, 2014, IEEE NETWORK, V28, P67, DOI 10.1109/MNET.2014.6963807
   Zhao YH, 2014, IEEE INFOCOM SER, P298, DOI 10.1109/INFOCOM.2014.6847951
NR 32
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24739
EP 24764
DI 10.1007/s11042-018-7050-x
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900049
DA 2024-07-18
ER

PT J
AU Kushwaha, N
   Pant, M
AF Kushwaha, Neetu
   Pant, Millie
TI Modified particle swarm optimization for multimodal functions and its
   application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Particle swarm optimization; Scale free network; PageRank; Topology;
   Multi-modal problems; Recommendation system; Collaborating filtering;
   Clustering
ID SIMILARITY MEASURE; ALGORITHM
AB In this paper, a Modified variant of Particle Swarm Optimization named MPSOPR is proposed. The velocity update in MPSOPR follows a neighbourhood-based learning strategy based on PageRank (PR) algorithm and a scale-free network is proposed for the interaction among particles in the population. This is in contrast to the basic PSO which has a fully connected topology or regular topology. The inclusion of these two modifications helps in enhancing the diversity and the information dissemination ability of the algorithm. Performance of MPSOPR is validated on a set of 17 benchmark problems divided into 3 groups, on basis of level of difficulties. Comparative analysis of the results obtained through MPSOPR with 9 other variants of PSO, indicate that the proposed scheme can help in improving the performance of PSO significantly. The performance of MPSOPR is further validated by employing it for solving problems related to recommender system.
C1 [Kushwaha, Neetu; Pant, Millie] Indian Inst Technol Roorkee, Dept ASE, Roorkee 247667, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Kushwaha, N (corresponding author), Indian Inst Technol Roorkee, Dept ASE, Roorkee 247667, Uttar Pradesh, India.
EM neetumits@gmail.com; millidma@gmail.com
RI KUSHWAHA, NEETU/CAF-2866-2022; PANT, Millie/C-9911-2018; ARSLAN,
   Okan/AAA-3232-2020; KUSHWAHA, NEETU/CAH-8878-2022
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Ahn HJ, 2008, INFORM SCIENCES, V178, P37, DOI 10.1016/j.ins.2007.07.024
   [Anonymous], AUI GIV RECOMMENDATI
   Barabási AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509
   Birtolo C., 2011, Proceedings of the 2011 11th International Conference on Intelligent Systems Design and Applications (ISDA), P100, DOI 10.1109/ISDA.2011.6121638
   Birtolo C, 2013, EXPERT SYST APPL, V40, P6997, DOI 10.1016/j.eswa.2013.06.022
   Celebi ME, 2013, EXPERT SYST APPL, V40, P200, DOI 10.1016/j.eswa.2012.07.021
   Chen WN, 2013, IEEE T EVOLUT COMPUT, V17, P241, DOI 10.1109/TEVC.2011.2173577
   Dowlatshahi MB, 2014, ENG APPL ARTIF INTEL, V36, P114, DOI 10.1016/j.engappai.2014.07.016
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Ferman A. M., 2002, JCDL 2002. Proceedings of the Second ACM/IEEE-CS Joint Conference on Digital Libraries, DOI 10.1145/544220.544341
   Funk Simon, 2006, Netflix update: Try this at home
   Hanjalic A, 2008, P IEEE, V96, P541, DOI 10.1109/JPROC.2008.916338
   Herlocker J, 2002, INFORM RETRIEVAL, V5, P287, DOI 10.1023/A:1020443909834
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Hruschka ER, 2009, IEEE T SYST MAN CY C, V39, P133, DOI 10.1109/TSMCC.2008.2007252
   Janson S, 2003, IEEE C EVOL COMPUTAT, P770
   Katarya R, 2016, MULTIMED TOOLS APPL, V75, P9225, DOI 10.1007/s11042-016-3481-4
   Kennedy J, 2003, SMCIA/03: PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL WORKSHOP ON SOFT COMPUTING IN INDUSTRIAL APPLICATIONS, P45
   Kennedy J, 2002, IEEE C EVOL COMPUTAT, P1671, DOI 10.1109/CEC.2002.1004493
   Kennedy J., 1999, EV COMP 1999 CEC 99, V3
   Kiran MS, 2017, APPL SOFT COMPUT, V60, P670, DOI 10.1016/j.asoc.2017.07.050
   Konstan J., 2001, P 10 INT C WORLD WID, P285
   Koohi H, 2016, MEASUREMENT, V91, P134, DOI 10.1016/j.measurement.2016.05.058
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Koren Y, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1644873.1644874
   Liang J, 2005, 2005 IEEE C
   Liang JJ, 2006, IEEE T EVOLUT COMPUT, V10, P281, DOI 10.1109/TEVC.2005.857610
   Liu CH, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0087818
   Liu HF, 2014, KNOWL-BASED SYST, V56, P156, DOI 10.1016/j.knosys.2013.11.006
   Liu Q, 2012, IEEE T SYST MAN CY B, V42, P218, DOI 10.1109/TSMCB.2011.2163711
   Liu Y, 2007, NEUROCOMPUTING, V70, P672, DOI 10.1016/j.neucom.2006.10.002
   Ma C-C, 2008, COMPUTER, P1
   Maulik U, 2000, PATTERN RECOGN, V33, P1455, DOI 10.1016/S0031-3203(99)00137-5
   Mendes R, 2004, IEEE T EVOLUT COMPUT, V8, P204, DOI [10.1109/TEVC.2004.826074, 10.1109/tevc.2004.826074]
   Ozturk C, 2015, APPL SOFT COMPUT, V28, P69, DOI 10.1016/j.asoc.2014.11.040
   Page L., 1999, PAGERANK CITATION RA, DOI DOI 10.1109/IISWC.2012.6402911
   Parsopoulos K., 2004, Lect. Ser. Computer and Comput. Sci, P868, DOI [10.1201/9780429081385-222, DOI 10.1201/9780429081385-222]
   Patra BK, 2015, KNOWL-BASED SYST, V82, P163, DOI 10.1016/j.knosys.2015.03.001
   Peña JM, 1999, PATTERN RECOGN LETT, V20, P1027, DOI 10.1016/S0167-8655(99)00069-0
   Peram T, 2003, PROCEEDINGS OF THE 2003 IEEE SWARM INTELLIGENCE SYMPOSIUM (SIS 03), P174, DOI 10.1109/SIS.2003.1202264
   Phoong SM, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL IV, PROCEEDINGS, P729
   Pitsilis G, 2011, CLUSTERING RECOMMEND, P82
   Ratnaweera A, 2004, IEEE T EVOLUT COMPUT, V8, P240, DOI 10.1109/tevc.2004.826071
   Resnick P., 1994, P ACM C COMP SUPP CO, P175
   Salomon R, 1996, BIOSYSTEMS, V39, P263, DOI 10.1016/0303-2647(96)01621-8
   Sarwar Badrul, 2002, P 5 INT C COMP INF T
   SELIM SZ, 1991, PATTERN RECOGN, V24, P1003, DOI 10.1016/0031-3203(91)90097-O
   Shardanand U., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P210, DOI 10.1145/223904.223931
   Shelokar PS, 2004, ANAL CHIM ACTA, V509, P187, DOI 10.1016/j.aca.2003.12.032
   Tian DP, 2018, SWARM EVOL COMPUT, V41, P49, DOI 10.1016/j.swevo.2018.01.011
   Tzortzis G, 2014, PATTERN RECOGN, V47, P2505, DOI 10.1016/j.patcog.2014.01.015
   van den Bergh F, 2004, IEEE T EVOLUT COMPUT, V8, P225, DOI [10.1109/TEVC.2004.826069, 10.1109/tevc.2004.826069]
   van der Merwe D, 2003, IEEE C EVOL COMPUTAT, P215, DOI 10.1109/CEC.2003.1299577
   Wang H, 2013, INFORM SCIENCES, V223, P119, DOI 10.1016/j.ins.2012.10.012
   Wang J., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P501, DOI 10.1145/1148170.1148257
   Xu X, 2015, APPL SOFT COMPUT, V29, P169, DOI 10.1016/j.asoc.2014.12.026
   Zhan ZH, 2009, IEEE T SYST MAN CY B, V39, P1362, DOI 10.1109/TSMCB.2009.2015956
   Zhang CG, 2011, INFORM SCIENCES, V181, P4550, DOI 10.1016/j.ins.2011.02.026
   Zhao ZL, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147944
   Zhou RJ, 2016, MULTIMED TOOLS APPL, V75, P6035, DOI 10.1007/s11042-015-3206-0
   Zhou Renjie, 2010, P 10 ACM SIGCOMM C I, P404, DOI DOI 10.1145/1879141.1879193
NR 62
TC 6
Z9 6
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 23917
EP 23947
DI 10.1007/s11042-018-6324-7
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900008
DA 2024-07-18
ER

PT J
AU Gorbova, J
   Colovic, M
   Marjanovic, M
   Njegus, A
   Anbarjafari, G
AF Gorbova, Jelena
   Colovic, Milica
   Marjanovic, Marina
   Njegus, Angelina
   Anbarjafari, Gholamreza
TI Going deeper in hidden sadness recognition using spontaneous micro
   expressions database
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Micro-expressions; Hidden sadness; Emotion recognition; Deep learning
ID MACHINE
AB Recognition of facial micro-expressions (MEs), which indicates conscious or unconscious suppressing of true emotions, is still a challenging task in the affective computing and computer vision. There are two main reasons for that: First, the lack of spontaneous MEs databases, preferably focused on one emotion. So far, posed facial MEs databases were developed, and in the most cases, machines were trained on this posed MEs, which are stronger and more visible than spontaneous ones. Second, in order to achieve high recognition rate, deep learning structures are required that can achieve the best performance with very large number of data. To address these challenges, we make the following contributions: (i) extension of our MEs spontaneous database by adding new subjects; (ii) We analysed spontaneous MEs in long videos only for hidden sadness; (iii) We presented deeper analysis for automatic hidden sadness detection algorithm with deep learning architecture and compared results with standard machine learning techniques for hidden sadness detection. It is shown that with our method 99.08% recognition performance has been achieved observing only the eye region of the face.
C1 [Gorbova, Jelena; Anbarjafari, Gholamreza] Univ Tartu, Inst Technol, ICV Lab, Tartu, Estonia.
   [Colovic, Milica; Marjanovic, Marina; Njegus, Angelina] Singidunum Univ, Belgrade, Serbia.
   [Anbarjafari, Gholamreza] Loughborough Univ London, Inst Digital Technol, London, England.
   [Anbarjafari, Gholamreza] Hasan Kalyoncu Univ, Fac Engn, Gaziantep, Turkey.
C3 University of Tartu; Loughborough University; Hasan Kalyoncu University
RP Anbarjafari, G (corresponding author), Univ Tartu, Inst Technol, ICV Lab, Tartu, Estonia.; Anbarjafari, G (corresponding author), Loughborough Univ London, Inst Digital Technol, London, England.; Anbarjafari, G (corresponding author), Hasan Kalyoncu Univ, Fac Engn, Gaziantep, Turkey.
EM lena@icv.tuit.ut.ee; mcolovic@singidunum.ac.rs;
   mmarjanovic@singidunum.ac.rs; anjegus@singidunum.ac.rs;
   shb@icv.tuit.ut.ee
RI Anbarjafari, Gholamreza/A-3845-2010; Njegus, Angelina/AFP-3970-2022
OI Anbarjafari, Gholamreza/0000-0001-8460-5717; Njegus,
   Angelina/0000-0001-8682-7014
FU Estonian Research Council [PUT638]; Scientific and Technological
   Research Council of Turkey (TUBITAK) [1001 - 116E097]; Estonian Centre
   of Excellence in IT (EXCITE) - European Regional Development Fund;
   NVIDIA Corporation
FX This work is supported Estonian Research Council Grant (PUT638), the
   Scientific and Technological Research Council of Turkey (TUBITAK)
   (Project 1001 - 116E097), and the Estonian Centre of Excellence in IT
   (EXCITE) funded by the European Regional Development Fund. The authors
   also gratefully acknowledge the support of NVIDIA Corporation with the
   donation of the Titan X and Titan V Pascal GPUs. The author would like
   to thank Miss Dariia Temirova for helping with deep neural network
   codes.
CR Anbarjafari G, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-6
   [Anonymous], GODISNJAK PSIHOLOGIJ
   [Anonymous], UNPUB
   [Anonymous], 2011, IEEE INT C COMP VIS
   [Anonymous], IEEE T AFFECTIVE COM
   [Anonymous], 2018, IEEE T AFFECTIVE COM
   [Anonymous], IEEE T AFFECTIVE COM
   [Anonymous], P 12 IEEE INT C AUT
   [Anonymous], METT SETT ONLINE TOO
   [Anonymous], 1966, Methods of research in psychotherapy, DOI [DOI 10.1007/978-1-4684-6045-2_14, 10.1007/978-1-4684-6045-2_14]
   [Anonymous], BRIT MACH VIS C
   [Anonymous], 2017, 2017 IEEE Workshop on Advanced Robotics and its Social Impacts (ARSO), DOI DOI 10.1109/ARSO.2017.8025197
   [Anonymous], GODINJAK PSIHOLOGIJU
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], ARXIV190207653
   Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Bolotnikova A, 2017, ANALOG INTEGR CIRC S, V92, P467, DOI 10.1007/s10470-017-1006-3
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Demirel H, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/482585
   Eisenbarth H, 2011, EMOTION, V11, P860, DOI 10.1037/a0022758
   Ekman P., 2003, UNMASKING FACE GUIDE
   Ekman P., 1974, The psychology of depression: Contemporary theory and research, P3
   Haamer RE, 2018, IEEE INT CONF AUTOMA, P621, DOI 10.1109/FG.2018.00098
   Fischer AH., 2003, European Review of Social Psychology, V14, P171, DOI [DOI 10.1080/10463280340000054, 10.1080/10463280340000054]
   Fung G., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P64, DOI 10.1145/347090.347105
   Gorbova J, 2018, IEEE MULTIMEDIA, V25, P24, DOI 10.1109/MMUL.2018.023121162
   Guo JZ, 2018, IEEE ACCESS, V6, P26391, DOI 10.1109/ACCESS.2018.2831927
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Hsu SC, 2017, 2017 FIRST IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC), P1, DOI [10.1109/PLASMA.2017.8496316, 10.1109/IRC.2017.12]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lévesque J, 2003, BIOL PSYCHIAT, V53, P502, DOI 10.1016/S0006-3223(02)01817-6
   Li X., 2017, IEEE Transactions on Affective Computing
   Li XB, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553717
   Li XH, 2016, INT CONF SIGN PROCES, P1130, DOI 10.1109/ICSP.2016.7878004
   Liong ST, 2018, SIGNAL PROCESS-IMAGE, V62, P82, DOI 10.1016/j.image.2017.11.006
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Mansoorizadeh M, 2010, MULTIMED TOOLS APPL, V49, P277, DOI 10.1007/s11042-009-0344-2
   Martinez Brais., 2010, 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops, CVPRW 2010, P48
   Mstafa RJ, 2016, MULTIMED TOOLS APPL, V75, P10311, DOI 10.1007/s11042-015-3060-0
   Patel D, 2016, INT C PATT RECOG, P2258, DOI 10.1109/ICPR.2016.7899972
   Pfister T, 2011, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2011.6126401
   Qi ZQ, 2013, PATTERN RECOGN, V46, P305, DOI 10.1016/j.patcog.2012.06.019
   Rahman AKMM, 2017, MULTIMED TOOLS APPL, V76, P7699, DOI 10.1007/s11042-016-3295-4
   Schmid PC, 2010, MOTIV EMOTION, V34, P288, DOI 10.1007/s11031-010-9170-0
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smith ML, 2005, PSYCHOL SCI, V16, P184, DOI 10.1111/j.0956-7976.2005.00801.x
   Tang HY, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY AND SECURITY (QRS 2016), P1, DOI 10.1109/QRS.2016.11
   Tertychnyi P, 2018, IET BIOMETRICS, V7, P550, DOI 10.1049/iet-bmt.2018.5074
   Wang SJ, 2016, NEUROCOMPUTING, V214, P218, DOI 10.1016/j.neucom.2016.05.083
   Wang SJ, 2014, INT C PATT RECOG, P4678, DOI 10.1109/ICPR.2014.800
   Wang YD, 2017, MULTIMED TOOLS APPL, V76, P21665, DOI 10.1007/s11042-016-4079-6
   Warren G, 2009, J NONVERBAL BEHAV, V33, P59, DOI 10.1007/s10919-008-0057-7
   Wu Q, 2011, LECT NOTES COMPUT SC, V6975, P152, DOI 10.1007/978-3-642-24571-8_16
   Yan WJ, 2013, IEEE INT CONF AUTOMA
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yan WJ, 2013, J NONVERBAL BEHAV, V37, P217, DOI 10.1007/s10919-013-0159-8
   Yang B, 2018, MULTIMED TOOLS APPL, V77, P20477, DOI 10.1007/s11042-017-5489-9
NR 61
TC 7
Z9 7
U1 2
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23161
EP 23178
DI 10.1007/s11042-019-7658-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400044
DA 2024-07-18
ER

PT J
AU Guttikonda, JB
   Sridevi, R
AF Guttikonda, John Babu
   Sridevi, R.
TI A new steganalysis approach with an efficient feature selection and
   classification algorithms for identifying the stego images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Steganalysis; Discrete wavelet transformation (DWT); Fast
   Walsh Hadamard transform; Gray level co-occurrence matrix; Pine growth
   optimization and cross integrated machine learning (CIML) classification
ID JPEG; STEGANOGRAPHY
AB The detection of stego images by using the steganalysis approach is one of the demanding task in the recent days. Because, it is used as an importer for the immoral activities by hiding the secrets in the messages. For this secret identification, the traditional works develop various steganographic techniques for steganalysis. But, it has some important drawbacks such as low detection percentage, inefficient results, and increased complexity. In order to solve these issues, this paper introduces a new steganalysis approach with an efficient feature selection and optimization techniques. The aim of this paper is to accurately detect the stego and clean images by implementing an efficient classification algorithm. Initially, a novel Coefficient based Walsh Hadamard Transform along with the Gray Level Co-occurrence Matrix (GLCM) is used for extracting the features of the image. Then, an efficient feature selection technique, namely, Pine Growth Optimization (PGO) is developed to select the optimal features from the extracted features. Finally, the Cross Integrated Machine Learning (CIML) classifier is implemented to classify the stego and clean images. The newness is provided during the feature extraction, selection and classification processes. In experiments, the performance results of the proposed steganalysis is evaluated and compared with the existing approaches by using different measures.
C1 [Guttikonda, John Babu] JNTUH Univ, Dept Comp Sci & Engn, Hyderabad 500085, Telangana, India.
   [Sridevi, R.] JNTUH Coll Engn, Dept Comp Sci, Hyderabad 500085, Telangana, India.
C3 Jawaharlal Nehru Technological University - Hyderabad; Jawaharlal Nehru
   Technological University - Hyderabad
RP Guttikonda, JB (corresponding author), JNTUH Univ, Dept Comp Sci & Engn, Hyderabad 500085, Telangana, India.
EM johnbabug@gmail.com
OI Rangu, Sridevi/0000-0002-1790-1927
CR Acharya UD, 2013, ARXIV13043629
   Alimoradi D, 2014, J COMPUT SEC
   [Anonymous], 2017, BERKELEY IMAGE DATAS
   [Anonymous], 2016, INT J IMAGE PROCESS
   Bera S, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P211, DOI 10.1109/WiSPNET.2016.7566122
   Böhme R, 2010, ADVANCED STATISTICAL STEGANALYSIS, P11
   Christaline J. Anita, 2016, INDIAN J SCI TECHNOL, V9
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Feng B, 2017, J VIS COMMUN IMAGE R
   Goljan M, 2014, IEEE INT WORKS INFOR, P185, DOI 10.1109/WIFS.2014.7084325
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Hou XD, 2014, SIGNAL PROCESS-IMAGE, V29, P385, DOI 10.1016/j.image.2014.01.006
   Hussain M, 2015, IEEE ICCE, P21, DOI 10.1109/ICCE-TW.2015.7216859
   Karimi H, 2015, IET IMAGE PROCESS, V9, P545, DOI 10.1049/iet-ipr.2013.0823
   Kong XW, 2016, NEUROCOMPUTING, V214, P458, DOI 10.1016/j.neucom.2016.06.037
   Lerch-Hostalot D, 2016, ENG APPL ARTIF INTEL, V50, P45, DOI 10.1016/j.engappai.2015.12.013
   Li FY, 2016, IEEE T INF FOREN SEC, V11, P344, DOI 10.1109/TIFS.2015.2496910
   Li H, 2015, ARXIV150304718
   Li XL, 2013, SIGNAL PROCESS, V93, P2529, DOI 10.1016/j.sigpro.2013.03.029
   Li X, 2014, MULTIMED TOOLS APPL, V68, P1051, DOI 10.1007/s11042-012-1112-2
   Liu JF, 2015, DIGIT SIGNAL PROCESS, V38, P66, DOI 10.1016/j.dsp.2014.12.004
   Mohammadi FG, 2014, ENG APPL ARTIF INTEL, V31, P35, DOI 10.1016/j.engappai.2013.09.016
   Ng WWY, 2014, INFORM SCIENCES, V281, P211, DOI 10.1016/j.ins.2014.05.028
   Nouri A, 2016, ADV COMPUT SCI INT J, V5, P33
   Pathak P, 2014, DIGIT INVEST, V11, P67, DOI 10.1016/j.diin.2013.12.002
   Qian YL, 2016, IEEE IMAGE PROC, P2752, DOI 10.1109/ICIP.2016.7532860
   Sajedi H, 2016, J INF SECUR APPL, V30, P3, DOI 10.1016/j.jisa.2016.04.001
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Song Jun-nan, 2018, Instrument Technique and Sensor, P1
   Thai TH, 2014, IEEE T IMAGE PROCESS, V23, P1980, DOI 10.1109/TIP.2014.2310126
   Trivedi MC, 2016, P 2 INT C INF COMM T, V84
   Vyas A, 2015, INT J ADV RES COMPUT, V6
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Wu AX, 2016, J VIS COMMUN IMAGE R, V34, P103, DOI 10.1016/j.jvcir.2015.10.013
   Wu ST, 2018, MULTIMED TOOLS APPL, V77, P10437, DOI 10.1007/s11042-017-4440-4
   Xuanhan Wang, 2017, IEEE Signal Processing Letters, V24, P510, DOI 10.1109/LSP.2016.2611485
   Yang CL, 2013, PATTERN RECOGN, V46, P948, DOI 10.1016/j.patcog.2012.07.011
   Zhang H, 2017, IEEE T INF FOREN SEC, V12, P465, DOI 10.1109/TIFS.2016.2623587
NR 38
TC 8
Z9 10
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21113
EP 21131
DI 10.1007/s11042-019-7168-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400025
DA 2024-07-18
ER

PT J
AU Biernacki, A
AF Biernacki, Arkadiusz
TI Identification of adaptive video streams based on traffic correlation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Network traffic; Adaptive video; Multimedia communication; Video
   streaming
ID CLASSIFICATION
AB Due to the popularity of Dynamic Adaptive Streaming Over HTTP (DASH), broadband and Internet service providers' links transmit mainly multimedia content. As the most popular providers encrypt their video services, the attempts to identify their traffic through Deep Packet Inspection (DPI) encounter difficulties. Therefore, encrypted DASH traffic requires new classification methods. In this work, we propose to identify DASH traffic taking into account statistical dependencies among video flows. For this purpose, we employ cluster analysis which can identify groups of traffic flows that show similarity using only the application level information. In our work, we applied three unsupervised clustering algorithms, namely MinMax K-Means, OPTICS and AutoClass, to classify video traces obtained from an emulated environment. The experimental results show that the employed algorithms are able to effectively distinguish video flows generated by different play-out strategies. The classification performance depends on the network conditions and parameters of the learning process.
C1 [Biernacki, Arkadiusz] Silesian Tech Univ, Inst Comp Sci, Akad 16, PL-44100 Gliwice, Poland.
C3 Silesian University of Technology
RP Biernacki, A (corresponding author), Silesian Tech Univ, Inst Comp Sci, Akad 16, PL-44100 Gliwice, Poland.
EM arkadiusz.biernacki@polsl.pl
OI Biernacki, Arkadiusz/0000-0002-5274-4250; Biernacki,
   Arkadiusz/0000-0001-5429-4065
FU Institute of Informatics, Gliwice, Poland [BK-213/RAU2/2018]
FX The work was carried out within the statutory research project of the
   Institute of Informatics, BK-213/RAU2/2018, Gliwice, Poland.
CR Alcock S, 2011, ACM SIGCOMM COMP COM, V41, P25, DOI 10.1145/1971162.1971166
   Alshammari R, 2011, COMPUT NETW, V55, P1326, DOI 10.1016/j.comnet.2010.12.002
   Amancio DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0094137
   Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49
   [Anonymous], 2011, P 19 ACM INT C MULT
   [Anonymous], TCPDUMP PUBLIC REPOS
   Arndt D. J., 2011, 2011 IEEE SSCI Symposium on Computational Intelligence for Security and Defense Applications (CISDA 2011), P107, DOI 10.1109/CISDA.2011.5945941
   Bakhshi T, 2015, 2015 INTERNET TECHNOLOGIES AND APPLICATIONS (ITA) PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE (ITA 15), P91, DOI 10.1109/ITechA.2015.7317376
   Biernacki A, 2017, KSII T INTERNET INF, V11, P374
   Biernacki A, 2016, J COMMUN NETW-S KOR, V18, P826, DOI 10.1109/JCN.2016.000111
   Botta A, 2012, COMPUT NETW, V56, P3531, DOI 10.1016/j.comnet.2012.02.019
   Bujlow T, 2015, COMPUT NETW, V76, P75, DOI 10.1016/j.comnet.2014.11.001
   Callado A, 2009, IEEE COMMUN SURV TUT, V11, P37, DOI 10.1109/SURV.2009.090304
   Cao ZW, 2014, INTERNATIONAL SYMPOSIUM 2014 - COMMON DEVELOPMENT OF SPORTS AND MODERN SOCIETY, P73
   Cisco, 2017, CISC VIS NETW IND GL
   Datta J, 2015, 2015 21 NAT C COMM N, P1, DOI DOI 10.1109/NCC.2015.7084879
   Du Y, 2013, TELECOMMUN SYST, V53, P163, DOI 10.1007/s11235-013-9690-5
   Dubin R, 2016, ARXIV160200489
   Dubin R, 2018, KSII T INTERNET INF, V12, P3804, DOI 10.3837/tiis.2018.08.014
   Erman Jeffrey., 2006, P 49 IEEE GLOBAL TEL, P1, DOI DOI 10.1109/GLOCOM.2006.443
   Erman Jeffrey., 2006, Proceedings of the 2006 SIGCOMM workshop on Mining Network Data, P281, DOI DOI 10.1145/1162678.1162679
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Famaey J, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P419
   Finsterbusch M, 2014, IEEE COMMUN SURV TUT, V16, P1135, DOI 10.1109/SURV.2013.100613.00161
   Gamez RCL, 2006, RR0612 ESAII U CAT R
   Hemminger Stephen., 2005, LINUX C, P18
   Hooghiemstra G, 2001, TECHNICAL REPORT
   Jiang J, 2012, 2012 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT 2012), VOL 2, P90, DOI 10.1109/WI-IAT.2012.40
   Keogh E, 2003, DATA MIN KNOWL DISC, V7, P349, DOI 10.1023/A:1024988512476
   Kim H., 2008, P 2008 ACM CONEXT C, DOI DOI 10.1145/1544012.1544023
   Kwapie J, 2012, PHYS REP, V515, P116
   Lederer S., 2012, P 3 MULT SYST C, P89
   Li Z, 2014, IEEE J SEL AREA COMM, V32, P719, DOI 10.1109/JSAC.2014.140405
   Mantegna RN, 1999, EUR PHYS J B, V11, P193, DOI 10.1007/s100510050929
   Miller K., 2012, 2012 Proceedings of the 19th International Packet Video Workshop (PV 2012), P173, DOI 10.1109/PV.2012.6229732
   Nguyen TTT, 2008, IEEE COMMUN SURV TUT, V10, P56, DOI 10.1109/SURV.2008.080406
   Pacheco F, 2018, IEEE COMMUN SURV TUT, P1
   Sandoval L, 2013, ALGORITHMIC FINANC, V2, P3, DOI 10.3233/AF-13015
   Singh H, 2015, INT C ADV COMPUT COM, P401, DOI 10.1109/ACCT.2015.54
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Stockhammer T., 2011, P 2 ANN ACM C MULTIM, P133
   Taylor VF, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P439, DOI 10.1109/EuroSP.2016.40
   Tzortzis G, 2014, PATTERN RECOGN, V47, P2505, DOI 10.1016/j.patcog.2014.01.015
   Velan P, 2015, INT J NETW MANAG, V25, P355, DOI 10.1002/nem.1901
   Yao J, 2011, LECT NOTES COMPUT SC, V6640, P92, DOI 10.1007/978-3-642-20757-0_8
   Zhang J, 2015, IEEE ACM T NETWORK, V23, P1257, DOI 10.1109/TNET.2014.2320577
   Zhang J, 2013, IEEE T PARALL DISTR, V24, P104, DOI 10.1109/TPDS.2012.98
NR 47
TC 3
Z9 4
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18271
EP 18291
DI 10.1007/s11042-019-7183-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200042
OA hybrid
DA 2024-07-18
ER

PT J
AU Yu, J
   Chang, ZC
   Xiao, CB
AF Yu, Jing
   Chang, Zhenchun
   Xiao, Chuangbai
TI Blur kernel estimation using sparse representation and cross-scale
   self-similarity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind deconvolution; Deblurring; Sparse representation; Self-similarity;
   Cross-scale
ID BLIND DECONVOLUTION; ALGORITHM
AB Blind image deconvolution, i.e., estimating both the latent image and the blur kernel from the only observed blurry image, is a severely ill-posed inverse problem. In this paper, we propose a blur kernel estimation method for blind motion deblurring using sparse representation and cross-scale self-similarity of image patches as priors to recover the latent sharp image from a single blurry image. Sparse representation indicates that image patches can always be represented well as a sparse linear combination of atoms in an appropriate dictionary. Cross-scale self-similarity results in that any image patch can in some way be well approximated by a number of other similar patches across different image scales. Our method is based on the observations that almost any image patch in a natural image has multiple similar patches in down-sampled versions of the image, and down-sampling produces image patches that are sharper than those in the blurry image itself. In our method, the dictionary for sparse representation is trained adaptively from sharper patches sampled from the down-sampled latent image estimate to make the similar patches of the latent sharp image well represented sparsely, and meanwhile, all patches from the latent image estimate are optimized to be as close to the sharper similar patches searched from the down-sampled version to enforce the sharp recovery of the latent image by constructing a non-local regularization. Experimental results on both simulated and real blurry images demonstrate that our method outperforms state-of-the-art blind deblurring methods.
C1 [Yu, Jing; Xiao, Chuangbai] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
   [Chang, Zhenchun] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
C3 Beijing University of Technology; Tsinghua University
RP Yu, J (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
EM jing.yu@bjut.edu.cn; txchangchun@163.com; cbxiao@bjut.edu.cn
FU National Natural Science Foundation of China [61501008]; Beijing
   Municipal Natural Science Foundation [4172002]
FX This study was funded by National Natural Science Foundation of China
   (61501008) and Beijing Municipal Natural Science Foundation (4172002).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2007, P IEEE C COMP VIS PA
   [Anonymous], 2010, UCBEECS201013
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Cho TS, 2011, PROC CVPR IEEE, P241, DOI 10.1109/CVPR.2011.5995479
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Jia C, 2011, IEEE IMAGE PROC, P681, DOI 10.1109/ICIP.2011.6116644
   Joshi N, 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587834
   Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521
   Lai WS, 2015, PROC CVPR IEEE, P64, DOI 10.1109/CVPR.2015.7298601
   Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2657, DOI 10.1109/CVPR.2011.5995308
   Levin A, ACM T GRAPHICS TOG, V26
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Li HS, 2012, INT C PATT RECOG, P3054
   Michaeli T, 2014, LECT NOTES COMPUT SC, V8691, P783, DOI 10.1007/978-3-319-10578-9_51
   Olonetsky I, 2012, LECT NOTES COMPUT SC, V7575, P602, DOI 10.1007/978-3-642-33765-9_43
   Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180
   [潘宗序 Pan Zongxu], 2014, [自动化学报, Acta Automatica Sinica], V40, P594
   Pan ZX, 2013, IEEE T GEOSCI REMOTE, V51, P4864, DOI 10.1109/TGRS.2012.2230270
   Perrone D., 2015, INT C EN MIN METH CO
   Perrone D, 2016, IEEE T PATTERN ANAL, V38, P1041, DOI 10.1109/TPAMI.2015.2477819
   Perrone D, 2014, PROC CVPR IEEE, P2909, DOI 10.1109/CVPR.2014.372
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409106
   Sun LX, 2013, PART FIBRE TOXICOL, V10, DOI 10.1186/1743-8977-10-43
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang MD, 2015, IEEE IMAGE PROC, P1623, DOI 10.1109/ICIP.2015.7351075
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Yan YY, 2017, PROC CVPR IEEE, P6978, DOI 10.1109/CVPR.2017.738
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yu F, 2017, INT CONF ACOUST SPEE, P1328, DOI 10.1109/ICASSP.2017.7952372
   Zhang HM, 2011, WOODHEAD PUBL MATER, P1
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 37
TC 4
Z9 6
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18549
EP 18570
DI 10.1007/s11042-019-7237-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200054
OA hybrid
DA 2024-07-18
ER

PT J
AU Garhwal, AS
   Yan, WQ
AF Garhwal, Abhimanyu Singh
   Yan, Wei Qi
TI BIIGA: Bioinformatics inspired image grouping approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image phylogeny; Multiple sequence alignment; Multiple print-scan
   degradations; Phylogenetic tree; Image to DNA encoding; Watermarked
   images
ID EVOLUTIONARY GENETICS ANALYSIS; DIGITAL INFORMATION; MAXIMUM-LIKELIHOOD;
   DNA-SEQUENCES; ALIGNMENT; MAFFT; SOFTWARE; STORAGE; MEGA; PROGRAM
AB Initial work on image phylogeny used different approaches like the minimum spanning tree etc. The less investigated attempt is a bioinformatics-inspired approach for image phylogeny. The aim of this paper is to bridge this gap by generating image phylogeny with the concept of phylogenetic trees in bioinformatics. These trees were developed by using multiple aligned DNA sequences of original or multiple print-scan (MPS) degraded variants of watermarked (W) and non-watermarked (NW) images. Experimental results disclosed the viability of a proposed novel approach and effectively grouped original or MPS degraded variants of the W or NW images. The proposed method's claims may revolutionise our knowledge of degraded (D) or non-degraded (ND) W and NW image grouping. It may direct to a new era of phylogenetic tree-based W or NW degraded or original images for developing the next generation of degraded (by MPS) W and NW grouping softwares. To the best of our knowledge, this is the first time such a method has been employed for image grouping. Our contributions are: (a) biologically-based image encoding to DNA letters (b) multiple sequence alignment (MSA) of DNA-encoded images (c) phylogenetic tree generation to group MPS-degraded W or NW images.
C1 [Garhwal, Abhimanyu Singh; Yan, Wei Qi] AUT, Auckland, New Zealand.
C3 Auckland University of Technology
RP Garhwal, AS (corresponding author), AUT, Auckland, New Zealand.
EM abhimanyugarhwal@gmail.com
RI Garhwal, Abhimanyu Singh/AAE-5933-2019
OI Garhwal, Abhimanyu Singh/0000-0002-9810-6705
CR Aliakbarpour H, 2011, IEEE INTL CONF IND I
   ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1016/S0022-2836(05)80360-2
   BACON DJ, 1986, J MOL BIOL, V191, P153, DOI 10.1016/0022-2836(86)90252-4
   Bhargava N, 2012, INT C RAD COMM COMP
   Bicego M, 2012, 21 INT C PATT REC IC
   Bicego M, 2015, EUR C COMP VIS
   Bicego M, 2016, COMPUT VIS IMAGE UND, V145, P59, DOI 10.1016/j.cviu.2015.11.011
   Chambers J, 2015, MULTIMED TOOLS APPL, V74, P4013, DOI 10.1007/s11042-013-1809-x
   Church GM, 2012, SCIENCE, V337, P1628, DOI 10.1126/science.1226355
   Costa FD, 2014, IEEE T INF FOREN SEC, V9, P1533, DOI 10.1109/TIFS.2014.2340017
   Cox JPL, 2001, TRENDS BIOTECHNOL, V19, P247, DOI 10.1016/S0167-7799(01)01671-7
   Darwin C., 1859, ORIGIN SPECIES MEANS
   Davis J, 1996, ART J, V55, P70, DOI 10.2307/777811
   Dias Z, 2010, IEEE INT WORKS INFOR
   Dias Z, 2013, J VIS COMMUN IMAGE R, V24, P1124, DOI 10.1016/j.jvcir.2013.07.011
   Dias Z, 2013, IEEE MULTIMEDIA, V20, P58, DOI 10.1109/MMUL.2013.17
   Dias Z, 2013, FORENSIC SCI INT, V231, P178, DOI 10.1016/j.forsciint.2013.05.002
   Dias Z, 2012, IEEE T INF FOREN SEC, V7, P774, DOI 10.1109/TIFS.2011.2169959
   FELSENSTEIN J, 1988, ANNU REV GENET, V22, P521, DOI 10.1146/annurev.ge.22.120188.002513
   FELSENSTEIN J, 1981, J MOL EVOL, V17, P368, DOI 10.1007/BF01734359
   Garhwal AS, 2015, INT J DIGIT CRIME FO, V7, P55, DOI [10.4018/IJDCF.2015100104, 10.4018/ijdcf.2015100104]
   Garhwal AS, 2018, MULTIMED TOOLS APPL, P1
   Garhwal AS, 2017, IVCNZ17
   Garhwal AS, 2018, THESIS
   Goldman N, 2013, NATURE, V494, P77, DOI 10.1038/nature11875
   Grass RN, 2015, ANGEW CHEM INT EDIT, V54, P2552, DOI 10.1002/anie.201411378
   HENIKOFF S, 1992, P NATL ACAD SCI USA, V89, P10915, DOI 10.1073/pnas.89.22.10915
   Hennig W., 1966, P263
   Katoh K, 2002, NUCLEIC ACIDS RES, V30, P3059, DOI 10.1093/nar/gkf436
   Katoh K, 2005, NUCLEIC ACIDS RES, V33, P511, DOI 10.1093/nar/gki198
   Katoh K, 2008, BRIEF BIOINFORM, V9, P286, DOI 10.1093/bib/bbn013
   Katoh K, 2007, BIOINFORMATICS, V23, P372, DOI 10.1093/bioinformatics/btl592
   Katoh Kazutaka, 2013, Mol Biol Evol, V30, P772, DOI 10.1093/molbev/mst010
   Katoh K, 2016, BIOINFORMATICS, V32, P1933, DOI 10.1093/bioinformatics/btw108
   Katoh Kazutaka, 2010, Bioinformatics, V26, P1899, DOI 10.1093/bioinformatics/btq224
   Katoh K, 2013, MOL BIOL EVOL, V30, P772, DOI 10.1093/molbev/mst010
   Katoh K, 2012, BIOINFORMATICS, V28, P3144, DOI 10.1093/bioinformatics/bts578
   Katoh K, 2009, METHODS MOL BIOL, V537, P39, DOI 10.1007/978-1-59745-251-9_3
   Katoh K, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-212
   Kiah HM, 2015, IEEE INF THEOR WORKS
   Kumar S, 2001, BIOINFORMATICS, V17, P1244, DOI 10.1093/bioinformatics/17.12.1244
   Kumar S, 2004, BRIEF BIOINFORM, V5, P150, DOI 10.1093/bib/5.2.150
   KUMAR S, 1994, COMPUT APPL BIOSCI, V10, P189
   Kumar S, 2016, MOL BIOL EVOL, V33, P1870, DOI [10.1093/molbev/msv279, 10.1093/molbev/msw054]
   Kumar S, 2012, BIOINFORMATICS, V28, P2685, DOI 10.1093/bioinformatics/bts507
   Kuraku S, 2013, NUCLEIC ACIDS RES, V41, pW22, DOI 10.1093/nar/gkt389
   Limbachiya D, 2015, 7 INT WORKSH SIGN DE
   Lobo I., 2008, J MOL BIOL, V215, P403
   Lovato P, 2012, JOINT IAPR INT WORKS
   MAFT, MAFT VERS 7
   MICHENER CD, 1957, EVOLUTION, V11, P130, DOI 10.2307/2406046
   Naidu V, 2014, 10 IEEE INT C NAT CO
   Naidu V, 2016, SYNTACTIC APPROACH D
   Naidu V, 2016, IEEE C EV COMP WCCI
   Naidu V, 2016, 14 IEEE INT C DEP AU
   Nucci M, 2013, IEEE 15 INT WORKSH M
   Oliveira A, 2014, IEEE IMAGE PROC, P5347, DOI 10.1109/ICIP.2014.7026082
   Rubio-Largo A, 2015, IEEE TRUST BIG, P242, DOI 10.1109/Trustcom.2015.639
   Stewart CB, 2000, THESIS
   Tamura K, 2013, MOL BIOL EVOL, V30, P2725, DOI [10.1093/molbev/mst197, 10.1093/molbev/msr121]
   Tamura K, 2007, MOL BIOL EVOL, V24, P1596, DOI 10.1093/molbev/msm092
   Wong PC, 2003, COMMUN ACM, V46, P95, DOI 10.1145/602421.602426
   Yamada KD, 2016, BIOINFORMATICS, V32, P3246, DOI 10.1093/bioinformatics/btw412
   Yan WQ, 2015, MULTIMED TOOLS APPL, V74, P4723, DOI 10.1007/s11042-013-1833-x
   Yang ZH, 2012, NAT REV GENET, V13, P303, DOI 10.1038/nrg3186
   Yazdi SMHT, 2015, SCI REP-UK, V5, DOI 10.1038/srep14138
   Yim Aldrin Kay-Yuen, 2014, Front Bioeng Biotechnol, V2, P49, DOI 10.3389/fbioe.2014.00049
NR 67
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14355
EP 14377
DI 10.1007/s11042-018-6817-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700011
DA 2024-07-18
ER

PT J
AU Manju, VN
   Fred, AL
AF Manju, V. N.
   Fred, A. Lenin
TI An efficient multi balanced cuckoo search K-means technique for
   segmentation and compression of compound images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compound images; Photographic images; Multi balanced cuckoo search
   (MB-CS) optimization algorithm; Segmentation and compression
ID QUALITY
AB The images comprise not only photographic images but also graphic and text images, they are determined in magazines, brochures and websites. The segmentation and compression of compound images (for instance, computer-generated images, scanned documents and so on) are tough to the procedure.The existing segmentation and compression techniques do not provide a complete comprehensive solution. To solve the problems in existing techniques, here we segmented the compound images via an optimization depended on K-means clustering technique along with AC (Alternate Current) coefficient method for the dynamic segmentation and then compressed individually. The AC coefficient based segmentation method results in detachment of smooth (background) and non-smooth (text, image and overlapping) areas. Further, the non-smooth part is segmented via the optimization depended on K-means clustering technique. Also, the density of segmented objects is headed applying different compression strategies such as the Huffman coder, arithmetic coder, and Jpeg coders. With the being approaches, the entire projected architecture is implemented in MATLAB and the function of the scheme is measured and equated. Our proposed system achieves better compression ratio (21.16), and also improves the performance for image quality index (0.931574), PSNR (Peak Signal to Noise Ratio) (34.91338), RMSE (Root Mean Square Error) (0.931574), SSIM (Structural Similarity) (0.546882), and SDME (Second Derivative-like Measure of Enhancement) (44.91293) than the available CS K-means algorithm.
C1 [Manju, V. N.] Sathyabama Inst Sci & Technol, Fac Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Fred, A. Lenin] Mar Ephraem Coll Engn & Technol, Marthandam, Tamil Nadu, India.
C3 Sathyabama Institute of Science & Technology
RP Manju, VN (corresponding author), Sathyabama Inst Sci & Technol, Fac Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM vnmanju0583@gmail.com
RI Fred, Lenin/AAU-9556-2021
OI V N, Manju/0000-0001-6754-7391; FRED, A.LENIN/0000-0002-6551-4796
CR [Anonymous], 2016, IEEE COMPUT GRAPH
   Aparna R, 2010, INT J COMPUT APPL, V1, P37
   Chen YL, 2012, EXPERT SYST APPL, V39, P494, DOI 10.1016/j.eswa.2011.07.040
   JI G, 2015, MATH PROBL ENG, V2015, P38
   Kalpana K, 2013, INT J COMPUTER TREND, V4
   Lan C, 2010, IEEE T IMAGE PROCESS, V19
   Lu N, 2018, SIGNAL PROCESS, V145, P225, DOI 10.1016/j.sigpro.2017.12.004
   Ma Z, 2014, IEEE T IMAGE PROCESS, V23, P4399, DOI 10.1109/TIP.2014.2346995
   Maheswari D., 2010, Computer Science and Engineering, V2, P1359
   Maheswari D., 2011, INT J MULTIMEDIA ITS, V3, P946
   Maheswari D, 2010, COMP INT COMP RES IC
   Manju VN, 2017, IET IMAGE PROCESSING
   Minaee S, 2016, IEEE J EM SEL TOP C, V6, P573, DOI 10.1109/JETCAS.2016.2597701
   Porikli F, 2010, IEEE T CIRC SYST VID, V20, P2, DOI 10.1109/TCSVT.2009.2020253
   Vil'kin A. M., 2013, Pattern Recognition and Image Analysis, V23, P153, DOI 10.1134/S1054661813010136
   Willéme A, 2016, IEEE J EM SEL TOP C, V6, P471, DOI 10.1109/JETCAS.2016.2601166
   Yang H, 2018, SIGNAL PROCESS-IMAGE, V62, P74, DOI 10.1016/j.image.2017.12.001
   Yang H, 2015, J VIS COMMUN IMAGE R, V26, P105, DOI 10.1016/j.jvcir.2014.11.001
NR 18
TC 6
Z9 6
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14897
EP 14915
DI 10.1007/s11042-018-6652-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700034
DA 2024-07-18
ER

PT J
AU Vishwakarma, VP
   Goel, T
AF Vishwakarma, Virendra P.
   Goel, Tripti
TI An efficient hybrid DWT-fuzzy filter in DCT domain based illumination
   normalization for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete cosine transform; Discrete wavelet transform; Face recognition;
   Illumination normalization
ID EIGENFACES; PATTERN; IMAGE
AB This paper presents an efficient hybrid DWT-DCT based illumination normalization technique for face recognition. In a face image, illumination usually changes slowly compared to the reflectance except some casting shadows and specularities on the face. Consequently, illumination variations mainly lie in the low frequency band of the face image. Therefore, in the present work, low frequency coefficients are processed to nullify the effect of illumination variations. Discrete wavelet transform (DWT) is used to decompose the image into frequency domain. It is a sub-band coding technique which decomposes image into four sub-bands: low-low (LL), low-high (LH), high-low (HL) and high-high (HH). As illumination is related to low frequency coefficients, normalization is mainly performed on LL sub-band rather than the whole face. The fuzzy filter is applied on the appropriate number of low frequency discrete Cosine transform (DCT) coefficients of LL sub-band to minimize the variations under different lighting conditions. Also, minor corrections are performed on the rest three sub-bands. After modification, the normalized LL sub-band and rest three sub-bands are combined to generate the normalized face image. The given approach achieves zero error rates on Yale B and CMU PIE face database. Also, good performance results have been achieved on Extended Yale B face database. These results clearly confirm the effectiveness of the given approach of illumination normalization.
C1 [Vishwakarma, Virendra P.] Guru Gobind Singh Indraprastha Univ, Univ Sch Informat Commun & Technol, Sect 16-C, New Delhi, India.
   [Goel, Tripti] Natl Inst Technol, Dept Elect & Commun Engn, Silchar, Assam, India.
C3 GGS Indraprastha University; National Institute of Technology (NIT
   System); National Institute of Technology Silchar
RP Vishwakarma, VP (corresponding author), Guru Gobind Singh Indraprastha Univ, Univ Sch Informat Commun & Technol, Sect 16-C, New Delhi, India.
EM virendravishwa@rediffmail.com; triptigoel83@gmail.com
OI Vishwakarma, Virendra P./0000-0003-4276-8766
CR Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 1997, P INT C AUD VID BAS
   [Anonymous], 1995, P INT C AUT FAC GEST
   [Anonymous], 2012, INT J ADV ENG TECHNO
   [Anonymous], P 2 INT C INF TECHN
   [Anonymous], IEEE T NEURAL NETW
   [Anonymous], 2006, FUNDAMENTALS DIGITAL
   [Anonymous], MATLAB REFERENCE MAN
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   Chen HF, 2000, PROC CVPR IEEE, P254, DOI 10.1109/CVPR.2000.855827
   Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353
   Cohen A., 1995, Wavelets and multiscale signal processing
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Delac K, 2006, INT C SYST SIGN IM P, V19, P1519
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   Faraji MR, 2015, IET COMPUT VIS, V9, P390, DOI 10.1049/iet-cvi.2014.0200
   Faraji MR, 2015, IET BIOMETRICS, V4, P10, DOI 10.1049/iet-bmt.2014.0033
   Faraji MR, 2014, IEEE SIGNAL PROC LET, V21, P1457, DOI 10.1109/LSP.2014.2343213
   Gao YS, 2002, IEEE T PATTERN ANAL, V24, P764, DOI 10.1109/TPAMI.2002.1008383
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gonzalez R. C., 2006, PEARSON ED INDIA, V3rd
   Jabid T, 2010, IEEE ICCE
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Juneja K, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P1079, DOI 10.1109/CCAA.2015.7148566
   Kim DJ, 2016, J NANOELECTRON OPTOE, V11, P141, DOI 10.1166/jno.2016.1855
   Klir G., 1995, Fuzzy sets and fuzzy logic, V4
   Lai ZR, 2015, IEEE T IMAGE PROCESS, V24, P1735, DOI 10.1109/TIP.2015.2409988
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Li S.Z., 2005, Handbook of Face Recognition
   Lin CC, 1996, PATTERN RECOGN, V29, P2079, DOI 10.1016/S0031-3203(96)00034-9
   Phillips P. J., 2007, 7408 NISTIR, P7408
   Phillips PJONATHON., 2003, Evaluation report
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Shan SG, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P157
   Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Syafeeza A., INT J ENG TECHNOLOGY, V6, P44
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Veenman CJ, 2005, IEEE T PATTERN ANAL, V27, P1417, DOI 10.1109/TPAMI.2005.187
   Vishwakarma Virendra P., 2009, International Journal of Recent Trends in Engineering, V1, P318
   Vishwakarma Virendra P., 2010, Journal of Computing and Information Technology - CIT, V18, P53, DOI 10.2498/cit.1001427
   Wang B, 2011, IEEE SIGNAL PROC LET, V18, P462, DOI 10.1109/LSP.2011.2158998
   Wu Y, 2014, NEUROCOMPUTING, V136, P262, DOI 10.1016/j.neucom.2014.01.006
   Xie XH, 2011, IEEE T IMAGE PROCESS, V20, P1807, DOI 10.1109/TIP.2010.2097270
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang L, P IEEE C COMP VIS PA, V1, P19
   Zhang TP, 2009, PATTERN RECOGN, V42, P251, DOI 10.1016/j.patcog.2008.03.017
   Zhao JL, 2003, PATTERN RECOGN LETT, V24, P2703, DOI 10.1016/S0167-8655(03)00113-2
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhao WY, 2001, INT J COMPUT VISION, V45, P55, DOI 10.1023/A:1012369907247
   Zhong FJ, 2013, NEUROCOMPUTING, V119, P375, DOI 10.1016/j.neucom.2013.03.020
   Zou X, 2007, 2007 FIRST IEEE INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P113
NR 58
TC 17
Z9 17
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15213
EP 15233
DI 10.1007/s11042-018-6837-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700047
DA 2024-07-18
ER

PT J
AU Wang, N
   Xue, YM
   Lin, Q
   Zhong, P
AF Wang, Nan
   Xue, Yiming
   Lin, Qiang
   Zhong, Ping
TI Structured sparse multi-view feature selection based on weighted hinge
   loss
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-view feature selection; Weighted hinge loss; Structured sparse;
   Classification
ID FRAMEWORK; LASSO
AB In applications, using features obtained from multiple views to describe objects has become popular because multiple views contain much more information than the single view. As the dimensions of the data sets are high, which may cause expensive time consumption and memory space, how to identify the representative views and features becomes a crucial problem. Multi-view feature selection that can integrate multiple views to select important and relevant features to improve performance has attracted more and more attentions in recent years. Previous supervised multi-view feature selection methods usually establish the models by concatenating multiple views into long vectors. However, this concatenation is not physically meaningful and implies that different views play the similar roles for specific tasks. In this paper, we propose a novel supervised multi-view feature selection method based on the weighted hinge loss (WHMVFS) that can learn the corresponding weight for each view and implement sparsity from the group and individual point of views under the structured sparsity framework. The newly proposed multi-view weighted hinge loss penalty not only has the ability to select more discriminative features for classification, but also can make the involved optimization problem be decomposed into several small scale subproblems, which can be easily solved by an iterative algorithm, and the convergence of the iterative algorithm is also proved. Experimental results conducted on real-world data sets show the effectiveness of the proposed method.
C1 [Wang, Nan; Lin, Qiang; Zhong, Ping] China Agr Univ, Coll Sci, Beijing 100083, Peoples R China.
   [Xue, Yiming] China Agr Univ, Coll Informat & Elect Engn, Beijing 100083, Peoples R China.
C3 China Agricultural University; China Agricultural University
RP Zhong, P (corresponding author), China Agr Univ, Coll Sci, Beijing 100083, Peoples R China.
EM zping@cau.edu.cn
RI Lin, Qiang/AAA-8516-2022
FU National Natural Science Foundation of China [61872368,
   U1536121,11171346]
FX The work is supported by the National Natural Science Foundation of
   China (Grant No. 61872368, U1536121,11171346). We thank Jing Zhong for
   her assistance of collecting data during the preparation of the
   revision. We also gratefully acknowledge the helpful comments and
   suggestions of the reviewers, which have improved the presentation.
CR [Anonymous], 2014, UEEE INT SYM PERS IN
   [Anonymous], MULTIMED TOOLS APPL, DOI DOI 10.5740/JA0ACINT.I
   [Anonymous], 2010, J ROYAL STAT SOC
   Cai X., 2013, 23 INT JOINT C ART I, P2598
   Cheng XH, 2017, NEUROCOMPUTING, V253, P115, DOI 10.1016/j.neucom.2016.10.089
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Gui J, 2017, IEEE T NEUR NET LEAR, V28, P1490, DOI 10.1109/TNNLS.2016.2551724
   Gui J, 2014, IEEE T IMAGE PROCESS, V23, P3126, DOI 10.1109/TIP.2014.2326001
   Jebara T, 2011, J MACH LEARN RES, V12, P75
   Li XL, 2017, AAAI CONF ARTIF INTE, P4147
   Lichman M., 2013, UCI MACHINE LEARNING
   Liu JT, 2012, PROCEEDINGS OF 2012 INTERNATIONAL CONFERENCE ON CONSTRUCTION & REAL ESTATE MANAGEMENT, VOLS 1 AND 2, P339
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Tibshirani R, 2011, J R STAT SOC B, V73, P273, DOI 10.1111/j.1467-9868.2011.00771.x
   Wang H., 2013, INT C MACHINE LEARNI, P352
   Wang H, 2011, TRANSPORT RES REC, P42, DOI 10.3141/2260-05
   Wang H, 2013, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2013.398
   Wang H, 2012, BIOINFORMATICS, V28, pI127, DOI 10.1093/bioinformatics/bts228
   Wang H, 2011, IEEE I CONF COMP VIS, P557, DOI 10.1109/ICCV.2011.6126288
   Wang Q, 2019, IEEE T NEUR NET LEAR, V30, P1265, DOI 10.1109/TNNLS.2018.2861209
   Wang Q, 2018, IEEE T GEOSCI REMOTE, V56, P5910, DOI 10.1109/TGRS.2018.2828161
   Wang XD, 2017, IMAGE VISION COMPUT, V63, P10, DOI 10.1016/j.imavis.2017.05.004
   Wang XD, 2016, NEUROCOMPUTING, V200, P47, DOI 10.1016/j.neucom.2016.03.017
   Xiao LH, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS), DOI 10.1109/BTAS.2013.6712752
   Xiao LH, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P246, DOI 10.1109/ACPR.2013.34
   Xu JL, 2017, IEEE T IMAGE PROCESS, V26, P3016, DOI 10.1109/TIP.2017.2665976
   Xu YM, 2016, PATTERN RECOGN, V53, P25, DOI 10.1016/j.patcog.2015.12.007
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Ye J., 2007, P 21 ANN C NEUR INF, V20, P1649
   Yuan M., 2006, Journal of the Royal Statistical Society, Series B, V70, P53
   Zhang MX, 2017, MULTIMED TOOLS APPL, V76, P10761, DOI 10.1007/s11042-015-3173-5
   Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735
NR 32
TC 8
Z9 9
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15455
EP 15481
DI 10.1007/s11042-018-6937-x
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700057
DA 2024-07-18
ER

PT J
AU Ekmen, B
   Ekenel, HK
AF Ekmen, Beste
   Ekenel, Hazim Kemal
TI From 2D to 3D real-time expression transfer for facial animation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Expression transfer; Facial animation; Facial tracking;
   Performance-driven animation
AB In this paper, we present a three-stage approach, which creates realistic facial animations by tracking expressions of a human face in 2D and transferring them to a human-like 3D model in real-time. Our calibration-free method, which is based on an average human face, does not require training. The tracking is performed using a single camera to enable several practical applications, for example, using tablets and mobile devices, and the expressions are transferred with a joint-based system to improve the quality and persuasiveness of animations. In the first step of the method, a joint-based facial rig providing mobility to pseudo-muscles is attached to the 3D model. The second stage covers the tracking of 2D positions of the facial landmarks from a single camera view and transfer of 3D relative movement data to move the respective joints on the model. The last step includes the recording of animation using a partially automated key-framing technique. Experiments on the extended Cohn-Kanade dataset using peak frames in frontal-view videos have shown that the presented method produces visually satisfying facial animations.
C1 [Ekmen, Beste; Ekenel, Hazim Kemal] Istanbul Tech Univ, Dept Comp Engn, TR-34469 Istanbul, Turkey.
C3 Istanbul Technical University
RP Ekmen, B (corresponding author), Istanbul Tech Univ, Dept Comp Engn, TR-34469 Istanbul, Turkey.
EM ekmenb@itu.edu.tr; ekenel@itu.edu.tr
RI EKENEL, HAZIM KEMAL/A-5293-2016
OI EKENEL, HAZIM KEMAL/0000-0003-3697-8548; Ekmen,
   Beste/0000-0002-3560-8572
FU TuBTAK project [113E067]; EU Seventh Framework Programme Marie Curie FP7
   integration project
FX This work was supported by the TuBTAK project 113E067 and the EU Seventh
   Framework Programme Marie Curie FP7 integration project.
CR Al-Nuaimi T, 2006, THESIS
   [Anonymous], ACM T GRAPHIC
   [Anonymous], 2008, Computer Facial Animation
   [Anonymous], 2008, DATA DRIVEN 3D FACIA
   [Anonymous], 2015, FAC MOD
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.262
   Autodesk, 2015, MAK
   BLACK MJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P374, DOI 10.1109/ICCV.1995.466915
   Cao C, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925873
   Cohen M. M., 1993, Models and Techniques in Computer Animation, P139
   COHEN MM, 1990, BEHAV RES METH INSTR, V22, P260, DOI 10.3758/BF03203157
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Covell M, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P122, DOI 10.1109/AFGR.1996.557253
   DeCarlo D, 2000, INT J COMPUT VISION, V38, P99, DOI 10.1023/A:1008122917811
   Ekmen B, 2016, 2016 24TH SIGNAL PROCESSING AND COMMUNICATION APPLICATION CONFERENCE (SIU), P1193, DOI 10.1109/SIU.2016.7495959
   Essa I., 1996, Proceedings. Computer Animation '96, P68, DOI 10.1109/CA.1996.540489
   Gambaretto E, 2014, ACM SIGGRAPH 2014 CO, P1
   Gokturk SB, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P701, DOI 10.1109/ICCV.2001.937695
   Ichim AE, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766974
   Jin-xiang Chai, 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P193
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Lanitis A, 1997, IEEE T PATTERN ANAL, V19, P743, DOI 10.1109/34.598231
   Laursen MH, 2012, THESIS
   Lewis J. P., 1987, SIGCHI Bulletin, P143, DOI 10.1145/1165387.30874
   Lewis J.P., 2006, ACM SIGGRAPH 2006 Courses
   Linghua Li, 2012, Proceedings of the 2012 International Conference on Computer Science and Electronics Engineering (ICCSEE 2012), P434, DOI 10.1109/ICCSEE.2012.129
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Noh J, 1998, TECH REP
   Parke FI, 1974, TECH REP
   Pelachaud C, 1996, COGNITIVE SCI, V20, P1, DOI 10.1207/s15516709cog2001_1
   Pighin F., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P143, DOI 10.1109/ICCV.1999.791210
   Platt S. M., 1981, Computer Graphics, V15, P245, DOI 10.1145/965161.806812
   PS S., 2017, Int. J. Control. Theory Appl, V10, P651
   Ruhland K, 2017, IEEE COMPUT GRAPH, V37, P30, DOI 10.1109/MCG.2017.3271467
   TERZOPOULOS D, 1993, IEEE T PATTERN ANAL, V15, P569, DOI 10.1109/34.216726
   Turunen Markku., 2009, Proceedings of the American Symposium in Computer Graphics (SIACG'09), P203, DOI [DOI 10.1002/9780470682531.PAT0170, 10.1002/9780470682531.pat0170]
   Waters K., 1987, ACM SIGGRAPH Comput. Graph., V21, P17
   Williams L., 1990, Computer Graphics, V24, P235, DOI 10.1145/97880.97906
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X
   Zhao H, 2007, P COMP AN SOC AG HAS
NR 41
TC 2
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12519
EP 12535
DI 10.1007/s11042-018-6785-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900064
DA 2024-07-18
ER

PT J
AU Farinella, GM
   Napoli, C
   Nicotra, G
   Riccobene, S
AF Farinella, Giovanni Maria
   Napoli, Christian
   Nicotra, Gabriele
   Riccobene, Salvatore
TI A context-driven privacy enforcement system for autonomous media capture
   devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image recognition; Features extraction; Artificial intelligence; Image
   classification; Cloud computing
ID INTERNET; THINGS
AB The evolution of the Internet of Things and the related market has renewed the concept of media recording and sharing by means of a new kind of home-consumer devices, capable of continuous and autonomous media capture and upload. Such technologies have already begun to tamper with people's privacy and discretion expectations, also raising many concerns about the potential legal implications. This work proposes an overall context-related privacy preserving system, based on context recognition. Our approach has been specifically developed considering contexts characterized by a high degree of similarity. The presented methodology has been devised in order to enforce privacy rules using image recognition techniques jointly with radio beacon technology. The reported results show that, in the peculiar environment considered in this paper, the use of radio beacon technology can help to increase the performances of image recognition techniques, both in terms of computational performances and elapsed time.
C1 [Farinella, Giovanni Maria; Napoli, Christian; Nicotra, Gabriele; Riccobene, Salvatore] Univ Catania, Dept Math & Comp Sci, Viale A Doria 6, I-95125 Catania, Italy.
C3 University of Catania
RP Farinella, GM (corresponding author), Univ Catania, Dept Math & Comp Sci, Viale A Doria 6, I-95125 Catania, Italy.
EM gfarinella@dmi.unict.it; napoli@dmi.unict.it; nicotra@dmi.unict.it;
   riccobene@unict.it
RI Battiato, Sebastiano/ABI-1584-2020; Napoli, Christian/H-9398-2012;
   FARINELLA, Giovanni Maria/L-8555-2015
OI Battiato, Sebastiano/0000-0001-6127-2470; Napoli,
   Christian/0000-0002-3336-5853; FARINELLA, Giovanni
   Maria/0000-0002-6034-0432
CR Abowd G, 2007, ASS COGN WORKSH
   Aditya Paarijaat, 2016, P 14 ANN INT C MOBIL, P235
   Allen AL, 2008, U CHICAGO LAW REV, V75, P47
   [Anonymous], 2002, J MACH LEARN RES
   [Anonymous], 2014, P 12 ACM C EMBEDDED, DOI [DOI 10.1145/2668332.2668339, 10.1145/2668332.2668339]
   [Anonymous], 2014, Networks and Distributed Systems Security (NDSS)
   Atzori L, 2010, COMPUT NETW, V54, P2787, DOI 10.1016/j.comnet.2010.05.010
   AVIDAN S, 2006, ADV NEURAL INFORM PR, P57
   Avidan S, 2006, LECT NOTES COMPUT SC, V3953, P1, DOI 10.1007/11744078_1
   Battiato S, 2017, LECT NOTES COMPUT SC, V10485, P580, DOI 10.1007/978-3-319-68548-9_53
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Butler DJ, 2015, ACMIEEE INT CONF HUM, P27, DOI 10.1145/2696454.2696484
   Campbell C., 2000, 8th European Symposium on Artificial Neural Networks. ESANN"2000. Proceedings, P27
   Chen Y., 2010, P 1 AUGM HUM INT C, P24
   Cheng WilliamC., 2004, Proceedings of the the 1st ACM Workshop on Continuous Archival and Retrieval of Personal Experiences, CARPE '04, P86
   Chon Y, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P481
   Cramer R, 2001, LECT NOTES COMPUT SC, V2045, P280
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dai J, 2015, IEEE IMAGE PROC, P4238, DOI 10.1109/ICIP.2015.7351605
   Du W., 2001, Proceedings of the 2001 workshop on New security paradigms, P13, DOI 10.1145/508171.508174
   Enck W, 2014, ACM T COMPUT SYST, V32, DOI 10.1145/2619091
   Erkin Z, 2009, LECT NOTES COMPUT SC, V5672, P235, DOI 10.1007/978-3-642-03168-7_14
   Goldreich O., 2009, FDN CRYPTOGRAPHY, V2
   Goldreich O., 2019, Providing Sound Foundations for Cryptography: On the Work of Shafi Goldwasser and Silvio Micali, P307, DOI DOI 10.1145/3335741.3335755
   Hoyle R, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P571, DOI 10.1145/2632048.2632079
   Jana S, 2013, P IEEE S SECUR PRIV, P349, DOI 10.1109/SP.2013.31
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar R, 2010, LINK MINING: MODELS, ALGORITHMS, AND APPLICATIONS, P337, DOI 10.1007/978-1-4419-6515-8_13
   Lindell Yehuda, 2008, J Priv Confidentiality, V2008, P197, DOI DOI 10.29012/JPC.V1I1.566
   Mann S, 1997, COMPUTER, V30, P25, DOI 10.1109/2.566147
   Mihailidis A, 2007, ASS COGN WORKSH
   Miluzzo E, 2008, SENSYS'08: PROCEEDINGS OF THE 6TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P337
   Nauman M., 2010, P 5 ACM S INF COMP C, V10, P328, DOI [10.1145/1755688.1755732, DOI 10.1145/1755688.1755732]
   O'Hara Kieron, 2008, Identity in the Information Society, V1, P155, DOI 10.1007/s12394-009-0008-4
   Ongtang M, 2010, 26TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2010), P221
   Palattella MR, 2016, IEEE J SEL AREA COMM, V34, P510, DOI 10.1109/JSAC.2016.2525418
   Park S., 2008, AAAI Fall Symposium: AI in Eldercare: New Solutions to Old Problems, P70
   Portokalidis G, 2010, 26TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2010), P347
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Teraoka T, 2012, HUM-CENTRIC COMPUT I, V2, DOI 10.1186/2192-1962-2-1
   Thierer A.D., 2015, RICH JL TECH, V21, P6
   Thomaz E, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P739, DOI 10.1145/2493432.2493509
   Truong KN, 2005, LECT NOTES COMPUT SC, V3660, P73
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wei J, 2014, IEEE CONSUM ELECTR M, V3, P53, DOI 10.1109/MCE.2014.2317895
   Wu J, 2007, PROCEEDINGS OF THE 2007 IEEE INTERNATIONAL CONFERENCE ON SERVICE OPERATIONS AND LOGISTICS, AND INFORMATICS, P7, DOI 10.1109/SOLI.2007.4383891
NR 49
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 14091
EP 14108
DI 10.1007/s11042-019-7376-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900067
DA 2024-07-18
ER

PT J
AU Hemida, O
   Huo, YR
   He, HJ
   Chen, F
AF Hemida, Omer
   Huo, Yaoran
   He, Hongjie
   Chen, Fan
TI A restorable fragile watermarking scheme with superior localization for
   both natural and text images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fragile watermarking; Digital image; Multi-stage neighbor detection; A
   variable length coding
ID SELF-RECOVERY; TAMPER DETECTION; AUTHENTICATION
AB In this paper, we present a method for detecting and restoring tampered information in natural and text images. To take the detection ability, invisibility, and recovery quality into account for both natural and text images, this work generates the authentication watermark for each 4 x 4 block by a hash function and a variable capacity recovery watermark for each 2 x 2 block by allocating more bits to the textural blocks and fewer bits to the smooth ones. The authentication watermark and the recovery one are embedded in the original image by adopting different strategies based on a secret key. The multi-stage neighbor detection strategy is designed to locate the tampered image blocks accurately. The proposed scheme outperforms in invisibility, with detecting tampered locations and recovery of the tampered regions. The simulation results show that the proposed scheme achieves better recovery quality and invisibility for natural and text images due to a variable-capacity recovery watermark and superior localization. Further, the proposed method computationally is less expensive compared with the existing works.
C1 [Hemida, Omer; Huo, Yaoran; He, Hongjie; Chen, Fan] Southwest Jiaotong Univ, Sichuan Key Lab Signal & Informat Proc, Chengdu, Sichuan, Peoples R China.
C3 Southwest Jiaotong University
RP Chen, F (corresponding author), Southwest Jiaotong Univ, Sichuan Key Lab Signal & Informat Proc, Chengdu, Sichuan, Peoples R China.
EM omerharoun1@yahoo.com; hjhe@swjtu.cn; mrchenfan@126.com
RI fan, chen/GWC-9330-2022
FU National Natural Science Foundation of China (NSFC) [61872303,61461047];
   Technology Innovation Talent Program of Science & Technology Department
   of Sichuan Province [2018RZ0143]
FX This work is supported by National Natural Science Foundation of China
   (NSFC) Under grants (61872303,61461047), and Technology Innovation
   Talent Program of Science & Technology Department of Sichuan
   Province(2018RZ0143).
CR Atallah MJ, 2003, LECT NOTES COMPUT SC, V2578, P196
   Benrhouma O, 2015, NONLINEAR DYNAM, V79, P1817, DOI 10.1007/s11071-014-1777-3
   Betancourth GP, 2012, C HUM SYST INTERACT, P168, DOI 10.1109/HSI.2012.32
   Brassil JT, 1999, P IEEE, V87, P1181, DOI 10.1109/5.771071
   Chang CC, 2006, PATTERN RECOGN LETT, V27, P439, DOI 10.1016/j.patrec.2005.09.006
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Dadkhah S, 2014, SIGNAL PROCESS-IMAGE, V29, P1197, DOI 10.1016/j.image.2014.09.001
   Dongmei Niu, 2016, Digital Forensics and Watermarking. 14th International Workshop, IWDW 2015. Revised Selected Papers: LNCS 9569, P250, DOI 10.1007/978-3-319-31960-5_21
   Fridrich J, 2002, J ELECTRON IMAGING, V11, P262, DOI 10.1117/1.1459449
   Fridrich J., 1999, P 1999 INT C IM PROC, P792, DOI [10.1109/ICIP.1999.817228, DOI 10.1109/ICIP.1999.817228]
   Han SH, 2010, INT J INF SECUR, V9, P19, DOI 10.1007/s10207-009-0093-2
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   He HJ, 2009, LECT NOTES COMPUT SC, V5806, P132
   He HJ, 2009, SIGNAL PROCESS, V89, P1557, DOI 10.1016/j.sigpro.2009.02.009
   Hu YC, 2017, MULTIMED TOOLS APPL, V76, P15435, DOI 10.1007/s11042-016-3847-7
   Ji P, 2016, LECT NOTES COMPUT SC, V10039, P104, DOI 10.1007/978-3-319-48671-0_10
   Kurniawan F, 2014, 2014 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES (ISBAST), P290, DOI 10.1109/ISBAST.2014.7013137
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Li CL, 2011, COMPUT ELECTR ENG, V37, P927, DOI 10.1016/j.compeleceng.2011.09.007
   Lin CC, 2017, MULTIMED TOOLS APPL, V76, P463, DOI 10.1007/s11042-015-3059-6
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Nyeem H, 2016, MULTIMED TOOLS APPL, V75, P15849, DOI 10.1007/s11042-015-2893-x
   Olanrewaju RF, 2016, INT CONF INFORM COMM, P222, DOI [10.1109/ICT4M.2016.053, 10.1109/ICT4M.2016.48]
   Piper A, 2013, IET INFORM SECUR, V7, P300, DOI 10.1049/iet-ifs.2010.0059
   Puhan NB, 2005, LECT NOTES ARTIF INT, V3802, P661
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Qin C, 2016, INFORM SCIENCES, V373, P233, DOI 10.1016/j.ins.2016.09.001
   Qin C, 2013, SIGNAL PROCESS, V93, P933, DOI 10.1016/j.sigpro.2012.11.013
   Rosales-Roldan L, 2013, SIGNAL PROCESS-IMAGE, V28, P69, DOI 10.1016/j.image.2012.11.006
   Shi H, 2017, MULTIMED TOOLS APPL, V76, P6941, DOI 10.1007/s11042-016-3328-z
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Singh P, 2016, MULTIMED TOOLS APPL, V75, P8165, DOI 10.1007/s11042-015-2736-9
   Sreenivas K, 2018, INT J MACH LEARN CYB, V9, P1193, DOI 10.1007/s13042-017-0641-4
   Tong XJ, 2013, SIGNAL PROCESS-IMAGE, V28, P301, DOI 10.1016/j.image.2012.12.003
   Wang H, 2014, SIGNAL PROCESS-IMAGE, V29, P773, DOI 10.1016/j.image.2014.05.001
   Wang XY, 2013, NONLINEAR DYNAM, V73, P1945, DOI 10.1007/s11071-013-0915-7
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiang Huazheng, 2006, Wuhan University Journal of Natural Sciences, V11, P1661, DOI 10.1007/BF02831845
   Yang CW, 2010, SIGNAL PROCESS, V90, P331, DOI 10.1016/j.sigpro.2009.07.007
   Zhang JP, 2013, OPTIK, V124, P6367, DOI 10.1016/j.ijleo.2013.05.040
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang XP, 2011, MULTIMED TOOLS APPL, V54, P385, DOI 10.1007/s11042-010-0541-z
NR 46
TC 9
Z9 9
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12373
EP 12403
DI 10.1007/s11042-018-6664-3
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900058
DA 2024-07-18
ER

PT J
AU Kim, JH
   Lee, J
AF Kim, Jong-Hyun
   Lee, Jung
TI An optimized placement of building drawings with moving least squares
   and K-means clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moving least squares; K-means clustering; Arrangement of building
   drawings; Architectural design
ID POLYGON CONTAINMENT; PARALLEL FRAMEWORK; PACKING
AB In this paper, we propose a method that can efficiently process the arrangement of building drawings using K-means clustering and vector field constructed by optimized moving least squares (MLS). In the proposed framework, after selecting the area to actually place the buildings, the vector field is generated by optimizing the MLS based on this area, and the angle to rotate the building drawing is determined based on this field. In the simulation step, K-means clustering is used to determine the initial layout of the building drawings, and their locations are advected based on the vector field calculated by MLS to further locate new building drawings in the empty space. This allows a maximum number of building plans to be placed within a given area. The practicality of the proposed method was verified by comparing with the actual architectural design, and the efficiency of the overall design process was improved by greatly reducing the amount of time and work required.
C1 [Kim, Jong-Hyun] Kangnam Univ, Dept Software Applicat, Yongin, Gyeonggi, South Korea.
   [Lee, Jung] Hallym Univ, Dept Convergence Software, Chunchon, Gangwon, South Korea.
C3 Kangnam University; Hallym University
RP Lee, J (corresponding author), Hallym Univ, Dept Convergence Software, Chunchon, Gangwon, South Korea.
EM jonghyunkim@kangnam.ac.kr; airjung@hallym.ac.kr
OI Lee, Jung/0000-0003-0458-1474
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Science, ICT & Future Planning
   [2017R1C1B5074984]; Hallym University [HRF-201704-014]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Science, ICT & Future Planning (No. 2017R1C1B5074984). This research was
   supported by a Hallym University Research Fund (HRF-201704-014).
CR AKINCI N, VIRTUAL, V24, P195, DOI DOI 10.1002/CAV.1499
   Avnaim F., 1988, STACS 88. 5th Annual Symposium on Theoretical Aspects of Computer Science. Proceedings, P322, DOI 10.1007/BFb0035856
   Avnaim Francis., 1987, P 3 ACM S COMPUTATIO, P242
   BAKER BS, 1986, J ALGORITHM, V7, P532, DOI 10.1016/0196-6774(86)90017-9
   Battiato S, 2007, COMPUT GRAPH FORUM, V26, P794, DOI 10.1111/j.1467-8659.2007.01021.x
   Battiato S., 2013, J ELECT COMPUT ENG, V2013, P8
   Bennell JA, 2009, J OPER RES SOC, V60, pS93, DOI 10.1057/jors.2008.169
   DOWSLAND KA, 1995, EUR J OPER RES, V84, P506, DOI 10.1016/0377-2217(95)00019-M
   Fang XZ, 2017, NEURAL NETWORKS, V88, P1, DOI 10.1016/j.neunet.2017.01.001
   Fang XZ, 2016, IEEE T CYBERNETICS, V46, P1828, DOI 10.1109/TCYB.2015.2454521
   FOWLER RJ, 1981, INFORM PROCESS LETT, V12, P133, DOI 10.1016/0020-0190(81)90111-3
   Grinde RB, 1996, EUR J OPER RES, V92, P368, DOI 10.1016/0377-2217(94)00279-7
   Grinde RB, 1997, COMPUT OPER RES, V24, P231, DOI 10.1016/S0305-0548(96)00050-0
   Hausner A, 2001, COMP GRAPH, P573, DOI 10.1145/383259.383327
   Liu Y, 2010, COMPUT GRAPH FORUM, V29, P2387, DOI 10.1111/j.1467-8659.2010.01752.x
   MARTIN RR, 1988, COMPUT AIDED DESIGN, V20, P506, DOI 10.1016/0010-4485(88)90040-1
   Milenkovic V, 1997, ALGORITHMICA, V19, P183, DOI 10.1007/PL00014416
   Milenkovic VJ, 1999, COMP GEOM-THEOR APPL, V13, P3, DOI 10.1016/S0925-7721(99)00006-1
   Milenkovic VJ, 1998, COMP GEOM-THEOR APPL, V10, P305, DOI 10.1016/S0925-7721(98)00012-1
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Puglisi Giovanni, 2012, COMPUTATIONAL IMAGIN, P189
   Yan C, 2018, IEEE Transactions on Multimedia
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
NR 26
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11719
EP 11734
DI 10.1007/s11042-018-6683-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900028
DA 2024-07-18
ER

PT J
AU Souaidi, M
   Abdelouahed, AA
   El Ansari, M
AF Souaidi, Meryem
   Abdelouahed, Abdelkaher Ait
   El Ansari, Mohamed
TI Multi-scale completed local binary patterns for ulcer detection in
   wireless capsule endoscopy images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless capsule endoscopy (WCE); Ulcer regions; Texture analysis;
   Completed local binary pattern (CLBP); Laplacian pyramid; Color space
ID COMPUTER-AIDED DIAGNOSIS; TEXTURE
AB This paper deals with ulcer abnormalities detection of small bowel, from wireless capsule endoscopy images (WCE). We propose a multi-scale approach based on completed local binary patterns, and laplacian pyramid (MS-CLBP). The proposed approach captures additional information about the magnitude as a robust descriptor against illuminations changes in WCE images. In addition, ulcer detection, was performed using the Green component and Cr components of RGB and YCbCr color spaces, respectively. Using the support vector machine (SVM) classifier, we conduct several experiments on two datasets. The results obtained validate the efficiency of the proposed system with an average accuracy of 95.11 and 93.88% for both datasets. Finally, a comparison with the state of the art methods shows that the proposed method is superior to the other approaches.
C1 [Souaidi, Meryem; Abdelouahed, Abdelkaher Ait; El Ansari, Mohamed] Ibn Zohr Univ, Fac Sci, Dept Comp Sci, LabSIV, BP 8106, Agadir 80000, Morocco.
C3 Ibn Zohr University of Agadir
RP Souaidi, M (corresponding author), Ibn Zohr Univ, Fac Sci, Dept Comp Sci, LabSIV, BP 8106, Agadir 80000, Morocco.
EM souaidi.meryem@gmail.com; a.abdelkaher@gmail.com; melansari@gmail.com
RI El Ansari, Mohamed/L-9738-2016
OI El Ansari, Mohamed/0000-0001-5394-9066
CR [Anonymous], 3 INT C ADV TECHN SI
   [Anonymous], 2010, AS PAC SIGN INF PROC
   [Anonymous], 2012, ARXIV12034855
   [Anonymous], NEW ADV BASIC CLIN G
   [Anonymous], P 2 INT C INT THINGS
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Charfi S, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P134
   Charfi S, 2018, MULTIMED TOOLS APPL, V77, P4047, DOI 10.1007/s11042-017-4555-7
   Charisis VS, 2013, COMP MED SY, P203, DOI 10.1109/CBMS.2013.6627789
   Chen Y., 2012, Proc. 20th ACM Int. Conf. Multimed, P1181, DOI DOI 10.1145/2393347.2396413
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Davarpanah SH, 2016, MULTIMED TOOLS APPL, V75, P6549, DOI 10.1007/s11042-015-2588-3
   Eid A, 2013, COMP MED SY, P273, DOI 10.1109/CBMS.2013.6627801
   El Ansari M, 2017, 2017 INT C WIRELESS, P1
   El Ansari M, 2018, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2018), VOL 5: VISAPP, P325, DOI 10.5220/0006620803250334
   Ellahyani A, 2017, MULTIMED TOOLS APPL, V76, P24495, DOI 10.1007/s11042-016-4207-3
   Gan T, 2008, WORLD J GASTROENTERO, V14, P6929, DOI 10.3748/wjg.14.6929
   Guo ZH, 2010, IEEE IMAGE PROC, P4521, DOI 10.1109/ICIP.2010.5653119
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Li BP, 2011, ARTIF INTELL MED, V52, P11, DOI 10.1016/j.artmed.2011.01.003
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Lin QY, 2015, IEEE IMAGE PROC, P26, DOI 10.1109/ICIP.2015.7350752
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Omidyeganeh M, 2013, MULTIMED TOOLS APPL, V65, P441, DOI 10.1007/s11042-012-1012-5
   Peterson L.E., 2009, SCHOLARPEDIA, V4, P1883, DOI 10.4249/scholarpedia.1883
   Porebski A, 2008, 1 WORKSHOPS IMAGE PR, P1
   Salehpour P, 2016, BIOMED ENG-APP BAS C, V28, DOI 10.4015/S1016237216500290
   Seguí S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.7017.09.004, 10.1016/j.cmpb.2012.09.004]
   Yeh J.-Y., 2014, Journal of Software Engineering and Applications, V07, P422, DOI DOI 10.4236/JSEA.2014.75039
   Yu LC, 2012, INT C PATT RECOG, P45
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Zhang GS, 2015, MULTIMED TOOLS APPL, V74, P3783, DOI 10.1007/s11042-013-1799-8
NR 40
TC 38
Z9 39
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13091
EP 13108
DI 10.1007/s11042-018-6086-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900019
DA 2024-07-18
ER

PT J
AU Cao, MY
   Wang, S
   Wei, L
   Rai, L
   Li, D
   Yu, H
   Shao, D
AF Cao, Maoyong
   Wang, Shuang
   Wei, Lu
   Rai, Laxmisha
   Li, Dong
   Yu, Hui
   Shao, Dan
TI Segmentation of immunohistochemical image of lung neuroendocrine tumor
   based on double layer watershed
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watershed; Ki-67; Segmentation; Lung neuroendocrine tumor
ID BREAST-CANCER
AB Lung neuroendocrine tumor is a special kind of lung cancer. The level of tumor is a major factor in the diagnostic process of this kind of tumor, where Ki-67 proliferation is often used as the classification index. The segmentation and classification of Ki-67 immunohistochemical images of lung neuroendocrine tumors is the key to realize automatic calculation of Ki-67 proliferation index. In this paper, a new image segmentation algorithm based on double layer watershed is proposed, which is suitable for the characteristics of uneven color of the nucleus. For calculating the Ki-67 proliferation index, classification of negative and positive tumor cells by their color difference is accomplished. By means of the features of regional average gray level, area and circularity, the segmentation of nucleus which cannot be completely segmented is supplemented. The mean and standard deviation are used to evaluate the accuracy after segmentation, and they have major improvement through the new algorithm proposed in this paper. Detailed theoretical analysis and reasonable experimental results demonstrate the feasibility and accuracy of the method.
C1 [Cao, Maoyong; Wang, Shuang; Wei, Lu] Shandong Univ Sci & Technol, Coll Elect Engn & Automat, 579 Qianwangang Rd, Qingdao 266590, Shandong, Peoples R China.
   [Rai, Laxmisha] Shandong Univ Sci & Technol, Coll Elect Commun & Phys, Qingdao, Shandong, Peoples R China.
   [Li, Dong; Yu, Hui; Shao, Dan] First Peoples Hosp, Qingdao Econ & Technol Dev Area, Qingdao, Shandong, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Cao, MY (corresponding author), Shandong Univ Sci & Technol, Coll Elect Engn & Automat, 579 Qianwangang Rd, Qingdao 266590, Shandong, Peoples R China.
EM my-cao@263.net
RI Rai, Laxmisha/B-6552-2008
OI Rai, Laxmisha/0000-0003-1494-1138
CR [Anonymous], P WORLD C INT CONTR, DOI DOI 10.1109/WCICA.2006.1713888
   Caves R, 1998, IEEE T IMAGE PROCESS, V7, P1534, DOI 10.1109/83.725361
   Chen S, 2011, MED PHYS, V38, P1844, DOI 10.1118/1.3561504
   Chen WQ, 2016, CA-CANCER J CLIN, V66, P115, DOI 10.3322/caac.21338
   Cheren M., 2009, Physical Craving and Food Addiction, P1
   Devaki K, 2014, IMAGING SCI J, V62, P303, DOI 10.1179/1743131X13Y.0000000066
   Fan D, 2016, MULTIMED TOOLS APPL, V75, P12227, DOI 10.1007/s11042-016-3459-2
   Frucci M, 2016, PATTERN RECOGN, V52, P148, DOI 10.1016/j.patcog.2015.08.017
   Hunter LA, 2013, MED PHYS, V40, DOI 10.1118/1.4829514
   Jingqi Ao, 2012, Proceedings of the 2012 IEEE Southwest Symposium on Image Analysis & Interpretation (SSIAI 2012), P29, DOI 10.1109/SSIAI.2012.6202445
   Lassen B, 2013, IEEE T MED IMAGING, V32, P210, DOI 10.1109/TMI.2012.2219881
   Lu SY, 2017, COMPUT METH PROG BIO, V141, P1, DOI 10.1016/j.cmpb.2017.01.014
   Mouelhi A, 2013, BIOMED SIGNAL PROCES, V8, P421, DOI 10.1016/j.bspc.2013.04.003
   Movsas B, 2003, J CLIN ONCOL, V21, P4553, DOI 10.1200/JCO.2003.04.018
   Ng A, 2010, MED PHYS, V37, P1017, DOI 10.1118/1.3284368
   Nielsen PS, 2014, APPL IMMUNOHISTO M M, V22, P568, DOI 10.1097/PAI.0b013e3182a84b99
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qi X, 2012, IEEE T BIO-MED ENG, V59, P754, DOI 10.1109/TBME.2011.2179298
   Rakovich TY, 2014, ACS NANO, V8, P5682, DOI 10.1021/nn500212h
   Sa JM, 2016, INT CONF SYST INFORM, P886, DOI 10.1109/ICSAI.2016.7811076
   Schüffler PJ, 2015, CYTOM PART A, V87A, P936, DOI 10.1002/cyto.a.22702
   Shi YH, 2013, APPL INTELL, V38, P16, DOI 10.1007/s10489-012-0354-z
   Tan YQ, 2013, MED PHYS, V40, DOI 10.1118/1.4793409
   Vitulano S, 1997, PATTERN RECOGN LETT, V18, P1125, DOI 10.1016/S0167-8655(97)00097-4
   Wei Q, 2008, INT J COMPUT ASS RAD, V3, P151, DOI 10.1007/s11548-008-0153-5
   Wu GR, 2012, MED PHYS, V39, P7694, DOI 10.1118/1.4768226
   Xie X, 2017, PROC IEEE MICR ELECT, P813, DOI 10.1109/MEMSYS.2017.7863532
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Xing FY, 2016, IEEE T MED IMAGING, V35, P550, DOI 10.1109/TMI.2015.2481436
   Xing FY, 2014, IEEE T BIO-MED ENG, V61, P859, DOI 10.1109/TBME.2013.2291703
   Xue Z, 2010, COMPUT MED IMAG GRAP, V34, P55, DOI 10.1016/j.compmedimag.2009.05.007
   Yang HG, 2014, PATTERN RECOGN, V47, P2266, DOI 10.1016/j.patcog.2013.11.004
   Zhang L, 2017, I S BIOMED IMAGING, P406, DOI 10.1109/ISBI.2017.7950548
   Zhang YD, 2015, INFORM SCIENCES, V322, P115, DOI 10.1016/j.ins.2015.06.017
   Zhang YD, 2009, SCI CHINA SER F, V52, P914, DOI 10.1007/s11432-009-0019-7
   ZIJDENBOS AP, 1994, IEEE T MED IMAGING, V13, P716, DOI 10.1109/42.363096
NR 36
TC 5
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 9193
EP 9215
DI 10.1007/s11042-018-6431-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800070
DA 2024-07-18
ER

PT J
AU Delforouzi, A
   Tabatabaei, SAH
   Shirahama, K
   Grzegorzek, M
AF Delforouzi, Ahmad
   Tabatabaei, Seyed Amir Hossein
   Shirahama, Kimiaki
   Grzegorzek, Marcin
TI A polar model for fast object tracking in 360-degree camera images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Polar model; 360-degree camera; Color binary features
ID OMNIDIRECTIONAL VISION; MULTIPLE
AB The task of fast object tracking in polar images using emerging high-resolution 360-degree camera technology is presented in this paper. In this approach, when an arbitrary object has been selected in the first frame, the proposed method searches for the object in the next frames. This task is challenging when the video contains complexity which cannot be handled by common tracking methods. The main contribution of this paper uses polar object selection and color binary features to facilitate robust object tracking in 360-degree images. Using the proposed polar object selection method, each object is represented by a polar component and high performance of the tracking algorithm in terms of precision and speed is achieved. We evaluate the applicability of our approach on a new dataset containing more than 30000 frames of 360-degree images wherein high performance in challenging real-world scenarios is demonstrated. The proposed algorithm outperforms the related methods.
C1 [Delforouzi, Ahmad; Tabatabaei, Seyed Amir Hossein; Shirahama, Kimiaki; Grzegorzek, Marcin] Univ Siegen, Res Grp Pattern Recognit, Hoelderlinstr 3, D-57076 Siegen, Germany.
C3 Universitat Siegen
RP Delforouzi, A (corresponding author), Univ Siegen, Res Grp Pattern Recognit, Hoelderlinstr 3, D-57076 Siegen, Germany.
EM ahmad.delforouzi@uni-siegen.de; amir.tabatabaei@uni-siegen.de;
   kimiaki.shirahama@uni-siegen.de; marcin.grzegorzek@uni-siegen.de
RI Grzegorzek, Marcin/AAF-1647-2021
OI Grzegorzek, Marcin/0000-0003-4877-8287
CR Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Bouguet J-Y, 1999, Pyramidal implementation of the Lucas Kanade feature tracker
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chen CH, 2008, IEEE T CIRC SYST VID, V18, P1052, DOI 10.1109/TCSVT.2008.928223
   Choe G, 2015, MULTIMED TOOLS APPL, V74, P9771, DOI 10.1007/s11042-014-2150-8
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Delforouzi A, 2016, INT C PATT RECOG, P1798, DOI 10.1109/ICPR.2016.7899897
   Delforouzi A, 2016, IEEE INT SYM MULTIM, P347, DOI [10.1109/ISM.2016.103, 10.1109/ISM.2016.0077]
   Demiroz B. E., 2012, 2012_5th_International Symposium_on_Communications,_Control_and_Signal_Processing, P1
   Ding GG, 2018, IEEE T INTELL TRANSP, V19, P140, DOI 10.1109/TITS.2017.2774778
   FOLDESY P, 2002, PROCEEDINGS OF THE 2, V7, P63
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hrabar S, 2003, IEEE INT CONF ROBOT, P558
   Hu S, 2012, AASRI PROC, V3, P351, DOI 10.1016/j.aasri.2012.11.055
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kim J, 2007, INT J CONTROL AUTOM, V5, P663
   Leibe B, 2005, PROC CVPR IEEE, P878
   LIN Z, 2007, IEEE 11TH INTERNATIO, V2007, P1
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Mao YL, 2018, IEEE INT CONF SENS, P145
   Markovic I, 2014, IEEE INT CONF ROBOT, P5630, DOI 10.1109/ICRA.2014.6907687
   Miao Q, 2011, PATTERN RECOGN LETT, V32, P1564, DOI 10.1016/j.patrec.2011.05.017
   Milan A, 2016, IEEE T PATTERN ANAL, V38, P2054, DOI 10.1109/TPAMI.2015.2505309
   Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103
   Oh CM, 2012, IEEE IND ELEC, P4232, DOI 10.1109/IECON.2012.6389210
   Scaramuzza D, 2008, IEEE T ROBOT, V24, P1015, DOI 10.1109/TRO.2008.2004490
   Scotti G., 2004, Intelligent Distributed Surveillance Systems (IDSS-04), P26
   Walia GS, 2016, MULTIMED TOOLS APPL, V75, P15821, DOI 10.1007/s11042-015-2890-0
   Wang DL, 2012, MULTIMED TOOLS APPL, V56, P303, DOI 10.1007/s11042-010-0646-4
   Wang L, 2012, IEEE T INTELL TRANSP, V13, P691, DOI 10.1109/TITS.2011.2179536
   Wang YP, 2012, J CHEM RES, P21, DOI 10.3184/174751912X13252567769442
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Xiao JJ, 2015, PROC CVPR IEEE, P4978, DOI 10.1109/CVPR.2015.7299132
   Zhang BC, 2017, IEEE T SYST MAN CY-S, V47, P693, DOI 10.1109/TSMC.2016.2629509
   Zhao S, 2016, IEEE T AUTOMAT CONTR, VPP, P1
   Zhao S, 2018, IEEE J BIOMED HEALTH, V22, P1571, DOI 10.1109/JBHI.2017.2776246
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zirakchi A, 2017, PROCEEDINGS OF THE ASME 10TH ANNUAL DYNAMIC SYSTEMS AND CONTROL CONFERENCE, 2017, VOL 2
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
NR 43
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 9275
EP 9297
DI 10.1007/s11042-018-6525-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800073
DA 2024-07-18
ER

PT J
AU Wang, RQ
   Wu, XX
AF Wang, Ruiqi
   Wu, Xinxiao
TI Combining multiple deep cues for action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Multiple deep cues; l(p)-norm multiple kernel
   learning
AB In this paper, we propose a novel deep learning based framework to fuse multiple cues of action motions, objects and scenes for complex action recognition. Since the deep features achieve promising results, three deep representations are extracted for capturing both temporal and contextual information of actions. Particularly, for the action cue, we first adopt a deep detection model to detect persons frame by frame and then feed the deep representations of persons into a Gated Recurrent Unit model to generate the action features. Different from the existing deep action features, our feature is capable of modeling the global dynamics of long human motion. The scene and object cues are also represented by deep features pooling on all the frames in a video. Moreover, we introduce an l(p)-norm multiple kernel learning method to effectively combine the multiple deep representations of the video to learn robust classifiers of actions by capturing the contextual relationships between action, object and scene. Extensive experiments on two real-world action datasets (i.e., UCF101 and HMDB51) clearly demonstrate the effectiveness of our method.
C1 [Wang, Ruiqi; Wu, Xinxiao] Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Wu, XX (corresponding author), Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
EM wang_ruiqi@bit.edu.cn; wuxinxiao@bit.edu.cn
FU Natural Science Foundation of China (NSFC) [61673062, 61472038]
FX This work was supported by the Natural Science Foundation of China
   (NSFC) under Grants No. 61673062 and No. 61472038.
CR [Anonymous], IJCAI
   [Anonymous], 2016, ECCV
   [Anonymous], 2009, CVPR
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], SIU
   [Anonymous], 2016, CVPR
   [Anonymous], CVPR
   [Anonymous], 2016, ICLR
   [Anonymous], IEEE T CYBERN
   [Anonymous], 2014, **DROPPED REF**
   [Anonymous], 2015, CVPR
   [Anonymous], ARXIV161106678 CORR
   [Anonymous], ARXIV14120767 CORR
   [Anonymous], 2016, CVPR
   [Anonymous], 2015, CVPR
   [Anonymous], 2015, ICML
   [Anonymous], J MACH LEARN RES
   [Anonymous], 2015, CVPR
   [Anonymous], AAAI
   [Anonymous], 2013, P ICCV
   [Anonymous], 2015, ICML
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2016, CVPR
   [Anonymous], 2015, P IEEE INT C COMPUTE
   [Anonymous], CVPR
   [Anonymous], 2017, CVPR
   [Anonymous], ARXIV170107368 CORR
   [Anonymous], 2016, ACM MM
   [Anonymous], 2010, ICML
   [Anonymous], CVPR
   [Anonymous], 2015, ICCV
   [Anonymous], 2004, ICML
   [Anonymous], 2016, CVPR
   [Anonymous], 2012, CoRR
   [Anonymous], 2016, ECCV
   [Anonymous], 2014, CVPR
   Baccouche Moez, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, P29, DOI 10.1007/978-3-642-25446-8_4
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Donahue J., 2015, CVPR
   Girshick R., 2013, IEEE Comput. Soc., P580
   Han Dong., 2009, ICCV
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ikizler-Cinbis Nazli., 2010, ECCV
   Jiang YG, 2011, IEEE T CIRC SYST VID, V21, P674, DOI 10.1109/TCSVT.2011.2129870
   Liu J., 2008, CVPR
   Liu WF, 2018, INFORM FUSION, V41, P119, DOI 10.1016/j.inffus.2017.09.001
   Liu WF, 2016, IEEE T IND ELECTRON, V63, P5120, DOI 10.1109/TIE.2016.2552147
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Niebles JuanCarlos., 2007, CVPR
   Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491
   Simonyan K., 2014, 14091556 ARXIV
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wang L., 2015, CVPR
   Wang S. H., 2016, MSC THESIS, P1
   Wu XX, 2013, IEEE T CIRC SYST VID, V23, P1422, DOI 10.1109/TCSVT.2013.2244794
   Yang XH, 2017, INFORM SCIENCES, V385, P338, DOI 10.1016/j.ins.2017.01.011
   Yao B., 2010, P CVPR
NR 59
TC 3
Z9 3
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 9933
EP 9950
DI 10.1007/s11042-018-6509-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400020
DA 2024-07-18
ER

PT J
AU Kaur, G
   Kaur, J
   Aggarwal, S
   Singla, C
   Mahajan, N
   Kaushal, S
   Sangaiah, AK
AF Kaur, Gurjot
   Kaur, Jasleen
   Aggarwal, Shubhani
   Singla, Chinn
   Mahajan, Nitish
   Kaushal, Sakshi
   Sangaiah, Arun Kumar
TI An optimized hardware calibration technique for transmission of
   real-time applications in VoIP network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VoIP; RTP; Quality of Service (QoS); codec; AHP; Benchmarking
AB Voice over Internet Protocol (VoIP) uses packet switching to transmit voice, video, data and chat services. VoIP applications depend upon various speech codecs which vary in speech quality, bandwidth and computational requirements. The key challenges for improving the VoIP Quality of Service (QoS) and Quality of Experience (QoE) is to use best codec by considering network traffic and selecting the optimal hardware. Hardware Calibration is a mechanism to aid service providers by selecting a suitable hardware for Call Manager to transmit different real-time based applications. The paper focuses on proposing a computational model which suggests the most suitable hardware for a specific load handling requirement. The selection of processor is done by taking into consideration the effect of different codecs when it takes calls per second as input and gives output as whichever hardware is recommended for Call Manager to handle different types of applications like Peer-To-Peer (P2P) application, Back-To-Back (BTB) application, enabling voice logging, etc. The emulations demonstrate that the proposed model is suitable for selection of hardware which provides better QoS and QoE for the transmission VoIP based real-time applications. Further, a multi-criteria decision-making method based on Analytic Hierarchy Process (AHP) is also proposed to decide which hardware can be chosen as Call Manager. The results obtained from AHP are used to validate the outcome of the proposed computational model. The computational model is applicable only when the tests are run on particular systems and it suggests the best hardware among them for the particular offered load. However, to suggest the best configuration corresponding to the input load from the possible configurations available in the market, benchmarking is performed. A common scale model for hardware benchmark estimation particularly has been proposed for different scenarios.
C1 [Kaur, Gurjot; Kaur, Jasleen; Aggarwal, Shubhani; Singla, Chinn; Mahajan, Nitish; Kaushal, Sakshi] Panjab Univ Chandigarh, Univ Inst Engn & Technol, Chandigarh, India.
   [Sangaiah, Arun Kumar] VIT Univ, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
C3 Panjab University; Vellore Institute of Technology (VIT); VIT Vellore
RP Kaushal, S (corresponding author), Panjab Univ Chandigarh, Univ Inst Engn & Technol, Chandigarh, India.; Sangaiah, AK (corresponding author), VIT Univ, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
EM sakshi@pu.ac.in; arunkumarsangaiah@gmail.com
RI Sangaiah, Arun Kumar/U-6785-2019; Aggarwal, Shubhani/AAY-2243-2020
OI Sangaiah, Arun Kumar/0000-0002-0229-2460; AGGARWAL,
   SHUBHANI/0000-0002-1832-6151
FU CC&BT, Ministry of Electronics and Information Technology, Government of
   India, India
FX This work is funded and supported by CC&BT, Ministry of Electronics and
   Information Technology, Government of India, India.
CR [Anonymous], 7339 RFC
   Ansari A.M., 2013, 2013 10 INT C WIR OP, P1
   Chang LH, 2013, COMPUT STAND INTER, V35, P158, DOI 10.1016/j.csi.2012.06.003
   Dagdeviren M, 2009, EXPERT SYST APPL, V36, P8143, DOI 10.1016/j.eswa.2008.10.016
   Freeman Roger L., 2015, Telecommunication system engineering, V82
   Goode B, 2002, P IEEE, V90, P1495, DOI 10.1109/JPROC.2002.802005
   HOLE DP, 2004, CAPACITY IEEE 802 11, P196
   Kim K, 2011, P 5 INT C UB INF MAN
   Kim K, 2011, PUBLIC HEALTH NUTR, V14, P1080, DOI 10.1017/S1368980010003733
   Naeem M, 2010, C LOCAL COMPUT NETW, P196, DOI 10.1109/LCN.2010.5735699
   Qiao ZH, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P1473, DOI 10.1109/ICC.2004.1312756
   Rasol M, 2016, INT J CLOUD APPL COM, V6, P25, DOI 10.4018/IJCAC.2016040103
   Rosenberg J, 2002, 3261 IETF RFC
   Rosenberg J., 2002, 3264 RFC
   Satty T.L., 1980, ANAL HIERARCHY PROCE
   Shah RD, 2016, PROCEDIA COMPUT SCI, V79, P940, DOI 10.1016/j.procs.2016.03.119
   Takahashi A, 2004, IEEE COMMUN MAG, V42, P28, DOI 10.1109/MCOM.2004.1316526
   Tarik Anouari, 2012, INT J COMPUTER APPL, P29
   Thompson C. A., 2013, ARXIV13122625
   Whittaker ET, CALCULUS OBSERVATION
   Yu J, 2008, INT J ADV TELECOM, V1, P27
NR 21
TC 6
Z9 7
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5537
EP 5570
DI 10.1007/s11042-017-5203-y
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100027
DA 2024-07-18
ER

PT J
AU Lishani, AO
   Boubchir, L
   Khalifa, E
   Bouridane, A
AF Lishani, Ait O.
   Boubchir, Larbi
   Khalifa, Emad
   Bouridane, Ahmed
TI Human gait recognition using GEI-based local multi-scale feature
   descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Gait recognition; Gait energy image; Multi-scale local
   binary pattern; Gabor filter bank; Spectra regression kernel
   discriminant analysis
ID DISCRIMINANT-ANALYSIS
AB Human gait recognition is a biometric technique for persons identification based on their walking manner. This paper proposes a novel gait recognition approach capable of selecting information characteristics for human identification under different conditions including normal walking, carrying a bag and wearing a clothing for different angles of view; thereby enhancing the recognition accomplishment. The proposed approach relies on two feature extraction methods based on multi-scale feature descriptors including Multi-scale Local Binary Pattern (MLBP) and Gabor filter bank, through Spectra Regression Kernel Discriminant Analysis (SRKDA) reduction algorithm. The proposed features are extracted locally from two Region of Interest (ROIs) representing the dynamic areas in the Gait Energy Image (GEI). The experiments conducted on CASIA and USF Gait databases have shown that the suggested methods achieve better recognition performances up to 92% in terms of identification rate at rank-1 than the existing similar and recent state-of-the-art methods.
C1 [Lishani, Ait O.; Khalifa, Emad; Bouridane, Ahmed] Northumbria Univ, Dept Comp & Informat Sci, Newcastle Upon Tyne NE2 1XE, Tyne & Wear, England.
   [Boubchir, Larbi] Univ Paris 08, LIASD Lab, Dept Comp Sci, 2 Rue Liberte, F-93526 St Denis, France.
C3 Northumbria University; Universite Paris-VIII
RP Boubchir, L (corresponding author), Univ Paris 08, LIASD Lab, Dept Comp Sci, 2 Rue Liberte, F-93526 St Denis, France.
EM larbi.boubchir@ai.univ-paris8.fr
RI Boubchir, Larbi/I-9623-2019
OI Boubchir, Larbi/0000-0002-5668-6801
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 1998, J COMPUT VIS RES
   [Anonymous], 2007, HDB BIOMETRICS HDB B
   Bashir K, 2009, GAIT REPRESENTATION
   Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027
   Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980
   BenAbdelkader C, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P372, DOI 10.1109/AFGR.2002.1004182
   Boulgouris NV, 2007, IEEE T IMAGE PROCESS, V16, P731, DOI 10.1109/TIP.2007.891157
   Boulgouris NV, 2005, IEEE SIGNAL PROC MAG, V22, P78, DOI 10.1109/MSP.2005.1550191
   Bounneche MD, 2016, NEUROCOMPUTING, V205, P274, DOI 10.1016/j.neucom.2016.05.005
   Cai D, 2007, IEEE DATA MINING, P427, DOI 10.1109/ICDM.2007.88
   Cai D, 2011, VLDB J, V20, P21, DOI 10.1007/s00778-010-0189-3
   Dupuis Y, 2013, IMAGE VISION COMPUT, V31, P580, DOI 10.1016/j.imavis.2013.04.001
   Guan Y, 2015, IEEE T PATTERN ANAL, V37, P1521, DOI 10.1109/TPAMI.2014.2366766
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hu MD, 2013, IEEE T CYBERNETICS, V43, P77, DOI 10.1109/TSMCB.2012.2199310
   Hu Ng, 2011, International Journal of New Computer Architectures and their Applications, V1, P358
   Isaac ERHP, 2017, IEEE SIGNAL PROC LET, V24, P1188, DOI 10.1109/LSP.2017.2715179
   Kumar JS, 2014, 2014 INTERNATIONAL CONFERENCE ON COMMUNICATION AND NETWORK TECHNOLOGIES (ICCNT), P1, DOI 10.1109/CNT.2014.7062712
   Kusakunniran Worapan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1058, DOI 10.1109/ICCVW.2009.5457587
   Kusakunniran W, 2010, PROC CVPR IEEE, P974, DOI 10.1109/CVPR.2010.5540113
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   Lancieri L, 2007, KNOWL-BASED SYST, V20, P266, DOI 10.1016/j.knosys.2006.05.018
   Lishani AO, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P789, DOI 10.1109/TSP.2017.8076096
   Lishani AO, 2017, SIGNAL IMAGE VIDEO P, V11, P1123, DOI 10.1007/s11760-017-1066-y
   Lishani AO, 2016, 2016 39TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P648, DOI 10.1109/TSP.2016.7760962
   Lishani AO, 2014, INT C MICROELECTRON, P36, DOI 10.1109/ICM.2014.7071800
   Little J, 1995, INT S COMP VIS
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Lu HP, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P249
   Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121
   NIYOGI SA, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P469, DOI 10.1109/CVPR.1994.323868
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Whytock T, 2014, J MATH IMAGING VIS, V50, P314, DOI 10.1007/s10851-014-0501-8
   Yam CY, 2004, PATTERN RECOGN, V37, P1057, DOI 10.1016/j.patcog.2003.09.012
   Yu Shiqi, 2006, P AS C COMP VIS, P708
   Zhang H, 2009, 2009 WASE INTERNATIONAL CONFERENCE ON INFORMATION ENGINEERING, ICIE 2009, VOL I, P83, DOI 10.1109/ICIE.2009.102
NR 42
TC 18
Z9 18
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5715
EP 5730
DI 10.1007/s11042-018-5752-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100035
DA 2024-07-18
ER

PT J
AU Wang, XJ
   Luo, GC
   Tian, L
AF Wang, Xinjian
   Luo, Guangchun
   Tian, Ling
TI Application of hyperspectral image anomaly detection algorithm for
   Internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral imagery (HSI); Anomaly detection; Segmented three-order
   Tucker decomposition; Internet of things(IOT)
ID CLASSIFICATION
AB Hyperspectral image(HSI) anomaly detection, as one of the hottest topics in current remote sensing information processing and image processing,has important theoretical value and has been widely used in military and civilian applications. Anomaly detection aims to detect and label small man-made abnormal targets or objects without any prior knowledge. In this paper, we proposed a segmented three-order Tucker decomposition for HSI anomaly detection. There are three major steps:1) the original HSI data is divided along the three dimensions into a grid of multiple of small-sized sub-tensors. 2)Tucker decomposition followed by anomaly detection algorithm is applied onto each sub-tensor. 3) the detection results from those sub-tensors are fused. Experiments reveal that the proposed method outperforms other current anomaly detectors with better detection performance. Finally, we introduce the application of hyperspectral image anomaly detection algorithm in the Internet of things(IOT).
C1 [Wang, Xinjian; Luo, Guangchun; Tian, Ling] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Wang, XJ (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Sichuan, Peoples R China.
EM wangxinjian_lw@163.com; gcluo@uestc.edu.cn; lingtian@uestc.edu.cn
CR Andersson CA, 1999, COMPUT STAT DATA AN, V31, P255, DOI 10.1016/S0167-9473(99)00017-1
   Bioucas-Dias JM, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2244672
   Carlotto MJ, 2005, IEEE T GEOSCI REMOTE, V43, P374, DOI 10.1109/TGRS.2004.841481
   Chang CI, 2002, IEEE T GEOSCI REMOTE, V40, P1314, DOI 10.1109/TGRS.2002.800280
   Chang CI, 2004, IEEE T GEOSCI REMOTE, V42, P608, DOI 10.1109/TGRS.2003.819189
   Chen SY, 2013, P SPIE DEF SEC SENS
   Du B, 2011, IEEE T GEOSCI REMOTE, V49, P1578, DOI 10.1109/TGRS.2010.2081677
   Fowler JE, 2012, IEEE T IMAGE PROCESS, V21, P184, DOI 10.1109/TIP.2011.2159730
   Govender M, 2007, WATER SA, V33, P145
   Gupta Ankit, 2015, IJCST, V3, P5
   Hsueh M, 2004, INT GEOSCI REMOTE SE, P3222
   Jia X, 1996, THESIS
   JIA XP, 1994, IEEE T GEOSCI REMOTE, V32, P274, DOI 10.1109/36.295042
   Kerekes J, 2008, IEEE GEOSCI REMOTE S, V5, P251, DOI 10.1109/LGRS.2008.915928
   Khazai S, 2011, IEEE GEOSCI REMOTE S, V8, P646, DOI 10.1109/LGRS.2010.2098842
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Lathauwer L.D., 1997, SIGNAL PROCESSING BA
   Li JY, 2015, IEEE J-STARS, V8, P2523, DOI 10.1109/JSTARS.2015.2437073
   Li W, 2015, IEEE T GEOSCI REMOTE, V53, P1463, DOI 10.1109/TGRS.2014.2343955
   Matteoli S., 2009, HYPERSPECTRAL IMAGE, P1
   Matteoli S, 2013, IEEE T GEOSCI REMOTE, V51, P2837, DOI 10.1109/TGRS.2012.2214392
   Matteoli S, 2010, IEEE AERO EL SYS MAG, V25, P5, DOI 10.1109/MAES.2010.5546306
   Plaza A, 2009, REMOTE SENS ENVIRON, V113, pS110, DOI 10.1016/j.rse.2007.07.028
   REED IS, 1990, IEEE T ACOUST SPEECH, V38, P1760, DOI 10.1109/29.60107
   Schaum A, 2009, P 2009 WORKSH AIPR I
   Schweizer SM, 2000, IEEE T INFORM THEORY, V46, P1855, DOI 10.1109/18.857796
   Stefanou MS, 2009, IEEE T GEOSCI REMOTE, V47, P1698, DOI 10.1109/TGRS.2008.2006364
   Stein DWJ, 2002, IEEE SIGNAL PROC MAG, V19, P58, DOI 10.1109/79.974730
   Zhang X, 2016, IEEE T GEOSCI REMOTE, V54, P5801, DOI 10.1109/TGRS.2016.2572400
   Zhao R, 2014, IEEE J-STARS, V7, P1227, DOI 10.1109/JSTARS.2014.2311995
NR 30
TC 6
Z9 6
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5155
EP 5167
DI 10.1007/s11042-017-4682-1
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100004
DA 2024-07-18
ER

PT J
AU Yoon, HS
   Hong, HG
   Lee, DE
   Park, KR
AF Yoon, Hyo Sik
   Hong, Hyung Gil
   Lee, Dong Eun
   Park, Kang Ryoung
TI Driver's eye-based gaze tracking system by one-point calibration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Driver's gaze detection; NIR camera and NIR illuminator; Pupil; corneal
   specular reflection and medial canthus; Initial calibration of driver;
   Maximum entropy criterion
ID VISUAL-ATTENTION; PERFORMANCE; MOTION; EEG
AB The accuracies of driver's gaze detection by previous researches are affected by the various sitting positions and heights of drivers in case that initial calibration of driver is not performed. By using dual cameras, the driver's calibration can be omitted, but processing time with complexity is increased. In addition, the problem of disappearing corneal specular reflection (SR) in the eye image as the driver severely turns his/her head has not been dealt in previous researches. To consider these issues, we propose a gaze tracking method based on driver's one-point calibration using both corneal SR and medial canthus (MC) based on maximum entropy criterion. An experiment with collected data from 26 subjects (wearing nothing, glasses, sunglasses, hat, or taking various hand pose) in a vehicle, showed that the accuracy of the proposed method is higher than that of other gaze tracking methods. In addition, we showed the effectiveness of our method in the real driving environment.
C1 [Yoon, Hyo Sik; Hong, Hyung Gil; Lee, Dong Eun; Park, Kang Ryoung] Dongguk Univ, Div Elect & Elect Engn, 30 Pil Dong Ro,1 Gil, Seoul 100715, South Korea.
C3 Dongguk University
RP Park, KR (corresponding author), Dongguk Univ, Div Elect & Elect Engn, 30 Pil Dong Ro,1 Gil, Seoul 100715, South Korea.
EM yoonhs@dongguk.edu; hell@dongguk.edu; leede@dongguk.edu;
   parkgr@dongguk.edu
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2017R1D1A1B03028417,
   NRF-2018R1D1A1B07041921]; National Research Foundation of Korea (NRF) -
   Korea government (Ministry of Science and ICT) [NRF-2017R1C1B5074062]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (NRF-2018R1D1A1B07041921), by the Basic Science
   Research Program through the National Research Foundation of Korea (NRF)
   funded by the Ministry of Education (NRF-2017R1D1A1B03028417), and by
   the National Research Foundation of Korea (NRF) grant funded by the
   Korea government (Ministry of Science and ICT) (NRF-2017R1C1B5074062).
CR ABTAHI S., 2011, Instrumentation and Measurement Technology Conference (I2MTC), 2011 IEEE 2011, P1
   Ahlstrom C, 2013, IEEE T INTELL TRANSP, V14, P965, DOI 10.1109/TITS.2013.2247759
   Batista JP, 2005, LECT NOTES COMPUT SC, V3522, P200
   BERGEN JR, 1992, LECT NOTES COMPUT SC, V588, P237
   Cai W, 2016, CHIN CONT DECIS CONF, P2126, DOI 10.1109/CCDC.2016.7531336
   Cheng HD, 1998, PATTERN RECOGN, V31, P857, DOI 10.1016/S0031-3203(97)00113-1
   Cho CW, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.5.053111
   Cho DC, 2013, IEEE T BIO-MED ENG, V60, P3432, DOI 10.1109/TBME.2013.2266413
   Choi IH, 2016, INT CONF BIG DATA, P143, DOI 10.1109/BIGCOMP.2016.7425813
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dong YC, 2011, IEEE T INTELL TRANSP, V12, P596, DOI 10.1109/TITS.2010.2092770
   Durna Y, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7050498
   Franchak JM, 2011, CHILD DEV, V82, P1738, DOI 10.1111/j.1467-8624.2011.01670.x
   Fridman L, 2016, IET COMPUT VIS, V10, P308, DOI 10.1049/iet-cvi.2015.0296
   Fu XP, 2013, IEEE T INTELL TRANSP, V14, P303, DOI 10.1109/TITS.2012.2217377
   Funke G., 2016, P HUM FACTORS ERGONO, V60, P1240, DOI DOI 10.1177/1541931213601289
   García I, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P618, DOI 10.1109/IVS.2012.6232222
   Ghosh S, 2015, LECT N BIOENG, P13, DOI 10.1007/978-81-322-2256-9_2
   Gonzalez RC., 2010, DIGITAL IMAGE PROCES
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Itkonen T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0135505
   Jang JW, 2018, MULTIMED TOOLS APPL, V77, P11925, DOI 10.1007/s11042-017-4842-3
   Jung D, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010110
   Kar A, 2017, IEEE ACCESS, V5, P16495, DOI 10.1109/ACCESS.2017.2735633
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Khushaba RN, 2011, IEEE T BIO-MED ENG, V58, P121, DOI 10.1109/TBME.2010.2077291
   Koblova EV, 2005, P SOC PHOTO-OPT INS, V5688, P302, DOI 10.1117/12.593651
   Lee BG, 2014, SENSORS-BASEL, V14, P17915, DOI 10.3390/s141017915
   Lee JW, 2013, SENSORS-BASEL, V13, P10802, DOI 10.3390/s130810802
   Lee SJ, 2011, IEEE T INTELL TRANSP, V12, P254, DOI 10.1109/TITS.2010.2091503
   Li G, 2015, SENSORS-BASEL, V15, P20873, DOI 10.3390/s150820873
   Li YT, 2018, IET COMMUN, V12, P751, DOI 10.1049/iet-com.2017.0502
   Li YT, 2016, MULTIMED TOOLS APPL, V75, P16959, DOI 10.1007/s11042-015-2969-7
   Li YS, 2017, INT J COMMUN SYST, V30, DOI 10.1002/dac.3181
   Li ZJ, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030495
   Liang YL, 2007, IEEE T INTELL TRANSP, V8, P340, DOI 10.1109/TITS.2007.895298
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Noris B, 2011, COMPUT VIS IMAGE UND, V115, P476, DOI 10.1016/j.cviu.2010.11.013
   Rantanen V, 2011, IEEE T INF TECHNOL B, V15, P795, DOI 10.1109/TITB.2011.2158321
   Ren YL, 2015, EVID-BASED COMPL ALT, V2015, DOI 10.1155/2015/684708
   Ren Y, 2014, SCI WORLD J, DOI 10.1155/2014/685362
   Sahayadhas A, 2012, SENSORS-BASEL, V12, P16937, DOI 10.3390/s121216937
   Shih SW, 2004, IEEE T SYST MAN CY B, V34, P234, DOI 10.1109/TSMCB.2003.811128
   Smith P, 2003, IEEE T INTELL TRANSP, V4, P205, DOI 10.1109/TITS.2003.821342
   Smith P, 2000, INT C PATT RECOG, P636, DOI 10.1109/ICPR.2000.902999
   Sturm RA, 2004, TRENDS GENET, V20, P327, DOI 10.1016/j.tig.2004.06.010
   Tawari A, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P988, DOI 10.1109/ITSC.2014.6957817
   Tawari A, 2014, IEEE INT VEH SYM, P344, DOI 10.1109/IVS.2014.6856607
   Tsukada A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2084, DOI 10.1109/ICCVW.2011.6130505
   van Leeuwen PM, 2015, PROCEDIA MANUF, V3, P3325, DOI 10.1016/j.promfg.2015.07.422
   Vicente F, 2015, IEEE T INTELL TRANSP, V16, P2014, DOI 10.1109/TITS.2015.2396031
   Vora S, 2017, IEEE INT VEH SYM, P849, DOI 10.1109/IVS.2017.7995822
   Wang J, 2016, SCI REP-UK, V6, DOI 10.1038/srep20728
   Yoo DH, 2005, COMPUT VIS IMAGE UND, V98, P25, DOI 10.1016/j.cviu.2004.07.011
NR 56
TC 8
Z9 9
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7155
EP 7179
DI 10.1007/s11042-018-6490-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700034
DA 2024-07-18
ER

PT J
AU Chauhan, DS
   Singh, AK
   Kumar, B
   Saini, JP
AF Chauhan, Digvijay Singh
   Singh, Amit Kumar
   Kumar, Basant
   Saini, J. P.
TI Quantization based multiple medical information watermarking for secure
   e-health
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image; Electronic patient record; Discrete wavelet transform;
   Non-region of interest; BCH and Turbo Error correction codes; Bit error
   rates
AB In this paper, an improved wavelet based medical image watermarking algorithm is proposed. Initially, the proposed technique decomposes the cover medical image into ROI and NROI regions and embedding three different watermarks into the non-region of interest (NROI) part of the transformed DWT cover image for compact and secure medical data transmission in E-health environment. In addition, the method addressing the problem of channel noise distortion may lead to faulty watermark by applying error correcting codes (ECCs) before embedding them into the cover image. Further, the bit error rates (BER) performance of the proposed method is determined for different kind of attacks including Checkmark' attacks. Experimental results indicate that the Turbo code performs better than BCH (Bose-Chaudhuri-Hochquenghem) error correction code. Furthermore, the experimental results validate the effectiveness of the proposed framework in terms of BER and embedding capacity compared to other state-of-the-art methods. Therefore, the proposed method finds potential application in prevention of patient identity theft in e-health applications.
C1 [Chauhan, Digvijay Singh] Feroze Gandhi Inst Engn & Technol, Dept Elect & Commun Engn, Raebareli, Uttar Pradesh, India.
   [Singh, Amit Kumar] Jaypee Univ Informat Technol Waknaghat, Dept Comp Sci & Engn, Solan, Himachal Prades, India.
   [Kumar, Basant] Motilal Nehru Natl Inst Technol, Dept Elect & Commun Engn, Allahabad, Uttar Pradesh, India.
   [Saini, J. P.] Bundelkhand Inst Engn & Technol, Dept Elect Engn, Jhansi, Uttar Pradesh, India.
C3 Jaypee University of Information Technology; National Institute of
   Technology (NIT System); Motilal Nehru National Institute of Technology;
   Bundelkhand Institute of Engineering & Technology
RP Singh, AK (corresponding author), Jaypee Univ Informat Technol Waknaghat, Dept Comp Sci & Engn, Solan, Himachal Prades, India.
EM digvijay.02@gmail.com; amit_245singh@yahoo.com; singhbasant@yahoo.com;
   jps_uptu@rediffmail.com
RI Singh, Amit Kumar/D-1300-2015
OI Singh, Amit Kumar/0000-0001-7359-2068
CR Al-Qershi O. M., 2010, 2010 IEEE International Conference on Information Theory and Information Security, P151, DOI 10.1109/ICITIS.2010.5688743
   Alwan MH, 2015, IEEE ST CONF RES DEV, P556, DOI 10.1109/SCORED.2015.7449398
   [Anonymous], 2010, INT J COMPUT SCI INF
   [Anonymous], 2000, Digital Watermarking
   Eswaraiah R, 2015, IET IMAGE PROCESS, V9, P615, DOI 10.1049/iet-ipr.2014.0986
   Giakoumaki A, 2006, MED BIOL ENG COMPUT, V44, P619, DOI 10.1007/s11517-006-0081-x
   Giakoumaki A, 2006, P 28 IEEE EMBS ANN I
   Hajjaji MA, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/313078
   Kumar B, 2014, 37 INT C TEL SIGN PR, P660
   Kundur D, 1999, P IEEE, V87, P1167, DOI 10.1109/5.771070
   Masek J, 2013, 2013 36TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P586, DOI 10.1109/TSP.2013.6614002
   Mohanty SP, 2000, WATERMARKING DIGITAL
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Pandey R, 2016, MULTIMED TOOLS APPL, V75, P14381, DOI 10.1007/s11042-016-3536-6
   Pavelin A, 2006, REMOTE CARDIOLOGY CO, V372, P79
   Rocek A, 2016, BIOMED SIGNAL PROCES, V29, P44, DOI 10.1016/j.bspc.2016.05.005
   Sajjad M, 2017, MULTIMED TOOLS APPL, V76, P3519, DOI 10.1007/s11042-016-3811-6
   Singh AK, 2016, DIGITAL IMAGE WATERM, P246
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2015, WIRELESS PERS COMMUN, V83, P2133, DOI 10.1007/s11277-015-2505-0
   Singh AK, 2015, P NATL A SCI INDIA A, V85, P295, DOI 10.1007/s40010-014-0197-6
   Singh AK, 2014, P NATL A SCI INDIA A, V84, P345, DOI 10.1007/s40010-014-0140-x
   Terzija N, 2002, P INT ASS SCI TECHN, P1
NR 24
TC 37
Z9 38
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 3911
EP 3923
DI 10.1007/s11042-017-4886-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200004
DA 2024-07-18
ER

PT J
AU Liang, W
AF Liang, Wei
TI RETRACTED: Scene art design based on human-computer interaction and
   multimedia information system: an interactive perspective (Retracted
   article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE VRML; Virtual environment; Assistant; Computer teaching; System;
   Construction
AB With the concept of the information superhighway being proposed, the educational model with the aid of information technology has developed rapidly. This paper uses constructivist learning theory to construct a new teaching model, including innovative teaching content and methods of change. Realizing the development of educational informatization and meeting the challenges brought by the information society to education has become an inevitable trend of today's education. The development and innovation of emerging technologies has become the main references in the field of teaching to help learners set up effective self-learning methods and develop the ability to continuously update knowledge. As a second-generation Web language, this article introduces VRML as a methodology. Combined with the characteristics of actual cases, this paper analyzes the application of VRML in virtual teaching environment and gives a concrete implementation method. In view of the application of virtual reality modeling language (VRML) in online teaching, this paper summarizes and analyzes the functions, basic features and development direction of VRML. This paper explores the basic theory of CAI and the principles of network teaching. We divide the online teaching mode based on VRML into two application methods and propose a network teaching mode based on VRML.
C1 [Liang, Wei] Ningbo Dahongying Univ, Coll Arts & Media, Ningbo 315175, Zhejiang, Peoples R China.
C3 Ningbo University of Finance & Economics
RP Liang, W (corresponding author), Ningbo Dahongying Univ, Coll Arts & Media, Ningbo 315175, Zhejiang, Peoples R China.
EM liangwei@dr.com
CR Akbarov SD, 2012, CMC-COMPUT MATER CON, V30, P1
   [Anonymous], J ADV RES DYNAMICAL
   [Anonymous], INT J TRANSPORTATION
   Atalay HA, 2017, INT BRAZ J UROL, V43, P470, DOI [10.1590/S1677-5538.IBJU.2016.0441, 10.1590/s1677-5538.ibju.2016.0441]
   Brusilovsky P, 2017, NEW REV HYPERMEDIA M, V23, P81, DOI 10.1080/13614568.2016.1179796
   Claesson A, 2017, JAMA-J AM MED ASSOC, V317, P2332, DOI 10.1001/jama.2017.3957
   Datta D, 2017, EXPERT SYST APPL, V68, P81, DOI 10.1016/j.eswa.2016.09.039
   Francalanci C, 2017, IEEE C RES CHALLENGE, P1
   Li T, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3017678
   Li X, 2017, MULTIMED TOOLS APPL, V76, P17801, DOI 10.1007/s11042-015-3095-2
   Li YB, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3923
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Pankow M, 2012, CMC-COMPUT MATER CON, V32, P81
   Park N, 2018, PERS UBIQUIT COMPUT, V22, P3, DOI 10.1007/s00779-017-1017-1
   Rossetto L, 2017, LECT NOTES COMPUT SC, V10133, P469, DOI 10.1007/978-3-319-51814-5_43
   Song Y, 2017, MULTIMED TOOLS APPL, V76, P10083, DOI 10.1007/s11042-016-3599-4
   Tang ZJ, 2018, CMC-COMPUT MATER CON, V55, P331, DOI 10.3970/cmc.2018.02222
   Varatharajan R, 2018, MULTIMED TOOLS APPL, V77, P10195, DOI 10.1007/s11042-017-5318-1
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Yin CY, 2017, NEUROCOMPUTING, V256, P49, DOI 10.1016/j.neucom.2016.07.079
   Zhu J, 2017, NEUROCOMPUTING, V220, P76, DOI 10.1016/j.neucom.2016.03.104
NR 21
TC 25
Z9 25
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4767
EP 4785
DI 10.1007/s11042-018-7070-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200043
DA 2024-07-18
ER

PT J
AU Pan, TY
   Dai, YZ
   Hu, MC
   Cheng, WH
AF Pan, Tse-Yu
   Dai, Yi-Zhu
   Hu, Min-Chun
   Cheng, Wen-Huang
TI Furniture style compatibility recommendation with cross-class triplet
   loss
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Style compatibility; Deep metric learning; Triplet convolutional neural
   network; 3D furniture model recommendation
AB Harmonizing the style of all the furniture placed within a constrained space/scene is an important principle for interior design. In this paper, we propose a furniture style compatibility recommendation approach for users to create a harmonic 3D virtual scene based on 2D furniture photos. Most previous works of 3D model style analysis measure the style similarity or compatibility based on predefined geometric features extracted from 3D models. However, style is a high-level semantic concept, which is difficult to be described explicitly by hand-crafted geometric features. Moreover, analyzing the style compatibility between two or more furniture belonging to different classes (e.g., table and lamp) is much more challenging since the given furniture may have very distinctive structures or geometric elements. Recently, deep neural network has been claimed to have more powerful ability to mimic the perception of human visual cortex, and therefore we propose to analyze style compatibility between 3D furniture models of different classes based on a Cross-Class Triplet Convolutional Neural Network (CNN). We conducted experiments based on a collected dataset containing 420 textured 3D furniture models. A group of raters were recruited from Amazon Mechanical Turk (AMT) to evaluate the comparative suitability of paired models within the dataset. The experimental results reveal that the proposed furniture style compatibility method based on deep learning performs better than the state-of-the-art method and can be used to efficiently generate harmonic virtual scenes.
C1 [Pan, Tse-Yu; Dai, Yi-Zhu; Hu, Min-Chun] Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 701, Taiwan.
   [Cheng, Wen-Huang] Acad Sinica, Res Ctr Informat Technol Innovat CITI, Taipei 115, Taiwan.
C3 National Cheng Kung University; Academia Sinica - Taiwan
RP Hu, MC (corresponding author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 701, Taiwan.
EM felix@mislab.csie.ncku.edu.tw; p268846@mislab.csie.ncku.edu.tw;
   anita_hu@mail.ncku.edu.tw; whcheng@citi.sinica.ncku.edu.tw
RI Hu, Min-Chun/AAX-1721-2020; Cheng, Wen-Huang/AAK-2774-2020
OI Hu, Min-Chun/0000-0003-1917-2155; 
CR [Anonymous], 2016, arXiv
   [Anonymous], P 42 GRAPH INT C CAN
   Bansal A, 2016, PROC CVPR IEEE, P5965, DOI 10.1109/CVPR.2016.642
   Bell S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766959
   Chang Yao-Wen., 2015, Proceedings of the 52nd Annual Design Automation Conference, P1
   Chen X, 2015, P ACM MULT C
   Cheng ZY, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1267, DOI 10.1145/2600428.2611187
   Edwards R, 2013, WHAT IS QALITATIVE I
   Fisher M, 2016, ACM T GRAPHIC, V31, P135
   Fukano K, 2016, P IEEE INT C PATT RE
   Funkhouser T.A., 2015, P COMP VIS PATT REC
   Garces Elena, 2014, ACM Transactions on Graphics, V33, DOI 10.1145/2601097.2601131
   Garces E, 2017, MULTIMED TOOLS APPL, V76, P13067, DOI 10.1007/s11042-016-3702-x
   Guo HY, 2016, IEEE T IMAGE PROCESS, V25, P5526, DOI 10.1109/TIP.2016.2609814
   Guo R., 2015, ARXIV150402437
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Hu M-C, 2017, Google Patents US Patent, Patent No. 9547943
   Huang FC, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766922
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508373
   Izadinia H, 2017, P IEEE INT C PATT RE
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kulis B, 2013, FOUND TRENDS MACH LE, V5, P287, DOI 10.1561/2200000019
   López GL, 2017, MULTIMED TOOLS APPL, V76, P6993, DOI 10.1007/s11042-016-3330-5
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461
   Lim I, 2016, COMPUT GRAPH FORUM, V35, P207, DOI 10.1111/cgf.12977
   Liu TQ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766898
   Lun ZL, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766929
   Luo Y, 2014, IEEE T IMAGE PROCESS, V23, P3789, DOI 10.1109/TIP.2014.2332398
   Mallya A., 2015, P IEEE INT C COMP VI
   Mei T, 2011, ACM T INFORM SYST, V29, DOI 10.1145/1961209.1961213
   O'Donovan P, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601110
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saleh B., 2015, Proceedings of the 41st Graphics Interface Conference, P59
   Wang Y, 2013, 2013 INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL AND BUSINESS INTELLIGENCE (ISCBI), P213, DOI 10.1109/ISCBI.2013.50
   Wilber MJ, 2014, 3 AAAI C HUM COMP CR
   Xie J, 2017, IEEE T PATTERN ANAL, V39, P1335, DOI 10.1109/TPAMI.2016.2596722
   Xu K, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866206
   Yu LF, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964981
   Yumer ME, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766908
   Zhang Y, 2015, P EUR C COMP VIS
   Zhu J, 2017, IEEE T WIREL COMMUN, V16, P2001, DOI 10.1109/TWC.2017.2659724
NR 43
TC 7
Z9 7
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 2645
EP 2665
DI 10.1007/s11042-018-5747-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600002
DA 2024-07-18
ER

PT J
AU Guzman-Zavaleta, ZJ
   Feregrino-Uribe, C
AF Jezabel Guzman-Zavaleta, Z.
   Feregrino-Uribe, Claudia
TI Partial-copy detection of non-simulated videos using learning at
   decision level
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video copy detection; Partial-copies; Non-simulated attacks; Passive
   fingerprint; Q-learning
AB There is a renewed tendency to improve video copy detection tasks due to the involved challenges in non-simulated applications. In an adverse real-world scenario, the volume of data to process as well as the variety of transformations to which a video is exposed increases continuously. Moreover, the interest in detecting not only long videos but also short partial copies increments the difficulties in copy detection methods. Therefore, we propose a practical copy detection method able to cope with partial-copies and useful in applications where real-time processing is required. To accomplish the desirable characteristics of high precision, fast processing and scalability, we use low-cost global descriptors in combination with a decision strategy adapted from a reinforcement learning technique. Our evaluation results are satisfactory to detect short segments of at least 2-seconds length under a non-simulated and severely transformed video dataset.
C1 [Jezabel Guzman-Zavaleta, Z.] Univ Iberoamer, Sci & Engn Dept, Puebla, Mexico.
   [Feregrino-Uribe, Claudia] INAOE, Comp Sci Dept, Puebla, Mexico.
C3 Instituto Nacional de Astrofisica, Optica y Electronica
RP Guzman-Zavaleta, ZJ (corresponding author), Univ Iberoamer, Sci & Engn Dept, Puebla, Mexico.
EM zobeida.guzman@iberopuebla.mx; cferegrino@inaoep.mx
RI Guzmán, Zobeida/HLP-7684-2023; Feregrino, Claudia/AAW-2607-2021;
   Guzman-Zavaleta, Zobeida Jezabel/X-4945-2019; Guzman Zavaleta, Zobeida
   Jezabel/D-9855-2019
OI Guzman Zavaleta, Zobeida Jezabel/0000-0002-3163-8862
CR [Anonymous], 2014, CoRR
   [Anonymous], 2016, J. Signal Inf. Process, DOI [10.4236/jsip.2016.72010, DOI 10.4236/JSIP.2016.72010]
   [Anonymous], 2015, ARXIV150708286
   [Anonymous], 1998, REINFORCEMENT LEARNI
   Awad G, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2629531
   Balntas V., 2016, ARXIV160105030
   Baraldi L, 2018, P IEEE CVF INT C COM
   Batista da Silva H, 2016, P 31 ANN ACM S APPL, P80, DOI [10. 1145/2851613. 2851876, DOI 10.1145/2851613.2851876]
   Cutting JE, 2011, I-PERCEPTION, V2, P569, DOI 10.1068/i0441aap
   Cutting JE, 2010, PSYCHOL SCI, V21, P432, DOI 10.1177/0956797610361679
   Douze M, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646421
   Esen E, 2016, ARXIV16070
   Esmaeili MM, 2011, IEEE T INF FOREN SEC, V6, P213, DOI 10.1109/TIFS.2010.2097593
   Himeur Y, 2018, MULTIMED TOOLS APPL, V77, P17309, DOI 10.1007/s11042-017-5307-4
   Guzman-Zavaleta ZJ, 2017, MULTIMED TOOLS APPL, V76, P24143, DOI 10.1007/s11042-016-4168-6
   Guzman-Zavaleta ZJ, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0166047
   Jiang YG, 2014, LECT NOTES COMPUT SC, V8692, P357, DOI 10.1007/978-3-319-10593-2_24
   Kalker T, 2001, PROC SPIE, V4518, P189, DOI 10.1117/12.448203
   Kim S, 2014, SIGNAL PROCESS-IMAGE, V29, P788, DOI 10.1016/j.image.2014.05.002
   Law-To J., 2007, Muscle-VCD-2007: a live benchmark for video copy detection
   Lian SG, 2010, STUD COMPUT INTELL, V282, P253
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Mobahi H., 2009, Proceedings of the 26th Annual International Conference on Machine Learning, P737
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Ragho SR, 2015, INT J SCI REIJSR, V4, P1775
   Robertson DJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0119460
   Rossion B, 2012, BRAIN COGNITION, V79, P138, DOI 10.1016/j.bandc.2012.01.001
   Sandeep R, 2016, MULTIMED TOOLS APPL, V75, P7779, DOI 10.1007/s11042-015-2695-1
   Shinde S, 2015, 6TH INTERNATIONAL CONFERENCE ON COMPUTER & COMMUNICATION TECHNOLOGY (ICCCT-2015), P15, DOI 10.1145/2818567.2818570
   Sun J, 2013, ADV MULTIMEDIA MODEL, P546, DOI [DOI 10.1007/978-3-642-35725-1_, 10.1007/978-3-642-35725-1_50]
   Sun JD, 2016, NEUROCOMPUTING, V213, P84, DOI 10.1016/j.neucom.2016.05.098
   Tsivian Yuri, 2005, CINEMETRICS
   Wang L, 2017, LECT NOTES COMPUT SC, V10132, P576, DOI 10.1007/978-3-319-51811-4_47
   Watkins C. J. C. H., 1989, Learning from Delayed Rewards
   Wu X, 2007, CC WEB VIDEO NEAR DU
   Yu D, 2011, IEEE SIGNAL PROC MAG, V28, P145, DOI 10.1109/MSP.2010.939038
   Yu-Gang Jiang, 2016, IEEE Transactions on Big Data, V2, P32, DOI 10.1109/TBDATA.2016.2530714
   Zhang Y, 2016, INT C PATT RECOG, P3951, DOI 10.1109/ICPR.2016.7900252
   Zhu YY, 2016, NEUROCOMPUTING, V187, P83, DOI 10.1016/j.neucom.2015.09.114
NR 41
TC 8
Z9 8
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2427
EP 2446
DI 10.1007/s11042-018-6345-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700050
DA 2024-07-18
ER

PT J
AU Jiang, ZQ
   Shen, XJ
   Gou, JP
   Wang, LJ
   Zha, ZJ
AF Jiang, Zhong-Qiu
   Shen, Xiang-Jun
   Gou, Jian-Ping
   Wang, Liangjun
   Zha, Zheng-Jun
TI Dynamically building diversified classifier pruning ensembles via
   canonical correlation analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ensemble learning; Classifier ensemble; Classifier combination;
   Classifier fusion
ID SPARSE REPRESENTATION; RANDOM SUBSPACE; SELECTION; NETWORKS
AB Empirical studies on ensemble learning that combines multiple classifiers have shown that, it is an effective technique to improve accuracy and stability of a single classifier. In this paper, we propose a novel method of dynamically building diversified sparse ensembles. We first apply a technique known as the canonical correlation to model the relationship between the input data variables and output base classifiers. The canonical (projected) output classifiers and input training data variables are encoded globally through a multi-linear projection of CCA, to decrease the impacts of noisy input data and incorrect classifiers to a minimum degree in such a global view. Secondly, based on the projection, a sparse regression method is used to prune representative classifiers by combining classifier diversity measurement. Based on the above methods, we evaluate the proposed approach by several datasets, such as UCI and handwritten digit recognition. Experimental results of the study show that, the proposed approach achieves better accuracy as compared to other ensemble methods such as QFWEC, Simple Vote Rule, Random Forest, Drep and Adaboost.
C1 [Jiang, Zhong-Qiu; Shen, Xiang-Jun; Gou, Jian-Ping; Wang, Liangjun] Jiangsu Univ, Sch Comp Sci & Telecommun Engn, Zhenjiang, Peoples R China.
   [Zha, Zheng-Jun] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei, Anhui, Peoples R China.
C3 Jiangsu University; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS
RP Shen, XJ (corresponding author), Jiangsu Univ, Sch Comp Sci & Telecommun Engn, Zhenjiang, Peoples R China.
EM xjshen@ujs.edu.cn
RI Zha, Zheng-Jun/AAF-8667-2020; Zha, Zheng-Jun/AAE-8408-2020; Gou,
   Jianping/JQX-2453-2023; fang, yu/KCK-2014-2024; guo, ppdop/KAL-9865-2024
OI Zha, Zheng-Jun/0000-0003-2510-8993; Gou, Jianping/0000-0003-1413-0693; 
FU National Natural Science Foundation of China [61572240,
   61601202,61502208]; Open Project Program of the National Laboratory of
   Pattern Recognition(NLPR) [201600005]; Natural Science Foundation of
   Jiangsu Province [BK20140571]
FX This work was funded in part by the National Natural Science Foundation
   of China(No.61572240, 61601202,61502208), the Open Project Program of
   the National Laboratory of Pattern Recognition(NLPR)(No.201600005),
   Natural Science Foundation of Jiangsu Province (Grant No. BK20140571).
CR [Anonymous], LEARNING DIVERSIFY V
   Bao BK, 2013, IEEE T IMAGE PROCESS, V22, P860, DOI 10.1109/TIP.2012.2219543
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Britto AS, 2014, PATTERN RECOGN, V47, P3665, DOI 10.1016/j.patcog.2014.05.003
   Chen HH, 2009, IEEE T KNOWL DATA EN, V21, P999, DOI 10.1109/TKDE.2009.62
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Franc V, 2002, INT C PATT RECOG, P236, DOI 10.1109/ICPR.2002.1048282
   Freund Y., 1996, INT C MACHINE LEARNI, P148
   Fumera G, 2005, IEEE T PATTERN ANAL, V27, P942, DOI 10.1109/TPAMI.2005.109
   Gao X, 2017, MULTIPLE RANK SUPERV
   Ghorai S, 2011, IEEE ACM T COMPUT BI, V8, P659, DOI 10.1109/TCBB.2010.36
   Giacinto G, 2001, IMAGE VISION COMPUT, V19, P699, DOI 10.1016/S0262-8856(01)00045-2
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Ko AHR, 2008, PATTERN RECOGN, V41, P1718, DOI 10.1016/j.patcog.2007.10.015
   Krogh A., 1995, Advances in Neural Information Processing Systems 7, P231
   Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006
   Kuncheva LI, 2004, COMBINING PATTERN CL, DOI DOI 10.1002/0471660264
   Kuncheva LI, 2007, IEEE T KNOWL DATA EN, V19, P500, DOI 10.1109/TKDE.2007.1016
   Kuncheva LI, 2014, KNOWL INF SYST, V38, P259, DOI 10.1007/s10115-012-0586-6
   Kuncheva LI, 2013, IEEE T KNOWL DATA EN, V25, P494, DOI 10.1109/TKDE.2011.234
   Liu JJ, 2016, NEUROCOMPUTING, V195, P112, DOI 10.1016/j.neucom.2015.09.119
   Liu L, 2013, PATTERN RECOGN, V46, P1810, DOI 10.1016/j.patcog.2012.10.004
   Liu WF, 2016, IEEE T IND ELECTRON, V63, P5120, DOI 10.1109/TIE.2016.2552147
   Mao SS, 2015, PATTERN RECOGN, V48, P1688, DOI 10.1016/j.patcog.2014.10.017
   Martínez-Muñoz G, 2009, IEEE T PATTERN ANAL, V31, P245, DOI 10.1109/TPAMI.2008.78
   Nan Li, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P330, DOI 10.1007/978-3-642-33460-3_27
   Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002
   Quan YH, 2016, PATTERN RECOGN, V55, P247, DOI 10.1016/j.patcog.2016.01.028
   Saitta L, 2006, LECT NOTES ARTIF INT, V4203, P662
   Sim J, 2005, PHYS THER, V85, P257
   Skalak D. B., 1996, P AM ASS ARTI INTELL, V1129, P1133
   Tang S, 2015, NEUROCOMPUTING, V169, P124, DOI 10.1016/j.neucom.2014.09.100
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Ueda N, 2000, IEEE T PATTERN ANAL, V22, P207, DOI 10.1109/34.825759
   Via Javier, 2005, 2005 13th European Signal Processing Conference, P1
   Wahlberg B., 2012, IFAC P, V45, P83
   Wang XZ, 2015, IEEE T FUZZY SYST, V23, P1638, DOI 10.1109/TFUZZ.2014.2371479
   Woloszynski T, 2011, PATTERN RECOGN, V44, P2656, DOI 10.1016/j.patcog.2011.03.020
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Yang XH, 2017, INFORM SCIENCES, V385, P338, DOI 10.1016/j.ins.2017.01.011
   Yin XC, 2015, NEUROCOMPUTING, V165, P14, DOI 10.1016/j.neucom.2014.06.092
   Zhang EL, 2016, PATTERN RECOGN, V59, P42, DOI 10.1016/j.patcog.2016.01.033
   Zhang L, 2011, PATTERN RECOGN, V44, P97, DOI 10.1016/j.patcog.2010.07.021
   Zhang L, 2010, NEURAL NETWORKS, V23, P373, DOI 10.1016/j.neunet.2009.11.012
   Zhang Y, 2006, J MACH LEARN RES, V7, P1315
   Zhao ZQ, 2016, IEEE T GEOSCI REMOTE, V54, P3532, DOI 10.1109/TGRS.2016.2519910
   Zhou Z.-H., 2001, P 17 INT JOINT C ART, V2, P797, DOI 10.1109/ICNC.2007.399
NR 48
TC 0
Z9 0
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 271
EP 288
DI 10.1007/s11042-018-5718-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500015
DA 2024-07-18
ER

PT J
AU Kravvaris, D
   Kermanidis, KL
AF Kravvaris, Dimitrios
   Kermanidis, Katia Lida
TI Automatic point of interest detection for open online educational video
   lectures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video lecture; Users' comments; Maximum likelihood; Latent Dirichlet
   allocation; Points of interest
AB The rise of massive open online courses had as a result an increase in the number of open online educational video lectures on the web, as well as in the number of users who watch them. The present work aims to optimize the searching time within an educational video lecture based on the users' opinion. The research presents a novel procedure for the automatic point of interest detection in an educational video lecture. State of the art algorithms are used to extract terminology from the users' comments and video lectures topics from relevant video transcripts. The topics of each video lecture are assessed based on the terminology resulting from the users' relevant comments. The topic with the best score (adding the keyness value of common topic-related words and terminology words) is selected as the most relevant to the video lecture. Then videos' timestamps that include the selected topic's words are presented to users as the points of interest of the video lecture. Finally, a user evaluation experiment is carried out, the results of which strengthen the reliability of the proposed procedure.
C1 [Kravvaris, Dimitrios; Kermanidis, Katia Lida] Ionian Univ, Dept Informat, 7 Tsirigoti Sq, Corfu 49132, Greece.
C3 Ionian University
RP Kravvaris, D (corresponding author), Ionian Univ, Dept Informat, 7 Tsirigoti Sq, Corfu 49132, Greece.
EM jkravv@gmail.com; kerman@ionio.gr
RI Kermanidis, Katia/AAM-2025-2021
CR Alharbi Ghada, 2015, EDM, P524
   [Anonymous], 2013, RapidMiner: Data Mining Use Cases and Business Analytics Applications
   Anthony L., 2014, AntConc Version 3.4.3
   Biswas A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P621, DOI 10.1145/2733373.2806253
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cha M, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P1
   Chorianopoulos K, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-10
   Deldjoo Y, 2016, J DATA SEMANT, V5, P99, DOI 10.1007/s13740-016-0060-9
   Gabrielatos C, 2012, CADS INT C
   Gelbukh A, 2010, LECT NOTES COMPUT SC, V6177, P248, DOI 10.1007/978-3-642-13881-2_26
   Giannakopoulos T, 2010, LECT NOTES ARTIF INT, V6040, P91, DOI 10.1007/978-3-642-12842-4_13
   Hoic-bozic N., 2016, RECOMMENDER SYSTEM W, V59, P39, DOI DOI 10.1109/TE.2015.2427116
   Imran Hazra, 2016, Vietnam Journal of Computer Science, V3, P3, DOI 10.1007/s40595-015-0049-6
   Ji XF, 2010, IEEE T SYST MAN CY C, V40, P13, DOI 10.1109/TSMCC.2009.2027608
   Liu B, 2010, BIOINFORMATICS, V26, P3105, DOI 10.1093/bioinformatics/btq576
   Mansoorizadeh M, 2010, MULTIMED TOOLS APPL, V49, P277, DOI 10.1007/s11042-009-0344-2
   McCallum A.K., 2002, MALLET MACHINE LEARN
   Park D, 2010, LECT NOTES COMPUT SC, V6314, P241, DOI 10.1007/978-3-642-15561-1_18
   Pazienza MT, 2005, STUD FUZZ SOFT COMP, V185, P255
   Philbin J, 2011, INT J COMPUT VISION, V95, P138, DOI 10.1007/s11263-010-0363-5
   Pojanapunya P, 2016, CORPUS LINGUISTICS L
   Rayson P., 2000, P WORKSHOP COMPARING, V9, P1, DOI DOI 10.3115/1117729.1117730
   Rosen-Zvi Michal., 2004, UAI
   Rousseau A, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P125
   Willett P, 2006, PROGRAM-ELECTRON LIB, V40, P219, DOI 10.1108/00330330610681295
   Xing Wei, 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P178
   Zhang H, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P331, DOI 10.1145/3041021.3054166
   Zhou XY, 2018, TRANSBOUND EMERG DIS, V65, pe205, DOI 10.1111/tbed.12683
NR 28
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2465
EP 2479
DI 10.1007/s11042-018-6372-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700052
DA 2024-07-18
ER

PT J
AU Li, ZS
   Liu, BT
   Yan, CG
AF Li, ZhiSheng
   Liu, Bingtao
   Yan, Chenggang
TI CFMDA: collaborative filtering-based MiRNA-disease association
   prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE miRNA-disease association prediction; Collaborative filtering;
   Computational model
ID PARALLEL FRAMEWORK; HUMAN MICRORNA
AB MicroRNAs (miRNAs) are increasingly becoming the focus in a number of researches because abundant studies certify miRNAs play vital roles and have critical functions in various biologic processes. Considering the high cost of experiment research to miRNA-disease association, we explore the way to predict the miRNA-disease association using the extensive collaborative filtering in order to diagnose the diseases better. Specifically, we introduce the prediction model of collaborative filtering-based miRNA-disease association prediction (CFMDA) and verify the model by leave-one-out cross validation(LOOCV) and case validation. The CFMDA considers the miRNA functional similarity and disease similarity while uses minimal amount of related information. CFMDA achieves AUCs of 0.8364 using leave-one-out cross validation, which is the highest AUCs compared to other 5 methods. Meanwhile, we obtain more than 85% confirmation of predicted associations using three kinds of case validations. Generally, our method is faster and more effective than other state-of-the-art methods while it doesn't need any negative samples.
C1 [Li, ZhiSheng; Liu, Bingtao; Yan, Chenggang] Hangzhou Dianzi Univ, Hangzhou, Zhejiang, Peoples R China.
C3 Hangzhou Dianzi University
RP Liu, BT; Yan, CG (corresponding author), Hangzhou Dianzi Univ, Hangzhou, Zhejiang, Peoples R China.
EM 1049867627@qq.com; liubingtao@hdu.edu.cn; cgyan@hdu.edu.cn
RI Liu, Bingtao/ISA-1439-2023; li, zhisheng/O-6845-2014
FU National Nature Science Foundation of China [61671196, 61327902];
   Zhejiang Province Nature Science Foundation of China [LR17F030006]
FX This work is supported by National Nature Science Foundation of China
   (61671196, 61327902) Zhejiang Province Nature Science Foundation of
   China LR17F030006.
CR Ambros V, 2004, NATURE, V431, P350, DOI 10.1038/nature02871
   [Anonymous], 2013, Book Linear cross-modal hashing for efficient multimedia search, DOI DOI 10.1145/2502081.2502107
   Birks DK, 2011, PEDIATR BLOOD CANCER, V56, P211, DOI 10.1002/pbc.22723
   Calin GA, 2006, NAT REV CANCER, V6, P857, DOI 10.1038/nrc1997
   Chen X, 2016, ONCOTARGET, V7, P65257, DOI 10.18632/oncotarget.11251
   Chen X, 2016, SCI REP-UK, V6, DOI 10.1038/srep21106
   Chen X, 2014, SCI REP-UK, V4, DOI 10.1038/srep05501
   Chen X, 2012, MOL BIOSYST, V8, P2792, DOI 10.1039/c2mb25180a
   Esquela-Kerscher A, 2006, NAT REV CANCER, V6, P259, DOI 10.1038/nrc1840
   Griffiths-Jones S, 2006, NUCLEIC ACIDS RES, V34, pD140, DOI 10.1093/nar/gkj112
   Jiang QH, 2010, BMC SYST BIOL, V4, DOI 10.1186/1752-0509-4-S1-S2
   Karaayvaz M, 2011, CLIN COLORECTAL CANC, V10, P340, DOI 10.1016/j.clcc.2011.06.002
   Li X., 2012, SYST BIOL CANC RES D, V2012, P289, DOI [10.1007/978-94-007-4819-4_12, DOI 10.1007/978-94-007-4819-4_12]
   Li Y, 2014, NUCLEIC ACIDS RES, V42, pD1070, DOI 10.1093/nar/gkt1023
   Liang AL, 2016, ONCOL REP, V35, P1950, DOI 10.3892/or.2016.4596
   Miska EA, 2005, CURR OPIN GENET DEV, V15, P563, DOI 10.1016/j.gde.2005.08.005
   Mork S, 2014, BIOINFORMATICS, V30, P392, DOI 10.1093/bioinformatics/btt677
   Nassar FJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0107566
   Nathans R, 2009, MOL CELL, V34, P696, DOI 10.1016/j.molcel.2009.06.003
   Pan R, 2008, IEEE DATA MINING, P502, DOI 10.1109/ICDM.2008.16
   Schaefer A, 2010, INT J CANCER, V126, P1166, DOI 10.1002/ijc.24827
   Shi HB, 2013, BMC SYST BIOL, V7, DOI 10.1186/1752-0509-7-101
   Takahashi M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0046684
   Wan DW, 2013, MED ONCOL, V30, DOI 10.1007/s12032-012-0378-6
   Xuan P, 2013, PLOS ONE, V8, DOI [10.1371/journal.pone.0070204, 10.1371/annotation/a076115e-dd8c-4da7-989d-c1174a8cd31e]
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhou J, 2011, J CLIN ONCOL, V29, P4781, DOI 10.1200/JCO.2011.38.2697
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
NR 32
TC 3
Z9 3
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 605
EP 618
DI 10.1007/s11042-017-5291-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500034
DA 2024-07-18
ER

PT J
AU Zhou, NR
   Luo, AW
   Zou, WP
AF Zhou, Nan Run
   Luo, An Wei
   Zou, Wei Ping
TI Secure and robust watermark scheme based on multiple transforms and
   particle swarm optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lifting wavelet transform; Discrete cosine transform; Discrete
   fractional angular transform; Singular value decomposition; False
   positive problem; Particle swarm optimization algorithm
ID DISCRETE WAVELET TRANSFORM; SVD; DWT
AB To improve the security, robustness and imperceptibility of watermark schemes, a novel watermark scheme is devised by fusing multiple watermark techniques, including lifting wavelet transform, discrete cosine transform, discrete fractional angular transform and singular value decomposition. To solve the false positive problem in various SVD-based watermark schemes, transform domain encryption is utilized and the embedding component of watermark instead of the whole watermark is embedded into the host image. Furthermore, the particle swarm optimization algorithm is used to optimize the scaling factors and the parameter of the improved discrete fractional angular transform. The proposed watermark scheme is tested by several attacks, such as JPEG compression, low-pass filtering, Histogram equalization, contrast enhance, and etc. Simulation results demonstrate that the proposed watermark scheme is superior in the aspects of security, robustness and imperceptibility.
C1 [Zhou, Nan Run; Luo, An Wei; Zou, Wei Ping] Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
   [Zou, Wei Ping] Univ Poitiers, XLIM UMR CNRS 7252, Poitiers, France.
C3 Nanchang University; Centre National de la Recherche Scientifique
   (CNRS); Universite de Poitiers
RP Zhou, NR (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
EM nrzhou@ncu.edu.cn
RI Zhou, Nanrun/HGC-4650-2022
FU National Natural Science Foundation of China [61462061, 61561033]; China
   Scholarship Council [201606825042]; Department of Human Resources and
   Social Security of Jiangxi Province; Major Academic Discipline and
   Technical Leader of Jiangxi Province [20162BCB22011]; Natural Science
   Foundation of Jiangxi Province [20171BAB202002]
FX This work is supported by the National Natural Science Foundation of
   China (Grant Nos. 61462061 and 61561033), the China Scholarship Council
   (Grant No. 201606825042), the Department of Human Resources and Social
   Security of Jiangxi Province, the Major Academic Discipline and
   Technical Leader of Jiangxi Province (Grant No. 20162BCB22011), and the
   Natural Science Foundation of Jiangxi Province (Grant No.
   20171BAB202002).
CR Abdallah EE, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2764466
   [Anonymous], INT WORKSH MULT TREN
   [Anonymous], ARXIV170807077
   [Anonymous], 2008, ARXIV PREPRINT ARXIV
   [Anonymous], 2016, P 24 ACM INT C MULT
   Bhatnagar G, 2012, COMPUT SECUR, V31, P40, DOI 10.1016/j.cose.2011.11.003
   Cedillo-Hernandez M, 2015, SIGNAL IMAGE VIDEO P, V9, P1163, DOI 10.1007/s11760-013-0555-x
   Chen B, 2017, CLUSTER COMPUT, V20, P413, DOI 10.1007/s10586-017-0731-9
   Ding M, 2016, IEEE T IMAGE PROCESS, V25, P776, DOI 10.1109/TIP.2015.2507445
   Ding M, 2015, IEEE T CYBERNETICS, V45, P2413, DOI 10.1109/TCYB.2014.2373393
   Esgandari R, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P988, DOI 10.1109/KBEI.2015.7436179
   Guo J, 2007, OPT COMMUN, V272, P344, DOI 10.1016/j.optcom.2006.11.034
   Hu HT, 2017, MULTIMED TOOLS APPL, V76, P6575, DOI 10.1007/s11042-016-3332-3
   Kakarala R, 2001, IEEE T IMAGE PROCESS, V10, P724, DOI 10.1109/83.918566
   Kazemivash B, 2017, MULTIMED TOOLS APPL, V76, P20499, DOI 10.1007/s11042-016-3962-5
   Keshavarzian R, 2016, AEU-INT J ELECTRON C, V70, P278, DOI 10.1016/j.aeue.2015.12.003
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Li JB, 2012, 2012 7TH INTERNATIONAL CONFERENCE ON COMPUTING AND CONVERGENCE TECHNOLOGY (ICCCT2012), P257
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu JX, 2017, MULTIMED TOOLS APPL, V76, P24009, DOI 10.1007/s11042-016-4178-4
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Liu S, 2017, IET IMAGE PROCESS, V11, P815, DOI 10.1049/iet-ipr.2016.0862
   Liu ZJ, 2008, OPT COMMUN, V281, P1424, DOI 10.1016/j.optcom.2007.11.012
   Loukhaoukha K., 2011, J Inf Hiding Multim Signal Process, V2, P303
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Singh P, 2013, AFRICON
   Su QT, 2015, SIGNAL IMAGE VIDEO P, V9, P991, DOI 10.1007/s11760-013-0534-2
   Su QT, 2013, AEU-INT J ELECTRON C, V67, P652, DOI 10.1016/j.aeue.2013.01.009
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang C, 2016, MULTIMED TOOLS APPL, V75, P9255, DOI 10.1007/s11042-016-3380-8
   Wang C, 2015, PROC INT C TOOLS ART, P234, DOI 10.1109/ICTAI.2015.45
   Ye XY, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P479, DOI 10.1109/CIS.2014.28
   Yu J, 2017, OPT APPL, V47, P141, DOI 10.5277/oa170113
   Zhang X, 2008, OPT ENG, V47, DOI 10.1117/1.2955819
   Zhang XP, 2005, IEEE T MULTIMEDIA, V7, P593, DOI 10.1109/TMM.2005.843357
   Zhang Z, 2016, INT CONF SIGN PROCES, P805, DOI 10.1109/ICSP.2016.7877942
NR 40
TC 54
Z9 55
U1 2
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2507
EP 2523
DI 10.1007/s11042-018-6322-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700054
DA 2024-07-18
ER

PT J
AU Ali, AH
   George, LE
   Zaidan, AA
   Mokhtar, MR
AF Ali, Ahmed Hussain
   George, Loay Edwar
   Zaidan, A. A.
   Mokhtar, Mohd Rosmadi
TI High capacity, transparent and secure audio steganography model based on
   fractal coding and chaotic map in temporal domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fractal coding; Least significant bit; Steganography; Information
   hiding; Logistic map; Statistical steganalysis
ID IMAGE STEGANOGRAPHY; WAVELET TRANSFORM; ALGORITHM; STEGANALYSIS; SCHEME
AB Information hiding researchers have been exploring techniques to improve the security of transmitting sensitive data through an unsecured channel. This paper proposes an audio steganography model for secure audio transmission during communication based on fractal coding and a chaotic least significant bit or also known as HASFC. This model contributes to enhancing the hiding capacity and preserving the statistical transparency and security. The HASFC model manages to embed secret audio into a cover audio with the same size. In order to achieve this result, fractal coding is adopted which produces high compression ratio with the acceptable reconstructed signal. The chaotic map is used to randomly select the cover samples for embedding and its initial parameters are utilized as a secret key to enhancing the security of the proposed model. Unlike the existing audio steganography schemes, The HASFC model outperforms related studies by improving the hiding capacity up to 30% and maintaining the transparency of stego audio with average values of SNR at 70.4, PRD at 0.0002 and SDG at 4.7. Moreover, the model also shows resistance against brute-force attack and statistical analysis.
C1 [Ali, Ahmed Hussain] Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Bangi, Malaysia.
   [Mokhtar, Mohd Rosmadi] Univ Kebangsaan Malaysia, Ctr Informat Technol, Core Applicat, Bangi, Malaysia.
   [George, Loay Edwar] Univ Baghdad, Coll Sci, Remote Sensing Dept, Baghdad, Iraq.
   [Zaidan, A. A.] Univ Pendidikan Sultan Idris, Dept Comp, Tanjung Malim, Malaysia.
C3 Universiti Kebangsaan Malaysia; Universiti Kebangsaan Malaysia;
   University of Baghdad; Universiti Pendidikan Sultan Idris
RP Ali, AH (corresponding author), Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Bangi, Malaysia.
EM ahmedhussainali@siswa.ukm.edu.my; loayedwar57@scbaghdad.edu.iq;
   aws.alaa@fskik.upsi.edu.my; mrm@ukm.edu.my
RI Albahri,, A. S./F-7289-2010; Ali, Ahmed/HOF-4672-2023; Ali, Ahmed
   H./ABI-1550-2020; George, Loay Edwar/S-6596-2019; Ali, Assoc. Prof.
   Ahmed H./O-6328-2019
OI Ali, Ahmed H./0000-0002-1278-2770; Ali, Assoc. Prof. Ahmed
   H./0000-0001-8561-1991; George, Loay/0000-0001-9028-0816
FU Ministry of Higher Education and Scientific Research, Studies Planning
   and Follow-up Directorate, Republic of Iraq; Research Center for
   Software Technology & Management, Faculty of Information Science and
   Technology, Universiti Kebangsaan Malaysia [DPP-2015-018]
FX This research is supported by the Ministry of Higher Education and
   Scientific Research, Studies Planning and Follow-up Directorate,
   Republic of Iraq and the Research Center for Software Technology &
   Management, Faculty of Information Science and Technology, Universiti
   Kebangsaan Malaysia (DPP-2015-018).
CR Al-Haj A, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-014-0037-2
   Al-Hilo Eman A., 2008, 2008 Digital Image Computing: Techniques and Applications, P486, DOI 10.1109/DICTA.2008.18
   Ali A. H., 2016, RES J APPL SCI ENG T, V12, P154, DOI [10.19026/rjaset.12.2316, DOI 10.19026/RJASET.12.2316]
   Ali AH, 2017, J THEORETICAL APPL I, V95, P1441
   Ali AH, 2016, INDIAN J SCI TECHNOL, V9, P6, DOI DOI 10.17485/ijst/2016/v9i38/101283
   Ali SM, 2013, INT J ADV RES COMPUT, V3, P7
   [Anonymous], 2011, WORLD APPL SCI J
   [Anonymous], INFORM HIDING APPL
   [Anonymous], 2014, RES J APPL SCI ENG T
   [Anonymous], 2010, WORLD APPL SCI J
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Ballesteros DM, 2012, EXPERT SYST APPL, V39, P9141, DOI 10.1016/j.eswa.2012.02.066
   BARNSLEY MF, 1988, BYTE, V13, P215
   Bazyar M, 2015, J TEKNOL, V74, P49
   Bedan AK, 2013, INT J SCI ENG RES, V4, P5
   Bhat KV, 2010, DIGIT SIGNAL PROCESS, V20, P1547, DOI 10.1016/j.dsp.2010.02.006
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Djebbar F, 2012, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2012-25
   El-Khamy SE, 2017, MULTIMED TOOLS APPL, V76, P24091, DOI 10.1007/s11042-016-4113-8
   El-Khamy SE, 2017, RAD SCI C NRSC 2017
   George L. E., 2011, Proceedings of the 2011 Eighth International Conference on Information Technology: New Generations (ITNG), P508, DOI 10.1109/ITNG.2011.94
   Ghasemzadeh H, 2016, DIGIT SIGNAL PROCESS, V51, P133, DOI 10.1016/j.dsp.2015.12.015
   Ghebleh M, 2014, COMMUN NONLINEAR SCI, V19, P1898, DOI 10.1016/j.cnsns.2013.10.014
   Hemalatha S, 2016, INT J ELECTRON SECUR, V8, P131, DOI 10.1504/IJESDF.2016.075586
   Ibaida A, 2014, FUTURE GENER COMP SY, V35, P91, DOI 10.1016/j.future.2013.12.025
   Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028
   Jaferzadeh K, 2016, PATTERN ANAL APPL, P1
   Kamble SD, 2015, ADV INTELL SYST COMP, V340, P649, DOI 10.1007/978-81-322-2247-7_66
   Kar DC, 2015, J INF SECUR APPL, V23, P54, DOI 10.1016/j.jisa.2015.02.001
   Kaur A, 2017, J INF SECUR APPL, V33, P1, DOI 10.1016/j.jisa.2016.12.003
   Kekre H. B., 2010, Proceedings of the Third International Conference on Emerging Trends in Engineering and Technology (ICETET 2010), P196, DOI 10.1109/ICETET.2010.118
   Kodituwakku S., 2010, Indian Journal of Computer Science and Engineering, V1, P416
   Lee JD, 2013, INFORM SCIENCES, V221, P419, DOI 10.1016/j.ins.2012.09.020
   Lei BY, 2012, SIGNAL PROCESS, V92, P1985, DOI 10.1016/j.sigpro.2011.12.021
   Lin CC, 2015, MULTIMED TOOLS APPL, V74, P3823, DOI 10.1007/s11042-013-1801-5
   Lin GS, 2010, IEEE T MULTIMEDIA, V12, P345, DOI 10.1109/TMM.2010.2051243
   Liu QZ, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2000486.2000492
   Lou DC, 2012, INFORM SCIENCES, V188, P346, DOI 10.1016/j.ins.2011.06.003
   Ma XX, 2015, J VIS COMMUN IMAGE R, V28, P60, DOI 10.1016/j.jvcir.2015.01.009
   Malik A, 2017, ENG SCI TECHNOL, V20, P72, DOI 10.1016/j.jestch.2016.06.005
   Mammeri Abdelhamid, 2012, ISRN Sensor Networks, DOI 10.5402/2012/760320
   Mohd BJ, 2013, SIGNAL IMAGE VIDEO P, V7, P1029, DOI 10.1007/s11760-012-0301-9
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Rahim Lukman Bin Ab., 2013, LECT NOTES ELECT ENG, P277
   Renza D, 2017, LECT NOTES COMPUT SC, V10125, P27, DOI 10.1007/978-3-319-52277-7_4
   Renza D, 2018, EXPERT SYST APPL, V91, P211, DOI 10.1016/j.eswa.2017.09.003
   Sayood Khalid, 2012, INTRO DATA COMPRESSI, P529
   Shahadi H, 2011, INT J COMP SCI IS, V8, P176
   Shahadi H. I., 2011, 2011 7th International Conference on Information Assurance and Security (IAS), P104, DOI 10.1109/ISIAS.2011.6122803
   Shahadi H. I., 2013, INDIAN J SCI TECHNOL, V7, P323, DOI 10.17485/ijst/2014/v7i3.14
   Sheltami T, 2016, FUTURE GENER COMP SY, V64, P151, DOI 10.1016/j.future.2016.01.015
   Shivdas DA, 2014, INT J SCI PROGR RES, V6, P61
   Tang MW, 2016, OPTIK, V127, P471, DOI 10.1016/j.ijleo.2015.09.216
   Tang MW, 2014, OPTIK, V125, P3972, DOI 10.1016/j.ijleo.2014.01.149
   Tsai YS, 2011, INFORM SCIENCES, V181, P3188, DOI 10.1016/j.ins.2011.03.017
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Tzanetakis G, 2009, MUSIC ANAL RETRIEVAL
   Valarmathi M, 2015, INFORM COMMUNICATION, P157
   Wu Q, 2016, J INF SECUR APPL, V26, P1, DOI 10.1016/j.jisa.2015.08.003
   Yu LF, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/876946
   Zaidan BB, 2017, SOFTWARE PRACT EXPER, V47, P1365, DOI 10.1002/spe.2465
NR 61
TC 42
Z9 44
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31487
EP 31516
DI 10.1007/s11042-018-6213-0
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600060
DA 2024-07-18
ER

PT J
AU Ankarao, V
   Sowmya, V
   Soman, KP
AF Ankarao, V.
   Sowmya, V.
   Soman, K. P.
TI Multi-sensor data fusion using NIHS transform and decomposition
   algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote sensing; Multi-spectral fusion; Dynamic mode decomposition; Image
   empirical mode decomposition; Non-linearIHS transform
ID EMPIRICAL MODE DECOMPOSITION; RESOLUTION IMAGE FUSION; BIDIMENSIONAL
   EMD; SPECTRAL-ANALYSIS; COLOR DISTORTION; REGRESSION; PATTERNS;
   TRADEOFF; TOOL; MS
AB Multi-spectral image fusion is to enhance the details present in multi-spectral bands with the spatial information available in the panchromatic image. Fused images have the effect of spectral distortions and lack of structural similarity. To overcome these limitations, three methods are proposed using intensity, hue, saturation (IHS) and nonlinear IHS (NIHS) transform along with the Dynamic Mode Decomposition (DMD) and 2D-Empirical Mode Decomposition (2D-EMD or IEMD). An intensity plane is calculated from the NIHS transform. The modes are constructed using DMD by considering the variations between the intensity plane computed using NIHS transforms of a low resolution multi-spectral image and a panchromatic image. Similarly, 2D-EMD is also used for image fusion. Modes are subjected to weighted fusion rule to get an intensity plane with spatial and edge information. Finally, the calculated intensity plane is concatenated along with the hue and saturation plane of low-resolution multi-spectral image and transformed into RGB color space. Thus, the fused images have high spatial and edge information on spectral bands. The experiments and its quality assessment assure that proposed methods perform better than the existing methods.
C1 [Ankarao, V.; Sowmya, V.; Soman, K. P.] Amrita Vishwa Vidyapeetham, Amrita Sch Engn, Ctr Computat Engn & Networking CEN, Coimbatore, Tamil Nadu, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Coimbatore
RP Sowmya, V (corresponding author), Amrita Vishwa Vidyapeetham, Amrita Sch Engn, Ctr Computat Engn & Networking CEN, Coimbatore, Tamil Nadu, India.
EM v_sowmya@cb.amrita.edu
RI V, Sowmya/L-1459-2019
OI V, Sowmya/0000-0003-3745-6944
CR Agarwal J, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-014-0020-z
   Aiazzi B, 2002, IEEE T GEOSCI REMOTE, V40, P2300, DOI 10.1109/TGRS.2002.803623
   Aiazzi B, 2007, IEEE T GEOSCI REMOTE, V45, P3230, DOI 10.1109/TGRS.2007.901007
   Amolins K, 2007, ISPRS J PHOTOGRAMM, V62, P249, DOI 10.1016/j.isprsjprs.2007.05.009
   Amro I, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-79
   Ankarao V, 2017, LECT NOTES ELECT ENG
   [Anonymous], 2 DIMENSIONAL VARIAT
   [Anonymous], 2015, INDIAN J SCI TECHNOL
   [Anonymous], 2013, ARXIV13125186
   Brunton BW, 2016, J NEUROSCI METH, V258, P1, DOI 10.1016/j.jneumeth.2015.10.010
   Chen KK, 2012, J NONLINEAR SCI, V22, P887, DOI 10.1007/s00332-012-9130-9
   Choi M, 2006, IEEE T GEOSCI REMOTE, V44, P1672, DOI 10.1109/TGRS.2006.869923
   Colominas MA, 2016, IEEE T IMAGE PROCESS, V25, P2288, DOI 10.1109/TIP.2016.2541959
   Colominas MA, 2015, DIGIT SIGNAL PROCESS, V40, P164, DOI 10.1016/j.dsp.2015.02.013
   Damerval C, 2005, IEEE SIGNAL PROC LET, V12, P701, DOI 10.1109/LSP.2005.855548
   Dragomiretskiy K, 2014, IEEE T SIGNAL PROCES, V62, P531, DOI 10.1109/TSP.2013.2288675
   Flandrin P, 2004, IEEE SIGNAL PROC LET, V11, P112, DOI 10.1109/LSP.2003.821662
   Ghahremani M, 2016, IEEE GEOSCI REMOTE S, V13, P1606, DOI 10.1109/LGRS.2016.2597271
   Grosek J., 2014, ARXIV14047592
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Jin B, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.080599
   Kutz JN., 2013, Data-Driven Modeling and Scientific Computation: Methods for Complex Systems and Big Data
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Linderhed A, 2005, IEEE INT C IM PROC 2
   Linderhed A, 2009, ADV DATA SCI ADAPT, V1, P265, DOI 10.1142/S1793536909000138
   Liu ZX, 2004, IEEE IMAGE PROC, P279
   Liu ZX, 2005, IEEE SIGNAL PROC LET, V12, P33, DOI 10.1109/LSP.2004.839700
   Looney D, 2009, IEEE T SIGNAL PROCES, V57, P1626, DOI 10.1109/TSP.2008.2011836
   Nunes JC, 2003, IMAGE VISION COMPUT, V21, P1019, DOI 10.1016/S0262-8856(03)00094-5
   Pradeep V. V., 2016, Int. J. Control Theory Appl., V9, P8051
   Pradeep VV, 2017, J INTELL FUZZY SYST, V32, P3151, DOI 10.3233/JIFS-169258
   Proctor JL, 2015, INT HEALTH, V7, P139, DOI 10.1093/inthealth/ihv009
   Rowley CW, 2009, J FLUID MECH, V641, P115, DOI 10.1017/S0022112009992059
   Sahu D., 2012, Int. J. Mod. Eng. Res. (IJMER), V2, P4298
   Schmid P, 2011, THEOR COMP FLUID DYN, V25, P249, DOI 10.1007/s00162-010-0203-9
   Schmid PJ, 2010, J FLUID MECH, V656, P5, DOI 10.1017/S0022112010001217
   Schmitt J, 2014, IEEE T IMAGE PROCESS, V23, P5233, DOI 10.1109/TIP.2014.2363000
   Tanaka K, 2013, IEEE ENG MED BIO, P973, DOI 10.1109/EMBC.2013.6609665
   Te-Ming Tu, 2001, Information Fusion, V2, P177, DOI 10.1016/S1566-2535(01)00036-7
   Tu TM, 2007, IEEE GEOSCI REMOTE S, V4, P302, DOI 10.1109/LGRS.2007.894143
   Wang J, 2008, GEO-SPAT INF SCI, V11, P31, DOI 10.1007/s11806-007-0150-9
   Wang ZJ, 2005, IEEE T GEOSCI REMOTE, V43, P1391, DOI 10.1109/TGRS.2005.846874
   Xu QZ, 2015, IEEE GEOSCI REMOTE S, V12, P28, DOI 10.1109/LGRS.2014.2324817
   Xu QZ, 2014, IEEE T GEOSCI REMOTE, V52, P7380, DOI 10.1109/TGRS.2014.2311815
   Zhang Y, 1999, INT J REMOTE SENS, V20, P2003, DOI 10.1080/014311699212317
NR 45
TC 5
Z9 6
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30381
EP 30402
DI 10.1007/s11042-018-6114-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600011
DA 2024-07-18
ER

PT J
AU Bhujle, H
   Vadavadagi, BH
   Galaveen, S
AF Bhujle, Hemalata
   Vadavadagi, Basavaraj H.
   Galaveen, Shivanand
TI Efficient non-local means denoising for image sequences with
   dimensionality reduction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nonlocal means; Shot boundary; Principal component analysis
ID SHOT-BOUNDARY DETECTION; PRINCIPAL COMPONENTS; WAVELET TRANSFORMS;
   NOISE-REDUCTION; RESTORATION; PATCH; DICTIONARIES; ALGORITHM
AB The aim of this paper is to improve both accuracy and computational efficiency of non-local means video (NLMV) denoising algorithm. A technique of principal component analysis (PCA) is used to reduce the heavy dimensionality of patches. A pre-processing step of shot boundary detection is used to split the video sequence into different shots having content-wise similar frames. Further PCA is computed globally for these shots. To speed-up the denoising process, weights are computed in reduced subspace. In the proposed method, we modify the original histogram difference (HD) technique such that content-wise similar frames are separated more systematically and accurately. We have achieved improvement with respect to accuracy and computational speed compared to standard NLM. Moreover, qualitative and quantitative comparisons show that the proposed method is consistently superior compared to that of NLM and some of its variants.
C1 [Bhujle, Hemalata; Vadavadagi, Basavaraj H.] SDM Coll Engn & Technol, Dept Elect & Commun Engn, Dharwad 580002, Karnataka, India.
   [Galaveen, Shivanand] Indian Inst Technol, Mumbai, Maharashtra, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Bombay
RP Bhujle, H (corresponding author), SDM Coll Engn & Technol, Dept Elect & Commun Engn, Dharwad 580002, Karnataka, India.
EM hemalatabhujle@gmail.com; vbasavaraj99@gmail.com; galaveen@gmail.com
RI Galaveen, Shivanand/AFE-8598-2022
OI Galaveen, Shivanand/0000-0003-2541-3816
CR Almahdi R, 2016, PROC NAECON IEEE NAT, P318, DOI 10.1109/NAECON.2016.7856822
   [Anonymous], P 15 EUR SIGN PROC C
   [Anonymous], 2016, P AI SAD INT C MULT
   [Anonymous], 6 INT C INT SYST DES
   Azzabou N., 2007, Proc. Int. Conf. Image Processing, VIII, P109
   Balster EJ, 2006, IEEE T CIRC SYST VID, V16, P220, DOI 10.1109/TCSVT.2005.857816
   Bhujle H, 2014, IEEE T IMAGE PROCESS, V23, P356, DOI 10.1109/TIP.2013.2290871
   Boreczky JS, 1996, J ELECTRON IMAGING, V5, P122, DOI 10.1117/12.238675
   Boulanger J, 2007, IEEE T PATTERN ANAL, V29, P1096, DOI 10.1109/TPAMI.2007.1064
   BRAILEAN JC, 1995, P IEEE, V83, P1272, DOI 10.1109/5.406412
   Brox T, 2008, IEEE T IMAGE PROCESS, V17, P1083, DOI 10.1109/TIP.2008.924281
   Bruni V, 2007, SIGNAL PROCESS-IMAGE, V22, P86, DOI 10.1016/j.image.2006.11.006
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1
   Campisi P, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P567, DOI 10.1109/ICDSP.2002.1028153
   Cerneková Z, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P181
   Cho D, 2005, SIGNAL PROCESS-IMAGE, V20, P77, DOI 10.1016/j.image.2004.10.003
   Coupé P, 2006, LECT NOTES COMPUT SC, V4191, P33
   Dekeyser F, 2000, IEEE IMAGE PROC, P208, DOI 10.1109/ICIP.2000.900931
   Dugad R., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P152, DOI 10.1109/ICIP.1999.819568
   Feng H., 2005, Multimedia information retrieval, P121
   Gargi U, 2000, IEEE T CIRC SYST VID, V10, P1, DOI 10.1109/76.825852
   Ghosh S, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.2.023026
   Gordienko Y, 2018, INT C ADV COMP INT
   Guo LW, 2010, J SIGNAL PROCESS SYS, V60, P273, DOI 10.1007/s11265-009-0365-0
   Hanjalic A, 2002, IEEE T CIRC SYST VID, V12, P90, DOI 10.1109/76.988656
   Hao BB, 2008, SIGNAL PROCESS-IMAGE, V23, P433, DOI 10.1016/j.image.2008.04.006
   Heng WJ, 1999, ISCAS '99: PROCEEDINGS OF THE 1999 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 4, P439, DOI 10.1109/ISCAS.1999.780036
   Hosseini H, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-15
   Hu JR, 2016, MAGN RESON IMAGING, V34, P990, DOI 10.1016/j.mri.2016.04.008
   Kalra GS, 2016, MULTIMED TOOLS APPL, V75, P4467, DOI 10.1007/s11042-015-2484-x
   Kervrann C, 2007, LECT NOTES COMPUT SC, V4485, P520
   Khazron PA, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3514739
   KLEIHORST RP, 1995, IEEE T IMAGE PROCESS, V4, P274, DOI 10.1109/83.366476
   Lee J. C.-M., 1994, Proceedings of IAPR Workshop on Machine Vision Applications, P502
   Lee SH, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P447, DOI 10.1109/ICIP.1998.723418
   Lee TH, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.2.023004
   Lelescu D, 2003, IEEE T MULTIMEDIA, V5, P106, DOI 10.1109/TMM.2003.808819
   Li W, 2016, IEEE INT C IM VIS CO, V318, P322
   Li W, 2011, SIGNAL PROCESS-IMAGE, V26, P250, DOI 10.1016/j.image.2011.04.005
   Li X, 2009, IEEE T CIRC SYST VID, V19, P27, DOI 10.1109/TCSVT.2008.2005805
   Mahmoudi M, 2005, IEEE SIGNAL PROC LET, V12, P839, DOI 10.1109/LSP.2005.859509
   Melange T, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2992065
   Mohamadi N, 2017, J MULTIMEDIA TOOLS A, V74, P1
   Muresan DD, 2003, IEEE IMAGE PROC, P101
   Orchard J, 2008, IEEE IMAGE PROC, P1732, DOI 10.1109/ICIP.2008.4712109
   Selesnick IW, 2003, PROC SPIE, V5207, P607, DOI 10.1117/12.504896
   Tasdizen T, 2008, IEEE IMAGE PROC, P1728, DOI 10.1109/ICIP.2008.4712108
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Vignesh R, 2010, IEEE SIGNAL PROC LET, V17, P277, DOI 10.1109/LSP.2009.2038956
   Wang XY, 2015, MULTIMED TOOLS APPL, V74, P11703, DOI 10.1007/s11042-014-2258-x
   Wang YS, 2016, NEUROCOMPUTING, V184, P232, DOI 10.1016/j.neucom.2015.08.104
   Xu BH, 2016, MULTIMED TOOLS APPL, V75, P2681, DOI 10.1007/s11042-015-2545-1
   Xu DQ, 2017, MULTIMED TOOLS APPL, V76, P17839, DOI 10.1007/s11042-015-3097-0
   YUAN JH, 2005, P 13 ANN ACM INT C M, P539
   Zhang HJ, 2001, AUTOMATIC PARTITIONI, P321
   Zhang JL, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.4.043013
   Zhu ZQ, 2015, PATTERN RECOGN, V48, P2592, DOI 10.1016/j.patcog.2015.01.001
   Zlokolica V, 2004, P IS T SPIE S EL IM, P1417
   Zlokolica V, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2201548
NR 60
TC 1
Z9 1
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30595
EP 30613
DI 10.1007/s11042-018-6159-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600021
DA 2024-07-18
ER

PT J
AU Bouslehi, H
   Seddik, H
AF Bouslehi, Hamdi
   Seddik, Hassene
TI Innovative image encryption scheme based on a new rapid hyperchaotic
   system and random iterative permutation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperchaos; Lyapunov exponent; Bifurcation; Encryption; Permutation;
   Randomness
ID ALGORITHM
AB Multimedia data such as: images, audio and video have become significantly more important, since the exchange of digital data over the network (wired/wireless) has expanded. Therefore an increasing need to secure the important data many techniques are used to such purpose. Cryptography remains an important and wide used mean to secure data. In this aim we propose a new rapid hyperchaotic system with higher confusion and a unique equilibrium point. Detailed mathematical study based on dynamic tests such as lyapunov exponents, Poincare map, the Lyapunov Dimension computing, Dissipation and the study of an attractor existence. In addition an electronic implementation is realized to simulate the attractor behavior. The developed system is injected in a new proposed encryption algorithm to introduce high randomness and hyperchaotic behavior to its output applied on digital images. Tests and simulation results on many images kinds prove the efficiency and higher velocity of processing time of the proposed algorithm.
C1 [Bouslehi, Hamdi; Seddik, Hassene] ENSIT Ecole Natl Super Sci & Ingn Tunis, Dept Elect, Tunis, Tunisia.
RP Bouslehi, H (corresponding author), ENSIT Ecole Natl Super Sci & Ingn Tunis, Dept Elect, Tunis, Tunisia.
EM Hamdi.bouslehi@gmail.com; seddik-hassene@ieee.org
OI hassene, seddik/0000-0003-0848-8285
CR [Anonymous], 2009, LECT NOTES COMPUTER, V5551, P253
   [Anonymous], 1949, Bell System Technical Journal
   [Anonymous], 2008, MULTIMIDIA CONTENT E
   [Anonymous], CHIN PHYS B
   DEJESUS EX, 1987, PHYS REV A, V35, P5288, DOI 10.1103/PhysRevA.35.5288
   Hamdi B, 2017, MULTIMED TOOLS APPL, V77, P7741
   Hamza R, 2017, PERVASIVE MOB COMPUT, V41, P436, DOI 10.1016/j.pmcj.2017.03.011
   Hamza R, 2016, INF SECUR J, V25, P162, DOI 10.1080/19393555.2016.1212954
   Junming Ma, 2015, International Journal of Computer Network and Information Security, V7, P25, DOI 10.5815/ijcnis.2015.05.04
   KAPITANIAK T, 1994, INT J BIFURCAT CHAOS, V4, P477, DOI 10.1142/S0218127494000356
   Li YX, 2005, INT J BIFURCAT CHAOS, V15, P3367, DOI 10.1142/S0218127405013988
   Liu SB, 2009, J COMPUT, V4, P1091
   Liu Y, 2015, MULTIMED TOOLS APPL
   Lorenz E. N, 1963, J ATMOS SCI, V20
   Mazloom S, 2009, CHAOS SOLITON FRACT, V42, P1745, DOI 10.1016/j.chaos.2009.03.084
   NING CZ, 1990, PHYS REV A, V41, P3826, DOI 10.1103/PhysRevA.41.3826
   Norouzi B, 2014, INT J NONLINEAR DYN, V78, P925
   Pyragas K, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.026212
   Qi GY, 2005, CHAOS SOLITON FRACT, V23, P1671, DOI 10.1016/j.chaos.2004.06.054
   ROSSLER OE, 1979, PHYS LETT A, V71, P155, DOI 10.1016/0375-9601(79)90150-6
   Rukhin A, 2010, NIST SPECIAL REVISED, V800-22
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Si G.Q., 2011, CHINESE PHYS B, V20, P229
   Wang W, 2017, COMPUT ELECTR ENG, V65, P1
   Wang W, 2016, WIRELESS COMMUNICATION AND SENSOR NETWORK, P711
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Y, 2009, CHAOS SOLITON FRACT, V41, P1773, DOI 10.1016/j.chaos.2008.07.031
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
NR 29
TC 15
Z9 15
U1 0
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30841
EP 30863
DI 10.1007/s11042-018-5997-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600032
DA 2024-07-18
ER

PT J
AU Pang, C
   Yao, HX
   Sun, XS
   Zhao, SC
   Zhang, YH
AF Pang, Cheng
   Yao, Hongxun
   Sun, Xiaoshuai
   Zhao, Sicheng
   Zhang, Yanhao
TI Exploring part-aware segmentation for fine-grained visual categorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Fine-grained visual categorization; GrabCut
ID LOCALIZATION; RECOGNITION
AB It is challenge to segment fine-grained objects due to appearance variations and clutter of backgrounds. Most of existing segmentation methods hardly separate small parts of the instance from its background with sufficient accuracy. However, such small parts usually contain important semantic information, which is crucial in fine-grained categorization. Observing that fine-grained objects almost share the same configuration of parts, we present a novel part-aware segmentation method, which explicitly detects semantic parts and preserve these parts during segmentation. We firstly design a hybrid part localization method, which generates accurate part proposals with moderate computation. Then we iteratively update the segmentation outputs and the part proposals, which obtains better foreground segmentation results. Experiments demonstrate the superiority of the proposed method, as compared to state-of-the-art segmentation approaches for fine-grained categorization.
C1 [Pang, Cheng; Yao, Hongxun; Sun, Xiaoshuai; Zhao, Sicheng; Zhang, Yanhao] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology
RP Yao, HX (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
EM h.yao@hit.edu.cn
OI Pang, Cheng/0000-0001-7829-8992
FU National Natural Science Foundation of China [61472103, 61772158,
   61702136]
FX This work was supported by the National Natural Science Foundation of
   China under Project No. 61472103, No. 61772158 and No. 61702136.
CR Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   Angelova A, 2013, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2013.110
   [Anonymous], 2011, Technical Report CNS-TR-2011-001
   [Anonymous], ARXIV17010534
   [Anonymous], P 55 ANN M ASS COMP
   [Anonymous], 2011, P CVPR WORKSH FIN GR
   [Anonymous], 2016 IEEE C COMP VIS
   [Anonymous], 2016 IEEE C COMP VIS
   [Anonymous], 2016, INT JOINT C ART INT
   [Anonymous], 2014, P INT C INTERNET MUL
   [Anonymous], 2016, 2016 IEEE C COMP VIS
   [Anonymous], ECCV WORKSH PARTS AT
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2016 IEEE C COMP VIS
   [Anonymous], 2016 IEEE C COMP VIS
   [Anonymous], 2016, 2016 IEEE C COMP VIS
   Berg T, 2014, PROC CVPR IEEE, P2019, DOI 10.1109/CVPR.2014.259
   Berg T, 2013, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2013.128
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Branson S, 2014, INT J COMPUT VISION, V108, P3, DOI 10.1007/s11263-014-0698-4
   Chai Y, 2013, IEEE I CONF COMP VIS, P321, DOI 10.1109/ICCV.2013.47
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Felzenszwalb P., 2008, 2008 IEEE C COMPUTER, P1
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Freytag A, 2014, LECT NOTES COMPUT SC, V8753, P144, DOI 10.1007/978-3-319-11752-2_12
   Gkioxari G, 2015, PROC CVPR IEEE, P759, DOI 10.1109/CVPR.2015.7298676
   Göring C, 2014, PROC CVPR IEEE, P2489, DOI 10.1109/CVPR.2014.319
   Jia D, 2013, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2013.81
   Jiang F, 2015, J MACH LEARN RES, V16, P227
   Lin D, 2015, PROC CVPR IEEE, P1666, DOI 10.1109/CVPR.2015.7298775
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liu JX, 2013, IEEE I CONF COMP VIS, P2520, DOI 10.1109/ICCV.2013.313
   Liu JX, 2014, LECT NOTES COMPUT SC, V8690, P456, DOI 10.1007/978-3-319-10605-2_30
   Liu JX, 2012, LECT NOTES COMPUT SC, V7572, P172, DOI 10.1007/978-3-642-33718-5_13
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu WF, 2018, INFORM FUSION, V41, P119, DOI 10.1016/j.inffus.2017.09.001
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229
   Mattos AB, 2014, IEEE IMAGE PROC, P5197, DOI 10.1109/ICIP.2014.7026052
   Ni BB, 2016, PROC CVPR IEEE, P1020, DOI 10.1109/CVPR.2016.116
   Pang C, 2015, LECT NOTES COMPUT SC, V9314, P538, DOI 10.1007/978-3-319-24075-6_52
   ROSCH E, 1976, COGNITIVE PSYCHOL, V8, P382, DOI 10.1016/0010-0285(76)90013-X
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sochor J, 2016, PROC CVPR IEEE, P3006, DOI 10.1109/CVPR.2016.328
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Wilf P, 2016, P NATL ACAD SCI USA, V113, P3305, DOI 10.1073/pnas.1524473113
   Wu B, 2008, 2008 IEEE C COMPUTER, P1
   Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685
   Xie LX, 2013, IEEE I CONF COMP VIS, P1641, DOI 10.1109/ICCV.2013.206
   Yao BP, 2013, IEEE I CONF COMP VIS, P2512, DOI 10.1109/ICCV.2013.312
   Yao BP, 2011, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR.2011.5995368
   Zhang N, 2013, IEEE I CONF COMP VIS, P729, DOI 10.1109/ICCV.2013.96
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhang SP, 2015, AAAI CONF ARTIF INTE, P3165
   Zhang SP, 2015, IEEE T CIRC SYST VID, V25, P1749, DOI 10.1109/TCSVT.2015.2406194
   Zhang SP, 2015, SIGNAL PROCESS, V110, P132, DOI 10.1016/j.sigpro.2014.08.027
   Zhang SP, 2014, INFORM SCIENCES, V281, P635, DOI 10.1016/j.ins.2013.12.052
NR 64
TC 3
Z9 3
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30291
EP 30310
DI 10.1007/s11042-018-5957-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600007
DA 2024-07-18
ER

PT J
AU Zhang, KY
   Peng, YL
   Liu, SG
AF Zhang, Keyou
   Peng, Yali
   Liu, Shigang
TI Discriminative face recognition via kernel sparse representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Sparse representation; l(2)-regularization; Kernel
   trick
ID COLLABORATIVE REPRESENTATION; CLASSIFIER; TUTORIAL
AB Sparse representation (SR) is a popular method in pattern recognition and computer vision, and achieves the noticeable performance for face recognition (FR) task. Nevertheless, the conventional SR algorithm is usually computationally expensive due to the solution of representation coefficients via l(1)-regularization minimization problem. Besides, the internal relationship of data, such as nonlinear structure is neglected by the classification procedure conducted on the original data space. To solve these problems, this paper proposes a discriminative FR method using kernel sparse representation (KSR) based on the framework of l(2)-regularization. With the goal of extracting richer information, a kernel function is used to map the original face samples into a high feature space. Then, a new SR method based on the framework of l(2)-regularization is designed to represent the face samples on this new space. This method can produce a discriminative representation for each face sample. In addition, the proposed method offers a computational efficient algorithm for FR task. Extensive experiments conducted on the face databases show the effectiveness of our method.
C1 [Zhang, Keyou; Peng, Yali] Minist Educ, Key Lab Modern Teaching Technol, Xian 710062, Shaanxi, Peoples R China.
   [Zhang, Keyou; Peng, Yali; Liu, Shigang] Engn Lab Teaching Informat Technol Shaanxi Prov, Xian 710119, Shaanxi, Peoples R China.
   [Zhang, Keyou; Liu, Shigang] Shaanxi Normal Univ, Sch Comp Sci, Xian 710119, Shaanxi, Peoples R China.
C3 Shaanxi Normal University
RP Peng, YL (corresponding author), Minist Educ, Key Lab Modern Teaching Technol, Xian 710062, Shaanxi, Peoples R China.; Peng, YL (corresponding author), Engn Lab Teaching Informat Technol Shaanxi Prov, Xian 710119, Shaanxi, Peoples R China.
EM 876750422@qq.com
FU National Natural Science Foundation of China [61672333, 61402274,
   61703096]; Pivot Science and Technology Innovation Team of Shaanxi
   Province of China [2014KTC-18]; Key Science and Technology Program of
   Shaanxi Province of China [2016GY-081]; Science Research and Development
   Program of Shaanxi Province [2016NY-176]; Fundamental Research Funds for
   the Central Universities [GK201803088, GK201803059]; China Postdoctoral
   Science Foundation [2017M611655]; Industry university cooperative
   education project of Higher Education Department of the Ministry of
   Education [201701023062]; Interdisciplinary Incubation Project of
   Learning Science of Shaanxi Normal University
FX This work was supported in part by the National Natural Science
   Foundation of China (No.61672333, 61402274, 61703096), the Pivot Science
   and Technology Innovation Team of Shaanxi Province of China
   (No.2014KTC-18), the Key Science and Technology Program of Shaanxi
   Province of China (No.2016GY-081), the Science Research and Development
   Program of Shaanxi Province (No.2016NY-176), Fundamental Research Funds
   for the Central Universities (No.GK201803059, GK201803088), China
   Postdoctoral Science Foundation(No.2017M611655), Industry university
   cooperative education project of Higher Education Department of the
   Ministry of Education (No.201701023062) and Interdisciplinary Incubation
   Project of Learning Science of Shaanxi Normal University.
CR [Anonymous], 2015, Geometric methods in signal and image analysis
   [Anonymous], 1988, THEORY REPRODUCING K
   ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI 10.1090/s0002-9947-1950-0051437-7
   Bach FR, 2003, J MACH LEARN RES, V3, P1, DOI 10.1162/153244303768966085
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Bian X, 2016, SIAM J IMAGING SCI, V9, P1107, DOI 10.1137/15M1030376
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chen SL, 2013, KNOWL-BASED SYST, V45, P94, DOI 10.1016/j.knosys.2013.02.010
   Gao SH, 2013, IEEE T IMAGE PROCESS, V22, P423, DOI 10.1109/TIP.2012.2215620
   Goel N, 2005, PROC SPIE, V5779, P426, DOI 10.1117/12.605553
   Hofmann T, 2008, ANN STAT, V36, P1171, DOI 10.1214/009053607000000677
   Hu WM, 2015, IEEE T PATTERN ANAL, V37, P816, DOI 10.1109/TPAMI.2014.2353628
   Jing GD, 2014, MULTIMED TOOLS APPL, V70, P741, DOI 10.1007/s11042-011-0953-4
   Liu ZH, 2013, APPL INTELL, V39, P307, DOI 10.1007/s10489-012-0414-4
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Martinez A., 1998, AR FACE DATABASE
   Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Qi Zhu, 2012, 2012 21st International Conference on Pattern Recognition (ICPR 2012), P1703
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Scholkopf B., 1997, Artificial Neural Networks - ICANN '97. 7th International Conference Proceedings, P583, DOI 10.1007/BFb0020217
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Shi QF, 2011, PROC CVPR IEEE, P553, DOI 10.1109/CVPR.2011.5995556
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112
   Wang B, 2013, INT CONF ACOUST SPEE, P2877, DOI 10.1109/ICASSP.2013.6638183
   Wang D, 2015, PATTERN RECOGN, V48, P3025, DOI 10.1016/j.patcog.2015.01.012
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2016, PATTERN RECOGN, V54, P68, DOI 10.1016/j.patcog.2015.12.017
   Xu Y, 2015, PATTERN RECOGN LETT, V68, P9, DOI 10.1016/j.patrec.2015.07.032
   Xu Y, 2013, INT J INNOV COMPUT I, V9, P543
   Xu Y, 2013, INFORM SCIENCES, V238, P138, DOI 10.1016/j.ins.2013.02.051
   Xu Y, 2013, PATTERN RECOGN, V46, P1151, DOI 10.1016/j.patcog.2012.11.003
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Yang AY, 2010, IEEE IMAGE PROC, P1849, DOI 10.1109/ICIP.2010.5651522
   Yang J, 2013, IEEE T NEUR NET LEAR, V24, P1023, DOI 10.1109/TNNLS.2013.2249088
   Yang J, 2012, PATTERN RECOGN, V45, P1104, DOI 10.1016/j.patcog.2011.08.022
   Yang M, 2012, PROC CVPR IEEE, P2224, DOI 10.1109/CVPR.2012.6247931
   Yong X, 2016, IEEE T NEURAL NETW L, P1
   Zeng SN, 2017, OPTIK, V140, P528, DOI 10.1016/j.ijleo.2017.04.070
   Zhang HC, 2013, PATTERN RECOGN, V46, P1511, DOI 10.1016/j.patcog.2012.10.025
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang L, 2015, MULTIMED TOOLS APPL, V74, P123, DOI 10.1007/s11042-013-1457-1
   Zhang XQ, 2015, INT J COMPUT VISION, V115, P279, DOI 10.1007/s11263-015-0819-8
   Zhang XQ, 2014, IEEE T IND ELECTRON, V61, P1072, DOI 10.1109/TIE.2013.2258306
   Zhang XQ, 2013, PATTERN RECOGN, V46, P1750, DOI 10.1016/j.patcog.2012.08.015
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
   Zhu PF, 2012, LECT NOTES COMPUT SC, V7572, P822, DOI 10.1007/978-3-642-33718-5_59
NR 49
TC 9
Z9 9
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 32243
EP 32256
DI 10.1007/s11042-018-6110-6
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000032
DA 2024-07-18
ER

PT J
AU Chi, HM
   Xia, HF
   Tang, X
   Zhang, YH
   Xia, XF
AF Chi, Hongmei
   Xia, Haifeng
   Tang, Xin
   Zhang, Yinghao
   Xia, Xiaofen
TI Supervised neighborhood regularized collaborative representation for
   face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collaborative representation; Locality information; Face recognition;
   Feature representation
ID SPARSE REPRESENTATION; DISCRIMINATIVE DICTIONARY; IMAGE; ILLUMINATION;
   EIGENFACES
AB How to represent a test sample is very crucial for linear representation based classification. The famous sparse representation focuses on employing linear combination of small samples to represent the query sample. However, the local structure and label information of data are neglected. Recently, locality-constrained collaborative representation (LCCR) has been proposed and integrates a kind of locality-constrained term into the collaborative representation scheme. For each test sample, LCCR mainly considers its neighbors to deal with noise and LCCR is robust to various corruptions. However, the nearby samples may not belong to the same class. To deal with this situation, in this paper, we not only utilize the positive effect of neighbors, but also consider the side effect of neighbors. A novel supervised neighborhood regularized collaborative representation (SNRCR) is proposed, which employs the local structure of data and the label information of neighbors to improve the discriminative capability of the coding vector. The objective function of SNRCR obtains the global optimal solution. Many experiments are conducted over six face data sets and the results show that SNRCR outperforms other algorithms in most case, especially when the size of training data is relatively small. We also analyze the differences between SNRCR and LCCR.
C1 [Chi, Hongmei; Xia, Haifeng; Tang, Xin; Zhang, Yinghao; Xia, Xiaofen] Huazhong Agr Univ, Coll Sci, Wuhan 430070, Peoples R China.
   [Xia, Haifeng] Sun Yat Sen Univ, Sch Math, Guangzhou 510275, Guangdong, Peoples R China.
   [Tang, Xin] Huazhong Agr Univ, Inst Stat Sci, Wuhan 430070, Peoples R China.
C3 Huazhong Agricultural University; Sun Yat Sen University; Huazhong
   Agricultural University
RP Tang, X (corresponding author), Huazhong Agr Univ, Coll Sci, Wuhan 430070, Peoples R China.; Tang, X (corresponding author), Huazhong Agr Univ, Inst Stat Sci, Wuhan 430070, Peoples R China.
EM tangxin@mail.hzau.edu.cn
FU National Natural Science Foundation of China [11601174, 11671161];
   Fundamental Research Funds for the Central Universities [2662015QC033,
   2662016PY053, 2662016PY019, 2662015PY046, 2014PY025]; National Creative
   Innovation Plan of College Students of China [201510504079]
FX This work is supported by the grants from the National Natural Science
   Foundation of China (No. 11601174, No. 11671161), the Fundamental
   Research Funds for the Central Universities (No. 2662015QC033, No.
   2662016PY053, No. 2662016PY019, No. 2662015PY046 and No. 2014PY025) and
   the National Creative Innovation Plan of College Students of China (No.
   201510504079).
CR Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chen H, 2016, APPL COMPUT HARMONIC
   Chen H, 2013, NEURAL COMPUT, V25, P1107, DOI 10.1162/NECO_a_00421
   Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644, DOI 10.1109/TPAMI.2002.1114855
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Gao SH, 2014, IEEE T IMAGE PROCESS, V23, P623, DOI 10.1109/TIP.2013.2290593
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Guo J, 2015, IEEE IMAGE PROC, P1558, DOI 10.1109/ICIP.2015.7351062
   Haghiri S, 2014, IEEE IMAGE PROC, P5242, DOI 10.1109/ICIP.2014.7026061
   He R, 2011, IEEE T PATTERN ANAL, V33, P1561, DOI 10.1109/TPAMI.2010.220
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Heisele B, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P688, DOI 10.1109/ICCV.2001.937693
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Liu BD, 2016, NEUROCOMPUTING, V204, P198, DOI 10.1016/j.neucom.2015.08.128
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Peng X, 2014, PATTERN RECOGN, V47, P2794, DOI 10.1016/j.patcog.2014.03.013
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Piao X, 2016, ARXIV160101432
   Ramirez I, 2010, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR.2010.5539964
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Shuyang Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P17, DOI 10.1109/CVPRW.2015.7301315
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Sun YB, 2014, IEEE T IMAGE PROCESS, V23, P3816, DOI 10.1109/TIP.2014.2331760
   Sun ZL, 2016, NEUROCOMPUTING, V188, P160, DOI 10.1016/j.neucom.2014.10.111
   Taigman Y., 2009, British Machine Vision Conference, P1
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Tang X, 2014, NEUROCOMPUTING, V145, P402, DOI 10.1016/j.neucom.2014.05.012
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Valmadre J, 2012, LECT NOTES COMPUT SC, V7572, P72, DOI 10.1007/978-3-642-33718-5_6
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wei CP, 2013, PATTERN RECOGN, V46, P1277, DOI 10.1016/j.patcog.2012.11.014
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2016, L2 REGULARIZATION IE
   Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Yang M, 2010, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2010.5652363
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang N, 2012, PATTERN RECOGN LETT, V33, P1689, DOI 10.1016/j.patrec.2012.05.020
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
   Zheng WM, 2005, NEUROCOMPUTING, V67, P357, DOI 10.1016/j.neucom.2004.12.008
   Zhu YG, 2011, PROCEEDINGS OF THE ASME INTERNATIONAL MANUFACTURING SCIENCE AND ENGINEERING CONFERENCE 2010, VOL 2, P1, DOI 10.1109/CVPR.2011.5995650
   Zhu Yingying, 2016, Med Image Comput Comput Assist Interv, V9900, P264, DOI 10.1007/978-3-319-46720-7_31
   Zhu YY, 2014, PROC CVPR IEEE, P1542, DOI 10.1109/CVPR.2014.200
   Zhu YY, 2015, IEEE T PATTERN ANAL, V37, P529, DOI 10.1109/TPAMI.2013.2295311
   Zhu YY, 2012, INT C PATT RECOG, P841
NR 50
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29509
EP 29529
DI 10.1007/s11042-017-4851-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800018
DA 2024-07-18
ER

PT J
AU Choi, YH
   Hong, M
   Choi, YJ
AF Choi, Young-Hwan
   Hong, Min
   Choi, Yoo-Joo
TI Parallel cloth simulation with GPGPU
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE GPU-based parallel processing; Real-time simulation; Mass-spring system;
   Physically-based simulation
ID ALGORITHM
AB In a 3D simulation, numerous physically and numerically related calculations are required to represent an object realistically. The existing CPU (central processing unit) technology, however, is incapable of handling such a large computational amount in real time. With the recent hardware-technology advancements, the GPU (graphics processing unit) can be used not only for conventional rendering operations, but also for general-purpose computational functions. In this paper, a mass-spring system for which the CPU and GPU versions are tested under the PC and mobile environments wherein the GPGPU (general-purpose computing on GPUs) is applied is proposed. For this paper, a virtual cloth with a mass-spring system was freely dropped onto a table, and the CPU and GPU performances were compared. The computational GPU performances regarding the PC and mobile devices were improved by 9.41 times and 45.11 times, respectively, compared with the CPU. The proposed GPU mass-spring system was then implemented with an edge-centric algorithm and a node-centric algorithm. The edge-centric algorithm is divided into two parts as follows: one for the spring-force calculation and one for the node-position calculation. These two parts are combined into a single computational process for the node-centric algorithm. For this paper, the computational speeds of the two algorithms were measured. The node-centric algorithm is faster than the edge-centric algorithm under the PC environment, but the edge-centric algorithm is faster under the mobile environment.
C1 [Choi, Young-Hwan] Soonchunhyang Univ, Dept Comp Sci, Asan, South Korea.
   [Hong, Min] Soonchunhyang Univ, Dept Comp Software Engn, Asan, South Korea.
   [Choi, Yoo-Joo] Seoul Media Inst Technol, Dept Newmedia, Seoul, South Korea.
C3 Soonchunhyang University; Soonchunhyang University
RP Choi, YJ (corresponding author), Seoul Media Inst Technol, Dept Newmedia, Seoul, South Korea.
EM compust@sch.ac.kr; mhong@sch.ac.kr; yjchoi@smit.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2015R1D1A1A01059304];
   Soonchunhyang University Research Fund
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2015R1D1A1A01059304) and was supported by the
   Soonchunhyang University Research Fund.
CR [Anonymous], P 25 ANN C COMP GRAP
   [Anonymous], J CONVERG
   [Anonymous], J CONVERGENCE
   Bostanci E, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0040-3
   BroNielsen M, 1996, COMPUT GRAPH FORUM, V15, pC57
   Campos RS, 2014, J SUPERCOMPUT, V69, P1, DOI 10.1007/s11227-014-1199-5
   Chen Y, 1998, COMPUTER ANIMATION, V98
   Chikazawa Y, 2001, COMPUT MECH, V27, P97, DOI 10.1007/s004660000216
   Gibson SF, 1997, P 1997 S INT 3D GRAP
   Hong M, 2016, HUM-CENTRIC COMPUT I, V6, DOI 10.1186/s13673-016-0079-9
   Jeon J, 2012, J INF PROCESS SYST, V8, P713, DOI 10.3745/JIPS.2012.8.4.713
   Jog A, 2013, ACM SIGPLAN NOTICES, V48, P395, DOI 10.1145/2499368.2451158
   Kurzion Y, 1995, SPRING COMP SCI, P21
   Lee S, 2012, J INF PROCESS SYST, V8, P159, DOI 10.3745/JIPS.2012.8.1.159
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Nie DH, 2009, J INF PROCESS SYST, V5, P105, DOI 10.3745/JIPS.2009.5.2.105
   Pan Yi, 2012, J. Converg., V3, P23
   Pei SW, 2016, KSII T INTERNET INF, V10, P3231, DOI 10.3837/tiis.2016.07.020
   Saravanan V, 2015, HUMAN CTR COMPUTING, V5, P1, DOI DOI 10.1186/S13673-014-0018-6
   Shan RY, 2016, KSII T INTERNET INF, V10, P4467, DOI 10.3837/tiis.2016.09.024
   Tang M, 2013, COMPUT GRAPH FORUM, V32, P21, DOI 10.1111/cgf.12208
   Vassilev T., 2002, P E W VISION, V2002, P149
   Wang CY, 2015, KSII T INTERNET INF, V9, P1457, DOI 10.3837/tiis.2015.04.011
NR 23
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 30105
EP 30120
DI 10.1007/s11042-018-6188-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800053
DA 2024-07-18
ER

EF